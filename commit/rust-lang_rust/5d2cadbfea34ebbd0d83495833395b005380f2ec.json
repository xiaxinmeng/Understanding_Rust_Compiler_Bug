{"sha": "5d2cadbfea34ebbd0d83495833395b005380f2ec", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVkMmNhZGJmZWEzNGViYmQwZDgzNDk1ODMzMzk1YjAwNTM4MGYyZWM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-06-07T01:43:37Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-06-07T01:43:37Z"}, "message": "auto merge of #6895 : cmr/rust/jemalloc, r=brson", "tree": {"sha": "6d1ec6b3541abccb8cffeb7b1aa11ffca65fe48f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6d1ec6b3541abccb8cffeb7b1aa11ffca65fe48f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5d2cadbfea34ebbd0d83495833395b005380f2ec", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5d2cadbfea34ebbd0d83495833395b005380f2ec", "html_url": "https://github.com/rust-lang/rust/commit/5d2cadbfea34ebbd0d83495833395b005380f2ec", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5d2cadbfea34ebbd0d83495833395b005380f2ec/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f2e6c01eaff38a93d3c604d6f54c6506f86de1cc", "url": "https://api.github.com/repos/rust-lang/rust/commits/f2e6c01eaff38a93d3c604d6f54c6506f86de1cc", "html_url": "https://github.com/rust-lang/rust/commit/f2e6c01eaff38a93d3c604d6f54c6506f86de1cc"}, {"sha": "829b5de9988fa71a7a585df5b9c46ea07e05a431", "url": "https://api.github.com/repos/rust-lang/rust/commits/829b5de9988fa71a7a585df5b9c46ea07e05a431", "html_url": "https://github.com/rust-lang/rust/commit/829b5de9988fa71a7a585df5b9c46ea07e05a431"}], "stats": {"total": 44457, "additions": 44444, "deletions": 13}, "files": [{"sha": "22d42a82a3b83108883e23a72f310b6b902f1b09", "filename": ".gitattributes", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/.gitattributes", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/.gitattributes", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.gitattributes?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -7,3 +7,4 @@\n src/rt/msvc/* -whitespace\n src/rt/vg/* -whitespace\n src/rt/linenoise/* -whitespace\n+src/rt/jemalloc/**/* -whitespace"}, {"sha": "e581631b71da51a9085c605a537176b4bec93118", "filename": "configure", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/configure", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/configure", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/configure?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -683,7 +683,8 @@ do\n     for i in                                          \\\n       isaac linenoise sync test \\\n       arch/i386 arch/x86_64 arch/arm arch/mips  \\\n-      libuv libuv/src/ares libuv/src/eio libuv/src/ev\n+      libuv libuv/src/ares libuv/src/eio libuv/src/ev \\\n+      jemalloc\n     do\n       make_dir rt/$t/stage$s/$i\n     done"}, {"sha": "4bb8de28aefa390d88ad91d413cae9f086c163d4", "filename": "mk/platform.mk", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/mk%2Fplatform.mk", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/mk%2Fplatform.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fplatform.mk?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -146,7 +146,7 @@ CFG_LIB_GLOB_x86_64-unknown-linux-gnu=lib$(1)-*.so\n CFG_LIB_DSYM_GLOB_x86_64-unknown-linux-gnu=lib$(1)-*.dylib.dSYM\n CFG_GCCISH_CFLAGS_x86_64-unknown-linux-gnu := -Wall -Werror -g -fPIC -m64\n CFG_GCCISH_CXXFLAGS_x86_64-unknown-linux-gnu := -fno-rtti\n-CFG_GCCISH_LINK_FLAGS_x86_64-unknown-linux-gnu := -shared -fPIC -ldl -lpthread -lrt -g -m64\n+CFG_GCCISH_LINK_FLAGS_x86_64-unknown-linux-gnu := -shared -fPIC -ldl -pthread  -lrt -g -m64\n CFG_GCCISH_DEF_FLAG_x86_64-unknown-linux-gnu := -Wl,--export-dynamic,--dynamic-list=\n CFG_GCCISH_PRE_LIB_FLAGS_x86_64-unknown-linux-gnu := -Wl,-whole-archive\n CFG_GCCISH_POST_LIB_FLAGS_x86_64-unknown-linux-gnu := -Wl,-no-whole-archive\n@@ -172,7 +172,7 @@ CFG_LIB_GLOB_i686-unknown-linux-gnu=lib$(1)-*.so\n CFG_LIB_DSYM_GLOB_i686-unknown-linux-gnu=lib$(1)-*.dylib.dSYM\n CFG_GCCISH_CFLAGS_i686-unknown-linux-gnu := -Wall -Werror -g -fPIC -m32\n CFG_GCCISH_CXXFLAGS_i686-unknown-linux-gnu := -fno-rtti\n-CFG_GCCISH_LINK_FLAGS_i686-unknown-linux-gnu := -shared -fPIC -ldl -lpthread -lrt -g -m32\n+CFG_GCCISH_LINK_FLAGS_i686-unknown-linux-gnu := -shared -fPIC -ldl -pthread  -lrt -g -m32\n CFG_GCCISH_DEF_FLAG_i686-unknown-linux-gnu := -Wl,--export-dynamic,--dynamic-list=\n CFG_GCCISH_PRE_LIB_FLAGS_i686-unknown-linux-gnu := -Wl,-whole-archive\n CFG_GCCISH_POST_LIB_FLAGS_i686-unknown-linux-gnu := -Wl,-no-whole-archive\n@@ -198,7 +198,7 @@ CFG_LIB_GLOB_x86_64-apple-darwin=lib$(1)-*.dylib\n CFG_LIB_DSYM_GLOB_x86_64-apple-darwin=lib$(1)-*.dylib.dSYM\n CFG_GCCISH_CFLAGS_x86_64-apple-darwin := -Wall -Werror -g -fPIC -m64 -arch x86_64\n CFG_GCCISH_CXXFLAGS_x86_64-apple-darwin := -fno-rtti\n-CFG_GCCISH_LINK_FLAGS_x86_64-apple-darwin := -dynamiclib -lpthread -framework CoreServices -Wl,-no_compact_unwind -m64\n+CFG_GCCISH_LINK_FLAGS_x86_64-apple-darwin := -dynamiclib -pthread  -framework CoreServices -Wl,-no_compact_unwind -m64\n CFG_GCCISH_DEF_FLAG_x86_64-apple-darwin := -Wl,-exported_symbols_list,\n CFG_GCCISH_PRE_LIB_FLAGS_x86_64-apple-darwin :=\n CFG_GCCISH_POST_LIB_FLAGS_x86_64-apple-darwin :=\n@@ -223,7 +223,7 @@ CFG_LIB_GLOB_i686-apple-darwin=lib$(1)-*.dylib\n CFG_LIB_DSYM_GLOB_i686-apple-darwin=lib$(1)-*.dylib.dSYM\n CFG_GCCISH_CFLAGS_i686-apple-darwin := -Wall -Werror -g -fPIC -m32 -arch i386\n CFG_GCCISH_CXXFLAGS_i686-apple-darwin := -fno-rtti\n-CFG_GCCISH_LINK_FLAGS_i686-apple-darwin := -dynamiclib -lpthread -framework CoreServices -Wl,-no_compact_unwind -m32\n+CFG_GCCISH_LINK_FLAGS_i686-apple-darwin := -dynamiclib -pthread  -framework CoreServices -Wl,-no_compact_unwind -m32\n CFG_GCCISH_DEF_FLAG_i686-apple-darwin := -Wl,-exported_symbols_list,\n CFG_GCCISH_PRE_LIB_FLAGS_i686-apple-darwin :=\n CFG_GCCISH_POST_LIB_FLAGS_i686-apple-darwin :=\n@@ -376,13 +376,13 @@ CFG_LIB_NAME_x86_64-unknown-freebsd=lib$(1).so\n CFG_LIB_GLOB_x86_64-unknown-freebsd=lib$(1)-*.so\n CFG_LIB_DSYM_GLOB_x86_64-unknown-freebsd=$(1)-*.dylib.dSYM\n CFG_GCCISH_CFLAGS_x86_64-unknown-freebsd := -Wall -Werror -g -fPIC -I/usr/local/include\n-CFG_GCCISH_LINK_FLAGS_x86_64-unknown-freebsd := -shared -fPIC -g -lpthread -lrt\n+CFG_GCCISH_LINK_FLAGS_x86_64-unknown-freebsd := -shared -fPIC -g -pthread  -lrt\n CFG_GCCISH_DEF_FLAG_x86_64-unknown-freebsd := -Wl,--export-dynamic,--dynamic-list=\n CFG_GCCISH_PRE_LIB_FLAGS_x86_64-unknown-freebsd := -Wl,-whole-archive\n CFG_GCCISH_POST_LIB_FLAGS_x86_64-unknown-freebsd := -Wl,-no-whole-archive\n CFG_DEF_SUFFIX_x86_64-unknown-freebsd := .bsd.def\n CFG_INSTALL_NAME_x86_64-unknown-freebsd =\n-CFG_LIBUV_LINK_FLAGS_x86_64-unknown-freebsd := -lpthread -lkvm\n+CFG_LIBUV_LINK_FLAGS_x86_64-unknown-freebsd := -pthread  -lkvm\n CFG_EXE_SUFFIX_x86_64-unknown-freebsd :=\n CFG_WINDOWSY_x86_64-unknown-freebsd :=\n CFG_UNIXY_x86_64-unknown-freebsd := 1"}, {"sha": "a14e49a169c935de3706fb0132309d42d9471a04", "filename": "mk/rt.mk", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/mk%2Frt.mk", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/mk%2Frt.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Frt.mk?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -106,18 +106,23 @@ RUNTIME_S_$(1)_$(2) := rt/arch/$$(HOST_$(1))/_context.S \\\n ifeq ($$(CFG_WINDOWSY_$(1)), 1)\n   LIBUV_OSTYPE_$(1)_$(2) := win\n   LIBUV_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/libuv/libuv.a\n+  JEMALLOC_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/jemalloc/lib/jemalloc.lib\n else ifeq ($(OSTYPE_$(1)), apple-darwin)\n   LIBUV_OSTYPE_$(1)_$(2) := mac\n   LIBUV_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/libuv/libuv.a\n+  JEMALLOC_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/jemalloc/lib/libjemalloc_pic.a\n else ifeq ($(OSTYPE_$(1)), unknown-freebsd)\n   LIBUV_OSTYPE_$(1)_$(2) := unix/freebsd\n   LIBUV_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/libuv/libuv.a\n+  JEMALLOC_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/jemalloc/lib/libjemalloc_pic.a\n else ifeq ($(OSTYPE_$(1)), linux-androideabi)\n   LIBUV_OSTYPE_$(1)_$(2) := unix/android\n   LIBUV_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/libuv/libuv.a\n+  JEMALLOC_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/jemalloc/lib/libjemalloc_pic.a\n else\n   LIBUV_OSTYPE_$(1)_$(2) := unix/linux\n   LIBUV_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/libuv/libuv.a\n+  JEMALLOC_LIB_$(1)_$(2) := rt/$(1)/stage$(2)/jemalloc/lib/libjemalloc_pic.a\n endif\n \n RUNTIME_DEF_$(1)_$(2) := rt/rustrt$(CFG_DEF_SUFFIX_$(1))\n@@ -133,8 +138,6 @@ ALL_OBJ_FILES += $$(RUNTIME_OBJS_$(1)_$(2))\n MORESTACK_OBJ_$(1)_$(2) := rt/$(1)/stage$(2)/arch/$$(HOST_$(1))/morestack.o\n ALL_OBJ_FILES += $$(MORESTACK_OBJS_$(1)_$(2))\n \n-RUNTIME_LIBS_$(1)_$(2) := $$(LIBUV_LIB_$(1)_$(2))\n-\n rt/$(1)/stage$(2)/%.o: rt/%.cpp $$(MKFILE_DEPS)\n \t@$$(call E, compile: $$@)\n \t$$(Q)$$(call CFG_COMPILE_CXX_$(1), $$@, $$(RUNTIME_INCS_$(1)_$(2)) \\\n@@ -155,11 +158,10 @@ rt/$(1)/stage$(2)/arch/$$(HOST_$(1))/libmorestack.a: $$(MORESTACK_OBJ_$(1)_$(2))\n \t$$(Q)$(AR_$(1)) rcs $$@ $$<\n \n rt/$(1)/stage$(2)/$(CFG_RUNTIME_$(1)): $$(RUNTIME_OBJS_$(1)_$(2)) $$(MKFILE_DEPS) \\\n-                        $$(RUNTIME_DEF_$(1)_$(2)) \\\n-                        $$(RUNTIME_LIBS_$(1)_$(2))\n+                        $$(RUNTIME_DEF_$(1)_$(2)) $$(LIBUV_LIB_$(1)_$(2)) $$(JEMALLOC_LIB_$(1)_$(2))\n \t@$$(call E, link: $$@)\n \t$$(Q)$$(call CFG_LINK_CXX_$(1),$$@, $$(RUNTIME_OBJS_$(1)_$(2)) \\\n-\t  $$(CFG_GCCISH_POST_LIB_FLAGS_$(1)) $$(RUNTIME_LIBS_$(1)_$(2)) \\\n+\t  $$(JEMALLOC_LIB_$(1)_$(2)) $$(CFG_GCCISH_POST_LIB_FLAGS_$(1)) $$(LIBUV_LIB_$(1)_$(2)) \\\n \t  $$(CFG_LIBUV_LINK_FLAGS_$(1)),$$(RUNTIME_DEF_$(1)_$(2)),$$(CFG_RUNTIME_$(1)))\n \n # FIXME: For some reason libuv's makefiles can't figure out the\n@@ -208,6 +210,9 @@ $$(LIBUV_LIB_$(1)_$(2)): $$(LIBUV_DEPS)\n \t\tV=$$(VERBOSE)\n endif\n \n+$$(JEMALLOC_LIB_$(1)_$(2)):\n+\tcd $$(CFG_BUILD_DIR)/rt/$(1)/stage$(2)/jemalloc; $(S)src/rt/jemalloc/configure --disable-experimental\n+\t$$(Q)$$(MAKE) -C $$(CFG_BUILD_DIR)/rt/$(1)/stage$(2)/jemalloc\n \n # These could go in rt.mk or rustllvm.mk, they're needed for both.\n "}, {"sha": "62f0731dab6e5a94e26232115d13f80ba1891bb2", "filename": "src/compiletest/procsrv.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Fcompiletest%2Fprocsrv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Fcompiletest%2Fprocsrv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcompiletest%2Fprocsrv.rs?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -17,6 +17,7 @@ use core::os;\n use core::run;\n use core::str;\n use core::task;\n+use core::vec;\n \n #[cfg(target_os = \"win32\")]\n fn target_env(lib_path: &str, prog: &str) -> ~[(~str,~str)] {\n@@ -28,7 +29,7 @@ fn target_env(lib_path: &str, prog: &str) -> ~[(~str,~str)] {\n     let aux_path = prog.slice(0u, prog.len() - 4u).to_owned() + \".libaux\";\n \n     env = do vec::map(env) |pair| {\n-        let (k,v) = *pair;\n+        let (k,v) = copy *pair;\n         if k == ~\"PATH\" { (~\"PATH\", v + \";\" + lib_path + \";\" + aux_path) }\n         else { (k,v) }\n     };"}, {"sha": "019e8132275d7398eabb90935f85f7b337d25658", "filename": "src/rt/jemalloc/COPYING", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FCOPYING", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FCOPYING", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2FCOPYING?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,27 @@\n+Unless otherwise specified, files in the jemalloc source distribution are\n+subject to the following license:\n+--------------------------------------------------------------------------------\n+Copyright (C) 2002-2013 Jason Evans <jasone@canonware.com>.\n+All rights reserved.\n+Copyright (C) 2007-2012 Mozilla Foundation.  All rights reserved.\n+Copyright (C) 2009-2013 Facebook, Inc.  All rights reserved.\n+\n+Redistribution and use in source and binary forms, with or without\n+modification, are permitted provided that the following conditions are met:\n+1. Redistributions of source code must retain the above copyright notice(s),\n+   this list of conditions and the following disclaimer.\n+2. Redistributions in binary form must reproduce the above copyright notice(s),\n+   this list of conditions and the following disclaimer in the documentation\n+   and/or other materials provided with the distribution.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDER(S) ``AS IS'' AND ANY EXPRESS\n+OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO\n+EVENT SHALL THE COPYRIGHT HOLDER(S) BE LIABLE FOR ANY DIRECT, INDIRECT,\n+INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE\n+OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n+ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+--------------------------------------------------------------------------------"}, {"sha": "fc096d8f42fde1898ee81b898ac974b9809a98c6", "filename": "src/rt/jemalloc/ChangeLog", "status": "added", "additions": 425, "deletions": 0, "changes": 425, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FChangeLog", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FChangeLog", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2FChangeLog?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,425 @@\n+Following are change highlights associated with official releases.  Important\n+bug fixes are all mentioned, but internal enhancements are omitted here for\n+brevity (even though they are more fun to write about).  Much more detail can be\n+found in the git revision history:\n+\n+    http://www.canonware.com/cgi-bin/gitweb.cgi?p=jemalloc.git\n+    git://canonware.com/jemalloc.git\n+\n+* 3.3.1 (March 6, 2013)\n+\n+  This version fixes bugs that are typically encountered only when utilizing\n+  custom run-time options.\n+\n+  Bug fixes:\n+  - Fix a locking order bug that could cause deadlock during fork if heap\n+    profiling were enabled.\n+  - Fix a chunk recycling bug that could cause the allocator to lose track of\n+    whether a chunk was zeroed.   On FreeBSD, NetBSD, and OS X, it could cause\n+    corruption if allocating via sbrk(2) (unlikely unless running with the\n+    \"dss:primary\" option specified).  This was completely harmless on Linux\n+    unless using mlockall(2) (and unlikely even then, unless the\n+    --disable-munmap configure option or the \"dss:primary\" option was\n+    specified).  This regression was introduced in 3.1.0 by the\n+    mlockall(2)/madvise(2) interaction fix.\n+  - Fix TLS-related memory corruption that could occur during thread exit if the\n+    thread never allocated memory.  Only the quarantine and prof facilities were\n+    susceptible.\n+  - Fix two quarantine bugs:\n+    + Internal reallocation of the quarantined object array leaked the old\n+      array.\n+    + Reallocation failure for internal reallocation of the quarantined object\n+      array (very unlikely) resulted in memory corruption.\n+  - Fix Valgrind integration to annotate all internally allocated memory in a\n+    way that keeps Valgrind happy about internal data structure access.\n+  - Fix building for s390 systems.\n+\n+* 3.3.0 (January 23, 2013)\n+\n+  This version includes a few minor performance improvements in addition to the\n+  listed new features and bug fixes.\n+\n+  New features:\n+  - Add clipping support to lg_chunk option processing.\n+  - Add the --enable-ivsalloc option.\n+  - Add the --without-export option.\n+  - Add the --disable-zone-allocator option.\n+\n+  Bug fixes:\n+  - Fix \"arenas.extend\" mallctl to output the number of arenas.\n+  - Fix chunk_recycyle() to unconditionally inform Valgrind that returned memory\n+    is undefined.\n+  - Fix build break on FreeBSD related to alloca.h.\n+\n+* 3.2.0 (November 9, 2012)\n+\n+  In addition to a couple of bug fixes, this version modifies page run\n+  allocation and dirty page purging algorithms in order to better control\n+  page-level virtual memory fragmentation.\n+\n+  Incompatible changes:\n+  - Change the \"opt.lg_dirty_mult\" default from 5 to 3 (32:1 to 8:1).\n+\n+  Bug fixes:\n+  - Fix dss/mmap allocation precedence code to use recyclable mmap memory only\n+    after primary dss allocation fails.\n+  - Fix deadlock in the \"arenas.purge\" mallctl.  This regression was introduced\n+    in 3.1.0 by the addition of the \"arena.<i>.purge\" mallctl.\n+\n+* 3.1.0 (October 16, 2012)\n+\n+  New features:\n+  - Auto-detect whether running inside Valgrind, thus removing the need to\n+    manually specify MALLOC_CONF=valgrind:true.\n+  - Add the \"arenas.extend\" mallctl, which allows applications to create\n+    manually managed arenas.\n+  - Add the ALLOCM_ARENA() flag for {,r,d}allocm().\n+  - Add the \"opt.dss\", \"arena.<i>.dss\", and \"stats.arenas.<i>.dss\" mallctls,\n+    which provide control over dss/mmap precedence.\n+  - Add the \"arena.<i>.purge\" mallctl, which obsoletes \"arenas.purge\".\n+  - Define LG_QUANTUM for hppa.\n+\n+  Incompatible changes:\n+  - Disable tcache by default if running inside Valgrind, in order to avoid\n+    making unallocated objects appear reachable to Valgrind.\n+  - Drop const from malloc_usable_size() argument on Linux.\n+\n+  Bug fixes:\n+  - Fix heap profiling crash if sampled object is freed via realloc(p, 0).\n+  - Remove const from __*_hook variable declarations, so that glibc can modify\n+    them during process forking.\n+  - Fix mlockall(2)/madvise(2) interaction.\n+  - Fix fork(2)-related deadlocks.\n+  - Fix error return value for \"thread.tcache.enabled\" mallctl.\n+\n+* 3.0.0 (May 11, 2012)\n+\n+  Although this version adds some major new features, the primary focus is on\n+  internal code cleanup that facilitates maintainability and portability, most\n+  of which is not reflected in the ChangeLog.  This is the first release to\n+  incorporate substantial contributions from numerous other developers, and the\n+  result is a more broadly useful allocator (see the git revision history for\n+  contribution details).  Note that the license has been unified, thanks to\n+  Facebook granting a license under the same terms as the other copyright\n+  holders (see COPYING).\n+\n+  New features:\n+  - Implement Valgrind support, redzones, and quarantine.\n+  - Add support for additional platforms:\n+    + FreeBSD\n+    + Mac OS X Lion\n+    + MinGW\n+    + Windows (no support yet for replacing the system malloc)\n+  - Add support for additional architectures:\n+    + MIPS\n+    + SH4\n+    + Tilera\n+  - Add support for cross compiling.\n+  - Add nallocm(), which rounds a request size up to the nearest size class\n+    without actually allocating.\n+  - Implement aligned_alloc() (blame C11).\n+  - Add the \"thread.tcache.enabled\" mallctl.\n+  - Add the \"opt.prof_final\" mallctl.\n+  - Update pprof (from gperftools 2.0).\n+  - Add the --with-mangling option.\n+  - Add the --disable-experimental option.\n+  - Add the --disable-munmap option, and make it the default on Linux.\n+  - Add the --enable-mremap option, which disables use of mremap(2) by default.\n+\n+  Incompatible changes:\n+  - Enable stats by default.\n+  - Enable fill by default.\n+  - Disable lazy locking by default.\n+  - Rename the \"tcache.flush\" mallctl to \"thread.tcache.flush\".\n+  - Rename the \"arenas.pagesize\" mallctl to \"arenas.page\".\n+  - Change the \"opt.lg_prof_sample\" default from 0 to 19 (1 B to 512 KiB).\n+  - Change the \"opt.prof_accum\" default from true to false.\n+\n+  Removed features:\n+  - Remove the swap feature, including the \"config.swap\", \"swap.avail\",\n+    \"swap.prezeroed\", \"swap.nfds\", and \"swap.fds\" mallctls.\n+  - Remove highruns statistics, including the\n+    \"stats.arenas.<i>.bins.<j>.highruns\" and\n+    \"stats.arenas.<i>.lruns.<j>.highruns\" mallctls.\n+  - As part of small size class refactoring, remove the \"opt.lg_[qc]space_max\",\n+    \"arenas.cacheline\", \"arenas.subpage\", \"arenas.[tqcs]space_{min,max}\", and\n+    \"arenas.[tqcs]bins\" mallctls.\n+  - Remove the \"arenas.chunksize\" mallctl.\n+  - Remove the \"opt.lg_prof_tcmax\" option.\n+  - Remove the \"opt.lg_prof_bt_max\" option.\n+  - Remove the \"opt.lg_tcache_gc_sweep\" option.\n+  - Remove the --disable-tiny option, including the \"config.tiny\" mallctl.\n+  - Remove the --enable-dynamic-page-shift configure option.\n+  - Remove the --enable-sysv configure option.\n+\n+  Bug fixes:\n+  - Fix a statistics-related bug in the \"thread.arena\" mallctl that could cause\n+    invalid statistics and crashes.\n+  - Work around TLS deallocation via free() on Linux.  This bug could cause\n+    write-after-free memory corruption.\n+  - Fix a potential deadlock that could occur during interval- and\n+    growth-triggered heap profile dumps.\n+  - Fix large calloc() zeroing bugs due to dropping chunk map unzeroed flags.\n+  - Fix chunk_alloc_dss() to stop claiming memory is zeroed.  This bug could\n+    cause memory corruption and crashes with --enable-dss specified.\n+  - Fix fork-related bugs that could cause deadlock in children between fork\n+    and exec.\n+  - Fix malloc_stats_print() to honor 'b' and 'l' in the opts parameter.\n+  - Fix realloc(p, 0) to act like free(p).\n+  - Do not enforce minimum alignment in memalign().\n+  - Check for NULL pointer in malloc_usable_size().\n+  - Fix an off-by-one heap profile statistics bug that could be observed in\n+    interval- and growth-triggered heap profiles.\n+  - Fix the \"epoch\" mallctl to update cached stats even if the passed in epoch\n+    is 0.\n+  - Fix bin->runcur management to fix a layout policy bug.  This bug did not\n+    affect correctness.\n+  - Fix a bug in choose_arena_hard() that potentially caused more arenas to be\n+    initialized than necessary.\n+  - Add missing \"opt.lg_tcache_max\" mallctl implementation.\n+  - Use glibc allocator hooks to make mixed allocator usage less likely.\n+  - Fix build issues for --disable-tcache.\n+  - Don't mangle pthread_create() when --with-private-namespace is specified.\n+\n+* 2.2.5 (November 14, 2011)\n+\n+  Bug fixes:\n+  - Fix huge_ralloc() race when using mremap(2).  This is a serious bug that\n+    could cause memory corruption and/or crashes.\n+  - Fix huge_ralloc() to maintain chunk statistics.\n+  - Fix malloc_stats_print(..., \"a\") output.\n+\n+* 2.2.4 (November 5, 2011)\n+\n+  Bug fixes:\n+  - Initialize arenas_tsd before using it.  This bug existed for 2.2.[0-3], as\n+    well as for --disable-tls builds in earlier releases.\n+  - Do not assume a 4 KiB page size in test/rallocm.c.\n+\n+* 2.2.3 (August 31, 2011)\n+\n+  This version fixes numerous bugs related to heap profiling.\n+\n+  Bug fixes:\n+  - Fix a prof-related race condition.  This bug could cause memory corruption,\n+    but only occurred in non-default configurations (prof_accum:false).\n+  - Fix off-by-one backtracing issues (make sure that prof_alloc_prep() is\n+    excluded from backtraces).\n+  - Fix a prof-related bug in realloc() (only triggered by OOM errors).\n+  - Fix prof-related bugs in allocm() and rallocm().\n+  - Fix prof_tdata_cleanup() for --disable-tls builds.\n+  - Fix a relative include path, to fix objdir builds.\n+\n+* 2.2.2 (July 30, 2011)\n+\n+  Bug fixes:\n+  - Fix a build error for --disable-tcache.\n+  - Fix assertions in arena_purge() (for real this time).\n+  - Add the --with-private-namespace option.  This is a workaround for symbol\n+    conflicts that can inadvertently arise when using static libraries.\n+\n+* 2.2.1 (March 30, 2011)\n+\n+  Bug fixes:\n+  - Implement atomic operations for x86/x64.  This fixes compilation failures\n+    for versions of gcc that are still in wide use.\n+  - Fix an assertion in arena_purge().\n+\n+* 2.2.0 (March 22, 2011)\n+\n+  This version incorporates several improvements to algorithms and data\n+  structures that tend to reduce fragmentation and increase speed.\n+\n+  New features:\n+  - Add the \"stats.cactive\" mallctl.\n+  - Update pprof (from google-perftools 1.7).\n+  - Improve backtracing-related configuration logic, and add the\n+    --disable-prof-libgcc option.\n+\n+  Bug fixes:\n+  - Change default symbol visibility from \"internal\", to \"hidden\", which\n+    decreases the overhead of library-internal function calls.\n+  - Fix symbol visibility so that it is also set on OS X.\n+  - Fix a build dependency regression caused by the introduction of the .pic.o\n+    suffix for PIC object files.\n+  - Add missing checks for mutex initialization failures.\n+  - Don't use libgcc-based backtracing except on x64, where it is known to work.\n+  - Fix deadlocks on OS X that were due to memory allocation in\n+    pthread_mutex_lock().\n+  - Heap profiling-specific fixes:\n+    + Fix memory corruption due to integer overflow in small region index\n+      computation, when using a small enough sample interval that profiling\n+      context pointers are stored in small run headers.\n+    + Fix a bootstrap ordering bug that only occurred with TLS disabled.\n+    + Fix a rallocm() rsize bug.\n+    + Fix error detection bugs for aligned memory allocation.\n+\n+* 2.1.3 (March 14, 2011)\n+\n+  Bug fixes:\n+  - Fix a cpp logic regression (due to the \"thread.{de,}allocatedp\" mallctl fix\n+    for OS X in 2.1.2).\n+  - Fix a \"thread.arena\" mallctl bug.\n+  - Fix a thread cache stats merging bug.\n+\n+* 2.1.2 (March 2, 2011)\n+\n+  Bug fixes:\n+  - Fix \"thread.{de,}allocatedp\" mallctl for OS X.\n+  - Add missing jemalloc.a to build system.\n+\n+* 2.1.1 (January 31, 2011)\n+\n+  Bug fixes:\n+  - Fix aligned huge reallocation (affected allocm()).\n+  - Fix the ALLOCM_LG_ALIGN macro definition.\n+  - Fix a heap dumping deadlock.\n+  - Fix a \"thread.arena\" mallctl bug.\n+\n+* 2.1.0 (December 3, 2010)\n+\n+  This version incorporates some optimizations that can't quite be considered\n+  bug fixes.\n+\n+  New features:\n+  - Use Linux's mremap(2) for huge object reallocation when possible.\n+  - Avoid locking in mallctl*() when possible.\n+  - Add the \"thread.[de]allocatedp\" mallctl's.\n+  - Convert the manual page source from roff to DocBook, and generate both roff\n+    and HTML manuals.\n+\n+  Bug fixes:\n+  - Fix a crash due to incorrect bootstrap ordering.  This only impacted\n+    --enable-debug --enable-dss configurations.\n+  - Fix a minor statistics bug for mallctl(\"swap.avail\", ...).\n+\n+* 2.0.1 (October 29, 2010)\n+\n+  Bug fixes:\n+  - Fix a race condition in heap profiling that could cause undefined behavior\n+    if \"opt.prof_accum\" were disabled.\n+  - Add missing mutex unlocks for some OOM error paths in the heap profiling\n+    code.\n+  - Fix a compilation error for non-C99 builds.\n+\n+* 2.0.0 (October 24, 2010)\n+\n+  This version focuses on the experimental *allocm() API, and on improved\n+  run-time configuration/introspection.  Nonetheless, numerous performance\n+  improvements are also included.\n+\n+  New features:\n+  - Implement the experimental {,r,s,d}allocm() API, which provides a superset\n+    of the functionality available via malloc(), calloc(), posix_memalign(),\n+    realloc(), malloc_usable_size(), and free().  These functions can be used to\n+    allocate/reallocate aligned zeroed memory, ask for optional extra memory\n+    during reallocation, prevent object movement during reallocation, etc.\n+  - Replace JEMALLOC_OPTIONS/JEMALLOC_PROF_PREFIX with MALLOC_CONF, which is\n+    more human-readable, and more flexible.  For example:\n+      JEMALLOC_OPTIONS=AJP\n+    is now:\n+      MALLOC_CONF=abort:true,fill:true,stats_print:true\n+  - Port to Apple OS X.  Sponsored by Mozilla.\n+  - Make it possible for the application to control thread-->arena mappings via\n+    the \"thread.arena\" mallctl.\n+  - Add compile-time support for all TLS-related functionality via pthreads TSD.\n+    This is mainly of interest for OS X, which does not support TLS, but has a\n+    TSD implementation with similar performance.\n+  - Override memalign() and valloc() if they are provided by the system.\n+  - Add the \"arenas.purge\" mallctl, which can be used to synchronously purge all\n+    dirty unused pages.\n+  - Make cumulative heap profiling data optional, so that it is possible to\n+    limit the amount of memory consumed by heap profiling data structures.\n+  - Add per thread allocation counters that can be accessed via the\n+    \"thread.allocated\" and \"thread.deallocated\" mallctls.\n+\n+  Incompatible changes:\n+  - Remove JEMALLOC_OPTIONS and malloc_options (see MALLOC_CONF above).\n+  - Increase default backtrace depth from 4 to 128 for heap profiling.\n+  - Disable interval-based profile dumps by default.\n+\n+  Bug fixes:\n+  - Remove bad assertions in fork handler functions.  These assertions could\n+    cause aborts for some combinations of configure settings.\n+  - Fix strerror_r() usage to deal with non-standard semantics in GNU libc.\n+  - Fix leak context reporting.  This bug tended to cause the number of contexts\n+    to be underreported (though the reported number of objects and bytes were\n+    correct).\n+  - Fix a realloc() bug for large in-place growing reallocation.  This bug could\n+    cause memory corruption, but it was hard to trigger.\n+  - Fix an allocation bug for small allocations that could be triggered if\n+    multiple threads raced to create a new run of backing pages.\n+  - Enhance the heap profiler to trigger samples based on usable size, rather\n+    than request size.\n+  - Fix a heap profiling bug due to sometimes losing track of requested object\n+    size for sampled objects.\n+\n+* 1.0.3 (August 12, 2010)\n+\n+  Bug fixes:\n+  - Fix the libunwind-based implementation of stack backtracing (used for heap\n+    profiling).  This bug could cause zero-length backtraces to be reported.\n+  - Add a missing mutex unlock in library initialization code.  If multiple\n+    threads raced to initialize malloc, some of them could end up permanently\n+    blocked.\n+\n+* 1.0.2 (May 11, 2010)\n+\n+  Bug fixes:\n+  - Fix junk filling of large objects, which could cause memory corruption.\n+  - Add MAP_NORESERVE support for chunk mapping, because otherwise virtual\n+    memory limits could cause swap file configuration to fail.  Contributed by\n+    Jordan DeLong.\n+\n+* 1.0.1 (April 14, 2010)\n+\n+  Bug fixes:\n+  - Fix compilation when --enable-fill is specified.\n+  - Fix threads-related profiling bugs that affected accuracy and caused memory\n+    to be leaked during thread exit.\n+  - Fix dirty page purging race conditions that could cause crashes.\n+  - Fix crash in tcache flushing code during thread destruction.\n+\n+* 1.0.0 (April 11, 2010)\n+\n+  This release focuses on speed and run-time introspection.  Numerous\n+  algorithmic improvements make this release substantially faster than its\n+  predecessors.\n+\n+  New features:\n+  - Implement autoconf-based configuration system.\n+  - Add mallctl*(), for the purposes of introspection and run-time\n+    configuration.\n+  - Make it possible for the application to manually flush a thread's cache, via\n+    the \"tcache.flush\" mallctl.\n+  - Base maximum dirty page count on proportion of active memory.\n+  - Compute various addtional run-time statistics, including per size class\n+    statistics for large objects.\n+  - Expose malloc_stats_print(), which can be called repeatedly by the\n+    application.\n+  - Simplify the malloc_message() signature to only take one string argument,\n+    and incorporate an opaque data pointer argument for use by the application\n+    in combination with malloc_stats_print().\n+  - Add support for allocation backed by one or more swap files, and allow the\n+    application to disable over-commit if swap files are in use.\n+  - Implement allocation profiling and leak checking.\n+\n+  Removed features:\n+  - Remove the dynamic arena rebalancing code, since thread-specific caching\n+    reduces its utility.\n+\n+  Bug fixes:\n+  - Modify chunk allocation to work when address space layout randomization\n+    (ASLR) is in use.\n+  - Fix thread cleanup bugs related to TLS destruction.\n+  - Handle 0-size allocation requests in posix_memalign().\n+  - Fix a chunk leak.  The leaked chunks were never touched, so this impacted\n+    virtual memory usage, but not physical memory usage.\n+\n+* linux_2008082[78]a (August 27/28, 2008)\n+\n+  These snapshot releases are the simple result of incorporating Linux-specific\n+  support into the FreeBSD malloc sources.\n+\n+--------------------------------------------------------------------------------\n+vim:filetype=text:textwidth=80"}, {"sha": "6e371ce50956752b7e20546b84db17c89a721788", "filename": "src/rt/jemalloc/INSTALL", "status": "added", "additions": 293, "deletions": 0, "changes": 293, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FINSTALL", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FINSTALL", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2FINSTALL?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,293 @@\n+Building and installing jemalloc can be as simple as typing the following while\n+in the root directory of the source tree:\n+\n+    ./configure\n+    make\n+    make install\n+\n+=== Advanced configuration =====================================================\n+\n+The 'configure' script supports numerous options that allow control of which\n+functionality is enabled, where jemalloc is installed, etc.  Optionally, pass\n+any of the following arguments (not a definitive list) to 'configure':\n+\n+--help\n+    Print a definitive list of options.\n+\n+--prefix=<install-root-dir>\n+    Set the base directory in which to install.  For example:\n+\n+        ./configure --prefix=/usr/local\n+\n+    will cause files to be installed into /usr/local/include, /usr/local/lib,\n+    and /usr/local/man.\n+\n+--with-rpath=<colon-separated-rpath>\n+    Embed one or more library paths, so that libjemalloc can find the libraries\n+    it is linked to.  This works only on ELF-based systems.\n+\n+--with-mangling=<map>\n+    Mangle public symbols specified in <map> which is a comma-separated list of\n+    name:mangled pairs.\n+\n+    For example, to use ld's --wrap option as an alternative method for\n+    overriding libc's malloc implementation, specify something like:\n+\n+      --with-mangling=malloc:__wrap_malloc,free:__wrap_free[...]\n+\n+    Note that mangling happens prior to application of the prefix specified by\n+    --with-jemalloc-prefix, and mangled symbols are then ignored when applying\n+    the prefix.\n+\n+--with-jemalloc-prefix=<prefix>\n+    Prefix all public APIs with <prefix>.  For example, if <prefix> is\n+    \"prefix_\", API changes like the following occur:\n+\n+      malloc()         --> prefix_malloc()\n+      malloc_conf      --> prefix_malloc_conf\n+      /etc/malloc.conf --> /etc/prefix_malloc.conf\n+      MALLOC_CONF      --> PREFIX_MALLOC_CONF\n+\n+    This makes it possible to use jemalloc at the same time as the system\n+    allocator, or even to use multiple copies of jemalloc simultaneously.\n+\n+    By default, the prefix is \"\", except on OS X, where it is \"je_\".  On OS X,\n+    jemalloc overlays the default malloc zone, but makes no attempt to actually\n+    replace the \"malloc\", \"calloc\", etc. symbols.\n+\n+--without-export\n+    Don't export public APIs. This can be useful when building jemalloc as a\n+    static library, or to avoid exporting public APIs when using the zone\n+    allocator on OSX.\n+\n+--with-private-namespace=<prefix>\n+    Prefix all library-private APIs with <prefix>.  For shared libraries,\n+    symbol visibility mechanisms prevent these symbols from being exported, but\n+    for static libraries, naming collisions are a real possibility.  By\n+    default, the prefix is \"\" (empty string).\n+\n+--with-install-suffix=<suffix>\n+    Append <suffix> to the base name of all installed files, such that multiple\n+    versions of jemalloc can coexist in the same installation directory.  For\n+    example, libjemalloc.so.0 becomes libjemalloc<suffix>.so.0.\n+\n+--enable-cc-silence\n+    Enable code that silences non-useful compiler warnings.  This is helpful\n+    when trying to tell serious warnings from those due to compiler\n+    limitations, but it potentially incurs a performance penalty.\n+\n+--enable-debug\n+    Enable assertions and validation code.  This incurs a substantial\n+    performance hit, but is very useful during application development.\n+    Implies --enable-ivsalloc.\n+\n+--enable-ivsalloc\n+    Enable validation code, which verifies that pointers reside within\n+    jemalloc-owned chunks before dereferencing them. This incurs a substantial\n+    performance hit.\n+\n+--disable-stats\n+    Disable statistics gathering functionality.  See the \"opt.stats_print\"\n+    option documentation for usage details.\n+\n+--enable-prof\n+    Enable heap profiling and leak detection functionality.  See the \"opt.prof\"\n+    option documentation for usage details.  When enabled, there are several\n+    approaches to backtracing, and the configure script chooses the first one\n+    in the following list that appears to function correctly:\n+\n+    + libunwind      (requires --enable-prof-libunwind)\n+    + libgcc         (unless --disable-prof-libgcc)\n+    + gcc intrinsics (unless --disable-prof-gcc)\n+\n+--enable-prof-libunwind\n+    Use the libunwind library (http://www.nongnu.org/libunwind/) for stack\n+    backtracing.\n+\n+--disable-prof-libgcc\n+    Disable the use of libgcc's backtracing functionality.\n+\n+--disable-prof-gcc\n+    Disable the use of gcc intrinsics for backtracing.\n+\n+--with-static-libunwind=<libunwind.a>\n+    Statically link against the specified libunwind.a rather than dynamically\n+    linking with -lunwind.\n+\n+--disable-tcache\n+    Disable thread-specific caches for small objects.  Objects are cached and\n+    released in bulk, thus reducing the total number of mutex operations.  See\n+    the \"opt.tcache\" option for usage details.\n+\n+--enable-mremap\n+    Enable huge realloc() via mremap(2).  mremap() is disabled by default\n+    because the flavor used is specific to Linux, which has a quirk in its\n+    virtual memory allocation algorithm that causes semi-permanent VM map holes\n+    under normal jemalloc operation.\n+\n+--disable-munmap\n+    Disable virtual memory deallocation via munmap(2); instead keep track of\n+    the virtual memory for later use.  munmap() is disabled by default (i.e.\n+    --disable-munmap is implied) on Linux, which has a quirk in its virtual\n+    memory allocation algorithm that causes semi-permanent VM map holes under\n+    normal jemalloc operation.\n+\n+--enable-dss\n+    Enable support for page allocation/deallocation via sbrk(2), in addition to\n+    mmap(2).\n+\n+--disable-fill\n+    Disable support for junk/zero filling of memory, quarantine, and redzones.\n+    See the \"opt.junk\", \"opt.zero\", \"opt.quarantine\", and \"opt.redzone\" option\n+    documentation for usage details.\n+\n+--disable-valgrind\n+    Disable support for Valgrind.\n+\n+--disable-experimental\n+    Disable support for the experimental API (*allocm()).\n+\n+--disable-zone-allocator\n+    Disable zone allocator for Darwin. This means jemalloc won't be hooked as\n+    the default allocator on OSX/iOS.\n+\n+--enable-utrace\n+    Enable utrace(2)-based allocation tracing.  This feature is not broadly\n+    portable (FreeBSD has it, but Linux and OS X do not).\n+\n+--enable-xmalloc\n+    Enable support for optional immediate termination due to out-of-memory\n+    errors, as is commonly implemented by \"xmalloc\" wrapper function for malloc.\n+    See the \"opt.xmalloc\" option documentation for usage details.\n+\n+--enable-lazy-lock\n+    Enable code that wraps pthread_create() to detect when an application\n+    switches from single-threaded to multi-threaded mode, so that it can avoid\n+    mutex locking/unlocking operations while in single-threaded mode.  In\n+    practice, this feature usually has little impact on performance unless\n+    thread-specific caching is disabled.\n+\n+--disable-tls\n+    Disable thread-local storage (TLS), which allows for fast access to\n+    thread-local variables via the __thread keyword.  If TLS is available,\n+    jemalloc uses it for several purposes.\n+\n+--with-xslroot=<path>\n+    Specify where to find DocBook XSL stylesheets when building the\n+    documentation.\n+\n+The following environment variables (not a definitive list) impact configure's\n+behavior:\n+\n+CFLAGS=\"?\"\n+    Pass these flags to the compiler.  You probably shouldn't define this unless\n+    you know what you are doing.  (Use EXTRA_CFLAGS instead.)\n+\n+EXTRA_CFLAGS=\"?\"\n+    Append these flags to CFLAGS.  This makes it possible to add flags such as\n+    -Werror, while allowing the configure script to determine what other flags\n+    are appropriate for the specified configuration.\n+\n+    The configure script specifically checks whether an optimization flag (-O*)\n+    is specified in EXTRA_CFLAGS, and refrains from specifying an optimization\n+    level if it finds that one has already been specified.\n+\n+CPPFLAGS=\"?\"\n+    Pass these flags to the C preprocessor.  Note that CFLAGS is not passed to\n+    'cpp' when 'configure' is looking for include files, so you must use\n+    CPPFLAGS instead if you need to help 'configure' find header files.\n+\n+LD_LIBRARY_PATH=\"?\"\n+    'ld' uses this colon-separated list to find libraries.\n+\n+LDFLAGS=\"?\"\n+    Pass these flags when linking.\n+\n+PATH=\"?\"\n+    'configure' uses this to find programs.\n+\n+=== Advanced compilation =======================================================\n+\n+To build only parts of jemalloc, use the following targets:\n+\n+    build_lib_shared\n+    build_lib_static\n+    build_lib\n+    build_doc_html\n+    build_doc_man\n+    build_doc\n+\n+To install only parts of jemalloc, use the following targets:\n+\n+    install_bin\n+    install_include\n+    install_lib_shared\n+    install_lib_static\n+    install_lib\n+    install_doc_html\n+    install_doc_man\n+    install_doc\n+\n+To clean up build results to varying degrees, use the following make targets:\n+\n+    clean\n+    distclean\n+    relclean\n+\n+=== Advanced installation ======================================================\n+\n+Optionally, define make variables when invoking make, including (not\n+exclusively):\n+\n+INCLUDEDIR=\"?\"\n+    Use this as the installation prefix for header files.\n+\n+LIBDIR=\"?\"\n+    Use this as the installation prefix for libraries.\n+\n+MANDIR=\"?\"\n+    Use this as the installation prefix for man pages.\n+\n+DESTDIR=\"?\"\n+    Prepend DESTDIR to INCLUDEDIR, LIBDIR, DATADIR, and MANDIR.  This is useful\n+    when installing to a different path than was specified via --prefix.\n+\n+CC=\"?\"\n+    Use this to invoke the C compiler.\n+\n+CFLAGS=\"?\"\n+    Pass these flags to the compiler.\n+\n+CPPFLAGS=\"?\"\n+    Pass these flags to the C preprocessor.\n+\n+LDFLAGS=\"?\"\n+    Pass these flags when linking.\n+\n+PATH=\"?\"\n+    Use this to search for programs used during configuration and building.\n+\n+=== Development ================================================================\n+\n+If you intend to make non-trivial changes to jemalloc, use the 'autogen.sh'\n+script rather than 'configure'.  This re-generates 'configure', enables\n+configuration dependency rules, and enables re-generation of automatically\n+generated source files.\n+\n+The build system supports using an object directory separate from the source\n+tree.  For example, you can create an 'obj' directory, and from within that\n+directory, issue configuration and build commands:\n+\n+    autoconf\n+    mkdir obj\n+    cd obj\n+    ../configure --enable-autogen\n+    make\n+\n+=== Documentation ==============================================================\n+\n+The manual page is generated in both html and roff formats.  Any web browser\n+can be used to view the html manual.  The roff manual page can be formatted\n+prior to installation via the following command:\n+\n+    nroff -man -t doc/jemalloc.3"}, {"sha": "74810472d1170de651afd89b6c65780562cbc125", "filename": "src/rt/jemalloc/Makefile.in", "status": "added", "additions": 324, "deletions": 0, "changes": 324, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FMakefile.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FMakefile.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2FMakefile.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,324 @@\n+# Clear out all vpaths, then set just one (default vpath) for the main build\n+# directory.\n+vpath\n+vpath % .\n+\n+# Clear the default suffixes, so that built-in rules are not used.\n+.SUFFIXES :\n+\n+SHELL := /bin/sh\n+\n+CC := @CC@\n+\n+# Configuration parameters.\n+DESTDIR =\n+BINDIR := $(DESTDIR)@BINDIR@\n+INCLUDEDIR := $(DESTDIR)@INCLUDEDIR@\n+LIBDIR := $(DESTDIR)@LIBDIR@\n+DATADIR := $(DESTDIR)@DATADIR@\n+MANDIR := $(DESTDIR)@MANDIR@\n+srcroot := @srcroot@\n+objroot := @objroot@\n+abs_srcroot := @abs_srcroot@\n+abs_objroot := @abs_objroot@\n+\n+# Build parameters.\n+CPPFLAGS := @CPPFLAGS@ -I$(srcroot)include -I$(objroot)include\n+CFLAGS := @CFLAGS@\n+LDFLAGS := @LDFLAGS@\n+EXTRA_LDFLAGS := @EXTRA_LDFLAGS@\n+LIBS := @LIBS@\n+RPATH_EXTRA := @RPATH_EXTRA@\n+SO := @so@\n+IMPORTLIB := @importlib@\n+O := @o@\n+A := @a@\n+EXE := @exe@\n+LIBPREFIX := @libprefix@\n+REV := @rev@\n+install_suffix := @install_suffix@\n+ABI := @abi@\n+XSLTPROC := @XSLTPROC@\n+AUTOCONF := @AUTOCONF@\n+_RPATH = @RPATH@\n+RPATH = $(if $(1),$(call _RPATH,$(1)))\n+cfghdrs_in := @cfghdrs_in@\n+cfghdrs_out := @cfghdrs_out@\n+cfgoutputs_in := @cfgoutputs_in@\n+cfgoutputs_out := @cfgoutputs_out@\n+enable_autogen := @enable_autogen@\n+enable_experimental := @enable_experimental@\n+enable_zone_allocator := @enable_zone_allocator@\n+DSO_LDFLAGS = @DSO_LDFLAGS@\n+SOREV = @SOREV@\n+PIC_CFLAGS = @PIC_CFLAGS@\n+CTARGET = @CTARGET@\n+LDTARGET = @LDTARGET@\n+MKLIB = @MKLIB@\n+CC_MM = @CC_MM@\n+\n+ifeq (macho, $(ABI))\n+TEST_LIBRARY_PATH := DYLD_FALLBACK_LIBRARY_PATH=\"$(objroot)lib\"\n+else\n+ifeq (pecoff, $(ABI))\n+TEST_LIBRARY_PATH := PATH=\"$(PATH):$(objroot)lib\"\n+else\n+TEST_LIBRARY_PATH :=\n+endif\n+endif\n+\n+LIBJEMALLOC := $(LIBPREFIX)jemalloc$(install_suffix)\n+\n+# Lists of files.\n+BINS := $(srcroot)bin/pprof $(objroot)bin/jemalloc.sh\n+CHDRS := $(objroot)include/jemalloc/jemalloc$(install_suffix).h \\\n+\t$(objroot)include/jemalloc/jemalloc_defs$(install_suffix).h\n+CSRCS := $(srcroot)src/jemalloc.c $(srcroot)src/arena.c $(srcroot)src/atomic.c \\\n+\t$(srcroot)src/base.c $(srcroot)src/bitmap.c $(srcroot)src/chunk.c \\\n+\t$(srcroot)src/chunk_dss.c $(srcroot)src/chunk_mmap.c \\\n+\t$(srcroot)src/ckh.c $(srcroot)src/ctl.c $(srcroot)src/extent.c \\\n+\t$(srcroot)src/hash.c $(srcroot)src/huge.c $(srcroot)src/mb.c \\\n+\t$(srcroot)src/mutex.c $(srcroot)src/prof.c $(srcroot)src/quarantine.c \\\n+\t$(srcroot)src/rtree.c $(srcroot)src/stats.c $(srcroot)src/tcache.c \\\n+\t$(srcroot)src/util.c $(srcroot)src/tsd.c\n+ifeq ($(enable_zone_allocator), 1)\n+CSRCS += $(srcroot)src/zone.c\n+endif\n+ifeq ($(IMPORTLIB),$(SO))\n+STATIC_LIBS := $(objroot)lib/$(LIBJEMALLOC).$(A)\n+endif\n+ifdef PIC_CFLAGS\n+STATIC_LIBS += $(objroot)lib/$(LIBJEMALLOC)_pic.$(A)\n+else\n+STATIC_LIBS += $(objroot)lib/$(LIBJEMALLOC)_s.$(A)\n+endif\n+DSOS := $(objroot)lib/$(LIBJEMALLOC).$(SOREV)\n+ifneq ($(SOREV),$(SO))\n+DSOS += $(objroot)lib/$(LIBJEMALLOC).$(SO)\n+endif\n+MAN3 := $(objroot)doc/jemalloc$(install_suffix).3\n+DOCS_XML := $(objroot)doc/jemalloc$(install_suffix).xml\n+DOCS_HTML := $(DOCS_XML:$(objroot)%.xml=$(srcroot)%.html)\n+DOCS_MAN3 := $(DOCS_XML:$(objroot)%.xml=$(srcroot)%.3)\n+DOCS := $(DOCS_HTML) $(DOCS_MAN3)\n+CTESTS := $(srcroot)test/aligned_alloc.c $(srcroot)test/allocated.c \\\n+\t$(srcroot)test/ALLOCM_ARENA.c $(srcroot)test/bitmap.c \\\n+\t$(srcroot)test/mremap.c $(srcroot)test/posix_memalign.c \\\n+\t$(srcroot)test/thread_arena.c $(srcroot)test/thread_tcache_enabled.c\n+ifeq ($(enable_experimental), 1)\n+CTESTS += $(srcroot)test/allocm.c $(srcroot)test/rallocm.c\n+endif\n+\n+COBJS := $(CSRCS:$(srcroot)%.c=$(objroot)%.$(O))\n+CPICOBJS := $(CSRCS:$(srcroot)%.c=$(objroot)%.pic.$(O))\n+CTESTOBJS := $(CTESTS:$(srcroot)%.c=$(objroot)%.$(O))\n+\n+.PHONY: all dist build_doc_html build_doc_man build_doc\n+.PHONY: install_bin install_include install_lib\n+.PHONY: install_doc_html install_doc_man install_doc install\n+.PHONY: tests check clean distclean relclean\n+\n+.SECONDARY : $(CTESTOBJS)\n+\n+# Default target.\n+all: build\n+\n+dist: build_doc\n+\n+$(srcroot)doc/%.html : $(objroot)doc/%.xml $(srcroot)doc/stylesheet.xsl $(objroot)doc/html.xsl\n+\t$(XSLTPROC) -o $@ $(objroot)doc/html.xsl $<\n+\n+$(srcroot)doc/%.3 : $(objroot)doc/%.xml $(srcroot)doc/stylesheet.xsl $(objroot)doc/manpages.xsl\n+\t$(XSLTPROC) -o $@ $(objroot)doc/manpages.xsl $<\n+\n+build_doc_html: $(DOCS_HTML)\n+build_doc_man: $(DOCS_MAN3)\n+build_doc: $(DOCS)\n+\n+#\n+# Include generated dependency files.\n+#\n+ifdef CC_MM\n+-include $(COBJS:%.$(O)=%.d)\n+-include $(CPICOBJS:%.$(O)=%.d)\n+-include $(CTESTOBJS:%.$(O)=%.d)\n+endif\n+\n+$(COBJS): $(objroot)src/%.$(O): $(srcroot)src/%.c\n+$(CPICOBJS): $(objroot)src/%.pic.$(O): $(srcroot)src/%.c\n+$(CPICOBJS): CFLAGS += $(PIC_CFLAGS)\n+$(CTESTOBJS): $(objroot)test/%.$(O): $(srcroot)test/%.c\n+$(CTESTOBJS): CPPFLAGS += -I$(objroot)test\n+ifneq ($(IMPORTLIB),$(SO))\n+$(COBJS): CPPFLAGS += -DDLLEXPORT\n+endif\n+\n+ifndef CC_MM\n+# Dependencies\n+HEADER_DIRS = $(srcroot)include/jemalloc/internal \\\n+\t$(objroot)include/jemalloc $(objroot)include/jemalloc/internal\n+HEADERS = $(wildcard $(foreach dir,$(HEADER_DIRS),$(dir)/*.h))\n+$(COBJS) $(CPICOBJS) $(CTESTOBJS): $(HEADERS)\n+$(CTESTOBJS): $(objroot)test/jemalloc_test.h\n+endif\n+\n+$(COBJS) $(CPICOBJS) $(CTESTOBJS): %.$(O):\n+\t@mkdir -p $(@D)\n+\t$(CC) $(CFLAGS) -c $(CPPFLAGS) $(CTARGET) $<\n+ifdef CC_MM\n+\t@$(CC) -MM $(CPPFLAGS) -MT $@ -o $(@:%.$(O)=%.d) $<\n+endif\n+\n+ifneq ($(SOREV),$(SO))\n+%.$(SO) : %.$(SOREV)\n+\t@mkdir -p $(@D)\n+\tln -sf $(<F) $@\n+endif\n+\n+$(objroot)lib/$(LIBJEMALLOC).$(SOREV) : $(if $(PIC_CFLAGS),$(CPICOBJS),$(COBJS))\n+\t@mkdir -p $(@D)\n+\t$(CC) $(DSO_LDFLAGS) $(call RPATH,$(RPATH_EXTRA)) $(LDTARGET) $+ $(LDFLAGS) $(LIBS) $(EXTRA_LDFLAGS)\n+\n+$(objroot)lib/$(LIBJEMALLOC)_pic.$(A) : $(CPICOBJS)\n+$(objroot)lib/$(LIBJEMALLOC).$(A) : $(COBJS)\n+$(objroot)lib/$(LIBJEMALLOC)_s.$(A) : $(COBJS)\n+\n+$(STATIC_LIBS):\n+\t@mkdir -p $(@D)\n+\t$(MKLIB) $+\n+\n+$(objroot)test/bitmap$(EXE): $(objroot)src/bitmap.$(O)\n+\n+$(objroot)test/%$(EXE): $(objroot)test/%.$(O) $(objroot)src/util.$(O) $(DSOS)\n+\t@mkdir -p $(@D)\n+\t$(CC) $(LDTARGET) $(filter %.$(O),$^) $(call RPATH,$(objroot)lib) $(objroot)lib/$(LIBJEMALLOC).$(IMPORTLIB) $(filter -lpthread,$(LIBS)) $(EXTRA_LDFLAGS)\n+\n+build_lib_shared: $(DSOS)\n+build_lib_static: $(STATIC_LIBS)\n+build: build_lib_shared build_lib_static\n+\n+install_bin:\n+\tinstall -d $(BINDIR)\n+\t@for b in $(BINS); do \\\n+\techo \"install -m 755 $$b $(BINDIR)\"; \\\n+\tinstall -m 755 $$b $(BINDIR); \\\n+done\n+\n+install_include:\n+\tinstall -d $(INCLUDEDIR)/jemalloc\n+\t@for h in $(CHDRS); do \\\n+\techo \"install -m 644 $$h $(INCLUDEDIR)/jemalloc\"; \\\n+\tinstall -m 644 $$h $(INCLUDEDIR)/jemalloc; \\\n+done\n+\n+install_lib_shared: $(DSOS)\n+\tinstall -d $(LIBDIR)\n+\tinstall -m 755 $(objroot)lib/$(LIBJEMALLOC).$(SOREV) $(LIBDIR)\n+ifneq ($(SOREV),$(SO))\n+\tln -sf $(LIBJEMALLOC).$(SOREV) $(LIBDIR)/$(LIBJEMALLOC).$(SO)\n+endif\n+\n+install_lib_static: $(STATIC_LIBS)\n+\tinstall -d $(LIBDIR)\n+\t@for l in $(STATIC_LIBS); do \\\n+\techo \"install -m 755 $$l $(LIBDIR)\"; \\\n+\tinstall -m 755 $$l $(LIBDIR); \\\n+done\n+\n+install_lib: install_lib_shared install_lib_static\n+\n+install_doc_html:\n+\tinstall -d $(DATADIR)/doc/jemalloc$(install_suffix)\n+\t@for d in $(DOCS_HTML); do \\\n+\techo \"install -m 644 $$d $(DATADIR)/doc/jemalloc$(install_suffix)\"; \\\n+\tinstall -m 644 $$d $(DATADIR)/doc/jemalloc$(install_suffix); \\\n+done\n+\n+install_doc_man:\n+\tinstall -d $(MANDIR)/man3\n+\t@for d in $(DOCS_MAN3); do \\\n+\techo \"install -m 644 $$d $(MANDIR)/man3\"; \\\n+\tinstall -m 644 $$d $(MANDIR)/man3; \\\n+done\n+\n+install_doc: install_doc_html install_doc_man\n+\n+install: install_bin install_include install_lib install_doc\n+\n+tests: $(CTESTS:$(srcroot)%.c=$(objroot)%$(EXE))\n+\n+check: tests\n+\t@mkdir -p $(objroot)test\n+\t@$(SHELL) -c 'total=0; \\\n+\t\tfailures=0; \\\n+\t\techo \"=========================================\"; \\\n+\t\tfor t in $(CTESTS:$(srcroot)%.c=$(objroot)%); do \\\n+\t\t\ttotal=`expr $$total + 1`; \\\n+\t\t\t/bin/echo -n \"$${t} ... \"; \\\n+\t\t\t$(TEST_LIBRARY_PATH) $${t}$(EXE) $(abs_srcroot) \\\n+\t\t\t  $(abs_objroot) > $(objroot)$${t}.out 2>&1; \\\n+\t\t\tif test -e \"$(srcroot)$${t}.exp\"; then \\\n+\t\t\t\tdiff -w -u $(srcroot)$${t}.exp \\\n+\t\t\t\t  $(objroot)$${t}.out >/dev/null 2>&1; \\\n+\t\t\t\tfail=$$?; \\\n+\t\t\t\tif test \"$${fail}\" -eq \"1\" ; then \\\n+\t\t\t\t\tfailures=`expr $${failures} + 1`; \\\n+\t\t\t\t\techo \"*** FAIL ***\"; \\\n+\t\t\t\telse \\\n+\t\t\t\t\techo \"pass\"; \\\n+\t\t\t\tfi; \\\n+\t\t\telse \\\n+\t\t\t\techo \"*** FAIL *** (.exp file is missing)\"; \\\n+\t\t\t\tfailures=`expr $${failures} + 1`; \\\n+\t\t\tfi; \\\n+\t\tdone; \\\n+\t\techo \"=========================================\"; \\\n+\t\techo \"Failures: $${failures}/$${total}\"'\n+\n+clean:\n+\trm -f $(COBJS)\n+\trm -f $(CPICOBJS)\n+\trm -f $(COBJS:%.$(O)=%.d)\n+\trm -f $(CPICOBJS:%.$(O)=%.d)\n+\trm -f $(CTESTOBJS:%.$(O)=%$(EXE))\n+\trm -f $(CTESTOBJS)\n+\trm -f $(CTESTOBJS:%.$(O)=%.d)\n+\trm -f $(CTESTOBJS:%.$(O)=%.out)\n+\trm -f $(DSOS) $(STATIC_LIBS)\n+\n+distclean: clean\n+\trm -rf $(objroot)autom4te.cache\n+\trm -f $(objroot)config.log\n+\trm -f $(objroot)config.status\n+\trm -f $(objroot)config.stamp\n+\trm -f $(cfghdrs_out)\n+\trm -f $(cfgoutputs_out)\n+\n+relclean: distclean\n+\trm -f $(objroot)configure\n+\trm -f $(srcroot)VERSION\n+\trm -f $(DOCS_HTML)\n+\trm -f $(DOCS_MAN3)\n+\n+#===============================================================================\n+# Re-configuration rules.\n+\n+ifeq ($(enable_autogen), 1)\n+$(srcroot)configure : $(srcroot)configure.ac\n+\tcd ./$(srcroot) && $(AUTOCONF)\n+\n+$(objroot)config.status : $(srcroot)configure\n+\t./$(objroot)config.status --recheck\n+\n+$(srcroot)config.stamp.in : $(srcroot)configure.ac\n+\techo stamp > $(srcroot)config.stamp.in\n+\n+$(objroot)config.stamp : $(cfgoutputs_in) $(cfghdrs_in) $(srcroot)configure\n+\t./$(objroot)config.status\n+\t@touch $@\n+\n+# There must be some action in order for make to re-read Makefile when it is\n+# out of date.\n+$(cfgoutputs_out) $(cfghdrs_out) : $(objroot)config.stamp\n+\t@true\n+endif"}, {"sha": "7661683bae7afd29d49b106e2ddc333054bea05e", "filename": "src/rt/jemalloc/README", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FREADME", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FREADME", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2FREADME?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,16 @@\n+jemalloc is a general-purpose scalable concurrent malloc(3) implementation.\n+This distribution is a \"portable\" implementation that currently targets\n+FreeBSD, Linux, Apple OS X, and MinGW.  jemalloc is included as the default\n+allocator in the FreeBSD and NetBSD operating systems, and it is used by the\n+Mozilla Firefox web browser on Microsoft Windows-related platforms.  Depending\n+on your needs, one of the other divergent versions may suit your needs better\n+than this distribution.\n+\n+The COPYING file contains copyright and licensing information.\n+\n+The INSTALL file contains information on how to configure, build, and install\n+jemalloc.\n+\n+The ChangeLog file contains a brief summary of changes for each release.\n+\n+URL: http://www.canonware.com/jemalloc/"}, {"sha": "900c82d1043de796d6f5a9dfb8972115be32839e", "filename": "src/rt/jemalloc/VERSION", "status": "added", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FVERSION", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2FVERSION", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2FVERSION?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1 @@\n+3.3.1-0-g9ef9d9e8c271cdf14f664b871a8f98c827714784"}, {"sha": "75f32da6873cdcbe202fd5b8d8e601191b7c9a29", "filename": "src/rt/jemalloc/autogen.sh", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fautogen.sh", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fautogen.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fautogen.sh?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,17 @@\n+#!/bin/sh\n+\n+for i in autoconf; do\n+    echo \"$i\"\n+    $i\n+    if [ $? -ne 0 ]; then\n+\techo \"Error $? in $i\"\n+\texit 1\n+    fi\n+done\n+\n+echo \"./configure --enable-autogen $@\"\n+./configure --enable-autogen $@\n+if [ $? -ne 0 ]; then\n+    echo \"Error $? in ./configure\"\n+    exit 1\n+fi"}, {"sha": "7c9f1b530dabfd4394500fcea0fb38b7148eca01", "filename": "src/rt/jemalloc/bin/jemalloc.sh", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fbin%2Fjemalloc.sh", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fbin%2Fjemalloc.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fbin%2Fjemalloc.sh?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,9 @@\n+#!/bin/sh\n+\n+prefix=/usr/local\n+exec_prefix=/usr/local\n+libdir=${exec_prefix}/lib\n+\n+LD_PRELOAD=${libdir}/libjemalloc.so.1\n+export LD_PRELOAD\n+exec \"$@\""}, {"sha": "cdf36737591aa1916616207272f99f7c8e8c01eb", "filename": "src/rt/jemalloc/bin/jemalloc.sh.in", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fbin%2Fjemalloc.sh.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fbin%2Fjemalloc.sh.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fbin%2Fjemalloc.sh.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,9 @@\n+#!/bin/sh\n+\n+prefix=@prefix@\n+exec_prefix=@exec_prefix@\n+libdir=@libdir@\n+\n+@LD_PRELOAD_VAR@=${libdir}/libjemalloc.@SOREV@\n+export @LD_PRELOAD_VAR@\n+exec \"$@\""}, {"sha": "46f4f3f70a0052cd528e843e222eeead57ff2ba1", "filename": "src/rt/jemalloc/bin/pprof", "status": "added", "additions": 5348, "deletions": 0, "changes": 5348, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fbin%2Fpprof", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fbin%2Fpprof", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fbin%2Fpprof?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "d622a44e551f209d5e8c5462b3fe53a162f7b330", "filename": "src/rt/jemalloc/config.guess", "status": "added", "additions": 1530, "deletions": 0, "changes": 1530, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfig.guess", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfig.guess", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fconfig.guess?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,1530 @@\n+#! /bin/sh\n+# Attempt to guess a canonical system name.\n+#   Copyright (C) 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n+#   2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n+#   2011, 2012 Free Software Foundation, Inc.\n+\n+timestamp='2012-02-10'\n+\n+# This file is free software; you can redistribute it and/or modify it\n+# under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 2 of the License, or\n+# (at your option) any later version.\n+#\n+# This program is distributed in the hope that it will be useful, but\n+# WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+# General Public License for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with this program; if not, see <http://www.gnu.org/licenses/>.\n+#\n+# As a special exception to the GNU General Public License, if you\n+# distribute this file as part of a program that contains a\n+# configuration script generated by Autoconf, you may include it under\n+# the same distribution terms that you use for the rest of that program.\n+\n+\n+# Originally written by Per Bothner.  Please send patches (context\n+# diff format) to <config-patches@gnu.org> and include a ChangeLog\n+# entry.\n+#\n+# This script attempts to guess a canonical system name similar to\n+# config.sub.  If it succeeds, it prints the system name on stdout, and\n+# exits with 0.  Otherwise, it exits with 1.\n+#\n+# You can get the latest version of this script from:\n+# http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD\n+\n+me=`echo \"$0\" | sed -e 's,.*/,,'`\n+\n+usage=\"\\\n+Usage: $0 [OPTION]\n+\n+Output the configuration name of the system \\`$me' is run on.\n+\n+Operation modes:\n+  -h, --help         print this help, then exit\n+  -t, --time-stamp   print date of last modification, then exit\n+  -v, --version      print version number, then exit\n+\n+Report bugs and patches to <config-patches@gnu.org>.\"\n+\n+version=\"\\\n+GNU config.guess ($timestamp)\n+\n+Originally written by Per Bothner.\n+Copyright (C) 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n+2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012\n+Free Software Foundation, Inc.\n+\n+This is free software; see the source for copying conditions.  There is NO\n+warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\"\n+\n+help=\"\n+Try \\`$me --help' for more information.\"\n+\n+# Parse command line\n+while test $# -gt 0 ; do\n+  case $1 in\n+    --time-stamp | --time* | -t )\n+       echo \"$timestamp\" ; exit ;;\n+    --version | -v )\n+       echo \"$version\" ; exit ;;\n+    --help | --h* | -h )\n+       echo \"$usage\"; exit ;;\n+    -- )     # Stop option processing\n+       shift; break ;;\n+    - )\t# Use stdin as input.\n+       break ;;\n+    -* )\n+       echo \"$me: invalid option $1$help\" >&2\n+       exit 1 ;;\n+    * )\n+       break ;;\n+  esac\n+done\n+\n+if test $# != 0; then\n+  echo \"$me: too many arguments$help\" >&2\n+  exit 1\n+fi\n+\n+trap 'exit 1' 1 2 15\n+\n+# CC_FOR_BUILD -- compiler used by this script. Note that the use of a\n+# compiler to aid in system detection is discouraged as it requires\n+# temporary files to be created and, as you can see below, it is a\n+# headache to deal with in a portable fashion.\n+\n+# Historically, `CC_FOR_BUILD' used to be named `HOST_CC'. We still\n+# use `HOST_CC' if defined, but it is deprecated.\n+\n+# Portable tmp directory creation inspired by the Autoconf team.\n+\n+set_cc_for_build='\n+trap \"exitcode=\\$?; (rm -f \\$tmpfiles 2>/dev/null; rmdir \\$tmp 2>/dev/null) && exit \\$exitcode\" 0 ;\n+trap \"rm -f \\$tmpfiles 2>/dev/null; rmdir \\$tmp 2>/dev/null; exit 1\" 1 2 13 15 ;\n+: ${TMPDIR=/tmp} ;\n+ { tmp=`(umask 077 && mktemp -d \"$TMPDIR/cgXXXXXX\") 2>/dev/null` && test -n \"$tmp\" && test -d \"$tmp\" ; } ||\n+ { test -n \"$RANDOM\" && tmp=$TMPDIR/cg$$-$RANDOM && (umask 077 && mkdir $tmp) ; } ||\n+ { tmp=$TMPDIR/cg-$$ && (umask 077 && mkdir $tmp) && echo \"Warning: creating insecure temp directory\" >&2 ; } ||\n+ { echo \"$me: cannot create a temporary directory in $TMPDIR\" >&2 ; exit 1 ; } ;\n+dummy=$tmp/dummy ;\n+tmpfiles=\"$dummy.c $dummy.o $dummy.rel $dummy\" ;\n+case $CC_FOR_BUILD,$HOST_CC,$CC in\n+ ,,)    echo \"int x;\" > $dummy.c ;\n+\tfor c in cc gcc c89 c99 ; do\n+\t  if ($c -c -o $dummy.o $dummy.c) >/dev/null 2>&1 ; then\n+\t     CC_FOR_BUILD=\"$c\"; break ;\n+\t  fi ;\n+\tdone ;\n+\tif test x\"$CC_FOR_BUILD\" = x ; then\n+\t  CC_FOR_BUILD=no_compiler_found ;\n+\tfi\n+\t;;\n+ ,,*)   CC_FOR_BUILD=$CC ;;\n+ ,*,*)  CC_FOR_BUILD=$HOST_CC ;;\n+esac ; set_cc_for_build= ;'\n+\n+# This is needed to find uname on a Pyramid OSx when run in the BSD universe.\n+# (ghazi@noc.rutgers.edu 1994-08-24)\n+if (test -f /.attbin/uname) >/dev/null 2>&1 ; then\n+\tPATH=$PATH:/.attbin ; export PATH\n+fi\n+\n+UNAME_MACHINE=`(uname -m) 2>/dev/null` || UNAME_MACHINE=unknown\n+UNAME_RELEASE=`(uname -r) 2>/dev/null` || UNAME_RELEASE=unknown\n+UNAME_SYSTEM=`(uname -s) 2>/dev/null`  || UNAME_SYSTEM=unknown\n+UNAME_VERSION=`(uname -v) 2>/dev/null` || UNAME_VERSION=unknown\n+\n+# Note: order is significant - the case branches are not exclusive.\n+\n+case \"${UNAME_MACHINE}:${UNAME_SYSTEM}:${UNAME_RELEASE}:${UNAME_VERSION}\" in\n+    *:NetBSD:*:*)\n+\t# NetBSD (nbsd) targets should (where applicable) match one or\n+\t# more of the tuples: *-*-netbsdelf*, *-*-netbsdaout*,\n+\t# *-*-netbsdecoff* and *-*-netbsd*.  For targets that recently\n+\t# switched to ELF, *-*-netbsd* would select the old\n+\t# object file format.  This provides both forward\n+\t# compatibility and a consistent mechanism for selecting the\n+\t# object file format.\n+\t#\n+\t# Note: NetBSD doesn't particularly care about the vendor\n+\t# portion of the name.  We always set it to \"unknown\".\n+\tsysctl=\"sysctl -n hw.machine_arch\"\n+\tUNAME_MACHINE_ARCH=`(/sbin/$sysctl 2>/dev/null || \\\n+\t    /usr/sbin/$sysctl 2>/dev/null || echo unknown)`\n+\tcase \"${UNAME_MACHINE_ARCH}\" in\n+\t    armeb) machine=armeb-unknown ;;\n+\t    arm*) machine=arm-unknown ;;\n+\t    sh3el) machine=shl-unknown ;;\n+\t    sh3eb) machine=sh-unknown ;;\n+\t    sh5el) machine=sh5le-unknown ;;\n+\t    *) machine=${UNAME_MACHINE_ARCH}-unknown ;;\n+\tesac\n+\t# The Operating System including object format, if it has switched\n+\t# to ELF recently, or will in the future.\n+\tcase \"${UNAME_MACHINE_ARCH}\" in\n+\t    arm*|i386|m68k|ns32k|sh3*|sparc|vax)\n+\t\teval $set_cc_for_build\n+\t\tif echo __ELF__ | $CC_FOR_BUILD -E - 2>/dev/null \\\n+\t\t\t| grep -q __ELF__\n+\t\tthen\n+\t\t    # Once all utilities can be ECOFF (netbsdecoff) or a.out (netbsdaout).\n+\t\t    # Return netbsd for either.  FIX?\n+\t\t    os=netbsd\n+\t\telse\n+\t\t    os=netbsdelf\n+\t\tfi\n+\t\t;;\n+\t    *)\n+\t\tos=netbsd\n+\t\t;;\n+\tesac\n+\t# The OS release\n+\t# Debian GNU/NetBSD machines have a different userland, and\n+\t# thus, need a distinct triplet. However, they do not need\n+\t# kernel version information, so it can be replaced with a\n+\t# suitable tag, in the style of linux-gnu.\n+\tcase \"${UNAME_VERSION}\" in\n+\t    Debian*)\n+\t\trelease='-gnu'\n+\t\t;;\n+\t    *)\n+\t\trelease=`echo ${UNAME_RELEASE}|sed -e 's/[-_].*/\\./'`\n+\t\t;;\n+\tesac\n+\t# Since CPU_TYPE-MANUFACTURER-KERNEL-OPERATING_SYSTEM:\n+\t# contains redundant information, the shorter form:\n+\t# CPU_TYPE-MANUFACTURER-OPERATING_SYSTEM is used.\n+\techo \"${machine}-${os}${release}\"\n+\texit ;;\n+    *:OpenBSD:*:*)\n+\tUNAME_MACHINE_ARCH=`arch | sed 's/OpenBSD.//'`\n+\techo ${UNAME_MACHINE_ARCH}-unknown-openbsd${UNAME_RELEASE}\n+\texit ;;\n+    *:ekkoBSD:*:*)\n+\techo ${UNAME_MACHINE}-unknown-ekkobsd${UNAME_RELEASE}\n+\texit ;;\n+    *:SolidBSD:*:*)\n+\techo ${UNAME_MACHINE}-unknown-solidbsd${UNAME_RELEASE}\n+\texit ;;\n+    macppc:MirBSD:*:*)\n+\techo powerpc-unknown-mirbsd${UNAME_RELEASE}\n+\texit ;;\n+    *:MirBSD:*:*)\n+\techo ${UNAME_MACHINE}-unknown-mirbsd${UNAME_RELEASE}\n+\texit ;;\n+    alpha:OSF1:*:*)\n+\tcase $UNAME_RELEASE in\n+\t*4.0)\n+\t\tUNAME_RELEASE=`/usr/sbin/sizer -v | awk '{print $3}'`\n+\t\t;;\n+\t*5.*)\n+\t\tUNAME_RELEASE=`/usr/sbin/sizer -v | awk '{print $4}'`\n+\t\t;;\n+\tesac\n+\t# According to Compaq, /usr/sbin/psrinfo has been available on\n+\t# OSF/1 and Tru64 systems produced since 1995.  I hope that\n+\t# covers most systems running today.  This code pipes the CPU\n+\t# types through head -n 1, so we only detect the type of CPU 0.\n+\tALPHA_CPU_TYPE=`/usr/sbin/psrinfo -v | sed -n -e 's/^  The alpha \\(.*\\) processor.*$/\\1/p' | head -n 1`\n+\tcase \"$ALPHA_CPU_TYPE\" in\n+\t    \"EV4 (21064)\")\n+\t\tUNAME_MACHINE=\"alpha\" ;;\n+\t    \"EV4.5 (21064)\")\n+\t\tUNAME_MACHINE=\"alpha\" ;;\n+\t    \"LCA4 (21066/21068)\")\n+\t\tUNAME_MACHINE=\"alpha\" ;;\n+\t    \"EV5 (21164)\")\n+\t\tUNAME_MACHINE=\"alphaev5\" ;;\n+\t    \"EV5.6 (21164A)\")\n+\t\tUNAME_MACHINE=\"alphaev56\" ;;\n+\t    \"EV5.6 (21164PC)\")\n+\t\tUNAME_MACHINE=\"alphapca56\" ;;\n+\t    \"EV5.7 (21164PC)\")\n+\t\tUNAME_MACHINE=\"alphapca57\" ;;\n+\t    \"EV6 (21264)\")\n+\t\tUNAME_MACHINE=\"alphaev6\" ;;\n+\t    \"EV6.7 (21264A)\")\n+\t\tUNAME_MACHINE=\"alphaev67\" ;;\n+\t    \"EV6.8CB (21264C)\")\n+\t\tUNAME_MACHINE=\"alphaev68\" ;;\n+\t    \"EV6.8AL (21264B)\")\n+\t\tUNAME_MACHINE=\"alphaev68\" ;;\n+\t    \"EV6.8CX (21264D)\")\n+\t\tUNAME_MACHINE=\"alphaev68\" ;;\n+\t    \"EV6.9A (21264/EV69A)\")\n+\t\tUNAME_MACHINE=\"alphaev69\" ;;\n+\t    \"EV7 (21364)\")\n+\t\tUNAME_MACHINE=\"alphaev7\" ;;\n+\t    \"EV7.9 (21364A)\")\n+\t\tUNAME_MACHINE=\"alphaev79\" ;;\n+\tesac\n+\t# A Pn.n version is a patched version.\n+\t# A Vn.n version is a released version.\n+\t# A Tn.n version is a released field test version.\n+\t# A Xn.n version is an unreleased experimental baselevel.\n+\t# 1.2 uses \"1.2\" for uname -r.\n+\techo ${UNAME_MACHINE}-dec-osf`echo ${UNAME_RELEASE} | sed -e 's/^[PVTX]//' | tr 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 'abcdefghijklmnopqrstuvwxyz'`\n+\t# Reset EXIT trap before exiting to avoid spurious non-zero exit code.\n+\texitcode=$?\n+\ttrap '' 0\n+\texit $exitcode ;;\n+    Alpha\\ *:Windows_NT*:*)\n+\t# How do we know it's Interix rather than the generic POSIX subsystem?\n+\t# Should we change UNAME_MACHINE based on the output of uname instead\n+\t# of the specific Alpha model?\n+\techo alpha-pc-interix\n+\texit ;;\n+    21064:Windows_NT:50:3)\n+\techo alpha-dec-winnt3.5\n+\texit ;;\n+    Amiga*:UNIX_System_V:4.0:*)\n+\techo m68k-unknown-sysv4\n+\texit ;;\n+    *:[Aa]miga[Oo][Ss]:*:*)\n+\techo ${UNAME_MACHINE}-unknown-amigaos\n+\texit ;;\n+    *:[Mm]orph[Oo][Ss]:*:*)\n+\techo ${UNAME_MACHINE}-unknown-morphos\n+\texit ;;\n+    *:OS/390:*:*)\n+\techo i370-ibm-openedition\n+\texit ;;\n+    *:z/VM:*:*)\n+\techo s390-ibm-zvmoe\n+\texit ;;\n+    *:OS400:*:*)\n+\techo powerpc-ibm-os400\n+\texit ;;\n+    arm:RISC*:1.[012]*:*|arm:riscix:1.[012]*:*)\n+\techo arm-acorn-riscix${UNAME_RELEASE}\n+\texit ;;\n+    arm:riscos:*:*|arm:RISCOS:*:*)\n+\techo arm-unknown-riscos\n+\texit ;;\n+    SR2?01:HI-UX/MPP:*:* | SR8000:HI-UX/MPP:*:*)\n+\techo hppa1.1-hitachi-hiuxmpp\n+\texit ;;\n+    Pyramid*:OSx*:*:* | MIS*:OSx*:*:* | MIS*:SMP_DC-OSx*:*:*)\n+\t# akee@wpdis03.wpafb.af.mil (Earle F. Ake) contributed MIS and NILE.\n+\tif test \"`(/bin/universe) 2>/dev/null`\" = att ; then\n+\t\techo pyramid-pyramid-sysv3\n+\telse\n+\t\techo pyramid-pyramid-bsd\n+\tfi\n+\texit ;;\n+    NILE*:*:*:dcosx)\n+\techo pyramid-pyramid-svr4\n+\texit ;;\n+    DRS?6000:unix:4.0:6*)\n+\techo sparc-icl-nx6\n+\texit ;;\n+    DRS?6000:UNIX_SV:4.2*:7* | DRS?6000:isis:4.2*:7*)\n+\tcase `/usr/bin/uname -p` in\n+\t    sparc) echo sparc-icl-nx7; exit ;;\n+\tesac ;;\n+    s390x:SunOS:*:*)\n+\techo ${UNAME_MACHINE}-ibm-solaris2`echo ${UNAME_RELEASE}|sed -e 's/[^.]*//'`\n+\texit ;;\n+    sun4H:SunOS:5.*:*)\n+\techo sparc-hal-solaris2`echo ${UNAME_RELEASE}|sed -e 's/[^.]*//'`\n+\texit ;;\n+    sun4*:SunOS:5.*:* | tadpole*:SunOS:5.*:*)\n+\techo sparc-sun-solaris2`echo ${UNAME_RELEASE}|sed -e 's/[^.]*//'`\n+\texit ;;\n+    i86pc:AuroraUX:5.*:* | i86xen:AuroraUX:5.*:*)\n+\techo i386-pc-auroraux${UNAME_RELEASE}\n+\texit ;;\n+    i86pc:SunOS:5.*:* | i86xen:SunOS:5.*:*)\n+\teval $set_cc_for_build\n+\tSUN_ARCH=\"i386\"\n+\t# If there is a compiler, see if it is configured for 64-bit objects.\n+\t# Note that the Sun cc does not turn __LP64__ into 1 like gcc does.\n+\t# This test works for both compilers.\n+\tif [ \"$CC_FOR_BUILD\" != 'no_compiler_found' ]; then\n+\t    if (echo '#ifdef __amd64'; echo IS_64BIT_ARCH; echo '#endif') | \\\n+\t\t(CCOPTS= $CC_FOR_BUILD -E - 2>/dev/null) | \\\n+\t\tgrep IS_64BIT_ARCH >/dev/null\n+\t    then\n+\t\tSUN_ARCH=\"x86_64\"\n+\t    fi\n+\tfi\n+\techo ${SUN_ARCH}-pc-solaris2`echo ${UNAME_RELEASE}|sed -e 's/[^.]*//'`\n+\texit ;;\n+    sun4*:SunOS:6*:*)\n+\t# According to config.sub, this is the proper way to canonicalize\n+\t# SunOS6.  Hard to guess exactly what SunOS6 will be like, but\n+\t# it's likely to be more like Solaris than SunOS4.\n+\techo sparc-sun-solaris3`echo ${UNAME_RELEASE}|sed -e 's/[^.]*//'`\n+\texit ;;\n+    sun4*:SunOS:*:*)\n+\tcase \"`/usr/bin/arch -k`\" in\n+\t    Series*|S4*)\n+\t\tUNAME_RELEASE=`uname -v`\n+\t\t;;\n+\tesac\n+\t# Japanese Language versions have a version number like `4.1.3-JL'.\n+\techo sparc-sun-sunos`echo ${UNAME_RELEASE}|sed -e 's/-/_/'`\n+\texit ;;\n+    sun3*:SunOS:*:*)\n+\techo m68k-sun-sunos${UNAME_RELEASE}\n+\texit ;;\n+    sun*:*:4.2BSD:*)\n+\tUNAME_RELEASE=`(sed 1q /etc/motd | awk '{print substr($5,1,3)}') 2>/dev/null`\n+\ttest \"x${UNAME_RELEASE}\" = \"x\" && UNAME_RELEASE=3\n+\tcase \"`/bin/arch`\" in\n+\t    sun3)\n+\t\techo m68k-sun-sunos${UNAME_RELEASE}\n+\t\t;;\n+\t    sun4)\n+\t\techo sparc-sun-sunos${UNAME_RELEASE}\n+\t\t;;\n+\tesac\n+\texit ;;\n+    aushp:SunOS:*:*)\n+\techo sparc-auspex-sunos${UNAME_RELEASE}\n+\texit ;;\n+    # The situation for MiNT is a little confusing.  The machine name\n+    # can be virtually everything (everything which is not\n+    # \"atarist\" or \"atariste\" at least should have a processor\n+    # > m68000).  The system name ranges from \"MiNT\" over \"FreeMiNT\"\n+    # to the lowercase version \"mint\" (or \"freemint\").  Finally\n+    # the system name \"TOS\" denotes a system which is actually not\n+    # MiNT.  But MiNT is downward compatible to TOS, so this should\n+    # be no problem.\n+    atarist[e]:*MiNT:*:* | atarist[e]:*mint:*:* | atarist[e]:*TOS:*:*)\n+\techo m68k-atari-mint${UNAME_RELEASE}\n+\texit ;;\n+    atari*:*MiNT:*:* | atari*:*mint:*:* | atarist[e]:*TOS:*:*)\n+\techo m68k-atari-mint${UNAME_RELEASE}\n+\texit ;;\n+    *falcon*:*MiNT:*:* | *falcon*:*mint:*:* | *falcon*:*TOS:*:*)\n+\techo m68k-atari-mint${UNAME_RELEASE}\n+\texit ;;\n+    milan*:*MiNT:*:* | milan*:*mint:*:* | *milan*:*TOS:*:*)\n+\techo m68k-milan-mint${UNAME_RELEASE}\n+\texit ;;\n+    hades*:*MiNT:*:* | hades*:*mint:*:* | *hades*:*TOS:*:*)\n+\techo m68k-hades-mint${UNAME_RELEASE}\n+\texit ;;\n+    *:*MiNT:*:* | *:*mint:*:* | *:*TOS:*:*)\n+\techo m68k-unknown-mint${UNAME_RELEASE}\n+\texit ;;\n+    m68k:machten:*:*)\n+\techo m68k-apple-machten${UNAME_RELEASE}\n+\texit ;;\n+    powerpc:machten:*:*)\n+\techo powerpc-apple-machten${UNAME_RELEASE}\n+\texit ;;\n+    RISC*:Mach:*:*)\n+\techo mips-dec-mach_bsd4.3\n+\texit ;;\n+    RISC*:ULTRIX:*:*)\n+\techo mips-dec-ultrix${UNAME_RELEASE}\n+\texit ;;\n+    VAX*:ULTRIX*:*:*)\n+\techo vax-dec-ultrix${UNAME_RELEASE}\n+\texit ;;\n+    2020:CLIX:*:* | 2430:CLIX:*:*)\n+\techo clipper-intergraph-clix${UNAME_RELEASE}\n+\texit ;;\n+    mips:*:*:UMIPS | mips:*:*:RISCos)\n+\teval $set_cc_for_build\n+\tsed 's/^\t//' << EOF >$dummy.c\n+#ifdef __cplusplus\n+#include <stdio.h>  /* for printf() prototype */\n+\tint main (int argc, char *argv[]) {\n+#else\n+\tint main (argc, argv) int argc; char *argv[]; {\n+#endif\n+\t#if defined (host_mips) && defined (MIPSEB)\n+\t#if defined (SYSTYPE_SYSV)\n+\t  printf (\"mips-mips-riscos%ssysv\\n\", argv[1]); exit (0);\n+\t#endif\n+\t#if defined (SYSTYPE_SVR4)\n+\t  printf (\"mips-mips-riscos%ssvr4\\n\", argv[1]); exit (0);\n+\t#endif\n+\t#if defined (SYSTYPE_BSD43) || defined(SYSTYPE_BSD)\n+\t  printf (\"mips-mips-riscos%sbsd\\n\", argv[1]); exit (0);\n+\t#endif\n+\t#endif\n+\t  exit (-1);\n+\t}\n+EOF\n+\t$CC_FOR_BUILD -o $dummy $dummy.c &&\n+\t  dummyarg=`echo \"${UNAME_RELEASE}\" | sed -n 's/\\([0-9]*\\).*/\\1/p'` &&\n+\t  SYSTEM_NAME=`$dummy $dummyarg` &&\n+\t    { echo \"$SYSTEM_NAME\"; exit; }\n+\techo mips-mips-riscos${UNAME_RELEASE}\n+\texit ;;\n+    Motorola:PowerMAX_OS:*:*)\n+\techo powerpc-motorola-powermax\n+\texit ;;\n+    Motorola:*:4.3:PL8-*)\n+\techo powerpc-harris-powermax\n+\texit ;;\n+    Night_Hawk:*:*:PowerMAX_OS | Synergy:PowerMAX_OS:*:*)\n+\techo powerpc-harris-powermax\n+\texit ;;\n+    Night_Hawk:Power_UNIX:*:*)\n+\techo powerpc-harris-powerunix\n+\texit ;;\n+    m88k:CX/UX:7*:*)\n+\techo m88k-harris-cxux7\n+\texit ;;\n+    m88k:*:4*:R4*)\n+\techo m88k-motorola-sysv4\n+\texit ;;\n+    m88k:*:3*:R3*)\n+\techo m88k-motorola-sysv3\n+\texit ;;\n+    AViiON:dgux:*:*)\n+\t# DG/UX returns AViiON for all architectures\n+\tUNAME_PROCESSOR=`/usr/bin/uname -p`\n+\tif [ $UNAME_PROCESSOR = mc88100 ] || [ $UNAME_PROCESSOR = mc88110 ]\n+\tthen\n+\t    if [ ${TARGET_BINARY_INTERFACE}x = m88kdguxelfx ] || \\\n+\t       [ ${TARGET_BINARY_INTERFACE}x = x ]\n+\t    then\n+\t\techo m88k-dg-dgux${UNAME_RELEASE}\n+\t    else\n+\t\techo m88k-dg-dguxbcs${UNAME_RELEASE}\n+\t    fi\n+\telse\n+\t    echo i586-dg-dgux${UNAME_RELEASE}\n+\tfi\n+\texit ;;\n+    M88*:DolphinOS:*:*)\t# DolphinOS (SVR3)\n+\techo m88k-dolphin-sysv3\n+\texit ;;\n+    M88*:*:R3*:*)\n+\t# Delta 88k system running SVR3\n+\techo m88k-motorola-sysv3\n+\texit ;;\n+    XD88*:*:*:*) # Tektronix XD88 system running UTekV (SVR3)\n+\techo m88k-tektronix-sysv3\n+\texit ;;\n+    Tek43[0-9][0-9]:UTek:*:*) # Tektronix 4300 system running UTek (BSD)\n+\techo m68k-tektronix-bsd\n+\texit ;;\n+    *:IRIX*:*:*)\n+\techo mips-sgi-irix`echo ${UNAME_RELEASE}|sed -e 's/-/_/g'`\n+\texit ;;\n+    ????????:AIX?:[12].1:2)   # AIX 2.2.1 or AIX 2.1.1 is RT/PC AIX.\n+\techo romp-ibm-aix     # uname -m gives an 8 hex-code CPU id\n+\texit ;;               # Note that: echo \"'`uname -s`'\" gives 'AIX '\n+    i*86:AIX:*:*)\n+\techo i386-ibm-aix\n+\texit ;;\n+    ia64:AIX:*:*)\n+\tif [ -x /usr/bin/oslevel ] ; then\n+\t\tIBM_REV=`/usr/bin/oslevel`\n+\telse\n+\t\tIBM_REV=${UNAME_VERSION}.${UNAME_RELEASE}\n+\tfi\n+\techo ${UNAME_MACHINE}-ibm-aix${IBM_REV}\n+\texit ;;\n+    *:AIX:2:3)\n+\tif grep bos325 /usr/include/stdio.h >/dev/null 2>&1; then\n+\t\teval $set_cc_for_build\n+\t\tsed 's/^\t\t//' << EOF >$dummy.c\n+\t\t#include <sys/systemcfg.h>\n+\n+\t\tmain()\n+\t\t\t{\n+\t\t\tif (!__power_pc())\n+\t\t\t\texit(1);\n+\t\t\tputs(\"powerpc-ibm-aix3.2.5\");\n+\t\t\texit(0);\n+\t\t\t}\n+EOF\n+\t\tif $CC_FOR_BUILD -o $dummy $dummy.c && SYSTEM_NAME=`$dummy`\n+\t\tthen\n+\t\t\techo \"$SYSTEM_NAME\"\n+\t\telse\n+\t\t\techo rs6000-ibm-aix3.2.5\n+\t\tfi\n+\telif grep bos324 /usr/include/stdio.h >/dev/null 2>&1; then\n+\t\techo rs6000-ibm-aix3.2.4\n+\telse\n+\t\techo rs6000-ibm-aix3.2\n+\tfi\n+\texit ;;\n+    *:AIX:*:[4567])\n+\tIBM_CPU_ID=`/usr/sbin/lsdev -C -c processor -S available | sed 1q | awk '{ print $1 }'`\n+\tif /usr/sbin/lsattr -El ${IBM_CPU_ID} | grep ' POWER' >/dev/null 2>&1; then\n+\t\tIBM_ARCH=rs6000\n+\telse\n+\t\tIBM_ARCH=powerpc\n+\tfi\n+\tif [ -x /usr/bin/oslevel ] ; then\n+\t\tIBM_REV=`/usr/bin/oslevel`\n+\telse\n+\t\tIBM_REV=${UNAME_VERSION}.${UNAME_RELEASE}\n+\tfi\n+\techo ${IBM_ARCH}-ibm-aix${IBM_REV}\n+\texit ;;\n+    *:AIX:*:*)\n+\techo rs6000-ibm-aix\n+\texit ;;\n+    ibmrt:4.4BSD:*|romp-ibm:BSD:*)\n+\techo romp-ibm-bsd4.4\n+\texit ;;\n+    ibmrt:*BSD:*|romp-ibm:BSD:*)            # covers RT/PC BSD and\n+\techo romp-ibm-bsd${UNAME_RELEASE}   # 4.3 with uname added to\n+\texit ;;                             # report: romp-ibm BSD 4.3\n+    *:BOSX:*:*)\n+\techo rs6000-bull-bosx\n+\texit ;;\n+    DPX/2?00:B.O.S.:*:*)\n+\techo m68k-bull-sysv3\n+\texit ;;\n+    9000/[34]??:4.3bsd:1.*:*)\n+\techo m68k-hp-bsd\n+\texit ;;\n+    hp300:4.4BSD:*:* | 9000/[34]??:4.3bsd:2.*:*)\n+\techo m68k-hp-bsd4.4\n+\texit ;;\n+    9000/[34678]??:HP-UX:*:*)\n+\tHPUX_REV=`echo ${UNAME_RELEASE}|sed -e 's/[^.]*.[0B]*//'`\n+\tcase \"${UNAME_MACHINE}\" in\n+\t    9000/31? )            HP_ARCH=m68000 ;;\n+\t    9000/[34]?? )         HP_ARCH=m68k ;;\n+\t    9000/[678][0-9][0-9])\n+\t\tif [ -x /usr/bin/getconf ]; then\n+\t\t    sc_cpu_version=`/usr/bin/getconf SC_CPU_VERSION 2>/dev/null`\n+\t\t    sc_kernel_bits=`/usr/bin/getconf SC_KERNEL_BITS 2>/dev/null`\n+\t\t    case \"${sc_cpu_version}\" in\n+\t\t      523) HP_ARCH=\"hppa1.0\" ;; # CPU_PA_RISC1_0\n+\t\t      528) HP_ARCH=\"hppa1.1\" ;; # CPU_PA_RISC1_1\n+\t\t      532)                      # CPU_PA_RISC2_0\n+\t\t\tcase \"${sc_kernel_bits}\" in\n+\t\t\t  32) HP_ARCH=\"hppa2.0n\" ;;\n+\t\t\t  64) HP_ARCH=\"hppa2.0w\" ;;\n+\t\t\t  '') HP_ARCH=\"hppa2.0\" ;;   # HP-UX 10.20\n+\t\t\tesac ;;\n+\t\t    esac\n+\t\tfi\n+\t\tif [ \"${HP_ARCH}\" = \"\" ]; then\n+\t\t    eval $set_cc_for_build\n+\t\t    sed 's/^\t\t//' << EOF >$dummy.c\n+\n+\t\t#define _HPUX_SOURCE\n+\t\t#include <stdlib.h>\n+\t\t#include <unistd.h>\n+\n+\t\tint main ()\n+\t\t{\n+\t\t#if defined(_SC_KERNEL_BITS)\n+\t\t    long bits = sysconf(_SC_KERNEL_BITS);\n+\t\t#endif\n+\t\t    long cpu  = sysconf (_SC_CPU_VERSION);\n+\n+\t\t    switch (cpu)\n+\t\t\t{\n+\t\t\tcase CPU_PA_RISC1_0: puts (\"hppa1.0\"); break;\n+\t\t\tcase CPU_PA_RISC1_1: puts (\"hppa1.1\"); break;\n+\t\t\tcase CPU_PA_RISC2_0:\n+\t\t#if defined(_SC_KERNEL_BITS)\n+\t\t\t    switch (bits)\n+\t\t\t\t{\n+\t\t\t\tcase 64: puts (\"hppa2.0w\"); break;\n+\t\t\t\tcase 32: puts (\"hppa2.0n\"); break;\n+\t\t\t\tdefault: puts (\"hppa2.0\"); break;\n+\t\t\t\t} break;\n+\t\t#else  /* !defined(_SC_KERNEL_BITS) */\n+\t\t\t    puts (\"hppa2.0\"); break;\n+\t\t#endif\n+\t\t\tdefault: puts (\"hppa1.0\"); break;\n+\t\t\t}\n+\t\t    exit (0);\n+\t\t}\n+EOF\n+\t\t    (CCOPTS= $CC_FOR_BUILD -o $dummy $dummy.c 2>/dev/null) && HP_ARCH=`$dummy`\n+\t\t    test -z \"$HP_ARCH\" && HP_ARCH=hppa\n+\t\tfi ;;\n+\tesac\n+\tif [ ${HP_ARCH} = \"hppa2.0w\" ]\n+\tthen\n+\t    eval $set_cc_for_build\n+\n+\t    # hppa2.0w-hp-hpux* has a 64-bit kernel and a compiler generating\n+\t    # 32-bit code.  hppa64-hp-hpux* has the same kernel and a compiler\n+\t    # generating 64-bit code.  GNU and HP use different nomenclature:\n+\t    #\n+\t    # $ CC_FOR_BUILD=cc ./config.guess\n+\t    # => hppa2.0w-hp-hpux11.23\n+\t    # $ CC_FOR_BUILD=\"cc +DA2.0w\" ./config.guess\n+\t    # => hppa64-hp-hpux11.23\n+\n+\t    if echo __LP64__ | (CCOPTS= $CC_FOR_BUILD -E - 2>/dev/null) |\n+\t\tgrep -q __LP64__\n+\t    then\n+\t\tHP_ARCH=\"hppa2.0w\"\n+\t    else\n+\t\tHP_ARCH=\"hppa64\"\n+\t    fi\n+\tfi\n+\techo ${HP_ARCH}-hp-hpux${HPUX_REV}\n+\texit ;;\n+    ia64:HP-UX:*:*)\n+\tHPUX_REV=`echo ${UNAME_RELEASE}|sed -e 's/[^.]*.[0B]*//'`\n+\techo ia64-hp-hpux${HPUX_REV}\n+\texit ;;\n+    3050*:HI-UX:*:*)\n+\teval $set_cc_for_build\n+\tsed 's/^\t//' << EOF >$dummy.c\n+\t#include <unistd.h>\n+\tint\n+\tmain ()\n+\t{\n+\t  long cpu = sysconf (_SC_CPU_VERSION);\n+\t  /* The order matters, because CPU_IS_HP_MC68K erroneously returns\n+\t     true for CPU_PA_RISC1_0.  CPU_IS_PA_RISC returns correct\n+\t     results, however.  */\n+\t  if (CPU_IS_PA_RISC (cpu))\n+\t    {\n+\t      switch (cpu)\n+\t\t{\n+\t\t  case CPU_PA_RISC1_0: puts (\"hppa1.0-hitachi-hiuxwe2\"); break;\n+\t\t  case CPU_PA_RISC1_1: puts (\"hppa1.1-hitachi-hiuxwe2\"); break;\n+\t\t  case CPU_PA_RISC2_0: puts (\"hppa2.0-hitachi-hiuxwe2\"); break;\n+\t\t  default: puts (\"hppa-hitachi-hiuxwe2\"); break;\n+\t\t}\n+\t    }\n+\t  else if (CPU_IS_HP_MC68K (cpu))\n+\t    puts (\"m68k-hitachi-hiuxwe2\");\n+\t  else puts (\"unknown-hitachi-hiuxwe2\");\n+\t  exit (0);\n+\t}\n+EOF\n+\t$CC_FOR_BUILD -o $dummy $dummy.c && SYSTEM_NAME=`$dummy` &&\n+\t\t{ echo \"$SYSTEM_NAME\"; exit; }\n+\techo unknown-hitachi-hiuxwe2\n+\texit ;;\n+    9000/7??:4.3bsd:*:* | 9000/8?[79]:4.3bsd:*:* )\n+\techo hppa1.1-hp-bsd\n+\texit ;;\n+    9000/8??:4.3bsd:*:*)\n+\techo hppa1.0-hp-bsd\n+\texit ;;\n+    *9??*:MPE/iX:*:* | *3000*:MPE/iX:*:*)\n+\techo hppa1.0-hp-mpeix\n+\texit ;;\n+    hp7??:OSF1:*:* | hp8?[79]:OSF1:*:* )\n+\techo hppa1.1-hp-osf\n+\texit ;;\n+    hp8??:OSF1:*:*)\n+\techo hppa1.0-hp-osf\n+\texit ;;\n+    i*86:OSF1:*:*)\n+\tif [ -x /usr/sbin/sysversion ] ; then\n+\t    echo ${UNAME_MACHINE}-unknown-osf1mk\n+\telse\n+\t    echo ${UNAME_MACHINE}-unknown-osf1\n+\tfi\n+\texit ;;\n+    parisc*:Lites*:*:*)\n+\techo hppa1.1-hp-lites\n+\texit ;;\n+    C1*:ConvexOS:*:* | convex:ConvexOS:C1*:*)\n+\techo c1-convex-bsd\n+\texit ;;\n+    C2*:ConvexOS:*:* | convex:ConvexOS:C2*:*)\n+\tif getsysinfo -f scalar_acc\n+\tthen echo c32-convex-bsd\n+\telse echo c2-convex-bsd\n+\tfi\n+\texit ;;\n+    C34*:ConvexOS:*:* | convex:ConvexOS:C34*:*)\n+\techo c34-convex-bsd\n+\texit ;;\n+    C38*:ConvexOS:*:* | convex:ConvexOS:C38*:*)\n+\techo c38-convex-bsd\n+\texit ;;\n+    C4*:ConvexOS:*:* | convex:ConvexOS:C4*:*)\n+\techo c4-convex-bsd\n+\texit ;;\n+    CRAY*Y-MP:*:*:*)\n+\techo ymp-cray-unicos${UNAME_RELEASE} | sed -e 's/\\.[^.]*$/.X/'\n+\texit ;;\n+    CRAY*[A-Z]90:*:*:*)\n+\techo ${UNAME_MACHINE}-cray-unicos${UNAME_RELEASE} \\\n+\t| sed -e 's/CRAY.*\\([A-Z]90\\)/\\1/' \\\n+\t      -e y/ABCDEFGHIJKLMNOPQRSTUVWXYZ/abcdefghijklmnopqrstuvwxyz/ \\\n+\t      -e 's/\\.[^.]*$/.X/'\n+\texit ;;\n+    CRAY*TS:*:*:*)\n+\techo t90-cray-unicos${UNAME_RELEASE} | sed -e 's/\\.[^.]*$/.X/'\n+\texit ;;\n+    CRAY*T3E:*:*:*)\n+\techo alphaev5-cray-unicosmk${UNAME_RELEASE} | sed -e 's/\\.[^.]*$/.X/'\n+\texit ;;\n+    CRAY*SV1:*:*:*)\n+\techo sv1-cray-unicos${UNAME_RELEASE} | sed -e 's/\\.[^.]*$/.X/'\n+\texit ;;\n+    *:UNICOS/mp:*:*)\n+\techo craynv-cray-unicosmp${UNAME_RELEASE} | sed -e 's/\\.[^.]*$/.X/'\n+\texit ;;\n+    F30[01]:UNIX_System_V:*:* | F700:UNIX_System_V:*:*)\n+\tFUJITSU_PROC=`uname -m | tr 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 'abcdefghijklmnopqrstuvwxyz'`\n+\tFUJITSU_SYS=`uname -p | tr 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 'abcdefghijklmnopqrstuvwxyz' | sed -e 's/\\///'`\n+\tFUJITSU_REL=`echo ${UNAME_RELEASE} | sed -e 's/ /_/'`\n+\techo \"${FUJITSU_PROC}-fujitsu-${FUJITSU_SYS}${FUJITSU_REL}\"\n+\texit ;;\n+    5000:UNIX_System_V:4.*:*)\n+\tFUJITSU_SYS=`uname -p | tr 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 'abcdefghijklmnopqrstuvwxyz' | sed -e 's/\\///'`\n+\tFUJITSU_REL=`echo ${UNAME_RELEASE} | tr 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 'abcdefghijklmnopqrstuvwxyz' | sed -e 's/ /_/'`\n+\techo \"sparc-fujitsu-${FUJITSU_SYS}${FUJITSU_REL}\"\n+\texit ;;\n+    i*86:BSD/386:*:* | i*86:BSD/OS:*:* | *:Ascend\\ Embedded/OS:*:*)\n+\techo ${UNAME_MACHINE}-pc-bsdi${UNAME_RELEASE}\n+\texit ;;\n+    sparc*:BSD/OS:*:*)\n+\techo sparc-unknown-bsdi${UNAME_RELEASE}\n+\texit ;;\n+    *:BSD/OS:*:*)\n+\techo ${UNAME_MACHINE}-unknown-bsdi${UNAME_RELEASE}\n+\texit ;;\n+    *:FreeBSD:*:*)\n+\tUNAME_PROCESSOR=`/usr/bin/uname -p`\n+\tcase ${UNAME_PROCESSOR} in\n+\t    amd64)\n+\t\techo x86_64-unknown-freebsd`echo ${UNAME_RELEASE}|sed -e 's/[-(].*//'` ;;\n+\t    *)\n+\t\techo ${UNAME_PROCESSOR}-unknown-freebsd`echo ${UNAME_RELEASE}|sed -e 's/[-(].*//'` ;;\n+\tesac\n+\texit ;;\n+    i*:CYGWIN*:*)\n+\techo ${UNAME_MACHINE}-pc-cygwin\n+\texit ;;\n+    *:MINGW*:*)\n+\techo ${UNAME_MACHINE}-pc-mingw32\n+\texit ;;\n+    i*:MSYS*:*)\n+\techo ${UNAME_MACHINE}-pc-msys\n+\texit ;;\n+    i*:windows32*:*)\n+\t# uname -m includes \"-pc\" on this system.\n+\techo ${UNAME_MACHINE}-mingw32\n+\texit ;;\n+    i*:PW*:*)\n+\techo ${UNAME_MACHINE}-pc-pw32\n+\texit ;;\n+    *:Interix*:*)\n+\tcase ${UNAME_MACHINE} in\n+\t    x86)\n+\t\techo i586-pc-interix${UNAME_RELEASE}\n+\t\texit ;;\n+\t    authenticamd | genuineintel | EM64T)\n+\t\techo x86_64-unknown-interix${UNAME_RELEASE}\n+\t\texit ;;\n+\t    IA64)\n+\t\techo ia64-unknown-interix${UNAME_RELEASE}\n+\t\texit ;;\n+\tesac ;;\n+    [345]86:Windows_95:* | [345]86:Windows_98:* | [345]86:Windows_NT:*)\n+\techo i${UNAME_MACHINE}-pc-mks\n+\texit ;;\n+    8664:Windows_NT:*)\n+\techo x86_64-pc-mks\n+\texit ;;\n+    i*:Windows_NT*:* | Pentium*:Windows_NT*:*)\n+\t# How do we know it's Interix rather than the generic POSIX subsystem?\n+\t# It also conflicts with pre-2.0 versions of AT&T UWIN. Should we\n+\t# UNAME_MACHINE based on the output of uname instead of i386?\n+\techo i586-pc-interix\n+\texit ;;\n+    i*:UWIN*:*)\n+\techo ${UNAME_MACHINE}-pc-uwin\n+\texit ;;\n+    amd64:CYGWIN*:*:* | x86_64:CYGWIN*:*:*)\n+\techo x86_64-unknown-cygwin\n+\texit ;;\n+    p*:CYGWIN*:*)\n+\techo powerpcle-unknown-cygwin\n+\texit ;;\n+    prep*:SunOS:5.*:*)\n+\techo powerpcle-unknown-solaris2`echo ${UNAME_RELEASE}|sed -e 's/[^.]*//'`\n+\texit ;;\n+    *:GNU:*:*)\n+\t# the GNU system\n+\techo `echo ${UNAME_MACHINE}|sed -e 's,[-/].*$,,'`-unknown-gnu`echo ${UNAME_RELEASE}|sed -e 's,/.*$,,'`\n+\texit ;;\n+    *:GNU/*:*:*)\n+\t# other systems with GNU libc and userland\n+\techo ${UNAME_MACHINE}-unknown-`echo ${UNAME_SYSTEM} | sed 's,^[^/]*/,,' | tr '[A-Z]' '[a-z]'``echo ${UNAME_RELEASE}|sed -e 's/[-(].*//'`-gnu\n+\texit ;;\n+    i*86:Minix:*:*)\n+\techo ${UNAME_MACHINE}-pc-minix\n+\texit ;;\n+    aarch64:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    aarch64_be:Linux:*:*)\n+\tUNAME_MACHINE=aarch64_be\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    alpha:Linux:*:*)\n+\tcase `sed -n '/^cpu model/s/^.*: \\(.*\\)/\\1/p' < /proc/cpuinfo` in\n+\t  EV5)   UNAME_MACHINE=alphaev5 ;;\n+\t  EV56)  UNAME_MACHINE=alphaev56 ;;\n+\t  PCA56) UNAME_MACHINE=alphapca56 ;;\n+\t  PCA57) UNAME_MACHINE=alphapca56 ;;\n+\t  EV6)   UNAME_MACHINE=alphaev6 ;;\n+\t  EV67)  UNAME_MACHINE=alphaev67 ;;\n+\t  EV68*) UNAME_MACHINE=alphaev68 ;;\n+\tesac\n+\tobjdump --private-headers /bin/sh | grep -q ld.so.1\n+\tif test \"$?\" = 0 ; then LIBC=\"libc1\" ; else LIBC=\"\" ; fi\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu${LIBC}\n+\texit ;;\n+    arm*:Linux:*:*)\n+\teval $set_cc_for_build\n+\tif echo __ARM_EABI__ | $CC_FOR_BUILD -E - 2>/dev/null \\\n+\t    | grep -q __ARM_EABI__\n+\tthen\n+\t    echo ${UNAME_MACHINE}-unknown-linux-gnu\n+\telse\n+\t    if echo __ARM_PCS_VFP | $CC_FOR_BUILD -E - 2>/dev/null \\\n+\t\t| grep -q __ARM_PCS_VFP\n+\t    then\n+\t\techo ${UNAME_MACHINE}-unknown-linux-gnueabi\n+\t    else\n+\t\techo ${UNAME_MACHINE}-unknown-linux-gnueabihf\n+\t    fi\n+\tfi\n+\texit ;;\n+    avr32*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    cris:Linux:*:*)\n+\techo ${UNAME_MACHINE}-axis-linux-gnu\n+\texit ;;\n+    crisv32:Linux:*:*)\n+\techo ${UNAME_MACHINE}-axis-linux-gnu\n+\texit ;;\n+    frv:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    hexagon:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    i*86:Linux:*:*)\n+\tLIBC=gnu\n+\teval $set_cc_for_build\n+\tsed 's/^\t//' << EOF >$dummy.c\n+\t#ifdef __dietlibc__\n+\tLIBC=dietlibc\n+\t#endif\n+EOF\n+\teval `$CC_FOR_BUILD -E $dummy.c 2>/dev/null | grep '^LIBC'`\n+\techo \"${UNAME_MACHINE}-pc-linux-${LIBC}\"\n+\texit ;;\n+    ia64:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    m32r*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    m68*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    mips:Linux:*:* | mips64:Linux:*:*)\n+\teval $set_cc_for_build\n+\tsed 's/^\t//' << EOF >$dummy.c\n+\t#undef CPU\n+\t#undef ${UNAME_MACHINE}\n+\t#undef ${UNAME_MACHINE}el\n+\t#if defined(__MIPSEL__) || defined(__MIPSEL) || defined(_MIPSEL) || defined(MIPSEL)\n+\tCPU=${UNAME_MACHINE}el\n+\t#else\n+\t#if defined(__MIPSEB__) || defined(__MIPSEB) || defined(_MIPSEB) || defined(MIPSEB)\n+\tCPU=${UNAME_MACHINE}\n+\t#else\n+\tCPU=\n+\t#endif\n+\t#endif\n+EOF\n+\teval `$CC_FOR_BUILD -E $dummy.c 2>/dev/null | grep '^CPU'`\n+\ttest x\"${CPU}\" != x && { echo \"${CPU}-unknown-linux-gnu\"; exit; }\n+\t;;\n+    or32:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    padre:Linux:*:*)\n+\techo sparc-unknown-linux-gnu\n+\texit ;;\n+    parisc64:Linux:*:* | hppa64:Linux:*:*)\n+\techo hppa64-unknown-linux-gnu\n+\texit ;;\n+    parisc:Linux:*:* | hppa:Linux:*:*)\n+\t# Look for CPU level\n+\tcase `grep '^cpu[^a-z]*:' /proc/cpuinfo 2>/dev/null | cut -d' ' -f2` in\n+\t  PA7*) echo hppa1.1-unknown-linux-gnu ;;\n+\t  PA8*) echo hppa2.0-unknown-linux-gnu ;;\n+\t  *)    echo hppa-unknown-linux-gnu ;;\n+\tesac\n+\texit ;;\n+    ppc64:Linux:*:*)\n+\techo powerpc64-unknown-linux-gnu\n+\texit ;;\n+    ppc:Linux:*:*)\n+\techo powerpc-unknown-linux-gnu\n+\texit ;;\n+    s390:Linux:*:* | s390x:Linux:*:*)\n+\techo ${UNAME_MACHINE}-ibm-linux\n+\texit ;;\n+    sh64*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    sh*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    sparc:Linux:*:* | sparc64:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    tile*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    vax:Linux:*:*)\n+\techo ${UNAME_MACHINE}-dec-linux-gnu\n+\texit ;;\n+    x86_64:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    xtensa*:Linux:*:*)\n+\techo ${UNAME_MACHINE}-unknown-linux-gnu\n+\texit ;;\n+    i*86:DYNIX/ptx:4*:*)\n+\t# ptx 4.0 does uname -s correctly, with DYNIX/ptx in there.\n+\t# earlier versions are messed up and put the nodename in both\n+\t# sysname and nodename.\n+\techo i386-sequent-sysv4\n+\texit ;;\n+    i*86:UNIX_SV:4.2MP:2.*)\n+\t# Unixware is an offshoot of SVR4, but it has its own version\n+\t# number series starting with 2...\n+\t# I am not positive that other SVR4 systems won't match this,\n+\t# I just have to hope.  -- rms.\n+\t# Use sysv4.2uw... so that sysv4* matches it.\n+\techo ${UNAME_MACHINE}-pc-sysv4.2uw${UNAME_VERSION}\n+\texit ;;\n+    i*86:OS/2:*:*)\n+\t# If we were able to find `uname', then EMX Unix compatibility\n+\t# is probably installed.\n+\techo ${UNAME_MACHINE}-pc-os2-emx\n+\texit ;;\n+    i*86:XTS-300:*:STOP)\n+\techo ${UNAME_MACHINE}-unknown-stop\n+\texit ;;\n+    i*86:atheos:*:*)\n+\techo ${UNAME_MACHINE}-unknown-atheos\n+\texit ;;\n+    i*86:syllable:*:*)\n+\techo ${UNAME_MACHINE}-pc-syllable\n+\texit ;;\n+    i*86:LynxOS:2.*:* | i*86:LynxOS:3.[01]*:* | i*86:LynxOS:4.[02]*:*)\n+\techo i386-unknown-lynxos${UNAME_RELEASE}\n+\texit ;;\n+    i*86:*DOS:*:*)\n+\techo ${UNAME_MACHINE}-pc-msdosdjgpp\n+\texit ;;\n+    i*86:*:4.*:* | i*86:SYSTEM_V:4.*:*)\n+\tUNAME_REL=`echo ${UNAME_RELEASE} | sed 's/\\/MP$//'`\n+\tif grep Novell /usr/include/link.h >/dev/null 2>/dev/null; then\n+\t\techo ${UNAME_MACHINE}-univel-sysv${UNAME_REL}\n+\telse\n+\t\techo ${UNAME_MACHINE}-pc-sysv${UNAME_REL}\n+\tfi\n+\texit ;;\n+    i*86:*:5:[678]*)\n+\t# UnixWare 7.x, OpenUNIX and OpenServer 6.\n+\tcase `/bin/uname -X | grep \"^Machine\"` in\n+\t    *486*)\t     UNAME_MACHINE=i486 ;;\n+\t    *Pentium)\t     UNAME_MACHINE=i586 ;;\n+\t    *Pent*|*Celeron) UNAME_MACHINE=i686 ;;\n+\tesac\n+\techo ${UNAME_MACHINE}-unknown-sysv${UNAME_RELEASE}${UNAME_SYSTEM}${UNAME_VERSION}\n+\texit ;;\n+    i*86:*:3.2:*)\n+\tif test -f /usr/options/cb.name; then\n+\t\tUNAME_REL=`sed -n 's/.*Version //p' </usr/options/cb.name`\n+\t\techo ${UNAME_MACHINE}-pc-isc$UNAME_REL\n+\telif /bin/uname -X 2>/dev/null >/dev/null ; then\n+\t\tUNAME_REL=`(/bin/uname -X|grep Release|sed -e 's/.*= //')`\n+\t\t(/bin/uname -X|grep i80486 >/dev/null) && UNAME_MACHINE=i486\n+\t\t(/bin/uname -X|grep '^Machine.*Pentium' >/dev/null) \\\n+\t\t\t&& UNAME_MACHINE=i586\n+\t\t(/bin/uname -X|grep '^Machine.*Pent *II' >/dev/null) \\\n+\t\t\t&& UNAME_MACHINE=i686\n+\t\t(/bin/uname -X|grep '^Machine.*Pentium Pro' >/dev/null) \\\n+\t\t\t&& UNAME_MACHINE=i686\n+\t\techo ${UNAME_MACHINE}-pc-sco$UNAME_REL\n+\telse\n+\t\techo ${UNAME_MACHINE}-pc-sysv32\n+\tfi\n+\texit ;;\n+    pc:*:*:*)\n+\t# Left here for compatibility:\n+\t# uname -m prints for DJGPP always 'pc', but it prints nothing about\n+\t# the processor, so we play safe by assuming i586.\n+\t# Note: whatever this is, it MUST be the same as what config.sub\n+\t# prints for the \"djgpp\" host, or else GDB configury will decide that\n+\t# this is a cross-build.\n+\techo i586-pc-msdosdjgpp\n+\texit ;;\n+    Intel:Mach:3*:*)\n+\techo i386-pc-mach3\n+\texit ;;\n+    paragon:*:*:*)\n+\techo i860-intel-osf1\n+\texit ;;\n+    i860:*:4.*:*) # i860-SVR4\n+\tif grep Stardent /usr/include/sys/uadmin.h >/dev/null 2>&1 ; then\n+\t  echo i860-stardent-sysv${UNAME_RELEASE} # Stardent Vistra i860-SVR4\n+\telse # Add other i860-SVR4 vendors below as they are discovered.\n+\t  echo i860-unknown-sysv${UNAME_RELEASE}  # Unknown i860-SVR4\n+\tfi\n+\texit ;;\n+    mini*:CTIX:SYS*5:*)\n+\t# \"miniframe\"\n+\techo m68010-convergent-sysv\n+\texit ;;\n+    mc68k:UNIX:SYSTEM5:3.51m)\n+\techo m68k-convergent-sysv\n+\texit ;;\n+    M680?0:D-NIX:5.3:*)\n+\techo m68k-diab-dnix\n+\texit ;;\n+    M68*:*:R3V[5678]*:*)\n+\ttest -r /sysV68 && { echo 'm68k-motorola-sysv'; exit; } ;;\n+    3[345]??:*:4.0:3.0 | 3[34]??A:*:4.0:3.0 | 3[34]??,*:*:4.0:3.0 | 3[34]??/*:*:4.0:3.0 | 4400:*:4.0:3.0 | 4850:*:4.0:3.0 | SKA40:*:4.0:3.0 | SDS2:*:4.0:3.0 | SHG2:*:4.0:3.0 | S7501*:*:4.0:3.0)\n+\tOS_REL=''\n+\ttest -r /etc/.relid \\\n+\t&& OS_REL=.`sed -n 's/[^ ]* [^ ]* \\([0-9][0-9]\\).*/\\1/p' < /etc/.relid`\n+\t/bin/uname -p 2>/dev/null | grep 86 >/dev/null \\\n+\t  && { echo i486-ncr-sysv4.3${OS_REL}; exit; }\n+\t/bin/uname -p 2>/dev/null | /bin/grep entium >/dev/null \\\n+\t  && { echo i586-ncr-sysv4.3${OS_REL}; exit; } ;;\n+    3[34]??:*:4.0:* | 3[34]??,*:*:4.0:*)\n+\t/bin/uname -p 2>/dev/null | grep 86 >/dev/null \\\n+\t  && { echo i486-ncr-sysv4; exit; } ;;\n+    NCR*:*:4.2:* | MPRAS*:*:4.2:*)\n+\tOS_REL='.3'\n+\ttest -r /etc/.relid \\\n+\t    && OS_REL=.`sed -n 's/[^ ]* [^ ]* \\([0-9][0-9]\\).*/\\1/p' < /etc/.relid`\n+\t/bin/uname -p 2>/dev/null | grep 86 >/dev/null \\\n+\t    && { echo i486-ncr-sysv4.3${OS_REL}; exit; }\n+\t/bin/uname -p 2>/dev/null | /bin/grep entium >/dev/null \\\n+\t    && { echo i586-ncr-sysv4.3${OS_REL}; exit; }\n+\t/bin/uname -p 2>/dev/null | /bin/grep pteron >/dev/null \\\n+\t    && { echo i586-ncr-sysv4.3${OS_REL}; exit; } ;;\n+    m68*:LynxOS:2.*:* | m68*:LynxOS:3.0*:*)\n+\techo m68k-unknown-lynxos${UNAME_RELEASE}\n+\texit ;;\n+    mc68030:UNIX_System_V:4.*:*)\n+\techo m68k-atari-sysv4\n+\texit ;;\n+    TSUNAMI:LynxOS:2.*:*)\n+\techo sparc-unknown-lynxos${UNAME_RELEASE}\n+\texit ;;\n+    rs6000:LynxOS:2.*:*)\n+\techo rs6000-unknown-lynxos${UNAME_RELEASE}\n+\texit ;;\n+    PowerPC:LynxOS:2.*:* | PowerPC:LynxOS:3.[01]*:* | PowerPC:LynxOS:4.[02]*:*)\n+\techo powerpc-unknown-lynxos${UNAME_RELEASE}\n+\texit ;;\n+    SM[BE]S:UNIX_SV:*:*)\n+\techo mips-dde-sysv${UNAME_RELEASE}\n+\texit ;;\n+    RM*:ReliantUNIX-*:*:*)\n+\techo mips-sni-sysv4\n+\texit ;;\n+    RM*:SINIX-*:*:*)\n+\techo mips-sni-sysv4\n+\texit ;;\n+    *:SINIX-*:*:*)\n+\tif uname -p 2>/dev/null >/dev/null ; then\n+\t\tUNAME_MACHINE=`(uname -p) 2>/dev/null`\n+\t\techo ${UNAME_MACHINE}-sni-sysv4\n+\telse\n+\t\techo ns32k-sni-sysv\n+\tfi\n+\texit ;;\n+    PENTIUM:*:4.0*:*)\t# Unisys `ClearPath HMP IX 4000' SVR4/MP effort\n+\t\t\t# says <Richard.M.Bartel@ccMail.Census.GOV>\n+\techo i586-unisys-sysv4\n+\texit ;;\n+    *:UNIX_System_V:4*:FTX*)\n+\t# From Gerald Hewes <hewes@openmarket.com>.\n+\t# How about differentiating between stratus architectures? -djm\n+\techo hppa1.1-stratus-sysv4\n+\texit ;;\n+    *:*:*:FTX*)\n+\t# From seanf@swdc.stratus.com.\n+\techo i860-stratus-sysv4\n+\texit ;;\n+    i*86:VOS:*:*)\n+\t# From Paul.Green@stratus.com.\n+\techo ${UNAME_MACHINE}-stratus-vos\n+\texit ;;\n+    *:VOS:*:*)\n+\t# From Paul.Green@stratus.com.\n+\techo hppa1.1-stratus-vos\n+\texit ;;\n+    mc68*:A/UX:*:*)\n+\techo m68k-apple-aux${UNAME_RELEASE}\n+\texit ;;\n+    news*:NEWS-OS:6*:*)\n+\techo mips-sony-newsos6\n+\texit ;;\n+    R[34]000:*System_V*:*:* | R4000:UNIX_SYSV:*:* | R*000:UNIX_SV:*:*)\n+\tif [ -d /usr/nec ]; then\n+\t\techo mips-nec-sysv${UNAME_RELEASE}\n+\telse\n+\t\techo mips-unknown-sysv${UNAME_RELEASE}\n+\tfi\n+\texit ;;\n+    BeBox:BeOS:*:*)\t# BeOS running on hardware made by Be, PPC only.\n+\techo powerpc-be-beos\n+\texit ;;\n+    BeMac:BeOS:*:*)\t# BeOS running on Mac or Mac clone, PPC only.\n+\techo powerpc-apple-beos\n+\texit ;;\n+    BePC:BeOS:*:*)\t# BeOS running on Intel PC compatible.\n+\techo i586-pc-beos\n+\texit ;;\n+    BePC:Haiku:*:*)\t# Haiku running on Intel PC compatible.\n+\techo i586-pc-haiku\n+\texit ;;\n+    SX-4:SUPER-UX:*:*)\n+\techo sx4-nec-superux${UNAME_RELEASE}\n+\texit ;;\n+    SX-5:SUPER-UX:*:*)\n+\techo sx5-nec-superux${UNAME_RELEASE}\n+\texit ;;\n+    SX-6:SUPER-UX:*:*)\n+\techo sx6-nec-superux${UNAME_RELEASE}\n+\texit ;;\n+    SX-7:SUPER-UX:*:*)\n+\techo sx7-nec-superux${UNAME_RELEASE}\n+\texit ;;\n+    SX-8:SUPER-UX:*:*)\n+\techo sx8-nec-superux${UNAME_RELEASE}\n+\texit ;;\n+    SX-8R:SUPER-UX:*:*)\n+\techo sx8r-nec-superux${UNAME_RELEASE}\n+\texit ;;\n+    Power*:Rhapsody:*:*)\n+\techo powerpc-apple-rhapsody${UNAME_RELEASE}\n+\texit ;;\n+    *:Rhapsody:*:*)\n+\techo ${UNAME_MACHINE}-apple-rhapsody${UNAME_RELEASE}\n+\texit ;;\n+    *:Darwin:*:*)\n+\tUNAME_PROCESSOR=`uname -p` || UNAME_PROCESSOR=unknown\n+\tcase $UNAME_PROCESSOR in\n+\t    i386)\n+\t\teval $set_cc_for_build\n+\t\tif [ \"$CC_FOR_BUILD\" != 'no_compiler_found' ]; then\n+\t\t  if (echo '#ifdef __LP64__'; echo IS_64BIT_ARCH; echo '#endif') | \\\n+\t\t      (CCOPTS= $CC_FOR_BUILD -E - 2>/dev/null) | \\\n+\t\t      grep IS_64BIT_ARCH >/dev/null\n+\t\t  then\n+\t\t      UNAME_PROCESSOR=\"x86_64\"\n+\t\t  fi\n+\t\tfi ;;\n+\t    unknown) UNAME_PROCESSOR=powerpc ;;\n+\tesac\n+\techo ${UNAME_PROCESSOR}-apple-darwin${UNAME_RELEASE}\n+\texit ;;\n+    *:procnto*:*:* | *:QNX:[0123456789]*:*)\n+\tUNAME_PROCESSOR=`uname -p`\n+\tif test \"$UNAME_PROCESSOR\" = \"x86\"; then\n+\t\tUNAME_PROCESSOR=i386\n+\t\tUNAME_MACHINE=pc\n+\tfi\n+\techo ${UNAME_PROCESSOR}-${UNAME_MACHINE}-nto-qnx${UNAME_RELEASE}\n+\texit ;;\n+    *:QNX:*:4*)\n+\techo i386-pc-qnx\n+\texit ;;\n+    NEO-?:NONSTOP_KERNEL:*:*)\n+\techo neo-tandem-nsk${UNAME_RELEASE}\n+\texit ;;\n+    NSE-?:NONSTOP_KERNEL:*:*)\n+\techo nse-tandem-nsk${UNAME_RELEASE}\n+\texit ;;\n+    NSR-?:NONSTOP_KERNEL:*:*)\n+\techo nsr-tandem-nsk${UNAME_RELEASE}\n+\texit ;;\n+    *:NonStop-UX:*:*)\n+\techo mips-compaq-nonstopux\n+\texit ;;\n+    BS2000:POSIX*:*:*)\n+\techo bs2000-siemens-sysv\n+\texit ;;\n+    DS/*:UNIX_System_V:*:*)\n+\techo ${UNAME_MACHINE}-${UNAME_SYSTEM}-${UNAME_RELEASE}\n+\texit ;;\n+    *:Plan9:*:*)\n+\t# \"uname -m\" is not consistent, so use $cputype instead. 386\n+\t# is converted to i386 for consistency with other x86\n+\t# operating systems.\n+\tif test \"$cputype\" = \"386\"; then\n+\t    UNAME_MACHINE=i386\n+\telse\n+\t    UNAME_MACHINE=\"$cputype\"\n+\tfi\n+\techo ${UNAME_MACHINE}-unknown-plan9\n+\texit ;;\n+    *:TOPS-10:*:*)\n+\techo pdp10-unknown-tops10\n+\texit ;;\n+    *:TENEX:*:*)\n+\techo pdp10-unknown-tenex\n+\texit ;;\n+    KS10:TOPS-20:*:* | KL10:TOPS-20:*:* | TYPE4:TOPS-20:*:*)\n+\techo pdp10-dec-tops20\n+\texit ;;\n+    XKL-1:TOPS-20:*:* | TYPE5:TOPS-20:*:*)\n+\techo pdp10-xkl-tops20\n+\texit ;;\n+    *:TOPS-20:*:*)\n+\techo pdp10-unknown-tops20\n+\texit ;;\n+    *:ITS:*:*)\n+\techo pdp10-unknown-its\n+\texit ;;\n+    SEI:*:*:SEIUX)\n+\techo mips-sei-seiux${UNAME_RELEASE}\n+\texit ;;\n+    *:DragonFly:*:*)\n+\techo ${UNAME_MACHINE}-unknown-dragonfly`echo ${UNAME_RELEASE}|sed -e 's/[-(].*//'`\n+\texit ;;\n+    *:*VMS:*:*)\n+\tUNAME_MACHINE=`(uname -p) 2>/dev/null`\n+\tcase \"${UNAME_MACHINE}\" in\n+\t    A*) echo alpha-dec-vms ; exit ;;\n+\t    I*) echo ia64-dec-vms ; exit ;;\n+\t    V*) echo vax-dec-vms ; exit ;;\n+\tesac ;;\n+    *:XENIX:*:SysV)\n+\techo i386-pc-xenix\n+\texit ;;\n+    i*86:skyos:*:*)\n+\techo ${UNAME_MACHINE}-pc-skyos`echo ${UNAME_RELEASE}` | sed -e 's/ .*$//'\n+\texit ;;\n+    i*86:rdos:*:*)\n+\techo ${UNAME_MACHINE}-pc-rdos\n+\texit ;;\n+    i*86:AROS:*:*)\n+\techo ${UNAME_MACHINE}-pc-aros\n+\texit ;;\n+    x86_64:VMkernel:*:*)\n+\techo ${UNAME_MACHINE}-unknown-esx\n+\texit ;;\n+esac\n+\n+#echo '(No uname command or uname output not recognized.)' 1>&2\n+#echo \"${UNAME_MACHINE}:${UNAME_SYSTEM}:${UNAME_RELEASE}:${UNAME_VERSION}\" 1>&2\n+\n+eval $set_cc_for_build\n+cat >$dummy.c <<EOF\n+#ifdef _SEQUENT_\n+# include <sys/types.h>\n+# include <sys/utsname.h>\n+#endif\n+main ()\n+{\n+#if defined (sony)\n+#if defined (MIPSEB)\n+  /* BFD wants \"bsd\" instead of \"newsos\".  Perhaps BFD should be changed,\n+     I don't know....  */\n+  printf (\"mips-sony-bsd\\n\"); exit (0);\n+#else\n+#include <sys/param.h>\n+  printf (\"m68k-sony-newsos%s\\n\",\n+#ifdef NEWSOS4\n+\t\"4\"\n+#else\n+\t\"\"\n+#endif\n+\t); exit (0);\n+#endif\n+#endif\n+\n+#if defined (__arm) && defined (__acorn) && defined (__unix)\n+  printf (\"arm-acorn-riscix\\n\"); exit (0);\n+#endif\n+\n+#if defined (hp300) && !defined (hpux)\n+  printf (\"m68k-hp-bsd\\n\"); exit (0);\n+#endif\n+\n+#if defined (NeXT)\n+#if !defined (__ARCHITECTURE__)\n+#define __ARCHITECTURE__ \"m68k\"\n+#endif\n+  int version;\n+  version=`(hostinfo | sed -n 's/.*NeXT Mach \\([0-9]*\\).*/\\1/p') 2>/dev/null`;\n+  if (version < 4)\n+    printf (\"%s-next-nextstep%d\\n\", __ARCHITECTURE__, version);\n+  else\n+    printf (\"%s-next-openstep%d\\n\", __ARCHITECTURE__, version);\n+  exit (0);\n+#endif\n+\n+#if defined (MULTIMAX) || defined (n16)\n+#if defined (UMAXV)\n+  printf (\"ns32k-encore-sysv\\n\"); exit (0);\n+#else\n+#if defined (CMU)\n+  printf (\"ns32k-encore-mach\\n\"); exit (0);\n+#else\n+  printf (\"ns32k-encore-bsd\\n\"); exit (0);\n+#endif\n+#endif\n+#endif\n+\n+#if defined (__386BSD__)\n+  printf (\"i386-pc-bsd\\n\"); exit (0);\n+#endif\n+\n+#if defined (sequent)\n+#if defined (i386)\n+  printf (\"i386-sequent-dynix\\n\"); exit (0);\n+#endif\n+#if defined (ns32000)\n+  printf (\"ns32k-sequent-dynix\\n\"); exit (0);\n+#endif\n+#endif\n+\n+#if defined (_SEQUENT_)\n+    struct utsname un;\n+\n+    uname(&un);\n+\n+    if (strncmp(un.version, \"V2\", 2) == 0) {\n+\tprintf (\"i386-sequent-ptx2\\n\"); exit (0);\n+    }\n+    if (strncmp(un.version, \"V1\", 2) == 0) { /* XXX is V1 correct? */\n+\tprintf (\"i386-sequent-ptx1\\n\"); exit (0);\n+    }\n+    printf (\"i386-sequent-ptx\\n\"); exit (0);\n+\n+#endif\n+\n+#if defined (vax)\n+# if !defined (ultrix)\n+#  include <sys/param.h>\n+#  if defined (BSD)\n+#   if BSD == 43\n+      printf (\"vax-dec-bsd4.3\\n\"); exit (0);\n+#   else\n+#    if BSD == 199006\n+      printf (\"vax-dec-bsd4.3reno\\n\"); exit (0);\n+#    else\n+      printf (\"vax-dec-bsd\\n\"); exit (0);\n+#    endif\n+#   endif\n+#  else\n+    printf (\"vax-dec-bsd\\n\"); exit (0);\n+#  endif\n+# else\n+    printf (\"vax-dec-ultrix\\n\"); exit (0);\n+# endif\n+#endif\n+\n+#if defined (alliant) && defined (i860)\n+  printf (\"i860-alliant-bsd\\n\"); exit (0);\n+#endif\n+\n+  exit (1);\n+}\n+EOF\n+\n+$CC_FOR_BUILD -o $dummy $dummy.c 2>/dev/null && SYSTEM_NAME=`$dummy` &&\n+\t{ echo \"$SYSTEM_NAME\"; exit; }\n+\n+# Apollos put the system type in the environment.\n+\n+test -d /usr/apollo && { echo ${ISP}-apollo-${SYSTYPE}; exit; }\n+\n+# Convex versions that predate uname can use getsysinfo(1)\n+\n+if [ -x /usr/convex/getsysinfo ]\n+then\n+    case `getsysinfo -f cpu_type` in\n+    c1*)\n+\techo c1-convex-bsd\n+\texit ;;\n+    c2*)\n+\tif getsysinfo -f scalar_acc\n+\tthen echo c32-convex-bsd\n+\telse echo c2-convex-bsd\n+\tfi\n+\texit ;;\n+    c34*)\n+\techo c34-convex-bsd\n+\texit ;;\n+    c38*)\n+\techo c38-convex-bsd\n+\texit ;;\n+    c4*)\n+\techo c4-convex-bsd\n+\texit ;;\n+    esac\n+fi\n+\n+cat >&2 <<EOF\n+$0: unable to guess system type\n+\n+This script, last modified $timestamp, has failed to recognize\n+the operating system you are using. It is advised that you\n+download the most up to date version of the config scripts from\n+\n+  http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD\n+and\n+  http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD\n+\n+If the version you run ($0) is already up to date, please\n+send the following data and any information you think might be\n+pertinent to <config-patches@gnu.org> in order to provide the needed\n+information to handle your system.\n+\n+config.guess timestamp = $timestamp\n+\n+uname -m = `(uname -m) 2>/dev/null || echo unknown`\n+uname -r = `(uname -r) 2>/dev/null || echo unknown`\n+uname -s = `(uname -s) 2>/dev/null || echo unknown`\n+uname -v = `(uname -v) 2>/dev/null || echo unknown`\n+\n+/usr/bin/uname -p = `(/usr/bin/uname -p) 2>/dev/null`\n+/bin/uname -X     = `(/bin/uname -X) 2>/dev/null`\n+\n+hostinfo               = `(hostinfo) 2>/dev/null`\n+/bin/universe          = `(/bin/universe) 2>/dev/null`\n+/usr/bin/arch -k       = `(/usr/bin/arch -k) 2>/dev/null`\n+/bin/arch              = `(/bin/arch) 2>/dev/null`\n+/usr/bin/oslevel       = `(/usr/bin/oslevel) 2>/dev/null`\n+/usr/convex/getsysinfo = `(/usr/convex/getsysinfo) 2>/dev/null`\n+\n+UNAME_MACHINE = ${UNAME_MACHINE}\n+UNAME_RELEASE = ${UNAME_RELEASE}\n+UNAME_SYSTEM  = ${UNAME_SYSTEM}\n+UNAME_VERSION = ${UNAME_VERSION}\n+EOF\n+\n+exit 1\n+\n+# Local variables:\n+# eval: (add-hook 'write-file-hooks 'time-stamp)\n+# time-stamp-start: \"timestamp='\"\n+# time-stamp-format: \"%:y-%02m-%02d\"\n+# time-stamp-end: \"'\"\n+# End:"}, {"sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391", "filename": "src/rt/jemalloc/config.stamp.in", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfig.stamp.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfig.stamp.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fconfig.stamp.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "c894da45500c4af1bf5688e713a8895622d18182", "filename": "src/rt/jemalloc/config.sub", "status": "added", "additions": 1773, "deletions": 0, "changes": 1773, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfig.sub", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfig.sub", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fconfig.sub?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,1773 @@\n+#! /bin/sh\n+# Configuration validation subroutine script.\n+#   Copyright (C) 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n+#   2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n+#   2011, 2012 Free Software Foundation, Inc.\n+\n+timestamp='2012-02-10'\n+\n+# This file is (in principle) common to ALL GNU software.\n+# The presence of a machine in this file suggests that SOME GNU software\n+# can handle that machine.  It does not imply ALL GNU software can.\n+#\n+# This file is free software; you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 2 of the License, or\n+# (at your option) any later version.\n+#\n+# This program is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with this program; if not, see <http://www.gnu.org/licenses/>.\n+#\n+# As a special exception to the GNU General Public License, if you\n+# distribute this file as part of a program that contains a\n+# configuration script generated by Autoconf, you may include it under\n+# the same distribution terms that you use for the rest of that program.\n+\n+\n+# Please send patches to <config-patches@gnu.org>.  Submit a context\n+# diff and a properly formatted GNU ChangeLog entry.\n+#\n+# Configuration subroutine to validate and canonicalize a configuration type.\n+# Supply the specified configuration type as an argument.\n+# If it is invalid, we print an error message on stderr and exit with code 1.\n+# Otherwise, we print the canonical config type on stdout and succeed.\n+\n+# You can get the latest version of this script from:\n+# http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD\n+\n+# This file is supposed to be the same for all GNU packages\n+# and recognize all the CPU types, system types and aliases\n+# that are meaningful with *any* GNU software.\n+# Each package is responsible for reporting which valid configurations\n+# it does not support.  The user should be able to distinguish\n+# a failure to support a valid configuration from a meaningless\n+# configuration.\n+\n+# The goal of this file is to map all the various variations of a given\n+# machine specification into a single specification in the form:\n+#\tCPU_TYPE-MANUFACTURER-OPERATING_SYSTEM\n+# or in some cases, the newer four-part form:\n+#\tCPU_TYPE-MANUFACTURER-KERNEL-OPERATING_SYSTEM\n+# It is wrong to echo any other type of specification.\n+\n+me=`echo \"$0\" | sed -e 's,.*/,,'`\n+\n+usage=\"\\\n+Usage: $0 [OPTION] CPU-MFR-OPSYS\n+       $0 [OPTION] ALIAS\n+\n+Canonicalize a configuration name.\n+\n+Operation modes:\n+  -h, --help         print this help, then exit\n+  -t, --time-stamp   print date of last modification, then exit\n+  -v, --version      print version number, then exit\n+\n+Report bugs and patches to <config-patches@gnu.org>.\"\n+\n+version=\"\\\n+GNU config.sub ($timestamp)\n+\n+Copyright (C) 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n+2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012\n+Free Software Foundation, Inc.\n+\n+This is free software; see the source for copying conditions.  There is NO\n+warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\"\n+\n+help=\"\n+Try \\`$me --help' for more information.\"\n+\n+# Parse command line\n+while test $# -gt 0 ; do\n+  case $1 in\n+    --time-stamp | --time* | -t )\n+       echo \"$timestamp\" ; exit ;;\n+    --version | -v )\n+       echo \"$version\" ; exit ;;\n+    --help | --h* | -h )\n+       echo \"$usage\"; exit ;;\n+    -- )     # Stop option processing\n+       shift; break ;;\n+    - )\t# Use stdin as input.\n+       break ;;\n+    -* )\n+       echo \"$me: invalid option $1$help\"\n+       exit 1 ;;\n+\n+    *local*)\n+       # First pass through any local machine types.\n+       echo $1\n+       exit ;;\n+\n+    * )\n+       break ;;\n+  esac\n+done\n+\n+case $# in\n+ 0) echo \"$me: missing argument$help\" >&2\n+    exit 1;;\n+ 1) ;;\n+ *) echo \"$me: too many arguments$help\" >&2\n+    exit 1;;\n+esac\n+\n+# Separate what the user gave into CPU-COMPANY and OS or KERNEL-OS (if any).\n+# Here we must recognize all the valid KERNEL-OS combinations.\n+maybe_os=`echo $1 | sed 's/^\\(.*\\)-\\([^-]*-[^-]*\\)$/\\2/'`\n+case $maybe_os in\n+  nto-qnx* | linux-gnu* | linux-android* | linux-dietlibc | linux-newlib* | \\\n+  linux-uclibc* | uclinux-uclibc* | uclinux-gnu* | kfreebsd*-gnu* | \\\n+  knetbsd*-gnu* | netbsd*-gnu* | \\\n+  kopensolaris*-gnu* | \\\n+  storm-chaos* | os2-emx* | rtmk-nova*)\n+    os=-$maybe_os\n+    basic_machine=`echo $1 | sed 's/^\\(.*\\)-\\([^-]*-[^-]*\\)$/\\1/'`\n+    ;;\n+  android-linux)\n+    os=-linux-android\n+    basic_machine=`echo $1 | sed 's/^\\(.*\\)-\\([^-]*-[^-]*\\)$/\\1/'`-unknown\n+    ;;\n+  *)\n+    basic_machine=`echo $1 | sed 's/-[^-]*$//'`\n+    if [ $basic_machine != $1 ]\n+    then os=`echo $1 | sed 's/.*-/-/'`\n+    else os=; fi\n+    ;;\n+esac\n+\n+### Let's recognize common machines as not being operating systems so\n+### that things like config.sub decstation-3100 work.  We also\n+### recognize some manufacturers as not being operating systems, so we\n+### can provide default operating systems below.\n+case $os in\n+\t-sun*os*)\n+\t\t# Prevent following clause from handling this invalid input.\n+\t\t;;\n+\t-dec* | -mips* | -sequent* | -encore* | -pc532* | -sgi* | -sony* | \\\n+\t-att* | -7300* | -3300* | -delta* | -motorola* | -sun[234]* | \\\n+\t-unicom* | -ibm* | -next | -hp | -isi* | -apollo | -altos* | \\\n+\t-convergent* | -ncr* | -news | -32* | -3600* | -3100* | -hitachi* |\\\n+\t-c[123]* | -convex* | -sun | -crds | -omron* | -dg | -ultra | -tti* | \\\n+\t-harris | -dolphin | -highlevel | -gould | -cbm | -ns | -masscomp | \\\n+\t-apple | -axis | -knuth | -cray | -microblaze)\n+\t\tos=\n+\t\tbasic_machine=$1\n+\t\t;;\n+\t-bluegene*)\n+\t\tos=-cnk\n+\t\t;;\n+\t-sim | -cisco | -oki | -wec | -winbond)\n+\t\tos=\n+\t\tbasic_machine=$1\n+\t\t;;\n+\t-scout)\n+\t\t;;\n+\t-wrs)\n+\t\tos=-vxworks\n+\t\tbasic_machine=$1\n+\t\t;;\n+\t-chorusos*)\n+\t\tos=-chorusos\n+\t\tbasic_machine=$1\n+\t\t;;\n+\t-chorusrdb)\n+\t\tos=-chorusrdb\n+\t\tbasic_machine=$1\n+\t\t;;\n+\t-hiux*)\n+\t\tos=-hiuxwe2\n+\t\t;;\n+\t-sco6)\n+\t\tos=-sco5v6\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-sco5)\n+\t\tos=-sco3.2v5\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-sco4)\n+\t\tos=-sco3.2v4\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-sco3.2.[4-9]*)\n+\t\tos=`echo $os | sed -e 's/sco3.2./sco3.2v/'`\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-sco3.2v[4-9]*)\n+\t\t# Don't forget version if it is 3.2v4 or newer.\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-sco5v6*)\n+\t\t# Don't forget version if it is 3.2v4 or newer.\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-sco*)\n+\t\tos=-sco3.2v2\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-udk*)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-isc)\n+\t\tos=-isc2.2\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-clix*)\n+\t\tbasic_machine=clipper-intergraph\n+\t\t;;\n+\t-isc*)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-pc/'`\n+\t\t;;\n+\t-lynx*)\n+\t\tos=-lynxos\n+\t\t;;\n+\t-ptx*)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86-.*/86-sequent/'`\n+\t\t;;\n+\t-windowsnt*)\n+\t\tos=`echo $os | sed -e 's/windowsnt/winnt/'`\n+\t\t;;\n+\t-psos*)\n+\t\tos=-psos\n+\t\t;;\n+\t-mint | -mint[0-9]*)\n+\t\tbasic_machine=m68k-atari\n+\t\tos=-mint\n+\t\t;;\n+esac\n+\n+# Decode aliases for certain CPU-COMPANY combinations.\n+case $basic_machine in\n+\t# Recognize the basic CPU types without company name.\n+\t# Some are omitted here because they have special meanings below.\n+\t1750a | 580 \\\n+\t| a29k \\\n+\t| aarch64 | aarch64_be \\\n+\t| alpha | alphaev[4-8] | alphaev56 | alphaev6[78] | alphapca5[67] \\\n+\t| alpha64 | alpha64ev[4-8] | alpha64ev56 | alpha64ev6[78] | alpha64pca5[67] \\\n+\t| am33_2.0 \\\n+\t| arc | arm | arm[bl]e | arme[lb] | armv[2345] | armv[345][lb] | avr | avr32 \\\n+        | be32 | be64 \\\n+\t| bfin \\\n+\t| c4x | clipper \\\n+\t| d10v | d30v | dlx | dsp16xx \\\n+\t| epiphany \\\n+\t| fido | fr30 | frv \\\n+\t| h8300 | h8500 | hppa | hppa1.[01] | hppa2.0 | hppa2.0[nw] | hppa64 \\\n+\t| hexagon \\\n+\t| i370 | i860 | i960 | ia64 \\\n+\t| ip2k | iq2000 \\\n+\t| le32 | le64 \\\n+\t| lm32 \\\n+\t| m32c | m32r | m32rle | m68000 | m68k | m88k \\\n+\t| maxq | mb | microblaze | mcore | mep | metag \\\n+\t| mips | mipsbe | mipseb | mipsel | mipsle \\\n+\t| mips16 \\\n+\t| mips64 | mips64el \\\n+\t| mips64octeon | mips64octeonel \\\n+\t| mips64orion | mips64orionel \\\n+\t| mips64r5900 | mips64r5900el \\\n+\t| mips64vr | mips64vrel \\\n+\t| mips64vr4100 | mips64vr4100el \\\n+\t| mips64vr4300 | mips64vr4300el \\\n+\t| mips64vr5000 | mips64vr5000el \\\n+\t| mips64vr5900 | mips64vr5900el \\\n+\t| mipsisa32 | mipsisa32el \\\n+\t| mipsisa32r2 | mipsisa32r2el \\\n+\t| mipsisa64 | mipsisa64el \\\n+\t| mipsisa64r2 | mipsisa64r2el \\\n+\t| mipsisa64sb1 | mipsisa64sb1el \\\n+\t| mipsisa64sr71k | mipsisa64sr71kel \\\n+\t| mipstx39 | mipstx39el \\\n+\t| mn10200 | mn10300 \\\n+\t| moxie \\\n+\t| mt \\\n+\t| msp430 \\\n+\t| nds32 | nds32le | nds32be \\\n+\t| nios | nios2 \\\n+\t| ns16k | ns32k \\\n+\t| open8 \\\n+\t| or32 \\\n+\t| pdp10 | pdp11 | pj | pjl \\\n+\t| powerpc | powerpc64 | powerpc64le | powerpcle \\\n+\t| pyramid \\\n+\t| rl78 | rx \\\n+\t| score \\\n+\t| sh | sh[1234] | sh[24]a | sh[24]aeb | sh[23]e | sh[34]eb | sheb | shbe | shle | sh[1234]le | sh3ele \\\n+\t| sh64 | sh64le \\\n+\t| sparc | sparc64 | sparc64b | sparc64v | sparc86x | sparclet | sparclite \\\n+\t| sparcv8 | sparcv9 | sparcv9b | sparcv9v \\\n+\t| spu \\\n+\t| tahoe | tic4x | tic54x | tic55x | tic6x | tic80 | tron \\\n+\t| ubicom32 \\\n+\t| v850 | v850e | v850e1 | v850e2 | v850es | v850e2v3 \\\n+\t| we32k \\\n+\t| x86 | xc16x | xstormy16 | xtensa \\\n+\t| z8k | z80)\n+\t\tbasic_machine=$basic_machine-unknown\n+\t\t;;\n+\tc54x)\n+\t\tbasic_machine=tic54x-unknown\n+\t\t;;\n+\tc55x)\n+\t\tbasic_machine=tic55x-unknown\n+\t\t;;\n+\tc6x)\n+\t\tbasic_machine=tic6x-unknown\n+\t\t;;\n+\tm6811 | m68hc11 | m6812 | m68hc12 | m68hcs12x | picochip)\n+\t\tbasic_machine=$basic_machine-unknown\n+\t\tos=-none\n+\t\t;;\n+\tm88110 | m680[12346]0 | m683?2 | m68360 | m5200 | v70 | w65 | z8k)\n+\t\t;;\n+\tms1)\n+\t\tbasic_machine=mt-unknown\n+\t\t;;\n+\n+\tstrongarm | thumb | xscale)\n+\t\tbasic_machine=arm-unknown\n+\t\t;;\n+\txgate)\n+\t\tbasic_machine=$basic_machine-unknown\n+\t\tos=-none\n+\t\t;;\n+\txscaleeb)\n+\t\tbasic_machine=armeb-unknown\n+\t\t;;\n+\n+\txscaleel)\n+\t\tbasic_machine=armel-unknown\n+\t\t;;\n+\n+\t# We use `pc' rather than `unknown'\n+\t# because (1) that's what they normally are, and\n+\t# (2) the word \"unknown\" tends to confuse beginning users.\n+\ti*86 | x86_64)\n+\t  basic_machine=$basic_machine-pc\n+\t  ;;\n+\t# Object if more than one company name word.\n+\t*-*-*)\n+\t\techo Invalid configuration \\`$1\\': machine \\`$basic_machine\\' not recognized 1>&2\n+\t\texit 1\n+\t\t;;\n+\t# Recognize the basic CPU types with company name.\n+\t580-* \\\n+\t| a29k-* \\\n+\t| aarch64-* | aarch64_be-* \\\n+\t| alpha-* | alphaev[4-8]-* | alphaev56-* | alphaev6[78]-* \\\n+\t| alpha64-* | alpha64ev[4-8]-* | alpha64ev56-* | alpha64ev6[78]-* \\\n+\t| alphapca5[67]-* | alpha64pca5[67]-* | arc-* \\\n+\t| arm-*  | armbe-* | armle-* | armeb-* | armv*-* \\\n+\t| avr-* | avr32-* \\\n+\t| be32-* | be64-* \\\n+\t| bfin-* | bs2000-* \\\n+\t| c[123]* | c30-* | [cjt]90-* | c4x-* \\\n+\t| clipper-* | craynv-* | cydra-* \\\n+\t| d10v-* | d30v-* | dlx-* \\\n+\t| elxsi-* \\\n+\t| f30[01]-* | f700-* | fido-* | fr30-* | frv-* | fx80-* \\\n+\t| h8300-* | h8500-* \\\n+\t| hppa-* | hppa1.[01]-* | hppa2.0-* | hppa2.0[nw]-* | hppa64-* \\\n+\t| hexagon-* \\\n+\t| i*86-* | i860-* | i960-* | ia64-* \\\n+\t| ip2k-* | iq2000-* \\\n+\t| le32-* | le64-* \\\n+\t| lm32-* \\\n+\t| m32c-* | m32r-* | m32rle-* \\\n+\t| m68000-* | m680[012346]0-* | m68360-* | m683?2-* | m68k-* \\\n+\t| m88110-* | m88k-* | maxq-* | mcore-* | metag-* | microblaze-* \\\n+\t| mips-* | mipsbe-* | mipseb-* | mipsel-* | mipsle-* \\\n+\t| mips16-* \\\n+\t| mips64-* | mips64el-* \\\n+\t| mips64octeon-* | mips64octeonel-* \\\n+\t| mips64orion-* | mips64orionel-* \\\n+\t| mips64r5900-* | mips64r5900el-* \\\n+\t| mips64vr-* | mips64vrel-* \\\n+\t| mips64vr4100-* | mips64vr4100el-* \\\n+\t| mips64vr4300-* | mips64vr4300el-* \\\n+\t| mips64vr5000-* | mips64vr5000el-* \\\n+\t| mips64vr5900-* | mips64vr5900el-* \\\n+\t| mipsisa32-* | mipsisa32el-* \\\n+\t| mipsisa32r2-* | mipsisa32r2el-* \\\n+\t| mipsisa64-* | mipsisa64el-* \\\n+\t| mipsisa64r2-* | mipsisa64r2el-* \\\n+\t| mipsisa64sb1-* | mipsisa64sb1el-* \\\n+\t| mipsisa64sr71k-* | mipsisa64sr71kel-* \\\n+\t| mipstx39-* | mipstx39el-* \\\n+\t| mmix-* \\\n+\t| mt-* \\\n+\t| msp430-* \\\n+\t| nds32-* | nds32le-* | nds32be-* \\\n+\t| nios-* | nios2-* \\\n+\t| none-* | np1-* | ns16k-* | ns32k-* \\\n+\t| open8-* \\\n+\t| orion-* \\\n+\t| pdp10-* | pdp11-* | pj-* | pjl-* | pn-* | power-* \\\n+\t| powerpc-* | powerpc64-* | powerpc64le-* | powerpcle-* \\\n+\t| pyramid-* \\\n+\t| rl78-* | romp-* | rs6000-* | rx-* \\\n+\t| sh-* | sh[1234]-* | sh[24]a-* | sh[24]aeb-* | sh[23]e-* | sh[34]eb-* | sheb-* | shbe-* \\\n+\t| shle-* | sh[1234]le-* | sh3ele-* | sh64-* | sh64le-* \\\n+\t| sparc-* | sparc64-* | sparc64b-* | sparc64v-* | sparc86x-* | sparclet-* \\\n+\t| sparclite-* \\\n+\t| sparcv8-* | sparcv9-* | sparcv9b-* | sparcv9v-* | sv1-* | sx?-* \\\n+\t| tahoe-* \\\n+\t| tic30-* | tic4x-* | tic54x-* | tic55x-* | tic6x-* | tic80-* \\\n+\t| tile*-* \\\n+\t| tron-* \\\n+\t| ubicom32-* \\\n+\t| v850-* | v850e-* | v850e1-* | v850es-* | v850e2-* | v850e2v3-* \\\n+\t| vax-* \\\n+\t| we32k-* \\\n+\t| x86-* | x86_64-* | xc16x-* | xps100-* \\\n+\t| xstormy16-* | xtensa*-* \\\n+\t| ymp-* \\\n+\t| z8k-* | z80-*)\n+\t\t;;\n+\t# Recognize the basic CPU types without company name, with glob match.\n+\txtensa*)\n+\t\tbasic_machine=$basic_machine-unknown\n+\t\t;;\n+\t# Recognize the various machine names and aliases which stand\n+\t# for a CPU type and a company and sometimes even an OS.\n+\t386bsd)\n+\t\tbasic_machine=i386-unknown\n+\t\tos=-bsd\n+\t\t;;\n+\t3b1 | 7300 | 7300-att | att-7300 | pc7300 | safari | unixpc)\n+\t\tbasic_machine=m68000-att\n+\t\t;;\n+\t3b*)\n+\t\tbasic_machine=we32k-att\n+\t\t;;\n+\ta29khif)\n+\t\tbasic_machine=a29k-amd\n+\t\tos=-udi\n+\t\t;;\n+\tabacus)\n+\t\tbasic_machine=abacus-unknown\n+\t\t;;\n+\tadobe68k)\n+\t\tbasic_machine=m68010-adobe\n+\t\tos=-scout\n+\t\t;;\n+\talliant | fx80)\n+\t\tbasic_machine=fx80-alliant\n+\t\t;;\n+\taltos | altos3068)\n+\t\tbasic_machine=m68k-altos\n+\t\t;;\n+\tam29k)\n+\t\tbasic_machine=a29k-none\n+\t\tos=-bsd\n+\t\t;;\n+\tamd64)\n+\t\tbasic_machine=x86_64-pc\n+\t\t;;\n+\tamd64-*)\n+\t\tbasic_machine=x86_64-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tamdahl)\n+\t\tbasic_machine=580-amdahl\n+\t\tos=-sysv\n+\t\t;;\n+\tamiga | amiga-*)\n+\t\tbasic_machine=m68k-unknown\n+\t\t;;\n+\tamigaos | amigados)\n+\t\tbasic_machine=m68k-unknown\n+\t\tos=-amigaos\n+\t\t;;\n+\tamigaunix | amix)\n+\t\tbasic_machine=m68k-unknown\n+\t\tos=-sysv4\n+\t\t;;\n+\tapollo68)\n+\t\tbasic_machine=m68k-apollo\n+\t\tos=-sysv\n+\t\t;;\n+\tapollo68bsd)\n+\t\tbasic_machine=m68k-apollo\n+\t\tos=-bsd\n+\t\t;;\n+\taros)\n+\t\tbasic_machine=i386-pc\n+\t\tos=-aros\n+\t\t;;\n+\taux)\n+\t\tbasic_machine=m68k-apple\n+\t\tos=-aux\n+\t\t;;\n+\tbalance)\n+\t\tbasic_machine=ns32k-sequent\n+\t\tos=-dynix\n+\t\t;;\n+\tblackfin)\n+\t\tbasic_machine=bfin-unknown\n+\t\tos=-linux\n+\t\t;;\n+\tblackfin-*)\n+\t\tbasic_machine=bfin-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\tos=-linux\n+\t\t;;\n+\tbluegene*)\n+\t\tbasic_machine=powerpc-ibm\n+\t\tos=-cnk\n+\t\t;;\n+\tc54x-*)\n+\t\tbasic_machine=tic54x-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tc55x-*)\n+\t\tbasic_machine=tic55x-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tc6x-*)\n+\t\tbasic_machine=tic6x-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tc90)\n+\t\tbasic_machine=c90-cray\n+\t\tos=-unicos\n+\t\t;;\n+\tcegcc)\n+\t\tbasic_machine=arm-unknown\n+\t\tos=-cegcc\n+\t\t;;\n+\tconvex-c1)\n+\t\tbasic_machine=c1-convex\n+\t\tos=-bsd\n+\t\t;;\n+\tconvex-c2)\n+\t\tbasic_machine=c2-convex\n+\t\tos=-bsd\n+\t\t;;\n+\tconvex-c32)\n+\t\tbasic_machine=c32-convex\n+\t\tos=-bsd\n+\t\t;;\n+\tconvex-c34)\n+\t\tbasic_machine=c34-convex\n+\t\tos=-bsd\n+\t\t;;\n+\tconvex-c38)\n+\t\tbasic_machine=c38-convex\n+\t\tos=-bsd\n+\t\t;;\n+\tcray | j90)\n+\t\tbasic_machine=j90-cray\n+\t\tos=-unicos\n+\t\t;;\n+\tcraynv)\n+\t\tbasic_machine=craynv-cray\n+\t\tos=-unicosmp\n+\t\t;;\n+\tcr16 | cr16-*)\n+\t\tbasic_machine=cr16-unknown\n+\t\tos=-elf\n+\t\t;;\n+\tcrds | unos)\n+\t\tbasic_machine=m68k-crds\n+\t\t;;\n+\tcrisv32 | crisv32-* | etraxfs*)\n+\t\tbasic_machine=crisv32-axis\n+\t\t;;\n+\tcris | cris-* | etrax*)\n+\t\tbasic_machine=cris-axis\n+\t\t;;\n+\tcrx)\n+\t\tbasic_machine=crx-unknown\n+\t\tos=-elf\n+\t\t;;\n+\tda30 | da30-*)\n+\t\tbasic_machine=m68k-da30\n+\t\t;;\n+\tdecstation | decstation-3100 | pmax | pmax-* | pmin | dec3100 | decstatn)\n+\t\tbasic_machine=mips-dec\n+\t\t;;\n+\tdecsystem10* | dec10*)\n+\t\tbasic_machine=pdp10-dec\n+\t\tos=-tops10\n+\t\t;;\n+\tdecsystem20* | dec20*)\n+\t\tbasic_machine=pdp10-dec\n+\t\tos=-tops20\n+\t\t;;\n+\tdelta | 3300 | motorola-3300 | motorola-delta \\\n+\t      | 3300-motorola | delta-motorola)\n+\t\tbasic_machine=m68k-motorola\n+\t\t;;\n+\tdelta88)\n+\t\tbasic_machine=m88k-motorola\n+\t\tos=-sysv3\n+\t\t;;\n+\tdicos)\n+\t\tbasic_machine=i686-pc\n+\t\tos=-dicos\n+\t\t;;\n+\tdjgpp)\n+\t\tbasic_machine=i586-pc\n+\t\tos=-msdosdjgpp\n+\t\t;;\n+\tdpx20 | dpx20-*)\n+\t\tbasic_machine=rs6000-bull\n+\t\tos=-bosx\n+\t\t;;\n+\tdpx2* | dpx2*-bull)\n+\t\tbasic_machine=m68k-bull\n+\t\tos=-sysv3\n+\t\t;;\n+\tebmon29k)\n+\t\tbasic_machine=a29k-amd\n+\t\tos=-ebmon\n+\t\t;;\n+\telxsi)\n+\t\tbasic_machine=elxsi-elxsi\n+\t\tos=-bsd\n+\t\t;;\n+\tencore | umax | mmax)\n+\t\tbasic_machine=ns32k-encore\n+\t\t;;\n+\tes1800 | OSE68k | ose68k | ose | OSE)\n+\t\tbasic_machine=m68k-ericsson\n+\t\tos=-ose\n+\t\t;;\n+\tfx2800)\n+\t\tbasic_machine=i860-alliant\n+\t\t;;\n+\tgenix)\n+\t\tbasic_machine=ns32k-ns\n+\t\t;;\n+\tgmicro)\n+\t\tbasic_machine=tron-gmicro\n+\t\tos=-sysv\n+\t\t;;\n+\tgo32)\n+\t\tbasic_machine=i386-pc\n+\t\tos=-go32\n+\t\t;;\n+\th3050r* | hiux*)\n+\t\tbasic_machine=hppa1.1-hitachi\n+\t\tos=-hiuxwe2\n+\t\t;;\n+\th8300hms)\n+\t\tbasic_machine=h8300-hitachi\n+\t\tos=-hms\n+\t\t;;\n+\th8300xray)\n+\t\tbasic_machine=h8300-hitachi\n+\t\tos=-xray\n+\t\t;;\n+\th8500hms)\n+\t\tbasic_machine=h8500-hitachi\n+\t\tos=-hms\n+\t\t;;\n+\tharris)\n+\t\tbasic_machine=m88k-harris\n+\t\tos=-sysv3\n+\t\t;;\n+\thp300-*)\n+\t\tbasic_machine=m68k-hp\n+\t\t;;\n+\thp300bsd)\n+\t\tbasic_machine=m68k-hp\n+\t\tos=-bsd\n+\t\t;;\n+\thp300hpux)\n+\t\tbasic_machine=m68k-hp\n+\t\tos=-hpux\n+\t\t;;\n+\thp3k9[0-9][0-9] | hp9[0-9][0-9])\n+\t\tbasic_machine=hppa1.0-hp\n+\t\t;;\n+\thp9k2[0-9][0-9] | hp9k31[0-9])\n+\t\tbasic_machine=m68000-hp\n+\t\t;;\n+\thp9k3[2-9][0-9])\n+\t\tbasic_machine=m68k-hp\n+\t\t;;\n+\thp9k6[0-9][0-9] | hp6[0-9][0-9])\n+\t\tbasic_machine=hppa1.0-hp\n+\t\t;;\n+\thp9k7[0-79][0-9] | hp7[0-79][0-9])\n+\t\tbasic_machine=hppa1.1-hp\n+\t\t;;\n+\thp9k78[0-9] | hp78[0-9])\n+\t\t# FIXME: really hppa2.0-hp\n+\t\tbasic_machine=hppa1.1-hp\n+\t\t;;\n+\thp9k8[67]1 | hp8[67]1 | hp9k80[24] | hp80[24] | hp9k8[78]9 | hp8[78]9 | hp9k893 | hp893)\n+\t\t# FIXME: really hppa2.0-hp\n+\t\tbasic_machine=hppa1.1-hp\n+\t\t;;\n+\thp9k8[0-9][13679] | hp8[0-9][13679])\n+\t\tbasic_machine=hppa1.1-hp\n+\t\t;;\n+\thp9k8[0-9][0-9] | hp8[0-9][0-9])\n+\t\tbasic_machine=hppa1.0-hp\n+\t\t;;\n+\thppa-next)\n+\t\tos=-nextstep3\n+\t\t;;\n+\thppaosf)\n+\t\tbasic_machine=hppa1.1-hp\n+\t\tos=-osf\n+\t\t;;\n+\thppro)\n+\t\tbasic_machine=hppa1.1-hp\n+\t\tos=-proelf\n+\t\t;;\n+\ti370-ibm* | ibm*)\n+\t\tbasic_machine=i370-ibm\n+\t\t;;\n+\ti*86v32)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86.*/86-pc/'`\n+\t\tos=-sysv32\n+\t\t;;\n+\ti*86v4*)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86.*/86-pc/'`\n+\t\tos=-sysv4\n+\t\t;;\n+\ti*86v)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86.*/86-pc/'`\n+\t\tos=-sysv\n+\t\t;;\n+\ti*86sol2)\n+\t\tbasic_machine=`echo $1 | sed -e 's/86.*/86-pc/'`\n+\t\tos=-solaris2\n+\t\t;;\n+\ti386mach)\n+\t\tbasic_machine=i386-mach\n+\t\tos=-mach\n+\t\t;;\n+\ti386-vsta | vsta)\n+\t\tbasic_machine=i386-unknown\n+\t\tos=-vsta\n+\t\t;;\n+\tiris | iris4d)\n+\t\tbasic_machine=mips-sgi\n+\t\tcase $os in\n+\t\t    -irix*)\n+\t\t\t;;\n+\t\t    *)\n+\t\t\tos=-irix4\n+\t\t\t;;\n+\t\tesac\n+\t\t;;\n+\tisi68 | isi)\n+\t\tbasic_machine=m68k-isi\n+\t\tos=-sysv\n+\t\t;;\n+\tm68knommu)\n+\t\tbasic_machine=m68k-unknown\n+\t\tos=-linux\n+\t\t;;\n+\tm68knommu-*)\n+\t\tbasic_machine=m68k-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\tos=-linux\n+\t\t;;\n+\tm88k-omron*)\n+\t\tbasic_machine=m88k-omron\n+\t\t;;\n+\tmagnum | m3230)\n+\t\tbasic_machine=mips-mips\n+\t\tos=-sysv\n+\t\t;;\n+\tmerlin)\n+\t\tbasic_machine=ns32k-utek\n+\t\tos=-sysv\n+\t\t;;\n+\tmicroblaze)\n+\t\tbasic_machine=microblaze-xilinx\n+\t\t;;\n+\tmingw32)\n+\t\tbasic_machine=i386-pc\n+\t\tos=-mingw32\n+\t\t;;\n+\tmingw32ce)\n+\t\tbasic_machine=arm-unknown\n+\t\tos=-mingw32ce\n+\t\t;;\n+\tminiframe)\n+\t\tbasic_machine=m68000-convergent\n+\t\t;;\n+\t*mint | -mint[0-9]* | *MiNT | *MiNT[0-9]*)\n+\t\tbasic_machine=m68k-atari\n+\t\tos=-mint\n+\t\t;;\n+\tmips3*-*)\n+\t\tbasic_machine=`echo $basic_machine | sed -e 's/mips3/mips64/'`\n+\t\t;;\n+\tmips3*)\n+\t\tbasic_machine=`echo $basic_machine | sed -e 's/mips3/mips64/'`-unknown\n+\t\t;;\n+\tmonitor)\n+\t\tbasic_machine=m68k-rom68k\n+\t\tos=-coff\n+\t\t;;\n+\tmorphos)\n+\t\tbasic_machine=powerpc-unknown\n+\t\tos=-morphos\n+\t\t;;\n+\tmsdos)\n+\t\tbasic_machine=i386-pc\n+\t\tos=-msdos\n+\t\t;;\n+\tms1-*)\n+\t\tbasic_machine=`echo $basic_machine | sed -e 's/ms1-/mt-/'`\n+\t\t;;\n+\tmsys)\n+\t\tbasic_machine=i386-pc\n+\t\tos=-msys\n+\t\t;;\n+\tmvs)\n+\t\tbasic_machine=i370-ibm\n+\t\tos=-mvs\n+\t\t;;\n+\tnacl)\n+\t\tbasic_machine=le32-unknown\n+\t\tos=-nacl\n+\t\t;;\n+\tncr3000)\n+\t\tbasic_machine=i486-ncr\n+\t\tos=-sysv4\n+\t\t;;\n+\tnetbsd386)\n+\t\tbasic_machine=i386-unknown\n+\t\tos=-netbsd\n+\t\t;;\n+\tnetwinder)\n+\t\tbasic_machine=armv4l-rebel\n+\t\tos=-linux\n+\t\t;;\n+\tnews | news700 | news800 | news900)\n+\t\tbasic_machine=m68k-sony\n+\t\tos=-newsos\n+\t\t;;\n+\tnews1000)\n+\t\tbasic_machine=m68030-sony\n+\t\tos=-newsos\n+\t\t;;\n+\tnews-3600 | risc-news)\n+\t\tbasic_machine=mips-sony\n+\t\tos=-newsos\n+\t\t;;\n+\tnecv70)\n+\t\tbasic_machine=v70-nec\n+\t\tos=-sysv\n+\t\t;;\n+\tnext | m*-next )\n+\t\tbasic_machine=m68k-next\n+\t\tcase $os in\n+\t\t    -nextstep* )\n+\t\t\t;;\n+\t\t    -ns2*)\n+\t\t      os=-nextstep2\n+\t\t\t;;\n+\t\t    *)\n+\t\t      os=-nextstep3\n+\t\t\t;;\n+\t\tesac\n+\t\t;;\n+\tnh3000)\n+\t\tbasic_machine=m68k-harris\n+\t\tos=-cxux\n+\t\t;;\n+\tnh[45]000)\n+\t\tbasic_machine=m88k-harris\n+\t\tos=-cxux\n+\t\t;;\n+\tnindy960)\n+\t\tbasic_machine=i960-intel\n+\t\tos=-nindy\n+\t\t;;\n+\tmon960)\n+\t\tbasic_machine=i960-intel\n+\t\tos=-mon960\n+\t\t;;\n+\tnonstopux)\n+\t\tbasic_machine=mips-compaq\n+\t\tos=-nonstopux\n+\t\t;;\n+\tnp1)\n+\t\tbasic_machine=np1-gould\n+\t\t;;\n+\tneo-tandem)\n+\t\tbasic_machine=neo-tandem\n+\t\t;;\n+\tnse-tandem)\n+\t\tbasic_machine=nse-tandem\n+\t\t;;\n+\tnsr-tandem)\n+\t\tbasic_machine=nsr-tandem\n+\t\t;;\n+\top50n-* | op60c-*)\n+\t\tbasic_machine=hppa1.1-oki\n+\t\tos=-proelf\n+\t\t;;\n+\topenrisc | openrisc-*)\n+\t\tbasic_machine=or32-unknown\n+\t\t;;\n+\tos400)\n+\t\tbasic_machine=powerpc-ibm\n+\t\tos=-os400\n+\t\t;;\n+\tOSE68000 | ose68000)\n+\t\tbasic_machine=m68000-ericsson\n+\t\tos=-ose\n+\t\t;;\n+\tos68k)\n+\t\tbasic_machine=m68k-none\n+\t\tos=-os68k\n+\t\t;;\n+\tpa-hitachi)\n+\t\tbasic_machine=hppa1.1-hitachi\n+\t\tos=-hiuxwe2\n+\t\t;;\n+\tparagon)\n+\t\tbasic_machine=i860-intel\n+\t\tos=-osf\n+\t\t;;\n+\tparisc)\n+\t\tbasic_machine=hppa-unknown\n+\t\tos=-linux\n+\t\t;;\n+\tparisc-*)\n+\t\tbasic_machine=hppa-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\tos=-linux\n+\t\t;;\n+\tpbd)\n+\t\tbasic_machine=sparc-tti\n+\t\t;;\n+\tpbb)\n+\t\tbasic_machine=m68k-tti\n+\t\t;;\n+\tpc532 | pc532-*)\n+\t\tbasic_machine=ns32k-pc532\n+\t\t;;\n+\tpc98)\n+\t\tbasic_machine=i386-pc\n+\t\t;;\n+\tpc98-*)\n+\t\tbasic_machine=i386-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tpentium | p5 | k5 | k6 | nexgen | viac3)\n+\t\tbasic_machine=i586-pc\n+\t\t;;\n+\tpentiumpro | p6 | 6x86 | athlon | athlon_*)\n+\t\tbasic_machine=i686-pc\n+\t\t;;\n+\tpentiumii | pentium2 | pentiumiii | pentium3)\n+\t\tbasic_machine=i686-pc\n+\t\t;;\n+\tpentium4)\n+\t\tbasic_machine=i786-pc\n+\t\t;;\n+\tpentium-* | p5-* | k5-* | k6-* | nexgen-* | viac3-*)\n+\t\tbasic_machine=i586-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tpentiumpro-* | p6-* | 6x86-* | athlon-*)\n+\t\tbasic_machine=i686-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tpentiumii-* | pentium2-* | pentiumiii-* | pentium3-*)\n+\t\tbasic_machine=i686-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tpentium4-*)\n+\t\tbasic_machine=i786-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tpn)\n+\t\tbasic_machine=pn-gould\n+\t\t;;\n+\tpower)\tbasic_machine=power-ibm\n+\t\t;;\n+\tppc | ppcbe)\tbasic_machine=powerpc-unknown\n+\t\t;;\n+\tppc-* | ppcbe-*)\n+\t\tbasic_machine=powerpc-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tppcle | powerpclittle | ppc-le | powerpc-little)\n+\t\tbasic_machine=powerpcle-unknown\n+\t\t;;\n+\tppcle-* | powerpclittle-*)\n+\t\tbasic_machine=powerpcle-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tppc64)\tbasic_machine=powerpc64-unknown\n+\t\t;;\n+\tppc64-*) basic_machine=powerpc64-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tppc64le | powerpc64little | ppc64-le | powerpc64-little)\n+\t\tbasic_machine=powerpc64le-unknown\n+\t\t;;\n+\tppc64le-* | powerpc64little-*)\n+\t\tbasic_machine=powerpc64le-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tps2)\n+\t\tbasic_machine=i386-ibm\n+\t\t;;\n+\tpw32)\n+\t\tbasic_machine=i586-unknown\n+\t\tos=-pw32\n+\t\t;;\n+\trdos)\n+\t\tbasic_machine=i386-pc\n+\t\tos=-rdos\n+\t\t;;\n+\trom68k)\n+\t\tbasic_machine=m68k-rom68k\n+\t\tos=-coff\n+\t\t;;\n+\trm[46]00)\n+\t\tbasic_machine=mips-siemens\n+\t\t;;\n+\trtpc | rtpc-*)\n+\t\tbasic_machine=romp-ibm\n+\t\t;;\n+\ts390 | s390-*)\n+\t\tbasic_machine=s390-ibm\n+\t\t;;\n+\ts390x | s390x-*)\n+\t\tbasic_machine=s390x-ibm\n+\t\t;;\n+\tsa29200)\n+\t\tbasic_machine=a29k-amd\n+\t\tos=-udi\n+\t\t;;\n+\tsb1)\n+\t\tbasic_machine=mipsisa64sb1-unknown\n+\t\t;;\n+\tsb1el)\n+\t\tbasic_machine=mipsisa64sb1el-unknown\n+\t\t;;\n+\tsde)\n+\t\tbasic_machine=mipsisa32-sde\n+\t\tos=-elf\n+\t\t;;\n+\tsei)\n+\t\tbasic_machine=mips-sei\n+\t\tos=-seiux\n+\t\t;;\n+\tsequent)\n+\t\tbasic_machine=i386-sequent\n+\t\t;;\n+\tsh)\n+\t\tbasic_machine=sh-hitachi\n+\t\tos=-hms\n+\t\t;;\n+\tsh5el)\n+\t\tbasic_machine=sh5le-unknown\n+\t\t;;\n+\tsh64)\n+\t\tbasic_machine=sh64-unknown\n+\t\t;;\n+\tsparclite-wrs | simso-wrs)\n+\t\tbasic_machine=sparclite-wrs\n+\t\tos=-vxworks\n+\t\t;;\n+\tsps7)\n+\t\tbasic_machine=m68k-bull\n+\t\tos=-sysv2\n+\t\t;;\n+\tspur)\n+\t\tbasic_machine=spur-unknown\n+\t\t;;\n+\tst2000)\n+\t\tbasic_machine=m68k-tandem\n+\t\t;;\n+\tstratus)\n+\t\tbasic_machine=i860-stratus\n+\t\tos=-sysv4\n+\t\t;;\n+\tstrongarm-* | thumb-*)\n+\t\tbasic_machine=arm-`echo $basic_machine | sed 's/^[^-]*-//'`\n+\t\t;;\n+\tsun2)\n+\t\tbasic_machine=m68000-sun\n+\t\t;;\n+\tsun2os3)\n+\t\tbasic_machine=m68000-sun\n+\t\tos=-sunos3\n+\t\t;;\n+\tsun2os4)\n+\t\tbasic_machine=m68000-sun\n+\t\tos=-sunos4\n+\t\t;;\n+\tsun3os3)\n+\t\tbasic_machine=m68k-sun\n+\t\tos=-sunos3\n+\t\t;;\n+\tsun3os4)\n+\t\tbasic_machine=m68k-sun\n+\t\tos=-sunos4\n+\t\t;;\n+\tsun4os3)\n+\t\tbasic_machine=sparc-sun\n+\t\tos=-sunos3\n+\t\t;;\n+\tsun4os4)\n+\t\tbasic_machine=sparc-sun\n+\t\tos=-sunos4\n+\t\t;;\n+\tsun4sol2)\n+\t\tbasic_machine=sparc-sun\n+\t\tos=-solaris2\n+\t\t;;\n+\tsun3 | sun3-*)\n+\t\tbasic_machine=m68k-sun\n+\t\t;;\n+\tsun4)\n+\t\tbasic_machine=sparc-sun\n+\t\t;;\n+\tsun386 | sun386i | roadrunner)\n+\t\tbasic_machine=i386-sun\n+\t\t;;\n+\tsv1)\n+\t\tbasic_machine=sv1-cray\n+\t\tos=-unicos\n+\t\t;;\n+\tsymmetry)\n+\t\tbasic_machine=i386-sequent\n+\t\tos=-dynix\n+\t\t;;\n+\tt3e)\n+\t\tbasic_machine=alphaev5-cray\n+\t\tos=-unicos\n+\t\t;;\n+\tt90)\n+\t\tbasic_machine=t90-cray\n+\t\tos=-unicos\n+\t\t;;\n+\ttile*)\n+\t\tbasic_machine=$basic_machine-unknown\n+\t\tos=-linux-gnu\n+\t\t;;\n+\ttx39)\n+\t\tbasic_machine=mipstx39-unknown\n+\t\t;;\n+\ttx39el)\n+\t\tbasic_machine=mipstx39el-unknown\n+\t\t;;\n+\ttoad1)\n+\t\tbasic_machine=pdp10-xkl\n+\t\tos=-tops20\n+\t\t;;\n+\ttower | tower-32)\n+\t\tbasic_machine=m68k-ncr\n+\t\t;;\n+\ttpf)\n+\t\tbasic_machine=s390x-ibm\n+\t\tos=-tpf\n+\t\t;;\n+\tudi29k)\n+\t\tbasic_machine=a29k-amd\n+\t\tos=-udi\n+\t\t;;\n+\tultra3)\n+\t\tbasic_machine=a29k-nyu\n+\t\tos=-sym1\n+\t\t;;\n+\tv810 | necv810)\n+\t\tbasic_machine=v810-nec\n+\t\tos=-none\n+\t\t;;\n+\tvaxv)\n+\t\tbasic_machine=vax-dec\n+\t\tos=-sysv\n+\t\t;;\n+\tvms)\n+\t\tbasic_machine=vax-dec\n+\t\tos=-vms\n+\t\t;;\n+\tvpp*|vx|vx-*)\n+\t\tbasic_machine=f301-fujitsu\n+\t\t;;\n+\tvxworks960)\n+\t\tbasic_machine=i960-wrs\n+\t\tos=-vxworks\n+\t\t;;\n+\tvxworks68)\n+\t\tbasic_machine=m68k-wrs\n+\t\tos=-vxworks\n+\t\t;;\n+\tvxworks29k)\n+\t\tbasic_machine=a29k-wrs\n+\t\tos=-vxworks\n+\t\t;;\n+\tw65*)\n+\t\tbasic_machine=w65-wdc\n+\t\tos=-none\n+\t\t;;\n+\tw89k-*)\n+\t\tbasic_machine=hppa1.1-winbond\n+\t\tos=-proelf\n+\t\t;;\n+\txbox)\n+\t\tbasic_machine=i686-pc\n+\t\tos=-mingw32\n+\t\t;;\n+\txps | xps100)\n+\t\tbasic_machine=xps100-honeywell\n+\t\t;;\n+\txscale-* | xscalee[bl]-*)\n+\t\tbasic_machine=`echo $basic_machine | sed 's/^xscale/arm/'`\n+\t\t;;\n+\tymp)\n+\t\tbasic_machine=ymp-cray\n+\t\tos=-unicos\n+\t\t;;\n+\tz8k-*-coff)\n+\t\tbasic_machine=z8k-unknown\n+\t\tos=-sim\n+\t\t;;\n+\tz80-*-coff)\n+\t\tbasic_machine=z80-unknown\n+\t\tos=-sim\n+\t\t;;\n+\tnone)\n+\t\tbasic_machine=none-none\n+\t\tos=-none\n+\t\t;;\n+\n+# Here we handle the default manufacturer of certain CPU types.  It is in\n+# some cases the only manufacturer, in others, it is the most popular.\n+\tw89k)\n+\t\tbasic_machine=hppa1.1-winbond\n+\t\t;;\n+\top50n)\n+\t\tbasic_machine=hppa1.1-oki\n+\t\t;;\n+\top60c)\n+\t\tbasic_machine=hppa1.1-oki\n+\t\t;;\n+\tromp)\n+\t\tbasic_machine=romp-ibm\n+\t\t;;\n+\tmmix)\n+\t\tbasic_machine=mmix-knuth\n+\t\t;;\n+\trs6000)\n+\t\tbasic_machine=rs6000-ibm\n+\t\t;;\n+\tvax)\n+\t\tbasic_machine=vax-dec\n+\t\t;;\n+\tpdp10)\n+\t\t# there are many clones, so DEC is not a safe bet\n+\t\tbasic_machine=pdp10-unknown\n+\t\t;;\n+\tpdp11)\n+\t\tbasic_machine=pdp11-dec\n+\t\t;;\n+\twe32k)\n+\t\tbasic_machine=we32k-att\n+\t\t;;\n+\tsh[1234] | sh[24]a | sh[24]aeb | sh[34]eb | sh[1234]le | sh[23]ele)\n+\t\tbasic_machine=sh-unknown\n+\t\t;;\n+\tsparc | sparcv8 | sparcv9 | sparcv9b | sparcv9v)\n+\t\tbasic_machine=sparc-sun\n+\t\t;;\n+\tcydra)\n+\t\tbasic_machine=cydra-cydrome\n+\t\t;;\n+\torion)\n+\t\tbasic_machine=orion-highlevel\n+\t\t;;\n+\torion105)\n+\t\tbasic_machine=clipper-highlevel\n+\t\t;;\n+\tmac | mpw | mac-mpw)\n+\t\tbasic_machine=m68k-apple\n+\t\t;;\n+\tpmac | pmac-mpw)\n+\t\tbasic_machine=powerpc-apple\n+\t\t;;\n+\t*-unknown)\n+\t\t# Make sure to match an already-canonicalized machine name.\n+\t\t;;\n+\t*)\n+\t\techo Invalid configuration \\`$1\\': machine \\`$basic_machine\\' not recognized 1>&2\n+\t\texit 1\n+\t\t;;\n+esac\n+\n+# Here we canonicalize certain aliases for manufacturers.\n+case $basic_machine in\n+\t*-digital*)\n+\t\tbasic_machine=`echo $basic_machine | sed 's/digital.*/dec/'`\n+\t\t;;\n+\t*-commodore*)\n+\t\tbasic_machine=`echo $basic_machine | sed 's/commodore.*/cbm/'`\n+\t\t;;\n+\t*)\n+\t\t;;\n+esac\n+\n+# Decode manufacturer-specific aliases for certain operating systems.\n+\n+if [ x\"$os\" != x\"\" ]\n+then\n+case $os in\n+\t# First match some system type aliases\n+\t# that might get confused with valid system types.\n+\t# -solaris* is a basic system type, with this one exception.\n+\t-auroraux)\n+\t\tos=-auroraux\n+\t\t;;\n+\t-solaris1 | -solaris1.*)\n+\t\tos=`echo $os | sed -e 's|solaris1|sunos4|'`\n+\t\t;;\n+\t-solaris)\n+\t\tos=-solaris2\n+\t\t;;\n+\t-svr4*)\n+\t\tos=-sysv4\n+\t\t;;\n+\t-unixware*)\n+\t\tos=-sysv4.2uw\n+\t\t;;\n+\t-gnu/linux*)\n+\t\tos=`echo $os | sed -e 's|gnu/linux|linux-gnu|'`\n+\t\t;;\n+\t# First accept the basic system types.\n+\t# The portable systems comes first.\n+\t# Each alternative MUST END IN A *, to match a version number.\n+\t# -sysv* is not here because it comes later, after sysvr4.\n+\t-gnu* | -bsd* | -mach* | -minix* | -genix* | -ultrix* | -irix* \\\n+\t      | -*vms* | -sco* | -esix* | -isc* | -aix* | -cnk* | -sunos | -sunos[34]*\\\n+\t      | -hpux* | -unos* | -osf* | -luna* | -dgux* | -auroraux* | -solaris* \\\n+\t      | -sym* | -kopensolaris* \\\n+\t      | -amigaos* | -amigados* | -msdos* | -newsos* | -unicos* | -aof* \\\n+\t      | -aos* | -aros* \\\n+\t      | -nindy* | -vxsim* | -vxworks* | -ebmon* | -hms* | -mvs* \\\n+\t      | -clix* | -riscos* | -uniplus* | -iris* | -rtu* | -xenix* \\\n+\t      | -hiux* | -386bsd* | -knetbsd* | -mirbsd* | -netbsd* \\\n+\t      | -openbsd* | -solidbsd* \\\n+\t      | -ekkobsd* | -kfreebsd* | -freebsd* | -riscix* | -lynxos* \\\n+\t      | -bosx* | -nextstep* | -cxux* | -aout* | -elf* | -oabi* \\\n+\t      | -ptx* | -coff* | -ecoff* | -winnt* | -domain* | -vsta* \\\n+\t      | -udi* | -eabi* | -lites* | -ieee* | -go32* | -aux* \\\n+\t      | -chorusos* | -chorusrdb* | -cegcc* \\\n+\t      | -cygwin* | -msys* | -pe* | -psos* | -moss* | -proelf* | -rtems* \\\n+\t      | -mingw32* | -linux-gnu* | -linux-android* \\\n+\t      | -linux-newlib* | -linux-uclibc* \\\n+\t      | -uxpv* | -beos* | -mpeix* | -udk* \\\n+\t      | -interix* | -uwin* | -mks* | -rhapsody* | -darwin* | -opened* \\\n+\t      | -openstep* | -oskit* | -conix* | -pw32* | -nonstopux* \\\n+\t      | -storm-chaos* | -tops10* | -tenex* | -tops20* | -its* \\\n+\t      | -os2* | -vos* | -palmos* | -uclinux* | -nucleus* \\\n+\t      | -morphos* | -superux* | -rtmk* | -rtmk-nova* | -windiss* \\\n+\t      | -powermax* | -dnix* | -nx6 | -nx7 | -sei* | -dragonfly* \\\n+\t      | -skyos* | -haiku* | -rdos* | -toppers* | -drops* | -es*)\n+\t# Remember, each alternative MUST END IN *, to match a version number.\n+\t\t;;\n+\t-qnx*)\n+\t\tcase $basic_machine in\n+\t\t    x86-* | i*86-*)\n+\t\t\t;;\n+\t\t    *)\n+\t\t\tos=-nto$os\n+\t\t\t;;\n+\t\tesac\n+\t\t;;\n+\t-nto-qnx*)\n+\t\t;;\n+\t-nto*)\n+\t\tos=`echo $os | sed -e 's|nto|nto-qnx|'`\n+\t\t;;\n+\t-sim | -es1800* | -hms* | -xray | -os68k* | -none* | -v88r* \\\n+\t      | -windows* | -osx | -abug | -netware* | -os9* | -beos* | -haiku* \\\n+\t      | -macos* | -mpw* | -magic* | -mmixware* | -mon960* | -lnews*)\n+\t\t;;\n+\t-mac*)\n+\t\tos=`echo $os | sed -e 's|mac|macos|'`\n+\t\t;;\n+\t-linux-dietlibc)\n+\t\tos=-linux-dietlibc\n+\t\t;;\n+\t-linux*)\n+\t\tos=`echo $os | sed -e 's|linux|linux-gnu|'`\n+\t\t;;\n+\t-sunos5*)\n+\t\tos=`echo $os | sed -e 's|sunos5|solaris2|'`\n+\t\t;;\n+\t-sunos6*)\n+\t\tos=`echo $os | sed -e 's|sunos6|solaris3|'`\n+\t\t;;\n+\t-opened*)\n+\t\tos=-openedition\n+\t\t;;\n+\t-os400*)\n+\t\tos=-os400\n+\t\t;;\n+\t-wince*)\n+\t\tos=-wince\n+\t\t;;\n+\t-osfrose*)\n+\t\tos=-osfrose\n+\t\t;;\n+\t-osf*)\n+\t\tos=-osf\n+\t\t;;\n+\t-utek*)\n+\t\tos=-bsd\n+\t\t;;\n+\t-dynix*)\n+\t\tos=-bsd\n+\t\t;;\n+\t-acis*)\n+\t\tos=-aos\n+\t\t;;\n+\t-atheos*)\n+\t\tos=-atheos\n+\t\t;;\n+\t-syllable*)\n+\t\tos=-syllable\n+\t\t;;\n+\t-386bsd)\n+\t\tos=-bsd\n+\t\t;;\n+\t-ctix* | -uts*)\n+\t\tos=-sysv\n+\t\t;;\n+\t-nova*)\n+\t\tos=-rtmk-nova\n+\t\t;;\n+\t-ns2 )\n+\t\tos=-nextstep2\n+\t\t;;\n+\t-nsk*)\n+\t\tos=-nsk\n+\t\t;;\n+\t# Preserve the version number of sinix5.\n+\t-sinix5.*)\n+\t\tos=`echo $os | sed -e 's|sinix|sysv|'`\n+\t\t;;\n+\t-sinix*)\n+\t\tos=-sysv4\n+\t\t;;\n+\t-tpf*)\n+\t\tos=-tpf\n+\t\t;;\n+\t-triton*)\n+\t\tos=-sysv3\n+\t\t;;\n+\t-oss*)\n+\t\tos=-sysv3\n+\t\t;;\n+\t-svr4)\n+\t\tos=-sysv4\n+\t\t;;\n+\t-svr3)\n+\t\tos=-sysv3\n+\t\t;;\n+\t-sysvr4)\n+\t\tos=-sysv4\n+\t\t;;\n+\t# This must come after -sysvr4.\n+\t-sysv*)\n+\t\t;;\n+\t-ose*)\n+\t\tos=-ose\n+\t\t;;\n+\t-es1800*)\n+\t\tos=-ose\n+\t\t;;\n+\t-xenix)\n+\t\tos=-xenix\n+\t\t;;\n+\t-*mint | -mint[0-9]* | -*MiNT | -MiNT[0-9]*)\n+\t\tos=-mint\n+\t\t;;\n+\t-aros*)\n+\t\tos=-aros\n+\t\t;;\n+\t-kaos*)\n+\t\tos=-kaos\n+\t\t;;\n+\t-zvmoe)\n+\t\tos=-zvmoe\n+\t\t;;\n+\t-dicos*)\n+\t\tos=-dicos\n+\t\t;;\n+\t-nacl*)\n+\t\t;;\n+\t-none)\n+\t\t;;\n+\t*)\n+\t\t# Get rid of the `-' at the beginning of $os.\n+\t\tos=`echo $os | sed 's/[^-]*-//'`\n+\t\techo Invalid configuration \\`$1\\': system \\`$os\\' not recognized 1>&2\n+\t\texit 1\n+\t\t;;\n+esac\n+else\n+\n+# Here we handle the default operating systems that come with various machines.\n+# The value should be what the vendor currently ships out the door with their\n+# machine or put another way, the most popular os provided with the machine.\n+\n+# Note that if you're going to try to match \"-MANUFACTURER\" here (say,\n+# \"-sun\"), then you have to tell the case statement up towards the top\n+# that MANUFACTURER isn't an operating system.  Otherwise, code above\n+# will signal an error saying that MANUFACTURER isn't an operating\n+# system, and we'll never get to this point.\n+\n+case $basic_machine in\n+\tscore-*)\n+\t\tos=-elf\n+\t\t;;\n+\tspu-*)\n+\t\tos=-elf\n+\t\t;;\n+\t*-acorn)\n+\t\tos=-riscix1.2\n+\t\t;;\n+\tarm*-rebel)\n+\t\tos=-linux\n+\t\t;;\n+\tarm*-semi)\n+\t\tos=-aout\n+\t\t;;\n+\tc4x-* | tic4x-*)\n+\t\tos=-coff\n+\t\t;;\n+\ttic54x-*)\n+\t\tos=-coff\n+\t\t;;\n+\ttic55x-*)\n+\t\tos=-coff\n+\t\t;;\n+\ttic6x-*)\n+\t\tos=-coff\n+\t\t;;\n+\t# This must come before the *-dec entry.\n+\tpdp10-*)\n+\t\tos=-tops20\n+\t\t;;\n+\tpdp11-*)\n+\t\tos=-none\n+\t\t;;\n+\t*-dec | vax-*)\n+\t\tos=-ultrix4.2\n+\t\t;;\n+\tm68*-apollo)\n+\t\tos=-domain\n+\t\t;;\n+\ti386-sun)\n+\t\tos=-sunos4.0.2\n+\t\t;;\n+\tm68000-sun)\n+\t\tos=-sunos3\n+\t\t;;\n+\tm68*-cisco)\n+\t\tos=-aout\n+\t\t;;\n+\tmep-*)\n+\t\tos=-elf\n+\t\t;;\n+\tmips*-cisco)\n+\t\tos=-elf\n+\t\t;;\n+\tmips*-*)\n+\t\tos=-elf\n+\t\t;;\n+\tor32-*)\n+\t\tos=-coff\n+\t\t;;\n+\t*-tti)\t# must be before sparc entry or we get the wrong os.\n+\t\tos=-sysv3\n+\t\t;;\n+\tsparc-* | *-sun)\n+\t\tos=-sunos4.1.1\n+\t\t;;\n+\t*-be)\n+\t\tos=-beos\n+\t\t;;\n+\t*-haiku)\n+\t\tos=-haiku\n+\t\t;;\n+\t*-ibm)\n+\t\tos=-aix\n+\t\t;;\n+\t*-knuth)\n+\t\tos=-mmixware\n+\t\t;;\n+\t*-wec)\n+\t\tos=-proelf\n+\t\t;;\n+\t*-winbond)\n+\t\tos=-proelf\n+\t\t;;\n+\t*-oki)\n+\t\tos=-proelf\n+\t\t;;\n+\t*-hp)\n+\t\tos=-hpux\n+\t\t;;\n+\t*-hitachi)\n+\t\tos=-hiux\n+\t\t;;\n+\ti860-* | *-att | *-ncr | *-altos | *-motorola | *-convergent)\n+\t\tos=-sysv\n+\t\t;;\n+\t*-cbm)\n+\t\tos=-amigaos\n+\t\t;;\n+\t*-dg)\n+\t\tos=-dgux\n+\t\t;;\n+\t*-dolphin)\n+\t\tos=-sysv3\n+\t\t;;\n+\tm68k-ccur)\n+\t\tos=-rtu\n+\t\t;;\n+\tm88k-omron*)\n+\t\tos=-luna\n+\t\t;;\n+\t*-next )\n+\t\tos=-nextstep\n+\t\t;;\n+\t*-sequent)\n+\t\tos=-ptx\n+\t\t;;\n+\t*-crds)\n+\t\tos=-unos\n+\t\t;;\n+\t*-ns)\n+\t\tos=-genix\n+\t\t;;\n+\ti370-*)\n+\t\tos=-mvs\n+\t\t;;\n+\t*-next)\n+\t\tos=-nextstep3\n+\t\t;;\n+\t*-gould)\n+\t\tos=-sysv\n+\t\t;;\n+\t*-highlevel)\n+\t\tos=-bsd\n+\t\t;;\n+\t*-encore)\n+\t\tos=-bsd\n+\t\t;;\n+\t*-sgi)\n+\t\tos=-irix\n+\t\t;;\n+\t*-siemens)\n+\t\tos=-sysv4\n+\t\t;;\n+\t*-masscomp)\n+\t\tos=-rtu\n+\t\t;;\n+\tf30[01]-fujitsu | f700-fujitsu)\n+\t\tos=-uxpv\n+\t\t;;\n+\t*-rom68k)\n+\t\tos=-coff\n+\t\t;;\n+\t*-*bug)\n+\t\tos=-coff\n+\t\t;;\n+\t*-apple)\n+\t\tos=-macos\n+\t\t;;\n+\t*-atari*)\n+\t\tos=-mint\n+\t\t;;\n+\t*)\n+\t\tos=-none\n+\t\t;;\n+esac\n+fi\n+\n+# Here we handle the case where we know the os, and the CPU type, but not the\n+# manufacturer.  We pick the logical manufacturer.\n+vendor=unknown\n+case $basic_machine in\n+\t*-unknown)\n+\t\tcase $os in\n+\t\t\t-riscix*)\n+\t\t\t\tvendor=acorn\n+\t\t\t\t;;\n+\t\t\t-sunos*)\n+\t\t\t\tvendor=sun\n+\t\t\t\t;;\n+\t\t\t-cnk*|-aix*)\n+\t\t\t\tvendor=ibm\n+\t\t\t\t;;\n+\t\t\t-beos*)\n+\t\t\t\tvendor=be\n+\t\t\t\t;;\n+\t\t\t-hpux*)\n+\t\t\t\tvendor=hp\n+\t\t\t\t;;\n+\t\t\t-mpeix*)\n+\t\t\t\tvendor=hp\n+\t\t\t\t;;\n+\t\t\t-hiux*)\n+\t\t\t\tvendor=hitachi\n+\t\t\t\t;;\n+\t\t\t-unos*)\n+\t\t\t\tvendor=crds\n+\t\t\t\t;;\n+\t\t\t-dgux*)\n+\t\t\t\tvendor=dg\n+\t\t\t\t;;\n+\t\t\t-luna*)\n+\t\t\t\tvendor=omron\n+\t\t\t\t;;\n+\t\t\t-genix*)\n+\t\t\t\tvendor=ns\n+\t\t\t\t;;\n+\t\t\t-mvs* | -opened*)\n+\t\t\t\tvendor=ibm\n+\t\t\t\t;;\n+\t\t\t-os400*)\n+\t\t\t\tvendor=ibm\n+\t\t\t\t;;\n+\t\t\t-ptx*)\n+\t\t\t\tvendor=sequent\n+\t\t\t\t;;\n+\t\t\t-tpf*)\n+\t\t\t\tvendor=ibm\n+\t\t\t\t;;\n+\t\t\t-vxsim* | -vxworks* | -windiss*)\n+\t\t\t\tvendor=wrs\n+\t\t\t\t;;\n+\t\t\t-aux*)\n+\t\t\t\tvendor=apple\n+\t\t\t\t;;\n+\t\t\t-hms*)\n+\t\t\t\tvendor=hitachi\n+\t\t\t\t;;\n+\t\t\t-mpw* | -macos*)\n+\t\t\t\tvendor=apple\n+\t\t\t\t;;\n+\t\t\t-*mint | -mint[0-9]* | -*MiNT | -MiNT[0-9]*)\n+\t\t\t\tvendor=atari\n+\t\t\t\t;;\n+\t\t\t-vos*)\n+\t\t\t\tvendor=stratus\n+\t\t\t\t;;\n+\t\tesac\n+\t\tbasic_machine=`echo $basic_machine | sed \"s/unknown/$vendor/\"`\n+\t\t;;\n+esac\n+\n+echo $basic_machine$os\n+exit\n+\n+# Local variables:\n+# eval: (add-hook 'write-file-hooks 'time-stamp)\n+# time-stamp-start: \"timestamp='\"\n+# time-stamp-format: \"%:y-%02m-%02d\"\n+# time-stamp-end: \"'\"\n+# End:"}, {"sha": "2ffd7032b08801a596b14e44eda25f4e6074bf83", "filename": "src/rt/jemalloc/configure", "status": "added", "additions": 8339, "deletions": 0, "changes": 8339, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfigure", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfigure", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fconfigure?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "ed7e3367f692c4dd3208ee2504cdcce744ec1857", "filename": "src/rt/jemalloc/configure.ac", "status": "added", "additions": 1333, "deletions": 0, "changes": 1333, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfigure.ac", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fconfigure.ac", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fconfigure.ac?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,1333 @@\n+dnl Process this file with autoconf to produce a configure script.\n+AC_INIT([Makefile.in])\n+\n+dnl ============================================================================\n+dnl Custom macro definitions.\n+\n+dnl JE_CFLAGS_APPEND(cflag)\n+AC_DEFUN([JE_CFLAGS_APPEND],\n+[\n+AC_MSG_CHECKING([whether compiler supports $1])\n+TCFLAGS=\"${CFLAGS}\"\n+if test \"x${CFLAGS}\" = \"x\" ; then\n+  CFLAGS=\"$1\"\n+else\n+  CFLAGS=\"${CFLAGS} $1\"\n+fi\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM(\n+[[\n+]], [[\n+    return 0;\n+]])],\n+              AC_MSG_RESULT([yes]),\n+              AC_MSG_RESULT([no])\n+              [CFLAGS=\"${TCFLAGS}\"]\n+)\n+])\n+\n+dnl JE_COMPILABLE(label, hcode, mcode, rvar)\n+dnl\n+dnl Use AC_LINK_IFELSE() rather than AC_COMPILE_IFELSE() so that linker errors\n+dnl cause failure.\n+AC_DEFUN([JE_COMPILABLE],\n+[\n+AC_CACHE_CHECK([whether $1 is compilable],\n+               [$4],\n+               [AC_LINK_IFELSE([AC_LANG_PROGRAM([$2],\n+                                                [$3])],\n+                               [$4=yes],\n+                               [$4=no])])\n+])\n+\n+dnl ============================================================================\n+\n+dnl Library revision.\n+rev=1\n+AC_SUBST([rev])\n+\n+srcroot=$srcdir\n+if test \"x${srcroot}\" = \"x.\" ; then\n+  srcroot=\"\"\n+else\n+  srcroot=\"${srcroot}/\"\n+fi\n+AC_SUBST([srcroot])\n+abs_srcroot=\"`cd \\\"${srcdir}\\\"; pwd`/\"\n+AC_SUBST([abs_srcroot])\n+\n+objroot=\"\"\n+AC_SUBST([objroot])\n+abs_objroot=\"`pwd`/\"\n+AC_SUBST([abs_objroot])\n+\n+dnl Munge install path variables.\n+if test \"x$prefix\" = \"xNONE\" ; then\n+  prefix=\"/usr/local\"\n+fi\n+if test \"x$exec_prefix\" = \"xNONE\" ; then\n+  exec_prefix=$prefix\n+fi\n+PREFIX=$prefix\n+AC_SUBST([PREFIX])\n+BINDIR=`eval echo $bindir`\n+BINDIR=`eval echo $BINDIR`\n+AC_SUBST([BINDIR])\n+INCLUDEDIR=`eval echo $includedir`\n+INCLUDEDIR=`eval echo $INCLUDEDIR`\n+AC_SUBST([INCLUDEDIR])\n+LIBDIR=`eval echo $libdir`\n+LIBDIR=`eval echo $LIBDIR`\n+AC_SUBST([LIBDIR])\n+DATADIR=`eval echo $datadir`\n+DATADIR=`eval echo $DATADIR`\n+AC_SUBST([DATADIR])\n+MANDIR=`eval echo $mandir`\n+MANDIR=`eval echo $MANDIR`\n+AC_SUBST([MANDIR])\n+\n+dnl Support for building documentation.\n+AC_PATH_PROG([XSLTPROC], [xsltproc], [false], [$PATH])\n+if test -d \"/usr/share/xml/docbook/stylesheet/docbook-xsl\" ; then\n+  DEFAULT_XSLROOT=\"/usr/share/xml/docbook/stylesheet/docbook-xsl\"\n+elif test -d \"/usr/share/sgml/docbook/xsl-stylesheets\" ; then\n+  DEFAULT_XSLROOT=\"/usr/share/sgml/docbook/xsl-stylesheets\"\n+else\n+  dnl Documentation building will fail if this default gets used.\n+  DEFAULT_XSLROOT=\"\"\n+fi\n+AC_ARG_WITH([xslroot],\n+  [AS_HELP_STRING([--with-xslroot=<path>], [XSL stylesheet root path])], [\n+if test \"x$with_xslroot\" = \"xno\" ; then\n+  XSLROOT=\"${DEFAULT_XSLROOT}\"\n+else\n+  XSLROOT=\"${with_xslroot}\"\n+fi\n+],\n+  XSLROOT=\"${DEFAULT_XSLROOT}\"\n+)\n+AC_SUBST([XSLROOT])\n+\n+dnl If CFLAGS isn't defined, set CFLAGS to something reasonable.  Otherwise,\n+dnl just prevent autoconf from molesting CFLAGS.\n+CFLAGS=$CFLAGS\n+AC_PROG_CC\n+if test \"x$GCC\" != \"xyes\" ; then\n+  AC_CACHE_CHECK([whether compiler is MSVC],\n+                 [je_cv_msvc],\n+                 [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([],\n+                                                     [\n+#ifndef _MSC_VER\n+  int fail[-1];\n+#endif\n+])],\n+                               [je_cv_msvc=yes],\n+                               [je_cv_msvc=no])])\n+fi\n+\n+if test \"x$CFLAGS\" = \"x\" ; then\n+  no_CFLAGS=\"yes\"\n+  if test \"x$GCC\" = \"xyes\" ; then\n+    JE_CFLAGS_APPEND([-std=gnu99])\n+    JE_CFLAGS_APPEND([-Wall])\n+    JE_CFLAGS_APPEND([-pipe])\n+    JE_CFLAGS_APPEND([-g3])\n+  elif test \"x$je_cv_msvc\" = \"xyes\" ; then\n+    CC=\"$CC -nologo\"\n+    JE_CFLAGS_APPEND([-Zi])\n+    JE_CFLAGS_APPEND([-MT])\n+    JE_CFLAGS_APPEND([-W3])\n+    CPPFLAGS=\"$CPPFLAGS -I${srcroot}/include/msvc_compat\"\n+  fi\n+fi\n+dnl Append EXTRA_CFLAGS to CFLAGS, if defined.\n+if test \"x$EXTRA_CFLAGS\" != \"x\" ; then\n+  JE_CFLAGS_APPEND([$EXTRA_CFLAGS])\n+fi\n+AC_PROG_CPP\n+\n+AC_CHECK_SIZEOF([void *])\n+if test \"x${ac_cv_sizeof_void_p}\" = \"x8\" ; then\n+  LG_SIZEOF_PTR=3\n+elif test \"x${ac_cv_sizeof_void_p}\" = \"x4\" ; then\n+  LG_SIZEOF_PTR=2\n+else\n+  AC_MSG_ERROR([Unsupported pointer size: ${ac_cv_sizeof_void_p}])\n+fi\n+AC_DEFINE_UNQUOTED([LG_SIZEOF_PTR], [$LG_SIZEOF_PTR])\n+\n+AC_CHECK_SIZEOF([int])\n+if test \"x${ac_cv_sizeof_int}\" = \"x8\" ; then\n+  LG_SIZEOF_INT=3\n+elif test \"x${ac_cv_sizeof_int}\" = \"x4\" ; then\n+  LG_SIZEOF_INT=2\n+else\n+  AC_MSG_ERROR([Unsupported int size: ${ac_cv_sizeof_int}])\n+fi\n+AC_DEFINE_UNQUOTED([LG_SIZEOF_INT], [$LG_SIZEOF_INT])\n+\n+AC_CHECK_SIZEOF([long])\n+if test \"x${ac_cv_sizeof_long}\" = \"x8\" ; then\n+  LG_SIZEOF_LONG=3\n+elif test \"x${ac_cv_sizeof_long}\" = \"x4\" ; then\n+  LG_SIZEOF_LONG=2\n+else\n+  AC_MSG_ERROR([Unsupported long size: ${ac_cv_sizeof_long}])\n+fi\n+AC_DEFINE_UNQUOTED([LG_SIZEOF_LONG], [$LG_SIZEOF_LONG])\n+\n+AC_CHECK_SIZEOF([intmax_t])\n+if test \"x${ac_cv_sizeof_intmax_t}\" = \"x16\" ; then\n+  LG_SIZEOF_INTMAX_T=4\n+elif test \"x${ac_cv_sizeof_intmax_t}\" = \"x8\" ; then\n+  LG_SIZEOF_INTMAX_T=3\n+elif test \"x${ac_cv_sizeof_intmax_t}\" = \"x4\" ; then\n+  LG_SIZEOF_INTMAX_T=2\n+else\n+  AC_MSG_ERROR([Unsupported intmax_t size: ${ac_cv_sizeof_intmax_t}])\n+fi\n+AC_DEFINE_UNQUOTED([LG_SIZEOF_INTMAX_T], [$LG_SIZEOF_INTMAX_T])\n+\n+AC_CANONICAL_HOST\n+dnl CPU-specific settings.\n+CPU_SPINWAIT=\"\"\n+case \"${host_cpu}\" in\n+  i[[345]]86)\n+\t;;\n+  i686)\n+\tJE_COMPILABLE([__asm__], [], [[__asm__ volatile(\"pause\"); return 0;]],\n+\t              [je_cv_asm])\n+\tif test \"x${je_cv_asm}\" = \"xyes\" ; then\n+\t    CPU_SPINWAIT='__asm__ volatile(\"pause\")'\n+\tfi\n+\t;;\n+  x86_64)\n+\tJE_COMPILABLE([__asm__ syntax], [],\n+\t              [[__asm__ volatile(\"pause\"); return 0;]], [je_cv_asm])\n+\tif test \"x${je_cv_asm}\" = \"xyes\" ; then\n+\t    CPU_SPINWAIT='__asm__ volatile(\"pause\")'\n+\tfi\n+\t;;\n+  *)\n+\t;;\n+esac\n+AC_DEFINE_UNQUOTED([CPU_SPINWAIT], [$CPU_SPINWAIT])\n+\n+LD_PRELOAD_VAR=\"LD_PRELOAD\"\n+so=\"so\"\n+importlib=\"${so}\"\n+o=\"$ac_objext\"\n+a=\"a\"\n+exe=\"$ac_exeext\"\n+libprefix=\"lib\"\n+DSO_LDFLAGS='-shared -Wl,-soname,$(@F)'\n+RPATH='-Wl,-rpath,$(1)'\n+SOREV=\"${so}.${rev}\"\n+PIC_CFLAGS='-fPIC -DPIC'\n+CTARGET='-o $@'\n+LDTARGET='-o $@'\n+EXTRA_LDFLAGS=\n+MKLIB='ar crus $@'\n+CC_MM=1\n+\n+dnl Platform-specific settings.  abi and RPATH can probably be determined\n+dnl programmatically, but doing so is error-prone, which makes it generally\n+dnl not worth the trouble.\n+dnl\n+dnl Define cpp macros in CPPFLAGS, rather than doing AC_DEFINE(macro), since the\n+dnl definitions need to be seen before any headers are included, which is a pain\n+dnl to make happen otherwise.\n+default_munmap=\"1\"\n+JEMALLOC_USABLE_SIZE_CONST=\"const\"\n+case \"${host}\" in\n+  *-*-darwin*)\n+\tCFLAGS=\"$CFLAGS\"\n+\tabi=\"macho\"\n+\tAC_DEFINE([JEMALLOC_PURGE_MADVISE_FREE], [ ])\n+\tRPATH=\"\"\n+\tLD_PRELOAD_VAR=\"DYLD_INSERT_LIBRARIES\"\n+\tso=\"dylib\"\n+\timportlib=\"${so}\"\n+\tforce_tls=\"0\"\n+\tDSO_LDFLAGS='-shared -Wl,-dylib_install_name,$(@F)'\n+\tSOREV=\"${rev}.${so}\"\n+\t;;\n+  *-*-freebsd*)\n+\tCFLAGS=\"$CFLAGS\"\n+\tabi=\"elf\"\n+\tAC_DEFINE([JEMALLOC_PURGE_MADVISE_FREE], [ ])\n+\tforce_lazy_lock=\"1\"\n+\t;;\n+  *-*-linux*)\n+\tCFLAGS=\"$CFLAGS\"\n+\tCPPFLAGS=\"$CPPFLAGS -D_GNU_SOURCE\"\n+\tabi=\"elf\"\n+\tAC_DEFINE([JEMALLOC_HAS_ALLOCA_H])\n+\tAC_DEFINE([JEMALLOC_PURGE_MADVISE_DONTNEED], [ ])\n+\tAC_DEFINE([JEMALLOC_THREADED_INIT], [ ])\n+\tJEMALLOC_USABLE_SIZE_CONST=\"\"\n+\tdefault_munmap=\"0\"\n+\t;;\n+  *-*-netbsd*)\n+\tAC_MSG_CHECKING([ABI])\n+        AC_COMPILE_IFELSE([AC_LANG_PROGRAM(\n+[[#ifdef __ELF__\n+/* ELF */\n+#else\n+#error aout\n+#endif\n+]])],\n+                          [CFLAGS=\"$CFLAGS\"; abi=\"elf\"],\n+                          [abi=\"aout\"])\n+\tAC_MSG_RESULT([$abi])\n+\tAC_DEFINE([JEMALLOC_PURGE_MADVISE_FREE], [ ])\n+\t;;\n+  *-*-solaris2*)\n+\tCFLAGS=\"$CFLAGS\"\n+\tabi=\"elf\"\n+\tRPATH='-Wl,-R,$(1)'\n+\tdnl Solaris needs this for sigwait().\n+\tCPPFLAGS=\"$CPPFLAGS -D_POSIX_PTHREAD_SEMANTICS\"\n+\tLIBS=\"$LIBS -lposix4 -lsocket -lnsl\"\n+\t;;\n+  *-ibm-aix*)\n+\tif \"$LG_SIZEOF_PTR\" = \"8\"; then\n+\t  dnl 64bit AIX\n+\t  LD_PRELOAD_VAR=\"LDR_PRELOAD64\"\n+\telse\n+\t  dnl 32bit AIX\n+\t  LD_PRELOAD_VAR=\"LDR_PRELOAD\"\n+\tfi\n+\tabi=\"xcoff\"\n+\t;;\n+  *-*-mingw*)\n+\tabi=\"pecoff\"\n+\tforce_tls=\"0\"\n+\tRPATH=\"\"\n+\tso=\"dll\"\n+\tif test \"x$je_cv_msvc\" = \"xyes\" ; then\n+\t  importlib=\"lib\"\n+\t  DSO_LDFLAGS=\"-LD\"\n+\t  EXTRA_LDFLAGS=\"-link -DEBUG\"\n+\t  CTARGET='-Fo$@'\n+\t  LDTARGET='-Fe$@'\n+\t  MKLIB='lib -nologo -out:$@'\n+\t  CC_MM=\n+        else\n+\t  importlib=\"${so}\"\n+\t  DSO_LDFLAGS=\"-shared\"\n+\tfi\n+\ta=\"lib\"\n+\tlibprefix=\"\"\n+\tSOREV=\"${so}\"\n+\tPIC_CFLAGS=\"\"\n+\t;;\n+  *)\n+\tAC_MSG_RESULT([Unsupported operating system: ${host}])\n+\tabi=\"elf\"\n+\t;;\n+esac\n+AC_DEFINE_UNQUOTED([JEMALLOC_USABLE_SIZE_CONST], [$JEMALLOC_USABLE_SIZE_CONST])\n+AC_SUBST([abi])\n+AC_SUBST([RPATH])\n+AC_SUBST([LD_PRELOAD_VAR])\n+AC_SUBST([so])\n+AC_SUBST([importlib])\n+AC_SUBST([o])\n+AC_SUBST([a])\n+AC_SUBST([exe])\n+AC_SUBST([libprefix])\n+AC_SUBST([DSO_LDFLAGS])\n+AC_SUBST([EXTRA_LDFLAGS])\n+AC_SUBST([SOREV])\n+AC_SUBST([PIC_CFLAGS])\n+AC_SUBST([CTARGET])\n+AC_SUBST([LDTARGET])\n+AC_SUBST([MKLIB])\n+AC_SUBST([CC_MM])\n+\n+if test \"x$abi\" != \"xpecoff\"; then\n+  dnl Heap profiling uses the log(3) function.\n+  LIBS=\"$LIBS -lm\"\n+fi\n+\n+JE_COMPILABLE([__attribute__ syntax],\n+              [static __attribute__((unused)) void foo(void){}],\n+              [],\n+              [je_cv_attribute])\n+if test \"x${je_cv_attribute}\" = \"xyes\" ; then\n+  AC_DEFINE([JEMALLOC_HAVE_ATTR], [ ])\n+  if test \"x${GCC}\" = \"xyes\" -a \"x${abi}\" = \"xelf\"; then\n+    JE_CFLAGS_APPEND([-fvisibility=hidden])\n+  fi\n+fi\n+dnl Check for tls_model attribute support (clang 3.0 still lacks support).\n+SAVED_CFLAGS=\"${CFLAGS}\"\n+JE_CFLAGS_APPEND([-Werror])\n+JE_COMPILABLE([tls_model attribute], [],\n+              [static __thread int\n+               __attribute__((tls_model(\"initial-exec\"))) foo;\n+               foo = 0;],\n+              [je_cv_tls_model])\n+CFLAGS=\"${SAVED_CFLAGS}\"\n+if test \"x${je_cv_tls_model}\" = \"xyes\" ; then\n+  AC_DEFINE([JEMALLOC_TLS_MODEL],\n+            [__attribute__((tls_model(\"initial-exec\")))])\n+else\n+  AC_DEFINE([JEMALLOC_TLS_MODEL], [ ])\n+fi\n+\n+dnl Support optional additions to rpath.\n+AC_ARG_WITH([rpath],\n+  [AS_HELP_STRING([--with-rpath=<rpath>], [Colon-separated rpath (ELF systems only)])],\n+if test \"x$with_rpath\" = \"xno\" ; then\n+  RPATH_EXTRA=\n+else\n+  RPATH_EXTRA=\"`echo $with_rpath | tr \\\":\\\" \\\" \\\"`\"\n+fi,\n+  RPATH_EXTRA=\n+)\n+AC_SUBST([RPATH_EXTRA])\n+\n+dnl Disable rules that do automatic regeneration of configure output by default.\n+AC_ARG_ENABLE([autogen],\n+  [AS_HELP_STRING([--enable-autogen], [Automatically regenerate configure output])],\n+if test \"x$enable_autogen\" = \"xno\" ; then\n+  enable_autogen=\"0\"\n+else\n+  enable_autogen=\"1\"\n+fi\n+,\n+enable_autogen=\"0\"\n+)\n+AC_SUBST([enable_autogen])\n+\n+AC_PROG_INSTALL\n+AC_PROG_RANLIB\n+AC_PATH_PROG([AR], [ar], [false], [$PATH])\n+AC_PATH_PROG([LD], [ld], [false], [$PATH])\n+AC_PATH_PROG([AUTOCONF], [autoconf], [false], [$PATH])\n+\n+public_syms=\"malloc_conf malloc_message malloc calloc posix_memalign aligned_alloc realloc free malloc_usable_size malloc_stats_print mallctl mallctlnametomib mallctlbymib\"\n+\n+dnl Check for allocator-related functions that should be wrapped.\n+AC_CHECK_FUNC([memalign],\n+\t      [AC_DEFINE([JEMALLOC_OVERRIDE_MEMALIGN], [ ])\n+\t       public_syms=\"${public_syms} memalign\"])\n+AC_CHECK_FUNC([valloc],\n+\t      [AC_DEFINE([JEMALLOC_OVERRIDE_VALLOC], [ ])\n+\t       public_syms=\"${public_syms} valloc\"])\n+\n+dnl Support the experimental API by default.\n+AC_ARG_ENABLE([experimental],\n+  [AS_HELP_STRING([--disable-experimental],\n+   [Disable support for the experimental API])],\n+[if test \"x$enable_experimental\" = \"xno\" ; then\n+  enable_experimental=\"0\"\n+else\n+  enable_experimental=\"1\"\n+fi\n+],\n+[enable_experimental=\"1\"]\n+)\n+if test \"x$enable_experimental\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_EXPERIMENTAL], [ ])\n+  public_syms=\"${public_syms} allocm dallocm nallocm rallocm sallocm\"\n+fi\n+AC_SUBST([enable_experimental])\n+\n+dnl Perform no name mangling by default.\n+AC_ARG_WITH([mangling],\n+  [AS_HELP_STRING([--with-mangling=<map>], [Mangle symbols in <map>])],\n+  [mangling_map=\"$with_mangling\"], [mangling_map=\"\"])\n+for nm in `echo ${mangling_map} |tr ',' ' '` ; do\n+  k=\"`echo ${nm} |tr ':' ' ' |awk '{print $1}'`\"\n+  n=\"je_${k}\"\n+  m=`echo ${nm} |tr ':' ' ' |awk '{print $2}'`\n+  AC_DEFINE_UNQUOTED([${n}], [${m}])\n+  dnl Remove key from public_syms so that it isn't redefined later.\n+  public_syms=`for sym in ${public_syms}; do echo \"${sym}\"; done |grep -v \"^${k}\\$\" |tr '\\n' ' '`\n+done\n+\n+dnl Do not prefix public APIs by default.\n+AC_ARG_WITH([jemalloc_prefix],\n+  [AS_HELP_STRING([--with-jemalloc-prefix=<prefix>], [Prefix to prepend to all public APIs])],\n+  [JEMALLOC_PREFIX=\"$with_jemalloc_prefix\"],\n+  [if test \"x$abi\" != \"xmacho\" -a \"x$abi\" != \"xpecoff\"; then\n+  JEMALLOC_PREFIX=\"\"\n+else\n+  JEMALLOC_PREFIX=\"je_\"\n+fi]\n+)\n+if test \"x$JEMALLOC_PREFIX\" != \"x\" ; then\n+  JEMALLOC_CPREFIX=`echo ${JEMALLOC_PREFIX} | tr \"a-z\" \"A-Z\"`\n+  AC_DEFINE_UNQUOTED([JEMALLOC_PREFIX], [\"$JEMALLOC_PREFIX\"])\n+  AC_DEFINE_UNQUOTED([JEMALLOC_CPREFIX], [\"$JEMALLOC_CPREFIX\"])\n+fi\n+dnl Generate macros to rename public symbols.  All public symbols are prefixed\n+dnl with je_ in the source code, so these macro definitions are needed even if\n+dnl --with-jemalloc-prefix wasn't specified.\n+for stem in ${public_syms}; do\n+  n=\"je_${stem}\"\n+  m=\"${JEMALLOC_PREFIX}${stem}\"\n+  AC_DEFINE_UNQUOTED([${n}], [${m}])\n+done\n+\n+AC_ARG_WITH([export],\n+  [AS_HELP_STRING([--without-export], [disable exporting jemalloc public APIs])],\n+  [if test \"x$with_export\" = \"xno\"; then\n+  AC_DEFINE([JEMALLOC_EXPORT],[])\n+fi]\n+)\n+\n+dnl Do not mangle library-private APIs by default.\n+AC_ARG_WITH([private_namespace],\n+  [AS_HELP_STRING([--with-private-namespace=<prefix>], [Prefix to prepend to all library-private APIs])],\n+  [JEMALLOC_PRIVATE_NAMESPACE=\"$with_private_namespace\"],\n+  [JEMALLOC_PRIVATE_NAMESPACE=\"\"]\n+)\n+AC_DEFINE_UNQUOTED([JEMALLOC_PRIVATE_NAMESPACE], [\"$JEMALLOC_PRIVATE_NAMESPACE\"])\n+if test \"x$JEMALLOC_PRIVATE_NAMESPACE\" != \"x\" ; then\n+  AC_DEFINE_UNQUOTED([JEMALLOC_N(string_that_no_one_should_want_to_use_as_a_jemalloc_private_namespace_prefix)], [${JEMALLOC_PRIVATE_NAMESPACE}##string_that_no_one_should_want_to_use_as_a_jemalloc_private_namespace_prefix])\n+else\n+  AC_DEFINE_UNQUOTED([JEMALLOC_N(string_that_no_one_should_want_to_use_as_a_jemalloc_private_namespace_prefix)], [string_that_no_one_should_want_to_use_as_a_jemalloc_private_namespace_prefix])\n+fi\n+\n+dnl Do not add suffix to installed files by default.\n+AC_ARG_WITH([install_suffix],\n+  [AS_HELP_STRING([--with-install-suffix=<suffix>], [Suffix to append to all installed files])],\n+  [INSTALL_SUFFIX=\"$with_install_suffix\"],\n+  [INSTALL_SUFFIX=]\n+)\n+install_suffix=\"$INSTALL_SUFFIX\"\n+AC_SUBST([install_suffix])\n+\n+cfgoutputs_in=\"${srcroot}Makefile.in\"\n+cfgoutputs_in=\"${cfgoutputs_in} ${srcroot}doc/html.xsl.in\"\n+cfgoutputs_in=\"${cfgoutputs_in} ${srcroot}doc/manpages.xsl.in\"\n+cfgoutputs_in=\"${cfgoutputs_in} ${srcroot}doc/jemalloc.xml.in\"\n+cfgoutputs_in=\"${cfgoutputs_in} ${srcroot}include/jemalloc/jemalloc.h.in\"\n+cfgoutputs_in=\"${cfgoutputs_in} ${srcroot}include/jemalloc/internal/jemalloc_internal.h.in\"\n+cfgoutputs_in=\"${cfgoutputs_in} ${srcroot}test/jemalloc_test.h.in\"\n+\n+cfgoutputs_out=\"Makefile\"\n+cfgoutputs_out=\"${cfgoutputs_out} doc/html.xsl\"\n+cfgoutputs_out=\"${cfgoutputs_out} doc/manpages.xsl\"\n+cfgoutputs_out=\"${cfgoutputs_out} doc/jemalloc${install_suffix}.xml\"\n+cfgoutputs_out=\"${cfgoutputs_out} include/jemalloc/jemalloc${install_suffix}.h\"\n+cfgoutputs_out=\"${cfgoutputs_out} include/jemalloc/internal/jemalloc_internal.h\"\n+cfgoutputs_out=\"${cfgoutputs_out} test/jemalloc_test.h\"\n+\n+cfgoutputs_tup=\"Makefile\"\n+cfgoutputs_tup=\"${cfgoutputs_tup} doc/html.xsl:doc/html.xsl.in\"\n+cfgoutputs_tup=\"${cfgoutputs_tup} doc/manpages.xsl:doc/manpages.xsl.in\"\n+cfgoutputs_tup=\"${cfgoutputs_tup} doc/jemalloc${install_suffix}.xml:doc/jemalloc.xml.in\"\n+cfgoutputs_tup=\"${cfgoutputs_tup} include/jemalloc/jemalloc${install_suffix}.h:include/jemalloc/jemalloc.h.in\"\n+cfgoutputs_tup=\"${cfgoutputs_tup} include/jemalloc/internal/jemalloc_internal.h\"\n+cfgoutputs_tup=\"${cfgoutputs_tup} test/jemalloc_test.h:test/jemalloc_test.h.in\"\n+\n+cfghdrs_in=\"${srcroot}include/jemalloc/jemalloc_defs.h.in\"\n+cfghdrs_in=\"${cfghdrs_in} ${srcroot}include/jemalloc/internal/size_classes.sh\"\n+\n+cfghdrs_out=\"include/jemalloc/jemalloc_defs${install_suffix}.h\"\n+cfghdrs_out=\"${cfghdrs_out} include/jemalloc/internal/size_classes.h\"\n+\n+cfghdrs_tup=\"include/jemalloc/jemalloc_defs${install_suffix}.h:include/jemalloc/jemalloc_defs.h.in\"\n+\n+dnl Do not silence irrelevant compiler warnings by default, since enabling this\n+dnl option incurs a performance penalty.\n+AC_ARG_ENABLE([cc-silence],\n+  [AS_HELP_STRING([--enable-cc-silence],\n+                  [Silence irrelevant compiler warnings])],\n+[if test \"x$enable_cc_silence\" = \"xno\" ; then\n+  enable_cc_silence=\"0\"\n+else\n+  enable_cc_silence=\"1\"\n+fi\n+],\n+[enable_cc_silence=\"0\"]\n+)\n+if test \"x$enable_cc_silence\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_CC_SILENCE], [ ])\n+fi\n+\n+dnl Do not compile with debugging by default.\n+AC_ARG_ENABLE([debug],\n+  [AS_HELP_STRING([--enable-debug], [Build debugging code (implies --enable-ivsalloc)])],\n+[if test \"x$enable_debug\" = \"xno\" ; then\n+  enable_debug=\"0\"\n+else\n+  enable_debug=\"1\"\n+fi\n+],\n+[enable_debug=\"0\"]\n+)\n+if test \"x$enable_debug\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_DEBUG], [ ])\n+  enable_ivsalloc=\"1\"\n+fi\n+AC_SUBST([enable_debug])\n+\n+dnl Do not validate pointers by default.\n+AC_ARG_ENABLE([ivsalloc],\n+  [AS_HELP_STRING([--enable-ivsalloc], [Validate pointers passed through the public API])],\n+[if test \"x$enable_ivsalloc\" = \"xno\" ; then\n+  enable_ivsalloc=\"0\"\n+else\n+  enable_ivsalloc=\"1\"\n+fi\n+],\n+[enable_ivsalloc=\"0\"]\n+)\n+if test \"x$enable_ivsalloc\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_IVSALLOC], [ ])\n+fi\n+\n+dnl Only optimize if not debugging.\n+if test \"x$enable_debug\" = \"x0\" -a \"x$no_CFLAGS\" = \"xyes\" ; then\n+  dnl Make sure that an optimization flag was not specified in EXTRA_CFLAGS.\n+  optimize=\"no\"\n+  echo \"$EXTRA_CFLAGS\" | grep \"\\-O\" >/dev/null || optimize=\"yes\"\n+  if test \"x${optimize}\" = \"xyes\" ; then\n+    if test \"x$GCC\" = \"xyes\" ; then\n+      JE_CFLAGS_APPEND([-O3])\n+      JE_CFLAGS_APPEND([-funroll-loops])\n+    elif test \"x$je_cv_msvc\" = \"xyes\" ; then\n+      JE_CFLAGS_APPEND([-O2])\n+    else\n+      JE_CFLAGS_APPEND([-O])\n+    fi\n+  fi\n+fi\n+\n+dnl Enable statistics calculation by default.\n+AC_ARG_ENABLE([stats],\n+  [AS_HELP_STRING([--disable-stats],\n+                  [Disable statistics calculation/reporting])],\n+[if test \"x$enable_stats\" = \"xno\" ; then\n+  enable_stats=\"0\"\n+else\n+  enable_stats=\"1\"\n+fi\n+],\n+[enable_stats=\"1\"]\n+)\n+if test \"x$enable_stats\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_STATS], [ ])\n+fi\n+AC_SUBST([enable_stats])\n+\n+dnl Do not enable profiling by default.\n+AC_ARG_ENABLE([prof],\n+  [AS_HELP_STRING([--enable-prof], [Enable allocation profiling])],\n+[if test \"x$enable_prof\" = \"xno\" ; then\n+  enable_prof=\"0\"\n+else\n+  enable_prof=\"1\"\n+fi\n+],\n+[enable_prof=\"0\"]\n+)\n+if test \"x$enable_prof\" = \"x1\" ; then\n+  backtrace_method=\"\"\n+else\n+  backtrace_method=\"N/A\"\n+fi\n+\n+AC_ARG_ENABLE([prof-libunwind],\n+  [AS_HELP_STRING([--enable-prof-libunwind], [Use libunwind for backtracing])],\n+[if test \"x$enable_prof_libunwind\" = \"xno\" ; then\n+  enable_prof_libunwind=\"0\"\n+else\n+  enable_prof_libunwind=\"1\"\n+fi\n+],\n+[enable_prof_libunwind=\"0\"]\n+)\n+AC_ARG_WITH([static_libunwind],\n+  [AS_HELP_STRING([--with-static-libunwind=<libunwind.a>],\n+  [Path to static libunwind library; use rather than dynamically linking])],\n+if test \"x$with_static_libunwind\" = \"xno\" ; then\n+  LUNWIND=\"-lunwind\"\n+else\n+  if test ! -f \"$with_static_libunwind\" ; then\n+    AC_MSG_ERROR([Static libunwind not found: $with_static_libunwind])\n+  fi\n+  LUNWIND=\"$with_static_libunwind\"\n+fi,\n+  LUNWIND=\"-lunwind\"\n+)\n+if test \"x$backtrace_method\" = \"x\" -a \"x$enable_prof_libunwind\" = \"x1\" ; then\n+  AC_CHECK_HEADERS([libunwind.h], , [enable_prof_libunwind=\"0\"])\n+  if test \"x$LUNWIND\" = \"x-lunwind\" ; then\n+    AC_CHECK_LIB([unwind], [backtrace], [LIBS=\"$LIBS $LUNWIND\"],\n+                 [enable_prof_libunwind=\"0\"])\n+  else\n+    LIBS=\"$LIBS $LUNWIND\"\n+  fi\n+  if test \"x${enable_prof_libunwind}\" = \"x1\" ; then\n+    backtrace_method=\"libunwind\"\n+    AC_DEFINE([JEMALLOC_PROF_LIBUNWIND], [ ])\n+  fi\n+fi\n+\n+AC_ARG_ENABLE([prof-libgcc],\n+  [AS_HELP_STRING([--disable-prof-libgcc],\n+  [Do not use libgcc for backtracing])],\n+[if test \"x$enable_prof_libgcc\" = \"xno\" ; then\n+  enable_prof_libgcc=\"0\"\n+else\n+  enable_prof_libgcc=\"1\"\n+fi\n+],\n+[enable_prof_libgcc=\"1\"]\n+)\n+if test \"x$backtrace_method\" = \"x\" -a \"x$enable_prof_libgcc\" = \"x1\" \\\n+     -a \"x$GCC\" = \"xyes\" ; then\n+  AC_CHECK_HEADERS([unwind.h], , [enable_prof_libgcc=\"0\"])\n+  AC_CHECK_LIB([gcc], [_Unwind_Backtrace], [LIBS=\"$LIBS -lgcc\"], [enable_prof_libgcc=\"0\"])\n+  dnl The following is conservative, in that it only has entries for CPUs on\n+  dnl which jemalloc has been tested.\n+  AC_MSG_CHECKING([libgcc-based backtracing reliability on ${host_cpu}])\n+  case \"${host_cpu}\" in\n+    i[[3456]]86)\n+      AC_MSG_RESULT([unreliable])\n+      enable_prof_libgcc=\"0\";\n+      ;;\n+    x86_64)\n+      AC_MSG_RESULT([reliable])\n+      ;;\n+    *)\n+      AC_MSG_RESULT([unreliable])\n+      enable_prof_libgcc=\"0\";\n+      ;;\n+  esac\n+  if test \"x${enable_prof_libgcc}\" = \"x1\" ; then\n+    backtrace_method=\"libgcc\"\n+    AC_DEFINE([JEMALLOC_PROF_LIBGCC], [ ])\n+  fi\n+else\n+  enable_prof_libgcc=\"0\"\n+fi\n+\n+AC_ARG_ENABLE([prof-gcc],\n+  [AS_HELP_STRING([--disable-prof-gcc],\n+  [Do not use gcc intrinsics for backtracing])],\n+[if test \"x$enable_prof_gcc\" = \"xno\" ; then\n+  enable_prof_gcc=\"0\"\n+else\n+  enable_prof_gcc=\"1\"\n+fi\n+],\n+[enable_prof_gcc=\"1\"]\n+)\n+if test \"x$backtrace_method\" = \"x\" -a \"x$enable_prof_gcc\" = \"x1\" \\\n+     -a \"x$GCC\" = \"xyes\" ; then\n+  backtrace_method=\"gcc intrinsics\"\n+  AC_DEFINE([JEMALLOC_PROF_GCC], [ ])\n+else\n+  enable_prof_gcc=\"0\"\n+fi\n+\n+if test \"x$backtrace_method\" = \"x\" ; then\n+  backtrace_method=\"none (disabling profiling)\"\n+  enable_prof=\"0\"\n+fi\n+AC_MSG_CHECKING([configured backtracing method])\n+AC_MSG_RESULT([$backtrace_method])\n+if test \"x$enable_prof\" = \"x1\" ; then\n+  if test \"x${force_tls}\" = \"x0\" ; then\n+    AC_MSG_ERROR([Heap profiling requires TLS]);\n+  fi\n+  force_tls=\"1\"\n+  AC_DEFINE([JEMALLOC_PROF], [ ])\n+fi\n+AC_SUBST([enable_prof])\n+\n+dnl Enable thread-specific caching by default.\n+AC_ARG_ENABLE([tcache],\n+  [AS_HELP_STRING([--disable-tcache], [Disable per thread caches])],\n+[if test \"x$enable_tcache\" = \"xno\" ; then\n+  enable_tcache=\"0\"\n+else\n+  enable_tcache=\"1\"\n+fi\n+],\n+[enable_tcache=\"1\"]\n+)\n+if test \"x$enable_tcache\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_TCACHE], [ ])\n+fi\n+AC_SUBST([enable_tcache])\n+\n+dnl Disable mremap() for huge realloc() by default.\n+AC_ARG_ENABLE([mremap],\n+  [AS_HELP_STRING([--enable-mremap], [Enable mremap(2) for huge realloc()])],\n+[if test \"x$enable_mremap\" = \"xno\" ; then\n+  enable_mremap=\"0\"\n+else\n+  enable_mremap=\"1\"\n+fi\n+],\n+[enable_mremap=\"0\"]\n+)\n+if test \"x$enable_mremap\" = \"x1\" ; then\n+  JE_COMPILABLE([mremap(...MREMAP_FIXED...)], [\n+#define _GNU_SOURCE\n+#include <sys/mman.h>\n+], [\n+void *p = mremap((void *)0, 0, 0, MREMAP_MAYMOVE|MREMAP_FIXED, (void *)0);\n+], [je_cv_mremap_fixed])\n+  if test \"x${je_cv_mremap_fixed}\" = \"xno\" ; then\n+    enable_mremap=\"0\"\n+  fi\n+fi\n+if test \"x$enable_mremap\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_MREMAP], [ ])\n+fi\n+AC_SUBST([enable_mremap])\n+\n+dnl Enable VM deallocation via munmap() by default.\n+AC_ARG_ENABLE([munmap],\n+  [AS_HELP_STRING([--disable-munmap], [Disable VM deallocation via munmap(2)])],\n+[if test \"x$enable_munmap\" = \"xno\" ; then\n+  enable_munmap=\"0\"\n+else\n+  enable_munmap=\"1\"\n+fi\n+],\n+[enable_munmap=\"${default_munmap}\"]\n+)\n+if test \"x$enable_munmap\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_MUNMAP], [ ])\n+fi\n+AC_SUBST([enable_munmap])\n+\n+dnl Do not enable allocation from DSS by default.\n+AC_ARG_ENABLE([dss],\n+  [AS_HELP_STRING([--enable-dss], [Enable allocation from DSS])],\n+[if test \"x$enable_dss\" = \"xno\" ; then\n+  enable_dss=\"0\"\n+else\n+  enable_dss=\"1\"\n+fi\n+],\n+[enable_dss=\"0\"]\n+)\n+dnl Check whether the BSD/SUSv1 sbrk() exists.  If not, disable DSS support.\n+AC_CHECK_FUNC([sbrk], [have_sbrk=\"1\"], [have_sbrk=\"0\"])\n+if test \"x$have_sbrk\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_HAVE_SBRK], [ ])\n+else\n+  enable_dss=\"0\"\n+fi\n+\n+if test \"x$enable_dss\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_DSS], [ ])\n+fi\n+AC_SUBST([enable_dss])\n+\n+dnl Support the junk/zero filling option by default.\n+AC_ARG_ENABLE([fill],\n+  [AS_HELP_STRING([--disable-fill],\n+                  [Disable support for junk/zero filling, quarantine, and redzones])],\n+[if test \"x$enable_fill\" = \"xno\" ; then\n+  enable_fill=\"0\"\n+else\n+  enable_fill=\"1\"\n+fi\n+],\n+[enable_fill=\"1\"]\n+)\n+if test \"x$enable_fill\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_FILL], [ ])\n+fi\n+AC_SUBST([enable_fill])\n+\n+dnl Disable utrace(2)-based tracing by default.\n+AC_ARG_ENABLE([utrace],\n+  [AS_HELP_STRING([--enable-utrace], [Enable utrace(2)-based tracing])],\n+[if test \"x$enable_utrace\" = \"xno\" ; then\n+  enable_utrace=\"0\"\n+else\n+  enable_utrace=\"1\"\n+fi\n+],\n+[enable_utrace=\"0\"]\n+)\n+JE_COMPILABLE([utrace(2)], [\n+#include <sys/types.h>\n+#include <sys/param.h>\n+#include <sys/time.h>\n+#include <sys/uio.h>\n+#include <sys/ktrace.h>\n+], [\n+\tutrace((void *)0, 0);\n+], [je_cv_utrace])\n+if test \"x${je_cv_utrace}\" = \"xno\" ; then\n+  enable_utrace=\"0\"\n+fi\n+if test \"x$enable_utrace\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_UTRACE], [ ])\n+fi\n+AC_SUBST([enable_utrace])\n+\n+dnl Support Valgrind by default.\n+AC_ARG_ENABLE([valgrind],\n+  [AS_HELP_STRING([--disable-valgrind], [Disable support for Valgrind])],\n+[if test \"x$enable_valgrind\" = \"xno\" ; then\n+  enable_valgrind=\"0\"\n+else\n+  enable_valgrind=\"1\"\n+fi\n+],\n+[enable_valgrind=\"1\"]\n+)\n+if test \"x$enable_valgrind\" = \"x1\" ; then\n+  JE_COMPILABLE([valgrind], [\n+#include <valgrind/valgrind.h>\n+#include <valgrind/memcheck.h>\n+\n+#if !defined(VALGRIND_RESIZEINPLACE_BLOCK)\n+#  error \"Incompatible Valgrind version\"\n+#endif\n+], [], [je_cv_valgrind])\n+  if test \"x${je_cv_valgrind}\" = \"xno\" ; then\n+    enable_valgrind=\"0\"\n+  fi\n+  if test \"x$enable_valgrind\" = \"x1\" ; then\n+    AC_DEFINE([JEMALLOC_VALGRIND], [ ])\n+  fi\n+fi\n+AC_SUBST([enable_valgrind])\n+\n+dnl Do not support the xmalloc option by default.\n+AC_ARG_ENABLE([xmalloc],\n+  [AS_HELP_STRING([--enable-xmalloc], [Support xmalloc option])],\n+[if test \"x$enable_xmalloc\" = \"xno\" ; then\n+  enable_xmalloc=\"0\"\n+else\n+  enable_xmalloc=\"1\"\n+fi\n+],\n+[enable_xmalloc=\"0\"]\n+)\n+if test \"x$enable_xmalloc\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_XMALLOC], [ ])\n+fi\n+AC_SUBST([enable_xmalloc])\n+\n+AC_CACHE_CHECK([STATIC_PAGE_SHIFT],\n+               [je_cv_static_page_shift],\n+               AC_RUN_IFELSE([AC_LANG_PROGRAM(\n+[[\n+#include <strings.h>\n+#ifdef _WIN32\n+#include <windows.h>\n+#else\n+#include <unistd.h>\n+#endif\n+#include <stdio.h>\n+]],\n+[[\n+    int result;\n+    FILE *f;\n+\n+#ifdef _WIN32\n+    SYSTEM_INFO si;\n+    GetSystemInfo(&si);\n+    result = si.dwPageSize;\n+#else\n+    result = sysconf(_SC_PAGESIZE);\n+#endif\n+    if (result == -1) {\n+\treturn 1;\n+    }\n+    result = ffsl(result) - 1;\n+\n+    f = fopen(\"conftest.out\", \"w\");\n+    if (f == NULL) {\n+\treturn 1;\n+    }\n+    fprintf(f, \"%d\\n\", result);\n+    fclose(f);\n+\n+    return 0;\n+]])],\n+                             [je_cv_static_page_shift=`cat conftest.out`],\n+                             [je_cv_static_page_shift=undefined]))\n+\n+if test \"x$je_cv_static_page_shift\" != \"xundefined\"; then\n+   AC_DEFINE_UNQUOTED([STATIC_PAGE_SHIFT], [$je_cv_static_page_shift])\n+else\n+   AC_MSG_ERROR([cannot determine value for STATIC_PAGE_SHIFT])\n+fi\n+\n+dnl ============================================================================\n+dnl jemalloc configuration.\n+dnl\n+\n+dnl Set VERSION if source directory has an embedded git repository.\n+if test -d \"${srcroot}.git\" ; then\n+  git describe --long --abbrev=40 > ${srcroot}VERSION\n+fi\n+jemalloc_version=`cat ${srcroot}VERSION`\n+jemalloc_version_major=`echo ${jemalloc_version} | tr \".g-\" \" \" | awk '{print [$]1}'`\n+jemalloc_version_minor=`echo ${jemalloc_version} | tr \".g-\" \" \" | awk '{print [$]2}'`\n+jemalloc_version_bugfix=`echo ${jemalloc_version} | tr \".g-\" \" \" | awk '{print [$]3}'`\n+jemalloc_version_nrev=`echo ${jemalloc_version} | tr \".g-\" \" \" | awk '{print [$]4}'`\n+jemalloc_version_gid=`echo ${jemalloc_version} | tr \".g-\" \" \" | awk '{print [$]5}'`\n+AC_SUBST([jemalloc_version])\n+AC_SUBST([jemalloc_version_major])\n+AC_SUBST([jemalloc_version_minor])\n+AC_SUBST([jemalloc_version_bugfix])\n+AC_SUBST([jemalloc_version_nrev])\n+AC_SUBST([jemalloc_version_gid])\n+\n+dnl ============================================================================\n+dnl Configure pthreads.\n+\n+if test \"x$abi\" != \"xpecoff\" ; then\n+  AC_CHECK_HEADERS([pthread.h], , [AC_MSG_ERROR([pthread.h is missing])])\n+  dnl Some systems may embed pthreads functionality in libc; check for libpthread\n+  dnl first, but try libc too before failing.\n+  AC_CHECK_LIB([pthread], [pthread_create], [LIBS=\"$LIBS -lpthread\"],\n+               [AC_SEARCH_LIBS([pthread_create], , ,\n+                               AC_MSG_ERROR([libpthread is missing]))])\n+fi\n+\n+CPPFLAGS=\"$CPPFLAGS -D_REENTRANT\"\n+\n+dnl Check whether the BSD-specific _malloc_thread_cleanup() exists.  If so, use\n+dnl it rather than pthreads TSD cleanup functions to support cleanup during\n+dnl thread exit, in order to avoid pthreads library recursion during\n+dnl bootstrapping.\n+AC_CHECK_FUNC([_malloc_thread_cleanup],\n+              [have__malloc_thread_cleanup=\"1\"],\n+              [have__malloc_thread_cleanup=\"0\"]\n+             )\n+if test \"x$have__malloc_thread_cleanup\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_MALLOC_THREAD_CLEANUP], [ ])\n+  force_tls=\"1\"\n+fi\n+\n+dnl Check whether the BSD-specific _pthread_mutex_init_calloc_cb() exists.  If\n+dnl so, mutex initialization causes allocation, and we need to implement this\n+dnl callback function in order to prevent recursive allocation.\n+AC_CHECK_FUNC([_pthread_mutex_init_calloc_cb],\n+              [have__pthread_mutex_init_calloc_cb=\"1\"],\n+              [have__pthread_mutex_init_calloc_cb=\"0\"]\n+             )\n+if test \"x$have__pthread_mutex_init_calloc_cb\" = \"x1\" ; then\n+  AC_DEFINE([JEMALLOC_MUTEX_INIT_CB])\n+fi\n+\n+dnl Disable lazy locking by default.\n+AC_ARG_ENABLE([lazy_lock],\n+  [AS_HELP_STRING([--enable-lazy-lock],\n+  [Enable lazy locking (only lock when multi-threaded)])],\n+[if test \"x$enable_lazy_lock\" = \"xno\" ; then\n+  enable_lazy_lock=\"0\"\n+else\n+  enable_lazy_lock=\"1\"\n+fi\n+],\n+[enable_lazy_lock=\"0\"]\n+)\n+if test \"x$enable_lazy_lock\" = \"x0\" -a \"x${force_lazy_lock}\" = \"x1\" ; then\n+  AC_MSG_RESULT([Forcing lazy-lock to avoid allocator/threading bootstrap issues])\n+  enable_lazy_lock=\"1\"\n+fi\n+if test \"x$enable_lazy_lock\" = \"x1\" ; then\n+  if test \"x$abi\" != \"xpecoff\" ; then\n+    AC_CHECK_HEADERS([dlfcn.h], , [AC_MSG_ERROR([dlfcn.h is missing])])\n+    AC_CHECK_FUNC([dlsym], [],\n+      [AC_CHECK_LIB([dl], [dlsym], [LIBS=\"$LIBS -ldl\"],\n+                    [AC_MSG_ERROR([libdl is missing])])\n+      ])\n+  fi\n+  AC_DEFINE([JEMALLOC_LAZY_LOCK], [ ])\n+fi\n+AC_SUBST([enable_lazy_lock])\n+\n+AC_ARG_ENABLE([tls],\n+  [AS_HELP_STRING([--disable-tls], [Disable thread-local storage (__thread keyword)])],\n+if test \"x$enable_tls\" = \"xno\" ; then\n+  enable_tls=\"0\"\n+else\n+  enable_tls=\"1\"\n+fi\n+,\n+enable_tls=\"1\"\n+)\n+if test \"x${enable_tls}\" = \"x0\" -a \"x${force_tls}\" = \"x1\" ; then\n+  AC_MSG_RESULT([Forcing TLS to avoid allocator/threading bootstrap issues])\n+  enable_tls=\"1\"\n+fi\n+if test \"x${enable_tls}\" = \"x1\" -a \"x${force_tls}\" = \"x0\" ; then\n+  AC_MSG_RESULT([Forcing no TLS to avoid allocator/threading bootstrap issues])\n+  enable_tls=\"0\"\n+fi\n+if test \"x${enable_tls}\" = \"x1\" ; then\n+AC_MSG_CHECKING([for TLS])\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM(\n+[[\n+    __thread int x;\n+]], [[\n+    x = 42;\n+\n+    return 0;\n+]])],\n+              AC_MSG_RESULT([yes]),\n+              AC_MSG_RESULT([no])\n+              enable_tls=\"0\")\n+fi\n+AC_SUBST([enable_tls])\n+if test \"x${enable_tls}\" = \"x1\" ; then\n+  AC_DEFINE_UNQUOTED([JEMALLOC_TLS], [ ])\n+elif test \"x${force_tls}\" = \"x1\" ; then\n+  AC_MSG_ERROR([Failed to configure TLS, which is mandatory for correct function])\n+fi\n+\n+dnl ============================================================================\n+dnl Check for ffsl(3), and fail if not found.  This function exists on all\n+dnl platforms that jemalloc currently has a chance of functioning on without\n+dnl modification.\n+JE_COMPILABLE([a program using ffsl], [\n+#include <stdio.h>\n+#include <strings.h>\n+#include <string.h>\n+], [\n+\t{\n+\t\tint rv = ffsl(0x08);\n+\t\tprintf(\"%d\\n\", rv);\n+\t}\n+], [je_cv_function_ffsl])\n+if test \"x${je_cv_function_ffsl}\" != \"xyes\" ; then\n+   AC_MSG_ERROR([Cannot build without ffsl(3)])\n+fi\n+\n+dnl ============================================================================\n+dnl Check for atomic(9) operations as provided on FreeBSD.\n+\n+JE_COMPILABLE([atomic(9)], [\n+#include <sys/types.h>\n+#include <machine/atomic.h>\n+#include <inttypes.h>\n+], [\n+\t{\n+\t\tuint32_t x32 = 0;\n+\t\tvolatile uint32_t *x32p = &x32;\n+\t\tatomic_fetchadd_32(x32p, 1);\n+\t}\n+\t{\n+\t\tunsigned long xlong = 0;\n+\t\tvolatile unsigned long *xlongp = &xlong;\n+\t\tatomic_fetchadd_long(xlongp, 1);\n+\t}\n+], [je_cv_atomic9])\n+if test \"x${je_cv_atomic9}\" = \"xyes\" ; then\n+  AC_DEFINE([JEMALLOC_ATOMIC9])\n+fi\n+\n+dnl ============================================================================\n+dnl Check for atomic(3) operations as provided on Darwin.\n+\n+JE_COMPILABLE([Darwin OSAtomic*()], [\n+#include <libkern/OSAtomic.h>\n+#include <inttypes.h>\n+], [\n+\t{\n+\t\tint32_t x32 = 0;\n+\t\tvolatile int32_t *x32p = &x32;\n+\t\tOSAtomicAdd32(1, x32p);\n+\t}\n+\t{\n+\t\tint64_t x64 = 0;\n+\t\tvolatile int64_t *x64p = &x64;\n+\t\tOSAtomicAdd64(1, x64p);\n+\t}\n+], [je_cv_osatomic])\n+if test \"x${je_cv_osatomic}\" = \"xyes\" ; then\n+  AC_DEFINE([JEMALLOC_OSATOMIC], [ ])\n+fi\n+\n+dnl ============================================================================\n+dnl Check whether __sync_{add,sub}_and_fetch() are available despite\n+dnl __GCC_HAVE_SYNC_COMPARE_AND_SWAP_n macros being undefined.\n+\n+AC_DEFUN([JE_SYNC_COMPARE_AND_SWAP_CHECK],[\n+  AC_CACHE_CHECK([whether to force $1-bit __sync_{add,sub}_and_fetch()],\n+               [je_cv_sync_compare_and_swap_$2],\n+               [AC_LINK_IFELSE([AC_LANG_PROGRAM([\n+                                                 #include <stdint.h>\n+                                                ],\n+                                                [\n+                                                 #ifndef __GCC_HAVE_SYNC_COMPARE_AND_SWAP_$2\n+                                                 {\n+                                                    uint$1_t x$1 = 0;\n+                                                    __sync_add_and_fetch(&x$1, 42);\n+                                                    __sync_sub_and_fetch(&x$1, 1);\n+                                                 }\n+                                                 #else\n+                                                 #error __GCC_HAVE_SYNC_COMPARE_AND_SWAP_$2 is defined, no need to force\n+                                                 #endif\n+                                                ])],\n+                               [je_cv_sync_compare_and_swap_$2=yes],\n+                               [je_cv_sync_compare_and_swap_$2=no])])\n+\n+  if test \"x${je_cv_sync_compare_and_swap_$2}\" = \"xyes\" ; then\n+    AC_DEFINE([JE_FORCE_SYNC_COMPARE_AND_SWAP_$2], [ ])\n+  fi\n+])\n+\n+if test \"x${je_cv_atomic9}\" != \"xyes\" -a \"x${je_cv_osatomic}\" != \"xyes\" ; then\n+  JE_SYNC_COMPARE_AND_SWAP_CHECK(32, 4)\n+  JE_SYNC_COMPARE_AND_SWAP_CHECK(64, 8)\n+fi\n+\n+dnl ============================================================================\n+dnl Check for spinlock(3) operations as provided on Darwin.\n+\n+JE_COMPILABLE([Darwin OSSpin*()], [\n+#include <libkern/OSAtomic.h>\n+#include <inttypes.h>\n+], [\n+\tOSSpinLock lock = 0;\n+\tOSSpinLockLock(&lock);\n+\tOSSpinLockUnlock(&lock);\n+], [je_cv_osspin])\n+if test \"x${je_cv_osspin}\" = \"xyes\" ; then\n+  AC_DEFINE([JEMALLOC_OSSPIN], [ ])\n+fi\n+\n+dnl ============================================================================\n+dnl Darwin-related configuration.\n+\n+AC_ARG_ENABLE([zone-allocator],\n+  [AS_HELP_STRING([--disable-zone-allocator],\n+                  [Disable zone allocator for Darwin])],\n+[if test \"x$enable_zone_allocator\" = \"xno\" ; then\n+  enable_zone_allocator=\"0\"\n+else\n+  enable_zone_allocator=\"1\"\n+fi\n+],\n+[if test \"x${abi}\" = \"xmacho\"; then\n+  enable_zone_allocator=\"1\"\n+fi\n+]\n+)\n+AC_SUBST([enable_zone_allocator])\n+\n+if test \"x${enable_zone_allocator}\" = \"x1\" ; then\n+  if test \"x${abi}\" != \"xmacho\"; then\n+    AC_MSG_ERROR([--enable-zone-allocator is only supported on Darwin])\n+  fi\n+  AC_DEFINE([JEMALLOC_IVSALLOC], [ ])\n+  AC_DEFINE([JEMALLOC_ZONE], [ ])\n+\n+  dnl The szone version jumped from 3 to 6 between the OS X 10.5.x and 10.6\n+  dnl releases.  malloc_zone_t and malloc_introspection_t have new fields in\n+  dnl 10.6, which is the only source-level indication of the change.\n+  AC_MSG_CHECKING([malloc zone version])\n+  AC_DEFUN([JE_ZONE_PROGRAM],\n+    [AC_LANG_PROGRAM(\n+      [#include <malloc/malloc.h>],\n+      [static foo[[sizeof($1) $2 sizeof(void *) * $3 ? 1 : -1]]]\n+    )])\n+\n+  AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_zone_t,==,14)],[JEMALLOC_ZONE_VERSION=3],[\n+  AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_zone_t,==,15)],[JEMALLOC_ZONE_VERSION=5],[\n+  AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_zone_t,==,16)],[\n+    AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_introspection_t,==,9)],[JEMALLOC_ZONE_VERSION=6],[\n+    AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_introspection_t,==,13)],[JEMALLOC_ZONE_VERSION=7],[JEMALLOC_ZONE_VERSION=]\n+  )])],[\n+  AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_zone_t,==,17)],[JEMALLOC_ZONE_VERSION=8],[\n+  AC_COMPILE_IFELSE([JE_ZONE_PROGRAM(malloc_zone_t,>,17)],[JEMALLOC_ZONE_VERSION=9],[JEMALLOC_ZONE_VERSION=]\n+  )])])])])\n+  if test \"x${JEMALLOC_ZONE_VERSION}\" = \"x\"; then\n+    AC_MSG_RESULT([unsupported])\n+    AC_MSG_ERROR([Unsupported malloc zone version])\n+  fi\n+  if test \"${JEMALLOC_ZONE_VERSION}\" = 9; then\n+    JEMALLOC_ZONE_VERSION=8\n+    AC_MSG_RESULT([> 8])\n+  else\n+    AC_MSG_RESULT([$JEMALLOC_ZONE_VERSION])\n+  fi\n+  AC_DEFINE_UNQUOTED(JEMALLOC_ZONE_VERSION, [$JEMALLOC_ZONE_VERSION])\n+fi\n+\n+dnl ============================================================================\n+dnl Check for typedefs, structures, and compiler characteristics.\n+AC_HEADER_STDBOOL\n+\n+AC_CONFIG_COMMANDS([include/jemalloc/internal/size_classes.h], [\n+  mkdir -p \"include/jemalloc/internal\"\n+  \"${srcdir}/include/jemalloc/internal/size_classes.sh\" > \"${objroot}include/jemalloc/internal/size_classes.h\"\n+])\n+\n+dnl Process .in files.\n+AC_SUBST([cfghdrs_in])\n+AC_SUBST([cfghdrs_out])\n+AC_CONFIG_HEADERS([$cfghdrs_tup])\n+\n+dnl ============================================================================\n+dnl Generate outputs.\n+AC_CONFIG_FILES([$cfgoutputs_tup config.stamp bin/jemalloc.sh])\n+AC_SUBST([cfgoutputs_in])\n+AC_SUBST([cfgoutputs_out])\n+AC_OUTPUT\n+\n+dnl ============================================================================\n+dnl Print out the results of configuration.\n+AC_MSG_RESULT([===============================================================================])\n+AC_MSG_RESULT([jemalloc version   : ${jemalloc_version}])\n+AC_MSG_RESULT([library revision   : ${rev}])\n+AC_MSG_RESULT([])\n+AC_MSG_RESULT([CC                 : ${CC}])\n+AC_MSG_RESULT([CPPFLAGS           : ${CPPFLAGS}])\n+AC_MSG_RESULT([CFLAGS             : ${CFLAGS}])\n+AC_MSG_RESULT([LDFLAGS            : ${LDFLAGS}])\n+AC_MSG_RESULT([LIBS               : ${LIBS}])\n+AC_MSG_RESULT([RPATH_EXTRA        : ${RPATH_EXTRA}])\n+AC_MSG_RESULT([])\n+AC_MSG_RESULT([XSLTPROC           : ${XSLTPROC}])\n+AC_MSG_RESULT([XSLROOT            : ${XSLROOT}])\n+AC_MSG_RESULT([])\n+AC_MSG_RESULT([PREFIX             : ${PREFIX}])\n+AC_MSG_RESULT([BINDIR             : ${BINDIR}])\n+AC_MSG_RESULT([INCLUDEDIR         : ${INCLUDEDIR}])\n+AC_MSG_RESULT([LIBDIR             : ${LIBDIR}])\n+AC_MSG_RESULT([DATADIR            : ${DATADIR}])\n+AC_MSG_RESULT([MANDIR             : ${MANDIR}])\n+AC_MSG_RESULT([])\n+AC_MSG_RESULT([srcroot            : ${srcroot}])\n+AC_MSG_RESULT([abs_srcroot        : ${abs_srcroot}])\n+AC_MSG_RESULT([objroot            : ${objroot}])\n+AC_MSG_RESULT([abs_objroot        : ${abs_objroot}])\n+AC_MSG_RESULT([])\n+AC_MSG_RESULT([JEMALLOC_PREFIX    : ${JEMALLOC_PREFIX}])\n+AC_MSG_RESULT([JEMALLOC_PRIVATE_NAMESPACE])\n+AC_MSG_RESULT([                   : ${JEMALLOC_PRIVATE_NAMESPACE}])\n+AC_MSG_RESULT([install_suffix     : ${install_suffix}])\n+AC_MSG_RESULT([autogen            : ${enable_autogen}])\n+AC_MSG_RESULT([experimental       : ${enable_experimental}])\n+AC_MSG_RESULT([cc-silence         : ${enable_cc_silence}])\n+AC_MSG_RESULT([debug              : ${enable_debug}])\n+AC_MSG_RESULT([stats              : ${enable_stats}])\n+AC_MSG_RESULT([prof               : ${enable_prof}])\n+AC_MSG_RESULT([prof-libunwind     : ${enable_prof_libunwind}])\n+AC_MSG_RESULT([prof-libgcc        : ${enable_prof_libgcc}])\n+AC_MSG_RESULT([prof-gcc           : ${enable_prof_gcc}])\n+AC_MSG_RESULT([tcache             : ${enable_tcache}])\n+AC_MSG_RESULT([fill               : ${enable_fill}])\n+AC_MSG_RESULT([utrace             : ${enable_utrace}])\n+AC_MSG_RESULT([valgrind           : ${enable_valgrind}])\n+AC_MSG_RESULT([xmalloc            : ${enable_xmalloc}])\n+AC_MSG_RESULT([mremap             : ${enable_mremap}])\n+AC_MSG_RESULT([munmap             : ${enable_munmap}])\n+AC_MSG_RESULT([dss                : ${enable_dss}])\n+AC_MSG_RESULT([lazy_lock          : ${enable_lazy_lock}])\n+AC_MSG_RESULT([tls                : ${enable_tls}])\n+AC_MSG_RESULT([===============================================================================])"}, {"sha": "a91d9746f6258dab4b021d84818d4df28d43139c", "filename": "src/rt/jemalloc/doc/html.xsl.in", "status": "added", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fhtml.xsl.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fhtml.xsl.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fdoc%2Fhtml.xsl.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,4 @@\n+<xsl:stylesheet xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" version=\"1.0\">\n+  <xsl:import href=\"@XSLROOT@/html/docbook.xsl\"/>\n+  <xsl:import href=\"@abs_srcroot@doc/stylesheet.xsl\"/>\n+</xsl:stylesheet>"}, {"sha": "1462e2c2b34b957085aa31535e195954ad8d57b0", "filename": "src/rt/jemalloc/doc/jemalloc.3", "status": "added", "additions": 1482, "deletions": 0, "changes": 1482, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fjemalloc.3", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fjemalloc.3", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fdoc%2Fjemalloc.3?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,1482 @@\n+'\\\" t\n+.\\\"     Title: JEMALLOC\n+.\\\"    Author: Jason Evans\n+.\\\" Generator: DocBook XSL Stylesheets v1.76.1 <http://docbook.sf.net/>\n+.\\\"      Date: 03/06/2013\n+.\\\"    Manual: User Manual\n+.\\\"    Source: jemalloc 3.3.1-0-g9ef9d9e8c271cdf14f664b871a8f98c827714784\n+.\\\"  Language: English\n+.\\\"\n+.TH \"JEMALLOC\" \"3\" \"03/06/2013\" \"jemalloc 3.3.1-0-g9ef9d9e8c271\" \"User Manual\"\n+.\\\" -----------------------------------------------------------------\n+.\\\" * Define some portability stuff\n+.\\\" -----------------------------------------------------------------\n+.\\\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+.\\\" http://bugs.debian.org/507673\n+.\\\" http://lists.gnu.org/archive/html/groff/2009-02/msg00013.html\n+.\\\" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+.ie \\n(.g .ds Aq \\(aq\n+.el       .ds Aq '\n+.\\\" -----------------------------------------------------------------\n+.\\\" * set default formatting\n+.\\\" -----------------------------------------------------------------\n+.\\\" disable hyphenation\n+.nh\n+.\\\" disable justification (adjust text to left margin only)\n+.ad l\n+.\\\" -----------------------------------------------------------------\n+.\\\" * MAIN CONTENT STARTS HERE *\n+.\\\" -----------------------------------------------------------------\n+.SH \"NAME\"\n+jemalloc \\- general purpose memory allocation functions\n+.SH \"LIBRARY\"\n+.PP\n+This manual describes jemalloc 3\\&.3\\&.1\\-0\\-g9ef9d9e8c271cdf14f664b871a8f98c827714784\\&. More information can be found at the\n+\\m[blue]\\fBjemalloc website\\fR\\m[]\\&\\s-2\\u[1]\\d\\s+2\\&.\n+.SH \"SYNOPSIS\"\n+.sp\n+.ft B\n+.nf\n+#include <stdlib\\&.h>\n+#include <jemalloc/jemalloc\\&.h>\n+.fi\n+.ft\n+.SS \"Standard API\"\n+.HP \\w'void\\ *malloc('u\n+.BI \"void *malloc(size_t\\ \" \"size\" \");\"\n+.HP \\w'void\\ *calloc('u\n+.BI \"void *calloc(size_t\\ \" \"number\" \", size_t\\ \" \"size\" \");\"\n+.HP \\w'int\\ posix_memalign('u\n+.BI \"int posix_memalign(void\\ **\" \"ptr\" \", size_t\\ \" \"alignment\" \", size_t\\ \" \"size\" \");\"\n+.HP \\w'void\\ *aligned_alloc('u\n+.BI \"void *aligned_alloc(size_t\\ \" \"alignment\" \", size_t\\ \" \"size\" \");\"\n+.HP \\w'void\\ *realloc('u\n+.BI \"void *realloc(void\\ *\" \"ptr\" \", size_t\\ \" \"size\" \");\"\n+.HP \\w'void\\ free('u\n+.BI \"void free(void\\ *\" \"ptr\" \");\"\n+.SS \"Non\\-standard API\"\n+.HP \\w'size_t\\ malloc_usable_size('u\n+.BI \"size_t malloc_usable_size(const\\ void\\ *\" \"ptr\" \");\"\n+.HP \\w'void\\ malloc_stats_print('u\n+.BI \"void malloc_stats_print(void\\ \" \"(*write_cb)\" \"\\ (void\\ *,\\ const\\ char\\ *), void\\ *\" \"cbopaque\" \", const\\ char\\ *\" \"opts\" \");\"\n+.HP \\w'int\\ mallctl('u\n+.BI \"int mallctl(const\\ char\\ *\" \"name\" \", void\\ *\" \"oldp\" \", size_t\\ *\" \"oldlenp\" \", void\\ *\" \"newp\" \", size_t\\ \" \"newlen\" \");\"\n+.HP \\w'int\\ mallctlnametomib('u\n+.BI \"int mallctlnametomib(const\\ char\\ *\" \"name\" \", size_t\\ *\" \"mibp\" \", size_t\\ *\" \"miblenp\" \");\"\n+.HP \\w'int\\ mallctlbymib('u\n+.BI \"int mallctlbymib(const\\ size_t\\ *\" \"mib\" \", size_t\\ \" \"miblen\" \", void\\ *\" \"oldp\" \", size_t\\ *\" \"oldlenp\" \", void\\ *\" \"newp\" \", size_t\\ \" \"newlen\" \");\"\n+.HP \\w'void\\ (*malloc_message)('u\n+.BI \"void (*malloc_message)(void\\ *\" \"cbopaque\" \", const\\ char\\ *\" \"s\" \");\"\n+.PP\n+const char *\\fImalloc_conf\\fR;\n+.SS \"Experimental API\"\n+.HP \\w'int\\ allocm('u\n+.BI \"int allocm(void\\ **\" \"ptr\" \", size_t\\ *\" \"rsize\" \", size_t\\ \" \"size\" \", int\\ \" \"flags\" \");\"\n+.HP \\w'int\\ rallocm('u\n+.BI \"int rallocm(void\\ **\" \"ptr\" \", size_t\\ *\" \"rsize\" \", size_t\\ \" \"size\" \", size_t\\ \" \"extra\" \", int\\ \" \"flags\" \");\"\n+.HP \\w'int\\ sallocm('u\n+.BI \"int sallocm(const\\ void\\ *\" \"ptr\" \", size_t\\ *\" \"rsize\" \", int\\ \" \"flags\" \");\"\n+.HP \\w'int\\ dallocm('u\n+.BI \"int dallocm(void\\ *\" \"ptr\" \", int\\ \" \"flags\" \");\"\n+.HP \\w'int\\ nallocm('u\n+.BI \"int nallocm(size_t\\ *\" \"rsize\" \", size_t\\ \" \"size\" \", int\\ \" \"flags\" \");\"\n+.SH \"DESCRIPTION\"\n+.SS \"Standard API\"\n+.PP\n+The\n+\\fBmalloc\\fR\\fB\\fR\n+function allocates\n+\\fIsize\\fR\n+bytes of uninitialized memory\\&. The allocated space is suitably aligned (after possible pointer coercion) for storage of any type of object\\&.\n+.PP\n+The\n+\\fBcalloc\\fR\\fB\\fR\n+function allocates space for\n+\\fInumber\\fR\n+objects, each\n+\\fIsize\\fR\n+bytes in length\\&. The result is identical to calling\n+\\fBmalloc\\fR\\fB\\fR\n+with an argument of\n+\\fInumber\\fR\n+*\n+\\fIsize\\fR, with the exception that the allocated memory is explicitly initialized to zero bytes\\&.\n+.PP\n+The\n+\\fBposix_memalign\\fR\\fB\\fR\n+function allocates\n+\\fIsize\\fR\n+bytes of memory such that the allocation\\*(Aqs base address is an even multiple of\n+\\fIalignment\\fR, and returns the allocation in the value pointed to by\n+\\fIptr\\fR\\&. The requested\n+\\fIalignment\\fR\n+must be a power of 2 at least as large as\n+sizeof(\\fBvoid *\\fR)\\&.\n+.PP\n+The\n+\\fBaligned_alloc\\fR\\fB\\fR\n+function allocates\n+\\fIsize\\fR\n+bytes of memory such that the allocation\\*(Aqs base address is an even multiple of\n+\\fIalignment\\fR\\&. The requested\n+\\fIalignment\\fR\n+must be a power of 2\\&. Behavior is undefined if\n+\\fIsize\\fR\n+is not an integral multiple of\n+\\fIalignment\\fR\\&.\n+.PP\n+The\n+\\fBrealloc\\fR\\fB\\fR\n+function changes the size of the previously allocated memory referenced by\n+\\fIptr\\fR\n+to\n+\\fIsize\\fR\n+bytes\\&. The contents of the memory are unchanged up to the lesser of the new and old sizes\\&. If the new size is larger, the contents of the newly allocated portion of the memory are undefined\\&. Upon success, the memory referenced by\n+\\fIptr\\fR\n+is freed and a pointer to the newly allocated memory is returned\\&. Note that\n+\\fBrealloc\\fR\\fB\\fR\n+may move the memory allocation, resulting in a different return value than\n+\\fIptr\\fR\\&. If\n+\\fIptr\\fR\n+is\n+\\fBNULL\\fR, the\n+\\fBrealloc\\fR\\fB\\fR\n+function behaves identically to\n+\\fBmalloc\\fR\\fB\\fR\n+for the specified size\\&.\n+.PP\n+The\n+\\fBfree\\fR\\fB\\fR\n+function causes the allocated memory referenced by\n+\\fIptr\\fR\n+to be made available for future allocations\\&. If\n+\\fIptr\\fR\n+is\n+\\fBNULL\\fR, no action occurs\\&.\n+.SS \"Non\\-standard API\"\n+.PP\n+The\n+\\fBmalloc_usable_size\\fR\\fB\\fR\n+function returns the usable size of the allocation pointed to by\n+\\fIptr\\fR\\&. The return value may be larger than the size that was requested during allocation\\&. The\n+\\fBmalloc_usable_size\\fR\\fB\\fR\n+function is not a mechanism for in\\-place\n+\\fBrealloc\\fR\\fB\\fR; rather it is provided solely as a tool for introspection purposes\\&. Any discrepancy between the requested allocation size and the size reported by\n+\\fBmalloc_usable_size\\fR\\fB\\fR\n+should not be depended on, since such behavior is entirely implementation\\-dependent\\&.\n+.PP\n+The\n+\\fBmalloc_stats_print\\fR\\fB\\fR\n+function writes human\\-readable summary statistics via the\n+\\fIwrite_cb\\fR\n+callback function pointer and\n+\\fIcbopaque\\fR\n+data passed to\n+\\fIwrite_cb\\fR, or\n+\\fBmalloc_message\\fR\\fB\\fR\n+if\n+\\fIwrite_cb\\fR\n+is\n+\\fBNULL\\fR\\&. This function can be called repeatedly\\&. General information that never changes during execution can be omitted by specifying \"g\" as a character within the\n+\\fIopts\\fR\n+string\\&. Note that\n+\\fBmalloc_message\\fR\\fB\\fR\n+uses the\n+\\fBmallctl*\\fR\\fB\\fR\n+functions internally, so inconsistent statistics can be reported if multiple threads use these functions simultaneously\\&. If\n+\\fB\\-\\-enable\\-stats\\fR\n+is specified during configuration, \\(lqm\\(rq and \\(lqa\\(rq can be specified to omit merged arena and per arena statistics, respectively; \\(lqb\\(rq and \\(lql\\(rq can be specified to omit per size class statistics for bins and large objects, respectively\\&. Unrecognized characters are silently ignored\\&. Note that thread caching may prevent some statistics from being completely up to date, since extra locking would be required to merge counters that track thread cache operations\\&.\n+.PP\n+The\n+\\fBmallctl\\fR\\fB\\fR\n+function provides a general interface for introspecting the memory allocator, as well as setting modifiable parameters and triggering actions\\&. The period\\-separated\n+\\fIname\\fR\n+argument specifies a location in a tree\\-structured namespace; see the\n+MALLCTL NAMESPACE\n+section for documentation on the tree contents\\&. To read a value, pass a pointer via\n+\\fIoldp\\fR\n+to adequate space to contain the value, and a pointer to its length via\n+\\fIoldlenp\\fR; otherwise pass\n+\\fBNULL\\fR\n+and\n+\\fBNULL\\fR\\&. Similarly, to write a value, pass a pointer to the value via\n+\\fInewp\\fR, and its length via\n+\\fInewlen\\fR; otherwise pass\n+\\fBNULL\\fR\n+and\n+\\fB0\\fR\\&.\n+.PP\n+The\n+\\fBmallctlnametomib\\fR\\fB\\fR\n+function provides a way to avoid repeated name lookups for applications that repeatedly query the same portion of the namespace, by translating a name to a \\(lqManagement Information Base\\(rq (MIB) that can be passed repeatedly to\n+\\fBmallctlbymib\\fR\\fB\\fR\\&. Upon successful return from\n+\\fBmallctlnametomib\\fR\\fB\\fR,\n+\\fImibp\\fR\n+contains an array of\n+\\fI*miblenp\\fR\n+integers, where\n+\\fI*miblenp\\fR\n+is the lesser of the number of components in\n+\\fIname\\fR\n+and the input value of\n+\\fI*miblenp\\fR\\&. Thus it is possible to pass a\n+\\fI*miblenp\\fR\n+that is smaller than the number of period\\-separated name components, which results in a partial MIB that can be used as the basis for constructing a complete MIB\\&. For name components that are integers (e\\&.g\\&. the 2 in\n+\"arenas\\&.bin\\&.2\\&.size\"), the corresponding MIB component will always be that integer\\&. Therefore, it is legitimate to construct code like the following:\n+.sp\n+.if n \\{\\\n+.RS 4\n+.\\}\n+.nf\n+unsigned nbins, i;\n+\n+int mib[4];\n+size_t len, miblen;\n+\n+len = sizeof(nbins);\n+mallctl(\"arenas\\&.nbins\", &nbins, &len, NULL, 0);\n+\n+miblen = 4;\n+mallnametomib(\"arenas\\&.bin\\&.0\\&.size\", mib, &miblen);\n+for (i = 0; i < nbins; i++) {\n+\tsize_t bin_size;\n+\n+\tmib[2] = i;\n+\tlen = sizeof(bin_size);\n+\tmallctlbymib(mib, miblen, &bin_size, &len, NULL, 0);\n+\t/* Do something with bin_size\\&.\\&.\\&. */\n+}\n+.fi\n+.if n \\{\\\n+.RE\n+.\\}\n+.SS \"Experimental API\"\n+.PP\n+The experimental API is subject to change or removal without regard for backward compatibility\\&. If\n+\\fB\\-\\-disable\\-experimental\\fR\n+is specified during configuration, the experimental API is omitted\\&.\n+.PP\n+The\n+\\fBallocm\\fR\\fB\\fR,\n+\\fBrallocm\\fR\\fB\\fR,\n+\\fBsallocm\\fR\\fB\\fR,\n+\\fBdallocm\\fR\\fB\\fR, and\n+\\fBnallocm\\fR\\fB\\fR\n+functions all have a\n+\\fIflags\\fR\n+argument that can be used to specify options\\&. The functions only check the options that are contextually relevant\\&. Use bitwise or (|) operations to specify one or more of the following:\n+.PP\n+\\fBALLOCM_LG_ALIGN(\\fR\\fB\\fIla\\fR\\fR\\fB) \\fR\n+.RS 4\n+Align the memory allocation to start at an address that is a multiple of\n+(1 << \\fIla\\fR)\\&. This macro does not validate that\n+\\fIla\\fR\n+is within the valid range\\&.\n+.RE\n+.PP\n+\\fBALLOCM_ALIGN(\\fR\\fB\\fIa\\fR\\fR\\fB) \\fR\n+.RS 4\n+Align the memory allocation to start at an address that is a multiple of\n+\\fIa\\fR, where\n+\\fIa\\fR\n+is a power of two\\&. This macro does not validate that\n+\\fIa\\fR\n+is a power of 2\\&.\n+.RE\n+.PP\n+\\fBALLOCM_ZERO\\fR\n+.RS 4\n+Initialize newly allocated memory to contain zero bytes\\&. In the growing reallocation case, the real size prior to reallocation defines the boundary between untouched bytes and those that are initialized to contain zero bytes\\&. If this option is absent, newly allocated memory is uninitialized\\&.\n+.RE\n+.PP\n+\\fBALLOCM_NO_MOVE\\fR\n+.RS 4\n+For reallocation, fail rather than moving the object\\&. This constraint can apply to both growth and shrinkage\\&.\n+.RE\n+.PP\n+\\fBALLOCM_ARENA(\\fR\\fB\\fIa\\fR\\fR\\fB) \\fR\n+.RS 4\n+Use the arena specified by the index\n+\\fIa\\fR\\&. This macro does not validate that\n+\\fIa\\fR\n+specifies an arena in the valid range\\&.\n+.RE\n+.PP\n+The\n+\\fBallocm\\fR\\fB\\fR\n+function allocates at least\n+\\fIsize\\fR\n+bytes of memory, sets\n+\\fI*ptr\\fR\n+to the base address of the allocation, and sets\n+\\fI*rsize\\fR\n+to the real size of the allocation if\n+\\fIrsize\\fR\n+is not\n+\\fBNULL\\fR\\&. Behavior is undefined if\n+\\fIsize\\fR\n+is\n+\\fB0\\fR\\&.\n+.PP\n+The\n+\\fBrallocm\\fR\\fB\\fR\n+function resizes the allocation at\n+\\fI*ptr\\fR\n+to be at least\n+\\fIsize\\fR\n+bytes, sets\n+\\fI*ptr\\fR\n+to the base address of the allocation if it moved, and sets\n+\\fI*rsize\\fR\n+to the real size of the allocation if\n+\\fIrsize\\fR\n+is not\n+\\fBNULL\\fR\\&. If\n+\\fIextra\\fR\n+is non\\-zero, an attempt is made to resize the allocation to be at least\n+\\fIsize\\fR + \\fIextra\\fR)\n+bytes, though inability to allocate the extra byte(s) will not by itself result in failure\\&. Behavior is undefined if\n+\\fIsize\\fR\n+is\n+\\fB0\\fR, or if\n+(\\fIsize\\fR + \\fIextra\\fR > \\fBSIZE_T_MAX\\fR)\\&.\n+.PP\n+The\n+\\fBsallocm\\fR\\fB\\fR\n+function sets\n+\\fI*rsize\\fR\n+to the real size of the allocation\\&.\n+.PP\n+The\n+\\fBdallocm\\fR\\fB\\fR\n+function causes the memory referenced by\n+\\fIptr\\fR\n+to be made available for future allocations\\&.\n+.PP\n+The\n+\\fBnallocm\\fR\\fB\\fR\n+function allocates no memory, but it performs the same size computation as the\n+\\fBallocm\\fR\\fB\\fR\n+function, and if\n+\\fIrsize\\fR\n+is not\n+\\fBNULL\\fR\n+it sets\n+\\fI*rsize\\fR\n+to the real size of the allocation that would result from the equivalent\n+\\fBallocm\\fR\\fB\\fR\n+function call\\&. Behavior is undefined if\n+\\fIsize\\fR\n+is\n+\\fB0\\fR\\&.\n+.SH \"TUNING\"\n+.PP\n+Once, when the first call is made to one of the memory allocation routines, the allocator initializes its internals based in part on various options that can be specified at compile\\- or run\\-time\\&.\n+.PP\n+The string pointed to by the global variable\n+\\fImalloc_conf\\fR, the \\(lqname\\(rq of the file referenced by the symbolic link named\n+/etc/malloc\\&.conf, and the value of the environment variable\n+\\fBMALLOC_CONF\\fR, will be interpreted, in that order, from left to right as options\\&.\n+.PP\n+An options string is a comma\\-separated list of option:value pairs\\&. There is one key corresponding to each\n+\"opt\\&.*\"\n+mallctl (see the\n+MALLCTL NAMESPACE\n+section for options documentation)\\&. For example,\n+abort:true,narenas:1\n+sets the\n+\"opt\\&.abort\"\n+and\n+\"opt\\&.narenas\"\n+options\\&. Some options have boolean values (true/false), others have integer values (base 8, 10, or 16, depending on prefix), and yet others have raw string values\\&.\n+.SH \"IMPLEMENTATION NOTES\"\n+.PP\n+Traditionally, allocators have used\n+\\fBsbrk\\fR(2)\n+to obtain memory, which is suboptimal for several reasons, including race conditions, increased fragmentation, and artificial limitations on maximum usable memory\\&. If\n+\\fB\\-\\-enable\\-dss\\fR\n+is specified during configuration, this allocator uses both\n+\\fBmmap\\fR(2)\n+and\n+\\fBsbrk\\fR(2), in that order of preference; otherwise only\n+\\fBmmap\\fR(2)\n+is used\\&.\n+.PP\n+This allocator uses multiple arenas in order to reduce lock contention for threaded programs on multi\\-processor systems\\&. This works well with regard to threading scalability, but incurs some costs\\&. There is a small fixed per\\-arena overhead, and additionally, arenas manage memory completely independently of each other, which means a small fixed increase in overall memory fragmentation\\&. These overheads are not generally an issue, given the number of arenas normally used\\&. Note that using substantially more arenas than the default is not likely to improve performance, mainly due to reduced cache performance\\&. However, it may make sense to reduce the number of arenas if an application does not make much use of the allocation functions\\&.\n+.PP\n+In addition to multiple arenas, unless\n+\\fB\\-\\-disable\\-tcache\\fR\n+is specified during configuration, this allocator supports thread\\-specific caching for small and large objects, in order to make it possible to completely avoid synchronization for most allocation requests\\&. Such caching allows very fast allocation in the common case, but it increases memory usage and fragmentation, since a bounded number of objects can remain allocated in each thread cache\\&.\n+.PP\n+Memory is conceptually broken into equal\\-sized chunks, where the chunk size is a power of two that is greater than the page size\\&. Chunks are always aligned to multiples of the chunk size\\&. This alignment makes it possible to find metadata for user objects very quickly\\&.\n+.PP\n+User objects are broken into three categories according to size: small, large, and huge\\&. Small objects are smaller than one page\\&. Large objects are smaller than the chunk size\\&. Huge objects are a multiple of the chunk size\\&. Small and large objects are managed by arenas; huge objects are managed separately in a single data structure that is shared by all threads\\&. Huge objects are used by applications infrequently enough that this single data structure is not a scalability issue\\&.\n+.PP\n+Each chunk that is managed by an arena tracks its contents as runs of contiguous pages (unused, backing a set of small objects, or backing one large object)\\&. The combination of chunk alignment and chunk page maps makes it possible to determine all metadata regarding small and large allocations in constant time\\&.\n+.PP\n+Small objects are managed in groups by page runs\\&. Each run maintains a frontier and free list to track which regions are in use\\&. Allocation requests that are no more than half the quantum (8 or 16, depending on architecture) are rounded up to the nearest power of two that is at least\n+sizeof(\\fBdouble\\fR)\\&. All other small object size classes are multiples of the quantum, spaced such that internal fragmentation is limited to approximately 25% for all but the smallest size classes\\&. Allocation requests that are larger than the maximum small size class, but small enough to fit in an arena\\-managed chunk (see the\n+\"opt\\&.lg_chunk\"\n+option), are rounded up to the nearest run size\\&. Allocation requests that are too large to fit in an arena\\-managed chunk are rounded up to the nearest multiple of the chunk size\\&.\n+.PP\n+Allocations are packed tightly together, which can be an issue for multi\\-threaded applications\\&. If you need to assure that allocations do not suffer from cacheline sharing, round your allocation requests up to the nearest multiple of the cacheline size, or specify cacheline alignment when allocating\\&.\n+.PP\n+Assuming 4 MiB chunks, 4 KiB pages, and a 16\\-byte quantum on a 64\\-bit system, the size classes in each category are as shown in\n+Table 1\\&.\n+.sp\n+.it 1 an-trap\n+.nr an-no-space-flag 1\n+.nr an-break-flag 1\n+.br\n+.B Table\\ \\&1.\\ \\&Size classes\n+.TS\n+allbox tab(:);\n+lB rB lB.\n+T{\n+Category\n+T}:T{\n+Spacing\n+T}:T{\n+Size\n+T}\n+.T&\n+l r l\n+^ r l\n+^ r l\n+^ r l\n+^ r l\n+^ r l\n+^ r l\n+l r l\n+l r l.\n+T{\n+Small\n+T}:T{\n+lg\n+T}:T{\n+[8]\n+T}\n+:T{\n+16\n+T}:T{\n+[16, 32, 48, \\&.\\&.\\&., 128]\n+T}\n+:T{\n+32\n+T}:T{\n+[160, 192, 224, 256]\n+T}\n+:T{\n+64\n+T}:T{\n+[320, 384, 448, 512]\n+T}\n+:T{\n+128\n+T}:T{\n+[640, 768, 896, 1024]\n+T}\n+:T{\n+256\n+T}:T{\n+[1280, 1536, 1792, 2048]\n+T}\n+:T{\n+512\n+T}:T{\n+[2560, 3072, 3584]\n+T}\n+T{\n+Large\n+T}:T{\n+4 KiB\n+T}:T{\n+[4 KiB, 8 KiB, 12 KiB, \\&.\\&.\\&., 4072 KiB]\n+T}\n+T{\n+Huge\n+T}:T{\n+4 MiB\n+T}:T{\n+[4 MiB, 8 MiB, 12 MiB, \\&.\\&.\\&.]\n+T}\n+.TE\n+.sp 1\n+.SH \"MALLCTL NAMESPACE\"\n+.PP\n+The following names are defined in the namespace accessible via the\n+\\fBmallctl*\\fR\\fB\\fR\n+functions\\&. Value types are specified in parentheses, their readable/writable statuses are encoded as\n+rw,\n+r\\-,\n+\\-w, or\n+\\-\\-, and required build configuration flags follow, if any\\&. A name element encoded as\n+<i>\n+or\n+<j>\n+indicates an integer component, where the integer varies from 0 to some upper value that must be determined via introspection\\&. In the case of\n+\"stats\\&.arenas\\&.<i>\\&.*\",\n+<i>\n+equal to\n+\"arenas\\&.narenas\"\n+can be used to access the summation of statistics from all arenas\\&. Take special note of the\n+\"epoch\"\n+mallctl, which controls refreshing of cached dynamic statistics\\&.\n+.PP\n+\"version\" (\\fBconst char *\\fR) r\\-\n+.RS 4\n+Return the jemalloc version string\\&.\n+.RE\n+.PP\n+\"epoch\" (\\fBuint64_t\\fR) rw\n+.RS 4\n+If a value is passed in, refresh the data from which the\n+\\fBmallctl*\\fR\\fB\\fR\n+functions report values, and increment the epoch\\&. Return the current epoch\\&. This is useful for detecting whether another thread caused a refresh\\&.\n+.RE\n+.PP\n+\"config\\&.debug\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-debug\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.dss\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-dss\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.fill\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-fill\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.lazy_lock\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-lazy\\-lock\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.mremap\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-mremap\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.munmap\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-munmap\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.prof\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-prof\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.prof_libgcc\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-disable\\-prof\\-libgcc\\fR\n+was not specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.prof_libunwind\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-prof\\-libunwind\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.stats\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-stats\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.tcache\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-disable\\-tcache\\fR\n+was not specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.tls\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-disable\\-tls\\fR\n+was not specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.utrace\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-utrace\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.valgrind\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-valgrind\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"config\\&.xmalloc\" (\\fBbool\\fR) r\\-\n+.RS 4\n+\\fB\\-\\-enable\\-xmalloc\\fR\n+was specified during build configuration\\&.\n+.RE\n+.PP\n+\"opt\\&.abort\" (\\fBbool\\fR) r\\-\n+.RS 4\n+Abort\\-on\\-warning enabled/disabled\\&. If true, most warnings are fatal\\&. The process will call\n+\\fBabort\\fR(3)\n+in these cases\\&. This option is disabled by default unless\n+\\fB\\-\\-enable\\-debug\\fR\n+is specified during configuration, in which case it is enabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.lg_chunk\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Virtual memory chunk size (log base 2)\\&. If a chunk size outside the supported size range is specified, the size is silently clipped to the minimum/maximum supported size\\&. The default chunk size is 4 MiB (2^22)\\&.\n+.RE\n+.PP\n+\"opt\\&.dss\" (\\fBconst char *\\fR) r\\-\n+.RS 4\n+dss (\\fBsbrk\\fR(2)) allocation precedence as related to\n+\\fBmmap\\fR(2)\n+allocation\\&. The following settings are supported: \\(lqdisabled\\(rq, \\(lqprimary\\(rq, and \\(lqsecondary\\(rq (default)\\&.\n+.RE\n+.PP\n+\"opt\\&.narenas\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Maximum number of arenas to use for automatic multiplexing of threads and arenas\\&. The default is four times the number of CPUs, or one if there is a single CPU\\&.\n+.RE\n+.PP\n+\"opt\\&.lg_dirty_mult\" (\\fBssize_t\\fR) r\\-\n+.RS 4\n+Per\\-arena minimum ratio (log base 2) of active to dirty pages\\&. Some dirty unused pages may be allowed to accumulate, within the limit set by the ratio (or one chunk worth of dirty pages, whichever is greater), before informing the kernel about some of those pages via\n+\\fBmadvise\\fR(2)\n+or a similar system call\\&. This provides the kernel with sufficient information to recycle dirty pages if physical memory becomes scarce and the pages remain unused\\&. The default minimum ratio is 8:1 (2^3:1); an option value of \\-1 will disable dirty page purging\\&.\n+.RE\n+.PP\n+\"opt\\&.stats_print\" (\\fBbool\\fR) r\\-\n+.RS 4\n+Enable/disable statistics printing at exit\\&. If enabled, the\n+\\fBmalloc_stats_print\\fR\\fB\\fR\n+function is called at program exit via an\n+\\fBatexit\\fR(3)\n+function\\&. If\n+\\fB\\-\\-enable\\-stats\\fR\n+is specified during configuration, this has the potential to cause deadlock for a multi\\-threaded process that exits while one or more threads are executing in the memory allocation functions\\&. Therefore, this option should only be used with care; it is primarily intended as a performance tuning aid during application development\\&. This option is disabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.junk\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-fill\\fR]\n+.RS 4\n+Junk filling enabled/disabled\\&. If enabled, each byte of uninitialized allocated memory will be initialized to\n+0xa5\\&. All deallocated memory will be initialized to\n+0x5a\\&. This is intended for debugging and will impact performance negatively\\&. This option is disabled by default unless\n+\\fB\\-\\-enable\\-debug\\fR\n+is specified during configuration, in which case it is enabled by default unless running inside\n+\\m[blue]\\fBValgrind\\fR\\m[]\\&\\s-2\\u[2]\\d\\s+2\\&.\n+.RE\n+.PP\n+\"opt\\&.quarantine\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-fill\\fR]\n+.RS 4\n+Per thread quarantine size in bytes\\&. If non\\-zero, each thread maintains a FIFO object quarantine that stores up to the specified number of bytes of memory\\&. The quarantined memory is not freed until it is released from quarantine, though it is immediately junk\\-filled if the\n+\"opt\\&.junk\"\n+option is enabled\\&. This feature is of particular use in combination with\n+\\m[blue]\\fBValgrind\\fR\\m[]\\&\\s-2\\u[2]\\d\\s+2, which can detect attempts to access quarantined objects\\&. This is intended for debugging and will impact performance negatively\\&. The default quarantine size is 0 unless running inside Valgrind, in which case the default is 16 MiB\\&.\n+.RE\n+.PP\n+\"opt\\&.redzone\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-fill\\fR]\n+.RS 4\n+Redzones enabled/disabled\\&. If enabled, small allocations have redzones before and after them\\&. Furthermore, if the\n+\"opt\\&.junk\"\n+option is enabled, the redzones are checked for corruption during deallocation\\&. However, the primary intended purpose of this feature is to be used in combination with\n+\\m[blue]\\fBValgrind\\fR\\m[]\\&\\s-2\\u[2]\\d\\s+2, which needs redzones in order to do effective buffer overflow/underflow detection\\&. This option is intended for debugging and will impact performance negatively\\&. This option is disabled by default unless running inside Valgrind\\&.\n+.RE\n+.PP\n+\"opt\\&.zero\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-fill\\fR]\n+.RS 4\n+Zero filling enabled/disabled\\&. If enabled, each byte of uninitialized allocated memory will be initialized to 0\\&. Note that this initialization only happens once for each byte, so\n+\\fBrealloc\\fR\\fB\\fR\n+and\n+\\fBrallocm\\fR\\fB\\fR\n+calls do not zero memory that was previously allocated\\&. This is intended for debugging and will impact performance negatively\\&. This option is disabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.utrace\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-utrace\\fR]\n+.RS 4\n+Allocation tracing based on\n+\\fButrace\\fR(2)\n+enabled/disabled\\&. This option is disabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.valgrind\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-valgrind\\fR]\n+.RS 4\n+\\m[blue]\\fBValgrind\\fR\\m[]\\&\\s-2\\u[2]\\d\\s+2\n+support enabled/disabled\\&. This option is vestigal because jemalloc auto\\-detects whether it is running inside Valgrind\\&. This option is disabled by default, unless running inside Valgrind\\&.\n+.RE\n+.PP\n+\"opt\\&.xmalloc\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-xmalloc\\fR]\n+.RS 4\n+Abort\\-on\\-out\\-of\\-memory enabled/disabled\\&. If enabled, rather than returning failure for any allocation function, display a diagnostic message on\n+\\fBSTDERR_FILENO\\fR\n+and cause the program to drop core (using\n+\\fBabort\\fR(3))\\&. If an application is designed to depend on this behavior, set the option at compile time by including the following in the source code:\n+.sp\n+.if n \\{\\\n+.RS 4\n+.\\}\n+.nf\n+malloc_conf = \"xmalloc:true\";\n+.fi\n+.if n \\{\\\n+.RE\n+.\\}\n+.sp\n+This option is disabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.tcache\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Thread\\-specific caching enabled/disabled\\&. When there are multiple threads, each thread uses a thread\\-specific cache for objects up to a certain size\\&. Thread\\-specific caching allows many allocations to be satisfied without performing any thread synchronization, at the cost of increased memory use\\&. See the\n+\"opt\\&.lg_tcache_max\"\n+option for related tuning information\\&. This option is enabled by default unless running inside\n+\\m[blue]\\fBValgrind\\fR\\m[]\\&\\s-2\\u[2]\\d\\s+2\\&.\n+.RE\n+.PP\n+\"opt\\&.lg_tcache_max\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Maximum size class (log base 2) to cache in the thread\\-specific cache\\&. At a minimum, all small size classes are cached, and at a maximum all large size classes are cached\\&. The default maximum is 32 KiB (2^15)\\&.\n+.RE\n+.PP\n+\"opt\\&.prof\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Memory profiling enabled/disabled\\&. If enabled, profile memory allocation activity\\&. See the\n+\"opt\\&.prof_active\"\n+option for on\\-the\\-fly activation/deactivation\\&. See the\n+\"opt\\&.lg_prof_sample\"\n+option for probabilistic sampling control\\&. See the\n+\"opt\\&.prof_accum\"\n+option for control of cumulative sample reporting\\&. See the\n+\"opt\\&.lg_prof_interval\"\n+option for information on interval\\-triggered profile dumping, the\n+\"opt\\&.prof_gdump\"\n+option for information on high\\-water\\-triggered profile dumping, and the\n+\"opt\\&.prof_final\"\n+option for final profile dumping\\&. Profile output is compatible with the included\n+\\fBpprof\\fR\n+Perl script, which originates from the\n+\\m[blue]\\fBgperftools package\\fR\\m[]\\&\\s-2\\u[3]\\d\\s+2\\&.\n+.RE\n+.PP\n+\"opt\\&.prof_prefix\" (\\fBconst char *\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Filename prefix for profile dumps\\&. If the prefix is set to the empty string, no automatic dumps will occur; this is primarily useful for disabling the automatic final heap dump (which also disables leak reporting, if enabled)\\&. The default prefix is\n+jeprof\\&.\n+.RE\n+.PP\n+\"opt\\&.prof_active\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Profiling activated/deactivated\\&. This is a secondary control mechanism that makes it possible to start the application with profiling enabled (see the\n+\"opt\\&.prof\"\n+option) but inactive, then toggle profiling at any time during program execution with the\n+\"prof\\&.active\"\n+mallctl\\&. This option is enabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.lg_prof_sample\" (\\fBssize_t\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Average interval (log base 2) between allocation samples, as measured in bytes of allocation activity\\&. Increasing the sampling interval decreases profile fidelity, but also decreases the computational overhead\\&. The default sample interval is 512 KiB (2^19 B)\\&.\n+.RE\n+.PP\n+\"opt\\&.prof_accum\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Reporting of cumulative object/byte counts in profile dumps enabled/disabled\\&. If this option is enabled, every unique backtrace must be stored for the duration of execution\\&. Depending on the application, this can impose a large memory overhead, and the cumulative counts are not always of interest\\&. This option is disabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.lg_prof_interval\" (\\fBssize_t\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Average interval (log base 2) between memory profile dumps, as measured in bytes of allocation activity\\&. The actual interval between dumps may be sporadic because decentralized allocation counters are used to avoid synchronization bottlenecks\\&. Profiles are dumped to files named according to the pattern\n+<prefix>\\&.<pid>\\&.<seq>\\&.i<iseq>\\&.heap, where\n+<prefix>\n+is controlled by the\n+\"opt\\&.prof_prefix\"\n+option\\&. By default, interval\\-triggered profile dumping is disabled (encoded as \\-1)\\&.\n+.RE\n+.PP\n+\"opt\\&.prof_gdump\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Trigger a memory profile dump every time the total virtual memory exceeds the previous maximum\\&. Profiles are dumped to files named according to the pattern\n+<prefix>\\&.<pid>\\&.<seq>\\&.u<useq>\\&.heap, where\n+<prefix>\n+is controlled by the\n+\"opt\\&.prof_prefix\"\n+option\\&. This option is disabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.prof_final\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Use an\n+\\fBatexit\\fR(3)\n+function to dump final memory usage to a file named according to the pattern\n+<prefix>\\&.<pid>\\&.<seq>\\&.f\\&.heap, where\n+<prefix>\n+is controlled by the\n+\"opt\\&.prof_prefix\"\n+option\\&. This option is enabled by default\\&.\n+.RE\n+.PP\n+\"opt\\&.prof_leak\" (\\fBbool\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Leak reporting enabled/disabled\\&. If enabled, use an\n+\\fBatexit\\fR(3)\n+function to report memory leaks detected by allocation sampling\\&. See the\n+\"opt\\&.prof\"\n+option for information on analyzing heap profile output\\&. This option is disabled by default\\&.\n+.RE\n+.PP\n+\"thread\\&.arena\" (\\fBunsigned\\fR) rw\n+.RS 4\n+Get or set the arena associated with the calling thread\\&. If the specified arena was not initialized beforehand (see the\n+\"arenas\\&.initialized\"\n+mallctl), it will be automatically initialized as a side effect of calling this interface\\&.\n+.RE\n+.PP\n+\"thread\\&.allocated\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Get the total number of bytes ever allocated by the calling thread\\&. This counter has the potential to wrap around; it is up to the application to appropriately interpret the counter in such cases\\&.\n+.RE\n+.PP\n+\"thread\\&.allocatedp\" (\\fBuint64_t *\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Get a pointer to the the value that is returned by the\n+\"thread\\&.allocated\"\n+mallctl\\&. This is useful for avoiding the overhead of repeated\n+\\fBmallctl*\\fR\\fB\\fR\n+calls\\&.\n+.RE\n+.PP\n+\"thread\\&.deallocated\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Get the total number of bytes ever deallocated by the calling thread\\&. This counter has the potential to wrap around; it is up to the application to appropriately interpret the counter in such cases\\&.\n+.RE\n+.PP\n+\"thread\\&.deallocatedp\" (\\fBuint64_t *\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Get a pointer to the the value that is returned by the\n+\"thread\\&.deallocated\"\n+mallctl\\&. This is useful for avoiding the overhead of repeated\n+\\fBmallctl*\\fR\\fB\\fR\n+calls\\&.\n+.RE\n+.PP\n+\"thread\\&.tcache\\&.enabled\" (\\fBbool\\fR) rw [\\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Enable/disable calling thread\\*(Aqs tcache\\&. The tcache is implicitly flushed as a side effect of becoming disabled (see\n+\"thread\\&.tcache\\&.flush\")\\&.\n+.RE\n+.PP\n+\"thread\\&.tcache\\&.flush\" (\\fBvoid\\fR) \\-\\- [\\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Flush calling thread\\*(Aqs tcache\\&. This interface releases all cached objects and internal data structures associated with the calling thread\\*(Aqs thread\\-specific cache\\&. Ordinarily, this interface need not be called, since automatic periodic incremental garbage collection occurs, and the thread cache is automatically discarded when a thread exits\\&. However, garbage collection is triggered by allocation activity, so it is possible for a thread that stops allocating/deallocating to retain its cache indefinitely, in which case the developer may find manual flushing useful\\&.\n+.RE\n+.PP\n+\"arena\\&.<i>\\&.purge\" (\\fBunsigned\\fR) \\-\\-\n+.RS 4\n+Purge unused dirty pages for arena <i>, or for all arenas if <i> equals\n+\"arenas\\&.narenas\"\\&.\n+.RE\n+.PP\n+\"arena\\&.<i>\\&.dss\" (\\fBconst char *\\fR) rw\n+.RS 4\n+Set the precedence of dss allocation as related to mmap allocation for arena <i>, or for all arenas if <i> equals\n+\"arenas\\&.narenas\"\\&. See\n+\"opt\\&.dss\"\n+for supported settings\\&.\n+.RE\n+.PP\n+\"arenas\\&.narenas\" (\\fBunsigned\\fR) r\\-\n+.RS 4\n+Current limit on number of arenas\\&.\n+.RE\n+.PP\n+\"arenas\\&.initialized\" (\\fBbool *\\fR) r\\-\n+.RS 4\n+An array of\n+\"arenas\\&.narenas\"\n+booleans\\&. Each boolean indicates whether the corresponding arena is initialized\\&.\n+.RE\n+.PP\n+\"arenas\\&.quantum\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Quantum size\\&.\n+.RE\n+.PP\n+\"arenas\\&.page\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Page size\\&.\n+.RE\n+.PP\n+\"arenas\\&.tcache_max\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Maximum thread\\-cached size class\\&.\n+.RE\n+.PP\n+\"arenas\\&.nbins\" (\\fBunsigned\\fR) r\\-\n+.RS 4\n+Number of bin size classes\\&.\n+.RE\n+.PP\n+\"arenas\\&.nhbins\" (\\fBunsigned\\fR) r\\- [\\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Total number of thread cache bin size classes\\&.\n+.RE\n+.PP\n+\"arenas\\&.bin\\&.<i>\\&.size\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Maximum size supported by size class\\&.\n+.RE\n+.PP\n+\"arenas\\&.bin\\&.<i>\\&.nregs\" (\\fBuint32_t\\fR) r\\-\n+.RS 4\n+Number of regions per page run\\&.\n+.RE\n+.PP\n+\"arenas\\&.bin\\&.<i>\\&.run_size\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Number of bytes per page run\\&.\n+.RE\n+.PP\n+\"arenas\\&.nlruns\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Total number of large size classes\\&.\n+.RE\n+.PP\n+\"arenas\\&.lrun\\&.<i>\\&.size\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Maximum size supported by this large size class\\&.\n+.RE\n+.PP\n+\"arenas\\&.purge\" (\\fBunsigned\\fR) \\-w\n+.RS 4\n+Purge unused dirty pages for the specified arena, or for all arenas if none is specified\\&.\n+.RE\n+.PP\n+\"arenas\\&.extend\" (\\fBunsigned\\fR) r\\-\n+.RS 4\n+Extend the array of arenas by appending a new arena, and returning the new arena index\\&.\n+.RE\n+.PP\n+\"prof\\&.active\" (\\fBbool\\fR) rw [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Control whether sampling is currently active\\&. See the\n+\"opt\\&.prof_active\"\n+option for additional information\\&.\n+.RE\n+.PP\n+\"prof\\&.dump\" (\\fBconst char *\\fR) \\-w [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Dump a memory profile to the specified file, or if NULL is specified, to a file according to the pattern\n+<prefix>\\&.<pid>\\&.<seq>\\&.m<mseq>\\&.heap, where\n+<prefix>\n+is controlled by the\n+\"opt\\&.prof_prefix\"\n+option\\&.\n+.RE\n+.PP\n+\"prof\\&.interval\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-prof\\fR]\n+.RS 4\n+Average number of bytes allocated between inverval\\-based profile dumps\\&. See the\n+\"opt\\&.lg_prof_interval\"\n+option for additional information\\&.\n+.RE\n+.PP\n+\"stats\\&.cactive\" (\\fBsize_t *\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Pointer to a counter that contains an approximate count of the current number of bytes in active pages\\&. The estimate may be high, but never low, because each arena rounds up to the nearest multiple of the chunk size when computing its contribution to the counter\\&. Note that the\n+\"epoch\"\n+mallctl has no bearing on this counter\\&. Furthermore, counter consistency is maintained via atomic operations, so it is necessary to use an atomic operation in order to guarantee a consistent read when dereferencing the pointer\\&.\n+.RE\n+.PP\n+\"stats\\&.allocated\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Total number of bytes allocated by the application\\&.\n+.RE\n+.PP\n+\"stats\\&.active\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Total number of bytes in active pages allocated by the application\\&. This is a multiple of the page size, and greater than or equal to\n+\"stats\\&.allocated\"\\&. This does not include\n+\"stats\\&.arenas\\&.<i>\\&.pdirty\"\n+and pages entirely devoted to allocator metadata\\&.\n+.RE\n+.PP\n+\"stats\\&.mapped\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Total number of bytes in chunks mapped on behalf of the application\\&. This is a multiple of the chunk size, and is at least as large as\n+\"stats\\&.active\"\\&. This does not include inactive chunks\\&.\n+.RE\n+.PP\n+\"stats\\&.chunks\\&.current\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Total number of chunks actively mapped on behalf of the application\\&. This does not include inactive chunks\\&.\n+.RE\n+.PP\n+\"stats\\&.chunks\\&.total\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of chunks allocated\\&.\n+.RE\n+.PP\n+\"stats\\&.chunks\\&.high\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Maximum number of active chunks at any time thus far\\&.\n+.RE\n+.PP\n+\"stats\\&.huge\\&.allocated\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of bytes currently allocated by huge objects\\&.\n+.RE\n+.PP\n+\"stats\\&.huge\\&.nmalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of huge allocation requests\\&.\n+.RE\n+.PP\n+\"stats\\&.huge\\&.ndalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of huge deallocation requests\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.dss\" (\\fBconst char *\\fR) r\\-\n+.RS 4\n+dss (\\fBsbrk\\fR(2)) allocation precedence as related to\n+\\fBmmap\\fR(2)\n+allocation\\&. See\n+\"opt\\&.dss\"\n+for details\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.nthreads\" (\\fBunsigned\\fR) r\\-\n+.RS 4\n+Number of threads currently assigned to arena\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.pactive\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Number of pages in active runs\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.pdirty\" (\\fBsize_t\\fR) r\\-\n+.RS 4\n+Number of pages within unused runs that are potentially dirty, and for which\n+\\fBmadvise\\fR\\fB\\fI\\&.\\&.\\&.\\fR\\fR\\fB \\fR\\fB\\fI\\fBMADV_DONTNEED\\fR\\fR\\fR\n+or similar has not been called\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.mapped\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of mapped bytes\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.npurge\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of dirty page purge sweeps performed\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.nmadvise\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of\n+\\fBmadvise\\fR\\fB\\fI\\&.\\&.\\&.\\fR\\fR\\fB \\fR\\fB\\fI\\fBMADV_DONTNEED\\fR\\fR\\fR\n+or similar calls made to purge dirty pages\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.npurged\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of pages purged\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.small\\&.allocated\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of bytes currently allocated by small objects\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.small\\&.nmalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of allocation requests served by small bins\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.small\\&.ndalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of small objects returned to bins\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.small\\&.nrequests\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of small allocation requests\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.large\\&.allocated\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Number of bytes currently allocated by large objects\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.large\\&.nmalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of large allocation requests served directly by the arena\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.large\\&.ndalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of large deallocation requests served directly by the arena\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.large\\&.nrequests\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of large allocation requests\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.allocated\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Current number of bytes allocated by bin\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.nmalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of allocations served by bin\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.ndalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of allocations returned to bin\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.nrequests\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of allocation requests\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.nfills\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR \\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Cumulative number of tcache fills\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.nflushes\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR \\fB\\-\\-enable\\-tcache\\fR]\n+.RS 4\n+Cumulative number of tcache flushes\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.nruns\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of runs created\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.nreruns\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of times the current run from which to allocate changed\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.bins\\&.<j>\\&.curruns\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Current number of runs\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.lruns\\&.<j>\\&.nmalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of allocation requests for this size class served directly by the arena\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.lruns\\&.<j>\\&.ndalloc\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of deallocation requests for this size class served directly by the arena\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.lruns\\&.<j>\\&.nrequests\" (\\fBuint64_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Cumulative number of allocation requests for this size class\\&.\n+.RE\n+.PP\n+\"stats\\&.arenas\\&.<i>\\&.lruns\\&.<j>\\&.curruns\" (\\fBsize_t\\fR) r\\- [\\fB\\-\\-enable\\-stats\\fR]\n+.RS 4\n+Current number of runs for this size class\\&.\n+.RE\n+.SH \"DEBUGGING MALLOC PROBLEMS\"\n+.PP\n+When debugging, it is a good idea to configure/build jemalloc with the\n+\\fB\\-\\-enable\\-debug\\fR\n+and\n+\\fB\\-\\-enable\\-fill\\fR\n+options, and recompile the program with suitable options and symbols for debugger support\\&. When so configured, jemalloc incorporates a wide variety of run\\-time assertions that catch application errors such as double\\-free, write\\-after\\-free, etc\\&.\n+.PP\n+Programs often accidentally depend on \\(lquninitialized\\(rq memory actually being filled with zero bytes\\&. Junk filling (see the\n+\"opt\\&.junk\"\n+option) tends to expose such bugs in the form of obviously incorrect results and/or coredumps\\&. Conversely, zero filling (see the\n+\"opt\\&.zero\"\n+option) eliminates the symptoms of such bugs\\&. Between these two options, it is usually possible to quickly detect, diagnose, and eliminate such bugs\\&.\n+.PP\n+This implementation does not provide much detail about the problems it detects, because the performance impact for storing such information would be prohibitive\\&. However, jemalloc does integrate with the most excellent\n+\\m[blue]\\fBValgrind\\fR\\m[]\\&\\s-2\\u[2]\\d\\s+2\n+tool if the\n+\\fB\\-\\-enable\\-valgrind\\fR\n+configuration option is enabled\\&.\n+.SH \"DIAGNOSTIC MESSAGES\"\n+.PP\n+If any of the memory allocation/deallocation functions detect an error or warning condition, a message will be printed to file descriptor\n+\\fBSTDERR_FILENO\\fR\\&. Errors will result in the process dumping core\\&. If the\n+\"opt\\&.abort\"\n+option is set, most warnings are treated as errors\\&.\n+.PP\n+The\n+\\fImalloc_message\\fR\n+variable allows the programmer to override the function which emits the text strings forming the errors and warnings if for some reason the\n+\\fBSTDERR_FILENO\\fR\n+file descriptor is not suitable for this\\&.\n+\\fBmalloc_message\\fR\\fB\\fR\n+takes the\n+\\fIcbopaque\\fR\n+pointer argument that is\n+\\fBNULL\\fR\n+unless overridden by the arguments in a call to\n+\\fBmalloc_stats_print\\fR\\fB\\fR, followed by a string pointer\\&. Please note that doing anything which tries to allocate memory in this function is likely to result in a crash or deadlock\\&.\n+.PP\n+All messages are prefixed by \\(lq<jemalloc>:\\(rq\\&.\n+.SH \"RETURN VALUES\"\n+.SS \"Standard API\"\n+.PP\n+The\n+\\fBmalloc\\fR\\fB\\fR\n+and\n+\\fBcalloc\\fR\\fB\\fR\n+functions return a pointer to the allocated memory if successful; otherwise a\n+\\fBNULL\\fR\n+pointer is returned and\n+\\fIerrno\\fR\n+is set to\n+ENOMEM\\&.\n+.PP\n+The\n+\\fBposix_memalign\\fR\\fB\\fR\n+function returns the value 0 if successful; otherwise it returns an error value\\&. The\n+\\fBposix_memalign\\fR\\fB\\fR\n+function will fail if:\n+.PP\n+EINVAL\n+.RS 4\n+The\n+\\fIalignment\\fR\n+parameter is not a power of 2 at least as large as\n+sizeof(\\fBvoid *\\fR)\\&.\n+.RE\n+.PP\n+ENOMEM\n+.RS 4\n+Memory allocation error\\&.\n+.RE\n+.PP\n+The\n+\\fBaligned_alloc\\fR\\fB\\fR\n+function returns a pointer to the allocated memory if successful; otherwise a\n+\\fBNULL\\fR\n+pointer is returned and\n+\\fIerrno\\fR\n+is set\\&. The\n+\\fBaligned_alloc\\fR\\fB\\fR\n+function will fail if:\n+.PP\n+EINVAL\n+.RS 4\n+The\n+\\fIalignment\\fR\n+parameter is not a power of 2\\&.\n+.RE\n+.PP\n+ENOMEM\n+.RS 4\n+Memory allocation error\\&.\n+.RE\n+.PP\n+The\n+\\fBrealloc\\fR\\fB\\fR\n+function returns a pointer, possibly identical to\n+\\fIptr\\fR, to the allocated memory if successful; otherwise a\n+\\fBNULL\\fR\n+pointer is returned, and\n+\\fIerrno\\fR\n+is set to\n+ENOMEM\n+if the error was the result of an allocation failure\\&. The\n+\\fBrealloc\\fR\\fB\\fR\n+function always leaves the original buffer intact when an error occurs\\&.\n+.PP\n+The\n+\\fBfree\\fR\\fB\\fR\n+function returns no value\\&.\n+.SS \"Non\\-standard API\"\n+.PP\n+The\n+\\fBmalloc_usable_size\\fR\\fB\\fR\n+function returns the usable size of the allocation pointed to by\n+\\fIptr\\fR\\&.\n+.PP\n+The\n+\\fBmallctl\\fR\\fB\\fR,\n+\\fBmallctlnametomib\\fR\\fB\\fR, and\n+\\fBmallctlbymib\\fR\\fB\\fR\n+functions return 0 on success; otherwise they return an error value\\&. The functions will fail if:\n+.PP\n+EINVAL\n+.RS 4\n+\\fInewp\\fR\n+is not\n+\\fBNULL\\fR, and\n+\\fInewlen\\fR\n+is too large or too small\\&. Alternatively,\n+\\fI*oldlenp\\fR\n+is too large or too small; in this case as much data as possible are read despite the error\\&.\n+.RE\n+.PP\n+ENOMEM\n+.RS 4\n+\\fI*oldlenp\\fR\n+is too short to hold the requested value\\&.\n+.RE\n+.PP\n+ENOENT\n+.RS 4\n+\\fIname\\fR\n+or\n+\\fImib\\fR\n+specifies an unknown/invalid value\\&.\n+.RE\n+.PP\n+EPERM\n+.RS 4\n+Attempt to read or write void value, or attempt to write read\\-only value\\&.\n+.RE\n+.PP\n+EAGAIN\n+.RS 4\n+A memory allocation failure occurred\\&.\n+.RE\n+.PP\n+EFAULT\n+.RS 4\n+An interface with side effects failed in some way not directly related to\n+\\fBmallctl*\\fR\\fB\\fR\n+read/write processing\\&.\n+.RE\n+.SS \"Experimental API\"\n+.PP\n+The\n+\\fBallocm\\fR\\fB\\fR,\n+\\fBrallocm\\fR\\fB\\fR,\n+\\fBsallocm\\fR\\fB\\fR,\n+\\fBdallocm\\fR\\fB\\fR, and\n+\\fBnallocm\\fR\\fB\\fR\n+functions return\n+\\fBALLOCM_SUCCESS\\fR\n+on success; otherwise they return an error value\\&. The\n+\\fBallocm\\fR\\fB\\fR,\n+\\fBrallocm\\fR\\fB\\fR, and\n+\\fBnallocm\\fR\\fB\\fR\n+functions will fail if:\n+.PP\n+ALLOCM_ERR_OOM\n+.RS 4\n+Out of memory\\&. Insufficient contiguous memory was available to service the allocation request\\&. The\n+\\fBallocm\\fR\\fB\\fR\n+function additionally sets\n+\\fI*ptr\\fR\n+to\n+\\fBNULL\\fR, whereas the\n+\\fBrallocm\\fR\\fB\\fR\n+function leaves\n+\\fB*ptr\\fR\n+unmodified\\&.\n+.RE\n+The\n+\\fBrallocm\\fR\\fB\\fR\n+function will also fail if:\n+.PP\n+ALLOCM_ERR_NOT_MOVED\n+.RS 4\n+\\fBALLOCM_NO_MOVE\\fR\n+was specified, but the reallocation request could not be serviced without moving the object\\&.\n+.RE\n+.SH \"ENVIRONMENT\"\n+.PP\n+The following environment variable affects the execution of the allocation functions:\n+.PP\n+\\fBMALLOC_CONF\\fR\n+.RS 4\n+If the environment variable\n+\\fBMALLOC_CONF\\fR\n+is set, the characters it contains will be interpreted as options\\&.\n+.RE\n+.SH \"EXAMPLES\"\n+.PP\n+To dump core whenever a problem occurs:\n+.sp\n+.if n \\{\\\n+.RS 4\n+.\\}\n+.nf\n+ln \\-s \\*(Aqabort:true\\*(Aq /etc/malloc\\&.conf\n+.fi\n+.if n \\{\\\n+.RE\n+.\\}\n+.PP\n+To specify in the source a chunk size that is 16 MiB:\n+.sp\n+.if n \\{\\\n+.RS 4\n+.\\}\n+.nf\n+malloc_conf = \"lg_chunk:24\";\n+.fi\n+.if n \\{\\\n+.RE\n+.\\}\n+.SH \"SEE ALSO\"\n+.PP\n+\\fBmadvise\\fR(2),\n+\\fBmmap\\fR(2),\n+\\fBsbrk\\fR(2),\n+\\fButrace\\fR(2),\n+\\fBalloca\\fR(3),\n+\\fBatexit\\fR(3),\n+\\fBgetpagesize\\fR(3)\n+.SH \"STANDARDS\"\n+.PP\n+The\n+\\fBmalloc\\fR\\fB\\fR,\n+\\fBcalloc\\fR\\fB\\fR,\n+\\fBrealloc\\fR\\fB\\fR, and\n+\\fBfree\\fR\\fB\\fR\n+functions conform to ISO/IEC 9899:1990 (\\(lqISO C90\\(rq)\\&.\n+.PP\n+The\n+\\fBposix_memalign\\fR\\fB\\fR\n+function conforms to IEEE Std 1003\\&.1\\-2001 (\\(lqPOSIX\\&.1\\(rq)\\&.\n+.SH \"AUTHOR\"\n+.PP\n+\\fBJason Evans\\fR\n+.RS 4\n+.RE\n+.SH \"NOTES\"\n+.IP \" 1.\" 4\n+jemalloc website\n+.RS 4\n+\\%http://www.canonware.com/jemalloc/\n+.RE\n+.IP \" 2.\" 4\n+Valgrind\n+.RS 4\n+\\%http://valgrind.org/\n+.RE\n+.IP \" 3.\" 4\n+gperftools package\n+.RS 4\n+\\%http://code.google.com/p/gperftools/\n+.RE"}, {"sha": "09305801babfc9bcab3229d7b36111e3451154ca", "filename": "src/rt/jemalloc/doc/jemalloc.xml.in", "status": "added", "additions": 2176, "deletions": 0, "changes": 2176, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fjemalloc.xml.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fjemalloc.xml.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fdoc%2Fjemalloc.xml.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,2176 @@\n+<?xml version='1.0' encoding='UTF-8'?>\n+<?xml-stylesheet type=\"text/xsl\"\n+        href=\"http://docbook.sourceforge.net/release/xsl/current/manpages/docbook.xsl\"?>\n+<!DOCTYPE refentry PUBLIC \"-//OASIS//DTD DocBook XML V4.4//EN\"\n+        \"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd\" [\n+]>\n+\n+<refentry>\n+  <refentryinfo>\n+    <title>User Manual</title>\n+    <productname>jemalloc</productname>\n+    <releaseinfo role=\"version\">@jemalloc_version@</releaseinfo>\n+    <authorgroup>\n+      <author>\n+        <firstname>Jason</firstname>\n+        <surname>Evans</surname>\n+        <personblurb>Author</personblurb>\n+      </author>\n+    </authorgroup>\n+  </refentryinfo>\n+  <refmeta>\n+    <refentrytitle>JEMALLOC</refentrytitle>\n+    <manvolnum>3</manvolnum>\n+  </refmeta>\n+  <refnamediv>\n+    <refdescriptor>jemalloc</refdescriptor>\n+    <refname>jemalloc</refname>\n+    <!-- Each refname causes a man page file to be created.  Only if this were\n+         the system malloc(3) implementation would these files be appropriate.\n+    <refname>malloc</refname>\n+    <refname>calloc</refname>\n+    <refname>posix_memalign</refname>\n+    <refname>aligned_alloc</refname>\n+    <refname>realloc</refname>\n+    <refname>free</refname>\n+    <refname>malloc_usable_size</refname>\n+    <refname>malloc_stats_print</refname>\n+    <refname>mallctl</refname>\n+    <refname>mallctlnametomib</refname>\n+    <refname>mallctlbymib</refname>\n+    <refname>allocm</refname>\n+    <refname>rallocm</refname>\n+    <refname>sallocm</refname>\n+    <refname>dallocm</refname>\n+    <refname>nallocm</refname>\n+    -->\n+    <refpurpose>general purpose memory allocation functions</refpurpose>\n+  </refnamediv>\n+  <refsect1 id=\"library\">\n+    <title>LIBRARY</title>\n+    <para>This manual describes jemalloc @jemalloc_version@.  More information\n+    can be found at the <ulink\n+    url=\"http://www.canonware.com/jemalloc/\">jemalloc website</ulink>.</para>\n+  </refsect1>\n+  <refsynopsisdiv>\n+    <title>SYNOPSIS</title>\n+    <funcsynopsis>\n+      <funcsynopsisinfo>#include &lt;<filename class=\"headerfile\">stdlib.h</filename>&gt;\n+#include &lt;<filename class=\"headerfile\">jemalloc/jemalloc.h</filename>&gt;</funcsynopsisinfo>\n+      <refsect2>\n+        <title>Standard API</title>\n+        <funcprototype>\n+          <funcdef>void *<function>malloc</function></funcdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>void *<function>calloc</function></funcdef>\n+          <paramdef>size_t <parameter>number</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>posix_memalign</function></funcdef>\n+          <paramdef>void **<parameter>ptr</parameter></paramdef>\n+          <paramdef>size_t <parameter>alignment</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>void *<function>aligned_alloc</function></funcdef>\n+          <paramdef>size_t <parameter>alignment</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>void *<function>realloc</function></funcdef>\n+          <paramdef>void *<parameter>ptr</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>void <function>free</function></funcdef>\n+          <paramdef>void *<parameter>ptr</parameter></paramdef>\n+        </funcprototype>\n+      </refsect2>\n+      <refsect2>\n+        <title>Non-standard API</title>\n+        <funcprototype>\n+          <funcdef>size_t <function>malloc_usable_size</function></funcdef>\n+          <paramdef>const void *<parameter>ptr</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>void <function>malloc_stats_print</function></funcdef>\n+          <paramdef>void <parameter>(*write_cb)</parameter>\n+            <funcparams>void *, const char *</funcparams>\n+          </paramdef>\n+          <paramdef>void *<parameter>cbopaque</parameter></paramdef>\n+          <paramdef>const char *<parameter>opts</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>mallctl</function></funcdef>\n+          <paramdef>const char *<parameter>name</parameter></paramdef>\n+          <paramdef>void *<parameter>oldp</parameter></paramdef>\n+          <paramdef>size_t *<parameter>oldlenp</parameter></paramdef>\n+          <paramdef>void *<parameter>newp</parameter></paramdef>\n+          <paramdef>size_t <parameter>newlen</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>mallctlnametomib</function></funcdef>\n+          <paramdef>const char *<parameter>name</parameter></paramdef>\n+          <paramdef>size_t *<parameter>mibp</parameter></paramdef>\n+          <paramdef>size_t *<parameter>miblenp</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>mallctlbymib</function></funcdef>\n+          <paramdef>const size_t *<parameter>mib</parameter></paramdef>\n+          <paramdef>size_t <parameter>miblen</parameter></paramdef>\n+          <paramdef>void *<parameter>oldp</parameter></paramdef>\n+          <paramdef>size_t *<parameter>oldlenp</parameter></paramdef>\n+          <paramdef>void *<parameter>newp</parameter></paramdef>\n+          <paramdef>size_t <parameter>newlen</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>void <function>(*malloc_message)</function></funcdef>\n+          <paramdef>void *<parameter>cbopaque</parameter></paramdef>\n+          <paramdef>const char *<parameter>s</parameter></paramdef>\n+        </funcprototype>\n+        <para><type>const char *</type><varname>malloc_conf</varname>;</para>\n+      </refsect2>\n+      <refsect2>\n+      <title>Experimental API</title>\n+        <funcprototype>\n+          <funcdef>int <function>allocm</function></funcdef>\n+          <paramdef>void **<parameter>ptr</parameter></paramdef>\n+          <paramdef>size_t *<parameter>rsize</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+          <paramdef>int <parameter>flags</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>rallocm</function></funcdef>\n+          <paramdef>void **<parameter>ptr</parameter></paramdef>\n+          <paramdef>size_t *<parameter>rsize</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+          <paramdef>size_t <parameter>extra</parameter></paramdef>\n+          <paramdef>int <parameter>flags</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>sallocm</function></funcdef>\n+          <paramdef>const void *<parameter>ptr</parameter></paramdef>\n+          <paramdef>size_t *<parameter>rsize</parameter></paramdef>\n+          <paramdef>int <parameter>flags</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>dallocm</function></funcdef>\n+          <paramdef>void *<parameter>ptr</parameter></paramdef>\n+          <paramdef>int <parameter>flags</parameter></paramdef>\n+        </funcprototype>\n+        <funcprototype>\n+          <funcdef>int <function>nallocm</function></funcdef>\n+          <paramdef>size_t *<parameter>rsize</parameter></paramdef>\n+          <paramdef>size_t <parameter>size</parameter></paramdef>\n+          <paramdef>int <parameter>flags</parameter></paramdef>\n+        </funcprototype>\n+      </refsect2>\n+    </funcsynopsis>\n+  </refsynopsisdiv>\n+  <refsect1 id=\"description\">\n+    <title>DESCRIPTION</title>\n+    <refsect2>\n+      <title>Standard API</title>\n+\n+      <para>The <function>malloc<parameter/></function> function allocates\n+      <parameter>size</parameter> bytes of uninitialized memory.  The allocated\n+      space is suitably aligned (after possible pointer coercion) for storage\n+      of any type of object.</para>\n+\n+      <para>The <function>calloc<parameter/></function> function allocates\n+      space for <parameter>number</parameter> objects, each\n+      <parameter>size</parameter> bytes in length.  The result is identical to\n+      calling <function>malloc<parameter/></function> with an argument of\n+      <parameter>number</parameter> * <parameter>size</parameter>, with the\n+      exception that the allocated memory is explicitly initialized to zero\n+      bytes.</para>\n+\n+      <para>The <function>posix_memalign<parameter/></function> function\n+      allocates <parameter>size</parameter> bytes of memory such that the\n+      allocation's base address is an even multiple of\n+      <parameter>alignment</parameter>, and returns the allocation in the value\n+      pointed to by <parameter>ptr</parameter>.  The requested\n+      <parameter>alignment</parameter> must be a power of 2 at least as large\n+      as <code language=\"C\">sizeof(<type>void *</type>)</code>.</para>\n+\n+      <para>The <function>aligned_alloc<parameter/></function> function\n+      allocates <parameter>size</parameter> bytes of memory such that the\n+      allocation's base address is an even multiple of\n+      <parameter>alignment</parameter>.  The requested\n+      <parameter>alignment</parameter> must be a power of 2.  Behavior is\n+      undefined if <parameter>size</parameter> is not an integral multiple of\n+      <parameter>alignment</parameter>.</para>\n+\n+      <para>The <function>realloc<parameter/></function> function changes the\n+      size of the previously allocated memory referenced by\n+      <parameter>ptr</parameter> to <parameter>size</parameter> bytes.  The\n+      contents of the memory are unchanged up to the lesser of the new and old\n+      sizes.  If the new size is larger, the contents of the newly allocated\n+      portion of the memory are undefined.  Upon success, the memory referenced\n+      by <parameter>ptr</parameter> is freed and a pointer to the newly\n+      allocated memory is returned.  Note that\n+      <function>realloc<parameter/></function> may move the memory allocation,\n+      resulting in a different return value than <parameter>ptr</parameter>.\n+      If <parameter>ptr</parameter> is <constant>NULL</constant>, the\n+      <function>realloc<parameter/></function> function behaves identically to\n+      <function>malloc<parameter/></function> for the specified size.</para>\n+\n+      <para>The <function>free<parameter/></function> function causes the\n+      allocated memory referenced by <parameter>ptr</parameter> to be made\n+      available for future allocations.  If <parameter>ptr</parameter> is\n+      <constant>NULL</constant>, no action occurs.</para>\n+    </refsect2>\n+    <refsect2>\n+      <title>Non-standard API</title>\n+\n+      <para>The <function>malloc_usable_size<parameter/></function> function\n+      returns the usable size of the allocation pointed to by\n+      <parameter>ptr</parameter>.  The return value may be larger than the size\n+      that was requested during allocation.  The\n+      <function>malloc_usable_size<parameter/></function> function is not a\n+      mechanism for in-place <function>realloc<parameter/></function>; rather\n+      it is provided solely as a tool for introspection purposes.  Any\n+      discrepancy between the requested allocation size and the size reported\n+      by <function>malloc_usable_size<parameter/></function> should not be\n+      depended on, since such behavior is entirely implementation-dependent.\n+      </para>\n+\n+      <para>The <function>malloc_stats_print<parameter/></function> function\n+      writes human-readable summary statistics via the\n+      <parameter>write_cb</parameter> callback function pointer and\n+      <parameter>cbopaque</parameter> data passed to\n+      <parameter>write_cb</parameter>, or\n+      <function>malloc_message<parameter/></function> if\n+      <parameter>write_cb</parameter> is <constant>NULL</constant>.  This\n+      function can be called repeatedly.  General information that never\n+      changes during execution can be omitted by specifying \"g\" as a character\n+      within the <parameter>opts</parameter> string.  Note that\n+      <function>malloc_message<parameter/></function> uses the\n+      <function>mallctl*<parameter/></function> functions internally, so\n+      inconsistent statistics can be reported if multiple threads use these\n+      functions simultaneously.  If <option>--enable-stats</option> is\n+      specified during configuration, &ldquo;m&rdquo; and &ldquo;a&rdquo; can\n+      be specified to omit merged arena and per arena statistics, respectively;\n+      &ldquo;b&rdquo; and &ldquo;l&rdquo; can be specified to omit per size\n+      class statistics for bins and large objects, respectively.  Unrecognized\n+      characters are silently ignored.  Note that thread caching may prevent\n+      some statistics from being completely up to date, since extra locking\n+      would be required to merge counters that track thread cache operations.\n+      </para>\n+\n+      <para>The <function>mallctl<parameter/></function> function provides a\n+      general interface for introspecting the memory allocator, as well as\n+      setting modifiable parameters and triggering actions.  The\n+      period-separated <parameter>name</parameter> argument specifies a\n+      location in a tree-structured namespace; see the <xref\n+      linkend=\"mallctl_namespace\" xrefstyle=\"template:%t\"/> section for\n+      documentation on the tree contents.  To read a value, pass a pointer via\n+      <parameter>oldp</parameter> to adequate space to contain the value, and a\n+      pointer to its length via <parameter>oldlenp</parameter>; otherwise pass\n+      <constant>NULL</constant> and <constant>NULL</constant>.  Similarly, to\n+      write a value, pass a pointer to the value via\n+      <parameter>newp</parameter>, and its length via\n+      <parameter>newlen</parameter>; otherwise pass <constant>NULL</constant>\n+      and <constant>0</constant>.</para>\n+\n+      <para>The <function>mallctlnametomib<parameter/></function> function\n+      provides a way to avoid repeated name lookups for applications that\n+      repeatedly query the same portion of the namespace, by translating a name\n+      to a &ldquo;Management Information Base&rdquo; (MIB) that can be passed\n+      repeatedly to <function>mallctlbymib<parameter/></function>.  Upon\n+      successful return from <function>mallctlnametomib<parameter/></function>,\n+      <parameter>mibp</parameter> contains an array of\n+      <parameter>*miblenp</parameter> integers, where\n+      <parameter>*miblenp</parameter> is the lesser of the number of components\n+      in <parameter>name</parameter> and the input value of\n+      <parameter>*miblenp</parameter>.  Thus it is possible to pass a\n+      <parameter>*miblenp</parameter> that is smaller than the number of\n+      period-separated name components, which results in a partial MIB that can\n+      be used as the basis for constructing a complete MIB.  For name\n+      components that are integers (e.g. the 2 in\n+      <link\n+      linkend=\"arenas.bin.i.size\"><mallctl>arenas.bin.2.size</mallctl></link>),\n+      the corresponding MIB component will always be that integer.  Therefore,\n+      it is legitimate to construct code like the following: <programlisting\n+      language=\"C\"><![CDATA[\n+unsigned nbins, i;\n+\n+int mib[4];\n+size_t len, miblen;\n+\n+len = sizeof(nbins);\n+mallctl(\"arenas.nbins\", &nbins, &len, NULL, 0);\n+\n+miblen = 4;\n+mallnametomib(\"arenas.bin.0.size\", mib, &miblen);\n+for (i = 0; i < nbins; i++) {\n+\tsize_t bin_size;\n+\n+\tmib[2] = i;\n+\tlen = sizeof(bin_size);\n+\tmallctlbymib(mib, miblen, &bin_size, &len, NULL, 0);\n+\t/* Do something with bin_size... */\n+}]]></programlisting></para>\n+    </refsect2>\n+    <refsect2>\n+      <title>Experimental API</title>\n+      <para>The experimental API is subject to change or removal without regard\n+      for backward compatibility.  If <option>--disable-experimental</option>\n+      is specified during configuration, the experimental API is\n+      omitted.</para>\n+\n+      <para>The <function>allocm<parameter/></function>,\n+      <function>rallocm<parameter/></function>,\n+      <function>sallocm<parameter/></function>,\n+      <function>dallocm<parameter/></function>, and\n+      <function>nallocm<parameter/></function> functions all have a\n+      <parameter>flags</parameter> argument that can be used to specify\n+      options.  The functions only check the options that are contextually\n+      relevant.  Use bitwise or (<code language=\"C\">|</code>) operations to\n+      specify one or more of the following:\n+        <variablelist>\n+          <varlistentry>\n+            <term><constant>ALLOCM_LG_ALIGN(<parameter>la</parameter>)\n+            </constant></term>\n+\n+            <listitem><para>Align the memory allocation to start at an address\n+            that is a multiple of <code language=\"C\">(1 &lt;&lt;\n+            <parameter>la</parameter>)</code>.  This macro does not validate\n+            that <parameter>la</parameter> is within the valid\n+            range.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><constant>ALLOCM_ALIGN(<parameter>a</parameter>)\n+            </constant></term>\n+\n+            <listitem><para>Align the memory allocation to start at an address\n+            that is a multiple of <parameter>a</parameter>, where\n+            <parameter>a</parameter> is a power of two.  This macro does not\n+            validate that <parameter>a</parameter> is a power of 2.\n+            </para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><constant>ALLOCM_ZERO</constant></term>\n+\n+            <listitem><para>Initialize newly allocated memory to contain zero\n+            bytes.  In the growing reallocation case, the real size prior to\n+            reallocation defines the boundary between untouched bytes and those\n+            that are initialized to contain zero bytes.  If this option is\n+            absent, newly allocated memory is uninitialized.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><constant>ALLOCM_NO_MOVE</constant></term>\n+\n+            <listitem><para>For reallocation, fail rather than moving the\n+            object.  This constraint can apply to both growth and\n+            shrinkage.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><constant>ALLOCM_ARENA(<parameter>a</parameter>)\n+            </constant></term>\n+\n+            <listitem><para>Use the arena specified by the index\n+            <parameter>a</parameter>.  This macro does not validate that\n+            <parameter>a</parameter> specifies an arena in the valid\n+            range.</para></listitem>\n+          </varlistentry>\n+        </variablelist>\n+      </para>\n+\n+      <para>The <function>allocm<parameter/></function> function allocates at\n+      least <parameter>size</parameter> bytes of memory, sets\n+      <parameter>*ptr</parameter> to the base address of the allocation, and\n+      sets <parameter>*rsize</parameter> to the real size of the allocation if\n+      <parameter>rsize</parameter> is not <constant>NULL</constant>.  Behavior\n+      is undefined if <parameter>size</parameter> is\n+      <constant>0</constant>.</para>\n+\n+      <para>The <function>rallocm<parameter/></function> function resizes the\n+      allocation at <parameter>*ptr</parameter> to be at least\n+      <parameter>size</parameter> bytes, sets <parameter>*ptr</parameter> to\n+      the base address of the allocation if it moved, and sets\n+      <parameter>*rsize</parameter> to the real size of the allocation if\n+      <parameter>rsize</parameter> is not <constant>NULL</constant>.  If\n+      <parameter>extra</parameter> is non-zero, an attempt is made to resize\n+      the allocation to be at least <code\n+      language=\"C\"><parameter>size</parameter> +\n+      <parameter>extra</parameter>)</code> bytes, though inability to allocate\n+      the extra byte(s) will not by itself result in failure.  Behavior is\n+      undefined if <parameter>size</parameter> is <constant>0</constant>, or if\n+      <code language=\"C\">(<parameter>size</parameter> +\n+      <parameter>extra</parameter> &gt;\n+      <constant>SIZE_T_MAX</constant>)</code>.</para>\n+\n+      <para>The <function>sallocm<parameter/></function> function sets\n+      <parameter>*rsize</parameter> to the real size of the allocation.</para>\n+\n+      <para>The <function>dallocm<parameter/></function> function causes the\n+      memory referenced by <parameter>ptr</parameter> to be made available for\n+      future allocations.</para>\n+\n+      <para>The <function>nallocm<parameter/></function> function allocates no\n+      memory, but it performs the same size computation as the\n+      <function>allocm<parameter/></function> function, and if\n+      <parameter>rsize</parameter> is not <constant>NULL</constant> it sets\n+      <parameter>*rsize</parameter> to the real size of the allocation that\n+      would result from the equivalent <function>allocm<parameter/></function>\n+      function call.  Behavior is undefined if\n+      <parameter>size</parameter> is <constant>0</constant>.</para>\n+    </refsect2>\n+  </refsect1>\n+  <refsect1 id=\"tuning\">\n+    <title>TUNING</title>\n+    <para>Once, when the first call is made to one of the memory allocation\n+    routines, the allocator initializes its internals based in part on various\n+    options that can be specified at compile- or run-time.</para>\n+\n+    <para>The string pointed to by the global variable\n+    <varname>malloc_conf</varname>, the &ldquo;name&rdquo; of the file\n+    referenced by the symbolic link named <filename\n+    class=\"symlink\">/etc/malloc.conf</filename>, and the value of the\n+    environment variable <envar>MALLOC_CONF</envar>, will be interpreted, in\n+    that order, from left to right as options.</para>\n+\n+    <para>An options string is a comma-separated list of option:value pairs.\n+    There is one key corresponding to each <link\n+    linkend=\"opt.abort\"><mallctl>opt.*</mallctl></link> mallctl (see the <xref\n+    linkend=\"mallctl_namespace\" xrefstyle=\"template:%t\"/> section for options\n+    documentation).  For example, <literal>abort:true,narenas:1</literal> sets\n+    the <link linkend=\"opt.abort\"><mallctl>opt.abort</mallctl></link> and <link\n+    linkend=\"opt.narenas\"><mallctl>opt.narenas</mallctl></link> options.  Some\n+    options have boolean values (true/false), others have integer values (base\n+    8, 10, or 16, depending on prefix), and yet others have raw string\n+    values.</para>\n+  </refsect1>\n+  <refsect1 id=\"implementation_notes\">\n+    <title>IMPLEMENTATION NOTES</title>\n+    <para>Traditionally, allocators have used\n+    <citerefentry><refentrytitle>sbrk</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry> to obtain memory, which is\n+    suboptimal for several reasons, including race conditions, increased\n+    fragmentation, and artificial limitations on maximum usable memory.  If\n+    <option>--enable-dss</option> is specified during configuration, this\n+    allocator uses both <citerefentry><refentrytitle>mmap</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry> and\n+    <citerefentry><refentrytitle>sbrk</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry>, in that order of preference;\n+    otherwise only <citerefentry><refentrytitle>mmap</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry> is used.</para>\n+\n+    <para>This allocator uses multiple arenas in order to reduce lock\n+    contention for threaded programs on multi-processor systems.  This works\n+    well with regard to threading scalability, but incurs some costs.  There is\n+    a small fixed per-arena overhead, and additionally, arenas manage memory\n+    completely independently of each other, which means a small fixed increase\n+    in overall memory fragmentation.  These overheads are not generally an\n+    issue, given the number of arenas normally used.  Note that using\n+    substantially more arenas than the default is not likely to improve\n+    performance, mainly due to reduced cache performance.  However, it may make\n+    sense to reduce the number of arenas if an application does not make much\n+    use of the allocation functions.</para>\n+\n+    <para>In addition to multiple arenas, unless\n+    <option>--disable-tcache</option> is specified during configuration, this\n+    allocator supports thread-specific caching for small and large objects, in\n+    order to make it possible to completely avoid synchronization for most\n+    allocation requests.  Such caching allows very fast allocation in the\n+    common case, but it increases memory usage and fragmentation, since a\n+    bounded number of objects can remain allocated in each thread cache.</para>\n+\n+    <para>Memory is conceptually broken into equal-sized chunks, where the\n+    chunk size is a power of two that is greater than the page size.  Chunks\n+    are always aligned to multiples of the chunk size.  This alignment makes it\n+    possible to find metadata for user objects very quickly.</para>\n+\n+    <para>User objects are broken into three categories according to size:\n+    small, large, and huge.  Small objects are smaller than one page.  Large\n+    objects are smaller than the chunk size.  Huge objects are a multiple of\n+    the chunk size.  Small and large objects are managed by arenas; huge\n+    objects are managed separately in a single data structure that is shared by\n+    all threads.  Huge objects are used by applications infrequently enough\n+    that this single data structure is not a scalability issue.</para>\n+\n+    <para>Each chunk that is managed by an arena tracks its contents as runs of\n+    contiguous pages (unused, backing a set of small objects, or backing one\n+    large object).  The combination of chunk alignment and chunk page maps\n+    makes it possible to determine all metadata regarding small and large\n+    allocations in constant time.</para>\n+\n+    <para>Small objects are managed in groups by page runs.  Each run maintains\n+    a frontier and free list to track which regions are in use.  Allocation\n+    requests that are no more than half the quantum (8 or 16, depending on\n+    architecture) are rounded up to the nearest power of two that is at least\n+    <code language=\"C\">sizeof(<type>double</type>)</code>.  All other small\n+    object size classes are multiples of the quantum, spaced such that internal\n+    fragmentation is limited to approximately 25% for all but the smallest size\n+    classes.  Allocation requests that are larger than the maximum small size\n+    class, but small enough to fit in an arena-managed chunk (see the <link\n+    linkend=\"opt.lg_chunk\"><mallctl>opt.lg_chunk</mallctl></link> option), are\n+    rounded up to the nearest run size.  Allocation requests that are too large\n+    to fit in an arena-managed chunk are rounded up to the nearest multiple of\n+    the chunk size.</para>\n+\n+    <para>Allocations are packed tightly together, which can be an issue for\n+    multi-threaded applications.  If you need to assure that allocations do not\n+    suffer from cacheline sharing, round your allocation requests up to the\n+    nearest multiple of the cacheline size, or specify cacheline alignment when\n+    allocating.</para>\n+\n+    <para>Assuming 4 MiB chunks, 4 KiB pages, and a 16-byte quantum on a 64-bit\n+    system, the size classes in each category are as shown in <xref\n+    linkend=\"size_classes\" xrefstyle=\"template:Table %n\"/>.</para>\n+\n+    <table xml:id=\"size_classes\" frame=\"all\">\n+      <title>Size classes</title>\n+      <tgroup cols=\"3\" colsep=\"1\" rowsep=\"1\">\n+      <colspec colname=\"c1\" align=\"left\"/>\n+      <colspec colname=\"c2\" align=\"right\"/>\n+      <colspec colname=\"c3\" align=\"left\"/>\n+      <thead>\n+        <row>\n+          <entry>Category</entry>\n+          <entry>Spacing</entry>\n+          <entry>Size</entry>\n+        </row>\n+      </thead>\n+      <tbody>\n+        <row>\n+          <entry morerows=\"6\">Small</entry>\n+          <entry>lg</entry>\n+          <entry>[8]</entry>\n+        </row>\n+        <row>\n+          <entry>16</entry>\n+          <entry>[16, 32, 48, ..., 128]</entry>\n+        </row>\n+        <row>\n+          <entry>32</entry>\n+          <entry>[160, 192, 224, 256]</entry>\n+        </row>\n+        <row>\n+          <entry>64</entry>\n+          <entry>[320, 384, 448, 512]</entry>\n+        </row>\n+        <row>\n+          <entry>128</entry>\n+          <entry>[640, 768, 896, 1024]</entry>\n+        </row>\n+        <row>\n+          <entry>256</entry>\n+          <entry>[1280, 1536, 1792, 2048]</entry>\n+        </row>\n+        <row>\n+          <entry>512</entry>\n+          <entry>[2560, 3072, 3584]</entry>\n+        </row>\n+        <row>\n+          <entry>Large</entry>\n+          <entry>4 KiB</entry>\n+          <entry>[4 KiB, 8 KiB, 12 KiB, ..., 4072 KiB]</entry>\n+        </row>\n+        <row>\n+          <entry>Huge</entry>\n+          <entry>4 MiB</entry>\n+          <entry>[4 MiB, 8 MiB, 12 MiB, ...]</entry>\n+        </row>\n+      </tbody>\n+      </tgroup>\n+    </table>\n+  </refsect1>\n+  <refsect1 id=\"mallctl_namespace\">\n+    <title>MALLCTL NAMESPACE</title>\n+    <para>The following names are defined in the namespace accessible via the\n+    <function>mallctl*<parameter/></function> functions.  Value types are\n+    specified in parentheses, their readable/writable statuses are encoded as\n+    <literal>rw</literal>, <literal>r-</literal>, <literal>-w</literal>, or\n+    <literal>--</literal>, and required build configuration flags follow, if\n+    any.  A name element encoded as <literal>&lt;i&gt;</literal> or\n+    <literal>&lt;j&gt;</literal> indicates an integer component, where the\n+    integer varies from 0 to some upper value that must be determined via\n+    introspection.  In the case of <mallctl>stats.arenas.&lt;i&gt;.*</mallctl>,\n+    <literal>&lt;i&gt;</literal> equal to <link\n+    linkend=\"arenas.narenas\"><mallctl>arenas.narenas</mallctl></link> can be\n+    used to access the summation of statistics from all arenas.  Take special\n+    note of the <link linkend=\"epoch\"><mallctl>epoch</mallctl></link> mallctl,\n+    which controls refreshing of cached dynamic statistics.</para>\n+\n+    <variablelist>\n+      <varlistentry>\n+        <term>\n+          <mallctl>version</mallctl>\n+          (<type>const char *</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Return the jemalloc version string.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"epoch\">\n+        <term>\n+          <mallctl>epoch</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>rw</literal>\n+        </term>\n+        <listitem><para>If a value is passed in, refresh the data from which\n+        the <function>mallctl*<parameter/></function> functions report values,\n+        and increment the epoch.  Return the current epoch.  This is useful for\n+        detecting whether another thread caused a refresh.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.debug</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-debug</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.dss</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-dss</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.fill</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-fill</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.lazy_lock</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-lazy-lock</option> was specified\n+        during build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.mremap</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-mremap</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.munmap</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-munmap</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.prof</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-prof</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.prof_libgcc</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--disable-prof-libgcc</option> was not\n+        specified during build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.prof_libunwind</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-prof-libunwind</option> was specified\n+        during build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.stats</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-stats</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.tcache</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--disable-tcache</option> was not specified\n+        during build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.tls</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--disable-tls</option> was not specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.utrace</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-utrace</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.valgrind</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-valgrind</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>config.xmalloc</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para><option>--enable-xmalloc</option> was specified during\n+        build configuration.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.abort\">\n+        <term>\n+          <mallctl>opt.abort</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Abort-on-warning enabled/disabled.  If true, most\n+        warnings are fatal.  The process will call\n+        <citerefentry><refentrytitle>abort</refentrytitle>\n+        <manvolnum>3</manvolnum></citerefentry> in these cases.  This option is\n+        disabled by default unless <option>--enable-debug</option> is\n+        specified during configuration, in which case it is enabled by default.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.lg_chunk\">\n+        <term>\n+          <mallctl>opt.lg_chunk</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Virtual memory chunk size (log base 2).  If a chunk\n+        size outside the supported size range is specified, the size is\n+        silently clipped to the minimum/maximum supported size.  The default\n+        chunk size is 4 MiB (2^22).\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.dss\">\n+        <term>\n+          <mallctl>opt.dss</mallctl>\n+          (<type>const char *</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>dss (<citerefentry><refentrytitle>sbrk</refentrytitle>\n+        <manvolnum>2</manvolnum></citerefentry>) allocation precedence as\n+        related to <citerefentry><refentrytitle>mmap</refentrytitle>\n+        <manvolnum>2</manvolnum></citerefentry> allocation.  The following\n+        settings are supported: &ldquo;disabled&rdquo;, &ldquo;primary&rdquo;,\n+        and &ldquo;secondary&rdquo; (default).</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.narenas\">\n+        <term>\n+          <mallctl>opt.narenas</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Maximum number of arenas to use for automatic\n+        multiplexing of threads and arenas.  The default is four times the\n+        number of CPUs, or one if there is a single CPU.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.lg_dirty_mult\">\n+        <term>\n+          <mallctl>opt.lg_dirty_mult</mallctl>\n+          (<type>ssize_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Per-arena minimum ratio (log base 2) of active to dirty\n+        pages.  Some dirty unused pages may be allowed to accumulate, within\n+        the limit set by the ratio (or one chunk worth of dirty pages,\n+        whichever is greater), before informing the kernel about some of those\n+        pages via <citerefentry><refentrytitle>madvise</refentrytitle>\n+        <manvolnum>2</manvolnum></citerefentry> or a similar system call.  This\n+        provides the kernel with sufficient information to recycle dirty pages\n+        if physical memory becomes scarce and the pages remain unused.  The\n+        default minimum ratio is 8:1 (2^3:1); an option value of -1 will\n+        disable dirty page purging.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.stats_print\">\n+        <term>\n+          <mallctl>opt.stats_print</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Enable/disable statistics printing at exit.  If\n+        enabled, the <function>malloc_stats_print<parameter/></function>\n+        function is called at program exit via an\n+        <citerefentry><refentrytitle>atexit</refentrytitle>\n+        <manvolnum>3</manvolnum></citerefentry> function.  If\n+        <option>--enable-stats</option> is specified during configuration, this\n+        has the potential to cause deadlock for a multi-threaded process that\n+        exits while one or more threads are executing in the memory allocation\n+        functions.  Therefore, this option should only be used with care; it is\n+        primarily intended as a performance tuning aid during application\n+        development.  This option is disabled by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.junk\">\n+        <term>\n+          <mallctl>opt.junk</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-fill</option>]\n+        </term>\n+        <listitem><para>Junk filling enabled/disabled.  If enabled, each byte\n+        of uninitialized allocated memory will be initialized to\n+        <literal>0xa5</literal>.  All deallocated memory will be initialized to\n+        <literal>0x5a</literal>.  This is intended for debugging and will\n+        impact performance negatively.  This option is disabled by default\n+        unless <option>--enable-debug</option> is specified during\n+        configuration, in which case it is enabled by default unless running\n+        inside <ulink\n+        url=\"http://valgrind.org/\">Valgrind</ulink>.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.quarantine\">\n+        <term>\n+          <mallctl>opt.quarantine</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-fill</option>]\n+        </term>\n+        <listitem><para>Per thread quarantine size in bytes.  If non-zero, each\n+        thread maintains a FIFO object quarantine that stores up to the\n+        specified number of bytes of memory.  The quarantined memory is not\n+        freed until it is released from quarantine, though it is immediately\n+        junk-filled if the <link\n+        linkend=\"opt.junk\"><mallctl>opt.junk</mallctl></link> option is\n+        enabled.  This feature is of particular use in combination with <ulink\n+        url=\"http://valgrind.org/\">Valgrind</ulink>, which can detect attempts\n+        to access quarantined objects.  This is intended for debugging and will\n+        impact performance negatively.  The default quarantine size is 0 unless\n+        running inside Valgrind, in which case the default is 16\n+        MiB.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.redzone\">\n+        <term>\n+          <mallctl>opt.redzone</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-fill</option>]\n+        </term>\n+        <listitem><para>Redzones enabled/disabled.  If enabled, small\n+        allocations have redzones before and after them.  Furthermore, if the\n+        <link linkend=\"opt.junk\"><mallctl>opt.junk</mallctl></link> option is\n+        enabled, the redzones are checked for corruption during deallocation.\n+        However, the primary intended purpose of this feature is to be used in\n+        combination with <ulink url=\"http://valgrind.org/\">Valgrind</ulink>,\n+        which needs redzones in order to do effective buffer overflow/underflow\n+        detection.  This option is intended for debugging and will impact\n+        performance negatively.  This option is disabled by\n+        default unless running inside Valgrind.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.zero\">\n+        <term>\n+          <mallctl>opt.zero</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-fill</option>]\n+        </term>\n+        <listitem><para>Zero filling enabled/disabled.  If enabled, each byte\n+        of uninitialized allocated memory will be initialized to 0.  Note that\n+        this initialization only happens once for each byte, so\n+        <function>realloc<parameter/></function> and\n+        <function>rallocm<parameter/></function> calls do not zero memory that\n+        was previously allocated.  This is intended for debugging and will\n+        impact performance negatively.  This option is disabled by default.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.utrace\">\n+        <term>\n+          <mallctl>opt.utrace</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-utrace</option>]\n+        </term>\n+        <listitem><para>Allocation tracing based on\n+        <citerefentry><refentrytitle>utrace</refentrytitle>\n+        <manvolnum>2</manvolnum></citerefentry> enabled/disabled.  This option\n+        is disabled by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.valgrind\">\n+        <term>\n+          <mallctl>opt.valgrind</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-valgrind</option>]\n+        </term>\n+        <listitem><para><ulink url=\"http://valgrind.org/\">Valgrind</ulink>\n+        support enabled/disabled.  This option is vestigal because jemalloc\n+        auto-detects whether it is running inside Valgrind.  This option is\n+        disabled by default, unless running inside Valgrind.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.xmalloc\">\n+        <term>\n+          <mallctl>opt.xmalloc</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-xmalloc</option>]\n+        </term>\n+        <listitem><para>Abort-on-out-of-memory enabled/disabled.  If enabled,\n+        rather than returning failure for any allocation function, display a\n+        diagnostic message on <constant>STDERR_FILENO</constant> and cause the\n+        program to drop core (using\n+        <citerefentry><refentrytitle>abort</refentrytitle>\n+        <manvolnum>3</manvolnum></citerefentry>).  If an application is\n+        designed to depend on this behavior, set the option at compile time by\n+        including the following in the source code:\n+        <programlisting language=\"C\"><![CDATA[\n+malloc_conf = \"xmalloc:true\";]]></programlisting>\n+        This option is disabled by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.tcache\">\n+        <term>\n+          <mallctl>opt.tcache</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Thread-specific caching enabled/disabled.  When there\n+        are multiple threads, each thread uses a thread-specific cache for\n+        objects up to a certain size.  Thread-specific caching allows many\n+        allocations to be satisfied without performing any thread\n+        synchronization, at the cost of increased memory use.  See the\n+        <link\n+        linkend=\"opt.lg_tcache_max\"><mallctl>opt.lg_tcache_max</mallctl></link>\n+        option for related tuning information.  This option is enabled by\n+        default unless running inside <ulink\n+        url=\"http://valgrind.org/\">Valgrind</ulink>.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.lg_tcache_max\">\n+        <term>\n+          <mallctl>opt.lg_tcache_max</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Maximum size class (log base 2) to cache in the\n+        thread-specific cache.  At a minimum, all small size classes are\n+        cached, and at a maximum all large size classes are cached.  The\n+        default maximum is 32 KiB (2^15).</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof\">\n+        <term>\n+          <mallctl>opt.prof</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Memory profiling enabled/disabled.  If enabled, profile\n+        memory allocation activity.  See the <link\n+        linkend=\"opt.prof_active\"><mallctl>opt.prof_active</mallctl></link>\n+        option for on-the-fly activation/deactivation.  See the <link\n+        linkend=\"opt.lg_prof_sample\"><mallctl>opt.lg_prof_sample</mallctl></link>\n+        option for probabilistic sampling control.  See the <link\n+        linkend=\"opt.prof_accum\"><mallctl>opt.prof_accum</mallctl></link>\n+        option for control of cumulative sample reporting.  See the <link\n+        linkend=\"opt.lg_prof_interval\"><mallctl>opt.lg_prof_interval</mallctl></link>\n+        option for information on interval-triggered profile dumping, the <link\n+        linkend=\"opt.prof_gdump\"><mallctl>opt.prof_gdump</mallctl></link>\n+        option for information on high-water-triggered profile dumping, and the\n+        <link linkend=\"opt.prof_final\"><mallctl>opt.prof_final</mallctl></link>\n+        option for final profile dumping.  Profile output is compatible with\n+        the included <command>pprof</command> Perl script, which originates\n+        from the <ulink url=\"http://code.google.com/p/gperftools/\">gperftools\n+        package</ulink>.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof_prefix\">\n+        <term>\n+          <mallctl>opt.prof_prefix</mallctl>\n+          (<type>const char *</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Filename prefix for profile dumps.  If the prefix is\n+        set to the empty string, no automatic dumps will occur; this is\n+        primarily useful for disabling the automatic final heap dump (which\n+        also disables leak reporting, if enabled).  The default prefix is\n+        <filename>jeprof</filename>.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof_active\">\n+        <term>\n+          <mallctl>opt.prof_active</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Profiling activated/deactivated.  This is a secondary\n+        control mechanism that makes it possible to start the application with\n+        profiling enabled (see the <link\n+        linkend=\"opt.prof\"><mallctl>opt.prof</mallctl></link> option) but\n+        inactive, then toggle profiling at any time during program execution\n+        with the <link\n+        linkend=\"prof.active\"><mallctl>prof.active</mallctl></link> mallctl.\n+        This option is enabled by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.lg_prof_sample\">\n+        <term>\n+          <mallctl>opt.lg_prof_sample</mallctl>\n+          (<type>ssize_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Average interval (log base 2) between allocation\n+        samples, as measured in bytes of allocation activity.  Increasing the\n+        sampling interval decreases profile fidelity, but also decreases the\n+        computational overhead.  The default sample interval is 512 KiB (2^19\n+        B).</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof_accum\">\n+        <term>\n+          <mallctl>opt.prof_accum</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Reporting of cumulative object/byte counts in profile\n+        dumps enabled/disabled.  If this option is enabled, every unique\n+        backtrace must be stored for the duration of execution.  Depending on\n+        the application, this can impose a large memory overhead, and the\n+        cumulative counts are not always of interest.  This option is disabled\n+        by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.lg_prof_interval\">\n+        <term>\n+          <mallctl>opt.lg_prof_interval</mallctl>\n+          (<type>ssize_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Average interval (log base 2) between memory profile\n+        dumps, as measured in bytes of allocation activity.  The actual\n+        interval between dumps may be sporadic because decentralized allocation\n+        counters are used to avoid synchronization bottlenecks.  Profiles are\n+        dumped to files named according to the pattern\n+        <filename>&lt;prefix&gt;.&lt;pid&gt;.&lt;seq&gt;.i&lt;iseq&gt;.heap</filename>,\n+        where <literal>&lt;prefix&gt;</literal> is controlled by the\n+        <link\n+        linkend=\"opt.prof_prefix\"><mallctl>opt.prof_prefix</mallctl></link>\n+        option.  By default, interval-triggered profile dumping is disabled\n+        (encoded as -1).\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof_gdump\">\n+        <term>\n+          <mallctl>opt.prof_gdump</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Trigger a memory profile dump every time the total\n+        virtual memory exceeds the previous maximum.  Profiles are dumped to\n+        files named according to the pattern\n+        <filename>&lt;prefix&gt;.&lt;pid&gt;.&lt;seq&gt;.u&lt;useq&gt;.heap</filename>,\n+        where <literal>&lt;prefix&gt;</literal> is controlled by the <link\n+        linkend=\"opt.prof_prefix\"><mallctl>opt.prof_prefix</mallctl></link>\n+        option.  This option is disabled by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof_final\">\n+        <term>\n+          <mallctl>opt.prof_final</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Use an\n+        <citerefentry><refentrytitle>atexit</refentrytitle>\n+        <manvolnum>3</manvolnum></citerefentry> function to dump final memory\n+        usage to a file named according to the pattern\n+        <filename>&lt;prefix&gt;.&lt;pid&gt;.&lt;seq&gt;.f.heap</filename>,\n+        where <literal>&lt;prefix&gt;</literal> is controlled by the <link\n+        linkend=\"opt.prof_prefix\"><mallctl>opt.prof_prefix</mallctl></link>\n+        option.  This option is enabled by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"opt.prof_leak\">\n+        <term>\n+          <mallctl>opt.prof_leak</mallctl>\n+          (<type>bool</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Leak reporting enabled/disabled.  If enabled, use an\n+        <citerefentry><refentrytitle>atexit</refentrytitle>\n+        <manvolnum>3</manvolnum></citerefentry> function to report memory leaks\n+        detected by allocation sampling.  See the\n+        <link linkend=\"opt.prof\"><mallctl>opt.prof</mallctl></link> option for\n+        information on analyzing heap profile output.  This option is disabled\n+        by default.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>thread.arena</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>rw</literal>\n+        </term>\n+        <listitem><para>Get or set the arena associated with the calling\n+        thread.  If the specified arena was not initialized beforehand (see the\n+        <link\n+        linkend=\"arenas.initialized\"><mallctl>arenas.initialized</mallctl></link>\n+        mallctl), it will be automatically initialized as a side effect of\n+        calling this interface.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"thread.allocated\">\n+        <term>\n+          <mallctl>thread.allocated</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Get the total number of bytes ever allocated by the\n+        calling thread.  This counter has the potential to wrap around; it is\n+        up to the application to appropriately interpret the counter in such\n+        cases.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>thread.allocatedp</mallctl>\n+          (<type>uint64_t *</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Get a pointer to the the value that is returned by the\n+        <link\n+        linkend=\"thread.allocated\"><mallctl>thread.allocated</mallctl></link>\n+        mallctl.  This is useful for avoiding the overhead of repeated\n+        <function>mallctl*<parameter/></function> calls.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"thread.deallocated\">\n+        <term>\n+          <mallctl>thread.deallocated</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Get the total number of bytes ever deallocated by the\n+        calling thread.  This counter has the potential to wrap around; it is\n+        up to the application to appropriately interpret the counter in such\n+        cases.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>thread.deallocatedp</mallctl>\n+          (<type>uint64_t *</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Get a pointer to the the value that is returned by the\n+        <link\n+        linkend=\"thread.deallocated\"><mallctl>thread.deallocated</mallctl></link>\n+        mallctl.  This is useful for avoiding the overhead of repeated\n+        <function>mallctl*<parameter/></function> calls.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>thread.tcache.enabled</mallctl>\n+          (<type>bool</type>)\n+          <literal>rw</literal>\n+          [<option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Enable/disable calling thread's tcache.  The tcache is\n+        implicitly flushed as a side effect of becoming\n+        disabled (see <link\n+        lenkend=\"thread.tcache.flush\"><mallctl>thread.tcache.flush</mallctl></link>).\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>thread.tcache.flush</mallctl>\n+          (<type>void</type>)\n+          <literal>--</literal>\n+          [<option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Flush calling thread's tcache.  This interface releases\n+        all cached objects and internal data structures associated with the\n+        calling thread's thread-specific cache.  Ordinarily, this interface\n+        need not be called, since automatic periodic incremental garbage\n+        collection occurs, and the thread cache is automatically discarded when\n+        a thread exits.  However, garbage collection is triggered by allocation\n+        activity, so it is possible for a thread that stops\n+        allocating/deallocating to retain its cache indefinitely, in which case\n+        the developer may find manual flushing useful.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"arena.i.purge\">\n+        <term>\n+          <mallctl>arena.&lt;i&gt;.purge</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>--</literal>\n+        </term>\n+        <listitem><para>Purge unused dirty pages for arena &lt;i&gt;, or for\n+        all arenas if &lt;i&gt; equals <link\n+        linkend=\"arenas.narenas\"><mallctl>arenas.narenas</mallctl></link>.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"arena.i.dss\">\n+        <term>\n+          <mallctl>arena.&lt;i&gt;.dss</mallctl>\n+          (<type>const char *</type>)\n+          <literal>rw</literal>\n+        </term>\n+        <listitem><para>Set the precedence of dss allocation as related to mmap\n+        allocation for arena &lt;i&gt;, or for all arenas if &lt;i&gt; equals\n+        <link\n+        linkend=\"arenas.narenas\"><mallctl>arenas.narenas</mallctl></link>.  See\n+        <link linkend=\"opt.dss\"><mallctl>opt.dss</mallctl></link> for supported\n+        settings.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"arenas.narenas\">\n+        <term>\n+          <mallctl>arenas.narenas</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Current limit on number of arenas.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"arenas.initialized\">\n+        <term>\n+          <mallctl>arenas.initialized</mallctl>\n+          (<type>bool *</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>An array of <link\n+        linkend=\"arenas.narenas\"><mallctl>arenas.narenas</mallctl></link>\n+        booleans.  Each boolean indicates whether the corresponding arena is\n+        initialized.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.quantum</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Quantum size.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.page</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Page size.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.tcache_max</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Maximum thread-cached size class.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.nbins</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Number of bin size classes.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.nhbins</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Total number of thread cache bin size\n+        classes.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"arenas.bin.i.size\">\n+        <term>\n+          <mallctl>arenas.bin.&lt;i&gt;.size</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Maximum size supported by size class.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.bin.&lt;i&gt;.nregs</mallctl>\n+          (<type>uint32_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Number of regions per page run.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.bin.&lt;i&gt;.run_size</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Number of bytes per page run.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.nlruns</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Total number of large size classes.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.lrun.&lt;i&gt;.size</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Maximum size supported by this large size\n+        class.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.purge</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>-w</literal>\n+        </term>\n+        <listitem><para>Purge unused dirty pages for the specified arena, or\n+        for all arenas if none is specified.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>arenas.extend</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Extend the array of arenas by appending a new arena,\n+        and returning the new arena index.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"prof.active\">\n+        <term>\n+          <mallctl>prof.active</mallctl>\n+          (<type>bool</type>)\n+          <literal>rw</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Control whether sampling is currently active.  See the\n+        <link\n+        linkend=\"opt.prof_active\"><mallctl>opt.prof_active</mallctl></link>\n+        option for additional information.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>prof.dump</mallctl>\n+          (<type>const char *</type>)\n+          <literal>-w</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Dump a memory profile to the specified file, or if NULL\n+        is specified, to a file according to the pattern\n+        <filename>&lt;prefix&gt;.&lt;pid&gt;.&lt;seq&gt;.m&lt;mseq&gt;.heap</filename>,\n+        where <literal>&lt;prefix&gt;</literal> is controlled by the\n+        <link\n+        linkend=\"opt.prof_prefix\"><mallctl>opt.prof_prefix</mallctl></link>\n+        option.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>prof.interval</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-prof</option>]\n+        </term>\n+        <listitem><para>Average number of bytes allocated between\n+        inverval-based profile dumps.  See the\n+        <link\n+        linkend=\"opt.lg_prof_interval\"><mallctl>opt.lg_prof_interval</mallctl></link>\n+        option for additional information.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"stats.cactive\">\n+        <term>\n+          <mallctl>stats.cactive</mallctl>\n+          (<type>size_t *</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Pointer to a counter that contains an approximate count\n+        of the current number of bytes in active pages.  The estimate may be\n+        high, but never low, because each arena rounds up to the nearest\n+        multiple of the chunk size when computing its contribution to the\n+        counter.  Note that the <link\n+        linkend=\"epoch\"><mallctl>epoch</mallctl></link> mallctl has no bearing\n+        on this counter.  Furthermore, counter consistency is maintained via\n+        atomic operations, so it is necessary to use an atomic operation in\n+        order to guarantee a consistent read when dereferencing the pointer.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"stats.allocated\">\n+        <term>\n+          <mallctl>stats.allocated</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Total number of bytes allocated by the\n+        application.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"stats.active\">\n+        <term>\n+          <mallctl>stats.active</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Total number of bytes in active pages allocated by the\n+        application.  This is a multiple of the page size, and greater than or\n+        equal to <link\n+        linkend=\"stats.allocated\"><mallctl>stats.allocated</mallctl></link>.\n+        This does not include <link linkend=\"stats.arenas.i.pdirty\">\n+        <mallctl>stats.arenas.&lt;i&gt;.pdirty</mallctl></link> and pages\n+        entirely devoted to allocator metadata.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.mapped</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Total number of bytes in chunks mapped on behalf of the\n+        application.  This is a multiple of the chunk size, and is at least as\n+        large as <link\n+        linkend=\"stats.active\"><mallctl>stats.active</mallctl></link>.  This\n+        does not include inactive chunks.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.chunks.current</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Total number of chunks actively mapped on behalf of the\n+        application.  This does not include inactive chunks.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.chunks.total</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of chunks allocated.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.chunks.high</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Maximum number of active chunks at any time thus far.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.huge.allocated</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of bytes currently allocated by huge objects.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.huge.nmalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of huge allocation requests.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.huge.ndalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of huge deallocation requests.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.dss</mallctl>\n+          (<type>const char *</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>dss (<citerefentry><refentrytitle>sbrk</refentrytitle>\n+        <manvolnum>2</manvolnum></citerefentry>) allocation precedence as\n+        related to <citerefentry><refentrytitle>mmap</refentrytitle>\n+        <manvolnum>2</manvolnum></citerefentry> allocation.  See <link\n+        linkend=\"opt.dss\"><mallctl>opt.dss</mallctl></link> for details.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.nthreads</mallctl>\n+          (<type>unsigned</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Number of threads currently assigned to\n+        arena.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.pactive</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Number of pages in active runs.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry id=\"stats.arenas.i.pdirty\">\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.pdirty</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+        </term>\n+        <listitem><para>Number of pages within unused runs that are potentially\n+        dirty, and for which <function>madvise<parameter>...</parameter>\n+        <parameter><constant>MADV_DONTNEED</constant></parameter></function> or\n+        similar has not been called.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.mapped</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of mapped bytes.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.npurge</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of dirty page purge sweeps performed.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.nmadvise</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of <function>madvise<parameter>...</parameter>\n+        <parameter><constant>MADV_DONTNEED</constant></parameter></function> or\n+        similar calls made to purge dirty pages.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.npurged</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of pages purged.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.small.allocated</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of bytes currently allocated by small objects.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.small.nmalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of allocation requests served by\n+        small bins.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.small.ndalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of small objects returned to bins.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.small.nrequests</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of small allocation requests.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.large.allocated</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Number of bytes currently allocated by large objects.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.large.nmalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of large allocation requests served\n+        directly by the arena.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.large.ndalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of large deallocation requests served\n+        directly by the arena.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.large.nrequests</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of large allocation requests.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.allocated</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Current number of bytes allocated by\n+        bin.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.nmalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of allocations served by bin.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.ndalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of allocations returned to bin.\n+        </para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.nrequests</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of allocation\n+        requests.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.nfills</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option> <option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Cumulative number of tcache fills.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.nflushes</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option> <option>--enable-tcache</option>]\n+        </term>\n+        <listitem><para>Cumulative number of tcache flushes.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.nruns</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of runs created.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.nreruns</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of times the current run from which\n+        to allocate changed.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.bins.&lt;j&gt;.curruns</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Current number of runs.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.lruns.&lt;j&gt;.nmalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of allocation requests for this size\n+        class served directly by the arena.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.lruns.&lt;j&gt;.ndalloc</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of deallocation requests for this\n+        size class served directly by the arena.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.lruns.&lt;j&gt;.nrequests</mallctl>\n+          (<type>uint64_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Cumulative number of allocation requests for this size\n+        class.</para></listitem>\n+      </varlistentry>\n+\n+      <varlistentry>\n+        <term>\n+          <mallctl>stats.arenas.&lt;i&gt;.lruns.&lt;j&gt;.curruns</mallctl>\n+          (<type>size_t</type>)\n+          <literal>r-</literal>\n+          [<option>--enable-stats</option>]\n+        </term>\n+        <listitem><para>Current number of runs for this size class.\n+        </para></listitem>\n+      </varlistentry>\n+    </variablelist>\n+  </refsect1>\n+  <refsect1 id=\"debugging_malloc_problems\">\n+    <title>DEBUGGING MALLOC PROBLEMS</title>\n+    <para>When debugging, it is a good idea to configure/build jemalloc with\n+    the <option>--enable-debug</option> and <option>--enable-fill</option>\n+    options, and recompile the program with suitable options and symbols for\n+    debugger support.  When so configured, jemalloc incorporates a wide variety\n+    of run-time assertions that catch application errors such as double-free,\n+    write-after-free, etc.</para>\n+\n+    <para>Programs often accidentally depend on &ldquo;uninitialized&rdquo;\n+    memory actually being filled with zero bytes.  Junk filling\n+    (see the <link linkend=\"opt.junk\"><mallctl>opt.junk</mallctl></link>\n+    option) tends to expose such bugs in the form of obviously incorrect\n+    results and/or coredumps.  Conversely, zero\n+    filling (see the <link\n+    linkend=\"opt.zero\"><mallctl>opt.zero</mallctl></link> option) eliminates\n+    the symptoms of such bugs.  Between these two options, it is usually\n+    possible to quickly detect, diagnose, and eliminate such bugs.</para>\n+\n+    <para>This implementation does not provide much detail about the problems\n+    it detects, because the performance impact for storing such information\n+    would be prohibitive.  However, jemalloc does integrate with the most\n+    excellent <ulink url=\"http://valgrind.org/\">Valgrind</ulink> tool if the\n+    <option>--enable-valgrind</option> configuration option is enabled.</para>\n+  </refsect1>\n+  <refsect1 id=\"diagnostic_messages\">\n+    <title>DIAGNOSTIC MESSAGES</title>\n+    <para>If any of the memory allocation/deallocation functions detect an\n+    error or warning condition, a message will be printed to file descriptor\n+    <constant>STDERR_FILENO</constant>.  Errors will result in the process\n+    dumping core.  If the <link\n+    linkend=\"opt.abort\"><mallctl>opt.abort</mallctl></link> option is set, most\n+    warnings are treated as errors.</para>\n+\n+    <para>The <varname>malloc_message</varname> variable allows the programmer\n+    to override the function which emits the text strings forming the errors\n+    and warnings if for some reason the <constant>STDERR_FILENO</constant> file\n+    descriptor is not suitable for this.\n+    <function>malloc_message<parameter/></function> takes the\n+    <parameter>cbopaque</parameter> pointer argument that is\n+    <constant>NULL</constant> unless overridden by the arguments in a call to\n+    <function>malloc_stats_print<parameter/></function>, followed by a string\n+    pointer.  Please note that doing anything which tries to allocate memory in\n+    this function is likely to result in a crash or deadlock.</para>\n+\n+    <para>All messages are prefixed by\n+    &ldquo;<computeroutput>&lt;jemalloc&gt;: </computeroutput>&rdquo;.</para>\n+  </refsect1>\n+  <refsect1 id=\"return_values\">\n+    <title>RETURN VALUES</title>\n+    <refsect2>\n+      <title>Standard API</title>\n+      <para>The <function>malloc<parameter/></function> and\n+      <function>calloc<parameter/></function> functions return a pointer to the\n+      allocated memory if successful; otherwise a <constant>NULL</constant>\n+      pointer is returned and <varname>errno</varname> is set to\n+      <errorname>ENOMEM</errorname>.</para>\n+\n+      <para>The <function>posix_memalign<parameter/></function> function\n+      returns the value 0 if successful; otherwise it returns an error value.\n+      The <function>posix_memalign<parameter/></function> function will fail\n+      if:\n+        <variablelist>\n+          <varlistentry>\n+            <term><errorname>EINVAL</errorname></term>\n+\n+            <listitem><para>The <parameter>alignment</parameter> parameter is\n+            not a power of 2 at least as large as\n+            <code language=\"C\">sizeof(<type>void *</type>)</code>.\n+            </para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>ENOMEM</errorname></term>\n+\n+            <listitem><para>Memory allocation error.</para></listitem>\n+          </varlistentry>\n+        </variablelist>\n+      </para>\n+\n+      <para>The <function>aligned_alloc<parameter/></function> function returns\n+      a pointer to the allocated memory if successful; otherwise a\n+      <constant>NULL</constant> pointer is returned and\n+      <varname>errno</varname> is set.  The\n+      <function>aligned_alloc<parameter/></function> function will fail if:\n+        <variablelist>\n+          <varlistentry>\n+            <term><errorname>EINVAL</errorname></term>\n+\n+            <listitem><para>The <parameter>alignment</parameter> parameter is\n+            not a power of 2.\n+            </para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>ENOMEM</errorname></term>\n+\n+            <listitem><para>Memory allocation error.</para></listitem>\n+          </varlistentry>\n+        </variablelist>\n+      </para>\n+\n+      <para>The <function>realloc<parameter/></function> function returns a\n+      pointer, possibly identical to <parameter>ptr</parameter>, to the\n+      allocated memory if successful; otherwise a <constant>NULL</constant>\n+      pointer is returned, and <varname>errno</varname> is set to\n+      <errorname>ENOMEM</errorname> if the error was the result of an\n+      allocation failure.  The <function>realloc<parameter/></function>\n+      function always leaves the original buffer intact when an error occurs.\n+      </para>\n+\n+      <para>The <function>free<parameter/></function> function returns no\n+      value.</para>\n+    </refsect2>\n+    <refsect2>\n+      <title>Non-standard API</title>\n+      <para>The <function>malloc_usable_size<parameter/></function> function\n+      returns the usable size of the allocation pointed to by\n+      <parameter>ptr</parameter>.  </para>\n+\n+      <para>The <function>mallctl<parameter/></function>,\n+      <function>mallctlnametomib<parameter/></function>, and\n+      <function>mallctlbymib<parameter/></function> functions return 0 on\n+      success; otherwise they return an error value.  The functions will fail\n+      if:\n+        <variablelist>\n+          <varlistentry>\n+            <term><errorname>EINVAL</errorname></term>\n+\n+            <listitem><para><parameter>newp</parameter> is not\n+            <constant>NULL</constant>, and <parameter>newlen</parameter> is too\n+            large or too small.  Alternatively, <parameter>*oldlenp</parameter>\n+            is too large or too small; in this case as much data as possible\n+            are read despite the error.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>ENOMEM</errorname></term>\n+\n+            <listitem><para><parameter>*oldlenp</parameter> is too short to\n+            hold the requested value.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>ENOENT</errorname></term>\n+\n+            <listitem><para><parameter>name</parameter> or\n+            <parameter>mib</parameter> specifies an unknown/invalid\n+            value.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>EPERM</errorname></term>\n+\n+            <listitem><para>Attempt to read or write void value, or attempt to\n+            write read-only value.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>EAGAIN</errorname></term>\n+\n+            <listitem><para>A memory allocation failure\n+            occurred.</para></listitem>\n+          </varlistentry>\n+          <varlistentry>\n+            <term><errorname>EFAULT</errorname></term>\n+\n+            <listitem><para>An interface with side effects failed in some way\n+            not directly related to <function>mallctl*<parameter/></function>\n+            read/write processing.</para></listitem>\n+          </varlistentry>\n+        </variablelist>\n+      </para>\n+    </refsect2>\n+    <refsect2>\n+      <title>Experimental API</title>\n+      <para>The <function>allocm<parameter/></function>,\n+      <function>rallocm<parameter/></function>,\n+      <function>sallocm<parameter/></function>,\n+      <function>dallocm<parameter/></function>, and\n+      <function>nallocm<parameter/></function> functions return\n+      <constant>ALLOCM_SUCCESS</constant> on success; otherwise they return an\n+      error value.  The <function>allocm<parameter/></function>,\n+      <function>rallocm<parameter/></function>, and\n+      <function>nallocm<parameter/></function> functions will fail if:\n+        <variablelist>\n+          <varlistentry>\n+            <term><errorname>ALLOCM_ERR_OOM</errorname></term>\n+\n+            <listitem><para>Out of memory.  Insufficient contiguous memory was\n+            available to service the allocation request.  The\n+            <function>allocm<parameter/></function> function additionally sets\n+            <parameter>*ptr</parameter> to <constant>NULL</constant>, whereas\n+            the <function>rallocm<parameter/></function> function leaves\n+            <constant>*ptr</constant> unmodified.</para></listitem>\n+          </varlistentry>\n+        </variablelist>\n+      The <function>rallocm<parameter/></function> function will also\n+      fail if:\n+        <variablelist>\n+          <varlistentry>\n+            <term><errorname>ALLOCM_ERR_NOT_MOVED</errorname></term>\n+\n+            <listitem><para><constant>ALLOCM_NO_MOVE</constant> was specified,\n+            but the reallocation request could not be serviced without moving\n+            the object.</para></listitem>\n+          </varlistentry>\n+        </variablelist>\n+      </para>\n+    </refsect2>\n+  </refsect1>\n+  <refsect1 id=\"environment\">\n+    <title>ENVIRONMENT</title>\n+    <para>The following environment variable affects the execution of the\n+    allocation functions:\n+      <variablelist>\n+        <varlistentry>\n+          <term><envar>MALLOC_CONF</envar></term>\n+\n+          <listitem><para>If the environment variable\n+          <envar>MALLOC_CONF</envar> is set, the characters it contains\n+          will be interpreted as options.</para></listitem>\n+        </varlistentry>\n+      </variablelist>\n+    </para>\n+  </refsect1>\n+  <refsect1 id=\"examples\">\n+    <title>EXAMPLES</title>\n+    <para>To dump core whenever a problem occurs:\n+      <screen>ln -s 'abort:true' /etc/malloc.conf</screen>\n+    </para>\n+    <para>To specify in the source a chunk size that is 16 MiB:\n+      <programlisting language=\"C\"><![CDATA[\n+malloc_conf = \"lg_chunk:24\";]]></programlisting></para>\n+  </refsect1>\n+  <refsect1 id=\"see_also\">\n+    <title>SEE ALSO</title>\n+    <para><citerefentry><refentrytitle>madvise</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry>,\n+    <citerefentry><refentrytitle>mmap</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry>,\n+    <citerefentry><refentrytitle>sbrk</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry>,\n+    <citerefentry><refentrytitle>utrace</refentrytitle>\n+    <manvolnum>2</manvolnum></citerefentry>,\n+    <citerefentry><refentrytitle>alloca</refentrytitle>\n+    <manvolnum>3</manvolnum></citerefentry>,\n+    <citerefentry><refentrytitle>atexit</refentrytitle>\n+    <manvolnum>3</manvolnum></citerefentry>,\n+    <citerefentry><refentrytitle>getpagesize</refentrytitle>\n+    <manvolnum>3</manvolnum></citerefentry></para>\n+  </refsect1>\n+  <refsect1 id=\"standards\">\n+    <title>STANDARDS</title>\n+    <para>The <function>malloc<parameter/></function>,\n+    <function>calloc<parameter/></function>,\n+    <function>realloc<parameter/></function>, and\n+    <function>free<parameter/></function> functions conform to ISO/IEC\n+    9899:1990 (&ldquo;ISO C90&rdquo;).</para>\n+\n+    <para>The <function>posix_memalign<parameter/></function> function conforms\n+    to IEEE Std 1003.1-2001 (&ldquo;POSIX.1&rdquo;).</para>\n+  </refsect1>\n+</refentry>"}, {"sha": "88b2626b958135e7ab822e7bfe630b6e813321f1", "filename": "src/rt/jemalloc/doc/manpages.xsl.in", "status": "added", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fmanpages.xsl.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fmanpages.xsl.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fdoc%2Fmanpages.xsl.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,4 @@\n+<xsl:stylesheet xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" version=\"1.0\">\n+  <xsl:import href=\"@XSLROOT@/manpages/docbook.xsl\"/>\n+  <xsl:import href=\"@abs_srcroot@doc/stylesheet.xsl\"/>\n+</xsl:stylesheet>"}, {"sha": "4e334a86f8770e67d53f09d1403b5fb1bb277729", "filename": "src/rt/jemalloc/doc/stylesheet.xsl", "status": "added", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fstylesheet.xsl", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fdoc%2Fstylesheet.xsl", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fdoc%2Fstylesheet.xsl?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,7 @@\n+<xsl:stylesheet xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" version=\"1.0\">\n+  <xsl:param name=\"funcsynopsis.style\">ansi</xsl:param>\n+  <xsl:param name=\"function.parens\" select=\"1\"/>\n+  <xsl:template match=\"mallctl\">\n+    \"<xsl:call-template name=\"inline.monoseq\"/>\"\n+  </xsl:template>\n+</xsl:stylesheet>"}, {"sha": "2ac5342d778a8d9107251c90d01d1b844a0b0d55", "filename": "src/rt/jemalloc/include/jemalloc/internal/arena.h", "status": "added", "additions": 1022, "deletions": 0, "changes": 1022, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Farena.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Farena.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Farena.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,1022 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+/*\n+ * RUN_MAX_OVRHD indicates maximum desired run header overhead.  Runs are sized\n+ * as small as possible such that this setting is still honored, without\n+ * violating other constraints.  The goal is to make runs as small as possible\n+ * without exceeding a per run external fragmentation threshold.\n+ *\n+ * We use binary fixed point math for overhead computations, where the binary\n+ * point is implicitly RUN_BFP bits to the left.\n+ *\n+ * Note that it is possible to set RUN_MAX_OVRHD low enough that it cannot be\n+ * honored for some/all object sizes, since when heap profiling is enabled\n+ * there is one pointer of header overhead per object (plus a constant).  This\n+ * constraint is relaxed (ignored) for runs that are so small that the\n+ * per-region overhead is greater than:\n+ *\n+ *   (RUN_MAX_OVRHD / (reg_interval << (3+RUN_BFP))\n+ */\n+#define\tRUN_BFP\t\t\t12\n+/*                                    \\/   Implicit binary fixed point. */\n+#define\tRUN_MAX_OVRHD\t\t0x0000003dU\n+#define\tRUN_MAX_OVRHD_RELAX\t0x00001800U\n+\n+/* Maximum number of regions in one run. */\n+#define\tLG_RUN_MAXREGS\t\t11\n+#define\tRUN_MAXREGS\t\t(1U << LG_RUN_MAXREGS)\n+\n+/*\n+ * Minimum redzone size.  Redzones may be larger than this if necessary to\n+ * preserve region alignment.\n+ */\n+#define\tREDZONE_MINSIZE\t\t16\n+\n+/*\n+ * The minimum ratio of active:dirty pages per arena is computed as:\n+ *\n+ *   (nactive >> opt_lg_dirty_mult) >= ndirty\n+ *\n+ * So, supposing that opt_lg_dirty_mult is 3, there can be no less than 8 times\n+ * as many active pages as dirty pages.\n+ */\n+#define\tLG_DIRTY_MULT_DEFAULT\t3\n+\n+typedef struct arena_chunk_map_s arena_chunk_map_t;\n+typedef struct arena_chunk_s arena_chunk_t;\n+typedef struct arena_run_s arena_run_t;\n+typedef struct arena_bin_info_s arena_bin_info_t;\n+typedef struct arena_bin_s arena_bin_t;\n+typedef struct arena_s arena_t;\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+/* Each element of the chunk map corresponds to one page within the chunk. */\n+struct arena_chunk_map_s {\n+#ifndef JEMALLOC_PROF\n+    /*\n+     * Overlay prof_ctx in order to allow it to be referenced by dead code.\n+     * Such antics aren't warranted for per arena data structures, but\n+     * chunk map overhead accounts for a percentage of memory, rather than\n+     * being just a fixed cost.\n+     */\n+    union {\n+#endif\n+    union {\n+        /*\n+         * Linkage for run trees.  There are two disjoint uses:\n+         *\n+         * 1) arena_t's runs_avail tree.\n+         * 2) arena_run_t conceptually uses this linkage for in-use\n+         *    non-full runs, rather than directly embedding linkage.\n+         */\n+        rb_node(arena_chunk_map_t)\trb_link;\n+        /*\n+         * List of runs currently in purgatory.  arena_chunk_purge()\n+         * temporarily allocates runs that contain dirty pages while\n+         * purging, so that other threads cannot use the runs while the\n+         * purging thread is operating without the arena lock held.\n+         */\n+        ql_elm(arena_chunk_map_t)\tql_link;\n+    }\t\t\t\tu;\n+\n+    /* Profile counters, used for large object runs. */\n+    prof_ctx_t\t\t\t*prof_ctx;\n+#ifndef JEMALLOC_PROF\n+    }; /* union { ... }; */\n+#endif\n+\n+    /*\n+     * Run address (or size) and various flags are stored together.  The bit\n+     * layout looks like (assuming 32-bit system):\n+     *\n+     *   ???????? ???????? ????nnnn nnnndula\n+     *\n+     * ? : Unallocated: Run address for first/last pages, unset for internal\n+     *                  pages.\n+     *     Small: Run page offset.\n+     *     Large: Run size for first page, unset for trailing pages.\n+     * n : binind for small size class, BININD_INVALID for large size class.\n+     * d : dirty?\n+     * u : unzeroed?\n+     * l : large?\n+     * a : allocated?\n+     *\n+     * Following are example bit patterns for the three types of runs.\n+     *\n+     * p : run page offset\n+     * s : run size\n+     * n : binind for size class; large objects set these to BININD_INVALID\n+     *     except for promoted allocations (see prof_promote)\n+     * x : don't care\n+     * - : 0\n+     * + : 1\n+     * [DULA] : bit set\n+     * [dula] : bit unset\n+     *\n+     *   Unallocated (clean):\n+     *     ssssssss ssssssss ssss++++ ++++du-a\n+     *     xxxxxxxx xxxxxxxx xxxxxxxx xxxx-Uxx\n+     *     ssssssss ssssssss ssss++++ ++++dU-a\n+     *\n+     *   Unallocated (dirty):\n+     *     ssssssss ssssssss ssss++++ ++++D--a\n+     *     xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx\n+     *     ssssssss ssssssss ssss++++ ++++D--a\n+     *\n+     *   Small:\n+     *     pppppppp pppppppp ppppnnnn nnnnd--A\n+     *     pppppppp pppppppp ppppnnnn nnnn---A\n+     *     pppppppp pppppppp ppppnnnn nnnnd--A\n+     *\n+     *   Large:\n+     *     ssssssss ssssssss ssss++++ ++++D-LA\n+     *     xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx\n+     *     -------- -------- ----++++ ++++D-LA\n+     *\n+     *   Large (sampled, size <= PAGE):\n+     *     ssssssss ssssssss ssssnnnn nnnnD-LA\n+     *\n+     *   Large (not sampled, size == PAGE):\n+     *     ssssssss ssssssss ssss++++ ++++D-LA\n+     */\n+    size_t\t\t\t\tbits;\n+#define\tCHUNK_MAP_BININD_SHIFT\t4\n+#define\tBININD_INVALID\t\t((size_t)0xffU)\n+/*     CHUNK_MAP_BININD_MASK == (BININD_INVALID << CHUNK_MAP_BININD_SHIFT) */\n+#define\tCHUNK_MAP_BININD_MASK\t((size_t)0xff0U)\n+#define\tCHUNK_MAP_BININD_INVALID CHUNK_MAP_BININD_MASK\n+#define\tCHUNK_MAP_FLAGS_MASK\t((size_t)0xcU)\n+#define\tCHUNK_MAP_DIRTY\t\t((size_t)0x8U)\n+#define\tCHUNK_MAP_UNZEROED\t((size_t)0x4U)\n+#define\tCHUNK_MAP_LARGE\t\t((size_t)0x2U)\n+#define\tCHUNK_MAP_ALLOCATED\t((size_t)0x1U)\n+#define\tCHUNK_MAP_KEY\t\tCHUNK_MAP_ALLOCATED\n+};\n+typedef rb_tree(arena_chunk_map_t) arena_avail_tree_t;\n+typedef rb_tree(arena_chunk_map_t) arena_run_tree_t;\n+\n+/* Arena chunk header. */\n+struct arena_chunk_s {\n+    /* Arena that owns the chunk. */\n+    arena_t\t\t\t*arena;\n+\n+    /* Linkage for tree of arena chunks that contain dirty runs. */\n+    rb_node(arena_chunk_t)\tdirty_link;\n+\n+    /* Number of dirty pages. */\n+    size_t\t\t\tndirty;\n+\n+    /* Number of available runs. */\n+    size_t\t\t\tnruns_avail;\n+\n+    /*\n+     * Number of available run adjacencies.  Clean and dirty available runs\n+     * are not coalesced, which causes virtual memory fragmentation.  The\n+     * ratio of (nruns_avail-nruns_adjac):nruns_adjac is used for tracking\n+     * this fragmentation.\n+     * */\n+    size_t\t\t\tnruns_adjac;\n+\n+    /*\n+     * Map of pages within chunk that keeps track of free/large/small.  The\n+     * first map_bias entries are omitted, since the chunk header does not\n+     * need to be tracked in the map.  This omission saves a header page\n+     * for common chunk sizes (e.g. 4 MiB).\n+     */\n+    arena_chunk_map_t\tmap[1]; /* Dynamically sized. */\n+};\n+typedef rb_tree(arena_chunk_t) arena_chunk_tree_t;\n+\n+struct arena_run_s {\n+    /* Bin this run is associated with. */\n+    arena_bin_t\t*bin;\n+\n+    /* Index of next region that has never been allocated, or nregs. */\n+    uint32_t\tnextind;\n+\n+    /* Number of free regions in run. */\n+    unsigned\tnfree;\n+};\n+\n+/*\n+ * Read-only information associated with each element of arena_t's bins array\n+ * is stored separately, partly to reduce memory usage (only one copy, rather\n+ * than one per arena), but mainly to avoid false cacheline sharing.\n+ *\n+ * Each run has the following layout:\n+ *\n+ *               /--------------------\\\n+ *               | arena_run_t header |\n+ *               | ...                |\n+ * bitmap_offset | bitmap             |\n+ *               | ...                |\n+ *   ctx0_offset | ctx map            |\n+ *               | ...                |\n+ *               |--------------------|\n+ *               | redzone            |\n+ *   reg0_offset | region 0           |\n+ *               | redzone            |\n+ *               |--------------------| \\\n+ *               | redzone            | |\n+ *               | region 1           |  > reg_interval\n+ *               | redzone            | /\n+ *               |--------------------|\n+ *               | ...                |\n+ *               | ...                |\n+ *               | ...                |\n+ *               |--------------------|\n+ *               | redzone            |\n+ *               | region nregs-1     |\n+ *               | redzone            |\n+ *               |--------------------|\n+ *               | alignment pad?     |\n+ *               \\--------------------/\n+ *\n+ * reg_interval has at least the same minimum alignment as reg_size; this\n+ * preserves the alignment constraint that sa2u() depends on.  Alignment pad is\n+ * either 0 or redzone_size; it is present only if needed to align reg0_offset.\n+ */\n+struct arena_bin_info_s {\n+    /* Size of regions in a run for this bin's size class. */\n+    size_t\t\treg_size;\n+\n+    /* Redzone size. */\n+    size_t\t\tredzone_size;\n+\n+    /* Interval between regions (reg_size + (redzone_size << 1)). */\n+    size_t\t\treg_interval;\n+\n+    /* Total size of a run for this bin's size class. */\n+    size_t\t\trun_size;\n+\n+    /* Total number of regions in a run for this bin's size class. */\n+    uint32_t\tnregs;\n+\n+    /*\n+     * Offset of first bitmap_t element in a run header for this bin's size\n+     * class.\n+     */\n+    uint32_t\tbitmap_offset;\n+\n+    /*\n+     * Metadata used to manipulate bitmaps for runs associated with this\n+     * bin.\n+     */\n+    bitmap_info_t\tbitmap_info;\n+\n+    /*\n+     * Offset of first (prof_ctx_t *) in a run header for this bin's size\n+     * class, or 0 if (config_prof == false || opt_prof == false).\n+     */\n+    uint32_t\tctx0_offset;\n+\n+    /* Offset of first region in a run for this bin's size class. */\n+    uint32_t\treg0_offset;\n+};\n+\n+struct arena_bin_s {\n+    /*\n+     * All operations on runcur, runs, and stats require that lock be\n+     * locked.  Run allocation/deallocation are protected by the arena lock,\n+     * which may be acquired while holding one or more bin locks, but not\n+     * vise versa.\n+     */\n+    malloc_mutex_t\tlock;\n+\n+    /*\n+     * Current run being used to service allocations of this bin's size\n+     * class.\n+     */\n+    arena_run_t\t*runcur;\n+\n+    /*\n+     * Tree of non-full runs.  This tree is used when looking for an\n+     * existing run when runcur is no longer usable.  We choose the\n+     * non-full run that is lowest in memory; this policy tends to keep\n+     * objects packed well, and it can also help reduce the number of\n+     * almost-empty chunks.\n+     */\n+    arena_run_tree_t runs;\n+\n+    /* Bin statistics. */\n+    malloc_bin_stats_t stats;\n+};\n+\n+struct arena_s {\n+    /* This arena's index within the arenas array. */\n+    unsigned\t\tind;\n+\n+    /*\n+     * Number of threads currently assigned to this arena.  This field is\n+     * protected by arenas_lock.\n+     */\n+    unsigned\t\tnthreads;\n+\n+    /*\n+     * There are three classes of arena operations from a locking\n+     * perspective:\n+     * 1) Thread asssignment (modifies nthreads) is protected by\n+     *    arenas_lock.\n+     * 2) Bin-related operations are protected by bin locks.\n+     * 3) Chunk- and run-related operations are protected by this mutex.\n+     */\n+    malloc_mutex_t\t\tlock;\n+\n+    arena_stats_t\t\tstats;\n+    /*\n+     * List of tcaches for extant threads associated with this arena.\n+     * Stats from these are merged incrementally, and at exit.\n+     */\n+    ql_head(tcache_t)\ttcache_ql;\n+\n+    uint64_t\t\tprof_accumbytes;\n+\n+    dss_prec_t\t\tdss_prec;\n+\n+    /* Tree of dirty-page-containing chunks this arena manages. */\n+    arena_chunk_tree_t\tchunks_dirty;\n+\n+    /*\n+     * In order to avoid rapid chunk allocation/deallocation when an arena\n+     * oscillates right on the cusp of needing a new chunk, cache the most\n+     * recently freed chunk.  The spare is left in the arena's chunk trees\n+     * until it is deleted.\n+     *\n+     * There is one spare chunk per arena, rather than one spare total, in\n+     * order to avoid interactions between multiple threads that could make\n+     * a single spare inadequate.\n+     */\n+    arena_chunk_t\t\t*spare;\n+\n+    /* Number of pages in active runs. */\n+    size_t\t\t\tnactive;\n+\n+    /*\n+     * Current count of pages within unused runs that are potentially\n+     * dirty, and for which madvise(... MADV_DONTNEED) has not been called.\n+     * By tracking this, we can institute a limit on how much dirty unused\n+     * memory is mapped for each arena.\n+     */\n+    size_t\t\t\tndirty;\n+\n+    /*\n+     * Approximate number of pages being purged.  It is possible for\n+     * multiple threads to purge dirty pages concurrently, and they use\n+     * npurgatory to indicate the total number of pages all threads are\n+     * attempting to purge.\n+     */\n+    size_t\t\t\tnpurgatory;\n+\n+    /*\n+     * Size/address-ordered trees of this arena's available runs.  The trees\n+     * are used for first-best-fit run allocation.\n+     */\n+    arena_avail_tree_t\truns_avail;\n+\n+    /* bins is used to store trees of free regions. */\n+    arena_bin_t\t\tbins[NBINS];\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+extern ssize_t\topt_lg_dirty_mult;\n+/*\n+ * small_size2bin is a compact lookup table that rounds request sizes up to\n+ * size classes.  In order to reduce cache footprint, the table is compressed,\n+ * and all accesses are via the SMALL_SIZE2BIN macro.\n+ */\n+extern uint8_t const\tsmall_size2bin[];\n+#define\tSMALL_SIZE2BIN(s)\t(small_size2bin[(s-1) >> LG_TINY_MIN])\n+\n+extern arena_bin_info_t\tarena_bin_info[NBINS];\n+\n+/* Number of large size classes. */\n+#define\t\t\tnlclasses (chunk_npages - map_bias)\n+\n+void\tarena_purge_all(arena_t *arena);\n+void\tarena_tcache_fill_small(arena_t *arena, tcache_bin_t *tbin,\n+    size_t binind, uint64_t prof_accumbytes);\n+void\tarena_alloc_junk_small(void *ptr, arena_bin_info_t *bin_info,\n+    bool zero);\n+void\tarena_dalloc_junk_small(void *ptr, arena_bin_info_t *bin_info);\n+void\t*arena_malloc_small(arena_t *arena, size_t size, bool zero);\n+void\t*arena_malloc_large(arena_t *arena, size_t size, bool zero);\n+void\t*arena_palloc(arena_t *arena, size_t size, size_t alignment, bool zero);\n+void\tarena_prof_promoted(const void *ptr, size_t size);\n+void\tarena_dalloc_bin_locked(arena_t *arena, arena_chunk_t *chunk, void *ptr,\n+    arena_chunk_map_t *mapelm);\n+void\tarena_dalloc_bin(arena_t *arena, arena_chunk_t *chunk, void *ptr,\n+    size_t pageind, arena_chunk_map_t *mapelm);\n+void\tarena_dalloc_small(arena_t *arena, arena_chunk_t *chunk, void *ptr,\n+    size_t pageind);\n+void\tarena_dalloc_large_locked(arena_t *arena, arena_chunk_t *chunk,\n+    void *ptr);\n+void\tarena_dalloc_large(arena_t *arena, arena_chunk_t *chunk, void *ptr);\n+void\t*arena_ralloc_no_move(void *ptr, size_t oldsize, size_t size,\n+    size_t extra, bool zero);\n+void\t*arena_ralloc(arena_t *arena, void *ptr, size_t oldsize, size_t size,\n+    size_t extra, size_t alignment, bool zero, bool try_tcache_alloc,\n+    bool try_tcache_dalloc);\n+dss_prec_t\tarena_dss_prec_get(arena_t *arena);\n+void\tarena_dss_prec_set(arena_t *arena, dss_prec_t dss_prec);\n+void\tarena_stats_merge(arena_t *arena, const char **dss, size_t *nactive,\n+    size_t *ndirty, arena_stats_t *astats, malloc_bin_stats_t *bstats,\n+    malloc_large_stats_t *lstats);\n+bool\tarena_new(arena_t *arena, unsigned ind);\n+void\tarena_boot(void);\n+void\tarena_prefork(arena_t *arena);\n+void\tarena_postfork_parent(arena_t *arena);\n+void\tarena_postfork_child(arena_t *arena);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+arena_chunk_map_t\t*arena_mapp_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\t*arena_mapbitsp_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_unallocated_size_get(arena_chunk_t *chunk,\n+    size_t pageind);\n+size_t\tarena_mapbits_large_size_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_small_runind_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_binind_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_dirty_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_unzeroed_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_large_get(arena_chunk_t *chunk, size_t pageind);\n+size_t\tarena_mapbits_allocated_get(arena_chunk_t *chunk, size_t pageind);\n+void\tarena_mapbits_unallocated_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t size, size_t flags);\n+void\tarena_mapbits_unallocated_size_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t size);\n+void\tarena_mapbits_large_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t size, size_t flags);\n+void\tarena_mapbits_large_binind_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t binind);\n+void\tarena_mapbits_small_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t runind, size_t binind, size_t flags);\n+void\tarena_mapbits_unzeroed_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t unzeroed);\n+bool\tarena_prof_accum_impl(arena_t *arena, uint64_t accumbytes);\n+bool\tarena_prof_accum_locked(arena_t *arena, uint64_t accumbytes);\n+bool\tarena_prof_accum(arena_t *arena, uint64_t accumbytes);\n+size_t\tarena_ptr_small_binind_get(const void *ptr, size_t mapbits);\n+size_t\tarena_bin_index(arena_t *arena, arena_bin_t *bin);\n+unsigned\tarena_run_regind(arena_run_t *run, arena_bin_info_t *bin_info,\n+    const void *ptr);\n+prof_ctx_t\t*arena_prof_ctx_get(const void *ptr);\n+void\tarena_prof_ctx_set(const void *ptr, prof_ctx_t *ctx);\n+void\t*arena_malloc(arena_t *arena, size_t size, bool zero, bool try_tcache);\n+size_t\tarena_salloc(const void *ptr, bool demote);\n+void\tarena_dalloc(arena_t *arena, arena_chunk_t *chunk, void *ptr,\n+    bool try_tcache);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_ARENA_C_))\n+#  ifdef JEMALLOC_ARENA_INLINE_A\n+JEMALLOC_ALWAYS_INLINE arena_chunk_map_t *\n+arena_mapp_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+\n+    assert(pageind >= map_bias);\n+    assert(pageind < chunk_npages);\n+\n+    return (&chunk->map[pageind-map_bias]);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t *\n+arena_mapbitsp_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+\n+    return (&arena_mapp_get(chunk, pageind)->bits);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+\n+    return (*arena_mapbitsp_get(chunk, pageind));\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_unallocated_size_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    assert((mapbits & (CHUNK_MAP_LARGE|CHUNK_MAP_ALLOCATED)) == 0);\n+    return (mapbits & ~PAGE_MASK);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_large_size_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    assert((mapbits & (CHUNK_MAP_LARGE|CHUNK_MAP_ALLOCATED)) ==\n+        (CHUNK_MAP_LARGE|CHUNK_MAP_ALLOCATED));\n+    return (mapbits & ~PAGE_MASK);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_small_runind_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    assert((mapbits & (CHUNK_MAP_LARGE|CHUNK_MAP_ALLOCATED)) ==\n+        CHUNK_MAP_ALLOCATED);\n+    return (mapbits >> LG_PAGE);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_binind_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+    size_t binind;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    binind = (mapbits & CHUNK_MAP_BININD_MASK) >> CHUNK_MAP_BININD_SHIFT;\n+    assert(binind < NBINS || binind == BININD_INVALID);\n+    return (binind);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_dirty_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    return (mapbits & CHUNK_MAP_DIRTY);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_unzeroed_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    return (mapbits & CHUNK_MAP_UNZEROED);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_large_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    return (mapbits & CHUNK_MAP_LARGE);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_mapbits_allocated_get(arena_chunk_t *chunk, size_t pageind)\n+{\n+    size_t mapbits;\n+\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    return (mapbits & CHUNK_MAP_ALLOCATED);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_mapbits_unallocated_set(arena_chunk_t *chunk, size_t pageind, size_t size,\n+    size_t flags)\n+{\n+    size_t *mapbitsp;\n+\n+    mapbitsp = arena_mapbitsp_get(chunk, pageind);\n+    assert((size & PAGE_MASK) == 0);\n+    assert((flags & ~CHUNK_MAP_FLAGS_MASK) == 0);\n+    assert((flags & (CHUNK_MAP_DIRTY|CHUNK_MAP_UNZEROED)) == flags);\n+    *mapbitsp = size | CHUNK_MAP_BININD_INVALID | flags;\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_mapbits_unallocated_size_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t size)\n+{\n+    size_t *mapbitsp;\n+\n+    mapbitsp = arena_mapbitsp_get(chunk, pageind);\n+    assert((size & PAGE_MASK) == 0);\n+    assert((*mapbitsp & (CHUNK_MAP_LARGE|CHUNK_MAP_ALLOCATED)) == 0);\n+    *mapbitsp = size | (*mapbitsp & PAGE_MASK);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_mapbits_large_set(arena_chunk_t *chunk, size_t pageind, size_t size,\n+    size_t flags)\n+{\n+    size_t *mapbitsp;\n+    size_t unzeroed;\n+\n+    mapbitsp = arena_mapbitsp_get(chunk, pageind);\n+    assert((size & PAGE_MASK) == 0);\n+    assert((flags & CHUNK_MAP_DIRTY) == flags);\n+    unzeroed = *mapbitsp & CHUNK_MAP_UNZEROED; /* Preserve unzeroed. */\n+    *mapbitsp = size | CHUNK_MAP_BININD_INVALID | flags | unzeroed |\n+        CHUNK_MAP_LARGE | CHUNK_MAP_ALLOCATED;\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_mapbits_large_binind_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t binind)\n+{\n+    size_t *mapbitsp;\n+\n+    assert(binind <= BININD_INVALID);\n+    mapbitsp = arena_mapbitsp_get(chunk, pageind);\n+    assert(arena_mapbits_large_size_get(chunk, pageind) == PAGE);\n+    *mapbitsp = (*mapbitsp & ~CHUNK_MAP_BININD_MASK) | (binind <<\n+        CHUNK_MAP_BININD_SHIFT);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_mapbits_small_set(arena_chunk_t *chunk, size_t pageind, size_t runind,\n+    size_t binind, size_t flags)\n+{\n+    size_t *mapbitsp;\n+    size_t unzeroed;\n+\n+    assert(binind < BININD_INVALID);\n+    mapbitsp = arena_mapbitsp_get(chunk, pageind);\n+    assert(pageind - runind >= map_bias);\n+    assert((flags & CHUNK_MAP_DIRTY) == flags);\n+    unzeroed = *mapbitsp & CHUNK_MAP_UNZEROED; /* Preserve unzeroed. */\n+    *mapbitsp = (runind << LG_PAGE) | (binind << CHUNK_MAP_BININD_SHIFT) |\n+        flags | unzeroed | CHUNK_MAP_ALLOCATED;\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_mapbits_unzeroed_set(arena_chunk_t *chunk, size_t pageind,\n+    size_t unzeroed)\n+{\n+    size_t *mapbitsp;\n+\n+    mapbitsp = arena_mapbitsp_get(chunk, pageind);\n+    *mapbitsp = (*mapbitsp & ~CHUNK_MAP_UNZEROED) | unzeroed;\n+}\n+\n+JEMALLOC_INLINE bool\n+arena_prof_accum_impl(arena_t *arena, uint64_t accumbytes)\n+{\n+\n+    cassert(config_prof);\n+    assert(prof_interval != 0);\n+\n+    arena->prof_accumbytes += accumbytes;\n+    if (arena->prof_accumbytes >= prof_interval) {\n+        arena->prof_accumbytes -= prof_interval;\n+        return (true);\n+    }\n+    return (false);\n+}\n+\n+JEMALLOC_INLINE bool\n+arena_prof_accum_locked(arena_t *arena, uint64_t accumbytes)\n+{\n+\n+    cassert(config_prof);\n+\n+    if (prof_interval == 0)\n+        return (false);\n+    return (arena_prof_accum_impl(arena, accumbytes));\n+}\n+\n+JEMALLOC_INLINE bool\n+arena_prof_accum(arena_t *arena, uint64_t accumbytes)\n+{\n+\n+    cassert(config_prof);\n+\n+    if (prof_interval == 0)\n+        return (false);\n+\n+    {\n+        bool ret;\n+\n+        malloc_mutex_lock(&arena->lock);\n+        ret = arena_prof_accum_impl(arena, accumbytes);\n+        malloc_mutex_unlock(&arena->lock);\n+        return (ret);\n+    }\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_ptr_small_binind_get(const void *ptr, size_t mapbits)\n+{\n+    size_t binind;\n+\n+    binind = (mapbits & CHUNK_MAP_BININD_MASK) >> CHUNK_MAP_BININD_SHIFT;\n+\n+    if (config_debug) {\n+        arena_chunk_t *chunk;\n+        arena_t *arena;\n+        size_t pageind;\n+        size_t actual_mapbits;\n+        arena_run_t *run;\n+        arena_bin_t *bin;\n+        size_t actual_binind;\n+        arena_bin_info_t *bin_info;\n+\n+        assert(binind != BININD_INVALID);\n+        assert(binind < NBINS);\n+        chunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+        arena = chunk->arena;\n+        pageind = ((uintptr_t)ptr - (uintptr_t)chunk) >> LG_PAGE;\n+        actual_mapbits = arena_mapbits_get(chunk, pageind);\n+        assert(mapbits == actual_mapbits);\n+        assert(arena_mapbits_large_get(chunk, pageind) == 0);\n+        assert(arena_mapbits_allocated_get(chunk, pageind) != 0);\n+        run = (arena_run_t *)((uintptr_t)chunk + (uintptr_t)((pageind -\n+            (actual_mapbits >> LG_PAGE)) << LG_PAGE));\n+        bin = run->bin;\n+        actual_binind = bin - arena->bins;\n+        assert(binind == actual_binind);\n+        bin_info = &arena_bin_info[actual_binind];\n+        assert(((uintptr_t)ptr - ((uintptr_t)run +\n+            (uintptr_t)bin_info->reg0_offset)) % bin_info->reg_interval\n+            == 0);\n+    }\n+\n+    return (binind);\n+}\n+#  endif /* JEMALLOC_ARENA_INLINE_A */\n+\n+#  ifdef JEMALLOC_ARENA_INLINE_B\n+JEMALLOC_INLINE size_t\n+arena_bin_index(arena_t *arena, arena_bin_t *bin)\n+{\n+    size_t binind = bin - arena->bins;\n+    assert(binind < NBINS);\n+    return (binind);\n+}\n+\n+JEMALLOC_INLINE unsigned\n+arena_run_regind(arena_run_t *run, arena_bin_info_t *bin_info, const void *ptr)\n+{\n+    unsigned shift, diff, regind;\n+    size_t interval;\n+\n+    /*\n+     * Freeing a pointer lower than region zero can cause assertion\n+     * failure.\n+     */\n+    assert((uintptr_t)ptr >= (uintptr_t)run +\n+        (uintptr_t)bin_info->reg0_offset);\n+\n+    /*\n+     * Avoid doing division with a variable divisor if possible.  Using\n+     * actual division here can reduce allocator throughput by over 20%!\n+     */\n+    diff = (unsigned)((uintptr_t)ptr - (uintptr_t)run -\n+        bin_info->reg0_offset);\n+\n+    /* Rescale (factor powers of 2 out of the numerator and denominator). */\n+    interval = bin_info->reg_interval;\n+    shift = ffs(interval) - 1;\n+    diff >>= shift;\n+    interval >>= shift;\n+\n+    if (interval == 1) {\n+        /* The divisor was a power of 2. */\n+        regind = diff;\n+    } else {\n+        /*\n+         * To divide by a number D that is not a power of two we\n+         * multiply by (2^21 / D) and then right shift by 21 positions.\n+         *\n+         *   X / D\n+         *\n+         * becomes\n+         *\n+         *   (X * interval_invs[D - 3]) >> SIZE_INV_SHIFT\n+         *\n+         * We can omit the first three elements, because we never\n+         * divide by 0, and 1 and 2 are both powers of two, which are\n+         * handled above.\n+         */\n+#define\tSIZE_INV_SHIFT\t((sizeof(unsigned) << 3) - LG_RUN_MAXREGS)\n+#define\tSIZE_INV(s)\t(((1U << SIZE_INV_SHIFT) / (s)) + 1)\n+        static const unsigned interval_invs[] = {\n+            SIZE_INV(3),\n+            SIZE_INV(4), SIZE_INV(5), SIZE_INV(6), SIZE_INV(7),\n+            SIZE_INV(8), SIZE_INV(9), SIZE_INV(10), SIZE_INV(11),\n+            SIZE_INV(12), SIZE_INV(13), SIZE_INV(14), SIZE_INV(15),\n+            SIZE_INV(16), SIZE_INV(17), SIZE_INV(18), SIZE_INV(19),\n+            SIZE_INV(20), SIZE_INV(21), SIZE_INV(22), SIZE_INV(23),\n+            SIZE_INV(24), SIZE_INV(25), SIZE_INV(26), SIZE_INV(27),\n+            SIZE_INV(28), SIZE_INV(29), SIZE_INV(30), SIZE_INV(31)\n+        };\n+\n+        if (interval <= ((sizeof(interval_invs) / sizeof(unsigned)) +\n+            2)) {\n+            regind = (diff * interval_invs[interval - 3]) >>\n+                SIZE_INV_SHIFT;\n+        } else\n+            regind = diff / interval;\n+#undef SIZE_INV\n+#undef SIZE_INV_SHIFT\n+    }\n+    assert(diff == regind * interval);\n+    assert(regind < bin_info->nregs);\n+\n+    return (regind);\n+}\n+\n+JEMALLOC_INLINE prof_ctx_t *\n+arena_prof_ctx_get(const void *ptr)\n+{\n+    prof_ctx_t *ret;\n+    arena_chunk_t *chunk;\n+    size_t pageind, mapbits;\n+\n+    cassert(config_prof);\n+    assert(ptr != NULL);\n+    assert(CHUNK_ADDR2BASE(ptr) != ptr);\n+\n+    chunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+    pageind = ((uintptr_t)ptr - (uintptr_t)chunk) >> LG_PAGE;\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    assert((mapbits & CHUNK_MAP_ALLOCATED) != 0);\n+    if ((mapbits & CHUNK_MAP_LARGE) == 0) {\n+        if (prof_promote)\n+            ret = (prof_ctx_t *)(uintptr_t)1U;\n+        else {\n+            arena_run_t *run = (arena_run_t *)((uintptr_t)chunk +\n+                (uintptr_t)((pageind - (mapbits >> LG_PAGE)) <<\n+                LG_PAGE));\n+            size_t binind = arena_ptr_small_binind_get(ptr,\n+                mapbits);\n+            arena_bin_info_t *bin_info = &arena_bin_info[binind];\n+            unsigned regind;\n+\n+            regind = arena_run_regind(run, bin_info, ptr);\n+            ret = *(prof_ctx_t **)((uintptr_t)run +\n+                bin_info->ctx0_offset + (regind *\n+                sizeof(prof_ctx_t *)));\n+        }\n+    } else\n+        ret = arena_mapp_get(chunk, pageind)->prof_ctx;\n+\n+    return (ret);\n+}\n+\n+JEMALLOC_INLINE void\n+arena_prof_ctx_set(const void *ptr, prof_ctx_t *ctx)\n+{\n+    arena_chunk_t *chunk;\n+    size_t pageind, mapbits;\n+\n+    cassert(config_prof);\n+    assert(ptr != NULL);\n+    assert(CHUNK_ADDR2BASE(ptr) != ptr);\n+\n+    chunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+    pageind = ((uintptr_t)ptr - (uintptr_t)chunk) >> LG_PAGE;\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    assert((mapbits & CHUNK_MAP_ALLOCATED) != 0);\n+    if ((mapbits & CHUNK_MAP_LARGE) == 0) {\n+        if (prof_promote == false) {\n+            arena_run_t *run = (arena_run_t *)((uintptr_t)chunk +\n+                (uintptr_t)((pageind - (mapbits >> LG_PAGE)) <<\n+                LG_PAGE));\n+            size_t binind;\n+            arena_bin_info_t *bin_info;\n+            unsigned regind;\n+\n+            binind = arena_ptr_small_binind_get(ptr, mapbits);\n+            bin_info = &arena_bin_info[binind];\n+            regind = arena_run_regind(run, bin_info, ptr);\n+\n+            *((prof_ctx_t **)((uintptr_t)run + bin_info->ctx0_offset\n+                + (regind * sizeof(prof_ctx_t *)))) = ctx;\n+        } else\n+            assert((uintptr_t)ctx == (uintptr_t)1U);\n+    } else\n+        arena_mapp_get(chunk, pageind)->prof_ctx = ctx;\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+arena_malloc(arena_t *arena, size_t size, bool zero, bool try_tcache)\n+{\n+    tcache_t *tcache;\n+\n+    assert(size != 0);\n+    assert(size <= arena_maxclass);\n+\n+    if (size <= SMALL_MAXCLASS) {\n+        if (try_tcache && (tcache = tcache_get(true)) != NULL)\n+            return (tcache_alloc_small(tcache, size, zero));\n+        else {\n+            return (arena_malloc_small(choose_arena(arena), size,\n+                zero));\n+        }\n+    } else {\n+        /*\n+         * Initialize tcache after checking size in order to avoid\n+         * infinite recursion during tcache initialization.\n+         */\n+        if (try_tcache && size <= tcache_maxclass && (tcache =\n+            tcache_get(true)) != NULL)\n+            return (tcache_alloc_large(tcache, size, zero));\n+        else {\n+            return (arena_malloc_large(choose_arena(arena), size,\n+                zero));\n+        }\n+    }\n+}\n+\n+/* Return the size of the allocation pointed to by ptr. */\n+JEMALLOC_ALWAYS_INLINE size_t\n+arena_salloc(const void *ptr, bool demote)\n+{\n+    size_t ret;\n+    arena_chunk_t *chunk;\n+    size_t pageind, binind;\n+\n+    assert(ptr != NULL);\n+    assert(CHUNK_ADDR2BASE(ptr) != ptr);\n+\n+    chunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+    pageind = ((uintptr_t)ptr - (uintptr_t)chunk) >> LG_PAGE;\n+    assert(arena_mapbits_allocated_get(chunk, pageind) != 0);\n+    binind = arena_mapbits_binind_get(chunk, pageind);\n+    if (binind == BININD_INVALID || (config_prof && demote == false &&\n+        prof_promote && arena_mapbits_large_get(chunk, pageind) != 0)) {\n+        /*\n+         * Large allocation.  In the common case (demote == true), and\n+         * as this is an inline function, most callers will only end up\n+         * looking at binind to determine that ptr is a small\n+         * allocation.\n+         */\n+        assert(((uintptr_t)ptr & PAGE_MASK) == 0);\n+        ret = arena_mapbits_large_size_get(chunk, pageind);\n+        assert(ret != 0);\n+        assert(pageind + (ret>>LG_PAGE) <= chunk_npages);\n+        assert(ret == PAGE || arena_mapbits_large_size_get(chunk,\n+            pageind+(ret>>LG_PAGE)-1) == 0);\n+        assert(binind == arena_mapbits_binind_get(chunk,\n+            pageind+(ret>>LG_PAGE)-1));\n+        assert(arena_mapbits_dirty_get(chunk, pageind) ==\n+            arena_mapbits_dirty_get(chunk, pageind+(ret>>LG_PAGE)-1));\n+    } else {\n+        /*\n+         * Small allocation (possibly promoted to a large object due to\n+         * prof_promote).\n+         */\n+        assert(arena_mapbits_large_get(chunk, pageind) != 0 ||\n+            arena_ptr_small_binind_get(ptr, arena_mapbits_get(chunk,\n+            pageind)) == binind);\n+        ret = arena_bin_info[binind].reg_size;\n+    }\n+\n+    return (ret);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+arena_dalloc(arena_t *arena, arena_chunk_t *chunk, void *ptr, bool try_tcache)\n+{\n+    size_t pageind, mapbits;\n+    tcache_t *tcache;\n+\n+    assert(arena != NULL);\n+    assert(chunk->arena == arena);\n+    assert(ptr != NULL);\n+    assert(CHUNK_ADDR2BASE(ptr) != ptr);\n+\n+    pageind = ((uintptr_t)ptr - (uintptr_t)chunk) >> LG_PAGE;\n+    mapbits = arena_mapbits_get(chunk, pageind);\n+    assert(arena_mapbits_allocated_get(chunk, pageind) != 0);\n+    if ((mapbits & CHUNK_MAP_LARGE) == 0) {\n+        /* Small allocation. */\n+        if (try_tcache && (tcache = tcache_get(false)) != NULL) {\n+            size_t binind;\n+\n+            binind = arena_ptr_small_binind_get(ptr, mapbits);\n+            tcache_dalloc_small(tcache, ptr, binind);\n+        } else\n+            arena_dalloc_small(arena, chunk, ptr, pageind);\n+    } else {\n+        size_t size = arena_mapbits_large_size_get(chunk, pageind);\n+\n+        assert(((uintptr_t)ptr & PAGE_MASK) == 0);\n+\n+        if (try_tcache && size <= tcache_maxclass && (tcache =\n+            tcache_get(false)) != NULL) {\n+            tcache_dalloc_large(tcache, ptr, size);\n+        } else\n+            arena_dalloc_large(arena, chunk, ptr);\n+    }\n+}\n+#  endif /* JEMALLOC_ARENA_INLINE_B */\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "76e7a350fc11b6e69e9bd881a29930f2a7321cfe", "filename": "src/rt/jemalloc/include/jemalloc/internal/atomic.h", "status": "added", "additions": 304, "deletions": 0, "changes": 304, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fatomic.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fatomic.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fatomic.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,304 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+#define\tatomic_read_uint64(p)\tatomic_add_uint64(p, 0)\n+#define\tatomic_read_uint32(p)\tatomic_add_uint32(p, 0)\n+#define\tatomic_read_z(p)\tatomic_add_z(p, 0)\n+#define\tatomic_read_u(p)\tatomic_add_u(p, 0)\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+uint64_t\tatomic_add_uint64(uint64_t *p, uint64_t x);\n+uint64_t\tatomic_sub_uint64(uint64_t *p, uint64_t x);\n+uint32_t\tatomic_add_uint32(uint32_t *p, uint32_t x);\n+uint32_t\tatomic_sub_uint32(uint32_t *p, uint32_t x);\n+size_t\tatomic_add_z(size_t *p, size_t x);\n+size_t\tatomic_sub_z(size_t *p, size_t x);\n+unsigned\tatomic_add_u(unsigned *p, unsigned x);\n+unsigned\tatomic_sub_u(unsigned *p, unsigned x);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_ATOMIC_C_))\n+/******************************************************************************/\n+/* 64-bit operations. */\n+#if (LG_SIZEOF_PTR == 3 || LG_SIZEOF_INT == 3)\n+#  ifdef __GCC_HAVE_SYNC_COMPARE_AND_SWAP_8\n+JEMALLOC_INLINE uint64_t\n+atomic_add_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (__sync_add_and_fetch(p, x));\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+atomic_sub_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (__sync_sub_and_fetch(p, x));\n+}\n+#elif (defined(_MSC_VER))\n+JEMALLOC_INLINE uint64_t\n+atomic_add_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (InterlockedExchangeAdd64(p, x));\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+atomic_sub_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (InterlockedExchangeAdd64(p, -((int64_t)x)));\n+}\n+#elif (defined(JEMALLOC_OSATOMIC))\n+JEMALLOC_INLINE uint64_t\n+atomic_add_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (OSAtomicAdd64((int64_t)x, (int64_t *)p));\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+atomic_sub_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (OSAtomicAdd64(-((int64_t)x), (int64_t *)p));\n+}\n+#  elif (defined(__amd64__) || defined(__x86_64__))\n+JEMALLOC_INLINE uint64_t\n+atomic_add_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    asm volatile (\n+        \"lock; xaddq %0, %1;\"\n+        : \"+r\" (x), \"=m\" (*p) /* Outputs. */\n+        : \"m\" (*p) /* Inputs. */\n+        );\n+\n+    return (x);\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+atomic_sub_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    x = (uint64_t)(-(int64_t)x);\n+    asm volatile (\n+        \"lock; xaddq %0, %1;\"\n+        : \"+r\" (x), \"=m\" (*p) /* Outputs. */\n+        : \"m\" (*p) /* Inputs. */\n+        );\n+\n+    return (x);\n+}\n+#  elif (defined(JEMALLOC_ATOMIC9))\n+JEMALLOC_INLINE uint64_t\n+atomic_add_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    /*\n+     * atomic_fetchadd_64() doesn't exist, but we only ever use this\n+     * function on LP64 systems, so atomic_fetchadd_long() will do.\n+     */\n+    assert(sizeof(uint64_t) == sizeof(unsigned long));\n+\n+    return (atomic_fetchadd_long(p, (unsigned long)x) + x);\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+atomic_sub_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    assert(sizeof(uint64_t) == sizeof(unsigned long));\n+\n+    return (atomic_fetchadd_long(p, (unsigned long)(-(long)x)) - x);\n+}\n+#  elif (defined(JE_FORCE_SYNC_COMPARE_AND_SWAP_8))\n+JEMALLOC_INLINE uint64_t\n+atomic_add_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (__sync_add_and_fetch(p, x));\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+atomic_sub_uint64(uint64_t *p, uint64_t x)\n+{\n+\n+    return (__sync_sub_and_fetch(p, x));\n+}\n+#  else\n+#    error \"Missing implementation for 64-bit atomic operations\"\n+#  endif\n+#endif\n+\n+/******************************************************************************/\n+/* 32-bit operations. */\n+#ifdef __GCC_HAVE_SYNC_COMPARE_AND_SWAP_4\n+JEMALLOC_INLINE uint32_t\n+atomic_add_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (__sync_add_and_fetch(p, x));\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+atomic_sub_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (__sync_sub_and_fetch(p, x));\n+}\n+#elif (defined(_MSC_VER))\n+JEMALLOC_INLINE uint32_t\n+atomic_add_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (InterlockedExchangeAdd(p, x));\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+atomic_sub_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (InterlockedExchangeAdd(p, -((int32_t)x)));\n+}\n+#elif (defined(JEMALLOC_OSATOMIC))\n+JEMALLOC_INLINE uint32_t\n+atomic_add_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (OSAtomicAdd32((int32_t)x, (int32_t *)p));\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+atomic_sub_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (OSAtomicAdd32(-((int32_t)x), (int32_t *)p));\n+}\n+#elif (defined(__i386__) || defined(__amd64__) || defined(__x86_64__))\n+JEMALLOC_INLINE uint32_t\n+atomic_add_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    asm volatile (\n+        \"lock; xaddl %0, %1;\"\n+        : \"+r\" (x), \"=m\" (*p) /* Outputs. */\n+        : \"m\" (*p) /* Inputs. */\n+        );\n+\n+    return (x);\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+atomic_sub_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    x = (uint32_t)(-(int32_t)x);\n+    asm volatile (\n+        \"lock; xaddl %0, %1;\"\n+        : \"+r\" (x), \"=m\" (*p) /* Outputs. */\n+        : \"m\" (*p) /* Inputs. */\n+        );\n+\n+    return (x);\n+}\n+#elif (defined(JEMALLOC_ATOMIC9))\n+JEMALLOC_INLINE uint32_t\n+atomic_add_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (atomic_fetchadd_32(p, x) + x);\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+atomic_sub_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (atomic_fetchadd_32(p, (uint32_t)(-(int32_t)x)) - x);\n+}\n+#elif (defined(JE_FORCE_SYNC_COMPARE_AND_SWAP_4))\n+JEMALLOC_INLINE uint32_t\n+atomic_add_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (__sync_add_and_fetch(p, x));\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+atomic_sub_uint32(uint32_t *p, uint32_t x)\n+{\n+\n+    return (__sync_sub_and_fetch(p, x));\n+}\n+#else\n+#  error \"Missing implementation for 32-bit atomic operations\"\n+#endif\n+\n+/******************************************************************************/\n+/* size_t operations. */\n+JEMALLOC_INLINE size_t\n+atomic_add_z(size_t *p, size_t x)\n+{\n+\n+#if (LG_SIZEOF_PTR == 3)\n+    return ((size_t)atomic_add_uint64((uint64_t *)p, (uint64_t)x));\n+#elif (LG_SIZEOF_PTR == 2)\n+    return ((size_t)atomic_add_uint32((uint32_t *)p, (uint32_t)x));\n+#endif\n+}\n+\n+JEMALLOC_INLINE size_t\n+atomic_sub_z(size_t *p, size_t x)\n+{\n+\n+#if (LG_SIZEOF_PTR == 3)\n+    return ((size_t)atomic_add_uint64((uint64_t *)p,\n+        (uint64_t)-((int64_t)x)));\n+#elif (LG_SIZEOF_PTR == 2)\n+    return ((size_t)atomic_add_uint32((uint32_t *)p,\n+        (uint32_t)-((int32_t)x)));\n+#endif\n+}\n+\n+/******************************************************************************/\n+/* unsigned operations. */\n+JEMALLOC_INLINE unsigned\n+atomic_add_u(unsigned *p, unsigned x)\n+{\n+\n+#if (LG_SIZEOF_INT == 3)\n+    return ((unsigned)atomic_add_uint64((uint64_t *)p, (uint64_t)x));\n+#elif (LG_SIZEOF_INT == 2)\n+    return ((unsigned)atomic_add_uint32((uint32_t *)p, (uint32_t)x));\n+#endif\n+}\n+\n+JEMALLOC_INLINE unsigned\n+atomic_sub_u(unsigned *p, unsigned x)\n+{\n+\n+#if (LG_SIZEOF_INT == 3)\n+    return ((unsigned)atomic_add_uint64((uint64_t *)p,\n+        (uint64_t)-((int64_t)x)));\n+#elif (LG_SIZEOF_INT == 2)\n+    return ((unsigned)atomic_add_uint32((uint32_t *)p,\n+        (uint32_t)-((int32_t)x)));\n+#endif\n+}\n+/******************************************************************************/\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "9cf75ffb0b3c1d4e9ee5b5c855127f4112538872", "filename": "src/rt/jemalloc/include/jemalloc/internal/base.h", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fbase.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fbase.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fbase.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,26 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+void\t*base_alloc(size_t size);\n+void\t*base_calloc(size_t number, size_t size);\n+extent_node_t *base_node_alloc(void);\n+void\tbase_node_dealloc(extent_node_t *node);\n+bool\tbase_boot(void);\n+void\tbase_prefork(void);\n+void\tbase_postfork_parent(void);\n+void\tbase_postfork_child(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "90064183c22badb1121d5d0d25168870c8dd00eb", "filename": "src/rt/jemalloc/include/jemalloc/internal/bitmap.h", "status": "added", "additions": 184, "deletions": 0, "changes": 184, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fbitmap.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fbitmap.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fbitmap.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,184 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+/* Maximum bitmap bit count is 2^LG_BITMAP_MAXBITS. */\n+#define\tLG_BITMAP_MAXBITS\tLG_RUN_MAXREGS\n+\n+typedef struct bitmap_level_s bitmap_level_t;\n+typedef struct bitmap_info_s bitmap_info_t;\n+typedef unsigned long bitmap_t;\n+#define\tLG_SIZEOF_BITMAP\tLG_SIZEOF_LONG\n+\n+/* Number of bits per group. */\n+#define\tLG_BITMAP_GROUP_NBITS\t\t(LG_SIZEOF_BITMAP + 3)\n+#define\tBITMAP_GROUP_NBITS\t\t(ZU(1) << LG_BITMAP_GROUP_NBITS)\n+#define\tBITMAP_GROUP_NBITS_MASK\t\t(BITMAP_GROUP_NBITS-1)\n+\n+/* Maximum number of levels possible. */\n+#define\tBITMAP_MAX_LEVELS\t\t\t\t\t\t\\\n+    (LG_BITMAP_MAXBITS / LG_SIZEOF_BITMAP)\t\t\t\t\\\n+    + !!(LG_BITMAP_MAXBITS % LG_SIZEOF_BITMAP)\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct bitmap_level_s {\n+    /* Offset of this level's groups within the array of groups. */\n+    size_t group_offset;\n+};\n+\n+struct bitmap_info_s {\n+    /* Logical number of bits in bitmap (stored at bottom level). */\n+    size_t nbits;\n+\n+    /* Number of levels necessary for nbits. */\n+    unsigned nlevels;\n+\n+    /*\n+     * Only the first (nlevels+1) elements are used, and levels are ordered\n+     * bottom to top (e.g. the bottom level is stored in levels[0]).\n+     */\n+    bitmap_level_t levels[BITMAP_MAX_LEVELS+1];\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+void\tbitmap_info_init(bitmap_info_t *binfo, size_t nbits);\n+size_t\tbitmap_info_ngroups(const bitmap_info_t *binfo);\n+size_t\tbitmap_size(size_t nbits);\n+void\tbitmap_init(bitmap_t *bitmap, const bitmap_info_t *binfo);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+bool\tbitmap_full(bitmap_t *bitmap, const bitmap_info_t *binfo);\n+bool\tbitmap_get(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit);\n+void\tbitmap_set(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit);\n+size_t\tbitmap_sfu(bitmap_t *bitmap, const bitmap_info_t *binfo);\n+void\tbitmap_unset(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_BITMAP_C_))\n+JEMALLOC_INLINE bool\n+bitmap_full(bitmap_t *bitmap, const bitmap_info_t *binfo)\n+{\n+    unsigned rgoff = binfo->levels[binfo->nlevels].group_offset - 1;\n+    bitmap_t rg = bitmap[rgoff];\n+    /* The bitmap is full iff the root group is 0. */\n+    return (rg == 0);\n+}\n+\n+JEMALLOC_INLINE bool\n+bitmap_get(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit)\n+{\n+    size_t goff;\n+    bitmap_t g;\n+\n+    assert(bit < binfo->nbits);\n+    goff = bit >> LG_BITMAP_GROUP_NBITS;\n+    g = bitmap[goff];\n+    return (!(g & (1LU << (bit & BITMAP_GROUP_NBITS_MASK))));\n+}\n+\n+JEMALLOC_INLINE void\n+bitmap_set(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit)\n+{\n+    size_t goff;\n+    bitmap_t *gp;\n+    bitmap_t g;\n+\n+    assert(bit < binfo->nbits);\n+    assert(bitmap_get(bitmap, binfo, bit) == false);\n+    goff = bit >> LG_BITMAP_GROUP_NBITS;\n+    gp = &bitmap[goff];\n+    g = *gp;\n+    assert(g & (1LU << (bit & BITMAP_GROUP_NBITS_MASK)));\n+    g ^= 1LU << (bit & BITMAP_GROUP_NBITS_MASK);\n+    *gp = g;\n+    assert(bitmap_get(bitmap, binfo, bit));\n+    /* Propagate group state transitions up the tree. */\n+    if (g == 0) {\n+        unsigned i;\n+        for (i = 1; i < binfo->nlevels; i++) {\n+            bit = goff;\n+            goff = bit >> LG_BITMAP_GROUP_NBITS;\n+            gp = &bitmap[binfo->levels[i].group_offset + goff];\n+            g = *gp;\n+            assert(g & (1LU << (bit & BITMAP_GROUP_NBITS_MASK)));\n+            g ^= 1LU << (bit & BITMAP_GROUP_NBITS_MASK);\n+            *gp = g;\n+            if (g != 0)\n+                break;\n+        }\n+    }\n+}\n+\n+/* sfu: set first unset. */\n+JEMALLOC_INLINE size_t\n+bitmap_sfu(bitmap_t *bitmap, const bitmap_info_t *binfo)\n+{\n+    size_t bit;\n+    bitmap_t g;\n+    unsigned i;\n+\n+    assert(bitmap_full(bitmap, binfo) == false);\n+\n+    i = binfo->nlevels - 1;\n+    g = bitmap[binfo->levels[i].group_offset];\n+    bit = ffsl(g) - 1;\n+    while (i > 0) {\n+        i--;\n+        g = bitmap[binfo->levels[i].group_offset + bit];\n+        bit = (bit << LG_BITMAP_GROUP_NBITS) + (ffsl(g) - 1);\n+    }\n+\n+    bitmap_set(bitmap, binfo, bit);\n+    return (bit);\n+}\n+\n+JEMALLOC_INLINE void\n+bitmap_unset(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit)\n+{\n+    size_t goff;\n+    bitmap_t *gp;\n+    bitmap_t g;\n+    bool propagate;\n+\n+    assert(bit < binfo->nbits);\n+    assert(bitmap_get(bitmap, binfo, bit));\n+    goff = bit >> LG_BITMAP_GROUP_NBITS;\n+    gp = &bitmap[goff];\n+    g = *gp;\n+    propagate = (g == 0);\n+    assert((g & (1LU << (bit & BITMAP_GROUP_NBITS_MASK))) == 0);\n+    g ^= 1LU << (bit & BITMAP_GROUP_NBITS_MASK);\n+    *gp = g;\n+    assert(bitmap_get(bitmap, binfo, bit) == false);\n+    /* Propagate group state transitions up the tree. */\n+    if (propagate) {\n+        unsigned i;\n+        for (i = 1; i < binfo->nlevels; i++) {\n+            bit = goff;\n+            goff = bit >> LG_BITMAP_GROUP_NBITS;\n+            gp = &bitmap[binfo->levels[i].group_offset + goff];\n+            g = *gp;\n+            propagate = (g == 0);\n+            assert((g & (1LU << (bit & BITMAP_GROUP_NBITS_MASK)))\n+                == 0);\n+            g ^= 1LU << (bit & BITMAP_GROUP_NBITS_MASK);\n+            *gp = g;\n+            if (propagate == false)\n+                break;\n+        }\n+    }\n+}\n+\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "ffd96ea01a80b6e00c39a14f5fa0ebf96eb293b2", "filename": "src/rt/jemalloc/include/jemalloc/internal/chunk.h", "status": "added", "additions": 63, "deletions": 0, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,63 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+/*\n+ * Size and alignment of memory chunks that are allocated by the OS's virtual\n+ * memory system.\n+ */\n+#define\tLG_CHUNK_DEFAULT\t22\n+\n+/* Return the chunk address for allocation address a. */\n+#define\tCHUNK_ADDR2BASE(a)\t\t\t\t\t\t\\\n+    ((void *)((uintptr_t)(a) & ~chunksize_mask))\n+\n+/* Return the chunk offset of address a. */\n+#define\tCHUNK_ADDR2OFFSET(a)\t\t\t\t\t\t\\\n+    ((size_t)((uintptr_t)(a) & chunksize_mask))\n+\n+/* Return the smallest chunk multiple that is >= s. */\n+#define\tCHUNK_CEILING(s)\t\t\t\t\t\t\\\n+    (((s) + chunksize_mask) & ~chunksize_mask)\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+extern size_t\t\topt_lg_chunk;\n+extern const char\t*opt_dss;\n+\n+/* Protects stats_chunks; currently not used for any other purpose. */\n+extern malloc_mutex_t\tchunks_mtx;\n+/* Chunk statistics. */\n+extern chunk_stats_t\tstats_chunks;\n+\n+extern rtree_t\t\t*chunks_rtree;\n+\n+extern size_t\t\tchunksize;\n+extern size_t\t\tchunksize_mask; /* (chunksize - 1). */\n+extern size_t\t\tchunk_npages;\n+extern size_t\t\tmap_bias; /* Number of arena chunk header pages. */\n+extern size_t\t\tarena_maxclass; /* Max size class for arenas. */\n+\n+void\t*chunk_alloc(size_t size, size_t alignment, bool base, bool *zero,\n+    dss_prec_t dss_prec);\n+void\tchunk_unmap(void *chunk, size_t size);\n+void\tchunk_dealloc(void *chunk, size_t size, bool unmap);\n+bool\tchunk_boot(void);\n+void\tchunk_prefork(void);\n+void\tchunk_postfork_parent(void);\n+void\tchunk_postfork_child(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/\n+\n+#include \"jemalloc/internal/chunk_dss.h\"\n+#include \"jemalloc/internal/chunk_mmap.h\""}, {"sha": "ebe501ba289cebdd08638ce9df1cef43f72580cf", "filename": "src/rt/jemalloc/include/jemalloc/internal/chunk_dss.h", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk_dss.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk_dss.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk_dss.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,38 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef enum {\n+    dss_prec_disabled  = 0,\n+    dss_prec_primary   = 1,\n+    dss_prec_secondary = 2,\n+\n+    dss_prec_limit     = 3\n+} dss_prec_t ;\n+#define\tDSS_PREC_DEFAULT\tdss_prec_secondary\n+#define\tDSS_DEFAULT\t\t\"secondary\"\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+extern const char *dss_prec_names[];\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+dss_prec_t\tchunk_dss_prec_get(void);\n+bool\tchunk_dss_prec_set(dss_prec_t dss_prec);\n+void\t*chunk_alloc_dss(size_t size, size_t alignment, bool *zero);\n+bool\tchunk_in_dss(void *chunk);\n+bool\tchunk_dss_boot(void);\n+void\tchunk_dss_prefork(void);\n+void\tchunk_dss_postfork_parent(void);\n+void\tchunk_dss_postfork_child(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "f24abac753823d1e06e1cc6e5663676c7442927f", "filename": "src/rt/jemalloc/include/jemalloc/internal/chunk_mmap.h", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk_mmap.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk_mmap.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fchunk_mmap.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,22 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+bool\tpages_purge(void *addr, size_t length);\n+\n+void\t*chunk_alloc_mmap(size_t size, size_t alignment, bool *zero);\n+bool\tchunk_dealloc_mmap(void *chunk, size_t size);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "f58630a65a266d8891b208920160e368446eafe5", "filename": "src/rt/jemalloc/include/jemalloc/internal/ckh.h", "status": "added", "additions": 88, "deletions": 0, "changes": 88, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fckh.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fckh.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fckh.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,88 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct ckh_s ckh_t;\n+typedef struct ckhc_s ckhc_t;\n+\n+/* Typedefs to allow easy function pointer passing. */\n+typedef void ckh_hash_t (const void *, size_t[2]);\n+typedef bool ckh_keycomp_t (const void *, const void *);\n+\n+/* Maintain counters used to get an idea of performance. */\n+/* #define\tCKH_COUNT */\n+/* Print counter values in ckh_delete() (requires CKH_COUNT). */\n+/* #define\tCKH_VERBOSE */\n+\n+/*\n+ * There are 2^LG_CKH_BUCKET_CELLS cells in each hash table bucket.  Try to fit\n+ * one bucket per L1 cache line.\n+ */\n+#define LG_CKH_BUCKET_CELLS (LG_CACHELINE - LG_SIZEOF_PTR - 1)\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+/* Hash table cell. */\n+struct ckhc_s {\n+    const void\t*key;\n+    const void\t*data;\n+};\n+\n+struct ckh_s {\n+#ifdef CKH_COUNT\n+    /* Counters used to get an idea of performance. */\n+    uint64_t\tngrows;\n+    uint64_t\tnshrinks;\n+    uint64_t\tnshrinkfails;\n+    uint64_t\tninserts;\n+    uint64_t\tnrelocs;\n+#endif\n+\n+    /* Used for pseudo-random number generation. */\n+#define\tCKH_A\t\t1103515241\n+#define\tCKH_C\t\t12347\n+    uint32_t\tprng_state;\n+\n+    /* Total number of items. */\n+    size_t\t\tcount;\n+\n+    /*\n+     * Minimum and current number of hash table buckets.  There are\n+     * 2^LG_CKH_BUCKET_CELLS cells per bucket.\n+     */\n+    unsigned\tlg_minbuckets;\n+    unsigned\tlg_curbuckets;\n+\n+    /* Hash and comparison functions. */\n+    ckh_hash_t\t*hash;\n+    ckh_keycomp_t\t*keycomp;\n+\n+    /* Hash table with 2^lg_curbuckets buckets. */\n+    ckhc_t\t\t*tab;\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+bool\tckh_new(ckh_t *ckh, size_t minitems, ckh_hash_t *hash,\n+    ckh_keycomp_t *keycomp);\n+void\tckh_delete(ckh_t *ckh);\n+size_t\tckh_count(ckh_t *ckh);\n+bool\tckh_iter(ckh_t *ckh, size_t *tabind, void **key, void **data);\n+bool\tckh_insert(ckh_t *ckh, const void *key, const void *data);\n+bool\tckh_remove(ckh_t *ckh, const void *searchkey, void **key,\n+    void **data);\n+bool\tckh_search(ckh_t *ckh, const void *seachkey, void **key, void **data);\n+void\tckh_string_hash(const void *key, size_t r_hash[2]);\n+bool\tckh_string_keycomp(const void *k1, const void *k2);\n+void\tckh_pointer_hash(const void *key, size_t r_hash[2]);\n+bool\tckh_pointer_keycomp(const void *k1, const void *k2);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "cc17461d840b9573aaa6788d0d5f3d00a1abfece", "filename": "src/rt/jemalloc/include/jemalloc/internal/ctl.h", "status": "added", "additions": 116, "deletions": 0, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fctl.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fctl.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fctl.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,116 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct ctl_node_s ctl_node_t;\n+typedef struct ctl_named_node_s ctl_named_node_t;\n+typedef struct ctl_indexed_node_s ctl_indexed_node_t;\n+typedef struct ctl_arena_stats_s ctl_arena_stats_t;\n+typedef struct ctl_stats_s ctl_stats_t;\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct ctl_node_s {\n+    bool\t\t\tnamed;\n+};\n+\n+struct ctl_named_node_s {\n+    struct ctl_node_s\tnode;\n+    const char\t\t*name;\n+    /* If (nchildren == 0), this is a terminal node. */\n+    unsigned\t\tnchildren;\n+    const\t\t\tctl_node_t *children;\n+    int\t\t\t(*ctl)(const size_t *, size_t, void *, size_t *,\n+        void *, size_t);\n+};\n+\n+struct ctl_indexed_node_s {\n+    struct ctl_node_s\tnode;\n+    const ctl_named_node_t\t*(*index)(const size_t *, size_t, size_t);\n+};\n+\n+struct ctl_arena_stats_s {\n+    bool\t\t\tinitialized;\n+    unsigned\t\tnthreads;\n+    const char\t\t*dss;\n+    size_t\t\t\tpactive;\n+    size_t\t\t\tpdirty;\n+    arena_stats_t\t\tastats;\n+\n+    /* Aggregate stats for small size classes, based on bin stats. */\n+    size_t\t\t\tallocated_small;\n+    uint64_t\t\tnmalloc_small;\n+    uint64_t\t\tndalloc_small;\n+    uint64_t\t\tnrequests_small;\n+\n+    malloc_bin_stats_t\tbstats[NBINS];\n+    malloc_large_stats_t\t*lstats;\t/* nlclasses elements. */\n+};\n+\n+struct ctl_stats_s {\n+    size_t\t\t\tallocated;\n+    size_t\t\t\tactive;\n+    size_t\t\t\tmapped;\n+    struct {\n+        size_t\t\tcurrent;\t/* stats_chunks.curchunks */\n+        uint64_t\ttotal;\t\t/* stats_chunks.nchunks */\n+        size_t\t\thigh;\t\t/* stats_chunks.highchunks */\n+    } chunks;\n+    struct {\n+        size_t\t\tallocated;\t/* huge_allocated */\n+        uint64_t\tnmalloc;\t/* huge_nmalloc */\n+        uint64_t\tndalloc;\t/* huge_ndalloc */\n+    } huge;\n+    unsigned\t\tnarenas;\n+    ctl_arena_stats_t\t*arenas;\t/* (narenas + 1) elements. */\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+int\tctl_byname(const char *name, void *oldp, size_t *oldlenp, void *newp,\n+    size_t newlen);\n+int\tctl_nametomib(const char *name, size_t *mibp, size_t *miblenp);\n+\n+int\tctl_bymib(const size_t *mib, size_t miblen, void *oldp, size_t *oldlenp,\n+    void *newp, size_t newlen);\n+bool\tctl_boot(void);\n+void\tctl_prefork(void);\n+void\tctl_postfork_parent(void);\n+void\tctl_postfork_child(void);\n+\n+#define\txmallctl(name, oldp, oldlenp, newp, newlen) do {\t\t\\\n+    if (je_mallctl(name, oldp, oldlenp, newp, newlen)\t\t\\\n+        != 0) {\t\t\t\t\t\t\t\\\n+        malloc_printf(\t\t\t\t\t\t\\\n+            \"<jemalloc>: Failure in xmallctl(\\\"%s\\\", ...)\\n\",\t\\\n+            name);\t\t\t\t\t\t\\\n+        abort();\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define\txmallctlnametomib(name, mibp, miblenp) do {\t\t\t\\\n+    if (je_mallctlnametomib(name, mibp, miblenp) != 0) {\t\t\\\n+        malloc_printf(\"<jemalloc>: Failure in \"\t\t\t\\\n+            \"xmallctlnametomib(\\\"%s\\\", ...)\\n\", name);\t\t\\\n+        abort();\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define\txmallctlbymib(mib, miblen, oldp, oldlenp, newp, newlen) do {\t\\\n+    if (je_mallctlbymib(mib, miblen, oldp, oldlenp, newp,\t\t\\\n+        newlen) != 0) {\t\t\t\t\t\t\\\n+        malloc_write(\t\t\t\t\t\t\\\n+            \"<jemalloc>: Failure in xmallctlbymib()\\n\");\t\\\n+        abort();\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "b79c1e0c9044cc910dc3b42485d5a1ee6b73b4b9", "filename": "src/rt/jemalloc/include/jemalloc/internal/extent.h", "status": "added", "additions": 45, "deletions": 0, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fextent.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fextent.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fextent.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,45 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct extent_node_s extent_node_t;\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+/* Tree of extents. */\n+struct extent_node_s {\n+    /* Linkage for the size/address-ordered tree. */\n+    rb_node(extent_node_t)\tlink_szad;\n+\n+    /* Linkage for the address-ordered tree. */\n+    rb_node(extent_node_t)\tlink_ad;\n+\n+    /* Profile counters, used for huge objects. */\n+    prof_ctx_t\t\t*prof_ctx;\n+\n+    /* Pointer to the extent that this tree node is responsible for. */\n+    void\t\t\t*addr;\n+\n+    /* Total region size. */\n+    size_t\t\t\tsize;\n+\n+    /* True if zero-filled; used by chunk recycling code. */\n+    bool\t\t\tzeroed;\n+};\n+typedef rb_tree(extent_node_t) extent_tree_t;\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+rb_proto(, extent_tree_szad_, extent_tree_t, extent_node_t)\n+\n+rb_proto(, extent_tree_ad_, extent_tree_t, extent_node_t)\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "d59c45a5fb31c004e0e13a7cbde19b35fdcc525c", "filename": "src/rt/jemalloc/include/jemalloc/internal/hash.h", "status": "added", "additions": 331, "deletions": 0, "changes": 331, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fhash.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fhash.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fhash.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,331 @@\n+/*\n+ * The following hash function is based on MurmurHash3, placed into the public\n+ * domain by Austin Appleby.  See http://code.google.com/p/smhasher/ for\n+ * details.\n+ */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+void\thash(const void *key, size_t len, const uint32_t seed,\n+    size_t r_hash[2]);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_HASH_C_))\n+/******************************************************************************/\n+/* Internal implementation. */\n+JEMALLOC_INLINE uint32_t\n+hash_rotl_32(uint32_t x, int8_t r)\n+{\n+\n+    return (x << r) | (x >> (32 - r));\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+hash_rotl_64(uint64_t x, int8_t r)\n+{\n+    return (x << r) | (x >> (64 - r));\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+hash_get_block_32(const uint32_t *p, int i)\n+{\n+\n+    return p[i];\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+hash_get_block_64(const uint64_t *p, int i)\n+{\n+\n+    return p[i];\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+hash_fmix_32(uint32_t h)\n+{\n+\n+    h ^= h >> 16;\n+    h *= 0x85ebca6b;\n+    h ^= h >> 13;\n+    h *= 0xc2b2ae35;\n+    h ^= h >> 16;\n+\n+    return h;\n+}\n+\n+JEMALLOC_INLINE uint64_t\n+hash_fmix_64(uint64_t k)\n+{\n+\n+    k ^= k >> 33;\n+    k *= QU(0xff51afd7ed558ccdLLU);\n+    k ^= k >> 33;\n+    k *= QU(0xc4ceb9fe1a85ec53LLU);\n+    k ^= k >> 33;\n+\n+    return k;\n+}\n+\n+JEMALLOC_INLINE uint32_t\n+hash_x86_32(const void *key, int len, uint32_t seed)\n+{\n+    const uint8_t *data = (const uint8_t *) key;\n+    const int nblocks = len / 4;\n+\n+    uint32_t h1 = seed;\n+\n+    const uint32_t c1 = 0xcc9e2d51;\n+    const uint32_t c2 = 0x1b873593;\n+\n+    /* body */\n+    {\n+        const uint32_t *blocks = (const uint32_t *) (data + nblocks*4);\n+        int i;\n+\n+        for (i = -nblocks; i; i++) {\n+            uint32_t k1 = hash_get_block_32(blocks, i);\n+\n+            k1 *= c1;\n+            k1 = hash_rotl_32(k1, 15);\n+            k1 *= c2;\n+\n+            h1 ^= k1;\n+            h1 = hash_rotl_32(h1, 13);\n+            h1 = h1*5 + 0xe6546b64;\n+        }\n+    }\n+\n+    /* tail */\n+    {\n+        const uint8_t *tail = (const uint8_t *) (data + nblocks*4);\n+\n+        uint32_t k1 = 0;\n+\n+        switch (len & 3) {\n+        case 3: k1 ^= tail[2] << 16;\n+        case 2: k1 ^= tail[1] << 8;\n+        case 1: k1 ^= tail[0]; k1 *= c1; k1 = hash_rotl_32(k1, 15);\n+            k1 *= c2; h1 ^= k1;\n+        }\n+    }\n+\n+    /* finalization */\n+    h1 ^= len;\n+\n+    h1 = hash_fmix_32(h1);\n+\n+    return h1;\n+}\n+\n+UNUSED JEMALLOC_INLINE void\n+hash_x86_128(const void *key, const int len, uint32_t seed,\n+  uint64_t r_out[2])\n+{\n+    const uint8_t * data = (const uint8_t *) key;\n+    const int nblocks = len / 16;\n+\n+    uint32_t h1 = seed;\n+    uint32_t h2 = seed;\n+    uint32_t h3 = seed;\n+    uint32_t h4 = seed;\n+\n+    const uint32_t c1 = 0x239b961b;\n+    const uint32_t c2 = 0xab0e9789;\n+    const uint32_t c3 = 0x38b34ae5;\n+    const uint32_t c4 = 0xa1e38b93;\n+\n+    /* body */\n+    {\n+        const uint32_t *blocks = (const uint32_t *) (data + nblocks*16);\n+        int i;\n+\n+        for (i = -nblocks; i; i++) {\n+            uint32_t k1 = hash_get_block_32(blocks, i*4 + 0);\n+            uint32_t k2 = hash_get_block_32(blocks, i*4 + 1);\n+            uint32_t k3 = hash_get_block_32(blocks, i*4 + 2);\n+            uint32_t k4 = hash_get_block_32(blocks, i*4 + 3);\n+\n+            k1 *= c1; k1 = hash_rotl_32(k1, 15); k1 *= c2; h1 ^= k1;\n+\n+            h1 = hash_rotl_32(h1, 19); h1 += h2;\n+            h1 = h1*5 + 0x561ccd1b;\n+\n+            k2 *= c2; k2 = hash_rotl_32(k2, 16); k2 *= c3; h2 ^= k2;\n+\n+            h2 = hash_rotl_32(h2, 17); h2 += h3;\n+            h2 = h2*5 + 0x0bcaa747;\n+\n+            k3 *= c3; k3 = hash_rotl_32(k3, 17); k3 *= c4; h3 ^= k3;\n+\n+            h3 = hash_rotl_32(h3, 15); h3 += h4;\n+            h3 = h3*5 + 0x96cd1c35;\n+\n+            k4 *= c4; k4 = hash_rotl_32(k4, 18); k4 *= c1; h4 ^= k4;\n+\n+            h4 = hash_rotl_32(h4, 13); h4 += h1;\n+            h4 = h4*5 + 0x32ac3b17;\n+        }\n+    }\n+\n+    /* tail */\n+    {\n+        const uint8_t *tail = (const uint8_t *) (data + nblocks*16);\n+        uint32_t k1 = 0;\n+        uint32_t k2 = 0;\n+        uint32_t k3 = 0;\n+        uint32_t k4 = 0;\n+\n+        switch (len & 15) {\n+        case 15: k4 ^= tail[14] << 16;\n+        case 14: k4 ^= tail[13] << 8;\n+        case 13: k4 ^= tail[12] << 0;\n+            k4 *= c4; k4 = hash_rotl_32(k4, 18); k4 *= c1; h4 ^= k4;\n+\n+        case 12: k3 ^= tail[11] << 24;\n+        case 11: k3 ^= tail[10] << 16;\n+        case 10: k3 ^= tail[ 9] << 8;\n+        case  9: k3 ^= tail[ 8] << 0;\n+             k3 *= c3; k3 = hash_rotl_32(k3, 17); k3 *= c4; h3 ^= k3;\n+\n+        case  8: k2 ^= tail[ 7] << 24;\n+        case  7: k2 ^= tail[ 6] << 16;\n+        case  6: k2 ^= tail[ 5] << 8;\n+        case  5: k2 ^= tail[ 4] << 0;\n+            k2 *= c2; k2 = hash_rotl_32(k2, 16); k2 *= c3; h2 ^= k2;\n+\n+        case  4: k1 ^= tail[ 3] << 24;\n+        case  3: k1 ^= tail[ 2] << 16;\n+        case  2: k1 ^= tail[ 1] << 8;\n+        case  1: k1 ^= tail[ 0] << 0;\n+            k1 *= c1; k1 = hash_rotl_32(k1, 15); k1 *= c2; h1 ^= k1;\n+        }\n+    }\n+\n+    /* finalization */\n+    h1 ^= len; h2 ^= len; h3 ^= len; h4 ^= len;\n+\n+    h1 += h2; h1 += h3; h1 += h4;\n+    h2 += h1; h3 += h1; h4 += h1;\n+\n+    h1 = hash_fmix_32(h1);\n+    h2 = hash_fmix_32(h2);\n+    h3 = hash_fmix_32(h3);\n+    h4 = hash_fmix_32(h4);\n+\n+    h1 += h2; h1 += h3; h1 += h4;\n+    h2 += h1; h3 += h1; h4 += h1;\n+\n+    r_out[0] = (((uint64_t) h2) << 32) | h1;\n+    r_out[1] = (((uint64_t) h4) << 32) | h3;\n+}\n+\n+UNUSED JEMALLOC_INLINE void\n+hash_x64_128(const void *key, const int len, const uint32_t seed,\n+  uint64_t r_out[2])\n+{\n+    const uint8_t *data = (const uint8_t *) key;\n+    const int nblocks = len / 16;\n+\n+    uint64_t h1 = seed;\n+    uint64_t h2 = seed;\n+\n+    const uint64_t c1 = QU(0x87c37b91114253d5LLU);\n+    const uint64_t c2 = QU(0x4cf5ad432745937fLLU);\n+\n+    /* body */\n+    {\n+        const uint64_t *blocks = (const uint64_t *) (data);\n+        int i;\n+\n+        for (i = 0; i < nblocks; i++) {\n+            uint64_t k1 = hash_get_block_64(blocks, i*2 + 0);\n+            uint64_t k2 = hash_get_block_64(blocks, i*2 + 1);\n+\n+            k1 *= c1; k1 = hash_rotl_64(k1, 31); k1 *= c2; h1 ^= k1;\n+\n+            h1 = hash_rotl_64(h1, 27); h1 += h2;\n+            h1 = h1*5 + 0x52dce729;\n+\n+            k2 *= c2; k2 = hash_rotl_64(k2, 33); k2 *= c1; h2 ^= k2;\n+\n+            h2 = hash_rotl_64(h2, 31); h2 += h1;\n+            h2 = h2*5 + 0x38495ab5;\n+        }\n+    }\n+\n+    /* tail */\n+    {\n+        const uint8_t *tail = (const uint8_t*)(data + nblocks*16);\n+        uint64_t k1 = 0;\n+        uint64_t k2 = 0;\n+\n+        switch (len & 15) {\n+        case 15: k2 ^= ((uint64_t)(tail[14])) << 48;\n+        case 14: k2 ^= ((uint64_t)(tail[13])) << 40;\n+        case 13: k2 ^= ((uint64_t)(tail[12])) << 32;\n+        case 12: k2 ^= ((uint64_t)(tail[11])) << 24;\n+        case 11: k2 ^= ((uint64_t)(tail[10])) << 16;\n+        case 10: k2 ^= ((uint64_t)(tail[ 9])) << 8;\n+        case  9: k2 ^= ((uint64_t)(tail[ 8])) << 0;\n+            k2 *= c2; k2 = hash_rotl_64(k2, 33); k2 *= c1; h2 ^= k2;\n+\n+        case  8: k1 ^= ((uint64_t)(tail[ 7])) << 56;\n+        case  7: k1 ^= ((uint64_t)(tail[ 6])) << 48;\n+        case  6: k1 ^= ((uint64_t)(tail[ 5])) << 40;\n+        case  5: k1 ^= ((uint64_t)(tail[ 4])) << 32;\n+        case  4: k1 ^= ((uint64_t)(tail[ 3])) << 24;\n+        case  3: k1 ^= ((uint64_t)(tail[ 2])) << 16;\n+        case  2: k1 ^= ((uint64_t)(tail[ 1])) << 8;\n+        case  1: k1 ^= ((uint64_t)(tail[ 0])) << 0;\n+            k1 *= c1; k1 = hash_rotl_64(k1, 31); k1 *= c2; h1 ^= k1;\n+        }\n+    }\n+\n+    /* finalization */\n+    h1 ^= len; h2 ^= len;\n+\n+    h1 += h2;\n+    h2 += h1;\n+\n+    h1 = hash_fmix_64(h1);\n+    h2 = hash_fmix_64(h2);\n+\n+    h1 += h2;\n+    h2 += h1;\n+\n+    r_out[0] = h1;\n+    r_out[1] = h2;\n+}\n+\n+\n+/******************************************************************************/\n+/* API. */\n+JEMALLOC_INLINE void\n+hash(const void *key, size_t len, const uint32_t seed, size_t r_hash[2])\n+{\n+#if (LG_SIZEOF_PTR == 3)\n+    hash_x64_128(key, len, seed, (uint64_t *)r_hash);\n+#else\n+    uint64_t hashes[2];\n+    hash_x86_128(key, len, seed, hashes);\n+    r_hash[0] = (size_t)hashes[0];\n+    r_hash[1] = (size_t)hashes[1];\n+#endif\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "d987d370767a659a558f53c87a95a1c4b99ee3da", "filename": "src/rt/jemalloc/include/jemalloc/internal/huge.h", "status": "added", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fhuge.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fhuge.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fhuge.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,40 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+/* Huge allocation statistics. */\n+extern uint64_t\t\thuge_nmalloc;\n+extern uint64_t\t\thuge_ndalloc;\n+extern size_t\t\thuge_allocated;\n+\n+/* Protects chunk-related data structures. */\n+extern malloc_mutex_t\thuge_mtx;\n+\n+void\t*huge_malloc(size_t size, bool zero);\n+void\t*huge_palloc(size_t size, size_t alignment, bool zero);\n+void\t*huge_ralloc_no_move(void *ptr, size_t oldsize, size_t size,\n+    size_t extra);\n+void\t*huge_ralloc(void *ptr, size_t oldsize, size_t size, size_t extra,\n+    size_t alignment, bool zero, bool try_tcache_dalloc);\n+void\thuge_dalloc(void *ptr, bool unmap);\n+size_t\thuge_salloc(const void *ptr);\n+prof_ctx_t\t*huge_prof_ctx_get(const void *ptr);\n+void\thuge_prof_ctx_set(const void *ptr, prof_ctx_t *ctx);\n+bool\thuge_boot(void);\n+void\thuge_prefork(void);\n+void\thuge_postfork_parent(void);\n+void\thuge_postfork_child(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "50d84cabf6954b24b74a0605dd19faf595ab6af2", "filename": "src/rt/jemalloc/include/jemalloc/internal/jemalloc_internal.h.in", "status": "added", "additions": 1026, "deletions": 0, "changes": 1026, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fjemalloc_internal.h.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fjemalloc_internal.h.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fjemalloc_internal.h.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,1026 @@\n+#ifndef JEMALLOC_INTERNAL_H\n+#define JEMALLOC_INTERNAL_H\n+#include <math.h>\n+#ifdef _WIN32\n+#  include <windows.h>\n+#  define ENOENT ERROR_PATH_NOT_FOUND\n+#  define EINVAL ERROR_BAD_ARGUMENTS\n+#  define EAGAIN ERROR_OUTOFMEMORY\n+#  define EPERM  ERROR_WRITE_FAULT\n+#  define EFAULT ERROR_INVALID_ADDRESS\n+#  define ENOMEM ERROR_NOT_ENOUGH_MEMORY\n+#  undef ERANGE\n+#  define ERANGE ERROR_INVALID_DATA\n+#else\n+#  include <sys/param.h>\n+#  include <sys/mman.h>\n+#  include <sys/syscall.h>\n+#  if !defined(SYS_write) && defined(__NR_write)\n+#    define SYS_write __NR_write\n+#  endif\n+#  include <sys/uio.h>\n+#  include <pthread.h>\n+#  include <errno.h>\n+#endif\n+#include <sys/types.h>\n+\n+#include <limits.h>\n+#ifndef SIZE_T_MAX\n+#  define SIZE_T_MAX\tSIZE_MAX\n+#endif\n+#include <stdarg.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <stdint.h>\n+#include <stddef.h>\n+#ifndef offsetof\n+#  define offsetof(type, member)\t((size_t)&(((type *)NULL)->member))\n+#endif\n+#include <inttypes.h>\n+#include <string.h>\n+#include <strings.h>\n+#include <ctype.h>\n+#ifdef _MSC_VER\n+#  include <io.h>\n+typedef intptr_t ssize_t;\n+#  define PATH_MAX 1024\n+#  define STDERR_FILENO 2\n+#  define __func__ __FUNCTION__\n+/* Disable warnings about deprecated system functions */\n+#  pragma warning(disable: 4996)\n+#else\n+#  include <unistd.h>\n+#endif\n+#include <fcntl.h>\n+\n+#define\tJEMALLOC_NO_DEMANGLE\n+#include \"../jemalloc@install_suffix@.h\"\n+\n+#ifdef JEMALLOC_UTRACE\n+#include <sys/ktrace.h>\n+#endif\n+\n+#ifdef JEMALLOC_VALGRIND\n+#include <valgrind/valgrind.h>\n+#include <valgrind/memcheck.h>\n+#endif\n+\n+#include \"jemalloc/internal/private_namespace.h\"\n+\n+#ifdef JEMALLOC_CC_SILENCE\n+#define\tUNUSED JEMALLOC_ATTR(unused)\n+#else\n+#define\tUNUSED\n+#endif\n+\n+static const bool config_debug =\n+#ifdef JEMALLOC_DEBUG\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_dss =\n+#ifdef JEMALLOC_DSS\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_fill =\n+#ifdef JEMALLOC_FILL\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_lazy_lock =\n+#ifdef JEMALLOC_LAZY_LOCK\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_prof =\n+#ifdef JEMALLOC_PROF\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_prof_libgcc =\n+#ifdef JEMALLOC_PROF_LIBGCC\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_prof_libunwind =\n+#ifdef JEMALLOC_PROF_LIBUNWIND\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_mremap =\n+#ifdef JEMALLOC_MREMAP\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_munmap =\n+#ifdef JEMALLOC_MUNMAP\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_stats =\n+#ifdef JEMALLOC_STATS\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_tcache =\n+#ifdef JEMALLOC_TCACHE\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_tls =\n+#ifdef JEMALLOC_TLS\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_utrace =\n+#ifdef JEMALLOC_UTRACE\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_valgrind =\n+#ifdef JEMALLOC_VALGRIND\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_xmalloc =\n+#ifdef JEMALLOC_XMALLOC\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+static const bool config_ivsalloc =\n+#ifdef JEMALLOC_IVSALLOC\n+    true\n+#else\n+    false\n+#endif\n+    ;\n+\n+#ifdef JEMALLOC_ATOMIC9\n+#include <machine/atomic.h>\n+#endif\n+\n+#if (defined(JEMALLOC_OSATOMIC) || defined(JEMALLOC_OSSPIN))\n+#include <libkern/OSAtomic.h>\n+#endif\n+\n+#ifdef JEMALLOC_ZONE\n+#include <mach/mach_error.h>\n+#include <mach/mach_init.h>\n+#include <mach/vm_map.h>\n+#include <malloc/malloc.h>\n+#endif\n+\n+#define\tRB_COMPACT\n+#include \"jemalloc/internal/rb.h\"\n+#include \"jemalloc/internal/qr.h\"\n+#include \"jemalloc/internal/ql.h\"\n+\n+/*\n+ * jemalloc can conceptually be broken into components (arena, tcache, etc.),\n+ * but there are circular dependencies that cannot be broken without\n+ * substantial performance degradation.  In order to reduce the effect on\n+ * visual code flow, read the header files in multiple passes, with one of the\n+ * following cpp variables defined during each pass:\n+ *\n+ *   JEMALLOC_H_TYPES   : Preprocessor-defined constants and psuedo-opaque data\n+ *                        types.\n+ *   JEMALLOC_H_STRUCTS : Data structures.\n+ *   JEMALLOC_H_EXTERNS : Extern data declarations and function prototypes.\n+ *   JEMALLOC_H_INLINES : Inline functions.\n+ */\n+/******************************************************************************/\n+#define JEMALLOC_H_TYPES\n+\n+#define\tALLOCM_LG_ALIGN_MASK\t((int)0x3f)\n+\n+#define\tZU(z)\t((size_t)z)\n+#define\tQU(q)\t((uint64_t)q)\n+\n+#ifndef __DECONST\n+#  define\t__DECONST(type, var)\t((type)(uintptr_t)(const void *)(var))\n+#endif\n+\n+#ifdef JEMALLOC_DEBUG\n+   /* Disable inlining to make debugging easier. */\n+#  define JEMALLOC_ALWAYS_INLINE\n+#  define JEMALLOC_INLINE\n+#  define inline\n+#else\n+#  define JEMALLOC_ENABLE_INLINE\n+#  ifdef JEMALLOC_HAVE_ATTR\n+#    define JEMALLOC_ALWAYS_INLINE \\\n+\t static inline JEMALLOC_ATTR(unused) JEMALLOC_ATTR(always_inline)\n+#  else\n+#    define JEMALLOC_ALWAYS_INLINE static inline\n+#  endif\n+#  define JEMALLOC_INLINE static inline\n+#  ifdef _MSC_VER\n+#    define inline _inline\n+#  endif\n+#endif\n+\n+/* Smallest size class to support. */\n+#define\tLG_TINY_MIN\t\t3\n+#define\tTINY_MIN\t\t(1U << LG_TINY_MIN)\n+\n+/*\n+ * Minimum alignment of allocations is 2^LG_QUANTUM bytes (ignoring tiny size\n+ * classes).\n+ */\n+#ifndef LG_QUANTUM\n+#  if (defined(__i386__) || defined(_M_IX86))\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __ia64__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __alpha__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __sparc64__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  if (defined(__amd64__) || defined(__x86_64__) || defined(_M_X64))\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __arm__\n+#    define LG_QUANTUM\t\t3\n+#  endif\n+#  ifdef __hppa__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __mips__\n+#    define LG_QUANTUM\t\t3\n+#  endif\n+#  ifdef __powerpc__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __s390__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __SH4__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifdef __tile__\n+#    define LG_QUANTUM\t\t4\n+#  endif\n+#  ifndef LG_QUANTUM\n+#    error \"No LG_QUANTUM definition for architecture; specify via CPPFLAGS\"\n+#  endif\n+#endif\n+\n+#define\tQUANTUM\t\t\t((size_t)(1U << LG_QUANTUM))\n+#define\tQUANTUM_MASK\t\t(QUANTUM - 1)\n+\n+/* Return the smallest quantum multiple that is >= a. */\n+#define\tQUANTUM_CEILING(a)\t\t\t\t\t\t\\\n+\t(((a) + QUANTUM_MASK) & ~QUANTUM_MASK)\n+\n+#define\tLONG\t\t\t((size_t)(1U << LG_SIZEOF_LONG))\n+#define\tLONG_MASK\t\t(LONG - 1)\n+\n+/* Return the smallest long multiple that is >= a. */\n+#define\tLONG_CEILING(a)\t\t\t\t\t\t\t\\\n+\t(((a) + LONG_MASK) & ~LONG_MASK)\n+\n+#define\tSIZEOF_PTR\t\t(1U << LG_SIZEOF_PTR)\n+#define\tPTR_MASK\t\t(SIZEOF_PTR - 1)\n+\n+/* Return the smallest (void *) multiple that is >= a. */\n+#define\tPTR_CEILING(a)\t\t\t\t\t\t\t\\\n+\t(((a) + PTR_MASK) & ~PTR_MASK)\n+\n+/*\n+ * Maximum size of L1 cache line.  This is used to avoid cache line aliasing.\n+ * In addition, this controls the spacing of cacheline-spaced size classes.\n+ *\n+ * CACHELINE cannot be based on LG_CACHELINE because __declspec(align()) can\n+ * only handle raw constants.\n+ */\n+#define\tLG_CACHELINE\t\t6\n+#define\tCACHELINE\t\t64\n+#define\tCACHELINE_MASK\t\t(CACHELINE - 1)\n+\n+/* Return the smallest cacheline multiple that is >= s. */\n+#define\tCACHELINE_CEILING(s)\t\t\t\t\t\t\\\n+\t(((s) + CACHELINE_MASK) & ~CACHELINE_MASK)\n+\n+/* Page size.  STATIC_PAGE_SHIFT is determined by the configure script. */\n+#ifdef PAGE_MASK\n+#  undef PAGE_MASK\n+#endif\n+#define\tLG_PAGE\t\tSTATIC_PAGE_SHIFT\n+#define\tPAGE\t\t((size_t)(1U << STATIC_PAGE_SHIFT))\n+#define\tPAGE_MASK\t((size_t)(PAGE - 1))\n+\n+/* Return the smallest pagesize multiple that is >= s. */\n+#define\tPAGE_CEILING(s)\t\t\t\t\t\t\t\\\n+\t(((s) + PAGE_MASK) & ~PAGE_MASK)\n+\n+/* Return the nearest aligned address at or below a. */\n+#define\tALIGNMENT_ADDR2BASE(a, alignment)\t\t\t\t\\\n+\t((void *)((uintptr_t)(a) & (-(alignment))))\n+\n+/* Return the offset between a and the nearest aligned address at or below a. */\n+#define\tALIGNMENT_ADDR2OFFSET(a, alignment)\t\t\t\t\\\n+\t((size_t)((uintptr_t)(a) & (alignment - 1)))\n+\n+/* Return the smallest alignment multiple that is >= s. */\n+#define\tALIGNMENT_CEILING(s, alignment)\t\t\t\t\t\\\n+\t(((s) + (alignment - 1)) & (-(alignment)))\n+\n+/* Declare a variable length array */\n+#if __STDC_VERSION__ < 199901L\n+#  ifdef _MSC_VER\n+#    include <malloc.h>\n+#    define alloca _alloca\n+#  else\n+#    ifdef JEMALLOC_HAS_ALLOCA_H\n+#      include <alloca.h>\n+#    else\n+#      include <stdlib.h>\n+#    endif\n+#  endif\n+#  define VARIABLE_ARRAY(type, name, count) \\\n+\ttype *name = alloca(sizeof(type) * count)\n+#else\n+#  define VARIABLE_ARRAY(type, name, count) type name[count]\n+#endif\n+\n+#ifdef JEMALLOC_VALGRIND\n+/*\n+ * The JEMALLOC_VALGRIND_*() macros must be macros rather than functions\n+ * so that when Valgrind reports errors, there are no extra stack frames\n+ * in the backtraces.\n+ *\n+ * The size that is reported to valgrind must be consistent through a chain of\n+ * malloc..realloc..realloc calls.  Request size isn't recorded anywhere in\n+ * jemalloc, so it is critical that all callers of these macros provide usize\n+ * rather than request size.  As a result, buffer overflow detection is\n+ * technically weakened for the standard API, though it is generally accepted\n+ * practice to consider any extra bytes reported by malloc_usable_size() as\n+ * usable space.\n+ */\n+#define\tJEMALLOC_VALGRIND_MALLOC(cond, ptr, usize, zero) do {\t\t\\\n+\tif (config_valgrind && opt_valgrind && cond)\t\t\t\\\n+\t\tVALGRIND_MALLOCLIKE_BLOCK(ptr, usize, p2rz(ptr), zero);\t\\\n+} while (0)\n+#define\tJEMALLOC_VALGRIND_REALLOC(ptr, usize, old_ptr, old_usize,\t\\\n+    old_rzsize, zero)  do {\t\t\t\t\t\t\\\n+\tif (config_valgrind && opt_valgrind) {\t\t\t\t\\\n+\t\tsize_t rzsize = p2rz(ptr);\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+\t\tif (ptr == old_ptr) {\t\t\t\t\t\\\n+\t\t\tVALGRIND_RESIZEINPLACE_BLOCK(ptr, old_usize,\t\\\n+\t\t\t    usize, rzsize);\t\t\t\t\\\n+\t\t\tif (zero && old_usize < usize) {\t\t\\\n+\t\t\t\tVALGRIND_MAKE_MEM_DEFINED(\t\t\\\n+\t\t\t\t    (void *)((uintptr_t)ptr +\t\t\\\n+\t\t\t\t    old_usize), usize - old_usize);\t\\\n+\t\t\t}\t\t\t\t\t\t\\\n+\t\t} else {\t\t\t\t\t\t\\\n+\t\t\tif (old_ptr != NULL) {\t\t\t\t\\\n+\t\t\t\tVALGRIND_FREELIKE_BLOCK(old_ptr,\t\\\n+\t\t\t\t    old_rzsize);\t\t\t\\\n+\t\t\t}\t\t\t\t\t\t\\\n+\t\t\tif (ptr != NULL) {\t\t\t\t\\\n+\t\t\t\tsize_t copy_size = (old_usize < usize)\t\\\n+\t\t\t\t    ?  old_usize : usize;\t\t\\\n+\t\t\t\tsize_t tail_size = usize - copy_size;\t\\\n+\t\t\t\tVALGRIND_MALLOCLIKE_BLOCK(ptr, usize,\t\\\n+\t\t\t\t    rzsize, false);\t\t\t\\\n+\t\t\t\tif (copy_size > 0) {\t\t\t\\\n+\t\t\t\t\tVALGRIND_MAKE_MEM_DEFINED(ptr,\t\\\n+\t\t\t\t\t    copy_size);\t\t\t\\\n+\t\t\t\t}\t\t\t\t\t\\\n+\t\t\t\tif (zero && tail_size > 0) {\t\t\\\n+\t\t\t\t\tVALGRIND_MAKE_MEM_DEFINED(\t\\\n+\t\t\t\t\t    (void *)((uintptr_t)ptr +\t\\\n+\t\t\t\t\t    copy_size), tail_size);\t\\\n+\t\t\t\t}\t\t\t\t\t\\\n+\t\t\t}\t\t\t\t\t\t\\\n+\t\t}\t\t\t\t\t\t\t\\\n+\t}\t\t\t\t\t\t\t\t\\\n+} while (0)\n+#define\tJEMALLOC_VALGRIND_FREE(ptr, rzsize) do {\t\t\t\\\n+\tif (config_valgrind && opt_valgrind)\t\t\t\t\\\n+\t\tVALGRIND_FREELIKE_BLOCK(ptr, rzsize);\t\t\t\\\n+} while (0)\n+#else\n+#define\tRUNNING_ON_VALGRIND\t((unsigned)0)\n+#define\tVALGRIND_MALLOCLIKE_BLOCK(addr, sizeB, rzB, is_zeroed) \\\n+    do {} while (0)\n+#define\tVALGRIND_RESIZEINPLACE_BLOCK(addr, oldSizeB, newSizeB, rzB) \\\n+    do {} while (0)\n+#define\tVALGRIND_FREELIKE_BLOCK(addr, rzB) do {} while (0)\n+#define\tVALGRIND_MAKE_MEM_NOACCESS(_qzz_addr, _qzz_len) do {} while (0)\n+#define\tVALGRIND_MAKE_MEM_UNDEFINED(_qzz_addr, _qzz_len) do {} while (0)\n+#define\tVALGRIND_MAKE_MEM_DEFINED(_qzz_addr, _qzz_len) do {} while (0)\n+#define\tJEMALLOC_VALGRIND_MALLOC(cond, ptr, usize, zero) do {} while (0)\n+#define\tJEMALLOC_VALGRIND_REALLOC(ptr, usize, old_ptr, old_usize,\t\\\n+    old_rzsize, zero) do {} while (0)\n+#define\tJEMALLOC_VALGRIND_FREE(ptr, rzsize) do {} while (0)\n+#endif\n+\n+#include \"jemalloc/internal/util.h\"\n+#include \"jemalloc/internal/atomic.h\"\n+#include \"jemalloc/internal/prng.h\"\n+#include \"jemalloc/internal/ckh.h\"\n+#include \"jemalloc/internal/size_classes.h\"\n+#include \"jemalloc/internal/stats.h\"\n+#include \"jemalloc/internal/ctl.h\"\n+#include \"jemalloc/internal/mutex.h\"\n+#include \"jemalloc/internal/tsd.h\"\n+#include \"jemalloc/internal/mb.h\"\n+#include \"jemalloc/internal/extent.h\"\n+#include \"jemalloc/internal/arena.h\"\n+#include \"jemalloc/internal/bitmap.h\"\n+#include \"jemalloc/internal/base.h\"\n+#include \"jemalloc/internal/chunk.h\"\n+#include \"jemalloc/internal/huge.h\"\n+#include \"jemalloc/internal/rtree.h\"\n+#include \"jemalloc/internal/tcache.h\"\n+#include \"jemalloc/internal/hash.h\"\n+#include \"jemalloc/internal/quarantine.h\"\n+#include \"jemalloc/internal/prof.h\"\n+\n+#undef JEMALLOC_H_TYPES\n+/******************************************************************************/\n+#define JEMALLOC_H_STRUCTS\n+\n+#include \"jemalloc/internal/util.h\"\n+#include \"jemalloc/internal/atomic.h\"\n+#include \"jemalloc/internal/prng.h\"\n+#include \"jemalloc/internal/ckh.h\"\n+#include \"jemalloc/internal/size_classes.h\"\n+#include \"jemalloc/internal/stats.h\"\n+#include \"jemalloc/internal/ctl.h\"\n+#include \"jemalloc/internal/mutex.h\"\n+#include \"jemalloc/internal/tsd.h\"\n+#include \"jemalloc/internal/mb.h\"\n+#include \"jemalloc/internal/bitmap.h\"\n+#include \"jemalloc/internal/extent.h\"\n+#include \"jemalloc/internal/arena.h\"\n+#include \"jemalloc/internal/base.h\"\n+#include \"jemalloc/internal/chunk.h\"\n+#include \"jemalloc/internal/huge.h\"\n+#include \"jemalloc/internal/rtree.h\"\n+#include \"jemalloc/internal/tcache.h\"\n+#include \"jemalloc/internal/hash.h\"\n+#include \"jemalloc/internal/quarantine.h\"\n+#include \"jemalloc/internal/prof.h\"\n+\n+typedef struct {\n+\tuint64_t\tallocated;\n+\tuint64_t\tdeallocated;\n+} thread_allocated_t;\n+/*\n+ * The JEMALLOC_CONCAT() wrapper is necessary to pass {0, 0} via a cpp macro\n+ * argument.\n+ */\n+#define\tTHREAD_ALLOCATED_INITIALIZER\tJEMALLOC_CONCAT({0, 0})\n+\n+#undef JEMALLOC_H_STRUCTS\n+/******************************************************************************/\n+#define JEMALLOC_H_EXTERNS\n+\n+extern bool\topt_abort;\n+extern bool\topt_junk;\n+extern size_t\topt_quarantine;\n+extern bool\topt_redzone;\n+extern bool\topt_utrace;\n+extern bool\topt_valgrind;\n+extern bool\topt_xmalloc;\n+extern bool\topt_zero;\n+extern size_t\topt_narenas;\n+\n+/* Number of CPUs. */\n+extern unsigned\t\tncpus;\n+\n+/* Protects arenas initialization (arenas, arenas_total). */\n+extern malloc_mutex_t\tarenas_lock;\n+/*\n+ * Arenas that are used to service external requests.  Not all elements of the\n+ * arenas array are necessarily used; arenas are created lazily as needed.\n+ *\n+ * arenas[0..narenas_auto) are used for automatic multiplexing of threads and\n+ * arenas.  arenas[narenas_auto..narenas_total) are only used if the application\n+ * takes some action to create them and allocate from them.\n+ */\n+extern arena_t\t\t**arenas;\n+extern unsigned\t\tnarenas_total;\n+extern unsigned\t\tnarenas_auto; /* Read-only after initialization. */\n+\n+arena_t\t*arenas_extend(unsigned ind);\n+void\tarenas_cleanup(void *arg);\n+arena_t\t*choose_arena_hard(void);\n+void\tjemalloc_prefork(void);\n+void\tjemalloc_postfork_parent(void);\n+void\tjemalloc_postfork_child(void);\n+\n+#include \"jemalloc/internal/util.h\"\n+#include \"jemalloc/internal/atomic.h\"\n+#include \"jemalloc/internal/prng.h\"\n+#include \"jemalloc/internal/ckh.h\"\n+#include \"jemalloc/internal/size_classes.h\"\n+#include \"jemalloc/internal/stats.h\"\n+#include \"jemalloc/internal/ctl.h\"\n+#include \"jemalloc/internal/mutex.h\"\n+#include \"jemalloc/internal/tsd.h\"\n+#include \"jemalloc/internal/mb.h\"\n+#include \"jemalloc/internal/bitmap.h\"\n+#include \"jemalloc/internal/extent.h\"\n+#include \"jemalloc/internal/arena.h\"\n+#include \"jemalloc/internal/base.h\"\n+#include \"jemalloc/internal/chunk.h\"\n+#include \"jemalloc/internal/huge.h\"\n+#include \"jemalloc/internal/rtree.h\"\n+#include \"jemalloc/internal/tcache.h\"\n+#include \"jemalloc/internal/hash.h\"\n+#include \"jemalloc/internal/quarantine.h\"\n+#include \"jemalloc/internal/prof.h\"\n+\n+#undef JEMALLOC_H_EXTERNS\n+/******************************************************************************/\n+#define JEMALLOC_H_INLINES\n+\n+#include \"jemalloc/internal/util.h\"\n+#include \"jemalloc/internal/atomic.h\"\n+#include \"jemalloc/internal/prng.h\"\n+#include \"jemalloc/internal/ckh.h\"\n+#include \"jemalloc/internal/size_classes.h\"\n+#include \"jemalloc/internal/stats.h\"\n+#include \"jemalloc/internal/ctl.h\"\n+#include \"jemalloc/internal/mutex.h\"\n+#include \"jemalloc/internal/tsd.h\"\n+#include \"jemalloc/internal/mb.h\"\n+#include \"jemalloc/internal/extent.h\"\n+#include \"jemalloc/internal/base.h\"\n+#include \"jemalloc/internal/chunk.h\"\n+#include \"jemalloc/internal/huge.h\"\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+malloc_tsd_protos(JEMALLOC_ATTR(unused), arenas, arena_t *)\n+\n+size_t\ts2u(size_t size);\n+size_t\tsa2u(size_t size, size_t alignment);\n+unsigned\tnarenas_total_get(void);\n+arena_t\t*choose_arena(arena_t *arena);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_C_))\n+/*\n+ * Map of pthread_self() --> arenas[???], used for selecting an arena to use\n+ * for allocations.\n+ */\n+malloc_tsd_externs(arenas, arena_t *)\n+malloc_tsd_funcs(JEMALLOC_ALWAYS_INLINE, arenas, arena_t *, NULL,\n+    arenas_cleanup)\n+\n+/*\n+ * Compute usable size that would result from allocating an object with the\n+ * specified size.\n+ */\n+JEMALLOC_ALWAYS_INLINE size_t\n+s2u(size_t size)\n+{\n+\n+\tif (size <= SMALL_MAXCLASS)\n+\t\treturn (arena_bin_info[SMALL_SIZE2BIN(size)].reg_size);\n+\tif (size <= arena_maxclass)\n+\t\treturn (PAGE_CEILING(size));\n+\treturn (CHUNK_CEILING(size));\n+}\n+\n+/*\n+ * Compute usable size that would result from allocating an object with the\n+ * specified size and alignment.\n+ */\n+JEMALLOC_ALWAYS_INLINE size_t\n+sa2u(size_t size, size_t alignment)\n+{\n+\tsize_t usize;\n+\n+\tassert(alignment != 0 && ((alignment - 1) & alignment) == 0);\n+\n+\t/*\n+\t * Round size up to the nearest multiple of alignment.\n+\t *\n+\t * This done, we can take advantage of the fact that for each small\n+\t * size class, every object is aligned at the smallest power of two\n+\t * that is non-zero in the base two representation of the size.  For\n+\t * example:\n+\t *\n+\t *   Size |   Base 2 | Minimum alignment\n+\t *   -----+----------+------------------\n+\t *     96 |  1100000 |  32\n+\t *    144 | 10100000 |  32\n+\t *    192 | 11000000 |  64\n+\t */\n+\tusize = ALIGNMENT_CEILING(size, alignment);\n+\t/*\n+\t * (usize < size) protects against the combination of maximal\n+\t * alignment and size greater than maximal alignment.\n+\t */\n+\tif (usize < size) {\n+\t\t/* size_t overflow. */\n+\t\treturn (0);\n+\t}\n+\n+\tif (usize <= arena_maxclass && alignment <= PAGE) {\n+\t\tif (usize <= SMALL_MAXCLASS)\n+\t\t\treturn (arena_bin_info[SMALL_SIZE2BIN(usize)].reg_size);\n+\t\treturn (PAGE_CEILING(usize));\n+\t} else {\n+\t\tsize_t run_size;\n+\n+\t\t/*\n+\t\t * We can't achieve subpage alignment, so round up alignment\n+\t\t * permanently; it makes later calculations simpler.\n+\t\t */\n+\t\talignment = PAGE_CEILING(alignment);\n+\t\tusize = PAGE_CEILING(size);\n+\t\t/*\n+\t\t * (usize < size) protects against very large sizes within\n+\t\t * PAGE of SIZE_T_MAX.\n+\t\t *\n+\t\t * (usize + alignment < usize) protects against the\n+\t\t * combination of maximal alignment and usize large enough\n+\t\t * to cause overflow.  This is similar to the first overflow\n+\t\t * check above, but it needs to be repeated due to the new\n+\t\t * usize value, which may now be *equal* to maximal\n+\t\t * alignment, whereas before we only detected overflow if the\n+\t\t * original size was *greater* than maximal alignment.\n+\t\t */\n+\t\tif (usize < size || usize + alignment < usize) {\n+\t\t\t/* size_t overflow. */\n+\t\t\treturn (0);\n+\t\t}\n+\n+\t\t/*\n+\t\t * Calculate the size of the over-size run that arena_palloc()\n+\t\t * would need to allocate in order to guarantee the alignment.\n+\t\t * If the run wouldn't fit within a chunk, round up to a huge\n+\t\t * allocation size.\n+\t\t */\n+\t\trun_size = usize + alignment - PAGE;\n+\t\tif (run_size <= arena_maxclass)\n+\t\t\treturn (PAGE_CEILING(usize));\n+\t\treturn (CHUNK_CEILING(usize));\n+\t}\n+}\n+\n+JEMALLOC_INLINE unsigned\n+narenas_total_get(void)\n+{\n+\tunsigned narenas;\n+\n+\tmalloc_mutex_lock(&arenas_lock);\n+\tnarenas = narenas_total;\n+\tmalloc_mutex_unlock(&arenas_lock);\n+\n+\treturn (narenas);\n+}\n+\n+/* Choose an arena based on a per-thread value. */\n+JEMALLOC_INLINE arena_t *\n+choose_arena(arena_t *arena)\n+{\n+\tarena_t *ret;\n+\n+\tif (arena != NULL)\n+\t\treturn (arena);\n+\n+\tif ((ret = *arenas_tsd_get()) == NULL) {\n+\t\tret = choose_arena_hard();\n+\t\tassert(ret != NULL);\n+\t}\n+\n+\treturn (ret);\n+}\n+#endif\n+\n+#include \"jemalloc/internal/bitmap.h\"\n+#include \"jemalloc/internal/rtree.h\"\n+/*\n+ * Include arena.h twice in order to resolve circular dependencies with\n+ * tcache.h.\n+ */\n+#define\tJEMALLOC_ARENA_INLINE_A\n+#include \"jemalloc/internal/arena.h\"\n+#undef JEMALLOC_ARENA_INLINE_A\n+#include \"jemalloc/internal/tcache.h\"\n+#define\tJEMALLOC_ARENA_INLINE_B\n+#include \"jemalloc/internal/arena.h\"\n+#undef JEMALLOC_ARENA_INLINE_B\n+#include \"jemalloc/internal/hash.h\"\n+#include \"jemalloc/internal/quarantine.h\"\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+void\t*imallocx(size_t size, bool try_tcache, arena_t *arena);\n+void\t*imalloc(size_t size);\n+void\t*icallocx(size_t size, bool try_tcache, arena_t *arena);\n+void\t*icalloc(size_t size);\n+void\t*ipallocx(size_t usize, size_t alignment, bool zero, bool try_tcache,\n+    arena_t *arena);\n+void\t*ipalloc(size_t usize, size_t alignment, bool zero);\n+size_t\tisalloc(const void *ptr, bool demote);\n+size_t\tivsalloc(const void *ptr, bool demote);\n+size_t\tu2rz(size_t usize);\n+size_t\tp2rz(const void *ptr);\n+void\tidallocx(void *ptr, bool try_tcache);\n+void\tidalloc(void *ptr);\n+void\tiqallocx(void *ptr, bool try_tcache);\n+void\tiqalloc(void *ptr);\n+void\t*irallocx(void *ptr, size_t size, size_t extra, size_t alignment,\n+    bool zero, bool no_move, bool try_tcache_alloc, bool try_tcache_dalloc,\n+    arena_t *arena);\n+void\t*iralloc(void *ptr, size_t size, size_t extra, size_t alignment,\n+    bool zero, bool no_move);\n+malloc_tsd_protos(JEMALLOC_ATTR(unused), thread_allocated, thread_allocated_t)\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_C_))\n+JEMALLOC_ALWAYS_INLINE void *\n+imallocx(size_t size, bool try_tcache, arena_t *arena)\n+{\n+\n+\tassert(size != 0);\n+\n+\tif (size <= arena_maxclass)\n+\t\treturn (arena_malloc(arena, size, false, try_tcache));\n+\telse\n+\t\treturn (huge_malloc(size, false));\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+imalloc(size_t size)\n+{\n+\n+\treturn (imallocx(size, true, NULL));\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+icallocx(size_t size, bool try_tcache, arena_t *arena)\n+{\n+\n+\tif (size <= arena_maxclass)\n+\t\treturn (arena_malloc(arena, size, true, try_tcache));\n+\telse\n+\t\treturn (huge_malloc(size, true));\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+icalloc(size_t size)\n+{\n+\n+\treturn (icallocx(size, true, NULL));\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+ipallocx(size_t usize, size_t alignment, bool zero, bool try_tcache,\n+    arena_t *arena)\n+{\n+\tvoid *ret;\n+\n+\tassert(usize != 0);\n+\tassert(usize == sa2u(usize, alignment));\n+\n+\tif (usize <= arena_maxclass && alignment <= PAGE)\n+\t\tret = arena_malloc(arena, usize, zero, try_tcache);\n+\telse {\n+\t\tif (usize <= arena_maxclass) {\n+\t\t\tret = arena_palloc(choose_arena(arena), usize,\n+\t\t\t    alignment, zero);\n+\t\t} else if (alignment <= chunksize)\n+\t\t\tret = huge_malloc(usize, zero);\n+\t\telse\n+\t\t\tret = huge_palloc(usize, alignment, zero);\n+\t}\n+\n+\tassert(ALIGNMENT_ADDR2BASE(ret, alignment) == ret);\n+\treturn (ret);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+ipalloc(size_t usize, size_t alignment, bool zero)\n+{\n+\n+\treturn (ipallocx(usize, alignment, zero, true, NULL));\n+}\n+\n+/*\n+ * Typical usage:\n+ *   void *ptr = [...]\n+ *   size_t sz = isalloc(ptr, config_prof);\n+ */\n+JEMALLOC_ALWAYS_INLINE size_t\n+isalloc(const void *ptr, bool demote)\n+{\n+\tsize_t ret;\n+\tarena_chunk_t *chunk;\n+\n+\tassert(ptr != NULL);\n+\t/* Demotion only makes sense if config_prof is true. */\n+\tassert(config_prof || demote == false);\n+\n+\tchunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+\tif (chunk != ptr)\n+\t\tret = arena_salloc(ptr, demote);\n+\telse\n+\t\tret = huge_salloc(ptr);\n+\n+\treturn (ret);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE size_t\n+ivsalloc(const void *ptr, bool demote)\n+{\n+\n+\t/* Return 0 if ptr is not within a chunk managed by jemalloc. */\n+\tif (rtree_get(chunks_rtree, (uintptr_t)CHUNK_ADDR2BASE(ptr)) == NULL)\n+\t\treturn (0);\n+\n+\treturn (isalloc(ptr, demote));\n+}\n+\n+JEMALLOC_INLINE size_t\n+u2rz(size_t usize)\n+{\n+\tsize_t ret;\n+\n+\tif (usize <= SMALL_MAXCLASS) {\n+\t\tsize_t binind = SMALL_SIZE2BIN(usize);\n+\t\tret = arena_bin_info[binind].redzone_size;\n+\t} else\n+\t\tret = 0;\n+\n+\treturn (ret);\n+}\n+\n+JEMALLOC_INLINE size_t\n+p2rz(const void *ptr)\n+{\n+\tsize_t usize = isalloc(ptr, false);\n+\n+\treturn (u2rz(usize));\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+idallocx(void *ptr, bool try_tcache)\n+{\n+\tarena_chunk_t *chunk;\n+\n+\tassert(ptr != NULL);\n+\n+\tchunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+\tif (chunk != ptr)\n+\t\tarena_dalloc(chunk->arena, chunk, ptr, try_tcache);\n+\telse\n+\t\thuge_dalloc(ptr, true);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+idalloc(void *ptr)\n+{\n+\n+\tidallocx(ptr, true);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+iqallocx(void *ptr, bool try_tcache)\n+{\n+\n+\tif (config_fill && opt_quarantine)\n+\t\tquarantine(ptr);\n+\telse\n+\t\tidallocx(ptr, try_tcache);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+iqalloc(void *ptr)\n+{\n+\n+\tiqallocx(ptr, true);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+irallocx(void *ptr, size_t size, size_t extra, size_t alignment, bool zero,\n+    bool no_move, bool try_tcache_alloc, bool try_tcache_dalloc, arena_t *arena)\n+{\n+\tvoid *ret;\n+\tsize_t oldsize;\n+\n+\tassert(ptr != NULL);\n+\tassert(size != 0);\n+\n+\toldsize = isalloc(ptr, config_prof);\n+\n+\tif (alignment != 0 && ((uintptr_t)ptr & ((uintptr_t)alignment-1))\n+\t    != 0) {\n+\t\tsize_t usize, copysize;\n+\n+\t\t/*\n+\t\t * Existing object alignment is inadequate; allocate new space\n+\t\t * and copy.\n+\t\t */\n+\t\tif (no_move)\n+\t\t\treturn (NULL);\n+\t\tusize = sa2u(size + extra, alignment);\n+\t\tif (usize == 0)\n+\t\t\treturn (NULL);\n+\t\tret = ipallocx(usize, alignment, zero, try_tcache_alloc, arena);\n+\t\tif (ret == NULL) {\n+\t\t\tif (extra == 0)\n+\t\t\t\treturn (NULL);\n+\t\t\t/* Try again, without extra this time. */\n+\t\t\tusize = sa2u(size, alignment);\n+\t\t\tif (usize == 0)\n+\t\t\t\treturn (NULL);\n+\t\t\tret = ipallocx(usize, alignment, zero, try_tcache_alloc,\n+\t\t\t    arena);\n+\t\t\tif (ret == NULL)\n+\t\t\t\treturn (NULL);\n+\t\t}\n+\t\t/*\n+\t\t * Copy at most size bytes (not size+extra), since the caller\n+\t\t * has no expectation that the extra bytes will be reliably\n+\t\t * preserved.\n+\t\t */\n+\t\tcopysize = (size < oldsize) ? size : oldsize;\n+\t\tmemcpy(ret, ptr, copysize);\n+\t\tiqallocx(ptr, try_tcache_dalloc);\n+\t\treturn (ret);\n+\t}\n+\n+\tif (no_move) {\n+\t\tif (size <= arena_maxclass) {\n+\t\t\treturn (arena_ralloc_no_move(ptr, oldsize, size,\n+\t\t\t    extra, zero));\n+\t\t} else {\n+\t\t\treturn (huge_ralloc_no_move(ptr, oldsize, size,\n+\t\t\t    extra));\n+\t\t}\n+\t} else {\n+\t\tif (size + extra <= arena_maxclass) {\n+\t\t\treturn (arena_ralloc(arena, ptr, oldsize, size, extra,\n+\t\t\t    alignment, zero, try_tcache_alloc,\n+\t\t\t    try_tcache_dalloc));\n+\t\t} else {\n+\t\t\treturn (huge_ralloc(ptr, oldsize, size, extra,\n+\t\t\t    alignment, zero, try_tcache_dalloc));\n+\t\t}\n+\t}\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+iralloc(void *ptr, size_t size, size_t extra, size_t alignment, bool zero,\n+    bool no_move)\n+{\n+\n+\treturn (irallocx(ptr, size, extra, alignment, zero, no_move, true, true,\n+\t    NULL));\n+}\n+\n+malloc_tsd_externs(thread_allocated, thread_allocated_t)\n+malloc_tsd_funcs(JEMALLOC_ALWAYS_INLINE, thread_allocated, thread_allocated_t,\n+    THREAD_ALLOCATED_INITIALIZER, malloc_tsd_no_cleanup)\n+#endif\n+\n+#include \"jemalloc/internal/prof.h\"\n+\n+#undef JEMALLOC_H_INLINES\n+/******************************************************************************/\n+#endif /* JEMALLOC_INTERNAL_H */"}, {"sha": "c60413e7e68f4dffe9108edb32277f6338e77bcc", "filename": "src/rt/jemalloc/include/jemalloc/internal/mb.h", "status": "added", "additions": 115, "deletions": 0, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fmb.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fmb.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fmb.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,115 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+void\tmb_write(void);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_MB_C_))\n+#ifdef __i386__\n+/*\n+ * According to the Intel Architecture Software Developer's Manual, current\n+ * processors execute instructions in order from the perspective of other\n+ * processors in a multiprocessor system, but 1) Intel reserves the right to\n+ * change that, and 2) the compiler's optimizer could re-order instructions if\n+ * there weren't some form of barrier.  Therefore, even if running on an\n+ * architecture that does not need memory barriers (everything through at least\n+ * i686), an \"optimizer barrier\" is necessary.\n+ */\n+JEMALLOC_INLINE void\n+mb_write(void)\n+{\n+\n+#  if 0\n+    /* This is a true memory barrier. */\n+    asm volatile (\"pusha;\"\n+        \"xor  %%eax,%%eax;\"\n+        \"cpuid;\"\n+        \"popa;\"\n+        : /* Outputs. */\n+        : /* Inputs. */\n+        : \"memory\" /* Clobbers. */\n+        );\n+#else\n+    /*\n+     * This is hopefully enough to keep the compiler from reordering\n+     * instructions around this one.\n+     */\n+    asm volatile (\"nop;\"\n+        : /* Outputs. */\n+        : /* Inputs. */\n+        : \"memory\" /* Clobbers. */\n+        );\n+#endif\n+}\n+#elif (defined(__amd64__) || defined(__x86_64__))\n+JEMALLOC_INLINE void\n+mb_write(void)\n+{\n+\n+    asm volatile (\"sfence\"\n+        : /* Outputs. */\n+        : /* Inputs. */\n+        : \"memory\" /* Clobbers. */\n+        );\n+}\n+#elif defined(__powerpc__)\n+JEMALLOC_INLINE void\n+mb_write(void)\n+{\n+\n+    asm volatile (\"eieio\"\n+        : /* Outputs. */\n+        : /* Inputs. */\n+        : \"memory\" /* Clobbers. */\n+        );\n+}\n+#elif defined(__sparc64__)\n+JEMALLOC_INLINE void\n+mb_write(void)\n+{\n+\n+    asm volatile (\"membar #StoreStore\"\n+        : /* Outputs. */\n+        : /* Inputs. */\n+        : \"memory\" /* Clobbers. */\n+        );\n+}\n+#elif defined(__tile__)\n+JEMALLOC_INLINE void\n+mb_write(void)\n+{\n+\n+    __sync_synchronize();\n+}\n+#else\n+/*\n+ * This is much slower than a simple memory barrier, but the semantics of mutex\n+ * unlock make this work.\n+ */\n+JEMALLOC_INLINE void\n+mb_write(void)\n+{\n+    malloc_mutex_t mtx;\n+\n+    malloc_mutex_init(&mtx);\n+    malloc_mutex_lock(&mtx);\n+    malloc_mutex_unlock(&mtx);\n+}\n+#endif\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "6a40432cd3cd1abddbb459df5bd10f4c7fafb437", "filename": "src/rt/jemalloc/include/jemalloc/internal/mutex.h", "status": "added", "additions": 99, "deletions": 0, "changes": 99, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fmutex.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fmutex.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fmutex.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,99 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct malloc_mutex_s malloc_mutex_t;\n+\n+#ifdef _WIN32\n+#  define MALLOC_MUTEX_INITIALIZER\n+#elif (defined(JEMALLOC_OSSPIN))\n+#  define MALLOC_MUTEX_INITIALIZER {0}\n+#elif (defined(JEMALLOC_MUTEX_INIT_CB))\n+#  define MALLOC_MUTEX_INITIALIZER {PTHREAD_MUTEX_INITIALIZER, NULL}\n+#else\n+#  if (defined(PTHREAD_MUTEX_ADAPTIVE_NP) &&\t\t\t\t\\\n+       defined(PTHREAD_ADAPTIVE_MUTEX_INITIALIZER_NP))\n+#    define MALLOC_MUTEX_TYPE PTHREAD_MUTEX_ADAPTIVE_NP\n+#    define MALLOC_MUTEX_INITIALIZER {PTHREAD_ADAPTIVE_MUTEX_INITIALIZER_NP}\n+#  else\n+#    define MALLOC_MUTEX_TYPE PTHREAD_MUTEX_DEFAULT\n+#    define MALLOC_MUTEX_INITIALIZER {PTHREAD_MUTEX_INITIALIZER}\n+#  endif\n+#endif\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct malloc_mutex_s {\n+#ifdef _WIN32\n+    CRITICAL_SECTION\tlock;\n+#elif (defined(JEMALLOC_OSSPIN))\n+    OSSpinLock\t\tlock;\n+#elif (defined(JEMALLOC_MUTEX_INIT_CB))\n+    pthread_mutex_t\t\tlock;\n+    malloc_mutex_t\t\t*postponed_next;\n+#else\n+    pthread_mutex_t\t\tlock;\n+#endif\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+#ifdef JEMALLOC_LAZY_LOCK\n+extern bool isthreaded;\n+#else\n+#  undef isthreaded /* Undo private_namespace.h definition. */\n+#  define isthreaded true\n+#endif\n+\n+bool\tmalloc_mutex_init(malloc_mutex_t *mutex);\n+void\tmalloc_mutex_prefork(malloc_mutex_t *mutex);\n+void\tmalloc_mutex_postfork_parent(malloc_mutex_t *mutex);\n+void\tmalloc_mutex_postfork_child(malloc_mutex_t *mutex);\n+bool\tmutex_boot(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+void\tmalloc_mutex_lock(malloc_mutex_t *mutex);\n+void\tmalloc_mutex_unlock(malloc_mutex_t *mutex);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_MUTEX_C_))\n+JEMALLOC_INLINE void\n+malloc_mutex_lock(malloc_mutex_t *mutex)\n+{\n+\n+    if (isthreaded) {\n+#ifdef _WIN32\n+        EnterCriticalSection(&mutex->lock);\n+#elif (defined(JEMALLOC_OSSPIN))\n+        OSSpinLockLock(&mutex->lock);\n+#else\n+        pthread_mutex_lock(&mutex->lock);\n+#endif\n+    }\n+}\n+\n+JEMALLOC_INLINE void\n+malloc_mutex_unlock(malloc_mutex_t *mutex)\n+{\n+\n+    if (isthreaded) {\n+#ifdef _WIN32\n+        LeaveCriticalSection(&mutex->lock);\n+#elif (defined(JEMALLOC_OSSPIN))\n+        OSSpinLockUnlock(&mutex->lock);\n+#else\n+        pthread_mutex_unlock(&mutex->lock);\n+#endif\n+    }\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "65de3163fd3698db1d63bccceb9d550d138a9eb3", "filename": "src/rt/jemalloc/include/jemalloc/internal/private_namespace.h", "status": "added", "additions": 390, "deletions": 0, "changes": 390, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprivate_namespace.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprivate_namespace.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprivate_namespace.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,390 @@\n+#define\ta0calloc JEMALLOC_N(a0calloc)\n+#define\ta0free JEMALLOC_N(a0free)\n+#define\ta0malloc JEMALLOC_N(a0malloc)\n+#define\tarena_alloc_junk_small JEMALLOC_N(arena_alloc_junk_small)\n+#define\tarena_bin_index JEMALLOC_N(arena_bin_index)\n+#define\tarena_bin_info JEMALLOC_N(arena_bin_info)\n+#define\tarena_boot JEMALLOC_N(arena_boot)\n+#define\tarena_dalloc JEMALLOC_N(arena_dalloc)\n+#define\tarena_dalloc_bin JEMALLOC_N(arena_dalloc_bin)\n+#define\tarena_dalloc_bin_locked JEMALLOC_N(arena_dalloc_bin_locked)\n+#define\tarena_dalloc_junk_small JEMALLOC_N(arena_dalloc_junk_small)\n+#define\tarena_dalloc_large JEMALLOC_N(arena_dalloc_large)\n+#define\tarena_dalloc_large_locked JEMALLOC_N(arena_dalloc_large_locked)\n+#define\tarena_dalloc_small JEMALLOC_N(arena_dalloc_small)\n+#define\tarena_dss_prec_get JEMALLOC_N(arena_dss_prec_get)\n+#define\tarena_dss_prec_set JEMALLOC_N(arena_dss_prec_set)\n+#define\tarena_malloc JEMALLOC_N(arena_malloc)\n+#define\tarena_malloc_large JEMALLOC_N(arena_malloc_large)\n+#define\tarena_malloc_small JEMALLOC_N(arena_malloc_small)\n+#define\tarena_mapbits_allocated_get JEMALLOC_N(arena_mapbits_allocated_get)\n+#define\tarena_mapbits_binind_get JEMALLOC_N(arena_mapbits_binind_get)\n+#define\tarena_mapbits_dirty_get JEMALLOC_N(arena_mapbits_dirty_get)\n+#define\tarena_mapbits_get JEMALLOC_N(arena_mapbits_get)\n+#define\tarena_mapbits_large_binind_set JEMALLOC_N(arena_mapbits_large_binind_set)\n+#define\tarena_mapbits_large_get JEMALLOC_N(arena_mapbits_large_get)\n+#define\tarena_mapbits_large_set JEMALLOC_N(arena_mapbits_large_set)\n+#define\tarena_mapbits_large_size_get JEMALLOC_N(arena_mapbits_large_size_get)\n+#define\tarena_mapbits_small_runind_get JEMALLOC_N(arena_mapbits_small_runind_get)\n+#define\tarena_mapbits_small_set JEMALLOC_N(arena_mapbits_small_set)\n+#define\tarena_mapbits_unallocated_set JEMALLOC_N(arena_mapbits_unallocated_set)\n+#define\tarena_mapbits_unallocated_size_get JEMALLOC_N(arena_mapbits_unallocated_size_get)\n+#define\tarena_mapbits_unallocated_size_set JEMALLOC_N(arena_mapbits_unallocated_size_set)\n+#define\tarena_mapbits_unzeroed_get JEMALLOC_N(arena_mapbits_unzeroed_get)\n+#define\tarena_mapbits_unzeroed_set JEMALLOC_N(arena_mapbits_unzeroed_set)\n+#define\tarena_mapbitsp_get JEMALLOC_N(arena_mapbitsp_get)\n+#define\tarena_mapp_get JEMALLOC_N(arena_mapp_get)\n+#define\tarena_maxclass JEMALLOC_N(arena_maxclass)\n+#define\tarena_new JEMALLOC_N(arena_new)\n+#define\tarena_palloc JEMALLOC_N(arena_palloc)\n+#define\tarena_postfork_child JEMALLOC_N(arena_postfork_child)\n+#define\tarena_postfork_parent JEMALLOC_N(arena_postfork_parent)\n+#define\tarena_prefork JEMALLOC_N(arena_prefork)\n+#define\tarena_prof_accum JEMALLOC_N(arena_prof_accum)\n+#define\tarena_prof_accum_impl JEMALLOC_N(arena_prof_accum_impl)\n+#define\tarena_prof_accum_locked JEMALLOC_N(arena_prof_accum_locked)\n+#define\tarena_prof_ctx_get JEMALLOC_N(arena_prof_ctx_get)\n+#define\tarena_prof_ctx_set JEMALLOC_N(arena_prof_ctx_set)\n+#define\tarena_prof_promoted JEMALLOC_N(arena_prof_promoted)\n+#define\tarena_ptr_small_binind_get JEMALLOC_N(arena_ptr_small_binind_get)\n+#define\tarena_purge_all JEMALLOC_N(arena_purge_all)\n+#define\tarena_ralloc JEMALLOC_N(arena_ralloc)\n+#define\tarena_ralloc_no_move JEMALLOC_N(arena_ralloc_no_move)\n+#define\tarena_run_regind JEMALLOC_N(arena_run_regind)\n+#define\tarena_salloc JEMALLOC_N(arena_salloc)\n+#define\tarena_stats_merge JEMALLOC_N(arena_stats_merge)\n+#define\tarena_tcache_fill_small JEMALLOC_N(arena_tcache_fill_small)\n+#define\tarenas JEMALLOC_N(arenas)\n+#define\tarenas_booted JEMALLOC_N(arenas_booted)\n+#define\tarenas_cleanup JEMALLOC_N(arenas_cleanup)\n+#define\tarenas_extend JEMALLOC_N(arenas_extend)\n+#define\tarenas_initialized JEMALLOC_N(arenas_initialized)\n+#define\tarenas_lock JEMALLOC_N(arenas_lock)\n+#define\tarenas_tls JEMALLOC_N(arenas_tls)\n+#define\tarenas_tsd JEMALLOC_N(arenas_tsd)\n+#define\tarenas_tsd_boot JEMALLOC_N(arenas_tsd_boot)\n+#define\tarenas_tsd_cleanup_wrapper JEMALLOC_N(arenas_tsd_cleanup_wrapper)\n+#define\tarenas_tsd_get JEMALLOC_N(arenas_tsd_get)\n+#define\tarenas_tsd_get_wrapper JEMALLOC_N(arenas_tsd_get_wrapper)\n+#define\tarenas_tsd_set JEMALLOC_N(arenas_tsd_set)\n+#define\tatomic_add_u JEMALLOC_N(atomic_add_u)\n+#define\tatomic_add_uint32 JEMALLOC_N(atomic_add_uint32)\n+#define\tatomic_add_uint64 JEMALLOC_N(atomic_add_uint64)\n+#define\tatomic_add_z JEMALLOC_N(atomic_add_z)\n+#define\tatomic_sub_u JEMALLOC_N(atomic_sub_u)\n+#define\tatomic_sub_uint32 JEMALLOC_N(atomic_sub_uint32)\n+#define\tatomic_sub_uint64 JEMALLOC_N(atomic_sub_uint64)\n+#define\tatomic_sub_z JEMALLOC_N(atomic_sub_z)\n+#define\tbase_alloc JEMALLOC_N(base_alloc)\n+#define\tbase_boot JEMALLOC_N(base_boot)\n+#define\tbase_calloc JEMALLOC_N(base_calloc)\n+#define\tbase_node_alloc JEMALLOC_N(base_node_alloc)\n+#define\tbase_node_dealloc JEMALLOC_N(base_node_dealloc)\n+#define\tbase_postfork_child JEMALLOC_N(base_postfork_child)\n+#define\tbase_postfork_parent JEMALLOC_N(base_postfork_parent)\n+#define\tbase_prefork JEMALLOC_N(base_prefork)\n+#define\tbitmap_full JEMALLOC_N(bitmap_full)\n+#define\tbitmap_get JEMALLOC_N(bitmap_get)\n+#define\tbitmap_info_init JEMALLOC_N(bitmap_info_init)\n+#define\tbitmap_info_ngroups JEMALLOC_N(bitmap_info_ngroups)\n+#define\tbitmap_init JEMALLOC_N(bitmap_init)\n+#define\tbitmap_set JEMALLOC_N(bitmap_set)\n+#define\tbitmap_sfu JEMALLOC_N(bitmap_sfu)\n+#define\tbitmap_size JEMALLOC_N(bitmap_size)\n+#define\tbitmap_unset JEMALLOC_N(bitmap_unset)\n+#define\tbt_init JEMALLOC_N(bt_init)\n+#define\tbuferror JEMALLOC_N(buferror)\n+#define\tchoose_arena JEMALLOC_N(choose_arena)\n+#define\tchoose_arena_hard JEMALLOC_N(choose_arena_hard)\n+#define\tchunk_alloc JEMALLOC_N(chunk_alloc)\n+#define\tchunk_alloc_dss JEMALLOC_N(chunk_alloc_dss)\n+#define\tchunk_alloc_mmap JEMALLOC_N(chunk_alloc_mmap)\n+#define\tchunk_boot JEMALLOC_N(chunk_boot)\n+#define\tchunk_dealloc JEMALLOC_N(chunk_dealloc)\n+#define\tchunk_dealloc_mmap JEMALLOC_N(chunk_dealloc_mmap)\n+#define\tchunk_dss_boot JEMALLOC_N(chunk_dss_boot)\n+#define\tchunk_dss_postfork_child JEMALLOC_N(chunk_dss_postfork_child)\n+#define\tchunk_dss_postfork_parent JEMALLOC_N(chunk_dss_postfork_parent)\n+#define\tchunk_dss_prec_get JEMALLOC_N(chunk_dss_prec_get)\n+#define\tchunk_dss_prec_set JEMALLOC_N(chunk_dss_prec_set)\n+#define\tchunk_dss_prefork JEMALLOC_N(chunk_dss_prefork)\n+#define\tchunk_in_dss JEMALLOC_N(chunk_in_dss)\n+#define\tchunk_npages JEMALLOC_N(chunk_npages)\n+#define\tchunk_postfork_child JEMALLOC_N(chunk_postfork_child)\n+#define\tchunk_postfork_parent JEMALLOC_N(chunk_postfork_parent)\n+#define\tchunk_prefork JEMALLOC_N(chunk_prefork)\n+#define\tchunk_unmap JEMALLOC_N(chunk_unmap)\n+#define\tchunks_mtx JEMALLOC_N(chunks_mtx)\n+#define\tchunks_rtree JEMALLOC_N(chunks_rtree)\n+#define\tchunksize JEMALLOC_N(chunksize)\n+#define\tchunksize_mask JEMALLOC_N(chunksize_mask)\n+#define\tckh_bucket_search JEMALLOC_N(ckh_bucket_search)\n+#define\tckh_count JEMALLOC_N(ckh_count)\n+#define\tckh_delete JEMALLOC_N(ckh_delete)\n+#define\tckh_evict_reloc_insert JEMALLOC_N(ckh_evict_reloc_insert)\n+#define\tckh_insert JEMALLOC_N(ckh_insert)\n+#define\tckh_isearch JEMALLOC_N(ckh_isearch)\n+#define\tckh_iter JEMALLOC_N(ckh_iter)\n+#define\tckh_new JEMALLOC_N(ckh_new)\n+#define\tckh_pointer_hash JEMALLOC_N(ckh_pointer_hash)\n+#define\tckh_pointer_keycomp JEMALLOC_N(ckh_pointer_keycomp)\n+#define\tckh_rebuild JEMALLOC_N(ckh_rebuild)\n+#define\tckh_remove JEMALLOC_N(ckh_remove)\n+#define\tckh_search JEMALLOC_N(ckh_search)\n+#define\tckh_string_hash JEMALLOC_N(ckh_string_hash)\n+#define\tckh_string_keycomp JEMALLOC_N(ckh_string_keycomp)\n+#define\tckh_try_bucket_insert JEMALLOC_N(ckh_try_bucket_insert)\n+#define\tckh_try_insert JEMALLOC_N(ckh_try_insert)\n+#define\tctl_boot JEMALLOC_N(ctl_boot)\n+#define\tctl_bymib JEMALLOC_N(ctl_bymib)\n+#define\tctl_byname JEMALLOC_N(ctl_byname)\n+#define\tctl_nametomib JEMALLOC_N(ctl_nametomib)\n+#define\tctl_postfork_child JEMALLOC_N(ctl_postfork_child)\n+#define\tctl_postfork_parent JEMALLOC_N(ctl_postfork_parent)\n+#define\tctl_prefork JEMALLOC_N(ctl_prefork)\n+#define\tdss_prec_names JEMALLOC_N(dss_prec_names)\n+#define\textent_tree_ad_first JEMALLOC_N(extent_tree_ad_first)\n+#define\textent_tree_ad_insert JEMALLOC_N(extent_tree_ad_insert)\n+#define\textent_tree_ad_iter JEMALLOC_N(extent_tree_ad_iter)\n+#define\textent_tree_ad_iter_recurse JEMALLOC_N(extent_tree_ad_iter_recurse)\n+#define\textent_tree_ad_iter_start JEMALLOC_N(extent_tree_ad_iter_start)\n+#define\textent_tree_ad_last JEMALLOC_N(extent_tree_ad_last)\n+#define\textent_tree_ad_new JEMALLOC_N(extent_tree_ad_new)\n+#define\textent_tree_ad_next JEMALLOC_N(extent_tree_ad_next)\n+#define\textent_tree_ad_nsearch JEMALLOC_N(extent_tree_ad_nsearch)\n+#define\textent_tree_ad_prev JEMALLOC_N(extent_tree_ad_prev)\n+#define\textent_tree_ad_psearch JEMALLOC_N(extent_tree_ad_psearch)\n+#define\textent_tree_ad_remove JEMALLOC_N(extent_tree_ad_remove)\n+#define\textent_tree_ad_reverse_iter JEMALLOC_N(extent_tree_ad_reverse_iter)\n+#define\textent_tree_ad_reverse_iter_recurse JEMALLOC_N(extent_tree_ad_reverse_iter_recurse)\n+#define\textent_tree_ad_reverse_iter_start JEMALLOC_N(extent_tree_ad_reverse_iter_start)\n+#define\textent_tree_ad_search JEMALLOC_N(extent_tree_ad_search)\n+#define\textent_tree_szad_first JEMALLOC_N(extent_tree_szad_first)\n+#define\textent_tree_szad_insert JEMALLOC_N(extent_tree_szad_insert)\n+#define\textent_tree_szad_iter JEMALLOC_N(extent_tree_szad_iter)\n+#define\textent_tree_szad_iter_recurse JEMALLOC_N(extent_tree_szad_iter_recurse)\n+#define\textent_tree_szad_iter_start JEMALLOC_N(extent_tree_szad_iter_start)\n+#define\textent_tree_szad_last JEMALLOC_N(extent_tree_szad_last)\n+#define\textent_tree_szad_new JEMALLOC_N(extent_tree_szad_new)\n+#define\textent_tree_szad_next JEMALLOC_N(extent_tree_szad_next)\n+#define\textent_tree_szad_nsearch JEMALLOC_N(extent_tree_szad_nsearch)\n+#define\textent_tree_szad_prev JEMALLOC_N(extent_tree_szad_prev)\n+#define\textent_tree_szad_psearch JEMALLOC_N(extent_tree_szad_psearch)\n+#define\textent_tree_szad_remove JEMALLOC_N(extent_tree_szad_remove)\n+#define\textent_tree_szad_reverse_iter JEMALLOC_N(extent_tree_szad_reverse_iter)\n+#define\textent_tree_szad_reverse_iter_recurse JEMALLOC_N(extent_tree_szad_reverse_iter_recurse)\n+#define\textent_tree_szad_reverse_iter_start JEMALLOC_N(extent_tree_szad_reverse_iter_start)\n+#define\textent_tree_szad_search JEMALLOC_N(extent_tree_szad_search)\n+#define\tget_errno JEMALLOC_N(get_errno)\n+#define\thash JEMALLOC_N(hash)\n+#define\thash_fmix_32 JEMALLOC_N(hash_fmix_32)\n+#define\thash_fmix_64 JEMALLOC_N(hash_fmix_64)\n+#define\thash_get_block_32 JEMALLOC_N(hash_get_block_32)\n+#define\thash_get_block_64 JEMALLOC_N(hash_get_block_64)\n+#define\thash_rotl_32 JEMALLOC_N(hash_rotl_32)\n+#define\thash_rotl_64 JEMALLOC_N(hash_rotl_64)\n+#define\thash_x64_128 JEMALLOC_N(hash_x64_128)\n+#define\thash_x86_128 JEMALLOC_N(hash_x86_128)\n+#define\thash_x86_32 JEMALLOC_N(hash_x86_32)\n+#define\thuge_allocated JEMALLOC_N(huge_allocated)\n+#define\thuge_boot JEMALLOC_N(huge_boot)\n+#define\thuge_dalloc JEMALLOC_N(huge_dalloc)\n+#define\thuge_malloc JEMALLOC_N(huge_malloc)\n+#define\thuge_mtx JEMALLOC_N(huge_mtx)\n+#define\thuge_ndalloc JEMALLOC_N(huge_ndalloc)\n+#define\thuge_nmalloc JEMALLOC_N(huge_nmalloc)\n+#define\thuge_palloc JEMALLOC_N(huge_palloc)\n+#define\thuge_postfork_child JEMALLOC_N(huge_postfork_child)\n+#define\thuge_postfork_parent JEMALLOC_N(huge_postfork_parent)\n+#define\thuge_prefork JEMALLOC_N(huge_prefork)\n+#define\thuge_prof_ctx_get JEMALLOC_N(huge_prof_ctx_get)\n+#define\thuge_prof_ctx_set JEMALLOC_N(huge_prof_ctx_set)\n+#define\thuge_ralloc JEMALLOC_N(huge_ralloc)\n+#define\thuge_ralloc_no_move JEMALLOC_N(huge_ralloc_no_move)\n+#define\thuge_salloc JEMALLOC_N(huge_salloc)\n+#define\tiallocm JEMALLOC_N(iallocm)\n+#define\ticalloc JEMALLOC_N(icalloc)\n+#define\ticallocx JEMALLOC_N(icallocx)\n+#define\tidalloc JEMALLOC_N(idalloc)\n+#define\tidallocx JEMALLOC_N(idallocx)\n+#define\timalloc JEMALLOC_N(imalloc)\n+#define\timallocx JEMALLOC_N(imallocx)\n+#define\tipalloc JEMALLOC_N(ipalloc)\n+#define\tipallocx JEMALLOC_N(ipallocx)\n+#define\tiqalloc JEMALLOC_N(iqalloc)\n+#define\tiqallocx JEMALLOC_N(iqallocx)\n+#define\tiralloc JEMALLOC_N(iralloc)\n+#define\tirallocx JEMALLOC_N(irallocx)\n+#define\tisalloc JEMALLOC_N(isalloc)\n+#define\tisthreaded JEMALLOC_N(isthreaded)\n+#define\tivsalloc JEMALLOC_N(ivsalloc)\n+#define\tjemalloc_postfork_child JEMALLOC_N(jemalloc_postfork_child)\n+#define\tjemalloc_postfork_parent JEMALLOC_N(jemalloc_postfork_parent)\n+#define\tjemalloc_prefork JEMALLOC_N(jemalloc_prefork)\n+#define\tmalloc_cprintf JEMALLOC_N(malloc_cprintf)\n+#define\tmalloc_mutex_init JEMALLOC_N(malloc_mutex_init)\n+#define\tmalloc_mutex_lock JEMALLOC_N(malloc_mutex_lock)\n+#define\tmalloc_mutex_postfork_child JEMALLOC_N(malloc_mutex_postfork_child)\n+#define\tmalloc_mutex_postfork_parent JEMALLOC_N(malloc_mutex_postfork_parent)\n+#define\tmalloc_mutex_prefork JEMALLOC_N(malloc_mutex_prefork)\n+#define\tmalloc_mutex_unlock JEMALLOC_N(malloc_mutex_unlock)\n+#define\tmalloc_printf JEMALLOC_N(malloc_printf)\n+#define\tmalloc_snprintf JEMALLOC_N(malloc_snprintf)\n+#define\tmalloc_strtoumax JEMALLOC_N(malloc_strtoumax)\n+#define\tmalloc_tsd_boot JEMALLOC_N(malloc_tsd_boot)\n+#define\tmalloc_tsd_cleanup_register JEMALLOC_N(malloc_tsd_cleanup_register)\n+#define\tmalloc_tsd_dalloc JEMALLOC_N(malloc_tsd_dalloc)\n+#define\tmalloc_tsd_malloc JEMALLOC_N(malloc_tsd_malloc)\n+#define\tmalloc_tsd_no_cleanup JEMALLOC_N(malloc_tsd_no_cleanup)\n+#define\tmalloc_vcprintf JEMALLOC_N(malloc_vcprintf)\n+#define\tmalloc_vsnprintf JEMALLOC_N(malloc_vsnprintf)\n+#define\tmalloc_write JEMALLOC_N(malloc_write)\n+#define\tmap_bias JEMALLOC_N(map_bias)\n+#define\tmb_write JEMALLOC_N(mb_write)\n+#define\tmutex_boot JEMALLOC_N(mutex_boot)\n+#define\tnarenas_auto JEMALLOC_N(narenas_auto)\n+#define\tnarenas_total JEMALLOC_N(narenas_total)\n+#define\tnarenas_total_get JEMALLOC_N(narenas_total_get)\n+#define\tncpus JEMALLOC_N(ncpus)\n+#define\tnhbins JEMALLOC_N(nhbins)\n+#define\topt_abort JEMALLOC_N(opt_abort)\n+#define\topt_junk JEMALLOC_N(opt_junk)\n+#define\topt_lg_chunk JEMALLOC_N(opt_lg_chunk)\n+#define\topt_lg_dirty_mult JEMALLOC_N(opt_lg_dirty_mult)\n+#define\topt_lg_prof_interval JEMALLOC_N(opt_lg_prof_interval)\n+#define\topt_lg_prof_sample JEMALLOC_N(opt_lg_prof_sample)\n+#define\topt_lg_tcache_max JEMALLOC_N(opt_lg_tcache_max)\n+#define\topt_narenas JEMALLOC_N(opt_narenas)\n+#define\topt_prof JEMALLOC_N(opt_prof)\n+#define\topt_prof_accum JEMALLOC_N(opt_prof_accum)\n+#define\topt_prof_active JEMALLOC_N(opt_prof_active)\n+#define\topt_prof_final JEMALLOC_N(opt_prof_final)\n+#define\topt_prof_gdump JEMALLOC_N(opt_prof_gdump)\n+#define\topt_prof_leak JEMALLOC_N(opt_prof_leak)\n+#define\topt_prof_prefix JEMALLOC_N(opt_prof_prefix)\n+#define\topt_quarantine JEMALLOC_N(opt_quarantine)\n+#define\topt_redzone JEMALLOC_N(opt_redzone)\n+#define\topt_stats_print JEMALLOC_N(opt_stats_print)\n+#define\topt_tcache JEMALLOC_N(opt_tcache)\n+#define\topt_utrace JEMALLOC_N(opt_utrace)\n+#define\topt_valgrind JEMALLOC_N(opt_valgrind)\n+#define\topt_xmalloc JEMALLOC_N(opt_xmalloc)\n+#define\topt_zero JEMALLOC_N(opt_zero)\n+#define\tp2rz JEMALLOC_N(p2rz)\n+#define\tpages_purge JEMALLOC_N(pages_purge)\n+#define\tpow2_ceil JEMALLOC_N(pow2_ceil)\n+#define\tprof_backtrace JEMALLOC_N(prof_backtrace)\n+#define\tprof_boot0 JEMALLOC_N(prof_boot0)\n+#define\tprof_boot1 JEMALLOC_N(prof_boot1)\n+#define\tprof_boot2 JEMALLOC_N(prof_boot2)\n+#define\tprof_ctx_get JEMALLOC_N(prof_ctx_get)\n+#define\tprof_ctx_set JEMALLOC_N(prof_ctx_set)\n+#define\tprof_free JEMALLOC_N(prof_free)\n+#define\tprof_gdump JEMALLOC_N(prof_gdump)\n+#define\tprof_idump JEMALLOC_N(prof_idump)\n+#define\tprof_interval JEMALLOC_N(prof_interval)\n+#define\tprof_lookup JEMALLOC_N(prof_lookup)\n+#define\tprof_malloc JEMALLOC_N(prof_malloc)\n+#define\tprof_mdump JEMALLOC_N(prof_mdump)\n+#define\tprof_postfork_child JEMALLOC_N(prof_postfork_child)\n+#define\tprof_postfork_parent JEMALLOC_N(prof_postfork_parent)\n+#define\tprof_prefork JEMALLOC_N(prof_prefork)\n+#define\tprof_promote JEMALLOC_N(prof_promote)\n+#define\tprof_realloc JEMALLOC_N(prof_realloc)\n+#define\tprof_sample_accum_update JEMALLOC_N(prof_sample_accum_update)\n+#define\tprof_sample_threshold_update JEMALLOC_N(prof_sample_threshold_update)\n+#define\tprof_tdata_booted JEMALLOC_N(prof_tdata_booted)\n+#define\tprof_tdata_cleanup JEMALLOC_N(prof_tdata_cleanup)\n+#define\tprof_tdata_get JEMALLOC_N(prof_tdata_get)\n+#define\tprof_tdata_init JEMALLOC_N(prof_tdata_init)\n+#define\tprof_tdata_initialized JEMALLOC_N(prof_tdata_initialized)\n+#define\tprof_tdata_tls JEMALLOC_N(prof_tdata_tls)\n+#define\tprof_tdata_tsd JEMALLOC_N(prof_tdata_tsd)\n+#define\tprof_tdata_tsd_boot JEMALLOC_N(prof_tdata_tsd_boot)\n+#define\tprof_tdata_tsd_cleanup_wrapper JEMALLOC_N(prof_tdata_tsd_cleanup_wrapper)\n+#define\tprof_tdata_tsd_get JEMALLOC_N(prof_tdata_tsd_get)\n+#define\tprof_tdata_tsd_get_wrapper JEMALLOC_N(prof_tdata_tsd_get_wrapper)\n+#define\tprof_tdata_tsd_set JEMALLOC_N(prof_tdata_tsd_set)\n+#define\tquarantine JEMALLOC_N(quarantine)\n+#define\tquarantine_alloc_hook JEMALLOC_N(quarantine_alloc_hook)\n+#define\tquarantine_boot JEMALLOC_N(quarantine_boot)\n+#define\tquarantine_booted JEMALLOC_N(quarantine_booted)\n+#define\tquarantine_cleanup JEMALLOC_N(quarantine_cleanup)\n+#define\tquarantine_init JEMALLOC_N(quarantine_init)\n+#define\tquarantine_tls JEMALLOC_N(quarantine_tls)\n+#define\tquarantine_tsd JEMALLOC_N(quarantine_tsd)\n+#define\tquarantine_tsd_boot JEMALLOC_N(quarantine_tsd_boot)\n+#define\tquarantine_tsd_cleanup_wrapper JEMALLOC_N(quarantine_tsd_cleanup_wrapper)\n+#define\tquarantine_tsd_get JEMALLOC_N(quarantine_tsd_get)\n+#define\tquarantine_tsd_get_wrapper JEMALLOC_N(quarantine_tsd_get_wrapper)\n+#define\tquarantine_tsd_set JEMALLOC_N(quarantine_tsd_set)\n+#define\tregister_zone JEMALLOC_N(register_zone)\n+#define\trtree_get JEMALLOC_N(rtree_get)\n+#define\trtree_get_locked JEMALLOC_N(rtree_get_locked)\n+#define\trtree_new JEMALLOC_N(rtree_new)\n+#define\trtree_postfork_child JEMALLOC_N(rtree_postfork_child)\n+#define\trtree_postfork_parent JEMALLOC_N(rtree_postfork_parent)\n+#define\trtree_prefork JEMALLOC_N(rtree_prefork)\n+#define\trtree_set JEMALLOC_N(rtree_set)\n+#define\ts2u JEMALLOC_N(s2u)\n+#define\tsa2u JEMALLOC_N(sa2u)\n+#define\tset_errno JEMALLOC_N(set_errno)\n+#define\tstats_cactive JEMALLOC_N(stats_cactive)\n+#define\tstats_cactive_add JEMALLOC_N(stats_cactive_add)\n+#define\tstats_cactive_get JEMALLOC_N(stats_cactive_get)\n+#define\tstats_cactive_sub JEMALLOC_N(stats_cactive_sub)\n+#define\tstats_chunks JEMALLOC_N(stats_chunks)\n+#define\tstats_print JEMALLOC_N(stats_print)\n+#define\ttcache_alloc_easy JEMALLOC_N(tcache_alloc_easy)\n+#define\ttcache_alloc_large JEMALLOC_N(tcache_alloc_large)\n+#define\ttcache_alloc_small JEMALLOC_N(tcache_alloc_small)\n+#define\ttcache_alloc_small_hard JEMALLOC_N(tcache_alloc_small_hard)\n+#define\ttcache_arena_associate JEMALLOC_N(tcache_arena_associate)\n+#define\ttcache_arena_dissociate JEMALLOC_N(tcache_arena_dissociate)\n+#define\ttcache_bin_flush_large JEMALLOC_N(tcache_bin_flush_large)\n+#define\ttcache_bin_flush_small JEMALLOC_N(tcache_bin_flush_small)\n+#define\ttcache_bin_info JEMALLOC_N(tcache_bin_info)\n+#define\ttcache_boot0 JEMALLOC_N(tcache_boot0)\n+#define\ttcache_boot1 JEMALLOC_N(tcache_boot1)\n+#define\ttcache_booted JEMALLOC_N(tcache_booted)\n+#define\ttcache_create JEMALLOC_N(tcache_create)\n+#define\ttcache_dalloc_large JEMALLOC_N(tcache_dalloc_large)\n+#define\ttcache_dalloc_small JEMALLOC_N(tcache_dalloc_small)\n+#define\ttcache_destroy JEMALLOC_N(tcache_destroy)\n+#define\ttcache_enabled_booted JEMALLOC_N(tcache_enabled_booted)\n+#define\ttcache_enabled_get JEMALLOC_N(tcache_enabled_get)\n+#define\ttcache_enabled_initialized JEMALLOC_N(tcache_enabled_initialized)\n+#define\ttcache_enabled_set JEMALLOC_N(tcache_enabled_set)\n+#define\ttcache_enabled_tls JEMALLOC_N(tcache_enabled_tls)\n+#define\ttcache_enabled_tsd JEMALLOC_N(tcache_enabled_tsd)\n+#define\ttcache_enabled_tsd_boot JEMALLOC_N(tcache_enabled_tsd_boot)\n+#define\ttcache_enabled_tsd_cleanup_wrapper JEMALLOC_N(tcache_enabled_tsd_cleanup_wrapper)\n+#define\ttcache_enabled_tsd_get JEMALLOC_N(tcache_enabled_tsd_get)\n+#define\ttcache_enabled_tsd_get_wrapper JEMALLOC_N(tcache_enabled_tsd_get_wrapper)\n+#define\ttcache_enabled_tsd_set JEMALLOC_N(tcache_enabled_tsd_set)\n+#define\ttcache_event JEMALLOC_N(tcache_event)\n+#define\ttcache_event_hard JEMALLOC_N(tcache_event_hard)\n+#define\ttcache_flush JEMALLOC_N(tcache_flush)\n+#define\ttcache_get JEMALLOC_N(tcache_get)\n+#define\ttcache_initialized JEMALLOC_N(tcache_initialized)\n+#define\ttcache_maxclass JEMALLOC_N(tcache_maxclass)\n+#define\ttcache_salloc JEMALLOC_N(tcache_salloc)\n+#define\ttcache_stats_merge JEMALLOC_N(tcache_stats_merge)\n+#define\ttcache_thread_cleanup JEMALLOC_N(tcache_thread_cleanup)\n+#define\ttcache_tls JEMALLOC_N(tcache_tls)\n+#define\ttcache_tsd JEMALLOC_N(tcache_tsd)\n+#define\ttcache_tsd_boot JEMALLOC_N(tcache_tsd_boot)\n+#define\ttcache_tsd_cleanup_wrapper JEMALLOC_N(tcache_tsd_cleanup_wrapper)\n+#define\ttcache_tsd_get JEMALLOC_N(tcache_tsd_get)\n+#define\ttcache_tsd_get_wrapper JEMALLOC_N(tcache_tsd_get_wrapper)\n+#define\ttcache_tsd_set JEMALLOC_N(tcache_tsd_set)\n+#define\tthread_allocated_booted JEMALLOC_N(thread_allocated_booted)\n+#define\tthread_allocated_initialized JEMALLOC_N(thread_allocated_initialized)\n+#define\tthread_allocated_tls JEMALLOC_N(thread_allocated_tls)\n+#define\tthread_allocated_tsd JEMALLOC_N(thread_allocated_tsd)\n+#define\tthread_allocated_tsd_boot JEMALLOC_N(thread_allocated_tsd_boot)\n+#define\tthread_allocated_tsd_cleanup_wrapper JEMALLOC_N(thread_allocated_tsd_cleanup_wrapper)\n+#define\tthread_allocated_tsd_get JEMALLOC_N(thread_allocated_tsd_get)\n+#define\tthread_allocated_tsd_get_wrapper JEMALLOC_N(thread_allocated_tsd_get_wrapper)\n+#define\tthread_allocated_tsd_set JEMALLOC_N(thread_allocated_tsd_set)\n+#define\tu2rz JEMALLOC_N(u2rz)"}, {"sha": "89fbfa9535f2c2f603c2390c1dab780d3ce474a2", "filename": "src/rt/jemalloc/include/jemalloc/internal/prng.h", "status": "added", "additions": 60, "deletions": 0, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprng.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprng.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprng.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,60 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+/*\n+ * Simple linear congruential pseudo-random number generator:\n+ *\n+ *   prng(y) = (a*x + c) % m\n+ *\n+ * where the following constants ensure maximal period:\n+ *\n+ *   a == Odd number (relatively prime to 2^n), and (a-1) is a multiple of 4.\n+ *   c == Odd number (relatively prime to 2^n).\n+ *   m == 2^32\n+ *\n+ * See Knuth's TAOCP 3rd Ed., Vol. 2, pg. 17 for details on these constraints.\n+ *\n+ * This choice of m has the disadvantage that the quality of the bits is\n+ * proportional to bit position.  For example. the lowest bit has a cycle of 2,\n+ * the next has a cycle of 4, etc.  For this reason, we prefer to use the upper\n+ * bits.\n+ *\n+ * Macro parameters:\n+ *   uint32_t r          : Result.\n+ *   unsigned lg_range   : (0..32], number of least significant bits to return.\n+ *   uint32_t state      : Seed value.\n+ *   const uint32_t a, c : See above discussion.\n+ */\n+#define prng32(r, lg_range, state, a, c) do {\t\t\t\t\\\n+    assert(lg_range > 0);\t\t\t\t\t\t\\\n+    assert(lg_range <= 32);\t\t\t\t\t\t\\\n+                                    \\\n+    r = (state * (a)) + (c);\t\t\t\t\t\\\n+    state = r;\t\t\t\t\t\t\t\\\n+    r >>= (32 - lg_range);\t\t\t\t\t\t\\\n+} while (false)\n+\n+/* Same as prng32(), but 64 bits of pseudo-randomness, using uint64_t. */\n+#define prng64(r, lg_range, state, a, c) do {\t\t\t\t\\\n+    assert(lg_range > 0);\t\t\t\t\t\t\\\n+    assert(lg_range <= 64);\t\t\t\t\t\t\\\n+                                    \\\n+    r = (state * (a)) + (c);\t\t\t\t\t\\\n+    state = r;\t\t\t\t\t\t\t\\\n+    r >>= (64 - lg_range);\t\t\t\t\t\t\\\n+} while (false)\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "2c4576f97e343b73a1226a387e5c5345e3ac6f76", "filename": "src/rt/jemalloc/include/jemalloc/internal/prof.h", "status": "added", "additions": 579, "deletions": 0, "changes": 579, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprof.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprof.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fprof.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,579 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct prof_bt_s prof_bt_t;\n+typedef struct prof_cnt_s prof_cnt_t;\n+typedef struct prof_thr_cnt_s prof_thr_cnt_t;\n+typedef struct prof_ctx_s prof_ctx_t;\n+typedef struct prof_tdata_s prof_tdata_t;\n+\n+/* Option defaults. */\n+#define\tPROF_PREFIX_DEFAULT\t\t\"jeprof\"\n+#define\tLG_PROF_SAMPLE_DEFAULT\t\t19\n+#define\tLG_PROF_INTERVAL_DEFAULT\t-1\n+\n+/*\n+ * Hard limit on stack backtrace depth.  The version of prof_backtrace() that\n+ * is based on __builtin_return_address() necessarily has a hard-coded number\n+ * of backtrace frame handlers, and should be kept in sync with this setting.\n+ */\n+#define\tPROF_BT_MAX\t\t\t128\n+\n+/* Maximum number of backtraces to store in each per thread LRU cache. */\n+#define\tPROF_TCMAX\t\t\t1024\n+\n+/* Initial hash table size. */\n+#define\tPROF_CKH_MINITEMS\t\t64\n+\n+/* Size of memory buffer to use when writing dump files. */\n+#define\tPROF_DUMP_BUFSIZE\t\t65536\n+\n+/* Size of stack-allocated buffer used by prof_printf(). */\n+#define\tPROF_PRINTF_BUFSIZE\t\t128\n+\n+/*\n+ * Number of mutexes shared among all ctx's.  No space is allocated for these\n+ * unless profiling is enabled, so it's okay to over-provision.\n+ */\n+#define\tPROF_NCTX_LOCKS\t\t\t1024\n+\n+/*\n+ * prof_tdata pointers close to NULL are used to encode state information that\n+ * is used for cleaning up during thread shutdown.\n+ */\n+#define\tPROF_TDATA_STATE_REINCARNATED\t((prof_tdata_t *)(uintptr_t)1)\n+#define\tPROF_TDATA_STATE_PURGATORY\t((prof_tdata_t *)(uintptr_t)2)\n+#define\tPROF_TDATA_STATE_MAX\t\tPROF_TDATA_STATE_PURGATORY\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct prof_bt_s {\n+    /* Backtrace, stored as len program counters. */\n+    void\t\t**vec;\n+    unsigned\tlen;\n+};\n+\n+#ifdef JEMALLOC_PROF_LIBGCC\n+/* Data structure passed to libgcc _Unwind_Backtrace() callback functions. */\n+typedef struct {\n+    prof_bt_t\t*bt;\n+    unsigned\tnignore;\n+    unsigned\tmax;\n+} prof_unwind_data_t;\n+#endif\n+\n+struct prof_cnt_s {\n+    /*\n+     * Profiling counters.  An allocation/deallocation pair can operate on\n+     * different prof_thr_cnt_t objects that are linked into the same\n+     * prof_ctx_t cnts_ql, so it is possible for the cur* counters to go\n+     * negative.  In principle it is possible for the *bytes counters to\n+     * overflow/underflow, but a general solution would require something\n+     * like 128-bit counters; this implementation doesn't bother to solve\n+     * that problem.\n+     */\n+    int64_t\t\tcurobjs;\n+    int64_t\t\tcurbytes;\n+    uint64_t\taccumobjs;\n+    uint64_t\taccumbytes;\n+};\n+\n+struct prof_thr_cnt_s {\n+    /* Linkage into prof_ctx_t's cnts_ql. */\n+    ql_elm(prof_thr_cnt_t)\tcnts_link;\n+\n+    /* Linkage into thread's LRU. */\n+    ql_elm(prof_thr_cnt_t)\tlru_link;\n+\n+    /*\n+     * Associated context.  If a thread frees an object that it did not\n+     * allocate, it is possible that the context is not cached in the\n+     * thread's hash table, in which case it must be able to look up the\n+     * context, insert a new prof_thr_cnt_t into the thread's hash table,\n+     * and link it into the prof_ctx_t's cnts_ql.\n+     */\n+    prof_ctx_t\t\t*ctx;\n+\n+    /*\n+     * Threads use memory barriers to update the counters.  Since there is\n+     * only ever one writer, the only challenge is for the reader to get a\n+     * consistent read of the counters.\n+     *\n+     * The writer uses this series of operations:\n+     *\n+     * 1) Increment epoch to an odd number.\n+     * 2) Update counters.\n+     * 3) Increment epoch to an even number.\n+     *\n+     * The reader must assure 1) that the epoch is even while it reads the\n+     * counters, and 2) that the epoch doesn't change between the time it\n+     * starts and finishes reading the counters.\n+     */\n+    unsigned\t\tepoch;\n+\n+    /* Profiling counters. */\n+    prof_cnt_t\t\tcnts;\n+};\n+\n+struct prof_ctx_s {\n+    /* Associated backtrace. */\n+    prof_bt_t\t\t*bt;\n+\n+    /* Protects nlimbo, cnt_merged, and cnts_ql. */\n+    malloc_mutex_t\t\t*lock;\n+\n+    /*\n+     * Number of threads that currently cause this ctx to be in a state of\n+     * limbo due to one of:\n+     *   - Initializing per thread counters associated with this ctx.\n+     *   - Preparing to destroy this ctx.\n+     * nlimbo must be 1 (single destroyer) in order to safely destroy the\n+     * ctx.\n+     */\n+    unsigned\t\tnlimbo;\n+\n+    /* Temporary storage for summation during dump. */\n+    prof_cnt_t\t\tcnt_summed;\n+\n+    /* When threads exit, they merge their stats into cnt_merged. */\n+    prof_cnt_t\t\tcnt_merged;\n+\n+    /*\n+     * List of profile counters, one for each thread that has allocated in\n+     * this context.\n+     */\n+    ql_head(prof_thr_cnt_t)\tcnts_ql;\n+};\n+\n+struct prof_tdata_s {\n+    /*\n+     * Hash of (prof_bt_t *)-->(prof_thr_cnt_t *).  Each thread keeps a\n+     * cache of backtraces, with associated thread-specific prof_thr_cnt_t\n+     * objects.  Other threads may read the prof_thr_cnt_t contents, but no\n+     * others will ever write them.\n+     *\n+     * Upon thread exit, the thread must merge all the prof_thr_cnt_t\n+     * counter data into the associated prof_ctx_t objects, and unlink/free\n+     * the prof_thr_cnt_t objects.\n+     */\n+    ckh_t\t\t\tbt2cnt;\n+\n+    /* LRU for contents of bt2cnt. */\n+    ql_head(prof_thr_cnt_t)\tlru_ql;\n+\n+    /* Backtrace vector, used for calls to prof_backtrace(). */\n+    void\t\t\t**vec;\n+\n+    /* Sampling state. */\n+    uint64_t\t\tprng_state;\n+    uint64_t\t\tthreshold;\n+    uint64_t\t\taccum;\n+\n+    /* State used to avoid dumping while operating on prof internals. */\n+    bool\t\t\tenq;\n+    bool\t\t\tenq_idump;\n+    bool\t\t\tenq_gdump;\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+extern bool\topt_prof;\n+/*\n+ * Even if opt_prof is true, sampling can be temporarily disabled by setting\n+ * opt_prof_active to false.  No locking is used when updating opt_prof_active,\n+ * so there are no guarantees regarding how long it will take for all threads\n+ * to notice state changes.\n+ */\n+extern bool\topt_prof_active;\n+extern size_t\topt_lg_prof_sample;   /* Mean bytes between samples. */\n+extern ssize_t\topt_lg_prof_interval; /* lg(prof_interval). */\n+extern bool\topt_prof_gdump;       /* High-water memory dumping. */\n+extern bool\topt_prof_final;       /* Final profile dumping. */\n+extern bool\topt_prof_leak;        /* Dump leak summary at exit. */\n+extern bool\topt_prof_accum;       /* Report cumulative bytes. */\n+extern char\topt_prof_prefix[PATH_MAX + 1];\n+\n+/*\n+ * Profile dump interval, measured in bytes allocated.  Each arena triggers a\n+ * profile dump when it reaches this threshold.  The effect is that the\n+ * interval between profile dumps averages prof_interval, though the actual\n+ * interval between dumps will tend to be sporadic, and the interval will be a\n+ * maximum of approximately (prof_interval * narenas).\n+ */\n+extern uint64_t\tprof_interval;\n+\n+/*\n+ * If true, promote small sampled objects to large objects, since small run\n+ * headers do not have embedded profile context pointers.\n+ */\n+extern bool\tprof_promote;\n+\n+void\tbt_init(prof_bt_t *bt, void **vec);\n+void\tprof_backtrace(prof_bt_t *bt, unsigned nignore);\n+prof_thr_cnt_t\t*prof_lookup(prof_bt_t *bt);\n+void\tprof_idump(void);\n+bool\tprof_mdump(const char *filename);\n+void\tprof_gdump(void);\n+prof_tdata_t\t*prof_tdata_init(void);\n+void\tprof_tdata_cleanup(void *arg);\n+void\tprof_boot0(void);\n+void\tprof_boot1(void);\n+bool\tprof_boot2(void);\n+void\tprof_prefork(void);\n+void\tprof_postfork_parent(void);\n+void\tprof_postfork_child(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#define\tPROF_ALLOC_PREP(nignore, size, ret) do {\t\t\t\\\n+    prof_tdata_t *prof_tdata;\t\t\t\t\t\\\n+    prof_bt_t bt;\t\t\t\t\t\t\t\\\n+                                    \\\n+    assert(size == s2u(size));\t\t\t\t\t\\\n+                                    \\\n+    prof_tdata = prof_tdata_get(true);\t\t\t\t\\\n+    if ((uintptr_t)prof_tdata <= (uintptr_t)PROF_TDATA_STATE_MAX) {\t\\\n+        if (prof_tdata != NULL)\t\t\t\t\t\\\n+            ret = (prof_thr_cnt_t *)(uintptr_t)1U;\t\t\\\n+        else\t\t\t\t\t\t\t\\\n+            ret = NULL;\t\t\t\t\t\\\n+        break;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    if (opt_prof_active == false) {\t\t\t\t\t\\\n+        /* Sampling is currently inactive, so avoid sampling. */\\\n+        ret = (prof_thr_cnt_t *)(uintptr_t)1U;\t\t\t\\\n+    } else if (opt_lg_prof_sample == 0) {\t\t\t\t\\\n+        /* Don't bother with sampling logic, since sampling   */\\\n+        /* interval is 1.                                     */\\\n+        bt_init(&bt, prof_tdata->vec);\t\t\t\t\\\n+        prof_backtrace(&bt, nignore);\t\t\t\t\\\n+        ret = prof_lookup(&bt);\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        if (prof_tdata->threshold == 0) {\t\t\t\\\n+            /* Initialize.  Seed the prng differently for */\\\n+            /* each thread.                               */\\\n+            prof_tdata->prng_state =\t\t\t\\\n+                (uint64_t)(uintptr_t)&size;\t\t\t\\\n+            prof_sample_threshold_update(prof_tdata);\t\\\n+        }\t\t\t\t\t\t\t\\\n+                                    \\\n+        /* Determine whether to capture a backtrace based on  */\\\n+        /* whether size is enough for prof_accum to reach     */\\\n+        /* prof_tdata->threshold.  However, delay updating    */\\\n+        /* these variables until prof_{m,re}alloc(), because  */\\\n+        /* we don't know for sure that the allocation will    */\\\n+        /* succeed.                                           */\\\n+        /*                                                    */\\\n+        /* Use subtraction rather than addition to avoid      */\\\n+        /* potential integer overflow.                        */\\\n+        if (size >= prof_tdata->threshold -\t\t\t\\\n+            prof_tdata->accum) {\t\t\t\t\\\n+            bt_init(&bt, prof_tdata->vec);\t\t\t\\\n+            prof_backtrace(&bt, nignore);\t\t\t\\\n+            ret = prof_lookup(&bt);\t\t\t\t\\\n+        } else\t\t\t\t\t\t\t\\\n+            ret = (prof_thr_cnt_t *)(uintptr_t)1U;\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+malloc_tsd_protos(JEMALLOC_ATTR(unused), prof_tdata, prof_tdata_t *)\n+\n+prof_tdata_t\t*prof_tdata_get(bool create);\n+void\tprof_sample_threshold_update(prof_tdata_t *prof_tdata);\n+prof_ctx_t\t*prof_ctx_get(const void *ptr);\n+void\tprof_ctx_set(const void *ptr, prof_ctx_t *ctx);\n+bool\tprof_sample_accum_update(size_t size);\n+void\tprof_malloc(const void *ptr, size_t size, prof_thr_cnt_t *cnt);\n+void\tprof_realloc(const void *ptr, size_t size, prof_thr_cnt_t *cnt,\n+    size_t old_size, prof_ctx_t *old_ctx);\n+void\tprof_free(const void *ptr, size_t size);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_PROF_C_))\n+/* Thread-specific backtrace cache, used to reduce bt2ctx contention. */\n+malloc_tsd_externs(prof_tdata, prof_tdata_t *)\n+malloc_tsd_funcs(JEMALLOC_INLINE, prof_tdata, prof_tdata_t *, NULL,\n+    prof_tdata_cleanup)\n+\n+JEMALLOC_INLINE prof_tdata_t *\n+prof_tdata_get(bool create)\n+{\n+    prof_tdata_t *prof_tdata;\n+\n+    cassert(config_prof);\n+\n+    prof_tdata = *prof_tdata_tsd_get();\n+    if (create && prof_tdata == NULL)\n+        prof_tdata = prof_tdata_init();\n+\n+    return (prof_tdata);\n+}\n+\n+JEMALLOC_INLINE void\n+prof_sample_threshold_update(prof_tdata_t *prof_tdata)\n+{\n+    uint64_t r;\n+    double u;\n+\n+    cassert(config_prof);\n+\n+    /*\n+     * Compute sample threshold as a geometrically distributed random\n+     * variable with mean (2^opt_lg_prof_sample).\n+     *\n+     *                         __        __\n+     *                         |  log(u)  |                     1\n+     * prof_tdata->threshold = | -------- |, where p = -------------------\n+     *                         | log(1-p) |             opt_lg_prof_sample\n+     *                                                 2\n+     *\n+     * For more information on the math, see:\n+     *\n+     *   Non-Uniform Random Variate Generation\n+     *   Luc Devroye\n+     *   Springer-Verlag, New York, 1986\n+     *   pp 500\n+     *   (http://cg.scs.carleton.ca/~luc/rnbookindex.html)\n+     */\n+    prng64(r, 53, prof_tdata->prng_state,\n+        UINT64_C(6364136223846793005), UINT64_C(1442695040888963407));\n+    u = (double)r * (1.0/9007199254740992.0L);\n+    prof_tdata->threshold = (uint64_t)(log(u) /\n+        log(1.0 - (1.0 / (double)((uint64_t)1U << opt_lg_prof_sample))))\n+        + (uint64_t)1U;\n+}\n+\n+JEMALLOC_INLINE prof_ctx_t *\n+prof_ctx_get(const void *ptr)\n+{\n+    prof_ctx_t *ret;\n+    arena_chunk_t *chunk;\n+\n+    cassert(config_prof);\n+    assert(ptr != NULL);\n+\n+    chunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+    if (chunk != ptr) {\n+        /* Region. */\n+        ret = arena_prof_ctx_get(ptr);\n+    } else\n+        ret = huge_prof_ctx_get(ptr);\n+\n+    return (ret);\n+}\n+\n+JEMALLOC_INLINE void\n+prof_ctx_set(const void *ptr, prof_ctx_t *ctx)\n+{\n+    arena_chunk_t *chunk;\n+\n+    cassert(config_prof);\n+    assert(ptr != NULL);\n+\n+    chunk = (arena_chunk_t *)CHUNK_ADDR2BASE(ptr);\n+    if (chunk != ptr) {\n+        /* Region. */\n+        arena_prof_ctx_set(ptr, ctx);\n+    } else\n+        huge_prof_ctx_set(ptr, ctx);\n+}\n+\n+JEMALLOC_INLINE bool\n+prof_sample_accum_update(size_t size)\n+{\n+    prof_tdata_t *prof_tdata;\n+\n+    cassert(config_prof);\n+    /* Sampling logic is unnecessary if the interval is 1. */\n+    assert(opt_lg_prof_sample != 0);\n+\n+    prof_tdata = prof_tdata_get(false);\n+    if ((uintptr_t)prof_tdata <= (uintptr_t)PROF_TDATA_STATE_MAX)\n+        return (true);\n+\n+    /* Take care to avoid integer overflow. */\n+    if (size >= prof_tdata->threshold - prof_tdata->accum) {\n+        prof_tdata->accum -= (prof_tdata->threshold - size);\n+        /* Compute new sample threshold. */\n+        prof_sample_threshold_update(prof_tdata);\n+        while (prof_tdata->accum >= prof_tdata->threshold) {\n+            prof_tdata->accum -= prof_tdata->threshold;\n+            prof_sample_threshold_update(prof_tdata);\n+        }\n+        return (false);\n+    } else {\n+        prof_tdata->accum += size;\n+        return (true);\n+    }\n+}\n+\n+JEMALLOC_INLINE void\n+prof_malloc(const void *ptr, size_t size, prof_thr_cnt_t *cnt)\n+{\n+\n+    cassert(config_prof);\n+    assert(ptr != NULL);\n+    assert(size == isalloc(ptr, true));\n+\n+    if (opt_lg_prof_sample != 0) {\n+        if (prof_sample_accum_update(size)) {\n+            /*\n+             * Don't sample.  For malloc()-like allocation, it is\n+             * always possible to tell in advance how large an\n+             * object's usable size will be, so there should never\n+             * be a difference between the size passed to\n+             * PROF_ALLOC_PREP() and prof_malloc().\n+             */\n+            assert((uintptr_t)cnt == (uintptr_t)1U);\n+        }\n+    }\n+\n+    if ((uintptr_t)cnt > (uintptr_t)1U) {\n+        prof_ctx_set(ptr, cnt->ctx);\n+\n+        cnt->epoch++;\n+        /*********/\n+        mb_write();\n+        /*********/\n+        cnt->cnts.curobjs++;\n+        cnt->cnts.curbytes += size;\n+        if (opt_prof_accum) {\n+            cnt->cnts.accumobjs++;\n+            cnt->cnts.accumbytes += size;\n+        }\n+        /*********/\n+        mb_write();\n+        /*********/\n+        cnt->epoch++;\n+        /*********/\n+        mb_write();\n+        /*********/\n+    } else\n+        prof_ctx_set(ptr, (prof_ctx_t *)(uintptr_t)1U);\n+}\n+\n+JEMALLOC_INLINE void\n+prof_realloc(const void *ptr, size_t size, prof_thr_cnt_t *cnt,\n+    size_t old_size, prof_ctx_t *old_ctx)\n+{\n+    prof_thr_cnt_t *told_cnt;\n+\n+    cassert(config_prof);\n+    assert(ptr != NULL || (uintptr_t)cnt <= (uintptr_t)1U);\n+\n+    if (ptr != NULL) {\n+        assert(size == isalloc(ptr, true));\n+        if (opt_lg_prof_sample != 0) {\n+            if (prof_sample_accum_update(size)) {\n+                /*\n+                 * Don't sample.  The size passed to\n+                 * PROF_ALLOC_PREP() was larger than what\n+                 * actually got allocated, so a backtrace was\n+                 * captured for this allocation, even though\n+                 * its actual size was insufficient to cross\n+                 * the sample threshold.\n+                 */\n+                cnt = (prof_thr_cnt_t *)(uintptr_t)1U;\n+            }\n+        }\n+    }\n+\n+    if ((uintptr_t)old_ctx > (uintptr_t)1U) {\n+        told_cnt = prof_lookup(old_ctx->bt);\n+        if (told_cnt == NULL) {\n+            /*\n+             * It's too late to propagate OOM for this realloc(),\n+             * so operate directly on old_cnt->ctx->cnt_merged.\n+             */\n+            malloc_mutex_lock(old_ctx->lock);\n+            old_ctx->cnt_merged.curobjs--;\n+            old_ctx->cnt_merged.curbytes -= old_size;\n+            malloc_mutex_unlock(old_ctx->lock);\n+            told_cnt = (prof_thr_cnt_t *)(uintptr_t)1U;\n+        }\n+    } else\n+        told_cnt = (prof_thr_cnt_t *)(uintptr_t)1U;\n+\n+    if ((uintptr_t)told_cnt > (uintptr_t)1U)\n+        told_cnt->epoch++;\n+    if ((uintptr_t)cnt > (uintptr_t)1U) {\n+        prof_ctx_set(ptr, cnt->ctx);\n+        cnt->epoch++;\n+    } else if (ptr != NULL)\n+        prof_ctx_set(ptr, (prof_ctx_t *)(uintptr_t)1U);\n+    /*********/\n+    mb_write();\n+    /*********/\n+    if ((uintptr_t)told_cnt > (uintptr_t)1U) {\n+        told_cnt->cnts.curobjs--;\n+        told_cnt->cnts.curbytes -= old_size;\n+    }\n+    if ((uintptr_t)cnt > (uintptr_t)1U) {\n+        cnt->cnts.curobjs++;\n+        cnt->cnts.curbytes += size;\n+        if (opt_prof_accum) {\n+            cnt->cnts.accumobjs++;\n+            cnt->cnts.accumbytes += size;\n+        }\n+    }\n+    /*********/\n+    mb_write();\n+    /*********/\n+    if ((uintptr_t)told_cnt > (uintptr_t)1U)\n+        told_cnt->epoch++;\n+    if ((uintptr_t)cnt > (uintptr_t)1U)\n+        cnt->epoch++;\n+    /*********/\n+    mb_write(); /* Not strictly necessary. */\n+}\n+\n+JEMALLOC_INLINE void\n+prof_free(const void *ptr, size_t size)\n+{\n+    prof_ctx_t *ctx = prof_ctx_get(ptr);\n+\n+    cassert(config_prof);\n+\n+    if ((uintptr_t)ctx > (uintptr_t)1) {\n+        prof_thr_cnt_t *tcnt;\n+        assert(size == isalloc(ptr, true));\n+        tcnt = prof_lookup(ctx->bt);\n+\n+        if (tcnt != NULL) {\n+            tcnt->epoch++;\n+            /*********/\n+            mb_write();\n+            /*********/\n+            tcnt->cnts.curobjs--;\n+            tcnt->cnts.curbytes -= size;\n+            /*********/\n+            mb_write();\n+            /*********/\n+            tcnt->epoch++;\n+            /*********/\n+            mb_write();\n+            /*********/\n+        } else {\n+            /*\n+             * OOM during free() cannot be propagated, so operate\n+             * directly on cnt->ctx->cnt_merged.\n+             */\n+            malloc_mutex_lock(ctx->lock);\n+            ctx->cnt_merged.curobjs--;\n+            ctx->cnt_merged.curbytes -= size;\n+            malloc_mutex_unlock(ctx->lock);\n+        }\n+    }\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "60613379ec16bff20727022c32144ca78edaf34f", "filename": "src/rt/jemalloc/include/jemalloc/internal/ql.h", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fql.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fql.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fql.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,83 @@\n+/*\n+ * List definitions.\n+ */\n+#define ql_head(a_type)\t\t\t\t\t\t\t\\\n+struct {\t\t\t\t\t\t\t\t\\\n+    a_type *qlh_first;\t\t\t\t\t\t\\\n+}\n+\n+#define ql_head_initializer(a_head) {NULL}\n+\n+#define ql_elm(a_type)\tqr(a_type)\n+\n+/* List functions. */\n+#define ql_new(a_head) do {\t\t\t\t\t\t\\\n+    (a_head)->qlh_first = NULL;\t\t\t\t\t\\\n+} while (0)\n+\n+#define ql_elm_new(a_elm, a_field) qr_new((a_elm), a_field)\n+\n+#define ql_first(a_head) ((a_head)->qlh_first)\n+\n+#define ql_last(a_head, a_field)\t\t\t\t\t\\\n+    ((ql_first(a_head) != NULL)\t\t\t\t\t\\\n+        ? qr_prev(ql_first(a_head), a_field) : NULL)\n+\n+#define ql_next(a_head, a_elm, a_field)\t\t\t\t\t\\\n+    ((ql_last(a_head, a_field) != (a_elm))\t\t\t\t\\\n+        ? qr_next((a_elm), a_field)\t: NULL)\n+\n+#define ql_prev(a_head, a_elm, a_field)\t\t\t\t\t\\\n+    ((ql_first(a_head) != (a_elm)) ? qr_prev((a_elm), a_field)\t\\\n+                       : NULL)\n+\n+#define ql_before_insert(a_head, a_qlelm, a_elm, a_field) do {\t\t\\\n+    qr_before_insert((a_qlelm), (a_elm), a_field);\t\t\t\\\n+    if (ql_first(a_head) == (a_qlelm)) {\t\t\t\t\\\n+        ql_first(a_head) = (a_elm);\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define ql_after_insert(a_qlelm, a_elm, a_field)\t\t\t\\\n+    qr_after_insert((a_qlelm), (a_elm), a_field)\n+\n+#define ql_head_insert(a_head, a_elm, a_field) do {\t\t\t\\\n+    if (ql_first(a_head) != NULL) {\t\t\t\t\t\\\n+        qr_before_insert(ql_first(a_head), (a_elm), a_field);\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    ql_first(a_head) = (a_elm);\t\t\t\t\t\\\n+} while (0)\n+\n+#define ql_tail_insert(a_head, a_elm, a_field) do {\t\t\t\\\n+    if (ql_first(a_head) != NULL) {\t\t\t\t\t\\\n+        qr_before_insert(ql_first(a_head), (a_elm), a_field);\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    ql_first(a_head) = qr_next((a_elm), a_field);\t\t\t\\\n+} while (0)\n+\n+#define ql_remove(a_head, a_elm, a_field) do {\t\t\t\t\\\n+    if (ql_first(a_head) == (a_elm)) {\t\t\t\t\\\n+        ql_first(a_head) = qr_next(ql_first(a_head), a_field);\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    if (ql_first(a_head) != (a_elm)) {\t\t\t\t\\\n+        qr_remove((a_elm), a_field);\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        ql_first(a_head) = NULL;\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define ql_head_remove(a_head, a_type, a_field) do {\t\t\t\\\n+    a_type *t = ql_first(a_head);\t\t\t\t\t\\\n+    ql_remove((a_head), t, a_field);\t\t\t\t\\\n+} while (0)\n+\n+#define ql_tail_remove(a_head, a_type, a_field) do {\t\t\t\\\n+    a_type *t = ql_last(a_head, a_field);\t\t\t\t\\\n+    ql_remove((a_head), t, a_field);\t\t\t\t\\\n+} while (0)\n+\n+#define ql_foreach(a_var, a_head, a_field)\t\t\t\t\\\n+    qr_foreach((a_var), ql_first(a_head), a_field)\n+\n+#define ql_reverse_foreach(a_var, a_head, a_field)\t\t\t\\\n+    qr_reverse_foreach((a_var), ql_first(a_head), a_field)"}, {"sha": "f7af73e30b6d248c67034f0529aa058eecf4c79e", "filename": "src/rt/jemalloc/include/jemalloc/internal/qr.h", "status": "added", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fqr.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fqr.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fqr.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,67 @@\n+/* Ring definitions. */\n+#define qr(a_type)\t\t\t\t\t\t\t\\\n+struct {\t\t\t\t\t\t\t\t\\\n+    a_type\t*qre_next;\t\t\t\t\t\t\\\n+    a_type\t*qre_prev;\t\t\t\t\t\t\\\n+}\n+\n+/* Ring functions. */\n+#define qr_new(a_qr, a_field) do {\t\t\t\t\t\\\n+    (a_qr)->a_field.qre_next = (a_qr);\t\t\t\t\\\n+    (a_qr)->a_field.qre_prev = (a_qr);\t\t\t\t\\\n+} while (0)\n+\n+#define qr_next(a_qr, a_field) ((a_qr)->a_field.qre_next)\n+\n+#define qr_prev(a_qr, a_field) ((a_qr)->a_field.qre_prev)\n+\n+#define qr_before_insert(a_qrelm, a_qr, a_field) do {\t\t\t\\\n+    (a_qr)->a_field.qre_prev = (a_qrelm)->a_field.qre_prev;\t\t\\\n+    (a_qr)->a_field.qre_next = (a_qrelm);\t\t\t\t\\\n+    (a_qr)->a_field.qre_prev->a_field.qre_next = (a_qr);\t\t\\\n+    (a_qrelm)->a_field.qre_prev = (a_qr);\t\t\t\t\\\n+} while (0)\n+\n+#define qr_after_insert(a_qrelm, a_qr, a_field)\t\t\t\t\\\n+    do\t\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+    (a_qr)->a_field.qre_next = (a_qrelm)->a_field.qre_next;\t\t\\\n+    (a_qr)->a_field.qre_prev = (a_qrelm);\t\t\t\t\\\n+    (a_qr)->a_field.qre_next->a_field.qre_prev = (a_qr);\t\t\\\n+    (a_qrelm)->a_field.qre_next = (a_qr);\t\t\t\t\\\n+    } while (0)\n+\n+#define qr_meld(a_qr_a, a_qr_b, a_field) do {\t\t\t\t\\\n+    void *t;\t\t\t\t\t\t\t\\\n+    (a_qr_a)->a_field.qre_prev->a_field.qre_next = (a_qr_b);\t\\\n+    (a_qr_b)->a_field.qre_prev->a_field.qre_next = (a_qr_a);\t\\\n+    t = (a_qr_a)->a_field.qre_prev;\t\t\t\t\t\\\n+    (a_qr_a)->a_field.qre_prev = (a_qr_b)->a_field.qre_prev;\t\\\n+    (a_qr_b)->a_field.qre_prev = t;\t\t\t\t\t\\\n+} while (0)\n+\n+/* qr_meld() and qr_split() are functionally equivalent, so there's no need to\n+ * have two copies of the code. */\n+#define qr_split(a_qr_a, a_qr_b, a_field)\t\t\t\t\\\n+    qr_meld((a_qr_a), (a_qr_b), a_field)\n+\n+#define qr_remove(a_qr, a_field) do {\t\t\t\t\t\\\n+    (a_qr)->a_field.qre_prev->a_field.qre_next\t\t\t\\\n+        = (a_qr)->a_field.qre_next;\t\t\t\t\t\\\n+    (a_qr)->a_field.qre_next->a_field.qre_prev\t\t\t\\\n+        = (a_qr)->a_field.qre_prev;\t\t\t\t\t\\\n+    (a_qr)->a_field.qre_next = (a_qr);\t\t\t\t\\\n+    (a_qr)->a_field.qre_prev = (a_qr);\t\t\t\t\\\n+} while (0)\n+\n+#define qr_foreach(var, a_qr, a_field)\t\t\t\t\t\\\n+    for ((var) = (a_qr);\t\t\t\t\t\t\\\n+        (var) != NULL;\t\t\t\t\t\t\\\n+        (var) = (((var)->a_field.qre_next != (a_qr))\t\t\\\n+        ? (var)->a_field.qre_next : NULL))\n+\n+#define qr_reverse_foreach(var, a_qr, a_field)\t\t\t\t\\\n+    for ((var) = ((a_qr) != NULL) ? qr_prev(a_qr, a_field) : NULL;\t\\\n+        (var) != NULL;\t\t\t\t\t\t\\\n+        (var) = (((var) != (a_qr))\t\t\t\t\t\\\n+        ? (var)->a_field.qre_prev : NULL))"}, {"sha": "7a0b7c32cabc2d36830e99d7b1b055b57c00ffb6", "filename": "src/rt/jemalloc/include/jemalloc/internal/quarantine.h", "status": "added", "additions": 66, "deletions": 0, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fquarantine.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fquarantine.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fquarantine.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,66 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct quarantine_obj_s quarantine_obj_t;\n+typedef struct quarantine_s quarantine_t;\n+\n+/* Default per thread quarantine size if valgrind is enabled. */\n+#define\tJEMALLOC_VALGRIND_QUARANTINE_DEFAULT\t(ZU(1) << 24)\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct quarantine_obj_s {\n+    void\t*ptr;\n+    size_t\tusize;\n+};\n+\n+struct quarantine_s {\n+    size_t\t\t\tcurbytes;\n+    size_t\t\t\tcurobjs;\n+    size_t\t\t\tfirst;\n+#define\tLG_MAXOBJS_INIT 10\n+    size_t\t\t\tlg_maxobjs;\n+    quarantine_obj_t\tobjs[1]; /* Dynamically sized ring buffer. */\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+quarantine_t\t*quarantine_init(size_t lg_maxobjs);\n+void\tquarantine(void *ptr);\n+void\tquarantine_cleanup(void *arg);\n+bool\tquarantine_boot(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+malloc_tsd_protos(JEMALLOC_ATTR(unused), quarantine, quarantine_t *)\n+\n+void\tquarantine_alloc_hook(void);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_QUARANTINE_C_))\n+malloc_tsd_externs(quarantine, quarantine_t *)\n+malloc_tsd_funcs(JEMALLOC_ALWAYS_INLINE, quarantine, quarantine_t *, NULL,\n+    quarantine_cleanup)\n+\n+JEMALLOC_ALWAYS_INLINE void\n+quarantine_alloc_hook(void)\n+{\n+    quarantine_t *quarantine;\n+\n+    assert(config_fill && opt_quarantine);\n+\n+    quarantine = *quarantine_tsd_get();\n+    if (quarantine == NULL)\n+        quarantine_init(LG_MAXOBJS_INIT);\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "cdc89d73859e1bed3b9f6778885a88511131d9ee", "filename": "src/rt/jemalloc/include/jemalloc/internal/rb.h", "status": "added", "additions": 973, "deletions": 0, "changes": 973, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Frb.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Frb.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Frb.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,973 @@\n+/*-\n+ *******************************************************************************\n+ *\n+ * cpp macro implementation of left-leaning 2-3 red-black trees.  Parent\n+ * pointers are not used, and color bits are stored in the least significant\n+ * bit of right-child pointers (if RB_COMPACT is defined), thus making node\n+ * linkage as compact as is possible for red-black trees.\n+ *\n+ * Usage:\n+ *\n+ *   #include <stdint.h>\n+ *   #include <stdbool.h>\n+ *   #define NDEBUG // (Optional, see assert(3).)\n+ *   #include <assert.h>\n+ *   #define RB_COMPACT // (Optional, embed color bits in right-child pointers.)\n+ *   #include <rb.h>\n+ *   ...\n+ *\n+ *******************************************************************************\n+ */\n+\n+#ifndef RB_H_\n+#define\tRB_H_\n+\n+#if 0\n+__FBSDID(\"$FreeBSD: head/lib/libc/stdlib/rb.h 204493 2010-02-28 22:57:13Z jasone $\");\n+#endif\n+\n+#ifdef RB_COMPACT\n+/* Node structure. */\n+#define\trb_node(a_type)\t\t\t\t\t\t\t\\\n+struct {\t\t\t\t\t\t\t\t\\\n+    a_type *rbn_left;\t\t\t\t\t\t\t\\\n+    a_type *rbn_right_red;\t\t\t\t\t\t\\\n+}\n+#else\n+#define\trb_node(a_type)\t\t\t\t\t\t\t\\\n+struct {\t\t\t\t\t\t\t\t\\\n+    a_type *rbn_left;\t\t\t\t\t\t\t\\\n+    a_type *rbn_right;\t\t\t\t\t\t\t\\\n+    bool rbn_red;\t\t\t\t\t\t\t\\\n+}\n+#endif\n+\n+/* Root structure. */\n+#define\trb_tree(a_type)\t\t\t\t\t\t\t\\\n+struct {\t\t\t\t\t\t\t\t\\\n+    a_type *rbt_root;\t\t\t\t\t\t\t\\\n+    a_type rbt_nil;\t\t\t\t\t\t\t\\\n+}\n+\n+/* Left accessors. */\n+#define\trbtn_left_get(a_type, a_field, a_node)\t\t\t\t\\\n+    ((a_node)->a_field.rbn_left)\n+#define\trbtn_left_set(a_type, a_field, a_node, a_left) do {\t\t\\\n+    (a_node)->a_field.rbn_left = a_left;\t\t\t\t\\\n+} while (0)\n+\n+#ifdef RB_COMPACT\n+/* Right accessors. */\n+#define\trbtn_right_get(a_type, a_field, a_node)\t\t\t\t\\\n+    ((a_type *) (((intptr_t) (a_node)->a_field.rbn_right_red)\t\t\\\n+      & ((ssize_t)-2)))\n+#define\trbtn_right_set(a_type, a_field, a_node, a_right) do {\t\t\\\n+    (a_node)->a_field.rbn_right_red = (a_type *) (((uintptr_t) a_right)\t\\\n+      | (((uintptr_t) (a_node)->a_field.rbn_right_red) & ((size_t)1)));\t\\\n+} while (0)\n+\n+/* Color accessors. */\n+#define\trbtn_red_get(a_type, a_field, a_node)\t\t\t\t\\\n+    ((bool) (((uintptr_t) (a_node)->a_field.rbn_right_red)\t\t\\\n+      & ((size_t)1)))\n+#define\trbtn_color_set(a_type, a_field, a_node, a_red) do {\t\t\\\n+    (a_node)->a_field.rbn_right_red = (a_type *) ((((intptr_t)\t\t\\\n+      (a_node)->a_field.rbn_right_red) & ((ssize_t)-2))\t\t\t\\\n+      | ((ssize_t)a_red));\t\t\t\t\t\t\\\n+} while (0)\n+#define\trbtn_red_set(a_type, a_field, a_node) do {\t\t\t\\\n+    (a_node)->a_field.rbn_right_red = (a_type *) (((uintptr_t)\t\t\\\n+      (a_node)->a_field.rbn_right_red) | ((size_t)1));\t\t\t\\\n+} while (0)\n+#define\trbtn_black_set(a_type, a_field, a_node) do {\t\t\t\\\n+    (a_node)->a_field.rbn_right_red = (a_type *) (((intptr_t)\t\t\\\n+      (a_node)->a_field.rbn_right_red) & ((ssize_t)-2));\t\t\\\n+} while (0)\n+#else\n+/* Right accessors. */\n+#define\trbtn_right_get(a_type, a_field, a_node)\t\t\t\t\\\n+    ((a_node)->a_field.rbn_right)\n+#define\trbtn_right_set(a_type, a_field, a_node, a_right) do {\t\t\\\n+    (a_node)->a_field.rbn_right = a_right;\t\t\t\t\\\n+} while (0)\n+\n+/* Color accessors. */\n+#define\trbtn_red_get(a_type, a_field, a_node)\t\t\t\t\\\n+    ((a_node)->a_field.rbn_red)\n+#define\trbtn_color_set(a_type, a_field, a_node, a_red) do {\t\t\\\n+    (a_node)->a_field.rbn_red = (a_red);\t\t\t\t\\\n+} while (0)\n+#define\trbtn_red_set(a_type, a_field, a_node) do {\t\t\t\\\n+    (a_node)->a_field.rbn_red = true;\t\t\t\t\t\\\n+} while (0)\n+#define\trbtn_black_set(a_type, a_field, a_node) do {\t\t\t\\\n+    (a_node)->a_field.rbn_red = false;\t\t\t\t\t\\\n+} while (0)\n+#endif\n+\n+/* Node initializer. */\n+#define\trbt_node_new(a_type, a_field, a_rbt, a_node) do {\t\t\\\n+    rbtn_left_set(a_type, a_field, (a_node), &(a_rbt)->rbt_nil);\t\\\n+    rbtn_right_set(a_type, a_field, (a_node), &(a_rbt)->rbt_nil);\t\\\n+    rbtn_red_set(a_type, a_field, (a_node));\t\t\t\t\\\n+} while (0)\n+\n+/* Tree initializer. */\n+#define\trb_new(a_type, a_field, a_rbt) do {\t\t\t\t\\\n+    (a_rbt)->rbt_root = &(a_rbt)->rbt_nil;\t\t\t\t\\\n+    rbt_node_new(a_type, a_field, a_rbt, &(a_rbt)->rbt_nil);\t\t\\\n+    rbtn_black_set(a_type, a_field, &(a_rbt)->rbt_nil);\t\t\t\\\n+} while (0)\n+\n+/* Internal utility macros. */\n+#define\trbtn_first(a_type, a_field, a_rbt, a_root, r_node) do {\t\t\\\n+    (r_node) = (a_root);\t\t\t\t\t\t\\\n+    if ((r_node) != &(a_rbt)->rbt_nil) {\t\t\t\t\\\n+    for (;\t\t\t\t\t\t\t\t\\\n+      rbtn_left_get(a_type, a_field, (r_node)) != &(a_rbt)->rbt_nil;\\\n+      (r_node) = rbtn_left_get(a_type, a_field, (r_node))) {\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define\trbtn_last(a_type, a_field, a_rbt, a_root, r_node) do {\t\t\\\n+    (r_node) = (a_root);\t\t\t\t\t\t\\\n+    if ((r_node) != &(a_rbt)->rbt_nil) {\t\t\t\t\\\n+    for (; rbtn_right_get(a_type, a_field, (r_node)) !=\t\t\\\n+      &(a_rbt)->rbt_nil; (r_node) = rbtn_right_get(a_type, a_field,\t\\\n+      (r_node))) {\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define\trbtn_rotate_left(a_type, a_field, a_node, r_node) do {\t\t\\\n+    (r_node) = rbtn_right_get(a_type, a_field, (a_node));\t\t\\\n+    rbtn_right_set(a_type, a_field, (a_node),\t\t\t\t\\\n+      rbtn_left_get(a_type, a_field, (r_node)));\t\t\t\\\n+    rbtn_left_set(a_type, a_field, (r_node), (a_node));\t\t\t\\\n+} while (0)\n+\n+#define\trbtn_rotate_right(a_type, a_field, a_node, r_node) do {\t\t\\\n+    (r_node) = rbtn_left_get(a_type, a_field, (a_node));\t\t\\\n+    rbtn_left_set(a_type, a_field, (a_node),\t\t\t\t\\\n+      rbtn_right_get(a_type, a_field, (r_node)));\t\t\t\\\n+    rbtn_right_set(a_type, a_field, (r_node), (a_node));\t\t\\\n+} while (0)\n+\n+/*\n+ * The rb_proto() macro generates function prototypes that correspond to the\n+ * functions generated by an equivalently parameterized call to rb_gen().\n+ */\n+\n+#define\trb_proto(a_attr, a_prefix, a_rbt_type, a_type)\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_prefix##new(a_rbt_type *rbtree);\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##first(a_rbt_type *rbtree);\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##last(a_rbt_type *rbtree);\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##next(a_rbt_type *rbtree, a_type *node);\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##prev(a_rbt_type *rbtree, a_type *node);\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##search(a_rbt_type *rbtree, a_type *key);\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##nsearch(a_rbt_type *rbtree, a_type *key);\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##psearch(a_rbt_type *rbtree, a_type *key);\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_prefix##insert(a_rbt_type *rbtree, a_type *node);\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_prefix##remove(a_rbt_type *rbtree, a_type *node);\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##iter(a_rbt_type *rbtree, a_type *start, a_type *(*cb)(\t\\\n+  a_rbt_type *, a_type *, void *), void *arg);\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##reverse_iter(a_rbt_type *rbtree, a_type *start,\t\t\\\n+  a_type *(*cb)(a_rbt_type *, a_type *, void *), void *arg);\n+\n+/*\n+ * The rb_gen() macro generates a type-specific red-black tree implementation,\n+ * based on the above cpp macros.\n+ *\n+ * Arguments:\n+ *\n+ *   a_attr    : Function attribute for generated functions (ex: static).\n+ *   a_prefix  : Prefix for generated functions (ex: ex_).\n+ *   a_rb_type : Type for red-black tree data structure (ex: ex_t).\n+ *   a_type    : Type for red-black tree node data structure (ex: ex_node_t).\n+ *   a_field   : Name of red-black tree node linkage (ex: ex_link).\n+ *   a_cmp     : Node comparison function name, with the following prototype:\n+ *                 int (a_cmp *)(a_type *a_node, a_type *a_other);\n+ *                                       ^^^^^^\n+ *                                    or a_key\n+ *               Interpretation of comparision function return values:\n+ *                 -1 : a_node <  a_other\n+ *                  0 : a_node == a_other\n+ *                  1 : a_node >  a_other\n+ *               In all cases, the a_node or a_key macro argument is the first\n+ *               argument to the comparison function, which makes it possible\n+ *               to write comparison functions that treat the first argument\n+ *               specially.\n+ *\n+ * Assuming the following setup:\n+ *\n+ *   typedef struct ex_node_s ex_node_t;\n+ *   struct ex_node_s {\n+ *       rb_node(ex_node_t) ex_link;\n+ *   };\n+ *   typedef rb_tree(ex_node_t) ex_t;\n+ *   rb_gen(static, ex_, ex_t, ex_node_t, ex_link, ex_cmp)\n+ *\n+ * The following API is generated:\n+ *\n+ *   static void\n+ *   ex_new(ex_t *tree);\n+ *       Description: Initialize a red-black tree structure.\n+ *       Args:\n+ *         tree: Pointer to an uninitialized red-black tree object.\n+ *\n+ *   static ex_node_t *\n+ *   ex_first(ex_t *tree);\n+ *   static ex_node_t *\n+ *   ex_last(ex_t *tree);\n+ *       Description: Get the first/last node in tree.\n+ *       Args:\n+ *         tree: Pointer to an initialized red-black tree object.\n+ *       Ret: First/last node in tree, or NULL if tree is empty.\n+ *\n+ *   static ex_node_t *\n+ *   ex_next(ex_t *tree, ex_node_t *node);\n+ *   static ex_node_t *\n+ *   ex_prev(ex_t *tree, ex_node_t *node);\n+ *       Description: Get node's successor/predecessor.\n+ *       Args:\n+ *         tree: Pointer to an initialized red-black tree object.\n+ *         node: A node in tree.\n+ *       Ret: node's successor/predecessor in tree, or NULL if node is\n+ *            last/first.\n+ *\n+ *   static ex_node_t *\n+ *   ex_search(ex_t *tree, ex_node_t *key);\n+ *       Description: Search for node that matches key.\n+ *       Args:\n+ *         tree: Pointer to an initialized red-black tree object.\n+ *         key : Search key.\n+ *       Ret: Node in tree that matches key, or NULL if no match.\n+ *\n+ *   static ex_node_t *\n+ *   ex_nsearch(ex_t *tree, ex_node_t *key);\n+ *   static ex_node_t *\n+ *   ex_psearch(ex_t *tree, ex_node_t *key);\n+ *       Description: Search for node that matches key.  If no match is found,\n+ *                    return what would be key's successor/predecessor, were\n+ *                    key in tree.\n+ *       Args:\n+ *         tree: Pointer to an initialized red-black tree object.\n+ *         key : Search key.\n+ *       Ret: Node in tree that matches key, or if no match, hypothetical node's\n+ *            successor/predecessor (NULL if no successor/predecessor).\n+ *\n+ *   static void\n+ *   ex_insert(ex_t *tree, ex_node_t *node);\n+ *       Description: Insert node into tree.\n+ *       Args:\n+ *         tree: Pointer to an initialized red-black tree object.\n+ *         node: Node to be inserted into tree.\n+ *\n+ *   static void\n+ *   ex_remove(ex_t *tree, ex_node_t *node);\n+ *       Description: Remove node from tree.\n+ *       Args:\n+ *         tree: Pointer to an initialized red-black tree object.\n+ *         node: Node in tree to be removed.\n+ *\n+ *   static ex_node_t *\n+ *   ex_iter(ex_t *tree, ex_node_t *start, ex_node_t *(*cb)(ex_t *,\n+ *     ex_node_t *, void *), void *arg);\n+ *   static ex_node_t *\n+ *   ex_reverse_iter(ex_t *tree, ex_node_t *start, ex_node *(*cb)(ex_t *,\n+ *     ex_node_t *, void *), void *arg);\n+ *       Description: Iterate forward/backward over tree, starting at node.  If\n+ *                    tree is modified, iteration must be immediately\n+ *                    terminated by the callback function that causes the\n+ *                    modification.\n+ *       Args:\n+ *         tree : Pointer to an initialized red-black tree object.\n+ *         start: Node at which to start iteration, or NULL to start at\n+ *                first/last node.\n+ *         cb   : Callback function, which is called for each node during\n+ *                iteration.  Under normal circumstances the callback function\n+ *                should return NULL, which causes iteration to continue.  If a\n+ *                callback function returns non-NULL, iteration is immediately\n+ *                terminated and the non-NULL return value is returned by the\n+ *                iterator.  This is useful for re-starting iteration after\n+ *                modifying tree.\n+ *         arg  : Opaque pointer passed to cb().\n+ *       Ret: NULL if iteration completed, or the non-NULL callback return value\n+ *            that caused termination of the iteration.\n+ */\n+#define\trb_gen(a_attr, a_prefix, a_rbt_type, a_type, a_field, a_cmp)\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_prefix##new(a_rbt_type *rbtree) {\t\t\t\t\t\\\n+    rb_new(a_type, a_field, rbtree);\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##first(a_rbt_type *rbtree) {\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    rbtn_first(a_type, a_field, rbtree, rbtree->rbt_root, ret);\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = NULL;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##last(a_rbt_type *rbtree) {\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    rbtn_last(a_type, a_field, rbtree, rbtree->rbt_root, ret);\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = NULL;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##next(a_rbt_type *rbtree, a_type *node) {\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if (rbtn_right_get(a_type, a_field, node) != &rbtree->rbt_nil) {\t\\\n+    rbtn_first(a_type, a_field, rbtree, rbtn_right_get(a_type,\t\\\n+      a_field, node), ret);\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *tnode = rbtree->rbt_root;\t\t\t\t\\\n+    assert(tnode != &rbtree->rbt_nil);\t\t\t\t\\\n+    ret = &rbtree->rbt_nil;\t\t\t\t\t\t\\\n+    while (true) {\t\t\t\t\t\t\t\\\n+        int cmp = (a_cmp)(node, tnode);\t\t\t\t\\\n+        if (cmp < 0) {\t\t\t\t\t\t\\\n+        ret = tnode;\t\t\t\t\t\t\\\n+        tnode = rbtn_left_get(a_type, a_field, tnode);\t\t\\\n+        } else if (cmp > 0) {\t\t\t\t\t\\\n+        tnode = rbtn_right_get(a_type, a_field, tnode);\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        break;\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+        assert(tnode != &rbtree->rbt_nil);\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = (NULL);\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##prev(a_rbt_type *rbtree, a_type *node) {\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if (rbtn_left_get(a_type, a_field, node) != &rbtree->rbt_nil) {\t\\\n+    rbtn_last(a_type, a_field, rbtree, rbtn_left_get(a_type,\t\\\n+      a_field, node), ret);\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *tnode = rbtree->rbt_root;\t\t\t\t\\\n+    assert(tnode != &rbtree->rbt_nil);\t\t\t\t\\\n+    ret = &rbtree->rbt_nil;\t\t\t\t\t\t\\\n+    while (true) {\t\t\t\t\t\t\t\\\n+        int cmp = (a_cmp)(node, tnode);\t\t\t\t\\\n+        if (cmp < 0) {\t\t\t\t\t\t\\\n+        tnode = rbtn_left_get(a_type, a_field, tnode);\t\t\\\n+        } else if (cmp > 0) {\t\t\t\t\t\\\n+        ret = tnode;\t\t\t\t\t\t\\\n+        tnode = rbtn_right_get(a_type, a_field, tnode);\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        break;\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+        assert(tnode != &rbtree->rbt_nil);\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = (NULL);\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##search(a_rbt_type *rbtree, a_type *key) {\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    int cmp;\t\t\t\t\t\t\t\t\\\n+    ret = rbtree->rbt_root;\t\t\t\t\t\t\\\n+    while (ret != &rbtree->rbt_nil\t\t\t\t\t\\\n+      && (cmp = (a_cmp)(key, ret)) != 0) {\t\t\t\t\\\n+    if (cmp < 0) {\t\t\t\t\t\t\t\\\n+        ret = rbtn_left_get(a_type, a_field, ret);\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        ret = rbtn_right_get(a_type, a_field, ret);\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = (NULL);\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##nsearch(a_rbt_type *rbtree, a_type *key) {\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    a_type *tnode = rbtree->rbt_root;\t\t\t\t\t\\\n+    ret = &rbtree->rbt_nil;\t\t\t\t\t\t\\\n+    while (tnode != &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    int cmp = (a_cmp)(key, tnode);\t\t\t\t\t\\\n+    if (cmp < 0) {\t\t\t\t\t\t\t\\\n+        ret = tnode;\t\t\t\t\t\t\\\n+        tnode = rbtn_left_get(a_type, a_field, tnode);\t\t\\\n+    } else if (cmp > 0) {\t\t\t\t\t\t\\\n+        tnode = rbtn_right_get(a_type, a_field, tnode);\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        ret = tnode;\t\t\t\t\t\t\\\n+        break;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = (NULL);\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##psearch(a_rbt_type *rbtree, a_type *key) {\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    a_type *tnode = rbtree->rbt_root;\t\t\t\t\t\\\n+    ret = &rbtree->rbt_nil;\t\t\t\t\t\t\\\n+    while (tnode != &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    int cmp = (a_cmp)(key, tnode);\t\t\t\t\t\\\n+    if (cmp < 0) {\t\t\t\t\t\t\t\\\n+        tnode = rbtn_left_get(a_type, a_field, tnode);\t\t\\\n+    } else if (cmp > 0) {\t\t\t\t\t\t\\\n+        ret = tnode;\t\t\t\t\t\t\\\n+        tnode = rbtn_right_get(a_type, a_field, tnode);\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        ret = tnode;\t\t\t\t\t\t\\\n+        break;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = (NULL);\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_prefix##insert(a_rbt_type *rbtree, a_type *node) {\t\t\t\\\n+    struct {\t\t\t\t\t\t\t\t\\\n+    a_type *node;\t\t\t\t\t\t\t\\\n+    int cmp;\t\t\t\t\t\t\t\\\n+    } path[sizeof(void *) << 4], *pathp;\t\t\t\t\\\n+    rbt_node_new(a_type, a_field, rbtree, node);\t\t\t\\\n+    /* Wind. */\t\t\t\t\t\t\t\t\\\n+    path->node = rbtree->rbt_root;\t\t\t\t\t\\\n+    for (pathp = path; pathp->node != &rbtree->rbt_nil; pathp++) {\t\\\n+    int cmp = pathp->cmp = a_cmp(node, pathp->node);\t\t\\\n+    assert(cmp != 0);\t\t\t\t\t\t\\\n+    if (cmp < 0) {\t\t\t\t\t\t\t\\\n+        pathp[1].node = rbtn_left_get(a_type, a_field,\t\t\\\n+          pathp->node);\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        pathp[1].node = rbtn_right_get(a_type, a_field,\t\t\\\n+          pathp->node);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    pathp->node = node;\t\t\t\t\t\t\t\\\n+    /* Unwind. */\t\t\t\t\t\t\t\\\n+    for (pathp--; (uintptr_t)pathp >= (uintptr_t)path; pathp--) {\t\\\n+    a_type *cnode = pathp->node;\t\t\t\t\t\\\n+    if (pathp->cmp < 0) {\t\t\t\t\t\t\\\n+        a_type *left = pathp[1].node;\t\t\t\t\\\n+        rbtn_left_set(a_type, a_field, cnode, left);\t\t\\\n+        if (rbtn_red_get(a_type, a_field, left)) {\t\t\t\\\n+        a_type *leftleft = rbtn_left_get(a_type, a_field, left);\\\n+        if (rbtn_red_get(a_type, a_field, leftleft)) {\t\t\\\n+            /* Fix up 4-node. */\t\t\t\t\\\n+            a_type *tnode;\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, leftleft);\t\t\\\n+            rbtn_rotate_right(a_type, a_field, cnode, tnode);\t\\\n+            cnode = tnode;\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        return;\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        a_type *right = pathp[1].node;\t\t\t\t\\\n+        rbtn_right_set(a_type, a_field, cnode, right);\t\t\\\n+        if (rbtn_red_get(a_type, a_field, right)) {\t\t\t\\\n+        a_type *left = rbtn_left_get(a_type, a_field, cnode);\t\\\n+        if (rbtn_red_get(a_type, a_field, left)) {\t\t\\\n+            /* Split 4-node. */\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, left);\t\t\\\n+            rbtn_black_set(a_type, a_field, right);\t\t\\\n+            rbtn_red_set(a_type, a_field, cnode);\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            /* Lean left. */\t\t\t\t\t\\\n+            a_type *tnode;\t\t\t\t\t\\\n+            bool tred = rbtn_red_get(a_type, a_field, cnode);\t\\\n+            rbtn_rotate_left(a_type, a_field, cnode, tnode);\t\\\n+            rbtn_color_set(a_type, a_field, tnode, tred);\t\\\n+            rbtn_red_set(a_type, a_field, cnode);\t\t\\\n+            cnode = tnode;\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        return;\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    pathp->node = cnode;\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    /* Set root, and make it black. */\t\t\t\t\t\\\n+    rbtree->rbt_root = path->node;\t\t\t\t\t\\\n+    rbtn_black_set(a_type, a_field, rbtree->rbt_root);\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_prefix##remove(a_rbt_type *rbtree, a_type *node) {\t\t\t\\\n+    struct {\t\t\t\t\t\t\t\t\\\n+    a_type *node;\t\t\t\t\t\t\t\\\n+    int cmp;\t\t\t\t\t\t\t\\\n+    } *pathp, *nodep, path[sizeof(void *) << 4];\t\t\t\\\n+    /* Wind. */\t\t\t\t\t\t\t\t\\\n+    nodep = NULL; /* Silence compiler warning. */\t\t\t\\\n+    path->node = rbtree->rbt_root;\t\t\t\t\t\\\n+    for (pathp = path; pathp->node != &rbtree->rbt_nil; pathp++) {\t\\\n+    int cmp = pathp->cmp = a_cmp(node, pathp->node);\t\t\\\n+    if (cmp < 0) {\t\t\t\t\t\t\t\\\n+        pathp[1].node = rbtn_left_get(a_type, a_field,\t\t\\\n+          pathp->node);\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        pathp[1].node = rbtn_right_get(a_type, a_field,\t\t\\\n+          pathp->node);\t\t\t\t\t\t\\\n+        if (cmp == 0) {\t\t\t\t\t\t\\\n+            /* Find node's successor, in preparation for swap. */\t\\\n+        pathp->cmp = 1;\t\t\t\t\t\t\\\n+        nodep = pathp;\t\t\t\t\t\t\\\n+        for (pathp++; pathp->node != &rbtree->rbt_nil;\t\t\\\n+          pathp++) {\t\t\t\t\t\t\\\n+            pathp->cmp = -1;\t\t\t\t\t\\\n+            pathp[1].node = rbtn_left_get(a_type, a_field,\t\\\n+              pathp->node);\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        break;\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    assert(nodep->node == node);\t\t\t\t\t\\\n+    pathp--;\t\t\t\t\t\t\t\t\\\n+    if (pathp->node != node) {\t\t\t\t\t\t\\\n+    /* Swap node with its successor. */\t\t\t\t\\\n+    bool tred = rbtn_red_get(a_type, a_field, pathp->node);\t\t\\\n+    rbtn_color_set(a_type, a_field, pathp->node,\t\t\t\\\n+      rbtn_red_get(a_type, a_field, node));\t\t\t\t\\\n+    rbtn_left_set(a_type, a_field, pathp->node,\t\t\t\\\n+      rbtn_left_get(a_type, a_field, node));\t\t\t\\\n+    /* If node's successor is its right child, the following code */\\\n+    /* will do the wrong thing for the right child pointer.       */\\\n+    /* However, it doesn't matter, because the pointer will be    */\\\n+    /* properly set when the successor is pruned.                 */\\\n+    rbtn_right_set(a_type, a_field, pathp->node,\t\t\t\\\n+      rbtn_right_get(a_type, a_field, node));\t\t\t\\\n+    rbtn_color_set(a_type, a_field, node, tred);\t\t\t\\\n+    /* The pruned leaf node's child pointers are never accessed   */\\\n+    /* again, so don't bother setting them to nil.                */\\\n+    nodep->node = pathp->node;\t\t\t\t\t\\\n+    pathp->node = node;\t\t\t\t\t\t\\\n+    if (nodep == path) {\t\t\t\t\t\t\\\n+        rbtree->rbt_root = nodep->node;\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        if (nodep[-1].cmp < 0) {\t\t\t\t\t\\\n+        rbtn_left_set(a_type, a_field, nodep[-1].node,\t\t\\\n+          nodep->node);\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        rbtn_right_set(a_type, a_field, nodep[-1].node,\t\t\\\n+          nodep->node);\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *left = rbtn_left_get(a_type, a_field, node);\t\t\\\n+    if (left != &rbtree->rbt_nil) {\t\t\t\t\t\\\n+        /* node has no successor, but it has a left child.        */\\\n+        /* Splice node out, without losing the left child.        */\\\n+        assert(rbtn_red_get(a_type, a_field, node) == false);\t\\\n+        assert(rbtn_red_get(a_type, a_field, left));\t\t\\\n+        rbtn_black_set(a_type, a_field, left);\t\t\t\\\n+        if (pathp == path) {\t\t\t\t\t\\\n+        rbtree->rbt_root = left;\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        if (pathp[-1].cmp < 0) {\t\t\t\t\\\n+            rbtn_left_set(a_type, a_field, pathp[-1].node,\t\\\n+              left);\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            rbtn_right_set(a_type, a_field, pathp[-1].node,\t\\\n+              left);\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+        return;\t\t\t\t\t\t\t\\\n+    } else if (pathp == path) {\t\t\t\t\t\\\n+        /* The tree only contained one node. */\t\t\t\\\n+        rbtree->rbt_root = &rbtree->rbt_nil;\t\t\t\\\n+        return;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (rbtn_red_get(a_type, a_field, pathp->node)) {\t\t\t\\\n+    /* Prune red node, which requires no fixup. */\t\t\t\\\n+    assert(pathp[-1].cmp < 0);\t\t\t\t\t\\\n+    rbtn_left_set(a_type, a_field, pathp[-1].node,\t\t\t\\\n+      &rbtree->rbt_nil);\t\t\t\t\t\t\\\n+    return;\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    /* The node to be pruned is black, so unwind until balance is     */\\\n+    /* restored.                                                      */\\\n+    pathp->node = &rbtree->rbt_nil;\t\t\t\t\t\\\n+    for (pathp--; (uintptr_t)pathp >= (uintptr_t)path; pathp--) {\t\\\n+    assert(pathp->cmp != 0);\t\t\t\t\t\\\n+    if (pathp->cmp < 0) {\t\t\t\t\t\t\\\n+        rbtn_left_set(a_type, a_field, pathp->node,\t\t\t\\\n+          pathp[1].node);\t\t\t\t\t\t\\\n+        assert(rbtn_red_get(a_type, a_field, pathp[1].node)\t\t\\\n+          == false);\t\t\t\t\t\t\\\n+        if (rbtn_red_get(a_type, a_field, pathp->node)) {\t\t\\\n+        a_type *right = rbtn_right_get(a_type, a_field,\t\t\\\n+          pathp->node);\t\t\t\t\t\t\\\n+        a_type *rightleft = rbtn_left_get(a_type, a_field,\t\\\n+          right);\t\t\t\t\t\t\\\n+        a_type *tnode;\t\t\t\t\t\t\\\n+        if (rbtn_red_get(a_type, a_field, rightleft)) {\t\t\\\n+            /* In the following diagrams, ||, //, and \\\\      */\\\n+            /* indicate the path to the removed node.         */\\\n+            /*                                                */\\\n+            /*      ||                                        */\\\n+            /*    pathp(r)                                    */\\\n+            /*  //        \\                                   */\\\n+            /* (b)        (b)                                 */\\\n+            /*           /                                    */\\\n+            /*          (r)                                   */\\\n+            /*                                                */\\\n+            rbtn_black_set(a_type, a_field, pathp->node);\t\\\n+            rbtn_rotate_right(a_type, a_field, right, tnode);\t\\\n+            rbtn_right_set(a_type, a_field, pathp->node, tnode);\\\n+            rbtn_rotate_left(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            /*      ||                                        */\\\n+            /*    pathp(r)                                    */\\\n+            /*  //        \\                                   */\\\n+            /* (b)        (b)                                 */\\\n+            /*           /                                    */\\\n+            /*          (b)                                   */\\\n+            /*                                                */\\\n+            rbtn_rotate_left(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        /* Balance restored, but rotation modified subtree    */\\\n+        /* root.                                              */\\\n+        assert((uintptr_t)pathp > (uintptr_t)path);\t\t\\\n+        if (pathp[-1].cmp < 0) {\t\t\t\t\\\n+            rbtn_left_set(a_type, a_field, pathp[-1].node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            rbtn_right_set(a_type, a_field, pathp[-1].node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        return;\t\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        a_type *right = rbtn_right_get(a_type, a_field,\t\t\\\n+          pathp->node);\t\t\t\t\t\t\\\n+        a_type *rightleft = rbtn_left_get(a_type, a_field,\t\\\n+          right);\t\t\t\t\t\t\\\n+        if (rbtn_red_get(a_type, a_field, rightleft)) {\t\t\\\n+            /*      ||                                        */\\\n+            /*    pathp(b)                                    */\\\n+            /*  //        \\                                   */\\\n+            /* (b)        (b)                                 */\\\n+            /*           /                                    */\\\n+            /*          (r)                                   */\\\n+            a_type *tnode;\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, rightleft);\t\t\\\n+            rbtn_rotate_right(a_type, a_field, right, tnode);\t\\\n+            rbtn_right_set(a_type, a_field, pathp->node, tnode);\\\n+            rbtn_rotate_left(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+            /* Balance restored, but rotation modified        */\\\n+            /* subree root, which may actually be the tree    */\\\n+            /* root.                                          */\\\n+            if (pathp == path) {\t\t\t\t\\\n+            /* Set root. */\t\t\t\t\t\\\n+            rbtree->rbt_root = tnode;\t\t\t\\\n+            } else {\t\t\t\t\t\t\\\n+            if (pathp[-1].cmp < 0) {\t\t\t\\\n+                rbtn_left_set(a_type, a_field,\t\t\\\n+                  pathp[-1].node, tnode);\t\t\t\\\n+            } else {\t\t\t\t\t\\\n+                rbtn_right_set(a_type, a_field,\t\t\\\n+                  pathp[-1].node, tnode);\t\t\t\\\n+            }\t\t\t\t\t\t\\\n+            }\t\t\t\t\t\t\t\\\n+            return;\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            /*      ||                                        */\\\n+            /*    pathp(b)                                    */\\\n+            /*  //        \\                                   */\\\n+            /* (b)        (b)                                 */\\\n+            /*           /                                    */\\\n+            /*          (b)                                   */\\\n+            a_type *tnode;\t\t\t\t\t\\\n+            rbtn_red_set(a_type, a_field, pathp->node);\t\t\\\n+            rbtn_rotate_left(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+            pathp->node = tnode;\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\\\n+        a_type *left;\t\t\t\t\t\t\\\n+        rbtn_right_set(a_type, a_field, pathp->node,\t\t\\\n+          pathp[1].node);\t\t\t\t\t\t\\\n+        left = rbtn_left_get(a_type, a_field, pathp->node);\t\t\\\n+        if (rbtn_red_get(a_type, a_field, left)) {\t\t\t\\\n+        a_type *tnode;\t\t\t\t\t\t\\\n+        a_type *leftright = rbtn_right_get(a_type, a_field,\t\\\n+          left);\t\t\t\t\t\t\\\n+        a_type *leftrightleft = rbtn_left_get(a_type, a_field,\t\\\n+          leftright);\t\t\t\t\t\t\\\n+        if (rbtn_red_get(a_type, a_field, leftrightleft)) {\t\\\n+            /*      ||                                        */\\\n+            /*    pathp(b)                                    */\\\n+            /*   /        \\\\                                  */\\\n+            /* (r)        (b)                                 */\\\n+            /*   \\                                            */\\\n+            /*   (b)                                          */\\\n+            /*   /                                            */\\\n+            /* (r)                                            */\\\n+            a_type *unode;\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, leftrightleft);\t\\\n+            rbtn_rotate_right(a_type, a_field, pathp->node,\t\\\n+              unode);\t\t\t\t\t\t\\\n+            rbtn_rotate_right(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+            rbtn_right_set(a_type, a_field, unode, tnode);\t\\\n+            rbtn_rotate_left(a_type, a_field, unode, tnode);\t\\\n+        } else {\t\t\t\t\t\t\\\n+            /*      ||                                        */\\\n+            /*    pathp(b)                                    */\\\n+            /*   /        \\\\                                  */\\\n+            /* (r)        (b)                                 */\\\n+            /*   \\                                            */\\\n+            /*   (b)                                          */\\\n+            /*   /                                            */\\\n+            /* (b)                                            */\\\n+            assert(leftright != &rbtree->rbt_nil);\t\t\\\n+            rbtn_red_set(a_type, a_field, leftright);\t\t\\\n+            rbtn_rotate_right(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, tnode);\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        /* Balance restored, but rotation modified subtree    */\\\n+        /* root, which may actually be the tree root.         */\\\n+        if (pathp == path) {\t\t\t\t\t\\\n+            /* Set root. */\t\t\t\t\t\\\n+            rbtree->rbt_root = tnode;\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            if (pathp[-1].cmp < 0) {\t\t\t\t\\\n+            rbtn_left_set(a_type, a_field, pathp[-1].node,\t\\\n+              tnode);\t\t\t\t\t\\\n+            } else {\t\t\t\t\t\t\\\n+            rbtn_right_set(a_type, a_field, pathp[-1].node,\t\\\n+              tnode);\t\t\t\t\t\\\n+            }\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        return;\t\t\t\t\t\t\t\\\n+        } else if (rbtn_red_get(a_type, a_field, pathp->node)) {\t\\\n+        a_type *leftleft = rbtn_left_get(a_type, a_field, left);\\\n+        if (rbtn_red_get(a_type, a_field, leftleft)) {\t\t\\\n+            /*        ||                                      */\\\n+            /*      pathp(r)                                  */\\\n+            /*     /        \\\\                                */\\\n+            /*   (b)        (b)                               */\\\n+            /*   /                                            */\\\n+            /* (r)                                            */\\\n+            a_type *tnode;\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, pathp->node);\t\\\n+            rbtn_red_set(a_type, a_field, left);\t\t\\\n+            rbtn_black_set(a_type, a_field, leftleft);\t\t\\\n+            rbtn_rotate_right(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+            /* Balance restored, but rotation modified        */\\\n+            /* subtree root.                                  */\\\n+            assert((uintptr_t)pathp > (uintptr_t)path);\t\t\\\n+            if (pathp[-1].cmp < 0) {\t\t\t\t\\\n+            rbtn_left_set(a_type, a_field, pathp[-1].node,\t\\\n+              tnode);\t\t\t\t\t\\\n+            } else {\t\t\t\t\t\t\\\n+            rbtn_right_set(a_type, a_field, pathp[-1].node,\t\\\n+              tnode);\t\t\t\t\t\\\n+            }\t\t\t\t\t\t\t\\\n+            return;\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            /*        ||                                      */\\\n+            /*      pathp(r)                                  */\\\n+            /*     /        \\\\                                */\\\n+            /*   (b)        (b)                               */\\\n+            /*   /                                            */\\\n+            /* (b)                                            */\\\n+            rbtn_red_set(a_type, a_field, left);\t\t\\\n+            rbtn_black_set(a_type, a_field, pathp->node);\t\\\n+            /* Balance restored. */\t\t\t\t\\\n+            return;\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\t\\\n+        a_type *leftleft = rbtn_left_get(a_type, a_field, left);\\\n+        if (rbtn_red_get(a_type, a_field, leftleft)) {\t\t\\\n+            /*               ||                               */\\\n+            /*             pathp(b)                           */\\\n+            /*            /        \\\\                         */\\\n+            /*          (b)        (b)                        */\\\n+            /*          /                                     */\\\n+            /*        (r)                                     */\\\n+            a_type *tnode;\t\t\t\t\t\\\n+            rbtn_black_set(a_type, a_field, leftleft);\t\t\\\n+            rbtn_rotate_right(a_type, a_field, pathp->node,\t\\\n+              tnode);\t\t\t\t\t\t\\\n+            /* Balance restored, but rotation modified        */\\\n+            /* subtree root, which may actually be the tree   */\\\n+            /* root.                                          */\\\n+            if (pathp == path) {\t\t\t\t\\\n+            /* Set root. */\t\t\t\t\t\\\n+            rbtree->rbt_root = tnode;\t\t\t\\\n+            } else {\t\t\t\t\t\t\\\n+            if (pathp[-1].cmp < 0) {\t\t\t\\\n+                rbtn_left_set(a_type, a_field,\t\t\\\n+                  pathp[-1].node, tnode);\t\t\t\\\n+            } else {\t\t\t\t\t\\\n+                rbtn_right_set(a_type, a_field,\t\t\\\n+                  pathp[-1].node, tnode);\t\t\t\\\n+            }\t\t\t\t\t\t\\\n+            }\t\t\t\t\t\t\t\\\n+            return;\t\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            /*               ||                               */\\\n+            /*             pathp(b)                           */\\\n+            /*            /        \\\\                         */\\\n+            /*          (b)        (b)                        */\\\n+            /*          /                                     */\\\n+            /*        (b)                                     */\\\n+            rbtn_red_set(a_type, a_field, left);\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    /* Set root. */\t\t\t\t\t\t\t\\\n+    rbtree->rbt_root = path->node;\t\t\t\t\t\\\n+    assert(rbtn_red_get(a_type, a_field, rbtree->rbt_root) == false);\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##iter_recurse(a_rbt_type *rbtree, a_type *node,\t\t\\\n+  a_type *(*cb)(a_rbt_type *, a_type *, void *), void *arg) {\t\t\\\n+    if (node == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    return (&rbtree->rbt_nil);\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if ((ret = a_prefix##iter_recurse(rbtree, rbtn_left_get(a_type,\t\\\n+      a_field, node), cb, arg)) != &rbtree->rbt_nil\t\t\t\\\n+      || (ret = cb(rbtree, node, arg)) != NULL) {\t\t\t\\\n+        return (ret);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_prefix##iter_recurse(rbtree, rbtn_right_get(a_type,\t\\\n+      a_field, node), cb, arg));\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##iter_start(a_rbt_type *rbtree, a_type *start, a_type *node,\t\\\n+  a_type *(*cb)(a_rbt_type *, a_type *, void *), void *arg) {\t\t\\\n+    int cmp = a_cmp(start, node);\t\t\t\t\t\\\n+    if (cmp < 0) {\t\t\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if ((ret = a_prefix##iter_start(rbtree, start,\t\t\t\\\n+      rbtn_left_get(a_type, a_field, node), cb, arg)) !=\t\t\\\n+      &rbtree->rbt_nil || (ret = cb(rbtree, node, arg)) != NULL) {\t\\\n+        return (ret);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_prefix##iter_recurse(rbtree, rbtn_right_get(a_type,\t\\\n+      a_field, node), cb, arg));\t\t\t\t\t\\\n+    } else if (cmp > 0) {\t\t\t\t\t\t\\\n+    return (a_prefix##iter_start(rbtree, start,\t\t\t\\\n+      rbtn_right_get(a_type, a_field, node), cb, arg));\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if ((ret = cb(rbtree, node, arg)) != NULL) {\t\t\t\\\n+        return (ret);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_prefix##iter_recurse(rbtree, rbtn_right_get(a_type,\t\\\n+      a_field, node), cb, arg));\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##iter(a_rbt_type *rbtree, a_type *start, a_type *(*cb)(\t\\\n+  a_rbt_type *, a_type *, void *), void *arg) {\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if (start != NULL) {\t\t\t\t\t\t\\\n+    ret = a_prefix##iter_start(rbtree, start, rbtree->rbt_root,\t\\\n+      cb, arg);\t\t\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    ret = a_prefix##iter_recurse(rbtree, rbtree->rbt_root, cb, arg);\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = NULL;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##reverse_iter_recurse(a_rbt_type *rbtree, a_type *node,\t\\\n+  a_type *(*cb)(a_rbt_type *, a_type *, void *), void *arg) {\t\t\\\n+    if (node == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    return (&rbtree->rbt_nil);\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if ((ret = a_prefix##reverse_iter_recurse(rbtree,\t\t\\\n+      rbtn_right_get(a_type, a_field, node), cb, arg)) !=\t\t\\\n+      &rbtree->rbt_nil || (ret = cb(rbtree, node, arg)) != NULL) {\t\\\n+        return (ret);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_prefix##reverse_iter_recurse(rbtree,\t\t\t\\\n+      rbtn_left_get(a_type, a_field, node), cb, arg));\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##reverse_iter_start(a_rbt_type *rbtree, a_type *start,\t\t\\\n+  a_type *node, a_type *(*cb)(a_rbt_type *, a_type *, void *),\t\t\\\n+  void *arg) {\t\t\t\t\t\t\t\t\\\n+    int cmp = a_cmp(start, node);\t\t\t\t\t\\\n+    if (cmp > 0) {\t\t\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if ((ret = a_prefix##reverse_iter_start(rbtree, start,\t\t\\\n+      rbtn_right_get(a_type, a_field, node), cb, arg)) !=\t\t\\\n+      &rbtree->rbt_nil || (ret = cb(rbtree, node, arg)) != NULL) {\t\\\n+        return (ret);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_prefix##reverse_iter_recurse(rbtree,\t\t\t\\\n+      rbtn_left_get(a_type, a_field, node), cb, arg));\t\t\\\n+    } else if (cmp < 0) {\t\t\t\t\t\t\\\n+    return (a_prefix##reverse_iter_start(rbtree, start,\t\t\\\n+      rbtn_left_get(a_type, a_field, node), cb, arg));\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if ((ret = cb(rbtree, node, arg)) != NULL) {\t\t\t\\\n+        return (ret);\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_prefix##reverse_iter_recurse(rbtree,\t\t\t\\\n+      rbtn_left_get(a_type, a_field, node), cb, arg));\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_prefix##reverse_iter(a_rbt_type *rbtree, a_type *start,\t\t\\\n+  a_type *(*cb)(a_rbt_type *, a_type *, void *), void *arg) {\t\t\\\n+    a_type *ret;\t\t\t\t\t\t\t\\\n+    if (start != NULL) {\t\t\t\t\t\t\\\n+    ret = a_prefix##reverse_iter_start(rbtree, start,\t\t\\\n+      rbtree->rbt_root, cb, arg);\t\t\t\t\t\\\n+    } else {\t\t\t\t\t\t\t\t\\\n+    ret = a_prefix##reverse_iter_recurse(rbtree, rbtree->rbt_root,\t\\\n+      cb, arg);\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    if (ret == &rbtree->rbt_nil) {\t\t\t\t\t\\\n+    ret = NULL;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\n+\n+#endif /* RB_H_ */"}, {"sha": "196d02717e9679c2dd12e940eb6bf8f8927efe2a", "filename": "src/rt/jemalloc/include/jemalloc/internal/rtree.h", "status": "added", "additions": 164, "deletions": 0, "changes": 164, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Frtree.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Frtree.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Frtree.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,164 @@\n+/*\n+ * This radix tree implementation is tailored to the singular purpose of\n+ * tracking which chunks are currently owned by jemalloc.  This functionality\n+ * is mandatory for OS X, where jemalloc must be able to respond to object\n+ * ownership queries.\n+ *\n+ *******************************************************************************\n+ */\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct rtree_s rtree_t;\n+\n+/*\n+ * Size of each radix tree node (must be a power of 2).  This impacts tree\n+ * depth.\n+ */\n+#if (LG_SIZEOF_PTR == 2)\n+#  define RTREE_NODESIZE (1U << 14)\n+#else\n+#  define RTREE_NODESIZE CACHELINE\n+#endif\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct rtree_s {\n+    malloc_mutex_t\tmutex;\n+    void\t\t**root;\n+    unsigned\theight;\n+    unsigned\tlevel2bits[1]; /* Dynamically sized. */\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+rtree_t\t*rtree_new(unsigned bits);\n+void\trtree_prefork(rtree_t *rtree);\n+void\trtree_postfork_parent(rtree_t *rtree);\n+void\trtree_postfork_child(rtree_t *rtree);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+#ifndef JEMALLOC_DEBUG\n+void\t*rtree_get_locked(rtree_t *rtree, uintptr_t key);\n+#endif\n+void\t*rtree_get(rtree_t *rtree, uintptr_t key);\n+bool\trtree_set(rtree_t *rtree, uintptr_t key, void *val);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_RTREE_C_))\n+#define\tRTREE_GET_GENERATE(f)\t\t\t\t\t\t\\\n+/* The least significant bits of the key are ignored. */\t\t\\\n+JEMALLOC_INLINE void *\t\t\t\t\t\t\t\\\n+f(rtree_t *rtree, uintptr_t key)\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    void *ret;\t\t\t\t\t\t\t\\\n+    uintptr_t subkey;\t\t\t\t\t\t\\\n+    unsigned i, lshift, height, bits;\t\t\t\t\\\n+    void **node, **child;\t\t\t\t\t\t\\\n+                                    \\\n+    RTREE_LOCK(&rtree->mutex);\t\t\t\t\t\\\n+    for (i = lshift = 0, height = rtree->height, node = rtree->root;\\\n+        i < height - 1;\t\t\t\t\t\t\\\n+        i++, lshift += bits, node = child) {\t\t\t\\\n+        bits = rtree->level2bits[i];\t\t\t\t\\\n+        subkey = (key << lshift) >> ((ZU(1) << (LG_SIZEOF_PTR + \\\n+            3)) - bits);\t\t\t\t\t\\\n+        child = (void**)node[subkey];\t\t\t\t\\\n+        if (child == NULL) {\t\t\t\t\t\\\n+            RTREE_UNLOCK(&rtree->mutex);\t\t\t\\\n+            return (NULL);\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    /*\t\t\t\t\t\t\t\t\\\n+     * node is a leaf, so it contains values rather than node\t\\\n+     * pointers.\t\t\t\t\t\t\t\\\n+     */\t\t\t\t\t\t\t\t\\\n+    bits = rtree->level2bits[i];\t\t\t\t\t\\\n+    subkey = (key << lshift) >> ((ZU(1) << (LG_SIZEOF_PTR+3)) -\t\\\n+        bits);\t\t\t\t\t\t\t\\\n+    ret = node[subkey];\t\t\t\t\t\t\\\n+    RTREE_UNLOCK(&rtree->mutex);\t\t\t\t\t\\\n+                                    \\\n+    RTREE_GET_VALIDATE\t\t\t\t\t\t\\\n+    return (ret);\t\t\t\t\t\t\t\\\n+}\n+\n+#ifdef JEMALLOC_DEBUG\n+#  define RTREE_LOCK(l)\t\tmalloc_mutex_lock(l)\n+#  define RTREE_UNLOCK(l)\tmalloc_mutex_unlock(l)\n+#  define RTREE_GET_VALIDATE\n+RTREE_GET_GENERATE(rtree_get_locked)\n+#  undef RTREE_LOCK\n+#  undef RTREE_UNLOCK\n+#  undef RTREE_GET_VALIDATE\n+#endif\n+\n+#define\tRTREE_LOCK(l)\n+#define\tRTREE_UNLOCK(l)\n+#ifdef JEMALLOC_DEBUG\n+   /*\n+    * Suppose that it were possible for a jemalloc-allocated chunk to be\n+    * munmap()ped, followed by a different allocator in another thread re-using\n+    * overlapping virtual memory, all without invalidating the cached rtree\n+    * value.  The result would be a false positive (the rtree would claim that\n+    * jemalloc owns memory that it had actually discarded).  This scenario\n+    * seems impossible, but the following assertion is a prudent sanity check.\n+    */\n+#  define RTREE_GET_VALIDATE\t\t\t\t\t\t\\\n+    assert(rtree_get_locked(rtree, key) == ret);\n+#else\n+#  define RTREE_GET_VALIDATE\n+#endif\n+RTREE_GET_GENERATE(rtree_get)\n+#undef RTREE_LOCK\n+#undef RTREE_UNLOCK\n+#undef RTREE_GET_VALIDATE\n+\n+JEMALLOC_INLINE bool\n+rtree_set(rtree_t *rtree, uintptr_t key, void *val)\n+{\n+    uintptr_t subkey;\n+    unsigned i, lshift, height, bits;\n+    void **node, **child;\n+\n+    malloc_mutex_lock(&rtree->mutex);\n+    for (i = lshift = 0, height = rtree->height, node = rtree->root;\n+        i < height - 1;\n+        i++, lshift += bits, node = child) {\n+        bits = rtree->level2bits[i];\n+        subkey = (key << lshift) >> ((ZU(1) << (LG_SIZEOF_PTR+3)) -\n+            bits);\n+        child = (void**)node[subkey];\n+        if (child == NULL) {\n+            child = (void**)base_alloc(sizeof(void *) <<\n+                rtree->level2bits[i+1]);\n+            if (child == NULL) {\n+                malloc_mutex_unlock(&rtree->mutex);\n+                return (true);\n+            }\n+            memset(child, 0, sizeof(void *) <<\n+                rtree->level2bits[i+1]);\n+            node[subkey] = child;\n+        }\n+    }\n+\n+    /* node is a leaf, so it contains values rather than node pointers. */\n+    bits = rtree->level2bits[i];\n+    subkey = (key << lshift) >> ((ZU(1) << (LG_SIZEOF_PTR+3)) - bits);\n+    node[subkey] = val;\n+    malloc_mutex_unlock(&rtree->mutex);\n+\n+    return (false);\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "29c80c1fb8d1bdfd7ebe880043a2d06aa367f4d4", "filename": "src/rt/jemalloc/include/jemalloc/internal/size_classes.sh", "status": "added", "additions": 122, "deletions": 0, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fsize_classes.sh", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fsize_classes.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fsize_classes.sh?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,122 @@\n+#!/bin/sh\n+\n+# The following limits are chosen such that they cover all supported platforms.\n+\n+# Range of quanta.\n+lg_qmin=3\n+lg_qmax=4\n+\n+# The range of tiny size classes is [2^lg_tmin..2^(lg_q-1)].\n+lg_tmin=3\n+\n+# Range of page sizes.\n+lg_pmin=12\n+lg_pmax=16\n+\n+pow2() {\n+  e=$1\n+  pow2_result=1\n+  while [ ${e} -gt 0 ] ; do\n+    pow2_result=$((${pow2_result} + ${pow2_result}))\n+    e=$((${e} - 1))\n+  done\n+}\n+\n+cat <<EOF\n+/* This file was automatically generated by size_classes.sh. */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+EOF\n+\n+lg_q=${lg_qmin}\n+while [ ${lg_q} -le ${lg_qmax} ] ; do\n+  lg_t=${lg_tmin}\n+  while [ ${lg_t} -le ${lg_q} ] ; do\n+    lg_p=${lg_pmin}\n+    while [ ${lg_p} -le ${lg_pmax} ] ; do\n+      echo \"#if (LG_TINY_MIN == ${lg_t} && LG_QUANTUM == ${lg_q} && LG_PAGE == ${lg_p})\"\n+      echo \"#define\tSIZE_CLASSES_DEFINED\"\n+      pow2 ${lg_q}; q=${pow2_result}\n+      pow2 ${lg_t}; t=${pow2_result}\n+      pow2 ${lg_p}; p=${pow2_result}\n+      bin=0\n+      psz=0\n+      sz=${t}\n+      delta=$((${sz} - ${psz}))\n+      echo \"/*  SIZE_CLASS(bin,\tdelta,\tsz) */\"\n+      echo \"#define\tSIZE_CLASSES\t\t\t\t\t\t\t\\\\\"\n+\n+      # Tiny size classes.\n+      while [ ${sz} -lt ${q} ] ; do\n+        echo \"    SIZE_CLASS(${bin},\t${delta},\t${sz})\t\t\t\t\t\\\\\"\n+        bin=$((${bin} + 1))\n+        psz=${sz}\n+        sz=$((${sz} + ${sz}))\n+        delta=$((${sz} - ${psz}))\n+      done\n+      # Quantum-multiple size classes.  For each doubling of sz, as many as 4\n+      # size classes exist.  Their spacing is the greater of:\n+      # - q\n+      # - sz/4, where sz is a power of 2\n+      while [ ${sz} -lt ${p} ] ; do\n+        if [ ${sz} -ge $((${q} * 4)) ] ; then\n+          i=$((${sz} / 4))\n+        else\n+          i=${q}\n+        fi\n+        next_2pow=$((${sz} * 2))\n+        while [ ${sz} -lt $next_2pow ] ; do\n+          echo \"    SIZE_CLASS(${bin},\t${delta},\t${sz})\t\t\t\t\t\\\\\"\n+          bin=$((${bin} + 1))\n+          psz=${sz}\n+          sz=$((${sz} + ${i}))\n+          delta=$((${sz} - ${psz}))\n+        done\n+      done\n+      echo\n+      echo \"#define\tNBINS\t\t${bin}\"\n+      echo \"#define\tSMALL_MAXCLASS\t${psz}\"\n+      echo \"#endif\"\n+      echo\n+      lg_p=$((${lg_p} + 1))\n+    done\n+    lg_t=$((${lg_t} + 1))\n+  done\n+  lg_q=$((${lg_q} + 1))\n+done\n+\n+cat <<EOF\n+#ifndef SIZE_CLASSES_DEFINED\n+#  error \"No size class definitions match configuration\"\n+#endif\n+#undef SIZE_CLASSES_DEFINED\n+/*\n+ * The small_size2bin lookup table uses uint8_t to encode each bin index, so we\n+ * cannot support more than 256 small size classes.  Further constrain NBINS to\n+ * 255 to support prof_promote, since all small size classes, plus a \"not\n+ * small\" size class must be stored in 8 bits of arena_chunk_map_t's bits\n+ * field.\n+ */\n+#if (NBINS > 255)\n+#  error \"Too many small size classes\"\n+#endif\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/\n+EOF"}, {"sha": "302c809195bb247bdae0abb0fffd6920fa233bc1", "filename": "src/rt/jemalloc/include/jemalloc/internal/stats.h", "status": "added", "additions": 173, "deletions": 0, "changes": 173, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fstats.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fstats.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Fstats.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,173 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct tcache_bin_stats_s tcache_bin_stats_t;\n+typedef struct malloc_bin_stats_s malloc_bin_stats_t;\n+typedef struct malloc_large_stats_s malloc_large_stats_t;\n+typedef struct arena_stats_s arena_stats_t;\n+typedef struct chunk_stats_s chunk_stats_t;\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+struct tcache_bin_stats_s {\n+    /*\n+     * Number of allocation requests that corresponded to the size of this\n+     * bin.\n+     */\n+    uint64_t\tnrequests;\n+};\n+\n+struct malloc_bin_stats_s {\n+    /*\n+     * Current number of bytes allocated, including objects currently\n+     * cached by tcache.\n+     */\n+    size_t\t\tallocated;\n+\n+    /*\n+     * Total number of allocation/deallocation requests served directly by\n+     * the bin.  Note that tcache may allocate an object, then recycle it\n+     * many times, resulting many increments to nrequests, but only one\n+     * each to nmalloc and ndalloc.\n+     */\n+    uint64_t\tnmalloc;\n+    uint64_t\tndalloc;\n+\n+    /*\n+     * Number of allocation requests that correspond to the size of this\n+     * bin.  This includes requests served by tcache, though tcache only\n+     * periodically merges into this counter.\n+     */\n+    uint64_t\tnrequests;\n+\n+    /* Number of tcache fills from this bin. */\n+    uint64_t\tnfills;\n+\n+    /* Number of tcache flushes to this bin. */\n+    uint64_t\tnflushes;\n+\n+    /* Total number of runs created for this bin's size class. */\n+    uint64_t\tnruns;\n+\n+    /*\n+     * Total number of runs reused by extracting them from the runs tree for\n+     * this bin's size class.\n+     */\n+    uint64_t\treruns;\n+\n+    /* Current number of runs in this bin. */\n+    size_t\t\tcurruns;\n+};\n+\n+struct malloc_large_stats_s {\n+    /*\n+     * Total number of allocation/deallocation requests served directly by\n+     * the arena.  Note that tcache may allocate an object, then recycle it\n+     * many times, resulting many increments to nrequests, but only one\n+     * each to nmalloc and ndalloc.\n+     */\n+    uint64_t\tnmalloc;\n+    uint64_t\tndalloc;\n+\n+    /*\n+     * Number of allocation requests that correspond to this size class.\n+     * This includes requests served by tcache, though tcache only\n+     * periodically merges into this counter.\n+     */\n+    uint64_t\tnrequests;\n+\n+    /* Current number of runs of this size class. */\n+    size_t\t\tcurruns;\n+};\n+\n+struct arena_stats_s {\n+    /* Number of bytes currently mapped. */\n+    size_t\t\tmapped;\n+\n+    /*\n+     * Total number of purge sweeps, total number of madvise calls made,\n+     * and total pages purged in order to keep dirty unused memory under\n+     * control.\n+     */\n+    uint64_t\tnpurge;\n+    uint64_t\tnmadvise;\n+    uint64_t\tpurged;\n+\n+    /* Per-size-category statistics. */\n+    size_t\t\tallocated_large;\n+    uint64_t\tnmalloc_large;\n+    uint64_t\tndalloc_large;\n+    uint64_t\tnrequests_large;\n+\n+    /*\n+     * One element for each possible size class, including sizes that\n+     * overlap with bin size classes.  This is necessary because ipalloc()\n+     * sometimes has to use such large objects in order to assure proper\n+     * alignment.\n+     */\n+    malloc_large_stats_t\t*lstats;\n+};\n+\n+struct chunk_stats_s {\n+    /* Number of chunks that were allocated. */\n+    uint64_t\tnchunks;\n+\n+    /* High-water mark for number of chunks allocated. */\n+    size_t\t\thighchunks;\n+\n+    /*\n+     * Current number of chunks allocated.  This value isn't maintained for\n+     * any other purpose, so keep track of it in order to be able to set\n+     * highchunks.\n+     */\n+    size_t\t\tcurchunks;\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+extern bool\topt_stats_print;\n+\n+extern size_t\tstats_cactive;\n+\n+void\tstats_print(void (*write)(void *, const char *), void *cbopaque,\n+    const char *opts);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+size_t\tstats_cactive_get(void);\n+void\tstats_cactive_add(size_t size);\n+void\tstats_cactive_sub(size_t size);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_STATS_C_))\n+JEMALLOC_INLINE size_t\n+stats_cactive_get(void)\n+{\n+\n+    return (atomic_read_z(&stats_cactive));\n+}\n+\n+JEMALLOC_INLINE void\n+stats_cactive_add(size_t size)\n+{\n+\n+    atomic_add_z(&stats_cactive, size);\n+}\n+\n+JEMALLOC_INLINE void\n+stats_cactive_sub(size_t size)\n+{\n+\n+    atomic_sub_z(&stats_cactive, size);\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "686412fb115c7380b7dc42327c4262e9275a49e5", "filename": "src/rt/jemalloc/include/jemalloc/internal/tcache.h", "status": "added", "additions": 442, "deletions": 0, "changes": 442, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Ftcache.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Ftcache.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Ftcache.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,442 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+typedef struct tcache_bin_info_s tcache_bin_info_t;\n+typedef struct tcache_bin_s tcache_bin_t;\n+typedef struct tcache_s tcache_t;\n+\n+/*\n+ * tcache pointers close to NULL are used to encode state information that is\n+ * used for two purposes: preventing thread caching on a per thread basis and\n+ * cleaning up during thread shutdown.\n+ */\n+#define\tTCACHE_STATE_DISABLED\t\t((tcache_t *)(uintptr_t)1)\n+#define\tTCACHE_STATE_REINCARNATED\t((tcache_t *)(uintptr_t)2)\n+#define\tTCACHE_STATE_PURGATORY\t\t((tcache_t *)(uintptr_t)3)\n+#define\tTCACHE_STATE_MAX\t\tTCACHE_STATE_PURGATORY\n+\n+/*\n+ * Absolute maximum number of cache slots for each small bin in the thread\n+ * cache.  This is an additional constraint beyond that imposed as: twice the\n+ * number of regions per run for this size class.\n+ *\n+ * This constant must be an even number.\n+ */\n+#define\tTCACHE_NSLOTS_SMALL_MAX\t\t200\n+\n+/* Number of cache slots for large size classes. */\n+#define\tTCACHE_NSLOTS_LARGE\t\t20\n+\n+/* (1U << opt_lg_tcache_max) is used to compute tcache_maxclass. */\n+#define\tLG_TCACHE_MAXCLASS_DEFAULT\t15\n+\n+/*\n+ * TCACHE_GC_SWEEP is the approximate number of allocation events between\n+ * full GC sweeps.  Integer rounding may cause the actual number to be\n+ * slightly higher, since GC is performed incrementally.\n+ */\n+#define\tTCACHE_GC_SWEEP\t\t\t8192\n+\n+/* Number of tcache allocation/deallocation events between incremental GCs. */\n+#define\tTCACHE_GC_INCR\t\t\t\t\t\t\t\\\n+    ((TCACHE_GC_SWEEP / NBINS) + ((TCACHE_GC_SWEEP / NBINS == 0) ? 0 : 1))\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+typedef enum {\n+    tcache_enabled_false   = 0, /* Enable cast to/from bool. */\n+    tcache_enabled_true    = 1,\n+    tcache_enabled_default = 2\n+} tcache_enabled_t;\n+\n+/*\n+ * Read-only information associated with each element of tcache_t's tbins array\n+ * is stored separately, mainly to reduce memory usage.\n+ */\n+struct tcache_bin_info_s {\n+    unsigned\tncached_max;\t/* Upper limit on ncached. */\n+};\n+\n+struct tcache_bin_s {\n+    tcache_bin_stats_t tstats;\n+    int\t\tlow_water;\t/* Min # cached since last GC. */\n+    unsigned\tlg_fill_div;\t/* Fill (ncached_max >> lg_fill_div). */\n+    unsigned\tncached;\t/* # of cached objects. */\n+    void\t\t**avail;\t/* Stack of available objects. */\n+};\n+\n+struct tcache_s {\n+    ql_elm(tcache_t) link;\t\t/* Used for aggregating stats. */\n+    uint64_t\tprof_accumbytes;/* Cleared after arena_prof_accum() */\n+    arena_t\t\t*arena;\t\t/* This thread's arena. */\n+    unsigned\tev_cnt;\t\t/* Event count since incremental GC. */\n+    unsigned\tnext_gc_bin;\t/* Next bin to GC. */\n+    tcache_bin_t\ttbins[1];\t/* Dynamically sized. */\n+    /*\n+     * The pointer stacks associated with tbins follow as a contiguous\n+     * array.  During tcache initialization, the avail pointer in each\n+     * element of tbins is initialized to point to the proper offset within\n+     * this array.\n+     */\n+};\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+extern bool\topt_tcache;\n+extern ssize_t\topt_lg_tcache_max;\n+\n+extern tcache_bin_info_t\t*tcache_bin_info;\n+\n+/*\n+ * Number of tcache bins.  There are NBINS small-object bins, plus 0 or more\n+ * large-object bins.\n+ */\n+extern size_t\t\t\tnhbins;\n+\n+/* Maximum cached size class. */\n+extern size_t\t\t\ttcache_maxclass;\n+\n+size_t\ttcache_salloc(const void *ptr);\n+void\ttcache_event_hard(tcache_t *tcache);\n+void\t*tcache_alloc_small_hard(tcache_t *tcache, tcache_bin_t *tbin,\n+    size_t binind);\n+void\ttcache_bin_flush_small(tcache_bin_t *tbin, size_t binind, unsigned rem,\n+    tcache_t *tcache);\n+void\ttcache_bin_flush_large(tcache_bin_t *tbin, size_t binind, unsigned rem,\n+    tcache_t *tcache);\n+void\ttcache_arena_associate(tcache_t *tcache, arena_t *arena);\n+void\ttcache_arena_dissociate(tcache_t *tcache);\n+tcache_t *tcache_create(arena_t *arena);\n+void\ttcache_destroy(tcache_t *tcache);\n+void\ttcache_thread_cleanup(void *arg);\n+void\ttcache_stats_merge(tcache_t *tcache, arena_t *arena);\n+bool\ttcache_boot0(void);\n+bool\ttcache_boot1(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+malloc_tsd_protos(JEMALLOC_ATTR(unused), tcache, tcache_t *)\n+malloc_tsd_protos(JEMALLOC_ATTR(unused), tcache_enabled, tcache_enabled_t)\n+\n+void\ttcache_event(tcache_t *tcache);\n+void\ttcache_flush(void);\n+bool\ttcache_enabled_get(void);\n+tcache_t *tcache_get(bool create);\n+void\ttcache_enabled_set(bool enabled);\n+void\t*tcache_alloc_easy(tcache_bin_t *tbin);\n+void\t*tcache_alloc_small(tcache_t *tcache, size_t size, bool zero);\n+void\t*tcache_alloc_large(tcache_t *tcache, size_t size, bool zero);\n+void\ttcache_dalloc_small(tcache_t *tcache, void *ptr, size_t binind);\n+void\ttcache_dalloc_large(tcache_t *tcache, void *ptr, size_t size);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_TCACHE_C_))\n+/* Map of thread-specific caches. */\n+malloc_tsd_externs(tcache, tcache_t *)\n+malloc_tsd_funcs(JEMALLOC_ALWAYS_INLINE, tcache, tcache_t *, NULL,\n+    tcache_thread_cleanup)\n+/* Per thread flag that allows thread caches to be disabled. */\n+malloc_tsd_externs(tcache_enabled, tcache_enabled_t)\n+malloc_tsd_funcs(JEMALLOC_ALWAYS_INLINE, tcache_enabled, tcache_enabled_t,\n+    tcache_enabled_default, malloc_tsd_no_cleanup)\n+\n+JEMALLOC_INLINE void\n+tcache_flush(void)\n+{\n+    tcache_t *tcache;\n+\n+    cassert(config_tcache);\n+\n+    tcache = *tcache_tsd_get();\n+    if ((uintptr_t)tcache <= (uintptr_t)TCACHE_STATE_MAX)\n+        return;\n+    tcache_destroy(tcache);\n+    tcache = NULL;\n+    tcache_tsd_set(&tcache);\n+}\n+\n+JEMALLOC_INLINE bool\n+tcache_enabled_get(void)\n+{\n+    tcache_enabled_t tcache_enabled;\n+\n+    cassert(config_tcache);\n+\n+    tcache_enabled = *tcache_enabled_tsd_get();\n+    if (tcache_enabled == tcache_enabled_default) {\n+        tcache_enabled = (tcache_enabled_t)opt_tcache;\n+        tcache_enabled_tsd_set(&tcache_enabled);\n+    }\n+\n+    return ((bool)tcache_enabled);\n+}\n+\n+JEMALLOC_INLINE void\n+tcache_enabled_set(bool enabled)\n+{\n+    tcache_enabled_t tcache_enabled;\n+    tcache_t *tcache;\n+\n+    cassert(config_tcache);\n+\n+    tcache_enabled = (tcache_enabled_t)enabled;\n+    tcache_enabled_tsd_set(&tcache_enabled);\n+    tcache = *tcache_tsd_get();\n+    if (enabled) {\n+        if (tcache == TCACHE_STATE_DISABLED) {\n+            tcache = NULL;\n+            tcache_tsd_set(&tcache);\n+        }\n+    } else /* disabled */ {\n+        if (tcache > TCACHE_STATE_MAX) {\n+            tcache_destroy(tcache);\n+            tcache = NULL;\n+        }\n+        if (tcache == NULL) {\n+            tcache = TCACHE_STATE_DISABLED;\n+            tcache_tsd_set(&tcache);\n+        }\n+    }\n+}\n+\n+JEMALLOC_ALWAYS_INLINE tcache_t *\n+tcache_get(bool create)\n+{\n+    tcache_t *tcache;\n+\n+    if (config_tcache == false)\n+        return (NULL);\n+    if (config_lazy_lock && isthreaded == false)\n+        return (NULL);\n+\n+    tcache = *tcache_tsd_get();\n+    if ((uintptr_t)tcache <= (uintptr_t)TCACHE_STATE_MAX) {\n+        if (tcache == TCACHE_STATE_DISABLED)\n+            return (NULL);\n+        if (tcache == NULL) {\n+            if (create == false) {\n+                /*\n+                 * Creating a tcache here would cause\n+                 * allocation as a side effect of free().\n+                 * Ordinarily that would be okay since\n+                 * tcache_create() failure is a soft failure\n+                 * that doesn't propagate.  However, if TLS\n+                 * data are freed via free() as in glibc,\n+                 * subtle corruption could result from setting\n+                 * a TLS variable after its backing memory is\n+                 * freed.\n+                 */\n+                return (NULL);\n+            }\n+            if (tcache_enabled_get() == false) {\n+                tcache_enabled_set(false); /* Memoize. */\n+                return (NULL);\n+            }\n+            return (tcache_create(choose_arena(NULL)));\n+        }\n+        if (tcache == TCACHE_STATE_PURGATORY) {\n+            /*\n+             * Make a note that an allocator function was called\n+             * after tcache_thread_cleanup() was called.\n+             */\n+            tcache = TCACHE_STATE_REINCARNATED;\n+            tcache_tsd_set(&tcache);\n+            return (NULL);\n+        }\n+        if (tcache == TCACHE_STATE_REINCARNATED)\n+            return (NULL);\n+        not_reached();\n+    }\n+\n+    return (tcache);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+tcache_event(tcache_t *tcache)\n+{\n+\n+    if (TCACHE_GC_INCR == 0)\n+        return;\n+\n+    tcache->ev_cnt++;\n+    assert(tcache->ev_cnt <= TCACHE_GC_INCR);\n+    if (tcache->ev_cnt == TCACHE_GC_INCR)\n+        tcache_event_hard(tcache);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+tcache_alloc_easy(tcache_bin_t *tbin)\n+{\n+    void *ret;\n+\n+    if (tbin->ncached == 0) {\n+        tbin->low_water = -1;\n+        return (NULL);\n+    }\n+    tbin->ncached--;\n+    if ((int)tbin->ncached < tbin->low_water)\n+        tbin->low_water = tbin->ncached;\n+    ret = tbin->avail[tbin->ncached];\n+    return (ret);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+tcache_alloc_small(tcache_t *tcache, size_t size, bool zero)\n+{\n+    void *ret;\n+    size_t binind;\n+    tcache_bin_t *tbin;\n+\n+    binind = SMALL_SIZE2BIN(size);\n+    assert(binind < NBINS);\n+    tbin = &tcache->tbins[binind];\n+    ret = tcache_alloc_easy(tbin);\n+    if (ret == NULL) {\n+        ret = tcache_alloc_small_hard(tcache, tbin, binind);\n+        if (ret == NULL)\n+            return (NULL);\n+    }\n+    assert(tcache_salloc(ret) == arena_bin_info[binind].reg_size);\n+\n+    if (zero == false) {\n+        if (config_fill) {\n+            if (opt_junk) {\n+                arena_alloc_junk_small(ret,\n+                    &arena_bin_info[binind], false);\n+            } else if (opt_zero)\n+                memset(ret, 0, size);\n+        }\n+    } else {\n+        if (config_fill && opt_junk) {\n+            arena_alloc_junk_small(ret, &arena_bin_info[binind],\n+                true);\n+        }\n+        VALGRIND_MAKE_MEM_UNDEFINED(ret, size);\n+        memset(ret, 0, size);\n+    }\n+    VALGRIND_MAKE_MEM_UNDEFINED(ret, size);\n+\n+    if (config_stats)\n+        tbin->tstats.nrequests++;\n+    if (config_prof)\n+        tcache->prof_accumbytes += arena_bin_info[binind].reg_size;\n+    tcache_event(tcache);\n+    return (ret);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void *\n+tcache_alloc_large(tcache_t *tcache, size_t size, bool zero)\n+{\n+    void *ret;\n+    size_t binind;\n+    tcache_bin_t *tbin;\n+\n+    size = PAGE_CEILING(size);\n+    assert(size <= tcache_maxclass);\n+    binind = NBINS + (size >> LG_PAGE) - 1;\n+    assert(binind < nhbins);\n+    tbin = &tcache->tbins[binind];\n+    ret = tcache_alloc_easy(tbin);\n+    if (ret == NULL) {\n+        /*\n+         * Only allocate one large object at a time, because it's quite\n+         * expensive to create one and not use it.\n+         */\n+        ret = arena_malloc_large(tcache->arena, size, zero);\n+        if (ret == NULL)\n+            return (NULL);\n+    } else {\n+        if (config_prof && prof_promote && size == PAGE) {\n+            arena_chunk_t *chunk =\n+                (arena_chunk_t *)CHUNK_ADDR2BASE(ret);\n+            size_t pageind = (((uintptr_t)ret - (uintptr_t)chunk) >>\n+                LG_PAGE);\n+            arena_mapbits_large_binind_set(chunk, pageind,\n+                BININD_INVALID);\n+        }\n+        if (zero == false) {\n+            if (config_fill) {\n+                if (opt_junk)\n+                    memset(ret, 0xa5, size);\n+                else if (opt_zero)\n+                    memset(ret, 0, size);\n+            }\n+        } else {\n+            VALGRIND_MAKE_MEM_UNDEFINED(ret, size);\n+            memset(ret, 0, size);\n+        }\n+        VALGRIND_MAKE_MEM_UNDEFINED(ret, size);\n+\n+        if (config_stats)\n+            tbin->tstats.nrequests++;\n+        if (config_prof)\n+            tcache->prof_accumbytes += size;\n+    }\n+\n+    tcache_event(tcache);\n+    return (ret);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+tcache_dalloc_small(tcache_t *tcache, void *ptr, size_t binind)\n+{\n+    tcache_bin_t *tbin;\n+    tcache_bin_info_t *tbin_info;\n+\n+    assert(tcache_salloc(ptr) <= SMALL_MAXCLASS);\n+\n+    if (config_fill && opt_junk)\n+        arena_dalloc_junk_small(ptr, &arena_bin_info[binind]);\n+\n+    tbin = &tcache->tbins[binind];\n+    tbin_info = &tcache_bin_info[binind];\n+    if (tbin->ncached == tbin_info->ncached_max) {\n+        tcache_bin_flush_small(tbin, binind, (tbin_info->ncached_max >>\n+            1), tcache);\n+    }\n+    assert(tbin->ncached < tbin_info->ncached_max);\n+    tbin->avail[tbin->ncached] = ptr;\n+    tbin->ncached++;\n+\n+    tcache_event(tcache);\n+}\n+\n+JEMALLOC_ALWAYS_INLINE void\n+tcache_dalloc_large(tcache_t *tcache, void *ptr, size_t size)\n+{\n+    size_t binind;\n+    tcache_bin_t *tbin;\n+    tcache_bin_info_t *tbin_info;\n+\n+    assert((size & PAGE_MASK) == 0);\n+    assert(tcache_salloc(ptr) > SMALL_MAXCLASS);\n+    assert(tcache_salloc(ptr) <= tcache_maxclass);\n+\n+    binind = NBINS + (size >> LG_PAGE) - 1;\n+\n+    if (config_fill && opt_junk)\n+        memset(ptr, 0x5a, size);\n+\n+    tbin = &tcache->tbins[binind];\n+    tbin_info = &tcache_bin_info[binind];\n+    if (tbin->ncached == tbin_info->ncached_max) {\n+        tcache_bin_flush_large(tbin, binind, (tbin_info->ncached_max >>\n+            1), tcache);\n+    }\n+    assert(tbin->ncached < tbin_info->ncached_max);\n+    tbin->avail[tbin->ncached] = ptr;\n+    tbin->ncached++;\n+\n+    tcache_event(tcache);\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "5ac96c92d4c119baa87ce98eb71282842d823367", "filename": "src/rt/jemalloc/include/jemalloc/internal/tsd.h", "status": "added", "additions": 397, "deletions": 0, "changes": 397, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Ftsd.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Ftsd.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Ftsd.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,397 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+/* Maximum number of malloc_tsd users with cleanup functions. */\n+#define\tMALLOC_TSD_CLEANUPS_MAX\t8\n+\n+typedef bool (*malloc_tsd_cleanup_t)(void);\n+\n+/*\n+ * TLS/TSD-agnostic macro-based implementation of thread-specific data.  There\n+ * are four macros that support (at least) three use cases: file-private,\n+ * library-private, and library-private inlined.  Following is an example\n+ * library-private tsd variable:\n+ *\n+ * In example.h:\n+ *   typedef struct {\n+ *           int x;\n+ *           int y;\n+ *   } example_t;\n+ *   #define EX_INITIALIZER JEMALLOC_CONCAT({0, 0})\n+ *   malloc_tsd_protos(, example, example_t *)\n+ *   malloc_tsd_externs(example, example_t *)\n+ * In example.c:\n+ *   malloc_tsd_data(, example, example_t *, EX_INITIALIZER)\n+ *   malloc_tsd_funcs(, example, example_t *, EX_INITIALIZER,\n+ *       example_tsd_cleanup)\n+ *\n+ * The result is a set of generated functions, e.g.:\n+ *\n+ *   bool example_tsd_boot(void) {...}\n+ *   example_t **example_tsd_get() {...}\n+ *   void example_tsd_set(example_t **val) {...}\n+ *\n+ * Note that all of the functions deal in terms of (a_type *) rather than\n+ * (a_type)  so that it is possible to support non-pointer types (unlike\n+ * pthreads TSD).  example_tsd_cleanup() is passed an (a_type *) pointer that is\n+ * cast to (void *).  This means that the cleanup function needs to cast *and*\n+ * dereference the function argument, e.g.:\n+ *\n+ *   void\n+ *   example_tsd_cleanup(void *arg)\n+ *   {\n+ *           example_t *example = *(example_t **)arg;\n+ *\n+ *           [...]\n+ *           if ([want the cleanup function to be called again]) {\n+ *                   example_tsd_set(&example);\n+ *           }\n+ *   }\n+ *\n+ * If example_tsd_set() is called within example_tsd_cleanup(), it will be\n+ * called again.  This is similar to how pthreads TSD destruction works, except\n+ * that pthreads only calls the cleanup function again if the value was set to\n+ * non-NULL.\n+ */\n+\n+/* malloc_tsd_protos(). */\n+#define\tmalloc_tsd_protos(a_attr, a_name, a_type)\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_boot(void);\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_get(void);\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_set(a_type *val);\n+\n+/* malloc_tsd_externs(). */\n+#ifdef JEMALLOC_MALLOC_THREAD_CLEANUP\n+#define\tmalloc_tsd_externs(a_name, a_type)\t\t\t\t\\\n+extern __thread a_type\ta_name##_tls;\t\t\t\t\t\\\n+extern __thread bool\ta_name##_initialized;\t\t\t\t\\\n+extern bool\t\ta_name##_booted;\n+#elif (defined(JEMALLOC_TLS))\n+#define\tmalloc_tsd_externs(a_name, a_type)\t\t\t\t\\\n+extern __thread a_type\ta_name##_tls;\t\t\t\t\t\\\n+extern pthread_key_t\ta_name##_tsd;\t\t\t\t\t\\\n+extern bool\t\ta_name##_booted;\n+#elif (defined(_WIN32))\n+#define malloc_tsd_externs(a_name, a_type)\t\t\t\t\\\n+extern DWORD\t\ta_name##_tsd;\t\t\t\t\t\\\n+extern bool\t\ta_name##_booted;\n+#else\n+#define\tmalloc_tsd_externs(a_name, a_type)\t\t\t\t\\\n+extern pthread_key_t\ta_name##_tsd;\t\t\t\t\t\\\n+extern bool\t\ta_name##_booted;\n+#endif\n+\n+/* malloc_tsd_data(). */\n+#ifdef JEMALLOC_MALLOC_THREAD_CLEANUP\n+#define\tmalloc_tsd_data(a_attr, a_name, a_type, a_initializer)\t\t\\\n+a_attr __thread a_type JEMALLOC_TLS_MODEL\t\t\t\t\\\n+    a_name##_tls = a_initializer;\t\t\t\t\t\\\n+a_attr __thread bool JEMALLOC_TLS_MODEL\t\t\t\t\t\\\n+    a_name##_initialized = false;\t\t\t\t\t\\\n+a_attr bool\t\ta_name##_booted = false;\n+#elif (defined(JEMALLOC_TLS))\n+#define\tmalloc_tsd_data(a_attr, a_name, a_type, a_initializer)\t\t\\\n+a_attr __thread a_type JEMALLOC_TLS_MODEL\t\t\t\t\\\n+    a_name##_tls = a_initializer;\t\t\t\t\t\\\n+a_attr pthread_key_t\ta_name##_tsd;\t\t\t\t\t\\\n+a_attr bool\t\ta_name##_booted = false;\n+#elif (defined(_WIN32))\n+#define\tmalloc_tsd_data(a_attr, a_name, a_type, a_initializer)\t\t\\\n+a_attr DWORD\t\ta_name##_tsd;\t\t\t\t\t\\\n+a_attr bool\t\ta_name##_booted = false;\n+#else\n+#define\tmalloc_tsd_data(a_attr, a_name, a_type, a_initializer)\t\t\\\n+a_attr pthread_key_t\ta_name##_tsd;\t\t\t\t\t\\\n+a_attr bool\t\ta_name##_booted = false;\n+#endif\n+\n+/* malloc_tsd_funcs(). */\n+#ifdef JEMALLOC_MALLOC_THREAD_CLEANUP\n+#define\tmalloc_tsd_funcs(a_attr, a_name, a_type, a_initializer,\t\t\\\n+    a_cleanup)\t\t\t\t\t\t\t\t\\\n+/* Initialization/cleanup. */\t\t\t\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_cleanup_wrapper(void)\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    if (a_name##_initialized) {\t\t\t\t\t\\\n+        a_name##_initialized = false;\t\t\t\t\\\n+        a_cleanup(&a_name##_tls);\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (a_name##_initialized);\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_boot(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    if (a_cleanup != malloc_tsd_no_cleanup) {\t\t\t\\\n+        malloc_tsd_cleanup_register(\t\t\t\t\\\n+            &a_name##_tsd_cleanup_wrapper);\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    a_name##_booted = true;\t\t\t\t\t\t\\\n+    return (false);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+/* Get/set. */\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_get(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    return (&a_name##_tls);\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_set(a_type *val)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    a_name##_tls = (*val);\t\t\t\t\t\t\\\n+    if (a_cleanup != malloc_tsd_no_cleanup)\t\t\t\t\\\n+        a_name##_initialized = true;\t\t\t\t\\\n+}\n+#elif (defined(JEMALLOC_TLS))\n+#define\tmalloc_tsd_funcs(a_attr, a_name, a_type, a_initializer,\t\t\\\n+    a_cleanup)\t\t\t\t\t\t\t\t\\\n+/* Initialization/cleanup. */\t\t\t\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_boot(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    if (a_cleanup != malloc_tsd_no_cleanup) {\t\t\t\\\n+        if (pthread_key_create(&a_name##_tsd, a_cleanup) != 0)\t\\\n+            return (true);\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    a_name##_booted = true;\t\t\t\t\t\t\\\n+    return (false);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+/* Get/set. */\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_get(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    return (&a_name##_tls);\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_set(a_type *val)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    a_name##_tls = (*val);\t\t\t\t\t\t\\\n+    if (a_cleanup != malloc_tsd_no_cleanup) {\t\t\t\\\n+        if (pthread_setspecific(a_name##_tsd,\t\t\t\\\n+            (void *)(&a_name##_tls))) {\t\t\t\t\\\n+            malloc_write(\"<jemalloc>: Error\"\t\t\\\n+                \" setting TSD for \"#a_name\"\\n\");\t\t\\\n+            if (opt_abort)\t\t\t\t\t\\\n+                abort();\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+}\n+#elif (defined(_WIN32))\n+#define\tmalloc_tsd_funcs(a_attr, a_name, a_type, a_initializer,\t\t\\\n+    a_cleanup)\t\t\t\t\t\t\t\t\\\n+/* Data structure. */\t\t\t\t\t\t\t\\\n+typedef struct {\t\t\t\t\t\t\t\\\n+    bool\tinitialized;\t\t\t\t\t\t\\\n+    a_type\tval;\t\t\t\t\t\t\t\\\n+} a_name##_tsd_wrapper_t;\t\t\t\t\t\t\\\n+/* Initialization/cleanup. */\t\t\t\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_cleanup_wrapper(void)\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper;\t\t\t\t\\\n+                                    \\\n+    wrapper = (a_name##_tsd_wrapper_t *) TlsGetValue(a_name##_tsd);\t\\\n+    if (wrapper == NULL)\t\t\t\t\t\t\\\n+        return (false);\t\t\t\t\t\t\\\n+    if (a_cleanup != malloc_tsd_no_cleanup &&\t\t\t\\\n+        wrapper->initialized) {\t\t\t\t\t\\\n+        a_type val = wrapper->val;\t\t\t\t\\\n+        a_type tsd_static_data = a_initializer;\t\t\t\\\n+        wrapper->initialized = false;\t\t\t\t\\\n+        wrapper->val = tsd_static_data;\t\t\t\t\\\n+        a_cleanup(&val);\t\t\t\t\t\\\n+        if (wrapper->initialized) {\t\t\t\t\\\n+            /* Trigger another cleanup round. */\t\t\\\n+            return (true);\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    malloc_tsd_dalloc(wrapper);\t\t\t\t\t\\\n+    return (false);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_boot(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    a_name##_tsd = TlsAlloc();\t\t\t\t\t\\\n+    if (a_name##_tsd == TLS_OUT_OF_INDEXES)\t\t\t\t\\\n+        return (true);\t\t\t\t\t\t\\\n+    if (a_cleanup != malloc_tsd_no_cleanup) {\t\t\t\\\n+        malloc_tsd_cleanup_register(\t\t\t\t\\\n+            &a_name##_tsd_cleanup_wrapper);\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    a_name##_booted = true;\t\t\t\t\t\t\\\n+    return (false);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+/* Get/set. */\t\t\t\t\t\t\t\t\\\n+a_attr a_name##_tsd_wrapper_t *\t\t\t\t\t\t\\\n+a_name##_tsd_get_wrapper(void)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper = (a_name##_tsd_wrapper_t *)\t\\\n+        TlsGetValue(a_name##_tsd);\t\t\t\t\t\\\n+                                    \\\n+    if (wrapper == NULL) {\t\t\t\t\t\t\\\n+        wrapper = (a_name##_tsd_wrapper_t *)\t\t\t\\\n+            malloc_tsd_malloc(sizeof(a_name##_tsd_wrapper_t));\t\\\n+        if (wrapper == NULL) {\t\t\t\t\t\\\n+            malloc_write(\"<jemalloc>: Error allocating\"\t\\\n+                \" TSD for \"#a_name\"\\n\");\t\t\t\\\n+            abort();\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            static a_type tsd_static_data = a_initializer;\t\\\n+            wrapper->initialized = false;\t\t\t\\\n+            wrapper->val = tsd_static_data;\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        if (!TlsSetValue(a_name##_tsd, (void *)wrapper)) {\t\\\n+            malloc_write(\"<jemalloc>: Error setting\"\t\\\n+                \" TSD for \"#a_name\"\\n\");\t\t\t\\\n+            abort();\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (wrapper);\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_get(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper;\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    wrapper = a_name##_tsd_get_wrapper();\t\t\t\t\\\n+    return (&wrapper->val);\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_set(a_type *val)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper;\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    wrapper = a_name##_tsd_get_wrapper();\t\t\t\t\\\n+    wrapper->val = *(val);\t\t\t\t\t\t\\\n+    if (a_cleanup != malloc_tsd_no_cleanup)\t\t\t\t\\\n+        wrapper->initialized = true;\t\t\t\t\\\n+}\n+#else\n+#define\tmalloc_tsd_funcs(a_attr, a_name, a_type, a_initializer,\t\t\\\n+    a_cleanup)\t\t\t\t\t\t\t\t\\\n+/* Data structure. */\t\t\t\t\t\t\t\\\n+typedef struct {\t\t\t\t\t\t\t\\\n+    bool\tinitialized;\t\t\t\t\t\t\\\n+    a_type\tval;\t\t\t\t\t\t\t\\\n+} a_name##_tsd_wrapper_t;\t\t\t\t\t\t\\\n+/* Initialization/cleanup. */\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_cleanup_wrapper(void *arg)\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper = (a_name##_tsd_wrapper_t *)arg;\\\n+                                    \\\n+    if (a_cleanup != malloc_tsd_no_cleanup &&\t\t\t\\\n+        wrapper->initialized) {\t\t\t\t\t\\\n+        wrapper->initialized = false;\t\t\t\t\\\n+        a_cleanup(&wrapper->val);\t\t\t\t\\\n+        if (wrapper->initialized) {\t\t\t\t\\\n+            /* Trigger another cleanup round. */\t\t\\\n+            if (pthread_setspecific(a_name##_tsd,\t\t\\\n+                (void *)wrapper)) {\t\t\t\t\\\n+                malloc_write(\"<jemalloc>: Error\"\t\\\n+                    \" setting TSD for \"#a_name\"\\n\");\t\\\n+                if (opt_abort)\t\t\t\t\\\n+                    abort();\t\t\t\\\n+            }\t\t\t\t\t\t\\\n+            return;\t\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    malloc_tsd_dalloc(wrapper);\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr bool\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_boot(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+                                    \\\n+    if (pthread_key_create(&a_name##_tsd,\t\t\t\t\\\n+        a_name##_tsd_cleanup_wrapper) != 0)\t\t\t\t\\\n+        return (true);\t\t\t\t\t\t\\\n+    a_name##_booted = true;\t\t\t\t\t\t\\\n+    return (false);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+/* Get/set. */\t\t\t\t\t\t\t\t\\\n+a_attr a_name##_tsd_wrapper_t *\t\t\t\t\t\t\\\n+a_name##_tsd_get_wrapper(void)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper = (a_name##_tsd_wrapper_t *)\t\\\n+        pthread_getspecific(a_name##_tsd);\t\t\t\t\\\n+                                    \\\n+    if (wrapper == NULL) {\t\t\t\t\t\t\\\n+        wrapper = (a_name##_tsd_wrapper_t *)\t\t\t\\\n+            malloc_tsd_malloc(sizeof(a_name##_tsd_wrapper_t));\t\\\n+        if (wrapper == NULL) {\t\t\t\t\t\\\n+            malloc_write(\"<jemalloc>: Error allocating\"\t\\\n+                \" TSD for \"#a_name\"\\n\");\t\t\t\\\n+            abort();\t\t\t\t\t\\\n+        } else {\t\t\t\t\t\t\\\n+            static a_type tsd_static_data = a_initializer;\t\\\n+            wrapper->initialized = false;\t\t\t\\\n+            wrapper->val = tsd_static_data;\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+        if (pthread_setspecific(a_name##_tsd,\t\t\t\\\n+            (void *)wrapper)) {\t\t\t\t\t\\\n+            malloc_write(\"<jemalloc>: Error setting\"\t\\\n+                \" TSD for \"#a_name\"\\n\");\t\t\t\\\n+            abort();\t\t\t\t\t\\\n+        }\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+    return (wrapper);\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr a_type *\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_get(void)\t\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper;\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    wrapper = a_name##_tsd_get_wrapper();\t\t\t\t\\\n+    return (&wrapper->val);\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+a_attr void\t\t\t\t\t\t\t\t\\\n+a_name##_tsd_set(a_type *val)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+    a_name##_tsd_wrapper_t *wrapper;\t\t\t\t\\\n+                                    \\\n+    assert(a_name##_booted);\t\t\t\t\t\\\n+    wrapper = a_name##_tsd_get_wrapper();\t\t\t\t\\\n+    wrapper->val = *(val);\t\t\t\t\t\t\\\n+    if (a_cleanup != malloc_tsd_no_cleanup)\t\t\t\t\\\n+        wrapper->initialized = true;\t\t\t\t\\\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+void\t*malloc_tsd_malloc(size_t size);\n+void\tmalloc_tsd_dalloc(void *wrapper);\n+void\tmalloc_tsd_no_cleanup(void *);\n+void\tmalloc_tsd_cleanup_register(bool (*f)(void));\n+void\tmalloc_tsd_boot(void);\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "2fdf756667d1bb0eb5a1549a256a057caaf069f1", "filename": "src/rt/jemalloc/include/jemalloc/internal/util.h", "status": "added", "additions": 160, "deletions": 0, "changes": 160, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Futil.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Futil.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Finternal%2Futil.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,160 @@\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_TYPES\n+\n+/* Size of stack-allocated buffer passed to buferror(). */\n+#define\tBUFERROR_BUF\t\t64\n+\n+/*\n+ * Size of stack-allocated buffer used by malloc_{,v,vc}printf().  This must be\n+ * large enough for all possible uses within jemalloc.\n+ */\n+#define\tMALLOC_PRINTF_BUFSIZE\t4096\n+\n+/*\n+ * Wrap a cpp argument that contains commas such that it isn't broken up into\n+ * multiple arguments.\n+ */\n+#define JEMALLOC_CONCAT(...) __VA_ARGS__\n+\n+/*\n+ * Silence compiler warnings due to uninitialized values.  This is used\n+ * wherever the compiler fails to recognize that the variable is never used\n+ * uninitialized.\n+ */\n+#ifdef JEMALLOC_CC_SILENCE\n+#  define JEMALLOC_CC_SILENCE_INIT(v) = v\n+#else\n+#  define JEMALLOC_CC_SILENCE_INIT(v)\n+#endif\n+\n+/*\n+ * Define a custom assert() in order to reduce the chances of deadlock during\n+ * assertion failure.\n+ */\n+#ifndef assert\n+#define\tassert(e) do {\t\t\t\t\t\t\t\\\n+    if (config_debug && !(e)) {\t\t\t\t\t\\\n+        malloc_printf(\t\t\t\t\t\t\\\n+            \"<jemalloc>: %s:%d: Failed assertion: \\\"%s\\\"\\n\",\t\\\n+            __FILE__, __LINE__, #e);\t\t\t\t\\\n+        abort();\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+#endif\n+\n+/* Use to assert a particular configuration, e.g., cassert(config_debug). */\n+#define\tcassert(c) do {\t\t\t\t\t\t\t\\\n+    if ((c) == false)\t\t\t\t\t\t\\\n+        assert(false);\t\t\t\t\t\t\\\n+} while (0)\n+\n+#ifndef not_reached\n+#define\tnot_reached() do {\t\t\t\t\t\t\\\n+    if (config_debug) {\t\t\t\t\t\t\\\n+        malloc_printf(\t\t\t\t\t\t\\\n+            \"<jemalloc>: %s:%d: Unreachable code reached\\n\",\t\\\n+            __FILE__, __LINE__);\t\t\t\t\\\n+        abort();\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+#endif\n+\n+#ifndef not_implemented\n+#define\tnot_implemented() do {\t\t\t\t\t\t\\\n+    if (config_debug) {\t\t\t\t\t\t\\\n+        malloc_printf(\"<jemalloc>: %s:%d: Not implemented\\n\",\t\\\n+            __FILE__, __LINE__);\t\t\t\t\\\n+        abort();\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+} while (0)\n+#endif\n+\n+#define\tassert_not_implemented(e) do {\t\t\t\t\t\\\n+    if (config_debug && !(e))\t\t\t\t\t\\\n+        not_implemented();\t\t\t\t\t\\\n+} while (0)\n+\n+#endif /* JEMALLOC_H_TYPES */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_STRUCTS\n+\n+#endif /* JEMALLOC_H_STRUCTS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_EXTERNS\n+\n+int\tbuferror(char *buf, size_t buflen);\n+uintmax_t\tmalloc_strtoumax(const char *nptr, char **endptr, int base);\n+void\tmalloc_write(const char *s);\n+\n+/*\n+ * malloc_vsnprintf() supports a subset of snprintf(3) that avoids floating\n+ * point math.\n+ */\n+int\tmalloc_vsnprintf(char *str, size_t size, const char *format,\n+    va_list ap);\n+int\tmalloc_snprintf(char *str, size_t size, const char *format, ...)\n+    JEMALLOC_ATTR(format(printf, 3, 4));\n+void\tmalloc_vcprintf(void (*write_cb)(void *, const char *), void *cbopaque,\n+    const char *format, va_list ap);\n+void malloc_cprintf(void (*write)(void *, const char *), void *cbopaque,\n+    const char *format, ...) JEMALLOC_ATTR(format(printf, 3, 4));\n+void\tmalloc_printf(const char *format, ...)\n+    JEMALLOC_ATTR(format(printf, 1, 2));\n+\n+#endif /* JEMALLOC_H_EXTERNS */\n+/******************************************************************************/\n+#ifdef JEMALLOC_H_INLINES\n+\n+#ifndef JEMALLOC_ENABLE_INLINE\n+size_t\tpow2_ceil(size_t x);\n+void\tmalloc_write(const char *s);\n+void\tset_errno(int errnum);\n+int\tget_errno(void);\n+#endif\n+\n+#if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_UTIL_C_))\n+/* Compute the smallest power of 2 that is >= x. */\n+JEMALLOC_INLINE size_t\n+pow2_ceil(size_t x)\n+{\n+\n+    x--;\n+    x |= x >> 1;\n+    x |= x >> 2;\n+    x |= x >> 4;\n+    x |= x >> 8;\n+    x |= x >> 16;\n+#if (LG_SIZEOF_PTR == 3)\n+    x |= x >> 32;\n+#endif\n+    x++;\n+    return (x);\n+}\n+\n+/* Sets error code */\n+JEMALLOC_INLINE void\n+set_errno(int errnum)\n+{\n+\n+#ifdef _WIN32\n+    SetLastError(errnum);\n+#else\n+    errno = errnum;\n+#endif\n+}\n+\n+/* Get last error code */\n+JEMALLOC_INLINE int\n+get_errno(void)\n+{\n+\n+#ifdef _WIN32\n+    return (GetLastError());\n+#else\n+    return (errno);\n+#endif\n+}\n+#endif\n+\n+#endif /* JEMALLOC_H_INLINES */\n+/******************************************************************************/"}, {"sha": "31b1304a20a48cdde14d9dd3407b2e4f1cc6f06b", "filename": "src/rt/jemalloc/include/jemalloc/jemalloc.h.in", "status": "added", "additions": 157, "deletions": 0, "changes": 157, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Fjemalloc.h.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Fjemalloc.h.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Fjemalloc.h.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,157 @@\n+#ifndef JEMALLOC_H_\n+#define\tJEMALLOC_H_\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+#include <limits.h>\n+#include <strings.h>\n+\n+#define\tJEMALLOC_VERSION \"@jemalloc_version@\"\n+#define\tJEMALLOC_VERSION_MAJOR @jemalloc_version_major@\n+#define\tJEMALLOC_VERSION_MINOR @jemalloc_version_minor@\n+#define\tJEMALLOC_VERSION_BUGFIX @jemalloc_version_bugfix@\n+#define\tJEMALLOC_VERSION_NREV @jemalloc_version_nrev@\n+#define\tJEMALLOC_VERSION_GID \"@jemalloc_version_gid@\"\n+\n+#include \"jemalloc_defs@install_suffix@.h\"\n+\n+#ifdef JEMALLOC_EXPERIMENTAL\n+#define\tALLOCM_LG_ALIGN(la)\t(la)\n+#if LG_SIZEOF_PTR == 2\n+#define\tALLOCM_ALIGN(a)\t(ffs(a)-1)\n+#else\n+#define\tALLOCM_ALIGN(a)\t((a < (size_t)INT_MAX) ? ffs(a)-1 : ffs(a>>32)+31)\n+#endif\n+#define\tALLOCM_ZERO\t((int)0x40)\n+#define\tALLOCM_NO_MOVE\t((int)0x80)\n+/* Bias arena index bits so that 0 encodes \"ALLOCM_ARENA() unspecified\". */\n+#define\tALLOCM_ARENA(a)\t((int)(((a)+1) << 8))\n+\n+#define\tALLOCM_SUCCESS\t\t0\n+#define\tALLOCM_ERR_OOM\t\t1\n+#define\tALLOCM_ERR_NOT_MOVED\t2\n+#endif\n+\n+/*\n+ * The je_ prefix on the following public symbol declarations is an artifact of\n+ * namespace management, and should be omitted in application code unless\n+ * JEMALLOC_NO_DEMANGLE is defined (see below).\n+ */\n+extern JEMALLOC_EXPORT const char\t*je_malloc_conf;\n+extern JEMALLOC_EXPORT void\t\t(*je_malloc_message)(void *cbopaque,\n+    const char *s);\n+\n+JEMALLOC_EXPORT void\t*je_malloc(size_t size) JEMALLOC_ATTR(malloc);\n+JEMALLOC_EXPORT void\t*je_calloc(size_t num, size_t size)\n+    JEMALLOC_ATTR(malloc);\n+JEMALLOC_EXPORT int\tje_posix_memalign(void **memptr, size_t alignment,\n+    size_t size) JEMALLOC_ATTR(nonnull(1));\n+JEMALLOC_EXPORT void\t*je_aligned_alloc(size_t alignment, size_t size)\n+    JEMALLOC_ATTR(malloc);\n+JEMALLOC_EXPORT void\t*je_realloc(void *ptr, size_t size);\n+JEMALLOC_EXPORT void\tje_free(void *ptr);\n+\n+#ifdef JEMALLOC_OVERRIDE_MEMALIGN\n+JEMALLOC_EXPORT void *\tje_memalign(size_t alignment, size_t size)\n+    JEMALLOC_ATTR(malloc);\n+#endif\n+\n+#ifdef JEMALLOC_OVERRIDE_VALLOC\n+JEMALLOC_EXPORT void *\tje_valloc(size_t size) JEMALLOC_ATTR(malloc);\n+#endif\n+\n+JEMALLOC_EXPORT size_t\tje_malloc_usable_size(\n+    JEMALLOC_USABLE_SIZE_CONST void *ptr);\n+JEMALLOC_EXPORT void\tje_malloc_stats_print(void (*write_cb)(void *,\n+    const char *), void *je_cbopaque, const char *opts);\n+JEMALLOC_EXPORT int\tje_mallctl(const char *name, void *oldp,\n+    size_t *oldlenp, void *newp, size_t newlen);\n+JEMALLOC_EXPORT int\tje_mallctlnametomib(const char *name, size_t *mibp,\n+    size_t *miblenp);\n+JEMALLOC_EXPORT int\tje_mallctlbymib(const size_t *mib, size_t miblen,\n+    void *oldp, size_t *oldlenp, void *newp, size_t newlen);\n+\n+#ifdef JEMALLOC_EXPERIMENTAL\n+JEMALLOC_EXPORT int\tje_allocm(void **ptr, size_t *rsize, size_t size,\n+    int flags) JEMALLOC_ATTR(nonnull(1));\n+JEMALLOC_EXPORT int\tje_rallocm(void **ptr, size_t *rsize, size_t size,\n+    size_t extra, int flags) JEMALLOC_ATTR(nonnull(1));\n+JEMALLOC_EXPORT int\tje_sallocm(const void *ptr, size_t *rsize, int flags)\n+    JEMALLOC_ATTR(nonnull(1));\n+JEMALLOC_EXPORT int\tje_dallocm(void *ptr, int flags)\n+    JEMALLOC_ATTR(nonnull(1));\n+JEMALLOC_EXPORT int\tje_nallocm(size_t *rsize, size_t size, int flags);\n+#endif\n+\n+/*\n+ * By default application code must explicitly refer to mangled symbol names,\n+ * so that it is possible to use jemalloc in conjunction with another allocator\n+ * in the same application.  Define JEMALLOC_MANGLE in order to cause automatic\n+ * name mangling that matches the API prefixing that happened as a result of\n+ * --with-mangling and/or --with-jemalloc-prefix configuration settings.\n+ */\n+#ifdef JEMALLOC_MANGLE\n+#ifndef JEMALLOC_NO_DEMANGLE\n+#define\tJEMALLOC_NO_DEMANGLE\n+#endif\n+#define\tmalloc_conf je_malloc_conf\n+#define\tmalloc_message je_malloc_message\n+#define\tmalloc je_malloc\n+#define\tcalloc je_calloc\n+#define\tposix_memalign je_posix_memalign\n+#define\taligned_alloc je_aligned_alloc\n+#define\trealloc je_realloc\n+#define\tfree je_free\n+#define\tmalloc_usable_size je_malloc_usable_size\n+#define\tmalloc_stats_print je_malloc_stats_print\n+#define\tmallctl je_mallctl\n+#define\tmallctlnametomib je_mallctlnametomib\n+#define\tmallctlbymib je_mallctlbymib\n+#define\tmemalign je_memalign\n+#define\tvalloc je_valloc\n+#ifdef JEMALLOC_EXPERIMENTAL\n+#define\tallocm je_allocm\n+#define\trallocm je_rallocm\n+#define\tsallocm je_sallocm\n+#define\tdallocm je_dallocm\n+#define\tnallocm je_nallocm\n+#endif\n+#endif\n+\n+/*\n+ * The je_* macros can be used as stable alternative names for the public\n+ * jemalloc API if JEMALLOC_NO_DEMANGLE is defined.  This is primarily meant\n+ * for use in jemalloc itself, but it can be used by application code to\n+ * provide isolation from the name mangling specified via --with-mangling\n+ * and/or --with-jemalloc-prefix.\n+ */\n+#ifndef JEMALLOC_NO_DEMANGLE\n+#undef je_malloc_conf\n+#undef je_malloc_message\n+#undef je_malloc\n+#undef je_calloc\n+#undef je_posix_memalign\n+#undef je_aligned_alloc\n+#undef je_realloc\n+#undef je_free\n+#undef je_malloc_usable_size\n+#undef je_malloc_stats_print\n+#undef je_mallctl\n+#undef je_mallctlnametomib\n+#undef je_mallctlbymib\n+#undef je_memalign\n+#undef je_valloc\n+#ifdef JEMALLOC_EXPERIMENTAL\n+#undef je_allocm\n+#undef je_rallocm\n+#undef je_sallocm\n+#undef je_dallocm\n+#undef je_nallocm\n+#endif\n+#endif\n+\n+#ifdef __cplusplus\n+};\n+#endif\n+#endif /* JEMALLOC_H_ */"}, {"sha": "3fcf93ce5d2e7ec814ece167d04b6bda737e1dcf", "filename": "src/rt/jemalloc/include/jemalloc/jemalloc_defs.h.in", "status": "added", "additions": 267, "deletions": 0, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Fjemalloc_defs.h.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Fjemalloc_defs.h.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fjemalloc%2Fjemalloc_defs.h.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,267 @@\n+/*\n+ * If JEMALLOC_PREFIX is defined via --with-jemalloc-prefix, it will cause all\n+ * public APIs to be prefixed.  This makes it possible, with some care, to use\n+ * multiple allocators simultaneously.\n+ */\n+#undef JEMALLOC_PREFIX\n+#undef JEMALLOC_CPREFIX\n+\n+/*\n+ * Name mangling for public symbols is controlled by --with-mangling and\n+ * --with-jemalloc-prefix.  With default settings the je_ prefix is stripped by\n+ * these macro definitions.\n+ */\n+#undef je_malloc_conf\n+#undef je_malloc_message\n+#undef je_malloc\n+#undef je_calloc\n+#undef je_posix_memalign\n+#undef je_aligned_alloc\n+#undef je_realloc\n+#undef je_free\n+#undef je_malloc_usable_size\n+#undef je_malloc_stats_print\n+#undef je_mallctl\n+#undef je_mallctlnametomib\n+#undef je_mallctlbymib\n+#undef je_memalign\n+#undef je_valloc\n+#undef je_allocm\n+#undef je_rallocm\n+#undef je_sallocm\n+#undef je_dallocm\n+#undef je_nallocm\n+\n+/*\n+ * JEMALLOC_PRIVATE_NAMESPACE is used as a prefix for all library-private APIs.\n+ * For shared libraries, symbol visibility mechanisms prevent these symbols\n+ * from being exported, but for static libraries, naming collisions are a real\n+ * possibility.\n+ */\n+#undef JEMALLOC_PRIVATE_NAMESPACE\n+#undef JEMALLOC_N\n+\n+/*\n+ * Hyper-threaded CPUs may need a special instruction inside spin loops in\n+ * order to yield to another virtual CPU.\n+ */\n+#undef CPU_SPINWAIT\n+\n+/* Defined if the equivalent of FreeBSD's atomic(9) functions are available. */\n+#undef JEMALLOC_ATOMIC9\n+\n+/*\n+ * Defined if OSAtomic*() functions are available, as provided by Darwin, and\n+ * documented in the atomic(3) manual page.\n+ */\n+#undef JEMALLOC_OSATOMIC\n+\n+/*\n+ * Defined if __sync_add_and_fetch(uint32_t *, uint32_t) and\n+ * __sync_sub_and_fetch(uint32_t *, uint32_t) are available, despite\n+ * __GCC_HAVE_SYNC_COMPARE_AND_SWAP_4 not being defined (which means the\n+ * functions are defined in libgcc instead of being inlines)\n+ */\n+#undef JE_FORCE_SYNC_COMPARE_AND_SWAP_4\n+\n+/*\n+ * Defined if __sync_add_and_fetch(uint64_t *, uint64_t) and\n+ * __sync_sub_and_fetch(uint64_t *, uint64_t) are available, despite\n+ * __GCC_HAVE_SYNC_COMPARE_AND_SWAP_8 not being defined (which means the\n+ * functions are defined in libgcc instead of being inlines)\n+ */\n+#undef JE_FORCE_SYNC_COMPARE_AND_SWAP_8\n+\n+/*\n+ * Defined if OSSpin*() functions are available, as provided by Darwin, and\n+ * documented in the spinlock(3) manual page.\n+ */\n+#undef JEMALLOC_OSSPIN\n+\n+/*\n+ * Defined if _malloc_thread_cleanup() exists.  At least in the case of\n+ * FreeBSD, pthread_key_create() allocates, which if used during malloc\n+ * bootstrapping will cause recursion into the pthreads library.  Therefore, if\n+ * _malloc_thread_cleanup() exists, use it as the basis for thread cleanup in\n+ * malloc_tsd.\n+ */\n+#undef JEMALLOC_MALLOC_THREAD_CLEANUP\n+\n+/*\n+ * Defined if threaded initialization is known to be safe on this platform.\n+ * Among other things, it must be possible to initialize a mutex without\n+ * triggering allocation in order for threaded allocation to be safe.\n+ */\n+#undef JEMALLOC_THREADED_INIT\n+\n+/*\n+ * Defined if the pthreads implementation defines\n+ * _pthread_mutex_init_calloc_cb(), in which case the function is used in order\n+ * to avoid recursive allocation during mutex initialization.\n+ */\n+#undef JEMALLOC_MUTEX_INIT_CB\n+\n+/* Defined if __attribute__((...)) syntax is supported. */\n+#undef JEMALLOC_HAVE_ATTR\n+#ifdef JEMALLOC_HAVE_ATTR\n+#  define JEMALLOC_ATTR(s) __attribute__((s))\n+#  define JEMALLOC_EXPORT JEMALLOC_ATTR(visibility(\"default\"))\n+#  define JEMALLOC_ALIGNED(s) JEMALLOC_ATTR(aligned(s))\n+#  define JEMALLOC_SECTION(s) JEMALLOC_ATTR(section(s))\n+#  define JEMALLOC_NOINLINE JEMALLOC_ATTR(noinline)\n+#elif _MSC_VER\n+#  define JEMALLOC_ATTR(s)\n+#  ifdef DLLEXPORT\n+#    define JEMALLOC_EXPORT __declspec(dllexport)\n+#  else\n+#    define JEMALLOC_EXPORT __declspec(dllimport)\n+#  endif\n+#  define JEMALLOC_ALIGNED(s) __declspec(align(s))\n+#  define JEMALLOC_SECTION(s) __declspec(allocate(s))\n+#  define JEMALLOC_NOINLINE __declspec(noinline)\n+#else\n+#  define JEMALLOC_ATTR(s)\n+#  define JEMALLOC_EXPORT\n+#  define JEMALLOC_ALIGNED(s)\n+#  define JEMALLOC_SECTION(s)\n+#  define JEMALLOC_NOINLINE\n+#endif\n+\n+/* Defined if sbrk() is supported. */\n+#undef JEMALLOC_HAVE_SBRK\n+\n+/* Non-empty if the tls_model attribute is supported. */\n+#undef JEMALLOC_TLS_MODEL\n+\n+/* JEMALLOC_CC_SILENCE enables code that silences unuseful compiler warnings. */\n+#undef JEMALLOC_CC_SILENCE\n+\n+/*\n+ * JEMALLOC_DEBUG enables assertions and other sanity checks, and disables\n+ * inline functions.\n+ */\n+#undef JEMALLOC_DEBUG\n+\n+/* JEMALLOC_STATS enables statistics calculation. */\n+#undef JEMALLOC_STATS\n+\n+/* JEMALLOC_PROF enables allocation profiling. */\n+#undef JEMALLOC_PROF\n+\n+/* Use libunwind for profile backtracing if defined. */\n+#undef JEMALLOC_PROF_LIBUNWIND\n+\n+/* Use libgcc for profile backtracing if defined. */\n+#undef JEMALLOC_PROF_LIBGCC\n+\n+/* Use gcc intrinsics for profile backtracing if defined. */\n+#undef JEMALLOC_PROF_GCC\n+\n+/*\n+ * JEMALLOC_TCACHE enables a thread-specific caching layer for small objects.\n+ * This makes it possible to allocate/deallocate objects without any locking\n+ * when the cache is in the steady state.\n+ */\n+#undef JEMALLOC_TCACHE\n+\n+/*\n+ * JEMALLOC_DSS enables use of sbrk(2) to allocate chunks from the data storage\n+ * segment (DSS).\n+ */\n+#undef JEMALLOC_DSS\n+\n+/* Support memory filling (junk/zero/quarantine/redzone). */\n+#undef JEMALLOC_FILL\n+\n+/* Support the experimental API. */\n+#undef JEMALLOC_EXPERIMENTAL\n+\n+/* Support utrace(2)-based tracing. */\n+#undef JEMALLOC_UTRACE\n+\n+/* Support Valgrind. */\n+#undef JEMALLOC_VALGRIND\n+\n+/* Support optional abort() on OOM. */\n+#undef JEMALLOC_XMALLOC\n+\n+/* Support lazy locking (avoid locking unless a second thread is launched). */\n+#undef JEMALLOC_LAZY_LOCK\n+\n+/* One page is 2^STATIC_PAGE_SHIFT bytes. */\n+#undef STATIC_PAGE_SHIFT\n+\n+/*\n+ * If defined, use munmap() to unmap freed chunks, rather than storing them for\n+ * later reuse.  This is disabled by default on Linux because common sequences\n+ * of mmap()/munmap() calls will cause virtual memory map holes.\n+ */\n+#undef JEMALLOC_MUNMAP\n+\n+/*\n+ * If defined, use mremap(...MREMAP_FIXED...) for huge realloc().  This is\n+ * disabled by default because it is Linux-specific and it will cause virtual\n+ * memory map holes, much like munmap(2) does.\n+ */\n+#undef JEMALLOC_MREMAP\n+\n+/* TLS is used to map arenas and magazine caches to threads. */\n+#undef JEMALLOC_TLS\n+\n+/*\n+ * JEMALLOC_IVSALLOC enables ivsalloc(), which verifies that pointers reside\n+ * within jemalloc-owned chunks before dereferencing them.\n+ */\n+#undef JEMALLOC_IVSALLOC\n+\n+/*\n+ * Define overrides for non-standard allocator-related functions if they\n+ * are present on the system.\n+ */\n+#undef JEMALLOC_OVERRIDE_MEMALIGN\n+#undef JEMALLOC_OVERRIDE_VALLOC\n+\n+/*\n+ * At least Linux omits the \"const\" in:\n+ *\n+ *   size_t malloc_usable_size(const void *ptr);\n+ *\n+ * Match the operating system's prototype.\n+ */\n+#undef JEMALLOC_USABLE_SIZE_CONST\n+\n+/*\n+ * Darwin (OS X) uses zones to work around Mach-O symbol override shortcomings.\n+ */\n+#undef JEMALLOC_ZONE\n+#undef JEMALLOC_ZONE_VERSION\n+\n+/*\n+ * Methods for purging unused pages differ between operating systems.\n+ *\n+ *   madvise(..., MADV_DONTNEED) : On Linux, this immediately discards pages,\n+ *                                 such that new pages will be demand-zeroed if\n+ *                                 the address region is later touched.\n+ *   madvise(..., MADV_FREE) : On FreeBSD and Darwin, this marks pages as being\n+ *                             unused, such that they will be discarded rather\n+ *                             than swapped out.\n+ */\n+#undef JEMALLOC_PURGE_MADVISE_DONTNEED\n+#undef JEMALLOC_PURGE_MADVISE_FREE\n+\n+/*\n+ * Define if operating system has alloca.h header.\n+ */\n+#undef JEMALLOC_HAS_ALLOCA_H\n+\n+/* sizeof(void *) == 2^LG_SIZEOF_PTR. */\n+#undef LG_SIZEOF_PTR\n+\n+/* sizeof(int) == 2^LG_SIZEOF_INT. */\n+#undef LG_SIZEOF_INT\n+\n+/* sizeof(long) == 2^LG_SIZEOF_LONG. */\n+#undef LG_SIZEOF_LONG\n+\n+/* sizeof(intmax_t) == 2^LG_SIZEOF_INTMAX_T. */\n+#undef LG_SIZEOF_INTMAX_T"}, {"sha": "e7a9b35281ec0eae4f2139ce9e74cd4c8f400227", "filename": "src/rt/jemalloc/include/msvc_compat/inttypes.h", "status": "added", "additions": 313, "deletions": 0, "changes": 313, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Finttypes.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Finttypes.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Finttypes.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,313 @@\n+// ISO C9x  compliant inttypes.h for Microsoft Visual Studio\n+// Based on ISO/IEC 9899:TC2 Committee draft (May 6, 2005) WG14/N1124\n+//\n+//  Copyright (c) 2006 Alexander Chemeris\n+//\n+// Redistribution and use in source and binary forms, with or without\n+// modification, are permitted provided that the following conditions are met:\n+//\n+//   1. Redistributions of source code must retain the above copyright notice,\n+//      this list of conditions and the following disclaimer.\n+//\n+//   2. Redistributions in binary form must reproduce the above copyright\n+//      notice, this list of conditions and the following disclaimer in the\n+//      documentation and/or other materials provided with the distribution.\n+//\n+//   3. The name of the author may be used to endorse or promote products\n+//      derived from this software without specific prior written permission.\n+//\n+// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR IMPLIED\n+// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n+// MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO\n+// EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n+// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n+// OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n+// WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR\n+// OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n+// ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+//\n+///////////////////////////////////////////////////////////////////////////////\n+\n+#ifndef _MSC_VER // [\n+#error \"Use this header only with Microsoft Visual C++ compilers!\"\n+#endif // _MSC_VER ]\n+\n+#ifndef _MSC_INTTYPES_H_ // [\n+#define _MSC_INTTYPES_H_\n+\n+#if _MSC_VER > 1000\n+#pragma once\n+#endif\n+\n+#include \"stdint.h\"\n+\n+// 7.8 Format conversion of integer types\n+\n+typedef struct {\n+   intmax_t quot;\n+   intmax_t rem;\n+} imaxdiv_t;\n+\n+// 7.8.1 Macros for format specifiers\n+\n+#if !defined(__cplusplus) || defined(__STDC_FORMAT_MACROS) // [   See footnote 185 at page 198\n+\n+#ifdef _WIN64\n+#  define __PRI64_PREFIX        \"l\"\n+#  define __PRIPTR_PREFIX       \"l\"\n+#else\n+#  define __PRI64_PREFIX        \"ll\"\n+#  define __PRIPTR_PREFIX\n+#endif\n+\n+// The fprintf macros for signed integers are:\n+#define PRId8       \"d\"\n+#define PRIi8       \"i\"\n+#define PRIdLEAST8  \"d\"\n+#define PRIiLEAST8  \"i\"\n+#define PRIdFAST8   \"d\"\n+#define PRIiFAST8   \"i\"\n+\n+#define PRId16       \"hd\"\n+#define PRIi16       \"hi\"\n+#define PRIdLEAST16  \"hd\"\n+#define PRIiLEAST16  \"hi\"\n+#define PRIdFAST16   \"hd\"\n+#define PRIiFAST16   \"hi\"\n+\n+#define PRId32       \"d\"\n+#define PRIi32       \"i\"\n+#define PRIdLEAST32  \"d\"\n+#define PRIiLEAST32  \"i\"\n+#define PRIdFAST32   \"d\"\n+#define PRIiFAST32   \"i\"\n+\n+#define PRId64       __PRI64_PREFIX \"d\"\n+#define PRIi64       __PRI64_PREFIX \"i\"\n+#define PRIdLEAST64  __PRI64_PREFIX \"d\"\n+#define PRIiLEAST64  __PRI64_PREFIX \"i\"\n+#define PRIdFAST64   __PRI64_PREFIX \"d\"\n+#define PRIiFAST64   __PRI64_PREFIX \"i\"\n+\n+#define PRIdMAX     __PRI64_PREFIX \"d\"\n+#define PRIiMAX     __PRI64_PREFIX \"i\"\n+\n+#define PRIdPTR     __PRIPTR_PREFIX \"d\"\n+#define PRIiPTR     __PRIPTR_PREFIX \"i\"\n+\n+// The fprintf macros for unsigned integers are:\n+#define PRIo8       \"o\"\n+#define PRIu8       \"u\"\n+#define PRIx8       \"x\"\n+#define PRIX8       \"X\"\n+#define PRIoLEAST8  \"o\"\n+#define PRIuLEAST8  \"u\"\n+#define PRIxLEAST8  \"x\"\n+#define PRIXLEAST8  \"X\"\n+#define PRIoFAST8   \"o\"\n+#define PRIuFAST8   \"u\"\n+#define PRIxFAST8   \"x\"\n+#define PRIXFAST8   \"X\"\n+\n+#define PRIo16       \"ho\"\n+#define PRIu16       \"hu\"\n+#define PRIx16       \"hx\"\n+#define PRIX16       \"hX\"\n+#define PRIoLEAST16  \"ho\"\n+#define PRIuLEAST16  \"hu\"\n+#define PRIxLEAST16  \"hx\"\n+#define PRIXLEAST16  \"hX\"\n+#define PRIoFAST16   \"ho\"\n+#define PRIuFAST16   \"hu\"\n+#define PRIxFAST16   \"hx\"\n+#define PRIXFAST16   \"hX\"\n+\n+#define PRIo32       \"o\"\n+#define PRIu32       \"u\"\n+#define PRIx32       \"x\"\n+#define PRIX32       \"X\"\n+#define PRIoLEAST32  \"o\"\n+#define PRIuLEAST32  \"u\"\n+#define PRIxLEAST32  \"x\"\n+#define PRIXLEAST32  \"X\"\n+#define PRIoFAST32   \"o\"\n+#define PRIuFAST32   \"u\"\n+#define PRIxFAST32   \"x\"\n+#define PRIXFAST32   \"X\"\n+\n+#define PRIo64       __PRI64_PREFIX \"o\"\n+#define PRIu64       __PRI64_PREFIX \"u\"\n+#define PRIx64       __PRI64_PREFIX \"x\"\n+#define PRIX64       __PRI64_PREFIX \"X\"\n+#define PRIoLEAST64  __PRI64_PREFIX \"o\"\n+#define PRIuLEAST64  __PRI64_PREFIX \"u\"\n+#define PRIxLEAST64  __PRI64_PREFIX \"x\"\n+#define PRIXLEAST64  __PRI64_PREFIX \"X\"\n+#define PRIoFAST64   __PRI64_PREFIX \"o\"\n+#define PRIuFAST64   __PRI64_PREFIX \"u\"\n+#define PRIxFAST64   __PRI64_PREFIX \"x\"\n+#define PRIXFAST64   __PRI64_PREFIX \"X\"\n+\n+#define PRIoMAX     __PRI64_PREFIX \"o\"\n+#define PRIuMAX     __PRI64_PREFIX \"u\"\n+#define PRIxMAX     __PRI64_PREFIX \"x\"\n+#define PRIXMAX     __PRI64_PREFIX \"X\"\n+\n+#define PRIoPTR     __PRIPTR_PREFIX \"o\"\n+#define PRIuPTR     __PRIPTR_PREFIX \"u\"\n+#define PRIxPTR     __PRIPTR_PREFIX \"x\"\n+#define PRIXPTR     __PRIPTR_PREFIX \"X\"\n+\n+// The fscanf macros for signed integers are:\n+#define SCNd8       \"d\"\n+#define SCNi8       \"i\"\n+#define SCNdLEAST8  \"d\"\n+#define SCNiLEAST8  \"i\"\n+#define SCNdFAST8   \"d\"\n+#define SCNiFAST8   \"i\"\n+\n+#define SCNd16       \"hd\"\n+#define SCNi16       \"hi\"\n+#define SCNdLEAST16  \"hd\"\n+#define SCNiLEAST16  \"hi\"\n+#define SCNdFAST16   \"hd\"\n+#define SCNiFAST16   \"hi\"\n+\n+#define SCNd32       \"ld\"\n+#define SCNi32       \"li\"\n+#define SCNdLEAST32  \"ld\"\n+#define SCNiLEAST32  \"li\"\n+#define SCNdFAST32   \"ld\"\n+#define SCNiFAST32   \"li\"\n+\n+#define SCNd64       \"I64d\"\n+#define SCNi64       \"I64i\"\n+#define SCNdLEAST64  \"I64d\"\n+#define SCNiLEAST64  \"I64i\"\n+#define SCNdFAST64   \"I64d\"\n+#define SCNiFAST64   \"I64i\"\n+\n+#define SCNdMAX     \"I64d\"\n+#define SCNiMAX     \"I64i\"\n+\n+#ifdef _WIN64 // [\n+#  define SCNdPTR     \"I64d\"\n+#  define SCNiPTR     \"I64i\"\n+#else  // _WIN64 ][\n+#  define SCNdPTR     \"ld\"\n+#  define SCNiPTR     \"li\"\n+#endif  // _WIN64 ]\n+\n+// The fscanf macros for unsigned integers are:\n+#define SCNo8       \"o\"\n+#define SCNu8       \"u\"\n+#define SCNx8       \"x\"\n+#define SCNX8       \"X\"\n+#define SCNoLEAST8  \"o\"\n+#define SCNuLEAST8  \"u\"\n+#define SCNxLEAST8  \"x\"\n+#define SCNXLEAST8  \"X\"\n+#define SCNoFAST8   \"o\"\n+#define SCNuFAST8   \"u\"\n+#define SCNxFAST8   \"x\"\n+#define SCNXFAST8   \"X\"\n+\n+#define SCNo16       \"ho\"\n+#define SCNu16       \"hu\"\n+#define SCNx16       \"hx\"\n+#define SCNX16       \"hX\"\n+#define SCNoLEAST16  \"ho\"\n+#define SCNuLEAST16  \"hu\"\n+#define SCNxLEAST16  \"hx\"\n+#define SCNXLEAST16  \"hX\"\n+#define SCNoFAST16   \"ho\"\n+#define SCNuFAST16   \"hu\"\n+#define SCNxFAST16   \"hx\"\n+#define SCNXFAST16   \"hX\"\n+\n+#define SCNo32       \"lo\"\n+#define SCNu32       \"lu\"\n+#define SCNx32       \"lx\"\n+#define SCNX32       \"lX\"\n+#define SCNoLEAST32  \"lo\"\n+#define SCNuLEAST32  \"lu\"\n+#define SCNxLEAST32  \"lx\"\n+#define SCNXLEAST32  \"lX\"\n+#define SCNoFAST32   \"lo\"\n+#define SCNuFAST32   \"lu\"\n+#define SCNxFAST32   \"lx\"\n+#define SCNXFAST32   \"lX\"\n+\n+#define SCNo64       \"I64o\"\n+#define SCNu64       \"I64u\"\n+#define SCNx64       \"I64x\"\n+#define SCNX64       \"I64X\"\n+#define SCNoLEAST64  \"I64o\"\n+#define SCNuLEAST64  \"I64u\"\n+#define SCNxLEAST64  \"I64x\"\n+#define SCNXLEAST64  \"I64X\"\n+#define SCNoFAST64   \"I64o\"\n+#define SCNuFAST64   \"I64u\"\n+#define SCNxFAST64   \"I64x\"\n+#define SCNXFAST64   \"I64X\"\n+\n+#define SCNoMAX     \"I64o\"\n+#define SCNuMAX     \"I64u\"\n+#define SCNxMAX     \"I64x\"\n+#define SCNXMAX     \"I64X\"\n+\n+#ifdef _WIN64 // [\n+#  define SCNoPTR     \"I64o\"\n+#  define SCNuPTR     \"I64u\"\n+#  define SCNxPTR     \"I64x\"\n+#  define SCNXPTR     \"I64X\"\n+#else  // _WIN64 ][\n+#  define SCNoPTR     \"lo\"\n+#  define SCNuPTR     \"lu\"\n+#  define SCNxPTR     \"lx\"\n+#  define SCNXPTR     \"lX\"\n+#endif  // _WIN64 ]\n+\n+#endif // __STDC_FORMAT_MACROS ]\n+\n+// 7.8.2 Functions for greatest-width integer types\n+\n+// 7.8.2.1 The imaxabs function\n+#define imaxabs _abs64\n+\n+// 7.8.2.2 The imaxdiv function\n+\n+// This is modified version of div() function from Microsoft's div.c found\n+// in %MSVC.NET%\\crt\\src\\div.c\n+#ifdef STATIC_IMAXDIV // [\n+static\n+#else // STATIC_IMAXDIV ][\n+_inline\n+#endif // STATIC_IMAXDIV ]\n+imaxdiv_t __cdecl imaxdiv(intmax_t numer, intmax_t denom)\n+{\n+   imaxdiv_t result;\n+\n+   result.quot = numer / denom;\n+   result.rem = numer % denom;\n+\n+   if (numer < 0 && result.rem > 0) {\n+      // did division wrong; must fix up\n+      ++result.quot;\n+      result.rem -= denom;\n+   }\n+\n+   return result;\n+}\n+\n+// 7.8.2.3 The strtoimax and strtoumax functions\n+#define strtoimax _strtoi64\n+#define strtoumax _strtoui64\n+\n+// 7.8.2.4 The wcstoimax and wcstoumax functions\n+#define wcstoimax _wcstoi64\n+#define wcstoumax _wcstoui64\n+\n+\n+#endif // _MSC_INTTYPES_H_ ]"}, {"sha": "da9ee8b809b8b6bee0f4f0bc7e2feb3012976ddb", "filename": "src/rt/jemalloc/include/msvc_compat/stdbool.h", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstdbool.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstdbool.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstdbool.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,16 @@\n+#ifndef stdbool_h\n+#define stdbool_h\n+\n+#include <wtypes.h>\n+\n+/* MSVC doesn't define _Bool or bool in C, but does have BOOL */\n+/* Note this doesn't pass autoconf's test because (bool) 0.5 != true */\n+typedef BOOL _Bool;\n+\n+#define bool _Bool\n+#define true 1\n+#define false 0\n+\n+#define __bool_true_false_are_defined 1\n+\n+#endif /* stdbool_h */"}, {"sha": "c66fbb817c0d16f47edbb8e2adf0d78c3313ce8a", "filename": "src/rt/jemalloc/include/msvc_compat/stdint.h", "status": "added", "additions": 247, "deletions": 0, "changes": 247, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstdint.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstdint.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstdint.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,247 @@\n+// ISO C9x  compliant stdint.h for Microsoft Visual Studio\n+// Based on ISO/IEC 9899:TC2 Committee draft (May 6, 2005) WG14/N1124\n+//\n+//  Copyright (c) 2006-2008 Alexander Chemeris\n+//\n+// Redistribution and use in source and binary forms, with or without\n+// modification, are permitted provided that the following conditions are met:\n+//\n+//   1. Redistributions of source code must retain the above copyright notice,\n+//      this list of conditions and the following disclaimer.\n+//\n+//   2. Redistributions in binary form must reproduce the above copyright\n+//      notice, this list of conditions and the following disclaimer in the\n+//      documentation and/or other materials provided with the distribution.\n+//\n+//   3. The name of the author may be used to endorse or promote products\n+//      derived from this software without specific prior written permission.\n+//\n+// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR IMPLIED\n+// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n+// MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO\n+// EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n+// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n+// OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n+// WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR\n+// OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n+// ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+//\n+///////////////////////////////////////////////////////////////////////////////\n+\n+#ifndef _MSC_VER // [\n+#error \"Use this header only with Microsoft Visual C++ compilers!\"\n+#endif // _MSC_VER ]\n+\n+#ifndef _MSC_STDINT_H_ // [\n+#define _MSC_STDINT_H_\n+\n+#if _MSC_VER > 1000\n+#pragma once\n+#endif\n+\n+#include <limits.h>\n+\n+// For Visual Studio 6 in C++ mode and for many Visual Studio versions when\n+// compiling for ARM we should wrap <wchar.h> include with 'extern \"C++\" {}'\n+// or compiler give many errors like this:\n+//   error C2733: second C linkage of overloaded function 'wmemchr' not allowed\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+#  include <wchar.h>\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+// Define _W64 macros to mark types changing their size, like intptr_t.\n+#ifndef _W64\n+#  if !defined(__midl) && (defined(_X86_) || defined(_M_IX86)) && _MSC_VER >= 1300\n+#     define _W64 __w64\n+#  else\n+#     define _W64\n+#  endif\n+#endif\n+\n+\n+// 7.18.1 Integer types\n+\n+// 7.18.1.1 Exact-width integer types\n+\n+// Visual Studio 6 and Embedded Visual C++ 4 doesn't\n+// realize that, e.g. char has the same size as __int8\n+// so we give up on __intX for them.\n+#if (_MSC_VER < 1300)\n+   typedef signed char       int8_t;\n+   typedef signed short      int16_t;\n+   typedef signed int        int32_t;\n+   typedef unsigned char     uint8_t;\n+   typedef unsigned short    uint16_t;\n+   typedef unsigned int      uint32_t;\n+#else\n+   typedef signed __int8     int8_t;\n+   typedef signed __int16    int16_t;\n+   typedef signed __int32    int32_t;\n+   typedef unsigned __int8   uint8_t;\n+   typedef unsigned __int16  uint16_t;\n+   typedef unsigned __int32  uint32_t;\n+#endif\n+typedef signed __int64       int64_t;\n+typedef unsigned __int64     uint64_t;\n+\n+\n+// 7.18.1.2 Minimum-width integer types\n+typedef int8_t    int_least8_t;\n+typedef int16_t   int_least16_t;\n+typedef int32_t   int_least32_t;\n+typedef int64_t   int_least64_t;\n+typedef uint8_t   uint_least8_t;\n+typedef uint16_t  uint_least16_t;\n+typedef uint32_t  uint_least32_t;\n+typedef uint64_t  uint_least64_t;\n+\n+// 7.18.1.3 Fastest minimum-width integer types\n+typedef int8_t    int_fast8_t;\n+typedef int16_t   int_fast16_t;\n+typedef int32_t   int_fast32_t;\n+typedef int64_t   int_fast64_t;\n+typedef uint8_t   uint_fast8_t;\n+typedef uint16_t  uint_fast16_t;\n+typedef uint32_t  uint_fast32_t;\n+typedef uint64_t  uint_fast64_t;\n+\n+// 7.18.1.4 Integer types capable of holding object pointers\n+#ifdef _WIN64 // [\n+   typedef signed __int64    intptr_t;\n+   typedef unsigned __int64  uintptr_t;\n+#else // _WIN64 ][\n+   typedef _W64 signed int   intptr_t;\n+   typedef _W64 unsigned int uintptr_t;\n+#endif // _WIN64 ]\n+\n+// 7.18.1.5 Greatest-width integer types\n+typedef int64_t   intmax_t;\n+typedef uint64_t  uintmax_t;\n+\n+\n+// 7.18.2 Limits of specified-width integer types\n+\n+#if !defined(__cplusplus) || defined(__STDC_LIMIT_MACROS) // [   See footnote 220 at page 257 and footnote 221 at page 259\n+\n+// 7.18.2.1 Limits of exact-width integer types\n+#define INT8_MIN     ((int8_t)_I8_MIN)\n+#define INT8_MAX     _I8_MAX\n+#define INT16_MIN    ((int16_t)_I16_MIN)\n+#define INT16_MAX    _I16_MAX\n+#define INT32_MIN    ((int32_t)_I32_MIN)\n+#define INT32_MAX    _I32_MAX\n+#define INT64_MIN    ((int64_t)_I64_MIN)\n+#define INT64_MAX    _I64_MAX\n+#define UINT8_MAX    _UI8_MAX\n+#define UINT16_MAX   _UI16_MAX\n+#define UINT32_MAX   _UI32_MAX\n+#define UINT64_MAX   _UI64_MAX\n+\n+// 7.18.2.2 Limits of minimum-width integer types\n+#define INT_LEAST8_MIN    INT8_MIN\n+#define INT_LEAST8_MAX    INT8_MAX\n+#define INT_LEAST16_MIN   INT16_MIN\n+#define INT_LEAST16_MAX   INT16_MAX\n+#define INT_LEAST32_MIN   INT32_MIN\n+#define INT_LEAST32_MAX   INT32_MAX\n+#define INT_LEAST64_MIN   INT64_MIN\n+#define INT_LEAST64_MAX   INT64_MAX\n+#define UINT_LEAST8_MAX   UINT8_MAX\n+#define UINT_LEAST16_MAX  UINT16_MAX\n+#define UINT_LEAST32_MAX  UINT32_MAX\n+#define UINT_LEAST64_MAX  UINT64_MAX\n+\n+// 7.18.2.3 Limits of fastest minimum-width integer types\n+#define INT_FAST8_MIN    INT8_MIN\n+#define INT_FAST8_MAX    INT8_MAX\n+#define INT_FAST16_MIN   INT16_MIN\n+#define INT_FAST16_MAX   INT16_MAX\n+#define INT_FAST32_MIN   INT32_MIN\n+#define INT_FAST32_MAX   INT32_MAX\n+#define INT_FAST64_MIN   INT64_MIN\n+#define INT_FAST64_MAX   INT64_MAX\n+#define UINT_FAST8_MAX   UINT8_MAX\n+#define UINT_FAST16_MAX  UINT16_MAX\n+#define UINT_FAST32_MAX  UINT32_MAX\n+#define UINT_FAST64_MAX  UINT64_MAX\n+\n+// 7.18.2.4 Limits of integer types capable of holding object pointers\n+#ifdef _WIN64 // [\n+#  define INTPTR_MIN   INT64_MIN\n+#  define INTPTR_MAX   INT64_MAX\n+#  define UINTPTR_MAX  UINT64_MAX\n+#else // _WIN64 ][\n+#  define INTPTR_MIN   INT32_MIN\n+#  define INTPTR_MAX   INT32_MAX\n+#  define UINTPTR_MAX  UINT32_MAX\n+#endif // _WIN64 ]\n+\n+// 7.18.2.5 Limits of greatest-width integer types\n+#define INTMAX_MIN   INT64_MIN\n+#define INTMAX_MAX   INT64_MAX\n+#define UINTMAX_MAX  UINT64_MAX\n+\n+// 7.18.3 Limits of other integer types\n+\n+#ifdef _WIN64 // [\n+#  define PTRDIFF_MIN  _I64_MIN\n+#  define PTRDIFF_MAX  _I64_MAX\n+#else  // _WIN64 ][\n+#  define PTRDIFF_MIN  _I32_MIN\n+#  define PTRDIFF_MAX  _I32_MAX\n+#endif  // _WIN64 ]\n+\n+#define SIG_ATOMIC_MIN  INT_MIN\n+#define SIG_ATOMIC_MAX  INT_MAX\n+\n+#ifndef SIZE_MAX // [\n+#  ifdef _WIN64 // [\n+#     define SIZE_MAX  _UI64_MAX\n+#  else // _WIN64 ][\n+#     define SIZE_MAX  _UI32_MAX\n+#  endif // _WIN64 ]\n+#endif // SIZE_MAX ]\n+\n+// WCHAR_MIN and WCHAR_MAX are also defined in <wchar.h>\n+#ifndef WCHAR_MIN // [\n+#  define WCHAR_MIN  0\n+#endif  // WCHAR_MIN ]\n+#ifndef WCHAR_MAX // [\n+#  define WCHAR_MAX  _UI16_MAX\n+#endif  // WCHAR_MAX ]\n+\n+#define WINT_MIN  0\n+#define WINT_MAX  _UI16_MAX\n+\n+#endif // __STDC_LIMIT_MACROS ]\n+\n+\n+// 7.18.4 Limits of other integer types\n+\n+#if !defined(__cplusplus) || defined(__STDC_CONSTANT_MACROS) // [   See footnote 224 at page 260\n+\n+// 7.18.4.1 Macros for minimum-width integer constants\n+\n+#define INT8_C(val)  val##i8\n+#define INT16_C(val) val##i16\n+#define INT32_C(val) val##i32\n+#define INT64_C(val) val##i64\n+\n+#define UINT8_C(val)  val##ui8\n+#define UINT16_C(val) val##ui16\n+#define UINT32_C(val) val##ui32\n+#define UINT64_C(val) val##ui64\n+\n+// 7.18.4.2 Macros for greatest-width integer constants\n+#define INTMAX_C   INT64_C\n+#define UINTMAX_C  UINT64_C\n+\n+#endif // __STDC_CONSTANT_MACROS ]\n+\n+\n+#endif // _MSC_STDINT_H_ ]"}, {"sha": "1ca24fa0f9ee6e98a5224b20942a82d6e72c1c4f", "filename": "src/rt/jemalloc/include/msvc_compat/strings.h", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstrings.h", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstrings.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finclude%2Fmsvc_compat%2Fstrings.h?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,23 @@\n+#ifndef strings_h\n+#define strings_h\n+\n+/* MSVC doesn't define ffs/ffsl. This dummy strings.h header is provided\n+ * for both */\n+#include <intrin.h>\n+#pragma intrinsic(_BitScanForward)\n+static __forceinline int ffsl(long x)\n+{\n+    unsigned long i;\n+\n+    if (_BitScanForward(&i, x))\n+        return (i + 1);\n+    return (0);\n+}\n+\n+static __forceinline int ffs(int x)\n+{\n+\n+    return (ffsl(x));\n+}\n+\n+#endif"}, {"sha": "058b26c82d24335834ad0472109d0cbc1c829084", "filename": "src/rt/jemalloc/install-sh", "status": "added", "additions": 250, "deletions": 0, "changes": 250, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finstall-sh", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Finstall-sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Finstall-sh?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec", "patch": "@@ -0,0 +1,250 @@\n+#! /bin/sh\n+#\n+# install - install a program, script, or datafile\n+# This comes from X11R5 (mit/util/scripts/install.sh).\n+#\n+# Copyright 1991 by the Massachusetts Institute of Technology\n+#\n+# Permission to use, copy, modify, distribute, and sell this software and its\n+# documentation for any purpose is hereby granted without fee, provided that\n+# the above copyright notice appear in all copies and that both that\n+# copyright notice and this permission notice appear in supporting\n+# documentation, and that the name of M.I.T. not be used in advertising or\n+# publicity pertaining to distribution of the software without specific,\n+# written prior permission.  M.I.T. makes no representations about the\n+# suitability of this software for any purpose.  It is provided \"as is\"\n+# without express or implied warranty.\n+#\n+# Calling this script install-sh is preferred over install.sh, to prevent\n+# `make' implicit rules from creating a file called install from it\n+# when there is no Makefile.\n+#\n+# This script is compatible with the BSD install script, but was written\n+# from scratch.  It can only install one file at a time, a restriction\n+# shared with many OS's install programs.\n+\n+\n+# set DOITPROG to echo to test this script\n+\n+# Don't use :- since 4.3BSD and earlier shells don't like it.\n+doit=\"${DOITPROG-}\"\n+\n+\n+# put in absolute paths if you don't have them in your path; or use env. vars.\n+\n+mvprog=\"${MVPROG-mv}\"\n+cpprog=\"${CPPROG-cp}\"\n+chmodprog=\"${CHMODPROG-chmod}\"\n+chownprog=\"${CHOWNPROG-chown}\"\n+chgrpprog=\"${CHGRPPROG-chgrp}\"\n+stripprog=\"${STRIPPROG-strip}\"\n+rmprog=\"${RMPROG-rm}\"\n+mkdirprog=\"${MKDIRPROG-mkdir}\"\n+\n+transformbasename=\"\"\n+transform_arg=\"\"\n+instcmd=\"$mvprog\"\n+chmodcmd=\"$chmodprog 0755\"\n+chowncmd=\"\"\n+chgrpcmd=\"\"\n+stripcmd=\"\"\n+rmcmd=\"$rmprog -f\"\n+mvcmd=\"$mvprog\"\n+src=\"\"\n+dst=\"\"\n+dir_arg=\"\"\n+\n+while [ x\"$1\" != x ]; do\n+    case $1 in\n+\t-c) instcmd=\"$cpprog\"\n+\t    shift\n+\t    continue;;\n+\n+\t-d) dir_arg=true\n+\t    shift\n+\t    continue;;\n+\n+\t-m) chmodcmd=\"$chmodprog $2\"\n+\t    shift\n+\t    shift\n+\t    continue;;\n+\n+\t-o) chowncmd=\"$chownprog $2\"\n+\t    shift\n+\t    shift\n+\t    continue;;\n+\n+\t-g) chgrpcmd=\"$chgrpprog $2\"\n+\t    shift\n+\t    shift\n+\t    continue;;\n+\n+\t-s) stripcmd=\"$stripprog\"\n+\t    shift\n+\t    continue;;\n+\n+\t-t=*) transformarg=`echo $1 | sed 's/-t=//'`\n+\t    shift\n+\t    continue;;\n+\n+\t-b=*) transformbasename=`echo $1 | sed 's/-b=//'`\n+\t    shift\n+\t    continue;;\n+\n+\t*)  if [ x\"$src\" = x ]\n+\t    then\n+\t\tsrc=$1\n+\t    else\n+\t\t# this colon is to work around a 386BSD /bin/sh bug\n+\t\t:\n+\t\tdst=$1\n+\t    fi\n+\t    shift\n+\t    continue;;\n+    esac\n+done\n+\n+if [ x\"$src\" = x ]\n+then\n+\techo \"install:\tno input file specified\"\n+\texit 1\n+else\n+\ttrue\n+fi\n+\n+if [ x\"$dir_arg\" != x ]; then\n+\tdst=$src\n+\tsrc=\"\"\n+\n+\tif [ -d $dst ]; then\n+\t\tinstcmd=:\n+\telse\n+\t\tinstcmd=mkdir\n+\tfi\n+else\n+\n+# Waiting for this to be detected by the \"$instcmd $src $dsttmp\" command\n+# might cause directories to be created, which would be especially bad\n+# if $src (and thus $dsttmp) contains '*'.\n+\n+\tif [ -f $src -o -d $src ]\n+\tthen\n+\t\ttrue\n+\telse\n+\t\techo \"install:  $src does not exist\"\n+\t\texit 1\n+\tfi\n+\n+\tif [ x\"$dst\" = x ]\n+\tthen\n+\t\techo \"install:\tno destination specified\"\n+\t\texit 1\n+\telse\n+\t\ttrue\n+\tfi\n+\n+# If destination is a directory, append the input filename; if your system\n+# does not like double slashes in filenames, you may need to add some logic\n+\n+\tif [ -d $dst ]\n+\tthen\n+\t\tdst=\"$dst\"/`basename $src`\n+\telse\n+\t\ttrue\n+\tfi\n+fi\n+\n+## this sed command emulates the dirname command\n+dstdir=`echo $dst | sed -e 's,[^/]*$,,;s,/$,,;s,^$,.,'`\n+\n+# Make sure that the destination directory exists.\n+#  this part is taken from Noah Friedman's mkinstalldirs script\n+\n+# Skip lots of stat calls in the usual case.\n+if [ ! -d \"$dstdir\" ]; then\n+defaultIFS='\n+'\n+IFS=\"${IFS-${defaultIFS}}\"\n+\n+oIFS=\"${IFS}\"\n+# Some sh's can't handle IFS=/ for some reason.\n+IFS='%'\n+set - `echo ${dstdir} | sed -e 's@/@%@g' -e 's@^%@/@'`\n+IFS=\"${oIFS}\"\n+\n+pathcomp=''\n+\n+while [ $# -ne 0 ] ; do\n+\tpathcomp=\"${pathcomp}${1}\"\n+\tshift\n+\n+\tif [ ! -d \"${pathcomp}\" ] ;\n+        then\n+\t\t$mkdirprog \"${pathcomp}\"\n+\telse\n+\t\ttrue\n+\tfi\n+\n+\tpathcomp=\"${pathcomp}/\"\n+done\n+fi\n+\n+if [ x\"$dir_arg\" != x ]\n+then\n+\t$doit $instcmd $dst &&\n+\n+\tif [ x\"$chowncmd\" != x ]; then $doit $chowncmd $dst; else true ; fi &&\n+\tif [ x\"$chgrpcmd\" != x ]; then $doit $chgrpcmd $dst; else true ; fi &&\n+\tif [ x\"$stripcmd\" != x ]; then $doit $stripcmd $dst; else true ; fi &&\n+\tif [ x\"$chmodcmd\" != x ]; then $doit $chmodcmd $dst; else true ; fi\n+else\n+\n+# If we're going to rename the final executable, determine the name now.\n+\n+\tif [ x\"$transformarg\" = x ]\n+\tthen\n+\t\tdstfile=`basename $dst`\n+\telse\n+\t\tdstfile=`basename $dst $transformbasename |\n+\t\t\tsed $transformarg`$transformbasename\n+\tfi\n+\n+# don't allow the sed command to completely eliminate the filename\n+\n+\tif [ x\"$dstfile\" = x ]\n+\tthen\n+\t\tdstfile=`basename $dst`\n+\telse\n+\t\ttrue\n+\tfi\n+\n+# Make a temp file name in the proper directory.\n+\n+\tdsttmp=$dstdir/#inst.$$#\n+\n+# Move or copy the file name to the temp name\n+\n+\t$doit $instcmd $src $dsttmp &&\n+\n+\ttrap \"rm -f ${dsttmp}\" 0 &&\n+\n+# and set any options; do chmod last to preserve setuid bits\n+\n+# If any of these fail, we abort the whole thing.  If we want to\n+# ignore errors from any of these, just make sure not to ignore\n+# errors from the above \"$doit $instcmd $src $dsttmp\" command.\n+\n+\tif [ x\"$chowncmd\" != x ]; then $doit $chowncmd $dsttmp; else true;fi &&\n+\tif [ x\"$chgrpcmd\" != x ]; then $doit $chgrpcmd $dsttmp; else true;fi &&\n+\tif [ x\"$stripcmd\" != x ]; then $doit $stripcmd $dsttmp; else true;fi &&\n+\tif [ x\"$chmodcmd\" != x ]; then $doit $chmodcmd $dsttmp; else true;fi &&\n+\n+# Now rename the file to the real destination.\n+\n+\t$doit $rmcmd -f $dstdir/$dstfile &&\n+\t$doit $mvcmd $dsttmp $dstdir/$dstfile\n+\n+fi &&\n+\n+\n+exit 0"}, {"sha": "05a787f89d9ddf5dfea5e171f98fd10b36dd7e28", "filename": "src/rt/jemalloc/src/arena.c", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Farena.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Farena.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Farena.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "77ee313113bebafa760447e2b032a6bf8bce97a4", "filename": "src/rt/jemalloc/src/atomic.c", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fatomic.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fatomic.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fatomic.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "4e62e8fa9189fe9ebdcdbbe7e49e38c62cb5de62", "filename": "src/rt/jemalloc/src/base.c", "status": "added", "additions": 142, "deletions": 0, "changes": 142, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fbase.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fbase.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fbase.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "b47e2629093f771b23846a4c378e0de87c03b608", "filename": "src/rt/jemalloc/src/bitmap.c", "status": "added", "additions": 90, "deletions": 0, "changes": 90, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fbitmap.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fbitmap.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fbitmap.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "044f76be96c2949c83461dd29c6590eb4d9c1798", "filename": "src/rt/jemalloc/src/chunk.c", "status": "added", "additions": 385, "deletions": 0, "changes": 385, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "24781cc52dca76aef9a8e3a1ff86803af0718775", "filename": "src/rt/jemalloc/src/chunk_dss.c", "status": "added", "additions": 197, "deletions": 0, "changes": 197, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk_dss.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk_dss.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk_dss.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "8a42e75915f8ee9e627003adef015c205032e852", "filename": "src/rt/jemalloc/src/chunk_mmap.c", "status": "added", "additions": 210, "deletions": 0, "changes": 210, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk_mmap.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk_mmap.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fchunk_mmap.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "2f38348bb85d942804c9a8c14969c7a0690481d5", "filename": "src/rt/jemalloc/src/ckh.c", "status": "added", "additions": 563, "deletions": 0, "changes": 563, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fckh.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fckh.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fckh.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "f2ef4e606114692795616663346ef61b859efbae", "filename": "src/rt/jemalloc/src/ctl.c", "status": "added", "additions": 1673, "deletions": 0, "changes": 1673, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fctl.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fctl.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fctl.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "8c09b486ed819a4af685488031ed17e70498fcfd", "filename": "src/rt/jemalloc/src/extent.c", "status": "added", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fextent.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fextent.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fextent.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "cfa4da0275cbcb9764efcadb90a5e3e218bd961a", "filename": "src/rt/jemalloc/src/hash.c", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fhash.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fhash.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fhash.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "aa08d43d3626b934c41537faeeb994d07cfbbc04", "filename": "src/rt/jemalloc/src/huge.c", "status": "added", "additions": 313, "deletions": 0, "changes": 313, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fhuge.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fhuge.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fhuge.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "bc350ed953b43b71a66885a61bbcaaa199cff17b", "filename": "src/rt/jemalloc/src/jemalloc.c", "status": "added", "additions": 1868, "deletions": 0, "changes": 1868, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fjemalloc.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fjemalloc.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fjemalloc.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "dc2c0a256fde43d9756a0b6a4149ac1b8d923995", "filename": "src/rt/jemalloc/src/mb.c", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fmb.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fmb.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fmb.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "55e18c23713624a2f25fa7750d679d56a3bbcc30", "filename": "src/rt/jemalloc/src/mutex.c", "status": "added", "additions": 149, "deletions": 0, "changes": 149, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fmutex.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fmutex.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fmutex.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "c133b95c2c6c6a673ea9dffa64fe414b3dc8d3c2", "filename": "src/rt/jemalloc/src/prof.c", "status": "added", "additions": 1283, "deletions": 0, "changes": 1283, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fprof.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fprof.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fprof.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "f96a948d5c70ce0add26fc137e4e7d3f03812772", "filename": "src/rt/jemalloc/src/quarantine.c", "status": "added", "additions": 190, "deletions": 0, "changes": 190, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fquarantine.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fquarantine.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fquarantine.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "90c6935a0edd531f2b3d6169b3c14ae84fa76392", "filename": "src/rt/jemalloc/src/rtree.c", "status": "added", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Frtree.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Frtree.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Frtree.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "43f87af67000134b814934e4d3932f715074e040", "filename": "src/rt/jemalloc/src/stats.c", "status": "added", "additions": 549, "deletions": 0, "changes": 549, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fstats.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fstats.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fstats.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "98ed19edd52e9ab3afe3fa4038a80e9f4f4ea686", "filename": "src/rt/jemalloc/src/tcache.c", "status": "added", "additions": 476, "deletions": 0, "changes": 476, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Ftcache.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Ftcache.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Ftcache.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "961a546329c163ff669beca2bf9a38f8a89c6844", "filename": "src/rt/jemalloc/src/tsd.c", "status": "added", "additions": 107, "deletions": 0, "changes": 107, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Ftsd.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Ftsd.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Ftsd.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "b3a011436984f055d9d59dcc5c345d0ff6b3795f", "filename": "src/rt/jemalloc/src/util.c", "status": "added", "additions": 641, "deletions": 0, "changes": 641, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Futil.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Futil.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Futil.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "c62c183f65ea5c0cb61b68f372ec397f9d2c7390", "filename": "src/rt/jemalloc/src/zone.c", "status": "added", "additions": 258, "deletions": 0, "changes": 258, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fzone.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Fsrc%2Fzone.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Fsrc%2Fzone.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "2c52485e8907d64ded2bff0c1f7349839fc5e672", "filename": "src/rt/jemalloc/test/ALLOCM_ARENA.c", "status": "added", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2FALLOCM_ARENA.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2FALLOCM_ARENA.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2FALLOCM_ARENA.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/ALLOCM_ARENA.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2FALLOCM_ARENA.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2FALLOCM_ARENA.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2FALLOCM_ARENA.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "5a9b0caea78b3e4fecce749e007542e56686da1d", "filename": "src/rt/jemalloc/test/aligned_alloc.c", "status": "added", "additions": 119, "deletions": 0, "changes": 119, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Faligned_alloc.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Faligned_alloc.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Faligned_alloc.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "b5061c7277e0e590b80b1a648d15d07d4877d386", "filename": "src/rt/jemalloc/test/aligned_alloc.exp", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Faligned_alloc.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Faligned_alloc.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Faligned_alloc.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "9884905d8100f27402bced99d53dc3c5167d9b84", "filename": "src/rt/jemalloc/test/allocated.c", "status": "added", "additions": 118, "deletions": 0, "changes": 118, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocated.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocated.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fallocated.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/allocated.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocated.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocated.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fallocated.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "80be673b8fdb50cc46d5b99fe34495d26431fb67", "filename": "src/rt/jemalloc/test/allocm.c", "status": "added", "additions": 194, "deletions": 0, "changes": 194, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocm.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocm.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fallocm.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "b5061c7277e0e590b80b1a648d15d07d4877d386", "filename": "src/rt/jemalloc/test/allocm.exp", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocm.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fallocm.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fallocm.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "b2cb63004bca0de6f4e21408e0e2925006114414", "filename": "src/rt/jemalloc/test/bitmap.c", "status": "added", "additions": 153, "deletions": 0, "changes": 153, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fbitmap.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fbitmap.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fbitmap.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/bitmap.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fbitmap.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fbitmap.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fbitmap.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "e38b48efa41522e612fcdcb7b55191538f241508", "filename": "src/rt/jemalloc/test/jemalloc_test.h.in", "status": "added", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fjemalloc_test.h.in", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fjemalloc_test.h.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fjemalloc_test.h.in?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "47efa7c415b3a95d99c04749f7a435c9b07f04ed", "filename": "src/rt/jemalloc/test/mremap.c", "status": "added", "additions": 60, "deletions": 0, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fmremap.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fmremap.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fmremap.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/mremap.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fmremap.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fmremap.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fmremap.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "2185bcf762a3a4de9a9e40f2723000796309e9a7", "filename": "src/rt/jemalloc/test/posix_memalign.c", "status": "added", "additions": 115, "deletions": 0, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fposix_memalign.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fposix_memalign.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fposix_memalign.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "b5061c7277e0e590b80b1a648d15d07d4877d386", "filename": "src/rt/jemalloc/test/posix_memalign.exp", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fposix_memalign.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fposix_memalign.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fposix_memalign.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "c5dedf48d7ba8cedd47031053d18e665dce93dc9", "filename": "src/rt/jemalloc/test/rallocm.c", "status": "added", "additions": 127, "deletions": 0, "changes": 127, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Frallocm.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Frallocm.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Frallocm.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/rallocm.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Frallocm.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Frallocm.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Frallocm.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "c5a21fa0c70d5beeab569edf5a199295a5ede886", "filename": "src/rt/jemalloc/test/thread_arena.c", "status": "added", "additions": 81, "deletions": 0, "changes": 81, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_arena.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_arena.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fthread_arena.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/thread_arena.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_arena.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_arena.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fthread_arena.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "2061b7bbaffc618dbf4f94caf1ceb0ca8dc73b1b", "filename": "src/rt/jemalloc/test/thread_tcache_enabled.c", "status": "added", "additions": 91, "deletions": 0, "changes": 91, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_tcache_enabled.c", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_tcache_enabled.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fthread_tcache_enabled.c?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}, {"sha": "369a88dd24049d0322e3d1e1928764c1cf2bcd0c", "filename": "src/rt/jemalloc/test/thread_tcache_enabled.exp", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_tcache_enabled.exp", "raw_url": "https://github.com/rust-lang/rust/raw/5d2cadbfea34ebbd0d83495833395b005380f2ec/src%2Frt%2Fjemalloc%2Ftest%2Fthread_tcache_enabled.exp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fjemalloc%2Ftest%2Fthread_tcache_enabled.exp?ref=5d2cadbfea34ebbd0d83495833395b005380f2ec"}]}