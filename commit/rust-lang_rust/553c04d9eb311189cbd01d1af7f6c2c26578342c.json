{"sha": "553c04d9eb311189cbd01d1af7f6c2c26578342c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU1M2MwNGQ5ZWIzMTExODljYmQwMWQxYWY3ZjZjMmMyNjU3ODM0MmM=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2018-04-02T15:19:32Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2018-04-02T20:48:34Z"}, "message": "proc_macro: Reorganize public API\n\nThis commit is a reorganization of the `proc_macro` crate's public user-facing\nAPI. This is the result of a number of discussions at the recent Rust All-Hands\nwhere we're hoping to get the `proc_macro` crate into ship shape for\nstabilization of a subset of its functionality in the Rust 2018 release.\n\nThe reorganization here is motivated by experiences from the `proc-macro2`,\n`quote`, and `syn` crates on crates.io (and other crates which depend on them).\nThe main focus is future flexibility along with making a few more operations\nconsistent and/or fixing bugs. A summary of the changes made from today's\n`proc_macro` API is:\n\n* The `TokenNode` enum has been removed and the public fields of `TokenTree`\n  have also been removed. Instead the `TokenTree` type is now a public enum\n  (what `TokenNode` was) and each variant is an opaque struct which internally\n  contains `Span` information. This makes the various tokens a bit more\n  consistent, require fewer wrappers, and otherwise provides good\n  future-compatibility as opaque structs are easy to modify later on.\n\n* `Literal` integer constructors have been expanded to be unambiguous as to what\n  they're doing and also allow for more future flexibility. Previously\n  constructors like `Literal::float` and `Literal::integer` were used to create\n  unsuffixed literals and the concrete methods like `Literal::i32` would create\n  a suffixed token. This wasn't immediately clear to all users (the\n  suffixed/unsuffixed aspect) and having *one* constructor for unsuffixed\n  literals required us to pick a largest type which may not always be true. To\n  fix these issues all constructors are now of the form\n  `Literal::i32_unsuffixed` or `Literal::i32_suffixed` (for all integral types).\n  This should allow future compatibility as well as being immediately clear\n  what's suffixed and what isn't.\n\n* Each variant of `TokenTree` internally contains a `Span` which can also be\n  configured via `set_span`. For example `Literal` and `Term` now both\n  internally contain a `Span` rather than having it stored in an auxiliary\n  location.\n\n* Constructors of all tokens are called `new` now (aka `Term::intern` is gone)\n  and most do not take spans. Manufactured tokens typically don't have a fresh\n  span to go with them and the span is purely used for error-reporting\n  **except** the span for `Term`, which currently affects hygiene. The default\n  spans for all these constructed tokens is `Span::call_site()` for now.\n\n  The `Term` type's constructor explicitly requires passing in a `Span` to\n  provide future-proofing against possible hygiene changes. It's intended that a\n  first pass of stabilization will likely only stabilize `Span::call_site()`\n  which is an explicit opt-in for \"I would like no hygiene here please\". The\n  intention here is to make this explicit in procedural macros to be\n  forwards-compatible with a hygiene-specifying solution.\n\n* Some of the conversions for `TokenStream` have been simplified a little.\n\n* The `TokenTreeIter` iterator was renamed to `token_stream::IntoIter`.\n\nOverall the hope is that this is the \"final pass\" at the API of `TokenStream`\nand most of `TokenTree` before stabilization. Explicitly left out here is any\nchanges to `Span`'s API which will likely need to be re-evaluated before\nstabilization.\n\nAll changes in this PR have already been reflected to the [`proc-macro2`],\n`quote`, and `syn` crates. New versions of all these crates have also been\npublished to crates.io.\n\nOnce this lands in nightly I plan on making an internals post again summarizing\nthe changes made here and also calling on all macro authors to give the APIs a\nspin and see how they work. Hopefully pending no major issues we can then have\nan FCP to stabilize later this cycle!\n\n[`proc-macro2`]: https://docs.rs/proc-macro2/0.3.1/proc_macro2/", "tree": {"sha": "1f3c35161bf5fd96ae38e42071da911b07142e85", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1f3c35161bf5fd96ae38e42071da911b07142e85"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/553c04d9eb311189cbd01d1af7f6c2c26578342c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/553c04d9eb311189cbd01d1af7f6c2c26578342c", "html_url": "https://github.com/rust-lang/rust/commit/553c04d9eb311189cbd01d1af7f6c2c26578342c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/553c04d9eb311189cbd01d1af7f6c2c26578342c/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "097efa9a998d4f3a4aee3af126e8f8a9eba1ae07", "url": "https://api.github.com/repos/rust-lang/rust/commits/097efa9a998d4f3a4aee3af126e8f8a9eba1ae07", "html_url": "https://github.com/rust-lang/rust/commit/097efa9a998d4f3a4aee3af126e8f8a9eba1ae07"}], "stats": {"total": 1040, "additions": 726, "deletions": 314}, "files": [{"sha": "837900f05d2e7e680b05110c79a39f89d19db7dd", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 562, "deletions": 185, "changes": 747, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -59,7 +59,6 @@ use syntax::errors::DiagnosticBuilder;\n use syntax::parse::{self, token};\n use syntax::symbol::Symbol;\n use syntax::tokenstream;\n-use syntax_pos::DUMMY_SP;\n use syntax_pos::{FileMap, Pos, SyntaxContext, FileName};\n use syntax_pos::hygiene::Mark;\n \n@@ -73,7 +72,7 @@ use syntax_pos::hygiene::Mark;\n /// The API of this type is intentionally bare-bones, but it'll be expanded over\n /// time!\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n-#[derive(Clone, Debug)]\n+#[derive(Clone)]\n pub struct TokenStream(tokenstream::TokenStream);\n \n /// Error returned from `TokenStream::from_str`.\n@@ -83,6 +82,20 @@ pub struct LexError {\n     _inner: (),\n }\n \n+impl TokenStream {\n+    /// Returns an empty `TokenStream`.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn empty() -> TokenStream {\n+        TokenStream(tokenstream::TokenStream::empty())\n+    }\n+\n+    /// Checks if this `TokenStream` is empty.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n+    }\n+}\n+\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl FromStr for TokenStream {\n     type Err = LexError;\n@@ -110,19 +123,12 @@ impl fmt::Display for TokenStream {\n     }\n }\n \n-/// `quote!(..)` accepts arbitrary tokens and expands into a `TokenStream` describing the input.\n-/// For example, `quote!(a + b)` will produce a expression, that, when evaluated, constructs\n-/// the `TokenStream` `[Word(\"a\"), Op('+', Alone), Word(\"b\")]`.\n-///\n-/// Unquoting is done with `$`, and works by taking the single next ident as the unquoted term.\n-/// To quote `$` itself, use `$$`.\n-#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-#[macro_export]\n-macro_rules! quote { () => {} }\n-\n-#[unstable(feature = \"proc_macro_internals\", issue = \"27812\")]\n-#[doc(hidden)]\n-mod quote;\n+#[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n+impl fmt::Debug for TokenStream {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        self.0.fmt(f)\n+    }\n+}\n \n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n impl From<TokenTree> for TokenStream {\n@@ -132,62 +138,79 @@ impl From<TokenTree> for TokenStream {\n }\n \n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-impl From<TokenNode> for TokenStream {\n-    fn from(kind: TokenNode) -> TokenStream {\n-        TokenTree::from(kind).into()\n-    }\n-}\n-\n-#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-impl<T: Into<TokenStream>> iter::FromIterator<T> for TokenStream {\n-    fn from_iter<I: IntoIterator<Item = T>>(streams: I) -> Self {\n+impl iter::FromIterator<TokenTree> for TokenStream {\n+    fn from_iter<I: IntoIterator<Item = TokenTree>>(trees: I) -> Self {\n         let mut builder = tokenstream::TokenStreamBuilder::new();\n-        for stream in streams {\n-            builder.push(stream.into().0);\n+        for tree in trees {\n+            builder.push(tree.to_internal());\n         }\n         TokenStream(builder.build())\n     }\n }\n \n+/// Implementation details for the `TokenTree` type, such as iterators.\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-impl IntoIterator for TokenStream {\n-    type Item = TokenTree;\n-    type IntoIter = TokenTreeIter;\n+pub mod token_stream {\n+    use syntax::tokenstream;\n+    use syntax_pos::DUMMY_SP;\n+\n+    use {TokenTree, TokenStream, Delimiter};\n \n-    fn into_iter(self) -> TokenTreeIter {\n-        TokenTreeIter { cursor: self.0.trees(), stack: Vec::new() }\n+    /// An iterator over `TokenTree`s.\n+    #[derive(Clone)]\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub struct IntoIter {\n+        cursor: tokenstream::Cursor,\n+        stack: Vec<TokenTree>,\n     }\n-}\n \n-impl TokenStream {\n-    /// Returns an empty `TokenStream`.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn empty() -> TokenStream {\n-        TokenStream(tokenstream::TokenStream::empty())\n+    impl Iterator for IntoIter {\n+        type Item = TokenTree;\n+\n+        fn next(&mut self) -> Option<TokenTree> {\n+            loop {\n+                let tree = self.stack.pop().or_else(|| {\n+                    let next = self.cursor.next_as_stream()?;\n+                    Some(TokenTree::from_internal(next, &mut self.stack))\n+                })?;\n+                if tree.span().0 == DUMMY_SP {\n+                    if let TokenTree::Group(ref group) = tree {\n+                        if group.delimiter() == Delimiter::None {\n+                            self.cursor.insert(group.stream.clone().0);\n+                            continue\n+                        }\n+                    }\n+                }\n+                return Some(tree);\n+            }\n+        }\n     }\n \n-    /// Checks if this `TokenStream` is empty.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn is_empty(&self) -> bool {\n-        self.0.is_empty()\n+    impl IntoIterator for TokenStream {\n+        type Item = TokenTree;\n+        type IntoIter = IntoIter;\n+\n+        fn into_iter(self) -> IntoIter {\n+            IntoIter { cursor: self.0.trees(), stack: Vec::new() }\n+        }\n     }\n }\n \n-/// A region of source code, along with macro expansion information.\n+/// `quote!(..)` accepts arbitrary tokens and expands into a `TokenStream` describing the input.\n+/// For example, `quote!(a + b)` will produce a expression, that, when evaluated, constructs\n+/// the `TokenStream` `[Word(\"a\"), Op('+', Alone), Word(\"b\")]`.\n+///\n+/// Unquoting is done with `$`, and works by taking the single next ident as the unquoted term.\n+/// To quote `$` itself, use `$$`.\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n-pub struct Span(syntax_pos::Span);\n+#[macro_export]\n+macro_rules! quote { () => {} }\n \n-impl Span {\n-    /// A span that resolves at the macro definition site.\n-    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn def_site() -> Span {\n-        ::__internal::with_sess(|(_, mark)| {\n-            let call_site = mark.expn_info().unwrap().call_site;\n-            Span(call_site.with_ctxt(SyntaxContext::empty().apply_mark(mark)))\n-        })\n-    }\n-}\n+#[unstable(feature = \"proc_macro_internals\", issue = \"27812\")]\n+#[doc(hidden)]\n+mod quote;\n \n /// Quote a `Span` into a `TokenStream`.\n /// This is needed to implement a custom quoter.\n@@ -196,6 +219,11 @@ pub fn quote_span(span: Span) -> TokenStream {\n     quote::Quote::quote(span)\n }\n \n+/// A region of source code, along with macro expansion information.\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+#[derive(Copy, Clone, Debug)]\n+pub struct Span(syntax_pos::Span);\n+\n macro_rules! diagnostic_method {\n     ($name:ident, $level:expr) => (\n         /// Create a new `Diagnostic` with the given `message` at the span\n@@ -208,6 +236,15 @@ macro_rules! diagnostic_method {\n }\n \n impl Span {\n+    /// A span that resolves at the macro definition site.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn def_site() -> Span {\n+        ::__internal::with_sess(|(_, mark)| {\n+            let call_site = mark.expn_info().unwrap().call_site;\n+            Span(call_site.with_ctxt(SyntaxContext::empty().apply_mark(mark)))\n+        })\n+    }\n+\n     /// The span of the invocation of the current procedural macro.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n     pub fn call_site() -> Span {\n@@ -284,6 +321,12 @@ impl Span {\n         other.resolved_at(*self)\n     }\n \n+    /// Compares to spans to see if they're equal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn eq(&self, other: &Span) -> bool {\n+        self.0 == other.0\n+    }\n+\n     diagnostic_method!(error, Level::Error);\n     diagnostic_method!(warning, Level::Warning);\n     diagnostic_method!(note, Level::Note);\n@@ -379,39 +422,97 @@ impl PartialEq<FileName> for SourceFile {\n /// A single token or a delimited sequence of token trees (e.g. `[1, (), ..]`).\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n #[derive(Clone, Debug)]\n-pub struct TokenTree {\n-    /// The `TokenTree`'s span\n-    pub span: Span,\n-    /// Description of the `TokenTree`\n-    pub kind: TokenNode,\n+pub enum TokenTree {\n+    /// A delimited tokenstream\n+    Group(Group),\n+    /// A unicode identifier\n+    Term(Term),\n+    /// A punctuation character (`+`, `,`, `$`, etc.).\n+    Op(Op),\n+    /// A literal character (`'a'`), string (`\"hello\"`), number (`2.3`), etc.\n+    Literal(Literal),\n+}\n+\n+impl TokenTree {\n+    /// Returns the span of this token, accessing the `span` method of each of\n+    /// the internal tokens.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn span(&self) -> Span {\n+        match *self {\n+            TokenTree::Group(ref t) => t.span(),\n+            TokenTree::Term(ref t) => t.span(),\n+            TokenTree::Op(ref t) => t.span(),\n+            TokenTree::Literal(ref t) => t.span(),\n+        }\n+    }\n+\n+    /// Configures the span for *only this token*.\n+    ///\n+    /// Note that if this token is a `Group` then this method will not configure\n+    /// the span of each of the internal tokens, this will simply delegate to\n+    /// the `set_span` method of each variant.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn set_span(&mut self, span: Span) {\n+        match *self {\n+            TokenTree::Group(ref mut t) => t.set_span(span),\n+            TokenTree::Term(ref mut t) => t.set_span(span),\n+            TokenTree::Op(ref mut t) => t.set_span(span),\n+            TokenTree::Literal(ref mut t) => t.set_span(span),\n+        }\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl From<Group> for TokenTree {\n+    fn from(g: Group) -> TokenTree {\n+        TokenTree::Group(g)\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl From<Term> for TokenTree {\n+    fn from(g: Term) -> TokenTree {\n+        TokenTree::Term(g)\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl From<Op> for TokenTree {\n+    fn from(g: Op) -> TokenTree {\n+        TokenTree::Op(g)\n+    }\n }\n \n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-impl From<TokenNode> for TokenTree {\n-    fn from(kind: TokenNode) -> TokenTree {\n-        TokenTree { span: Span::def_site(), kind: kind }\n+impl From<Literal> for TokenTree {\n+    fn from(g: Literal) -> TokenTree {\n+        TokenTree::Literal(g)\n     }\n }\n \n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n impl fmt::Display for TokenTree {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        TokenStream::from(self.clone()).fmt(f)\n+        match *self {\n+            TokenTree::Group(ref t) => t.fmt(f),\n+            TokenTree::Term(ref t) => t.fmt(f),\n+            TokenTree::Op(ref t) => t.fmt(f),\n+            TokenTree::Literal(ref t) => t.fmt(f),\n+        }\n     }\n }\n \n-/// Description of a `TokenTree`\n+/// A delimited token stream\n+///\n+/// A `Group` internally contains a `TokenStream` which is delimited by a\n+/// `Delimiter`. Groups represent multiple tokens internally and have a `Span`\n+/// for the entire stream.\n #[derive(Clone, Debug)]\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-pub enum TokenNode {\n-    /// A delimited tokenstream.\n-    Group(Delimiter, TokenStream),\n-    /// A unicode identifier.\n-    Term(Term),\n-    /// A punctuation character (`+`, `,`, `$`, etc.).\n-    Op(char, Spacing),\n-    /// A literal character (`'a'`), string (`\"hello\"`), or number (`2.3`).\n-    Literal(Literal),\n+pub struct Group {\n+    delimiter: Delimiter,\n+    stream: TokenStream,\n+    span: Span,\n }\n \n /// Describes how a sequence of token trees is delimited.\n@@ -428,25 +529,74 @@ pub enum Delimiter {\n     None,\n }\n \n-/// An interned string.\n-#[derive(Copy, Clone, Debug)]\n-#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-pub struct Term(Symbol);\n+impl Group {\n+    /// Creates a new `group` with the given delimiter and token stream.\n+    ///\n+    /// This constructor will set the span for this group to\n+    /// `Span::call_site()`. To change the span you can use the `set_span`\n+    /// method below.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn new(delimiter: Delimiter, stream: TokenStream) -> Group {\n+        Group {\n+            delimiter: delimiter,\n+            stream: stream,\n+            span: Span::call_site(),\n+        }\n+    }\n \n-impl Term {\n-    /// Intern a string into a `Term`.\n+    /// Returns the delimiter of this `Group`\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn intern(string: &str) -> Term {\n-        Term(Symbol::intern(string))\n+    pub fn delimiter(&self) -> Delimiter {\n+        self.delimiter\n     }\n \n-    /// Get a reference to the interned string.\n+    /// Returns the `TokenStream` of tokens that are delimited in this `Group`.\n+    ///\n+    /// Note that the returned token stream does not include the delimiter\n+    /// returned above.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn as_str(&self) -> &str {\n-        unsafe { &*(&*self.0.as_str() as *const str) }\n+    pub fn stream(&self) -> TokenStream {\n+        self.stream.clone()\n+    }\n+\n+    /// Returns the span for the delimiters of this token stream, spanning the\n+    /// entire `Group`.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn span(&self) -> Span {\n+        self.span\n+    }\n+\n+    /// Configures the span for this `Group`'s delimiters, but not its internal\n+    /// tokens.\n+    ///\n+    /// This method will **not** set the span of all the internal tokens spanned\n+    /// by this group, but rather it will only set the span of the delimiter\n+    /// tokens at the level of the `Group`.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn set_span(&mut self, span: Span) {\n+        self.span = span;\n     }\n }\n \n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl fmt::Display for Group {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        TokenStream::from(TokenTree::from(self.clone())).fmt(f)\n+    }\n+}\n+\n+/// An `Op` is an operator like `+` or `-`, and only represents one character.\n+///\n+/// Operators like `+=` are represented as two instance of `Op` with different\n+/// forms of `Spacing` returned.\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+#[derive(Copy, Clone, Debug)]\n+pub struct Op {\n+    op: char,\n+    spacing: Spacing,\n+    span: Span,\n+}\n+\n /// Whether an `Op` is either followed immediately by another `Op` or followed by whitespace.\n #[derive(Copy, Clone, Debug, PartialEq, Eq)]\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n@@ -457,68 +607,285 @@ pub enum Spacing {\n     Joint,\n }\n \n-/// A literal character (`'a'`), string (`\"hello\"`), or number (`2.3`).\n-#[derive(Clone, Debug)]\n+impl Op {\n+    /// Creates a new `Op` from the given character and spacing.\n+    ///\n+    /// The returned `Op` will have the default span of `Span::call_site()`\n+    /// which can be further configured with the `set_span` method below.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn new(op: char, spacing: Spacing) -> Op {\n+        Op {\n+            op: op,\n+            spacing: spacing,\n+            span: Span::call_site(),\n+        }\n+    }\n+\n+    /// Returns the character this operation represents, for example `'+'`\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn op(&self) -> char {\n+        self.op\n+    }\n+\n+    /// Returns the spacing of this operator, indicating whether it's a joint\n+    /// operator with more operators coming next in the token stream or an\n+    /// `Alone` meaning that the operator has ended.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn spacing(&self) -> Spacing {\n+        self.spacing\n+    }\n+\n+    /// Returns the span for this operator character\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn span(&self) -> Span {\n+        self.span\n+    }\n+\n+    /// Configure the span for this operator's character\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn set_span(&mut self, span: Span) {\n+        self.span = span;\n+    }\n+}\n+\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-pub struct Literal(token::Token);\n+impl fmt::Display for Op {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        TokenStream::from(TokenTree::from(self.clone())).fmt(f)\n+    }\n+}\n \n+/// An interned string.\n+#[derive(Copy, Clone, Debug)]\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-impl fmt::Display for Literal {\n+pub struct Term {\n+    sym: Symbol,\n+    span: Span,\n+}\n+\n+impl Term {\n+    /// Creates a new `Term` with the given `string` as well as the specified\n+    /// `span`.\n+    ///\n+    /// Note that `span`, currently in rustc, configures the hygiene information\n+    /// for this identifier. As of this time `Span::call_site()` explicitly\n+    /// opts-in to **non-hygienic** information (aka copy/pasted code) while\n+    /// spans like `Span::def_site()` will opt-in to hygienic information,\n+    /// meaning that code at the call site of the macro can't access this\n+    /// identifier.\n+    ///\n+    /// Due to the current importance of hygiene this constructor, unlike other\n+    /// tokens, requires a `Span` to be specified at construction.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn new(string: &str, span: Span) -> Term {\n+        Term {\n+            sym: Symbol::intern(string),\n+            span,\n+        }\n+    }\n+\n+    /// Get a reference to the interned string.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn as_str(&self) -> &str {\n+        unsafe { &*(&*self.sym.as_str() as *const str) }\n+    }\n+\n+    /// Returns the span of this `Term`, encompassing the entire string returned\n+    /// by `as_str`.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn span(&self) -> Span {\n+        self.span\n+    }\n+\n+    /// Configures the span of this `Term`, possibly changing hygiene\n+    /// information.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn set_span(&mut self, span: Span) {\n+        self.span = span;\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl fmt::Display for Term {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        TokenTree { kind: TokenNode::Literal(self.clone()), span: Span(DUMMY_SP) }.fmt(f)\n+        self.as_str().fmt(f)\n     }\n }\n \n-macro_rules! int_literals {\n-    ($($int_kind:ident),*) => {$(\n-        /// Integer literal.\n+/// A literal character (`'a'`), string (`\"hello\"`), a number (`2.3`), etc.\n+#[derive(Clone, Debug)]\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub struct Literal {\n+    token: token::Token,\n+    span: Span,\n+}\n+\n+macro_rules! suffixed_int_literals {\n+    ($($name:ident => $kind:ident,)*) => ($(\n+        /// Creates a new suffixed integer literal with the specified value.\n+        ///\n+        /// This function will create an integer like `1u32` where the integer\n+        /// value specified is the first part of the token and the integral is\n+        /// also suffixed at the end.\n+        ///\n+        /// Literals created through this method have the `Span::call_site()`\n+        /// span by default, which can be configured with the `set_span` method\n+        /// below.\n         #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-        pub fn $int_kind(n: $int_kind) -> Literal {\n-            Literal::typed_integer(n as i128, stringify!($int_kind))\n+        pub fn $name(n: $kind) -> Literal {\n+            let lit = token::Lit::Integer(Symbol::intern(&n.to_string()));\n+            let ty = Some(Symbol::intern(stringify!($kind)));\n+            Literal {\n+                token: token::Literal(lit, ty),\n+                span: Span::call_site(),\n+            }\n+        }\n+    )*)\n+}\n+\n+macro_rules! unsuffixed_int_literals {\n+    ($($name:ident => $kind:ident,)*) => ($(\n+        /// Creates a new unsuffixed integer literal with the specified value.\n+        ///\n+        /// This function will create an integer like `1` where the integer\n+        /// value specified is the first part of the token. No suffix is\n+        /// specified on this token, meaning that invocations like\n+        /// `Literal::i8_unsuffixed(1)` are equivalent to\n+        /// `Literal::u32_unsuffixed(1)`.\n+        ///\n+        /// Literals created through this method have the `Span::call_site()`\n+        /// span by default, which can be configured with the `set_span` method\n+        /// below.\n+        #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+        pub fn $name(n: $kind) -> Literal {\n+            let lit = token::Lit::Integer(Symbol::intern(&n.to_string()));\n+            Literal {\n+                token: token::Literal(lit, None),\n+                span: Span::call_site(),\n+            }\n         }\n-    )*}\n+    )*)\n }\n \n impl Literal {\n-    /// Integer literal\n-    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn integer(n: i128) -> Literal {\n-        Literal(token::Literal(token::Lit::Integer(Symbol::intern(&n.to_string())), None))\n+    suffixed_int_literals! {\n+        u8_suffixed => u8,\n+        u16_suffixed => u16,\n+        u32_suffixed => u32,\n+        u64_suffixed => u64,\n+        u128_suffixed => u128,\n+        usize_suffixed => usize,\n+        i8_suffixed => i8,\n+        i16_suffixed => i16,\n+        i32_suffixed => i32,\n+        i64_suffixed => i64,\n+        i128_suffixed => i128,\n+        isize_suffixed => isize,\n     }\n \n-    int_literals!(u8, i8, u16, i16, u32, i32, u64, i64, usize, isize);\n-    fn typed_integer(n: i128, kind: &'static str) -> Literal {\n-        Literal(token::Literal(token::Lit::Integer(Symbol::intern(&n.to_string())),\n-                               Some(Symbol::intern(kind))))\n+    unsuffixed_int_literals! {\n+        u8_unsuffixed => u8,\n+        u16_unsuffixed => u16,\n+        u32_unsuffixed => u32,\n+        u64_unsuffixed => u64,\n+        u128_unsuffixed => u128,\n+        usize_unsuffixed => usize,\n+        i8_unsuffixed => i8,\n+        i16_unsuffixed => i16,\n+        i32_unsuffixed => i32,\n+        i64_unsuffixed => i64,\n+        i128_unsuffixed => i128,\n+        isize_unsuffixed => isize,\n     }\n \n-    /// Floating point literal.\n+    /// Creates a new unsuffixed floating-point literal.\n+    ///\n+    /// This constructor is similar to those like `Literal::i8_unsuffixed` where\n+    /// the float's value is emitted directly into the token but no suffix is\n+    /// used, so it may be inferred to be a `f64` later in the compiler.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function requires that the specified float is finite, for\n+    /// example if it is infinity or NaN this function will panic.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn float(n: f64) -> Literal {\n+    pub fn f32_unsuffixed(n: f32) -> Literal {\n         if !n.is_finite() {\n             panic!(\"Invalid float literal {}\", n);\n         }\n-        Literal(token::Literal(token::Lit::Float(Symbol::intern(&n.to_string())), None))\n+        let lit = token::Lit::Float(Symbol::intern(&n.to_string()));\n+        Literal {\n+            token: token::Literal(lit, None),\n+            span: Span::call_site(),\n+        }\n     }\n \n-    /// Floating point literal.\n+    /// Creates a new suffixed floating-point literal.\n+    ///\n+    /// This consturctor will create a literal like `1.0f32` where the value\n+    /// specified is the preceding part of the token and `f32` is the suffix of\n+    /// the token. This token will always be inferred to be an `f32` in the\n+    /// compiler.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function requires that the specified float is finite, for\n+    /// example if it is infinity or NaN this function will panic.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn f32(n: f32) -> Literal {\n+    pub fn f32_suffixed(n: f32) -> Literal {\n         if !n.is_finite() {\n-            panic!(\"Invalid f32 literal {}\", n);\n+            panic!(\"Invalid float literal {}\", n);\n+        }\n+        let lit = token::Lit::Float(Symbol::intern(&n.to_string()));\n+        Literal {\n+            token: token::Literal(lit, Some(Symbol::intern(\"f32\"))),\n+            span: Span::call_site(),\n         }\n-        Literal(token::Literal(token::Lit::Float(Symbol::intern(&n.to_string())),\n-                               Some(Symbol::intern(\"f32\"))))\n     }\n \n-    /// Floating point literal.\n+    /// Creates a new unsuffixed floating-point literal.\n+    ///\n+    /// This constructor is similar to those like `Literal::i8_unsuffixed` where\n+    /// the float's value is emitted directly into the token but no suffix is\n+    /// used, so it may be inferred to be a `f64` later in the compiler.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function requires that the specified float is finite, for\n+    /// example if it is infinity or NaN this function will panic.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-    pub fn f64(n: f64) -> Literal {\n+    pub fn f64_unsuffixed(n: f64) -> Literal {\n         if !n.is_finite() {\n-            panic!(\"Invalid f64 literal {}\", n);\n+            panic!(\"Invalid float literal {}\", n);\n+        }\n+        let lit = token::Lit::Float(Symbol::intern(&n.to_string()));\n+        Literal {\n+            token: token::Literal(lit, None),\n+            span: Span::call_site(),\n+        }\n+    }\n+\n+    /// Creates a new suffixed floating-point literal.\n+    ///\n+    /// This consturctor will create a literal like `1.0f64` where the value\n+    /// specified is the preceding part of the token and `f64` is the suffix of\n+    /// the token. This token will always be inferred to be an `f64` in the\n+    /// compiler.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function requires that the specified float is finite, for\n+    /// example if it is infinity or NaN this function will panic.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn f64_suffixed(n: f64) -> Literal {\n+        if !n.is_finite() {\n+            panic!(\"Invalid float literal {}\", n);\n+        }\n+        let lit = token::Lit::Float(Symbol::intern(&n.to_string()));\n+        Literal {\n+            token: token::Literal(lit, Some(Symbol::intern(\"f64\"))),\n+            span: Span::call_site(),\n         }\n-        Literal(token::Literal(token::Lit::Float(Symbol::intern(&n.to_string())),\n-                               Some(Symbol::intern(\"f64\"))))\n     }\n \n     /// String literal.\n@@ -528,52 +895,51 @@ impl Literal {\n         for ch in string.chars() {\n             escaped.extend(ch.escape_debug());\n         }\n-        Literal(token::Literal(token::Lit::Str_(Symbol::intern(&escaped)), None))\n+        Literal {\n+            token: token::Literal(token::Lit::Str_(Symbol::intern(&escaped)), None),\n+            span: Span::call_site(),\n+        }\n     }\n \n     /// Character literal.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n     pub fn character(ch: char) -> Literal {\n         let mut escaped = String::new();\n         escaped.extend(ch.escape_unicode());\n-        Literal(token::Literal(token::Lit::Char(Symbol::intern(&escaped)), None))\n+        Literal {\n+            token: token::Literal(token::Lit::Char(Symbol::intern(&escaped)), None),\n+            span: Span::call_site(),\n+        }\n     }\n \n     /// Byte string literal.\n     #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n     pub fn byte_string(bytes: &[u8]) -> Literal {\n         let string = bytes.iter().cloned().flat_map(ascii::escape_default)\n             .map(Into::<char>::into).collect::<String>();\n-        Literal(token::Literal(token::Lit::ByteStr(Symbol::intern(&string)), None))\n+        Literal {\n+            token: token::Literal(token::Lit::ByteStr(Symbol::intern(&string)), None),\n+            span: Span::call_site(),\n+        }\n     }\n-}\n \n-/// An iterator over `TokenTree`s.\n-#[derive(Clone)]\n-#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-pub struct TokenTreeIter {\n-    cursor: tokenstream::Cursor,\n-    stack: Vec<TokenTree>,\n+    /// Returns the span encompassing this literal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn span(&self) -> Span {\n+        self.span\n+    }\n+\n+    /// Configures the span associated for this literal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn set_span(&mut self, span: Span) {\n+        self.span = span;\n+    }\n }\n \n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n-impl Iterator for TokenTreeIter {\n-    type Item = TokenTree;\n-\n-    fn next(&mut self) -> Option<TokenTree> {\n-        loop {\n-            let tree = self.stack.pop().or_else(|| {\n-                let next = self.cursor.next_as_stream()?;\n-                Some(TokenTree::from_internal(next, &mut self.stack))\n-            })?;\n-            if tree.span.0 == DUMMY_SP {\n-                if let TokenNode::Group(Delimiter::None, stream) = tree.kind {\n-                    self.cursor.insert(stream.0);\n-                    continue\n-                }\n-            }\n-            return Some(tree);\n-        }\n+impl fmt::Display for Literal {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        TokenStream::from(TokenTree::from(self.clone())).fmt(f)\n     }\n }\n \n@@ -607,31 +973,34 @@ impl TokenTree {\n             tokenstream::TokenTree::Token(span, token) => (span, token),\n             tokenstream::TokenTree::Delimited(span, delimed) => {\n                 let delimiter = Delimiter::from_internal(delimed.delim);\n-                return TokenTree {\n-                    span: Span(span),\n-                    kind: TokenNode::Group(delimiter, TokenStream(delimed.tts.into())),\n-                };\n+                let mut g = Group::new(delimiter, TokenStream(delimed.tts.into()));\n+                g.set_span(Span(span));\n+                return g.into()\n             }\n         };\n \n         let op_kind = if is_joint { Spacing::Joint } else { Spacing::Alone };\n         macro_rules! tt {\n-            ($e:expr) => (TokenTree { span: Span(span), kind: $e })\n+            ($e:expr) => ({\n+                let mut x = TokenTree::from($e);\n+                x.set_span(Span(span));\n+                x\n+            })\n         }\n         macro_rules! op {\n-            ($a:expr) => (TokenNode::Op($a, op_kind));\n+            ($a:expr) => (tt!(Op::new($a, op_kind)));\n             ($a:expr, $b:expr) => ({\n-                stack.push(tt!(TokenNode::Op($b, op_kind).into()));\n-                TokenNode::Op($a, Spacing::Joint)\n+                stack.push(tt!(Op::new($b, op_kind)));\n+                tt!(Op::new($a, Spacing::Joint))\n             });\n             ($a:expr, $b:expr, $c:expr) => ({\n-                stack.push(tt!(TokenNode::Op($c, op_kind)));\n-                stack.push(tt!(TokenNode::Op($b, Spacing::Joint)));\n-                TokenNode::Op($a, Spacing::Joint)\n+                stack.push(tt!(Op::new($c, op_kind)));\n+                stack.push(tt!(Op::new($b, Spacing::Joint)));\n+                tt!(Op::new($a, Spacing::Joint))\n             })\n         }\n \n-        let kind = match token {\n+        match token {\n             Eq => op!('='),\n             Lt => op!('<'),\n             Le => op!('<', '='),\n@@ -679,80 +1048,88 @@ impl TokenTree {\n             Dollar => op!('$'),\n             Question => op!('?'),\n \n-            Ident(ident, false) | Lifetime(ident) => TokenNode::Term(Term(ident.name)),\n-            Ident(ident, true) => TokenNode::Term(Term(Symbol::intern(&format!(\"r#{}\", ident)))),\n-            Literal(..) => TokenNode::Literal(self::Literal(token)),\n+            Ident(ident, false) | Lifetime(ident) => {\n+                tt!(Term::new(&ident.name.as_str(), Span(span)))\n+            }\n+            Ident(ident, true) => {\n+                tt!(Term::new(&format!(\"r#{}\", ident), Span(span)))\n+            }\n+            Literal(..) => tt!(self::Literal { token, span: Span(span) }),\n             DocComment(c) => {\n                 let stream = vec![\n-                    tt!(TokenNode::Term(Term::intern(\"doc\"))),\n-                    tt!(op!('=')),\n-                    tt!(TokenNode::Literal(self::Literal(Literal(Lit::Str_(c), None)))),\n+                    tt!(Term::new(\"doc\", Span(span))),\n+                    tt!(Op::new('=', Spacing::Alone)),\n+                    tt!(self::Literal::string(&c.as_str())),\n                 ].into_iter().collect();\n-                stack.push(tt!(TokenNode::Group(Delimiter::Bracket, stream)));\n-                op!('#')\n+                stack.push(tt!(Group::new(Delimiter::Bracket, stream)));\n+                tt!(Op::new('#', Spacing::Alone))\n             }\n \n             Interpolated(_) => {\n                 __internal::with_sess(|(sess, _)| {\n                     let tts = token.interpolated_to_tokenstream(sess, span);\n-                    TokenNode::Group(Delimiter::None, TokenStream(tts))\n+                    tt!(Group::new(Delimiter::None, TokenStream(tts)))\n                 })\n             }\n \n             DotEq => op!('.', '='),\n             OpenDelim(..) | CloseDelim(..) => unreachable!(),\n             Whitespace | Comment | Shebang(..) | Eof => unreachable!(),\n-        };\n-\n-        TokenTree { span: Span(span), kind: kind }\n+        }\n     }\n \n     fn to_internal(self) -> tokenstream::TokenStream {\n         use syntax::parse::token::*;\n         use syntax::tokenstream::{TokenTree, Delimited};\n \n-        let (op, kind) = match self.kind {\n-            TokenNode::Op(op, kind) => (op, kind),\n-            TokenNode::Group(delimiter, tokens) => {\n-                return TokenTree::Delimited(self.span.0, Delimited {\n-                    delim: delimiter.to_internal(),\n-                    tts: tokens.0.into(),\n+        let (op, kind, span) = match self {\n+            self::TokenTree::Op(tt) => (tt.op(), tt.spacing(), tt.span()),\n+            self::TokenTree::Group(tt) => {\n+                return TokenTree::Delimited(tt.span.0, Delimited {\n+                    delim: tt.delimiter.to_internal(),\n+                    tts: tt.stream.0.into(),\n                 }).into();\n             },\n-            TokenNode::Term(symbol) => {\n-                let ident = ast::Ident { name: symbol.0, ctxt: self.span.0.ctxt() };\n-                let sym_str = symbol.0.as_str();\n+            self::TokenTree::Term(tt) => {\n+                let ident = ast::Ident { name: tt.sym, ctxt: tt.span.0.ctxt() };\n+                let sym_str = tt.sym.as_str();\n                 let token =\n                     if sym_str.starts_with(\"'\") { Lifetime(ident) }\n                     else if sym_str.starts_with(\"r#\") {\n                         let name = Symbol::intern(&sym_str[2..]);\n-                        let ident = ast::Ident { name, ctxt: self.span.0.ctxt() };\n+                        let ident = ast::Ident { name, ctxt: tt.span.0.ctxt() };\n                         Ident(ident, true)\n                     } else { Ident(ident, false) };\n-                return TokenTree::Token(self.span.0, token).into();\n+                return TokenTree::Token(tt.span.0, token).into();\n             }\n-            TokenNode::Literal(self::Literal(Literal(Lit::Integer(ref a), b)))\n+            self::TokenTree::Literal(self::Literal {\n+                token: Literal(Lit::Integer(ref a), b),\n+                span,\n+            })\n                 if a.as_str().starts_with(\"-\") =>\n             {\n                 let minus = BinOp(BinOpToken::Minus);\n                 let integer = Symbol::intern(&a.as_str()[1..]);\n                 let integer = Literal(Lit::Integer(integer), b);\n-                let a = TokenTree::Token(self.span.0, minus);\n-                let b = TokenTree::Token(self.span.0, integer);\n+                let a = TokenTree::Token(span.0, minus);\n+                let b = TokenTree::Token(span.0, integer);\n                 return vec![a, b].into_iter().collect()\n             }\n-            TokenNode::Literal(self::Literal(Literal(Lit::Float(ref a), b)))\n+            self::TokenTree::Literal(self::Literal {\n+                token: Literal(Lit::Float(ref a), b),\n+                span,\n+            })\n                 if a.as_str().starts_with(\"-\") =>\n             {\n                 let minus = BinOp(BinOpToken::Minus);\n                 let float = Symbol::intern(&a.as_str()[1..]);\n                 let float = Literal(Lit::Float(float), b);\n-                let a = TokenTree::Token(self.span.0, minus);\n-                let b = TokenTree::Token(self.span.0, float);\n+                let a = TokenTree::Token(span.0, minus);\n+                let b = TokenTree::Token(span.0, float);\n                 return vec![a, b].into_iter().collect()\n             }\n-            TokenNode::Literal(token) => {\n-                return TokenTree::Token(self.span.0, token.0).into()\n+            self::TokenTree::Literal(tt) => {\n+                return TokenTree::Token(tt.span.0, tt.token).into()\n             }\n         };\n \n@@ -781,7 +1158,7 @@ impl TokenTree {\n             _ => panic!(\"unsupported character {}\", op),\n         };\n \n-        let tree = TokenTree::Token(self.span.0, token);\n+        let tree = TokenTree::Token(span.0, token);\n         match kind {\n             Spacing::Alone => tree.into(),\n             Spacing::Joint => tree.joint(),"}, {"sha": "cc8575b88be97f9004d8dff382a0724d442a1d8c", "filename": "src/libproc_macro/quote.rs", "status": "modified", "additions": 83, "deletions": 55, "changes": 138, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Flibproc_macro%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Flibproc_macro%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fquote.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -14,7 +14,7 @@\n //! This quasiquoter uses macros 2.0 hygiene to reliably access\n //! items from `proc_macro`, to build a `proc_macro::TokenStream`.\n \n-use {Delimiter, Literal, Spacing, Span, Term, TokenNode, TokenStream, TokenTree};\n+use {Delimiter, Literal, Spacing, Span, Term, Op, Group, TokenStream, TokenTree};\n \n use syntax::ext::base::{ExtCtxt, ProcMacro};\n use syntax::parse::token;\n@@ -23,47 +23,59 @@ use syntax::tokenstream;\n pub struct Quoter;\n \n pub fn unquote<T: Into<TokenStream> + Clone>(tokens: &T) -> TokenStream {\n-    T::into(tokens.clone())\n+    tokens.clone().into()\n }\n \n pub trait Quote {\n     fn quote(self) -> TokenStream;\n }\n \n+macro_rules! tt2ts {\n+    ($e:expr) => (TokenStream::from(TokenTree::from($e)))\n+}\n+\n macro_rules! quote_tok {\n-    (,) => { TokenNode::Op(',', Spacing::Alone) };\n-    (.) => { TokenNode::Op('.', Spacing::Alone) };\n-    (:) => { TokenNode::Op(':', Spacing::Alone) };\n+    (,) => { tt2ts!(Op::new(',', Spacing::Alone)) };\n+    (.) => { tt2ts!(Op::new('.', Spacing::Alone)) };\n+    (:) => { tt2ts!(Op::new(':', Spacing::Alone)) };\n+    (|) => { tt2ts!(Op::new('|', Spacing::Alone)) };\n     (::) => {\n         [\n-            TokenNode::Op(':', Spacing::Joint),\n-            TokenNode::Op(':', Spacing::Alone)\n-        ].iter().cloned().collect::<TokenStream>()\n+            TokenTree::from(Op::new(':', Spacing::Joint)),\n+            TokenTree::from(Op::new(':', Spacing::Alone)),\n+        ].iter()\n+            .cloned()\n+            .map(|mut x| {\n+                x.set_span(Span::def_site());\n+                x\n+            })\n+            .collect::<TokenStream>()\n     };\n-    (!) => { TokenNode::Op('!', Spacing::Alone) };\n-    (<) => { TokenNode::Op('<', Spacing::Alone) };\n-    (>) => { TokenNode::Op('>', Spacing::Alone) };\n-    (_) => { TokenNode::Op('_', Spacing::Alone) };\n-    (0) => { TokenNode::Literal(::Literal::integer(0)) };\n-    (&) => { TokenNode::Op('&', Spacing::Alone) };\n-    ($i:ident) => { TokenNode::Term(Term::intern(stringify!($i))) };\n+    (!) => { tt2ts!(Op::new('!', Spacing::Alone)) };\n+    (<) => { tt2ts!(Op::new('<', Spacing::Alone)) };\n+    (>) => { tt2ts!(Op::new('>', Spacing::Alone)) };\n+    (_) => { tt2ts!(Op::new('_', Spacing::Alone)) };\n+    (0) => { tt2ts!(Literal::i8_unsuffixed(0)) };\n+    (&) => { tt2ts!(Op::new('&', Spacing::Alone)) };\n+    ($i:ident) => { tt2ts!(Term::new(stringify!($i), Span::def_site())) };\n }\n \n macro_rules! quote_tree {\n     ((unquote $($t:tt)*)) => { $($t)* };\n     ((quote $($t:tt)*)) => { ($($t)*).quote() };\n-    (($($t:tt)*)) => { TokenNode::Group(Delimiter::Parenthesis, quote!($($t)*)) };\n-    ([$($t:tt)*]) => { TokenNode::Group(Delimiter::Bracket, quote!($($t)*)) };\n-    ({$($t:tt)*}) => { TokenNode::Group(Delimiter::Brace, quote!($($t)*)) };\n+    (($($t:tt)*)) => { tt2ts!(Group::new(Delimiter::Parenthesis, quote!($($t)*))) };\n+    ([$($t:tt)*]) => { tt2ts!(Group::new(Delimiter::Bracket, quote!($($t)*))) };\n+    ({$($t:tt)*}) => { tt2ts!(Group::new(Delimiter::Brace, quote!($($t)*))) };\n     ($t:tt) => { quote_tok!($t) };\n }\n \n macro_rules! quote {\n     () => { TokenStream::empty() };\n     ($($t:tt)*) => {\n-        [\n-            $(TokenStream::from(quote_tree!($t)),)*\n-        ].iter().cloned().collect::<TokenStream>()\n+        [$(quote_tree!($t),)*].iter()\n+            .cloned()\n+            .flat_map(|x| x.into_iter())\n+            .collect::<TokenStream>()\n     };\n }\n \n@@ -97,72 +109,81 @@ impl Quote for TokenStream {\n         let tokens = self.into_iter().filter_map(|tree| {\n             if after_dollar {\n                 after_dollar = false;\n-                match tree.kind {\n-                    TokenNode::Term(_) => {\n+                match tree {\n+                    TokenTree::Term(_) => {\n+                        let tree = TokenStream::from(tree);\n                         return Some(quote!(::__internal::unquote(&(unquote tree)),));\n                     }\n-                    TokenNode::Op('$', _) => {}\n+                    TokenTree::Op(ref tt) if tt.op() == '$' => {}\n                     _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n                 }\n-            } else if let TokenNode::Op('$', _) = tree.kind {\n-                after_dollar = true;\n-                return None;\n+            } else if let TokenTree::Op(tt) = tree {\n+                if tt.op() == '$' {\n+                    after_dollar = true;\n+                    return None;\n+                }\n             }\n \n             Some(quote!(::TokenStream::from((quote tree)),))\n-        }).collect::<TokenStream>();\n+        }).flat_map(|t| t.into_iter()).collect::<TokenStream>();\n \n         if after_dollar {\n             panic!(\"unexpected trailing `$` in `quote!`\");\n         }\n \n-        quote!([(unquote tokens)].iter().cloned().collect::<::TokenStream>())\n+        quote!(\n+            [(unquote tokens)].iter()\n+                .cloned()\n+                .flat_map(|x| x.into_iter())\n+                .collect::<::TokenStream>()\n+        )\n     }\n }\n \n impl Quote for TokenTree {\n     fn quote(self) -> TokenStream {\n-        quote!(::TokenTree { span: (quote self.span), kind: (quote self.kind) })\n+        match self {\n+            TokenTree::Op(tt) => quote!(::TokenTree::Op( (quote tt) )),\n+            TokenTree::Group(tt) => quote!(::TokenTree::Group( (quote tt) )),\n+            TokenTree::Term(tt) => quote!(::TokenTree::Term( (quote tt) )),\n+            TokenTree::Literal(tt) => quote!(::TokenTree::Literal( (quote tt) )),\n+        }\n     }\n }\n \n-impl Quote for TokenNode {\n+impl Quote for char {\n     fn quote(self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident($($arg:ident),+)),*) => {\n-                match self {\n-                    $(TokenNode::$i($($arg),+) => quote! {\n-                        ::TokenNode::$i($((quote $arg)),+)\n-                    },)*\n-                }\n-            }\n-        }\n+        TokenTree::from(Literal::character(self)).into()\n+    }\n+}\n \n-        gen_match! { Op(op, kind), Group(delim, tokens), Term(term), Literal(lit) }\n+impl<'a> Quote for &'a str {\n+    fn quote(self) -> TokenStream {\n+        TokenTree::from(Literal::string(self)).into()\n     }\n }\n \n-impl Quote for char {\n+impl Quote for usize {\n     fn quote(self) -> TokenStream {\n-        TokenNode::Literal(Literal::character(self)).into()\n+        TokenTree::from(Literal::usize_unsuffixed(self)).into()\n     }\n }\n \n-impl<'a> Quote for &'a str {\n+impl Quote for Group {\n     fn quote(self) -> TokenStream {\n-        TokenNode::Literal(Literal::string(self)).into()\n+        quote!(::Group::new((quote self.delimiter()), (quote self.stream())))\n     }\n }\n \n-impl Quote for usize {\n+impl Quote for Op {\n     fn quote(self) -> TokenStream {\n-        TokenNode::Literal(Literal::integer(self as i128)).into()\n+        quote!(::Op::new((quote self.op()), (quote self.spacing())))\n     }\n }\n \n impl Quote for Term {\n     fn quote(self) -> TokenStream {\n-        quote!(::Term::intern((quote self.as_str())))\n+        quote!(::Term::new((quote self.as_str()), (quote self.span())))\n     }\n }\n \n@@ -182,31 +203,38 @@ macro_rules! literals {\n         impl LiteralKind {\n             pub fn with_contents_and_suffix(self, contents: Term, suffix: Option<Term>)\n                                             -> Literal {\n-                let contents = contents.0;\n-                let suffix = suffix.map(|t| t.0);\n+                let sym = contents.sym;\n+                let suffix = suffix.map(|t| t.sym);\n                 match self {\n                     $(LiteralKind::$i => {\n-                        Literal(token::Literal(token::Lit::$i(contents), suffix))\n+                        Literal {\n+                            token: token::Literal(token::Lit::$i(sym), suffix),\n+                            span: contents.span,\n+                        }\n                     })*\n                     $(LiteralKind::$raw(n) => {\n-                        Literal(token::Literal(token::Lit::$raw(contents, n), suffix))\n+                        Literal {\n+                            token: token::Literal(token::Lit::$raw(sym, n), suffix),\n+                            span: contents.span,\n+                        }\n                     })*\n                 }\n             }\n         }\n \n         impl Literal {\n             fn kind_contents_and_suffix(self) -> (LiteralKind, Term, Option<Term>) {\n-                let (lit, suffix) = match self.0 {\n+                let (lit, suffix) = match self.token {\n                     token::Literal(lit, suffix) => (lit, suffix),\n-                    _ => panic!(\"unsupported literal {:?}\", self.0),\n+                    _ => panic!(\"unsupported literal {:?}\", self.token),\n                 };\n \n                 let (kind, contents) = match lit {\n                     $(token::Lit::$i(contents) => (LiteralKind::$i, contents),)*\n                     $(token::Lit::$raw(contents, n) => (LiteralKind::$raw(n), contents),)*\n                 };\n-                (kind, Term(contents), suffix.map(Term))\n+                let suffix = suffix.map(|sym| Term::new(&sym.as_str(), self.span()));\n+                (kind, Term::new(&contents.as_str(), self.span()), suffix)\n             }\n         }\n "}, {"sha": "bbfec5815ba5c17262c9c7fe12864b9b58358c6b", "filename": "src/test/compile-fail-fulldeps/proc-macro/auxiliary/attributes-included.rs", "status": "modified", "additions": 47, "deletions": 40, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fauxiliary%2Fattributes-included.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fauxiliary%2Fattributes-included.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fauxiliary%2Fattributes-included.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -16,7 +16,7 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, TokenTree, TokenNode, Delimiter, Literal, Spacing};\n+use proc_macro::{TokenStream, TokenTree, Delimiter, Literal, Spacing, Group};\n \n #[proc_macro_attribute]\n pub fn foo(attr: TokenStream, input: TokenStream) -> TokenStream {\n@@ -52,24 +52,30 @@ pub fn bar(attr: TokenStream, input: TokenStream) -> TokenStream {\n }\n \n fn assert_inline(slice: &mut &[TokenTree]) {\n-    match slice[0].kind {\n-        TokenNode::Op('#', _) => {}\n+    match &slice[0] {\n+        TokenTree::Op(tt) => assert_eq!(tt.op(), '#'),\n         _ => panic!(\"expected '#' char\"),\n     }\n-    match slice[1].kind {\n-        TokenNode::Group(Delimiter::Bracket, _) => {}\n+    match &slice[1] {\n+        TokenTree::Group(tt) => assert_eq!(tt.delimiter(), Delimiter::Bracket),\n         _ => panic!(\"expected brackets\"),\n     }\n     *slice = &slice[2..];\n }\n \n fn assert_doc(slice: &mut &[TokenTree]) {\n-    match slice[0].kind {\n-        TokenNode::Op('#', Spacing::Alone) => {}\n+    match &slice[0] {\n+        TokenTree::Op(tt) => {\n+            assert_eq!(tt.op(), '#');\n+            assert_eq!(tt.spacing(), Spacing::Alone);\n+        }\n         _ => panic!(\"expected #\"),\n     }\n-    let inner = match slice[1].kind {\n-        TokenNode::Group(Delimiter::Bracket, ref s) => s.clone(),\n+    let inner = match &slice[1] {\n+        TokenTree::Group(tt) => {\n+            assert_eq!(tt.delimiter(), Delimiter::Bracket);\n+            tt.stream()\n+        }\n         _ => panic!(\"expected brackets\"),\n     };\n     let tokens = inner.into_iter().collect::<Vec<_>>();\n@@ -79,49 +85,55 @@ fn assert_doc(slice: &mut &[TokenTree]) {\n         panic!(\"expected three tokens in doc\")\n     }\n \n-    match tokens[0].kind {\n-        TokenNode::Term(ref t) => assert_eq!(\"doc\", t.as_str()),\n+    match &tokens[0] {\n+        TokenTree::Term(tt) => assert_eq!(\"doc\", tt.as_str()),\n         _ => panic!(\"expected `doc`\"),\n     }\n-    match tokens[1].kind {\n-        TokenNode::Op('=', Spacing::Alone) => {}\n+    match &tokens[1] {\n+        TokenTree::Op(tt) => {\n+            assert_eq!(tt.op(), '=');\n+            assert_eq!(tt.spacing(), Spacing::Alone);\n+        }\n         _ => panic!(\"expected equals\"),\n     }\n-    match tokens[2].kind {\n-        TokenNode::Literal(_) => {}\n+    match tokens[2] {\n+        TokenTree::Literal(_) => {}\n         _ => panic!(\"expected literal\"),\n     }\n \n     *slice = &slice[2..];\n }\n \n fn assert_invoc(slice: &mut &[TokenTree]) {\n-    match slice[0].kind {\n-        TokenNode::Op('#', _) => {}\n+    match &slice[0] {\n+        TokenTree::Op(tt) => assert_eq!(tt.op(), '#'),\n         _ => panic!(\"expected '#' char\"),\n     }\n-    match slice[1].kind {\n-        TokenNode::Group(Delimiter::Bracket, _) => {}\n+    match &slice[1] {\n+        TokenTree::Group(tt) => assert_eq!(tt.delimiter(), Delimiter::Bracket),\n         _ => panic!(\"expected brackets\"),\n     }\n     *slice = &slice[2..];\n }\n \n fn assert_foo(slice: &mut &[TokenTree]) {\n-    match slice[0].kind {\n-        TokenNode::Term(ref name) => assert_eq!(name.as_str(), \"fn\"),\n+    match &slice[0] {\n+        TokenTree::Term(tt) => assert_eq!(tt.as_str(), \"fn\"),\n         _ => panic!(\"expected fn\"),\n     }\n-    match slice[1].kind {\n-        TokenNode::Term(ref name) => assert_eq!(name.as_str(), \"foo\"),\n+    match &slice[1] {\n+        TokenTree::Term(tt) => assert_eq!(tt.as_str(), \"foo\"),\n         _ => panic!(\"expected foo\"),\n     }\n-    match slice[2].kind {\n-        TokenNode::Group(Delimiter::Parenthesis, ref s) => assert!(s.is_empty()),\n+    match &slice[2] {\n+        TokenTree::Group(tt) => {\n+            assert_eq!(tt.delimiter(), Delimiter::Parenthesis);\n+            assert!(tt.stream().is_empty());\n+        }\n         _ => panic!(\"expected parens\"),\n     }\n-    match slice[3].kind {\n-        TokenNode::Group(Delimiter::Brace, _) => {}\n+    match &slice[3] {\n+        TokenTree::Group(tt) => assert_eq!(tt.delimiter(), Delimiter::Brace),\n         _ => panic!(\"expected braces\"),\n     }\n     *slice = &slice[4..];\n@@ -132,22 +144,17 @@ fn fold_stream(input: TokenStream) -> TokenStream {\n }\n \n fn fold_tree(input: TokenTree) -> TokenTree {\n-    TokenTree {\n-        span: input.span,\n-        kind: fold_node(input.kind),\n-    }\n-}\n-\n-fn fold_node(input: TokenNode) -> TokenNode {\n     match input {\n-        TokenNode::Group(a, b) => TokenNode::Group(a, fold_stream(b)),\n-        TokenNode::Op(a, b) => TokenNode::Op(a, b),\n-        TokenNode::Term(a) => TokenNode::Term(a),\n-        TokenNode::Literal(a) => {\n+        TokenTree::Group(b) => {\n+            TokenTree::Group(Group::new(b.delimiter(), fold_stream(b.stream())))\n+        }\n+        TokenTree::Op(b) => TokenTree::Op(b),\n+        TokenTree::Term(a) => TokenTree::Term(a),\n+        TokenTree::Literal(a) => {\n             if a.to_string() != \"\\\"foo\\\"\" {\n-                TokenNode::Literal(a)\n+                TokenTree::Literal(a)\n             } else {\n-                TokenNode::Literal(Literal::integer(3))\n+                TokenTree::Literal(Literal::i32_unsuffixed(3))\n             }\n         }\n     }"}, {"sha": "281ee70815e11c80442dfce57c8735435ef49c9a", "filename": "src/test/run-pass-fulldeps/auxiliary/cond_plugin.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -15,15 +15,15 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, TokenNode, quote};\n+use proc_macro::*;\n \n #[proc_macro]\n pub fn cond(input: TokenStream) -> TokenStream {\n     let mut conds = Vec::new();\n     let mut input = input.into_iter().peekable();\n     while let Some(tree) = input.next() {\n-        let cond = match tree.kind {\n-            TokenNode::Group(_, cond) => cond,\n+        let cond = match tree {\n+            TokenTree::Group(tt) => tt.stream(),\n             _ => panic!(\"Invalid input\"),\n         };\n         let mut cond_trees = cond.clone().into_iter();\n@@ -32,8 +32,8 @@ pub fn cond(input: TokenStream) -> TokenStream {\n         if rhs.is_empty() {\n             panic!(\"Invalid macro usage in cond: {}\", cond);\n         }\n-        let is_else = match test.kind {\n-            TokenNode::Term(word) => word.as_str() == \"else\",\n+        let is_else = match test {\n+            TokenTree::Term(word) => word.as_str() == \"else\",\n             _ => false,\n         };\n         conds.push(if is_else || input.peek().is_none() {\n@@ -43,5 +43,5 @@ pub fn cond(input: TokenStream) -> TokenStream {\n         });\n     }\n \n-    conds.into_iter().collect()\n+    conds.into_iter().flat_map(|x| x.into_iter()).collect()\n }"}, {"sha": "d3670ae66feedf01ba43f5870b6b5131d3375afd", "filename": "src/test/run-pass-fulldeps/auxiliary/proc_macro_def.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fproc_macro_def.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fproc_macro_def.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fproc_macro_def.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -15,7 +15,7 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, quote};\n+use proc_macro::*;\n \n #[proc_macro_attribute]\n pub fn attr_tru(_attr: TokenStream, item: TokenStream) -> TokenStream {"}, {"sha": "063d8dc40536dc5a737ca96020bafc1d8af0e2a9", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/count_compound_ops.rs", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fcount_compound_ops.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fcount_compound_ops.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fcount_compound_ops.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -15,20 +15,25 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, TokenNode, Spacing, Literal, quote};\n+use proc_macro::{TokenStream, TokenTree, Spacing, Literal, quote};\n \n #[proc_macro]\n pub fn count_compound_ops(input: TokenStream) -> TokenStream {\n     assert_eq!(count_compound_ops_helper(quote!(++ (&&) 4@a)), 3);\n-    TokenNode::Literal(Literal::u32(count_compound_ops_helper(input))).into()\n+    let l = Literal::u32_suffixed(count_compound_ops_helper(input));\n+    TokenTree::from(l).into()\n }\n \n fn count_compound_ops_helper(input: TokenStream) -> u32 {\n     let mut count = 0;\n     for token in input {\n-        match token.kind {\n-            TokenNode::Op(c, Spacing::Alone) => count += 1,\n-            TokenNode::Group(_, tokens) => count += count_compound_ops_helper(tokens),\n+        match &token {\n+            TokenTree::Op(tt) if tt.spacing() == Spacing::Alone => {\n+                count += 1;\n+            }\n+            TokenTree::Group(tt) => {\n+                count += count_compound_ops_helper(tt.stream());\n+            }\n             _ => {}\n         }\n     }"}, {"sha": "e76e4d585f497562691d16094397c253923e04e1", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/negative-token.rs", "status": "modified", "additions": 2, "deletions": 8, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnegative-token.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnegative-token.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnegative-token.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -19,16 +19,10 @@ use proc_macro::*;\n \n #[proc_macro]\n pub fn neg_one(_input: TokenStream) -> TokenStream {\n-    TokenTree {\n-        span: Span::call_site(),\n-        kind: TokenNode::Literal(Literal::i32(-1)),\n-    }.into()\n+    TokenTree::Literal(Literal::i32_suffixed(-1)).into()\n }\n \n #[proc_macro]\n pub fn neg_one_float(_input: TokenStream) -> TokenStream {\n-    TokenTree {\n-        span: Span::call_site(),\n-        kind: TokenNode::Literal(Literal::f32(-1.0)),\n-    }.into()\n+    TokenTree::Literal(Literal::f32_suffixed(-1.0)).into()\n }"}, {"sha": "6ab9d6d0b8a7ce1dc688b54a6ce7161ee02f6c2c", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/span-api-tests.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fspan-api-tests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fspan-api-tests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fspan-api-tests.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -27,7 +27,7 @@ pub fn reemit(input: TokenStream) -> TokenStream {\n #[proc_macro]\n pub fn assert_fake_source_file(input: TokenStream) -> TokenStream {\n     for tk in input {\n-        let source_file = tk.span.source_file();\n+        let source_file = tk.span().source_file();\n         assert!(!source_file.is_real(), \"Source file is real: {:?}\", source_file);\n     }\n \n@@ -37,7 +37,7 @@ pub fn assert_fake_source_file(input: TokenStream) -> TokenStream {\n #[proc_macro]\n pub fn assert_source_file(input: TokenStream) -> TokenStream {\n     for tk in input {\n-        let source_file = tk.span.source_file();\n+        let source_file = tk.span().source_file();\n         assert!(source_file.is_real(), \"Source file is not real: {:?}\", source_file);\n     }\n "}, {"sha": "ed11b2db2f5ffb235eaecd81e7a1d621642eb1f5", "filename": "src/test/ui-fulldeps/proc-macro/auxiliary/parent-source-spans.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fparent-source-spans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fparent-source-spans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fparent-source-spans.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -14,12 +14,12 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, TokenTree, TokenNode, Span};\n+use proc_macro::{TokenStream, TokenTree, Span};\n \n fn lit_span(tt: TokenTree) -> (Span, String) {\n-    use TokenNode::*;\n-    match tt.kind {\n-        Literal(..) | Group(..) => (tt.span, tt.to_string().trim().into()),\n+    match tt {\n+        TokenTree::Literal(..) |\n+        TokenTree::Group(..) => (tt.span(), tt.to_string().trim().into()),\n         _ => panic!(\"expected a literal in token tree, got: {:?}\", tt)\n     }\n }"}, {"sha": "fda0e28891f26b0712f7b264f3b8070a8348e100", "filename": "src/test/ui-fulldeps/proc-macro/auxiliary/three-equals.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fthree-equals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/553c04d9eb311189cbd01d1af7f6c2c26578342c/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fthree-equals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fthree-equals.rs?ref=553c04d9eb311189cbd01d1af7f6c2c26578342c", "patch": "@@ -14,26 +14,27 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, TokenNode, Span, Diagnostic};\n+use proc_macro::{TokenStream, TokenTree, Span, Diagnostic};\n \n fn parse(input: TokenStream) -> Result<(), Diagnostic> {\n     let mut count = 0;\n     let mut last_span = Span::def_site();\n     for tree in input {\n-        let span = tree.span;\n+        let span = tree.span();\n         if count >= 3 {\n             return Err(span.error(format!(\"expected EOF, found `{}`.\", tree))\n                            .span_note(last_span, \"last good input was here\")\n                            .help(\"input must be: `===`\"))\n         }\n \n-        if let TokenNode::Op('=', _) = tree.kind {\n-            count += 1;\n-        } else {\n-            return Err(span.error(format!(\"expected `=`, found `{}`.\", tree)));\n+        if let TokenTree::Op(tt) = tree {\n+            if tt.op() == '=' {\n+                count += 1;\n+                last_span = span;\n+                continue\n+            }\n         }\n-\n-        last_span = span;\n+        return Err(span.error(format!(\"expected `=`, found `{}`.\", tree)));\n     }\n \n     if count < 3 {"}]}