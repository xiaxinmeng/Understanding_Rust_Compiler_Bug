{"sha": "0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjYWViZmFiZTZmMzUwNjM1NTU4MWIyZmJmY2ZhMGNhMDVhNzY4ZmM=", "commit": {"author": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-03-17T15:45:02Z"}, "committer": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-07-26T22:37:02Z"}, "message": "Hygiene serialization implementation", "tree": {"sha": "eca88f696de79845ca88ee7b99623e3bf34e5844", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/eca88f696de79845ca88ee7b99623e3bf34e5844"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE7J9Gc3TfBwj2K399tAh+UQ6YsWQFAl8eBY4ACgkQtAh+UQ6Y\nsWQ1Fg/+OBsdEh6+aeeJZVTBojDTJ0nffNENzrzXwAUlYZJVzuigFz8xFgcAfriI\nodXc/5TlhuYEhl+oWlR7quT5xsJOxJUJlpDu2yS5PVLPFPRKS4I37aAI7QdghMSn\nqUQEW6eIAUuJnyCd8y6PARln3J3DFFWlafwEeIymB+Qz5exd/u64qQr26WILeRfQ\nR2nYNmqYtq4XIfnl1j4cSGFBF2r35VVY1DgKknMvFT7jGSdmvUb5PDnh2e+pTe3F\nTCHucZo6OVY4gCNsKCiCJGsY5P8DGv6yrzEhKfkbZZTmyYSDMjRZ8VAwhh22pmYV\nOcHZ2mrj9YnQUFnz1quudnqej8e55ZlIZMq/sJhVD/wP3tB/1k0KYOhr195G8fbr\nOtjrjex8eYLlHSTY9urYhbwo0SHf4kV8Qvx5GPBukLUa8s32R/1t5oMIYb7QlL0D\nOIXxOhDbZIHAn+F3Edqozs8YyQU2EeE6g0LyMsba5kWcP5+B4bHMEl85/3QYlNoZ\nZZhmM8ZnPu6m7vF31sJ/pe2JQDVrkMIta95k9JkQqxeEP57AbMBCvWCdsu8DU9kT\nWvF/VKW3xa98RLKsBcxBx4tbvRnEQ57BA4W554Ja65hl1ZwG6nXkoeEJv3vmvrvg\nrxxEl5OZIDgb9Tpvn6AEPVAxehPTRLgy9kNYpc377FXRPnxXqtQ=\n=dLfC\n-----END PGP SIGNATURE-----", "payload": "tree eca88f696de79845ca88ee7b99623e3bf34e5844\nparent 6c8927b0cf80ceee19386026cf9d7fd4fd9d486f\nauthor Aaron Hill <aa1ronham@gmail.com> 1584459902 -0400\ncommitter Aaron Hill <aa1ronham@gmail.com> 1595803022 -0400\n\nHygiene serialization implementation\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "html_url": "https://github.com/rust-lang/rust/commit/0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/comments", "author": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6c8927b0cf80ceee19386026cf9d7fd4fd9d486f", "url": "https://api.github.com/repos/rust-lang/rust/commits/6c8927b0cf80ceee19386026cf9d7fd4fd9d486f", "html_url": "https://github.com/rust-lang/rust/commit/6c8927b0cf80ceee19386026cf9d7fd4fd9d486f"}], "stats": {"total": 1213, "additions": 929, "deletions": 284}, "files": [{"sha": "abd5df537db99f14354b4ce904ab43d03cfc3e14", "filename": "src/librustc_ast_lowering/expr.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_ast_lowering%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_ast_lowering%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast_lowering%2Fexpr.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -9,7 +9,8 @@ use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::struct_span_err;\n use rustc_hir as hir;\n use rustc_hir::def::Res;\n-use rustc_span::source_map::{respan, DesugaringKind, ForLoopLoc, Span, Spanned};\n+use rustc_span::hygiene::ForLoopLoc;\n+use rustc_span::source_map::{respan, DesugaringKind, Span, Spanned};\n use rustc_span::symbol::{sym, Ident, Symbol};\n use rustc_target::asm;\n use std::collections::hash_map::Entry;"}, {"sha": "daa75d423249aa4da01bb6146224a041acb36f2f", "filename": "src/librustc_expand/base.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_expand%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_expand%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_expand%2Fbase.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -13,7 +13,7 @@ use rustc_data_structures::sync::{self, Lrc};\n use rustc_errors::{DiagnosticBuilder, ErrorReported};\n use rustc_parse::{self, nt_to_tokenstream, parser, MACRO_ARGUMENTS};\n use rustc_session::{parse::ParseSess, Limit};\n-use rustc_span::def_id::DefId;\n+use rustc_span::def_id::{DefId, LOCAL_CRATE};\n use rustc_span::edition::Edition;\n use rustc_span::hygiene::{AstPass, ExpnData, ExpnId, ExpnKind};\n use rustc_span::source_map::SourceMap;\n@@ -873,6 +873,8 @@ impl SyntaxExtension {\n             local_inner_macros: self.local_inner_macros,\n             edition: self.edition,\n             macro_def_id,\n+            krate: LOCAL_CRATE,\n+            orig_id: None,\n         }\n     }\n }"}, {"sha": "4a40f799c15b7dd1bea183a1406cf671b5345db0", "filename": "src/librustc_expand/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_expand%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_expand%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_expand%2Fexpand.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -1,7 +1,7 @@\n use crate::base::*;\n use crate::config::StripUnconfigured;\n use crate::configure;\n-use crate::hygiene::{ExpnData, ExpnId, ExpnKind, SyntaxContext};\n+use crate::hygiene::{ExpnData, ExpnKind, SyntaxContext};\n use crate::mbe::macro_rules::annotate_err_with_kind;\n use crate::module::{parse_external_mod, push_directory, Directory, DirectoryOwnership};\n use crate::placeholders::{placeholder, PlaceholderExpander};\n@@ -27,7 +27,7 @@ use rustc_session::parse::{feature_err, ParseSess};\n use rustc_session::Limit;\n use rustc_span::source_map::respan;\n use rustc_span::symbol::{sym, Ident, Symbol};\n-use rustc_span::{FileName, Span, DUMMY_SP};\n+use rustc_span::{ExpnId, FileName, Span, DUMMY_SP};\n \n use smallvec::{smallvec, SmallVec};\n use std::io::ErrorKind;"}, {"sha": "724b4123fab6c9243857d92b2733ee52e5547b9f", "filename": "src/librustc_metadata/creader.rs", "status": "modified", "additions": 21, "deletions": 15, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Fcreader.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Fcreader.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcreader.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -307,11 +307,16 @@ impl<'a> CrateLoader<'a> {\n         let private_dep =\n             self.sess.opts.externs.get(&name.as_str()).map(|e| e.is_private_dep).unwrap_or(false);\n \n-        info!(\"register crate `{}` (private_dep = {})\", crate_root.name(), private_dep);\n-\n         // Claim this crate number and cache it\n         let cnum = self.cstore.alloc_new_crate_num();\n \n+        info!(\n+            \"register crate `{}` (cnum = {}. private_dep = {})\",\n+            crate_root.name(),\n+            cnum,\n+            private_dep\n+        );\n+\n         // Maintain a reference to the top most crate.\n         // Stash paths for top-most crate locally if necessary.\n         let crate_paths;\n@@ -339,22 +344,21 @@ impl<'a> CrateLoader<'a> {\n             None\n         };\n \n-        self.cstore.set_crate_data(\n+        let crate_metadata = CrateMetadata::new(\n+            self.sess,\n+            metadata,\n+            crate_root,\n+            raw_proc_macros,\n             cnum,\n-            CrateMetadata::new(\n-                self.sess,\n-                metadata,\n-                crate_root,\n-                raw_proc_macros,\n-                cnum,\n-                cnum_map,\n-                dep_kind,\n-                source,\n-                private_dep,\n-                host_hash,\n-            ),\n+            cnum_map,\n+            dep_kind,\n+            source,\n+            private_dep,\n+            host_hash,\n         );\n \n+        self.cstore.set_crate_data(cnum, crate_metadata);\n+\n         Ok(cnum)\n     }\n \n@@ -569,6 +573,8 @@ impl<'a> CrateLoader<'a> {\n             let cnum = self.maybe_resolve_crate(dep.name, dep_kind, Some((root, &dep)))?;\n             crate_num_map.push(cnum);\n         }\n+\n+        debug!(\"resolve_crate_deps: cnum_map for {:?} is {:?}\", krate, crate_num_map);\n         Ok(crate_num_map)\n     }\n "}, {"sha": "d4add2ab7ade0898ab5f086f57c9c3f65849049d", "filename": "src/librustc_metadata/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Flib.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -9,6 +9,7 @@\n #![feature(proc_macro_internals)]\n #![feature(min_specialization)]\n #![feature(stmt_expr_attributes)]\n+#![feature(never_type)]\n #![recursion_limit = \"256\"]\n \n extern crate proc_macro;"}, {"sha": "7d428840cc906609e913f8465e68944905f1ab52", "filename": "src/librustc_metadata/rmeta/decoder.rs", "status": "modified", "additions": 76, "deletions": 2, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -32,18 +32,21 @@ use rustc_middle::ty::{self, Ty, TyCtxt};\n use rustc_middle::util::common::record_time;\n use rustc_serialize::{opaque, Decodable, Decoder, SpecializedDecoder, UseSpecializedDecodable};\n use rustc_session::Session;\n+use rustc_span::hygiene::ExpnDataDecodeMode;\n use rustc_span::source_map::{respan, Spanned};\n use rustc_span::symbol::{sym, Ident, Symbol};\n-use rustc_span::{self, hygiene::MacroKind, BytePos, Pos, Span, DUMMY_SP};\n+use rustc_span::{self, hygiene::MacroKind, BytePos, ExpnId, Pos, Span, SyntaxContext, DUMMY_SP};\n \n use log::debug;\n use proc_macro::bridge::client::ProcMacro;\n+use std::cell::Cell;\n use std::io;\n use std::mem;\n use std::num::NonZeroUsize;\n use std::path::Path;\n \n pub use cstore_impl::{provide, provide_extern};\n+use rustc_span::hygiene::HygieneContext;\n \n mod cstore_impl;\n \n@@ -106,6 +109,13 @@ crate struct CrateMetadata {\n     /// The hash for the host proc macro. Used to support `-Z dual-proc-macro`.\n     host_hash: Option<Svh>,\n \n+    /// Additional data used for decoding `HygieneData` (e.g. `SyntaxContext`\n+    /// and `ExpnId`).\n+    /// Note that we store a `HygieneContext` for each `CrateMetadat`. This is\n+    /// because `SyntaxContext` ids are not globally unique, so we need\n+    /// to track which ids we've decoded on a per-crate basis.\n+    hygiene_context: HygieneContext,\n+\n     // --- Data used only for improving diagnostics ---\n     /// Information about the `extern crate` item or path that caused this crate to be loaded.\n     /// If this is `None`, then the crate was injected (e.g., by the allocator).\n@@ -411,6 +421,7 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for DecodeContext<'a, 'tcx> {\n \n         let lo = BytePos::decode(self)?;\n         let len = BytePos::decode(self)?;\n+        let ctxt = SyntaxContext::decode(self)?;\n         let hi = lo + len;\n \n         let sess = if let Some(sess) = self.sess {\n@@ -524,7 +535,7 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for DecodeContext<'a, 'tcx> {\n         let hi =\n             (hi + source_file.translated_source_file.start_pos) - source_file.original_start_pos;\n \n-        Ok(Span::with_root_ctxt(lo, hi))\n+        Ok(Span::new(lo, hi, ctxt))\n     }\n }\n \n@@ -1120,6 +1131,14 @@ impl<'a, 'tcx> CrateMetadataRef<'a> {\n         !self.is_proc_macro(id) && self.root.tables.mir.get(self, id).is_some()\n     }\n \n+    fn module_expansion(&self, id: DefIndex, sess: &Session) -> ExpnId {\n+        if let EntryKind::Mod(m) = self.kind(id) {\n+            m.decode((self, sess)).expansion\n+        } else {\n+            panic!(\"Expected module, found {:?}\", self.local_def_id(id))\n+        }\n+    }\n+\n     fn get_optimized_mir(&self, tcx: TyCtxt<'tcx>, id: DefIndex) -> Body<'tcx> {\n         self.root\n             .tables\n@@ -1652,6 +1671,7 @@ impl CrateMetadata {\n             private_dep,\n             host_hash,\n             extern_crate: Lock::new(None),\n+            hygiene_context: HygieneContext::new(),\n         }\n     }\n \n@@ -1784,3 +1804,57 @@ fn macro_kind(raw: &ProcMacro) -> MacroKind {\n         ProcMacro::Bang { .. } => MacroKind::Bang,\n     }\n }\n+\n+impl<'a, 'tcx> SpecializedDecoder<SyntaxContext> for DecodeContext<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<SyntaxContext, Self::Error> {\n+        let cdata = self.cdata();\n+        let sess = self.sess.unwrap();\n+        let cname = cdata.root.name;\n+        rustc_span::hygiene::decode_syntax_context(self, &cdata.hygiene_context, |_, id| {\n+            debug!(\"SpecializedDecoder<SyntaxContext>: decoding {}\", id);\n+            Ok(cdata\n+                .root\n+                .syntax_contexts\n+                .get(&cdata, id)\n+                .unwrap_or_else(|| panic!(\"Missing SyntaxContext {:?} for crate {:?}\", id, cname))\n+                .decode((&cdata, sess)))\n+        })\n+    }\n+}\n+\n+impl<'a, 'tcx> SpecializedDecoder<ExpnId> for DecodeContext<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<ExpnId, Self::Error> {\n+        let local_cdata = self.cdata();\n+        let sess = self.sess.unwrap();\n+        let expn_cnum = Cell::new(None);\n+        let get_ctxt = |cnum| {\n+            expn_cnum.set(Some(cnum));\n+            if cnum == LOCAL_CRATE {\n+                &local_cdata.hygiene_context\n+            } else {\n+                &local_cdata.cstore.get_crate_data(cnum).cdata.hygiene_context\n+            }\n+        };\n+\n+        rustc_span::hygiene::decode_expn_id(\n+            self,\n+            ExpnDataDecodeMode::Metadata(get_ctxt),\n+            |_this, index| {\n+                let cnum = expn_cnum.get().unwrap();\n+                // Lookup local `ExpnData`s in our own crate data. Foreign `ExpnData`s\n+                // are stored in the owning crate, to avoid duplication.\n+                let crate_data = if cnum == LOCAL_CRATE {\n+                    local_cdata\n+                } else {\n+                    local_cdata.cstore.get_crate_data(cnum)\n+                };\n+                Ok(crate_data\n+                    .root\n+                    .expn_data\n+                    .get(&crate_data, index)\n+                    .unwrap()\n+                    .decode((&crate_data, sess)))\n+            },\n+        )\n+    }\n+}"}, {"sha": "e51862be9a86fde19f8bf13abde658cf4de8e5a2", "filename": "src/librustc_metadata/rmeta/decoder/cstore_impl.rs", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -21,9 +21,10 @@ use rustc_middle::ty::{self, TyCtxt};\n use rustc_session::utils::NativeLibKind;\n use rustc_session::{CrateDisambiguator, Session};\n use rustc_span::source_map::{self, Span, Spanned};\n-use rustc_span::symbol::{Ident, Symbol};\n+use rustc_span::symbol::Symbol;\n \n use rustc_data_structures::sync::Lrc;\n+use rustc_span::ExpnId;\n use smallvec::SmallVec;\n use std::any::Any;\n \n@@ -417,13 +418,7 @@ impl CStore {\n             attr::mark_used(attr);\n         }\n \n-        let ident = data\n-            .def_key(id.index)\n-            .disambiguated_data\n-            .data\n-            .get_opt_name()\n-            .map(Ident::with_dummy_span) // FIXME: cross-crate hygiene\n-            .expect(\"no name in load_macro\");\n+        let ident = data.item_ident(id.index, sess);\n \n         LoadedMacro::MacroDef(\n             ast::Item {\n@@ -454,6 +449,10 @@ impl CStore {\n     pub fn item_generics_num_lifetimes(&self, def_id: DefId, sess: &Session) -> usize {\n         self.get_crate_data(def_id.krate).get_generics(def_id.index, sess).own_counts().lifetimes\n     }\n+\n+    pub fn module_expansion_untracked(&self, def_id: DefId, sess: &Session) -> ExpnId {\n+        self.get_crate_data(def_id.krate).module_expansion(def_id.index, sess)\n+    }\n }\n \n impl CrateStore for CStore {"}, {"sha": "6539c13d812c36cfc0d729e4dc2dc2a7435b0be4", "filename": "src/librustc_metadata/rmeta/encoder.rs", "status": "modified", "additions": 133, "deletions": 9, "changes": 142, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -1,4 +1,4 @@\n-use crate::rmeta::table::FixedSizeEncoding;\n+use crate::rmeta::table::{FixedSizeEncoding, TableBuilder};\n use crate::rmeta::*;\n \n use log::{debug, trace};\n@@ -30,9 +30,10 @@ use rustc_middle::ty::codec::{self as ty_codec, TyEncoder};\n use rustc_middle::ty::{self, SymbolName, Ty, TyCtxt};\n use rustc_serialize::{opaque, Encodable, Encoder, SpecializedEncoder, UseSpecializedEncodable};\n use rustc_session::config::CrateType;\n+use rustc_span::hygiene::ExpnDataEncodeMode;\n use rustc_span::source_map::Spanned;\n use rustc_span::symbol::{sym, Ident, Symbol};\n-use rustc_span::{self, ExternalSource, FileName, SourceFile, Span};\n+use rustc_span::{self, ExternalSource, FileName, SourceFile, Span, SyntaxContext};\n use rustc_target::abi::VariantIdx;\n use std::hash::Hash;\n use std::num::NonZeroUsize;\n@@ -66,6 +67,15 @@ struct EncodeContext<'tcx> {\n     // with a result containing a foreign `Span`.\n     required_source_files: Option<GrowableBitSet<usize>>,\n     is_proc_macro: bool,\n+    /// All `SyntaxContexts` for which we have writen `SyntaxContextData` into crate metadata.\n+    /// This is `None` after we finish encoding `SyntaxContexts`, to ensure\n+    /// that we don't accidentally try to encode any more `SyntaxContexts`\n+    serialized_ctxts: Option<FxHashSet<SyntaxContext>>,\n+    /// The `SyntaxContexts` that we have serialized (e.g. as a result of encoding `Spans`)\n+    /// in the most recent 'round' of serializnig. Serializing `SyntaxContextData`\n+    /// may cause us to serialize more `SyntaxContext`s, so serialize in a loop\n+    /// until we reach a fixed point.\n+    latest_ctxts: Option<FxHashSet<SyntaxContext>>,\n }\n \n macro_rules! encoder_methods {\n@@ -150,6 +160,21 @@ impl<'tcx> SpecializedEncoder<DefId> for EncodeContext<'tcx> {\n     }\n }\n \n+impl<'tcx> SpecializedEncoder<SyntaxContext> for EncodeContext<'tcx> {\n+    fn specialized_encode(&mut self, ctxt: &SyntaxContext) -> Result<(), Self::Error> {\n+        if !self.serialized_ctxts.as_ref().unwrap().contains(ctxt) {\n+            self.latest_ctxts.as_mut().unwrap().insert(*ctxt);\n+        }\n+        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, self)\n+    }\n+}\n+\n+impl<'tcx> SpecializedEncoder<ExpnId> for EncodeContext<'tcx> {\n+    fn specialized_encode(&mut self, expn: &ExpnId) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_expn_id(*expn, ExpnDataEncodeMode::Metadata, self)\n+    }\n+}\n+\n impl<'tcx> SpecializedEncoder<DefIndex> for EncodeContext<'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_index: &DefIndex) -> Result<(), Self::Error> {\n@@ -234,15 +259,24 @@ impl<'tcx> SpecializedEncoder<Span> for EncodeContext<'tcx> {\n         let len = hi - lo;\n         len.encode(self)?;\n \n+        // FIXME: Once #69976 is merged, treat proc-macros normally\n+        // Currently, we can't encode `SyntaxContextData` for proc-macro crates,\n+        // since the `SyntaxContextData`/`ExpnData` might reference `DefIds` from\n+        // dependencies (which are not currently loaded during decoding).\n+        if self.is_proc_macro {\n+            SyntaxContext::root().encode(self)?;\n+        } else {\n+            span.ctxt.encode(self)?;\n+        }\n+\n         if tag == TAG_VALID_SPAN_FOREIGN {\n             // This needs to be two lines to avoid holding the `self.source_file_cache`\n             // while calling `cnum.encode(self)`\n             let cnum = self.source_file_cache.0.cnum;\n             cnum.encode(self)?;\n         }\n-        Ok(())\n \n-        // Don't encode the expansion context.\n+        Ok(())\n     }\n }\n \n@@ -478,6 +512,7 @@ impl<'tcx> EncodeContext<'tcx> {\n \n         let mut i = self.position();\n \n+        // Encode the crate deps\n         let crate_deps = self.encode_crate_deps();\n         let dylib_dependency_formats = self.encode_dylib_dependency_formats();\n         let dep_bytes = self.position() - i;\n@@ -556,12 +591,23 @@ impl<'tcx> EncodeContext<'tcx> {\n         let proc_macro_data_bytes = self.position() - i;\n \n         // Encode exported symbols info. This is prefetched in `encode_metadata` so we encode\n-        // this late to give the prefetching as much time as possible to complete.\n+        // this as late as possible to give the prefetching as much time as possible to complete.\n         i = self.position();\n         let exported_symbols = tcx.exported_symbols(LOCAL_CRATE);\n         let exported_symbols = self.encode_exported_symbols(&exported_symbols);\n         let exported_symbols_bytes = self.position() - i;\n \n+        // Encode the hygiene data,\n+        // IMPORTANT: this *must* be the last thing that we encode (other than `SourceMap`). The process\n+        // of encoding other items (e.g. `optimized_mir`) may cause us to load\n+        // data from the incremental cache. If this causes us to deserialize a `Span`,\n+        // then we may load additional `SyntaxContext`s into the global `HygieneData`.\n+        // Therefore, we need to encode the hygiene data last to ensure that we encode\n+        // any `SyntaxContext`s that might be used.\n+        i = self.position();\n+        let (syntax_contexts, syntax_bytes, expn_data, expn_bytes) = self.encode_hygiene();\n+        let hygiene_bytes = self.position() - i;\n+\n         // Encode source_map. This needs to be done last,\n         // since encoding `Span`s tells us which `SourceFiles` we actually\n         // need to encode.\n@@ -618,6 +664,8 @@ impl<'tcx> EncodeContext<'tcx> {\n             exported_symbols,\n             interpret_alloc_index,\n             tables,\n+            syntax_contexts,\n+            expn_data,\n         });\n \n         let total_bytes = self.position();\n@@ -643,6 +691,9 @@ impl<'tcx> EncodeContext<'tcx> {\n             println!(\" proc-macro-data-bytes: {}\", proc_macro_data_bytes);\n             println!(\"            item bytes: {}\", item_bytes);\n             println!(\"           table bytes: {}\", tables_bytes);\n+            println!(\"         hygiene bytes: {}\", hygiene_bytes);\n+            println!(\"   SyntaxContext bytes: {}\", syntax_bytes);\n+            println!(\"          ExpnId bytes: {}\", expn_bytes);\n             println!(\"            zero bytes: {}\", zero_bytes);\n             println!(\"           total bytes: {}\", total_bytes);\n         }\n@@ -752,11 +803,12 @@ impl EncodeContext<'tcx> {\n         vis: &hir::Visibility<'_>,\n     ) {\n         let tcx = self.tcx;\n-        let def_id = tcx.hir().local_def_id(id);\n+        let local_def_id = tcx.hir().local_def_id(id);\n+        let def_id = local_def_id.to_def_id();\n         debug!(\"EncodeContext::encode_info_for_mod({:?})\", def_id);\n \n         let data = ModData {\n-            reexports: match tcx.module_exports(def_id) {\n+            reexports: match tcx.module_exports(local_def_id) {\n                 Some(exports) => {\n                     let hir_map = self.tcx.hir();\n                     self.lazy(\n@@ -767,10 +819,9 @@ impl EncodeContext<'tcx> {\n                 }\n                 _ => Lazy::empty(),\n             },\n+            expansion: tcx.hir().definitions().expansion_that_defined(local_def_id),\n         };\n \n-        let def_id = def_id.to_def_id();\n-\n         record!(self.tables.kind[def_id] <- EntryKind::Mod(self.lazy(data)));\n         record!(self.tables.visibility[def_id] <- ty::Visibility::from_hir(vis, id, self.tcx));\n         record!(self.tables.span[def_id] <- self.tcx.def_span(def_id));\n@@ -1425,6 +1476,77 @@ impl EncodeContext<'tcx> {\n         self.lazy(foreign_modules.iter().cloned())\n     }\n \n+    fn encode_hygiene(&mut self) -> (SyntaxContextTable, usize, ExpnDataTable, usize) {\n+        let mut syntax_contexts: TableBuilder<_, _> = Default::default();\n+        let mut expn_data_table: TableBuilder<_, _> = Default::default();\n+\n+        let mut i = self.position();\n+        // We need to encode the `ExpnData` *before* we encode\n+        // the `SyntaxContextData`, since encoding `ExpnData` may cause\n+        // us to use more `SyntaxContexts` when we encode the spans stored\n+        // inside `ExpnData`\n+        rustc_span::hygiene::for_all_expn_data(|index, expn_data| {\n+            // Don't encode the ExpnData for ExpnIds from foreign crates.\n+            // The crate that defines the ExpnId will store the ExpnData,\n+            // and the metadata decoder will look it from from that crate via the CStore\n+            if expn_data.krate == LOCAL_CRATE {\n+                expn_data_table.set(index, self.lazy(expn_data));\n+            }\n+            Ok::<(), !>(())\n+        })\n+        .unwrap();\n+\n+        let expn_bytes = self.position() - i;\n+\n+        i = self.position();\n+        let mut num_serialized = 0;\n+\n+        // When we serialize a `SyntaxContextData`, we may end up serializing\n+        // a `SyntaxContext` that we haven't seen before. Therefore,\n+        while !self.latest_ctxts.as_ref().unwrap().is_empty() {\n+            debug!(\n+                \"encode_hygiene: Serializing a round of {:?} SyntaxContextDatas: {:?}\",\n+                self.latest_ctxts.as_ref().unwrap().len(),\n+                self.latest_ctxts.as_ref().unwrap()\n+            );\n+\n+            // Consume the current round of SyntaxContexts.\n+            let latest = self.latest_ctxts.replace(FxHashSet::default()).unwrap();\n+\n+            // It's fine to iterate over a HashMap, because thw serialization\n+            // of the table that we insert data into doesn't depend on insertion\n+            // order\n+            rustc_span::hygiene::for_all_data_in(latest.into_iter(), |(index, ctxt, data)| {\n+                if self.serialized_ctxts.as_mut().unwrap().insert(ctxt) {\n+                    syntax_contexts.set(index, self.lazy(data));\n+                    num_serialized += 1;\n+                }\n+                Ok::<_, !>(())\n+            })\n+            .unwrap();\n+        }\n+        debug!(\"encode_hygiene: Done serializing SyntaxContextData\");\n+        let syntax_bytes = self.position() - i;\n+\n+        let total = rustc_span::hygiene::num_syntax_ctxts();\n+        debug!(\n+            \"encode_hygiene: stored {}/{} ({})\",\n+            num_serialized,\n+            total,\n+            (num_serialized as f32) / (total as f32)\n+        );\n+\n+        self.serialized_ctxts.take();\n+        self.latest_ctxts.take();\n+\n+        (\n+            syntax_contexts.encode(&mut self.opaque),\n+            syntax_bytes,\n+            expn_data_table.encode(&mut self.opaque),\n+            expn_bytes,\n+        )\n+    }\n+\n     fn encode_proc_macros(&mut self) -> Option<Lazy<[DefIndex]>> {\n         let is_proc_macro = self.tcx.sess.crate_types().contains(&CrateType::ProcMacro);\n         if is_proc_macro {\n@@ -1919,6 +2041,8 @@ fn encode_metadata_impl(tcx: TyCtxt<'_>) -> EncodedMetadata {\n         interpret_allocs_inverse: Default::default(),\n         required_source_files: Some(GrowableBitSet::with_capacity(source_map_files.len())),\n         is_proc_macro: tcx.sess.crate_types().contains(&CrateType::ProcMacro),\n+        serialized_ctxts: Some(Default::default()),\n+        latest_ctxts: Some(Default::default()),\n     };\n     drop(source_map_files);\n "}, {"sha": "55ef66f1939c4e1a18c79db4e4cf7d24f16d6929", "filename": "src/librustc_metadata/rmeta/mod.rs", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fmod.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -20,14 +20,15 @@ use rustc_session::config::SymbolManglingVersion;\n use rustc_session::CrateDisambiguator;\n use rustc_span::edition::Edition;\n use rustc_span::symbol::{Ident, Symbol};\n-use rustc_span::{self, Span};\n+use rustc_span::{self, ExpnData, ExpnId, Span};\n use rustc_target::spec::{PanicStrategy, TargetTriple};\n \n use std::marker::PhantomData;\n use std::num::NonZeroUsize;\n \n pub use decoder::{provide, provide_extern};\n crate use decoder::{CrateMetadata, CrateNumMap, MetadataBlob};\n+use rustc_span::hygiene::SyntaxContextData;\n \n mod decoder;\n mod encoder;\n@@ -168,6 +169,9 @@ macro_rules! Lazy {\n     ($T:ty) => {Lazy<$T, ()>};\n }\n \n+type SyntaxContextTable = Lazy<Table<u32, Lazy<SyntaxContextData>>>;\n+type ExpnDataTable = Lazy<Table<u32, Lazy<ExpnData>>>;\n+\n #[derive(RustcEncodable, RustcDecodable)]\n crate struct CrateRoot<'tcx> {\n     name: Symbol,\n@@ -202,6 +206,10 @@ crate struct CrateRoot<'tcx> {\n     proc_macro_data: Option<Lazy<[DefIndex]>>,\n \n     exported_symbols: Lazy!([(ExportedSymbol<'tcx>, SymbolExportLevel)]),\n+\n+    syntax_contexts: SyntaxContextTable,\n+    expn_data: ExpnDataTable,\n+\n     source_map: Lazy<[rustc_span::SourceFile]>,\n \n     compiler_builtins: bool,\n@@ -322,6 +330,7 @@ struct RenderedConst(String);\n #[derive(RustcEncodable, RustcDecodable)]\n struct ModData {\n     reexports: Lazy<[Export<hir::HirId>]>,\n+    expansion: ExpnId,\n }\n \n #[derive(RustcEncodable, RustcDecodable)]"}, {"sha": "e1d0a0dbf2ffa2c77d37bfb554300622a7d425c7", "filename": "src/librustc_metadata/rmeta/table.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Ftable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_metadata%2Frmeta%2Ftable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Ftable.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -155,7 +155,7 @@ impl<I: Idx, T> TableBuilder<I, T>\n where\n     Option<T>: FixedSizeEncoding,\n {\n-    pub(super) fn set(&mut self, i: I, value: T) {\n+    pub(crate) fn set(&mut self, i: I, value: T) {\n         // FIXME(eddyb) investigate more compact encodings for sparse tables.\n         // On the PR @michaelwoerister mentioned:\n         // > Space requirements could perhaps be optimized by using the HAMT `popcnt`\n@@ -170,7 +170,7 @@ where\n         Some(value).write_to_bytes_at(&mut self.bytes, i);\n     }\n \n-    pub(super) fn encode(&self, buf: &mut Encoder) -> Lazy<Table<I, T>> {\n+    pub(crate) fn encode(&self, buf: &mut Encoder) -> Lazy<Table<I, T>> {\n         let pos = buf.position();\n         buf.emit_raw_bytes(&self.bytes);\n         Lazy::from_position_and_meta(NonZeroUsize::new(pos as usize).unwrap(), self.bytes.len())"}, {"sha": "19a7d2ec2218dd2222c574f96a57959e083b58b5", "filename": "src/librustc_middle/ich/hcx.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Fich%2Fhcx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Fich%2Fhcx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fich%2Fhcx.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -14,6 +14,7 @@ use rustc_span::source_map::SourceMap;\n use rustc_span::symbol::Symbol;\n use rustc_span::{BytePos, CachingSourceMapView, SourceFile};\n \n+use rustc_span::def_id::{CrateNum, CRATE_DEF_INDEX};\n use smallvec::SmallVec;\n use std::cmp::Ord;\n \n@@ -229,6 +230,12 @@ impl<'a> rustc_span::HashStableContext for StableHashingContext<'a> {\n         self.hash_spans\n     }\n \n+    #[inline]\n+    fn hash_crate_num(&mut self, cnum: CrateNum, hasher: &mut StableHasher) {\n+        let hcx = self;\n+        hcx.def_path_hash(DefId { krate: cnum, index: CRATE_DEF_INDEX }).hash_stable(hcx, hasher);\n+    }\n+\n     #[inline]\n     fn hash_def_id(&mut self, def_id: DefId, hasher: &mut StableHasher) {\n         let hcx = self;"}, {"sha": "c2d177b69b6b95409d95d90593de14b12f9a70d4", "filename": "src/librustc_middle/ich/impls_hir.rs", "status": "modified", "additions": 0, "deletions": 7, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Fich%2Fimpls_hir.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Fich%2Fimpls_hir.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fich%2Fimpls_hir.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -147,13 +147,6 @@ impl<'a> ToStableHashKey<StableHashingContext<'a>> for LocalDefId {\n     }\n }\n \n-impl<'a> HashStable<StableHashingContext<'a>> for CrateNum {\n-    #[inline]\n-    fn hash_stable(&self, hcx: &mut StableHashingContext<'a>, hasher: &mut StableHasher) {\n-        hcx.def_path_hash(DefId { krate: *self, index: CRATE_DEF_INDEX }).hash_stable(hcx, hasher);\n-    }\n-}\n-\n impl<'a> ToStableHashKey<StableHashingContext<'a>> for CrateNum {\n     type KeyType = DefPathHash;\n "}, {"sha": "25e5379881e70ad56df532f2490a61f1a028e74e", "filename": "src/librustc_middle/lint.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Flint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Flint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Flint.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -346,6 +346,6 @@ pub fn in_external_macro(sess: &Session, span: Span) -> bool {\n             // Dummy span for the `def_site` means it's an external macro.\n             expn_data.def_site.is_dummy() || sess.source_map().is_imported(expn_data.def_site)\n         }\n-        ExpnKind::Macro(..) => true, // definitely a plugin\n+        ExpnKind::Macro { .. } => true, // definitely a plugin\n     }\n }"}, {"sha": "ed330321bdb71167a2c20f0ed7f9c923d9c8df7b", "filename": "src/librustc_middle/ty/query/on_disk_cache.rs", "status": "modified", "additions": 148, "deletions": 72, "changes": 220, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -17,22 +17,24 @@ use rustc_serialize::{\n     UseSpecializedDecodable, UseSpecializedEncodable,\n };\n use rustc_session::{CrateDisambiguator, Session};\n-use rustc_span::hygiene::{ExpnId, SyntaxContext};\n+use rustc_span::hygiene::{\n+    ExpnDataDecodeMode, ExpnDataEncodeMode, ExpnId, HygieneContext, SyntaxContext,\n+    SyntaxContextData,\n+};\n use rustc_span::source_map::{SourceMap, StableSourceFileId};\n use rustc_span::symbol::Ident;\n use rustc_span::CachingSourceMapView;\n-use rustc_span::{BytePos, SourceFile, Span, DUMMY_SP};\n+use rustc_span::{BytePos, ExpnData, SourceFile, Span, DUMMY_SP};\n use std::mem;\n \n const TAG_FILE_FOOTER: u128 = 0xC0FFEE_C0FFEE_C0FFEE_C0FFEE_C0FFEE;\n \n-const TAG_NO_EXPN_DATA: u8 = 0;\n-const TAG_EXPN_DATA_SHORTHAND: u8 = 1;\n-const TAG_EXPN_DATA_INLINE: u8 = 2;\n-\n const TAG_VALID_SPAN: u8 = 0;\n const TAG_INVALID_SPAN: u8 = 1;\n \n+const TAG_SYNTAX_CONTEXT: u8 = 0;\n+const TAG_EXPN_DATA: u8 = 1;\n+\n /// Provides an interface to incremental compilation data cached from the\n /// previous compilation session. This data will eventually include the results\n /// of a few selected queries (like `typeck` and `mir_optimized`) and\n@@ -53,7 +55,6 @@ pub struct OnDiskCache<'sess> {\n \n     // Caches that are populated lazily during decoding.\n     file_index_to_file: Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n-    synthetic_syntax_contexts: Lock<FxHashMap<AbsoluteBytePos, SyntaxContext>>,\n \n     // A map from dep-node to the position of the cached query result in\n     // `serialized_data`.\n@@ -64,9 +65,28 @@ pub struct OnDiskCache<'sess> {\n     prev_diagnostics_index: FxHashMap<SerializedDepNodeIndex, AbsoluteBytePos>,\n \n     alloc_decoding_state: AllocDecodingState,\n+\n+    // A map from syntax context ids to the position of their associated\n+    // `SyntaxContextData`. We use a `u32` instead of a `SyntaxContext`\n+    // to represent the fact that we are storing *encoded* ids. When we decode\n+    // a `SyntaxContext`, a new id will be allocated from the global `HygieneData`,\n+    // which will almost certainly be different than the serialized id.\n+    syntax_contexts: FxHashMap<u32, AbsoluteBytePos>,\n+    // A map from the `DefPathHash` of an `ExpnId` to the position\n+    // of their associated `ExpnData`. Ideally, we would store a `DefId`,\n+    // but we need to decode this before we've constructed a `TyCtxt` (which\n+    // makes it difficult to decode a `DefId`).\n+\n+    // Note that these `DefPathHashes` correspond to both local and foreign\n+    // `ExpnData` (e.g `ExpnData.krate` may not be `LOCAL_CRATE`). Alternatively,\n+    // we could look up the `ExpnData` from the metadata of foreign crates,\n+    // but it seemed easier to have `OnDiskCache` be independent of the `CStore`.\n+    expn_data: FxHashMap<u32, AbsoluteBytePos>,\n+    // Additional information used when decoding hygiene data.\n+    hygiene_context: HygieneContext,\n }\n \n-// This type is used only for (de-)serialization.\n+// This type is used only for serialization and deserialization.\n #[derive(RustcEncodable, RustcDecodable)]\n struct Footer {\n     file_index_to_stable_id: FxHashMap<SourceFileIndex, StableSourceFileId>,\n@@ -75,6 +95,10 @@ struct Footer {\n     diagnostics_index: EncodedQueryResultIndex,\n     // The location of all allocations.\n     interpret_alloc_index: Vec<u32>,\n+    // See `OnDiskCache.syntax_contexts`\n+    syntax_contexts: FxHashMap<u32, AbsoluteBytePos>,\n+    // See `OnDiskCache.expn_data`\n+    expn_data: FxHashMap<u32, AbsoluteBytePos>,\n }\n \n type EncodedQueryResultIndex = Vec<(SerializedDepNodeIndex, AbsoluteBytePos)>;\n@@ -116,6 +140,7 @@ impl<'sess> OnDiskCache<'sess> {\n \n             // Decode the file footer, which contains all the lookup tables, etc.\n             decoder.set_position(footer_pos);\n+\n             decode_tagged(&mut decoder, TAG_FILE_FOOTER)\n                 .expect(\"error while trying to decode footer position\")\n         };\n@@ -130,8 +155,10 @@ impl<'sess> OnDiskCache<'sess> {\n             current_diagnostics: Default::default(),\n             query_result_index: footer.query_result_index.into_iter().collect(),\n             prev_diagnostics_index: footer.diagnostics_index.into_iter().collect(),\n-            synthetic_syntax_contexts: Default::default(),\n             alloc_decoding_state: AllocDecodingState::new(footer.interpret_alloc_index),\n+            syntax_contexts: footer.syntax_contexts,\n+            expn_data: footer.expn_data,\n+            hygiene_context: HygieneContext::new(),\n         }\n     }\n \n@@ -146,8 +173,10 @@ impl<'sess> OnDiskCache<'sess> {\n             current_diagnostics: Default::default(),\n             query_result_index: Default::default(),\n             prev_diagnostics_index: Default::default(),\n-            synthetic_syntax_contexts: Default::default(),\n             alloc_decoding_state: AllocDecodingState::new(Vec::new()),\n+            syntax_contexts: FxHashMap::default(),\n+            expn_data: FxHashMap::default(),\n+            hygiene_context: HygieneContext::new(),\n         }\n     }\n \n@@ -180,7 +209,6 @@ impl<'sess> OnDiskCache<'sess> {\n                 encoder,\n                 type_shorthands: Default::default(),\n                 predicate_shorthands: Default::default(),\n-                expn_data_shorthands: Default::default(),\n                 interpret_allocs: Default::default(),\n                 interpret_allocs_inverse: Vec::new(),\n                 source_map: CachingSourceMapView::new(tcx.sess.source_map()),\n@@ -264,7 +292,32 @@ impl<'sess> OnDiskCache<'sess> {\n                 })\n                 .collect();\n \n-            // Encode the file footer.\n+            let mut syntax_contexts = FxHashMap::default();\n+            let mut expn_data = FxHashMap::default();\n+\n+            // Encode all hygiene data (`SyntaxContextData` and `ExpnData`) from the current\n+            // session.\n+            // FIXME: Investigate tracking which `SyntaxContext`s and `ExpnId`s we actually\n+            // need, to avoid serializing data that will never be used. This will require\n+            // tracking which `SyntaxContext`s/`ExpnId`s are actually (transitively) referenced\n+            // from any of the `Span`s that we serialize.\n+\n+            rustc_span::hygiene::for_all_data(|(index, _ctxt, data)| {\n+                let pos = AbsoluteBytePos::new(encoder.position());\n+                encoder.encode_tagged(TAG_SYNTAX_CONTEXT, data)?;\n+                syntax_contexts.insert(index, pos);\n+                Ok(())\n+            })?;\n+\n+            rustc_span::hygiene::for_all_expn_data(|index, data| {\n+                let pos = AbsoluteBytePos::new(encoder.position());\n+                encoder.encode_tagged(TAG_EXPN_DATA, data)?;\n+                //let hash = tcx.def_path_hash(data.def_id.unwrap());\n+                expn_data.insert(index, pos);\n+                Ok(())\n+            })?;\n+\n+            // `Encode the file footer.\n             let footer_pos = encoder.position() as u64;\n             encoder.encode_tagged(\n                 TAG_FILE_FOOTER,\n@@ -274,6 +327,8 @@ impl<'sess> OnDiskCache<'sess> {\n                     query_result_index,\n                     diagnostics_index,\n                     interpret_alloc_index,\n+                    syntax_contexts,\n+                    expn_data,\n                 },\n             )?;\n \n@@ -367,6 +422,21 @@ impl<'sess> OnDiskCache<'sess> {\n     {\n         let pos = index.get(&dep_node_index).cloned()?;\n \n+        self.with_decoder(tcx, pos, |decoder| match decode_tagged(decoder, dep_node_index) {\n+            Ok(v) => Some(v),\n+            Err(e) => bug!(\"could not decode cached {}: {}\", debug_tag, e),\n+        })\n+    }\n+\n+    fn with_decoder<'tcx, T, F: FnOnce(&mut CacheDecoder<'sess, 'tcx>) -> T>(\n+        &'sess self,\n+        tcx: TyCtxt<'tcx>,\n+        pos: AbsoluteBytePos,\n+        f: F,\n+    ) -> T\n+    where\n+        T: Decodable,\n+    {\n         let cnum_map =\n             self.cnum_map.get_or_init(|| Self::compute_cnum_map(tcx, &self.prev_cnums[..]));\n \n@@ -375,16 +445,14 @@ impl<'sess> OnDiskCache<'sess> {\n             opaque: opaque::Decoder::new(&self.serialized_data[..], pos.to_usize()),\n             source_map: self.source_map,\n             cnum_map,\n-            synthetic_syntax_contexts: &self.synthetic_syntax_contexts,\n             file_index_to_file: &self.file_index_to_file,\n             file_index_to_stable_id: &self.file_index_to_stable_id,\n             alloc_decoding_session: self.alloc_decoding_state.new_decoding_session(),\n+            syntax_contexts: &self.syntax_contexts,\n+            expn_data: &self.expn_data,\n+            hygiene_context: &self.hygiene_context,\n         };\n-\n-        match decode_tagged(&mut decoder, dep_node_index) {\n-            Ok(v) => Some(v),\n-            Err(e) => bug!(\"could not decode cached {}: {}\", debug_tag, e),\n-        }\n+        f(&mut decoder)\n     }\n \n     // This function builds mapping from previous-session-`CrateNum` to\n@@ -430,10 +498,12 @@ struct CacheDecoder<'a, 'tcx> {\n     opaque: opaque::Decoder<'a>,\n     source_map: &'a SourceMap,\n     cnum_map: &'a IndexVec<CrateNum, Option<CrateNum>>,\n-    synthetic_syntax_contexts: &'a Lock<FxHashMap<AbsoluteBytePos, SyntaxContext>>,\n     file_index_to_file: &'a Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n     file_index_to_stable_id: &'a FxHashMap<SourceFileIndex, StableSourceFileId>,\n     alloc_decoding_session: AllocDecodingSession<'a>,\n+    syntax_contexts: &'a FxHashMap<u32, AbsoluteBytePos>,\n+    expn_data: &'a FxHashMap<u32, AbsoluteBytePos>,\n+    hygiene_context: &'a HygieneContext,\n }\n \n impl<'a, 'tcx> CacheDecoder<'a, 'tcx> {\n@@ -577,6 +647,43 @@ impl<'a, 'tcx> TyDecoder<'tcx> for CacheDecoder<'a, 'tcx> {\n \n implement_ty_decoder!(CacheDecoder<'a, 'tcx>);\n \n+impl<'a, 'tcx> SpecializedDecoder<SyntaxContext> for CacheDecoder<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<SyntaxContext, Self::Error> {\n+        let syntax_contexts = self.syntax_contexts;\n+        rustc_span::hygiene::decode_syntax_context(self, self.hygiene_context, |this, id| {\n+            // This closure is invoked if we haven't already decoded the data for the `SyntaxContext` we are deserializing.\n+            // We look up the position of the associated `SyntaxData` and decode it.\n+            let pos = syntax_contexts.get(&id).unwrap();\n+            this.with_position(pos.to_usize(), |decoder| {\n+                let data: SyntaxContextData = decode_tagged(decoder, TAG_SYNTAX_CONTEXT)?;\n+                Ok(data)\n+            })\n+        })\n+    }\n+}\n+\n+impl<'a, 'tcx> SpecializedDecoder<ExpnId> for CacheDecoder<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<ExpnId, Self::Error> {\n+        let expn_data = self.expn_data;\n+        rustc_span::hygiene::decode_expn_id(\n+            self,\n+            ExpnDataDecodeMode::incr_comp(self.hygiene_context),\n+            |this, index| {\n+                // This closure is invoked if we haven't already decoded the data for the `ExpnId` we are deserializing.\n+                // We look up the position of the associated `ExpnData` and decode it.\n+                let pos = expn_data\n+                    .get(&index)\n+                    .unwrap_or_else(|| panic!(\"Bad index {:?} (map {:?})\", index, expn_data));\n+\n+                this.with_position(pos.to_usize(), |decoder| {\n+                    let data: ExpnData = decode_tagged(decoder, TAG_EXPN_DATA)?;\n+                    Ok(data)\n+                })\n+            },\n+        )\n+    }\n+}\n+\n impl<'a, 'tcx> SpecializedDecoder<interpret::AllocId> for CacheDecoder<'a, 'tcx> {\n     fn specialized_decode(&mut self) -> Result<interpret::AllocId, Self::Error> {\n         let alloc_decoding_session = self.alloc_decoding_session;\n@@ -598,48 +705,13 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for CacheDecoder<'a, 'tcx> {\n         let line_lo = usize::decode(self)?;\n         let col_lo = BytePos::decode(self)?;\n         let len = BytePos::decode(self)?;\n+        let ctxt = SyntaxContext::decode(self)?;\n \n         let file_lo = self.file_index_to_file(file_lo_index);\n         let lo = file_lo.lines[line_lo - 1] + col_lo;\n         let hi = lo + len;\n \n-        let expn_data_tag = u8::decode(self)?;\n-\n-        // FIXME(mw): This method does not restore `ExpnData::parent` or\n-        // `SyntaxContextData::prev_ctxt` or `SyntaxContextData::opaque`. These things\n-        // don't seem to be used after HIR lowering, so everything should be fine\n-        // until we want incremental compilation to serialize Spans that we need\n-        // full hygiene information for.\n-        let location = || Span::with_root_ctxt(lo, hi);\n-        let recover_from_expn_data = |this: &Self, expn_data, transparency, pos| {\n-            let span = location().fresh_expansion_with_transparency(expn_data, transparency);\n-            this.synthetic_syntax_contexts.borrow_mut().insert(pos, span.ctxt());\n-            span\n-        };\n-        Ok(match expn_data_tag {\n-            TAG_NO_EXPN_DATA => location(),\n-            TAG_EXPN_DATA_INLINE => {\n-                let (expn_data, transparency) = Decodable::decode(self)?;\n-                recover_from_expn_data(\n-                    self,\n-                    expn_data,\n-                    transparency,\n-                    AbsoluteBytePos::new(self.opaque.position()),\n-                )\n-            }\n-            TAG_EXPN_DATA_SHORTHAND => {\n-                let pos = AbsoluteBytePos::decode(self)?;\n-                let cached_ctxt = self.synthetic_syntax_contexts.borrow().get(&pos).cloned();\n-                if let Some(ctxt) = cached_ctxt {\n-                    Span::new(lo, hi, ctxt)\n-                } else {\n-                    let (expn_data, transparency) =\n-                        self.with_position(pos.to_usize(), |this| Decodable::decode(this))?;\n-                    recover_from_expn_data(self, expn_data, transparency, pos)\n-                }\n-            }\n-            _ => unreachable!(),\n-        })\n+        Ok(Span::new(lo, hi, ctxt))\n     }\n }\n \n@@ -695,7 +767,6 @@ struct CacheEncoder<'a, 'tcx, E: ty_codec::TyEncoder> {\n     encoder: &'a mut E,\n     type_shorthands: FxHashMap<Ty<'tcx>, usize>,\n     predicate_shorthands: FxHashMap<ty::Predicate<'tcx>, usize>,\n-    expn_data_shorthands: FxHashMap<ExpnId, AbsoluteBytePos>,\n     interpret_allocs: FxHashMap<interpret::AllocId, usize>,\n     interpret_allocs_inverse: Vec<interpret::AllocId>,\n     source_map: CachingSourceMapView<'tcx>,\n@@ -750,6 +821,24 @@ where\n     }\n }\n \n+impl<'a, 'tcx, E> SpecializedEncoder<SyntaxContext> for CacheEncoder<'a, 'tcx, E>\n+where\n+    E: 'a + TyEncoder,\n+{\n+    fn specialized_encode(&mut self, ctxt: &SyntaxContext) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, self)\n+    }\n+}\n+\n+impl<'a, 'tcx, E> SpecializedEncoder<ExpnId> for CacheEncoder<'a, 'tcx, E>\n+where\n+    E: 'a + TyEncoder,\n+{\n+    fn specialized_encode(&mut self, expn: &ExpnId) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_expn_id(*expn, ExpnDataEncodeMode::IncrComp, self)\n+    }\n+}\n+\n impl<'a, 'tcx, E> SpecializedEncoder<Span> for CacheEncoder<'a, 'tcx, E>\n where\n     E: 'a + TyEncoder,\n@@ -779,21 +868,8 @@ where\n         line_lo.encode(self)?;\n         col_lo.encode(self)?;\n         len.encode(self)?;\n-\n-        if span_data.ctxt == SyntaxContext::root() {\n-            TAG_NO_EXPN_DATA.encode(self)\n-        } else {\n-            let (expn_id, transparency, expn_data) = span_data.ctxt.outer_mark_with_data();\n-            if let Some(pos) = self.expn_data_shorthands.get(&expn_id).cloned() {\n-                TAG_EXPN_DATA_SHORTHAND.encode(self)?;\n-                pos.encode(self)\n-            } else {\n-                TAG_EXPN_DATA_INLINE.encode(self)?;\n-                let pos = AbsoluteBytePos::new(self.position());\n-                self.expn_data_shorthands.insert(expn_id, pos);\n-                (expn_data, transparency).encode(self)\n-            }\n-        }\n+        span_data.ctxt.encode(self)?;\n+        Ok(())\n     }\n }\n "}, {"sha": "737fd13812058bc9ab3aa1373a857a686260947e", "filename": "src/librustc_resolve/build_reduced_graph.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -35,7 +35,7 @@ use rustc_middle::ty;\n use rustc_span::hygiene::{ExpnId, MacroKind};\n use rustc_span::source_map::{respan, Spanned};\n use rustc_span::symbol::{kw, sym, Ident, Symbol};\n-use rustc_span::{Span, DUMMY_SP};\n+use rustc_span::Span;\n \n use log::debug;\n use std::cell::Cell;\n@@ -130,8 +130,8 @@ impl<'a> Resolver<'a> {\n             parent,\n             kind,\n             def_id,\n-            ExpnId::root(),\n-            DUMMY_SP,\n+            self.cstore().module_expansion_untracked(def_id, &self.session),\n+            self.cstore().get_span_untracked(def_id, &self.session),\n         ));\n         self.extern_module_map.insert(def_id, module);\n         module\n@@ -888,7 +888,7 @@ impl<'a, 'b> BuildReducedGraphVisitor<'a, 'b> {\n     fn build_reduced_graph_for_external_crate_res(&mut self, child: Export<NodeId>) {\n         let parent = self.parent_scope.module;\n         let Export { ident, res, vis, span } = child;\n-        let expansion = ExpnId::root(); // FIXME(jseyfried) intercrate hygiene\n+        let expansion = self.parent_scope.expansion;\n         // Record primary definitions.\n         match res {\n             Res::Def(kind @ (DefKind::Mod | DefKind::Enum | DefKind::Trait), def_id) => {"}, {"sha": "dfc50a30c121e4965c5f9b1ff8da7bb5102afb42", "filename": "src/librustc_resolve/lib.rs", "status": "modified", "additions": 33, "deletions": 3, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_resolve%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_resolve%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Flib.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -434,7 +434,7 @@ impl ModuleKind {\n ///\n /// Multiple bindings in the same module can have the same key (in a valid\n /// program) if all but one of them come from glob imports.\n-#[derive(Copy, Clone, PartialEq, Eq, Hash)]\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n struct BindingKey {\n     /// The identifier for the binding, aways the `normalize_to_macros_2_0` version of the\n     /// identifier.\n@@ -1988,6 +1988,7 @@ impl<'a> Resolver<'a> {\n     }\n \n     fn resolve_crate_root(&mut self, ident: Ident) -> Module<'a> {\n+        debug!(\"resolve_crate_root({:?})\", ident);\n         let mut ctxt = ident.span.ctxt();\n         let mark = if ident.name == kw::DollarCrate {\n             // When resolving `$crate` from a `macro_rules!` invoked in a `macro`,\n@@ -1997,6 +1998,10 @@ impl<'a> Resolver<'a> {\n             // definitions actually produced by `macro` and `macro` definitions produced by\n             // `macro_rules!`, but at least such configurations are not stable yet.\n             ctxt = ctxt.normalize_to_macro_rules();\n+            debug!(\n+                \"resolve_crate_root: marks={:?}\",\n+                ctxt.marks().into_iter().map(|(i, t)| (i.expn_data(), t)).collect::<Vec<_>>()\n+            );\n             let mut iter = ctxt.marks().into_iter().rev().peekable();\n             let mut result = None;\n             // Find the last opaque mark from the end if it exists.\n@@ -2008,6 +2013,11 @@ impl<'a> Resolver<'a> {\n                     break;\n                 }\n             }\n+            debug!(\n+                \"resolve_crate_root: found opaque mark {:?} {:?}\",\n+                result,\n+                result.map(|r| r.expn_data())\n+            );\n             // Then find the last semi-transparent mark from the end if it exists.\n             for (mark, transparency) in iter {\n                 if transparency == Transparency::SemiTransparent {\n@@ -2016,16 +2026,36 @@ impl<'a> Resolver<'a> {\n                     break;\n                 }\n             }\n+            debug!(\n+                \"resolve_crate_root: found semi-transparent mark {:?} {:?}\",\n+                result,\n+                result.map(|r| r.expn_data())\n+            );\n             result\n         } else {\n+            debug!(\"resolve_crate_root: not DollarCrate\");\n             ctxt = ctxt.normalize_to_macros_2_0();\n             ctxt.adjust(ExpnId::root())\n         };\n         let module = match mark {\n             Some(def) => self.macro_def_scope(def),\n-            None => return self.graph_root,\n+            None => {\n+                debug!(\n+                    \"resolve_crate_root({:?}): found no mark (ident.span = {:?})\",\n+                    ident, ident.span\n+                );\n+                return self.graph_root;\n+            }\n         };\n-        self.get_module(DefId { index: CRATE_DEF_INDEX, ..module.normal_ancestor_id })\n+        let module = self.get_module(DefId { index: CRATE_DEF_INDEX, ..module.normal_ancestor_id });\n+        debug!(\n+            \"resolve_crate_root({:?}): got module {:?} ({:?}) (ident.span = {:?})\",\n+            ident,\n+            module,\n+            module.kind.name(),\n+            ident.span\n+        );\n+        module\n     }\n \n     fn resolve_self(&mut self, ctxt: &mut SyntaxContext, module: Module<'a>) -> Module<'a> {"}, {"sha": "0751dbb027ae2045cf522519dbd0474a0559456b", "filename": "src/librustc_save_analysis/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_save_analysis%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_save_analysis%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Flib.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -789,7 +789,7 @@ impl<'tcx> SaveContext<'tcx> {\n         let callee = span.source_callee()?;\n \n         let mac_name = match callee.kind {\n-            ExpnKind::Macro(mac_kind, name) => match mac_kind {\n+            ExpnKind::Macro(kind, name) => match kind {\n                 MacroKind::Bang => name,\n \n                 // Ignore attribute macros, their spans are usually mangled"}, {"sha": "a874f81868f153ab6f373101b30136841687b10e", "filename": "src/librustc_span/def_id.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_span%2Fdef_id.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_span%2Fdef_id.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Fdef_id.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -247,3 +247,9 @@ impl<CTX: HashStableContext> HashStable<CTX> for DefId {\n         hcx.hash_def_id(*self, hasher)\n     }\n }\n+\n+impl<CTX: HashStableContext> HashStable<CTX> for CrateNum {\n+    fn hash_stable(&self, hcx: &mut CTX, hasher: &mut StableHasher) {\n+        hcx.hash_crate_num(*self, hasher)\n+    }\n+}"}, {"sha": "c5ba42c57282314289eab42f9d35bace9ad6193d", "filename": "src/librustc_span/hygiene.rs", "status": "modified", "additions": 276, "deletions": 24, "changes": 300, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_span%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_span%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Fhygiene.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -24,24 +24,27 @@\n // because getting it wrong can lead to nested `HygieneData::with` calls that\n // trigger runtime aborts. (Fortunately these are obvious and easy to fix.)\n \n-use crate::def_id::{DefId, CRATE_DEF_INDEX};\n use crate::edition::Edition;\n use crate::symbol::{kw, sym, Symbol};\n use crate::SESSION_GLOBALS;\n use crate::{Span, DUMMY_SP};\n \n+use crate::def_id::{CrateNum, DefId, CRATE_DEF_INDEX, LOCAL_CRATE};\n+use log::*;\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::Lrc;\n+use rustc_data_structures::sync::{Lock, Lrc};\n use rustc_macros::HashStable_Generic;\n-use rustc_serialize::{Decodable, Decoder, Encodable, Encoder};\n+use rustc_serialize::{\n+    Decodable, Decoder, Encodable, Encoder, UseSpecializedDecodable, UseSpecializedEncodable,\n+};\n use std::fmt;\n \n /// A `SyntaxContext` represents a chain of pairs `(ExpnId, Transparency)` named \"marks\".\n #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]\n pub struct SyntaxContext(u32);\n \n-#[derive(Debug)]\n-struct SyntaxContextData {\n+#[derive(Debug, RustcEncodable, RustcDecodable, Clone)]\n+pub struct SyntaxContextData {\n     outer_expn: ExpnId,\n     outer_transparency: Transparency,\n     parent: SyntaxContext,\n@@ -77,6 +80,8 @@ pub enum Transparency {\n     Opaque,\n }\n \n+pub(crate) const NUM_TRANSPARENCIES: usize = 3;\n+\n impl ExpnId {\n     pub fn fresh(expn_data: Option<ExpnData>) -> Self {\n         HygieneData::with(|data| data.fresh_expn(expn_data))\n@@ -104,10 +109,11 @@ impl ExpnId {\n     }\n \n     #[inline]\n-    pub fn set_expn_data(self, expn_data: ExpnData) {\n+    pub fn set_expn_data(self, mut expn_data: ExpnData) {\n         HygieneData::with(|data| {\n             let old_expn_data = &mut data.expn_data[self.0 as usize];\n             assert!(old_expn_data.is_none(), \"expansion data is reset for an expansion ID\");\n+            expn_data.orig_id.replace(self.as_u32()).expect_none(\"orig_id should be None\");\n             *old_expn_data = Some(expn_data);\n         })\n     }\n@@ -143,7 +149,7 @@ impl ExpnId {\n }\n \n #[derive(Debug)]\n-crate struct HygieneData {\n+pub struct HygieneData {\n     /// Each expansion should have an associated expansion data, but sometimes there's a delay\n     /// between creation of an expansion ID and obtaining its data (e.g. macros are collected\n     /// first and then resolved later), so we use an `Option` here.\n@@ -154,13 +160,16 @@ crate struct HygieneData {\n \n impl HygieneData {\n     crate fn new(edition: Edition) -> Self {\n+        let mut root_data = ExpnData::default(\n+            ExpnKind::Root,\n+            DUMMY_SP,\n+            edition,\n+            Some(DefId::local(CRATE_DEF_INDEX)),\n+        );\n+        root_data.orig_id = Some(0);\n+\n         HygieneData {\n-            expn_data: vec![Some(ExpnData::default(\n-                ExpnKind::Root,\n-                DUMMY_SP,\n-                edition,\n-                Some(DefId::local(CRATE_DEF_INDEX)),\n-            ))],\n+            expn_data: vec![Some(root_data)],\n             syntax_context_data: vec![SyntaxContextData {\n                 outer_expn: ExpnId::root(),\n                 outer_transparency: Transparency::Opaque,\n@@ -173,13 +182,17 @@ impl HygieneData {\n         }\n     }\n \n-    fn with<T, F: FnOnce(&mut HygieneData) -> T>(f: F) -> T {\n+    pub fn with<T, F: FnOnce(&mut HygieneData) -> T>(f: F) -> T {\n         SESSION_GLOBALS.with(|session_globals| f(&mut *session_globals.hygiene_data.borrow_mut()))\n     }\n \n-    fn fresh_expn(&mut self, expn_data: Option<ExpnData>) -> ExpnId {\n+    fn fresh_expn(&mut self, mut expn_data: Option<ExpnData>) -> ExpnId {\n+        let raw_id = self.expn_data.len() as u32;\n+        if let Some(data) = expn_data.as_mut() {\n+            data.orig_id.replace(raw_id).expect_none(\"orig_id should be None\");\n+        }\n         self.expn_data.push(expn_data);\n-        ExpnId(self.expn_data.len() as u32 - 1)\n+        ExpnId(raw_id)\n     }\n \n     fn expn_data(&self, expn_id: ExpnId) -> &ExpnData {\n@@ -226,6 +239,7 @@ impl HygieneData {\n     fn marks(&self, mut ctxt: SyntaxContext) -> Vec<(ExpnId, Transparency)> {\n         let mut marks = Vec::new();\n         while ctxt != SyntaxContext::root() {\n+            debug!(\"marks: getting parent of {:?}\", ctxt);\n             marks.push(self.outer_mark(ctxt));\n             ctxt = self.parent_ctxt(ctxt);\n         }\n@@ -234,8 +248,14 @@ impl HygieneData {\n     }\n \n     fn walk_chain(&self, mut span: Span, to: SyntaxContext) -> Span {\n+        debug!(\"walk_chain({:?}, {:?})\", span, to);\n+        debug!(\"walk_chain: span ctxt = {:?}\", span.ctxt());\n         while span.from_expansion() && span.ctxt() != to {\n-            span = self.expn_data(self.outer_expn(span.ctxt())).call_site;\n+            let outer_expn = self.outer_expn(span.ctxt());\n+            debug!(\"walk_chain({:?}): outer_expn={:?}\", span, outer_expn);\n+            let expn_data = self.expn_data(outer_expn);\n+            debug!(\"walk_chain({:?}): expn_data={:?}\", span, expn_data);\n+            span = expn_data.call_site;\n         }\n         span\n     }\n@@ -682,6 +702,16 @@ pub struct ExpnData {\n     /// The `DefId` of the macro being invoked,\n     /// if this `ExpnData` corresponds to a macro invocation\n     pub macro_def_id: Option<DefId>,\n+    /// The crate that originally created this `ExpnData. During\n+    /// metadata serialization, we only encode `ExpnData`s that were\n+    /// created locally - when our serialized metadata is decoded,\n+    /// foreign `ExpnId`s will have their `ExpnData` looked up\n+    /// from the crate specified by `Crate\n+    pub krate: CrateNum,\n+    /// The raw that this `ExpnData` had in its original crate.\n+    /// An `ExpnData` can be created before being assigned an `ExpnId`,\n+    /// so this might be `None` until `set_expn_data` is called\n+    pub orig_id: Option<u32>,\n }\n \n impl ExpnData {\n@@ -702,6 +732,8 @@ impl ExpnData {\n             local_inner_macros: false,\n             edition,\n             macro_def_id,\n+            krate: LOCAL_CRATE,\n+            orig_id: None,\n         }\n     }\n \n@@ -789,7 +821,7 @@ impl MacroKind {\n }\n \n /// The kind of AST transform.\n-#[derive(Clone, Copy, PartialEq, Debug, RustcEncodable, RustcDecodable, HashStable_Generic)]\n+#[derive(Clone, Copy, Debug, PartialEq, RustcEncodable, RustcDecodable, HashStable_Generic)]\n pub enum AstPass {\n     StdImports,\n     TestHarness,\n@@ -847,14 +879,234 @@ impl DesugaringKind {\n     }\n }\n \n-impl Encodable for ExpnId {\n-    fn encode<E: Encoder>(&self, _: &mut E) -> Result<(), E::Error> {\n-        Ok(()) // FIXME(jseyfried) intercrate hygiene\n+impl UseSpecializedEncodable for ExpnId {}\n+impl UseSpecializedDecodable for ExpnId {}\n+\n+/// Additional information used to assist in decoding hygiene data\n+pub struct HygieneContext {\n+    // Maps serialized `SyntaxContext` ids to a `SyntaxContext` in the current\n+    // global `HygieneData`. When we deserialize a `SyntaxContext`, we need to create\n+    // a new id in the global `HygieneData`. This map tracks the ID we end up picking,\n+    // so that multiple occurences of the same serialized id are decoded to the same\n+    // `SyntaxContext`\n+    remapped_ctxts: Lock<Vec<Option<SyntaxContext>>>,\n+    // The same as `remapepd_ctxts`, but for `ExpnId`s\n+    remapped_expns: Lock<Vec<Option<ExpnId>>>,\n+}\n+\n+impl HygieneContext {\n+    pub fn new() -> HygieneContext {\n+        HygieneContext {\n+            remapped_ctxts: Lock::new(Vec::new()),\n+            remapped_expns: Lock::new(Vec::new()),\n+        }\n     }\n }\n \n-impl Decodable for ExpnId {\n-    fn decode<D: Decoder>(_: &mut D) -> Result<Self, D::Error> {\n-        Ok(ExpnId::root()) // FIXME(jseyfried) intercrate hygiene\n+pub fn decode_expn_id<\n+    'a,\n+    D: Decoder,\n+    F: FnOnce(&mut D, u32) -> Result<ExpnData, D::Error>,\n+    G: FnOnce(CrateNum) -> &'a HygieneContext,\n+>(\n+    d: &mut D,\n+    mode: ExpnDataDecodeMode<'a, G>,\n+    decode_data: F,\n+) -> Result<ExpnId, D::Error> {\n+    let index = u32::decode(d)?;\n+    let context = match mode {\n+        ExpnDataDecodeMode::IncrComp(context) => context,\n+        ExpnDataDecodeMode::Metadata(get_context) => {\n+            let krate = CrateNum::decode(d)?;\n+            get_context(krate)\n+        }\n+    };\n+\n+    // Do this after decoding, so that we decode a `CrateNum`\n+    // if necessary\n+    if index == ExpnId::root().as_u32() {\n+        debug!(\"decode_expn_id: deserialized root\");\n+        return Ok(ExpnId::root());\n+    }\n+\n+    let outer_expns = &context.remapped_expns;\n+\n+    // Ensure that the lock() temporary is dropped early\n+    {\n+        if let Some(expn_id) = outer_expns.lock().get(index as usize).copied().flatten() {\n+            return Ok(expn_id);\n+        }\n     }\n+\n+    // Don't decode the data inside `HygieneData::with`, since we need to recursively decode\n+    // other ExpnIds\n+    let expn_data = decode_data(d, index)?;\n+\n+    let expn_id = HygieneData::with(|hygiene_data| {\n+        let expn_id = ExpnId(hygiene_data.expn_data.len() as u32);\n+        hygiene_data.expn_data.push(Some(expn_data));\n+\n+        // Drop lock() temporary early\n+        {\n+            let mut expns = outer_expns.lock();\n+            let new_len = index as usize + 1;\n+            if expns.len() < new_len {\n+                expns.resize(new_len, None);\n+            }\n+            expns[index as usize] = Some(expn_id);\n+        }\n+        expn_id\n+    });\n+    return Ok(expn_id);\n }\n+\n+// Decodes `SyntaxContext`, using the provided `HygieneContext`\n+// to track which `SyntaxContext`s we have already decoded.\n+// The provided closure will be invoked to deserialize a `SyntaxContextData`\n+// if we haven't already seen the id of the `SyntaxContext` we are deserializing.\n+pub fn decode_syntax_context<\n+    D: Decoder,\n+    F: FnOnce(&mut D, u32) -> Result<SyntaxContextData, D::Error>,\n+>(\n+    d: &mut D,\n+    context: &HygieneContext,\n+    decode_data: F,\n+) -> Result<SyntaxContext, D::Error> {\n+    let raw_id: u32 = Decodable::decode(d)?;\n+    if raw_id == 0 {\n+        debug!(\"decode_syntax_context: deserialized root\");\n+        // The root is special\n+        return Ok(SyntaxContext::root());\n+    }\n+\n+    let outer_ctxts = &context.remapped_ctxts;\n+\n+    // Ensure that the lock() temporary is dropped early\n+    {\n+        if let Some(ctxt) = outer_ctxts.lock().get(raw_id as usize).copied().flatten() {\n+            return Ok(ctxt);\n+        }\n+    }\n+\n+    // Allocate and store SyntaxContext id *before* calling the decoder function,\n+    // as the SyntaxContextData may reference itself.\n+    let new_ctxt = HygieneData::with(|hygiene_data| {\n+        let new_ctxt = SyntaxContext(hygiene_data.syntax_context_data.len() as u32);\n+        // Push a dummy SyntaxContextData to ensure that nobody else can get the\n+        // same ID as us. This will be overwritten after call `decode_Data`\n+        hygiene_data.syntax_context_data.push(SyntaxContextData {\n+            outer_expn: ExpnId::root(),\n+            outer_transparency: Transparency::Transparent,\n+            parent: SyntaxContext::root(),\n+            opaque: SyntaxContext::root(),\n+            opaque_and_semitransparent: SyntaxContext::root(),\n+            dollar_crate_name: kw::Invalid,\n+        });\n+        // Ensure that the lock() temporary is dropped early\n+        {\n+            let mut ctxts = outer_ctxts.lock();\n+            let new_len = raw_id as usize + 1;\n+            if ctxts.len() < new_len {\n+                ctxts.resize(new_len, None);\n+            }\n+            ctxts[raw_id as usize] = Some(new_ctxt);\n+        }\n+        new_ctxt\n+    });\n+\n+    // Don't try to decode data while holding the lock, since we need to\n+    // be able to recursively decode a SyntaxContext\n+    let mut ctxt_data = decode_data(d, raw_id)?;\n+    // Reset `dollar_crate_name` so that it will be updated by `update_dollar_crate_names`\n+    // We don't care what the encoding crate set this to - we want to resolve it\n+    // from the perspective of the current compilation session\n+    ctxt_data.dollar_crate_name = kw::DollarCrate;\n+\n+    // Overwrite the dummy data with our decoded SyntaxContextData\n+    HygieneData::with(|hygiene_data| {\n+        let dummy = std::mem::replace(\n+            &mut hygiene_data.syntax_context_data[new_ctxt.as_u32() as usize],\n+            ctxt_data,\n+        );\n+        // Make sure nothing weird happening while `decode_data` was running\n+        assert_eq!(dummy.dollar_crate_name, kw::Invalid);\n+    });\n+\n+    return Ok(new_ctxt);\n+}\n+\n+pub fn num_syntax_ctxts() -> usize {\n+    HygieneData::with(|data| data.syntax_context_data.len())\n+}\n+\n+pub fn for_all_data_in<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n+    ctxts: impl Iterator<Item = SyntaxContext>,\n+    mut f: F,\n+) -> Result<(), E> {\n+    let all_data: Vec<_> = HygieneData::with(|data| {\n+        ctxts.map(|ctxt| (ctxt, data.syntax_context_data[ctxt.0 as usize].clone())).collect()\n+    });\n+    for (ctxt, data) in all_data.into_iter() {\n+        f((ctxt.0, ctxt, &data))?;\n+    }\n+    Ok(())\n+}\n+\n+pub fn for_all_data<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n+    mut f: F,\n+) -> Result<(), E> {\n+    let all_data = HygieneData::with(|data| data.syntax_context_data.clone());\n+    for (i, data) in all_data.into_iter().enumerate() {\n+        f((i as u32, SyntaxContext(i as u32), &data))?;\n+    }\n+    Ok(())\n+}\n+\n+pub fn for_all_expn_data<E, F: FnMut(u32, &ExpnData) -> Result<(), E>>(mut f: F) -> Result<(), E> {\n+    let all_data = HygieneData::with(|data| data.expn_data.clone());\n+    for (i, data) in all_data.into_iter().enumerate() {\n+        f(i as u32, &data.unwrap_or_else(|| panic!(\"Missing ExpnData!\")))?;\n+    }\n+    Ok(())\n+}\n+\n+pub fn raw_encode_syntax_context<E: Encoder>(\n+    ctxt: SyntaxContext,\n+    e: &mut E,\n+) -> Result<(), E::Error> {\n+    ctxt.0.encode(e)\n+}\n+\n+pub fn raw_encode_expn_id<E: Encoder>(\n+    expn: ExpnId,\n+    mode: ExpnDataEncodeMode,\n+    e: &mut E,\n+) -> Result<(), E::Error> {\n+    match mode {\n+        ExpnDataEncodeMode::IncrComp => expn.0.encode(e),\n+        ExpnDataEncodeMode::Metadata => {\n+            let data = expn.expn_data();\n+            data.orig_id.expect(\"Missing orig_id\").encode(e)?;\n+            data.krate.encode(e)\n+        }\n+    }\n+}\n+\n+pub enum ExpnDataEncodeMode {\n+    IncrComp,\n+    Metadata,\n+}\n+\n+pub enum ExpnDataDecodeMode<'a, F: FnOnce(CrateNum) -> &'a HygieneContext> {\n+    IncrComp(&'a HygieneContext),\n+    Metadata(F),\n+}\n+\n+impl<'a> ExpnDataDecodeMode<'a, Box<dyn FnOnce(CrateNum) -> &'a HygieneContext>> {\n+    pub fn incr_comp(ctxt: &'a HygieneContext) -> Self {\n+        ExpnDataDecodeMode::IncrComp(ctxt)\n+    }\n+}\n+\n+impl UseSpecializedEncodable for SyntaxContext {}\n+impl UseSpecializedDecodable for SyntaxContext {}"}, {"sha": "f49e7f15a5c029d258f99d85b3d5c3b49fecfe34", "filename": "src/librustc_span/lib.rs", "status": "modified", "additions": 47, "deletions": 14, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_span%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Flibrustc_span%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Flib.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -12,6 +12,7 @@\n #![feature(nll)]\n #![feature(optin_builtin_traits)]\n #![feature(min_specialization)]\n+#![feature(option_expect_none)]\n \n // FIXME(#56935): Work around ICEs during cross-compilation.\n #[allow(unused)]\n@@ -30,8 +31,8 @@ pub mod edition;\n use edition::Edition;\n pub mod hygiene;\n pub use hygiene::SyntaxContext;\n-use hygiene::Transparency;\n pub use hygiene::{DesugaringKind, ExpnData, ExpnId, ExpnKind, ForLoopLoc, MacroKind};\n+use hygiene::{Transparency, NUM_TRANSPARENCIES};\n pub mod def_id;\n use def_id::{CrateNum, DefId, LOCAL_CRATE};\n mod span_encoding;\n@@ -44,7 +45,6 @@ mod analyze_source_file;\n pub mod fatal_error;\n \n use rustc_data_structures::fingerprint::Fingerprint;\n-use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::sync::{Lock, Lrc};\n \n@@ -86,6 +86,9 @@ impl SessionGlobals {\n     }\n }\n \n+// If this ever becomes non thread-local, `decode_syntax_context`\n+// and `decode_expn_id` will need to be updated to handle concurrent\n+// deserialization.\n scoped_tls::scoped_thread_local!(pub static SESSION_GLOBALS: SessionGlobals);\n \n // FIXME: Perhaps this should not implement Rustc{Decodable, Encodable}\n@@ -1733,8 +1736,9 @@ fn lookup_line(lines: &[BytePos], pos: BytePos) -> isize {\n /// This is a hack to allow using the `HashStable_Generic` derive macro\n /// instead of implementing everything in librustc_middle.\n pub trait HashStableContext {\n-    fn hash_spans(&self) -> bool;\n     fn hash_def_id(&mut self, _: DefId, hasher: &mut StableHasher);\n+    fn hash_crate_num(&mut self, _: CrateNum, hasher: &mut StableHasher);\n+    fn hash_spans(&self) -> bool;\n     fn byte_pos_to_line_and_col(\n         &mut self,\n         byte: BytePos,\n@@ -1757,15 +1761,14 @@ where\n     fn hash_stable(&self, ctx: &mut CTX, hasher: &mut StableHasher) {\n         const TAG_VALID_SPAN: u8 = 0;\n         const TAG_INVALID_SPAN: u8 = 1;\n-        const TAG_EXPANSION: u8 = 0;\n-        const TAG_NO_EXPANSION: u8 = 1;\n \n         if !ctx.hash_spans() {\n             return;\n         }\n \n         if *self == DUMMY_SP {\n-            return std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            return;\n         }\n \n         // If this is not an empty or invalid span, we want to hash the last\n@@ -1775,12 +1778,16 @@ where\n         let (file_lo, line_lo, col_lo) = match ctx.byte_pos_to_line_and_col(span.lo) {\n             Some(pos) => pos,\n             None => {\n-                return std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+                std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+                span.ctxt.hash_stable(ctx, hasher);\n+                return;\n             }\n         };\n \n         if !file_lo.contains(span.hi) {\n-            return std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            span.ctxt.hash_stable(ctx, hasher);\n+            return;\n         }\n \n         std::hash::Hash::hash(&TAG_VALID_SPAN, hasher);\n@@ -1793,8 +1800,16 @@ where\n         let len = ((span.hi - span.lo).0 as u64) << 32;\n         let line_col_len = col | line | len;\n         std::hash::Hash::hash(&line_col_len, hasher);\n+        span.ctxt.hash_stable(ctx, hasher);\n+    }\n+}\n \n-        if span.ctxt == SyntaxContext::root() {\n+impl<CTX: HashStableContext> HashStable<CTX> for SyntaxContext {\n+    fn hash_stable(&self, ctx: &mut CTX, hasher: &mut StableHasher) {\n+        const TAG_EXPANSION: u8 = 0;\n+        const TAG_NO_EXPANSION: u8 = 1;\n+\n+        if *self == SyntaxContext::root() {\n             TAG_NO_EXPANSION.hash_stable(ctx, hasher);\n         } else {\n             TAG_EXPANSION.hash_stable(ctx, hasher);\n@@ -1803,21 +1818,39 @@ where\n             // times, we cache a stable hash of it and hash that instead of\n             // recursing every time.\n             thread_local! {\n-                static CACHE: RefCell<FxHashMap<hygiene::ExpnId, u64>> = Default::default();\n+                static CACHE: RefCell<Vec<Option<[Option<u64>; NUM_TRANSPARENCIES]>>> = Default::default();\n             }\n \n             let sub_hash: u64 = CACHE.with(|cache| {\n-                let expn_id = span.ctxt.outer_expn();\n+                let (expn_id, transparency, _) = self.outer_mark_with_data();\n+                let index = expn_id.as_u32() as usize;\n \n-                if let Some(&sub_hash) = cache.borrow().get(&expn_id) {\n-                    return sub_hash;\n+                if let Some(sub_hash_cache) = cache.borrow().get(index).copied().flatten() {\n+                    if let Some(sub_hash) = sub_hash_cache[transparency as usize] {\n+                        return sub_hash;\n+                    }\n                 }\n \n+                let new_len = index + 1;\n+\n                 let mut hasher = StableHasher::new();\n                 expn_id.expn_data().hash_stable(ctx, &mut hasher);\n+                transparency.hash_stable(ctx, &mut hasher);\n+\n                 let sub_hash: Fingerprint = hasher.finish();\n                 let sub_hash = sub_hash.to_smaller_hash();\n-                cache.borrow_mut().insert(expn_id, sub_hash);\n+\n+                let mut cache = cache.borrow_mut();\n+                if cache.len() < new_len {\n+                    cache.resize(new_len, None);\n+                }\n+                if let Some(mut sub_hash_cache) = cache[index] {\n+                    sub_hash_cache[transparency as usize] = Some(sub_hash);\n+                } else {\n+                    let mut sub_hash_cache = [None; NUM_TRANSPARENCIES];\n+                    sub_hash_cache[transparency as usize] = Some(sub_hash);\n+                    cache[index] = Some(sub_hash_cache);\n+                }\n                 sub_hash\n             });\n "}, {"sha": "3df6450fd3e1453b5ee79d8658a4fb3548d909a0", "filename": "src/test/ui/hygiene/auxiliary/needs_hygiene.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fneeds_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fneeds_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fneeds_hygiene.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -0,0 +1,5 @@\n+#![feature(decl_macro)]\n+macro x() { struct MyStruct; }\n+\n+x!();\n+x!();"}, {"sha": "75742960b7e3ccafef7b7725be18502395658955", "filename": "src/test/ui/hygiene/cross_crate_hygiene.rs", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fcross_crate_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fcross_crate_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fcross_crate_hygiene.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -0,0 +1,8 @@\n+// check-pass\n+// aux-build:needs_hygiene.rs\n+\n+extern crate needs_hygiene;\n+\n+use needs_hygiene::*;\n+\n+fn main() {}"}, {"sha": "5cf169dfb141bdf68ac262e12b65e28f89ec441f", "filename": "src/test/ui/hygiene/panic-location.rs", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.rs?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -0,0 +1,10 @@\n+// run-fail\n+// check-run-results\n+// exec-env:RUST_BACKTRACE=0\n+//\n+// Regression test for issue #70963\n+// The captured stderr from this test reports a location\n+// inside `VecDeque::with_capacity`, instead of `<::core::macros::panic macros>`\n+fn main() {\n+    std::collections::VecDeque::<String>::with_capacity(!0);\n+}"}, {"sha": "abdccf63b52f8c9c77e143829d094f1e453b4f02", "filename": "src/test/ui/hygiene/panic-location.run.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.run.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.run.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.run.stderr?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -0,0 +1,2 @@\n+thread 'main' panicked at 'capacity overflow', $SRC_DIR/liballoc/collections/vec_deque.rs:LL:COL\n+note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace"}, {"sha": "43b4a05468b8b6db78fbee0bfabf9875f9eb4cd7", "filename": "src/test/ui/proc-macro/dollar-crate-issue-57089.stdout", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -2,79 +2,79 @@ PRINT-BANG INPUT (DISPLAY): struct M($crate :: S) ;\n PRINT-BANG INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"M\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct A($crate :: S) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n ]"}, {"sha": "163f573522f69b56e7200ed9ed69ab096ecd73f1", "filename": "src/test/ui/proc-macro/dollar-crate-issue-62325.stdout", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -2,109 +2,109 @@ PRINT-ATTR INPUT (DISPLAY): struct A(identity ! ($crate :: S)) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"identity\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"$crate\",\n-                        span: #3 bytes(LO..HI),\n+                        span: #6 bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Joint,\n-                        span: #3 bytes(LO..HI),\n+                        span: #6 bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Alone,\n-                        span: #3 bytes(LO..HI),\n+                        span: #6 bytes(LO..HI),\n                     },\n                     Ident {\n                         ident: \"S\",\n-                        span: #3 bytes(LO..HI),\n+                        span: #6 bytes(LO..HI),\n                     },\n                 ],\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct B(identity ! ($crate :: S)) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #10 bytes(LO..HI),\n+        span: #13 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"B\",\n-        span: #10 bytes(LO..HI),\n+        span: #13 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"identity\",\n-                span: #10 bytes(LO..HI),\n+                span: #13 bytes(LO..HI),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: #10 bytes(LO..HI),\n+                span: #13 bytes(LO..HI),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"$crate\",\n-                        span: #10 bytes(LO..HI),\n+                        span: #13 bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Joint,\n-                        span: #10 bytes(LO..HI),\n+                        span: #13 bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Alone,\n-                        span: #10 bytes(LO..HI),\n+                        span: #13 bytes(LO..HI),\n                     },\n                     Ident {\n                         ident: \"S\",\n-                        span: #10 bytes(LO..HI),\n+                        span: #13 bytes(LO..HI),\n                     },\n                 ],\n-                span: #10 bytes(LO..HI),\n+                span: #13 bytes(LO..HI),\n             },\n         ],\n-        span: #10 bytes(LO..HI),\n+        span: #13 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #10 bytes(LO..HI),\n+        span: #13 bytes(LO..HI),\n     },\n ]"}, {"sha": "69105b23cf9aeffd70a5549ae22ee4623f974e39", "filename": "src/test/ui/proc-macro/dollar-crate.stdout", "status": "modified", "additions": 48, "deletions": 48, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -2,239 +2,239 @@ PRINT-BANG INPUT (DISPLAY): struct M($crate :: S) ;\n PRINT-BANG INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"M\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct A($crate :: S) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): struct D($crate :: S) ;\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"D\",\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #6 bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #6 bytes(LO..HI),\n     },\n ]\n PRINT-BANG INPUT (DISPLAY): struct M($crate :: S) ;\n PRINT-BANG INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"M\",\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n         ],\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct A($crate :: S) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n         ],\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): struct D($crate :: S) ;\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Ident {\n         ident: \"D\",\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #13 bytes(LO..HI),\n+                span: #16 bytes(LO..HI),\n             },\n         ],\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #13 bytes(LO..HI),\n+        span: #16 bytes(LO..HI),\n     },\n ]"}, {"sha": "0c2d91ee0abfb5e674fbfb708f58a23e60ac0f15", "filename": "src/test/ui/proc-macro/input-interpolated.stdout", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -8,7 +8,7 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 span: #0 bytes(402..403),\n             },\n         ],\n-        span: #3 bytes(269..271),\n+        span: #6 bytes(269..271),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): const A : u8 = 0 ;"}, {"sha": "95f89b46d0513baf2ab5bbbc37ba941415c1bfc4", "filename": "src/test/ui/proc-macro/meta-macro-hygiene.stdout", "status": "modified", "additions": 11, "deletions": 4, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -1,4 +1,4 @@\n-Def site: $DIR/auxiliary/make-macro.rs:7:9: 10:10 (#3)\n+Def site: $DIR/auxiliary/make-macro.rs:7:9: 10:10 (#6)\n #![feature /* 0#0 */(prelude_import)]\n #[prelude_import /* 0#1 */]\n use std /* 0#1 */::prelude /* 0#1 */::v1 /* 0#1 */::*;\n@@ -21,12 +21,19 @@ Expansions:\n 0: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: Root\n 1: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: AstPass(StdImports)\n 2: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: Macro(Bang, \"meta_macro::print_def_site\")\n+3: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: Macro(Bang, \"cfg_if\")\n+4: parent: ExpnId(3), call_site_ctxt: #4, def_site_ctxt: #0, kind: Macro(Bang, \"$crate::cfg_if\")\n+5: parent: ExpnId(4), call_site_ctxt: #5, def_site_ctxt: #0, kind: Macro(Bang, \"$crate::cfg_if\")\n+6: parent: ExpnId(5), call_site_ctxt: #0, def_site_ctxt: #0, kind: Macro(Bang, \"features\")\n \n SyntaxContexts:\n #0: parent: #0, outer_mark: (ExpnId(0), Opaque)\n #1: parent: #0, outer_mark: (ExpnId(1), Opaque)\n #2: parent: #0, outer_mark: (ExpnId(1), Transparent)\n-#3: parent: #0, outer_mark: (ExpnId(2), Opaque)\n-#4: parent: #0, outer_mark: (ExpnId(2), Transparent)\n-#5: parent: #0, outer_mark: (ExpnId(2), SemiTransparent)\n+#3: parent: #0, outer_mark: (ExpnId(6), SemiTransparent)\n+#4: parent: #0, outer_mark: (ExpnId(3), SemiTransparent)\n+#5: parent: #0, outer_mark: (ExpnId(4), SemiTransparent)\n+#6: parent: #0, outer_mark: (ExpnId(2), Opaque)\n+#7: parent: #0, outer_mark: (ExpnId(2), Transparent)\n+#8: parent: #0, outer_mark: (ExpnId(2), SemiTransparent)\n */"}, {"sha": "006c659df0b2fbb0e1283408c3d303b159dab240", "filename": "src/test/ui/proc-macro/meta-macro.stdout", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -1 +1 @@\n-Def site: $DIR/auxiliary/make-macro.rs:7:9: 10:10 (#3)\n+Def site: $DIR/auxiliary/make-macro.rs:7:9: 10:10 (#6)"}, {"sha": "7508231eb8cf91511e782db295d09648a82587b4", "filename": "src/test/ui/proc-macro/nested-macro-rules.stdout", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -5,10 +5,10 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         stream: TokenStream [\n             Ident {\n                 ident: \"FirstStruct\",\n-                span: $DIR/auxiliary/nested-macro-rules.rs:15:14: 15:25 (#3),\n+                span: $DIR/auxiliary/nested-macro-rules.rs:15:14: 15:25 (#8),\n             },\n         ],\n-        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#3),\n+        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#7),\n     },\n ]\n PRINT-BANG INPUT (DISPLAY): SecondStruct\n@@ -18,9 +18,9 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         stream: TokenStream [\n             Ident {\n                 ident: \"SecondStruct\",\n-                span: $DIR/nested-macro-rules.rs:18:38: 18:50 (#9),\n+                span: $DIR/nested-macro-rules.rs:18:38: 18:50 (#14),\n             },\n         ],\n-        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#8),\n+        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#13),\n     },\n ]"}, {"sha": "ab7df9b9e9879250e5d73375c16361439bfcc85f", "filename": "src/test/ui/proc-macro/nodelim-groups.stdout", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0caebfabe6f3506355581b2fbfcfa0ca05a768fc/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.stdout?ref=0caebfabe6f3506355581b2fbfcfa0ca05a768fc", "patch": "@@ -4,7 +4,7 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         kind: Str,\n         symbol: \"hi\",\n         suffix: None,\n-        span: $DIR/nodelim-groups.rs:13:42: 13:46 (#3),\n+        span: $DIR/nodelim-groups.rs:13:42: 13:46 (#6),\n     },\n     Group {\n         delimiter: None,\n@@ -44,7 +44,7 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 span: $DIR/nodelim-groups.rs:17:27: 17:28 (#0),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:47: 13:51 (#3),\n+        span: $DIR/nodelim-groups.rs:13:47: 13:51 (#6),\n     },\n     Group {\n         delimiter: Parenthesis,\n@@ -53,21 +53,21 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:53: 13:54 (#3),\n+                span: $DIR/nodelim-groups.rs:13:53: 13:54 (#6),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:55: 13:56 (#3),\n+                span: $DIR/nodelim-groups.rs:13:55: 13:56 (#6),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:57: 13:58 (#3),\n+                span: $DIR/nodelim-groups.rs:13:57: 13:58 (#6),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:52: 13:59 (#3),\n+        span: $DIR/nodelim-groups.rs:13:52: 13:59 (#6),\n     },\n ]\n PRINT-BANG INPUT (DISPLAY): \"hi\" \"hello\".len() + \"world\".len() (1 + 1)\n@@ -77,7 +77,7 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         kind: Str,\n         symbol: \"hi\",\n         suffix: None,\n-        span: $DIR/nodelim-groups.rs:13:42: 13:46 (#8),\n+        span: $DIR/nodelim-groups.rs:13:42: 13:46 (#11),\n     },\n     Group {\n         delimiter: None,\n@@ -86,49 +86,49 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Str,\n                 symbol: \"hello\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Punct {\n                 ch: '.',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Ident {\n                 ident: \"len\",\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [],\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Literal {\n                 kind: Str,\n                 symbol: \"world\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Punct {\n                 ch: '.',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Ident {\n                 ident: \"len\",\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [],\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+        span: $DIR/nodelim-groups.rs:13:47: 13:51 (#11),\n     },\n     Group {\n         delimiter: Parenthesis,\n@@ -137,20 +137,20 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:53: 13:54 (#8),\n+                span: $DIR/nodelim-groups.rs:13:53: 13:54 (#11),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:55: 13:56 (#8),\n+                span: $DIR/nodelim-groups.rs:13:55: 13:56 (#11),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:57: 13:58 (#8),\n+                span: $DIR/nodelim-groups.rs:13:57: 13:58 (#11),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:52: 13:59 (#8),\n+        span: $DIR/nodelim-groups.rs:13:52: 13:59 (#11),\n     },\n ]"}]}