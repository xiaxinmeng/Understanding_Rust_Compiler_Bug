{"sha": "97409e5fc83ab8a4460474f5dc5a119160873544", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk3NDA5ZTVmYzgzYWI4YTQ0NjA0NzRmNWRjNWExMTkxNjA4NzM1NDQ=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-08-27T19:30:36Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-08-27T19:30:36Z"}, "message": "Merge #9970\n\n9970: feat: Implement attribute input token mapping, fix attribute item token mapping r=Veykril a=Veykril\n\n![image](https://user-images.githubusercontent.com/3757771/130328577-4c1ad72c-51b1-47c3-8d3d-3242ec44a355.png)\r\n\r\nThe token mapping for items with attributes got overwritten partially by the attributes non-item input, since attributes have two different inputs, the item and the direct input both.\r\nThis PR gives attributes a second TokenMap for its direct input. We now shift all normal input IDs by the item input maximum(we maybe wanna swap this see below) similar to what we do for macro-rules/def. For mapping down we then have to figure out whether we are inside the direct attribute input or its item input to pick the appropriate mapping which can be done with some token range comparisons.\r\n\r\nFixes https://github.com/rust-analyzer/rust-analyzer/issues/9867\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>", "tree": {"sha": "33aee2fc8296ed16daa4ddb0dbef7f6298c17a19", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/33aee2fc8296ed16daa4ddb0dbef7f6298c17a19"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/97409e5fc83ab8a4460474f5dc5a119160873544", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhKT1cCRBK7hj4Ov3rIwAA6DoIADiBTrmSdlypPC1NukB88I5E\n0uNhs+QFYPv6tl0i9cWfxRmFr14J7tV2appOcVf+sr3J0U7455Oq3bAeTVpk6hNg\nbAoSYnYyCOCxXD7Vxv2i93ajCcwr+NWOrg2SCsB+oQRwlbmUppa1Kh3SaXRqQ4T2\nqTrk0K7cIMemL7vrUsVXfKG07sDEsrJSSuPKjF9bqK04fMvpeapvjiqjxveE0tKu\n75TTkiKIUZRzGss1ZdIZTEpXWQu5evDN7uvyuYg4ob6GKinYZEGg5RPqH5KTGMya\neYcUTyQ11tTUK03clRKkCZlgJxJ/SjDZlcjOIFSJajW8OTR0g3TwTRR8lkvsmio=\n=EMn8\n-----END PGP SIGNATURE-----\n", "payload": "tree 33aee2fc8296ed16daa4ddb0dbef7f6298c17a19\nparent 3acbf94d29fb57f83666cf6538435b12d4a431b6\nparent 4933beca87a19233cb6de6384da29f081eb05aaf\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1630092636 +0000\ncommitter GitHub <noreply@github.com> 1630092636 +0000\n\nMerge #9970\n\n9970: feat: Implement attribute input token mapping, fix attribute item token mapping r=Veykril a=Veykril\n\n![image](https://user-images.githubusercontent.com/3757771/130328577-4c1ad72c-51b1-47c3-8d3d-3242ec44a355.png)\r\n\r\nThe token mapping for items with attributes got overwritten partially by the attributes non-item input, since attributes have two different inputs, the item and the direct input both.\r\nThis PR gives attributes a second TokenMap for its direct input. We now shift all normal input IDs by the item input maximum(we maybe wanna swap this see below) similar to what we do for macro-rules/def. For mapping down we then have to figure out whether we are inside the direct attribute input or its item input to pick the appropriate mapping which can be done with some token range comparisons.\r\n\r\nFixes https://github.com/rust-analyzer/rust-analyzer/issues/9867\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/97409e5fc83ab8a4460474f5dc5a119160873544", "html_url": "https://github.com/rust-lang/rust/commit/97409e5fc83ab8a4460474f5dc5a119160873544", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/97409e5fc83ab8a4460474f5dc5a119160873544/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3acbf94d29fb57f83666cf6538435b12d4a431b6", "url": "https://api.github.com/repos/rust-lang/rust/commits/3acbf94d29fb57f83666cf6538435b12d4a431b6", "html_url": "https://github.com/rust-lang/rust/commit/3acbf94d29fb57f83666cf6538435b12d4a431b6"}, {"sha": "4933beca87a19233cb6de6384da29f081eb05aaf", "url": "https://api.github.com/repos/rust-lang/rust/commits/4933beca87a19233cb6de6384da29f081eb05aaf", "html_url": "https://github.com/rust-lang/rust/commit/4933beca87a19233cb6de6384da29f081eb05aaf"}], "stats": {"total": 286, "additions": 197, "deletions": 89}, "files": [{"sha": "18f6015843c27cb6db8e0626aa2a676ad18fa944", "filename": "crates/hir/src/semantics.rs", "status": "modified", "additions": 15, "deletions": 19, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Fsemantics.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -474,7 +474,7 @@ impl<'db> SemanticsImpl<'db> {\n                                 .entry(file_id)\n                                 .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n                                 .as_ref()?\n-                                .map_token_down(token.as_ref())?;\n+                                .map_token_down(self.db.upcast(), None, token.as_ref())?;\n \n                             if let Some(parent) = token.value.parent() {\n                                 self.cache(find_root(&parent), token.file_id);\n@@ -483,24 +483,21 @@ impl<'db> SemanticsImpl<'db> {\n                             return Some(token);\n                         },\n                         ast::Item(item) => {\n-                            match self.with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item))) {\n-                                Some(call_id) => {\n-                                    let file_id = call_id.as_file();\n-                                    let token = self\n-                                        .expansion_info_cache\n-                                        .borrow_mut()\n-                                        .entry(file_id)\n-                                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                                        .as_ref()?\n-                                        .map_token_down(token.as_ref())?;\n-\n-                                    if let Some(parent) = token.value.parent() {\n-                                        self.cache(find_root(&parent), token.file_id);\n-                                    }\n-\n-                                    return Some(token);\n+                            if let Some(call_id) = self.with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone()))) {\n+                                let file_id = call_id.as_file();\n+                                let token = self\n+                                    .expansion_info_cache\n+                                    .borrow_mut()\n+                                    .entry(file_id)\n+                                    .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                                    .as_ref()?\n+                                    .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n+\n+                                if let Some(parent) = token.value.parent() {\n+                                    self.cache(find_root(&parent), token.file_id);\n                                 }\n-                                None => {}\n+\n+                                return Some(token);\n                             }\n                         },\n                         _ => {}\n@@ -512,7 +509,6 @@ impl<'db> SemanticsImpl<'db> {\n         })\n         .last()\n         .unwrap();\n-\n         token.value\n     }\n "}, {"sha": "163a45ca1425c24604685c50170102936b706997", "filename": "crates/hir_def/src/attr.rs", "status": "modified", "additions": 12, "deletions": 9, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_def%2Fsrc%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_def%2Fsrc%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_def%2Fsrc%2Fattr.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -2,7 +2,9 @@\n \n use std::{\n     convert::{TryFrom, TryInto},\n-    fmt, ops,\n+    fmt,\n+    hash::Hash,\n+    ops,\n     sync::Arc,\n };\n \n@@ -158,7 +160,7 @@ impl RawAttrs {\n                 }\n \n                 let subtree = match attr.input.as_deref() {\n-                    Some(AttrInput::TokenTree(it)) => it,\n+                    Some(AttrInput::TokenTree(it, _)) => it,\n                     _ => return smallvec![attr.clone()],\n                 };\n \n@@ -258,7 +260,7 @@ impl Attrs {\n     pub fn docs(&self) -> Option<Documentation> {\n         let docs = self.by_key(\"doc\").attrs().flat_map(|attr| match attr.input.as_deref()? {\n             AttrInput::Literal(s) => Some(s),\n-            AttrInput::TokenTree(_) => None,\n+            AttrInput::TokenTree(..) => None,\n         });\n         let indent = docs\n             .clone()\n@@ -463,7 +465,7 @@ impl AttrsWithOwner {\n         // FIXME: code duplication in `docs` above\n         let docs = self.by_key(\"doc\").attrs().flat_map(|attr| match attr.input.as_deref()? {\n             AttrInput::Literal(s) => Some((s, attr.id)),\n-            AttrInput::TokenTree(_) => None,\n+            AttrInput::TokenTree(..) => None,\n         });\n         let indent = docs\n             .clone()\n@@ -652,14 +654,14 @@ pub enum AttrInput {\n     /// `#[attr = \"string\"]`\n     Literal(SmolStr),\n     /// `#[attr(subtree)]`\n-    TokenTree(Subtree),\n+    TokenTree(tt::Subtree, mbe::TokenMap),\n }\n \n impl fmt::Display for AttrInput {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         match self {\n             AttrInput::Literal(lit) => write!(f, \" = \\\"{}\\\"\", lit.escape_debug()),\n-            AttrInput::TokenTree(subtree) => subtree.fmt(f),\n+            AttrInput::TokenTree(subtree, _) => subtree.fmt(f),\n         }\n     }\n }\n@@ -679,7 +681,8 @@ impl Attr {\n             };\n             Some(Interned::new(AttrInput::Literal(value)))\n         } else if let Some(tt) = ast.token_tree() {\n-            Some(Interned::new(AttrInput::TokenTree(syntax_node_to_token_tree(tt.syntax()).0)))\n+            let (tree, map) = syntax_node_to_token_tree(tt.syntax());\n+            Some(Interned::new(AttrInput::TokenTree(tree, map)))\n         } else {\n             None\n         };\n@@ -709,7 +712,7 @@ impl Attr {\n         }\n \n         match self.input.as_deref() {\n-            Some(AttrInput::TokenTree(args)) => {\n+            Some(AttrInput::TokenTree(args, _)) => {\n                 let mut counter = 0;\n                 let paths = args\n                     .token_trees\n@@ -756,7 +759,7 @@ pub struct AttrQuery<'a> {\n impl<'a> AttrQuery<'a> {\n     pub fn tt_values(self) -> impl Iterator<Item = &'a Subtree> {\n         self.attrs().filter_map(|attr| match attr.input.as_deref()? {\n-            AttrInput::TokenTree(it) => Some(it),\n+            AttrInput::TokenTree(it, _) => Some(it),\n             _ => None,\n         })\n     }"}, {"sha": "ea6a2b4a6fa3fb883d72cdc6b4cec39c5cb6df84", "filename": "crates/hir_def/src/lib.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_def%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_def%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_def%2Fsrc%2Flib.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -786,13 +786,13 @@ fn attr_macro_as_call_id(\n         .ok_or_else(|| UnresolvedMacro { path: item_attr.path.clone() })?;\n     let mut arg = match &macro_attr.input {\n         Some(input) => match &**input {\n-            attr::AttrInput::Literal(_) => tt::Subtree::default(),\n-            attr::AttrInput::TokenTree(tt) => tt.clone(),\n+            attr::AttrInput::Literal(_) => Default::default(),\n+            attr::AttrInput::TokenTree(tt, map) => (tt.clone(), map.clone()),\n         },\n-        None => tt::Subtree::default(),\n+        None => Default::default(),\n     };\n     // The parentheses are always disposed here.\n-    arg.delimiter = None;\n+    arg.0.delimiter = None;\n \n     let res = def.as_lazy_macro(\n         db.upcast(),"}, {"sha": "bab0b4c7299e31f2469c059643075725da44385e", "filename": "crates/hir_def/src/nameres/collector.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_def%2Fsrc%2Fnameres%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_def%2Fsrc%2Fnameres%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_def%2Fsrc%2Fnameres%2Fcollector.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -289,7 +289,7 @@ impl DefCollector<'_> {\n                     || *attr_name == hir_expand::name![register_tool]\n                 {\n                     match attr.input.as_deref() {\n-                        Some(AttrInput::TokenTree(subtree)) => match &*subtree.token_trees {\n+                        Some(AttrInput::TokenTree(subtree, _)) => match &*subtree.token_trees {\n                             [tt::TokenTree::Leaf(tt::Leaf::Ident(name))] => name.as_name(),\n                             _ => continue,\n                         },"}, {"sha": "0c5457016efdde14e93d95014434aad0c139d333", "filename": "crates/hir_expand/src/db.rs", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fdb.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -223,7 +223,7 @@ fn parse_macro_expansion(\n         Ok(it) => it,\n         Err(err) => {\n             log::debug!(\n-                \"failed to parse expanstion to {:?} = {}\",\n+                \"failed to parse expansion to {:?} = {}\",\n                 fragment_kind,\n                 tt.as_debug_string()\n             );\n@@ -386,11 +386,15 @@ fn expand_proc_macro(db: &dyn AstDatabase, id: MacroCallId) -> ExpandResult<tt::\n     };\n \n     let attr_arg = match &loc.kind {\n-        MacroCallKind::Attr { attr_args, .. } => Some(attr_args),\n+        MacroCallKind::Attr { attr_args, .. } => {\n+            let mut attr_args = attr_args.0.clone();\n+            mbe::Shift::new(&macro_arg.0).shift_all(&mut attr_args);\n+            Some(attr_args)\n+        }\n         _ => None,\n     };\n \n-    expander.expand(db, loc.krate, &macro_arg.0, attr_arg)\n+    expander.expand(db, loc.krate, &macro_arg.0, attr_arg.as_ref())\n }\n \n fn is_self_replicating(from: &SyntaxNode, to: &SyntaxNode) -> bool {"}, {"sha": "5deb59ae31f0edb77e81a08dbb040cf99cf7569a", "filename": "crates/hir_expand/src/hygiene.rs", "status": "modified", "additions": 55, "deletions": 24, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -9,12 +9,15 @@ use db::TokenExpander;\n use either::Either;\n use mbe::Origin;\n use parser::SyntaxKind;\n-use syntax::{ast, AstNode, SyntaxNode, TextRange, TextSize};\n+use syntax::{\n+    ast::{self, AttrsOwner},\n+    AstNode, SyntaxNode, TextRange, TextSize,\n+};\n \n use crate::{\n     db::{self, AstDatabase},\n     name::{AsName, Name},\n-    HirFileId, HirFileIdRepr, InFile, MacroCallLoc, MacroDefKind, MacroFile,\n+    HirFileId, HirFileIdRepr, InFile, MacroCallKind, MacroCallLoc, MacroDefKind, MacroFile,\n };\n \n #[derive(Clone, Debug)]\n@@ -121,11 +124,12 @@ impl HygieneFrames {\n #[derive(Debug, Clone, PartialEq, Eq)]\n struct HygieneInfo {\n     file: MacroFile,\n-    /// The `macro_rules!` arguments.\n-    def_start: Option<InFile<TextSize>>,\n+    /// The start offset of the `macro_rules!` arguments or attribute input.\n+    attr_input_or_mac_def_start: Option<InFile<TextSize>>,\n \n     macro_def: Arc<TokenExpander>,\n     macro_arg: Arc<(tt::Subtree, mbe::TokenMap)>,\n+    macro_arg_shift: mbe::Shift,\n     exp_map: Arc<mbe::TokenMap>,\n }\n \n@@ -136,22 +140,34 @@ impl HygieneInfo {\n         token: TextRange,\n     ) -> Option<(InFile<TextRange>, Origin)> {\n         let token_id = self.exp_map.token_by_range(token)?;\n+        let (mut token_id, origin) = self.macro_def.map_id_up(token_id);\n \n-        let (token_id, origin) = self.macro_def.map_id_up(token_id);\n-        let (token_map, tt) = match origin {\n-            mbe::Origin::Call => {\n-                let call_id = self.file.macro_call_id;\n-                let loc: MacroCallLoc = db.lookup_intern_macro(call_id);\n-                let arg_start = loc.kind.arg(db)?.text_range().start();\n-                (&self.macro_arg.1, InFile::new(loc.kind.file_id(), arg_start))\n-            }\n-            mbe::Origin::Def => match (&*self.macro_def, self.def_start) {\n-                (\n-                    TokenExpander::MacroDef { def_site_token_map, .. }\n-                    | TokenExpander::MacroRules { def_site_token_map, .. },\n-                    Some(tt),\n-                ) => (def_site_token_map, tt),\n-                _ => panic!(\"`Origin::Def` used with non-`macro_rules!` macro\"),\n+        let loc = db.lookup_intern_macro(self.file.macro_call_id);\n+\n+        let (token_map, tt) = match &loc.kind {\n+            MacroCallKind::Attr { attr_args, .. } => match self.macro_arg_shift.unshift(token_id) {\n+                Some(unshifted) => {\n+                    token_id = unshifted;\n+                    (&attr_args.1, self.attr_input_or_mac_def_start?)\n+                }\n+                None => (\n+                    &self.macro_arg.1,\n+                    InFile::new(loc.kind.file_id(), loc.kind.arg(db)?.text_range().start()),\n+                ),\n+            },\n+            _ => match origin {\n+                mbe::Origin::Call => (\n+                    &self.macro_arg.1,\n+                    InFile::new(loc.kind.file_id(), loc.kind.arg(db)?.text_range().start()),\n+                ),\n+                mbe::Origin::Def => match (&*self.macro_def, &self.attr_input_or_mac_def_start) {\n+                    (\n+                        TokenExpander::MacroDef { def_site_token_map, .. }\n+                        | TokenExpander::MacroRules { def_site_token_map, .. },\n+                        Some(tt),\n+                    ) => (def_site_token_map, *tt),\n+                    _ => panic!(\"`Origin::Def` used with non-`macro_rules!` macro\"),\n+                },\n             },\n         };\n \n@@ -165,19 +181,34 @@ fn make_hygiene_info(\n     macro_file: MacroFile,\n     loc: &MacroCallLoc,\n ) -> Option<HygieneInfo> {\n-    let def_offset = loc.def.ast_id().left().and_then(|id| {\n+    let def = loc.def.ast_id().left().and_then(|id| {\n         let def_tt = match id.to_node(db) {\n-            ast::Macro::MacroRules(mac) => mac.token_tree()?.syntax().text_range().start(),\n-            ast::Macro::MacroDef(mac) => mac.body()?.syntax().text_range().start(),\n+            ast::Macro::MacroRules(mac) => mac.token_tree()?,\n+            ast::Macro::MacroDef(mac) => mac.body()?,\n         };\n         Some(InFile::new(id.file_id, def_tt))\n     });\n+    let attr_input_or_mac_def = def.or_else(|| match loc.kind {\n+        MacroCallKind::Attr { ast_id, invoc_attr_index, .. } => {\n+            let tt = ast_id.to_node(db).attrs().nth(invoc_attr_index as usize)?.token_tree()?;\n+            Some(InFile::new(ast_id.file_id, tt))\n+        }\n+        _ => None,\n+    });\n \n     let macro_def = db.macro_def(loc.def)?;\n     let (_, exp_map) = db.parse_macro_expansion(macro_file).value?;\n     let macro_arg = db.macro_arg(macro_file.macro_call_id)?;\n \n-    Some(HygieneInfo { file: macro_file, def_start: def_offset, macro_arg, macro_def, exp_map })\n+    Some(HygieneInfo {\n+        file: macro_file,\n+        attr_input_or_mac_def_start: attr_input_or_mac_def\n+            .map(|it| it.map(|tt| tt.syntax().text_range().start())),\n+        macro_arg_shift: mbe::Shift::new(&macro_arg.0),\n+        macro_arg,\n+        macro_def,\n+        exp_map,\n+    })\n }\n \n impl HygieneFrame {\n@@ -214,7 +245,7 @@ impl HygieneFrame {\n             Some(it) => it,\n         };\n \n-        let def_site = info.def_start.map(|it| db.hygiene_frame(it.file_id));\n+        let def_site = info.attr_input_or_mac_def_start.map(|it| db.hygiene_frame(it.file_id));\n         let call_site = Some(db.hygiene_frame(calling_file));\n \n         HygieneFrame { expansion: Some(info), local_inner, krate, call_site, def_site }"}, {"sha": "40380e1df17dc25de1a5498cd81b2bc8b278fc89", "filename": "crates/hir_expand/src/lib.rs", "status": "modified", "additions": 93, "deletions": 21, "changes": 114, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fhir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Flib.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -27,7 +27,7 @@ use std::{hash::Hash, iter, sync::Arc};\n use base_db::{impl_intern_key, salsa, CrateId, FileId, FileRange};\n use syntax::{\n     algo::skip_trivia_token,\n-    ast::{self, AstNode},\n+    ast::{self, AstNode, AttrsOwner},\n     Direction, SyntaxNode, SyntaxToken, TextRange, TextSize,\n };\n \n@@ -36,6 +36,7 @@ use crate::{\n     builtin_attr::BuiltinAttrExpander,\n     builtin_derive::BuiltinDeriveExpander,\n     builtin_macro::{BuiltinFnLikeExpander, EagerExpander},\n+    db::TokenExpander,\n     proc_macro::ProcMacroExpander,\n };\n \n@@ -132,6 +133,17 @@ impl HirFileId {\n                     };\n                     Some(InFile::new(id.file_id, def_tt))\n                 });\n+                let attr_input_or_mac_def = def.or_else(|| match loc.kind {\n+                    MacroCallKind::Attr { ast_id, invoc_attr_index, .. } => {\n+                        let tt = ast_id\n+                            .to_node(db)\n+                            .attrs()\n+                            .nth(invoc_attr_index as usize)?\n+                            .token_tree()?;\n+                        Some(InFile::new(ast_id.file_id, tt))\n+                    }\n+                    _ => None,\n+                });\n \n                 let macro_def = db.macro_def(loc.def)?;\n                 let (parse, exp_map) = db.parse_macro_expansion(macro_file).value?;\n@@ -140,7 +152,8 @@ impl HirFileId {\n                 Some(ExpansionInfo {\n                     expanded: InFile::new(self, parse.syntax_node()),\n                     arg: InFile::new(loc.kind.file_id(), arg_tt),\n-                    def,\n+                    attr_input_or_mac_def,\n+                    macro_arg_shift: mbe::Shift::new(&macro_arg.0),\n                     macro_arg,\n                     macro_def,\n                     exp_map,\n@@ -270,7 +283,7 @@ pub enum MacroCallKind {\n     Attr {\n         ast_id: AstId<ast::Item>,\n         attr_name: String,\n-        attr_args: tt::Subtree,\n+        attr_args: (tt::Subtree, mbe::TokenMap),\n         /// Syntactical index of the invoking `#[attribute]`.\n         ///\n         /// Outer attributes are counted first, then inner attributes. This does not support\n@@ -335,11 +348,12 @@ impl MacroCallId {\n pub struct ExpansionInfo {\n     expanded: InFile<SyntaxNode>,\n     arg: InFile<SyntaxNode>,\n-    /// The `macro_rules!` arguments.\n-    def: Option<InFile<ast::TokenTree>>,\n+    /// The `macro_rules!` arguments or attribute input.\n+    attr_input_or_mac_def: Option<InFile<ast::TokenTree>>,\n \n-    macro_def: Arc<db::TokenExpander>,\n+    macro_def: Arc<TokenExpander>,\n     macro_arg: Arc<(tt::Subtree, mbe::TokenMap)>,\n+    macro_arg_shift: mbe::Shift,\n     exp_map: Arc<mbe::TokenMap>,\n }\n \n@@ -350,11 +364,53 @@ impl ExpansionInfo {\n         Some(self.arg.with_value(self.arg.value.parent()?))\n     }\n \n-    pub fn map_token_down(&self, token: InFile<&SyntaxToken>) -> Option<InFile<SyntaxToken>> {\n+    pub fn map_token_down(\n+        &self,\n+        db: &dyn db::AstDatabase,\n+        item: Option<ast::Item>,\n+        token: InFile<&SyntaxToken>,\n+    ) -> Option<InFile<SyntaxToken>> {\n         assert_eq!(token.file_id, self.arg.file_id);\n-        let range = token.value.text_range().checked_sub(self.arg.value.text_range().start())?;\n-        let token_id = self.macro_arg.1.token_by_range(range)?;\n-        let token_id = self.macro_def.map_id_down(token_id);\n+        let token_id = if let Some(item) = item {\n+            let call_id = match self.expanded.file_id.0 {\n+                HirFileIdRepr::FileId(_) => return None,\n+                HirFileIdRepr::MacroFile(macro_file) => macro_file.macro_call_id,\n+            };\n+            let loc = db.lookup_intern_macro(call_id);\n+\n+            let token_range = token.value.text_range();\n+            match &loc.kind {\n+                MacroCallKind::Attr { attr_args, invoc_attr_index, .. } => {\n+                    let attr = item.attrs().nth(*invoc_attr_index as usize)?;\n+                    match attr.token_tree() {\n+                        Some(token_tree)\n+                            if token_tree.syntax().text_range().contains_range(token_range) =>\n+                        {\n+                            let attr_input_start =\n+                                token_tree.left_delimiter_token()?.text_range().start();\n+                            let range = token.value.text_range().checked_sub(attr_input_start)?;\n+                            let token_id =\n+                                self.macro_arg_shift.shift(attr_args.1.token_by_range(range)?);\n+                            Some(token_id)\n+                        }\n+                        _ => None,\n+                    }\n+                }\n+                _ => None,\n+            }\n+        } else {\n+            None\n+        };\n+\n+        let token_id = match token_id {\n+            Some(token_id) => token_id,\n+            None => {\n+                let range =\n+                    token.value.text_range().checked_sub(self.arg.value.text_range().start())?;\n+                let token_id = self.macro_arg.1.token_by_range(range)?;\n+                self.macro_def.map_id_down(token_id)\n+            }\n+        };\n \n         let range = self.exp_map.range_by_token(token_id, token.value.kind())?;\n \n@@ -365,20 +421,36 @@ impl ExpansionInfo {\n \n     pub fn map_token_up(\n         &self,\n+        db: &dyn db::AstDatabase,\n         token: InFile<&SyntaxToken>,\n     ) -> Option<(InFile<SyntaxToken>, Origin)> {\n         let token_id = self.exp_map.token_by_range(token.value.text_range())?;\n+        let (mut token_id, origin) = self.macro_def.map_id_up(token_id);\n \n-        let (token_id, origin) = self.macro_def.map_id_up(token_id);\n-        let (token_map, tt) = match origin {\n-            mbe::Origin::Call => (&self.macro_arg.1, self.arg.clone()),\n-            mbe::Origin::Def => match (&*self.macro_def, self.def.as_ref()) {\n-                (\n-                    db::TokenExpander::MacroRules { def_site_token_map, .. }\n-                    | db::TokenExpander::MacroDef { def_site_token_map, .. },\n-                    Some(tt),\n-                ) => (def_site_token_map, tt.syntax().cloned()),\n-                _ => panic!(\"`Origin::Def` used with non-`macro_rules!` macro\"),\n+        let call_id = match self.expanded.file_id.0 {\n+            HirFileIdRepr::FileId(_) => return None,\n+            HirFileIdRepr::MacroFile(macro_file) => macro_file.macro_call_id,\n+        };\n+        let loc = db.lookup_intern_macro(call_id);\n+\n+        let (token_map, tt) = match &loc.kind {\n+            MacroCallKind::Attr { attr_args, .. } => match self.macro_arg_shift.unshift(token_id) {\n+                Some(unshifted) => {\n+                    token_id = unshifted;\n+                    (&attr_args.1, self.attr_input_or_mac_def.clone()?.syntax().cloned())\n+                }\n+                None => (&self.macro_arg.1, self.arg.clone()),\n+            },\n+            _ => match origin {\n+                mbe::Origin::Call => (&self.macro_arg.1, self.arg.clone()),\n+                mbe::Origin::Def => match (&*self.macro_def, &self.attr_input_or_mac_def) {\n+                    (\n+                        TokenExpander::MacroRules { def_site_token_map, .. }\n+                        | TokenExpander::MacroDef { def_site_token_map, .. },\n+                        Some(tt),\n+                    ) => (def_site_token_map, tt.syntax().cloned()),\n+                    _ => panic!(\"`Origin::Def` used with non-`macro_rules!` macro\"),\n+                },\n             },\n         };\n \n@@ -532,7 +604,7 @@ fn ascend_call_token(\n     expansion: &ExpansionInfo,\n     token: InFile<SyntaxToken>,\n ) -> Option<InFile<SyntaxToken>> {\n-    let (mapped, origin) = expansion.map_token_up(token.as_ref())?;\n+    let (mapped, origin) = expansion.map_token_up(db, token.as_ref())?;\n     if origin != Origin::Call {\n         return None;\n     }"}, {"sha": "d2b955c5c8136642e6d4b714e29cb8d42bc41429", "filename": "crates/mbe/src/lib.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fmbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fmbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Flib.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -97,11 +97,11 @@ struct Rule {\n     rhs: MetaTemplate,\n }\n \n-#[derive(Clone, Copy, Debug, PartialEq, Eq)]\n-struct Shift(u32);\n+#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]\n+pub struct Shift(u32);\n \n impl Shift {\n-    fn new(tt: &tt::Subtree) -> Shift {\n+    pub fn new(tt: &tt::Subtree) -> Shift {\n         // Note that TokenId is started from zero,\n         // We have to add 1 to prevent duplication.\n         let value = max_id(tt).map_or(0, |it| it + 1);\n@@ -134,7 +134,7 @@ impl Shift {\n     }\n \n     /// Shift given TokenTree token id\n-    fn shift_all(self, tt: &mut tt::Subtree) {\n+    pub fn shift_all(self, tt: &mut tt::Subtree) {\n         for t in &mut tt.token_trees {\n             match t {\n                 tt::TokenTree::Leaf(leaf) => match leaf {\n@@ -152,14 +152,14 @@ impl Shift {\n         }\n     }\n \n-    fn shift(self, id: tt::TokenId) -> tt::TokenId {\n+    pub fn shift(self, id: tt::TokenId) -> tt::TokenId {\n         if id == tt::TokenId::unspecified() {\n             return id;\n         }\n         tt::TokenId(id.0 + self.0)\n     }\n \n-    fn unshift(self, id: tt::TokenId) -> Option<tt::TokenId> {\n+    pub fn unshift(self, id: tt::TokenId) -> Option<tt::TokenId> {\n         id.0.checked_sub(self.0).map(tt::TokenId)\n     }\n }"}, {"sha": "ff0c106cf255dd43cf8a57c86765b534d01bae40", "filename": "crates/mbe/src/token_map.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fmbe%2Fsrc%2Ftoken_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/97409e5fc83ab8a4460474f5dc5a119160873544/crates%2Fmbe%2Fsrc%2Ftoken_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftoken_map.rs?ref=97409e5fc83ab8a4460474f5dc5a119160873544", "patch": "@@ -1,9 +1,11 @@\n //! Mapping between `TokenId`s and the token's position in macro definitions or inputs.\n \n+use std::hash::Hash;\n+\n use parser::{SyntaxKind, T};\n use syntax::{TextRange, TextSize};\n \n-#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n+#[derive(Debug, PartialEq, Eq, Clone, Copy, Hash)]\n enum TokenTextRange {\n     Token(TextRange),\n     Delimiter(TextRange),\n@@ -25,7 +27,7 @@ impl TokenTextRange {\n }\n \n /// Maps `tt::TokenId` to the relative range of the original token.\n-#[derive(Debug, PartialEq, Eq, Clone, Default)]\n+#[derive(Debug, PartialEq, Eq, Clone, Default, Hash)]\n pub struct TokenMap {\n     /// Maps `tt::TokenId` to the *relative* source range.\n     entries: Vec<(tt::TokenId, TokenTextRange)>,"}]}