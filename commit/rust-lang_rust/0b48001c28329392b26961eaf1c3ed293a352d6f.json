{"sha": "0b48001c28329392b26961eaf1c3ed293a352d6f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBiNDgwMDFjMjgzMjkzOTJiMjY5NjFlYWYxYzNlZDI5M2EzNTJkNmY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-11-07T15:26:26Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-11-07T15:26:26Z"}, "message": "auto merge of #17830 : pczarn/rust/interp_tt, r=pnkfelix\n\nCloses #14197\r\n\r\nRemoves the `matchers` nonterminal.\r\n\r\nIf you're using `$foo:matchers` in a macro, write `$foo:tt` instead.\r\n\r\n[breaking-change]", "tree": {"sha": "7519b6fedac45695508ca60d5b2a4542ad2a22e2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7519b6fedac45695508ca60d5b2a4542ad2a22e2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0b48001c28329392b26961eaf1c3ed293a352d6f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0b48001c28329392b26961eaf1c3ed293a352d6f", "html_url": "https://github.com/rust-lang/rust/commit/0b48001c28329392b26961eaf1c3ed293a352d6f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0b48001c28329392b26961eaf1c3ed293a352d6f/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "223ca7643976c89c76d78337a5f7a9b1677cc0f1", "url": "https://api.github.com/repos/rust-lang/rust/commits/223ca7643976c89c76d78337a5f7a9b1677cc0f1", "html_url": "https://github.com/rust-lang/rust/commit/223ca7643976c89c76d78337a5f7a9b1677cc0f1"}, {"sha": "00676c8ea20a7310dacc85759daf57eab86ac965", "url": "https://api.github.com/repos/rust-lang/rust/commits/00676c8ea20a7310dacc85759daf57eab86ac965", "html_url": "https://github.com/rust-lang/rust/commit/00676c8ea20a7310dacc85759daf57eab86ac965"}], "stats": {"total": 974, "additions": 539, "deletions": 435}, "files": [{"sha": "ff50636a8d982f14309713774b07dd5f43b3a59d", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -163,7 +163,8 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n \n             token::Lifetime(..) => \"lifetime\",\n             token::DocComment(..) => \"doccomment\",\n-            token::Underscore | token::Eof | token::Interpolated(..) => \"\",\n+            token::Underscore | token::Eof | token::Interpolated(..) |\n+                token::MatchNt(..) | token::SubstNt(..) => \"\",\n         };\n \n         // as mentioned above, use the original source code instead of"}, {"sha": "20f7caac48222c6cc860e351cc51e7a988d524fb", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 83, "deletions": 80, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -10,7 +10,7 @@\n \n // The Rust abstract syntax tree.\n \n-use codemap::{Span, Spanned, DUMMY_SP, ExpnId};\n+use codemap::{Span, Spanned, DUMMY_SP, ExpnId, respan};\n use abi::Abi;\n use ast_util;\n use owned_slice::OwnedSlice;\n@@ -713,6 +713,19 @@ impl Delimited {\n     }\n }\n \n+/// A sequence of token treesee\n+#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n+pub struct SequenceRepetition {\n+    /// The sequence of token trees\n+    pub tts: Vec<TokenTree>,\n+    /// The optional separator\n+    pub separator: Option<token::Token>,\n+    /// Whether the sequence can be repeated zero (*), or one or more times (+)\n+    pub op: KleeneOp,\n+    /// The number of `MatchNt`s that appear in the sequence (and subsequences)\n+    pub num_captures: uint,\n+}\n+\n /// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n /// for token sequences.\n #[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n@@ -727,14 +740,12 @@ pub enum KleeneOp {\n /// be passed to syntax extensions using a uniform type.\n ///\n /// If the syntax extension is an MBE macro, it will attempt to match its\n-/// LHS \"matchers\" against the provided token tree, and if it finds a\n+/// LHS token tree against the provided token tree, and if it finds a\n /// match, will transcribe the RHS token tree, splicing in any captured\n-/// `macro_parser::matched_nonterminals` into the `TtNonterminal`s it finds.\n+/// macro_parser::matched_nonterminals into the `SubstNt`s it finds.\n ///\n-/// The RHS of an MBE macro is the only place a `TtNonterminal` or `TtSequence`\n-/// makes any real sense. You could write them elsewhere but nothing\n-/// else knows what to do with them, so you'll probably get a syntax\n-/// error.\n+/// The RHS of an MBE macro is the only place `SubstNt`s are substituted.\n+/// Nothing special happens to misnamed or misplaced `SubstNt`s.\n #[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n pub enum TokenTree {\n@@ -743,90 +754,82 @@ pub enum TokenTree {\n     /// A delimited sequence of token trees\n     TtDelimited(Span, Rc<Delimited>),\n \n-    // These only make sense for right-hand-sides of MBE macros:\n+    // This only makes sense in MBE macros.\n \n-    /// A Kleene-style repetition sequence with an optional separator.\n-    // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TtSequence(Span, Rc<Vec<TokenTree>>, Option<token::Token>, KleeneOp),\n-    /// A syntactic variable that will be filled in by macro expansion.\n-    TtNonterminal(Span, Ident)\n+    /// A kleene-style repetition sequence with a span\n+    // FIXME(eddyb) #12938 Use DST.\n+    TtSequence(Span, Rc<SequenceRepetition>),\n }\n \n impl TokenTree {\n+    pub fn len(&self) -> uint {\n+        match *self {\n+            TtToken(_, token::DocComment(_)) => 2,\n+            TtToken(_, token::SubstNt(..)) => 2,\n+            TtToken(_, token::MatchNt(..)) => 3,\n+            TtDelimited(_, ref delimed) => {\n+                delimed.tts.len() + 2\n+            }\n+            TtSequence(_, ref seq) => {\n+                seq.tts.len()\n+            }\n+            TtToken(..) => 0\n+        }\n+    }\n+\n+    pub fn get_tt(&self, index: uint) -> TokenTree {\n+        match (self, index) {\n+            (&TtToken(sp, token::DocComment(_)), 0) => {\n+                TtToken(sp, token::Pound)\n+            }\n+            (&TtToken(sp, token::DocComment(name)), 1) => {\n+                let doc = MetaNameValue(token::intern_and_get_ident(\"doc\"),\n+                                        respan(sp, LitStr(token::get_name(name), CookedStr)));\n+                let doc = token::NtMeta(P(respan(sp, doc)));\n+                TtDelimited(sp, Rc::new(Delimited {\n+                    delim: token::Bracket,\n+                    open_span: sp,\n+                    tts: vec![TtToken(sp, token::Interpolated(doc))],\n+                    close_span: sp,\n+                }))\n+            }\n+            (&TtDelimited(_, ref delimed), _) => {\n+                if index == 0 {\n+                    return delimed.open_tt();\n+                }\n+                if index == delimed.tts.len() + 1 {\n+                    return delimed.close_tt();\n+                }\n+                delimed.tts[index - 1].clone()\n+            }\n+            (&TtToken(sp, token::SubstNt(name, name_st)), _) => {\n+                let v = [TtToken(sp, token::Dollar),\n+                         TtToken(sp, token::Ident(name, name_st))];\n+                v[index]\n+            }\n+            (&TtToken(sp, token::MatchNt(name, kind, name_st, kind_st)), _) => {\n+                let v = [TtToken(sp, token::SubstNt(name, name_st)),\n+                         TtToken(sp, token::Colon),\n+                         TtToken(sp, token::Ident(kind, kind_st))];\n+                v[index]\n+            }\n+            (&TtSequence(_, ref seq), _) => {\n+                seq.tts[index].clone()\n+            }\n+            _ => panic!(\"Cannot expand a token tree\")\n+        }\n+    }\n+\n     /// Returns the `Span` corresponding to this token tree.\n     pub fn get_span(&self) -> Span {\n         match *self {\n-            TtToken(span, _)           => span,\n-            TtDelimited(span, _)       => span,\n-            TtSequence(span, _, _, _)  => span,\n-            TtNonterminal(span, _)     => span,\n+            TtToken(span, _)     => span,\n+            TtDelimited(span, _) => span,\n+            TtSequence(span, _)  => span,\n         }\n     }\n }\n \n-// Matchers are nodes defined-by and recognized-by the main rust parser and\n-// language, but they're only ever found inside syntax-extension invocations;\n-// indeed, the only thing that ever _activates_ the rules in the rust parser\n-// for parsing a matcher is a matcher looking for the 'matchers' nonterminal\n-// itself. Matchers represent a small sub-language for pattern-matching\n-// token-trees, and are thus primarily used by the macro-defining extension\n-// itself.\n-//\n-// MatchTok\n-// --------\n-//\n-//     A matcher that matches a single token, denoted by the token itself. So\n-//     long as there's no $ involved.\n-//\n-//\n-// MatchSeq\n-// --------\n-//\n-//     A matcher that matches a sequence of sub-matchers, denoted various\n-//     possible ways:\n-//\n-//             $(M)*       zero or more Ms\n-//             $(M)+       one or more Ms\n-//             $(M),+      one or more comma-separated Ms\n-//             $(A B C);*  zero or more semi-separated 'A B C' seqs\n-//\n-//\n-// MatchNonterminal\n-// -----------------\n-//\n-//     A matcher that matches one of a few interesting named rust\n-//     nonterminals, such as types, expressions, items, or raw token-trees. A\n-//     black-box matcher on expr, for example, binds an expr to a given ident,\n-//     and that ident can re-occur as an interpolation in the RHS of a\n-//     macro-by-example rule. For example:\n-//\n-//        $foo:expr   =>     1 + $foo    // interpolate an expr\n-//        $foo:tt     =>     $foo        // interpolate a token-tree\n-//        $foo:tt     =>     bar! $foo   // only other valid interpolation\n-//                                       // is in arg position for another\n-//                                       // macro\n-//\n-// As a final, horrifying aside, note that macro-by-example's input is\n-// also matched by one of these matchers. Holy self-referential! It is matched\n-// by a MatchSeq, specifically this one:\n-//\n-//                   $( $lhs:matchers => $rhs:tt );+\n-//\n-// If you understand that, you have closed the loop and understand the whole\n-// macro system. Congratulations.\n-pub type Matcher = Spanned<Matcher_>;\n-\n-#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n-pub enum Matcher_ {\n-    /// Match one token\n-    MatchTok(token::Token),\n-    /// Match repetitions of a sequence: body, separator, Kleene operator,\n-    /// lo, hi position-in-match-array used:\n-    MatchSeq(Vec<Matcher>, Option<token::Token>, KleeneOp, uint, uint),\n-    /// Parse a Rust NT: name to bind, name of NT, position in match array:\n-    MatchNonterminal(Ident, Ident, uint)\n-}\n-\n pub type Mac = Spanned<Mac_>;\n \n /// Represents a macro invocation. The Path indicates which macro"}, {"sha": "db6be89e6e9efb918452d88ab980545857e87868", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 33, "deletions": 19, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -616,6 +616,20 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                                 vec!(mk_name(cx, sp, ident.ident())));\n         }\n \n+        token::MatchNt(name, kind, name_style, kind_style) => {\n+            return cx.expr_call(sp,\n+                                mk_token_path(cx, sp, \"MatchNt\"),\n+                                vec![mk_ident(cx, sp, name),\n+                                     mk_ident(cx, sp, kind),\n+                                     match name_style {\n+                                         ModName => mk_token_path(cx, sp, \"ModName\"),\n+                                         Plain   => mk_token_path(cx, sp, \"Plain\"),\n+                                     },\n+                                     match kind_style {\n+                                         ModName => mk_token_path(cx, sp, \"ModName\"),\n+                                         Plain   => mk_token_path(cx, sp, \"Plain\"),\n+                                     }]);\n+        }\n         token::Interpolated(_) => panic!(\"quote! with interpolated token\"),\n \n         _ => ()\n@@ -654,6 +668,25 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n \n fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n     match *tt {\n+        ast::TtToken(sp, SubstNt(ident, _)) => {\n+            // tt.extend($ident.to_tokens(ext_cx).into_iter())\n+\n+            let e_to_toks =\n+                cx.expr_method_call(sp,\n+                                    cx.expr_ident(sp, ident),\n+                                    id_ext(\"to_tokens\"),\n+                                    vec!(cx.expr_ident(sp, id_ext(\"ext_cx\"))));\n+            let e_to_toks =\n+                cx.expr_method_call(sp, e_to_toks, id_ext(\"into_iter\"), vec![]);\n+\n+            let e_push =\n+                cx.expr_method_call(sp,\n+                                    cx.expr_ident(sp, id_ext(\"tt\")),\n+                                    id_ext(\"extend\"),\n+                                    vec!(e_to_toks));\n+\n+            vec!(cx.stmt_expr(e_push))\n+        }\n         ast::TtToken(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n             let e_tok = cx.expr_call(sp,\n@@ -673,25 +706,6 @@ fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n                 .collect()\n         },\n         ast::TtSequence(..) => panic!(\"TtSequence in quote!\"),\n-        ast::TtNonterminal(sp, ident) => {\n-            // tt.extend($ident.to_tokens(ext_cx).into_iter())\n-\n-            let e_to_toks =\n-                cx.expr_method_call(sp,\n-                                    cx.expr_ident(sp, ident),\n-                                    id_ext(\"to_tokens\"),\n-                                    vec!(cx.expr_ident(sp, id_ext(\"ext_cx\"))));\n-            let e_to_toks =\n-                cx.expr_method_call(sp, e_to_toks, id_ext(\"into_iter\"), vec![]);\n-\n-            let e_push =\n-                cx.expr_method_call(sp,\n-                                    cx.expr_ident(sp, id_ext(\"tt\")),\n-                                    id_ext(\"extend\"),\n-                                    vec!(e_to_toks));\n-\n-            vec!(cx.stmt_expr(e_push))\n-        },\n     }\n }\n "}, {"sha": "1f0b6672594737bfdb33e5073b8ccc6f7e76f029", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 199, "deletions": 130, "changes": 329, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -78,126 +78,165 @@\n \n \n use ast;\n-use ast::{Matcher, MatchTok, MatchSeq, MatchNonterminal, Ident};\n+use ast::{TokenTree, Ident};\n+use ast::{TtDelimited, TtSequence, TtToken};\n use codemap::{BytePos, mk_sp};\n use codemap;\n use parse::lexer::*; //resolve bug?\n use parse::ParseSess;\n use parse::attr::ParserAttr;\n use parse::parser::{LifetimeAndTypesWithoutColons, Parser};\n+use parse::token::{Eof, DocComment, MatchNt, SubstNt};\n use parse::token::{Token, Nonterminal};\n use parse::token;\n use print::pprust;\n use ptr::P;\n \n+use std::mem;\n use std::rc::Rc;\n use std::collections::HashMap;\n+use std::collections::hash_map::{Vacant, Occupied};\n \n-/* to avoid costly uniqueness checks, we require that `MatchSeq` always has a\n-nonempty body. */\n+// To avoid costly uniqueness checks, we require that `MatchSeq` always has\n+// a nonempty body.\n \n+#[deriving(Clone)]\n+enum TokenTreeOrTokenTreeVec {\n+    Tt(ast::TokenTree),\n+    TtSeq(Rc<Vec<ast::TokenTree>>),\n+}\n+\n+impl TokenTreeOrTokenTreeVec {\n+    fn len(&self) -> uint {\n+        match self {\n+            &TtSeq(ref v) => v.len(),\n+            &Tt(ref tt) => tt.len(),\n+        }\n+    }\n+\n+    fn get_tt(&self, index: uint) -> TokenTree {\n+        match self {\n+            &TtSeq(ref v) => v[index].clone(),\n+            &Tt(ref tt) => tt.get_tt(index),\n+        }\n+    }\n+}\n+\n+/// an unzipping of `TokenTree`s\n+#[deriving(Clone)]\n+struct MatcherTtFrame {\n+    elts: TokenTreeOrTokenTreeVec,\n+    idx: uint,\n+}\n \n #[deriving(Clone)]\n pub struct MatcherPos {\n-    elts: Vec<ast::Matcher> , // maybe should be <'>? Need to understand regions.\n+    stack: Vec<MatcherTtFrame>,\n+    top_elts: TokenTreeOrTokenTreeVec,\n     sep: Option<Token>,\n     idx: uint,\n     up: Option<Box<MatcherPos>>,\n     matches: Vec<Vec<Rc<NamedMatch>>>,\n-    match_lo: uint, match_hi: uint,\n+    match_lo: uint,\n+    match_cur: uint,\n+    match_hi: uint,\n     sp_lo: BytePos,\n }\n \n-pub fn count_names(ms: &[Matcher]) -> uint {\n-    ms.iter().fold(0, |ct, m| {\n-        ct + match m.node {\n-            MatchTok(_) => 0u,\n-            MatchSeq(ref more_ms, _, _, _, _) => {\n-                count_names(more_ms.as_slice())\n+pub fn count_names(ms: &[TokenTree]) -> uint {\n+    ms.iter().fold(0, |count, elt| {\n+        count + match elt {\n+            &TtSequence(_, ref seq) => {\n+                seq.num_captures\n             }\n-            MatchNonterminal(_, _, _) => 1u\n-        }})\n-}\n-\n-pub fn initial_matcher_pos(ms: Vec<Matcher> , sep: Option<Token>, lo: BytePos)\n-                           -> Box<MatcherPos> {\n-    let mut match_idx_hi = 0u;\n-    for elt in ms.iter() {\n-        match elt.node {\n-            MatchTok(_) => (),\n-            MatchSeq(_,_,_,_,hi) => {\n-                match_idx_hi = hi;       // it is monotonic...\n+            &TtDelimited(_, ref delim) => {\n+                count_names(delim.tts.as_slice())\n             }\n-            MatchNonterminal(_,_,pos) => {\n-                match_idx_hi = pos+1u;  // ...so latest is highest\n+            &TtToken(_, MatchNt(..)) => {\n+                1\n             }\n+            &TtToken(_, _) => 0,\n         }\n-    }\n-    let matches = Vec::from_fn(count_names(ms.as_slice()), |_i| Vec::new());\n+    })\n+}\n+\n+pub fn initial_matcher_pos(ms: Rc<Vec<TokenTree>>, sep: Option<Token>, lo: BytePos)\n+                           -> Box<MatcherPos> {\n+    let match_idx_hi = count_names(ms.as_slice());\n+    let matches = Vec::from_fn(match_idx_hi, |_i| Vec::new());\n     box MatcherPos {\n-        elts: ms,\n+        stack: vec![],\n+        top_elts: TtSeq(ms),\n         sep: sep,\n         idx: 0u,\n         up: None,\n         matches: matches,\n         match_lo: 0u,\n+        match_cur: 0u,\n         match_hi: match_idx_hi,\n         sp_lo: lo\n     }\n }\n \n-/// NamedMatch is a pattern-match result for a single ast::MatchNonterminal:\n+/// NamedMatch is a pattern-match result for a single token::MATCH_NONTERMINAL:\n /// so it is associated with a single ident in a parse, and all\n-/// MatchedNonterminal's in the NamedMatch have the same nonterminal type\n-/// (expr, item, etc). All the leaves in a single NamedMatch correspond to a\n-/// single matcher_nonterminal in the ast::Matcher that produced it.\n+/// `MatchedNonterminal`s in the NamedMatch have the same nonterminal type\n+/// (expr, item, etc). Each leaf in a single NamedMatch corresponds to a\n+/// single token::MATCH_NONTERMINAL in the TokenTree that produced it.\n ///\n-/// It should probably be renamed, it has more or less exact correspondence to\n-/// ast::match nodes, and the in-memory structure of a particular NamedMatch\n-/// represents the match that occurred when a particular subset of an\n-/// ast::match -- those ast::Matcher nodes leading to a single\n-/// MatchNonterminal -- was applied to a particular token tree.\n+/// The in-memory structure of a particular NamedMatch represents the match\n+/// that occurred when a particular subset of a matcher was applied to a\n+/// particular token tree.\n ///\n /// The width of each MatchedSeq in the NamedMatch, and the identity of the\n-/// MatchedNonterminal's, will depend on the token tree it was applied to: each\n-/// MatchedSeq corresponds to a single MatchSeq in the originating\n-/// ast::Matcher. The depth of the NamedMatch structure will therefore depend\n-/// only on the nesting depth of ast::MatchSeq's in the originating\n-/// ast::Matcher it was derived from.\n+/// `MatchedNonterminal`s, will depend on the token tree it was applied to:\n+/// each MatchedSeq corresponds to a single TTSeq in the originating\n+/// token tree. The depth of the NamedMatch structure will therefore depend\n+/// only on the nesting depth of `ast::TTSeq`s in the originating\n+/// token tree it was derived from.\n \n pub enum NamedMatch {\n     MatchedSeq(Vec<Rc<NamedMatch>>, codemap::Span),\n     MatchedNonterminal(Nonterminal)\n }\n \n-pub fn nameize(p_s: &ParseSess, ms: &[Matcher], res: &[Rc<NamedMatch>])\n+pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n             -> HashMap<Ident, Rc<NamedMatch>> {\n-    fn n_rec(p_s: &ParseSess, m: &Matcher, res: &[Rc<NamedMatch>],\n-             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>) {\n-        match *m {\n-          codemap::Spanned {node: MatchTok(_), .. } => (),\n-          codemap::Spanned {node: MatchSeq(ref more_ms, _, _, _, _), .. } => {\n-            for next_m in more_ms.iter() {\n-                n_rec(p_s, next_m, res, ret_val)\n-            };\n-          }\n-          codemap::Spanned {\n-                node: MatchNonterminal(bind_name, _, idx),\n-                span\n-          } => {\n-            if ret_val.contains_key(&bind_name) {\n-                let string = token::get_ident(bind_name);\n-                p_s.span_diagnostic\n-                   .span_fatal(span,\n-                               format!(\"duplicated bind name: {}\",\n-                                       string.get()).as_slice())\n+    fn n_rec(p_s: &ParseSess, m: &TokenTree, res: &[Rc<NamedMatch>],\n+             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>, idx: &mut uint) {\n+        match m {\n+            &TtSequence(_, ref seq) => {\n+                for next_m in seq.tts.iter() {\n+                    n_rec(p_s, next_m, res, ret_val, idx)\n+                }\n+            }\n+            &TtDelimited(_, ref delim) => {\n+                for next_m in delim.tts.iter() {\n+                    n_rec(p_s, next_m, res, ret_val, idx)\n+                }\n             }\n-            ret_val.insert(bind_name, res[idx].clone());\n-          }\n+            &TtToken(sp, MatchNt(bind_name, _, _, _)) => {\n+                match ret_val.entry(bind_name) {\n+                    Vacant(spot) => {\n+                        spot.set(res[*idx].clone());\n+                        *idx += 1;\n+                    }\n+                    Occupied(..) => {\n+                        let string = token::get_ident(bind_name);\n+                        p_s.span_diagnostic\n+                           .span_fatal(sp,\n+                                       format!(\"duplicated bind name: {}\",\n+                                               string.get()).as_slice())\n+                    }\n+                }\n+            }\n+            &TtToken(_, SubstNt(..)) => panic!(\"Cannot fill in a NT\"),\n+            &TtToken(_, _) => (),\n         }\n     }\n     let mut ret_val = HashMap::new();\n-    for m in ms.iter() { n_rec(p_s, m, res, &mut ret_val) }\n+    let mut idx = 0u;\n+    for m in ms.iter() { n_rec(p_s, m, res, &mut ret_val, &mut idx) }\n     ret_val\n }\n \n@@ -210,7 +249,7 @@ pub enum ParseResult {\n pub fn parse_or_else(sess: &ParseSess,\n                      cfg: ast::CrateConfig,\n                      rdr: TtReader,\n-                     ms: Vec<Matcher> )\n+                     ms: Vec<TokenTree> )\n                      -> HashMap<Ident, Rc<NamedMatch>> {\n     match parse(sess, cfg, rdr, ms.as_slice()) {\n         Success(m) => m,\n@@ -237,12 +276,12 @@ pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n pub fn parse(sess: &ParseSess,\n              cfg: ast::CrateConfig,\n              mut rdr: TtReader,\n-             ms: &[Matcher])\n+             ms: &[TokenTree])\n              -> ParseResult {\n     let mut cur_eis = Vec::new();\n-    cur_eis.push(initial_matcher_pos(ms.iter()\n-                                       .map(|x| (*x).clone())\n-                                       .collect(),\n+    cur_eis.push(initial_matcher_pos(Rc::new(ms.iter()\n+                                                .map(|x| (*x).clone())\n+                                                .collect()),\n                                      None,\n                                      rdr.peek().sp.lo));\n \n@@ -255,13 +294,24 @@ pub fn parse(sess: &ParseSess,\n \n         /* we append new items to this while we go */\n         loop {\n-            let ei = match cur_eis.pop() {\n+            let mut ei = match cur_eis.pop() {\n                 None => break, /* for each Earley Item */\n                 Some(ei) => ei,\n             };\n \n+            // When unzipped trees end, remove them\n+            while ei.idx >= ei.top_elts.len() {\n+                match ei.stack.pop() {\n+                    Some(MatcherTtFrame { elts, idx }) => {\n+                        ei.top_elts = elts;\n+                        ei.idx = idx + 1;\n+                    }\n+                    None => break\n+                }\n+            }\n+\n             let idx = ei.idx;\n-            let len = ei.elts.len();\n+            let len = ei.top_elts.len();\n \n             /* at end of sequence */\n             if idx >= len {\n@@ -293,6 +343,7 @@ pub fn parse(sess: &ParseSess,\n                                                                        sp.hi))));\n                         }\n \n+                        new_pos.match_cur = ei.match_hi;\n                         new_pos.idx += 1;\n                         cur_eis.push(new_pos);\n                     }\n@@ -301,69 +352,86 @@ pub fn parse(sess: &ParseSess,\n \n                     // the *_t vars are workarounds for the lack of unary move\n                     match ei.sep {\n-                      Some(ref t) if idx == len => { // we need a separator\n-                        // i'm conflicted about whether this should be hygienic....\n-                        // though in this case, if the separators are never legal\n-                        // idents, it shouldn't matter.\n-                        if token_name_eq(&tok, t) { //pass the separator\n-                            let mut ei_t = ei.clone();\n-                            ei_t.idx += 1;\n-                            next_eis.push(ei_t);\n+                        Some(ref t) if idx == len => { // we need a separator\n+                            // i'm conflicted about whether this should be hygienic....\n+                            // though in this case, if the separators are never legal\n+                            // idents, it shouldn't matter.\n+                            if token_name_eq(&tok, t) { //pass the separator\n+                                let mut ei_t = ei.clone();\n+                                // ei_t.match_cur = ei_t.match_lo;\n+                                ei_t.idx += 1;\n+                                next_eis.push(ei_t);\n+                            }\n+                        }\n+                        _ => { // we don't need a separator\n+                            let mut ei_t = ei;\n+                            ei_t.match_cur = ei_t.match_lo;\n+                            ei_t.idx = 0;\n+                            cur_eis.push(ei_t);\n                         }\n-                      }\n-                      _ => { // we don't need a separator\n-                        let mut ei_t = ei;\n-                        ei_t.idx = 0;\n-                        cur_eis.push(ei_t);\n-                      }\n                     }\n                 } else {\n                     eof_eis.push(ei);\n                 }\n             } else {\n-                match ei.elts[idx].node.clone() {\n-                  /* need to descend into sequence */\n-                  MatchSeq(ref matchers, ref sep, kleene_op,\n-                           match_idx_lo, match_idx_hi) => {\n-                    if kleene_op == ast::ZeroOrMore {\n-                        let mut new_ei = ei.clone();\n-                        new_ei.idx += 1u;\n-                        //we specifically matched zero repeats.\n-                        for idx in range(match_idx_lo, match_idx_hi) {\n-                            new_ei.matches[idx]\n-                                  .push(Rc::new(MatchedSeq(Vec::new(), sp)));\n+                match ei.top_elts.get_tt(idx) {\n+                    /* need to descend into sequence */\n+                    TtSequence(sp, seq) => {\n+                        if seq.op == ast::ZeroOrMore {\n+                            let mut new_ei = ei.clone();\n+                            new_ei.match_cur += seq.num_captures;\n+                            new_ei.idx += 1u;\n+                            //we specifically matched zero repeats.\n+                            for idx in range(ei.match_cur, ei.match_cur + seq.num_captures) {\n+                                new_ei.matches[idx].push(Rc::new(MatchedSeq(Vec::new(), sp)));\n+                            }\n+\n+                            cur_eis.push(new_ei);\n                         }\n \n-                        cur_eis.push(new_ei);\n+                        let matches = Vec::from_elem(ei.matches.len(), Vec::new());\n+                        let ei_t = ei;\n+                        cur_eis.push(box MatcherPos {\n+                            stack: vec![],\n+                            sep: seq.separator.clone(),\n+                            idx: 0u,\n+                            matches: matches,\n+                            match_lo: ei_t.match_cur,\n+                            match_cur: ei_t.match_cur,\n+                            match_hi: ei_t.match_cur + seq.num_captures,\n+                            up: Some(ei_t),\n+                            sp_lo: sp.lo,\n+                            top_elts: Tt(TtSequence(sp, seq)),\n+                        });\n                     }\n-\n-                    let matches = Vec::from_elem(ei.matches.len(), Vec::new());\n-                    let ei_t = ei;\n-                    cur_eis.push(box MatcherPos {\n-                        elts: (*matchers).clone(),\n-                        sep: (*sep).clone(),\n-                        idx: 0u,\n-                        up: Some(ei_t),\n-                        matches: matches,\n-                        match_lo: match_idx_lo, match_hi: match_idx_hi,\n-                        sp_lo: sp.lo\n-                    });\n-                  }\n-                  MatchNonterminal(_,_,_) => {\n-                    // Built-in nonterminals never start with these tokens,\n-                    // so we can eliminate them from consideration.\n-                    match tok {\n-                        token::CloseDelim(_) => {},\n-                        _ => bb_eis.push(ei),\n+                    TtToken(_, MatchNt(..)) => {\n+                        // Built-in nonterminals never start with these tokens,\n+                        // so we can eliminate them from consideration.\n+                        match tok {\n+                            token::CloseDelim(_) => {},\n+                            _ => bb_eis.push(ei),\n+                        }\n                     }\n-                  }\n-                  MatchTok(ref t) => {\n-                    let mut ei_t = ei.clone();\n-                    if token_name_eq(t,&tok) {\n-                        ei_t.idx += 1;\n-                        next_eis.push(ei_t);\n+                    TtToken(sp, SubstNt(..)) => {\n+                        return Error(sp, \"Cannot transcribe in macro LHS\".into_string())\n+                    }\n+                    seq @ TtDelimited(..) | seq @ TtToken(_, DocComment(..)) => {\n+                        let lower_elts = mem::replace(&mut ei.top_elts, Tt(seq));\n+                        let idx = ei.idx;\n+                        ei.stack.push(MatcherTtFrame {\n+                            elts: lower_elts,\n+                            idx: idx,\n+                        });\n+                        ei.idx = 0;\n+                        cur_eis.push(ei);\n+                    }\n+                    TtToken(_, ref t) => {\n+                        let mut ei_t = ei.clone();\n+                        if token_name_eq(t,&tok) {\n+                            ei_t.idx += 1;\n+                            next_eis.push(ei_t);\n+                        }\n                     }\n-                  }\n                 }\n             }\n         }\n@@ -385,8 +453,8 @@ pub fn parse(sess: &ParseSess,\n             if (bb_eis.len() > 0u && next_eis.len() > 0u)\n                 || bb_eis.len() > 1u {\n                 let nts = bb_eis.iter().map(|ei| {\n-                    match ei.elts[ei.idx].node {\n-                      MatchNonterminal(bind, name, _) => {\n+                    match ei.top_elts.get_tt(ei.idx) {\n+                      TtToken(_, MatchNt(bind, name, _, _)) => {\n                         (format!(\"{} ('{}')\",\n                                 token::get_ident(name),\n                                 token::get_ident(bind))).to_string()\n@@ -410,12 +478,14 @@ pub fn parse(sess: &ParseSess,\n                 let mut rust_parser = Parser::new(sess, cfg.clone(), box rdr.clone());\n \n                 let mut ei = bb_eis.pop().unwrap();\n-                match ei.elts[ei.idx].node {\n-                  MatchNonterminal(_, name, idx) => {\n+                match ei.top_elts.get_tt(ei.idx) {\n+                  TtToken(_, MatchNt(_, name, _, _)) => {\n                     let name_string = token::get_ident(name);\n-                    ei.matches[idx].push(Rc::new(MatchedNonterminal(\n+                    let match_cur = ei.match_cur;\n+                    ei.matches[match_cur].push(Rc::new(MatchedNonterminal(\n                         parse_nt(&mut rust_parser, name_string.get()))));\n                     ei.idx += 1u;\n+                    ei.match_cur += 1;\n                   }\n                   _ => panic!()\n                 }\n@@ -461,7 +531,6 @@ pub fn parse_nt(p: &mut Parser, name: &str) -> Nonterminal {\n         p.quote_depth -= 1u;\n         res\n       }\n-      \"matchers\" => token::NtMatchers(p.parse_matchers()),\n       _ => {\n           p.fatal(format!(\"unsupported builtin nonterminal parser: {}\",\n                           name).as_slice())"}, {"sha": "92c68b7a9c7247d0a04cd4128b4b084cb7a56aee", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 41, "deletions": 25, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -8,9 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TtDelimited};\n+use ast::{Ident, TtDelimited, TtSequence, TtToken};\n use ast;\n-use codemap::{Span, Spanned, DUMMY_SP};\n+use codemap::{Span, DUMMY_SP};\n use ext::base::{ExtCtxt, MacResult, MacroDef};\n use ext::base::{NormalTT, TTMacroExpander};\n use ext::tt::macro_parser::{Success, Error, Failure};\n@@ -20,7 +20,7 @@ use parse::lexer::new_tt_reader;\n use parse::parser::Parser;\n use parse::attr::ParserAttr;\n use parse::token::{special_idents, gensym_ident};\n-use parse::token::{NtMatchers, NtTT};\n+use parse::token::{MatchNt, NtTT};\n use parse::token;\n use print;\n use ptr::P;\n@@ -158,14 +158,19 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n \n     for (i, lhs) in lhses.iter().enumerate() { // try each arm's matchers\n         match **lhs {\n-          MatchedNonterminal(NtMatchers(ref mtcs)) => {\n+          MatchedNonterminal(NtTT(ref lhs_tt)) => {\n+            let lhs_tt = match **lhs_tt {\n+                TtDelimited(_, ref delim) => delim.tts.as_slice(),\n+                _ => cx.span_fatal(sp, \"malformed macro lhs\")\n+            };\n             // `None` is because we're not interpolating\n-            let arg_rdr = new_tt_reader(&cx.parse_sess().span_diagnostic,\n-                                        None,\n-                                        arg.iter()\n-                                           .map(|x| (*x).clone())\n-                                           .collect());\n-            match parse(cx.parse_sess(), cx.cfg(), arg_rdr, mtcs.as_slice()) {\n+            let mut arg_rdr = new_tt_reader(&cx.parse_sess().span_diagnostic,\n+                                            None,\n+                                            arg.iter()\n+                                               .map(|x| (*x).clone())\n+                                               .collect());\n+            arg_rdr.desugar_doc_comments = true;\n+            match parse(cx.parse_sess(), cx.cfg(), arg_rdr, lhs_tt) {\n               Success(named_matches) => {\n                 let rhs = match *rhses[i] {\n                     // okay, what's your transcriber?\n@@ -202,6 +207,11 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n     cx.span_fatal(best_fail_spot, best_fail_msg.as_slice());\n }\n \n+// Note that macro-by-example's input is also matched against a token tree:\n+//                   $( $lhs:tt => $rhs:tt );+\n+//\n+// Holy self-referential!\n+\n /// This procedure performs the expansion of the\n /// macro_rules! macro. It parses the RHS and adds\n /// an extension to the current context.\n@@ -210,31 +220,37 @@ pub fn add_new_extension<'cx>(cx: &'cx mut ExtCtxt,\n                               name: Ident,\n                               arg: Vec<ast::TokenTree> )\n                               -> Box<MacResult+'cx> {\n-    // these spans won't matter, anyways\n-    fn ms(m: Matcher_) -> Matcher {\n-        Spanned {\n-            node: m.clone(),\n-            span: DUMMY_SP\n-        }\n-    }\n \n     let lhs_nm =  gensym_ident(\"lhs\");\n     let rhs_nm =  gensym_ident(\"rhs\");\n \n     // The pattern that macro_rules matches.\n     // The grammar for macro_rules! is:\n-    // $( $lhs:mtcs => $rhs:tt );+\n+    // $( $lhs:tt => $rhs:tt );+\n     // ...quasiquoting this would be nice.\n+    // These spans won't matter, anyways\n+    let match_lhs_tok = MatchNt(lhs_nm, special_idents::tt, token::Plain, token::Plain);\n+    let match_rhs_tok = MatchNt(rhs_nm, special_idents::tt, token::Plain, token::Plain);\n     let argument_gram = vec!(\n-        ms(MatchSeq(vec!(\n-            ms(MatchNonterminal(lhs_nm, special_idents::matchers, 0u)),\n-            ms(MatchTok(token::FatArrow)),\n-            ms(MatchNonterminal(rhs_nm, special_idents::tt, 1u))),\n-                                Some(token::Semi), ast::OneOrMore, 0u, 2u)),\n+        TtSequence(DUMMY_SP,\n+                   Rc::new(ast::SequenceRepetition {\n+                       tts: vec![\n+                           TtToken(DUMMY_SP, match_lhs_tok),\n+                           TtToken(DUMMY_SP, token::FatArrow),\n+                           TtToken(DUMMY_SP, match_rhs_tok)],\n+                       separator: Some(token::Semi),\n+                       op: ast::OneOrMore,\n+                       num_captures: 2\n+                   })),\n         //to phase into semicolon-termination instead of\n         //semicolon-separation\n-        ms(MatchSeq(vec!(ms(MatchTok(token::Semi))), None,\n-                            ast::ZeroOrMore, 2u, 2u)));\n+        TtSequence(DUMMY_SP,\n+                   Rc::new(ast::SequenceRepetition {\n+                       tts: vec![TtToken(DUMMY_SP, token::Semi)],\n+                       separator: None,\n+                       op: ast::ZeroOrMore,\n+                       num_captures: 0\n+                   })));\n \n \n     // Parse the macro_rules! invocation (`none` is for no interpolations):"}, {"sha": "5842afe11ce2ccf67cfdef4c1f9ad5cf34bc3091", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 94, "deletions": 71, "changes": 165, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -9,10 +9,11 @@\n // except according to those terms.\n \n use ast;\n-use ast::{TokenTree, TtDelimited, TtToken, TtSequence, TtNonterminal, Ident};\n+use ast::{TokenTree, TtDelimited, TtToken, TtSequence, Ident};\n use codemap::{Span, DUMMY_SP};\n use diagnostic::SpanHandler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n+use parse::token::{Eof, DocComment, Interpolated, MatchNt, SubstNt};\n use parse::token::{Token, NtIdent};\n use parse::token;\n use parse::lexer::TokenAndSpan;\n@@ -24,7 +25,7 @@ use std::collections::HashMap;\n ///an unzipping of `TokenTree`s\n #[deriving(Clone)]\n struct TtFrame {\n-    forest: Rc<Vec<ast::TokenTree>>,\n+    forest: TokenTree,\n     idx: uint,\n     dotdotdoted: bool,\n     sep: Option<Token>,\n@@ -42,6 +43,8 @@ pub struct TtReader<'a> {\n     /* cached: */\n     pub cur_tok: Token,\n     pub cur_span: Span,\n+    /// Transform doc comments. Only useful in macro invocations\n+    pub desugar_doc_comments: bool,\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n@@ -54,7 +57,11 @@ pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n         stack: vec!(TtFrame {\n-            forest: Rc::new(src),\n+            forest: TtSequence(DUMMY_SP, Rc::new(ast::SequenceRepetition {\n+                tts: src,\n+                // doesn't matter. This merely holds the root unzipping.\n+                separator: None, op: ast::ZeroOrMore, num_captures: 0\n+            })),\n             idx: 0,\n             dotdotdoted: false,\n             sep: None,\n@@ -65,6 +72,7 @@ pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n         },\n         repeat_idx: Vec::new(),\n         repeat_len: Vec::new(),\n+        desugar_doc_comments: false,\n         /* dummy values, never read: */\n         cur_tok: token::Eof,\n         cur_span: DUMMY_SP,\n@@ -85,17 +93,9 @@ fn lookup_cur_matched_by_matched(r: &TtReader, start: Rc<NamedMatch>) -> Rc<Name\n     })\n }\n \n-fn lookup_cur_matched(r: &TtReader, name: Ident) -> Rc<NamedMatch> {\n+fn lookup_cur_matched(r: &TtReader, name: Ident) -> Option<Rc<NamedMatch>> {\n     let matched_opt = r.interpolations.find_copy(&name);\n-    match matched_opt {\n-        Some(s) => lookup_cur_matched_by_matched(r, s),\n-        None => {\n-            r.sp_diag\n-             .span_fatal(r.cur_span,\n-                         format!(\"unknown macro variable `{}`\",\n-                                 token::get_ident(name)).as_slice());\n-        }\n-    }\n+    matched_opt.map(|s| lookup_cur_matched_by_matched(r, s))\n }\n \n #[deriving(Clone)]\n@@ -133,16 +133,20 @@ fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n-        TtSequence(_, ref tts, _, _) => {\n-            tts.iter().fold(LisUnconstrained, |size, tt| {\n+        TtSequence(_, ref seq) => {\n+            seq.tts.iter().fold(LisUnconstrained, |size, tt| {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n+        TtToken(_, SubstNt(name, _)) | TtToken(_, MatchNt(name, _, _, _)) =>\n+            match lookup_cur_matched(r, name) {\n+                Some(matched) => match *matched {\n+                    MatchedNonterminal(_) => LisUnconstrained,\n+                    MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name),\n+                },\n+                _ => LisUnconstrained\n+            },\n         TtToken(..) => LisUnconstrained,\n-        TtNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n-            MatchedNonterminal(_) => LisUnconstrained,\n-            MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name)\n-        },\n     }\n }\n \n@@ -202,46 +206,27 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n         let t = {\n             let frame = r.stack.last().unwrap();\n             // FIXME(pcwalton): Bad copy.\n-            (*frame.forest)[frame.idx].clone()\n+            frame.forest.get_tt(frame.idx)\n         };\n         match t {\n-            TtDelimited(_, ref delimed) => {\n-                let mut tts = Vec::with_capacity(1 + delimed.tts.len() + 1);\n-                tts.push(delimed.open_tt());\n-                tts.extend(delimed.tts.iter().map(|tt| tt.clone()));\n-                tts.push(delimed.close_tt());\n-\n-                r.stack.push(TtFrame {\n-                    forest: Rc::new(tts),\n-                    idx: 0,\n-                    dotdotdoted: false,\n-                    sep: None\n-                });\n-                // if this could be 0-length, we'd need to potentially recur here\n-            }\n-            TtToken(sp, tok) => {\n-                r.cur_span = sp;\n-                r.cur_tok = tok;\n-                r.stack.last_mut().unwrap().idx += 1;\n-                return ret_val;\n-            }\n-            TtSequence(sp, tts, sep, kleene_op) => {\n+            TtSequence(sp, seq) => {\n                 // FIXME(pcwalton): Bad copy.\n-                match lockstep_iter_size(&TtSequence(sp, tts.clone(), sep.clone(), kleene_op), r) {\n+                match lockstep_iter_size(&TtSequence(sp, seq.clone()),\n+                                         r) {\n                     LisUnconstrained => {\n                         r.sp_diag.span_fatal(\n                             sp.clone(), /* blame macro writer */\n                             \"attempted to repeat an expression \\\n                              containing no syntax \\\n                              variables matched as repeating at this depth\");\n-                        }\n-                        LisContradiction(ref msg) => {\n-                            // FIXME #2887 blame macro invoker instead\n-                            r.sp_diag.span_fatal(sp.clone(), msg.as_slice());\n-                        }\n+                    }\n+                    LisContradiction(ref msg) => {\n+                        // FIXME #2887 blame macro invoker instead\n+                        r.sp_diag.span_fatal(sp.clone(), msg.as_slice());\n+                    }\n                     LisConstraint(len, _) => {\n                         if len == 0 {\n-                            if kleene_op == ast::OneOrMore {\n+                            if seq.op == ast::OneOrMore {\n                                 // FIXME #2887 blame invoker\n                                 r.sp_diag.span_fatal(sp.clone(),\n                                                      \"this must repeat at least once\");\n@@ -253,40 +238,78 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                         r.repeat_len.push(len);\n                         r.repeat_idx.push(0);\n                         r.stack.push(TtFrame {\n-                            forest: tts,\n                             idx: 0,\n                             dotdotdoted: true,\n-                            sep: sep.clone()\n+                            sep: seq.separator.clone(),\n+                            forest: TtSequence(sp, seq),\n                         });\n                     }\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n-            TtNonterminal(sp, ident) => {\n-                r.stack.last_mut().unwrap().idx += 1;\n-                match *lookup_cur_matched(r, ident) {\n-                    /* sidestep the interpolation tricks for ident because\n-                       (a) idents can be in lots of places, so it'd be a pain\n-                       (b) we actually can, since it's a token. */\n-                    MatchedNonterminal(NtIdent(box sn, b)) => {\n-                        r.cur_span = sp;\n-                        r.cur_tok = token::Ident(sn,b);\n-                        return ret_val;\n-                    }\n-                    MatchedNonterminal(ref other_whole_nt) => {\n-                        // FIXME(pcwalton): Bad copy.\n-                        r.cur_span = sp;\n-                        r.cur_tok = token::Interpolated((*other_whole_nt).clone());\n-                        return ret_val;\n+            TtToken(sp, SubstNt(ident, namep)) => {\n+                match lookup_cur_matched(r, ident) {\n+                    None => {\n+                        r.stack.push(TtFrame {\n+                            forest: TtToken(sp, SubstNt(ident, namep)),\n+                            idx: 0,\n+                            dotdotdoted: false,\n+                            sep: None\n+                        });\n+                        // this can't be 0 length, just like TtDelimited\n                     }\n-                    MatchedSeq(..) => {\n-                        r.sp_diag.span_fatal(\n-                            r.cur_span, /* blame the macro writer */\n-                            format!(\"variable '{}' is still repeating at this depth\",\n-                                    token::get_ident(ident)).as_slice());\n+                    Some(cur_matched) => {\n+                        r.stack.last_mut().unwrap().idx += 1;\n+                        match *cur_matched {\n+                            // sidestep the interpolation tricks for ident because\n+                            // (a) idents can be in lots of places, so it'd be a pain\n+                            // (b) we actually can, since it's a token.\n+                            MatchedNonterminal(NtIdent(box sn, b)) => {\n+                                r.cur_span = sp;\n+                                r.cur_tok = token::Ident(sn, b);\n+                                return ret_val;\n+                            }\n+                            MatchedNonterminal(ref other_whole_nt) => {\n+                                // FIXME(pcwalton): Bad copy.\n+                                r.cur_span = sp;\n+                                r.cur_tok = token::Interpolated((*other_whole_nt).clone());\n+                                return ret_val;\n+                            }\n+                            MatchedSeq(..) => {\n+                                r.sp_diag.span_fatal(\n+                                    r.cur_span, /* blame the macro writer */\n+                                    format!(\"variable '{}' is still repeating at this depth\",\n+                                            token::get_ident(ident)).as_slice());\n+                            }\n+                        }\n                     }\n                 }\n             }\n+            // TtDelimited or any token that can be unzipped\n+            seq @ TtDelimited(..) | seq @ TtToken(_, MatchNt(..)) => {\n+                // do not advance the idx yet\n+                r.stack.push(TtFrame {\n+                   forest: seq,\n+                   idx: 0,\n+                   dotdotdoted: false,\n+                   sep: None\n+                });\n+                // if this could be 0-length, we'd need to potentially recur here\n+            }\n+            TtToken(sp, DocComment(name)) if r.desugar_doc_comments => {\n+                r.stack.push(TtFrame {\n+                   forest: TtToken(sp, DocComment(name)),\n+                   idx: 0,\n+                   dotdotdoted: false,\n+                   sep: None\n+                });\n+            }\n+            TtToken(sp, tok) => {\n+                r.cur_span = sp;\n+                r.cur_tok = tok;\n+                r.stack.last_mut().unwrap().idx += 1;\n+                return ret_val;\n+            }\n         }\n     }\n }"}, {"sha": "2074a6bfab9820cfb05298402837301b8ed77d6c", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 12, "deletions": 8, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -619,13 +619,13 @@ pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n                             }\n                         ))\n         },\n-        TtSequence(span, ref pattern, ref sep, is_optional) =>\n+        TtSequence(span, ref seq) =>\n             TtSequence(span,\n-                       Rc::new(fld.fold_tts(pattern.as_slice())),\n-                       sep.clone().map(|tok| fld.fold_token(tok)),\n-                       is_optional),\n-        TtNonterminal(sp,ref ident) =>\n-            TtNonterminal(sp,fld.fold_ident(*ident))\n+                       Rc::new(SequenceRepetition {\n+                           tts: fld.fold_tts(seq.tts.as_slice()),\n+                           separator: seq.separator.clone().map(|tok| fld.fold_token(tok)),\n+                           ..**seq\n+                       })),\n     }\n }\n \n@@ -641,6 +641,12 @@ pub fn noop_fold_token<T: Folder>(t: token::Token, fld: &mut T) -> token::Token\n         }\n         token::Lifetime(id) => token::Lifetime(fld.fold_ident(id)),\n         token::Interpolated(nt) => token::Interpolated(fld.fold_interpolated(nt)),\n+        token::SubstNt(ident, namep) => {\n+            token::SubstNt(fld.fold_ident(ident), namep)\n+        }\n+        token::MatchNt(name, kind, namep, kindp) => {\n+            token::MatchNt(fld.fold_ident(name), fld.fold_ident(kind), namep, kindp)\n+        }\n         _ => t\n     }\n }\n@@ -689,8 +695,6 @@ pub fn noop_fold_interpolated<T: Folder>(nt: token::Nonterminal, fld: &mut T)\n         token::NtMeta(meta_item) => token::NtMeta(fld.fold_meta_item(meta_item)),\n         token::NtPath(box path) => token::NtPath(box fld.fold_path(path)),\n         token::NtTT(tt) => token::NtTT(P(fld.fold_tt(&*tt))),\n-        // it looks to me like we can leave out the matchers: token::NtMatchers(matchers)\n-        _ => nt\n     }\n }\n "}, {"sha": "9ba11d63da54f4f42aa82be676cec150f3ce8d50", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 28, "deletions": 68, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -37,8 +37,8 @@ use ast::{ItemMac, ItemMod, ItemStruct, ItemTrait, ItemTy};\n use ast::{LifetimeDef, Lit, Lit_};\n use ast::{LitBool, LitChar, LitByte, LitBinary};\n use ast::{LitNil, LitStr, LitInt, Local, LocalLet};\n-use ast::{MutImmutable, MutMutable, Mac_, MacInvocTT, Matcher, MatchNonterminal, MatchNormal};\n-use ast::{MatchSeq, MatchTok, Method, MutTy, BiMul, Mutability};\n+use ast::{MutImmutable, MutMutable, Mac_, MacInvocTT, MatchNormal};\n+use ast::{Method, MutTy, BiMul, Mutability};\n use ast::{MethodImplItem, NamedField, UnNeg, NoReturn, UnNot};\n use ast::{Pat, PatEnum, PatIdent, PatLit, PatRange, PatRegion, PatStruct};\n use ast::{PatTup, PatBox, PatWild, PatWildMulti, PatWildSingle};\n@@ -48,8 +48,9 @@ use ast::{StmtExpr, StmtSemi, StmtMac, StructDef, StructField};\n use ast::{StructVariantKind, BiSub};\n use ast::StrStyle;\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n-use ast::{Delimited, TokenTree, TraitItem, TraitRef, TtDelimited, TtSequence, TtToken};\n-use ast::{TtNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n+use ast::{Delimited, SequenceRepetition, TokenTree, TraitItem, TraitRef};\n+use ast::{TtDelimited, TtSequence, TtToken};\n+use ast::{TupleVariantKind, Ty, Ty_, TyBot};\n use ast::{TypeField, TyFixedLengthVec, TyClosure, TyProc, TyBareFn};\n use ast::{TyTypeof, TyInfer, TypeMethod};\n use ast::{TyNil, TyParam, TyParamBound, TyParen, TyPath, TyPtr, TyQPath};\n@@ -64,6 +65,7 @@ use ast_util::{as_prec, ident_to_path, operator_prec};\n use ast_util;\n use codemap::{Span, BytePos, Spanned, spanned, mk_sp};\n use codemap;\n+use ext::tt::macro_parser;\n use parse;\n use parse::attr::ParserAttr;\n use parse::classify;\n@@ -72,7 +74,7 @@ use parse::common::{seq_sep_trailing_allowed};\n use parse::lexer::Reader;\n use parse::lexer::TokenAndSpan;\n use parse::obsolete::*;\n-use parse::token::InternedString;\n+use parse::token::{MatchNt, SubstNt, InternedString};\n use parse::token::{keywords, special_idents};\n use parse::token;\n use parse::{new_sub_parser_from_file, ParseSess};\n@@ -2579,7 +2581,7 @@ impl<'a> Parser<'a> {\n     pub fn parse_token_tree(&mut self) -> TokenTree {\n         // FIXME #6994: currently, this is too eager. It\n         // parses token trees but also identifies TtSequence's\n-        // and TtNonterminal's; it's too early to know yet\n+        // and token::SubstNt's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n         maybe_whole!(deref self, NtTT);\n@@ -2620,9 +2622,27 @@ impl<'a> Parser<'a> {\n                     let seq = match seq {\n                         Spanned { node, .. } => node,\n                     };\n-                    TtSequence(mk_sp(sp.lo, p.span.hi), Rc::new(seq), sep, repeat)\n+                    let name_num = macro_parser::count_names(seq.as_slice());\n+                    TtSequence(mk_sp(sp.lo, p.span.hi),\n+                               Rc::new(SequenceRepetition {\n+                                   tts: seq,\n+                                   separator: sep,\n+                                   op: repeat,\n+                                   num_captures: name_num\n+                               }))\n                 } else {\n-                    TtNonterminal(sp, p.parse_ident())\n+                    // A nonterminal that matches or not\n+                    let namep = match p.token { token::Ident(_, p) => p, _ => token::Plain };\n+                    let name = p.parse_ident();\n+                    if p.token == token::Colon && p.look_ahead(1, |t| t.is_ident()) {\n+                        p.bump();\n+                        let kindp = match p.token { token::Ident(_, p) => p, _ => token::Plain };\n+                        let nt_kind = p.parse_ident();\n+                        let m = TtToken(sp, MatchNt(name, nt_kind, namep, kindp));\n+                        m\n+                    } else {\n+                        TtToken(sp, SubstNt(name, namep))\n+                    }\n                 }\n               }\n               _ => {\n@@ -2686,66 +2706,6 @@ impl<'a> Parser<'a> {\n         tts\n     }\n \n-    pub fn parse_matchers(&mut self) -> Vec<Matcher> {\n-        // unification of Matcher's and TokenTree's would vastly improve\n-        // the interpolation of Matcher's\n-        maybe_whole!(self, NtMatchers);\n-        let mut name_idx = 0u;\n-        let delim = self.expect_open_delim();\n-        self.parse_matcher_subseq_upto(&mut name_idx, &token::CloseDelim(delim))\n-    }\n-\n-    /// This goofy function is necessary to correctly match parens in Matcher's.\n-    /// Otherwise, `$( ( )` would be a valid Matcher, and `$( () )` would be\n-    /// invalid. It's similar to common::parse_seq.\n-    pub fn parse_matcher_subseq_upto(&mut self,\n-                                     name_idx: &mut uint,\n-                                     ket: &token::Token)\n-                                     -> Vec<Matcher> {\n-        let mut ret_val = Vec::new();\n-        let mut lparens = 0u;\n-\n-        while self.token != *ket || lparens > 0u {\n-            if self.token == token::OpenDelim(token::Paren) { lparens += 1u; }\n-            if self.token == token::CloseDelim(token::Paren) { lparens -= 1u; }\n-            ret_val.push(self.parse_matcher(name_idx));\n-        }\n-\n-        self.bump();\n-\n-        return ret_val;\n-    }\n-\n-    pub fn parse_matcher(&mut self, name_idx: &mut uint) -> Matcher {\n-        let lo = self.span.lo;\n-\n-        let m = if self.token == token::Dollar {\n-            self.bump();\n-            if self.token == token::OpenDelim(token::Paren) {\n-                let name_idx_lo = *name_idx;\n-                self.bump();\n-                let ms = self.parse_matcher_subseq_upto(name_idx,\n-                                                        &token::CloseDelim(token::Paren));\n-                if ms.len() == 0u {\n-                    self.fatal(\"repetition body must be nonempty\");\n-                }\n-                let (sep, kleene_op) = self.parse_sep_and_kleene_op();\n-                MatchSeq(ms, sep, kleene_op, name_idx_lo, *name_idx)\n-            } else {\n-                let bound_to = self.parse_ident();\n-                self.expect(&token::Colon);\n-                let nt_name = self.parse_ident();\n-                let m = MatchNonterminal(bound_to, nt_name, *name_idx);\n-                *name_idx += 1;\n-                m\n-            }\n-        } else {\n-            MatchTok(self.bump_and_get())\n-        };\n-\n-        return spanned(lo, self.span.hi, m);\n-    }\n-\n     /// Parse a prefix-operator expr\n     pub fn parse_prefix_expr(&mut self) -> P<Expr> {\n         let lo = self.span.lo;"}, {"sha": "b0cca5e14de15448bcf603e4be57c97bbafd8b40", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -108,7 +108,15 @@ pub enum Token {\n \n     /* For interpolation */\n     Interpolated(Nonterminal),\n+    // Can be expanded into several tokens.\n+    /// Doc comment\n     DocComment(ast::Name),\n+    // In left-hand-sides of MBE macros:\n+    /// Parse a nonterminal (name to bind, name of NT, styles of their idents)\n+    MatchNt(ast::Ident, ast::Ident, IdentStyle, IdentStyle),\n+    // In right-hand-sides of MBE macros:\n+    /// A syntactic variable that will be filled in by macro expansion.\n+    SubstNt(ast::Ident, IdentStyle),\n \n     // Junk. These carry no data because we don't really care about the data\n     // they *would* carry, and don't really want to allocate a new ident for\n@@ -329,7 +337,6 @@ pub enum Nonterminal {\n     NtMeta(P<ast::MetaItem>),\n     NtPath(Box<ast::Path>),\n     NtTT(P<ast::TokenTree>), // needs P'ed to break a circularity\n-    NtMatchers(Vec<ast::Matcher>)\n }\n \n impl fmt::Show for Nonterminal {\n@@ -345,7 +352,6 @@ impl fmt::Show for Nonterminal {\n             NtMeta(..) => f.pad(\"NtMeta(..)\"),\n             NtPath(..) => f.pad(\"NtPath(..)\"),\n             NtTT(..) => f.pad(\"NtTT(..)\"),\n-            NtMatchers(..) => f.pad(\"NtMatchers(..)\"),\n         }\n     }\n }"}, {"sha": "63e2c5499e8f167a4807d341fb494adc5361aa50", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 13, "deletions": 16, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -254,6 +254,8 @@ pub fn token_to_string(tok: &Token) -> String {\n \n         /* Other */\n         token::DocComment(s)        => s.as_str().into_string(),\n+        token::SubstNt(s, _)        => format!(\"${}\", s),\n+        token::MatchNt(s, t, _, _)  => format!(\"${}:{}\", s, t),\n         token::Eof                  => \"<eof>\".into_string(),\n         token::Whitespace           => \" \".into_string(),\n         token::Comment              => \"/* */\".into_string(),\n@@ -270,7 +272,6 @@ pub fn token_to_string(tok: &Token) -> String {\n             token::NtPat(..)      => \"an interpolated pattern\".into_string(),\n             token::NtIdent(..)    => \"an interpolated identifier\".into_string(),\n             token::NtTT(..)       => \"an interpolated tt\".into_string(),\n-            token::NtMatchers(..) => \"an interpolated matcher sequence\".into_string(),\n         }\n     }\n }\n@@ -1105,13 +1106,6 @@ impl<'a> State<'a> {\n     /// expression arguments as expressions). It can be done! I think.\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> IoResult<()> {\n         match *tt {\n-            ast::TtDelimited(_, ref delimed) => {\n-                try!(word(&mut self.s, token_to_string(&delimed.open_token()).as_slice()));\n-                try!(space(&mut self.s));\n-                try!(self.print_tts(delimed.tts.as_slice()));\n-                try!(space(&mut self.s));\n-                word(&mut self.s, token_to_string(&delimed.close_token()).as_slice())\n-            },\n             ast::TtToken(_, ref tk) => {\n                 try!(word(&mut self.s, token_to_string(tk).as_slice()));\n                 match *tk {\n@@ -1121,27 +1115,30 @@ impl<'a> State<'a> {\n                     _ => Ok(())\n                 }\n             }\n-            ast::TtSequence(_, ref tts, ref separator, kleene_op) => {\n+            ast::TtDelimited(_, ref delimed) => {\n+                try!(word(&mut self.s, token_to_string(&delimed.open_token()).as_slice()));\n+                try!(space(&mut self.s));\n+                try!(self.print_tts(delimed.tts.as_slice()));\n+                try!(space(&mut self.s));\n+                word(&mut self.s, token_to_string(&delimed.close_token()).as_slice())\n+            },\n+            ast::TtSequence(_, ref seq) => {\n                 try!(word(&mut self.s, \"$(\"));\n-                for tt_elt in (*tts).iter() {\n+                for tt_elt in seq.tts.iter() {\n                     try!(self.print_tt(tt_elt));\n                 }\n                 try!(word(&mut self.s, \")\"));\n-                match *separator {\n+                match seq.separator {\n                     Some(ref tk) => {\n                         try!(word(&mut self.s, token_to_string(tk).as_slice()));\n                     }\n                     None => {},\n                 }\n-                match kleene_op {\n+                match seq.op {\n                     ast::ZeroOrMore => word(&mut self.s, \"*\"),\n                     ast::OneOrMore => word(&mut self.s, \"+\"),\n                 }\n             }\n-            ast::TtNonterminal(_, name) => {\n-                try!(word(&mut self.s, \"$\"));\n-                self.print_ident(name)\n-            }\n         }\n     }\n "}, {"sha": "267b30677a18f13f7343880be19b9598f2d21ebc", "filename": "src/test/compile-fail/issue-6596.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Ftest%2Fcompile-fail%2Fissue-6596.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Ftest%2Fcompile-fail%2Fissue-6596.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-6596.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -10,7 +10,7 @@\n \n #![feature(macro_rules)]\n \n-// error-pattern: unknown macro variable `nonexistent`\n+// error-pattern: unexpected token\n \n macro_rules! e(\n     ($inp:ident) => ("}, {"sha": "d6d32d94a29568deb4a2b53356f26edb6e18340d", "filename": "src/test/compile-fail/macro-match-nonterminal.rs", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Ftest%2Fcompile-fail%2Fmacro-match-nonterminal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Ftest%2Fcompile-fail%2Fmacro-match-nonterminal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fmacro-match-nonterminal.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -0,0 +1,17 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![feature(macro_rules)]\n+\n+macro_rules! test ( ($a, $b) => (()); ) //~ ERROR Cannot transcribe\n+\n+fn main() {\n+    test!()\n+}"}, {"sha": "561933d75992765e7bb9d5a0ada87c08709424db", "filename": "src/test/run-pass/macro-of-higher-order.rs", "status": "renamed", "additions": 8, "deletions": 14, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Ftest%2Frun-pass%2Fmacro-of-higher-order.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b48001c28329392b26961eaf1c3ed293a352d6f/src%2Ftest%2Frun-pass%2Fmacro-of-higher-order.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fmacro-of-higher-order.rs?ref=0b48001c28329392b26961eaf1c3ed293a352d6f", "patch": "@@ -1,4 +1,4 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n // file at the top-level directory of this distribution and at\n // http://rust-lang.org/COPYRIGHT.\n //\n@@ -10,20 +10,14 @@\n \n #![feature(macro_rules)]\n \n-macro_rules! print_hd_tl (\n-    ($field_hd:ident, $($field_tl:ident),+) => ({\n-        print!(\"{}\", stringify!($field)); //~ ERROR unknown macro variable\n-        print!(\"::[\");\n-        $(\n-            print!(\"{}\", stringify!($field_tl));\n-            print!(\", \");\n-        )+\n-        // FIXME: #9970\n-        print!(\"{}\", \"]\\n\");\n-    })\n+macro_rules! higher_order (\n+    (subst $lhs:tt => $rhs:tt) => ({\n+            macro_rules! anon ( $lhs => $rhs )\n+            anon!(1u, 2u, \"foo\")\n+    });\n )\n \n fn main() {\n-    print_hd_tl!(x, y, z, w)\n+    let val = higher_order!(subst ($x:expr, $y:expr, $foo:expr) => (($x + $y, $foo)));\n+    assert_eq!(val, (3, \"foo\"));\n }\n-", "previous_filename": "src/test/compile-fail/issue-5060-fail.rs"}]}