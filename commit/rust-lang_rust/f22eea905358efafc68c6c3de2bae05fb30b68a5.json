{"sha": "f22eea905358efafc68c6c3de2bae05fb30b68a5", "node_id": "C_kwDOAAsO6NoAKGYyMmVlYTkwNTM1OGVmYWZjNjhjNmMzZGUyYmFlMDVmYjMwYjY4YTU", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-09-27T16:45:40Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-09-27T16:45:40Z"}, "message": "Merge #10372\n\n10372: minor: Cleanup descend_into_macros_impl r=Veykril a=Veykril\n\nbors r+\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>", "tree": {"sha": "794241353655c5de88e8a1d2330f142ea061a014", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/794241353655c5de88e8a1d2330f142ea061a014"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f22eea905358efafc68c6c3de2bae05fb30b68a5", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhUfU0CRBK7hj4Ov3rIwAAdeUIAKjQi5EbTYdu8mbnNo062WjC\n1nUwvtYv2SWtDV4RncGPF0x05Xw1Mp2pkayhcK0k0Nfvfxa4dfz4VxNZ4kuiggI5\nMz2gjbIZygCzzsxTWSEhapAx0RszOpWF/KteS7vMHW88fozoGK8vrSz4ClBwdUBJ\nKJq41MDmXHxW4UaZwrA+g7oQFmlaUDmNJ3ciyozMh7aSQGOXgeZ0yUbw4yq1mCB3\n50o/Bd/l1+/e1OVfhMaC/C/pcW4LQJAYUAwxGdanmSedqRSHwh2e2oEiWV6RU1QF\neqPZTHxM83DaDnLt8hgLNOYI/ZQDuqIA3Ae7tPfX6lAkDPGMWznuQIbVzjBRW3g=\n=m47y\n-----END PGP SIGNATURE-----\n", "payload": "tree 794241353655c5de88e8a1d2330f142ea061a014\nparent ffcaceb80f230cffac51bd1e0d206c18f89a15e5\nparent 75660ff94fd54a921d411a75789a994111184257\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1632761140 +0000\ncommitter GitHub <noreply@github.com> 1632761140 +0000\n\nMerge #10372\n\n10372: minor: Cleanup descend_into_macros_impl r=Veykril a=Veykril\n\nbors r+\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f22eea905358efafc68c6c3de2bae05fb30b68a5", "html_url": "https://github.com/rust-lang/rust/commit/f22eea905358efafc68c6c3de2bae05fb30b68a5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f22eea905358efafc68c6c3de2bae05fb30b68a5/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ffcaceb80f230cffac51bd1e0d206c18f89a15e5", "url": "https://api.github.com/repos/rust-lang/rust/commits/ffcaceb80f230cffac51bd1e0d206c18f89a15e5", "html_url": "https://github.com/rust-lang/rust/commit/ffcaceb80f230cffac51bd1e0d206c18f89a15e5"}, {"sha": "75660ff94fd54a921d411a75789a994111184257", "url": "https://api.github.com/repos/rust-lang/rust/commits/75660ff94fd54a921d411a75789a994111184257", "html_url": "https://github.com/rust-lang/rust/commit/75660ff94fd54a921d411a75789a994111184257"}], "stats": {"total": 79, "additions": 43, "deletions": 36}, "files": [{"sha": "38c24d53db5fa3067f004bd4c5da079f1357bb24", "filename": "crates/hir/src/semantics.rs", "status": "modified", "additions": 43, "deletions": 36, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/f22eea905358efafc68c6c3de2bae05fb30b68a5/crates%2Fhir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f22eea905358efafc68c6c3de2bae05fb30b68a5/crates%2Fhir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Fsemantics.rs?ref=f22eea905358efafc68c6c3de2bae05fb30b68a5", "patch": "@@ -544,38 +544,54 @@ impl<'db> SemanticsImpl<'db> {\n         let sa = self.analyze(&parent);\n         let mut queue = vec![InFile::new(sa.file_id, token)];\n         let mut cache = self.expansion_info_cache.borrow_mut();\n+\n+        let mut process_expansion_for_token =\n+            |queue: &mut Vec<_>, file_id, item, token: InFile<&_>| {\n+                let mapped_tokens = cache\n+                    .entry(file_id)\n+                    .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                    .as_ref()?\n+                    .map_token_down(self.db.upcast(), item, token)?;\n+\n+                let len = queue.len();\n+                // requeue the tokens we got from mapping our current token down\n+                queue.extend(mapped_tokens.inspect(|token| {\n+                    if let Some(parent) = token.value.parent() {\n+                        self.cache(find_root(&parent), token.file_id);\n+                    }\n+                }));\n+                // if the length changed we have found a mapping for the token\n+                (queue.len() != len).then(|| ())\n+            };\n+\n         // Remap the next token in the queue into a macro call its in, if it is not being remapped\n         // either due to not being in a macro-call or because its unused push it into the result vec,\n         // otherwise push the remapped tokens back into the queue as they can potentially be remapped again.\n         while let Some(token) = queue.pop() {\n             self.db.unwind_if_cancelled();\n             let was_not_remapped = (|| {\n-                if let Some((call_id, item)) = token\n-                    .value\n-                    .ancestors()\n-                    .filter_map(ast::Item::cast)\n-                    .filter_map(|item| {\n-                        self.with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone())))\n-                            .zip(Some(item))\n-                    })\n-                    .last()\n-                {\n+                // are we inside an attribute macro call\n+                let containing_attribute_macro_call = self.with_ctx(|ctx| {\n+                    token\n+                        .value\n+                        .ancestors()\n+                        .filter_map(ast::Item::cast)\n+                        .filter_map(|item| {\n+                            Some((ctx.item_to_macro_call(token.with_value(item.clone()))?, item))\n+                        })\n+                        .last()\n+                });\n+                if let Some((call_id, item)) = containing_attribute_macro_call {\n                     let file_id = call_id.as_file();\n-                    let tokens = cache\n-                        .entry(file_id)\n-                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                        .as_ref()?\n-                        .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n-\n-                    let len = queue.len();\n-                    queue.extend(tokens.inspect(|token| {\n-                        if let Some(parent) = token.value.parent() {\n-                            self.cache(find_root(&parent), token.file_id);\n-                        }\n-                    }));\n-                    return (queue.len() != len).then(|| ());\n+                    return process_expansion_for_token(\n+                        &mut queue,\n+                        file_id,\n+                        Some(item),\n+                        token.as_ref(),\n+                    );\n                 }\n \n+                // or are we inside a function-like macro call\n                 if let Some(macro_call) = token.value.ancestors().find_map(ast::MacroCall::cast) {\n                     let tt = macro_call.token_tree()?;\n                     let l_delim = match tt.left_delimiter_token() {\n@@ -589,21 +605,12 @@ impl<'db> SemanticsImpl<'db> {\n                     if !TextRange::new(l_delim, r_delim).contains_range(token.value.text_range()) {\n                         return None;\n                     }\n+\n                     let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n-                    let tokens = cache\n-                        .entry(file_id)\n-                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                        .as_ref()?\n-                        .map_token_down(self.db.upcast(), None, token.as_ref())?;\n-\n-                    let len = queue.len();\n-                    queue.extend(tokens.inspect(|token| {\n-                        if let Some(parent) = token.value.parent() {\n-                            self.cache(find_root(&parent), token.file_id);\n-                        }\n-                    }));\n-                    return (queue.len() != len).then(|| ());\n+                    return process_expansion_for_token(&mut queue, file_id, None, token.as_ref());\n                 }\n+\n+                // outside of a macro invocation so this is a \"final\" token\n                 None\n             })()\n             .is_none();"}]}