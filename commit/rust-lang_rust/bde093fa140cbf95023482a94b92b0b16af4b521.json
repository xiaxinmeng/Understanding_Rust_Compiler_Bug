{"sha": "bde093fa140cbf95023482a94b92b0b16af4b521", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJkZTA5M2ZhMTQwY2JmOTUwMjM0ODJhOTRiOTJiMGIxNmFmNGI1MjE=", "commit": {"author": {"name": "Oliver Schneider", "email": "git-spam-no-reply9815368754983@oli-obk.de", "date": "2017-12-14T10:03:55Z"}, "committer": {"name": "Oliver Schneider", "email": "git-spam-no-reply9815368754983@oli-obk.de", "date": "2017-12-14T10:35:33Z"}, "message": "Move validation from rustc to miri", "tree": {"sha": "d596d82e5da18bc4779838c31165db45f3b2d0be", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d596d82e5da18bc4779838c31165db45f3b2d0be"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bde093fa140cbf95023482a94b92b0b16af4b521", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEYFTdM4NKd7XQft77pp+NIls619kFAloyU/cACgkQpp+NIls6\n19lXww//eNIpcJ1OAsHU3qP6cA2zcDJ6Qra1ywPITfHIqgTTkjdo8hU7Tk49ZkF/\nxI+p3tZDGnGD3L/U1UEN6tSKaVHsLDLD8/Ys06aWw3w3LQKEFg3rhGTz6zAzWMyj\neW30APf/L1Q8A9dao28RhiUyTPPSEic8xT2FURe8RKvRr4t9ic3WaDwoKzEACNoS\nH7SJoEbzXkEykygrQc7gqiscey/o37638yN0ciqgroCFBzXgvGHuNM4kn1GIY9t1\nfyZ2PIJf7MzsNdOaNNRIGZ3no8QOXUg2Rku+B7AGJqU8IT5U0vakMKlc6CYmZ5iT\n5/vjBcV9MuiSg7liKWuLALrMS7kGLL6owPtFNDjV+OiTSfEJ+lRs6EyKNdKXU1me\nZsqvfPBgd2DWoW1q2BKXD9rDsBlHZy9CfkgHBD1svYG9/krFVSJG9JZB8+Gz7/7X\nk0De64rP8ai9gyXbfkPjhy0CqHQhQUkqvHUL2jniUiotzwiMQRHiJH2M9EW3UX17\nXQv9mt2AmcvKvgmj04Qp5SoMyYs5W8HBUGkb2ubDTNxSO++f6li6NcBxluM8yI9B\nOisNZTW4Wrp5cEXOVCe97Lyp8XCpUSQ4Xf7IizMpJrNHxJlA2WH9Ii0I5h/ZXgU1\n4hlJ3xCywiAWIzR/kOxiu0Ms5N1W3p7m1FqwUWasTMCJQe9JZUE=\n=npAF\n-----END PGP SIGNATURE-----", "payload": "tree d596d82e5da18bc4779838c31165db45f3b2d0be\nparent eccf680b5d191bb39ef2fc5ae51bf3909c312bbe\nauthor Oliver Schneider <git-spam-no-reply9815368754983@oli-obk.de> 1513245835 +0100\ncommitter Oliver Schneider <git-spam-no-reply9815368754983@oli-obk.de> 1513247733 +0100\n\nMove validation from rustc to miri\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bde093fa140cbf95023482a94b92b0b16af4b521", "html_url": "https://github.com/rust-lang/rust/commit/bde093fa140cbf95023482a94b92b0b16af4b521", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bde093fa140cbf95023482a94b92b0b16af4b521/comments", "author": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "committer": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "eccf680b5d191bb39ef2fc5ae51bf3909c312bbe", "url": "https://api.github.com/repos/rust-lang/rust/commits/eccf680b5d191bb39ef2fc5ae51bf3909c312bbe", "html_url": "https://github.com/rust-lang/rust/commit/eccf680b5d191bb39ef2fc5ae51bf3909c312bbe"}], "stats": {"total": 1686, "additions": 1633, "deletions": 53}, "files": [{"sha": "79fad037385c7cb93b5bb41e74092f636f81f38e", "filename": "Cargo.toml", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/Cargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/Cargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.toml?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -24,6 +24,8 @@ path = \"miri/lib.rs\"\n [dependencies]\n byteorder = { version = \"1.1\", features = [\"i128\"]}\n cargo_metadata = { version = \"0.2\", optional = true }\n+regex = \"0.2.2\"\n+lazy_static = \"1.0\"\n \n [features]\n cargo_miri = [\"cargo_metadata\"]"}, {"sha": "71da97b5ab9b2c782ff6cc581727feb723081a55", "filename": "miri/fn_call.rs", "status": "modified", "additions": 22, "deletions": 23, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Ffn_call.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Ffn_call.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Ffn_call.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -8,10 +8,9 @@ use syntax::codemap::Span;\n \n use std::mem;\n \n-use rustc::mir::interpret::*;\n use rustc::traits;\n \n-use super::{TlsKey, EvalContext};\n+use super::*;\n \n use tls::MemoryExt;\n \n@@ -50,7 +49,7 @@ pub trait EvalContextExt<'tcx> {\n     fn write_null(&mut self, dest: Place, dest_ty: Ty<'tcx>) -> EvalResult<'tcx>;\n }\n \n-impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator> {\n+impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator<'tcx>> {\n     fn eval_fn_call(\n         &mut self,\n         instance: ty::Instance<'tcx>,\n@@ -119,7 +118,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             }\n \n             \"free\" => {\n-                let ptr = args[0].into_ptr(&mut self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 if !ptr.is_null()? {\n                     self.memory.deallocate(\n                         ptr.to_ptr()?,\n@@ -150,8 +149,8 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             }\n \n             \"dlsym\" => {\n-                let _handle = args[0].into_ptr(&mut self.memory)?;\n-                let symbol = args[1].into_ptr(&mut self.memory)?.to_ptr()?;\n+                let _handle = self.into_ptr(args[0].value)?;\n+                let symbol = self.into_ptr(args[1].value)?.to_ptr()?;\n                 let symbol_name = self.memory.read_c_str(symbol)?;\n                 let err = format!(\"bad c unicode symbol: {:?}\", symbol_name);\n                 let symbol_name = ::std::str::from_utf8(symbol_name).unwrap_or(&err);\n@@ -165,8 +164,8 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n                 // fn __rust_maybe_catch_panic(f: fn(*mut u8), data: *mut u8, data_ptr: *mut usize, vtable_ptr: *mut usize) -> u32\n                 // We abort on panic, so not much is going on here, but we still have to call the closure\n                 let u8_ptr_ty = self.tcx.mk_mut_ptr(self.tcx.types.u8);\n-                let f = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n-                let data = args[1].into_ptr(&mut self.memory)?;\n+                let f = self.into_ptr(args[0].value)?.to_ptr()?;\n+                let data = self.into_ptr(args[1].value)?;\n                 let f_instance = self.memory.get_fn(f)?;\n                 self.write_null(dest, dest_ty)?;\n \n@@ -205,8 +204,8 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             }\n \n             \"memcmp\" => {\n-                let left = args[0].into_ptr(&mut self.memory)?;\n-                let right = args[1].into_ptr(&mut self.memory)?;\n+                let left = self.into_ptr(args[0].value)?;\n+                let right = self.into_ptr(args[1].value)?;\n                 let n = self.value_to_primval(args[2])?.to_u64()?;\n \n                 let result = {\n@@ -229,7 +228,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             }\n \n             \"memrchr\" => {\n-                let ptr = args[0].into_ptr(&mut self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let val = self.value_to_primval(args[1])?.to_u64()? as u8;\n                 let num = self.value_to_primval(args[2])?.to_u64()?;\n                 if let Some(idx) = self.memory.read_bytes(ptr, num)?.iter().rev().position(\n@@ -244,7 +243,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             }\n \n             \"memchr\" => {\n-                let ptr = args[0].into_ptr(&mut self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let val = self.value_to_primval(args[1])?.to_u64()? as u8;\n                 let num = self.value_to_primval(args[2])?.to_u64()?;\n                 if let Some(idx) = self.memory.read_bytes(ptr, num)?.iter().position(\n@@ -260,7 +259,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             \"getenv\" => {\n                 let result = {\n-                    let name_ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n+                    let name_ptr = self.into_ptr(args[0].value)?.to_ptr()?;\n                     let name = self.memory.read_c_str(name_ptr)?;\n                     match self.machine.env_vars.get(name) {\n                         Some(&var) => PrimVal::Ptr(var),\n@@ -273,7 +272,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             \"unsetenv\" => {\n                 let mut success = None;\n                 {\n-                    let name_ptr = args[0].into_ptr(&mut self.memory)?;\n+                    let name_ptr = self.into_ptr(args[0].value)?;\n                     if !name_ptr.is_null()? {\n                         let name = self.memory.read_c_str(name_ptr.to_ptr()?)?;\n                         if !name.is_empty() && !name.contains(&b'=') {\n@@ -294,8 +293,8 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             \"setenv\" => {\n                 let mut new = None;\n                 {\n-                    let name_ptr = args[0].into_ptr(&mut self.memory)?;\n-                    let value_ptr = args[1].into_ptr(&mut self.memory)?.to_ptr()?;\n+                    let name_ptr = self.into_ptr(args[0].value)?;\n+                    let value_ptr = self.into_ptr(args[1].value)?.to_ptr()?;\n                     let value = self.memory.read_c_str(value_ptr)?;\n                     if !name_ptr.is_null()? {\n                         let name = self.memory.read_c_str(name_ptr.to_ptr()?)?;\n@@ -329,7 +328,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             \"write\" => {\n                 let fd = self.value_to_primval(args[0])?.to_u64()?;\n-                let buf = args[1].into_ptr(&mut self.memory)?;\n+                let buf = self.into_ptr(args[1].value)?;\n                 let n = self.value_to_primval(args[2])?.to_u64()?;\n                 trace!(\"Called write({:?}, {:?}, {:?})\", fd, buf, n);\n                 let result = if fd == 1 || fd == 2 {\n@@ -358,7 +357,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             }\n \n             \"strlen\" => {\n-                let ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n+                let ptr = self.into_ptr(args[0].value)?.to_ptr()?;\n                 let n = self.memory.read_c_str(ptr)?.len();\n                 self.write_primval(dest, PrimVal::Bytes(n as u128), dest_ty)?;\n             }\n@@ -406,10 +405,10 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             // Hook pthread calls that go to the thread-local storage memory subsystem\n             \"pthread_key_create\" => {\n-                let key_ptr = args[0].into_ptr(&mut self.memory)?;\n+                let key_ptr = self.into_ptr(args[0].value)?;\n \n                 // Extract the function type out of the signature (that seems easier than constructing it ourselves...)\n-                let dtor = match args[1].into_ptr(&mut self.memory)?.into_inner_primval() {\n+                let dtor = match self.into_ptr(args[1].value)?.into_inner_primval() {\n                     PrimVal::Ptr(dtor_ptr) => Some(self.memory.get_fn(dtor_ptr)?),\n                     PrimVal::Bytes(0) => None,\n                     PrimVal::Bytes(_) => return err!(ReadBytesAsPointer),\n@@ -452,7 +451,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             \"pthread_setspecific\" => {\n                 // The conversion into TlsKey here is a little fishy, but should work as long as usize >= libc::pthread_key_t\n                 let key = self.value_to_primval(args[0])?.to_u64()? as TlsKey;\n-                let new_ptr = args[1].into_ptr(&mut self.memory)?;\n+                let new_ptr = self.into_ptr(args[1].value)?;\n                 self.memory.store_tls(key, new_ptr)?;\n \n                 // Return success (0)\n@@ -577,7 +576,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n                 self.write_primval(dest, PrimVal::Ptr(ptr), dest_ty)?;\n             }\n             \"alloc::heap::::__rust_dealloc\" => {\n-                let ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n+                let ptr = self.into_ptr(args[0].value)?.to_ptr()?;\n                 let old_size = self.value_to_primval(args[1])?.to_u64()?;\n                 let align = self.value_to_primval(args[2])?.to_u64()?;\n                 if old_size == 0 {\n@@ -593,7 +592,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n                 )?;\n             }\n             \"alloc::heap::::__rust_realloc\" => {\n-                let ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n+                let ptr = self.into_ptr(args[0].value)?.to_ptr()?;\n                 let old_size = self.value_to_primval(args[1])?.to_u64()?;\n                 let old_align = self.value_to_primval(args[2])?.to_u64()?;\n                 let new_size = self.value_to_primval(args[3])?.to_u64()?;"}, {"sha": "0e541cf2920865f4a3fc73caa79fe6a395e06328", "filename": "miri/helpers.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fhelpers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fhelpers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Fhelpers.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -1,5 +1,4 @@\n-use rustc::mir::interpret::{Pointer, EvalResult, PrimVal, EvalContext};\n-\n+use super::{Pointer, EvalResult, PrimVal, EvalContext};\n use rustc::ty::Ty;\n use rustc::ty::layout::LayoutOf;\n \n@@ -19,7 +18,7 @@ pub trait EvalContextExt<'tcx> {\n     ) -> EvalResult<'tcx, Pointer>;\n }\n \n-impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator> {\n+impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator<'tcx>> {\n     fn wrapping_pointer_offset(\n         &self,\n         ptr: Pointer,"}, {"sha": "705c332523397a02192a5a7690ef01c1eb9f2f7d", "filename": "miri/intrinsic.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Fintrinsic.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -3,8 +3,8 @@ use rustc::traits::Reveal;\n use rustc::ty::layout::{TyLayout, LayoutOf};\n use rustc::ty;\n \n-use rustc::mir::interpret::{EvalResult, Place, PlaceExtra, PrimVal, PrimValKind, Value, Pointer,\n-                            HasMemory, AccessKind, EvalContext, PtrAndAlign, ValTy};\n+use rustc::mir::interpret::{EvalResult, PrimVal, PrimValKind, Value, Pointer, AccessKind, PtrAndAlign};\n+use rustc_mir::interpret::{Place, PlaceExtra, HasMemory, EvalContext, ValTy};\n \n use helpers::EvalContextExt as HelperEvalContextExt;\n \n@@ -19,7 +19,7 @@ pub trait EvalContextExt<'tcx> {\n     ) -> EvalResult<'tcx>;\n }\n \n-impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator> {\n+impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator<'tcx>> {\n     fn call_intrinsic(\n         &mut self,\n         instance: ty::Instance<'tcx>,\n@@ -70,7 +70,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             \"arith_offset\" => {\n                 let offset = self.value_to_primval(args[1])?.to_i128()? as i64;\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let result_ptr = self.wrapping_pointer_offset(ptr, substs.type_at(0), offset)?;\n                 self.write_ptr(dest, result_ptr, dest_layout.ty)?;\n             }\n@@ -86,7 +86,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             \"atomic_load_relaxed\" |\n             \"atomic_load_acq\" |\n             \"volatile_load\" => {\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let valty = ValTy {\n                     value: Value::by_ref(ptr),\n                     ty: substs.type_at(0),\n@@ -99,7 +99,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             \"atomic_store_rel\" |\n             \"volatile_store\" => {\n                 let ty = substs.type_at(0);\n-                let dest = args[0].into_ptr(&self.memory)?;\n+                let dest = self.into_ptr(args[0].value)?;\n                 self.write_value_to_ptr(args[1].value, dest, ty)?;\n             }\n \n@@ -109,7 +109,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             _ if intrinsic_name.starts_with(\"atomic_xchg\") => {\n                 let ty = substs.type_at(0);\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let change = self.value_to_primval(args[1])?;\n                 let old = self.read_value(ptr, ty)?;\n                 let old = match old {\n@@ -127,7 +127,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             _ if intrinsic_name.starts_with(\"atomic_cxchg\") => {\n                 let ty = substs.type_at(0);\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let expect_old = self.value_to_primval(args[1])?;\n                 let change = self.value_to_primval(args[2])?;\n                 let old = self.read_value(ptr, ty)?;\n@@ -175,7 +175,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n             \"atomic_xsub_acqrel\" |\n             \"atomic_xsub_relaxed\" => {\n                 let ty = substs.type_at(0);\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let change = self.value_to_primval(args[1])?;\n                 let old = self.read_value(ptr, ty)?;\n                 let old = match old {\n@@ -211,8 +211,8 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n                     // TODO: We do not even validate alignment for the 0-bytes case.  libstd relies on this in vec::IntoIter::next.\n                     // Also see the write_bytes intrinsic.\n                     let elem_align = elem_layout.align.abi();\n-                    let src = args[0].into_ptr(&self.memory)?;\n-                    let dest = args[1].into_ptr(&self.memory)?;\n+                    let src = self.into_ptr(args[0].value)?;\n+                    let dest = self.into_ptr(args[1].value)?;\n                     self.memory.copy(\n                         src,\n                         dest,\n@@ -240,7 +240,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             \"discriminant_value\" => {\n                 let ty = substs.type_at(0);\n-                let adt_ptr = args[0].into_ptr(&self.memory)?;\n+                let adt_ptr = self.into_ptr(args[0].value)?;\n                 let place = Place::from_primval_ptr(adt_ptr);\n                 let discr_val = self.read_discriminant_value(place, ty)?;\n                 self.write_primval(dest, PrimVal::Bytes(discr_val), dest_layout.ty)?;\n@@ -366,7 +366,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             \"move_val_init\" => {\n                 let ty = substs.type_at(0);\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 self.write_value_to_ptr(args[1].value, ptr, ty)?;\n             }\n \n@@ -383,7 +383,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n \n             \"offset\" => {\n                 let offset = self.value_to_primval(args[1])?.to_i128()? as i64;\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let result_ptr = self.pointer_offset(ptr, substs.type_at(0), offset)?;\n                 self.write_ptr(dest, result_ptr, dest_layout.ty)?;\n             }\n@@ -634,7 +634,7 @@ impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator>\n                 let ty = substs.type_at(0);\n                 let ty_layout = self.layout_of(ty)?;\n                 let val_byte = self.value_to_primval(args[1])?.to_u128()? as u8;\n-                let ptr = args[0].into_ptr(&self.memory)?;\n+                let ptr = self.into_ptr(args[0].value)?;\n                 let count = self.value_to_primval(args[2])?.to_u64()?;\n                 if count > 0 {\n                     // HashMap relies on write_bytes on a NULL ptr with count == 0 to work"}, {"sha": "739ccfbf76712d8dd955639e89d7c3133c791363", "filename": "miri/lib.rs", "status": "modified", "additions": 87, "deletions": 5, "changes": 92, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Flib.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -1,14 +1,21 @@\n #![feature(\n     i128_type,\n     rustc_private,\n+    conservative_impl_trait,\n+    catch_expr,\n )]\n \n // From rustc.\n #[macro_use]\n extern crate log;\n #[macro_use]\n extern crate rustc;\n+extern crate rustc_mir;\n+extern crate rustc_data_structures;\n extern crate syntax;\n+extern crate regex;\n+#[macro_use]\n+extern crate lazy_static;\n \n use rustc::ty::{self, TyCtxt};\n use rustc::ty::layout::{TyLayout, LayoutOf};\n@@ -22,18 +29,27 @@ use syntax::codemap::Span;\n use std::collections::{HashMap, BTreeMap};\n \n pub use rustc::mir::interpret::*;\n+pub use rustc_mir::interpret::*;\n \n mod fn_call;\n mod operator;\n mod intrinsic;\n mod helpers;\n mod memory;\n mod tls;\n+mod locks;\n+mod range_map;\n+mod validation;\n \n use fn_call::EvalContextExt as MissingFnsEvalContextExt;\n use operator::EvalContextExt as OperatorEvalContextExt;\n use intrinsic::EvalContextExt as IntrinsicEvalContextExt;\n use tls::EvalContextExt as TlsEvalContextExt;\n+use locks::LockInfo;\n+use locks::MemoryExt as LockMemoryExt;\n+use validation::EvalContextExt as ValidationEvalContextExt;\n+use range_map::RangeMap;\n+use validation::{ValidationQuery, AbsPlace};\n \n pub fn eval_main<'a, 'tcx: 'a>(\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n@@ -42,7 +58,7 @@ pub fn eval_main<'a, 'tcx: 'a>(\n     limits: ResourceLimits,\n ) {\n     fn run_main<'a, 'tcx: 'a>(\n-        ecx: &mut rustc::mir::interpret::EvalContext<'a, 'tcx, Evaluator>,\n+        ecx: &mut rustc_mir::interpret::EvalContext<'a, 'tcx, Evaluator<'tcx>>,\n         main_id: DefId,\n         start_wrapper: Option<DefId>,\n     ) -> EvalResult<'tcx> {\n@@ -156,10 +172,13 @@ pub fn eval_main<'a, 'tcx: 'a>(\n }\n \n #[derive(Default)]\n-pub struct Evaluator {\n+pub struct Evaluator<'tcx> {\n     /// Environment variables set by `setenv`\n     /// Miri does not expose env vars from the host to the emulated program\n     pub(crate) env_vars: HashMap<Vec<u8>, MemoryPointer>,\n+\n+    /// Places that were suspended by the validation subsystem, and will be recovered later\n+    pub(crate) suspended: HashMap<DynamicLifetime, Vec<ValidationQuery<'tcx>>>,\n }\n \n pub type TlsKey = usize;\n@@ -177,9 +196,15 @@ pub struct MemoryData<'tcx> {\n \n     /// pthreads-style thread-local storage.\n     thread_local: BTreeMap<TlsKey, TlsEntry<'tcx>>,\n+\n+    /// Memory regions that are locked by some function\n+    ///\n+    /// Only mutable (static mut, heap, stack) allocations have an entry in this map.\n+    /// The entry is created when allocating the memory and deleted after deallocation.\n+    locks: HashMap<u64, RangeMap<LockInfo<'tcx>>>,\n }\n \n-impl<'tcx> Machine<'tcx> for Evaluator {\n+impl<'tcx> Machine<'tcx> for Evaluator<'tcx> {\n     type MemoryData = MemoryData<'tcx>;\n     type MemoryKinds = memory::MemoryKind;\n \n@@ -196,7 +221,7 @@ impl<'tcx> Machine<'tcx> for Evaluator {\n     }\n \n     fn call_intrinsic<'a>(\n-        ecx: &mut rustc::mir::interpret::EvalContext<'a, 'tcx, Self>,\n+        ecx: &mut rustc_mir::interpret::EvalContext<'a, 'tcx, Self>,\n         instance: ty::Instance<'tcx>,\n         args: &[ValTy<'tcx>],\n         dest: Place,\n@@ -207,7 +232,7 @@ impl<'tcx> Machine<'tcx> for Evaluator {\n     }\n \n     fn try_ptr_op<'a>(\n-        ecx: &rustc::mir::interpret::EvalContext<'a, 'tcx, Self>,\n+        ecx: &rustc_mir::interpret::EvalContext<'a, 'tcx, Self>,\n         bin_op: mir::BinOp,\n         left: PrimVal,\n         left_ty: ty::Ty<'tcx>,\n@@ -303,4 +328,61 @@ impl<'tcx> Machine<'tcx> for Evaluator {\n         );\n         Ok(())\n     }\n+\n+    fn check_locks<'a>(\n+        mem: &Memory<'a, 'tcx, Self>,\n+        ptr: MemoryPointer,\n+        size: u64,\n+        access: AccessKind,\n+    ) -> EvalResult<'tcx> {\n+        mem.check_locks(ptr, size, access)\n+    }\n+\n+    fn add_lock<'a>(\n+        mem: &mut Memory<'a, 'tcx, Self>,\n+        id: u64,\n+    ) {\n+        mem.data.locks.insert(id, RangeMap::new());\n+    }\n+\n+    fn free_lock<'a>(\n+        mem: &mut Memory<'a, 'tcx, Self>,\n+        id: u64,\n+        len: u64,\n+    ) -> EvalResult<'tcx> {\n+        mem.data.locks\n+            .remove(&id)\n+            .expect(\"allocation has no corresponding locks\")\n+            .check(\n+                Some(mem.cur_frame),\n+                0,\n+                len,\n+                AccessKind::Read,\n+            )\n+            .map_err(|lock| {\n+                EvalErrorKind::DeallocatedLockedMemory {\n+                    //ptr, FIXME\n+                    ptr: MemoryPointer {\n+                        alloc_id: AllocId(0),\n+                        offset: 0,\n+                    },\n+                    lock: lock.active,\n+                }.into()\n+            })\n+    }\n+\n+    fn end_region<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        reg: Option<::rustc::middle::region::Scope>,\n+    ) -> EvalResult<'tcx> {\n+        ecx.end_region(reg)\n+    }\n+\n+    fn validation_op<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        op: ::rustc::mir::ValidationOp,\n+        operand: &::rustc::mir::ValidationOperand<'tcx, ::rustc::mir::Place<'tcx>>,\n+    ) -> EvalResult<'tcx> {\n+        ecx.validation_op(op, operand)\n+    }\n }"}, {"sha": "3a9df6a38dff11238adbf1669f091b52cc4a5f5e", "filename": "miri/locks.rs", "status": "added", "additions": 405, "deletions": 0, "changes": 405, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Flocks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Flocks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Flocks.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -0,0 +1,405 @@\n+use super::*;\n+use rustc::middle::region;\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Locks\n+////////////////////////////////////////////////////////////////////////////////\n+\n+/// Information about a lock that is currently held.\n+#[derive(Clone, Debug)]\n+pub struct LockInfo<'tcx> {\n+    /// Stores for which lifetimes (of the original write lock) we got\n+    /// which suspensions.\n+    suspended: HashMap<WriteLockId<'tcx>, Vec<region::Scope>>,\n+    /// The current state of the lock that's actually effective.\n+    pub active: Lock,\n+}\n+\n+/// Write locks are identified by a stack frame and an \"abstract\" (untyped) place.\n+/// It may be tempting to use the lifetime as identifier, but that does not work\n+/// for two reasons:\n+/// * First of all, due to subtyping, the same lock may be referred to with different\n+///   lifetimes.\n+/// * Secondly, different write locks may actually have the same lifetime.  See `test2`\n+///   in `run-pass/many_shr_bor.rs`.\n+/// The Id is \"captured\" when the lock is first suspended; at that point, the borrow checker\n+/// considers the path frozen and hence the Id remains stable.\n+#[derive(Clone, Debug, PartialEq, Eq, Hash)]\n+pub struct WriteLockId<'tcx> {\n+    frame: usize,\n+    path: AbsPlace<'tcx>,\n+}\n+\n+\n+use rustc::mir::interpret::Lock::*;\n+use rustc::mir::interpret::Lock;\n+\n+impl<'tcx> Default for LockInfo<'tcx> {\n+    fn default() -> Self {\n+        LockInfo::new(NoLock)\n+    }\n+}\n+\n+impl<'tcx> LockInfo<'tcx> {\n+    fn new(lock: Lock) -> LockInfo<'tcx> {\n+        LockInfo {\n+            suspended: HashMap::new(),\n+            active: lock,\n+        }\n+    }\n+\n+    fn access_permitted(&self, frame: Option<usize>, access: AccessKind) -> bool {\n+        use super::AccessKind::*;\n+        match (&self.active, access) {\n+            (&NoLock, _) => true,\n+            (&ReadLock(ref lfts), Read) => {\n+                assert!(!lfts.is_empty(), \"Someone left an empty read lock behind.\");\n+                // Read access to read-locked region is okay, no matter who's holding the read lock.\n+                true\n+            }\n+            (&WriteLock(ref lft), _) => {\n+                // All access is okay if we are the ones holding it\n+                Some(lft.frame) == frame\n+            }\n+            _ => false, // Nothing else is okay.\n+        }\n+    }\n+}\n+\n+pub trait MemoryExt<'tcx> {\n+    fn check_locks(\n+        &self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        access: AccessKind,\n+    ) -> EvalResult<'tcx>;\n+    fn acquire_lock(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        region: Option<region::Scope>,\n+        kind: AccessKind,\n+    ) -> EvalResult<'tcx>;\n+    fn suspend_write_lock(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        lock_path: &AbsPlace<'tcx>,\n+        suspend: Option<region::Scope>,\n+    ) -> EvalResult<'tcx>;\n+    fn recover_write_lock(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        lock_path: &AbsPlace<'tcx>,\n+        lock_region: Option<region::Scope>,\n+        suspended_region: region::Scope,\n+    ) -> EvalResult<'tcx>;\n+    fn locks_lifetime_ended(&mut self, ending_region: Option<region::Scope>);\n+}\n+\n+\n+impl<'a, 'tcx: 'a> MemoryExt<'tcx> for Memory<'a, 'tcx, Evaluator<'tcx>> {\n+    fn check_locks(\n+        &self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        access: AccessKind,\n+    ) -> EvalResult<'tcx> {\n+        if len == 0 {\n+            return Ok(());\n+        }\n+        let locks = match self.data.locks.get(&ptr.alloc_id.0) {\n+            Some(locks) => locks,\n+            // immutable static or other constant memory\n+            None => return Ok(()),\n+        };\n+        let frame = self.cur_frame;\n+        locks\n+            .check(Some(frame), ptr.offset, len, access)\n+            .map_err(|lock| {\n+                EvalErrorKind::MemoryLockViolation {\n+                    ptr,\n+                    len,\n+                    frame,\n+                    access,\n+                    lock: lock.active,\n+                }.into()\n+            })\n+    }\n+\n+    /// Acquire the lock for the given lifetime\n+    fn acquire_lock(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        region: Option<region::Scope>,\n+        kind: AccessKind,\n+    ) -> EvalResult<'tcx> {\n+        let frame = self.cur_frame;\n+        assert!(len > 0);\n+        trace!(\n+            \"Frame {} acquiring {:?} lock at {:?}, size {} for region {:?}\",\n+            frame,\n+            kind,\n+            ptr,\n+            len,\n+            region\n+        );\n+        self.check_bounds(ptr.offset(len, &*self)?, true)?; // if ptr.offset is in bounds, then so is ptr (because offset checks for overflow)\n+\n+        let locks = match self.data.locks.get_mut(&ptr.alloc_id.0) {\n+            Some(locks) => locks,\n+            // immutable static or other constant memory\n+            None => return Ok(()),\n+        };\n+\n+        // Iterate over our range and acquire the lock.  If the range is already split into pieces,\n+        // we have to manipulate all of them.\n+        let lifetime = DynamicLifetime { frame, region };\n+        for lock in locks.iter_mut(ptr.offset, len) {\n+            if !lock.access_permitted(None, kind) {\n+                return err!(MemoryAcquireConflict {\n+                    ptr,\n+                    len,\n+                    kind,\n+                    lock: lock.active.clone(),\n+                });\n+            }\n+            // See what we have to do\n+            match (&mut lock.active, kind) {\n+                (active @ &mut NoLock, AccessKind::Write) => {\n+                    *active = WriteLock(lifetime);\n+                }\n+                (active @ &mut NoLock, AccessKind::Read) => {\n+                    *active = ReadLock(vec![lifetime]);\n+                }\n+                (&mut ReadLock(ref mut lifetimes), AccessKind::Read) => {\n+                    lifetimes.push(lifetime);\n+                }\n+                _ => bug!(\"We already checked that there is no conflicting lock\"),\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    /// Release or suspend a write lock of the given lifetime prematurely.\n+    /// When releasing, if there is a read lock or someone else's write lock, that's an error.\n+    /// If no lock is held, that's fine.  This can happen when e.g. a local is initialized\n+    /// from a constant, and then suspended.\n+    /// When suspending, the same cases are fine; we just register an additional suspension.\n+    fn suspend_write_lock(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        lock_path: &AbsPlace<'tcx>,\n+        suspend: Option<region::Scope>,\n+    ) -> EvalResult<'tcx> {\n+        assert!(len > 0);\n+        let cur_frame = self.cur_frame;\n+        let locks = match self.data.locks.get_mut(&ptr.alloc_id.0) {\n+            Some(locks) => locks,\n+            // immutable static or other constant memory\n+            None => return Ok(()),\n+        };\n+\n+        'locks: for lock in locks.iter_mut(ptr.offset, len) {\n+            let is_our_lock = match lock.active {\n+                WriteLock(lft) =>\n+                    // Double-check that we are holding the lock.\n+                    // (Due to subtyping, checking the region would not make any sense.)\n+                    lft.frame == cur_frame,\n+                ReadLock(_) | NoLock => false,\n+            };\n+            if is_our_lock {\n+                trace!(\"Releasing {:?}\", lock.active);\n+                // Disable the lock\n+                lock.active = NoLock;\n+            } else {\n+                trace!(\n+                    \"Not touching {:?} as it is not our lock\",\n+                    lock.active,\n+                );\n+            }\n+            // Check if we want to register a suspension\n+            if let Some(suspend_region) = suspend {\n+                let lock_id = WriteLockId {\n+                    frame: cur_frame,\n+                    path: lock_path.clone(),\n+                };\n+                trace!(\"Adding suspension to {:?}\", lock_id);\n+                let mut new_suspension = false;\n+                lock.suspended\n+                    .entry(lock_id)\n+                    // Remember whether we added a new suspension or not\n+                    .or_insert_with(|| { new_suspension = true; Vec::new() })\n+                    .push(suspend_region);\n+                // If the suspension is new, we should have owned this.\n+                // If there already was a suspension, we should NOT have owned this.\n+                if new_suspension == is_our_lock {\n+                    // All is well\n+                    continue 'locks;\n+                }\n+            } else {\n+                if !is_our_lock {\n+                    // All is well.\n+                    continue 'locks;\n+                }\n+            }\n+            // If we get here, releasing this is an error except for NoLock.\n+            if lock.active != NoLock {\n+                return err!(InvalidMemoryLockRelease {\n+                    ptr,\n+                    len,\n+                    frame: cur_frame,\n+                    lock: lock.active.clone(),\n+                });\n+            }\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Release a suspension from the write lock.  If this is the last suspension or if there is no suspension, acquire the lock.\n+    fn recover_write_lock(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        len: u64,\n+        lock_path: &AbsPlace<'tcx>,\n+        lock_region: Option<region::Scope>,\n+        suspended_region: region::Scope,\n+    ) -> EvalResult<'tcx> {\n+        assert!(len > 0);\n+        let cur_frame = self.cur_frame;\n+        let lock_id = WriteLockId {\n+            frame: cur_frame,\n+            path: lock_path.clone(),\n+        };\n+        let locks = match self.data.locks.get_mut(&ptr.alloc_id.0) {\n+            Some(locks) => locks,\n+            // immutable static or other constant memory\n+            None => return Ok(()),\n+        };\n+\n+        for lock in locks.iter_mut(ptr.offset, len) {\n+            // Check if we have a suspension here\n+            let (got_the_lock, remove_suspension) = match lock.suspended.get_mut(&lock_id) {\n+                None => {\n+                    trace!(\"No suspension around, we can just acquire\");\n+                    (true, false)\n+                }\n+                Some(suspensions) => {\n+                    trace!(\"Found suspension of {:?}, removing it\", lock_id);\n+                    // That's us!  Remove suspension (it should be in there).  The same suspension can\n+                    // occur multiple times (when there are multiple shared borrows of this that have the same\n+                    // lifetime); only remove one of them.\n+                    let idx = match suspensions.iter().enumerate().find(|&(_, re)| re == &suspended_region) {\n+                        None => // TODO: Can the user trigger this?\n+                            bug!(\"We have this lock suspended, but not for the given region.\"),\n+                        Some((idx, _)) => idx\n+                    };\n+                    suspensions.remove(idx);\n+                    let got_lock = suspensions.is_empty();\n+                    if got_lock {\n+                        trace!(\"All suspensions are gone, we can have the lock again\");\n+                    }\n+                    (got_lock, got_lock)\n+                }\n+            };\n+            if remove_suspension {\n+                // with NLL, we could do that up in the match above...\n+                assert!(got_the_lock);\n+                lock.suspended.remove(&lock_id);\n+            }\n+            if got_the_lock {\n+                match lock.active {\n+                    ref mut active @ NoLock => {\n+                        *active = WriteLock(\n+                            DynamicLifetime {\n+                                frame: cur_frame,\n+                                region: lock_region,\n+                            }\n+                        );\n+                    }\n+                    _ => {\n+                        return err!(MemoryAcquireConflict {\n+                            ptr,\n+                            len,\n+                            kind: AccessKind::Write,\n+                            lock: lock.active.clone(),\n+                        })\n+                    }\n+                }\n+            }\n+        }\n+\n+        Ok(())\n+    }\n+\n+    fn locks_lifetime_ended(&mut self, ending_region: Option<region::Scope>) {\n+        let cur_frame = self.cur_frame;\n+        trace!(\n+            \"Releasing frame {} locks that expire at {:?}\",\n+            cur_frame,\n+            ending_region\n+        );\n+        let has_ended = |lifetime: &DynamicLifetime| -> bool {\n+            if lifetime.frame != cur_frame {\n+                return false;\n+            }\n+            match ending_region {\n+                None => true, // When a function ends, we end *all* its locks. It's okay for a function to still have lifetime-related locks\n+                // when it returns, that can happen e.g. with NLL when a lifetime can, but does not have to, extend beyond the\n+                // end of a function.  Same for a function still having recoveries.\n+                Some(ending_region) => lifetime.region == Some(ending_region),\n+            }\n+        };\n+\n+        for alloc_locks in self.data.locks.values_mut() {\n+            for lock in alloc_locks.iter_mut_all() {\n+                // Delete everything that ends now -- i.e., keep only all the other lifetimes.\n+                let lock_ended = match lock.active {\n+                    WriteLock(ref lft) => has_ended(lft),\n+                    ReadLock(ref mut lfts) => {\n+                        lfts.retain(|lft| !has_ended(lft));\n+                        lfts.is_empty()\n+                    }\n+                    NoLock => false,\n+                };\n+                if lock_ended {\n+                    lock.active = NoLock;\n+                }\n+                // Also clean up suspended write locks when the function returns\n+                if ending_region.is_none() {\n+                    lock.suspended.retain(|id, _suspensions| id.frame != cur_frame);\n+                }\n+            }\n+            // Clean up the map\n+            alloc_locks.retain(|lock| match lock.active {\n+                NoLock => lock.suspended.len() > 0,\n+                _ => true,\n+            });\n+        }\n+    }\n+}\n+\n+impl<'tcx> RangeMap<LockInfo<'tcx>> {\n+    pub fn check(\n+        &self,\n+        frame: Option<usize>,\n+        offset: u64,\n+        len: u64,\n+        access: AccessKind,\n+    ) -> Result<(), LockInfo<'tcx>> {\n+        if len == 0 {\n+            return Ok(());\n+        }\n+        for lock in self.iter(offset, len) {\n+            // Check if the lock is in conflict with the access.\n+            if !lock.access_permitted(frame, access) {\n+                return Err(lock.clone());\n+            }\n+        }\n+        Ok(())\n+    }\n+}"}, {"sha": "bed0eb28c25c691e465fd7fa7e65831698bc5929", "filename": "miri/memory.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Fmemory.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -9,8 +9,8 @@ pub enum MemoryKind {\n     Env,\n }\n \n-impl Into<::rustc::mir::interpret::MemoryKind<MemoryKind>> for MemoryKind {\n-    fn into(self) -> ::rustc::mir::interpret::MemoryKind<MemoryKind> {\n-        ::rustc::mir::interpret::MemoryKind::Machine(self)\n+impl Into<::rustc_mir::interpret::MemoryKind<MemoryKind>> for MemoryKind {\n+    fn into(self) -> ::rustc_mir::interpret::MemoryKind<MemoryKind> {\n+        ::rustc_mir::interpret::MemoryKind::Machine(self)\n     }\n }"}, {"sha": "e70f1b12628ac9b33a6057e002b83ce725a19d48", "filename": "miri/operator.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Foperator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Foperator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Foperator.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -1,7 +1,7 @@\n use rustc::ty;\n use rustc::mir;\n \n-use rustc::mir::interpret::*;\n+use super::*;\n \n use helpers::EvalContextExt as HelperEvalContextExt;\n \n@@ -24,7 +24,7 @@ pub trait EvalContextExt<'tcx> {\n     ) -> EvalResult<'tcx, (PrimVal, bool)>;\n }\n \n-impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator> {\n+impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator<'tcx>> {\n     fn ptr_op(\n         &self,\n         bin_op: mir::BinOp,"}, {"sha": "5cdcbe35121a579e26b6d74c461b5cb64ece2676", "filename": "miri/range_map.rs", "status": "added", "additions": 250, "deletions": 0, "changes": 250, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Frange_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Frange_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Frange_map.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -0,0 +1,250 @@\n+//! Implements a map from integer indices to data.\n+//! Rather than storing data for every index, internally, this maps entire ranges to the data.\n+//! To this end, the APIs all work on ranges, not on individual integers. Ranges are split as\n+//! necessary (e.g. when [0,5) is first associated with X, and then [1,2) is mutated).\n+//! Users must not depend on whether a range is coalesced or not, even though this is observable\n+//! via the iteration APIs.\n+use std::collections::BTreeMap;\n+use std::ops;\n+\n+#[derive(Clone, Debug)]\n+pub struct RangeMap<T> {\n+    map: BTreeMap<Range, T>,\n+}\n+\n+// The derived `Ord` impl sorts first by the first field, then, if the fields are the same,\n+// by the second field.\n+// This is exactly what we need for our purposes, since a range query on a BTReeSet/BTreeMap will give us all\n+// `MemoryRange`s whose `start` is <= than the one we're looking for, but not > the end of the range we're checking.\n+// At the same time the `end` is irrelevant for the sorting and range searching, but used for the check.\n+// This kind of search breaks, if `end < start`, so don't do that!\n+#[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd, Debug)]\n+struct Range {\n+    start: u64,\n+    end: u64, // Invariant: end > start\n+}\n+\n+impl Range {\n+    fn range(offset: u64, len: u64) -> ops::Range<Range> {\n+        assert!(len > 0);\n+        // We select all elements that are within\n+        // the range given by the offset into the allocation and the length.\n+        // This is sound if all ranges that intersect with the argument range, are in the\n+        // resulting range of ranges.\n+        let left = Range {\n+            // lowest range to include `offset`\n+            start: 0,\n+            end: offset + 1,\n+        };\n+        let right = Range {\n+            // lowest (valid) range not to include `offset+len`\n+            start: offset + len,\n+            end: offset + len + 1,\n+        };\n+        left..right\n+    }\n+\n+    /// Tests if all of [offset, offset+len) are contained in this range.\n+    fn overlaps(&self, offset: u64, len: u64) -> bool {\n+        assert!(len > 0);\n+        offset < self.end && offset + len >= self.start\n+    }\n+}\n+\n+impl<T> RangeMap<T> {\n+    pub fn new() -> RangeMap<T> {\n+        RangeMap { map: BTreeMap::new() }\n+    }\n+\n+    fn iter_with_range<'a>(\n+        &'a self,\n+        offset: u64,\n+        len: u64,\n+    ) -> impl Iterator<Item = (&'a Range, &'a T)> + 'a {\n+        assert!(len > 0);\n+        self.map.range(Range::range(offset, len)).filter_map(\n+            move |(range,\n+                   data)| {\n+                if range.overlaps(offset, len) {\n+                    Some((range, data))\n+                } else {\n+                    None\n+                }\n+            },\n+        )\n+    }\n+\n+    pub fn iter<'a>(&'a self, offset: u64, len: u64) -> impl Iterator<Item = &'a T> + 'a {\n+        self.iter_with_range(offset, len).map(|(_, data)| data)\n+    }\n+\n+    fn split_entry_at(&mut self, offset: u64)\n+    where\n+        T: Clone,\n+    {\n+        let range = match self.iter_with_range(offset, 1).next() {\n+            Some((&range, _)) => range,\n+            None => return,\n+        };\n+        assert!(\n+            range.start <= offset && range.end > offset,\n+            \"We got a range that doesn't even contain what we asked for.\"\n+        );\n+        // There is an entry overlapping this position, see if we have to split it\n+        if range.start < offset {\n+            let data = self.map.remove(&range).unwrap();\n+            let old = self.map.insert(\n+                Range {\n+                    start: range.start,\n+                    end: offset,\n+                },\n+                data.clone(),\n+            );\n+            assert!(old.is_none());\n+            let old = self.map.insert(\n+                Range {\n+                    start: offset,\n+                    end: range.end,\n+                },\n+                data,\n+            );\n+            assert!(old.is_none());\n+        }\n+    }\n+\n+    pub fn iter_mut_all<'a>(&'a mut self) -> impl Iterator<Item = &'a mut T> + 'a {\n+        self.map.values_mut()\n+    }\n+\n+    /// Provide mutable iteration over everything in the given range.  As a side-effect,\n+    /// this will split entries in the map that are only partially hit by the given range,\n+    /// to make sure that when they are mutated, the effect is constrained to the given range.\n+    pub fn iter_mut_with_gaps<'a>(\n+        &'a mut self,\n+        offset: u64,\n+        len: u64,\n+    ) -> impl Iterator<Item = &'a mut T> + 'a\n+    where\n+        T: Clone,\n+    {\n+        assert!(len > 0);\n+        // Preparation: Split first and last entry as needed.\n+        self.split_entry_at(offset);\n+        self.split_entry_at(offset + len);\n+        // Now we can provide a mutable iterator\n+        self.map.range_mut(Range::range(offset, len)).filter_map(\n+            move |(&range, data)| {\n+                if range.overlaps(offset, len) {\n+                    assert!(\n+                        offset <= range.start && offset + len >= range.end,\n+                        \"The splitting went wrong\"\n+                    );\n+                    Some(data)\n+                } else {\n+                    // Skip this one\n+                    None\n+                }\n+            },\n+        )\n+    }\n+\n+    /// Provide a mutable iterator over everything in the given range, with the same side-effects as\n+    /// iter_mut_with_gaps.  Furthermore, if there are gaps between ranges, fill them with the given default.\n+    /// This is also how you insert.\n+    pub fn iter_mut<'a>(&'a mut self, offset: u64, len: u64) -> impl Iterator<Item = &'a mut T> + 'a\n+    where\n+        T: Clone + Default,\n+    {\n+        // Do a first iteration to collect the gaps\n+        let mut gaps = Vec::new();\n+        let mut last_end = offset;\n+        for (range, _) in self.iter_with_range(offset, len) {\n+            if last_end < range.start {\n+                gaps.push(Range {\n+                    start: last_end,\n+                    end: range.start,\n+                });\n+            }\n+            last_end = range.end;\n+        }\n+        if last_end < offset + len {\n+            gaps.push(Range {\n+                start: last_end,\n+                end: offset + len,\n+            });\n+        }\n+\n+        // Add default for all gaps\n+        for gap in gaps {\n+            let old = self.map.insert(gap, Default::default());\n+            assert!(old.is_none());\n+        }\n+\n+        // Now provide mutable iteration\n+        self.iter_mut_with_gaps(offset, len)\n+    }\n+\n+    pub fn retain<F>(&mut self, mut f: F)\n+    where\n+        F: FnMut(&T) -> bool,\n+    {\n+        let mut remove = Vec::new();\n+        for (range, data) in self.map.iter() {\n+            if !f(data) {\n+                remove.push(*range);\n+            }\n+        }\n+\n+        for range in remove {\n+            self.map.remove(&range);\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+\n+    /// Query the map at every offset in the range and collect the results.\n+    fn to_vec<T: Copy>(map: &RangeMap<T>, offset: u64, len: u64) -> Vec<T> {\n+        (offset..offset + len)\n+            .into_iter()\n+            .map(|i| *map.iter(i, 1).next().unwrap())\n+            .collect()\n+    }\n+\n+    #[test]\n+    fn basic_insert() {\n+        let mut map = RangeMap::<i32>::new();\n+        // Insert\n+        for x in map.iter_mut(10, 1) {\n+            *x = 42;\n+        }\n+        // Check\n+        assert_eq!(to_vec(&map, 10, 1), vec![42]);\n+    }\n+\n+    #[test]\n+    fn gaps() {\n+        let mut map = RangeMap::<i32>::new();\n+        for x in map.iter_mut(11, 1) {\n+            *x = 42;\n+        }\n+        for x in map.iter_mut(15, 1) {\n+            *x = 42;\n+        }\n+\n+        // Now request a range that needs three gaps filled\n+        for x in map.iter_mut(10, 10) {\n+            if *x != 42 {\n+                *x = 23;\n+            }\n+        }\n+\n+        assert_eq!(\n+            to_vec(&map, 10, 10),\n+            vec![23, 42, 23, 23, 23, 42, 23, 23, 23, 23]\n+        );\n+        assert_eq!(to_vec(&map, 13, 5), vec![23, 23, 42, 23, 23]);\n+    }\n+}"}, {"sha": "7f4f194c67f116609528d3bd1088bc38f4bacb77", "filename": "miri/tls.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Ftls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Ftls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Ftls.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -18,7 +18,7 @@ pub trait EvalContextExt<'tcx> {\n     fn run_tls_dtors(&mut self) -> EvalResult<'tcx>;\n }\n \n-impl<'a, 'tcx: 'a> MemoryExt<'tcx> for Memory<'a, 'tcx, Evaluator> {\n+impl<'a, 'tcx: 'a> MemoryExt<'tcx> for Memory<'a, 'tcx, Evaluator<'tcx>> {\n     fn create_tls_key(&mut self, dtor: Option<ty::Instance<'tcx>>) -> TlsKey {\n         let new_key = self.data.next_thread_local;\n         self.data.next_thread_local += 1;\n@@ -106,7 +106,7 @@ impl<'a, 'tcx: 'a> MemoryExt<'tcx> for Memory<'a, 'tcx, Evaluator> {\n     }\n }\n \n-impl<'a, 'tcx: 'a> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, Evaluator> {\n+impl<'a, 'tcx: 'a> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, Evaluator<'tcx>> {\n     fn run_tls_dtors(&mut self) -> EvalResult<'tcx> {\n         let mut dtor = self.memory.fetch_tls_dtor(None)?;\n         // FIXME: replace loop by some structure that works with stepping"}, {"sha": "52f0c24bd6d18fd66724a46732068129e1131dbb", "filename": "miri/validation.rs", "status": "added", "additions": 843, "deletions": 0, "changes": 843, "blob_url": "https://github.com/rust-lang/rust/blob/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fvalidation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bde093fa140cbf95023482a94b92b0b16af4b521/miri%2Fvalidation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/miri%2Fvalidation.rs?ref=bde093fa140cbf95023482a94b92b0b16af4b521", "patch": "@@ -0,0 +1,843 @@\n+use rustc::hir::{self, Mutability};\n+use rustc::hir::Mutability::*;\n+use rustc::mir::{self, ValidationOp, ValidationOperand};\n+use rustc::ty::{self, Ty, TypeFoldable, TyCtxt};\n+use rustc::ty::layout::LayoutOf;\n+use rustc::ty::subst::{Substs, Subst};\n+use rustc::traits;\n+use rustc::infer::InferCtxt;\n+use rustc::traits::Reveal;\n+use rustc::middle::region;\n+use rustc_data_structures::indexed_vec::Idx;\n+use rustc_mir::interpret::HasMemory;\n+\n+use super::{EvalContext, Place, PlaceExtra, ValTy};\n+use rustc::mir::interpret::{DynamicLifetime, AccessKind, EvalErrorKind, Value, EvalError, EvalResult};\n+use locks::MemoryExt;\n+\n+pub type ValidationQuery<'tcx> = ValidationOperand<'tcx, (AbsPlace<'tcx>, Place)>;\n+\n+#[derive(Copy, Clone, Debug, PartialEq)]\n+pub(crate) enum ValidationMode {\n+    Acquire,\n+    /// Recover because the given region ended\n+    Recover(region::Scope),\n+    ReleaseUntil(Option<region::Scope>),\n+}\n+\n+impl ValidationMode {\n+    fn acquiring(self) -> bool {\n+        use self::ValidationMode::*;\n+        match self {\n+            Acquire | Recover(_) => true,\n+            ReleaseUntil(_) => false,\n+        }\n+    }\n+}\n+\n+// Abstract places\n+#[derive(Clone, Debug, PartialEq, Eq, Hash)]\n+pub enum AbsPlace<'tcx> {\n+    Local(mir::Local),\n+    Static(hir::def_id::DefId),\n+    Projection(Box<AbsPlaceProjection<'tcx>>),\n+}\n+\n+type AbsPlaceProjection<'tcx> = mir::Projection<'tcx, AbsPlace<'tcx>, u64, ()>;\n+type AbsPlaceElem<'tcx> = mir::ProjectionElem<'tcx, u64, ()>;\n+\n+impl<'tcx> AbsPlace<'tcx> {\n+    pub fn field(self, f: mir::Field) -> AbsPlace<'tcx> {\n+        self.elem(mir::ProjectionElem::Field(f, ()))\n+    }\n+\n+    pub fn deref(self) -> AbsPlace<'tcx> {\n+        self.elem(mir::ProjectionElem::Deref)\n+    }\n+\n+    pub fn downcast(self, adt_def: &'tcx ty::AdtDef, variant_index: usize) -> AbsPlace<'tcx> {\n+        self.elem(mir::ProjectionElem::Downcast(adt_def, variant_index))\n+    }\n+\n+    pub fn index(self, index: u64) -> AbsPlace<'tcx> {\n+        self.elem(mir::ProjectionElem::Index(index))\n+    }\n+\n+    fn elem(self, elem: AbsPlaceElem<'tcx>) -> AbsPlace<'tcx> {\n+        AbsPlace::Projection(Box::new(AbsPlaceProjection {\n+            base: self,\n+            elem,\n+        }))\n+    }\n+}\n+\n+pub(crate) trait EvalContextExt<'tcx> {\n+    fn abstract_place_projection(&self, proj: &mir::PlaceProjection<'tcx>) -> EvalResult<'tcx, AbsPlaceProjection<'tcx>>;\n+    fn abstract_place(&self, place: &mir::Place<'tcx>) -> EvalResult<'tcx, AbsPlace<'tcx>>;\n+    fn validation_op(\n+        &mut self,\n+        op: ValidationOp,\n+        operand: &ValidationOperand<'tcx, mir::Place<'tcx>>,\n+    ) -> EvalResult<'tcx>;\n+    fn end_region(&mut self, scope: Option<region::Scope>) -> EvalResult<'tcx>;\n+    fn normalize_type_unerased(&self, ty: Ty<'tcx>) -> Ty<'tcx>;\n+    fn field_with_lifetimes(\n+        &mut self,\n+        base: Place,\n+        layout: ty::layout::TyLayout<'tcx>,\n+        i: usize,\n+    ) -> EvalResult<'tcx, Ty<'tcx>>;\n+    fn validate_fields(\n+        &mut self,\n+        query: ValidationQuery<'tcx>,\n+        mode: ValidationMode,\n+    ) -> EvalResult<'tcx>;\n+    fn validate_ptr(\n+        &mut self,\n+        val: Value,\n+        abs_place: AbsPlace<'tcx>,\n+        pointee_ty: Ty<'tcx>,\n+        re: Option<region::Scope>,\n+        mutbl: Mutability,\n+        mode: ValidationMode,\n+    ) -> EvalResult<'tcx>;\n+    fn validate(\n+        &mut self,\n+        query: ValidationQuery<'tcx>,\n+        mode: ValidationMode,\n+    ) -> EvalResult<'tcx>;\n+}\n+\n+impl<'a, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'tcx, super::Evaluator<'tcx>> {\n+    fn abstract_place_projection(&self, proj: &mir::PlaceProjection<'tcx>) -> EvalResult<'tcx, AbsPlaceProjection<'tcx>> {\n+        use self::mir::ProjectionElem::*;\n+\n+        let elem = match proj.elem {\n+            Deref => Deref,\n+            Field(f, _) => Field(f, ()),\n+            Index(v) => {\n+                let value = self.frame().get_local(v)?;\n+                let ty = self.tcx.types.usize;\n+                let n = self.value_to_primval(ValTy { value, ty })?.to_u64()?;\n+                Index(n)\n+            },\n+            ConstantIndex { offset, min_length, from_end } =>\n+                ConstantIndex { offset, min_length, from_end },\n+            Subslice { from, to } =>\n+                Subslice { from, to },\n+            Downcast(adt, sz) => Downcast(adt, sz),\n+        };\n+        Ok(AbsPlaceProjection {\n+            base: self.abstract_place(&proj.base)?,\n+            elem\n+        })\n+    }\n+\n+    fn abstract_place(&self, place: &mir::Place<'tcx>) -> EvalResult<'tcx, AbsPlace<'tcx>> {\n+        Ok(match place {\n+            &mir::Place::Local(l) => AbsPlace::Local(l),\n+            &mir::Place::Static(ref s) => AbsPlace::Static(s.def_id),\n+            &mir::Place::Projection(ref p) =>\n+                AbsPlace::Projection(Box::new(self.abstract_place_projection(&*p)?)),\n+        })\n+    }\n+\n+    // Validity checks\n+    fn validation_op(\n+        &mut self,\n+        op: ValidationOp,\n+        operand: &ValidationOperand<'tcx, mir::Place<'tcx>>,\n+    ) -> EvalResult<'tcx> {\n+        // If mir-emit-validate is set to 0 (i.e., disabled), we may still see validation commands\n+        // because other crates may have been compiled with mir-emit-validate > 0.  Ignore those\n+        // commands.  This makes mir-emit-validate also a flag to control whether miri will do\n+        // validation or not.\n+        if self.tcx.sess.opts.debugging_opts.mir_emit_validate == 0 {\n+            return Ok(());\n+        }\n+        debug_assert!(self.memory.cur_frame == self.cur_frame());\n+\n+        // HACK: Determine if this method is whitelisted and hence we do not perform any validation.\n+        // We currently insta-UB on anything passing around uninitialized memory, so we have to whitelist\n+        // the places that are allowed to do that.\n+        // The second group is stuff libstd does that is forbidden even under relaxed validation.\n+        {\n+            // The regexp we use for filtering\n+            use regex::Regex;\n+            lazy_static! {\n+                static ref RE: Regex = Regex::new(\"^(\\\n+                    (std|alloc::heap::__core)::mem::(uninitialized|forget)::|\\\n+                    <(std|alloc)::heap::Heap as (std::heap|alloc::allocator)::Alloc>::|\\\n+                    <(std|alloc::heap::__core)::mem::ManuallyDrop<T>><.*>::new$|\\\n+                    <(std|alloc::heap::__core)::mem::ManuallyDrop<T> as std::ops::DerefMut><.*>::deref_mut$|\\\n+                    (std|alloc::heap::__core)::ptr::read::|\\\n+                    \\\n+                    <std::sync::Arc<T>><.*>::inner$|\\\n+                    <std::sync::Arc<T>><.*>::drop_slow$|\\\n+                    (std::heap|alloc::allocator)::Layout::for_value::|\\\n+                    (std|alloc::heap::__core)::mem::(size|align)_of_val::\\\n+                )\").unwrap();\n+            }\n+            // Now test\n+            let name = self.frame().instance.to_string();\n+            if RE.is_match(&name) {\n+                return Ok(());\n+            }\n+        }\n+\n+        // We need to monomorphize ty *without* erasing lifetimes\n+        trace!(\"validation_op1: {:?}\", operand.ty.sty);\n+        let ty = operand.ty.subst(self.tcx, self.substs());\n+        trace!(\"validation_op2: {:?}\", operand.ty.sty);\n+        let place = self.eval_place(&operand.place)?;\n+        let abs_place = self.abstract_place(&operand.place)?;\n+        let query = ValidationQuery {\n+            place: (abs_place, place),\n+            ty,\n+            re: operand.re,\n+            mutbl: operand.mutbl,\n+        };\n+\n+        // Check the mode, and also perform mode-specific operations\n+        let mode = match op {\n+            ValidationOp::Acquire => ValidationMode::Acquire,\n+            ValidationOp::Release => ValidationMode::ReleaseUntil(None),\n+            ValidationOp::Suspend(scope) => {\n+                if query.mutbl == MutMutable {\n+                    let lft = DynamicLifetime {\n+                        frame: self.cur_frame(),\n+                        region: Some(scope), // Notably, we only ever suspend things for given regions.\n+                        // Suspending for the entire function does not make any sense.\n+                    };\n+                    trace!(\"Suspending {:?} until {:?}\", query, scope);\n+                    self.machine.suspended.entry(lft).or_insert_with(Vec::new).push(\n+                        query.clone(),\n+                    );\n+                }\n+                ValidationMode::ReleaseUntil(Some(scope))\n+            }\n+        };\n+        self.validate(query, mode)\n+    }\n+\n+    /// Release locks and executes suspensions of the given region (or the entire fn, in case of None).\n+    fn end_region(&mut self, scope: Option<region::Scope>) -> EvalResult<'tcx> {\n+        debug_assert!(self.memory.cur_frame == self.cur_frame());\n+        self.memory.locks_lifetime_ended(scope);\n+        match scope {\n+            Some(scope) => {\n+                // Recover suspended places\n+                let lft = DynamicLifetime {\n+                    frame: self.cur_frame(),\n+                    region: Some(scope),\n+                };\n+                if let Some(queries) = self.machine.suspended.remove(&lft) {\n+                    for query in queries {\n+                        trace!(\"Recovering {:?} from suspension\", query);\n+                        self.validate(query, ValidationMode::Recover(scope))?;\n+                    }\n+                }\n+            }\n+            None => {\n+                // Clean suspension table of current frame\n+                let cur_frame = self.cur_frame();\n+                self.machine.suspended.retain(|lft, _| {\n+                    lft.frame != cur_frame // keep only what is in the other (lower) frames\n+                });\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    fn normalize_type_unerased(&self, ty: Ty<'tcx>) -> Ty<'tcx> {\n+        return normalize_associated_type(self.tcx, &ty);\n+\n+        use syntax::codemap::{Span, DUMMY_SP};\n+\n+        // We copy a bunch of stuff from rustc/infer/mod.rs to be able to tweak its behavior\n+        fn normalize_projections_in<'a, 'gcx, 'tcx, T>(\n+            self_: &InferCtxt<'a, 'gcx, 'tcx>,\n+            param_env: ty::ParamEnv<'tcx>,\n+            value: &T,\n+        ) -> T::Lifted\n+        where\n+            T: TypeFoldable<'tcx> + ty::Lift<'gcx>,\n+        {\n+            let mut selcx = traits::SelectionContext::new(self_);\n+            let cause = traits::ObligationCause::dummy();\n+            let traits::Normalized {\n+                value: result,\n+                obligations,\n+            } = traits::normalize(&mut selcx, param_env, cause, value);\n+\n+            let mut fulfill_cx = traits::FulfillmentContext::new();\n+\n+            for obligation in obligations {\n+                fulfill_cx.register_predicate_obligation(self_, obligation);\n+            }\n+\n+            drain_fulfillment_cx_or_panic(self_, DUMMY_SP, &mut fulfill_cx, &result)\n+        }\n+\n+        fn drain_fulfillment_cx_or_panic<'a, 'gcx, 'tcx, T>(\n+            self_: &InferCtxt<'a, 'gcx, 'tcx>,\n+            span: Span,\n+            fulfill_cx: &mut traits::FulfillmentContext<'tcx>,\n+            result: &T,\n+        ) -> T::Lifted\n+        where\n+            T: TypeFoldable<'tcx> + ty::Lift<'gcx>,\n+        {\n+            // In principle, we only need to do this so long as `result`\n+            // contains unbound type parameters. It could be a slight\n+            // optimization to stop iterating early.\n+            match fulfill_cx.select_all_or_error(self_) {\n+                Ok(()) => { }\n+                Err(errors) => {\n+                    span_bug!(\n+                        span,\n+                        \"Encountered errors `{:?}` resolving bounds after type-checking\",\n+                        errors\n+                    );\n+                }\n+            }\n+\n+            let result = self_.resolve_type_vars_if_possible(result);\n+            let result = self_.tcx.fold_regions(\n+                &result,\n+                &mut false,\n+                |r, _| match *r {\n+                    ty::ReVar(_) => self_.tcx.types.re_erased,\n+                    _ => r,\n+                },\n+            );\n+\n+            match self_.tcx.lift_to_global(&result) {\n+                Some(result) => result,\n+                None => {\n+                    span_bug!(span, \"Uninferred types/regions in `{:?}`\", result);\n+                }\n+            }\n+        }\n+\n+        trait MyTransNormalize<'gcx>: TypeFoldable<'gcx> {\n+            fn my_trans_normalize<'a, 'tcx>(\n+                &self,\n+                infcx: &InferCtxt<'a, 'gcx, 'tcx>,\n+                param_env: ty::ParamEnv<'tcx>,\n+            ) -> Self;\n+        }\n+\n+        macro_rules! items { ($($item:item)+) => ($($item)+) }\n+        macro_rules! impl_trans_normalize {\n+            ($lt_gcx:tt, $($ty:ty),+) => {\n+                items!($(impl<$lt_gcx> MyTransNormalize<$lt_gcx> for $ty {\n+                    fn my_trans_normalize<'a, 'tcx>(&self,\n+                                                infcx: &InferCtxt<'a, $lt_gcx, 'tcx>,\n+                                                param_env: ty::ParamEnv<'tcx>)\n+                                                -> Self {\n+                        normalize_projections_in(infcx, param_env, self)\n+                    }\n+                })+);\n+            }\n+        }\n+\n+        impl_trans_normalize!('gcx,\n+            Ty<'gcx>,\n+            &'gcx Substs<'gcx>,\n+            ty::FnSig<'gcx>,\n+            ty::PolyFnSig<'gcx>,\n+            ty::ClosureSubsts<'gcx>,\n+            ty::PolyTraitRef<'gcx>,\n+            ty::ExistentialTraitRef<'gcx>\n+        );\n+\n+        fn normalize_associated_type<'a, 'tcx, T>(self_: TyCtxt<'a, 'tcx, 'tcx>, value: &T) -> T\n+        where\n+            T: MyTransNormalize<'tcx>,\n+        {\n+            let param_env = ty::ParamEnv::empty(Reveal::All);\n+\n+            if !value.has_projections() {\n+                return value.clone();\n+            }\n+\n+            self_.infer_ctxt().enter(|infcx| {\n+                value.my_trans_normalize(&infcx, param_env)\n+            })\n+        }\n+    }\n+\n+    // This is a copy of `Layout::field`\n+    //\n+    // FIXME: remove once validation does not depend on lifetimes\n+    fn field_with_lifetimes(\n+        &mut self,\n+        base: Place,\n+        mut layout: ty::layout::TyLayout<'tcx>,\n+        i: usize,\n+    ) -> EvalResult<'tcx, Ty<'tcx>> {\n+        match base {\n+            Place::Ptr { extra: PlaceExtra::DowncastVariant(variant_index), .. } => {\n+                layout = layout.for_variant(&self, variant_index);\n+            }\n+            _ => {}\n+        }\n+        let tcx = self.tcx;\n+        Ok(match layout.ty.sty {\n+            ty::TyBool |\n+            ty::TyChar |\n+            ty::TyInt(_) |\n+            ty::TyUint(_) |\n+            ty::TyFloat(_) |\n+            ty::TyFnPtr(_) |\n+            ty::TyNever |\n+            ty::TyFnDef(..) |\n+            ty::TyDynamic(..) |\n+            ty::TyForeign(..) => {\n+                bug!(\"TyLayout::field_type({:?}): not applicable\", layout)\n+            }\n+\n+            // Potentially-fat pointers.\n+            ty::TyRef(_, ty::TypeAndMut { ty: pointee, .. }) |\n+            ty::TyRawPtr(ty::TypeAndMut { ty: pointee, .. }) => {\n+                assert!(i < 2);\n+\n+                // Reuse the fat *T type as its own thin pointer data field.\n+                // This provides information about e.g. DST struct pointees\n+                // (which may have no non-DST form), and will work as long\n+                // as the `Abi` or `FieldPlacement` is checked by users.\n+                if i == 0 {\n+                    return Ok(layout.ty);\n+                }\n+\n+                match tcx.struct_tail(pointee).sty {\n+                    ty::TySlice(_) |\n+                    ty::TyStr => tcx.types.usize,\n+                    ty::TyDynamic(..) => {\n+                        // FIXME(eddyb) use an usize/fn() array with\n+                        // the correct number of vtables slots.\n+                        tcx.mk_imm_ref(tcx.types.re_static, tcx.mk_nil())\n+                    }\n+                    _ => bug!(\"TyLayout::field_type({:?}): not applicable\", layout)\n+                }\n+            }\n+\n+            // Arrays and slices.\n+            ty::TyArray(element, _) |\n+            ty::TySlice(element) => element,\n+            ty::TyStr => tcx.types.u8,\n+\n+            // Tuples, generators and closures.\n+            ty::TyClosure(def_id, ref substs) => {\n+                substs.upvar_tys(def_id, tcx).nth(i).unwrap()\n+            }\n+\n+            ty::TyGenerator(def_id, ref substs, _) => {\n+                substs.field_tys(def_id, tcx).nth(i).unwrap()\n+            }\n+\n+            ty::TyTuple(tys, _) => tys[i],\n+\n+            // SIMD vector types.\n+            ty::TyAdt(def, ..) if def.repr.simd() => {\n+                layout.ty.simd_type(tcx)\n+            }\n+\n+            // ADTs.\n+            ty::TyAdt(def, substs) => {\n+                use rustc::ty::layout::Variants;\n+                match layout.variants {\n+                    Variants::Single { index } => {\n+                        def.variants[index].fields[i].ty(tcx, substs)\n+                    }\n+\n+                    // Discriminant field for enums (where applicable).\n+                    Variants::Tagged { ref discr, .. } |\n+                    Variants::NicheFilling { niche: ref discr, .. } => {\n+                        assert_eq!(i, 0);\n+                        return Ok(discr.value.to_ty(tcx))\n+                    }\n+                }\n+            }\n+\n+            ty::TyProjection(_) | ty::TyAnon(..) | ty::TyParam(_) |\n+            ty::TyInfer(_) | ty::TyError => {\n+                bug!(\"TyLayout::field_type: unexpected type `{}`\", layout.ty)\n+            }\n+        })\n+    }\n+\n+    fn validate_fields(\n+        &mut self,\n+        query: ValidationQuery<'tcx>,\n+        mode: ValidationMode,\n+    ) -> EvalResult<'tcx> {\n+        let mut layout = self.layout_of(query.ty)?;\n+        layout.ty = query.ty;\n+\n+        // TODO: Maybe take visibility/privacy into account.\n+        for idx in 0..layout.fields.count() {\n+            let field = mir::Field::new(idx);\n+            let (field_place, field_layout) =\n+                self.place_field(query.place.1, field, layout)?;\n+            // layout stuff erases lifetimes, get the field ourselves\n+            let field_ty = self.field_with_lifetimes(query.place.1, layout, idx)?;\n+            trace!(\"assuming \\n{:?}\\n == \\n{:?}\\n except for lifetimes\", field_layout.ty, field_ty);\n+            self.validate(\n+                ValidationQuery {\n+                    place: (query.place.0.clone().field(field), field_place),\n+                    ty: field_ty,\n+                    ..query\n+                },\n+                mode,\n+            )?;\n+        }\n+\n+        Ok(())\n+    }\n+\n+    fn validate_ptr(\n+        &mut self,\n+        val: Value,\n+        abs_place: AbsPlace<'tcx>,\n+        pointee_ty: Ty<'tcx>,\n+        re: Option<region::Scope>,\n+        mutbl: Mutability,\n+        mode: ValidationMode,\n+    ) -> EvalResult<'tcx> {\n+        // Check alignment and non-NULLness\n+        let (_, align) = self.size_and_align_of_dst(pointee_ty, val)?;\n+        let ptr = self.into_ptr(val)?;\n+        self.memory.check_align(ptr, align.abi(), None)?;\n+\n+        // Recurse\n+        let pointee_place = self.val_to_place(val, pointee_ty)?;\n+        self.validate(\n+            ValidationQuery {\n+                place: (abs_place.deref(), pointee_place),\n+                ty: pointee_ty,\n+                re,\n+                mutbl,\n+            },\n+            mode,\n+        )\n+    }\n+\n+    /// Validate the place at the given type. If `acquire` is false, just do a release of all write locks\n+    fn validate(\n+        &mut self,\n+        mut query: ValidationQuery<'tcx>,\n+        mode: ValidationMode,\n+    ) -> EvalResult<'tcx> {\n+        use rustc::ty::TypeVariants::*;\n+        use rustc::ty::RegionKind::*;\n+        use rustc::ty::AdtKind;\n+\n+        // No point releasing shared stuff.\n+        if !mode.acquiring() && query.mutbl == MutImmutable {\n+            return Ok(());\n+        }\n+        // When we recover, we may see data whose validity *just* ended.  Do not acquire it.\n+        if let ValidationMode::Recover(ending_ce) = mode {\n+            if query.re == Some(ending_ce) {\n+                return Ok(());\n+            }\n+        }\n+\n+        query.ty = self.normalize_type_unerased(&query.ty);\n+        trace!(\"{:?} on {:#?}\", mode, query);\n+        trace!(\"{:#?}\", query.ty.sty);\n+\n+        // Decide whether this type *owns* the memory it covers (like integers), or whether it\n+        // just assembles pieces (that each own their memory) together to a larger whole.\n+        // TODO: Currently, we don't acquire locks for padding and discriminants. We should.\n+        let is_owning = match query.ty.sty {\n+            TyInt(_) | TyUint(_) | TyRawPtr(_) | TyBool | TyFloat(_) | TyChar | TyStr |\n+            TyRef(..) | TyFnPtr(..) | TyFnDef(..) | TyNever => true,\n+            TyAdt(adt, _) if adt.is_box() => true,\n+            TySlice(_) | TyAdt(_, _) | TyTuple(..) | TyClosure(..) | TyArray(..) |\n+            TyDynamic(..) | TyGenerator(..) | TyForeign(_) => false,\n+            TyParam(_) | TyInfer(_) | TyProjection(_) | TyAnon(..) | TyError => {\n+                bug!(\"I got an incomplete/unnormalized type for validation\")\n+            }\n+        };\n+        if is_owning {\n+            // We need to lock.  So we need memory.  So we have to force_acquire.\n+            // Tracking the same state for locals not backed by memory would just duplicate too\n+            // much machinery.\n+            // FIXME: We ignore alignment.\n+            let (ptr, extra) = self.force_allocation(query.place.1)?.to_ptr_extra_aligned();\n+            // Determine the size\n+            // FIXME: Can we reuse size_and_align_of_dst for Places?\n+            let layout = self.layout_of(query.ty)?;\n+            let len = if !layout.is_unsized() {\n+                assert_eq!(extra, PlaceExtra::None, \"Got a fat ptr to a sized type\");\n+                layout.size.bytes()\n+            } else {\n+                // The only unsized typ we concider \"owning\" is TyStr.\n+                assert_eq!(\n+                    query.ty.sty,\n+                    TyStr,\n+                    \"Found a surprising unsized owning type\"\n+                );\n+                // The extra must be the length, in bytes.\n+                match extra {\n+                    PlaceExtra::Length(len) => len,\n+                    _ => bug!(\"TyStr must have a length as extra\"),\n+                }\n+            };\n+            // Handle locking\n+            if len > 0 {\n+                let ptr = ptr.to_ptr()?;\n+                match query.mutbl {\n+                    MutImmutable => {\n+                        if mode.acquiring() {\n+                            self.memory.acquire_lock(\n+                                ptr,\n+                                len,\n+                                query.re,\n+                                AccessKind::Read,\n+                            )?;\n+                        }\n+                    }\n+                    // No releasing of read locks, ever.\n+                    MutMutable => {\n+                        match mode {\n+                            ValidationMode::Acquire => {\n+                                self.memory.acquire_lock(\n+                                    ptr,\n+                                    len,\n+                                    query.re,\n+                                    AccessKind::Write,\n+                                )?\n+                            }\n+                            ValidationMode::Recover(ending_ce) => {\n+                                self.memory.recover_write_lock(\n+                                    ptr,\n+                                    len,\n+                                    &query.place.0,\n+                                    query.re,\n+                                    ending_ce,\n+                                )?\n+                            }\n+                            ValidationMode::ReleaseUntil(suspended_ce) => {\n+                                self.memory.suspend_write_lock(\n+                                    ptr,\n+                                    len,\n+                                    &query.place.0,\n+                                    suspended_ce,\n+                                )?\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+        let res = do catch {\n+            match query.ty.sty {\n+                TyInt(_) | TyUint(_) | TyRawPtr(_) => {\n+                    if mode.acquiring() {\n+                        // Make sure we can read this.\n+                        let val = self.read_place(query.place.1)?;\n+                        self.follow_by_ref_value(val, query.ty)?;\n+                        // FIXME: It would be great to rule out Undef here, but that doesn't actually work.\n+                        // Passing around undef data is a thing that e.g. Vec::extend_with does.\n+                    }\n+                    Ok(())\n+                }\n+                TyBool | TyFloat(_) | TyChar => {\n+                    if mode.acquiring() {\n+                        let val = self.read_place(query.place.1)?;\n+                        let val = self.value_to_primval(ValTy { value: val, ty: query.ty })?;\n+                        val.to_bytes()?;\n+                        // TODO: Check if these are valid bool/float/codepoint/UTF-8\n+                    }\n+                    Ok(())\n+                }\n+                TyNever => err!(ValidationFailure(format!(\"The empty type is never valid.\"))),\n+                TyRef(region,\n+                    ty::TypeAndMut {\n+                        ty: pointee_ty,\n+                        mutbl,\n+                    }) => {\n+                    let val = self.read_place(query.place.1)?;\n+                    // Sharing restricts our context\n+                    if mutbl == MutImmutable {\n+                        query.mutbl = MutImmutable;\n+                    }\n+                    // Inner lifetimes *outlive* outer ones, so only if we have no lifetime restriction yet,\n+                    // we record the region of this borrow to the context.\n+                    if query.re == None {\n+                        match *region {\n+                            ReScope(scope) => query.re = Some(scope),\n+                            // It is possible for us to encounter erased lifetimes here because the lifetimes in\n+                            // this functions' Subst will be erased.\n+                            _ => {}\n+                        }\n+                    }\n+                    self.validate_ptr(val, query.place.0, pointee_ty, query.re, query.mutbl, mode)\n+                }\n+                TyAdt(adt, _) if adt.is_box() => {\n+                    let val = self.read_place(query.place.1)?;\n+                    self.validate_ptr(val, query.place.0, query.ty.boxed_ty(), query.re, query.mutbl, mode)\n+                }\n+                TyFnPtr(_sig) => {\n+                    let ptr = self.read_place(query.place.1)?;\n+                    let ptr = self.into_ptr(ptr)?.to_ptr()?;\n+                    self.memory.get_fn(ptr)?;\n+                    // TODO: Check if the signature matches (should be the same check as what terminator/mod.rs already does on call?).\n+                    Ok(())\n+                }\n+                TyFnDef(..) => {\n+                    // This is a zero-sized type with all relevant data sitting in the type.\n+                    // There is nothing to validate.\n+                    Ok(())\n+                }\n+\n+                // Compound types\n+                TyStr => {\n+                    // TODO: Validate strings\n+                    Ok(())\n+                }\n+                TySlice(elem_ty) => {\n+                    let len = match query.place.1 {\n+                        Place::Ptr { extra: PlaceExtra::Length(len), .. } => len,\n+                        _ => {\n+                            bug!(\n+                                \"acquire_valid of a TySlice given non-slice place: {:?}\",\n+                                query.place\n+                            )\n+                        }\n+                    };\n+                    for i in 0..len {\n+                        let inner_place = self.place_index(query.place.1, query.ty, i)?;\n+                        self.validate(\n+                            ValidationQuery {\n+                                place: (query.place.0.clone().index(i), inner_place),\n+                                ty: elem_ty,\n+                                ..query\n+                            },\n+                            mode,\n+                        )?;\n+                    }\n+                    Ok(())\n+                }\n+                TyArray(elem_ty, len) => {\n+                    let len = len.val.to_const_int().unwrap().to_u64().unwrap();\n+                    for i in 0..len {\n+                        let inner_place = self.place_index(query.place.1, query.ty, i as u64)?;\n+                        self.validate(\n+                            ValidationQuery {\n+                                place: (query.place.0.clone().index(i as u64), inner_place),\n+                                ty: elem_ty,\n+                                ..query\n+                            },\n+                            mode,\n+                        )?;\n+                    }\n+                    Ok(())\n+                }\n+                TyDynamic(_data, _region) => {\n+                    // Check that this is a valid vtable\n+                    let vtable = match query.place.1 {\n+                        Place::Ptr { extra: PlaceExtra::Vtable(vtable), .. } => vtable,\n+                        _ => {\n+                            bug!(\n+                                \"acquire_valid of a TyDynamic given non-trait-object place: {:?}\",\n+                                query.place\n+                            )\n+                        }\n+                    };\n+                    self.read_size_and_align_from_vtable(vtable)?;\n+                    // TODO: Check that the vtable contains all the function pointers we expect it to have.\n+                    // Trait objects cannot have any operations performed\n+                    // on them directly.  We cannot, in general, even acquire any locks as the trait object *could*\n+                    // contain an UnsafeCell.  If we call functions to get access to data, we will validate\n+                    // their return values.  So, it doesn't seem like there's anything else to do.\n+                    Ok(())\n+                }\n+                TyAdt(adt, _) => {\n+                    if Some(adt.did) == self.tcx.lang_items().unsafe_cell_type() &&\n+                        query.mutbl == MutImmutable\n+                    {\n+                        // No locks for shared unsafe cells.  Also no other validation, the only field is private anyway.\n+                        return Ok(());\n+                    }\n+\n+                    match adt.adt_kind() {\n+                        AdtKind::Enum => {\n+                            let discr = self.read_discriminant_value(query.place.1, query.ty)?;\n+\n+                            // Get variant index for discriminant\n+                            let variant_idx = adt.discriminants(self.tcx).position(|variant_discr| {\n+                                variant_discr.to_u128_unchecked() == discr\n+                            });\n+                            let variant_idx = match variant_idx {\n+                                Some(val) => val,\n+                                None => return err!(InvalidDiscriminant),\n+                            };\n+                            let variant = &adt.variants[variant_idx];\n+\n+                            if variant.fields.len() > 0 {\n+                                // Downcast to this variant, if needed\n+                                let place = if adt.is_enum() {\n+                                    (\n+                                        query.place.0.downcast(adt, variant_idx),\n+                                        self.eval_place_projection(\n+                                            query.place.1,\n+                                            query.ty,\n+                                            &mir::ProjectionElem::Downcast(adt, variant_idx),\n+                                        )?,\n+                                    )\n+                                } else {\n+                                    query.place\n+                                };\n+\n+                                // Recursively validate the fields\n+                                self.validate_fields(\n+                                    ValidationQuery { place, ..query },\n+                                    mode,\n+                                )\n+                            } else {\n+                                // No fields, nothing left to check.  Downcasting may fail, e.g. in case of a CEnum.\n+                                Ok(())\n+                            }\n+                        }\n+                        AdtKind::Struct => {\n+                            self.validate_fields(query, mode)\n+                        }\n+                        AdtKind::Union => {\n+                            // No guarantees are provided for union types.\n+                            // TODO: Make sure that all access to union fields is unsafe; otherwise, we may have some checking to do (but what exactly?)\n+                            Ok(())\n+                        }\n+                    }\n+                }\n+                TyTuple(..) |\n+                TyClosure(..) => {\n+                    // TODO: Check if the signature matches for `TyClosure`\n+                    // (should be the same check as what terminator/mod.rs already does on call?).\n+                    // Is there other things we can/should check?  Like vtable pointers?\n+                    self.validate_fields(query, mode)\n+                }\n+                // FIXME: generators aren't validated right now\n+                TyGenerator(..) => Ok(()),\n+                _ => bug!(\"We already established that this is a type we support. ({})\", query.ty),\n+            }\n+        };\n+        match res {\n+            // ReleaseUntil(None) of an uninitalized variable is a NOP.  This is needed because\n+            // we have to release the return value of a function; due to destination-passing-style\n+            // the callee may directly write there.\n+            // TODO: Ideally we would know whether the destination is already initialized, and only\n+            // release if it is.  But of course that can't even always be statically determined.\n+            Err(EvalError { kind: EvalErrorKind::ReadUndefBytes, .. })\n+                if mode == ValidationMode::ReleaseUntil(None) => {\n+                return Ok(());\n+            }\n+            res => res,\n+        }\n+    }\n+}"}]}