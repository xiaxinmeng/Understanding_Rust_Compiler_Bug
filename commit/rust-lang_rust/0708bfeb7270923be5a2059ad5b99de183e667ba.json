{"sha": "0708bfeb7270923be5a2059ad5b99de183e667ba", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA3MDhiZmViNzI3MDkyM2JlNWEyMDU5YWQ1Yjk5ZGUxODNlNjY3YmE=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-01-04T18:02:54Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-01-04T18:02:54Z"}, "message": "Merge #7159\n\n7159: Refactor mbe to reduce clone and copying r=edwin0cheng a=edwin0cheng\n\nbors r+\n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>", "tree": {"sha": "bb7ef6ad070b09e0cd5738a7a7a6f1b430009e8e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bb7ef6ad070b09e0cd5738a7a7a6f1b430009e8e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0708bfeb7270923be5a2059ad5b99de183e667ba", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJf81hOCRBK7hj4Ov3rIwAAdHIIAC6llevELhSqNotosezftCaZ\nxj3FxUka9gFBEipU+4yaWGE01gvZ16h0Imv5P7puo23M5lidPFztSw0nEkGExJ5f\niqCVoc4VwPSdEIAsER3hoB5CyEoY6hmnXv+2s3Wvrai85Ipv23RdPK1qYw4sotxY\nmsY5V4tOkqfpHcPDMC25e8UHv7keHXSK+1OGMVHict5gagkSIgVx+ldgRTp0FP7M\nnR+btfwW3iQhdJ/HBeTC6DXFlR0bHusxjga6cHxKKkbgR2ovJkBXt7Abb01bj+1N\n77XpDq+XDOZDgeXwPP5j6HFh3i6nOYu+s4rnYihqx8LEzbfXBDwdlOJq3315JXk=\n=lTR6\n-----END PGP SIGNATURE-----\n", "payload": "tree bb7ef6ad070b09e0cd5738a7a7a6f1b430009e8e\nparent c96b4eec957e53802817384ca3c58d834f06d6db\nparent d387bfdc4abc47ff62f1dffe7d41ce2bb11e7a00\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1609783374 +0000\ncommitter GitHub <noreply@github.com> 1609783374 +0000\n\nMerge #7159\n\n7159: Refactor mbe to reduce clone and copying r=edwin0cheng a=edwin0cheng\n\nbors r+\n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0708bfeb7270923be5a2059ad5b99de183e667ba", "html_url": "https://github.com/rust-lang/rust/commit/0708bfeb7270923be5a2059ad5b99de183e667ba", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0708bfeb7270923be5a2059ad5b99de183e667ba/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c96b4eec957e53802817384ca3c58d834f06d6db", "url": "https://api.github.com/repos/rust-lang/rust/commits/c96b4eec957e53802817384ca3c58d834f06d6db", "html_url": "https://github.com/rust-lang/rust/commit/c96b4eec957e53802817384ca3c58d834f06d6db"}, {"sha": "d387bfdc4abc47ff62f1dffe7d41ce2bb11e7a00", "url": "https://api.github.com/repos/rust-lang/rust/commits/d387bfdc4abc47ff62f1dffe7d41ce2bb11e7a00", "html_url": "https://github.com/rust-lang/rust/commit/d387bfdc4abc47ff62f1dffe7d41ce2bb11e7a00"}], "stats": {"total": 324, "additions": 172, "deletions": 152}, "files": [{"sha": "1923daca55766ba00ce6fe8fb9b1505c4fe68df6", "filename": "crates/hir_expand/src/proc_macro.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fhir_expand%2Fsrc%2Fproc_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fhir_expand%2Fsrc%2Fproc_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fproc_macro.rs?ref=0708bfeb7270923be5a2059ad5b99de183e667ba", "patch": "@@ -58,7 +58,7 @@ impl ProcMacroExpander {\n }\n \n fn eat_punct(cursor: &mut Cursor, c: char) -> bool {\n-    if let Some(tt::TokenTree::Leaf(tt::Leaf::Punct(punct))) = cursor.token_tree() {\n+    if let Some(tt::buffer::TokenTreeRef::Leaf(tt::Leaf::Punct(punct), _)) = cursor.token_tree() {\n         if punct.char == c {\n             *cursor = cursor.bump();\n             return true;\n@@ -68,7 +68,7 @@ fn eat_punct(cursor: &mut Cursor, c: char) -> bool {\n }\n \n fn eat_subtree(cursor: &mut Cursor, kind: tt::DelimiterKind) -> bool {\n-    if let Some(tt::TokenTree::Subtree(subtree)) = cursor.token_tree() {\n+    if let Some(tt::buffer::TokenTreeRef::Subtree(subtree, _)) = cursor.token_tree() {\n         if Some(kind) == subtree.delimiter_kind() {\n             *cursor = cursor.bump_subtree();\n             return true;\n@@ -78,7 +78,7 @@ fn eat_subtree(cursor: &mut Cursor, kind: tt::DelimiterKind) -> bool {\n }\n \n fn eat_ident(cursor: &mut Cursor, t: &str) -> bool {\n-    if let Some(tt::TokenTree::Leaf(tt::Leaf::Ident(ident))) = cursor.token_tree() {\n+    if let Some(tt::buffer::TokenTreeRef::Leaf(tt::Leaf::Ident(ident), _)) = cursor.token_tree() {\n         if t == ident.text.as_str() {\n             *cursor = cursor.bump();\n             return true;\n@@ -88,7 +88,7 @@ fn eat_ident(cursor: &mut Cursor, t: &str) -> bool {\n }\n \n fn remove_derive_attrs(tt: &tt::Subtree) -> Option<tt::Subtree> {\n-    let buffer = TokenBuffer::new(&tt.token_trees);\n+    let buffer = TokenBuffer::from_tokens(&tt.token_trees);\n     let mut p = buffer.begin();\n     let mut result = tt::Subtree::default();\n \n@@ -106,7 +106,7 @@ fn remove_derive_attrs(tt: &tt::Subtree) -> Option<tt::Subtree> {\n             }\n         }\n \n-        result.token_trees.push(curr.token_tree()?.clone());\n+        result.token_trees.push(curr.token_tree()?.cloned());\n         p = curr.bump();\n     }\n "}, {"sha": "fdc8844cef0cdd1af52f672f61e714bf98a46dce", "filename": "crates/mbe/src/mbe_expander/matcher.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fmbe%2Fsrc%2Fmbe_expander%2Fmatcher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fmbe%2Fsrc%2Fmbe_expander%2Fmatcher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fmbe_expander%2Fmatcher.rs?ref=0708bfeb7270923be5a2059ad5b99de183e667ba", "patch": "@@ -309,7 +309,7 @@ impl<'a> TtIter<'a> {\n             }\n         }\n \n-        let buffer = TokenBuffer::new(&self.inner.as_slice());\n+        let buffer = TokenBuffer::from_tokens(&self.inner.as_slice());\n         let mut src = SubtreeTokenSource::new(&buffer);\n         let mut sink = OffsetTokenSink { cursor: buffer.begin(), error: false };\n \n@@ -336,11 +336,11 @@ impl<'a> TtIter<'a> {\n             err = Some(err!(\"no tokens consumed\"));\n         }\n         let res = match res.len() {\n-            1 => Some(res[0].clone()),\n+            1 => Some(res[0].cloned()),\n             0 => None,\n             _ => Some(tt::TokenTree::Subtree(tt::Subtree {\n                 delimiter: None,\n-                token_trees: res.into_iter().cloned().collect(),\n+                token_trees: res.into_iter().map(|it| it.cloned()).collect(),\n             })),\n         };\n         ExpandResult { value: res, err }"}, {"sha": "d7433bd353c7ea37aa3f979baafbd0aacbf736fc", "filename": "crates/mbe/src/subtree_source.rs", "status": "modified", "additions": 63, "deletions": 89, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fmbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fmbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsubtree_source.rs?ref=0708bfeb7270923be5a2059ad5b99de183e667ba", "patch": "@@ -1,143 +1,117 @@\n //! FIXME: write short doc here\n \n use parser::{Token, TokenSource};\n-use std::cell::{Cell, Ref, RefCell};\n use syntax::{lex_single_syntax_kind, SmolStr, SyntaxKind, SyntaxKind::*, T};\n-use tt::buffer::{Cursor, TokenBuffer};\n+use tt::buffer::TokenBuffer;\n \n #[derive(Debug, Clone, Eq, PartialEq)]\n struct TtToken {\n-    kind: SyntaxKind,\n-    is_joint_to_next: bool,\n+    tt: Token,\n     text: SmolStr,\n }\n \n-pub(crate) struct SubtreeTokenSource<'a> {\n-    cached_cursor: Cell<Cursor<'a>>,\n-    cached: RefCell<Vec<Option<TtToken>>>,\n+pub(crate) struct SubtreeTokenSource {\n+    cached: Vec<TtToken>,\n     curr: (Token, usize),\n }\n \n-impl<'a> SubtreeTokenSource<'a> {\n+impl<'a> SubtreeTokenSource {\n     // Helper function used in test\n     #[cfg(test)]\n     pub(crate) fn text(&self) -> SmolStr {\n-        match *self.get(self.curr.1) {\n+        match self.cached.get(self.curr.1) {\n             Some(ref tt) => tt.text.clone(),\n             _ => SmolStr::new(\"\"),\n         }\n     }\n }\n \n-impl<'a> SubtreeTokenSource<'a> {\n-    pub(crate) fn new(buffer: &'a TokenBuffer) -> SubtreeTokenSource<'a> {\n-        let cursor = buffer.begin();\n+impl<'a> SubtreeTokenSource {\n+    pub(crate) fn new(buffer: &TokenBuffer) -> SubtreeTokenSource {\n+        let mut current = buffer.begin();\n+        let mut cached = Vec::with_capacity(100);\n \n-        let mut res = SubtreeTokenSource {\n-            curr: (Token { kind: EOF, is_jointed_to_next: false }, 0),\n-            cached_cursor: Cell::new(cursor),\n-            cached: RefCell::new(Vec::with_capacity(10)),\n-        };\n-        res.curr = (res.mk_token(0), 0);\n-        res\n-    }\n+        while !current.eof() {\n+            let cursor = current;\n+            let tt = cursor.token_tree();\n \n-    fn mk_token(&self, pos: usize) -> Token {\n-        match *self.get(pos) {\n-            Some(ref tt) => Token { kind: tt.kind, is_jointed_to_next: tt.is_joint_to_next },\n-            None => Token { kind: EOF, is_jointed_to_next: false },\n-        }\n-    }\n-\n-    fn get(&self, pos: usize) -> Ref<Option<TtToken>> {\n-        fn is_lifetime(c: Cursor) -> Option<(Cursor, SmolStr)> {\n-            let tkn = c.token_tree();\n-\n-            if let Some(tt::TokenTree::Leaf(tt::Leaf::Punct(punct))) = tkn {\n+            // Check if it is lifetime\n+            if let Some(tt::buffer::TokenTreeRef::Leaf(tt::Leaf::Punct(punct), _)) = tt {\n                 if punct.char == '\\'' {\n-                    let next = c.bump();\n-                    if let Some(tt::TokenTree::Leaf(tt::Leaf::Ident(ident))) = next.token_tree() {\n-                        let res_cursor = next.bump();\n-                        let text = SmolStr::new(\"'\".to_string() + &ident.to_string());\n-\n-                        return Some((res_cursor, text));\n+                    let next = cursor.bump();\n+                    if let Some(tt::buffer::TokenTreeRef::Leaf(tt::Leaf::Ident(ident), _)) =\n+                        next.token_tree()\n+                    {\n+                        let text = SmolStr::new(\"'\".to_string() + &ident.text);\n+                        cached.push(TtToken {\n+                            tt: Token { kind: LIFETIME_IDENT, is_jointed_to_next: false },\n+                            text,\n+                        });\n+                        current = next.bump();\n+                        continue;\n                     } else {\n                         panic!(\"Next token must be ident : {:#?}\", next.token_tree());\n                     }\n                 }\n             }\n \n-            None\n-        }\n-\n-        if pos < self.cached.borrow().len() {\n-            return Ref::map(self.cached.borrow(), |c| &c[pos]);\n-        }\n-\n-        {\n-            let mut cached = self.cached.borrow_mut();\n-            while pos >= cached.len() {\n-                let cursor = self.cached_cursor.get();\n-                if cursor.eof() {\n-                    cached.push(None);\n-                    continue;\n+            current = match tt {\n+                Some(tt::buffer::TokenTreeRef::Leaf(leaf, _)) => {\n+                    cached.push(convert_leaf(&leaf));\n+                    cursor.bump()\n                 }\n-\n-                if let Some((curr, text)) = is_lifetime(cursor) {\n-                    cached.push(Some(TtToken {\n-                        kind: LIFETIME_IDENT,\n-                        is_joint_to_next: false,\n-                        text,\n-                    }));\n-                    self.cached_cursor.set(curr);\n-                    continue;\n+                Some(tt::buffer::TokenTreeRef::Subtree(subtree, _)) => {\n+                    cached.push(convert_delim(subtree.delimiter_kind(), false));\n+                    cursor.subtree().unwrap()\n                 }\n-\n-                match cursor.token_tree() {\n-                    Some(tt::TokenTree::Leaf(leaf)) => {\n-                        cached.push(Some(convert_leaf(&leaf)));\n-                        self.cached_cursor.set(cursor.bump());\n-                    }\n-                    Some(tt::TokenTree::Subtree(subtree)) => {\n-                        self.cached_cursor.set(cursor.subtree().unwrap());\n-                        cached.push(Some(convert_delim(subtree.delimiter_kind(), false)));\n-                    }\n-                    None => {\n-                        if let Some(subtree) = cursor.end() {\n-                            cached.push(Some(convert_delim(subtree.delimiter_kind(), true)));\n-                            self.cached_cursor.set(cursor.bump());\n-                        }\n+                None => {\n+                    if let Some(subtree) = cursor.end() {\n+                        cached.push(convert_delim(subtree.delimiter_kind(), true));\n+                        cursor.bump()\n+                    } else {\n+                        continue;\n                     }\n                 }\n-            }\n+            };\n         }\n \n-        Ref::map(self.cached.borrow(), |c| &c[pos])\n+        let mut res = SubtreeTokenSource {\n+            curr: (Token { kind: EOF, is_jointed_to_next: false }, 0),\n+            cached,\n+        };\n+        res.curr = (res.token(0), 0);\n+        res\n+    }\n+\n+    fn token(&self, pos: usize) -> Token {\n+        match self.cached.get(pos) {\n+            Some(it) => it.tt,\n+            None => Token { kind: EOF, is_jointed_to_next: false },\n+        }\n     }\n }\n \n-impl<'a> TokenSource for SubtreeTokenSource<'a> {\n+impl<'a> TokenSource for SubtreeTokenSource {\n     fn current(&self) -> Token {\n         self.curr.0\n     }\n \n     /// Lookahead n token\n     fn lookahead_nth(&self, n: usize) -> Token {\n-        self.mk_token(self.curr.1 + n)\n+        self.token(self.curr.1 + n)\n     }\n \n     /// bump cursor to next token\n     fn bump(&mut self) {\n         if self.current().kind == EOF {\n             return;\n         }\n-\n-        self.curr = (self.mk_token(self.curr.1 + 1), self.curr.1 + 1);\n+        self.curr = (self.token(self.curr.1 + 1), self.curr.1 + 1);\n     }\n \n     /// Is the current token a specified keyword?\n     fn is_keyword(&self, kw: &str) -> bool {\n-        match *self.get(self.curr.1) {\n+        match self.cached.get(self.curr.1) {\n             Some(ref t) => t.text == *kw,\n             _ => false,\n         }\n@@ -155,7 +129,7 @@ fn convert_delim(d: Option<tt::DelimiterKind>, closing: bool) -> TtToken {\n     let idx = closing as usize;\n     let kind = kinds[idx];\n     let text = if !texts.is_empty() { &texts[idx..texts.len() - (1 - idx)] } else { \"\" };\n-    TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text) }\n+    TtToken { tt: Token { kind, is_jointed_to_next: false }, text: SmolStr::new(text) }\n }\n \n fn convert_literal(l: &tt::Literal) -> TtToken {\n@@ -169,7 +143,7 @@ fn convert_literal(l: &tt::Literal) -> TtToken {\n         })\n         .unwrap_or_else(|| panic!(\"Fail to convert given literal {:#?}\", &l));\n \n-    TtToken { kind, is_joint_to_next: false, text: l.text.clone() }\n+    TtToken { tt: Token { kind, is_jointed_to_next: false }, text: l.text.clone() }\n }\n \n fn convert_ident(ident: &tt::Ident) -> TtToken {\n@@ -180,7 +154,7 @@ fn convert_ident(ident: &tt::Ident) -> TtToken {\n         _ => SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT),\n     };\n \n-    TtToken { kind, is_joint_to_next: false, text: ident.text.clone() }\n+    TtToken { tt: Token { kind, is_jointed_to_next: false }, text: ident.text.clone() }\n }\n \n fn convert_punct(p: tt::Punct) -> TtToken {\n@@ -194,7 +168,7 @@ fn convert_punct(p: tt::Punct) -> TtToken {\n         let s: &str = p.char.encode_utf8(&mut buf);\n         SmolStr::new(s)\n     };\n-    TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n+    TtToken { tt: Token { kind, is_jointed_to_next: p.spacing == tt::Spacing::Joint }, text }\n }\n \n fn convert_leaf(leaf: &tt::Leaf) -> TtToken {\n@@ -208,6 +182,7 @@ fn convert_leaf(leaf: &tt::Leaf) -> TtToken {\n #[cfg(test)]\n mod tests {\n     use super::{convert_literal, TtToken};\n+    use parser::Token;\n     use syntax::{SmolStr, SyntaxKind};\n \n     #[test]\n@@ -218,8 +193,7 @@ mod tests {\n                 text: SmolStr::new(\"-42.0\")\n             }),\n             TtToken {\n-                kind: SyntaxKind::FLOAT_NUMBER,\n-                is_joint_to_next: false,\n+                tt: Token { kind: SyntaxKind::FLOAT_NUMBER, is_jointed_to_next: false },\n                 text: SmolStr::new(\"-42.0\")\n             }\n         );"}, {"sha": "671036e1ca60263cad25940622908cff8dd4704c", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 25, "deletions": 26, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=0708bfeb7270923be5a2059ad5b99de183e667ba", "patch": "@@ -70,15 +70,12 @@ pub fn token_tree_to_syntax_node(\n     tt: &tt::Subtree,\n     fragment_kind: FragmentKind,\n ) -> Result<(Parse<SyntaxNode>, TokenMap), ExpandError> {\n-    let tmp;\n-    let tokens = match tt {\n-        tt::Subtree { delimiter: None, token_trees } => token_trees.as_slice(),\n-        _ => {\n-            tmp = [tt.clone().into()];\n-            &tmp[..]\n+    let buffer = match tt {\n+        tt::Subtree { delimiter: None, token_trees } => {\n+            TokenBuffer::from_tokens(token_trees.as_slice())\n         }\n+        _ => TokenBuffer::from_subtree(tt),\n     };\n-    let buffer = TokenBuffer::new(&tokens);\n     let mut token_source = SubtreeTokenSource::new(&buffer);\n     let mut tree_sink = TtTreeSink::new(buffer.begin());\n     parser::parse_fragment(&mut token_source, &mut tree_sink, fragment_kind);\n@@ -414,7 +411,7 @@ trait TokenConvertor {\n     fn id_alloc(&mut self) -> &mut TokenIdAlloc;\n }\n \n-impl<'a> SrcToken for (RawToken, &'a str) {\n+impl<'a> SrcToken for (&'a RawToken, &'a str) {\n     fn kind(&self) -> SyntaxKind {\n         self.0.kind\n     }\n@@ -431,7 +428,7 @@ impl<'a> SrcToken for (RawToken, &'a str) {\n impl RawConvertor<'_> {}\n \n impl<'a> TokenConvertor for RawConvertor<'a> {\n-    type Token = (RawToken, &'a str);\n+    type Token = (&'a RawToken, &'a str);\n \n     fn convert_doc_comment(&self, token: &Self::Token) -> Option<Vec<tt::TokenTree>> {\n         convert_doc_comment(&doc_comment(token.1))\n@@ -442,11 +439,11 @@ impl<'a> TokenConvertor for RawConvertor<'a> {\n         let range = TextRange::at(self.offset, token.len);\n         self.offset += token.len;\n \n-        Some(((*token, &self.text[range]), range))\n+        Some(((token, &self.text[range]), range))\n     }\n \n     fn peek(&self) -> Option<Self::Token> {\n-        let token = self.inner.as_slice().get(0).cloned();\n+        let token = self.inner.as_slice().get(0);\n \n         token.map(|it| {\n             let range = TextRange::at(self.offset, it.len);\n@@ -601,17 +598,16 @@ impl<'a> TtTreeSink<'a> {\n     }\n }\n \n-fn delim_to_str(d: Option<tt::DelimiterKind>, closing: bool) -> SmolStr {\n+fn delim_to_str(d: Option<tt::DelimiterKind>, closing: bool) -> &'static str {\n     let texts = match d {\n         Some(tt::DelimiterKind::Parenthesis) => \"()\",\n         Some(tt::DelimiterKind::Brace) => \"{}\",\n         Some(tt::DelimiterKind::Bracket) => \"[]\",\n-        None => return \"\".into(),\n+        None => return \"\",\n     };\n \n     let idx = closing as usize;\n-    let text = &texts[idx..texts.len() - (1 - idx)];\n-    text.into()\n+    &texts[idx..texts.len() - (1 - idx)]\n }\n \n impl<'a> TreeSink for TtTreeSink<'a> {\n@@ -626,29 +622,32 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n \n         let mut last = self.cursor;\n         for _ in 0..n_tokens {\n+            let tmp_str: SmolStr;\n             if self.cursor.eof() {\n                 break;\n             }\n             last = self.cursor;\n-            let text: SmolStr = match self.cursor.token_tree() {\n-                Some(tt::TokenTree::Leaf(leaf)) => {\n+            let text: &str = match self.cursor.token_tree() {\n+                Some(tt::buffer::TokenTreeRef::Leaf(leaf, _)) => {\n                     // Mark the range if needed\n                     let (text, id) = match leaf {\n-                        tt::Leaf::Ident(ident) => (ident.text.clone(), ident.id),\n+                        tt::Leaf::Ident(ident) => (&ident.text, ident.id),\n                         tt::Leaf::Punct(punct) => {\n                             assert!(punct.char.is_ascii());\n                             let char = &(punct.char as u8);\n-                            let text = std::str::from_utf8(std::slice::from_ref(char)).unwrap();\n-                            (SmolStr::new_inline(text), punct.id)\n+                            tmp_str = SmolStr::new_inline(\n+                                std::str::from_utf8(std::slice::from_ref(char)).unwrap(),\n+                            );\n+                            (&tmp_str, punct.id)\n                         }\n-                        tt::Leaf::Literal(lit) => (lit.text.clone(), lit.id),\n+                        tt::Leaf::Literal(lit) => (&lit.text, lit.id),\n                     };\n                     let range = TextRange::at(self.text_pos, TextSize::of(text.as_str()));\n                     self.token_map.insert(id, range);\n                     self.cursor = self.cursor.bump();\n                     text\n                 }\n-                Some(tt::TokenTree::Subtree(subtree)) => {\n+                Some(tt::buffer::TokenTreeRef::Subtree(subtree, _)) => {\n                     self.cursor = self.cursor.subtree().unwrap();\n                     if let Some(id) = subtree.delimiter.map(|it| it.id) {\n                         self.open_delims.insert(id, self.text_pos);\n@@ -672,7 +671,7 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n                 }\n             };\n             self.buf += &text;\n-            self.text_pos += TextSize::of(text.as_str());\n+            self.text_pos += TextSize::of(text);\n         }\n \n         let text = SmolStr::new(self.buf.as_str());\n@@ -682,8 +681,8 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n         // Add whitespace between adjoint puncts\n         let next = last.bump();\n         if let (\n-            Some(tt::TokenTree::Leaf(tt::Leaf::Punct(curr))),\n-            Some(tt::TokenTree::Leaf(tt::Leaf::Punct(_))),\n+            Some(tt::buffer::TokenTreeRef::Leaf(tt::Leaf::Punct(curr), _)),\n+            Some(tt::buffer::TokenTreeRef::Leaf(tt::Leaf::Punct(_), _)),\n         ) = (last.token_tree(), next.token_tree())\n         {\n             // Note: We always assume the semi-colon would be the last token in\n@@ -742,7 +741,7 @@ mod tests {\n         )\n         .expand_tt(\"literals!(foo);\");\n         let tts = &[expansion.into()];\n-        let buffer = tt::buffer::TokenBuffer::new(tts);\n+        let buffer = tt::buffer::TokenBuffer::from_tokens(tts);\n         let mut tt_src = SubtreeTokenSource::new(&buffer);\n         let mut tokens = vec![];\n         while tt_src.current().kind != EOF {"}, {"sha": "3606c887dc1b5735f6e4bbe5fc1a9d70c055c1e3", "filename": "crates/tt/src/buffer.rs", "status": "modified", "additions": 76, "deletions": 29, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Ftt%2Fsrc%2Fbuffer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0708bfeb7270923be5a2059ad5b99de183e667ba/crates%2Ftt%2Fsrc%2Fbuffer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Ftt%2Fsrc%2Fbuffer.rs?ref=0708bfeb7270923be5a2059ad5b99de183e667ba", "patch": "@@ -1,6 +1,6 @@\n //! FIXME: write short doc here\n \n-use crate::{Subtree, TokenTree};\n+use crate::{Leaf, Subtree, TokenTree};\n \n #[derive(Copy, Clone, Debug, Eq, PartialEq)]\n struct EntryId(usize);\n@@ -13,7 +13,7 @@ struct EntryPtr(EntryId, usize);\n #[derive(Debug)]\n enum Entry<'t> {\n     // Mimicking types from proc-macro.\n-    Subtree(&'t TokenTree, EntryId),\n+    Subtree(Option<&'t TokenTree>, &'t Subtree, EntryId),\n     Leaf(&'t TokenTree),\n     // End entries contain a pointer to the entry from the containing\n     // token tree, or None if this is the outermost level.\n@@ -27,49 +27,76 @@ pub struct TokenBuffer<'t> {\n     buffers: Vec<Box<[Entry<'t>]>>,\n }\n \n-impl<'t> TokenBuffer<'t> {\n-    pub fn new(tokens: &'t [TokenTree]) -> TokenBuffer<'t> {\n-        let mut buffers = vec![];\n-\n-        let idx = TokenBuffer::new_inner(tokens, &mut buffers, None);\n-        assert_eq!(idx, 0);\n-\n-        TokenBuffer { buffers }\n-    }\n+trait TokenList<'a> {\n+    fn entries(&self) -> (Vec<(usize, (&'a Subtree, Option<&'a TokenTree>))>, Vec<Entry<'a>>);\n+}\n \n-    fn new_inner(\n-        tokens: &'t [TokenTree],\n-        buffers: &mut Vec<Box<[Entry<'t>]>>,\n-        next: Option<EntryPtr>,\n-    ) -> usize {\n+impl<'a> TokenList<'a> for &'a [TokenTree] {\n+    fn entries(&self) -> (Vec<(usize, (&'a Subtree, Option<&'a TokenTree>))>, Vec<Entry<'a>>) {\n         // Must contain everything in tokens and then the Entry::End\n-        let start_capacity = tokens.len() + 1;\n+        let start_capacity = self.len() + 1;\n         let mut entries = Vec::with_capacity(start_capacity);\n         let mut children = vec![];\n-\n-        for (idx, tt) in tokens.iter().enumerate() {\n+        for (idx, tt) in self.iter().enumerate() {\n             match tt {\n                 TokenTree::Leaf(_) => {\n                     entries.push(Entry::Leaf(tt));\n                 }\n                 TokenTree::Subtree(subtree) => {\n                     entries.push(Entry::End(None));\n-                    children.push((idx, (subtree, tt)));\n+                    children.push((idx, (subtree, Some(tt))));\n                 }\n             }\n         }\n+        (children, entries)\n+    }\n+}\n+\n+impl<'a> TokenList<'a> for &'a Subtree {\n+    fn entries(&self) -> (Vec<(usize, (&'a Subtree, Option<&'a TokenTree>))>, Vec<Entry<'a>>) {\n+        // Must contain everything in tokens and then the Entry::End\n+        let mut entries = vec![];\n+        let mut children = vec![];\n+        entries.push(Entry::End(None));\n+        children.push((0usize, (*self, None)));\n+        (children, entries)\n+    }\n+}\n+\n+impl<'t> TokenBuffer<'t> {\n+    pub fn from_tokens(tokens: &'t [TokenTree]) -> TokenBuffer<'t> {\n+        Self::new(tokens)\n+    }\n+\n+    pub fn from_subtree(subtree: &'t Subtree) -> TokenBuffer<'t> {\n+        Self::new(subtree)\n+    }\n+\n+    fn new<T: TokenList<'t>>(tokens: T) -> TokenBuffer<'t> {\n+        let mut buffers = vec![];\n+        let idx = TokenBuffer::new_inner(tokens, &mut buffers, None);\n+        assert_eq!(idx, 0);\n+        TokenBuffer { buffers }\n+    }\n+\n+    fn new_inner<T: TokenList<'t>>(\n+        tokens: T,\n+        buffers: &mut Vec<Box<[Entry<'t>]>>,\n+        next: Option<EntryPtr>,\n+    ) -> usize {\n+        let (children, mut entries) = tokens.entries();\n \n         entries.push(Entry::End(next));\n         let res = buffers.len();\n         buffers.push(entries.into_boxed_slice());\n \n         for (child_idx, (subtree, tt)) in children {\n             let idx = TokenBuffer::new_inner(\n-                &subtree.token_trees,\n+                subtree.token_trees.as_slice(),\n                 buffers,\n                 Some(EntryPtr(EntryId(res), child_idx + 1)),\n             );\n-            buffers[res].as_mut()[child_idx] = Entry::Subtree(tt, EntryId(idx));\n+            buffers[res].as_mut()[child_idx] = Entry::Subtree(tt, subtree, EntryId(idx));\n         }\n \n         res\n@@ -87,6 +114,24 @@ impl<'t> TokenBuffer<'t> {\n     }\n }\n \n+#[derive(Debug)]\n+pub enum TokenTreeRef<'a> {\n+    Subtree(&'a Subtree, Option<&'a TokenTree>),\n+    Leaf(&'a Leaf, &'a TokenTree),\n+}\n+\n+impl<'a> TokenTreeRef<'a> {\n+    pub fn cloned(&self) -> TokenTree {\n+        match &self {\n+            TokenTreeRef::Subtree(subtree, tt) => match tt {\n+                Some(it) => (*it).clone(),\n+                None => (*subtree).clone().into(),\n+            },\n+            TokenTreeRef::Leaf(_, tt) => (*tt).clone(),\n+        }\n+    }\n+}\n+\n /// A safe version of `Cursor` from `syn` crate https://github.com/dtolnay/syn/blob/6533607f91686545cb034d2838beea338d9d0742/src/buffer.rs#L125\n #[derive(Copy, Clone, Debug)]\n pub struct Cursor<'a> {\n@@ -114,12 +159,11 @@ impl<'a> Cursor<'a> {\n         match self.entry() {\n             Some(Entry::End(Some(ptr))) => {\n                 let idx = ptr.1;\n-                if let Some(Entry::Subtree(TokenTree::Subtree(subtree), _)) =\n+                if let Some(Entry::Subtree(_, subtree, _)) =\n                     self.buffer.entry(&EntryPtr(ptr.0, idx - 1))\n                 {\n                     return Some(subtree);\n                 }\n-\n                 None\n             }\n             _ => None,\n@@ -134,18 +178,21 @@ impl<'a> Cursor<'a> {\n     /// a cursor into that subtree\n     pub fn subtree(self) -> Option<Cursor<'a>> {\n         match self.entry() {\n-            Some(Entry::Subtree(_, entry_id)) => {\n+            Some(Entry::Subtree(_, _, entry_id)) => {\n                 Some(Cursor::create(self.buffer, EntryPtr(*entry_id, 0)))\n             }\n             _ => None,\n         }\n     }\n \n     /// If the cursor is pointing at a `TokenTree`, returns it\n-    pub fn token_tree(self) -> Option<&'a TokenTree> {\n+    pub fn token_tree(self) -> Option<TokenTreeRef<'a>> {\n         match self.entry() {\n-            Some(Entry::Leaf(tt)) => Some(tt),\n-            Some(Entry::Subtree(tt, _)) => Some(tt),\n+            Some(Entry::Leaf(tt)) => match tt {\n+                TokenTree::Leaf(leaf) => Some(TokenTreeRef::Leaf(leaf, *tt)),\n+                TokenTree::Subtree(subtree) => Some(TokenTreeRef::Subtree(subtree, Some(tt))),\n+            },\n+            Some(Entry::Subtree(tt, subtree, _)) => Some(TokenTreeRef::Subtree(subtree, *tt)),\n             Some(Entry::End(_)) => None,\n             None => None,\n         }\n@@ -172,7 +219,7 @@ impl<'a> Cursor<'a> {\n     /// a cursor into that subtree\n     pub fn bump_subtree(self) -> Cursor<'a> {\n         match self.entry() {\n-            Some(Entry::Subtree(_, _)) => self.subtree().unwrap(),\n+            Some(Entry::Subtree(_, _, _)) => self.subtree().unwrap(),\n             _ => self.bump(),\n         }\n     }"}]}