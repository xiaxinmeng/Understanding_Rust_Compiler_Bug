{"sha": "aa6fba98ae717d6090cdd5d0569114adfc825680", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFhNmZiYTk4YWU3MTdkNjA5MGNkZDVkMDU2OTExNGFkZmM4MjU2ODA=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-04T22:17:07Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-06T11:04:02Z"}, "message": "syntax: Use `Token` in `Parser`", "tree": {"sha": "bbc8aed18256400f2873cddccc7a5553e993d408", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bbc8aed18256400f2873cddccc7a5553e993d408"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/aa6fba98ae717d6090cdd5d0569114adfc825680", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/aa6fba98ae717d6090cdd5d0569114adfc825680", "html_url": "https://github.com/rust-lang/rust/commit/aa6fba98ae717d6090cdd5d0569114adfc825680", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/aa6fba98ae717d6090cdd5d0569114adfc825680/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c0c57acd7b8061697d196fd800a7ff3151c37f38", "url": "https://api.github.com/repos/rust-lang/rust/commits/c0c57acd7b8061697d196fd800a7ff3151c37f38", "html_url": "https://github.com/rust-lang/rust/commit/c0c57acd7b8061697d196fd800a7ff3151c37f38"}], "stats": {"total": 252, "additions": 126, "deletions": 126}, "files": [{"sha": "4f681a77ed350e87491afbe125fae83b36797a27", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 8, "deletions": 9, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -273,7 +273,7 @@ pub enum ParseResult<T> {\n     Success(T),\n     /// Arm failed to match. If the second parameter is `token::Eof`, it indicates an unexpected\n     /// end of macro invocation. Otherwise, it indicates that no rules expected the given token.\n-    Failure(syntax_pos::Span, TokenKind, &'static str),\n+    Failure(Token, &'static str),\n     /// Fatal error (malformed macro?). Abort compilation.\n     Error(syntax_pos::Span, String),\n }\n@@ -701,7 +701,7 @@ pub fn parse(\n             parser.span,\n         ) {\n             Success(_) => {}\n-            Failure(sp, tok, t) => return Failure(sp, tok, t),\n+            Failure(token, msg) => return Failure(token, msg),\n             Error(sp, msg) => return Error(sp, msg),\n         }\n \n@@ -727,13 +727,13 @@ pub fn parse(\n                     \"ambiguity: multiple successful parses\".to_string(),\n                 );\n             } else {\n+                let span = if parser.span.is_dummy() {\n+                    parser.span\n+                } else {\n+                    sess.source_map().next_point(parser.span)\n+                };\n                 return Failure(\n-                    if parser.span.is_dummy() {\n-                        parser.span\n-                    } else {\n-                        sess.source_map().next_point(parser.span)\n-                    },\n-                    token::Eof,\n+                    Token { kind: token::Eof, span },\n                     \"missing tokens in macro arguments\",\n                 );\n             }\n@@ -771,7 +771,6 @@ pub fn parse(\n         // then there is a syntax error.\n         else if bb_items.is_empty() && next_items.is_empty() {\n             return Failure(\n-                parser.span,\n                 parser.token.clone(),\n                 \"no rules expected this token in macro call\",\n             );"}, {"sha": "05e921b1bfd1a8fbba45de7366c4d3665ae69ccd", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -190,10 +190,10 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n                     arm_span,\n                 })\n             }\n-            Failure(sp, tok, t) => if sp.lo() >= best_fail_spot.lo() {\n-                best_fail_spot = sp;\n-                best_fail_tok = Some(tok);\n-                best_fail_text = Some(t);\n+            Failure(token, msg) => if token.span.lo() >= best_fail_spot.lo() {\n+                best_fail_spot = token.span;\n+                best_fail_tok = Some(token.kind);\n+                best_fail_text = Some(msg);\n             },\n             Error(err_sp, ref msg) => {\n                 cx.span_fatal(err_sp.substitute_dummy(sp), &msg[..])\n@@ -288,11 +288,11 @@ pub fn compile(\n \n     let argument_map = match parse(sess, body.stream(), &argument_gram, None, true) {\n         Success(m) => m,\n-        Failure(sp, tok, t) => {\n-            let s = parse_failure_msg(tok);\n-            let sp = sp.substitute_dummy(def.span);\n+        Failure(token, msg) => {\n+            let s = parse_failure_msg(token.kind);\n+            let sp = token.span.substitute_dummy(def.span);\n             let mut err = sess.span_diagnostic.struct_span_fatal(sp, &s);\n-            err.span_label(sp, t);\n+            err.span_label(sp, msg);\n             err.emit();\n             FatalError.raise();\n         }"}, {"sha": "8040168a67ec3bf4ba9c7abab063dab79e524c7d", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -24,7 +24,7 @@ impl<'a> Parser<'a> {\n         let mut just_parsed_doc_comment = false;\n         loop {\n             debug!(\"parse_outer_attributes: self.token={:?}\", self.token);\n-            match self.token {\n+            match self.token.kind {\n                 token::Pound => {\n                     let inner_error_reason = if just_parsed_doc_comment {\n                         \"an inner attribute is not permitted following an outer doc comment\"\n@@ -81,7 +81,7 @@ impl<'a> Parser<'a> {\n         debug!(\"parse_attribute_with_inner_parse_policy: inner_parse_policy={:?} self.token={:?}\",\n                inner_parse_policy,\n                self.token);\n-        let (span, path, tokens, style) = match self.token {\n+        let (span, path, tokens, style) = match self.token.kind {\n             token::Pound => {\n                 let lo = self.span;\n                 self.bump();\n@@ -140,7 +140,7 @@ impl<'a> Parser<'a> {\n     /// PATH `=` TOKEN_TREE\n     /// The delimiters or `=` are still put into the resulting token stream.\n     crate fn parse_meta_item_unrestricted(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n-        let meta = match self.token {\n+        let meta = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n                 Nonterminal::NtMeta(ref meta) => Some(meta.clone()),\n                 _ => None,\n@@ -159,7 +159,7 @@ impl<'a> Parser<'a> {\n             } else if self.eat(&token::Eq) {\n                 let eq = TokenTree::token(self.prev_span, token::Eq);\n                 let mut is_interpolated_expr = false;\n-                if let token::Interpolated(nt) = &self.token {\n+                if let token::Interpolated(nt) = &self.token.kind {\n                     if let token::NtExpr(..) = **nt {\n                         is_interpolated_expr = true;\n                     }\n@@ -188,7 +188,7 @@ impl<'a> Parser<'a> {\n     crate fn parse_inner_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = vec![];\n         loop {\n-            match self.token {\n+            match self.token.kind {\n                 token::Pound => {\n                     // Don't even try to parse if it's not an inner attribute.\n                     if !self.look_ahead(1, |t| t == &token::Not) {\n@@ -236,7 +236,7 @@ impl<'a> Parser<'a> {\n     /// meta_item : IDENT ( '=' UNSUFFIXED_LIT | '(' meta_item_inner? ')' )? ;\n     /// meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n     pub fn parse_meta_item(&mut self) -> PResult<'a, ast::MetaItem> {\n-        let nt_meta = match self.token {\n+        let nt_meta = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n                 token::NtMeta(ref e) => Some(e.clone()),\n                 _ => None,"}, {"sha": "1759a229cf49d7f039d9bfa6112a802f09cde531", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -201,7 +201,7 @@ impl<'a> Parser<'a> {\n             self.span,\n             &format!(\"expected identifier, found {}\", self.this_token_descr()),\n         );\n-        if let token::Ident(ident, false) = &self.token {\n+        if let token::Ident(ident, false) = &self.token.kind {\n             if ident.is_raw_guess() {\n                 err.span_suggestion(\n                     self.span,\n@@ -730,7 +730,7 @@ impl<'a> Parser<'a> {\n     ) -> PResult<'a, bool /* recovered */> {\n         let token_str = pprust::token_to_string(t);\n         let this_token_str = self.this_token_descr();\n-        let (prev_sp, sp) = match (&self.token, self.subparser_name) {\n+        let (prev_sp, sp) = match (&self.token.kind, self.subparser_name) {\n             // Point at the end of the macro call when reaching end of macro arguments.\n             (token::Eof, Some(_)) => {\n                 let sp = self.sess.source_map().next_point(self.span);\n@@ -746,7 +746,7 @@ impl<'a> Parser<'a> {\n         let msg = format!(\n             \"expected `{}`, found {}\",\n             token_str,\n-            match (&self.token, self.subparser_name) {\n+            match (&self.token.kind, self.subparser_name) {\n                 (token::Eof, Some(origin)) => format!(\"end of {}\", origin),\n                 _ => this_token_str,\n             },\n@@ -989,7 +989,7 @@ impl<'a> Parser<'a> {\n                break_on_semi, break_on_block);\n         loop {\n             debug!(\"recover_stmt_ loop {:?}\", self.token);\n-            match self.token {\n+            match self.token.kind {\n                 token::OpenDelim(token::DelimToken::Brace) => {\n                     brace_depth += 1;\n                     self.bump();\n@@ -1074,7 +1074,7 @@ impl<'a> Parser<'a> {\n     }\n \n     crate fn eat_incorrect_doc_comment(&mut self, applied_to: &str) {\n-        if let token::DocComment(_) = self.token {\n+        if let token::DocComment(_) = self.token.kind {\n             let mut err = self.diagnostic().struct_span_err(\n                 self.span,\n                 &format!(\"documentation comments cannot be applied to {}\", applied_to),\n@@ -1214,7 +1214,7 @@ impl<'a> Parser<'a> {\n     }\n \n     crate fn expected_expression_found(&self) -> DiagnosticBuilder<'a> {\n-        let (span, msg) = match (&self.token, self.subparser_name) {\n+        let (span, msg) = match (&self.token.kind, self.subparser_name) {\n             (&token::Eof, Some(origin)) => {\n                 let sp = self.sess.source_map().next_point(self.span);\n                 (sp, format!(\"expected expression, found end of {}\", origin))"}, {"sha": "1abb8254bc6a19bd07e1cd7e4e18f21a7730fd44", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 12, "deletions": 14, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -3,7 +3,7 @@\n use crate::ast::{self, Ident, Lit, LitKind};\n use crate::parse::parser::Parser;\n use crate::parse::PResult;\n-use crate::parse::token::{self, TokenKind};\n+use crate::parse::token::{self, Token, TokenKind};\n use crate::parse::unescape::{unescape_str, unescape_char, unescape_byte_str, unescape_byte};\n use crate::print::pprust;\n use crate::symbol::{kw, sym, Symbol};\n@@ -272,44 +272,42 @@ impl<'a> Parser<'a> {\n         if self.token == token::Dot {\n             // Attempt to recover `.4` as `0.4`.\n             recovered = self.look_ahead(1, |t| {\n-                if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = *t {\n+                if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = t.kind {\n                     let next_span = self.look_ahead_span(1);\n                     if self.span.hi() == next_span.lo() {\n                         let s = String::from(\"0.\") + &symbol.as_str();\n-                        let token = TokenKind::lit(token::Float, Symbol::intern(&s), suffix);\n-                        return Some((token, self.span.to(next_span)));\n+                        let kind = TokenKind::lit(token::Float, Symbol::intern(&s), suffix);\n+                        return Some(Token { kind, span: self.span.to(next_span) });\n                     }\n                 }\n                 None\n             });\n-            if let Some((ref token, span)) = recovered {\n+            if let Some(token) = &recovered {\n                 self.bump();\n                 self.diagnostic()\n-                    .struct_span_err(span, \"float literals must have an integer part\")\n+                    .struct_span_err(token.span, \"float literals must have an integer part\")\n                     .span_suggestion(\n-                        span,\n+                        token.span,\n                         \"must have an integer part\",\n-                        pprust::token_to_string(&token),\n+                        pprust::token_to_string(token),\n                         Applicability::MachineApplicable,\n                     )\n                     .emit();\n             }\n         }\n \n-        let (token, span) = recovered.as_ref().map_or((&self.token, self.span),\n-                                                      |(token, span)| (token, *span));\n-\n-        match Lit::from_token(token, span) {\n+        let token = recovered.as_ref().unwrap_or(&self.token);\n+        match Lit::from_token(token, token.span) {\n             Ok(lit) => {\n                 self.bump();\n                 Ok(lit)\n             }\n             Err(LitError::NotLiteral) => {\n                 let msg = format!(\"unexpected token: {}\", self.this_token_descr());\n-                Err(self.span_fatal(span, &msg))\n+                Err(self.span_fatal(token.span, &msg))\n             }\n             Err(err) => {\n-                let lit = token.expect_lit();\n+                let (lit, span) = (token.expect_lit(), token.span);\n                 self.bump();\n                 err.report(&self.sess.span_diagnostic, lit, span);\n                 let lit = token::Lit::new(token::Err, lit.symbol, lit.suffix);"}, {"sha": "5187621258d0d5b4bf50cc9801a83ba5f65eab96", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -239,7 +239,7 @@ fn maybe_source_file_to_parser(\n     let mut parser = stream_to_parser(sess, stream, None);\n     parser.unclosed_delims = unclosed_delims;\n     if parser.token == token::Eof && parser.span.is_dummy() {\n-        parser.span = Span::new(end_pos, end_pos, parser.span.ctxt());\n+        parser.token.span = Span::new(end_pos, end_pos, parser.span.ctxt());\n     }\n \n     Ok(parser)"}, {"sha": "cc67a3fbd6632bb4fcb83c42030bf925bdd23906", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 82, "deletions": 79, "changes": 161, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -57,6 +57,7 @@ use log::debug;\n use std::borrow::Cow;\n use std::cmp;\n use std::mem;\n+use std::ops::Deref;\n use std::path::{self, Path, PathBuf};\n use std::slice;\n \n@@ -121,7 +122,7 @@ crate enum BlockMode {\n /// `token::Interpolated` tokens.\n macro_rules! maybe_whole_expr {\n     ($p:expr) => {\n-        if let token::Interpolated(nt) = &$p.token {\n+        if let token::Interpolated(nt) = &$p.token.kind {\n             match &**nt {\n                 token::NtExpr(e) | token::NtLiteral(e) => {\n                     let e = e.clone();\n@@ -147,7 +148,7 @@ macro_rules! maybe_whole_expr {\n /// As maybe_whole_expr, but for things other than expressions\n macro_rules! maybe_whole {\n     ($p:expr, $constructor:ident, |$x:ident| $e:expr) => {\n-        if let token::Interpolated(nt) = &$p.token {\n+        if let token::Interpolated(nt) = &$p.token.kind {\n             if let token::$constructor(x) = &**nt {\n                 let $x = x.clone();\n                 $p.bump();\n@@ -161,7 +162,7 @@ macro_rules! maybe_whole {\n macro_rules! maybe_recover_from_interpolated_ty_qpath {\n     ($self: expr, $allow_qpath_recovery: expr) => {\n         if $allow_qpath_recovery && $self.look_ahead(1, |t| t == &token::ModSep) {\n-            if let token::Interpolated(nt) = &$self.token {\n+            if let token::Interpolated(nt) = &$self.token.kind {\n                 if let token::NtTy(ty) = &**nt {\n                     let ty = ty.clone();\n                     $self.bump();\n@@ -196,14 +197,13 @@ enum PrevTokenKind {\n #[derive(Clone)]\n pub struct Parser<'a> {\n     pub sess: &'a ParseSess,\n-    /// the current token:\n-    pub token: token::TokenKind,\n-    /// the span of the current token:\n-    pub span: Span,\n+    /// The current token.\n+    pub token: Token,\n+    /// The span of the previous token.\n     meta_var_span: Option<Span>,\n     /// The span of the previous token.\n     pub prev_span: Span,\n-    /// The kind of the previous troken.\n+    /// The previous token kind.\n     prev_token_kind: PrevTokenKind,\n     restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files.\n@@ -242,6 +242,15 @@ impl<'a> Drop for Parser<'a> {\n     }\n }\n \n+// FIXME: Parser uses `self.span` all the time.\n+// Remove this impl if you think that using `self.token.span` instead is acceptable.\n+impl Deref for Parser<'_> {\n+    type Target = Token;\n+    fn deref(&self) -> &Self::Target {\n+        &self.token\n+    }\n+}\n+\n #[derive(Clone)]\n crate struct TokenCursor {\n     crate frame: TokenCursorFrame,\n@@ -468,8 +477,7 @@ impl<'a> Parser<'a> {\n     ) -> Self {\n         let mut parser = Parser {\n             sess,\n-            token: token::Whitespace,\n-            span: DUMMY_SP,\n+            token: Token { kind: token::Whitespace, span: DUMMY_SP },\n             prev_span: DUMMY_SP,\n             meta_var_span: None,\n             prev_token_kind: PrevTokenKind::Other,\n@@ -498,9 +506,7 @@ impl<'a> Parser<'a> {\n             subparser_name,\n         };\n \n-        let tok = parser.next_tok();\n-        parser.token = tok.kind;\n-        parser.span = tok.span;\n+        parser.token = parser.next_tok();\n \n         if let Some(directory) = directory {\n             parser.directory = directory;\n@@ -534,7 +540,7 @@ impl<'a> Parser<'a> {\n     }\n \n     crate fn token_descr(&self) -> Option<&'static str> {\n-        Some(match &self.token {\n+        Some(match &self.token.kind {\n             t if t.is_special_ident() => \"reserved identifier\",\n             t if t.is_used_keyword() => \"keyword\",\n             t if t.is_unused_keyword() => \"reserved keyword\",\n@@ -612,7 +618,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_ident_common(&mut self, recover: bool) -> PResult<'a, ast::Ident> {\n-        match self.token {\n+        match self.token.kind {\n             token::Ident(ident, _) => {\n                 if self.token.is_reserved_ident() {\n                     let mut err = self.expected_ident_found();\n@@ -732,7 +738,7 @@ impl<'a> Parser<'a> {\n     /// See issue #47856 for an example of when this may occur.\n     fn eat_plus(&mut self) -> bool {\n         self.expected_tokens.push(TokenType::Token(token::BinOp(token::Plus)));\n-        match self.token {\n+        match self.token.kind {\n             token::BinOp(token::Plus) => {\n                 self.bump();\n                 true\n@@ -763,7 +769,7 @@ impl<'a> Parser<'a> {\n     /// `&` and continues. If an `&` is not seen, signals an error.\n     fn expect_and(&mut self) -> PResult<'a, ()> {\n         self.expected_tokens.push(TokenType::Token(token::BinOp(token::And)));\n-        match self.token {\n+        match self.token.kind {\n             token::BinOp(token::And) => {\n                 self.bump();\n                 Ok(())\n@@ -780,7 +786,7 @@ impl<'a> Parser<'a> {\n     /// `|` and continues. If an `|` is not seen, signals an error.\n     fn expect_or(&mut self) -> PResult<'a, ()> {\n         self.expected_tokens.push(TokenType::Token(token::BinOp(token::Or)));\n-        match self.token {\n+        match self.token.kind {\n             token::BinOp(token::Or) => {\n                 self.bump();\n                 Ok(())\n@@ -805,7 +811,7 @@ impl<'a> Parser<'a> {\n     /// starting token.\n     fn eat_lt(&mut self) -> bool {\n         self.expected_tokens.push(TokenType::Token(token::Lt));\n-        let ate = match self.token {\n+        let ate = match self.token.kind {\n             token::Lt => {\n                 self.bump();\n                 true\n@@ -845,7 +851,7 @@ impl<'a> Parser<'a> {\n     /// with a single `>` and continues. If a `>` is not seen, signals an error.\n     fn expect_gt(&mut self) -> PResult<'a, ()> {\n         self.expected_tokens.push(TokenType::Token(token::Gt));\n-        let ate = match self.token {\n+        let ate = match self.token.kind {\n             token::Gt => {\n                 self.bump();\n                 Some(())\n@@ -928,7 +934,7 @@ impl<'a> Parser<'a> {\n                     TokenExpectType::NoExpect => self.token == **k,\n                 }\n             }) {\n-            match self.token {\n+            match self.token.kind {\n                 token::CloseDelim(..) | token::Eof => break,\n                 _ => {}\n             };\n@@ -1011,7 +1017,7 @@ impl<'a> Parser<'a> {\n         self.prev_span = self.meta_var_span.take().unwrap_or(self.span);\n \n         // Record last token kind for possible error recovery.\n-        self.prev_token_kind = match self.token {\n+        self.prev_token_kind = match self.token.kind {\n             token::DocComment(..) => PrevTokenKind::DocComment,\n             token::Comma => PrevTokenKind::Comma,\n             token::BinOp(token::Plus) => PrevTokenKind::Plus,\n@@ -1022,9 +1028,7 @@ impl<'a> Parser<'a> {\n             _ => PrevTokenKind::Other,\n         };\n \n-        let next = self.next_tok();\n-        self.token = next.kind;\n-        self.span = next.span;\n+        self.token = self.next_tok();\n         self.expected_tokens.clear();\n         // check after each token\n         self.process_potential_macro_variable();\n@@ -1038,24 +1042,25 @@ impl<'a> Parser<'a> {\n         // fortunately for tokens currently using `bump_with`, the\n         // prev_token_kind will be of no use anyway.\n         self.prev_token_kind = PrevTokenKind::Other;\n-        self.token = next;\n-        self.span = span;\n+        self.token = Token { kind: next, span };\n         self.expected_tokens.clear();\n     }\n \n     pub fn look_ahead<R, F>(&self, dist: usize, f: F) -> R where\n-        F: FnOnce(&token::TokenKind) -> R,\n+        F: FnOnce(&token::Token) -> R,\n     {\n         if dist == 0 {\n-            return f(&self.token)\n+            // FIXME: Avoid cloning here.\n+            return f(&self.token);\n         }\n \n-        f(&match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n+        let frame = &self.token_cursor.frame;\n+        f(&match frame.tree_cursor.look_ahead(dist - 1) {\n             Some(tree) => match tree {\n-                TokenTree::Token(token) => token.kind,\n-                TokenTree::Delimited(_, delim, _) => token::OpenDelim(delim),\n-            },\n-            None => token::CloseDelim(self.token_cursor.frame.delim),\n+                TokenTree::Token(token) => token,\n+                TokenTree::Delimited(dspan, delim, _) => Token { kind: token::OpenDelim(delim), span: dspan.open },\n+            }\n+            None => Token { kind: token::CloseDelim(frame.delim), span: frame.span.close }\n         })\n     }\n \n@@ -1209,7 +1214,7 @@ impl<'a> Parser<'a> {\n                 decl,\n             };\n \n-            let body = match self.token {\n+            let body = match self.token.kind {\n                 token::Semi => {\n                     self.bump();\n                     *at_end = true;\n@@ -1477,7 +1482,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn is_named_argument(&self) -> bool {\n-        let offset = match self.token {\n+        let offset = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n                 token::NtPat(..) => return self.look_ahead(1, |t| t == &token::Colon),\n                 _ => 0,\n@@ -1612,7 +1617,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_path_segment_ident(&mut self) -> PResult<'a, ast::Ident> {\n-        match self.token {\n+        match self.token.kind {\n             token::Ident(ident, _) if self.token.is_path_segment_keyword() => {\n                 let span = self.span;\n                 self.bump();\n@@ -1623,7 +1628,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_ident_or_underscore(&mut self) -> PResult<'a, ast::Ident> {\n-        match self.token {\n+        match self.token.kind {\n             token::Ident(ident, false) if ident.name == kw::Underscore => {\n                 let span = self.span;\n                 self.bump();\n@@ -1710,7 +1715,7 @@ impl<'a> Parser<'a> {\n     /// backwards-compatibility. This is used when parsing derive macro paths in `#[derive]`\n     /// attributes.\n     pub fn parse_path_allowing_meta(&mut self, style: PathStyle) -> PResult<'a, ast::Path> {\n-        let meta_ident = match self.token {\n+        let meta_ident = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n                 token::NtMeta(ref meta) => match meta.node {\n                     ast::MetaItemKind::Word => Some(meta.path.clone()),\n@@ -1859,7 +1864,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_field_name(&mut self) -> PResult<'a, Ident> {\n-        if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = self.token {\n+        if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = self.token.kind {\n             self.expect_no_suffix(self.span, \"a tuple index\", suffix);\n             self.bump();\n             Ok(Ident::new(symbol, self.prev_span))\n@@ -1949,7 +1954,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn expect_delimited_token_tree(&mut self) -> PResult<'a, (MacDelimiter, TokenStream)> {\n-        let delim = match self.token {\n+        let delim = match self.token.kind {\n             token::OpenDelim(delim) => delim,\n             _ => {\n                 let msg = \"expected open delimiter\";\n@@ -1993,7 +1998,7 @@ impl<'a> Parser<'a> {\n         let ex: ExprKind;\n \n         // Note: when adding new syntax here, don't forget to adjust TokenKind::can_begin_expr().\n-        match self.token {\n+        match self.token.kind {\n             token::OpenDelim(token::Paren) => {\n                 self.bump();\n \n@@ -2363,7 +2368,7 @@ impl<'a> Parser<'a> {\n             }\n \n             let mut recovery_field = None;\n-            if let token::Ident(ident, _) = self.token {\n+            if let token::Ident(ident, _) = self.token.kind {\n                 if !self.token.is_reserved_ident() && self.look_ahead(1, |t| *t == token::Colon) {\n                     // Use in case of error after field-looking code: `S { foo: () with a }`\n                     let mut ident = ident.clone();\n@@ -2503,7 +2508,7 @@ impl<'a> Parser<'a> {\n         let segment = self.parse_path_segment(PathStyle::Expr)?;\n         self.check_trailing_angle_brackets(&segment, token::OpenDelim(token::Paren));\n \n-        Ok(match self.token {\n+        Ok(match self.token.kind {\n             token::OpenDelim(token::Paren) => {\n                 // Method call `expr.f()`\n                 let mut args = self.parse_unspanned_seq(\n@@ -2542,7 +2547,7 @@ impl<'a> Parser<'a> {\n \n             // expr.f\n             if self.eat(&token::Dot) {\n-                match self.token {\n+                match self.token.kind {\n                     token::Ident(..) => {\n                         e = self.parse_dot_suffix(e, lo)?;\n                     }\n@@ -2594,7 +2599,7 @@ impl<'a> Parser<'a> {\n                 continue;\n             }\n             if self.expr_is_complete(&e) { break; }\n-            match self.token {\n+            match self.token.kind {\n                 // expr(...)\n                 token::OpenDelim(token::Paren) => {\n                     let seq = self.parse_unspanned_seq(\n@@ -2627,11 +2632,11 @@ impl<'a> Parser<'a> {\n     }\n \n     crate fn process_potential_macro_variable(&mut self) {\n-        let (token, span) = match self.token {\n+        self.token = match self.token.kind {\n             token::Dollar if self.span.ctxt() != syntax_pos::hygiene::SyntaxContext::empty() &&\n                              self.look_ahead(1, |t| t.is_ident()) => {\n                 self.bump();\n-                let name = match self.token {\n+                let name = match self.token.kind {\n                     token::Ident(ident, _) => ident,\n                     _ => unreachable!()\n                 };\n@@ -2646,24 +2651,22 @@ impl<'a> Parser<'a> {\n                 // Interpolated identifier and lifetime tokens are replaced with usual identifier\n                 // and lifetime tokens, so the former are never encountered during normal parsing.\n                 match **nt {\n-                    token::NtIdent(ident, is_raw) => (token::Ident(ident, is_raw), ident.span),\n-                    token::NtLifetime(ident) => (token::Lifetime(ident), ident.span),\n+                    token::NtIdent(ident, is_raw) => Token { kind: token::Ident(ident, is_raw), span: ident.span },\n+                    token::NtLifetime(ident) => Token { kind: token::Lifetime(ident), span: ident.span },\n                     _ => return,\n                 }\n             }\n             _ => return,\n         };\n-        self.token = token;\n-        self.span = span;\n     }\n \n     /// Parses a single token tree from the input.\n     crate fn parse_token_tree(&mut self) -> TokenTree {\n-        match self.token {\n+        match self.token.kind {\n             token::OpenDelim(..) => {\n                 let frame = mem::replace(&mut self.token_cursor.frame,\n                                          self.token_cursor.stack.pop().unwrap());\n-                self.span = frame.span.entire();\n+                self.token.span = frame.span.entire();\n                 self.bump();\n                 TokenTree::Delimited(\n                     frame.span,\n@@ -2673,9 +2676,9 @@ impl<'a> Parser<'a> {\n             },\n             token::CloseDelim(_) | token::Eof => unreachable!(),\n             _ => {\n-                let (token, span) = (mem::replace(&mut self.token, token::Whitespace), self.span);\n+                let token = mem::replace(&mut self.token, Token { kind: token::Whitespace, span: DUMMY_SP });\n                 self.bump();\n-                TokenTree::token(span, token)\n+                TokenTree::Token(token)\n             }\n         }\n     }\n@@ -2692,7 +2695,7 @@ impl<'a> Parser<'a> {\n     pub fn parse_tokens(&mut self) -> TokenStream {\n         let mut result = Vec::new();\n         loop {\n-            match self.token {\n+            match self.token.kind {\n                 token::Eof | token::CloseDelim(..) => break,\n                 _ => result.push(self.parse_token_tree().into()),\n             }\n@@ -2707,7 +2710,7 @@ impl<'a> Parser<'a> {\n         let attrs = self.parse_or_use_outer_attributes(already_parsed_attrs)?;\n         let lo = self.span;\n         // Note: when adding new unary operators, don't forget to adjust TokenKind::can_begin_expr()\n-        let (hi, ex) = match self.token {\n+        let (hi, ex) = match self.token.kind {\n             token::Not => {\n                 self.bump();\n                 let e = self.parse_prefix_expr(None);\n@@ -2760,7 +2763,7 @@ impl<'a> Parser<'a> {\n                 // `not` is just an ordinary identifier in Rust-the-language,\n                 // but as `rustc`-the-compiler, we can issue clever diagnostics\n                 // for confused users who really want to say `!`\n-                let token_cannot_continue_expr = |t: &token::TokenKind| match *t {\n+                let token_cannot_continue_expr = |t: &token::Token| match t.kind {\n                     // These tokens can start an expression after `!`, but\n                     // can't continue an expression after an ident\n                     token::Ident(ident, is_raw) => token::ident_can_begin_expr(ident, is_raw),\n@@ -3040,7 +3043,7 @@ impl<'a> Parser<'a> {\n \n                 match self.parse_path(PathStyle::Expr) {\n                     Ok(path) => {\n-                        let (op_noun, op_verb) = match self.token {\n+                        let (op_noun, op_verb) = match self.token.kind {\n                             token::Lt => (\"comparison\", \"comparing\"),\n                             token::BinOp(token::Shl) => (\"shift\", \"shifting\"),\n                             _ => {\n@@ -3844,14 +3847,14 @@ impl<'a> Parser<'a> {\n     // helper function to decide whether to parse as ident binding or to try to do\n     // something more complex like range patterns\n     fn parse_as_ident(&mut self) -> bool {\n-        self.look_ahead(1, |t| match *t {\n+        self.look_ahead(1, |t| match t.kind {\n             token::OpenDelim(token::Paren) | token::OpenDelim(token::Brace) |\n             token::DotDotDot | token::DotDotEq | token::ModSep | token::Not => Some(false),\n             // ensure slice patterns [a, b.., c] and [a, b, c..] don't go into the\n             // range pattern branch\n             token::DotDot => None,\n             _ => Some(true),\n-        }).unwrap_or_else(|| self.look_ahead(2, |t| match *t {\n+        }).unwrap_or_else(|| self.look_ahead(2, |t| match t.kind {\n             token::Comma | token::CloseDelim(token::Bracket) => true,\n             _ => false,\n         }))\n@@ -3914,12 +3917,12 @@ impl<'a> Parser<'a> {\n \n         let lo = self.span;\n         let pat;\n-        match self.token {\n+        match self.token.kind {\n             token::BinOp(token::And) | token::AndAnd => {\n                 // Parse &pat / &mut pat\n                 self.expect_and()?;\n                 let mutbl = self.parse_mutability();\n-                if let token::Lifetime(ident) = self.token {\n+                if let token::Lifetime(ident) = self.token.kind {\n                     let mut err = self.fatal(&format!(\"unexpected lifetime `{}` in pattern\",\n                                                       ident));\n                     err.span_label(self.span, \"unexpected lifetime\");\n@@ -3990,7 +3993,7 @@ impl<'a> Parser<'a> {\n                     // Parse an unqualified path\n                     (None, self.parse_path(PathStyle::Expr)?)\n                 };\n-                match self.token {\n+                match self.token.kind {\n                     token::Not if qself.is_none() => {\n                         // Parse macro invocation\n                         self.bump();\n@@ -3999,7 +4002,7 @@ impl<'a> Parser<'a> {\n                         pat = PatKind::Mac(mac);\n                     }\n                     token::DotDotDot | token::DotDotEq | token::DotDot => {\n-                        let end_kind = match self.token {\n+                        let end_kind = match self.token.kind {\n                             token::DotDot => RangeEnd::Excluded,\n                             token::DotDotDot => RangeEnd::Included(RangeSyntax::DotDotDot),\n                             token::DotDotEq => RangeEnd::Included(RangeSyntax::DotDotEq),\n@@ -4325,7 +4328,7 @@ impl<'a> Parser<'a> {\n     fn eat_macro_def(&mut self, attrs: &[Attribute], vis: &Visibility, lo: Span)\n                      -> PResult<'a, Option<P<Item>>> {\n         let token_lo = self.span;\n-        let (ident, def) = match self.token {\n+        let (ident, def) = match self.token.kind {\n             token::Ident(ident, false) if ident.name == kw::Macro => {\n                 self.bump();\n                 let ident = self.parse_ident()?;\n@@ -4436,15 +4439,15 @@ impl<'a> Parser<'a> {\n             }\n \n             // it's a macro invocation\n-            let id = match self.token {\n+            let id = match self.token.kind {\n                 token::OpenDelim(_) => Ident::invalid(), // no special identifier\n                 _ => self.parse_ident()?,\n             };\n \n             // check that we're pointing at delimiters (need to check\n             // again after the `if`, because of `parse_ident`\n             // consuming more tokens).\n-            match self.token {\n+            match self.token.kind {\n                 token::OpenDelim(_) => {}\n                 _ => {\n                     // we only expect an ident if we didn't parse one\n@@ -4481,7 +4484,7 @@ impl<'a> Parser<'a> {\n                 // We used to incorrectly stop parsing macro-expanded statements here.\n                 // If the next token will be an error anyway but could have parsed with the\n                 // earlier behavior, stop parsing here and emit a warning to avoid breakage.\n-                else if macro_legacy_warnings && self.token.can_begin_expr() && match self.token {\n+                else if macro_legacy_warnings && self.token.can_begin_expr() && match self.token.kind {\n                     // These can continue an expression, so we can't stop parsing and warn.\n                     token::OpenDelim(token::Paren) | token::OpenDelim(token::Bracket) |\n                     token::BinOp(token::Minus) | token::BinOp(token::Star) |\n@@ -5250,7 +5253,7 @@ impl<'a> Parser<'a> {\n                 assoc_ty_constraints.push(span);\n             } else if self.check_const_arg() {\n                 // Parse const argument.\n-                let expr = if let token::OpenDelim(token::Brace) = self.token {\n+                let expr = if let token::OpenDelim(token::Brace) = self.token.kind {\n                     self.parse_block_expr(None, self.span, BlockCheckMode::Default, ThinVec::new())?\n                 } else if self.token.is_ident() {\n                     // FIXME(const_generics): to distinguish between idents for types and consts,\n@@ -5477,7 +5480,7 @@ impl<'a> Parser<'a> {\n \n     /// Returns the parsed optional self argument and whether a self shortcut was used.\n     fn parse_self_arg(&mut self) -> PResult<'a, Option<Arg>> {\n-        let expect_ident = |this: &mut Self| match this.token {\n+        let expect_ident = |this: &mut Self| match this.token.kind {\n             // Preserve hygienic context.\n             token::Ident(ident, _) =>\n                 { let span = this.span; this.bump(); Ident::new(ident.name, span) }\n@@ -5492,7 +5495,7 @@ impl<'a> Parser<'a> {\n         // Only a limited set of initial token sequences is considered `self` parameters; anything\n         // else is parsed as a normal function parameter list, so some lookahead is required.\n         let eself_lo = self.span;\n-        let (eself, eself_ident, eself_hi) = match self.token {\n+        let (eself, eself_ident, eself_hi) = match self.token.kind {\n             token::BinOp(token::And) => {\n                 // `&self`\n                 // `&mut self`\n@@ -5803,7 +5806,7 @@ impl<'a> Parser<'a> {\n         match *vis {\n             VisibilityKind::Inherited => {}\n             _ => {\n-                let is_macro_rules: bool = match self.token {\n+                let is_macro_rules: bool = match self.token.kind {\n                     token::Ident(sid, _) => sid.name == sym::macro_rules,\n                     _ => false,\n                 };\n@@ -5918,7 +5921,7 @@ impl<'a> Parser<'a> {\n             self.expect(&token::OpenDelim(token::Brace))?;\n             let mut trait_items = vec![];\n             while !self.eat(&token::CloseDelim(token::Brace)) {\n-                if let token::DocComment(_) = self.token {\n+                if let token::DocComment(_) = self.token.kind {\n                     if self.look_ahead(1,\n                     |tok| tok == &token::CloseDelim(token::Brace)) {\n                         let mut err = self.diagnostic().struct_span_err_with_code(\n@@ -6246,7 +6249,7 @@ impl<'a> Parser<'a> {\n         if self.token == token::Comma {\n             seen_comma = true;\n         }\n-        match self.token {\n+        match self.token.kind {\n             token::Comma => {\n                 self.bump();\n             }\n@@ -7011,7 +7014,7 @@ impl<'a> Parser<'a> {\n     /// Parses a string as an ABI spec on an extern type or module. Consumes\n     /// the `extern` keyword, if one is found.\n     fn parse_opt_abi(&mut self) -> PResult<'a, Option<Abi>> {\n-        match self.token {\n+        match self.token.kind {\n             token::Literal(token::Lit { kind: token::Str, symbol, suffix }) |\n             token::Literal(token::Lit { kind: token::StrRaw(..), symbol, suffix }) => {\n                 let sp = self.span;\n@@ -7046,7 +7049,7 @@ impl<'a> Parser<'a> {\n                 if token.is_keyword(kw::Move) {\n                     return true;\n                 }\n-                match *token {\n+                match token.kind {\n                     token::BinOp(token::Or) | token::OrOr => true,\n                     _ => false,\n                 }\n@@ -7818,7 +7821,7 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_optional_str(&mut self) -> Option<(Symbol, ast::StrStyle, Option<ast::Name>)> {\n-        let ret = match self.token {\n+        let ret = match self.token.kind {\n             token::Literal(token::Lit { kind: token::Str, symbol, suffix }) =>\n                 (symbol, ast::StrStyle::Cooked, suffix),\n             token::Literal(token::Lit { kind: token::StrRaw(n), symbol, suffix }) =>"}, {"sha": "b015815ac9c1ea2b79b1554e3dc36c07dad40346", "filename": "src/libsyntax_ext/asm.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax_ext%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax_ext%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fasm.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -260,7 +260,7 @@ fn parse_inline_asm<'a>(\n         loop {\n             // MOD_SEP is a double colon '::' without space in between.\n             // When encountered, the state must be advanced twice.\n-            match (&p.token, state.next(), state.next().next()) {\n+            match (&p.token.kind, state.next(), state.next().next()) {\n                 (&token::Colon, StateNone, _) |\n                 (&token::ModSep, _, StateNone) => {\n                     p.bump();"}, {"sha": "e5e422c4d9c778fd8607da94d2956b97ce7eeed9", "filename": "src/libsyntax_ext/assert.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax_ext%2Fassert.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax_ext%2Fassert.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fassert.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -103,7 +103,7 @@ fn parse_assert<'a>(\n     //\n     // Parse this as an actual message, and suggest inserting a comma. Eventually, this should be\n     // turned into an error.\n-    let custom_message = if let token::Literal(token::Lit { kind: token::Str, .. }) = parser.token {\n+    let custom_message = if let token::Literal(token::Lit { kind: token::Str, .. }) = parser.token.kind {\n         let mut err = cx.struct_span_warn(parser.span, \"unexpected string literal\");\n         let comma_span = cx.source_map().next_point(parser.prev_span);\n         err.span_suggestion_short("}, {"sha": "0eaac544e332acba38387fe042461f76b2d7ae5c", "filename": "src/libsyntax_ext/format.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax_ext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6fba98ae717d6090cdd5d0569114adfc825680/src%2Flibsyntax_ext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fformat.rs?ref=aa6fba98ae717d6090cdd5d0569114adfc825680", "patch": "@@ -149,7 +149,7 @@ fn parse_args<'a>(\n         } // accept trailing commas\n         if named || (p.token.is_ident() && p.look_ahead(1, |t| *t == token::Eq)) {\n             named = true;\n-            let ident = if let token::Ident(i, _) = p.token {\n+            let ident = if let token::Ident(i, _) = p.token.kind {\n                 p.bump();\n                 i\n             } else {"}]}