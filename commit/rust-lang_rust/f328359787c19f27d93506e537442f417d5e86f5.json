{"sha": "f328359787c19f27d93506e537442f417d5e86f5", "node_id": "C_kwDOAAsO6NoAKGYzMjgzNTk3ODdjMTlmMjdkOTM1MDZlNTM3NDQyZjQxN2Q1ZTg2ZjU", "commit": {"author": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2022-01-09T18:25:10Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-01-09T18:25:10Z"}, "message": "Merge pull request #1216 from bjorn3/reduce_cg_clif_compile_times\n\nRefactor the intrinsics module for slightly better build times", "tree": {"sha": "f37c0fe9e80b06c332a6ed44c317c63db8cfe44f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f37c0fe9e80b06c332a6ed44c317c63db8cfe44f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f328359787c19f27d93506e537442f417d5e86f5", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJh2yiGCRBK7hj4Ov3rIwAAASwIACrlZEEtuNFzA2K9w8MNgNRl\n+7rufnIECYOBVYtGArXhwGD0gAct94g0b5WTnHbV+and7gaBaZAMFwOXdrKpnVcI\nEQHTniBIps63m7/VjqlAEm5vmI/PSo1adkGimjqmxzJcIr1p7qda+Z//JmTqR4MR\nnVfhLixtYRfCBIIN05UFJXq1p5vWCrLKXtt+YfMk3TrntLUag68QKh1Yzn/6z6VM\nJW/1xiTIztmms4QBtZ+cQE0LbthIU42ay9dRMFHnppp/1G2p+VlViyc0Qy7GxtYv\ndzG4wLMH/r2DNye/BJwShZswwDHwq6BVf06XhY0N+hQ5RHdFK+E5RgPaqBmduds=\n=Yjjd\n-----END PGP SIGNATURE-----\n", "payload": "tree f37c0fe9e80b06c332a6ed44c317c63db8cfe44f\nparent e4fff03d40ca602d447f3965e1afed2262978640\nparent b7cda373d585d024b120401b2b796181567e5ae9\nauthor bjorn3 <bjorn3@users.noreply.github.com> 1641752710 +0100\ncommitter GitHub <noreply@github.com> 1641752710 +0100\n\nMerge pull request #1216 from bjorn3/reduce_cg_clif_compile_times\n\nRefactor the intrinsics module for slightly better build times"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f328359787c19f27d93506e537442f417d5e86f5", "html_url": "https://github.com/rust-lang/rust/commit/f328359787c19f27d93506e537442f417d5e86f5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f328359787c19f27d93506e537442f417d5e86f5/comments", "author": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e4fff03d40ca602d447f3965e1afed2262978640", "url": "https://api.github.com/repos/rust-lang/rust/commits/e4fff03d40ca602d447f3965e1afed2262978640", "html_url": "https://github.com/rust-lang/rust/commit/e4fff03d40ca602d447f3965e1afed2262978640"}, {"sha": "b7cda373d585d024b120401b2b796181567e5ae9", "url": "https://api.github.com/repos/rust-lang/rust/commits/b7cda373d585d024b120401b2b796181567e5ae9", "html_url": "https://github.com/rust-lang/rust/commit/b7cda373d585d024b120401b2b796181567e5ae9"}], "stats": {"total": 725, "additions": 328, "deletions": 397}, "files": [{"sha": "20f8699d12abd2f160e0508c2fa6fff6cba97f16", "filename": "src/intrinsics/llvm.rs", "status": "modified", "additions": 10, "deletions": 12, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/f328359787c19f27d93506e537442f417d5e86f5/src%2Fintrinsics%2Fllvm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f328359787c19f27d93506e537442f417d5e86f5/src%2Fintrinsics%2Fllvm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsics%2Fllvm.rs?ref=f328359787c19f27d93506e537442f417d5e86f5", "patch": "@@ -73,32 +73,30 @@ pub(crate) fn codegen_llvm_intrinsic_call<'tcx>(\n                 kind => unreachable!(\"kind {:?}\", kind),\n             };\n \n-            simd_pair_for_each_lane(fx, x, y, ret, |fx, lane_layout, res_lane_layout, x_lane, y_lane| {\n-                let res_lane = match lane_layout.ty.kind() {\n+            simd_pair_for_each_lane(fx, x, y, ret, &|fx, lane_ty, res_lane_ty, x_lane, y_lane| {\n+                let res_lane = match lane_ty.kind() {\n                     ty::Float(_) => fx.bcx.ins().fcmp(flt_cc, x_lane, y_lane),\n-                    _ => unreachable!(\"{:?}\", lane_layout.ty),\n+                    _ => unreachable!(\"{:?}\", lane_ty),\n                 };\n-                bool_to_zero_or_max_uint(fx, res_lane_layout, res_lane)\n+                bool_to_zero_or_max_uint(fx, res_lane_ty, res_lane)\n             });\n         };\n         \"llvm.x86.sse2.psrli.d\", (c a, o imm8) {\n             let imm8 = crate::constant::mir_operand_get_const_val(fx, imm8).expect(\"llvm.x86.sse2.psrli.d imm8 not const\");\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, res_lane_layout, lane| {\n-                let res_lane = match imm8.try_to_bits(Size::from_bytes(4)).unwrap_or_else(|| panic!(\"imm8 not scalar: {:?}\", imm8)) {\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _res_lane_ty, lane| {\n+                match imm8.try_to_bits(Size::from_bytes(4)).unwrap_or_else(|| panic!(\"imm8 not scalar: {:?}\", imm8)) {\n                     imm8 if imm8 < 32 => fx.bcx.ins().ushr_imm(lane, i64::from(imm8 as u8)),\n                     _ => fx.bcx.ins().iconst(types::I32, 0),\n-                };\n-                CValue::by_val(res_lane, res_lane_layout)\n+                }\n             });\n         };\n         \"llvm.x86.sse2.pslli.d\", (c a, o imm8) {\n             let imm8 = crate::constant::mir_operand_get_const_val(fx, imm8).expect(\"llvm.x86.sse2.psrli.d imm8 not const\");\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, res_lane_layout, lane| {\n-                let res_lane = match imm8.try_to_bits(Size::from_bytes(4)).unwrap_or_else(|| panic!(\"imm8 not scalar: {:?}\", imm8)) {\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _res_lane_ty, lane| {\n+                match imm8.try_to_bits(Size::from_bytes(4)).unwrap_or_else(|| panic!(\"imm8 not scalar: {:?}\", imm8)) {\n                     imm8 if imm8 < 32 => fx.bcx.ins().ishl_imm(lane, i64::from(imm8 as u8)),\n                     _ => fx.bcx.ins().iconst(types::I32, 0),\n-                };\n-                CValue::by_val(res_lane, res_lane_layout)\n+                }\n             });\n         };\n         \"llvm.x86.sse2.storeu.dq\", (v mem_addr, c a) {"}, {"sha": "1e384668fc72e093c62758ab4fa22a7bddbba3b6", "filename": "src/intrinsics/mod.rs", "status": "modified", "additions": 166, "deletions": 282, "changes": 448, "blob_url": "https://github.com/rust-lang/rust/blob/f328359787c19f27d93506e537442f417d5e86f5/src%2Fintrinsics%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f328359787c19f27d93506e537442f417d5e86f5/src%2Fintrinsics%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsics%2Fmod.rs?ref=f328359787c19f27d93506e537442f417d5e86f5", "patch": "@@ -9,7 +9,8 @@ pub(crate) use cpuid::codegen_cpuid_call;\n pub(crate) use llvm::codegen_llvm_intrinsic_call;\n \n use rustc_middle::ty::print::with_no_trimmed_paths;\n-use rustc_span::symbol::{kw, sym};\n+use rustc_middle::ty::subst::SubstsRef;\n+use rustc_span::symbol::{kw, sym, Symbol};\n \n use crate::prelude::*;\n use cranelift_codegen::ir::AtomicRmwOp;\n@@ -41,29 +42,18 @@ macro intrinsic_arg {\n     }\n }\n \n-macro intrinsic_substs {\n-    ($substs:expr, $index:expr,) => {},\n-    ($substs:expr, $index:expr, $first:ident $(,$rest:ident)*) => {\n-        let $first = $substs.type_at($index);\n-        intrinsic_substs!($substs, $index+1, $($rest),*);\n-    }\n-}\n-\n macro intrinsic_match {\n     ($fx:expr, $intrinsic:expr, $substs:expr, $args:expr,\n     _ => $unknown:block;\n     $(\n-        $($($name:tt).*)|+ $(if $cond:expr)?, $(<$($subst:ident),*>)? ($($a:ident $arg:ident),*) $content:block;\n+        $($($name:tt).*)|+ $(if $cond:expr)?, ($($a:ident $arg:ident),*) $content:block;\n     )*) => {\n         let _ = $substs; // Silence warning when substs is unused.\n         match $intrinsic {\n             $(\n                 $(intrinsic_pat!($($name).*))|* $(if $cond)? => {\n                     #[allow(unused_parens, non_snake_case)]\n                     {\n-                        $(\n-                            intrinsic_substs!($substs, 0, $($subst),*);\n-                        )?\n                         if let [$($arg),*] = $args {\n                             let ($($arg,)*) = (\n                                 $(intrinsic_arg!($a $fx, $arg),)*\n@@ -83,38 +73,6 @@ macro intrinsic_match {\n     }\n }\n \n-macro call_intrinsic_match {\n-    ($fx:expr, $intrinsic:expr, $substs:expr, $ret:expr, $destination:expr, $args:expr, $(\n-        $name:ident($($arg:ident),*) -> $ty:ident => $func:ident,\n-    )*) => {\n-        match $intrinsic {\n-            $(\n-                sym::$name => {\n-                    assert!($substs.is_noop());\n-                    if let [$(ref $arg),*] = *$args {\n-                        let ($($arg,)*) = (\n-                            $(codegen_operand($fx, $arg),)*\n-                        );\n-                        let res = $fx.easy_call(stringify!($func), &[$($arg),*], $fx.tcx.types.$ty);\n-                        $ret.write_cvalue($fx, res);\n-\n-                        if let Some((_, dest)) = $destination {\n-                            let ret_block = $fx.get_block(dest);\n-                            $fx.bcx.ins().jump(ret_block, &[]);\n-                            return;\n-                        } else {\n-                            unreachable!();\n-                        }\n-                    } else {\n-                        bug!(\"wrong number of args for intrinsic {:?}\", $intrinsic);\n-                    }\n-                }\n-            )*\n-            _ => {}\n-        }\n-    }\n-}\n-\n macro validate_atomic_type($fx:ident, $intrinsic:ident, $span:ident, $ty:expr) {\n     match $ty.kind() {\n         ty::Uint(_) | ty::Int(_) | ty::RawPtr(..) => {}\n@@ -133,15 +91,6 @@ macro validate_atomic_type($fx:ident, $intrinsic:ident, $span:ident, $ty:expr) {\n     }\n }\n \n-macro validate_simd_type($fx:ident, $intrinsic:ident, $span:ident, $ty:expr) {\n-    if !$ty.is_simd() {\n-        $fx.tcx.sess.span_err($span, &format!(\"invalid monomorphization of `{}` intrinsic: expected SIMD input type, found non-SIMD `{}`\", $intrinsic, $ty));\n-        // Prevent verifier error\n-        crate::trap::trap_unreachable($fx, \"compilation should not have succeeded\");\n-        return;\n-    }\n-}\n-\n pub(crate) fn clif_vector_type<'tcx>(tcx: TyCtxt<'tcx>, layout: TyAndLayout<'tcx>) -> Option<Type> {\n     let (element, count) = match layout.abi {\n         Abi::Vector { element, count } => (element, count),\n@@ -159,12 +108,7 @@ fn simd_for_each_lane<'tcx>(\n     fx: &mut FunctionCx<'_, '_, 'tcx>,\n     val: CValue<'tcx>,\n     ret: CPlace<'tcx>,\n-    f: impl Fn(\n-        &mut FunctionCx<'_, '_, 'tcx>,\n-        TyAndLayout<'tcx>,\n-        TyAndLayout<'tcx>,\n-        Value,\n-    ) -> CValue<'tcx>,\n+    f: &dyn Fn(&mut FunctionCx<'_, '_, 'tcx>, Ty<'tcx>, Ty<'tcx>, Value) -> Value,\n ) {\n     let layout = val.layout();\n \n@@ -177,7 +121,8 @@ fn simd_for_each_lane<'tcx>(\n     for lane_idx in 0..lane_count {\n         let lane = val.value_lane(fx, lane_idx).load_scalar(fx);\n \n-        let res_lane = f(fx, lane_layout, ret_lane_layout, lane);\n+        let res_lane = f(fx, lane_layout.ty, ret_lane_layout.ty, lane);\n+        let res_lane = CValue::by_val(res_lane, ret_lane_layout);\n \n         ret.place_lane(fx, lane_idx).write_cvalue(fx, res_lane);\n     }\n@@ -188,13 +133,7 @@ fn simd_pair_for_each_lane<'tcx>(\n     x: CValue<'tcx>,\n     y: CValue<'tcx>,\n     ret: CPlace<'tcx>,\n-    f: impl Fn(\n-        &mut FunctionCx<'_, '_, 'tcx>,\n-        TyAndLayout<'tcx>,\n-        TyAndLayout<'tcx>,\n-        Value,\n-        Value,\n-    ) -> CValue<'tcx>,\n+    f: &dyn Fn(&mut FunctionCx<'_, '_, 'tcx>, Ty<'tcx>, Ty<'tcx>, Value, Value) -> Value,\n ) {\n     assert_eq!(x.layout(), y.layout());\n     let layout = x.layout();\n@@ -209,7 +148,8 @@ fn simd_pair_for_each_lane<'tcx>(\n         let x_lane = x.value_lane(fx, lane_idx).load_scalar(fx);\n         let y_lane = y.value_lane(fx, lane_idx).load_scalar(fx);\n \n-        let res_lane = f(fx, lane_layout, ret_lane_layout, x_lane, y_lane);\n+        let res_lane = f(fx, lane_layout.ty, ret_lane_layout.ty, x_lane, y_lane);\n+        let res_lane = CValue::by_val(res_lane, ret_lane_layout);\n \n         ret.place_lane(fx, lane_idx).write_cvalue(fx, res_lane);\n     }\n@@ -220,7 +160,7 @@ fn simd_reduce<'tcx>(\n     val: CValue<'tcx>,\n     acc: Option<Value>,\n     ret: CPlace<'tcx>,\n-    f: impl Fn(&mut FunctionCx<'_, '_, 'tcx>, TyAndLayout<'tcx>, Value, Value) -> Value,\n+    f: &dyn Fn(&mut FunctionCx<'_, '_, 'tcx>, Ty<'tcx>, Value, Value) -> Value,\n ) {\n     let (lane_count, lane_ty) = val.layout().ty.simd_size_and_type(fx.tcx);\n     let lane_layout = fx.layout_of(lane_ty);\n@@ -230,7 +170,7 @@ fn simd_reduce<'tcx>(\n         if let Some(acc) = acc { (acc, 0) } else { (val.value_lane(fx, 0).load_scalar(fx), 1) };\n     for lane_idx in start_lane..lane_count {\n         let lane = val.value_lane(fx, lane_idx).load_scalar(fx);\n-        res_val = f(fx, lane_layout, res_val, lane);\n+        res_val = f(fx, lane_layout.ty, res_val, lane);\n     }\n     let res = CValue::by_val(res_val, lane_layout);\n     ret.write_cvalue(fx, res);\n@@ -241,7 +181,7 @@ fn simd_reduce_bool<'tcx>(\n     fx: &mut FunctionCx<'_, '_, 'tcx>,\n     val: CValue<'tcx>,\n     ret: CPlace<'tcx>,\n-    f: impl Fn(&mut FunctionCx<'_, '_, 'tcx>, Value, Value) -> Value,\n+    f: &dyn Fn(&mut FunctionCx<'_, '_, 'tcx>, Value, Value) -> Value,\n ) {\n     let (lane_count, _lane_ty) = val.layout().ty.simd_size_and_type(fx.tcx);\n     assert!(ret.layout().ty.is_bool());\n@@ -264,10 +204,10 @@ fn simd_reduce_bool<'tcx>(\n \n fn bool_to_zero_or_max_uint<'tcx>(\n     fx: &mut FunctionCx<'_, '_, 'tcx>,\n-    layout: TyAndLayout<'tcx>,\n+    ty: Ty<'tcx>,\n     val: Value,\n-) -> CValue<'tcx> {\n-    let ty = fx.clif_type(layout.ty).unwrap();\n+) -> Value {\n+    let ty = fx.clif_type(ty).unwrap();\n \n     let int_ty = match ty {\n         types::F32 => types::I32,\n@@ -282,122 +222,7 @@ fn bool_to_zero_or_max_uint<'tcx>(\n         res = fx.bcx.ins().bitcast(ty, res);\n     }\n \n-    CValue::by_val(res, layout)\n-}\n-\n-macro simd_cmp {\n-    ($fx:expr, $cc:ident|$cc_f:ident($x:ident, $y:ident) -> $ret:ident) => {\n-        let vector_ty = clif_vector_type($fx.tcx, $x.layout());\n-\n-        if let Some(vector_ty) = vector_ty {\n-            let x = $x.load_scalar($fx);\n-            let y = $y.load_scalar($fx);\n-            let val = if vector_ty.lane_type().is_float() {\n-                $fx.bcx.ins().fcmp(FloatCC::$cc_f, x, y)\n-            } else {\n-                $fx.bcx.ins().icmp(IntCC::$cc, x, y)\n-            };\n-\n-            // HACK This depends on the fact that icmp for vectors represents bools as 0 and !0, not 0 and 1.\n-            let val = $fx.bcx.ins().raw_bitcast(vector_ty, val);\n-\n-            $ret.write_cvalue($fx, CValue::by_val(val, $ret.layout()));\n-        } else {\n-            simd_pair_for_each_lane(\n-                $fx,\n-                $x,\n-                $y,\n-                $ret,\n-                |fx, lane_layout, res_lane_layout, x_lane, y_lane| {\n-                    let res_lane = match lane_layout.ty.kind() {\n-                        ty::Uint(_) | ty::Int(_) => fx.bcx.ins().icmp(IntCC::$cc, x_lane, y_lane),\n-                        ty::Float(_) => fx.bcx.ins().fcmp(FloatCC::$cc_f, x_lane, y_lane),\n-                        _ => unreachable!(\"{:?}\", lane_layout.ty),\n-                    };\n-                    bool_to_zero_or_max_uint(fx, res_lane_layout, res_lane)\n-                },\n-            );\n-        }\n-    },\n-    ($fx:expr, $cc_u:ident|$cc_s:ident|$cc_f:ident($x:ident, $y:ident) -> $ret:ident) => {\n-        // FIXME use vector icmp when possible\n-        simd_pair_for_each_lane(\n-            $fx,\n-            $x,\n-            $y,\n-            $ret,\n-            |fx, lane_layout, res_lane_layout, x_lane, y_lane| {\n-                let res_lane = match lane_layout.ty.kind() {\n-                    ty::Uint(_) => fx.bcx.ins().icmp(IntCC::$cc_u, x_lane, y_lane),\n-                    ty::Int(_) => fx.bcx.ins().icmp(IntCC::$cc_s, x_lane, y_lane),\n-                    ty::Float(_) => fx.bcx.ins().fcmp(FloatCC::$cc_f, x_lane, y_lane),\n-                    _ => unreachable!(\"{:?}\", lane_layout.ty),\n-                };\n-                bool_to_zero_or_max_uint(fx, res_lane_layout, res_lane)\n-            },\n-        );\n-    },\n-}\n-\n-macro simd_int_binop {\n-    ($fx:expr, $op:ident($x:ident, $y:ident) -> $ret:ident) => {\n-        simd_int_binop!($fx, $op|$op($x, $y) -> $ret);\n-    },\n-    ($fx:expr, $op_u:ident|$op_s:ident($x:ident, $y:ident) -> $ret:ident) => {\n-        simd_pair_for_each_lane(\n-            $fx,\n-            $x,\n-            $y,\n-            $ret,\n-            |fx, lane_layout, ret_lane_layout, x_lane, y_lane| {\n-                let res_lane = match lane_layout.ty.kind() {\n-                    ty::Uint(_) => fx.bcx.ins().$op_u(x_lane, y_lane),\n-                    ty::Int(_) => fx.bcx.ins().$op_s(x_lane, y_lane),\n-                    _ => unreachable!(\"{:?}\", lane_layout.ty),\n-                };\n-                CValue::by_val(res_lane, ret_lane_layout)\n-            },\n-        );\n-    },\n-}\n-\n-macro simd_int_flt_binop {\n-    ($fx:expr, $op:ident|$op_f:ident($x:ident, $y:ident) -> $ret:ident) => {\n-        simd_int_flt_binop!($fx, $op|$op|$op_f($x, $y) -> $ret);\n-    },\n-    ($fx:expr, $op_u:ident|$op_s:ident|$op_f:ident($x:ident, $y:ident) -> $ret:ident) => {\n-        simd_pair_for_each_lane(\n-            $fx,\n-            $x,\n-            $y,\n-            $ret,\n-            |fx, lane_layout, ret_lane_layout, x_lane, y_lane| {\n-                let res_lane = match lane_layout.ty.kind() {\n-                    ty::Uint(_) => fx.bcx.ins().$op_u(x_lane, y_lane),\n-                    ty::Int(_) => fx.bcx.ins().$op_s(x_lane, y_lane),\n-                    ty::Float(_) => fx.bcx.ins().$op_f(x_lane, y_lane),\n-                    _ => unreachable!(\"{:?}\", lane_layout.ty),\n-                };\n-                CValue::by_val(res_lane, ret_lane_layout)\n-            },\n-        );\n-    },\n-}\n-\n-macro simd_flt_binop($fx:expr, $op:ident($x:ident, $y:ident) -> $ret:ident) {\n-    simd_pair_for_each_lane(\n-        $fx,\n-        $x,\n-        $y,\n-        $ret,\n-        |fx, lane_layout, ret_lane_layout, x_lane, y_lane| {\n-            let res_lane = match lane_layout.ty.kind() {\n-                ty::Float(_) => fx.bcx.ins().$op(x_lane, y_lane),\n-                _ => unreachable!(\"{:?}\", lane_layout.ty),\n-            };\n-            CValue::by_val(res_lane, ret_lane_layout)\n-        },\n-    );\n+    res\n }\n \n pub(crate) fn codegen_intrinsic_call<'tcx>(\n@@ -428,57 +253,109 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n     };\n \n     if intrinsic.as_str().starts_with(\"simd_\") {\n-        self::simd::codegen_simd_intrinsic_call(fx, instance, args, ret, span);\n+        self::simd::codegen_simd_intrinsic_call(fx, intrinsic, substs, args, ret, span);\n         let ret_block = fx.get_block(destination.expect(\"SIMD intrinsics don't diverge\").1);\n         fx.bcx.ins().jump(ret_block, &[]);\n-        return;\n+    } else if codegen_float_intrinsic_call(fx, intrinsic, args, ret) {\n+        let ret_block = fx.get_block(destination.expect(\"Float intrinsics don't diverge\").1);\n+        fx.bcx.ins().jump(ret_block, &[]);\n+    } else {\n+        codegen_regular_intrinsic_call(\n+            fx,\n+            instance,\n+            intrinsic,\n+            substs,\n+            args,\n+            ret,\n+            span,\n+            destination,\n+        );\n     }\n+}\n \n-    let usize_layout = fx.layout_of(fx.tcx.types.usize);\n+fn codegen_float_intrinsic_call<'tcx>(\n+    fx: &mut FunctionCx<'_, '_, 'tcx>,\n+    intrinsic: Symbol,\n+    args: &[mir::Operand<'tcx>],\n+    ret: CPlace<'tcx>,\n+) -> bool {\n+    let (name, arg_count, ty) = match intrinsic {\n+        sym::expf32 => (\"expf\", 1, fx.tcx.types.f32),\n+        sym::expf64 => (\"exp\", 1, fx.tcx.types.f64),\n+        sym::exp2f32 => (\"exp2f\", 1, fx.tcx.types.f32),\n+        sym::exp2f64 => (\"exp2\", 1, fx.tcx.types.f64),\n+        sym::sqrtf32 => (\"sqrtf\", 1, fx.tcx.types.f32),\n+        sym::sqrtf64 => (\"sqrt\", 1, fx.tcx.types.f64),\n+        sym::powif32 => (\"__powisf2\", 2, fx.tcx.types.f32), // compiler-builtins\n+        sym::powif64 => (\"__powidf2\", 2, fx.tcx.types.f64), // compiler-builtins\n+        sym::powf32 => (\"powf\", 2, fx.tcx.types.f32),\n+        sym::powf64 => (\"pow\", 2, fx.tcx.types.f64),\n+        sym::logf32 => (\"logf\", 1, fx.tcx.types.f32),\n+        sym::logf64 => (\"log\", 1, fx.tcx.types.f64),\n+        sym::log2f32 => (\"log2f\", 1, fx.tcx.types.f32),\n+        sym::log2f64 => (\"log2\", 1, fx.tcx.types.f64),\n+        sym::log10f32 => (\"log10f\", 1, fx.tcx.types.f32),\n+        sym::log10f64 => (\"log10\", 1, fx.tcx.types.f64),\n+        sym::fabsf32 => (\"fabsf\", 1, fx.tcx.types.f32),\n+        sym::fabsf64 => (\"fabs\", 1, fx.tcx.types.f64),\n+        sym::fmaf32 => (\"fmaf\", 3, fx.tcx.types.f32),\n+        sym::fmaf64 => (\"fma\", 3, fx.tcx.types.f64),\n+        sym::copysignf32 => (\"copysignf\", 2, fx.tcx.types.f32),\n+        sym::copysignf64 => (\"copysign\", 2, fx.tcx.types.f64),\n+        sym::floorf32 => (\"floorf\", 1, fx.tcx.types.f32),\n+        sym::floorf64 => (\"floor\", 1, fx.tcx.types.f64),\n+        sym::ceilf32 => (\"ceilf\", 1, fx.tcx.types.f32),\n+        sym::ceilf64 => (\"ceil\", 1, fx.tcx.types.f64),\n+        sym::truncf32 => (\"truncf\", 1, fx.tcx.types.f32),\n+        sym::truncf64 => (\"trunc\", 1, fx.tcx.types.f64),\n+        sym::roundf32 => (\"roundf\", 1, fx.tcx.types.f32),\n+        sym::roundf64 => (\"round\", 1, fx.tcx.types.f64),\n+        sym::sinf32 => (\"sinf\", 1, fx.tcx.types.f32),\n+        sym::sinf64 => (\"sin\", 1, fx.tcx.types.f64),\n+        sym::cosf32 => (\"cosf\", 1, fx.tcx.types.f32),\n+        sym::cosf64 => (\"cos\", 1, fx.tcx.types.f64),\n+        _ => return false,\n+    };\n \n-    call_intrinsic_match! {\n-        fx, intrinsic, substs, ret, destination, args,\n-        expf32(flt) -> f32 => expf,\n-        expf64(flt) -> f64 => exp,\n-        exp2f32(flt) -> f32 => exp2f,\n-        exp2f64(flt) -> f64 => exp2,\n-        sqrtf32(flt) -> f32 => sqrtf,\n-        sqrtf64(flt) -> f64 => sqrt,\n-        powif32(a, x) -> f32 => __powisf2, // compiler-builtins\n-        powif64(a, x) -> f64 => __powidf2, // compiler-builtins\n-        powf32(a, x) -> f32 => powf,\n-        powf64(a, x) -> f64 => pow,\n-        logf32(flt) -> f32 => logf,\n-        logf64(flt) -> f64 => log,\n-        log2f32(flt) -> f32 => log2f,\n-        log2f64(flt) -> f64 => log2,\n-        log10f32(flt) -> f32 => log10f,\n-        log10f64(flt) -> f64 => log10,\n-        fabsf32(flt) -> f32 => fabsf,\n-        fabsf64(flt) -> f64 => fabs,\n-        fmaf32(x, y, z) -> f32 => fmaf,\n-        fmaf64(x, y, z) -> f64 => fma,\n-        copysignf32(x, y) -> f32 => copysignf,\n-        copysignf64(x, y) -> f64 => copysign,\n-\n-        // rounding variants\n-        // FIXME use clif insts\n-        floorf32(flt) -> f32 => floorf,\n-        floorf64(flt) -> f64 => floor,\n-        ceilf32(flt) -> f32 => ceilf,\n-        ceilf64(flt) -> f64 => ceil,\n-        truncf32(flt) -> f32 => truncf,\n-        truncf64(flt) -> f64 => trunc,\n-        roundf32(flt) -> f32 => roundf,\n-        roundf64(flt) -> f64 => round,\n-\n-        // trigonometry\n-        sinf32(flt) -> f32 => sinf,\n-        sinf64(flt) -> f64 => sin,\n-        cosf32(flt) -> f32 => cosf,\n-        cosf64(flt) -> f64 => cos,\n+    if args.len() != arg_count {\n+        bug!(\"wrong number of args for intrinsic {:?}\", intrinsic);\n     }\n \n+    let (a, b, c);\n+    let args = match args {\n+        [x] => {\n+            a = [codegen_operand(fx, x)];\n+            &a as &[_]\n+        }\n+        [x, y] => {\n+            b = [codegen_operand(fx, x), codegen_operand(fx, y)];\n+            &b\n+        }\n+        [x, y, z] => {\n+            c = [codegen_operand(fx, x), codegen_operand(fx, y), codegen_operand(fx, z)];\n+            &c\n+        }\n+        _ => unreachable!(),\n+    };\n+\n+    let res = fx.easy_call(name, &args, ty);\n+    ret.write_cvalue(fx, res);\n+\n+    true\n+}\n+\n+fn codegen_regular_intrinsic_call<'tcx>(\n+    fx: &mut FunctionCx<'_, '_, 'tcx>,\n+    instance: Instance<'tcx>,\n+    intrinsic: Symbol,\n+    substs: SubstsRef<'tcx>,\n+    args: &[mir::Operand<'tcx>],\n+    ret: CPlace<'tcx>,\n+    span: Span,\n+    destination: Option<(CPlace<'tcx>, BasicBlock)>,\n+) {\n+    let usize_layout = fx.layout_of(fx.tcx.types.usize);\n+\n     intrinsic_match! {\n         fx, intrinsic, substs, args,\n         _ => {\n@@ -492,7 +369,8 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n         breakpoint, () {\n             fx.bcx.ins().debugtrap();\n         };\n-        copy | copy_nonoverlapping, <elem_ty> (v src, v dst, v count) {\n+        copy | copy_nonoverlapping, (v src, v dst, v count) {\n+            let elem_ty = substs.type_at(0);\n             let elem_size: u64 = fx.layout_of(elem_ty).size.bytes();\n             assert_eq!(args.len(), 3);\n             let byte_amount = if elem_size != 1 {\n@@ -510,7 +388,8 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             }\n         };\n         // NOTE: the volatile variants have src and dst swapped\n-        volatile_copy_memory | volatile_copy_nonoverlapping_memory, <elem_ty> (v dst, v src, v count) {\n+        volatile_copy_memory | volatile_copy_nonoverlapping_memory, (v dst, v src, v count) {\n+            let elem_ty = substs.type_at(0);\n             let elem_size: u64 = fx.layout_of(elem_ty).size.bytes();\n             assert_eq!(args.len(), 3);\n             let byte_amount = if elem_size != 1 {\n@@ -528,8 +407,8 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n                 fx.bcx.call_memmove(fx.target_config, dst, src, byte_amount);\n             }\n         };\n-        size_of_val, <T> (c ptr) {\n-            let layout = fx.layout_of(T);\n+        size_of_val, (c ptr) {\n+            let layout = fx.layout_of(substs.type_at(0));\n             let size = if layout.is_unsized() {\n                 let (_ptr, info) = ptr.load_scalar_pair(fx);\n                 let (size, _align) = crate::unsize::size_and_align_of_dst(fx, layout, info);\n@@ -542,8 +421,8 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             };\n             ret.write_cvalue(fx, CValue::by_val(size, usize_layout));\n         };\n-        min_align_of_val, <T> (c ptr) {\n-            let layout = fx.layout_of(T);\n+        min_align_of_val, (c ptr) {\n+            let layout = fx.layout_of(substs.type_at(0));\n             let align = if layout.is_unsized() {\n                 let (_ptr, info) = ptr.load_scalar_pair(fx);\n                 let (_size, align) = crate::unsize::size_and_align_of_dst(fx, layout, info);\n@@ -589,15 +468,15 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             );\n             ret.write_cvalue(fx, res);\n         };\n-        saturating_add | saturating_sub, <T> (c lhs, c rhs) {\n+        saturating_add | saturating_sub, (c lhs, c rhs) {\n             assert_eq!(lhs.layout().ty, rhs.layout().ty);\n             let bin_op = match intrinsic {\n                 sym::saturating_add => BinOp::Add,\n                 sym::saturating_sub => BinOp::Sub,\n                 _ => unreachable!(),\n             };\n \n-            let signed = type_sign(T);\n+            let signed = type_sign(lhs.layout().ty);\n \n             let checked_res = crate::num::codegen_checked_int_binop(\n                 fx,\n@@ -607,7 +486,7 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             );\n \n             let (val, has_overflow) = checked_res.load_scalar_pair(fx);\n-            let clif_ty = fx.clif_type(T).unwrap();\n+            let clif_ty = fx.clif_type(lhs.layout().ty).unwrap();\n \n             let (min, max) = type_min_max_value(&mut fx.bcx, clif_ty, signed);\n \n@@ -629,17 +508,19 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n                 _ => unreachable!(),\n             };\n \n-            let res = CValue::by_val(val, fx.layout_of(T));\n+            let res = CValue::by_val(val, lhs.layout());\n \n             ret.write_cvalue(fx, res);\n         };\n-        rotate_left, <T>(v x, v y) {\n-            let layout = fx.layout_of(T);\n+        rotate_left, (c x, v y) {\n+            let layout = x.layout();\n+            let x = x.load_scalar(fx);\n             let res = fx.bcx.ins().rotl(x, y);\n             ret.write_cvalue(fx, CValue::by_val(res, layout));\n         };\n-        rotate_right, <T>(v x, v y) {\n-            let layout = fx.layout_of(T);\n+        rotate_right, (c x, v y) {\n+            let layout = x.layout();\n+            let x = x.load_scalar(fx);\n             let res = fx.bcx.ins().rotr(x, y);\n             ret.write_cvalue(fx, CValue::by_val(res, layout));\n         };\n@@ -675,29 +556,33 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             // FIXME use emit_small_memset\n             fx.bcx.call_memset(fx.target_config, dst_ptr, val, count);\n         };\n-        ctlz | ctlz_nonzero, <T> (v arg) {\n+        ctlz | ctlz_nonzero, (c arg) {\n+            let val = arg.load_scalar(fx);\n             // FIXME trap on `ctlz_nonzero` with zero arg.\n-            let res = fx.bcx.ins().clz(arg);\n-            let res = CValue::by_val(res, fx.layout_of(T));\n+            let res = fx.bcx.ins().clz(val);\n+            let res = CValue::by_val(res, arg.layout());\n             ret.write_cvalue(fx, res);\n         };\n-        cttz | cttz_nonzero, <T> (v arg) {\n+        cttz | cttz_nonzero, (c arg) {\n+            let val = arg.load_scalar(fx);\n             // FIXME trap on `cttz_nonzero` with zero arg.\n-            let res = fx.bcx.ins().ctz(arg);\n-            let res = CValue::by_val(res, fx.layout_of(T));\n+            let res = fx.bcx.ins().ctz(val);\n+            let res = CValue::by_val(res, arg.layout());\n             ret.write_cvalue(fx, res);\n         };\n-        ctpop, <T> (v arg) {\n-            let res = fx.bcx.ins().popcnt(arg);\n-            let res = CValue::by_val(res, fx.layout_of(T));\n+        ctpop, (c arg) {\n+            let val = arg.load_scalar(fx);\n+            let res = fx.bcx.ins().popcnt(val);\n+            let res = CValue::by_val(res, arg.layout());\n             ret.write_cvalue(fx, res);\n         };\n-        bitreverse, <T> (v arg) {\n-            let res = fx.bcx.ins().bitrev(arg);\n-            let res = CValue::by_val(res, fx.layout_of(T));\n+        bitreverse, (c arg) {\n+            let val = arg.load_scalar(fx);\n+            let res = fx.bcx.ins().bitrev(val);\n+            let res = CValue::by_val(res, arg.layout());\n             ret.write_cvalue(fx, res);\n         };\n-        bswap, <T> (v arg) {\n+        bswap, (c arg) {\n             // FIXME(CraneStation/cranelift#794) add bswap instruction to cranelift\n             fn swap(bcx: &mut FunctionBuilder<'_>, v: Value) -> Value {\n                 match bcx.func.dfg.value_type(v) {\n@@ -773,15 +658,16 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n                     ty => unreachable!(\"bswap {}\", ty),\n                 }\n             }\n-            let res = CValue::by_val(swap(&mut fx.bcx, arg), fx.layout_of(T));\n+            let val = arg.load_scalar(fx);\n+            let res = CValue::by_val(swap(&mut fx.bcx, val), arg.layout());\n             ret.write_cvalue(fx, res);\n         };\n-        assert_inhabited | assert_zero_valid | assert_uninit_valid, <T> () {\n-            let layout = fx.layout_of(T);\n+        assert_inhabited | assert_zero_valid | assert_uninit_valid, () {\n+            let layout = fx.layout_of(substs.type_at(0));\n             if layout.abi.is_uninhabited() {\n                 with_no_trimmed_paths(|| crate::base::codegen_panic(\n                     fx,\n-                    &format!(\"attempted to instantiate uninhabited type `{}`\", T),\n+                    &format!(\"attempted to instantiate uninhabited type `{}`\", layout.ty),\n                     span,\n                 ));\n                 return;\n@@ -790,7 +676,7 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             if intrinsic == sym::assert_zero_valid && !layout.might_permit_raw_init(fx, /*zero:*/ true) {\n                 with_no_trimmed_paths(|| crate::base::codegen_panic(\n                     fx,\n-                    &format!(\"attempted to zero-initialize type `{}`, which is invalid\", T),\n+                    &format!(\"attempted to zero-initialize type `{}`, which is invalid\", layout.ty),\n                     span,\n                 ));\n                 return;\n@@ -799,7 +685,7 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             if intrinsic == sym::assert_uninit_valid && !layout.might_permit_raw_init(fx, /*zero:*/ false) {\n                 with_no_trimmed_paths(|| crate::base::codegen_panic(\n                     fx,\n-                    &format!(\"attempted to leave type `{}` uninitialized, which is invalid\", T),\n+                    &format!(\"attempted to leave type `{}` uninitialized, which is invalid\", layout.ty),\n                     span,\n                 ));\n                 return;\n@@ -832,10 +718,11 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             ret.write_cvalue(fx, val);\n         };\n \n-        ptr_offset_from, <T> (v ptr, v base) {\n+        ptr_offset_from, (v ptr, v base) {\n+            let ty = substs.type_at(0);\n             let isize_layout = fx.layout_of(fx.tcx.types.isize);\n \n-            let pointee_size: u64 = fx.layout_of(T).size.bytes();\n+            let pointee_size: u64 = fx.layout_of(ty).size.bytes();\n             let diff = fx.bcx.ins().isub(ptr, base);\n             // FIXME this can be an exact division.\n             let val = CValue::by_val(fx.bcx.ins().sdiv_imm(diff, pointee_size as i64), isize_layout);\n@@ -864,13 +751,14 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             // FIXME use a compiler fence once Cranelift supports it\n             fx.bcx.ins().fence();\n         };\n-        _ if intrinsic.as_str().starts_with(\"atomic_load\"), <T> (v ptr) {\n-            validate_atomic_type!(fx, intrinsic, span, T);\n-            let ty = fx.clif_type(T).unwrap();\n+        _ if intrinsic.as_str().starts_with(\"atomic_load\"), (v ptr) {\n+            let ty = substs.type_at(0);\n+            validate_atomic_type!(fx, intrinsic, span, ty);\n+            let clif_ty = fx.clif_type(ty).unwrap();\n \n-            let val = fx.bcx.ins().atomic_load(ty, MemFlags::trusted(), ptr);\n+            let val = fx.bcx.ins().atomic_load(clif_ty, MemFlags::trusted(), ptr);\n \n-            let val = CValue::by_val(val, fx.layout_of(T));\n+            let val = CValue::by_val(val, fx.layout_of(ty));\n             ret.write_cvalue(fx, val);\n         };\n         _ if intrinsic.as_str().starts_with(\"atomic_store\"), (v ptr, c val) {\n@@ -1101,18 +989,14 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n             ret.write_cvalue(fx, CValue::by_val(res, ret.layout()));\n         };\n \n-        raw_eq, <T>(v lhs_ref, v rhs_ref) {\n-            fn type_by_size(size: Size) -> Option<Type> {\n-                Type::int(size.bits().try_into().ok()?)\n-            }\n-\n-            let size = fx.layout_of(T).layout.size;\n+        raw_eq, (v lhs_ref, v rhs_ref) {\n+            let size = fx.layout_of(substs.type_at(0)).layout.size;\n             // FIXME add and use emit_small_memcmp\n             let is_eq_value =\n                 if size == Size::ZERO {\n                     // No bytes means they're trivially equal\n                     fx.bcx.ins().iconst(types::I8, 1)\n-                } else if let Some(clty) = type_by_size(size) {\n+                } else if let Some(clty) = size.bits().try_into().ok().and_then(Type::int) {\n                     // Can't use `trusted` for these loads; they could be unaligned.\n                     let mut flags = MemFlags::new();\n                     flags.set_notrap();"}, {"sha": "106a190096dbaa3dabb536d33b9d4ef4b06140fe", "filename": "src/intrinsics/simd.rs", "status": "modified", "additions": 152, "deletions": 103, "changes": 255, "blob_url": "https://github.com/rust-lang/rust/blob/f328359787c19f27d93506e537442f417d5e86f5/src%2Fintrinsics%2Fsimd.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f328359787c19f27d93506e537442f417d5e86f5/src%2Fintrinsics%2Fsimd.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsics%2Fsimd.rs?ref=f328359787c19f27d93506e537442f417d5e86f5", "patch": "@@ -1,61 +1,118 @@\n //! Codegen `extern \"platform-intrinsic\"` intrinsics.\n \n+use rustc_middle::ty::subst::SubstsRef;\n+use rustc_span::Symbol;\n+\n use super::*;\n use crate::prelude::*;\n \n+fn validate_simd_type(fx: &mut FunctionCx<'_, '_, '_>, intrinsic: Symbol, span: Span, ty: Ty<'_>) {\n+    if !ty.is_simd() {\n+        fx.tcx.sess.span_err(span, &format!(\"invalid monomorphization of `{}` intrinsic: expected SIMD input type, found non-SIMD `{}`\", intrinsic, ty));\n+        // Prevent verifier error\n+        crate::trap::trap_unreachable(fx, \"compilation should not have succeeded\");\n+        return;\n+    }\n+}\n+\n+macro simd_cmp($fx:expr, $cc_u:ident|$cc_s:ident|$cc_f:ident($x:ident, $y:ident) -> $ret:ident) {\n+    // FIXME use vector instructions when possible\n+    simd_pair_for_each_lane($fx, $x, $y, $ret, &|fx, lane_ty, res_lane_ty, x_lane, y_lane| {\n+        let res_lane = match lane_ty.kind() {\n+            ty::Uint(_) => fx.bcx.ins().icmp(IntCC::$cc_u, x_lane, y_lane),\n+            ty::Int(_) => fx.bcx.ins().icmp(IntCC::$cc_s, x_lane, y_lane),\n+            ty::Float(_) => fx.bcx.ins().fcmp(FloatCC::$cc_f, x_lane, y_lane),\n+            _ => unreachable!(\"{:?}\", lane_ty),\n+        };\n+\n+        let ty = fx.clif_type(res_lane_ty).unwrap();\n+\n+        let res_lane = fx.bcx.ins().bint(ty, res_lane);\n+        fx.bcx.ins().ineg(res_lane)\n+    });\n+}\n+\n+macro simd_int_binop($fx:expr, $op_u:ident|$op_s:ident($x:ident, $y:ident) -> $ret:ident) {\n+    // FIXME use vector instructions when possible\n+    simd_pair_for_each_lane($fx, $x, $y, $ret, &|fx, lane_ty, _ret_lane_ty, x_lane, y_lane| {\n+        match lane_ty.kind() {\n+            ty::Uint(_) => fx.bcx.ins().$op_u(x_lane, y_lane),\n+            ty::Int(_) => fx.bcx.ins().$op_s(x_lane, y_lane),\n+            _ => unreachable!(\"{:?}\", lane_ty),\n+        }\n+    });\n+}\n+\n+macro simd_int_flt_binop($fx:expr, $op_u:ident|$op_s:ident|$op_f:ident($x:ident, $y:ident) -> $ret:ident) {\n+    // FIXME use vector instructions when possible\n+    simd_pair_for_each_lane($fx, $x, $y, $ret, &|fx, lane_ty, _ret_lane_ty, x_lane, y_lane| {\n+        match lane_ty.kind() {\n+            ty::Uint(_) => fx.bcx.ins().$op_u(x_lane, y_lane),\n+            ty::Int(_) => fx.bcx.ins().$op_s(x_lane, y_lane),\n+            ty::Float(_) => fx.bcx.ins().$op_f(x_lane, y_lane),\n+            _ => unreachable!(\"{:?}\", lane_ty),\n+        }\n+    });\n+}\n+\n+macro simd_flt_binop($fx:expr, $op:ident($x:ident, $y:ident) -> $ret:ident) {\n+    // FIXME use vector instructions when possible\n+    simd_pair_for_each_lane($fx, $x, $y, $ret, &|fx, lane_ty, _ret_lane_ty, x_lane, y_lane| {\n+        match lane_ty.kind() {\n+            ty::Float(_) => fx.bcx.ins().$op(x_lane, y_lane),\n+            _ => unreachable!(\"{:?}\", lane_ty),\n+        }\n+    });\n+}\n+\n pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n     fx: &mut FunctionCx<'_, '_, 'tcx>,\n-    instance: Instance<'tcx>,\n+    intrinsic: Symbol,\n+    substs: SubstsRef<'tcx>,\n     args: &[mir::Operand<'tcx>],\n     ret: CPlace<'tcx>,\n     span: Span,\n ) {\n-    let def_id = instance.def_id();\n-    let substs = instance.substs;\n-\n-    let intrinsic = fx.tcx.item_name(def_id);\n-\n     intrinsic_match! {\n         fx, intrinsic, substs, args,\n         _ => {\n             fx.tcx.sess.span_fatal(span, &format!(\"Unknown SIMD intrinsic {}\", intrinsic));\n         };\n \n         simd_cast, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, lane_layout, ret_lane_layout, lane| {\n-                let ret_lane_ty = fx.clif_type(ret_lane_layout.ty).unwrap();\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, lane_ty, ret_lane_ty, lane| {\n+                let ret_lane_clif_ty = fx.clif_type(ret_lane_ty).unwrap();\n \n-                let from_signed = type_sign(lane_layout.ty);\n-                let to_signed = type_sign(ret_lane_layout.ty);\n+                let from_signed = type_sign(lane_ty);\n+                let to_signed = type_sign(ret_lane_ty);\n \n-                let ret_lane = clif_int_or_float_cast(fx, lane, from_signed, ret_lane_ty, to_signed);\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+                clif_int_or_float_cast(fx, lane, from_signed, ret_lane_clif_ty, to_signed)\n             });\n         };\n \n         simd_eq, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_cmp!(fx, Equal|Equal(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_cmp!(fx, Equal|Equal|Equal(x, y) -> ret);\n         };\n         simd_ne, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_cmp!(fx, NotEqual|NotEqual(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_cmp!(fx, NotEqual|NotEqual|NotEqual(x, y) -> ret);\n         };\n         simd_lt, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_cmp!(fx, UnsignedLessThan|SignedLessThan|LessThan(x, y) -> ret);\n         };\n         simd_le, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_cmp!(fx, UnsignedLessThanOrEqual|SignedLessThanOrEqual|LessThanOrEqual(x, y) -> ret);\n         };\n         simd_gt, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_cmp!(fx, UnsignedGreaterThan|SignedGreaterThan|GreaterThan(x, y) -> ret);\n         };\n         simd_ge, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_cmp!(\n                 fx,\n                 UnsignedGreaterThanOrEqual|SignedGreaterThanOrEqual|GreaterThanOrEqual\n@@ -65,7 +122,7 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n \n         // simd_shuffle32<T, U>(x: T, y: T, idx: [u32; 32]) -> U\n         _ if intrinsic.as_str().starts_with(\"simd_shuffle\"), (c x, c y, o idx) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n \n             // If this intrinsic is the older \"simd_shuffleN\" form, simply parse the integer.\n             // If there is no suffix, use the index array length.\n@@ -167,7 +224,7 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_extract, (c v, o idx) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n             let idx_const = if let Some(idx_const) = crate::constant::mir_operand_get_const_val(fx, idx) {\n                 idx_const\n             } else {\n@@ -195,53 +252,50 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_neg, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, lane_layout, ret_lane_layout, lane| {\n-                let ret_lane = match lane_layout.ty.kind() {\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, lane_ty, _ret_lane_ty, lane| {\n+                match lane_ty.kind() {\n                     ty::Int(_) => fx.bcx.ins().ineg(lane),\n                     ty::Float(_) => fx.bcx.ins().fneg(lane),\n                     _ => unreachable!(),\n-                };\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+                }\n             });\n         };\n \n         simd_fabs, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, ret_lane_layout, lane| {\n-                let ret_lane = fx.bcx.ins().fabs(lane);\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _ret_lane_ty, lane| {\n+                fx.bcx.ins().fabs(lane)\n             });\n         };\n \n         simd_fsqrt, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, ret_lane_layout, lane| {\n-                let ret_lane = fx.bcx.ins().sqrt(lane);\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _ret_lane_ty, lane| {\n+                fx.bcx.ins().sqrt(lane)\n             });\n         };\n \n         simd_add, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_flt_binop!(fx, iadd|fadd(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_flt_binop!(fx, iadd|iadd|fadd(x, y) -> ret);\n         };\n         simd_sub, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_flt_binop!(fx, isub|fsub(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_flt_binop!(fx, isub|isub|fsub(x, y) -> ret);\n         };\n         simd_mul, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_flt_binop!(fx, imul|fmul(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_flt_binop!(fx, imul|imul|fmul(x, y) -> ret);\n         };\n         simd_div, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_int_flt_binop!(fx, udiv|sdiv|fdiv(x, y) -> ret);\n         };\n         simd_rem, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_pair_for_each_lane(fx, x, y, ret, |fx, lane_layout, ret_lane_layout, x_lane, y_lane| {\n-                let res_lane = match lane_layout.ty.kind() {\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_pair_for_each_lane(fx, x, y, ret, &|fx, lane_ty, _ret_lane_ty, x_lane, y_lane| {\n+                match lane_ty.kind() {\n                     ty::Uint(_) => fx.bcx.ins().urem(x_lane, y_lane),\n                     ty::Int(_) => fx.bcx.ins().srem(x_lane, y_lane),\n                     ty::Float(FloatTy::F32) => fx.lib_call(\n@@ -256,34 +310,33 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n                         vec![AbiParam::new(types::F64)],\n                         &[x_lane, y_lane],\n                     )[0],\n-                    _ => unreachable!(\"{:?}\", lane_layout.ty),\n-                };\n-                CValue::by_val(res_lane, ret_lane_layout)\n+                    _ => unreachable!(\"{:?}\", lane_ty),\n+                }\n             });\n         };\n         simd_shl, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_binop!(fx, ishl(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_binop!(fx, ishl|ishl(x, y) -> ret);\n         };\n         simd_shr, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_int_binop!(fx, ushr|sshr(x, y) -> ret);\n         };\n         simd_and, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_binop!(fx, band(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_binop!(fx, band|band(x, y) -> ret);\n         };\n         simd_or, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_binop!(fx, bor(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_binop!(fx, bor|bor(x, y) -> ret);\n         };\n         simd_xor, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n-            simd_int_binop!(fx, bxor(x, y) -> ret);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n+            simd_int_binop!(fx, bxor|bxor(x, y) -> ret);\n         };\n \n         simd_fma, (c a, c b, c c) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n             assert_eq!(a.layout(), b.layout());\n             assert_eq!(a.layout(), c.layout());\n             let layout = a.layout();\n@@ -306,18 +359,18 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_fmin, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_flt_binop!(fx, fmin(x, y) -> ret);\n         };\n         simd_fmax, (c x, c y) {\n-            validate_simd_type!(fx, intrinsic, span, x.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, x.layout().ty);\n             simd_flt_binop!(fx, fmax(x, y) -> ret);\n         };\n \n         simd_round, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, lane_layout, ret_lane_layout, lane| {\n-                let res_lane = match lane_layout.ty.kind() {\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, lane_ty, _ret_lane_ty, lane| {\n+                match lane_ty.kind() {\n                     ty::Float(FloatTy::F32) => fx.lib_call(\n                         \"roundf\",\n                         vec![AbiParam::new(types::F32)],\n@@ -330,37 +383,33 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n                         vec![AbiParam::new(types::F64)],\n                         &[lane],\n                     )[0],\n-                    _ => unreachable!(\"{:?}\", lane_layout.ty),\n-                };\n-                CValue::by_val(res_lane, ret_lane_layout)\n+                    _ => unreachable!(\"{:?}\", lane_ty),\n+                }\n             });\n         };\n         simd_ceil, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, ret_lane_layout, lane| {\n-                let ret_lane = fx.bcx.ins().ceil(lane);\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _ret_lane_ty, lane| {\n+                fx.bcx.ins().ceil(lane)\n             });\n         };\n         simd_floor, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, ret_lane_layout, lane| {\n-                let ret_lane = fx.bcx.ins().floor(lane);\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _ret_lane_ty, lane| {\n+                fx.bcx.ins().floor(lane)\n             });\n         };\n         simd_trunc, (c a) {\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n-            simd_for_each_lane(fx, a, ret, |fx, _lane_layout, ret_lane_layout, lane| {\n-                let ret_lane = fx.bcx.ins().trunc(lane);\n-                CValue::by_val(ret_lane, ret_lane_layout)\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n+            simd_for_each_lane(fx, a, ret, &|fx, _lane_ty, _ret_lane_ty, lane| {\n+                fx.bcx.ins().trunc(lane)\n             });\n         };\n \n         simd_reduce_add_ordered | simd_reduce_add_unordered, (c v, v acc) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, Some(acc), ret, |fx, lane_layout, a, b| {\n-                if lane_layout.ty.is_floating_point() {\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, Some(acc), ret, &|fx, lane_ty, a, b| {\n+                if lane_ty.is_floating_point() {\n                     fx.bcx.ins().fadd(a, b)\n                 } else {\n                     fx.bcx.ins().iadd(a, b)\n@@ -369,9 +418,9 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_reduce_mul_ordered | simd_reduce_mul_unordered, (c v, v acc) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, Some(acc), ret, |fx, lane_layout, a, b| {\n-                if lane_layout.ty.is_floating_point() {\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, Some(acc), ret, &|fx, lane_ty, a, b| {\n+                if lane_ty.is_floating_point() {\n                     fx.bcx.ins().fmul(a, b)\n                 } else {\n                     fx.bcx.ins().imul(a, b)\n@@ -380,34 +429,34 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_reduce_all, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce_bool(fx, v, ret, |fx, a, b| fx.bcx.ins().band(a, b));\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce_bool(fx, v, ret, &|fx, a, b| fx.bcx.ins().band(a, b));\n         };\n \n         simd_reduce_any, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce_bool(fx, v, ret, |fx, a, b| fx.bcx.ins().bor(a, b));\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce_bool(fx, v, ret, &|fx, a, b| fx.bcx.ins().bor(a, b));\n         };\n \n         simd_reduce_and, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, None, ret, |fx, _layout, a, b| fx.bcx.ins().band(a, b));\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, None, ret, &|fx, _ty, a, b| fx.bcx.ins().band(a, b));\n         };\n \n         simd_reduce_or, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, None, ret, |fx, _layout, a, b| fx.bcx.ins().bor(a, b));\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, None, ret, &|fx, _ty, a, b| fx.bcx.ins().bor(a, b));\n         };\n \n         simd_reduce_xor, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, None, ret, |fx, _layout, a, b| fx.bcx.ins().bxor(a, b));\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, None, ret, &|fx, _ty, a, b| fx.bcx.ins().bxor(a, b));\n         };\n \n         simd_reduce_min, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, None, ret, |fx, layout, a, b| {\n-                let lt = match layout.ty.kind() {\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, None, ret, &|fx, ty, a, b| {\n+                let lt = match ty.kind() {\n                     ty::Int(_) => fx.bcx.ins().icmp(IntCC::SignedLessThan, a, b),\n                     ty::Uint(_) => fx.bcx.ins().icmp(IntCC::UnsignedLessThan, a, b),\n                     ty::Float(_) => fx.bcx.ins().fcmp(FloatCC::LessThan, a, b),\n@@ -418,9 +467,9 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_reduce_max, (c v) {\n-            validate_simd_type!(fx, intrinsic, span, v.layout().ty);\n-            simd_reduce(fx, v, None, ret, |fx, layout, a, b| {\n-                let gt = match layout.ty.kind() {\n+            validate_simd_type(fx, intrinsic, span, v.layout().ty);\n+            simd_reduce(fx, v, None, ret, &|fx, ty, a, b| {\n+                let gt = match ty.kind() {\n                     ty::Int(_) => fx.bcx.ins().icmp(IntCC::SignedGreaterThan, a, b),\n                     ty::Uint(_) => fx.bcx.ins().icmp(IntCC::UnsignedGreaterThan, a, b),\n                     ty::Float(_) => fx.bcx.ins().fcmp(FloatCC::GreaterThan, a, b),\n@@ -431,8 +480,8 @@ pub(super) fn codegen_simd_intrinsic_call<'tcx>(\n         };\n \n         simd_select, (c m, c a, c b) {\n-            validate_simd_type!(fx, intrinsic, span, m.layout().ty);\n-            validate_simd_type!(fx, intrinsic, span, a.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, m.layout().ty);\n+            validate_simd_type(fx, intrinsic, span, a.layout().ty);\n             assert_eq!(a.layout(), b.layout());\n \n             let (lane_count, lane_ty) = a.layout().ty.simd_size_and_type(fx.tcx);"}]}