{"sha": "b4cf2cdf870512373a656393f393bce84eb78d80", "node_id": "C_kwDOAAsO6NoAKGI0Y2YyY2RmODcwNTEyMzczYTY1NjM5M2YzOTNiY2U4NGViNzhkODA", "commit": {"author": {"name": "Camille GILLOT", "email": "gillot.camille@gmail.com", "date": "2022-04-10T13:39:12Z"}, "committer": {"name": "Camille GILLOT", "email": "gillot.camille@gmail.com", "date": "2022-04-10T14:59:51Z"}, "message": "Simplify FixedSizeEncoding using const generics.", "tree": {"sha": "0b90ec84b072fafb64c726563d24e7c053bbcc2a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0b90ec84b072fafb64c726563d24e7c053bbcc2a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b4cf2cdf870512373a656393f393bce84eb78d80", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b4cf2cdf870512373a656393f393bce84eb78d80", "html_url": "https://github.com/rust-lang/rust/commit/b4cf2cdf870512373a656393f393bce84eb78d80", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b4cf2cdf870512373a656393f393bce84eb78d80/comments", "author": {"login": "cjgillot", "id": 1822483, "node_id": "MDQ6VXNlcjE4MjI0ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/1822483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjgillot", "html_url": "https://github.com/cjgillot", "followers_url": "https://api.github.com/users/cjgillot/followers", "following_url": "https://api.github.com/users/cjgillot/following{/other_user}", "gists_url": "https://api.github.com/users/cjgillot/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjgillot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjgillot/subscriptions", "organizations_url": "https://api.github.com/users/cjgillot/orgs", "repos_url": "https://api.github.com/users/cjgillot/repos", "events_url": "https://api.github.com/users/cjgillot/events{/privacy}", "received_events_url": "https://api.github.com/users/cjgillot/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cjgillot", "id": 1822483, "node_id": "MDQ6VXNlcjE4MjI0ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/1822483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjgillot", "html_url": "https://github.com/cjgillot", "followers_url": "https://api.github.com/users/cjgillot/followers", "following_url": "https://api.github.com/users/cjgillot/following{/other_user}", "gists_url": "https://api.github.com/users/cjgillot/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjgillot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjgillot/subscriptions", "organizations_url": "https://api.github.com/users/cjgillot/orgs", "repos_url": "https://api.github.com/users/cjgillot/repos", "events_url": "https://api.github.com/users/cjgillot/events{/privacy}", "received_events_url": "https://api.github.com/users/cjgillot/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b9287a83c5691568827f056bea0241a0bdb72f18", "url": "https://api.github.com/repos/rust-lang/rust/commits/b9287a83c5691568827f056bea0241a0bdb72f18", "html_url": "https://github.com/rust-lang/rust/commit/b9287a83c5691568827f056bea0241a0bdb72f18"}], "stats": {"total": 193, "additions": 86, "deletions": 107}, "files": [{"sha": "aebd293f6c211976ada0edc86622a1fed6239cee", "filename": "compiler/rustc_metadata/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b4cf2cdf870512373a656393f393bce84eb78d80/compiler%2Frustc_metadata%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b4cf2cdf870512373a656393f393bce84eb78d80/compiler%2Frustc_metadata%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_metadata%2Fsrc%2Flib.rs?ref=b4cf2cdf870512373a656393f393bce84eb78d80", "patch": "@@ -7,6 +7,7 @@\n #![feature(proc_macro_internals)]\n #![feature(macro_metavar_expr)]\n #![feature(min_specialization)]\n+#![feature(slice_as_chunks)]\n #![feature(try_blocks)]\n #![feature(never_type)]\n #![recursion_limit = \"256\"]"}, {"sha": "7a23cba536a0a18bfdfbc69b4fb3cda5333aacad", "filename": "compiler/rustc_metadata/src/rmeta/table.rs", "status": "modified", "additions": 85, "deletions": 107, "changes": 192, "blob_url": "https://github.com/rust-lang/rust/blob/b4cf2cdf870512373a656393f393bce84eb78d80/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Ftable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b4cf2cdf870512373a656393f393bce84eb78d80/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Ftable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Ftable.rs?ref=b4cf2cdf870512373a656393f393bce84eb78d80", "patch": "@@ -16,76 +16,34 @@ use tracing::debug;\n /// Unchecked invariant: `Self::default()` should encode as `[0; BYTE_LEN]`,\n /// but this has no impact on safety.\n pub(super) trait FixedSizeEncoding: Default {\n-    const BYTE_LEN: usize;\n-\n-    // FIXME(eddyb) convert to and from `[u8; Self::BYTE_LEN]` instead,\n-    // once that starts being allowed by the compiler (i.e. lazy normalization).\n-    fn from_bytes(b: &[u8]) -> Self;\n-    fn write_to_bytes(self, b: &mut [u8]);\n-\n-    // FIXME(eddyb) make these generic functions, or at least defaults here.\n-    // (same problem as above, needs `[u8; Self::BYTE_LEN]`)\n-    // For now, a macro (`fixed_size_encoding_byte_len_and_defaults`) is used.\n-\n-    /// Read a `Self` value (encoded as `Self::BYTE_LEN` bytes),\n-    /// from `&b[i * Self::BYTE_LEN..]`, returning `None` if `i`\n-    /// is not in bounds, or `Some(Self::from_bytes(...))` otherwise.\n-    fn maybe_read_from_bytes_at(b: &[u8], i: usize) -> Option<Self>;\n-    /// Write a `Self` value (encoded as `Self::BYTE_LEN` bytes),\n-    /// at `&mut b[i * Self::BYTE_LEN..]`, using `Self::write_to_bytes`.\n-    fn write_to_bytes_at(self, b: &mut [u8], i: usize);\n-}\n+    /// This should be `[u8; BYTE_LEN]`;\n+    type ByteArray;\n \n-// HACK(eddyb) this shouldn't be needed (see comments on the methods above).\n-macro_rules! fixed_size_encoding_byte_len_and_defaults {\n-    ($byte_len:expr) => {\n-        const BYTE_LEN: usize = $byte_len;\n-        fn maybe_read_from_bytes_at(b: &[u8], i: usize) -> Option<Self> {\n-            const BYTE_LEN: usize = $byte_len;\n-            // HACK(eddyb) ideally this would be done with fully safe code,\n-            // but slicing `[u8]` with `i * N..` is optimized worse, due to the\n-            // possibility of `i * N` overflowing, than indexing `[[u8; N]]`.\n-            let b = unsafe {\n-                std::slice::from_raw_parts(b.as_ptr() as *const [u8; BYTE_LEN], b.len() / BYTE_LEN)\n-            };\n-            b.get(i).map(|b| FixedSizeEncoding::from_bytes(b))\n-        }\n-        fn write_to_bytes_at(self, b: &mut [u8], i: usize) {\n-            const BYTE_LEN: usize = $byte_len;\n-            // HACK(eddyb) ideally this would be done with fully safe code,\n-            // see similar comment in `read_from_bytes_at` for why it can't yet.\n-            let b = unsafe {\n-                std::slice::from_raw_parts_mut(\n-                    b.as_mut_ptr() as *mut [u8; BYTE_LEN],\n-                    b.len() / BYTE_LEN,\n-                )\n-            };\n-            self.write_to_bytes(&mut b[i]);\n-        }\n-    };\n+    fn from_bytes(b: &Self::ByteArray) -> Self;\n+    fn write_to_bytes(self, b: &mut Self::ByteArray);\n }\n \n impl FixedSizeEncoding for u32 {\n-    fixed_size_encoding_byte_len_and_defaults!(4);\n+    type ByteArray = [u8; 4];\n \n-    fn from_bytes(b: &[u8]) -> Self {\n-        let mut bytes = [0; Self::BYTE_LEN];\n-        bytes.copy_from_slice(&b[..Self::BYTE_LEN]);\n-        Self::from_le_bytes(bytes)\n+    #[inline]\n+    fn from_bytes(b: &[u8; 4]) -> Self {\n+        Self::from_le_bytes(*b)\n     }\n \n-    fn write_to_bytes(self, b: &mut [u8]) {\n-        b[..Self::BYTE_LEN].copy_from_slice(&self.to_le_bytes());\n+    #[inline]\n+    fn write_to_bytes(self, b: &mut [u8; 4]) {\n+        *b = self.to_le_bytes();\n     }\n }\n \n macro_rules! fixed_size_enum {\n     ($ty:ty { $(($($pat:tt)*))* }) => {\n         impl FixedSizeEncoding for Option<$ty> {\n-            fixed_size_encoding_byte_len_and_defaults!(1);\n+            type ByteArray = [u8;1];\n \n             #[inline]\n-            fn from_bytes(b: &[u8]) -> Self {\n+            fn from_bytes(b: &[u8;1]) -> Self {\n                 use $ty::*;\n                 if b[0] == 0 {\n                     return None;\n@@ -97,7 +55,7 @@ macro_rules! fixed_size_enum {\n             }\n \n             #[inline]\n-            fn write_to_bytes(self, b: &mut [u8]) {\n+            fn write_to_bytes(self, b: &mut [u8;1]) {\n                 use $ty::*;\n                 b[0] = match self {\n                     None => 0,\n@@ -184,45 +142,45 @@ fixed_size_enum! {\n \n // We directly encode `DefPathHash` because a `Lazy` would encur a 25% cost.\n impl FixedSizeEncoding for Option<DefPathHash> {\n-    fixed_size_encoding_byte_len_and_defaults!(16);\n+    type ByteArray = [u8; 16];\n \n     #[inline]\n-    fn from_bytes(b: &[u8]) -> Self {\n-        Some(DefPathHash(Fingerprint::from_le_bytes(b.try_into().unwrap())))\n+    fn from_bytes(b: &[u8; 16]) -> Self {\n+        Some(DefPathHash(Fingerprint::from_le_bytes(*b)))\n     }\n \n     #[inline]\n-    fn write_to_bytes(self, b: &mut [u8]) {\n+    fn write_to_bytes(self, b: &mut [u8; 16]) {\n         let Some(DefPathHash(fingerprint)) = self else {\n             panic!(\"Trying to encode absent DefPathHash.\")\n         };\n-        b[..Self::BYTE_LEN].copy_from_slice(&fingerprint.to_le_bytes());\n+        *b = fingerprint.to_le_bytes();\n     }\n }\n \n // We directly encode RawDefId because using a `Lazy` would incur a 50% overhead in the worst case.\n impl FixedSizeEncoding for Option<RawDefId> {\n-    fixed_size_encoding_byte_len_and_defaults!(2 * u32::BYTE_LEN);\n+    type ByteArray = [u8; 8];\n \n     #[inline]\n-    fn from_bytes(b: &[u8]) -> Self {\n-        let krate = u32::from_bytes(&b[0..4]);\n-        let index = u32::from_bytes(&b[4..8]);\n+    fn from_bytes(b: &[u8; 8]) -> Self {\n+        let krate = u32::from_le_bytes(b[0..4].try_into().unwrap());\n+        let index = u32::from_le_bytes(b[4..8].try_into().unwrap());\n         if krate == 0 {\n             return None;\n         }\n         Some(RawDefId { krate: krate - 1, index })\n     }\n \n     #[inline]\n-    fn write_to_bytes(self, b: &mut [u8]) {\n+    fn write_to_bytes(self, b: &mut [u8; 8]) {\n         match self {\n-            None => 0u32.write_to_bytes(b),\n+            None => *b = [0; 8],\n             Some(RawDefId { krate, index }) => {\n                 // CrateNum is less than `CrateNum::MAX_AS_U32`.\n                 debug_assert!(krate < u32::MAX);\n-                (1 + krate).write_to_bytes(&mut b[0..4]);\n-                index.write_to_bytes(&mut b[4..8]);\n+                b[0..4].copy_from_slice(&(1 + krate).to_le_bytes());\n+                b[4..8].copy_from_slice(&index.to_le_bytes());\n             }\n         }\n     }\n@@ -232,44 +190,51 @@ impl FixedSizeEncoding for Option<RawDefId> {\n // generic `Lazy<T>` impl, but in the general case we might not need / want to\n // fit every `usize` in `u32`.\n impl<T> FixedSizeEncoding for Option<Lazy<T>> {\n-    fixed_size_encoding_byte_len_and_defaults!(u32::BYTE_LEN);\n+    type ByteArray = [u8; 4];\n \n-    fn from_bytes(b: &[u8]) -> Self {\n-        Some(Lazy::from_position(NonZeroUsize::new(u32::from_bytes(b) as usize)?))\n+    #[inline]\n+    fn from_bytes(b: &[u8; 4]) -> Self {\n+        let position = NonZeroUsize::new(u32::from_bytes(b) as usize)?;\n+        Some(Lazy::from_position(position))\n     }\n \n-    fn write_to_bytes(self, b: &mut [u8]) {\n+    #[inline]\n+    fn write_to_bytes(self, b: &mut [u8; 4]) {\n         let position = self.map_or(0, |lazy| lazy.position.get());\n         let position: u32 = position.try_into().unwrap();\n-\n         position.write_to_bytes(b)\n     }\n }\n \n impl<T> FixedSizeEncoding for Option<Lazy<[T]>> {\n-    fixed_size_encoding_byte_len_and_defaults!(u32::BYTE_LEN * 2);\n+    type ByteArray = [u8; 8];\n \n-    fn from_bytes(b: &[u8]) -> Self {\n-        Some(Lazy::from_position_and_meta(\n-            <Option<Lazy<T>>>::from_bytes(b)?.position,\n-            u32::from_bytes(&b[u32::BYTE_LEN..]) as usize,\n-        ))\n+    #[inline]\n+    fn from_bytes(b: &[u8; 8]) -> Self {\n+        let ([ref position_bytes, ref meta_bytes],[])= b.as_chunks::<4>() else { panic!() };\n+        let position = NonZeroUsize::new(u32::from_bytes(position_bytes) as usize)?;\n+        let len = u32::from_bytes(meta_bytes) as usize;\n+        Some(Lazy::from_position_and_meta(position, len))\n     }\n \n-    fn write_to_bytes(self, b: &mut [u8]) {\n-        self.map(|lazy| Lazy::<T>::from_position(lazy.position)).write_to_bytes(b);\n+    #[inline]\n+    fn write_to_bytes(self, b: &mut [u8; 8]) {\n+        let ([ref mut position_bytes, ref mut meta_bytes],[])= b.as_chunks_mut::<4>() else { panic!() };\n+\n+        let position = self.map_or(0, |lazy| lazy.position.get());\n+        let position: u32 = position.try_into().unwrap();\n+        position.write_to_bytes(position_bytes);\n \n         let len = self.map_or(0, |lazy| lazy.meta);\n         let len: u32 = len.try_into().unwrap();\n-\n-        len.write_to_bytes(&mut b[u32::BYTE_LEN..]);\n+        len.write_to_bytes(meta_bytes);\n     }\n }\n \n /// Random-access table (i.e. offering constant-time `get`/`set`), similar to\n /// `Vec<Option<T>>`, but without requiring encoding or decoding all the values\n /// eagerly and in-order.\n-/// A total of `(max_idx + 1) * <Option<T> as FixedSizeEncoding>::BYTE_LEN` bytes\n+/// A total of `(max_idx + 1)` times `Option<T> as FixedSizeEncoding>::ByteArray`\n /// are used for a table, where `max_idx` is the largest index passed to\n /// `TableBuilder::set`.\n pub(super) struct Table<I: Idx, T>\n@@ -287,53 +252,54 @@ pub(super) struct TableBuilder<I: Idx, T>\n where\n     Option<T>: FixedSizeEncoding,\n {\n-    // FIXME(eddyb) use `IndexVec<I, [u8; <Option<T>>::BYTE_LEN]>` instead of\n-    // `Vec<u8>`, once that starts working (i.e. lazy normalization).\n-    // Then again, that has the downside of not allowing `TableBuilder::encode` to\n-    // obtain a `&[u8]` entirely in safe code, for writing the bytes out.\n-    bytes: Vec<u8>,\n-    _marker: PhantomData<(fn(&I), T)>,\n+    blocks: IndexVec<I, <Option<T> as FixedSizeEncoding>::ByteArray>,\n+    _marker: PhantomData<T>,\n }\n \n impl<I: Idx, T> Default for TableBuilder<I, T>\n where\n     Option<T>: FixedSizeEncoding,\n {\n     fn default() -> Self {\n-        TableBuilder { bytes: vec![], _marker: PhantomData }\n+        TableBuilder { blocks: Default::default(), _marker: PhantomData }\n     }\n }\n \n impl<I: Idx, T> TableBuilder<I, T>\n where\n     Option<T>: FixedSizeEncoding,\n {\n-    pub(crate) fn set(&mut self, i: I, value: T) {\n+    pub(crate) fn set<const N: usize>(&mut self, i: I, value: T)\n+    where\n+        Option<T>: FixedSizeEncoding<ByteArray = [u8; N]>,\n+    {\n         // FIXME(eddyb) investigate more compact encodings for sparse tables.\n         // On the PR @michaelwoerister mentioned:\n         // > Space requirements could perhaps be optimized by using the HAMT `popcnt`\n         // > trick (i.e. divide things into buckets of 32 or 64 items and then\n         // > store bit-masks of which item in each bucket is actually serialized).\n-        let i = i.index();\n-        let needed = (i + 1) * <Option<T>>::BYTE_LEN;\n-        if self.bytes.len() < needed {\n-            self.bytes.resize(needed, 0);\n-        }\n-\n-        Some(value).write_to_bytes_at(&mut self.bytes, i);\n+        self.blocks.ensure_contains_elem(i, || [0; N]);\n+        Some(value).write_to_bytes(&mut self.blocks[i]);\n     }\n \n-    pub(crate) fn encode(&self, buf: &mut Encoder) -> Lazy<Table<I, T>> {\n+    pub(crate) fn encode<const N: usize>(&self, buf: &mut Encoder) -> Lazy<Table<I, T>>\n+    where\n+        Option<T>: FixedSizeEncoding<ByteArray = [u8; N]>,\n+    {\n         let pos = buf.position();\n-        buf.emit_raw_bytes(&self.bytes).unwrap();\n-        Lazy::from_position_and_meta(NonZeroUsize::new(pos as usize).unwrap(), self.bytes.len())\n+        for block in &self.blocks {\n+            buf.emit_raw_bytes(block).unwrap();\n+        }\n+        let num_bytes = self.blocks.len() * N;\n+        Lazy::from_position_and_meta(NonZeroUsize::new(pos as usize).unwrap(), num_bytes)\n     }\n }\n \n impl<I: Idx, T> LazyMeta for Table<I, T>\n where\n     Option<T>: FixedSizeEncoding,\n {\n+    /// Number of bytes in the data stream.\n     type Meta = usize;\n }\n \n@@ -343,16 +309,28 @@ where\n {\n     /// Given the metadata, extract out the value at a particular index (if any).\n     #[inline(never)]\n-    pub(super) fn get<'a, 'tcx, M: Metadata<'a, 'tcx>>(&self, metadata: M, i: I) -> Option<T> {\n+    pub(super) fn get<'a, 'tcx, M: Metadata<'a, 'tcx>, const N: usize>(\n+        &self,\n+        metadata: M,\n+        i: I,\n+    ) -> Option<T>\n+    where\n+        Option<T>: FixedSizeEncoding<ByteArray = [u8; N]>,\n+    {\n         debug!(\"Table::lookup: index={:?} len={:?}\", i, self.meta);\n \n         let start = self.position.get();\n         let bytes = &metadata.blob()[start..start + self.meta];\n-        <Option<T>>::maybe_read_from_bytes_at(bytes, i.index())?\n+        let (bytes, []) = bytes.as_chunks::<N>() else { panic!() };\n+        let bytes = bytes.get(i.index())?;\n+        FixedSizeEncoding::from_bytes(bytes)\n     }\n \n     /// Size of the table in entries, including possible gaps.\n-    pub(super) fn size(&self) -> usize {\n-        self.meta / <Option<T>>::BYTE_LEN\n+    pub(super) fn size<const N: usize>(&self) -> usize\n+    where\n+        Option<T>: FixedSizeEncoding<ByteArray = [u8; N]>,\n+    {\n+        self.meta / N\n     }\n }"}]}