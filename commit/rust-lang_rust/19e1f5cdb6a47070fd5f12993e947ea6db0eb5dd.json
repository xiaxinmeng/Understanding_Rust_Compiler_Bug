{"sha": "19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE5ZTFmNWNkYjZhNDcwNzBmZDVmMTI5OTNlOTQ3ZWE2ZGIwZWI1ZGQ=", "commit": {"author": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2014-07-14T08:52:18Z"}, "committer": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2014-07-21T17:59:57Z"}, "message": "Lexer; subtly wrong; no makefile", "tree": {"sha": "d8487f1df822558c4a0318356953d43b1e2534bb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d8487f1df822558c4a0318356953d43b1e2534bb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "html_url": "https://github.com/rust-lang/rust/commit/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/comments", "author": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "committer": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e62479133b9b81ae5c32720fa18bd589a9f425e8", "url": "https://api.github.com/repos/rust-lang/rust/commits/e62479133b9b81ae5c32720fa18bd589a9f425e8", "html_url": "https://github.com/rust-lang/rust/commit/e62479133b9b81ae5c32720fa18bd589a9f425e8"}], "stats": {"total": 401, "additions": 401, "deletions": 0}, "files": [{"sha": "69f8ab1e486aaaa5debc26e68fa1a3fde8dd018d", "filename": "src/grammar/README.md", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/src%2Fgrammar%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/src%2Fgrammar%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2FREADME.md?ref=19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "patch": "@@ -0,0 +1,19 @@\n+Reference grammar.\n+\n+Uses [antlr4](http://www.antlr.org/) and a custom Rust tool to compare\n+ASTs/token streams generated.\n+\n+To use:\n+\n+```\n+antlr4 RustLexer.g4\n+javac *.java\n+rustc -O verify.rs\n+for file in ../*/**.rs; do\n+    echo $file;\n+    grun RustLexer tokens -tokens < $file | ./verify $file || break\n+done\n+```\n+\n+Note That the `../*/**.rs` glob will match every `*.rs` file in the above\n+directory and all of its recursive children. This is a zsh extension."}, {"sha": "8a1a39aea0ddf1cf02fe23885fdee3cfad1505ef", "filename": "src/grammar/RustLexer.g4", "status": "added", "additions": 165, "deletions": 0, "changes": 165, "blob_url": "https://github.com/rust-lang/rust/blob/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/src%2Fgrammar%2FRustLexer.g4", "raw_url": "https://github.com/rust-lang/rust/raw/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/src%2Fgrammar%2FRustLexer.g4", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2FRustLexer.g4?ref=19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "patch": "@@ -0,0 +1,165 @@\n+lexer grammar RustLexer;\n+\n+/* Note: due to antlr limitations, we can't represent XID_start and\n+ * XID_continue properly. ASCII-only substitute. */\n+\n+fragment XID_start : [_a-zA-Z] ;\n+fragment XID_continue : [_a-zA-Z0-9] ;\n+\n+/* Expression-operator symbols */\n+\n+EQ      : '=' ;\n+LT      : '<' ;\n+LE      : '<=' ;\n+EQEQ    : '==' ;\n+NE      : '!=' ;\n+GE      : '>=' ;\n+GT      : '>' ;\n+ANDAND  : '&&' ;\n+OROR    : '||' ;\n+NOT     : '!' ;\n+TILDE   : '~' ;\n+PLUS    : '+' ;\n+MINUS   : '-' ;\n+STAR    : '*' ;\n+SLASH   : '/' ;\n+PERCENT : '%' ;\n+CARET   : '^' ;\n+AND     : '&' ;\n+OR      : '|' ;\n+SHL     : '<<' ;\n+SHR     : '>>' ;\n+\n+BINOP\n+    : PLUS\n+    | MINUS\n+    | STAR\n+    | PERCENT\n+    | CARET\n+    | AND\n+    | OR\n+    | SHL\n+    | SHR\n+    ;\n+\n+BINOPEQ : BINOP EQ ;\n+\n+/* \"Structural symbols\" */\n+\n+AT         : '@' ;\n+DOT        : '.' ;\n+DOTDOT     : '..' ;\n+DOTDOTDOT  : '...' ;\n+COMMA      : ',' ;\n+SEMI       : ';' ;\n+COLON      : ':' ;\n+MOD_SEP    : '::' ;\n+RARROW     : '->' ;\n+FAT_ARROW  : '=>' ;\n+LPAREN     : '(' ;\n+RPAREN     : ')' ;\n+LBRACKET   : '[' ;\n+RBRACKET   : ']' ;\n+LBRACE     : '{' ;\n+RBRACE     : '}' ;\n+POUND      : '#';\n+DOLLAR     : '$' ;\n+UNDERSCORE : '_' ;\n+\n+// Literals\n+\n+fragment HEXIT\n+  : [0-9a-fA-F]\n+  ;\n+\n+fragment CHAR_ESCAPE\n+  : [nrt\\\\'\"0]\n+  | [xX] HEXIT HEXIT\n+  | 'u' HEXIT HEXIT HEXIT HEXIT\n+  | 'U' HEXIT HEXIT HEXIT HEXIT HEXIT HEXIT HEXIT HEXIT\n+  ;\n+\n+LIT_CHAR\n+  : '\\'' ( '\\\\' CHAR_ESCAPE | ~[\\\\'\\n\\t\\r] ) '\\''\n+  ;\n+\n+INT_SUFFIX\n+  : 'i'\n+  | 'i8'\n+  | 'i16'\n+  | 'i32'\n+  | 'i64'\n+  | 'u'\n+  | 'u8'\n+  | 'u16'\n+  | 'u32'\n+  | 'u64'\n+  ;\n+\n+LIT_INTEGER\n+  : [0-9][0-9_]* INT_SUFFIX?\n+  | '0b' [01][01_]* INT_SUFFIX?\n+  | '0o' [0-7][0-7_]* INT_SUFFIX?\n+  | '0x' [0-9a-fA-F][0-9a-fA-F_]* INT_SUFFIX?\n+  ;\n+\n+FLOAT_SUFFIX\n+  : 'f32'\n+  | 'f64'\n+  | 'f128'\n+  ;\n+\n+LIT_FLOAT\n+  : [0-9][0-9_]* ('.' | ('.' [0-9][0-9_]*)? ([eE] [-+]? [0-9][0-9_]*)? FLOAT_SUFFIX?)\n+  ;\n+\n+LIT_STR\n+  : '\"' ('\\\\\\n' | '\\\\\\r\\n' | '\\\\' CHAR_ESCAPE | .)*? '\"'\n+  ;\n+\n+LIT_BINARY : 'b' LIT_STR ;\n+LIT_BINARY_RAW : 'b' LIT_STR_RAW ;\n+\n+/* this is a bit messy */\n+\n+fragment LIT_STR_RAW_INNER\n+  : '\"' .*? '\"'\n+  | LIT_STR_RAW_INNER2\n+  ;\n+\n+fragment LIT_STR_RAW_INNER2\n+  : POUND LIT_STR_RAW_INNER POUND\n+  ;\n+\n+LIT_STR_RAW\n+  : 'r' LIT_STR_RAW_INNER\n+  ;\n+\n+IDENT : XID_start XID_continue* ;\n+\n+LIFETIME : '\\'' IDENT ;\n+\n+WHITESPACE : [ \\r\\n\\t]+ ;\n+\n+COMMENT\n+  : '//' ~[\\r\\n]*\n+  | '////' ~[\\r\\n]*\n+  | BLOCK_COMMENT\n+  ;\n+\n+mode DOCCOMMENT;\n+\n+fragment DOC_BLOCK_COMMENT\n+  : ('/**' | '/*!') (DOC_BLOCK_COMMENT | .)*? '*/'\n+  ;\n+\n+DOC_COMMENT\n+  : '///' ~[\\r\\n]*\n+  | '//!' ~[\\r\\n]*\n+  | DOC_BLOCK_COMMENT\n+  ;\n+\n+fragment BLOCK_COMMENT\n+  : '/*' (BLOCK_COMMENT | .)*? '*/'\n+  ;\n+"}, {"sha": "56c78b89ba2e067463ad95ab35f74634a1682f16", "filename": "src/grammar/verify.rs", "status": "added", "additions": 217, "deletions": 0, "changes": 217, "blob_url": "https://github.com/rust-lang/rust/blob/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/src%2Fgrammar%2Fverify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd/src%2Fgrammar%2Fverify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2Fverify.rs?ref=19e1f5cdb6a47070fd5f12993e947ea6db0eb5dd", "patch": "@@ -0,0 +1,217 @@\n+#![feature(globs, phase, macro_rules)]\n+\n+extern crate syntax;\n+extern crate rustc;\n+\n+#[phase(link)]\n+extern crate regex;\n+\n+#[phase(link, plugin)]\n+extern crate log;\n+\n+#[phase(plugin)] extern crate regex_macros;\n+\n+use std::collections::HashMap;\n+use std::io::File;\n+\n+use syntax::parse;\n+use syntax::parse::lexer;\n+use rustc::driver::{session, config};\n+\n+use syntax::ast;\n+use syntax::ast::Name;\n+use syntax::parse::token::*;\n+use syntax::parse::lexer::TokenAndSpan;\n+\n+fn parse_token_list(file: &str) -> HashMap<String, Token> {\n+    fn id() -> Token {\n+        IDENT(ast::Ident { name: Name(0), ctxt: 0, }, false)\n+    }\n+\n+    let mut res = HashMap::new();\n+\n+    res.insert(\"-1\".to_string(), EOF);\n+\n+    for line in file.split('\\n') {\n+        let eq = match line.trim().rfind('=') {\n+            Some(val) => val,\n+            None => continue\n+        };\n+\n+        let val = line.slice_to(eq);\n+        let num = line.slice_from(eq + 1);\n+\n+        let tok = match val {\n+            \"SHR\" => BINOP(SHR),\n+            \"DOLLAR\" => DOLLAR,\n+            \"LT\" => LT,\n+            \"STAR\" => BINOP(STAR),\n+            \"FLOAT_SUFFIX\" => id(),\n+            \"INT_SUFFIX\" => id(),\n+            \"SHL\" => BINOP(SHL),\n+            \"LBRACE\" => LBRACE,\n+            \"RARROW\" => RARROW,\n+            \"LIT_STR\" => LIT_STR(Name(0)),\n+            \"DOTDOT\" => DOTDOT,\n+            \"MOD_SEP\" => MOD_SEP,\n+            \"DOTDOTDOT\" => DOTDOTDOT,\n+            \"NOT\" => NOT,\n+            \"AND\" => BINOP(AND),\n+            \"LPAREN\" => LPAREN,\n+            \"ANDAND\" => ANDAND,\n+            \"AT\" => AT,\n+            \"LBRACKET\" => LBRACKET,\n+            \"LIT_STR_RAW\" => LIT_STR_RAW(Name(0), 0),\n+            \"RPAREN\" => RPAREN,\n+            \"SLASH\" => BINOP(SLASH),\n+            \"COMMA\" => COMMA,\n+            \"LIFETIME\" => LIFETIME(ast::Ident { name: Name(0), ctxt: 0 }),\n+            \"CARET\" => BINOP(CARET),\n+            \"TILDE\" => TILDE,\n+            \"IDENT\" => id(),\n+            \"PLUS\" => BINOP(PLUS),\n+            \"LIT_CHAR\" => LIT_CHAR(Name(0)),\n+            \"EQ\" => EQ,\n+            \"RBRACKET\" => RBRACKET,\n+            \"COMMENT\" => COMMENT,\n+            \"DOC_COMMENT\" => DOC_COMMENT(Name(0)),\n+            \"DOT\" => DOT,\n+            \"EQEQ\" => EQEQ,\n+            \"NE\" => NE,\n+            \"GE\" => GE,\n+            \"PERCENT\" => BINOP(PERCENT),\n+            \"RBRACE\" => RBRACE,\n+            \"BINOP\" => BINOP(PLUS),\n+            \"POUND\" => POUND,\n+            \"OROR\" => OROR,\n+            \"LIT_INTEGER\" => LIT_INTEGER(Name(0)),\n+            \"BINOPEQ\" => BINOPEQ(PLUS),\n+            \"LIT_FLOAT\" => LIT_FLOAT(Name(0)),\n+            \"WHITESPACE\" => WS,\n+            \"UNDERSCORE\" => UNDERSCORE,\n+            \"MINUS\" => BINOP(MINUS),\n+            \"SEMI\" => SEMI,\n+            \"COLON\" => COLON,\n+            \"FAT_ARROW\" => FAT_ARROW,\n+            \"OR\" => BINOP(OR),\n+            \"GT\" => GT,\n+            \"LE\" => LE,\n+            \"LIT_BINARY\" => LIT_BINARY(Name(0)),\n+            \"LIT_BINARY_RAW\" => LIT_BINARY_RAW(Name(0), 0),\n+            _ => continue\n+        };\n+\n+        res.insert(num.to_string(), tok);\n+    }\n+\n+    debug!(\"Token map: {}\", res);\n+    res\n+}\n+\n+fn str_to_binop(mut s: &str) -> BinOp {\n+    if s.ends_with(\"'\") {\n+        s = s.slice_to(s.len() - 1);\n+    }\n+\n+    match s {\n+        \"+\" => PLUS,\n+        \"-\" => MINUS,\n+        \"*\" => STAR,\n+        \"%\" => PERCENT,\n+        \"^\" => CARET,\n+        \"&\" => AND,\n+        \"|\" => OR,\n+        \"<<\" => SHL,\n+        \">>\" => SHR,\n+        _ => fail!(\"Bad binop str {}\", s)\n+    }\n+}\n+\n+fn parse_antlr_token(s: &str, tokens: &HashMap<String, Token>) -> TokenAndSpan {\n+    let re = regex!(r\"\\[@(?P<seq>\\d+),(?P<start>\\d+):(?P<end>\\d+)='(?P<content>.+?),<(?P<toknum>-?\\d+)>,\\d+:\\d+]\");\n+\n+    let m = re.captures(s).expect(format!(\"The regex didn't match {}\", s).as_slice());\n+    let start = m.name(\"start\");\n+    let end = m.name(\"end\");\n+    let toknum = m.name(\"toknum\");\n+    let content = m.name(\"content\");\n+\n+    let proto_tok = tokens.find_equiv(&toknum).expect(format!(\"didn't find token {} in the map\", toknum).as_slice());\n+    let real_tok = match *proto_tok {\n+        BINOP(PLUS) => BINOP(str_to_binop(content)),\n+        BINOPEQ(PLUS) => BINOPEQ(str_to_binop(content.slice_to(content.len() - 2))),\n+        ref t => t.clone()\n+    };\n+\n+    let offset = if real_tok == EOF {\n+        1\n+    } else {\n+        0\n+    };\n+\n+    let sp = syntax::codemap::Span {\n+        lo: syntax::codemap::BytePos(from_str::<u32>(start).unwrap() - offset),\n+        hi: syntax::codemap::BytePos(from_str::<u32>(end).unwrap() + 1),\n+        expn_info: None\n+    };\n+\n+    TokenAndSpan {\n+        tok: real_tok,\n+        sp: sp\n+    }\n+}\n+\n+fn main() {\n+    fn next(r: &mut lexer::StringReader) -> TokenAndSpan {\n+        use syntax::parse::lexer::Reader;\n+        r.next_token()\n+    }\n+\n+    let token_map = parse_token_list(File::open(&Path::new(\"RustLexer.tokens\")).unwrap().read_to_string().unwrap().as_slice());\n+    let mut stdin = std::io::stdin();\n+    let mut antlr_tokens = stdin.lines().map(|l| parse_antlr_token(l.unwrap().as_slice().trim(), &token_map));\n+\n+    let code = File::open(&Path::new(std::os::args().get(1).as_slice())).unwrap().read_to_string().unwrap();\n+    let options = config::basic_options();\n+    let session = session::build_session(options, None);\n+    let filemap = parse::string_to_filemap(&session.parse_sess,\n+                                           code,\n+                                           String::from_str(\"<n/a>\"));\n+    let mut lexer = lexer::StringReader::new(session.diagnostic(), filemap);\n+\n+    for antlr_tok in antlr_tokens {\n+        let rustc_tok = next(&mut lexer);\n+        if rustc_tok.tok == EOF && antlr_tok.tok == EOF {\n+            continue\n+        }\n+\n+        assert!(rustc_tok.sp == antlr_tok.sp, \"{} and {} have different spans\", rustc_tok, antlr_tok);\n+\n+        macro_rules! matches (\n+            ( $($x:pat),+ ) => (\n+                match rustc_tok.tok {\n+                    $($x => match antlr_tok.tok {\n+                        $x => (),\n+                        _ => fail!(\"{} is not {}\", antlr_tok, rustc_tok)\n+                    },)*\n+                    ref c => assert!(c == antlr_tok.tok, \"{} is not {}\", rustc_tok, antlr_tok)\n+                }\n+            )\n+        )\n+\n+        matches!(LIT_BYTE(..),\n+            LIT_CHAR(..),\n+            LIT_INTEGER(..),\n+            LIT_FLOAT(..),\n+            LIT_STR(..),\n+            LIT_STR_RAW(..),\n+            LIT_BINARY(..),\n+            LIT_BINARY_RAW(..),\n+            IDENT(..),\n+            LIFETIME(..),\n+            INTERPOLATED(..),\n+            DOC_COMMENT(..),\n+            SHEBANG(..)\n+        );\n+    }\n+}"}]}