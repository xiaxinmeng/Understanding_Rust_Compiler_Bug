{"sha": "1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "node_id": "C_kwDOAAsO6NoAKDEyMDJiYmFmNDhhMGE5MTlhMmUwY2ZkOGI3ZGNlOTdlOGZjMzAzMGQ", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-30T14:50:05Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-30T14:50:05Z"}, "message": "Auto merge of #99887 - nnethercote:rm-TreeAndSpacing, r=petrochenkov\n\nRemove `TreeAndSpacing`.\n\nA `TokenStream` contains a `Lrc<Vec<(TokenTree, Spacing)>>`. But this is\nnot quite right. `Spacing` makes sense for `TokenTree::Token`, but does\nnot make sense for `TokenTree::Delimited`, because a\n`TokenTree::Delimited` cannot be joined with another `TokenTree`.\n\nThis commit fixes this problem, by adding `Spacing` to `TokenTree::Token`,\nchanging `TokenStream` to contain a `Lrc<Vec<TokenTree>>`, and removing the\n`TreeAndSpacing` typedef.\n\nThe commit removes these two impls:\n- `impl From<TokenTree> for TokenStream`\n- `impl From<TokenTree> for TreeAndSpacing`\n\nThese were useful, but also resulted in code with many `.into()` calls\nthat was hard to read, particularly for anyone not highly familiar with\nthe relevant types. This commit makes some other changes to compensate:\n- `TokenTree::token()` becomes `TokenTree::token_{alone,joint}()`.\n- `TokenStream::token_{alone,joint}()` are added.\n- `TokenStream::delimited` is added.\n\nThis results in things like this:\n```rust\nTokenTree::token(token::Semi, stmt.span).into()\n```\nchanging to this:\n```rust\nTokenStream::token_alone(token::Semi, stmt.span)\n```\nThis makes the type of the result, and its spacing, clearer.\n\nThese changes also simplifies `Cursor` and `CursorRef`, because they no longer\nneed to distinguish between `next` and `next_with_spacing`.\n\nr? `@petrochenkov`", "tree": {"sha": "66db6409f3f134b44bc1475829b0cdd371530a5c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/66db6409f3f134b44bc1475829b0cdd371530a5c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "html_url": "https://github.com/rust-lang/rust/commit/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c907b6f7e0f89c3c4146b585961d2ddcf173584b", "url": "https://api.github.com/repos/rust-lang/rust/commits/c907b6f7e0f89c3c4146b585961d2ddcf173584b", "html_url": "https://github.com/rust-lang/rust/commit/c907b6f7e0f89c3c4146b585961d2ddcf173584b"}, {"sha": "332dffb1f9964cdfcaa91853e4a65ccf6567138f", "url": "https://api.github.com/repos/rust-lang/rust/commits/332dffb1f9964cdfcaa91853e4a65ccf6567138f", "html_url": "https://github.com/rust-lang/rust/commit/332dffb1f9964cdfcaa91853e4a65ccf6567138f"}], "stats": {"total": 624, "additions": 317, "deletions": 307}, "files": [{"sha": "86af7769d1b0baf7d7cb4aed1bbcbe699cf22a0e", "filename": "compiler/rustc_ast/src/attr/mod.rs", "status": "modified", "additions": 36, "deletions": 35, "changes": 71, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -8,7 +8,7 @@ use crate::ast::{Path, PathSegment};\n use crate::ptr::P;\n use crate::token::{self, CommentKind, Delimiter, Token};\n use crate::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n-use crate::tokenstream::{DelimSpan, Spacing, TokenTree, TreeAndSpacing};\n+use crate::tokenstream::{DelimSpan, Spacing, TokenTree};\n use crate::tokenstream::{LazyTokenStream, TokenStream};\n use crate::util::comments;\n \n@@ -388,20 +388,20 @@ pub fn list_contains_name(items: &[NestedMetaItem], name: Symbol) -> bool {\n }\n \n impl MetaItem {\n-    fn token_trees_and_spacings(&self) -> Vec<TreeAndSpacing> {\n+    fn token_trees(&self) -> Vec<TokenTree> {\n         let mut idents = vec![];\n         let mut last_pos = BytePos(0_u32);\n         for (i, segment) in self.path.segments.iter().enumerate() {\n             let is_first = i == 0;\n             if !is_first {\n                 let mod_sep_span =\n                     Span::new(last_pos, segment.ident.span.lo(), segment.ident.span.ctxt(), None);\n-                idents.push(TokenTree::token(token::ModSep, mod_sep_span).into());\n+                idents.push(TokenTree::token_alone(token::ModSep, mod_sep_span));\n             }\n-            idents.push(TokenTree::Token(Token::from_ast_ident(segment.ident)).into());\n+            idents.push(TokenTree::Token(Token::from_ast_ident(segment.ident), Spacing::Alone));\n             last_pos = segment.ident.span.hi();\n         }\n-        idents.extend(self.kind.token_trees_and_spacings(self.span));\n+        idents.extend(self.kind.token_trees(self.span));\n         idents\n     }\n \n@@ -411,12 +411,13 @@ impl MetaItem {\n     {\n         // FIXME: Share code with `parse_path`.\n         let path = match tokens.next().map(TokenTree::uninterpolate) {\n-            Some(TokenTree::Token(Token {\n-                kind: kind @ (token::Ident(..) | token::ModSep),\n-                span,\n-            })) => 'arm: {\n+            Some(TokenTree::Token(\n+                Token { kind: kind @ (token::Ident(..) | token::ModSep), span },\n+                _,\n+            )) => 'arm: {\n                 let mut segments = if let token::Ident(name, _) = kind {\n-                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. })) = tokens.peek()\n+                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. }, _)) =\n+                        tokens.peek()\n                     {\n                         tokens.next();\n                         vec![PathSegment::from_ident(Ident::new(name, span))]\n@@ -427,14 +428,15 @@ impl MetaItem {\n                     vec![PathSegment::path_root(span)]\n                 };\n                 loop {\n-                    if let Some(TokenTree::Token(Token { kind: token::Ident(name, _), span })) =\n+                    if let Some(TokenTree::Token(Token { kind: token::Ident(name, _), span }, _)) =\n                         tokens.next().map(TokenTree::uninterpolate)\n                     {\n                         segments.push(PathSegment::from_ident(Ident::new(name, span)));\n                     } else {\n                         return None;\n                     }\n-                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. })) = tokens.peek()\n+                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. }, _)) =\n+                        tokens.peek()\n                     {\n                         tokens.next();\n                     } else {\n@@ -444,7 +446,7 @@ impl MetaItem {\n                 let span = span.with_hi(segments.last().unwrap().ident.span.hi());\n                 Path { span, segments, tokens: None }\n             }\n-            Some(TokenTree::Token(Token { kind: token::Interpolated(nt), .. })) => match *nt {\n+            Some(TokenTree::Token(Token { kind: token::Interpolated(nt), .. }, _)) => match *nt {\n                 token::Nonterminal::NtMeta(ref item) => return item.meta(item.path.span),\n                 token::Nonterminal::NtPath(ref path) => (**path).clone(),\n                 _ => return None,\n@@ -491,9 +493,9 @@ impl MetaItemKind {\n                 let mut tts = Vec::new();\n                 for (i, item) in list.iter().enumerate() {\n                     if i > 0 {\n-                        tts.push(TokenTree::token(token::Comma, span).into());\n+                        tts.push(TokenTree::token_alone(token::Comma, span));\n                     }\n-                    tts.extend(item.token_trees_and_spacings())\n+                    tts.extend(item.token_trees())\n                 }\n                 MacArgs::Delimited(\n                     DelimSpan::from_single(span),\n@@ -504,31 +506,28 @@ impl MetaItemKind {\n         }\n     }\n \n-    fn token_trees_and_spacings(&self, span: Span) -> Vec<TreeAndSpacing> {\n+    fn token_trees(&self, span: Span) -> Vec<TokenTree> {\n         match *self {\n             MetaItemKind::Word => vec![],\n             MetaItemKind::NameValue(ref lit) => {\n                 vec![\n-                    TokenTree::token(token::Eq, span).into(),\n-                    TokenTree::Token(lit.to_token()).into(),\n+                    TokenTree::token_alone(token::Eq, span),\n+                    TokenTree::Token(lit.to_token(), Spacing::Alone),\n                 ]\n             }\n             MetaItemKind::List(ref list) => {\n                 let mut tokens = Vec::new();\n                 for (i, item) in list.iter().enumerate() {\n                     if i > 0 {\n-                        tokens.push(TokenTree::token(token::Comma, span).into());\n+                        tokens.push(TokenTree::token_alone(token::Comma, span));\n                     }\n-                    tokens.extend(item.token_trees_and_spacings())\n+                    tokens.extend(item.token_trees())\n                 }\n-                vec![\n-                    TokenTree::Delimited(\n-                        DelimSpan::from_single(span),\n-                        Delimiter::Parenthesis,\n-                        TokenStream::new(tokens),\n-                    )\n-                    .into(),\n-                ]\n+                vec![TokenTree::Delimited(\n+                    DelimSpan::from_single(span),\n+                    Delimiter::Parenthesis,\n+                    TokenStream::new(tokens),\n+                )]\n             }\n         }\n     }\n@@ -540,7 +539,7 @@ impl MetaItemKind {\n             let item = NestedMetaItem::from_tokens(&mut tokens)?;\n             result.push(item);\n             match tokens.next() {\n-                None | Some(TokenTree::Token(Token { kind: token::Comma, .. })) => {}\n+                None | Some(TokenTree::Token(Token { kind: token::Comma, .. }, _)) => {}\n                 _ => return None,\n             }\n         }\n@@ -554,7 +553,7 @@ impl MetaItemKind {\n             Some(TokenTree::Delimited(_, Delimiter::Invisible, inner_tokens)) => {\n                 MetaItemKind::name_value_from_tokens(&mut inner_tokens.into_trees())\n             }\n-            Some(TokenTree::Token(token)) => {\n+            Some(TokenTree::Token(token, _)) => {\n                 Lit::from_token(&token).ok().map(MetaItemKind::NameValue)\n             }\n             _ => None,\n@@ -586,7 +585,7 @@ impl MetaItemKind {\n                 MetaItemKind::list_from_tokens(inner_tokens)\n             }\n             Some(TokenTree::Delimited(..)) => None,\n-            Some(TokenTree::Token(Token { kind: token::Eq, .. })) => {\n+            Some(TokenTree::Token(Token { kind: token::Eq, .. }, _)) => {\n                 tokens.next();\n                 MetaItemKind::name_value_from_tokens(tokens)\n             }\n@@ -603,10 +602,12 @@ impl NestedMetaItem {\n         }\n     }\n \n-    fn token_trees_and_spacings(&self) -> Vec<TreeAndSpacing> {\n+    fn token_trees(&self) -> Vec<TokenTree> {\n         match *self {\n-            NestedMetaItem::MetaItem(ref item) => item.token_trees_and_spacings(),\n-            NestedMetaItem::Literal(ref lit) => vec![TokenTree::Token(lit.to_token()).into()],\n+            NestedMetaItem::MetaItem(ref item) => item.token_trees(),\n+            NestedMetaItem::Literal(ref lit) => {\n+                vec![TokenTree::Token(lit.to_token(), Spacing::Alone)]\n+            }\n         }\n     }\n \n@@ -615,7 +616,7 @@ impl NestedMetaItem {\n         I: Iterator<Item = TokenTree>,\n     {\n         match tokens.peek() {\n-            Some(TokenTree::Token(token))\n+            Some(TokenTree::Token(token, _))\n                 if let Ok(lit) = Lit::from_token(token) =>\n             {\n                 tokens.next();"}, {"sha": "01bd498b377800e27e410e977889971ddf5bec94", "filename": "compiler/rustc_ast/src/mut_visit.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -675,7 +675,7 @@ pub fn visit_attr_annotated_tt<T: MutVisitor>(tt: &mut AttrAnnotatedTokenTree, v\n // No `noop_` prefix because there isn't a corresponding method in `MutVisitor`.\n pub fn visit_tt<T: MutVisitor>(tt: &mut TokenTree, vis: &mut T) {\n     match tt {\n-        TokenTree::Token(token) => {\n+        TokenTree::Token(token, _) => {\n             visit_token(token, vis);\n         }\n         TokenTree::Delimited(DelimSpan { open, close }, _delim, tts) => {\n@@ -690,7 +690,7 @@ pub fn visit_tt<T: MutVisitor>(tt: &mut TokenTree, vis: &mut T) {\n pub fn visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &mut T) {\n     if T::VISIT_TOKENS && !tts.is_empty() {\n         let tts = Lrc::make_mut(tts);\n-        visit_vec(tts, |(tree, _is_joint)| visit_tt(tree, vis));\n+        visit_vec(tts, |tree| visit_tt(tree, vis));\n     }\n }\n "}, {"sha": "9e4a22e1fa3cd19551ddeda23c2609dc172f4953", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 74, "deletions": 78, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -42,11 +42,15 @@ use std::{fmt, iter};\n #[derive(Debug, Clone, PartialEq, Encodable, Decodable, HashStable_Generic)]\n pub enum TokenTree {\n     /// A single token.\n-    Token(Token),\n+    Token(Token, Spacing),\n     /// A delimited sequence of token trees.\n     Delimited(DelimSpan, Delimiter, TokenStream),\n }\n \n+// This type is used a lot. Make sure it doesn't unintentionally get bigger.\n+#[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n+rustc_data_structures::static_assert_size!(TokenTree, 32);\n+\n // Ensure all fields of `TokenTree` is `Send` and `Sync`.\n #[cfg(parallel_compiler)]\n fn _dummy()\n@@ -62,7 +66,7 @@ impl TokenTree {\n     /// Checks if this `TokenTree` is equal to the other, regardless of span information.\n     pub fn eq_unspanned(&self, other: &TokenTree) -> bool {\n         match (self, other) {\n-            (TokenTree::Token(token), TokenTree::Token(token2)) => token.kind == token2.kind,\n+            (TokenTree::Token(token, _), TokenTree::Token(token2, _)) => token.kind == token2.kind,\n             (TokenTree::Delimited(_, delim, tts), TokenTree::Delimited(_, delim2, tts2)) => {\n                 delim == delim2 && tts.eq_unspanned(&tts2)\n             }\n@@ -73,26 +77,34 @@ impl TokenTree {\n     /// Retrieves the `TokenTree`'s span.\n     pub fn span(&self) -> Span {\n         match self {\n-            TokenTree::Token(token) => token.span,\n+            TokenTree::Token(token, _) => token.span,\n             TokenTree::Delimited(sp, ..) => sp.entire(),\n         }\n     }\n \n     /// Modify the `TokenTree`'s span in-place.\n     pub fn set_span(&mut self, span: Span) {\n         match self {\n-            TokenTree::Token(token) => token.span = span,\n+            TokenTree::Token(token, _) => token.span = span,\n             TokenTree::Delimited(dspan, ..) => *dspan = DelimSpan::from_single(span),\n         }\n     }\n \n-    pub fn token(kind: TokenKind, span: Span) -> TokenTree {\n-        TokenTree::Token(Token::new(kind, span))\n+    // Create a `TokenTree::Token` with alone spacing.\n+    pub fn token_alone(kind: TokenKind, span: Span) -> TokenTree {\n+        TokenTree::Token(Token::new(kind, span), Spacing::Alone)\n+    }\n+\n+    // Create a `TokenTree::Token` with joint spacing.\n+    pub fn token_joint(kind: TokenKind, span: Span) -> TokenTree {\n+        TokenTree::Token(Token::new(kind, span), Spacing::Joint)\n     }\n \n     pub fn uninterpolate(self) -> TokenTree {\n         match self {\n-            TokenTree::Token(token) => TokenTree::Token(token.uninterpolate().into_owned()),\n+            TokenTree::Token(token, spacing) => {\n+                TokenTree::Token(token.uninterpolate().into_owned(), spacing)\n+            }\n             tt => tt,\n         }\n     }\n@@ -194,13 +206,12 @@ impl AttrAnnotatedTokenStream {\n             .iter()\n             .flat_map(|tree| match &tree.0 {\n                 AttrAnnotatedTokenTree::Token(inner) => {\n-                    smallvec![(TokenTree::Token(inner.clone()), tree.1)].into_iter()\n+                    smallvec![TokenTree::Token(inner.clone(), tree.1)].into_iter()\n+                }\n+                AttrAnnotatedTokenTree::Delimited(span, delim, stream) => {\n+                    smallvec![TokenTree::Delimited(*span, *delim, stream.to_tokenstream()),]\n+                        .into_iter()\n                 }\n-                AttrAnnotatedTokenTree::Delimited(span, delim, stream) => smallvec![(\n-                    TokenTree::Delimited(*span, *delim, stream.to_tokenstream()),\n-                    tree.1,\n-                )]\n-                .into_iter(),\n                 AttrAnnotatedTokenTree::Attributes(data) => {\n                     let mut outer_attrs = Vec::new();\n                     let mut inner_attrs = Vec::new();\n@@ -226,7 +237,7 @@ impl AttrAnnotatedTokenStream {\n                     if !inner_attrs.is_empty() {\n                         let mut found = false;\n                         // Check the last two trees (to account for a trailing semi)\n-                        for (tree, _) in target_tokens.iter_mut().rev().take(2) {\n+                        for tree in target_tokens.iter_mut().rev().take(2) {\n                             if let TokenTree::Delimited(span, delim, delim_tokens) = tree {\n                                 // Inner attributes are only supported on extern blocks, functions, impls,\n                                 // and modules. All of these have their inner attributes placed at\n@@ -299,15 +310,13 @@ pub struct AttributesData {\n /// Today's `TokenTree`s can still contain AST via `token::Interpolated` for\n /// backwards compatibility.\n #[derive(Clone, Debug, Default, Encodable, Decodable)]\n-pub struct TokenStream(pub(crate) Lrc<Vec<TreeAndSpacing>>);\n-\n-pub type TreeAndSpacing = (TokenTree, Spacing);\n+pub struct TokenStream(pub(crate) Lrc<Vec<TokenTree>>);\n \n // `TokenStream` is used a lot. Make sure it doesn't unintentionally get bigger.\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n rustc_data_structures::static_assert_size!(TokenStream, 8);\n \n-#[derive(Clone, Copy, Debug, PartialEq, Encodable, Decodable)]\n+#[derive(Clone, Copy, Debug, PartialEq, Encodable, Decodable, HashStable_Generic)]\n pub enum Spacing {\n     Alone,\n     Joint,\n@@ -323,22 +332,22 @@ impl TokenStream {\n         while let Some((pos, ts)) = iter.next() {\n             if let Some((_, next)) = iter.peek() {\n                 let sp = match (&ts, &next) {\n-                    (_, (TokenTree::Token(Token { kind: token::Comma, .. }), _)) => continue,\n+                    (_, TokenTree::Token(Token { kind: token::Comma, .. }, _)) => continue,\n                     (\n-                        (TokenTree::Token(token_left), Spacing::Alone),\n-                        (TokenTree::Token(token_right), _),\n+                        TokenTree::Token(token_left, Spacing::Alone),\n+                        TokenTree::Token(token_right, _),\n                     ) if ((token_left.is_ident() && !token_left.is_reserved_ident())\n                         || token_left.is_lit())\n                         && ((token_right.is_ident() && !token_right.is_reserved_ident())\n                             || token_right.is_lit()) =>\n                     {\n                         token_left.span\n                     }\n-                    ((TokenTree::Delimited(sp, ..), Spacing::Alone), _) => sp.entire(),\n+                    (TokenTree::Delimited(sp, ..), _) => sp.entire(),\n                     _ => continue,\n                 };\n                 let sp = sp.shrink_to_hi();\n-                let comma = (TokenTree::token(token::Comma, sp), Spacing::Alone);\n+                let comma = TokenTree::token_alone(token::Comma, sp);\n                 suggestion = Some((pos, comma, sp));\n             }\n         }\n@@ -360,21 +369,9 @@ impl From<(AttrAnnotatedTokenTree, Spacing)> for AttrAnnotatedTokenStream {\n     }\n }\n \n-impl From<TokenTree> for TokenStream {\n-    fn from(tree: TokenTree) -> TokenStream {\n-        TokenStream::new(vec![(tree, Spacing::Alone)])\n-    }\n-}\n-\n-impl From<TokenTree> for TreeAndSpacing {\n-    fn from(tree: TokenTree) -> TreeAndSpacing {\n-        (tree, Spacing::Alone)\n-    }\n-}\n-\n impl iter::FromIterator<TokenTree> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = TokenTree>>(iter: I) -> Self {\n-        TokenStream::new(iter.into_iter().map(Into::into).collect::<Vec<TreeAndSpacing>>())\n+        TokenStream::new(iter.into_iter().collect::<Vec<TokenTree>>())\n     }\n }\n \n@@ -387,7 +384,7 @@ impl PartialEq<TokenStream> for TokenStream {\n }\n \n impl TokenStream {\n-    pub fn new(streams: Vec<TreeAndSpacing>) -> TokenStream {\n+    pub fn new(streams: Vec<TokenTree>) -> TokenStream {\n         TokenStream(Lrc::new(streams))\n     }\n \n@@ -420,13 +417,7 @@ impl TokenStream {\n     }\n \n     pub fn map_enumerated<F: FnMut(usize, &TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        TokenStream(Lrc::new(\n-            self.0\n-                .iter()\n-                .enumerate()\n-                .map(|(i, (tree, is_joint))| (f(i, tree), *is_joint))\n-                .collect(),\n-        ))\n+        TokenStream(Lrc::new(self.0.iter().enumerate().map(|(i, tree)| f(i, tree)).collect()))\n     }\n \n     fn opt_from_ast(node: &(impl HasAttrs + HasTokens)) -> Option<TokenStream> {\n@@ -444,6 +435,21 @@ impl TokenStream {\n         Some(attr_annotated.to_tokenstream())\n     }\n \n+    // Create a token stream containing a single token with alone spacing.\n+    pub fn token_alone(kind: TokenKind, span: Span) -> TokenStream {\n+        TokenStream::new(vec![TokenTree::token_alone(kind, span)])\n+    }\n+\n+    // Create a token stream containing a single token with joint spacing.\n+    pub fn token_joint(kind: TokenKind, span: Span) -> TokenStream {\n+        TokenStream::new(vec![TokenTree::token_joint(kind, span)])\n+    }\n+\n+    // Create a token stream containing a single `Delimited`.\n+    pub fn delimited(span: DelimSpan, delim: Delimiter, tts: TokenStream) -> TokenStream {\n+        TokenStream::new(vec![TokenTree::Delimited(span, delim, tts)])\n+    }\n+\n     pub fn from_ast(node: &(impl HasAttrs + HasSpan + HasTokens + fmt::Debug)) -> TokenStream {\n         TokenStream::opt_from_ast(node)\n             .unwrap_or_else(|| panic!(\"missing tokens for node at {:?}: {:?}\", node.span(), node))\n@@ -452,16 +458,16 @@ impl TokenStream {\n     pub fn from_nonterminal_ast(nt: &Nonterminal) -> TokenStream {\n         match nt {\n             Nonterminal::NtIdent(ident, is_raw) => {\n-                TokenTree::token(token::Ident(ident.name, *is_raw), ident.span).into()\n+                TokenStream::token_alone(token::Ident(ident.name, *is_raw), ident.span)\n             }\n             Nonterminal::NtLifetime(ident) => {\n-                TokenTree::token(token::Lifetime(ident.name), ident.span).into()\n+                TokenStream::token_alone(token::Lifetime(ident.name), ident.span)\n             }\n             Nonterminal::NtItem(item) => TokenStream::from_ast(item),\n             Nonterminal::NtBlock(block) => TokenStream::from_ast(block),\n             Nonterminal::NtStmt(stmt) if let StmtKind::Empty = stmt.kind => {\n                 // FIXME: Properly collect tokens for empty statements.\n-                TokenTree::token(token::Semi, stmt.span).into()\n+                TokenStream::token_alone(token::Semi, stmt.span)\n             }\n             Nonterminal::NtStmt(stmt) => TokenStream::from_ast(stmt),\n             Nonterminal::NtPat(pat) => TokenStream::from_ast(pat),\n@@ -473,23 +479,23 @@ impl TokenStream {\n         }\n     }\n \n-    fn flatten_token(token: &Token) -> TokenTree {\n+    fn flatten_token(token: &Token, spacing: Spacing) -> TokenTree {\n         match &token.kind {\n             token::Interpolated(nt) if let token::NtIdent(ident, is_raw) = **nt => {\n-                TokenTree::token(token::Ident(ident.name, is_raw), ident.span)\n+                TokenTree::Token(Token::new(token::Ident(ident.name, is_raw), ident.span), spacing)\n             }\n             token::Interpolated(nt) => TokenTree::Delimited(\n                 DelimSpan::from_single(token.span),\n                 Delimiter::Invisible,\n                 TokenStream::from_nonterminal_ast(&nt).flattened(),\n             ),\n-            _ => TokenTree::Token(token.clone()),\n+            _ => TokenTree::Token(token.clone(), spacing),\n         }\n     }\n \n     fn flatten_token_tree(tree: &TokenTree) -> TokenTree {\n         match tree {\n-            TokenTree::Token(token) => TokenStream::flatten_token(token),\n+            TokenTree::Token(token, spacing) => TokenStream::flatten_token(token, *spacing),\n             TokenTree::Delimited(span, delim, tts) => {\n                 TokenTree::Delimited(*span, *delim, tts.flattened())\n             }\n@@ -500,7 +506,7 @@ impl TokenStream {\n     pub fn flattened(&self) -> TokenStream {\n         fn can_skip(stream: &TokenStream) -> bool {\n             stream.trees().all(|tree| match tree {\n-                TokenTree::Token(token) => !matches!(token.kind, token::Interpolated(_)),\n+                TokenTree::Token(token, _) => !matches!(token.kind, token::Interpolated(_)),\n                 TokenTree::Delimited(_, _, inner) => can_skip(inner),\n             })\n         }\n@@ -522,8 +528,8 @@ impl TokenStreamBuilder {\n         TokenStreamBuilder(SmallVec::new())\n     }\n \n-    pub fn push<T: Into<TokenStream>>(&mut self, stream: T) {\n-        self.0.push(stream.into());\n+    pub fn push(&mut self, stream: TokenStream) {\n+        self.0.push(stream);\n     }\n \n     pub fn build(self) -> TokenStream {\n@@ -564,14 +570,14 @@ impl TokenStreamBuilder {\n                     // `stream` is not empty and the first tree within it is a\n                     // token tree, and (c) the two tokens can be glued\n                     // together...\n-                    if let Some((TokenTree::Token(last_tok), Spacing::Joint)) = res_vec_mut.last()\n-                        && let Some((TokenTree::Token(tok), spacing)) = stream.0.first()\n+                    if let Some(TokenTree::Token(last_tok, Spacing::Joint)) = res_vec_mut.last()\n+                        && let Some(TokenTree::Token(tok, spacing)) = stream.0.first()\n                         && let Some(glued_tok) = last_tok.glue(&tok)\n                     {\n                         // ...then overwrite the last token tree in\n                         // `res_vec_mut` with the glued token, and skip the\n                         // first token tree from `stream`.\n-                        *res_vec_mut.last_mut().unwrap() = (TokenTree::Token(glued_tok), *spacing);\n+                        *res_vec_mut.last_mut().unwrap() = TokenTree::Token(glued_tok, *spacing);\n                         res_vec_mut.extend(stream_iter.skip(1));\n                     } else {\n                         // Append all of `stream`.\n@@ -597,24 +603,19 @@ impl<'t> CursorRef<'t> {\n         CursorRef { stream, index: 0 }\n     }\n \n-    #[inline]\n-    fn next_with_spacing(&mut self) -> Option<&'t TreeAndSpacing> {\n-        self.stream.0.get(self.index).map(|tree| {\n-            self.index += 1;\n-            tree\n-        })\n-    }\n-\n     pub fn look_ahead(&self, n: usize) -> Option<&TokenTree> {\n-        self.stream.0[self.index..].get(n).map(|(tree, _)| tree)\n+        self.stream.0.get(self.index + n)\n     }\n }\n \n impl<'t> Iterator for CursorRef<'t> {\n     type Item = &'t TokenTree;\n \n     fn next(&mut self) -> Option<&'t TokenTree> {\n-        self.next_with_spacing().map(|(tree, _)| tree)\n+        self.stream.0.get(self.index).map(|tree| {\n+            self.index += 1;\n+            tree\n+        })\n     }\n }\n \n@@ -630,7 +631,10 @@ impl Iterator for Cursor {\n     type Item = TokenTree;\n \n     fn next(&mut self) -> Option<TokenTree> {\n-        self.next_with_spacing().map(|(tree, _)| tree)\n+        self.stream.0.get(self.index).map(|tree| {\n+            self.index += 1;\n+            tree.clone()\n+        })\n     }\n }\n \n@@ -640,23 +644,15 @@ impl Cursor {\n     }\n \n     #[inline]\n-    pub fn next_with_spacing(&mut self) -> Option<TreeAndSpacing> {\n-        self.stream.0.get(self.index).map(|tree| {\n-            self.index += 1;\n-            tree.clone()\n-        })\n-    }\n-\n-    #[inline]\n-    pub fn next_with_spacing_ref(&mut self) -> Option<&TreeAndSpacing> {\n+    pub fn next_ref(&mut self) -> Option<&TokenTree> {\n         self.stream.0.get(self.index).map(|tree| {\n             self.index += 1;\n             tree\n         })\n     }\n \n     pub fn look_ahead(&self, n: usize) -> Option<&TokenTree> {\n-        self.stream.0[self.index..].get(n).map(|(tree, _)| tree)\n+        self.stream.0.get(self.index + n)\n     }\n }\n "}, {"sha": "55ddd24c48a83a83972ced7be3ba273f7af6e705", "filename": "compiler/rustc_ast_pretty/src/pprust/state.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast_pretty%2Fsrc%2Fpprust%2Fstate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_ast_pretty%2Fsrc%2Fpprust%2Fstate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_pretty%2Fsrc%2Fpprust%2Fstate.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -145,7 +145,7 @@ pub fn print_crate<'a>(\n /// This makes printed token streams look slightly nicer,\n /// and also addresses some specific regressions described in #63896 and #73345.\n fn tt_prepend_space(tt: &TokenTree, prev: &TokenTree) -> bool {\n-    if let TokenTree::Token(token) = prev {\n+    if let TokenTree::Token(token, _) = prev {\n         if matches!(token.kind, token::Dot | token::Dollar) {\n             return false;\n         }\n@@ -154,12 +154,12 @@ fn tt_prepend_space(tt: &TokenTree, prev: &TokenTree) -> bool {\n         }\n     }\n     match tt {\n-        TokenTree::Token(token) => !matches!(token.kind, token::Comma | token::Not | token::Dot),\n+        TokenTree::Token(token, _) => !matches!(token.kind, token::Comma | token::Not | token::Dot),\n         TokenTree::Delimited(_, Delimiter::Parenthesis, _) => {\n-            !matches!(prev, TokenTree::Token(Token { kind: token::Ident(..), .. }))\n+            !matches!(prev, TokenTree::Token(Token { kind: token::Ident(..), .. }, _))\n         }\n         TokenTree::Delimited(_, Delimiter::Bracket, _) => {\n-            !matches!(prev, TokenTree::Token(Token { kind: token::Pound, .. }))\n+            !matches!(prev, TokenTree::Token(Token { kind: token::Pound, .. }, _))\n         }\n         TokenTree::Delimited(..) => true,\n     }\n@@ -526,7 +526,7 @@ pub trait PrintState<'a>: std::ops::Deref<Target = pp::Printer> + std::ops::Dere\n     /// expression arguments as expressions). It can be done! I think.\n     fn print_tt(&mut self, tt: &TokenTree, convert_dollar_crate: bool) {\n         match tt {\n-            TokenTree::Token(token) => {\n+            TokenTree::Token(token, _) => {\n                 let token_str = self.token_to_string_ext(&token, convert_dollar_crate);\n                 self.word(token_str);\n                 if let token::DocComment(..) = token.kind {"}, {"sha": "dcea883a5a37869fac600c2c027410d38a0043c7", "filename": "compiler/rustc_builtin_macros/src/assert/context.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_builtin_macros%2Fsrc%2Fassert%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_builtin_macros%2Fsrc%2Fassert%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fassert%2Fcontext.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -152,7 +152,7 @@ impl<'cx, 'a> Context<'cx, 'a> {\n     fn build_panic(&self, expr_str: &str, panic_path: Path) -> P<Expr> {\n         let escaped_expr_str = escape_to_fmt(expr_str);\n         let initial = [\n-            TokenTree::token(\n+            TokenTree::token_alone(\n                 token::Literal(token::Lit {\n                     kind: token::LitKind::Str,\n                     symbol: Symbol::intern(&if self.fmt_string.is_empty() {\n@@ -167,12 +167,12 @@ impl<'cx, 'a> Context<'cx, 'a> {\n                 }),\n                 self.span,\n             ),\n-            TokenTree::token(token::Comma, self.span),\n+            TokenTree::token_alone(token::Comma, self.span),\n         ];\n         let captures = self.capture_decls.iter().flat_map(|cap| {\n             [\n-                TokenTree::token(token::Ident(cap.ident.name, false), cap.ident.span),\n-                TokenTree::token(token::Comma, self.span),\n+                TokenTree::token_alone(token::Ident(cap.ident.name, false), cap.ident.span),\n+                TokenTree::token_alone(token::Comma, self.span),\n             ]\n         });\n         self.cx.expr("}, {"sha": "297c604e02043074ad82b498583d9ae1d6c02848", "filename": "compiler/rustc_builtin_macros/src/concat_idents.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_builtin_macros%2Fsrc%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_builtin_macros%2Fsrc%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fconcat_idents.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -20,14 +20,14 @@ pub fn expand_concat_idents<'cx>(\n     for (i, e) in tts.into_trees().enumerate() {\n         if i & 1 == 1 {\n             match e {\n-                TokenTree::Token(Token { kind: token::Comma, .. }) => {}\n+                TokenTree::Token(Token { kind: token::Comma, .. }, _) => {}\n                 _ => {\n                     cx.span_err(sp, \"concat_idents! expecting comma\");\n                     return DummyResult::any(sp);\n                 }\n             }\n         } else {\n-            if let TokenTree::Token(token) = e {\n+            if let TokenTree::Token(token, _) = e {\n                 if let Some((ident, _)) = token.ident() {\n                     res_str.push_str(ident.name.as_str());\n                     continue;"}, {"sha": "cc5ae6894e6fe028a2e0a8e7b99b8370cad7a540", "filename": "compiler/rustc_builtin_macros/src/trace_macros.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_builtin_macros%2Fsrc%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_builtin_macros%2Fsrc%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Ftrace_macros.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -11,8 +11,8 @@ pub fn expand_trace_macros(\n     let mut cursor = tt.into_trees();\n     let mut err = false;\n     let value = match &cursor.next() {\n-        Some(TokenTree::Token(token)) if token.is_keyword(kw::True) => true,\n-        Some(TokenTree::Token(token)) if token.is_keyword(kw::False) => false,\n+        Some(TokenTree::Token(token, _)) if token.is_keyword(kw::True) => true,\n+        Some(TokenTree::Token(token, _)) if token.is_keyword(kw::False) => false,\n         _ => {\n             err = true;\n             false"}, {"sha": "3e1acf4382d5bcd48f7f3ba0664786010ddb15a2", "filename": "compiler/rustc_expand/src/config.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -401,15 +401,15 @@ impl<'a> StripUnconfigured<'a> {\n         // Use the `#` in `#[cfg_attr(pred, attr)]` as the `#` token\n         // for `attr` when we expand it to `#[attr]`\n         let mut orig_trees = orig_tokens.into_trees();\n-        let TokenTree::Token(pound_token @ Token { kind: TokenKind::Pound, .. }) = orig_trees.next().unwrap() else {\n+        let TokenTree::Token(pound_token @ Token { kind: TokenKind::Pound, .. }, _) = orig_trees.next().unwrap() else {\n             panic!(\"Bad tokens for attribute {:?}\", attr);\n         };\n         let pound_span = pound_token.span;\n \n         let mut trees = vec![(AttrAnnotatedTokenTree::Token(pound_token), Spacing::Alone)];\n         if attr.style == AttrStyle::Inner {\n             // For inner attributes, we do the same thing for the `!` in `#![some_attr]`\n-            let TokenTree::Token(bang_token @ Token { kind: TokenKind::Not, .. }) = orig_trees.next().unwrap() else {\n+            let TokenTree::Token(bang_token @ Token { kind: TokenKind::Not, .. }, _) = orig_trees.next().unwrap() else {\n                 panic!(\"Bad tokens for attribute {:?}\", attr);\n             };\n             trees.push((AttrAnnotatedTokenTree::Token(bang_token), Spacing::Alone));"}, {"sha": "f7e1575afbf429b547d9c91084bb5389138df363", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -481,7 +481,7 @@ pub fn compile_declarative_macro(\n             .map(|m| {\n                 if let MatchedTokenTree(ref tt) = *m {\n                     let tt = mbe::quoted::parse(\n-                        tt.clone().into(),\n+                        TokenStream::new(vec![tt.clone()]),\n                         true,\n                         &sess.parse_sess,\n                         def.id,\n@@ -505,7 +505,7 @@ pub fn compile_declarative_macro(\n             .map(|m| {\n                 if let MatchedTokenTree(ref tt) = *m {\n                     return mbe::quoted::parse(\n-                        tt.clone().into(),\n+                        TokenStream::new(vec![tt.clone()]),\n                         false,\n                         &sess.parse_sess,\n                         def.id,"}, {"sha": "fc808401a5eb10d61b70555e738157e932c84681", "filename": "compiler/rustc_expand/src/mbe/metavar_expr.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmetavar_expr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmetavar_expr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmetavar_expr.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -106,7 +106,7 @@ fn parse_depth<'sess>(\n     let Some(tt) = iter.next() else { return Ok(0) };\n     let TokenTree::Token(token::Token {\n         kind: token::TokenKind::Literal(lit), ..\n-    }) = tt else {\n+    }, _) = tt else {\n         return Err(sess.span_diagnostic.struct_span_err(\n             span,\n             \"meta-variable expression depth must be a literal\"\n@@ -130,7 +130,7 @@ fn parse_ident<'sess>(\n     sess: &'sess ParseSess,\n     span: Span,\n ) -> PResult<'sess, Ident> {\n-    if let Some(tt) = iter.next() && let TokenTree::Token(token) = tt {\n+    if let Some(tt) = iter.next() && let TokenTree::Token(token, _) = tt {\n         if let Some((elem, false)) = token.ident() {\n             return Ok(elem);\n         }\n@@ -153,7 +153,7 @@ fn parse_ident<'sess>(\n /// Tries to move the iterator forward returning `true` if there is a comma. If not, then the\n /// iterator is not modified and the result is `false`.\n fn try_eat_comma(iter: &mut CursorRef<'_>) -> bool {\n-    if let Some(TokenTree::Token(token::Token { kind: token::Comma, .. })) = iter.look_ahead(0) {\n+    if let Some(TokenTree::Token(token::Token { kind: token::Comma, .. }, _)) = iter.look_ahead(0) {\n         let _ = iter.next();\n         return true;\n     }"}, {"sha": "ee17d54f629d110df1b43ad70b283d4ceec078f1", "filename": "compiler/rustc_expand/src/mbe/quoted.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -56,9 +56,9 @@ pub(super) fn parse(\n         match tree {\n             TokenTree::MetaVar(start_sp, ident) if parsing_patterns => {\n                 let span = match trees.next() {\n-                    Some(tokenstream::TokenTree::Token(Token { kind: token::Colon, span })) => {\n+                    Some(tokenstream::TokenTree::Token(Token { kind: token::Colon, span }, _)) => {\n                         match trees.next() {\n-                            Some(tokenstream::TokenTree::Token(token)) => match token.ident() {\n+                            Some(tokenstream::TokenTree::Token(token, _)) => match token.ident() {\n                                 Some((frag, _)) => {\n                                     let span = token.span.with_lo(start_sp.lo());\n \n@@ -146,7 +146,7 @@ fn parse_tree(\n     // Depending on what `tree` is, we could be parsing different parts of a macro\n     match tree {\n         // `tree` is a `$` token. Look at the next token in `trees`\n-        tokenstream::TokenTree::Token(Token { kind: token::Dollar, span }) => {\n+        tokenstream::TokenTree::Token(Token { kind: token::Dollar, span }, _) => {\n             // FIXME: Handle `Invisible`-delimited groups in a more systematic way\n             // during parsing.\n             let mut next = outer_trees.next();\n@@ -217,7 +217,7 @@ fn parse_tree(\n \n                 // `tree` is followed by an `ident`. This could be `$meta_var` or the `$crate`\n                 // special metavariable that names the crate of the invocation.\n-                Some(tokenstream::TokenTree::Token(token)) if token.is_ident() => {\n+                Some(tokenstream::TokenTree::Token(token, _)) if token.is_ident() => {\n                     let (ident, is_raw) = token.ident().unwrap();\n                     let span = ident.span.with_lo(span.lo());\n                     if ident.name == kw::Crate && !is_raw {\n@@ -228,7 +228,7 @@ fn parse_tree(\n                 }\n \n                 // `tree` is followed by another `$`. This is an escaped `$`.\n-                Some(tokenstream::TokenTree::Token(Token { kind: token::Dollar, span })) => {\n+                Some(tokenstream::TokenTree::Token(Token { kind: token::Dollar, span }, _)) => {\n                     if parsing_patterns {\n                         span_dollar_dollar_or_metavar_in_the_lhs_err(\n                             sess,\n@@ -241,7 +241,7 @@ fn parse_tree(\n                 }\n \n                 // `tree` is followed by some other token. This is an error.\n-                Some(tokenstream::TokenTree::Token(token)) => {\n+                Some(tokenstream::TokenTree::Token(token, _)) => {\n                     let msg = format!(\n                         \"expected identifier, found `{}`\",\n                         pprust::token_to_string(&token),\n@@ -256,7 +256,7 @@ fn parse_tree(\n         }\n \n         // `tree` is an arbitrary token. Keep it.\n-        tokenstream::TokenTree::Token(token) => TokenTree::Token(token),\n+        tokenstream::TokenTree::Token(token, _) => TokenTree::Token(token),\n \n         // `tree` is the beginning of a delimited set of tokens (e.g., `(` or `{`). We need to\n         // descend into the delimited set and further parse it.\n@@ -291,7 +291,7 @@ fn parse_kleene_op(\n     span: Span,\n ) -> Result<Result<(KleeneOp, Span), Token>, Span> {\n     match input.next() {\n-        Some(tokenstream::TokenTree::Token(token)) => match kleene_op(&token) {\n+        Some(tokenstream::TokenTree::Token(token, _)) => match kleene_op(&token) {\n             Some(op) => Ok(Ok((op, token.span))),\n             None => Ok(Err(token)),\n         },"}, {"sha": "e47ea83ac3809b6f43df08b98dc7540cee8f6d43", "filename": "compiler/rustc_expand/src/mbe/transcribe.rs", "status": "modified", "additions": 25, "deletions": 28, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Ftranscribe.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -3,7 +3,7 @@ use crate::mbe::macro_parser::{MatchedNonterminal, MatchedSeq, MatchedTokenTree,\n use crate::mbe::{self, MetaVarExpr};\n use rustc_ast::mut_visit::{self, MutVisitor};\n use rustc_ast::token::{self, Delimiter, Token, TokenKind};\n-use rustc_ast::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndSpacing};\n+use rustc_ast::tokenstream::{DelimSpan, Spacing, TokenStream, TokenTree};\n use rustc_data_structures::fx::FxHashMap;\n use rustc_errors::{pluralize, PResult};\n use rustc_errors::{DiagnosticBuilder, ErrorGuaranteed};\n@@ -105,7 +105,7 @@ pub(super) fn transcribe<'a>(\n     //\n     // Thus, if we try to pop the `result_stack` and it is empty, we have reached the top-level\n     // again, and we are done transcribing.\n-    let mut result: Vec<TreeAndSpacing> = Vec::new();\n+    let mut result: Vec<TokenTree> = Vec::new();\n     let mut result_stack = Vec::new();\n     let mut marker = Marker(cx.current_expansion.id, transparency);\n \n@@ -123,7 +123,7 @@ pub(super) fn transcribe<'a>(\n                 if repeat_idx < repeat_len {\n                     *idx = 0;\n                     if let Some(sep) = sep {\n-                        result.push(TokenTree::Token(sep.clone()).into());\n+                        result.push(TokenTree::Token(sep.clone(), Spacing::Alone));\n                     }\n                     continue;\n                 }\n@@ -150,7 +150,7 @@ pub(super) fn transcribe<'a>(\n                     // Step back into the parent Delimited.\n                     let tree = TokenTree::Delimited(span, delim, TokenStream::new(result));\n                     result = result_stack.pop().unwrap();\n-                    result.push(tree.into());\n+                    result.push(tree);\n                 }\n             }\n             continue;\n@@ -227,15 +227,15 @@ pub(super) fn transcribe<'a>(\n                             // `tt`s are emitted into the output stream directly as \"raw tokens\",\n                             // without wrapping them into groups.\n                             let token = tt.clone();\n-                            result.push(token.into());\n+                            result.push(token);\n                         }\n                         MatchedNonterminal(ref nt) => {\n                             // Other variables are emitted into the output stream as groups with\n                             // `Delimiter::Invisible` to maintain parsing priorities.\n                             // `Interpolated` is currently used for such groups in rustc parser.\n                             marker.visit_span(&mut sp);\n-                            let token = TokenTree::token(token::Interpolated(nt.clone()), sp);\n-                            result.push(token.into());\n+                            let token = TokenTree::token_alone(token::Interpolated(nt.clone()), sp);\n+                            result.push(token);\n                         }\n                         MatchedSeq(..) => {\n                             // We were unable to descend far enough. This is an error.\n@@ -250,8 +250,11 @@ pub(super) fn transcribe<'a>(\n                     // with modified syntax context. (I believe this supports nested macros).\n                     marker.visit_span(&mut sp);\n                     marker.visit_ident(&mut original_ident);\n-                    result.push(TokenTree::token(token::Dollar, sp).into());\n-                    result.push(TokenTree::Token(Token::from_ast_ident(original_ident)).into());\n+                    result.push(TokenTree::token_alone(token::Dollar, sp));\n+                    result.push(TokenTree::Token(\n+                        Token::from_ast_ident(original_ident),\n+                        Spacing::Alone,\n+                    ));\n                 }\n             }\n \n@@ -281,8 +284,8 @@ pub(super) fn transcribe<'a>(\n             mbe::TokenTree::Token(token) => {\n                 let mut token = token.clone();\n                 mut_visit::visit_token(&mut token, &mut marker);\n-                let tt = TokenTree::Token(token);\n-                result.push(tt.into());\n+                let tt = TokenTree::Token(token, Spacing::Alone);\n+                result.push(tt);\n             }\n \n             // There should be no meta-var declarations in the invocation of a macro.\n@@ -532,7 +535,7 @@ fn transcribe_metavar_expr<'a>(\n     interp: &FxHashMap<MacroRulesNormalizedIdent, NamedMatch>,\n     marker: &mut Marker,\n     repeats: &[(usize, usize)],\n-    result: &mut Vec<TreeAndSpacing>,\n+    result: &mut Vec<TokenTree>,\n     sp: &DelimSpan,\n ) -> PResult<'a, ()> {\n     let mut visited_span = || {\n@@ -544,37 +547,31 @@ fn transcribe_metavar_expr<'a>(\n         MetaVarExpr::Count(original_ident, depth_opt) => {\n             let matched = matched_from_ident(cx, original_ident, interp)?;\n             let count = count_repetitions(cx, depth_opt, matched, &repeats, sp)?;\n-            let tt = TokenTree::token(\n+            let tt = TokenTree::token_alone(\n                 TokenKind::lit(token::Integer, sym::integer(count), None),\n                 visited_span(),\n             );\n-            result.push(tt.into());\n+            result.push(tt);\n         }\n         MetaVarExpr::Ignore(original_ident) => {\n             // Used to ensure that `original_ident` is present in the LHS\n             let _ = matched_from_ident(cx, original_ident, interp)?;\n         }\n         MetaVarExpr::Index(depth) => match repeats.iter().nth_back(depth) {\n             Some((index, _)) => {\n-                result.push(\n-                    TokenTree::token(\n-                        TokenKind::lit(token::Integer, sym::integer(*index), None),\n-                        visited_span(),\n-                    )\n-                    .into(),\n-                );\n+                result.push(TokenTree::token_alone(\n+                    TokenKind::lit(token::Integer, sym::integer(*index), None),\n+                    visited_span(),\n+                ));\n             }\n             None => return Err(out_of_bounds_err(cx, repeats.len(), sp.entire(), \"index\")),\n         },\n         MetaVarExpr::Length(depth) => match repeats.iter().nth_back(depth) {\n             Some((_, length)) => {\n-                result.push(\n-                    TokenTree::token(\n-                        TokenKind::lit(token::Integer, sym::integer(*length), None),\n-                        visited_span(),\n-                    )\n-                    .into(),\n-                );\n+                result.push(TokenTree::token_alone(\n+                    TokenKind::lit(token::Integer, sym::integer(*length), None),\n+                    visited_span(),\n+                ));\n             }\n             None => return Err(out_of_bounds_err(cx, repeats.len(), sp.entire(), \"length\")),\n         },"}, {"sha": "a3c631d3318a08246a2fa2628002889231ba3438", "filename": "compiler/rustc_expand/src/parse/tests.rs", "status": "modified", "additions": 17, "deletions": 19, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fparse%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fparse%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fparse%2Ftests.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -66,32 +66,32 @@ fn string_to_tts_macro() {\n \n         match tts {\n             [\n-                TokenTree::Token(Token { kind: token::Ident(name_macro_rules, false), .. }),\n-                TokenTree::Token(Token { kind: token::Not, .. }),\n-                TokenTree::Token(Token { kind: token::Ident(name_zip, false), .. }),\n+                TokenTree::Token(Token { kind: token::Ident(name_macro_rules, false), .. }, _),\n+                TokenTree::Token(Token { kind: token::Not, .. }, _),\n+                TokenTree::Token(Token { kind: token::Ident(name_zip, false), .. }, _),\n                 TokenTree::Delimited(_, macro_delim, macro_tts),\n             ] if name_macro_rules == &kw::MacroRules && name_zip.as_str() == \"zip\" => {\n                 let tts = &macro_tts.trees().collect::<Vec<_>>();\n                 match &tts[..] {\n                     [\n                         TokenTree::Delimited(_, first_delim, first_tts),\n-                        TokenTree::Token(Token { kind: token::FatArrow, .. }),\n+                        TokenTree::Token(Token { kind: token::FatArrow, .. }, _),\n                         TokenTree::Delimited(_, second_delim, second_tts),\n                     ] if macro_delim == &Delimiter::Parenthesis => {\n                         let tts = &first_tts.trees().collect::<Vec<_>>();\n                         match &tts[..] {\n                             [\n-                                TokenTree::Token(Token { kind: token::Dollar, .. }),\n-                                TokenTree::Token(Token { kind: token::Ident(name, false), .. }),\n+                                TokenTree::Token(Token { kind: token::Dollar, .. }, _),\n+                                TokenTree::Token(Token { kind: token::Ident(name, false), .. }, _),\n                             ] if first_delim == &Delimiter::Parenthesis && name.as_str() == \"a\" => {\n                             }\n                             _ => panic!(\"value 3: {:?} {:?}\", first_delim, first_tts),\n                         }\n                         let tts = &second_tts.trees().collect::<Vec<_>>();\n                         match &tts[..] {\n                             [\n-                                TokenTree::Token(Token { kind: token::Dollar, .. }),\n-                                TokenTree::Token(Token { kind: token::Ident(name, false), .. }),\n+                                TokenTree::Token(Token { kind: token::Dollar, .. }, _),\n+                                TokenTree::Token(Token { kind: token::Ident(name, false), .. }, _),\n                             ] if second_delim == &Delimiter::Parenthesis\n                                 && name.as_str() == \"a\" => {}\n                             _ => panic!(\"value 4: {:?} {:?}\", second_delim, second_tts),\n@@ -111,29 +111,27 @@ fn string_to_tts_1() {\n         let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n \n         let expected = TokenStream::new(vec![\n-            TokenTree::token(token::Ident(kw::Fn, false), sp(0, 2)).into(),\n-            TokenTree::token(token::Ident(Symbol::intern(\"a\"), false), sp(3, 4)).into(),\n+            TokenTree::token_alone(token::Ident(kw::Fn, false), sp(0, 2)),\n+            TokenTree::token_alone(token::Ident(Symbol::intern(\"a\"), false), sp(3, 4)),\n             TokenTree::Delimited(\n                 DelimSpan::from_pair(sp(5, 6), sp(13, 14)),\n                 Delimiter::Parenthesis,\n                 TokenStream::new(vec![\n-                    TokenTree::token(token::Ident(Symbol::intern(\"b\"), false), sp(6, 7)).into(),\n-                    TokenTree::token(token::Colon, sp(8, 9)).into(),\n-                    TokenTree::token(token::Ident(sym::i32, false), sp(10, 13)).into(),\n+                    TokenTree::token_alone(token::Ident(Symbol::intern(\"b\"), false), sp(6, 7)),\n+                    TokenTree::token_alone(token::Colon, sp(8, 9)),\n+                    TokenTree::token_alone(token::Ident(sym::i32, false), sp(10, 13)),\n                 ])\n                 .into(),\n-            )\n-            .into(),\n+            ),\n             TokenTree::Delimited(\n                 DelimSpan::from_pair(sp(15, 16), sp(20, 21)),\n                 Delimiter::Brace,\n                 TokenStream::new(vec![\n-                    TokenTree::token(token::Ident(Symbol::intern(\"b\"), false), sp(17, 18)).into(),\n-                    TokenTree::token(token::Semi, sp(18, 19)).into(),\n+                    TokenTree::token_joint(token::Ident(Symbol::intern(\"b\"), false), sp(17, 18)),\n+                    TokenTree::token_alone(token::Semi, sp(18, 19)),\n                 ])\n                 .into(),\n-            )\n-            .into(),\n+            ),\n         ]);\n \n         assert_eq!(tts, expected);"}, {"sha": "1a2ab9d190ebdcd8c141a3abacf222506f936bbc", "filename": "compiler/rustc_expand/src/proc_macro.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -4,7 +4,7 @@ use crate::proc_macro_server;\n use rustc_ast as ast;\n use rustc_ast::ptr::P;\n use rustc_ast::token;\n-use rustc_ast::tokenstream::{TokenStream, TokenTree};\n+use rustc_ast::tokenstream::TokenStream;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::ErrorGuaranteed;\n use rustc_parse::parser::ForceCollect;\n@@ -123,7 +123,7 @@ impl MultiItemModifier for DeriveProcMacro {\n                 Annotatable::Stmt(stmt) => token::NtStmt(stmt),\n                 _ => unreachable!(),\n             };\n-            TokenTree::token(token::Interpolated(Lrc::new(nt)), DUMMY_SP).into()\n+            TokenStream::token_alone(token::Interpolated(Lrc::new(nt)), DUMMY_SP)\n         } else {\n             item.to_tokens()\n         };"}, {"sha": "7d9a4aed0bf5409f9dc03455dbd71abafe5ce35b", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 24, "deletions": 25, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -92,9 +92,8 @@ impl FromInternal<(TokenStream, &mut Rustc<'_, '_>)> for Vec<TokenTree<TokenStre\n         let mut trees = Vec::with_capacity(stream.len().next_power_of_two());\n         let mut cursor = stream.into_trees();\n \n-        while let Some((tree, spacing)) = cursor.next_with_spacing() {\n-            let joint = spacing == Joint;\n-            let Token { kind, span } = match tree {\n+        while let Some(tree) = cursor.next() {\n+            let (Token { kind, span }, joint) = match tree {\n                 tokenstream::TokenTree::Delimited(span, delim, tts) => {\n                     let delimiter = pm::Delimiter::from_internal(delim);\n                     trees.push(TokenTree::Group(Group {\n@@ -108,7 +107,7 @@ impl FromInternal<(TokenStream, &mut Rustc<'_, '_>)> for Vec<TokenTree<TokenStre\n                     }));\n                     continue;\n                 }\n-                tokenstream::TokenTree::Token(token) => token,\n+                tokenstream::TokenTree::Token(token, spacing) => (token, spacing == Joint),\n             };\n \n             let mut op = |s: &str| {\n@@ -194,7 +193,7 @@ impl FromInternal<(TokenStream, &mut Rustc<'_, '_>)> for Vec<TokenTree<TokenStre\n                         TokenKind::lit(token::Str, Symbol::intern(&escaped), None),\n                     ]\n                     .into_iter()\n-                    .map(|kind| tokenstream::TokenTree::token(kind, span))\n+                    .map(|kind| tokenstream::TokenTree::token_alone(kind, span))\n                     .collect();\n                     trees.push(TokenTree::Punct(Punct { ch: b'#', joint: false, span }));\n                     if attr_style == ast::AttrStyle::Inner {\n@@ -246,16 +245,15 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n         let (ch, joint, span) = match tree {\n             TokenTree::Punct(Punct { ch, joint, span }) => (ch, joint, span),\n             TokenTree::Group(Group { delimiter, stream, span: DelimSpan { open, close, .. } }) => {\n-                return tokenstream::TokenTree::Delimited(\n+                return tokenstream::TokenStream::delimited(\n                     tokenstream::DelimSpan { open, close },\n                     delimiter.to_internal(),\n                     stream.unwrap_or_default(),\n-                )\n-                .into();\n+                );\n             }\n             TokenTree::Ident(self::Ident { sym, is_raw, span }) => {\n                 rustc.sess().symbol_gallery.insert(sym, span);\n-                return tokenstream::TokenTree::token(Ident(sym, is_raw), span).into();\n+                return tokenstream::TokenStream::token_alone(Ident(sym, is_raw), span);\n             }\n             TokenTree::Literal(self::Literal {\n                 kind: self::LitKind::Integer,\n@@ -266,8 +264,8 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                 let minus = BinOp(BinOpToken::Minus);\n                 let symbol = Symbol::intern(&symbol.as_str()[1..]);\n                 let integer = TokenKind::lit(token::Integer, symbol, suffix);\n-                let a = tokenstream::TokenTree::token(minus, span);\n-                let b = tokenstream::TokenTree::token(integer, span);\n+                let a = tokenstream::TokenTree::token_alone(minus, span);\n+                let b = tokenstream::TokenTree::token_alone(integer, span);\n                 return [a, b].into_iter().collect();\n             }\n             TokenTree::Literal(self::Literal {\n@@ -279,16 +277,15 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                 let minus = BinOp(BinOpToken::Minus);\n                 let symbol = Symbol::intern(&symbol.as_str()[1..]);\n                 let float = TokenKind::lit(token::Float, symbol, suffix);\n-                let a = tokenstream::TokenTree::token(minus, span);\n-                let b = tokenstream::TokenTree::token(float, span);\n+                let a = tokenstream::TokenTree::token_alone(minus, span);\n+                let b = tokenstream::TokenTree::token_alone(float, span);\n                 return [a, b].into_iter().collect();\n             }\n             TokenTree::Literal(self::Literal { kind, symbol, suffix, span }) => {\n-                return tokenstream::TokenTree::token(\n+                return tokenstream::TokenStream::token_alone(\n                     TokenKind::lit(kind.to_internal(), symbol, suffix),\n                     span,\n-                )\n-                .into();\n+                );\n             }\n         };\n \n@@ -318,8 +315,11 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n             _ => unreachable!(),\n         };\n \n-        let tree = tokenstream::TokenTree::token(kind, span);\n-        TokenStream::new(vec![(tree, if joint { Joint } else { Alone })])\n+        if joint {\n+            tokenstream::TokenStream::token_joint(kind, span)\n+        } else {\n+            tokenstream::TokenStream::token_alone(kind, span)\n+        }\n     }\n }\n \n@@ -486,21 +486,20 @@ impl server::TokenStream for Rustc<'_, '_> {\n         // We don't use `TokenStream::from_ast` as the tokenstream currently cannot\n         // be recovered in the general case.\n         match &expr.kind {\n-            ast::ExprKind::Lit(l) if l.token.kind == token::Bool => {\n-                Ok(tokenstream::TokenTree::token(token::Ident(l.token.symbol, false), l.span)\n-                    .into())\n-            }\n+            ast::ExprKind::Lit(l) if l.token.kind == token::Bool => Ok(\n+                tokenstream::TokenStream::token_alone(token::Ident(l.token.symbol, false), l.span),\n+            ),\n             ast::ExprKind::Lit(l) => {\n-                Ok(tokenstream::TokenTree::token(token::Literal(l.token), l.span).into())\n+                Ok(tokenstream::TokenStream::token_alone(token::Literal(l.token), l.span))\n             }\n             ast::ExprKind::Unary(ast::UnOp::Neg, e) => match &e.kind {\n                 ast::ExprKind::Lit(l) => match l.token {\n                     token::Lit { kind: token::Integer | token::Float, .. } => {\n                         Ok(Self::TokenStream::from_iter([\n                             // FIXME: The span of the `-` token is lost when\n                             // parsing, so we cannot faithfully recover it here.\n-                            tokenstream::TokenTree::token(token::BinOp(token::Minus), e.span),\n-                            tokenstream::TokenTree::token(token::Literal(l.token), l.span),\n+                            tokenstream::TokenTree::token_alone(token::BinOp(token::Minus), e.span),\n+                            tokenstream::TokenTree::token_alone(token::Literal(l.token), l.span),\n                         ]))\n                     }\n                     _ => Err(()),"}, {"sha": "eed69681011e3dc4a6b86540a9fef8a971a33c06", "filename": "compiler/rustc_expand/src/tokenstream/tests.rs", "status": "modified", "additions": 6, "deletions": 11, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -1,7 +1,7 @@\n use crate::tests::string_to_stream;\n \n use rustc_ast::token;\n-use rustc_ast::tokenstream::{Spacing, TokenStream, TokenStreamBuilder, TokenTree};\n+use rustc_ast::tokenstream::{TokenStream, TokenStreamBuilder};\n use rustc_span::create_default_session_globals_then;\n use rustc_span::{BytePos, Span, Symbol};\n \n@@ -13,10 +13,6 @@ fn sp(a: u32, b: u32) -> Span {\n     Span::with_root_ctxt(BytePos(a), BytePos(b))\n }\n \n-fn joint(tree: TokenTree) -> TokenStream {\n-    TokenStream::new(vec![(tree, Spacing::Joint)])\n-}\n-\n #[test]\n fn test_concat() {\n     create_default_session_globals_then(|| {\n@@ -90,9 +86,8 @@ fn test_diseq_1() {\n #[test]\n fn test_is_empty() {\n     create_default_session_globals_then(|| {\n-        let test0: TokenStream = Vec::<TokenTree>::new().into_iter().collect();\n-        let test1: TokenStream =\n-            TokenTree::token(token::Ident(Symbol::intern(\"a\"), false), sp(0, 1)).into();\n+        let test0 = TokenStream::default();\n+        let test1 = TokenStream::token_alone(token::Ident(Symbol::intern(\"a\"), false), sp(0, 1));\n         let test2 = string_to_ts(\"foo(bar::baz)\");\n \n         assert_eq!(test0.is_empty(), true);\n@@ -105,9 +100,9 @@ fn test_is_empty() {\n fn test_dotdotdot() {\n     create_default_session_globals_then(|| {\n         let mut builder = TokenStreamBuilder::new();\n-        builder.push(joint(TokenTree::token(token::Dot, sp(0, 1))));\n-        builder.push(joint(TokenTree::token(token::Dot, sp(1, 2))));\n-        builder.push(TokenTree::token(token::Dot, sp(2, 3)));\n+        builder.push(TokenStream::token_joint(token::Dot, sp(0, 1)));\n+        builder.push(TokenStream::token_joint(token::Dot, sp(1, 2)));\n+        builder.push(TokenStream::token_alone(token::Dot, sp(2, 3)));\n         let stream = builder.build();\n         assert!(stream.eq_unspanned(&string_to_ts(\"...\")));\n         assert_eq!(stream.trees().count(), 1);"}, {"sha": "ca3e6ce4d60bfb75c12cadd61120f6f061f0ca9e", "filename": "compiler/rustc_lint/src/builtin.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_lint%2Fsrc%2Fbuiltin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_lint%2Fsrc%2Fbuiltin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_lint%2Fsrc%2Fbuiltin.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -1974,7 +1974,7 @@ impl KeywordIdents {\n         for tt in tokens.into_trees() {\n             match tt {\n                 // Only report non-raw idents.\n-                TokenTree::Token(token) => {\n+                TokenTree::Token(token, _) => {\n                     if let Some((ident, false)) = token.ident() {\n                         self.check_ident_token(cx, UnderMacro(true), ident);\n                     }"}, {"sha": "0816bc8deb66f020df5a01b41f8d6ee3de52099c", "filename": "compiler/rustc_parse/src/lexer/tokentrees.rs", "status": "modified", "additions": 12, "deletions": 16, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_parse%2Fsrc%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_parse%2Fsrc%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flexer%2Ftokentrees.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -1,11 +1,7 @@\n use super::{StringReader, UnmatchedBrace};\n \n use rustc_ast::token::{self, Delimiter, Token};\n-use rustc_ast::tokenstream::{\n-    DelimSpan,\n-    Spacing::{self, *},\n-    TokenStream, TokenTree, TreeAndSpacing,\n-};\n+use rustc_ast::tokenstream::{DelimSpan, Spacing, TokenStream, TokenTree};\n use rustc_ast_pretty::pprust::token_to_string;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_errors::PResult;\n@@ -77,7 +73,7 @@ impl<'a> TokenTreesReader<'a> {\n         }\n     }\n \n-    fn parse_token_tree(&mut self) -> PResult<'a, TreeAndSpacing> {\n+    fn parse_token_tree(&mut self) -> PResult<'a, TokenTree> {\n         let sm = self.string_reader.sess.source_map();\n \n         match self.token.kind {\n@@ -223,7 +219,7 @@ impl<'a> TokenTreesReader<'a> {\n                     _ => {}\n                 }\n \n-                Ok(TokenTree::Delimited(delim_span, delim, tts).into())\n+                Ok(TokenTree::Delimited(delim_span, delim, tts))\n             }\n             token::CloseDelim(delim) => {\n                 // An unexpected closing delimiter (i.e., there is no\n@@ -258,12 +254,12 @@ impl<'a> TokenTreesReader<'a> {\n                 Err(err)\n             }\n             _ => {\n-                let tt = TokenTree::Token(self.token.take());\n+                let tok = self.token.take();\n                 let mut spacing = self.bump();\n                 if !self.token.is_op() {\n-                    spacing = Alone;\n+                    spacing = Spacing::Alone;\n                 }\n-                Ok((tt, spacing))\n+                Ok(TokenTree::Token(tok, spacing))\n             }\n         }\n     }\n@@ -277,20 +273,20 @@ impl<'a> TokenTreesReader<'a> {\n \n #[derive(Default)]\n struct TokenStreamBuilder {\n-    buf: Vec<TreeAndSpacing>,\n+    buf: Vec<TokenTree>,\n }\n \n impl TokenStreamBuilder {\n-    fn push(&mut self, (tree, joint): TreeAndSpacing) {\n-        if let Some((TokenTree::Token(prev_token), Joint)) = self.buf.last()\n-            && let TokenTree::Token(token) = &tree\n+    fn push(&mut self, tree: TokenTree) {\n+        if let Some(TokenTree::Token(prev_token, Spacing::Joint)) = self.buf.last()\n+            && let TokenTree::Token(token, joint) = &tree\n             && let Some(glued) = prev_token.glue(token)\n         {\n             self.buf.pop();\n-            self.buf.push((TokenTree::Token(glued), joint));\n+            self.buf.push(TokenTree::Token(glued, *joint));\n             return;\n         }\n-        self.buf.push((tree, joint))\n+        self.buf.push(tree);\n     }\n \n     fn into_token_stream(self) -> TokenStream {"}, {"sha": "2c1e5807aa7f9a7ef656e9e4fcd75a77462ea677", "filename": "compiler/rustc_parse/src/parser/item.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -1664,8 +1664,8 @@ impl<'a> Parser<'a> {\n             let body = self.parse_token_tree(); // `MacBody`\n             // Convert `MacParams MacBody` into `{ MacParams => MacBody }`.\n             let bspan = body.span();\n-            let arrow = TokenTree::token(token::FatArrow, pspan.between(bspan)); // `=>`\n-            let tokens = TokenStream::new(vec![params.into(), arrow.into(), body.into()]);\n+            let arrow = TokenTree::token_alone(token::FatArrow, pspan.between(bspan)); // `=>`\n+            let tokens = TokenStream::new(vec![params, arrow, body]);\n             let dspan = DelimSpan::from_pair(pspan.shrink_to_lo(), bspan.shrink_to_hi());\n             P(MacArgs::Delimited(dspan, MacDelimiter::Brace, tokens))\n         } else {"}, {"sha": "1ac8b224248de1d932ed05977472cf48c25206a7", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 22, "deletions": 18, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -268,13 +268,13 @@ impl TokenCursor {\n             // FIXME: we currently don't return `Delimiter` open/close delims. To fix #67062 we will\n             // need to, whereupon the `delim != Delimiter::Invisible` conditions below can be\n             // removed.\n-            if let Some((tree, spacing)) = self.frame.tree_cursor.next_with_spacing_ref() {\n+            if let Some(tree) = self.frame.tree_cursor.next_ref() {\n                 match tree {\n-                    &TokenTree::Token(ref token) => match (desugar_doc_comments, token) {\n+                    &TokenTree::Token(ref token, spacing) => match (desugar_doc_comments, token) {\n                         (true, &Token { kind: token::DocComment(_, attr_style, data), span }) => {\n                             return self.desugar(attr_style, data, span);\n                         }\n-                        _ => return (token.clone(), *spacing),\n+                        _ => return (token.clone(), spacing),\n                     },\n                     &TokenTree::Delimited(sp, delim, ref tts) => {\n                         // Set `open_delim` to true here because we deal with it immediately.\n@@ -318,12 +318,14 @@ impl TokenCursor {\n             delim_span,\n             Delimiter::Bracket,\n             [\n-                TokenTree::token(token::Ident(sym::doc, false), span),\n-                TokenTree::token(token::Eq, span),\n-                TokenTree::token(TokenKind::lit(token::StrRaw(num_of_hashes), data, None), span),\n+                TokenTree::token_alone(token::Ident(sym::doc, false), span),\n+                TokenTree::token_alone(token::Eq, span),\n+                TokenTree::token_alone(\n+                    TokenKind::lit(token::StrRaw(num_of_hashes), data, None),\n+                    span,\n+                ),\n             ]\n-            .iter()\n-            .cloned()\n+            .into_iter()\n             .collect::<TokenStream>(),\n         );\n \n@@ -332,14 +334,16 @@ impl TokenCursor {\n             TokenCursorFrame::new(\n                 None,\n                 if attr_style == AttrStyle::Inner {\n-                    [TokenTree::token(token::Pound, span), TokenTree::token(token::Not, span), body]\n-                        .iter()\n-                        .cloned()\n-                        .collect::<TokenStream>()\n+                    [\n+                        TokenTree::token_alone(token::Pound, span),\n+                        TokenTree::token_alone(token::Not, span),\n+                        body,\n+                    ]\n+                    .into_iter()\n+                    .collect::<TokenStream>()\n                 } else {\n-                    [TokenTree::token(token::Pound, span), body]\n-                        .iter()\n-                        .cloned()\n+                    [TokenTree::token_alone(token::Pound, span), body]\n+                        .into_iter()\n                         .collect::<TokenStream>()\n                 },\n             ),\n@@ -1042,7 +1046,7 @@ impl<'a> Parser<'a> {\n             if all_normal {\n                 return match frame.tree_cursor.look_ahead(dist - 1) {\n                     Some(tree) => match tree {\n-                        TokenTree::Token(token) => looker(token),\n+                        TokenTree::Token(token, _) => looker(token),\n                         TokenTree::Delimited(dspan, delim, _) => {\n                             looker(&Token::new(token::OpenDelim(*delim), dspan.open))\n                         }\n@@ -1226,7 +1230,7 @@ impl<'a> Parser<'a> {\n             token::CloseDelim(_) | token::Eof => unreachable!(),\n             _ => {\n                 self.bump();\n-                TokenTree::Token(self.prev_token.clone())\n+                TokenTree::Token(self.prev_token.clone(), Spacing::Alone)\n             }\n         }\n     }\n@@ -1245,7 +1249,7 @@ impl<'a> Parser<'a> {\n         loop {\n             match self.token.kind {\n                 token::Eof | token::CloseDelim(..) => break,\n-                _ => result.push(self.parse_token_tree().into()),\n+                _ => result.push(self.parse_token_tree()),\n             }\n         }\n         TokenStream::new(result)"}, {"sha": "ed7683e36fd30f4e841707902b94785a81a80cc3", "filename": "src/librustdoc/clean/render_macro_matchers.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/src%2Flibrustdoc%2Fclean%2Frender_macro_matchers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/src%2Flibrustdoc%2Fclean%2Frender_macro_matchers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Frender_macro_matchers.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -43,7 +43,7 @@ pub(super) fn render_macro_matcher(tcx: TyCtxt<'_>, matcher: &TokenTree) -> Stri\n         TokenTree::Delimited(_span, _delim, tts) => print_tts(&mut printer, tts),\n         // Matcher which is not a Delimited is unexpected and should've failed\n         // to compile, but we render whatever it is wrapped in parens.\n-        TokenTree::Token(_) => print_tt(&mut printer, matcher),\n+        TokenTree::Token(..) => print_tt(&mut printer, matcher),\n     }\n     printer.end();\n     printer.break_offset_if_not_bol(0, -4);\n@@ -93,7 +93,7 @@ fn snippet_equal_to_token(tcx: TyCtxt<'_>, matcher: &TokenTree) -> Option<String\n \n fn print_tt(printer: &mut Printer<'_>, tt: &TokenTree) {\n     match tt {\n-        TokenTree::Token(token) => {\n+        TokenTree::Token(token, _) => {\n             let token_str = printer.token_to_string(token);\n             printer.word(token_str);\n             if let token::DocComment(..) = token.kind {\n@@ -138,7 +138,7 @@ fn print_tts(printer: &mut Printer<'_>, tts: &TokenStream) {\n     let mut state = Start;\n     for tt in tts.trees() {\n         let (needs_space, next_state) = match &tt {\n-            TokenTree::Token(tt) => match (state, &tt.kind) {\n+            TokenTree::Token(tt, _) => match (state, &tt.kind) {\n                 (Dollar, token::Ident(..)) => (false, DollarIdent),\n                 (DollarIdent, token::Colon) => (false, DollarIdentColon),\n                 (DollarIdentColon, token::Ident(..)) => (false, Other),"}, {"sha": "454ec23388af94511525b335d1e672dc8f6e062a", "filename": "src/tools/clippy/clippy_lints/src/crate_in_macro_def.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/src%2Ftools%2Fclippy%2Fclippy_lints%2Fsrc%2Fcrate_in_macro_def.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/src%2Ftools%2Fclippy%2Fclippy_lints%2Fsrc%2Fcrate_in_macro_def.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fclippy%2Fclippy_lints%2Fsrc%2Fcrate_in_macro_def.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -110,14 +110,14 @@ fn contains_unhygienic_crate_reference(tts: &TokenStream) -> Option<Span> {\n \n fn is_crate_keyword(tt: &TokenTree) -> Option<Span> {\n     if_chain! {\n-        if let TokenTree::Token(Token { kind: TokenKind::Ident(symbol, _), span }) = tt;\n+        if let TokenTree::Token(Token { kind: TokenKind::Ident(symbol, _), span }, _) = tt;\n         if symbol.as_str() == \"crate\";\n         then { Some(*span) } else { None }\n     }\n }\n \n fn is_token(tt: &TokenTree, kind: &TokenKind) -> bool {\n-    if let TokenTree::Token(Token { kind: other, .. }) = tt {\n+    if let TokenTree::Token(Token { kind: other, .. }, _) = tt {\n         kind == other\n     } else {\n         false"}, {"sha": "3a641fab5d647258f8e3780a7ee32328a09d65a6", "filename": "src/tools/rustfmt/src/macros.rs", "status": "modified", "additions": 61, "deletions": 37, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/src%2Ftools%2Frustfmt%2Fsrc%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d/src%2Ftools%2Frustfmt%2Fsrc%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Frustfmt%2Fsrc%2Fmacros.rs?ref=1202bbaf48a0a919a2e0cfd8b7dce97e8fc3030d", "patch": "@@ -13,7 +13,7 @@ use std::collections::HashMap;\n use std::panic::{catch_unwind, AssertUnwindSafe};\n \n use rustc_ast::token::{BinOpToken, Delimiter, Token, TokenKind};\n-use rustc_ast::tokenstream::{Cursor, Spacing, TokenStream, TokenTree};\n+use rustc_ast::tokenstream::{Cursor, TokenStream, TokenTree};\n use rustc_ast::{ast, ptr};\n use rustc_ast_pretty::pprust;\n use rustc_span::{\n@@ -682,7 +682,7 @@ struct MacroArgParser {\n \n fn last_tok(tt: &TokenTree) -> Token {\n     match *tt {\n-        TokenTree::Token(ref t) => t.clone(),\n+        TokenTree::Token(ref t, _) => t.clone(),\n         TokenTree::Delimited(delim_span, delim, _) => Token {\n             kind: TokenKind::CloseDelim(delim),\n             span: delim_span.close,\n@@ -737,10 +737,13 @@ impl MacroArgParser {\n \n     fn add_meta_variable(&mut self, iter: &mut Cursor) -> Option<()> {\n         match iter.next() {\n-            Some(TokenTree::Token(Token {\n-                kind: TokenKind::Ident(name, _),\n-                ..\n-            })) => {\n+            Some(TokenTree::Token(\n+                Token {\n+                    kind: TokenKind::Ident(name, _),\n+                    ..\n+                },\n+                _,\n+            )) => {\n                 self.result.push(ParsedMacroArg {\n                     kind: MacroArgKind::MetaVariable(name, self.buf.clone()),\n                 });\n@@ -777,21 +780,30 @@ impl MacroArgParser {\n             }\n \n             match tok {\n-                TokenTree::Token(Token {\n-                    kind: TokenKind::BinOp(BinOpToken::Plus),\n-                    ..\n-                })\n-                | TokenTree::Token(Token {\n-                    kind: TokenKind::Question,\n-                    ..\n-                })\n-                | TokenTree::Token(Token {\n-                    kind: TokenKind::BinOp(BinOpToken::Star),\n-                    ..\n-                }) => {\n+                TokenTree::Token(\n+                    Token {\n+                        kind: TokenKind::BinOp(BinOpToken::Plus),\n+                        ..\n+                    },\n+                    _,\n+                )\n+                | TokenTree::Token(\n+                    Token {\n+                        kind: TokenKind::Question,\n+                        ..\n+                    },\n+                    _,\n+                )\n+                | TokenTree::Token(\n+                    Token {\n+                        kind: TokenKind::BinOp(BinOpToken::Star),\n+                        ..\n+                    },\n+                    _,\n+                ) => {\n                     break;\n                 }\n-                TokenTree::Token(ref t) => {\n+                TokenTree::Token(ref t, _) => {\n                     buffer.push_str(&pprust::token_to_string(t));\n                 }\n                 _ => return None,\n@@ -859,10 +871,13 @@ impl MacroArgParser {\n \n         while let Some(tok) = iter.next() {\n             match tok {\n-                TokenTree::Token(Token {\n-                    kind: TokenKind::Dollar,\n-                    span,\n-                }) => {\n+                TokenTree::Token(\n+                    Token {\n+                        kind: TokenKind::Dollar,\n+                        span,\n+                    },\n+                    _,\n+                ) => {\n                     // We always want to add a separator before meta variables.\n                     if !self.buf.is_empty() {\n                         self.add_separator();\n@@ -875,13 +890,16 @@ impl MacroArgParser {\n                         span,\n                     };\n                 }\n-                TokenTree::Token(Token {\n-                    kind: TokenKind::Colon,\n-                    ..\n-                }) if self.is_meta_var => {\n+                TokenTree::Token(\n+                    Token {\n+                        kind: TokenKind::Colon,\n+                        ..\n+                    },\n+                    _,\n+                ) if self.is_meta_var => {\n                     self.add_meta_variable(&mut iter)?;\n                 }\n-                TokenTree::Token(ref t) => self.update_buffer(t),\n+                TokenTree::Token(ref t, _) => self.update_buffer(t),\n                 TokenTree::Delimited(_delimited_span, delimited, ref tts) => {\n                     if !self.buf.is_empty() {\n                         if next_space(&self.last_tok.kind) == SpaceState::Always {\n@@ -1123,12 +1141,15 @@ impl MacroParser {\n             TokenTree::Token(..) => return None,\n             TokenTree::Delimited(delimited_span, d, _) => (delimited_span.open.lo(), d),\n         };\n-        let args = TokenStream::new(vec![(tok, Spacing::Joint)]);\n+        let args = TokenStream::new(vec![tok]);\n         match self.toks.next()? {\n-            TokenTree::Token(Token {\n-                kind: TokenKind::FatArrow,\n-                ..\n-            }) => {}\n+            TokenTree::Token(\n+                Token {\n+                    kind: TokenKind::FatArrow,\n+                    ..\n+                },\n+                _,\n+            ) => {}\n             _ => return None,\n         }\n         let (mut hi, body, whole_body) = match self.toks.next()? {\n@@ -1147,10 +1168,13 @@ impl MacroParser {\n                 )\n             }\n         };\n-        if let Some(TokenTree::Token(Token {\n-            kind: TokenKind::Semi,\n-            span,\n-        })) = self.toks.look_ahead(0)\n+        if let Some(TokenTree::Token(\n+            Token {\n+                kind: TokenKind::Semi,\n+                span,\n+            },\n+            _,\n+        )) = self.toks.look_ahead(0)\n         {\n             hi = span.hi();\n             self.toks.next();"}]}