{"sha": "3f064cae3d9d0d33951a44c30d83696563244572", "node_id": "MDY6Q29tbWl0NzI0NzEyOjNmMDY0Y2FlM2Q5ZDBkMzM5NTFhNDRjMzBkODM2OTY1NjMyNDQ1NzI=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-10T23:31:34Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-11T13:03:16Z"}, "message": "Move literal parsing code into a separate file\n\nRemove some dead code", "tree": {"sha": "c72777f2d563c1b75235b76bdd4663744e67f218", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c72777f2d563c1b75235b76bdd4663744e67f218"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3f064cae3d9d0d33951a44c30d83696563244572", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3f064cae3d9d0d33951a44c30d83696563244572", "html_url": "https://github.com/rust-lang/rust/commit/3f064cae3d9d0d33951a44c30d83696563244572", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3f064cae3d9d0d33951a44c30d83696563244572/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8739668438a40712a0bc617bc587d415c8cb42f0", "url": "https://api.github.com/repos/rust-lang/rust/commits/8739668438a40712a0bc617bc587d415c8cb42f0", "html_url": "https://github.com/rust-lang/rust/commit/8739668438a40712a0bc617bc587d415c8cb42f0"}], "stats": {"total": 1058, "additions": 521, "deletions": 537}, "files": [{"sha": "07e4bbf78ffdf4666dbd171e10665c2768c4c011", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 0, "deletions": 99, "changes": 99, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -27,11 +27,9 @@ use crate::ThinVec;\n use crate::tokenstream::{TokenStream, TokenTree, DelimSpan};\n use crate::GLOBALS;\n \n-use errors::Handler;\n use log::debug;\n use syntax_pos::{FileName, Span};\n \n-use std::ascii;\n use std::iter;\n use std::ops::DerefMut;\n \n@@ -620,103 +618,6 @@ impl NestedMetaItem {\n     }\n }\n \n-impl Lit {\n-    crate fn tokens(&self) -> TokenStream {\n-        let token = match self.token {\n-            token::Bool(symbol) => Token::Ident(Ident::with_empty_ctxt(symbol), false),\n-            token => Token::Literal(token, self.suffix),\n-        };\n-        TokenTree::Token(self.span, token).into()\n-    }\n-}\n-\n-impl LitKind {\n-    /// Attempts to recover a token from semantic literal.\n-    /// This function is used when the original token doesn't exist (e.g. the literal is created\n-    /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n-    pub fn to_lit_token(&self) -> (token::Lit, Option<Symbol>) {\n-        match *self {\n-            LitKind::Str(string, ast::StrStyle::Cooked) => {\n-                let escaped = string.as_str().escape_default().to_string();\n-                (token::Lit::Str_(Symbol::intern(&escaped)), None)\n-            }\n-            LitKind::Str(string, ast::StrStyle::Raw(n)) => {\n-                (token::Lit::StrRaw(string, n), None)\n-            }\n-            LitKind::ByteStr(ref bytes) => {\n-                let string = bytes.iter().cloned().flat_map(ascii::escape_default)\n-                    .map(Into::<char>::into).collect::<String>();\n-                (token::Lit::ByteStr(Symbol::intern(&string)), None)\n-            }\n-            LitKind::Byte(byte) => {\n-                let string: String = ascii::escape_default(byte).map(Into::<char>::into).collect();\n-                (token::Lit::Byte(Symbol::intern(&string)), None)\n-            }\n-            LitKind::Char(ch) => {\n-                let string: String = ch.escape_default().map(Into::<char>::into).collect();\n-                (token::Lit::Char(Symbol::intern(&string)), None)\n-            }\n-            LitKind::Int(n, ty) => {\n-                let suffix = match ty {\n-                    ast::LitIntType::Unsigned(ty) => Some(Symbol::intern(ty.ty_to_string())),\n-                    ast::LitIntType::Signed(ty) => Some(Symbol::intern(ty.ty_to_string())),\n-                    ast::LitIntType::Unsuffixed => None,\n-                };\n-                (token::Lit::Integer(Symbol::intern(&n.to_string())), suffix)\n-            }\n-            LitKind::Float(symbol, ty) => {\n-                (token::Lit::Float(symbol), Some(Symbol::intern(ty.ty_to_string())))\n-            }\n-            LitKind::FloatUnsuffixed(symbol) => (token::Lit::Float(symbol), None),\n-            LitKind::Bool(value) => {\n-                let kw = if value { keywords::True } else { keywords::False };\n-                (token::Lit::Bool(kw.name()), None)\n-            }\n-            LitKind::Err(val) => (token::Lit::Err(val), None),\n-        }\n-    }\n-}\n-\n-impl Lit {\n-    /// Converts literal token with a suffix into an AST literal.\n-    /// Works speculatively and may return `None` is diagnostic handler is not passed.\n-    /// If diagnostic handler is passed, may return `Some`,\n-    /// possibly after reporting non-fatal errors and recovery, or `None` for irrecoverable errors.\n-    crate fn from_token(\n-        token: &token::Token,\n-        span: Span,\n-        diag: Option<(Span, &Handler)>,\n-    ) -> Option<Lit> {\n-        let (token, suffix) = match *token {\n-            token::Ident(ident, false) if ident.name == keywords::True.name() ||\n-                                          ident.name == keywords::False.name() =>\n-                (token::Bool(ident.name), None),\n-            token::Literal(token, suffix) =>\n-                (token, suffix),\n-            token::Interpolated(ref nt) => {\n-                if let token::NtExpr(expr) | token::NtLiteral(expr) = &**nt {\n-                    if let ast::ExprKind::Lit(lit) = &expr.node {\n-                        return Some(lit.clone());\n-                    }\n-                }\n-                return None;\n-            }\n-            _ => return None,\n-        };\n-\n-        let node = LitKind::from_lit_token(token, suffix, diag)?;\n-        Some(Lit { node, token, suffix, span })\n-    }\n-\n-    /// Attempts to recover an AST literal from semantic literal.\n-    /// This function is used when the original token doesn't exist (e.g. the literal is created\n-    /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n-    pub fn from_lit_kind(node: LitKind, span: Span) -> Lit {\n-        let (token, suffix) = node.to_lit_token();\n-        Lit { node, token, suffix, span }\n-    }\n-}\n-\n pub trait HasAttrs: Sized {\n     fn attrs(&self) -> &[ast::Attribute];\n     fn visit_attrs<F: FnOnce(&mut Vec<ast::Attribute>)>(&mut self, f: F);"}, {"sha": "dfd6f451c28d7779a3f2c50af7f3a8b772aa1a20", "filename": "src/libsyntax/parse/classify.rs", "status": "modified", "additions": 0, "deletions": 13, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fclassify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fclassify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fclassify.rs?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -25,16 +25,3 @@ pub fn expr_requires_semi_to_be_stmt(e: &ast::Expr) -> bool {\n         _ => true,\n     }\n }\n-\n-/// this statement requires a semicolon after it.\n-/// note that in one case (`stmt_semi`), we've already\n-/// seen the semicolon, and thus don't need another.\n-pub fn stmt_ends_with_semi(stmt: &ast::StmtKind) -> bool {\n-    match *stmt {\n-        ast::StmtKind::Local(_) => true,\n-        ast::StmtKind::Expr(ref e) => expr_requires_semi_to_be_stmt(e),\n-        ast::StmtKind::Item(_) |\n-        ast::StmtKind::Semi(..) |\n-        ast::StmtKind::Mac(..) => false,\n-    }\n-}"}, {"sha": "e76605cde32ab4376e5f4e5f50b127d07d8b877c", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -262,18 +262,6 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    pub fn new(sess: &'a ParseSess,\n-               source_file: Lrc<syntax_pos::SourceFile>,\n-               override_span: Option<Span>) -> Self {\n-        let mut sr = StringReader::new_raw(sess, source_file, override_span);\n-        if sr.advance_token().is_err() {\n-            sr.emit_fatal_errors();\n-            FatalError.raise();\n-        }\n-\n-        sr\n-    }\n-\n     pub fn new_or_buffered_errs(sess: &'a ParseSess,\n                                 source_file: Lrc<syntax_pos::SourceFile>,\n                                 override_span: Option<Span>) -> Result<Self, Vec<Diagnostic>> {\n@@ -1627,7 +1615,12 @@ mod tests {\n                  teststr: String)\n                  -> StringReader<'a> {\n         let sf = sm.new_source_file(PathBuf::from(teststr.clone()).into(), teststr);\n-        StringReader::new(sess, sf, None)\n+        let mut sr = StringReader::new_raw(sess, sf, None);\n+        if sr.advance_token().is_err() {\n+            sr.emit_fatal_errors();\n+            FatalError.raise();\n+        }\n+        sr\n     }\n \n     #[test]"}, {"sha": "2c7ba13fbef82d64f2d49931b5e52408f726bb84", "filename": "src/libsyntax/parse/literal.rs", "status": "added", "additions": 487, "deletions": 0, "changes": 487, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -0,0 +1,487 @@\n+//! Code related to parsing literals.\n+\n+use crate::ast::{self, Ident, Lit, LitKind};\n+use crate::parse::parser::Parser;\n+use crate::parse::PResult;\n+use crate::parse::token::{self, Token};\n+use crate::parse::unescape::{unescape_str, unescape_char, unescape_byte_str, unescape_byte};\n+use crate::print::pprust;\n+use crate::symbol::{keywords, Symbol};\n+use crate::tokenstream::{TokenStream, TokenTree};\n+\n+use errors::{Applicability, Handler};\n+use log::debug;\n+use rustc_data_structures::sync::Lrc;\n+use syntax_pos::Span;\n+\n+use std::ascii;\n+\n+macro_rules! err {\n+    ($opt_diag:expr, |$span:ident, $diag:ident| $($body:tt)*) => {\n+        match $opt_diag {\n+            Some(($span, $diag)) => { $($body)* }\n+            None => return None,\n+        }\n+    }\n+}\n+\n+impl LitKind {\n+    /// Converts literal token with a suffix into a semantic literal.\n+    /// Works speculatively and may return `None` is diagnostic handler is not passed.\n+    /// If diagnostic handler is passed, always returns `Some`,\n+    /// possibly after reporting non-fatal errors and recovery.\n+    fn from_lit_token(\n+        lit: token::Lit,\n+        suf: Option<Symbol>,\n+        diag: Option<(Span, &Handler)>\n+    ) -> Option<LitKind> {\n+        if suf.is_some() && !lit.may_have_suffix() {\n+            err!(diag, |span, diag| {\n+                expect_no_suffix(span, diag, &format!(\"a {}\", lit.literal_name()), suf)\n+            });\n+        }\n+\n+        Some(match lit {\n+            token::Bool(i) => {\n+                assert!(i == keywords::True.name() || i == keywords::False.name());\n+                LitKind::Bool(i == keywords::True.name())\n+            }\n+            token::Byte(i) => {\n+                match unescape_byte(&i.as_str()) {\n+                    Ok(c) => LitKind::Byte(c),\n+                    Err(_) => LitKind::Err(i),\n+                }\n+            },\n+            token::Char(i) => {\n+                match unescape_char(&i.as_str()) {\n+                    Ok(c) => LitKind::Char(c),\n+                    Err(_) => LitKind::Err(i),\n+                }\n+            },\n+            token::Err(i) => LitKind::Err(i),\n+\n+            // There are some valid suffixes for integer and float literals,\n+            // so all the handling is done internally.\n+            token::Integer(s) => return integer_lit(&s.as_str(), suf, diag),\n+            token::Float(s) => return float_lit(&s.as_str(), suf, diag),\n+\n+            token::Str_(mut sym) => {\n+                // If there are no characters requiring special treatment we can\n+                // reuse the symbol from the Token. Otherwise, we must generate a\n+                // new symbol because the string in the LitKind is different to the\n+                // string in the Token.\n+                let mut has_error = false;\n+                let s = &sym.as_str();\n+                if s.as_bytes().iter().any(|&c| c == b'\\\\' || c == b'\\r') {\n+                    let mut buf = String::with_capacity(s.len());\n+                    unescape_str(s, &mut |_, unescaped_char| {\n+                        match unescaped_char {\n+                            Ok(c) => buf.push(c),\n+                            Err(_) => has_error = true,\n+                        }\n+                    });\n+                    if has_error {\n+                        return Some(LitKind::Err(sym));\n+                    }\n+                    sym = Symbol::intern(&buf)\n+                }\n+\n+                LitKind::Str(sym, ast::StrStyle::Cooked)\n+            }\n+            token::StrRaw(mut sym, n) => {\n+                // Ditto.\n+                let s = &sym.as_str();\n+                if s.contains('\\r') {\n+                    sym = Symbol::intern(&raw_str_lit(s));\n+                }\n+                LitKind::Str(sym, ast::StrStyle::Raw(n))\n+            }\n+            token::ByteStr(i) => {\n+                let s = &i.as_str();\n+                let mut buf = Vec::with_capacity(s.len());\n+                let mut has_error = false;\n+                unescape_byte_str(s, &mut |_, unescaped_byte| {\n+                    match unescaped_byte {\n+                        Ok(c) => buf.push(c),\n+                        Err(_) => has_error = true,\n+                    }\n+                });\n+                if has_error {\n+                    return Some(LitKind::Err(i));\n+                }\n+                buf.shrink_to_fit();\n+                LitKind::ByteStr(Lrc::new(buf))\n+            }\n+            token::ByteStrRaw(i, _) => {\n+                LitKind::ByteStr(Lrc::new(i.to_string().into_bytes()))\n+            }\n+        })\n+    }\n+\n+    /// Attempts to recover a token from semantic literal.\n+    /// This function is used when the original token doesn't exist (e.g. the literal is created\n+    /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n+    pub fn to_lit_token(&self) -> (token::Lit, Option<Symbol>) {\n+        match *self {\n+            LitKind::Str(string, ast::StrStyle::Cooked) => {\n+                let escaped = string.as_str().escape_default().to_string();\n+                (token::Lit::Str_(Symbol::intern(&escaped)), None)\n+            }\n+            LitKind::Str(string, ast::StrStyle::Raw(n)) => {\n+                (token::Lit::StrRaw(string, n), None)\n+            }\n+            LitKind::ByteStr(ref bytes) => {\n+                let string = bytes.iter().cloned().flat_map(ascii::escape_default)\n+                    .map(Into::<char>::into).collect::<String>();\n+                (token::Lit::ByteStr(Symbol::intern(&string)), None)\n+            }\n+            LitKind::Byte(byte) => {\n+                let string: String = ascii::escape_default(byte).map(Into::<char>::into).collect();\n+                (token::Lit::Byte(Symbol::intern(&string)), None)\n+            }\n+            LitKind::Char(ch) => {\n+                let string: String = ch.escape_default().map(Into::<char>::into).collect();\n+                (token::Lit::Char(Symbol::intern(&string)), None)\n+            }\n+            LitKind::Int(n, ty) => {\n+                let suffix = match ty {\n+                    ast::LitIntType::Unsigned(ty) => Some(Symbol::intern(ty.ty_to_string())),\n+                    ast::LitIntType::Signed(ty) => Some(Symbol::intern(ty.ty_to_string())),\n+                    ast::LitIntType::Unsuffixed => None,\n+                };\n+                (token::Lit::Integer(Symbol::intern(&n.to_string())), suffix)\n+            }\n+            LitKind::Float(symbol, ty) => {\n+                (token::Lit::Float(symbol), Some(Symbol::intern(ty.ty_to_string())))\n+            }\n+            LitKind::FloatUnsuffixed(symbol) => (token::Lit::Float(symbol), None),\n+            LitKind::Bool(value) => {\n+                let kw = if value { keywords::True } else { keywords::False };\n+                (token::Lit::Bool(kw.name()), None)\n+            }\n+            LitKind::Err(val) => (token::Lit::Err(val), None),\n+        }\n+    }\n+}\n+\n+impl Lit {\n+    /// Converts literal token with a suffix into an AST literal.\n+    /// Works speculatively and may return `None` is diagnostic handler is not passed.\n+    /// If diagnostic handler is passed, may return `Some`,\n+    /// possibly after reporting non-fatal errors and recovery, or `None` for irrecoverable errors.\n+    crate fn from_token(\n+        token: &token::Token,\n+        span: Span,\n+        diag: Option<(Span, &Handler)>,\n+    ) -> Option<Lit> {\n+        let (token, suffix) = match *token {\n+            token::Ident(ident, false) if ident.name == keywords::True.name() ||\n+                                          ident.name == keywords::False.name() =>\n+                (token::Bool(ident.name), None),\n+            token::Literal(token, suffix) =>\n+                (token, suffix),\n+            token::Interpolated(ref nt) => {\n+                if let token::NtExpr(expr) | token::NtLiteral(expr) = &**nt {\n+                    if let ast::ExprKind::Lit(lit) = &expr.node {\n+                        return Some(lit.clone());\n+                    }\n+                }\n+                return None;\n+            }\n+            _ => return None,\n+        };\n+\n+        let node = LitKind::from_lit_token(token, suffix, diag)?;\n+        Some(Lit { node, token, suffix, span })\n+    }\n+\n+    /// Attempts to recover an AST literal from semantic literal.\n+    /// This function is used when the original token doesn't exist (e.g. the literal is created\n+    /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n+    pub fn from_lit_kind(node: LitKind, span: Span) -> Lit {\n+        let (token, suffix) = node.to_lit_token();\n+        Lit { node, token, suffix, span }\n+    }\n+\n+    /// Losslessly convert an AST literal into a token stream.\n+    crate fn tokens(&self) -> TokenStream {\n+        let token = match self.token {\n+            token::Bool(symbol) => Token::Ident(Ident::with_empty_ctxt(symbol), false),\n+            token => Token::Literal(token, self.suffix),\n+        };\n+        TokenTree::Token(self.span, token).into()\n+    }\n+}\n+\n+impl<'a> Parser<'a> {\n+    /// Matches `lit = true | false | token_lit`.\n+    crate fn parse_lit(&mut self) -> PResult<'a, Lit> {\n+        let diag = Some((self.span, &self.sess.span_diagnostic));\n+        if let Some(lit) = Lit::from_token(&self.token, self.span, diag) {\n+            self.bump();\n+            return Ok(lit);\n+        } else if self.token == token::Dot {\n+            // Recover `.4` as `0.4`.\n+            let recovered = self.look_ahead(1, |t| {\n+                if let token::Literal(token::Integer(val), suf) = *t {\n+                    let next_span = self.look_ahead_span(1);\n+                    if self.span.hi() == next_span.lo() {\n+                        let sym = String::from(\"0.\") + &val.as_str();\n+                        let token = token::Literal(token::Float(Symbol::intern(&sym)), suf);\n+                        return Some((token, self.span.to(next_span)));\n+                    }\n+                }\n+                None\n+            });\n+            if let Some((token, span)) = recovered {\n+                self.diagnostic()\n+                    .struct_span_err(span, \"float literals must have an integer part\")\n+                    .span_suggestion(\n+                        span,\n+                        \"must have an integer part\",\n+                        pprust::token_to_string(&token),\n+                        Applicability::MachineApplicable,\n+                    )\n+                    .emit();\n+                let diag = Some((span, &self.sess.span_diagnostic));\n+                if let Some(lit) = Lit::from_token(&token, span, diag) {\n+                    self.bump();\n+                    self.bump();\n+                    return Ok(lit);\n+                }\n+            }\n+        }\n+\n+        Err(self.span_fatal(self.span, &format!(\"unexpected token: {}\", self.this_token_descr())))\n+    }\n+}\n+\n+crate fn expect_no_suffix(sp: Span, diag: &Handler, kind: &str, suffix: Option<ast::Name>) {\n+    match suffix {\n+        None => {/* everything ok */}\n+        Some(suf) => {\n+            let text = suf.as_str();\n+            if text.is_empty() {\n+                diag.span_bug(sp, \"found empty literal suffix in Some\")\n+            }\n+            let mut err = if kind == \"a tuple index\" &&\n+                [\"i32\", \"u32\", \"isize\", \"usize\"].contains(&text.to_string().as_str())\n+            {\n+                // #59553: warn instead of reject out of hand to allow the fix to percolate\n+                // through the ecosystem when people fix their macros\n+                let mut err = diag.struct_span_warn(\n+                    sp,\n+                    &format!(\"suffixes on {} are invalid\", kind),\n+                );\n+                err.note(&format!(\n+                    \"`{}` is *temporarily* accepted on tuple index fields as it was \\\n+                        incorrectly accepted on stable for a few releases\",\n+                    text,\n+                ));\n+                err.help(\n+                    \"on proc macros, you'll want to use `syn::Index::from` or \\\n+                        `proc_macro::Literal::*_unsuffixed` for code that will desugar \\\n+                        to tuple field access\",\n+                );\n+                err.note(\n+                    \"for more context, see https://github.com/rust-lang/rust/issues/60210\",\n+                );\n+                err\n+            } else {\n+                diag.struct_span_err(sp, &format!(\"suffixes on {} are invalid\", kind))\n+            };\n+            err.span_label(sp, format!(\"invalid suffix `{}`\", text));\n+            err.emit();\n+        }\n+    }\n+}\n+\n+/// Parses a string representing a raw string literal into its final form. The\n+/// only operation this does is convert embedded CRLF into a single LF.\n+fn raw_str_lit(lit: &str) -> String {\n+    debug!(\"raw_str_lit: given {}\", lit.escape_default());\n+    let mut res = String::with_capacity(lit.len());\n+\n+    let mut chars = lit.chars().peekable();\n+    while let Some(c) = chars.next() {\n+        if c == '\\r' {\n+            if *chars.peek().unwrap() != '\\n' {\n+                panic!(\"lexer accepted bare CR\");\n+            }\n+            chars.next();\n+            res.push('\\n');\n+        } else {\n+            res.push(c);\n+        }\n+    }\n+\n+    res.shrink_to_fit();\n+    res\n+}\n+\n+// check if `s` looks like i32 or u1234 etc.\n+fn looks_like_width_suffix(first_chars: &[char], s: &str) -> bool {\n+    s.starts_with(first_chars) && s[1..].chars().all(|c| c.is_ascii_digit())\n+}\n+\n+fn filtered_float_lit(data: Symbol, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n+                      -> Option<LitKind> {\n+    debug!(\"filtered_float_lit: {}, {:?}\", data, suffix);\n+    let suffix = match suffix {\n+        Some(suffix) => suffix,\n+        None => return Some(LitKind::FloatUnsuffixed(data)),\n+    };\n+\n+    Some(match &*suffix.as_str() {\n+        \"f32\" => LitKind::Float(data, ast::FloatTy::F32),\n+        \"f64\" => LitKind::Float(data, ast::FloatTy::F64),\n+        suf => {\n+            err!(diag, |span, diag| {\n+                if suf.len() >= 2 && looks_like_width_suffix(&['f'], suf) {\n+                    // if it looks like a width, lets try to be helpful.\n+                    let msg = format!(\"invalid width `{}` for float literal\", &suf[1..]);\n+                    diag.struct_span_err(span, &msg).help(\"valid widths are 32 and 64\").emit()\n+                } else {\n+                    let msg = format!(\"invalid suffix `{}` for float literal\", suf);\n+                    diag.struct_span_err(span, &msg)\n+                        .span_label(span, format!(\"invalid suffix `{}`\", suf))\n+                        .help(\"valid suffixes are `f32` and `f64`\")\n+                        .emit();\n+                }\n+            });\n+\n+            LitKind::FloatUnsuffixed(data)\n+        }\n+    })\n+}\n+fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n+                 -> Option<LitKind> {\n+    debug!(\"float_lit: {:?}, {:?}\", s, suffix);\n+    // FIXME #2252: bounds checking float literals is deferred until trans\n+\n+    // Strip underscores without allocating a new String unless necessary.\n+    let s2;\n+    let s = if s.chars().any(|c| c == '_') {\n+        s2 = s.chars().filter(|&c| c != '_').collect::<String>();\n+        &s2\n+    } else {\n+        s\n+    };\n+\n+    filtered_float_lit(Symbol::intern(s), suffix, diag)\n+}\n+\n+fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n+                   -> Option<LitKind> {\n+    // s can only be ascii, byte indexing is fine\n+\n+    // Strip underscores without allocating a new String unless necessary.\n+    let s2;\n+    let mut s = if s.chars().any(|c| c == '_') {\n+        s2 = s.chars().filter(|&c| c != '_').collect::<String>();\n+        &s2\n+    } else {\n+        s\n+    };\n+\n+    debug!(\"integer_lit: {}, {:?}\", s, suffix);\n+\n+    let mut base = 10;\n+    let orig = s;\n+    let mut ty = ast::LitIntType::Unsuffixed;\n+\n+    if s.starts_with('0') && s.len() > 1 {\n+        match s.as_bytes()[1] {\n+            b'x' => base = 16,\n+            b'o' => base = 8,\n+            b'b' => base = 2,\n+            _ => { }\n+        }\n+    }\n+\n+    // 1f64 and 2f32 etc. are valid float literals.\n+    if let Some(suf) = suffix {\n+        if looks_like_width_suffix(&['f'], &suf.as_str()) {\n+            let err = match base {\n+                16 => Some(\"hexadecimal float literal is not supported\"),\n+                8 => Some(\"octal float literal is not supported\"),\n+                2 => Some(\"binary float literal is not supported\"),\n+                _ => None,\n+            };\n+            if let Some(err) = err {\n+                err!(diag, |span, diag| {\n+                    diag.struct_span_err(span, err)\n+                        .span_label(span, \"not supported\")\n+                        .emit();\n+                });\n+            }\n+            return filtered_float_lit(Symbol::intern(s), Some(suf), diag)\n+        }\n+    }\n+\n+    if base != 10 {\n+        s = &s[2..];\n+    }\n+\n+    if let Some(suf) = suffix {\n+        if suf.as_str().is_empty() {\n+            err!(diag, |span, diag| diag.span_bug(span, \"found empty literal suffix in Some\"));\n+        }\n+        ty = match &*suf.as_str() {\n+            \"isize\" => ast::LitIntType::Signed(ast::IntTy::Isize),\n+            \"i8\"  => ast::LitIntType::Signed(ast::IntTy::I8),\n+            \"i16\" => ast::LitIntType::Signed(ast::IntTy::I16),\n+            \"i32\" => ast::LitIntType::Signed(ast::IntTy::I32),\n+            \"i64\" => ast::LitIntType::Signed(ast::IntTy::I64),\n+            \"i128\" => ast::LitIntType::Signed(ast::IntTy::I128),\n+            \"usize\" => ast::LitIntType::Unsigned(ast::UintTy::Usize),\n+            \"u8\"  => ast::LitIntType::Unsigned(ast::UintTy::U8),\n+            \"u16\" => ast::LitIntType::Unsigned(ast::UintTy::U16),\n+            \"u32\" => ast::LitIntType::Unsigned(ast::UintTy::U32),\n+            \"u64\" => ast::LitIntType::Unsigned(ast::UintTy::U64),\n+            \"u128\" => ast::LitIntType::Unsigned(ast::UintTy::U128),\n+            suf => {\n+                // i<digits> and u<digits> look like widths, so lets\n+                // give an error message along those lines\n+                err!(diag, |span, diag| {\n+                    if looks_like_width_suffix(&['i', 'u'], suf) {\n+                        let msg = format!(\"invalid width `{}` for integer literal\", &suf[1..]);\n+                        diag.struct_span_err(span, &msg)\n+                            .help(\"valid widths are 8, 16, 32, 64 and 128\")\n+                            .emit();\n+                    } else {\n+                        let msg = format!(\"invalid suffix `{}` for numeric literal\", suf);\n+                        diag.struct_span_err(span, &msg)\n+                            .span_label(span, format!(\"invalid suffix `{}`\", suf))\n+                            .help(\"the suffix must be one of the integral types \\\n+                                   (`u32`, `isize`, etc)\")\n+                            .emit();\n+                    }\n+                });\n+\n+                ty\n+            }\n+        }\n+    }\n+\n+    debug!(\"integer_lit: the type is {:?}, base {:?}, the new string is {:?}, the original \\\n+           string was {:?}, the original suffix was {:?}\", ty, base, s, orig, suffix);\n+\n+    Some(match u128::from_str_radix(s, base) {\n+        Ok(r) => LitKind::Int(r, ty),\n+        Err(_) => {\n+            // small bases are lexed as if they were base 10, e.g, the string\n+            // might be `0b10201`. This will cause the conversion above to fail,\n+            // but these cases have errors in the lexer: we don't want to emit\n+            // two errors, and we especially don't want to emit this error since\n+            // it isn't necessarily true.\n+            let already_errored = base < 10 &&\n+                s.chars().any(|c| c.to_digit(10).map_or(false, |d| d >= base));\n+\n+            if !already_errored {\n+                err!(diag, |span, diag| diag.span_err(span, \"int literal is too large\"));\n+            }\n+            LitKind::Int(0, ty)\n+        }\n+    })\n+}"}, {"sha": "526143b28755fa204bd2de07c192a4072f6a8c33", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 7, "deletions": 345, "changes": 352, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,11 +1,10 @@\n //! The main parser interface.\n \n-use crate::ast::{self, CrateConfig, LitKind, NodeId};\n+use crate::ast::{self, CrateConfig, NodeId};\n use crate::early_buffered_lints::{BufferedEarlyLint, BufferedEarlyLintId};\n use crate::source_map::{SourceMap, FilePathMapping};\n use crate::feature_gate::UnstableFeatures;\n use crate::parse::parser::Parser;\n-use crate::symbol::{keywords, Symbol};\n use crate::syntax::parse::parser::emit_unclosed_delims;\n use crate::tokenstream::{TokenStream, TokenTree};\n use crate::diagnostics::plugin::ErrorMap;\n@@ -14,7 +13,6 @@ use crate::print::pprust::token_to_string;\n use errors::{Applicability, FatalError, Level, Handler, ColorConfig, Diagnostic, DiagnosticBuilder};\n use rustc_data_structures::sync::{Lrc, Lock};\n use syntax_pos::{Span, SourceFile, FileName, MultiSpan};\n-use log::debug;\n \n use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use std::borrow::Cow;\n@@ -25,18 +23,15 @@ pub type PResult<'a, T> = Result<T, DiagnosticBuilder<'a>>;\n \n #[macro_use]\n pub mod parser;\n-\n+pub mod attr;\n pub mod lexer;\n pub mod token;\n-pub mod attr;\n-pub mod diagnostics;\n-\n-pub mod classify;\n-\n-pub(crate) mod unescape;\n-use unescape::{unescape_str, unescape_char, unescape_byte_str, unescape_byte};\n \n-pub(crate) mod unescape_error_reporting;\n+crate mod classify;\n+crate mod diagnostics;\n+crate mod literal;\n+crate mod unescape;\n+crate mod unescape_error_reporting;\n \n /// Info about a parsing session.\n pub struct ParseSess {\n@@ -334,339 +329,6 @@ pub fn stream_to_parser(sess: &ParseSess, stream: TokenStream) -> Parser<'_> {\n     Parser::new(sess, stream, None, true, false)\n }\n \n-/// Parses a string representing a raw string literal into its final form. The\n-/// only operation this does is convert embedded CRLF into a single LF.\n-fn raw_str_lit(lit: &str) -> String {\n-    debug!(\"raw_str_lit: given {}\", lit.escape_default());\n-    let mut res = String::with_capacity(lit.len());\n-\n-    let mut chars = lit.chars().peekable();\n-    while let Some(c) = chars.next() {\n-        if c == '\\r' {\n-            if *chars.peek().unwrap() != '\\n' {\n-                panic!(\"lexer accepted bare CR\");\n-            }\n-            chars.next();\n-            res.push('\\n');\n-        } else {\n-            res.push(c);\n-        }\n-    }\n-\n-    res.shrink_to_fit();\n-    res\n-}\n-\n-// check if `s` looks like i32 or u1234 etc.\n-fn looks_like_width_suffix(first_chars: &[char], s: &str) -> bool {\n-    s.starts_with(first_chars) && s[1..].chars().all(|c| c.is_ascii_digit())\n-}\n-\n-macro_rules! err {\n-    ($opt_diag:expr, |$span:ident, $diag:ident| $($body:tt)*) => {\n-        match $opt_diag {\n-            Some(($span, $diag)) => { $($body)* }\n-            None => return None,\n-        }\n-    }\n-}\n-\n-crate fn expect_no_suffix(sp: Span, diag: &Handler, kind: &str, suffix: Option<ast::Name>) {\n-    match suffix {\n-        None => {/* everything ok */}\n-        Some(suf) => {\n-            let text = suf.as_str();\n-            if text.is_empty() {\n-                diag.span_bug(sp, \"found empty literal suffix in Some\")\n-            }\n-            let mut err = if kind == \"a tuple index\" &&\n-                [\"i32\", \"u32\", \"isize\", \"usize\"].contains(&text.to_string().as_str())\n-            {\n-                // #59553: warn instead of reject out of hand to allow the fix to percolate\n-                // through the ecosystem when people fix their macros\n-                let mut err = diag.struct_span_warn(\n-                    sp,\n-                    &format!(\"suffixes on {} are invalid\", kind),\n-                );\n-                err.note(&format!(\n-                    \"`{}` is *temporarily* accepted on tuple index fields as it was \\\n-                        incorrectly accepted on stable for a few releases\",\n-                    text,\n-                ));\n-                err.help(\n-                    \"on proc macros, you'll want to use `syn::Index::from` or \\\n-                        `proc_macro::Literal::*_unsuffixed` for code that will desugar \\\n-                        to tuple field access\",\n-                );\n-                err.note(\n-                    \"for more context, see https://github.com/rust-lang/rust/issues/60210\",\n-                );\n-                err\n-            } else {\n-                diag.struct_span_err(sp, &format!(\"suffixes on {} are invalid\", kind))\n-            };\n-            err.span_label(sp, format!(\"invalid suffix `{}`\", text));\n-            err.emit();\n-        }\n-    }\n-}\n-\n-impl LitKind {\n-    /// Converts literal token with a suffix into a semantic literal.\n-    /// Works speculatively and may return `None` is diagnostic handler is not passed.\n-    /// If diagnostic handler is passed, always returns `Some`,\n-    /// possibly after reporting non-fatal errors and recovery.\n-    crate fn from_lit_token(\n-        lit: token::Lit,\n-        suf: Option<Symbol>,\n-        diag: Option<(Span, &Handler)>\n-    ) -> Option<LitKind> {\n-        if suf.is_some() && !lit.may_have_suffix() {\n-            err!(diag, |span, diag| {\n-                expect_no_suffix(span, diag, &format!(\"a {}\", lit.literal_name()), suf)\n-            });\n-        }\n-\n-        Some(match lit {\n-            token::Bool(i) => {\n-                assert!(i == keywords::True.name() || i == keywords::False.name());\n-                LitKind::Bool(i == keywords::True.name())\n-            }\n-            token::Byte(i) => {\n-                match unescape_byte(&i.as_str()) {\n-                    Ok(c) => LitKind::Byte(c),\n-                    Err(_) => LitKind::Err(i),\n-                }\n-            },\n-            token::Char(i) => {\n-                match unescape_char(&i.as_str()) {\n-                    Ok(c) => LitKind::Char(c),\n-                    Err(_) => LitKind::Err(i),\n-                }\n-            },\n-            token::Err(i) => LitKind::Err(i),\n-\n-            // There are some valid suffixes for integer and float literals,\n-            // so all the handling is done internally.\n-            token::Integer(s) => return integer_lit(&s.as_str(), suf, diag),\n-            token::Float(s) => return float_lit(&s.as_str(), suf, diag),\n-\n-            token::Str_(mut sym) => {\n-                // If there are no characters requiring special treatment we can\n-                // reuse the symbol from the Token. Otherwise, we must generate a\n-                // new symbol because the string in the LitKind is different to the\n-                // string in the Token.\n-                let mut has_error = false;\n-                let s = &sym.as_str();\n-                if s.as_bytes().iter().any(|&c| c == b'\\\\' || c == b'\\r') {\n-                    let mut buf = String::with_capacity(s.len());\n-                    unescape_str(s, &mut |_, unescaped_char| {\n-                        match unescaped_char {\n-                            Ok(c) => buf.push(c),\n-                            Err(_) => has_error = true,\n-                        }\n-                    });\n-                    if has_error {\n-                        return Some(LitKind::Err(sym));\n-                    }\n-                    sym = Symbol::intern(&buf)\n-                }\n-\n-                LitKind::Str(sym, ast::StrStyle::Cooked)\n-            }\n-            token::StrRaw(mut sym, n) => {\n-                // Ditto.\n-                let s = &sym.as_str();\n-                if s.contains('\\r') {\n-                    sym = Symbol::intern(&raw_str_lit(s));\n-                }\n-                LitKind::Str(sym, ast::StrStyle::Raw(n))\n-            }\n-            token::ByteStr(i) => {\n-                let s = &i.as_str();\n-                let mut buf = Vec::with_capacity(s.len());\n-                let mut has_error = false;\n-                unescape_byte_str(s, &mut |_, unescaped_byte| {\n-                    match unescaped_byte {\n-                        Ok(c) => buf.push(c),\n-                        Err(_) => has_error = true,\n-                    }\n-                });\n-                if has_error {\n-                    return Some(LitKind::Err(i));\n-                }\n-                buf.shrink_to_fit();\n-                LitKind::ByteStr(Lrc::new(buf))\n-            }\n-            token::ByteStrRaw(i, _) => {\n-                LitKind::ByteStr(Lrc::new(i.to_string().into_bytes()))\n-            }\n-        })\n-    }\n-}\n-\n-fn filtered_float_lit(data: Symbol, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                      -> Option<LitKind> {\n-    debug!(\"filtered_float_lit: {}, {:?}\", data, suffix);\n-    let suffix = match suffix {\n-        Some(suffix) => suffix,\n-        None => return Some(LitKind::FloatUnsuffixed(data)),\n-    };\n-\n-    Some(match &*suffix.as_str() {\n-        \"f32\" => LitKind::Float(data, ast::FloatTy::F32),\n-        \"f64\" => LitKind::Float(data, ast::FloatTy::F64),\n-        suf => {\n-            err!(diag, |span, diag| {\n-                if suf.len() >= 2 && looks_like_width_suffix(&['f'], suf) {\n-                    // if it looks like a width, lets try to be helpful.\n-                    let msg = format!(\"invalid width `{}` for float literal\", &suf[1..]);\n-                    diag.struct_span_err(span, &msg).help(\"valid widths are 32 and 64\").emit()\n-                } else {\n-                    let msg = format!(\"invalid suffix `{}` for float literal\", suf);\n-                    diag.struct_span_err(span, &msg)\n-                        .span_label(span, format!(\"invalid suffix `{}`\", suf))\n-                        .help(\"valid suffixes are `f32` and `f64`\")\n-                        .emit();\n-                }\n-            });\n-\n-            LitKind::FloatUnsuffixed(data)\n-        }\n-    })\n-}\n-fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                 -> Option<LitKind> {\n-    debug!(\"float_lit: {:?}, {:?}\", s, suffix);\n-    // FIXME #2252: bounds checking float literals is deferred until trans\n-\n-    // Strip underscores without allocating a new String unless necessary.\n-    let s2;\n-    let s = if s.chars().any(|c| c == '_') {\n-        s2 = s.chars().filter(|&c| c != '_').collect::<String>();\n-        &s2\n-    } else {\n-        s\n-    };\n-\n-    filtered_float_lit(Symbol::intern(s), suffix, diag)\n-}\n-\n-fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                   -> Option<LitKind> {\n-    // s can only be ascii, byte indexing is fine\n-\n-    // Strip underscores without allocating a new String unless necessary.\n-    let s2;\n-    let mut s = if s.chars().any(|c| c == '_') {\n-        s2 = s.chars().filter(|&c| c != '_').collect::<String>();\n-        &s2\n-    } else {\n-        s\n-    };\n-\n-    debug!(\"integer_lit: {}, {:?}\", s, suffix);\n-\n-    let mut base = 10;\n-    let orig = s;\n-    let mut ty = ast::LitIntType::Unsuffixed;\n-\n-    if s.starts_with('0') && s.len() > 1 {\n-        match s.as_bytes()[1] {\n-            b'x' => base = 16,\n-            b'o' => base = 8,\n-            b'b' => base = 2,\n-            _ => { }\n-        }\n-    }\n-\n-    // 1f64 and 2f32 etc. are valid float literals.\n-    if let Some(suf) = suffix {\n-        if looks_like_width_suffix(&['f'], &suf.as_str()) {\n-            let err = match base {\n-                16 => Some(\"hexadecimal float literal is not supported\"),\n-                8 => Some(\"octal float literal is not supported\"),\n-                2 => Some(\"binary float literal is not supported\"),\n-                _ => None,\n-            };\n-            if let Some(err) = err {\n-                err!(diag, |span, diag| {\n-                    diag.struct_span_err(span, err)\n-                        .span_label(span, \"not supported\")\n-                        .emit();\n-                });\n-            }\n-            return filtered_float_lit(Symbol::intern(s), Some(suf), diag)\n-        }\n-    }\n-\n-    if base != 10 {\n-        s = &s[2..];\n-    }\n-\n-    if let Some(suf) = suffix {\n-        if suf.as_str().is_empty() {\n-            err!(diag, |span, diag| diag.span_bug(span, \"found empty literal suffix in Some\"));\n-        }\n-        ty = match &*suf.as_str() {\n-            \"isize\" => ast::LitIntType::Signed(ast::IntTy::Isize),\n-            \"i8\"  => ast::LitIntType::Signed(ast::IntTy::I8),\n-            \"i16\" => ast::LitIntType::Signed(ast::IntTy::I16),\n-            \"i32\" => ast::LitIntType::Signed(ast::IntTy::I32),\n-            \"i64\" => ast::LitIntType::Signed(ast::IntTy::I64),\n-            \"i128\" => ast::LitIntType::Signed(ast::IntTy::I128),\n-            \"usize\" => ast::LitIntType::Unsigned(ast::UintTy::Usize),\n-            \"u8\"  => ast::LitIntType::Unsigned(ast::UintTy::U8),\n-            \"u16\" => ast::LitIntType::Unsigned(ast::UintTy::U16),\n-            \"u32\" => ast::LitIntType::Unsigned(ast::UintTy::U32),\n-            \"u64\" => ast::LitIntType::Unsigned(ast::UintTy::U64),\n-            \"u128\" => ast::LitIntType::Unsigned(ast::UintTy::U128),\n-            suf => {\n-                // i<digits> and u<digits> look like widths, so lets\n-                // give an error message along those lines\n-                err!(diag, |span, diag| {\n-                    if looks_like_width_suffix(&['i', 'u'], suf) {\n-                        let msg = format!(\"invalid width `{}` for integer literal\", &suf[1..]);\n-                        diag.struct_span_err(span, &msg)\n-                            .help(\"valid widths are 8, 16, 32, 64 and 128\")\n-                            .emit();\n-                    } else {\n-                        let msg = format!(\"invalid suffix `{}` for numeric literal\", suf);\n-                        diag.struct_span_err(span, &msg)\n-                            .span_label(span, format!(\"invalid suffix `{}`\", suf))\n-                            .help(\"the suffix must be one of the integral types \\\n-                                   (`u32`, `isize`, etc)\")\n-                            .emit();\n-                    }\n-                });\n-\n-                ty\n-            }\n-        }\n-    }\n-\n-    debug!(\"integer_lit: the type is {:?}, base {:?}, the new string is {:?}, the original \\\n-           string was {:?}, the original suffix was {:?}\", ty, base, s, orig, suffix);\n-\n-    Some(match u128::from_str_radix(s, base) {\n-        Ok(r) => LitKind::Int(r, ty),\n-        Err(_) => {\n-            // small bases are lexed as if they were base 10, e.g, the string\n-            // might be `0b10201`. This will cause the conversion above to fail,\n-            // but these cases have errors in the lexer: we don't want to emit\n-            // two errors, and we especially don't want to emit this error since\n-            // it isn't necessarily true.\n-            let already_errored = base < 10 &&\n-                s.chars().any(|c| c.to_digit(10).map_or(false, |d| d >= base));\n-\n-            if !already_errored {\n-                err!(diag, |span, diag| diag.span_err(span, \"int literal is too large\"));\n-            }\n-            LitKind::Int(0, ty)\n-        }\n-    })\n-}\n-\n /// A sequence separator.\n pub struct SeqSep {\n     /// The seperator token."}, {"sha": "f95981680b940581f6b9557f99f16d6456c33d1d", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 5, "deletions": 51, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -15,7 +15,7 @@ use crate::ast::{ForeignItem, ForeignItemKind, FunctionRetTy};\n use crate::ast::{GenericParam, GenericParamKind};\n use crate::ast::GenericArg;\n use crate::ast::{Ident, ImplItem, IsAsync, IsAuto, Item, ItemKind};\n-use crate::ast::{Label, Lifetime, Lit};\n+use crate::ast::{Label, Lifetime};\n use crate::ast::{Local, LocalSource};\n use crate::ast::MacStmtStyle;\n use crate::ast::{Mac, Mac_, MacDelimiter};\n@@ -35,7 +35,7 @@ use crate::ast::{RangeEnd, RangeSyntax};\n use crate::{ast, attr};\n use crate::ext::base::DummyResult;\n use crate::source_map::{self, SourceMap, Spanned, respan};\n-use crate::parse::{self, SeqSep, classify, token};\n+use crate::parse::{SeqSep, classify, literal, token};\n use crate::parse::lexer::{TokenAndSpan, UnmatchedBrace};\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use crate::parse::token::DelimToken;\n@@ -613,19 +613,14 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    fn this_token_descr(&self) -> String {\n+    crate fn this_token_descr(&self) -> String {\n         if let Some(prefix) = self.token_descr() {\n             format!(\"{} `{}`\", prefix, self.this_token_to_string())\n         } else {\n             format!(\"`{}`\", self.this_token_to_string())\n         }\n     }\n \n-    fn unexpected_last<T>(&self, t: &token::Token) -> PResult<'a, T> {\n-        let token_str = pprust::token_to_string(t);\n-        Err(self.span_fatal(self.prev_span, &format!(\"unexpected token: `{}`\", token_str)))\n-    }\n-\n     crate fn unexpected<T>(&mut self) -> PResult<'a, T> {\n         match self.expect_one_of(&[], &[]) {\n             Err(e) => Err(e),\n@@ -1109,7 +1104,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn expect_no_suffix(&self, sp: Span, kind: &str, suffix: Option<ast::Name>) {\n-        parse::expect_no_suffix(sp, &self.sess.span_diagnostic, kind, suffix)\n+        literal::expect_no_suffix(sp, &self.sess.span_diagnostic, kind, suffix)\n     }\n \n     /// Attempts to consume a `<`. If `<<` is seen, replaces it with a single\n@@ -1387,7 +1382,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    fn look_ahead_span(&self, dist: usize) -> Span {\n+    crate fn look_ahead_span(&self, dist: usize) -> Span {\n         if dist == 0 {\n             return self.span\n         }\n@@ -2030,47 +2025,6 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Matches `lit = true | false | token_lit`.\n-    crate fn parse_lit(&mut self) -> PResult<'a, Lit> {\n-        let diag = Some((self.span, &self.sess.span_diagnostic));\n-        if let Some(lit) = Lit::from_token(&self.token, self.span, diag) {\n-            self.bump();\n-            return Ok(lit);\n-        } else if self.token == token::Dot {\n-            // Recover `.4` as `0.4`.\n-            let recovered = self.look_ahead(1, |t| {\n-                if let token::Literal(token::Integer(val), suf) = *t {\n-                    let next_span = self.look_ahead_span(1);\n-                    if self.span.hi() == next_span.lo() {\n-                        let sym = String::from(\"0.\") + &val.as_str();\n-                        let token = token::Literal(token::Float(Symbol::intern(&sym)), suf);\n-                        return Some((token, self.span.to(next_span)));\n-                    }\n-                }\n-                None\n-            });\n-            if let Some((token, span)) = recovered {\n-                self.diagnostic()\n-                    .struct_span_err(span, \"float literals must have an integer part\")\n-                    .span_suggestion(\n-                        span,\n-                        \"must have an integer part\",\n-                        pprust::token_to_string(&token),\n-                        Applicability::MachineApplicable,\n-                    )\n-                    .emit();\n-                let diag = Some((span, &self.sess.span_diagnostic));\n-                if let Some(lit) = Lit::from_token(&token, span, diag) {\n-                    self.bump();\n-                    self.bump();\n-                    return Ok(lit);\n-                }\n-            }\n-        }\n-\n-        self.unexpected_last(&self.token)\n-    }\n-\n     /// Matches `'-' lit | lit` (cf. `ast_validation::AstValidator::check_expr_within_pat`).\n     crate fn parse_literal_maybe_minus(&mut self) -> PResult<'a, P<Expr>> {\n         maybe_whole_expr!(self);"}, {"sha": "571779dfa1ae72f740d58e14cdc87170ff622aa1", "filename": "src/test/ui/attr-eq-token-tree.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fattr-eq-token-tree.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fattr-eq-token-tree.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fattr-eq-token-tree.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,8 +1,8 @@\n error: unexpected token: `!`\n-  --> $DIR/attr-eq-token-tree.rs:3:11\n+  --> $DIR/attr-eq-token-tree.rs:3:13\n    |\n LL | #[my_attr = !]\n-   |           ^\n+   |             ^\n \n error: aborting due to previous error\n "}, {"sha": "359725a41c105892aedde9f8ecdcbc8460050c59", "filename": "src/test/ui/exclusive-range/exclusive_range_pattern_syntax_collision.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fexclusive-range%2Fexclusive_range_pattern_syntax_collision.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fexclusive-range%2Fexclusive_range_pattern_syntax_collision.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fexclusive-range%2Fexclusive_range_pattern_syntax_collision.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,8 +1,8 @@\n error: unexpected token: `,`\n-  --> $DIR/exclusive_range_pattern_syntax_collision.rs:5:15\n+  --> $DIR/exclusive_range_pattern_syntax_collision.rs:5:17\n    |\n LL |         [_, 99.., _] => {},\n-   |               ^^\n+   |                 ^\n \n error: aborting due to previous error\n "}, {"sha": "8f849d7b3f87c5a53f8af1f5d302b970afe481f0", "filename": "src/test/ui/exclusive-range/exclusive_range_pattern_syntax_collision2.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fexclusive-range%2Fexclusive_range_pattern_syntax_collision2.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fexclusive-range%2Fexclusive_range_pattern_syntax_collision2.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fexclusive-range%2Fexclusive_range_pattern_syntax_collision2.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,8 +1,8 @@\n error: unexpected token: `]`\n-  --> $DIR/exclusive_range_pattern_syntax_collision2.rs:5:15\n+  --> $DIR/exclusive_range_pattern_syntax_collision2.rs:5:17\n    |\n LL |         [_, 99..] => {},\n-   |               ^^\n+   |                 ^\n \n error: aborting due to previous error\n "}, {"sha": "d28ce25341d3ac89509674565b09e7635aae21e9", "filename": "src/test/ui/macros/macro-attribute.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fmacros%2Fmacro-attribute.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fmacros%2Fmacro-attribute.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fmacros%2Fmacro-attribute.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,8 +1,8 @@\n error: unexpected token: `$`\n-  --> $DIR/macro-attribute.rs:1:7\n+  --> $DIR/macro-attribute.rs:1:9\n    |\n LL | #[doc = $not_there]\n-   |       ^\n+   |         ^\n \n error: aborting due to previous error\n "}, {"sha": "e805416172bab8d58133ea77e026cf0546341cc8", "filename": "src/test/ui/malformed/malformed-interpolated.stderr", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -7,19 +7,19 @@ LL | check!(0u8);\n    = help: instead of using a suffixed literal (1u8, 1.0f32, etc.), use an unsuffixed version (1, 1.0, etc.).\n \n error: unexpected token: `-0`\n-  --> $DIR/malformed-interpolated.rs:5:19\n+  --> $DIR/malformed-interpolated.rs:5:21\n    |\n LL |         #[my_attr = $expr]\n-   |                   ^\n+   |                     ^^^^^\n ...\n LL | check!(-0); // ERROR, see above\n    | ----------- in this macro invocation\n \n error: unexpected token: `0 + 0`\n-  --> $DIR/malformed-interpolated.rs:5:19\n+  --> $DIR/malformed-interpolated.rs:5:21\n    |\n LL |         #[my_attr = $expr]\n-   |                   ^\n+   |                     ^^^^^\n ...\n LL | check!(0 + 0); // ERROR, see above\n    | -------------- in this macro invocation"}, {"sha": "2d772dae69125c74ffc2bf4358471a11cf086ca1", "filename": "src/test/ui/parser/attr-bad-meta-2.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fparser%2Fattr-bad-meta-2.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fparser%2Fattr-bad-meta-2.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fattr-bad-meta-2.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,8 +1,8 @@\n error: unexpected token: `]`\n-  --> $DIR/attr-bad-meta-2.rs:1:8\n+  --> $DIR/attr-bad-meta-2.rs:1:9\n    |\n LL | #[path =]\n-   |        ^\n+   |         ^\n \n error: aborting due to previous error\n "}, {"sha": "f9832214c6800b4c7ba8fc0012d47ecc78a86b22", "filename": "src/test/ui/parser/pat-tuple-5.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fparser%2Fpat-tuple-5.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3f064cae3d9d0d33951a44c30d83696563244572/src%2Ftest%2Fui%2Fparser%2Fpat-tuple-5.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fpat-tuple-5.stderr?ref=3f064cae3d9d0d33951a44c30d83696563244572", "patch": "@@ -1,8 +1,8 @@\n error: unexpected token: `)`\n-  --> $DIR/pat-tuple-5.rs:3:14\n+  --> $DIR/pat-tuple-5.rs:3:16\n    |\n LL |         (pat ..) => {}\n-   |              ^^\n+   |                ^\n \n error: aborting due to previous error\n "}]}