{"sha": "b3c676ed868c1dda574ce0745f272ea76c5255c3", "node_id": "MDY6Q29tbWl0NzI0NzEyOmIzYzY3NmVkODY4YzFkZGE1NzRjZTA3NDVmMjcyZWE3NmM1MjU1YzM=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-10-27T16:06:38Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-10-27T19:53:01Z"}, "message": "rollup merge of #18229 : bjz/ttdelim", "tree": {"sha": "316a57c4575b97a95ed659583225f6a311253016", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/316a57c4575b97a95ed659583225f6a311253016"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b3c676ed868c1dda574ce0745f272ea76c5255c3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b3c676ed868c1dda574ce0745f272ea76c5255c3", "html_url": "https://github.com/rust-lang/rust/commit/b3c676ed868c1dda574ce0745f272ea76c5255c3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b3c676ed868c1dda574ce0745f272ea76c5255c3/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "83e91fb489232a4cedb06568f08982e6bfb6b4c8", "url": "https://api.github.com/repos/rust-lang/rust/commits/83e91fb489232a4cedb06568f08982e6bfb6b4c8", "html_url": "https://github.com/rust-lang/rust/commit/83e91fb489232a4cedb06568f08982e6bfb6b4c8"}, {"sha": "6598d33bd0edf22adb24423851bf2761cae0ada0", "url": "https://api.github.com/repos/rust-lang/rust/commits/6598d33bd0edf22adb24423851bf2761cae0ada0", "html_url": "https://github.com/rust-lang/rust/commit/6598d33bd0edf22adb24423851bf2761cae0ada0"}], "stats": {"total": 602, "additions": 331, "deletions": 271}, "files": [{"sha": "83a5697f75a69d92c5283a2d9ba91a2c35bc957d", "filename": "src/doc/guide-plugin.md", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Fdoc%2Fguide-plugin.md", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Fdoc%2Fguide-plugin.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fguide-plugin.md?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -56,7 +56,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{IDENT, get_ident};\n-use syntax::ast::{TokenTree, TTTok};\n+use syntax::ast::{TokenTree, TtToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n use syntax::ext::build::AstBuilder;  // trait for expr_uint\n use rustc::plugin::Registry;\n@@ -71,7 +71,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TTTok(_, IDENT(s, _))] => get_ident(s).to_string(),\n+        [TtToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}, {"sha": "580b93eb4c6f31f46324fd5db2b6f4e1e7a05b8b", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 47, "deletions": 15, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -24,6 +24,9 @@ use std::fmt::Show;\n use std::rc::Rc;\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n+#[cfg(stage0)]\n+pub use self::TtToken as TTTok;\n+\n // FIXME #6993: in librustc, uses of \"ident\" should be replaced\n // by just \"Name\".\n \n@@ -592,6 +595,28 @@ pub enum CaptureClause {\n     CaptureByRef,\n }\n \n+/// A token that delimits a sequence of token trees\n+#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n+pub struct Delimiter {\n+    pub span: Span,\n+    pub token: ::parse::token::Token,\n+}\n+\n+impl Delimiter {\n+    /// Convert the delimiter to a `TtToken`\n+    pub fn to_tt(&self) -> TokenTree {\n+        TtToken(self.span, self.token.clone())\n+    }\n+}\n+\n+/// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n+/// for token sequences.\n+#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n+pub enum KleeneOp {\n+    ZeroOrMore,\n+    OneOrMore,\n+}\n+\n /// When the main rust parser encounters a syntax-extension invocation, it\n /// parses the arguments to the invocation as a token-tree. This is a very\n /// loose structure, such that all sorts of different AST-fragments can\n@@ -600,32 +625,39 @@ pub enum CaptureClause {\n /// If the syntax extension is an MBE macro, it will attempt to match its\n /// LHS \"matchers\" against the provided token tree, and if it finds a\n /// match, will transcribe the RHS token tree, splicing in any captured\n-/// macro_parser::matched_nonterminals into the TTNonterminals it finds.\n+/// `macro_parser::matched_nonterminals` into the `TtNonterminal`s it finds.\n ///\n-/// The RHS of an MBE macro is the only place a TTNonterminal or TTSeq\n+/// The RHS of an MBE macro is the only place a `TtNonterminal` or `TtSequence`\n /// makes any real sense. You could write them elsewhere but nothing\n /// else knows what to do with them, so you'll probably get a syntax\n /// error.\n #[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n pub enum TokenTree {\n     /// A single token\n-    TTTok(Span, ::parse::token::Token),\n-    /// A delimited sequence (the delimiters appear as the first\n-    /// and last elements of the vector)\n-    // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTDelim(Rc<Vec<TokenTree>>),\n+    TtToken(Span, ::parse::token::Token),\n+    /// A delimited sequence of token trees\n+    TtDelimited(Span, Rc<(Delimiter, Vec<TokenTree>, Delimiter)>),\n \n     // These only make sense for right-hand-sides of MBE macros:\n \n-    /// A kleene-style repetition sequence with a span, a TTForest,\n-    /// an optional separator, and a boolean where true indicates\n-    /// zero or more (..), and false indicates one or more (+).\n+    /// A Kleene-style repetition sequence with an optional separator.\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTSeq(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, bool),\n-\n+    TtSequence(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, KleeneOp),\n     /// A syntactic variable that will be filled in by macro expansion.\n-    TTNonterminal(Span, Ident)\n+    TtNonterminal(Span, Ident)\n+}\n+\n+impl TokenTree {\n+    /// Returns the `Span` corresponding to this token tree.\n+    pub fn get_span(&self) -> Span {\n+        match *self {\n+            TtToken(span, _)           => span,\n+            TtDelimited(span, _)       => span,\n+            TtSequence(span, _, _, _)  => span,\n+            TtNonterminal(span, _)     => span,\n+        }\n+    }\n }\n \n // Matchers are nodes defined-by and recognized-by the main rust parser and\n@@ -684,9 +716,9 @@ pub type Matcher = Spanned<Matcher_>;\n pub enum Matcher_ {\n     /// Match one token\n     MatchTok(::parse::token::Token),\n-    /// Match repetitions of a sequence: body, separator, zero ok?,\n+    /// Match repetitions of a sequence: body, separator, Kleene operator,\n     /// lo, hi position-in-match-array used:\n-    MatchSeq(Vec<Matcher> , Option<::parse::token::Token>, bool, uint, uint),\n+    MatchSeq(Vec<Matcher> , Option<::parse::token::Token>, KleeneOp, uint, uint),\n     /// Parse a Rust NT: name to bind, name of NT, position in match array:\n     MatchNonterminal(Ident, Ident, uint)\n }"}, {"sha": "b8795ad5be80fa12211ca1a34b99deb01afbd995", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -50,7 +50,7 @@ pub fn expand_diagnostic_used<'cx>(ecx: &'cx mut ExtCtxt,\n                                    token_tree: &[TokenTree])\n                                    -> Box<MacResult+'cx> {\n     let code = match token_tree {\n-        [ast::TTTok(_, token::IDENT(code, _))] => code,\n+        [ast::TtToken(_, token::IDENT(code, _))] => code,\n         _ => unreachable!()\n     };\n     with_registered_diagnostics(|diagnostics| {\n@@ -82,12 +82,12 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n                                        token_tree: &[TokenTree])\n                                        -> Box<MacResult+'cx> {\n     let (code, description) = match token_tree {\n-        [ast::TTTok(_, token::IDENT(ref code, _))] => {\n+        [ast::TtToken(_, token::IDENT(ref code, _))] => {\n             (code, None)\n         },\n-        [ast::TTTok(_, token::IDENT(ref code, _)),\n-         ast::TTTok(_, token::COMMA),\n-         ast::TTTok(_, token::LIT_STR_RAW(description, _))] => {\n+        [ast::TtToken(_, token::IDENT(ref code, _)),\n+         ast::TtToken(_, token::COMMA),\n+         ast::TtToken(_, token::LIT_STR_RAW(description, _))] => {\n             (code, Some(description))\n         }\n         _ => unreachable!()\n@@ -110,7 +110,7 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n                                           token_tree: &[TokenTree])\n                                           -> Box<MacResult+'cx> {\n     let name = match token_tree {\n-        [ast::TTTok(_, token::IDENT(ref name, _))] => name,\n+        [ast::TtToken(_, token::IDENT(ref name, _))] => name,\n         _ => unreachable!()\n     };\n "}, {"sha": "64c8068607aa011259e14c0528419e248ef1a25f", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -684,8 +684,8 @@ pub fn get_single_str_from_tts(cx: &ExtCtxt,\n         cx.span_err(sp, format!(\"{} takes 1 argument.\", name).as_slice());\n     } else {\n         match tts[0] {\n-            ast::TTTok(_, token::LIT_STR(ident)) => return Some(parse::str_lit(ident.as_str())),\n-            ast::TTTok(_, token::LIT_STR_RAW(ident, _)) => {\n+            ast::TtToken(_, token::LIT_STR(ident)) => return Some(parse::str_lit(ident.as_str())),\n+            ast::TtToken(_, token::LIT_STR_RAW(ident, _)) => {\n                 return Some(parse::raw_str_lit(ident.as_str()))\n             }\n             _ => {"}, {"sha": "e12f9ee133a328171a687b423d7b40b6ba3a576e", "filename": "src/libsyntax/ext/concat_idents.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fconcat_idents.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -23,15 +23,15 @@ pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]\n     for (i, e) in tts.iter().enumerate() {\n         if i & 1 == 1 {\n             match *e {\n-                ast::TTTok(_, token::COMMA) => (),\n+                ast::TtToken(_, token::COMMA) => (),\n                 _ => {\n                     cx.span_err(sp, \"concat_idents! expecting comma.\");\n                     return DummyResult::expr(sp);\n                 }\n             }\n         } else {\n             match *e {\n-                ast::TTTok(_, token::IDENT(ident,_)) => {\n+                ast::TtToken(_, token::IDENT(ident,_)) => {\n                     res_str.push_str(token::get_ident(ident).get())\n                 }\n                 _ => {"}, {"sha": "30301e3b8cc92414a940ebc6fb374d958a267479", "filename": "src/libsyntax/ext/log_syntax.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Flog_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Flog_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Flog_syntax.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -13,16 +13,14 @@ use codemap;\n use ext::base;\n use print;\n \n-use std::rc::Rc;\n-\n pub fn expand_syntax_ext<'cx>(cx: &'cx mut base::ExtCtxt,\n                               sp: codemap::Span,\n-                              tt: &[ast::TokenTree])\n+                              tts: &[ast::TokenTree])\n                               -> Box<base::MacResult+'cx> {\n \n     cx.print_backtrace();\n-    println!(\"{}\", print::pprust::tt_to_string(&ast::TTDelim(\n-                Rc::new(tt.iter().map(|x| (*x).clone()).collect()))));\n+\n+    println!(\"{}\", print::pprust::tts_to_string(tts));\n \n     // any so that `log_syntax` can be invoked as an expression and item.\n     base::DummyResult::any(sp)"}, {"sha": "6f1fd90adfa4b6591a58d80f596d184fa1c51f5b", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 16, "deletions": 13, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -23,7 +23,7 @@ use ptr::P;\n *\n * This is registered as a set of expression syntax extension called quote!\n * that lifts its argument token-tree to an AST representing the\n-* construction of the same token tree, with ast::TTNonterminal nodes\n+* construction of the same token tree, with ast::TtNonterminal nodes\n * interpreted as antiquotes (splices).\n *\n */\n@@ -637,26 +637,29 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n }\n \n \n-fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n+fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n     match *tt {\n-        ast::TTTok(sp, ref tok) => {\n+        ast::TtToken(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n             let e_tok = cx.expr_call(sp,\n-                                     mk_ast_path(cx, sp, \"TTTok\"),\n+                                     mk_ast_path(cx, sp, \"TtToken\"),\n                                      vec!(e_sp, mk_token(cx, sp, tok)));\n             let e_push =\n                 cx.expr_method_call(sp,\n                                     cx.expr_ident(sp, id_ext(\"tt\")),\n                                     id_ext(\"push\"),\n                                     vec!(e_tok));\n             vec!(cx.stmt_expr(e_push))\n-        }\n-\n-        ast::TTDelim(ref tts) => mk_tts(cx, sp, tts.as_slice()),\n-        ast::TTSeq(..) => fail!(\"TTSeq in quote!\"),\n-\n-        ast::TTNonterminal(sp, ident) => {\n-\n+        },\n+        ast::TtDelimited(sp, ref delimed) => {\n+            let (ref open, ref tts, ref close) = **delimed;\n+            mk_tt(cx, sp, &open.to_tt()).into_iter()\n+                .chain(tts.iter().flat_map(|tt| mk_tt(cx, sp, tt).into_iter()))\n+                .chain(mk_tt(cx, sp, &close.to_tt()).into_iter())\n+                .collect()\n+        },\n+        ast::TtSequence(..) => fail!(\"TtSequence in quote!\"),\n+        ast::TtNonterminal(sp, ident) => {\n             // tt.extend($ident.to_tokens(ext_cx).into_iter())\n \n             let e_to_toks =\n@@ -674,7 +677,7 @@ fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n                                     vec!(e_to_toks));\n \n             vec!(cx.stmt_expr(e_push))\n-        }\n+        },\n     }\n }\n \n@@ -690,7 +693,7 @@ fn mk_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n               -> (P<ast::Expr>, P<ast::Expr>) {\n     // NB: It appears that the main parser loses its mind if we consider\n-    // $foo as a TTNonterminal during the main parse, so we have to re-parse\n+    // $foo as a TtNonterminal during the main parse, so we have to re-parse\n     // under quote_depth > 0. This is silly and should go away; the _guess_ is\n     // it has to do with transition away from supporting old-style macros, so\n     // try removing it when enough of them are gone."}, {"sha": "abf798ddacb3a12c36895d32f77b9c21033e347a", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -20,10 +20,10 @@ pub fn expand_trace_macros(cx: &mut ExtCtxt,\n                            tt: &[ast::TokenTree])\n                            -> Box<base::MacResult+'static> {\n     match tt {\n-        [ast::TTTok(_, ref tok)] if is_keyword(keywords::True, tok) => {\n+        [ast::TtToken(_, ref tok)] if is_keyword(keywords::True, tok) => {\n             cx.set_trace_macros(true);\n         }\n-        [ast::TTTok(_, ref tok)] if is_keyword(keywords::False, tok) => {\n+        [ast::TtToken(_, ref tok)] if is_keyword(keywords::False, tok) => {\n             cx.set_trace_macros(false);\n         }\n         _ => cx.span_err(sp, \"trace_macros! accepts only `true` or `false`\"),"}, {"sha": "cea8cab52654d3e3a0af7fe6f73b15224cef6b90", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -323,9 +323,9 @@ pub fn parse(sess: &ParseSess,\n             } else {\n                 match ei.elts[idx].node.clone() {\n                   /* need to descend into sequence */\n-                  MatchSeq(ref matchers, ref sep, zero_ok,\n+                  MatchSeq(ref matchers, ref sep, kleene_op,\n                            match_idx_lo, match_idx_hi) => {\n-                    if zero_ok {\n+                    if kleene_op == ast::ZeroOrMore {\n                         let mut new_ei = ei.clone();\n                         new_ei.idx += 1u;\n                         //we specifically matched zero repeats."}, {"sha": "3b51fb380b816853611a75d0e4cb6762355a5827", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 12, "deletions": 18, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TTDelim};\n+use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TtDelimited};\n use ast;\n use codemap::{Span, Spanned, DUMMY_SP};\n use ext::base::{ExtCtxt, MacResult, MacroDef};\n@@ -147,13 +147,9 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                           rhses: &[Rc<NamedMatch>])\n                           -> Box<MacResult+'cx> {\n     if cx.trace_macros() {\n-        println!(\"{}! {} {} {}\",\n+        println!(\"{}! {{ {} }}\",\n                  token::get_ident(name),\n-                 \"{\",\n-                 print::pprust::tt_to_string(&TTDelim(Rc::new(arg.iter()\n-                                                              .map(|x| (*x).clone())\n-                                                              .collect()))),\n-                 \"}\");\n+                 print::pprust::tts_to_string(arg));\n     }\n \n     // Which arm's failure should we report? (the one furthest along)\n@@ -175,15 +171,12 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     // okay, what's your transcriber?\n                     MatchedNonterminal(NtTT(ref tt)) => {\n                         match **tt {\n-                            // cut off delimiters; don't parse 'em\n-                            TTDelim(ref tts) => {\n-                                (*tts).slice(1u,(*tts).len()-1u)\n-                                      .iter()\n-                                      .map(|x| (*x).clone())\n-                                      .collect()\n-                            }\n-                            _ => cx.span_fatal(\n-                                sp, \"macro rhs must be delimited\")\n+                            // ignore delimiters\n+                            TtDelimited(_, ref delimed) => {\n+                                let (_, ref tts, _) = **delimed;\n+                                tts.clone()\n+                            },\n+                            _ => cx.span_fatal(sp, \"macro rhs must be delimited\"),\n                         }\n                     },\n                     _ => cx.span_bug(sp, \"bad thing in rhs\")\n@@ -239,10 +232,11 @@ pub fn add_new_extension<'cx>(cx: &'cx mut ExtCtxt,\n         ms(MatchSeq(vec!(\n             ms(MatchNonterminal(lhs_nm, special_idents::matchers, 0u)),\n             ms(MatchTok(FAT_ARROW)),\n-            ms(MatchNonterminal(rhs_nm, special_idents::tt, 1u))), Some(SEMI), false, 0u, 2u)),\n+            ms(MatchNonterminal(rhs_nm, special_idents::tt, 1u))), Some(SEMI),\n+                                ast::OneOrMore, 0u, 2u)),\n         //to phase into semicolon-termination instead of\n         //semicolon-separation\n-        ms(MatchSeq(vec!(ms(MatchTok(SEMI))), None, true, 2u, 2u)));\n+        ms(MatchSeq(vec!(ms(MatchTok(SEMI))), None, ast::ZeroOrMore, 2u, 2u)));\n \n \n     // Parse the macro_rules! invocation (`none` is for no interpolations):"}, {"sha": "1bb519f66cd55fca25fc26930f80c3a2f727787c", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 48, "deletions": 33, "changes": 81, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -9,7 +9,7 @@\n // except according to those terms.\n \n use ast;\n-use ast::{TokenTree, TTDelim, TTTok, TTSeq, TTNonterminal, Ident};\n+use ast::{TokenTree, TtDelimited, TtToken, TtSequence, TtNonterminal, Ident};\n use codemap::{Span, DUMMY_SP};\n use diagnostic::SpanHandler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n@@ -18,6 +18,7 @@ use parse::token;\n use parse::lexer::TokenAndSpan;\n \n use std::rc::Rc;\n+use std::ops::Add;\n use std::collections::HashMap;\n \n ///an unzipping of `TokenTree`s\n@@ -44,7 +45,7 @@ pub struct TtReader<'a> {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TTSeq`s and `TTNonterminal`s, `interp` can (and\n+/// `src` contains no `TtSequence`s and `TtNonterminal`s, `interp` can (and\n /// should) be none.\n pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n                          interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n@@ -104,37 +105,45 @@ enum LockstepIterSize {\n     LisContradiction(String),\n }\n \n-fn lis_merge(lhs: LockstepIterSize, rhs: LockstepIterSize) -> LockstepIterSize {\n-    match lhs {\n-        LisUnconstrained => rhs.clone(),\n-        LisContradiction(_) => lhs.clone(),\n-        LisConstraint(l_len, l_id) => match rhs {\n-            LisUnconstrained => lhs.clone(),\n-            LisContradiction(_) => rhs.clone(),\n-            LisConstraint(r_len, _) if l_len == r_len => lhs.clone(),\n-            LisConstraint(r_len, r_id) => {\n-                let l_n = token::get_ident(l_id);\n-                let r_n = token::get_ident(r_id);\n-                LisContradiction(format!(\"inconsistent lockstep iteration: \\\n-                                          '{}' has {} items, but '{}' has {}\",\n-                                          l_n, l_len, r_n, r_len).to_string())\n-            }\n+impl Add<LockstepIterSize, LockstepIterSize> for LockstepIterSize {\n+    fn add(&self, other: &LockstepIterSize) -> LockstepIterSize {\n+        match *self {\n+            LisUnconstrained => other.clone(),\n+            LisContradiction(_) => self.clone(),\n+            LisConstraint(l_len, l_id) => match *other {\n+                LisUnconstrained => self.clone(),\n+                LisContradiction(_) => other.clone(),\n+                LisConstraint(r_len, _) if l_len == r_len => self.clone(),\n+                LisConstraint(r_len, r_id) => {\n+                    let l_n = token::get_ident(l_id);\n+                    let r_n = token::get_ident(r_id);\n+                    LisContradiction(format!(\"inconsistent lockstep iteration: \\\n+                                              '{}' has {} items, but '{}' has {}\",\n+                                              l_n, l_len, r_n, r_len).to_string())\n+                }\n+            },\n         }\n     }\n }\n \n fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n     match *t {\n-        TTDelim(ref tts) | TTSeq(_, ref tts, _, _) => {\n-            tts.iter().fold(LisUnconstrained, |lis, tt| {\n-                lis_merge(lis, lockstep_iter_size(tt, r))\n+        TtDelimited(_, ref delimed) => {\n+            let (_, ref tts, _) = **delimed;\n+            tts.iter().fold(LisUnconstrained, |size, tt| {\n+                size + lockstep_iter_size(tt, r)\n             })\n-        }\n-        TTTok(..) => LisUnconstrained,\n-        TTNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n+        },\n+        TtSequence(_, ref tts, _, _) => {\n+            tts.iter().fold(LisUnconstrained, |size, tt| {\n+                size + lockstep_iter_size(tt, r)\n+            })\n+        },\n+        TtToken(..) => LisUnconstrained,\n+        TtNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n             MatchedNonterminal(_) => LisUnconstrained,\n             MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name)\n-        }\n+        },\n     }\n }\n \n@@ -189,32 +198,38 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             }\n         }\n     }\n-    loop { /* because it's easiest, this handles `TTDelim` not starting\n-              with a `TTTok`, even though it won't happen */\n+    loop { /* because it's easiest, this handles `TtDelimited` not starting\n+              with a `TtToken`, even though it won't happen */\n         let t = {\n             let frame = r.stack.last().unwrap();\n             // FIXME(pcwalton): Bad copy.\n             (*frame.forest)[frame.idx].clone()\n         };\n         match t {\n-            TTDelim(tts) => {\n+            TtDelimited(_, ref delimed) => {\n+                let (ref open, ref tts, ref close) = **delimed;\n+                let mut forest = Vec::with_capacity(1 + tts.len() + 1);\n+                forest.push(open.to_tt());\n+                forest.extend(tts.iter().map(|x| (*x).clone()));\n+                forest.push(close.to_tt());\n+\n                 r.stack.push(TtFrame {\n-                    forest: tts,\n+                    forest: Rc::new(forest),\n                     idx: 0,\n                     dotdotdoted: false,\n                     sep: None\n                 });\n                 // if this could be 0-length, we'd need to potentially recur here\n             }\n-            TTTok(sp, tok) => {\n+            TtToken(sp, tok) => {\n                 r.cur_span = sp;\n                 r.cur_tok = tok;\n                 r.stack.last_mut().unwrap().idx += 1;\n                 return ret_val;\n             }\n-            TTSeq(sp, tts, sep, zerok) => {\n+            TtSequence(sp, tts, sep, kleene_op) => {\n                 // FIXME(pcwalton): Bad copy.\n-                match lockstep_iter_size(&TTSeq(sp, tts.clone(), sep.clone(), zerok), r) {\n+                match lockstep_iter_size(&TtSequence(sp, tts.clone(), sep.clone(), kleene_op), r) {\n                     LisUnconstrained => {\n                         r.sp_diag.span_fatal(\n                             sp.clone(), /* blame macro writer */\n@@ -228,7 +243,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                         }\n                     LisConstraint(len, _) => {\n                         if len == 0 {\n-                            if !zerok {\n+                            if kleene_op == ast::OneOrMore {\n                                 // FIXME #2887 blame invoker\n                                 r.sp_diag.span_fatal(sp.clone(),\n                                                      \"this must repeat at least once\");\n@@ -249,7 +264,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n-            TTNonterminal(sp, ident) => {\n+            TtNonterminal(sp, ident) => {\n                 r.stack.last_mut().unwrap().idx += 1;\n                 match *lookup_cur_matched(r, ident) {\n                     /* sidestep the interpolation tricks for ident because"}, {"sha": "0f9ab5c6b261ece7ff24a099f92b4a8c4a4c8e9e", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 23, "deletions": 10, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -569,16 +569,29 @@ pub fn noop_fold_arg<T: Folder>(Arg {id, pat, ty}: Arg, fld: &mut T) -> Arg {\n \n pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n     match *tt {\n-        TTTok(span, ref tok) =>\n-            TTTok(span, fld.fold_token(tok.clone())),\n-        TTDelim(ref tts) => TTDelim(Rc::new(fld.fold_tts(tts.as_slice()))),\n-        TTSeq(span, ref pattern, ref sep, is_optional) =>\n-            TTSeq(span,\n-                  Rc::new(fld.fold_tts(pattern.as_slice())),\n-                  sep.clone().map(|tok| fld.fold_token(tok)),\n-                  is_optional),\n-        TTNonterminal(sp,ref ident) =>\n-            TTNonterminal(sp,fld.fold_ident(*ident))\n+        TtToken(span, ref tok) =>\n+            TtToken(span, fld.fold_token(tok.clone())),\n+        TtDelimited(span, ref delimed) => {\n+            let (ref open, ref tts, ref close) = **delimed;\n+            TtDelimited(span, Rc::new((\n+                            Delimiter {\n+                                span: open.span,\n+                                token: fld.fold_token(open.token.clone())\n+                            },\n+                            fld.fold_tts(tts.as_slice()),\n+                            Delimiter {\n+                                span: close.span,\n+                                token: fld.fold_token(close.token.clone())\n+                            },\n+                        )))\n+        },\n+        TtSequence(span, ref pattern, ref sep, is_optional) =>\n+            TtSequence(span,\n+                       Rc::new(fld.fold_tts(pattern.as_slice())),\n+                       sep.clone().map(|tok| fld.fold_token(tok)),\n+                       is_optional),\n+        TtNonterminal(sp,ref ident) =>\n+            TtNonterminal(sp,fld.fold_ident(*ident))\n     }\n }\n "}, {"sha": "2965094f23662f396aeb47ec7fcd3f6da47e740a", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 107, "deletions": 121, "changes": 228, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -788,65 +788,57 @@ mod test {\n     }\n \n     // check the token-tree-ization of macros\n-    #[test] fn string_to_tts_macro () {\n+    #[test]\n+    fn string_to_tts_macro () {\n         let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n         let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n-            [ast::TTTok(_,_),\n-             ast::TTTok(_,token::NOT),\n-             ast::TTTok(_,_),\n-             ast::TTDelim(ref delim_elts)] => {\n-                let delim_elts: &[ast::TokenTree] = delim_elts.as_slice();\n-                match delim_elts {\n-                    [ast::TTTok(_,token::LPAREN),\n-                     ast::TTDelim(ref first_set),\n-                     ast::TTTok(_,token::FAT_ARROW),\n-                     ast::TTDelim(ref second_set),\n-                     ast::TTTok(_,token::RPAREN)] => {\n-                        let first_set: &[ast::TokenTree] =\n-                            first_set.as_slice();\n-                        match first_set {\n-                            [ast::TTTok(_,token::LPAREN),\n-                             ast::TTTok(_,token::DOLLAR),\n-                             ast::TTTok(_,_),\n-                             ast::TTTok(_,token::RPAREN)] => {\n-                                let second_set: &[ast::TokenTree] =\n-                                    second_set.as_slice();\n-                                match second_set {\n-                                    [ast::TTTok(_,token::LPAREN),\n-                                     ast::TTTok(_,token::DOLLAR),\n-                                     ast::TTTok(_,_),\n-                                     ast::TTTok(_,token::RPAREN)] => {\n-                                        assert_eq!(\"correct\",\"correct\")\n-                                    }\n-                                    _ => assert_eq!(\"wrong 4\",\"correct\")\n-                                }\n-                            },\n-                            _ => {\n-                                error!(\"failing value 3: {}\",first_set);\n-                                assert_eq!(\"wrong 3\",\"correct\")\n-                            }\n+            [ast::TtToken(_, token::IDENT(name_macro_rules, false)),\n+             ast::TtToken(_, token::NOT),\n+             ast::TtToken(_, token::IDENT(name_zip, false)),\n+             ast::TtDelimited(_, ref macro_delimed)]\n+            if name_macro_rules.as_str() == \"macro_rules\"\n+            && name_zip.as_str() == \"zip\" => {\n+                let (ref macro_open, ref macro_tts, ref macro_close) = **macro_delimed;\n+                match (macro_open, macro_tts.as_slice(), macro_close) {\n+                    (&ast::Delimiter { token: token::LPAREN, .. },\n+                     [ast::TtDelimited(_, ref first_delimed),\n+                      ast::TtToken(_, token::FAT_ARROW),\n+                      ast::TtDelimited(_, ref second_delimed)],\n+                     &ast::Delimiter { token: token::RPAREN, .. }) => {\n+                        let (ref first_open, ref first_tts, ref first_close) = **first_delimed;\n+                        match (first_open, first_tts.as_slice(), first_close) {\n+                            (&ast::Delimiter { token: token::LPAREN, .. },\n+                             [ast::TtToken(_, token::DOLLAR),\n+                              ast::TtToken(_, token::IDENT(name, false))],\n+                             &ast::Delimiter { token: token::RPAREN, .. })\n+                            if name.as_str() == \"a\" => {},\n+                            _ => fail!(\"value 3: {}\", **first_delimed),\n+                        }\n+                        let (ref second_open, ref second_tts, ref second_close) = **second_delimed;\n+                        match (second_open, second_tts.as_slice(), second_close) {\n+                            (&ast::Delimiter { token: token::LPAREN, .. },\n+                             [ast::TtToken(_, token::DOLLAR),\n+                              ast::TtToken(_, token::IDENT(name, false))],\n+                             &ast::Delimiter { token: token::RPAREN, .. })\n+                            if name.as_str() == \"a\" => {},\n+                            _ => fail!(\"value 4: {}\", **second_delimed),\n                         }\n                     },\n-                    _ => {\n-                        error!(\"failing value 2: {}\",delim_elts);\n-                        assert_eq!(\"wrong\",\"correct\");\n-                    }\n+                    _ => fail!(\"value 2: {}\", **macro_delimed),\n                 }\n             },\n-            _ => {\n-                error!(\"failing value: {}\",tts);\n-                assert_eq!(\"wrong 1\",\"correct\");\n-            }\n+            _ => fail!(\"value: {}\",tts),\n         }\n     }\n \n-    #[test] fn string_to_tts_1 () {\n+    #[test]\n+    fn string_to_tts_1 () {\n         let tts = string_to_tts(\"fn a (b : int) { b; }\".to_string());\n         assert_eq!(json::encode(&tts),\n         \"[\\\n     {\\\n-        \\\"variant\\\":\\\"TTTok\\\",\\\n+        \\\"variant\\\":\\\"TtToken\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n             {\\\n@@ -859,7 +851,7 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTTok\\\",\\\n+        \\\"variant\\\":\\\"TtToken\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n             {\\\n@@ -872,96 +864,90 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTDelim\\\",\\\n+        \\\"variant\\\":\\\"TtDelimited\\\",\\\n         \\\"fields\\\":[\\\n+            null,\\\n             [\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        \\\"LPAREN\\\"\\\n-                    ]\\\n-                },\\\n-                {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        {\\\n-                            \\\"variant\\\":\\\"IDENT\\\",\\\n-                            \\\"fields\\\":[\\\n-                                \\\"b\\\",\\\n-                                false\\\n-                            ]\\\n-                        }\\\n-                    ]\\\n+                    \\\"span\\\":null,\\\n+                    \\\"token\\\":\\\"LPAREN\\\"\\\n                 },\\\n+                [\\\n+                    {\\\n+                        \\\"variant\\\":\\\"TtToken\\\",\\\n+                        \\\"fields\\\":[\\\n+                            null,\\\n+                            {\\\n+                                \\\"variant\\\":\\\"IDENT\\\",\\\n+                                \\\"fields\\\":[\\\n+                                    \\\"b\\\",\\\n+                                    false\\\n+                                ]\\\n+                            }\\\n+                        ]\\\n+                    },\\\n+                    {\\\n+                        \\\"variant\\\":\\\"TtToken\\\",\\\n+                        \\\"fields\\\":[\\\n+                            null,\\\n+                            \\\"COLON\\\"\\\n+                        ]\\\n+                    },\\\n+                    {\\\n+                        \\\"variant\\\":\\\"TtToken\\\",\\\n+                        \\\"fields\\\":[\\\n+                            null,\\\n+                            {\\\n+                                \\\"variant\\\":\\\"IDENT\\\",\\\n+                                \\\"fields\\\":[\\\n+                                    \\\"int\\\",\\\n+                                    false\\\n+                                ]\\\n+                            }\\\n+                        ]\\\n+                    }\\\n+                ],\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        \\\"COLON\\\"\\\n-                    ]\\\n-                },\\\n-                {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        {\\\n-                            \\\"variant\\\":\\\"IDENT\\\",\\\n-                            \\\"fields\\\":[\\\n-                                \\\"int\\\",\\\n-                                false\\\n-                            ]\\\n-                        }\\\n-                    ]\\\n-                },\\\n-                {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        \\\"RPAREN\\\"\\\n-                    ]\\\n+                    \\\"span\\\":null,\\\n+                    \\\"token\\\":\\\"RPAREN\\\"\\\n                 }\\\n             ]\\\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTDelim\\\",\\\n+        \\\"variant\\\":\\\"TtDelimited\\\",\\\n         \\\"fields\\\":[\\\n+            null,\\\n             [\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        \\\"LBRACE\\\"\\\n-                    ]\\\n-                },\\\n-                {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        {\\\n-                            \\\"variant\\\":\\\"IDENT\\\",\\\n-                            \\\"fields\\\":[\\\n-                                \\\"b\\\",\\\n-                                false\\\n-                            ]\\\n-                        }\\\n-                    ]\\\n-                },\\\n-                {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        \\\"SEMI\\\"\\\n-                    ]\\\n+                    \\\"span\\\":null,\\\n+                    \\\"token\\\":\\\"LBRACE\\\"\\\n                 },\\\n+                [\\\n+                    {\\\n+                        \\\"variant\\\":\\\"TtToken\\\",\\\n+                        \\\"fields\\\":[\\\n+                            null,\\\n+                            {\\\n+                                \\\"variant\\\":\\\"IDENT\\\",\\\n+                                \\\"fields\\\":[\\\n+                                    \\\"b\\\",\\\n+                                    false\\\n+                                ]\\\n+                            }\\\n+                        ]\\\n+                    },\\\n+                    {\\\n+                        \\\"variant\\\":\\\"TtToken\\\",\\\n+                        \\\"fields\\\":[\\\n+                            null,\\\n+                            \\\"SEMI\\\"\\\n+                        ]\\\n+                    }\\\n+                ],\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n-                    \\\"fields\\\":[\\\n-                        null,\\\n-                        \\\"RBRACE\\\"\\\n-                    ]\\\n+                    \\\"span\\\":null,\\\n+                    \\\"token\\\":\\\"RBRACE\\\"\\\n                 }\\\n             ]\\\n         ]\\"}, {"sha": "7bf751c2d5ebf3b4a7a9c50767bdd4e4c20d618d", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 41, "deletions": 32, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -48,8 +48,8 @@ use ast::{StmtExpr, StmtSemi, StmtMac, StructDef, StructField};\n use ast::{StructVariantKind, BiSub};\n use ast::StrStyle;\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n-use ast::{TokenTree, TraitItem, TraitRef, TTDelim, TTSeq, TTTok};\n-use ast::{TTNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n+use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TtDelimited, TtSequence, TtToken};\n+use ast::{TtNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n use ast::{TypeField, TyFixedLengthVec, TyClosure, TyProc, TyBareFn};\n use ast::{TyTypeof, TyInfer, TypeMethod};\n use ast::{TyNil, TyParam, TyParamBound, TyParen, TyPath, TyPtr, TyQPath};\n@@ -2497,27 +2497,30 @@ impl<'a> Parser<'a> {\n         return e;\n     }\n \n-    /// Parse an optional separator followed by a kleene-style\n+    /// Parse an optional separator followed by a Kleene-style\n     /// repetition token (+ or *).\n-    pub fn parse_sep_and_zerok(&mut self) -> (Option<token::Token>, bool) {\n-        fn parse_zerok(parser: &mut Parser) -> Option<bool> {\n+    pub fn parse_sep_and_kleene_op(&mut self) -> (Option<token::Token>, ast::KleeneOp) {\n+        fn parse_kleene_op(parser: &mut Parser) -> Option<ast::KleeneOp> {\n             match parser.token {\n-                token::BINOP(token::STAR) | token::BINOP(token::PLUS) => {\n-                    let zerok = parser.token == token::BINOP(token::STAR);\n+                token::BINOP(token::STAR) => {\n                     parser.bump();\n-                    Some(zerok)\n+                    Some(ast::ZeroOrMore)\n+                },\n+                token::BINOP(token::PLUS) => {\n+                    parser.bump();\n+                    Some(ast::OneOrMore)\n                 },\n                 _ => None\n             }\n         };\n \n-        match parse_zerok(self) {\n-            Some(zerok) => return (None, zerok),\n+        match parse_kleene_op(self) {\n+            Some(kleene_op) => return (None, kleene_op),\n             None => {}\n         }\n \n         let separator = self.bump_and_get();\n-        match parse_zerok(self) {\n+        match parse_kleene_op(self) {\n             Some(zerok) => (Some(separator), zerok),\n             None => self.fatal(\"expected `*` or `+`\")\n         }\n@@ -2526,8 +2529,8 @@ impl<'a> Parser<'a> {\n     /// parse a single token tree from the input.\n     pub fn parse_token_tree(&mut self) -> TokenTree {\n         // FIXME #6994: currently, this is too eager. It\n-        // parses token trees but also identifies TTSeq's\n-        // and TTNonterminal's; it's too early to know yet\n+        // parses token trees but also identifies TtSequence's\n+        // and TtNonterminal's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n         maybe_whole!(deref self, NtTT);\n@@ -2564,26 +2567,21 @@ impl<'a> Parser<'a> {\n                         seq_sep_none(),\n                         |p| p.parse_token_tree()\n                     );\n-                    let (s, z) = p.parse_sep_and_zerok();\n+                    let (sep, repeat) = p.parse_sep_and_kleene_op();\n                     let seq = match seq {\n                         Spanned { node, .. } => node,\n                     };\n-                    TTSeq(mk_sp(sp.lo, p.span.hi), Rc::new(seq), s, z)\n+                    TtSequence(mk_sp(sp.lo, p.span.hi), Rc::new(seq), sep, repeat)\n                 } else {\n-                    TTNonterminal(sp, p.parse_ident())\n+                    TtNonterminal(sp, p.parse_ident())\n                 }\n               }\n               _ => {\n-                  parse_any_tt_tok(p)\n+                  TtToken(p.span, p.bump_and_get())\n               }\n             }\n         }\n \n-        // turn the next token into a TTTok:\n-        fn parse_any_tt_tok(p: &mut Parser) -> TokenTree {\n-            TTTok(p.span, p.bump_and_get())\n-        }\n-\n         match (&self.token, token::close_delimiter_for(&self.token)) {\n             (&token::EOF, _) => {\n                 let open_braces = self.open_braces.clone();\n@@ -2595,21 +2593,32 @@ impl<'a> Parser<'a> {\n                 self.fatal(\"this file contains an un-closed delimiter \");\n             }\n             (_, Some(close_delim)) => {\n+                // The span for beginning of the delimited section\n+                let pre_span = self.span;\n+\n                 // Parse the open delimiter.\n                 self.open_braces.push(self.span);\n-                let mut result = vec!(parse_any_tt_tok(self));\n+                let open = Delimiter {\n+                    span: self.span,\n+                    token: self.bump_and_get(),\n+                };\n \n-                let trees =\n-                    self.parse_seq_to_before_end(&close_delim,\n-                                                 seq_sep_none(),\n-                                                 |p| p.parse_token_tree());\n-                result.extend(trees.into_iter());\n+                // Parse the token trees within the delimeters\n+                let tts = self.parse_seq_to_before_end(\n+                    &close_delim, seq_sep_none(), |p| p.parse_token_tree()\n+                );\n \n                 // Parse the close delimiter.\n-                result.push(parse_any_tt_tok(self));\n+                let close = Delimiter {\n+                    span: self.span,\n+                    token: self.bump_and_get(),\n+                };\n                 self.open_braces.pop().unwrap();\n \n-                TTDelim(Rc::new(result))\n+                // Expand to cover the entire delimited token tree\n+                let span = Span { hi: self.span.hi, ..pre_span };\n+\n+                TtDelimited(span, Rc::new((open, tts, close)))\n             }\n             _ => parse_non_delim_tt_tok(self)\n         }\n@@ -2673,8 +2682,8 @@ impl<'a> Parser<'a> {\n                 if ms.len() == 0u {\n                     self.fatal(\"repetition body must be nonempty\");\n                 }\n-                let (sep, zerok) = self.parse_sep_and_zerok();\n-                MatchSeq(ms, sep, zerok, name_idx_lo, *name_idx)\n+                let (sep, kleene_op) = self.parse_sep_and_kleene_op();\n+                MatchSeq(ms, sep, kleene_op, name_idx_lo, *name_idx)\n             } else {\n                 let bound_to = self.parse_ident();\n                 self.expect(&token::COLON);"}, {"sha": "0a77343547bf857010786ec19d71b2286eca96c9", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 16, "deletions": 6, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -1020,8 +1020,15 @@ impl<'a> State<'a> {\n     /// expression arguments as expressions). It can be done! I think.\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> IoResult<()> {\n         match *tt {\n-            ast::TTDelim(ref tts) => self.print_tts(tts.as_slice()),\n-            ast::TTTok(_, ref tk) => {\n+            ast::TtDelimited(_, ref delimed) => {\n+                let (ref open, ref tts, ref close) = **delimed;\n+                try!(word(&mut self.s, parse::token::to_string(&open.token).as_slice()));\n+                try!(space(&mut self.s));\n+                try!(self.print_tts(tts.as_slice()));\n+                try!(space(&mut self.s));\n+                word(&mut self.s, parse::token::to_string(&close.token).as_slice())\n+            },\n+            ast::TtToken(_, ref tk) => {\n                 try!(word(&mut self.s, parse::token::to_string(tk).as_slice()));\n                 match *tk {\n                     parse::token::DOC_COMMENT(..) => {\n@@ -1030,22 +1037,25 @@ impl<'a> State<'a> {\n                     _ => Ok(())\n                 }\n             }\n-            ast::TTSeq(_, ref tts, ref sep, zerok) => {\n+            ast::TtSequence(_, ref tts, ref separator, kleene_op) => {\n                 try!(word(&mut self.s, \"$(\"));\n                 for tt_elt in (*tts).iter() {\n                     try!(self.print_tt(tt_elt));\n                 }\n                 try!(word(&mut self.s, \")\"));\n-                match *sep {\n+                match *separator {\n                     Some(ref tk) => {\n                         try!(word(&mut self.s,\n                                   parse::token::to_string(tk).as_slice()));\n                     }\n                     None => ()\n                 }\n-                word(&mut self.s, if zerok { \"*\" } else { \"+\" })\n+                match kleene_op {\n+                    ast::ZeroOrMore => word(&mut self.s, \"*\"),\n+                    ast::OneOrMore => word(&mut self.s, \"+\"),\n+                }\n             }\n-            ast::TTNonterminal(_, name) => {\n+            ast::TtNonterminal(_, name) => {\n                 try!(word(&mut self.s, \"$\"));\n                 self.print_ident(name)\n             }"}, {"sha": "40ed3a35ddf134bb6b6f9b174bb704d800738314", "filename": "src/test/auxiliary/roman_numerals.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b3c676ed868c1dda574ce0745f272ea76c5255c3/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Froman_numerals.rs?ref=b3c676ed868c1dda574ce0745f272ea76c5255c3", "patch": "@@ -18,7 +18,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{IDENT, get_ident};\n-use syntax::ast::{TokenTree, TTTok};\n+use syntax::ast::{TokenTree, TtToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n use syntax::ext::build::AstBuilder;  // trait for expr_uint\n use rustc::plugin::Registry;\n@@ -39,7 +39,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TTTok(_, IDENT(s, _))] => get_ident(s).to_string(),\n+        [TtToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}]}