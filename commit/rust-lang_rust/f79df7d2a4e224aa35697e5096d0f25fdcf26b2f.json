{"sha": "f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "node_id": "C_kwDOAAsO6NoAKGY3OWRmN2QyYTRlMjI0YWEzNTY5N2U1MDk2ZDBmMjVmZGNmMjZiMmY", "commit": {"author": {"name": "Maybe Waffle", "email": "waffle.lapkin@gmail.com", "date": "2023-04-19T18:00:48Z"}, "committer": {"name": "Maybe Waffle", "email": "waffle.lapkin@gmail.com", "date": "2023-04-19T18:00:48Z"}, "message": "`deny(unsafe_op_in_unsafe_fn)` in `rustc_data_structures`", "tree": {"sha": "d72dfc093802d242feb9b81299ee3c8179b34cb7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d72dfc093802d242feb9b81299ee3c8179b34cb7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "html_url": "https://github.com/rust-lang/rust/commit/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/comments", "author": {"login": "WaffleLapkin", "id": 38225716, "node_id": "MDQ6VXNlcjM4MjI1NzE2", "avatar_url": "https://avatars.githubusercontent.com/u/38225716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaffleLapkin", "html_url": "https://github.com/WaffleLapkin", "followers_url": "https://api.github.com/users/WaffleLapkin/followers", "following_url": "https://api.github.com/users/WaffleLapkin/following{/other_user}", "gists_url": "https://api.github.com/users/WaffleLapkin/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaffleLapkin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaffleLapkin/subscriptions", "organizations_url": "https://api.github.com/users/WaffleLapkin/orgs", "repos_url": "https://api.github.com/users/WaffleLapkin/repos", "events_url": "https://api.github.com/users/WaffleLapkin/events{/privacy}", "received_events_url": "https://api.github.com/users/WaffleLapkin/received_events", "type": "User", "site_admin": false}, "committer": {"login": "WaffleLapkin", "id": 38225716, "node_id": "MDQ6VXNlcjM4MjI1NzE2", "avatar_url": "https://avatars.githubusercontent.com/u/38225716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaffleLapkin", "html_url": "https://github.com/WaffleLapkin", "followers_url": "https://api.github.com/users/WaffleLapkin/followers", "following_url": "https://api.github.com/users/WaffleLapkin/following{/other_user}", "gists_url": "https://api.github.com/users/WaffleLapkin/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaffleLapkin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaffleLapkin/subscriptions", "organizations_url": "https://api.github.com/users/WaffleLapkin/orgs", "repos_url": "https://api.github.com/users/WaffleLapkin/repos", "events_url": "https://api.github.com/users/WaffleLapkin/events{/privacy}", "received_events_url": "https://api.github.com/users/WaffleLapkin/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d7f9e81650dcee3e2d5ad1973a71da644a2eff93", "url": "https://api.github.com/repos/rust-lang/rust/commits/d7f9e81650dcee3e2d5ad1973a71da644a2eff93", "html_url": "https://github.com/rust-lang/rust/commit/d7f9e81650dcee3e2d5ad1973a71da644a2eff93"}], "stats": {"total": 210, "additions": 109, "deletions": 101}, "files": [{"sha": "426d2c4034bd8f64c0aa3eaf032743ef791b957d", "filename": "compiler/rustc_data_structures/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Flib.rs?ref=f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "patch": "@@ -35,6 +35,7 @@\n #![allow(rustc::potential_query_instability)]\n #![deny(rustc::untranslatable_diagnostic)]\n #![deny(rustc::diagnostic_outside_of_impl)]\n+#![deny(unsafe_op_in_unsafe_fn)]\n \n #[macro_use]\n extern crate tracing;"}, {"sha": "ca908671ae5307b6d78bfc6424040781b1f156bd", "filename": "compiler/rustc_data_structures/src/memmap.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Fmemmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Fmemmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fmemmap.rs?ref=f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "patch": "@@ -13,7 +13,8 @@ pub struct Mmap(Vec<u8>);\n impl Mmap {\n     #[inline]\n     pub unsafe fn map(file: File) -> io::Result<Self> {\n-        memmap2::Mmap::map(&file).map(Mmap)\n+        // Safety: this is in fact not safe.\n+        unsafe { memmap2::Mmap::map(&file).map(Mmap) }\n     }\n }\n "}, {"sha": "4a0ed87f77c84e78c3a011b1cbc374062d573c4b", "filename": "compiler/rustc_data_structures/src/sip128.rs", "status": "modified", "additions": 101, "deletions": 95, "changes": 196, "blob_url": "https://github.com/rust-lang/rust/blob/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Fsip128.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Fsip128.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fsip128.rs?ref=f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "patch": "@@ -96,28 +96,30 @@ macro_rules! compress {\n unsafe fn copy_nonoverlapping_small(src: *const u8, dst: *mut u8, count: usize) {\n     debug_assert!(count <= 8);\n \n-    if count == 8 {\n-        ptr::copy_nonoverlapping(src, dst, 8);\n-        return;\n-    }\n+    unsafe {\n+        if count == 8 {\n+            ptr::copy_nonoverlapping(src, dst, 8);\n+            return;\n+        }\n \n-    let mut i = 0;\n-    if i + 3 < count {\n-        ptr::copy_nonoverlapping(src.add(i), dst.add(i), 4);\n-        i += 4;\n-    }\n+        let mut i = 0;\n+        if i + 3 < count {\n+            ptr::copy_nonoverlapping(src.add(i), dst.add(i), 4);\n+            i += 4;\n+        }\n \n-    if i + 1 < count {\n-        ptr::copy_nonoverlapping(src.add(i), dst.add(i), 2);\n-        i += 2\n-    }\n+        if i + 1 < count {\n+            ptr::copy_nonoverlapping(src.add(i), dst.add(i), 2);\n+            i += 2\n+        }\n \n-    if i < count {\n-        *dst.add(i) = *src.add(i);\n-        i += 1;\n-    }\n+        if i < count {\n+            *dst.add(i) = *src.add(i);\n+            i += 1;\n+        }\n \n-    debug_assert_eq!(i, count);\n+        debug_assert_eq!(i, count);\n+    }\n }\n \n // # Implementation\n@@ -232,38 +234,40 @@ impl SipHasher128 {\n     // overflow) if it wasn't already.\n     #[inline(never)]\n     unsafe fn short_write_process_buffer<const LEN: usize>(&mut self, bytes: [u8; LEN]) {\n-        let nbuf = self.nbuf;\n-        debug_assert!(LEN <= 8);\n-        debug_assert!(nbuf < BUFFER_SIZE);\n-        debug_assert!(nbuf + LEN >= BUFFER_SIZE);\n-        debug_assert!(nbuf + LEN < BUFFER_WITH_SPILL_SIZE);\n+        unsafe {\n+            let nbuf = self.nbuf;\n+            debug_assert!(LEN <= 8);\n+            debug_assert!(nbuf < BUFFER_SIZE);\n+            debug_assert!(nbuf + LEN >= BUFFER_SIZE);\n+            debug_assert!(nbuf + LEN < BUFFER_WITH_SPILL_SIZE);\n+\n+            // Copy first part of input into end of buffer, possibly into spill\n+            // element. The memcpy call is optimized away because the size is known.\n+            let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n+            ptr::copy_nonoverlapping(bytes.as_ptr(), dst, LEN);\n+\n+            // Process buffer.\n+            for i in 0..BUFFER_CAPACITY {\n+                let elem = self.buf.get_unchecked(i).assume_init().to_le();\n+                self.state.v3 ^= elem;\n+                Sip13Rounds::c_rounds(&mut self.state);\n+                self.state.v0 ^= elem;\n+            }\n \n-        // Copy first part of input into end of buffer, possibly into spill\n-        // element. The memcpy call is optimized away because the size is known.\n-        let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n-        ptr::copy_nonoverlapping(bytes.as_ptr(), dst, LEN);\n-\n-        // Process buffer.\n-        for i in 0..BUFFER_CAPACITY {\n-            let elem = self.buf.get_unchecked(i).assume_init().to_le();\n-            self.state.v3 ^= elem;\n-            Sip13Rounds::c_rounds(&mut self.state);\n-            self.state.v0 ^= elem;\n+            // Copy remaining input into start of buffer by copying LEN - 1\n+            // elements from spill (at most LEN - 1 bytes could have overflowed\n+            // into the spill). The memcpy call is optimized away because the size\n+            // is known. And the whole copy is optimized away for LEN == 1.\n+            let dst = self.buf.as_mut_ptr() as *mut u8;\n+            let src = self.buf.get_unchecked(BUFFER_SPILL_INDEX) as *const _ as *const u8;\n+            ptr::copy_nonoverlapping(src, dst, LEN - 1);\n+\n+            // This function should only be called when the write fills the buffer.\n+            // Therefore, when LEN == 1, the new `self.nbuf` must be zero.\n+            // LEN is statically known, so the branch is optimized away.\n+            self.nbuf = if LEN == 1 { 0 } else { nbuf + LEN - BUFFER_SIZE };\n+            self.processed += BUFFER_SIZE;\n         }\n-\n-        // Copy remaining input into start of buffer by copying LEN - 1\n-        // elements from spill (at most LEN - 1 bytes could have overflowed\n-        // into the spill). The memcpy call is optimized away because the size\n-        // is known. And the whole copy is optimized away for LEN == 1.\n-        let dst = self.buf.as_mut_ptr() as *mut u8;\n-        let src = self.buf.get_unchecked(BUFFER_SPILL_INDEX) as *const _ as *const u8;\n-        ptr::copy_nonoverlapping(src, dst, LEN - 1);\n-\n-        // This function should only be called when the write fills the buffer.\n-        // Therefore, when LEN == 1, the new `self.nbuf` must be zero.\n-        // LEN is statically known, so the branch is optimized away.\n-        self.nbuf = if LEN == 1 { 0 } else { nbuf + LEN - BUFFER_SIZE };\n-        self.processed += BUFFER_SIZE;\n     }\n \n     // A write function for byte slices.\n@@ -301,57 +305,59 @@ impl SipHasher128 {\n     // containing the byte offset `self.nbuf`.\n     #[inline(never)]\n     unsafe fn slice_write_process_buffer(&mut self, msg: &[u8]) {\n-        let length = msg.len();\n-        let nbuf = self.nbuf;\n-        debug_assert!(nbuf < BUFFER_SIZE);\n-        debug_assert!(nbuf + length >= BUFFER_SIZE);\n-\n-        // Always copy first part of input into current element of buffer.\n-        // This function should only be called when the write fills the buffer,\n-        // so we know that there is enough input to fill the current element.\n-        let valid_in_elem = nbuf % ELEM_SIZE;\n-        let needed_in_elem = ELEM_SIZE - valid_in_elem;\n-\n-        let src = msg.as_ptr();\n-        let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n-        copy_nonoverlapping_small(src, dst, needed_in_elem);\n-\n-        // Process buffer.\n+        unsafe {\n+            let length = msg.len();\n+            let nbuf = self.nbuf;\n+            debug_assert!(nbuf < BUFFER_SIZE);\n+            debug_assert!(nbuf + length >= BUFFER_SIZE);\n+\n+            // Always copy first part of input into current element of buffer.\n+            // This function should only be called when the write fills the buffer,\n+            // so we know that there is enough input to fill the current element.\n+            let valid_in_elem = nbuf % ELEM_SIZE;\n+            let needed_in_elem = ELEM_SIZE - valid_in_elem;\n+\n+            let src = msg.as_ptr();\n+            let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n+            copy_nonoverlapping_small(src, dst, needed_in_elem);\n+\n+            // Process buffer.\n+\n+            // Using `nbuf / ELEM_SIZE + 1` rather than `(nbuf + needed_in_elem) /\n+            // ELEM_SIZE` to show the compiler that this loop's upper bound is > 0.\n+            // We know that is true, because last step ensured we have a full\n+            // element in the buffer.\n+            let last = nbuf / ELEM_SIZE + 1;\n+\n+            for i in 0..last {\n+                let elem = self.buf.get_unchecked(i).assume_init().to_le();\n+                self.state.v3 ^= elem;\n+                Sip13Rounds::c_rounds(&mut self.state);\n+                self.state.v0 ^= elem;\n+            }\n \n-        // Using `nbuf / ELEM_SIZE + 1` rather than `(nbuf + needed_in_elem) /\n-        // ELEM_SIZE` to show the compiler that this loop's upper bound is > 0.\n-        // We know that is true, because last step ensured we have a full\n-        // element in the buffer.\n-        let last = nbuf / ELEM_SIZE + 1;\n+            // Process the remaining element-sized chunks of input.\n+            let mut processed = needed_in_elem;\n+            let input_left = length - processed;\n+            let elems_left = input_left / ELEM_SIZE;\n+            let extra_bytes_left = input_left % ELEM_SIZE;\n+\n+            for _ in 0..elems_left {\n+                let elem = (msg.as_ptr().add(processed) as *const u64).read_unaligned().to_le();\n+                self.state.v3 ^= elem;\n+                Sip13Rounds::c_rounds(&mut self.state);\n+                self.state.v0 ^= elem;\n+                processed += ELEM_SIZE;\n+            }\n \n-        for i in 0..last {\n-            let elem = self.buf.get_unchecked(i).assume_init().to_le();\n-            self.state.v3 ^= elem;\n-            Sip13Rounds::c_rounds(&mut self.state);\n-            self.state.v0 ^= elem;\n-        }\n+            // Copy remaining input into start of buffer.\n+            let src = msg.as_ptr().add(processed);\n+            let dst = self.buf.as_mut_ptr() as *mut u8;\n+            copy_nonoverlapping_small(src, dst, extra_bytes_left);\n \n-        // Process the remaining element-sized chunks of input.\n-        let mut processed = needed_in_elem;\n-        let input_left = length - processed;\n-        let elems_left = input_left / ELEM_SIZE;\n-        let extra_bytes_left = input_left % ELEM_SIZE;\n-\n-        for _ in 0..elems_left {\n-            let elem = (msg.as_ptr().add(processed) as *const u64).read_unaligned().to_le();\n-            self.state.v3 ^= elem;\n-            Sip13Rounds::c_rounds(&mut self.state);\n-            self.state.v0 ^= elem;\n-            processed += ELEM_SIZE;\n+            self.nbuf = extra_bytes_left;\n+            self.processed += nbuf + processed;\n         }\n-\n-        // Copy remaining input into start of buffer.\n-        let src = msg.as_ptr().add(processed);\n-        let dst = self.buf.as_mut_ptr() as *mut u8;\n-        copy_nonoverlapping_small(src, dst, extra_bytes_left);\n-\n-        self.nbuf = extra_bytes_left;\n-        self.processed += nbuf + processed;\n     }\n \n     #[inline]"}, {"sha": "8568aac67c08c719631c85be87f2586397c2911c", "filename": "compiler/rustc_data_structures/src/tagged_ptr.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Ftagged_ptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f79df7d2a4e224aa35697e5096d0f25fdcf26b2f/compiler%2Frustc_data_structures%2Fsrc%2Ftagged_ptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Ftagged_ptr.rs?ref=f79df7d2a4e224aa35697e5096d0f25fdcf26b2f", "patch": "@@ -153,7 +153,7 @@ unsafe impl<T: ?Sized + Aligned> Pointer for Box<T> {\n     #[inline]\n     unsafe fn from_ptr(ptr: NonNull<T>) -> Self {\n         // Safety: `ptr` comes from `into_ptr` which calls `Box::into_raw`\n-        Box::from_raw(ptr.as_ptr())\n+        unsafe { Box::from_raw(ptr.as_ptr()) }\n     }\n }\n \n@@ -169,7 +169,7 @@ unsafe impl<T: ?Sized + Aligned> Pointer for Rc<T> {\n     #[inline]\n     unsafe fn from_ptr(ptr: NonNull<T>) -> Self {\n         // Safety: `ptr` comes from `into_ptr` which calls `Rc::into_raw`\n-        Rc::from_raw(ptr.as_ptr())\n+        unsafe { Rc::from_raw(ptr.as_ptr()) }\n     }\n }\n \n@@ -185,7 +185,7 @@ unsafe impl<T: ?Sized + Aligned> Pointer for Arc<T> {\n     #[inline]\n     unsafe fn from_ptr(ptr: NonNull<T>) -> Self {\n         // Safety: `ptr` comes from `into_ptr` which calls `Arc::into_raw`\n-        Arc::from_raw(ptr.as_ptr())\n+        unsafe { Arc::from_raw(ptr.as_ptr()) }\n     }\n }\n \n@@ -201,7 +201,7 @@ unsafe impl<'a, T: 'a + ?Sized + Aligned> Pointer for &'a T {\n     unsafe fn from_ptr(ptr: NonNull<T>) -> Self {\n         // Safety:\n         // `ptr` comes from `into_ptr` which gets the pointer from a reference\n-        ptr.as_ref()\n+        unsafe { ptr.as_ref() }\n     }\n }\n \n@@ -217,7 +217,7 @@ unsafe impl<'a, T: 'a + ?Sized + Aligned> Pointer for &'a mut T {\n     unsafe fn from_ptr(mut ptr: NonNull<T>) -> Self {\n         // Safety:\n         // `ptr` comes from `into_ptr` which gets the pointer from a reference\n-        ptr.as_mut()\n+        unsafe { ptr.as_mut() }\n     }\n }\n "}]}