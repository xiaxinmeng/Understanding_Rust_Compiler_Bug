{"sha": "92d49cf6c5dec016fc1262e4436c62dc199f2b9d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjkyZDQ5Y2Y2YzVkZWMwMTZmYzEyNjJlNDQzNmM2MmRjMTk5ZjJiOWQ=", "commit": {"author": {"name": "Carol (Nichols || Goulding)", "email": "carol.nichols@gmail.com", "date": "2015-05-03T21:41:23Z"}, "committer": {"name": "Carol Nichols", "email": "carol.nichols@gmail.com", "date": "2015-05-03T21:45:37Z"}, "message": "Remove unused extract_grammar.py\n\nThis script used to be used to extract the grammar sections from the\nreference, but there is now a separate src/doc/grammar.md where the\ngrammar sections that used to be in the reference live, so there is\nno longer a need to extract the grammar from the reference.", "tree": {"sha": "07a475746c26d2caa83f0b68c0a76658f5bb8c3a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/07a475746c26d2caa83f0b68c0a76658f5bb8c3a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/92d49cf6c5dec016fc1262e4436c62dc199f2b9d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/92d49cf6c5dec016fc1262e4436c62dc199f2b9d", "html_url": "https://github.com/rust-lang/rust/commit/92d49cf6c5dec016fc1262e4436c62dc199f2b9d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/92d49cf6c5dec016fc1262e4436c62dc199f2b9d/comments", "author": {"login": "carols10cents", "id": 193874, "node_id": "MDQ6VXNlcjE5Mzg3NA==", "avatar_url": "https://avatars.githubusercontent.com/u/193874?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carols10cents", "html_url": "https://github.com/carols10cents", "followers_url": "https://api.github.com/users/carols10cents/followers", "following_url": "https://api.github.com/users/carols10cents/following{/other_user}", "gists_url": "https://api.github.com/users/carols10cents/gists{/gist_id}", "starred_url": "https://api.github.com/users/carols10cents/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carols10cents/subscriptions", "organizations_url": "https://api.github.com/users/carols10cents/orgs", "repos_url": "https://api.github.com/users/carols10cents/repos", "events_url": "https://api.github.com/users/carols10cents/events{/privacy}", "received_events_url": "https://api.github.com/users/carols10cents/received_events", "type": "User", "site_admin": false}, "committer": {"login": "carols10cents", "id": 193874, "node_id": "MDQ6VXNlcjE5Mzg3NA==", "avatar_url": "https://avatars.githubusercontent.com/u/193874?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carols10cents", "html_url": "https://github.com/carols10cents", "followers_url": "https://api.github.com/users/carols10cents/followers", "following_url": "https://api.github.com/users/carols10cents/following{/other_user}", "gists_url": "https://api.github.com/users/carols10cents/gists{/gist_id}", "starred_url": "https://api.github.com/users/carols10cents/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carols10cents/subscriptions", "organizations_url": "https://api.github.com/users/carols10cents/orgs", "repos_url": "https://api.github.com/users/carols10cents/repos", "events_url": "https://api.github.com/users/carols10cents/events{/privacy}", "received_events_url": "https://api.github.com/users/carols10cents/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1a60dc4fc4b66760b71f1700cdb8b151cb8a67d9", "url": "https://api.github.com/repos/rust-lang/rust/commits/1a60dc4fc4b66760b71f1700cdb8b151cb8a67d9", "html_url": "https://github.com/rust-lang/rust/commit/1a60dc4fc4b66760b71f1700cdb8b151cb8a67d9"}], "stats": {"total": 156, "additions": 0, "deletions": 156}, "files": [{"sha": "a12c3298cb35b93b057ed019f97ea208d4665f9d", "filename": "src/etc/extract_grammar.py", "status": "removed", "additions": 0, "deletions": 156, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/1a60dc4fc4b66760b71f1700cdb8b151cb8a67d9/src%2Fetc%2Fextract_grammar.py", "raw_url": "https://github.com/rust-lang/rust/raw/1a60dc4fc4b66760b71f1700cdb8b151cb8a67d9/src%2Fetc%2Fextract_grammar.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fextract_grammar.py?ref=1a60dc4fc4b66760b71f1700cdb8b151cb8a67d9", "patch": "@@ -1,156 +0,0 @@\n-#!/usr/bin/env python\n-#\n-# Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n-# file at the top-level directory of this distribution and at\n-# http://rust-lang.org/COPYRIGHT.\n-#\n-# Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-# http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-# <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-# option. This file may not be copied, modified, or distributed\n-# except according to those terms.\n-\n-# This script is for extracting the grammar from the rust docs.\n-\n-import fileinput\n-\n-collections = {\"gram\": [],\n-               \"keyword\": [],\n-               \"reserved\": [],\n-               \"binop\": [],\n-               \"unop\": []}\n-\n-\n-in_coll = False\n-coll = \"\"\n-\n-for line in fileinput.input(openhook=fileinput.hook_encoded(\"utf-8\")):\n-    if in_coll:\n-        if line.startswith(\"~~~~\"):\n-            in_coll = False\n-        else:\n-            if coll in [\"keyword\", \"reserved\", \"binop\", \"unop\"]:\n-                for word in line.split():\n-                    if word not in collections[coll]:\n-                        collections[coll].append(word)\n-            else:\n-                collections[coll].append(line)\n-\n-    else:\n-        if line.startswith(\"~~~~\"):\n-            for cname in collections:\n-                if (\".\" + cname) in line:\n-                    coll = cname\n-                    in_coll = True\n-                    break\n-\n-# Define operator symbol-names here\n-\n-tokens = [\"non_star\", \"non_slash\", \"non_eol\",\n-          \"non_single_quote\", \"non_double_quote\", \"ident\"]\n-\n-symnames = {\n-    \".\": \"dot\",\n-    \"+\": \"plus\",\n-    \"-\": \"minus\",\n-    \"/\": \"slash\",\n-    \"*\": \"star\",\n-    \"%\": \"percent\",\n-\n-    \"~\": \"tilde\",\n-    \"@\": \"at\",\n-\n-    \"!\": \"not\",\n-    \"&\": \"and\",\n-    \"|\": \"or\",\n-    \"^\": \"xor\",\n-\n-    \"<<\": \"lsl\",\n-    \">>\": \"lsr\",\n-    \">>>\": \"asr\",\n-\n-    \"&&\": \"andand\",\n-    \"||\": \"oror\",\n-\n-    \"<\": \"lt\",\n-    \"<=\": \"le\",\n-    \"==\": \"eqeq\",\n-    \">=\": \"ge\",\n-    \">\": \"gt\",\n-\n-    \"=\": \"eq\",\n-\n-    \"+=\": \"plusequal\",\n-    \"-=\": \"minusequal\",\n-    \"/=\": \"divequal\",\n-    \"*=\": \"starequal\",\n-    \"%=\": \"percentequal\",\n-\n-    \"&=\": \"andequal\",\n-    \"|=\": \"orequal\",\n-    \"^=\": \"xorequal\",\n-\n-    \">>=\": \"lsrequal\",\n-    \">>>=\": \"asrequal\",\n-    \"<<=\": \"lslequal\",\n-\n-    \"::\": \"coloncolon\",\n-\n-    \"->\": \"rightarrow\",\n-    \"<-\": \"leftarrow\",\n-    \"<->\": \"swaparrow\",\n-\n-    \"//\": \"linecomment\",\n-    \"/*\": \"openblockcomment\",\n-    \"*/\": \"closeblockcomment\",\n-    \"macro_rules\": \"macro_rules\",\n-    \"=>\": \"eg\",\n-    \"..\": \"dotdot\",\n-    \",\": \"comma\"\n-}\n-\n-lines = []\n-\n-for line in collections[\"gram\"]:\n-    line2 = \"\"\n-    for word in line.split():\n-        # replace strings with keyword-names or symbol-names from table\n-        if word.startswith(\"\\\"\"):\n-            word = word[1:-1]\n-            if word in symnames:\n-                word = symnames[word]\n-            else:\n-                for ch in word:\n-                    if not ch.isalpha():\n-                        raise Exception(\"non-alpha apparent keyword: \"\n-                                        + word)\n-                if word not in tokens:\n-                    if (word in collections[\"keyword\"] or\n-                            word in collections[\"reserved\"]):\n-                        tokens.append(word)\n-                    else:\n-                        raise Exception(\"unknown keyword/reserved word: \"\n-                                        + word)\n-\n-        line2 += \" \" + word\n-    lines.append(line2)\n-\n-\n-for word in collections[\"keyword\"] + collections[\"reserved\"]:\n-    if word not in tokens:\n-        tokens.append(word)\n-\n-for sym in collections[\"unop\"] + collections[\"binop\"] + symnames.keys():\n-    word = symnames[sym]\n-    if word not in tokens:\n-        tokens.append(word)\n-\n-\n-print(\"%start parser, token;\")\n-print(\"%%token %s ;\" % (\"\\n\\t, \".join(tokens)))\n-for coll in [\"keyword\", \"reserved\"]:\n-    print(\"%s: %s ; \" % (coll, \"\\n\\t| \".join(collections[coll])))\n-for coll in [\"binop\", \"unop\"]:\n-    print(\"%s: %s ; \" % (coll, \"\\n\\t| \".join([symnames[x]\n-                                              for x in collections[coll]])))\n-print(\"\\n\".join(lines))"}]}