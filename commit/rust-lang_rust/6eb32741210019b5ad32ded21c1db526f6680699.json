{"sha": "6eb32741210019b5ad32ded21c1db526f6680699", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZlYjMyNzQxMjEwMDE5YjVhZDMyZGVkMjFjMWRiNTI2ZjY2ODA2OTk=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2018-12-11T14:21:43Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2018-12-11T14:21:43Z"}, "message": "Merge pull request #568 from RalfJung/cleanup\n\nCleanup: Avoid repeating signatures, get rid of to_bytes hack", "tree": {"sha": "d1e2e64aae83d83e8fcf819406d15c689d5ccf19", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d1e2e64aae83d83e8fcf819406d15c689d5ccf19"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6eb32741210019b5ad32ded21c1db526f6680699", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJcD8f3CRBK7hj4Ov3rIwAAdHIIAGS981C/SyWoQxD4Q6naU0g5\nY8yZcrPuVqdO4CFBx8EMA4s+zh7IQ+x5F/XcuzNvj3Q9/b5rXzXs19N+VXWSGg/F\nvLYpcJPWVuglug18vU17QffCURdKqSrA77pefKqjOfwKa0upzp43roEYHJxxFOh+\nC/92WJVEXf6Iz2G+heHI84Boh33D2dIrrsrr+FDIKIX7A+XTc4SYwenflFlCZUW+\nCLySzaWqUvkKxU7cUwD5jJC/ZNadYOv03sGhj/2i7y3biTMtt6NK4+oO258KVhDF\nf/jNLNg1jxa6gNXwLt8+0JMRt5FLnZzyxp3xcz6MUm/SHSRk3XtQoBtAy1WmJnM=\n=GanA\n-----END PGP SIGNATURE-----\n", "payload": "tree d1e2e64aae83d83e8fcf819406d15c689d5ccf19\nparent 4f61314fc5ed33b822384f52103214965482e77c\nparent 6b376dc3940513b5f7414333a42ce28b47268965\nauthor Ralf Jung <post@ralfj.de> 1544538103 +0100\ncommitter GitHub <noreply@github.com> 1544538103 +0100\n\nMerge pull request #568 from RalfJung/cleanup\n\nCleanup: Avoid repeating signatures, get rid of to_bytes hack"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6eb32741210019b5ad32ded21c1db526f6680699", "html_url": "https://github.com/rust-lang/rust/commit/6eb32741210019b5ad32ded21c1db526f6680699", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6eb32741210019b5ad32ded21c1db526f6680699/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4f61314fc5ed33b822384f52103214965482e77c", "url": "https://api.github.com/repos/rust-lang/rust/commits/4f61314fc5ed33b822384f52103214965482e77c", "html_url": "https://github.com/rust-lang/rust/commit/4f61314fc5ed33b822384f52103214965482e77c"}, {"sha": "6b376dc3940513b5f7414333a42ce28b47268965", "url": "https://api.github.com/repos/rust-lang/rust/commits/6b376dc3940513b5f7414333a42ce28b47268965", "html_url": "https://github.com/rust-lang/rust/commit/6b376dc3940513b5f7414333a42ce28b47268965"}], "stats": {"total": 886, "additions": 402, "deletions": 484}, "files": [{"sha": "5d41848b643e76327f22800ab248c19f0f41917d", "filename": "src/fn_call.rs", "status": "modified", "additions": 160, "deletions": 177, "changes": 337, "blob_url": "https://github.com/rust-lang/rust/blob/6eb32741210019b5ad32ded21c1db526f6680699/src%2Ffn_call.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6eb32741210019b5ad32ded21c1db526f6680699/src%2Ffn_call.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ffn_call.rs?ref=6eb32741210019b5ad32ded21c1db526f6680699", "patch": "@@ -6,60 +6,40 @@ use syntax::attr;\n \n use crate::*;\n \n-pub trait EvalContextExt<'tcx, 'mir> {\n-    /// Emulate calling a foreign item, fail if the item is not supported.\n-    /// This function will handle `goto_block` if needed.\n-    fn emulate_foreign_item(\n-        &mut self,\n-        def_id: DefId,\n-        args: &[OpTy<'tcx, Borrow>],\n-        dest: PlaceTy<'tcx, Borrow>,\n-        ret: mir::BasicBlock,\n-    ) -> EvalResult<'tcx>;\n-\n-    fn find_fn(\n-        &mut self,\n-        instance: ty::Instance<'tcx>,\n-        args: &[OpTy<'tcx, Borrow>],\n-        dest: Option<PlaceTy<'tcx, Borrow>>,\n-        ret: Option<mir::BasicBlock>,\n-    ) -> EvalResult<'tcx, Option<&'mir mir::Mir<'tcx>>>;\n-\n-    fn write_null(&mut self, dest: PlaceTy<'tcx, Borrow>) -> EvalResult<'tcx>;\n-}\n-\n-impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalContext<'a, 'mir, 'tcx> {\n+impl<'a, 'mir, 'tcx> EvalContextExt<'a, 'mir, 'tcx> for crate::MiriEvalContext<'a, 'mir, 'tcx> {}\n+pub trait EvalContextExt<'a, 'mir, 'tcx: 'a+'mir>: crate::MiriEvalContextExt<'a, 'mir, 'tcx> {\n     fn find_fn(\n         &mut self,\n         instance: ty::Instance<'tcx>,\n         args: &[OpTy<'tcx, Borrow>],\n         dest: Option<PlaceTy<'tcx, Borrow>>,\n         ret: Option<mir::BasicBlock>,\n     ) -> EvalResult<'tcx, Option<&'mir mir::Mir<'tcx>>> {\n+        let this = self.eval_context_mut();\n         trace!(\"eval_fn_call: {:#?}, {:?}\", instance, dest.map(|place| *place));\n \n         // first run the common hooks also supported by CTFE\n-        if self.hook_fn(instance, args, dest)? {\n-            self.goto_block(ret)?;\n+        if this.hook_fn(instance, args, dest)? {\n+            this.goto_block(ret)?;\n             return Ok(None);\n         }\n         // there are some more lang items we want to hook that CTFE does not hook (yet)\n-        if self.tcx.lang_items().align_offset_fn() == Some(instance.def.def_id()) {\n+        if this.tcx.lang_items().align_offset_fn() == Some(instance.def.def_id()) {\n             // FIXME: return a real value in case the target allocation has an\n             // alignment bigger than the one requested\n             let n = u128::max_value();\n             let dest = dest.unwrap();\n-            let n = self.truncate(n, dest.layout);\n-            self.write_scalar(Scalar::from_uint(n, dest.layout.size), dest)?;\n-            self.goto_block(ret)?;\n+            let n = this.truncate(n, dest.layout);\n+            this.write_scalar(Scalar::from_uint(n, dest.layout.size), dest)?;\n+            this.goto_block(ret)?;\n             return Ok(None);\n         }\n \n         // Try to see if we can do something about foreign items\n-        if self.tcx.is_foreign_item(instance.def_id()) {\n+        if this.tcx.is_foreign_item(instance.def_id()) {\n             // An external function that we cannot find MIR for, but we can still run enough\n             // of them to make miri viable.\n-            self.emulate_foreign_item(\n+            this.emulate_foreign_item(\n                 instance.def_id(),\n                 args,\n                 dest.unwrap(),\n@@ -70,46 +50,49 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n         }\n \n         // Otherwise, load the MIR\n-        Ok(Some(self.load_mir(instance.def)?))\n+        Ok(Some(this.load_mir(instance.def)?))\n     }\n \n+    /// Emulate calling a foreign item, fail if the item is not supported.\n+    /// This function will handle `goto_block` if needed.\n     fn emulate_foreign_item(\n         &mut self,\n         def_id: DefId,\n         args: &[OpTy<'tcx, Borrow>],\n         dest: PlaceTy<'tcx, Borrow>,\n         ret: mir::BasicBlock,\n     ) -> EvalResult<'tcx> {\n-        let attrs = self.tcx.get_attrs(def_id);\n+        let this = self.eval_context_mut();\n+        let attrs = this.tcx.get_attrs(def_id);\n         let link_name = match attr::first_attr_value_str_by_name(&attrs, \"link_name\") {\n             Some(name) => name.as_str(),\n-            None => self.tcx.item_name(def_id).as_str(),\n+            None => this.tcx.item_name(def_id).as_str(),\n         };\n         // Strip linker suffixes (seen on 32bit macOS)\n         let link_name = link_name.trim_end_matches(\"$UNIX2003\");\n \n-        let tcx = &{self.tcx.tcx};\n+        let tcx = &{this.tcx.tcx};\n \n         // All these functions take raw pointers, so if we access memory directly\n         // (as opposed to through a place), we have to remember to erase any tag\n         // that might still hang around!\n \n         match &link_name[..] {\n             \"malloc\" => {\n-                let size = self.read_scalar(args[0])?.to_usize(self)?;\n+                let size = this.read_scalar(args[0])?.to_usize(this)?;\n                 if size == 0 {\n-                    self.write_null(dest)?;\n+                    this.write_null(dest)?;\n                 } else {\n-                    let align = self.tcx.data_layout.pointer_align.abi;\n-                    let ptr = self.memory_mut().allocate(Size::from_bytes(size), align, MiriMemoryKind::C.into())?;\n-                    self.write_scalar(Scalar::Ptr(ptr.with_default_tag()), dest)?;\n+                    let align = this.tcx.data_layout.pointer_align.abi;\n+                    let ptr = this.memory_mut().allocate(Size::from_bytes(size), align, MiriMemoryKind::C.into())?;\n+                    this.write_scalar(Scalar::Ptr(ptr.with_default_tag()), dest)?;\n                 }\n             }\n \n             \"free\" => {\n-                let ptr = self.read_scalar(args[0])?.not_undef()?;\n-                if !ptr.is_null_ptr(self) {\n-                    self.memory_mut().deallocate(\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                if !ptr.is_null_ptr(this) {\n+                    this.memory_mut().deallocate(\n                         ptr.to_ptr()?,\n                         None,\n                         MiriMemoryKind::C.into(),\n@@ -118,80 +101,80 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             }\n \n             \"__rust_alloc\" => {\n-                let size = self.read_scalar(args[0])?.to_usize(self)?;\n-                let align = self.read_scalar(args[1])?.to_usize(self)?;\n+                let size = this.read_scalar(args[0])?.to_usize(this)?;\n+                let align = this.read_scalar(args[1])?.to_usize(this)?;\n                 if size == 0 {\n                     return err!(HeapAllocZeroBytes);\n                 }\n                 if !align.is_power_of_two() {\n                     return err!(HeapAllocNonPowerOfTwoAlignment(align));\n                 }\n-                let ptr = self.memory_mut()\n+                let ptr = this.memory_mut()\n                     .allocate(\n                         Size::from_bytes(size),\n                         Align::from_bytes(align).unwrap(),\n                         MiriMemoryKind::Rust.into()\n                     )?\n                     .with_default_tag();\n-                self.write_scalar(Scalar::Ptr(ptr), dest)?;\n+                this.write_scalar(Scalar::Ptr(ptr), dest)?;\n             }\n             \"__rust_alloc_zeroed\" => {\n-                let size = self.read_scalar(args[0])?.to_usize(self)?;\n-                let align = self.read_scalar(args[1])?.to_usize(self)?;\n+                let size = this.read_scalar(args[0])?.to_usize(this)?;\n+                let align = this.read_scalar(args[1])?.to_usize(this)?;\n                 if size == 0 {\n                     return err!(HeapAllocZeroBytes);\n                 }\n                 if !align.is_power_of_two() {\n                     return err!(HeapAllocNonPowerOfTwoAlignment(align));\n                 }\n-                let ptr = self.memory_mut()\n+                let ptr = this.memory_mut()\n                     .allocate(\n                         Size::from_bytes(size),\n                         Align::from_bytes(align).unwrap(),\n                         MiriMemoryKind::Rust.into()\n                     )?\n                     .with_default_tag();\n-                self.memory_mut()\n+                this.memory_mut()\n                     .get_mut(ptr.alloc_id)?\n                     .write_repeat(tcx, ptr, 0, Size::from_bytes(size))?;\n-                self.write_scalar(Scalar::Ptr(ptr), dest)?;\n+                this.write_scalar(Scalar::Ptr(ptr), dest)?;\n             }\n             \"__rust_dealloc\" => {\n-                let ptr = self.read_scalar(args[0])?.to_ptr()?;\n-                let old_size = self.read_scalar(args[1])?.to_usize(self)?;\n-                let align = self.read_scalar(args[2])?.to_usize(self)?;\n+                let ptr = this.read_scalar(args[0])?.to_ptr()?;\n+                let old_size = this.read_scalar(args[1])?.to_usize(this)?;\n+                let align = this.read_scalar(args[2])?.to_usize(this)?;\n                 if old_size == 0 {\n                     return err!(HeapAllocZeroBytes);\n                 }\n                 if !align.is_power_of_two() {\n                     return err!(HeapAllocNonPowerOfTwoAlignment(align));\n                 }\n-                self.memory_mut().deallocate(\n+                this.memory_mut().deallocate(\n                     ptr,\n                     Some((Size::from_bytes(old_size), Align::from_bytes(align).unwrap())),\n                     MiriMemoryKind::Rust.into(),\n                 )?;\n             }\n             \"__rust_realloc\" => {\n-                let ptr = self.read_scalar(args[0])?.to_ptr()?;\n-                let old_size = self.read_scalar(args[1])?.to_usize(self)?;\n-                let align = self.read_scalar(args[2])?.to_usize(self)?;\n-                let new_size = self.read_scalar(args[3])?.to_usize(self)?;\n+                let ptr = this.read_scalar(args[0])?.to_ptr()?;\n+                let old_size = this.read_scalar(args[1])?.to_usize(this)?;\n+                let align = this.read_scalar(args[2])?.to_usize(this)?;\n+                let new_size = this.read_scalar(args[3])?.to_usize(this)?;\n                 if old_size == 0 || new_size == 0 {\n                     return err!(HeapAllocZeroBytes);\n                 }\n                 if !align.is_power_of_two() {\n                     return err!(HeapAllocNonPowerOfTwoAlignment(align));\n                 }\n-                let new_ptr = self.memory_mut().reallocate(\n+                let new_ptr = this.memory_mut().reallocate(\n                     ptr,\n                     Size::from_bytes(old_size),\n                     Align::from_bytes(align).unwrap(),\n                     Size::from_bytes(new_size),\n                     Align::from_bytes(align).unwrap(),\n                     MiriMemoryKind::Rust.into(),\n                 )?;\n-                self.write_scalar(Scalar::Ptr(new_ptr.with_default_tag()), dest)?;\n+                this.write_scalar(Scalar::Ptr(new_ptr.with_default_tag()), dest)?;\n             }\n \n             \"syscall\" => {\n@@ -200,7 +183,7 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                 //\n                 // libc::syscall(NR_GETRANDOM, buf.as_mut_ptr(), buf.len(), GRND_NONBLOCK)\n                 // is called if a `HashMap` is created the regular way.\n-                match self.read_scalar(args[0])?.to_usize(self)? {\n+                match this.read_scalar(args[0])?.to_usize(this)? {\n                     318 | 511 => {\n                         return err!(Unimplemented(\n                             \"miri does not support random number generators\".to_owned(),\n@@ -215,9 +198,9 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             }\n \n             \"dlsym\" => {\n-                let _handle = self.read_scalar(args[0])?;\n-                let symbol = self.read_scalar(args[1])?.to_ptr()?;\n-                let symbol_name = self.memory().get(symbol.alloc_id)?.read_c_str(tcx, symbol)?;\n+                let _handle = this.read_scalar(args[0])?;\n+                let symbol = this.read_scalar(args[1])?.to_ptr()?;\n+                let symbol_name = this.memory().get(symbol.alloc_id)?.read_c_str(tcx, symbol)?;\n                 let err = format!(\"bad c unicode symbol: {:?}\", symbol_name);\n                 let symbol_name = ::std::str::from_utf8(symbol_name).unwrap_or(&err);\n                 return err!(Unimplemented(format!(\n@@ -229,38 +212,38 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             \"__rust_maybe_catch_panic\" => {\n                 // fn __rust_maybe_catch_panic(f: fn(*mut u8), data: *mut u8, data_ptr: *mut usize, vtable_ptr: *mut usize) -> u32\n                 // We abort on panic, so not much is going on here, but we still have to call the closure\n-                let f = self.read_scalar(args[0])?.to_ptr()?;\n-                let data = self.read_scalar(args[1])?.not_undef()?;\n-                let f_instance = self.memory().get_fn(f)?;\n-                self.write_null(dest)?;\n+                let f = this.read_scalar(args[0])?.to_ptr()?;\n+                let data = this.read_scalar(args[1])?.not_undef()?;\n+                let f_instance = this.memory().get_fn(f)?;\n+                this.write_null(dest)?;\n                 trace!(\"__rust_maybe_catch_panic: {:?}\", f_instance);\n \n                 // Now we make a function call.  TODO: Consider making this re-usable?  EvalContext::step does sth. similar for the TLS dtors,\n                 // and of course eval_main.\n-                let mir = self.load_mir(f_instance.def)?;\n-                let ret_place = MPlaceTy::dangling(self.layout_of(self.tcx.mk_unit())?, self).into();\n-                self.push_stack_frame(\n+                let mir = this.load_mir(f_instance.def)?;\n+                let ret_place = MPlaceTy::dangling(this.layout_of(this.tcx.mk_unit())?, this).into();\n+                this.push_stack_frame(\n                     f_instance,\n                     mir.span,\n                     mir,\n                     Some(ret_place),\n                     StackPopCleanup::Goto(Some(ret)), // directly return to caller\n                 )?;\n-                let mut args = self.frame().mir.args_iter();\n+                let mut args = this.frame().mir.args_iter();\n \n                 let arg_local = args.next().ok_or_else(||\n                     EvalErrorKind::AbiViolation(\n                         \"Argument to __rust_maybe_catch_panic does not take enough arguments.\"\n                             .to_owned(),\n                     ),\n                 )?;\n-                let arg_dest = self.eval_place(&mir::Place::Local(arg_local))?;\n-                self.write_scalar(data, arg_dest)?;\n+                let arg_dest = this.eval_place(&mir::Place::Local(arg_local))?;\n+                this.write_scalar(data, arg_dest)?;\n \n                 assert!(args.next().is_none(), \"__rust_maybe_catch_panic argument has more arguments than expected\");\n \n                 // We ourselves will return 0, eventually (because we will not return if we paniced)\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n \n                 // Don't fall through, we do NOT want to `goto_block`!\n                 return Ok(());\n@@ -270,13 +253,13 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                 return err!(MachineError(\"the evaluated program panicked\".to_string())),\n \n             \"memcmp\" => {\n-                let left = self.read_scalar(args[0])?.not_undef()?;\n-                let right = self.read_scalar(args[1])?.not_undef()?;\n-                let n = Size::from_bytes(self.read_scalar(args[2])?.to_usize(self)?);\n+                let left = this.read_scalar(args[0])?.not_undef()?;\n+                let right = this.read_scalar(args[1])?.not_undef()?;\n+                let n = Size::from_bytes(this.read_scalar(args[2])?.to_usize(this)?);\n \n                 let result = {\n-                    let left_bytes = self.memory().read_bytes(left, n)?;\n-                    let right_bytes = self.memory().read_bytes(right, n)?;\n+                    let left_bytes = this.memory().read_bytes(left, n)?;\n+                    let right_bytes = this.memory().read_bytes(right, n)?;\n \n                     use std::cmp::Ordering::*;\n                     match left_bytes.cmp(right_bytes) {\n@@ -286,125 +269,125 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                     }\n                 };\n \n-                self.write_scalar(\n+                this.write_scalar(\n                     Scalar::from_int(result, Size::from_bits(32)),\n                     dest,\n                 )?;\n             }\n \n             \"memrchr\" => {\n-                let ptr = self.read_scalar(args[0])?.not_undef()?;\n-                let val = self.read_scalar(args[1])?.to_bytes()? as u8;\n-                let num = self.read_scalar(args[2])?.to_usize(self)?;\n-                if let Some(idx) = self.memory().read_bytes(ptr, Size::from_bytes(num))?\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                let val = this.read_scalar(args[1])?.to_i32()? as u8;\n+                let num = this.read_scalar(args[2])?.to_usize(this)?;\n+                if let Some(idx) = this.memory().read_bytes(ptr, Size::from_bytes(num))?\n                     .iter().rev().position(|&c| c == val)\n                 {\n-                    let new_ptr = ptr.ptr_offset(Size::from_bytes(num - idx as u64 - 1), self)?;\n-                    self.write_scalar(new_ptr, dest)?;\n+                    let new_ptr = ptr.ptr_offset(Size::from_bytes(num - idx as u64 - 1), this)?;\n+                    this.write_scalar(new_ptr, dest)?;\n                 } else {\n-                    self.write_null(dest)?;\n+                    this.write_null(dest)?;\n                 }\n             }\n \n             \"memchr\" => {\n-                let ptr = self.read_scalar(args[0])?.not_undef()?;\n-                let val = self.read_scalar(args[1])?.to_bytes()? as u8;\n-                let num = self.read_scalar(args[2])?.to_usize(self)?;\n-                if let Some(idx) = self.memory().read_bytes(ptr, Size::from_bytes(num))?.iter().position(\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                let val = this.read_scalar(args[1])?.to_i32()? as u8;\n+                let num = this.read_scalar(args[2])?.to_usize(this)?;\n+                if let Some(idx) = this.memory().read_bytes(ptr, Size::from_bytes(num))?.iter().position(\n                     |&c| c == val,\n                 )\n                 {\n-                    let new_ptr = ptr.ptr_offset(Size::from_bytes(idx as u64), self)?;\n-                    self.write_scalar(new_ptr, dest)?;\n+                    let new_ptr = ptr.ptr_offset(Size::from_bytes(idx as u64), this)?;\n+                    this.write_scalar(new_ptr, dest)?;\n                 } else {\n-                    self.write_null(dest)?;\n+                    this.write_null(dest)?;\n                 }\n             }\n \n             \"getenv\" => {\n                 let result = {\n-                    let name_ptr = self.read_scalar(args[0])?.to_ptr()?;\n-                    let name = self.memory().get(name_ptr.alloc_id)?.read_c_str(tcx, name_ptr)?;\n-                    match self.machine.env_vars.get(name) {\n+                    let name_ptr = this.read_scalar(args[0])?.to_ptr()?;\n+                    let name = this.memory().get(name_ptr.alloc_id)?.read_c_str(tcx, name_ptr)?;\n+                    match this.machine.env_vars.get(name) {\n                         Some(&var) => Scalar::Ptr(var),\n-                        None => Scalar::ptr_null(&*self.tcx),\n+                        None => Scalar::ptr_null(&*this.tcx),\n                     }\n                 };\n-                self.write_scalar(result, dest)?;\n+                this.write_scalar(result, dest)?;\n             }\n \n             \"unsetenv\" => {\n                 let mut success = None;\n                 {\n-                    let name_ptr = self.read_scalar(args[0])?.not_undef()?;\n-                    if !name_ptr.is_null_ptr(self) {\n+                    let name_ptr = this.read_scalar(args[0])?.not_undef()?;\n+                    if !name_ptr.is_null_ptr(this) {\n                         let name_ptr = name_ptr.to_ptr()?;\n-                        let name = self.memory().get(name_ptr.alloc_id)?.read_c_str(tcx, name_ptr)?.to_owned();\n+                        let name = this.memory().get(name_ptr.alloc_id)?.read_c_str(tcx, name_ptr)?.to_owned();\n                         if !name.is_empty() && !name.contains(&b'=') {\n-                            success = Some(self.machine.env_vars.remove(&name));\n+                            success = Some(this.machine.env_vars.remove(&name));\n                         }\n                     }\n                 }\n                 if let Some(old) = success {\n                     if let Some(var) = old {\n-                        self.memory_mut().deallocate(var, None, MiriMemoryKind::Env.into())?;\n+                        this.memory_mut().deallocate(var, None, MiriMemoryKind::Env.into())?;\n                     }\n-                    self.write_null(dest)?;\n+                    this.write_null(dest)?;\n                 } else {\n-                    self.write_scalar(Scalar::from_int(-1, dest.layout.size), dest)?;\n+                    this.write_scalar(Scalar::from_int(-1, dest.layout.size), dest)?;\n                 }\n             }\n \n             \"setenv\" => {\n                 let mut new = None;\n                 {\n-                    let name_ptr = self.read_scalar(args[0])?.not_undef()?;\n-                    let value_ptr = self.read_scalar(args[1])?.to_ptr()?;\n-                    let value = self.memory().get(value_ptr.alloc_id)?.read_c_str(tcx, value_ptr)?;\n-                    if !name_ptr.is_null_ptr(self) {\n+                    let name_ptr = this.read_scalar(args[0])?.not_undef()?;\n+                    let value_ptr = this.read_scalar(args[1])?.to_ptr()?;\n+                    let value = this.memory().get(value_ptr.alloc_id)?.read_c_str(tcx, value_ptr)?;\n+                    if !name_ptr.is_null_ptr(this) {\n                         let name_ptr = name_ptr.to_ptr()?;\n-                        let name = self.memory().get(name_ptr.alloc_id)?.read_c_str(tcx, name_ptr)?;\n+                        let name = this.memory().get(name_ptr.alloc_id)?.read_c_str(tcx, name_ptr)?;\n                         if !name.is_empty() && !name.contains(&b'=') {\n                             new = Some((name.to_owned(), value.to_owned()));\n                         }\n                     }\n                 }\n                 if let Some((name, value)) = new {\n                     // +1 for the null terminator\n-                    let value_copy = self.memory_mut().allocate(\n+                    let value_copy = this.memory_mut().allocate(\n                         Size::from_bytes((value.len() + 1) as u64),\n                         Align::from_bytes(1).unwrap(),\n                         MiriMemoryKind::Env.into(),\n                     )?.with_default_tag();\n                     {\n-                        let alloc = self.memory_mut().get_mut(value_copy.alloc_id)?;\n+                        let alloc = this.memory_mut().get_mut(value_copy.alloc_id)?;\n                         alloc.write_bytes(tcx, value_copy, &value)?;\n                         let trailing_zero_ptr = value_copy.offset(Size::from_bytes(value.len() as u64), tcx)?;\n                         alloc.write_bytes(tcx, trailing_zero_ptr, &[0])?;\n                     }\n-                    if let Some(var) = self.machine.env_vars.insert(\n+                    if let Some(var) = this.machine.env_vars.insert(\n                         name.to_owned(),\n                         value_copy,\n                     )\n                     {\n-                        self.memory_mut().deallocate(var, None, MiriMemoryKind::Env.into())?;\n+                        this.memory_mut().deallocate(var, None, MiriMemoryKind::Env.into())?;\n                     }\n-                    self.write_null(dest)?;\n+                    this.write_null(dest)?;\n                 } else {\n-                    self.write_scalar(Scalar::from_int(-1, dest.layout.size), dest)?;\n+                    this.write_scalar(Scalar::from_int(-1, dest.layout.size), dest)?;\n                 }\n             }\n \n             \"write\" => {\n-                let fd = self.read_scalar(args[0])?.to_bytes()?;\n-                let buf = self.read_scalar(args[1])?.not_undef()?;\n-                let n = self.read_scalar(args[2])?.to_bytes()? as u64;\n+                let fd = this.read_scalar(args[0])?.to_i32()?;\n+                let buf = this.read_scalar(args[1])?.not_undef()?;\n+                let n = this.read_scalar(args[2])?.to_usize(&*this.tcx)?;\n                 trace!(\"Called write({:?}, {:?}, {:?})\", fd, buf, n);\n                 let result = if fd == 1 || fd == 2 {\n                     // stdout/stderr\n                     use std::io::{self, Write};\n \n-                    let buf_cont = self.memory().read_bytes(buf, Size::from_bytes(n))?;\n+                    let buf_cont = this.memory().read_bytes(buf, Size::from_bytes(n))?;\n                     let res = if fd == 1 {\n                         io::stdout().write(buf_cont)\n                     } else {\n@@ -418,25 +401,25 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                     warn!(\"Ignored output to FD {}\", fd);\n                     n as i64 // pretend it all went well\n                 }; // now result is the value we return back to the program\n-                self.write_scalar(\n+                this.write_scalar(\n                     Scalar::from_int(result, dest.layout.size),\n                     dest,\n                 )?;\n             }\n \n             \"strlen\" => {\n-                let ptr = self.read_scalar(args[0])?.to_ptr()?;\n-                let n = self.memory().get(ptr.alloc_id)?.read_c_str(tcx, ptr)?.len();\n-                self.write_scalar(Scalar::from_uint(n as u64, dest.layout.size), dest)?;\n+                let ptr = this.read_scalar(args[0])?.to_ptr()?;\n+                let n = this.memory().get(ptr.alloc_id)?.read_c_str(tcx, ptr)?.len();\n+                this.write_scalar(Scalar::from_uint(n as u64, dest.layout.size), dest)?;\n             }\n \n             // Some things needed for sys::thread initialization to go through\n             \"signal\" | \"sigaction\" | \"sigaltstack\" => {\n-                self.write_scalar(Scalar::from_int(0, dest.layout.size), dest)?;\n+                this.write_scalar(Scalar::from_int(0, dest.layout.size), dest)?;\n             }\n \n             \"sysconf\" => {\n-                let name = self.read_scalar(args[0])?.to_i32()?;\n+                let name = this.read_scalar(args[0])?.to_i32()?;\n \n                 trace!(\"sysconf() called with name {}\", name);\n                 // cache the sysconf integers via miri's global cache\n@@ -446,13 +429,13 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                 ];\n                 let mut result = None;\n                 for &(path, path_value) in paths {\n-                    if let Ok(instance) = self.resolve_path(path) {\n+                    if let Ok(instance) = this.resolve_path(path) {\n                         let cid = GlobalId {\n                             instance,\n                             promoted: None,\n                         };\n-                        let const_val = self.const_eval_raw(cid)?;\n-                        let const_val = self.read_scalar(const_val.into())?;\n+                        let const_val = this.const_eval_raw(cid)?;\n+                        let const_val = this.read_scalar(const_val.into())?;\n                         let value = const_val.to_i32()?;\n                         if value == name {\n                             result = Some(path_value);\n@@ -461,7 +444,7 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                     }\n                 }\n                 if let Some(result) = result {\n-                    self.write_scalar(result, dest)?;\n+                    this.write_scalar(result, dest)?;\n                 } else {\n                     return err!(Unimplemented(\n                         format!(\"Unimplemented sysconf name: {}\", name),\n@@ -471,13 +454,13 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n \n             // Hook pthread calls that go to the thread-local storage memory subsystem\n             \"pthread_key_create\" => {\n-                let key_ptr = self.read_scalar(args[0])?.to_ptr()?;\n+                let key_ptr = this.read_scalar(args[0])?.to_ptr()?;\n \n                 // Extract the function type out of the signature (that seems easier than constructing it ourselves...)\n-                let dtor = match self.read_scalar(args[1])?.not_undef()? {\n-                    Scalar::Ptr(dtor_ptr) => Some(self.memory().get_fn(dtor_ptr)?),\n+                let dtor = match this.read_scalar(args[1])?.not_undef()? {\n+                    Scalar::Ptr(dtor_ptr) => Some(this.memory().get_fn(dtor_ptr)?),\n                     Scalar::Bits { bits: 0, size } => {\n-                        assert_eq!(size as u64, self.memory().pointer_size().bytes());\n+                        assert_eq!(size as u64, this.memory().pointer_size().bytes());\n                         None\n                     },\n                     Scalar::Bits { .. } => return err!(ReadBytesAsPointer),\n@@ -486,43 +469,43 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n                 // Figure out how large a pthread TLS key actually is. This is libc::pthread_key_t.\n                 let key_type = args[0].layout.ty.builtin_deref(true)\n                                    .ok_or_else(|| EvalErrorKind::AbiViolation(\"Wrong signature used for pthread_key_create: First argument must be a raw pointer.\".to_owned()))?.ty;\n-                let key_layout = self.layout_of(key_type)?;\n+                let key_layout = this.layout_of(key_type)?;\n \n                 // Create key and write it into the memory where key_ptr wants it\n-                let key = self.machine.tls.create_tls_key(dtor, tcx) as u128;\n+                let key = this.machine.tls.create_tls_key(dtor, tcx) as u128;\n                 if key_layout.size.bits() < 128 && key >= (1u128 << key_layout.size.bits() as u128) {\n                     return err!(OutOfTls);\n                 }\n \n-                self.memory().check_align(key_ptr.into(), key_layout.align.abi)?;\n-                self.memory_mut().get_mut(key_ptr.alloc_id)?.write_scalar(\n+                this.memory().check_align(key_ptr.into(), key_layout.align.abi)?;\n+                this.memory_mut().get_mut(key_ptr.alloc_id)?.write_scalar(\n                     tcx,\n                     key_ptr,\n                     Scalar::from_uint(key, key_layout.size).into(),\n                     key_layout.size,\n                 )?;\n \n                 // Return success (0)\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n             \"pthread_key_delete\" => {\n-                let key = self.read_scalar(args[0])?.to_bytes()?;\n-                self.machine.tls.delete_tls_key(key)?;\n+                let key = this.read_scalar(args[0])?.to_bits(args[0].layout.size)?;\n+                this.machine.tls.delete_tls_key(key)?;\n                 // Return success (0)\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n             \"pthread_getspecific\" => {\n-                let key = self.read_scalar(args[0])?.to_bytes()?;\n-                let ptr = self.machine.tls.load_tls(key)?;\n-                self.write_scalar(ptr, dest)?;\n+                let key = this.read_scalar(args[0])?.to_bits(args[0].layout.size)?;\n+                let ptr = this.machine.tls.load_tls(key)?;\n+                this.write_scalar(ptr, dest)?;\n             }\n             \"pthread_setspecific\" => {\n-                let key = self.read_scalar(args[0])?.to_bytes()?;\n-                let new_ptr = self.read_scalar(args[1])?.not_undef()?;\n-                self.machine.tls.store_tls(key, new_ptr)?;\n+                let key = this.read_scalar(args[0])?.to_bits(args[0].layout.size)?;\n+                let new_ptr = this.read_scalar(args[1])?.not_undef()?;\n+                this.machine.tls.store_tls(key, new_ptr)?;\n \n                 // Return success (0)\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n \n             \"_tlv_atexit\" => {\n@@ -532,19 +515,19 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             // Determining stack base address\n             \"pthread_attr_init\" | \"pthread_attr_destroy\" | \"pthread_attr_get_np\" |\n             \"pthread_getattr_np\" | \"pthread_self\" | \"pthread_get_stacksize_np\" => {\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n             \"pthread_attr_getstack\" => {\n                 // second argument is where we are supposed to write the stack size\n-                let ptr = self.deref_operand(args[1])?;\n+                let ptr = this.deref_operand(args[1])?;\n                 let stackaddr = Scalar::from_int(0x80000, args[1].layout.size); // just any address\n-                self.write_scalar(stackaddr, ptr.into())?;\n+                this.write_scalar(stackaddr, ptr.into())?;\n                 // return 0\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n             \"pthread_get_stackaddr_np\" => {\n                 let stackaddr = Scalar::from_int(0x80000, dest.layout.size); // just any address\n-                self.write_scalar(stackaddr, dest)?;\n+                this.write_scalar(stackaddr, dest)?;\n             }\n \n             // Stub out calls for condvar, mutex and rwlock to just return 0\n@@ -554,22 +537,22 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             \"pthread_rwlock_wrlock\" | \"pthread_rwlock_destroy\" | \"pthread_condattr_init\" |\n             \"pthread_condattr_setclock\" | \"pthread_cond_init\" | \"pthread_condattr_destroy\" |\n             \"pthread_cond_destroy\" => {\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n \n             \"mmap\" => {\n                 // This is a horrible hack, but well... the guard page mechanism calls mmap and expects a particular return value, so we give it that value\n-                let addr = self.read_scalar(args[0])?.not_undef()?;\n-                self.write_scalar(addr, dest)?;\n+                let addr = this.read_scalar(args[0])?.not_undef()?;\n+                this.write_scalar(addr, dest)?;\n             }\n             \"mprotect\" => {\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             }\n \n             // Windows API subs\n             \"AddVectoredExceptionHandler\" => {\n                 // any non zero value works for the stdlib. This is just used for stackoverflows anyway\n-                self.write_scalar(Scalar::from_int(1, dest.layout.size), dest)?;\n+                this.write_scalar(Scalar::from_int(1, dest.layout.size), dest)?;\n             },\n             \"InitializeCriticalSection\" |\n             \"EnterCriticalSection\" |\n@@ -582,38 +565,38 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             \"GetProcAddress\" |\n             \"TryEnterCriticalSection\" => {\n                 // pretend these do not exist/nothing happened, by returning zero\n-                self.write_null(dest)?;\n+                this.write_null(dest)?;\n             },\n             \"GetLastError\" => {\n                 // this is c::ERROR_CALL_NOT_IMPLEMENTED\n-                self.write_scalar(Scalar::from_int(120, dest.layout.size), dest)?;\n+                this.write_scalar(Scalar::from_int(120, dest.layout.size), dest)?;\n             },\n \n             // Windows TLS\n             \"TlsAlloc\" => {\n                 // This just creates a key; Windows does not natively support TLS dtors.\n \n                 // Create key and return it\n-                let key = self.machine.tls.create_tls_key(None, tcx) as u128;\n+                let key = this.machine.tls.create_tls_key(None, tcx) as u128;\n \n                 // Figure out how large a TLS key actually is. This is c::DWORD.\n                 if dest.layout.size.bits() < 128 && key >= (1u128 << dest.layout.size.bits() as u128) {\n                     return err!(OutOfTls);\n                 }\n-                self.write_scalar(Scalar::from_uint(key, dest.layout.size), dest)?;\n+                this.write_scalar(Scalar::from_uint(key, dest.layout.size), dest)?;\n             }\n             \"TlsGetValue\" => {\n-                let key = self.read_scalar(args[0])?.to_bytes()?;\n-                let ptr = self.machine.tls.load_tls(key)?;\n-                self.write_scalar(ptr, dest)?;\n+                let key = this.read_scalar(args[0])?.to_bits(args[0].layout.size)?;\n+                let ptr = this.machine.tls.load_tls(key)?;\n+                this.write_scalar(ptr, dest)?;\n             }\n             \"TlsSetValue\" => {\n-                let key = self.read_scalar(args[0])?.to_bytes()?;\n-                let new_ptr = self.read_scalar(args[1])?.not_undef()?;\n-                self.machine.tls.store_tls(key, new_ptr)?;\n+                let key = this.read_scalar(args[0])?.to_bits(args[0].layout.size)?;\n+                let new_ptr = this.read_scalar(args[1])?.not_undef()?;\n+                this.machine.tls.store_tls(key, new_ptr)?;\n \n                 // Return success (1)\n-                self.write_scalar(Scalar::from_int(1, dest.layout.size), dest)?;\n+                this.write_scalar(Scalar::from_int(1, dest.layout.size), dest)?;\n             }\n \n             // We can't execute anything else\n@@ -624,12 +607,12 @@ impl<'a, 'mir, 'tcx: 'mir + 'a> EvalContextExt<'tcx, 'mir> for super::MiriEvalCo\n             }\n         }\n \n-        self.goto_block(Some(ret))?;\n-        self.dump_place(*dest);\n+        this.goto_block(Some(ret))?;\n+        this.dump_place(*dest);\n         Ok(())\n     }\n \n     fn write_null(&mut self, dest: PlaceTy<'tcx, Borrow>) -> EvalResult<'tcx> {\n-        self.write_scalar(Scalar::from_int(0, dest.layout.size), dest)\n+        self.eval_context_mut().write_scalar(Scalar::from_int(0, dest.layout.size), dest)\n     }\n }"}, {"sha": "fab0c67d0aa4b111a44ead7acfc5ce5d17e62c19", "filename": "src/helpers.rs", "status": "modified", "additions": 18, "deletions": 52, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/6eb32741210019b5ad32ded21c1db526f6680699/src%2Fhelpers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6eb32741210019b5ad32ded21c1db526f6680699/src%2Fhelpers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fhelpers.rs?ref=6eb32741210019b5ad32ded21c1db526f6680699", "patch": "@@ -5,68 +5,31 @@ use rustc::hir::def_id::{DefId, CRATE_DEF_INDEX};\n \n use crate::*;\n \n-pub trait ScalarExt {\n-    /// HACK: this function just extracts all bits if `defined != 0`\n-    /// Mainly used for args of C-functions and we should totally correctly fetch the size\n-    /// of their arguments\n-    fn to_bytes(self) -> EvalResult<'static, u128>;\n-}\n-\n-impl<Tag> ScalarExt for Scalar<Tag> {\n-    fn to_bytes(self) -> EvalResult<'static, u128> {\n-        match self {\n-            Scalar::Bits { bits, size } => {\n-                assert_ne!(size, 0);\n-                Ok(bits)\n-            },\n-            Scalar::Ptr(_) => err!(ReadPointerAsBytes),\n-        }\n-    }\n-}\n-\n-impl<Tag> ScalarExt for ScalarMaybeUndef<Tag> {\n-    fn to_bytes(self) -> EvalResult<'static, u128> {\n-        self.not_undef()?.to_bytes()\n-    }\n-}\n-\n-pub trait EvalContextExt<'tcx> {\n-    fn resolve_path(&self, path: &[&str]) -> EvalResult<'tcx, ty::Instance<'tcx>>;\n-\n-    /// Visit the memory covered by `place`, sensitive to freezing:  The 3rd parameter\n-    /// will be true if this is frozen, false if this is in an `UnsafeCell`.\n-    fn visit_freeze_sensitive(\n-        &self,\n-        place: MPlaceTy<'tcx, Borrow>,\n-        size: Size,\n-        action: impl FnMut(Pointer<Borrow>, Size, bool) -> EvalResult<'tcx>,\n-    ) -> EvalResult<'tcx>;\n-}\n-\n-\n-impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super::Evaluator<'tcx>> {\n+impl<'a, 'mir, 'tcx> EvalContextExt<'a, 'mir, 'tcx> for crate::MiriEvalContext<'a, 'mir, 'tcx> {}\n+pub trait EvalContextExt<'a, 'mir, 'tcx: 'a+'mir>: crate::MiriEvalContextExt<'a, 'mir, 'tcx> {\n     /// Get an instance for a path.\n     fn resolve_path(&self, path: &[&str]) -> EvalResult<'tcx, ty::Instance<'tcx>> {\n-        self.tcx\n+        let this = self.eval_context_ref();\n+        this.tcx\n             .crates()\n             .iter()\n-            .find(|&&krate| self.tcx.original_crate_name(krate) == path[0])\n+            .find(|&&krate| this.tcx.original_crate_name(krate) == path[0])\n             .and_then(|krate| {\n                 let krate = DefId {\n                     krate: *krate,\n                     index: CRATE_DEF_INDEX,\n                 };\n-                let mut items = self.tcx.item_children(krate);\n+                let mut items = this.tcx.item_children(krate);\n                 let mut path_it = path.iter().skip(1).peekable();\n \n                 while let Some(segment) = path_it.next() {\n                     for item in mem::replace(&mut items, Default::default()).iter() {\n                         if item.ident.name == *segment {\n                             if path_it.peek().is_none() {\n-                                return Some(ty::Instance::mono(self.tcx.tcx, item.def.def_id()));\n+                                return Some(ty::Instance::mono(this.tcx.tcx, item.def.def_id()));\n                             }\n \n-                            items = self.tcx.item_children(item.def.def_id());\n+                            items = this.tcx.item_children(item.def.def_id());\n                             break;\n                         }\n                     }\n@@ -79,15 +42,18 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n             })\n     }\n \n+    /// Visit the memory covered by `place`, sensitive to freezing:  The 3rd parameter\n+    /// will be true if this is frozen, false if this is in an `UnsafeCell`.\n     fn visit_freeze_sensitive(\n         &self,\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n         mut action: impl FnMut(Pointer<Borrow>, Size, bool) -> EvalResult<'tcx>,\n     ) -> EvalResult<'tcx> {\n+        let this = self.eval_context_ref();\n         trace!(\"visit_frozen(place={:?}, size={:?})\", *place, size);\n         debug_assert_eq!(size,\n-            self.size_and_align_of_mplace(place)?\n+            this.size_and_align_of_mplace(place)?\n             .map(|(size, _)| size)\n             .unwrap_or_else(|| place.layout.size)\n         );\n@@ -106,8 +72,8 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n             }\n             // We assume that we are given the fields in increasing offset order,\n             // and nothing else changes.\n-            let unsafe_cell_offset = unsafe_cell_ptr.get_ptr_offset(self);\n-            let end_offset = end_ptr.get_ptr_offset(self);\n+            let unsafe_cell_offset = unsafe_cell_ptr.get_ptr_offset(this);\n+            let end_offset = end_ptr.get_ptr_offset(this);\n             assert!(unsafe_cell_offset >= end_offset);\n             let frozen_size = unsafe_cell_offset - end_offset;\n             // Everything between the end_ptr and this `UnsafeCell` is frozen.\n@@ -119,18 +85,18 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n                 action(unsafe_cell_ptr.to_ptr()?, unsafe_cell_size, /*frozen*/false)?;\n             }\n             // Update end end_ptr.\n-            end_ptr = unsafe_cell_ptr.ptr_wrapping_offset(unsafe_cell_size, self);\n+            end_ptr = unsafe_cell_ptr.ptr_wrapping_offset(unsafe_cell_size, this);\n             // Done\n             Ok(())\n         };\n         // Run a visitor\n         {\n             let mut visitor = UnsafeCellVisitor {\n-                ecx: self,\n+                ecx: this,\n                 unsafe_cell_action: |place| {\n                     trace!(\"unsafe_cell_action on {:?}\", place.ptr);\n                     // We need a size to go on.\n-                    let unsafe_cell_size = self.size_and_align_of_mplace(place)?\n+                    let unsafe_cell_size = this.size_and_align_of_mplace(place)?\n                         .map(|(size, _)| size)\n                         // for extern types, just cover what we can\n                         .unwrap_or_else(|| place.layout.size);\n@@ -146,7 +112,7 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n         }\n         // The part between the end_ptr and the end of the place is also frozen.\n         // So pretend there is a 0-sized `UnsafeCell` at the end.\n-        unsafe_cell_action(place.ptr.ptr_wrapping_offset(size, self), Size::ZERO)?;\n+        unsafe_cell_action(place.ptr.ptr_wrapping_offset(size, this), Size::ZERO)?;\n         // Done!\n         return Ok(());\n "}, {"sha": "0f7382b61b726668be102dbfa44b1b22c4d063ba", "filename": "src/intrinsic.rs", "status": "modified", "additions": 119, "deletions": 126, "changes": 245, "blob_url": "https://github.com/rust-lang/rust/blob/6eb32741210019b5ad32ded21c1db526f6680699/src%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6eb32741210019b5ad32ded21c1db526f6680699/src%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsic.rs?ref=6eb32741210019b5ad32ded21c1db526f6680699", "patch": "@@ -6,50 +6,43 @@ use rustc::mir::interpret::{EvalResult, PointerArithmetic};\n \n use crate::{\n     PlaceTy, OpTy, Immediate, Scalar, ScalarMaybeUndef, Borrow,\n-    ScalarExt, OperatorEvalContextExt\n+    OperatorEvalContextExt\n };\n \n-pub trait EvalContextExt<'tcx> {\n-    fn call_intrinsic(\n-        &mut self,\n-        instance: ty::Instance<'tcx>,\n-        args: &[OpTy<'tcx, Borrow>],\n-        dest: PlaceTy<'tcx, Borrow>,\n-    ) -> EvalResult<'tcx>;\n-}\n-\n-impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, 'tcx> {\n+impl<'a, 'mir, 'tcx> EvalContextExt<'a, 'mir, 'tcx> for crate::MiriEvalContext<'a, 'mir, 'tcx> {}\n+pub trait EvalContextExt<'a, 'mir, 'tcx: 'a+'mir>: crate::MiriEvalContextExt<'a, 'mir, 'tcx> {\n     fn call_intrinsic(\n         &mut self,\n         instance: ty::Instance<'tcx>,\n         args: &[OpTy<'tcx, Borrow>],\n         dest: PlaceTy<'tcx, Borrow>,\n     ) -> EvalResult<'tcx> {\n-        if self.emulate_intrinsic(instance, args, dest)? {\n+        let this = self.eval_context_mut();\n+        if this.emulate_intrinsic(instance, args, dest)? {\n             return Ok(());\n         }\n-        let tcx = &{self.tcx.tcx};\n+        let tcx = &{this.tcx.tcx};\n         let substs = instance.substs;\n \n         // All these intrinsics take raw pointers, so if we access memory directly\n         // (as opposed to through a place), we have to remember to erase any tag\n         // that might still hang around!\n \n-        let intrinsic_name = &self.tcx.item_name(instance.def_id()).as_str()[..];\n+        let intrinsic_name = &this.tcx.item_name(instance.def_id()).as_str()[..];\n         match intrinsic_name {\n             \"arith_offset\" => {\n-                let offset = self.read_scalar(args[1])?.to_isize(self)?;\n-                let ptr = self.read_scalar(args[0])?.not_undef()?;\n+                let offset = this.read_scalar(args[1])?.to_isize(this)?;\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n \n                 let pointee_ty = substs.type_at(0);\n-                let pointee_size = self.layout_of(pointee_ty)?.size.bytes() as i64;\n+                let pointee_size = this.layout_of(pointee_ty)?.size.bytes() as i64;\n                 let offset = offset.overflowing_mul(pointee_size).0;\n-                let result_ptr = ptr.ptr_wrapping_signed_offset(offset, self);\n-                self.write_scalar(result_ptr, dest)?;\n+                let result_ptr = ptr.ptr_wrapping_signed_offset(offset, this);\n+                this.write_scalar(result_ptr, dest)?;\n             }\n \n             \"assume\" => {\n-                let cond = self.read_scalar(args[0])?.to_bool()?;\n+                let cond = this.read_scalar(args[0])?.to_bool()?;\n                 if !cond {\n                     return err!(AssumptionNotHeld);\n                 }\n@@ -59,44 +52,44 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n             \"atomic_load_relaxed\" |\n             \"atomic_load_acq\" |\n             \"volatile_load\" => {\n-                let ptr = self.deref_operand(args[0])?;\n-                let val = self.read_scalar(ptr.into())?; // make sure it fits into a scalar; otherwise it cannot be atomic\n-                self.write_scalar(val, dest)?;\n+                let ptr = this.deref_operand(args[0])?;\n+                let val = this.read_scalar(ptr.into())?; // make sure it fits into a scalar; otherwise it cannot be atomic\n+                this.write_scalar(val, dest)?;\n             }\n \n             \"atomic_store\" |\n             \"atomic_store_relaxed\" |\n             \"atomic_store_rel\" |\n             \"volatile_store\" => {\n-                let ptr = self.deref_operand(args[0])?;\n-                let val = self.read_scalar(args[1])?; // make sure it fits into a scalar; otherwise it cannot be atomic\n-                self.write_scalar(val, ptr.into())?;\n+                let ptr = this.deref_operand(args[0])?;\n+                let val = this.read_scalar(args[1])?; // make sure it fits into a scalar; otherwise it cannot be atomic\n+                this.write_scalar(val, ptr.into())?;\n             }\n \n             \"atomic_fence_acq\" => {\n                 // we are inherently singlethreaded and singlecored, this is a nop\n             }\n \n             _ if intrinsic_name.starts_with(\"atomic_xchg\") => {\n-                let ptr = self.deref_operand(args[0])?;\n-                let new = self.read_scalar(args[1])?;\n-                let old = self.read_scalar(ptr.into())?;\n-                self.write_scalar(old, dest)?; // old value is returned\n-                self.write_scalar(new, ptr.into())?;\n+                let ptr = this.deref_operand(args[0])?;\n+                let new = this.read_scalar(args[1])?;\n+                let old = this.read_scalar(ptr.into())?;\n+                this.write_scalar(old, dest)?; // old value is returned\n+                this.write_scalar(new, ptr.into())?;\n             }\n \n             _ if intrinsic_name.starts_with(\"atomic_cxchg\") => {\n-                let ptr = self.deref_operand(args[0])?;\n-                let expect_old = self.read_immediate(args[1])?; // read as immediate for the sake of `binary_op_imm()`\n-                let new = self.read_scalar(args[2])?;\n-                let old = self.read_immediate(ptr.into())?; // read as immediate for the sake of `binary_op_imm()`\n+                let ptr = this.deref_operand(args[0])?;\n+                let expect_old = this.read_immediate(args[1])?; // read as immediate for the sake of `binary_op_imm()`\n+                let new = this.read_scalar(args[2])?;\n+                let old = this.read_immediate(ptr.into())?; // read as immediate for the sake of `binary_op_imm()`\n                 // binary_op_imm will bail if either of them is not a scalar\n-                let (eq, _) = self.binary_op_imm(mir::BinOp::Eq, old, expect_old)?;\n+                let (eq, _) = this.binary_op_imm(mir::BinOp::Eq, old, expect_old)?;\n                 let res = Immediate::ScalarPair(old.to_scalar_or_undef(), eq.into());\n-                self.write_immediate(res, dest)?; // old value is returned\n+                this.write_immediate(res, dest)?; // old value is returned\n                 // update ptr depending on comparison\n                 if eq.to_bool()? {\n-                    self.write_scalar(new, ptr.into())?;\n+                    this.write_scalar(new, ptr.into())?;\n                 }\n             }\n \n@@ -125,13 +118,13 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n             \"atomic_xsub_rel\" |\n             \"atomic_xsub_acqrel\" |\n             \"atomic_xsub_relaxed\" => {\n-                let ptr = self.deref_operand(args[0])?;\n+                let ptr = this.deref_operand(args[0])?;\n                 if !ptr.layout.ty.is_integral() {\n                     return err!(Unimplemented(format!(\"Atomic arithmetic operations only work on integer types\")));\n                 }\n-                let rhs = self.read_immediate(args[1])?;\n-                let old = self.read_immediate(ptr.into())?;\n-                self.write_immediate(*old, dest)?; // old value is returned\n+                let rhs = this.read_immediate(args[1])?;\n+                let old = this.read_immediate(ptr.into())?;\n+                this.write_immediate(*old, dest)?; // old value is returned\n                 let op = match intrinsic_name.split('_').nth(1).unwrap() {\n                     \"or\" => mir::BinOp::BitOr,\n                     \"xor\" => mir::BinOp::BitXor,\n@@ -141,22 +134,22 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n                     _ => bug!(),\n                 };\n                 // Atomics wrap around on overflow.\n-                self.binop_ignore_overflow(op, old, rhs, ptr.into())?;\n+                this.binop_ignore_overflow(op, old, rhs, ptr.into())?;\n             }\n \n             \"breakpoint\" => unimplemented!(), // halt miri\n \n             \"copy\" |\n             \"copy_nonoverlapping\" => {\n                 let elem_ty = substs.type_at(0);\n-                let elem_layout = self.layout_of(elem_ty)?;\n+                let elem_layout = this.layout_of(elem_ty)?;\n                 let elem_size = elem_layout.size.bytes();\n-                let count = self.read_scalar(args[2])?.to_usize(self)?;\n+                let count = this.read_scalar(args[2])?.to_usize(this)?;\n                 let elem_align = elem_layout.align.abi;\n                 // erase tags: this is a raw ptr operation\n-                let src = self.read_scalar(args[0])?.not_undef()?;\n-                let dest = self.read_scalar(args[1])?.not_undef()?;\n-                self.memory_mut().copy(\n+                let src = this.read_scalar(args[0])?.not_undef()?;\n+                let dest = this.read_scalar(args[1])?.not_undef()?;\n+                this.memory_mut().copy(\n                     src,\n                     elem_align,\n                     dest,\n@@ -167,14 +160,14 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n             }\n \n             \"discriminant_value\" => {\n-                let place = self.deref_operand(args[0])?;\n-                let discr_val = self.read_discriminant(place.into())?.0;\n-                self.write_scalar(Scalar::from_uint(discr_val, dest.layout.size), dest)?;\n+                let place = this.deref_operand(args[0])?;\n+                let discr_val = this.read_discriminant(place.into())?.0;\n+                this.write_scalar(Scalar::from_uint(discr_val, dest.layout.size), dest)?;\n             }\n \n             \"sinf32\" | \"fabsf32\" | \"cosf32\" | \"sqrtf32\" | \"expf32\" | \"exp2f32\" | \"logf32\" |\n             \"log10f32\" | \"log2f32\" | \"floorf32\" | \"ceilf32\" | \"truncf32\" => {\n-                let f = self.read_scalar(args[0])?.to_f32()?;\n+                let f = this.read_scalar(args[0])?.to_f32()?;\n                 let f = match intrinsic_name {\n                     \"sinf32\" => f.sin(),\n                     \"fabsf32\" => f.abs(),\n@@ -190,12 +183,12 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n                     \"truncf32\" => f.trunc(),\n                     _ => bug!(),\n                 };\n-                self.write_scalar(Scalar::from_f32(f), dest)?;\n+                this.write_scalar(Scalar::from_f32(f), dest)?;\n             }\n \n             \"sinf64\" | \"fabsf64\" | \"cosf64\" | \"sqrtf64\" | \"expf64\" | \"exp2f64\" | \"logf64\" |\n             \"log10f64\" | \"log2f64\" | \"floorf64\" | \"ceilf64\" | \"truncf64\" => {\n-                let f = self.read_scalar(args[0])?.to_f64()?;\n+                let f = this.read_scalar(args[0])?.to_f64()?;\n                 let f = match intrinsic_name {\n                     \"sinf64\" => f.sin(),\n                     \"fabsf64\" => f.abs(),\n@@ -211,12 +204,12 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n                     \"truncf64\" => f.trunc(),\n                     _ => bug!(),\n                 };\n-                self.write_scalar(Scalar::from_f64(f), dest)?;\n+                this.write_scalar(Scalar::from_f64(f), dest)?;\n             }\n \n             \"fadd_fast\" | \"fsub_fast\" | \"fmul_fast\" | \"fdiv_fast\" | \"frem_fast\" => {\n-                let a = self.read_immediate(args[0])?;\n-                let b = self.read_immediate(args[1])?;\n+                let a = this.read_immediate(args[0])?;\n+                let b = this.read_immediate(args[1])?;\n                 let op = match intrinsic_name {\n                     \"fadd_fast\" => mir::BinOp::Add,\n                     \"fsub_fast\" => mir::BinOp::Sub,\n@@ -225,19 +218,19 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n                     \"frem_fast\" => mir::BinOp::Rem,\n                     _ => bug!(),\n                 };\n-                self.binop_ignore_overflow(op, a, b, dest)?;\n+                this.binop_ignore_overflow(op, a, b, dest)?;\n             }\n \n             \"exact_div\" => {\n                 // Performs an exact division, resulting in undefined behavior where\n                 // `x % y != 0` or `y == 0` or `x == T::min_value() && y == -1`\n-                let a = self.read_immediate(args[0])?;\n-                let b = self.read_immediate(args[1])?;\n+                let a = this.read_immediate(args[0])?;\n+                let b = this.read_immediate(args[1])?;\n                 // check x % y != 0\n-                if self.binary_op_imm(mir::BinOp::Rem, a, b)?.0.to_bytes()? != 0 {\n+                if this.binary_op_imm(mir::BinOp::Rem, a, b)?.0.to_bits(dest.layout.size)? != 0 {\n                     return err!(ValidationFailure(format!(\"exact_div: {:?} cannot be divided by {:?}\", a, b)));\n                 }\n-                self.binop_ignore_overflow(mir::BinOp::Div, a, b, dest)?;\n+                this.binop_ignore_overflow(mir::BinOp::Div, a, b, dest)?;\n             },\n \n             \"likely\" | \"unlikely\" | \"forget\" => {}\n@@ -252,121 +245,121 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n                 if !dest.layout.is_zst() { // nothing to do for ZST\n                     match dest.layout.abi {\n                         layout::Abi::Scalar(ref s) => {\n-                            let x = Scalar::from_int(0, s.value.size(self));\n-                            self.write_immediate(Immediate::Scalar(x.into()), dest)?;\n+                            let x = Scalar::from_int(0, s.value.size(this));\n+                            this.write_immediate(Immediate::Scalar(x.into()), dest)?;\n                         }\n                         layout::Abi::ScalarPair(ref s1, ref s2) => {\n-                            let x = Scalar::from_int(0, s1.value.size(self));\n-                            let y = Scalar::from_int(0, s2.value.size(self));\n-                            self.write_immediate(Immediate::ScalarPair(x.into(), y.into()), dest)?;\n+                            let x = Scalar::from_int(0, s1.value.size(this));\n+                            let y = Scalar::from_int(0, s2.value.size(this));\n+                            this.write_immediate(Immediate::ScalarPair(x.into(), y.into()), dest)?;\n                         }\n                         _ => {\n                             // Do it in memory\n-                            let mplace = self.force_allocation(dest)?;\n+                            let mplace = this.force_allocation(dest)?;\n                             assert!(mplace.meta.is_none());\n                             // not a zst, must be valid pointer\n                             let ptr = mplace.ptr.to_ptr()?;\n-                            self.memory_mut().get_mut(ptr.alloc_id)?.write_repeat(tcx, ptr, 0, dest.layout.size)?;\n+                            this.memory_mut().get_mut(ptr.alloc_id)?.write_repeat(tcx, ptr, 0, dest.layout.size)?;\n                         }\n                     }\n                 }\n             }\n \n             \"pref_align_of\" => {\n                 let ty = substs.type_at(0);\n-                let layout = self.layout_of(ty)?;\n+                let layout = this.layout_of(ty)?;\n                 let align = layout.align.pref.bytes();\n-                let ptr_size = self.pointer_size();\n+                let ptr_size = this.pointer_size();\n                 let align_val = Scalar::from_uint(align as u128, ptr_size);\n-                self.write_scalar(align_val, dest)?;\n+                this.write_scalar(align_val, dest)?;\n             }\n \n             \"move_val_init\" => {\n-                let ptr = self.deref_operand(args[0])?;\n-                self.copy_op(args[1], ptr.into())?;\n+                let ptr = this.deref_operand(args[0])?;\n+                this.copy_op(args[1], ptr.into())?;\n             }\n \n             \"offset\" => {\n-                let offset = self.read_scalar(args[1])?.to_isize(self)?;\n-                let ptr = self.read_scalar(args[0])?.not_undef()?;\n-                let result_ptr = self.pointer_offset_inbounds(ptr, substs.type_at(0), offset)?;\n-                self.write_scalar(result_ptr, dest)?;\n+                let offset = this.read_scalar(args[1])?.to_isize(this)?;\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                let result_ptr = this.pointer_offset_inbounds(ptr, substs.type_at(0), offset)?;\n+                this.write_scalar(result_ptr, dest)?;\n             }\n \n             \"powf32\" => {\n-                let f = self.read_scalar(args[0])?.to_f32()?;\n-                let f2 = self.read_scalar(args[1])?.to_f32()?;\n-                self.write_scalar(\n+                let f = this.read_scalar(args[0])?.to_f32()?;\n+                let f2 = this.read_scalar(args[1])?.to_f32()?;\n+                this.write_scalar(\n                     Scalar::from_f32(f.powf(f2)),\n                     dest,\n                 )?;\n             }\n \n             \"powf64\" => {\n-                let f = self.read_scalar(args[0])?.to_f64()?;\n-                let f2 = self.read_scalar(args[1])?.to_f64()?;\n-                self.write_scalar(\n+                let f = this.read_scalar(args[0])?.to_f64()?;\n+                let f2 = this.read_scalar(args[1])?.to_f64()?;\n+                this.write_scalar(\n                     Scalar::from_f64(f.powf(f2)),\n                     dest,\n                 )?;\n             }\n \n             \"fmaf32\" => {\n-                let a = self.read_scalar(args[0])?.to_f32()?;\n-                let b = self.read_scalar(args[1])?.to_f32()?;\n-                let c = self.read_scalar(args[2])?.to_f32()?;\n-                self.write_scalar(\n+                let a = this.read_scalar(args[0])?.to_f32()?;\n+                let b = this.read_scalar(args[1])?.to_f32()?;\n+                let c = this.read_scalar(args[2])?.to_f32()?;\n+                this.write_scalar(\n                     Scalar::from_f32(a * b + c),\n                     dest,\n                 )?;\n             }\n \n             \"fmaf64\" => {\n-                let a = self.read_scalar(args[0])?.to_f64()?;\n-                let b = self.read_scalar(args[1])?.to_f64()?;\n-                let c = self.read_scalar(args[2])?.to_f64()?;\n-                self.write_scalar(\n+                let a = this.read_scalar(args[0])?.to_f64()?;\n+                let b = this.read_scalar(args[1])?.to_f64()?;\n+                let c = this.read_scalar(args[2])?.to_f64()?;\n+                this.write_scalar(\n                     Scalar::from_f64(a * b + c),\n                     dest,\n                 )?;\n             }\n \n             \"powif32\" => {\n-                let f = self.read_scalar(args[0])?.to_f32()?;\n-                let i = self.read_scalar(args[1])?.to_i32()?;\n-                self.write_scalar(\n+                let f = this.read_scalar(args[0])?.to_f32()?;\n+                let i = this.read_scalar(args[1])?.to_i32()?;\n+                this.write_scalar(\n                     Scalar::from_f32(f.powi(i)),\n                     dest,\n                 )?;\n             }\n \n             \"powif64\" => {\n-                let f = self.read_scalar(args[0])?.to_f64()?;\n-                let i = self.read_scalar(args[1])?.to_i32()?;\n-                self.write_scalar(\n+                let f = this.read_scalar(args[0])?.to_f64()?;\n+                let i = this.read_scalar(args[1])?.to_i32()?;\n+                this.write_scalar(\n                     Scalar::from_f64(f.powi(i)),\n                     dest,\n                 )?;\n             }\n \n             \"size_of_val\" => {\n-                let mplace = self.deref_operand(args[0])?;\n-                let (size, _) = self.size_and_align_of_mplace(mplace)?\n+                let mplace = this.deref_operand(args[0])?;\n+                let (size, _) = this.size_and_align_of_mplace(mplace)?\n                     .expect(\"size_of_val called on extern type\");\n-                let ptr_size = self.pointer_size();\n-                self.write_scalar(\n+                let ptr_size = this.pointer_size();\n+                this.write_scalar(\n                     Scalar::from_uint(size.bytes() as u128, ptr_size),\n                     dest,\n                 )?;\n             }\n \n             \"min_align_of_val\" |\n             \"align_of_val\" => {\n-                let mplace = self.deref_operand(args[0])?;\n-                let (_, align) = self.size_and_align_of_mplace(mplace)?\n+                let mplace = this.deref_operand(args[0])?;\n+                let (_, align) = this.size_and_align_of_mplace(mplace)?\n                     .expect(\"size_of_val called on extern type\");\n-                let ptr_size = self.pointer_size();\n-                self.write_scalar(\n+                let ptr_size = this.pointer_size();\n+                this.write_scalar(\n                     Scalar::from_uint(align.bytes(), ptr_size),\n                     dest,\n                 )?;\n@@ -375,18 +368,18 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n             \"type_name\" => {\n                 let ty = substs.type_at(0);\n                 let ty_name = ty.to_string();\n-                let value = self.str_to_immediate(&ty_name)?;\n-                self.write_immediate(value, dest)?;\n+                let value = this.str_to_immediate(&ty_name)?;\n+                this.write_immediate(value, dest)?;\n             }\n \n             \"unchecked_div\" => {\n-                let l = self.read_immediate(args[0])?;\n-                let r = self.read_immediate(args[1])?;\n-                let rval = r.to_scalar()?.to_bytes()?;\n+                let l = this.read_immediate(args[0])?;\n+                let r = this.read_immediate(args[1])?;\n+                let rval = r.to_scalar()?.to_bits(args[1].layout.size)?;\n                 if rval == 0 {\n                     return err!(Intrinsic(format!(\"Division by 0 in unchecked_div\")));\n                 }\n-                self.binop_ignore_overflow(\n+                this.binop_ignore_overflow(\n                     mir::BinOp::Div,\n                     l,\n                     r,\n@@ -395,13 +388,13 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n             }\n \n             \"unchecked_rem\" => {\n-                let l = self.read_immediate(args[0])?;\n-                let r = self.read_immediate(args[1])?;\n-                let rval = r.to_scalar()?.to_bytes()?;\n+                let l = this.read_immediate(args[0])?;\n+                let r = this.read_immediate(args[1])?;\n+                let rval = r.to_scalar()?.to_bits(args[1].layout.size)?;\n                 if rval == 0 {\n                     return err!(Intrinsic(format!(\"Division by 0 in unchecked_rem\")));\n                 }\n-                self.binop_ignore_overflow(\n+                this.binop_ignore_overflow(\n                     mir::BinOp::Rem,\n                     l,\n                     r,\n@@ -420,18 +413,18 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n                     match dest.layout.abi {\n                         layout::Abi::Scalar(..) => {\n                             let x = ScalarMaybeUndef::Undef;\n-                            self.write_immediate(Immediate::Scalar(x), dest)?;\n+                            this.write_immediate(Immediate::Scalar(x), dest)?;\n                         }\n                         layout::Abi::ScalarPair(..) => {\n                             let x = ScalarMaybeUndef::Undef;\n-                            self.write_immediate(Immediate::ScalarPair(x, x), dest)?;\n+                            this.write_immediate(Immediate::ScalarPair(x, x), dest)?;\n                         }\n                         _ => {\n                             // Do it in memory\n-                            let mplace = self.force_allocation(dest)?;\n+                            let mplace = this.force_allocation(dest)?;\n                             assert!(mplace.meta.is_none());\n                             let ptr = mplace.ptr.to_ptr()?;\n-                            self.memory_mut()\n+                            this.memory_mut()\n                                 .get_mut(ptr.alloc_id)?\n                                 .mark_definedness(ptr, dest.layout.size, false)?;\n                         }\n@@ -441,15 +434,15 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, '\n \n             \"write_bytes\" => {\n                 let ty = substs.type_at(0);\n-                let ty_layout = self.layout_of(ty)?;\n-                let val_byte = self.read_scalar(args[1])?.to_u8()?;\n-                let ptr = self.read_scalar(args[0])?.not_undef()?;\n-                let count = self.read_scalar(args[2])?.to_usize(self)?;\n-                self.memory().check_align(ptr, ty_layout.align.abi)?;\n+                let ty_layout = this.layout_of(ty)?;\n+                let val_byte = this.read_scalar(args[1])?.to_u8()?;\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                let count = this.read_scalar(args[2])?.to_usize(this)?;\n+                this.memory().check_align(ptr, ty_layout.align.abi)?;\n                 let byte_count = ty_layout.size * count;\n                 if byte_count.bytes() != 0 {\n                     let ptr = ptr.to_ptr()?;\n-                    self.memory_mut()\n+                    this.memory_mut()\n                         .get_mut(ptr.alloc_id)?\n                         .write_repeat(tcx, ptr, val_byte, byte_count)?;\n                 }"}, {"sha": "28639976aa03fe97f02fcbd0726c8874ccefd7bd", "filename": "src/lib.rs", "status": "modified", "additions": 16, "deletions": 1, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/6eb32741210019b5ad32ded21c1db526f6680699/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6eb32741210019b5ad32ded21c1db526f6680699/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=6eb32741210019b5ad32ded21c1db526f6680699", "patch": "@@ -43,7 +43,7 @@ pub use crate::intrinsic::EvalContextExt as IntrinsicEvalContextExt;\n pub use crate::tls::{EvalContextExt as TlsEvalContextExt, TlsData};\n use crate::range_map::RangeMap;\n #[allow(unused_imports)] // FIXME rustc bug https://github.com/rust-lang/rust/issues/53682\n-pub use crate::helpers::{ScalarExt, EvalContextExt as HelpersEvalContextExt};\n+pub use crate::helpers::{EvalContextExt as HelpersEvalContextExt};\n use crate::mono_hash_map::MonoHashMap;\n pub use crate::stacked_borrows::{EvalContextExt as StackedBorEvalContextExt};\n \n@@ -277,6 +277,21 @@ impl<'tcx> Evaluator<'tcx> {\n #[allow(dead_code)] // FIXME https://github.com/rust-lang/rust/issues/47131\n type MiriEvalContext<'a, 'mir, 'tcx> = EvalContext<'a, 'mir, 'tcx, Evaluator<'tcx>>;\n \n+// A little trait that's useful to be inherited by extension traits\n+pub trait MiriEvalContextExt<'a, 'mir, 'tcx> {\n+    fn eval_context_ref(&self) -> &MiriEvalContext<'a, 'mir, 'tcx>;\n+    fn eval_context_mut(&mut self) -> &mut MiriEvalContext<'a, 'mir, 'tcx>;\n+}\n+impl<'a, 'mir, 'tcx> MiriEvalContextExt<'a, 'mir, 'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n+    #[inline(always)]\n+    fn eval_context_ref(&self) -> &MiriEvalContext<'a, 'mir, 'tcx> {\n+        self\n+    }\n+    #[inline(always)]\n+    fn eval_context_mut(&mut self) -> &mut MiriEvalContext<'a, 'mir, 'tcx> {\n+        self\n+    }\n+}\n \n impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n     type MemoryKinds = MiriMemoryKind;"}, {"sha": "748ac020d6a81eb1e63a873f9691b2d75274d100", "filename": "src/stacked_borrows.rs", "status": "modified", "additions": 76, "deletions": 113, "changes": 189, "blob_url": "https://github.com/rust-lang/rust/blob/6eb32741210019b5ad32ded21c1db526f6680699/src%2Fstacked_borrows.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6eb32741210019b5ad32ded21c1db526f6680699/src%2Fstacked_borrows.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstacked_borrows.rs?ref=6eb32741210019b5ad32ded21c1db526f6680699", "patch": "@@ -516,60 +516,90 @@ impl<'tcx> Stacks {\n     }\n }\n \n-\n-\n-pub trait EvalContextExt<'tcx> {\n-    fn ptr_dereference(\n-        &self,\n-        place: MPlaceTy<'tcx, Borrow>,\n-        size: Size,\n-        mutability: Option<Mutability>,\n-    ) -> EvalResult<'tcx>;\n-\n-    fn tag_new_allocation(\n-        &mut self,\n-        id: AllocId,\n-        kind: MemoryKind<MiriMemoryKind>,\n-    ) -> Borrow;\n-\n-    /// Reborrow the given place, returning the newly tagged ptr to it.\n+impl<'a, 'mir, 'tcx> EvalContextPrivExt<'a, 'mir, 'tcx> for crate::MiriEvalContext<'a, 'mir, 'tcx> {}\n+trait EvalContextPrivExt<'a, 'mir, 'tcx: 'a+'mir>: crate::MiriEvalContextExt<'a, 'mir, 'tcx> {\n     fn reborrow(\n         &mut self,\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n         fn_barrier: bool,\n         new_bor: Borrow\n-    ) -> EvalResult<'tcx>;\n+    ) -> EvalResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        let ptr = place.ptr.to_ptr()?;\n+        let barrier = if fn_barrier { Some(this.frame().extra) } else { None };\n+        trace!(\"reborrow: Creating new reference for {:?} (pointee {}): {:?}\",\n+            ptr, place.layout.ty, new_bor);\n+\n+        // Get the allocation.  It might not be mutable, so we cannot use `get_mut`.\n+        let alloc = this.memory().get(ptr.alloc_id)?;\n+        alloc.check_bounds(this, ptr, size)?;\n+        // Update the stacks.\n+        if let Borrow::Shr(Some(_)) = new_bor {\n+            // Reference that cares about freezing. We need a frozen-sensitive reborrow.\n+            this.visit_freeze_sensitive(place, size, |cur_ptr, size, frozen| {\n+                let kind = if frozen { RefKind::Frozen } else { RefKind::Raw };\n+                alloc.extra.reborrow(cur_ptr, size, barrier, new_bor, kind)\n+            })?;\n+        } else {\n+            // Just treat this as one big chunk.\n+            let kind = if new_bor.is_unique() { RefKind::Unique } else { RefKind::Raw };\n+            alloc.extra.reborrow(ptr, size, barrier, new_bor, kind)?;\n+        }\n+        Ok(())\n+    }\n \n     /// Retag an indidual pointer, returning the retagged version.\n     fn retag_reference(\n         &mut self,\n-        ptr: ImmTy<'tcx, Borrow>,\n+        val: ImmTy<'tcx, Borrow>,\n         mutbl: Mutability,\n         fn_barrier: bool,\n         two_phase: bool,\n-    ) -> EvalResult<'tcx, Immediate<Borrow>>;\n+    ) -> EvalResult<'tcx, Immediate<Borrow>> {\n+        let this = self.eval_context_mut();\n+        // We want a place for where the ptr *points to*, so we get one.\n+        let place = this.ref_to_mplace(val)?;\n+        let size = this.size_and_align_of_mplace(place)?\n+            .map(|(size, _)| size)\n+            .unwrap_or_else(|| place.layout.size);\n+        if size == Size::ZERO {\n+            // Nothing to do for ZSTs.\n+            return Ok(*val);\n+        }\n \n-    fn retag(\n-        &mut self,\n-        fn_entry: bool,\n-        two_phase: bool,\n-        place: PlaceTy<'tcx, Borrow>\n-    ) -> EvalResult<'tcx>;\n+        // Compute new borrow.\n+        let time = this.machine.stacked_borrows.increment_clock();\n+        let new_bor = match mutbl {\n+            MutMutable => Borrow::Uniq(time),\n+            MutImmutable => Borrow::Shr(Some(time)),\n+        };\n \n-    fn escape_to_raw(\n-        &mut self,\n-        place: MPlaceTy<'tcx, Borrow>,\n-        size: Size,\n-    ) -> EvalResult<'tcx>;\n+        // Reborrow.\n+        this.reborrow(place, size, fn_barrier, new_bor)?;\n+        let new_place = place.with_tag(new_bor);\n+        // Handle two-phase borrows.\n+        if two_phase {\n+            assert!(mutbl == MutMutable, \"two-phase shared borrows make no sense\");\n+            // We immediately share it, to allow read accesses\n+            let two_phase_time = this.machine.stacked_borrows.increment_clock();\n+            let two_phase_bor = Borrow::Shr(Some(two_phase_time));\n+            this.reborrow(new_place, size, /*fn_barrier*/false, two_phase_bor)?;\n+        }\n+\n+        // Return new ptr.\n+        Ok(new_place.to_ref())\n+    }\n }\n \n-impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n+impl<'a, 'mir, 'tcx> EvalContextExt<'a, 'mir, 'tcx> for crate::MiriEvalContext<'a, 'mir, 'tcx> {}\n+pub trait EvalContextExt<'a, 'mir, 'tcx: 'a+'mir>: crate::MiriEvalContextExt<'a, 'mir, 'tcx> {\n     fn tag_new_allocation(\n         &mut self,\n         id: AllocId,\n         kind: MemoryKind<MiriMemoryKind>,\n     ) -> Borrow {\n+        let this = self.eval_context_mut();\n         let time = match kind {\n             MemoryKind::Stack => {\n                 // New unique borrow. This `Uniq` is not accessible by the program,\n@@ -580,15 +610,15 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n                 // `reset` which the blog post [1] says to perform when accessing a local.\n                 //\n                 // [1] https://www.ralfj.de/blog/2018/08/07/stacked-borrows.html\n-                self.machine.stacked_borrows.increment_clock()\n+                this.machine.stacked_borrows.increment_clock()\n             }\n             _ => {\n                 // Nothing to do for everything else\n                 return Borrow::default()\n             }\n         };\n         // Make this the active borrow for this allocation\n-        let alloc = self.memory_mut().get_mut(id).expect(\"This is a new allocation, it must still exist\");\n+        let alloc = this.memory_mut().get_mut(id).expect(\"This is a new allocation, it must still exist\");\n         let size = Size::from_bytes(alloc.bytes.len() as u64);\n         alloc.extra.first_item(BorStackItem::Uniq(time), size);\n         Borrow::Uniq(time)\n@@ -604,6 +634,7 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         size: Size,\n         mutability: Option<Mutability>,\n     ) -> EvalResult<'tcx> {\n+        let this = self.eval_context_ref();\n         trace!(\"ptr_dereference: Accessing {} reference for {:?} (pointee {})\",\n             if let Some(mutability) = mutability { format!(\"{:?}\", mutability) } else { format!(\"raw\") },\n             place.ptr, place.layout.ty);\n@@ -614,13 +645,13 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         }\n \n         // Get the allocation\n-        let alloc = self.memory().get(ptr.alloc_id)?;\n-        alloc.check_bounds(self, ptr, size)?;\n+        let alloc = this.memory().get(ptr.alloc_id)?;\n+        alloc.check_bounds(this, ptr, size)?;\n         // If we got here, we do some checking, *but* we leave the tag unchanged.\n         if let Borrow::Shr(Some(_)) = ptr.tag {\n             assert_eq!(mutability, Some(MutImmutable));\n             // We need a frozen-sensitive check\n-            self.visit_freeze_sensitive(place, size, |cur_ptr, size, frozen| {\n+            this.visit_freeze_sensitive(place, size, |cur_ptr, size, frozen| {\n                 let kind = if frozen { RefKind::Frozen } else { RefKind::Raw };\n                 alloc.extra.deref(cur_ptr, size, kind)\n             })?;\n@@ -641,86 +672,18 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n     ) -> EvalResult<'tcx> {\n-        self.reborrow(place, size, /*fn_barrier*/ false, Borrow::default())?;\n-        Ok(())\n-    }\n-\n-    fn reborrow(\n-        &mut self,\n-        place: MPlaceTy<'tcx, Borrow>,\n-        size: Size,\n-        fn_barrier: bool,\n-        new_bor: Borrow\n-    ) -> EvalResult<'tcx> {\n-        let ptr = place.ptr.to_ptr()?;\n-        let barrier = if fn_barrier { Some(self.frame().extra) } else { None };\n-        trace!(\"reborrow: Creating new reference for {:?} (pointee {}): {:?}\",\n-            ptr, place.layout.ty, new_bor);\n-\n-        // Get the allocation.  It might not be mutable, so we cannot use `get_mut`.\n-        let alloc = self.memory().get(ptr.alloc_id)?;\n-        alloc.check_bounds(self, ptr, size)?;\n-        // Update the stacks.\n-        if let Borrow::Shr(Some(_)) = new_bor {\n-            // Reference that cares about freezing. We need a frozen-sensitive reborrow.\n-            self.visit_freeze_sensitive(place, size, |cur_ptr, size, frozen| {\n-                let kind = if frozen { RefKind::Frozen } else { RefKind::Raw };\n-                alloc.extra.reborrow(cur_ptr, size, barrier, new_bor, kind)\n-            })?;\n-        } else {\n-            // Just treat this as one big chunk.\n-            let kind = if new_bor.is_unique() { RefKind::Unique } else { RefKind::Raw };\n-            alloc.extra.reborrow(ptr, size, barrier, new_bor, kind)?;\n-        }\n+        let this = self.eval_context_mut();\n+        this.reborrow(place, size, /*fn_barrier*/ false, Borrow::default())?;\n         Ok(())\n     }\n \n-    fn retag_reference(\n-        &mut self,\n-        val: ImmTy<'tcx, Borrow>,\n-        mutbl: Mutability,\n-        fn_barrier: bool,\n-        two_phase: bool,\n-    ) -> EvalResult<'tcx, Immediate<Borrow>> {\n-        // We want a place for where the ptr *points to*, so we get one.\n-        let place = self.ref_to_mplace(val)?;\n-        let size = self.size_and_align_of_mplace(place)?\n-            .map(|(size, _)| size)\n-            .unwrap_or_else(|| place.layout.size);\n-        if size == Size::ZERO {\n-            // Nothing to do for ZSTs.\n-            return Ok(*val);\n-        }\n-\n-        // Compute new borrow.\n-        let time = self.machine.stacked_borrows.increment_clock();\n-        let new_bor = match mutbl {\n-            MutMutable => Borrow::Uniq(time),\n-            MutImmutable => Borrow::Shr(Some(time)),\n-        };\n-\n-        // Reborrow.\n-        self.reborrow(place, size, fn_barrier, new_bor)?;\n-        let new_place = place.with_tag(new_bor);\n-        // Handle two-phase borrows.\n-        if two_phase {\n-            assert!(mutbl == MutMutable, \"two-phase shared borrows make no sense\");\n-            // We immediately share it, to allow read accesses\n-            let two_phase_time = self.machine.stacked_borrows.increment_clock();\n-            let two_phase_bor = Borrow::Shr(Some(two_phase_time));\n-            self.reborrow(new_place, size, /*fn_barrier*/false, two_phase_bor)?;\n-        }\n-\n-        // Return new ptr.\n-        Ok(new_place.to_ref())\n-    }\n-\n     fn retag(\n         &mut self,\n         fn_entry: bool,\n         two_phase: bool,\n         place: PlaceTy<'tcx, Borrow>\n     ) -> EvalResult<'tcx> {\n+        let this = self.eval_context_mut();\n         // Determine mutability and whether to add a barrier.\n         // Cannot use `builtin_deref` because that reports *immutable* for `Box`,\n         // making it useless.\n@@ -740,14 +703,14 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         // avoids allocating.\n         if let Some((mutbl, barrier)) = qualify(place.layout.ty, fn_entry) {\n             // fast path\n-            let val = self.read_immediate(self.place_to_op(place)?)?;\n-            let val = self.retag_reference(val, mutbl, barrier, two_phase)?;\n-            self.write_immediate(val, place)?;\n+            let val = this.read_immediate(this.place_to_op(place)?)?;\n+            let val = this.retag_reference(val, mutbl, barrier, two_phase)?;\n+            this.write_immediate(val, place)?;\n             return Ok(());\n         }\n-        let place = self.force_allocation(place)?;\n+        let place = this.force_allocation(place)?;\n \n-        let mut visitor = RetagVisitor { ecx: self, fn_entry, two_phase };\n+        let mut visitor = RetagVisitor { ecx: this, fn_entry, two_phase };\n         visitor.visit_value(place)?;\n \n         // The actual visitor"}, {"sha": "5411e021619c4490e3c6c018e2fa610ad7e9f03a", "filename": "src/tls.rs", "status": "modified", "additions": 13, "deletions": 15, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/6eb32741210019b5ad32ded21c1db526f6680699/src%2Ftls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6eb32741210019b5ad32ded21c1db526f6680699/src%2Ftls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftls.rs?ref=6eb32741210019b5ad32ded21c1db526f6680699", "patch": "@@ -34,10 +34,6 @@ impl<'tcx> Default for TlsData<'tcx> {\n     }\n }\n \n-pub trait EvalContextExt<'tcx> {\n-    fn run_tls_dtors(&mut self) -> EvalResult<'tcx>;\n-}\n-\n impl<'tcx> TlsData<'tcx> {\n     pub fn create_tls_key(\n         &mut self,\n@@ -133,35 +129,37 @@ impl<'tcx> TlsData<'tcx> {\n     }\n }\n \n-impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for super::MiriEvalContext<'a, 'mir, 'tcx> {\n+impl<'a, 'mir, 'tcx> EvalContextExt<'a, 'mir, 'tcx> for crate::MiriEvalContext<'a, 'mir, 'tcx> {}\n+pub trait EvalContextExt<'a, 'mir, 'tcx: 'a+'mir>: crate::MiriEvalContextExt<'a, 'mir, 'tcx> {\n     fn run_tls_dtors(&mut self) -> EvalResult<'tcx> {\n-        let mut dtor = self.machine.tls.fetch_tls_dtor(None, &*self.tcx);\n+        let this = self.eval_context_mut();\n+        let mut dtor = this.machine.tls.fetch_tls_dtor(None, &*this.tcx);\n         // FIXME: replace loop by some structure that works with stepping\n         while let Some((instance, ptr, key)) = dtor {\n             trace!(\"Running TLS dtor {:?} on {:?}\", instance, ptr);\n             // TODO: Potentially, this has to support all the other possible instances?\n             // See eval_fn_call in interpret/terminator/mod.rs\n-            let mir = self.load_mir(instance.def)?;\n-            let ret_place = MPlaceTy::dangling(self.layout_of(self.tcx.mk_unit())?, self).into();\n-            self.push_stack_frame(\n+            let mir = this.load_mir(instance.def)?;\n+            let ret_place = MPlaceTy::dangling(this.layout_of(this.tcx.mk_unit())?, this).into();\n+            this.push_stack_frame(\n                 instance,\n                 mir.span,\n                 mir,\n                 Some(ret_place),\n                 StackPopCleanup::None { cleanup: true },\n             )?;\n-            let arg_local = self.frame().mir.args_iter().next().ok_or_else(\n+            let arg_local = this.frame().mir.args_iter().next().ok_or_else(\n                 || EvalErrorKind::AbiViolation(\"TLS dtor does not take enough arguments.\".to_owned()),\n             )?;\n-            let dest = self.eval_place(&mir::Place::Local(arg_local))?;\n-            self.write_scalar(ptr, dest)?;\n+            let dest = this.eval_place(&mir::Place::Local(arg_local))?;\n+            this.write_scalar(ptr, dest)?;\n \n             // step until out of stackframes\n-            self.run()?;\n+            this.run()?;\n \n-            dtor = match self.machine.tls.fetch_tls_dtor(Some(key), &*self.tcx) {\n+            dtor = match this.machine.tls.fetch_tls_dtor(Some(key), &*this.tcx) {\n                 dtor @ Some(_) => dtor,\n-                None => self.machine.tls.fetch_tls_dtor(None, &*self.tcx),\n+                None => this.machine.tls.fetch_tls_dtor(None, &*this.tcx),\n             };\n         }\n         // FIXME: On a windows target, call `unsafe extern \"system\" fn on_tls_callback`."}]}