{"sha": "307aacaf05419fbd45c9c5c428cb1004801f455b", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMwN2FhY2FmMDU0MTlmYmQ0NWM5YzVjNDI4Y2IxMDA0ODAxZjQ1NWI=", "commit": {"author": {"name": "Camille GILLOT", "email": "gillot.camille@gmail.com", "date": "2021-05-11T18:12:52Z"}, "committer": {"name": "Camille GILLOT", "email": "gillot.camille@gmail.com", "date": "2021-08-22T18:23:31Z"}, "message": "Decouple JobOwner from cache.", "tree": {"sha": "69738780a192e74429a42a487cbbf2f3823da4e6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/69738780a192e74429a42a487cbbf2f3823da4e6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/307aacaf05419fbd45c9c5c428cb1004801f455b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/307aacaf05419fbd45c9c5c428cb1004801f455b", "html_url": "https://github.com/rust-lang/rust/commit/307aacaf05419fbd45c9c5c428cb1004801f455b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/307aacaf05419fbd45c9c5c428cb1004801f455b/comments", "author": {"login": "cjgillot", "id": 1822483, "node_id": "MDQ6VXNlcjE4MjI0ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/1822483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjgillot", "html_url": "https://github.com/cjgillot", "followers_url": "https://api.github.com/users/cjgillot/followers", "following_url": "https://api.github.com/users/cjgillot/following{/other_user}", "gists_url": "https://api.github.com/users/cjgillot/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjgillot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjgillot/subscriptions", "organizations_url": "https://api.github.com/users/cjgillot/orgs", "repos_url": "https://api.github.com/users/cjgillot/repos", "events_url": "https://api.github.com/users/cjgillot/events{/privacy}", "received_events_url": "https://api.github.com/users/cjgillot/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cjgillot", "id": 1822483, "node_id": "MDQ6VXNlcjE4MjI0ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/1822483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjgillot", "html_url": "https://github.com/cjgillot", "followers_url": "https://api.github.com/users/cjgillot/followers", "following_url": "https://api.github.com/users/cjgillot/following{/other_user}", "gists_url": "https://api.github.com/users/cjgillot/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjgillot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjgillot/subscriptions", "organizations_url": "https://api.github.com/users/cjgillot/orgs", "repos_url": "https://api.github.com/users/cjgillot/repos", "events_url": "https://api.github.com/users/cjgillot/events{/privacy}", "received_events_url": "https://api.github.com/users/cjgillot/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d2304008c1ea8985f21e98ecdba3108611e8786d", "url": "https://api.github.com/repos/rust-lang/rust/commits/d2304008c1ea8985f21e98ecdba3108611e8786d", "html_url": "https://github.com/rust-lang/rust/commit/d2304008c1ea8985f21e98ecdba3108611e8786d"}], "stats": {"total": 139, "additions": 66, "deletions": 73}, "files": [{"sha": "8b338a0b1d1e2c97f4b19bb857f959c7182de307", "filename": "compiler/rustc_query_system/src/query/job.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/307aacaf05419fbd45c9c5c428cb1004801f455b/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/307aacaf05419fbd45c9c5c428cb1004801f455b/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs?ref=307aacaf05419fbd45c9c5c428cb1004801f455b", "patch": "@@ -143,6 +143,8 @@ impl<D> QueryJobId<D>\n where\n     D: Copy + Clone + Eq + Hash,\n {\n+    #[cold]\n+    #[inline(never)]\n     pub(super) fn find_cycle_in_stack(\n         &self,\n         query_map: QueryMap<D>,"}, {"sha": "204c10e8e990cb5ecdd19788232ebb015b1b0349", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 64, "deletions": 73, "changes": 137, "blob_url": "https://github.com/rust-lang/rust/blob/307aacaf05419fbd45c9c5c428cb1004801f455b/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/307aacaf05419fbd45c9c5c428cb1004801f455b/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=307aacaf05419fbd45c9c5c428cb1004801f455b", "patch": "@@ -12,12 +12,12 @@ use crate::query::{QueryContext, QueryMap, QuerySideEffects, QueryStackFrame};\n \n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n+#[cfg(parallel_compiler)]\n+use rustc_data_structures::profiling::TimingGuard;\n use rustc_data_structures::sharded::{get_shard_index_by_hash, Sharded};\n use rustc_data_structures::sync::{Lock, LockGuard};\n use rustc_data_structures::thin_vec::ThinVec;\n-#[cfg(not(parallel_compiler))]\n-use rustc_errors::DiagnosticBuilder;\n-use rustc_errors::{Diagnostic, FatalError};\n+use rustc_errors::{Diagnostic, DiagnosticBuilder, FatalError};\n use rustc_span::{Span, DUMMY_SP};\n use std::cell::Cell;\n use std::collections::hash_map::Entry;\n@@ -147,24 +147,21 @@ impl<D, K> Default for QueryState<D, K> {\n \n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n-struct JobOwner<'tcx, D, C>\n+struct JobOwner<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n-    state: &'tcx QueryState<D, C::Key>,\n-    cache: &'tcx QueryCacheStore<C>,\n-    key: C::Key,\n+    state: &'tcx QueryState<D, K>,\n+    key: K,\n     id: QueryJobId<D>,\n }\n \n #[cold]\n #[inline(never)]\n-#[cfg(not(parallel_compiler))]\n fn mk_cycle<CTX, V, R>(\n     tcx: CTX,\n-    root: QueryJobId<CTX::DepKind>,\n-    span: Span,\n+    error: CycleError,\n     handle_cycle_error: fn(CTX, DiagnosticBuilder<'_>) -> V,\n     cache: &dyn crate::query::QueryStorage<Value = V, Stored = R>,\n ) -> R\n@@ -173,20 +170,15 @@ where\n     V: std::fmt::Debug,\n     R: Clone,\n {\n-    let error: CycleError = root.find_cycle_in_stack(\n-        tcx.try_collect_active_jobs().unwrap(),\n-        &tcx.current_query_job(),\n-        span,\n-    );\n     let error = report_cycle(tcx.dep_context().sess(), error);\n     let value = handle_cycle_error(tcx, error);\n     cache.store_nocache(value)\n }\n \n-impl<'tcx, D, C> JobOwner<'tcx, D, C>\n+impl<'tcx, D, K> JobOwner<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n     /// start executing the query, or returns with the result of the query.\n@@ -198,14 +190,13 @@ where\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n     fn try_start<'b, CTX>(\n-        tcx: CTX,\n-        state: &'b QueryState<CTX::DepKind, C::Key>,\n-        cache: &'b QueryCacheStore<C>,\n+        tcx: &'b CTX,\n+        state: &'b QueryState<CTX::DepKind, K>,\n         span: Span,\n-        key: C::Key,\n+        key: K,\n         lookup: QueryLookup,\n-        query: &QueryVtable<CTX, C::Key, C::Value>,\n-    ) -> TryGetJob<'b, CTX::DepKind, C>\n+        dep_kind: CTX::DepKind,\n+    ) -> TryGetJob<'b, CTX::DepKind, K>\n     where\n         CTX: QueryContext,\n     {\n@@ -226,26 +217,24 @@ where\n                 let key = entry.key().clone();\n                 entry.insert(QueryResult::Started(job));\n \n-                let global_id = QueryJobId::new(id, shard, query.dep_kind);\n-                let owner = JobOwner { state, cache, id: global_id, key };\n+                let global_id = QueryJobId::new(id, shard, dep_kind);\n+                let owner = JobOwner { state, id: global_id, key };\n                 return TryGetJob::NotYetStarted(owner);\n             }\n             Entry::Occupied(mut entry) => {\n                 match entry.get_mut() {\n                     #[cfg(not(parallel_compiler))]\n                     QueryResult::Started(job) => {\n-                        let id = QueryJobId::new(job.id, shard, query.dep_kind);\n+                        let id = QueryJobId::new(job.id, shard, dep_kind);\n \n                         drop(state_lock);\n \n                         // If we are single-threaded we know that we have cycle error,\n                         // so we just return the error.\n-                        return TryGetJob::Cycle(mk_cycle(\n-                            tcx,\n-                            id,\n+                        return TryGetJob::Cycle(id.find_cycle_in_stack(\n+                            tcx.try_collect_active_jobs().unwrap(),\n+                            &tcx.current_query_job(),\n                             span,\n-                            query.handle_cycle_error,\n-                            &cache.cache,\n                         ));\n                     }\n                     #[cfg(parallel_compiler)]\n@@ -257,38 +246,17 @@ where\n \n                         // Get the latch out\n                         let latch = job.latch();\n-                        let key = entry.key().clone();\n \n                         drop(state_lock);\n \n                         // With parallel queries we might just have to wait on some other\n                         // thread.\n                         let result = latch.wait_on(tcx.current_query_job(), span);\n \n-                        if let Err(cycle) = result {\n-                            let cycle = report_cycle(tcx.dep_context().sess(), cycle);\n-                            let value = (query.handle_cycle_error)(tcx, cycle);\n-                            let value = cache.cache.store_nocache(value);\n-                            return TryGetJob::Cycle(value);\n+                        match result {\n+                            Ok(()) => TryGetJob::JobCompleted(query_blocked_prof_timer),\n+                            Err(cycle) => TryGetJob::Cycle(cycle),\n                         }\n-\n-                        let cached = cache\n-                            .cache\n-                            .lookup(cache, &key, |value, index| {\n-                                if unlikely!(tcx.dep_context().profiler().enabled()) {\n-                                    tcx.dep_context().profiler().query_cache_hit(index.into());\n-                                }\n-                                #[cfg(debug_assertions)]\n-                                {\n-                                    cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n-                                }\n-                                (value.clone(), index)\n-                            })\n-                            .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n-\n-                        query_blocked_prof_timer.finish_with_query_invocation_id(cached.1.into());\n-\n-                        return TryGetJob::JobCompleted(cached);\n                     }\n                     QueryResult::Poisoned => FatalError.raise(),\n                 }\n@@ -298,11 +266,18 @@ where\n \n     /// Completes the query by updating the query cache with the `result`,\n     /// signals the waiter and forgets the JobOwner, so it won't poison the query\n-    fn complete(self, result: C::Value, dep_node_index: DepNodeIndex) -> C::Stored {\n+    fn complete<C>(\n+        self,\n+        cache: &QueryCacheStore<C>,\n+        result: C::Value,\n+        dep_node_index: DepNodeIndex,\n+    ) -> C::Stored\n+    where\n+        C: QueryCache<Key = K>,\n+    {\n         // We can move out of `self` here because we `mem::forget` it below\n         let key = unsafe { ptr::read(&self.key) };\n         let state = self.state;\n-        let cache = self.cache;\n \n         // Forget ourself so our destructor won't poison the query\n         mem::forget(self);\n@@ -338,10 +313,10 @@ where\n     (result, diagnostics.into_inner())\n }\n \n-impl<'tcx, D, C> Drop for JobOwner<'tcx, D, C>\n+impl<'tcx, D, K> Drop for JobOwner<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n     #[inline(never)]\n     #[cold]\n@@ -372,22 +347,22 @@ pub(crate) struct CycleError {\n }\n \n /// The result of `try_start`.\n-enum TryGetJob<'tcx, D, C>\n+enum TryGetJob<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n     /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'tcx, D, C>),\n+    NotYetStarted(JobOwner<'tcx, D, K>),\n \n     /// The query was already completed.\n     /// Returns the result of the query and its dep-node index\n     /// if it succeeded or a cycle error if it failed.\n     #[cfg(parallel_compiler)]\n-    JobCompleted((C::Stored, DepNodeIndex)),\n+    JobCompleted(TimingGuard<'tcx>),\n \n     /// Trying to execute the query resulted in a cycle.\n-    Cycle(C::Stored),\n+    Cycle(CycleError),\n }\n \n /// Checks if the query is already computed and in the cache.\n@@ -436,19 +411,35 @@ where\n     C::Key: Clone + DepNodeParams<CTX::DepContext>,\n     CTX: QueryContext,\n {\n-    let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n-        tcx,\n+    let job = match JobOwner::<'_, CTX::DepKind, C::Key>::try_start(\n+        &tcx,\n         state,\n-        cache,\n         span,\n         key.clone(),\n         lookup,\n-        query,\n+        query.dep_kind,\n     ) {\n         TryGetJob::NotYetStarted(job) => job,\n-        TryGetJob::Cycle(result) => return (result, None),\n+        TryGetJob::Cycle(error) => {\n+            let result = mk_cycle(tcx, error, query.handle_cycle_error, &cache.cache);\n+            return (result, None);\n+        }\n         #[cfg(parallel_compiler)]\n-        TryGetJob::JobCompleted((v, index)) => {\n+        TryGetJob::JobCompleted(query_blocked_prof_timer) => {\n+            let (v, index) = cache\n+                .cache\n+                .lookup(cache, &key, |value, index| (value.clone(), index))\n+                .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n+\n+            if unlikely!(tcx.dep_context().profiler().enabled()) {\n+                tcx.dep_context().profiler().query_cache_hit(index.into());\n+            }\n+            #[cfg(debug_assertions)]\n+            {\n+                cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+            }\n+            query_blocked_prof_timer.finish_with_query_invocation_id(index.into());\n+\n             return (v, Some(index));\n         }\n     };\n@@ -461,7 +452,7 @@ where\n         let result = tcx.start_query(job.id, None, || compute(*tcx.dep_context(), key));\n         let dep_node_index = dep_graph.next_virtual_depnode_index();\n         prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-        let result = job.complete(result, dep_node_index);\n+        let result = job.complete(cache, result, dep_node_index);\n         return (result, None);\n     }\n \n@@ -504,7 +495,7 @@ where\n             force_query_with_job(tcx, key, job.id, dep_node, query, compute)\n         }\n     };\n-    let result = job.complete(result, dep_node_index);\n+    let result = job.complete(cache, result, dep_node_index);\n     (result, Some(dep_node_index))\n }\n "}]}