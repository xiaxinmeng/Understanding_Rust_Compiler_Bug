{"sha": "28077f971a29ddb8dee947f4c9ab14119944f66f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI4MDc3Zjk3MWEyOWRkYjhkZWU5NDdmNGM5YWIxNDExOTk0NGY2NmY=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2020-06-18T06:48:12Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-06-18T06:48:12Z"}, "message": "Merge #4872\n\n4872: Reduce the usage of bare subscript operator r=matklad a=Veetaha\n\n\n\nCo-authored-by: Veetaha <veetaha2@gmail.com>", "tree": {"sha": "12dabfcde7bda31842c28c48afef1f4de8dfd4d6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/12dabfcde7bda31842c28c48afef1f4de8dfd4d6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/28077f971a29ddb8dee947f4c9ab14119944f66f", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJe6w4sCRBK7hj4Ov3rIwAAdHIIAFcshsQWnywWnNkrLOAMIMMT\ncbP907c+zIPW/tLi8MCEY3mTAJj3GYnvLx+aMd6KMNUQduyMluCHwUaRxKTRgrMW\nnEhE1zU36ZD01vxrMVfNAds69RwjeTzDAj06k57HyYeBcclvNzlYPQWA6m4fYnJb\n7tRw/GLTngEAxHRJXDX/zPSY3qQb6hS+TMW+T1Rfu49bbhdQRI7/qFeejitQONtF\nVUOIqHAv0Tu3gBL9k8U+ioCOB3ouD0AswpI3t1DjAxCzDWH9/KgX/v5nFjI+wXEs\nLmF1N7NItBdPq6qHKgePqQOxu71BNJrzVN5PFXoI/+Bmo4Sla3tWEygYUq2BC2I=\n=86KJ\n-----END PGP SIGNATURE-----\n", "payload": "tree 12dabfcde7bda31842c28c48afef1f4de8dfd4d6\nparent 99e3acd1fec3cd9c1a77b029a4f4e6fce040c102\nparent 667d224fcc2dced629168a19f94dcef0ba4386d7\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1592462892 +0000\ncommitter GitHub <noreply@github.com> 1592462892 +0000\n\nMerge #4872\n\n4872: Reduce the usage of bare subscript operator r=matklad a=Veetaha\n\n\n\nCo-authored-by: Veetaha <veetaha2@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/28077f971a29ddb8dee947f4c9ab14119944f66f", "html_url": "https://github.com/rust-lang/rust/commit/28077f971a29ddb8dee947f4c9ab14119944f66f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/28077f971a29ddb8dee947f4c9ab14119944f66f/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "99e3acd1fec3cd9c1a77b029a4f4e6fce040c102", "url": "https://api.github.com/repos/rust-lang/rust/commits/99e3acd1fec3cd9c1a77b029a4f4e6fce040c102", "html_url": "https://github.com/rust-lang/rust/commit/99e3acd1fec3cd9c1a77b029a4f4e6fce040c102"}, {"sha": "667d224fcc2dced629168a19f94dcef0ba4386d7", "url": "https://api.github.com/repos/rust-lang/rust/commits/667d224fcc2dced629168a19f94dcef0ba4386d7", "html_url": "https://github.com/rust-lang/rust/commit/667d224fcc2dced629168a19f94dcef0ba4386d7"}], "stats": {"total": 89, "additions": 43, "deletions": 46}, "files": [{"sha": "97aa3e7951ca270ba460e06b4d0d5959a00e8a63", "filename": "crates/ra_syntax/src/parsing/text_token_source.rs", "status": "modified", "additions": 43, "deletions": 46, "changes": 89, "blob_url": "https://github.com/rust-lang/rust/blob/28077f971a29ddb8dee947f4c9ab14119944f66f/crates%2Fra_syntax%2Fsrc%2Fparsing%2Ftext_token_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/28077f971a29ddb8dee947f4c9ab14119944f66f/crates%2Fra_syntax%2Fsrc%2Fparsing%2Ftext_token_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Ftext_token_source.rs?ref=28077f971a29ddb8dee947f4c9ab14119944f66f", "patch": "@@ -1,40 +1,35 @@\n-//! FIXME: write short doc here\n+//! See `TextTokenSource` docs.\n \n-use ra_parser::Token as PToken;\n use ra_parser::TokenSource;\n \n use crate::{parsing::lexer::Token, SyntaxKind::EOF, TextRange, TextSize};\n \n+/// Implementation of `ra_parser::TokenSource` that takes tokens from source code text.\n pub(crate) struct TextTokenSource<'t> {\n     text: &'t str,\n-    /// start position of each token(expect whitespace and comment)\n+    /// token and its start position (non-whitespace/comment tokens)\n     /// ```non-rust\n     ///  struct Foo;\n-    /// ^------^---\n-    /// |      |  ^-\n-    /// 0      7  10\n+    ///  ^------^--^-\n+    ///  |      |    \\________\n+    ///  |      \\____         \\\n+    ///  |           \\         |\n+    ///  (struct, 0) (Foo, 7) (;, 10)\n     /// ```\n-    /// (token, start_offset): `[(struct, 0), (Foo, 7), (;, 10)]`\n-    start_offsets: Vec<TextSize>,\n-    /// non-whitespace/comment tokens\n-    /// ```non-rust\n-    /// struct Foo {}\n-    /// ^^^^^^ ^^^ ^^\n-    /// ```\n-    /// tokens: `[struct, Foo, {, }]`\n-    tokens: Vec<Token>,\n+    /// `[(struct, 0), (Foo, 7), (;, 10)]`\n+    token_offset_pairs: Vec<(Token, TextSize)>,\n \n     /// Current token and position\n-    curr: (PToken, usize),\n+    curr: (ra_parser::Token, usize),\n }\n \n impl<'t> TokenSource for TextTokenSource<'t> {\n-    fn current(&self) -> PToken {\n+    fn current(&self) -> ra_parser::Token {\n         self.curr.0\n     }\n \n-    fn lookahead_nth(&self, n: usize) -> PToken {\n-        mk_token(self.curr.1 + n, &self.start_offsets, &self.tokens)\n+    fn lookahead_nth(&self, n: usize) -> ra_parser::Token {\n+        mk_token(self.curr.1 + n, &self.token_offset_pairs)\n     }\n \n     fn bump(&mut self) {\n@@ -43,45 +38,47 @@ impl<'t> TokenSource for TextTokenSource<'t> {\n         }\n \n         let pos = self.curr.1 + 1;\n-        self.curr = (mk_token(pos, &self.start_offsets, &self.tokens), pos);\n+        self.curr = (mk_token(pos, &self.token_offset_pairs), pos);\n     }\n \n     fn is_keyword(&self, kw: &str) -> bool {\n-        let pos = self.curr.1;\n-        if pos >= self.tokens.len() {\n-            return false;\n-        }\n-        let range = TextRange::at(self.start_offsets[pos], self.tokens[pos].len);\n-        self.text[range] == *kw\n+        self.token_offset_pairs\n+            .get(self.curr.1)\n+            .map(|(token, offset)| &self.text[TextRange::at(*offset, token.len)] == kw)\n+            .unwrap_or(false)\n     }\n }\n \n-fn mk_token(pos: usize, start_offsets: &[TextSize], tokens: &[Token]) -> PToken {\n-    let kind = tokens.get(pos).map(|t| t.kind).unwrap_or(EOF);\n-    let is_jointed_to_next = if pos + 1 < start_offsets.len() {\n-        start_offsets[pos] + tokens[pos].len == start_offsets[pos + 1]\n-    } else {\n-        false\n+fn mk_token(pos: usize, token_offset_pairs: &[(Token, TextSize)]) -> ra_parser::Token {\n+    let (kind, is_jointed_to_next) = match token_offset_pairs.get(pos) {\n+        Some((token, offset)) => (\n+            token.kind,\n+            token_offset_pairs\n+                .get(pos + 1)\n+                .map(|(_, next_offset)| offset + token.len == *next_offset)\n+                .unwrap_or(false),\n+        ),\n+        None => (EOF, false),\n     };\n-\n-    PToken { kind, is_jointed_to_next }\n+    ra_parser::Token { kind, is_jointed_to_next }\n }\n \n impl<'t> TextTokenSource<'t> {\n     /// Generate input from tokens(expect comment and whitespace).\n     pub fn new(text: &'t str, raw_tokens: &'t [Token]) -> TextTokenSource<'t> {\n-        let mut tokens = Vec::new();\n-        let mut start_offsets = Vec::new();\n-        let mut len = 0.into();\n-        for &token in raw_tokens.iter() {\n-            if !token.kind.is_trivia() {\n-                tokens.push(token);\n-                start_offsets.push(len);\n-            }\n-            len += token.len;\n-        }\n+        let token_offset_pairs: Vec<_> = raw_tokens\n+            .iter()\n+            .filter_map({\n+                let mut len = 0.into();\n+                move |token| {\n+                    let pair = if token.kind.is_trivia() { None } else { Some((*token, len)) };\n+                    len += token.len;\n+                    pair\n+                }\n+            })\n+            .collect();\n \n-        let first = mk_token(0, &start_offsets, &tokens);\n-        TextTokenSource { text, start_offsets, tokens, curr: (first, 0) }\n+        let first = mk_token(0, &token_offset_pairs);\n+        TextTokenSource { text, token_offset_pairs, curr: (first, 0) }\n     }\n }"}]}