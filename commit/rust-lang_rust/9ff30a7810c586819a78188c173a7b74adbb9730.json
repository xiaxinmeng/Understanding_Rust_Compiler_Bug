{"sha": "9ff30a7810c586819a78188c173a7b74adbb9730", "node_id": "MDY6Q29tbWl0NzI0NzEyOjlmZjMwYTc4MTBjNTg2ODE5YTc4MTg4YzE3M2E3Yjc0YWRiYjk3MzA=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-12-21T01:02:54Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-12-21T01:02:54Z"}, "message": "Auto merge of #67464 - Centril:rollup-j3mkl1m, r=Centril\n\nRollup of 6 pull requests\n\nSuccessful merges:\n\n - #67130 (Const prop should finish propagation into user defined variables)\n - #67163 (Split up ptr/mod.rs in libcore...)\n - #67314 (Don't suppress move errors for union fields)\n - #67392 (Fix unresolved type span inside async object)\n - #67404 (Separate region inference logic from error handling better)\n - #67428 (`is_binding_pat`: use explicit match & include or-pats in grammar)\n\nFailed merges:\n\nr? @ghost", "tree": {"sha": "accbdc8fc8c5cfb005fce2904071db26b97ac171", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/accbdc8fc8c5cfb005fce2904071db26b97ac171"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/9ff30a7810c586819a78188c173a7b74adbb9730", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/9ff30a7810c586819a78188c173a7b74adbb9730", "html_url": "https://github.com/rust-lang/rust/commit/9ff30a7810c586819a78188c173a7b74adbb9730", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/9ff30a7810c586819a78188c173a7b74adbb9730/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ccd238309f9dce92a05a23c2959e2819668c69a4", "url": "https://api.github.com/repos/rust-lang/rust/commits/ccd238309f9dce92a05a23c2959e2819668c69a4", "html_url": "https://github.com/rust-lang/rust/commit/ccd238309f9dce92a05a23c2959e2819668c69a4"}, {"sha": "f465f95b4b9302434246209c968c90b8704b8099", "url": "https://api.github.com/repos/rust-lang/rust/commits/f465f95b4b9302434246209c968c90b8704b8099", "html_url": "https://github.com/rust-lang/rust/commit/f465f95b4b9302434246209c968c90b8704b8099"}], "stats": {"total": 3918, "additions": 2090, "deletions": 1828}, "files": [{"sha": "be2b7ff5f773b69650719fdaef64a7f520aa253e", "filename": "src/libcore/ptr/const_ptr.rs", "status": "added", "additions": 755, "deletions": 0, "changes": 755, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibcore%2Fptr%2Fconst_ptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibcore%2Fptr%2Fconst_ptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fptr%2Fconst_ptr.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -0,0 +1,755 @@\n+use crate::cmp::Ordering::{self, Less, Equal, Greater};\n+use crate::intrinsics;\n+use crate::mem;\n+use super::*;\n+\n+// ignore-tidy-undocumented-unsafe\n+\n+#[lang = \"const_ptr\"]\n+impl<T: ?Sized> *const T {\n+    /// Returns `true` if the pointer is null.\n+    ///\n+    /// Note that unsized types have many possible null pointers, as only the\n+    /// raw data pointer is considered, not their length, vtable, etc.\n+    /// Therefore, two pointers that are null may still not compare equal to\n+    /// each other.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let s: &str = \"Follow the rabbit\";\n+    /// let ptr: *const u8 = s.as_ptr();\n+    /// assert!(!ptr.is_null());\n+    /// ```\n+    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+    #[inline]\n+    pub fn is_null(self) -> bool {\n+        // Compare via a cast to a thin pointer, so fat pointers are only\n+        // considering their \"data\" part for null-ness.\n+        (self as *const u8) == null()\n+    }\n+\n+    /// Casts to a pointer of another type.\n+    #[stable(feature = \"ptr_cast\", since = \"1.38.0\")]\n+    #[rustc_const_stable(feature = \"const_ptr_cast\", since = \"1.38.0\")]\n+    #[inline]\n+    pub const fn cast<U>(self) -> *const U {\n+        self as _\n+    }\n+\n+    /// Returns `None` if the pointer is null, or else returns a reference to\n+    /// the value wrapped in `Some`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// While this method and its mutable counterpart are useful for\n+    /// null-safety, it is important to note that this is still an unsafe\n+    /// operation because the returned value could be pointing to invalid\n+    /// memory.\n+    ///\n+    /// When calling this method, you have to ensure that *either* the pointer is NULL *or*\n+    /// all of the following is true:\n+    /// - it is properly aligned\n+    /// - it must point to an initialized instance of T; in particular, the pointer must be\n+    ///   \"dereferencable\" in the sense defined [here].\n+    ///\n+    /// This applies even if the result of this method is unused!\n+    /// (The part about being initialized is not yet fully decided, but until\n+    /// it is, the only safe approach is to ensure that they are indeed initialized.)\n+    ///\n+    /// Additionally, the lifetime `'a` returned is arbitrarily chosen and does\n+    /// not necessarily reflect the actual lifetime of the data. *You* must enforce\n+    /// Rust's aliasing rules. In particular, for the duration of this lifetime,\n+    /// the memory the pointer points to must not get mutated (except inside `UnsafeCell`).\n+    ///\n+    /// [here]: crate::ptr#safety\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let ptr: *const u8 = &10u8 as *const u8;\n+    ///\n+    /// unsafe {\n+    ///     if let Some(val_back) = ptr.as_ref() {\n+    ///         println!(\"We got back the value: {}!\", val_back);\n+    ///     }\n+    /// }\n+    /// ```\n+    ///\n+    /// # Null-unchecked version\n+    ///\n+    /// If you are sure the pointer can never be null and are looking for some kind of\n+    /// `as_ref_unchecked` that returns the `&T` instead of `Option<&T>`, know that you can\n+    /// dereference the pointer directly.\n+    ///\n+    /// ```\n+    /// let ptr: *const u8 = &10u8 as *const u8;\n+    ///\n+    /// unsafe {\n+    ///     let val_back = &*ptr;\n+    ///     println!(\"We got back the value: {}!\", val_back);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"ptr_as_ref\", since = \"1.9.0\")]\n+    #[inline]\n+    pub unsafe fn as_ref<'a>(self) -> Option<&'a T> {\n+        if self.is_null() { None } else { Some(&*self) }\n+    }\n+\n+    /// Calculates the offset from a pointer.\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum, **in bytes** must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_offset`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// [`wrapping_offset`]: #method.wrapping_offset\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let s: &str = \"123\";\n+    /// let ptr: *const u8 = s.as_ptr();\n+    ///\n+    /// unsafe {\n+    ///     println!(\"{}\", *ptr.offset(1) as char);\n+    ///     println!(\"{}\", *ptr.offset(2) as char);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+    #[inline]\n+    pub unsafe fn offset(self, count: isize) -> *const T\n+        where\n+            T: Sized,\n+    {\n+        intrinsics::offset(self, count)\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// In particular, the resulting pointer remains attached to the same allocated\n+    /// object that `self` points to. It may *not* be used to access a\n+    /// different allocated object. Note that in Rust,\n+    /// every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// In other words, `x.wrapping_offset(y.wrapping_offset_from(x))` is\n+    /// *not* the same as `y`, and dereferencing it is undefined behavior\n+    /// unless `x` and `y` point into the same allocated object.\n+    ///\n+    /// Compared to [`offset`], this method basically delays the requirement of staying\n+    /// within the same allocated object: [`offset`] is immediate Undefined Behavior when\n+    /// crossing object boundaries; `wrapping_offset` produces a pointer but still leads\n+    /// to Undefined Behavior if that pointer is dereferenced. [`offset`] can be optimized\n+    /// better and is thus preferrable in performance-sensitive code.\n+    ///\n+    /// If you need to cross object boundaries, cast the pointer to an integer and\n+    /// do the arithmetic there.\n+    ///\n+    /// [`offset`]: #method.offset\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// // Iterate using a raw pointer in increments of two elements\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let step = 2;\n+    /// let end_rounded_up = ptr.wrapping_offset(6);\n+    ///\n+    /// // This loop prints \"1, 3, 5, \"\n+    /// while ptr != end_rounded_up {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_offset(step);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"ptr_wrapping_offset\", since = \"1.16.0\")]\n+    #[inline]\n+    pub fn wrapping_offset(self, count: isize) -> *const T\n+        where\n+            T: Sized,\n+    {\n+        unsafe { intrinsics::arith_offset(self, count) }\n+    }\n+\n+    /// Calculates the distance between two pointers. The returned value is in\n+    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n+    ///\n+    /// This function is the inverse of [`offset`].\n+    ///\n+    /// [`offset`]: #method.offset\n+    /// [`wrapping_offset_from`]: #method.wrapping_offset_from\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and other pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The distance between the pointers, **in bytes**, cannot overflow an `isize`.\n+    ///\n+    /// * The distance between the pointers, in bytes, must be an exact multiple\n+    ///   of the size of `T`.\n+    ///\n+    /// * The distance being in bounds cannot rely on \"wrapping around\" the address space.\n+    ///\n+    /// The compiler and standard library generally try to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `ptr_into_vec.offset_from(vec.as_ptr())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_offset_from`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function panics if `T` is a Zero-Sized Type (\"ZST\").\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(ptr_offset_from)]\n+    ///\n+    /// let a = [0; 5];\n+    /// let ptr1: *const i32 = &a[1];\n+    /// let ptr2: *const i32 = &a[3];\n+    /// unsafe {\n+    ///     assert_eq!(ptr2.offset_from(ptr1), 2);\n+    ///     assert_eq!(ptr1.offset_from(ptr2), -2);\n+    ///     assert_eq!(ptr1.offset(2), ptr2);\n+    ///     assert_eq!(ptr2.offset(-2), ptr1);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"ptr_offset_from\", issue = \"41079\")]\n+    #[rustc_const_unstable(feature = \"const_ptr_offset_from\", issue = \"41079\")]\n+    #[inline]\n+    pub const unsafe fn offset_from(self, origin: *const T) -> isize\n+        where\n+            T: Sized,\n+    {\n+        let pointee_size = mem::size_of::<T>();\n+        let ok = 0 < pointee_size && pointee_size <= isize::max_value() as usize;\n+        // assert that the pointee size is valid in a const eval compatible way\n+        // FIXME: do this with a real assert at some point\n+        [()][(!ok) as usize];\n+        intrinsics::ptr_offset_from(self, origin)\n+    }\n+\n+    /// Calculates the distance between two pointers. The returned value is in\n+    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n+    ///\n+    /// If the address different between the two pointers is not a multiple of\n+    /// `mem::size_of::<T>()` then the result of the division is rounded towards\n+    /// zero.\n+    ///\n+    /// Though this method is safe for any two pointers, note that its result\n+    /// will be mostly useless if the two pointers aren't into the same allocated\n+    /// object, for example if they point to two different local variables.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function panics if `T` is a zero-sized type.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(ptr_wrapping_offset_from)]\n+    ///\n+    /// let a = [0; 5];\n+    /// let ptr1: *const i32 = &a[1];\n+    /// let ptr2: *const i32 = &a[3];\n+    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n+    /// assert_eq!(ptr1.wrapping_offset_from(ptr2), -2);\n+    /// assert_eq!(ptr1.wrapping_offset(2), ptr2);\n+    /// assert_eq!(ptr2.wrapping_offset(-2), ptr1);\n+    ///\n+    /// let ptr1: *const i32 = 3 as _;\n+    /// let ptr2: *const i32 = 13 as _;\n+    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n+    /// ```\n+    #[unstable(feature = \"ptr_wrapping_offset_from\", issue = \"41079\")]\n+    #[inline]\n+    pub fn wrapping_offset_from(self, origin: *const T) -> isize\n+        where\n+            T: Sized,\n+    {\n+        let pointee_size = mem::size_of::<T>();\n+        assert!(0 < pointee_size && pointee_size <= isize::max_value() as usize);\n+\n+        let d = isize::wrapping_sub(self as _, origin as _);\n+        d.wrapping_div(pointee_size as _)\n+    }\n+\n+    /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a `usize`.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_add`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// [`wrapping_add`]: #method.wrapping_add\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let s: &str = \"123\";\n+    /// let ptr: *const u8 = s.as_ptr();\n+    ///\n+    /// unsafe {\n+    ///     println!(\"{}\", *ptr.add(1) as char);\n+    ///     println!(\"{}\", *ptr.add(2) as char);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn add(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer (convenience for\n+    /// `.offset((count as isize).wrapping_neg())`).\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The computed offset cannot exceed `isize::MAX` **bytes**.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len()).sub(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_sub`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// [`wrapping_sub`]: #method.wrapping_sub\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let s: &str = \"123\";\n+    ///\n+    /// unsafe {\n+    ///     let end: *const u8 = s.as_ptr().add(3);\n+    ///     println!(\"{}\", *end.sub(1) as char);\n+    ///     println!(\"{}\", *end.sub(2) as char);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn sub(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset(count as isize)`)\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// In particular, the resulting pointer remains attached to the same allocated\n+    /// object that `self` points to. It may *not* be used to access a\n+    /// different allocated object. Note that in Rust,\n+    /// every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// Compared to [`add`], this method basically delays the requirement of staying\n+    /// within the same allocated object: [`add`] is immediate Undefined Behavior when\n+    /// crossing object boundaries; `wrapping_add` produces a pointer but still leads\n+    /// to Undefined Behavior if that pointer is dereferenced. [`add`] can be optimized\n+    /// better and is thus preferrable in performance-sensitive code.\n+    ///\n+    /// If you need to cross object boundaries, cast the pointer to an integer and\n+    /// do the arithmetic there.\n+    ///\n+    /// [`add`]: #method.add\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// // Iterate using a raw pointer in increments of two elements\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let step = 2;\n+    /// let end_rounded_up = ptr.wrapping_add(6);\n+    ///\n+    /// // This loop prints \"1, 3, 5, \"\n+    /// while ptr != end_rounded_up {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_add(step);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub fn wrapping_add(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.wrapping_offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset((count as isize).wrapping_sub())`)\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// In particular, the resulting pointer remains attached to the same allocated\n+    /// object that `self` points to. It may *not* be used to access a\n+    /// different allocated object. Note that in Rust,\n+    /// every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// Compared to [`sub`], this method basically delays the requirement of staying\n+    /// within the same allocated object: [`sub`] is immediate Undefined Behavior when\n+    /// crossing object boundaries; `wrapping_sub` produces a pointer but still leads\n+    /// to Undefined Behavior if that pointer is dereferenced. [`sub`] can be optimized\n+    /// better and is thus preferrable in performance-sensitive code.\n+    ///\n+    /// If you need to cross object boundaries, cast the pointer to an integer and\n+    /// do the arithmetic there.\n+    ///\n+    /// [`sub`]: #method.sub\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// // Iterate using a raw pointer in increments of two elements (backwards)\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let start_rounded_down = ptr.wrapping_sub(2);\n+    /// ptr = ptr.wrapping_add(4);\n+    /// let step = 2;\n+    /// // This loop prints \"5, 3, 1, \"\n+    /// while ptr != start_rounded_down {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_sub(step);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub fn wrapping_sub(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.wrapping_offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// See [`ptr::read`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::read`]: ./ptr/fn.read.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn read(self) -> T\n+        where\n+            T: Sized,\n+    {\n+        read(self)\n+    }\n+\n+    /// Performs a volatile read of the value from `self` without moving it. This\n+    /// leaves the memory in `self` unchanged.\n+    ///\n+    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n+    /// to not be elided or reordered by the compiler across other volatile\n+    /// operations.\n+    ///\n+    /// See [`ptr::read_volatile`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::read_volatile`]: ./ptr/fn.read_volatile.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn read_volatile(self) -> T\n+        where\n+            T: Sized,\n+    {\n+        read_volatile(self)\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// Unlike `read`, the pointer may be unaligned.\n+    ///\n+    /// See [`ptr::read_unaligned`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::read_unaligned`]: ./ptr/fn.read_unaligned.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn read_unaligned(self) -> T\n+        where\n+            T: Sized,\n+    {\n+        read_unaligned(self)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as [`ptr::copy`].\n+    ///\n+    /// See [`ptr::copy`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::copy`]: ./ptr/fn.copy.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn copy_to(self, dest: *mut T, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        copy(self, dest, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may *not* overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as [`ptr::copy_nonoverlapping`].\n+    ///\n+    /// See [`ptr::copy_nonoverlapping`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::copy_nonoverlapping`]: ./ptr/fn.copy_nonoverlapping.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        copy_nonoverlapping(self, dest, count)\n+    }\n+\n+    /// Computes the offset that needs to be applied to the pointer in order to make it aligned to\n+    /// `align`.\n+    ///\n+    /// If it is not possible to align the pointer, the implementation returns\n+    /// `usize::max_value()`. It is permissible for the implementation to *always*\n+    /// return `usize::max_value()`. Only your algorithm's performance can depend\n+    /// on getting a usable offset here, not its correctness.\n+    ///\n+    /// The offset is expressed in number of `T` elements, and not bytes. The value returned can be\n+    /// used with the `wrapping_add` method.\n+    ///\n+    /// There are no guarantees whatsoever that offsetting the pointer will not overflow or go\n+    /// beyond the allocation that the pointer points into. It is up to the caller to ensure that\n+    /// the returned offset is correct in all terms other than alignment.\n+    ///\n+    /// # Panics\n+    ///\n+    /// The function panics if `align` is not a power-of-two.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Accessing adjacent `u8` as `u16`\n+    ///\n+    /// ```\n+    /// # fn foo(n: usize) {\n+    /// # use std::mem::align_of;\n+    /// # unsafe {\n+    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n+    /// let ptr = &x[n] as *const u8;\n+    /// let offset = ptr.align_offset(align_of::<u16>());\n+    /// if offset < x.len() - n - 1 {\n+    ///     let u16_ptr = ptr.add(offset) as *const u16;\n+    ///     assert_ne!(*u16_ptr, 500);\n+    /// } else {\n+    ///     // while the pointer can be aligned via `offset`, it would point\n+    ///     // outside the allocation\n+    /// }\n+    /// # } }\n+    /// ```\n+    #[stable(feature = \"align_offset\", since = \"1.36.0\")]\n+    pub fn align_offset(self, align: usize) -> usize\n+        where\n+            T: Sized,\n+    {\n+        if !align.is_power_of_two() {\n+            panic!(\"align_offset: align is not a power-of-two\");\n+        }\n+        unsafe { align_offset(self, align) }\n+    }\n+}\n+\n+// Equality for pointers\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> PartialEq for *const T {\n+    #[inline]\n+    fn eq(&self, other: &*const T) -> bool { *self == *other }\n+}\n+\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> Eq for *const T {}\n+\n+// Comparison for pointers\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> Ord for *const T {\n+    #[inline]\n+    fn cmp(&self, other: &*const T) -> Ordering {\n+        if self < other {\n+            Less\n+        } else if self == other {\n+            Equal\n+        } else {\n+            Greater\n+        }\n+    }\n+}\n+\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> PartialOrd for *const T {\n+    #[inline]\n+    fn partial_cmp(&self, other: &*const T) -> Option<Ordering> {\n+        Some(self.cmp(other))\n+    }\n+\n+    #[inline]\n+    fn lt(&self, other: &*const T) -> bool { *self < *other }\n+\n+    #[inline]\n+    fn le(&self, other: &*const T) -> bool { *self <= *other }\n+\n+    #[inline]\n+    fn gt(&self, other: &*const T) -> bool { *self > *other }\n+\n+    #[inline]\n+    fn ge(&self, other: &*const T) -> bool { *self >= *other }\n+}"}, {"sha": "a3a73ff6c6cf6a3e41049d4a28d7bc5151a9137e", "filename": "src/libcore/ptr/mod.rs", "status": "modified", "additions": 5, "deletions": 1691, "changes": 1696, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibcore%2Fptr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibcore%2Fptr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fptr%2Fmod.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -65,16 +65,15 @@\n //! [`write_volatile`]: ./fn.write_volatile.html\n //! [`NonNull::dangling`]: ./struct.NonNull.html#method.dangling\n \n-// ignore-tidy-filelength\n // ignore-tidy-undocumented-unsafe\n \n #![stable(feature = \"rust1\", since = \"1.0.0\")]\n \n-use crate::cmp::Ordering::{self, Equal, Greater, Less};\n+use crate::intrinsics;\n use crate::fmt;\n use crate::hash;\n-use crate::intrinsics;\n use crate::mem::{self, MaybeUninit};\n+use crate::cmp::Ordering;\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub use crate::intrinsics::copy_nonoverlapping;\n@@ -93,6 +92,9 @@ mod unique;\n #[unstable(feature = \"ptr_internals\", issue = \"0\")]\n pub use unique::Unique;\n \n+mod const_ptr;\n+mod mut_ptr;\n+\n /// Executes the destructor (if any) of the pointed-to value.\n ///\n /// This is semantically equivalent to calling [`ptr::read`] and discarding\n@@ -1034,1586 +1036,6 @@ pub unsafe fn write_volatile<T>(dst: *mut T, src: T) {\n     intrinsics::volatile_store(dst, src);\n }\n \n-#[lang = \"const_ptr\"]\n-impl<T: ?Sized> *const T {\n-    /// Returns `true` if the pointer is null.\n-    ///\n-    /// Note that unsized types have many possible null pointers, as only the\n-    /// raw data pointer is considered, not their length, vtable, etc.\n-    /// Therefore, two pointers that are null may still not compare equal to\n-    /// each other.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let s: &str = \"Follow the rabbit\";\n-    /// let ptr: *const u8 = s.as_ptr();\n-    /// assert!(!ptr.is_null());\n-    /// ```\n-    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n-    #[inline]\n-    pub fn is_null(self) -> bool {\n-        // Compare via a cast to a thin pointer, so fat pointers are only\n-        // considering their \"data\" part for null-ness.\n-        (self as *const u8) == null()\n-    }\n-\n-    /// Casts to a pointer of another type.\n-    #[stable(feature = \"ptr_cast\", since = \"1.38.0\")]\n-    #[rustc_const_stable(feature = \"const_ptr_cast\", since = \"1.38.0\")]\n-    #[inline]\n-    pub const fn cast<U>(self) -> *const U {\n-        self as _\n-    }\n-\n-    /// Returns `None` if the pointer is null, or else returns a reference to\n-    /// the value wrapped in `Some`.\n-    ///\n-    /// # Safety\n-    ///\n-    /// While this method and its mutable counterpart are useful for\n-    /// null-safety, it is important to note that this is still an unsafe\n-    /// operation because the returned value could be pointing to invalid\n-    /// memory.\n-    ///\n-    /// When calling this method, you have to ensure that *either* the pointer is NULL *or*\n-    /// all of the following is true:\n-    /// - it is properly aligned\n-    /// - it must point to an initialized instance of T; in particular, the pointer must be\n-    ///   \"dereferencable\" in the sense defined [here].\n-    ///\n-    /// This applies even if the result of this method is unused!\n-    /// (The part about being initialized is not yet fully decided, but until\n-    /// it is, the only safe approach is to ensure that they are indeed initialized.)\n-    ///\n-    /// Additionally, the lifetime `'a` returned is arbitrarily chosen and does\n-    /// not necessarily reflect the actual lifetime of the data. *You* must enforce\n-    /// Rust's aliasing rules. In particular, for the duration of this lifetime,\n-    /// the memory the pointer points to must not get mutated (except inside `UnsafeCell`).\n-    ///\n-    /// [here]: crate::ptr#safety\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let ptr: *const u8 = &10u8 as *const u8;\n-    ///\n-    /// unsafe {\n-    ///     if let Some(val_back) = ptr.as_ref() {\n-    ///         println!(\"We got back the value: {}!\", val_back);\n-    ///     }\n-    /// }\n-    /// ```\n-    ///\n-    /// # Null-unchecked version\n-    ///\n-    /// If you are sure the pointer can never be null and are looking for some kind of\n-    /// `as_ref_unchecked` that returns the `&T` instead of `Option<&T>`, know that you can\n-    /// dereference the pointer directly.\n-    ///\n-    /// ```\n-    /// let ptr: *const u8 = &10u8 as *const u8;\n-    ///\n-    /// unsafe {\n-    ///     let val_back = &*ptr;\n-    ///     println!(\"We got back the value: {}!\", val_back);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"ptr_as_ref\", since = \"1.9.0\")]\n-    #[inline]\n-    pub unsafe fn as_ref<'a>(self) -> Option<&'a T> {\n-        if self.is_null() { None } else { Some(&*self) }\n-    }\n-\n-    /// Calculates the offset from a pointer.\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and resulting pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n-    ///\n-    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n-    ///   space. That is, the infinite-precision sum, **in bytes** must fit in a usize.\n-    ///\n-    /// The compiler and standard library generally tries to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `vec.as_ptr().add(vec.len())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_offset`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// [`wrapping_offset`]: #method.wrapping_offset\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let s: &str = \"123\";\n-    /// let ptr: *const u8 = s.as_ptr();\n-    ///\n-    /// unsafe {\n-    ///     println!(\"{}\", *ptr.offset(1) as char);\n-    ///     println!(\"{}\", *ptr.offset(2) as char);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n-    #[inline]\n-    pub unsafe fn offset(self, count: isize) -> *const T\n-    where\n-        T: Sized,\n-    {\n-        intrinsics::offset(self, count)\n-    }\n-\n-    /// Calculates the offset from a pointer using wrapping arithmetic.\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// The resulting pointer does not need to be in bounds, but it is\n-    /// potentially hazardous to dereference (which requires `unsafe`).\n-    ///\n-    /// In particular, the resulting pointer remains attached to the same allocated\n-    /// object that `self` points to. It may *not* be used to access a\n-    /// different allocated object. Note that in Rust,\n-    /// every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// In other words, `x.wrapping_offset(y.wrapping_offset_from(x))` is\n-    /// *not* the same as `y`, and dereferencing it is undefined behavior\n-    /// unless `x` and `y` point into the same allocated object.\n-    ///\n-    /// Compared to [`offset`], this method basically delays the requirement of staying\n-    /// within the same allocated object: [`offset`] is immediate Undefined Behavior when\n-    /// crossing object boundaries; `wrapping_offset` produces a pointer but still leads\n-    /// to Undefined Behavior if that pointer is dereferenced. [`offset`] can be optimized\n-    /// better and is thus preferrable in performance-sensitive code.\n-    ///\n-    /// If you need to cross object boundaries, cast the pointer to an integer and\n-    /// do the arithmetic there.\n-    ///\n-    /// [`offset`]: #method.offset\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// // Iterate using a raw pointer in increments of two elements\n-    /// let data = [1u8, 2, 3, 4, 5];\n-    /// let mut ptr: *const u8 = data.as_ptr();\n-    /// let step = 2;\n-    /// let end_rounded_up = ptr.wrapping_offset(6);\n-    ///\n-    /// // This loop prints \"1, 3, 5, \"\n-    /// while ptr != end_rounded_up {\n-    ///     unsafe {\n-    ///         print!(\"{}, \", *ptr);\n-    ///     }\n-    ///     ptr = ptr.wrapping_offset(step);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"ptr_wrapping_offset\", since = \"1.16.0\")]\n-    #[inline]\n-    pub fn wrapping_offset(self, count: isize) -> *const T\n-    where\n-        T: Sized,\n-    {\n-        unsafe { intrinsics::arith_offset(self, count) }\n-    }\n-\n-    /// Calculates the distance between two pointers. The returned value is in\n-    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n-    ///\n-    /// This function is the inverse of [`offset`].\n-    ///\n-    /// [`offset`]: #method.offset\n-    /// [`wrapping_offset_from`]: #method.wrapping_offset_from\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and other pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The distance between the pointers, **in bytes**, cannot overflow an `isize`.\n-    ///\n-    /// * The distance between the pointers, in bytes, must be an exact multiple\n-    ///   of the size of `T`.\n-    ///\n-    /// * The distance being in bounds cannot rely on \"wrapping around\" the address space.\n-    ///\n-    /// The compiler and standard library generally try to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `ptr_into_vec.offset_from(vec.as_ptr())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_offset_from`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// # Panics\n-    ///\n-    /// This function panics if `T` is a Zero-Sized Type (\"ZST\").\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// #![feature(ptr_offset_from)]\n-    ///\n-    /// let a = [0; 5];\n-    /// let ptr1: *const i32 = &a[1];\n-    /// let ptr2: *const i32 = &a[3];\n-    /// unsafe {\n-    ///     assert_eq!(ptr2.offset_from(ptr1), 2);\n-    ///     assert_eq!(ptr1.offset_from(ptr2), -2);\n-    ///     assert_eq!(ptr1.offset(2), ptr2);\n-    ///     assert_eq!(ptr2.offset(-2), ptr1);\n-    /// }\n-    /// ```\n-    #[unstable(feature = \"ptr_offset_from\", issue = \"41079\")]\n-    #[rustc_const_unstable(feature = \"const_ptr_offset_from\", issue = \"41079\")]\n-    #[inline]\n-    pub const unsafe fn offset_from(self, origin: *const T) -> isize\n-    where\n-        T: Sized,\n-    {\n-        let pointee_size = mem::size_of::<T>();\n-        let ok = 0 < pointee_size && pointee_size <= isize::max_value() as usize;\n-        // assert that the pointee size is valid in a const eval compatible way\n-        // FIXME: do this with a real assert at some point\n-        [()][(!ok) as usize];\n-        intrinsics::ptr_offset_from(self, origin)\n-    }\n-\n-    /// Calculates the distance between two pointers. The returned value is in\n-    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n-    ///\n-    /// If the address different between the two pointers is not a multiple of\n-    /// `mem::size_of::<T>()` then the result of the division is rounded towards\n-    /// zero.\n-    ///\n-    /// Though this method is safe for any two pointers, note that its result\n-    /// will be mostly useless if the two pointers aren't into the same allocated\n-    /// object, for example if they point to two different local variables.\n-    ///\n-    /// # Panics\n-    ///\n-    /// This function panics if `T` is a zero-sized type.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// #![feature(ptr_wrapping_offset_from)]\n-    ///\n-    /// let a = [0; 5];\n-    /// let ptr1: *const i32 = &a[1];\n-    /// let ptr2: *const i32 = &a[3];\n-    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n-    /// assert_eq!(ptr1.wrapping_offset_from(ptr2), -2);\n-    /// assert_eq!(ptr1.wrapping_offset(2), ptr2);\n-    /// assert_eq!(ptr2.wrapping_offset(-2), ptr1);\n-    ///\n-    /// let ptr1: *const i32 = 3 as _;\n-    /// let ptr2: *const i32 = 13 as _;\n-    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n-    /// ```\n-    #[unstable(feature = \"ptr_wrapping_offset_from\", issue = \"41079\")]\n-    #[inline]\n-    pub fn wrapping_offset_from(self, origin: *const T) -> isize\n-    where\n-        T: Sized,\n-    {\n-        let pointee_size = mem::size_of::<T>();\n-        assert!(0 < pointee_size && pointee_size <= isize::max_value() as usize);\n-\n-        let d = isize::wrapping_sub(self as _, origin as _);\n-        d.wrapping_div(pointee_size as _)\n-    }\n-\n-    /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and resulting pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n-    ///\n-    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n-    ///   space. That is, the infinite-precision sum must fit in a `usize`.\n-    ///\n-    /// The compiler and standard library generally tries to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `vec.as_ptr().add(vec.len())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_add`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// [`wrapping_add`]: #method.wrapping_add\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let s: &str = \"123\";\n-    /// let ptr: *const u8 = s.as_ptr();\n-    ///\n-    /// unsafe {\n-    ///     println!(\"{}\", *ptr.add(1) as char);\n-    ///     println!(\"{}\", *ptr.add(2) as char);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn add(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.offset(count as isize)\n-    }\n-\n-    /// Calculates the offset from a pointer (convenience for\n-    /// `.offset((count as isize).wrapping_neg())`).\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and resulting pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The computed offset cannot exceed `isize::MAX` **bytes**.\n-    ///\n-    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n-    ///   space. That is, the infinite-precision sum must fit in a usize.\n-    ///\n-    /// The compiler and standard library generally tries to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `vec.as_ptr().add(vec.len()).sub(vec.len())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_sub`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// [`wrapping_sub`]: #method.wrapping_sub\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let s: &str = \"123\";\n-    ///\n-    /// unsafe {\n-    ///     let end: *const u8 = s.as_ptr().add(3);\n-    ///     println!(\"{}\", *end.sub(1) as char);\n-    ///     println!(\"{}\", *end.sub(2) as char);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn sub(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.offset((count as isize).wrapping_neg())\n-    }\n-\n-    /// Calculates the offset from a pointer using wrapping arithmetic.\n-    /// (convenience for `.wrapping_offset(count as isize)`)\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// The resulting pointer does not need to be in bounds, but it is\n-    /// potentially hazardous to dereference (which requires `unsafe`).\n-    ///\n-    /// In particular, the resulting pointer remains attached to the same allocated\n-    /// object that `self` points to. It may *not* be used to access a\n-    /// different allocated object. Note that in Rust,\n-    /// every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// Compared to [`add`], this method basically delays the requirement of staying\n-    /// within the same allocated object: [`add`] is immediate Undefined Behavior when\n-    /// crossing object boundaries; `wrapping_add` produces a pointer but still leads\n-    /// to Undefined Behavior if that pointer is dereferenced. [`add`] can be optimized\n-    /// better and is thus preferrable in performance-sensitive code.\n-    ///\n-    /// If you need to cross object boundaries, cast the pointer to an integer and\n-    /// do the arithmetic there.\n-    ///\n-    /// [`add`]: #method.add\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// // Iterate using a raw pointer in increments of two elements\n-    /// let data = [1u8, 2, 3, 4, 5];\n-    /// let mut ptr: *const u8 = data.as_ptr();\n-    /// let step = 2;\n-    /// let end_rounded_up = ptr.wrapping_add(6);\n-    ///\n-    /// // This loop prints \"1, 3, 5, \"\n-    /// while ptr != end_rounded_up {\n-    ///     unsafe {\n-    ///         print!(\"{}, \", *ptr);\n-    ///     }\n-    ///     ptr = ptr.wrapping_add(step);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub fn wrapping_add(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.wrapping_offset(count as isize)\n-    }\n-\n-    /// Calculates the offset from a pointer using wrapping arithmetic.\n-    /// (convenience for `.wrapping_offset((count as isize).wrapping_sub())`)\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// The resulting pointer does not need to be in bounds, but it is\n-    /// potentially hazardous to dereference (which requires `unsafe`).\n-    ///\n-    /// In particular, the resulting pointer remains attached to the same allocated\n-    /// object that `self` points to. It may *not* be used to access a\n-    /// different allocated object. Note that in Rust,\n-    /// every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// Compared to [`sub`], this method basically delays the requirement of staying\n-    /// within the same allocated object: [`sub`] is immediate Undefined Behavior when\n-    /// crossing object boundaries; `wrapping_sub` produces a pointer but still leads\n-    /// to Undefined Behavior if that pointer is dereferenced. [`sub`] can be optimized\n-    /// better and is thus preferrable in performance-sensitive code.\n-    ///\n-    /// If you need to cross object boundaries, cast the pointer to an integer and\n-    /// do the arithmetic there.\n-    ///\n-    /// [`sub`]: #method.sub\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// // Iterate using a raw pointer in increments of two elements (backwards)\n-    /// let data = [1u8, 2, 3, 4, 5];\n-    /// let mut ptr: *const u8 = data.as_ptr();\n-    /// let start_rounded_down = ptr.wrapping_sub(2);\n-    /// ptr = ptr.wrapping_add(4);\n-    /// let step = 2;\n-    /// // This loop prints \"5, 3, 1, \"\n-    /// while ptr != start_rounded_down {\n-    ///     unsafe {\n-    ///         print!(\"{}, \", *ptr);\n-    ///     }\n-    ///     ptr = ptr.wrapping_sub(step);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub fn wrapping_sub(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.wrapping_offset((count as isize).wrapping_neg())\n-    }\n-\n-    /// Reads the value from `self` without moving it. This leaves the\n-    /// memory in `self` unchanged.\n-    ///\n-    /// See [`ptr::read`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::read`]: ./ptr/fn.read.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn read(self) -> T\n-    where\n-        T: Sized,\n-    {\n-        read(self)\n-    }\n-\n-    /// Performs a volatile read of the value from `self` without moving it. This\n-    /// leaves the memory in `self` unchanged.\n-    ///\n-    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n-    /// to not be elided or reordered by the compiler across other volatile\n-    /// operations.\n-    ///\n-    /// See [`ptr::read_volatile`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::read_volatile`]: ./ptr/fn.read_volatile.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn read_volatile(self) -> T\n-    where\n-        T: Sized,\n-    {\n-        read_volatile(self)\n-    }\n-\n-    /// Reads the value from `self` without moving it. This leaves the\n-    /// memory in `self` unchanged.\n-    ///\n-    /// Unlike `read`, the pointer may be unaligned.\n-    ///\n-    /// See [`ptr::read_unaligned`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::read_unaligned`]: ./ptr/fn.read_unaligned.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn read_unaligned(self) -> T\n-    where\n-        T: Sized,\n-    {\n-        read_unaligned(self)\n-    }\n-\n-    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n-    /// and destination may overlap.\n-    ///\n-    /// NOTE: this has the *same* argument order as [`ptr::copy`].\n-    ///\n-    /// See [`ptr::copy`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::copy`]: ./ptr/fn.copy.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn copy_to(self, dest: *mut T, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        copy(self, dest, count)\n-    }\n-\n-    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n-    /// and destination may *not* overlap.\n-    ///\n-    /// NOTE: this has the *same* argument order as [`ptr::copy_nonoverlapping`].\n-    ///\n-    /// See [`ptr::copy_nonoverlapping`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::copy_nonoverlapping`]: ./ptr/fn.copy_nonoverlapping.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        copy_nonoverlapping(self, dest, count)\n-    }\n-\n-    /// Computes the offset that needs to be applied to the pointer in order to make it aligned to\n-    /// `align`.\n-    ///\n-    /// If it is not possible to align the pointer, the implementation returns\n-    /// `usize::max_value()`. It is permissible for the implementation to *always*\n-    /// return `usize::max_value()`. Only your algorithm's performance can depend\n-    /// on getting a usable offset here, not its correctness.\n-    ///\n-    /// The offset is expressed in number of `T` elements, and not bytes. The value returned can be\n-    /// used with the `wrapping_add` method.\n-    ///\n-    /// There are no guarantees whatsoever that offsetting the pointer will not overflow or go\n-    /// beyond the allocation that the pointer points into. It is up to the caller to ensure that\n-    /// the returned offset is correct in all terms other than alignment.\n-    ///\n-    /// # Panics\n-    ///\n-    /// The function panics if `align` is not a power-of-two.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Accessing adjacent `u8` as `u16`\n-    ///\n-    /// ```\n-    /// # fn foo(n: usize) {\n-    /// # use std::mem::align_of;\n-    /// # unsafe {\n-    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n-    /// let ptr = &x[n] as *const u8;\n-    /// let offset = ptr.align_offset(align_of::<u16>());\n-    /// if offset < x.len() - n - 1 {\n-    ///     let u16_ptr = ptr.add(offset) as *const u16;\n-    ///     assert_ne!(*u16_ptr, 500);\n-    /// } else {\n-    ///     // while the pointer can be aligned via `offset`, it would point\n-    ///     // outside the allocation\n-    /// }\n-    /// # } }\n-    /// ```\n-    #[stable(feature = \"align_offset\", since = \"1.36.0\")]\n-    pub fn align_offset(self, align: usize) -> usize\n-    where\n-        T: Sized,\n-    {\n-        if !align.is_power_of_two() {\n-            panic!(\"align_offset: align is not a power-of-two\");\n-        }\n-        unsafe { align_offset(self, align) }\n-    }\n-}\n-\n-#[lang = \"mut_ptr\"]\n-impl<T: ?Sized> *mut T {\n-    /// Returns `true` if the pointer is null.\n-    ///\n-    /// Note that unsized types have many possible null pointers, as only the\n-    /// raw data pointer is considered, not their length, vtable, etc.\n-    /// Therefore, two pointers that are null may still not compare equal to\n-    /// each other.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let mut s = [1, 2, 3];\n-    /// let ptr: *mut u32 = s.as_mut_ptr();\n-    /// assert!(!ptr.is_null());\n-    /// ```\n-    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n-    #[inline]\n-    pub fn is_null(self) -> bool {\n-        // Compare via a cast to a thin pointer, so fat pointers are only\n-        // considering their \"data\" part for null-ness.\n-        (self as *mut u8) == null_mut()\n-    }\n-\n-    /// Casts to a pointer of another type.\n-    #[stable(feature = \"ptr_cast\", since = \"1.38.0\")]\n-    #[rustc_const_stable(feature = \"const_ptr_cast\", since = \"1.38.0\")]\n-    #[inline]\n-    pub const fn cast<U>(self) -> *mut U {\n-        self as _\n-    }\n-\n-    /// Returns `None` if the pointer is null, or else returns a reference to\n-    /// the value wrapped in `Some`.\n-    ///\n-    /// # Safety\n-    ///\n-    /// While this method and its mutable counterpart are useful for\n-    /// null-safety, it is important to note that this is still an unsafe\n-    /// operation because the returned value could be pointing to invalid\n-    /// memory.\n-    ///\n-    /// When calling this method, you have to ensure that if the pointer is\n-    /// non-NULL, then it is properly aligned, dereferencable (for the whole\n-    /// size of `T`) and points to an initialized instance of `T`. This applies\n-    /// even if the result of this method is unused!\n-    /// (The part about being initialized is not yet fully decided, but until\n-    /// it is, the only safe approach is to ensure that they are indeed initialized.)\n-    ///\n-    /// Additionally, the lifetime `'a` returned is arbitrarily chosen and does\n-    /// not necessarily reflect the actual lifetime of the data. It is up to the\n-    /// caller to ensure that for the duration of this lifetime, the memory this\n-    /// pointer points to does not get written to outside of `UnsafeCell<U>`.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let ptr: *mut u8 = &mut 10u8 as *mut u8;\n-    ///\n-    /// unsafe {\n-    ///     if let Some(val_back) = ptr.as_ref() {\n-    ///         println!(\"We got back the value: {}!\", val_back);\n-    ///     }\n-    /// }\n-    /// ```\n-    ///\n-    /// # Null-unchecked version\n-    ///\n-    /// If you are sure the pointer can never be null and are looking for some kind of\n-    /// `as_ref_unchecked` that returns the `&T` instead of `Option<&T>`, know that you can\n-    /// dereference the pointer directly.\n-    ///\n-    /// ```\n-    /// let ptr: *mut u8 = &mut 10u8 as *mut u8;\n-    ///\n-    /// unsafe {\n-    ///     let val_back = &*ptr;\n-    ///     println!(\"We got back the value: {}!\", val_back);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"ptr_as_ref\", since = \"1.9.0\")]\n-    #[inline]\n-    pub unsafe fn as_ref<'a>(self) -> Option<&'a T> {\n-        if self.is_null() { None } else { Some(&*self) }\n-    }\n-\n-    /// Calculates the offset from a pointer.\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and resulting pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n-    ///\n-    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n-    ///   space. That is, the infinite-precision sum, **in bytes** must fit in a usize.\n-    ///\n-    /// The compiler and standard library generally tries to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `vec.as_ptr().add(vec.len())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_offset`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// [`wrapping_offset`]: #method.wrapping_offset\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let mut s = [1, 2, 3];\n-    /// let ptr: *mut u32 = s.as_mut_ptr();\n-    ///\n-    /// unsafe {\n-    ///     println!(\"{}\", *ptr.offset(1));\n-    ///     println!(\"{}\", *ptr.offset(2));\n-    /// }\n-    /// ```\n-    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n-    #[inline]\n-    pub unsafe fn offset(self, count: isize) -> *mut T\n-    where\n-        T: Sized,\n-    {\n-        intrinsics::offset(self, count) as *mut T\n-    }\n-\n-    /// Calculates the offset from a pointer using wrapping arithmetic.\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// The resulting pointer does not need to be in bounds, but it is\n-    /// potentially hazardous to dereference (which requires `unsafe`).\n-    ///\n-    /// In particular, the resulting pointer remains attached to the same allocated\n-    /// object that `self` points to. It may *not* be used to access a\n-    /// different allocated object. Note that in Rust,\n-    /// every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// In other words, `x.wrapping_offset(y.wrapping_offset_from(x))` is\n-    /// *not* the same as `y`, and dereferencing it is undefined behavior\n-    /// unless `x` and `y` point into the same allocated object.\n-    ///\n-    /// Compared to [`offset`], this method basically delays the requirement of staying\n-    /// within the same allocated object: [`offset`] is immediate Undefined Behavior when\n-    /// crossing object boundaries; `wrapping_offset` produces a pointer but still leads\n-    /// to Undefined Behavior if that pointer is dereferenced. [`offset`] can be optimized\n-    /// better and is thus preferrable in performance-sensitive code.\n-    ///\n-    /// If you need to cross object boundaries, cast the pointer to an integer and\n-    /// do the arithmetic there.\n-    ///\n-    /// [`offset`]: #method.offset\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// // Iterate using a raw pointer in increments of two elements\n-    /// let mut data = [1u8, 2, 3, 4, 5];\n-    /// let mut ptr: *mut u8 = data.as_mut_ptr();\n-    /// let step = 2;\n-    /// let end_rounded_up = ptr.wrapping_offset(6);\n-    ///\n-    /// while ptr != end_rounded_up {\n-    ///     unsafe {\n-    ///         *ptr = 0;\n-    ///     }\n-    ///     ptr = ptr.wrapping_offset(step);\n-    /// }\n-    /// assert_eq!(&data, &[0, 2, 0, 4, 0]);\n-    /// ```\n-    #[stable(feature = \"ptr_wrapping_offset\", since = \"1.16.0\")]\n-    #[inline]\n-    pub fn wrapping_offset(self, count: isize) -> *mut T\n-    where\n-        T: Sized,\n-    {\n-        unsafe { intrinsics::arith_offset(self, count) as *mut T }\n-    }\n-\n-    /// Returns `None` if the pointer is null, or else returns a mutable\n-    /// reference to the value wrapped in `Some`.\n-    ///\n-    /// # Safety\n-    ///\n-    /// As with [`as_ref`], this is unsafe because it cannot verify the validity\n-    /// of the returned pointer, nor can it ensure that the lifetime `'a`\n-    /// returned is indeed a valid lifetime for the contained data.\n-    ///\n-    /// When calling this method, you have to ensure that *either* the pointer is NULL *or*\n-    /// all of the following is true:\n-    /// - it is properly aligned\n-    /// - it must point to an initialized instance of T; in particular, the pointer must be\n-    ///   \"dereferencable\" in the sense defined [here].\n-    ///\n-    /// This applies even if the result of this method is unused!\n-    /// (The part about being initialized is not yet fully decided, but until\n-    /// it is the only safe approach is to ensure that they are indeed initialized.)\n-    ///\n-    /// Additionally, the lifetime `'a` returned is arbitrarily chosen and does\n-    /// not necessarily reflect the actual lifetime of the data. *You* must enforce\n-    /// Rust's aliasing rules. In particular, for the duration of this lifetime,\n-    /// the memory this pointer points to must not get accessed (read or written)\n-    /// through any other pointer.\n-    ///\n-    /// [here]: crate::ptr#safety\n-    /// [`as_ref`]: #method.as_ref\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let mut s = [1, 2, 3];\n-    /// let ptr: *mut u32 = s.as_mut_ptr();\n-    /// let first_value = unsafe { ptr.as_mut().unwrap() };\n-    /// *first_value = 4;\n-    /// println!(\"{:?}\", s); // It'll print: \"[4, 2, 3]\".\n-    /// ```\n-    #[stable(feature = \"ptr_as_ref\", since = \"1.9.0\")]\n-    #[inline]\n-    pub unsafe fn as_mut<'a>(self) -> Option<&'a mut T> {\n-        if self.is_null() { None } else { Some(&mut *self) }\n-    }\n-\n-    /// Calculates the distance between two pointers. The returned value is in\n-    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n-    ///\n-    /// This function is the inverse of [`offset`].\n-    ///\n-    /// [`offset`]: #method.offset-1\n-    /// [`wrapping_offset_from`]: #method.wrapping_offset_from-1\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and other pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The distance between the pointers, **in bytes**, cannot overflow an `isize`.\n-    ///\n-    /// * The distance between the pointers, in bytes, must be an exact multiple\n-    ///   of the size of `T`.\n-    ///\n-    /// * The distance being in bounds cannot rely on \"wrapping around\" the address space.\n-    ///\n-    /// The compiler and standard library generally try to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `ptr_into_vec.offset_from(vec.as_ptr())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_offset_from`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// # Panics\n-    ///\n-    /// This function panics if `T` is a Zero-Sized Type (\"ZST\").\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// #![feature(ptr_offset_from)]\n-    ///\n-    /// let mut a = [0; 5];\n-    /// let ptr1: *mut i32 = &mut a[1];\n-    /// let ptr2: *mut i32 = &mut a[3];\n-    /// unsafe {\n-    ///     assert_eq!(ptr2.offset_from(ptr1), 2);\n-    ///     assert_eq!(ptr1.offset_from(ptr2), -2);\n-    ///     assert_eq!(ptr1.offset(2), ptr2);\n-    ///     assert_eq!(ptr2.offset(-2), ptr1);\n-    /// }\n-    /// ```\n-    #[unstable(feature = \"ptr_offset_from\", issue = \"41079\")]\n-    #[rustc_const_unstable(feature = \"const_ptr_offset_from\", issue = \"41079\")]\n-    #[inline]\n-    pub const unsafe fn offset_from(self, origin: *const T) -> isize\n-    where\n-        T: Sized,\n-    {\n-        (self as *const T).offset_from(origin)\n-    }\n-\n-    /// Calculates the distance between two pointers. The returned value is in\n-    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n-    ///\n-    /// If the address different between the two pointers is not a multiple of\n-    /// `mem::size_of::<T>()` then the result of the division is rounded towards\n-    /// zero.\n-    ///\n-    /// Though this method is safe for any two pointers, note that its result\n-    /// will be mostly useless if the two pointers aren't into the same allocated\n-    /// object, for example if they point to two different local variables.\n-    ///\n-    /// # Panics\n-    ///\n-    /// This function panics if `T` is a zero-sized type.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// #![feature(ptr_wrapping_offset_from)]\n-    ///\n-    /// let mut a = [0; 5];\n-    /// let ptr1: *mut i32 = &mut a[1];\n-    /// let ptr2: *mut i32 = &mut a[3];\n-    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n-    /// assert_eq!(ptr1.wrapping_offset_from(ptr2), -2);\n-    /// assert_eq!(ptr1.wrapping_offset(2), ptr2);\n-    /// assert_eq!(ptr2.wrapping_offset(-2), ptr1);\n-    ///\n-    /// let ptr1: *mut i32 = 3 as _;\n-    /// let ptr2: *mut i32 = 13 as _;\n-    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n-    /// ```\n-    #[unstable(feature = \"ptr_wrapping_offset_from\", issue = \"41079\")]\n-    #[inline]\n-    pub fn wrapping_offset_from(self, origin: *const T) -> isize\n-    where\n-        T: Sized,\n-    {\n-        (self as *const T).wrapping_offset_from(origin)\n-    }\n-\n-    /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and resulting pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n-    ///\n-    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n-    ///   space. That is, the infinite-precision sum must fit in a `usize`.\n-    ///\n-    /// The compiler and standard library generally tries to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `vec.as_ptr().add(vec.len())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_add`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// [`wrapping_add`]: #method.wrapping_add\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let s: &str = \"123\";\n-    /// let ptr: *const u8 = s.as_ptr();\n-    ///\n-    /// unsafe {\n-    ///     println!(\"{}\", *ptr.add(1) as char);\n-    ///     println!(\"{}\", *ptr.add(2) as char);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn add(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.offset(count as isize)\n-    }\n-\n-    /// Calculates the offset from a pointer (convenience for\n-    /// `.offset((count as isize).wrapping_neg())`).\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// If any of the following conditions are violated, the result is Undefined\n-    /// Behavior:\n-    ///\n-    /// * Both the starting and resulting pointer must be either in bounds or one\n-    ///   byte past the end of the same allocated object. Note that in Rust,\n-    ///   every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// * The computed offset cannot exceed `isize::MAX` **bytes**.\n-    ///\n-    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n-    ///   space. That is, the infinite-precision sum must fit in a usize.\n-    ///\n-    /// The compiler and standard library generally tries to ensure allocations\n-    /// never reach a size where an offset is a concern. For instance, `Vec`\n-    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n-    /// `vec.as_ptr().add(vec.len()).sub(vec.len())` is always safe.\n-    ///\n-    /// Most platforms fundamentally can't even construct such an allocation.\n-    /// For instance, no known 64-bit platform can ever serve a request\n-    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n-    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n-    /// more than `isize::MAX` bytes with things like Physical Address\n-    /// Extension. As such, memory acquired directly from allocators or memory\n-    /// mapped files *may* be too large to handle with this function.\n-    ///\n-    /// Consider using [`wrapping_sub`] instead if these constraints are\n-    /// difficult to satisfy. The only advantage of this method is that it\n-    /// enables more aggressive compiler optimizations.\n-    ///\n-    /// [`wrapping_sub`]: #method.wrapping_sub\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// let s: &str = \"123\";\n-    ///\n-    /// unsafe {\n-    ///     let end: *const u8 = s.as_ptr().add(3);\n-    ///     println!(\"{}\", *end.sub(1) as char);\n-    ///     println!(\"{}\", *end.sub(2) as char);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn sub(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.offset((count as isize).wrapping_neg())\n-    }\n-\n-    /// Calculates the offset from a pointer using wrapping arithmetic.\n-    /// (convenience for `.wrapping_offset(count as isize)`)\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// The resulting pointer does not need to be in bounds, but it is\n-    /// potentially hazardous to dereference (which requires `unsafe`).\n-    ///\n-    /// In particular, the resulting pointer remains attached to the same allocated\n-    /// object that `self` points to. It may *not* be used to access a\n-    /// different allocated object. Note that in Rust,\n-    /// every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// Compared to [`add`], this method basically delays the requirement of staying\n-    /// within the same allocated object: [`add`] is immediate Undefined Behavior when\n-    /// crossing object boundaries; `wrapping_add` produces a pointer but still leads\n-    /// to Undefined Behavior if that pointer is dereferenced. [`add`] can be optimized\n-    /// better and is thus preferrable in performance-sensitive code.\n-    ///\n-    /// If you need to cross object boundaries, cast the pointer to an integer and\n-    /// do the arithmetic there.\n-    ///\n-    /// [`add`]: #method.add\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// // Iterate using a raw pointer in increments of two elements\n-    /// let data = [1u8, 2, 3, 4, 5];\n-    /// let mut ptr: *const u8 = data.as_ptr();\n-    /// let step = 2;\n-    /// let end_rounded_up = ptr.wrapping_add(6);\n-    ///\n-    /// // This loop prints \"1, 3, 5, \"\n-    /// while ptr != end_rounded_up {\n-    ///     unsafe {\n-    ///         print!(\"{}, \", *ptr);\n-    ///     }\n-    ///     ptr = ptr.wrapping_add(step);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub fn wrapping_add(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.wrapping_offset(count as isize)\n-    }\n-\n-    /// Calculates the offset from a pointer using wrapping arithmetic.\n-    /// (convenience for `.wrapping_offset((count as isize).wrapping_sub())`)\n-    ///\n-    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n-    /// offset of `3 * size_of::<T>()` bytes.\n-    ///\n-    /// # Safety\n-    ///\n-    /// The resulting pointer does not need to be in bounds, but it is\n-    /// potentially hazardous to dereference (which requires `unsafe`).\n-    ///\n-    /// In particular, the resulting pointer remains attached to the same allocated\n-    /// object that `self` points to. It may *not* be used to access a\n-    /// different allocated object. Note that in Rust,\n-    /// every (stack-allocated) variable is considered a separate allocated object.\n-    ///\n-    /// Compared to [`sub`], this method basically delays the requirement of staying\n-    /// within the same allocated object: [`sub`] is immediate Undefined Behavior when\n-    /// crossing object boundaries; `wrapping_sub` produces a pointer but still leads\n-    /// to Undefined Behavior if that pointer is dereferenced. [`sub`] can be optimized\n-    /// better and is thus preferrable in performance-sensitive code.\n-    ///\n-    /// If you need to cross object boundaries, cast the pointer to an integer and\n-    /// do the arithmetic there.\n-    ///\n-    /// [`sub`]: #method.sub\n-    ///\n-    /// # Examples\n-    ///\n-    /// Basic usage:\n-    ///\n-    /// ```\n-    /// // Iterate using a raw pointer in increments of two elements (backwards)\n-    /// let data = [1u8, 2, 3, 4, 5];\n-    /// let mut ptr: *const u8 = data.as_ptr();\n-    /// let start_rounded_down = ptr.wrapping_sub(2);\n-    /// ptr = ptr.wrapping_add(4);\n-    /// let step = 2;\n-    /// // This loop prints \"5, 3, 1, \"\n-    /// while ptr != start_rounded_down {\n-    ///     unsafe {\n-    ///         print!(\"{}, \", *ptr);\n-    ///     }\n-    ///     ptr = ptr.wrapping_sub(step);\n-    /// }\n-    /// ```\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub fn wrapping_sub(self, count: usize) -> Self\n-    where\n-        T: Sized,\n-    {\n-        self.wrapping_offset((count as isize).wrapping_neg())\n-    }\n-\n-    /// Reads the value from `self` without moving it. This leaves the\n-    /// memory in `self` unchanged.\n-    ///\n-    /// See [`ptr::read`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::read`]: ./ptr/fn.read.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn read(self) -> T\n-    where\n-        T: Sized,\n-    {\n-        read(self)\n-    }\n-\n-    /// Performs a volatile read of the value from `self` without moving it. This\n-    /// leaves the memory in `self` unchanged.\n-    ///\n-    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n-    /// to not be elided or reordered by the compiler across other volatile\n-    /// operations.\n-    ///\n-    /// See [`ptr::read_volatile`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::read_volatile`]: ./ptr/fn.read_volatile.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn read_volatile(self) -> T\n-    where\n-        T: Sized,\n-    {\n-        read_volatile(self)\n-    }\n-\n-    /// Reads the value from `self` without moving it. This leaves the\n-    /// memory in `self` unchanged.\n-    ///\n-    /// Unlike `read`, the pointer may be unaligned.\n-    ///\n-    /// See [`ptr::read_unaligned`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::read_unaligned`]: ./ptr/fn.read_unaligned.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn read_unaligned(self) -> T\n-    where\n-        T: Sized,\n-    {\n-        read_unaligned(self)\n-    }\n-\n-    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n-    /// and destination may overlap.\n-    ///\n-    /// NOTE: this has the *same* argument order as [`ptr::copy`].\n-    ///\n-    /// See [`ptr::copy`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::copy`]: ./ptr/fn.copy.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn copy_to(self, dest: *mut T, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        copy(self, dest, count)\n-    }\n-\n-    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n-    /// and destination may *not* overlap.\n-    ///\n-    /// NOTE: this has the *same* argument order as [`ptr::copy_nonoverlapping`].\n-    ///\n-    /// See [`ptr::copy_nonoverlapping`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::copy_nonoverlapping`]: ./ptr/fn.copy_nonoverlapping.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        copy_nonoverlapping(self, dest, count)\n-    }\n-\n-    /// Copies `count * size_of<T>` bytes from `src` to `self`. The source\n-    /// and destination may overlap.\n-    ///\n-    /// NOTE: this has the *opposite* argument order of [`ptr::copy`].\n-    ///\n-    /// See [`ptr::copy`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::copy`]: ./ptr/fn.copy.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn copy_from(self, src: *const T, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        copy(src, self, count)\n-    }\n-\n-    /// Copies `count * size_of<T>` bytes from `src` to `self`. The source\n-    /// and destination may *not* overlap.\n-    ///\n-    /// NOTE: this has the *opposite* argument order of [`ptr::copy_nonoverlapping`].\n-    ///\n-    /// See [`ptr::copy_nonoverlapping`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::copy_nonoverlapping`]: ./ptr/fn.copy_nonoverlapping.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn copy_from_nonoverlapping(self, src: *const T, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        copy_nonoverlapping(src, self, count)\n-    }\n-\n-    /// Executes the destructor (if any) of the pointed-to value.\n-    ///\n-    /// See [`ptr::drop_in_place`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::drop_in_place`]: ./ptr/fn.drop_in_place.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn drop_in_place(self) {\n-        drop_in_place(self)\n-    }\n-\n-    /// Overwrites a memory location with the given value without reading or\n-    /// dropping the old value.\n-    ///\n-    /// See [`ptr::write`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::write`]: ./ptr/fn.write.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn write(self, val: T)\n-    where\n-        T: Sized,\n-    {\n-        write(self, val)\n-    }\n-\n-    /// Invokes memset on the specified pointer, setting `count * size_of::<T>()`\n-    /// bytes of memory starting at `self` to `val`.\n-    ///\n-    /// See [`ptr::write_bytes`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::write_bytes`]: ./ptr/fn.write_bytes.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn write_bytes(self, val: u8, count: usize)\n-    where\n-        T: Sized,\n-    {\n-        write_bytes(self, val, count)\n-    }\n-\n-    /// Performs a volatile write of a memory location with the given value without\n-    /// reading or dropping the old value.\n-    ///\n-    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n-    /// to not be elided or reordered by the compiler across other volatile\n-    /// operations.\n-    ///\n-    /// See [`ptr::write_volatile`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::write_volatile`]: ./ptr/fn.write_volatile.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn write_volatile(self, val: T)\n-    where\n-        T: Sized,\n-    {\n-        write_volatile(self, val)\n-    }\n-\n-    /// Overwrites a memory location with the given value without reading or\n-    /// dropping the old value.\n-    ///\n-    /// Unlike `write`, the pointer may be unaligned.\n-    ///\n-    /// See [`ptr::write_unaligned`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::write_unaligned`]: ./ptr/fn.write_unaligned.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn write_unaligned(self, val: T)\n-    where\n-        T: Sized,\n-    {\n-        write_unaligned(self, val)\n-    }\n-\n-    /// Replaces the value at `self` with `src`, returning the old\n-    /// value, without dropping either.\n-    ///\n-    /// See [`ptr::replace`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::replace`]: ./ptr/fn.replace.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn replace(self, src: T) -> T\n-    where\n-        T: Sized,\n-    {\n-        replace(self, src)\n-    }\n-\n-    /// Swaps the values at two mutable locations of the same type, without\n-    /// deinitializing either. They may overlap, unlike `mem::swap` which is\n-    /// otherwise equivalent.\n-    ///\n-    /// See [`ptr::swap`] for safety concerns and examples.\n-    ///\n-    /// [`ptr::swap`]: ./ptr/fn.swap.html\n-    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n-    #[inline]\n-    pub unsafe fn swap(self, with: *mut T)\n-    where\n-        T: Sized,\n-    {\n-        swap(self, with)\n-    }\n-\n-    /// Computes the offset that needs to be applied to the pointer in order to make it aligned to\n-    /// `align`.\n-    ///\n-    /// If it is not possible to align the pointer, the implementation returns\n-    /// `usize::max_value()`. It is permissible for the implementation to *always*\n-    /// return `usize::max_value()`. Only your algorithm's performance can depend\n-    /// on getting a usable offset here, not its correctness.\n-    ///\n-    /// The offset is expressed in number of `T` elements, and not bytes. The value returned can be\n-    /// used with the `wrapping_add` method.\n-    ///\n-    /// There are no guarantees whatsoever that offsetting the pointer will not overflow or go\n-    /// beyond the allocation that the pointer points into. It is up to the caller to ensure that\n-    /// the returned offset is correct in all terms other than alignment.\n-    ///\n-    /// # Panics\n-    ///\n-    /// The function panics if `align` is not a power-of-two.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Accessing adjacent `u8` as `u16`\n-    ///\n-    /// ```\n-    /// # fn foo(n: usize) {\n-    /// # use std::mem::align_of;\n-    /// # unsafe {\n-    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n-    /// let ptr = &x[n] as *const u8;\n-    /// let offset = ptr.align_offset(align_of::<u16>());\n-    /// if offset < x.len() - n - 1 {\n-    ///     let u16_ptr = ptr.add(offset) as *const u16;\n-    ///     assert_ne!(*u16_ptr, 500);\n-    /// } else {\n-    ///     // while the pointer can be aligned via `offset`, it would point\n-    ///     // outside the allocation\n-    /// }\n-    /// # } }\n-    /// ```\n-    #[stable(feature = \"align_offset\", since = \"1.36.0\")]\n-    pub fn align_offset(self, align: usize) -> usize\n-    where\n-        T: Sized,\n-    {\n-        if !align.is_power_of_two() {\n-            panic!(\"align_offset: align is not a power-of-two\");\n-        }\n-        unsafe { align_offset(self, align) }\n-    }\n-}\n-\n /// Align pointer `p`.\n ///\n /// Calculate offset (in terms of elements of `stride` stride) that has to be applied\n@@ -2728,29 +1150,6 @@ pub(crate) unsafe fn align_offset<T: Sized>(p: *const T, a: usize) -> usize {\n     usize::max_value()\n }\n \n-// Equality for pointers\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> PartialEq for *const T {\n-    #[inline]\n-    fn eq(&self, other: &*const T) -> bool {\n-        *self == *other\n-    }\n-}\n-\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> Eq for *const T {}\n-\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> PartialEq for *mut T {\n-    #[inline]\n-    fn eq(&self, other: &*mut T) -> bool {\n-        *self == *other\n-    }\n-}\n-\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> Eq for *mut T {}\n-\n /// Compares raw pointers for equality.\n ///\n /// This is the same as using the `==` operator, but less generic:\n@@ -2944,88 +1343,3 @@ fnptr_impls_args! { A, B, C, D, E, F, G, H, I }\n fnptr_impls_args! { A, B, C, D, E, F, G, H, I, J }\n fnptr_impls_args! { A, B, C, D, E, F, G, H, I, J, K }\n fnptr_impls_args! { A, B, C, D, E, F, G, H, I, J, K, L }\n-\n-// Comparison for pointers\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> Ord for *const T {\n-    #[inline]\n-    fn cmp(&self, other: &*const T) -> Ordering {\n-        if self < other {\n-            Less\n-        } else if self == other {\n-            Equal\n-        } else {\n-            Greater\n-        }\n-    }\n-}\n-\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> PartialOrd for *const T {\n-    #[inline]\n-    fn partial_cmp(&self, other: &*const T) -> Option<Ordering> {\n-        Some(self.cmp(other))\n-    }\n-\n-    #[inline]\n-    fn lt(&self, other: &*const T) -> bool {\n-        *self < *other\n-    }\n-\n-    #[inline]\n-    fn le(&self, other: &*const T) -> bool {\n-        *self <= *other\n-    }\n-\n-    #[inline]\n-    fn gt(&self, other: &*const T) -> bool {\n-        *self > *other\n-    }\n-\n-    #[inline]\n-    fn ge(&self, other: &*const T) -> bool {\n-        *self >= *other\n-    }\n-}\n-\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> Ord for *mut T {\n-    #[inline]\n-    fn cmp(&self, other: &*mut T) -> Ordering {\n-        if self < other {\n-            Less\n-        } else if self == other {\n-            Equal\n-        } else {\n-            Greater\n-        }\n-    }\n-}\n-\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-impl<T: ?Sized> PartialOrd for *mut T {\n-    #[inline]\n-    fn partial_cmp(&self, other: &*mut T) -> Option<Ordering> {\n-        Some(self.cmp(other))\n-    }\n-\n-    #[inline]\n-    fn lt(&self, other: &*mut T) -> bool {\n-        *self < *other\n-    }\n-\n-    #[inline]\n-    fn le(&self, other: &*mut T) -> bool {\n-        *self <= *other\n-    }\n-\n-    #[inline]\n-    fn gt(&self, other: &*mut T) -> bool {\n-        *self > *other\n-    }\n-\n-    #[inline]\n-    fn ge(&self, other: &*mut T) -> bool {\n-        *self >= *other\n-    }\n-}"}, {"sha": "fd5decbd7eac5718aaa413f11d04e0b8c32f88ea", "filename": "src/libcore/ptr/mut_ptr.rs", "status": "added", "additions": 925, "deletions": 0, "changes": 925, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibcore%2Fptr%2Fmut_ptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibcore%2Fptr%2Fmut_ptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fptr%2Fmut_ptr.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -0,0 +1,925 @@\n+use crate::cmp::Ordering::{self, Less, Equal, Greater};\n+use crate::intrinsics;\n+use super::*;\n+\n+// ignore-tidy-undocumented-unsafe\n+\n+#[lang = \"mut_ptr\"]\n+impl<T: ?Sized> *mut T {\n+    /// Returns `true` if the pointer is null.\n+    ///\n+    /// Note that unsized types have many possible null pointers, as only the\n+    /// raw data pointer is considered, not their length, vtable, etc.\n+    /// Therefore, two pointers that are null may still not compare equal to\n+    /// each other.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let mut s = [1, 2, 3];\n+    /// let ptr: *mut u32 = s.as_mut_ptr();\n+    /// assert!(!ptr.is_null());\n+    /// ```\n+    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+    #[inline]\n+    pub fn is_null(self) -> bool {\n+        // Compare via a cast to a thin pointer, so fat pointers are only\n+        // considering their \"data\" part for null-ness.\n+        (self as *mut u8) == null_mut()\n+    }\n+\n+    /// Casts to a pointer of another type.\n+    #[stable(feature = \"ptr_cast\", since = \"1.38.0\")]\n+    #[rustc_const_stable(feature = \"const_ptr_cast\", since = \"1.38.0\")]\n+    #[inline]\n+    pub const fn cast<U>(self) -> *mut U {\n+        self as _\n+    }\n+\n+    /// Returns `None` if the pointer is null, or else returns a reference to\n+    /// the value wrapped in `Some`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// While this method and its mutable counterpart are useful for\n+    /// null-safety, it is important to note that this is still an unsafe\n+    /// operation because the returned value could be pointing to invalid\n+    /// memory.\n+    ///\n+    /// When calling this method, you have to ensure that if the pointer is\n+    /// non-NULL, then it is properly aligned, dereferencable (for the whole\n+    /// size of `T`) and points to an initialized instance of `T`. This applies\n+    /// even if the result of this method is unused!\n+    /// (The part about being initialized is not yet fully decided, but until\n+    /// it is, the only safe approach is to ensure that they are indeed initialized.)\n+    ///\n+    /// Additionally, the lifetime `'a` returned is arbitrarily chosen and does\n+    /// not necessarily reflect the actual lifetime of the data. It is up to the\n+    /// caller to ensure that for the duration of this lifetime, the memory this\n+    /// pointer points to does not get written to outside of `UnsafeCell<U>`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let ptr: *mut u8 = &mut 10u8 as *mut u8;\n+    ///\n+    /// unsafe {\n+    ///     if let Some(val_back) = ptr.as_ref() {\n+    ///         println!(\"We got back the value: {}!\", val_back);\n+    ///     }\n+    /// }\n+    /// ```\n+    ///\n+    /// # Null-unchecked version\n+    ///\n+    /// If you are sure the pointer can never be null and are looking for some kind of\n+    /// `as_ref_unchecked` that returns the `&T` instead of `Option<&T>`, know that you can\n+    /// dereference the pointer directly.\n+    ///\n+    /// ```\n+    /// let ptr: *mut u8 = &mut 10u8 as *mut u8;\n+    ///\n+    /// unsafe {\n+    ///     let val_back = &*ptr;\n+    ///     println!(\"We got back the value: {}!\", val_back);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"ptr_as_ref\", since = \"1.9.0\")]\n+    #[inline]\n+    pub unsafe fn as_ref<'a>(self) -> Option<&'a T> {\n+        if self.is_null() { None } else { Some(&*self) }\n+    }\n+\n+    /// Calculates the offset from a pointer.\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum, **in bytes** must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_offset`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// [`wrapping_offset`]: #method.wrapping_offset\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let mut s = [1, 2, 3];\n+    /// let ptr: *mut u32 = s.as_mut_ptr();\n+    ///\n+    /// unsafe {\n+    ///     println!(\"{}\", *ptr.offset(1));\n+    ///     println!(\"{}\", *ptr.offset(2));\n+    /// }\n+    /// ```\n+    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+    #[inline]\n+    pub unsafe fn offset(self, count: isize) -> *mut T\n+        where\n+            T: Sized,\n+    {\n+        intrinsics::offset(self, count) as *mut T\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// In particular, the resulting pointer remains attached to the same allocated\n+    /// object that `self` points to. It may *not* be used to access a\n+    /// different allocated object. Note that in Rust,\n+    /// every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// In other words, `x.wrapping_offset(y.wrapping_offset_from(x))` is\n+    /// *not* the same as `y`, and dereferencing it is undefined behavior\n+    /// unless `x` and `y` point into the same allocated object.\n+    ///\n+    /// Compared to [`offset`], this method basically delays the requirement of staying\n+    /// within the same allocated object: [`offset`] is immediate Undefined Behavior when\n+    /// crossing object boundaries; `wrapping_offset` produces a pointer but still leads\n+    /// to Undefined Behavior if that pointer is dereferenced. [`offset`] can be optimized\n+    /// better and is thus preferrable in performance-sensitive code.\n+    ///\n+    /// If you need to cross object boundaries, cast the pointer to an integer and\n+    /// do the arithmetic there.\n+    ///\n+    /// [`offset`]: #method.offset\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// // Iterate using a raw pointer in increments of two elements\n+    /// let mut data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *mut u8 = data.as_mut_ptr();\n+    /// let step = 2;\n+    /// let end_rounded_up = ptr.wrapping_offset(6);\n+    ///\n+    /// while ptr != end_rounded_up {\n+    ///     unsafe {\n+    ///         *ptr = 0;\n+    ///     }\n+    ///     ptr = ptr.wrapping_offset(step);\n+    /// }\n+    /// assert_eq!(&data, &[0, 2, 0, 4, 0]);\n+    /// ```\n+    #[stable(feature = \"ptr_wrapping_offset\", since = \"1.16.0\")]\n+    #[inline]\n+    pub fn wrapping_offset(self, count: isize) -> *mut T\n+        where\n+            T: Sized,\n+    {\n+        unsafe { intrinsics::arith_offset(self, count) as *mut T }\n+    }\n+\n+    /// Returns `None` if the pointer is null, or else returns a mutable\n+    /// reference to the value wrapped in `Some`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// As with [`as_ref`], this is unsafe because it cannot verify the validity\n+    /// of the returned pointer, nor can it ensure that the lifetime `'a`\n+    /// returned is indeed a valid lifetime for the contained data.\n+    ///\n+    /// When calling this method, you have to ensure that *either* the pointer is NULL *or*\n+    /// all of the following is true:\n+    /// - it is properly aligned\n+    /// - it must point to an initialized instance of T; in particular, the pointer must be\n+    ///   \"dereferencable\" in the sense defined [here].\n+    ///\n+    /// This applies even if the result of this method is unused!\n+    /// (The part about being initialized is not yet fully decided, but until\n+    /// it is the only safe approach is to ensure that they are indeed initialized.)\n+    ///\n+    /// Additionally, the lifetime `'a` returned is arbitrarily chosen and does\n+    /// not necessarily reflect the actual lifetime of the data. *You* must enforce\n+    /// Rust's aliasing rules. In particular, for the duration of this lifetime,\n+    /// the memory this pointer points to must not get accessed (read or written)\n+    /// through any other pointer.\n+    ///\n+    /// [here]: crate::ptr#safety\n+    /// [`as_ref`]: #method.as_ref\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let mut s = [1, 2, 3];\n+    /// let ptr: *mut u32 = s.as_mut_ptr();\n+    /// let first_value = unsafe { ptr.as_mut().unwrap() };\n+    /// *first_value = 4;\n+    /// println!(\"{:?}\", s); // It'll print: \"[4, 2, 3]\".\n+    /// ```\n+    #[stable(feature = \"ptr_as_ref\", since = \"1.9.0\")]\n+    #[inline]\n+    pub unsafe fn as_mut<'a>(self) -> Option<&'a mut T> {\n+        if self.is_null() { None } else { Some(&mut *self) }\n+    }\n+\n+    /// Calculates the distance between two pointers. The returned value is in\n+    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n+    ///\n+    /// This function is the inverse of [`offset`].\n+    ///\n+    /// [`offset`]: #method.offset-1\n+    /// [`wrapping_offset_from`]: #method.wrapping_offset_from-1\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and other pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The distance between the pointers, **in bytes**, cannot overflow an `isize`.\n+    ///\n+    /// * The distance between the pointers, in bytes, must be an exact multiple\n+    ///   of the size of `T`.\n+    ///\n+    /// * The distance being in bounds cannot rely on \"wrapping around\" the address space.\n+    ///\n+    /// The compiler and standard library generally try to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `ptr_into_vec.offset_from(vec.as_ptr())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_offset_from`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function panics if `T` is a Zero-Sized Type (\"ZST\").\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(ptr_offset_from)]\n+    ///\n+    /// let mut a = [0; 5];\n+    /// let ptr1: *mut i32 = &mut a[1];\n+    /// let ptr2: *mut i32 = &mut a[3];\n+    /// unsafe {\n+    ///     assert_eq!(ptr2.offset_from(ptr1), 2);\n+    ///     assert_eq!(ptr1.offset_from(ptr2), -2);\n+    ///     assert_eq!(ptr1.offset(2), ptr2);\n+    ///     assert_eq!(ptr2.offset(-2), ptr1);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"ptr_offset_from\", issue = \"41079\")]\n+    #[rustc_const_unstable(feature = \"const_ptr_offset_from\", issue = \"41079\")]\n+    #[inline]\n+    pub const unsafe fn offset_from(self, origin: *const T) -> isize\n+        where\n+            T: Sized,\n+    {\n+        (self as *const T).offset_from(origin)\n+    }\n+\n+    /// Calculates the distance between two pointers. The returned value is in\n+    /// units of T: the distance in bytes is divided by `mem::size_of::<T>()`.\n+    ///\n+    /// If the address different between the two pointers is not a multiple of\n+    /// `mem::size_of::<T>()` then the result of the division is rounded towards\n+    /// zero.\n+    ///\n+    /// Though this method is safe for any two pointers, note that its result\n+    /// will be mostly useless if the two pointers aren't into the same allocated\n+    /// object, for example if they point to two different local variables.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function panics if `T` is a zero-sized type.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(ptr_wrapping_offset_from)]\n+    ///\n+    /// let mut a = [0; 5];\n+    /// let ptr1: *mut i32 = &mut a[1];\n+    /// let ptr2: *mut i32 = &mut a[3];\n+    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n+    /// assert_eq!(ptr1.wrapping_offset_from(ptr2), -2);\n+    /// assert_eq!(ptr1.wrapping_offset(2), ptr2);\n+    /// assert_eq!(ptr2.wrapping_offset(-2), ptr1);\n+    ///\n+    /// let ptr1: *mut i32 = 3 as _;\n+    /// let ptr2: *mut i32 = 13 as _;\n+    /// assert_eq!(ptr2.wrapping_offset_from(ptr1), 2);\n+    /// ```\n+    #[unstable(feature = \"ptr_wrapping_offset_from\", issue = \"41079\")]\n+    #[inline]\n+    pub fn wrapping_offset_from(self, origin: *const T) -> isize\n+        where\n+            T: Sized,\n+    {\n+        (self as *const T).wrapping_offset_from(origin)\n+    }\n+\n+    /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow an `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a `usize`.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_add`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// [`wrapping_add`]: #method.wrapping_add\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let s: &str = \"123\";\n+    /// let ptr: *const u8 = s.as_ptr();\n+    ///\n+    /// unsafe {\n+    ///     println!(\"{}\", *ptr.add(1) as char);\n+    ///     println!(\"{}\", *ptr.add(2) as char);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn add(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer (convenience for\n+    /// `.offset((count as isize).wrapping_neg())`).\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of the same allocated object. Note that in Rust,\n+    ///   every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// * The computed offset cannot exceed `isize::MAX` **bytes**.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len()).sub(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2<sup>63</sup> bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using [`wrapping_sub`] instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// [`wrapping_sub`]: #method.wrapping_sub\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// let s: &str = \"123\";\n+    ///\n+    /// unsafe {\n+    ///     let end: *const u8 = s.as_ptr().add(3);\n+    ///     println!(\"{}\", *end.sub(1) as char);\n+    ///     println!(\"{}\", *end.sub(2) as char);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn sub(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset(count as isize)`)\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// In particular, the resulting pointer remains attached to the same allocated\n+    /// object that `self` points to. It may *not* be used to access a\n+    /// different allocated object. Note that in Rust,\n+    /// every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// Compared to [`add`], this method basically delays the requirement of staying\n+    /// within the same allocated object: [`add`] is immediate Undefined Behavior when\n+    /// crossing object boundaries; `wrapping_add` produces a pointer but still leads\n+    /// to Undefined Behavior if that pointer is dereferenced. [`add`] can be optimized\n+    /// better and is thus preferrable in performance-sensitive code.\n+    ///\n+    /// If you need to cross object boundaries, cast the pointer to an integer and\n+    /// do the arithmetic there.\n+    ///\n+    /// [`add`]: #method.add\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// // Iterate using a raw pointer in increments of two elements\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let step = 2;\n+    /// let end_rounded_up = ptr.wrapping_add(6);\n+    ///\n+    /// // This loop prints \"1, 3, 5, \"\n+    /// while ptr != end_rounded_up {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_add(step);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub fn wrapping_add(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.wrapping_offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset((count as isize).wrapping_sub())`)\n+    ///\n+    /// `count` is in units of T; e.g., a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// In particular, the resulting pointer remains attached to the same allocated\n+    /// object that `self` points to. It may *not* be used to access a\n+    /// different allocated object. Note that in Rust,\n+    /// every (stack-allocated) variable is considered a separate allocated object.\n+    ///\n+    /// Compared to [`sub`], this method basically delays the requirement of staying\n+    /// within the same allocated object: [`sub`] is immediate Undefined Behavior when\n+    /// crossing object boundaries; `wrapping_sub` produces a pointer but still leads\n+    /// to Undefined Behavior if that pointer is dereferenced. [`sub`] can be optimized\n+    /// better and is thus preferrable in performance-sensitive code.\n+    ///\n+    /// If you need to cross object boundaries, cast the pointer to an integer and\n+    /// do the arithmetic there.\n+    ///\n+    /// [`sub`]: #method.sub\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// // Iterate using a raw pointer in increments of two elements (backwards)\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let start_rounded_down = ptr.wrapping_sub(2);\n+    /// ptr = ptr.wrapping_add(4);\n+    /// let step = 2;\n+    /// // This loop prints \"5, 3, 1, \"\n+    /// while ptr != start_rounded_down {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_sub(step);\n+    /// }\n+    /// ```\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub fn wrapping_sub(self, count: usize) -> Self\n+        where\n+            T: Sized,\n+    {\n+        self.wrapping_offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// See [`ptr::read`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::read`]: ./ptr/fn.read.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn read(self) -> T\n+        where\n+            T: Sized,\n+    {\n+        read(self)\n+    }\n+\n+    /// Performs a volatile read of the value from `self` without moving it. This\n+    /// leaves the memory in `self` unchanged.\n+    ///\n+    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n+    /// to not be elided or reordered by the compiler across other volatile\n+    /// operations.\n+    ///\n+    /// See [`ptr::read_volatile`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::read_volatile`]: ./ptr/fn.read_volatile.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn read_volatile(self) -> T\n+        where\n+            T: Sized,\n+    {\n+        read_volatile(self)\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// Unlike `read`, the pointer may be unaligned.\n+    ///\n+    /// See [`ptr::read_unaligned`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::read_unaligned`]: ./ptr/fn.read_unaligned.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn read_unaligned(self) -> T\n+        where\n+            T: Sized,\n+    {\n+        read_unaligned(self)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as [`ptr::copy`].\n+    ///\n+    /// See [`ptr::copy`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::copy`]: ./ptr/fn.copy.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn copy_to(self, dest: *mut T, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        copy(self, dest, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may *not* overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as [`ptr::copy_nonoverlapping`].\n+    ///\n+    /// See [`ptr::copy_nonoverlapping`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::copy_nonoverlapping`]: ./ptr/fn.copy_nonoverlapping.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        copy_nonoverlapping(self, dest, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `src` to `self`. The source\n+    /// and destination may overlap.\n+    ///\n+    /// NOTE: this has the *opposite* argument order of [`ptr::copy`].\n+    ///\n+    /// See [`ptr::copy`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::copy`]: ./ptr/fn.copy.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn copy_from(self, src: *const T, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        copy(src, self, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `src` to `self`. The source\n+    /// and destination may *not* overlap.\n+    ///\n+    /// NOTE: this has the *opposite* argument order of [`ptr::copy_nonoverlapping`].\n+    ///\n+    /// See [`ptr::copy_nonoverlapping`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::copy_nonoverlapping`]: ./ptr/fn.copy_nonoverlapping.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn copy_from_nonoverlapping(self, src: *const T, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        copy_nonoverlapping(src, self, count)\n+    }\n+\n+    /// Executes the destructor (if any) of the pointed-to value.\n+    ///\n+    /// See [`ptr::drop_in_place`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::drop_in_place`]: ./ptr/fn.drop_in_place.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn drop_in_place(self) {\n+        drop_in_place(self)\n+    }\n+\n+    /// Overwrites a memory location with the given value without reading or\n+    /// dropping the old value.\n+    ///\n+    /// See [`ptr::write`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::write`]: ./ptr/fn.write.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn write(self, val: T)\n+        where\n+            T: Sized,\n+    {\n+        write(self, val)\n+    }\n+\n+    /// Invokes memset on the specified pointer, setting `count * size_of::<T>()`\n+    /// bytes of memory starting at `self` to `val`.\n+    ///\n+    /// See [`ptr::write_bytes`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::write_bytes`]: ./ptr/fn.write_bytes.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn write_bytes(self, val: u8, count: usize)\n+        where\n+            T: Sized,\n+    {\n+        write_bytes(self, val, count)\n+    }\n+\n+    /// Performs a volatile write of a memory location with the given value without\n+    /// reading or dropping the old value.\n+    ///\n+    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n+    /// to not be elided or reordered by the compiler across other volatile\n+    /// operations.\n+    ///\n+    /// See [`ptr::write_volatile`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::write_volatile`]: ./ptr/fn.write_volatile.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn write_volatile(self, val: T)\n+        where\n+            T: Sized,\n+    {\n+        write_volatile(self, val)\n+    }\n+\n+    /// Overwrites a memory location with the given value without reading or\n+    /// dropping the old value.\n+    ///\n+    /// Unlike `write`, the pointer may be unaligned.\n+    ///\n+    /// See [`ptr::write_unaligned`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::write_unaligned`]: ./ptr/fn.write_unaligned.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn write_unaligned(self, val: T)\n+        where\n+            T: Sized,\n+    {\n+        write_unaligned(self, val)\n+    }\n+\n+    /// Replaces the value at `self` with `src`, returning the old\n+    /// value, without dropping either.\n+    ///\n+    /// See [`ptr::replace`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::replace`]: ./ptr/fn.replace.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn replace(self, src: T) -> T\n+        where\n+            T: Sized,\n+    {\n+        replace(self, src)\n+    }\n+\n+    /// Swaps the values at two mutable locations of the same type, without\n+    /// deinitializing either. They may overlap, unlike `mem::swap` which is\n+    /// otherwise equivalent.\n+    ///\n+    /// See [`ptr::swap`] for safety concerns and examples.\n+    ///\n+    /// [`ptr::swap`]: ./ptr/fn.swap.html\n+    #[stable(feature = \"pointer_methods\", since = \"1.26.0\")]\n+    #[inline]\n+    pub unsafe fn swap(self, with: *mut T)\n+        where\n+            T: Sized,\n+    {\n+        swap(self, with)\n+    }\n+\n+    /// Computes the offset that needs to be applied to the pointer in order to make it aligned to\n+    /// `align`.\n+    ///\n+    /// If it is not possible to align the pointer, the implementation returns\n+    /// `usize::max_value()`. It is permissible for the implementation to *always*\n+    /// return `usize::max_value()`. Only your algorithm's performance can depend\n+    /// on getting a usable offset here, not its correctness.\n+    ///\n+    /// The offset is expressed in number of `T` elements, and not bytes. The value returned can be\n+    /// used with the `wrapping_add` method.\n+    ///\n+    /// There are no guarantees whatsoever that offsetting the pointer will not overflow or go\n+    /// beyond the allocation that the pointer points into. It is up to the caller to ensure that\n+    /// the returned offset is correct in all terms other than alignment.\n+    ///\n+    /// # Panics\n+    ///\n+    /// The function panics if `align` is not a power-of-two.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Accessing adjacent `u8` as `u16`\n+    ///\n+    /// ```\n+    /// # fn foo(n: usize) {\n+    /// # use std::mem::align_of;\n+    /// # unsafe {\n+    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n+    /// let ptr = &x[n] as *const u8;\n+    /// let offset = ptr.align_offset(align_of::<u16>());\n+    /// if offset < x.len() - n - 1 {\n+    ///     let u16_ptr = ptr.add(offset) as *const u16;\n+    ///     assert_ne!(*u16_ptr, 500);\n+    /// } else {\n+    ///     // while the pointer can be aligned via `offset`, it would point\n+    ///     // outside the allocation\n+    /// }\n+    /// # } }\n+    /// ```\n+    #[stable(feature = \"align_offset\", since = \"1.36.0\")]\n+    pub fn align_offset(self, align: usize) -> usize\n+        where\n+            T: Sized,\n+    {\n+        if !align.is_power_of_two() {\n+            panic!(\"align_offset: align is not a power-of-two\");\n+        }\n+        unsafe { align_offset(self, align) }\n+    }\n+}\n+\n+// Equality for pointers\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> PartialEq for *mut T {\n+    #[inline]\n+    fn eq(&self, other: &*mut T) -> bool { *self == *other }\n+}\n+\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> Eq for *mut T {}\n+\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> Ord for *mut T {\n+    #[inline]\n+    fn cmp(&self, other: &*mut T) -> Ordering {\n+        if self < other {\n+            Less\n+        } else if self == other {\n+            Equal\n+        } else {\n+            Greater\n+        }\n+    }\n+}\n+\n+#[stable(feature = \"rust1\", since = \"1.0.0\")]\n+impl<T: ?Sized> PartialOrd for *mut T {\n+    #[inline]\n+    fn partial_cmp(&self, other: &*mut T) -> Option<Ordering> {\n+        Some(self.cmp(other))\n+    }\n+\n+    #[inline]\n+    fn lt(&self, other: &*mut T) -> bool { *self < *other }\n+\n+    #[inline]\n+    fn le(&self, other: &*mut T) -> bool { *self <= *other }\n+\n+    #[inline]\n+    fn gt(&self, other: &*mut T) -> bool { *self > *other }\n+\n+    #[inline]\n+    fn ge(&self, other: &*mut T) -> bool { *self >= *other }\n+}"}, {"sha": "2cffcc5bfade8a72175bc91d2322093e6bb33b4c", "filename": "src/librustc/hir/mod.rs", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc%2Fhir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc%2Fhir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmod.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -1857,6 +1857,16 @@ impl fmt::Display for YieldSource {\n     }\n }\n \n+impl From<GeneratorKind> for YieldSource {\n+    fn from(kind: GeneratorKind) -> Self {\n+        match kind {\n+            // Guess based on the kind of the current generator.\n+            GeneratorKind::Gen => Self::Yield,\n+            GeneratorKind::Async(_) => Self::Await,\n+        }\n+    }\n+}\n+\n // N.B., if you change this, you'll probably want to change the corresponding\n // type structure in middle/ty.rs as well.\n #[derive(RustcEncodable, RustcDecodable, Debug, HashStable)]"}, {"sha": "e050e5f8942558f96a83434c847feed6c3c5cb2f", "filename": "src/librustc/middle/region.rs", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc%2Fmiddle%2Fregion.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc%2Fmiddle%2Fregion.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fregion.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -1173,6 +1173,7 @@ fn resolve_local<'tcx>(\n     ///        | VariantName(..., P&, ...)\n     ///        | [ ..., P&, ... ]\n     ///        | ( ..., P&, ... )\n+    ///        | ... \"|\" P& \"|\" ...\n     ///        | box P&\n     fn is_binding_pat(pat: &hir::Pat) -> bool {\n         // Note that the code below looks for *explicit* refs only, that is, it won't\n@@ -1212,6 +1213,7 @@ fn resolve_local<'tcx>(\n                 pats3.iter().any(|p| is_binding_pat(&p))\n             }\n \n+            PatKind::Or(ref subpats) |\n             PatKind::TupleStruct(_, ref subpats, _) |\n             PatKind::Tuple(ref subpats, _) => {\n                 subpats.iter().any(|p| is_binding_pat(&p))\n@@ -1221,7 +1223,13 @@ fn resolve_local<'tcx>(\n                 is_binding_pat(&subpat)\n             }\n \n-            _ => false,\n+            PatKind::Ref(_, _) |\n+            PatKind::Binding(hir::BindingAnnotation::Unannotated, ..) |\n+            PatKind::Binding(hir::BindingAnnotation::Mutable, ..) |\n+            PatKind::Wild |\n+            PatKind::Path(_) |\n+            PatKind::Lit(_) |\n+            PatKind::Range(_, _, _) => false,\n         }\n     }\n "}, {"sha": "b78cd6bccf8ca9ff80ee9f8931c93bd378b303aa", "filename": "src/librustc_mir/borrow_check/diagnostics/region_errors.rs", "status": "modified", "additions": 33, "deletions": 4, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Fborrow_check%2Fdiagnostics%2Fregion_errors.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Fborrow_check%2Fdiagnostics%2Fregion_errors.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fdiagnostics%2Fregion_errors.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -1,10 +1,13 @@\n //! Error reporting machinery for lifetime errors.\n \n use rustc::hir::def_id::DefId;\n-use rustc::infer::error_reporting::nice_region_error::NiceRegionError;\n-use rustc::infer::InferCtxt;\n-use rustc::infer::NLLRegionVariableOrigin;\n-use rustc::mir::{ConstraintCategory, Local, Location, Body};\n+use rustc::infer::{\n+    error_reporting::nice_region_error::NiceRegionError,\n+    InferCtxt, NLLRegionVariableOrigin,\n+};\n+use rustc::mir::{\n+    ConstraintCategory, Local, Location, Body,\n+};\n use rustc::ty::{self, RegionVid};\n use rustc_index::vec::IndexVec;\n use rustc_errors::DiagnosticBuilder;\n@@ -93,6 +96,32 @@ pub struct ErrorConstraintInfo {\n }\n \n impl<'tcx> RegionInferenceContext<'tcx> {\n+    /// Converts a region inference variable into a `ty::Region` that\n+    /// we can use for error reporting. If `r` is universally bound,\n+    /// then we use the name that we have on record for it. If `r` is\n+    /// existentially bound, then we check its inferred value and try\n+    /// to find a good name from that. Returns `None` if we can't find\n+    /// one (e.g., this is just some random part of the CFG).\n+    pub fn to_error_region(&self, r: RegionVid) -> Option<ty::Region<'tcx>> {\n+        self.to_error_region_vid(r).and_then(|r| self.definitions[r].external_name)\n+    }\n+\n+    /// Returns the [RegionVid] corresponding to the region returned by\n+    /// `to_error_region`.\n+    pub fn to_error_region_vid(&self, r: RegionVid) -> Option<RegionVid> {\n+        if self.universal_regions.is_universal_region(r) {\n+            Some(r)\n+        } else {\n+            let r_scc = self.constraint_sccs.scc(r);\n+            let upper_bound = self.universal_upper_bound(r);\n+            if self.scc_values.contains(r_scc, upper_bound) {\n+                self.to_error_region_vid(upper_bound)\n+            } else {\n+                None\n+            }\n+        }\n+    }\n+\n     /// Tries to find the best constraint to blame for the fact that\n     /// `R: from_region`, where `R` is some region that meets\n     /// `target_test`. This works by following the constraint graph,"}, {"sha": "dedc6b9b09af2ee33c0e739cd7d22db43ea42710", "filename": "src/librustc_mir/borrow_check/region_infer/mod.rs", "status": "modified", "additions": 63, "deletions": 84, "changes": 147, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Fborrow_check%2Fregion_infer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Fborrow_check%2Fregion_infer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fregion_infer%2Fmod.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -928,32 +928,6 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         }\n     }\n \n-    /// Converts a region inference variable into a `ty::Region` that\n-    /// we can use for error reporting. If `r` is universally bound,\n-    /// then we use the name that we have on record for it. If `r` is\n-    /// existentially bound, then we check its inferred value and try\n-    /// to find a good name from that. Returns `None` if we can't find\n-    /// one (e.g., this is just some random part of the CFG).\n-    pub fn to_error_region(&self, r: RegionVid) -> Option<ty::Region<'tcx>> {\n-        self.to_error_region_vid(r).and_then(|r| self.definitions[r].external_name)\n-    }\n-\n-    /// Returns the [RegionVid] corresponding to the region returned by\n-    /// `to_error_region`.\n-    pub fn to_error_region_vid(&self, r: RegionVid) -> Option<RegionVid> {\n-        if self.universal_regions.is_universal_region(r) {\n-            Some(r)\n-        } else {\n-            let r_scc = self.constraint_sccs.scc(r);\n-            let upper_bound = self.universal_upper_bound(r);\n-            if self.scc_values.contains(r_scc, upper_bound) {\n-                self.to_error_region_vid(upper_bound)\n-            } else {\n-                None\n-            }\n-        }\n-    }\n-\n     /// Invoked when we have some type-test (e.g., `T: 'X`) that we cannot\n     /// prove to be satisfied. If this is a closure, we will attempt to\n     /// \"promote\" this type-test into our `ClosureRegionRequirements` and\n@@ -1164,7 +1138,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n     ///   include the CFG anyhow.\n     /// - For each `end('x)` element in `'r`, compute the mutual LUB, yielding\n     ///   a result `'y`.\n-    fn universal_upper_bound(&self, r: RegionVid) -> RegionVid {\n+    pub (in crate::borrow_check) fn universal_upper_bound(&self, r: RegionVid) -> RegionVid {\n         debug!(\"universal_upper_bound(r={:?}={})\", r, self.region_value_str(r));\n \n         // Find the smallest universal region that contains all other\n@@ -1458,19 +1432,34 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             debug!(\"check_polonius_subset_errors: subset_error longer_fr={:?},\\\n                 shorter_fr={:?}\", longer_fr, shorter_fr);\n \n-            self.report_or_propagate_universal_region_error(\n+            let propagated = self.try_propagate_universal_region_error(\n                 *longer_fr,\n                 *shorter_fr,\n-                infcx,\n                 body,\n-                local_names,\n-                upvars,\n-                mir_def_id,\n                 &mut propagated_outlives_requirements,\n-                &mut outlives_suggestion,\n-                errors_buffer,\n-                region_naming,\n             );\n+            if !propagated {\n+                // If we are not in a context where we can't propagate errors, or we\n+                // could not shrink `fr` to something smaller, then just report an\n+                // error.\n+                //\n+                // Note: in this case, we use the unapproximated regions to report the\n+                // error. This gives better error messages in some cases.\n+                let db = self.report_error(\n+                    body,\n+                    local_names,\n+                    upvars,\n+                    infcx,\n+                    mir_def_id,\n+                    *longer_fr,\n+                    NLLRegionVariableOrigin::FreeRegion,\n+                    *shorter_fr,\n+                    &mut outlives_suggestion,\n+                    region_naming,\n+                );\n+\n+                db.buffer(errors_buffer);\n+            }\n         }\n \n         // Handle the placeholder errors as usual, until the chalk-rustc-polonius triumvirate has\n@@ -1594,48 +1583,59 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             return None;\n         }\n \n-        self.report_or_propagate_universal_region_error(\n+        let propagated = self.try_propagate_universal_region_error(\n             longer_fr,\n             shorter_fr,\n-            infcx,\n             body,\n-            local_names,\n-            upvars,\n-            mir_def_id,\n             propagated_outlives_requirements,\n-            outlives_suggestion,\n-            errors_buffer,\n-            region_naming,\n-        )\n+        );\n+\n+        if propagated {\n+            None\n+        } else {\n+            // If we are not in a context where we can't propagate errors, or we\n+            // could not shrink `fr` to something smaller, then just report an\n+            // error.\n+            //\n+            // Note: in this case, we use the unapproximated regions to report the\n+            // error. This gives better error messages in some cases.\n+            let db = self.report_error(\n+                body,\n+                local_names,\n+                upvars,\n+                infcx,\n+                mir_def_id,\n+                longer_fr,\n+                NLLRegionVariableOrigin::FreeRegion,\n+                shorter_fr,\n+                outlives_suggestion,\n+                region_naming,\n+            );\n+\n+            db.buffer(errors_buffer);\n+\n+            Some(ErrorReported)\n+        }\n     }\n \n-    fn report_or_propagate_universal_region_error(\n+    /// Attempt to propagate a region error (e.g. `'a: 'b`) that is not met to a closure's\n+    /// creator. If we cannot, then the caller should report an error to the user.\n+    ///\n+    /// Returns `true` if the error was propagated, and `false` otherwise.\n+    fn try_propagate_universal_region_error(\n         &self,\n         longer_fr: RegionVid,\n         shorter_fr: RegionVid,\n-        infcx: &InferCtxt<'_, 'tcx>,\n         body: &Body<'tcx>,\n-        local_names: &IndexVec<Local, Option<Symbol>>,\n-        upvars: &[Upvar],\n-        mir_def_id: DefId,\n         propagated_outlives_requirements: &mut Option<&mut Vec<ClosureOutlivesRequirement<'tcx>>>,\n-        outlives_suggestion: &mut OutlivesSuggestionBuilder<'_>,\n-        errors_buffer: &mut Vec<Diagnostic>,\n-        region_naming: &mut RegionErrorNamingCtx,\n-    ) -> Option<ErrorReported> {\n-        debug!(\n-            \"report_or_propagate_universal_region_error: fr={:?} does not outlive shorter_fr={:?}\",\n-            longer_fr, shorter_fr,\n-        );\n-\n+    ) -> bool {\n         if let Some(propagated_outlives_requirements) = propagated_outlives_requirements {\n             // Shrink `longer_fr` until we find a non-local region (if we do).\n             // We'll call it `fr-` -- it's ever so slightly smaller than\n             // `longer_fr`.\n-\n             if let Some(fr_minus) =\n                 self.universal_region_relations.non_local_lower_bound(longer_fr) {\n-                debug!(\"report_or_propagate_universal_region_error: fr_minus={:?}\", fr_minus);\n+                debug!(\"try_propagate_universal_region_error: fr_minus={:?}\", fr_minus);\n \n                 let blame_span_category =\n                     self.find_outlives_blame_span(body, longer_fr,\n@@ -1648,7 +1648,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n                     .universal_region_relations\n                     .non_local_upper_bounds(&shorter_fr);\n                 debug!(\n-                    \"report_or_propagate_universal_region_error: shorter_fr_plus={:?}\",\n+                    \"try_propagate_universal_region_error: shorter_fr_plus={:?}\",\n                     shorter_fr_plus\n                 );\n                 for &&fr in &shorter_fr_plus {\n@@ -1660,32 +1660,11 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n                         category: blame_span_category.0,\n                     });\n                 }\n-                return None;\n+                return true;\n             }\n         }\n \n-        // If we are not in a context where we can't propagate errors, or we\n-        // could not shrink `fr` to something smaller, then just report an\n-        // error.\n-        //\n-        // Note: in this case, we use the unapproximated regions to report the\n-        // error. This gives better error messages in some cases.\n-        let db = self.report_error(\n-            body,\n-            local_names,\n-            upvars,\n-            infcx,\n-            mir_def_id,\n-            longer_fr,\n-            NLLRegionVariableOrigin::FreeRegion,\n-            shorter_fr,\n-            outlives_suggestion,\n-            region_naming,\n-        );\n-\n-        db.buffer(errors_buffer);\n-\n-        Some(ErrorReported)\n+        false\n     }\n \n     fn check_bound_universal_region("}, {"sha": "0b8f41f51a1ee04739e7dbe5efb865ad35cd5f88", "filename": "src/librustc_mir/dataflow/move_paths/builder.rs", "status": "modified", "additions": 22, "deletions": 9, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Fdataflow%2Fmove_paths%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Fdataflow%2Fmove_paths%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fdataflow%2Fmove_paths%2Fbuilder.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -103,6 +103,13 @@ impl<'b, 'a, 'tcx> Gatherer<'b, 'a, 'tcx> {\n             }\n         };\n \n+        // The move path index of the first union that we find. Once this is\n+        // some we stop creating child move paths, since moves from unions\n+        // move the whole thing.\n+        // We continue looking for other move errors though so that moving\n+        // from `*(u.f: &_)` isn't allowed.\n+        let mut union_path = None;\n+\n         for (i, elem) in place.projection.iter().enumerate() {\n             let proj_base = &place.projection[..i];\n             let body = self.builder.body;\n@@ -127,9 +134,8 @@ impl<'b, 'a, 'tcx> Gatherer<'b, 'a, 'tcx> {\n                         InteriorOfTypeWithDestructor { container_ty: place_ty },\n                     ));\n                 }\n-                // move out of union - always move the entire union\n                 ty::Adt(adt, _) if adt.is_union() => {\n-                    return Err(MoveError::UnionMove { path: base });\n+                    union_path.get_or_insert(base);\n                 }\n                 ty::Slice(_) => {\n                     return Err(MoveError::cannot_move_out_of(\n@@ -155,15 +161,22 @@ impl<'b, 'a, 'tcx> Gatherer<'b, 'a, 'tcx> {\n                 _ => {}\n             };\n \n-            base = self.add_move_path(base, elem, |tcx| {\n-                Place {\n-                    base: place.base.clone(),\n-                    projection: tcx.intern_place_elems(&place.projection[..i+1]),\n-                }\n-            });\n+            if union_path.is_none() {\n+                base = self.add_move_path(base, elem, |tcx| {\n+                    Place {\n+                        base: place.base.clone(),\n+                        projection: tcx.intern_place_elems(&place.projection[..i+1]),\n+                    }\n+                });\n+            }\n         }\n \n-        Ok(base)\n+        if let Some(base) = union_path {\n+            // Move out of union - always move the entire union.\n+            Err(MoveError::UnionMove { path: base })\n+        } else {\n+            Ok(base)\n+        }\n     }\n \n     fn add_move_path("}, {"sha": "62aec1975c2160d0feeed16a925a2755d97a4983", "filename": "src/librustc_mir/transform/const_prop.rs", "status": "modified", "additions": 34, "deletions": 18, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Ftransform%2Fconst_prop.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_mir%2Ftransform%2Fconst_prop.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Ftransform%2Fconst_prop.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -262,7 +262,7 @@ struct ConstPropagator<'mir, 'tcx> {\n     ecx: InterpCx<'mir, 'tcx, ConstPropMachine>,\n     tcx: TyCtxt<'tcx>,\n     source: MirSource<'tcx>,\n-    can_const_prop: IndexVec<Local, bool>,\n+    can_const_prop: IndexVec<Local, ConstPropMode>,\n     param_env: ParamEnv<'tcx>,\n     // FIXME(eddyb) avoid cloning these two fields more than once,\n     // by accessing them through `ecx` instead.\n@@ -708,17 +708,28 @@ impl<'mir, 'tcx> ConstPropagator<'mir, 'tcx> {\n     }\n }\n \n+/// The mode that `ConstProp` is allowed to run in for a given `Local`.\n+#[derive(Clone, Copy, Debug, PartialEq)]\n+enum ConstPropMode {\n+    /// The `Local` can be propagated into and reads of this `Local` can also be propagated.\n+    FullConstProp,\n+    /// The `Local` can be propagated into but reads cannot be propagated.\n+    OnlyPropagateInto,\n+    /// No propagation is allowed at all.\n+    NoPropagation,\n+}\n+\n struct CanConstProp {\n-    can_const_prop: IndexVec<Local, bool>,\n+    can_const_prop: IndexVec<Local, ConstPropMode>,\n     // false at the beginning, once set, there are not allowed to be any more assignments\n     found_assignment: IndexVec<Local, bool>,\n }\n \n impl CanConstProp {\n     /// returns true if `local` can be propagated\n-    fn check(body: ReadOnlyBodyAndCache<'_, '_>) -> IndexVec<Local, bool> {\n+    fn check(body: ReadOnlyBodyAndCache<'_, '_>) -> IndexVec<Local, ConstPropMode> {\n         let mut cpv = CanConstProp {\n-            can_const_prop: IndexVec::from_elem(true, &body.local_decls),\n+            can_const_prop: IndexVec::from_elem(ConstPropMode::FullConstProp, &body.local_decls),\n             found_assignment: IndexVec::from_elem(false, &body.local_decls),\n         };\n         for (local, val) in cpv.can_const_prop.iter_enumerated_mut() {\n@@ -728,10 +739,10 @@ impl CanConstProp {\n             // FIXME(oli-obk): lint variables until they are used in a condition\n             // FIXME(oli-obk): lint if return value is constant\n             let local_kind = body.local_kind(local);\n-            *val = local_kind == LocalKind::Temp || local_kind == LocalKind::ReturnPointer;\n \n-            if !*val {\n-                trace!(\"local {:?} can't be propagated because it's not a temporary\", local);\n+            if local_kind == LocalKind::Arg || local_kind == LocalKind::Var {\n+                *val = ConstPropMode::OnlyPropagateInto;\n+                trace!(\"local {:?} can't be const propagated because it's not a temporary\", local);\n             }\n         }\n         cpv.visit_body(body);\n@@ -753,7 +764,7 @@ impl<'tcx> Visitor<'tcx> for CanConstProp {\n             // only occur in independent execution paths\n             MutatingUse(MutatingUseContext::Store) => if self.found_assignment[local] {\n                 trace!(\"local {:?} can't be propagated because of multiple assignments\", local);\n-                self.can_const_prop[local] = false;\n+                self.can_const_prop[local] = ConstPropMode::NoPropagation;\n             } else {\n                 self.found_assignment[local] = true\n             },\n@@ -766,7 +777,7 @@ impl<'tcx> Visitor<'tcx> for CanConstProp {\n             NonUse(_) => {},\n             _ => {\n                 trace!(\"local {:?} can't be propagaged because it's used: {:?}\", local, context);\n-                self.can_const_prop[local] = false;\n+                self.can_const_prop[local] = ConstPropMode::NoPropagation;\n             },\n         }\n     }\n@@ -800,10 +811,10 @@ impl<'mir, 'tcx> MutVisitor<'tcx> for ConstPropagator<'mir, 'tcx> {\n             if let Ok(place_layout) = self.tcx.layout_of(self.param_env.and(place_ty)) {\n                 if let Some(local) = place.as_local() {\n                     let source = statement.source_info;\n+                    let can_const_prop = self.can_const_prop[local];\n                     if let Some(()) = self.const_prop(rval, place_layout, source, place) {\n-                        if self.can_const_prop[local] {\n-                            trace!(\"propagated into {:?}\", local);\n-\n+                        if can_const_prop == ConstPropMode::FullConstProp ||\n+                           can_const_prop == ConstPropMode::OnlyPropagateInto {\n                             if let Some(value) = self.get_const(local) {\n                                 if self.should_const_prop(value) {\n                                     trace!(\"replacing {:?} with {:?}\", rval, value);\n@@ -812,21 +823,26 @@ impl<'mir, 'tcx> MutVisitor<'tcx> for ConstPropagator<'mir, 'tcx> {\n                                         value,\n                                         statement.source_info,\n                                     );\n+\n+                                    if can_const_prop == ConstPropMode::FullConstProp {\n+                                        trace!(\"propagated into {:?}\", local);\n+                                    }\n                                 }\n                             }\n-                        } else {\n-                            trace!(\"can't propagate into {:?}\", local);\n-                            if local != RETURN_PLACE {\n-                                self.remove_const(local);\n-                            }\n+                        }\n+                    }\n+                    if self.can_const_prop[local] != ConstPropMode::FullConstProp {\n+                        trace!(\"can't propagate into {:?}\", local);\n+                        if local != RETURN_PLACE {\n+                            self.remove_const(local);\n                         }\n                     }\n                 }\n             }\n         } else {\n             match statement.kind {\n                 StatementKind::StorageLive(local) |\n-                StatementKind::StorageDead(local) if self.can_const_prop[local] => {\n+                StatementKind::StorageDead(local) => {\n                     let frame = self.ecx.frame_mut();\n                     frame.locals[local].value =\n                         if let StatementKind::StorageLive(_) = statement.kind {"}, {"sha": "607efca88dd704379a3d35f3ad2155569d055050", "filename": "src/librustc_typeck/check/generator_interior.rs", "status": "modified", "additions": 14, "deletions": 7, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_typeck%2Fcheck%2Fgenerator_interior.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Flibrustc_typeck%2Fcheck%2Fgenerator_interior.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fgenerator_interior.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -19,6 +19,7 @@ struct InteriorVisitor<'a, 'tcx> {\n     region_scope_tree: &'tcx region::ScopeTree,\n     expr_count: usize,\n     kind: hir::GeneratorKind,\n+    prev_unresolved_span: Option<Span>,\n }\n \n impl<'a, 'tcx> InteriorVisitor<'a, 'tcx> {\n@@ -32,7 +33,6 @@ impl<'a, 'tcx> InteriorVisitor<'a, 'tcx> {\n         debug!(\"generator_interior: attempting to record type {:?} {:?} {:?} {:?}\",\n                ty, scope, expr, source_span);\n \n-\n         let live_across_yield = scope.map(|s| {\n             self.region_scope_tree.yield_in_scope(s).and_then(|yield_data| {\n                 // If we are recording an expression that is the last yield\n@@ -54,15 +54,11 @@ impl<'a, 'tcx> InteriorVisitor<'a, 'tcx> {\n         }).unwrap_or_else(|| Some(YieldData {\n             span: DUMMY_SP,\n             expr_and_pat_count: 0,\n-            source: match self.kind { // Guess based on the kind of the current generator.\n-                hir::GeneratorKind::Gen => hir::YieldSource::Yield,\n-                hir::GeneratorKind::Async(_) => hir::YieldSource::Await,\n-            },\n+            source: self.kind.into(),\n         }));\n \n         if let Some(yield_data) = live_across_yield {\n             let ty = self.fcx.resolve_vars_if_possible(&ty);\n-\n             debug!(\"type in expr = {:?}, scope = {:?}, type = {:?}, count = {}, yield_span = {:?}\",\n                    expr, scope, ty, self.expr_count, yield_data.span);\n \n@@ -74,9 +70,12 @@ impl<'a, 'tcx> InteriorVisitor<'a, 'tcx> {\n                                    yield_data.source);\n \n                 // If unresolved type isn't a ty_var then unresolved_type_span is None\n+                let span = self.prev_unresolved_span.unwrap_or_else(\n+                    || unresolved_type_span.unwrap_or(source_span)\n+                );\n                 self.fcx.need_type_info_err_in_generator(\n                     self.kind,\n-                    unresolved_type_span.unwrap_or(source_span),\n+                    span,\n                     unresolved_type,\n                 )\n                     .span_note(yield_data.span, &*note)\n@@ -94,6 +93,13 @@ impl<'a, 'tcx> InteriorVisitor<'a, 'tcx> {\n         } else {\n             debug!(\"no type in expr = {:?}, count = {:?}, span = {:?}\",\n                    expr, self.expr_count, expr.map(|e| e.span));\n+            let ty = self.fcx.resolve_vars_if_possible(&ty);\n+            if let Some((unresolved_type, unresolved_type_span))\n+                = self.fcx.unresolved_type_vars(&ty) {\n+                debug!(\"remained unresolved_type = {:?}, unresolved_type_span: {:?}\",\n+                    unresolved_type, unresolved_type_span);\n+                self.prev_unresolved_span = unresolved_type_span;\n+            }\n         }\n     }\n }\n@@ -112,6 +118,7 @@ pub fn resolve_interior<'a, 'tcx>(\n         region_scope_tree: fcx.tcx.region_scope_tree(def_id),\n         expr_count: 0,\n         kind,\n+        prev_unresolved_span: None,\n     };\n     intravisit::walk_body(&mut visitor, body);\n "}, {"sha": "d04dcc6a05ce183e870313133141a670c8312261", "filename": "src/test/mir-opt/const_prop/aggregate.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Faggregate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Faggregate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fmir-opt%2Fconst_prop%2Faggregate.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -19,7 +19,7 @@ fn main() {\n //      ...\n //      _3 = (const 0i32, const 1i32, const 2i32);\n //      _2 = const 1i32;\n-//      _1 = Add(move _2, const 0i32);\n+//      _1 = const 1i32;\n //      ...\n //  }\n // END rustc.main.ConstProp.after.mir"}, {"sha": "406585b5cab8e1b3299ff94dceeaa990728f2a1a", "filename": "src/test/mir-opt/const_prop/array_index.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Farray_index.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Farray_index.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fmir-opt%2Fconst_prop%2Farray_index.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -26,7 +26,7 @@ fn main() {\n //      assert(const true, \"index out of bounds: the len is move _4 but the index is _3\") -> bb1;\n //  }\n //  bb1: {\n-//      _1 = _2[_3];\n+//      _1 = const 2u32;\n //      ...\n //      return;\n //  }"}, {"sha": "93a53db9093608cf472185be56f729ff5b895002", "filename": "src/test/mir-opt/const_prop/optimizes_into_variable.rs", "status": "added", "additions": 149, "deletions": 0, "changes": 149, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Foptimizes_into_variable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Foptimizes_into_variable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fmir-opt%2Fconst_prop%2Foptimizes_into_variable.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -0,0 +1,149 @@\n+// compile-flags: -C overflow-checks=on\n+\n+struct Point {\n+    x: u32,\n+    y: u32,\n+}\n+\n+fn main() {\n+    let x = 2 + 2;\n+    let y = [0, 1, 2, 3, 4, 5][3];\n+    let z = (Point { x: 12, y: 42}).y;\n+}\n+\n+// END RUST SOURCE\n+// START rustc.main.ConstProp.before.mir\n+// let mut _0: ();\n+// let _1: i32;\n+// let mut _2: (i32, bool);\n+// let mut _4: [i32; 6];\n+// let _5: usize;\n+// let mut _6: usize;\n+// let mut _7: bool;\n+// let mut _9: Point;\n+// scope 1 {\n+//   debug x => _1;\n+//   let _3: i32;\n+//   scope 2 {\n+//     debug y => _3;\n+//     let _8: u32;\n+//     scope 3 {\n+//       debug z => _8;\n+//     }\n+//   }\n+// }\n+// bb0: {\n+//   StorageLive(_1);\n+//   _2 = CheckedAdd(const 2i32, const 2i32);\n+//   assert(!move (_2.1: bool), \"attempt to add with overflow\") -> bb1;\n+// }\n+// bb1: {\n+//   _1 = move (_2.0: i32);\n+//   StorageLive(_3);\n+//   StorageLive(_4);\n+//   _4 = [const 0i32, const 1i32, const 2i32, const 3i32, const 4i32, const 5i32];\n+//   StorageLive(_5);\n+//   _5 = const 3usize;\n+//   _6 = const 6usize;\n+//   _7 = Lt(_5, _6);\n+//   assert(move _7, \"index out of bounds: the len is move _6 but the index is _5\") -> bb2;\n+// }\n+// bb2: {\n+//   _3 = _4[_5];\n+//   StorageDead(_5);\n+//   StorageDead(_4);\n+//   StorageLive(_8);\n+//   StorageLive(_9);\n+//   _9 = Point { x: const 12u32, y: const 42u32 };\n+//   _8 = (_9.1: u32);\n+//   StorageDead(_9);\n+//   _0 = ();\n+//   StorageDead(_8);\n+//   StorageDead(_3);\n+//   StorageDead(_1);\n+//   return;\n+// }\n+// END rustc.main.ConstProp.before.mir\n+// START rustc.main.ConstProp.after.mir\n+// let mut _0: ();\n+// let _1: i32;\n+// let mut _2: (i32, bool);\n+// let mut _4: [i32; 6];\n+// let _5: usize;\n+// let mut _6: usize;\n+// let mut _7: bool;\n+// let mut _9: Point;\n+// scope 1 {\n+//   debug x => _1;\n+//   let _3: i32;\n+//   scope 2 {\n+//     debug y => _3;\n+//     let _8: u32;\n+//     scope 3 {\n+//       debug z => _8;\n+//     }\n+//   }\n+// }\n+// bb0: {\n+//   StorageLive(_1);\n+//   _2 = (const 4i32, const false);\n+//   assert(!const false, \"attempt to add with overflow\") -> bb1;\n+// }\n+// bb1: {\n+//   _1 = const 4i32;\n+//   StorageLive(_3);\n+//   StorageLive(_4);\n+//   _4 = [const 0i32, const 1i32, const 2i32, const 3i32, const 4i32, const 5i32];\n+//   StorageLive(_5);\n+//   _5 = const 3usize;\n+//   _6 = const 6usize;\n+//   _7 = const true;\n+//   assert(const true, \"index out of bounds: the len is move _6 but the index is _5\") -> bb2;\n+// }\n+// bb2: {\n+//   _3 = const 3i32;\n+//   StorageDead(_5);\n+//   StorageDead(_4);\n+//   StorageLive(_8);\n+//   StorageLive(_9);\n+//   _9 = Point { x: const 12u32, y: const 42u32 };\n+//   _8 = const 42u32;\n+//   StorageDead(_9);\n+//   _0 = ();\n+//   StorageDead(_8);\n+//   StorageDead(_3);\n+//   StorageDead(_1);\n+//   return;\n+// }\n+// END rustc.main.ConstProp.after.mir\n+// START rustc.main.SimplifyLocals.after.mir\n+// let mut _0: ();\n+// let _1: i32;\n+// let mut _3: [i32; 6];\n+// scope 1 {\n+//   debug x => _1;\n+//   let _2: i32;\n+//   scope 2 {\n+//     debug y => _2;\n+//     let _4: u32;\n+//     scope 3 {\n+//       debug z => _4;\n+//     }\n+//   }\n+// }\n+// bb0: {\n+//   StorageLive(_1);\n+//   _1 = const 4i32;\n+//   StorageLive(_2);\n+//   StorageLive(_3);\n+//   _3 = [const 0i32, const 1i32, const 2i32, const 3i32, const 4i32, const 5i32];\n+//   _2 = const 3i32;\n+//   StorageDead(_3);\n+//   StorageLive(_4);\n+//   _4 = const 42u32;\n+//   StorageDead(_4);\n+//   StorageDead(_2);\n+//   StorageDead(_1);\n+//   return;\n+// }\n+// END rustc.main.SimplifyLocals.after.mir"}, {"sha": "d9e0eb623afe11fdff9e921e6cf4e1ba102e624d", "filename": "src/test/mir-opt/const_prop/read_immutable_static.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Fread_immutable_static.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Fread_immutable_static.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fmir-opt%2Fconst_prop%2Fread_immutable_static.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -25,7 +25,7 @@ fn main() {\n //      _2 = const 2u8;\n //      ...\n //      _4 = const 2u8;\n-//      _1 = Add(move _2, move _4);\n+//      _1 = const 4u8;\n //      ...\n //  }\n // END rustc.main.ConstProp.after.mir"}, {"sha": "48c06290cec00f387b7212395c39c368d5a1c63e", "filename": "src/test/mir-opt/const_prop/repeat.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Frepeat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fmir-opt%2Fconst_prop%2Frepeat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fmir-opt%2Fconst_prop%2Frepeat.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -30,7 +30,7 @@ fn main() {\n //  }\n //  bb1: {\n //      _2 = const 42u32;\n-//      _1 = Add(move _2, const 0u32);\n+//      _1 = const 42u32;\n //      ...\n //      return;\n //  }"}, {"sha": "8fbf120fc1c78e1a8a9827595f84067033861ce9", "filename": "src/test/ui/borrowck/move-from-union-field-issue-66500.rs", "status": "added", "additions": 30, "deletions": 0, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fui%2Fborrowck%2Fmove-from-union-field-issue-66500.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fui%2Fborrowck%2Fmove-from-union-field-issue-66500.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fborrowck%2Fmove-from-union-field-issue-66500.rs?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -0,0 +1,30 @@\n+// Moving from a reference/raw pointer should be an error, even when they're\n+// the field of a union.\n+\n+#![feature(untagged_unions)]\n+\n+union Pointers {\n+    a: &'static String,\n+    b: &'static mut String,\n+    c: *const String,\n+    d: *mut String,\n+}\n+\n+unsafe fn move_ref(u: Pointers) -> String {\n+    *u.a\n+    //~^ ERROR cannot move out of `*u.a`\n+}\n+unsafe fn move_ref_mut(u: Pointers) -> String {\n+    *u.b\n+    //~^ ERROR cannot move out of `*u.b`\n+}\n+unsafe fn move_ptr(u: Pointers) -> String {\n+    *u.c\n+    //~^ ERROR cannot move out of `*u.c`\n+}\n+unsafe fn move_ptr_mut(u: Pointers) -> String {\n+    *u.d\n+    //~^ ERROR cannot move out of `*u.d`\n+}\n+\n+fn main() {}"}, {"sha": "a7cb1c9e2213547e9c8c0e00dc8acaba0b84829d", "filename": "src/test/ui/borrowck/move-from-union-field-issue-66500.stderr", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fui%2Fborrowck%2Fmove-from-union-field-issue-66500.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fui%2Fborrowck%2Fmove-from-union-field-issue-66500.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fborrowck%2Fmove-from-union-field-issue-66500.stderr?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -0,0 +1,27 @@\n+error[E0507]: cannot move out of `*u.a` which is behind a shared reference\n+  --> $DIR/move-from-union-field-issue-66500.rs:14:5\n+   |\n+LL |     *u.a\n+   |     ^^^^ move occurs because `*u.a` has type `std::string::String`, which does not implement the `Copy` trait\n+\n+error[E0507]: cannot move out of `*u.b` which is behind a mutable reference\n+  --> $DIR/move-from-union-field-issue-66500.rs:18:5\n+   |\n+LL |     *u.b\n+   |     ^^^^ move occurs because `*u.b` has type `std::string::String`, which does not implement the `Copy` trait\n+\n+error[E0507]: cannot move out of `*u.c` which is behind a raw pointer\n+  --> $DIR/move-from-union-field-issue-66500.rs:22:5\n+   |\n+LL |     *u.c\n+   |     ^^^^ move occurs because `*u.c` has type `std::string::String`, which does not implement the `Copy` trait\n+\n+error[E0507]: cannot move out of `*u.d` which is behind a raw pointer\n+  --> $DIR/move-from-union-field-issue-66500.rs:26:5\n+   |\n+LL |     *u.d\n+   |     ^^^^ move occurs because `*u.d` has type `std::string::String`, which does not implement the `Copy` trait\n+\n+error: aborting due to 4 previous errors\n+\n+For more information about this error, try `rustc --explain E0507`."}, {"sha": "ac08b2f2427c796db2d5468f1345b599e56decce", "filename": "src/test/ui/consts/offset_from_ub.stderr", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fui%2Fconsts%2Foffset_from_ub.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/9ff30a7810c586819a78188c173a7b74adbb9730/src%2Ftest%2Fui%2Fconsts%2Foffset_from_ub.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fconsts%2Foffset_from_ub.stderr?ref=9ff30a7810c586819a78188c173a7b74adbb9730", "patch": "@@ -1,11 +1,11 @@\n error: any use of this value will cause an error\n-  --> $SRC_DIR/libcore/ptr/mod.rs:LL:COL\n+  --> $SRC_DIR/libcore/ptr/const_ptr.rs:LL:COL\n    |\n LL |           intrinsics::ptr_offset_from(self, origin)\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |           |\n    |           ptr_offset_from cannot compute offset of pointers into different allocations.\n-   |           inside call to `std::ptr::<impl *const Struct>::offset_from` at $DIR/offset_from_ub.rs:19:27\n+   |           inside call to `std::ptr::const_ptr::<impl *const Struct>::offset_from` at $DIR/offset_from_ub.rs:19:27\n    | \n   ::: $DIR/offset_from_ub.rs:13:1\n    |\n@@ -21,13 +21,13 @@ LL | | };\n    = note: `#[deny(const_err)]` on by default\n \n error: any use of this value will cause an error\n-  --> $SRC_DIR/libcore/ptr/mod.rs:LL:COL\n+  --> $SRC_DIR/libcore/ptr/const_ptr.rs:LL:COL\n    |\n LL |           intrinsics::ptr_offset_from(self, origin)\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |           |\n    |           a memory access tried to interpret some bytes as a pointer\n-   |           inside call to `std::ptr::<impl *const u8>::offset_from` at $DIR/offset_from_ub.rs:25:14\n+   |           inside call to `std::ptr::const_ptr::<impl *const u8>::offset_from` at $DIR/offset_from_ub.rs:25:14\n    | \n   ::: $DIR/offset_from_ub.rs:23:1\n    |\n@@ -38,13 +38,13 @@ LL | | };\n    | |__-\n \n error: any use of this value will cause an error\n-  --> $SRC_DIR/libcore/ptr/mod.rs:LL:COL\n+  --> $SRC_DIR/libcore/ptr/const_ptr.rs:LL:COL\n    |\n LL |           intrinsics::ptr_offset_from(self, origin)\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |           |\n    |           exact_div: 1 cannot be divided by 2 without remainder\n-   |           inside call to `std::ptr::<impl *const u16>::offset_from` at $DIR/offset_from_ub.rs:33:14\n+   |           inside call to `std::ptr::const_ptr::<impl *const u16>::offset_from` at $DIR/offset_from_ub.rs:33:14\n    | \n   ::: $DIR/offset_from_ub.rs:28:1\n    |\n@@ -58,13 +58,13 @@ LL | | };\n    | |__-\n \n error: any use of this value will cause an error\n-  --> $SRC_DIR/libcore/ptr/mod.rs:LL:COL\n+  --> $SRC_DIR/libcore/ptr/const_ptr.rs:LL:COL\n    |\n LL |           intrinsics::ptr_offset_from(self, origin)\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |           |\n    |           invalid use of NULL pointer\n-   |           inside call to `std::ptr::<impl *const u8>::offset_from` at $DIR/offset_from_ub.rs:39:14\n+   |           inside call to `std::ptr::const_ptr::<impl *const u8>::offset_from` at $DIR/offset_from_ub.rs:39:14\n    | \n   ::: $DIR/offset_from_ub.rs:36:1\n    |\n@@ -76,13 +76,13 @@ LL | | };\n    | |__-\n \n error: any use of this value will cause an error\n-  --> $SRC_DIR/libcore/ptr/mod.rs:LL:COL\n+  --> $SRC_DIR/libcore/ptr/const_ptr.rs:LL:COL\n    |\n LL |           intrinsics::ptr_offset_from(self, origin)\n    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |           |\n    |           a memory access tried to interpret some bytes as a pointer\n-   |           inside call to `std::ptr::<impl *const u8>::offset_from` at $DIR/offset_from_ub.rs:46:14\n+   |           inside call to `std::ptr::const_ptr::<impl *const u8>::offset_from` at $DIR/offset_from_ub.rs:46:14\n    | \n   ::: $DIR/offset_from_ub.rs:42:1\n    |"}]}