{"sha": "0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBhMzZlYTdkYjEzMGRmYWE2MDEyZDc2Y2NmODBiOWI3N2UxNTc5NmI=", "commit": {"author": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-07-20T22:32:52Z"}, "committer": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-07-20T22:32:52Z"}, "message": "get into the weeds over GEP and allocations", "tree": {"sha": "ff041295a14d1c31a2fbaafe7e7122c5321b46b5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ff041295a14d1c31a2fbaafe7e7122c5321b46b5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "html_url": "https://github.com/rust-lang/rust/commit/0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/comments", "author": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7a47ffcbc73fa3bd02429c92841dcb0792a1f9b8", "url": "https://api.github.com/repos/rust-lang/rust/commits/7a47ffcbc73fa3bd02429c92841dcb0792a1f9b8", "html_url": "https://github.com/rust-lang/rust/commit/7a47ffcbc73fa3bd02429c92841dcb0792a1f9b8"}], "stats": {"total": 267, "additions": 209, "deletions": 58}, "files": [{"sha": "6f98220ebc9753ef04549cb6754d15358b2e7619", "filename": "src/doc/tarpl/vec-alloc.md", "status": "modified", "additions": 131, "deletions": 25, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/src%2Fdoc%2Ftarpl%2Fvec-alloc.md", "raw_url": "https://github.com/rust-lang/rust/raw/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/src%2Fdoc%2Ftarpl%2Fvec-alloc.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-alloc.md?ref=0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "patch": "@@ -1,5 +1,22 @@\n % Allocating Memory\n \n+Using Unique throws a wrench in an important feature of Vec (and indeed all of\n+the std collections): an empty Vec doesn't actually allocate at all. So if we\n+can't allocate, but also can't put a null pointer in `ptr`, what do we do in\n+`Vec::new`? Well, we just put some other garbage in there!\n+\n+This is perfectly fine because we already have `cap == 0` as our sentinel for no\n+allocation. We don't even need to handle it specially in almost any code because\n+we usually need to check if `cap > len` or `len > 0` anyway. The traditional\n+Rust value to put here is `0x01`. The standard library actually exposes this\n+as `std::rt::heap::EMPTY`. There are quite a few places where we'll\n+want to use `heap::EMPTY` because there's no real allocation to talk about but\n+`null` would make the compiler do bad things.\n+\n+All of the `heap` API is totally unstable under the `heap_api` feature, though.\n+We could trivially define `heap::EMPTY` ourselves, but we'll want the rest of\n+the `heap` API anyway, so let's just get that dependency over with.\n+\n So:\n \n ```rust,ignore\n@@ -24,15 +41,29 @@ I slipped in that assert there because zero-sized types will require some\n special handling throughout our code, and I want to defer the issue for now.\n Without this assert, some of our early drafts will do some Very Bad Things.\n \n-Next we need to figure out what to actually do when we *do* want space. For that,\n-we'll need to use the rest of the heap APIs. These basically allow us to\n-talk directly to Rust's instance of jemalloc.\n-\n-We'll also need a way to handle out-of-memory conditions. The standard library\n-calls the `abort` intrinsic, but calling intrinsics from normal Rust code is a\n-pretty bad idea. Unfortunately, the `abort` exposed by the standard library\n-allocates. Not something we want to do during `oom`! Instead, we'll call\n-`std::process::exit`.\n+Next we need to figure out what to actually do when we *do* want space. For\n+that, we'll need to use the rest of the heap APIs. These basically allow us to\n+talk directly to Rust's allocator (jemalloc by default).\n+\n+We'll also need a way to handle out-of-memory (OOM) conditions. The standard\n+library calls the `abort` intrinsic, which just calls an illegal instruction to\n+crash the whole program. The reason we abort and don't panic is because\n+unwinding can cause allocations to happen, and that seems like a bad thing to do\n+when your allocator just came back with \"hey I don't have any more memory\".\n+\n+Of course, this is a bit silly since most platforms don't actually run out of\n+memory in a conventional way. Your operating system will probably kill the\n+application by another means if you legitimately start using up all the memory.\n+The most likely way we'll trigger OOM is by just asking for ludicrous quantities\n+of memory at once (e.g. half the theoretical address space). As such it's\n+*probably* fine to panic and nothing bad will happen. Still, we're trying to be\n+like the standard library as much as possible, so we'll just kill the whole\n+program.\n+\n+We said we don't want to use intrinsics, so doing *exactly* what `std` does is\n+out. `std::rt::util::abort` actually exists, but it takes a message to print,\n+which will probably allocate. Also it's still unstable. Instead, we'll call\n+`std::process::exit` with some random number.\n \n ```rust\n fn oom() {\n@@ -51,29 +82,104 @@ else:\n     cap *= 2\n ```\n \n-But Rust's only supported allocator API is so low level that we'll need to\n-do a fair bit of extra work, though. We also need to guard against some special\n-conditions that can occur with really large allocations. In particular, we index\n-into arrays using unsigned integers, but `ptr::offset` takes signed integers. This\n-means Bad Things will happen if we ever manage to grow to contain more than\n-`isize::MAX` elements. Thankfully, this isn't something we need to worry about\n-in most cases.\n+But Rust's only supported allocator API is so low level that we'll need to do a\n+fair bit of extra work. We also need to guard against some special\n+conditions that can occur with really large allocations or empty allocations.\n+\n+In particular, `ptr::offset` will cause us *a lot* of trouble, because it has\n+the semantics of LLVM's GEP inbounds instruction. If you're fortunate enough to\n+not have dealt with this instruction, here's the basic story with GEP: alias\n+analysis, alias analysis, alias analysis. It's super important to an optimizing\n+compiler to be able to reason about data dependencies and aliasing.\n \n-On 64-bit targets we're artifically limited to only 48-bits, so we'll run out\n-of memory far before we reach that point. However on 32-bit targets, particularly\n-those with extensions to use more of the address space, it's theoretically possible\n-to successfully allocate more than `isize::MAX` bytes of memory. Still, we only\n-really need to worry about that if we're allocating elements that are a byte large.\n-Anything else will use up too much space.\n+As a simple example, consider the following fragment of code:\n+\n+```rust\n+# let x = &mut 0;\n+# let y = &mut 0;\n+*x *= 7;\n+*y *= 3;\n+```\n \n-However since this is a tutorial, we're not going to be particularly optimal here,\n-and just unconditionally check, rather than use clever platform-specific `cfg`s.\n+If the compiler can prove that `x` and `y` point to different locations in\n+memory, the two operations can in theory be executed in parallel (by e.g.\n+loading them into different registers and working on them independently).\n+However in *general* the compiler can't do this because if x and y point to\n+the same location in memory, the operations need to be done to the same value,\n+and they can't just be merged afterwards.\n+\n+When you use GEP inbounds, you are specifically telling LLVM that the offsets\n+you're about to do are within the bounds of a single allocated entity. The\n+ultimate payoff being that LLVM can assume that if two pointers are known to\n+point to two disjoint objects, all the offsets of those pointers are *also*\n+known to not alias (because you won't just end up in some random place in\n+memory). LLVM is heavily optimized to work with GEP offsets, and inbounds\n+offsets are the best of all, so it's important that we use them as much as\n+possible.\n+\n+So that's what GEP's about, how can it cause us trouble?\n+\n+The first problem is that we index into arrays with unsigned integers, but\n+GEP (and as a consequence `ptr::offset`) takes a *signed integer*. This means\n+that half of the seemingly valid indices into an array will overflow GEP and\n+actually go in the wrong direction! As such we must limit all allocations to\n+`isize::MAX` elements. This actually means we only need to worry about\n+byte-sized objects, because e.g. `> isize::MAX` `u16`s will truly exhaust all of\n+the system's memory. However in order to avoid subtle corner cases where someone\n+reinterprets some array of `< isize::MAX` objects as bytes, std limits all\n+allocations to `isize::MAX` bytes.\n+\n+On all 64-bit targets that Rust currently supports we're artificially limited\n+to significantly less than all 64 bits of the address space (modern x64\n+platforms only expose 48-bit addressing), so we can rely on just running out of\n+memory first. However on 32-bit targets, particularly those with extensions to\n+use more of the address space (PAE x86 or x32), it's theoretically possible to\n+successfully allocate more than `isize::MAX` bytes of memory.\n+\n+However since this is a tutorial, we're not going to be particularly optimal\n+here, and just unconditionally check, rather than use clever platform-specific\n+`cfg`s.\n+\n+The other corner-case we need to worry about is *empty* allocations. There will\n+be two kinds of empty allocations we need to worry about: `cap = 0` for all T,\n+and `cap > 0` for zero-sized types.\n+\n+These cases are tricky because they come\n+down to what LLVM means by \"allocated\". LLVM's notion of an\n+allocation is significantly more abstract than how we usually use it. Because\n+LLVM needs to work with different languages' semantics and custom allocators,\n+it can't really intimately understand allocation. Instead, the main idea behind\n+allocation is \"doesn't overlap with other stuff\". That is, heap allocations,\n+stack allocations, and globals don't randomly overlap. Yep, it's about alias\n+analysis. As such, Rust can technically play a bit fast an loose with the notion of\n+an allocation as long as it's *consistent*.\n+\n+Getting back to the empty allocation case, there are a couple of places where\n+we want to offset by 0 as a consequence of generic code. The question is then:\n+is it consistent to do so? For zero-sized types, we have concluded that it is\n+indeed consistent to do a GEP inbounds offset by an arbitrary number of\n+elements. This is a runtime no-op because every element takes up no space,\n+and it's fine to pretend that there's infinite zero-sized types allocated\n+at `0x01`. No allocator will ever allocate that address, because they won't\n+allocate `0x00` and they generally allocate to some minimal alignment higher\n+than a byte.\n+\n+However what about for positive-sized types? That one's a bit trickier. In\n+principle, you can argue that offsetting by 0 gives LLVM no information: either\n+there's an element before the address, or after it, but it can't know which.\n+However we've chosen to conservatively assume that it may do bad things. As\n+such we *will* guard against this case explicitly.\n+\n+*Phew*\n+\n+Ok with all the nonsense out of the way, let's actually allocate some memory:\n \n ```rust,ignore\n fn grow(&mut self) {\n     // this is all pretty delicate, so let's say it's all unsafe\n     unsafe {\n-        let align = mem::min_align_of::<T>();\n+        // current API requires us to specify size and alignment manually.\n+        let align = mem::align_of::<T>();\n         let elem_size = mem::size_of::<T>();\n \n         let (new_cap, ptr) = if self.cap == 0 {"}, {"sha": "bce9a2f22f4df516499dea8f5fc833202404acc8", "filename": "src/doc/tarpl/vec-layout.md", "status": "modified", "additions": 63, "deletions": 32, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/src%2Fdoc%2Ftarpl%2Fvec-layout.md", "raw_url": "https://github.com/rust-lang/rust/raw/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/src%2Fdoc%2Ftarpl%2Fvec-layout.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-layout.md?ref=0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "patch": "@@ -13,15 +13,64 @@ pub struct Vec<T> {\n # fn main() {}\n ```\n \n-And indeed this would compile. Unfortunately, it would be incorrect. The\n-compiler will give us too strict variance, so e.g. an `&Vec<&'static str>`\n+And indeed this would compile. Unfortunately, it would be incorrect. First, the\n+compiler will give us too strict variance. So a `&Vec<&'static str>`\n couldn't be used where an `&Vec<&'a str>` was expected. More importantly, it\n-will give incorrect ownership information to dropck, as it will conservatively\n-assume we don't own any values of type `T`. See [the chapter on ownership and\n-lifetimes] (lifetimes.html) for details.\n+will give incorrect ownership information to the drop checker, as it will\n+conservatively assume we don't own any values of type `T`. See [the chapter\n+on ownership and lifetimes][ownership] for all the details on variance and\n+drop check.\n \n-As we saw in the lifetimes chapter, we should use `Unique<T>` in place of\n-`*mut T` when we have a raw pointer to an allocation we own:\n+As we saw in the ownership chapter, we should use `Unique<T>` in place of\n+`*mut T` when we have a raw pointer to an allocation we own. Unique is unstable,\n+so we'd like to not use it if possible, though.\n+\n+As a recap, Unique is a wrapper around a raw pointer that declares that:\n+\n+* We are variant over `T`\n+* We may own a value of type `T` (for drop check)\n+* We are Send/Sync if `T` is Send/Sync\n+* We deref to `*mut T` (so it largely acts like a `*mut` in our code)\n+* Our pointer is never null (so `Option<Vec<T>>` is null-pointer-optimized)\n+\n+We can implement all of the above requirements except for the last\n+one in stable Rust:\n+\n+```rust\n+use std::marker::PhantomData;\n+use std::ops::Deref;\n+use std::mem;\n+\n+struct Unique<T> {\n+    ptr: *const T,              // *const for variance\n+    _marker: PhantomData<T>,    // For the drop checker\n+}\n+\n+// Deriving Send and Sync is safe because we are the Unique owners\n+// of this data. It's like Unique<T> is \"just\" T.\n+unsafe impl<T: Send> Send for Unique<T> {}\n+unsafe impl<T: Sync> Sync for Unique<T> {}\n+\n+impl<T> Unique<T> {\n+    pub fn new(ptr: *mut T) -> Self {\n+        Unique { ptr: ptr, _marker: PhantomData }\n+    }\n+}\n+\n+impl<T> Deref for Unique<T> {\n+    type Target = *mut T;\n+    fn deref(&self) -> &*mut T {\n+        // There's no way to cast the *const to a *mut\n+        // while also taking a reference. So we just\n+        // transmute it since it's all \"just pointers\".\n+        unsafe { mem::transmute(&self.ptr) }\n+    }\n+}\n+```\n+\n+Unfortunately the mechanism for stating that your value is non-zero is\n+unstable and unlikely to be stabilized soon. As such we're just going to\n+take the hit and use std's Unique:\n \n \n ```rust\n@@ -38,29 +87,11 @@ pub struct Vec<T> {\n # fn main() {}\n ```\n \n-As a recap, Unique is a wrapper around a raw pointer that declares that:\n-\n-* We may own a value of type `T`\n-* We are Send/Sync iff `T` is Send/Sync\n-* Our pointer is never null (and therefore `Option<Vec>` is\n-  null-pointer-optimized)\n-\n-That last point is subtle. First, it makes `Unique::new` unsafe to call, because\n-putting `null` inside of it is Undefined Behaviour. It also throws a\n-wrench in an important feature of Vec (and indeed all of the std collections):\n-an empty Vec doesn't actually allocate at all. So if we can't allocate,\n-but also can't put a null pointer in `ptr`, what do we do in\n-`Vec::new`? Well, we just put some other garbage in there!\n-\n-This is perfectly fine because we already have `cap == 0` as our sentinel for no\n-allocation. We don't even need to handle it specially in almost any code because\n-we usually need to check if `cap > len` or `len > 0` anyway. The traditional\n-Rust value to put here is `0x01`. The standard library actually exposes this\n-as `std::rt::heap::EMPTY`. There are quite a few places where we'll want to use\n-`heap::EMPTY` because there's no real allocation to talk about but `null` would\n-make the compiler angry.\n-\n-All of the `heap` API is totally unstable under the `heap_api` feature, though.\n-We could trivially define `heap::EMPTY` ourselves, but we'll want the rest of\n-the `heap` API anyway, so let's just get that dependency over with.\n+If you don't care about the null-pointer optimization, then you can use the\n+stable code. However we will be designing the rest of the code around enabling\n+the optimization. In particular, `Unique::new` is unsafe to call, because\n+putting `null` inside of it is Undefined Behaviour. Our stable Unique doesn't\n+need `new` to be unsafe because it doesn't make any interesting guarantees about\n+its contents.\n \n+[ownership]: ownership.html"}, {"sha": "39d9686ccac7fe1553dfb3bf0775947166795519", "filename": "src/doc/tarpl/vec.md", "status": "modified", "additions": 15, "deletions": 1, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/src%2Fdoc%2Ftarpl%2Fvec.md", "raw_url": "https://github.com/rust-lang/rust/raw/0a36ea7db130dfaa6012d76ccf80b9b77e15796b/src%2Fdoc%2Ftarpl%2Fvec.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec.md?ref=0a36ea7db130dfaa6012d76ccf80b9b77e15796b", "patch": "@@ -2,5 +2,19 @@\n \n To bring everything together, we're going to write `std::Vec` from scratch.\n Because all the best tools for writing unsafe code are unstable, this\n-project will only work on nightly (as of Rust 1.2.0).\n+project will only work on nightly (as of Rust 1.2.0). With the exception of the\n+allocator API, much of the unstable code we'll use is expected to be stabilized\n+in a similar form as it is today.\n \n+However we will generally try to avoid unstable code where possible. In\n+particular we won't use any intrinsics that could make a code a little\n+bit nicer or efficient because intrinsics are permanently unstable. Although\n+many intrinsics *do* become stabilized elsewhere (`std::ptr` and `str::mem`\n+consist of many intrinsics).\n+\n+Ultimately this means out implementation may not take advantage of all\n+possible optimizations, though it will be by no means *naive*. We will\n+definitely get into the weeds over nitty-gritty details, even\n+when the problem doesn't *really* merit it.\n+\n+You wanted advanced. We're gonna go advanced."}]}