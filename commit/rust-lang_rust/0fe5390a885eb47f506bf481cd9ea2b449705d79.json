{"sha": "0fe5390a885eb47f506bf481cd9ea2b449705d79", "node_id": "C_kwDOAAsO6NoAKDBmZTUzOTBhODg1ZWI0N2Y1MDZiZjQ4MWNkOWVhMmI0NDk3MDVkNzk", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-15T14:30:14Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-15T14:30:14Z"}, "message": "Auto merge of #99046 - nnethercote:final-derive-output-improvements, r=Mark-Simulacrum\n\nFinal derive output improvements\n\nWith all these changes, the derive output in `deriving-all-codegen.stdout` is pretty close to optimal, i.e. very similar to what you'd write by hand.\n\nr? `@ghost`", "tree": {"sha": "bdd20aa8ad0eb35ff8fc1678de3a8a7070d9bd81", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bdd20aa8ad0eb35ff8fc1678de3a8a7070d9bd81"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0fe5390a885eb47f506bf481cd9ea2b449705d79", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0fe5390a885eb47f506bf481cd9ea2b449705d79", "html_url": "https://github.com/rust-lang/rust/commit/0fe5390a885eb47f506bf481cd9ea2b449705d79", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0fe5390a885eb47f506bf481cd9ea2b449705d79/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "116819f54f062a2f425deac4ec29245038c26613", "url": "https://api.github.com/repos/rust-lang/rust/commits/116819f54f062a2f425deac4ec29245038c26613", "html_url": "https://github.com/rust-lang/rust/commit/116819f54f062a2f425deac4ec29245038c26613"}, {"sha": "1cb1d63bd2d11ba1403c76f5c22802dd62ed2387", "url": "https://api.github.com/repos/rust-lang/rust/commits/1cb1d63bd2d11ba1403c76f5c22802dd62ed2387", "html_url": "https://github.com/rust-lang/rust/commit/1cb1d63bd2d11ba1403c76f5c22802dd62ed2387"}], "stats": {"total": 1292, "additions": 717, "deletions": 575}, "files": [{"sha": "7755ff779c4d9c4dc9b6c6c928fa5972d907f130", "filename": "compiler/rustc_builtin_macros/src/deriving/clone.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fclone.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fclone.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fclone.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -148,7 +148,7 @@ fn cs_clone_simple(\n             ),\n         }\n     }\n-    BlockOrExpr::new_mixed(stmts, cx.expr_deref(trait_span, cx.expr_self(trait_span)))\n+    BlockOrExpr::new_mixed(stmts, Some(cx.expr_deref(trait_span, cx.expr_self(trait_span))))\n }\n \n fn cs_clone(\n@@ -161,7 +161,7 @@ fn cs_clone(\n     let all_fields;\n     let fn_path = cx.std_path(&[sym::clone, sym::Clone, sym::clone]);\n     let subcall = |cx: &mut ExtCtxt<'_>, field: &FieldInfo| {\n-        let args = vec![cx.expr_addr_of(field.span, field.self_expr.clone())];\n+        let args = vec![field.self_expr.clone()];\n         cx.expr_call_global(field.span, fn_path.clone(), args)\n     };\n \n@@ -177,9 +177,7 @@ fn cs_clone(\n             all_fields = af;\n             vdata = &variant.data;\n         }\n-        EnumNonMatchingCollapsed(..) => {\n-            cx.span_bug(trait_span, &format!(\"non-matching enum variants in `derive({})`\", name,))\n-        }\n+        EnumTag(..) => cx.span_bug(trait_span, &format!(\"enum tags in `derive({})`\", name,)),\n         StaticEnum(..) | StaticStruct(..) => {\n             cx.span_bug(trait_span, &format!(\"associated function in `derive({})`\", name))\n         }"}, {"sha": "1612be862377bf162e8eed5a6a5fe90ab1688edb", "filename": "compiler/rustc_builtin_macros/src/deriving/cmp/ord.rs", "status": "modified", "additions": 1, "deletions": 14, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Ford.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Ford.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Ford.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -63,10 +63,7 @@ pub fn cs_cmp(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_>) -> Bl\n                 let [other_expr] = &field.other_selflike_exprs[..] else {\n                         cx.span_bug(field.span, \"not exactly 2 arguments in `derive(Ord)`\");\n                     };\n-                let args = vec![\n-                    cx.expr_addr_of(field.span, field.self_expr.clone()),\n-                    cx.expr_addr_of(field.span, other_expr.clone()),\n-                ];\n+                let args = vec![field.self_expr.clone(), other_expr.clone()];\n                 cx.expr_call_global(field.span, cmp_path.clone(), args)\n             }\n             CsFold::Combine(span, expr1, expr2) => {\n@@ -76,16 +73,6 @@ pub fn cs_cmp(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_>) -> Bl\n                 cx.expr_match(span, expr2, vec![eq_arm, neq_arm])\n             }\n             CsFold::Fieldless => cx.expr_path(equal_path.clone()),\n-            CsFold::EnumNonMatching(span, tag_tuple) => {\n-                if tag_tuple.len() != 2 {\n-                    cx.span_bug(span, \"not exactly 2 arguments in `derive(Ord)`\")\n-                } else {\n-                    let lft = cx.expr_addr_of(span, cx.expr_ident(span, tag_tuple[0]));\n-                    let rgt = cx.expr_addr_of(span, cx.expr_ident(span, tag_tuple[1]));\n-                    let fn_cmp_path = cx.std_path(&[sym::cmp, sym::Ord, sym::cmp]);\n-                    cx.expr_call_global(span, fn_cmp_path, vec![lft, rgt])\n-                }\n-            }\n         },\n     );\n     BlockOrExpr::new_expr(expr)"}, {"sha": "0141b337726214877c66d5253825f3ed46a7780d", "filename": "compiler/rustc_builtin_macros/src/deriving/cmp/partial_eq.rs", "status": "modified", "additions": 17, "deletions": 3, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Fpartial_eq.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Fpartial_eq.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Fpartial_eq.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -2,7 +2,8 @@ use crate::deriving::generic::ty::*;\n use crate::deriving::generic::*;\n use crate::deriving::{path_local, path_std};\n \n-use rustc_ast::{BinOpKind, MetaItem};\n+use rustc_ast::ptr::P;\n+use rustc_ast::{BinOpKind, BorrowKind, Expr, ExprKind, MetaItem, Mutability};\n use rustc_expand::base::{Annotatable, ExtCtxt};\n use rustc_span::symbol::sym;\n use rustc_span::Span;\n@@ -32,11 +33,24 @@ pub fn expand_deriving_partial_eq(\n                     let [other_expr] = &field.other_selflike_exprs[..] else {\n                         cx.span_bug(field.span, \"not exactly 2 arguments in `derive(PartialEq)`\");\n                     };\n-                    cx.expr_binary(field.span, op, field.self_expr.clone(), other_expr.clone())\n+\n+                    // We received `&T` arguments. Convert them to `T` by\n+                    // stripping `&` or adding `*`. This isn't necessary for\n+                    // type checking, but it results in much better error\n+                    // messages if something goes wrong.\n+                    let convert = |expr: &P<Expr>| {\n+                        if let ExprKind::AddrOf(BorrowKind::Ref, Mutability::Not, inner) =\n+                            &expr.kind\n+                        {\n+                            inner.clone()\n+                        } else {\n+                            cx.expr_deref(field.span, expr.clone())\n+                        }\n+                    };\n+                    cx.expr_binary(field.span, op, convert(&field.self_expr), convert(other_expr))\n                 }\n                 CsFold::Combine(span, expr1, expr2) => cx.expr_binary(span, combiner, expr1, expr2),\n                 CsFold::Fieldless => cx.expr_bool(span, base),\n-                CsFold::EnumNonMatching(span, _tag_tuple) => cx.expr_bool(span, !base),\n             },\n         );\n         BlockOrExpr::new_expr(expr)"}, {"sha": "2ebb01cc8a0353b4261f437407f83ec1f090a988", "filename": "compiler/rustc_builtin_macros/src/deriving/cmp/partial_ord.rs", "status": "modified", "additions": 1, "deletions": 15, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Fpartial_ord.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Fpartial_ord.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fcmp%2Fpartial_ord.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -71,10 +71,7 @@ pub fn cs_partial_cmp(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_\n                 let [other_expr] = &field.other_selflike_exprs[..] else {\n                         cx.span_bug(field.span, \"not exactly 2 arguments in `derive(Ord)`\");\n                     };\n-                let args = vec![\n-                    cx.expr_addr_of(field.span, field.self_expr.clone()),\n-                    cx.expr_addr_of(field.span, other_expr.clone()),\n-                ];\n+                let args = vec![field.self_expr.clone(), other_expr.clone()];\n                 cx.expr_call_global(field.span, partial_cmp_path.clone(), args)\n             }\n             CsFold::Combine(span, expr1, expr2) => {\n@@ -85,17 +82,6 @@ pub fn cs_partial_cmp(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_\n                 cx.expr_match(span, expr2, vec![eq_arm, neq_arm])\n             }\n             CsFold::Fieldless => cx.expr_some(span, cx.expr_path(equal_path.clone())),\n-            CsFold::EnumNonMatching(span, tag_tuple) => {\n-                if tag_tuple.len() != 2 {\n-                    cx.span_bug(span, \"not exactly 2 arguments in `derive(PartialOrd)`\")\n-                } else {\n-                    let lft = cx.expr_addr_of(span, cx.expr_ident(span, tag_tuple[0]));\n-                    let rgt = cx.expr_addr_of(span, cx.expr_ident(span, tag_tuple[1]));\n-                    let fn_partial_cmp_path =\n-                        cx.std_path(&[sym::cmp, sym::PartialOrd, sym::partial_cmp]);\n-                    cx.expr_call_global(span, fn_partial_cmp_path, vec![lft, rgt])\n-                }\n-            }\n         },\n     );\n     BlockOrExpr::new_expr(expr)"}, {"sha": "ceef893e862eb5350c408ef8b8104f9558a1adc9", "filename": "compiler/rustc_builtin_macros/src/deriving/debug.rs", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fdebug.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fdebug.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fdebug.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -45,7 +45,7 @@ fn show_substructure(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_>\n     let (ident, vdata, fields) = match substr.fields {\n         Struct(vdata, fields) => (substr.type_ident, *vdata, fields),\n         EnumMatching(_, _, v, fields) => (v.ident, &v.data, fields),\n-        EnumNonMatchingCollapsed(..) | StaticStruct(..) | StaticEnum(..) => {\n+        EnumTag(..) | StaticStruct(..) | StaticEnum(..) => {\n             cx.span_bug(span, \"nonsensical .fields in `#[derive(Debug)]`\")\n         }\n     };\n@@ -95,9 +95,8 @@ fn show_substructure(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_>\n                 );\n                 args.push(name);\n             }\n-            // Use double indirection to make sure this works for unsized types\n+            // Use an extra indirection to make sure this works for unsized types.\n             let field = cx.expr_addr_of(field.span, field.self_expr.clone());\n-            let field = cx.expr_addr_of(field.span, field);\n             args.push(field);\n         }\n         let expr = cx.expr_call_global(span, fn_path_debug, args);\n@@ -115,9 +114,9 @@ fn show_substructure(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_>\n                 ));\n             }\n \n-            // Use double indirection to make sure this works for unsized types\n-            let value_ref = cx.expr_addr_of(field.span, field.self_expr.clone());\n-            value_exprs.push(cx.expr_addr_of(field.span, value_ref));\n+            // Use an extra indirection to make sure this works for unsized types.\n+            let field = cx.expr_addr_of(field.span, field.self_expr.clone());\n+            value_exprs.push(field);\n         }\n \n         // `let names: &'static _ = &[\"field1\", \"field2\"];`\n@@ -177,6 +176,6 @@ fn show_substructure(cx: &mut ExtCtxt<'_>, span: Span, substr: &Substructure<'_>\n             stmts.push(names_let.unwrap());\n         }\n         stmts.push(values_let);\n-        BlockOrExpr::new_mixed(stmts, expr)\n+        BlockOrExpr::new_mixed(stmts, Some(expr))\n     }\n }"}, {"sha": "70167cac68a7eb3196197d3b66aad635e4dbe522", "filename": "compiler/rustc_builtin_macros/src/deriving/encodable.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fencodable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fencodable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fencodable.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -287,7 +287,7 @@ fn encodable_substructure(\n                 fn_emit_enum_path,\n                 vec![encoder, cx.expr_str(trait_span, substr.type_ident.name), blk],\n             );\n-            BlockOrExpr::new_mixed(vec![me], expr)\n+            BlockOrExpr::new_mixed(vec![me], Some(expr))\n         }\n \n         _ => cx.bug(\"expected Struct or EnumMatching in derive(Encodable)\"),"}, {"sha": "076b627ca79f6bb6bcf68b052be82282de1c06ef", "filename": "compiler/rustc_builtin_macros/src/deriving/generic/mod.rs", "status": "modified", "additions": 240, "deletions": 248, "changes": 488, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fgeneric%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fgeneric%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fgeneric%2Fmod.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -21,21 +21,14 @@\n //!   `struct T(i32, char)`).\n //! - `EnumMatching`, when `Self` is an enum and all the arguments are the\n //!   same variant of the enum (e.g., `Some(1)`, `Some(3)` and `Some(4)`)\n-//! - `EnumNonMatchingCollapsed` when `Self` is an enum and the arguments\n-//!   are not the same variant (e.g., `None`, `Some(1)` and `None`).\n+//! - `EnumTag` when `Self` is an enum, for comparing the enum tags.\n //! - `StaticEnum` and `StaticStruct` for static methods, where the type\n //!   being derived upon is either an enum or struct respectively. (Any\n //!   argument with type Self is just grouped among the non-self\n //!   arguments.)\n //!\n //! In the first two cases, the values from the corresponding fields in\n-//! all the arguments are grouped together. For `EnumNonMatchingCollapsed`\n-//! this isn't possible (different variants have different fields), so the\n-//! fields are inaccessible. (Previous versions of the deriving infrastructure\n-//! had a way to expand into code that could access them, at the cost of\n-//! generating exponential amounts of code; see issue #15375). There are no\n-//! fields with values in the static cases, so these are treated entirely\n-//! differently.\n+//! all the arguments are grouped together.\n //!\n //! The non-static cases have `Option<ident>` in several places associated\n //! with field `expr`s. This represents the name of the field it is\n@@ -142,21 +135,15 @@\n //!                }])\n //! ```\n //!\n-//! For `C0(a)` and `C1 {x}` ,\n+//! For the tags,\n //!\n //! ```{.text}\n-//! EnumNonMatchingCollapsed(\n-//!     &[<ident for self index value>, <ident of __arg_1 index value>])\n+//! EnumTag(\n+//!     &[<ident of self tag>, <ident of other tag>], <expr to combine with>)\n //! ```\n-//!\n-//! It is the same for when the arguments are flipped to `C1 {x}` and\n-//! `C0(a)`; the only difference is what the values of the identifiers\n-//! <ident for self index value> and <ident of __arg_1 index value> will\n-//! be in the generated code.\n-//!\n-//! `EnumNonMatchingCollapsed` deliberately provides far less information\n-//! than is generally available for a given pair of variants; see #15375\n-//! for discussion.\n+//! Note that this setup doesn't allow for the brute-force \"match every variant\n+//! against every other variant\" approach, which is bad because it produces a\n+//! quadratic amount of code (see #15375).\n //!\n //! ## Static\n //!\n@@ -180,10 +167,9 @@ use std::iter;\n use std::vec;\n \n use rustc_ast::ptr::P;\n-use rustc_ast::{self as ast, BinOpKind, EnumDef, Expr, Generics, PatKind};\n+use rustc_ast::{self as ast, EnumDef, Expr, Generics, PatKind};\n use rustc_ast::{GenericArg, GenericParamKind, VariantData};\n use rustc_attr as attr;\n-use rustc_data_structures::map_in_place::MapInPlace;\n use rustc_expand::base::{Annotatable, ExtCtxt};\n use rustc_span::symbol::{kw, sym, Ident, Symbol};\n use rustc_span::Span;\n@@ -236,6 +222,8 @@ pub struct MethodDef<'a> {\n     pub attributes: Vec<ast::Attribute>,\n \n     /// Can we combine fieldless variants for enums into a single match arm?\n+    /// If true, indicates that the trait operation uses the enum tag in some\n+    /// way.\n     pub unify_fieldless_variants: bool,\n \n     pub combine_substructure: RefCell<CombineSubstructureFunc<'a>>,\n@@ -275,19 +263,22 @@ pub enum StaticFields {\n \n /// A summary of the possible sets of fields.\n pub enum SubstructureFields<'a> {\n+    /// A non-static method with `Self` is a struct.\n     Struct(&'a ast::VariantData, Vec<FieldInfo>),\n+\n     /// Matching variants of the enum: variant index, variant count, ast::Variant,\n     /// fields: the field name is only non-`None` in the case of a struct\n     /// variant.\n     EnumMatching(usize, usize, &'a ast::Variant, Vec<FieldInfo>),\n \n-    /// Non-matching variants of the enum, but with all state hidden from the\n-    /// consequent code. The field is a list of `Ident`s bound to the variant\n-    /// index values for each of the actual input `Self` arguments.\n-    EnumNonMatchingCollapsed(&'a [Ident]),\n+    /// The tag of an enum. The first field is a `FieldInfo` for the tags, as\n+    /// if they were fields. The second field is the expression to combine the\n+    /// tag expression with; it will be `None` if no match is necessary.\n+    EnumTag(FieldInfo, Option<P<Expr>>),\n \n     /// A static method where `Self` is a struct.\n     StaticStruct(&'a ast::VariantData, StaticFields),\n+\n     /// A static method where `Self` is an enum.\n     StaticEnum(&'a ast::EnumDef, Vec<(Ident, Span, StaticFields)>),\n }\n@@ -325,8 +316,8 @@ impl BlockOrExpr {\n         BlockOrExpr(vec![], Some(expr))\n     }\n \n-    pub fn new_mixed(stmts: Vec<ast::Stmt>, expr: P<Expr>) -> BlockOrExpr {\n-        BlockOrExpr(stmts, Some(expr))\n+    pub fn new_mixed(stmts: Vec<ast::Stmt>, expr: Option<P<Expr>>) -> BlockOrExpr {\n+        BlockOrExpr(stmts, expr)\n     }\n \n     // Converts it into a block.\n@@ -344,7 +335,14 @@ impl BlockOrExpr {\n                 None => cx.expr_block(cx.block(span, vec![])),\n                 Some(expr) => expr,\n             }\n+        } else if self.0.len() == 1\n+            && let ast::StmtKind::Expr(expr) = &self.0[0].kind\n+            && self.1.is_none()\n+        {\n+            // There's only a single statement expression. Pull it out.\n+            expr.clone()\n         } else {\n+            // Multiple statements and/or expressions.\n             cx.expr_block(self.into_block(cx, span))\n         }\n     }\n@@ -455,7 +453,6 @@ impl<'a> TraitDef<'a> {\n                 };\n                 let container_id = cx.current_expansion.id.expn_data().parent.expect_local();\n                 let always_copy = has_no_type_params && cx.resolver.has_derive_copy(container_id);\n-                let use_temporaries = is_packed && always_copy;\n \n                 let newitem = match item.kind {\n                     ast::ItemKind::Struct(ref struct_def, ref generics) => self.expand_struct_def(\n@@ -464,11 +461,11 @@ impl<'a> TraitDef<'a> {\n                         item.ident,\n                         generics,\n                         from_scratch,\n-                        use_temporaries,\n                         is_packed,\n+                        always_copy,\n                     ),\n                     ast::ItemKind::Enum(ref enum_def, ref generics) => {\n-                        // We ignore `use_temporaries` here, because\n+                        // We ignore `is_packed`/`always_copy` here, because\n                         // `repr(packed)` enums cause an error later on.\n                         //\n                         // This can only cause further compilation errors\n@@ -484,8 +481,8 @@ impl<'a> TraitDef<'a> {\n                                 item.ident,\n                                 generics,\n                                 from_scratch,\n-                                use_temporaries,\n                                 is_packed,\n+                                always_copy,\n                             )\n                         } else {\n                             cx.span_err(mitem.span, \"this trait cannot be derived for unions\");\n@@ -766,8 +763,8 @@ impl<'a> TraitDef<'a> {\n         type_ident: Ident,\n         generics: &Generics,\n         from_scratch: bool,\n-        use_temporaries: bool,\n         is_packed: bool,\n+        always_copy: bool,\n     ) -> P<ast::Item> {\n         let field_tys: Vec<P<ast::Ty>> =\n             struct_def.fields().iter().map(|field| field.ty.clone()).collect();\n@@ -795,8 +792,8 @@ impl<'a> TraitDef<'a> {\n                         type_ident,\n                         &selflike_args,\n                         &nonselflike_args,\n-                        use_temporaries,\n                         is_packed,\n+                        always_copy,\n                     )\n                 };\n \n@@ -937,9 +934,7 @@ impl<'a> MethodDef<'a> {\n \n             match ty {\n                 // Selflike (`&Self`) arguments only occur in non-static methods.\n-                Ref(box Self_, _) if !self.is_static() => {\n-                    selflike_args.push(cx.expr_deref(span, arg_expr))\n-                }\n+                Ref(box Self_, _) if !self.is_static() => selflike_args.push(arg_expr),\n                 Self_ => cx.span_bug(span, \"`Self` in non-return position\"),\n                 _ => nonselflike_args.push(arg_expr),\n             }\n@@ -1008,7 +1003,7 @@ impl<'a> MethodDef<'a> {\n     /// ```\n     /// #[derive(PartialEq)]\n     /// # struct Dummy;\n-    /// struct A { x: i32, y: i32 }\n+    /// struct A { x: u8, y: u8 }\n     ///\n     /// // equivalent to:\n     /// impl PartialEq for A {\n@@ -1018,11 +1013,27 @@ impl<'a> MethodDef<'a> {\n     /// }\n     /// ```\n     /// But if the struct is `repr(packed)`, we can't use something like\n-    /// `&self.x` on a packed type (as required for e.g. `Debug` and `Hash`)\n-    /// because that might cause an unaligned ref. So we use let-destructuring\n-    /// instead.\n+    /// `&self.x` because that might cause an unaligned ref. So for any trait\n+    /// method that takes a reference, if the struct impls `Copy` then we use a\n+    /// local block to force a copy:\n     /// ```\n-    /// # struct A { x: i32, y: i32 }\n+    /// # struct A { x: u8, y: u8 }\n+    /// impl PartialEq for A {\n+    ///     fn eq(&self, other: &A) -> bool {\n+    ///         // Desugars to `{ self.x }.eq(&{ other.y }) && ...`\n+    ///         { self.x } == { other.y } && { self.y } == { other.y }\n+    ///     }\n+    /// }\n+    /// impl Hash for A {\n+    ///     fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n+    ///         ::core::hash::Hash::hash(&{ self.x }, state);\n+    ///         ::core::hash::Hash::hash(&{ self.y }, state)\n+    ///     }\n+    /// }\n+    /// ```\n+    /// If the struct doesn't impl `Copy`, we use let-destructuring with `ref`:\n+    /// ```\n+    /// # struct A { x: u8, y: u8 }\n     /// impl PartialEq for A {\n     ///     fn eq(&self, other: &A) -> bool {\n     ///         let Self { x: ref __self_0_0, y: ref __self_0_1 } = *self;\n@@ -1031,6 +1042,8 @@ impl<'a> MethodDef<'a> {\n     ///     }\n     /// }\n     /// ```\n+    /// This latter case only works if the fields match the alignment required\n+    /// by the `packed(N)` attribute. (We'll get errors later on if not.)\n     fn expand_struct_method_body<'b>(\n         &self,\n         cx: &mut ExtCtxt<'_>,\n@@ -1039,8 +1052,8 @@ impl<'a> MethodDef<'a> {\n         type_ident: Ident,\n         selflike_args: &[P<Expr>],\n         nonselflike_args: &[P<Expr>],\n-        use_temporaries: bool,\n         is_packed: bool,\n+        always_copy: bool,\n     ) -> BlockOrExpr {\n         let span = trait_.span;\n         assert!(selflike_args.len() == 1 || selflike_args.len() == 2);\n@@ -1057,29 +1070,31 @@ impl<'a> MethodDef<'a> {\n \n         if !is_packed {\n             let selflike_fields =\n-                trait_.create_struct_field_access_fields(cx, selflike_args, struct_def);\n+                trait_.create_struct_field_access_fields(cx, selflike_args, struct_def, false);\n+            mk_body(cx, selflike_fields)\n+        } else if always_copy {\n+            let selflike_fields =\n+                trait_.create_struct_field_access_fields(cx, selflike_args, struct_def, true);\n             mk_body(cx, selflike_fields)\n         } else {\n+            // Neither packed nor copy. Need to use ref patterns.\n             let prefixes: Vec<_> =\n                 (0..selflike_args.len()).map(|i| format!(\"__self_{}\", i)).collect();\n+            let addr_of = always_copy;\n             let selflike_fields =\n-                trait_.create_struct_pattern_fields(cx, struct_def, &prefixes, use_temporaries);\n+                trait_.create_struct_pattern_fields(cx, struct_def, &prefixes, addr_of);\n             let mut body = mk_body(cx, selflike_fields);\n \n             let struct_path = cx.path(span, vec![Ident::new(kw::SelfUpper, type_ident.span)]);\n-            let patterns = trait_.create_struct_patterns(\n-                cx,\n-                struct_path,\n-                struct_def,\n-                &prefixes,\n-                ast::Mutability::Not,\n-                use_temporaries,\n-            );\n+            let use_ref_pat = is_packed && !always_copy;\n+            let patterns =\n+                trait_.create_struct_patterns(cx, struct_path, struct_def, &prefixes, use_ref_pat);\n \n             // Do the let-destructuring.\n             let mut stmts: Vec<_> = iter::zip(selflike_args, patterns)\n                 .map(|(selflike_arg_expr, pat)| {\n-                    cx.stmt_let_pat(span, pat, selflike_arg_expr.clone())\n+                    let selflike_arg_expr = cx.expr_deref(span, selflike_arg_expr.clone());\n+                    cx.stmt_let_pat(span, pat, selflike_arg_expr)\n                 })\n                 .collect();\n             stmts.extend(std::mem::take(&mut body.0));\n@@ -1119,82 +1134,128 @@ impl<'a> MethodDef<'a> {\n     /// impl ::core::cmp::PartialEq for A {\n     ///     #[inline]\n     ///     fn eq(&self, other: &A) -> bool {\n-    ///         {\n-    ///             let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-    ///             let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-    ///             if true && __self_vi == __arg_1_vi {\n-    ///                 match (&*self, &*other) {\n-    ///                     (&A::A2(ref __self_0), &A::A2(ref __arg_1_0)) =>\n-    ///                         (*__self_0) == (*__arg_1_0),\n-    ///                     _ => true,\n-    ///                 }\n-    ///             } else {\n-    ///                 false // catch-all handler\n+    ///         let __self_tag = ::core::intrinsics::discriminant_value(self);\n+    ///         let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+    ///         __self_tag == __arg1_tag &&\n+    ///             match (self, other) {\n+    ///                 (A::A2(__self_0), A::A2(__arg1_0)) =>\n+    ///                     *__self_0 == *__arg1_0,\n+    ///                 _ => true,\n     ///             }\n-    ///         }\n     ///     }\n     /// }\n     /// ```\n-    /// Creates a match for a tuple of all `selflike_args`, where either all\n-    /// variants match, or it falls into a catch-all for when one variant\n-    /// does not match.\n-    ///\n-    /// There are N + 1 cases because is a case for each of the N\n-    /// variants where all of the variants match, and one catch-all for\n-    /// when one does not match.\n-    ///\n-    /// As an optimization we generate code which checks whether all variants\n-    /// match first which makes llvm see that C-like enums can be compiled into\n-    /// a simple equality check (for PartialEq).\n-    ///\n-    /// The catch-all handler is provided access the variant index values\n-    /// for each of the selflike_args, carried in precomputed variables.\n+    /// Creates a tag check combined with a match for a tuple of all\n+    /// `selflike_args`, with an arm for each variant with fields, possibly an\n+    /// arm for each fieldless variant (if `!unify_fieldless_variants` is not\n+    /// true), and possibly a default arm.\n     fn expand_enum_method_body<'b>(\n         &self,\n         cx: &mut ExtCtxt<'_>,\n         trait_: &TraitDef<'b>,\n         enum_def: &'b EnumDef,\n         type_ident: Ident,\n-        mut selflike_args: Vec<P<Expr>>,\n+        selflike_args: Vec<P<Expr>>,\n         nonselflike_args: &[P<Expr>],\n     ) -> BlockOrExpr {\n         let span = trait_.span;\n         let variants = &enum_def.variants;\n \n+        // Traits that unify fieldless variants always use the tag(s).\n+        let uses_tags = self.unify_fieldless_variants;\n+\n+        // There is no sensible code to be generated for *any* deriving on a\n+        // zero-variant enum. So we just generate a failing expression.\n+        if variants.is_empty() {\n+            return BlockOrExpr(vec![], Some(deriving::call_unreachable(cx, span)));\n+        }\n+\n         let prefixes = iter::once(\"__self\".to_string())\n             .chain(\n                 selflike_args\n                     .iter()\n                     .enumerate()\n                     .skip(1)\n-                    .map(|(arg_count, _selflike_arg)| format!(\"__arg_{}\", arg_count)),\n+                    .map(|(arg_count, _selflike_arg)| format!(\"__arg{}\", arg_count)),\n             )\n             .collect::<Vec<String>>();\n \n-        // The `vi_idents` will be bound, solely in the catch-all, to\n-        // a series of let statements mapping each selflike_arg to an int\n-        // value corresponding to its discriminant.\n-        let vi_idents = prefixes\n-            .iter()\n-            .map(|name| {\n-                let vi_suffix = format!(\"{}_vi\", name);\n-                Ident::from_str_and_span(&vi_suffix, span)\n-            })\n-            .collect::<Vec<Ident>>();\n+        // Build a series of let statements mapping each selflike_arg\n+        // to its discriminant value.\n+        //\n+        // e.g. for `PartialEq::eq` builds two statements:\n+        // ```\n+        // let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        // let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        // ```\n+        let get_tag_pieces = |cx: &ExtCtxt<'_>| {\n+            let tag_idents: Vec<_> = prefixes\n+                .iter()\n+                .map(|name| Ident::from_str_and_span(&format!(\"{}_tag\", name), span))\n+                .collect();\n \n-        // Builds, via callback to call_substructure_method, the\n-        // delegated expression that handles the catch-all case,\n-        // using `__variants_tuple` to drive logic if necessary.\n-        let catch_all_substructure = EnumNonMatchingCollapsed(&vi_idents);\n+            let mut tag_exprs: Vec<_> = tag_idents\n+                .iter()\n+                .map(|&ident| cx.expr_addr_of(span, cx.expr_ident(span, ident)))\n+                .collect();\n \n-        let first_fieldless = variants.iter().find(|v| v.data.fields().is_empty());\n+            let self_expr = tag_exprs.remove(0);\n+            let other_selflike_exprs = tag_exprs;\n+            let tag_field = FieldInfo { span, name: None, self_expr, other_selflike_exprs };\n+\n+            let tag_let_stmts: Vec<_> = iter::zip(&tag_idents, &selflike_args)\n+                .map(|(&ident, selflike_arg)| {\n+                    let variant_value = deriving::call_intrinsic(\n+                        cx,\n+                        span,\n+                        sym::discriminant_value,\n+                        vec![selflike_arg.clone()],\n+                    );\n+                    cx.stmt_let(span, false, ident, variant_value)\n+                })\n+                .collect();\n+\n+            (tag_field, tag_let_stmts)\n+        };\n+\n+        // There are some special cases involving fieldless enums where no\n+        // match is necessary.\n+        let all_fieldless = variants.iter().all(|v| v.data.fields().is_empty());\n+        if all_fieldless {\n+            if uses_tags && variants.len() > 1 {\n+                // If the type is fieldless and the trait uses the tag and\n+                // there are multiple variants, we need just an operation on\n+                // the tag(s).\n+                let (tag_field, mut tag_let_stmts) = get_tag_pieces(cx);\n+                let mut tag_check = self.call_substructure_method(\n+                    cx,\n+                    trait_,\n+                    type_ident,\n+                    nonselflike_args,\n+                    &EnumTag(tag_field, None),\n+                );\n+                tag_let_stmts.append(&mut tag_check.0);\n+                return BlockOrExpr(tag_let_stmts, tag_check.1);\n+            }\n+\n+            if variants.len() == 1 {\n+                // If there is a single variant, we don't need an operation on\n+                // the tag(s). Just use the most degenerate result.\n+                return self.call_substructure_method(\n+                    cx,\n+                    trait_,\n+                    type_ident,\n+                    nonselflike_args,\n+                    &EnumMatching(0, 1, &variants[0], Vec::new()),\n+                );\n+            };\n+        }\n \n         // These arms are of the form:\n         // (Variant1, Variant1, ...) => Body1\n         // (Variant2, Variant2, ...) => Body2\n         // ...\n         // where each tuple has length = selflike_args.len()\n-\n         let mut match_arms: Vec<ast::Arm> = variants\n             .iter()\n             .enumerate()\n@@ -1203,30 +1264,22 @@ impl<'a> MethodDef<'a> {\n                 // A single arm has form (&VariantK, &VariantK, ...) => BodyK\n                 // (see \"Final wrinkle\" note below for why.)\n \n-                let use_temporaries = false; // enums can't be repr(packed)\n-                let fields = trait_.create_struct_pattern_fields(\n+                let addr_of = false; // because enums can't be repr(packed)\n+                let fields =\n+                    trait_.create_struct_pattern_fields(cx, &variant.data, &prefixes, addr_of);\n+\n+                let sp = variant.span.with_ctxt(trait_.span.ctxt());\n+                let variant_path = cx.path(sp, vec![type_ident, variant.ident]);\n+                let use_ref_pat = false; // because enums can't be repr(packed)\n+                let mut subpats: Vec<_> = trait_.create_struct_patterns(\n                     cx,\n+                    variant_path,\n                     &variant.data,\n                     &prefixes,\n-                    use_temporaries,\n+                    use_ref_pat,\n                 );\n \n-                let sp = variant.span.with_ctxt(trait_.span.ctxt());\n-                let variant_path = cx.path(sp, vec![type_ident, variant.ident]);\n-                let mut subpats: Vec<_> = trait_\n-                    .create_struct_patterns(\n-                        cx,\n-                        variant_path,\n-                        &variant.data,\n-                        &prefixes,\n-                        ast::Mutability::Not,\n-                        use_temporaries,\n-                    )\n-                    .into_iter()\n-                    .map(|p| cx.pat(span, PatKind::Ref(p, ast::Mutability::Not)))\n-                    .collect();\n-\n-                // Here is the pat = `(&VariantK, &VariantK, ...)`\n+                // `(VariantK, VariantK, ...)` or just `VariantK`.\n                 let single_pat = if subpats.len() == 1 {\n                     subpats.pop().unwrap()\n                 } else {\n@@ -1256,27 +1309,28 @@ impl<'a> MethodDef<'a> {\n             })\n             .collect();\n \n+        // Add a default arm to the match, if necessary.\n+        let first_fieldless = variants.iter().find(|v| v.data.fields().is_empty());\n         let default = match first_fieldless {\n             Some(v) if self.unify_fieldless_variants => {\n-                // We need a default case that handles the fieldless variants.\n-                // The index and actual variant aren't meaningful in this case,\n-                // so just use whatever\n-                let substructure = EnumMatching(0, variants.len(), v, Vec::new());\n+                // We need a default case that handles all the fieldless\n+                // variants. The index and actual variant aren't meaningful in\n+                // this case, so just use dummy values.\n                 Some(\n                     self.call_substructure_method(\n                         cx,\n                         trait_,\n                         type_ident,\n                         nonselflike_args,\n-                        &substructure,\n+                        &EnumMatching(0, variants.len(), v, Vec::new()),\n                     )\n                     .into_expr(cx, span),\n                 )\n             }\n             _ if variants.len() > 1 && selflike_args.len() > 1 => {\n-                // Since we know that all the arguments will match if we reach\n+                // Because we know that all the arguments will match if we reach\n                 // the match expression we add the unreachable intrinsics as the\n-                // result of the catch all which should help llvm in optimizing it\n+                // result of the default which should help llvm in optimizing it.\n                 Some(deriving::call_unreachable(cx, span))\n             }\n             _ => None,\n@@ -1285,111 +1339,41 @@ impl<'a> MethodDef<'a> {\n             match_arms.push(cx.arm(span, cx.pat_wild(span), arm));\n         }\n \n-        // We will usually need the catch-all after matching the\n-        // tuples `(VariantK, VariantK, ...)` for each VariantK of the\n-        // enum.  But:\n-        //\n-        // * when there is only one Self arg, the arms above suffice\n-        // (and the deriving we call back into may not be prepared to\n-        // handle EnumNonMatchCollapsed), and,\n-        //\n-        // * when the enum has only one variant, the single arm that\n-        // is already present always suffices.\n-        //\n-        // * In either of the two cases above, if we *did* add a\n-        //   catch-all `_` match, it would trigger the\n-        //   unreachable-pattern error.\n-        //\n-        if variants.len() > 1 && selflike_args.len() > 1 {\n-            // Build a series of let statements mapping each selflike_arg\n-            // to its discriminant value.\n-            //\n-            // i.e., for `enum E<T> { A, B(1), C(T, T) }`, and a deriving\n-            // with three Self args, builds three statements:\n-            // ```\n-            // let __self_vi = std::intrinsics::discriminant_value(&self);\n-            // let __arg_1_vi = std::intrinsics::discriminant_value(&arg1);\n-            // let __arg_2_vi = std::intrinsics::discriminant_value(&arg2);\n-            // ```\n-            let mut index_let_stmts: Vec<ast::Stmt> = Vec::with_capacity(vi_idents.len() + 1);\n-\n-            // We also build an expression which checks whether all discriminants are equal:\n-            // `__self_vi == __arg_1_vi && __self_vi == __arg_2_vi && ...`\n-            let mut discriminant_test = cx.expr_bool(span, true);\n-            for (i, (&ident, selflike_arg)) in iter::zip(&vi_idents, &selflike_args).enumerate() {\n-                let selflike_addr = cx.expr_addr_of(span, selflike_arg.clone());\n-                let variant_value = deriving::call_intrinsic(\n-                    cx,\n-                    span,\n-                    sym::discriminant_value,\n-                    vec![selflike_addr],\n-                );\n-                let let_stmt = cx.stmt_let(span, false, ident, variant_value);\n-                index_let_stmts.push(let_stmt);\n-\n-                if i > 0 {\n-                    let id0 = cx.expr_ident(span, vi_idents[0]);\n-                    let id = cx.expr_ident(span, ident);\n-                    let test = cx.expr_binary(span, BinOpKind::Eq, id0, id);\n-                    discriminant_test = if i == 1 {\n-                        test\n-                    } else {\n-                        cx.expr_binary(span, BinOpKind::And, discriminant_test, test)\n-                    };\n-                }\n-            }\n-\n-            let arm_expr = self\n-                .call_substructure_method(\n-                    cx,\n-                    trait_,\n-                    type_ident,\n-                    nonselflike_args,\n-                    &catch_all_substructure,\n-                )\n-                .into_expr(cx, span);\n-\n-            // Final wrinkle: the selflike_args are expressions that deref\n-            // down to desired places, but we cannot actually deref\n-            // them when they are fed as r-values into a tuple\n-            // expression; here add a layer of borrowing, turning\n-            // `(*self, *__arg_0, ...)` into `(&*self, &*__arg_0, ...)`.\n-            selflike_args.map_in_place(|selflike_arg| cx.expr_addr_of(span, selflike_arg));\n-            let match_arg = cx.expr(span, ast::ExprKind::Tup(selflike_args));\n-\n-            // Lastly we create an expression which branches on all discriminants being equal\n-            //  if discriminant_test {\n-            //      match (...) {\n-            //          (Variant1, Variant1, ...) => Body1\n-            //          (Variant2, Variant2, ...) => Body2,\n-            //          ...\n-            //          _ => ::core::intrinsics::unreachable()\n-            //      }\n-            //  }\n-            //  else {\n-            //      <delegated expression referring to __self_vi, et al.>\n-            //  }\n-            let all_match = cx.expr_match(span, match_arg, match_arms);\n-            let arm_expr = cx.expr_if(span, discriminant_test, all_match, Some(arm_expr));\n-            BlockOrExpr(index_let_stmts, Some(arm_expr))\n-        } else if variants.is_empty() {\n-            // There is no sensible code to be generated for *any* deriving on\n-            // a zero-variant enum. So we just generate a failing expression\n-            // for the zero variant case.\n-            BlockOrExpr(vec![], Some(deriving::call_unreachable(cx, span)))\n-        } else {\n-            // Final wrinkle: the selflike_args are expressions that deref\n-            // down to desired places, but we cannot actually deref\n-            // them when they are fed as r-values into a tuple\n-            // expression; here add a layer of borrowing, turning\n-            // `(*self, *__arg_0, ...)` into `(&*self, &*__arg_0, ...)`.\n-            selflike_args.map_in_place(|selflike_arg| cx.expr_addr_of(span, selflike_arg));\n+        // Create a match expression with one arm per discriminant plus\n+        // possibly a default arm, e.g.:\n+        //      match (self, other) {\n+        //          (Variant1, Variant1, ...) => Body1\n+        //          (Variant2, Variant2, ...) => Body2,\n+        //          ...\n+        //          _ => ::core::intrinsics::unreachable()\n+        //      }\n+        let get_match_expr = |mut selflike_args: Vec<P<Expr>>| {\n             let match_arg = if selflike_args.len() == 1 {\n                 selflike_args.pop().unwrap()\n             } else {\n                 cx.expr(span, ast::ExprKind::Tup(selflike_args))\n             };\n-            BlockOrExpr(vec![], Some(cx.expr_match(span, match_arg, match_arms)))\n+            cx.expr_match(span, match_arg, match_arms)\n+        };\n+\n+        // If the trait uses the tag and there are multiple variants, we need\n+        // to add a tag check operation before the match. Otherwise, the match\n+        // is enough.\n+        if uses_tags && variants.len() > 1 {\n+            let (tag_field, mut tag_let_stmts) = get_tag_pieces(cx);\n+\n+            // Combine a tag check with the match.\n+            let mut tag_check_plus_match = self.call_substructure_method(\n+                cx,\n+                trait_,\n+                type_ident,\n+                nonselflike_args,\n+                &EnumTag(tag_field, Some(get_match_expr(selflike_args))),\n+            );\n+            tag_let_stmts.append(&mut tag_check_plus_match.0);\n+            BlockOrExpr(tag_let_stmts, tag_check_plus_match.1)\n+        } else {\n+            BlockOrExpr(vec![], Some(get_match_expr(selflike_args)))\n         }\n     }\n \n@@ -1453,19 +1437,18 @@ impl<'a> TraitDef<'a> {\n         struct_path: ast::Path,\n         struct_def: &'a VariantData,\n         prefixes: &[String],\n-        mutbl: ast::Mutability,\n-        use_temporaries: bool,\n+        use_ref_pat: bool,\n     ) -> Vec<P<ast::Pat>> {\n         prefixes\n             .iter()\n             .map(|prefix| {\n                 let pieces_iter =\n                     struct_def.fields().iter().enumerate().map(|(i, struct_field)| {\n                         let sp = struct_field.span.with_ctxt(self.span.ctxt());\n-                        let binding_mode = if use_temporaries {\n-                            ast::BindingMode::ByValue(ast::Mutability::Not)\n+                        let binding_mode = if use_ref_pat {\n+                            ast::BindingMode::ByRef(ast::Mutability::Not)\n                         } else {\n-                            ast::BindingMode::ByRef(mutbl)\n+                            ast::BindingMode::ByValue(ast::Mutability::Not)\n                         };\n                         let ident = self.mk_pattern_ident(prefix, i);\n                         let path = ident.with_span_pos(sp);\n@@ -1544,15 +1527,15 @@ impl<'a> TraitDef<'a> {\n         cx: &mut ExtCtxt<'_>,\n         struct_def: &'a VariantData,\n         prefixes: &[String],\n-        use_temporaries: bool,\n+        addr_of: bool,\n     ) -> Vec<FieldInfo> {\n         self.create_fields(struct_def, |i, _struct_field, sp| {\n             prefixes\n                 .iter()\n                 .map(|prefix| {\n                     let ident = self.mk_pattern_ident(prefix, i);\n                     let expr = cx.expr_path(cx.path_ident(sp, ident));\n-                    if use_temporaries { expr } else { cx.expr_deref(sp, expr) }\n+                    if addr_of { cx.expr_addr_of(sp, expr) } else { expr }\n                 })\n                 .collect()\n         })\n@@ -1563,28 +1546,31 @@ impl<'a> TraitDef<'a> {\n         cx: &mut ExtCtxt<'_>,\n         selflike_args: &[P<Expr>],\n         struct_def: &'a VariantData,\n+        copy: bool,\n     ) -> Vec<FieldInfo> {\n         self.create_fields(struct_def, |i, struct_field, sp| {\n             selflike_args\n                 .iter()\n-                .map(|mut selflike_arg| {\n-                    // We don't the need the deref, if there is one.\n-                    if let ast::ExprKind::Unary(ast::UnOp::Deref, inner) = &selflike_arg.kind {\n-                        selflike_arg = inner;\n-                    }\n-                    // Note: we must use `struct_field.span` rather than `span` in the\n+                .map(|selflike_arg| {\n+                    // Note: we must use `struct_field.span` rather than `sp` in the\n                     // `unwrap_or_else` case otherwise the hygiene is wrong and we get\n                     // \"field `0` of struct `Point` is private\" errors on tuple\n                     // structs.\n-                    cx.expr(\n+                    let mut field_expr = cx.expr(\n                         sp,\n                         ast::ExprKind::Field(\n                             selflike_arg.clone(),\n                             struct_field.ident.unwrap_or_else(|| {\n                                 Ident::from_str_and_span(&i.to_string(), struct_field.span)\n                             }),\n                         ),\n-                    )\n+                    );\n+                    if copy {\n+                        field_expr = cx.expr_block(\n+                            cx.block(struct_field.span, vec![cx.stmt_expr(field_expr)]),\n+                        );\n+                    }\n+                    cx.expr_addr_of(sp, field_expr)\n                 })\n                 .collect()\n         })\n@@ -1605,11 +1591,6 @@ pub enum CsFold<'a> {\n \n     // The fallback case for a struct or enum variant with no fields.\n     Fieldless,\n-\n-    /// The fallback case for non-matching enum variants. The slice is the\n-    /// identifiers holding the variant index value for each of the `Self`\n-    /// arguments.\n-    EnumNonMatching(Span, &'a [Ident]),\n }\n \n /// Folds over fields, combining the expressions for each field in a sequence.\n@@ -1624,8 +1605,8 @@ pub fn cs_fold<F>(\n where\n     F: FnMut(&mut ExtCtxt<'_>, CsFold<'_>) -> P<Expr>,\n {\n-    match *substructure.fields {\n-        EnumMatching(.., ref all_fields) | Struct(_, ref all_fields) => {\n+    match substructure.fields {\n+        EnumMatching(.., all_fields) | Struct(_, all_fields) => {\n             if all_fields.is_empty() {\n                 return f(cx, CsFold::Fieldless);\n             }\n@@ -1649,7 +1630,18 @@ where\n                 rest.iter().rfold(base_expr, op)\n             }\n         }\n-        EnumNonMatchingCollapsed(tuple) => f(cx, CsFold::EnumNonMatching(trait_span, tuple)),\n+        EnumTag(tag_field, match_expr) => {\n+            let tag_check_expr = f(cx, CsFold::Single(tag_field));\n+            if let Some(match_expr) = match_expr {\n+                if use_foldl {\n+                    f(cx, CsFold::Combine(trait_span, tag_check_expr, match_expr.clone()))\n+                } else {\n+                    f(cx, CsFold::Combine(trait_span, match_expr.clone(), tag_check_expr))\n+                }\n+            } else {\n+                tag_check_expr\n+            }\n+        }\n         StaticEnum(..) | StaticStruct(..) => cx.span_bug(trait_span, \"static function in `derive`\"),\n     }\n }"}, {"sha": "4d46f7cd48a5107117d36938df28808b379dedd5", "filename": "compiler/rustc_builtin_macros/src/deriving/generic/ty.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fgeneric%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fgeneric%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fgeneric%2Fty.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -196,9 +196,8 @@ impl Bounds {\n }\n \n pub fn get_explicit_self(cx: &ExtCtxt<'_>, span: Span) -> (P<Expr>, ast::ExplicitSelf) {\n-    // this constructs a fresh `self` path\n+    // This constructs a fresh `self` path.\n     let self_path = cx.expr_self(span);\n     let self_ty = respan(span, SelfKind::Region(None, ast::Mutability::Not));\n-    let self_expr = cx.expr_deref(span, self_path);\n-    (self_expr, self_ty)\n+    (self_path, self_ty)\n }"}, {"sha": "32ae3d3447896eeb8cdf4abd4c67147b9fd57b07", "filename": "compiler/rustc_builtin_macros/src/deriving/hash.rs", "status": "modified", "additions": 14, "deletions": 24, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fhash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fhash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fderiving%2Fhash.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -1,6 +1,6 @@\n use crate::deriving::generic::ty::*;\n use crate::deriving::generic::*;\n-use crate::deriving::{self, path_std, pathvec_std};\n+use crate::deriving::{path_std, pathvec_std};\n \n use rustc_ast::{MetaItem, Mutability};\n use rustc_expand::base::{Annotatable, ExtCtxt};\n@@ -52,39 +52,29 @@ fn hash_substructure(\n     let [state_expr] = substr.nonselflike_args else {\n         cx.span_bug(trait_span, \"incorrect number of arguments in `derive(Hash)`\");\n     };\n-    let call_hash = |span, thing_expr| {\n+    let call_hash = |span, expr| {\n         let hash_path = {\n             let strs = cx.std_path(&[sym::hash, sym::Hash, sym::hash]);\n \n             cx.expr_path(cx.path_global(span, strs))\n         };\n-        let ref_thing = cx.expr_addr_of(span, thing_expr);\n-        let expr = cx.expr_call(span, hash_path, vec![ref_thing, state_expr.clone()]);\n+        let expr = cx.expr_call(span, hash_path, vec![expr, state_expr.clone()]);\n         cx.stmt_expr(expr)\n     };\n-    let mut stmts = Vec::new();\n \n-    let fields = match substr.fields {\n-        Struct(_, fs) | EnumMatching(_, 1, .., fs) => fs,\n-        EnumMatching(.., fs) => {\n-            let variant_value = deriving::call_intrinsic(\n-                cx,\n-                trait_span,\n-                sym::discriminant_value,\n-                vec![cx.expr_self(trait_span)],\n-            );\n-\n-            stmts.push(call_hash(trait_span, variant_value));\n-\n-            fs\n+    let (stmts, match_expr) = match substr.fields {\n+        Struct(_, fields) | EnumMatching(.., fields) => {\n+            let stmts =\n+                fields.iter().map(|field| call_hash(field.span, field.self_expr.clone())).collect();\n+            (stmts, None)\n+        }\n+        EnumTag(tag_field, match_expr) => {\n+            assert!(tag_field.other_selflike_exprs.is_empty());\n+            let stmts = vec![call_hash(tag_field.span, tag_field.self_expr.clone())];\n+            (stmts, match_expr.clone())\n         }\n         _ => cx.span_bug(trait_span, \"impossible substructure in `derive(Hash)`\"),\n     };\n \n-    stmts.extend(\n-        fields\n-            .iter()\n-            .map(|FieldInfo { ref self_expr, span, .. }| call_hash(*span, self_expr.clone())),\n-    );\n-    BlockOrExpr::new_stmts(stmts)\n+    BlockOrExpr::new_mixed(stmts, match_expr)\n }"}, {"sha": "aef79ae8a5b8d332e6eebd9dba46f06d25dd6a7f", "filename": "src/test/ui/deriving/deriving-all-codegen.rs", "status": "modified", "additions": 23, "deletions": 3, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/src%2Ftest%2Fui%2Fderiving%2Fderiving-all-codegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/src%2Ftest%2Fui%2Fderiving%2Fderiving-all-codegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fderiving%2Fderiving-all-codegen.rs?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -31,13 +31,26 @@ struct Point {\n // A large struct.\n #[derive(Clone, Debug, Default, Hash, PartialEq, Eq, PartialOrd, Ord)]\n struct Big {\n-    b1: u32, b2: u32, b3: u32, b4: u32, b5: u32, b6: u32, b7: u32, b8:u32,\n+    b1: u32, b2: u32, b3: u32, b4: u32, b5: u32, b6: u32, b7: u32, b8: u32,\n }\n \n-// A packed tuple struct.\n+// A struct with an unsized field. Some derives are not usable in this case.\n+#[derive(Debug, Hash, PartialEq, Eq, PartialOrd, Ord)]\n+struct Unsized([u32]);\n+\n+// A packed tuple struct that impls `Copy`.\n #[derive(Clone, Copy, Debug, Default, Hash, PartialEq, Eq, PartialOrd, Ord)]\n #[repr(packed)]\n-struct Packed(u32);\n+struct PackedCopy(u32);\n+\n+// A packed tuple struct that does not impl `Copy`. Note that the alignment of\n+// the field must be 1 for this code to be valid. Otherwise it triggers an\n+// error \"`#[derive]` can't be used on a `#[repr(packed)]` struct that does not\n+// derive Copy (error E0133)\" at MIR building time. This is a weird case and\n+// it's possible that this struct is not supposed to work, but for now it does.\n+#[derive(Clone, Debug, Default, Hash, PartialEq, Eq, PartialOrd, Ord)]\n+#[repr(packed)]\n+struct PackedNonCopy(u8);\n \n // An empty enum.\n #[derive(Clone, Copy, Debug, Hash, PartialEq, Eq, PartialOrd, Ord)]\n@@ -49,6 +62,13 @@ enum Enum1 {\n     Single { x: u32 }\n }\n \n+// A C-like, fieldless enum with a single variant.\n+#[derive(Clone, Debug, Default, Hash, PartialEq, Eq, PartialOrd, Ord)]\n+enum Fieldless1 {\n+    #[default]\n+    A,\n+}\n+\n // A C-like, fieldless enum.\n #[derive(Clone, Copy, Debug, Default, Hash, PartialEq, Eq, PartialOrd, Ord)]\n enum Fieldless {"}, {"sha": "542911537be7e62300fd979466d67273937e5a42", "filename": "src/test/ui/deriving/deriving-all-codegen.stdout", "status": "modified", "additions": 409, "deletions": 252, "changes": 661, "blob_url": "https://github.com/rust-lang/rust/blob/0fe5390a885eb47f506bf481cd9ea2b449705d79/src%2Ftest%2Fui%2Fderiving%2Fderiving-all-codegen.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/0fe5390a885eb47f506bf481cd9ea2b449705d79/src%2Ftest%2Fui%2Fderiving%2Fderiving-all-codegen.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fderiving%2Fderiving-all-codegen.stdout?ref=0fe5390a885eb47f506bf481cd9ea2b449705d79", "patch": "@@ -367,91 +367,225 @@ impl ::core::cmp::Ord for Big {\n     }\n }\n \n-// A packed tuple struct.\n+// A struct with an unsized field. Some derives are not usable in this case.\n+struct Unsized([u32]);\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::fmt::Debug for Unsized {\n+    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n+        ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"Unsized\",\n+            &&self.0)\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::hash::Hash for Unsized {\n+    fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n+        ::core::hash::Hash::hash(&self.0, state)\n+    }\n+}\n+impl ::core::marker::StructuralPartialEq for Unsized {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::PartialEq for Unsized {\n+    #[inline]\n+    fn eq(&self, other: &Unsized) -> bool { self.0 == other.0 }\n+    #[inline]\n+    fn ne(&self, other: &Unsized) -> bool { self.0 != other.0 }\n+}\n+impl ::core::marker::StructuralEq for Unsized {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Eq for Unsized {\n+    #[inline]\n+    #[doc(hidden)]\n+    #[no_coverage]\n+    fn assert_receiver_is_total_eq(&self) -> () {\n+        let _: ::core::cmp::AssertParamIsEq<[u32]>;\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::PartialOrd for Unsized {\n+    #[inline]\n+    fn partial_cmp(&self, other: &Unsized)\n+        -> ::core::option::Option<::core::cmp::Ordering> {\n+        ::core::cmp::PartialOrd::partial_cmp(&self.0, &other.0)\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Ord for Unsized {\n+    #[inline]\n+    fn cmp(&self, other: &Unsized) -> ::core::cmp::Ordering {\n+        ::core::cmp::Ord::cmp(&self.0, &other.0)\n+    }\n+}\n+\n+// A packed tuple struct that impls `Copy`.\n #[repr(packed)]\n-struct Packed(u32);\n+struct PackedCopy(u32);\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::clone::Clone for Packed {\n+impl ::core::clone::Clone for PackedCopy {\n     #[inline]\n-    fn clone(&self) -> Packed {\n+    fn clone(&self) -> PackedCopy {\n         let _: ::core::clone::AssertParamIsClone<u32>;\n         *self\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::marker::Copy for Packed { }\n+impl ::core::marker::Copy for PackedCopy { }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::fmt::Debug for Packed {\n+impl ::core::fmt::Debug for PackedCopy {\n     fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n-        let Self(__self_0_0) = *self;\n-        ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"Packed\",\n-            &&__self_0_0)\n+        ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"PackedCopy\",\n+            &&{ self.0 })\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::default::Default for Packed {\n+impl ::core::default::Default for PackedCopy {\n     #[inline]\n-    fn default() -> Packed { Packed(::core::default::Default::default()) }\n+    fn default() -> PackedCopy {\n+        PackedCopy(::core::default::Default::default())\n+    }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::hash::Hash for Packed {\n+impl ::core::hash::Hash for PackedCopy {\n     fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n-        let Self(__self_0_0) = *self;\n-        ::core::hash::Hash::hash(&__self_0_0, state)\n+        ::core::hash::Hash::hash(&{ self.0 }, state)\n+    }\n+}\n+impl ::core::marker::StructuralPartialEq for PackedCopy {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::PartialEq for PackedCopy {\n+    #[inline]\n+    fn eq(&self, other: &PackedCopy) -> bool { { self.0 } == { other.0 } }\n+    #[inline]\n+    fn ne(&self, other: &PackedCopy) -> bool { { self.0 } != { other.0 } }\n+}\n+impl ::core::marker::StructuralEq for PackedCopy {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Eq for PackedCopy {\n+    #[inline]\n+    #[doc(hidden)]\n+    #[no_coverage]\n+    fn assert_receiver_is_total_eq(&self) -> () {\n+        let _: ::core::cmp::AssertParamIsEq<u32>;\n     }\n }\n-impl ::core::marker::StructuralPartialEq for Packed {}\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::cmp::PartialEq for Packed {\n+impl ::core::cmp::PartialOrd for PackedCopy {\n     #[inline]\n-    fn eq(&self, other: &Packed) -> bool {\n-        let Self(__self_0_0) = *self;\n-        let Self(__self_1_0) = *other;\n-        __self_0_0 == __self_1_0\n+    fn partial_cmp(&self, other: &PackedCopy)\n+        -> ::core::option::Option<::core::cmp::Ordering> {\n+        ::core::cmp::PartialOrd::partial_cmp(&{ self.0 }, &{ other.0 })\n     }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Ord for PackedCopy {\n     #[inline]\n-    fn ne(&self, other: &Packed) -> bool {\n-        let Self(__self_0_0) = *self;\n-        let Self(__self_1_0) = *other;\n-        __self_0_0 != __self_1_0\n+    fn cmp(&self, other: &PackedCopy) -> ::core::cmp::Ordering {\n+        ::core::cmp::Ord::cmp(&{ self.0 }, &{ other.0 })\n     }\n }\n-impl ::core::marker::StructuralEq for Packed {}\n+\n+// A packed tuple struct that does not impl `Copy`. Note that the alignment of\n+// the field must be 1 for this code to be valid. Otherwise it triggers an\n+// error \"`#[derive]` can't be used on a `#[repr(packed)]` struct that does not\n+// derive Copy (error E0133)\" at MIR building time. This is a weird case and\n+// it's possible that this struct is not supposed to work, but for now it does.\n+#[repr(packed)]\n+struct PackedNonCopy(u8);\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::cmp::Eq for Packed {\n+impl ::core::clone::Clone for PackedNonCopy {\n+    #[inline]\n+    fn clone(&self) -> PackedNonCopy {\n+        let Self(ref __self_0_0) = *self;\n+        PackedNonCopy(::core::clone::Clone::clone(__self_0_0))\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::fmt::Debug for PackedNonCopy {\n+    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n+        let Self(ref __self_0_0) = *self;\n+        ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"PackedNonCopy\",\n+            &__self_0_0)\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::default::Default for PackedNonCopy {\n+    #[inline]\n+    fn default() -> PackedNonCopy {\n+        PackedNonCopy(::core::default::Default::default())\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::hash::Hash for PackedNonCopy {\n+    fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n+        let Self(ref __self_0_0) = *self;\n+        ::core::hash::Hash::hash(__self_0_0, state)\n+    }\n+}\n+impl ::core::marker::StructuralPartialEq for PackedNonCopy {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::PartialEq for PackedNonCopy {\n+    #[inline]\n+    fn eq(&self, other: &PackedNonCopy) -> bool {\n+        let Self(ref __self_0_0) = *self;\n+        let Self(ref __self_1_0) = *other;\n+        *__self_0_0 == *__self_1_0\n+    }\n+    #[inline]\n+    fn ne(&self, other: &PackedNonCopy) -> bool {\n+        let Self(ref __self_0_0) = *self;\n+        let Self(ref __self_1_0) = *other;\n+        *__self_0_0 != *__self_1_0\n+    }\n+}\n+impl ::core::marker::StructuralEq for PackedNonCopy {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Eq for PackedNonCopy {\n     #[inline]\n     #[doc(hidden)]\n     #[no_coverage]\n     fn assert_receiver_is_total_eq(&self) -> () {\n-        let _: ::core::cmp::AssertParamIsEq<u32>;\n+        let _: ::core::cmp::AssertParamIsEq<u8>;\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::cmp::PartialOrd for Packed {\n+impl ::core::cmp::PartialOrd for PackedNonCopy {\n     #[inline]\n-    fn partial_cmp(&self, other: &Packed)\n+    fn partial_cmp(&self, other: &PackedNonCopy)\n         -> ::core::option::Option<::core::cmp::Ordering> {\n-        let Self(__self_0_0) = *self;\n-        let Self(__self_1_0) = *other;\n-        ::core::cmp::PartialOrd::partial_cmp(&__self_0_0, &__self_1_0)\n+        let Self(ref __self_0_0) = *self;\n+        let Self(ref __self_1_0) = *other;\n+        ::core::cmp::PartialOrd::partial_cmp(__self_0_0, __self_1_0)\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n-impl ::core::cmp::Ord for Packed {\n+impl ::core::cmp::Ord for PackedNonCopy {\n     #[inline]\n-    fn cmp(&self, other: &Packed) -> ::core::cmp::Ordering {\n-        let Self(__self_0_0) = *self;\n-        let Self(__self_1_0) = *other;\n-        ::core::cmp::Ord::cmp(&__self_0_0, &__self_1_0)\n+    fn cmp(&self, other: &PackedNonCopy) -> ::core::cmp::Ordering {\n+        let Self(ref __self_0_0) = *self;\n+        let Self(ref __self_1_0) = *other;\n+        ::core::cmp::Ord::cmp(__self_0_0, __self_1_0)\n     }\n }\n \n@@ -527,31 +661,30 @@ enum Enum1 {\n impl ::core::clone::Clone for Enum1 {\n     #[inline]\n     fn clone(&self) -> Enum1 {\n-        match &*self {\n-            &Enum1::Single { x: ref __self_0 } =>\n-                Enum1::Single { x: ::core::clone::Clone::clone(&*__self_0) },\n+        match self {\n+            Enum1::Single { x: __self_0 } =>\n+                Enum1::Single { x: ::core::clone::Clone::clone(__self_0) },\n         }\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::fmt::Debug for Enum1 {\n     fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n-        match &*self {\n-            &Enum1::Single { x: ref __self_0 } =>\n+        match self {\n+            Enum1::Single { x: __self_0 } =>\n                 ::core::fmt::Formatter::debug_struct_field1_finish(f,\n-                    \"Single\", \"x\", &&*__self_0),\n+                    \"Single\", \"x\", &__self_0),\n         }\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::hash::Hash for Enum1 {\n     fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n-        match &*self {\n-            &Enum1::Single { x: ref __self_0 } => {\n-                ::core::hash::Hash::hash(&*__self_0, state)\n-            }\n+        match self {\n+            Enum1::Single { x: __self_0 } =>\n+                ::core::hash::Hash::hash(__self_0, state),\n         }\n     }\n }\n@@ -561,16 +694,16 @@ impl ::core::marker::StructuralPartialEq for Enum1 {}\n impl ::core::cmp::PartialEq for Enum1 {\n     #[inline]\n     fn eq(&self, other: &Enum1) -> bool {\n-        match (&*self, &*other) {\n-            (&Enum1::Single { x: ref __self_0 }, &Enum1::Single {\n-                x: ref __arg_1_0 }) => *__self_0 == *__arg_1_0,\n+        match (self, other) {\n+            (Enum1::Single { x: __self_0 }, Enum1::Single { x: __arg1_0 }) =>\n+                *__self_0 == *__arg1_0,\n         }\n     }\n     #[inline]\n     fn ne(&self, other: &Enum1) -> bool {\n-        match (&*self, &*other) {\n-            (&Enum1::Single { x: ref __self_0 }, &Enum1::Single {\n-                x: ref __arg_1_0 }) => *__self_0 != *__arg_1_0,\n+        match (self, other) {\n+            (Enum1::Single { x: __self_0 }, Enum1::Single { x: __arg1_0 }) =>\n+                *__self_0 != *__arg1_0,\n         }\n     }\n }\n@@ -591,10 +724,9 @@ impl ::core::cmp::PartialOrd for Enum1 {\n     #[inline]\n     fn partial_cmp(&self, other: &Enum1)\n         -> ::core::option::Option<::core::cmp::Ordering> {\n-        match (&*self, &*other) {\n-            (&Enum1::Single { x: ref __self_0 }, &Enum1::Single {\n-                x: ref __arg_1_0 }) =>\n-                ::core::cmp::PartialOrd::partial_cmp(&*__self_0, &*__arg_1_0),\n+        match (self, other) {\n+            (Enum1::Single { x: __self_0 }, Enum1::Single { x: __arg1_0 }) =>\n+                ::core::cmp::PartialOrd::partial_cmp(__self_0, __arg1_0),\n         }\n     }\n }\n@@ -603,14 +735,77 @@ impl ::core::cmp::PartialOrd for Enum1 {\n impl ::core::cmp::Ord for Enum1 {\n     #[inline]\n     fn cmp(&self, other: &Enum1) -> ::core::cmp::Ordering {\n-        match (&*self, &*other) {\n-            (&Enum1::Single { x: ref __self_0 }, &Enum1::Single {\n-                x: ref __arg_1_0 }) =>\n-                ::core::cmp::Ord::cmp(&*__self_0, &*__arg_1_0),\n+        match (self, other) {\n+            (Enum1::Single { x: __self_0 }, Enum1::Single { x: __arg1_0 }) =>\n+                ::core::cmp::Ord::cmp(__self_0, __arg1_0),\n         }\n     }\n }\n \n+// A C-like, fieldless enum with a single variant.\n+enum Fieldless1 {\n+\n+    #[default]\n+    A,\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::clone::Clone for Fieldless1 {\n+    #[inline]\n+    fn clone(&self) -> Fieldless1 { Fieldless1::A }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::fmt::Debug for Fieldless1 {\n+    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n+        ::core::fmt::Formatter::write_str(f, \"A\")\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::default::Default for Fieldless1 {\n+    #[inline]\n+    fn default() -> Fieldless1 { Self::A }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::hash::Hash for Fieldless1 {\n+    fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {}\n+}\n+impl ::core::marker::StructuralPartialEq for Fieldless1 {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::PartialEq for Fieldless1 {\n+    #[inline]\n+    fn eq(&self, other: &Fieldless1) -> bool { true }\n+}\n+impl ::core::marker::StructuralEq for Fieldless1 {}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Eq for Fieldless1 {\n+    #[inline]\n+    #[doc(hidden)]\n+    #[no_coverage]\n+    fn assert_receiver_is_total_eq(&self) -> () {}\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::PartialOrd for Fieldless1 {\n+    #[inline]\n+    fn partial_cmp(&self, other: &Fieldless1)\n+        -> ::core::option::Option<::core::cmp::Ordering> {\n+        ::core::option::Option::Some(::core::cmp::Ordering::Equal)\n+    }\n+}\n+#[automatically_derived]\n+#[allow(unused_qualifications)]\n+impl ::core::cmp::Ord for Fieldless1 {\n+    #[inline]\n+    fn cmp(&self, other: &Fieldless1) -> ::core::cmp::Ordering {\n+        ::core::cmp::Ordering::Equal\n+    }\n+}\n+\n // A C-like, fieldless enum.\n enum Fieldless {\n \n@@ -632,10 +827,10 @@ impl ::core::marker::Copy for Fieldless { }\n #[allow(unused_qualifications)]\n impl ::core::fmt::Debug for Fieldless {\n     fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n-        match &*self {\n-            &Fieldless::A => ::core::fmt::Formatter::write_str(f, \"A\"),\n-            &Fieldless::B => ::core::fmt::Formatter::write_str(f, \"B\"),\n-            &Fieldless::C => ::core::fmt::Formatter::write_str(f, \"C\"),\n+        match self {\n+            Fieldless::A => ::core::fmt::Formatter::write_str(f, \"A\"),\n+            Fieldless::B => ::core::fmt::Formatter::write_str(f, \"B\"),\n+            Fieldless::C => ::core::fmt::Formatter::write_str(f, \"C\"),\n         }\n     }\n }\n@@ -649,12 +844,8 @@ impl ::core::default::Default for Fieldless {\n #[allow(unused_qualifications)]\n impl ::core::hash::Hash for Fieldless {\n     fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n-        match &*self {\n-            _ => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state)\n-            }\n-        }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        ::core::hash::Hash::hash(&__self_tag, state)\n     }\n }\n impl ::core::marker::StructuralPartialEq for Fieldless {}\n@@ -663,11 +854,9 @@ impl ::core::marker::StructuralPartialEq for Fieldless {}\n impl ::core::cmp::PartialEq for Fieldless {\n     #[inline]\n     fn eq(&self, other: &Fieldless) -> bool {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) { _ => true, }\n-            } else { false }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        __self_tag == __arg1_tag\n     }\n }\n impl ::core::marker::StructuralEq for Fieldless {}\n@@ -685,28 +874,19 @@ impl ::core::cmp::PartialOrd for Fieldless {\n     #[inline]\n     fn partial_cmp(&self, other: &Fieldless)\n         -> ::core::option::Option<::core::cmp::Ordering> {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    _ =>\n-                        ::core::option::Option::Some(::core::cmp::Ordering::Equal),\n-                }\n-            } else {\n-               ::core::cmp::PartialOrd::partial_cmp(&__self_vi, &__arg_1_vi)\n-           }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        ::core::cmp::PartialOrd::partial_cmp(&__self_tag, &__arg1_tag)\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::cmp::Ord for Fieldless {\n     #[inline]\n     fn cmp(&self, other: &Fieldless) -> ::core::cmp::Ordering {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) { _ => ::core::cmp::Ordering::Equal, }\n-            } else { ::core::cmp::Ord::cmp(&__self_vi, &__arg_1_vi) }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        ::core::cmp::Ord::cmp(&__self_tag, &__arg1_tag)\n     }\n }\n \n@@ -738,15 +918,15 @@ impl ::core::marker::Copy for Mixed { }\n #[allow(unused_qualifications)]\n impl ::core::fmt::Debug for Mixed {\n     fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n-        match &*self {\n-            &Mixed::P => ::core::fmt::Formatter::write_str(f, \"P\"),\n-            &Mixed::Q => ::core::fmt::Formatter::write_str(f, \"Q\"),\n-            &Mixed::R(ref __self_0) =>\n+        match self {\n+            Mixed::P => ::core::fmt::Formatter::write_str(f, \"P\"),\n+            Mixed::Q => ::core::fmt::Formatter::write_str(f, \"Q\"),\n+            Mixed::R(__self_0) =>\n                 ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"R\",\n-                    &&*__self_0),\n-            &Mixed::S { d1: ref __self_0, d2: ref __self_1 } =>\n+                    &__self_0),\n+            Mixed::S { d1: __self_0, d2: __self_1 } =>\n                 ::core::fmt::Formatter::debug_struct_field2_finish(f, \"S\",\n-                    \"d1\", &&*__self_0, \"d2\", &&*__self_1),\n+                    \"d1\", &__self_0, \"d2\", &__self_1),\n         }\n     }\n }\n@@ -760,22 +940,15 @@ impl ::core::default::Default for Mixed {\n #[allow(unused_qualifications)]\n impl ::core::hash::Hash for Mixed {\n     fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n-        match &*self {\n-            &Mixed::R(ref __self_0) => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state);\n-                ::core::hash::Hash::hash(&*__self_0, state)\n-            }\n-            &Mixed::S { d1: ref __self_0, d2: ref __self_1 } => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state);\n-                ::core::hash::Hash::hash(&*__self_0, state);\n-                ::core::hash::Hash::hash(&*__self_1, state)\n-            }\n-            _ => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state)\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        ::core::hash::Hash::hash(&__self_tag, state);\n+        match self {\n+            Mixed::R(__self_0) => ::core::hash::Hash::hash(__self_0, state),\n+            Mixed::S { d1: __self_0, d2: __self_1 } => {\n+                ::core::hash::Hash::hash(__self_0, state);\n+                ::core::hash::Hash::hash(__self_1, state)\n             }\n+            _ => {}\n         }\n     }\n }\n@@ -785,33 +958,31 @@ impl ::core::marker::StructuralPartialEq for Mixed {}\n impl ::core::cmp::PartialEq for Mixed {\n     #[inline]\n     fn eq(&self, other: &Mixed) -> bool {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Mixed::R(ref __self_0), &Mixed::R(ref __arg_1_0)) =>\n-                        *__self_0 == *__arg_1_0,\n-                    (&Mixed::S { d1: ref __self_0, d2: ref __self_1 },\n-                        &Mixed::S { d1: ref __arg_1_0, d2: ref __arg_1_1 }) =>\n-                        *__self_0 == *__arg_1_0 && *__self_1 == *__arg_1_1,\n-                    _ => true,\n-                }\n-            } else { false }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        __self_tag == __arg1_tag &&\n+            match (self, other) {\n+                (Mixed::R(__self_0), Mixed::R(__arg1_0)) =>\n+                    *__self_0 == *__arg1_0,\n+                (Mixed::S { d1: __self_0, d2: __self_1 }, Mixed::S {\n+                    d1: __arg1_0, d2: __arg1_1 }) =>\n+                    *__self_0 == *__arg1_0 && *__self_1 == *__arg1_1,\n+                _ => true,\n+            }\n     }\n     #[inline]\n     fn ne(&self, other: &Mixed) -> bool {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Mixed::R(ref __self_0), &Mixed::R(ref __arg_1_0)) =>\n-                        *__self_0 != *__arg_1_0,\n-                    (&Mixed::S { d1: ref __self_0, d2: ref __self_1 },\n-                        &Mixed::S { d1: ref __arg_1_0, d2: ref __arg_1_1 }) =>\n-                        *__self_0 != *__arg_1_0 || *__self_1 != *__arg_1_1,\n-                    _ => false,\n-                }\n-            } else { true }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        __self_tag != __arg1_tag ||\n+            match (self, other) {\n+                (Mixed::R(__self_0), Mixed::R(__arg1_0)) =>\n+                    *__self_0 != *__arg1_0,\n+                (Mixed::S { d1: __self_0, d2: __self_1 }, Mixed::S {\n+                    d1: __arg1_0, d2: __arg1_1 }) =>\n+                    *__self_0 != *__arg1_0 || *__self_1 != *__arg1_1,\n+                _ => false,\n+            }\n     }\n }\n impl ::core::marker::StructuralEq for Mixed {}\n@@ -831,52 +1002,51 @@ impl ::core::cmp::PartialOrd for Mixed {\n     #[inline]\n     fn partial_cmp(&self, other: &Mixed)\n         -> ::core::option::Option<::core::cmp::Ordering> {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Mixed::R(ref __self_0), &Mixed::R(ref __arg_1_0)) =>\n-                        ::core::cmp::PartialOrd::partial_cmp(&*__self_0,\n-                            &*__arg_1_0),\n-                    (&Mixed::S { d1: ref __self_0, d2: ref __self_1 },\n-                        &Mixed::S { d1: ref __arg_1_0, d2: ref __arg_1_1 }) =>\n-                        match ::core::cmp::PartialOrd::partial_cmp(&*__self_0,\n-                                &*__arg_1_0) {\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        match ::core::cmp::PartialOrd::partial_cmp(&__self_tag, &__arg1_tag) {\n+            ::core::option::Option::Some(::core::cmp::Ordering::Equal) =>\n+                match (self, other) {\n+                    (Mixed::R(__self_0), Mixed::R(__arg1_0)) =>\n+                        ::core::cmp::PartialOrd::partial_cmp(__self_0, __arg1_0),\n+                    (Mixed::S { d1: __self_0, d2: __self_1 }, Mixed::S {\n+                        d1: __arg1_0, d2: __arg1_1 }) =>\n+                        match ::core::cmp::PartialOrd::partial_cmp(__self_0,\n+                                __arg1_0) {\n                             ::core::option::Option::Some(::core::cmp::Ordering::Equal)\n-                                =>\n-                                ::core::cmp::PartialOrd::partial_cmp(&*__self_1,\n-                                    &*__arg_1_1),\n+                                => ::core::cmp::PartialOrd::partial_cmp(__self_1, __arg1_1),\n                             cmp => cmp,\n                         },\n                     _ =>\n                         ::core::option::Option::Some(::core::cmp::Ordering::Equal),\n-                }\n-            } else {\n-               ::core::cmp::PartialOrd::partial_cmp(&__self_vi, &__arg_1_vi)\n-           }\n+                },\n+            cmp => cmp,\n+        }\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::cmp::Ord for Mixed {\n     #[inline]\n     fn cmp(&self, other: &Mixed) -> ::core::cmp::Ordering {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Mixed::R(ref __self_0), &Mixed::R(ref __arg_1_0)) =>\n-                        ::core::cmp::Ord::cmp(&*__self_0, &*__arg_1_0),\n-                    (&Mixed::S { d1: ref __self_0, d2: ref __self_1 },\n-                        &Mixed::S { d1: ref __arg_1_0, d2: ref __arg_1_1 }) =>\n-                        match ::core::cmp::Ord::cmp(&*__self_0, &*__arg_1_0) {\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        match ::core::cmp::Ord::cmp(&__self_tag, &__arg1_tag) {\n+            ::core::cmp::Ordering::Equal =>\n+                match (self, other) {\n+                    (Mixed::R(__self_0), Mixed::R(__arg1_0)) =>\n+                        ::core::cmp::Ord::cmp(__self_0, __arg1_0),\n+                    (Mixed::S { d1: __self_0, d2: __self_1 }, Mixed::S {\n+                        d1: __arg1_0, d2: __arg1_1 }) =>\n+                        match ::core::cmp::Ord::cmp(__self_0, __arg1_0) {\n                             ::core::cmp::Ordering::Equal =>\n-                                ::core::cmp::Ord::cmp(&*__self_1, &*__arg_1_1),\n+                                ::core::cmp::Ord::cmp(__self_1, __arg1_1),\n                             cmp => cmp,\n                         },\n                     _ => ::core::cmp::Ordering::Equal,\n-                }\n-            } else { ::core::cmp::Ord::cmp(&__self_vi, &__arg_1_vi) }\n+                },\n+            cmp => cmp,\n+        }\n     }\n }\n \n@@ -888,53 +1058,43 @@ enum Fielded { X(u32), Y(bool), Z(Option<i32>), }\n impl ::core::clone::Clone for Fielded {\n     #[inline]\n     fn clone(&self) -> Fielded {\n-        match &*self {\n-            &Fielded::X(ref __self_0) =>\n-                Fielded::X(::core::clone::Clone::clone(&*__self_0)),\n-            &Fielded::Y(ref __self_0) =>\n-                Fielded::Y(::core::clone::Clone::clone(&*__self_0)),\n-            &Fielded::Z(ref __self_0) =>\n-                Fielded::Z(::core::clone::Clone::clone(&*__self_0)),\n+        match self {\n+            Fielded::X(__self_0) =>\n+                Fielded::X(::core::clone::Clone::clone(__self_0)),\n+            Fielded::Y(__self_0) =>\n+                Fielded::Y(::core::clone::Clone::clone(__self_0)),\n+            Fielded::Z(__self_0) =>\n+                Fielded::Z(::core::clone::Clone::clone(__self_0)),\n         }\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::fmt::Debug for Fielded {\n     fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {\n-        match &*self {\n-            &Fielded::X(ref __self_0) =>\n+        match self {\n+            Fielded::X(__self_0) =>\n                 ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"X\",\n-                    &&*__self_0),\n-            &Fielded::Y(ref __self_0) =>\n+                    &__self_0),\n+            Fielded::Y(__self_0) =>\n                 ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"Y\",\n-                    &&*__self_0),\n-            &Fielded::Z(ref __self_0) =>\n+                    &__self_0),\n+            Fielded::Z(__self_0) =>\n                 ::core::fmt::Formatter::debug_tuple_field1_finish(f, \"Z\",\n-                    &&*__self_0),\n+                    &__self_0),\n         }\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::hash::Hash for Fielded {\n     fn hash<__H: ::core::hash::Hasher>(&self, state: &mut __H) -> () {\n-        match &*self {\n-            &Fielded::X(ref __self_0) => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state);\n-                ::core::hash::Hash::hash(&*__self_0, state)\n-            }\n-            &Fielded::Y(ref __self_0) => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state);\n-                ::core::hash::Hash::hash(&*__self_0, state)\n-            }\n-            &Fielded::Z(ref __self_0) => {\n-                ::core::hash::Hash::hash(&::core::intrinsics::discriminant_value(self),\n-                    state);\n-                ::core::hash::Hash::hash(&*__self_0, state)\n-            }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        ::core::hash::Hash::hash(&__self_tag, state);\n+        match self {\n+            Fielded::X(__self_0) => ::core::hash::Hash::hash(__self_0, state),\n+            Fielded::Y(__self_0) => ::core::hash::Hash::hash(__self_0, state),\n+            Fielded::Z(__self_0) => ::core::hash::Hash::hash(__self_0, state),\n         }\n     }\n }\n@@ -944,35 +1104,33 @@ impl ::core::marker::StructuralPartialEq for Fielded {}\n impl ::core::cmp::PartialEq for Fielded {\n     #[inline]\n     fn eq(&self, other: &Fielded) -> bool {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Fielded::X(ref __self_0), &Fielded::X(ref __arg_1_0)) =>\n-                        *__self_0 == *__arg_1_0,\n-                    (&Fielded::Y(ref __self_0), &Fielded::Y(ref __arg_1_0)) =>\n-                        *__self_0 == *__arg_1_0,\n-                    (&Fielded::Z(ref __self_0), &Fielded::Z(ref __arg_1_0)) =>\n-                        *__self_0 == *__arg_1_0,\n-                    _ => unsafe { ::core::intrinsics::unreachable() }\n-                }\n-            } else { false }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        __self_tag == __arg1_tag &&\n+            match (self, other) {\n+                (Fielded::X(__self_0), Fielded::X(__arg1_0)) =>\n+                    *__self_0 == *__arg1_0,\n+                (Fielded::Y(__self_0), Fielded::Y(__arg1_0)) =>\n+                    *__self_0 == *__arg1_0,\n+                (Fielded::Z(__self_0), Fielded::Z(__arg1_0)) =>\n+                    *__self_0 == *__arg1_0,\n+                _ => unsafe { ::core::intrinsics::unreachable() }\n+            }\n     }\n     #[inline]\n     fn ne(&self, other: &Fielded) -> bool {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Fielded::X(ref __self_0), &Fielded::X(ref __arg_1_0)) =>\n-                        *__self_0 != *__arg_1_0,\n-                    (&Fielded::Y(ref __self_0), &Fielded::Y(ref __arg_1_0)) =>\n-                        *__self_0 != *__arg_1_0,\n-                    (&Fielded::Z(ref __self_0), &Fielded::Z(ref __arg_1_0)) =>\n-                        *__self_0 != *__arg_1_0,\n-                    _ => unsafe { ::core::intrinsics::unreachable() }\n-                }\n-            } else { true }\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        __self_tag != __arg1_tag ||\n+            match (self, other) {\n+                (Fielded::X(__self_0), Fielded::X(__arg1_0)) =>\n+                    *__self_0 != *__arg1_0,\n+                (Fielded::Y(__self_0), Fielded::Y(__arg1_0)) =>\n+                    *__self_0 != *__arg1_0,\n+                (Fielded::Z(__self_0), Fielded::Z(__arg1_0)) =>\n+                    *__self_0 != *__arg1_0,\n+                _ => unsafe { ::core::intrinsics::unreachable() }\n+            }\n     }\n }\n impl ::core::marker::StructuralEq for Fielded {}\n@@ -994,44 +1152,43 @@ impl ::core::cmp::PartialOrd for Fielded {\n     #[inline]\n     fn partial_cmp(&self, other: &Fielded)\n         -> ::core::option::Option<::core::cmp::Ordering> {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Fielded::X(ref __self_0), &Fielded::X(ref __arg_1_0)) =>\n-                        ::core::cmp::PartialOrd::partial_cmp(&*__self_0,\n-                            &*__arg_1_0),\n-                    (&Fielded::Y(ref __self_0), &Fielded::Y(ref __arg_1_0)) =>\n-                        ::core::cmp::PartialOrd::partial_cmp(&*__self_0,\n-                            &*__arg_1_0),\n-                    (&Fielded::Z(ref __self_0), &Fielded::Z(ref __arg_1_0)) =>\n-                        ::core::cmp::PartialOrd::partial_cmp(&*__self_0,\n-                            &*__arg_1_0),\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        match ::core::cmp::PartialOrd::partial_cmp(&__self_tag, &__arg1_tag) {\n+            ::core::option::Option::Some(::core::cmp::Ordering::Equal) =>\n+                match (self, other) {\n+                    (Fielded::X(__self_0), Fielded::X(__arg1_0)) =>\n+                        ::core::cmp::PartialOrd::partial_cmp(__self_0, __arg1_0),\n+                    (Fielded::Y(__self_0), Fielded::Y(__arg1_0)) =>\n+                        ::core::cmp::PartialOrd::partial_cmp(__self_0, __arg1_0),\n+                    (Fielded::Z(__self_0), Fielded::Z(__arg1_0)) =>\n+                        ::core::cmp::PartialOrd::partial_cmp(__self_0, __arg1_0),\n                     _ => unsafe { ::core::intrinsics::unreachable() }\n-                }\n-            } else {\n-               ::core::cmp::PartialOrd::partial_cmp(&__self_vi, &__arg_1_vi)\n-           }\n+                },\n+            cmp => cmp,\n+        }\n     }\n }\n #[automatically_derived]\n #[allow(unused_qualifications)]\n impl ::core::cmp::Ord for Fielded {\n     #[inline]\n     fn cmp(&self, other: &Fielded) -> ::core::cmp::Ordering {\n-        let __self_vi = ::core::intrinsics::discriminant_value(&*self);\n-        let __arg_1_vi = ::core::intrinsics::discriminant_value(&*other);\n-        if __self_vi == __arg_1_vi {\n-                match (&*self, &*other) {\n-                    (&Fielded::X(ref __self_0), &Fielded::X(ref __arg_1_0)) =>\n-                        ::core::cmp::Ord::cmp(&*__self_0, &*__arg_1_0),\n-                    (&Fielded::Y(ref __self_0), &Fielded::Y(ref __arg_1_0)) =>\n-                        ::core::cmp::Ord::cmp(&*__self_0, &*__arg_1_0),\n-                    (&Fielded::Z(ref __self_0), &Fielded::Z(ref __arg_1_0)) =>\n-                        ::core::cmp::Ord::cmp(&*__self_0, &*__arg_1_0),\n+        let __self_tag = ::core::intrinsics::discriminant_value(self);\n+        let __arg1_tag = ::core::intrinsics::discriminant_value(other);\n+        match ::core::cmp::Ord::cmp(&__self_tag, &__arg1_tag) {\n+            ::core::cmp::Ordering::Equal =>\n+                match (self, other) {\n+                    (Fielded::X(__self_0), Fielded::X(__arg1_0)) =>\n+                        ::core::cmp::Ord::cmp(__self_0, __arg1_0),\n+                    (Fielded::Y(__self_0), Fielded::Y(__arg1_0)) =>\n+                        ::core::cmp::Ord::cmp(__self_0, __arg1_0),\n+                    (Fielded::Z(__self_0), Fielded::Z(__arg1_0)) =>\n+                        ::core::cmp::Ord::cmp(__self_0, __arg1_0),\n                     _ => unsafe { ::core::intrinsics::unreachable() }\n-                }\n-            } else { ::core::cmp::Ord::cmp(&__self_vi, &__arg_1_vi) }\n+                },\n+            cmp => cmp,\n+        }\n     }\n }\n "}]}