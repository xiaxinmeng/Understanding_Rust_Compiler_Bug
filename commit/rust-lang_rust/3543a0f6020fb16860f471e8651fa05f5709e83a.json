{"sha": "3543a0f6020fb16860f471e8651fa05f5709e83a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM1NDNhMGY2MDIwZmIxNjg2MGY0NzFlODY1MWZhMDVmNTcwOWU4M2E=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-10-18T05:27:57Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2016-10-18T05:27:57Z"}, "message": "Auto merge of #36969 - nnethercote:rename-Parser-fields, r=eddyb\n\nClarify the positions of the lexer and parser\n\nThe lexer and parser use unclear names to indicate their positions in the\nsource code. I propose the following renamings.\n\nLexer:\n```\npos      -> next_pos      # it's actually the next pos!\nlast_pos -> pos           # it's actually the current pos!\ncurr     -> ch            # the current char\ncurr_is  -> ch_is         # tests the current char\ncol (unchanged)           # the current column\n```\nparser\n```\n- last_span       -> prev_span          # the previous token's span\n- last_token_kind -> prev_token_kind    # the previous token's kind\n- LastTokenKind   -> PrevTokenKind      # ditto (but the type)\n- token (unchanged)                     # the current token\n- span (unchanged)                      # the current span\n```\n\nThings to note:\n- This proposal removes all uses of \"last\", which is an unclear word because it\n  could mean (a) previous, (b) final, or (c) most recent, i.e. current.\n- The \"current\" things (ch, col, token, span) consistently lack a prefix. The\n  \"previous\" and \"next\" things consistently have a prefix.", "tree": {"sha": "a4ed9fd39414df30ca4c891131f55d2c755ef6d8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a4ed9fd39414df30ca4c891131f55d2c755ef6d8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3543a0f6020fb16860f471e8651fa05f5709e83a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3543a0f6020fb16860f471e8651fa05f5709e83a", "html_url": "https://github.com/rust-lang/rust/commit/3543a0f6020fb16860f471e8651fa05f5709e83a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3543a0f6020fb16860f471e8651fa05f5709e83a/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1d3dfa5301f59e86547a4034fb654c4efb47ac0e", "url": "https://api.github.com/repos/rust-lang/rust/commits/1d3dfa5301f59e86547a4034fb654c4efb47ac0e", "html_url": "https://github.com/rust-lang/rust/commit/1d3dfa5301f59e86547a4034fb654c4efb47ac0e"}, {"sha": "94b36594c628d6703f879856b9b3d4d08a6debfa", "url": "https://api.github.com/repos/rust-lang/rust/commits/94b36594c628d6703f879856b9b3d4d08a6debfa", "html_url": "https://github.com/rust-lang/rust/commit/94b36594c628d6703f879856b9b3d4d08a6debfa"}], "stats": {"total": 829, "additions": 414, "deletions": 415}, "files": [{"sha": "f97df67c4456038d4db6c6c5414d283104260cb6", "filename": "src/librustc_metadata/creader.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibrustc_metadata%2Fcreader.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibrustc_metadata%2Fcreader.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcreader.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -582,7 +582,7 @@ impl<'a> CrateReader<'a> {\n                     unreachable!();\n                 }\n             };\n-            let local_span = mk_sp(lo, p.last_span.hi);\n+            let local_span = mk_sp(lo, p.prev_span.hi);\n \n             // Mark the attrs as used\n             for attr in &def.attrs {"}, {"sha": "22c087aba80f11ea7abb6db8168f750d0c6fcb4f", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -139,9 +139,9 @@ impl<'a> SpanUtils<'a> {\n         let mut prev = toks.real_token();\n         let mut result = None;\n         let mut bracket_count = 0;\n-        let mut last_span = None;\n+        let mut prev_span = None;\n         while prev.tok != token::Eof {\n-            last_span = None;\n+            prev_span = None;\n             let mut next = toks.real_token();\n \n             if (next.tok == token::OpenDelim(token::Paren) || next.tok == token::Lt) &&\n@@ -166,12 +166,12 @@ impl<'a> SpanUtils<'a> {\n             };\n \n             if prev.tok.is_ident() && bracket_count == 0 {\n-                last_span = Some(prev.sp);\n+                prev_span = Some(prev.sp);\n             }\n             prev = next;\n         }\n-        if result.is_none() && last_span.is_some() {\n-            return self.make_sub_span(span, last_span);\n+        if result.is_none() && prev_span.is_some() {\n+            return self.make_sub_span(span, prev_span);\n         }\n         return self.make_sub_span(span, result);\n     }"}, {"sha": "49012ad036a9a9211a43d6ac0855beee96eae1e5", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -804,7 +804,7 @@ impl CodeMap {\n     }\n \n     pub fn macro_backtrace(&self, span: Span) -> Vec<MacroBacktrace> {\n-        let mut last_span = DUMMY_SP;\n+        let mut prev_span = DUMMY_SP;\n         let mut span = span;\n         let mut result = vec![];\n         loop {\n@@ -827,14 +827,14 @@ impl CodeMap {\n                 None => break,\n                 Some((call_site, macro_decl_name, def_site_span)) => {\n                     // Don't print recursive invocations\n-                    if !call_site.source_equal(&last_span) {\n+                    if !call_site.source_equal(&prev_span) {\n                         result.push(MacroBacktrace {\n                             call_site: call_site,\n                             macro_decl_name: macro_decl_name,\n                             def_site_span: def_site_span,\n                         });\n                     }\n-                    last_span = span;\n+                    prev_span = span;\n                     span = call_site;\n                 }\n             }"}, {"sha": "3cb34fa3c91c5a940e83e11f03bfcd72134abb37", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -126,7 +126,7 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::OpenDelim(token::Bracket))?;\n                 let meta_item = self.parse_meta_item()?;\n                 self.expect(&token::CloseDelim(token::Bracket))?;\n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n \n                 (mk_sp(lo, hi), meta_item, style)\n             }\n@@ -231,16 +231,16 @@ impl<'a> Parser<'a> {\n             token::Eq => {\n                 self.bump();\n                 let lit = self.parse_unsuffixed_lit()?;\n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n                 Ok(P(spanned(lo, hi, ast::MetaItemKind::NameValue(name, lit))))\n             }\n             token::OpenDelim(token::Paren) => {\n                 let inner_items = self.parse_meta_seq()?;\n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n                 Ok(P(spanned(lo, hi, ast::MetaItemKind::List(name, inner_items))))\n             }\n             _ => {\n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n                 Ok(P(spanned(lo, hi, ast::MetaItemKind::Word(name))))\n             }\n         }\n@@ -253,14 +253,14 @@ impl<'a> Parser<'a> {\n \n         match self.parse_unsuffixed_lit() {\n             Ok(lit) => {\n-                return Ok(spanned(lo, self.last_span.hi, ast::NestedMetaItemKind::Literal(lit)))\n+                return Ok(spanned(lo, self.prev_span.hi, ast::NestedMetaItemKind::Literal(lit)))\n             }\n             Err(ref mut err) => self.diagnostic().cancel(err)\n         }\n \n         match self.parse_meta_item() {\n             Ok(mi) => {\n-                return Ok(spanned(lo, self.last_span.hi, ast::NestedMetaItemKind::MetaItem(mi)))\n+                return Ok(spanned(lo, self.prev_span.hi, ast::NestedMetaItemKind::MetaItem(mi)))\n             }\n             Err(ref mut err) => self.diagnostic().cancel(err)\n         }"}, {"sha": "38f811d54dab83adcfb0cfc46296736083d601d1", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -149,13 +149,13 @@ fn push_blank_line_comment(rdr: &StringReader, comments: &mut Vec<Comment>) {\n     comments.push(Comment {\n         style: BlankLine,\n         lines: Vec::new(),\n-        pos: rdr.last_pos,\n+        pos: rdr.pos,\n     });\n }\n \n fn consume_whitespace_counting_blank_lines(rdr: &mut StringReader, comments: &mut Vec<Comment>) {\n-    while is_pattern_whitespace(rdr.curr) && !rdr.is_eof() {\n-        if rdr.col == CharPos(0) && rdr.curr_is('\\n') {\n+    while is_pattern_whitespace(rdr.ch) && !rdr.is_eof() {\n+        if rdr.col == CharPos(0) && rdr.ch_is('\\n') {\n             push_blank_line_comment(rdr, &mut *comments);\n         }\n         rdr.bump();\n@@ -167,7 +167,7 @@ fn read_shebang_comment(rdr: &mut StringReader,\n                         code_to_the_left: bool,\n                         comments: &mut Vec<Comment>) {\n     debug!(\">>> shebang comment\");\n-    let p = rdr.last_pos;\n+    let p = rdr.pos;\n     debug!(\"<<< shebang comment\");\n     comments.push(Comment {\n         style: if code_to_the_left { Trailing } else { Isolated },\n@@ -180,9 +180,9 @@ fn read_line_comments(rdr: &mut StringReader,\n                       code_to_the_left: bool,\n                       comments: &mut Vec<Comment>) {\n     debug!(\">>> line comments\");\n-    let p = rdr.last_pos;\n+    let p = rdr.pos;\n     let mut lines: Vec<String> = Vec::new();\n-    while rdr.curr_is('/') && rdr.nextch_is('/') {\n+    while rdr.ch_is('/') && rdr.nextch_is('/') {\n         let line = rdr.read_one_line_comment();\n         debug!(\"{}\", line);\n         // Doc comments are not put in comments.\n@@ -240,7 +240,7 @@ fn read_block_comment(rdr: &mut StringReader,\n                       code_to_the_left: bool,\n                       comments: &mut Vec<Comment>) {\n     debug!(\">>> block comment\");\n-    let p = rdr.last_pos;\n+    let p = rdr.pos;\n     let mut lines: Vec<String> = Vec::new();\n     let col = rdr.col;\n     rdr.bump();\n@@ -249,9 +249,9 @@ fn read_block_comment(rdr: &mut StringReader,\n     let mut curr_line = String::from(\"/*\");\n \n     // doc-comments are not really comments, they are attributes\n-    if (rdr.curr_is('*') && !rdr.nextch_is('*')) || rdr.curr_is('!') {\n-        while !(rdr.curr_is('*') && rdr.nextch_is('/')) && !rdr.is_eof() {\n-            curr_line.push(rdr.curr.unwrap());\n+    if (rdr.ch_is('*') && !rdr.nextch_is('*')) || rdr.ch_is('!') {\n+        while !(rdr.ch_is('*') && rdr.nextch_is('/')) && !rdr.is_eof() {\n+            curr_line.push(rdr.ch.unwrap());\n             rdr.bump();\n         }\n         if !rdr.is_eof() {\n@@ -271,19 +271,19 @@ fn read_block_comment(rdr: &mut StringReader,\n             if rdr.is_eof() {\n                 panic!(rdr.fatal(\"unterminated block comment\"));\n             }\n-            if rdr.curr_is('\\n') {\n+            if rdr.ch_is('\\n') {\n                 trim_whitespace_prefix_and_push_line(&mut lines, curr_line, col);\n                 curr_line = String::new();\n                 rdr.bump();\n             } else {\n-                curr_line.push(rdr.curr.unwrap());\n-                if rdr.curr_is('/') && rdr.nextch_is('*') {\n+                curr_line.push(rdr.ch.unwrap());\n+                if rdr.ch_is('/') && rdr.nextch_is('*') {\n                     rdr.bump();\n                     rdr.bump();\n                     curr_line.push('*');\n                     level += 1;\n                 } else {\n-                    if rdr.curr_is('*') && rdr.nextch_is('/') {\n+                    if rdr.ch_is('*') && rdr.nextch_is('/') {\n                         rdr.bump();\n                         rdr.bump();\n                         curr_line.push('/');\n@@ -305,7 +305,7 @@ fn read_block_comment(rdr: &mut StringReader,\n         Isolated\n     };\n     rdr.consume_non_eol_whitespace();\n-    if !rdr.is_eof() && !rdr.curr_is('\\n') && lines.len() == 1 {\n+    if !rdr.is_eof() && !rdr.ch_is('\\n') && lines.len() == 1 {\n         style = Mixed;\n     }\n     debug!(\"<<< block comment\");\n@@ -319,11 +319,11 @@ fn read_block_comment(rdr: &mut StringReader,\n \n fn consume_comment(rdr: &mut StringReader, code_to_the_left: bool, comments: &mut Vec<Comment>) {\n     debug!(\">>> consume comment\");\n-    if rdr.curr_is('/') && rdr.nextch_is('/') {\n+    if rdr.ch_is('/') && rdr.nextch_is('/') {\n         read_line_comments(rdr, code_to_the_left, comments);\n-    } else if rdr.curr_is('/') && rdr.nextch_is('*') {\n+    } else if rdr.ch_is('/') && rdr.nextch_is('*') {\n         read_block_comment(rdr, code_to_the_left, comments);\n-    } else if rdr.curr_is('#') && rdr.nextch_is('!') {\n+    } else if rdr.ch_is('#') && rdr.nextch_is('!') {\n         read_shebang_comment(rdr, code_to_the_left, comments);\n     } else {\n         panic!();\n@@ -357,7 +357,7 @@ pub fn gather_comments_and_literals(span_diagnostic: &errors::Handler,\n         loop {\n             let mut code_to_the_left = !first_read;\n             rdr.consume_non_eol_whitespace();\n-            if rdr.curr_is('\\n') {\n+            if rdr.ch_is('\\n') {\n                 code_to_the_left = false;\n                 consume_whitespace_counting_blank_lines(&mut rdr, &mut comments);\n             }\n@@ -369,7 +369,7 @@ pub fn gather_comments_and_literals(span_diagnostic: &errors::Handler,\n         }\n \n \n-        let bstart = rdr.last_pos;\n+        let bstart = rdr.pos;\n         rdr.next_token();\n         // discard, and look ahead; we're working with internal state\n         let TokenAndSpan { tok, sp } = rdr.peek();"}, {"sha": "aca41bd7b5915a83eb44a2736741ddec6a0d6dbc", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 201, "deletions": 198, "changes": 399, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -77,13 +77,13 @@ pub struct TokenAndSpan {\n pub struct StringReader<'a> {\n     pub span_diagnostic: &'a Handler,\n     /// The absolute offset within the codemap of the next character to read\n+    pub next_pos: BytePos,\n+    /// The absolute offset within the codemap of the current character\n     pub pos: BytePos,\n-    /// The absolute offset within the codemap of the last character read(curr)\n-    pub last_pos: BytePos,\n     /// The column of the next character to read\n     pub col: CharPos,\n-    /// The last character to be read\n-    pub curr: Option<char>,\n+    /// The current character (which has been read from self.pos)\n+    pub ch: Option<char>,\n     pub filemap: Rc<syntax_pos::FileMap>,\n     /// If Some, stop reading the source at this position (inclusive).\n     pub terminator: Option<BytePos>,\n@@ -102,12 +102,12 @@ pub struct StringReader<'a> {\n \n impl<'a> Reader for StringReader<'a> {\n     fn is_eof(&self) -> bool {\n-        if self.curr.is_none() {\n+        if self.ch.is_none() {\n             return true;\n         }\n \n         match self.terminator {\n-            Some(t) => self.pos > t,\n+            Some(t) => self.next_pos > t,\n             None => false,\n         }\n     }\n@@ -173,7 +173,7 @@ impl<'a> Reader for TtReader<'a> {\n }\n \n impl<'a> StringReader<'a> {\n-    /// For comments.rs, which hackily pokes into pos and curr\n+    /// For comments.rs, which hackily pokes into next_pos and ch\n     pub fn new_raw<'b>(span_diagnostic: &'b Handler,\n                        filemap: Rc<syntax_pos::FileMap>)\n                        -> StringReader<'b> {\n@@ -195,10 +195,10 @@ impl<'a> StringReader<'a> {\n \n         StringReader {\n             span_diagnostic: span_diagnostic,\n+            next_pos: filemap.start_pos,\n             pos: filemap.start_pos,\n-            last_pos: filemap.start_pos,\n             col: CharPos(0),\n-            curr: Some('\\n'),\n+            ch: Some('\\n'),\n             filemap: filemap,\n             terminator: None,\n             save_new_lines: true,\n@@ -221,8 +221,8 @@ impl<'a> StringReader<'a> {\n         sr\n     }\n \n-    pub fn curr_is(&self, c: char) -> bool {\n-        self.curr == Some(c)\n+    pub fn ch_is(&self, c: char) -> bool {\n+        self.ch == Some(c)\n     }\n \n     /// Report a fatal lexical error with a given span.\n@@ -317,9 +317,9 @@ impl<'a> StringReader<'a> {\n                     self.peek_tok = token::Eof;\n                     self.peek_span = syntax_pos::mk_sp(self.filemap.end_pos, self.filemap.end_pos);\n                 } else {\n-                    let start_bytepos = self.last_pos;\n+                    let start_bytepos = self.pos;\n                     self.peek_tok = self.next_token_inner()?;\n-                    self.peek_span = syntax_pos::mk_sp(start_bytepos, self.last_pos);\n+                    self.peek_span = syntax_pos::mk_sp(start_bytepos, self.pos);\n                 };\n             }\n         }\n@@ -331,19 +331,19 @@ impl<'a> StringReader<'a> {\n     }\n \n     /// Calls `f` with a string slice of the source text spanning from `start`\n-    /// up to but excluding `self.last_pos`, meaning the slice does not include\n-    /// the character `self.curr`.\n+    /// up to but excluding `self.pos`, meaning the slice does not include\n+    /// the character `self.ch`.\n     pub fn with_str_from<T, F>(&self, start: BytePos, f: F) -> T\n         where F: FnOnce(&str) -> T\n     {\n-        self.with_str_from_to(start, self.last_pos, f)\n+        self.with_str_from_to(start, self.pos, f)\n     }\n \n     /// Create a Name from a given offset to the current offset, each\n     /// adjusted 1 towards each other (assumes that on either side there is a\n     /// single-byte delimiter).\n     pub fn name_from(&self, start: BytePos) -> ast::Name {\n-        debug!(\"taking an ident from {:?} to {:?}\", start, self.last_pos);\n+        debug!(\"taking an ident from {:?} to {:?}\", start, self.pos);\n         self.with_str_from(start, token::intern)\n     }\n \n@@ -414,32 +414,35 @@ impl<'a> StringReader<'a> {\n     /// Advance the StringReader by one character. If a newline is\n     /// discovered, add it to the FileMap's list of line start offsets.\n     pub fn bump(&mut self) {\n-        self.last_pos = self.pos;\n-        let current_byte_offset = self.byte_offset(self.pos).to_usize();\n-        if current_byte_offset < self.source_text.len() {\n-            let last_char = self.curr.unwrap();\n-            let ch = char_at(&self.source_text, current_byte_offset);\n-            let byte_offset_diff = ch.len_utf8();\n-            self.pos = self.pos + Pos::from_usize(byte_offset_diff);\n-            self.curr = Some(ch);\n-            self.col = self.col + CharPos(1);\n-            if last_char == '\\n' {\n+        let new_pos = self.next_pos;\n+        let new_byte_offset = self.byte_offset(new_pos).to_usize();\n+        if new_byte_offset < self.source_text.len() {\n+            let old_ch_is_newline = self.ch.unwrap() == '\\n';\n+            let new_ch = char_at(&self.source_text, new_byte_offset);\n+            let new_ch_len = new_ch.len_utf8();\n+\n+            self.ch = Some(new_ch);\n+            self.pos = new_pos;\n+            self.next_pos = new_pos + Pos::from_usize(new_ch_len);\n+            if old_ch_is_newline {\n                 if self.save_new_lines {\n-                    self.filemap.next_line(self.last_pos);\n+                    self.filemap.next_line(self.pos);\n                 }\n                 self.col = CharPos(0);\n+            } else {\n+                self.col = self.col + CharPos(1);\n             }\n-\n-            if byte_offset_diff > 1 {\n-                self.filemap.record_multibyte_char(self.last_pos, byte_offset_diff);\n+            if new_ch_len > 1 {\n+                self.filemap.record_multibyte_char(self.pos, new_ch_len);\n             }\n         } else {\n-            self.curr = None;\n+            self.ch = None;\n+            self.pos = new_pos;\n         }\n     }\n \n     pub fn nextch(&self) -> Option<char> {\n-        let offset = self.byte_offset(self.pos).to_usize();\n+        let offset = self.byte_offset(self.next_pos).to_usize();\n         if offset < self.source_text.len() {\n             Some(char_at(&self.source_text, offset))\n         } else {\n@@ -452,7 +455,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     pub fn nextnextch(&self) -> Option<char> {\n-        let offset = self.byte_offset(self.pos).to_usize();\n+        let offset = self.byte_offset(self.next_pos).to_usize();\n         let s = &self.source_text[..];\n         if offset >= s.len() {\n             return None;\n@@ -471,11 +474,11 @@ impl<'a> StringReader<'a> {\n \n     /// Eats <XID_start><XID_continue>*, if possible.\n     fn scan_optional_raw_name(&mut self) -> Option<ast::Name> {\n-        if !ident_start(self.curr) {\n+        if !ident_start(self.ch) {\n             return None;\n         }\n-        let start = self.last_pos;\n-        while ident_continue(self.curr) {\n+        let start = self.pos;\n+        while ident_continue(self.ch) {\n             self.bump();\n         }\n \n@@ -488,37 +491,37 @@ impl<'a> StringReader<'a> {\n         })\n     }\n \n-    /// PRECONDITION: self.curr is not whitespace\n+    /// PRECONDITION: self.ch is not whitespace\n     /// Eats any kind of comment.\n     fn scan_comment(&mut self) -> Option<TokenAndSpan> {\n-        if let Some(c) = self.curr {\n+        if let Some(c) = self.ch {\n             if c.is_whitespace() {\n-                self.span_diagnostic.span_err(syntax_pos::mk_sp(self.last_pos, self.last_pos),\n+                self.span_diagnostic.span_err(syntax_pos::mk_sp(self.pos, self.pos),\n                                               \"called consume_any_line_comment, but there \\\n                                                was whitespace\");\n             }\n         }\n \n-        if self.curr_is('/') {\n+        if self.ch_is('/') {\n             match self.nextch() {\n                 Some('/') => {\n                     self.bump();\n                     self.bump();\n \n                     // line comments starting with \"///\" or \"//!\" are doc-comments\n-                    let doc_comment = self.curr_is('/') || self.curr_is('!');\n-                    let start_bpos = self.last_pos - BytePos(2);\n+                    let doc_comment = self.ch_is('/') || self.ch_is('!');\n+                    let start_bpos = self.pos - BytePos(2);\n \n                     while !self.is_eof() {\n-                        match self.curr.unwrap() {\n+                        match self.ch.unwrap() {\n                             '\\n' => break,\n                             '\\r' => {\n                                 if self.nextch_is('\\n') {\n                                     // CRLF\n                                     break;\n                                 } else if doc_comment {\n-                                    self.err_span_(self.last_pos,\n-                                                   self.pos,\n+                                    self.err_span_(self.pos,\n+                                                   self.next_pos,\n                                                    \"bare CR not allowed in doc-comment\");\n                                 }\n                             }\n@@ -538,13 +541,13 @@ impl<'a> StringReader<'a> {\n \n                             Some(TokenAndSpan {\n                                 tok: tok,\n-                                sp: syntax_pos::mk_sp(start_bpos, self.last_pos),\n+                                sp: syntax_pos::mk_sp(start_bpos, self.pos),\n                             })\n                         })\n                     } else {\n                         Some(TokenAndSpan {\n                             tok: token::Comment,\n-                            sp: syntax_pos::mk_sp(start_bpos, self.last_pos),\n+                            sp: syntax_pos::mk_sp(start_bpos, self.pos),\n                         })\n                     };\n                 }\n@@ -555,7 +558,7 @@ impl<'a> StringReader<'a> {\n                 }\n                 _ => None,\n             }\n-        } else if self.curr_is('#') {\n+        } else if self.ch_is('#') {\n             if self.nextch_is('!') {\n \n                 // Parse an inner attribute.\n@@ -567,17 +570,17 @@ impl<'a> StringReader<'a> {\n                 // we're at the beginning of the file...\n                 let cmap = CodeMap::new();\n                 cmap.files.borrow_mut().push(self.filemap.clone());\n-                let loc = cmap.lookup_char_pos_adj(self.last_pos);\n+                let loc = cmap.lookup_char_pos_adj(self.pos);\n                 debug!(\"Skipping a shebang\");\n                 if loc.line == 1 && loc.col == CharPos(0) {\n                     // FIXME: Add shebang \"token\", return it\n-                    let start = self.last_pos;\n-                    while !self.curr_is('\\n') && !self.is_eof() {\n+                    let start = self.pos;\n+                    while !self.ch_is('\\n') && !self.is_eof() {\n                         self.bump();\n                     }\n                     return Some(TokenAndSpan {\n                         tok: token::Shebang(self.name_from(start)),\n-                        sp: syntax_pos::mk_sp(start, self.last_pos),\n+                        sp: syntax_pos::mk_sp(start, self.pos),\n                     });\n                 }\n             }\n@@ -590,7 +593,7 @@ impl<'a> StringReader<'a> {\n     /// If there is whitespace, shebang, or a comment, scan it. Otherwise,\n     /// return None.\n     fn scan_whitespace_or_comment(&mut self) -> Option<TokenAndSpan> {\n-        match self.curr.unwrap_or('\\0') {\n+        match self.ch.unwrap_or('\\0') {\n             // # to handle shebang at start of file -- this is the entry point\n             // for skipping over all \"junk\"\n             '/' | '#' => {\n@@ -599,13 +602,13 @@ impl<'a> StringReader<'a> {\n                 c\n             },\n             c if is_pattern_whitespace(Some(c)) => {\n-                let start_bpos = self.last_pos;\n-                while is_pattern_whitespace(self.curr) {\n+                let start_bpos = self.pos;\n+                while is_pattern_whitespace(self.ch) {\n                     self.bump();\n                 }\n                 let c = Some(TokenAndSpan {\n                     tok: token::Whitespace,\n-                    sp: syntax_pos::mk_sp(start_bpos, self.last_pos),\n+                    sp: syntax_pos::mk_sp(start_bpos, self.pos),\n                 });\n                 debug!(\"scanning whitespace: {:?}\", c);\n                 c\n@@ -617,8 +620,8 @@ impl<'a> StringReader<'a> {\n     /// Might return a sugared-doc-attr\n     fn scan_block_comment(&mut self) -> Option<TokenAndSpan> {\n         // block comments starting with \"/**\" or \"/*!\" are doc-comments\n-        let is_doc_comment = self.curr_is('*') || self.curr_is('!');\n-        let start_bpos = self.last_pos - BytePos(2);\n+        let is_doc_comment = self.ch_is('*') || self.ch_is('!');\n+        let start_bpos = self.pos - BytePos(2);\n \n         let mut level: isize = 1;\n         let mut has_cr = false;\n@@ -629,10 +632,10 @@ impl<'a> StringReader<'a> {\n                 } else {\n                     \"unterminated block comment\"\n                 };\n-                let last_bpos = self.last_pos;\n+                let last_bpos = self.pos;\n                 panic!(self.fatal_span_(start_bpos, last_bpos, msg));\n             }\n-            let n = self.curr.unwrap();\n+            let n = self.ch.unwrap();\n             match n {\n                 '/' if self.nextch_is('*') => {\n                     level += 1;\n@@ -667,7 +670,7 @@ impl<'a> StringReader<'a> {\n \n             Some(TokenAndSpan {\n                 tok: tok,\n-                sp: syntax_pos::mk_sp(start_bpos, self.last_pos),\n+                sp: syntax_pos::mk_sp(start_bpos, self.pos),\n             })\n         })\n     }\n@@ -682,7 +685,7 @@ impl<'a> StringReader<'a> {\n         assert!(real_radix <= scan_radix);\n         let mut len = 0;\n         loop {\n-            let c = self.curr;\n+            let c = self.ch;\n             if c == Some('_') {\n                 debug!(\"skipping a _\");\n                 self.bump();\n@@ -694,8 +697,8 @@ impl<'a> StringReader<'a> {\n                     // check that the hypothetical digit is actually\n                     // in range for the true radix\n                     if c.unwrap().to_digit(real_radix).is_none() {\n-                        self.err_span_(self.last_pos,\n-                                       self.pos,\n+                        self.err_span_(self.pos,\n+                                       self.next_pos,\n                                        &format!(\"invalid digit for a base {} literal\", real_radix));\n                     }\n                     len += 1;\n@@ -710,12 +713,12 @@ impl<'a> StringReader<'a> {\n     fn scan_number(&mut self, c: char) -> token::Lit {\n         let num_digits;\n         let mut base = 10;\n-        let start_bpos = self.last_pos;\n+        let start_bpos = self.pos;\n \n         self.bump();\n \n         if c == '0' {\n-            match self.curr.unwrap_or('\\0') {\n+            match self.ch.unwrap_or('\\0') {\n                 'b' => {\n                     self.bump();\n                     base = 2;\n@@ -747,34 +750,34 @@ impl<'a> StringReader<'a> {\n \n         if num_digits == 0 {\n             self.err_span_(start_bpos,\n-                           self.last_pos,\n+                           self.pos,\n                            \"no valid digits found for number\");\n             return token::Integer(token::intern(\"0\"));\n         }\n \n         // might be a float, but don't be greedy if this is actually an\n         // integer literal followed by field/method access or a range pattern\n         // (`0..2` and `12.foo()`)\n-        if self.curr_is('.') && !self.nextch_is('.') &&\n+        if self.ch_is('.') && !self.nextch_is('.') &&\n            !self.nextch()\n                 .unwrap_or('\\0')\n                 .is_xid_start() {\n             // might have stuff after the ., and if it does, it needs to start\n             // with a number\n             self.bump();\n-            if self.curr.unwrap_or('\\0').is_digit(10) {\n+            if self.ch.unwrap_or('\\0').is_digit(10) {\n                 self.scan_digits(10, 10);\n                 self.scan_float_exponent();\n             }\n-            let last_pos = self.last_pos;\n-            self.check_float_base(start_bpos, last_pos, base);\n+            let pos = self.pos;\n+            self.check_float_base(start_bpos, pos, base);\n             return token::Float(self.name_from(start_bpos));\n         } else {\n             // it might be a float if it has an exponent\n-            if self.curr_is('e') || self.curr_is('E') {\n+            if self.ch_is('e') || self.ch_is('E') {\n                 self.scan_float_exponent();\n-                let last_pos = self.last_pos;\n-                self.check_float_base(start_bpos, last_pos, base);\n+                let pos = self.pos;\n+                self.check_float_base(start_bpos, pos, base);\n                 return token::Float(self.name_from(start_bpos));\n             }\n             // but we certainly have an integer!\n@@ -786,30 +789,30 @@ impl<'a> StringReader<'a> {\n     /// error if too many or too few digits are encountered.\n     fn scan_hex_digits(&mut self, n_digits: usize, delim: char, below_0x7f_only: bool) -> bool {\n         debug!(\"scanning {} digits until {:?}\", n_digits, delim);\n-        let start_bpos = self.last_pos;\n+        let start_bpos = self.pos;\n         let mut accum_int = 0;\n \n         let mut valid = true;\n         for _ in 0..n_digits {\n             if self.is_eof() {\n-                let last_bpos = self.last_pos;\n+                let last_bpos = self.pos;\n                 panic!(self.fatal_span_(start_bpos,\n                                         last_bpos,\n                                         \"unterminated numeric character escape\"));\n             }\n-            if self.curr_is(delim) {\n-                let last_bpos = self.last_pos;\n+            if self.ch_is(delim) {\n+                let last_bpos = self.pos;\n                 self.err_span_(start_bpos,\n                                last_bpos,\n                                \"numeric character escape is too short\");\n                 valid = false;\n                 break;\n             }\n-            let c = self.curr.unwrap_or('\\x00');\n+            let c = self.ch.unwrap_or('\\x00');\n             accum_int *= 16;\n             accum_int += c.to_digit(16).unwrap_or_else(|| {\n-                self.err_span_char(self.last_pos,\n-                                   self.pos,\n+                self.err_span_char(self.pos,\n+                                   self.next_pos,\n                                    \"invalid character in numeric character escape\",\n                                    c);\n \n@@ -821,7 +824,7 @@ impl<'a> StringReader<'a> {\n \n         if below_0x7f_only && accum_int >= 0x80 {\n             self.err_span_(start_bpos,\n-                           self.last_pos,\n+                           self.pos,\n                            \"this form of character escape may only be used with characters in \\\n                             the range [\\\\x00-\\\\x7f]\");\n             valid = false;\n@@ -830,7 +833,7 @@ impl<'a> StringReader<'a> {\n         match char::from_u32(accum_int) {\n             Some(_) => valid,\n             None => {\n-                let last_bpos = self.last_pos;\n+                let last_bpos = self.pos;\n                 self.err_span_(start_bpos, last_bpos, \"invalid numeric character escape\");\n                 false\n             }\n@@ -851,8 +854,8 @@ impl<'a> StringReader<'a> {\n         match first_source_char {\n             '\\\\' => {\n                 // '\\X' for some X must be a character constant:\n-                let escaped = self.curr;\n-                let escaped_pos = self.last_pos;\n+                let escaped = self.ch;\n+                let escaped_pos = self.pos;\n                 self.bump();\n                 match escaped {\n                     None => {}  // EOF here is an error that will be checked later.\n@@ -861,10 +864,10 @@ impl<'a> StringReader<'a> {\n                             'n' | 'r' | 't' | '\\\\' | '\\'' | '\"' | '0' => true,\n                             'x' => self.scan_byte_escape(delim, !ascii_only),\n                             'u' => {\n-                                let valid = if self.curr_is('{') {\n+                                let valid = if self.ch_is('{') {\n                                     self.scan_unicode_escape(delim) && !ascii_only\n                                 } else {\n-                                    let span = syntax_pos::mk_sp(start, self.last_pos);\n+                                    let span = syntax_pos::mk_sp(start, self.pos);\n                                     self.span_diagnostic\n                                         .struct_span_err(span, \"incorrect unicode escape sequence\")\n                                         .span_help(span,\n@@ -875,7 +878,7 @@ impl<'a> StringReader<'a> {\n                                 };\n                                 if ascii_only {\n                                     self.err_span_(start,\n-                                                   self.last_pos,\n+                                                   self.pos,\n                                                    \"unicode escape sequences cannot be used as a \\\n                                                     byte or in a byte string\");\n                                 }\n@@ -886,14 +889,14 @@ impl<'a> StringReader<'a> {\n                                 self.consume_whitespace();\n                                 true\n                             }\n-                            '\\r' if delim == '\"' && self.curr_is('\\n') => {\n+                            '\\r' if delim == '\"' && self.ch_is('\\n') => {\n                                 self.consume_whitespace();\n                                 true\n                             }\n                             c => {\n-                                let last_pos = self.last_pos;\n+                                let pos = self.pos;\n                                 let mut err = self.struct_err_span_char(escaped_pos,\n-                                                                        last_pos,\n+                                                                        pos,\n                                                                         if ascii_only {\n                                                                             \"unknown byte escape\"\n                                                                         } else {\n@@ -902,13 +905,13 @@ impl<'a> StringReader<'a> {\n                                                                         },\n                                                                         c);\n                                 if e == '\\r' {\n-                                    err.span_help(syntax_pos::mk_sp(escaped_pos, last_pos),\n+                                    err.span_help(syntax_pos::mk_sp(escaped_pos, pos),\n                                                   \"this is an isolated carriage return; consider \\\n                                                    checking your editor and version control \\\n                                                    settings\");\n                                 }\n                                 if (e == '{' || e == '}') && !ascii_only {\n-                                    err.span_help(syntax_pos::mk_sp(escaped_pos, last_pos),\n+                                    err.span_help(syntax_pos::mk_sp(escaped_pos, pos),\n                                                   \"if used in a formatting string, curly braces \\\n                                                    are escaped with `{{` and `}}`\");\n                                 }\n@@ -920,9 +923,9 @@ impl<'a> StringReader<'a> {\n                 }\n             }\n             '\\t' | '\\n' | '\\r' | '\\'' if delim == '\\'' => {\n-                let last_pos = self.last_pos;\n+                let pos = self.pos;\n                 self.err_span_char(start,\n-                                   last_pos,\n+                                   pos,\n                                    if ascii_only {\n                                        \"byte constant must be escaped\"\n                                    } else {\n@@ -932,21 +935,21 @@ impl<'a> StringReader<'a> {\n                 return false;\n             }\n             '\\r' => {\n-                if self.curr_is('\\n') {\n+                if self.ch_is('\\n') {\n                     self.bump();\n                     return true;\n                 } else {\n                     self.err_span_(start,\n-                                   self.last_pos,\n+                                   self.pos,\n                                    \"bare CR not allowed in string, use \\\\r instead\");\n                     return false;\n                 }\n             }\n             _ => {\n                 if ascii_only && first_source_char > '\\x7F' {\n-                    let last_pos = self.last_pos;\n+                    let pos = self.pos;\n                     self.err_span_(start,\n-                                   last_pos,\n+                                   pos,\n                                    \"byte constant must be ASCII. Use a \\\\xHH escape for a \\\n                                     non-ASCII byte\");\n                     return false;\n@@ -962,29 +965,29 @@ impl<'a> StringReader<'a> {\n     /// will read at least one digit, and up to 6, and pass over the }.\n     fn scan_unicode_escape(&mut self, delim: char) -> bool {\n         self.bump(); // past the {\n-        let start_bpos = self.last_pos;\n+        let start_bpos = self.pos;\n         let mut count = 0;\n         let mut accum_int = 0;\n         let mut valid = true;\n \n-        while !self.curr_is('}') && count <= 6 {\n-            let c = match self.curr {\n+        while !self.ch_is('}') && count <= 6 {\n+            let c = match self.ch {\n                 Some(c) => c,\n                 None => {\n                     panic!(self.fatal_span_(start_bpos,\n-                                            self.last_pos,\n+                                            self.pos,\n                                             \"unterminated unicode escape (found EOF)\"));\n                 }\n             };\n             accum_int *= 16;\n             accum_int += c.to_digit(16).unwrap_or_else(|| {\n                 if c == delim {\n-                    panic!(self.fatal_span_(self.last_pos,\n-                                            self.pos,\n+                    panic!(self.fatal_span_(self.pos,\n+                                            self.next_pos,\n                                             \"unterminated unicode escape (needed a `}`)\"));\n                 } else {\n-                    self.err_span_char(self.last_pos,\n-                                       self.pos,\n+                    self.err_span_char(self.pos,\n+                                       self.next_pos,\n                                        \"invalid character in unicode escape\",\n                                        c);\n                 }\n@@ -997,14 +1000,14 @@ impl<'a> StringReader<'a> {\n \n         if count > 6 {\n             self.err_span_(start_bpos,\n-                           self.last_pos,\n+                           self.pos,\n                            \"overlong unicode escape (can have at most 6 hex digits)\");\n             valid = false;\n         }\n \n         if valid && (char::from_u32(accum_int).is_none() || count == 0) {\n             self.err_span_(start_bpos,\n-                           self.last_pos,\n+                           self.pos,\n                            \"invalid unicode character escape\");\n             valid = false;\n         }\n@@ -1015,14 +1018,14 @@ impl<'a> StringReader<'a> {\n \n     /// Scan over a float exponent.\n     fn scan_float_exponent(&mut self) {\n-        if self.curr_is('e') || self.curr_is('E') {\n+        if self.ch_is('e') || self.ch_is('E') {\n             self.bump();\n-            if self.curr_is('-') || self.curr_is('+') {\n+            if self.ch_is('-') || self.ch_is('+') {\n                 self.bump();\n             }\n             if self.scan_digits(10, 10) == 0 {\n-                self.err_span_(self.last_pos,\n-                               self.pos,\n+                self.err_span_(self.pos,\n+                               self.next_pos,\n                                \"expected at least one digit in exponent\")\n             }\n         }\n@@ -1053,7 +1056,7 @@ impl<'a> StringReader<'a> {\n \n     fn binop(&mut self, op: token::BinOpToken) -> token::Token {\n         self.bump();\n-        if self.curr_is('=') {\n+        if self.ch_is('=') {\n             self.bump();\n             return token::BinOpEq(op);\n         } else {\n@@ -1064,7 +1067,7 @@ impl<'a> StringReader<'a> {\n     /// Return the next token from the string, advances the input past that\n     /// token, and updates the interner\n     fn next_token_inner(&mut self) -> Result<token::Token, ()> {\n-        let c = self.curr;\n+        let c = self.ch;\n         if ident_start(c) &&\n            match (c.unwrap(), self.nextch(), self.nextnextch()) {\n             // Note: r as in r\" or r#\" is part of a raw string literal,\n@@ -1078,8 +1081,8 @@ impl<'a> StringReader<'a> {\n             ('b', Some('r'), Some('#')) => false,\n             _ => true,\n         } {\n-            let start = self.last_pos;\n-            while ident_continue(self.curr) {\n+            let start = self.pos;\n+            while ident_continue(self.ch) {\n                 self.bump();\n             }\n \n@@ -1112,9 +1115,9 @@ impl<'a> StringReader<'a> {\n             }\n             '.' => {\n                 self.bump();\n-                return if self.curr_is('.') {\n+                return if self.ch_is('.') {\n                     self.bump();\n-                    if self.curr_is('.') {\n+                    if self.ch_is('.') {\n                         self.bump();\n                         Ok(token::DotDotDot)\n                     } else {\n@@ -1166,7 +1169,7 @@ impl<'a> StringReader<'a> {\n             }\n             ':' => {\n                 self.bump();\n-                if self.curr_is(':') {\n+                if self.ch_is(':') {\n                     self.bump();\n                     return Ok(token::ModSep);\n                 } else {\n@@ -1182,10 +1185,10 @@ impl<'a> StringReader<'a> {\n             // Multi-byte tokens.\n             '=' => {\n                 self.bump();\n-                if self.curr_is('=') {\n+                if self.ch_is('=') {\n                     self.bump();\n                     return Ok(token::EqEq);\n-                } else if self.curr_is('>') {\n+                } else if self.ch_is('>') {\n                     self.bump();\n                     return Ok(token::FatArrow);\n                 } else {\n@@ -1194,7 +1197,7 @@ impl<'a> StringReader<'a> {\n             }\n             '!' => {\n                 self.bump();\n-                if self.curr_is('=') {\n+                if self.ch_is('=') {\n                     self.bump();\n                     return Ok(token::Ne);\n                 } else {\n@@ -1203,7 +1206,7 @@ impl<'a> StringReader<'a> {\n             }\n             '<' => {\n                 self.bump();\n-                match self.curr.unwrap_or('\\x00') {\n+                match self.ch.unwrap_or('\\x00') {\n                     '=' => {\n                         self.bump();\n                         return Ok(token::Le);\n@@ -1213,7 +1216,7 @@ impl<'a> StringReader<'a> {\n                     }\n                     '-' => {\n                         self.bump();\n-                        match self.curr.unwrap_or('\\x00') {\n+                        match self.ch.unwrap_or('\\x00') {\n                             _ => {\n                                 return Ok(token::LArrow);\n                             }\n@@ -1226,7 +1229,7 @@ impl<'a> StringReader<'a> {\n             }\n             '>' => {\n                 self.bump();\n-                match self.curr.unwrap_or('\\x00') {\n+                match self.ch.unwrap_or('\\x00') {\n                     '=' => {\n                         self.bump();\n                         return Ok(token::Ge);\n@@ -1241,25 +1244,25 @@ impl<'a> StringReader<'a> {\n             }\n             '\\'' => {\n                 // Either a character constant 'a' OR a lifetime name 'abc\n-                let start_with_quote = self.last_pos;\n+                let start_with_quote = self.pos;\n                 self.bump();\n-                let start = self.last_pos;\n+                let start = self.pos;\n \n                 // the eof will be picked up by the final `'` check below\n-                let c2 = self.curr.unwrap_or('\\x00');\n+                let c2 = self.ch.unwrap_or('\\x00');\n                 self.bump();\n \n                 // If the character is an ident start not followed by another single\n                 // quote, then this is a lifetime name:\n-                if ident_start(Some(c2)) && !self.curr_is('\\'') {\n-                    while ident_continue(self.curr) {\n+                if ident_start(Some(c2)) && !self.ch_is('\\'') {\n+                    while ident_continue(self.ch) {\n                         self.bump();\n                     }\n                     // lifetimes shouldn't end with a single quote\n                     // if we find one, then this is an invalid character literal\n-                    if self.curr_is('\\'') {\n+                    if self.ch_is('\\'') {\n                         panic!(self.fatal_span_verbose(\n-                               start_with_quote, self.pos,\n+                               start_with_quote, self.next_pos,\n                                String::from(\"character literal may only contain one codepoint\")));\n \n                     }\n@@ -1277,7 +1280,7 @@ impl<'a> StringReader<'a> {\n                         str_to_ident(lifetime_name)\n                     });\n                     let keyword_checking_token = &token::Ident(keyword_checking_ident);\n-                    let last_bpos = self.last_pos;\n+                    let last_bpos = self.pos;\n                     if keyword_checking_token.is_any_keyword() &&\n                        !keyword_checking_token.is_keyword(keywords::Static) {\n                         self.err_span_(start, last_bpos, \"lifetimes cannot use keyword names\");\n@@ -1292,9 +1295,9 @@ impl<'a> StringReader<'a> {\n                                                    false,\n                                                    '\\'');\n \n-                if !self.curr_is('\\'') {\n+                if !self.ch_is('\\'') {\n                     panic!(self.fatal_span_verbose(\n-                           start_with_quote, self.last_pos,\n+                           start_with_quote, self.pos,\n                            String::from(\"character literal may only contain one codepoint\")));\n                 }\n \n@@ -1303,13 +1306,13 @@ impl<'a> StringReader<'a> {\n                 } else {\n                     token::intern(\"0\")\n                 };\n-                self.bump(); // advance curr past token\n+                self.bump(); // advance ch past token\n                 let suffix = self.scan_optional_raw_name();\n                 return Ok(token::Literal(token::Char(id), suffix));\n             }\n             'b' => {\n                 self.bump();\n-                let lit = match self.curr {\n+                let lit = match self.ch {\n                     Some('\\'') => self.scan_byte(),\n                     Some('\"') => self.scan_byte_string(),\n                     Some('r') => self.scan_raw_byte_string(),\n@@ -1319,19 +1322,19 @@ impl<'a> StringReader<'a> {\n                 return Ok(token::Literal(lit, suffix));\n             }\n             '\"' => {\n-                let start_bpos = self.last_pos;\n+                let start_bpos = self.pos;\n                 let mut valid = true;\n                 self.bump();\n-                while !self.curr_is('\"') {\n+                while !self.ch_is('\"') {\n                     if self.is_eof() {\n-                        let last_bpos = self.last_pos;\n+                        let last_bpos = self.pos;\n                         panic!(self.fatal_span_(start_bpos,\n                                                 last_bpos,\n                                                 \"unterminated double quote string\"));\n                     }\n \n-                    let ch_start = self.last_pos;\n-                    let ch = self.curr.unwrap();\n+                    let ch_start = self.pos;\n+                    let ch = self.ch.unwrap();\n                     self.bump();\n                     valid &= self.scan_char_or_byte(ch_start,\n                                                     ch,\n@@ -1350,56 +1353,56 @@ impl<'a> StringReader<'a> {\n                 return Ok(token::Literal(token::Str_(id), suffix));\n             }\n             'r' => {\n-                let start_bpos = self.last_pos;\n+                let start_bpos = self.pos;\n                 self.bump();\n                 let mut hash_count = 0;\n-                while self.curr_is('#') {\n+                while self.ch_is('#') {\n                     self.bump();\n                     hash_count += 1;\n                 }\n \n                 if self.is_eof() {\n-                    let last_bpos = self.last_pos;\n+                    let last_bpos = self.pos;\n                     panic!(self.fatal_span_(start_bpos, last_bpos, \"unterminated raw string\"));\n-                } else if !self.curr_is('\"') {\n-                    let last_bpos = self.last_pos;\n-                    let curr_char = self.curr.unwrap();\n+                } else if !self.ch_is('\"') {\n+                    let last_bpos = self.pos;\n+                    let curr_char = self.ch.unwrap();\n                     panic!(self.fatal_span_char(start_bpos,\n                                                 last_bpos,\n                                                 \"found invalid character; only `#` is allowed \\\n                                                  in raw string delimitation\",\n                                                 curr_char));\n                 }\n                 self.bump();\n-                let content_start_bpos = self.last_pos;\n+                let content_start_bpos = self.pos;\n                 let mut content_end_bpos;\n                 let mut valid = true;\n                 'outer: loop {\n                     if self.is_eof() {\n-                        let last_bpos = self.last_pos;\n+                        let last_bpos = self.pos;\n                         panic!(self.fatal_span_(start_bpos, last_bpos, \"unterminated raw string\"));\n                     }\n-                    // if self.curr_is('\"') {\n-                    // content_end_bpos = self.last_pos;\n+                    // if self.ch_is('\"') {\n+                    // content_end_bpos = self.pos;\n                     // for _ in 0..hash_count {\n                     // self.bump();\n-                    // if !self.curr_is('#') {\n+                    // if !self.ch_is('#') {\n                     // continue 'outer;\n-                    let c = self.curr.unwrap();\n+                    let c = self.ch.unwrap();\n                     match c {\n                         '\"' => {\n-                            content_end_bpos = self.last_pos;\n+                            content_end_bpos = self.pos;\n                             for _ in 0..hash_count {\n                                 self.bump();\n-                                if !self.curr_is('#') {\n+                                if !self.ch_is('#') {\n                                     continue 'outer;\n                                 }\n                             }\n                             break;\n                         }\n                         '\\r' => {\n                             if !self.nextch_is('\\n') {\n-                                let last_bpos = self.last_pos;\n+                                let last_bpos = self.pos;\n                                 self.err_span_(start_bpos,\n                                                last_bpos,\n                                                \"bare CR not allowed in raw string, use \\\\r \\\n@@ -1466,8 +1469,8 @@ impl<'a> StringReader<'a> {\n                 return Ok(self.binop(token::Percent));\n             }\n             c => {\n-                let last_bpos = self.last_pos;\n-                let bpos = self.pos;\n+                let last_bpos = self.pos;\n+                let bpos = self.next_pos;\n                 let mut err = self.struct_fatal_span_char(last_bpos,\n                                                           bpos,\n                                                           \"unknown start of token\",\n@@ -1480,18 +1483,18 @@ impl<'a> StringReader<'a> {\n     }\n \n     fn consume_whitespace(&mut self) {\n-        while is_pattern_whitespace(self.curr) && !self.is_eof() {\n+        while is_pattern_whitespace(self.ch) && !self.is_eof() {\n             self.bump();\n         }\n     }\n \n     fn read_to_eol(&mut self) -> String {\n         let mut val = String::new();\n-        while !self.curr_is('\\n') && !self.is_eof() {\n-            val.push(self.curr.unwrap());\n+        while !self.ch_is('\\n') && !self.is_eof() {\n+            val.push(self.ch.unwrap());\n             self.bump();\n         }\n-        if self.curr_is('\\n') {\n+        if self.ch_is('\\n') {\n             self.bump();\n         }\n         return val;\n@@ -1505,37 +1508,37 @@ impl<'a> StringReader<'a> {\n     }\n \n     fn consume_non_eol_whitespace(&mut self) {\n-        while is_pattern_whitespace(self.curr) && !self.curr_is('\\n') && !self.is_eof() {\n+        while is_pattern_whitespace(self.ch) && !self.ch_is('\\n') && !self.is_eof() {\n             self.bump();\n         }\n     }\n \n     fn peeking_at_comment(&self) -> bool {\n-        (self.curr_is('/') && self.nextch_is('/')) || (self.curr_is('/') && self.nextch_is('*')) ||\n+        (self.ch_is('/') && self.nextch_is('/')) || (self.ch_is('/') && self.nextch_is('*')) ||\n         // consider shebangs comments, but not inner attributes\n-        (self.curr_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n+        (self.ch_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n     }\n \n     fn scan_byte(&mut self) -> token::Lit {\n         self.bump();\n-        let start = self.last_pos;\n+        let start = self.pos;\n \n         // the eof will be picked up by the final `'` check below\n-        let c2 = self.curr.unwrap_or('\\x00');\n+        let c2 = self.ch.unwrap_or('\\x00');\n         self.bump();\n \n         let valid = self.scan_char_or_byte(start,\n                                            c2,\n                                            // ascii_only =\n                                            true,\n                                            '\\'');\n-        if !self.curr_is('\\'') {\n+        if !self.ch_is('\\'') {\n             // Byte offsetting here is okay because the\n             // character before position `start` are an\n             // ascii single quote and ascii 'b'.\n-            let last_pos = self.last_pos;\n+            let pos = self.pos;\n             panic!(self.fatal_span_verbose(start - BytePos(2),\n-                                           last_pos,\n+                                           pos,\n                                            \"unterminated byte constant\".to_string()));\n         }\n \n@@ -1544,7 +1547,7 @@ impl<'a> StringReader<'a> {\n         } else {\n             token::intern(\"?\")\n         };\n-        self.bump(); // advance curr past token\n+        self.bump(); // advance ch past token\n         return token::Byte(id);\n     }\n \n@@ -1554,17 +1557,17 @@ impl<'a> StringReader<'a> {\n \n     fn scan_byte_string(&mut self) -> token::Lit {\n         self.bump();\n-        let start = self.last_pos;\n+        let start = self.pos;\n         let mut valid = true;\n \n-        while !self.curr_is('\"') {\n+        while !self.ch_is('\"') {\n             if self.is_eof() {\n-                let last_pos = self.last_pos;\n-                panic!(self.fatal_span_(start, last_pos, \"unterminated double quote byte string\"));\n+                let pos = self.pos;\n+                panic!(self.fatal_span_(start, pos, \"unterminated double quote byte string\"));\n             }\n \n-            let ch_start = self.last_pos;\n-            let ch = self.curr.unwrap();\n+            let ch_start = self.pos;\n+            let ch = self.ch.unwrap();\n             self.bump();\n             valid &= self.scan_char_or_byte(ch_start,\n                                             ch,\n@@ -1582,49 +1585,49 @@ impl<'a> StringReader<'a> {\n     }\n \n     fn scan_raw_byte_string(&mut self) -> token::Lit {\n-        let start_bpos = self.last_pos;\n+        let start_bpos = self.pos;\n         self.bump();\n         let mut hash_count = 0;\n-        while self.curr_is('#') {\n+        while self.ch_is('#') {\n             self.bump();\n             hash_count += 1;\n         }\n \n         if self.is_eof() {\n-            let last_pos = self.last_pos;\n-            panic!(self.fatal_span_(start_bpos, last_pos, \"unterminated raw string\"));\n-        } else if !self.curr_is('\"') {\n-            let last_pos = self.last_pos;\n-            let ch = self.curr.unwrap();\n+            let pos = self.pos;\n+            panic!(self.fatal_span_(start_bpos, pos, \"unterminated raw string\"));\n+        } else if !self.ch_is('\"') {\n+            let pos = self.pos;\n+            let ch = self.ch.unwrap();\n             panic!(self.fatal_span_char(start_bpos,\n-                                        last_pos,\n+                                        pos,\n                                         \"found invalid character; only `#` is allowed in raw \\\n                                          string delimitation\",\n                                         ch));\n         }\n         self.bump();\n-        let content_start_bpos = self.last_pos;\n+        let content_start_bpos = self.pos;\n         let mut content_end_bpos;\n         'outer: loop {\n-            match self.curr {\n+            match self.ch {\n                 None => {\n-                    let last_pos = self.last_pos;\n-                    panic!(self.fatal_span_(start_bpos, last_pos, \"unterminated raw string\"))\n+                    let pos = self.pos;\n+                    panic!(self.fatal_span_(start_bpos, pos, \"unterminated raw string\"))\n                 }\n                 Some('\"') => {\n-                    content_end_bpos = self.last_pos;\n+                    content_end_bpos = self.pos;\n                     for _ in 0..hash_count {\n                         self.bump();\n-                        if !self.curr_is('#') {\n+                        if !self.ch_is('#') {\n                             continue 'outer;\n                         }\n                     }\n                     break;\n                 }\n                 Some(c) => {\n                     if c > '\\x7F' {\n-                        let last_pos = self.last_pos;\n-                        self.err_span_char(last_pos, last_pos, \"raw byte string must be ASCII\", c);\n+                        let pos = self.pos;\n+                        self.err_span_char(pos, pos, \"raw byte string must be ASCII\", c);\n                     }\n                 }\n             }\n@@ -1738,7 +1741,7 @@ mod tests {\n         assert_eq!(tok1, tok2);\n         assert_eq!(string_reader.next_token().tok, token::Whitespace);\n         // the 'main' id is already read:\n-        assert_eq!(string_reader.last_pos.clone(), BytePos(28));\n+        assert_eq!(string_reader.pos.clone(), BytePos(28));\n         // read another token:\n         let tok3 = string_reader.next_token();\n         let tok4 = TokenAndSpan {\n@@ -1751,7 +1754,7 @@ mod tests {\n         };\n         assert_eq!(tok3, tok4);\n         // the lparen is already read:\n-        assert_eq!(string_reader.last_pos.clone(), BytePos(29))\n+        assert_eq!(string_reader.pos.clone(), BytePos(29))\n     }\n \n     // check that the given reader produces the desired stream"}, {"sha": "1e08b20b7e1f4cca71ca043772d0537939af62e5", "filename": "src/libsyntax/parse/lexer/unicode_chars.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -234,7 +234,7 @@ pub fn check_for_substitution<'a>(reader: &StringReader<'a>,\n     .iter()\n     .find(|&&(c, _, _)| c == ch)\n     .map(|&(_, u_name, ascii_char)| {\n-        let span = make_span(reader.last_pos, reader.pos);\n+        let span = make_span(reader.pos, reader.next_pos);\n         match ASCII_ARRAY.iter().find(|&&(c, _)| c == ascii_char) {\n             Some(&(ascii_char, ascii_name)) => {\n                 let msg ="}, {"sha": "61268d457ce44a6658c0f46cdadc5a8a7c53d166", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 171, "deletions": 175, "changes": 346, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -238,7 +238,7 @@ fn maybe_append(mut lhs: Vec<Attribute>, rhs: Option<Vec<Attribute>>)\n }\n \n #[derive(PartialEq)]\n-enum LastTokenKind {\n+enum PrevTokenKind {\n     DocComment,\n     Comma,\n     Interpolated,\n@@ -254,11 +254,11 @@ pub struct Parser<'a> {\n     pub token: token::Token,\n     /// the span of the current token:\n     pub span: Span,\n-    /// the span of the prior token:\n-    pub last_span: Span,\n+    /// the span of the previous token:\n+    pub prev_span: Span,\n     pub cfg: CrateConfig,\n     /// the previous token kind\n-    last_token_kind: LastTokenKind,\n+    prev_token_kind: PrevTokenKind,\n     pub buffer: [TokenAndSpan; 4],\n     pub buffer_start: isize,\n     pub buffer_end: isize,\n@@ -368,8 +368,8 @@ impl<'a> Parser<'a> {\n             cfg: cfg,\n             token: tok0.tok,\n             span: span,\n-            last_span: span,\n-            last_token_kind: LastTokenKind::Other,\n+            prev_span: span,\n+            prev_token_kind: PrevTokenKind::Other,\n             buffer: [\n                 placeholder.clone(),\n                 placeholder.clone(),\n@@ -414,8 +414,7 @@ impl<'a> Parser<'a> {\n \n     pub fn unexpected_last<T>(&self, t: &token::Token) -> PResult<'a, T> {\n         let token_str = Parser::token_to_string(t);\n-        let last_span = self.last_span;\n-        Err(self.span_fatal(last_span, &format!(\"unexpected token: `{}`\", token_str)))\n+        Err(self.span_fatal(self.prev_span, &format!(\"unexpected token: `{}`\", token_str)))\n     }\n \n     pub fn unexpected<T>(&mut self) -> PResult<'a, T> {\n@@ -505,8 +504,8 @@ impl<'a> Parser<'a> {\n                                  expr: PResult<'a, P<Expr>>)\n                                  -> PResult<'a, (Span, P<Expr>)> {\n         expr.map(|e| {\n-            if self.last_token_kind == LastTokenKind::Interpolated {\n-                (self.last_span, e)\n+            if self.prev_token_kind == PrevTokenKind::Interpolated {\n+                (self.prev_span, e)\n             } else {\n                 (e.span, e)\n             }\n@@ -525,8 +524,8 @@ impl<'a> Parser<'a> {\n                 self.bug(\"ident interpolation not converted to real token\");\n             }\n             _ => {\n-                Err(if self.last_token_kind == LastTokenKind::DocComment {\n-                    self.span_fatal_help(self.last_span,\n+                Err(if self.prev_token_kind == PrevTokenKind::DocComment {\n+                    self.span_fatal_help(self.prev_span,\n                         \"found a documentation comment that doesn't document anything\",\n                         \"doc comments must come before what they document, maybe a comment was \\\n                         intended with `//`?\")\n@@ -923,20 +922,20 @@ impl<'a> Parser<'a> {\n \n     /// Advance the parser by one token\n     pub fn bump(&mut self) {\n-        if self.last_token_kind == LastTokenKind::Eof {\n+        if self.prev_token_kind == PrevTokenKind::Eof {\n             // Bumping after EOF is a bad sign, usually an infinite loop.\n             self.bug(\"attempted to bump the parser past EOF (may be stuck in a loop)\");\n         }\n \n-        self.last_span = self.span;\n+        self.prev_span = self.span;\n \n         // Record last token kind for possible error recovery.\n-        self.last_token_kind = match self.token {\n-            token::DocComment(..) => LastTokenKind::DocComment,\n-            token::Comma => LastTokenKind::Comma,\n-            token::Interpolated(..) => LastTokenKind::Interpolated,\n-            token::Eof => LastTokenKind::Eof,\n-            _ => LastTokenKind::Other,\n+        self.prev_token_kind = match self.token {\n+            token::DocComment(..) => PrevTokenKind::DocComment,\n+            token::Comma => PrevTokenKind::Comma,\n+            token::Interpolated(..) => PrevTokenKind::Interpolated,\n+            token::Eof => PrevTokenKind::Eof,\n+            _ => PrevTokenKind::Other,\n         };\n \n         let next = if self.buffer_start == self.buffer_end {\n@@ -974,11 +973,11 @@ impl<'a> Parser<'a> {\n                      next: token::Token,\n                      lo: BytePos,\n                      hi: BytePos) {\n-        self.last_span = mk_sp(self.span.lo, lo);\n+        self.prev_span = mk_sp(self.span.lo, lo);\n         // It would be incorrect to record the kind of the current token, but\n         // fortunately for tokens currently using `bump_with`, the\n-        // last_token_kind will be of no use anyway.\n-        self.last_token_kind = LastTokenKind::Other;\n+        // prev_token_kind will be of no use anyway.\n+        self.prev_token_kind = PrevTokenKind::Other;\n         self.span = mk_sp(lo, hi);\n         self.token = next;\n         self.expected_tokens.clear();\n@@ -1114,8 +1113,7 @@ impl<'a> Parser<'a> {\n         let bounds = self.parse_ty_param_bounds(BoundParsingMode::Modified)?;\n \n         if !bounds.iter().any(|b| if let TraitTyParamBound(..) = *b { true } else { false }) {\n-            let last_span = self.last_span;\n-            self.span_err(last_span, \"at least one trait must be specified\");\n+            self.span_err(self.prev_span, \"at least one trait must be specified\");\n         }\n \n         Ok(ast::TyKind::ImplTrait(bounds))\n@@ -1213,7 +1211,7 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Semi)?\n             }\n \n-            let mac = spanned(lo, self.last_span.hi, Mac_ { path: pth, tts: tts });\n+            let mac = spanned(lo, self.prev_span.hi, Mac_ { path: pth, tts: tts });\n             (keywords::Invalid.ident(), ast::TraitItemKind::Macro(mac))\n         } else {\n             let (constness, unsafety, abi) = match self.parse_fn_front_matter() {\n@@ -1283,7 +1281,7 @@ impl<'a> Parser<'a> {\n             ident: name,\n             attrs: attrs,\n             node: node,\n-            span: mk_sp(lo, self.last_span.hi),\n+            span: mk_sp(lo, self.prev_span.hi),\n         })\n     }\n \n@@ -1330,13 +1328,13 @@ impl<'a> Parser<'a> {\n         // In type grammar, `+` is treated like a binary operator,\n         // and hence both L and R side are required.\n         if bounds.is_empty() {\n-            let last_span = self.last_span;\n-            self.span_err(last_span,\n+            let prev_span = self.prev_span;\n+            self.span_err(prev_span,\n                           \"at least one type parameter bound \\\n                           must be specified\");\n         }\n \n-        let sp = mk_sp(lo, self.last_span.hi);\n+        let sp = mk_sp(lo, self.prev_span.hi);\n         let sum = ast::TyKind::ObjectSum(lhs, bounds);\n         Ok(P(Ty {id: ast::DUMMY_NODE_ID, node: sum, span: sp}))\n     }\n@@ -1438,7 +1436,7 @@ impl<'a> Parser<'a> {\n             return Err(self.fatal(&msg));\n         };\n \n-        let sp = mk_sp(lo, self.last_span.hi);\n+        let sp = mk_sp(lo, self.prev_span.hi);\n         Ok(P(Ty {id: ast::DUMMY_NODE_ID, node: t, span: sp}))\n     }\n \n@@ -1456,7 +1454,7 @@ impl<'a> Parser<'a> {\n         } else if self.eat_keyword(keywords::Const) {\n             Mutability::Immutable\n         } else {\n-            let span = self.last_span;\n+            let span = self.prev_span;\n             self.span_err(span,\n                           \"expected mut or const in raw pointer type (use \\\n                            `*mut T` or `*const T` as appropriate)\");\n@@ -1499,7 +1497,7 @@ impl<'a> Parser<'a> {\n             pat\n         } else {\n             debug!(\"parse_arg_general ident_to_pat\");\n-            let sp = self.last_span;\n+            let sp = self.prev_span;\n             let spanned = Spanned { span: sp, node: keywords::Invalid.ident() };\n             P(Pat {\n                 id: ast::DUMMY_NODE_ID,\n@@ -1624,7 +1622,7 @@ impl<'a> Parser<'a> {\n             let lit = self.parse_lit_token()?;\n             lit\n         };\n-        Ok(codemap::Spanned { node: lit, span: mk_sp(lo, self.last_span.hi) })\n+        Ok(codemap::Spanned { node: lit, span: mk_sp(lo, self.prev_span.hi) })\n     }\n \n     /// matches '-' lit | lit\n@@ -1633,11 +1631,11 @@ impl<'a> Parser<'a> {\n         let minus_present = self.eat(&token::BinOp(token::Minus));\n         let lo = self.span.lo;\n         let literal = P(self.parse_lit()?);\n-        let hi = self.last_span.hi;\n+        let hi = self.prev_span.hi;\n         let expr = self.mk_expr(lo, hi, ExprKind::Lit(literal), ThinVec::new());\n \n         if minus_present {\n-            let minus_hi = self.last_span.hi;\n+            let minus_hi = self.prev_span.hi;\n             let unary = self.mk_unary(UnOp::Neg, expr);\n             Ok(self.mk_expr(minus_lo, minus_hi, unary, ThinVec::new()))\n         } else {\n@@ -1672,7 +1670,7 @@ impl<'a> Parser<'a> {\n     /// `<T as U>::F::a::<S>`\n     pub fn parse_qualified_path(&mut self, mode: PathStyle)\n                                 -> PResult<'a, (QSelf, ast::Path)> {\n-        let span = self.last_span;\n+        let span = self.prev_span;\n         let self_type = self.parse_ty_sum()?;\n         let mut path = if self.eat_keyword(keywords::As) {\n             self.parse_path(PathStyle::Type)?\n@@ -1705,7 +1703,7 @@ impl<'a> Parser<'a> {\n         };\n         path.segments.extend(segments);\n \n-        path.span.hi = self.last_span.hi;\n+        path.span.hi = self.prev_span.hi;\n \n         Ok((qself, path))\n     }\n@@ -1743,7 +1741,7 @@ impl<'a> Parser<'a> {\n         };\n \n         // Assemble the span.\n-        let span = mk_sp(lo, self.last_span.hi);\n+        let span = mk_sp(lo, self.prev_span.hi);\n \n         // Assemble the result.\n         Ok(ast::Path {\n@@ -1773,7 +1771,7 @@ impl<'a> Parser<'a> {\n                     bindings: P::from_vec(bindings),\n                 })\n             } else if self.eat(&token::OpenDelim(token::Paren)) {\n-                let lo = self.last_span.lo;\n+                let lo = self.prev_span.lo;\n \n                 let inputs = self.parse_seq_to_end(\n                     &token::CloseDelim(token::Paren),\n@@ -1786,7 +1784,7 @@ impl<'a> Parser<'a> {\n                     None\n                 };\n \n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n \n                 ast::PathParameters::Parenthesized(ast::ParenthesizedParameterData {\n                     span: mk_sp(lo, hi),\n@@ -2017,7 +2015,7 @@ impl<'a> Parser<'a> {\n     pub fn parse_field(&mut self) -> PResult<'a, Field> {\n         let lo = self.span.lo;\n         let i = self.parse_field_name()?;\n-        let hi = self.last_span.hi;\n+        let hi = self.prev_span.hi;\n         self.expect(&token::Colon)?;\n         let e = self.parse_expr()?;\n         Ok(ast::Field {\n@@ -2172,7 +2170,7 @@ impl<'a> Parser<'a> {\n                 }\n                 self.bump();\n \n-                hi = self.last_span.hi;\n+                hi = self.prev_span.hi;\n                 return if es.len() == 1 && !trailing_comma {\n                     Ok(self.mk_expr(lo, hi, ExprKind::Paren(es.into_iter().nth(0).unwrap()), attrs))\n                 } else {\n@@ -2221,7 +2219,7 @@ impl<'a> Parser<'a> {\n                         ex = ExprKind::Vec(vec!(first_expr));\n                     }\n                 }\n-                hi = self.last_span.hi;\n+                hi = self.prev_span.hi;\n             }\n             _ => {\n                 if self.eat_lt() {\n@@ -2231,18 +2229,18 @@ impl<'a> Parser<'a> {\n                     return Ok(self.mk_expr(lo, hi, ExprKind::Path(Some(qself), path), attrs));\n                 }\n                 if self.eat_keyword(keywords::Move) {\n-                    let lo = self.last_span.lo;\n+                    let lo = self.prev_span.lo;\n                     return self.parse_lambda_expr(lo, CaptureBy::Value, attrs);\n                 }\n                 if self.eat_keyword(keywords::If) {\n                     return self.parse_if_expr(attrs);\n                 }\n                 if self.eat_keyword(keywords::For) {\n-                    let lo = self.last_span.lo;\n+                    let lo = self.prev_span.lo;\n                     return self.parse_for_expr(None, lo, attrs);\n                 }\n                 if self.eat_keyword(keywords::While) {\n-                    let lo = self.last_span.lo;\n+                    let lo = self.prev_span.lo;\n                     return self.parse_while_expr(None, lo, attrs);\n                 }\n                 if self.token.is_lifetime() {\n@@ -2263,7 +2261,7 @@ impl<'a> Parser<'a> {\n                     return Err(self.fatal(\"expected `while`, `for`, or `loop` after a label\"))\n                 }\n                 if self.eat_keyword(keywords::Loop) {\n-                    let lo = self.last_span.lo;\n+                    let lo = self.prev_span.lo;\n                     return self.parse_loop_expr(None, lo, attrs);\n                 }\n                 if self.eat_keyword(keywords::Continue) {\n@@ -2277,7 +2275,7 @@ impl<'a> Parser<'a> {\n                     } else {\n                         ExprKind::Continue(None)\n                     };\n-                    let hi = self.last_span.hi;\n+                    let hi = self.prev_span.hi;\n                     return Ok(self.mk_expr(lo, hi, ex, attrs));\n                 }\n                 if self.eat_keyword(keywords::Match) {\n@@ -2307,7 +2305,7 @@ impl<'a> Parser<'a> {\n                     } else {\n                         ex = ExprKind::Break(None);\n                     }\n-                    hi = self.last_span.hi;\n+                    hi = self.prev_span.hi;\n                 } else if self.token.is_keyword(keywords::Let) {\n                     // Catch this syntax error here, instead of in `check_strict_keywords`, so\n                     // that we can explicitly mention that let is not to be used as an expression\n@@ -2324,7 +2322,7 @@ impl<'a> Parser<'a> {\n                         let tts = self.parse_seq_to_end(&token::CloseDelim(delim),\n                                                         SeqSep::none(),\n                                                         |p| p.parse_token_tree())?;\n-                        let hi = self.last_span.hi;\n+                        let hi = self.prev_span.hi;\n                         return Ok(self.mk_mac_expr(lo, hi, Mac_ { path: pth, tts: tts }, attrs));\n                     }\n                     if self.check(&token::OpenDelim(token::Brace)) {\n@@ -2489,8 +2487,8 @@ impl<'a> Parser<'a> {\n         };\n \n         if !bindings.is_empty() {\n-            let last_span = self.last_span;\n-            self.span_err(last_span, \"type bindings are only permitted on trait paths\");\n+            let prev_span = self.prev_span;\n+            self.span_err(prev_span, \"type bindings are only permitted on trait paths\");\n         }\n \n         Ok(match self.token {\n@@ -2502,7 +2500,7 @@ impl<'a> Parser<'a> {\n                     SeqSep::trailing_allowed(token::Comma),\n                     |p| Ok(p.parse_expr()?)\n                 )?;\n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n \n                 es.insert(0, self_value);\n                 let id = spanned(ident_span.lo, ident_span.hi, ident);\n@@ -2512,8 +2510,8 @@ impl<'a> Parser<'a> {\n             // Field access.\n             _ => {\n                 if !tys.is_empty() {\n-                    let last_span = self.last_span;\n-                    self.span_err(last_span,\n+                    let prev_span = self.prev_span;\n+                    self.span_err(prev_span,\n                                   \"field expressions may not \\\n                                    have type parameters\");\n                 }\n@@ -2531,15 +2529,15 @@ impl<'a> Parser<'a> {\n         loop {\n             // expr?\n             while self.eat(&token::Question) {\n-                let hi = self.last_span.hi;\n+                let hi = self.prev_span.hi;\n                 e = self.mk_expr(lo, hi, ExprKind::Try(e), ThinVec::new());\n             }\n \n             // expr.f\n             if self.eat(&token::Dot) {\n                 match self.token {\n                   token::Ident(i) => {\n-                    let dot_pos = self.last_span.hi;\n+                    let dot_pos = self.prev_span.hi;\n                     hi = self.span.hi;\n                     self.bump();\n \n@@ -2551,7 +2549,7 @@ impl<'a> Parser<'a> {\n                     // A tuple index may not have a suffix\n                     self.expect_no_suffix(sp, \"tuple index\", suf);\n \n-                    let dot = self.last_span.hi;\n+                    let dot = self.prev_span.hi;\n                     hi = self.span.hi;\n                     self.bump();\n \n@@ -2563,16 +2561,16 @@ impl<'a> Parser<'a> {\n                             e = self.mk_expr(lo, hi, field, ThinVec::new());\n                         }\n                         None => {\n-                            let last_span = self.last_span;\n-                            self.span_err(last_span, \"invalid tuple or tuple struct index\");\n+                            let prev_span = self.prev_span;\n+                            self.span_err(prev_span, \"invalid tuple or tuple struct index\");\n                         }\n                     }\n                   }\n                   token::Literal(token::Float(n), _suf) => {\n                     self.bump();\n-                    let last_span = self.last_span;\n+                    let prev_span = self.prev_span;\n                     let fstr = n.as_str();\n-                    let mut err = self.diagnostic().struct_span_err(last_span,\n+                    let mut err = self.diagnostic().struct_span_err(prev_span,\n                         &format!(\"unexpected token: `{}`\", n.as_str()));\n                     if fstr.chars().all(|x| \"0123456789.\".contains(x)) {\n                         let float = match fstr.parse::<f64>().ok() {\n@@ -2591,7 +2589,7 @@ impl<'a> Parser<'a> {\n                     let actual = self.this_token_to_string();\n                     self.span_err(self.span, &format!(\"unexpected token: `{}`\", actual));\n \n-                    let dot_pos = self.last_span.hi;\n+                    let dot_pos = self.prev_span.hi;\n                     e = self.parse_dot_suffix(keywords::Invalid.ident(),\n                                               mk_sp(dot_pos, dot_pos),\n                                               e, lo)?;\n@@ -2609,7 +2607,7 @@ impl<'a> Parser<'a> {\n                     SeqSep::trailing_allowed(token::Comma),\n                     |p| Ok(p.parse_expr()?)\n                 )?;\n-                hi = self.last_span.hi;\n+                hi = self.prev_span.hi;\n \n                 let nd = self.mk_call(e, es);\n                 e = self.mk_expr(lo, hi, nd, ThinVec::new());\n@@ -2952,8 +2950,8 @@ impl<'a> Parser<'a> {\n         self.expected_tokens.push(TokenType::Operator);\n         while let Some(op) = AssocOp::from_token(&self.token) {\n \n-            let lhs_span = if self.last_token_kind == LastTokenKind::Interpolated {\n-                self.last_span\n+            let lhs_span = if self.prev_token_kind == PrevTokenKind::Interpolated {\n+                self.prev_span\n             } else {\n                 lhs.span\n             };\n@@ -3146,7 +3144,7 @@ impl<'a> Parser<'a> {\n         if self.check_keyword(keywords::Let) {\n             return self.parse_if_let_expr(attrs);\n         }\n-        let lo = self.last_span.lo;\n+        let lo = self.prev_span.lo;\n         let cond = self.parse_expr_res(Restrictions::RESTRICTION_NO_STRUCT_LITERAL, None)?;\n         let thn = self.parse_block()?;\n         let mut els: Option<P<Expr>> = None;\n@@ -3162,7 +3160,7 @@ impl<'a> Parser<'a> {\n     /// Parse an 'if let' expression ('if' token already eaten)\n     pub fn parse_if_let_expr(&mut self, attrs: ThinVec<Attribute>)\n                              -> PResult<'a, P<Expr>> {\n-        let lo = self.last_span.lo;\n+        let lo = self.prev_span.lo;\n         self.expect_keyword(keywords::Let)?;\n         let pat = self.parse_pat()?;\n         self.expect(&token::Eq)?;\n@@ -3185,7 +3183,7 @@ impl<'a> Parser<'a> {\n                              -> PResult<'a, P<Expr>>\n     {\n         let decl = self.parse_fn_block_decl()?;\n-        let decl_hi = self.last_span.hi;\n+        let decl_hi = self.prev_span.hi;\n         let body = match decl.output {\n             FunctionRetTy::Default(_) => {\n                 // If no explicit return type is given, parse any\n@@ -3238,7 +3236,7 @@ impl<'a> Parser<'a> {\n         let (iattrs, loop_block) = self.parse_inner_attrs_and_block()?;\n         attrs.extend(iattrs);\n \n-        let hi = self.last_span.hi;\n+        let hi = self.prev_span.hi;\n \n         Ok(self.mk_expr(span_lo, hi,\n                         ExprKind::ForLoop(pat, expr, loop_block, opt_ident),\n@@ -3286,8 +3284,8 @@ impl<'a> Parser<'a> {\n \n     // `match` token already eaten\n     fn parse_match_expr(&mut self, mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n-        let match_span = self.last_span;\n-        let lo = self.last_span.lo;\n+        let match_span = self.prev_span;\n+        let lo = self.prev_span.lo;\n         let discriminant = self.parse_expr_res(Restrictions::RESTRICTION_NO_STRUCT_LITERAL,\n                                                None)?;\n         if let Err(mut e) = self.expect(&token::OpenDelim(token::Brace)) {\n@@ -3409,7 +3407,7 @@ impl<'a> Parser<'a> {\n                 }\n             } else if ddpos.is_some() && self.eat(&token::DotDot) {\n                 // Emit a friendly error, ignore `..` and continue parsing\n-                self.span_err(self.last_span, \"`..` can only be used once per \\\n+                self.span_err(self.prev_span, \"`..` can only be used once per \\\n                                                tuple or tuple struct pattern\");\n             } else {\n                 fields.push(self.parse_pat()?);\n@@ -3520,15 +3518,15 @@ impl<'a> Parser<'a> {\n                 let is_ref = self.eat_keyword(keywords::Ref);\n                 let is_mut = self.eat_keyword(keywords::Mut);\n                 let fieldname = self.parse_ident()?;\n-                hi = self.last_span.hi;\n+                hi = self.prev_span.hi;\n \n                 let bind_type = match (is_ref, is_mut) {\n                     (true, true) => BindingMode::ByRef(Mutability::Mutable),\n                     (true, false) => BindingMode::ByRef(Mutability::Immutable),\n                     (false, true) => BindingMode::ByValue(Mutability::Mutable),\n                     (false, false) => BindingMode::ByValue(Mutability::Immutable),\n                 };\n-                let fieldpath = codemap::Spanned{span:self.last_span, node:fieldname};\n+                let fieldpath = codemap::Spanned{span:self.prev_span, node:fieldname};\n                 let fieldpat = P(ast::Pat{\n                     id: ast::DUMMY_NODE_ID,\n                     node: PatKind::Ident(bind_type, fieldpath, None),\n@@ -3567,7 +3565,7 @@ impl<'a> Parser<'a> {\n                 // Parse an unqualified path\n                 (None, self.parse_path(PathStyle::Expr)?)\n             };\n-            let hi = self.last_span.hi;\n+            let hi = self.prev_span.hi;\n             Ok(self.mk_expr(lo, hi, ExprKind::Path(qself, path), ThinVec::new()))\n         } else {\n             self.parse_pat_literal_maybe_minus()\n@@ -3651,12 +3649,12 @@ impl<'a> Parser<'a> {\n                         let tts = self.parse_seq_to_end(&token::CloseDelim(delim),\n                                                         SeqSep::none(),\n                                                         |p| p.parse_token_tree())?;\n-                        let mac = spanned(lo, self.last_span.hi, Mac_ { path: path, tts: tts });\n+                        let mac = spanned(lo, self.prev_span.hi, Mac_ { path: path, tts: tts });\n                         pat = PatKind::Mac(mac);\n                     }\n                     token::DotDotDot => {\n                         // Parse range\n-                        let hi = self.last_span.hi;\n+                        let hi = self.prev_span.hi;\n                         let begin =\n                               self.mk_expr(lo, hi, ExprKind::Path(qself, path), ThinVec::new());\n                         self.bump();\n@@ -3709,7 +3707,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        let hi = self.last_span.hi;\n+        let hi = self.prev_span.hi;\n         Ok(P(ast::Pat {\n             id: ast::DUMMY_NODE_ID,\n             node: pat,\n@@ -3724,8 +3722,8 @@ impl<'a> Parser<'a> {\n                        binding_mode: ast::BindingMode)\n                        -> PResult<'a, PatKind> {\n         let ident = self.parse_ident()?;\n-        let last_span = self.last_span;\n-        let name = codemap::Spanned{span: last_span, node: ident};\n+        let prev_span = self.prev_span;\n+        let name = codemap::Spanned{span: prev_span, node: ident};\n         let sub = if self.eat(&token::At) {\n             Some(self.parse_pat()?)\n         } else {\n@@ -3739,9 +3737,8 @@ impl<'a> Parser<'a> {\n         // binding mode then we do not end up here, because the lookahead\n         // will direct us over to parse_enum_variant()\n         if self.token == token::OpenDelim(token::Paren) {\n-            let last_span = self.last_span;\n             return Err(self.span_fatal(\n-                last_span,\n+                self.prev_span,\n                 \"expected identifier, found enum pattern\"))\n         }\n \n@@ -3763,7 +3760,7 @@ impl<'a> Parser<'a> {\n             pat: pat,\n             init: init,\n             id: ast::DUMMY_NODE_ID,\n-            span: mk_sp(lo, self.last_span.hi),\n+            span: mk_sp(lo, self.prev_span.hi),\n             attrs: attrs,\n         }))\n     }\n@@ -3778,7 +3775,7 @@ impl<'a> Parser<'a> {\n         self.expect(&token::Colon)?;\n         let ty = self.parse_ty_sum()?;\n         Ok(StructField {\n-            span: mk_sp(lo, self.last_span.hi),\n+            span: mk_sp(lo, self.prev_span.hi),\n             ident: Some(name),\n             vis: vis,\n             id: ast::DUMMY_NODE_ID,\n@@ -3796,7 +3793,7 @@ impl<'a> Parser<'a> {\n             _ => \"expected item after attributes\",\n         };\n \n-        self.span_err(self.last_span, message);\n+        self.span_err(self.prev_span, message);\n     }\n \n     /// Parse a statement. This stops just before trailing semicolons on everything but items.\n@@ -3886,7 +3883,7 @@ impl<'a> Parser<'a> {\n             Stmt {\n                 id: ast::DUMMY_NODE_ID,\n                 node: StmtKind::Local(self.parse_local(attrs.into())?),\n-                span: mk_sp(lo, self.last_span.hi),\n+                span: mk_sp(lo, self.prev_span.hi),\n             }\n         } else if self.token.is_path_start() && self.token != token::Lt && {\n             !self.check_keyword(keywords::Union) ||\n@@ -3898,7 +3895,7 @@ impl<'a> Parser<'a> {\n                 let expr = if self.check(&token::OpenDelim(token::Brace)) {\n                     self.parse_struct_expr(lo, pth, ThinVec::new())?\n                 } else {\n-                    let hi = self.last_span.hi;\n+                    let hi = self.prev_span.hi;\n                     self.mk_expr(lo, hi, ExprKind::Path(None, pth), ThinVec::new())\n                 };\n \n@@ -3910,7 +3907,7 @@ impl<'a> Parser<'a> {\n                 return Ok(Some(Stmt {\n                     id: ast::DUMMY_NODE_ID,\n                     node: StmtKind::Expr(expr),\n-                    span: mk_sp(lo, self.last_span.hi),\n+                    span: mk_sp(lo, self.prev_span.hi),\n                 }));\n             }\n \n@@ -3946,7 +3943,7 @@ impl<'a> Parser<'a> {\n                 SeqSep::none(),\n                 |p| p.parse_token_tree()\n             )?;\n-            let hi = self.last_span.hi;\n+            let hi = self.prev_span.hi;\n \n             let style = if delim == token::Brace {\n                 MacStmtStyle::Braces\n@@ -3991,8 +3988,7 @@ impl<'a> Parser<'a> {\n                 // Require a semicolon or braces.\n                 if style != MacStmtStyle::Braces {\n                     if !self.eat(&token::Semi) {\n-                        let last_span = self.last_span;\n-                        self.span_err(last_span,\n+                        self.span_err(self.prev_span,\n                                       \"macros that expand to items must \\\n                                        either be surrounded with braces or \\\n                                        followed by a semicolon\");\n@@ -4023,8 +4019,8 @@ impl<'a> Parser<'a> {\n                 None => {\n                     let unused_attrs = |attrs: &[_], s: &mut Self| {\n                         if attrs.len() > 0 {\n-                            if s.last_token_kind == LastTokenKind::DocComment {\n-                                s.span_err_help(s.last_span,\n+                            if s.prev_token_kind == PrevTokenKind::DocComment {\n+                                s.span_err_help(s.prev_span,\n                                     \"found a documentation comment that doesn't document anything\",\n                                     \"doc comments must come before what they document, maybe a \\\n                                     comment was intended with `//`?\");\n@@ -4087,7 +4083,7 @@ impl<'a> Parser<'a> {\n                     let mut stmt_span = stmt.span;\n                     // expand the span to include the semicolon, if it exists\n                     if self.eat(&token::Semi) {\n-                        stmt_span.hi = self.last_span.hi;\n+                        stmt_span.hi = self.prev_span.hi;\n                     }\n                     e.span_help(stmt_span, \"try placing this code inside a block\");\n                 }\n@@ -4133,7 +4129,7 @@ impl<'a> Parser<'a> {\n             stmts: stmts,\n             id: ast::DUMMY_NODE_ID,\n             rules: s,\n-            span: mk_sp(lo, self.last_span.hi),\n+            span: mk_sp(lo, self.prev_span.hi),\n         }))\n     }\n \n@@ -4172,7 +4168,7 @@ impl<'a> Parser<'a> {\n             stmt = stmt.add_trailing_semicolon();\n         }\n \n-        stmt.span.hi = self.last_span.hi;\n+        stmt.span.hi = self.prev_span.hi;\n         Ok(Some(stmt))\n     }\n \n@@ -4308,8 +4304,8 @@ impl<'a> Parser<'a> {\n                 if ty_param.default.is_some() {\n                     seen_default = true;\n                 } else if seen_default {\n-                    let last_span = p.last_span;\n-                    p.span_err(last_span,\n+                    let prev_span = p.prev_span;\n+                    p.span_err(prev_span,\n                                \"type parameters with a default must be trailing\");\n                 }\n                 Ok(ty_param)\n@@ -4327,7 +4323,7 @@ impl<'a> Parser<'a> {\n                     id: ast::DUMMY_NODE_ID,\n                     predicates: Vec::new(),\n                 },\n-                span: mk_sp(span_lo, self.last_span.hi),\n+                span: mk_sp(span_lo, self.prev_span.hi),\n             })\n         } else {\n             Ok(ast::Generics::default())\n@@ -4342,7 +4338,7 @@ impl<'a> Parser<'a> {\n \n         let missing_comma = !lifetimes.is_empty() &&\n                             !self.token.is_like_gt() &&\n-                            self.last_token_kind != LastTokenKind::Comma;\n+                            self.prev_token_kind != PrevTokenKind::Comma;\n \n         if missing_comma {\n \n@@ -4449,7 +4445,7 @@ impl<'a> Parser<'a> {\n                     let bounds =\n                         self.parse_lifetimes(token::BinOp(token::Plus))?;\n \n-                    let hi = self.last_span.hi;\n+                    let hi = self.prev_span.hi;\n                     let span = mk_sp(lo, hi);\n \n                     where_clause.predicates.push(ast::WherePredicate::RegionPredicate(\n@@ -4478,7 +4474,7 @@ impl<'a> Parser<'a> {\n \n                     if self.eat(&token::Colon) {\n                         let bounds = self.parse_ty_param_bounds(BoundParsingMode::Bare)?;\n-                        let hi = self.last_span.hi;\n+                        let hi = self.prev_span.hi;\n                         let span = mk_sp(lo, hi);\n \n                         if bounds.is_empty() {\n@@ -4498,7 +4494,7 @@ impl<'a> Parser<'a> {\n                         parsed_something = true;\n                     } else if self.eat(&token::Eq) {\n                         // let ty = try!(self.parse_ty());\n-                        let hi = self.last_span.hi;\n+                        let hi = self.prev_span.hi;\n                         let span = mk_sp(lo, hi);\n                         // where_clause.predicates.push(\n                         //     ast::WherePredicate::EqPredicate(ast::WhereEqPredicate {\n@@ -4513,8 +4509,8 @@ impl<'a> Parser<'a> {\n                                      \"equality constraints are not yet supported \\\n                                      in where clauses (#20041)\");\n                     } else {\n-                        let last_span = self.last_span;\n-                        self.span_err(last_span,\n+                        let prev_span = self.prev_span;\n+                        self.span_err(prev_span,\n                               \"unexpected token in `where` clause\");\n                     }\n                 }\n@@ -4526,8 +4522,8 @@ impl<'a> Parser<'a> {\n         }\n \n         if !parsed_something {\n-            let last_span = self.last_span;\n-            self.span_err(last_span,\n+            let prev_span = self.prev_span;\n+            self.span_err(prev_span,\n                           \"a `where` clause must have at least one predicate \\\n                            in it\");\n         }\n@@ -4600,7 +4596,7 @@ impl<'a> Parser<'a> {\n     fn parse_self_arg(&mut self) -> PResult<'a, Option<Arg>> {\n         let expect_ident = |this: &mut Self| match this.token {\n             // Preserve hygienic context.\n-            token::Ident(ident) => { this.bump(); codemap::respan(this.last_span, ident) }\n+            token::Ident(ident) => { this.bump(); codemap::respan(this.prev_span, ident) }\n             _ => unreachable!()\n         };\n \n@@ -4689,7 +4685,7 @@ impl<'a> Parser<'a> {\n             _ => return Ok(None),\n         };\n \n-        let eself = codemap::respan(mk_sp(eself_lo, self.last_span.hi), eself);\n+        let eself = codemap::respan(mk_sp(eself_lo, self.prev_span.hi), eself);\n         Ok(Some(Arg::from_self(eself, eself_ident)))\n     }\n \n@@ -4807,7 +4803,7 @@ impl<'a> Parser<'a> {\n                                                 ast::Unsafety,\n                                                 abi::Abi)> {\n         let is_const_fn = self.eat_keyword(keywords::Const);\n-        let const_span = self.last_span;\n+        let const_span = self.prev_span;\n         let unsafety = self.parse_unsafety()?;\n         let (constness, unsafety, abi) = if is_const_fn {\n             (respan(const_span, Constness::Const), unsafety, Abi::Rust)\n@@ -4817,7 +4813,7 @@ impl<'a> Parser<'a> {\n             } else {\n                 Abi::Rust\n             };\n-            (respan(self.last_span, Constness::NotConst), unsafety, abi)\n+            (respan(self.prev_span, Constness::NotConst), unsafety, abi)\n         };\n         self.expect_keyword(keywords::Fn)?;\n         Ok((constness, unsafety, abi))\n@@ -4854,7 +4850,7 @@ impl<'a> Parser<'a> {\n \n         Ok(ImplItem {\n             id: ast::DUMMY_NODE_ID,\n-            span: mk_sp(lo, self.last_span.hi),\n+            span: mk_sp(lo, self.prev_span.hi),\n             ident: name,\n             vis: vis,\n             defaultness: defaultness,\n@@ -4894,8 +4890,8 @@ impl<'a> Parser<'a> {\n         if self.token.is_path_start() {\n             // method macro.\n \n-            let last_span = self.last_span;\n-            self.complain_if_pub_macro(&vis, last_span);\n+            let prev_span = self.prev_span;\n+            self.complain_if_pub_macro(&vis, prev_span);\n \n             let lo = self.span.lo;\n             let pth = self.parse_path(PathStyle::Mod)?;\n@@ -4910,7 +4906,7 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Semi)?\n             }\n \n-            let mac = spanned(lo, self.last_span.hi, Mac_ { path: pth, tts: tts });\n+            let mac = spanned(lo, self.prev_span.hi, Mac_ { path: pth, tts: tts });\n             Ok((keywords::Invalid.ident(), vec![], ast::ImplItemKind::Macro(mac)))\n         } else {\n             let (constness, unsafety, abi) = self.parse_fn_front_matter()?;\n@@ -5051,7 +5047,7 @@ impl<'a> Parser<'a> {\n         Ok(ast::PolyTraitRef {\n             bound_lifetimes: lifetime_defs,\n             trait_ref: self.parse_trait_ref()?,\n-            span: mk_sp(lo, self.last_span.hi),\n+            span: mk_sp(lo, self.prev_span.hi),\n         })\n     }\n \n@@ -5217,7 +5213,7 @@ impl<'a> Parser<'a> {\n     // If `allow_path` is false, just parse the `pub` in `pub(path)` (but still parse `pub(crate)`)\n     fn parse_visibility(&mut self, allow_path: bool) -> PResult<'a, Visibility> {\n         let pub_crate = |this: &mut Self| {\n-            let span = this.last_span;\n+            let span = this.prev_span;\n             this.expect(&token::CloseDelim(token::Paren))?;\n             Ok(Visibility::Crate(span))\n         };\n@@ -5268,7 +5264,7 @@ impl<'a> Parser<'a> {\n         let hi = if self.span == syntax_pos::DUMMY_SP {\n             inner_lo\n         } else {\n-            self.last_span.hi\n+            self.prev_span.hi\n         };\n \n         Ok(ast::Mod {\n@@ -5537,9 +5533,9 @@ impl<'a> Parser<'a> {\n         };\n         self.expect(&token::Semi)?;\n \n-        let last_span = self.last_span;\n+        let prev_span = self.prev_span;\n         Ok(self.mk_item(lo,\n-                        last_span.hi,\n+                        prev_span.hi,\n                         ident,\n                         ItemKind::ExternCrate(maybe_path),\n                         visibility,\n@@ -5574,13 +5570,13 @@ impl<'a> Parser<'a> {\n         }\n         self.expect(&token::CloseDelim(token::Brace))?;\n \n-        let last_span = self.last_span;\n+        let prev_span = self.prev_span;\n         let m = ast::ForeignMod {\n             abi: abi,\n             items: foreign_items\n         };\n         Ok(self.mk_item(lo,\n-                     last_span.hi,\n+                     prev_span.hi,\n                      keywords::Invalid.ident(),\n                      ItemKind::ForeignMod(m),\n                      visibility,\n@@ -5633,7 +5629,7 @@ impl<'a> Parser<'a> {\n                 data: struct_def,\n                 disr_expr: disr_expr,\n             };\n-            variants.push(spanned(vlo, self.last_span.hi, vr));\n+            variants.push(spanned(vlo, self.prev_span.hi, vr));\n \n             if !self.eat(&token::Comma) { break; }\n         }\n@@ -5670,9 +5666,9 @@ impl<'a> Parser<'a> {\n                 match abi::lookup(&s.as_str()) {\n                     Some(abi) => Ok(Some(abi)),\n                     None => {\n-                        let last_span = self.last_span;\n+                        let prev_span = self.prev_span;\n                         self.span_err(\n-                            last_span,\n+                            prev_span,\n                             &format!(\"invalid ABI: expected one of [{}], \\\n                                      found `{}`\",\n                                     abi::all_names().join(\", \"),\n@@ -5714,9 +5710,9 @@ impl<'a> Parser<'a> {\n             let item_ = ItemKind::Use(self.parse_view_path()?);\n             self.expect(&token::Semi)?;\n \n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     keywords::Invalid.ident(),\n                                     item_,\n                                     visibility,\n@@ -5733,15 +5729,15 @@ impl<'a> Parser<'a> {\n \n             if self.eat_keyword(keywords::Fn) {\n                 // EXTERN FUNCTION ITEM\n-                let fn_span = self.last_span;\n+                let fn_span = self.prev_span;\n                 let abi = opt_abi.unwrap_or(Abi::C);\n                 let (ident, item_, extra_attrs) =\n                     self.parse_item_fn(Unsafety::Normal,\n                                        respan(fn_span, Constness::NotConst),\n                                        abi)?;\n-                let last_span = self.last_span;\n+                let prev_span = self.prev_span;\n                 let item = self.mk_item(lo,\n-                                        last_span.hi,\n+                                        prev_span.hi,\n                                         ident,\n                                         item_,\n                                         visibility,\n@@ -5762,17 +5758,17 @@ impl<'a> Parser<'a> {\n                 Mutability::Immutable\n             };\n             let (ident, item_, extra_attrs) = self.parse_item_const(Some(m))?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n         if self.eat_keyword(keywords::Const) {\n-            let const_span = self.last_span;\n+            let const_span = self.prev_span;\n             if self.check_keyword(keywords::Fn)\n                 || (self.check_keyword(keywords::Unsafe)\n                     && self.look_ahead(1, |t| t.is_keyword(keywords::Fn))) {\n@@ -5787,9 +5783,9 @@ impl<'a> Parser<'a> {\n                     self.parse_item_fn(unsafety,\n                                        respan(const_span, Constness::Const),\n                                        Abi::Rust)?;\n-                let last_span = self.last_span;\n+                let prev_span = self.prev_span;\n                 let item = self.mk_item(lo,\n-                                        last_span.hi,\n+                                        prev_span.hi,\n                                         ident,\n                                         item_,\n                                         visibility,\n@@ -5799,15 +5795,15 @@ impl<'a> Parser<'a> {\n \n             // CONST ITEM\n             if self.eat_keyword(keywords::Mut) {\n-                let last_span = self.last_span;\n-                self.diagnostic().struct_span_err(last_span, \"const globals cannot be mutable\")\n+                let prev_span = self.prev_span;\n+                self.diagnostic().struct_span_err(prev_span, \"const globals cannot be mutable\")\n                                  .help(\"did you mean to declare a static?\")\n                                  .emit();\n             }\n             let (ident, item_, extra_attrs) = self.parse_item_const(None)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5822,9 +5818,9 @@ impl<'a> Parser<'a> {\n             self.expect_keyword(keywords::Trait)?;\n             let (ident, item_, extra_attrs) =\n                 self.parse_item_trait(ast::Unsafety::Unsafe)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5838,9 +5834,9 @@ impl<'a> Parser<'a> {\n             self.expect_keyword(keywords::Unsafe)?;\n             self.expect_keyword(keywords::Impl)?;\n             let (ident, item_, extra_attrs) = self.parse_item_impl(ast::Unsafety::Unsafe)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5850,14 +5846,14 @@ impl<'a> Parser<'a> {\n         if self.check_keyword(keywords::Fn) {\n             // FUNCTION ITEM\n             self.bump();\n-            let fn_span = self.last_span;\n+            let fn_span = self.prev_span;\n             let (ident, item_, extra_attrs) =\n                 self.parse_item_fn(Unsafety::Normal,\n                                    respan(fn_span, Constness::NotConst),\n                                    Abi::Rust)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5874,14 +5870,14 @@ impl<'a> Parser<'a> {\n                 Abi::Rust\n             };\n             self.expect_keyword(keywords::Fn)?;\n-            let fn_span = self.last_span;\n+            let fn_span = self.prev_span;\n             let (ident, item_, extra_attrs) =\n                 self.parse_item_fn(Unsafety::Unsafe,\n                                    respan(fn_span, Constness::NotConst),\n                                    abi)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5892,9 +5888,9 @@ impl<'a> Parser<'a> {\n             // MODULE ITEM\n             let (ident, item_, extra_attrs) =\n                 self.parse_item_mod(&attrs[..])?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5904,9 +5900,9 @@ impl<'a> Parser<'a> {\n         if self.eat_keyword(keywords::Type) {\n             // TYPE ITEM\n             let (ident, item_, extra_attrs) = self.parse_item_type()?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5916,9 +5912,9 @@ impl<'a> Parser<'a> {\n         if self.eat_keyword(keywords::Enum) {\n             // ENUM ITEM\n             let (ident, item_, extra_attrs) = self.parse_item_enum()?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5929,9 +5925,9 @@ impl<'a> Parser<'a> {\n             // TRAIT ITEM\n             let (ident, item_, extra_attrs) =\n                 self.parse_item_trait(ast::Unsafety::Normal)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5941,9 +5937,9 @@ impl<'a> Parser<'a> {\n         if self.eat_keyword(keywords::Impl) {\n             // IMPL ITEM\n             let (ident, item_, extra_attrs) = self.parse_item_impl(ast::Unsafety::Normal)?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5953,9 +5949,9 @@ impl<'a> Parser<'a> {\n         if self.eat_keyword(keywords::Struct) {\n             // STRUCT ITEM\n             let (ident, item_, extra_attrs) = self.parse_item_struct()?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -5967,9 +5963,9 @@ impl<'a> Parser<'a> {\n             // UNION ITEM\n             self.bump();\n             let (ident, item_, extra_attrs) = self.parse_item_union()?;\n-            let last_span = self.last_span;\n+            let prev_span = self.prev_span;\n             let item = self.mk_item(lo,\n-                                    last_span.hi,\n+                                    prev_span.hi,\n                                     ident,\n                                     item_,\n                                     visibility,\n@@ -6015,8 +6011,8 @@ impl<'a> Parser<'a> {\n         if macros_allowed && self.token.is_path_start() {\n             // MACRO INVOCATION ITEM\n \n-            let last_span = self.last_span;\n-            self.complain_if_pub_macro(&visibility, last_span);\n+            let prev_span = self.prev_span;\n+            self.complain_if_pub_macro(&visibility, prev_span);\n \n             let mac_lo = self.span.lo;\n \n@@ -6039,15 +6035,15 @@ impl<'a> Parser<'a> {\n                                             |p| p.parse_token_tree())?;\n             if delim != token::Brace {\n                 if !self.eat(&token::Semi) {\n-                    let last_span = self.last_span;\n-                    self.span_err(last_span,\n+                    let prev_span = self.prev_span;\n+                    self.span_err(prev_span,\n                                   \"macros that expand to items must either \\\n                                    be surrounded with braces or followed by \\\n                                    a semicolon\");\n                 }\n             }\n \n-            let hi = self.last_span.hi;\n+            let hi = self.prev_span.hi;\n             let mac = spanned(mac_lo, hi, Mac_ { path: pth, tts: tts });\n             let item = self.mk_item(lo, hi, id, ItemKind::Mac(mac), visibility, attrs);\n             return Ok(Some(item));\n@@ -6057,8 +6053,8 @@ impl<'a> Parser<'a> {\n         match visibility {\n             Visibility::Inherited => {}\n             _ => {\n-                let last_span = self.last_span;\n-                return Err(self.span_fatal(last_span, \"unmatched visibility `pub`\"));\n+                let prev_span = self.prev_span;\n+                return Err(self.span_fatal(prev_span, \"unmatched visibility `pub`\"));\n             }\n         }\n \n@@ -6089,7 +6085,7 @@ impl<'a> Parser<'a> {\n                 rename: rename,\n                 id: ast::DUMMY_NODE_ID\n             };\n-            let hi = this.last_span.hi;\n+            let hi = this.prev_span.hi;\n             Ok(spanned(lo, hi, node))\n         })\n     }\n@@ -6134,7 +6130,7 @@ impl<'a> Parser<'a> {\n                 // `foo::bar` or `foo::bar as baz`\n                 let rename = self.parse_rename()?.\n                                   unwrap_or(prefix.segments.last().unwrap().identifier);\n-                Ok(P(spanned(lo, self.last_span.hi, ViewPathSimple(rename, prefix))))\n+                Ok(P(spanned(lo, self.prev_span.hi, ViewPathSimple(rename, prefix))))\n             }\n         }\n     }\n@@ -6182,7 +6178,7 @@ impl<'a> Parser<'a> {\n     pub fn parse_str(&mut self) -> PResult<'a, (InternedString, StrStyle)> {\n         match self.parse_optional_str() {\n             Some((s, style, suf)) => {\n-                let sp = self.last_span;\n+                let sp = self.prev_span;\n                 self.expect_no_suffix(sp, \"string literal\", suf);\n                 Ok((s, style))\n             }"}, {"sha": "c16b7d29594115ab960eadfce94068a694ccede6", "filename": "src/libsyntax_ext/asm.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax_ext%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3543a0f6020fb16860f471e8651fa05f5709e83a/src%2Flibsyntax_ext%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fasm.rs?ref=3543a0f6020fb16860f471e8651fa05f5709e83a", "patch": "@@ -122,7 +122,7 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt,\n \n                     let (constraint, _str_style) = panictry!(p.parse_str());\n \n-                    let span = p.last_span;\n+                    let span = p.prev_span;\n \n                     panictry!(p.expect(&token::OpenDelim(token::Paren)));\n                     let out = panictry!(p.parse_expr());\n@@ -167,9 +167,9 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt,\n                     let (constraint, _str_style) = panictry!(p.parse_str());\n \n                     if constraint.starts_with(\"=\") {\n-                        cx.span_err(p.last_span, \"input operand constraint contains '='\");\n+                        cx.span_err(p.prev_span, \"input operand constraint contains '='\");\n                     } else if constraint.starts_with(\"+\") {\n-                        cx.span_err(p.last_span, \"input operand constraint contains '+'\");\n+                        cx.span_err(p.prev_span, \"input operand constraint contains '+'\");\n                     }\n \n                     panictry!(p.expect(&token::OpenDelim(token::Paren)));\n@@ -189,9 +189,9 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt,\n                     let (s, _str_style) = panictry!(p.parse_str());\n \n                     if OPTIONS.iter().any(|&opt| s == opt) {\n-                        cx.span_warn(p.last_span, \"expected a clobber, found an option\");\n+                        cx.span_warn(p.prev_span, \"expected a clobber, found an option\");\n                     } else if s.starts_with(\"{\") || s.ends_with(\"}\") {\n-                        cx.span_err(p.last_span, \"clobber should not be surrounded by braces\");\n+                        cx.span_err(p.prev_span, \"clobber should not be surrounded by braces\");\n                     }\n \n                     clobs.push(s);\n@@ -209,7 +209,7 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt,\n                 } else if option == \"intel\" {\n                     dialect = AsmDialect::Intel;\n                 } else {\n-                    cx.span_warn(p.last_span, \"unrecognized option\");\n+                    cx.span_warn(p.prev_span, \"unrecognized option\");\n                 }\n \n                 if p.token == token::Comma {"}]}