{"sha": "a961e6785c7ed33a532bb6172ae0c95f44db5726", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE5NjFlNjc4NWM3ZWQzM2E1MzJiYjYxNzJhZTBjOTVmNDRkYjU3MjY=", "commit": {"author": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2021-01-13T21:28:57Z"}, "committer": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2021-01-14T03:10:36Z"}, "message": "Set tokens on AST node in `collect_tokens`\n\nA new `HasTokens` trait is introduced, which is used to move logic from\nthe callers of `collect_tokens` into the body of `collect_tokens`.\n\nIn addition to reducing duplication, this paves the way for PR #80689,\nwhich needs to perform additional logic during token collection.", "tree": {"sha": "dc59d2e6fa8795734ec9cedb16dcd09b53ae338f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dc59d2e6fa8795734ec9cedb16dcd09b53ae338f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a961e6785c7ed33a532bb6172ae0c95f44db5726", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE7J9Gc3TfBwj2K399tAh+UQ6YsWQFAl//ti0ACgkQtAh+UQ6Y\nsWTb4RAAjNiaStZAJsXEK0q9rMTkbGHKNlYwxqMQj7VO7HIu6tEANys9ZvcJ0GCf\nQnDtPP2BH0rYdP6D+7d2JupOWHPZ8uUhSOS/es/ERyQLnLZFrh2eJelIlhfWPhcT\nVkDrLPmEeEwIi5uUHFRxLYuptx+A/f9I/yP0iONbWjRii1n/8nyyHm3+TxXgDh7U\nGv8YyCgJh6/0pQTB1nsJSpj4+pDlHzkxVcFm9C3lVXQCPcZWIIJ//SPJ6lagjEr2\nduFaHVasyJO8asiX8ooMHuBnLsiVbP537sl1QqAvaMsUCLErO+X14rNzp3jBrxaf\nNUYz5CfnRY+X/AhYc/Ws49jI7t4wVzUOwBKxjeeqmXbq/gwrw1GFCJaJt820BVYk\n4iaiItT5BR2bF7I1Z8GCezn7Usdo2S1kdUdeUkKmOUYfpijf4WXyuzwhMg1WDclJ\nQqIHjRKCiuIQUE9PtMDmQHLB5UZGMWjGzh1A/gbjz4loKj+34ZiUewwUFEqy0ytM\nBmkBwTUut6LSLDVkXBmHNoRSmM3qRDQJws0nDFvsX5g2VedaGQ8pniRTrBPTtlLv\n/8eYVW4iwR2rsRoysRL26h3flCXIA0d/xnifnFp5xV7pCb/FA6qfRY5YTh44oa5I\n2pKk0AFhRRtLW9n56IFFdh0tPTlVtDNzNCnUKgo4usCX0RSUlJs=\n=F7ZO\n-----END PGP SIGNATURE-----", "payload": "tree dc59d2e6fa8795734ec9cedb16dcd09b53ae338f\nparent 9bc8b00b4a4e38ccbc3aeec2c123538973c67eba\nauthor Aaron Hill <aa1ronham@gmail.com> 1610573337 -0500\ncommitter Aaron Hill <aa1ronham@gmail.com> 1610593836 -0500\n\nSet tokens on AST node in `collect_tokens`\n\nA new `HasTokens` trait is introduced, which is used to move logic from\nthe callers of `collect_tokens` into the body of `collect_tokens`.\n\nIn addition to reducing duplication, this paves the way for PR #80689,\nwhich needs to perform additional logic during token collection.\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a961e6785c7ed33a532bb6172ae0c95f44db5726", "html_url": "https://github.com/rust-lang/rust/commit/a961e6785c7ed33a532bb6172ae0c95f44db5726", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a961e6785c7ed33a532bb6172ae0c95f44db5726/comments", "author": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9bc8b00b4a4e38ccbc3aeec2c123538973c67eba", "url": "https://api.github.com/repos/rust-lang/rust/commits/9bc8b00b4a4e38ccbc3aeec2c123538973c67eba", "html_url": "https://github.com/rust-lang/rust/commit/9bc8b00b4a4e38ccbc3aeec2c123538973c67eba"}], "stats": {"total": 248, "additions": 101, "deletions": 147}, "files": [{"sha": "e3ef386b5e625287ef7d0517fdff07eb14494940", "filename": "compiler/rustc_ast/src/ast.rs", "status": "modified", "additions": 66, "deletions": 10, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -916,16 +916,6 @@ impl Stmt {\n         }\n     }\n \n-    pub fn set_tokens(&mut self, tokens: Option<LazyTokenStream>) {\n-        match self.kind {\n-            StmtKind::Local(ref mut local) => local.tokens = tokens,\n-            StmtKind::Item(ref mut item) => item.tokens = tokens,\n-            StmtKind::Expr(ref mut expr) | StmtKind::Semi(ref mut expr) => expr.tokens = tokens,\n-            StmtKind::Empty => {}\n-            StmtKind::MacCall(ref mut mac) => mac.tokens = tokens,\n-        }\n-    }\n-\n     pub fn has_trailing_semicolon(&self) -> bool {\n         match &self.kind {\n             StmtKind::Semi(_) => true,\n@@ -2881,3 +2871,69 @@ impl TryFrom<ItemKind> for ForeignItemKind {\n }\n \n pub type ForeignItem = Item<ForeignItemKind>;\n+\n+pub trait HasTokens {\n+    /// Called by `Parser::collect_tokens` to store the collected\n+    /// tokens inside an AST node\n+    fn finalize_tokens(&mut self, tokens: LazyTokenStream);\n+}\n+\n+impl<T: HasTokens + 'static> HasTokens for P<T> {\n+    fn finalize_tokens(&mut self, tokens: LazyTokenStream) {\n+        (**self).finalize_tokens(tokens);\n+    }\n+}\n+\n+impl<T: HasTokens> HasTokens for Option<T> {\n+    fn finalize_tokens(&mut self, tokens: LazyTokenStream) {\n+        if let Some(inner) = self {\n+            inner.finalize_tokens(tokens);\n+        }\n+    }\n+}\n+\n+impl HasTokens for Attribute {\n+    fn finalize_tokens(&mut self, tokens: LazyTokenStream) {\n+        match &mut self.kind {\n+            AttrKind::Normal(_, attr_tokens) => {\n+                if attr_tokens.is_none() {\n+                    *attr_tokens = Some(tokens);\n+                }\n+            }\n+            AttrKind::DocComment(..) => {\n+                panic!(\"Called finalize_tokens on doc comment attr {:?}\", self)\n+            }\n+        }\n+    }\n+}\n+\n+impl HasTokens for Stmt {\n+    fn finalize_tokens(&mut self, tokens: LazyTokenStream) {\n+        let stmt_tokens = match self.kind {\n+            StmtKind::Local(ref mut local) => &mut local.tokens,\n+            StmtKind::Item(ref mut item) => &mut item.tokens,\n+            StmtKind::Expr(ref mut expr) | StmtKind::Semi(ref mut expr) => &mut expr.tokens,\n+            StmtKind::Empty => return,\n+            StmtKind::MacCall(ref mut mac) => &mut mac.tokens,\n+        };\n+        if stmt_tokens.is_none() {\n+            *stmt_tokens = Some(tokens);\n+        }\n+    }\n+}\n+\n+macro_rules! derive_has_tokens {\n+    ($($ty:path),*) => { $(\n+        impl HasTokens for $ty {\n+            fn finalize_tokens(&mut self, tokens: LazyTokenStream) {\n+                if self.tokens.is_none() {\n+                    self.tokens = Some(tokens);\n+                }\n+            }\n+        }\n+    )* }\n+}\n+\n+derive_has_tokens! {\n+    Item, Expr, Ty, AttrItem, Visibility, Path, Block, Pat\n+}"}, {"sha": "1b26fb3337043dc29845035817c11b4aa10bd12c", "filename": "compiler/rustc_parse/src/parser/attr.rs", "status": "modified", "additions": 4, "deletions": 12, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -89,7 +89,7 @@ impl<'a> Parser<'a> {\n             inner_parse_policy, self.token\n         );\n         let lo = self.token.span;\n-        let ((item, style, span), tokens) = self.collect_tokens(|this| {\n+        self.collect_tokens(|this| {\n             if this.eat(&token::Pound) {\n                 let style = if this.eat(&token::Not) {\n                     ast::AttrStyle::Inner\n@@ -107,15 +107,13 @@ impl<'a> Parser<'a> {\n                     this.error_on_forbidden_inner_attr(attr_sp, inner_parse_policy);\n                 }\n \n-                Ok((item, style, attr_sp))\n+                Ok(attr::mk_attr_from_item(item, None, style, attr_sp))\n             } else {\n                 let token_str = pprust::token_to_string(&this.token);\n                 let msg = &format!(\"expected `#`, found `{}`\", token_str);\n                 Err(this.struct_span_err(this.token.span, msg))\n             }\n-        })?;\n-\n-        Ok(attr::mk_attr_from_item(item, tokens, style, span))\n+        })\n     }\n \n     pub(super) fn error_on_forbidden_inner_attr(&self, attr_sp: Span, policy: InnerAttrPolicy<'_>) {\n@@ -165,13 +163,7 @@ impl<'a> Parser<'a> {\n                 let args = this.parse_attr_args()?;\n                 Ok(ast::AttrItem { path, args, tokens: None })\n             };\n-            if capture_tokens {\n-                let (mut item, tokens) = self.collect_tokens(do_parse)?;\n-                item.tokens = tokens;\n-                item\n-            } else {\n-                do_parse(self)?\n-            }\n+            if capture_tokens { self.collect_tokens(do_parse) } else { do_parse(self) }?\n         })\n     }\n "}, {"sha": "6db415ead415c22ca34d1556bde48f5c211cf294", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 4, "deletions": 16, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -472,7 +472,8 @@ impl<'a> Parser<'a> {\n     /// Parses a prefix-unary-operator expr.\n     fn parse_prefix_expr(&mut self, attrs: Option<AttrVec>) -> PResult<'a, P<Expr>> {\n         let attrs = self.parse_or_use_outer_attributes(attrs)?;\n-        self.maybe_collect_tokens(super::attr::maybe_needs_tokens(&attrs), |this| {\n+        let needs_tokens = super::attr::maybe_needs_tokens(&attrs);\n+        let do_parse = |this: &mut Parser<'a>| {\n             let lo = this.token.span;\n             // Note: when adding new unary operators, don't forget to adjust TokenKind::can_begin_expr()\n             let (hi, ex) = match this.token.uninterpolate().kind {\n@@ -488,7 +489,8 @@ impl<'a> Parser<'a> {\n                 _ => return this.parse_dot_or_call_expr(Some(attrs)),\n             }?;\n             Ok(this.mk_expr(lo.to(hi), ex, attrs))\n-        })\n+        };\n+        if needs_tokens { self.collect_tokens(do_parse) } else { do_parse(self) }\n     }\n \n     fn parse_prefix_expr_common(&mut self, lo: Span) -> PResult<'a, (Span, P<Expr>)> {\n@@ -1125,20 +1127,6 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    fn maybe_collect_tokens(\n-        &mut self,\n-        needs_tokens: bool,\n-        f: impl FnOnce(&mut Self) -> PResult<'a, P<Expr>>,\n-    ) -> PResult<'a, P<Expr>> {\n-        if needs_tokens {\n-            let (mut expr, tokens) = self.collect_tokens(f)?;\n-            expr.tokens = tokens;\n-            Ok(expr)\n-        } else {\n-            f(self)\n-        }\n-    }\n-\n     fn parse_lit_expr(&mut self, attrs: AttrVec) -> PResult<'a, P<Expr>> {\n         let lo = self.token.span;\n         match self.parse_opt_lit() {"}, {"sha": "810ae61307c1950ec590a9e917a26509c3189369", "filename": "compiler/rustc_parse/src/parser/item.rs", "status": "modified", "additions": 1, "deletions": 13, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -125,19 +125,7 @@ impl<'a> Parser<'a> {\n             item\n         };\n \n-        let (mut item, tokens) = if needs_tokens {\n-            let (item, tokens) = self.collect_tokens(parse_item)?;\n-            (item, tokens)\n-        } else {\n-            (parse_item(self)?, None)\n-        };\n-        if let Some(item) = &mut item {\n-            // If we captured tokens during parsing (due to encountering an `NtItem`),\n-            // use those instead\n-            if item.tokens.is_none() {\n-                item.tokens = tokens;\n-            }\n-        }\n+        let item = if needs_tokens { self.collect_tokens(parse_item) } else { parse_item(self) }?;\n \n         self.unclosed_delims.append(&mut unclosed_delims);\n         Ok(item)"}, {"sha": "5d7ea5b8d578e3733bd5fd4021817691c487f1ca", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -19,8 +19,8 @@ use rustc_ast::token::{self, DelimToken, Token, TokenKind};\n use rustc_ast::tokenstream::{self, DelimSpan, LazyTokenStream, Spacing};\n use rustc_ast::tokenstream::{CreateTokenStream, TokenStream, TokenTree, TreeAndSpacing};\n use rustc_ast::DUMMY_NODE_ID;\n-use rustc_ast::{self as ast, AnonConst, AttrStyle, AttrVec, Const, CrateSugar, Extern, Unsafe};\n-use rustc_ast::{Async, Expr, ExprKind, MacArgs, MacDelimiter, Mutability, StrLit};\n+use rustc_ast::{self as ast, AnonConst, AttrStyle, AttrVec, Const, CrateSugar, Extern, HasTokens};\n+use rustc_ast::{Async, Expr, ExprKind, MacArgs, MacDelimiter, Mutability, StrLit, Unsafe};\n use rustc_ast::{Visibility, VisibilityKind};\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n@@ -1234,10 +1234,10 @@ impl<'a> Parser<'a> {\n     /// This restriction shouldn't be an issue in practice,\n     /// since this function is used to record the tokens for\n     /// a parsed AST item, which always has matching delimiters.\n-    pub fn collect_tokens<R>(\n+    pub fn collect_tokens<R: HasTokens>(\n         &mut self,\n         f: impl FnOnce(&mut Self) -> PResult<'a, R>,\n-    ) -> PResult<'a, (R, Option<LazyTokenStream>)> {\n+    ) -> PResult<'a, R> {\n         let start_token = (self.token.clone(), self.token_spacing);\n         let cursor_snapshot = TokenCursor {\n             frame: self.token_cursor.frame.clone(),\n@@ -1249,7 +1249,7 @@ impl<'a> Parser<'a> {\n             append_unglued_token: self.token_cursor.append_unglued_token.clone(),\n         };\n \n-        let ret = f(self)?;\n+        let mut ret = f(self)?;\n \n         // Produces a `TokenStream` on-demand. Using `cursor_snapshot`\n         // and `num_calls`, we can reconstruct the `TokenStream` seen\n@@ -1319,7 +1319,8 @@ impl<'a> Parser<'a> {\n             trailing_semi: false,\n             append_unglued_token: self.token_cursor.append_unglued_token.clone(),\n         };\n-        Ok((ret, Some(LazyTokenStream::new(lazy_impl))))\n+        ret.finalize_tokens(LazyTokenStream::new(lazy_impl));\n+        Ok(ret)\n     }\n \n     /// `::{` or `::*`"}, {"sha": "97d0c0d8745832805718068cf40358ea34408298", "filename": "compiler/rustc_parse/src/parser/nonterminal.rs", "status": "modified", "additions": 18, "deletions": 81, "changes": 99, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -99,80 +99,34 @@ impl<'a> Parser<'a> {\n         // we always capture tokens for any `Nonterminal` which needs them.\n         Ok(match kind {\n             NonterminalKind::Item => match self.collect_tokens(|this| this.parse_item())? {\n-                (Some(mut item), tokens) => {\n-                    // If we captured tokens during parsing (due to outer attributes),\n-                    // use those.\n-                    if item.tokens.is_none() {\n-                        item.tokens = tokens;\n-                    }\n-                    token::NtItem(item)\n-                }\n-                (None, _) => {\n+                Some(item) => token::NtItem(item),\n+                None => {\n                     return Err(self.struct_span_err(self.token.span, \"expected an item keyword\"));\n                 }\n             },\n             NonterminalKind::Block => {\n-                let (mut block, tokens) = self.collect_tokens(|this| this.parse_block())?;\n-                // We have have eaten an NtBlock, which could already have tokens\n-                if block.tokens.is_none() {\n-                    block.tokens = tokens;\n-                }\n-                token::NtBlock(block)\n+                token::NtBlock(self.collect_tokens(|this| this.parse_block())?)\n             }\n-            NonterminalKind::Stmt => {\n-                let (stmt, tokens) = self.collect_tokens(|this| this.parse_stmt())?;\n-                match stmt {\n-                    Some(mut s) => {\n-                        if s.tokens().is_none() {\n-                            s.set_tokens(tokens);\n-                        }\n-                        token::NtStmt(s)\n-                    }\n-                    None => {\n-                        return Err(self.struct_span_err(self.token.span, \"expected a statement\"));\n-                    }\n+            NonterminalKind::Stmt => match self.collect_tokens(|this| this.parse_stmt())? {\n+                Some(s) => token::NtStmt(s),\n+                None => {\n+                    return Err(self.struct_span_err(self.token.span, \"expected a statement\"));\n                 }\n-            }\n+            },\n             NonterminalKind::Pat2018 { .. } | NonterminalKind::Pat2021 { .. } => {\n-                let (mut pat, tokens) = self.collect_tokens(|this| match kind {\n+                token::NtPat(self.collect_tokens(|this| match kind {\n                     NonterminalKind::Pat2018 { .. } => this.parse_pat(None),\n                     NonterminalKind::Pat2021 { .. } => {\n                         this.parse_top_pat(GateOr::Yes, RecoverComma::No)\n                     }\n                     _ => unreachable!(),\n-                })?;\n-                // We have have eaten an NtPat, which could already have tokens\n-                if pat.tokens.is_none() {\n-                    pat.tokens = tokens;\n-                }\n-                token::NtPat(pat)\n-            }\n-            NonterminalKind::Expr => {\n-                let (mut expr, tokens) = self.collect_tokens(|this| this.parse_expr())?;\n-                // If we captured tokens during parsing (due to outer attributes),\n-                // use those.\n-                if expr.tokens.is_none() {\n-                    expr.tokens = tokens;\n-                }\n-                token::NtExpr(expr)\n+                })?)\n             }\n+            NonterminalKind::Expr => token::NtExpr(self.collect_tokens(|this| this.parse_expr())?),\n             NonterminalKind::Literal => {\n-                let (mut lit, tokens) =\n-                    self.collect_tokens(|this| this.parse_literal_maybe_minus())?;\n-                // We have have eaten a nonterminal, which  could already have tokens\n-                if lit.tokens.is_none() {\n-                    lit.tokens = tokens;\n-                }\n-                token::NtLiteral(lit)\n-            }\n-            NonterminalKind::Ty => {\n-                let (mut ty, tokens) = self.collect_tokens(|this| this.parse_ty())?;\n-                // We have an eaten an NtTy, which could already have tokens\n-                if ty.tokens.is_none() {\n-                    ty.tokens = tokens;\n-                }\n-                token::NtTy(ty)\n+                token::NtLiteral(self.collect_tokens(|this| this.parse_literal_maybe_minus())?)\n             }\n+            NonterminalKind::Ty => token::NtTy(self.collect_tokens(|this| this.parse_ty())?),\n             // this could be handled like a token, since it is one\n             NonterminalKind::Ident => {\n                 if let Some((ident, is_raw)) = get_macro_ident(&self.token) {\n@@ -185,32 +139,15 @@ impl<'a> Parser<'a> {\n                 }\n             }\n             NonterminalKind::Path => {\n-                let (mut path, tokens) =\n-                    self.collect_tokens(|this| this.parse_path(PathStyle::Type))?;\n-                // We have have eaten an NtPath, which could already have tokens\n-                if path.tokens.is_none() {\n-                    path.tokens = tokens;\n-                }\n-                token::NtPath(path)\n+                token::NtPath(self.collect_tokens(|this| this.parse_path(PathStyle::Type))?)\n             }\n             NonterminalKind::Meta => {\n-                let (mut attr, tokens) = self.collect_tokens(|this| this.parse_attr_item(false))?;\n-                // We may have eaten a nonterminal, which could already have tokens\n-                if attr.tokens.is_none() {\n-                    attr.tokens = tokens;\n-                }\n-                token::NtMeta(P(attr))\n+                token::NtMeta(P(self.collect_tokens(|this| this.parse_attr_item(false))?))\n             }\n             NonterminalKind::TT => token::NtTT(self.parse_token_tree()),\n-            NonterminalKind::Vis => {\n-                let (mut vis, tokens) =\n-                    self.collect_tokens(|this| this.parse_visibility(FollowedByType::Yes))?;\n-                // We may have etan an `NtVis`, which could already have tokens\n-                if vis.tokens.is_none() {\n-                    vis.tokens = tokens;\n-                }\n-                token::NtVis(vis)\n-            }\n+            NonterminalKind::Vis => token::NtVis(\n+                self.collect_tokens(|this| this.parse_visibility(FollowedByType::Yes))?,\n+            ),\n             NonterminalKind::Lifetime => {\n                 if self.check_lifetime() {\n                     token::NtLifetime(self.expect_lifetime().ident)"}, {"sha": "641b29227db98d246adb8b6a481e2fed2c9490f1", "filename": "compiler/rustc_parse/src/parser/stmt.rs", "status": "modified", "additions": 1, "deletions": 9, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a961e6785c7ed33a532bb6172ae0c95f44db5726/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs?ref=a961e6785c7ed33a532bb6172ae0c95f44db5726", "patch": "@@ -89,15 +89,7 @@ impl<'a> Parser<'a> {\n         };\n \n         let stmt = if has_attrs {\n-            let (mut stmt, tokens) = self.collect_tokens(parse_stmt_inner)?;\n-            if let Some(stmt) = &mut stmt {\n-                // If we already have tokens (e.g. due to encounting an `NtStmt`),\n-                // use those instead.\n-                if stmt.tokens().is_none() {\n-                    stmt.set_tokens(tokens);\n-                }\n-            }\n-            stmt\n+            self.collect_tokens(parse_stmt_inner)?\n         } else {\n             parse_stmt_inner(self)?\n         };"}]}