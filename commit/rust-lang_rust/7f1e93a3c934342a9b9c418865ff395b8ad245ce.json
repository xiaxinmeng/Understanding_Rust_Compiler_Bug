{"sha": "7f1e93a3c934342a9b9c418865ff395b8ad245ce", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdmMWU5M2EzYzkzNDM0MmE5YjljNDE4ODY1ZmYzOTViOGFkMjQ1Y2U=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-07T13:42:53Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-07T13:42:53Z"}, "message": "Refactoring subtree_source", "tree": {"sha": "f31ec549b70a9260939c0fc8c0d4bb6433133a0d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f31ec549b70a9260939c0fc8c0d4bb6433133a0d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7f1e93a3c934342a9b9c418865ff395b8ad245ce", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7f1e93a3c934342a9b9c418865ff395b8ad245ce", "html_url": "https://github.com/rust-lang/rust/commit/7f1e93a3c934342a9b9c418865ff395b8ad245ce", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7f1e93a3c934342a9b9c418865ff395b8ad245ce/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "aac9dfa46418603940ab2333cfea2190d9464d9e", "url": "https://api.github.com/repos/rust-lang/rust/commits/aac9dfa46418603940ab2333cfea2190d9464d9e", "html_url": "https://github.com/rust-lang/rust/commit/aac9dfa46418603940ab2333cfea2190d9464d9e"}], "stats": {"total": 750, "additions": 386, "deletions": 364}, "files": [{"sha": "38d3ec7e131c0f7f3e29be34638b39bc730af50f", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=7f1e93a3c934342a9b9c418865ff395b8ad245ce", "patch": "@@ -15,10 +15,12 @@ macro_rules! impl_froms {\n     }\n }\n \n-mod tt_cursor;\n+// mod tt_cursor;\n mod mbe_parser;\n mod mbe_expander;\n mod syntax_bridge;\n+mod tt_cursor;\n+mod subtree_source;\n \n use ra_syntax::SmolStr;\n "}, {"sha": "8f5ce4ed5f76e9b40704a78142198e89ac4eddd3", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "added", "additions": 352, "deletions": 0, "changes": 352, "blob_url": "https://github.com/rust-lang/rust/blob/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=7f1e93a3c934342a9b9c418865ff395b8ad245ce", "patch": "@@ -0,0 +1,352 @@\n+use ra_parser::{TokenSource};\n+use ra_syntax::{classify_literal, SmolStr, SyntaxKind, SyntaxKind::*};\n+\n+#[derive(Debug)]\n+struct TtToken {\n+    pub kind: SyntaxKind,\n+    pub is_joint_to_next: bool,\n+    pub text: SmolStr,\n+    pub n_tokens: usize,\n+}\n+\n+/// SubtreeSourceQuerier let outside to query internal tokens as string\n+pub(crate) struct SubtreeSourceQuerier<'a> {\n+    src: &'a SubtreeTokenSource<'a>,\n+}\n+\n+impl<'a> SubtreeSourceQuerier<'a> {\n+    pub(crate) fn token(&self, uidx: usize) -> (SyntaxKind, &SmolStr) {\n+        let tkn = &self.src.tokens[uidx];\n+        (tkn.kind, &tkn.text)\n+    }\n+}\n+\n+pub(crate) struct SubtreeTokenSource<'a> {\n+    tt_pos: usize,\n+    tokens: Vec<TtToken>,\n+    subtree: &'a tt::Subtree,\n+}\n+\n+impl<'a> SubtreeTokenSource<'a> {\n+    pub fn new(subtree: &tt::Subtree) -> SubtreeTokenSource {\n+        SubtreeTokenSource { tokens: TtTokenBuilder::build(subtree), tt_pos: 0, subtree }\n+    }\n+\n+    pub fn advance(&mut self, curr: usize, skip_first_delimiter: bool) {\n+        if skip_first_delimiter {\n+            self.tt_pos += 1;\n+        }\n+\n+        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n+        // It is because TtToken is not One to One mapping to tt::Token\n+        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n+        // * One to One =>  ident, single char punch\n+        // * Many to One => `tt::TokenTree::SubTree`\n+        // * One to Many => multibyte punct\n+        //\n+        // Such that we cannot simpliy advance the cursor\n+        // We have to bump it one by one\n+        let mut pos = 0;\n+        while pos < curr {\n+            pos += self.bump(&self.subtree.token_trees[pos]);\n+        }\n+    }\n+\n+    pub fn querier(&self) -> SubtreeSourceQuerier {\n+        SubtreeSourceQuerier { src: self }\n+    }\n+\n+    fn count(&self, tt: &tt::TokenTree) -> usize {\n+        assert!(!self.tokens.is_empty());\n+        TtTokenBuilder::count_tt_tokens(tt, None)\n+    }\n+\n+    pub(crate) fn bump(&mut self, tt: &tt::TokenTree) -> usize {\n+        let cur = &self.tokens[self.tt_pos];\n+        let n_tokens = cur.n_tokens;\n+        self.tt_pos += self.count(tt);\n+        n_tokens\n+    }\n+\n+    pub(crate) fn bump_n(\n+        &mut self,\n+        n_tokens: usize,\n+        mut token_pos: usize,\n+    ) -> (usize, Vec<&tt::TokenTree>) {\n+        let mut res = vec![];\n+        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n+        // It is because TtToken is not One to One mapping to tt::Token\n+        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n+        // * One to One =>  ident, single char punch\n+        // * Many to One => `tt::TokenTree::SubTree`\n+        // * One to Many => multibyte punct\n+        //\n+        // Such that we cannot simpliy advance the cursor\n+        // We have to bump it one by one\n+        let next_pos = self.tt_pos + n_tokens;\n+        let old_token_pos = token_pos;\n+\n+        while self.tt_pos < next_pos {\n+            let current = &self.subtree.token_trees[token_pos];\n+            let n = self.bump(current);\n+            res.extend((0..n).map(|i| &self.subtree.token_trees[token_pos + i]));\n+            token_pos += n;\n+        }\n+\n+        (token_pos - old_token_pos, res)\n+    }\n+}\n+\n+impl<'a> TokenSource for SubtreeTokenSource<'a> {\n+    fn token_kind(&self, pos: usize) -> SyntaxKind {\n+        if let Some(tok) = self.tokens.get(self.tt_pos + pos) {\n+            tok.kind\n+        } else {\n+            SyntaxKind::EOF\n+        }\n+    }\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n+        self.tokens[self.tt_pos + pos].is_joint_to_next\n+    }\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n+        self.tokens[self.tt_pos + pos].text == *kw\n+    }\n+}\n+\n+struct TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    iter: itertools::MultiPeek<I>,\n+}\n+\n+// helper function\n+fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n+    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n+        return Some(pp);\n+    }\n+    None\n+}\n+\n+impl<'a, I> TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    pub fn new(iter: I) -> Self {\n+        TokenPeek { iter: itertools::multipeek(iter) }\n+    }\n+\n+    pub fn next(&mut self) -> Option<&tt::TokenTree> {\n+        self.iter.next()\n+    }\n+\n+    fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n+        if p.spacing != tt::Spacing::Joint {\n+            return None;\n+        }\n+\n+        self.iter.reset_peek();\n+        let p1 = to_punct(self.iter.peek()?)?;\n+        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n+    }\n+\n+    fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n+        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n+            if !last_joint {\n+                None\n+            } else {\n+                let p2 = to_punct(*self.iter.peek()?)?;\n+                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n+            }\n+        })\n+    }\n+}\n+\n+struct TtTokenBuilder {\n+    tokens: Vec<TtToken>,\n+}\n+\n+impl TtTokenBuilder {\n+    fn build(sub: &tt::Subtree) -> Vec<TtToken> {\n+        let mut res = TtTokenBuilder { tokens: vec![] };\n+        res.convert_subtree(sub);\n+        res.tokens\n+    }\n+\n+    fn convert_subtree(&mut self, sub: &tt::Subtree) {\n+        self.push_delim(sub.delimiter, false);\n+        let mut peek = TokenPeek::new(sub.token_trees.iter());\n+        while let Some(tt) = peek.iter.next() {\n+            self.convert_tt(tt, &mut peek);\n+        }\n+        self.push_delim(sub.delimiter, true)\n+    }\n+\n+    fn convert_tt<'b, I>(&mut self, tt: &tt::TokenTree, iter: &mut TokenPeek<'b, I>)\n+    where\n+        I: Iterator<Item = &'b tt::TokenTree>,\n+    {\n+        match tt {\n+            tt::TokenTree::Leaf(token) => self.convert_token(token, iter),\n+            tt::TokenTree::Subtree(sub) => self.convert_subtree(sub),\n+        }\n+    }\n+\n+    fn convert_token<'b, I>(&mut self, token: &tt::Leaf, iter: &mut TokenPeek<'b, I>)\n+    where\n+        I: Iterator<Item = &'b tt::TokenTree>,\n+    {\n+        let tok = match token {\n+            tt::Leaf::Literal(l) => TtToken {\n+                kind: classify_literal(&l.text).unwrap().kind,\n+                is_joint_to_next: false,\n+                text: l.text.clone(),\n+                n_tokens: 1,\n+            },\n+            tt::Leaf::Punct(p) => {\n+                if let Some((kind, is_joint_to_next, text, size)) =\n+                    Self::convert_multi_char_punct(p, iter)\n+                {\n+                    for _ in 0..size - 1 {\n+                        iter.next();\n+                    }\n+\n+                    TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n+                } else {\n+                    let kind = match p.char {\n+                        // lexer may produce combpund tokens for these ones\n+                        '.' => DOT,\n+                        ':' => COLON,\n+                        '=' => EQ,\n+                        '!' => EXCL,\n+                        '-' => MINUS,\n+                        c => SyntaxKind::from_char(c).unwrap(),\n+                    };\n+                    let text = {\n+                        let mut buf = [0u8; 4];\n+                        let s: &str = p.char.encode_utf8(&mut buf);\n+                        SmolStr::new(s)\n+                    };\n+                    TtToken {\n+                        kind,\n+                        is_joint_to_next: p.spacing == tt::Spacing::Joint,\n+                        text,\n+                        n_tokens: 1,\n+                    }\n+                }\n+            }\n+            tt::Leaf::Ident(ident) => {\n+                let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n+                TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n+            }\n+        };\n+        self.tokens.push(tok)\n+    }\n+\n+    fn convert_multi_char_punct<'b, I>(\n+        p: &tt::Punct,\n+        iter: &mut TokenPeek<'b, I>,\n+    ) -> Option<(SyntaxKind, bool, &'static str, usize)>\n+    where\n+        I: Iterator<Item = &'b tt::TokenTree>,\n+    {\n+        if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n+            if let Some((kind, text)) = match m {\n+                ('<', '<', '=') => Some((SHLEQ, \"<<=\")),\n+                ('>', '>', '=') => Some((SHREQ, \">>=\")),\n+                ('.', '.', '.') => Some((DOTDOTDOT, \"...\")),\n+                ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n+                _ => None,\n+            } {\n+                return Some((kind, is_joint_to_next, text, 3));\n+            }\n+        }\n+\n+        if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n+            if let Some((kind, text)) = match m {\n+                ('<', '<') => Some((SHL, \"<<\")),\n+                ('>', '>') => Some((SHR, \">>\")),\n+\n+                ('|', '|') => Some((PIPEPIPE, \"||\")),\n+                ('&', '&') => Some((AMPAMP, \"&&\")),\n+                ('%', '=') => Some((PERCENTEQ, \"%=\")),\n+                ('*', '=') => Some((STAREQ, \"*=\")),\n+                ('/', '=') => Some((SLASHEQ, \"/=\")),\n+                ('^', '=') => Some((CARETEQ, \"^=\")),\n+\n+                ('&', '=') => Some((AMPEQ, \"&=\")),\n+                ('|', '=') => Some((PIPEEQ, \"|=\")),\n+                ('-', '=') => Some((MINUSEQ, \"-=\")),\n+                ('+', '=') => Some((PLUSEQ, \"+=\")),\n+                ('>', '=') => Some((GTEQ, \">=\")),\n+                ('<', '=') => Some((LTEQ, \"<=\")),\n+\n+                ('-', '>') => Some((THIN_ARROW, \"->\")),\n+                ('!', '=') => Some((NEQ, \"!=\")),\n+                ('=', '>') => Some((FAT_ARROW, \"=>\")),\n+                ('=', '=') => Some((EQEQ, \"==\")),\n+                ('.', '.') => Some((DOTDOT, \"..\")),\n+                (':', ':') => Some((COLONCOLON, \"::\")),\n+\n+                _ => None,\n+            } {\n+                return Some((kind, is_joint_to_next, text, 2));\n+            }\n+        }\n+\n+        None\n+    }\n+\n+    fn push_delim(&mut self, d: tt::Delimiter, closing: bool) {\n+        let (kinds, texts) = match d {\n+            tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n+            tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n+            tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n+            tt::Delimiter::None => return,\n+        };\n+        let idx = closing as usize;\n+        let kind = kinds[idx];\n+        let text = &texts[idx..texts.len() - (1 - idx)];\n+        let tok = TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 };\n+        self.tokens.push(tok)\n+    }\n+\n+    fn skip_sibling_leaf(leaf: &tt::Leaf, iter: &mut std::slice::Iter<tt::TokenTree>) {\n+        if let tt::Leaf::Punct(p) = leaf {\n+            let mut peek = TokenPeek::new(iter);\n+            if let Some((_, _, _, size)) = TtTokenBuilder::convert_multi_char_punct(p, &mut peek) {\n+                for _ in 0..size - 1 {\n+                    peek.next();\n+                }\n+            }\n+        }\n+    }\n+\n+    fn count_tt_tokens(\n+        tt: &tt::TokenTree,\n+        iter: Option<&mut std::slice::Iter<tt::TokenTree>>,\n+    ) -> usize {\n+        match tt {\n+            tt::TokenTree::Subtree(sub_tree) => {\n+                let mut iter = sub_tree.token_trees.iter();\n+                let mut count = match sub_tree.delimiter {\n+                    tt::Delimiter::None => 0,\n+                    _ => 2,\n+                };\n+\n+                while let Some(tt) = iter.next() {\n+                    count += Self::count_tt_tokens(&tt, Some(&mut iter));\n+                }\n+                count\n+            }\n+\n+            tt::TokenTree::Leaf(leaf) => {\n+                iter.map(|iter| {\n+                    Self::skip_sibling_leaf(leaf, iter);\n+                });\n+\n+                1\n+            }\n+        }\n+    }\n+}"}, {"sha": "102bba3417b86fe35df916fc2b288f742449bcdc", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 21, "deletions": 241, "changes": 262, "blob_url": "https://github.com/rust-lang/rust/blob/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=7f1e93a3c934342a9b9c418865ff395b8ad245ce", "patch": "@@ -1,9 +1,11 @@\n-use ra_parser::{TokenSource, TreeSink, ParseError};\n+use ra_parser::{TreeSink, ParseError};\n use ra_syntax::{\n     AstNode, SyntaxNode, TextRange, SyntaxKind, SmolStr, SyntaxTreeBuilder, TreeArc, SyntaxElement,\n-    ast, SyntaxKind::*, TextUnit, classify_literal\n+    ast, SyntaxKind::*, TextUnit\n };\n \n+use crate::subtree_source::{SubtreeTokenSource, SubtreeSourceQuerier};\n+\n /// Maps `tt::TokenId` to the relative range of the original token.\n #[derive(Default)]\n pub struct TokenMap {\n@@ -22,8 +24,8 @@ pub fn ast_to_token_tree(ast: &ast::TokenTree) -> Option<(tt::Subtree, TokenMap)\n \n /// Parses the token tree (result of macro expansion) as a sequence of items\n pub fn token_tree_to_ast_item_list(tt: &tt::Subtree) -> TreeArc<ast::SourceFile> {\n-    let token_source = TtTokenSource::new(tt);\n-    let mut tree_sink = TtTreeSink::new(&token_source.tokens);\n+    let token_source = SubtreeTokenSource::new(tt);\n+    let mut tree_sink = TtTreeSink::new(token_source.querier());\n     ra_parser::parse(&token_source, &mut tree_sink);\n     let syntax = tree_sink.inner.finish();\n     ast::SourceFile::cast(&syntax).unwrap().to_owned()\n@@ -103,243 +105,19 @@ fn convert_tt(\n     Some(res)\n }\n \n-#[derive(Debug)]\n-pub(crate) struct TtTokenSource {\n-    pub tokens: Vec<TtToken>,\n-}\n-\n-#[derive(Debug)]\n-pub(crate) struct TtToken {\n-    pub kind: SyntaxKind,\n-    pub is_joint_to_next: bool,\n-    pub text: SmolStr,\n-    pub n_tokens: usize,\n-}\n-\n-// Some helper functions\n-fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n-    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n-        return Some(pp);\n-    }\n-    None\n-}\n-\n-pub(crate) struct TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    iter: itertools::MultiPeek<I>,\n-}\n-\n-impl<'a, I> TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    pub fn new(iter: I) -> Self {\n-        TokenPeek { iter: itertools::multipeek(iter) }\n-    }\n-\n-    pub fn next(&mut self) -> Option<&tt::TokenTree> {\n-        self.iter.next()\n-    }\n-\n-    fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n-        if p.spacing != tt::Spacing::Joint {\n-            return None;\n-        }\n-\n-        self.iter.reset_peek();\n-        let p1 = to_punct(self.iter.peek()?)?;\n-        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n-    }\n-\n-    fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n-        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n-            if !last_joint {\n-                None\n-            } else {\n-                let p2 = to_punct(*self.iter.peek()?)?;\n-                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n-            }\n-        })\n-    }\n-}\n-\n-impl TtTokenSource {\n-    pub fn new(tt: &tt::Subtree) -> TtTokenSource {\n-        let mut res = TtTokenSource { tokens: Vec::new() };\n-        res.convert_subtree(tt);\n-        res\n-    }\n-    fn convert_subtree(&mut self, sub: &tt::Subtree) {\n-        self.push_delim(sub.delimiter, false);\n-        let mut peek = TokenPeek::new(sub.token_trees.iter());\n-        while let Some(tt) = peek.iter.next() {\n-            self.convert_tt(tt, &mut peek);\n-        }\n-        self.push_delim(sub.delimiter, true)\n-    }\n-\n-    fn convert_tt<'a, I>(&mut self, tt: &tt::TokenTree, iter: &mut TokenPeek<'a, I>)\n-    where\n-        I: Iterator<Item = &'a tt::TokenTree>,\n-    {\n-        match tt {\n-            tt::TokenTree::Leaf(token) => self.convert_token(token, iter),\n-            tt::TokenTree::Subtree(sub) => self.convert_subtree(sub),\n-        }\n-    }\n-\n-    fn convert_token<'a, I>(&mut self, token: &tt::Leaf, iter: &mut TokenPeek<'a, I>)\n-    where\n-        I: Iterator<Item = &'a tt::TokenTree>,\n-    {\n-        let tok = match token {\n-            tt::Leaf::Literal(l) => TtToken {\n-                kind: classify_literal(&l.text).unwrap().kind,\n-                is_joint_to_next: false,\n-                text: l.text.clone(),\n-                n_tokens: 1,\n-            },\n-            tt::Leaf::Punct(p) => {\n-                if let Some((kind, is_joint_to_next, text, size)) =\n-                    Self::convert_multi_char_punct(p, iter)\n-                {\n-                    for _ in 0..size - 1 {\n-                        iter.next();\n-                    }\n-\n-                    TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n-                } else {\n-                    let kind = match p.char {\n-                        // lexer may produce combpund tokens for these ones\n-                        '.' => DOT,\n-                        ':' => COLON,\n-                        '=' => EQ,\n-                        '!' => EXCL,\n-                        '-' => MINUS,\n-                        c => SyntaxKind::from_char(c).unwrap(),\n-                    };\n-                    let text = {\n-                        let mut buf = [0u8; 4];\n-                        let s: &str = p.char.encode_utf8(&mut buf);\n-                        SmolStr::new(s)\n-                    };\n-                    TtToken {\n-                        kind,\n-                        is_joint_to_next: p.spacing == tt::Spacing::Joint,\n-                        text,\n-                        n_tokens: 1,\n-                    }\n-                }\n-            }\n-            tt::Leaf::Ident(ident) => {\n-                let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n-                TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n-            }\n-        };\n-        self.tokens.push(tok)\n-    }\n-\n-    pub(crate) fn convert_multi_char_punct<'a, I>(\n-        p: &tt::Punct,\n-        iter: &mut TokenPeek<'a, I>,\n-    ) -> Option<(SyntaxKind, bool, &'static str, usize)>\n-    where\n-        I: Iterator<Item = &'a tt::TokenTree>,\n-    {\n-        if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n-            if let Some((kind, text)) = match m {\n-                ('<', '<', '=') => Some((SHLEQ, \"<<=\")),\n-                ('>', '>', '=') => Some((SHREQ, \">>=\")),\n-                ('.', '.', '.') => Some((DOTDOTDOT, \"...\")),\n-                ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n-                _ => None,\n-            } {\n-                return Some((kind, is_joint_to_next, text, 3));\n-            }\n-        }\n-\n-        if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n-            if let Some((kind, text)) = match m {\n-                ('<', '<') => Some((SHL, \"<<\")),\n-                ('>', '>') => Some((SHR, \">>\")),\n-\n-                ('|', '|') => Some((PIPEPIPE, \"||\")),\n-                ('&', '&') => Some((AMPAMP, \"&&\")),\n-                ('%', '=') => Some((PERCENTEQ, \"%=\")),\n-                ('*', '=') => Some((STAREQ, \"*=\")),\n-                ('/', '=') => Some((SLASHEQ, \"/=\")),\n-                ('^', '=') => Some((CARETEQ, \"^=\")),\n-\n-                ('&', '=') => Some((AMPEQ, \"&=\")),\n-                ('|', '=') => Some((PIPEEQ, \"|=\")),\n-                ('-', '=') => Some((MINUSEQ, \"-=\")),\n-                ('+', '=') => Some((PLUSEQ, \"+=\")),\n-                ('>', '=') => Some((GTEQ, \">=\")),\n-                ('<', '=') => Some((LTEQ, \"<=\")),\n-\n-                ('-', '>') => Some((THIN_ARROW, \"->\")),\n-                ('!', '=') => Some((NEQ, \"!=\")),\n-                ('=', '>') => Some((FAT_ARROW, \"=>\")),\n-                ('=', '=') => Some((EQEQ, \"==\")),\n-                ('.', '.') => Some((DOTDOT, \"..\")),\n-                (':', ':') => Some((COLONCOLON, \"::\")),\n-\n-                _ => None,\n-            } {\n-                return Some((kind, is_joint_to_next, text, 2));\n-            }\n-        }\n-\n-        None\n-    }\n-\n-    fn push_delim(&mut self, d: tt::Delimiter, closing: bool) {\n-        let (kinds, texts) = match d {\n-            tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n-            tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n-            tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n-            tt::Delimiter::None => return,\n-        };\n-        let idx = closing as usize;\n-        let kind = kinds[idx];\n-        let text = &texts[idx..texts.len() - (1 - idx)];\n-        let tok = TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 };\n-        self.tokens.push(tok)\n-    }\n-}\n-\n-impl TokenSource for TtTokenSource {\n-    fn token_kind(&self, pos: usize) -> SyntaxKind {\n-        if let Some(tok) = self.tokens.get(pos) {\n-            tok.kind\n-        } else {\n-            SyntaxKind::EOF\n-        }\n-    }\n-    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n-        self.tokens[pos].is_joint_to_next\n-    }\n-    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n-        self.tokens[pos].text == *kw\n-    }\n-}\n-\n-#[derive(Default)]\n struct TtTreeSink<'a> {\n     buf: String,\n-    tokens: &'a [TtToken],\n+    src_querier: SubtreeSourceQuerier<'a>,\n     text_pos: TextUnit,\n     token_pos: usize,\n     inner: SyntaxTreeBuilder,\n }\n \n impl<'a> TtTreeSink<'a> {\n-    fn new(tokens: &'a [TtToken]) -> TtTreeSink {\n+    fn new(src_querier: SubtreeSourceQuerier<'a>) -> TtTreeSink {\n         TtTreeSink {\n             buf: String::new(),\n-            tokens,\n+            src_querier,\n             text_pos: 0.into(),\n             token_pos: 0,\n             inner: SyntaxTreeBuilder::default(),\n@@ -350,7 +128,7 @@ impl<'a> TtTreeSink<'a> {\n impl<'a> TreeSink for TtTreeSink<'a> {\n     fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         for _ in 0..n_tokens {\n-            self.buf += self.tokens[self.token_pos].text.as_str();\n+            self.buf += self.src_querier.token(self.token_pos).1;\n             self.token_pos += 1;\n         }\n         self.text_pos += TextUnit::of_str(&self.buf);\n@@ -394,21 +172,23 @@ mod tests {\n             \"#,\n         );\n         let expansion = expand(&rules, \"literals!(foo)\");\n-        let tt_src = TtTokenSource::new(&expansion);\n+        let tt_src = SubtreeTokenSource::new(&expansion);\n+\n+        let query = tt_src.querier();\n \n         // [{]\n         // [let] [a] [=] ['c'] [;]\n-        assert_eq!(tt_src.tokens[1 + 3].text, \"'c'\");\n-        assert_eq!(tt_src.tokens[1 + 3].kind, CHAR);\n+        assert_eq!(query.token(1 + 3).1, \"'c'\");\n+        assert_eq!(query.token(1 + 3).0, CHAR);\n         // [let] [c] [=] [1000] [;]\n-        assert_eq!(tt_src.tokens[1 + 5 + 3].text, \"1000\");\n-        assert_eq!(tt_src.tokens[1 + 5 + 3].kind, INT_NUMBER);\n+        assert_eq!(query.token(1 + 5 + 3).1, \"1000\");\n+        assert_eq!(query.token(1 + 5 + 3).0, INT_NUMBER);\n         // [let] [f] [=] [12E+99_f64] [;]\n-        assert_eq!(tt_src.tokens[1 + 10 + 3].text, \"12E+99_f64\");\n-        assert_eq!(tt_src.tokens[1 + 10 + 3].kind, FLOAT_NUMBER);\n+        assert_eq!(query.token(1 + 10 + 3).1, \"12E+99_f64\");\n+        assert_eq!(query.token(1 + 10 + 3).0, FLOAT_NUMBER);\n \n         // [let] [s] [=] [\"rust1\"] [;]\n-        assert_eq!(tt_src.tokens[1 + 15 + 3].text, \"\\\"rust1\\\"\");\n-        assert_eq!(tt_src.tokens[1 + 15 + 3].kind, STRING);\n+        assert_eq!(query.token(1 + 15 + 3).1, \"\\\"rust1\\\"\");\n+        assert_eq!(query.token(1 + 15 + 3).0, STRING);\n     }\n }"}, {"sha": "52e07259929cae1caa35ad1fd508ad675ed7b88d", "filename": "crates/ra_mbe/src/tt_cursor.rs", "status": "modified", "additions": 10, "deletions": 122, "changes": 132, "blob_url": "https://github.com/rust-lang/rust/blob/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f1e93a3c934342a9b9c418865ff395b8ad245ce/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs?ref=7f1e93a3c934342a9b9c418865ff395b8ad245ce", "patch": "@@ -1,116 +1,17 @@\n use crate::ParseError;\n-use crate::syntax_bridge::{TtTokenSource, TtToken, TokenPeek};\n+use crate::subtree_source::SubtreeTokenSource;\n+\n use ra_parser::{TokenSource, TreeSink};\n \n use ra_syntax::{\n     SyntaxKind\n };\n \n-struct TtCursorTokenSource {\n-    tt_pos: usize,\n-    inner: TtTokenSource,\n-}\n-\n-impl TtCursorTokenSource {\n-    fn new(subtree: &tt::Subtree, curr: usize) -> TtCursorTokenSource {\n-        let mut res = TtCursorTokenSource { inner: TtTokenSource::new(subtree), tt_pos: 1 };\n-\n-        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n-        // It is because TtToken is not One to One mapping to tt::Token\n-        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n-        // * One to One =>  ident, single char punch\n-        // * Many to One => `tt::TokenTree::SubTree`\n-        // * One to Many => multibyte punct\n-        //\n-        // Such that we cannot simpliy advance the cursor\n-        // We have to bump it one by one\n-        let mut pos = 0;\n-        while pos < curr {\n-            pos += res.bump(&subtree.token_trees[pos]);\n-        }\n-\n-        res\n-    }\n-\n-    fn skip_sibling_leaf(&self, leaf: &tt::Leaf, iter: &mut std::slice::Iter<tt::TokenTree>) {\n-        if let tt::Leaf::Punct(p) = leaf {\n-            let mut peek = TokenPeek::new(iter);\n-            if let Some((_, _, _, size)) = TtTokenSource::convert_multi_char_punct(p, &mut peek) {\n-                for _ in 0..size - 1 {\n-                    peek.next();\n-                }\n-            }\n-        }\n-    }\n-\n-    fn count_tt_tokens(\n-        &self,\n-        tt: &tt::TokenTree,\n-        iter: Option<&mut std::slice::Iter<tt::TokenTree>>,\n-    ) -> usize {\n-        assert!(!self.inner.tokens.is_empty());\n-\n-        match tt {\n-            tt::TokenTree::Subtree(sub_tree) => {\n-                let mut iter = sub_tree.token_trees.iter();\n-                let mut count = match sub_tree.delimiter {\n-                    tt::Delimiter::None => 0,\n-                    _ => 2,\n-                };\n-\n-                while let Some(tt) = iter.next() {\n-                    count += self.count_tt_tokens(&tt, Some(&mut iter));\n-                }\n-                count\n-            }\n-\n-            tt::TokenTree::Leaf(leaf) => {\n-                iter.map(|iter| {\n-                    self.skip_sibling_leaf(leaf, iter);\n-                });\n-\n-                1\n-            }\n-        }\n-    }\n-\n-    fn count(&self, tt: &tt::TokenTree) -> usize {\n-        self.count_tt_tokens(tt, None)\n-    }\n-\n-    fn bump(&mut self, tt: &tt::TokenTree) -> usize {\n-        let cur = self.current().unwrap();\n-        let n_tokens = cur.n_tokens;\n-        self.tt_pos += self.count(tt);\n-        n_tokens\n-    }\n-\n-    fn current(&self) -> Option<&TtToken> {\n-        self.inner.tokens.get(self.tt_pos)\n-    }\n-}\n-\n-impl TokenSource for TtCursorTokenSource {\n-    fn token_kind(&self, pos: usize) -> SyntaxKind {\n-        if let Some(tok) = self.inner.tokens.get(self.tt_pos + pos) {\n-            tok.kind\n-        } else {\n-            SyntaxKind::EOF\n-        }\n-    }\n-    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n-        self.inner.tokens[self.tt_pos + pos].is_joint_to_next\n-    }\n-    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n-        self.inner.tokens[self.tt_pos + pos].text == *kw\n-    }\n-}\n-\n-struct TtCursorTokenSink {\n+struct SubtreeTokenSink {\n     token_pos: usize,\n }\n \n-impl TreeSink for TtCursorTokenSink {\n+impl TreeSink for SubtreeTokenSink {\n     fn token(&mut self, _kind: SyntaxKind, n_tokens: u8) {\n         self.token_pos += n_tokens as usize;\n     }\n@@ -201,24 +102,10 @@ impl<'a> TtCursor<'a> {\n     fn eat_parse_result(\n         &mut self,\n         parsed_token: usize,\n-        src: &mut TtCursorTokenSource,\n+        src: &mut SubtreeTokenSource,\n     ) -> Option<tt::TokenTree> {\n-        let mut res = vec![];\n-\n-        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n-        // It is because TtToken is not One to One mapping to tt::Token\n-        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n-        // * One to One =>  ident, single char punch\n-        // * Many to One => `tt::TokenTree::SubTree`\n-        // * One to Many => multibyte punct\n-        //\n-        // Such that we cannot simpliy advance the cursor\n-        // We have to bump it one by one\n-        let next_pos = src.tt_pos + parsed_token;\n-        while src.tt_pos < next_pos {\n-            let n = src.bump(self.current().unwrap());\n-            res.extend((0..n).map(|_| self.eat().unwrap()));\n-        }\n+        let (adv, res) = src.bump_n(parsed_token, self.pos);\n+        self.pos += adv;\n \n         let res: Vec<_> = res.into_iter().cloned().collect();\n \n@@ -236,8 +123,9 @@ impl<'a> TtCursor<'a> {\n     where\n         F: FnOnce(&dyn TokenSource, &mut dyn TreeSink),\n     {\n-        let mut src = TtCursorTokenSource::new(self.subtree, self.pos);\n-        let mut sink = TtCursorTokenSink { token_pos: 0 };\n+        let mut src = SubtreeTokenSource::new(self.subtree);\n+        src.advance(self.pos, true);\n+        let mut sink = SubtreeTokenSink { token_pos: 0 };\n \n         f(&src, &mut sink);\n "}]}