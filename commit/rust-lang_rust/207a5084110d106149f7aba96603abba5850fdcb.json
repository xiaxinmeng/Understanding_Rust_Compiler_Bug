{"sha": "207a5084110d106149f7aba96603abba5850fdcb", "node_id": "MDY6Q29tbWl0NzI0NzEyOjIwN2E1MDg0MTEwZDEwNjE0OWY3YWJhOTY2MDNhYmJhNTg1MGZkY2I=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-12-04T01:07:48Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-12-04T01:07:48Z"}, "message": "auto merge of #18770 : pczarn/rust/hash_map-explicit-shrinking, r=Gankro\n\nPart of enforcing capacity-related conventions, for #18424, the collections reform.\r\n\r\nImplements `fn shrink_to_fit` for HashMap.\r\nThe `reserve` method now takes as an argument the *extra* space to reserve.", "tree": {"sha": "68f4bbf8f42480ac9d323d8b9c786596ff08f528", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/68f4bbf8f42480ac9d323d8b9c786596ff08f528"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/207a5084110d106149f7aba96603abba5850fdcb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/207a5084110d106149f7aba96603abba5850fdcb", "html_url": "https://github.com/rust-lang/rust/commit/207a5084110d106149f7aba96603abba5850fdcb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/207a5084110d106149f7aba96603abba5850fdcb/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "daa0745886c2382c37d5d345f4c5b1b8f7b9a387", "url": "https://api.github.com/repos/rust-lang/rust/commits/daa0745886c2382c37d5d345f4c5b1b8f7b9a387", "html_url": "https://github.com/rust-lang/rust/commit/daa0745886c2382c37d5d345f4c5b1b8f7b9a387"}, {"sha": "b82624bf205e83555d7764d9f849fbfd30df0083", "url": "https://api.github.com/repos/rust-lang/rust/commits/b82624bf205e83555d7764d9f849fbfd30df0083", "html_url": "https://github.com/rust-lang/rust/commit/b82624bf205e83555d7764d9f849fbfd30df0083"}], "stats": {"total": 398, "additions": 255, "deletions": 143}, "files": [{"sha": "17e6becdfaffa60c0518976a2b46b18747143933", "filename": "src/libstd/collections/hash/map.rs", "status": "modified", "additions": 209, "deletions": 139, "changes": 348, "blob_url": "https://github.com/rust-lang/rust/blob/207a5084110d106149f7aba96603abba5850fdcb/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/207a5084110d106149f7aba96603abba5850fdcb/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs?ref=207a5084110d106149f7aba96603abba5850fdcb", "patch": "@@ -23,7 +23,7 @@ use hash::{Hash, Hasher, RandomSipHasher};\n use iter::{mod, Iterator, IteratorExt, FromIterator, Extend};\n use kinds::Sized;\n use mem::{mod, replace};\n-use num::UnsignedInt;\n+use num::{Int, UnsignedInt};\n use ops::{Deref, Index, IndexMut};\n use option::{Some, None, Option};\n use result::{Result, Ok, Err};\n@@ -41,45 +41,53 @@ use super::table::{\n     SafeHash\n };\n \n-// FIXME(conventions): update capacity management to match other collections (no auto-shrink)\n-\n const INITIAL_LOG2_CAP: uint = 5;\n pub const INITIAL_CAPACITY: uint = 1 << INITIAL_LOG2_CAP; // 2^5\n \n /// The default behavior of HashMap implements a load factor of 90.9%.\n-/// This behavior is characterized by the following conditions:\n+/// This behavior is characterized by the following condition:\n ///\n-/// - if size > 0.909 * capacity: grow\n-/// - if size < 0.25 * capacity: shrink (if this won't bring capacity lower\n-///   than the minimum)\n+/// - if size > 0.909 * capacity: grow the map\n #[deriving(Clone)]\n-struct DefaultResizePolicy {\n-    /// Doubled minimal capacity. The capacity must never drop below\n-    /// the minimum capacity. (The check happens before the capacity\n-    /// is potentially halved.)\n-    minimum_capacity2: uint\n-}\n+struct DefaultResizePolicy;\n \n impl DefaultResizePolicy {\n-    fn new(new_capacity: uint) -> DefaultResizePolicy {\n-        DefaultResizePolicy {\n-            minimum_capacity2: new_capacity << 1\n-        }\n+    fn new() -> DefaultResizePolicy {\n+        DefaultResizePolicy\n     }\n \n     #[inline]\n-    fn capacity_range(&self, new_size: uint) -> (uint, uint) {\n-        // Here, we are rephrasing the logic by specifying the ranges:\n+    fn min_capacity(&self, usable_size: uint) -> uint {\n+        // Here, we are rephrasing the logic by specifying the lower limit\n+        // on capacity:\n         //\n-        // - if `size * 1.1 < cap < size * 4`: don't resize\n-        // - if `cap < minimum_capacity * 2`: don't shrink\n-        // - otherwise, resize accordingly\n-        ((new_size * 11) / 10, max(new_size << 2, self.minimum_capacity2))\n+        // - if `cap < size * 1.1`: grow the map\n+        usable_size * 11 / 10\n     }\n \n+    /// An inverse of `min_capacity`, approximately.\n     #[inline]\n-    fn reserve(&mut self, new_capacity: uint) {\n-        self.minimum_capacity2 = new_capacity << 1;\n+    fn usable_capacity(&self, cap: uint) -> uint {\n+        // As the number of entries approaches usable capacity,\n+        // min_capacity(size) must be smaller than the internal capacity,\n+        // so that the map is not resized:\n+        // `min_capacity(usable_capacity(x)) <= x`.\n+        // The lef-hand side can only be smaller due to flooring by integer\n+        // division.\n+        //\n+        // This doesn't have to be checked for overflow since allocation size\n+        // in bytes will overflow earlier than multiplication by 10.\n+        cap * 10 / 11\n+    }\n+}\n+\n+#[test]\n+fn test_resize_policy() {\n+    use prelude::*;\n+    let rp = DefaultResizePolicy;\n+    for n in range(0u, 1000) {\n+        assert!(rp.min_capacity(rp.usable_capacity(n)) <= n);\n+        assert!(rp.usable_capacity(rp.min_capacity(n)) <= n);\n     }\n }\n \n@@ -282,7 +290,6 @@ pub struct HashMap<K, V, H = RandomSipHasher> {\n \n     table: RawTable<K, V>,\n \n-    // We keep this at the end since it might as well have tail padding.\n     resize_policy: DefaultResizePolicy,\n }\n \n@@ -529,7 +536,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     pub fn with_hasher(hasher: H) -> HashMap<K, V, H> {\n         HashMap {\n             hasher:        hasher,\n-            resize_policy: DefaultResizePolicy::new(INITIAL_CAPACITY),\n+            resize_policy: DefaultResizePolicy::new(),\n             table:         RawTable::new(0),\n         }\n     }\n@@ -554,20 +561,39 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     /// ```\n     #[inline]\n     pub fn with_capacity_and_hasher(capacity: uint, hasher: H) -> HashMap<K, V, H> {\n-        let cap = max(INITIAL_CAPACITY, capacity).next_power_of_two();\n+        let resize_policy = DefaultResizePolicy::new();\n+        let min_cap = max(INITIAL_CAPACITY, resize_policy.min_capacity(capacity));\n+        let internal_cap = min_cap.checked_next_power_of_two().expect(\"capacity overflow\");\n+        assert!(internal_cap >= capacity, \"capacity overflow\");\n         HashMap {\n             hasher:        hasher,\n-            resize_policy: DefaultResizePolicy::new(cap),\n-            table:         RawTable::new(cap),\n+            resize_policy: resize_policy,\n+            table:         RawTable::new(internal_cap),\n         }\n     }\n \n-    /// The hashtable will never try to shrink below this size. You can use\n-    /// this function to reduce reallocations if your hashtable frequently\n-    /// grows and shrinks by large amounts.\n+    /// Returns the number of elements the map can hold without reallocating.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let map: HashMap<int, int> = HashMap::with_capacity(100);\n+    /// assert!(map.capacity() >= 100);\n+    /// ```\n+    #[inline]\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn capacity(&self) -> uint {\n+        self.resize_policy.usable_capacity(self.table.capacity())\n+    }\n+\n+    /// Reserves capacity for at least `additional` more elements to be inserted\n+    /// in the `HashMap`. The collection may reserve more space to avoid\n+    /// frequent reallocations.\n+    ///\n+    /// # Panics\n     ///\n-    /// This function has no effect on the operational semantics of the\n-    /// hashtable, only on performance.\n+    /// Panics if the new allocation size overflows `uint`.\n     ///\n     /// # Example\n     ///\n@@ -576,13 +602,18 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     /// let mut map: HashMap<&str, int> = HashMap::new();\n     /// map.reserve(10);\n     /// ```\n-    pub fn reserve(&mut self, new_minimum_capacity: uint) {\n-        let cap = max(INITIAL_CAPACITY, new_minimum_capacity).next_power_of_two();\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn reserve(&mut self, additional: uint) {\n+        let new_size = self.len().checked_add(additional).expect(\"capacity overflow\");\n+        let min_cap = self.resize_policy.min_capacity(new_size);\n \n-        self.resize_policy.reserve(cap);\n+        // An invalid value shouldn't make us run out of space. This includes\n+        // an overflow check.\n+        assert!(new_size <= min_cap);\n \n-        if self.table.capacity() < cap {\n-            self.resize(cap);\n+        if self.table.capacity() < min_cap {\n+            let new_capacity = max(min_cap.next_power_of_two(), INITIAL_CAPACITY);\n+            self.resize(new_capacity);\n         }\n     }\n \n@@ -601,94 +632,106 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n             return;\n         }\n \n-        if new_capacity < old_table.capacity() {\n-            // Shrink the table. Naive algorithm for resizing:\n-            for (h, k, v) in old_table.into_iter() {\n-                self.insert_hashed_nocheck(h, k, v);\n-            }\n-        } else {\n-            // Grow the table.\n-            // Specialization of the other branch.\n-            let mut bucket = Bucket::first(&mut old_table);\n-\n-            // \"So a few of the first shall be last: for many be called,\n-            // but few chosen.\"\n-            //\n-            // We'll most likely encounter a few buckets at the beginning that\n-            // have their initial buckets near the end of the table. They were\n-            // placed at the beginning as the probe wrapped around the table\n-            // during insertion. We must skip forward to a bucket that won't\n-            // get reinserted too early and won't unfairly steal others spot.\n-            // This eliminates the need for robin hood.\n-            loop {\n-                bucket = match bucket.peek() {\n-                    Full(full) => {\n-                        if full.distance() == 0 {\n-                            // This bucket occupies its ideal spot.\n-                            // It indicates the start of another \"cluster\".\n-                            bucket = full.into_bucket();\n-                            break;\n-                        }\n-                        // Leaving this bucket in the last cluster for later.\n-                        full.into_bucket()\n-                    }\n-                    Empty(b) => {\n-                        // Encountered a hole between clusters.\n-                        b.into_bucket()\n-                    }\n-                };\n-                bucket.next();\n-            }\n+        // Grow the table.\n+        // Specialization of the other branch.\n+        let mut bucket = Bucket::first(&mut old_table);\n \n-            // This is how the buckets might be laid out in memory:\n-            // ($ marks an initialized bucket)\n-            //  ________________\n-            // |$$$_$$$$$$_$$$$$|\n-            //\n-            // But we've skipped the entire initial cluster of buckets\n-            // and will continue iteration in this order:\n-            //  ________________\n-            //     |$$$$$$_$$$$$\n-            //                  ^ wrap around once end is reached\n-            //  ________________\n-            //  $$$_____________|\n-            //    ^ exit once table.size == 0\n-            loop {\n-                bucket = match bucket.peek() {\n-                    Full(bucket) => {\n-                        let h = bucket.hash();\n-                        let (b, k, v) = bucket.take();\n-                        self.insert_hashed_ordered(h, k, v);\n-                        {\n-                            let t = b.table(); // FIXME \"lifetime too short\".\n-                            if t.size() == 0 { break }\n-                        };\n-                        b.into_bucket()\n+        // \"So a few of the first shall be last: for many be called,\n+        // but few chosen.\"\n+        //\n+        // We'll most likely encounter a few buckets at the beginning that\n+        // have their initial buckets near the end of the table. They were\n+        // placed at the beginning as the probe wrapped around the table\n+        // during insertion. We must skip forward to a bucket that won't\n+        // get reinserted too early and won't unfairly steal others spot.\n+        // This eliminates the need for robin hood.\n+        loop {\n+            bucket = match bucket.peek() {\n+                Full(full) => {\n+                    if full.distance() == 0 {\n+                        // This bucket occupies its ideal spot.\n+                        // It indicates the start of another \"cluster\".\n+                        bucket = full.into_bucket();\n+                        break;\n                     }\n-                    Empty(b) => b.into_bucket()\n-                };\n-                bucket.next();\n-            }\n+                    // Leaving this bucket in the last cluster for later.\n+                    full.into_bucket()\n+                }\n+                Empty(b) => {\n+                    // Encountered a hole between clusters.\n+                    b.into_bucket()\n+                }\n+            };\n+            bucket.next();\n+        }\n+\n+        // This is how the buckets might be laid out in memory:\n+        // ($ marks an initialized bucket)\n+        //  ________________\n+        // |$$$_$$$$$$_$$$$$|\n+        //\n+        // But we've skipped the entire initial cluster of buckets\n+        // and will continue iteration in this order:\n+        //  ________________\n+        //     |$$$$$$_$$$$$\n+        //                  ^ wrap around once end is reached\n+        //  ________________\n+        //  $$$_____________|\n+        //    ^ exit once table.size == 0\n+        loop {\n+            bucket = match bucket.peek() {\n+                Full(bucket) => {\n+                    let h = bucket.hash();\n+                    let (b, k, v) = bucket.take();\n+                    self.insert_hashed_ordered(h, k, v);\n+                    {\n+                        let t = b.table(); // FIXME \"lifetime too short\".\n+                        if t.size() == 0 { break }\n+                    };\n+                    b.into_bucket()\n+                }\n+                Empty(b) => b.into_bucket()\n+            };\n+            bucket.next();\n         }\n \n         assert_eq!(self.table.size(), old_size);\n     }\n \n-    /// Performs any necessary resize operations, such that there's space for\n-    /// new_size elements.\n-    fn make_some_room(&mut self, new_size: uint) {\n-        let (grow_at, shrink_at) = self.resize_policy.capacity_range(new_size);\n-        let cap = self.table.capacity();\n+    /// Shrinks the capacity of the map as much as possible. It will drop\n+    /// down as much as possible while maintaining the internal rules\n+    /// and possibly leaving some space in accordance with the resize policy.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map: HashMap<int, int> = HashMap::with_capacity(100);\n+    /// map.insert(1, 2);\n+    /// map.insert(3, 4);\n+    /// assert!(map.capacity() >= 100);\n+    /// map.shrink_to_fit();\n+    /// assert!(map.capacity() >= 2);\n+    /// ```\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn shrink_to_fit(&mut self) {\n+        let min_capacity = self.resize_policy.min_capacity(self.len());\n+        let min_capacity = max(min_capacity.next_power_of_two(), INITIAL_CAPACITY);\n \n         // An invalid value shouldn't make us run out of space.\n-        debug_assert!(grow_at >= new_size);\n+        debug_assert!(self.len() <= min_capacity);\n \n-        if cap <= grow_at {\n-            let new_capacity = max(cap << 1, INITIAL_CAPACITY);\n-            self.resize(new_capacity);\n-        } else if shrink_at <= cap {\n-            let new_capacity = cap >> 1;\n-            self.resize(new_capacity);\n+        if self.table.capacity() != min_capacity {\n+            let old_table = replace(&mut self.table, RawTable::new(min_capacity));\n+            let old_size = old_table.size();\n+\n+            // Shrink the table. Naive algorithm for resizing:\n+            for (h, k, v) in old_table.into_iter() {\n+                self.insert_hashed_nocheck(h, k, v);\n+            }\n+\n+            debug_assert_eq!(self.table.size(), old_size);\n         }\n     }\n \n@@ -775,8 +818,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n             return None\n         }\n \n-        let potential_new_size = self.table.size() - 1;\n-        self.make_some_room(potential_new_size);\n+        self.reserve(1);\n \n         match self.search_equiv_mut(k) {\n             Some(bucket) => {\n@@ -907,12 +949,8 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n \n     /// Gets the given key's corresponding entry in the map for in-place manipulation\n     pub fn entry<'a>(&'a mut self, key: K) -> Entry<'a, K, V> {\n-        // Gotta resize now, and we don't know which direction, so try both?\n-        let size = self.table.size();\n-        self.make_some_room(size + 1);\n-        if size > 0 {\n-            self.make_some_room(size - 1);\n-        }\n+        // Gotta resize now.\n+        self.reserve(1);\n \n         let hash = self.make_hash(&key);\n         search_entry_hashed(&mut self.table, hash, key)\n@@ -964,10 +1002,6 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     /// ```\n     #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n     pub fn clear(&mut self) {\n-        // Prevent reallocations from happening from now on. Makes it possible\n-        // for the map to be reused but has a downside: reserves permanently.\n-        self.resize_policy.reserve(self.table.size());\n-\n         let cap = self.table.capacity();\n         let mut buckets = Bucket::first(&mut self.table);\n \n@@ -1100,8 +1134,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n     pub fn insert(&mut self, k: K, v: V) -> Option<V> {\n         let hash = self.make_hash(&k);\n-        let potential_new_size = self.table.size() + 1;\n-        self.make_some_room(potential_new_size);\n+        self.reserve(1);\n \n         let mut retval = None;\n         self.insert_or_replace_with(hash, k, v, |_, val_ref, val| {\n@@ -1141,9 +1174,6 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n             return None\n         }\n \n-        let potential_new_size = self.table.size() - 1;\n-        self.make_some_room(potential_new_size);\n-\n         self.search_mut(k).map(|bucket| {\n             let (_k, val) = pop_internal(bucket);\n             val\n@@ -1894,7 +1924,7 @@ mod test_map {\n     }\n \n     #[test]\n-    fn test_resize_policy() {\n+    fn test_behavior_resize_policy() {\n         let mut m = HashMap::new();\n \n         assert_eq!(m.len(), 0);\n@@ -1905,7 +1935,7 @@ mod test_map {\n         m.remove(&0);\n         assert!(m.is_empty());\n         let initial_cap = m.table.capacity();\n-        m.reserve(initial_cap * 2);\n+        m.reserve(initial_cap);\n         let cap = m.table.capacity();\n \n         assert_eq!(cap, initial_cap * 2);\n@@ -1935,15 +1965,55 @@ mod test_map {\n             assert_eq!(m.table.capacity(), new_cap);\n         }\n         // A little more than one quarter full.\n-        // Shrinking starts as we remove more elements:\n+        m.shrink_to_fit();\n+        assert_eq!(m.table.capacity(), cap);\n+        // again, a little more than half full\n         for _ in range(0, cap / 2 - 1) {\n             i -= 1;\n             m.remove(&i);\n         }\n+        m.shrink_to_fit();\n \n         assert_eq!(m.len(), i);\n         assert!(!m.is_empty());\n-        assert_eq!(m.table.capacity(), cap);\n+        assert_eq!(m.table.capacity(), initial_cap);\n+    }\n+\n+    #[test]\n+    fn test_reserve_shrink_to_fit() {\n+        let mut m = HashMap::new();\n+        m.insert(0u, 0u);\n+        m.remove(&0);\n+        assert!(m.capacity() >= m.len());\n+        for i in range(0, 128) {\n+            m.insert(i, i);\n+        }\n+        m.reserve(256);\n+\n+        let usable_cap = m.capacity();\n+        for i in range(128, 128+256) {\n+            m.insert(i, i);\n+            assert_eq!(m.capacity(), usable_cap);\n+        }\n+\n+        for i in range(100, 128+256) {\n+            assert_eq!(m.remove(&i), Some(i));\n+        }\n+        m.shrink_to_fit();\n+\n+        assert_eq!(m.len(), 100);\n+        assert!(!m.is_empty());\n+        assert!(m.capacity() >= m.len());\n+\n+        for i in range(0, 100) {\n+            assert_eq!(m.remove(&i), Some(i));\n+        }\n+        m.shrink_to_fit();\n+        m.insert(0, 0);\n+\n+        assert_eq!(m.len(), 1);\n+        assert!(m.capacity() >= m.len());\n+        assert_eq!(m.remove(&0), Some(0));\n     }\n \n     #[test]"}, {"sha": "b40622171d52a2ab2c187262ddaf76e667c92eee", "filename": "src/libstd/collections/hash/set.rs", "status": "modified", "additions": 46, "deletions": 4, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/207a5084110d106149f7aba96603abba5850fdcb/src%2Flibstd%2Fcollections%2Fhash%2Fset.rs", "raw_url": "https://github.com/rust-lang/rust/raw/207a5084110d106149f7aba96603abba5850fdcb/src%2Flibstd%2Fcollections%2Fhash%2Fset.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhash%2Fset.rs?ref=207a5084110d106149f7aba96603abba5850fdcb", "patch": "@@ -25,7 +25,6 @@ use result::{Ok, Err};\n use super::map::{HashMap, Entries, MoveEntries, INITIAL_CAPACITY};\n \n // FIXME(conventions): implement BitOr, BitAnd, BitXor, and Sub\n-// FIXME(conventions): update capacity management to match other collections (no auto-shrink)\n \n \n // Future Optimization (FIXME!)\n@@ -172,7 +171,28 @@ impl<T: Eq + Hash<S>, S, H: Hasher<S>> HashSet<T, H> {\n         HashSet { map: HashMap::with_capacity_and_hasher(capacity, hasher) }\n     }\n \n-    /// Reserve space for at least `n` elements in the hash table.\n+    /// Returns the number of elements the set can hold without reallocating.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let set: HashSet<int> = HashSet::with_capacity(100);\n+    /// assert!(set.capacity() >= 100);\n+    /// ```\n+    #[inline]\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn capacity(&self) -> uint {\n+        self.map.capacity()\n+    }\n+\n+    /// Reserves capacity for at least `additional` more elements to be inserted\n+    /// in the `HashSet`. The collection may reserve more space to avoid\n+    /// frequent reallocations.\n+    ///\n+    /// # Panics\n+    ///\n+    /// Panics if the new allocation size overflows `uint`.\n     ///\n     /// # Example\n     ///\n@@ -181,8 +201,30 @@ impl<T: Eq + Hash<S>, S, H: Hasher<S>> HashSet<T, H> {\n     /// let mut set: HashSet<int> = HashSet::new();\n     /// set.reserve(10);\n     /// ```\n-    pub fn reserve(&mut self, n: uint) {\n-        self.map.reserve(n)\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn reserve(&mut self, additional: uint) {\n+        self.map.reserve(additional)\n+    }\n+\n+    /// Shrinks the capacity of the set as much as possible. It will drop\n+    /// down as much as possible while maintaining the internal rules\n+    /// and possibly leaving some space in accordance with the resize policy.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    ///\n+    /// let mut set: HashSet<int> = HashSet::with_capacity(100);\n+    /// set.insert(1);\n+    /// set.insert(2);\n+    /// assert!(set.capacity() >= 100);\n+    /// set.shrink_to_fit();\n+    /// assert!(set.capacity() >= 2);\n+    /// ```\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn shrink_to_fit(&mut self) {\n+        self.map.shrink_to_fit()\n     }\n \n     /// Deprecated: use `contains` and `BorrowFrom`."}]}