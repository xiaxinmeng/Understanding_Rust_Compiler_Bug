{"sha": "a7b35b5618da9c557a8d318aa7839a96fecb4d05", "node_id": "C_kwDOAAsO6NoAKGE3YjM1YjU2MThkYTljNTU3YThkMzE4YWE3ODM5YTk2ZmVjYjRkMDU", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-09-20T06:08:25Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-09-21T01:22:31Z"}, "message": "Overhaul `-Zmeta-stats` output.\n\nIt's now much more like the `-Zhir-stats` output.\n- Each line is preceded with `meta-stats`, which makes the provenance\n  clearer and allows filtering of the output.\n- Sections are now sorted in reverse order of size.\n- Column headings avoid the need to repeat the word \"bytes\" on every line.\n- Long numbers now have `_` separators for easier reading.\n- Consistent use of '-' within section labels, rather than a mix of '-',\n  '_', and ' '.\n\nThe code itself is shorter and easier to read thanks to:\n- the `stat` macro, which encapsulates each section's encoding, avoids\n  some boilerplate, and removes the need for some low-value comments;\n- the `stats` vector, which replaces dozens of local variables.", "tree": {"sha": "51573cef64569c65970848c19213271c992c93b4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/51573cef64569c65970848c19213271c992c93b4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a7b35b5618da9c557a8d318aa7839a96fecb4d05", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a7b35b5618da9c557a8d318aa7839a96fecb4d05", "html_url": "https://github.com/rust-lang/rust/commit/a7b35b5618da9c557a8d318aa7839a96fecb4d05", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a7b35b5618da9c557a8d318aa7839a96fecb4d05/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b7dc9341b5a57e120470f8bb0e4831bffab63c89", "url": "https://api.github.com/repos/rust-lang/rust/commits/b7dc9341b5a57e120470f8bb0e4831bffab63c89", "html_url": "https://github.com/rust-lang/rust/commit/b7dc9341b5a57e120470f8bb0e4831bffab63c89"}], "stats": {"total": 344, "additions": 142, "deletions": 202}, "files": [{"sha": "67c28461ce5cf338c75373d64c430a3709c0a388", "filename": "compiler/rustc_metadata/src/rmeta/encoder.rs", "status": "modified", "additions": 142, "deletions": 202, "changes": 344, "blob_url": "https://github.com/rust-lang/rust/blob/a7b35b5618da9c557a8d318aa7839a96fecb4d05/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a7b35b5618da9c557a8d318aa7839a96fecb4d05/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Fencoder.rs?ref=a7b35b5618da9c557a8d318aa7839a96fecb4d05", "patch": "@@ -28,6 +28,7 @@ use rustc_middle::ty::codec::TyEncoder;\n use rustc_middle::ty::fast_reject::{self, SimplifiedType, TreatParams};\n use rustc_middle::ty::query::Providers;\n use rustc_middle::ty::{self, SymbolName, Ty, TyCtxt};\n+use rustc_middle::util::common::to_readable_str;\n use rustc_serialize::{opaque, Decodable, Decoder, Encodable, Encoder};\n use rustc_session::config::CrateType;\n use rustc_session::cstore::{ForeignModule, LinkagePreference, NativeLib};\n@@ -554,78 +555,56 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n \n     fn encode_crate_root(&mut self) -> LazyValue<CrateRoot> {\n         let tcx = self.tcx;\n-        let mut i = 0;\n-        let preamble_bytes = self.position() - i;\n-\n-        // Encode the crate deps\n-        i = self.position();\n-        let crate_deps = self.encode_crate_deps();\n-        let dylib_dependency_formats = self.encode_dylib_dependency_formats();\n-        let dep_bytes = self.position() - i;\n-\n-        // Encode the lib features.\n-        i = self.position();\n-        let lib_features = self.encode_lib_features();\n-        let lib_feature_bytes = self.position() - i;\n-\n-        // Encode the stability implications.\n-        i = self.position();\n-        let stability_implications = self.encode_stability_implications();\n-        let stability_implications_bytes = self.position() - i;\n-\n-        // Encode the language items.\n-        i = self.position();\n-        let lang_items = self.encode_lang_items();\n-        let lang_items_missing = self.encode_lang_items_missing();\n-        let lang_item_bytes = self.position() - i;\n-\n-        // Encode the diagnostic items.\n-        i = self.position();\n-        let diagnostic_items = self.encode_diagnostic_items();\n-        let diagnostic_item_bytes = self.position() - i;\n-\n-        // Encode the native libraries used\n-        i = self.position();\n-        let native_libraries = self.encode_native_libraries();\n-        let native_lib_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let foreign_modules = self.encode_foreign_modules();\n-        let foreign_modules_bytes = self.position() - i;\n-\n-        // Encode DefPathTable\n-        i = self.position();\n-        self.encode_def_path_table();\n-        let def_path_table_bytes = self.position() - i;\n+        let mut stats: Vec<(&'static str, usize)> = Vec::with_capacity(32);\n+\n+        macro_rules! stat {\n+            ($label:literal, $f:expr) => {{\n+                let orig_pos = self.position();\n+                let res = $f();\n+                stats.push(($label, self.position() - orig_pos));\n+                res\n+            }};\n+        }\n+\n+        // We have already encoded some things. Get their combined size from the current position.\n+        stats.push((\"preamble\", self.position()));\n+\n+        let (crate_deps, dylib_dependency_formats) =\n+            stat!(\"dep\", || (self.encode_crate_deps(), self.encode_dylib_dependency_formats()));\n+\n+        let lib_features = stat!(\"lib-features\", || self.encode_lib_features());\n+\n+        let stability_implications =\n+            stat!(\"stability-implications\", || self.encode_stability_implications());\n+\n+        let (lang_items, lang_items_missing) = stat!(\"lang-items\", || {\n+            (self.encode_lang_items(), self.encode_lang_items_missing())\n+        });\n+\n+        let diagnostic_items = stat!(\"diagnostic-items\", || self.encode_diagnostic_items());\n+\n+        let native_libraries = stat!(\"native-libs\", || self.encode_native_libraries());\n+\n+        let foreign_modules = stat!(\"foreign-modules\", || self.encode_foreign_modules());\n+\n+        _ = stat!(\"def-path-table\", || self.encode_def_path_table());\n \n         // Encode the def IDs of traits, for rustdoc and diagnostics.\n-        i = self.position();\n-        let traits = self.encode_traits();\n-        let traits_bytes = self.position() - i;\n+        let traits = stat!(\"traits\", || self.encode_traits());\n \n         // Encode the def IDs of impls, for coherence checking.\n-        i = self.position();\n-        let impls = self.encode_impls();\n-        let impls_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let incoherent_impls = self.encode_incoherent_impls();\n-        let incoherent_impls_bytes = self.position() - i;\n-\n-        // Encode MIR.\n-        i = self.position();\n-        self.encode_mir();\n-        let mir_bytes = self.position() - i;\n-\n-        // Encode the items.\n-        i = self.position();\n-        self.encode_def_ids();\n-        self.encode_info_for_items();\n-        let item_bytes = self.position() - i;\n-\n-        // Encode the allocation index\n-        i = self.position();\n-        let interpret_alloc_index = {\n+        let impls = stat!(\"impls\", || self.encode_impls());\n+\n+        let incoherent_impls = stat!(\"incoherent-impls\", || self.encode_incoherent_impls());\n+\n+        _ = stat!(\"mir\", || self.encode_mir());\n+\n+        _ = stat!(\"items\", || {\n+            self.encode_def_ids();\n+            self.encode_info_for_items();\n+        });\n+\n+        let interpret_alloc_index = stat!(\"interpret-alloc-index\", || {\n             let mut interpret_alloc_index = Vec::new();\n             let mut n = 0;\n             trace!(\"beginning to encode alloc ids\");\n@@ -646,125 +625,90 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n                 n = new_n;\n             }\n             self.lazy_array(interpret_alloc_index)\n-        };\n-        let interpret_alloc_index_bytes = self.position() - i;\n+        });\n \n-        // Encode the proc macro data. This affects 'tables',\n-        // so we need to do this before we encode the tables.\n-        // This overwrites def_keys, so it must happen after encode_def_path_table.\n-        i = self.position();\n-        let proc_macro_data = self.encode_proc_macros();\n-        let proc_macro_data_bytes = self.position() - i;\n+        // Encode the proc macro data. This affects `tables`, so we need to do this before we\n+        // encode the tables. This overwrites def_keys, so it must happen after\n+        // encode_def_path_table.\n+        let proc_macro_data = stat!(\"proc-macro-data\", || self.encode_proc_macros());\n \n-        i = self.position();\n-        let tables = self.tables.encode(&mut self.opaque);\n-        let tables_bytes = self.position() - i;\n+        let tables = stat!(\"tables\", || self.tables.encode(&mut self.opaque));\n \n-        i = self.position();\n-        let debugger_visualizers = self.encode_debugger_visualizers();\n-        let debugger_visualizers_bytes = self.position() - i;\n+        let debugger_visualizers =\n+            stat!(\"debugger-visualizers\", || self.encode_debugger_visualizers());\n \n         // Encode exported symbols info. This is prefetched in `encode_metadata` so we encode\n         // this as late as possible to give the prefetching as much time as possible to complete.\n-        i = self.position();\n-        let exported_symbols = tcx.exported_symbols(LOCAL_CRATE);\n-        let exported_symbols = self.encode_exported_symbols(&exported_symbols);\n-        let exported_symbols_bytes = self.position() - i;\n+        let exported_symbols = stat!(\"exported-symbols\", || {\n+            self.encode_exported_symbols(&tcx.exported_symbols(LOCAL_CRATE))\n+        });\n \n-        // Encode the hygiene data,\n+        // Encode the hygiene data.\n         // IMPORTANT: this *must* be the last thing that we encode (other than `SourceMap`). The\n         // process of encoding other items (e.g. `optimized_mir`) may cause us to load data from\n         // the incremental cache. If this causes us to deserialize a `Span`, then we may load\n         // additional `SyntaxContext`s into the global `HygieneData`. Therefore, we need to encode\n         // the hygiene data last to ensure that we encode any `SyntaxContext`s that might be used.\n-        i = self.position();\n-        let (syntax_contexts, expn_data, expn_hashes) = self.encode_hygiene();\n-        let hygiene_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let def_path_hash_map = self.encode_def_path_hash_map();\n-        let def_path_hash_map_bytes = self.position() - i;\n-\n-        // Encode source_map. This needs to be done last,\n-        // since encoding `Span`s tells us which `SourceFiles` we actually\n-        // need to encode.\n-        i = self.position();\n-        let source_map = self.encode_source_map();\n-        let source_map_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let attrs = tcx.hir().krate_attrs();\n-        let has_default_lib_allocator = tcx.sess.contains_name(&attrs, sym::default_lib_allocator);\n-        let root = self.lazy(CrateRoot {\n-            name: tcx.crate_name(LOCAL_CRATE),\n-            extra_filename: tcx.sess.opts.cg.extra_filename.clone(),\n-            triple: tcx.sess.opts.target_triple.clone(),\n-            hash: tcx.crate_hash(LOCAL_CRATE),\n-            stable_crate_id: tcx.def_path_hash(LOCAL_CRATE.as_def_id()).stable_crate_id(),\n-            required_panic_strategy: tcx.required_panic_strategy(LOCAL_CRATE),\n-            panic_in_drop_strategy: tcx.sess.opts.unstable_opts.panic_in_drop,\n-            edition: tcx.sess.edition(),\n-            has_global_allocator: tcx.has_global_allocator(LOCAL_CRATE),\n-            has_panic_handler: tcx.has_panic_handler(LOCAL_CRATE),\n-            has_default_lib_allocator,\n-            proc_macro_data,\n-            debugger_visualizers,\n-            compiler_builtins: tcx.sess.contains_name(&attrs, sym::compiler_builtins),\n-            needs_allocator: tcx.sess.contains_name(&attrs, sym::needs_allocator),\n-            needs_panic_runtime: tcx.sess.contains_name(&attrs, sym::needs_panic_runtime),\n-            no_builtins: tcx.sess.contains_name(&attrs, sym::no_builtins),\n-            panic_runtime: tcx.sess.contains_name(&attrs, sym::panic_runtime),\n-            profiler_runtime: tcx.sess.contains_name(&attrs, sym::profiler_runtime),\n-            symbol_mangling_version: tcx.sess.opts.get_symbol_mangling_version(),\n-\n-            crate_deps,\n-            dylib_dependency_formats,\n-            lib_features,\n-            stability_implications,\n-            lang_items,\n-            diagnostic_items,\n-            lang_items_missing,\n-            native_libraries,\n-            foreign_modules,\n-            source_map,\n-            traits,\n-            impls,\n-            incoherent_impls,\n-            exported_symbols,\n-            interpret_alloc_index,\n-            tables,\n-            syntax_contexts,\n-            expn_data,\n-            expn_hashes,\n-            def_path_hash_map,\n+        let (syntax_contexts, expn_data, expn_hashes) = stat!(\"hygiene\", || self.encode_hygiene());\n+\n+        let def_path_hash_map = stat!(\"def-path-hash-map\", || self.encode_def_path_hash_map());\n+\n+        // Encode source_map. This needs to be done last, because encoding `Span`s tells us which\n+        // `SourceFiles` we actually need to encode.\n+        let source_map = stat!(\"source-map\", || self.encode_source_map());\n+\n+        let root = stat!(\"final\", || {\n+            let attrs = tcx.hir().krate_attrs();\n+            self.lazy(CrateRoot {\n+                name: tcx.crate_name(LOCAL_CRATE),\n+                extra_filename: tcx.sess.opts.cg.extra_filename.clone(),\n+                triple: tcx.sess.opts.target_triple.clone(),\n+                hash: tcx.crate_hash(LOCAL_CRATE),\n+                stable_crate_id: tcx.def_path_hash(LOCAL_CRATE.as_def_id()).stable_crate_id(),\n+                required_panic_strategy: tcx.required_panic_strategy(LOCAL_CRATE),\n+                panic_in_drop_strategy: tcx.sess.opts.unstable_opts.panic_in_drop,\n+                edition: tcx.sess.edition(),\n+                has_global_allocator: tcx.has_global_allocator(LOCAL_CRATE),\n+                has_panic_handler: tcx.has_panic_handler(LOCAL_CRATE),\n+                has_default_lib_allocator: tcx\n+                    .sess\n+                    .contains_name(&attrs, sym::default_lib_allocator),\n+                proc_macro_data,\n+                debugger_visualizers,\n+                compiler_builtins: tcx.sess.contains_name(&attrs, sym::compiler_builtins),\n+                needs_allocator: tcx.sess.contains_name(&attrs, sym::needs_allocator),\n+                needs_panic_runtime: tcx.sess.contains_name(&attrs, sym::needs_panic_runtime),\n+                no_builtins: tcx.sess.contains_name(&attrs, sym::no_builtins),\n+                panic_runtime: tcx.sess.contains_name(&attrs, sym::panic_runtime),\n+                profiler_runtime: tcx.sess.contains_name(&attrs, sym::profiler_runtime),\n+                symbol_mangling_version: tcx.sess.opts.get_symbol_mangling_version(),\n+\n+                crate_deps,\n+                dylib_dependency_formats,\n+                lib_features,\n+                stability_implications,\n+                lang_items,\n+                diagnostic_items,\n+                lang_items_missing,\n+                native_libraries,\n+                foreign_modules,\n+                source_map,\n+                traits,\n+                impls,\n+                incoherent_impls,\n+                exported_symbols,\n+                interpret_alloc_index,\n+                tables,\n+                syntax_contexts,\n+                expn_data,\n+                expn_hashes,\n+                def_path_hash_map,\n+            })\n         });\n-        let final_bytes = self.position() - i;\n \n         let total_bytes = self.position();\n \n-        let computed_total_bytes = preamble_bytes\n-            + dep_bytes\n-            + lib_feature_bytes\n-            + stability_implications_bytes\n-            + lang_item_bytes\n-            + diagnostic_item_bytes\n-            + native_lib_bytes\n-            + foreign_modules_bytes\n-            + def_path_table_bytes\n-            + traits_bytes\n-            + impls_bytes\n-            + incoherent_impls_bytes\n-            + mir_bytes\n-            + item_bytes\n-            + interpret_alloc_index_bytes\n-            + proc_macro_data_bytes\n-            + tables_bytes\n-            + debugger_visualizers_bytes\n-            + exported_symbols_bytes\n-            + hygiene_bytes\n-            + def_path_hash_map_bytes\n-            + source_map_bytes\n-            + final_bytes;\n+        let computed_total_bytes: usize = stats.iter().map(|(_, size)| size).sum();\n         assert_eq!(total_bytes, computed_total_bytes);\n \n         if tcx.sess.meta_stats() {\n@@ -782,42 +726,38 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n             }\n             assert_eq!(self.opaque.file().stream_position().unwrap(), pos_before_rewind);\n \n+            stats.sort_by_key(|&(_, usize)| usize);\n+\n+            let prefix = \"meta-stats\";\n             let perc = |bytes| (bytes * 100) as f64 / total_bytes as f64;\n-            let p = |label, bytes| {\n-                eprintln!(\"{:>21}: {:>8} bytes ({:4.1}%)\", label, bytes, perc(bytes));\n-            };\n \n-            eprintln!(\"\");\n+            eprintln!(\"{} METADATA STATS\", prefix);\n+            eprintln!(\"{} {:<23}{:>10}\", prefix, \"Section\", \"Size\");\n+            eprintln!(\n+                \"{} ----------------------------------------------------------------\",\n+                prefix\n+            );\n+            for (label, size) in stats {\n+                eprintln!(\n+                    \"{} {:<23}{:>10} ({:4.1}%)\",\n+                    prefix,\n+                    label,\n+                    to_readable_str(size),\n+                    perc(size)\n+                );\n+            }\n+            eprintln!(\n+                \"{} ----------------------------------------------------------------\",\n+                prefix\n+            );\n             eprintln!(\n-                \"{} metadata bytes, of which {} bytes ({:.1}%) are zero\",\n-                total_bytes,\n-                zero_bytes,\n+                \"{} {:<23}{:>10} (of which {:.1}% are zero bytes)\",\n+                prefix,\n+                \"Total\",\n+                to_readable_str(total_bytes),\n                 perc(zero_bytes)\n             );\n-            p(\"preamble\", preamble_bytes);\n-            p(\"dep\", dep_bytes);\n-            p(\"lib feature\", lib_feature_bytes);\n-            p(\"stability_implications\", stability_implications_bytes);\n-            p(\"lang item\", lang_item_bytes);\n-            p(\"diagnostic item\", diagnostic_item_bytes);\n-            p(\"native lib\", native_lib_bytes);\n-            p(\"foreign modules\", foreign_modules_bytes);\n-            p(\"def-path table\", def_path_table_bytes);\n-            p(\"traits\", traits_bytes);\n-            p(\"impls\", impls_bytes);\n-            p(\"incoherent_impls\", incoherent_impls_bytes);\n-            p(\"mir\", mir_bytes);\n-            p(\"item\", item_bytes);\n-            p(\"interpret_alloc_index\", interpret_alloc_index_bytes);\n-            p(\"proc-macro-data\", proc_macro_data_bytes);\n-            p(\"tables\", tables_bytes);\n-            p(\"debugger visualizers\", debugger_visualizers_bytes);\n-            p(\"exported symbols\", exported_symbols_bytes);\n-            p(\"hygiene\", hygiene_bytes);\n-            p(\"def-path hashes\", def_path_hash_map_bytes);\n-            p(\"source_map\", source_map_bytes);\n-            p(\"final\", final_bytes);\n-            eprintln!(\"\");\n+            eprintln!(\"{}\", prefix);\n         }\n \n         root"}]}