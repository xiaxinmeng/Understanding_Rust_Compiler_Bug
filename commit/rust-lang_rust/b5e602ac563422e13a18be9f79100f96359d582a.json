{"sha": "b5e602ac563422e13a18be9f79100f96359d582a", "node_id": "MDY6Q29tbWl0NzI0NzEyOmI1ZTYwMmFjNTYzNDIyZTEzYTE4YmU5Zjc5MTAwZjk2MzU5ZDU4MmE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-11-10T20:26:10Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-11-10T20:26:10Z"}, "message": "auto merge of #10321 : alexcrichton/rust/uv-rewrite, r=brson\n\nThe major impetus for this pull request was to remove all usage of `~fn()` in `librustuv`. This construct is going away as a language feature, and additionally it imposes the requirement that all I/O operations have at least one allocation. This allocation has been seen to have a fairly high performance impact in profiles of I/O benchmarks.\r\n\r\nI've migrated `librustuv` away from all usage of `~fn()`, and at the same time it no longer allocates on every I/O operation anywhere. The scheduler is now much more tightly integrated with all of the libuv bindings and most of the uv callbacks are specialized functions for a certain procedure. This is a step backwards in terms of making `librustuv` usable anywhere else, but I think that the performance gains are a big win here.\r\n\r\nIn just a simple benchmark of reading/writing 4k of 0s at a time between a tcp client/server in separate processes on the same system, I have witnessed the throughput increase from ~750MB/s to ~1200MB/s with this change applied.\r\n\r\nI'm still in the process of testing this change, although all the major bugs (to my knowledge) have been fleshed out and removed. There are still a few spurious segfaults, and that's what I'm currently investigating. In the meantime, I wanted to put this up for review to get some eyes on it other than mine. I'll update this once I've got all the tests passing reliably again.", "tree": {"sha": "68f474d86ebf9a96a47259aaf2f3626a02d70eb5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/68f474d86ebf9a96a47259aaf2f3626a02d70eb5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b5e602ac563422e13a18be9f79100f96359d582a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b5e602ac563422e13a18be9f79100f96359d582a", "html_url": "https://github.com/rust-lang/rust/commit/b5e602ac563422e13a18be9f79100f96359d582a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b5e602ac563422e13a18be9f79100f96359d582a/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3851f908d16b55dfe69d5a423ecbef4cd224fae2", "url": "https://api.github.com/repos/rust-lang/rust/commits/3851f908d16b55dfe69d5a423ecbef4cd224fae2", "html_url": "https://github.com/rust-lang/rust/commit/3851f908d16b55dfe69d5a423ecbef4cd224fae2"}, {"sha": "e38a89d0b0fcc3b2f5cad600d7b3a16faeb94248", "url": "https://api.github.com/repos/rust-lang/rust/commits/e38a89d0b0fcc3b2f5cad600d7b3a16faeb94248", "html_url": "https://github.com/rust-lang/rust/commit/e38a89d0b0fcc3b2f5cad600d7b3a16faeb94248"}], "stats": {"total": 9302, "additions": 3630, "deletions": 5672}, "files": [{"sha": "39679cbed6961566d9d801425c5b6bc445365057", "filename": "mk/rt.mk", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/mk%2Frt.mk", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/mk%2Frt.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Frt.mk?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -207,7 +207,7 @@ LIBUV_MAKEFILE_$(1) := $$(CFG_BUILD_DIR)$$(RT_OUTPUT_DIR_$(1))/libuv/Makefile\n \n $$(LIBUV_MAKEFILE_$(1)): $$(LIBUV_DEPS)\n \t(cd $(S)src/libuv/ && \\\n-\t $$(CFG_PYTHON) ./gyp_uv -f make -Dtarget_arch=$$(LIBUV_ARCH_$(1)) \\\n+\t $$(CFG_PYTHON) ./gyp_uv.py -f make -Dtarget_arch=$$(LIBUV_ARCH_$(1)) \\\n \t   -D ninja \\\n \t   -DOS=$$(LIBUV_OSTYPE_$(1)) \\\n \t   -Goutput_dir=$$(@D) --generator-output $$(@D))\n@@ -218,7 +218,7 @@ $$(LIBUV_MAKEFILE_$(1)): $$(LIBUV_DEPS)\n ifdef CFG_WINDOWSY_$(1)\n $$(LIBUV_LIB_$(1)): $$(LIBUV_DEPS)\n \t$$(Q)$$(MAKE) -C $$(S)src/libuv -f Makefile.mingw \\\n-\t\tCFLAGS=\"$$(CFG_GCCISH_CFLAGS) $$(LIBUV_FLAGS_$$(HOST_$(1))) $$(SNAP_DEFINES)\" \\\n+\t\tCC=\"$$(CC) $$(CFG_GCCISH_CFLAGS) $$(LIBUV_FLAGS_$$(HOST_$(1))) $$(SNAP_DEFINES)\" \\\n \t\tAR=\"$$(AR_$(1))\" \\\n \t\tV=$$(VERBOSE)\n \t$$(Q)cp $$(S)src/libuv/libuv.a $$@"}, {"sha": "601cc9f84add0ef3307ea73ad51abe6157c43e3c", "filename": "src/librustuv/addrinfo.rs", "status": "modified", "additions": 70, "deletions": 133, "changes": 203, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Faddrinfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Faddrinfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Faddrinfo.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,41 +8,34 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::cast::transmute;\n-use std::cell::Cell;\n-use std::libc::{c_int, c_void};\n-use std::ptr::null;\n use ai = std::rt::io::net::addrinfo;\n+use std::libc::c_int;\n+use std::ptr::null;\n+use std::rt::BlockedTask;\n+use std::rt::local::Local;\n+use std::rt::sched::Scheduler;\n \n-use uvll;\n-use uvll::UV_GETADDRINFO;\n-use super::{Loop, UvError, NativeHandle, status_to_maybe_uv_error};\n use net;\n+use super::{Loop, UvError, Request, wait_until_woken_after};\n+use uvll;\n \n-type GetAddrInfoCallback = ~fn(GetAddrInfoRequest, &net::UvAddrInfo, Option<UvError>);\n-\n-pub struct GetAddrInfoRequest(*uvll::uv_getaddrinfo_t);\n-\n-pub struct RequestData {\n-    priv getaddrinfo_cb: Option<GetAddrInfoCallback>,\n+struct Addrinfo {\n+    handle: *uvll::addrinfo,\n }\n \n-impl GetAddrInfoRequest {\n-    pub fn new() -> GetAddrInfoRequest {\n-        let req = unsafe { uvll::malloc_req(UV_GETADDRINFO) };\n-        assert!(req.is_not_null());\n-        let mut req: GetAddrInfoRequest = NativeHandle::from_native_handle(req);\n-        req.install_req_data();\n-        return req;\n-    }\n+struct Ctx {\n+    slot: Option<BlockedTask>,\n+    status: c_int,\n+    addrinfo: Option<Addrinfo>,\n+}\n \n-    pub fn getaddrinfo(&mut self, loop_: &Loop, node: Option<&str>,\n-                       service: Option<&str>, hints: Option<ai::Hint>,\n-                       cb: GetAddrInfoCallback) {\n+pub struct GetAddrInfoRequest;\n \n+impl GetAddrInfoRequest {\n+    pub fn run(loop_: &Loop, node: Option<&str>, service: Option<&str>,\n+               hints: Option<ai::Hint>) -> Result<~[ai::Info], UvError> {\n         assert!(node.is_some() || service.is_some());\n-\n-        let (c_node, c_node_ptr) = match node {\n+        let (_c_node, c_node_ptr) = match node {\n             Some(n) => {\n                 let c_node = n.to_c_str();\n                 let c_node_ptr = c_node.with_ref(|r| r);\n@@ -51,7 +44,7 @@ impl GetAddrInfoRequest {\n             None => (None, null())\n         };\n \n-        let (c_service, c_service_ptr) = match service {\n+        let (_c_service, c_service_ptr) = match service {\n             Some(s) => {\n                 let c_service = s.to_c_str();\n                 let c_service_ptr = c_service.with_ref(|r| r);\n@@ -60,37 +53,13 @@ impl GetAddrInfoRequest {\n             None => (None, null())\n         };\n \n-        let cb = Cell::new(cb);\n-        let wrapper_cb: GetAddrInfoCallback = |req, addrinfo, err| {\n-            // Capture some heap values that need to stay alive for the\n-            // getaddrinfo call\n-            let _ = &c_node;\n-            let _ = &c_service;\n-\n-            let cb = cb.take();\n-            cb(req, addrinfo, err)\n-        };\n-\n         let hint = hints.map(|hint| {\n             let mut flags = 0;\n             do each_ai_flag |cval, aival| {\n                 if hint.flags & (aival as uint) != 0 {\n                     flags |= cval as i32;\n                 }\n             }\n-            /* XXX: do we really want to support these?\n-            let socktype = match hint.socktype {\n-                Some(ai::Stream) => uvll::rust_SOCK_STREAM(),\n-                Some(ai::Datagram) => uvll::rust_SOCK_DGRAM(),\n-                Some(ai::Raw) => uvll::rust_SOCK_RAW(),\n-                None => 0,\n-            };\n-            let protocol = match hint.protocol {\n-                Some(ai::UDP) => uvll::rust_IPPROTO_UDP(),\n-                Some(ai::TCP) => uvll::rust_IPPROTO_TCP(),\n-                _ => 0,\n-            };\n-            */\n             let socktype = 0;\n             let protocol = 0;\n \n@@ -106,66 +75,48 @@ impl GetAddrInfoRequest {\n             }\n         });\n         let hint_ptr = hint.as_ref().map_default(null(), |x| x as *uvll::addrinfo);\n+        let mut req = Request::new(uvll::UV_GETADDRINFO);\n+\n+        return match unsafe {\n+            uvll::uv_getaddrinfo(loop_.handle, req.handle,\n+                                 getaddrinfo_cb, c_node_ptr, c_service_ptr,\n+                                 hint_ptr)\n+        } {\n+            0 => {\n+                req.defuse(); // uv callback now owns this request\n+                let mut cx = Ctx { slot: None, status: 0, addrinfo: None };\n+\n+                do wait_until_woken_after(&mut cx.slot) {\n+                    req.set_data(&cx);\n+                }\n \n-        self.get_req_data().getaddrinfo_cb = Some(wrapper_cb);\n-\n-        unsafe {\n-            assert!(0 == uvll::getaddrinfo(loop_.native_handle(),\n-                                           self.native_handle(),\n-                                           getaddrinfo_cb,\n-                                           c_node_ptr,\n-                                           c_service_ptr,\n-                                           hint_ptr));\n-        }\n-\n-        extern \"C\" fn getaddrinfo_cb(req: *uvll::uv_getaddrinfo_t,\n-                                     status: c_int,\n-                                     res: *uvll::addrinfo) {\n-            let mut req: GetAddrInfoRequest = NativeHandle::from_native_handle(req);\n-            let err = status_to_maybe_uv_error(status);\n-            let addrinfo = net::UvAddrInfo(res);\n-            let data = req.get_req_data();\n-            (*data.getaddrinfo_cb.get_ref())(req, &addrinfo, err);\n-            unsafe {\n-                uvll::freeaddrinfo(res);\n+                match cx.status {\n+                    0 => Ok(accum_addrinfo(cx.addrinfo.get_ref())),\n+                    n => Err(UvError(n))\n+                }\n             }\n-        }\n-    }\n+            n => Err(UvError(n))\n+        };\n \n-    fn get_loop(&self) -> Loop {\n-        unsafe {\n-            Loop {\n-                handle: uvll::get_loop_from_fs_req(self.native_handle())\n-            }\n-        }\n-    }\n \n-    fn install_req_data(&mut self) {\n-        let req = self.native_handle() as *uvll::uv_getaddrinfo_t;\n-        let data = ~RequestData {\n-            getaddrinfo_cb: None\n-        };\n-        unsafe {\n-            let data = transmute::<~RequestData, *c_void>(data);\n-            uvll::set_data_for_req(req, data);\n-        }\n-    }\n+        extern fn getaddrinfo_cb(req: *uvll::uv_getaddrinfo_t,\n+                                 status: c_int,\n+                                 res: *uvll::addrinfo) {\n+            let req = Request::wrap(req);\n+            assert!(status != uvll::ECANCELED);\n+            let cx: &mut Ctx = unsafe { req.get_data() };\n+            cx.status = status;\n+            cx.addrinfo = Some(Addrinfo { handle: res });\n \n-    fn get_req_data<'r>(&'r mut self) -> &'r mut RequestData {\n-        unsafe {\n-            let data = uvll::get_data_for_req(self.native_handle());\n-            let data = transmute::<&*c_void, &mut ~RequestData>(&data);\n-            return &mut **data;\n+            let sched: ~Scheduler = Local::take();\n+            sched.resume_blocked_task_immediately(cx.slot.take_unwrap());\n         }\n     }\n+}\n \n-    fn delete(self) {\n-        unsafe {\n-            let data = uvll::get_data_for_req(self.native_handle());\n-            let _data = transmute::<*c_void, ~RequestData>(data);\n-            uvll::set_data_for_req(self.native_handle(), null::<()>());\n-            uvll::free_req(self.native_handle());\n-        }\n+impl Drop for Addrinfo {\n+    fn drop(&mut self) {\n+        unsafe { uvll::uv_freeaddrinfo(self.handle) }\n     }\n }\n \n@@ -184,15 +135,13 @@ fn each_ai_flag(_f: &fn(c_int, ai::Flag)) {\n }\n \n // Traverse the addrinfo linked list, producing a vector of Rust socket addresses\n-pub fn accum_addrinfo(addr: &net::UvAddrInfo) -> ~[ai::Info] {\n+pub fn accum_addrinfo(addr: &Addrinfo) -> ~[ai::Info] {\n     unsafe {\n-        let &net::UvAddrInfo(addr) = addr;\n-        let mut addr = addr;\n+        let mut addr = addr.handle;\n \n         let mut addrs = ~[];\n         loop {\n-            let uvaddr = net::sockaddr_to_UvSocketAddr((*addr).ai_addr);\n-            let rustaddr = net::uv_socket_addr_to_socket_addr(uvaddr);\n+            let rustaddr = net::sockaddr_to_socket_addr((*addr).ai_addr);\n \n             let mut flags = 0;\n             do each_ai_flag |cval, aival| {\n@@ -235,39 +184,27 @@ pub fn accum_addrinfo(addr: &net::UvAddrInfo) -> ~[ai::Info] {\n     }\n }\n \n-impl NativeHandle<*uvll::uv_getaddrinfo_t> for GetAddrInfoRequest {\n-    fn from_native_handle(handle: *uvll::uv_getaddrinfo_t) -> GetAddrInfoRequest {\n-        GetAddrInfoRequest(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_getaddrinfo_t {\n-        match self { &GetAddrInfoRequest(ptr) => ptr }\n-    }\n-}\n-\n #[cfg(test)]\n mod test {\n-    use Loop;\n     use std::rt::io::net::ip::{SocketAddr, Ipv4Addr};\n     use super::*;\n+    use super::super::local_loop;\n \n     #[test]\n     fn getaddrinfo_test() {\n-        let mut loop_ = Loop::new();\n-        let mut req = GetAddrInfoRequest::new();\n-        do req.getaddrinfo(&loop_, Some(\"localhost\"), None, None) |_, addrinfo, _| {\n-            let sockaddrs = accum_addrinfo(addrinfo);\n-            let mut found_local = false;\n-            let local_addr = &SocketAddr {\n-                ip: Ipv4Addr(127, 0, 0, 1),\n-                port: 0\n-            };\n-            for addr in sockaddrs.iter() {\n-                found_local = found_local || addr.address == *local_addr;\n+        match GetAddrInfoRequest::run(local_loop(), Some(\"localhost\"), None, None) {\n+            Ok(infos) => {\n+                let mut found_local = false;\n+                let local_addr = &SocketAddr {\n+                    ip: Ipv4Addr(127, 0, 0, 1),\n+                    port: 0\n+                };\n+                for addr in infos.iter() {\n+                    found_local = found_local || addr.address == *local_addr;\n+                }\n+                assert!(found_local);\n             }\n-            assert!(found_local);\n+            Err(e) => fail!(\"{:?}\", e),\n         }\n-        loop_.run();\n-        loop_.close();\n-        req.delete();\n     }\n }"}, {"sha": "04e7bce5bd18190fb7fcbe799ab332f39c8d39ab", "filename": "src/librustuv/async.rs", "status": "modified", "additions": 125, "deletions": 46, "changes": 171, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fasync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fasync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fasync.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,76 +8,155 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use std::cast;\n use std::libc::c_int;\n+use std::rt::rtio::{Callback, RemoteCallback};\n+use std::unstable::sync::Exclusive;\n \n use uvll;\n-use super::{Watcher, Loop, NativeHandle, AsyncCallback, WatcherInterop};\n-use super::status_to_maybe_uv_error;\n+use super::{Loop, UvHandle};\n \n-pub struct AsyncWatcher(*uvll::uv_async_t);\n-impl Watcher for AsyncWatcher { }\n+// The entire point of async is to call into a loop from other threads so it\n+// does not need to home.\n+pub struct AsyncWatcher {\n+    handle: *uvll::uv_async_t,\n+\n+    // A flag to tell the callback to exit, set from the dtor. This is\n+    // almost never contested - only in rare races with the dtor.\n+    exit_flag: Exclusive<bool>\n+}\n+\n+struct Payload {\n+    callback: ~Callback,\n+    exit_flag: Exclusive<bool>,\n+}\n \n impl AsyncWatcher {\n-    pub fn new(loop_: &mut Loop, cb: AsyncCallback) -> AsyncWatcher {\n+    pub fn new(loop_: &mut Loop, cb: ~Callback) -> AsyncWatcher {\n+        let handle = UvHandle::alloc(None::<AsyncWatcher>, uvll::UV_ASYNC);\n+        assert_eq!(unsafe {\n+            uvll::uv_async_init(loop_.handle, handle, async_cb)\n+        }, 0);\n+        let flag = Exclusive::new(false);\n+        let payload = ~Payload { callback: cb, exit_flag: flag.clone() };\n         unsafe {\n-            let handle = uvll::malloc_handle(uvll::UV_ASYNC);\n-            assert!(handle.is_not_null());\n-            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n-            watcher.install_watcher_data();\n-            let data = watcher.get_watcher_data();\n-            data.async_cb = Some(cb);\n-            assert_eq!(0, uvll::async_init(loop_.native_handle(), handle, async_cb));\n-            return watcher;\n+            let payload: *u8 = cast::transmute(payload);\n+            uvll::set_data_for_uv_handle(handle, payload);\n         }\n+        return AsyncWatcher { handle: handle, exit_flag: flag, };\n+    }\n+}\n \n-        extern fn async_cb(handle: *uvll::uv_async_t, status: c_int) {\n-            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n-            let status = status_to_maybe_uv_error(status);\n-            let data = watcher.get_watcher_data();\n-            let cb = data.async_cb.get_ref();\n-            (*cb)(watcher, status);\n-        }\n+impl UvHandle<uvll::uv_async_t> for AsyncWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_async_t { self.handle }\n+    unsafe fn from_uv_handle<'a>(_: &'a *uvll::uv_async_t) -> &'a mut AsyncWatcher {\n+        fail!(\"async watchers can't be built from their handles\");\n     }\n+}\n \n-    pub fn send(&mut self) {\n-        unsafe {\n-            let handle = self.native_handle();\n-            uvll::async_send(handle);\n-        }\n+extern fn async_cb(handle: *uvll::uv_async_t, status: c_int) {\n+    assert!(status == 0);\n+    let payload: &mut Payload = unsafe {\n+        cast::transmute(uvll::get_data_for_uv_handle(handle))\n+    };\n+\n+    // The synchronization logic here is subtle. To review,\n+    // the uv async handle type promises that, after it is\n+    // triggered the remote callback is definitely called at\n+    // least once. UvRemoteCallback needs to maintain those\n+    // semantics while also shutting down cleanly from the\n+    // dtor. In our case that means that, when the\n+    // UvRemoteCallback dtor calls `async.send()`, here `f` is\n+    // always called later.\n+\n+    // In the dtor both the exit flag is set and the async\n+    // callback fired under a lock.  Here, before calling `f`,\n+    // we take the lock and check the flag. Because we are\n+    // checking the flag before calling `f`, and the flag is\n+    // set under the same lock as the send, then if the flag\n+    // is set then we're guaranteed to call `f` after the\n+    // final send.\n+\n+    // If the check was done after `f()` then there would be a\n+    // period between that call and the check where the dtor\n+    // could be called in the other thread, missing the final\n+    // callback while still destroying the handle.\n+\n+    let should_exit = unsafe {\n+        payload.exit_flag.with_imm(|&should_exit| should_exit)\n+    };\n+\n+    payload.callback.call();\n+\n+    if should_exit {\n+        unsafe { uvll::uv_close(handle, close_cb) }\n     }\n }\n \n-impl NativeHandle<*uvll::uv_async_t> for AsyncWatcher {\n-    fn from_native_handle(handle: *uvll::uv_async_t) -> AsyncWatcher {\n-        AsyncWatcher(handle)\n+extern fn close_cb(handle: *uvll::uv_handle_t) {\n+    // drop the payload\n+    let _payload: ~Payload = unsafe {\n+        cast::transmute(uvll::get_data_for_uv_handle(handle))\n+    };\n+    // and then free the handle\n+    unsafe { uvll::free_handle(handle) }\n+}\n+\n+impl RemoteCallback for AsyncWatcher {\n+    fn fire(&mut self) {\n+        unsafe { uvll::uv_async_send(self.handle) }\n     }\n-    fn native_handle(&self) -> *uvll::uv_async_t {\n-        match self { &AsyncWatcher(ptr) => ptr }\n+}\n+\n+impl Drop for AsyncWatcher {\n+    fn drop(&mut self) {\n+        unsafe {\n+            do self.exit_flag.with |should_exit| {\n+                // NB: These two things need to happen atomically. Otherwise\n+                // the event handler could wake up due to a *previous*\n+                // signal and see the exit flag, destroying the handle\n+                // before the final send.\n+                *should_exit = true;\n+                uvll::uv_async_send(self.handle)\n+            }\n+        }\n     }\n }\n \n #[cfg(test)]\n-mod test {\n+mod test_remote {\n+    use std::cell::Cell;\n+    use std::rt::rtio::Callback;\n+    use std::rt::thread::Thread;\n+    use std::rt::tube::Tube;\n \n     use super::*;\n-    use Loop;\n-    use std::unstable::run_in_bare_thread;\n-    use std::rt::thread::Thread;\n-    use std::cell::Cell;\n+    use super::super::local_loop;\n \n+    // Make sure that we can fire watchers in remote threads and that they\n+    // actually trigger what they say they will.\n     #[test]\n     fn smoke_test() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let watcher = AsyncWatcher::new(&mut loop_, |w, _| w.close(||()) );\n-            let watcher_cell = Cell::new(watcher);\n-            let thread = do Thread::start {\n-                let mut watcher = watcher_cell.take();\n-                watcher.send();\n-            };\n-            loop_.run();\n-            loop_.close();\n-            thread.join();\n+        struct MyCallback(Option<Tube<int>>);\n+        impl Callback for MyCallback {\n+            fn call(&mut self) {\n+                // this can get called more than once, but we only want to send\n+                // once\n+                if self.is_some() {\n+                    self.take_unwrap().send(1);\n+                }\n+            }\n         }\n+\n+        let mut tube = Tube::new();\n+        let cb = ~MyCallback(Some(tube.clone()));\n+        let watcher = Cell::new(AsyncWatcher::new(local_loop(), cb as ~Callback));\n+\n+        let thread = do Thread::start {\n+            watcher.take().fire();\n+        };\n+\n+        assert_eq!(tube.recv(), 1);\n+        thread.join();\n     }\n }"}, {"sha": "a5848194d05bbb0ff1fe9923bc52feb3777e8205", "filename": "src/librustuv/file.rs", "status": "modified", "additions": 470, "deletions": 611, "changes": 1081, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Ffile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Ffile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Ffile.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,701 +8,560 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::ptr::null;\n-use std::c_str;\n use std::c_str::CString;\n+use std::c_str;\n use std::cast::transmute;\n+use std::cast;\n+use std::libc::{c_int, c_char, c_void, size_t};\n use std::libc;\n-use std::libc::{c_int, c_char, c_void};\n-\n-use super::{Request, NativeHandle, Loop, FsCallback, Buf,\n-            status_to_maybe_uv_error, UvError};\n+use std::rt::BlockedTask;\n+use std::rt::io::{FileStat, IoError};\n+use std::rt::io;\n+use std::rt::local::Local;\n+use std::rt::rtio;\n+use std::rt::sched::{Scheduler, SchedHandle};\n+use std::task;\n+use std::vec;\n+\n+use super::{Loop, UvError, uv_error_to_io_error, wait_until_woken_after};\n+use uvio::HomingIO;\n use uvll;\n-use uvll::*;\n \n-pub struct FsRequest(*uvll::uv_fs_t);\n-impl Request for FsRequest {}\n+pub struct FsRequest {\n+    req: *uvll::uv_fs_t,\n+    priv fired: bool,\n+}\n \n-pub struct RequestData {\n-    priv complete_cb: Option<FsCallback>\n+pub struct FileWatcher {\n+    priv loop_: Loop,\n+    priv fd: c_int,\n+    priv close: rtio::CloseBehavior,\n+    priv home: SchedHandle,\n }\n \n impl FsRequest {\n-    pub fn new() -> FsRequest {\n-        let fs_req = unsafe { malloc_req(UV_FS) };\n-        assert!(fs_req.is_not_null());\n-        let fs_req: FsRequest = NativeHandle::from_native_handle(fs_req);\n-        fs_req\n-    }\n-\n-    pub fn open(self, loop_: &Loop, path: &CString, flags: int, mode: int,\n-                cb: FsCallback) {\n-        let complete_cb_ptr = {\n-            let mut me = self;\n-            me.req_boilerplate(Some(cb))\n-        };\n-        let ret = path.with_ref(|p| unsafe {\n-            uvll::fs_open(loop_.native_handle(),\n-                          self.native_handle(), p, flags, mode, complete_cb_ptr)\n-        });\n-        assert_eq!(ret, 0);\n-    }\n-\n-    pub fn open_sync(mut self, loop_: &Loop, path: &CString,\n-                     flags: int, mode: int) -> Result<c_int, UvError> {\n-        let complete_cb_ptr = self.req_boilerplate(None);\n-        let result = path.with_ref(|p| unsafe {\n-            uvll::fs_open(loop_.native_handle(),\n-                    self.native_handle(), p, flags, mode, complete_cb_ptr)\n-        });\n-        self.sync_cleanup(result)\n-    }\n-\n-    pub fn unlink(mut self, loop_: &Loop, path: &CString, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        let ret = path.with_ref(|p| unsafe {\n-            uvll::fs_unlink(loop_.native_handle(),\n-                          self.native_handle(), p, complete_cb_ptr)\n-        });\n-        assert_eq!(ret, 0);\n-    }\n-\n-    pub fn unlink_sync(mut self, loop_: &Loop, path: &CString)\n-      -> Result<c_int, UvError> {\n-        let complete_cb_ptr = self.req_boilerplate(None);\n-        let result = path.with_ref(|p| unsafe {\n-            uvll::fs_unlink(loop_.native_handle(),\n-                          self.native_handle(), p, complete_cb_ptr)\n-        });\n-        self.sync_cleanup(result)\n-    }\n-\n-    pub fn lstat(mut self, loop_: &Loop, path: &CString, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        let ret = path.with_ref(|p| unsafe {\n-            uvll::uv_fs_lstat(loop_.native_handle(),\n-                              self.native_handle(), p, complete_cb_ptr)\n-        });\n-        assert_eq!(ret, 0);\n-    }\n-\n-    pub fn stat(mut self, loop_: &Loop, path: &CString, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        let ret = path.with_ref(|p| unsafe {\n-            uvll::fs_stat(loop_.native_handle(),\n-                          self.native_handle(), p, complete_cb_ptr)\n-        });\n-        assert_eq!(ret, 0);\n-    }\n-\n-    pub fn write(mut self, loop_: &Loop, fd: c_int, buf: Buf, offset: i64,\n-                 cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        let base_ptr = buf.base as *c_void;\n-        let len = buf.len as uint;\n-        let ret = unsafe {\n-            uvll::fs_write(loop_.native_handle(), self.native_handle(),\n-                           fd, base_ptr,\n-                           len, offset, complete_cb_ptr)\n-        };\n-        assert_eq!(ret, 0);\n-    }\n-    pub fn write_sync(mut self, loop_: &Loop, fd: c_int, buf: Buf, offset: i64)\n-          -> Result<c_int, UvError> {\n-        let complete_cb_ptr = self.req_boilerplate(None);\n-        let base_ptr = buf.base as *c_void;\n-        let len = buf.len as uint;\n-        let result = unsafe {\n-            uvll::fs_write(loop_.native_handle(), self.native_handle(),\n-                           fd, base_ptr,\n-                           len, offset, complete_cb_ptr)\n-        };\n-        self.sync_cleanup(result)\n-    }\n-\n-    pub fn read(mut self, loop_: &Loop, fd: c_int, buf: Buf, offset: i64,\n-                cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        let buf_ptr = buf.base as *c_void;\n-        let len = buf.len as uint;\n-        let ret = unsafe {\n-            uvll::fs_read(loop_.native_handle(), self.native_handle(),\n-                           fd, buf_ptr,\n-                           len, offset, complete_cb_ptr)\n-        };\n-        assert_eq!(ret, 0);\n-    }\n-    pub fn read_sync(mut self, loop_: &Loop, fd: c_int, buf: Buf, offset: i64)\n-          -> Result<c_int, UvError> {\n-        let complete_cb_ptr = self.req_boilerplate(None);\n-        let buf_ptr = buf.base as *c_void;\n-        let len = buf.len as uint;\n-        let result = unsafe {\n-            uvll::fs_read(loop_.native_handle(), self.native_handle(),\n-                           fd, buf_ptr,\n-                           len, offset, complete_cb_ptr)\n-        };\n-        self.sync_cleanup(result)\n-    }\n-\n-    pub fn close(mut self, loop_: &Loop, fd: c_int, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::fs_close(loop_.native_handle(), self.native_handle(),\n-                           fd, complete_cb_ptr)\n-        }, 0);\n-    }\n-    pub fn close_sync(mut self, loop_: &Loop,\n-                      fd: c_int) -> Result<c_int, UvError> {\n-        let complete_cb_ptr = self.req_boilerplate(None);\n-        let result = unsafe {\n-            uvll::fs_close(loop_.native_handle(), self.native_handle(),\n-                           fd, complete_cb_ptr)\n-        };\n-        self.sync_cleanup(result)\n-    }\n-\n-    pub fn mkdir(mut self, loop_: &Loop, path: &CString, mode: c_int,\n-                 cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(path.with_ref(|p| unsafe {\n-            uvll::fs_mkdir(loop_.native_handle(),\n-                           self.native_handle(), p, mode, complete_cb_ptr)\n-        }), 0);\n-    }\n-\n-    pub fn rmdir(mut self, loop_: &Loop, path: &CString, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(path.with_ref(|p| unsafe {\n-            uvll::fs_rmdir(loop_.native_handle(),\n-                           self.native_handle(), p, complete_cb_ptr)\n-        }), 0);\n-    }\n-\n-    pub fn rename(mut self, loop_: &Loop, path: &CString, to: &CString,\n-                  cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::fs_rename(loop_.native_handle(),\n-                            self.native_handle(),\n-                            path.with_ref(|p| p),\n-                            to.with_ref(|p| p),\n-                            complete_cb_ptr)\n-        }, 0);\n-    }\n-\n-    pub fn chmod(mut self, loop_: &Loop, path: &CString, mode: c_int,\n-                 cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(path.with_ref(|p| unsafe {\n-            uvll::fs_chmod(loop_.native_handle(), self.native_handle(), p, mode,\n-                           complete_cb_ptr)\n-        }), 0);\n-    }\n-\n-    pub fn readdir(mut self, loop_: &Loop, path: &CString,\n-                   flags: c_int, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(path.with_ref(|p| unsafe {\n-            uvll::fs_readdir(loop_.native_handle(),\n-                             self.native_handle(), p, flags, complete_cb_ptr)\n-        }), 0);\n-    }\n-\n-    pub fn readlink(mut self, loop_: &Loop, path: &CString, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(path.with_ref(|p| unsafe {\n-            uvll::uv_fs_readlink(loop_.native_handle(),\n-                                 self.native_handle(), p, complete_cb_ptr)\n-        }), 0);\n-    }\n-\n-    pub fn chown(mut self, loop_: &Loop, path: &CString, uid: int, gid: int,\n-                 cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(path.with_ref(|p| unsafe {\n-            uvll::uv_fs_chown(loop_.native_handle(),\n-                              self.native_handle(), p,\n+    pub fn open(loop_: &Loop, path: &CString, flags: int, mode: int)\n+        -> Result<FileWatcher, UvError>\n+    {\n+        execute(|req, cb| unsafe {\n+            uvll::uv_fs_open(loop_.handle,\n+                             req, path.with_ref(|p| p), flags as c_int,\n+                             mode as c_int, cb)\n+        }).map(|req|\n+            FileWatcher::new(*loop_, req.get_result() as c_int,\n+                             rtio::CloseSynchronously)\n+        )\n+    }\n+\n+    pub fn unlink(loop_: &Loop, path: &CString) -> Result<(), UvError> {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_unlink(loop_.handle, req, path.with_ref(|p| p),\n+                               cb)\n+        })\n+    }\n+\n+    pub fn lstat(loop_: &Loop, path: &CString) -> Result<FileStat, UvError> {\n+        execute(|req, cb| unsafe {\n+            uvll::uv_fs_lstat(loop_.handle, req, path.with_ref(|p| p),\n+                              cb)\n+        }).map(|req| req.mkstat())\n+    }\n+\n+    pub fn stat(loop_: &Loop, path: &CString) -> Result<FileStat, UvError> {\n+        execute(|req, cb| unsafe {\n+            uvll::uv_fs_stat(loop_.handle, req, path.with_ref(|p| p),\n+                             cb)\n+        }).map(|req| req.mkstat())\n+    }\n+\n+    pub fn write(loop_: &Loop, fd: c_int, buf: &[u8], offset: i64)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_write(loop_.handle, req,\n+                              fd, vec::raw::to_ptr(buf) as *c_void,\n+                              buf.len() as size_t, offset, cb)\n+        })\n+    }\n+\n+    pub fn read(loop_: &Loop, fd: c_int, buf: &mut [u8], offset: i64)\n+        -> Result<int, UvError>\n+    {\n+        do execute(|req, cb| unsafe {\n+            uvll::uv_fs_read(loop_.handle, req,\n+                             fd, vec::raw::to_ptr(buf) as *c_void,\n+                             buf.len() as size_t, offset, cb)\n+        }).map |req| {\n+            req.get_result() as int\n+        }\n+    }\n+\n+    pub fn mkdir(loop_: &Loop, path: &CString, mode: c_int)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_mkdir(loop_.handle, req, path.with_ref(|p| p),\n+                              mode, cb)\n+        })\n+    }\n+\n+    pub fn rmdir(loop_: &Loop, path: &CString) -> Result<(), UvError> {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_rmdir(loop_.handle, req, path.with_ref(|p| p),\n+                              cb)\n+        })\n+    }\n+\n+    pub fn rename(loop_: &Loop, path: &CString, to: &CString)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_rename(loop_.handle,\n+                               req,\n+                               path.with_ref(|p| p),\n+                               to.with_ref(|p| p),\n+                               cb)\n+        })\n+    }\n+\n+    pub fn chmod(loop_: &Loop, path: &CString, mode: c_int)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_chmod(loop_.handle, req, path.with_ref(|p| p),\n+                              mode, cb)\n+        })\n+    }\n+\n+    pub fn readdir(loop_: &Loop, path: &CString, flags: c_int)\n+        -> Result<~[Path], UvError>\n+    {\n+        execute(|req, cb| unsafe {\n+            uvll::uv_fs_readdir(loop_.handle,\n+                                req, path.with_ref(|p| p), flags, cb)\n+        }).map(|req| unsafe {\n+            let mut paths = ~[];\n+            let path = CString::new(path.with_ref(|p| p), false);\n+            let parent = Path::new(path);\n+            do c_str::from_c_multistring(req.get_ptr() as *libc::c_char,\n+                                         Some(req.get_result() as uint)) |rel| {\n+                let p = rel.as_bytes();\n+                paths.push(parent.join(p.slice_to(rel.len())));\n+            };\n+            paths\n+        })\n+    }\n+\n+    pub fn readlink(loop_: &Loop, path: &CString) -> Result<Path, UvError> {\n+        do execute(|req, cb| unsafe {\n+            uvll::uv_fs_readlink(loop_.handle, req,\n+                                 path.with_ref(|p| p), cb)\n+        }).map |req| {\n+            Path::new(unsafe {\n+                CString::new(req.get_ptr() as *libc::c_char, false)\n+            })\n+        }\n+    }\n+\n+    pub fn chown(loop_: &Loop, path: &CString, uid: int, gid: int)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_chown(loop_.handle,\n+                              req, path.with_ref(|p| p),\n                               uid as uvll::uv_uid_t,\n                               gid as uvll::uv_gid_t,\n-                              complete_cb_ptr)\n-        }), 0);\n+                              cb)\n+        })\n     }\n \n-    pub fn truncate(mut self, loop_: &Loop, file: c_int, offset: i64,\n-                    cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::uv_fs_ftruncate(loop_.native_handle(),\n-                                  self.native_handle(), file, offset,\n-                                  complete_cb_ptr)\n-        }, 0);\n+    pub fn truncate(loop_: &Loop, file: c_int, offset: i64)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_ftruncate(loop_.handle, req, file, offset, cb)\n+        })\n     }\n \n-    pub fn link(mut self, loop_: &Loop, src: &CString, dst: &CString,\n-                cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::uv_fs_link(loop_.native_handle(), self.native_handle(),\n+    pub fn link(loop_: &Loop, src: &CString, dst: &CString)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_link(loop_.handle, req,\n                              src.with_ref(|p| p),\n                              dst.with_ref(|p| p),\n-                             complete_cb_ptr)\n-        }, 0);\n+                             cb)\n+        })\n     }\n \n-    pub fn symlink(mut self, loop_: &Loop, src: &CString, dst: &CString,\n-                   cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::uv_fs_symlink(loop_.native_handle(), self.native_handle(),\n+    pub fn symlink(loop_: &Loop, src: &CString, dst: &CString)\n+        -> Result<(), UvError>\n+    {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_symlink(loop_.handle, req,\n                                 src.with_ref(|p| p),\n                                 dst.with_ref(|p| p),\n-                                0,\n-                                complete_cb_ptr)\n-        }, 0);\n-    }\n-\n-    pub fn fsync(mut self, loop_: &Loop, fd: c_int, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::uv_fs_fsync(loop_.native_handle(), self.native_handle(), fd,\n-                              complete_cb_ptr)\n-        }, 0);\n-    }\n-\n-    pub fn datasync(mut self, loop_: &Loop, fd: c_int, cb: FsCallback) {\n-        let complete_cb_ptr = self.req_boilerplate(Some(cb));\n-        assert_eq!(unsafe {\n-            uvll::uv_fs_fdatasync(loop_.native_handle(), self.native_handle(), fd,\n-                                  complete_cb_ptr)\n-        }, 0);\n-    }\n-\n-    // accessors/utility funcs\n-    fn sync_cleanup(self, result: c_int)\n-          -> Result<c_int, UvError> {\n-        self.cleanup_and_delete();\n-        match status_to_maybe_uv_error(result as i32) {\n-            Some(err) => Err(err),\n-            None => Ok(result)\n-        }\n-    }\n-    fn req_boilerplate(&mut self, cb: Option<FsCallback>) -> *u8 {\n-        let result = match cb {\n-            Some(_) => {\n-                compl_cb as *u8\n-            },\n-            None => 0 as *u8\n-        };\n-        self.install_req_data(cb);\n-        result\n-    }\n-    pub fn install_req_data(&mut self, cb: Option<FsCallback>) {\n-        let fs_req = (self.native_handle()) as *uvll::uv_write_t;\n-        let data = ~RequestData {\n-            complete_cb: cb\n-        };\n-        unsafe {\n-            let data = transmute::<~RequestData, *c_void>(data);\n-            uvll::set_data_for_req(fs_req, data);\n-        }\n+                                0, cb)\n+        })\n     }\n \n-    fn get_req_data<'r>(&'r mut self) -> &'r mut RequestData {\n-        unsafe {\n-            let data = uvll::get_data_for_req((self.native_handle()));\n-            let data = transmute::<&*c_void, &mut ~RequestData>(&data);\n-            &mut **data\n-        }\n+    pub fn fsync(loop_: &Loop, fd: c_int) -> Result<(), UvError> {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_fsync(loop_.handle, req, fd, cb)\n+        })\n     }\n \n-    pub fn get_path(&self) -> *c_char {\n-        unsafe { uvll::get_path_from_fs_req(self.native_handle()) }\n+    pub fn datasync(loop_: &Loop, fd: c_int) -> Result<(), UvError> {\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_fdatasync(loop_.handle, req, fd, cb)\n+        })\n     }\n \n-    pub fn get_result(&self) -> c_int {\n-        unsafe { uvll::get_result_from_fs_req(self.native_handle()) }\n+    pub fn utime(loop_: &Loop, path: &CString, atime: u64, mtime: u64)\n+        -> Result<(), UvError>\n+    {\n+        // libuv takes seconds\n+        let atime = atime as libc::c_double / 1000.0;\n+        let mtime = mtime as libc::c_double / 1000.0;\n+        execute_nop(|req, cb| unsafe {\n+            uvll::uv_fs_utime(loop_.handle, req, path.with_ref(|p| p),\n+                              atime, mtime, cb)\n+        })\n     }\n \n-    pub fn get_loop(&self) -> Loop {\n-        unsafe { Loop{handle:uvll::get_loop_from_fs_req(self.native_handle())} }\n+    pub fn get_result(&self) -> c_int {\n+        unsafe { uvll::get_result_from_fs_req(self.req) }\n     }\n \n-    pub fn get_stat(&self) -> uv_stat_t {\n-        let stat = uv_stat_t::new();\n-        unsafe { uvll::populate_stat(self.native_handle(), &stat); }\n+    pub fn get_stat(&self) -> uvll::uv_stat_t {\n+        let stat = uvll::uv_stat_t::new();\n+        unsafe { uvll::populate_stat(self.req, &stat); }\n         stat\n     }\n \n     pub fn get_ptr(&self) -> *libc::c_void {\n+        unsafe { uvll::get_ptr_from_fs_req(self.req) }\n+    }\n+\n+    pub fn mkstat(&self) -> FileStat {\n+        let path = unsafe { uvll::get_path_from_fs_req(self.req) };\n+        let path = unsafe { Path::new(CString::new(path, false)) };\n+        let stat = self.get_stat();\n+        fn to_msec(stat: uvll::uv_timespec_t) -> u64 {\n+            // Be sure to cast to u64 first to prevent overflowing if the tv_sec\n+            // field is a 32-bit integer.\n+            (stat.tv_sec as u64) * 1000 + (stat.tv_nsec as u64) / 1000000\n+        }\n+        let kind = match (stat.st_mode as c_int) & libc::S_IFMT {\n+            libc::S_IFREG => io::TypeFile,\n+            libc::S_IFDIR => io::TypeDirectory,\n+            libc::S_IFIFO => io::TypeNamedPipe,\n+            libc::S_IFBLK => io::TypeBlockSpecial,\n+            libc::S_IFLNK => io::TypeSymlink,\n+            _ => io::TypeUnknown,\n+        };\n+        FileStat {\n+            path: path,\n+            size: stat.st_size as u64,\n+            kind: kind,\n+            perm: (stat.st_mode as io::FilePermission) & io::AllPermissions,\n+            created: to_msec(stat.st_birthtim),\n+            modified: to_msec(stat.st_mtim),\n+            accessed: to_msec(stat.st_atim),\n+            unstable: io::UnstableFileStat {\n+                device: stat.st_dev as u64,\n+                inode: stat.st_ino as u64,\n+                rdev: stat.st_rdev as u64,\n+                nlink: stat.st_nlink as u64,\n+                uid: stat.st_uid as u64,\n+                gid: stat.st_gid as u64,\n+                blksize: stat.st_blksize as u64,\n+                blocks: stat.st_blocks as u64,\n+                flags: stat.st_flags as u64,\n+                gen: stat.st_gen as u64,\n+            }\n+        }\n+    }\n+}\n+\n+impl Drop for FsRequest {\n+    fn drop(&mut self) {\n         unsafe {\n-            uvll::get_ptr_from_fs_req(self.native_handle())\n+            if self.fired {\n+                uvll::uv_fs_req_cleanup(self.req);\n+            }\n+            uvll::free_req(self.req);\n         }\n     }\n+}\n \n-    pub fn each_path(&mut self, f: &fn(&CString)) {\n-        let ptr = self.get_ptr();\n-        match self.get_result() {\n-            n if (n <= 0) => {}\n-            n => {\n-                let n_len = n as uint;\n-                // we pass in the len that uv tells us is there\n-                // for the entries and we don't continue past that..\n-                // it appears that sometimes the multistring isn't\n-                // correctly delimited and we stray into garbage memory?\n-                // in any case, passing Some(n_len) fixes it and ensures\n-                // good results\n-                unsafe {\n-                    c_str::from_c_multistring(ptr as *libc::c_char,\n-                                              Some(n_len), f);\n+fn execute(f: &fn(*uvll::uv_fs_t, uvll::uv_fs_cb) -> c_int)\n+    -> Result<FsRequest, UvError>\n+{\n+    return do task::unkillable {\n+        let mut req = FsRequest {\n+            fired: false,\n+            req: unsafe { uvll::malloc_req(uvll::UV_FS) }\n+        };\n+        match f(req.req, fs_cb) {\n+            0 => {\n+                req.fired = true;\n+                let mut slot = None;\n+                do wait_until_woken_after(&mut slot) {\n+                    unsafe { uvll::set_data_for_req(req.req, &slot) }\n+                }\n+                match req.get_result() {\n+                    n if n < 0 => Err(UvError(n)),\n+                    _ => Ok(req),\n                 }\n             }\n+            n => Err(UvError(n))\n+\n         }\n+    };\n+\n+    extern fn fs_cb(req: *uvll::uv_fs_t) {\n+        let slot: &mut Option<BlockedTask> = unsafe {\n+            cast::transmute(uvll::get_data_for_req(req))\n+        };\n+        let sched: ~Scheduler = Local::take();\n+        sched.resume_blocked_task_immediately(slot.take_unwrap());\n     }\n+}\n \n-    fn cleanup_and_delete(self) {\n-        unsafe {\n-            let data = uvll::get_data_for_req(self.native_handle());\n-            let _data = transmute::<*c_void, ~RequestData>(data);\n-            uvll::set_data_for_req(self.native_handle(), null::<()>());\n-            uvll::fs_req_cleanup(self.native_handle());\n-            free_req(self.native_handle() as *c_void)\n+fn execute_nop(f: &fn(*uvll::uv_fs_t, uvll::uv_fs_cb) -> c_int)\n+    -> Result<(), UvError>\n+{\n+    execute(f).map(|_| {})\n+}\n+\n+impl HomingIO for FileWatcher {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n+\n+impl FileWatcher {\n+    pub fn new(loop_: Loop, fd: c_int, close: rtio::CloseBehavior) -> FileWatcher {\n+        FileWatcher {\n+            loop_: loop_,\n+            fd: fd,\n+            close: close,\n+            home: get_handle_to_current_scheduler!()\n         }\n     }\n-}\n \n-impl NativeHandle<*uvll::uv_fs_t> for FsRequest {\n-    fn from_native_handle(handle: *uvll:: uv_fs_t) -> FsRequest {\n-        FsRequest(handle)\n+    fn base_read(&mut self, buf: &mut [u8], offset: i64) -> Result<int, IoError> {\n+        let _m = self.fire_homing_missile();\n+        let r = FsRequest::read(&self.loop_, self.fd, buf, offset);\n+        r.map_err(uv_error_to_io_error)\n     }\n-    fn native_handle(&self) -> *uvll::uv_fs_t {\n-        match self { &FsRequest(ptr) => ptr }\n+    fn base_write(&mut self, buf: &[u8], offset: i64) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        let r = FsRequest::write(&self.loop_, self.fd, buf, offset);\n+        r.map_err(uv_error_to_io_error)\n+    }\n+    fn seek_common(&mut self, pos: i64, whence: c_int) ->\n+        Result<u64, IoError>{\n+        #[fixed_stack_segment]; #[inline(never)];\n+        unsafe {\n+            match libc::lseek(self.fd, pos as libc::off_t, whence) {\n+                -1 => {\n+                    Err(IoError {\n+                        kind: io::OtherIoError,\n+                        desc: \"Failed to lseek.\",\n+                        detail: None\n+                    })\n+                },\n+                n => Ok(n as u64)\n+            }\n+        }\n     }\n }\n \n-fn sync_cleanup(result: int)\n-    -> Result<int, UvError> {\n-    match status_to_maybe_uv_error(result as i32) {\n-        Some(err) => Err(err),\n-        None => Ok(result)\n+impl Drop for FileWatcher {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        match self.close {\n+            rtio::DontClose => {}\n+            rtio::CloseAsynchronously => {\n+                unsafe {\n+                    let req = uvll::malloc_req(uvll::UV_FS);\n+                    uvll::uv_fs_close(self.loop_.handle, req, self.fd, close_cb);\n+                }\n+\n+                extern fn close_cb(req: *uvll::uv_fs_t) {\n+                    unsafe {\n+                        uvll::uv_fs_req_cleanup(req);\n+                        uvll::free_req(req);\n+                    }\n+                }\n+            }\n+            rtio::CloseSynchronously => {\n+                execute_nop(|req, cb| unsafe {\n+                    uvll::uv_fs_close(self.loop_.handle, req, self.fd, cb)\n+                });\n+            }\n+        }\n     }\n }\n \n-extern fn compl_cb(req: *uv_fs_t) {\n-    let mut req: FsRequest = NativeHandle::from_native_handle(req);\n-    // pull the user cb out of the req data\n-    let cb = {\n-        let data = req.get_req_data();\n-        assert!(data.complete_cb.is_some());\n-        // option dance, option dance. oooooh yeah.\n-        data.complete_cb.take_unwrap()\n-    };\n-    // in uv_fs_open calls, the result will be the fd in the\n-    // case of success, otherwise it's -1 indicating an error\n-    let result = req.get_result();\n-    let status = status_to_maybe_uv_error(result);\n-    // we have a req and status, call the user cb..\n-    // only giving the user a ref to the FsRequest, as we\n-    // have to clean it up, afterwards (and they aren't really\n-    // reusable, anyways\n-    cb(&mut req, status);\n-    // clean up the req (and its data!) after calling the user cb\n-    req.cleanup_and_delete();\n+impl rtio::RtioFileStream for FileWatcher {\n+    fn read(&mut self, buf: &mut [u8]) -> Result<int, IoError> {\n+        self.base_read(buf, -1)\n+    }\n+    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n+        self.base_write(buf, -1)\n+    }\n+    fn pread(&mut self, buf: &mut [u8], offset: u64) -> Result<int, IoError> {\n+        self.base_read(buf, offset as i64)\n+    }\n+    fn pwrite(&mut self, buf: &[u8], offset: u64) -> Result<(), IoError> {\n+        self.base_write(buf, offset as i64)\n+    }\n+    fn seek(&mut self, pos: i64, whence: io::SeekStyle) -> Result<u64, IoError> {\n+        use std::libc::{SEEK_SET, SEEK_CUR, SEEK_END};\n+        let whence = match whence {\n+            io::SeekSet => SEEK_SET,\n+            io::SeekCur => SEEK_CUR,\n+            io::SeekEnd => SEEK_END\n+        };\n+        self.seek_common(pos, whence)\n+    }\n+    fn tell(&self) -> Result<u64, IoError> {\n+        use std::libc::SEEK_CUR;\n+        // this is temporary\n+        let self_ = unsafe { cast::transmute_mut(self) };\n+        self_.seek_common(0, SEEK_CUR)\n+    }\n+    fn fsync(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        FsRequest::fsync(&self.loop_, self.fd).map_err(uv_error_to_io_error)\n+    }\n+    fn datasync(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        FsRequest::datasync(&self.loop_, self.fd).map_err(uv_error_to_io_error)\n+    }\n+    fn truncate(&mut self, offset: i64) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        let r = FsRequest::truncate(&self.loop_, self.fd, offset);\n+        r.map_err(uv_error_to_io_error)\n+    }\n }\n \n #[cfg(test)]\n mod test {\n-    use super::*;\n-    //use std::rt::test::*;\n-    use std::libc::{STDOUT_FILENO, c_int};\n-    use std::vec;\n-    use std::str;\n-    use std::unstable::run_in_bare_thread;\n-    use super::super::{Loop, Buf, slice_to_uv_buf};\n+    use std::libc::c_int;\n     use std::libc::{O_CREAT, O_RDWR, O_RDONLY, S_IWUSR, S_IRUSR};\n-\n-    #[test]\n-    fn file_test_full_simple() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let create_flags = O_RDWR | O_CREAT;\n-            let read_flags = O_RDONLY;\n-            // 0644 BZZT! WRONG! 0600! See below.\n-            let mode = S_IWUSR |S_IRUSR;\n-                // these aren't defined in std::libc :(\n-                //map_mode(S_IRGRP) |\n-                //map_mode(S_IROTH);\n-            let path_str = \"./tmp/file_full_simple.txt\";\n-            let write_val = \"hello\".as_bytes().to_owned();\n-            let write_buf  = slice_to_uv_buf(write_val);\n-            let write_buf_ptr: *Buf = &write_buf;\n-            let read_buf_len = 1028;\n-            let read_mem = vec::from_elem(read_buf_len, 0u8);\n-            let read_buf = slice_to_uv_buf(read_mem);\n-            let read_buf_ptr: *Buf = &read_buf;\n-            let open_req = FsRequest::new();\n-            do open_req.open(&loop_, &path_str.to_c_str(), create_flags as int,\n-                             mode as int) |req, uverr| {\n-                assert!(uverr.is_none());\n-                let fd = req.get_result();\n-                let buf = unsafe { *write_buf_ptr };\n-                let write_req = FsRequest::new();\n-                do write_req.write(&req.get_loop(), fd, buf, -1) |req, uverr| {\n-                    let close_req = FsRequest::new();\n-                    do close_req.close(&req.get_loop(), fd) |req, _| {\n-                        assert!(uverr.is_none());\n-                        let loop_ = req.get_loop();\n-                        let open_req = FsRequest::new();\n-                        do open_req.open(&loop_, &path_str.to_c_str(),\n-                                         read_flags as int,0) |req, uverr| {\n-                            assert!(uverr.is_none());\n-                            let loop_ = req.get_loop();\n-                            let fd = req.get_result();\n-                            let read_buf = unsafe { *read_buf_ptr };\n-                            let read_req = FsRequest::new();\n-                            do read_req.read(&loop_, fd, read_buf, 0) |req, uverr| {\n-                                assert!(uverr.is_none());\n-                                let loop_ = req.get_loop();\n-                                // we know nread >=0 because uverr is none..\n-                                let nread = req.get_result() as uint;\n-                                // nread == 0 would be EOF\n-                                if nread > 0 {\n-                                    let read_str = unsafe {\n-                                        let read_buf = *read_buf_ptr;\n-                                        str::from_utf8(\n-                                            vec::from_buf(\n-                                                read_buf.base, nread))\n-                                    };\n-                                    assert!(read_str == ~\"hello\");\n-                                    let close_req = FsRequest::new();\n-                                    do close_req.close(&loop_, fd) |req,uverr| {\n-                                        assert!(uverr.is_none());\n-                                        let loop_ = &req.get_loop();\n-                                        let unlink_req = FsRequest::new();\n-                                        do unlink_req.unlink(loop_,\n-                                                             &path_str.to_c_str())\n-                                        |_,uverr| {\n-                                            assert!(uverr.is_none());\n-                                        };\n-                                    };\n-                                };\n-                            };\n-                        };\n-                    };\n-                };\n-            };\n-            loop_.run();\n-            loop_.close();\n-        }\n-    }\n+    use std::rt::io;\n+    use std::str;\n+    use std::vec;\n+    use super::*;\n+    use l = super::super::local_loop;\n \n     #[test]\n     fn file_test_full_simple_sync() {\n-        do run_in_bare_thread {\n-            // setup\n-            let mut loop_ = Loop::new();\n-            let create_flags = O_RDWR |\n-                O_CREAT;\n-            let read_flags = O_RDONLY;\n-            // 0644\n-            let mode = S_IWUSR |\n-                S_IRUSR;\n-                //S_IRGRP |\n-                //S_IROTH;\n-            let path_str = \"./tmp/file_full_simple_sync.txt\";\n-            let write_val = \"hello\".as_bytes().to_owned();\n-            let write_buf = slice_to_uv_buf(write_val);\n+        let create_flags = O_RDWR | O_CREAT;\n+        let read_flags = O_RDONLY;\n+        let mode = S_IWUSR | S_IRUSR;\n+        let path_str = \"./tmp/file_full_simple_sync.txt\";\n+\n+        {\n             // open/create\n-            let open_req = FsRequest::new();\n-            let result = open_req.open_sync(&loop_, &path_str.to_c_str(),\n-                                            create_flags as int, mode as int);\n+            let result = FsRequest::open(l(), &path_str.to_c_str(),\n+                                         create_flags as int, mode as int);\n             assert!(result.is_ok());\n-            let fd = result.unwrap();\n+            let result = result.unwrap();\n+            let fd = result.fd;\n+\n             // write\n-            let write_req = FsRequest::new();\n-            let result = write_req.write_sync(&loop_, fd, write_buf, -1);\n-            assert!(result.is_ok());\n-            // close\n-            let close_req = FsRequest::new();\n-            let result = close_req.close_sync(&loop_, fd);\n+            let result = FsRequest::write(l(), fd, \"hello\".as_bytes(), -1);\n             assert!(result.is_ok());\n+        }\n+\n+        {\n             // re-open\n-            let open_req = FsRequest::new();\n-            let result = open_req.open_sync(&loop_, &path_str.to_c_str(),\n-                                                   read_flags as int,0);\n+            let result = FsRequest::open(l(), &path_str.to_c_str(),\n+                                         read_flags as int, 0);\n             assert!(result.is_ok());\n-            let len = 1028;\n-            let fd = result.unwrap();\n+            let result = result.unwrap();\n+            let fd = result.fd;\n+\n             // read\n-            let read_mem: ~[u8] = vec::from_elem(len, 0u8);\n-            let buf = slice_to_uv_buf(read_mem);\n-            let read_req = FsRequest::new();\n-            let result = read_req.read_sync(&loop_, fd, buf, 0);\n+            let mut read_mem = vec::from_elem(1000, 0u8);\n+            let result = FsRequest::read(l(), fd, read_mem, 0);\n             assert!(result.is_ok());\n+\n             let nread = result.unwrap();\n-            // nread == 0 would be EOF.. we know it's >= zero because otherwise\n-            // the above assert would fail\n-            if nread > 0 {\n-                let read_str = str::from_utf8(\n-                    read_mem.slice(0, nread as uint));\n-                assert!(read_str == ~\"hello\");\n-                // close\n-                let close_req = FsRequest::new();\n-                let result = close_req.close_sync(&loop_, fd);\n-                assert!(result.is_ok());\n-                // unlink\n-                let unlink_req = FsRequest::new();\n-                let result = unlink_req.unlink_sync(&loop_, &path_str.to_c_str());\n-                assert!(result.is_ok());\n-            } else { fail!(\"nread was 0.. wudn't expectin' that.\"); }\n-            loop_.close();\n+            assert!(nread > 0);\n+            let read_str = str::from_utf8(read_mem.slice(0, nread as uint));\n+            assert_eq!(read_str, ~\"hello\");\n         }\n+        // unlink\n+        let result = FsRequest::unlink(l(), &path_str.to_c_str());\n+        assert!(result.is_ok());\n     }\n \n-    fn naive_print(loop_: &Loop, input: &str) {\n-        let write_val = input.as_bytes();\n-        let write_buf = slice_to_uv_buf(write_val);\n-        let write_req = FsRequest::new();\n-        write_req.write_sync(loop_, STDOUT_FILENO, write_buf, -1);\n-    }\n-\n-    #[test]\n-    fn file_test_write_to_stdout() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            naive_print(&loop_, \"zanzibar!\\n\");\n-            loop_.run();\n-            loop_.close();\n-        };\n-    }\n     #[test]\n-    fn file_test_stat_simple() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let path = \"./tmp/file_test_stat_simple.txt\";\n-            let create_flags = O_RDWR |\n-                O_CREAT;\n-            let mode = S_IWUSR |\n-                S_IRUSR;\n-            let write_val = \"hello\".as_bytes().to_owned();\n-            let write_buf  = slice_to_uv_buf(write_val);\n-            let write_buf_ptr: *Buf = &write_buf;\n-            let open_req = FsRequest::new();\n-            do open_req.open(&loop_, &path.to_c_str(), create_flags as int,\n-                             mode as int) |req, uverr| {\n-                assert!(uverr.is_none());\n-                let fd = req.get_result();\n-                let buf = unsafe { *write_buf_ptr };\n-                let write_req = FsRequest::new();\n-                do write_req.write(&req.get_loop(), fd, buf, 0) |req, uverr| {\n-                    assert!(uverr.is_none());\n-                    let loop_ = req.get_loop();\n-                    let stat_req = FsRequest::new();\n-                    do stat_req.stat(&loop_, &path.to_c_str()) |req, uverr| {\n-                        assert!(uverr.is_none());\n-                        let loop_ = req.get_loop();\n-                        let stat = req.get_stat();\n-                        let sz: uint = stat.st_size as uint;\n-                        assert!(sz > 0);\n-                        let close_req = FsRequest::new();\n-                        do close_req.close(&loop_, fd) |req, uverr| {\n-                            assert!(uverr.is_none());\n-                            let loop_ = req.get_loop();\n-                            let unlink_req = FsRequest::new();\n-                            do unlink_req.unlink(&loop_,\n-                                                 &path.to_c_str()) |req,uverr| {\n-                                assert!(uverr.is_none());\n-                                let loop_ = req.get_loop();\n-                                let stat_req = FsRequest::new();\n-                                do stat_req.stat(&loop_,\n-                                                 &path.to_c_str()) |_, uverr| {\n-                                    // should cause an error because the\n-                                    // file doesn't exist anymore\n-                                    assert!(uverr.is_some());\n-                                };\n-                            };\n-                        };\n-                    };\n-                };\n-            };\n-            loop_.run();\n-            loop_.close();\n-        }\n+    fn file_test_stat() {\n+        let path = &\"./tmp/file_test_stat_simple\".to_c_str();\n+        let create_flags = (O_RDWR | O_CREAT) as int;\n+        let mode = (S_IWUSR | S_IRUSR) as int;\n+\n+        let result = FsRequest::open(l(), path, create_flags, mode);\n+        assert!(result.is_ok());\n+        let file = result.unwrap();\n+\n+        let result = FsRequest::write(l(), file.fd, \"hello\".as_bytes(), 0);\n+        assert!(result.is_ok());\n+\n+        let result = FsRequest::stat(l(), path);\n+        assert!(result.is_ok());\n+        assert_eq!(result.unwrap().size, 5);\n+\n+        fn free<T>(_: T) {}\n+        free(file);\n+\n+        let result = FsRequest::unlink(l(), path);\n+        assert!(result.is_ok());\n     }\n \n     #[test]\n     fn file_test_mk_rm_dir() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let path = \"./tmp/mk_rm_dir\";\n-            let mode = S_IWUSR |\n-                S_IRUSR;\n-            let mkdir_req = FsRequest::new();\n-            do mkdir_req.mkdir(&loop_, &path.to_c_str(),\n-                               mode as c_int) |req,uverr| {\n-                assert!(uverr.is_none());\n-                let loop_ = req.get_loop();\n-                let stat_req = FsRequest::new();\n-                do stat_req.stat(&loop_, &path.to_c_str()) |req, uverr| {\n-                    assert!(uverr.is_none());\n-                    let loop_ = req.get_loop();\n-                    let stat = req.get_stat();\n-                    naive_print(&loop_, format!(\"{:?}\", stat));\n-                    assert!(stat.is_dir());\n-                    let rmdir_req = FsRequest::new();\n-                    do rmdir_req.rmdir(&loop_, &path.to_c_str()) |req,uverr| {\n-                        assert!(uverr.is_none());\n-                        let loop_ = req.get_loop();\n-                        let stat_req = FsRequest::new();\n-                        do stat_req.stat(&loop_, &path.to_c_str()) |_req, uverr| {\n-                            assert!(uverr.is_some());\n-                        }\n-                    }\n-                }\n-            }\n-            loop_.run();\n-            loop_.close();\n-        }\n+        let path = &\"./tmp/mk_rm_dir\".to_c_str();\n+        let mode = S_IWUSR | S_IRUSR;\n+\n+        let result = FsRequest::mkdir(l(), path, mode);\n+        assert!(result.is_ok());\n+\n+        let result = FsRequest::stat(l(), path);\n+        assert!(result.is_ok());\n+        assert!(result.unwrap().kind == io::TypeDirectory);\n+\n+        let result = FsRequest::rmdir(l(), path);\n+        assert!(result.is_ok());\n+\n+        let result = FsRequest::stat(l(), path);\n+        assert!(result.is_err());\n     }\n+\n     #[test]\n     fn file_test_mkdir_chokes_on_double_create() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let path = \"./tmp/double_create_dir\";\n-            let mode = S_IWUSR |\n-                S_IRUSR;\n-            let mkdir_req = FsRequest::new();\n-            do mkdir_req.mkdir(&loop_, &path.to_c_str(), mode as c_int) |req,uverr| {\n-                assert!(uverr.is_none());\n-                let loop_ = req.get_loop();\n-                let mkdir_req = FsRequest::new();\n-                do mkdir_req.mkdir(&loop_, &path.to_c_str(),\n-                                   mode as c_int) |req,uverr| {\n-                    assert!(uverr.is_some());\n-                    let loop_ = req.get_loop();\n-                    let _stat = req.get_stat();\n-                    let rmdir_req = FsRequest::new();\n-                    do rmdir_req.rmdir(&loop_, &path.to_c_str()) |req,uverr| {\n-                        assert!(uverr.is_none());\n-                        let _loop = req.get_loop();\n-                    }\n-                }\n-            }\n-            loop_.run();\n-            loop_.close();\n-        }\n+        let path = &\"./tmp/double_create_dir\".to_c_str();\n+        let mode = S_IWUSR | S_IRUSR;\n+\n+        let result = FsRequest::stat(l(), path);\n+        assert!(result.is_err(), \"{:?}\", result);\n+        let result = FsRequest::mkdir(l(), path, mode as c_int);\n+        assert!(result.is_ok(), \"{:?}\", result);\n+        let result = FsRequest::mkdir(l(), path, mode as c_int);\n+        assert!(result.is_err(), \"{:?}\", result);\n+        let result = FsRequest::rmdir(l(), path);\n+        assert!(result.is_ok(), \"{:?}\", result);\n     }\n+\n     #[test]\n     fn file_test_rmdir_chokes_on_nonexistant_path() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let path = \"./tmp/never_existed_dir\";\n-            let rmdir_req = FsRequest::new();\n-            do rmdir_req.rmdir(&loop_, &path.to_c_str()) |_req, uverr| {\n-                assert!(uverr.is_some());\n-            }\n-            loop_.run();\n-            loop_.close();\n-        }\n+        let path = &\"./tmp/never_existed_dir\".to_c_str();\n+        let result = FsRequest::rmdir(l(), path);\n+        assert!(result.is_err());\n     }\n }"}, {"sha": "80481498881c49440c515f0eddd6e40f5c4a1d8e", "filename": "src/librustuv/idle.rs", "status": "modified", "additions": 122, "deletions": 91, "changes": 213, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fidle.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fidle.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fidle.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,130 +8,161 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::libc::c_int;\n+use std::cast;\n+use std::libc::{c_int, c_void};\n \n use uvll;\n-use super::{Watcher, Loop, NativeHandle, IdleCallback, status_to_maybe_uv_error};\n-\n-pub struct IdleWatcher(*uvll::uv_idle_t);\n-impl Watcher for IdleWatcher { }\n+use super::{Loop, UvHandle};\n+use std::rt::rtio::{Callback, PausibleIdleCallback};\n+\n+pub struct IdleWatcher {\n+    handle: *uvll::uv_idle_t,\n+    idle_flag: bool,\n+    closed: bool,\n+    callback: ~Callback,\n+}\n \n impl IdleWatcher {\n-    pub fn new(loop_: &mut Loop) -> IdleWatcher {\n+    pub fn new(loop_: &mut Loop, cb: ~Callback) -> ~IdleWatcher {\n+        let handle = UvHandle::alloc(None::<IdleWatcher>, uvll::UV_IDLE);\n+        assert_eq!(unsafe {\n+            uvll::uv_idle_init(loop_.handle, handle)\n+        }, 0);\n+        let me = ~IdleWatcher {\n+            handle: handle,\n+            idle_flag: false,\n+            closed: false,\n+            callback: cb,\n+        };\n+        return me.install();\n+    }\n+\n+    pub fn onetime(loop_: &mut Loop, f: proc()) {\n+        let handle = UvHandle::alloc(None::<IdleWatcher>, uvll::UV_IDLE);\n         unsafe {\n-            let handle = uvll::malloc_handle(uvll::UV_IDLE);\n-            assert!(handle.is_not_null());\n-            assert_eq!(uvll::idle_init(loop_.native_handle(), handle), 0);\n-            let mut watcher: IdleWatcher = NativeHandle::from_native_handle(handle);\n-            watcher.install_watcher_data();\n-            return watcher\n+            assert_eq!(uvll::uv_idle_init(loop_.handle, handle), 0);\n+            let data: *c_void = cast::transmute(~f);\n+            uvll::set_data_for_uv_handle(handle, data);\n+            assert_eq!(uvll::uv_idle_start(handle, onetime_cb), 0)\n         }\n-    }\n \n-    pub fn start(&mut self, cb: IdleCallback) {\n-        {\n-            let data = self.get_watcher_data();\n-            data.idle_cb = Some(cb);\n+        extern fn onetime_cb(handle: *uvll::uv_idle_t, status: c_int) {\n+            assert_eq!(status, 0);\n+            unsafe {\n+                let data = uvll::get_data_for_uv_handle(handle);\n+                let f: ~proc() = cast::transmute(data);\n+                (*f)();\n+                uvll::uv_idle_stop(handle);\n+                uvll::uv_close(handle, close_cb);\n+            }\n         }\n \n-        unsafe {\n-            assert_eq!(uvll::idle_start(self.native_handle(), idle_cb), 0)\n+        extern fn close_cb(handle: *uvll::uv_handle_t) {\n+            unsafe { uvll::free_handle(handle) }\n         }\n     }\n+}\n \n-    pub fn restart(&mut self) {\n-        unsafe {\n-            assert!(self.get_watcher_data().idle_cb.is_some());\n-            assert_eq!(uvll::idle_start(self.native_handle(), idle_cb), 0)\n+impl PausibleIdleCallback for IdleWatcher {\n+    fn pause(&mut self) {\n+        if self.idle_flag == true {\n+            assert_eq!(unsafe {uvll::uv_idle_stop(self.handle) }, 0);\n+            self.idle_flag = false;\n         }\n     }\n-\n-    pub fn stop(&mut self) {\n-        // NB: Not resetting the Rust idle_cb to None here because `stop` is\n-        // likely called from *within* the idle callback, causing a use after\n-        // free\n-\n-        unsafe {\n-            assert_eq!(uvll::idle_stop(self.native_handle()), 0);\n+    fn resume(&mut self) {\n+        if self.idle_flag == false {\n+            assert_eq!(unsafe { uvll::uv_idle_start(self.handle, idle_cb) }, 0)\n+            self.idle_flag = true;\n         }\n     }\n }\n \n-impl NativeHandle<*uvll::uv_idle_t> for IdleWatcher {\n-    fn from_native_handle(handle: *uvll::uv_idle_t) -> IdleWatcher {\n-        IdleWatcher(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_idle_t {\n-        match self { &IdleWatcher(ptr) => ptr }\n-    }\n+impl UvHandle<uvll::uv_idle_t> for IdleWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_idle_t { self.handle }\n }\n \n extern fn idle_cb(handle: *uvll::uv_idle_t, status: c_int) {\n-    let mut idle_watcher: IdleWatcher = NativeHandle::from_native_handle(handle);\n-    let data = idle_watcher.get_watcher_data();\n-    let cb: &IdleCallback = data.idle_cb.get_ref();\n-    let status = status_to_maybe_uv_error(status);\n-    (*cb)(idle_watcher, status);\n+    assert_eq!(status, 0);\n+    let idle: &mut IdleWatcher = unsafe { UvHandle::from_uv_handle(&handle) };\n+    idle.callback.call();\n+}\n+\n+impl Drop for IdleWatcher {\n+    fn drop(&mut self) {\n+        self.pause();\n+        self.close_async_();\n+    }\n }\n \n #[cfg(test)]\n mod test {\n-\n-    use Loop;\n     use super::*;\n-    use std::unstable::run_in_bare_thread;\n+    use std::rt::tube::Tube;\n+    use std::rt::rtio::{Callback, PausibleIdleCallback};\n+    use super::super::local_loop;\n+\n+    struct MyCallback(Tube<int>, int);\n+    impl Callback for MyCallback {\n+        fn call(&mut self) {\n+            match *self {\n+                MyCallback(ref mut tube, val) => tube.send(val)\n+            }\n+        }\n+    }\n \n     #[test]\n-    #[ignore(reason = \"valgrind - loop destroyed before watcher?\")]\n-    fn idle_new_then_close() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let idle_watcher = { IdleWatcher::new(&mut loop_) };\n-            idle_watcher.close(||());\n-        }\n+    fn not_used() {\n+        let cb = ~MyCallback(Tube::new(), 1);\n+        let _idle = IdleWatcher::new(local_loop(), cb as ~Callback);\n     }\n \n     #[test]\n-    fn idle_smoke_test() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n-            let mut count = 10;\n-            let count_ptr: *mut int = &mut count;\n-            do idle_watcher.start |idle_watcher, status| {\n-                let mut idle_watcher = idle_watcher;\n-                assert!(status.is_none());\n-                if unsafe { *count_ptr == 10 } {\n-                    idle_watcher.stop();\n-                    idle_watcher.close(||());\n-                } else {\n-                    unsafe { *count_ptr = *count_ptr + 1; }\n-                }\n-            }\n-            loop_.run();\n-            loop_.close();\n-            assert_eq!(count, 10);\n-        }\n+    fn smoke_test() {\n+        let mut tube = Tube::new();\n+        let cb = ~MyCallback(tube.clone(), 1);\n+        let mut idle = IdleWatcher::new(local_loop(), cb as ~Callback);\n+        idle.resume();\n+        tube.recv();\n+    }\n+\n+    #[test] #[should_fail]\n+    fn smoke_fail() {\n+        let tube = Tube::new();\n+        let cb = ~MyCallback(tube.clone(), 1);\n+        let mut idle = IdleWatcher::new(local_loop(), cb as ~Callback);\n+        idle.resume();\n+        fail!();\n     }\n \n     #[test]\n-    fn idle_start_stop_start() {\n-        do run_in_bare_thread {\n-            let mut loop_ = Loop::new();\n-            let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n-            do idle_watcher.start |idle_watcher, status| {\n-                let mut idle_watcher = idle_watcher;\n-                assert!(status.is_none());\n-                idle_watcher.stop();\n-                do idle_watcher.start |idle_watcher, status| {\n-                    assert!(status.is_none());\n-                    let mut idle_watcher = idle_watcher;\n-                    idle_watcher.stop();\n-                    idle_watcher.close(||());\n-                }\n-            }\n-            loop_.run();\n-            loop_.close();\n-        }\n+    fn fun_combinations_of_methods() {\n+        let mut tube = Tube::new();\n+        let cb = ~MyCallback(tube.clone(), 1);\n+        let mut idle = IdleWatcher::new(local_loop(), cb as ~Callback);\n+        idle.resume();\n+        tube.recv();\n+        idle.pause();\n+        idle.resume();\n+        idle.resume();\n+        tube.recv();\n+        idle.pause();\n+        idle.pause();\n+        idle.resume();\n+        tube.recv();\n+    }\n+\n+    #[test]\n+    fn pause_pauses() {\n+        let mut tube = Tube::new();\n+        let cb = ~MyCallback(tube.clone(), 1);\n+        let mut idle1 = IdleWatcher::new(local_loop(), cb as ~Callback);\n+        let cb = ~MyCallback(tube.clone(), 2);\n+        let mut idle2 = IdleWatcher::new(local_loop(), cb as ~Callback);\n+        idle2.resume();\n+        assert_eq!(tube.recv(), 2);\n+        idle2.pause();\n+        idle1.resume();\n+        assert_eq!(tube.recv(), 1);\n     }\n }"}, {"sha": "edb1953b9b1c39b2716f2e980c55ea69f83a908c", "filename": "src/librustuv/lib.rs", "status": "modified", "additions": 214, "deletions": 201, "changes": 415, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Flib.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -45,29 +45,31 @@ via `close` and `delete` methods.\n \n #[feature(macro_rules, globs)];\n \n-use std::str::raw::from_c_str;\n-use std::vec;\n-use std::ptr;\n-use std::str;\n-use std::libc::{c_void, c_int, size_t, malloc, free};\n use std::cast::transmute;\n+use std::cast;\n+use std::libc::{c_int, malloc};\n use std::ptr::null;\n+use std::ptr;\n+use std::rt::BlockedTask;\n+use std::rt::local::Local;\n+use std::rt::sched::Scheduler;\n+use std::str::raw::from_c_str;\n+use std::str;\n+use std::task;\n use std::unstable::finally::Finally;\n-use std::rt::io::net::ip::SocketAddr;\n-use std::rt::io::signal::Signum;\n+use std::vec;\n \n use std::rt::io::IoError;\n \n-//#[cfg(test)] use unstable::run_in_bare_thread;\n-\n-pub use self::file::{FsRequest};\n-pub use self::net::{StreamWatcher, TcpWatcher, UdpWatcher};\n-pub use self::idle::IdleWatcher;\n-pub use self::timer::TimerWatcher;\n pub use self::async::AsyncWatcher;\n+pub use self::file::{FsRequest, FileWatcher};\n+pub use self::idle::IdleWatcher;\n+pub use self::net::{TcpWatcher, TcpListener, TcpAcceptor, UdpWatcher};\n+pub use self::pipe::{PipeWatcher, PipeListener, PipeAcceptor};\n pub use self::process::Process;\n-pub use self::pipe::Pipe;\n pub use self::signal::SignalWatcher;\n+pub use self::timer::TimerWatcher;\n+pub use self::tty::TtyWatcher;\n \n mod macros;\n \n@@ -87,177 +89,194 @@ pub mod process;\n pub mod pipe;\n pub mod tty;\n pub mod signal;\n+pub mod stream;\n \n-/// XXX: Loop(*handle) is buggy with destructors. Normal structs\n-/// with dtors may not be destructured, but tuple structs can,\n-/// but the results are not correct.\n-pub struct Loop {\n-    priv handle: *uvll::uv_loop_t\n-}\n+/// A type that wraps a uv handle\n+pub trait UvHandle<T> {\n+    fn uv_handle(&self) -> *T;\n \n-pub struct Handle(*uvll::uv_handle_t);\n+    // FIXME(#8888) dummy self\n+    fn alloc(_: Option<Self>, ty: uvll::uv_handle_type) -> *T {\n+        unsafe {\n+            let handle = uvll::malloc_handle(ty);\n+            assert!(!handle.is_null());\n+            handle as *T\n+        }\n+    }\n \n-impl Watcher for Handle {}\n-impl NativeHandle<*uvll::uv_handle_t> for Handle {\n-    fn from_native_handle(h: *uvll::uv_handle_t) -> Handle { Handle(h) }\n-    fn native_handle(&self) -> *uvll::uv_handle_t { **self }\n-}\n+    unsafe fn from_uv_handle<'a>(h: &'a *T) -> &'a mut Self {\n+        cast::transmute(uvll::get_data_for_uv_handle(*h))\n+    }\n \n-/// The trait implemented by uv 'watchers' (handles). Watchers are\n-/// non-owning wrappers around the uv handles and are not completely\n-/// safe - there may be multiple instances for a single underlying\n-/// handle.  Watchers are generally created, then `start`ed, `stop`ed\n-/// and `close`ed, but due to their complex life cycle may not be\n-/// entirely memory safe if used in unanticipated patterns.\n-pub trait Watcher { }\n+    fn install(~self) -> ~Self {\n+        unsafe {\n+            let myptr = cast::transmute::<&~Self, &*u8>(&self);\n+            uvll::set_data_for_uv_handle(self.uv_handle(), *myptr);\n+        }\n+        self\n+    }\n \n-pub trait Request { }\n+    fn close_async_(&mut self) {\n+        // we used malloc to allocate all handles, so we must always have at\n+        // least a callback to free all the handles we allocated.\n+        extern fn close_cb(handle: *uvll::uv_handle_t) {\n+            unsafe { uvll::free_handle(handle) }\n+        }\n \n-/// A type that wraps a native handle\n-pub trait NativeHandle<T> {\n-    fn from_native_handle(T) -> Self;\n-    fn native_handle(&self) -> T;\n-}\n+        unsafe {\n+            uvll::set_data_for_uv_handle(self.uv_handle(), null::<()>());\n+            uvll::uv_close(self.uv_handle() as *uvll::uv_handle_t, close_cb)\n+        }\n+    }\n \n-impl Loop {\n-    pub fn new() -> Loop {\n-        let handle = unsafe { uvll::loop_new() };\n-        assert!(handle.is_not_null());\n-        NativeHandle::from_native_handle(handle)\n+    fn close(&mut self) {\n+        let mut slot = None;\n+\n+        unsafe {\n+            uvll::uv_close(self.uv_handle() as *uvll::uv_handle_t, close_cb);\n+            uvll::set_data_for_uv_handle(self.uv_handle(), ptr::null::<()>());\n+\n+            do wait_until_woken_after(&mut slot) {\n+                uvll::set_data_for_uv_handle(self.uv_handle(), &slot);\n+            }\n+        }\n+\n+        extern fn close_cb(handle: *uvll::uv_handle_t) {\n+            unsafe {\n+                let data = uvll::get_data_for_uv_handle(handle);\n+                uvll::free_handle(handle);\n+                if data == ptr::null() { return }\n+                let slot: &mut Option<BlockedTask> = cast::transmute(data);\n+                let sched: ~Scheduler = Local::take();\n+                sched.resume_blocked_task_immediately(slot.take_unwrap());\n+            }\n+        }\n     }\n+}\n \n-    pub fn run(&mut self) {\n-        unsafe { uvll::run(self.native_handle()) };\n+pub struct ForbidSwitch {\n+    msg: &'static str,\n+    sched: uint,\n+}\n+\n+impl ForbidSwitch {\n+    fn new(s: &'static str) -> ForbidSwitch {\n+        ForbidSwitch {\n+            msg: s, sched: Local::borrow(|s: &mut Scheduler| s.sched_id())\n+        }\n     }\n+}\n \n-    pub fn close(&mut self) {\n-        unsafe { uvll::loop_delete(self.native_handle()) };\n+impl Drop for ForbidSwitch {\n+    fn drop(&mut self) {\n+        assert!(self.sched == Local::borrow(|s: &mut Scheduler| s.sched_id()),\n+                \"didnt want a scheduler switch: {}\", self.msg);\n     }\n }\n \n-impl NativeHandle<*uvll::uv_loop_t> for Loop {\n-    fn from_native_handle(handle: *uvll::uv_loop_t) -> Loop {\n-        Loop { handle: handle }\n+pub struct ForbidUnwind {\n+    msg: &'static str,\n+    failing_before: bool,\n+}\n+\n+impl ForbidUnwind {\n+    fn new(s: &'static str) -> ForbidUnwind {\n+        ForbidUnwind {\n+            msg: s, failing_before: task::failing(),\n+        }\n     }\n-    fn native_handle(&self) -> *uvll::uv_loop_t {\n-        self.handle\n+}\n+\n+impl Drop for ForbidUnwind {\n+    fn drop(&mut self) {\n+        assert!(self.failing_before == task::failing(),\n+                \"didnt want an unwind during: {}\", self.msg);\n     }\n }\n \n-// XXX: The uv alloc callback also has a *uv_handle_t arg\n-pub type AllocCallback = ~fn(uint) -> Buf;\n-pub type ReadCallback = ~fn(StreamWatcher, int, Buf, Option<UvError>);\n-pub type NullCallback = ~fn();\n-pub type IdleCallback = ~fn(IdleWatcher, Option<UvError>);\n-pub type ConnectionCallback = ~fn(StreamWatcher, Option<UvError>);\n-pub type FsCallback = ~fn(&mut FsRequest, Option<UvError>);\n-// first int is exit_status, second is term_signal\n-pub type ExitCallback = ~fn(Process, int, int, Option<UvError>);\n-pub type TimerCallback = ~fn(TimerWatcher, Option<UvError>);\n-pub type AsyncCallback = ~fn(AsyncWatcher, Option<UvError>);\n-pub type UdpReceiveCallback = ~fn(UdpWatcher, int, Buf, SocketAddr, uint, Option<UvError>);\n-pub type UdpSendCallback = ~fn(UdpWatcher, Option<UvError>);\n-pub type SignalCallback = ~fn(SignalWatcher, Signum);\n-\n-\n-/// Callbacks used by StreamWatchers, set as custom data on the foreign handle.\n-/// XXX: Would be better not to have all watchers allocate room for all callback types.\n-struct WatcherData {\n-    read_cb: Option<ReadCallback>,\n-    write_cb: Option<ConnectionCallback>,\n-    connect_cb: Option<ConnectionCallback>,\n-    close_cb: Option<NullCallback>,\n-    alloc_cb: Option<AllocCallback>,\n-    idle_cb: Option<IdleCallback>,\n-    timer_cb: Option<TimerCallback>,\n-    async_cb: Option<AsyncCallback>,\n-    udp_recv_cb: Option<UdpReceiveCallback>,\n-    udp_send_cb: Option<UdpSendCallback>,\n-    exit_cb: Option<ExitCallback>,\n-    signal_cb: Option<SignalCallback>,\n+fn wait_until_woken_after(slot: *mut Option<BlockedTask>, f: &fn()) {\n+    let _f = ForbidUnwind::new(\"wait_until_woken_after\");\n+    unsafe {\n+        assert!((*slot).is_none());\n+        let sched: ~Scheduler = Local::take();\n+        do sched.deschedule_running_task_and_then |_, task| {\n+            f();\n+            *slot = Some(task);\n+        }\n+    }\n }\n \n-pub trait WatcherInterop {\n-    fn event_loop(&self) -> Loop;\n-    fn install_watcher_data(&mut self);\n-    fn get_watcher_data<'r>(&'r mut self) -> &'r mut WatcherData;\n-    fn drop_watcher_data(&mut self);\n-    fn close(self, cb: NullCallback);\n-    fn close_async(self);\n+pub struct Request {\n+    handle: *uvll::uv_req_t,\n+    priv defused: bool,\n }\n \n-impl<H, W: Watcher + NativeHandle<*H>> WatcherInterop for W {\n-    /// Get the uv event loop from a Watcher\n-    fn event_loop(&self) -> Loop {\n+impl Request {\n+    pub fn new(ty: uvll::uv_req_type) -> Request {\n         unsafe {\n-            let handle = self.native_handle();\n-            let loop_ = uvll::get_loop_for_uv_handle(handle);\n-            NativeHandle::from_native_handle(loop_)\n+            let handle = uvll::malloc_req(ty);\n+            uvll::set_data_for_req(handle, null::<()>());\n+            Request::wrap(handle)\n         }\n     }\n \n-    fn install_watcher_data(&mut self) {\n-        unsafe {\n-            let data = ~WatcherData {\n-                read_cb: None,\n-                write_cb: None,\n-                connect_cb: None,\n-                close_cb: None,\n-                alloc_cb: None,\n-                idle_cb: None,\n-                timer_cb: None,\n-                async_cb: None,\n-                udp_recv_cb: None,\n-                udp_send_cb: None,\n-                exit_cb: None,\n-                signal_cb: None,\n-            };\n-            let data = transmute::<~WatcherData, *c_void>(data);\n-            uvll::set_data_for_uv_handle(self.native_handle(), data);\n-        }\n+    pub fn wrap(handle: *uvll::uv_req_t) -> Request {\n+        Request { handle: handle, defused: false }\n     }\n \n-    fn get_watcher_data<'r>(&'r mut self) -> &'r mut WatcherData {\n-        unsafe {\n-            let data = uvll::get_data_for_uv_handle(self.native_handle());\n-            let data = transmute::<&*c_void, &mut ~WatcherData>(&data);\n-            return &mut **data;\n-        }\n+    pub fn set_data<T>(&self, t: *T) {\n+        unsafe { uvll::set_data_for_req(self.handle, t) }\n     }\n \n-    fn drop_watcher_data(&mut self) {\n-        unsafe {\n-            let data = uvll::get_data_for_uv_handle(self.native_handle());\n-            let _data = transmute::<*c_void, ~WatcherData>(data);\n-            uvll::set_data_for_uv_handle(self.native_handle(), null::<()>());\n-        }\n+    pub unsafe fn get_data<T>(&self) -> &'static mut T {\n+        let data = uvll::get_data_for_req(self.handle);\n+        assert!(data != null());\n+        cast::transmute(data)\n+    }\n+\n+    // This function should be used when the request handle has been given to an\n+    // underlying uv function, and the uv function has succeeded. This means\n+    // that uv will at some point invoke the callback, and in the meantime we\n+    // can't deallocate the handle because libuv could be using it.\n+    //\n+    // This is still a problem in blocking situations due to linked failure. In\n+    // the connection callback the handle should be re-wrapped with the `wrap`\n+    // function to ensure its destruction.\n+    pub fn defuse(&mut self) {\n+        self.defused = true;\n     }\n+}\n \n-    fn close(mut self, cb: NullCallback) {\n-        {\n-            let data = self.get_watcher_data();\n-            assert!(data.close_cb.is_none());\n-            data.close_cb = Some(cb);\n+impl Drop for Request {\n+    fn drop(&mut self) {\n+        if !self.defused {\n+            unsafe { uvll::free_req(self.handle) }\n         }\n+    }\n+}\n \n-        unsafe { uvll::close(self.native_handle(), close_cb); }\n+/// XXX: Loop(*handle) is buggy with destructors. Normal structs\n+/// with dtors may not be destructured, but tuple structs can,\n+/// but the results are not correct.\n+pub struct Loop {\n+    priv handle: *uvll::uv_loop_t\n+}\n \n-        extern fn close_cb(handle: *uvll::uv_handle_t) {\n-            let mut h: Handle = NativeHandle::from_native_handle(handle);\n-            h.get_watcher_data().close_cb.take_unwrap()();\n-            h.drop_watcher_data();\n-            unsafe { uvll::free_handle(handle as *c_void) }\n-        }\n+impl Loop {\n+    pub fn new() -> Loop {\n+        let handle = unsafe { uvll::loop_new() };\n+        assert!(handle.is_not_null());\n+        Loop::wrap(handle)\n     }\n \n-    fn close_async(self) {\n-        unsafe { uvll::close(self.native_handle(), close_cb); }\n+    pub fn wrap(handle: *uvll::uv_loop_t) -> Loop { Loop { handle: handle } }\n \n-        extern fn close_cb(handle: *uvll::uv_handle_t) {\n-            let mut h: Handle = NativeHandle::from_native_handle(handle);\n-            h.drop_watcher_data();\n-            unsafe { uvll::free_handle(handle as *c_void) }\n-        }\n+    pub fn run(&mut self) {\n+        unsafe { uvll::uv_run(self.handle, uvll::RUN_DEFAULT) };\n+    }\n+\n+    pub fn close(&mut self) {\n+        unsafe { uvll::uv_loop_delete(self.handle) };\n     }\n }\n \n@@ -270,7 +289,7 @@ impl UvError {\n     pub fn name(&self) -> ~str {\n         unsafe {\n             let inner = match self { &UvError(a) => a };\n-            let name_str = uvll::err_name(inner);\n+            let name_str = uvll::uv_err_name(inner);\n             assert!(name_str.is_not_null());\n             from_c_str(name_str)\n         }\n@@ -279,7 +298,7 @@ impl UvError {\n     pub fn desc(&self) -> ~str {\n         unsafe {\n             let inner = match self { &UvError(a) => a };\n-            let desc_str = uvll::strerror(inner);\n+            let desc_str = uvll::uv_strerror(inner);\n             assert!(desc_str.is_not_null());\n             from_c_str(desc_str)\n         }\n@@ -309,7 +328,7 @@ pub fn uv_error_to_io_error(uverr: UvError) -> IoError {\n         use std::rt::io::*;\n \n         // uv error descriptions are static\n-        let c_desc = uvll::strerror(*uverr);\n+        let c_desc = uvll::uv_strerror(*uverr);\n         let desc = str::raw::c_str_to_static_slice(c_desc);\n \n         let kind = match *uverr {\n@@ -337,16 +356,19 @@ pub fn uv_error_to_io_error(uverr: UvError) -> IoError {\n     }\n }\n \n-/// Given a uv handle, convert a callback status to a UvError\n-pub fn status_to_maybe_uv_error(status: c_int) -> Option<UvError>\n-{\n+/// Given a uv error code, convert a callback status to a UvError\n+pub fn status_to_maybe_uv_error(status: c_int) -> Option<UvError> {\n     if status >= 0 {\n         None\n     } else {\n         Some(UvError(status))\n     }\n }\n \n+pub fn status_to_io_result(status: c_int) -> Result<(), IoError> {\n+    if status >= 0 {Ok(())} else {Err(uv_error_to_io_error(UvError(status)))}\n+}\n+\n /// The uv buffer type\n pub type Buf = uvll::uv_buf_t;\n \n@@ -360,65 +382,56 @@ pub fn empty_buf() -> Buf {\n /// Borrow a slice to a Buf\n pub fn slice_to_uv_buf(v: &[u8]) -> Buf {\n     let data = vec::raw::to_ptr(v);\n-    unsafe { uvll::buf_init(data, v.len()) }\n+    uvll::uv_buf_t { base: data, len: v.len() as uvll::uv_buf_len_t }\n }\n \n-// XXX: Do these conversions without copying\n-\n-/// Transmute an owned vector to a Buf\n-pub fn vec_to_uv_buf(v: ~[u8]) -> Buf {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n+#[cfg(test)]\n+fn local_loop() -> &'static mut Loop {\n     unsafe {\n-        let data = malloc(v.len() as size_t) as *u8;\n-        assert!(data.is_not_null());\n-        do v.as_imm_buf |b, l| {\n-            let data = data as *mut u8;\n-            ptr::copy_memory(data, b, l)\n-        }\n-        uvll::buf_init(data, v.len())\n+        cast::transmute(do Local::borrow |sched: &mut Scheduler| {\n+            let mut io = None;\n+            do sched.event_loop.io |i| {\n+                let (_vtable, uvio): (uint, &'static mut uvio::UvIoFactory) =\n+                    cast::transmute(i);\n+                io = Some(uvio);\n+            }\n+            io.unwrap()\n+        }.uv_loop())\n     }\n }\n \n-/// Transmute a Buf that was once a ~[u8] back to ~[u8]\n-pub fn vec_from_uv_buf(buf: Buf) -> Option<~[u8]> {\n-    #[fixed_stack_segment]; #[inline(never)];\n+#[cfg(test)]\n+mod test {\n+    use std::cast::transmute;\n+    use std::ptr;\n+    use std::unstable::run_in_bare_thread;\n \n-    if !(buf.len == 0 && buf.base.is_null()) {\n-        let v = unsafe { vec::from_buf(buf.base, buf.len as uint) };\n-        unsafe { free(buf.base as *c_void) };\n-        return Some(v);\n-    } else {\n-        // No buffer\n-        uvdebug!(\"No buffer!\");\n-        return None;\n-    }\n-}\n-/*\n-#[test]\n-fn test_slice_to_uv_buf() {\n-    let slice = [0, .. 20];\n-    let buf = slice_to_uv_buf(slice);\n+    use super::{slice_to_uv_buf, Loop};\n \n-    assert!(buf.len == 20);\n+    #[test]\n+    fn test_slice_to_uv_buf() {\n+        let slice = [0, .. 20];\n+        let buf = slice_to_uv_buf(slice);\n \n-    unsafe {\n-        let base = transmute::<*u8, *mut u8>(buf.base);\n-        (*base) = 1;\n-        (*ptr::mut_offset(base, 1)) = 2;\n-    }\n+        assert_eq!(buf.len, 20);\n \n-    assert!(slice[0] == 1);\n-    assert!(slice[1] == 2);\n-}\n+        unsafe {\n+            let base = transmute::<*u8, *mut u8>(buf.base);\n+            (*base) = 1;\n+            (*ptr::mut_offset(base, 1)) = 2;\n+        }\n \n+        assert!(slice[0] == 1);\n+        assert!(slice[1] == 2);\n+    }\n \n-#[test]\n-fn loop_smoke_test() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        loop_.run();\n-        loop_.close();\n+\n+    #[test]\n+    fn loop_smoke_test() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            loop_.run();\n+            loop_.close();\n+        }\n     }\n }\n-*/"}, {"sha": "90b8263da79fd326614f251e6e4af11b5253bd8c", "filename": "src/librustuv/macros.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fmacros.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -27,6 +27,11 @@ macro_rules! uvdebug (\n     })\n )\n \n+// get a handle for the current scheduler\n+macro_rules! get_handle_to_current_scheduler(\n+    () => (do Local::borrow |sched: &mut Scheduler| { sched.make_handle() })\n+)\n+\n pub fn dumb_println(args: &fmt::Arguments) {\n     use std::rt::io::native::stdio::stderr;\n     use std::rt::io::Writer;"}, {"sha": "32c9b6c3d172999f6efffb262b81ca3624840784", "filename": "src/librustuv/net.rs", "status": "modified", "additions": 1082, "deletions": 646, "changes": 1728, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fnet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fnet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fnet.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,844 +8,1280 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::libc::{size_t, ssize_t, c_int, c_void, c_uint};\n-use std::vec;\n+use std::cast;\n+use std::libc;\n+use std::libc::{size_t, ssize_t, c_int, c_void, c_uint, c_char};\n+use std::ptr;\n+use std::rt::BlockedTask;\n+use std::rt::io::IoError;\n+use std::rt::io::net::ip::{Ipv4Addr, Ipv6Addr, SocketAddr, IpAddr};\n+use std::rt::local::Local;\n+use std::rt::rtio;\n+use std::rt::sched::{Scheduler, SchedHandle};\n+use std::rt::tube::Tube;\n use std::str;\n-use std::rt::io::net::ip::{SocketAddr, Ipv4Addr, Ipv6Addr};\n+use std::task;\n+use std::vec;\n \n+use stream::StreamWatcher;\n+use super::{Loop, Request, UvError, Buf, status_to_io_result,\n+            uv_error_to_io_error, UvHandle, slice_to_uv_buf,\n+            wait_until_woken_after};\n+use uvio::HomingIO;\n use uvll;\n-use uvll::*;\n-use super::{AllocCallback, ConnectionCallback, ReadCallback, UdpReceiveCallback,\n-            UdpSendCallback, Loop, Watcher, Request, UvError, Buf, NativeHandle,\n-            status_to_maybe_uv_error, empty_buf};\n-\n-pub struct UvAddrInfo(*uvll::addrinfo);\n-\n-pub enum UvSocketAddr {\n-    UvIpv4SocketAddr(*sockaddr_in),\n-    UvIpv6SocketAddr(*sockaddr_in6),\n-}\n+use uvll::sockaddr;\n \n-pub fn sockaddr_to_UvSocketAddr(addr: *uvll::sockaddr) -> UvSocketAddr {\n-    unsafe {\n-        assert!((is_ip4_addr(addr) || is_ip6_addr(addr)));\n-        assert!(!(is_ip4_addr(addr) && is_ip6_addr(addr)));\n-        match addr {\n-            _ if is_ip4_addr(addr) => UvIpv4SocketAddr(addr as *uvll::sockaddr_in),\n-            _ if is_ip6_addr(addr) => UvIpv6SocketAddr(addr as *uvll::sockaddr_in6),\n-            _ => fail!(),\n-        }\n-    }\n-}\n+////////////////////////////////////////////////////////////////////////////////\n+/// Generic functions related to dealing with sockaddr things\n+////////////////////////////////////////////////////////////////////////////////\n \n-fn socket_addr_as_uv_socket_addr<T>(addr: SocketAddr, f: &fn(UvSocketAddr) -> T) -> T {\n+#[fixed_stack_segment]\n+fn socket_addr_as_sockaddr<T>(addr: SocketAddr, f: &fn(*sockaddr) -> T) -> T {\n     let malloc = match addr.ip {\n-        Ipv4Addr(*) => malloc_ip4_addr,\n-        Ipv6Addr(*) => malloc_ip6_addr,\n-    };\n-    let wrap = match addr.ip {\n-        Ipv4Addr(*) => UvIpv4SocketAddr,\n-        Ipv6Addr(*) => UvIpv6SocketAddr,\n-    };\n-    let free = match addr.ip {\n-        Ipv4Addr(*) => free_ip4_addr,\n-        Ipv6Addr(*) => free_ip6_addr,\n+        Ipv4Addr(*) => uvll::rust_malloc_ip4_addr,\n+        Ipv6Addr(*) => uvll::rust_malloc_ip6_addr,\n     };\n \n-    let addr = unsafe { malloc(addr.ip.to_str(), addr.port as int) };\n+    let ip = addr.ip.to_str();\n+    let addr = ip.with_c_str(|p| unsafe { malloc(p, addr.port as c_int) });\n     do (|| {\n-        f(wrap(addr))\n+        f(addr)\n     }).finally {\n-        unsafe { free(addr) };\n+        unsafe { libc::free(addr) };\n     }\n }\n \n-fn uv_socket_addr_as_socket_addr<T>(addr: UvSocketAddr, f: &fn(SocketAddr) -> T) -> T {\n-    let ip_size = match addr {\n-        UvIpv4SocketAddr(*) => 4/*groups of*/ * 3/*digits separated by*/ + 3/*periods*/,\n-        UvIpv6SocketAddr(*) => 8/*groups of*/ * 4/*hex digits separated by*/ + 7 /*colons*/,\n-    };\n-    let ip_name = {\n-        let buf = vec::from_elem(ip_size + 1 /*null terminated*/, 0u8);\n-        unsafe {\n+#[fixed_stack_segment]\n+pub fn sockaddr_to_socket_addr(addr: *sockaddr) -> SocketAddr {\n+    unsafe {\n+        let ip_size = if uvll::rust_is_ipv4_sockaddr(addr) == 1 {\n+            4/*groups of*/ * 3/*digits separated by*/ + 3/*periods*/\n+        } else if uvll::rust_is_ipv6_sockaddr(addr) == 1 {\n+            8/*groups of*/ * 4/*hex digits separated by*/ + 7 /*colons*/\n+        } else {\n+            fail!(\"unknown address?\");\n+        };\n+        let ip_name = {\n+            let buf = vec::from_elem(ip_size + 1 /*null terminated*/, 0u8);\n             let buf_ptr = vec::raw::to_ptr(buf);\n-            match addr {\n-                UvIpv4SocketAddr(addr) => uvll::ip4_name(addr, buf_ptr, ip_size as size_t),\n-                UvIpv6SocketAddr(addr) => uvll::ip6_name(addr, buf_ptr, ip_size as size_t),\n+            if uvll::rust_is_ipv4_sockaddr(addr) == 1 {\n+                uvll::uv_ip4_name(addr, buf_ptr as *c_char, ip_size as size_t);\n+            } else {\n+                uvll::uv_ip6_name(addr, buf_ptr as *c_char, ip_size as size_t);\n             }\n+            buf\n         };\n-        buf\n-    };\n-    let ip_port = unsafe {\n-        let port = match addr {\n-            UvIpv4SocketAddr(addr) => uvll::ip4_port(addr),\n-            UvIpv6SocketAddr(addr) => uvll::ip6_port(addr),\n+        let ip_port = {\n+            let port = if uvll::rust_is_ipv4_sockaddr(addr) == 1 {\n+                uvll::rust_ip4_port(addr)\n+            } else {\n+                uvll::rust_ip6_port(addr)\n+            };\n+            port as u16\n         };\n-        port as u16\n-    };\n-    let ip_str = str::from_utf8_slice(ip_name).trim_right_chars(&'\\x00');\n-    let ip_addr = FromStr::from_str(ip_str).unwrap();\n-\n-    // finally run the closure\n-    f(SocketAddr { ip: ip_addr, port: ip_port })\n-}\n+        let ip_str = str::from_utf8_slice(ip_name).trim_right_chars(&'\\x00');\n+        let ip_addr = FromStr::from_str(ip_str).unwrap();\n \n-pub fn uv_socket_addr_to_socket_addr(addr: UvSocketAddr) -> SocketAddr {\n-    use std::util;\n-    uv_socket_addr_as_socket_addr(addr, util::id)\n+        SocketAddr { ip: ip_addr, port: ip_port }\n+    }\n }\n \n #[cfg(test)]\n #[test]\n fn test_ip4_conversion() {\n     use std::rt;\n     let ip4 = rt::test::next_test_ip4();\n-    assert_eq!(ip4, socket_addr_as_uv_socket_addr(ip4, uv_socket_addr_to_socket_addr));\n+    do socket_addr_as_sockaddr(ip4) |addr| {\n+        assert_eq!(ip4, sockaddr_to_socket_addr(addr));\n+    }\n }\n \n #[cfg(test)]\n #[test]\n fn test_ip6_conversion() {\n     use std::rt;\n     let ip6 = rt::test::next_test_ip6();\n-    assert_eq!(ip6, socket_addr_as_uv_socket_addr(ip6, uv_socket_addr_to_socket_addr));\n-}\n-\n-// uv_stream_t is the parent class of uv_tcp_t, uv_pipe_t, uv_tty_t\n-// and uv_file_t\n-pub struct StreamWatcher(*uvll::uv_stream_t);\n-impl Watcher for StreamWatcher { }\n-\n-impl StreamWatcher {\n-    pub fn read_start(&mut self, alloc: AllocCallback, cb: ReadCallback) {\n-        unsafe {\n-            match uvll::read_start(self.native_handle(), alloc_cb, read_cb) {\n-                0 => {\n-                    let data = self.get_watcher_data();\n-                    data.alloc_cb = Some(alloc);\n-                    data.read_cb = Some(cb);\n-                }\n-                n => {\n-                    cb(*self, 0, empty_buf(), Some(UvError(n)))\n-                }\n-            }\n-        }\n+    do socket_addr_as_sockaddr(ip6) |addr| {\n+        assert_eq!(ip6, sockaddr_to_socket_addr(addr));\n+    }\n+}\n \n-        extern fn alloc_cb(stream: *uvll::uv_stream_t, suggested_size: size_t) -> Buf {\n-            let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(stream);\n-            let alloc_cb = stream_watcher.get_watcher_data().alloc_cb.get_ref();\n-            return (*alloc_cb)(suggested_size as uint);\n-        }\n+enum SocketNameKind {\n+    TcpPeer,\n+    Tcp,\n+    Udp\n+}\n \n-        extern fn read_cb(stream: *uvll::uv_stream_t, nread: ssize_t, buf: Buf) {\n-            uvdebug!(\"buf addr: {}\", buf.base);\n-            uvdebug!(\"buf len: {}\", buf.len);\n-            let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(stream);\n-            let cb = stream_watcher.get_watcher_data().read_cb.get_ref();\n-            let status = status_to_maybe_uv_error(nread as c_int);\n-            (*cb)(stream_watcher, nread as int, buf, status);\n-        }\n+#[fixed_stack_segment]\n+fn socket_name(sk: SocketNameKind, handle: *c_void) -> Result<SocketAddr, IoError> {\n+    unsafe {\n+        let getsockname = match sk {\n+            TcpPeer => uvll::uv_tcp_getpeername,\n+            Tcp     => uvll::uv_tcp_getsockname,\n+            Udp     => uvll::uv_udp_getsockname,\n+        };\n+\n+        // Allocate a sockaddr_storage\n+        // since we don't know if it's ipv4 or ipv6\n+        let size = uvll::rust_sockaddr_size();\n+        let name = libc::malloc(size as size_t);\n+        assert!(!name.is_null());\n+        let mut namelen = size;\n+\n+        let ret = match getsockname(handle, name, &mut namelen) {\n+            0 => Ok(sockaddr_to_socket_addr(name)),\n+            n => Err(uv_error_to_io_error(UvError(n)))\n+        };\n+        libc::free(name);\n+        ret\n     }\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+/// TCP implementation\n+////////////////////////////////////////////////////////////////////////////////\n \n-    pub fn read_stop(&mut self) {\n-        // It would be nice to drop the alloc and read callbacks here,\n-        // but read_stop may be called from inside one of them and we\n-        // would end up freeing the in-use environment\n-        let handle = self.native_handle();\n-        unsafe { assert_eq!(uvll::read_stop(handle), 0); }\n+pub struct TcpWatcher {\n+    handle: *uvll::uv_tcp_t,\n+    stream: StreamWatcher,\n+    home: SchedHandle,\n+}\n+\n+pub struct TcpListener {\n+    home: SchedHandle,\n+    handle: *uvll::uv_pipe_t,\n+    priv closing_task: Option<BlockedTask>,\n+    priv outgoing: Tube<Result<~rtio::RtioTcpStream, IoError>>,\n+}\n+\n+pub struct TcpAcceptor {\n+    listener: ~TcpListener,\n+    priv incoming: Tube<Result<~rtio::RtioTcpStream, IoError>>,\n+}\n+\n+// TCP watchers (clients/streams)\n+\n+impl TcpWatcher {\n+    pub fn new(loop_: &Loop) -> TcpWatcher {\n+        let handle = unsafe { uvll::malloc_handle(uvll::UV_TCP) };\n+        assert_eq!(unsafe {\n+            uvll::uv_tcp_init(loop_.handle, handle)\n+        }, 0);\n+        TcpWatcher {\n+            home: get_handle_to_current_scheduler!(),\n+            handle: handle,\n+            stream: StreamWatcher::new(handle),\n+        }\n     }\n \n-    pub fn write(&mut self, buf: Buf, cb: ConnectionCallback) {\n-        let req = WriteRequest::new();\n-        return unsafe {\n-            match uvll::write(req.native_handle(), self.native_handle(),\n-                              [buf], write_cb) {\n-                0 => {\n-                    let data = self.get_watcher_data();\n-                    assert!(data.write_cb.is_none());\n-                    data.write_cb = Some(cb);\n-                }\n-                n => {\n-                    req.delete();\n-                    cb(*self, Some(UvError(n)))\n+    pub fn connect(loop_: &mut Loop, address: SocketAddr)\n+        -> Result<TcpWatcher, UvError>\n+    {\n+        struct Ctx { status: c_int, task: Option<BlockedTask> }\n+\n+        return do task::unkillable {\n+            let tcp = TcpWatcher::new(loop_);\n+            let ret = do socket_addr_as_sockaddr(address) |addr| {\n+                let mut req = Request::new(uvll::UV_CONNECT);\n+                let result = unsafe {\n+                    uvll::uv_tcp_connect(req.handle, tcp.handle, addr,\n+                                         connect_cb)\n+                };\n+                match result {\n+                    0 => {\n+                        req.defuse(); // uv callback now owns this request\n+                        let mut cx = Ctx { status: 0, task: None };\n+                        do wait_until_woken_after(&mut cx.task) {\n+                            req.set_data(&cx);\n+                        }\n+                        match cx.status {\n+                            0 => Ok(()),\n+                            n => Err(UvError(n)),\n+                        }\n+                    }\n+                    n => Err(UvError(n))\n                 }\n+            };\n+\n+            match ret {\n+                Ok(()) => Ok(tcp),\n+                Err(e) => Err(e),\n             }\n         };\n \n-        extern fn write_cb(req: *uvll::uv_write_t, status: c_int) {\n-            let write_request: WriteRequest = NativeHandle::from_native_handle(req);\n-            let mut stream_watcher = write_request.stream();\n-            write_request.delete();\n-            let cb = stream_watcher.get_watcher_data().write_cb.take_unwrap();\n-            let status = status_to_maybe_uv_error(status);\n-            cb(stream_watcher, status);\n+        extern fn connect_cb(req: *uvll::uv_connect_t, status: c_int) {\n+            let req = Request::wrap(req);\n+            assert!(status != uvll::ECANCELED);\n+            let cx: &mut Ctx = unsafe { req.get_data() };\n+            cx.status = status;\n+            let scheduler: ~Scheduler = Local::take();\n+            scheduler.resume_blocked_task_immediately(cx.task.take_unwrap());\n         }\n     }\n+}\n+\n+impl HomingIO for TcpWatcher {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n+\n+impl rtio::RtioSocket for TcpWatcher {\n+    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n+        let _m = self.fire_homing_missile();\n+        socket_name(Tcp, self.handle)\n+    }\n+}\n \n+impl rtio::RtioTcpStream for TcpWatcher {\n+    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.stream.read(buf).map_err(uv_error_to_io_error)\n+    }\n \n-    pub fn listen(&mut self, cb: ConnectionCallback) -> Result<(), UvError> {\n-        {\n-            let data = self.get_watcher_data();\n-            assert!(data.connect_cb.is_none());\n-            data.connect_cb = Some(cb);\n-        }\n+    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.stream.write(buf).map_err(uv_error_to_io_error)\n+    }\n \n-        return unsafe {\n-            static BACKLOG: c_int = 128; // XXX should be configurable\n-            match uvll::listen(self.native_handle(), BACKLOG, connection_cb) {\n-                0 => Ok(()),\n-                n => Err(UvError(n))\n-            }\n-        };\n+    fn peer_name(&mut self) -> Result<SocketAddr, IoError> {\n+        let _m = self.fire_homing_missile();\n+        socket_name(TcpPeer, self.handle)\n+    }\n \n-        extern fn connection_cb(handle: *uvll::uv_stream_t, status: c_int) {\n-            uvdebug!(\"connection_cb\");\n-            let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(handle);\n-            let cb = stream_watcher.get_watcher_data().connect_cb.get_ref();\n-            let status = status_to_maybe_uv_error(status);\n-            (*cb)(stream_watcher, status);\n-        }\n+    fn control_congestion(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_tcp_nodelay(self.handle, 0 as c_int)\n+        })\n     }\n \n-    pub fn accept(&mut self, stream: StreamWatcher) {\n-        let self_handle = self.native_handle() as *c_void;\n-        let stream_handle = stream.native_handle() as *c_void;\n-        assert_eq!(0, unsafe { uvll::accept(self_handle, stream_handle) } );\n+    fn nodelay(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_tcp_nodelay(self.handle, 1 as c_int)\n+        })\n     }\n-}\n \n-impl NativeHandle<*uvll::uv_stream_t> for StreamWatcher {\n-    fn from_native_handle(handle: *uvll::uv_stream_t) -> StreamWatcher {\n-        StreamWatcher(handle)\n+    fn keepalive(&mut self, delay_in_seconds: uint) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_tcp_keepalive(self.handle, 1 as c_int,\n+                                   delay_in_seconds as c_uint)\n+        })\n     }\n-    fn native_handle(&self) -> *uvll::uv_stream_t {\n-        match self { &StreamWatcher(ptr) => ptr }\n+\n+    fn letdie(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_tcp_keepalive(self.handle, 0 as c_int, 0 as c_uint)\n+        })\n     }\n }\n \n-pub struct TcpWatcher(*uvll::uv_tcp_t);\n-impl Watcher for TcpWatcher { }\n+impl UvHandle<uvll::uv_tcp_t> for TcpWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_tcp_t { self.stream.handle }\n+}\n \n-impl TcpWatcher {\n-    pub fn new(loop_: &Loop) -> TcpWatcher {\n-        unsafe {\n-            let handle = malloc_handle(UV_TCP);\n-            assert!(handle.is_not_null());\n-            assert_eq!(0, uvll::tcp_init(loop_.native_handle(), handle));\n-            let mut watcher: TcpWatcher = NativeHandle::from_native_handle(handle);\n-            watcher.install_watcher_data();\n-            return watcher;\n-        }\n-    }\n-\n-    pub fn bind(&mut self, address: SocketAddr) -> Result<(), UvError> {\n-        do socket_addr_as_uv_socket_addr(address) |addr| {\n-            let result = unsafe {\n-                match addr {\n-                    UvIpv4SocketAddr(addr) => uvll::tcp_bind(self.native_handle(), addr),\n-                    UvIpv6SocketAddr(addr) => uvll::tcp_bind6(self.native_handle(), addr),\n-                }\n+impl Drop for TcpWatcher {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        self.close();\n+    }\n+}\n+\n+// TCP listeners (unbound servers)\n+\n+impl TcpListener {\n+    pub fn bind(loop_: &mut Loop, address: SocketAddr)\n+        -> Result<~TcpListener, UvError>\n+    {\n+        do task::unkillable {\n+            let handle = unsafe { uvll::malloc_handle(uvll::UV_TCP) };\n+            assert_eq!(unsafe {\n+                uvll::uv_tcp_init(loop_.handle, handle)\n+            }, 0);\n+            let l = ~TcpListener {\n+                home: get_handle_to_current_scheduler!(),\n+                handle: handle,\n+                closing_task: None,\n+                outgoing: Tube::new(),\n             };\n-            match result {\n-                0 => Ok(()),\n-                _ => Err(UvError(result)),\n+            let res = socket_addr_as_sockaddr(address, |addr| unsafe {\n+                uvll::uv_tcp_bind(l.handle, addr)\n+            });\n+            match res {\n+                0 => Ok(l.install()),\n+                n => Err(UvError(n))\n             }\n         }\n     }\n+}\n \n-    pub fn connect(&mut self, address: SocketAddr, cb: ConnectionCallback) {\n-        unsafe {\n-            assert!(self.get_watcher_data().connect_cb.is_none());\n-            self.get_watcher_data().connect_cb = Some(cb);\n+impl HomingIO for TcpListener {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n \n-            let connect_handle = ConnectRequest::new().native_handle();\n-            uvdebug!(\"connect_t: {}\", connect_handle);\n-            do socket_addr_as_uv_socket_addr(address) |addr| {\n-                let result = match addr {\n-                    UvIpv4SocketAddr(addr) => uvll::tcp_connect(connect_handle,\n-                                                      self.native_handle(), addr, connect_cb),\n-                    UvIpv6SocketAddr(addr) => uvll::tcp_connect6(connect_handle,\n-                                                       self.native_handle(), addr, connect_cb),\n-                };\n-                assert_eq!(0, result);\n-            }\n+impl UvHandle<uvll::uv_tcp_t> for TcpListener {\n+    fn uv_handle(&self) -> *uvll::uv_tcp_t { self.handle }\n+}\n \n-            extern fn connect_cb(req: *uvll::uv_connect_t, status: c_int) {\n-                uvdebug!(\"connect_t: {}\", req);\n-                let connect_request: ConnectRequest = NativeHandle::from_native_handle(req);\n-                let mut stream_watcher = connect_request.stream();\n-                connect_request.delete();\n-                let cb = stream_watcher.get_watcher_data().connect_cb.take_unwrap();\n-                let status = status_to_maybe_uv_error(status);\n-                cb(stream_watcher, status);\n-            }\n+impl rtio::RtioSocket for TcpListener {\n+    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n+        let _m = self.fire_homing_missile();\n+        socket_name(Tcp, self.handle)\n+    }\n+}\n+\n+impl rtio::RtioTcpListener for TcpListener {\n+    fn listen(mut ~self) -> Result<~rtio::RtioTcpAcceptor, IoError> {\n+        // create the acceptor object from ourselves\n+        let incoming = self.outgoing.clone();\n+        let mut acceptor = ~TcpAcceptor {\n+            listener: self,\n+            incoming: incoming,\n+        };\n+\n+        let _m = acceptor.fire_homing_missile();\n+        // XXX: the 128 backlog should be configurable\n+        match unsafe { uvll::uv_listen(acceptor.listener.handle, 128, listen_cb) } {\n+            0 => Ok(acceptor as ~rtio::RtioTcpAcceptor),\n+            n => Err(uv_error_to_io_error(UvError(n))),\n+        }\n+    }\n+}\n+\n+extern fn listen_cb(server: *uvll::uv_stream_t, status: c_int) {\n+    assert!(status != uvll::ECANCELED);\n+    let msg = match status {\n+        0 => {\n+            let loop_ = Loop::wrap(unsafe {\n+                uvll::get_loop_for_uv_handle(server)\n+            });\n+            let client = TcpWatcher::new(&loop_);\n+            assert_eq!(unsafe { uvll::uv_accept(server, client.handle) }, 0);\n+            Ok(~client as ~rtio::RtioTcpStream)\n         }\n+        n => Err(uv_error_to_io_error(UvError(n)))\n+    };\n+\n+    let tcp: &mut TcpListener = unsafe { UvHandle::from_uv_handle(&server) };\n+    tcp.outgoing.send(msg);\n+}\n+\n+impl Drop for TcpListener {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        self.close();\n     }\n+}\n+\n+extern fn listener_close_cb(handle: *uvll::uv_handle_t) {\n+    let tcp: &mut TcpListener = unsafe { UvHandle::from_uv_handle(&handle) };\n+    unsafe { uvll::free_handle(handle) }\n \n-    pub fn as_stream(&self) -> StreamWatcher {\n-        NativeHandle::from_native_handle(self.native_handle() as *uvll::uv_stream_t)\n+    let sched: ~Scheduler = Local::take();\n+    sched.resume_blocked_task_immediately(tcp.closing_task.take_unwrap());\n+}\n+\n+// TCP acceptors (bound servers)\n+\n+impl HomingIO for TcpAcceptor {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { self.listener.home() }\n+}\n+\n+impl rtio::RtioSocket for TcpAcceptor {\n+    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n+        let _m = self.fire_homing_missile();\n+        socket_name(Tcp, self.listener.handle)\n     }\n }\n \n-impl NativeHandle<*uvll::uv_tcp_t> for TcpWatcher {\n-    fn from_native_handle(handle: *uvll::uv_tcp_t) -> TcpWatcher {\n-        TcpWatcher(handle)\n+impl rtio::RtioTcpAcceptor for TcpAcceptor {\n+    fn accept(&mut self) -> Result<~rtio::RtioTcpStream, IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.incoming.recv()\n     }\n-    fn native_handle(&self) -> *uvll::uv_tcp_t {\n-        match self { &TcpWatcher(ptr) => ptr }\n+\n+    fn accept_simultaneously(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_tcp_simultaneous_accepts(self.listener.handle, 1)\n+        })\n+    }\n+\n+    fn dont_accept_simultaneously(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_tcp_simultaneous_accepts(self.listener.handle, 0)\n+        })\n     }\n }\n \n-pub struct UdpWatcher(*uvll::uv_udp_t);\n-impl Watcher for UdpWatcher { }\n+////////////////////////////////////////////////////////////////////////////////\n+/// UDP implementation\n+////////////////////////////////////////////////////////////////////////////////\n+\n+pub struct UdpWatcher {\n+    handle: *uvll::uv_udp_t,\n+    home: SchedHandle,\n+}\n \n impl UdpWatcher {\n-    pub fn new(loop_: &Loop) -> UdpWatcher {\n-        unsafe {\n-            let handle = malloc_handle(UV_UDP);\n-            assert!(handle.is_not_null());\n-            assert_eq!(0, uvll::udp_init(loop_.native_handle(), handle));\n-            let mut watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n-            watcher.install_watcher_data();\n-            return watcher;\n-        }\n-    }\n-\n-    pub fn bind(&mut self, address: SocketAddr) -> Result<(), UvError> {\n-        do socket_addr_as_uv_socket_addr(address) |addr| {\n-            let result = unsafe {\n-                match addr {\n-                    UvIpv4SocketAddr(addr) => uvll::udp_bind(self.native_handle(), addr, 0u32),\n-                    UvIpv6SocketAddr(addr) => uvll::udp_bind6(self.native_handle(), addr, 0u32),\n-                }\n+    pub fn bind(loop_: &Loop, address: SocketAddr)\n+        -> Result<UdpWatcher, UvError>\n+    {\n+        do task::unkillable {\n+            let udp = UdpWatcher {\n+                handle: unsafe { uvll::malloc_handle(uvll::UV_UDP) },\n+                home: get_handle_to_current_scheduler!(),\n             };\n+            assert_eq!(unsafe {\n+                uvll::uv_udp_init(loop_.handle, udp.handle)\n+            }, 0);\n+            let result = socket_addr_as_sockaddr(address, |addr| unsafe {\n+                uvll::uv_udp_bind(udp.handle, addr, 0u32)\n+            });\n             match result {\n-                0 => Ok(()),\n-                _ => Err(UvError(result)),\n+                0 => Ok(udp),\n+                n => Err(UvError(n)),\n             }\n         }\n     }\n+}\n \n-    pub fn recv_start(&mut self, alloc: AllocCallback, cb: UdpReceiveCallback) {\n-        {\n-            let data = self.get_watcher_data();\n-            data.alloc_cb = Some(alloc);\n-            data.udp_recv_cb = Some(cb);\n-        }\n+impl UvHandle<uvll::uv_udp_t> for UdpWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_udp_t { self.handle }\n+}\n \n-        unsafe { uvll::udp_recv_start(self.native_handle(), alloc_cb, recv_cb); }\n+impl HomingIO for UdpWatcher {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n+\n+impl rtio::RtioSocket for UdpWatcher {\n+    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n+        let _m = self.fire_homing_missile();\n+        socket_name(Udp, self.handle)\n+    }\n+}\n \n-        extern fn alloc_cb(handle: *uvll::uv_udp_t, suggested_size: size_t) -> Buf {\n-            let mut udp_watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n-            let alloc_cb = udp_watcher.get_watcher_data().alloc_cb.get_ref();\n-            return (*alloc_cb)(suggested_size as uint);\n+impl rtio::RtioUdpSocket for UdpWatcher {\n+    fn recvfrom(&mut self, buf: &mut [u8])\n+        -> Result<(uint, SocketAddr), IoError>\n+    {\n+        struct Ctx {\n+            task: Option<BlockedTask>,\n+            buf: Option<Buf>,\n+            result: Option<(ssize_t, Option<SocketAddr>)>,\n         }\n+        let _m = self.fire_homing_missile();\n+\n+        let a = match unsafe {\n+            uvll::uv_udp_recv_start(self.handle, alloc_cb, recv_cb)\n+        } {\n+            0 => {\n+                let mut cx = Ctx {\n+                    task: None,\n+                    buf: Some(slice_to_uv_buf(buf)),\n+                    result: None,\n+                };\n+                do wait_until_woken_after(&mut cx.task) {\n+                    unsafe { uvll::set_data_for_uv_handle(self.handle, &cx) }\n+                }\n+                match cx.result.take_unwrap() {\n+                    (n, _) if n < 0 =>\n+                        Err(uv_error_to_io_error(UvError(n as c_int))),\n+                    (n, addr) => Ok((n as uint, addr.unwrap()))\n+                }\n+            }\n+            n => Err(uv_error_to_io_error(UvError(n)))\n+        };\n+        return a;\n+\n+        extern fn alloc_cb(handle: *uvll::uv_udp_t,\n+                           _suggested_size: size_t,\n+                           buf: *mut Buf) {\n+            unsafe {\n+                let cx: &mut Ctx =\n+                    cast::transmute(uvll::get_data_for_uv_handle(handle));\n+                *buf = cx.buf.take().expect(\"recv alloc_cb called more than once\")\n+            }\n+        }\n+\n+        extern fn recv_cb(handle: *uvll::uv_udp_t, nread: ssize_t, buf: *Buf,\n+                          addr: *uvll::sockaddr, _flags: c_uint) {\n+            assert!(nread != uvll::ECANCELED as ssize_t);\n+            let cx: &mut Ctx = unsafe {\n+                cast::transmute(uvll::get_data_for_uv_handle(handle))\n+            };\n \n-        extern fn recv_cb(handle: *uvll::uv_udp_t, nread: ssize_t, buf: Buf,\n-                          addr: *uvll::sockaddr, flags: c_uint) {\n             // When there's no data to read the recv callback can be a no-op.\n             // This can happen if read returns EAGAIN/EWOULDBLOCK. By ignoring\n             // this we just drop back to kqueue and wait for the next callback.\n             if nread == 0 {\n-                return;\n+                cx.buf = Some(unsafe { *buf });\n+                return\n             }\n \n-            uvdebug!(\"buf addr: {}\", buf.base);\n-            uvdebug!(\"buf len: {}\", buf.len);\n-            let mut udp_watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n-            let cb = udp_watcher.get_watcher_data().udp_recv_cb.get_ref();\n-            let status = status_to_maybe_uv_error(nread as c_int);\n-            let addr = uv_socket_addr_to_socket_addr(sockaddr_to_UvSocketAddr(addr));\n-            (*cb)(udp_watcher, nread as int, buf, addr, flags as uint, status);\n-        }\n-    }\n-\n-    pub fn recv_stop(&mut self) {\n-        unsafe { uvll::udp_recv_stop(self.native_handle()); }\n-    }\n-\n-    pub fn send(&mut self, buf: Buf, address: SocketAddr, cb: UdpSendCallback) {\n-        {\n-            let data = self.get_watcher_data();\n-            assert!(data.udp_send_cb.is_none());\n-            data.udp_send_cb = Some(cb);\n-        }\n+            unsafe {\n+                assert_eq!(uvll::uv_udp_recv_stop(handle), 0)\n+            }\n \n-        let req = UdpSendRequest::new();\n-        do socket_addr_as_uv_socket_addr(address) |addr| {\n-            let result = unsafe {\n-                match addr {\n-                    UvIpv4SocketAddr(addr) => uvll::udp_send(req.native_handle(),\n-                                                   self.native_handle(), [buf], addr, send_cb),\n-                    UvIpv6SocketAddr(addr) => uvll::udp_send6(req.native_handle(),\n-                                                    self.native_handle(), [buf], addr, send_cb),\n-                }\n+            let cx: &mut Ctx = unsafe {\n+                cast::transmute(uvll::get_data_for_uv_handle(handle))\n             };\n-            assert_eq!(0, result);\n-        }\n+            let addr = if addr == ptr::null() {\n+                None\n+            } else {\n+                Some(sockaddr_to_socket_addr(addr))\n+            };\n+            cx.result = Some((nread, addr));\n \n-        extern fn send_cb(req: *uvll::uv_udp_send_t, status: c_int) {\n-            let send_request: UdpSendRequest = NativeHandle::from_native_handle(req);\n-            let mut udp_watcher = send_request.handle();\n-            send_request.delete();\n-            let cb = udp_watcher.get_watcher_data().udp_send_cb.take_unwrap();\n-            let status = status_to_maybe_uv_error(status);\n-            cb(udp_watcher, status);\n+            let sched: ~Scheduler = Local::take();\n+            sched.resume_blocked_task_immediately(cx.task.take_unwrap());\n         }\n     }\n-}\n \n-impl NativeHandle<*uvll::uv_udp_t> for UdpWatcher {\n-    fn from_native_handle(handle: *uvll::uv_udp_t) -> UdpWatcher {\n-        UdpWatcher(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_udp_t {\n-        match self { &UdpWatcher(ptr) => ptr }\n-    }\n-}\n+    fn sendto(&mut self, buf: &[u8], dst: SocketAddr) -> Result<(), IoError> {\n+        struct Ctx { task: Option<BlockedTask>, result: c_int }\n \n-// uv_connect_t is a subclass of uv_req_t\n-pub struct ConnectRequest(*uvll::uv_connect_t);\n-impl Request for ConnectRequest { }\n+        let _m = self.fire_homing_missile();\n \n-impl ConnectRequest {\n+        let mut req = Request::new(uvll::UV_UDP_SEND);\n+        let buf = slice_to_uv_buf(buf);\n+        let result = socket_addr_as_sockaddr(dst, |dst| unsafe {\n+            uvll::uv_udp_send(req.handle, self.handle, [buf], dst, send_cb)\n+        });\n \n-    pub fn new() -> ConnectRequest {\n-        let connect_handle = unsafe { malloc_req(UV_CONNECT) };\n-        assert!(connect_handle.is_not_null());\n-        ConnectRequest(connect_handle as *uvll::uv_connect_t)\n-    }\n+        return match result {\n+            0 => {\n+                req.defuse(); // uv callback now owns this request\n+                let mut cx = Ctx { task: None, result: 0 };\n+                do wait_until_woken_after(&mut cx.task) {\n+                    req.set_data(&cx);\n+                }\n+                match cx.result {\n+                    0 => Ok(()),\n+                    n => Err(uv_error_to_io_error(UvError(n)))\n+                }\n+            }\n+            n => Err(uv_error_to_io_error(UvError(n)))\n+        };\n \n-    fn stream(&self) -> StreamWatcher {\n-        unsafe {\n-            let stream_handle = uvll::get_stream_handle_from_connect_req(self.native_handle());\n-            NativeHandle::from_native_handle(stream_handle)\n-        }\n-    }\n+        extern fn send_cb(req: *uvll::uv_udp_send_t, status: c_int) {\n+            let req = Request::wrap(req);\n+            assert!(status != uvll::ECANCELED);\n+            let cx: &mut Ctx = unsafe { req.get_data() };\n+            cx.result = status;\n \n-    fn delete(self) {\n-        unsafe { free_req(self.native_handle() as *c_void) }\n+            let sched: ~Scheduler = Local::take();\n+            sched.resume_blocked_task_immediately(cx.task.take_unwrap());\n+        }\n     }\n-}\n \n-impl NativeHandle<*uvll::uv_connect_t> for ConnectRequest {\n-    fn from_native_handle(handle: *uvll:: uv_connect_t) -> ConnectRequest {\n-        ConnectRequest(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_connect_t {\n-        match self { &ConnectRequest(ptr) => ptr }\n+    fn join_multicast(&mut self, multi: IpAddr) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            do multi.to_str().with_c_str |m_addr| {\n+                uvll::uv_udp_set_membership(self.handle,\n+                                            m_addr, ptr::null(),\n+                                            uvll::UV_JOIN_GROUP)\n+            }\n+        })\n     }\n-}\n-\n-pub struct WriteRequest(*uvll::uv_write_t);\n-\n-impl Request for WriteRequest { }\n \n-impl WriteRequest {\n-    pub fn new() -> WriteRequest {\n-        let write_handle = unsafe { malloc_req(UV_WRITE) };\n-        assert!(write_handle.is_not_null());\n-        WriteRequest(write_handle as *uvll::uv_write_t)\n+    fn leave_multicast(&mut self, multi: IpAddr) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            do multi.to_str().with_c_str |m_addr| {\n+                uvll::uv_udp_set_membership(self.handle,\n+                                            m_addr, ptr::null(),\n+                                            uvll::UV_LEAVE_GROUP)\n+            }\n+        })\n     }\n \n-    pub fn stream(&self) -> StreamWatcher {\n-        unsafe {\n-            let stream_handle = uvll::get_stream_handle_from_write_req(self.native_handle());\n-            NativeHandle::from_native_handle(stream_handle)\n-        }\n+    fn loop_multicast_locally(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_udp_set_multicast_loop(self.handle,\n+                                            1 as c_int)\n+        })\n     }\n \n-    pub fn delete(self) {\n-        unsafe { free_req(self.native_handle() as *c_void) }\n+    fn dont_loop_multicast_locally(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_udp_set_multicast_loop(self.handle,\n+                                            0 as c_int)\n+        })\n     }\n-}\n \n-impl NativeHandle<*uvll::uv_write_t> for WriteRequest {\n-    fn from_native_handle(handle: *uvll:: uv_write_t) -> WriteRequest {\n-        WriteRequest(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_write_t {\n-        match self { &WriteRequest(ptr) => ptr }\n+    fn multicast_time_to_live(&mut self, ttl: int) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_udp_set_multicast_ttl(self.handle,\n+                                           ttl as c_int)\n+        })\n     }\n-}\n-\n-pub struct UdpSendRequest(*uvll::uv_udp_send_t);\n-impl Request for UdpSendRequest { }\n \n-impl UdpSendRequest {\n-    pub fn new() -> UdpSendRequest {\n-        let send_handle = unsafe { malloc_req(UV_UDP_SEND) };\n-        assert!(send_handle.is_not_null());\n-        UdpSendRequest(send_handle as *uvll::uv_udp_send_t)\n+    fn time_to_live(&mut self, ttl: int) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_udp_set_ttl(self.handle, ttl as c_int)\n+        })\n     }\n \n-    pub fn handle(&self) -> UdpWatcher {\n-        let send_request_handle = unsafe {\n-            uvll::get_udp_handle_from_send_req(self.native_handle())\n-        };\n-        NativeHandle::from_native_handle(send_request_handle)\n+    fn hear_broadcasts(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_udp_set_broadcast(self.handle,\n+                                       1 as c_int)\n+        })\n     }\n \n-    pub fn delete(self) {\n-        unsafe { free_req(self.native_handle() as *c_void) }\n+    fn ignore_broadcasts(&mut self) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        status_to_io_result(unsafe {\n+            uvll::uv_udp_set_broadcast(self.handle,\n+                                       0 as c_int)\n+        })\n     }\n }\n \n-impl NativeHandle<*uvll::uv_udp_send_t> for UdpSendRequest {\n-    fn from_native_handle(handle: *uvll::uv_udp_send_t) -> UdpSendRequest {\n-        UdpSendRequest(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_udp_send_t {\n-        match self { &UdpSendRequest(ptr) => ptr }\n+impl Drop for UdpWatcher {\n+    fn drop(&mut self) {\n+        // Send ourselves home to close this handle (blocking while doing so).\n+        let _m = self.fire_homing_missile();\n+        self.close();\n     }\n }\n \n+////////////////////////////////////////////////////////////////////////////////\n+/// UV request support\n+////////////////////////////////////////////////////////////////////////////////\n+\n #[cfg(test)]\n mod test {\n-    use super::*;\n-    use std::util::ignore;\n     use std::cell::Cell;\n-    use std::vec;\n-    use std::unstable::run_in_bare_thread;\n-    use std::rt::thread::Thread;\n+    use std::comm::oneshot;\n     use std::rt::test::*;\n-    use super::super::{Loop, AllocCallback};\n-    use super::super::{vec_from_uv_buf, vec_to_uv_buf, slice_to_uv_buf};\n+    use std::rt::rtio::{RtioTcpStream, RtioTcpListener, RtioTcpAcceptor,\n+                        RtioUdpSocket};\n+    use std::task;\n+\n+    use super::*;\n+    use super::super::local_loop;\n \n     #[test]\n     fn connect_close_ip4() {\n-        do run_in_bare_thread() {\n-            let mut loop_ = Loop::new();\n-            let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-            // Connect to a port where nobody is listening\n-            let addr = next_test_ip4();\n-            do tcp_watcher.connect(addr) |stream_watcher, status| {\n-                uvdebug!(\"tcp_watcher.connect!\");\n-                assert!(status.is_some());\n-                assert_eq!(status.unwrap().name(), ~\"ECONNREFUSED\");\n-                stream_watcher.close(||());\n-            }\n-            loop_.run();\n-            loop_.close();\n+        match TcpWatcher::connect(local_loop(), next_test_ip4()) {\n+            Ok(*) => fail!(),\n+            Err(e) => assert_eq!(e.name(), ~\"ECONNREFUSED\"),\n         }\n     }\n \n     #[test]\n     fn connect_close_ip6() {\n-        do run_in_bare_thread() {\n-            let mut loop_ = Loop::new();\n-            let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-            // Connect to a port where nobody is listening\n-            let addr = next_test_ip6();\n-            do tcp_watcher.connect(addr) |stream_watcher, status| {\n-                uvdebug!(\"tcp_watcher.connect!\");\n-                assert!(status.is_some());\n-                assert_eq!(status.unwrap().name(), ~\"ECONNREFUSED\");\n-                stream_watcher.close(||());\n-            }\n-            loop_.run();\n-            loop_.close();\n+        match TcpWatcher::connect(local_loop(), next_test_ip6()) {\n+            Ok(*) => fail!(),\n+            Err(e) => assert_eq!(e.name(), ~\"ECONNREFUSED\"),\n         }\n     }\n \n     #[test]\n     fn udp_bind_close_ip4() {\n-        do run_in_bare_thread() {\n-            let mut loop_ = Loop::new();\n-            let mut udp_watcher = { UdpWatcher::new(&mut loop_) };\n-            let addr = next_test_ip4();\n-            udp_watcher.bind(addr);\n-            udp_watcher.close(||());\n-            loop_.run();\n-            loop_.close();\n+        match UdpWatcher::bind(local_loop(), next_test_ip4()) {\n+            Ok(*) => {}\n+            Err(*) => fail!()\n         }\n     }\n \n     #[test]\n     fn udp_bind_close_ip6() {\n-        do run_in_bare_thread() {\n-            let mut loop_ = Loop::new();\n-            let mut udp_watcher = { UdpWatcher::new(&mut loop_) };\n-            let addr = next_test_ip6();\n-            udp_watcher.bind(addr);\n-            udp_watcher.close(||());\n-            loop_.run();\n-            loop_.close();\n+        match UdpWatcher::bind(local_loop(), next_test_ip6()) {\n+            Ok(*) => {}\n+            Err(*) => fail!()\n         }\n     }\n \n     #[test]\n     fn listen_ip4() {\n-        do run_in_bare_thread() {\n-            static MAX: int = 10;\n-            let mut loop_ = Loop::new();\n-            let mut server_tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-            let addr = next_test_ip4();\n-            server_tcp_watcher.bind(addr);\n-            let loop_ = loop_;\n-            uvdebug!(\"listening\");\n-            let mut stream = server_tcp_watcher.as_stream();\n-            let res = do stream.listen |mut server_stream_watcher, status| {\n-                uvdebug!(\"listened!\");\n-                assert!(status.is_none());\n-                let mut loop_ = loop_;\n-                let client_tcp_watcher = TcpWatcher::new(&mut loop_);\n-                let mut client_tcp_watcher = client_tcp_watcher.as_stream();\n-                server_stream_watcher.accept(client_tcp_watcher);\n-                let count_cell = Cell::new(0);\n-                let server_stream_watcher = server_stream_watcher;\n-                uvdebug!(\"starting read\");\n-                let alloc: AllocCallback = |size| {\n-                    vec_to_uv_buf(vec::from_elem(size, 0u8))\n-                };\n-                do client_tcp_watcher.read_start(alloc) |stream_watcher, nread, buf, status| {\n-\n-                    uvdebug!(\"i'm reading!\");\n-                    let buf = vec_from_uv_buf(buf);\n-                    let mut count = count_cell.take();\n-                    if status.is_none() {\n-                        uvdebug!(\"got {} bytes\", nread);\n-                        let buf = buf.unwrap();\n-                        for byte in buf.slice(0, nread as uint).iter() {\n-                            assert!(*byte == count as u8);\n-                            uvdebug!(\"{}\", *byte as uint);\n-                            count += 1;\n-                        }\n-                    } else {\n-                        assert_eq!(count, MAX);\n-                        do stream_watcher.close {\n-                            server_stream_watcher.close(||());\n-                        }\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let addr = next_test_ip4();\n+\n+        do spawn {\n+            let w = match TcpListener::bind(local_loop(), addr) {\n+                Ok(w) => w, Err(e) => fail!(\"{:?}\", e)\n+            };\n+            let mut w = match w.listen() {\n+                Ok(w) => w, Err(e) => fail!(\"{:?}\", e),\n+            };\n+            chan.take().send(());\n+            match w.accept() {\n+                Ok(mut stream) => {\n+                    let mut buf = [0u8, ..10];\n+                    match stream.read(buf) {\n+                        Ok(10) => {} e => fail!(\"{:?}\", e),\n+                    }\n+                    for i in range(0, 10u8) {\n+                        assert_eq!(buf[i], i + 1);\n                     }\n-                    count_cell.put_back(count);\n                 }\n-            };\n+                Err(e) => fail!(\"{:?}\", e)\n+            }\n+        }\n \n-            assert!(res.is_ok());\n-\n-            let client_thread = do Thread::start {\n-                uvdebug!(\"starting client thread\");\n-                let mut loop_ = Loop::new();\n-                let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-                do tcp_watcher.connect(addr) |mut stream_watcher, status| {\n-                    uvdebug!(\"connecting\");\n-                    assert!(status.is_none());\n-                    let msg = ~[0, 1, 2, 3, 4, 5, 6 ,7 ,8, 9];\n-                    let buf = slice_to_uv_buf(msg);\n-                    let msg_cell = Cell::new(msg);\n-                    do stream_watcher.write(buf) |stream_watcher, status| {\n-                        uvdebug!(\"writing\");\n-                        assert!(status.is_none());\n-                        let msg_cell = Cell::new(msg_cell.take());\n-                        stream_watcher.close(||ignore(msg_cell.take()));\n+        port.recv();\n+        let mut w = match TcpWatcher::connect(local_loop(), addr) {\n+            Ok(w) => w, Err(e) => fail!(\"{:?}\", e)\n+        };\n+        match w.write([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) {\n+            Ok(()) => {}, Err(e) => fail!(\"{:?}\", e)\n+        }\n+    }\n+\n+    #[test]\n+    fn listen_ip6() {\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let addr = next_test_ip6();\n+\n+        do spawn {\n+            let w = match TcpListener::bind(local_loop(), addr) {\n+                Ok(w) => w, Err(e) => fail!(\"{:?}\", e)\n+            };\n+            let mut w = match w.listen() {\n+                Ok(w) => w, Err(e) => fail!(\"{:?}\", e),\n+            };\n+            chan.take().send(());\n+            match w.accept() {\n+                Ok(mut stream) => {\n+                    let mut buf = [0u8, ..10];\n+                    match stream.read(buf) {\n+                        Ok(10) => {} e => fail!(\"{:?}\", e),\n+                    }\n+                    for i in range(0, 10u8) {\n+                        assert_eq!(buf[i], i + 1);\n                     }\n                 }\n-                loop_.run();\n-                loop_.close();\n-            };\n+                Err(e) => fail!(\"{:?}\", e)\n+            }\n+        }\n \n-            let mut loop_ = loop_;\n-            loop_.run();\n-            loop_.close();\n-            client_thread.join();\n+        port.recv();\n+        let mut w = match TcpWatcher::connect(local_loop(), addr) {\n+            Ok(w) => w, Err(e) => fail!(\"{:?}\", e)\n         };\n+        match w.write([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) {\n+            Ok(()) => {}, Err(e) => fail!(\"{:?}\", e)\n+        }\n     }\n \n     #[test]\n-    fn listen_ip6() {\n-        do run_in_bare_thread() {\n-            static MAX: int = 10;\n-            let mut loop_ = Loop::new();\n-            let mut server_tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-            let addr = next_test_ip6();\n-            server_tcp_watcher.bind(addr);\n-            let loop_ = loop_;\n-            uvdebug!(\"listening\");\n-            let mut stream = server_tcp_watcher.as_stream();\n-            let res = do stream.listen |mut server_stream_watcher, status| {\n-                uvdebug!(\"listened!\");\n-                assert!(status.is_none());\n-                let mut loop_ = loop_;\n-                let client_tcp_watcher = TcpWatcher::new(&mut loop_);\n-                let mut client_tcp_watcher = client_tcp_watcher.as_stream();\n-                server_stream_watcher.accept(client_tcp_watcher);\n-                let count_cell = Cell::new(0);\n-                let server_stream_watcher = server_stream_watcher;\n-                uvdebug!(\"starting read\");\n-                let alloc: AllocCallback = |size| {\n-                    vec_to_uv_buf(vec::from_elem(size, 0u8))\n-                };\n-                do client_tcp_watcher.read_start(alloc)\n-                    |stream_watcher, nread, buf, status| {\n-\n-                    uvdebug!(\"i'm reading!\");\n-                    let buf = vec_from_uv_buf(buf);\n-                    let mut count = count_cell.take();\n-                    if status.is_none() {\n-                        uvdebug!(\"got {} bytes\", nread);\n-                        let buf = buf.unwrap();\n-                        let r = buf.slice(0, nread as uint);\n-                        for byte in r.iter() {\n-                            assert!(*byte == count as u8);\n-                            uvdebug!(\"{}\", *byte as uint);\n-                            count += 1;\n-                        }\n-                    } else {\n-                        assert_eq!(count, MAX);\n-                        do stream_watcher.close {\n-                            server_stream_watcher.close(||());\n-                        }\n+    fn udp_recv_ip4() {\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let client = next_test_ip4();\n+        let server = next_test_ip4();\n+\n+        do spawn {\n+            match UdpWatcher::bind(local_loop(), server) {\n+                Ok(mut w) => {\n+                    chan.take().send(());\n+                    let mut buf = [0u8, ..10];\n+                    match w.recvfrom(buf) {\n+                        Ok((10, addr)) => assert_eq!(addr, client),\n+                        e => fail!(\"{:?}\", e),\n+                    }\n+                    for i in range(0, 10u8) {\n+                        assert_eq!(buf[i], i + 1);\n                     }\n-                    count_cell.put_back(count);\n                 }\n-            };\n-            assert!(res.is_ok());\n-\n-            let client_thread = do Thread::start {\n-                uvdebug!(\"starting client thread\");\n-                let mut loop_ = Loop::new();\n-                let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-                do tcp_watcher.connect(addr) |mut stream_watcher, status| {\n-                    uvdebug!(\"connecting\");\n-                    assert!(status.is_none());\n-                    let msg = ~[0, 1, 2, 3, 4, 5, 6 ,7 ,8, 9];\n-                    let buf = slice_to_uv_buf(msg);\n-                    let msg_cell = Cell::new(msg);\n-                    do stream_watcher.write(buf) |stream_watcher, status| {\n-                        uvdebug!(\"writing\");\n-                        assert!(status.is_none());\n-                        let msg_cell = Cell::new(msg_cell.take());\n-                        stream_watcher.close(||ignore(msg_cell.take()));\n+                Err(e) => fail!(\"{:?}\", e)\n+            }\n+        }\n+\n+        port.recv();\n+        let mut w = match UdpWatcher::bind(local_loop(), client) {\n+            Ok(w) => w, Err(e) => fail!(\"{:?}\", e)\n+        };\n+        match w.sendto([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], server) {\n+            Ok(()) => {}, Err(e) => fail!(\"{:?}\", e)\n+        }\n+    }\n+\n+    #[test]\n+    fn udp_recv_ip6() {\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let client = next_test_ip6();\n+        let server = next_test_ip6();\n+\n+        do spawn {\n+            match UdpWatcher::bind(local_loop(), server) {\n+                Ok(mut w) => {\n+                    chan.take().send(());\n+                    let mut buf = [0u8, ..10];\n+                    match w.recvfrom(buf) {\n+                        Ok((10, addr)) => assert_eq!(addr, client),\n+                        e => fail!(\"{:?}\", e),\n+                    }\n+                    for i in range(0, 10u8) {\n+                        assert_eq!(buf[i], i + 1);\n                     }\n                 }\n-                loop_.run();\n-                loop_.close();\n-            };\n+                Err(e) => fail!(\"{:?}\", e)\n+            }\n+        }\n \n-            let mut loop_ = loop_;\n-            loop_.run();\n-            loop_.close();\n-            client_thread.join();\n+        port.recv();\n+        let mut w = match UdpWatcher::bind(local_loop(), client) {\n+            Ok(w) => w, Err(e) => fail!(\"{:?}\", e)\n+        };\n+        match w.sendto([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], server) {\n+            Ok(()) => {}, Err(e) => fail!(\"{:?}\", e)\n         }\n     }\n \n     #[test]\n-    fn udp_recv_ip4() {\n-        do run_in_bare_thread() {\n-            static MAX: int = 10;\n-            let mut loop_ = Loop::new();\n-            let server_addr = next_test_ip4();\n-            let client_addr = next_test_ip4();\n-\n-            let mut server = UdpWatcher::new(&loop_);\n-            assert!(server.bind(server_addr).is_ok());\n-\n-            uvdebug!(\"starting read\");\n-            let alloc: AllocCallback = |size| {\n-                vec_to_uv_buf(vec::from_elem(size, 0u8))\n-            };\n+    fn test_read_read_read() {\n+        use std::rt::rtio::*;\n+        let addr = next_test_ip4();\n+        static MAX: uint = 5000;\n+        let (port, chan) = oneshot();\n+        let port = Cell::new(port);\n+        let chan = Cell::new(chan);\n+\n+        do spawn {\n+            let listener = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut acceptor = listener.listen().unwrap();\n+            chan.take().send(());\n+            let mut stream = acceptor.accept().unwrap();\n+            let buf = [1, .. 2048];\n+            let mut total_bytes_written = 0;\n+            while total_bytes_written < MAX {\n+                assert!(stream.write(buf).is_ok());\n+                uvdebug!(\"wrote bytes\");\n+                total_bytes_written += buf.len();\n+            }\n+        }\n \n-            do server.recv_start(alloc) |mut server, nread, buf, src, flags, status| {\n-                server.recv_stop();\n-                uvdebug!(\"i'm reading!\");\n-                assert!(status.is_none());\n-                assert_eq!(flags, 0);\n-                assert_eq!(src, client_addr);\n-\n-                let buf = vec_from_uv_buf(buf);\n-                let mut count = 0;\n-                uvdebug!(\"got {} bytes\", nread);\n-\n-                let buf = buf.unwrap();\n-                for &byte in buf.slice(0, nread as uint).iter() {\n-                    assert!(byte == count as u8);\n-                    uvdebug!(\"{}\", byte as uint);\n-                    count += 1;\n+        do spawn {\n+            port.take().recv();\n+            let mut stream = TcpWatcher::connect(local_loop(), addr).unwrap();\n+            let mut buf = [0, .. 2048];\n+            let mut total_bytes_read = 0;\n+            while total_bytes_read < MAX {\n+                let nread = stream.read(buf).unwrap();\n+                total_bytes_read += nread;\n+                for i in range(0u, nread) {\n+                    assert_eq!(buf[i], 1);\n                 }\n-                assert_eq!(count, MAX);\n+            }\n+            uvdebug!(\"read {} bytes total\", total_bytes_read);\n+        }\n+    }\n+\n+    #[test]\n+    #[ignore(cfg(windows))] // FIXME(#10102) server never sees second packet\n+    fn test_udp_twice() {\n+        let server_addr = next_test_ip4();\n+        let client_addr = next_test_ip4();\n+        let (port, chan) = oneshot();\n+        let port = Cell::new(port);\n+        let chan = Cell::new(chan);\n+\n+        do spawn {\n+            let mut client = UdpWatcher::bind(local_loop(), client_addr).unwrap();\n+            port.take().recv();\n+            assert!(client.sendto([1], server_addr).is_ok());\n+            assert!(client.sendto([2], server_addr).is_ok());\n+        }\n \n-                server.close(||{});\n+        let mut server = UdpWatcher::bind(local_loop(), server_addr).unwrap();\n+        chan.take().send(());\n+        let mut buf1 = [0];\n+        let mut buf2 = [0];\n+        let (nread1, src1) = server.recvfrom(buf1).unwrap();\n+        let (nread2, src2) = server.recvfrom(buf2).unwrap();\n+        assert_eq!(nread1, 1);\n+        assert_eq!(nread2, 1);\n+        assert_eq!(src1, client_addr);\n+        assert_eq!(src2, client_addr);\n+        assert_eq!(buf1[0], 1);\n+        assert_eq!(buf2[0], 2);\n+    }\n+\n+    #[test]\n+    fn test_udp_many_read() {\n+        let server_out_addr = next_test_ip4();\n+        let server_in_addr = next_test_ip4();\n+        let client_out_addr = next_test_ip4();\n+        let client_in_addr = next_test_ip4();\n+        static MAX: uint = 500_000;\n+\n+        let (p1, c1) = oneshot();\n+        let (p2, c2) = oneshot();\n+\n+        let first = Cell::new((p1, c2));\n+        let second = Cell::new((p2, c1));\n+\n+        do spawn {\n+            let l = local_loop();\n+            let mut server_out = UdpWatcher::bind(l, server_out_addr).unwrap();\n+            let mut server_in = UdpWatcher::bind(l, server_in_addr).unwrap();\n+            let (port, chan) = first.take();\n+            chan.send(());\n+            port.recv();\n+            let msg = [1, .. 2048];\n+            let mut total_bytes_sent = 0;\n+            let mut buf = [1];\n+            while buf[0] == 1 {\n+                // send more data\n+                assert!(server_out.sendto(msg, client_in_addr).is_ok());\n+                total_bytes_sent += msg.len();\n+                // check if the client has received enough\n+                let res = server_in.recvfrom(buf);\n+                assert!(res.is_ok());\n+                let (nread, src) = res.unwrap();\n+                assert_eq!(nread, 1);\n+                assert_eq!(src, client_out_addr);\n             }\n+            assert!(total_bytes_sent >= MAX);\n+        }\n \n-            let thread = do Thread::start {\n-                let mut loop_ = Loop::new();\n-                let mut client = UdpWatcher::new(&loop_);\n-                assert!(client.bind(client_addr).is_ok());\n-                let msg = ~[0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n-                let buf = slice_to_uv_buf(msg);\n-                do client.send(buf, server_addr) |client, status| {\n-                    uvdebug!(\"writing\");\n-                    assert!(status.is_none());\n-                    client.close(||{});\n+        do spawn {\n+            let l = local_loop();\n+            let mut client_out = UdpWatcher::bind(l, client_out_addr).unwrap();\n+            let mut client_in = UdpWatcher::bind(l, client_in_addr).unwrap();\n+            let (port, chan) = second.take();\n+            port.recv();\n+            chan.send(());\n+            let mut total_bytes_recv = 0;\n+            let mut buf = [0, .. 2048];\n+            while total_bytes_recv < MAX {\n+                // ask for more\n+                assert!(client_out.sendto([1], server_in_addr).is_ok());\n+                // wait for data\n+                let res = client_in.recvfrom(buf);\n+                assert!(res.is_ok());\n+                let (nread, src) = res.unwrap();\n+                assert_eq!(src, server_out_addr);\n+                total_bytes_recv += nread;\n+                for i in range(0u, nread) {\n+                    assert_eq!(buf[i], 1);\n                 }\n+            }\n+            // tell the server we're done\n+            assert!(client_out.sendto([0], server_in_addr).is_ok());\n+        }\n+    }\n \n-                loop_.run();\n-                loop_.close();\n-            };\n+    #[test]\n+    fn test_read_and_block() {\n+        let addr = next_test_ip4();\n+        let (port, chan) = oneshot();\n+        let port = Cell::new(port);\n+        let chan = Cell::new(chan);\n+\n+        do spawn {\n+            let listener = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut acceptor = listener.listen().unwrap();\n+            let (port2, chan2) = stream();\n+            chan.take().send(port2);\n+            let mut stream = acceptor.accept().unwrap();\n+            let mut buf = [0, .. 2048];\n+\n+            let expected = 32;\n+            let mut current = 0;\n+            let mut reads = 0;\n+\n+            while current < expected {\n+                let nread = stream.read(buf).unwrap();\n+                for i in range(0u, nread) {\n+                    let val = buf[i] as uint;\n+                    assert_eq!(val, current % 8);\n+                    current += 1;\n+                }\n+                reads += 1;\n+\n+                chan2.send(());\n+            }\n+\n+            // Make sure we had multiple reads\n+            assert!(reads > 1);\n+        }\n \n-            loop_.run();\n-            loop_.close();\n-            thread.join();\n+        do spawn {\n+            let port2 = port.take().recv();\n+            let mut stream = TcpWatcher::connect(local_loop(), addr).unwrap();\n+            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n+            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n+            port2.recv();\n+            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n+            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n+            port2.recv();\n         }\n     }\n \n     #[test]\n-    fn udp_recv_ip6() {\n-        do run_in_bare_thread() {\n-            static MAX: int = 10;\n-            let mut loop_ = Loop::new();\n-            let server_addr = next_test_ip6();\n-            let client_addr = next_test_ip6();\n-\n-            let mut server = UdpWatcher::new(&loop_);\n-            assert!(server.bind(server_addr).is_ok());\n-\n-            uvdebug!(\"starting read\");\n-            let alloc: AllocCallback = |size| {\n-                vec_to_uv_buf(vec::from_elem(size, 0u8))\n+    fn test_simple_tcp_server_and_client_on_diff_threads() {\n+        let addr = next_test_ip4();\n+\n+        do task::spawn_sched(task::SingleThreaded) {\n+            let listener = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut acceptor = listener.listen().unwrap();\n+            let mut stream = acceptor.accept().unwrap();\n+            let mut buf = [0, .. 2048];\n+            let nread = stream.read(buf).unwrap();\n+            assert_eq!(nread, 8);\n+            for i in range(0u, nread) {\n+                assert_eq!(buf[i], i as u8);\n+            }\n+        }\n+\n+        do task::spawn_sched(task::SingleThreaded) {\n+            let mut stream = TcpWatcher::connect(local_loop(), addr);\n+            while stream.is_err() {\n+                stream = TcpWatcher::connect(local_loop(), addr);\n+            }\n+            stream.unwrap().write([0, 1, 2, 3, 4, 5, 6, 7]);\n+        }\n+    }\n+\n+    // On one thread, create a udp socket. Then send that socket to another\n+    // thread and destroy the socket on the remote thread. This should make sure\n+    // that homing kicks in for the socket to go back home to the original\n+    // thread, close itself, and then come back to the last thread.\n+    #[test]\n+    fn test_homing_closes_correctly() {\n+        let (port, chan) = oneshot();\n+        let port = Cell::new(port);\n+        let chan = Cell::new(chan);\n+\n+        do task::spawn_sched(task::SingleThreaded) {\n+            let chan = Cell::new(chan.take());\n+            let listener = UdpWatcher::bind(local_loop(), next_test_ip4()).unwrap();\n+            chan.take().send(listener);\n+        }\n+\n+        do task::spawn_sched(task::SingleThreaded) {\n+            let port = Cell::new(port.take());\n+            port.take().recv();\n+        }\n+    }\n+\n+    // This is a bit of a crufty old test, but it has its uses.\n+    #[test]\n+    fn test_simple_homed_udp_io_bind_then_move_task_then_home_and_close() {\n+        use std::cast;\n+        use std::rt::local::Local;\n+        use std::rt::rtio::{EventLoop, IoFactory};\n+        use std::rt::sched::Scheduler;\n+        use std::rt::sched::{Shutdown, TaskFromFriend};\n+        use std::rt::sleeper_list::SleeperList;\n+        use std::rt::task::Task;\n+        use std::rt::task::UnwindResult;\n+        use std::rt::thread::Thread;\n+        use std::rt::work_queue::WorkQueue;\n+        use std::unstable::run_in_bare_thread;\n+        use uvio::UvEventLoop;\n+\n+        do run_in_bare_thread {\n+            let sleepers = SleeperList::new();\n+            let work_queue1 = WorkQueue::new();\n+            let work_queue2 = WorkQueue::new();\n+            let queues = ~[work_queue1.clone(), work_queue2.clone()];\n+\n+            let loop1 = ~UvEventLoop::new() as ~EventLoop;\n+            let mut sched1 = ~Scheduler::new(loop1, work_queue1, queues.clone(),\n+                                             sleepers.clone());\n+            let loop2 = ~UvEventLoop::new() as ~EventLoop;\n+            let mut sched2 = ~Scheduler::new(loop2, work_queue2, queues.clone(),\n+                                             sleepers.clone());\n+\n+            let handle1 = Cell::new(sched1.make_handle());\n+            let handle2 = Cell::new(sched2.make_handle());\n+            let tasksFriendHandle = Cell::new(sched2.make_handle());\n+\n+            let on_exit: ~fn(UnwindResult) = |exit_status| {\n+                handle1.take().send(Shutdown);\n+                handle2.take().send(Shutdown);\n+                assert!(exit_status.is_success());\n             };\n \n-            do server.recv_start(alloc) |mut server, nread, buf, src, flags, status| {\n-                server.recv_stop();\n-                uvdebug!(\"i'm reading!\");\n-                assert!(status.is_none());\n-                assert_eq!(flags, 0);\n-                assert_eq!(src, client_addr);\n-\n-                let buf = vec_from_uv_buf(buf);\n-                let mut count = 0;\n-                uvdebug!(\"got {} bytes\", nread);\n-\n-                let buf = buf.unwrap();\n-                for &byte in buf.slice(0, nread as uint).iter() {\n-                    assert!(byte == count as u8);\n-                    uvdebug!(\"{}\", byte as uint);\n-                    count += 1;\n+            unsafe fn local_io() -> &'static mut IoFactory {\n+                do Local::borrow |sched: &mut Scheduler| {\n+                    let mut io = None;\n+                    sched.event_loop.io(|i| io = Some(i));\n+                    cast::transmute(io.unwrap())\n                 }\n-                assert_eq!(count, MAX);\n-\n-                server.close(||{});\n             }\n \n-            let thread = do Thread::start {\n-                let mut loop_ = Loop::new();\n-                let mut client = UdpWatcher::new(&loop_);\n-                assert!(client.bind(client_addr).is_ok());\n-                let msg = ~[0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n-                let buf = slice_to_uv_buf(msg);\n-                do client.send(buf, server_addr) |client, status| {\n-                    uvdebug!(\"writing\");\n-                    assert!(status.is_none());\n-                    client.close(||{});\n+            let test_function: ~fn() = || {\n+                let io = unsafe { local_io() };\n+                let addr = next_test_ip4();\n+                let maybe_socket = io.udp_bind(addr);\n+                // this socket is bound to this event loop\n+                assert!(maybe_socket.is_ok());\n+\n+                // block self on sched1\n+                do task::unkillable { // FIXME(#8674)\n+                    let scheduler: ~Scheduler = Local::take();\n+                    do scheduler.deschedule_running_task_and_then |_, task| {\n+                        // unblock task\n+                        do task.wake().map |task| {\n+                            // send self to sched2\n+                            tasksFriendHandle.take().send(TaskFromFriend(task));\n+                        };\n+                        // sched1 should now sleep since it has nothing else to do\n+                    }\n                 }\n+                // sched2 will wake up and get the task as we do nothing else,\n+                // the function ends and the socket goes out of scope sched2\n+                // will start to run the destructor the destructor will first\n+                // block the task, set it's home as sched1, then enqueue it\n+                // sched2 will dequeue the task, see that it has a home, and\n+                // send it to sched1 sched1 will wake up, exec the close\n+                // function on the correct loop, and then we're done\n+            };\n \n-                loop_.run();\n-                loop_.close();\n+            let mut main_task = ~Task::new_root(&mut sched1.stack_pool, None,\n+                                                test_function);\n+            main_task.death.on_exit = Some(on_exit);\n+            let main_task = Cell::new(main_task);\n+\n+            let null_task = Cell::new(~do Task::new_root(&mut sched2.stack_pool,\n+                                                         None) || {});\n+\n+            let sched1 = Cell::new(sched1);\n+            let sched2 = Cell::new(sched2);\n+\n+            let thread1 = do Thread::start {\n+                sched1.take().bootstrap(main_task.take());\n+            };\n+            let thread2 = do Thread::start {\n+                sched2.take().bootstrap(null_task.take());\n             };\n \n-            loop_.run();\n-            loop_.close();\n-            thread.join();\n+            thread1.join();\n+            thread2.join();\n+        }\n+    }\n+\n+    #[should_fail] #[test]\n+    fn tcp_listener_fail_cleanup() {\n+        let addr = next_test_ip4();\n+        let w = TcpListener::bind(local_loop(), addr).unwrap();\n+        let _w = w.listen().unwrap();\n+        fail!();\n+    }\n+\n+    #[should_fail] #[test]\n+    fn tcp_stream_fail_cleanup() {\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let addr = next_test_ip4();\n+\n+        do task::spawn_unlinked { // please no linked failure\n+            let w = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut w = w.listen().unwrap();\n+            chan.take().send(());\n+            w.accept();\n+        }\n+        port.recv();\n+        let _w = TcpWatcher::connect(local_loop(), addr).unwrap();\n+        fail!();\n+    }\n+\n+    #[should_fail] #[test]\n+    fn udp_listener_fail_cleanup() {\n+        let addr = next_test_ip4();\n+        let _w = UdpWatcher::bind(local_loop(), addr).unwrap();\n+        fail!();\n+    }\n+\n+    #[should_fail] #[test]\n+    fn udp_fail_other_task() {\n+        let addr = next_test_ip4();\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+\n+        // force the handle to be created on a different scheduler, failure in\n+        // the original task will force a homing operation back to this\n+        // scheduler.\n+        do task::spawn_sched(task::SingleThreaded) {\n+            let w = UdpWatcher::bind(local_loop(), addr).unwrap();\n+            chan.take().send(w);\n+        }\n+\n+        let _w = port.recv();\n+        fail!();\n+    }\n+\n+    #[should_fail]\n+    #[test]\n+    #[ignore(reason = \"linked failure\")]\n+    fn linked_failure1() {\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let addr = next_test_ip4();\n+\n+        do spawn {\n+            let w = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut w = w.listen().unwrap();\n+            chan.take().send(());\n+            w.accept();\n+        }\n+\n+        port.recv();\n+        fail!();\n+    }\n+\n+    #[should_fail]\n+    #[test]\n+    #[ignore(reason = \"linked failure\")]\n+    fn linked_failure2() {\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+        let addr = next_test_ip4();\n+\n+        do spawn {\n+            let w = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut w = w.listen().unwrap();\n+            chan.take().send(());\n+            let mut buf = [0];\n+            w.accept().unwrap().read(buf);\n         }\n+\n+        port.recv();\n+        let _w = TcpWatcher::connect(local_loop(), addr).unwrap();\n+\n+        fail!();\n+    }\n+\n+    #[should_fail]\n+    #[test]\n+    #[ignore(reason = \"linked failure\")]\n+    fn linked_failure3() {\n+        let (port, chan) = stream();\n+        let chan = Cell::new(chan);\n+        let addr = next_test_ip4();\n+\n+        do spawn {\n+            let chan = chan.take();\n+            let w = TcpListener::bind(local_loop(), addr).unwrap();\n+            let mut w = w.listen().unwrap();\n+            chan.send(());\n+            let mut conn = w.accept().unwrap();\n+            chan.send(());\n+            let buf = [0, ..65536];\n+            conn.write(buf);\n+        }\n+\n+        port.recv();\n+        let _w = TcpWatcher::connect(local_loop(), addr).unwrap();\n+        port.recv();\n+        fail!();\n     }\n }"}, {"sha": "c123f916ef23f73973dd514419b8992268f4f26b", "filename": "src/librustuv/pipe.rs", "status": "modified", "additions": 290, "deletions": 54, "changes": 344, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fpipe.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,91 +8,327 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::libc;\n use std::c_str::CString;\n+use std::libc;\n+use std::rt::BlockedTask;\n+use std::rt::io::IoError;\n+use std::rt::local::Local;\n+use std::rt::rtio::{RtioPipe, RtioUnixListener, RtioUnixAcceptor};\n+use std::rt::sched::{Scheduler, SchedHandle};\n+use std::rt::tube::Tube;\n+use std::task;\n \n-use super::{Loop, UvError, Watcher, NativeHandle, status_to_maybe_uv_error};\n-use super::ConnectionCallback;\n-use net;\n+use stream::StreamWatcher;\n+use super::{Loop, UvError, UvHandle, Request, uv_error_to_io_error,\n+            wait_until_woken_after};\n+use uvio::HomingIO;\n use uvll;\n \n-pub struct Pipe(*uvll::uv_pipe_t);\n+pub struct PipeWatcher {\n+    stream: StreamWatcher,\n+    home: SchedHandle,\n+    priv defused: bool,\n+}\n \n-impl Watcher for Pipe {}\n+pub struct PipeListener {\n+    home: SchedHandle,\n+    pipe: *uvll::uv_pipe_t,\n+    priv outgoing: Tube<Result<~RtioPipe, IoError>>,\n+}\n \n-impl Pipe {\n-    pub fn new(loop_: &Loop, ipc: bool) -> Pipe {\n-        unsafe {\n+pub struct PipeAcceptor {\n+    listener: ~PipeListener,\n+    priv incoming: Tube<Result<~RtioPipe, IoError>>,\n+}\n+\n+// PipeWatcher implementation and traits\n+\n+impl PipeWatcher {\n+    // Creates an uninitialized pipe watcher. The underlying uv pipe is ready to\n+    // get bound to some other source (this is normally a helper method paired\n+    // with another call).\n+    pub fn new(loop_: &Loop, ipc: bool) -> PipeWatcher {\n+        let handle = unsafe {\n             let handle = uvll::malloc_handle(uvll::UV_NAMED_PIPE);\n-            assert!(handle.is_not_null());\n+            assert!(!handle.is_null());\n             let ipc = ipc as libc::c_int;\n-            assert_eq!(uvll::pipe_init(loop_.native_handle(), handle, ipc), 0);\n-            let mut ret: Pipe =\n-                    NativeHandle::from_native_handle(handle);\n-            ret.install_watcher_data();\n-            ret\n+            assert_eq!(uvll::uv_pipe_init(loop_.handle, handle, ipc), 0);\n+            handle\n+        };\n+        PipeWatcher {\n+            stream: StreamWatcher::new(handle),\n+            home: get_handle_to_current_scheduler!(),\n+            defused: false,\n         }\n     }\n \n-    pub fn as_stream(&self) -> net::StreamWatcher {\n-        net::StreamWatcher(**self as *uvll::uv_stream_t)\n-    }\n-\n-    #[fixed_stack_segment] #[inline(never)]\n-    pub fn open(&mut self, file: libc::c_int) -> Result<(), UvError> {\n-        match unsafe { uvll::pipe_open(self.native_handle(), file) } {\n-            0 => Ok(()),\n+    pub fn open(loop_: &Loop, file: libc::c_int) -> Result<PipeWatcher, UvError>\n+    {\n+        let pipe = PipeWatcher::new(loop_, false);\n+        match unsafe { uvll::uv_pipe_open(pipe.handle(), file) } {\n+            0 => Ok(pipe),\n             n => Err(UvError(n))\n         }\n     }\n \n-    #[fixed_stack_segment] #[inline(never)]\n-    pub fn bind(&mut self, name: &CString) -> Result<(), UvError> {\n-        do name.with_ref |name| {\n-            match unsafe { uvll::pipe_bind(self.native_handle(), name) } {\n-                0 => Ok(()),\n+    pub fn connect(loop_: &Loop, name: &CString) -> Result<PipeWatcher, UvError>\n+    {\n+        struct Ctx { task: Option<BlockedTask>, result: libc::c_int, }\n+        return do task::unkillable {\n+            let mut cx = Ctx { task: None, result: 0 };\n+            let mut req = Request::new(uvll::UV_CONNECT);\n+            let pipe = PipeWatcher::new(loop_, false);\n+\n+            do wait_until_woken_after(&mut cx.task) {\n+                unsafe {\n+                    uvll::uv_pipe_connect(req.handle,\n+                                          pipe.handle(),\n+                                          name.with_ref(|p| p),\n+                                          connect_cb)\n+                }\n+                req.set_data(&cx);\n+                req.defuse(); // uv callback now owns this request\n+            }\n+            match cx.result {\n+                0 => Ok(pipe),\n                 n => Err(UvError(n))\n             }\n+\n+        };\n+\n+        extern fn connect_cb(req: *uvll::uv_connect_t, status: libc::c_int) {;\n+            let req = Request::wrap(req);\n+            assert!(status != uvll::ECANCELED);\n+            let cx: &mut Ctx = unsafe { req.get_data() };\n+            cx.result = status;\n+            let sched: ~Scheduler = Local::take();\n+            sched.resume_blocked_task_immediately(cx.task.take_unwrap());\n         }\n     }\n \n-    #[fixed_stack_segment] #[inline(never)]\n-    pub fn connect(&mut self, name: &CString, cb: ConnectionCallback) {\n-        {\n-            let data = self.get_watcher_data();\n-            assert!(data.connect_cb.is_none());\n-            data.connect_cb = Some(cb);\n+    pub fn handle(&self) -> *uvll::uv_pipe_t { self.stream.handle }\n+\n+    // Unwraps the underlying uv pipe. This cancels destruction of the pipe and\n+    // allows the pipe to get moved elsewhere\n+    fn unwrap(mut self) -> *uvll::uv_pipe_t {\n+        self.defused = true;\n+        return self.stream.handle;\n+    }\n+}\n+\n+impl RtioPipe for PipeWatcher {\n+    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.stream.read(buf).map_err(uv_error_to_io_error)\n+    }\n+\n+    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.stream.write(buf).map_err(uv_error_to_io_error)\n+    }\n+}\n+\n+impl HomingIO for PipeWatcher {\n+    fn home<'a>(&'a mut self) -> &'a mut SchedHandle { &mut self.home }\n+}\n+\n+impl UvHandle<uvll::uv_pipe_t> for PipeWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_pipe_t { self.stream.handle }\n+}\n+\n+impl Drop for PipeWatcher {\n+    fn drop(&mut self) {\n+        if !self.defused {\n+            let _m = self.fire_homing_missile();\n+            self.close();\n         }\n+    }\n+}\n+\n+extern fn pipe_close_cb(handle: *uvll::uv_handle_t) {\n+    unsafe { uvll::free_handle(handle) }\n+}\n \n-        let connect = net::ConnectRequest::new();\n-        let name = do name.with_ref |p| { p };\n+// PipeListener implementation and traits\n \n-        unsafe {\n-            uvll::pipe_connect(connect.native_handle(),\n-                               self.native_handle(),\n-                               name,\n-                               connect_cb)\n+impl PipeListener {\n+    pub fn bind(loop_: &Loop, name: &CString) -> Result<~PipeListener, UvError> {\n+        do task::unkillable {\n+            let pipe = PipeWatcher::new(loop_, false);\n+            match unsafe {\n+                uvll::uv_pipe_bind(pipe.handle(), name.with_ref(|p| p))\n+            } {\n+                0 => {\n+                    // If successful, unwrap the PipeWatcher because we control how\n+                    // we close the pipe differently. We can't rely on\n+                    // StreamWatcher's default close method.\n+                    let p = ~PipeListener {\n+                        home: get_handle_to_current_scheduler!(),\n+                        pipe: pipe.unwrap(),\n+                        outgoing: Tube::new(),\n+                    };\n+                    Ok(p.install())\n+                }\n+                n => Err(UvError(n))\n+            }\n         }\n+    }\n+}\n \n-        extern \"C\" fn connect_cb(req: *uvll::uv_connect_t, status: libc::c_int) {\n-            let connect_request: net::ConnectRequest =\n-                    NativeHandle::from_native_handle(req);\n-            let mut stream_watcher = connect_request.stream();\n-            connect_request.delete();\n+impl RtioUnixListener for PipeListener {\n+    fn listen(mut ~self) -> Result<~RtioUnixAcceptor, IoError> {\n+        // create the acceptor object from ourselves\n+        let incoming = self.outgoing.clone();\n+        let mut acceptor = ~PipeAcceptor {\n+            listener: self,\n+            incoming: incoming,\n+        };\n \n-            let cb = stream_watcher.get_watcher_data().connect_cb.take_unwrap();\n-            let status = status_to_maybe_uv_error(status);\n-            cb(stream_watcher, status);\n+        let _m = acceptor.fire_homing_missile();\n+        // XXX: the 128 backlog should be configurable\n+        match unsafe { uvll::uv_listen(acceptor.listener.pipe, 128, listen_cb) } {\n+            0 => Ok(acceptor as ~RtioUnixAcceptor),\n+            n => Err(uv_error_to_io_error(UvError(n))),\n         }\n     }\n+}\n \n+impl HomingIO for PipeListener {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n }\n \n-impl NativeHandle<*uvll::uv_pipe_t> for Pipe {\n-    fn from_native_handle(handle: *uvll::uv_pipe_t) -> Pipe {\n-        Pipe(handle)\n+impl UvHandle<uvll::uv_pipe_t> for PipeListener {\n+    fn uv_handle(&self) -> *uvll::uv_pipe_t { self.pipe }\n+}\n+\n+extern fn listen_cb(server: *uvll::uv_stream_t, status: libc::c_int) {\n+    assert!(status != uvll::ECANCELED);\n+    let msg = match status {\n+        0 => {\n+            let loop_ = Loop::wrap(unsafe {\n+                uvll::get_loop_for_uv_handle(server)\n+            });\n+            let client = PipeWatcher::new(&loop_, false);\n+            assert_eq!(unsafe { uvll::uv_accept(server, client.handle()) }, 0);\n+            Ok(~client as ~RtioPipe)\n+        }\n+        n => Err(uv_error_to_io_error(UvError(n)))\n+    };\n+\n+    let pipe: &mut PipeListener = unsafe { UvHandle::from_uv_handle(&server) };\n+    pipe.outgoing.send(msg);\n+}\n+\n+impl Drop for PipeListener {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        self.close();\n+    }\n+}\n+\n+// PipeAcceptor implementation and traits\n+\n+impl RtioUnixAcceptor for PipeAcceptor {\n+    fn accept(&mut self) -> Result<~RtioPipe, IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.incoming.recv()\n+    }\n+}\n+\n+impl HomingIO for PipeAcceptor {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { self.listener.home() }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use std::cell::Cell;\n+    use std::comm::oneshot;\n+    use std::rt::rtio::{RtioUnixListener, RtioUnixAcceptor, RtioPipe};\n+    use std::rt::test::next_test_unix;\n+    use std::task;\n+\n+    use super::*;\n+    use super::super::local_loop;\n+\n+    #[test]\n+    #[ignore(cfg(windows))] // FIXME(#10386): how windows pipes work\n+    fn connect_err() {\n+        match PipeWatcher::connect(local_loop(), &\"path/to/nowhere\".to_c_str()) {\n+            Ok(*) => fail!(),\n+            Err(*) => {}\n+        }\n+    }\n+\n+    #[test]\n+    #[ignore(cfg(windows))] // FIXME(#10386): how windows pipes work\n+    fn bind_err() {\n+        match PipeListener::bind(local_loop(), &\"path/to/nowhere\".to_c_str()) {\n+            Ok(*) => fail!(),\n+            Err(e) => assert_eq!(e.name(), ~\"EACCES\"),\n+        }\n+    }\n+\n+    #[test]\n+    #[ignore(cfg(windows))] // FIXME(#10386): how windows pipes work\n+    fn bind() {\n+        let p = next_test_unix().to_c_str();\n+        match PipeListener::bind(local_loop(), &p) {\n+            Ok(*) => {}\n+            Err(*) => fail!(),\n+        }\n+    }\n+\n+    #[test] #[should_fail]\n+    #[ignore(cfg(windows))] // FIXME(#10386): how windows pipes work\n+    fn bind_fail() {\n+        let p = next_test_unix().to_c_str();\n+        let _w = PipeListener::bind(local_loop(), &p).unwrap();\n+        fail!();\n     }\n-    fn native_handle(&self) -> *uvll::uv_pipe_t {\n-        match self { &Pipe(ptr) => ptr }\n+\n+    #[test]\n+    #[ignore(cfg(windows))] // FIXME(#10386): how windows pipes work\n+    fn connect() {\n+        let path = next_test_unix();\n+        let path2 = path.clone();\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+\n+        do spawn {\n+            let p = PipeListener::bind(local_loop(), &path2.to_c_str()).unwrap();\n+            let mut p = p.listen().unwrap();\n+            chan.take().send(());\n+            let mut client = p.accept().unwrap();\n+            let mut buf = [0];\n+            assert!(client.read(buf).unwrap() == 1);\n+            assert_eq!(buf[0], 1);\n+            assert!(client.write([2]).is_ok());\n+        }\n+        port.recv();\n+        let mut c = PipeWatcher::connect(local_loop(), &path.to_c_str()).unwrap();\n+        assert!(c.write([1]).is_ok());\n+        let mut buf = [0];\n+        assert!(c.read(buf).unwrap() == 1);\n+        assert_eq!(buf[0], 2);\n+    }\n+\n+    #[test] #[should_fail]\n+    #[ignore(cfg(windows))] // FIXME(#10386): how windows pipes work\n+    fn connect_fail() {\n+        let path = next_test_unix();\n+        let path2 = path.clone();\n+        let (port, chan) = oneshot();\n+        let chan = Cell::new(chan);\n+\n+        do task::spawn_unlinked { // plz no linked failure\n+            let p = PipeListener::bind(local_loop(), &path2.to_c_str()).unwrap();\n+            let mut p = p.listen().unwrap();\n+            chan.take().send(());\n+            p.accept();\n+        }\n+        port.recv();\n+        let _c = PipeWatcher::connect(local_loop(), &path.to_c_str()).unwrap();\n+        fail!()\n+\n     }\n }"}, {"sha": "7e75515972cb8893a195286b68aaaecd9d8b1e3f", "filename": "src/librustuv/process.rs", "status": "modified", "additions": 106, "deletions": 71, "changes": 177, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fprocess.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fprocess.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fprocess.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,59 +8,44 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::cell::Cell;\n+use std::libc::c_int;\n use std::libc;\n use std::ptr;\n-use std::vec;\n+use std::rt::BlockedTask;\n+use std::rt::io::IoError;\n use std::rt::io::process::*;\n+use std::rt::local::Local;\n+use std::rt::rtio::RtioProcess;\n+use std::rt::sched::{Scheduler, SchedHandle};\n+use std::vec;\n \n-use super::{Watcher, Loop, NativeHandle, UvError};\n-use super::{status_to_maybe_uv_error, ExitCallback};\n-use uvio::{UvPipeStream, UvUnboundPipe};\n+use super::{Loop, UvHandle, UvError, uv_error_to_io_error,\n+            wait_until_woken_after};\n+use uvio::HomingIO;\n use uvll;\n+use pipe::PipeWatcher;\n \n-/// A process wraps the handle of the underlying uv_process_t.\n-pub struct Process(*uvll::uv_process_t);\n+pub struct Process {\n+    handle: *uvll::uv_process_t,\n+    home: SchedHandle,\n \n-impl Watcher for Process {}\n+    /// Task to wake up (may be null) for when the process exits\n+    to_wake: Option<BlockedTask>,\n \n-impl Process {\n-    /// Creates a new process, ready to spawn inside an event loop\n-    pub fn new() -> Process {\n-        let handle = unsafe { uvll::malloc_handle(uvll::UV_PROCESS) };\n-        assert!(handle.is_not_null());\n-        let mut ret: Process = NativeHandle::from_native_handle(handle);\n-        ret.install_watcher_data();\n-        return ret;\n-    }\n+    /// Collected from the exit_cb\n+    exit_status: Option<int>,\n+    term_signal: Option<int>,\n+}\n \n+impl Process {\n     /// Spawn a new process inside the specified event loop.\n     ///\n-    /// The `config` variable will be passed down to libuv, and the `exit_cb`\n-    /// will be run only once, when the process exits.\n-    ///\n     /// Returns either the corresponding process object or an error which\n     /// occurred.\n-    pub fn spawn(&mut self, loop_: &Loop, config: ProcessConfig,\n-                 exit_cb: ExitCallback)\n-                    -> Result<~[Option<~UvPipeStream>], UvError>\n+    pub fn spawn(loop_: &Loop, config: ProcessConfig)\n+                -> Result<(~Process, ~[Option<PipeWatcher>]), UvError>\n     {\n         let cwd = config.cwd.map(|s| s.to_c_str());\n-\n-        extern fn on_exit(p: *uvll::uv_process_t,\n-                          exit_status: libc::c_int,\n-                          term_signal: libc::c_int) {\n-            let mut p: Process = NativeHandle::from_native_handle(p);\n-            let err = match exit_status {\n-                0 => None,\n-                _ => status_to_maybe_uv_error(-1)\n-            };\n-            p.get_watcher_data().exit_cb.take_unwrap()(p,\n-                                                       exit_status as int,\n-                                                       term_signal as int,\n-                                                       err);\n-        }\n-\n         let io = config.io;\n         let mut stdio = vec::with_capacity::<uvll::uv_stdio_container_t>(io.len());\n         let mut ret_io = vec::with_capacity(io.len());\n@@ -73,9 +58,7 @@ impl Process {\n             }\n         }\n \n-        let exit_cb = Cell::new(exit_cb);\n-        let ret_io = Cell::new(ret_io);\n-        do with_argv(config.program, config.args) |argv| {\n+        let ret = do with_argv(config.program, config.args) |argv| {\n             do with_env(config.env) |envp| {\n                 let options = uvll::uv_process_options_t {\n                     exit_cb: on_exit,\n@@ -93,40 +76,52 @@ impl Process {\n                     gid: 0,\n                 };\n \n+                let handle = UvHandle::alloc(None::<Process>, uvll::UV_PROCESS);\n+                let process = ~Process {\n+                    handle: handle,\n+                    home: get_handle_to_current_scheduler!(),\n+                    to_wake: None,\n+                    exit_status: None,\n+                    term_signal: None,\n+                };\n                 match unsafe {\n-                    uvll::spawn(loop_.native_handle(), **self, options)\n+                    uvll::uv_spawn(loop_.handle, handle, &options)\n                 } {\n-                    0 => {\n-                        (*self).get_watcher_data().exit_cb = Some(exit_cb.take());\n-                        Ok(ret_io.take())\n-                    }\n-                    err => Err(UvError(err))\n+                    0 => Ok(process.install()),\n+                    err => Err(UvError(err)),\n                 }\n             }\n-        }\n-    }\n+        };\n \n-    /// Sends a signal to this process.\n-    ///\n-    /// This is a wrapper around `uv_process_kill`\n-    pub fn kill(&self, signum: int) -> Result<(), UvError> {\n-        match unsafe {\n-            uvll::process_kill(self.native_handle(), signum as libc::c_int)\n-        } {\n-            0 => Ok(()),\n-            err => Err(UvError(err))\n+        match ret {\n+            Ok(p) => Ok((p, ret_io)),\n+            Err(e) => Err(e),\n         }\n     }\n+}\n+\n+extern fn on_exit(handle: *uvll::uv_process_t,\n+                  exit_status: i64,\n+                  term_signal: libc::c_int) {\n+    let p: &mut Process = unsafe { UvHandle::from_uv_handle(&handle) };\n \n-    /// Returns the process id of a spawned process\n-    pub fn pid(&self) -> libc::pid_t {\n-        unsafe { uvll::process_pid(**self) as libc::pid_t }\n+    assert!(p.exit_status.is_none());\n+    assert!(p.term_signal.is_none());\n+    p.exit_status = Some(exit_status as int);\n+    p.term_signal = Some(term_signal as int);\n+\n+    match p.to_wake.take() {\n+        Some(task) => {\n+            let scheduler: ~Scheduler = Local::take();\n+            scheduler.resume_blocked_task_immediately(task);\n+        }\n+        None => {}\n     }\n }\n \n unsafe fn set_stdio(dst: *uvll::uv_stdio_container_t,\n                     io: &StdioContainer,\n-                    loop_: &Loop) -> Option<~UvPipeStream> {\n+                    loop_: &Loop) -> Option<PipeWatcher> {\n     match *io {\n         Ignored => {\n             uvll::set_stdio_container_flags(dst, uvll::STDIO_IGNORE);\n@@ -145,11 +140,10 @@ unsafe fn set_stdio(dst: *uvll::uv_stdio_container_t,\n             if writable {\n                 flags |= uvll::STDIO_WRITABLE_PIPE as libc::c_int;\n             }\n-            let pipe = UvUnboundPipe::new(loop_);\n-            let handle = pipe.pipe.as_stream().native_handle();\n+            let pipe = PipeWatcher::new(loop_, false);\n             uvll::set_stdio_container_flags(dst, flags);\n-            uvll::set_stdio_container_stream(dst, handle);\n-            Some(~UvPipeStream::new(pipe))\n+            uvll::set_stdio_container_stream(dst, pipe.handle());\n+            Some(pipe)\n         }\n     }\n }\n@@ -192,11 +186,52 @@ fn with_env<T>(env: Option<&[(~str, ~str)]>, f: &fn(**libc::c_char) -> T) -> T {\n     c_envp.as_imm_buf(|buf, _| f(buf))\n }\n \n-impl NativeHandle<*uvll::uv_process_t> for Process {\n-    fn from_native_handle(handle: *uvll::uv_process_t) -> Process {\n-        Process(handle)\n+impl HomingIO for Process {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n+\n+impl UvHandle<uvll::uv_process_t> for Process {\n+    fn uv_handle(&self) -> *uvll::uv_process_t { self.handle }\n+}\n+\n+impl RtioProcess for Process {\n+    fn id(&self) -> libc::pid_t {\n+        unsafe { uvll::process_pid(self.handle) as libc::pid_t }\n     }\n-    fn native_handle(&self) -> *uvll::uv_process_t {\n-        match self { &Process(ptr) => ptr }\n+\n+    fn kill(&mut self, signal: int) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        match unsafe {\n+            uvll::uv_process_kill(self.handle, signal as libc::c_int)\n+        } {\n+            0 => Ok(()),\n+            err => Err(uv_error_to_io_error(UvError(err)))\n+        }\n+    }\n+\n+    fn wait(&mut self) -> int {\n+        // Make sure (on the home scheduler) that we have an exit status listed\n+        let _m = self.fire_homing_missile();\n+        match self.exit_status {\n+            Some(*) => {}\n+            None => {\n+                // If there's no exit code previously listed, then the\n+                // process's exit callback has yet to be invoked. We just\n+                // need to deschedule ourselves and wait to be reawoken.\n+                wait_until_woken_after(&mut self.to_wake, || {});\n+                assert!(self.exit_status.is_some());\n+            }\n+        }\n+\n+        // FIXME(#10109): this is wrong\n+        self.exit_status.unwrap()\n+    }\n+}\n+\n+impl Drop for Process {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        assert!(self.to_wake.is_none());\n+        self.close();\n     }\n }"}, {"sha": "da2e1d8837c458e21acda539cd62c79a272d5764", "filename": "src/librustuv/signal.rs", "status": "modified", "additions": 71, "deletions": 43, "changes": 114, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fsignal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fsignal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fsignal.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,65 +8,93 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::cast;\n use std::libc::c_int;\n use std::rt::io::signal::Signum;\n+use std::rt::sched::{SchedHandle, Scheduler};\n+use std::comm::{SharedChan, SendDeferred};\n+use std::rt::local::Local;\n+use std::rt::rtio::RtioSignal;\n \n-use super::{Loop, NativeHandle, SignalCallback, UvError, Watcher};\n+use super::{Loop, UvError, UvHandle};\n use uvll;\n+use uvio::HomingIO;\n \n-pub struct SignalWatcher(*uvll::uv_signal_t);\n+pub struct SignalWatcher {\n+    handle: *uvll::uv_signal_t,\n+    home: SchedHandle,\n \n-impl Watcher for SignalWatcher { }\n+    channel: SharedChan<Signum>,\n+    signal: Signum,\n+}\n \n impl SignalWatcher {\n-    pub fn new(loop_: &mut Loop) -> SignalWatcher {\n-        unsafe {\n-            let handle = uvll::malloc_handle(uvll::UV_SIGNAL);\n-            assert!(handle.is_not_null());\n-            assert!(0 == uvll::signal_init(loop_.native_handle(), handle));\n-            let mut watcher: SignalWatcher = NativeHandle::from_native_handle(handle);\n-            watcher.install_watcher_data();\n-            return watcher;\n-        }\n-    }\n-\n-    pub fn start(&mut self, signum: Signum, callback: SignalCallback)\n-            -> Result<(), UvError>\n-    {\n-        return unsafe {\n-            match uvll::signal_start(self.native_handle(), signal_cb,\n-                                     signum as c_int) {\n-                0 => {\n-                    let data = self.get_watcher_data();\n-                    data.signal_cb = Some(callback);\n-                    Ok(())\n-                }\n-                n => Err(UvError(n)),\n-            }\n+    pub fn new(loop_: &mut Loop, signum: Signum,\n+               channel: SharedChan<Signum>) -> Result<~SignalWatcher, UvError> {\n+        let s = ~SignalWatcher {\n+            handle: UvHandle::alloc(None::<SignalWatcher>, uvll::UV_SIGNAL),\n+            home: get_handle_to_current_scheduler!(),\n+            channel: channel,\n+            signal: signum,\n         };\n+        assert_eq!(unsafe {\n+            uvll::uv_signal_init(loop_.handle, s.handle)\n+        }, 0);\n \n-        extern fn signal_cb(handle: *uvll::uv_signal_t, signum: c_int) {\n-            let mut watcher: SignalWatcher = NativeHandle::from_native_handle(handle);\n-            let data = watcher.get_watcher_data();\n-            let cb = data.signal_cb.get_ref();\n-            (*cb)(watcher, unsafe { cast::transmute(signum as int) });\n+        match unsafe {\n+            uvll::uv_signal_start(s.handle, signal_cb, signum as c_int)\n+        } {\n+            0 => Ok(s.install()),\n+            n => Err(UvError(n)),\n         }\n-    }\n \n-    pub fn stop(&mut self) {\n-        unsafe {\n-            uvll::signal_stop(self.native_handle());\n-        }\n     }\n }\n \n-impl NativeHandle<*uvll::uv_signal_t> for SignalWatcher {\n-    fn from_native_handle(handle: *uvll::uv_signal_t) -> SignalWatcher {\n-        SignalWatcher(handle)\n+extern fn signal_cb(handle: *uvll::uv_signal_t, signum: c_int) {\n+    let s: &mut SignalWatcher = unsafe { UvHandle::from_uv_handle(&handle) };\n+    assert_eq!(signum as int, s.signal as int);\n+    s.channel.send_deferred(s.signal);\n+}\n+\n+impl HomingIO for SignalWatcher {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n+\n+impl UvHandle<uvll::uv_signal_t> for SignalWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_signal_t { self.handle }\n+}\n+\n+impl RtioSignal for SignalWatcher {}\n+\n+impl Drop for SignalWatcher {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        self.close_async_();\n     }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+    use std::cell::Cell;\n+    use super::super::local_loop;\n+    use std::rt::io::signal;\n+    use std::comm::{SharedChan, stream};\n+\n+    #[test]\n+    fn closing_channel_during_drop_doesnt_kill_everything() {\n+        // see issue #10375, relates to timers as well.\n+        let (port, chan) = stream();\n+        let chan = SharedChan::new(chan);\n+        let _signal = SignalWatcher::new(local_loop(), signal::Interrupt,\n+                                         chan);\n+\n+        let port = Cell::new(port);\n+        do spawn {\n+            port.take().try_recv();\n+        }\n \n-    fn native_handle(&self) -> *uvll::uv_signal_t {\n-        match self { &SignalWatcher(ptr) => ptr }\n+        // when we drop the SignalWatcher we're going to destroy the channel,\n+        // which must wake up the task on the other end\n     }\n }"}, {"sha": "08b307700c7cdb866dff8cf5cc33610970a2b073", "filename": "src/librustuv/stream.rs", "status": "added", "additions": 180, "deletions": 0, "changes": 180, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fstream.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -0,0 +1,180 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use std::cast;\n+use std::libc::{c_int, size_t, ssize_t};\n+use std::ptr;\n+use std::rt::BlockedTask;\n+use std::rt::local::Local;\n+use std::rt::sched::Scheduler;\n+\n+use super::{UvError, Buf, slice_to_uv_buf, Request, wait_until_woken_after,\n+            ForbidUnwind};\n+use uvll;\n+\n+// This is a helper structure which is intended to get embedded into other\n+// Watcher structures. This structure will retain a handle to the underlying\n+// uv_stream_t instance, and all I/O operations assume that it's already located\n+// on the appropriate scheduler.\n+pub struct StreamWatcher {\n+    handle: *uvll::uv_stream_t,\n+\n+    // Cache the last used uv_write_t so we don't have to allocate a new one on\n+    // every call to uv_write(). Ideally this would be a stack-allocated\n+    // structure, but currently we don't have mappings for all the structures\n+    // defined in libuv, so we're foced to malloc this.\n+    priv last_write_req: Option<Request>,\n+}\n+\n+struct ReadContext {\n+    buf: Option<Buf>,\n+    result: ssize_t,\n+    task: Option<BlockedTask>,\n+}\n+\n+struct WriteContext {\n+    result: c_int,\n+    task: Option<BlockedTask>,\n+}\n+\n+impl StreamWatcher {\n+    // Creates a new helper structure which should be then embedded into another\n+    // watcher. This provides the generic read/write methods on streams.\n+    //\n+    // This structure will *not* close the stream when it is dropped. It is up\n+    // to the enclosure structure to be sure to call the close method (which\n+    // will block the task). Note that this is also required to prevent memory\n+    // leaks.\n+    //\n+    // It should also be noted that the `data` field of the underlying uv handle\n+    // will be manipulated on each of the methods called on this watcher.\n+    // Wrappers should ensure to always reset the field to an appropriate value\n+    // if they rely on the field to perform an action.\n+    pub fn new(stream: *uvll::uv_stream_t) -> StreamWatcher {\n+        StreamWatcher {\n+            handle: stream,\n+            last_write_req: None,\n+        }\n+    }\n+\n+    pub fn read(&mut self, buf: &mut [u8]) -> Result<uint, UvError> {\n+        // This read operation needs to get canceled on an unwind via libuv's\n+        // uv_read_stop function\n+        let _f = ForbidUnwind::new(\"stream read\");\n+\n+        // Send off the read request, but don't block until we're sure that the\n+        // read request is queued.\n+        match unsafe {\n+            uvll::uv_read_start(self.handle, alloc_cb, read_cb)\n+        } {\n+            0 => {\n+                let mut rcx = ReadContext {\n+                    buf: Some(slice_to_uv_buf(buf)),\n+                    result: 0,\n+                    task: None,\n+                };\n+                do wait_until_woken_after(&mut rcx.task) {\n+                    unsafe {\n+                        uvll::set_data_for_uv_handle(self.handle, &rcx)\n+                    }\n+                }\n+                match rcx.result {\n+                    n if n < 0 => Err(UvError(n as c_int)),\n+                    n => Ok(n as uint),\n+                }\n+            }\n+            n => Err(UvError(n))\n+        }\n+    }\n+\n+    pub fn write(&mut self, buf: &[u8]) -> Result<(), UvError> {\n+        // The ownership of the write request is dubious if this function\n+        // unwinds. I believe that if the write_cb fails to re-schedule the task\n+        // then the write request will be leaked.\n+        let _f = ForbidUnwind::new(\"stream write\");\n+\n+        // Prepare the write request, either using a cached one or allocating a\n+        // new one\n+        let mut req = match self.last_write_req.take() {\n+            Some(req) => req, None => Request::new(uvll::UV_WRITE),\n+        };\n+        req.set_data(ptr::null::<()>());\n+\n+        // Send off the request, but be careful to not block until we're sure\n+        // that the write reqeust is queued. If the reqeust couldn't be queued,\n+        // then we should return immediately with an error.\n+        match unsafe {\n+            uvll::uv_write(req.handle, self.handle, [slice_to_uv_buf(buf)],\n+                           write_cb)\n+        } {\n+            0 => {\n+                let mut wcx = WriteContext { result: 0, task: None, };\n+                req.defuse(); // uv callback now owns this request\n+\n+                do wait_until_woken_after(&mut wcx.task) {\n+                    req.set_data(&wcx);\n+                }\n+                self.last_write_req = Some(Request::wrap(req.handle));\n+                match wcx.result {\n+                    0 => Ok(()),\n+                    n => Err(UvError(n)),\n+                }\n+            }\n+            n => Err(UvError(n)),\n+        }\n+    }\n+}\n+\n+// This allocation callback expects to be invoked once and only once. It will\n+// unwrap the buffer in the ReadContext stored in the stream and return it. This\n+// will fail if it is called more than once.\n+extern fn alloc_cb(stream: *uvll::uv_stream_t, _hint: size_t, buf: *mut Buf) {\n+    uvdebug!(\"alloc_cb\");\n+    unsafe {\n+        let rcx: &mut ReadContext =\n+            cast::transmute(uvll::get_data_for_uv_handle(stream));\n+        *buf = rcx.buf.take().expect(\"stream alloc_cb called more than once\");\n+    }\n+}\n+\n+// When a stream has read some data, we will always forcibly stop reading and\n+// return all the data read (even if it didn't fill the whole buffer).\n+extern fn read_cb(handle: *uvll::uv_stream_t, nread: ssize_t, _buf: *Buf) {\n+    uvdebug!(\"read_cb {}\", nread);\n+    assert!(nread != uvll::ECANCELED as ssize_t);\n+    let rcx: &mut ReadContext = unsafe {\n+        cast::transmute(uvll::get_data_for_uv_handle(handle))\n+    };\n+    // Stop reading so that no read callbacks are\n+    // triggered before the user calls `read` again.\n+    // XXX: Is there a performance impact to calling\n+    // stop here?\n+    unsafe { assert_eq!(uvll::uv_read_stop(handle), 0); }\n+    rcx.result = nread;\n+\n+    let scheduler: ~Scheduler = Local::take();\n+    scheduler.resume_blocked_task_immediately(rcx.task.take_unwrap());\n+}\n+\n+// Unlike reading, the WriteContext is stored in the uv_write_t request. Like\n+// reading, however, all this does is wake up the blocked task after squirreling\n+// away the error code as a result.\n+extern fn write_cb(req: *uvll::uv_write_t, status: c_int) {\n+    let mut req = Request::wrap(req);\n+    assert!(status != uvll::ECANCELED);\n+    // Remember to not free the request because it is re-used between writes on\n+    // the same stream.\n+    let wcx: &mut WriteContext = unsafe { req.get_data() };\n+    wcx.result = status;\n+    req.defuse();\n+\n+    let sched: ~Scheduler = Local::take();\n+    sched.resume_blocked_task_immediately(wcx.task.take_unwrap());\n+}"}, {"sha": "017639903051752f78ebcdce7730e6ad3636b362", "filename": "src/librustuv/timer.rs", "status": "modified", "additions": 258, "deletions": 111, "changes": 369, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Ftimer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Ftimer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Ftimer.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -8,150 +8,297 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use std::comm::{oneshot, stream, PortOne, ChanOne, SendDeferred};\n use std::libc::c_int;\n+use std::rt::BlockedTask;\n+use std::rt::local::Local;\n+use std::rt::rtio::RtioTimer;\n+use std::rt::sched::{Scheduler, SchedHandle};\n+use std::util;\n \n use uvll;\n-use super::{Watcher, Loop, NativeHandle, TimerCallback, status_to_maybe_uv_error};\n+use super::{Loop, UvHandle, ForbidUnwind, ForbidSwitch};\n+use uvio::HomingIO;\n \n-pub struct TimerWatcher(*uvll::uv_timer_t);\n-impl Watcher for TimerWatcher { }\n+pub struct TimerWatcher {\n+    handle: *uvll::uv_timer_t,\n+    home: SchedHandle,\n+    action: Option<NextAction>,\n+}\n+\n+pub enum NextAction {\n+    WakeTask(BlockedTask),\n+    SendOnce(ChanOne<()>),\n+    SendMany(Chan<()>),\n+}\n \n impl TimerWatcher {\n-    pub fn new(loop_: &mut Loop) -> TimerWatcher {\n-        unsafe {\n-            let handle = uvll::malloc_handle(uvll::UV_TIMER);\n-            assert!(handle.is_not_null());\n-            assert!(0 == uvll::timer_init(loop_.native_handle(), handle));\n-            let mut watcher: TimerWatcher = NativeHandle::from_native_handle(handle);\n-            watcher.install_watcher_data();\n-            return watcher;\n-        }\n+    pub fn new(loop_: &mut Loop) -> ~TimerWatcher {\n+        let handle = UvHandle::alloc(None::<TimerWatcher>, uvll::UV_TIMER);\n+        assert_eq!(unsafe {\n+            uvll::uv_timer_init(loop_.handle, handle)\n+        }, 0);\n+        let me = ~TimerWatcher {\n+            handle: handle,\n+            action: None,\n+            home: get_handle_to_current_scheduler!(),\n+        };\n+        return me.install();\n     }\n \n-    pub fn start(&mut self, timeout: u64, repeat: u64, cb: TimerCallback) {\n-        {\n-            let data = self.get_watcher_data();\n-            data.timer_cb = Some(cb);\n-        }\n+    fn start(&mut self, msecs: u64, period: u64) {\n+        assert_eq!(unsafe {\n+            uvll::uv_timer_start(self.handle, timer_cb, msecs, period)\n+        }, 0)\n+    }\n \n-        unsafe {\n-            uvll::timer_start(self.native_handle(), timer_cb, timeout, repeat);\n-        }\n+    fn stop(&mut self) {\n+        assert_eq!(unsafe { uvll::uv_timer_stop(self.handle) }, 0)\n+    }\n+}\n \n-        extern fn timer_cb(handle: *uvll::uv_timer_t, status: c_int) {\n-            let mut watcher: TimerWatcher = NativeHandle::from_native_handle(handle);\n-            let data = watcher.get_watcher_data();\n-            let cb = data.timer_cb.get_ref();\n-            let status = status_to_maybe_uv_error(status);\n-            (*cb)(watcher, status);\n+impl HomingIO for TimerWatcher {\n+    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n+}\n+\n+impl UvHandle<uvll::uv_timer_t> for TimerWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_timer_t { self.handle }\n+}\n+\n+impl RtioTimer for TimerWatcher {\n+    fn sleep(&mut self, msecs: u64) {\n+        // As with all of the below functions, we must be extra careful when\n+        // destroying the previous action. If the previous action was a channel,\n+        // destroying it could invoke a context switch. For these situtations,\n+        // we must temporarily un-home ourselves, then destroy the action, and\n+        // then re-home again.\n+        let missile = self.fire_homing_missile();\n+        self.stop();\n+        let _missile = match util::replace(&mut self.action, None) {\n+            None => missile, // no need to do a homing dance\n+            Some(action) => {\n+                util::ignore(missile);      // un-home ourself\n+                util::ignore(action);       // destroy the previous action\n+                self.fire_homing_missile()  // re-home ourself\n+            }\n+        };\n+\n+        // If the descheduling operation unwinds after the timer has been\n+        // started, then we need to call stop on the timer.\n+        let _f = ForbidUnwind::new(\"timer\");\n+\n+        let sched: ~Scheduler = Local::take();\n+        do sched.deschedule_running_task_and_then |_sched, task| {\n+            self.action = Some(WakeTask(task));\n+            self.start(msecs, 0);\n         }\n+        self.stop();\n     }\n \n-    pub fn stop(&mut self) {\n-        unsafe {\n-            uvll::timer_stop(self.native_handle());\n-        }\n+    fn oneshot(&mut self, msecs: u64) -> PortOne<()> {\n+        let (port, chan) = oneshot();\n+\n+        // similarly to the destructor, we must drop the previous action outside\n+        // of the homing missile\n+        let _prev_action = {\n+            let _m = self.fire_homing_missile();\n+            self.stop();\n+            self.start(msecs, 0);\n+            util::replace(&mut self.action, Some(SendOnce(chan)))\n+        };\n+\n+        return port;\n+    }\n+\n+    fn period(&mut self, msecs: u64) -> Port<()> {\n+        let (port, chan) = stream();\n+\n+        // similarly to the destructor, we must drop the previous action outside\n+        // of the homing missile\n+        let _prev_action = {\n+            let _m = self.fire_homing_missile();\n+            self.stop();\n+            self.start(msecs, msecs);\n+            util::replace(&mut self.action, Some(SendMany(chan)))\n+        };\n+\n+        return port;\n     }\n }\n \n-impl NativeHandle<*uvll::uv_timer_t> for TimerWatcher {\n-    fn from_native_handle(handle: *uvll::uv_timer_t) -> TimerWatcher {\n-        TimerWatcher(handle)\n+extern fn timer_cb(handle: *uvll::uv_timer_t, status: c_int) {\n+    let _f = ForbidSwitch::new(\"timer callback can't switch\");\n+    assert_eq!(status, 0);\n+    let timer: &mut TimerWatcher = unsafe { UvHandle::from_uv_handle(&handle) };\n+\n+    match timer.action.take_unwrap() {\n+        WakeTask(task) => {\n+            let sched: ~Scheduler = Local::take();\n+            sched.resume_blocked_task_immediately(task);\n+        }\n+        SendOnce(chan) => chan.send_deferred(()),\n+        SendMany(chan) => {\n+            chan.send_deferred(());\n+            timer.action = Some(SendMany(chan));\n+        }\n     }\n-    fn native_handle(&self) -> *uvll::uv_idle_t {\n-        match self { &TimerWatcher(ptr) => ptr }\n+}\n+\n+impl Drop for TimerWatcher {\n+    fn drop(&mut self) {\n+        // note that this drop is a little subtle. Dropping a channel which is\n+        // held internally may invoke some scheduling operations. We can't take\n+        // the channel unless we're on the home scheduler, but once we're on the\n+        // home scheduler we should never move. Hence, we take the timer's\n+        // action item and then move it outside of the homing block.\n+        let _action = {\n+            let _m = self.fire_homing_missile();\n+            self.stop();\n+            self.close_async_();\n+            self.action.take()\n+        };\n     }\n }\n \n #[cfg(test)]\n mod test {\n     use super::*;\n-    use Loop;\n-    use std::unstable::run_in_bare_thread;\n+    use std::cell::Cell;\n+    use std::rt::rtio::RtioTimer;\n+    use super::super::local_loop;\n \n     #[test]\n-    fn smoke_test() {\n-        do run_in_bare_thread {\n-            let mut count = 0;\n-            let count_ptr: *mut int = &mut count;\n-            let mut loop_ = Loop::new();\n-            let mut timer = TimerWatcher::new(&mut loop_);\n-            do timer.start(10, 0) |timer, status| {\n-                assert!(status.is_none());\n-                unsafe { *count_ptr += 1 };\n-                timer.close(||());\n-            }\n-            loop_.run();\n-            loop_.close();\n-            assert!(count == 1);\n-        }\n+    fn oneshot() {\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let port = timer.oneshot(1);\n+        port.recv();\n+        let port = timer.oneshot(1);\n+        port.recv();\n     }\n \n     #[test]\n-    fn start_twice() {\n-        do run_in_bare_thread {\n-            let mut count = 0;\n-            let count_ptr: *mut int = &mut count;\n-            let mut loop_ = Loop::new();\n-            let mut timer = TimerWatcher::new(&mut loop_);\n-            do timer.start(10, 0) |timer, status| {\n-                let mut timer = timer;\n-                assert!(status.is_none());\n-                unsafe { *count_ptr += 1 };\n-                do timer.start(10, 0) |timer, status| {\n-                    assert!(status.is_none());\n-                    unsafe { *count_ptr += 1 };\n-                    timer.close(||());\n-                }\n-            }\n-            loop_.run();\n-            loop_.close();\n-            assert!(count == 2);\n+    fn override() {\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let oport = timer.oneshot(1);\n+        let pport = timer.period(1);\n+        timer.sleep(1);\n+        assert_eq!(oport.try_recv(), None);\n+        assert_eq!(pport.try_recv(), None);\n+        timer.oneshot(1).recv();\n+    }\n+\n+    #[test]\n+    fn period() {\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let port = timer.period(1);\n+        port.recv();\n+        port.recv();\n+        let port = timer.period(1);\n+        port.recv();\n+        port.recv();\n+    }\n+\n+    #[test]\n+    fn sleep() {\n+        let mut timer = TimerWatcher::new(local_loop());\n+        timer.sleep(1);\n+        timer.sleep(1);\n+    }\n+\n+    #[test] #[should_fail]\n+    fn oneshot_fail() {\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let _port = timer.oneshot(1);\n+        fail!();\n+    }\n+\n+    #[test] #[should_fail]\n+    fn period_fail() {\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let _port = timer.period(1);\n+        fail!();\n+    }\n+\n+    #[test] #[should_fail]\n+    fn normal_fail() {\n+        let _timer = TimerWatcher::new(local_loop());\n+        fail!();\n+    }\n+\n+    #[test]\n+    fn closing_channel_during_drop_doesnt_kill_everything() {\n+        // see issue #10375\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let timer_port = Cell::new(timer.period(1000));\n+\n+        do spawn {\n+            timer_port.take().try_recv();\n         }\n+\n+        // when we drop the TimerWatcher we're going to destroy the channel,\n+        // which must wake up the task on the other end\n     }\n \n     #[test]\n-    fn repeat_stop() {\n-        do run_in_bare_thread {\n-            let mut count = 0;\n-            let count_ptr: *mut int = &mut count;\n-            let mut loop_ = Loop::new();\n-            let mut timer = TimerWatcher::new(&mut loop_);\n-            do timer.start(1, 2) |timer, status| {\n-                assert!(status.is_none());\n-                unsafe {\n-                    *count_ptr += 1;\n-\n-                    if *count_ptr == 10 {\n-\n-                        // Stop the timer and do something else\n-                        let mut timer = timer;\n-                        timer.stop();\n-                        // Freeze timer so it can be captured\n-                        let timer = timer;\n-\n-                        let mut loop_ = timer.event_loop();\n-                        let mut timer2 = TimerWatcher::new(&mut loop_);\n-                        do timer2.start(10, 0) |timer2, _| {\n-\n-                            *count_ptr += 1;\n-\n-                            timer2.close(||());\n-\n-                            // Restart the original timer\n-                            let mut timer = timer;\n-                            do timer.start(1, 0) |timer, _| {\n-                                *count_ptr += 1;\n-                                timer.close(||());\n-                            }\n-                        }\n-                    }\n-                };\n-            }\n-            loop_.run();\n-            loop_.close();\n-            assert!(count == 12);\n+    fn reset_doesnt_switch_tasks() {\n+        // similar test to the one above.\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let timer_port = Cell::new(timer.period(1000));\n+\n+        do spawn {\n+            timer_port.take().try_recv();\n         }\n+\n+        timer.oneshot(1);\n+    }\n+    #[test]\n+    fn reset_doesnt_switch_tasks2() {\n+        // similar test to the one above.\n+        let mut timer = TimerWatcher::new(local_loop());\n+        let timer_port = Cell::new(timer.period(1000));\n+\n+        do spawn {\n+            timer_port.take().try_recv();\n+        }\n+\n+        timer.sleep(1);\n+    }\n+\n+    #[test]\n+    fn sender_goes_away_oneshot() {\n+        let port = {\n+            let mut timer = TimerWatcher::new(local_loop());\n+            timer.oneshot(1000)\n+        };\n+        assert_eq!(port.try_recv(), None);\n     }\n \n+    #[test]\n+    fn sender_goes_away_period() {\n+        let port = {\n+            let mut timer = TimerWatcher::new(local_loop());\n+            timer.period(1000)\n+        };\n+        assert_eq!(port.try_recv(), None);\n+    }\n+\n+    #[test]\n+    fn receiver_goes_away_oneshot() {\n+        let mut timer1 = TimerWatcher::new(local_loop());\n+        timer1.oneshot(1);\n+        let mut timer2 = TimerWatcher::new(local_loop());\n+        // while sleeping, the prevous timer should fire and not have its\n+        // callback do something terrible.\n+        timer2.sleep(2);\n+    }\n+\n+    #[test]\n+    fn receiver_goes_away_period() {\n+        let mut timer1 = TimerWatcher::new(local_loop());\n+        timer1.period(1);\n+        let mut timer2 = TimerWatcher::new(local_loop());\n+        // while sleeping, the prevous timer should fire and not have its\n+        // callback do something terrible.\n+        timer2.sleep(2);\n+    }\n }"}, {"sha": "d3f001f39312f055bb4444f6f8d5b76b91065b91", "filename": "src/librustuv/tty.rs", "status": "modified", "additions": 74, "deletions": 39, "changes": 113, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Ftty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Ftty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Ftty.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -9,75 +9,110 @@\n // except according to those terms.\n \n use std::libc;\n+use std::rt::io::IoError;\n+use std::rt::local::Local;\n+use std::rt::rtio::RtioTTY;\n+use std::rt::sched::{Scheduler, SchedHandle};\n \n-use super::{Watcher, Loop, NativeHandle, UvError};\n-use net;\n+use stream::StreamWatcher;\n+use super::{Loop, UvError, UvHandle, uv_error_to_io_error};\n+use uvio::HomingIO;\n use uvll;\n \n-/// A process wraps the handle of the underlying uv_process_t.\n-pub struct TTY(*uvll::uv_tty_t);\n-\n-impl Watcher for TTY {}\n+pub struct TtyWatcher{\n+    tty: *uvll::uv_tty_t,\n+    stream: StreamWatcher,\n+    home: SchedHandle,\n+    fd: libc::c_int,\n+}\n \n-impl TTY {\n-    #[fixed_stack_segment] #[inline(never)]\n-    pub fn new(loop_: &Loop, fd: libc::c_int, readable: bool) ->\n-            Result<TTY, UvError>\n+impl TtyWatcher {\n+    pub fn new(loop_: &Loop, fd: libc::c_int, readable: bool)\n+        -> Result<TtyWatcher, UvError>\n     {\n-        let handle = unsafe { uvll::malloc_handle(uvll::UV_TTY) };\n-        assert!(handle.is_not_null());\n+        // libuv may succeed in giving us a handle (via uv_tty_init), but if the\n+        // handle isn't actually connected to a terminal there are frequently\n+        // many problems in using it with libuv. To get around this, always\n+        // return a failure if the specified file descriptor isn't actually a\n+        // TTY.\n+        //\n+        // Related:\n+        // - https://github.com/joyent/libuv/issues/982\n+        // - https://github.com/joyent/libuv/issues/988\n+        if unsafe { uvll::guess_handle(fd) != uvll::UV_TTY as libc::c_int } {\n+            return Err(UvError(uvll::EBADF));\n+        }\n \n-        let ret = unsafe {\n-            uvll::tty_init(loop_.native_handle(), handle, fd as libc::c_int,\n-                           readable as libc::c_int)\n-        };\n-        match ret {\n+        // If this file descriptor is indeed guessed to be a tty, then go ahead\n+        // with attempting to open it as a tty.\n+        let handle = UvHandle::alloc(None::<TtyWatcher>, uvll::UV_TTY);\n+        match unsafe {\n+            uvll::uv_tty_init(loop_.handle, handle, fd as libc::c_int,\n+                              readable as libc::c_int)\n+        } {\n             0 => {\n-                let mut ret: TTY = NativeHandle::from_native_handle(handle);\n-                ret.install_watcher_data();\n-                Ok(ret)\n+                Ok(TtyWatcher {\n+                    tty: handle,\n+                    stream: StreamWatcher::new(handle),\n+                    home: get_handle_to_current_scheduler!(),\n+                    fd: fd,\n+                })\n             }\n             n => {\n-                unsafe { uvll::free_handle(handle); }\n+                unsafe { uvll::free_handle(handle) }\n                 Err(UvError(n))\n             }\n         }\n     }\n+}\n+\n+impl RtioTTY for TtyWatcher {\n+    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.stream.read(buf).map_err(uv_error_to_io_error)\n+    }\n \n-    pub fn as_stream(&self) -> net::StreamWatcher {\n-        net::StreamWatcher(**self as *uvll::uv_stream_t)\n+    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n+        let _m = self.fire_homing_missile();\n+        self.stream.write(buf).map_err(uv_error_to_io_error)\n     }\n \n-    #[fixed_stack_segment] #[inline(never)]\n-    pub fn set_mode(&self, raw: bool) -> Result<(), UvError> {\n+    fn set_raw(&mut self, raw: bool) -> Result<(), IoError> {\n         let raw = raw as libc::c_int;\n-        match unsafe { uvll::tty_set_mode(self.native_handle(), raw) } {\n+        let _m = self.fire_homing_missile();\n+        match unsafe { uvll::uv_tty_set_mode(self.tty, raw) } {\n             0 => Ok(()),\n-            n => Err(UvError(n))\n+            n => Err(uv_error_to_io_error(UvError(n)))\n         }\n     }\n \n-    #[fixed_stack_segment] #[inline(never)] #[allow(unused_mut)]\n-    pub fn get_winsize(&self) -> Result<(int, int), UvError> {\n+    #[allow(unused_mut)]\n+    fn get_winsize(&mut self) -> Result<(int, int), IoError> {\n         let mut width: libc::c_int = 0;\n         let mut height: libc::c_int = 0;\n         let widthptr: *libc::c_int = &width;\n         let heightptr: *libc::c_int = &width;\n \n-        match unsafe { uvll::tty_get_winsize(self.native_handle(),\n-                                             widthptr, heightptr) } {\n+        let _m = self.fire_homing_missile();\n+        match unsafe { uvll::uv_tty_get_winsize(self.tty,\n+                                                widthptr, heightptr) } {\n             0 => Ok((width as int, height as int)),\n-            n => Err(UvError(n))\n+            n => Err(uv_error_to_io_error(UvError(n)))\n         }\n     }\n }\n \n-impl NativeHandle<*uvll::uv_tty_t> for TTY {\n-    fn from_native_handle(handle: *uvll::uv_tty_t) -> TTY {\n-        TTY(handle)\n-    }\n-    fn native_handle(&self) -> *uvll::uv_tty_t {\n-        match self { &TTY(ptr) => ptr }\n-    }\n+impl UvHandle<uvll::uv_tty_t> for TtyWatcher {\n+    fn uv_handle(&self) -> *uvll::uv_tty_t { self.tty }\n+}\n+\n+impl HomingIO for TtyWatcher {\n+    fn home<'a>(&'a mut self) -> &'a mut SchedHandle { &mut self.home }\n }\n \n+impl Drop for TtyWatcher {\n+    fn drop(&mut self) {\n+        let _m = self.fire_homing_missile();\n+        self.close_async_();\n+    }\n+}"}, {"sha": "75ec5f26b336ce8ffc972d12260bfae950c932cd", "filename": "src/librustuv/uvio.rs", "status": "modified", "additions": 155, "deletions": 2331, "changes": 2486, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fuvio.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -9,47 +9,32 @@\n // except according to those terms.\n \n use std::c_str::CString;\n-use std::cast::transmute;\n-use std::cast;\n-use std::cell::Cell;\n-use std::comm::{SendDeferred, SharedChan, Port, PortOne, GenericChan};\n+use std::comm::SharedChan;\n+use std::libc::c_int;\n use std::libc;\n-use std::libc::{c_int, c_uint, c_void, pid_t};\n-use std::ptr;\n-use std::str;\n-use std::rt::io;\n+use std::path::Path;\n use std::rt::io::IoError;\n-use std::rt::io::net::ip::{SocketAddr, IpAddr};\n-use std::rt::io::{standard_error, OtherIoError, SeekStyle, SeekSet, SeekCur,\n-                  SeekEnd};\n+use std::rt::io::net::ip::SocketAddr;\n use std::rt::io::process::ProcessConfig;\n-use std::rt::BlockedTask;\n+use std::rt::io;\n use std::rt::local::Local;\n use std::rt::rtio::*;\n use std::rt::sched::{Scheduler, SchedHandle};\n-use std::rt::tube::Tube;\n use std::rt::task::Task;\n-use std::unstable::sync::Exclusive;\n-use std::libc::{lseek, off_t};\n-use std::rt::io::{FileMode, FileAccess, FileStat};\n+use std::libc::{O_CREAT, O_APPEND, O_TRUNC, O_RDWR, O_RDONLY, O_WRONLY,\n+                S_IRUSR, S_IWUSR};\n+use std::rt::io::{FileMode, FileAccess, Open, Append, Truncate, Read, Write,\n+                  ReadWrite, FileStat};\n use std::rt::io::signal::Signum;\n-use std::task;\n+use std::util;\n use ai = std::rt::io::net::addrinfo;\n \n #[cfg(test)] use std::unstable::run_in_bare_thread;\n-#[cfg(test)] use std::rt::test::{spawntask,\n-                                 next_test_ip4,\n-                                 run_in_mt_newsched_task};\n-#[cfg(test)] use std::rt::comm::oneshot;\n \n use super::*;\n-use idle::IdleWatcher;\n-use net::{UvIpv4SocketAddr, UvIpv6SocketAddr};\n-use addrinfo::{GetAddrInfoRequest, accum_addrinfo};\n+use addrinfo::GetAddrInfoRequest;\n \n-// XXX we should not be calling uvll functions in here.\n-\n-trait HomingIO {\n+pub trait HomingIO {\n \n     fn home<'r>(&'r mut self) -> &'r mut SchedHandle;\n \n@@ -59,123 +44,95 @@ trait HomingIO {\n     fn go_to_IO_home(&mut self) -> uint {\n         use std::rt::sched::RunOnce;\n \n+        unsafe {\n+            let task: *mut Task = Local::unsafe_borrow();\n+            (*task).death.inhibit_kill((*task).unwinder.unwinding);\n+        }\n+\n+        let _f = ForbidUnwind::new(\"going home\");\n+\n         let current_sched_id = do Local::borrow |sched: &mut Scheduler| {\n             sched.sched_id()\n         };\n \n         // Only need to invoke a context switch if we're not on the right\n         // scheduler.\n         if current_sched_id != self.home().sched_id {\n-            do task::unkillable { // FIXME(#8674)\n-                let scheduler: ~Scheduler = Local::take();\n-                do scheduler.deschedule_running_task_and_then |_, task| {\n-                    /* FIXME(#8674) if the task was already killed then wake\n-                     * will return None. In that case, the home pointer will\n-                     * never be set.\n-                     *\n-                     * RESOLUTION IDEA: Since the task is dead, we should\n-                     * just abort the IO action.\n-                     */\n-                    do task.wake().map |task| {\n-                        self.home().send(RunOnce(task));\n-                    };\n-                }\n+            let scheduler: ~Scheduler = Local::take();\n+            do scheduler.deschedule_running_task_and_then |_, task| {\n+                do task.wake().map |task| {\n+                    self.home().send(RunOnce(task));\n+                };\n             }\n         }\n+        let current_sched_id = do Local::borrow |sched: &mut Scheduler| {\n+            sched.sched_id()\n+        };\n+        assert!(current_sched_id == self.home().sched_id);\n \n         self.home().sched_id\n     }\n \n-    // XXX: dummy self parameter\n-    fn restore_original_home(_: Option<Self>, io_home: uint) {\n-        // It would truly be a sad day if we had moved off the home I/O\n-        // scheduler while we were doing I/O.\n-        assert_eq!(Local::borrow(|sched: &mut Scheduler| sched.sched_id()),\n-                   io_home);\n-\n-        // If we were a homed task, then we must send ourselves back to the\n-        // original scheduler. Otherwise, we can just return and keep running\n-        if !Task::on_appropriate_sched() {\n-            do task::unkillable { // FIXME(#8674)\n-                let scheduler: ~Scheduler = Local::take();\n-                do scheduler.deschedule_running_task_and_then |_, task| {\n-                    do task.wake().map |task| {\n-                        Scheduler::run_task(task);\n-                    };\n-                }\n-            }\n-        }\n-    }\n-\n-    fn home_for_io<A>(&mut self, io: &fn(&mut Self) -> A) -> A {\n-        let home = self.go_to_IO_home();\n-        let a = io(self); // do IO\n-        HomingIO::restore_original_home(None::<Self>, home);\n-        a // return the result of the IO\n+    /// Fires a single homing missile, returning another missile targeted back\n+    /// at the original home of this task. In other words, this function will\n+    /// move the local task to its I/O scheduler and then return an RAII wrapper\n+    /// which will return the task home.\n+    fn fire_homing_missile(&mut self) -> HomingMissile {\n+        HomingMissile { io_home: self.go_to_IO_home() }\n     }\n \n-    fn home_for_io_consume<A>(mut self, io: &fn(Self) -> A) -> A {\n-        let home = self.go_to_IO_home();\n-        let a = io(self); // do IO\n-        HomingIO::restore_original_home(None::<Self>, home);\n-        a // return the result of the IO\n-    }\n+    /// Same as `fire_homing_missile`, but returns the local I/O scheduler as\n+    /// well (the one that was homed to).\n+    fn fire_homing_missile_sched(&mut self) -> (HomingMissile, ~Scheduler) {\n+        // First, transplant ourselves to the home I/O scheduler\n+        let missile = self.fire_homing_missile();\n+        // Next (must happen next), grab the local I/O scheduler\n+        let io_sched: ~Scheduler = Local::take();\n \n-    fn home_for_io_with_sched<A>(&mut self, io_sched: &fn(&mut Self, ~Scheduler) -> A) -> A {\n-        let home = self.go_to_IO_home();\n-        let a = do task::unkillable { // FIXME(#8674)\n-            let scheduler: ~Scheduler = Local::take();\n-            io_sched(self, scheduler) // do IO and scheduling action\n-        };\n-        HomingIO::restore_original_home(None::<Self>, home);\n-        a // return result of IO\n+        (missile, io_sched)\n     }\n }\n \n-// get a handle for the current scheduler\n-macro_rules! get_handle_to_current_scheduler(\n-    () => (do Local::borrow |sched: &mut Scheduler| { sched.make_handle() })\n-)\n-\n-enum SocketNameKind {\n-    TcpPeer,\n-    Tcp,\n-    Udp\n+/// After a homing operation has been completed, this will return the current\n+/// task back to its appropriate home (if applicable). The field is used to\n+/// assert that we are where we think we are.\n+struct HomingMissile {\n+    priv io_home: uint,\n }\n \n-fn socket_name<T, U: Watcher + NativeHandle<*T>>(sk: SocketNameKind,\n-                                                 handle: U) -> Result<SocketAddr, IoError> {\n-    let getsockname = match sk {\n-        TcpPeer => uvll::tcp_getpeername,\n-        Tcp     => uvll::tcp_getsockname,\n-        Udp     => uvll::udp_getsockname,\n-    };\n-\n-    // Allocate a sockaddr_storage\n-    // since we don't know if it's ipv4 or ipv6\n-    let r_addr = unsafe { uvll::malloc_sockaddr_storage() };\n+impl HomingMissile {\n+    pub fn check(&self, msg: &'static str) {\n+        let local_id = Local::borrow(|sched: &mut Scheduler| sched.sched_id());\n+        assert!(local_id == self.io_home, \"{}\", msg);\n+    }\n+}\n \n-    let r = unsafe {\n-        getsockname(handle.native_handle() as *c_void, r_addr as *uvll::sockaddr_storage)\n-    };\n+impl Drop for HomingMissile {\n+    fn drop(&mut self) {\n+        let f = ForbidUnwind::new(\"leaving home\");\n \n-    if r != 0 {\n-        let status = status_to_maybe_uv_error(r);\n-        return Err(uv_error_to_io_error(status.unwrap()));\n-    }\n+        // It would truly be a sad day if we had moved off the home I/O\n+        // scheduler while we were doing I/O.\n+        self.check(\"task moved away from the home scheduler\");\n \n-    let addr = unsafe {\n-        if uvll::is_ip6_addr(r_addr as *uvll::sockaddr) {\n-            net::uv_socket_addr_to_socket_addr(UvIpv6SocketAddr(r_addr as *uvll::sockaddr_in6))\n-        } else {\n-            net::uv_socket_addr_to_socket_addr(UvIpv4SocketAddr(r_addr as *uvll::sockaddr_in))\n+        // If we were a homed task, then we must send ourselves back to the\n+        // original scheduler. Otherwise, we can just return and keep running\n+        if !Task::on_appropriate_sched() {\n+            let scheduler: ~Scheduler = Local::take();\n+            do scheduler.deschedule_running_task_and_then |_, task| {\n+                do task.wake().map |task| {\n+                    Scheduler::run_task(task);\n+                };\n+            }\n         }\n-    };\n-\n-    unsafe { uvll::free_sockaddr_storage(r_addr); }\n \n-    Ok(addr)\n+        util::ignore(f);\n \n+        unsafe {\n+            let task: *mut Task = Local::unsafe_borrow();\n+            (*task).death.allow_kill((*task).unwinder.unwinding);\n+        }\n+    }\n }\n \n // Obviously an Event Loop is always home.\n@@ -202,27 +159,16 @@ impl EventLoop for UvEventLoop {\n         self.uvio.uv_loop().run();\n     }\n \n-    fn callback(&mut self, f: ~fn()) {\n-        let mut idle_watcher =  IdleWatcher::new(self.uvio.uv_loop());\n-        do idle_watcher.start |mut idle_watcher, status| {\n-            assert!(status.is_none());\n-            idle_watcher.stop();\n-            idle_watcher.close(||());\n-            f();\n-        }\n+    fn callback(&mut self, f: proc()) {\n+        IdleWatcher::onetime(self.uvio.uv_loop(), f);\n     }\n \n-    fn pausible_idle_callback(&mut self) -> ~PausibleIdleCallback {\n-        let idle_watcher = IdleWatcher::new(self.uvio.uv_loop());\n-        ~UvPausibleIdleCallback {\n-            watcher: idle_watcher,\n-            idle_flag: false,\n-            closed: false\n-        } as ~PausibleIdleCallback\n+    fn pausible_idle_callback(&mut self, cb: ~Callback) -> ~PausibleIdleCallback {\n+        IdleWatcher::new(self.uvio.uv_loop(), cb) as ~PausibleIdleCallback\n     }\n \n-    fn remote_callback(&mut self, f: ~fn()) -> ~RemoteCallback {\n-        ~UvRemoteCallback::new(self.uvio.uv_loop(), f) as ~RemoteCallback\n+    fn remote_callback(&mut self, f: ~Callback) -> ~RemoteCallback {\n+        ~AsyncWatcher::new(self.uvio.uv_loop(), f) as ~RemoteCallback\n     }\n \n     fn io<'a>(&'a mut self, f: &fn(&'a mut IoFactory)) {\n@@ -236,44 +182,6 @@ pub extern \"C\" fn new_loop() -> ~EventLoop {\n     ~UvEventLoop::new() as ~EventLoop\n }\n \n-pub struct UvPausibleIdleCallback {\n-    priv watcher: IdleWatcher,\n-    priv idle_flag: bool,\n-    priv closed: bool\n-}\n-\n-impl PausibleIdleCallback for UvPausibleIdleCallback {\n-    #[inline]\n-    fn start(&mut self, f: ~fn()) {\n-        do self.watcher.start |_idle_watcher, _status| {\n-            f();\n-        };\n-        self.idle_flag = true;\n-    }\n-    #[inline]\n-    fn pause(&mut self) {\n-        if self.idle_flag == true {\n-            self.watcher.stop();\n-            self.idle_flag = false;\n-        }\n-    }\n-    #[inline]\n-    fn resume(&mut self) {\n-        if self.idle_flag == false {\n-            self.watcher.restart();\n-            self.idle_flag = true;\n-        }\n-    }\n-    #[inline]\n-    fn close(&mut self) {\n-        self.pause();\n-        if !self.closed {\n-            self.closed = true;\n-            self.watcher.close(||{});\n-        }\n-    }\n-}\n-\n #[test]\n fn test_callback_run_once() {\n     do run_in_bare_thread {\n@@ -288,119 +196,6 @@ fn test_callback_run_once() {\n     }\n }\n \n-// The entire point of async is to call into a loop from other threads so it does not need to home.\n-pub struct UvRemoteCallback {\n-    // The uv async handle for triggering the callback\n-    priv async: AsyncWatcher,\n-    // A flag to tell the callback to exit, set from the dtor. This is\n-    // almost never contested - only in rare races with the dtor.\n-    priv exit_flag: Exclusive<bool>\n-}\n-\n-impl UvRemoteCallback {\n-    pub fn new(loop_: &mut Loop, f: ~fn()) -> UvRemoteCallback {\n-        let exit_flag = Exclusive::new(false);\n-        let exit_flag_clone = exit_flag.clone();\n-        let async = do AsyncWatcher::new(loop_) |watcher, status| {\n-            assert!(status.is_none());\n-\n-            // The synchronization logic here is subtle. To review,\n-            // the uv async handle type promises that, after it is\n-            // triggered the remote callback is definitely called at\n-            // least once. UvRemoteCallback needs to maintain those\n-            // semantics while also shutting down cleanly from the\n-            // dtor. In our case that means that, when the\n-            // UvRemoteCallback dtor calls `async.send()`, here `f` is\n-            // always called later.\n-\n-            // In the dtor both the exit flag is set and the async\n-            // callback fired under a lock.  Here, before calling `f`,\n-            // we take the lock and check the flag. Because we are\n-            // checking the flag before calling `f`, and the flag is\n-            // set under the same lock as the send, then if the flag\n-            // is set then we're guaranteed to call `f` after the\n-            // final send.\n-\n-            // If the check was done after `f()` then there would be a\n-            // period between that call and the check where the dtor\n-            // could be called in the other thread, missing the final\n-            // callback while still destroying the handle.\n-\n-            let should_exit = unsafe {\n-                exit_flag_clone.with_imm(|&should_exit| should_exit)\n-            };\n-\n-            f();\n-\n-            if should_exit {\n-                watcher.close(||());\n-            }\n-\n-        };\n-        UvRemoteCallback {\n-            async: async,\n-            exit_flag: exit_flag\n-        }\n-    }\n-}\n-\n-impl RemoteCallback for UvRemoteCallback {\n-    fn fire(&mut self) { self.async.send() }\n-}\n-\n-impl Drop for UvRemoteCallback {\n-    fn drop(&mut self) {\n-        unsafe {\n-            let this: &mut UvRemoteCallback = cast::transmute_mut(self);\n-            do this.exit_flag.with |should_exit| {\n-                // NB: These two things need to happen atomically. Otherwise\n-                // the event handler could wake up due to a *previous*\n-                // signal and see the exit flag, destroying the handle\n-                // before the final send.\n-                *should_exit = true;\n-                this.async.send();\n-            }\n-        }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test_remote {\n-    use std::cell::Cell;\n-    use std::rt::test::*;\n-    use std::rt::thread::Thread;\n-    use std::rt::tube::Tube;\n-    use std::rt::rtio::EventLoop;\n-    use std::rt::local::Local;\n-    use std::rt::sched::Scheduler;\n-\n-    #[test]\n-    fn test_uv_remote() {\n-        do run_in_mt_newsched_task {\n-            let mut tube = Tube::new();\n-            let tube_clone = tube.clone();\n-            let remote_cell = Cell::new_empty();\n-            do Local::borrow |sched: &mut Scheduler| {\n-                let tube_clone = tube_clone.clone();\n-                let tube_clone_cell = Cell::new(tube_clone);\n-                let remote = do sched.event_loop.remote_callback {\n-                    // This could be called multiple times\n-                    if !tube_clone_cell.is_empty() {\n-                        tube_clone_cell.take().send(1);\n-                    }\n-                };\n-                remote_cell.put_back(remote);\n-            }\n-            let thread = do Thread::start {\n-                remote_cell.take().fire();\n-            };\n-\n-            assert!(tube.recv() == 1);\n-            thread.join();\n-        }\n-    }\n-}\n-\n pub struct UvIoFactory(Loop);\n \n impl UvIoFactory {\n@@ -409,219 +204,47 @@ impl UvIoFactory {\n     }\n }\n \n-/// Helper for a variety of simple uv_fs_* functions that have no ret val. This\n-/// function takes the loop that it will act on, and then invokes the specified\n-/// callback in a situation where the task wil be immediately blocked\n-/// afterwards. The `FsCallback` yielded must be invoked to reschedule the task\n-/// (once the result of the operation is known).\n-fn uv_fs_helper<T:Send>(loop_: &mut Loop,\n-                        retfn: extern \"Rust\" fn(&mut FsRequest) -> T,\n-                        cb: &fn(&mut FsRequest, &mut Loop, FsCallback))\n-                        -> Result<T, IoError> {\n-    let result_cell = Cell::new_empty();\n-    let result_cell_ptr: *Cell<Result<T, IoError>> = &result_cell;\n-    do task::unkillable { // FIXME(#8674)\n-        let scheduler: ~Scheduler = Local::take();\n-        let mut new_req = FsRequest::new();\n-        do scheduler.deschedule_running_task_and_then |_, task| {\n-            let task_cell = Cell::new(task);\n-            do cb(&mut new_req, loop_) |req, err| {\n-                let res = match err {\n-                    None => Ok(retfn(req)),\n-                    Some(err) => Err(uv_error_to_io_error(err))\n-                };\n-                unsafe { (*result_cell_ptr).put_back(res); }\n-                let scheduler: ~Scheduler = Local::take();\n-                scheduler.resume_blocked_task_immediately(task_cell.take());\n-            };\n-        }\n-    }\n-    assert!(!result_cell.is_empty());\n-    return result_cell.take();\n-}\n-\n-fn unit(_: &mut FsRequest) {}\n-\n-fn fs_mkstat(f: &mut FsRequest) -> FileStat {\n-    let path = unsafe { Path::new(CString::new(f.get_path(), false)) };\n-    let stat = f.get_stat();\n-    fn to_msec(stat: uvll::uv_timespec_t) -> u64 {\n-        (stat.tv_sec * 1000 + stat.tv_nsec / 1000000) as u64\n-    }\n-    let kind = match (stat.st_mode as c_int) & libc::S_IFMT {\n-        libc::S_IFREG => io::TypeFile,\n-        libc::S_IFDIR => io::TypeDirectory,\n-        libc::S_IFIFO => io::TypeNamedPipe,\n-        libc::S_IFBLK => io::TypeBlockSpecial,\n-        libc::S_IFLNK => io::TypeSymlink,\n-        _ => io::TypeUnknown,\n-    };\n-    FileStat {\n-        path: path,\n-        size: stat.st_size as u64,\n-        kind: kind,\n-        perm: (stat.st_mode as io::FilePermission) & io::AllPermissions,\n-        created: to_msec(stat.st_birthtim),\n-        modified: to_msec(stat.st_mtim),\n-        accessed: to_msec(stat.st_atim),\n-        unstable: io::UnstableFileStat {\n-            device: stat.st_dev as u64,\n-            inode: stat.st_ino as u64,\n-            rdev: stat.st_rdev as u64,\n-            nlink: stat.st_nlink as u64,\n-            uid: stat.st_uid as u64,\n-            gid: stat.st_gid as u64,\n-            blksize: stat.st_blksize as u64,\n-            blocks: stat.st_blocks as u64,\n-            flags: stat.st_flags as u64,\n-            gen: stat.st_gen as u64,\n-        }\n-    }\n-}\n-\n impl IoFactory for UvIoFactory {\n     // Connect to an address and return a new stream\n     // NB: This blocks the task waiting on the connection.\n     // It would probably be better to return a future\n-    fn tcp_connect(&mut self, addr: SocketAddr) -> Result<~RtioTcpStream, IoError> {\n-        // Create a cell in the task to hold the result. We will fill\n-        // the cell before resuming the task.\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<~RtioTcpStream, IoError>> = &result_cell;\n-\n-        // Block this task and take ownership, switch to scheduler context\n-        do task::unkillable { // FIXME(#8674)\n-            let scheduler: ~Scheduler = Local::take();\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-\n-                let mut tcp = TcpWatcher::new(self.uv_loop());\n-                let task_cell = Cell::new(task);\n-\n-                // Wait for a connection\n-                do tcp.connect(addr) |stream, status| {\n-                    match status {\n-                        None => {\n-                            let tcp = NativeHandle::from_native_handle(stream.native_handle());\n-                            let home = get_handle_to_current_scheduler!();\n-                            let res = Ok(~UvTcpStream { watcher: tcp, home: home }\n-                                                as ~RtioTcpStream);\n-\n-                            // Store the stream in the task's stack\n-                            unsafe { (*result_cell_ptr).put_back(res); }\n-\n-                            // Context switch\n-                            let scheduler: ~Scheduler = Local::take();\n-                            scheduler.resume_blocked_task_immediately(task_cell.take());\n-                        }\n-                        Some(_) => {\n-                            let task_cell = Cell::new(task_cell.take());\n-                            do stream.close {\n-                                let res = Err(uv_error_to_io_error(status.unwrap()));\n-                                unsafe { (*result_cell_ptr).put_back(res); }\n-                                let scheduler: ~Scheduler = Local::take();\n-                                scheduler.resume_blocked_task_immediately(task_cell.take());\n-                            }\n-                        }\n-                    }\n-                }\n-            }\n+    fn tcp_connect(&mut self, addr: SocketAddr)\n+        -> Result<~RtioTcpStream, IoError>\n+    {\n+        match TcpWatcher::connect(self.uv_loop(), addr) {\n+            Ok(t) => Ok(~t as ~RtioTcpStream),\n+            Err(e) => Err(uv_error_to_io_error(e)),\n         }\n-\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n     }\n \n     fn tcp_bind(&mut self, addr: SocketAddr) -> Result<~RtioTcpListener, IoError> {\n-        let mut watcher = TcpWatcher::new(self.uv_loop());\n-        match watcher.bind(addr) {\n-            Ok(_) => {\n-                let home = get_handle_to_current_scheduler!();\n-                Ok(~UvTcpListener::new(watcher, home) as ~RtioTcpListener)\n-            }\n-            Err(uverr) => {\n-                do task::unkillable { // FIXME(#8674)\n-                    let scheduler: ~Scheduler = Local::take();\n-                    do scheduler.deschedule_running_task_and_then |_, task| {\n-                        let task_cell = Cell::new(task);\n-                        do watcher.as_stream().close {\n-                            let scheduler: ~Scheduler = Local::take();\n-                            scheduler.resume_blocked_task_immediately(task_cell.take());\n-                        }\n-                    }\n-                    Err(uv_error_to_io_error(uverr))\n-                }\n-            }\n+        match TcpListener::bind(self.uv_loop(), addr) {\n+            Ok(t) => Ok(t as ~RtioTcpListener),\n+            Err(e) => Err(uv_error_to_io_error(e)),\n         }\n     }\n \n     fn udp_bind(&mut self, addr: SocketAddr) -> Result<~RtioUdpSocket, IoError> {\n-        let mut watcher = UdpWatcher::new(self.uv_loop());\n-        match watcher.bind(addr) {\n-            Ok(_) => {\n-                let home = get_handle_to_current_scheduler!();\n-                Ok(~UvUdpSocket { watcher: watcher, home: home } as ~RtioUdpSocket)\n-            }\n-            Err(uverr) => {\n-                do task::unkillable { // FIXME(#8674)\n-                    let scheduler: ~Scheduler = Local::take();\n-                    do scheduler.deschedule_running_task_and_then |_, task| {\n-                        let task_cell = Cell::new(task);\n-                        do watcher.close {\n-                            let scheduler: ~Scheduler = Local::take();\n-                            scheduler.resume_blocked_task_immediately(task_cell.take());\n-                        }\n-                    }\n-                    Err(uv_error_to_io_error(uverr))\n-                }\n-            }\n+        match UdpWatcher::bind(self.uv_loop(), addr) {\n+            Ok(u) => Ok(~u as ~RtioUdpSocket),\n+            Err(e) => Err(uv_error_to_io_error(e)),\n         }\n     }\n \n     fn timer_init(&mut self) -> Result<~RtioTimer, IoError> {\n-        let watcher = TimerWatcher::new(self.uv_loop());\n-        let home = get_handle_to_current_scheduler!();\n-        Ok(~UvTimer::new(watcher, home) as ~RtioTimer)\n+        Ok(TimerWatcher::new(self.uv_loop()) as ~RtioTimer)\n     }\n \n     fn get_host_addresses(&mut self, host: Option<&str>, servname: Option<&str>,\n                           hint: Option<ai::Hint>) -> Result<~[ai::Info], IoError> {\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<~[ai::Info], IoError>> = &result_cell;\n-        let host_ptr: *Option<&str> = &host;\n-        let servname_ptr: *Option<&str> = &servname;\n-        let hint_ptr: *Option<ai::Hint> = &hint;\n-        let addrinfo_req = GetAddrInfoRequest::new();\n-        let addrinfo_req_cell = Cell::new(addrinfo_req);\n-\n-        do task::unkillable { // FIXME(#8674)\n-            let scheduler: ~Scheduler = Local::take();\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                let mut addrinfo_req = addrinfo_req_cell.take();\n-                unsafe {\n-                    do addrinfo_req.getaddrinfo(self.uv_loop(),\n-                                                *host_ptr, *servname_ptr,\n-                                                *hint_ptr) |_, addrinfo, err| {\n-                        let res = match err {\n-                            None => Ok(accum_addrinfo(addrinfo)),\n-                            Some(err) => Err(uv_error_to_io_error(err))\n-                        };\n-                        (*result_cell_ptr).put_back(res);\n-                        let scheduler: ~Scheduler = Local::take();\n-                        scheduler.resume_blocked_task_immediately(task_cell.take());\n-                    }\n-                }\n-            }\n-        }\n-        addrinfo_req.delete();\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n+        let r = GetAddrInfoRequest::run(self.uv_loop(), host, servname, hint);\n+        r.map_err(uv_error_to_io_error)\n     }\n \n-    fn fs_from_raw_fd(&mut self, fd: c_int, close: CloseBehavior) -> ~RtioFileStream {\n-        let loop_ = Loop {handle: self.uv_loop().native_handle()};\n-        let home = get_handle_to_current_scheduler!();\n-        ~UvFileStream::new(loop_, fd, close, home) as ~RtioFileStream\n+    fn fs_from_raw_fd(&mut self, fd: c_int,\n+                      close: CloseBehavior) -> ~RtioFileStream {\n+        let loop_ = Loop::wrap(self.uv_loop().handle);\n+        ~FileWatcher::new(loop_, fd, close) as ~RtioFileStream\n     }\n \n     fn fs_open(&mut self, path: &CString, fm: FileMode, fa: FileAccess)\n@@ -639,1918 +262,119 @@ impl IoFactory for UvIoFactory {\n             io::ReadWrite => (flags | libc::O_RDWR | libc::O_CREAT,\n                               libc::S_IRUSR | libc::S_IWUSR),\n         };\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<~RtioFileStream,\n-                                           IoError>> = &result_cell;\n-        do task::unkillable { // FIXME(#8674)\n-            let scheduler: ~Scheduler = Local::take();\n-            let open_req = file::FsRequest::new();\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                do open_req.open(self.uv_loop(), path, flags as int, mode as int)\n-                      |req,err| {\n-                    if err.is_none() {\n-                        let loop_ = Loop {handle: req.get_loop().native_handle()};\n-                        let home = get_handle_to_current_scheduler!();\n-                        let fd = req.get_result() as c_int;\n-                        let fs = ~UvFileStream::new(\n-                            loop_, fd, CloseSynchronously, home) as ~RtioFileStream;\n-                        let res = Ok(fs);\n-                        unsafe { (*result_cell_ptr).put_back(res); }\n-                        let scheduler: ~Scheduler = Local::take();\n-                        scheduler.resume_blocked_task_immediately(task_cell.take());\n-                    } else {\n-                        let res = Err(uv_error_to_io_error(err.unwrap()));\n-                        unsafe { (*result_cell_ptr).put_back(res); }\n-                        let scheduler: ~Scheduler = Local::take();\n-                        scheduler.resume_blocked_task_immediately(task_cell.take());\n-                    }\n-                };\n-            };\n-        };\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n+\n+        match FsRequest::open(self.uv_loop(), path, flags as int, mode as int) {\n+            Ok(fs) => Ok(~fs as ~RtioFileStream),\n+            Err(e) => Err(uv_error_to_io_error(e))\n+        }\n     }\n \n     fn fs_unlink(&mut self, path: &CString) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.unlink(l, path, cb)\n-        }\n+        let r = FsRequest::unlink(self.uv_loop(), path);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_lstat(&mut self, path: &CString) -> Result<FileStat, IoError> {\n-        do uv_fs_helper(self.uv_loop(), fs_mkstat) |req, l, cb| {\n-            req.lstat(l, path, cb)\n-        }\n+        let r = FsRequest::lstat(self.uv_loop(), path);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_stat(&mut self, path: &CString) -> Result<FileStat, IoError> {\n-        do uv_fs_helper(self.uv_loop(), fs_mkstat) |req, l, cb| {\n-            req.stat(l, path, cb)\n-        }\n+        let r = FsRequest::stat(self.uv_loop(), path);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_mkdir(&mut self, path: &CString,\n                 perm: io::FilePermission) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.mkdir(l, path, perm as c_int, cb)\n-        }\n+        let r = FsRequest::mkdir(self.uv_loop(), path, perm as c_int);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_rmdir(&mut self, path: &CString) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.rmdir(l, path, cb)\n-        }\n+        let r = FsRequest::rmdir(self.uv_loop(), path);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_rename(&mut self, path: &CString, to: &CString) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.rename(l, path, to, cb)\n-        }\n+        let r = FsRequest::rename(self.uv_loop(), path, to);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_chmod(&mut self, path: &CString,\n                 perm: io::FilePermission) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.chmod(l, path, perm as c_int, cb)\n-        }\n+        let r = FsRequest::chmod(self.uv_loop(), path, perm as c_int);\n+        r.map_err(uv_error_to_io_error)\n     }\n-    fn fs_readdir(&mut self, path: &CString, flags: c_int) ->\n-        Result<~[Path], IoError> {\n-        use str::StrSlice;\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<~[Path],\n-                                           IoError>> = &result_cell;\n-        let path_cell = Cell::new(path);\n-        do task::unkillable { // FIXME(#8674)\n-            let scheduler: ~Scheduler = Local::take();\n-            let stat_req = file::FsRequest::new();\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                let path = path_cell.take();\n-                // Don't pick up the null byte\n-                let slice = path.as_bytes().slice(0, path.len());\n-                let path_parent = Cell::new(Path::new(slice));\n-                do stat_req.readdir(self.uv_loop(), path, flags) |req,err| {\n-                    let parent = path_parent.take();\n-                    let res = match err {\n-                        None => {\n-                            let mut paths = ~[];\n-                            do req.each_path |rel_path| {\n-                                let p = rel_path.as_bytes();\n-                                paths.push(parent.join(p.slice_to(rel_path.len())));\n-                            }\n-                            Ok(paths)\n-                        },\n-                        Some(e) => {\n-                            Err(uv_error_to_io_error(e))\n-                        }\n-                    };\n-                    unsafe { (*result_cell_ptr).put_back(res); }\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                };\n-            };\n-        };\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n+    fn fs_readdir(&mut self, path: &CString, flags: c_int)\n+        -> Result<~[Path], IoError>\n+    {\n+        let r = FsRequest::readdir(self.uv_loop(), path, flags);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_link(&mut self, src: &CString, dst: &CString) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.link(l, src, dst, cb)\n-        }\n+        let r = FsRequest::link(self.uv_loop(), src, dst);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_symlink(&mut self, src: &CString, dst: &CString) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.symlink(l, src, dst, cb)\n-        }\n+        let r = FsRequest::symlink(self.uv_loop(), src, dst);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_chown(&mut self, path: &CString, uid: int, gid: int) -> Result<(), IoError> {\n-        do uv_fs_helper(self.uv_loop(), unit) |req, l, cb| {\n-            req.chown(l, path, uid, gid, cb)\n-        }\n+        let r = FsRequest::chown(self.uv_loop(), path, uid, gid);\n+        r.map_err(uv_error_to_io_error)\n     }\n     fn fs_readlink(&mut self, path: &CString) -> Result<Path, IoError> {\n-        fn getlink(f: &mut FsRequest) -> Path {\n-            Path::new(unsafe { CString::new(f.get_ptr() as *libc::c_char, false) })\n-        }\n-        do uv_fs_helper(self.uv_loop(), getlink) |req, l, cb| {\n-            req.readlink(l, path, cb)\n-        }\n+        let r = FsRequest::readlink(self.uv_loop(), path);\n+        r.map_err(uv_error_to_io_error)\n+    }\n+    fn fs_utime(&mut self, path: &CString, atime: u64, mtime: u64)\n+        -> Result<(), IoError>\n+    {\n+        let r = FsRequest::utime(self.uv_loop(), path, atime, mtime);\n+        r.map_err(uv_error_to_io_error)\n     }\n \n     fn spawn(&mut self, config: ProcessConfig)\n             -> Result<(~RtioProcess, ~[Option<~RtioPipe>]), IoError>\n     {\n-        // Sadly, we must create the UvProcess before we actually call uv_spawn\n-        // so that the exit_cb can close over it and notify it when the process\n-        // has exited.\n-        let mut ret = ~UvProcess {\n-            process: Process::new(),\n-            home: None,\n-            exit_status: None,\n-            term_signal: None,\n-            exit_error: None,\n-            descheduled: None,\n-        };\n-        let ret_ptr = unsafe {\n-            *cast::transmute::<&~UvProcess, &*mut UvProcess>(&ret)\n-        };\n-\n-        // The purpose of this exit callback is to record the data about the\n-        // exit and then wake up the task which may be waiting for the process\n-        // to exit. This is all performed in the current io-loop, and the\n-        // implementation of UvProcess ensures that reading these fields always\n-        // occurs on the current io-loop.\n-        let exit_cb: ExitCallback = |_, exit_status, term_signal, error| {\n-            unsafe {\n-                assert!((*ret_ptr).exit_status.is_none());\n-                (*ret_ptr).exit_status = Some(exit_status);\n-                (*ret_ptr).term_signal = Some(term_signal);\n-                (*ret_ptr).exit_error = error;\n-                match (*ret_ptr).descheduled.take() {\n-                    Some(task) => {\n-                        let scheduler: ~Scheduler = Local::take();\n-                        scheduler.resume_blocked_task_immediately(task);\n-                    }\n-                    None => {}\n-                }\n-            }\n-        };\n-\n-        match ret.process.spawn(self.uv_loop(), config, exit_cb) {\n-            Ok(io) => {\n-                // Only now do we actually get a handle to this scheduler.\n-                ret.home = Some(get_handle_to_current_scheduler!());\n-                Ok((ret as ~RtioProcess,\n-                    io.move_iter().map(|p| p.map(|p| p as ~RtioPipe)).collect()))\n-            }\n-            Err(uverr) => {\n-                // We still need to close the process handle we created, but\n-                // that's taken care for us in the destructor of UvProcess\n-                Err(uv_error_to_io_error(uverr))\n+        match Process::spawn(self.uv_loop(), config) {\n+            Ok((p, io)) => {\n+                Ok((p as ~RtioProcess,\n+                    io.move_iter().map(|i| i.map(|p| ~p as ~RtioPipe)).collect()))\n             }\n+            Err(e) => Err(uv_error_to_io_error(e)),\n         }\n     }\n \n-    fn unix_bind(&mut self, path: &CString) ->\n-        Result<~RtioUnixListener, IoError> {\n-        let mut pipe = UvUnboundPipe::new(self.uv_loop());\n-        match pipe.pipe.bind(path) {\n-            Ok(()) => Ok(~UvUnixListener::new(pipe) as ~RtioUnixListener),\n+    fn unix_bind(&mut self, path: &CString) -> Result<~RtioUnixListener, IoError>\n+    {\n+        match PipeListener::bind(self.uv_loop(), path) {\n+            Ok(p) => Ok(p as ~RtioUnixListener),\n             Err(e) => Err(uv_error_to_io_error(e)),\n         }\n     }\n \n     fn unix_connect(&mut self, path: &CString) -> Result<~RtioPipe, IoError> {\n-        let pipe = UvUnboundPipe::new(self.uv_loop());\n-        let mut rawpipe = pipe.pipe;\n-\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<~RtioPipe, IoError>> = &result_cell;\n-        let pipe_cell = Cell::new(pipe);\n-        let pipe_cell_ptr: *Cell<UvUnboundPipe> = &pipe_cell;\n-\n-        let scheduler: ~Scheduler = Local::take();\n-        do scheduler.deschedule_running_task_and_then |_, task| {\n-            let task_cell = Cell::new(task);\n-            do rawpipe.connect(path) |_stream, err| {\n-                let res = match err {\n-                    None => {\n-                        let pipe = unsafe { (*pipe_cell_ptr).take() };\n-                        Ok(~UvPipeStream::new(pipe) as ~RtioPipe)\n-                    }\n-                    Some(e) => Err(uv_error_to_io_error(e)),\n-                };\n-                unsafe { (*result_cell_ptr).put_back(res); }\n-                let scheduler: ~Scheduler = Local::take();\n-                scheduler.resume_blocked_task_immediately(task_cell.take());\n-            }\n+        match PipeWatcher::connect(self.uv_loop(), path) {\n+            Ok(p) => Ok(~p as ~RtioPipe),\n+            Err(e) => Err(uv_error_to_io_error(e)),\n         }\n-\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n     }\n \n     fn tty_open(&mut self, fd: c_int, readable: bool)\n             -> Result<~RtioTTY, IoError> {\n-        match tty::TTY::new(self.uv_loop(), fd, readable) {\n-            Ok(tty) => Ok(~UvTTY {\n-                home: get_handle_to_current_scheduler!(),\n-                tty: tty,\n-                fd: fd,\n-            } as ~RtioTTY),\n+        match TtyWatcher::new(self.uv_loop(), fd, readable) {\n+            Ok(tty) => Ok(~tty as ~RtioTTY),\n             Err(e) => Err(uv_error_to_io_error(e))\n         }\n     }\n \n     fn pipe_open(&mut self, fd: c_int) -> Result<~RtioPipe, IoError> {\n-        let mut pipe = UvUnboundPipe::new(self.uv_loop());\n-        match pipe.pipe.open(fd) {\n-            Ok(()) => Ok(~UvPipeStream::new(pipe) as ~RtioPipe),\n+        match PipeWatcher::open(self.uv_loop(), fd) {\n+            Ok(s) => Ok(~s as ~RtioPipe),\n             Err(e) => Err(uv_error_to_io_error(e))\n         }\n     }\n \n     fn signal(&mut self, signum: Signum, channel: SharedChan<Signum>)\n         -> Result<~RtioSignal, IoError> {\n-        let watcher = SignalWatcher::new(self.uv_loop());\n-        let home = get_handle_to_current_scheduler!();\n-        let mut signal = ~UvSignal::new(watcher, home);\n-        match signal.watcher.start(signum, |_, _| channel.send_deferred(signum)) {\n-            Ok(()) => Ok(signal as ~RtioSignal),\n+        match SignalWatcher::new(self.uv_loop(), signum, channel) {\n+            Ok(s) => Ok(s as ~RtioSignal),\n             Err(e) => Err(uv_error_to_io_error(e)),\n         }\n     }\n }\n-\n-pub struct UvTcpListener {\n-    priv watcher : TcpWatcher,\n-    priv home: SchedHandle,\n-}\n-\n-impl HomingIO for UvTcpListener {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl UvTcpListener {\n-    fn new(watcher: TcpWatcher, home: SchedHandle) -> UvTcpListener {\n-        UvTcpListener { watcher: watcher, home: home }\n-    }\n-}\n-\n-impl Drop for UvTcpListener {\n-    fn drop(&mut self) {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task = Cell::new(task);\n-                do self_.watcher.as_stream().close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task.take());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-impl RtioSocket for UvTcpListener {\n-    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n-        do self.home_for_io |self_| {\n-            socket_name(Tcp, self_.watcher)\n-        }\n-    }\n-}\n-\n-impl RtioTcpListener for UvTcpListener {\n-    fn listen(~self) -> Result<~RtioTcpAcceptor, IoError> {\n-        do self.home_for_io_consume |self_| {\n-            let acceptor = ~UvTcpAcceptor::new(self_);\n-            let incoming = Cell::new(acceptor.incoming.clone());\n-            let mut stream = acceptor.listener.watcher.as_stream();\n-            let res = do stream.listen |mut server, status| {\n-                do incoming.with_mut_ref |incoming| {\n-                    let inc = match status {\n-                        Some(_) => Err(standard_error(OtherIoError)),\n-                        None => {\n-                            let inc = TcpWatcher::new(&server.event_loop());\n-                            // first accept call in the callback guarenteed to succeed\n-                            server.accept(inc.as_stream());\n-                            let home = get_handle_to_current_scheduler!();\n-                            Ok(~UvTcpStream { watcher: inc, home: home }\n-                                    as ~RtioTcpStream)\n-                        }\n-                    };\n-                    incoming.send(inc);\n-                }\n-            };\n-            match res {\n-                Ok(()) => Ok(acceptor as ~RtioTcpAcceptor),\n-                Err(e) => Err(uv_error_to_io_error(e)),\n-            }\n-        }\n-    }\n-}\n-\n-pub struct UvTcpAcceptor {\n-    priv listener: UvTcpListener,\n-    priv incoming: Tube<Result<~RtioTcpStream, IoError>>,\n-}\n-\n-impl HomingIO for UvTcpAcceptor {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { self.listener.home() }\n-}\n-\n-impl UvTcpAcceptor {\n-    fn new(listener: UvTcpListener) -> UvTcpAcceptor {\n-        UvTcpAcceptor { listener: listener, incoming: Tube::new() }\n-    }\n-}\n-\n-impl RtioSocket for UvTcpAcceptor {\n-    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n-        do self.home_for_io |self_| {\n-            socket_name(Tcp, self_.listener.watcher)\n-        }\n-    }\n-}\n-\n-fn accept_simultaneously(stream: StreamWatcher, a: int) -> Result<(), IoError> {\n-    let r = unsafe {\n-        uvll::tcp_simultaneous_accepts(stream.native_handle(), a as c_int)\n-    };\n-\n-    match status_to_maybe_uv_error(r) {\n-        Some(err) => Err(uv_error_to_io_error(err)),\n-        None => Ok(())\n-    }\n-}\n-\n-impl RtioTcpAcceptor for UvTcpAcceptor {\n-    fn accept(&mut self) -> Result<~RtioTcpStream, IoError> {\n-        do self.home_for_io |self_| {\n-            self_.incoming.recv()\n-        }\n-    }\n-\n-    fn accept_simultaneously(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            accept_simultaneously(self_.listener.watcher.as_stream(), 1)\n-        }\n-    }\n-\n-    fn dont_accept_simultaneously(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            accept_simultaneously(self_.listener.watcher.as_stream(), 0)\n-        }\n-    }\n-}\n-\n-fn read_stream(mut watcher: StreamWatcher,\n-               scheduler: ~Scheduler,\n-               buf: &mut [u8]) -> Result<uint, IoError> {\n-    let result_cell = Cell::new_empty();\n-    let result_cell_ptr: *Cell<Result<uint, IoError>> = &result_cell;\n-\n-    let uv_buf = slice_to_uv_buf(buf);\n-    do scheduler.deschedule_running_task_and_then |_sched, task| {\n-        let task_cell = Cell::new(task);\n-        // XXX: We shouldn't reallocate these callbacks every\n-        // call to read\n-        let alloc: AllocCallback = |_| uv_buf;\n-        do watcher.read_start(alloc) |mut watcher, nread, _buf, status| {\n-\n-            // Stop reading so that no read callbacks are\n-            // triggered before the user calls `read` again.\n-            // XXX: Is there a performance impact to calling\n-            // stop here?\n-            watcher.read_stop();\n-\n-            let result = if status.is_none() {\n-                assert!(nread >= 0);\n-                Ok(nread as uint)\n-            } else {\n-                Err(uv_error_to_io_error(status.unwrap()))\n-            };\n-\n-            unsafe { (*result_cell_ptr).put_back(result); }\n-\n-            let scheduler: ~Scheduler = Local::take();\n-            scheduler.resume_blocked_task_immediately(task_cell.take());\n-        }\n-    }\n-\n-    assert!(!result_cell.is_empty());\n-    result_cell.take()\n-}\n-\n-fn write_stream(mut watcher: StreamWatcher,\n-                scheduler: ~Scheduler,\n-                buf: &[u8]) -> Result<(), IoError> {\n-    let result_cell = Cell::new_empty();\n-    let result_cell_ptr: *Cell<Result<(), IoError>> = &result_cell;\n-    let buf_ptr: *&[u8] = &buf;\n-    do scheduler.deschedule_running_task_and_then |_, task| {\n-        let task_cell = Cell::new(task);\n-        let buf = unsafe { slice_to_uv_buf(*buf_ptr) };\n-        do watcher.write(buf) |_watcher, status| {\n-            let result = if status.is_none() {\n-                Ok(())\n-            } else {\n-                Err(uv_error_to_io_error(status.unwrap()))\n-            };\n-\n-            unsafe { (*result_cell_ptr).put_back(result); }\n-\n-            let scheduler: ~Scheduler = Local::take();\n-            scheduler.resume_blocked_task_immediately(task_cell.take());\n-        }\n-    }\n-\n-    assert!(!result_cell.is_empty());\n-    result_cell.take()\n-}\n-\n-pub struct UvUnboundPipe {\n-    pipe: Pipe,\n-    priv home: SchedHandle,\n-}\n-\n-impl UvUnboundPipe {\n-    /// Creates a new unbound pipe homed to the current scheduler, placed on the\n-    /// specified event loop\n-    pub fn new(loop_: &Loop) -> UvUnboundPipe {\n-        UvUnboundPipe {\n-            pipe: Pipe::new(loop_, false),\n-            home: get_handle_to_current_scheduler!(),\n-        }\n-    }\n-}\n-\n-impl HomingIO for UvUnboundPipe {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl Drop for UvUnboundPipe {\n-    fn drop(&mut self) {\n-        do self.home_for_io |self_| {\n-            let scheduler: ~Scheduler = Local::take();\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                do self_.pipe.close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-pub struct UvPipeStream {\n-    priv inner: UvUnboundPipe,\n-}\n-\n-impl UvPipeStream {\n-    pub fn new(inner: UvUnboundPipe) -> UvPipeStream {\n-        UvPipeStream { inner: inner }\n-    }\n-}\n-\n-impl RtioPipe for UvPipeStream {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n-        do self.inner.home_for_io_with_sched |self_, scheduler| {\n-            read_stream(self_.pipe.as_stream(), scheduler, buf)\n-        }\n-    }\n-    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n-        do self.inner.home_for_io_with_sched |self_, scheduler| {\n-            write_stream(self_.pipe.as_stream(), scheduler, buf)\n-        }\n-    }\n-}\n-\n-pub struct UvTcpStream {\n-    priv watcher: TcpWatcher,\n-    priv home: SchedHandle,\n-}\n-\n-impl HomingIO for UvTcpStream {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl Drop for UvTcpStream {\n-    fn drop(&mut self) {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                do self_.watcher.as_stream().close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-impl RtioSocket for UvTcpStream {\n-    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n-        do self.home_for_io |self_| {\n-            socket_name(Tcp, self_.watcher)\n-        }\n-    }\n-}\n-\n-impl RtioTcpStream for UvTcpStream {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            read_stream(self_.watcher.as_stream(), scheduler, buf)\n-        }\n-    }\n-\n-    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            write_stream(self_.watcher.as_stream(), scheduler, buf)\n-        }\n-    }\n-\n-    fn peer_name(&mut self) -> Result<SocketAddr, IoError> {\n-        do self.home_for_io |self_| {\n-            socket_name(TcpPeer, self_.watcher)\n-        }\n-    }\n-\n-    fn control_congestion(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            let r = unsafe { uvll::tcp_nodelay(self_.watcher.native_handle(), 0 as c_int) };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn nodelay(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            let r = unsafe { uvll::tcp_nodelay(self_.watcher.native_handle(), 1 as c_int) };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn keepalive(&mut self, delay_in_seconds: uint) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            let r = unsafe {\n-                uvll::tcp_keepalive(self_.watcher.native_handle(), 1 as c_int,\n-                                    delay_in_seconds as c_uint)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn letdie(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            let r = unsafe {\n-                uvll::tcp_keepalive(self_.watcher.native_handle(), 0 as c_int, 0 as c_uint)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-}\n-\n-pub struct UvUdpSocket {\n-    priv watcher: UdpWatcher,\n-    priv home: SchedHandle,\n-}\n-\n-impl HomingIO for UvUdpSocket {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl Drop for UvUdpSocket {\n-    fn drop(&mut self) {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                do self_.watcher.close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-impl RtioSocket for UvUdpSocket {\n-    fn socket_name(&mut self) -> Result<SocketAddr, IoError> {\n-        do self.home_for_io |self_| {\n-            socket_name(Udp, self_.watcher)\n-        }\n-    }\n-}\n-\n-impl RtioUdpSocket for UvUdpSocket {\n-    fn recvfrom(&mut self, buf: &mut [u8]) -> Result<(uint, SocketAddr), IoError> {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            let result_cell = Cell::new_empty();\n-            let result_cell_ptr: *Cell<Result<(uint, SocketAddr), IoError>> = &result_cell;\n-            let uv_buf = slice_to_uv_buf(buf);\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                let alloc: AllocCallback = |_| uv_buf;\n-                do self_.watcher.recv_start(alloc) |mut watcher, nread, _buf, addr, flags, status| {\n-                    let _ = flags; // /XXX add handling for partials?\n-\n-                    watcher.recv_stop();\n-\n-                    let result = match status {\n-                        None => {\n-                            assert!(nread >= 0);\n-                            Ok((nread as uint, addr))\n-                        }\n-                        Some(err) => Err(uv_error_to_io_error(err)),\n-                    };\n-\n-                    unsafe { (*result_cell_ptr).put_back(result); }\n-\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-\n-            assert!(!result_cell.is_empty());\n-            result_cell.take()\n-        }\n-    }\n-\n-    fn sendto(&mut self, buf: &[u8], dst: SocketAddr) -> Result<(), IoError> {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            let result_cell = Cell::new_empty();\n-            let result_cell_ptr: *Cell<Result<(), IoError>> = &result_cell;\n-            let buf_ptr: *&[u8] = &buf;\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                let buf = unsafe { slice_to_uv_buf(*buf_ptr) };\n-                do self_.watcher.send(buf, dst) |_watcher, status| {\n-\n-                    let result = match status {\n-                        None => Ok(()),\n-                        Some(err) => Err(uv_error_to_io_error(err)),\n-                    };\n-\n-                    unsafe { (*result_cell_ptr).put_back(result); }\n-\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-\n-            assert!(!result_cell.is_empty());\n-            result_cell.take()\n-        }\n-    }\n-\n-    fn join_multicast(&mut self, multi: IpAddr) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            let r = unsafe {\n-                do multi.to_str().with_c_str |m_addr| {\n-                    uvll::udp_set_membership(self_.watcher.native_handle(), m_addr,\n-                                             ptr::null(), uvll::UV_JOIN_GROUP)\n-                }\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn leave_multicast(&mut self, multi: IpAddr) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            let r = unsafe {\n-                do multi.to_str().with_c_str |m_addr| {\n-                    uvll::udp_set_membership(self_.watcher.native_handle(), m_addr,\n-                                             ptr::null(), uvll::UV_LEAVE_GROUP)\n-                }\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn loop_multicast_locally(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-\n-            let r = unsafe {\n-                uvll::udp_set_multicast_loop(self_.watcher.native_handle(), 1 as c_int)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn dont_loop_multicast_locally(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-\n-            let r = unsafe {\n-                uvll::udp_set_multicast_loop(self_.watcher.native_handle(), 0 as c_int)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn multicast_time_to_live(&mut self, ttl: int) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-\n-            let r = unsafe {\n-                uvll::udp_set_multicast_ttl(self_.watcher.native_handle(), ttl as c_int)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn time_to_live(&mut self, ttl: int) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-\n-            let r = unsafe {\n-                uvll::udp_set_ttl(self_.watcher.native_handle(), ttl as c_int)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn hear_broadcasts(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-\n-            let r = unsafe {\n-                uvll::udp_set_broadcast(self_.watcher.native_handle(), 1 as c_int)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-\n-    fn ignore_broadcasts(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-\n-            let r = unsafe {\n-                uvll::udp_set_broadcast(self_.watcher.native_handle(), 0 as c_int)\n-            };\n-\n-            match status_to_maybe_uv_error(r) {\n-                Some(err) => Err(uv_error_to_io_error(err)),\n-                None => Ok(())\n-            }\n-        }\n-    }\n-}\n-\n-pub struct UvTimer {\n-    priv watcher: timer::TimerWatcher,\n-    priv home: SchedHandle,\n-}\n-\n-impl HomingIO for UvTimer {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl UvTimer {\n-    fn new(w: timer::TimerWatcher, home: SchedHandle) -> UvTimer {\n-        UvTimer { watcher: w, home: home }\n-    }\n-}\n-\n-impl Drop for UvTimer {\n-    fn drop(&mut self) {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            uvdebug!(\"closing UvTimer\");\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                do self_.watcher.close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-impl RtioTimer for UvTimer {\n-    fn sleep(&mut self, msecs: u64) {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            do scheduler.deschedule_running_task_and_then |_sched, task| {\n-                uvdebug!(\"sleep: entered scheduler context\");\n-                let task_cell = Cell::new(task);\n-                do self_.watcher.start(msecs, 0) |_, status| {\n-                    assert!(status.is_none());\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-            self_.watcher.stop();\n-        }\n-    }\n-\n-    fn oneshot(&mut self, msecs: u64) -> PortOne<()> {\n-        use std::comm::oneshot;\n-\n-        let (port, chan) = oneshot();\n-        let chan = Cell::new(chan);\n-        do self.home_for_io |self_| {\n-            let chan = Cell::new(chan.take());\n-            do self_.watcher.start(msecs, 0) |_, status| {\n-                assert!(status.is_none());\n-                assert!(!chan.is_empty());\n-                chan.take().send_deferred(());\n-            }\n-        }\n-\n-        return port;\n-    }\n-\n-    fn period(&mut self, msecs: u64) -> Port<()> {\n-        use std::comm::stream;\n-\n-        let (port, chan) = stream();\n-        let chan = Cell::new(chan);\n-        do self.home_for_io |self_| {\n-            let chan = Cell::new(chan.take());\n-            do self_.watcher.start(msecs, msecs) |_, status| {\n-                assert!(status.is_none());\n-                do chan.with_ref |chan| {\n-                    chan.send_deferred(());\n-                }\n-            }\n-        }\n-\n-        return port;\n-    }\n-}\n-\n-pub struct UvFileStream {\n-    priv loop_: Loop,\n-    priv fd: c_int,\n-    priv close: CloseBehavior,\n-    priv home: SchedHandle,\n-}\n-\n-impl HomingIO for UvFileStream {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl UvFileStream {\n-    fn new(loop_: Loop, fd: c_int, close: CloseBehavior,\n-           home: SchedHandle) -> UvFileStream {\n-        UvFileStream {\n-            loop_: loop_,\n-            fd: fd,\n-            close: close,\n-            home: home,\n-        }\n-    }\n-    fn base_read(&mut self, buf: &mut [u8], offset: i64) -> Result<int, IoError> {\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<int, IoError>> = &result_cell;\n-        let buf_ptr: *&mut [u8] = &buf;\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let buf = unsafe { slice_to_uv_buf(*buf_ptr) };\n-                let task_cell = Cell::new(task);\n-                let read_req = file::FsRequest::new();\n-                do read_req.read(&self_.loop_, self_.fd, buf, offset) |req, uverr| {\n-                    let res = match uverr  {\n-                        None => Ok(req.get_result() as int),\n-                        Some(err) => Err(uv_error_to_io_error(err))\n-                    };\n-                    unsafe { (*result_cell_ptr).put_back(res); }\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-        }\n-        result_cell.take()\n-    }\n-    fn base_write(&mut self, buf: &[u8], offset: i64) -> Result<(), IoError> {\n-        do self.nop_req |self_, req, cb| {\n-            req.write(&self_.loop_, self_.fd, slice_to_uv_buf(buf), offset, cb)\n-        }\n-    }\n-    fn seek_common(&mut self, pos: i64, whence: c_int) ->\n-        Result<u64, IoError>{\n-        #[fixed_stack_segment]; #[inline(never)];\n-        unsafe {\n-            match lseek(self.fd, pos as off_t, whence) {\n-                -1 => {\n-                    Err(IoError {\n-                        kind: OtherIoError,\n-                        desc: \"Failed to lseek.\",\n-                        detail: None\n-                    })\n-                },\n-                n => Ok(n as u64)\n-            }\n-        }\n-    }\n-    fn nop_req(&mut self, f: &fn(&mut UvFileStream, file::FsRequest, FsCallback))\n-            -> Result<(), IoError> {\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<(), IoError>> = &result_cell;\n-        do self.home_for_io_with_sched |self_, sched| {\n-            do sched.deschedule_running_task_and_then |_, task| {\n-                let task = Cell::new(task);\n-                let req = file::FsRequest::new();\n-                do f(self_, req) |_, uverr| {\n-                    let res = match uverr  {\n-                        None => Ok(()),\n-                        Some(err) => Err(uv_error_to_io_error(err))\n-                    };\n-                    unsafe { (*result_cell_ptr).put_back(res); }\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task.take());\n-                }\n-            }\n-        }\n-        result_cell.take()\n-    }\n-}\n-\n-impl Drop for UvFileStream {\n-    fn drop(&mut self) {\n-        match self.close {\n-            DontClose => {}\n-            CloseAsynchronously => {\n-                let close_req = file::FsRequest::new();\n-                do close_req.close(&self.loop_, self.fd) |_,_| {}\n-            }\n-            CloseSynchronously => {\n-                do self.home_for_io_with_sched |self_, scheduler| {\n-                    do scheduler.deschedule_running_task_and_then |_, task| {\n-                        let task_cell = Cell::new(task);\n-                        let close_req = file::FsRequest::new();\n-                        do close_req.close(&self_.loop_, self_.fd) |_,_| {\n-                            let scheduler: ~Scheduler = Local::take();\n-                            scheduler.resume_blocked_task_immediately(task_cell.take());\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-impl RtioFileStream for UvFileStream {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<int, IoError> {\n-        self.base_read(buf, -1)\n-    }\n-    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n-        self.base_write(buf, -1)\n-    }\n-    fn pread(&mut self, buf: &mut [u8], offset: u64) -> Result<int, IoError> {\n-        self.base_read(buf, offset as i64)\n-    }\n-    fn pwrite(&mut self, buf: &[u8], offset: u64) -> Result<(), IoError> {\n-        self.base_write(buf, offset as i64)\n-    }\n-    fn seek(&mut self, pos: i64, whence: SeekStyle) -> Result<u64, IoError> {\n-        use std::libc::{SEEK_SET, SEEK_CUR, SEEK_END};\n-        let whence = match whence {\n-            SeekSet => SEEK_SET,\n-            SeekCur => SEEK_CUR,\n-            SeekEnd => SEEK_END\n-        };\n-        self.seek_common(pos, whence)\n-    }\n-    fn tell(&self) -> Result<u64, IoError> {\n-        use std::libc::SEEK_CUR;\n-        // this is temporary\n-        let self_ = unsafe { cast::transmute::<&UvFileStream, &mut UvFileStream>(self) };\n-        self_.seek_common(0, SEEK_CUR)\n-    }\n-    fn fsync(&mut self) -> Result<(), IoError> {\n-        do self.nop_req |self_, req, cb| {\n-            req.fsync(&self_.loop_, self_.fd, cb)\n-        }\n-    }\n-    fn datasync(&mut self) -> Result<(), IoError> {\n-        do self.nop_req |self_, req, cb| {\n-            req.datasync(&self_.loop_, self_.fd, cb)\n-        }\n-    }\n-    fn truncate(&mut self, offset: i64) -> Result<(), IoError> {\n-        do self.nop_req |self_, req, cb| {\n-            req.truncate(&self_.loop_, self_.fd, offset, cb)\n-        }\n-    }\n-}\n-\n-pub struct UvProcess {\n-    priv process: process::Process,\n-\n-    // Sadly, this structure must be created before we return it, so in that\n-    // brief interim the `home` is None.\n-    priv home: Option<SchedHandle>,\n-\n-    // All None until the process exits (exit_error may stay None)\n-    priv exit_status: Option<int>,\n-    priv term_signal: Option<int>,\n-    priv exit_error: Option<UvError>,\n-\n-    // Used to store which task to wake up from the exit_cb\n-    priv descheduled: Option<BlockedTask>,\n-}\n-\n-impl HomingIO for UvProcess {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { self.home.get_mut_ref() }\n-}\n-\n-impl Drop for UvProcess {\n-    fn drop(&mut self) {\n-        let close = |self_: &mut UvProcess| {\n-            let scheduler: ~Scheduler = Local::take();\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task = Cell::new(task);\n-                do self_.process.close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task.take());\n-                }\n-            }\n-        };\n-\n-        // If home is none, then this process never actually successfully\n-        // spawned, so there's no need to switch event loops\n-        if self.home.is_none() {\n-            close(self)\n-        } else {\n-            self.home_for_io(close)\n-        }\n-    }\n-}\n-\n-impl RtioProcess for UvProcess {\n-    fn id(&self) -> pid_t {\n-        self.process.pid()\n-    }\n-\n-    fn kill(&mut self, signal: int) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            match self_.process.kill(signal) {\n-                Ok(()) => Ok(()),\n-                Err(uverr) => Err(uv_error_to_io_error(uverr))\n-            }\n-        }\n-    }\n-\n-    fn wait(&mut self) -> int {\n-        // Make sure (on the home scheduler) that we have an exit status listed\n-        do self.home_for_io |self_| {\n-            match self_.exit_status {\n-                Some(*) => {}\n-                None => {\n-                    // If there's no exit code previously listed, then the\n-                    // process's exit callback has yet to be invoked. We just\n-                    // need to deschedule ourselves and wait to be reawoken.\n-                    let scheduler: ~Scheduler = Local::take();\n-                    do scheduler.deschedule_running_task_and_then |_, task| {\n-                        assert!(self_.descheduled.is_none());\n-                        self_.descheduled = Some(task);\n-                    }\n-                    assert!(self_.exit_status.is_some());\n-                }\n-            }\n-        }\n-\n-        self.exit_status.unwrap()\n-    }\n-}\n-\n-pub struct UvUnixListener {\n-    priv inner: UvUnboundPipe\n-}\n-\n-impl HomingIO for UvUnixListener {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { self.inner.home() }\n-}\n-\n-impl UvUnixListener {\n-    fn new(pipe: UvUnboundPipe) -> UvUnixListener {\n-        UvUnixListener { inner: pipe }\n-    }\n-}\n-\n-impl RtioUnixListener for UvUnixListener {\n-    fn listen(~self) -> Result<~RtioUnixAcceptor, IoError> {\n-        do self.home_for_io_consume |self_| {\n-            let acceptor = ~UvUnixAcceptor::new(self_);\n-            let incoming = Cell::new(acceptor.incoming.clone());\n-            let mut stream = acceptor.listener.inner.pipe.as_stream();\n-            let res = do stream.listen |mut server, status| {\n-                do incoming.with_mut_ref |incoming| {\n-                    let inc = match status {\n-                        Some(e) => Err(uv_error_to_io_error(e)),\n-                        None => {\n-                            let pipe = UvUnboundPipe::new(&server.event_loop());\n-                            server.accept(pipe.pipe.as_stream());\n-                            Ok(~UvPipeStream::new(pipe) as ~RtioPipe)\n-                        }\n-                    };\n-                    incoming.send(inc);\n-                }\n-            };\n-            match res {\n-                Ok(()) => Ok(acceptor as ~RtioUnixAcceptor),\n-                Err(e) => Err(uv_error_to_io_error(e)),\n-            }\n-        }\n-    }\n-}\n-\n-pub struct UvTTY {\n-    tty: tty::TTY,\n-    home: SchedHandle,\n-    fd: c_int,\n-}\n-\n-impl HomingIO for UvTTY {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl Drop for UvTTY {\n-    fn drop(&mut self) {\n-        // TTY handles are used for the logger in a task, so this destructor is\n-        // run when a task is destroyed. When a task is being destroyed, a local\n-        // scheduler isn't available, so we can't do the normal \"take the\n-        // scheduler and resume once close is done\". Instead close operations on\n-        // a TTY are asynchronous.\n-        self.tty.close_async();\n-    }\n-}\n-\n-impl RtioTTY for UvTTY {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            read_stream(self_.tty.as_stream(), scheduler, buf)\n-        }\n-    }\n-\n-    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            write_stream(self_.tty.as_stream(), scheduler, buf)\n-        }\n-    }\n-\n-    fn set_raw(&mut self, raw: bool) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            match self_.tty.set_mode(raw) {\n-                Ok(p) => Ok(p), Err(e) => Err(uv_error_to_io_error(e))\n-            }\n-        }\n-    }\n-\n-    fn get_winsize(&mut self) -> Result<(int, int), IoError> {\n-        do self.home_for_io |self_| {\n-            match self_.tty.get_winsize() {\n-                Ok(p) => Ok(p), Err(e) => Err(uv_error_to_io_error(e))\n-            }\n-        }\n-    }\n-\n-    fn isatty(&self) -> bool {\n-        unsafe { uvll::guess_handle(self.fd) == uvll::UV_TTY as c_int }\n-    }\n-}\n-\n-pub struct UvUnixAcceptor {\n-    listener: UvUnixListener,\n-    incoming: Tube<Result<~RtioPipe, IoError>>,\n-}\n-\n-impl HomingIO for UvUnixAcceptor {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { self.listener.home() }\n-}\n-\n-impl UvUnixAcceptor {\n-    fn new(listener: UvUnixListener) -> UvUnixAcceptor {\n-        UvUnixAcceptor { listener: listener, incoming: Tube::new() }\n-    }\n-}\n-\n-impl RtioUnixAcceptor for UvUnixAcceptor {\n-    fn accept(&mut self) -> Result<~RtioPipe, IoError> {\n-        do self.home_for_io |self_| {\n-            self_.incoming.recv()\n-        }\n-    }\n-\n-    fn accept_simultaneously(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            accept_simultaneously(self_.listener.inner.pipe.as_stream(), 1)\n-        }\n-    }\n-\n-    fn dont_accept_simultaneously(&mut self) -> Result<(), IoError> {\n-        do self.home_for_io |self_| {\n-            accept_simultaneously(self_.listener.inner.pipe.as_stream(), 0)\n-        }\n-    }\n-}\n-\n-pub struct UvSignal {\n-    watcher: signal::SignalWatcher,\n-    home: SchedHandle,\n-}\n-\n-impl HomingIO for UvSignal {\n-    fn home<'r>(&'r mut self) -> &'r mut SchedHandle { &mut self.home }\n-}\n-\n-impl UvSignal {\n-    fn new(w: signal::SignalWatcher, home: SchedHandle) -> UvSignal {\n-        UvSignal { watcher: w, home: home }\n-    }\n-}\n-\n-impl RtioSignal for UvSignal {}\n-\n-impl Drop for UvSignal {\n-    fn drop(&mut self) {\n-        do self.home_for_io_with_sched |self_, scheduler| {\n-            uvdebug!(\"closing UvSignal\");\n-            do scheduler.deschedule_running_task_and_then |_, task| {\n-                let task_cell = Cell::new(task);\n-                do self_.watcher.close {\n-                    let scheduler: ~Scheduler = Local::take();\n-                    scheduler.resume_blocked_task_immediately(task_cell.take());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-// this function is full of lies\n-unsafe fn local_io() -> &'static mut IoFactory {\n-    do Local::borrow |sched: &mut Scheduler| {\n-        let mut io = None;\n-        sched.event_loop.io(|i| io = Some(i));\n-        cast::transmute(io.unwrap())\n-    }\n-}\n-\n-#[test]\n-fn test_simple_io_no_connect() {\n-    do run_in_mt_newsched_task {\n-        unsafe {\n-            let io = local_io();\n-            let addr = next_test_ip4();\n-            let maybe_chan = io.tcp_connect(addr);\n-            assert!(maybe_chan.is_err());\n-        }\n-    }\n-}\n-\n-#[test]\n-fn test_simple_udp_io_bind_only() {\n-    do run_in_mt_newsched_task {\n-        unsafe {\n-            let io = local_io();\n-            let addr = next_test_ip4();\n-            let maybe_socket = io.udp_bind(addr);\n-            assert!(maybe_socket.is_ok());\n-        }\n-    }\n-}\n-\n-#[test]\n-fn test_simple_homed_udp_io_bind_then_move_task_then_home_and_close() {\n-    use std::rt::sleeper_list::SleeperList;\n-    use std::rt::work_queue::WorkQueue;\n-    use std::rt::thread::Thread;\n-    use std::rt::task::Task;\n-    use std::rt::sched::{Shutdown, TaskFromFriend};\n-    use std::rt::task::UnwindResult;\n-    do run_in_bare_thread {\n-        let sleepers = SleeperList::new();\n-        let work_queue1 = WorkQueue::new();\n-        let work_queue2 = WorkQueue::new();\n-        let queues = ~[work_queue1.clone(), work_queue2.clone()];\n-\n-        let loop1 = ~UvEventLoop::new() as ~EventLoop;\n-        let mut sched1 = ~Scheduler::new(loop1, work_queue1, queues.clone(),\n-                                         sleepers.clone());\n-        let loop2 = ~UvEventLoop::new() as ~EventLoop;\n-        let mut sched2 = ~Scheduler::new(loop2, work_queue2, queues.clone(),\n-                                         sleepers.clone());\n-\n-        let handle1 = Cell::new(sched1.make_handle());\n-        let handle2 = Cell::new(sched2.make_handle());\n-        let tasksFriendHandle = Cell::new(sched2.make_handle());\n-\n-        let on_exit: ~fn(UnwindResult) = |exit_status| {\n-            handle1.take().send(Shutdown);\n-            handle2.take().send(Shutdown);\n-            assert!(exit_status.is_success());\n-        };\n-\n-        let test_function: ~fn() = || {\n-            let io = unsafe { local_io() };\n-            let addr = next_test_ip4();\n-            let maybe_socket = io.udp_bind(addr);\n-            // this socket is bound to this event loop\n-            assert!(maybe_socket.is_ok());\n-\n-            // block self on sched1\n-            do task::unkillable { // FIXME(#8674)\n-                let scheduler: ~Scheduler = Local::take();\n-                do scheduler.deschedule_running_task_and_then |_, task| {\n-                    // unblock task\n-                    do task.wake().map |task| {\n-                      // send self to sched2\n-                      tasksFriendHandle.take().send(TaskFromFriend(task));\n-                    };\n-                    // sched1 should now sleep since it has nothing else to do\n-                }\n-            }\n-            // sched2 will wake up and get the task\n-            // as we do nothing else, the function ends and the socket goes out of scope\n-            // sched2 will start to run the destructor\n-            // the destructor will first block the task, set it's home as sched1, then enqueue it\n-            // sched2 will dequeue the task, see that it has a home, and send it to sched1\n-            // sched1 will wake up, exec the close function on the correct loop, and then we're done\n-        };\n-\n-        let mut main_task = ~Task::new_root(&mut sched1.stack_pool, None, test_function);\n-        main_task.death.on_exit = Some(on_exit);\n-        let main_task = Cell::new(main_task);\n-\n-        let null_task = Cell::new(~do Task::new_root(&mut sched2.stack_pool, None) || {});\n-\n-        let sched1 = Cell::new(sched1);\n-        let sched2 = Cell::new(sched2);\n-\n-        let thread1 = do Thread::start {\n-            sched1.take().bootstrap(main_task.take());\n-        };\n-        let thread2 = do Thread::start {\n-            sched2.take().bootstrap(null_task.take());\n-        };\n-\n-        thread1.join();\n-        thread2.join();\n-    }\n-}\n-\n-#[test]\n-fn test_simple_homed_udp_io_bind_then_move_handle_then_home_and_close() {\n-    use std::rt::sleeper_list::SleeperList;\n-    use std::rt::work_queue::WorkQueue;\n-    use std::rt::thread::Thread;\n-    use std::rt::task::Task;\n-    use std::rt::comm::oneshot;\n-    use std::rt::sched::Shutdown;\n-    use std::rt::task::UnwindResult;\n-    do run_in_bare_thread {\n-        let sleepers = SleeperList::new();\n-        let work_queue1 = WorkQueue::new();\n-        let work_queue2 = WorkQueue::new();\n-        let queues = ~[work_queue1.clone(), work_queue2.clone()];\n-\n-        let loop1 = ~UvEventLoop::new() as ~EventLoop;\n-        let mut sched1 = ~Scheduler::new(loop1, work_queue1, queues.clone(),\n-                                         sleepers.clone());\n-        let loop2 = ~UvEventLoop::new() as ~EventLoop;\n-        let mut sched2 = ~Scheduler::new(loop2, work_queue2, queues.clone(),\n-                                         sleepers.clone());\n-\n-        let handle1 = Cell::new(sched1.make_handle());\n-        let handle2 = Cell::new(sched2.make_handle());\n-\n-        let (port, chan) = oneshot();\n-        let port = Cell::new(port);\n-        let chan = Cell::new(chan);\n-\n-        let body1: ~fn() = || {\n-            let io = unsafe { local_io() };\n-            let addr = next_test_ip4();\n-            let socket = io.udp_bind(addr);\n-            assert!(socket.is_ok());\n-            chan.take().send(socket);\n-        };\n-\n-        let body2: ~fn() = || {\n-            let socket = port.take().recv();\n-            assert!(socket.is_ok());\n-            /* The socket goes out of scope and the destructor is called.\n-             * The destructor:\n-             *  - sends itself back to sched1\n-             *  - frees the socket\n-             *  - resets the home of the task to whatever it was previously\n-             */\n-        };\n-\n-        let on_exit: ~fn(UnwindResult) = |exit| {\n-            handle1.take().send(Shutdown);\n-            handle2.take().send(Shutdown);\n-            assert!(exit.is_success());\n-        };\n-\n-        let task1 = Cell::new(~Task::new_root(&mut sched1.stack_pool, None, body1));\n-\n-        let mut task2 = ~Task::new_root(&mut sched2.stack_pool, None, body2);\n-        task2.death.on_exit = Some(on_exit);\n-        let task2 = Cell::new(task2);\n-\n-        let sched1 = Cell::new(sched1);\n-        let sched2 = Cell::new(sched2);\n-\n-        let thread1 = do Thread::start {\n-            sched1.take().bootstrap(task1.take());\n-        };\n-        let thread2 = do Thread::start {\n-            sched2.take().bootstrap(task2.take());\n-        };\n-\n-        thread1.join();\n-        thread2.join();\n-    }\n-}\n-\n-#[test]\n-fn test_simple_tcp_server_and_client() {\n-    do run_in_mt_newsched_task {\n-        let addr = next_test_ip4();\n-        let (port, chan) = oneshot();\n-        let port = Cell::new(port);\n-        let chan = Cell::new(chan);\n-\n-        // Start the server first so it's listening when we connect\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let listener = io.tcp_bind(addr).unwrap();\n-                let mut acceptor = listener.listen().unwrap();\n-                chan.take().send(());\n-                let mut stream = acceptor.accept().unwrap();\n-                let mut buf = [0, .. 2048];\n-                let nread = stream.read(buf).unwrap();\n-                assert_eq!(nread, 8);\n-                for i in range(0u, nread) {\n-                    uvdebug!(\"{}\", buf[i]);\n-                    assert_eq!(buf[i], i as u8);\n-                }\n-            }\n-        }\n-\n-        do spawntask {\n-            unsafe {\n-                port.take().recv();\n-                let io = local_io();\n-                let mut stream = io.tcp_connect(addr).unwrap();\n-                stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-            }\n-        }\n-    }\n-}\n-\n-#[test]\n-fn test_simple_tcp_server_and_client_on_diff_threads() {\n-    use std::rt::sleeper_list::SleeperList;\n-    use std::rt::work_queue::WorkQueue;\n-    use std::rt::thread::Thread;\n-    use std::rt::task::Task;\n-    use std::rt::sched::{Shutdown};\n-    use std::rt::task::UnwindResult;\n-    do run_in_bare_thread {\n-        let sleepers = SleeperList::new();\n-\n-        let server_addr = next_test_ip4();\n-        let client_addr = server_addr.clone();\n-\n-        let server_work_queue = WorkQueue::new();\n-        let client_work_queue = WorkQueue::new();\n-        let queues = ~[server_work_queue.clone(), client_work_queue.clone()];\n-\n-        let sloop = ~UvEventLoop::new() as ~EventLoop;\n-        let mut server_sched = ~Scheduler::new(sloop, server_work_queue,\n-                                               queues.clone(), sleepers.clone());\n-        let cloop = ~UvEventLoop::new() as ~EventLoop;\n-        let mut client_sched = ~Scheduler::new(cloop, client_work_queue,\n-                                               queues.clone(), sleepers.clone());\n-\n-        let server_handle = Cell::new(server_sched.make_handle());\n-        let client_handle = Cell::new(client_sched.make_handle());\n-\n-        let server_on_exit: ~fn(UnwindResult) = |exit_status| {\n-            server_handle.take().send(Shutdown);\n-            assert!(exit_status.is_success());\n-        };\n-\n-        let client_on_exit: ~fn(UnwindResult) = |exit_status| {\n-            client_handle.take().send(Shutdown);\n-            assert!(exit_status.is_success());\n-        };\n-\n-        let server_fn: ~fn() = || {\n-            let io = unsafe { local_io() };\n-            let listener = io.tcp_bind(server_addr).unwrap();\n-            let mut acceptor = listener.listen().unwrap();\n-            let mut stream = acceptor.accept().unwrap();\n-            let mut buf = [0, .. 2048];\n-            let nread = stream.read(buf).unwrap();\n-            assert_eq!(nread, 8);\n-            for i in range(0u, nread) {\n-                assert_eq!(buf[i], i as u8);\n-            }\n-        };\n-\n-        let client_fn: ~fn() = || {\n-            let io = unsafe { local_io() };\n-            let mut stream = io.tcp_connect(client_addr);\n-            while stream.is_err() {\n-                stream = io.tcp_connect(client_addr);\n-            }\n-            stream.unwrap().write([0, 1, 2, 3, 4, 5, 6, 7]);\n-        };\n-\n-        let mut server_task = ~Task::new_root(&mut server_sched.stack_pool, None, server_fn);\n-        server_task.death.on_exit = Some(server_on_exit);\n-        let server_task = Cell::new(server_task);\n-\n-        let mut client_task = ~Task::new_root(&mut client_sched.stack_pool, None, client_fn);\n-        client_task.death.on_exit = Some(client_on_exit);\n-        let client_task = Cell::new(client_task);\n-\n-        let server_sched = Cell::new(server_sched);\n-        let client_sched = Cell::new(client_sched);\n-\n-        let server_thread = do Thread::start {\n-            server_sched.take().bootstrap(server_task.take());\n-        };\n-        let client_thread = do Thread::start {\n-            client_sched.take().bootstrap(client_task.take());\n-        };\n-\n-        server_thread.join();\n-        client_thread.join();\n-    }\n-}\n-\n-#[test]\n-fn test_simple_udp_server_and_client() {\n-    do run_in_mt_newsched_task {\n-        let server_addr = next_test_ip4();\n-        let client_addr = next_test_ip4();\n-        let (port, chan) = oneshot();\n-        let port = Cell::new(port);\n-        let chan = Cell::new(chan);\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let mut server_socket = io.udp_bind(server_addr).unwrap();\n-                chan.take().send(());\n-                let mut buf = [0, .. 2048];\n-                let (nread,src) = server_socket.recvfrom(buf).unwrap();\n-                assert_eq!(nread, 8);\n-                for i in range(0u, nread) {\n-                    uvdebug!(\"{}\", buf[i]);\n-                    assert_eq!(buf[i], i as u8);\n-                }\n-                assert_eq!(src, client_addr);\n-            }\n-        }\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let mut client_socket = io.udp_bind(client_addr).unwrap();\n-                port.take().recv();\n-                client_socket.sendto([0, 1, 2, 3, 4, 5, 6, 7], server_addr);\n-            }\n-        }\n-    }\n-}\n-\n-#[test] #[ignore(reason = \"busted\")]\n-fn test_read_and_block() {\n-    do run_in_mt_newsched_task {\n-        let addr = next_test_ip4();\n-        let (port, chan) = oneshot();\n-        let port = Cell::new(port);\n-        let chan = Cell::new(chan);\n-\n-        do spawntask {\n-            let io = unsafe { local_io() };\n-            let listener = io.tcp_bind(addr).unwrap();\n-            let mut acceptor = listener.listen().unwrap();\n-            chan.take().send(());\n-            let mut stream = acceptor.accept().unwrap();\n-            let mut buf = [0, .. 2048];\n-\n-            let expected = 32;\n-            let mut current = 0;\n-            let mut reads = 0;\n-\n-            while current < expected {\n-                let nread = stream.read(buf).unwrap();\n-                for i in range(0u, nread) {\n-                    let val = buf[i] as uint;\n-                    assert_eq!(val, current % 8);\n-                    current += 1;\n-                }\n-                reads += 1;\n-\n-                do task::unkillable { // FIXME(#8674)\n-                    let scheduler: ~Scheduler = Local::take();\n-                    // Yield to the other task in hopes that it\n-                    // will trigger a read callback while we are\n-                    // not ready for it\n-                    do scheduler.deschedule_running_task_and_then |sched, task| {\n-                        let task = Cell::new(task);\n-                        sched.enqueue_blocked_task(task.take());\n-                    }\n-                }\n-            }\n-\n-            // Make sure we had multiple reads\n-            assert!(reads > 1);\n-        }\n-\n-        do spawntask {\n-            unsafe {\n-                port.take().recv();\n-                let io = local_io();\n-                let mut stream = io.tcp_connect(addr).unwrap();\n-                stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-                stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-                stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-                stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-            }\n-        }\n-\n-    }\n-}\n-\n-#[test]\n-fn test_read_read_read() {\n-    do run_in_mt_newsched_task {\n-        let addr = next_test_ip4();\n-        static MAX: uint = 500000;\n-        let (port, chan) = oneshot();\n-        let port = Cell::new(port);\n-        let chan = Cell::new(chan);\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let listener = io.tcp_bind(addr).unwrap();\n-                let mut acceptor = listener.listen().unwrap();\n-                chan.take().send(());\n-                let mut stream = acceptor.accept().unwrap();\n-                let buf = [1, .. 2048];\n-                let mut total_bytes_written = 0;\n-                while total_bytes_written < MAX {\n-                    stream.write(buf);\n-                    total_bytes_written += buf.len();\n-                }\n-            }\n-        }\n-\n-        do spawntask {\n-            unsafe {\n-                port.take().recv();\n-                let io = local_io();\n-                let mut stream = io.tcp_connect(addr).unwrap();\n-                let mut buf = [0, .. 2048];\n-                let mut total_bytes_read = 0;\n-                while total_bytes_read < MAX {\n-                    let nread = stream.read(buf).unwrap();\n-                    uvdebug!(\"read {} bytes\", nread);\n-                    total_bytes_read += nread;\n-                    for i in range(0u, nread) {\n-                        assert_eq!(buf[i], 1);\n-                    }\n-                }\n-                uvdebug!(\"read {} bytes total\", total_bytes_read);\n-            }\n-        }\n-    }\n-}\n-\n-#[test]\n-#[ignore(cfg(windows))] // FIXME(#10102) the server never sees the second send\n-fn test_udp_twice() {\n-    do run_in_mt_newsched_task {\n-        let server_addr = next_test_ip4();\n-        let client_addr = next_test_ip4();\n-        let (port, chan) = oneshot();\n-        let port = Cell::new(port);\n-        let chan = Cell::new(chan);\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let mut client = io.udp_bind(client_addr).unwrap();\n-                port.take().recv();\n-                assert!(client.sendto([1], server_addr).is_ok());\n-                assert!(client.sendto([2], server_addr).is_ok());\n-            }\n-        }\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let mut server = io.udp_bind(server_addr).unwrap();\n-                chan.take().send(());\n-                let mut buf1 = [0];\n-                let mut buf2 = [0];\n-                let (nread1, src1) = server.recvfrom(buf1).unwrap();\n-                let (nread2, src2) = server.recvfrom(buf2).unwrap();\n-                assert_eq!(nread1, 1);\n-                assert_eq!(nread2, 1);\n-                assert_eq!(src1, client_addr);\n-                assert_eq!(src2, client_addr);\n-                assert_eq!(buf1[0], 1);\n-                assert_eq!(buf2[0], 2);\n-            }\n-        }\n-    }\n-}\n-\n-#[test]\n-fn test_udp_many_read() {\n-    do run_in_mt_newsched_task {\n-        let server_out_addr = next_test_ip4();\n-        let server_in_addr = next_test_ip4();\n-        let client_out_addr = next_test_ip4();\n-        let client_in_addr = next_test_ip4();\n-        static MAX: uint = 500_000;\n-\n-        let (p1, c1) = oneshot();\n-        let (p2, c2) = oneshot();\n-\n-        let first = Cell::new((p1, c2));\n-        let second = Cell::new((p2, c1));\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let mut server_out = io.udp_bind(server_out_addr).unwrap();\n-                let mut server_in = io.udp_bind(server_in_addr).unwrap();\n-                let (port, chan) = first.take();\n-                chan.send(());\n-                port.recv();\n-                let msg = [1, .. 2048];\n-                let mut total_bytes_sent = 0;\n-                let mut buf = [1];\n-                while buf[0] == 1 {\n-                    // send more data\n-                    assert!(server_out.sendto(msg, client_in_addr).is_ok());\n-                    total_bytes_sent += msg.len();\n-                    // check if the client has received enough\n-                    let res = server_in.recvfrom(buf);\n-                    assert!(res.is_ok());\n-                    let (nread, src) = res.unwrap();\n-                    assert_eq!(nread, 1);\n-                    assert_eq!(src, client_out_addr);\n-                }\n-                assert!(total_bytes_sent >= MAX);\n-            }\n-        }\n-\n-        do spawntask {\n-            unsafe {\n-                let io = local_io();\n-                let mut client_out = io.udp_bind(client_out_addr).unwrap();\n-                let mut client_in = io.udp_bind(client_in_addr).unwrap();\n-                let (port, chan) = second.take();\n-                port.recv();\n-                chan.send(());\n-                let mut total_bytes_recv = 0;\n-                let mut buf = [0, .. 2048];\n-                while total_bytes_recv < MAX {\n-                    // ask for more\n-                    assert!(client_out.sendto([1], server_in_addr).is_ok());\n-                    // wait for data\n-                    let res = client_in.recvfrom(buf);\n-                    assert!(res.is_ok());\n-                    let (nread, src) = res.unwrap();\n-                    assert_eq!(src, server_out_addr);\n-                    total_bytes_recv += nread;\n-                    for i in range(0u, nread) {\n-                        assert_eq!(buf[i], 1);\n-                    }\n-                }\n-                // tell the server we're done\n-                assert!(client_out.sendto([0], server_in_addr).is_ok());\n-            }\n-        }\n-    }\n-}\n-\n-#[test]\n-fn test_timer_sleep_simple() {\n-    do run_in_mt_newsched_task {\n-        unsafe {\n-            let io = local_io();\n-            let timer = io.timer_init();\n-            do timer.map |mut t| { t.sleep(1) };\n-        }\n-    }\n-}\n-\n-fn file_test_uvio_full_simple_impl() {\n-    use std::rt::io::{Open, ReadWrite, Read};\n-    unsafe {\n-        let io = local_io();\n-        let write_val = \"hello uvio!\";\n-        let path = \"./tmp/file_test_uvio_full.txt\";\n-        {\n-            let create_fm = Open;\n-            let create_fa = ReadWrite;\n-            let mut fd = io.fs_open(&path.to_c_str(), create_fm, create_fa).unwrap();\n-            let write_buf = write_val.as_bytes();\n-            fd.write(write_buf);\n-        }\n-        {\n-            let ro_fm = Open;\n-            let ro_fa = Read;\n-            let mut fd = io.fs_open(&path.to_c_str(), ro_fm, ro_fa).unwrap();\n-            let mut read_vec = [0, .. 1028];\n-            let nread = fd.read(read_vec).unwrap();\n-            let read_val = str::from_utf8(read_vec.slice(0, nread as uint));\n-            assert!(read_val == write_val.to_owned());\n-        }\n-        io.fs_unlink(&path.to_c_str());\n-    }\n-}\n-\n-#[test]\n-fn file_test_uvio_full_simple() {\n-    do run_in_mt_newsched_task {\n-        file_test_uvio_full_simple_impl();\n-    }\n-}\n-\n-fn uvio_naive_print(input: &str) {\n-    unsafe {\n-        use std::libc::{STDOUT_FILENO};\n-        let io = local_io();\n-        {\n-            let mut fd = io.fs_from_raw_fd(STDOUT_FILENO, DontClose);\n-            let write_buf = input.as_bytes();\n-            fd.write(write_buf);\n-        }\n-    }\n-}\n-\n-#[test]\n-fn file_test_uvio_write_to_stdout() {\n-    do run_in_mt_newsched_task {\n-        uvio_naive_print(\"jubilation\\n\");\n-    }\n-}"}, {"sha": "c76d03bfe6c33a6985ef182f9b020646b7c1c2ff", "filename": "src/librustuv/uvll.rs", "status": "modified", "additions": 228, "deletions": 683, "changes": 911, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fuvll.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibrustuv%2Fuvll.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fuvll.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -29,11 +29,10 @@\n \n #[allow(non_camel_case_types)]; // C types\n \n-use std::libc::{size_t, c_int, c_uint, c_void, c_char, uintptr_t};\n+use std::libc::{size_t, c_int, c_uint, c_void, c_char, uintptr_t, c_double};\n use std::libc::ssize_t;\n use std::libc::{malloc, free};\n use std::libc;\n-use std::ptr;\n use std::vec;\n \n pub use self::errors::*;\n@@ -48,12 +47,14 @@ pub static UNKNOWN: c_int = -4094;\n pub mod errors {\n     use std::libc::c_int;\n \n-    pub static EACCES: c_int = -4093;\n-    pub static ECONNREFUSED: c_int = -4079;\n-    pub static ECONNRESET: c_int = -4078;\n-    pub static ENOTCONN: c_int = -4054;\n-    pub static EPIPE: c_int = -4048;\n-    pub static ECONNABORTED: c_int = -4080;\n+    pub static EACCES: c_int = -4092;\n+    pub static ECONNREFUSED: c_int = -4078;\n+    pub static ECONNRESET: c_int = -4077;\n+    pub static ENOTCONN: c_int = -4053;\n+    pub static EPIPE: c_int = -4047;\n+    pub static ECONNABORTED: c_int = -4079;\n+    pub static ECANCELED: c_int = -4081;\n+    pub static EBADF: c_int = -4083;\n }\n #[cfg(not(windows))]\n pub mod errors {\n@@ -66,6 +67,8 @@ pub mod errors {\n     pub static ENOTCONN: c_int = -libc::ENOTCONN;\n     pub static EPIPE: c_int = -libc::EPIPE;\n     pub static ECONNABORTED: c_int = -libc::ECONNABORTED;\n+    pub static ECANCELED : c_int = -libc::ECANCELED;\n+    pub static EBADF : c_int = -libc::EBADF;\n }\n \n pub static PROCESS_SETUID: c_int = 1 << 0;\n@@ -81,20 +84,32 @@ pub static STDIO_INHERIT_STREAM: c_int = 0x04;\n pub static STDIO_READABLE_PIPE: c_int = 0x10;\n pub static STDIO_WRITABLE_PIPE: c_int = 0x20;\n \n+#[cfg(unix)]\n+pub type uv_buf_len_t = libc::size_t;\n+#[cfg(windows)]\n+pub type uv_buf_len_t = libc::c_ulong;\n+\n // see libuv/include/uv-unix.h\n #[cfg(unix)]\n pub struct uv_buf_t {\n     base: *u8,\n-    len: libc::size_t,\n+    len: uv_buf_len_t,\n }\n \n // see libuv/include/uv-win.h\n #[cfg(windows)]\n pub struct uv_buf_t {\n-    len: u32,\n+    len: uv_buf_len_t,\n     base: *u8,\n }\n \n+#[repr(C)]\n+pub enum uv_run_mode {\n+    RUN_DEFAULT = 0,\n+    RUN_ONCE,\n+    RUN_NOWAIT,\n+}\n+\n pub struct uv_process_options_t {\n     exit_cb: uv_exit_cb,\n     file: *libc::c_char,\n@@ -116,6 +131,7 @@ pub struct uv_stdio_container_t {\n }\n \n pub type uv_handle_t = c_void;\n+pub type uv_req_t = c_void;\n pub type uv_loop_t = c_void;\n pub type uv_idle_t = c_void;\n pub type uv_tcp_t = c_void;\n@@ -190,15 +206,16 @@ impl uv_stat_t {\n pub type uv_idle_cb = extern \"C\" fn(handle: *uv_idle_t,\n                                     status: c_int);\n pub type uv_alloc_cb = extern \"C\" fn(stream: *uv_stream_t,\n-                                     suggested_size: size_t) -> uv_buf_t;\n+                                     suggested_size: size_t,\n+                                     buf: *mut uv_buf_t);\n pub type uv_read_cb = extern \"C\" fn(stream: *uv_stream_t,\n                                     nread: ssize_t,\n-                                    buf: uv_buf_t);\n+                                    buf: *uv_buf_t);\n pub type uv_udp_send_cb = extern \"C\" fn(req: *uv_udp_send_t,\n                                         status: c_int);\n pub type uv_udp_recv_cb = extern \"C\" fn(handle: *uv_udp_t,\n                                         nread: ssize_t,\n-                                        buf: uv_buf_t,\n+                                        buf: *uv_buf_t,\n                                         addr: *sockaddr,\n                                         flags: c_uint);\n pub type uv_close_cb = extern \"C\" fn(handle: *uv_handle_t);\n@@ -218,16 +235,13 @@ pub type uv_getaddrinfo_cb = extern \"C\" fn(req: *uv_getaddrinfo_t,\n                                            status: c_int,\n                                            res: *addrinfo);\n pub type uv_exit_cb = extern \"C\" fn(handle: *uv_process_t,\n-                                    exit_status: c_int,\n+                                    exit_status: i64,\n                                     term_signal: c_int);\n pub type uv_signal_cb = extern \"C\" fn(handle: *uv_signal_t,\n                                       signum: c_int);\n pub type uv_fs_cb = extern \"C\" fn(req: *uv_fs_t);\n \n pub type sockaddr = c_void;\n-pub type sockaddr_in = c_void;\n-pub type sockaddr_in6 = c_void;\n-pub type sockaddr_storage = c_void;\n \n #[cfg(unix)]\n pub type socklen_t = c_int;\n@@ -276,6 +290,7 @@ pub struct addrinfo {\n #[cfg(windows)] pub type uv_uid_t = libc::c_uchar;\n #[cfg(windows)] pub type uv_gid_t = libc::c_uchar;\n \n+#[repr(C)]\n #[deriving(Eq)]\n pub enum uv_handle_type {\n     UV_UNKNOWN_HANDLE,\n@@ -299,6 +314,7 @@ pub enum uv_handle_type {\n     UV_HANDLE_TYPE_MAX\n }\n \n+#[repr(C)]\n #[cfg(unix)]\n #[deriving(Eq)]\n pub enum uv_req_type {\n@@ -316,6 +332,7 @@ pub enum uv_req_type {\n \n // uv_req_type may have additional fields defined by UV_REQ_TYPE_PRIVATE.\n // See UV_REQ_TYPE_PRIVATE at libuv/include/uv-win.h\n+#[repr(C)]\n #[cfg(windows)]\n #[deriving(Eq)]\n pub enum uv_req_type {\n@@ -339,6 +356,7 @@ pub enum uv_req_type {\n     UV_REQ_TYPE_MAX\n }\n \n+#[repr(C)]\n #[deriving(Eq)]\n pub enum uv_membership {\n     UV_LEAVE_GROUP,\n@@ -349,7 +367,7 @@ pub unsafe fn malloc_handle(handle: uv_handle_type) -> *c_void {\n     #[fixed_stack_segment]; #[inline(never)];\n \n     assert!(handle != UV_UNKNOWN_HANDLE && handle != UV_HANDLE_TYPE_MAX);\n-    let size = rust_uv_handle_size(handle as uint);\n+    let size = uv_handle_size(handle);\n     let p = malloc(size);\n     assert!(p.is_not_null());\n     return p;\n@@ -365,7 +383,7 @@ pub unsafe fn malloc_req(req: uv_req_type) -> *c_void {\n     #[fixed_stack_segment]; #[inline(never)];\n \n     assert!(req != UV_UNKNOWN_REQ && req != UV_REQ_TYPE_MAX);\n-    let size = rust_uv_req_size(req as uint);\n+    let size = uv_req_size(req);\n     let p = malloc(size);\n     assert!(p.is_not_null());\n     return p;\n@@ -400,452 +418,23 @@ pub unsafe fn loop_new() -> *c_void {\n     return rust_uv_loop_new();\n }\n \n-pub unsafe fn loop_delete(loop_handle: *c_void) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_loop_delete(loop_handle);\n-}\n-\n-pub unsafe fn run(loop_handle: *c_void) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_run(loop_handle);\n-}\n-\n-pub unsafe fn close<T>(handle: *T, cb: uv_close_cb) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_close(handle as *c_void, cb);\n-}\n-\n-pub unsafe fn walk(loop_handle: *c_void, cb: uv_walk_cb, arg: *c_void) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_walk(loop_handle, cb, arg);\n-}\n-\n-pub unsafe fn idle_init(loop_handle: *uv_loop_t, handle: *uv_idle_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_idle_init(loop_handle, handle)\n-}\n-\n-pub unsafe fn idle_start(handle: *uv_idle_t, cb: uv_idle_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_idle_start(handle, cb)\n-}\n-\n-pub unsafe fn idle_stop(handle: *uv_idle_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_idle_stop(handle)\n-}\n-\n-pub unsafe fn udp_init(loop_handle: *uv_loop_t, handle: *uv_udp_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_init(loop_handle, handle);\n-}\n-\n-pub unsafe fn udp_bind(server: *uv_udp_t, addr: *sockaddr_in, flags: c_uint) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_bind(server, addr, flags);\n-}\n-\n-pub unsafe fn udp_bind6(server: *uv_udp_t, addr: *sockaddr_in6, flags: c_uint) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_bind6(server, addr, flags);\n-}\n-\n-pub unsafe fn udp_send<T>(req: *uv_udp_send_t, handle: *T, buf_in: &[uv_buf_t],\n-                          addr: *sockaddr_in, cb: uv_udp_send_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    let buf_ptr = vec::raw::to_ptr(buf_in);\n-    let buf_cnt = buf_in.len() as i32;\n-    return rust_uv_udp_send(req, handle as *c_void, buf_ptr, buf_cnt, addr, cb);\n-}\n-\n-pub unsafe fn udp_send6<T>(req: *uv_udp_send_t, handle: *T, buf_in: &[uv_buf_t],\n-                          addr: *sockaddr_in6, cb: uv_udp_send_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    let buf_ptr = vec::raw::to_ptr(buf_in);\n-    let buf_cnt = buf_in.len() as i32;\n-    return rust_uv_udp_send6(req, handle as *c_void, buf_ptr, buf_cnt, addr, cb);\n-}\n-\n-pub unsafe fn udp_recv_start(server: *uv_udp_t, on_alloc: uv_alloc_cb,\n-                             on_recv: uv_udp_recv_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_recv_start(server, on_alloc, on_recv);\n-}\n-\n-pub unsafe fn udp_recv_stop(server: *uv_udp_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_recv_stop(server);\n-}\n-\n pub unsafe fn get_udp_handle_from_send_req(send_req: *uv_udp_send_t) -> *uv_udp_t {\n     #[fixed_stack_segment]; #[inline(never)];\n \n     return rust_uv_get_udp_handle_from_send_req(send_req);\n }\n \n-pub unsafe fn udp_getsockname(handle: *uv_udp_t, name: *sockaddr_storage) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_getsockname(handle, name);\n-}\n-\n-pub unsafe fn udp_set_membership(handle: *uv_udp_t, multicast_addr: *c_char,\n-                                 interface_addr: *c_char, membership: uv_membership) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_set_membership(handle, multicast_addr, interface_addr, membership as c_int);\n-}\n-\n-pub unsafe fn udp_set_multicast_loop(handle: *uv_udp_t, on: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_set_multicast_loop(handle, on);\n-}\n-\n-pub unsafe fn udp_set_multicast_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_set_multicast_ttl(handle, ttl);\n-}\n-\n-pub unsafe fn udp_set_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_set_ttl(handle, ttl);\n-}\n-\n-pub unsafe fn udp_set_broadcast(handle: *uv_udp_t, on: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_udp_set_broadcast(handle, on);\n-}\n-\n-pub unsafe fn tcp_init(loop_handle: *c_void, handle: *uv_tcp_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_init(loop_handle, handle);\n-}\n-\n-pub unsafe fn tcp_connect(connect_ptr: *uv_connect_t, tcp_handle_ptr: *uv_tcp_t,\n-                          addr_ptr: *sockaddr_in, after_connect_cb: uv_connect_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_connect(connect_ptr, tcp_handle_ptr, after_connect_cb, addr_ptr);\n-}\n-\n-pub unsafe fn tcp_connect6(connect_ptr: *uv_connect_t, tcp_handle_ptr: *uv_tcp_t,\n-                           addr_ptr: *sockaddr_in6, after_connect_cb: uv_connect_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_connect6(connect_ptr, tcp_handle_ptr, after_connect_cb, addr_ptr);\n-}\n-\n-pub unsafe fn tcp_bind(tcp_server_ptr: *uv_tcp_t, addr_ptr: *sockaddr_in) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_bind(tcp_server_ptr, addr_ptr);\n-}\n-\n-pub unsafe fn tcp_bind6(tcp_server_ptr: *uv_tcp_t, addr_ptr: *sockaddr_in6) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_bind6(tcp_server_ptr, addr_ptr);\n-}\n-\n-pub unsafe fn tcp_getpeername(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_storage) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_getpeername(tcp_handle_ptr, name);\n-}\n-\n-pub unsafe fn tcp_getsockname(handle: *uv_tcp_t, name: *sockaddr_storage) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_getsockname(handle, name);\n-}\n-\n-pub unsafe fn tcp_nodelay(handle: *uv_tcp_t, enable: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_nodelay(handle, enable);\n-}\n-\n-pub unsafe fn tcp_keepalive(handle: *uv_tcp_t, enable: c_int, delay: c_uint) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_keepalive(handle, enable, delay);\n-}\n-\n-pub unsafe fn tcp_simultaneous_accepts(handle: *uv_tcp_t, enable: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_tcp_simultaneous_accepts(handle, enable);\n-}\n-\n-pub unsafe fn listen<T>(stream: *T, backlog: c_int,\n-                        cb: uv_connection_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_listen(stream as *c_void, backlog, cb);\n-}\n-\n-pub unsafe fn accept(server: *c_void, client: *c_void) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_accept(server as *c_void, client as *c_void);\n-}\n-\n-pub unsafe fn write<T>(req: *uv_write_t,\n-                       stream: *T,\n+pub unsafe fn uv_write(req: *uv_write_t,\n+                       stream: *uv_stream_t,\n                        buf_in: &[uv_buf_t],\n                        cb: uv_write_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n+    externfn!(fn uv_write(req: *uv_write_t, stream: *uv_stream_t,\n+                          buf_in: *uv_buf_t, buf_cnt: c_int,\n+                          cb: uv_write_cb) -> c_int)\n \n     let buf_ptr = vec::raw::to_ptr(buf_in);\n     let buf_cnt = buf_in.len() as i32;\n-    return rust_uv_write(req as *c_void, stream as *c_void, buf_ptr, buf_cnt, cb);\n-}\n-pub unsafe fn read_start(stream: *uv_stream_t,\n-                         on_alloc: uv_alloc_cb,\n-                         on_read: uv_read_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_read_start(stream as *c_void, on_alloc, on_read);\n-}\n-\n-pub unsafe fn read_stop(stream: *uv_stream_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_read_stop(stream as *c_void);\n-}\n-\n-pub unsafe fn strerror(err: c_int) -> *c_char {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_strerror(err);\n-}\n-pub unsafe fn err_name(err: c_int) -> *c_char {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_err_name(err);\n-}\n-\n-pub unsafe fn async_init(loop_handle: *c_void,\n-                         async_handle: *uv_async_t,\n-                         cb: uv_async_cb) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_async_init(loop_handle, async_handle, cb);\n-}\n-\n-pub unsafe fn async_send(async_handle: *uv_async_t) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_async_send(async_handle);\n-}\n-pub unsafe fn buf_init(input: *u8, len: uint) -> uv_buf_t {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    let out_buf = uv_buf_t { base: ptr::null(), len: 0 as size_t };\n-    let out_buf_ptr = ptr::to_unsafe_ptr(&out_buf);\n-    rust_uv_buf_init(out_buf_ptr, input, len as size_t);\n-    return out_buf;\n-}\n-\n-pub unsafe fn timer_init(loop_ptr: *c_void, timer_ptr: *uv_timer_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_timer_init(loop_ptr, timer_ptr);\n-}\n-pub unsafe fn timer_start(timer_ptr: *uv_timer_t,\n-                          cb: uv_timer_cb, timeout: u64,\n-                          repeat: u64) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_timer_start(timer_ptr, cb, timeout, repeat);\n-}\n-pub unsafe fn timer_stop(timer_ptr: *uv_timer_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_timer_stop(timer_ptr);\n-}\n-\n-pub unsafe fn is_ip4_addr(addr: *sockaddr) -> bool {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    match rust_uv_is_ipv4_sockaddr(addr) { 0 => false, _ => true }\n-}\n-\n-pub unsafe fn is_ip6_addr(addr: *sockaddr) -> bool {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    match rust_uv_is_ipv6_sockaddr(addr) { 0 => false, _ => true }\n-}\n-\n-pub unsafe fn malloc_ip4_addr(ip: &str, port: int) -> *sockaddr_in {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    do ip.with_c_str |ip_buf| {\n-        rust_uv_ip4_addrp(ip_buf as *u8, port as libc::c_int)\n-    }\n-}\n-pub unsafe fn malloc_ip6_addr(ip: &str, port: int) -> *sockaddr_in6 {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    do ip.with_c_str |ip_buf| {\n-        rust_uv_ip6_addrp(ip_buf as *u8, port as libc::c_int)\n-    }\n-}\n-\n-pub unsafe fn malloc_sockaddr_storage() -> *sockaddr_storage {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_malloc_sockaddr_storage()\n-}\n-\n-pub unsafe fn free_sockaddr_storage(ss: *sockaddr_storage) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_free_sockaddr_storage(ss);\n-}\n-\n-pub unsafe fn free_ip4_addr(addr: *sockaddr_in) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_free_ip4_addr(addr);\n-}\n-\n-pub unsafe fn free_ip6_addr(addr: *sockaddr_in6) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_free_ip6_addr(addr);\n-}\n-\n-pub unsafe fn ip4_name(addr: *sockaddr_in, dst: *u8, size: size_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_ip4_name(addr, dst, size);\n-}\n-\n-pub unsafe fn ip6_name(addr: *sockaddr_in6, dst: *u8, size: size_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_ip6_name(addr, dst, size);\n-}\n-\n-pub unsafe fn ip4_port(addr: *sockaddr_in) -> c_uint {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-   return rust_uv_ip4_port(addr);\n-}\n-\n-pub unsafe fn ip6_port(addr: *sockaddr_in6) -> c_uint {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_ip6_port(addr);\n-}\n-\n-pub unsafe fn fs_open(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char, flags: int, mode: int,\n-                cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_open(loop_ptr, req, path, flags as c_int, mode as c_int, cb)\n-}\n-\n-pub unsafe fn fs_unlink(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n-                cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_unlink(loop_ptr, req, path, cb)\n-}\n-pub unsafe fn fs_write(loop_ptr: *uv_loop_t, req: *uv_fs_t, fd: c_int, buf: *c_void,\n-                       len: uint, offset: i64, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_write(loop_ptr, req, fd, buf, len as c_uint, offset, cb)\n-}\n-pub unsafe fn fs_read(loop_ptr: *uv_loop_t, req: *uv_fs_t, fd: c_int, buf: *c_void,\n-                       len: uint, offset: i64, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_read(loop_ptr, req, fd, buf, len as c_uint, offset, cb)\n-}\n-pub unsafe fn fs_close(loop_ptr: *uv_loop_t, req: *uv_fs_t, fd: c_int,\n-                cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_close(loop_ptr, req, fd, cb)\n-}\n-pub unsafe fn fs_stat(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_stat(loop_ptr, req, path, cb)\n-}\n-pub unsafe fn fs_fstat(loop_ptr: *uv_loop_t, req: *uv_fs_t, fd: c_int, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_fstat(loop_ptr, req, fd, cb)\n-}\n-pub unsafe fn fs_mkdir(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n-                       mode: c_int, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_mkdir(loop_ptr, req, path, mode as c_int, cb)\n-}\n-pub unsafe fn fs_rmdir(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n-                cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_rmdir(loop_ptr, req, path, cb)\n-}\n-pub unsafe fn fs_rename(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n-                        to: *c_char, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_rename(loop_ptr, req, path, to, cb)\n-}\n-pub unsafe fn fs_chmod(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n-                       mode: c_int, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_chmod(loop_ptr, req, path, mode as c_int, cb)\n-}\n-pub unsafe fn fs_readdir(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n-                flags: c_int, cb: *u8) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_readdir(loop_ptr, req, path, flags, cb)\n-}\n-pub unsafe fn populate_stat(req_in: *uv_fs_t, stat_out: *uv_stat_t) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_populate_uv_stat(req_in, stat_out)\n-}\n-pub unsafe fn fs_req_cleanup(req: *uv_fs_t) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    rust_uv_fs_req_cleanup(req);\n-}\n-\n-pub unsafe fn spawn(loop_ptr: *c_void, result: *uv_process_t,\n-                    options: uv_process_options_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_spawn(loop_ptr, result, options);\n-}\n-\n-pub unsafe fn process_kill(p: *uv_process_t, signum: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_process_kill(p, signum);\n+    return uv_write(req, stream, buf_ptr, buf_cnt, cb);\n }\n \n pub unsafe fn process_pid(p: *uv_process_t) -> c_int {\n@@ -871,11 +460,6 @@ pub unsafe fn set_stdio_container_stream(c: *uv_stdio_container_t,\n     rust_set_stdio_container_stream(c, stream);\n }\n \n-pub unsafe fn pipe_init(loop_ptr: *c_void, p: *uv_pipe_t, ipc: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_pipe_init(loop_ptr, p, ipc)\n-}\n-\n // data access helpers\n pub unsafe fn get_result_from_fs_req(req: *uv_fs_t) -> c_int {\n     #[fixed_stack_segment]; #[inline(never)];\n@@ -947,273 +531,234 @@ pub unsafe fn set_data_for_req<T, U>(req: *T, data: *U) {\n \n     rust_uv_set_data_for_req(req as *c_void, data as *c_void);\n }\n-pub unsafe fn get_base_from_buf(buf: uv_buf_t) -> *u8 {\n-    #[fixed_stack_segment]; #[inline(never)];\n-\n-    return rust_uv_get_base_from_buf(buf);\n-}\n-pub unsafe fn get_len_from_buf(buf: uv_buf_t) -> size_t {\n+pub unsafe fn populate_stat(req_in: *uv_fs_t, stat_out: *uv_stat_t) {\n     #[fixed_stack_segment]; #[inline(never)];\n \n-    return rust_uv_get_len_from_buf(buf);\n-}\n-pub unsafe fn getaddrinfo(loop_: *uv_loop_t, req: *uv_getaddrinfo_t,\n-               getaddrinfo_cb: uv_getaddrinfo_cb,\n-               node: *c_char, service: *c_char,\n-               hints: *addrinfo) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_getaddrinfo(loop_, req, getaddrinfo_cb, node, service, hints);\n-}\n-pub unsafe fn freeaddrinfo(ai: *addrinfo) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_freeaddrinfo(ai);\n-}\n-pub unsafe fn pipe_open(pipe: *uv_pipe_t, file: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_pipe_open(pipe, file)\n-}\n-pub unsafe fn pipe_bind(pipe: *uv_pipe_t, name: *c_char) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_pipe_bind(pipe, name)\n-}\n-pub unsafe fn pipe_connect(req: *uv_connect_t, handle: *uv_pipe_t,\n-                           name: *c_char, cb: uv_connect_cb) {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_pipe_connect(req, handle, name, cb)\n-}\n-pub unsafe fn tty_init(loop_ptr: *uv_loop_t, tty: *uv_tty_t, fd: c_int,\n-                       readable: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_tty_init(loop_ptr, tty, fd, readable)\n-}\n-pub unsafe fn tty_set_mode(tty: *uv_tty_t, mode: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_tty_set_mode(tty, mode)\n-}\n-pub unsafe fn tty_get_winsize(tty: *uv_tty_t, width: *c_int,\n-                              height: *c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_tty_get_winsize(tty, width, height)\n+    rust_uv_populate_uv_stat(req_in, stat_out)\n }\n-// FIXME(#9613) this should return uv_handle_type, not a c_int\n-pub unsafe fn guess_handle(fd: c_int) -> c_int {\n+pub unsafe fn guess_handle(handle: c_int) -> c_int {\n     #[fixed_stack_segment]; #[inline(never)];\n-    rust_uv_guess_handle(fd)\n-}\n \n-pub unsafe fn signal_init(loop_: *uv_loop_t, handle: *uv_signal_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_signal_init(loop_, handle);\n-}\n-pub unsafe fn signal_start(handle: *uv_signal_t,\n-                           signal_cb: uv_signal_cb,\n-                           signum: c_int) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_signal_start(handle, signal_cb, signum);\n-}\n-pub unsafe fn signal_stop(handle: *uv_signal_t) -> c_int {\n-    #[fixed_stack_segment]; #[inline(never)];\n-    return rust_uv_signal_stop(handle);\n+    rust_uv_guess_handle(handle)\n }\n \n-pub struct uv_err_data {\n-    err_name: ~str,\n-    err_msg: ~str,\n-}\n \n // uv_support is the result of compiling rust_uv.cpp\n+//\n+// Note that this is in a cfg'd block so it doesn't get linked during testing.\n+// There's a bit of a conundrum when testing in that we're actually assuming\n+// that the tests are running in a uv loop, but they were created from the\n+// statically linked uv to the original rustuv crate. When we create the test\n+// executable, on some platforms if we re-link against uv, it actually creates\n+// second copies of everything. We obviously don't want this, so instead of\n+// dying horribly during testing, we allow all of the test rustuv's references\n+// to get resolved to the original rustuv crate.\n #[link_args = \"-luv_support -luv\"]\n+#[cfg(not(test))]\n+extern {}\n+\n extern {\n+    fn rust_uv_loop_new() -> *c_void;\n+\n+    // dealing with sockaddr things\n+    pub fn rust_sockaddr_size() -> c_int;\n+    pub fn rust_malloc_ip4_addr(s: *c_char, port: c_int) -> *sockaddr;\n+    pub fn rust_malloc_ip6_addr(s: *c_char, port: c_int) -> *sockaddr;\n+    pub fn rust_ip4_port(src: *sockaddr) -> c_uint;\n+    pub fn rust_ip6_port(src: *sockaddr) -> c_uint;\n+    pub fn rust_is_ipv4_sockaddr(addr: *sockaddr) -> c_int;\n+    pub fn rust_is_ipv6_sockaddr(addr: *sockaddr) -> c_int;\n \n-    fn rust_uv_handle_size(type_: uintptr_t) -> size_t;\n-    fn rust_uv_req_size(type_: uintptr_t) -> size_t;\n     fn rust_uv_handle_type_max() -> uintptr_t;\n     fn rust_uv_req_type_max() -> uintptr_t;\n-\n-    // libuv public API\n-    fn rust_uv_loop_new() -> *c_void;\n-    fn rust_uv_loop_delete(lp: *c_void);\n-    fn rust_uv_run(loop_handle: *c_void);\n-    fn rust_uv_close(handle: *c_void, cb: uv_close_cb);\n-    fn rust_uv_walk(loop_handle: *c_void, cb: uv_walk_cb, arg: *c_void);\n-\n-    fn rust_uv_idle_init(loop_handle: *uv_loop_t, handle: *uv_idle_t) -> c_int;\n-    fn rust_uv_idle_start(handle: *uv_idle_t, cb: uv_idle_cb) -> c_int;\n-    fn rust_uv_idle_stop(handle: *uv_idle_t) -> c_int;\n-\n-    fn rust_uv_async_send(handle: *uv_async_t);\n-    fn rust_uv_async_init(loop_handle: *c_void,\n-                          async_handle: *uv_async_t,\n-                          cb: uv_async_cb) -> c_int;\n-    fn rust_uv_tcp_init(loop_handle: *c_void, handle_ptr: *uv_tcp_t) -> c_int;\n-    fn rust_uv_buf_init(out_buf: *uv_buf_t, base: *u8, len: size_t);\n-    fn rust_uv_strerror(err: c_int) -> *c_char;\n-    fn rust_uv_err_name(err: c_int) -> *c_char;\n-    fn rust_uv_ip4_addrp(ip: *u8, port: c_int) -> *sockaddr_in;\n-    fn rust_uv_ip6_addrp(ip: *u8, port: c_int) -> *sockaddr_in6;\n-    fn rust_uv_free_ip4_addr(addr: *sockaddr_in);\n-    fn rust_uv_free_ip6_addr(addr: *sockaddr_in6);\n-    fn rust_uv_ip4_name(src: *sockaddr_in, dst: *u8, size: size_t) -> c_int;\n-    fn rust_uv_ip6_name(src: *sockaddr_in6, dst: *u8, size: size_t) -> c_int;\n-    fn rust_uv_ip4_port(src: *sockaddr_in) -> c_uint;\n-    fn rust_uv_ip6_port(src: *sockaddr_in6) -> c_uint;\n-    fn rust_uv_tcp_connect(req: *uv_connect_t, handle: *uv_tcp_t,\n-                           cb: uv_connect_cb,\n-                           addr: *sockaddr_in) -> c_int;\n-    fn rust_uv_tcp_bind(tcp_server: *uv_tcp_t, addr: *sockaddr_in) -> c_int;\n-    fn rust_uv_tcp_connect6(req: *uv_connect_t, handle: *uv_tcp_t,\n-                            cb: uv_connect_cb,\n-                            addr: *sockaddr_in6) -> c_int;\n-    fn rust_uv_tcp_bind6(tcp_server: *uv_tcp_t, addr: *sockaddr_in6) -> c_int;\n-    fn rust_uv_tcp_getpeername(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_storage) -> c_int;\n-    fn rust_uv_tcp_getsockname(handle: *uv_tcp_t, name: *sockaddr_storage) -> c_int;\n-    fn rust_uv_tcp_nodelay(handle: *uv_tcp_t, enable: c_int) -> c_int;\n-    fn rust_uv_tcp_keepalive(handle: *uv_tcp_t, enable: c_int, delay: c_uint) -> c_int;\n-    fn rust_uv_tcp_simultaneous_accepts(handle: *uv_tcp_t, enable: c_int) -> c_int;\n-\n-    fn rust_uv_udp_init(loop_handle: *uv_loop_t, handle_ptr: *uv_udp_t) -> c_int;\n-    fn rust_uv_udp_bind(server: *uv_udp_t, addr: *sockaddr_in, flags: c_uint) -> c_int;\n-    fn rust_uv_udp_bind6(server: *uv_udp_t, addr: *sockaddr_in6, flags: c_uint) -> c_int;\n-    fn rust_uv_udp_send(req: *uv_udp_send_t, handle: *uv_udp_t, buf_in: *uv_buf_t,\n-                        buf_cnt: c_int, addr: *sockaddr_in, cb: uv_udp_send_cb) -> c_int;\n-    fn rust_uv_udp_send6(req: *uv_udp_send_t, handle: *uv_udp_t, buf_in: *uv_buf_t,\n-                         buf_cnt: c_int, addr: *sockaddr_in6, cb: uv_udp_send_cb) -> c_int;\n-    fn rust_uv_udp_recv_start(server: *uv_udp_t,\n-                              on_alloc: uv_alloc_cb,\n-                              on_recv: uv_udp_recv_cb) -> c_int;\n-    fn rust_uv_udp_recv_stop(server: *uv_udp_t) -> c_int;\n     fn rust_uv_get_udp_handle_from_send_req(req: *uv_udp_send_t) -> *uv_udp_t;\n-    fn rust_uv_udp_getsockname(handle: *uv_udp_t, name: *sockaddr_storage) -> c_int;\n-    fn rust_uv_udp_set_membership(handle: *uv_udp_t, multicast_addr: *c_char,\n-                                  interface_addr: *c_char, membership: c_int) -> c_int;\n-    fn rust_uv_udp_set_multicast_loop(handle: *uv_udp_t, on: c_int) -> c_int;\n-    fn rust_uv_udp_set_multicast_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int;\n-    fn rust_uv_udp_set_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int;\n-    fn rust_uv_udp_set_broadcast(handle: *uv_udp_t, on: c_int) -> c_int;\n-\n-    fn rust_uv_is_ipv4_sockaddr(addr: *sockaddr) -> c_int;\n-    fn rust_uv_is_ipv6_sockaddr(addr: *sockaddr) -> c_int;\n-    fn rust_uv_malloc_sockaddr_storage() -> *sockaddr_storage;\n-    fn rust_uv_free_sockaddr_storage(ss: *sockaddr_storage);\n-\n-    fn rust_uv_listen(stream: *c_void, backlog: c_int,\n-                      cb: uv_connection_cb) -> c_int;\n-    fn rust_uv_accept(server: *c_void, client: *c_void) -> c_int;\n-    fn rust_uv_write(req: *c_void, stream: *c_void, buf_in: *uv_buf_t, buf_cnt: c_int,\n-                     cb: uv_write_cb) -> c_int;\n-    fn rust_uv_read_start(stream: *c_void,\n-                          on_alloc: uv_alloc_cb,\n-                          on_read: uv_read_cb) -> c_int;\n-    fn rust_uv_read_stop(stream: *c_void) -> c_int;\n-    fn rust_uv_timer_init(loop_handle: *c_void, timer_handle: *uv_timer_t) -> c_int;\n-    fn rust_uv_timer_start(timer_handle: *uv_timer_t, cb: uv_timer_cb, timeout: libc::uint64_t,\n-                           repeat: libc::uint64_t) -> c_int;\n-    fn rust_uv_timer_stop(handle: *uv_timer_t) -> c_int;\n-    fn rust_uv_fs_open(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                       flags: c_int, mode: c_int, cb: *u8) -> c_int;\n-    fn rust_uv_fs_unlink(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                       cb: *u8) -> c_int;\n-    fn rust_uv_fs_write(loop_ptr: *c_void, req: *uv_fs_t, fd: c_int,\n-                       buf: *c_void, len: c_uint, offset: i64, cb: *u8) -> c_int;\n-    fn rust_uv_fs_read(loop_ptr: *c_void, req: *uv_fs_t, fd: c_int,\n-                       buf: *c_void, len: c_uint, offset: i64, cb: *u8) -> c_int;\n-    fn rust_uv_fs_close(loop_ptr: *c_void, req: *uv_fs_t, fd: c_int,\n-                        cb: *u8) -> c_int;\n-    fn rust_uv_fs_stat(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char, cb: *u8) -> c_int;\n-    fn rust_uv_fs_fstat(loop_ptr: *c_void, req: *uv_fs_t, fd: c_int, cb: *u8) -> c_int;\n-    fn rust_uv_fs_mkdir(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                        mode: c_int, cb: *u8) -> c_int;\n-    fn rust_uv_fs_rmdir(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                        cb: *u8) -> c_int;\n-    fn rust_uv_fs_rename(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                         to: *c_char, cb: *u8) -> c_int;\n-    fn rust_uv_fs_chmod(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                        mode: c_int, cb: *u8) -> c_int;\n-    fn rust_uv_fs_readdir(loop_ptr: *c_void, req: *uv_fs_t, path: *c_char,\n-                        flags: c_int, cb: *u8) -> c_int;\n-    fn rust_uv_fs_req_cleanup(req: *uv_fs_t);\n+\n     fn rust_uv_populate_uv_stat(req_in: *uv_fs_t, stat_out: *uv_stat_t);\n     fn rust_uv_get_result_from_fs_req(req: *uv_fs_t) -> c_int;\n     fn rust_uv_get_ptr_from_fs_req(req: *uv_fs_t) -> *libc::c_void;\n     fn rust_uv_get_path_from_fs_req(req: *uv_fs_t) -> *c_char;\n     fn rust_uv_get_loop_from_fs_req(req: *uv_fs_t) -> *uv_loop_t;\n     fn rust_uv_get_loop_from_getaddrinfo_req(req: *uv_fs_t) -> *uv_loop_t;\n-\n-    fn rust_uv_get_stream_handle_from_connect_req(connect_req: *uv_connect_t) -> *uv_stream_t;\n-    fn rust_uv_get_stream_handle_from_write_req(write_req: *uv_write_t) -> *uv_stream_t;\n+    fn rust_uv_get_stream_handle_from_connect_req(req: *uv_connect_t) -> *uv_stream_t;\n+    fn rust_uv_get_stream_handle_from_write_req(req: *uv_write_t) -> *uv_stream_t;\n     fn rust_uv_get_loop_for_uv_handle(handle: *c_void) -> *c_void;\n     fn rust_uv_get_data_for_uv_loop(loop_ptr: *c_void) -> *c_void;\n     fn rust_uv_set_data_for_uv_loop(loop_ptr: *c_void, data: *c_void);\n     fn rust_uv_get_data_for_uv_handle(handle: *c_void) -> *c_void;\n     fn rust_uv_set_data_for_uv_handle(handle: *c_void, data: *c_void);\n     fn rust_uv_get_data_for_req(req: *c_void) -> *c_void;\n     fn rust_uv_set_data_for_req(req: *c_void, data: *c_void);\n-    fn rust_uv_get_base_from_buf(buf: uv_buf_t) -> *u8;\n-    fn rust_uv_get_len_from_buf(buf: uv_buf_t) -> size_t;\n-    fn rust_uv_getaddrinfo(loop_: *uv_loop_t, req: *uv_getaddrinfo_t,\n-                           getaddrinfo_cb: uv_getaddrinfo_cb,\n-                           node: *c_char, service: *c_char,\n-                           hints: *addrinfo) -> c_int;\n-    fn rust_uv_freeaddrinfo(ai: *addrinfo);\n-    fn rust_uv_spawn(loop_ptr: *c_void, outptr: *uv_process_t,\n-                     options: uv_process_options_t) -> c_int;\n-    fn rust_uv_process_kill(p: *uv_process_t, signum: c_int) -> c_int;\n-    fn rust_uv_process_pid(p: *uv_process_t) -> c_int;\n     fn rust_set_stdio_container_flags(c: *uv_stdio_container_t, flags: c_int);\n     fn rust_set_stdio_container_fd(c: *uv_stdio_container_t, fd: c_int);\n     fn rust_set_stdio_container_stream(c: *uv_stdio_container_t,\n                                        stream: *uv_stream_t);\n-    fn rust_uv_pipe_init(loop_ptr: *c_void, p: *uv_pipe_t, ipc: c_int) -> c_int;\n-\n-    fn rust_uv_pipe_open(pipe: *uv_pipe_t, file: c_int) -> c_int;\n-    fn rust_uv_pipe_bind(pipe: *uv_pipe_t, name: *c_char) -> c_int;\n-    fn rust_uv_pipe_connect(req: *uv_connect_t, handle: *uv_pipe_t,\n-                            name: *c_char, cb: uv_connect_cb);\n-    fn rust_uv_tty_init(loop_ptr: *uv_loop_t, tty: *uv_tty_t, fd: c_int,\n-                        readable: c_int) -> c_int;\n-    fn rust_uv_tty_set_mode(tty: *uv_tty_t, mode: c_int) -> c_int;\n-    fn rust_uv_tty_get_winsize(tty: *uv_tty_t, width: *c_int,\n-                               height: *c_int) -> c_int;\n+    fn rust_uv_process_pid(p: *uv_process_t) -> c_int;\n     fn rust_uv_guess_handle(fd: c_int) -> c_int;\n+}\n \n-    // XXX: see comments in addrinfo.rs\n-    // These should all really be constants...\n-    //#[rust_stack] pub fn rust_SOCK_STREAM() -> c_int;\n-    //#[rust_stack] pub fn rust_SOCK_DGRAM() -> c_int;\n-    //#[rust_stack] pub fn rust_SOCK_RAW() -> c_int;\n-    //#[rust_stack] pub fn rust_IPPROTO_UDP() -> c_int;\n-    //#[rust_stack] pub fn rust_IPPROTO_TCP() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_ADDRCONFIG() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_ALL() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_CANONNAME() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_NUMERICHOST() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_NUMERICSERV() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_PASSIVE() -> c_int;\n-    //#[rust_stack] pub fn rust_AI_V4MAPPED() -> c_int;\n-\n-    fn rust_uv_signal_init(loop_: *uv_loop_t, handle: *uv_signal_t) -> c_int;\n-    fn rust_uv_signal_start(handle: *uv_signal_t,\n-                            signal_cb: uv_signal_cb,\n-                            signum: c_int) -> c_int;\n-    fn rust_uv_signal_stop(handle: *uv_signal_t) -> c_int;\n+// generic uv functions\n+externfn!(fn uv_loop_delete(l: *uv_loop_t))\n+externfn!(fn uv_handle_size(ty: uv_handle_type) -> size_t)\n+externfn!(fn uv_req_size(ty: uv_req_type) -> size_t)\n+externfn!(fn uv_run(l: *uv_loop_t, mode: uv_run_mode) -> c_int)\n+externfn!(fn uv_close(h: *uv_handle_t, cb: uv_close_cb))\n+externfn!(fn uv_walk(l: *uv_loop_t, cb: uv_walk_cb, arg: *c_void))\n+externfn!(fn uv_buf_init(base: *c_char, len: c_uint) -> uv_buf_t)\n+externfn!(fn uv_strerror(err: c_int) -> *c_char)\n+externfn!(fn uv_err_name(err: c_int) -> *c_char)\n+externfn!(fn uv_listen(s: *uv_stream_t, backlog: c_int,\n+                       cb: uv_connection_cb) -> c_int)\n+externfn!(fn uv_accept(server: *uv_stream_t, client: *uv_stream_t) -> c_int)\n+externfn!(fn uv_read_start(stream: *uv_stream_t,\n+                           on_alloc: uv_alloc_cb,\n+                           on_read: uv_read_cb) -> c_int)\n+externfn!(fn uv_read_stop(stream: *uv_stream_t) -> c_int)\n+\n+// idle bindings\n+externfn!(fn uv_idle_init(l: *uv_loop_t, i: *uv_idle_t) -> c_int)\n+externfn!(fn uv_idle_start(i: *uv_idle_t, cb: uv_idle_cb) -> c_int)\n+externfn!(fn uv_idle_stop(i: *uv_idle_t) -> c_int)\n+\n+// async bindings\n+externfn!(fn uv_async_init(l: *uv_loop_t, a: *uv_async_t,\n+                           cb: uv_async_cb) -> c_int)\n+externfn!(fn uv_async_send(a: *uv_async_t))\n+\n+// tcp bindings\n+externfn!(fn uv_tcp_init(l: *uv_loop_t, h: *uv_tcp_t) -> c_int)\n+externfn!(fn uv_tcp_connect(c: *uv_connect_t, h: *uv_tcp_t,\n+                            addr: *sockaddr, cb: uv_connect_cb) -> c_int)\n+externfn!(fn uv_tcp_bind(t: *uv_tcp_t, addr: *sockaddr) -> c_int)\n+externfn!(fn uv_ip4_name(src: *sockaddr, dst: *c_char,\n+                         size: size_t) -> c_int)\n+externfn!(fn uv_ip6_name(src: *sockaddr, dst: *c_char,\n+                         size: size_t) -> c_int)\n+externfn!(fn uv_tcp_nodelay(h: *uv_tcp_t, enable: c_int) -> c_int)\n+externfn!(fn uv_tcp_keepalive(h: *uv_tcp_t, enable: c_int,\n+                              delay: c_uint) -> c_int)\n+externfn!(fn uv_tcp_simultaneous_accepts(h: *uv_tcp_t, enable: c_int) -> c_int)\n+externfn!(fn uv_tcp_getsockname(h: *uv_tcp_t, name: *sockaddr,\n+                                len: *mut c_int) -> c_int)\n+externfn!(fn uv_tcp_getpeername(h: *uv_tcp_t, name: *sockaddr,\n+                                len: *mut c_int) -> c_int)\n+externfn!(fn uv_ip4_addr(ip: *c_char, port: c_int, addr: *sockaddr) -> c_int)\n+externfn!(fn uv_ip6_addr(ip: *c_char, port: c_int, addr: *sockaddr) -> c_int)\n+\n+// udp bindings\n+externfn!(fn uv_udp_init(l: *uv_loop_t, h: *uv_udp_t) -> c_int)\n+externfn!(fn uv_udp_bind(h: *uv_udp_t, addr: *sockaddr, flags: c_uint) -> c_int)\n+externfn!(fn uv_udp_recv_start(server: *uv_udp_t,\n+                               on_alloc: uv_alloc_cb,\n+                               on_recv: uv_udp_recv_cb) -> c_int)\n+externfn!(fn uv_udp_set_membership(handle: *uv_udp_t, multicast_addr: *c_char,\n+                                   interface_addr: *c_char,\n+                                   membership: uv_membership) -> c_int)\n+externfn!(fn uv_udp_recv_stop(server: *uv_udp_t) -> c_int)\n+externfn!(fn uv_udp_set_multicast_loop(handle: *uv_udp_t, on: c_int) -> c_int)\n+externfn!(fn uv_udp_set_multicast_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int)\n+externfn!(fn uv_udp_set_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int)\n+externfn!(fn uv_udp_set_broadcast(handle: *uv_udp_t, on: c_int) -> c_int)\n+externfn!(fn uv_udp_getsockname(h: *uv_udp_t, name: *sockaddr,\n+                                len: *mut c_int) -> c_int)\n+\n+pub unsafe fn uv_udp_send(req: *uv_udp_send_t,\n+                          handle: *uv_udp_t,\n+                          buf_in: &[uv_buf_t],\n+                          addr: *sockaddr,\n+                          cb: uv_udp_send_cb) -> c_int {\n+    externfn!(fn uv_udp_send(req: *uv_write_t, stream: *uv_stream_t,\n+                             buf_in: *uv_buf_t, buf_cnt: c_int, addr: *sockaddr,\n+                             cb: uv_udp_send_cb) -> c_int)\n \n-}\n+    let buf_ptr = vec::raw::to_ptr(buf_in);\n+    let buf_cnt = buf_in.len() as i32;\n+    return uv_udp_send(req, handle, buf_ptr, buf_cnt, addr, cb);\n+}\n+\n+// timer bindings\n+externfn!(fn uv_timer_init(l: *uv_loop_t, t: *uv_timer_t) -> c_int)\n+externfn!(fn uv_timer_start(t: *uv_timer_t, cb: uv_timer_cb,\n+                            timeout: libc::uint64_t,\n+                            repeat: libc::uint64_t) -> c_int)\n+externfn!(fn uv_timer_stop(handle: *uv_timer_t) -> c_int)\n+\n+// fs operations\n+externfn!(fn uv_fs_open(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                        flags: c_int, mode: c_int, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_unlink(loop_ptr: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                          cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_write(l: *uv_loop_t, req: *uv_fs_t, fd: c_int, buf: *c_void,\n+                         len: size_t, offset: i64, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_read(l: *uv_loop_t, req: *uv_fs_t, fd: c_int, buf: *c_void,\n+                        len: size_t, offset: i64, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_close(l: *uv_loop_t, req: *uv_fs_t, fd: c_int,\n+                         cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_stat(l: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                        cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_fstat(l: *uv_loop_t, req: *uv_fs_t, fd: c_int,\n+                         cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_mkdir(l: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                         mode: c_int, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_rmdir(l: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                         cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_readdir(l: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                           flags: c_int, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_req_cleanup(req: *uv_fs_t))\n externfn!(fn uv_fs_fsync(handle: *uv_loop_t, req: *uv_fs_t, file: c_int,\n-                         cb: *u8) -> c_int)\n+                         cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_fdatasync(handle: *uv_loop_t, req: *uv_fs_t, file: c_int,\n-                             cb: *u8) -> c_int)\n+                             cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_ftruncate(handle: *uv_loop_t, req: *uv_fs_t, file: c_int,\n-                             offset: i64, cb: *u8) -> c_int)\n+                             offset: i64, cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_readlink(handle: *uv_loop_t, req: *uv_fs_t, file: *c_char,\n-                            cb: *u8) -> c_int)\n+                            cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_symlink(handle: *uv_loop_t, req: *uv_fs_t, src: *c_char,\n-                           dst: *c_char, flags: c_int, cb: *u8) -> c_int)\n+                           dst: *c_char, flags: c_int, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_rename(handle: *uv_loop_t, req: *uv_fs_t, src: *c_char,\n+                          dst: *c_char, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_utime(handle: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                         atime: c_double, mtime: c_double,\n+                         cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_link(handle: *uv_loop_t, req: *uv_fs_t, src: *c_char,\n-                        dst: *c_char, cb: *u8) -> c_int)\n+                        dst: *c_char, cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_chown(handle: *uv_loop_t, req: *uv_fs_t, src: *c_char,\n-                         uid: uv_uid_t, gid: uv_gid_t, cb: *u8) -> c_int)\n+                         uid: uv_uid_t, gid: uv_gid_t, cb: uv_fs_cb) -> c_int)\n+externfn!(fn uv_fs_chmod(handle: *uv_loop_t, req: *uv_fs_t, path: *c_char,\n+                         mode: c_int, cb: uv_fs_cb) -> c_int)\n externfn!(fn uv_fs_lstat(handle: *uv_loop_t, req: *uv_fs_t, file: *c_char,\n-                         cb: *u8) -> c_int)\n+                         cb: uv_fs_cb) -> c_int)\n+\n+// getaddrinfo\n+externfn!(fn uv_getaddrinfo(loop_: *uv_loop_t, req: *uv_getaddrinfo_t,\n+                            getaddrinfo_cb: uv_getaddrinfo_cb,\n+                            node: *c_char, service: *c_char,\n+                            hints: *addrinfo) -> c_int)\n+externfn!(fn uv_freeaddrinfo(ai: *addrinfo))\n+\n+// process spawning\n+externfn!(fn uv_spawn(loop_ptr: *uv_loop_t, outptr: *uv_process_t,\n+                      options: *uv_process_options_t) -> c_int)\n+externfn!(fn uv_process_kill(p: *uv_process_t, signum: c_int) -> c_int)\n+\n+// pipes\n+externfn!(fn uv_pipe_init(l: *uv_loop_t, p: *uv_pipe_t, ipc: c_int) -> c_int)\n+externfn!(fn uv_pipe_open(pipe: *uv_pipe_t, file: c_int) -> c_int)\n+externfn!(fn uv_pipe_bind(pipe: *uv_pipe_t, name: *c_char) -> c_int)\n+externfn!(fn uv_pipe_connect(req: *uv_connect_t, handle: *uv_pipe_t,\n+                             name: *c_char, cb: uv_connect_cb))\n+\n+// tty\n+externfn!(fn uv_tty_init(l: *uv_loop_t, tty: *uv_tty_t, fd: c_int,\n+                         readable: c_int) -> c_int)\n+externfn!(fn uv_tty_set_mode(tty: *uv_tty_t, mode: c_int) -> c_int)\n+externfn!(fn uv_tty_get_winsize(tty: *uv_tty_t, width: *c_int,\n+                                height: *c_int) -> c_int)\n+\n+// signals\n+externfn!(fn uv_signal_init(loop_: *uv_loop_t, handle: *uv_signal_t) -> c_int)\n+externfn!(fn uv_signal_start(h: *uv_signal_t, cb: uv_signal_cb,\n+                             signum: c_int) -> c_int)\n+externfn!(fn uv_signal_stop(handle: *uv_signal_t) -> c_int)\n \n // libuv requires various system libraries to successfully link on some\n // platforms"}, {"sha": "1c464110ce0519e81abfd40447222ebc562ce0a8", "filename": "src/libstd/logging.rs", "status": "modified", "additions": 9, "deletions": 7, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Flogging.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Flogging.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Flogging.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -107,14 +107,16 @@ pub fn log(_level: u32, args: &fmt::Arguments) {\n         let optional_task: Option<*mut Task> = Local::try_unsafe_borrow();\n         match optional_task {\n             Some(local) => {\n-                // Use the available logger\n-                (*local).logger.log(args);\n-            }\n-            None => {\n-                // There is no logger anywhere, just write to stderr\n-                let mut logger = StdErrLogger::new();\n-                logger.log(args);\n+                match (*local).logger {\n+                    // Use the available logger if we have one\n+                    Some(ref mut logger) => return logger.log(args),\n+                    None => {}\n+                }\n             }\n+            None => {}\n         }\n+        // There is no logger anywhere, just write to stderr\n+        let mut logger = StdErrLogger::new();\n+        logger.log(args);\n     }\n }"}, {"sha": "322c58bc2b807539e657a65e73f08987d53f5ec0", "filename": "src/libstd/rt/basic.rs", "status": "modified", "additions": 16, "deletions": 24, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fbasic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fbasic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fbasic.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -15,7 +15,8 @@\n use prelude::*;\n \n use cast;\n-use rt::rtio::{EventLoop, IoFactory, RemoteCallback, PausibleIdleCallback};\n+use rt::rtio::{EventLoop, IoFactory, RemoteCallback, PausibleIdleCallback,\n+               Callback};\n use unstable::sync::Exclusive;\n use util;\n \n@@ -25,9 +26,9 @@ pub fn event_loop() -> ~EventLoop {\n }\n \n struct BasicLoop {\n-    work: ~[~fn()],               // pending work\n-    idle: Option<*BasicPausible>, // only one is allowed\n-    remotes: ~[(uint, ~fn())],\n+    work: ~[proc()],                  // pending work\n+    idle: Option<*mut BasicPausible>, // only one is allowed\n+    remotes: ~[(uint, ~Callback)],\n     next_remote: uint,\n     messages: Exclusive<~[Message]>\n }\n@@ -86,8 +87,8 @@ impl BasicLoop {\n     fn message(&mut self, message: Message) {\n         match message {\n             RunRemote(i) => {\n-                match self.remotes.iter().find(|& &(id, _)| id == i) {\n-                    Some(&(_, ref f)) => (*f)(),\n+                match self.remotes.mut_iter().find(|& &(id, _)| id == i) {\n+                    Some(&(_, ref mut f)) => f.call(),\n                     None => unreachable!()\n                 }\n             }\n@@ -106,7 +107,7 @@ impl BasicLoop {\n             match self.idle {\n                 Some(idle) => {\n                     if (*idle).active {\n-                        (*(*idle).work.get_ref())();\n+                        (*idle).work.call();\n                     }\n                 }\n                 None => {}\n@@ -144,22 +145,22 @@ impl EventLoop for BasicLoop {\n         }\n     }\n \n-    fn callback(&mut self, f: ~fn()) {\n+    fn callback(&mut self, f: proc()) {\n         self.work.push(f);\n     }\n \n     // XXX: Seems like a really weird requirement to have an event loop provide.\n-    fn pausible_idle_callback(&mut self) -> ~PausibleIdleCallback {\n-        let callback = ~BasicPausible::new(self);\n+    fn pausible_idle_callback(&mut self, cb: ~Callback) -> ~PausibleIdleCallback {\n+        let callback = ~BasicPausible::new(self, cb);\n         rtassert!(self.idle.is_none());\n         unsafe {\n-            let cb_ptr: &*BasicPausible = cast::transmute(&callback);\n+            let cb_ptr: &*mut BasicPausible = cast::transmute(&callback);\n             self.idle = Some(*cb_ptr);\n         }\n         return callback as ~PausibleIdleCallback;\n     }\n \n-    fn remote_callback(&mut self, f: ~fn()) -> ~RemoteCallback {\n+    fn remote_callback(&mut self, f: ~Callback) -> ~RemoteCallback {\n         let id = self.next_remote;\n         self.next_remote += 1;\n         self.remotes.push((id, f));\n@@ -203,36 +204,27 @@ impl Drop for BasicRemote {\n \n struct BasicPausible {\n     eloop: *mut BasicLoop,\n-    work: Option<~fn()>,\n+    work: ~Callback,\n     active: bool,\n }\n \n impl BasicPausible {\n-    fn new(eloop: &mut BasicLoop) -> BasicPausible {\n+    fn new(eloop: &mut BasicLoop, cb: ~Callback) -> BasicPausible {\n         BasicPausible {\n             active: false,\n-            work: None,\n+            work: cb,\n             eloop: eloop,\n         }\n     }\n }\n \n impl PausibleIdleCallback for BasicPausible {\n-    fn start(&mut self, f: ~fn()) {\n-        rtassert!(!self.active && self.work.is_none());\n-        self.active = true;\n-        self.work = Some(f);\n-    }\n     fn pause(&mut self) {\n         self.active = false;\n     }\n     fn resume(&mut self) {\n         self.active = true;\n     }\n-    fn close(&mut self) {\n-        self.active = false;\n-        self.work = None;\n-    }\n }\n \n impl Drop for BasicPausible {"}, {"sha": "06c07308cf634fa78335c6cb6322c5824ae75fb0", "filename": "src/libstd/rt/io/fs.rs", "status": "modified", "additions": 43, "deletions": 2, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Ffs.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -587,6 +587,22 @@ pub fn rmdir_recursive(path: &Path) {\n     rmdir(path);\n }\n \n+/// Changes the timestamps for a file's last modification and access time.\n+/// The file at the path specified will have its last access time set to\n+/// `atime` and its modification time set to `mtime`. The times specified should\n+/// be in milliseconds.\n+///\n+/// # Errors\n+///\n+/// This function will raise on the `io_error` condition if an error\n+/// happens.\n+// FIXME(#10301) these arguments should not be u64\n+pub fn change_file_times(path: &Path, atime: u64, mtime: u64) {\n+    do io_raise |io| {\n+        io.fs_utime(&path.to_c_str(), atime, mtime)\n+    };\n+}\n+\n impl Reader for File {\n     fn read(&mut self, buf: &mut [u8]) -> Option<uint> {\n         match self.fd.read(buf) {\n@@ -704,8 +720,8 @@ mod test {\n     use rt::io;\n     use str;\n     use super::{File, rmdir, mkdir, readdir, rmdir_recursive, mkdir_recursive,\n-                copy, unlink, stat, symlink, link, readlink, chmod, chown,\n-                lstat};\n+                copy, unlink, stat, symlink, link, readlink, chmod,\n+                lstat, change_file_times};\n \n     fn tmpdir() -> Path {\n         use os;\n@@ -1244,4 +1260,29 @@ mod test {\n \n         rmdir_recursive(&tmpdir);\n     }\n+\n+    #[test]\n+    fn utime() {\n+        let tmpdir = tmpdir();\n+        let path = tmpdir.join(\"a\");\n+        File::create(&path);\n+\n+        change_file_times(&path, 1000, 2000);\n+        assert_eq!(path.stat().accessed, 1000);\n+        assert_eq!(path.stat().modified, 2000);\n+\n+        rmdir_recursive(&tmpdir);\n+    }\n+\n+    #[test]\n+    fn utime_noexist() {\n+        let tmpdir = tmpdir();\n+\n+        match io::result(|| change_file_times(&tmpdir.join(\"a\"), 100, 200)) {\n+            Ok(*) => fail!(),\n+            Err(*) => {}\n+        }\n+\n+        rmdir_recursive(&tmpdir);\n+    }\n }"}, {"sha": "ce9504a5b43d9b01abec0b4a34be4ac175199b22", "filename": "src/libstd/rt/io/mod.rs", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fmod.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -423,7 +423,11 @@ pub fn ignore_io_error<T>(cb: &fn() -> T) -> T {\n /// closure if no error occurred.\n pub fn result<T>(cb: &fn() -> T) -> Result<T, IoError> {\n     let mut err = None;\n-    let ret = io_error::cond.trap(|e| err = Some(e)).inside(cb);\n+    let ret = io_error::cond.trap(|e| {\n+        if err.is_none() {\n+            err = Some(e);\n+        }\n+    }).inside(cb);\n     match err {\n         Some(e) => Err(e),\n         None => Ok(ret),\n@@ -1142,8 +1146,9 @@ pub struct FileStat {\n     /// The file permissions currently on the file\n     perm: FilePermission,\n \n-    // XXX: These time fields are pretty useless without an actual time\n-    //      representation, what are the milliseconds relative to?\n+    // FIXME(#10301): These time fields are pretty useless without an actual\n+    //                time representation, what are the milliseconds relative\n+    //                to?\n \n     /// The time that the file was created at, in platform-dependent\n     /// milliseconds"}, {"sha": "6d4f29182dda6cf19b6fc1e079a9f25f98aa541b", "filename": "src/libstd/rt/io/native/file.rs", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fnative%2Ffile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fnative%2Ffile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fnative%2Ffile.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -80,18 +80,20 @@ pub type fd_t = libc::c_int;\n \n pub struct FileDesc {\n     priv fd: fd_t,\n+    priv close_on_drop: bool,\n }\n \n impl FileDesc {\n     /// Create a `FileDesc` from an open C file descriptor.\n     ///\n     /// The `FileDesc` will take ownership of the specified file descriptor and\n-    /// close it upon destruction.\n+    /// close it upon destruction if the `close_on_drop` flag is true, otherwise\n+    /// it will not close the file descriptor when this `FileDesc` is dropped.\n     ///\n     /// Note that all I/O operations done on this object will be *blocking*, but\n     /// they do not require the runtime to be active.\n-    pub fn new(fd: fd_t) -> FileDesc {\n-        FileDesc { fd: fd }\n+    pub fn new(fd: fd_t, close_on_drop: bool) -> FileDesc {\n+        FileDesc { fd: fd, close_on_drop: close_on_drop }\n     }\n }\n \n@@ -137,7 +139,9 @@ impl Writer for FileDesc {\n impl Drop for FileDesc {\n     #[fixed_stack_segment] #[inline(never)]\n     fn drop(&mut self) {\n-        unsafe { libc::close(self.fd); }\n+        if self.close_on_drop {\n+            unsafe { libc::close(self.fd); }\n+        }\n     }\n }\n \n@@ -245,8 +249,8 @@ mod tests {\n         // opening or closing files.\n         unsafe {\n             let os::Pipe { input, out } = os::pipe();\n-            let mut reader = FileDesc::new(input);\n-            let mut writer = FileDesc::new(out);\n+            let mut reader = FileDesc::new(input, true);\n+            let mut writer = FileDesc::new(out, true);\n \n             writer.write(bytes!(\"test\"));\n             let mut buf = [0u8, ..4];"}, {"sha": "f5c39de1bf44ecfd76e69f5bf274fea4193990a2", "filename": "src/libstd/rt/io/native/process.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fnative%2Fprocess.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fnative%2Fprocess.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fnative%2Fprocess.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -105,9 +105,9 @@ impl Process {\n         Process {\n             pid: res.pid,\n             handle: res.handle,\n-            input: in_pipe.map(|pipe| file::FileDesc::new(pipe.out)),\n-            output: out_pipe.map(|pipe| file::FileDesc::new(pipe.input)),\n-            error: err_pipe.map(|pipe| file::FileDesc::new(pipe.input)),\n+            input: in_pipe.map(|pipe| file::FileDesc::new(pipe.out, true)),\n+            output: out_pipe.map(|pipe| file::FileDesc::new(pipe.input, true)),\n+            error: err_pipe.map(|pipe| file::FileDesc::new(pipe.input, true)),\n             exit_code: None,\n         }\n     }"}, {"sha": "ddfbb9a8f8c28f2edf0f5578465876ad6c5dd20e", "filename": "src/libstd/rt/io/native/stdio.rs", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fnative%2Fstdio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fnative%2Fstdio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fnative%2Fstdio.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -36,10 +36,8 @@ pub struct StdIn {\n \n impl StdIn {\n     /// Duplicates the stdin file descriptor, returning an io::Reader\n-    #[fixed_stack_segment] #[inline(never)]\n     pub fn new() -> StdIn {\n-        let fd = unsafe { libc::dup(libc::STDIN_FILENO) };\n-        StdIn { fd: file::FileDesc::new(fd) }\n+        StdIn { fd: file::FileDesc::new(libc::STDIN_FILENO, false) }\n     }\n }\n \n@@ -54,10 +52,8 @@ pub struct StdOut {\n \n impl StdOut {\n     /// Duplicates the specified file descriptor, returning an io::Writer\n-    #[fixed_stack_segment] #[inline(never)]\n     pub fn new(fd: file::fd_t) -> StdOut {\n-        let fd = unsafe { libc::dup(fd) };\n-        StdOut { fd: file::FileDesc::new(fd) }\n+        StdOut { fd: file::FileDesc::new(fd, false) }\n     }\n }\n "}, {"sha": "acc2e11f067e6fff714c74ec4facfe3b50a34497", "filename": "src/libstd/rt/io/stdio.rs", "status": "modified", "additions": 13, "deletions": 5, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fstdio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Fstdio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fstdio.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -33,7 +33,8 @@ use result::{Ok, Err};\n use rt::io::buffered::LineBufferedWriter;\n use rt::rtio::{IoFactory, RtioTTY, RtioFileStream, with_local_io,\n                CloseAsynchronously};\n-use super::{Reader, Writer, io_error, IoError, OtherIoError};\n+use super::{Reader, Writer, io_error, IoError, OtherIoError,\n+            standard_error, EndOfFile};\n \n // And so begins the tale of acquiring a uv handle to a stdio stream on all\n // platforms in all situations. Our story begins by splitting the world into two\n@@ -203,6 +204,15 @@ impl Reader for StdReader {\n             File(ref mut file) => file.read(buf).map(|i| i as uint),\n         };\n         match ret {\n+            // When reading a piped stdin, libuv will return 0-length reads when\n+            // stdin reaches EOF. For pretty much all other streams it will\n+            // return an actual EOF error, but apparently for stdin it's a\n+            // little different. Hence, here we convert a 0 length read to an\n+            // end-of-file indicator so the caller knows to stop reading.\n+            Ok(0) => {\n+                io_error::cond.raise(standard_error(EndOfFile));\n+                None\n+            }\n             Ok(amt) => Some(amt as uint),\n             Err(e) => {\n                 io_error::cond.raise(e);\n@@ -277,12 +287,10 @@ impl StdWriter {\n         }\n     }\n \n-    /// Returns whether this tream is attached to a TTY instance or not.\n-    ///\n-    /// This is similar to libc's isatty() function\n+    /// Returns whether this stream is attached to a TTY instance or not.\n     pub fn isatty(&self) -> bool {\n         match self.inner {\n-            TTY(ref tty) => tty.isatty(),\n+            TTY(*) => true,\n             File(*) => false,\n         }\n     }"}, {"sha": "b0cf7dee10abb434a6017e249da21c0308717845", "filename": "src/libstd/rt/io/timer.rs", "status": "modified", "additions": 3, "deletions": 11, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Ftimer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fio%2Ftimer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Ftimer.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -142,14 +142,10 @@ mod test {\n     fn oneshot_twice() {\n         do run_in_mt_newsched_task {\n             let mut timer = Timer::new().unwrap();\n-            let port1 = timer.oneshot(100000000000);\n+            let port1 = timer.oneshot(10000);\n             let port = timer.oneshot(1);\n             port.recv();\n-            let port1 = Cell::new(port1);\n-            let ret = do task::try {\n-                port1.take().recv();\n-            };\n-            assert!(ret.is_err());\n+            assert_eq!(port1.try_recv(), None);\n         }\n     }\n \n@@ -160,11 +156,7 @@ mod test {\n             let port = timer.oneshot(100000000000);\n             timer.sleep(1); // this should invalidate the port\n \n-            let port = Cell::new(port);\n-            let ret = do task::try {\n-                port.take().recv();\n-            };\n-            assert!(ret.is_err());\n+            assert_eq!(port.try_recv(), None);\n         }\n     }\n "}, {"sha": "c37195a7b1553a8002387c5898c6524d17822b0c", "filename": "src/libstd/rt/logging.rs", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Flogging.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Flogging.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flogging.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -172,20 +172,18 @@ pub trait Logger {\n /// This logger emits output to the stderr of the process, and contains a lazily\n /// initialized event-loop driven handle to the stream.\n pub struct StdErrLogger {\n-    priv handle: Option<LineBufferedWriter<StdWriter>>,\n+    priv handle: LineBufferedWriter<StdWriter>,\n }\n \n impl StdErrLogger {\n-    pub fn new() -> StdErrLogger { StdErrLogger { handle: None } }\n+    pub fn new() -> StdErrLogger {\n+        StdErrLogger { handle: LineBufferedWriter::new(io::stderr()) }\n+    }\n }\n \n impl Logger for StdErrLogger {\n     fn log(&mut self, args: &fmt::Arguments) {\n-        // First time logging? Get a handle to the stderr of this process.\n-        if self.handle.is_none() {\n-            self.handle = Some(LineBufferedWriter::new(io::stderr()));\n-        }\n-        fmt::writeln(self.handle.get_mut_ref() as &mut io::Writer, args);\n+        fmt::writeln(&mut self.handle as &mut io::Writer, args);\n     }\n }\n "}, {"sha": "3ef57710344dc06c700b834770099fa83a292dde", "filename": "src/libstd/rt/macros.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmacros.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -34,15 +34,15 @@ macro_rules! rtassert (\n     ( $arg:expr ) => ( {\n         if ::rt::util::ENFORCE_SANITY {\n             if !$arg {\n-                rtabort!(\"assertion failed: {}\", stringify!($arg));\n+                rtabort!(\" assertion failed: {}\", stringify!($arg));\n             }\n         }\n     } )\n )\n \n \n macro_rules! rtabort (\n-    ($($msg:tt)*) => ( {\n-        ::rt::util::abort(format!($($msg)*));\n+    ($($arg:tt)*) => ( {\n+        ::rt::util::abort(format!($($arg)*));\n     } )\n )"}, {"sha": "d623914cdadc93e95d6569b876e8c9f5594722e5", "filename": "src/libstd/rt/rtio.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Frtio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Frtio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Frtio.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -24,11 +24,15 @@ use path::Path;\n use super::io::{SeekStyle};\n use super::io::{FileMode, FileAccess, FileStat, FilePermission};\n \n+pub trait Callback {\n+    fn call(&mut self);\n+}\n+\n pub trait EventLoop {\n     fn run(&mut self);\n-    fn callback(&mut self, ~fn());\n-    fn pausible_idle_callback(&mut self) -> ~PausibleIdleCallback;\n-    fn remote_callback(&mut self, ~fn()) -> ~RemoteCallback;\n+    fn callback(&mut self, proc());\n+    fn pausible_idle_callback(&mut self, ~Callback) -> ~PausibleIdleCallback;\n+    fn remote_callback(&mut self, ~Callback) -> ~RemoteCallback;\n \n     /// The asynchronous I/O services. Not all event loops may provide one\n     // FIXME(#9382) this is an awful interface\n@@ -121,6 +125,8 @@ pub trait IoFactory {\n     fn fs_readlink(&mut self, path: &CString) -> Result<Path, IoError>;\n     fn fs_symlink(&mut self, src: &CString, dst: &CString) -> Result<(), IoError>;\n     fn fs_link(&mut self, src: &CString, dst: &CString) -> Result<(), IoError>;\n+    fn fs_utime(&mut self, src: &CString, atime: u64, mtime: u64) ->\n+        Result<(), IoError>;\n \n     // misc\n     fn timer_init(&mut self) -> Result<~RtioTimer, IoError>;\n@@ -209,23 +215,18 @@ pub trait RtioUnixListener {\n \n pub trait RtioUnixAcceptor {\n     fn accept(&mut self) -> Result<~RtioPipe, IoError>;\n-    fn accept_simultaneously(&mut self) -> Result<(), IoError>;\n-    fn dont_accept_simultaneously(&mut self) -> Result<(), IoError>;\n }\n \n pub trait RtioTTY {\n     fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError>;\n     fn write(&mut self, buf: &[u8]) -> Result<(), IoError>;\n     fn set_raw(&mut self, raw: bool) -> Result<(), IoError>;\n     fn get_winsize(&mut self) -> Result<(int, int), IoError>;\n-    fn isatty(&self) -> bool;\n }\n \n pub trait PausibleIdleCallback {\n-    fn start(&mut self, f: ~fn());\n     fn pause(&mut self);\n     fn resume(&mut self);\n-    fn close(&mut self);\n }\n \n pub trait RtioSignal {}"}, {"sha": "c2e665f4903073cda371dbb09d452d5542ab4969", "filename": "src/libstd/rt/sched.rs", "status": "modified", "additions": 16, "deletions": 8, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsched.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -23,7 +23,7 @@ use super::message_queue::MessageQueue;\n use rt::kill::BlockedTask;\n use rt::local_ptr;\n use rt::local::Local;\n-use rt::rtio::{RemoteCallback, PausibleIdleCallback};\n+use rt::rtio::{RemoteCallback, PausibleIdleCallback, Callback};\n use borrow::{to_uint};\n use cell::Cell;\n use rand::{XorShiftRng, Rng, Rand};\n@@ -169,7 +169,8 @@ impl Scheduler {\n     pub fn bootstrap(mut ~self, task: ~Task) {\n \n         // Build an Idle callback.\n-        self.idle_callback = Some(self.event_loop.pausible_idle_callback());\n+        let cb = ~SchedRunner as ~Callback;\n+        self.idle_callback = Some(self.event_loop.pausible_idle_callback(cb));\n \n         // Initialize the TLS key.\n         local_ptr::init_tls_key();\n@@ -184,7 +185,7 @@ impl Scheduler {\n         // Before starting our first task, make sure the idle callback\n         // is active. As we do not start in the sleep state this is\n         // important.\n-        self.idle_callback.get_mut_ref().start(Scheduler::run_sched_once);\n+        self.idle_callback.get_mut_ref().resume();\n \n         // Now, as far as all the scheduler state is concerned, we are\n         // inside the \"scheduler\" context. So we can act like the\n@@ -202,7 +203,7 @@ impl Scheduler {\n \n         // Close the idle callback.\n         let mut sched: ~Scheduler = Local::take();\n-        sched.idle_callback.get_mut_ref().close();\n+        sched.idle_callback.take();\n         // Make one go through the loop to run the close callback.\n         sched.run();\n \n@@ -454,8 +455,7 @@ impl Scheduler {\n     // * Task Routing Functions - Make sure tasks send up in the right\n     // place.\n \n-    fn process_task(mut ~self, mut task: ~Task,\n-                    schedule_fn: SchedulingFn) {\n+    fn process_task(mut ~self, mut task: ~Task, schedule_fn: SchedulingFn) {\n         rtdebug!(\"processing a task\");\n \n         let home = task.take_unwrap_home();\n@@ -767,7 +767,7 @@ impl Scheduler {\n     }\n \n     pub fn make_handle(&mut self) -> SchedHandle {\n-        let remote = self.event_loop.remote_callback(Scheduler::run_sched_once);\n+        let remote = self.event_loop.remote_callback(~SchedRunner as ~Callback);\n \n         return SchedHandle {\n             remote: remote,\n@@ -779,7 +779,7 @@ impl Scheduler {\n \n // Supporting types\n \n-type SchedulingFn = ~fn(~Scheduler, ~Task);\n+type SchedulingFn = extern \"Rust\" fn (~Scheduler, ~Task);\n \n pub enum SchedMessage {\n     Wake,\n@@ -802,6 +802,14 @@ impl SchedHandle {\n     }\n }\n \n+struct SchedRunner;\n+\n+impl Callback for SchedRunner {\n+    fn call(&mut self) {\n+        Scheduler::run_sched_once();\n+    }\n+}\n+\n struct CleanupJob {\n     task: ~Task,\n     f: UnsafeTaskReceiver"}, {"sha": "7e374fc602138c832fe3347216c21fa4f224463d", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -50,7 +50,7 @@ pub struct Task {\n     heap: LocalHeap,\n     priv gc: GarbageCollector,\n     storage: LocalStorage,\n-    logger: StdErrLogger,\n+    logger: Option<StdErrLogger>,\n     unwinder: Unwinder,\n     taskgroup: Option<Taskgroup>,\n     death: Death,\n@@ -180,7 +180,7 @@ impl Task {\n             heap: LocalHeap::new(),\n             gc: GarbageCollector,\n             storage: LocalStorage(None),\n-            logger: StdErrLogger::new(),\n+            logger: None,\n             unwinder: Unwinder { unwinding: false, cause: None },\n             taskgroup: None,\n             death: Death::new(),\n@@ -215,7 +215,7 @@ impl Task {\n             heap: LocalHeap::new(),\n             gc: GarbageCollector,\n             storage: LocalStorage(None),\n-            logger: StdErrLogger::new(),\n+            logger: None,\n             unwinder: Unwinder { unwinding: false, cause: None },\n             taskgroup: None,\n             death: Death::new(),\n@@ -238,7 +238,7 @@ impl Task {\n             heap: LocalHeap::new(),\n             gc: GarbageCollector,\n             storage: LocalStorage(None),\n-            logger: StdErrLogger::new(),\n+            logger: None,\n             unwinder: Unwinder { unwinding: false, cause: None },\n             taskgroup: None,\n             // FIXME(#7544) make watching optional\n@@ -320,6 +320,7 @@ impl Task {\n                     }\n                     None => {}\n                 }\n+                self.logger.take();\n             }\n         }\n "}, {"sha": "fe23944397d87dde8a576d05abdfa91828c1f22c", "filename": "src/libstd/run.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frun.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Flibstd%2Frun.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frun.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -436,13 +436,13 @@ mod tests {\n     }\n \n     fn writeclose(fd: c_int, s: &str) {\n-        let mut writer = file::FileDesc::new(fd);\n+        let mut writer = file::FileDesc::new(fd, true);\n         writer.write(s.as_bytes());\n     }\n \n     fn readclose(fd: c_int) -> ~str {\n         let mut res = ~[];\n-        let mut reader = file::FileDesc::new(fd);\n+        let mut reader = file::FileDesc::new(fd, true);\n         let mut buf = [0, ..1024];\n         loop {\n             match reader.read(buf) {"}, {"sha": "7ac7e0248b34732e9963cdb8e31f7e612d23d14b", "filename": "src/libuv", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibuv?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -1 +1 @@\n-Subproject commit d88cf5652a1afb23939da0bae86c70ec521b9921\n+Subproject commit 7ac7e0248b34732e9963cdb8e31f7e612d23d14b"}, {"sha": "f3be486a25ab2b3cf3554731a3e7446d252662af", "filename": "src/rt/rust_uv.cpp", "status": "modified", "additions": 23, "deletions": 504, "changes": 527, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Frt%2Frust_uv.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Frt%2Frust_uv.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_uv.cpp?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -31,244 +31,16 @@ rust_uv_loop_new() {\n     return (void*)uv_loop_new();\n }\n \n-extern \"C\" void\n-rust_uv_loop_delete(uv_loop_t* loop) {\n-    // FIXME: This is a workaround for #1815. libev uses realloc(0) to\n-    // free the loop, which valgrind doesn't like. We have suppressions\n-    // to make valgrind ignore them.\n-    //\n-    // Valgrind also has a sanity check when collecting allocation backtraces\n-    // that the stack pointer must be at least 512 bytes into the stack (at\n-    // least 512 bytes of frames must have come before). When this is not\n-    // the case it doesn't collect the backtrace.\n-    //\n-    // Unfortunately, with our spaghetti stacks that valgrind check triggers\n-    // sometimes and we don't get the backtrace for the realloc(0), it\n-    // fails to be suppressed, and it gets reported as 0 bytes lost\n-    // from a malloc with no backtrace.\n-    //\n-    // This pads our stack with some extra space before deleting the loop\n-    alloca(512);\n-    uv_loop_delete(loop);\n-}\n-\n extern \"C\" void\n rust_uv_loop_set_data(uv_loop_t* loop, void* data) {\n     loop->data = data;\n }\n \n-extern \"C\" void\n-rust_uv_run(uv_loop_t* loop) {\n-    uv_run(loop, UV_RUN_DEFAULT);\n-}\n-\n-extern \"C\" void\n-rust_uv_close(uv_handle_t* handle, uv_close_cb cb) {\n-    uv_close(handle, cb);\n-}\n-\n-extern \"C\" void\n-rust_uv_walk(uv_loop_t* loop, uv_walk_cb cb, void* arg) {\n-    uv_walk(loop, cb, arg);\n-}\n-\n-extern \"C\" void\n-rust_uv_async_send(uv_async_t* handle) {\n-    uv_async_send(handle);\n-}\n-\n-extern \"C\" int\n-rust_uv_async_init(uv_loop_t* loop_handle,\n-        uv_async_t* async_handle,\n-        uv_async_cb cb) {\n-    return uv_async_init(loop_handle, async_handle, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_timer_init(uv_loop_t* loop, uv_timer_t* timer) {\n-    return uv_timer_init(loop, timer);\n-}\n-\n-extern \"C\" int\n-rust_uv_timer_start(uv_timer_t* the_timer, uv_timer_cb cb,\n-                    int64_t timeout, int64_t repeat) {\n-    return uv_timer_start(the_timer, cb, timeout, repeat);\n-}\n-\n-extern \"C\" int\n-rust_uv_timer_stop(uv_timer_t* the_timer) {\n-    return uv_timer_stop(the_timer);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_init(uv_loop_t* loop, uv_tcp_t* handle) {\n-    return uv_tcp_init(loop, handle);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_connect(uv_connect_t* connect_ptr,\n-        uv_tcp_t* tcp_ptr,\n-        uv_connect_cb cb,\n-        sockaddr_in* addr_ptr) {\n-    // FIXME ref #2064\n-    sockaddr_in addr = *addr_ptr;\n-    int result = uv_tcp_connect(connect_ptr, tcp_ptr, addr, cb);\n-    return result;\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_bind(uv_tcp_t* tcp_server, sockaddr_in* addr_ptr) {\n-    // FIXME ref #2064\n-    sockaddr_in addr = *addr_ptr;\n-    return uv_tcp_bind(tcp_server, addr);\n-}\n-extern \"C\" int\n-rust_uv_tcp_connect6(uv_connect_t* connect_ptr,\n-        uv_tcp_t* tcp_ptr,\n-        uv_connect_cb cb,\n-        sockaddr_in6* addr_ptr) {\n-    // FIXME ref #2064\n-    sockaddr_in6 addr = *addr_ptr;\n-    int result = uv_tcp_connect6(connect_ptr, tcp_ptr, addr, cb);\n-    return result;\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_bind6\n-(uv_tcp_t* tcp_server, sockaddr_in6* addr_ptr) {\n-    // FIXME ref #2064\n-    sockaddr_in6 addr = *addr_ptr;\n-    return uv_tcp_bind6(tcp_server, addr);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_getpeername\n-(uv_tcp_t* handle, sockaddr_storage* name) {\n-    // sockaddr_storage is big enough to hold either\n-    // sockaddr_in or sockaddr_in6\n-    int namelen = sizeof(sockaddr_in);\n-    return uv_tcp_getpeername(handle, (sockaddr*)name, &namelen);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_getsockname\n-(uv_tcp_t* handle, sockaddr_storage* name) {\n-    // sockaddr_storage is big enough to hold either\n-    // sockaddr_in or sockaddr_in6\n-    int namelen = sizeof(sockaddr_storage);\n-    return uv_tcp_getsockname(handle, (sockaddr*)name, &namelen);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_nodelay\n-(uv_tcp_t* handle, int enable) {\n-    return uv_tcp_nodelay(handle, enable);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_keepalive\n-(uv_tcp_t* handle, int enable, unsigned int delay) {\n-    return uv_tcp_keepalive(handle, enable, delay);\n-}\n-\n-extern \"C\" int\n-rust_uv_tcp_simultaneous_accepts\n-(uv_tcp_t* handle, int enable) {\n-    return uv_tcp_simultaneous_accepts(handle, enable);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_init(uv_loop_t* loop, uv_udp_t* handle) {\n-    return uv_udp_init(loop, handle);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_bind(uv_udp_t* server, sockaddr_in* addr_ptr, unsigned flags) {\n-    return uv_udp_bind(server, *addr_ptr, flags);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_bind6(uv_udp_t* server, sockaddr_in6* addr_ptr, unsigned flags) {\n-    return uv_udp_bind6(server, *addr_ptr, flags);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_send(uv_udp_send_t* req, uv_udp_t* handle, uv_buf_t* buf_in,\n-                 int buf_cnt, sockaddr_in* addr_ptr, uv_udp_send_cb cb) {\n-    return uv_udp_send(req, handle, buf_in, buf_cnt, *addr_ptr, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_send6(uv_udp_send_t* req, uv_udp_t* handle, uv_buf_t* buf_in,\n-                  int buf_cnt, sockaddr_in6* addr_ptr, uv_udp_send_cb cb) {\n-    return uv_udp_send6(req, handle, buf_in, buf_cnt, *addr_ptr, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_recv_start(uv_udp_t* server, uv_alloc_cb on_alloc, uv_udp_recv_cb on_read) {\n-    return uv_udp_recv_start(server, on_alloc, on_read);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_recv_stop(uv_udp_t* server) {\n-    return uv_udp_recv_stop(server);\n-}\n-\n extern \"C\" uv_udp_t*\n rust_uv_get_udp_handle_from_send_req(uv_udp_send_t* send_req) {\n     return send_req->handle;\n }\n \n-extern \"C\" int\n-rust_uv_udp_getsockname\n-(uv_udp_t* handle, sockaddr_storage* name) {\n-    // sockaddr_storage is big enough to hold either\n-    // sockaddr_in or sockaddr_in6\n-    int namelen = sizeof(sockaddr_storage);\n-    return uv_udp_getsockname(handle, (sockaddr*)name, &namelen);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_set_membership\n-(uv_udp_t* handle, const char* m_addr, const char* i_addr, uv_membership membership) {\n-    return uv_udp_set_membership(handle, m_addr, i_addr, membership);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_set_multicast_loop\n-(uv_udp_t* handle, int on) {\n-    return uv_udp_set_multicast_loop(handle, on);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_set_multicast_ttl\n-(uv_udp_t* handle, int ttl) {\n-    return uv_udp_set_multicast_ttl(handle, ttl);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_set_ttl\n-(uv_udp_t* handle, int ttl) {\n-    return uv_udp_set_ttl(handle, ttl);\n-}\n-\n-extern \"C\" int\n-rust_uv_udp_set_broadcast\n-(uv_udp_t* handle, int on) {\n-    return uv_udp_set_broadcast(handle, on);\n-}\n-\n-extern \"C\" int\n-rust_uv_listen(uv_stream_t* stream, int backlog,\n-        uv_connection_cb cb) {\n-    return uv_listen(stream, backlog, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_accept(uv_stream_t* server, uv_stream_t* client) {\n-    return uv_accept(server, client);\n-}\n-\n extern \"C\" uv_stream_t*\n rust_uv_get_stream_handle_from_connect_req(uv_connect_t* connect) {\n     return connect->handle;\n@@ -278,11 +50,6 @@ rust_uv_get_stream_handle_from_write_req(uv_write_t* write_req) {\n     return write_req->handle;\n }\n \n-extern \"C\" void\n-rust_uv_buf_init(uv_buf_t* out_buf, char* base, size_t len) {\n-    *out_buf = uv_buf_init(base, len);\n-}\n-\n extern \"C\" uv_loop_t*\n rust_uv_get_loop_for_uv_handle(uv_handle_t* handle) {\n     return handle->loop;\n@@ -319,178 +86,50 @@ rust_uv_set_data_for_req(uv_req_t* req, void* data) {\n     req->data = data;\n }\n \n-extern \"C\" char*\n-rust_uv_get_base_from_buf(uv_buf_t buf) {\n-    return buf.base;\n-}\n-\n-extern \"C\" size_t\n-rust_uv_get_len_from_buf(uv_buf_t buf) {\n-    return buf.len;\n-}\n-\n-extern \"C\" const char*\n-rust_uv_strerror(int err) {\n-    return uv_strerror(err);\n-}\n-\n-extern \"C\" const char*\n-rust_uv_err_name(int err) {\n-    return uv_err_name(err);\n-}\n-\n-extern \"C\" int\n-rust_uv_write(uv_write_t* req, uv_stream_t* handle,\n-        uv_buf_t* bufs, int buf_cnt,\n-        uv_write_cb cb) {\n-    return uv_write(req, handle, bufs, buf_cnt, cb);\n-}\n-extern \"C\" int\n-rust_uv_read_start(uv_stream_t* stream, uv_alloc_cb on_alloc,\n-        uv_read_cb on_read) {\n-    return uv_read_start(stream, on_alloc, on_read);\n-}\n-\n extern \"C\" int\n-rust_uv_read_stop(uv_stream_t* stream) {\n-    return uv_read_stop(stream);\n-}\n-\n-extern \"C\" struct sockaddr_in\n-rust_uv_ip4_addr(const char* ip, int port) {\n-    struct sockaddr_in addr = uv_ip4_addr(ip, port);\n-    return addr;\n-}\n-extern \"C\" struct sockaddr_in6\n-rust_uv_ip6_addr(const char* ip, int port) {\n-    return uv_ip6_addr(ip, port);\n-}\n-\n-extern \"C\" struct sockaddr_in*\n-rust_uv_ip4_addrp(const char* ip, int port) {\n-  struct sockaddr_in addr = uv_ip4_addr(ip, port);\n-  struct sockaddr_in *addrp = (sockaddr_in*)malloc(sizeof(struct sockaddr_in));\n-  assert(addrp);\n-  memcpy(addrp, &addr, sizeof(struct sockaddr_in));\n-  return addrp;\n-}\n-extern \"C\" struct sockaddr_in6*\n-rust_uv_ip6_addrp(const char* ip, int port) {\n-  struct sockaddr_in6 addr = uv_ip6_addr(ip, port);\n-  struct sockaddr_in6 *addrp = (sockaddr_in6*)malloc(sizeof(struct sockaddr_in6));\n-  assert(addrp);\n-  memcpy(addrp, &addr, sizeof(struct sockaddr_in6));\n-  return addrp;\n-}\n-\n-extern \"C\" struct sockaddr_storage *\n-rust_uv_malloc_sockaddr_storage() {\n-    struct sockaddr_storage *ss = (sockaddr_storage *)malloc(sizeof(struct sockaddr_storage));\n-    return ss;\n+rust_sockaddr_size() {\n+    return sizeof(struct sockaddr_storage);\n }\n \n-extern \"C\" void\n-rust_uv_free_sockaddr_storage(struct sockaddr_storage *ss) {\n-    free(ss);\n+extern \"C\" struct sockaddr*\n+rust_malloc_ip4_addr(char *name, int port) {\n+    struct sockaddr_in *addr = (struct sockaddr_in*) calloc(1, rust_sockaddr_size());\n+    assert(addr != NULL);\n+    addr->sin_port = htons(port);\n+    assert(uv_inet_pton(AF_INET, name, &addr->sin_addr) == 0);\n+    addr->sin_family = AF_INET;\n+    return (struct sockaddr*) addr;\n }\n \n-extern \"C\" void\n-rust_uv_free_ip4_addr(sockaddr_in *addrp) {\n-  free(addrp);\n+extern \"C\" struct sockaddr*\n+rust_malloc_ip6_addr(char *name, int port) {\n+    struct sockaddr_in6 *addr = (struct sockaddr_in6*) calloc(1, rust_sockaddr_size());\n+    assert(addr != NULL);\n+    addr->sin6_port = htons(port);\n+    assert(uv_inet_pton(AF_INET6, name, &addr->sin6_addr) == 0);\n+    addr->sin6_family = AF_INET6;\n+    return (struct sockaddr*) addr;\n }\n \n-extern \"C\" void\n-rust_uv_free_ip6_addr(sockaddr_in6 *addrp) {\n-  free(addrp);\n-}\n-\n-extern \"C\" int\n-rust_uv_ip4_name(struct sockaddr_in* src, char* dst, size_t size) {\n-    return uv_ip4_name(src, dst, size);\n-}\n-extern \"C\" int\n-rust_uv_ip6_name(struct sockaddr_in6* src, char* dst, size_t size) {\n-    int result = uv_ip6_name(src, dst, size);\n-    return result;\n-}\n extern \"C\" unsigned int\n-rust_uv_ip4_port(struct sockaddr_in* src) {\n+rust_ip4_port(struct sockaddr_in* src) {\n     return ntohs(src->sin_port);\n }\n extern \"C\" unsigned int\n-rust_uv_ip6_port(struct sockaddr_in6* src) {\n+rust_ip6_port(struct sockaddr_in6* src) {\n     return ntohs(src->sin6_port);\n }\n \n-extern  \"C\" int\n-rust_uv_getaddrinfo(uv_loop_t* loop, uv_getaddrinfo_t* handle,\n-                    uv_getaddrinfo_cb cb,\n-                    char* node, char* service,\n-                    addrinfo* hints) {\n-    return uv_getaddrinfo(loop, handle, cb, node, service, hints);\n-}\n-extern \"C\" void\n-rust_uv_freeaddrinfo(addrinfo* res) {\n-    uv_freeaddrinfo(res);\n-}\n-\n extern \"C\" int\n-rust_uv_is_ipv4_sockaddr(sockaddr* addr) {\n+rust_is_ipv4_sockaddr(sockaddr* addr) {\n     return addr->sa_family == AF_INET;\n }\n \n extern \"C\" int\n-rust_uv_is_ipv6_sockaddr(sockaddr* addr) {\n+rust_is_ipv6_sockaddr(sockaddr* addr) {\n     return addr->sa_family == AF_INET6;\n }\n \n-extern \"C\" bool\n-rust_uv_is_ipv4_addrinfo(addrinfo* input) {\n-    return input->ai_family == AF_INET;\n-}\n-\n-extern \"C\" bool\n-rust_uv_is_ipv6_addrinfo(addrinfo* input) {\n-    return input->ai_family == AF_INET6;\n-}\n-extern \"C\" addrinfo*\n-rust_uv_get_next_addrinfo(addrinfo* input) {\n-    return input->ai_next;\n-}\n-extern \"C\" sockaddr_in*\n-rust_uv_addrinfo_as_sockaddr_in(addrinfo* input) {\n-    return (sockaddr_in*)input->ai_addr;\n-}\n-extern \"C\" sockaddr_in6*\n-rust_uv_addrinfo_as_sockaddr_in6(addrinfo* input) {\n-    return (sockaddr_in6*)input->ai_addr;\n-}\n-\n-extern \"C\" int\n-rust_uv_idle_init(uv_loop_t* loop, uv_idle_t* idle) {\n-  return uv_idle_init(loop, idle);\n-}\n-\n-extern \"C\" int\n-rust_uv_idle_start(uv_idle_t* idle, uv_idle_cb cb) {\n-  return uv_idle_start(idle, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_idle_stop(uv_idle_t* idle) {\n-  return uv_idle_stop(idle);\n-}\n-\n-extern \"C\" size_t\n-rust_uv_handle_size(uintptr_t type) {\n-  return uv_handle_size((uv_handle_type)type);\n-}\n-\n-extern \"C\" size_t\n-rust_uv_req_size(uintptr_t type) {\n-  return uv_req_size((uv_req_type)type);\n-}\n-\n extern \"C\" uintptr_t\n rust_uv_handle_type_max() {\n   return UV_HANDLE_TYPE_MAX;\n@@ -501,33 +140,6 @@ rust_uv_req_type_max() {\n   return UV_REQ_TYPE_MAX;\n }\n \n-extern \"C\" int\n-rust_uv_fs_open(uv_loop_t* loop, uv_fs_t* req, const char* path, int flags,\n-                int mode, uv_fs_cb cb) {\n-  return uv_fs_open(loop, req, path, flags, mode, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_unlink(uv_loop_t* loop, uv_fs_t* req, const char* path, uv_fs_cb cb) {\n-  return uv_fs_unlink(loop, req, path, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_write(uv_loop_t* loop, uv_fs_t* req, uv_file fd, void* buf,\n-                 size_t len, int64_t offset, uv_fs_cb cb) {\n-  return uv_fs_write(loop, req, fd, buf, len, offset, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_read(uv_loop_t* loop, uv_fs_t* req, uv_file fd, void* buf,\n-                 size_t len, int64_t offset, uv_fs_cb cb) {\n-  return uv_fs_read(loop, req, fd, buf, len, offset, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_close(uv_loop_t* loop, uv_fs_t* req, uv_file fd, uv_fs_cb cb) {\n-  return uv_fs_close(loop, req, fd, cb);\n-}\n-extern \"C\" void\n-rust_uv_fs_req_cleanup(uv_fs_t* req) {\n-  uv_fs_req_cleanup(req);\n-}\n extern \"C\" int\n rust_uv_get_result_from_fs_req(uv_fs_t* req) {\n   return req->result;\n@@ -550,15 +162,6 @@ rust_uv_get_loop_from_getaddrinfo_req(uv_getaddrinfo_t* req) {\n   return req->loop;\n }\n \n-extern \"C\" int\n-rust_uv_fs_stat(uv_loop_t* loop, uv_fs_t* req, const char* path, uv_fs_cb cb) {\n-  return uv_fs_stat(loop, req, path, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_fstat(uv_loop_t* loop, uv_fs_t* req, uv_file file, uv_fs_cb cb) {\n-  return uv_fs_fstat(loop, req, file, cb);\n-}\n-\n extern \"C\" void\n rust_uv_populate_uv_stat(uv_fs_t* req_in, uv_stat_t* stat_out) {\n   stat_out->st_dev = req_in->statbuf.st_dev;\n@@ -583,39 +186,6 @@ rust_uv_populate_uv_stat(uv_fs_t* req_in, uv_stat_t* stat_out) {\n   stat_out->st_birthtim.tv_nsec = req_in->statbuf.st_birthtim.tv_nsec;\n }\n \n-extern \"C\" int\n-rust_uv_fs_mkdir(uv_loop_t* loop, uv_fs_t* req, const char* path, int mode, uv_fs_cb cb) {\n-  return uv_fs_mkdir(loop, req, path, mode, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_rmdir(uv_loop_t* loop, uv_fs_t* req, const char* path, uv_fs_cb cb) {\n-  return uv_fs_rmdir(loop, req, path, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_fs_readdir(uv_loop_t* loop, uv_fs_t* req, const char* path, int flags, uv_fs_cb cb) {\n-  return uv_fs_readdir(loop, req, path, flags, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_rename(uv_loop_t *loop, uv_fs_t* req, const char *path,\n-                  const char *to, uv_fs_cb cb) {\n-    return uv_fs_rename(loop, req, path, to, cb);\n-}\n-extern \"C\" int\n-rust_uv_fs_chmod(uv_loop_t* loop, uv_fs_t* req, const char* path, int mode, uv_fs_cb cb) {\n-  return uv_fs_chmod(loop, req, path, mode, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_spawn(uv_loop_t *loop, uv_process_t *p, uv_process_options_t options) {\n-  return uv_spawn(loop, p, options);\n-}\n-\n-extern \"C\" int\n-rust_uv_process_kill(uv_process_t *p, int signum) {\n-  return uv_process_kill(p, signum);\n-}\n-\n extern \"C\" void\n rust_set_stdio_container_flags(uv_stdio_container_t *c, int flags) {\n   c->flags = (uv_stdio_flags) flags;\n@@ -636,58 +206,7 @@ rust_uv_process_pid(uv_process_t* p) {\n   return p->pid;\n }\n \n-extern \"C\" int\n-rust_uv_pipe_init(uv_loop_t *loop, uv_pipe_t* p, int ipc) {\n-  return uv_pipe_init(loop, p, ipc);\n-}\n-\n-extern \"C\" int\n-rust_uv_pipe_open(uv_pipe_t *pipe, int file) {\n-    return uv_pipe_open(pipe, file);\n-}\n-\n-extern \"C\" int\n-rust_uv_pipe_bind(uv_pipe_t *pipe, char *name) {\n-    return uv_pipe_bind(pipe, name);\n-}\n-\n-extern \"C\" void\n-rust_uv_pipe_connect(uv_connect_t *req, uv_pipe_t *handle,\n-                     char *name, uv_connect_cb cb) {\n-    uv_pipe_connect(req, handle, name, cb);\n-}\n-\n-extern \"C\" int\n-rust_uv_tty_init(uv_loop_t *loop, uv_tty_t *tty, int fd, int readable) {\n-    return uv_tty_init(loop, tty, fd, readable);\n-}\n-\n-extern \"C\" int\n-rust_uv_tty_set_mode(uv_tty_t *tty, int mode) {\n-    return uv_tty_set_mode(tty, mode);\n-}\n-\n-extern \"C\" int\n-rust_uv_tty_get_winsize(uv_tty_t *tty, int *width, int *height) {\n-    return uv_tty_get_winsize(tty, width, height);\n-}\n-\n extern \"C\" int\n rust_uv_guess_handle(int fd) {\n-    return uv_guess_handle(fd);\n-}\n-\n-extern \"C\" int\n-rust_uv_signal_init(uv_loop_t* loop, uv_signal_t* handle) {\n-  return uv_signal_init(loop, handle);\n-}\n-\n-extern \"C\" int\n-rust_uv_signal_start(uv_signal_t* handle, uv_signal_cb signal_cb, int signum) {\n-  return uv_signal_start(handle, signal_cb, signum);\n-}\n-\n-extern \"C\" int\n-rust_uv_signal_stop(uv_signal_t* handle) {\n-  return uv_signal_stop(handle);\n+  return uv_guess_handle(fd);\n }"}, {"sha": "629a807266182f10330717afb453fa082bb013ea", "filename": "src/test/run-pass/closure-reform.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Ftest%2Frun-pass%2Fclosure-reform.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Ftest%2Frun-pass%2Fclosure-reform.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fclosure-reform.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -67,7 +67,8 @@ pub fn main() {\n     call_that(|x, y| *x + *y - z);\n \n     call_cramped(|| 1, || unsafe {\n-        cast::transmute(&100)\n+        static a: uint = 100;\n+        cast::transmute(&a)\n     });\n \n     // External functions"}, {"sha": "f45889eeb03b6476dbd81893fbdc01c1cb5c9f1d", "filename": "src/test/run-pass/rtio-processes.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/b5e602ac563422e13a18be9f79100f96359d582a/src%2Ftest%2Frun-pass%2Frtio-processes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e602ac563422e13a18be9f79100f96359d582a/src%2Ftest%2Frun-pass%2Frtio-processes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Frtio-processes.rs?ref=b5e602ac563422e13a18be9f79100f96359d582a", "patch": "@@ -23,8 +23,8 @@\n //\n // See #9341\n \n+use std::rt::io;\n use std::rt::io::process::{Process, ProcessConfig, CreatePipe, Ignored};\n-use std::rt::io::{Reader, Writer};\n use std::str;\n \n #[test]\n@@ -55,10 +55,10 @@ fn smoke_failure() {\n         cwd: None,\n         io: io,\n     };\n-    let p = Process::new(args);\n-    assert!(p.is_some());\n-    let mut p = p.unwrap();\n-    assert!(p.wait() != 0);\n+    match io::result(|| Process::new(args)) {\n+        Ok(*) => fail!(),\n+        Err(*) => {}\n+    }\n }\n \n #[test]"}]}