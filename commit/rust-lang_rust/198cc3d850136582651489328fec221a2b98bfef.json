{"sha": "198cc3d850136582651489328fec221a2b98bfef", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE5OGNjM2Q4NTAxMzY1ODI2NTE0ODkzMjhmZWMyMjFhMmI5OGJmZWY=", "commit": {"author": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2014-02-28T20:54:01Z"}, "committer": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2014-03-02T06:40:52Z"}, "message": "libsyntax: Fix errors arising from the automated `~[T]` conversion", "tree": {"sha": "fe47f6fab3d4ead61053684613d0b1852ec7e311", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fe47f6fab3d4ead61053684613d0b1852ec7e311"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/198cc3d850136582651489328fec221a2b98bfef", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/198cc3d850136582651489328fec221a2b98bfef", "html_url": "https://github.com/rust-lang/rust/commit/198cc3d850136582651489328fec221a2b98bfef", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/198cc3d850136582651489328fec221a2b98bfef/comments", "author": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "58fd6ab90db3eb68c94695e1254a73e57bc44658", "url": "https://api.github.com/repos/rust-lang/rust/commits/58fd6ab90db3eb68c94695e1254a73e57bc44658", "html_url": "https://github.com/rust-lang/rust/commit/58fd6ab90db3eb68c94695e1254a73e57bc44658"}], "stats": {"total": 883, "additions": 577, "deletions": 306}, "files": [{"sha": "9b6acdd9b9ee554d670f02e5682ec7c12bc30e67", "filename": "src/libstd/vec_ng.rs", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibstd%2Fvec_ng.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibstd%2Fvec_ng.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fvec_ng.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -16,6 +16,7 @@ use clone::Clone;\n use cmp::{Eq, Ordering, TotalEq, TotalOrd};\n use container::Container;\n use default::Default;\n+use fmt;\n use iter::{DoubleEndedIterator, FromIterator, Iterator};\n use libc::{free, c_void};\n use mem::{size_of, move_val_init};\n@@ -82,6 +83,26 @@ impl<T: Clone> Vec<T> {\n             self.push((*element).clone())\n         }\n     }\n+\n+\n+    pub fn grow(&mut self, n: uint, initval: &T) {\n+        let new_len = self.len() + n;\n+        self.reserve(new_len);\n+        let mut i: uint = 0u;\n+\n+        while i < n {\n+            self.push((*initval).clone());\n+            i += 1u;\n+        }\n+    }\n+\n+    pub fn grow_set(&mut self, index: uint, initval: &T, val: T) {\n+        let l = self.len();\n+        if index >= l {\n+            self.grow(index - l + 1u, initval);\n+        }\n+        *self.get_mut(index) = val;\n+    }\n }\n \n impl<T:Clone> Clone for Vec<T> {\n@@ -388,6 +409,12 @@ impl<T> Default for Vec<T> {\n     }\n }\n \n+impl<T:fmt::Show> fmt::Show for Vec<T> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        self.as_slice().fmt(f)\n+    }\n+}\n+\n pub struct MoveItems<T> {\n     priv allocation: *mut c_void, // the block of memory allocated for the vector\n     priv iter: Items<'static, T>"}, {"sha": "a06415bc083a8ab33e992f62a6f2f8093e94f932", "filename": "src/libsyntax/abi.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fabi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fabi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fabi.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -119,7 +119,7 @@ pub fn lookup(name: &str) -> Option<Abi> {\n }\n \n pub fn all_names() -> Vec<&'static str> {\n-    AbiDatas.map(|d| d.name)\n+    AbiDatas.iter().map(|d| d.name).collect()\n }\n \n impl Abi {"}, {"sha": "947463d8f47b116ba93de9f6ff26859690068ba2", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -23,6 +23,7 @@ use std::cell::RefCell;\n use collections::HashMap;\n use std::option::Option;\n use std::rc::Rc;\n+use std::vec_ng::Vec;\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n /// A pointer abstraction. FIXME(eddyb) #10676 use Rc<T> in the future.\n@@ -1193,6 +1194,8 @@ mod test {\n     use codemap::*;\n     use super::*;\n \n+    use std::vec_ng::Vec;\n+\n     fn is_freeze<T: Freeze>() {}\n \n     // Assert that the AST remains Freeze (#10693)."}, {"sha": "56a99736866f6a037fdc48413c36ad3ac702d48a", "filename": "src/libsyntax/ast_map.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fast_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fast_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_map.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -23,6 +23,7 @@ use std::cell::RefCell;\n use std::iter;\n use std::vec;\n use std::fmt;\n+use std::vec_ng::Vec;\n \n #[deriving(Clone, Eq)]\n pub enum PathElem {\n@@ -191,7 +192,11 @@ pub struct Map {\n impl Map {\n     fn find_entry(&self, id: NodeId) -> Option<MapEntry> {\n         let map = self.map.borrow();\n-        map.get().get(id as uint).map(|x| *x)\n+        if map.get().len() > id as uint {\n+            Some(*map.get().get(id as uint))\n+        } else {\n+            None\n+        }\n     }\n \n     /// Retrieve the Node corresponding to `id`, failing if it cannot"}, {"sha": "db9ea480e96206fb877393f2566bacab40a3d1b5", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 13, "deletions": 10, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -23,6 +23,7 @@ use std::cmp;\n use collections::HashMap;\n use std::u32;\n use std::local_data;\n+use std::vec_ng::Vec;\n \n pub fn path_name_i(idents: &[Ident]) -> ~str {\n     // FIXME: Bad copies (#2543 -- same for everything else that says \"bad\")\n@@ -795,7 +796,7 @@ pub fn resolve_internal(id : Ident,\n             let resolved = {\n                 let result = {\n                     let table = table.table.borrow();\n-                    table.get()[id.ctxt]\n+                    *table.get().get(id.ctxt as uint)\n                 };\n                 match result {\n                     EmptyCtxt => id.name,\n@@ -844,7 +845,7 @@ pub fn marksof(ctxt: SyntaxContext, stopname: Name, table: &SCTable) -> Vec<Mrk>\n     loop {\n         let table_entry = {\n             let table = table.table.borrow();\n-            table.get()[loopvar]\n+            *table.get().get(loopvar as uint)\n         };\n         match table_entry {\n             EmptyCtxt => {\n@@ -873,7 +874,7 @@ pub fn marksof(ctxt: SyntaxContext, stopname: Name, table: &SCTable) -> Vec<Mrk>\n pub fn mtwt_outer_mark(ctxt: SyntaxContext) -> Mrk {\n     let sctable = get_sctable();\n     let table = sctable.table.borrow();\n-    match table.get()[ctxt] {\n+    match *table.get().get(ctxt as uint) {\n         ast::Mark(mrk,_) => mrk,\n         _ => fail!(\"can't retrieve outer mark when outside is not a mark\")\n     }\n@@ -901,7 +902,7 @@ pub fn getLast(arr: &Vec<Mrk> ) -> Mrk {\n pub fn path_name_eq(a : &ast::Path, b : &ast::Path) -> bool {\n     (a.span == b.span)\n     && (a.global == b.global)\n-    && (segments_name_eq(a.segments, b.segments))\n+    && (segments_name_eq(a.segments.as_slice(), b.segments.as_slice()))\n }\n \n // are two arrays of segments equal when compared unhygienically?\n@@ -938,6 +939,8 @@ mod test {\n     use opt_vec;\n     use collections::HashMap;\n \n+    use std::vec_ng::Vec;\n+\n     fn ident_to_segment(id : &Ident) -> PathSegment {\n         PathSegment {identifier:id.clone(),\n                      lifetimes: opt_vec::Empty,\n@@ -1000,7 +1003,7 @@ mod test {\n         let mut result = Vec::new();\n         loop {\n             let table = table.table.borrow();\n-            match table.get()[sc] {\n+            match *table.get().get(sc as uint) {\n                 EmptyCtxt => {return result;},\n                 Mark(mrk,tail) => {\n                     result.push(M(mrk));\n@@ -1024,9 +1027,9 @@ mod test {\n         assert_eq!(unfold_test_sc(test_sc.clone(),EMPTY_CTXT,&mut t),4);\n         {\n             let table = t.table.borrow();\n-            assert!(table.get()[2] == Mark(9,0));\n-            assert!(table.get()[3] == Rename(id(101,0),14,2));\n-            assert!(table.get()[4] == Mark(3,3));\n+            assert!(*table.get().get(2) == Mark(9,0));\n+            assert!(*table.get().get(3) == Rename(id(101,0),14,2));\n+            assert!(*table.get().get(4) == Mark(3,3));\n         }\n         assert_eq!(refold_test_sc(4,&t),test_sc);\n     }\n@@ -1045,8 +1048,8 @@ mod test {\n         assert_eq!(unfold_marks(vec!(3,7),EMPTY_CTXT,&mut t),3);\n         {\n             let table = t.table.borrow();\n-            assert!(table.get()[2] == Mark(7,0));\n-            assert!(table.get()[3] == Mark(3,2));\n+            assert!(*table.get().get(2) == Mark(7,0));\n+            assert!(*table.get().get(3) == Mark(3,2));\n         }\n     }\n "}, {"sha": "ed56ef15a1c8b7ceee5846d4c275189924ff6208", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,7 @@ use parse::token;\n use crateid::CrateId;\n \n use collections::HashSet;\n+use std::vec_ng::Vec;\n \n pub trait AttrMetaMethods {\n     // This could be changed to `fn check_name(&self, name: InternedString) ->\n@@ -226,7 +227,8 @@ pub fn sort_meta_items(items: &[@MetaItem]) -> Vec<@MetaItem> {\n         match m.node {\n             MetaList(ref n, ref mis) => {\n                 @Spanned {\n-                    node: MetaList((*n).clone(), sort_meta_items(*mis)),\n+                    node: MetaList((*n).clone(),\n+                                   sort_meta_items(mis.as_slice())),\n                     .. /*bad*/ (*m).clone()\n                 }\n             }\n@@ -243,7 +245,7 @@ pub fn find_linkage_metas(attrs: &[Attribute]) -> Vec<@MetaItem> {\n     let mut result = Vec::new();\n     for attr in attrs.iter().filter(|at| at.name().equiv(&(\"link\"))) {\n         match attr.meta().node {\n-            MetaList(_, ref items) => result.push_all(*items),\n+            MetaList(_, ref items) => result.push_all(items.as_slice()),\n             _ => ()\n         }\n     }\n@@ -272,9 +274,9 @@ pub fn find_inline_attr(attrs: &[Attribute]) -> InlineAttr {\n         match attr.node.value.node {\n           MetaWord(ref n) if n.equiv(&(\"inline\")) => InlineHint,\n           MetaList(ref n, ref items) if n.equiv(&(\"inline\")) => {\n-            if contains_name(*items, \"always\") {\n+            if contains_name(items.as_slice(), \"always\") {\n                 InlineAlways\n-            } else if contains_name(*items, \"never\") {\n+            } else if contains_name(items.as_slice(), \"never\") {\n                 InlineNever\n             } else {\n                 InlineHint"}, {"sha": "6f17505c902279ee302d0bb241e7d180f10a81c1", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -23,6 +23,7 @@ source code snippets, etc.\n \n use std::cell::RefCell;\n use std::cmp;\n+use std::vec_ng::Vec;\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n pub trait Pos {\n@@ -224,14 +225,14 @@ impl FileMap {\n         // the new charpos must be > the last one (or it's the first one).\n         let mut lines = self.lines.borrow_mut();;\n         let line_len = lines.get().len();\n-        assert!(line_len == 0 || (lines.get()[line_len - 1] < pos))\n+        assert!(line_len == 0 || (*lines.get().get(line_len - 1) < pos))\n         lines.get().push(pos);\n     }\n \n     // get a line from the list of pre-computed line-beginnings\n     pub fn get_line(&self, line: int) -> ~str {\n         let mut lines = self.lines.borrow_mut();\n-        let begin: BytePos = lines.get()[line] - self.start_pos;\n+        let begin: BytePos = *lines.get().get(line as uint) - self.start_pos;\n         let begin = begin.to_uint();\n         let slice = self.src.slice_from(begin);\n         match slice.find('\\n') {\n@@ -373,7 +374,7 @@ impl CodeMap {\n         let mut b = len;\n         while b - a > 1u {\n             let m = (a + b) / 2u;\n-            if files[m].start_pos > pos {\n+            if files.get(m).start_pos > pos {\n                 b = m;\n             } else {\n                 a = m;\n@@ -383,7 +384,7 @@ impl CodeMap {\n         // filemap, but are not the filemaps we want (because they are length 0, they cannot\n         // contain what we are looking for). So, rewind until we find a useful filemap.\n         loop {\n-            let lines = files[a].lines.borrow();\n+            let lines = files.get(a).lines.borrow();\n             let lines = lines.get();\n             if lines.len() > 0 {\n                 break;\n@@ -405,13 +406,13 @@ impl CodeMap {\n         let idx = self.lookup_filemap_idx(pos);\n \n         let files = self.files.borrow();\n-        let f = files.get()[idx];\n+        let f = *files.get().get(idx);\n         let mut a = 0u;\n         let mut lines = f.lines.borrow_mut();\n         let mut b = lines.get().len();\n         while b - a > 1u {\n             let m = (a + b) / 2u;\n-            if lines.get()[m] > pos { b = m; } else { a = m; }\n+            if *lines.get().get(m) > pos { b = m; } else { a = m; }\n         }\n         return FileMapAndLine {fm: f, line: a};\n     }\n@@ -421,7 +422,7 @@ impl CodeMap {\n         let line = a + 1u; // Line numbers start at 1\n         let chpos = self.bytepos_to_file_charpos(pos);\n         let lines = f.lines.borrow();\n-        let linebpos = lines.get()[a];\n+        let linebpos = *lines.get().get(a);\n         let linechpos = self.bytepos_to_file_charpos(linebpos);\n         debug!(\"codemap: byte pos {:?} is on the line at byte pos {:?}\",\n                pos, linebpos);\n@@ -440,7 +441,7 @@ impl CodeMap {\n         -> FileMapAndBytePos {\n         let idx = self.lookup_filemap_idx(bpos);\n         let files = self.files.borrow();\n-        let fm = files.get()[idx];\n+        let fm = *files.get().get(idx);\n         let offset = bpos - fm.start_pos;\n         return FileMapAndBytePos {fm: fm, pos: offset};\n     }\n@@ -450,7 +451,7 @@ impl CodeMap {\n         debug!(\"codemap: converting {:?} to char pos\", bpos);\n         let idx = self.lookup_filemap_idx(bpos);\n         let files = self.files.borrow();\n-        let map = files.get()[idx];\n+        let map = files.get().get(idx);\n \n         // The number of extra bytes due to multibyte chars in the FileMap\n         let mut total_extra_bytes = 0;"}, {"sha": "e5136b7081b336e940bc1b1c02fd3cac2b096c0d", "filename": "src/libsyntax/crateid.rs", "status": "modified", "additions": 9, "deletions": 6, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fcrateid.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fcrateid.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcrateid.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -19,6 +19,7 @@ use std::fmt;\n /// to be `0.0`.\n \n use std::from_str::FromStr;\n+use std::vec_ng::Vec;\n \n #[deriving(Clone, Eq)]\n pub struct CrateId {\n@@ -49,24 +50,26 @@ impl fmt::Show for CrateId {\n impl FromStr for CrateId {\n     fn from_str(s: &str) -> Option<CrateId> {\n         let pieces: Vec<&str> = s.splitn('#', 1).collect();\n-        let path = pieces[0].to_owned();\n+        let path = pieces.get(0).to_owned();\n \n         if path.starts_with(\"/\") || path.ends_with(\"/\") ||\n             path.starts_with(\".\") || path.is_empty() {\n             return None;\n         }\n \n         let path_pieces: Vec<&str> = path.rsplitn('/', 1).collect();\n-        let inferred_name = path_pieces[0];\n+        let inferred_name = *path_pieces.get(0);\n \n         let (name, version) = if pieces.len() == 1 {\n             (inferred_name.to_owned(), None)\n         } else {\n-            let hash_pieces: Vec<&str> = pieces[1].splitn(':', 1).collect();\n+            let hash_pieces: Vec<&str> = pieces.get(1)\n+                                               .splitn(':', 1)\n+                                               .collect();\n             let (hash_name, hash_version) = if hash_pieces.len() == 1 {\n-                (\"\", hash_pieces[0])\n+                (\"\", *hash_pieces.get(0))\n             } else {\n-                (hash_pieces[0], hash_pieces[1])\n+                (*hash_pieces.get(0), *hash_pieces.get(1))\n             };\n \n             let name = if !hash_name.is_empty() {\n@@ -89,7 +92,7 @@ impl FromStr for CrateId {\n         };\n \n         Some(CrateId {\n-            path: path,\n+            path: path.clone(),\n             name: name,\n             version: version,\n         })"}, {"sha": "c0c64d6fd60b293770670a3479ac3ee3a0d56dfa", "filename": "src/libsyntax/diagnostic.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fdiagnostic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fdiagnostic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostic.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -325,7 +325,7 @@ fn highlight_lines(err: &mut EmitterWriter,\n     if lines.lines.len() == 1u {\n         let lo = cm.lookup_char_pos(sp.lo);\n         let mut digits = 0u;\n-        let mut num = (lines.lines[0] + 1u) / 10u;\n+        let mut num = (*lines.lines.get(0) + 1u) / 10u;\n \n         // how many digits must be indent past?\n         while num > 0u { num /= 10u; digits += 1u; }\n@@ -337,7 +337,7 @@ fn highlight_lines(err: &mut EmitterWriter,\n         // part of the 'filename:line ' part of the previous line.\n         let skip = fm.name.len() + digits + 3u;\n         for _ in range(0, skip) { s.push_char(' '); }\n-        let orig = fm.get_line(lines.lines[0] as int);\n+        let orig = fm.get_line(*lines.lines.get(0) as int);\n         for pos in range(0u, left-skip) {\n             let curChar = orig[pos] as char;\n             // Whenever a tab occurs on the previous line, we insert one on"}, {"sha": "6080613460da219c0e3976de88bb1df44677bfd3", "filename": "src/libsyntax/ext/asm.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fasm.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -20,6 +20,8 @@ use parse;\n use parse::token::InternedString;\n use parse::token;\n \n+use std::vec_ng::Vec;\n+\n enum State {\n     Asm,\n     Outputs,\n@@ -42,7 +44,9 @@ pub fn expand_asm(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                -> base::MacResult {\n     let mut p = parse::new_parser_from_tts(cx.parse_sess(),\n                                            cx.cfg(),\n-                                           tts.to_owned());\n+                                           tts.iter()\n+                                              .map(|x| (*x).clone())\n+                                              .collect());\n \n     let mut asm = InternedString::new(\"\");\n     let mut asm_str_style = None;"}, {"sha": "e9fe21eded60c87ab17f43a55c42eea7cd1b9d31", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -20,6 +20,7 @@ use parse::token::{InternedString, intern, str_to_ident};\n use util::small_vector::SmallVector;\n \n use collections::HashMap;\n+use std::vec_ng::Vec;\n \n // new-style macro! tt code:\n //\n@@ -461,7 +462,9 @@ pub fn get_exprs_from_tts(cx: &ExtCtxt,\n                           tts: &[ast::TokenTree]) -> Option<Vec<@ast::Expr> > {\n     let mut p = parse::new_parser_from_tts(cx.parse_sess(),\n                                            cx.cfg(),\n-                                           tts.to_owned());\n+                                           tts.iter()\n+                                              .map(|x| (*x).clone())\n+                                              .collect());\n     let mut es = Vec::new();\n     while p.token != token::EOF {\n         if es.len() != 0 && !p.eat(&token::COMMA) {\n@@ -553,6 +556,7 @@ impl SyntaxEnv {\n     }\n \n     pub fn info<'a>(&'a mut self) -> &'a mut BlockInfo {\n-        &mut self.chain[self.chain.len()-1].info\n+        let last_chain_index = self.chain.len() - 1;\n+        &mut self.chain.get_mut(last_chain_index).info\n     }\n }"}, {"sha": "34625923ea1f6fb4ba0c4b1d37d8f38e1e6c4db4", "filename": "src/libsyntax/ext/build.rs", "status": "modified", "additions": 22, "deletions": 11, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbuild.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,8 @@ use opt_vec::OptVec;\n use parse::token::special_idents;\n use parse::token;\n \n+use std::vec_ng::Vec;\n+\n pub struct Field {\n     ident: ast::Ident,\n     ex: @ast::Expr\n@@ -132,7 +134,7 @@ pub trait AstBuilder {\n \n     fn expr_vstore(&self, sp: Span, expr: @ast::Expr, vst: ast::ExprVstore) -> @ast::Expr;\n     fn expr_vec(&self, sp: Span, exprs: Vec<@ast::Expr> ) -> @ast::Expr;\n-    fn expr_vec_uniq(&self, sp: Span, exprs: Vec<@ast::Expr> ) -> @ast::Expr;\n+    fn expr_vec_ng(&self, sp: Span) -> @ast::Expr;\n     fn expr_vec_slice(&self, sp: Span, exprs: Vec<@ast::Expr> ) -> @ast::Expr;\n     fn expr_str(&self, sp: Span, s: InternedString) -> @ast::Expr;\n     fn expr_str_uniq(&self, sp: Span, s: InternedString) -> @ast::Expr;\n@@ -580,8 +582,13 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n     fn expr_vec(&self, sp: Span, exprs: Vec<@ast::Expr> ) -> @ast::Expr {\n         self.expr(sp, ast::ExprVec(exprs, ast::MutImmutable))\n     }\n-    fn expr_vec_uniq(&self, sp: Span, exprs: Vec<@ast::Expr> ) -> @ast::Expr {\n-        self.expr_vstore(sp, self.expr_vec(sp, exprs), ast::ExprVstoreUniq)\n+    fn expr_vec_ng(&self, sp: Span) -> @ast::Expr {\n+        self.expr_call_global(sp,\n+                              vec!(self.ident_of(\"std\"),\n+                                   self.ident_of(\"vec_ng\"),\n+                                   self.ident_of(\"Vec\"),\n+                                   self.ident_of(\"new\")),\n+                              Vec::new())\n     }\n     fn expr_vec_slice(&self, sp: Span, exprs: Vec<@ast::Expr> ) -> @ast::Expr {\n         self.expr_vstore(sp, self.expr_vec(sp, exprs), ast::ExprVstoreSlice)\n@@ -701,14 +708,12 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n \n         self.expr(span, ast::ExprFnBlock(fn_decl, blk))\n     }\n-    fn lambda0(&self, _span: Span, blk: P<ast::Block>) -> @ast::Expr {\n-        let blk_e = self.expr(blk.span, ast::ExprBlock(blk));\n-        quote_expr!(self, || $blk_e )\n+    fn lambda0(&self, span: Span, blk: P<ast::Block>) -> @ast::Expr {\n+        self.lambda(span, Vec::new(), blk)\n     }\n \n-    fn lambda1(&self, _span: Span, blk: P<ast::Block>, ident: ast::Ident) -> @ast::Expr {\n-        let blk_e = self.expr(blk.span, ast::ExprBlock(blk));\n-        quote_expr!(self, |$ident| $blk_e )\n+    fn lambda1(&self, span: Span, blk: P<ast::Block>, ident: ast::Ident) -> @ast::Expr {\n+        self.lambda(span, vec!(ident), blk)\n     }\n \n     fn lambda_expr(&self, span: Span, ids: Vec<ast::Ident> , expr: @ast::Expr) -> @ast::Expr {\n@@ -721,7 +726,11 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n         self.lambda1(span, self.block_expr(expr), ident)\n     }\n \n-    fn lambda_stmts(&self, span: Span, ids: Vec<ast::Ident> , stmts: Vec<@ast::Stmt> ) -> @ast::Expr {\n+    fn lambda_stmts(&self,\n+                    span: Span,\n+                    ids: Vec<ast::Ident>,\n+                    stmts: Vec<@ast::Stmt>)\n+                    -> @ast::Expr {\n         self.lambda(span, ids, self.block(span, stmts, None))\n     }\n     fn lambda_stmts_0(&self, span: Span, stmts: Vec<@ast::Stmt> ) -> @ast::Expr {\n@@ -921,7 +930,9 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n         self.view_use(sp, vis,\n                       vec!(@respan(sp,\n                                 ast::ViewPathList(self.path(sp, path),\n-                                                  imports,\n+                                                  imports.iter()\n+                                                         .map(|x| *x)\n+                                                         .collect(),\n                                                   ast::DUMMY_NODE_ID))))\n     }\n "}, {"sha": "6123fd4d3d4907d1ca516e2ce49886d268889f30", "filename": "src/libsyntax/ext/bytes.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fbytes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fbytes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbytes.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -17,6 +17,7 @@ use ext::base;\n use ext::build::AstBuilder;\n \n use std::char;\n+use std::vec_ng::Vec;\n \n pub fn expand_syntax_ext(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]) -> base::MacResult {\n     // Gather all argument expressions"}, {"sha": "5d11a0d1e2ff23d8dbe2d843f1dd866bdd5b91f0", "filename": "src/libsyntax/ext/cfg.rs", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fcfg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fcfg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fcfg.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -26,10 +26,14 @@ use parse::token::InternedString;\n use parse::token;\n use parse;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_cfg(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]) -> base::MacResult {\n     let mut p = parse::new_parser_from_tts(cx.parse_sess(),\n                                            cx.cfg(),\n-                                           tts.to_owned());\n+                                           tts.iter()\n+                                              .map(|x| (*x).clone())\n+                                              .collect());\n \n     let mut cfgs = Vec::new();\n     // parse `cfg!(meta_item, meta_item(x,y), meta_item=\"foo\", ...)`\n@@ -42,7 +46,8 @@ pub fn expand_cfg(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]) -> base::M\n     // test_cfg searches for meta items looking like `cfg(foo, ...)`\n     let in_cfg = &[cx.meta_list(sp, InternedString::new(\"cfg\"), cfgs)];\n \n-    let matches_cfg = attr::test_cfg(cx.cfg(), in_cfg.iter().map(|&x| x));\n+    let matches_cfg = attr::test_cfg(cx.cfg().as_slice(),\n+                                     in_cfg.iter().map(|&x| x));\n     let e = cx.expr_bool(sp, matches_cfg);\n     MRExpr(e)\n }"}, {"sha": "feda1694ff1936eb359928a3b801ea10d30e65ad", "filename": "src/libsyntax/ext/deriving/clone.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fclone.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fclone.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fclone.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,6 +14,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_clone(cx: &mut ExtCtxt,\n                              span: Span,\n                              mitem: @MetaItem,\n@@ -99,7 +101,7 @@ fn cs_clone(\n                                                                  name))\n     }\n \n-    if all_fields.len() >= 1 && all_fields[0].name.is_none() {\n+    if all_fields.len() >= 1 && all_fields.get(0).name.is_none() {\n         // enum-like\n         let subcalls = all_fields.map(subcall);\n         cx.expr_call_ident(trait_span, ctor_ident, subcalls)"}, {"sha": "1e7199ccc9557ef7428138e9489853c0f58fa3f6", "filename": "src/libsyntax/ext/deriving/cmp/eq.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Feq.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Feq.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Feq.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,6 +14,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_eq(cx: &mut ExtCtxt,\n                           span: Span,\n                           mitem: @MetaItem,"}, {"sha": "66f459882397c929a1cf888f7ddbfc95e2359d3f", "filename": "src/libsyntax/ext/deriving/cmp/ord.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ford.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ford.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ford.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -15,6 +15,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_ord(cx: &mut ExtCtxt,\n                            span: Span,\n                            mitem: @MetaItem,"}, {"sha": "2b3c0b9ea69153b1e0f8f81300329608e329a200", "filename": "src/libsyntax/ext/deriving/cmp/totaleq.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ftotaleq.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ftotaleq.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ftotaleq.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,6 +14,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_totaleq(cx: &mut ExtCtxt,\n                                span: Span,\n                                mitem: @MetaItem,"}, {"sha": "89a344bdb7b3c13d62d657dc95f1e215fc009663", "filename": "src/libsyntax/ext/deriving/cmp/totalord.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ftotalord.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ftotalord.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fcmp%2Ftotalord.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,7 +14,9 @@ use codemap::Span;\n use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n+\n use std::cmp::{Ordering, Equal, Less, Greater};\n+use std::vec_ng::Vec;\n \n pub fn expand_deriving_totalord(cx: &mut ExtCtxt,\n                                 span: Span,"}, {"sha": "bc6d69c7ccabe8b4570b7391b9570fb39c414912", "filename": "src/libsyntax/ext/deriving/decodable.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,8 @@ use ext::deriving::generic::*;\n use parse::token::InternedString;\n use parse::token;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_decodable(cx: &mut ExtCtxt,\n                                  span: Span,\n                                  mitem: @MetaItem,"}, {"sha": "8259459f57ab60305d8a17e322d2f5f1c4b61952", "filename": "src/libsyntax/ext/deriving/default.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fdefault.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fdefault.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fdefault.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,6 +14,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_default(cx: &mut ExtCtxt,\n                             span: Span,\n                             mitem: @MetaItem,"}, {"sha": "091ff7b9c90bd360f1e4ddfdd9d5bae934591ebe", "filename": "src/libsyntax/ext/deriving/encodable.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fencodable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fencodable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fencodable.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -89,6 +89,8 @@ use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n use parse::token;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_encodable(cx: &mut ExtCtxt,\n                                  span: Span,\n                                  mitem: @MetaItem,"}, {"sha": "1dc474551cf7c03127c73dbdd8740fa6f2e8dd19", "filename": "src/libsyntax/ext/deriving/generic.rs", "status": "modified", "additions": 34, "deletions": 20, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -188,7 +188,8 @@ use opt_vec;\n use parse::token::InternedString;\n use parse::token;\n \n-use std::vec;\n+use std::vec_ng::Vec;\n+use std::vec_ng;\n \n pub use self::ty::*;\n mod ty;\n@@ -410,7 +411,7 @@ impl<'a> TraitDef<'a> {\n         cx.item(\n             self.span,\n             ident,\n-            vec_ng::append(vec!(doc_attr), self.attributes),\n+            vec_ng::append(vec!(doc_attr), self.attributes.as_slice()),\n             ast::ItemImpl(trait_generics, opt_trait_ref,\n                           self_type, methods.map(|x| *x)))\n     }\n@@ -431,13 +432,15 @@ impl<'a> TraitDef<'a> {\n                     self,\n                     struct_def,\n                     type_ident,\n-                    self_args, nonself_args)\n+                    self_args.as_slice(),\n+                    nonself_args.as_slice())\n             } else {\n                 method_def.expand_struct_method_body(cx,\n                                                      self,\n                                                      struct_def,\n                                                      type_ident,\n-                                                     self_args, nonself_args)\n+                                                     self_args.as_slice(),\n+                                                     nonself_args.as_slice())\n             };\n \n             method_def.create_method(cx, self,\n@@ -465,13 +468,15 @@ impl<'a> TraitDef<'a> {\n                     self,\n                     enum_def,\n                     type_ident,\n-                    self_args, nonself_args)\n+                    self_args.as_slice(),\n+                    nonself_args.as_slice())\n             } else {\n                 method_def.expand_enum_method_body(cx,\n                                                    self,\n                                                    enum_def,\n                                                    type_ident,\n-                                                   self_args, nonself_args)\n+                                                   self_args.as_slice(),\n+                                                   nonself_args.as_slice())\n             };\n \n             method_def.create_method(cx, self,\n@@ -666,14 +671,15 @@ impl<'a> MethodDef<'a> {\n \n         // transpose raw_fields\n         let fields = if raw_fields.len() > 0 {\n-            raw_fields[0].iter()\n-                         .enumerate()\n-                         .map(|(i, &(span, opt_id, field))| {\n-                let other_fields = raw_fields.tail().map(|l| {\n-                    match &l[i] {\n+            raw_fields.get(0)\n+                      .iter()\n+                      .enumerate()\n+                      .map(|(i, &(span, opt_id, field))| {\n+                let other_fields = raw_fields.tail().iter().map(|l| {\n+                    match l.get(i) {\n                         &(_, _, ex) => ex\n                     }\n-                });\n+                }).collect();\n                 FieldInfo {\n                     span: span,\n                     name: opt_id,\n@@ -820,17 +826,17 @@ impl<'a> MethodDef<'a> {\n                 Some(variant_index) => {\n                     // `ref` inside let matches is buggy. Causes havoc wih rusc.\n                     // let (variant_index, ref self_vec) = matches_so_far[0];\n-                    let (variant, self_vec) = match matches_so_far[0] {\n-                        (_, v, ref s) => (v, s)\n+                    let (variant, self_vec) = match matches_so_far.get(0) {\n+                        &(_, v, ref s) => (v, s)\n                     };\n \n-                    let mut enum_matching_fields = vec::from_elem(self_vec.len(), Vec::new());\n+                    let mut enum_matching_fields = Vec::from_elem(self_vec.len(), Vec::new());\n \n                     for triple in matches_so_far.tail().iter() {\n                         match triple {\n                             &(_, _, ref other_fields) => {\n                                 for (i, &(_, _, e)) in other_fields.iter().enumerate() {\n-                                    enum_matching_fields[i].push(e);\n+                                    enum_matching_fields.get_mut(i).push(e);\n                                 }\n                             }\n                         }\n@@ -849,7 +855,7 @@ impl<'a> MethodDef<'a> {\n                     substructure = EnumMatching(variant_index, variant, field_tuples);\n                 }\n                 None => {\n-                    substructure = EnumNonMatching(*matches_so_far);\n+                    substructure = EnumNonMatching(matches_so_far.as_slice());\n                 }\n             }\n             self.call_substructure_method(cx, trait_, type_ident,\n@@ -877,7 +883,7 @@ impl<'a> MethodDef<'a> {\n                 };\n \n                 // matching-variant match\n-                let variant = enum_def.variants[index];\n+                let variant = *enum_def.variants.get(index);\n                 let (pattern, idents) = trait_.create_enum_variant_pattern(cx,\n                                                                            variant,\n                                                                            current_match_str,\n@@ -1149,11 +1155,19 @@ pub fn cs_fold(use_foldl: bool,\n         EnumMatching(_, _, ref all_fields) | Struct(ref all_fields) => {\n             if use_foldl {\n                 all_fields.iter().fold(base, |old, field| {\n-                    f(cx, field.span, old, field.self_, field.other)\n+                    f(cx,\n+                      field.span,\n+                      old,\n+                      field.self_,\n+                      field.other.as_slice())\n                 })\n             } else {\n                 all_fields.rev_iter().fold(base, |old, field| {\n-                    f(cx, field.span, old, field.self_, field.other)\n+                    f(cx,\n+                      field.span,\n+                      old,\n+                      field.self_,\n+                      field.other.as_slice())\n                 })\n             }\n         },"}, {"sha": "1d6cfab120d2de2087a1ef8909518950fd924b31", "filename": "src/libsyntax/ext/deriving/hash.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fhash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fhash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fhash.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,6 +14,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_hash(cx: &mut ExtCtxt,\n                             span: Span,\n                             mitem: @MetaItem,"}, {"sha": "ecd042eb172ef251fefb239e1dcf60a0c031e6eb", "filename": "src/libsyntax/ext/deriving/primitive.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fprimitive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fprimitive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fprimitive.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -16,6 +16,8 @@ use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n use parse::token::InternedString;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_from_primitive(cx: &mut ExtCtxt,\n                                       span: Span,\n                                       mitem: @MetaItem,"}, {"sha": "da9679eb65578a1aef250e66b5d9970f9f65be38", "filename": "src/libsyntax/ext/deriving/rand.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Frand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Frand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Frand.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -16,6 +16,8 @@ use ext::build::{AstBuilder};\n use ext::deriving::generic::*;\n use opt_vec;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_rand(cx: &mut ExtCtxt,\n                             span: Span,\n                             mitem: @MetaItem,\n@@ -64,7 +66,7 @@ fn rand_substructure(cx: &mut ExtCtxt, trait_span: Span, substr: &Substructure)\n     let rand_call = |cx: &mut ExtCtxt, span| {\n         cx.expr_call_global(span,\n                             rand_ident.clone(),\n-                            vec!( rng[0] ))\n+                            vec!( *rng.get(0) ))\n     };\n \n     return match *substr.fields {\n@@ -90,7 +92,7 @@ fn rand_substructure(cx: &mut ExtCtxt, trait_span: Span, substr: &Substructure)\n             // ::std::rand::Rand::rand(rng)\n             let rv_call = cx.expr_call(trait_span,\n                                        rand_name,\n-                                       vec!( rng[0] ));\n+                                       vec!( *rng.get(0) ));\n \n             // need to specify the uint-ness of the random number\n             let uint_ty = cx.ty_ident(trait_span, cx.ident_of(\"uint\"));"}, {"sha": "51399d8efabe97c2a0df4c73a713a32cce7b4f4c", "filename": "src/libsyntax/ext/deriving/show.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fshow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fshow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fshow.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -19,6 +19,7 @@ use ext::deriving::generic::*;\n use parse::token;\n \n use collections::HashMap;\n+use std::vec_ng::Vec;\n \n pub fn expand_deriving_show(cx: &mut ExtCtxt,\n                             span: Span,\n@@ -79,7 +80,7 @@ fn show_substructure(cx: &mut ExtCtxt, span: Span,\n         EnumMatching(_, _, ref fields) if fields.len() == 0 => {}\n \n         Struct(ref fields) | EnumMatching(_, _, ref fields) => {\n-            if fields[0].name.is_none() {\n+            if fields.get(0).name.is_none() {\n                 // tuple struct/\"normal\" variant\n \n                 format_string.push_str(\"(\");\n@@ -135,6 +136,6 @@ fn show_substructure(cx: &mut ExtCtxt, span: Span,\n     // phew, not our responsibility any more!\n     format::expand_preparsed_format_args(cx, span,\n                                          format_closure,\n-                                         format_string, exprs, ~[],\n+                                         format_string, exprs, Vec::new(),\n                                          HashMap::new())\n }"}, {"sha": "b88cd117911c70896d08bbb2e1f9fc8ab858d52a", "filename": "src/libsyntax/ext/deriving/ty.rs", "status": "modified", "additions": 12, "deletions": 5, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fty.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,8 @@ use codemap::{Span,respan};\n use opt_vec;\n use opt_vec::OptVec;\n \n+use std::vec_ng::Vec;\n+\n /// The types of pointers\n pub enum PtrTy<'a> {\n     Send, // ~\n@@ -188,10 +190,10 @@ impl<'a> Ty<'a> {\n fn mk_ty_param(cx: &ExtCtxt, span: Span, name: &str, bounds: &[Path],\n                self_ident: Ident, self_generics: &Generics) -> ast::TyParam {\n     let bounds = opt_vec::from(\n-        bounds.map(|b| {\n+        bounds.iter().map(|b| {\n             let path = b.to_path(cx, span, self_ident, self_generics);\n             cx.typarambound(path)\n-        }));\n+        }).collect());\n     cx.typaram(cx.ident_of(name), bounds, None)\n }\n \n@@ -204,8 +206,8 @@ fn mk_generics(lifetimes: Vec<ast::Lifetime> ,  ty_params: Vec<ast::TyParam> ) -\n \n /// Lifetimes and bounds on type parameters\n pub struct LifetimeBounds<'a> {\n-    lifetimes: Vec<&'a str> ,\n-    bounds: vec!((&'a str, Vec<Path<'a>> ))\n+    lifetimes: Vec<&'a str>,\n+    bounds: Vec<(&'a str, Vec<Path<'a>>)>,\n }\n \n impl<'a> LifetimeBounds<'a> {\n@@ -226,7 +228,12 @@ impl<'a> LifetimeBounds<'a> {\n         let ty_params = self.bounds.map(|t| {\n             match t {\n                 &(ref name, ref bounds) => {\n-                    mk_ty_param(cx, span, *name, *bounds, self_ty, self_generics)\n+                    mk_ty_param(cx,\n+                                span,\n+                                *name,\n+                                bounds.as_slice(),\n+                                self_ty,\n+                                self_generics)\n                 }\n             }\n         });"}, {"sha": "98c0ec9d07238502ce8c6b7d31b7a75eaf785564", "filename": "src/libsyntax/ext/deriving/zero.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fzero.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fderiving%2Fzero.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fzero.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -14,6 +14,8 @@ use ext::base::ExtCtxt;\n use ext::build::AstBuilder;\n use ext::deriving::generic::*;\n \n+use std::vec_ng::Vec;\n+\n pub fn expand_deriving_zero(cx: &mut ExtCtxt,\n                             span: Span,\n                             mitem: @MetaItem,"}, {"sha": "b0b5fa26015ccd6f5ee124ba75e44e93d7f500fb", "filename": "src/libsyntax/ext/env.rs", "status": "modified", "additions": 29, "deletions": 4, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fenv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fenv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fenv.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -19,6 +19,7 @@ use codemap::Span;\n use ext::base::*;\n use ext::base;\n use ext::build::AstBuilder;\n+use opt_vec;\n use parse::token;\n \n use std::os;\n@@ -31,8 +32,30 @@ pub fn expand_option_env(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     };\n \n     let e = match os::getenv(var) {\n-      None => quote_expr!(cx, ::std::option::None::<&'static str>),\n-      Some(s) => quote_expr!(cx, ::std::option::Some($s))\n+      None => {\n+          cx.expr_path(cx.path_all(sp,\n+                                   true,\n+                                   vec!(cx.ident_of(\"std\"),\n+                                        cx.ident_of(\"option\"),\n+                                        cx.ident_of(\"None\")),\n+                                   opt_vec::Empty,\n+                                   vec!(cx.ty_rptr(sp,\n+                                                   cx.ty_ident(sp,\n+                                                        cx.ident_of(\"str\")),\n+                                                   Some(cx.lifetime(sp,\n+                                                        cx.ident_of(\n+                                                            \"static\").name)),\n+                                                   ast::MutImmutable))))\n+      }\n+      Some(s) => {\n+          cx.expr_call_global(sp,\n+                              vec!(cx.ident_of(\"std\"),\n+                                   cx.ident_of(\"option\"),\n+                                   cx.ident_of(\"Some\")),\n+                              vec!(cx.expr_str(sp,\n+                                               token::intern_and_get_ident(\n+                                          s))))\n+      }\n     };\n     MRExpr(e)\n }\n@@ -48,7 +71,9 @@ pub fn expand_env(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n         Some(exprs) => exprs\n     };\n \n-    let var = match expr_to_str(cx, exprs[0], \"expected string literal\") {\n+    let var = match expr_to_str(cx,\n+                                *exprs.get(0),\n+                                \"expected string literal\") {\n         None => return MacResult::dummy_expr(sp),\n         Some((v, _style)) => v\n     };\n@@ -59,7 +84,7 @@ pub fn expand_env(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                                                 var))\n         }\n         2 => {\n-            match expr_to_str(cx, exprs[1], \"expected string literal\") {\n+            match expr_to_str(cx, *exprs.get(1), \"expected string literal\") {\n                 None => return MacResult::dummy_expr(sp),\n                 Some((s, _style)) => s\n             }"}, {"sha": "b162e17f53de1d55223129a031208b7cd2b43469", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 50, "deletions": 33, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -31,6 +31,7 @@ use util::small_vector::SmallVector;\n use std::cast;\n use std::unstable::dynamic_lib::DynamicLibrary;\n use std::os;\n+use std::vec_ng::Vec;\n \n pub fn expand_expr(e: @ast::Expr, fld: &mut MacroExpander) -> @ast::Expr {\n     match e.node {\n@@ -53,7 +54,7 @@ pub fn expand_expr(e: @ast::Expr, fld: &mut MacroExpander) -> @ast::Expr {\n                         // let compilation continue\n                         return MacResult::raw_dummy_expr(e.span);\n                     }\n-                    let extname = pth.segments[0].identifier;\n+                    let extname = pth.segments.get(0).identifier;\n                     let extnamestr = token::get_ident(extname);\n                     // leaving explicit deref here to highlight unbox op:\n                     let marked_after = match fld.extsbox.find(&extname.name) {\n@@ -77,7 +78,7 @@ pub fn expand_expr(e: @ast::Expr, fld: &mut MacroExpander) -> @ast::Expr {\n                             });\n                             let fm = fresh_mark();\n                             // mark before:\n-                            let marked_before = mark_tts(*tts,fm);\n+                            let marked_before = mark_tts(tts.as_slice(), fm);\n \n                             // The span that we pass to the expanders we want to\n                             // be the root of the call stack. That's the most\n@@ -87,7 +88,7 @@ pub fn expand_expr(e: @ast::Expr, fld: &mut MacroExpander) -> @ast::Expr {\n \n                             let expanded = match expandfun.expand(fld.cx,\n                                                    mac_span.call_site,\n-                                                   marked_before) {\n+                                                   marked_before.as_slice()) {\n                                 MRExpr(e) => e,\n                                 MRAny(any_macro) => any_macro.make_expr(),\n                                 _ => {\n@@ -181,7 +182,10 @@ pub fn expand_expr(e: @ast::Expr, fld: &mut MacroExpander) -> @ast::Expr {\n             // `match i.next() { ... }`\n             let match_expr = {\n                 let next_call_expr =\n-                    fld.cx.expr_method_call(span, fld.cx.expr_path(local_path), next_ident, Vec::new());\n+                    fld.cx.expr_method_call(span,\n+                                            fld.cx.expr_path(local_path),\n+                                            next_ident,\n+                                            Vec::new());\n \n                 fld.cx.expr_match(span, next_call_expr, vec!(none_arm, some_arm))\n             };\n@@ -276,7 +280,7 @@ pub fn expand_item(it: @ast::Item, fld: &mut MacroExpander)\n         ast::ItemMac(..) => expand_item_mac(it, fld),\n         ast::ItemMod(_) | ast::ItemForeignMod(_) => {\n             fld.cx.mod_push(it.ident);\n-            let macro_escape = contains_macro_escape(it.attrs);\n+            let macro_escape = contains_macro_escape(it.attrs.as_slice());\n             let result = with_exts_frame!(fld.extsbox,\n                                           macro_escape,\n                                           noop_fold_item(it, fld));\n@@ -309,7 +313,7 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n         _ => fld.cx.span_bug(it.span, \"invalid item macro invocation\")\n     };\n \n-    let extname = pth.segments[0].identifier;\n+    let extname = pth.segments.get(0).identifier;\n     let extnamestr = token::get_ident(extname);\n     let fm = fresh_mark();\n     let expanded = match fld.extsbox.find(&extname.name) {\n@@ -339,8 +343,8 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n                 }\n             });\n             // mark before expansion:\n-            let marked_before = mark_tts(tts,fm);\n-            expander.expand(fld.cx, it.span, marked_before)\n+            let marked_before = mark_tts(tts.as_slice(), fm);\n+            expander.expand(fld.cx, it.span, marked_before.as_slice())\n         }\n         Some(&IdentTT(ref expander, span)) => {\n             if it.ident.name == parse::token::special_idents::invalid.name {\n@@ -358,7 +362,7 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n                 }\n             });\n             // mark before expansion:\n-            let marked_tts = mark_tts(tts,fm);\n+            let marked_tts = mark_tts(tts.as_slice(), fm);\n             expander.expand(fld.cx, it.span, it.ident, marked_tts)\n         }\n         _ => {\n@@ -391,7 +395,7 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n             // yikes... no idea how to apply the mark to this. I'm afraid\n             // we're going to have to wait-and-see on this one.\n             fld.extsbox.insert(intern(name), ext);\n-            if attr::contains_name(it.attrs, \"macro_export\") {\n+            if attr::contains_name(it.attrs.as_slice(), \"macro_export\") {\n                 SmallVector::one(it)\n             } else {\n                 SmallVector::zero()\n@@ -504,7 +508,7 @@ pub fn expand_stmt(s: &Stmt, fld: &mut MacroExpander) -> SmallVector<@Stmt> {\n         fld.cx.span_err(pth.span, \"expected macro name without module separators\");\n         return SmallVector::zero();\n     }\n-    let extname = pth.segments[0].identifier;\n+    let extname = pth.segments.get(0).identifier;\n     let extnamestr = token::get_ident(extname);\n     let marked_after = match fld.extsbox.find(&extname.name) {\n         None => {\n@@ -523,15 +527,15 @@ pub fn expand_stmt(s: &Stmt, fld: &mut MacroExpander) -> SmallVector<@Stmt> {\n             });\n             let fm = fresh_mark();\n             // mark before expansion:\n-            let marked_tts = mark_tts(tts,fm);\n+            let marked_tts = mark_tts(tts.as_slice(), fm);\n \n             // See the comment in expand_expr for why we want the original span,\n             // not the current mac.span.\n             let mac_span = original_span(fld.cx);\n \n             let expanded = match expandfun.expand(fld.cx,\n                                                   mac_span.call_site,\n-                                                  marked_tts) {\n+                                                  marked_tts.as_slice()) {\n                 MRExpr(e) => {\n                     @codemap::Spanned {\n                         node: StmtExpr(e, ast::DUMMY_NODE_ID),\n@@ -676,7 +680,8 @@ impl Visitor<()> for NewNameFinderContext {\n                         span: _,\n                         segments: ref segments\n                     } if segments.len() == 1 => {\n-                        self.ident_accumulator.push(segments[0].identifier)\n+                        self.ident_accumulator.push(segments.get(0)\n+                                                            .identifier)\n                     }\n                     // I believe these must be enums...\n                     _ => ()\n@@ -843,7 +848,7 @@ impl Folder for Marker {\n         let macro = match m.node {\n             MacInvocTT(ref path, ref tts, ctxt) => {\n                 MacInvocTT(self.fold_path(path),\n-                           fold_tts(*tts, self),\n+                           fold_tts(tts.as_slice(), self),\n                            new_mark(self.mark, ctxt))\n             }\n         };\n@@ -912,6 +917,8 @@ mod test {\n     use visit;\n     use visit::Visitor;\n \n+    use std::vec_ng::Vec;\n+\n     // a visitor that extracts the paths\n     // from a given thingy and puts them in a mutable\n     // array (passed in to the traversal)\n@@ -1015,9 +1022,9 @@ mod test {\n         let attr2 = make_dummy_attr (\"bar\");\n         let escape_attr = make_dummy_attr (\"macro_escape\");\n         let attrs1 = vec!(attr1, escape_attr, attr2);\n-        assert_eq!(contains_macro_escape (attrs1),true);\n+        assert_eq!(contains_macro_escape(attrs1.as_slice()),true);\n         let attrs2 = vec!(attr1,attr2);\n-        assert_eq!(contains_macro_escape (attrs2),false);\n+        assert_eq!(contains_macro_escape(attrs2.as_slice()),false);\n     }\n \n     // make a MetaWord outer attribute with the given name\n@@ -1082,7 +1089,7 @@ mod test {\n     // in principle, you might want to control this boolean on a per-varref basis,\n     // but that would make things even harder to understand, and might not be\n     // necessary for thorough testing.\n-    type RenamingTest = (&'static str, vec!(Vec<uint> ), bool);\n+    type RenamingTest = (&'static str, Vec<Vec<uint>>, bool);\n \n     #[test]\n     fn automatic_renaming () {\n@@ -1131,8 +1138,8 @@ mod test {\n         // must be one check clause for each binding:\n         assert_eq!(bindings.len(),bound_connections.len());\n         for (binding_idx,shouldmatch) in bound_connections.iter().enumerate() {\n-            let binding_name = mtwt_resolve(bindings[binding_idx]);\n-            let binding_marks = mtwt_marksof(bindings[binding_idx].ctxt,invalid_name);\n+            let binding_name = mtwt_resolve(*bindings.get(binding_idx));\n+            let binding_marks = mtwt_marksof(bindings.get(binding_idx).ctxt,invalid_name);\n             // shouldmatch can't name varrefs that don't exist:\n             assert!((shouldmatch.len() == 0) ||\n                     (varrefs.len() > *shouldmatch.iter().max().unwrap()));\n@@ -1141,13 +1148,18 @@ mod test {\n                     // it should be a path of length 1, and it should\n                     // be free-identifier=? or bound-identifier=? to the given binding\n                     assert_eq!(varref.segments.len(),1);\n-                    let varref_name = mtwt_resolve(varref.segments[0].identifier);\n-                    let varref_marks = mtwt_marksof(varref.segments[0].identifier.ctxt,\n+                    let varref_name = mtwt_resolve(varref.segments\n+                                                         .get(0)\n+                                                         .identifier);\n+                    let varref_marks = mtwt_marksof(varref.segments\n+                                                          .get(0)\n+                                                          .identifier\n+                                                          .ctxt,\n                                                     invalid_name);\n                     if !(varref_name==binding_name) {\n                         println!(\"uh oh, should match but doesn't:\");\n                         println!(\"varref: {:?}\",varref);\n-                        println!(\"binding: {:?}\", bindings[binding_idx]);\n+                        println!(\"binding: {:?}\", *bindings.get(binding_idx));\n                         ast_util::display_sctable(get_sctable());\n                     }\n                     assert_eq!(varref_name,binding_name);\n@@ -1158,7 +1170,8 @@ mod test {\n                     }\n                 } else {\n                     let fail = (varref.segments.len() == 1)\n-                        && (mtwt_resolve(varref.segments[0].identifier) == binding_name);\n+                        && (mtwt_resolve(varref.segments.get(0).identifier) ==\n+                                         binding_name);\n                     // temp debugging:\n                     if fail {\n                         println!(\"failure on test {}\",test_idx);\n@@ -1167,11 +1180,13 @@ mod test {\n                         println!(\"uh oh, matches but shouldn't:\");\n                         println!(\"varref: {:?}\",varref);\n                         // good lord, you can't make a path with 0 segments, can you?\n-                        let string = token::get_ident(varref.segments[0].identifier);\n+                        let string = token::get_ident(varref.segments\n+                                                            .get(0)\n+                                                            .identifier);\n                         println!(\"varref's first segment's uint: {}, and string: \\\"{}\\\"\",\n-                                 varref.segments[0].identifier.name,\n+                                 varref.segments.get(0).identifier.name,\n                                  string.get());\n-                        println!(\"binding: {:?}\", bindings[binding_idx]);\n+                        println!(\"binding: {:?}\", *bindings.get(binding_idx));\n                         ast_util::display_sctable(get_sctable());\n                     }\n                     assert!(!fail);\n@@ -1197,7 +1212,7 @@ foo_module!()\n                 let string = ident.get();\n                 \"xx\" == string\n             }).collect();\n-        let cxbinds: &[&ast::Ident] = cxbinds;\n+        let cxbinds: &[&ast::Ident] = cxbinds.as_slice();\n         let cxbind = match cxbinds {\n             [b] => b,\n             _ => fail!(\"expected just one binding for ext_cx\")\n@@ -1211,16 +1226,17 @@ foo_module!()\n         // the xx binding should bind all of the xx varrefs:\n         for (idx,v) in varrefs.iter().filter(|p| {\n             p.segments.len() == 1\n-            && \"xx\" == token::get_ident(p.segments[0].identifier).get()\n+            && \"xx\" == token::get_ident(p.segments.get(0).identifier).get()\n         }).enumerate() {\n-            if mtwt_resolve(v.segments[0].identifier) != resolved_binding {\n+            if mtwt_resolve(v.segments.get(0).identifier) !=\n+                    resolved_binding {\n                 println!(\"uh oh, xx binding didn't match xx varref:\");\n                 println!(\"this is xx varref \\\\# {:?}\",idx);\n                 println!(\"binding: {:?}\",cxbind);\n                 println!(\"resolves to: {:?}\",resolved_binding);\n-                println!(\"varref: {:?}\",v.segments[0].identifier);\n+                println!(\"varref: {:?}\",v.segments.get(0).identifier);\n                 println!(\"resolves to: {:?}\",\n-                         mtwt_resolve(v.segments[0].identifier));\n+                         mtwt_resolve(v.segments.get(0).identifier));\n                 let table = get_sctable();\n                 println!(\"SC table:\");\n \n@@ -1231,7 +1247,8 @@ foo_module!()\n                     }\n                 }\n             }\n-            assert_eq!(mtwt_resolve(v.segments[0].identifier),resolved_binding);\n+            assert_eq!(mtwt_resolve(v.segments.get(0).identifier),\n+                       resolved_binding);\n         };\n     }\n "}, {"sha": "7752d88596820bd5d66dee1d3da13217d9e0e6d8", "filename": "src/libsyntax/ext/format.rs", "status": "modified", "additions": 19, "deletions": 14, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fformat.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -22,6 +22,7 @@ use rsparse = parse;\n use std::fmt::parse;\n use collections::{HashMap, HashSet};\n use std::vec;\n+use std::vec_ng::Vec;\n \n #[deriving(Eq)]\n enum ArgumentType {\n@@ -49,7 +50,7 @@ struct Context<'a> {\n     // were declared in.\n     names: HashMap<~str, @ast::Expr>,\n     name_types: HashMap<~str, ArgumentType>,\n-    name_ordering: ~[~str],\n+    name_ordering: Vec<~str>,\n \n     // Collection of the compiled `rt::Piece` structures\n     pieces: Vec<@ast::Expr> ,\n@@ -70,15 +71,17 @@ struct Context<'a> {\n ///     Some((fmtstr, unnamed arguments, ordering of named arguments,\n ///           named arguments))\n fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n-    -> (@ast::Expr, Option<(@ast::Expr, Vec<@ast::Expr>, ~[~str],\n+    -> (@ast::Expr, Option<(@ast::Expr, Vec<@ast::Expr>, Vec<~str>,\n                             HashMap<~str, @ast::Expr>)>) {\n     let mut args = Vec::new();\n     let mut names = HashMap::<~str, @ast::Expr>::new();\n-    let mut order = ~[];\n+    let mut order = Vec::new();\n \n     let mut p = rsparse::new_parser_from_tts(ecx.parse_sess(),\n                                              ecx.cfg(),\n-                                             tts.to_owned());\n+                                             tts.iter()\n+                                                .map(|x| (*x).clone())\n+                                                .collect());\n     // Parse the leading function expression (maybe a block, maybe a path)\n     let extra = p.parse_expr();\n     if !p.eat(&token::COMMA) {\n@@ -275,14 +278,14 @@ impl<'a> Context<'a> {\n                     return;\n                 }\n                 {\n-                    let arg_type = match self.arg_types[arg] {\n-                        None => None,\n-                        Some(ref x) => Some(x)\n+                    let arg_type = match self.arg_types.get(arg) {\n+                        &None => None,\n+                        &Some(ref x) => Some(x)\n                     };\n-                    self.verify_same(self.args[arg].span, &ty, arg_type);\n+                    self.verify_same(self.args.get(arg).span, &ty, arg_type);\n                 }\n-                if self.arg_types[arg].is_none() {\n-                    self.arg_types[arg] = Some(ty);\n+                if self.arg_types.get(arg).is_none() {\n+                    *self.arg_types.get_mut(arg) = Some(ty);\n                 }\n             }\n \n@@ -653,7 +656,9 @@ impl<'a> Context<'a> {\n         // of each variable because we don't want to move out of the arguments\n         // passed to this function.\n         for (i, &e) in self.args.iter().enumerate() {\n-            if self.arg_types[i].is_none() { continue } // error already generated\n+            if self.arg_types.get(i).is_none() {\n+                continue // error already generated\n+            }\n \n             let name = self.ecx.ident_of(format!(\"__arg{}\", i));\n             pats.push(self.ecx.pat_ident(e.span, name));\n@@ -748,7 +753,7 @@ impl<'a> Context<'a> {\n     fn format_arg(&self, sp: Span, argno: Position, arg: @ast::Expr)\n                   -> @ast::Expr {\n         let ty = match argno {\n-            Exact(ref i) => self.arg_types[*i].get_ref(),\n+            Exact(ref i) => self.arg_types.get(*i).get_ref(),\n             Named(ref s) => self.name_types.get(s)\n         };\n \n@@ -822,7 +827,7 @@ pub fn expand_preparsed_format_args(ecx: &mut ExtCtxt, sp: Span,\n                                     efmt: @ast::Expr, args: Vec<@ast::Expr>,\n                                     name_ordering: Vec<~str>,\n                                     names: HashMap<~str, @ast::Expr>) -> @ast::Expr {\n-    let arg_types = vec::from_fn(args.len(), |_| None);\n+    let arg_types = Vec::from_fn(args.len(), |_| None);\n     let mut cx = Context {\n         ecx: ecx,\n         args: args,\n@@ -871,7 +876,7 @@ pub fn expand_preparsed_format_args(ecx: &mut ExtCtxt, sp: Span,\n     // Make sure that all arguments were used and all arguments have types.\n     for (i, ty) in cx.arg_types.iter().enumerate() {\n         if ty.is_none() {\n-            cx.ecx.span_err(cx.args[i].span, \"argument never used\");\n+            cx.ecx.span_err(cx.args.get(i).span, \"argument never used\");\n         }\n     }\n     for (name, e) in cx.names.iter() {"}, {"sha": "b94928238e9bb215540349e5f60d61bf75c40f6f", "filename": "src/libsyntax/ext/log_syntax.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Flog_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Flog_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Flog_syntax.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -20,7 +20,8 @@ pub fn expand_syntax_ext(cx: &mut ExtCtxt,\n                       -> base::MacResult {\n \n     cx.print_backtrace();\n-    println!(\"{}\", print::pprust::tt_to_str(&ast::TTDelim(@tt.to_owned())));\n+    println!(\"{}\", print::pprust::tt_to_str(&ast::TTDelim(\n+                @tt.iter().map(|x| (*x).clone()).collect())));\n \n     //trivial expression\n     MRExpr(@ast::Expr {"}, {"sha": "e96597d41594b94d423c674e5991f15b66806b23", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 14, "deletions": 8, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -17,6 +17,8 @@ use parse::token::*;\n use parse::token;\n use parse;\n \n+use std::vec_ng::Vec;\n+\n /**\n *\n * Quasiquoting works via token trees.\n@@ -35,6 +37,8 @@ pub mod rt {\n     use parse;\n     use print::pprust;\n \n+    use std::vec_ng::Vec;\n+\n     pub use ast::*;\n     pub use parse::token::*;\n     pub use parse::new_parser_from_tts;\n@@ -305,7 +309,7 @@ pub fn expand_quote_expr(cx: &mut ExtCtxt,\n pub fn expand_quote_item(cx: &mut ExtCtxt,\n                          sp: Span,\n                          tts: &[ast::TokenTree]) -> base::MacResult {\n-    let e_attrs = cx.expr_vec_uniq(sp, Vec::new());\n+    let e_attrs = cx.expr_vec_ng(sp);\n     let expanded = expand_parse_call(cx, sp, \"parse_item\",\n                                     vec!(e_attrs), tts);\n     base::MRExpr(expanded)\n@@ -332,7 +336,7 @@ pub fn expand_quote_ty(cx: &mut ExtCtxt,\n pub fn expand_quote_stmt(cx: &mut ExtCtxt,\n                          sp: Span,\n                          tts: &[ast::TokenTree]) -> base::MacResult {\n-    let e_attrs = cx.expr_vec_uniq(sp, Vec::new());\n+    let e_attrs = cx.expr_vec_ng(sp);\n     let expanded = expand_parse_call(cx, sp, \"parse_stmt\",\n                                     vec!(e_attrs), tts);\n     base::MRExpr(expanded)\n@@ -540,7 +544,7 @@ fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<@ast::Stmt> {\n             vec!(cx.stmt_expr(e_push))\n         }\n \n-        ast::TTDelim(ref tts) => mk_tts(cx, sp, **tts),\n+        ast::TTDelim(ref tts) => mk_tts(cx, sp, tts.as_slice()),\n         ast::TTSeq(..) => fail!(\"TTSeq in quote!\"),\n \n         ast::TTNonterminal(sp, ident) => {\n@@ -583,7 +587,9 @@ fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n \n     let mut p = parse::new_parser_from_tts(cx.parse_sess(),\n                                            cx.cfg(),\n-                                           tts.to_owned());\n+                                           tts.iter()\n+                                              .map(|x| (*x).clone())\n+                                              .collect());\n     p.quote_depth += 1u;\n \n     let cx_expr = p.parse_expr();\n@@ -629,14 +635,14 @@ fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                                   id_ext(\"_sp\"),\n                                   e_sp);\n \n-    let stmt_let_tt = cx.stmt_let(sp, true,\n-                                  id_ext(\"tt\"),\n-                                  cx.expr_vec_uniq(sp, Vec::new()));\n+    let stmt_let_tt = cx.stmt_let(sp, true, id_ext(\"tt\"), cx.expr_vec_ng(sp));\n \n+    let mut vector = vec!(stmt_let_sp, stmt_let_tt);\n+    vector.push_all_move(mk_tts(cx, sp, tts.as_slice()));\n     let block = cx.expr_block(\n         cx.block_all(sp,\n                      Vec::new(),\n-                     vec!(stmt_let_sp, stmt_let_tt) + mk_tts(cx, sp, tts),\n+                     vector,\n                      Some(cx.expr_ident(sp, id_ext(\"tt\")))));\n \n     (cx_expr, block)"}, {"sha": "4c18eb83afceec6e1cd162840ac1a9cda1dfbfac", "filename": "src/libsyntax/ext/registrar.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fregistrar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fregistrar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fregistrar.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -15,6 +15,8 @@ use diagnostic;\n use visit;\n use visit::Visitor;\n \n+use std::vec_ng::Vec;\n+\n struct MacroRegistrarContext {\n     registrars: Vec<(ast::NodeId, Span)> ,\n }\n@@ -23,7 +25,8 @@ impl Visitor<()> for MacroRegistrarContext {\n     fn visit_item(&mut self, item: &ast::Item, _: ()) {\n         match item.node {\n             ast::ItemFn(..) => {\n-                if attr::contains_name(item.attrs, \"macro_registrar\") {\n+                if attr::contains_name(item.attrs.as_slice(),\n+                                       \"macro_registrar\") {\n                     self.registrars.push((item.id, item.span));\n                 }\n             }"}, {"sha": "b31388f58eb9fdc653529d9d904706227afdea1e", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -142,6 +142,7 @@ pub fn expand_include_bin(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n             return MacResult::dummy_expr(sp);\n         }\n         Ok(bytes) => {\n+            let bytes = bytes.iter().map(|x| *x).collect();\n             base::MRExpr(cx.expr_lit(sp, ast::LitBinary(Rc::new(bytes))))\n         }\n     }"}, {"sha": "183cccde18e86c487b2fc39824ead710ca6fcea9", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -24,7 +24,7 @@ pub fn expand_trace_macros(cx: &mut ExtCtxt,\n     let cfg = cx.cfg();\n     let tt_rdr = new_tt_reader(cx.parse_sess().span_diagnostic,\n                                None,\n-                               tt.to_owned());\n+                               tt.iter().map(|x| (*x).clone()).collect());\n     let mut rust_parser = Parser(sess, cfg.clone(), tt_rdr.dup());\n \n     if rust_parser.is_keyword(keywords::True) {"}, {"sha": "c9d3150c2cd417b630bd6b45e0a3b07060b960db", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 25, "deletions": 16, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -22,7 +22,7 @@ use parse::token::{Token, EOF, Nonterminal};\n use parse::token;\n \n use collections::HashMap;\n-use std::vec;\n+use std::vec_ng::Vec;\n \n /* This is an Earley-like parser, without support for in-grammar nonterminals,\n only by calling out to the main rust parser for named nonterminals (which it\n@@ -103,7 +103,7 @@ pub struct MatcherPos {\n     sep: Option<Token>,\n     idx: uint,\n     up: Option<~MatcherPos>,\n-    matches: vec!(Vec<@NamedMatch> ),\n+    matches: Vec<Vec<@NamedMatch>>,\n     match_lo: uint, match_hi: uint,\n     sp_lo: BytePos,\n }\n@@ -112,7 +112,9 @@ pub fn count_names(ms: &[Matcher]) -> uint {\n     ms.iter().fold(0, |ct, m| {\n         ct + match m.node {\n             MatchTok(_) => 0u,\n-            MatchSeq(ref more_ms, _, _, _, _) => count_names((*more_ms)),\n+            MatchSeq(ref more_ms, _, _, _, _) => {\n+                count_names(more_ms.as_slice())\n+            }\n             MatchNonterminal(_, _, _) => 1u\n         }})\n }\n@@ -131,7 +133,7 @@ pub fn initial_matcher_pos(ms: Vec<Matcher> , sep: Option<Token>, lo: BytePos)\n             }\n         }\n     }\n-    let matches = vec::from_fn(count_names(ms), |_i| Vec::new());\n+    let matches = Vec::from_fn(count_names(ms.as_slice()), |_i| Vec::new());\n     ~MatcherPos {\n         elts: ms,\n         sep: sep,\n@@ -208,7 +210,7 @@ pub fn parse_or_else<R: Reader>(sess: @ParseSess,\n                                 rdr: R,\n                                 ms: Vec<Matcher> )\n                                 -> HashMap<Ident, @NamedMatch> {\n-    match parse(sess, cfg, rdr, ms) {\n+    match parse(sess, cfg, rdr, ms.as_slice()) {\n         Success(m) => m,\n         Failure(sp, str) => sess.span_diagnostic.span_fatal(sp, str),\n         Error(sp, str) => sess.span_diagnostic.span_fatal(sp, str)\n@@ -231,7 +233,11 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n                         ms: &[Matcher])\n                         -> ParseResult {\n     let mut cur_eis = Vec::new();\n-    cur_eis.push(initial_matcher_pos(ms.to_owned(), None, rdr.peek().sp.lo));\n+    cur_eis.push(initial_matcher_pos(ms.iter()\n+                                       .map(|x| (*x).clone())\n+                                       .collect(),\n+                                     None,\n+                                     rdr.peek().sp.lo));\n \n     loop {\n         let mut bb_eis = Vec::new(); // black-box parsed by parser.rs\n@@ -274,8 +280,9 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n \n                         // Only touch the binders we have actually bound\n                         for idx in range(ei.match_lo, ei.match_hi) {\n-                            let sub = ei.matches[idx].clone();\n-                            new_pos.matches[idx]\n+                            let sub = (*ei.matches.get(idx)).clone();\n+                            new_pos.matches\n+                                   .get_mut(idx)\n                                    .push(@MatchedSeq(sub, mk_sp(ei.sp_lo,\n                                                                 sp.hi)));\n                         }\n@@ -308,7 +315,7 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n                     eof_eis.push(ei);\n                 }\n             } else {\n-                match ei.elts[idx].node.clone() {\n+                match ei.elts.get(idx).node.clone() {\n                   /* need to descend into sequence */\n                   MatchSeq(ref matchers, ref sep, zero_ok,\n                            match_idx_lo, match_idx_hi) => {\n@@ -317,13 +324,15 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n                         new_ei.idx += 1u;\n                         //we specifically matched zero repeats.\n                         for idx in range(match_idx_lo, match_idx_hi) {\n-                            new_ei.matches[idx].push(@MatchedSeq(Vec::new(), sp));\n+                            new_ei.matches\n+                                  .get_mut(idx)\n+                                  .push(@MatchedSeq(Vec::new(), sp));\n                         }\n \n                         cur_eis.push(new_ei);\n                     }\n \n-                    let matches = vec::from_elem(ei.matches.len(), Vec::new());\n+                    let matches = Vec::from_elem(ei.matches.len(), Vec::new());\n                     let ei_t = ei;\n                     cur_eis.push(~MatcherPos {\n                         elts: (*matchers).clone(),\n@@ -352,10 +361,10 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n         if token_name_eq(&tok, &EOF) {\n             if eof_eis.len() == 1u {\n                 let mut v = Vec::new();\n-                for dv in eof_eis[0u].matches.mut_iter() {\n+                for dv in eof_eis.get_mut(0).matches.mut_iter() {\n                     v.push(dv.pop().unwrap());\n                 }\n-                return Success(nameize(sess, ms, v));\n+                return Success(nameize(sess, ms, v.as_slice()));\n             } else if eof_eis.len() > 1u {\n                 return Error(sp, ~\"ambiguity: multiple successful parses\");\n             } else {\n@@ -365,7 +374,7 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n             if (bb_eis.len() > 0u && next_eis.len() > 0u)\n                 || bb_eis.len() > 1u {\n                 let nts = bb_eis.map(|ei| {\n-                    match ei.elts[ei.idx].node {\n+                    match ei.elts.get(ei.idx).node {\n                       MatchNonterminal(bind, name, _) => {\n                         format!(\"{} ('{}')\",\n                                 token::get_ident(name),\n@@ -390,10 +399,10 @@ pub fn parse<R: Reader>(sess: @ParseSess,\n                 let mut rust_parser = Parser(sess, cfg.clone(), rdr.dup());\n \n                 let mut ei = bb_eis.pop().unwrap();\n-                match ei.elts[ei.idx].node {\n+                match ei.elts.get(ei.idx).node {\n                   MatchNonterminal(_, name, idx) => {\n                     let name_string = token::get_ident(name);\n-                    ei.matches[idx].push(@MatchedNonterminal(\n+                    ei.matches.get_mut(idx).push(@MatchedNonterminal(\n                         parse_nt(&mut rust_parser, name_string.get())));\n                     ei.idx += 1u;\n                   }"}, {"sha": "712d5f6bd27dac80b4a8ed525883f13bc47e482f", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 22, "deletions": 6, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -25,9 +25,11 @@ use parse::token::{special_idents, gensym_ident};\n use parse::token::{FAT_ARROW, SEMI, NtMatchers, NtTT, EOF};\n use parse::token;\n use print;\n-use std::cell::RefCell;\n use util::small_vector::SmallVector;\n \n+use std::cell::RefCell;\n+use std::vec_ng::Vec;\n+\n struct ParserAnyMacro {\n     parser: RefCell<Parser>,\n }\n@@ -100,7 +102,12 @@ impl MacroExpander for MacroRulesMacroExpander {\n               sp: Span,\n               arg: &[ast::TokenTree])\n               -> MacResult {\n-        generic_extension(cx, sp, self.name, arg, *self.lhses, *self.rhses)\n+        generic_extension(cx,\n+                          sp,\n+                          self.name,\n+                          arg,\n+                          self.lhses.as_slice(),\n+                          self.rhses.as_slice())\n     }\n }\n \n@@ -115,7 +122,9 @@ fn generic_extension(cx: &ExtCtxt,\n     if cx.trace_macros() {\n         println!(\"{}! \\\\{ {} \\\\}\",\n                  token::get_ident(name),\n-                 print::pprust::tt_to_str(&TTDelim(@arg.to_owned())));\n+                 print::pprust::tt_to_str(&TTDelim(@arg.iter()\n+                                                       .map(|x| (*x).clone())\n+                                                       .collect())));\n     }\n \n     // Which arm's failure should we report? (the one furthest along)\n@@ -128,16 +137,23 @@ fn generic_extension(cx: &ExtCtxt,\n         match **lhs {\n           MatchedNonterminal(NtMatchers(ref mtcs)) => {\n             // `None` is because we're not interpolating\n-            let arg_rdr = new_tt_reader(s_d, None, arg.to_owned());\n-            match parse(cx.parse_sess(), cx.cfg(), arg_rdr, *mtcs) {\n+            let arg_rdr = new_tt_reader(s_d,\n+                                        None,\n+                                        arg.iter()\n+                                           .map(|x| (*x).clone())\n+                                           .collect());\n+            match parse(cx.parse_sess(), cx.cfg(), arg_rdr, mtcs.as_slice()) {\n               Success(named_matches) => {\n                 let rhs = match *rhses[i] {\n                     // okay, what's your transcriber?\n                     MatchedNonterminal(NtTT(tt)) => {\n                         match *tt {\n                             // cut off delimiters; don't parse 'em\n                             TTDelim(ref tts) => {\n-                                (*tts).slice(1u,(*tts).len()-1u).to_owned()\n+                                (*tts).slice(1u,(*tts).len()-1u)\n+                                      .iter()\n+                                      .map(|x| (*x).clone())\n+                                      .collect()\n                             }\n                             _ => cx.span_fatal(\n                                 sp, \"macro rhs must be delimited\")"}, {"sha": "a3f179e851ad321127f9e95c130d803b8ded428e", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -18,6 +18,7 @@ use parse::token;\n use parse::lexer::TokenAndSpan;\n \n use std::cell::{Cell, RefCell};\n+use std::vec_ng::Vec;\n use collections::HashMap;\n \n ///an unzipping of `TokenTree`s\n@@ -106,7 +107,7 @@ fn lookup_cur_matched_by_matched(r: &TtReader, start: @NamedMatch)\n                 // end of the line; duplicate henceforth\n                 ad\n             }\n-            MatchedSeq(ref ads, _) => ads[*idx]\n+            MatchedSeq(ref ads, _) => *ads.get(*idx)\n         }\n     }\n     let repeat_idx = r.repeat_idx.borrow();\n@@ -217,7 +218,8 @@ pub fn tt_next_token(r: &TtReader) -> TokenAndSpan {\n             r.stack.get().idx.set(0u);\n             {\n                 let mut repeat_idx = r.repeat_idx.borrow_mut();\n-                repeat_idx.get()[repeat_idx.get().len() - 1u] += 1u;\n+                let last_repeat_idx = repeat_idx.get().len() - 1u;\n+                *repeat_idx.get().get_mut(last_repeat_idx) += 1u;\n             }\n             match r.stack.get().sep.clone() {\n               Some(tk) => {\n@@ -231,7 +233,7 @@ pub fn tt_next_token(r: &TtReader) -> TokenAndSpan {\n     loop { /* because it's easiest, this handles `TTDelim` not starting\n     with a `TTTok`, even though it won't happen */\n         // FIXME(pcwalton): Bad copy.\n-        match r.stack.get().forest[r.stack.get().idx.get()].clone() {\n+        match (*r.stack.get().forest.get(r.stack.get().idx.get())).clone() {\n           TTDelim(tts) => {\n             r.stack.set(@TtFrame {\n                 forest: tts,"}, {"sha": "b01ba7718ba58b4013634048adf396ffd4d410a9", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 13, "deletions": 11, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -16,18 +16,20 @@ use parse::token;\n use opt_vec::OptVec;\n use util::small_vector::SmallVector;\n \n+use std::vec_ng::Vec;\n+\n // We may eventually want to be able to fold over type parameters, too.\n pub trait Folder {\n     fn fold_crate(&mut self, c: Crate) -> Crate {\n         noop_fold_crate(c, self)\n     }\n \n     fn fold_meta_items(&mut self, meta_items: &[@MetaItem]) -> Vec<@MetaItem> {\n-        meta_items.map(|x| fold_meta_item_(*x, self))\n+        meta_items.iter().map(|x| fold_meta_item_(*x, self)).collect()\n     }\n \n     fn fold_view_paths(&mut self, view_paths: &[@ViewPath]) -> Vec<@ViewPath> {\n-        view_paths.map(|view_path| {\n+        view_paths.iter().map(|view_path| {\n             let inner_view_path = match view_path.node {\n                 ViewPathSimple(ref ident, ref path, node_id) => {\n                     ViewPathSimple(ident.clone(),\n@@ -60,7 +62,7 @@ pub trait Folder {\n                 node: inner_view_path,\n                 span: self.new_span(view_path.span),\n             }\n-        })\n+        }).collect()\n     }\n \n     fn fold_view_item(&mut self, vi: &ViewItem) -> ViewItem {\n@@ -275,7 +277,7 @@ pub trait Folder {\n             node: match macro.node {\n                 MacInvocTT(ref p, ref tts, ctxt) => {\n                     MacInvocTT(self.fold_path(p),\n-                               fold_tts(*tts, self),\n+                               fold_tts(tts.as_slice(), self),\n                                ctxt)\n                 }\n             },\n@@ -284,7 +286,7 @@ pub trait Folder {\n     }\n \n     fn map_exprs(&self, f: |@Expr| -> @Expr, es: &[@Expr]) -> Vec<@Expr> {\n-        es.map(|x| f(*x))\n+        es.iter().map(|x| f(*x)).collect()\n     }\n \n     fn new_id(&mut self, i: NodeId) -> NodeId {\n@@ -371,20 +373,20 @@ fn fold_arg_<T: Folder>(a: &Arg, fld: &mut T) -> Arg {\n // token::LIFETIME are certainly not loop labels. But we can't tell in their\n // token form. So this is less ideal and hacky but it works.\n pub fn fold_tts<T: Folder>(tts: &[TokenTree], fld: &mut T) -> Vec<TokenTree> {\n-    tts.map(|tt| {\n+    tts.iter().map(|tt| {\n         match *tt {\n             TTTok(span, ref tok) =>\n             TTTok(span,maybe_fold_ident(tok,fld)),\n-            TTDelim(tts) => TTDelim(@fold_tts(*tts, fld)),\n+            TTDelim(tts) => TTDelim(@fold_tts(tts.as_slice(), fld)),\n             TTSeq(span, pattern, ref sep, is_optional) =>\n             TTSeq(span,\n-                  @fold_tts(*pattern, fld),\n+                  @fold_tts(pattern.as_slice(), fld),\n                   sep.as_ref().map(|tok|maybe_fold_ident(tok,fld)),\n                   is_optional),\n             TTNonterminal(sp,ref ident) =>\n             TTNonterminal(sp,fld.fold_ident(*ident))\n         }\n-    })\n+    }).collect()\n }\n \n // apply ident folder if it's an ident, otherwise leave it alone\n@@ -518,7 +520,7 @@ pub fn noop_fold_view_item<T: Folder>(vi: &ViewItem, folder: &mut T)\n                               folder.new_id(node_id))\n         }\n         ViewItemUse(ref view_paths) => {\n-            ViewItemUse(folder.fold_view_paths(*view_paths))\n+            ViewItemUse(folder.fold_view_paths(view_paths.as_slice()))\n         }\n     };\n     ViewItem {\n@@ -881,7 +883,7 @@ mod test {\n     // this version doesn't care about getting comments or docstrings in.\n     fn fake_print_crate(s: &mut pprust::State,\n                         krate: &ast::Crate) -> io::IoResult<()> {\n-        pprust::print_mod(s, &krate.module, krate.attrs)\n+        pprust::print_mod(s, &krate.module, krate.attrs.as_slice())\n     }\n \n     // change every identifier to \"zz\""}, {"sha": "ec81fff51c791ae7f82bc88047ad80e909c67bf9", "filename": "src/libsyntax/opt_vec.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fopt_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fopt_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fopt_vec.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -15,8 +15,9 @@\n  * other useful things like `push()` and `len()`.\n  */\n \n-use std::vec;\n use std::default::Default;\n+use std::vec;\n+use std::vec_ng::Vec;\n \n #[deriving(Clone, Encodable, Decodable, Hash)]\n pub enum OptVec<T> {\n@@ -87,7 +88,7 @@ impl<T> OptVec<T> {\n     pub fn get<'a>(&'a self, i: uint) -> &'a T {\n         match *self {\n             Empty => fail!(\"invalid index {}\", i),\n-            Vec(ref v) => &v[i]\n+            Vec(ref v) => v.get(i)\n         }\n     }\n \n@@ -147,7 +148,7 @@ impl<T:Clone> OptVec<T> {\n         let mut v0 = vec!(t);\n         match *self {\n             Empty => {}\n-            Vec(ref v1) => { v0.push_all(*v1); }\n+            Vec(ref v1) => { v0.push_all(v1.as_slice()); }\n         }\n         return Vec(v0);\n     }"}, {"sha": "0a74c7ca8212464cf5f7ca08066a15b7060c1e89", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -15,6 +15,8 @@ use parse::token;\n use parse::parser::Parser;\n use parse::token::INTERPOLATED;\n \n+use std::vec_ng::Vec;\n+\n // a parser that can parse attributes.\n pub trait ParserAttr {\n     fn parse_outer_attributes(&mut self) -> Vec<ast::Attribute> ;"}, {"sha": "c2a2097de2442cd3a708cf9ceaedd75e49d1e6bb", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -20,6 +20,7 @@ use parse::token;\n use std::io;\n use std::str;\n use std::uint;\n+use std::vec_ng::Vec;\n \n #[deriving(Clone, Eq)]\n pub enum CommentStyle {\n@@ -58,20 +59,20 @@ pub fn strip_doc_comment_decoration(comment: &str) -> ~str {\n         let mut i = 0u;\n         let mut j = lines.len();\n         // first line of all-stars should be omitted\n-        if lines.len() > 0 && lines[0].chars().all(|c| c == '*') {\n+        if lines.len() > 0 && lines.get(0).chars().all(|c| c == '*') {\n             i += 1;\n         }\n-        while i < j && lines[i].trim().is_empty() {\n+        while i < j && lines.get(i).trim().is_empty() {\n             i += 1;\n         }\n         // like the first, a last line of all stars should be omitted\n-        if j > i && lines[j - 1].chars().skip(1).all(|c| c == '*') {\n+        if j > i && lines.get(j - 1).chars().skip(1).all(|c| c == '*') {\n             j -= 1;\n         }\n-        while j > i && lines[j - 1].trim().is_empty() {\n+        while j > i && lines.get(j - 1).trim().is_empty() {\n             j -= 1;\n         }\n-        return lines.slice(i, j).to_owned();\n+        return lines.slice(i, j).iter().map(|x| (*x).clone()).collect();\n     }\n \n     /// remove a \"[ \\t]*\\*\" block from each line, if possible"}, {"sha": "884fc306f22ea6684c461378b1e206d751adbe17", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -1005,6 +1005,7 @@ mod test {\n     use parse::token;\n     use parse::token::{str_to_ident};\n     use std::io::util;\n+    use std::vec_ng::Vec;\n \n     // represents a testing reader (incl. both reader and interner)\n     struct Env {"}, {"sha": "9e5db1770bf311ecd0c875ec4b806050fdd2f1d4", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,7 @@ use parse::parser::Parser;\n use std::cell::RefCell;\n use std::io::File;\n use std::str;\n+use std::vec_ng::Vec;\n \n pub mod lexer;\n pub mod parser;\n@@ -288,6 +289,7 @@ mod test {\n     use std::io;\n     use std::io::MemWriter;\n     use std::str;\n+    use std::vec_ng::Vec;\n     use codemap::{Span, BytePos, Spanned};\n     use opt_vec;\n     use ast;\n@@ -362,27 +364,28 @@ mod test {\n     // check the token-tree-ization of macros\n     #[test] fn string_to_tts_macro () {\n         let tts = string_to_tts(~\"macro_rules! zip (($a)=>($a))\");\n-        let tts: &[ast::TokenTree] = tts;\n+        let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n             [ast::TTTok(_,_),\n              ast::TTTok(_,token::NOT),\n              ast::TTTok(_,_),\n              ast::TTDelim(delim_elts)] => {\n-                let delim_elts: &[ast::TokenTree] = *delim_elts;\n+                let delim_elts: &[ast::TokenTree] = delim_elts.as_slice();\n                 match delim_elts {\n                     [ast::TTTok(_,token::LPAREN),\n                      ast::TTDelim(first_set),\n                      ast::TTTok(_,token::FAT_ARROW),\n                      ast::TTDelim(second_set),\n                      ast::TTTok(_,token::RPAREN)] => {\n-                        let first_set: &[ast::TokenTree] = *first_set;\n+                        let first_set: &[ast::TokenTree] =\n+                            first_set.as_slice();\n                         match first_set {\n                             [ast::TTTok(_,token::LPAREN),\n                              ast::TTTok(_,token::DOLLAR),\n                              ast::TTTok(_,_),\n                              ast::TTTok(_,token::RPAREN)] => {\n                                 let second_set: &[ast::TokenTree] =\n-                                    *second_set;\n+                                    second_set.as_slice();\n                                 match second_set {\n                                     [ast::TTTok(_,token::LPAREN),\n                                      ast::TTTok(_,token::DOLLAR),"}, {"sha": "9b209aadf19e50b91b61f6d8817980f461e3db5c", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 41, "deletions": 23, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -82,7 +82,8 @@ use std::cell::Cell;\n use collections::HashSet;\n use std::kinds::marker;\n use std::mem::replace;\n-use std::vec;\n+use std::vec_ng::Vec;\n+use std::vec_ng;\n \n #[allow(non_camel_case_types)]\n #[deriving(Eq)]\n@@ -270,7 +271,7 @@ fn maybe_append(lhs: Vec<Attribute> , rhs: Option<Vec<Attribute> >)\n              -> Vec<Attribute> {\n     match rhs {\n         None => lhs,\n-        Some(ref attrs) => vec_ng::append(lhs, (*attrs))\n+        Some(ref attrs) => vec_ng::append(lhs, attrs.as_slice())\n     }\n }\n \n@@ -406,8 +407,11 @@ impl Parser {\n         } else if inedible.contains(&self.token) {\n             // leave it in the input\n         } else {\n-            let expected = vec_ng::append(edible.to_owned(), inedible);\n-            let expect = tokens_to_str(expected);\n+            let expected = vec_ng::append(edible.iter()\n+                                                .map(|x| (*x).clone())\n+                                                .collect(),\n+                                          inedible);\n+            let expect = tokens_to_str(expected.as_slice());\n             let actual = self.this_token_to_str();\n             self.fatal(\n                 if expected.len() != 1 {\n@@ -445,8 +449,12 @@ impl Parser {\n         match e.node {\n             ExprPath(..) => {\n                 // might be unit-struct construction; check for recoverableinput error.\n-                let expected = vec_ng::append(edible.to_owned(), inedible);\n-                self.check_for_erroneous_unit_struct_expecting(expected);\n+                let expected = vec_ng::append(edible.iter()\n+                                                    .map(|x| (*x).clone())\n+                                                    .collect(),\n+                                              inedible);\n+                self.check_for_erroneous_unit_struct_expecting(\n+                    expected.as_slice());\n             }\n             _ => {}\n         }\n@@ -464,8 +472,12 @@ impl Parser {\n         debug!(\"commit_stmt {:?}\", s);\n         let _s = s; // unused, but future checks might want to inspect `s`.\n         if self.last_token.as_ref().map_or(false, |t| is_ident_or_path(*t)) {\n-            let expected = vec_ng::append(edible.to_owned(), inedible);\n-            self.check_for_erroneous_unit_struct_expecting(expected);\n+            let expected = vec_ng::append(edible.iter()\n+                                                .map(|x| (*x).clone())\n+                                                .collect(),\n+                                          inedible.as_slice());\n+            self.check_for_erroneous_unit_struct_expecting(\n+                expected.as_slice());\n         }\n         self.expect_one_of(edible, inedible)\n     }\n@@ -1082,7 +1094,7 @@ impl Parser {\n                 debug!(\"parse_trait_methods(): parsing provided method\");\n                 let (inner_attrs, body) =\n                     p.parse_inner_attrs_and_block();\n-                let attrs = vec_ng::append(attrs, inner_attrs);\n+                let attrs = vec_ng::append(attrs, inner_attrs.as_slice());\n                 Provided(@ast::Method {\n                     ident: ident,\n                     attrs: attrs,\n@@ -1189,7 +1201,7 @@ impl Parser {\n \n                 if ts.len() == 1 && !one_tuple {\n                     self.expect(&token::RPAREN);\n-                    return ts[0]\n+                    return *ts.get(0)\n                 }\n \n                 let t = TyTup(ts);\n@@ -1769,7 +1781,7 @@ impl Parser {\n             self.commit_expr_expecting(*es.last().unwrap(), token::RPAREN);\n \n             return if es.len() == 1 && !trailing_comma {\n-                self.mk_expr(lo, hi, ExprParen(es[0]))\n+                self.mk_expr(lo, hi, ExprParen(*es.get(0)))\n             }\n             else {\n                 self.mk_expr(lo, hi, ExprTup(es))\n@@ -1859,7 +1871,9 @@ impl Parser {\n                         seq_sep_trailing_allowed(token::COMMA),\n                         |p| p.parse_expr()\n                     );\n-                    ex = ExprVec(vec!(first_expr) + remaining_exprs, mutbl);\n+                    let mut exprs = vec!(first_expr);\n+                    exprs.push_all_move(remaining_exprs);\n+                    ex = ExprVec(exprs, mutbl);\n                 } else {\n                     // Vector with one element.\n                     self.expect(&token::RBRACKET);\n@@ -3327,7 +3341,7 @@ impl Parser {\n         while self.token != token::RBRACE {\n             // parsing items even when they're not allowed lets us give\n             // better error messages and recover more gracefully.\n-            attributes_box.push_all(self.parse_outer_attributes());\n+            attributes_box.push_all(self.parse_outer_attributes().as_slice());\n             match self.token {\n                 token::SEMI => {\n                     if !attributes_box.is_empty() {\n@@ -3850,7 +3864,7 @@ impl Parser {\n \n         let (inner_attrs, body) = self.parse_inner_attrs_and_block();\n         let hi = body.span.hi;\n-        let attrs = vec_ng::append(attrs, inner_attrs);\n+        let attrs = vec_ng::append(attrs, inner_attrs.as_slice());\n         @ast::Method {\n             ident: ident,\n             attrs: attrs,\n@@ -4082,7 +4096,8 @@ impl Parser {\n         while self.token != term {\n             let mut attrs = self.parse_outer_attributes();\n             if first {\n-                attrs = attrs_remaining + attrs;\n+                attrs = vec_ng::append(attrs_remaining.clone(),\n+                                       attrs.as_slice());\n                 first = false;\n             }\n             debug!(\"parse_mod_items: parse_item_or_view_item(attrs={:?})\",\n@@ -4164,7 +4179,7 @@ impl Parser {\n                     -> (ast::Item_, Vec<ast::Attribute> ) {\n         let mut prefix = Path::new(self.sess.cm.span_to_filename(self.span));\n         prefix.pop();\n-        let mod_path = Path::new(\".\").join_many(self.mod_path_stack);\n+        let mod_path = Path::new(\".\").join_many(self.mod_path_stack.as_slice());\n         let dir_path = prefix.join(&mod_path);\n         let file_path = match ::attr::first_attr_value_str_by_name(\n                 outer_attrs, \"path\") {\n@@ -4194,7 +4209,7 @@ impl Parser {\n         };\n \n         self.eval_src_mod_from_path(file_path,\n-                                    outer_attrs.to_owned(),\n+                                    outer_attrs.iter().map(|x| *x).collect(),\n                                     id_sp)\n     }\n \n@@ -4231,7 +4246,7 @@ impl Parser {\n                                      &path,\n                                      id_sp);\n         let (inner, next) = p0.parse_inner_attrs_and_next();\n-        let mod_attrs = vec_ng::append(outer_attrs, inner);\n+        let mod_attrs = vec_ng::append(outer_attrs, inner.as_slice());\n         let first_item_outer_attrs = next;\n         let m0 = p0.parse_mod_items(token::EOF, first_item_outer_attrs);\n         {\n@@ -4556,7 +4571,7 @@ impl Parser {\n         match self.token {\n             INTERPOLATED(token::NtItem(item)) => {\n                 self.bump();\n-                let new_attrs = vec_ng::append(attrs, item.attrs);\n+                let new_attrs = vec_ng::append(attrs, item.attrs.as_slice());\n                 return IoviItem(@Item {\n                     attrs: new_attrs,\n                     ..(*item).clone()\n@@ -4662,7 +4677,8 @@ impl Parser {\n         }\n         if self.eat_keyword(keywords::Mod) {\n             // MODULE ITEM\n-            let (ident, item_, extra_attrs) = self.parse_item_mod(attrs);\n+            let (ident, item_, extra_attrs) =\n+                self.parse_item_mod(attrs.as_slice());\n             let item = self.mk_item(lo,\n                                     self.last_span.hi,\n                                     ident,\n@@ -4946,7 +4962,7 @@ impl Parser {\n           }\n           _ => ()\n         }\n-        let last = path[path.len() - 1u];\n+        let last = *path.get(path.len() - 1u);\n         let path = ast::Path {\n             span: mk_sp(lo, self.span.hi),\n             global: false,\n@@ -4984,7 +5000,8 @@ impl Parser {\n                                   macros_allowed: bool)\n                                   -> ParsedItemsAndViewItems {\n         let mut attrs = vec_ng::append(first_item_attrs,\n-                                    self.parse_outer_attributes());\n+                                       self.parse_outer_attributes()\n+                                           .as_slice());\n         // First, parse view items.\n         let mut view_items : Vec<ast::ViewItem> = Vec::new();\n         let mut items = Vec::new();\n@@ -5065,7 +5082,8 @@ impl Parser {\n                            macros_allowed: bool)\n         -> ParsedItemsAndViewItems {\n         let mut attrs = vec_ng::append(first_item_attrs,\n-                                    self.parse_outer_attributes());\n+                                       self.parse_outer_attributes()\n+                                           .as_slice());\n         let mut foreign_items = Vec::new();\n         loop {\n             match self.parse_foreign_item(attrs, macros_allowed) {"}, {"sha": "1499a1b4c19be37efb990b1af9b7c0b0d81d36b4", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,7 @@ use std::char;\n use std::fmt;\n use std::local_data;\n use std::path::BytesContainer;\n+use std::vec_ng::Vec;\n \n #[allow(non_camel_case_types)]\n #[deriving(Clone, Encodable, Decodable, Eq, Hash, Show)]\n@@ -412,13 +413,11 @@ macro_rules! declare_special_idents_and_keywords {(\n         // The indices here must correspond to the numbers in\n         // special_idents, in Keyword to_ident(), and in static\n         // constants below.\n-        let init_vec = vec!(\n-            $( $si_str, )*\n-            $( $sk_str, )*\n-            $( $rk_str, )*\n-        );\n-\n-        interner::StrInterner::prefill(init_vec)\n+        let mut init_vec = Vec::new();\n+        $(init_vec.push($si_str);)*\n+        $(init_vec.push($sk_str);)*\n+        $(init_vec.push($rk_str);)*\n+        interner::StrInterner::prefill(init_vec.as_slice())\n     }\n }}\n "}, {"sha": "e9e0e4835933bd8785749573299bd6f778929b1b", "filename": "src/libsyntax/print/pp.rs", "status": "modified", "additions": 51, "deletions": 37, "changes": 88, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fprint%2Fpp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fprint%2Fpp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpp.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -62,7 +62,7 @@\n  */\n \n use std::io;\n-use std::vec;\n+use std::vec_ng::Vec;\n \n #[deriving(Clone, Eq)]\n pub enum Breaks {\n@@ -131,7 +131,7 @@ pub fn buf_str(toks: Vec<Token> , szs: Vec<int> , left: uint, right: uint,\n         if i != left {\n             s.push_str(\", \");\n         }\n-        s.push_str(format!(\"{}={}\", szs[i], tok_str(toks[i].clone())));\n+        s.push_str(format!(\"{}={}\", szs.get(i), tok_str(toks.get(i).clone())));\n         i += 1u;\n         i %= n;\n     }\n@@ -156,9 +156,9 @@ pub fn mk_printer(out: ~io::Writer, linewidth: uint) -> Printer {\n     // fall behind.\n     let n: uint = 3 * linewidth;\n     debug!(\"mk_printer {}\", linewidth);\n-    let token: Vec<Token> = vec::from_elem(n, Eof);\n-    let size: Vec<int> = vec::from_elem(n, 0);\n-    let scan_stack: Vec<uint> = vec::from_elem(n, 0u);\n+    let token: Vec<Token> = Vec::from_elem(n, Eof);\n+    let size: Vec<int> = Vec::from_elem(n, 0);\n+    let scan_stack: Vec<uint> = Vec::from_elem(n, 0u);\n     Printer {\n         out: out,\n         buf_len: n,\n@@ -286,20 +286,21 @@ pub struct Printer {\n \n impl Printer {\n     pub fn last_token(&mut self) -> Token {\n-        self.token[self.right].clone()\n+        (*self.token.get(self.right)).clone()\n     }\n     // be very careful with this!\n     pub fn replace_last_token(&mut self, t: Token) {\n-        self.token[self.right] = t;\n+        *self.token.get_mut(self.right) = t;\n     }\n     pub fn pretty_print(&mut self, t: Token) -> io::IoResult<()> {\n         debug!(\"pp ~[{},{}]\", self.left, self.right);\n         match t {\n           Eof => {\n             if !self.scan_stack_empty {\n                 self.check_stack(0);\n-                let left = self.token[self.left].clone();\n-                try!(self.advance_left(left, self.size[self.left]));\n+                let left = (*self.token.get(self.left)).clone();\n+                let left_size = *self.size.get(self.left);\n+                try!(self.advance_left(left, left_size));\n             }\n             self.indent(0);\n             Ok(())\n@@ -313,8 +314,8 @@ impl Printer {\n             } else { self.advance_right(); }\n             debug!(\"pp Begin({})/buffer ~[{},{}]\",\n                    b.offset, self.left, self.right);\n-            self.token[self.right] = t;\n-            self.size[self.right] = -self.right_total;\n+            *self.token.get_mut(self.right) = t;\n+            *self.size.get_mut(self.right) = -self.right_total;\n             self.scan_push(self.right);\n             Ok(())\n           }\n@@ -325,8 +326,8 @@ impl Printer {\n             } else {\n                 debug!(\"pp End/buffer ~[{},{}]\", self.left, self.right);\n                 self.advance_right();\n-                self.token[self.right] = t;\n-                self.size[self.right] = -1;\n+                *self.token.get_mut(self.right) = t;\n+                *self.size.get_mut(self.right) = -1;\n                 self.scan_push(self.right);\n                 Ok(())\n             }\n@@ -342,8 +343,8 @@ impl Printer {\n                    b.offset, self.left, self.right);\n             self.check_stack(0);\n             self.scan_push(self.right);\n-            self.token[self.right] = t;\n-            self.size[self.right] = -self.right_total;\n+            *self.token.get_mut(self.right) = t;\n+            *self.size.get_mut(self.right) = -self.right_total;\n             self.right_total += b.blank_space;\n             Ok(())\n           }\n@@ -356,8 +357,8 @@ impl Printer {\n                 debug!(\"pp String('{}')/buffer ~[{},{}]\",\n                        *s, self.left, self.right);\n                 self.advance_right();\n-                self.token[self.right] = t.clone();\n-                self.size[self.right] = len;\n+                *self.token.get_mut(self.right) = t.clone();\n+                *self.size.get_mut(self.right) = len;\n                 self.right_total += len;\n                 self.check_stream()\n             }\n@@ -371,13 +372,15 @@ impl Printer {\n             debug!(\"scan window is {}, longer than space on line ({})\",\n                    self.right_total - self.left_total, self.space);\n             if !self.scan_stack_empty {\n-                if self.left == self.scan_stack[self.bottom] {\n+                if self.left == *self.scan_stack.get(self.bottom) {\n                     debug!(\"setting {} to infinity and popping\", self.left);\n-                    self.size[self.scan_pop_bottom()] = SIZE_INFINITY;\n+                    let scanned = self.scan_pop_bottom();\n+                    *self.size.get_mut(scanned) = SIZE_INFINITY;\n                 }\n             }\n-            let left = self.token[self.left].clone();\n-            try!(self.advance_left(left, self.size[self.left]));\n+            let left = (*self.token.get(self.left)).clone();\n+            let left_size = *self.size.get(self.left);\n+            try!(self.advance_left(left, left_size));\n             if self.left != self.right {\n                 try!(self.check_stream());\n             }\n@@ -393,26 +396,30 @@ impl Printer {\n             self.top %= self.buf_len;\n             assert!((self.top != self.bottom));\n         }\n-        self.scan_stack[self.top] = x;\n+        *self.scan_stack.get_mut(self.top) = x;\n     }\n     pub fn scan_pop(&mut self) -> uint {\n         assert!((!self.scan_stack_empty));\n-        let x = self.scan_stack[self.top];\n+        let x = *self.scan_stack.get(self.top);\n         if self.top == self.bottom {\n             self.scan_stack_empty = true;\n-        } else { self.top += self.buf_len - 1u; self.top %= self.buf_len; }\n+        } else {\n+            self.top += self.buf_len - 1u; self.top %= self.buf_len;\n+        }\n         return x;\n     }\n     pub fn scan_top(&mut self) -> uint {\n         assert!((!self.scan_stack_empty));\n-        return self.scan_stack[self.top];\n+        return *self.scan_stack.get(self.top);\n     }\n     pub fn scan_pop_bottom(&mut self) -> uint {\n         assert!((!self.scan_stack_empty));\n-        let x = self.scan_stack[self.bottom];\n+        let x = *self.scan_stack.get(self.bottom);\n         if self.top == self.bottom {\n             self.scan_stack_empty = true;\n-        } else { self.bottom += 1u; self.bottom %= self.buf_len; }\n+        } else {\n+            self.bottom += 1u; self.bottom %= self.buf_len;\n+        }\n         return x;\n     }\n     pub fn advance_right(&mut self) {\n@@ -435,8 +442,9 @@ impl Printer {\n             if self.left != self.right {\n                 self.left += 1u;\n                 self.left %= self.buf_len;\n-                let left = self.token[self.left].clone();\n-                try!(self.advance_left(left, self.size[self.left]));\n+                let left = (*self.token.get(self.left)).clone();\n+                let left_size = *self.size.get(self.left);\n+                try!(self.advance_left(left, left_size));\n             }\n             ret\n         } else {\n@@ -446,22 +454,28 @@ impl Printer {\n     pub fn check_stack(&mut self, k: int) {\n         if !self.scan_stack_empty {\n             let x = self.scan_top();\n-            match self.token[x] {\n-              Begin(_) => {\n+            match self.token.get(x) {\n+              &Begin(_) => {\n                 if k > 0 {\n-                    self.size[self.scan_pop()] = self.size[x] +\n+                    let popped = self.scan_pop();\n+                    *self.size.get_mut(popped) = *self.size.get(x) +\n                         self.right_total;\n                     self.check_stack(k - 1);\n                 }\n               }\n-              End => {\n+              &End => {\n                 // paper says + not =, but that makes no sense.\n-                self.size[self.scan_pop()] = 1;\n+                let popped = self.scan_pop();\n+                *self.size.get_mut(popped) = 1;\n                 self.check_stack(k + 1);\n               }\n               _ => {\n-                self.size[self.scan_pop()] = self.size[x] + self.right_total;\n-                if k > 0 { self.check_stack(k); }\n+                let popped = self.scan_pop();\n+                *self.size.get_mut(popped) = *self.size.get(x) +\n+                    self.right_total;\n+                if k > 0 {\n+                    self.check_stack(k);\n+                }\n               }\n             }\n         }\n@@ -481,7 +495,7 @@ impl Printer {\n         let print_stack = &mut self.print_stack;\n         let n = print_stack.len();\n         if n != 0u {\n-            print_stack[n - 1u]\n+            *print_stack.get(n - 1u)\n         } else {\n             PrintStackElem {\n                 offset: 0,"}, {"sha": "d027efc1d42f6247735b78b611590d6bf2d327c6", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 64, "deletions": 41, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -33,6 +33,7 @@ use std::char;\n use std::str;\n use std::io;\n use std::io::MemWriter;\n+use std::vec_ng::Vec;\n \n // The &mut State is stored here to prevent recursive type.\n pub enum AnnNode<'a, 'b> {\n@@ -147,7 +148,7 @@ pub fn print_crate(cm: @CodeMap,\n }\n \n pub fn print_crate_(s: &mut State, krate: &ast::Crate) -> io::IoResult<()> {\n-    try!(print_mod(s, &krate.module, krate.attrs));\n+    try!(print_mod(s, &krate.module, krate.attrs.as_slice()));\n     try!(print_remaining_comments(s));\n     try!(eof(&mut s.s));\n     Ok(())\n@@ -319,7 +320,7 @@ pub fn in_cbox(s: &mut State) -> bool {\n     let boxes = s.boxes.borrow();\n     let len = boxes.get().len();\n     if len == 0u { return false; }\n-    return boxes.get()[len - 1u] == pp::Consistent;\n+    return *boxes.get().get(len - 1u) == pp::Consistent;\n }\n \n pub fn hardbreak_if_not_bol(s: &mut State) -> io::IoResult<()> {\n@@ -463,7 +464,7 @@ pub fn print_type(s: &mut State, ty: &ast::Ty) -> io::IoResult<()> {\n         }\n         ast::TyTup(ref elts) => {\n             try!(popen(s));\n-            try!(commasep(s, Inconsistent, *elts, print_type_ref));\n+            try!(commasep(s, Inconsistent, elts.as_slice(), print_type_ref));\n             if elts.len() == 1 {\n                 try!(word(&mut s.s, \",\"));\n             }\n@@ -517,7 +518,7 @@ pub fn print_foreign_item(s: &mut State,\n                           item: &ast::ForeignItem) -> io::IoResult<()> {\n     try!(hardbreak_if_not_bol(s));\n     try!(maybe_print_comment(s, item.span.lo));\n-    try!(print_outer_attributes(s, item.attrs));\n+    try!(print_outer_attributes(s, item.attrs.as_slice()));\n     match item.node {\n         ast::ForeignItemFn(decl, ref generics) => {\n             try!(print_fn(s, decl, None, AbiSet::Rust(), item.ident, generics,\n@@ -545,7 +546,7 @@ pub fn print_foreign_item(s: &mut State,\n pub fn print_item(s: &mut State, item: &ast::Item) -> io::IoResult<()> {\n     try!(hardbreak_if_not_bol(s));\n     try!(maybe_print_comment(s, item.span.lo));\n-    try!(print_outer_attributes(s, item.attrs));\n+    try!(print_outer_attributes(s, item.attrs.as_slice()));\n     {\n         let ann_node = NodeItem(s, item);\n         try!(s.ann.pre(ann_node));\n@@ -580,21 +581,21 @@ pub fn print_item(s: &mut State, item: &ast::Item) -> io::IoResult<()> {\n             item.vis\n         ));\n         try!(word(&mut s.s, \" \"));\n-        try!(print_block_with_attrs(s, body, item.attrs));\n+        try!(print_block_with_attrs(s, body, item.attrs.as_slice()));\n       }\n       ast::ItemMod(ref _mod) => {\n         try!(head(s, visibility_qualified(item.vis, \"mod\")));\n         try!(print_ident(s, item.ident));\n         try!(nbsp(s));\n         try!(bopen(s));\n-        try!(print_mod(s, _mod, item.attrs));\n+        try!(print_mod(s, _mod, item.attrs.as_slice()));\n         try!(bclose(s, item.span));\n       }\n       ast::ItemForeignMod(ref nmod) => {\n         try!(head(s, \"extern\"));\n         try!(word_nbsp(s, nmod.abis.to_str()));\n         try!(bopen(s));\n-        try!(print_foreign_mod(s, nmod, item.attrs));\n+        try!(print_foreign_mod(s, nmod, item.attrs.as_slice()));\n         try!(bclose(s, item.span));\n       }\n       ast::ItemTy(ty, ref params) => {\n@@ -646,7 +647,7 @@ pub fn print_item(s: &mut State, item: &ast::Item) -> io::IoResult<()> {\n \n         try!(space(&mut s.s));\n         try!(bopen(s));\n-        try!(print_inner_attributes(s, item.attrs));\n+        try!(print_inner_attributes(s, item.attrs.as_slice()));\n         for meth in methods.iter() {\n            try!(print_method(s, *meth));\n         }\n@@ -706,7 +707,7 @@ pub fn print_enum_def(s: &mut State, enum_definition: &ast::EnumDef,\n     try!(print_ident(s, ident));\n     try!(print_generics(s, generics));\n     try!(space(&mut s.s));\n-    try!(print_variants(s, enum_definition.variants, span));\n+    try!(print_variants(s, enum_definition.variants.as_slice(), span));\n     Ok(())\n }\n \n@@ -717,7 +718,7 @@ pub fn print_variants(s: &mut State,\n     for &v in variants.iter() {\n         try!(space_if_not_bol(s));\n         try!(maybe_print_comment(s, v.span.lo));\n-        try!(print_outer_attributes(s, v.node.attrs));\n+        try!(print_outer_attributes(s, v.node.attrs.as_slice()));\n         try!(ibox(s, indent_unit));\n         try!(print_variant(s, v));\n         try!(word(&mut s.s, \",\"));\n@@ -761,7 +762,10 @@ pub fn print_struct(s: &mut State,\n     if ast_util::struct_def_is_tuple_like(struct_def) {\n         if !struct_def.fields.is_empty() {\n             try!(popen(s));\n-            try!(commasep(s, Inconsistent, struct_def.fields, |s, field| {\n+            try!(commasep(s,\n+                          Inconsistent,\n+                          struct_def.fields.as_slice(),\n+                          |s, field| {\n                 match field.node.kind {\n                     ast::NamedField(..) => fail!(\"unexpected named field\"),\n                     ast::UnnamedField => {\n@@ -787,7 +791,8 @@ pub fn print_struct(s: &mut State,\n                 ast::NamedField(ident, visibility) => {\n                     try!(hardbreak_if_not_bol(s));\n                     try!(maybe_print_comment(s, field.span.lo));\n-                    try!(print_outer_attributes(s, field.node.attrs));\n+                    try!(print_outer_attributes(s,\n+                                                field.node.attrs.as_slice()));\n                     try!(print_visibility(s, visibility));\n                     try!(print_ident(s, ident));\n                     try!(word_nbsp(s, \":\"));\n@@ -857,7 +862,10 @@ pub fn print_variant(s: &mut State, v: &ast::Variant) -> io::IoResult<()> {\n                                      arg: &ast::VariantArg) -> io::IoResult<()> {\n                     print_type(s, arg.ty)\n                 }\n-                try!(commasep(s, Consistent, *args, print_variant_arg));\n+                try!(commasep(s,\n+                              Consistent,\n+                              args.as_slice(),\n+                              print_variant_arg));\n                 try!(pclose(s));\n             }\n         }\n@@ -881,7 +889,7 @@ pub fn print_variant(s: &mut State, v: &ast::Variant) -> io::IoResult<()> {\n pub fn print_ty_method(s: &mut State, m: &ast::TypeMethod) -> io::IoResult<()> {\n     try!(hardbreak_if_not_bol(s));\n     try!(maybe_print_comment(s, m.span.lo));\n-    try!(print_outer_attributes(s, m.attrs));\n+    try!(print_outer_attributes(s, m.attrs.as_slice()));\n     try!(print_ty_fn(s,\n                        None,\n                        None,\n@@ -907,12 +915,12 @@ pub fn print_trait_method(s: &mut State,\n pub fn print_method(s: &mut State, meth: &ast::Method) -> io::IoResult<()> {\n     try!(hardbreak_if_not_bol(s));\n     try!(maybe_print_comment(s, meth.span.lo));\n-    try!(print_outer_attributes(s, meth.attrs));\n+    try!(print_outer_attributes(s, meth.attrs.as_slice()));\n     try!(print_fn(s, meth.decl, Some(meth.purity), AbiSet::Rust(),\n                     meth.ident, &meth.generics, Some(meth.explicit_self.node),\n                     meth.vis));\n     try!(word(&mut s.s, \" \"));\n-    print_block_with_attrs(s, meth.body, meth.attrs)\n+    print_block_with_attrs(s, meth.body, meth.attrs.as_slice())\n }\n \n pub fn print_outer_attributes(s: &mut State,\n@@ -1184,7 +1192,7 @@ pub fn print_expr(s: &mut State, expr: &ast::Expr) -> io::IoResult<()> {\n             try!(word(&mut s.s, \"mut\"));\n             if exprs.len() > 0u { try!(nbsp(s)); }\n         }\n-        try!(commasep_exprs(s, Inconsistent, *exprs));\n+        try!(commasep_exprs(s, Inconsistent, exprs.as_slice()));\n         try!(word(&mut s.s, \"]\"));\n         try!(end(s));\n       }\n@@ -1207,7 +1215,11 @@ pub fn print_expr(s: &mut State, expr: &ast::Expr) -> io::IoResult<()> {\n       ast::ExprStruct(ref path, ref fields, wth) => {\n         try!(print_path(s, path, true));\n         try!(word(&mut s.s, \"{\"));\n-        try!(commasep_cmnt(s, Consistent, (*fields), print_field, get_span));\n+        try!(commasep_cmnt(s,\n+                           Consistent,\n+                           fields.as_slice(),\n+                           print_field,\n+                           get_span));\n         match wth {\n             Some(expr) => {\n                 try!(ibox(s, indent_unit));\n@@ -1225,24 +1237,24 @@ pub fn print_expr(s: &mut State, expr: &ast::Expr) -> io::IoResult<()> {\n       }\n       ast::ExprTup(ref exprs) => {\n         try!(popen(s));\n-        try!(commasep_exprs(s, Inconsistent, *exprs));\n+        try!(commasep_exprs(s, Inconsistent, exprs.as_slice()));\n         if exprs.len() == 1 {\n             try!(word(&mut s.s, \",\"));\n         }\n         try!(pclose(s));\n       }\n       ast::ExprCall(func, ref args) => {\n         try!(print_expr(s, func));\n-        try!(print_call_post(s, *args));\n+        try!(print_call_post(s, args.as_slice()));\n       }\n       ast::ExprMethodCall(ident, ref tys, ref args) => {\n         let base_args = args.slice_from(1);\n-        try!(print_expr(s, args[0]));\n+        try!(print_expr(s, *args.get(0)));\n         try!(word(&mut s.s, \".\"));\n         try!(print_ident(s, ident));\n         if tys.len() > 0u {\n             try!(word(&mut s.s, \"::<\"));\n-            try!(commasep(s, Inconsistent, *tys, print_type_ref));\n+            try!(commasep(s, Inconsistent, tys.as_slice(), print_type_ref));\n             try!(word(&mut s.s, \">\"));\n         }\n         try!(print_call_post(s, base_args));\n@@ -1455,7 +1467,7 @@ pub fn print_expr(s: &mut State, expr: &ast::Expr) -> io::IoResult<()> {\n         try!(print_ident(s, id));\n         if tys.len() > 0u {\n             try!(word(&mut s.s, \"::<\"));\n-            try!(commasep(s, Inconsistent, *tys, print_type_ref));\n+            try!(commasep(s, Inconsistent, tys.as_slice(), print_type_ref));\n             try!(word(&mut s.s, \">\"));\n         }\n       }\n@@ -1649,7 +1661,7 @@ fn print_path_(s: &mut State,\n                 }\n                 try!(commasep(s,\n                                 Inconsistent,\n-                                segment.types.map_to_vec(|&t| t),\n+                                segment.types.map_to_vec(|&t| t).as_slice(),\n                                 print_type_ref));\n             }\n \n@@ -1708,7 +1720,7 @@ pub fn print_pat(s: &mut State, pat: &ast::Pat) -> io::IoResult<()> {\n           Some(ref args) => {\n             if !args.is_empty() {\n               try!(popen(s));\n-              try!(commasep(s, Inconsistent, *args,\n+              try!(commasep(s, Inconsistent, args.as_slice(),\n                               |s, &p| print_pat(s, p)));\n               try!(pclose(s));\n             } else { }\n@@ -1727,7 +1739,7 @@ pub fn print_pat(s: &mut State, pat: &ast::Pat) -> io::IoResult<()> {\n             Ok(())\n         }\n         fn get_span(f: &ast::FieldPat) -> codemap::Span { return f.pat.span; }\n-        try!(commasep_cmnt(s, Consistent, *fields,\n+        try!(commasep_cmnt(s, Consistent, fields.as_slice(),\n                              |s, f| print_field(s,f),\n                              get_span));\n         if etc {\n@@ -1738,7 +1750,10 @@ pub fn print_pat(s: &mut State, pat: &ast::Pat) -> io::IoResult<()> {\n       }\n       ast::PatTup(ref elts) => {\n         try!(popen(s));\n-        try!(commasep(s, Inconsistent, *elts, |s, &p| print_pat(s, p)));\n+        try!(commasep(s,\n+                      Inconsistent,\n+                      elts.as_slice(),\n+                      |s, &p| print_pat(s, p)));\n         if elts.len() == 1 {\n             try!(word(&mut s.s, \",\"));\n         }\n@@ -1761,7 +1776,10 @@ pub fn print_pat(s: &mut State, pat: &ast::Pat) -> io::IoResult<()> {\n       }\n       ast::PatVec(ref before, slice, ref after) => {\n         try!(word(&mut s.s, \"[\"));\n-        try!(commasep(s, Inconsistent, *before, |s, &p| print_pat(s, p)));\n+        try!(commasep(s,\n+                      Inconsistent,\n+                      before.as_slice(),\n+                      |s, &p| print_pat(s, p)));\n         for &p in slice.iter() {\n             if !before.is_empty() { try!(word_space(s, \",\")); }\n             match *p {\n@@ -1773,7 +1791,10 @@ pub fn print_pat(s: &mut State, pat: &ast::Pat) -> io::IoResult<()> {\n             try!(print_pat(s, p));\n             if !after.is_empty() { try!(word_space(s, \",\")); }\n         }\n-        try!(commasep(s, Inconsistent, *after, |s, &p| print_pat(s, p)));\n+        try!(commasep(s,\n+                      Inconsistent,\n+                      after.as_slice(),\n+                      |s, &p| print_pat(s, p)));\n         try!(word(&mut s.s, \"]\"));\n       }\n     }\n@@ -1842,7 +1863,7 @@ pub fn print_fn_args(s: &mut State, decl: &ast::FnDecl,\n     for &explicit_self in opt_explicit_self.iter() {\n         let m = match explicit_self {\n             ast::SelfStatic => ast::MutImmutable,\n-            _ => match decl.inputs[0].pat.node {\n+            _ => match decl.inputs.get(0).pat.node {\n                 ast::PatIdent(ast::BindByValue(m), _, _) => m,\n                 _ => ast::MutImmutable\n             }\n@@ -1986,7 +2007,7 @@ pub fn print_generics(s: &mut State,\n             ints.push(i);\n         }\n \n-        try!(commasep(s, Inconsistent, ints,\n+        try!(commasep(s, Inconsistent, ints.as_slice(),\n                         |s, &i| print_item(s, generics, i)));\n         try!(word(&mut s.s, \">\"));\n     }\n@@ -2041,7 +2062,7 @@ pub fn print_view_path(s: &mut State, vp: &ast::ViewPath) -> io::IoResult<()> {\n             try!(print_path(s, path, false));\n             try!(word(&mut s.s, \"::{\"));\n         }\n-        try!(commasep(s, Inconsistent, (*idents), |s, w| {\n+        try!(commasep(s, Inconsistent, idents.as_slice(), |s, w| {\n             print_ident(s, w.node.name)\n         }));\n         word(&mut s.s, \"}\")\n@@ -2057,7 +2078,7 @@ pub fn print_view_paths(s: &mut State,\n pub fn print_view_item(s: &mut State, item: &ast::ViewItem) -> io::IoResult<()> {\n     try!(hardbreak_if_not_bol(s));\n     try!(maybe_print_comment(s, item.span.lo));\n-    try!(print_outer_attributes(s, item.attrs));\n+    try!(print_outer_attributes(s, item.attrs.as_slice()));\n     try!(print_visibility(s, item.vis));\n     match item.node {\n         ast::ViewItemExternMod(id, ref optional_path, _) => {\n@@ -2073,7 +2094,7 @@ pub fn print_view_item(s: &mut State, item: &ast::ViewItem) -> io::IoResult<()>\n \n         ast::ViewItemUse(ref vps) => {\n             try!(head(s, \"use\"));\n-            try!(print_view_paths(s, *vps));\n+            try!(print_view_paths(s, vps.as_slice()));\n         }\n     }\n     try!(word(&mut s.s, \";\"));\n@@ -2103,7 +2124,7 @@ pub fn print_arg(s: &mut State, input: &ast::Arg) -> io::IoResult<()> {\n             match input.pat.node {\n                 ast::PatIdent(_, ref path, _) if\n                     path.segments.len() == 1 &&\n-                    path.segments[0].identifier.name ==\n+                    path.segments.get(0).identifier.name ==\n                         parse::token::special_idents::invalid.name => {\n                     // Do nothing.\n                 }\n@@ -2286,7 +2307,7 @@ pub fn print_literal(s: &mut State, lit: &ast::Lit) -> io::IoResult<()> {\n       ast::LitBinary(ref arr) => {\n         try!(ibox(s, indent_unit));\n         try!(word(&mut s.s, \"[\"));\n-        try!(commasep_cmnt(s, Inconsistent, *arr.borrow(),\n+        try!(commasep_cmnt(s, Inconsistent, arr.borrow().as_slice(),\n                              |s, u| word(&mut s.s, format!(\"{}\", *u)),\n                              |_| lit.span));\n         try!(word(&mut s.s, \"]\"));\n@@ -2303,7 +2324,7 @@ pub fn next_lit(s: &mut State, pos: BytePos) -> Option<comments::Literal> {\n     match s.literals {\n       Some(ref lits) => {\n         while s.cur_cmnt_and_lit.cur_lit < lits.len() {\n-            let ltrl = (*lits)[s.cur_cmnt_and_lit.cur_lit].clone();\n+            let ltrl = (*(*lits).get(s.cur_cmnt_and_lit.cur_lit)).clone();\n             if ltrl.pos > pos { return None; }\n             s.cur_cmnt_and_lit.cur_lit += 1u;\n             if ltrl.pos == pos { return Some(ltrl); }\n@@ -2335,7 +2356,7 @@ pub fn print_comment(s: &mut State,\n         comments::Mixed => {\n             assert_eq!(cmnt.lines.len(), 1u);\n             try!(zerobreak(&mut s.s));\n-            try!(word(&mut s.s, cmnt.lines[0]));\n+            try!(word(&mut s.s, *cmnt.lines.get(0)));\n             try!(zerobreak(&mut s.s));\n         }\n         comments::Isolated => {\n@@ -2352,7 +2373,7 @@ pub fn print_comment(s: &mut State,\n         comments::Trailing => {\n             try!(word(&mut s.s, \" \"));\n             if cmnt.lines.len() == 1u {\n-                try!(word(&mut s.s, cmnt.lines[0]));\n+                try!(word(&mut s.s, *cmnt.lines.get(0)));\n                 try!(hardbreak(&mut s.s));\n             } else {\n                 try!(ibox(s, 0u));\n@@ -2414,7 +2435,7 @@ pub fn next_comment(s: &mut State) -> Option<comments::Comment> {\n     match s.comments {\n         Some(ref cmnts) => {\n             if s.cur_cmnt_and_lit.cur_cmnt < cmnts.len() {\n-                Some(cmnts[s.cur_cmnt_and_lit.cur_cmnt].clone())\n+                Some((*cmnts.get(s.cur_cmnt_and_lit.cur_cmnt)).clone())\n             } else {\n                 None\n             }\n@@ -2535,6 +2556,8 @@ mod test {\n     use codemap;\n     use parse::token;\n \n+    use std::vec_ng::Vec;\n+\n     #[test]\n     fn test_fun_to_str() {\n         let abba_ident = token::str_to_ident(\"abba\");"}, {"sha": "ba154a8d8923c12138a9e72a219e72f98913e22e", "filename": "src/libsyntax/util/interner.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Futil%2Finterner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Futil%2Finterner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Finterner.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -21,6 +21,7 @@ use std::cmp::Equiv;\n use std::fmt;\n use std::hash::Hash;\n use std::rc::Rc;\n+use std::vec_ng::Vec;\n \n pub struct Interner<T> {\n     priv map: RefCell<HashMap<T, Name>>,\n@@ -68,7 +69,7 @@ impl<T:Eq + Hash + Freeze + Clone + 'static> Interner<T> {\n \n     pub fn get(&self, idx: Name) -> T {\n         let vect = self.vect.borrow();\n-        vect.get()[idx].clone()\n+        (*vect.get().get(idx as uint)).clone()\n     }\n \n     pub fn len(&self) -> uint {\n@@ -189,21 +190,21 @@ impl StrInterner {\n         let new_idx = self.len() as Name;\n         // leave out of map to avoid colliding\n         let mut vect = self.vect.borrow_mut();\n-        let existing = vect.get()[idx].clone();\n+        let existing = (*vect.get().get(idx as uint)).clone();\n         vect.get().push(existing);\n         new_idx\n     }\n \n     pub fn get(&self, idx: Name) -> RcStr {\n         let vect = self.vect.borrow();\n-        vect.get()[idx].clone()\n+        (*vect.get().get(idx as uint)).clone()\n     }\n \n     /// Returns this string with lifetime tied to the interner. Since\n     /// strings may never be removed from the interner, this is safe.\n     pub fn get_ref<'a>(&'a self, idx: Name) -> &'a str {\n         let vect = self.vect.borrow();\n-        let s: &str = vect.get()[idx].as_slice();\n+        let s: &str = vect.get().get(idx as uint).as_slice();\n         unsafe {\n             cast::transmute(s)\n         }"}, {"sha": "03fc30e2fd771dcca105928d87b21c5b152315aa", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -15,6 +15,8 @@ use parse::{new_parser_from_source_str};\n use parse::parser::Parser;\n use parse::token;\n \n+use std::vec_ng::Vec;\n+\n // map a string to tts, using a made-up filename: return both the TokenTree's\n // and the ParseSess\n pub fn string_to_tts_and_sess (source_str : ~str) -> (Vec<ast::TokenTree> , @ParseSess) {"}, {"sha": "9eb9871bb21414206e4ba7cdbd4c071e9d21fc37", "filename": "src/libsyntax/util/small_vector.rs", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Futil%2Fsmall_vector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Futil%2Fsmall_vector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fsmall_vector.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -7,8 +7,10 @@\n // <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n+\n use std::mem;\n-use std::vec;\n+use std::vec_ng::Vec;\n+use std::vec_ng;\n \n /// A vector type optimized for cases where the size is almost always 0 or 1\n pub enum SmallVector<T> {\n@@ -73,7 +75,7 @@ impl<T> SmallVector<T> {\n     pub fn get<'a>(&'a self, idx: uint) -> &'a T {\n         match *self {\n             One(ref v) if idx == 0 => v,\n-            Many(ref vs) => &vs[idx],\n+            Many(ref vs) => vs.get(idx),\n             _ => fail!(\"out of bounds access\")\n         }\n     }\n@@ -104,7 +106,7 @@ impl<T> SmallVector<T> {\n pub enum MoveItems<T> {\n     priv ZeroIterator,\n     priv OneIterator(T),\n-    priv ManyIterator(vec::MoveItems<T>),\n+    priv ManyIterator(vec_ng::MoveItems<T>),\n }\n \n impl<T> Iterator<T> for MoveItems<T> {\n@@ -136,6 +138,8 @@ impl<T> Iterator<T> for MoveItems<T> {\n mod test {\n     use super::*;\n \n+    use std::vec_ng::Vec;\n+\n     #[test]\n     fn test_len() {\n         let v: SmallVector<int> = SmallVector::zero();"}, {"sha": "2edfd367f4ef2712442920a25ed42d24bae74d1f", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/198cc3d850136582651489328fec221a2b98bfef/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=198cc3d850136582651489328fec221a2b98bfef", "patch": "@@ -637,7 +637,7 @@ pub fn walk_expr<E: Clone, V: Visitor<E>>(visitor: &mut V, expression: &Expr, en\n             visitor.visit_expr(subexpression, env.clone())\n         }\n         ExprVec(ref subexpressions, _) => {\n-            walk_exprs(visitor, *subexpressions, env.clone())\n+            walk_exprs(visitor, subexpressions.as_slice(), env.clone())\n         }\n         ExprRepeat(element, count, _) => {\n             visitor.visit_expr(element, env.clone());\n@@ -662,7 +662,7 @@ pub fn walk_expr<E: Clone, V: Visitor<E>>(visitor: &mut V, expression: &Expr, en\n             visitor.visit_expr(callee_expression, env.clone())\n         }\n         ExprMethodCall(_, ref types, ref arguments) => {\n-            walk_exprs(visitor, *arguments, env.clone());\n+            walk_exprs(visitor, arguments.as_slice(), env.clone());\n             for &typ in types.iter() {\n                 visitor.visit_ty(typ, env.clone())\n             }"}]}