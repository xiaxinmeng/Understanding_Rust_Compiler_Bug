{"sha": "796bfccac4215fc753f805cc61bb87a64a06b5f6", "node_id": "MDY6Q29tbWl0NzI0NzEyOjc5NmJmY2NhYzQyMTVmYzc1M2Y4MDVjYzYxYmI4N2E2NGEwNmI1ZjY=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-09-02T17:14:23Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-09-02T17:14:23Z"}, "message": "Merge #10127\n\n10127: fix: When descending tokens don't bail on failed macro call expansions r=Veykril a=Veykril\n\n(with `#[test]` expansion enabled)\r\n![image](https://user-images.githubusercontent.com/3757771/131887786-ced9988b-80fa-4e8f-b114-337572950cc3.png)\r\n\r\nThe problem was pretty simple, since we go through the ancestors we first try to expand the macro call node we are in since in attributed items these are valid syntaxnodes instead of TokenTrees, we then fail the expansion since the expansion only exists in the attribute expanded file and therefor skip the attribute expansion due to returning immediately. So instead of breaking out we just continue looking up the ancestors.\r\n\r\nFixes https://github.com/rust-analyzer/rust-analyzer/issues/10115\r\nbors r+\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>", "tree": {"sha": "236560cd88fe61d305fe3a6c273f8b2219bef2d3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/236560cd88fe61d305fe3a6c273f8b2219bef2d3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/796bfccac4215fc753f805cc61bb87a64a06b5f6", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhMQZvCRBK7hj4Ov3rIwAACXUIAIBGjkFYn2dmqzBDqz2noVmU\n/5982zKYt8zW6ITWXYIv2nzBGbfLTnAeK2E/qyMHw82+iScBh6dIPnuNhUFyFKnM\njaPdfDbmQX4MSAOexs6ukafu0MxcodQ6UWgN5c06WkXhDiULDVUIrqHPc9QHXgL4\n6G/8SrQrtFnXsfqdc9AJDToC2Nr0GDx8N+Fvr4cowdjfMAAf0I2JSrPB0MDm0dwy\nELf9eRycjzGSe6Q59fsx8JKSwwXMmIBTIJONyhZOTFRMvn4XX8U8Jd+wWt4FQ5ma\nm9Q09q9ZwMOkUNHR0ENwmdLMrJH/bdLn/ITEn3EqlpRUtgi09Ki7p55UQoPTCHg=\n=pq20\n-----END PGP SIGNATURE-----\n", "payload": "tree 236560cd88fe61d305fe3a6c273f8b2219bef2d3\nparent 2aee17e556743aa16643f5efe74347b06fc563a5\nparent 0fee14bfddcf13f370c356b94d098dea7dca378d\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1630602863 +0000\ncommitter GitHub <noreply@github.com> 1630602863 +0000\n\nMerge #10127\n\n10127: fix: When descending tokens don't bail on failed macro call expansions r=Veykril a=Veykril\n\n(with `#[test]` expansion enabled)\r\n![image](https://user-images.githubusercontent.com/3757771/131887786-ced9988b-80fa-4e8f-b114-337572950cc3.png)\r\n\r\nThe problem was pretty simple, since we go through the ancestors we first try to expand the macro call node we are in since in attributed items these are valid syntaxnodes instead of TokenTrees, we then fail the expansion since the expansion only exists in the attribute expanded file and therefor skip the attribute expansion due to returning immediately. So instead of breaking out we just continue looking up the ancestors.\r\n\r\nFixes https://github.com/rust-analyzer/rust-analyzer/issues/10115\r\nbors r+\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/796bfccac4215fc753f805cc61bb87a64a06b5f6", "html_url": "https://github.com/rust-lang/rust/commit/796bfccac4215fc753f805cc61bb87a64a06b5f6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/796bfccac4215fc753f805cc61bb87a64a06b5f6/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2aee17e556743aa16643f5efe74347b06fc563a5", "url": "https://api.github.com/repos/rust-lang/rust/commits/2aee17e556743aa16643f5efe74347b06fc563a5", "html_url": "https://github.com/rust-lang/rust/commit/2aee17e556743aa16643f5efe74347b06fc563a5"}, {"sha": "0fee14bfddcf13f370c356b94d098dea7dca378d", "url": "https://api.github.com/repos/rust-lang/rust/commits/0fee14bfddcf13f370c356b94d098dea7dca378d", "html_url": "https://github.com/rust-lang/rust/commit/0fee14bfddcf13f370c356b94d098dea7dca378d"}], "stats": {"total": 106, "additions": 57, "deletions": 49}, "files": [{"sha": "de84a0f55bbe8eacfad0c03ee4d15ff27dfb1206", "filename": "crates/hir/src/semantics.rs", "status": "modified", "additions": 57, "deletions": 49, "changes": 106, "blob_url": "https://github.com/rust-lang/rust/blob/796bfccac4215fc753f805cc61bb87a64a06b5f6/crates%2Fhir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/796bfccac4215fc753f805cc61bb87a64a06b5f6/crates%2Fhir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Fsemantics.rs?ref=796bfccac4215fc753f805cc61bb87a64a06b5f6", "patch": "@@ -467,65 +467,73 @@ impl<'db> SemanticsImpl<'db> {\n         let mut queue = vec![InFile::new(sa.file_id, token)];\n         let mut cache = self.expansion_info_cache.borrow_mut();\n         let mut res = smallvec![];\n+        // Remap the next token in the queue into a macro call its in, if it is not being remapped\n+        // either due to not being in a macro-call or because its unused push it into the result vec,\n+        // otherwise push the remapped tokens back into the queue as they can potentially be remapped again.\n         while let Some(token) = queue.pop() {\n             self.db.unwind_if_cancelled();\n \n             let was_not_remapped = (|| {\n                 for node in token.value.ancestors() {\n-                    match_ast! {\n-                        match node {\n-                            ast::MacroCall(macro_call) => {\n-                                let tt = macro_call.token_tree()?;\n-                                let l_delim = match tt.left_delimiter_token() {\n-                                    Some(it) => it.text_range().end(),\n-                                    None => tt.syntax().text_range().start()\n-                                };\n-                                let r_delim = match tt.right_delimiter_token() {\n-                                    Some(it) => it.text_range().start(),\n-                                    None => tt.syntax().text_range().end()\n-                                };\n-                                if !TextRange::new(l_delim, r_delim).contains_range(token.value.text_range()) {\n-                                    return None;\n-                                }\n-                                let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n-                                let tokens = cache\n-                                    .entry(file_id)\n-                                    .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                                    .as_ref()?\n-                                    .map_token_down(self.db.upcast(), None, token.as_ref())?;\n-\n-                                let len = queue.len();\n-                                queue.extend(tokens.inspect(|token| {\n-                                    if let Some(parent) = token.value.parent() {\n-                                        self.cache(find_root(&parent), token.file_id);\n-                                    }\n-                                }));\n-                                return (queue.len() != len).then(|| ());\n-                            },\n-                            ast::Item(item) => {\n-                                if let Some(call_id) = self.with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone()))) {\n-                                    let file_id = call_id.as_file();\n-                                    let tokens = cache\n-                                        .entry(file_id)\n-                                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                                        .as_ref()?\n-                                        .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n-\n-                                    let len = queue.len();\n-                                    queue.extend(tokens.inspect(|token| {\n-                                        if let Some(parent) = token.value.parent() {\n-                                            self.cache(find_root(&parent), token.file_id);\n-                                        }\n-                                    }));\n-                                    return (queue.len() != len).then(|| ());\n+                    if let Some(macro_call) = ast::MacroCall::cast(node.clone()) {\n+                        let tt = match macro_call.token_tree() {\n+                            Some(tt) => tt,\n+                            None => continue,\n+                        };\n+                        let l_delim = match tt.left_delimiter_token() {\n+                            Some(it) => it.text_range().end(),\n+                            None => tt.syntax().text_range().start(),\n+                        };\n+                        let r_delim = match tt.right_delimiter_token() {\n+                            Some(it) => it.text_range().start(),\n+                            None => tt.syntax().text_range().end(),\n+                        };\n+                        if !TextRange::new(l_delim, r_delim)\n+                            .contains_range(token.value.text_range())\n+                        {\n+                            continue;\n+                        }\n+                        let file_id = match sa.expand(self.db, token.with_value(&macro_call)) {\n+                            Some(file_id) => file_id,\n+                            None => continue,\n+                        };\n+                        let tokens = cache\n+                            .entry(file_id)\n+                            .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                            .as_ref()?\n+                            .map_token_down(self.db.upcast(), None, token.as_ref())?;\n+\n+                        let len = queue.len();\n+                        queue.extend(tokens.inspect(|token| {\n+                            if let Some(parent) = token.value.parent() {\n+                                self.cache(find_root(&parent), token.file_id);\n+                            }\n+                        }));\n+                        return (queue.len() != len).then(|| ());\n+                    } else if let Some(item) = ast::Item::cast(node.clone()) {\n+                        if let Some(call_id) = self\n+                            .with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone())))\n+                        {\n+                            let file_id = call_id.as_file();\n+                            let tokens = cache\n+                                .entry(file_id)\n+                                .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                                .as_ref()?\n+                                .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n+\n+                            let len = queue.len();\n+                            queue.extend(tokens.inspect(|token| {\n+                                if let Some(parent) = token.value.parent() {\n+                                    self.cache(find_root(&parent), token.file_id);\n                                 }\n-                            },\n-                            _ => {}\n+                            }));\n+                            return (queue.len() != len).then(|| ());\n                         }\n                     }\n                 }\n                 None\n-            })().is_none();\n+            })()\n+            .is_none();\n             if was_not_remapped {\n                 res.push(token.value)\n             }"}]}