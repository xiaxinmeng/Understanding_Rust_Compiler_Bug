{"sha": "242f0ae1d8e6766091a6050431c3d417a43a2a3e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI0MmYwYWUxZDhlNjc2NjA5MWE2MDUwNDMxYzNkNDE3YTQzYTJhM2U=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2019-12-18T11:47:50Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-12-18T11:47:50Z"}, "message": "Merge #2545\n\n2545: Add Token id to all tt::TokenTree r=matklad a=edwin0cheng\n\nThis PR try to add token id to all `tt::Leaf` and `tt::Delimiter`.\r\n\r\n~~Some tests are failed now because of #2544~~ \r\n\r\n~~Still blocked by a test in goto-definition : see https://github.com/rust-analyzer/rust-analyzer/pull/2544#issuecomment-565572553~~\n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>", "tree": {"sha": "b45d7619b97cc6edaf6bcf7d1a42366879bdd703", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b45d7619b97cc6edaf6bcf7d1a42366879bdd703"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/242f0ae1d8e6766091a6050431c3d417a43a2a3e", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJd+hHmCRBK7hj4Ov3rIwAAdHIIAClke4IgiBygNk8GyB9bdevN\nL7/ngsYU9Ww9IwGA96awfkuc1v1h7tlS+IuO/ef7J9m7je/sprhW+DxSsoJv0mSv\nB9f5euJQZ43U432ciGafoYUj5cbgvVIJKotEor6kplVTsu3oy2zAqvIs+pdCxCQI\nomYo2ukASBobTWgj/8GWO7GhpBfucfdqTxR5b0oohI6zMPoxwe4TpYIYuE0fAcce\nnHS5RXWPT0zDPQfnebh7/nLTr28I+85kmfMbinu5ukxoez0QOJKJ2FpbTr96DKxl\ntlNpa3bd6XHQWJCaSug91LPZQ9dF/fjiCsr05XrbZNNCRt4yNXt3T062haVliL0=\n=mbiC\n-----END PGP SIGNATURE-----\n", "payload": "tree b45d7619b97cc6edaf6bcf7d1a42366879bdd703\nparent 46ca40ccfced6945e05a25979a2703ad967d2fe0\nparent 41544a40883874553f570e2999bf56d172bd6246\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1576669670 +0000\ncommitter GitHub <noreply@github.com> 1576669670 +0000\n\nMerge #2545\n\n2545: Add Token id to all tt::TokenTree r=matklad a=edwin0cheng\n\nThis PR try to add token id to all `tt::Leaf` and `tt::Delimiter`.\r\n\r\n~~Some tests are failed now because of #2544~~ \r\n\r\n~~Still blocked by a test in goto-definition : see https://github.com/rust-analyzer/rust-analyzer/pull/2544#issuecomment-565572553~~\n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/242f0ae1d8e6766091a6050431c3d417a43a2a3e", "html_url": "https://github.com/rust-lang/rust/commit/242f0ae1d8e6766091a6050431c3d417a43a2a3e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/242f0ae1d8e6766091a6050431c3d417a43a2a3e/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "46ca40ccfced6945e05a25979a2703ad967d2fe0", "url": "https://api.github.com/repos/rust-lang/rust/commits/46ca40ccfced6945e05a25979a2703ad967d2fe0", "html_url": "https://github.com/rust-lang/rust/commit/46ca40ccfced6945e05a25979a2703ad967d2fe0"}, {"sha": "41544a40883874553f570e2999bf56d172bd6246", "url": "https://api.github.com/repos/rust-lang/rust/commits/41544a40883874553f570e2999bf56d172bd6246", "html_url": "https://github.com/rust-lang/rust/commit/41544a40883874553f570e2999bf56d172bd6246"}], "stats": {"total": 353, "additions": 272, "deletions": 81}, "files": [{"sha": "62c60e336cec21c58fcda496b1cb0cfe9a630a8e", "filename": "crates/ra_hir_expand/src/builtin_derive.rs", "status": "modified", "additions": 24, "deletions": 4, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_hir_expand%2Fsrc%2Fbuiltin_derive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_hir_expand%2Fsrc%2Fbuiltin_derive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Fbuiltin_derive.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -97,11 +97,24 @@ fn parse_adt(tt: &tt::Subtree) -> Result<BasicAdtInfo, mbe::ExpandError> {\n \n fn make_type_args(n: usize, bound: Vec<tt::TokenTree>) -> Vec<tt::TokenTree> {\n     let mut result = Vec::<tt::TokenTree>::new();\n-    result.push(tt::Leaf::Punct(tt::Punct { char: '<', spacing: tt::Spacing::Alone }).into());\n+    result.push(\n+        tt::Leaf::Punct(tt::Punct {\n+            char: '<',\n+            spacing: tt::Spacing::Alone,\n+            id: tt::TokenId::unspecified(),\n+        })\n+        .into(),\n+    );\n     for i in 0..n {\n         if i > 0 {\n-            result\n-                .push(tt::Leaf::Punct(tt::Punct { char: ',', spacing: tt::Spacing::Alone }).into());\n+            result.push(\n+                tt::Leaf::Punct(tt::Punct {\n+                    char: ',',\n+                    spacing: tt::Spacing::Alone,\n+                    id: tt::TokenId::unspecified(),\n+                })\n+                .into(),\n+            );\n         }\n         result.push(\n             tt::Leaf::Ident(tt::Ident {\n@@ -112,7 +125,14 @@ fn make_type_args(n: usize, bound: Vec<tt::TokenTree>) -> Vec<tt::TokenTree> {\n         );\n         result.extend(bound.iter().cloned());\n     }\n-    result.push(tt::Leaf::Punct(tt::Punct { char: '>', spacing: tt::Spacing::Alone }).into());\n+    result.push(\n+        tt::Leaf::Punct(tt::Punct {\n+            char: '>',\n+            spacing: tt::Spacing::Alone,\n+            id: tt::TokenId::unspecified(),\n+        })\n+        .into(),\n+    );\n     result\n }\n "}, {"sha": "2fa5d51402bc6f8828e1f1147fb6cb76df4f32f6", "filename": "crates/ra_hir_expand/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Flib.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -227,7 +227,7 @@ impl ExpansionInfo {\n         let token_id = self.macro_arg.1.token_by_range(range)?;\n         let token_id = self.macro_def.0.map_id_down(token_id);\n \n-        let range = self.exp_map.range_by_token(token_id)?;\n+        let range = self.exp_map.range_by_token(token_id)?.by_kind(token.value.kind())?;\n \n         let token = algo::find_covering_element(&self.expanded.value, range).into_token()?;\n \n@@ -248,7 +248,7 @@ impl ExpansionInfo {\n             }\n         };\n \n-        let range = token_map.range_by_token(token_id)?;\n+        let range = token_map.range_by_token(token_id)?.by_kind(token.value.kind())?;\n         let token = algo::find_covering_element(&tt.value, range + tt.value.text_range().start())\n             .into_token()?;\n         Some((tt.with_value(token), origin))"}, {"sha": "49155fe6262c234d8bd222a4e13ac75d2dc41b80", "filename": "crates/ra_hir_expand/src/quote.rs", "status": "modified", "additions": 19, "deletions": 8, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_hir_expand%2Fsrc%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_hir_expand%2Fsrc%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Fquote.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -16,7 +16,10 @@ macro_rules! __quote {\n         {\n             let children = $crate::__quote!($($tt)*);\n             let subtree = tt::Subtree {\n-                delimiter: Some(tt::Delimiter::$delim),\n+                delimiter: Some(tt::Delimiter {\n+                    kind: tt::DelimiterKind::$delim,\n+                    id: tt::TokenId::unspecified(),\n+                }),\n                 token_trees: $crate::quote::IntoTt::to_tokens(children),\n             };\n             subtree\n@@ -29,6 +32,7 @@ macro_rules! __quote {\n                 tt::Leaf::Punct(tt::Punct {\n                     char: $first,\n                     spacing: tt::Spacing::Alone,\n+                    id: tt::TokenId::unspecified(),\n                 }).into()\n             ]\n         }\n@@ -40,10 +44,12 @@ macro_rules! __quote {\n                 tt::Leaf::Punct(tt::Punct {\n                     char: $first,\n                     spacing: tt::Spacing::Joint,\n+                    id: tt::TokenId::unspecified(),\n                 }).into(),\n                 tt::Leaf::Punct(tt::Punct {\n                     char: $sec,\n                     spacing: tt::Spacing::Alone,\n+                    id: tt::TokenId::unspecified(),\n                 }).into()\n             ]\n         }\n@@ -179,15 +185,15 @@ macro_rules! impl_to_to_tokentrees {\n }\n \n impl_to_to_tokentrees! {\n-    u32 => self { tt::Literal{text: self.to_string().into()} };\n-    usize => self { tt::Literal{text: self.to_string().into()}};\n-    i32 => self { tt::Literal{text: self.to_string().into()}};\n+    u32 => self { tt::Literal{text: self.to_string().into(), id: tt::TokenId::unspecified()} };\n+    usize => self { tt::Literal{text: self.to_string().into(), id: tt::TokenId::unspecified()}};\n+    i32 => self { tt::Literal{text: self.to_string().into(), id: tt::TokenId::unspecified()}};\n     tt::Leaf => self { self };\n     tt::Literal => self { self };\n     tt::Ident => self { self };\n     tt::Punct => self { self };\n-    &str => self { tt::Literal{text: format!(\"{:?}\", self.escape_default().to_string()).into()}};\n-    String => self { tt::Literal{text: format!(\"{:?}\", self.escape_default().to_string()).into()}}\n+    &str => self { tt::Literal{text: format!(\"{:?}\", self.escape_default().to_string()).into(), id: tt::TokenId::unspecified()}};\n+    String => self { tt::Literal{text: format!(\"{:?}\", self.escape_default().to_string()).into(), id: tt::TokenId::unspecified()}}\n }\n \n #[cfg(test)]\n@@ -254,8 +260,13 @@ mod tests {\n         let fields =\n             fields.iter().map(|it| quote!(#it: self.#it.clone(), ).token_trees.clone()).flatten();\n \n-        let list =\n-            tt::Subtree { delimiter: Some(tt::Delimiter::Brace), token_trees: fields.collect() };\n+        let list = tt::Subtree {\n+            delimiter: Some(tt::Delimiter {\n+                kind: tt::DelimiterKind::Brace,\n+                id: tt::TokenId::unspecified(),\n+            }),\n+            token_trees: fields.collect(),\n+        };\n \n         let quoted = quote! {\n             impl Clone for #struct_name {"}, {"sha": "45dad2d108bc8ffda931f94515a9c51e6dcd278e", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 15, "deletions": 3, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -67,7 +67,15 @@ impl Shift {\n                 .token_trees\n                 .iter()\n                 .filter_map(|tt| match tt {\n-                    tt::TokenTree::Subtree(subtree) => max_id(subtree),\n+                    tt::TokenTree::Subtree(subtree) => {\n+                        let tree_id = max_id(subtree);\n+                        match subtree.delimiter {\n+                            Some(it) if it.id != tt::TokenId::unspecified() => {\n+                                Some(tree_id.map_or(it.id.0, |t| t.max(it.id.0)))\n+                            }\n+                            _ => tree_id,\n+                        }\n+                    }\n                     tt::TokenTree::Leaf(tt::Leaf::Ident(ident))\n                         if ident.id != tt::TokenId::unspecified() =>\n                     {\n@@ -85,9 +93,13 @@ impl Shift {\n             match t {\n                 tt::TokenTree::Leaf(leaf) => match leaf {\n                     tt::Leaf::Ident(ident) => ident.id = self.shift(ident.id),\n-                    _ => (),\n+                    tt::Leaf::Punct(punct) => punct.id = self.shift(punct.id),\n+                    tt::Leaf::Literal(lit) => lit.id = self.shift(lit.id),\n                 },\n-                tt::TokenTree::Subtree(tt) => self.shift_all(tt),\n+                tt::TokenTree::Subtree(tt) => {\n+                    tt.delimiter.as_mut().map(|it: &mut Delimiter| it.id = self.shift(it.id));\n+                    self.shift_all(tt)\n+                }\n             }\n         }\n     }"}, {"sha": "e36b5a412b903dc65487b61e1a010d9f94cbed35", "filename": "crates/ra_mbe/src/mbe_expander/matcher.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fmbe_expander%2Fmatcher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fmbe_expander%2Fmatcher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fmbe_expander%2Fmatcher.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -106,7 +106,7 @@ fn match_subtree(\n             }\n             Op::TokenTree(tt::TokenTree::Subtree(lhs)) => {\n                 let rhs = src.expect_subtree().map_err(|()| err!(\"expected subtree\"))?;\n-                if lhs.delimiter != rhs.delimiter {\n+                if lhs.delimiter_kind() != rhs.delimiter_kind() {\n                     bail!(\"mismatched delimiter\")\n                 }\n                 let mut src = TtIter::new(rhs);"}, {"sha": "eda66cd506ebe2f6928011ee20877e10e339f900", "filename": "crates/ra_mbe/src/mbe_expander/transcriber.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fmbe_expander%2Ftranscriber.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fmbe_expander%2Ftranscriber.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fmbe_expander%2Ftranscriber.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -108,7 +108,12 @@ fn expand_var(ctx: &mut ExpandCtx, v: &SmolStr) -> Result<Fragment, ExpandError>\n         let tt = tt::Subtree {\n             delimiter: None,\n             token_trees: vec![\n-                tt::Leaf::from(tt::Punct { char: '$', spacing: tt::Spacing::Alone }).into(),\n+                tt::Leaf::from(tt::Punct {\n+                    char: '$',\n+                    spacing: tt::Spacing::Alone,\n+                    id: tt::TokenId::unspecified(),\n+                })\n+                .into(),\n                 tt::Leaf::from(tt::Ident { text: v.clone(), id: tt::TokenId::unspecified() })\n                     .into(),\n             ],"}, {"sha": "b841c39d31440aa54c45c70873ad9d2c3cd621a2", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -70,11 +70,11 @@ impl<'a> SubtreeTokenSource<'a> {\n                     }\n                     Some(tt::TokenTree::Subtree(subtree)) => {\n                         self.cached_cursor.set(cursor.subtree().unwrap());\n-                        cached.push(Some(convert_delim(subtree.delimiter, false)));\n+                        cached.push(Some(convert_delim(subtree.delimiter_kind(), false)));\n                     }\n                     None => {\n                         if let Some(subtree) = cursor.end() {\n-                            cached.push(Some(convert_delim(subtree.delimiter, true)));\n+                            cached.push(Some(convert_delim(subtree.delimiter_kind(), true)));\n                             self.cached_cursor.set(cursor.bump());\n                         }\n                     }\n@@ -114,11 +114,11 @@ impl<'a> TokenSource for SubtreeTokenSource<'a> {\n     }\n }\n \n-fn convert_delim(d: Option<tt::Delimiter>, closing: bool) -> TtToken {\n+fn convert_delim(d: Option<tt::DelimiterKind>, closing: bool) -> TtToken {\n     let (kinds, texts) = match d {\n-        Some(tt::Delimiter::Parenthesis) => ([T!['('], T![')']], \"()\"),\n-        Some(tt::Delimiter::Brace) => ([T!['{'], T!['}']], \"{}\"),\n-        Some(tt::Delimiter::Bracket) => ([T!['['], T![']']], \"[]\"),\n+        Some(tt::DelimiterKind::Parenthesis) => ([T!['('], T![')']], \"()\"),\n+        Some(tt::DelimiterKind::Brace) => ([T!['{'], T!['}']], \"{}\"),\n+        Some(tt::DelimiterKind::Bracket) => ([T!['['], T![']']], \"[]\"),\n         None => ([L_DOLLAR, R_DOLLAR], \"\"),\n     };\n "}, {"sha": "2c60430d155cd51cfe072551124d276bfb563043", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 131, "deletions": 45, "changes": 176, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -5,17 +5,37 @@ use ra_syntax::{\n     ast, AstToken, NodeOrToken, Parse, SmolStr, SyntaxKind, SyntaxKind::*, SyntaxNode,\n     SyntaxTreeBuilder, TextRange, TextUnit, T,\n };\n+use rustc_hash::FxHashMap;\n use std::iter::successors;\n use tt::buffer::{Cursor, TokenBuffer};\n \n use crate::subtree_source::SubtreeTokenSource;\n use crate::ExpandError;\n \n+#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n+pub enum TokenTextRange {\n+    Token(TextRange),\n+    Delimiter(TextRange, TextRange),\n+}\n+\n+impl TokenTextRange {\n+    pub fn by_kind(self, kind: SyntaxKind) -> Option<TextRange> {\n+        match self {\n+            TokenTextRange::Token(it) => Some(it),\n+            TokenTextRange::Delimiter(open, close) => match kind {\n+                T!['{'] | T!['('] | T!['['] => Some(open),\n+                T!['}'] | T![')'] | T![']'] => Some(close),\n+                _ => None,\n+            },\n+        }\n+    }\n+}\n+\n /// Maps `tt::TokenId` to the relative range of the original token.\n #[derive(Debug, PartialEq, Eq, Default)]\n pub struct TokenMap {\n     /// Maps `tt::TokenId` to the *relative* source range.\n-    entries: Vec<(tt::TokenId, TextRange)>,\n+    entries: Vec<(tt::TokenId, TokenTextRange)>,\n }\n \n /// Convert the syntax tree (what user has written) to a `TokenTree` (what macro\n@@ -71,17 +91,32 @@ pub fn token_tree_to_syntax_node(\n \n impl TokenMap {\n     pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n-        let &(token_id, _) = self.entries.iter().find(|(_, range)| *range == relative_range)?;\n+        let &(token_id, _) = self.entries.iter().find(|(_, range)| match range {\n+            TokenTextRange::Token(it) => *it == relative_range,\n+            TokenTextRange::Delimiter(open, close) => {\n+                *open == relative_range || *close == relative_range\n+            }\n+        })?;\n         Some(token_id)\n     }\n \n-    pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TextRange> {\n+    pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TokenTextRange> {\n         let &(_, range) = self.entries.iter().find(|(tid, _)| *tid == token_id)?;\n         Some(range)\n     }\n \n     fn insert(&mut self, token_id: tt::TokenId, relative_range: TextRange) {\n-        self.entries.push((token_id, relative_range));\n+        self.entries.push((token_id, TokenTextRange::Token(relative_range)));\n+    }\n+\n+    fn insert_delim(\n+        &mut self,\n+        token_id: tt::TokenId,\n+        open_relative_range: TextRange,\n+        close_relative_range: TextRange,\n+    ) {\n+        self.entries\n+            .push((token_id, TokenTextRange::Delimiter(open_relative_range, close_relative_range)));\n     }\n }\n \n@@ -121,7 +156,10 @@ fn convert_doc_comment(token: &ra_syntax::SyntaxToken) -> Option<Vec<tt::TokenTr\n         token_trees.push(mk_punct('!'));\n     }\n     token_trees.push(tt::TokenTree::from(tt::Subtree {\n-        delimiter: Some(tt::Delimiter::Bracket),\n+        delimiter: Some(tt::Delimiter {\n+            kind: tt::DelimiterKind::Bracket,\n+            id: tt::TokenId::unspecified(),\n+        }),\n         token_trees: meta_tkns,\n     }));\n \n@@ -136,11 +174,15 @@ fn convert_doc_comment(token: &ra_syntax::SyntaxToken) -> Option<Vec<tt::TokenTr\n     }\n \n     fn mk_punct(c: char) -> tt::TokenTree {\n-        tt::TokenTree::from(tt::Leaf::from(tt::Punct { char: c, spacing: tt::Spacing::Alone }))\n+        tt::TokenTree::from(tt::Leaf::from(tt::Punct {\n+            char: c,\n+            spacing: tt::Spacing::Alone,\n+            id: tt::TokenId::unspecified(),\n+        }))\n     }\n \n     fn mk_doc_literal(comment: &ast::Comment) -> tt::TokenTree {\n-        let lit = tt::Literal { text: doc_comment_text(comment) };\n+        let lit = tt::Literal { text: doc_comment_text(comment), id: tt::TokenId::unspecified() };\n \n         tt::TokenTree::from(tt::Leaf::from(lit))\n     }\n@@ -186,12 +228,16 @@ impl Convertor {\n         .last()\n         .unwrap();\n \n-        let (delimiter, skip_first) = match (first_child.kind(), last_child.kind()) {\n-            (T!['('], T![')']) => (Some(tt::Delimiter::Parenthesis), true),\n-            (T!['{'], T!['}']) => (Some(tt::Delimiter::Brace), true),\n-            (T!['['], T![']']) => (Some(tt::Delimiter::Bracket), true),\n+        let (delimiter_kind, skip_first) = match (first_child.kind(), last_child.kind()) {\n+            (T!['('], T![')']) => (Some(tt::DelimiterKind::Parenthesis), true),\n+            (T!['{'], T!['}']) => (Some(tt::DelimiterKind::Brace), true),\n+            (T!['['], T![']']) => (Some(tt::DelimiterKind::Bracket), true),\n             _ => (None, false),\n         };\n+        let delimiter = delimiter_kind.map(|kind| tt::Delimiter {\n+            kind,\n+            id: self.alloc_delim(first_child.text_range(), last_child.text_range()),\n+        });\n \n         let mut token_trees = Vec::new();\n         let mut child_iter = tt.children_with_tokens().skip(skip_first as usize).peekable();\n@@ -223,25 +269,34 @@ impl Convertor {\n                             .take(token.text().len() - 1)\n                             .chain(std::iter::once(last_spacing));\n                         for (char, spacing) in token.text().chars().zip(spacing_iter) {\n-                            token_trees.push(tt::Leaf::from(tt::Punct { char, spacing }).into());\n+                            token_trees.push(\n+                                tt::Leaf::from(tt::Punct {\n+                                    char,\n+                                    spacing,\n+                                    id: self.alloc(token.text_range()),\n+                                })\n+                                .into(),\n+                            );\n                         }\n                     } else {\n-                        let child: tt::TokenTree =\n-                            if token.kind() == T![true] || token.kind() == T![false] {\n-                                tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n-                            } else if token.kind().is_keyword()\n-                                || token.kind() == IDENT\n-                                || token.kind() == LIFETIME\n-                            {\n-                                let id = self.alloc(token.text_range());\n-                                let text = token.text().clone();\n-                                tt::Leaf::from(tt::Ident { text, id }).into()\n-                            } else if token.kind().is_literal() {\n-                                tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n-                            } else {\n-                                return None;\n+                        macro_rules! make_leaf {\n+                            ($i:ident) => {\n+                                tt::$i {\n+                                    id: self.alloc(token.text_range()),\n+                                    text: token.text().clone(),\n+                                }\n+                                .into()\n                             };\n-                        token_trees.push(child);\n+                        }\n+\n+                        let child: tt::Leaf = match token.kind() {\n+                            T![true] | T![false] => make_leaf!(Literal),\n+                            IDENT | LIFETIME => make_leaf!(Ident),\n+                            k if k.is_keyword() => make_leaf!(Ident),\n+                            k if k.is_literal() => make_leaf!(Literal),\n+                            _ => return None,\n+                        };\n+                        token_trees.push(child.into());\n                     }\n                 }\n                 NodeOrToken::Node(node) => {\n@@ -266,11 +321,26 @@ impl Convertor {\n         self.map.insert(token_id, relative_range);\n         token_id\n     }\n+\n+    fn alloc_delim(\n+        &mut self,\n+        open_abs_range: TextRange,\n+        close_abs_range: TextRange,\n+    ) -> tt::TokenId {\n+        let open_relative_range = open_abs_range - self.global_offset;\n+        let close_relative_range = close_abs_range - self.global_offset;\n+        let token_id = tt::TokenId(self.next_id);\n+        self.next_id += 1;\n+\n+        self.map.insert_delim(token_id, open_relative_range, close_relative_range);\n+        token_id\n+    }\n }\n \n struct TtTreeSink<'a> {\n     buf: String,\n     cursor: Cursor<'a>,\n+    open_delims: FxHashMap<tt::TokenId, TextUnit>,\n     text_pos: TextUnit,\n     inner: SyntaxTreeBuilder,\n     token_map: TokenMap,\n@@ -285,6 +355,7 @@ impl<'a> TtTreeSink<'a> {\n         TtTreeSink {\n             buf: String::new(),\n             cursor,\n+            open_delims: FxHashMap::default(),\n             text_pos: 0.into(),\n             inner: SyntaxTreeBuilder::default(),\n             roots: smallvec::SmallVec::new(),\n@@ -297,11 +368,11 @@ impl<'a> TtTreeSink<'a> {\n     }\n }\n \n-fn delim_to_str(d: Option<tt::Delimiter>, closing: bool) -> SmolStr {\n+fn delim_to_str(d: Option<tt::DelimiterKind>, closing: bool) -> SmolStr {\n     let texts = match d {\n-        Some(tt::Delimiter::Parenthesis) => \"()\",\n-        Some(tt::Delimiter::Brace) => \"{}\",\n-        Some(tt::Delimiter::Bracket) => \"[]\",\n+        Some(tt::DelimiterKind::Parenthesis) => \"()\",\n+        Some(tt::DelimiterKind::Brace) => \"{}\",\n+        Some(tt::DelimiterKind::Bracket) => \"[]\",\n         None => return \"\".into(),\n     };\n \n@@ -322,34 +393,49 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n                 break;\n             }\n \n-            match self.cursor.token_tree() {\n+            let text: SmolStr = match self.cursor.token_tree() {\n                 Some(tt::TokenTree::Leaf(leaf)) => {\n                     // Mark the range if needed\n-                    if let tt::Leaf::Ident(ident) = leaf {\n-                        if kind == IDENT {\n-                            let range =\n-                                TextRange::offset_len(self.text_pos, TextUnit::of_str(&ident.text));\n-                            self.token_map.insert(ident.id, range);\n-                        }\n-                    }\n-\n+                    let id = match leaf {\n+                        tt::Leaf::Ident(ident) => ident.id,\n+                        tt::Leaf::Punct(punct) => punct.id,\n+                        tt::Leaf::Literal(lit) => lit.id,\n+                    };\n+                    let text = SmolStr::new(format!(\"{}\", leaf));\n+                    let range = TextRange::offset_len(self.text_pos, TextUnit::of_str(&text));\n+                    self.token_map.insert(id, range);\n                     self.cursor = self.cursor.bump();\n-                    self.buf += &format!(\"{}\", leaf);\n+                    text\n                 }\n                 Some(tt::TokenTree::Subtree(subtree)) => {\n                     self.cursor = self.cursor.subtree().unwrap();\n-                    self.buf += &delim_to_str(subtree.delimiter, false);\n+                    if let Some(id) = subtree.delimiter.map(|it| it.id) {\n+                        self.open_delims.insert(id, self.text_pos);\n+                    }\n+                    delim_to_str(subtree.delimiter_kind(), false)\n                 }\n                 None => {\n                     if let Some(parent) = self.cursor.end() {\n                         self.cursor = self.cursor.bump();\n-                        self.buf += &delim_to_str(parent.delimiter, true);\n+                        if let Some(id) = parent.delimiter.map(|it| it.id) {\n+                            if let Some(open_delim) = self.open_delims.get(&id) {\n+                                let open_range =\n+                                    TextRange::offset_len(*open_delim, TextUnit::from_usize(1));\n+                                let close_range =\n+                                    TextRange::offset_len(self.text_pos, TextUnit::from_usize(1));\n+                                self.token_map.insert_delim(id, open_range, close_range);\n+                            }\n+                        }\n+                        delim_to_str(parent.delimiter_kind(), true)\n+                    } else {\n+                        continue;\n                     }\n                 }\n             };\n+            self.buf += &text;\n+            self.text_pos += TextUnit::of_str(&text);\n         }\n \n-        self.text_pos += TextUnit::of_str(&self.buf);\n         let text = SmolStr::new(self.buf.as_str());\n         self.buf.clear();\n         self.inner.token(kind, text);\n@@ -495,7 +581,7 @@ mod tests {\n         let token_tree = ast::TokenTree::cast(token_tree).unwrap();\n         let tt = ast_to_token_tree(&token_tree).unwrap().0;\n \n-        assert_eq!(tt.delimiter, Some(tt::Delimiter::Brace));\n+        assert_eq!(tt.delimiter_kind(), Some(tt::DelimiterKind::Brace));\n     }\n \n     #[test]"}, {"sha": "ff225f0db21d8ba650bc25cb38b187927bcca1b8", "filename": "crates/ra_mbe/src/tests.rs", "status": "modified", "additions": 51, "deletions": 6, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_mbe%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Ftests.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -77,13 +77,41 @@ macro_rules! foobar {\n     }\n \n     assert_eq!(expansion.token_trees.len(), 3);\n-    // ($e:ident) => { foo bar $e }\n-    //   0 1            2   3   4\n-    assert_eq!(get_id(&expansion.token_trees[0]), Some(2));\n-    assert_eq!(get_id(&expansion.token_trees[1]), Some(3));\n+    // {($e:ident) => { foo bar $e }}\n+    // 012345      67 8 9   T   12\n+    assert_eq!(get_id(&expansion.token_trees[0]), Some(9));\n+    assert_eq!(get_id(&expansion.token_trees[1]), Some(10));\n \n-    // So baz should be 5\n-    assert_eq!(get_id(&expansion.token_trees[2]), Some(5));\n+    // The input args of macro call include parentheses:\n+    // (baz)\n+    // So baz should be 12+1+1\n+    assert_eq!(get_id(&expansion.token_trees[2]), Some(14));\n+}\n+\n+#[test]\n+fn test_token_map() {\n+    use ra_parser::SyntaxKind::*;\n+    use ra_syntax::T;\n+\n+    let macro_definition = r#\"\n+macro_rules! foobar {\n+    ($e:ident) => { fn $e() {} }\n+}\n+\"#;\n+    let rules = create_rules(macro_definition);\n+    let (expansion, (token_map, content)) = expand_and_map(&rules, \"foobar!(baz);\");\n+\n+    let get_text = |id, kind| -> String {\n+        content[token_map.range_by_token(id).unwrap().by_kind(kind).unwrap()].to_string()\n+    };\n+\n+    assert_eq!(expansion.token_trees.len(), 4);\n+    // {($e:ident) => { fn $e() {} }}\n+    // 012345      67 8 9  T12  3\n+\n+    assert_eq!(get_text(tt::TokenId(9), IDENT), \"fn\");\n+    assert_eq!(get_text(tt::TokenId(12), T!['(']), \"(\");\n+    assert_eq!(get_text(tt::TokenId(13), T!['{']), \"{\");\n }\n \n #[test]\n@@ -1441,6 +1469,23 @@ pub(crate) fn expand(rules: &MacroRules, invocation: &str) -> tt::Subtree {\n     rules.expand(&invocation_tt).unwrap()\n }\n \n+pub(crate) fn expand_and_map(\n+    rules: &MacroRules,\n+    invocation: &str,\n+) -> (tt::Subtree, (TokenMap, String)) {\n+    let source_file = ast::SourceFile::parse(invocation).ok().unwrap();\n+    let macro_invocation =\n+        source_file.syntax().descendants().find_map(ast::MacroCall::cast).unwrap();\n+\n+    let (invocation_tt, _) = ast_to_token_tree(&macro_invocation.token_tree().unwrap()).unwrap();\n+    let expanded = rules.expand(&invocation_tt).unwrap();\n+\n+    let (node, expanded_token_tree) =\n+        token_tree_to_syntax_node(&expanded, FragmentKind::Items).unwrap();\n+\n+    (expanded, (expanded_token_tree, node.syntax_node().to_string()))\n+}\n+\n pub(crate) enum MacroKind {\n     Items,\n     Stmts,"}, {"sha": "10f424aae96c645cecae2b7f5e411c61d24a79c0", "filename": "crates/ra_tt/src/lib.rs", "status": "modified", "additions": 17, "deletions": 5, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_tt%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/242f0ae1d8e6766091a6050431c3d417a43a2a3e/crates%2Fra_tt%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_tt%2Fsrc%2Flib.rs?ref=242f0ae1d8e6766091a6050431c3d417a43a2a3e", "patch": "@@ -55,7 +55,13 @@ pub struct Subtree {\n }\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]\n-pub enum Delimiter {\n+pub struct Delimiter {\n+    pub id: TokenId,\n+    pub kind: DelimiterKind,\n+}\n+\n+#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]\n+pub enum DelimiterKind {\n     Parenthesis,\n     Brace,\n     Bracket,\n@@ -64,12 +70,14 @@ pub enum Delimiter {\n #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n pub struct Literal {\n     pub text: SmolStr,\n+    pub id: TokenId,\n }\n \n #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n pub struct Punct {\n     pub char: char,\n     pub spacing: Spacing,\n+    pub id: TokenId,\n }\n \n #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n@@ -95,10 +103,10 @@ impl fmt::Display for TokenTree {\n \n impl fmt::Display for Subtree {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        let (l, r) = match self.delimiter {\n-            Some(Delimiter::Parenthesis) => (\"(\", \")\"),\n-            Some(Delimiter::Brace) => (\"{\", \"}\"),\n-            Some(Delimiter::Bracket) => (\"[\", \"]\"),\n+        let (l, r) = match self.delimiter_kind() {\n+            Some(DelimiterKind::Parenthesis) => (\"(\", \")\"),\n+            Some(DelimiterKind::Brace) => (\"{\", \"}\"),\n+            Some(DelimiterKind::Bracket) => (\"[\", \"]\"),\n             None => (\"\", \"\"),\n         };\n         f.write_str(l)?;\n@@ -163,6 +171,10 @@ impl Subtree {\n \n         self.token_trees.len() + children_count\n     }\n+\n+    pub fn delimiter_kind(&self) -> Option<DelimiterKind> {\n+        self.delimiter.map(|it| it.kind)\n+    }\n }\n \n pub mod buffer;"}]}