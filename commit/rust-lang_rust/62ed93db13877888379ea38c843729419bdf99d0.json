{"sha": "62ed93db13877888379ea38c843729419bdf99d0", "node_id": "MDY6Q29tbWl0NzI0NzEyOjYyZWQ5M2RiMTM4Nzc4ODgzNzllYTM4Yzg0MzcyOTQxOWJkZjk5ZDA=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-11-08T01:57:01Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-11-08T02:19:41Z"}, "message": "Refactor and add more comments", "tree": {"sha": "4c5097eb65cc19861580cbc29bd2fc43486fed84", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4c5097eb65cc19861580cbc29bd2fc43486fed84"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/62ed93db13877888379ea38c843729419bdf99d0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/62ed93db13877888379ea38c843729419bdf99d0", "html_url": "https://github.com/rust-lang/rust/commit/62ed93db13877888379ea38c843729419bdf99d0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/62ed93db13877888379ea38c843729419bdf99d0/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "568f3cff41fd4ef49468b60f4343755a5b7b05cb", "url": "https://api.github.com/repos/rust-lang/rust/commits/568f3cff41fd4ef49468b60f4343755a5b7b05cb", "html_url": "https://github.com/rust-lang/rust/commit/568f3cff41fd4ef49468b60f4343755a5b7b05cb"}], "stats": {"total": 110, "additions": 52, "deletions": 58}, "files": [{"sha": "1eaf8bf309e7d93e28efdafb68075ce311629f90", "filename": "crates/ra_hir_expand/src/db.rs", "status": "modified", "additions": 6, "deletions": 8, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/62ed93db13877888379ea38c843729419bdf99d0/crates%2Fra_hir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/62ed93db13877888379ea38c843729419bdf99d0/crates%2Fra_hir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Fdb.rs?ref=62ed93db13877888379ea38c843729419bdf99d0", "patch": "@@ -148,17 +148,15 @@ pub(crate) fn parse_macro_with_info(\n     let arg_tt = loc.ast_id.to_node(db).token_tree();\n     let def_tt = loc.def.ast_id.to_node(db).token_tree();\n \n-    let arg_start = arg_tt.map(|t| t.syntax().text_range().start());\n-    let def_start = def_tt.map(|t| t.syntax().text_range().start());\n+    let arg_range = arg_tt.map(|t| t.syntax().text_range());\n+    let def_range = def_tt.map(|t| t.syntax().text_range());\n \n     let shift = db.macro_def(loc.def)?.0.shift();\n \n-    let arg_map = arg_start\n-        .map(|start| exp_map.map_ranges(&expand_info.arg_map, start, shift))\n-        .unwrap_or_default();\n-    let def_map = def_start\n-        .map(|start| exp_map.map_ranges(&expand_info.def_map, start, 0))\n-        .unwrap_or_default();\n+    let arg_map =\n+        arg_range.map(|it| exp_map.map_ranges(&expand_info.arg_map, it, shift)).unwrap_or_default();\n+    let def_map =\n+        def_range.map(|it| exp_map.map_ranges(&expand_info.def_map, it, 0)).unwrap_or_default();\n \n     let info = ExpansionInfo { arg_map, def_map };\n "}, {"sha": "a49e63ace49b06154a3025a2dd58e29072787fee", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 46, "deletions": 50, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/62ed93db13877888379ea38c843729419bdf99d0/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/62ed93db13877888379ea38c843729419bdf99d0/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=62ed93db13877888379ea38c843729419bdf99d0", "patch": "@@ -22,7 +22,7 @@ pub struct TokenMap {\n \n /// Maps relative range of the expanded syntax node to `tt::TokenId`\n #[derive(Debug, PartialEq, Eq, Default)]\n-pub struct ExpandedRangeMap {\n+pub struct RevTokenMap {\n     ranges: Vec<(TextRange, tt::TokenId)>,\n }\n \n@@ -58,7 +58,7 @@ pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> Option<(tt::Subtree, Toke\n fn fragment_to_syntax_node(\n     tt: &tt::Subtree,\n     fragment_kind: FragmentKind,\n-) -> Result<(Parse<SyntaxNode>, ExpandedRangeMap), ExpandError> {\n+) -> Result<(Parse<SyntaxNode>, RevTokenMap), ExpandError> {\n     let tmp;\n     let tokens = match tt {\n         tt::Subtree { delimiter: tt::Delimiter::None, token_trees } => token_trees.as_slice(),\n@@ -79,44 +79,29 @@ fn fragment_to_syntax_node(\n     Ok((parse, range_map))\n }\n \n-/// Parses the token tree (result of macro expansion) to an expression\n-pub fn token_tree_to_expr(\n-    tt: &tt::Subtree,\n-) -> Result<(Parse<ast::Expr>, ExpandedRangeMap), ExpandError> {\n-    let (parse, map) = fragment_to_syntax_node(tt, Expr)?;\n-    parse.cast().ok_or_else(|| crate::ExpandError::ConversionError).map(|p| (p, map))\n-}\n-\n-/// Parses the token tree (result of macro expansion) to a Pattern\n-pub fn token_tree_to_pat(\n-    tt: &tt::Subtree,\n-) -> Result<(Parse<ast::Pat>, ExpandedRangeMap), ExpandError> {\n-    let (parse, map) = fragment_to_syntax_node(tt, Pattern)?;\n-    parse.cast().ok_or_else(|| crate::ExpandError::ConversionError).map(|p| (p, map))\n-}\n-\n-/// Parses the token tree (result of macro expansion) to a Type\n-pub fn token_tree_to_ty(\n-    tt: &tt::Subtree,\n-) -> Result<(Parse<ast::TypeRef>, ExpandedRangeMap), ExpandError> {\n-    let (parse, map) = fragment_to_syntax_node(tt, Type)?;\n-    parse.cast().ok_or_else(|| crate::ExpandError::ConversionError).map(|p| (p, map))\n-}\n-\n-/// Parses the token tree (result of macro expansion) as a sequence of stmts\n-pub fn token_tree_to_macro_stmts(\n-    tt: &tt::Subtree,\n-) -> Result<(Parse<ast::MacroStmts>, ExpandedRangeMap), ExpandError> {\n-    let (parse, map) = fragment_to_syntax_node(tt, Statements)?;\n-    parse.cast().ok_or_else(|| crate::ExpandError::ConversionError).map(|p| (p, map))\n+macro_rules! impl_token_tree_conversions {\n+    ($($(#[$attr:meta])* $name:ident => ($kind:ident, $t:ty) ),*) => {\n+        $(\n+            $(#[$attr])*\n+            pub fn $name(tt: &tt::Subtree) -> Result<(Parse<$t>, RevTokenMap), ExpandError> {\n+                let (parse, map) = fragment_to_syntax_node(tt, $kind)?;\n+                parse.cast().ok_or_else(|| crate::ExpandError::ConversionError).map(|p| (p, map))\n+            }\n+        )*\n+    }\n }\n \n-/// Parses the token tree (result of macro expansion) as a sequence of items\n-pub fn token_tree_to_items(\n-    tt: &tt::Subtree,\n-) -> Result<(Parse<ast::MacroItems>, ExpandedRangeMap), ExpandError> {\n-    let (parse, map) = fragment_to_syntax_node(tt, Items)?;\n-    parse.cast().ok_or_else(|| crate::ExpandError::ConversionError).map(|p| (p, map))\n+impl_token_tree_conversions! {\n+    /// Parses the token tree (result of macro expansion) to an expression\n+    token_tree_to_expr => (Expr, ast::Expr),\n+    /// Parses the token tree (result of macro expansion) to a Pattern\n+    token_tree_to_pat => (Pattern, ast::Pat),\n+    /// Parses the token tree (result of macro expansion) to a Type\n+    token_tree_to_ty => (Type, ast::TypeRef),\n+    /// Parses the token tree (result of macro expansion) as a sequence of stmts\n+    token_tree_to_macro_stmts => (Statements, ast::MacroStmts),\n+    /// Parses the token tree (result of macro expansion) as a sequence of items\n+    token_tree_to_items => (Items, ast::MacroItems)\n }\n \n impl TokenMap {\n@@ -132,15 +117,28 @@ impl TokenMap {\n     }\n }\n \n-impl ExpandedRangeMap {\n-    fn add(&mut self, relative_range: TextRange, token_id: &tt::TokenId) {\n+impl RevTokenMap {\n+    fn add(&mut self, relative_range: TextRange, token_id: tt::TokenId) {\n         self.ranges.push((relative_range, token_id.clone()))\n     }\n \n+    /// Map a given token map to (Expanded syntax node, Input tokens) text-ranges pair\n+    ///\n+    /// This function do the following things:\n+    ///\n+    /// 1. Undo the increment of token-id `shift`:\n+    ///     When we output a token from from macro argument, we increased its id\n+    ///     by `shift` (so it's guaranteed to not to collide with anything from the definition)\n+    ///     We undo the increment here to rollback to its original token id.\n+    /// 2. Offset the input tokens (`to`) by `parent` text-range:\n+    ///     We transforms the input tokens text-ranges from relative to original first token\n+    ///     to parent text-range\n+    /// 3. Maps expanded tokens text-ranges to parent text-ranges\n+    ///\n     pub fn map_ranges(\n         &self,\n         to: &TokenMap,\n-        start: TextUnit,\n+        parent: TextRange,\n         shift: u32,\n     ) -> Vec<(TextRange, TextRange)> {\n         self.ranges\n@@ -149,7 +147,7 @@ impl ExpandedRangeMap {\n                 let adjusted_id = tt::TokenId(tid.0.checked_sub(shift)?);\n                 let to_range = to.relative_range_of(adjusted_id)?;\n \n-                Some((*r, TextRange::offset_len(to_range.start() + start, to_range.len())))\n+                Some((*r, TextRange::offset_len(to_range.start() + parent.start(), to_range.len())))\n             })\n             .collect()\n     }\n@@ -301,7 +299,7 @@ struct TtTreeSink<'a> {\n     cursor: Cursor<'a>,\n     text_pos: TextUnit,\n     inner: SyntaxTreeBuilder,\n-    range_map: ExpandedRangeMap,\n+    range_map: RevTokenMap,\n \n     // Number of roots\n     // Use for detect ill-form tree which is not single root\n@@ -316,11 +314,11 @@ impl<'a> TtTreeSink<'a> {\n             text_pos: 0.into(),\n             inner: SyntaxTreeBuilder::default(),\n             roots: smallvec::SmallVec::new(),\n-            range_map: ExpandedRangeMap::default(),\n+            range_map: RevTokenMap::default(),\n         }\n     }\n \n-    fn finish(self) -> (Parse<SyntaxNode>, ExpandedRangeMap) {\n+    fn finish(self) -> (Parse<SyntaxNode>, RevTokenMap) {\n         (self.inner.finish(), self.range_map)\n     }\n }\n@@ -355,11 +353,9 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n                     // Mark the range if needed\n                     if let tt::Leaf::Ident(ident) = leaf {\n                         if kind == IDENT {\n-                            let range = TextRange::offset_len(\n-                                self.text_pos + TextUnit::of_str(&self.buf),\n-                                TextUnit::of_str(&ident.text),\n-                            );\n-                            self.range_map.add(range, &ident.id);\n+                            let range =\n+                                TextRange::offset_len(self.text_pos, TextUnit::of_str(&ident.text));\n+                            self.range_map.add(range, ident.id);\n                         }\n                     }\n "}]}