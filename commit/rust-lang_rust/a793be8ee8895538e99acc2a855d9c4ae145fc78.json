{"sha": "a793be8ee8895538e99acc2a855d9c4ae145fc78", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE3OTNiZThlZTg4OTU1MzhlOTlhY2MyYTg1NWQ5YzRhZTE0NWZjNzg=", "commit": {"author": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2021-03-31T10:34:01Z"}, "committer": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2021-03-31T10:34:01Z"}, "message": "Remove the stack2reg optimization completely\n\nIt is broken and needs to be rewritten from scratch", "tree": {"sha": "52614dc3ffcba79dc55293c47a39a9cbde216d1c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/52614dc3ffcba79dc55293c47a39a9cbde216d1c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a793be8ee8895538e99acc2a855d9c4ae145fc78", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a793be8ee8895538e99acc2a855d9c4ae145fc78", "html_url": "https://github.com/rust-lang/rust/commit/a793be8ee8895538e99acc2a855d9c4ae145fc78", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a793be8ee8895538e99acc2a855d9c4ae145fc78/comments", "author": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "afe74d71e4c2f08696ade0de321a45f7442440d8", "url": "https://api.github.com/repos/rust-lang/rust/commits/afe74d71e4c2f08696ade0de321a45f7442440d8", "html_url": "https://github.com/rust-lang/rust/commit/afe74d71e4c2f08696ade0de321a45f7442440d8"}], "stats": {"total": 502, "additions": 3, "deletions": 499}, "files": [{"sha": "58a24c4193032abd13da32aef89f864785df834b", "filename": "src/intrinsics/mod.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a793be8ee8895538e99acc2a855d9c4ae145fc78/src%2Fintrinsics%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a793be8ee8895538e99acc2a855d9c4ae145fc78/src%2Fintrinsics%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsics%2Fmod.rs?ref=a793be8ee8895538e99acc2a855d9c4ae145fc78", "patch": "@@ -827,7 +827,6 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n \n         volatile_load | unaligned_volatile_load, (c ptr) {\n             // Cranelift treats loads as volatile by default\n-            // FIXME ignore during stack2reg optimization\n             // FIXME correctly handle unaligned_volatile_load\n             let inner_layout =\n                 fx.layout_of(ptr.layout().ty.builtin_deref(true).unwrap().ty);\n@@ -836,7 +835,6 @@ pub(crate) fn codegen_intrinsic_call<'tcx>(\n         };\n         volatile_store | unaligned_volatile_store, (v ptr, c val) {\n             // Cranelift treats stores as volatile by default\n-            // FIXME ignore during stack2reg optimization\n             // FIXME correctly handle unaligned_volatile_store\n             let dest = CPlace::for_ptr(Pointer::new(ptr), val.layout());\n             dest.write_cvalue(fx, val);"}, {"sha": "95e8a449fa2109535fdfee90b629c2018d3f341d", "filename": "src/optimize/mod.rs", "status": "modified", "additions": 3, "deletions": 11, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/a793be8ee8895538e99acc2a855d9c4ae145fc78/src%2Foptimize%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a793be8ee8895538e99acc2a855d9c4ae145fc78/src%2Foptimize%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Foptimize%2Fmod.rs?ref=a793be8ee8895538e99acc2a855d9c4ae145fc78", "patch": "@@ -4,7 +4,6 @@ use crate::prelude::*;\n \n mod code_layout;\n pub(crate) mod peephole;\n-mod stack2reg;\n \n pub(crate) fn optimize_function<'tcx>(\n     tcx: TyCtxt<'tcx>,\n@@ -13,18 +12,11 @@ pub(crate) fn optimize_function<'tcx>(\n     cold_blocks: &EntitySet<Block>,\n     clif_comments: &mut crate::pretty_clif::CommentWriter,\n ) {\n+    // FIXME classify optimizations over opt levels once we have more\n+\n     // The code_layout optimization is very cheap.\n     self::code_layout::optimize_function(ctx, cold_blocks);\n \n-    if tcx.sess.opts.optimize == rustc_session::config::OptLevel::No {\n-        return; // FIXME classify optimizations over opt levels\n-    }\n-\n-    // FIXME(#1142) stack2reg miscompiles lewton\n-    if false {\n-        self::stack2reg::optimize_function(ctx, clif_comments);\n-    }\n-\n-    crate::pretty_clif::write_clif_file(tcx, \"stack2reg\", None, instance, &ctx, &*clif_comments);\n+    crate::pretty_clif::write_clif_file(tcx, \"preopt\", None, instance, &ctx, &*clif_comments);\n     crate::base::verify_func(tcx, &*clif_comments, &ctx.func);\n }"}, {"sha": "8bb02a3e5585482b4e88a0135524f494a74ff184", "filename": "src/optimize/stack2reg.rs", "status": "removed", "additions": 0, "deletions": 486, "changes": 486, "blob_url": "https://github.com/rust-lang/rust/blob/afe74d71e4c2f08696ade0de321a45f7442440d8/src%2Foptimize%2Fstack2reg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/afe74d71e4c2f08696ade0de321a45f7442440d8/src%2Foptimize%2Fstack2reg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Foptimize%2Fstack2reg.rs?ref=afe74d71e4c2f08696ade0de321a45f7442440d8", "patch": "@@ -1,486 +0,0 @@\n-//! This optimization replaces stack accesses with SSA variables and removes dead stores when possible.\n-//!\n-//! # Undefined behaviour\n-//!\n-//! This optimization is based on the assumption that stack slots which don't have their address\n-//! leaked through `stack_addr` are only accessed using `stack_load` and `stack_store` in the\n-//! function which has the stack slots. This optimization also assumes that stack slot accesses\n-//! are never out of bounds. If these assumptions are not correct, then this optimization may remove\n-//! `stack_store` instruction incorrectly, or incorrectly use a previously stored value as the value\n-//! being loaded by a `stack_load`.\n-\n-use std::collections::BTreeMap;\n-use std::fmt;\n-use std::ops::Not;\n-\n-use rustc_data_structures::fx::FxHashSet;\n-\n-use cranelift_codegen::cursor::{Cursor, FuncCursor};\n-use cranelift_codegen::ir::immediates::Offset32;\n-use cranelift_codegen::ir::{InstructionData, Opcode, ValueDef};\n-\n-use crate::prelude::*;\n-\n-/// Workaround for `StackSlot` not implementing `Ord`.\n-#[derive(Copy, Clone, PartialEq, Eq)]\n-struct OrdStackSlot(StackSlot);\n-\n-impl fmt::Debug for OrdStackSlot {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        write!(f, \"{:?}\", self.0)\n-    }\n-}\n-\n-impl PartialOrd for OrdStackSlot {\n-    fn partial_cmp(&self, rhs: &Self) -> Option<std::cmp::Ordering> {\n-        self.0.as_u32().partial_cmp(&rhs.0.as_u32())\n-    }\n-}\n-\n-impl Ord for OrdStackSlot {\n-    fn cmp(&self, rhs: &Self) -> std::cmp::Ordering {\n-        self.0.as_u32().cmp(&rhs.0.as_u32())\n-    }\n-}\n-\n-#[derive(Debug, Default)]\n-struct StackSlotUsage {\n-    stack_addr: FxHashSet<Inst>,\n-    stack_load: FxHashSet<Inst>,\n-    stack_store: FxHashSet<Inst>,\n-}\n-\n-impl StackSlotUsage {\n-    fn potential_stores_for_load(&self, ctx: &Context, load: Inst) -> Vec<Inst> {\n-        self.stack_store\n-            .iter()\n-            .cloned()\n-            .filter(|&store| {\n-                match spatial_overlap(&ctx.func, store, load) {\n-                    SpatialOverlap::No => false, // Can never be the source of the loaded value.\n-                    SpatialOverlap::Partial | SpatialOverlap::Full => true,\n-                }\n-            })\n-            .filter(|&store| {\n-                match temporal_order(ctx, store, load) {\n-                    TemporalOrder::NeverBefore => false, // Can never be the source of the loaded value.\n-                    TemporalOrder::MaybeBefore | TemporalOrder::DefinitivelyBefore => true,\n-                }\n-            })\n-            .collect::<Vec<Inst>>()\n-    }\n-\n-    fn potential_loads_of_store(&self, ctx: &Context, store: Inst) -> Vec<Inst> {\n-        self.stack_load\n-            .iter()\n-            .cloned()\n-            .filter(|&load| {\n-                match spatial_overlap(&ctx.func, store, load) {\n-                    SpatialOverlap::No => false, // Can never be the source of the loaded value.\n-                    SpatialOverlap::Partial | SpatialOverlap::Full => true,\n-                }\n-            })\n-            .filter(|&load| {\n-                match temporal_order(ctx, store, load) {\n-                    TemporalOrder::NeverBefore => false, // Can never be the source of the loaded value.\n-                    TemporalOrder::MaybeBefore | TemporalOrder::DefinitivelyBefore => true,\n-                }\n-            })\n-            .collect::<Vec<Inst>>()\n-    }\n-\n-    fn remove_unused_stack_addr(func: &mut Function, inst: Inst) {\n-        func.dfg.detach_results(inst);\n-        func.dfg.replace(inst).nop();\n-    }\n-\n-    fn remove_unused_load(func: &mut Function, load: Inst) {\n-        func.dfg.detach_results(load);\n-        func.dfg.replace(load).nop();\n-    }\n-\n-    fn remove_dead_store(&mut self, func: &mut Function, store: Inst) {\n-        func.dfg.replace(store).nop();\n-        self.stack_store.remove(&store);\n-    }\n-\n-    fn change_load_to_alias(&mut self, func: &mut Function, load: Inst, value: Value) {\n-        let loaded_value = func.dfg.inst_results(load)[0];\n-        let loaded_type = func.dfg.value_type(loaded_value);\n-\n-        if func.dfg.value_type(value) == loaded_type {\n-            func.dfg.detach_results(load);\n-            func.dfg.replace(load).nop();\n-            func.dfg.change_to_alias(loaded_value, value);\n-        } else {\n-            func.dfg.replace(load).bitcast(loaded_type, value);\n-        }\n-\n-        self.stack_load.remove(&load);\n-    }\n-}\n-\n-struct OptimizeContext<'a> {\n-    ctx: &'a mut Context,\n-    stack_slot_usage_map: BTreeMap<OrdStackSlot, StackSlotUsage>,\n-}\n-\n-impl<'a> OptimizeContext<'a> {\n-    fn for_context(ctx: &'a mut Context) -> Self {\n-        ctx.flowgraph(); // Compute cfg and domtree.\n-\n-        // Record all stack_addr, stack_load and stack_store instructions.\n-        let mut stack_slot_usage_map = BTreeMap::<OrdStackSlot, StackSlotUsage>::new();\n-\n-        let mut cursor = FuncCursor::new(&mut ctx.func);\n-        while let Some(_block) = cursor.next_block() {\n-            while let Some(inst) = cursor.next_inst() {\n-                match cursor.func.dfg[inst] {\n-                    InstructionData::StackLoad {\n-                        opcode: Opcode::StackAddr,\n-                        stack_slot,\n-                        offset: _,\n-                    } => {\n-                        stack_slot_usage_map\n-                            .entry(OrdStackSlot(stack_slot))\n-                            .or_insert_with(StackSlotUsage::default)\n-                            .stack_addr\n-                            .insert(inst);\n-                    }\n-                    InstructionData::StackLoad {\n-                        opcode: Opcode::StackLoad,\n-                        stack_slot,\n-                        offset: _,\n-                    } => {\n-                        stack_slot_usage_map\n-                            .entry(OrdStackSlot(stack_slot))\n-                            .or_insert_with(StackSlotUsage::default)\n-                            .stack_load\n-                            .insert(inst);\n-                    }\n-                    InstructionData::StackStore {\n-                        opcode: Opcode::StackStore,\n-                        arg: _,\n-                        stack_slot,\n-                        offset: _,\n-                    } => {\n-                        stack_slot_usage_map\n-                            .entry(OrdStackSlot(stack_slot))\n-                            .or_insert_with(StackSlotUsage::default)\n-                            .stack_store\n-                            .insert(inst);\n-                    }\n-                    _ => {}\n-                }\n-            }\n-        }\n-\n-        OptimizeContext { ctx, stack_slot_usage_map }\n-    }\n-}\n-\n-pub(super) fn optimize_function(\n-    ctx: &mut Context,\n-    clif_comments: &mut crate::pretty_clif::CommentWriter,\n-) {\n-    combine_stack_addr_with_load_store(&mut ctx.func);\n-\n-    let mut opt_ctx = OptimizeContext::for_context(ctx);\n-\n-    // FIXME Repeat following instructions until fixpoint.\n-\n-    remove_unused_stack_addr_and_stack_load(&mut opt_ctx);\n-\n-    if clif_comments.enabled() {\n-        for (&OrdStackSlot(stack_slot), usage) in &opt_ctx.stack_slot_usage_map {\n-            clif_comments.add_comment(stack_slot, format!(\"used by: {:?}\", usage));\n-        }\n-    }\n-\n-    for (stack_slot, users) in opt_ctx.stack_slot_usage_map.iter_mut() {\n-        if users.stack_addr.is_empty().not() {\n-            // Stack addr leaked; there may be unknown loads and stores.\n-            // FIXME use stacked borrows to optimize\n-            continue;\n-        }\n-\n-        for load in users.stack_load.clone().into_iter() {\n-            let potential_stores = users.potential_stores_for_load(&opt_ctx.ctx, load);\n-\n-            if clif_comments.enabled() {\n-                for &store in &potential_stores {\n-                    clif_comments.add_comment(\n-                        load,\n-                        format!(\n-                            \"Potential store -> load forwarding {} -> {} ({:?}, {:?})\",\n-                            opt_ctx.ctx.func.dfg.display_inst(store, None),\n-                            opt_ctx.ctx.func.dfg.display_inst(load, None),\n-                            spatial_overlap(&opt_ctx.ctx.func, store, load),\n-                            temporal_order(&opt_ctx.ctx, store, load),\n-                        ),\n-                    );\n-                }\n-            }\n-\n-            match *potential_stores {\n-                [] => {\n-                    if clif_comments.enabled() {\n-                        clif_comments\n-                            .add_comment(load, \"[BUG?] Reading uninitialized memory\".to_string());\n-                    }\n-                }\n-                [store]\n-                    if spatial_overlap(&opt_ctx.ctx.func, store, load) == SpatialOverlap::Full\n-                        && temporal_order(&opt_ctx.ctx, store, load)\n-                            == TemporalOrder::DefinitivelyBefore =>\n-                {\n-                    // Only one store could have been the origin of the value.\n-                    let stored_value = opt_ctx.ctx.func.dfg.inst_args(store)[0];\n-\n-                    if clif_comments.enabled() {\n-                        clif_comments.add_comment(\n-                            load,\n-                            format!(\"Store to load forward {} -> {}\", store, load),\n-                        );\n-                    }\n-\n-                    users.change_load_to_alias(&mut opt_ctx.ctx.func, load, stored_value);\n-                }\n-                _ => {} // FIXME implement this\n-            }\n-        }\n-\n-        for store in users.stack_store.clone().into_iter() {\n-            let potential_loads = users.potential_loads_of_store(&opt_ctx.ctx, store);\n-\n-            if clif_comments.enabled() {\n-                for &load in &potential_loads {\n-                    clif_comments.add_comment(\n-                        store,\n-                        format!(\n-                            \"Potential load from store {} <- {} ({:?}, {:?})\",\n-                            opt_ctx.ctx.func.dfg.display_inst(load, None),\n-                            opt_ctx.ctx.func.dfg.display_inst(store, None),\n-                            spatial_overlap(&opt_ctx.ctx.func, store, load),\n-                            temporal_order(&opt_ctx.ctx, store, load),\n-                        ),\n-                    );\n-                }\n-            }\n-\n-            if potential_loads.is_empty() {\n-                // Never loaded; can safely remove all stores and the stack slot.\n-                // FIXME also remove stores when there is always a next store before a load.\n-\n-                if clif_comments.enabled() {\n-                    clif_comments.add_comment(\n-                        store,\n-                        format!(\n-                            \"Remove dead stack store {} of {}\",\n-                            opt_ctx.ctx.func.dfg.display_inst(store, None),\n-                            stack_slot.0\n-                        ),\n-                    );\n-                }\n-\n-                users.remove_dead_store(&mut opt_ctx.ctx.func, store);\n-            }\n-        }\n-\n-        if users.stack_store.is_empty() && users.stack_load.is_empty() {\n-            opt_ctx.ctx.func.stack_slots[stack_slot.0].size = 0;\n-        }\n-    }\n-}\n-\n-fn combine_stack_addr_with_load_store(func: &mut Function) {\n-    // Turn load and store into stack_load and stack_store when possible.\n-    let mut cursor = FuncCursor::new(func);\n-    while let Some(_block) = cursor.next_block() {\n-        while let Some(inst) = cursor.next_inst() {\n-            match cursor.func.dfg[inst] {\n-                InstructionData::Load { opcode: Opcode::Load, arg: addr, flags: _, offset } => {\n-                    if cursor.func.dfg.ctrl_typevar(inst) == types::I128\n-                        || cursor.func.dfg.ctrl_typevar(inst).is_vector()\n-                    {\n-                        continue; // WORKAROUD: stack_load.i128 not yet implemented\n-                    }\n-                    if let Some((stack_slot, stack_addr_offset)) =\n-                        try_get_stack_slot_and_offset_for_addr(cursor.func, addr)\n-                    {\n-                        if let Some(combined_offset) = offset.try_add_i64(stack_addr_offset.into())\n-                        {\n-                            let ty = cursor.func.dfg.ctrl_typevar(inst);\n-                            cursor.func.dfg.replace(inst).stack_load(\n-                                ty,\n-                                stack_slot,\n-                                combined_offset,\n-                            );\n-                        }\n-                    }\n-                }\n-                InstructionData::Store {\n-                    opcode: Opcode::Store,\n-                    args: [value, addr],\n-                    flags: _,\n-                    offset,\n-                } => {\n-                    if cursor.func.dfg.ctrl_typevar(inst) == types::I128\n-                        || cursor.func.dfg.ctrl_typevar(inst).is_vector()\n-                    {\n-                        continue; // WORKAROUND: stack_store.i128 not yet implemented\n-                    }\n-                    if let Some((stack_slot, stack_addr_offset)) =\n-                        try_get_stack_slot_and_offset_for_addr(cursor.func, addr)\n-                    {\n-                        if let Some(combined_offset) = offset.try_add_i64(stack_addr_offset.into())\n-                        {\n-                            cursor.func.dfg.replace(inst).stack_store(\n-                                value,\n-                                stack_slot,\n-                                combined_offset,\n-                            );\n-                        }\n-                    }\n-                }\n-                _ => {}\n-            }\n-        }\n-    }\n-}\n-\n-fn remove_unused_stack_addr_and_stack_load(opt_ctx: &mut OptimizeContext<'_>) {\n-    // FIXME incrementally rebuild on each call?\n-    let mut stack_addr_load_insts_users = FxHashMap::<Inst, FxHashSet<Inst>>::default();\n-\n-    let mut cursor = FuncCursor::new(&mut opt_ctx.ctx.func);\n-    while let Some(_block) = cursor.next_block() {\n-        while let Some(inst) = cursor.next_inst() {\n-            for &arg in cursor.func.dfg.inst_args(inst) {\n-                if let ValueDef::Result(arg_origin, 0) = cursor.func.dfg.value_def(arg) {\n-                    match cursor.func.dfg[arg_origin].opcode() {\n-                        Opcode::StackAddr | Opcode::StackLoad => {\n-                            stack_addr_load_insts_users\n-                                .entry(arg_origin)\n-                                .or_insert_with(FxHashSet::default)\n-                                .insert(inst);\n-                        }\n-                        _ => {}\n-                    }\n-                }\n-            }\n-        }\n-    }\n-\n-    #[cfg(debug_assertions)]\n-    for inst in stack_addr_load_insts_users.keys() {\n-        let mut is_recorded_stack_addr_or_stack_load = false;\n-        for stack_slot_users in opt_ctx.stack_slot_usage_map.values() {\n-            is_recorded_stack_addr_or_stack_load |= stack_slot_users.stack_addr.contains(inst)\n-                || stack_slot_users.stack_load.contains(inst);\n-        }\n-        assert!(is_recorded_stack_addr_or_stack_load);\n-    }\n-\n-    // Replace all unused stack_addr and stack_load instructions with nop.\n-    let mut func = &mut opt_ctx.ctx.func;\n-\n-    for stack_slot_users in opt_ctx.stack_slot_usage_map.values_mut() {\n-        stack_slot_users\n-            .stack_addr\n-            .drain_filter(|inst| {\n-                stack_addr_load_insts_users.get(inst).map(|users| users.is_empty()).unwrap_or(true)\n-            })\n-            .for_each(|inst| StackSlotUsage::remove_unused_stack_addr(&mut func, inst));\n-\n-        stack_slot_users\n-            .stack_load\n-            .drain_filter(|inst| {\n-                stack_addr_load_insts_users.get(inst).map(|users| users.is_empty()).unwrap_or(true)\n-            })\n-            .for_each(|inst| StackSlotUsage::remove_unused_load(&mut func, inst));\n-    }\n-}\n-\n-fn try_get_stack_slot_and_offset_for_addr(\n-    func: &Function,\n-    addr: Value,\n-) -> Option<(StackSlot, Offset32)> {\n-    if let ValueDef::Result(addr_inst, 0) = func.dfg.value_def(addr) {\n-        if let InstructionData::StackLoad { opcode: Opcode::StackAddr, stack_slot, offset } =\n-            func.dfg[addr_inst]\n-        {\n-            return Some((stack_slot, offset));\n-        }\n-    }\n-    None\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n-enum SpatialOverlap {\n-    No,\n-    Partial,\n-    Full,\n-}\n-\n-fn spatial_overlap(func: &Function, src: Inst, dest: Inst) -> SpatialOverlap {\n-    fn inst_info(func: &Function, inst: Inst) -> (StackSlot, Offset32, u32) {\n-        match func.dfg[inst] {\n-            InstructionData::StackLoad { opcode: Opcode::StackAddr, stack_slot, offset }\n-            | InstructionData::StackLoad { opcode: Opcode::StackLoad, stack_slot, offset }\n-            | InstructionData::StackStore {\n-                opcode: Opcode::StackStore,\n-                stack_slot,\n-                offset,\n-                arg: _,\n-            } => (stack_slot, offset, func.dfg.ctrl_typevar(inst).bytes()),\n-            _ => unreachable!(\"{:?}\", func.dfg[inst]),\n-        }\n-    }\n-\n-    debug_assert_ne!(src, dest);\n-\n-    let (src_ss, src_offset, src_size) = inst_info(func, src);\n-    let (dest_ss, dest_offset, dest_size) = inst_info(func, dest);\n-\n-    if src_ss != dest_ss {\n-        return SpatialOverlap::No;\n-    }\n-\n-    if src_offset == dest_offset && src_size == dest_size {\n-        return SpatialOverlap::Full;\n-    }\n-\n-    let src_end: i64 = src_offset.try_add_i64(i64::from(src_size)).unwrap().into();\n-    let dest_end: i64 = dest_offset.try_add_i64(i64::from(dest_size)).unwrap().into();\n-    if src_end <= dest_offset.into() || dest_end <= src_offset.into() {\n-        return SpatialOverlap::No;\n-    }\n-\n-    SpatialOverlap::Partial\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n-enum TemporalOrder {\n-    /// `src` will never be executed before `dest`.\n-    NeverBefore,\n-\n-    /// `src` may be executed before `dest`.\n-    MaybeBefore,\n-\n-    /// `src` will always be executed before `dest`.\n-    /// There may still be other instructions in between.\n-    DefinitivelyBefore,\n-}\n-\n-fn temporal_order(ctx: &Context, src: Inst, dest: Inst) -> TemporalOrder {\n-    debug_assert_ne!(src, dest);\n-\n-    if ctx.domtree.dominates(src, dest, &ctx.func.layout) {\n-        TemporalOrder::DefinitivelyBefore\n-    } else if ctx.domtree.dominates(src, dest, &ctx.func.layout) {\n-        TemporalOrder::NeverBefore\n-    } else {\n-        TemporalOrder::MaybeBefore\n-    }\n-}"}]}