{"sha": "87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg3YTQzNjM3N2E3Y2RkZDFkNDQyNmM5NjA0YzQ4ZTBhYTJlYzBiMTE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-03-03T19:48:12Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-03-03T19:48:12Z"}, "message": "Auto merge of #58425 - wesleywiser:more_profiler_changes, r=michaelwoerister\n\n[self-profiler] Make the profiler faster/more efficient\n\nRelated to #58372\n\nr? @michaelwoerister", "tree": {"sha": "004e4050002db99f09f07452936cf6b1742d5575", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/004e4050002db99f09f07452936cf6b1742d5575"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "html_url": "https://github.com/rust-lang/rust/commit/87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2cfd6444a7fb4bd6acef2b97ba53059adc0500a6", "url": "https://api.github.com/repos/rust-lang/rust/commits/2cfd6444a7fb4bd6acef2b97ba53059adc0500a6", "html_url": "https://github.com/rust-lang/rust/commit/2cfd6444a7fb4bd6acef2b97ba53059adc0500a6"}, {"sha": "f20ad7043904023e810cfaeb5d775f281a4a1619", "url": "https://api.github.com/repos/rust-lang/rust/commits/f20ad7043904023e810cfaeb5d775f281a4a1619", "html_url": "https://github.com/rust-lang/rust/commit/f20ad7043904023e810cfaeb5d775f281a4a1619"}], "stats": {"total": 715, "additions": 343, "deletions": 372}, "files": [{"sha": "9154cb4d5b8b6d8e44061e74a1169e18ae9bf202", "filename": "Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -2625,6 +2625,7 @@ dependencies = [\n  \"log 0.4.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"num_cpus 1.8.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"parking_lot 0.7.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc 0.0.0\",\n  \"rustc-demangle 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc_allocator 0.0.0\","}, {"sha": "774ab0333db54a27f89a230c9643f12163029638", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -1405,9 +1405,7 @@ options! {DebuggingOptions, DebuggingSetter, basic_debugging_options,\n     crate_attr: Vec<String> = (Vec::new(), parse_string_push, [TRACKED],\n         \"inject the given attribute in the crate\"),\n     self_profile: bool = (false, parse_bool, [UNTRACKED],\n-        \"run the self profiler\"),\n-    profile_json: bool = (false, parse_bool, [UNTRACKED],\n-        \"output a json file with profiler results\"),\n+        \"run the self profiler and output the raw event data\"),\n     emit_stack_sizes: bool = (false, parse_bool, [UNTRACKED],\n         \"emits a section containing stack size metadata\"),\n     plt: Option<bool> = (None, parse_opt_bool, [TRACKED],"}, {"sha": "774bc8b450b594eba6d185a94adf811c1b767f72", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 19, "deletions": 24, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -44,7 +44,9 @@ use std::fmt;\n use std::io::Write;\n use std::path::PathBuf;\n use std::time::Duration;\n-use std::sync::mpsc;\n+use std::sync::{Arc, mpsc};\n+\n+use parking_lot::Mutex as PlMutex;\n \n mod code_stats;\n pub mod config;\n@@ -127,11 +129,8 @@ pub struct Session {\n     /// Used by `-Z profile-queries` in `util::common`.\n     pub profile_channel: Lock<Option<mpsc::Sender<ProfileQueriesMsg>>>,\n \n-    /// Used by `-Z self-profile`.\n-    pub self_profiling_active: bool,\n-\n-    /// Used by `-Z self-profile`.\n-    pub self_profiling: Lock<SelfProfiler>,\n+    /// Used by -Z self-profile\n+    pub self_profiling: Option<Arc<PlMutex<SelfProfiler>>>,\n \n     /// Some measurements that are being gathered during compilation.\n     pub perf_stats: PerfStats,\n@@ -834,27 +833,23 @@ impl Session {\n     #[inline(never)]\n     #[cold]\n     fn profiler_active<F: FnOnce(&mut SelfProfiler) -> ()>(&self, f: F) {\n-        let mut profiler = self.self_profiling.borrow_mut();\n-        f(&mut profiler);\n+        match &self.self_profiling {\n+            None => bug!(\"profiler_active() called but there was no profiler active\"),\n+            Some(profiler) => {\n+                let mut p = profiler.lock();\n+\n+                f(&mut p);\n+            }\n+        }\n     }\n \n     #[inline(always)]\n     pub fn profiler<F: FnOnce(&mut SelfProfiler) -> ()>(&self, f: F) {\n-        if unlikely!(self.self_profiling_active) {\n+        if unlikely!(self.self_profiling.is_some()) {\n             self.profiler_active(f)\n         }\n     }\n \n-    pub fn print_profiler_results(&self) {\n-        let mut profiler = self.self_profiling.borrow_mut();\n-        profiler.print_results(&self.opts);\n-    }\n-\n-    pub fn save_json_results(&self) {\n-        let profiler = self.self_profiling.borrow();\n-        profiler.save_results(&self.opts);\n-    }\n-\n     pub fn print_perf_stats(&self) {\n         println!(\n             \"Total time spent computing symbol hashes:      {}\",\n@@ -1136,6 +1131,10 @@ pub fn build_session_(\n     source_map: Lrc<source_map::SourceMap>,\n     driver_lint_caps: FxHashMap<lint::LintId, lint::Level>,\n ) -> Session {\n+    let self_profiler =\n+        if sopts.debugging_opts.self_profile { Some(Arc::new(PlMutex::new(SelfProfiler::new()))) }\n+        else { None };\n+\n     let host_triple = TargetTriple::from_triple(config::host_triple());\n     let host = Target::search(&host_triple).unwrap_or_else(|e|\n         span_diagnostic\n@@ -1185,9 +1184,6 @@ pub fn build_session_(\n         CguReuseTracker::new_disabled()\n     };\n \n-    let self_profiling_active = sopts.debugging_opts.self_profile ||\n-                                sopts.debugging_opts.profile_json;\n-\n     let sess = Session {\n         target: target_cfg,\n         host,\n@@ -1216,8 +1212,7 @@ pub fn build_session_(\n         imported_macro_spans: OneThread::new(RefCell::new(FxHashMap::default())),\n         incr_comp_session: OneThread::new(RefCell::new(IncrCompSession::NotInitialized)),\n         cgu_reuse_tracker,\n-        self_profiling_active,\n-        self_profiling: Lock::new(SelfProfiler::new()),\n+        self_profiling: self_profiler,\n         profile_channel: Lock::new(None),\n         perf_stats: PerfStats {\n             symbol_hash_time: Lock::new(Duration::from_secs(0)),"}, {"sha": "c134d48f987be5ded1c711a6b0f8786545d30c8a", "filename": "src/librustc/util/profiling.rs", "status": "modified", "additions": 290, "deletions": 337, "changes": 627, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc%2Futil%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc%2Futil%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fprofiling.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -1,10 +1,13 @@\n-use std::collections::{BTreeMap, HashMap};\n use std::fs;\n-use std::io::{self, Write};\n+use std::io::{BufWriter, Write};\n+use std::mem;\n+use std::process;\n use std::thread::ThreadId;\n-use std::time::Instant;\n+use std::time::{Duration, Instant, SystemTime};\n \n-use crate::session::config::{Options, OptLevel};\n+use crate::session::config::Options;\n+\n+use rustc_data_structures::fx::FxHashMap;\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq, Ord, PartialOrd)]\n pub enum ProfileCategory {\n@@ -19,170 +22,71 @@ pub enum ProfileCategory {\n \n #[derive(Clone, Copy, Debug, Eq, PartialEq)]\n pub enum ProfilerEvent {\n-    QueryStart { query_name: &'static str, category: ProfileCategory, time: Instant },\n-    QueryEnd { query_name: &'static str, category: ProfileCategory, time: Instant },\n-    GenericActivityStart { category: ProfileCategory, time: Instant },\n-    GenericActivityEnd { category: ProfileCategory, time: Instant },\n-    QueryCacheHit { query_name: &'static str, category: ProfileCategory },\n-    QueryCount { query_name: &'static str, category: ProfileCategory, count: usize },\n-    IncrementalLoadResultStart { query_name: &'static str, time: Instant },\n-    IncrementalLoadResultEnd { query_name: &'static str, time: Instant },\n-    QueryBlockedStart { query_name: &'static str, category: ProfileCategory, time: Instant },\n-    QueryBlockedEnd { query_name: &'static str, category: ProfileCategory, time: Instant },\n+    QueryStart { query_name: &'static str, category: ProfileCategory, time: u64 },\n+    QueryEnd { query_name: &'static str, category: ProfileCategory, time: u64 },\n+    GenericActivityStart { category: ProfileCategory, time: u64 },\n+    GenericActivityEnd { category: ProfileCategory, time: u64 },\n+    IncrementalLoadResultStart { query_name: &'static str, time: u64 },\n+    IncrementalLoadResultEnd { query_name: &'static str, time: u64 },\n+    QueryCacheHit { query_name: &'static str, category: ProfileCategory, time: u64 },\n+    QueryCount { query_name: &'static str, category: ProfileCategory, count: usize, time: u64 },\n+    QueryBlockedStart { query_name: &'static str, category: ProfileCategory, time: u64 },\n+    QueryBlockedEnd { query_name: &'static str, category: ProfileCategory, time: u64 },\n }\n \n impl ProfilerEvent {\n-    fn is_start_event(&self) -> bool {\n+    fn timestamp(&self) -> u64 {\n         use self::ProfilerEvent::*;\n \n         match self {\n-            QueryStart { .. } |\n-            GenericActivityStart { .. } |\n-            IncrementalLoadResultStart { .. } |\n-            QueryBlockedStart { .. } => true,\n-\n-            QueryEnd { .. } |\n-            GenericActivityEnd { .. } |\n-            QueryCacheHit { .. } |\n-            QueryCount { .. } |\n-            IncrementalLoadResultEnd { .. } |\n-            QueryBlockedEnd { .. } => false,\n-        }\n-    }\n-}\n-\n-pub struct SelfProfiler {\n-    events: HashMap<ThreadId, Vec<ProfilerEvent>>,\n-}\n-\n-struct CategoryResultData {\n-    query_times: BTreeMap<&'static str, u64>,\n-    query_cache_stats: BTreeMap<&'static str, (u64, u64)>, //(hits, total)\n-}\n-\n-impl CategoryResultData {\n-    fn new() -> CategoryResultData {\n-        CategoryResultData {\n-            query_times: BTreeMap::new(),\n-            query_cache_stats: BTreeMap::new(),\n-        }\n-    }\n-\n-    fn total_time(&self) -> u64 {\n-        self.query_times.iter().map(|(_, time)| time).sum()\n-    }\n-\n-    fn total_cache_data(&self) -> (u64, u64) {\n-        let (mut hits, mut total) = (0, 0);\n-\n-        for (_, (h, t)) in &self.query_cache_stats {\n-            hits += h;\n-            total += t;\n+            QueryStart { time, .. } |\n+            QueryEnd { time, .. } |\n+            GenericActivityStart { time, .. } |\n+            GenericActivityEnd { time, .. } |\n+            QueryCacheHit { time, .. } |\n+            QueryCount { time, .. } |\n+            IncrementalLoadResultStart { time, .. } |\n+            IncrementalLoadResultEnd { time, .. } |\n+            QueryBlockedStart { time, .. } |\n+            QueryBlockedEnd { time, .. } => *time\n         }\n-\n-        (hits, total)\n     }\n }\n \n-impl Default for CategoryResultData {\n-    fn default() -> CategoryResultData {\n-        CategoryResultData::new()\n-    }\n-}\n-\n-struct CalculatedResults {\n-    categories: BTreeMap<ProfileCategory, CategoryResultData>,\n-    crate_name: Option<String>,\n-    optimization_level: OptLevel,\n-    incremental: bool,\n-    verbose: bool,\n+fn thread_id_to_u64(tid: ThreadId) -> u64 {\n+    unsafe { mem::transmute::<ThreadId, u64>(tid) }\n }\n \n-impl CalculatedResults {\n-    fn new() -> CalculatedResults {\n-        CalculatedResults {\n-            categories: BTreeMap::new(),\n-            crate_name: None,\n-            optimization_level: OptLevel::No,\n-            incremental: false,\n-            verbose: false,\n-        }\n-    }\n-\n-    fn consolidate(mut cr1: CalculatedResults, cr2: CalculatedResults) -> CalculatedResults {\n-        for (category, data) in cr2.categories {\n-            let cr1_data = cr1.categories.entry(category).or_default();\n-\n-            for (query, time) in data.query_times {\n-                *cr1_data.query_times.entry(query).or_default() += time;\n-            }\n-\n-            for (query, (hits, total)) in data.query_cache_stats {\n-                let (h, t) = cr1_data.query_cache_stats.entry(query).or_insert((0, 0));\n-                *h += hits;\n-                *t += total;\n-            }\n-        }\n-\n-        cr1\n-    }\n-\n-    fn total_time(&self) -> u64 {\n-        self.categories.iter().map(|(_, data)| data.total_time()).sum()\n-    }\n-\n-    fn with_options(mut self, opts: &Options) -> CalculatedResults {\n-        self.crate_name = opts.crate_name.clone();\n-        self.optimization_level = opts.optimize;\n-        self.incremental = opts.incremental.is_some();\n-        self.verbose = opts.debugging_opts.verbose;\n-\n-        self\n-    }\n-}\n-\n-fn time_between_ns(start: Instant, end: Instant) -> u64 {\n-    if start < end {\n-        let time = end - start;\n-        (time.as_secs() * 1_000_000_000) + (time.subsec_nanos() as u64)\n-    } else {\n-        debug!(\"time_between_ns: ignorning instance of end < start\");\n-        0\n-    }\n-}\n-\n-fn calculate_percent(numerator: u64, denominator: u64) -> f32 {\n-    if denominator > 0 {\n-        ((numerator as f32) / (denominator as f32)) * 100.0\n-    } else {\n-        0.0\n-    }\n+pub struct SelfProfiler {\n+    events: FxHashMap<ThreadId, Vec<ProfilerEvent>>,\n+    start_time: SystemTime,\n+    start_instant: Instant,\n }\n \n impl SelfProfiler {\n     pub fn new() -> SelfProfiler {\n-        let mut profiler = SelfProfiler {\n-            events: HashMap::new(),\n+        let profiler = SelfProfiler {\n+            events: Default::default(),\n+            start_time: SystemTime::now(),\n+            start_instant: Instant::now(),\n         };\n \n-        profiler.start_activity(ProfileCategory::Other);\n-\n         profiler\n     }\n \n     #[inline]\n     pub fn start_activity(&mut self, category: ProfileCategory) {\n         self.record(ProfilerEvent::GenericActivityStart {\n             category,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n     #[inline]\n     pub fn end_activity(&mut self, category: ProfileCategory) {\n         self.record(ProfilerEvent::GenericActivityEnd {\n             category,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n@@ -197,6 +101,7 @@ impl SelfProfiler {\n             query_name,\n             category,\n             count,\n+            time: self.get_time_from_start(),\n         })\n     }\n \n@@ -205,6 +110,7 @@ impl SelfProfiler {\n         self.record(ProfilerEvent::QueryCacheHit {\n             query_name,\n             category,\n+            time: self.get_time_from_start(),\n         })\n     }\n \n@@ -213,7 +119,7 @@ impl SelfProfiler {\n         self.record(ProfilerEvent::QueryStart {\n             query_name,\n             category,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         });\n     }\n \n@@ -222,23 +128,23 @@ impl SelfProfiler {\n         self.record(ProfilerEvent::QueryEnd {\n             query_name,\n             category,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n     #[inline]\n     pub fn incremental_load_result_start(&mut self, query_name: &'static str) {\n         self.record(ProfilerEvent::IncrementalLoadResultStart {\n             query_name,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n     #[inline]\n     pub fn incremental_load_result_end(&mut self, query_name: &'static str) {\n         self.record(ProfilerEvent::IncrementalLoadResultEnd {\n             query_name,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n@@ -247,7 +153,7 @@ impl SelfProfiler {\n         self.record(ProfilerEvent::QueryBlockedStart {\n             query_name,\n             category,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n@@ -256,7 +162,7 @@ impl SelfProfiler {\n         self.record(ProfilerEvent::QueryBlockedEnd {\n             query_name,\n             category,\n-            time: Instant::now(),\n+            time: self.get_time_from_start(),\n         })\n     }\n \n@@ -268,208 +174,255 @@ impl SelfProfiler {\n         events.push(event);\n     }\n \n-    fn calculate_thread_results(events: &Vec<ProfilerEvent>) -> CalculatedResults {\n-        use self::ProfilerEvent::*;\n-\n-        assert!(\n-            events.last().map(|e| !e.is_start_event()).unwrap_or(true),\n-            \"there was an event running when calculate_reslts() was called\"\n-        );\n-\n-        let mut results = CalculatedResults::new();\n-\n-        //(event, child time to subtract)\n-        let mut query_stack = Vec::new();\n-\n-        for event in events {\n-            match event {\n-                QueryStart { .. } | GenericActivityStart { .. } => {\n-                    query_stack.push((event, 0));\n-                },\n-                QueryEnd { query_name, category, time: end_time } => {\n-                    let previous_query = query_stack.pop();\n-                    if let Some((QueryStart {\n-                                    query_name: p_query_name,\n-                                    time: start_time,\n-                                    category: _ }, child_time_to_subtract)) = previous_query {\n-                        assert_eq!(\n-                            p_query_name,\n-                            query_name,\n-                            \"Saw a query end but the previous query wasn't the corresponding start\"\n-                        );\n-\n-                        let time_ns = time_between_ns(*start_time, *end_time);\n-                        let self_time_ns = time_ns - child_time_to_subtract;\n-                        let result_data = results.categories.entry(*category).or_default();\n+    #[inline]\n+    fn get_time_from_start(&self) -> u64 {\n+        let duration = Instant::now() - self.start_instant;\n+        duration.as_nanos() as u64\n+    }\n \n-                        *result_data.query_times.entry(query_name).or_default() += self_time_ns;\n+    pub fn dump_raw_events(&self, opts: &Options) {\n+        use self::ProfilerEvent::*;\n \n-                        if let Some((_, child_time_to_subtract)) = query_stack.last_mut() {\n-                            *child_time_to_subtract += time_ns;\n-                        }\n-                    } else {\n-                        bug!(\"Saw a query end but the previous event wasn't a query start\");\n-                    }\n+        let pid = process::id();\n+\n+        let filename =\n+            format!(\"{}.profile_events.json\", opts.crate_name.clone().unwrap_or_default());\n+\n+        let mut file = BufWriter::new(fs::File::create(filename).unwrap());\n+\n+        let threads: Vec<_> =\n+            self.events\n+                .keys()\n+                .into_iter()\n+                .map(|tid| format!(\"{}\", thread_id_to_u64(*tid)))\n+                .collect();\n+\n+        write!(file,\n+            \"{{\\\n+                \\\"processes\\\": {{\\\n+                    \\\"{}\\\": {{\\\n+                        \\\"threads\\\": [{}],\\\n+                        \\\"crate_name\\\": \\\"{}\\\",\\\n+                        \\\"opt_level\\\": \\\"{:?}\\\",\\\n+                        \\\"incremental\\\": {}\\\n+                    }}\\\n+                }},\\\n+                \\\"events\\\": [\\\n+             \",\n+            pid,\n+            threads.join(\",\"),\n+            opts.crate_name.clone().unwrap_or_default(),\n+            opts.optimize,\n+            if opts.incremental.is_some() { \"true\" } else { \"false\" },\n+        ).unwrap();\n+\n+        let mut is_first = true;\n+        for (thread_id, events) in &self.events {\n+            let thread_id = thread_id_to_u64(*thread_id);\n+\n+            for event in events {\n+                if is_first {\n+                    is_first = false;\n+                } else {\n+                    writeln!(file, \",\").unwrap();\n                 }\n-                GenericActivityEnd { category, time: end_time } => {\n-                    let previous_event = query_stack.pop();\n-                    if let Some((GenericActivityStart {\n-                                    category: previous_category,\n-                                    time: start_time }, child_time_to_subtract)) = previous_event {\n-                        assert_eq!(\n-                            previous_category,\n-                            category,\n-                            \"Saw an end but the previous event wasn't the corresponding start\"\n-                        );\n-\n-                        let time_ns = time_between_ns(*start_time, *end_time);\n-                        let self_time_ns = time_ns - child_time_to_subtract;\n-                        let result_data = results.categories.entry(*category).or_default();\n-\n-                        *result_data.query_times\n-                            .entry(\"{time spent not running queries}\")\n-                            .or_default() += self_time_ns;\n-\n-                        if let Some((_, child_time_to_subtract)) = query_stack.last_mut() {\n-                            *child_time_to_subtract += time_ns;\n-                        }\n-                    } else {\n-                        bug!(\"Saw an activity end but the previous event wasn't an activity start\");\n-                    }\n-                },\n-                QueryCacheHit { category, query_name } => {\n-                    let result_data = results.categories.entry(*category).or_default();\n-\n-                    let (hits, total) =\n-                        result_data.query_cache_stats.entry(query_name).or_insert((0, 0));\n-                    *hits += 1;\n-                    *total += 1;\n-                },\n-                QueryCount { category, query_name, count } => {\n-                    let result_data = results.categories.entry(*category).or_default();\n-\n-                    let (_, totals) =\n-                        result_data.query_cache_stats.entry(query_name).or_insert((0, 0));\n-                    *totals += *count as u64;\n-                },\n-                //we don't summarize incremental load result events in the simple output mode\n-                IncrementalLoadResultStart { .. } | IncrementalLoadResultEnd { .. } => { },\n-                //we don't summarize parallel query blocking in the simple output mode\n-                QueryBlockedStart { .. } | QueryBlockedEnd { .. } => { },\n-            }\n-        }\n \n-        //normalize the times to ms\n-        for (_, data) in &mut results.categories {\n-            for (_, time) in &mut data.query_times {\n-                *time = *time / 1_000_000;\n-            }\n-        }\n-\n-        results\n-    }\n-\n-    fn get_results(&self, opts: &Options) -> CalculatedResults {\n-        self.events\n-            .iter()\n-            .map(|(_, r)| SelfProfiler::calculate_thread_results(r))\n-            .fold(CalculatedResults::new(), CalculatedResults::consolidate)\n-            .with_options(opts)\n-    }\n-\n-    pub fn print_results(&mut self, opts: &Options) {\n-        self.end_activity(ProfileCategory::Other);\n-\n-        let results = self.get_results(opts);\n-\n-        let total_time = results.total_time() as f32;\n-\n-        let out = io::stderr();\n-        let mut lock = out.lock();\n-\n-        let crate_name = results.crate_name.map(|n| format!(\" for {}\", n)).unwrap_or_default();\n-\n-        writeln!(lock, \"Self profiling results{}:\", crate_name).unwrap();\n-        writeln!(lock).unwrap();\n-\n-        writeln!(lock, \"| Phase                                     | Time (ms)      \\\n-                        | Time (%) | Queries        | Hits (%)\")\n-            .unwrap();\n-        writeln!(lock, \"| ----------------------------------------- | -------------- \\\n-                        | -------- | -------------- | --------\")\n-            .unwrap();\n-\n-        let mut categories: Vec<_> = results.categories.iter().collect();\n-        categories.sort_by_cached_key(|(_, d)| d.total_time());\n-\n-        for (category, data) in categories.iter().rev() {\n-            let (category_hits, category_total) = data.total_cache_data();\n-            let category_hit_percent = calculate_percent(category_hits, category_total);\n-\n-            writeln!(\n-                lock,\n-                \"| {0: <41} | {1: >14} | {2: >8.2} | {3: >14} | {4: >8}\",\n-                format!(\"{:?}\", category),\n-                data.total_time(),\n-                ((data.total_time() as f32) / total_time) * 100.0,\n-                category_total,\n-                format!(\"{:.2}\", category_hit_percent),\n-            ).unwrap();\n-\n-            //in verbose mode, show individual query data\n-            if results.verbose {\n-                //don't show queries that took less than 1ms\n-                let mut times: Vec<_> = data.query_times.iter().filter(|(_, t)| **t > 0).collect();\n-                times.sort_by(|(_, time1), (_, time2)| time2.cmp(time1));\n-\n-                for (query, time) in times {\n-                    let (hits, total) = data.query_cache_stats.get(query).unwrap_or(&(0, 0));\n-                    let hit_percent = calculate_percent(*hits, *total);\n-\n-                    writeln!(\n-                        lock,\n-                        \"| - {0: <39} | {1: >14} | {2: >8.2} | {3: >14} | {4: >8}\",\n-                        query,\n-                        time,\n-                        ((*time as f32) / total_time) * 100.0,\n-                        total,\n-                        format!(\"{:.2}\", hit_percent),\n-                    ).unwrap();\n+                let (secs, nanos) = {\n+                    let time = self.start_time + Duration::from_nanos(event.timestamp());\n+                    let time_since_unix =\n+                        time.duration_since(SystemTime::UNIX_EPOCH).unwrap_or_default();\n+                    (time_since_unix.as_secs(), time_since_unix.subsec_nanos())\n+                };\n+\n+                match event {\n+                    QueryStart { query_name, category, time: _ } =>\n+                        write!(file,\n+                            \"{{ \\\n+                                \\\"QueryStart\\\": {{ \\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    QueryEnd { query_name, category, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"QueryEnd\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    GenericActivityStart { category, time: _ } =>\n+                        write!(file,\n+                            \"{{\n+                                \\\"GenericActivityStart\\\": {{\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    GenericActivityEnd { category, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"GenericActivityEnd\\\": {{\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    QueryCacheHit { query_name, category, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"QueryCacheHit\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    QueryCount { query_name, category, count, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"QueryCount\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"count\\\": {},\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            category,\n+                            count,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    IncrementalLoadResultStart { query_name, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"IncrementalLoadResultStart\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    IncrementalLoadResultEnd { query_name, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"IncrementalLoadResultEnd\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    QueryBlockedStart { query_name, category, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"QueryBlockedStart\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap(),\n+                    QueryBlockedEnd { query_name, category, time: _ } =>\n+                        write!(file,\n+                            \"{{\\\n+                                \\\"QueryBlockedEnd\\\": {{\\\n+                                    \\\"query_name\\\": \\\"{}\\\",\\\n+                                    \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"time\\\": {{\\\n+                                        \\\"secs\\\": {},\\\n+                                        \\\"nanos\\\": {}\\\n+                                    }},\\\n+                                    \\\"thread_id\\\": {}\\\n+                                }}\\\n+                            }}\",\n+                            query_name,\n+                            category,\n+                            secs,\n+                            nanos,\n+                            thread_id,\n+                        ).unwrap()\n                 }\n             }\n         }\n \n-        writeln!(lock).unwrap();\n-        writeln!(lock, \"Optimization level: {:?}\", opts.optimize).unwrap();\n-        writeln!(lock, \"Incremental: {}\", if results.incremental { \"on\" } else { \"off\" }).unwrap();\n-    }\n-\n-    pub fn save_results(&self, opts: &Options) {\n-        let results = self.get_results(opts);\n-\n-        let compilation_options =\n-            format!(\"{{ \\\"optimization_level\\\": \\\"{:?}\\\", \\\"incremental\\\": {} }}\",\n-                    results.optimization_level,\n-                    if results.incremental { \"true\" } else { \"false\" });\n-\n-        let mut category_data = String::new();\n-\n-        for (category, data) in &results.categories {\n-            let (hits, total) = data.total_cache_data();\n-            let hit_percent = calculate_percent(hits, total);\n-\n-            category_data.push_str(&format!(\"{{ \\\"category\\\": \\\"{:?}\\\", \\\"time_ms\\\": {}, \\\n-                                                \\\"query_count\\\": {}, \\\"query_hits\\\": {} }}\",\n-                                            category,\n-                                            data.total_time(),\n-                                            total,\n-                                            format!(\"{:.2}\", hit_percent)));\n-        }\n-\n-        let json = format!(\"{{ \\\"category_data\\\": {}, \\\"compilation_options\\\": {} }}\",\n-                        category_data,\n-                        compilation_options);\n-\n-        fs::write(\"self_profiler_results.json\", json).unwrap();\n+        write!(file, \"] }}\").unwrap();\n     }\n }"}, {"sha": "4702e34aa19e7fabe00b33304e339b3a47ea8d68", "filename": "src/librustc_codegen_ssa/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_codegen_ssa%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_codegen_ssa%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2FCargo.toml?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -19,6 +19,7 @@ memmap = \"0.6\"\n log = \"0.4.5\"\n libc = \"0.2.44\"\n jobserver = \"0.1.11\"\n+parking_lot = \"0.7\"\n \n serialize = { path = \"../libserialize\" }\n syntax = { path = \"../libsyntax\" }"}, {"sha": "4bccc2a6d1f7b7d06809b8fd0b644cc42fd213d4", "filename": "src/librustc_codegen_ssa/back/write.rs", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -19,6 +19,7 @@ use rustc::util::time_graph::{self, TimeGraph, Timeline};\n use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n use rustc::ty::TyCtxt;\n use rustc::util::common::{time_depth, set_time_depth, print_time_passes_entry};\n+use rustc::util::profiling::SelfProfiler;\n use rustc_fs_util::link_or_copy;\n use rustc_data_structures::svh::Svh;\n use rustc_errors::{Handler, Level, DiagnosticBuilder, FatalError, DiagnosticId};\n@@ -29,6 +30,7 @@ use syntax::ext::hygiene::Mark;\n use syntax_pos::MultiSpan;\n use syntax_pos::symbol::Symbol;\n use jobserver::{Client, Acquired};\n+use parking_lot::Mutex as PlMutex;\n \n use std::any::Any;\n use std::fs;\n@@ -201,6 +203,7 @@ pub struct CodegenContext<B: WriteBackendMethods> {\n     // Resources needed when running LTO\n     pub backend: B,\n     pub time_passes: bool,\n+    pub profiler: Option<Arc<PlMutex<SelfProfiler>>>,\n     pub lto: Lto,\n     pub no_landing_pads: bool,\n     pub save_temps: bool,\n@@ -254,6 +257,26 @@ impl<B: WriteBackendMethods> CodegenContext<B> {\n             ModuleKind::Allocator => &self.allocator_module_config,\n         }\n     }\n+\n+    #[inline(never)]\n+    #[cold]\n+    fn profiler_active<F: FnOnce(&mut SelfProfiler) -> ()>(&self, f: F) {\n+        match &self.profiler {\n+            None => bug!(\"profiler_active() called but there was no profiler active\"),\n+            Some(profiler) => {\n+                let mut p = profiler.lock();\n+\n+                f(&mut p);\n+            }\n+        }\n+    }\n+\n+    #[inline(always)]\n+    pub fn profile<F: FnOnce(&mut SelfProfiler) -> ()>(&self, f: F) {\n+        if unlikely!(self.profiler.is_some()) {\n+            self.profiler_active(f)\n+        }\n+    }\n }\n \n fn generate_lto_work<B: ExtraBackendMethods>(\n@@ -1033,6 +1056,7 @@ fn start_executing_work<B: ExtraBackendMethods>(\n         save_temps: sess.opts.cg.save_temps,\n         opts: Arc::new(sess.opts.clone()),\n         time_passes: sess.time_passes(),\n+        profiler: sess.self_profiling.clone(),\n         exported_symbols,\n         plugin_passes: sess.plugin_llvm_passes.borrow().clone(),\n         remark: sess.opts.cg.remark.clone(),"}, {"sha": "fec41936a238432314336d6f149669c70f51b5e0", "filename": "src/librustc_codegen_ssa/lib.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_codegen_ssa%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_codegen_ssa%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Flib.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -2,9 +2,11 @@\n \n #![feature(box_patterns)]\n #![feature(box_syntax)]\n+#![feature(core_intrinsics)]\n #![feature(custom_attribute)]\n #![feature(libc)]\n #![feature(rustc_diagnostic_macros)]\n+#![feature(stmt_expr_attributes)]\n #![feature(in_band_lifetimes)]\n #![feature(nll)]\n #![allow(unused_attributes)]\n@@ -20,6 +22,7 @@\n \n #[macro_use] extern crate log;\n #[macro_use] extern crate rustc;\n+#[macro_use] extern crate rustc_data_structures;\n #[macro_use] extern crate syntax;\n \n use std::path::PathBuf;"}, {"sha": "d3e295607c2b395b40dd1f222a8286f705bde98b", "filename": "src/librustc_driver/driver.rs", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_driver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_driver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fdriver.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -349,14 +349,6 @@ pub fn compile_input(\n         sess.print_perf_stats();\n     }\n \n-    if sess.opts.debugging_opts.self_profile {\n-        sess.print_profiler_results();\n-    }\n-\n-    if sess.opts.debugging_opts.profile_json {\n-        sess.save_json_results();\n-    }\n-\n     controller_entry_point!(\n         compilation_done,\n         sess,"}, {"sha": "cc1b8916c1074401e87b08cea6b3843bca4f1258", "filename": "src/librustc_driver/lib.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_driver%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87a436377a7cddd1d4426c9604c48e0aa2ec0b11/src%2Flibrustc_driver%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Flib.rs?ref=87a436377a7cddd1d4426c9604c48e0aa2ec0b11", "patch": "@@ -276,6 +276,10 @@ fn run_compiler_with_pool<'a>(\n                               &control)\n     };\n \n+    if sess.opts.debugging_opts.self_profile {\n+        sess.profiler(|p| p.dump_raw_events(&sess.opts));\n+    }\n+\n     (result, Some(sess))\n }\n "}]}