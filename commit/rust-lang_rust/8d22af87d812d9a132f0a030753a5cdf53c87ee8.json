{"sha": "8d22af87d812d9a132f0a030753a5cdf53c87ee8", "node_id": "MDY6Q29tbWl0NzI0NzEyOjhkMjJhZjg3ZDgxMmQ5YTEzMmYwYTAzMDc1M2E1Y2RmNTNjODdlZTg=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-07-22T18:27:29Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-07-22T18:27:29Z"}, "message": "Auto merge of #43059 - Mark-Simulacrum:rustbuild-2.0, r=alexcrichton\n\nRework Rustbuild to an eagerly compiling approach\n\nThis introduces a new dependency on `serde`; I don't believe that's a problem since bootstrap is compiled with nightly/beta always so proc macros are available. Compile times are slightly longer -- about 2-3x (30 seconds vs. 10 seconds). I don't think this is too big a problem, especially since recompiling bootstrap is somewhat rare. I think we can remove the dependency on Serde if necessary, though, so let me know.\n\nr? @alexcrichton", "tree": {"sha": "8e63144c83e9b2a43701de768dc8ddaece405c31", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8e63144c83e9b2a43701de768dc8ddaece405c31"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8d22af87d812d9a132f0a030753a5cdf53c87ee8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8d22af87d812d9a132f0a030753a5cdf53c87ee8", "html_url": "https://github.com/rust-lang/rust/commit/8d22af87d812d9a132f0a030753a5cdf53c87ee8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8d22af87d812d9a132f0a030753a5cdf53c87ee8/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f8d485f53dbe87e0d7b4ad14904fd7b0447a8cbe", "url": "https://api.github.com/repos/rust-lang/rust/commits/f8d485f53dbe87e0d7b4ad14904fd7b0447a8cbe", "html_url": "https://github.com/rust-lang/rust/commit/f8d485f53dbe87e0d7b4ad14904fd7b0447a8cbe"}, {"sha": "1c118231adaa941899773420b21bc6b55ca3014f", "url": "https://api.github.com/repos/rust-lang/rust/commits/1c118231adaa941899773420b21bc6b55ca3014f", "html_url": "https://github.com/rust-lang/rust/commit/1c118231adaa941899773420b21bc6b55ca3014f"}], "stats": {"total": 10137, "additions": 5460, "deletions": 4677}, "files": [{"sha": "692252a8b05d4c82a9f964522ab77f50a0b1fd33", "filename": "src/Cargo.lock", "status": "modified", "additions": 8, "deletions": 13, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -134,10 +134,13 @@ dependencies = [\n  \"filetime 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"gcc 0.3.51 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"getopts 0.2.14 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"lazy_static 0.2.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"libc 0.2.26 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"num_cpus 1.6.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n- \"rustc-serialize 0.3.24 (registry+https://github.com/rust-lang/crates.io-index)\",\n- \"toml 0.1.30 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"serde 1.0.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"serde_derive 1.0.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"serde_json 1.0.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"toml 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n [[package]]\n@@ -153,8 +156,9 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n name = \"build-manifest\"\n version = \"0.1.0\"\n dependencies = [\n- \"rustc-serialize 0.3.24 (registry+https://github.com/rust-lang/crates.io-index)\",\n- \"toml 0.1.30 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"serde 1.0.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"serde_derive 1.0.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"toml 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n [[package]]\n@@ -1901,14 +1905,6 @@ dependencies = [\n name = \"tidy\"\n version = \"0.1.0\"\n \n-[[package]]\n-name = \"toml\"\n-version = \"0.1.30\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-dependencies = [\n- \"rustc-serialize 0.3.24 (registry+https://github.com/rust-lang/crates.io-index)\",\n-]\n-\n [[package]]\n name = \"toml\"\n version = \"0.2.1\"\n@@ -2206,7 +2202,6 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \"checksum thread-id 2.0.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"a9539db560102d1cef46b8b78ce737ff0bb64e7e18d35b2a5688f7d097d0ff03\"\n \"checksum thread_local 0.2.7 (registry+https://github.com/rust-lang/crates.io-index)\" = \"8576dbbfcaef9641452d5cf0df9b0e7eeab7694956dd33bb61515fb8f18cfdd5\"\n \"checksum thread_local 0.3.4 (registry+https://github.com/rust-lang/crates.io-index)\" = \"1697c4b57aeeb7a536b647165a2825faddffb1d3bad386d507709bd51a90bb14\"\n-\"checksum toml 0.1.30 (registry+https://github.com/rust-lang/crates.io-index)\" = \"0590d72182e50e879c4da3b11c6488dae18fccb1ae0c7a3eda18e16795844796\"\n \"checksum toml 0.2.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"736b60249cb25337bc196faa43ee12c705e426f3d55c214d73a4e7be06f92cb4\"\n \"checksum toml 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"b0601da6c97135c8d330c7a13a013ca6cd4143221b01de2f8d4edc50a9e551c7\"\n \"checksum typed-arena 1.3.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"5934776c3ac1bea4a9d56620d6bf2d483b20d394e49581db40f187e1118ff667\""}, {"sha": "daa2a3d0a0ff485c1927fe3626be3ece37e70410", "filename": "src/bootstrap/Cargo.toml", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2FCargo.toml?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -33,8 +33,11 @@ build_helper = { path = \"../build_helper\" }\n cmake = \"0.1.23\"\n filetime = \"0.1\"\n num_cpus = \"1.0\"\n-toml = \"0.1\"\n getopts = \"0.2\"\n-rustc-serialize = \"0.3\"\n gcc = \"0.3.50\"\n libc = \"0.2\"\n+serde = \"1.0.8\"\n+serde_derive = \"1.0.8\"\n+serde_json = \"1.0.2\"\n+toml = \"0.4\"\n+lazy_static = \"0.2\""}, {"sha": "7be391e5420278a6a8259844d5f014960b62bdb8", "filename": "src/bootstrap/builder.rs", "status": "added", "additions": 618, "deletions": 0, "changes": 618, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fbuilder.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -0,0 +1,618 @@\n+// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use std::fmt::Debug;\n+use std::hash::Hash;\n+use std::cell::RefCell;\n+use std::path::{Path, PathBuf};\n+use std::process::Command;\n+use std::fs;\n+use std::ops::Deref;\n+use std::any::Any;\n+use std::collections::BTreeSet;\n+\n+use compile;\n+use install;\n+use dist;\n+use util::{exe, libdir, add_lib_path};\n+use {Build, Mode};\n+use cache::{INTERNER, Interned, Cache};\n+use check;\n+use flags::Subcommand;\n+use doc;\n+use tool;\n+\n+pub use Compiler;\n+\n+pub struct Builder<'a> {\n+    pub build: &'a Build,\n+    pub top_stage: u32,\n+    pub kind: Kind,\n+    cache: Cache,\n+    stack: RefCell<Vec<Box<Any>>>,\n+}\n+\n+impl<'a> Deref for Builder<'a> {\n+    type Target = Build;\n+\n+    fn deref(&self) -> &Self::Target {\n+        self.build\n+    }\n+}\n+\n+pub trait Step: 'static + Clone + Debug + PartialEq + Eq + Hash {\n+    /// `PathBuf` when directories are created or to return a `Compiler` once\n+    /// it's been assembled.\n+    type Output: Clone;\n+\n+    const DEFAULT: bool = false;\n+\n+    /// Run this rule for all hosts without cross compiling.\n+    const ONLY_HOSTS: bool = false;\n+\n+    /// Run this rule for all targets, but only with the native host.\n+    const ONLY_BUILD_TARGETS: bool = false;\n+\n+    /// Only run this step with the build triple as host and target.\n+    const ONLY_BUILD: bool = false;\n+\n+    /// Primary function to execute this rule. Can call `builder.ensure(...)`\n+    /// with other steps to run those.\n+    fn run(self, builder: &Builder) -> Self::Output;\n+\n+    /// When bootstrap is passed a set of paths, this controls whether this rule\n+    /// will execute. However, it does not get called in a \"default\" context\n+    /// when we are not passed any paths; in that case, make_run is called\n+    /// directly.\n+    fn should_run(run: ShouldRun) -> ShouldRun;\n+\n+    /// Build up a \"root\" rule, either as a default rule or from a path passed\n+    /// to us.\n+    ///\n+    /// When path is `None`, we are executing in a context where no paths were\n+    /// passed. When `./x.py build` is run, for example, this rule could get\n+    /// called if it is in the correct list below with a path of `None`.\n+    fn make_run(_run: RunConfig) {\n+        // It is reasonable to not have an implementation of make_run for rules\n+        // who do not want to get called from the root context. This means that\n+        // they are likely dependencies (e.g., sysroot creation) or similar, and\n+        // as such calling them from ./x.py isn't logical.\n+        unimplemented!()\n+    }\n+}\n+\n+pub struct RunConfig<'a> {\n+    pub builder: &'a Builder<'a>,\n+    pub host: Interned<String>,\n+    pub target: Interned<String>,\n+    pub path: Option<&'a Path>,\n+}\n+\n+struct StepDescription {\n+    default: bool,\n+    only_hosts: bool,\n+    only_build_targets: bool,\n+    only_build: bool,\n+    should_run: fn(ShouldRun) -> ShouldRun,\n+    make_run: fn(RunConfig),\n+}\n+\n+impl StepDescription {\n+    fn from<S: Step>() -> StepDescription {\n+        StepDescription {\n+            default: S::DEFAULT,\n+            only_hosts: S::ONLY_HOSTS,\n+            only_build_targets: S::ONLY_BUILD_TARGETS,\n+            only_build: S::ONLY_BUILD,\n+            should_run: S::should_run,\n+            make_run: S::make_run,\n+        }\n+    }\n+\n+    fn maybe_run(&self, builder: &Builder, path: Option<&Path>) {\n+        let build = builder.build;\n+        let hosts = if self.only_build_targets || self.only_build {\n+            &build.config.host[..1]\n+        } else {\n+            &build.hosts\n+        };\n+\n+        // Determine the actual targets participating in this rule.\n+        // NOTE: We should keep the full projection from build triple to\n+        // the hosts for the dist steps, now that the hosts array above is\n+        // truncated to avoid duplication of work in that case. Therefore\n+        // the original non-shadowed hosts array is used below.\n+        let targets = if self.only_hosts {\n+            // If --target was specified but --host wasn't specified,\n+            // don't run any host-only tests. Also, respect any `--host`\n+            // overrides as done for `hosts`.\n+            if build.flags.host.len() > 0 {\n+                &build.flags.host[..]\n+            } else if build.flags.target.len() > 0 {\n+                &[]\n+            } else if self.only_build {\n+                &build.config.host[..1]\n+            } else {\n+                &build.config.host[..]\n+            }\n+        } else {\n+            &build.targets\n+        };\n+\n+        for host in hosts {\n+            for target in targets {\n+                let run = RunConfig {\n+                    builder,\n+                    path,\n+                    host: *host,\n+                    target: *target,\n+                };\n+                (self.make_run)(run);\n+            }\n+        }\n+    }\n+\n+    fn run(v: &[StepDescription], builder: &Builder, paths: &[PathBuf]) {\n+        let should_runs = v.iter().map(|desc| {\n+            (desc.should_run)(ShouldRun::new(builder))\n+        }).collect::<Vec<_>>();\n+        if paths.is_empty() {\n+            for (desc, should_run) in v.iter().zip(should_runs) {\n+                if desc.default && should_run.is_really_default {\n+                    desc.maybe_run(builder, None);\n+                }\n+            }\n+        } else {\n+            for path in paths {\n+                let mut attempted_run = false;\n+                for (desc, should_run) in v.iter().zip(&should_runs) {\n+                    if should_run.run(path) {\n+                        attempted_run = true;\n+                        desc.maybe_run(builder, Some(path));\n+                    }\n+                }\n+\n+                if !attempted_run {\n+                    eprintln!(\"Warning: no rules matched {}.\", path.display());\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Clone)]\n+pub struct ShouldRun<'a> {\n+    pub builder: &'a Builder<'a>,\n+    // use a BTreeSet to maintain sort order\n+    paths: BTreeSet<PathBuf>,\n+\n+    // If this is a default rule, this is an additional constraint placed on\n+    // it's run. Generally something like compiler docs being enabled.\n+    is_really_default: bool,\n+}\n+\n+impl<'a> ShouldRun<'a> {\n+    fn new(builder: &'a Builder) -> ShouldRun<'a> {\n+        ShouldRun {\n+            builder: builder,\n+            paths: BTreeSet::new(),\n+            is_really_default: true, // by default no additional conditions\n+        }\n+    }\n+\n+    pub fn default_condition(mut self, cond: bool) -> Self {\n+        self.is_really_default = cond;\n+        self\n+    }\n+\n+    pub fn krate(mut self, name: &str) -> Self {\n+        for (_, krate_path) in self.builder.crates(name) {\n+            self.paths.insert(PathBuf::from(krate_path));\n+        }\n+        self\n+    }\n+\n+    pub fn path(mut self, path: &str) -> Self {\n+        self.paths.insert(PathBuf::from(path));\n+        self\n+    }\n+\n+    // allows being more explicit about why should_run in Step returns the value passed to it\n+    pub fn never(self) -> ShouldRun<'a> {\n+        self\n+    }\n+\n+    fn run(&self, path: &Path) -> bool {\n+        self.paths.iter().any(|p| path.ends_with(p))\n+    }\n+}\n+\n+#[derive(Copy, Clone, PartialEq, Eq, Debug)]\n+pub enum Kind {\n+    Build,\n+    Test,\n+    Bench,\n+    Dist,\n+    Doc,\n+    Install,\n+}\n+\n+impl<'a> Builder<'a> {\n+    fn get_step_descriptions(kind: Kind) -> Vec<StepDescription> {\n+        macro_rules! describe {\n+            ($($rule:ty),+ $(,)*) => {{\n+                vec![$(StepDescription::from::<$rule>()),+]\n+            }};\n+        }\n+        match kind {\n+            Kind::Build => describe!(compile::Std, compile::Test, compile::Rustc,\n+                compile::StartupObjects, tool::BuildManifest, tool::Rustbook, tool::ErrorIndex,\n+                tool::UnstableBookGen, tool::Tidy, tool::Linkchecker, tool::CargoTest,\n+                tool::Compiletest, tool::RemoteTestServer, tool::RemoteTestClient,\n+                tool::RustInstaller, tool::Cargo, tool::Rls),\n+            Kind::Test => describe!(check::Tidy, check::Bootstrap, check::DefaultCompiletest,\n+                check::HostCompiletest, check::Crate, check::CrateLibrustc, check::Linkcheck,\n+                check::Cargotest, check::Cargo, check::Rls, check::Docs, check::ErrorIndex,\n+                check::Distcheck),\n+            Kind::Bench => describe!(check::Crate, check::CrateLibrustc),\n+            Kind::Doc => describe!(doc::UnstableBook, doc::UnstableBookGen, doc::TheBook,\n+                doc::Standalone, doc::Std, doc::Test, doc::Rustc, doc::ErrorIndex, doc::Nomicon,\n+                doc::Reference),\n+            Kind::Dist => describe!(dist::Docs, dist::Mingw, dist::Rustc, dist::DebuggerScripts,\n+                dist::Std, dist::Analysis, dist::Src, dist::PlainSourceTarball, dist::Cargo,\n+                dist::Rls, dist::Extended, dist::HashSign),\n+            Kind::Install => describe!(install::Docs, install::Std, install::Cargo, install::Rls,\n+                install::Analysis, install::Src, install::Rustc),\n+        }\n+    }\n+\n+    pub fn get_help(build: &Build, subcommand: &str) -> Option<String> {\n+        let kind = match subcommand {\n+            \"build\" => Kind::Build,\n+            \"doc\" => Kind::Doc,\n+            \"test\" => Kind::Test,\n+            \"bench\" => Kind::Bench,\n+            \"dist\" => Kind::Dist,\n+            \"install\" => Kind::Install,\n+            _ => return None,\n+        };\n+\n+        let builder = Builder {\n+            build: build,\n+            top_stage: build.flags.stage.unwrap_or(2),\n+            kind: kind,\n+            cache: Cache::new(),\n+            stack: RefCell::new(Vec::new()),\n+        };\n+\n+        let builder = &builder;\n+        let mut should_run = ShouldRun::new(builder);\n+        for desc in Builder::get_step_descriptions(builder.kind) {\n+            should_run = (desc.should_run)(should_run);\n+        }\n+        let mut help = String::from(\"Available paths:\\n\");\n+        for path in should_run.paths {\n+            help.push_str(format!(\"    ./x.py {} {}\\n\", subcommand, path.display()).as_str());\n+        }\n+        Some(help)\n+    }\n+\n+    pub fn run(build: &Build) {\n+        let (kind, paths) = match build.flags.cmd {\n+            Subcommand::Build { ref paths } => (Kind::Build, &paths[..]),\n+            Subcommand::Doc { ref paths } => (Kind::Doc, &paths[..]),\n+            Subcommand::Test { ref paths, .. } => (Kind::Test, &paths[..]),\n+            Subcommand::Bench { ref paths, .. } => (Kind::Bench, &paths[..]),\n+            Subcommand::Dist { ref paths } => (Kind::Dist, &paths[..]),\n+            Subcommand::Install { ref paths } => (Kind::Install, &paths[..]),\n+            Subcommand::Clean => panic!(),\n+        };\n+\n+        let builder = Builder {\n+            build: build,\n+            top_stage: build.flags.stage.unwrap_or(2),\n+            kind: kind,\n+            cache: Cache::new(),\n+            stack: RefCell::new(Vec::new()),\n+        };\n+\n+        StepDescription::run(&Builder::get_step_descriptions(builder.kind), &builder, paths);\n+    }\n+\n+    pub fn default_doc(&self, paths: Option<&[PathBuf]>) {\n+        let paths = paths.unwrap_or(&[]);\n+        StepDescription::run(&Builder::get_step_descriptions(Kind::Doc), self, paths);\n+    }\n+\n+    /// Obtain a compiler at a given stage and for a given host. Explictly does\n+    /// not take `Compiler` since all `Compiler` instances are meant to be\n+    /// obtained through this function, since it ensures that they are valid\n+    /// (i.e., built and assembled).\n+    pub fn compiler(&self, stage: u32, host: Interned<String>) -> Compiler {\n+        self.ensure(compile::Assemble { target_compiler: Compiler { stage, host } })\n+    }\n+\n+    pub fn sysroot(&self, compiler: Compiler) -> Interned<PathBuf> {\n+        self.ensure(compile::Sysroot { compiler })\n+    }\n+\n+    /// Returns the libdir where the standard library and other artifacts are\n+    /// found for a compiler's sysroot.\n+    pub fn sysroot_libdir(\n+        &self, compiler: Compiler, target: Interned<String>\n+    ) -> Interned<PathBuf> {\n+        #[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+        struct Libdir {\n+            compiler: Compiler,\n+            target: Interned<String>,\n+        }\n+        impl Step for Libdir {\n+            type Output = Interned<PathBuf>;\n+\n+            fn should_run(run: ShouldRun) -> ShouldRun {\n+                run.never()\n+            }\n+\n+            fn run(self, builder: &Builder) -> Interned<PathBuf> {\n+                let compiler = self.compiler;\n+                let lib = if compiler.stage >= 2 && builder.build.config.libdir_relative.is_some() {\n+                    builder.build.config.libdir_relative.clone().unwrap()\n+                } else {\n+                    PathBuf::from(\"lib\")\n+                };\n+                let sysroot = builder.sysroot(self.compiler).join(lib)\n+                    .join(\"rustlib\").join(self.target).join(\"lib\");\n+                let _ = fs::remove_dir_all(&sysroot);\n+                t!(fs::create_dir_all(&sysroot));\n+                INTERNER.intern_path(sysroot)\n+            }\n+        }\n+        self.ensure(Libdir { compiler, target })\n+    }\n+\n+    /// Returns the compiler's libdir where it stores the dynamic libraries that\n+    /// it itself links against.\n+    ///\n+    /// For example this returns `<sysroot>/lib` on Unix and `<sysroot>/bin` on\n+    /// Windows.\n+    pub fn rustc_libdir(&self, compiler: Compiler) -> PathBuf {\n+        if compiler.is_snapshot(self) {\n+            self.build.rustc_snapshot_libdir()\n+        } else {\n+            self.sysroot(compiler).join(libdir(&compiler.host))\n+        }\n+    }\n+\n+    /// Adds the compiler's directory of dynamic libraries to `cmd`'s dynamic\n+    /// library lookup path.\n+    pub fn add_rustc_lib_path(&self, compiler: Compiler, cmd: &mut Command) {\n+        // Windows doesn't need dylib path munging because the dlls for the\n+        // compiler live next to the compiler and the system will find them\n+        // automatically.\n+        if cfg!(windows) {\n+            return\n+        }\n+\n+        add_lib_path(vec![self.rustc_libdir(compiler)], cmd);\n+    }\n+\n+    /// Get a path to the compiler specified.\n+    pub fn rustc(&self, compiler: Compiler) -> PathBuf {\n+        if compiler.is_snapshot(self) {\n+            self.initial_rustc.clone()\n+        } else {\n+            self.sysroot(compiler).join(\"bin\").join(exe(\"rustc\", &compiler.host))\n+        }\n+    }\n+\n+    /// Get the `rustdoc` executable next to the specified compiler\n+    pub fn rustdoc(&self, compiler: Compiler) -> PathBuf {\n+        let mut rustdoc = self.rustc(compiler);\n+        rustdoc.pop();\n+        rustdoc.push(exe(\"rustdoc\", &compiler.host));\n+        rustdoc\n+    }\n+\n+    /// Prepares an invocation of `cargo` to be run.\n+    ///\n+    /// This will create a `Command` that represents a pending execution of\n+    /// Cargo. This cargo will be configured to use `compiler` as the actual\n+    /// rustc compiler, its output will be scoped by `mode`'s output directory,\n+    /// it will pass the `--target` flag for the specified `target`, and will be\n+    /// executing the Cargo command `cmd`.\n+    pub fn cargo(&self,\n+             compiler: Compiler,\n+             mode: Mode,\n+             target: Interned<String>,\n+             cmd: &str) -> Command {\n+        let mut cargo = Command::new(&self.initial_cargo);\n+        let out_dir = self.stage_out(compiler, mode);\n+        cargo.env(\"CARGO_TARGET_DIR\", out_dir)\n+             .arg(cmd)\n+             .arg(\"-j\").arg(self.jobs().to_string())\n+             .arg(\"--target\").arg(target);\n+\n+        // FIXME: Temporary fix for https://github.com/rust-lang/cargo/issues/3005\n+        // Force cargo to output binaries with disambiguating hashes in the name\n+        cargo.env(\"__CARGO_DEFAULT_LIB_METADATA\", &self.config.channel);\n+\n+        let stage;\n+        if compiler.stage == 0 && self.local_rebuild {\n+            // Assume the local-rebuild rustc already has stage1 features.\n+            stage = 1;\n+        } else {\n+            stage = compiler.stage;\n+        }\n+\n+        // Customize the compiler we're running. Specify the compiler to cargo\n+        // as our shim and then pass it some various options used to configure\n+        // how the actual compiler itself is called.\n+        //\n+        // These variables are primarily all read by\n+        // src/bootstrap/bin/{rustc.rs,rustdoc.rs}\n+        cargo.env(\"RUSTBUILD_NATIVE_DIR\", self.native_dir(target))\n+             .env(\"RUSTC\", self.out.join(\"bootstrap/debug/rustc\"))\n+             .env(\"RUSTC_REAL\", self.rustc(compiler))\n+             .env(\"RUSTC_STAGE\", stage.to_string())\n+             .env(\"RUSTC_CODEGEN_UNITS\",\n+                  self.config.rust_codegen_units.to_string())\n+             .env(\"RUSTC_DEBUG_ASSERTIONS\",\n+                  self.config.rust_debug_assertions.to_string())\n+             .env(\"RUSTC_SYSROOT\", self.sysroot(compiler))\n+             .env(\"RUSTC_LIBDIR\", self.rustc_libdir(compiler))\n+             .env(\"RUSTC_RPATH\", self.config.rust_rpath.to_string())\n+             .env(\"RUSTDOC\", self.out.join(\"bootstrap/debug/rustdoc\"))\n+             .env(\"RUSTDOC_REAL\", self.rustdoc(compiler))\n+             .env(\"RUSTC_FLAGS\", self.rustc_flags(target).join(\" \"));\n+\n+        if mode != Mode::Tool {\n+            // Tools don't get debuginfo right now, e.g. cargo and rls don't\n+            // get compiled with debuginfo.\n+            cargo.env(\"RUSTC_DEBUGINFO\", self.config.rust_debuginfo.to_string())\n+                 .env(\"RUSTC_DEBUGINFO_LINES\", self.config.rust_debuginfo_lines.to_string())\n+                 .env(\"RUSTC_FORCE_UNSTABLE\", \"1\");\n+\n+            // Currently the compiler depends on crates from crates.io, and\n+            // then other crates can depend on the compiler (e.g. proc-macro\n+            // crates). Let's say, for example that rustc itself depends on the\n+            // bitflags crate. If an external crate then depends on the\n+            // bitflags crate as well, we need to make sure they don't\n+            // conflict, even if they pick the same verison of bitflags. We'll\n+            // want to make sure that e.g. a plugin and rustc each get their\n+            // own copy of bitflags.\n+\n+            // Cargo ensures that this works in general through the -C metadata\n+            // flag. This flag will frob the symbols in the binary to make sure\n+            // they're different, even though the source code is the exact\n+            // same. To solve this problem for the compiler we extend Cargo's\n+            // already-passed -C metadata flag with our own. Our rustc.rs\n+            // wrapper around the actual rustc will detect -C metadata being\n+            // passed and frob it with this extra string we're passing in.\n+            cargo.env(\"RUSTC_METADATA_SUFFIX\", \"rustc\");\n+        }\n+\n+        // Enable usage of unstable features\n+        cargo.env(\"RUSTC_BOOTSTRAP\", \"1\");\n+        self.add_rust_test_threads(&mut cargo);\n+\n+        // Almost all of the crates that we compile as part of the bootstrap may\n+        // have a build script, including the standard library. To compile a\n+        // build script, however, it itself needs a standard library! This\n+        // introduces a bit of a pickle when we're compiling the standard\n+        // library itself.\n+        //\n+        // To work around this we actually end up using the snapshot compiler\n+        // (stage0) for compiling build scripts of the standard library itself.\n+        // The stage0 compiler is guaranteed to have a libstd available for use.\n+        //\n+        // For other crates, however, we know that we've already got a standard\n+        // library up and running, so we can use the normal compiler to compile\n+        // build scripts in that situation.\n+        if mode == Mode::Libstd {\n+            cargo.env(\"RUSTC_SNAPSHOT\", &self.initial_rustc)\n+                 .env(\"RUSTC_SNAPSHOT_LIBDIR\", self.rustc_snapshot_libdir());\n+        } else {\n+            cargo.env(\"RUSTC_SNAPSHOT\", self.rustc(compiler))\n+                 .env(\"RUSTC_SNAPSHOT_LIBDIR\", self.rustc_libdir(compiler));\n+        }\n+\n+        // Ignore incremental modes except for stage0, since we're\n+        // not guaranteeing correctness across builds if the compiler\n+        // is changing under your feet.`\n+        if self.flags.incremental && compiler.stage == 0 {\n+            let incr_dir = self.incremental_dir(compiler);\n+            cargo.env(\"RUSTC_INCREMENTAL\", incr_dir);\n+        }\n+\n+        if let Some(ref on_fail) = self.flags.on_fail {\n+            cargo.env(\"RUSTC_ON_FAIL\", on_fail);\n+        }\n+\n+        cargo.env(\"RUSTC_VERBOSE\", format!(\"{}\", self.verbosity));\n+\n+        // Specify some various options for build scripts used throughout\n+        // the build.\n+        //\n+        // FIXME: the guard against msvc shouldn't need to be here\n+        if !target.contains(\"msvc\") {\n+            cargo.env(format!(\"CC_{}\", target), self.cc(target))\n+                 .env(format!(\"AR_{}\", target), self.ar(target).unwrap()) // only msvc is None\n+                 .env(format!(\"CFLAGS_{}\", target), self.cflags(target).join(\" \"));\n+\n+            if let Ok(cxx) = self.cxx(target) {\n+                 cargo.env(format!(\"CXX_{}\", target), cxx);\n+            }\n+        }\n+\n+        if mode == Mode::Libstd && self.config.extended && compiler.is_final_stage(self) {\n+            cargo.env(\"RUSTC_SAVE_ANALYSIS\", \"api\".to_string());\n+        }\n+\n+        // Environment variables *required* throughout the build\n+        //\n+        // FIXME: should update code to not require this env var\n+        cargo.env(\"CFG_COMPILER_HOST_TRIPLE\", target);\n+\n+        if self.is_verbose() {\n+            cargo.arg(\"-v\");\n+        }\n+        // FIXME: cargo bench does not accept `--release`\n+        if self.config.rust_optimize && cmd != \"bench\" {\n+            cargo.arg(\"--release\");\n+        }\n+        if self.config.locked_deps {\n+            cargo.arg(\"--locked\");\n+        }\n+        if self.config.vendor || self.is_sudo {\n+            cargo.arg(\"--frozen\");\n+        }\n+\n+        self.ci_env.force_coloring_in_ci(&mut cargo);\n+\n+        cargo\n+    }\n+\n+    /// Ensure that a given step is built, returning it's output. This will\n+    /// cache the step, so it is safe (and good!) to call this as often as\n+    /// needed to ensure that all dependencies are built.\n+    pub fn ensure<S: Step>(&'a self, step: S) -> S::Output {\n+        {\n+            let mut stack = self.stack.borrow_mut();\n+            for stack_step in stack.iter() {\n+                // should skip\n+                if stack_step.downcast_ref::<S>().map_or(true, |stack_step| *stack_step != step) {\n+                    continue;\n+                }\n+                let mut out = String::new();\n+                out += &format!(\"\\n\\nCycle in build detected when adding {:?}\\n\", step);\n+                for el in stack.iter().rev() {\n+                    out += &format!(\"\\t{:?}\\n\", el);\n+                }\n+                panic!(out);\n+            }\n+            if let Some(out) = self.cache.get(&step) {\n+                self.build.verbose(&format!(\"{}c {:?}\", \"  \".repeat(stack.len()), step));\n+\n+                return out;\n+            }\n+            self.build.verbose(&format!(\"{}> {:?}\", \"  \".repeat(stack.len()), step));\n+            stack.push(Box::new(step.clone()));\n+        }\n+        let out = step.clone().run(self);\n+        {\n+            let mut stack = self.stack.borrow_mut();\n+            let cur_step = stack.pop().expect(\"step stack empty\");\n+            assert_eq!(cur_step.downcast_ref(), Some(&step));\n+        }\n+        self.build.verbose(&format!(\"{}< {:?}\", \"  \".repeat(self.stack.borrow().len()), step));\n+        self.cache.put(step, out.clone());\n+        out\n+    }\n+}"}, {"sha": "c27493158826cf695c69586e0af896e91f9e35bd", "filename": "src/bootstrap/cache.rs", "status": "added", "additions": 267, "deletions": 0, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fcache.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -0,0 +1,267 @@\n+// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use std::any::{Any, TypeId};\n+use std::borrow::Borrow;\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::convert::AsRef;\n+use std::ffi::OsStr;\n+use std::fmt;\n+use std::hash::{Hash, Hasher};\n+use std::marker::PhantomData;\n+use std::mem;\n+use std::ops::Deref;\n+use std::path::{Path, PathBuf};\n+use std::sync::Mutex;\n+\n+use builder::Step;\n+\n+pub struct Interned<T>(usize, PhantomData<*const T>);\n+\n+impl Default for Interned<String> {\n+    fn default() -> Self {\n+        INTERNER.intern_string(String::default())\n+    }\n+}\n+\n+impl Default for Interned<PathBuf> {\n+    fn default() -> Self {\n+        INTERNER.intern_path(PathBuf::default())\n+    }\n+}\n+\n+impl<T> Copy for Interned<T> {}\n+impl<T> Clone for Interned<T> {\n+    fn clone(&self) -> Interned<T> {\n+        *self\n+    }\n+}\n+\n+impl<T> PartialEq for Interned<T> {\n+    fn eq(&self, other: &Self) -> bool {\n+        self.0 == other.0\n+    }\n+}\n+impl<T> Eq for Interned<T> {}\n+\n+impl PartialEq<str> for Interned<String> {\n+    fn eq(&self, other: &str) -> bool {\n+       *self == other\n+    }\n+}\n+impl<'a> PartialEq<&'a str> for Interned<String> {\n+    fn eq(&self, other: &&str) -> bool {\n+        **self == **other\n+    }\n+}\n+impl<'a, T> PartialEq<&'a Interned<T>> for Interned<T> {\n+    fn eq(&self, other: &&Self) -> bool {\n+        self.0 == other.0\n+    }\n+}\n+impl<'a, T> PartialEq<Interned<T>> for &'a Interned<T> {\n+    fn eq(&self, other: &Interned<T>) -> bool {\n+        self.0 == other.0\n+    }\n+}\n+\n+unsafe impl<T> Send for Interned<T> {}\n+unsafe impl<T> Sync for Interned<T> {}\n+\n+impl fmt::Display for Interned<String> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        let s: &str = &*self;\n+        f.write_str(s)\n+    }\n+}\n+\n+impl fmt::Debug for Interned<String> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        let s: &str = &*self;\n+        f.write_fmt(format_args!(\"{:?}\", s))\n+    }\n+}\n+impl fmt::Debug for Interned<PathBuf> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        let s: &Path = &*self;\n+        f.write_fmt(format_args!(\"{:?}\", s))\n+    }\n+}\n+\n+impl Hash for Interned<String> {\n+    fn hash<H: Hasher>(&self, state: &mut H) {\n+        let l = INTERNER.strs.lock().unwrap();\n+        l.get(*self).hash(state)\n+    }\n+}\n+\n+impl Hash for Interned<PathBuf> {\n+    fn hash<H: Hasher>(&self, state: &mut H) {\n+        let l = INTERNER.paths.lock().unwrap();\n+        l.get(*self).hash(state)\n+    }\n+}\n+\n+impl Deref for Interned<String> {\n+    type Target = str;\n+    fn deref(&self) -> &'static str {\n+        let l = INTERNER.strs.lock().unwrap();\n+        unsafe { mem::transmute::<&str, &'static str>(l.get(*self)) }\n+    }\n+}\n+\n+impl Deref for Interned<PathBuf> {\n+    type Target = Path;\n+    fn deref(&self) -> &'static Path {\n+        let l = INTERNER.paths.lock().unwrap();\n+        unsafe { mem::transmute::<&Path, &'static Path>(l.get(*self)) }\n+    }\n+}\n+\n+impl AsRef<Path> for Interned<PathBuf> {\n+    fn as_ref(&self) -> &'static Path {\n+        let l = INTERNER.paths.lock().unwrap();\n+        unsafe { mem::transmute::<&Path, &'static Path>(l.get(*self)) }\n+    }\n+}\n+\n+impl AsRef<Path> for Interned<String> {\n+    fn as_ref(&self) -> &'static Path {\n+        let l = INTERNER.strs.lock().unwrap();\n+        unsafe { mem::transmute::<&Path, &'static Path>(l.get(*self).as_ref()) }\n+    }\n+}\n+\n+impl AsRef<OsStr> for Interned<PathBuf> {\n+    fn as_ref(&self) -> &'static OsStr {\n+        let l = INTERNER.paths.lock().unwrap();\n+        unsafe { mem::transmute::<&OsStr, &'static OsStr>(l.get(*self).as_ref()) }\n+    }\n+}\n+\n+impl AsRef<OsStr> for Interned<String> {\n+    fn as_ref(&self) -> &'static OsStr {\n+        let l = INTERNER.strs.lock().unwrap();\n+        unsafe { mem::transmute::<&OsStr, &'static OsStr>(l.get(*self).as_ref()) }\n+    }\n+}\n+\n+\n+struct TyIntern<T> {\n+    items: Vec<T>,\n+    set: HashMap<T, Interned<T>>,\n+}\n+\n+impl<T: Hash + Clone + Eq> TyIntern<T> {\n+    fn new() -> TyIntern<T> {\n+        TyIntern {\n+            items: Vec::new(),\n+            set: HashMap::new(),\n+        }\n+    }\n+\n+    fn intern_borrow<B>(&mut self, item: &B) -> Interned<T>\n+    where\n+        B: Eq + Hash + ToOwned<Owned=T> + ?Sized,\n+        T: Borrow<B>,\n+    {\n+        if let Some(i) = self.set.get(&item) {\n+            return *i;\n+        }\n+        let item = item.to_owned();\n+        let interned =  Interned(self.items.len(), PhantomData::<*const T>);\n+        self.set.insert(item.clone(), interned);\n+        self.items.push(item);\n+        interned\n+    }\n+\n+    fn intern(&mut self, item: T) -> Interned<T> {\n+        if let Some(i) = self.set.get(&item) {\n+            return *i;\n+        }\n+        let interned =  Interned(self.items.len(), PhantomData::<*const T>);\n+        self.set.insert(item.clone(), interned);\n+        self.items.push(item);\n+        interned\n+    }\n+\n+    fn get(&self, i: Interned<T>) -> &T {\n+        &self.items[i.0]\n+    }\n+}\n+\n+pub struct Interner {\n+    strs: Mutex<TyIntern<String>>,\n+    paths: Mutex<TyIntern<PathBuf>>,\n+}\n+\n+impl Interner {\n+    fn new() -> Interner {\n+        Interner {\n+            strs: Mutex::new(TyIntern::new()),\n+            paths: Mutex::new(TyIntern::new()),\n+        }\n+    }\n+\n+    pub fn intern_str(&self, s: &str) -> Interned<String> {\n+        self.strs.lock().unwrap().intern_borrow(s)\n+    }\n+    pub fn intern_string(&self, s: String) -> Interned<String> {\n+        self.strs.lock().unwrap().intern(s)\n+    }\n+\n+    pub fn intern_path(&self, s: PathBuf) -> Interned<PathBuf> {\n+        self.paths.lock().unwrap().intern(s)\n+    }\n+}\n+\n+lazy_static! {\n+    pub static ref INTERNER: Interner = Interner::new();\n+}\n+\n+/// This is essentially a HashMap which allows storing any type in its input and\n+/// any type in its output. It is a write-once cache; values are never evicted,\n+/// which means that references to the value can safely be returned from the\n+/// get() method.\n+#[derive(Debug)]\n+pub struct Cache(\n+    RefCell<HashMap<\n+        TypeId,\n+        Box<Any>, // actually a HashMap<Step, Interned<Step::Output>>\n+    >>\n+);\n+\n+impl Cache {\n+    pub fn new() -> Cache {\n+        Cache(RefCell::new(HashMap::new()))\n+    }\n+\n+    pub fn put<S: Step>(&self, step: S, value: S::Output) {\n+        let mut cache = self.0.borrow_mut();\n+        let type_id = TypeId::of::<S>();\n+        let stepcache = cache.entry(type_id)\n+                        .or_insert_with(|| Box::new(HashMap::<S, S::Output>::new()))\n+                        .downcast_mut::<HashMap<S, S::Output>>()\n+                        .expect(\"invalid type mapped\");\n+        assert!(!stepcache.contains_key(&step), \"processing {:?} a second time\", step);\n+        stepcache.insert(step, value);\n+    }\n+\n+    pub fn get<S: Step>(&self, step: &S) -> Option<S::Output> {\n+        let mut cache = self.0.borrow_mut();\n+        let type_id = TypeId::of::<S>();\n+        let stepcache = cache.entry(type_id)\n+                        .or_insert_with(|| Box::new(HashMap::<S, S::Output>::new()))\n+                        .downcast_mut::<HashMap<S, S::Output>>()\n+                        .expect(\"invalid type mapped\");\n+        stepcache.get(step).cloned()\n+    }\n+}"}, {"sha": "739904e4f7c58edabc56553b8bf0b037f8f53bec", "filename": "src/bootstrap/cc.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fcc.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -38,6 +38,7 @@ use gcc;\n \n use Build;\n use config::Target;\n+use cache::Interned;\n \n pub fn find(build: &mut Build) {\n     // For all targets we're going to need a C compiler for building some shims\n@@ -50,11 +51,11 @@ pub fn find(build: &mut Build) {\n         cfg.cargo_metadata(false).opt_level(0).debug(false)\n            .target(target).host(&build.build);\n \n-        let config = build.config.target_config.get(target);\n+        let config = build.config.target_config.get(&target);\n         if let Some(cc) = config.and_then(|c| c.cc.as_ref()) {\n             cfg.compiler(cc);\n         } else {\n-            set_compiler(&mut cfg, \"gcc\", target, config, build);\n+            set_compiler(&mut cfg, \"gcc\", *target, config, build);\n         }\n \n         let compiler = cfg.get_compiler();\n@@ -63,7 +64,7 @@ pub fn find(build: &mut Build) {\n         if let Some(ref ar) = ar {\n             build.verbose(&format!(\"AR_{} = {:?}\", target, ar));\n         }\n-        build.cc.insert(target.to_string(), (compiler, ar));\n+        build.cc.insert(*target, (compiler, ar));\n     }\n \n     // For all host triples we need to find a C++ compiler as well\n@@ -78,20 +79,20 @@ pub fn find(build: &mut Build) {\n         if let Some(cxx) = config.and_then(|c| c.cxx.as_ref()) {\n             cfg.compiler(cxx);\n         } else {\n-            set_compiler(&mut cfg, \"g++\", host, config, build);\n+            set_compiler(&mut cfg, \"g++\", *host, config, build);\n         }\n         let compiler = cfg.get_compiler();\n         build.verbose(&format!(\"CXX_{} = {:?}\", host, compiler.path()));\n-        build.cxx.insert(host.to_string(), compiler);\n+        build.cxx.insert(*host, compiler);\n     }\n }\n \n fn set_compiler(cfg: &mut gcc::Config,\n                 gnu_compiler: &str,\n-                target: &str,\n+                target: Interned<String>,\n                 config: Option<&Target>,\n                 build: &Build) {\n-    match target {\n+    match &*target {\n         // When compiling for android we may have the NDK configured in the\n         // config.toml in which case we look there. Otherwise the default\n         // compiler already takes into account the triple in question."}, {"sha": "ee589261752913cbf23e726368545a5f748965c1", "filename": "src/bootstrap/check.rs", "status": "modified", "additions": 1062, "deletions": 467, "changes": 1529, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcheck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcheck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fcheck.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -25,14 +25,20 @@ use std::io::Read;\n \n use build_helper::{self, output};\n \n-use {Build, Compiler, Mode};\n+use {Build, Mode};\n use dist;\n-use util::{self, dylib_path, dylib_path_var, exe};\n+use util::{self, dylib_path, dylib_path_var};\n+\n+use compile;\n+use native;\n+use builder::{Kind, RunConfig, ShouldRun, Builder, Compiler, Step};\n+use tool::{self, Tool};\n+use cache::{INTERNER, Interned};\n \n const ADB_TEST_DIR: &str = \"/data/tmp/work\";\n \n /// The two modes of the test runner; tests or benchmarks.\n-#[derive(Copy, Clone)]\n+#[derive(Debug, PartialEq, Eq, Hash, Copy, Clone)]\n pub enum TestKind {\n     /// Run `cargo test`\n     Test,\n@@ -81,320 +87,718 @@ fn try_run_quiet(build: &Build, cmd: &mut Command) {\n     }\n }\n \n-/// Runs the `linkchecker` tool as compiled in `stage` by the `host` compiler.\n-///\n-/// This tool in `src/tools` will verify the validity of all our links in the\n-/// documentation to ensure we don't have a bunch of dead ones.\n-pub fn linkcheck(build: &Build, host: &str) {\n-    println!(\"Linkcheck ({})\", host);\n-    let compiler = Compiler::new(0, host);\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Linkcheck {\n+    host: Interned<String>,\n+}\n+\n+impl Step for Linkcheck {\n+    type Output = ();\n+    const ONLY_HOSTS: bool = true;\n+    const DEFAULT: bool = true;\n \n-    let _time = util::timeit();\n-    try_run(build, build.tool_cmd(&compiler, \"linkchecker\")\n-                        .arg(build.out.join(host).join(\"doc\")));\n+    /// Runs the `linkchecker` tool as compiled in `stage` by the `host` compiler.\n+    ///\n+    /// This tool in `src/tools` will verify the validity of all our links in the\n+    /// documentation to ensure we don't have a bunch of dead ones.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let host = self.host;\n+\n+        println!(\"Linkcheck ({})\", host);\n+\n+        builder.default_doc(None);\n+\n+        let _time = util::timeit();\n+        try_run(build, builder.tool_cmd(Tool::Linkchecker)\n+                            .arg(build.out.join(host).join(\"doc\")));\n+    }\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/tools/linkchecker\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Linkcheck { host: run.host });\n+    }\n }\n \n-/// Runs the `cargotest` tool as compiled in `stage` by the `host` compiler.\n-///\n-/// This tool in `src/tools` will check out a few Rust projects and run `cargo\n-/// test` to ensure that we don't regress the test suites there.\n-pub fn cargotest(build: &Build, stage: u32, host: &str) {\n-    let compiler = Compiler::new(stage, host);\n-\n-    // Note that this is a short, cryptic, and not scoped directory name. This\n-    // is currently to minimize the length of path on Windows where we otherwise\n-    // quickly run into path name limit constraints.\n-    let out_dir = build.out.join(\"ct\");\n-    t!(fs::create_dir_all(&out_dir));\n-\n-    let _time = util::timeit();\n-    let mut cmd = Command::new(build.tool(&Compiler::new(0, host), \"cargotest\"));\n-    build.prepare_tool_cmd(&compiler, &mut cmd);\n-    try_run(build, cmd.arg(&build.initial_cargo)\n-                      .arg(&out_dir)\n-                      .env(\"RUSTC\", build.compiler_path(&compiler))\n-                      .env(\"RUSTDOC\", build.rustdoc(&compiler)));\n-}\n-\n-/// Runs `cargo test` for `cargo` packaged with Rust.\n-pub fn cargo(build: &Build, stage: u32, host: &str) {\n-    let compiler = &Compiler::new(stage, host);\n-\n-    let mut cargo = build.cargo(compiler, Mode::Tool, host, \"test\");\n-    cargo.arg(\"--manifest-path\").arg(build.src.join(\"src/tools/cargo/Cargo.toml\"));\n-    if !build.fail_fast {\n-        cargo.arg(\"--no-fail-fast\");\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Cargotest {\n+    stage: u32,\n+    host: Interned<String>,\n+}\n+\n+impl Step for Cargotest {\n+    type Output = ();\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/tools/cargotest\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Cargotest {\n+            stage: run.builder.top_stage,\n+            host: run.host,\n+        });\n+    }\n+\n+    /// Runs the `cargotest` tool as compiled in `stage` by the `host` compiler.\n+    ///\n+    /// This tool in `src/tools` will check out a few Rust projects and run `cargo\n+    /// test` to ensure that we don't regress the test suites there.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = builder.compiler(self.stage, self.host);\n+        builder.ensure(compile::Rustc { compiler, target: compiler.host });\n+\n+        // Note that this is a short, cryptic, and not scoped directory name. This\n+        // is currently to minimize the length of path on Windows where we otherwise\n+        // quickly run into path name limit constraints.\n+        let out_dir = build.out.join(\"ct\");\n+        t!(fs::create_dir_all(&out_dir));\n+\n+        let _time = util::timeit();\n+        let mut cmd = builder.tool_cmd(Tool::CargoTest);\n+        try_run(build, cmd.arg(&build.initial_cargo)\n+                          .arg(&out_dir)\n+                          .env(\"RUSTC\", builder.rustc(compiler))\n+                          .env(\"RUSTDOC\", builder.rustdoc(compiler)));\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Cargo {\n+    stage: u32,\n+    host: Interned<String>,\n+}\n+\n+impl Step for Cargo {\n+    type Output = ();\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/tools/cargo\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Cargo {\n+            stage: run.builder.top_stage,\n+            host: run.target,\n+        });\n     }\n \n-    // Don't build tests dynamically, just a pain to work with\n-    cargo.env(\"RUSTC_NO_PREFER_DYNAMIC\", \"1\");\n+    /// Runs `cargo test` for `cargo` packaged with Rust.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = builder.compiler(self.stage, self.host);\n \n-    // Don't run cross-compile tests, we may not have cross-compiled libstd libs\n-    // available.\n-    cargo.env(\"CFG_DISABLE_CROSS_TESTS\", \"1\");\n+        builder.ensure(tool::Cargo { stage: self.stage, target: self.host });\n+        let mut cargo = builder.cargo(compiler, Mode::Tool, self.host, \"test\");\n+        cargo.arg(\"--manifest-path\").arg(build.src.join(\"src/tools/cargo/Cargo.toml\"));\n+        if !build.fail_fast {\n+            cargo.arg(\"--no-fail-fast\");\n+        }\n+\n+        // Don't build tests dynamically, just a pain to work with\n+        cargo.env(\"RUSTC_NO_PREFER_DYNAMIC\", \"1\");\n+\n+        // Don't run cross-compile tests, we may not have cross-compiled libstd libs\n+        // available.\n+        cargo.env(\"CFG_DISABLE_CROSS_TESTS\", \"1\");\n+\n+        try_run(build, cargo.env(\"PATH\", &path_for_cargo(builder, compiler)));\n+    }\n+}\n \n-    try_run(build, cargo.env(\"PATH\", &path_for_cargo(build, compiler)));\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Rls {\n+    stage: u32,\n+    host: Interned<String>,\n }\n \n-/// Runs `cargo test` for the rls.\n-pub fn rls(build: &Build, stage: u32, host: &str) {\n-    let compiler = &Compiler::new(stage, host);\n+impl Step for Rls {\n+    type Output = ();\n+    const ONLY_HOSTS: bool = true;\n \n-    let mut cargo = build.cargo(compiler, Mode::Tool, host, \"test\");\n-    cargo.arg(\"--manifest-path\").arg(build.src.join(\"src/tools/rls/Cargo.toml\"));\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/tools/rls\")\n+    }\n \n-    // Don't build tests dynamically, just a pain to work with\n-    cargo.env(\"RUSTC_NO_PREFER_DYNAMIC\", \"1\");\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Rls {\n+            stage: run.builder.top_stage,\n+            host: run.target,\n+        });\n+    }\n \n-    build.add_rustc_lib_path(compiler, &mut cargo);\n+    /// Runs `cargo test` for the rls.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let host = self.host;\n+        let compiler = builder.compiler(stage, host);\n \n-    try_run(build, &mut cargo);\n+        builder.ensure(tool::Rls { stage: self.stage, target: self.host });\n+        let mut cargo = builder.cargo(compiler, Mode::Tool, host, \"test\");\n+        cargo.arg(\"--manifest-path\").arg(build.src.join(\"src/tools/rls/Cargo.toml\"));\n+\n+        // Don't build tests dynamically, just a pain to work with\n+        cargo.env(\"RUSTC_NO_PREFER_DYNAMIC\", \"1\");\n+\n+        builder.add_rustc_lib_path(compiler, &mut cargo);\n+\n+        try_run(build, &mut cargo);\n+    }\n }\n \n-fn path_for_cargo(build: &Build, compiler: &Compiler) -> OsString {\n+fn path_for_cargo(builder: &Builder, compiler: Compiler) -> OsString {\n     // Configure PATH to find the right rustc. NB. we have to use PATH\n     // and not RUSTC because the Cargo test suite has tests that will\n     // fail if rustc is not spelled `rustc`.\n-    let path = build.sysroot(compiler).join(\"bin\");\n+    let path = builder.sysroot(compiler).join(\"bin\");\n     let old_path = env::var_os(\"PATH\").unwrap_or_default();\n     env::join_paths(iter::once(path).chain(env::split_paths(&old_path))).expect(\"\")\n }\n \n-/// Runs the `tidy` tool as compiled in `stage` by the `host` compiler.\n-///\n-/// This tool in `src/tools` checks up on various bits and pieces of style and\n-/// otherwise just implements a few lint-like checks that are specific to the\n-/// compiler itself.\n-pub fn tidy(build: &Build, host: &str) {\n-    let _folder = build.fold_output(|| \"tidy\");\n-    println!(\"tidy check ({})\", host);\n-    let compiler = Compiler::new(0, host);\n-    let mut cmd = build.tool_cmd(&compiler, \"tidy\");\n-    cmd.arg(build.src.join(\"src\"));\n-    if !build.config.vendor {\n-        cmd.arg(\"--no-vendor\");\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Tidy {\n+    host: Interned<String>,\n+}\n+\n+impl Step for Tidy {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+    const ONLY_BUILD: bool = true;\n+\n+    /// Runs the `tidy` tool as compiled in `stage` by the `host` compiler.\n+    ///\n+    /// This tool in `src/tools` checks up on various bits and pieces of style and\n+    /// otherwise just implements a few lint-like checks that are specific to the\n+    /// compiler itself.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let host = self.host;\n+\n+        let _folder = build.fold_output(|| \"tidy\");\n+        println!(\"tidy check ({})\", host);\n+        let mut cmd = builder.tool_cmd(Tool::Tidy);\n+        cmd.arg(build.src.join(\"src\"));\n+        if !build.config.vendor {\n+            cmd.arg(\"--no-vendor\");\n+        }\n+        if build.config.quiet_tests {\n+            cmd.arg(\"--quiet\");\n+        }\n+        try_run(build, &mut cmd);\n     }\n-    if build.config.quiet_tests {\n-        cmd.arg(\"--quiet\");\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/tools/tidy\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Tidy {\n+            host: run.builder.build.build,\n+        });\n     }\n-    try_run(build, &mut cmd);\n }\n \n-fn testdir(build: &Build, host: &str) -> PathBuf {\n+fn testdir(build: &Build, host: Interned<String>) -> PathBuf {\n     build.out.join(host).join(\"test\")\n }\n \n-/// Executes the `compiletest` tool to run a suite of tests.\n-///\n-/// Compiles all tests with `compiler` for `target` with the specified\n-/// compiletest `mode` and `suite` arguments. For example `mode` can be\n-/// \"run-pass\" or `suite` can be something like `debuginfo`.\n-pub fn compiletest(build: &Build,\n-                   compiler: &Compiler,\n-                   target: &str,\n-                   mode: &str,\n-                   suite: &str) {\n-    let _folder = build.fold_output(|| format!(\"test_{}\", suite));\n-    println!(\"Check compiletest suite={} mode={} ({} -> {})\",\n-             suite, mode, compiler.host, target);\n-    let mut cmd = Command::new(build.tool(&Compiler::new(0, compiler.host),\n-                                          \"compiletest\"));\n-    build.prepare_tool_cmd(compiler, &mut cmd);\n-\n-    // compiletest currently has... a lot of arguments, so let's just pass all\n-    // of them!\n-\n-    cmd.arg(\"--compile-lib-path\").arg(build.rustc_libdir(compiler));\n-    cmd.arg(\"--run-lib-path\").arg(build.sysroot_libdir(compiler, target));\n-    cmd.arg(\"--rustc-path\").arg(build.compiler_path(compiler));\n-    cmd.arg(\"--rustdoc-path\").arg(build.rustdoc(compiler));\n-    cmd.arg(\"--src-base\").arg(build.src.join(\"src/test\").join(suite));\n-    cmd.arg(\"--build-base\").arg(testdir(build, compiler.host).join(suite));\n-    cmd.arg(\"--stage-id\").arg(format!(\"stage{}-{}\", compiler.stage, target));\n-    cmd.arg(\"--mode\").arg(mode);\n-    cmd.arg(\"--target\").arg(target);\n-    cmd.arg(\"--host\").arg(compiler.host);\n-    cmd.arg(\"--llvm-filecheck\").arg(build.llvm_filecheck(&build.build));\n-\n-    if let Some(ref nodejs) = build.config.nodejs {\n-        cmd.arg(\"--nodejs\").arg(nodejs);\n-    }\n-\n-    let mut flags = vec![\"-Crpath\".to_string()];\n-    if build.config.rust_optimize_tests {\n-        flags.push(\"-O\".to_string());\n-    }\n-    if build.config.rust_debuginfo_tests {\n-        flags.push(\"-g\".to_string());\n-    }\n-\n-    let mut hostflags = build.rustc_flags(&compiler.host);\n-    hostflags.extend(flags.clone());\n-    cmd.arg(\"--host-rustcflags\").arg(hostflags.join(\" \"));\n-\n-    let mut targetflags = build.rustc_flags(&target);\n-    targetflags.extend(flags);\n-    targetflags.push(format!(\"-Lnative={}\",\n-                             build.test_helpers_out(target).display()));\n-    cmd.arg(\"--target-rustcflags\").arg(targetflags.join(\" \"));\n-\n-    cmd.arg(\"--docck-python\").arg(build.python());\n-\n-    if build.build.ends_with(\"apple-darwin\") {\n-        // Force /usr/bin/python on macOS for LLDB tests because we're loading the\n-        // LLDB plugin's compiled module which only works with the system python\n-        // (namely not Homebrew-installed python)\n-        cmd.arg(\"--lldb-python\").arg(\"/usr/bin/python\");\n-    } else {\n-        cmd.arg(\"--lldb-python\").arg(build.python());\n-    }\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+struct Test {\n+    path: &'static str,\n+    mode: &'static str,\n+    suite: &'static str,\n+}\n \n-    if let Some(ref gdb) = build.config.gdb {\n-        cmd.arg(\"--gdb\").arg(gdb);\n-    }\n-    if let Some(ref vers) = build.lldb_version {\n-        cmd.arg(\"--lldb-version\").arg(vers);\n+static DEFAULT_COMPILETESTS: &[Test] = &[\n+    Test { path: \"src/test/ui\", mode: \"ui\", suite: \"ui\" },\n+    Test { path: \"src/test/run-pass\", mode: \"run-pass\", suite: \"run-pass\" },\n+    Test { path: \"src/test/compile-fail\", mode: \"compile-fail\", suite: \"compile-fail\" },\n+    Test { path: \"src/test/parse-fail\", mode: \"parse-fail\", suite: \"parse-fail\" },\n+    Test { path: \"src/test/run-fail\", mode: \"run-fail\", suite: \"run-fail\" },\n+    Test {\n+        path: \"src/test/run-pass-valgrind\",\n+        mode: \"run-pass-valgrind\",\n+        suite: \"run-pass-valgrind\"\n+    },\n+    Test { path: \"src/test/mir-opt\", mode: \"mir-opt\", suite: \"mir-opt\" },\n+    Test { path: \"src/test/codegen\", mode: \"codegen\", suite: \"codegen\" },\n+    Test { path: \"src/test/codegen-units\", mode: \"codegen-units\", suite: \"codegen-units\" },\n+    Test { path: \"src/test/incremental\", mode: \"incremental\", suite: \"incremental\" },\n+\n+    // What this runs varies depending on the native platform being apple\n+    Test { path: \"src/test/debuginfo\", mode: \"debuginfo-XXX\", suite: \"debuginfo\" },\n+];\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct DefaultCompiletest {\n+    compiler: Compiler,\n+    target: Interned<String>,\n+    mode: &'static str,\n+    suite: &'static str,\n+}\n+\n+impl Step for DefaultCompiletest {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(mut run: ShouldRun) -> ShouldRun {\n+        for test in DEFAULT_COMPILETESTS {\n+            run = run.path(test.path);\n+        }\n+        run\n     }\n-    if let Some(ref dir) = build.lldb_python_dir {\n-        cmd.arg(\"--lldb-python-dir\").arg(dir);\n+\n+    fn make_run(run: RunConfig) {\n+        let compiler = run.builder.compiler(run.builder.top_stage, run.host);\n+\n+        let test = run.path.map(|path| {\n+            DEFAULT_COMPILETESTS.iter().find(|&&test| {\n+                path.ends_with(test.path)\n+            }).unwrap_or_else(|| {\n+                panic!(\"make_run in compile test to receive test path, received {:?}\", path);\n+            })\n+        });\n+\n+        if let Some(test) = test {\n+            run.builder.ensure(DefaultCompiletest {\n+                compiler,\n+                target: run.target,\n+                mode: test.mode,\n+                suite: test.suite,\n+            });\n+        } else {\n+            for test in DEFAULT_COMPILETESTS {\n+                run.builder.ensure(DefaultCompiletest {\n+                    compiler,\n+                    target: run.target,\n+                    mode: test.mode,\n+                    suite: test.suite\n+                });\n+            }\n+        }\n     }\n-    let llvm_config = build.llvm_config(target);\n-    let llvm_version = output(Command::new(&llvm_config).arg(\"--version\"));\n-    cmd.arg(\"--llvm-version\").arg(llvm_version);\n-    if !build.is_rust_llvm(target) {\n-        cmd.arg(\"--system-llvm\");\n+\n+    fn run(self, builder: &Builder) {\n+        builder.ensure(Compiletest {\n+            compiler: self.compiler,\n+            target: self.target,\n+            mode: self.mode,\n+            suite: self.suite,\n+        })\n     }\n+}\n \n-    cmd.args(&build.flags.cmd.test_args());\n+// Also default, but host-only.\n+static HOST_COMPILETESTS: &[Test] = &[\n+    Test { path: \"src/test/ui-fulldeps\", mode: \"ui\", suite: \"ui-fulldeps\" },\n+    Test { path: \"src/test/run-pass-fulldeps\", mode: \"run-pass\", suite: \"run-pass-fulldeps\" },\n+    Test { path: \"src/test/run-fail-fulldeps\", mode: \"run-fail\", suite: \"run-fail-fulldeps\" },\n+    Test {\n+        path: \"src/test/compile-fail-fulldeps\",\n+        mode: \"compile-fail\",\n+        suite: \"compile-fail-fulldeps\",\n+    },\n+    Test { path: \"src/test/run-make\", mode: \"run-make\", suite: \"run-make\" },\n+    Test { path: \"src/test/rustdoc\", mode: \"rustdoc\", suite: \"rustdoc\" },\n+\n+    Test { path: \"src/test/pretty\", mode: \"pretty\", suite: \"pretty\" },\n+    Test { path: \"src/test/run-pass/pretty\", mode: \"pretty\", suite: \"run-pass\" },\n+    Test { path: \"src/test/run-fail/pretty\", mode: \"pretty\", suite: \"run-fail\" },\n+    Test { path: \"src/test/run-pass-valgrind/pretty\", mode: \"pretty\", suite: \"run-pass-valgrind\" },\n+    Test { path: \"src/test/run-pass-fulldeps/pretty\", mode: \"pretty\", suite: \"run-pass-fulldeps\" },\n+    Test { path: \"src/test/run-fail-fulldeps/pretty\", mode: \"pretty\", suite: \"run-fail-fulldeps\" },\n+];\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct HostCompiletest {\n+    compiler: Compiler,\n+    target: Interned<String>,\n+    mode: &'static str,\n+    suite: &'static str,\n+}\n \n-    if build.is_verbose() {\n-        cmd.arg(\"--verbose\");\n+impl Step for HostCompiletest {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(mut run: ShouldRun) -> ShouldRun {\n+        for test in HOST_COMPILETESTS {\n+            run = run.path(test.path);\n+        }\n+        run\n     }\n \n-    if build.config.quiet_tests {\n-        cmd.arg(\"--quiet\");\n-    }\n-\n-    // Only pass correct values for these flags for the `run-make` suite as it\n-    // requires that a C++ compiler was configured which isn't always the case.\n-    if suite == \"run-make\" {\n-        let llvm_components = output(Command::new(&llvm_config).arg(\"--components\"));\n-        let llvm_cxxflags = output(Command::new(&llvm_config).arg(\"--cxxflags\"));\n-        cmd.arg(\"--cc\").arg(build.cc(target))\n-           .arg(\"--cxx\").arg(build.cxx(target).unwrap())\n-           .arg(\"--cflags\").arg(build.cflags(target).join(\" \"))\n-           .arg(\"--llvm-components\").arg(llvm_components.trim())\n-           .arg(\"--llvm-cxxflags\").arg(llvm_cxxflags.trim());\n-    } else {\n-        cmd.arg(\"--cc\").arg(\"\")\n-           .arg(\"--cxx\").arg(\"\")\n-           .arg(\"--cflags\").arg(\"\")\n-           .arg(\"--llvm-components\").arg(\"\")\n-           .arg(\"--llvm-cxxflags\").arg(\"\");\n-    }\n-\n-    if build.remote_tested(target) {\n-        cmd.arg(\"--remote-test-client\")\n-           .arg(build.tool(&Compiler::new(0, &build.build),\n-                           \"remote-test-client\"));\n-    }\n-\n-    // Running a C compiler on MSVC requires a few env vars to be set, to be\n-    // sure to set them here.\n-    //\n-    // Note that if we encounter `PATH` we make sure to append to our own `PATH`\n-    // rather than stomp over it.\n-    if target.contains(\"msvc\") {\n-        for &(ref k, ref v) in build.cc[target].0.env() {\n-            if k != \"PATH\" {\n-                cmd.env(k, v);\n+    fn make_run(run: RunConfig) {\n+        let compiler = run.builder.compiler(run.builder.top_stage, run.host);\n+\n+        let test = run.path.map(|path| {\n+            HOST_COMPILETESTS.iter().find(|&&test| {\n+                path.ends_with(test.path)\n+            }).unwrap_or_else(|| {\n+                panic!(\"make_run in compile test to receive test path, received {:?}\", path);\n+            })\n+        });\n+\n+        if let Some(test) = test {\n+            run.builder.ensure(HostCompiletest {\n+                compiler,\n+                target: run.target,\n+                mode: test.mode,\n+                suite: test.suite,\n+            });\n+        } else {\n+            for test in HOST_COMPILETESTS {\n+                run.builder.ensure(HostCompiletest {\n+                    compiler,\n+                    target: run.target,\n+                    mode: test.mode,\n+                    suite: test.suite\n+                });\n             }\n         }\n     }\n-    cmd.env(\"RUSTC_BOOTSTRAP\", \"1\");\n-    build.add_rust_test_threads(&mut cmd);\n \n-    if build.config.sanitizers {\n-        cmd.env(\"SANITIZER_SUPPORT\", \"1\");\n+    fn run(self, builder: &Builder) {\n+        builder.ensure(Compiletest {\n+            compiler: self.compiler,\n+            target: self.target,\n+            mode: self.mode,\n+            suite: self.suite,\n+        })\n     }\n+}\n \n-    if build.config.profiler {\n-        cmd.env(\"PROFILER_SUPPORT\", \"1\");\n-    }\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+struct Compiletest {\n+    compiler: Compiler,\n+    target: Interned<String>,\n+    mode: &'static str,\n+    suite: &'static str,\n+}\n \n-    cmd.arg(\"--adb-path\").arg(\"adb\");\n-    cmd.arg(\"--adb-test-dir\").arg(ADB_TEST_DIR);\n-    if target.contains(\"android\") {\n-        // Assume that cc for this target comes from the android sysroot\n-        cmd.arg(\"--android-cross-path\")\n-           .arg(build.cc(target).parent().unwrap().parent().unwrap());\n-    } else {\n-        cmd.arg(\"--android-cross-path\").arg(\"\");\n+impl Step for Compiletest {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n     }\n \n-    build.ci_env.force_coloring_in_ci(&mut cmd);\n+    /// Executes the `compiletest` tool to run a suite of tests.\n+    ///\n+    /// Compiles all tests with `compiler` for `target` with the specified\n+    /// compiletest `mode` and `suite` arguments. For example `mode` can be\n+    /// \"run-pass\" or `suite` can be something like `debuginfo`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target = self.target;\n+        let mode = self.mode;\n+        let suite = self.suite;\n+\n+        // Skip codegen tests if they aren't enabled in configuration.\n+        if !build.config.codegen_tests && suite == \"codegen\" {\n+            return;\n+        }\n \n-    let _time = util::timeit();\n-    try_run(build, &mut cmd);\n-}\n+        if suite == \"debuginfo\" {\n+            // Skip debuginfo tests on MSVC\n+            if build.build.contains(\"msvc\") {\n+                return;\n+            }\n \n-/// Run `rustdoc --test` for all documentation in `src/doc`.\n-///\n-/// This will run all tests in our markdown documentation (e.g. the book)\n-/// located in `src/doc`. The `rustdoc` that's run is the one that sits next to\n-/// `compiler`.\n-pub fn docs(build: &Build, compiler: &Compiler) {\n-    // Do a breadth-first traversal of the `src/doc` directory and just run\n-    // tests for all files that end in `*.md`\n-    let mut stack = vec![build.src.join(\"src/doc\")];\n-    let _time = util::timeit();\n-    let _folder = build.fold_output(|| \"test_docs\");\n-\n-    while let Some(p) = stack.pop() {\n-        if p.is_dir() {\n-            stack.extend(t!(p.read_dir()).map(|p| t!(p).path()));\n-            continue\n+            if mode == \"debuginfo-XXX\" {\n+                return if build.build.contains(\"apple\") {\n+                    builder.ensure(Compiletest {\n+                        mode: \"debuginfo-lldb\",\n+                        ..self\n+                    });\n+                } else {\n+                    builder.ensure(Compiletest {\n+                        mode: \"debuginfo-gdb\",\n+                        ..self\n+                    });\n+                };\n+            }\n+\n+            builder.ensure(dist::DebuggerScripts {\n+                sysroot: builder.sysroot(compiler),\n+                target: target\n+            });\n+        }\n+\n+        if suite.ends_with(\"fulldeps\") ||\n+            // FIXME: Does pretty need librustc compiled? Note that there are\n+            // fulldeps test suites with mode = pretty as well.\n+            mode == \"pretty\" ||\n+            mode == \"rustdoc\" ||\n+            mode == \"run-make\" {\n+            builder.ensure(compile::Rustc { compiler, target });\n+        }\n+\n+        builder.ensure(compile::Test { compiler, target });\n+        builder.ensure(native::TestHelpers { target });\n+        builder.ensure(RemoteCopyLibs { compiler, target });\n+\n+        let _folder = build.fold_output(|| format!(\"test_{}\", suite));\n+        println!(\"Check compiletest suite={} mode={} ({} -> {})\",\n+                 suite, mode, &compiler.host, target);\n+        let mut cmd = builder.tool_cmd(Tool::Compiletest);\n+\n+        // compiletest currently has... a lot of arguments, so let's just pass all\n+        // of them!\n+\n+        cmd.arg(\"--compile-lib-path\").arg(builder.rustc_libdir(compiler));\n+        cmd.arg(\"--run-lib-path\").arg(builder.sysroot_libdir(compiler, target));\n+        cmd.arg(\"--rustc-path\").arg(builder.rustc(compiler));\n+        cmd.arg(\"--rustdoc-path\").arg(builder.rustdoc(compiler));\n+        cmd.arg(\"--src-base\").arg(build.src.join(\"src/test\").join(suite));\n+        cmd.arg(\"--build-base\").arg(testdir(build, compiler.host).join(suite));\n+        cmd.arg(\"--stage-id\").arg(format!(\"stage{}-{}\", compiler.stage, target));\n+        cmd.arg(\"--mode\").arg(mode);\n+        cmd.arg(\"--target\").arg(target);\n+        cmd.arg(\"--host\").arg(&*compiler.host);\n+        cmd.arg(\"--llvm-filecheck\").arg(build.llvm_filecheck(build.build));\n+\n+        if let Some(ref nodejs) = build.config.nodejs {\n+            cmd.arg(\"--nodejs\").arg(nodejs);\n+        }\n+\n+        let mut flags = vec![\"-Crpath\".to_string()];\n+        if build.config.rust_optimize_tests {\n+            flags.push(\"-O\".to_string());\n+        }\n+        if build.config.rust_debuginfo_tests {\n+            flags.push(\"-g\".to_string());\n+        }\n+\n+        let mut hostflags = build.rustc_flags(compiler.host);\n+        hostflags.extend(flags.clone());\n+        cmd.arg(\"--host-rustcflags\").arg(hostflags.join(\" \"));\n+\n+        let mut targetflags = build.rustc_flags(target);\n+        targetflags.extend(flags);\n+        targetflags.push(format!(\"-Lnative={}\",\n+                                 build.test_helpers_out(target).display()));\n+        cmd.arg(\"--target-rustcflags\").arg(targetflags.join(\" \"));\n+\n+        cmd.arg(\"--docck-python\").arg(build.python());\n+\n+        if build.build.ends_with(\"apple-darwin\") {\n+            // Force /usr/bin/python on macOS for LLDB tests because we're loading the\n+            // LLDB plugin's compiled module which only works with the system python\n+            // (namely not Homebrew-installed python)\n+            cmd.arg(\"--lldb-python\").arg(\"/usr/bin/python\");\n+        } else {\n+            cmd.arg(\"--lldb-python\").arg(build.python());\n+        }\n+\n+        if let Some(ref gdb) = build.config.gdb {\n+            cmd.arg(\"--gdb\").arg(gdb);\n+        }\n+        if let Some(ref vers) = build.lldb_version {\n+            cmd.arg(\"--lldb-version\").arg(vers);\n+        }\n+        if let Some(ref dir) = build.lldb_python_dir {\n+            cmd.arg(\"--lldb-python-dir\").arg(dir);\n+        }\n+        let llvm_config = build.llvm_config(target);\n+        let llvm_version = output(Command::new(&llvm_config).arg(\"--version\"));\n+        cmd.arg(\"--llvm-version\").arg(llvm_version);\n+        if !build.is_rust_llvm(target) {\n+            cmd.arg(\"--system-llvm\");\n+        }\n+\n+        cmd.args(&build.flags.cmd.test_args());\n+\n+        if build.is_verbose() {\n+            cmd.arg(\"--verbose\");\n+        }\n+\n+        if build.config.quiet_tests {\n+            cmd.arg(\"--quiet\");\n+        }\n+\n+        // Only pass correct values for these flags for the `run-make` suite as it\n+        // requires that a C++ compiler was configured which isn't always the case.\n+        if suite == \"run-make\" {\n+            let llvm_components = output(Command::new(&llvm_config).arg(\"--components\"));\n+            let llvm_cxxflags = output(Command::new(&llvm_config).arg(\"--cxxflags\"));\n+            cmd.arg(\"--cc\").arg(build.cc(target))\n+               .arg(\"--cxx\").arg(build.cxx(target).unwrap())\n+               .arg(\"--cflags\").arg(build.cflags(target).join(\" \"))\n+               .arg(\"--llvm-components\").arg(llvm_components.trim())\n+               .arg(\"--llvm-cxxflags\").arg(llvm_cxxflags.trim());\n+        } else {\n+            cmd.arg(\"--cc\").arg(\"\")\n+               .arg(\"--cxx\").arg(\"\")\n+               .arg(\"--cflags\").arg(\"\")\n+               .arg(\"--llvm-components\").arg(\"\")\n+               .arg(\"--llvm-cxxflags\").arg(\"\");\n+        }\n+\n+        if build.remote_tested(target) {\n+            cmd.arg(\"--remote-test-client\").arg(builder.tool_exe(Tool::RemoteTestClient));\n+        }\n+\n+        // Running a C compiler on MSVC requires a few env vars to be set, to be\n+        // sure to set them here.\n+        //\n+        // Note that if we encounter `PATH` we make sure to append to our own `PATH`\n+        // rather than stomp over it.\n+        if target.contains(\"msvc\") {\n+            for &(ref k, ref v) in build.cc[&target].0.env() {\n+                if k != \"PATH\" {\n+                    cmd.env(k, v);\n+                }\n+            }\n+        }\n+        cmd.env(\"RUSTC_BOOTSTRAP\", \"1\");\n+        build.add_rust_test_threads(&mut cmd);\n+\n+        if build.config.sanitizers {\n+            cmd.env(\"SANITIZER_SUPPORT\", \"1\");\n         }\n \n-        if p.extension().and_then(|s| s.to_str()) != Some(\"md\") {\n-            continue;\n+        if build.config.profiler {\n+            cmd.env(\"PROFILER_SUPPORT\", \"1\");\n         }\n \n-        // The nostarch directory in the book is for no starch, and so isn't\n-        // guaranteed to build. We don't care if it doesn't build, so skip it.\n-        if p.to_str().map_or(false, |p| p.contains(\"nostarch\")) {\n-            continue;\n+        cmd.arg(\"--adb-path\").arg(\"adb\");\n+        cmd.arg(\"--adb-test-dir\").arg(ADB_TEST_DIR);\n+        if target.contains(\"android\") {\n+            // Assume that cc for this target comes from the android sysroot\n+            cmd.arg(\"--android-cross-path\")\n+               .arg(build.cc(target).parent().unwrap().parent().unwrap());\n+        } else {\n+            cmd.arg(\"--android-cross-path\").arg(\"\");\n         }\n \n-        markdown_test(build, compiler, &p);\n+        build.ci_env.force_coloring_in_ci(&mut cmd);\n+\n+        let _time = util::timeit();\n+        try_run(build, &mut cmd);\n     }\n }\n \n-/// Run the error index generator tool to execute the tests located in the error\n-/// index.\n-///\n-/// The `error_index_generator` tool lives in `src/tools` and is used to\n-/// generate a markdown file from the error indexes of the code base which is\n-/// then passed to `rustdoc --test`.\n-pub fn error_index(build: &Build, compiler: &Compiler) {\n-    let _folder = build.fold_output(|| \"test_error_index\");\n-    println!(\"Testing error-index stage{}\", compiler.stage);\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Docs {\n+    compiler: Compiler,\n+}\n+\n+impl Step for Docs {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/doc\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Docs {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+        });\n+    }\n+\n+    /// Run `rustdoc --test` for all documentation in `src/doc`.\n+    ///\n+    /// This will run all tests in our markdown documentation (e.g. the book)\n+    /// located in `src/doc`. The `rustdoc` that's run is the one that sits next to\n+    /// `compiler`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+\n+        builder.ensure(compile::Test { compiler, target: compiler.host });\n+\n+        // Do a breadth-first traversal of the `src/doc` directory and just run\n+        // tests for all files that end in `*.md`\n+        let mut stack = vec![build.src.join(\"src/doc\")];\n+        let _time = util::timeit();\n+        let _folder = build.fold_output(|| \"test_docs\");\n+\n+        while let Some(p) = stack.pop() {\n+            if p.is_dir() {\n+                stack.extend(t!(p.read_dir()).map(|p| t!(p).path()));\n+                continue\n+            }\n+\n+            if p.extension().and_then(|s| s.to_str()) != Some(\"md\") {\n+                continue;\n+            }\n+\n+            // The nostarch directory in the book is for no starch, and so isn't\n+            // guaranteed to build. We don't care if it doesn't build, so skip it.\n+            if p.to_str().map_or(false, |p| p.contains(\"nostarch\")) {\n+                continue;\n+            }\n+\n+            markdown_test(builder, compiler, &p);\n+        }\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct ErrorIndex {\n+    compiler: Compiler,\n+}\n+\n+impl Step for ErrorIndex {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/tools/error_index_generator\")\n+    }\n \n-    let dir = testdir(build, compiler.host);\n-    t!(fs::create_dir_all(&dir));\n-    let output = dir.join(\"error-index.md\");\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(ErrorIndex {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+        });\n+    }\n+\n+    /// Run the error index generator tool to execute the tests located in the error\n+    /// index.\n+    ///\n+    /// The `error_index_generator` tool lives in `src/tools` and is used to\n+    /// generate a markdown file from the error indexes of the code base which is\n+    /// then passed to `rustdoc --test`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+\n+        builder.ensure(compile::Std { compiler, target: compiler.host });\n+\n+        let _folder = build.fold_output(|| \"test_error_index\");\n+        println!(\"Testing error-index stage{}\", compiler.stage);\n \n-    let _time = util::timeit();\n-    build.run(build.tool_cmd(&Compiler::new(0, compiler.host),\n-                             \"error_index_generator\")\n-                   .arg(\"markdown\")\n-                   .arg(&output)\n-                   .env(\"CFG_BUILD\", &build.build));\n+        let dir = testdir(build, compiler.host);\n+        t!(fs::create_dir_all(&dir));\n+        let output = dir.join(\"error-index.md\");\n \n-    markdown_test(build, compiler, &output);\n+        let _time = util::timeit();\n+        build.run(builder.tool_cmd(Tool::ErrorIndex)\n+                    .arg(\"markdown\")\n+                    .arg(&output)\n+                    .env(\"CFG_BUILD\", &build.build));\n+\n+        markdown_test(builder, compiler, &output);\n+    }\n }\n \n-fn markdown_test(build: &Build, compiler: &Compiler, markdown: &Path) {\n+fn markdown_test(builder: &Builder, compiler: Compiler, markdown: &Path) {\n+    let build = builder.build;\n     let mut file = t!(File::open(markdown));\n     let mut contents = String::new();\n     t!(file.read_to_string(&mut contents));\n@@ -403,8 +807,8 @@ fn markdown_test(build: &Build, compiler: &Compiler, markdown: &Path) {\n     }\n \n     println!(\"doc tests for: {}\", markdown.display());\n-    let mut cmd = Command::new(build.rustdoc(compiler));\n-    build.add_rustc_lib_path(compiler, &mut cmd);\n+    let mut cmd = Command::new(builder.rustdoc(compiler));\n+    builder.add_rustc_lib_path(compiler, &mut cmd);\n     build.add_rust_test_threads(&mut cmd);\n     cmd.arg(\"--test\");\n     cmd.arg(markdown);\n@@ -420,126 +824,251 @@ fn markdown_test(build: &Build, compiler: &Compiler, markdown: &Path) {\n     }\n }\n \n-/// Run all unit tests plus documentation tests for an entire crate DAG defined\n-/// by a `Cargo.toml`\n-///\n-/// This is what runs tests for crates like the standard library, compiler, etc.\n-/// It essentially is the driver for running `cargo test`.\n-///\n-/// Currently this runs all tests for a DAG by passing a bunch of `-p foo`\n-/// arguments, and those arguments are discovered from `cargo metadata`.\n-pub fn krate(build: &Build,\n-             compiler: &Compiler,\n-             target: &str,\n-             mode: Mode,\n-             test_kind: TestKind,\n-             krate: Option<&str>) {\n-    let (name, path, features, root) = match mode {\n-        Mode::Libstd => {\n-            (\"libstd\", \"src/libstd\", build.std_features(), \"std\")\n-        }\n-        Mode::Libtest => {\n-            (\"libtest\", \"src/libtest\", String::new(), \"test\")\n-        }\n-        Mode::Librustc => {\n-            (\"librustc\", \"src/rustc\", build.rustc_features(), \"rustc-main\")\n-        }\n-        _ => panic!(\"can only test libraries\"),\n-    };\n-    let _folder = build.fold_output(|| {\n-        format!(\"{}_stage{}-{}\", test_kind.subcommand(), compiler.stage, name)\n-    });\n-    println!(\"{} {} stage{} ({} -> {})\", test_kind, name, compiler.stage,\n-             compiler.host, target);\n-\n-    // If we're not doing a full bootstrap but we're testing a stage2 version of\n-    // libstd, then what we're actually testing is the libstd produced in\n-    // stage1. Reflect that here by updating the compiler that we're working\n-    // with automatically.\n-    let compiler = if build.force_use_stage1(compiler, target) {\n-        Compiler::new(1, compiler.host)\n-    } else {\n-        compiler.clone()\n-    };\n-\n-    // Build up the base `cargo test` command.\n-    //\n-    // Pass in some standard flags then iterate over the graph we've discovered\n-    // in `cargo metadata` with the maps above and figure out what `-p`\n-    // arguments need to get passed.\n-    let mut cargo = build.cargo(&compiler, mode, target, test_kind.subcommand());\n-    cargo.arg(\"--manifest-path\")\n-         .arg(build.src.join(path).join(\"Cargo.toml\"))\n-         .arg(\"--features\").arg(features);\n-    if test_kind.subcommand() == \"test\" && !build.fail_fast {\n-        cargo.arg(\"--no-fail-fast\");\n-    }\n-\n-    match krate {\n-        Some(krate) => {\n-            cargo.arg(\"-p\").arg(krate);\n-        }\n-        None => {\n-            let mut visited = HashSet::new();\n-            let mut next = vec![root];\n-            while let Some(name) = next.pop() {\n-                // Right now jemalloc is our only target-specific crate in the\n-                // sense that it's not present on all platforms. Custom skip it\n-                // here for now, but if we add more this probably wants to get\n-                // more generalized.\n-                //\n-                // Also skip `build_helper` as it's not compiled normally for\n-                // target during the bootstrap and it's just meant to be a\n-                // helper crate, not tested. If it leaks through then it ends up\n-                // messing with various mtime calculations and such.\n-                if !name.contains(\"jemalloc\") && name != \"build_helper\" {\n-                    cargo.arg(\"-p\").arg(&format!(\"{}:0.0.0\", name));\n-                }\n-                for dep in build.crates[name].deps.iter() {\n-                    if visited.insert(dep) {\n-                        next.push(dep);\n-                    }\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct CrateLibrustc {\n+    compiler: Compiler,\n+    target: Interned<String>,\n+    test_kind: TestKind,\n+    krate: Option<Interned<String>>,\n+}\n+\n+impl Step for CrateLibrustc {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.krate(\"rustc-main\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        let builder = run.builder;\n+        let compiler = builder.compiler(builder.top_stage, run.host);\n+\n+        let make = |name: Option<Interned<String>>| {\n+            let test_kind = if builder.kind == Kind::Test {\n+                TestKind::Test\n+            } else if builder.kind == Kind::Bench {\n+                TestKind::Bench\n+            } else {\n+                panic!(\"unexpected builder.kind in crate: {:?}\", builder.kind);\n+            };\n+\n+            builder.ensure(CrateLibrustc {\n+                compiler,\n+                target: run.target,\n+                test_kind: test_kind,\n+                krate: name,\n+            });\n+        };\n+\n+        if let Some(path) = run.path {\n+            for (name, krate_path) in builder.crates(\"rustc-main\") {\n+                if path.ends_with(krate_path) {\n+                    make(Some(name));\n                 }\n             }\n+        } else {\n+            make(None);\n         }\n     }\n \n-    // The tests are going to run with the *target* libraries, so we need to\n-    // ensure that those libraries show up in the LD_LIBRARY_PATH equivalent.\n-    //\n-    // Note that to run the compiler we need to run with the *host* libraries,\n-    // but our wrapper scripts arrange for that to be the case anyway.\n-    let mut dylib_path = dylib_path();\n-    dylib_path.insert(0, build.sysroot_libdir(&compiler, target));\n-    cargo.env(dylib_path_var(), env::join_paths(&dylib_path).unwrap());\n \n-    if target.contains(\"emscripten\") || build.remote_tested(target) {\n-        cargo.arg(\"--no-run\");\n+    fn run(self, builder: &Builder) {\n+        builder.ensure(Crate {\n+            compiler: self.compiler,\n+            target: self.target,\n+            mode: Mode::Librustc,\n+            test_kind: self.test_kind,\n+            krate: self.krate,\n+        });\n     }\n+}\n \n-    cargo.arg(\"--\");\n \n-    if build.config.quiet_tests {\n-        cargo.arg(\"--quiet\");\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Crate {\n+    compiler: Compiler,\n+    target: Interned<String>,\n+    mode: Mode,\n+    test_kind: TestKind,\n+    krate: Option<Interned<String>>,\n+}\n+\n+impl Step for Crate {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.krate(\"std\").krate(\"test\")\n     }\n \n-    let _time = util::timeit();\n+    fn make_run(run: RunConfig) {\n+        let builder = run.builder;\n+        let compiler = builder.compiler(builder.top_stage, run.host);\n+\n+        let make = |mode: Mode, name: Option<Interned<String>>| {\n+            let test_kind = if builder.kind == Kind::Test {\n+                TestKind::Test\n+            } else if builder.kind == Kind::Bench {\n+                TestKind::Bench\n+            } else {\n+                panic!(\"unexpected builder.kind in crate: {:?}\", builder.kind);\n+            };\n+\n+            builder.ensure(Crate {\n+                compiler,\n+                target: run.target,\n+                mode: mode,\n+                test_kind: test_kind,\n+                krate: name,\n+            });\n+        };\n+\n+        if let Some(path) = run.path {\n+            for (name, krate_path) in builder.crates(\"std\") {\n+                if path.ends_with(krate_path) {\n+                    make(Mode::Libstd, Some(name));\n+                }\n+            }\n+            for (name, krate_path) in builder.crates(\"test\") {\n+                if path.ends_with(krate_path) {\n+                    make(Mode::Libtest, Some(name));\n+                }\n+            }\n+        } else {\n+            make(Mode::Libstd, None);\n+            make(Mode::Libtest, None);\n+        }\n+    }\n \n-    if target.contains(\"emscripten\") {\n-        build.run(&mut cargo);\n-        krate_emscripten(build, &compiler, target, mode);\n-    } else if build.remote_tested(target) {\n-        build.run(&mut cargo);\n-        krate_remote(build, &compiler, target, mode);\n-    } else {\n-        cargo.args(&build.flags.cmd.test_args());\n-        try_run(build, &mut cargo);\n+    /// Run all unit tests plus documentation tests for an entire crate DAG defined\n+    /// by a `Cargo.toml`\n+    ///\n+    /// This is what runs tests for crates like the standard library, compiler, etc.\n+    /// It essentially is the driver for running `cargo test`.\n+    ///\n+    /// Currently this runs all tests for a DAG by passing a bunch of `-p foo`\n+    /// arguments, and those arguments are discovered from `cargo metadata`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target = self.target;\n+        let mode = self.mode;\n+        let test_kind = self.test_kind;\n+        let krate = self.krate;\n+\n+        builder.ensure(compile::Test { compiler, target });\n+        builder.ensure(RemoteCopyLibs { compiler, target });\n+        let (name, path, features, root) = match mode {\n+            Mode::Libstd => {\n+                (\"libstd\", \"src/libstd\", build.std_features(), \"std\")\n+            }\n+            Mode::Libtest => {\n+                (\"libtest\", \"src/libtest\", String::new(), \"test\")\n+            }\n+            Mode::Librustc => {\n+                builder.ensure(compile::Rustc { compiler, target });\n+                (\"librustc\", \"src/rustc\", build.rustc_features(), \"rustc-main\")\n+            }\n+            _ => panic!(\"can only test libraries\"),\n+        };\n+        let root = INTERNER.intern_string(String::from(root));\n+        let _folder = build.fold_output(|| {\n+            format!(\"{}_stage{}-{}\", test_kind.subcommand(), compiler.stage, name)\n+        });\n+        println!(\"{} {} stage{} ({} -> {})\", test_kind, name, compiler.stage,\n+                &compiler.host, target);\n+\n+        // If we're not doing a full bootstrap but we're testing a stage2 version of\n+        // libstd, then what we're actually testing is the libstd produced in\n+        // stage1. Reflect that here by updating the compiler that we're working\n+        // with automatically.\n+        let compiler = if build.force_use_stage1(compiler, target) {\n+            builder.compiler(1, compiler.host)\n+        } else {\n+            compiler.clone()\n+        };\n+\n+        // Build up the base `cargo test` command.\n+        //\n+        // Pass in some standard flags then iterate over the graph we've discovered\n+        // in `cargo metadata` with the maps above and figure out what `-p`\n+        // arguments need to get passed.\n+        let mut cargo = builder.cargo(compiler, mode, target, test_kind.subcommand());\n+        cargo.arg(\"--manifest-path\")\n+            .arg(build.src.join(path).join(\"Cargo.toml\"))\n+            .arg(\"--features\").arg(features);\n+        if test_kind.subcommand() == \"test\" && !build.fail_fast {\n+            cargo.arg(\"--no-fail-fast\");\n+        }\n+\n+        match krate {\n+            Some(krate) => {\n+                cargo.arg(\"-p\").arg(krate);\n+            }\n+            None => {\n+                let mut visited = HashSet::new();\n+                let mut next = vec![root];\n+                while let Some(name) = next.pop() {\n+                    // Right now jemalloc is our only target-specific crate in the\n+                    // sense that it's not present on all platforms. Custom skip it\n+                    // here for now, but if we add more this probably wants to get\n+                    // more generalized.\n+                    //\n+                    // Also skip `build_helper` as it's not compiled normally for\n+                    // target during the bootstrap and it's just meant to be a\n+                    // helper crate, not tested. If it leaks through then it ends up\n+                    // messing with various mtime calculations and such.\n+                    if !name.contains(\"jemalloc\") && *name != *\"build_helper\" {\n+                        cargo.arg(\"-p\").arg(&format!(\"{}:0.0.0\", name));\n+                    }\n+                    for dep in build.crates[&name].deps.iter() {\n+                        if visited.insert(dep) {\n+                            next.push(*dep);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+        // The tests are going to run with the *target* libraries, so we need to\n+        // ensure that those libraries show up in the LD_LIBRARY_PATH equivalent.\n+        //\n+        // Note that to run the compiler we need to run with the *host* libraries,\n+        // but our wrapper scripts arrange for that to be the case anyway.\n+        let mut dylib_path = dylib_path();\n+        dylib_path.insert(0, PathBuf::from(&*builder.sysroot_libdir(compiler, target)));\n+        cargo.env(dylib_path_var(), env::join_paths(&dylib_path).unwrap());\n+\n+        if target.contains(\"emscripten\") || build.remote_tested(target) {\n+            cargo.arg(\"--no-run\");\n+        }\n+\n+        cargo.arg(\"--\");\n+\n+        if build.config.quiet_tests {\n+            cargo.arg(\"--quiet\");\n+        }\n+\n+        let _time = util::timeit();\n+\n+        if target.contains(\"emscripten\") {\n+            build.run(&mut cargo);\n+            krate_emscripten(build, compiler, target, mode);\n+        } else if build.remote_tested(target) {\n+            build.run(&mut cargo);\n+            krate_remote(builder, compiler, target, mode);\n+        } else {\n+            cargo.args(&build.flags.cmd.test_args());\n+            try_run(build, &mut cargo);\n+        }\n     }\n }\n \n fn krate_emscripten(build: &Build,\n-                    compiler: &Compiler,\n-                    target: &str,\n+                    compiler: Compiler,\n+                    target: Interned<String>,\n                     mode: Mode) {\n     let out_dir = build.cargo_out(compiler, mode, target);\n     let tests = find_tests(&out_dir.join(\"deps\"), target);\n@@ -556,15 +1085,15 @@ fn krate_emscripten(build: &Build,\n     }\n }\n \n-fn krate_remote(build: &Build,\n-                compiler: &Compiler,\n-                target: &str,\n+fn krate_remote(builder: &Builder,\n+                compiler: Compiler,\n+                target: Interned<String>,\n                 mode: Mode) {\n+    let build = builder.build;\n     let out_dir = build.cargo_out(compiler, mode, target);\n     let tests = find_tests(&out_dir.join(\"deps\"), target);\n \n-    let tool = build.tool(&Compiler::new(0, &build.build),\n-                          \"remote-test-client\");\n+    let tool = builder.tool_exe(Tool::RemoteTestClient);\n     for test in tests {\n         let mut cmd = Command::new(&tool);\n         cmd.arg(\"run\")\n@@ -577,7 +1106,7 @@ fn krate_remote(build: &Build,\n     }\n }\n \n-fn find_tests(dir: &Path, target: &str) -> Vec<PathBuf> {\n+fn find_tests(dir: &Path, target: Interned<String>) -> Vec<PathBuf> {\n     let mut dst = Vec::new();\n     for e in t!(dir.read_dir()).map(|e| t!(e)) {\n         let file_type = t!(e.file_type());\n@@ -596,105 +1125,171 @@ fn find_tests(dir: &Path, target: &str) -> Vec<PathBuf> {\n     dst\n }\n \n-pub fn remote_copy_libs(build: &Build, compiler: &Compiler, target: &str) {\n-    if !build.remote_tested(target) {\n-        return\n-    }\n-\n-    println!(\"REMOTE copy libs to emulator ({})\", target);\n-    t!(fs::create_dir_all(build.out.join(\"tmp\")));\n-\n-    let server = build.cargo_out(compiler, Mode::Tool, target)\n-                      .join(exe(\"remote-test-server\", target));\n-\n-    // Spawn the emulator and wait for it to come online\n-    let tool = build.tool(&Compiler::new(0, &build.build),\n-                          \"remote-test-client\");\n-    let mut cmd = Command::new(&tool);\n-    cmd.arg(\"spawn-emulator\")\n-       .arg(target)\n-       .arg(&server)\n-       .arg(build.out.join(\"tmp\"));\n-    if let Some(rootfs) = build.qemu_rootfs(target) {\n-        cmd.arg(rootfs);\n-    }\n-    build.run(&mut cmd);\n-\n-    // Push all our dylibs to the emulator\n-    for f in t!(build.sysroot_libdir(compiler, target).read_dir()) {\n-        let f = t!(f);\n-        let name = f.file_name().into_string().unwrap();\n-        if util::is_dylib(&name) {\n-            build.run(Command::new(&tool)\n-                              .arg(\"push\")\n-                              .arg(f.path()));\n-        }\n-    }\n-}\n-\n-/// Run \"distcheck\", a 'make check' from a tarball\n-pub fn distcheck(build: &Build) {\n-    if build.build != \"x86_64-unknown-linux-gnu\" {\n-        return\n-    }\n-    if !build.config.host.iter().any(|s| s == \"x86_64-unknown-linux-gnu\") {\n-        return\n-    }\n-    if !build.config.target.iter().any(|s| s == \"x86_64-unknown-linux-gnu\") {\n-        return\n-    }\n-\n-    println!(\"Distcheck\");\n-    let dir = build.out.join(\"tmp\").join(\"distcheck\");\n-    let _ = fs::remove_dir_all(&dir);\n-    t!(fs::create_dir_all(&dir));\n-\n-    let mut cmd = Command::new(\"tar\");\n-    cmd.arg(\"-xzf\")\n-       .arg(dist::rust_src_location(build))\n-       .arg(\"--strip-components=1\")\n-       .current_dir(&dir);\n-    build.run(&mut cmd);\n-    build.run(Command::new(\"./configure\")\n-                     .args(&build.config.configure_args)\n-                     .arg(\"--enable-vendor\")\n-                     .current_dir(&dir));\n-    build.run(Command::new(build_helper::make(&build.build))\n-                     .arg(\"check\")\n-                     .current_dir(&dir));\n-\n-    // Now make sure that rust-src has all of libstd's dependencies\n-    println!(\"Distcheck rust-src\");\n-    let dir = build.out.join(\"tmp\").join(\"distcheck-src\");\n-    let _ = fs::remove_dir_all(&dir);\n-    t!(fs::create_dir_all(&dir));\n-\n-    let mut cmd = Command::new(\"tar\");\n-    cmd.arg(\"-xzf\")\n-       .arg(dist::rust_src_installer(build))\n-       .arg(\"--strip-components=1\")\n-       .current_dir(&dir);\n-    build.run(&mut cmd);\n-\n-    let toml = dir.join(\"rust-src/lib/rustlib/src/rust/src/libstd/Cargo.toml\");\n-    build.run(Command::new(&build.initial_cargo)\n-                     .arg(\"generate-lockfile\")\n-                     .arg(\"--manifest-path\")\n-                     .arg(&toml)\n-                     .current_dir(&dir));\n-}\n-\n-/// Test the build system itself\n-pub fn bootstrap(build: &Build) {\n-    let mut cmd = Command::new(&build.initial_cargo);\n-    cmd.arg(\"test\")\n-       .current_dir(build.src.join(\"src/bootstrap\"))\n-       .env(\"CARGO_TARGET_DIR\", build.out.join(\"bootstrap\"))\n-       .env(\"RUSTC_BOOTSTRAP\", \"1\")\n-       .env(\"RUSTC\", &build.initial_rustc);\n-    if !build.fail_fast {\n-        cmd.arg(\"--no-fail-fast\");\n+/// Some test suites are run inside emulators or on remote devices, and most\n+/// of our test binaries are linked dynamically which means we need to ship\n+/// the standard library and such to the emulator ahead of time. This step\n+/// represents this and is a dependency of all test suites.\n+///\n+/// Most of the time this is a noop. For some steps such as shipping data to\n+/// QEMU we have to build our own tools so we've got conditional dependencies\n+/// on those programs as well. Note that the remote test client is built for\n+/// the build target (us) and the server is built for the target.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct RemoteCopyLibs {\n+    compiler: Compiler,\n+    target: Interned<String>,\n+}\n+\n+impl Step for RemoteCopyLibs {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n+    }\n+\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target = self.target;\n+        if !build.remote_tested(target) {\n+            return\n+        }\n+\n+        builder.ensure(compile::Test { compiler, target });\n+\n+        println!(\"REMOTE copy libs to emulator ({})\", target);\n+        t!(fs::create_dir_all(build.out.join(\"tmp\")));\n+\n+        let server = builder.ensure(tool::RemoteTestServer { stage: compiler.stage, target });\n+\n+        // Spawn the emulator and wait for it to come online\n+        let tool = builder.tool_exe(Tool::RemoteTestClient);\n+        let mut cmd = Command::new(&tool);\n+        cmd.arg(\"spawn-emulator\")\n+           .arg(target)\n+           .arg(&server)\n+           .arg(build.out.join(\"tmp\"));\n+        if let Some(rootfs) = build.qemu_rootfs(target) {\n+            cmd.arg(rootfs);\n+        }\n+        build.run(&mut cmd);\n+\n+        // Push all our dylibs to the emulator\n+        for f in t!(builder.sysroot_libdir(compiler, target).read_dir()) {\n+            let f = t!(f);\n+            let name = f.file_name().into_string().unwrap();\n+            if util::is_dylib(&name) {\n+                build.run(Command::new(&tool)\n+                                  .arg(\"push\")\n+                                  .arg(f.path()));\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Distcheck;\n+\n+impl Step for Distcheck {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"distcheck\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Distcheck);\n+    }\n+\n+    /// Run \"distcheck\", a 'make check' from a tarball\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+\n+        if *build.build != *\"x86_64-unknown-linux-gnu\" {\n+            return\n+        }\n+        if !build.config.host.iter().any(|s| s == \"x86_64-unknown-linux-gnu\") {\n+            return\n+        }\n+        if !build.config.target.iter().any(|s| s == \"x86_64-unknown-linux-gnu\") {\n+            return\n+        }\n+\n+        println!(\"Distcheck\");\n+        let dir = build.out.join(\"tmp\").join(\"distcheck\");\n+        let _ = fs::remove_dir_all(&dir);\n+        t!(fs::create_dir_all(&dir));\n+\n+        // Guarantee that these are built before we begin running.\n+        builder.ensure(dist::PlainSourceTarball);\n+        builder.ensure(dist::Src);\n+\n+        let mut cmd = Command::new(\"tar\");\n+        cmd.arg(\"-xzf\")\n+           .arg(builder.ensure(dist::PlainSourceTarball))\n+           .arg(\"--strip-components=1\")\n+           .current_dir(&dir);\n+        build.run(&mut cmd);\n+        build.run(Command::new(\"./configure\")\n+                         .args(&build.config.configure_args)\n+                         .arg(\"--enable-vendor\")\n+                         .current_dir(&dir));\n+        build.run(Command::new(build_helper::make(&build.build))\n+                         .arg(\"check\")\n+                         .current_dir(&dir));\n+\n+        // Now make sure that rust-src has all of libstd's dependencies\n+        println!(\"Distcheck rust-src\");\n+        let dir = build.out.join(\"tmp\").join(\"distcheck-src\");\n+        let _ = fs::remove_dir_all(&dir);\n+        t!(fs::create_dir_all(&dir));\n+\n+        let mut cmd = Command::new(\"tar\");\n+        cmd.arg(\"-xzf\")\n+           .arg(builder.ensure(dist::Src))\n+           .arg(\"--strip-components=1\")\n+           .current_dir(&dir);\n+        build.run(&mut cmd);\n+\n+        let toml = dir.join(\"rust-src/lib/rustlib/src/rust/src/libstd/Cargo.toml\");\n+        build.run(Command::new(&build.initial_cargo)\n+                         .arg(\"generate-lockfile\")\n+                         .arg(\"--manifest-path\")\n+                         .arg(&toml)\n+                         .current_dir(&dir));\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Bootstrap;\n+\n+impl Step for Bootstrap {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+    const ONLY_BUILD: bool = true;\n+\n+    /// Test the build system itself\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let mut cmd = Command::new(&build.initial_cargo);\n+        cmd.arg(\"test\")\n+           .current_dir(build.src.join(\"src/bootstrap\"))\n+           .env(\"CARGO_TARGET_DIR\", build.out.join(\"bootstrap\"))\n+           .env(\"RUSTC_BOOTSTRAP\", \"1\")\n+           .env(\"RUSTC\", &build.initial_rustc);\n+        if !build.fail_fast {\n+            cmd.arg(\"--no-fail-fast\");\n+        }\n+        cmd.arg(\"--\").args(&build.flags.cmd.test_args());\n+        try_run(build, &mut cmd);\n+    }\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/bootstrap\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Bootstrap);\n     }\n-    cmd.arg(\"--\").args(&build.flags.cmd.test_args());\n-    try_run(build, &mut cmd);\n }"}, {"sha": "cbe2be2d26ad712bf6e9f29e473ab17f2f5a994e", "filename": "src/bootstrap/compile.rs", "status": "modified", "additions": 591, "deletions": 339, "changes": 930, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcompile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fcompile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fcompile.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -23,113 +23,181 @@ use std::io::prelude::*;\n use std::path::{Path, PathBuf};\n use std::process::{Command, Stdio};\n use std::str;\n+use std::cmp::min;\n \n use build_helper::{output, mtime, up_to_date};\n use filetime::FileTime;\n-use rustc_serialize::json;\n+use serde_json;\n \n-use channel::GitInfo;\n use util::{exe, libdir, is_dylib, copy};\n use {Build, Compiler, Mode};\n+use native;\n \n-/// Build the standard library.\n-///\n-/// This will build the standard library for a particular stage of the build\n-/// using the `compiler` targeting the `target` architecture. The artifacts\n-/// created will also be linked into the sysroot directory.\n-pub fn std(build: &Build, target: &str, compiler: &Compiler) {\n-    let libdir = build.sysroot_libdir(compiler, target);\n-    t!(fs::create_dir_all(&libdir));\n-\n-    let _folder = build.fold_output(|| format!(\"stage{}-std\", compiler.stage));\n-    println!(\"Building stage{} std artifacts ({} -> {})\", compiler.stage,\n-             compiler.host, target);\n-\n-    let out_dir = build.cargo_out(compiler, Mode::Libstd, target);\n-    build.clear_if_dirty(&out_dir, &build.compiler_path(compiler));\n-    let mut cargo = build.cargo(compiler, Mode::Libstd, target, \"build\");\n-    let mut features = build.std_features();\n-\n-    if let Some(target) = env::var_os(\"MACOSX_STD_DEPLOYMENT_TARGET\") {\n-        cargo.env(\"MACOSX_DEPLOYMENT_TARGET\", target);\n-    }\n-\n-    // When doing a local rebuild we tell cargo that we're stage1 rather than\n-    // stage0. This works fine if the local rust and being-built rust have the\n-    // same view of what the default allocator is, but fails otherwise. Since\n-    // we don't have a way to express an allocator preference yet, work\n-    // around the issue in the case of a local rebuild with jemalloc disabled.\n-    if compiler.stage == 0 && build.local_rebuild && !build.config.use_jemalloc {\n-        features.push_str(\" force_alloc_system\");\n-    }\n-\n-    if compiler.stage != 0 && build.config.sanitizers {\n-        // This variable is used by the sanitizer runtime crates, e.g.\n-        // rustc_lsan, to build the sanitizer runtime from C code\n-        // When this variable is missing, those crates won't compile the C code,\n-        // so we don't set this variable during stage0 where llvm-config is\n-        // missing\n-        // We also only build the runtimes when --enable-sanitizers (or its\n-        // config.toml equivalent) is used\n-        cargo.env(\"LLVM_CONFIG\", build.llvm_config(target));\n+use cache::{INTERNER, Interned};\n+use builder::{Step, RunConfig, ShouldRun, Builder};\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Std {\n+    pub target: Interned<String>,\n+    pub compiler: Compiler,\n+}\n+\n+impl Step for Std {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/libstd\").krate(\"std\")\n     }\n-    cargo.arg(\"--features\").arg(features)\n-         .arg(\"--manifest-path\")\n-         .arg(build.src.join(\"src/libstd/Cargo.toml\"));\n \n-    if let Some(target) = build.config.target_config.get(target) {\n-        if let Some(ref jemalloc) = target.jemalloc {\n-            cargo.env(\"JEMALLOC_OVERRIDE\", jemalloc);\n-        }\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Std {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+            target: run.target,\n+        });\n     }\n-    if target.contains(\"musl\") {\n-        if let Some(p) = build.musl_root(target) {\n-            cargo.env(\"MUSL_ROOT\", p);\n+\n+    /// Build the standard library.\n+    ///\n+    /// This will build the standard library for a particular stage of the build\n+    /// using the `compiler` targeting the `target` architecture. The artifacts\n+    /// created will also be linked into the sysroot directory.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let compiler = self.compiler;\n+\n+        builder.ensure(StartupObjects { compiler, target });\n+\n+        if build.force_use_stage1(compiler, target) {\n+            let from = builder.compiler(1, build.build);\n+            builder.ensure(Std {\n+                compiler: from,\n+                target: target,\n+            });\n+            println!(\"Uplifting stage1 std ({} -> {})\", from.host, target);\n+            builder.ensure(StdLink {\n+                compiler: from,\n+                target_compiler: compiler,\n+                target: target,\n+            });\n+            return;\n+        }\n+\n+        let _folder = build.fold_output(|| format!(\"stage{}-std\", compiler.stage));\n+        println!(\"Building stage{} std artifacts ({} -> {})\", compiler.stage,\n+                &compiler.host, target);\n+\n+        let out_dir = build.cargo_out(compiler, Mode::Libstd, target);\n+        build.clear_if_dirty(&out_dir, &builder.rustc(compiler));\n+        let mut cargo = builder.cargo(compiler, Mode::Libstd, target, \"build\");\n+        let mut features = build.std_features();\n+\n+        if let Some(target) = env::var_os(\"MACOSX_STD_DEPLOYMENT_TARGET\") {\n+            cargo.env(\"MACOSX_DEPLOYMENT_TARGET\", target);\n+        }\n+\n+        // When doing a local rebuild we tell cargo that we're stage1 rather than\n+        // stage0. This works fine if the local rust and being-built rust have the\n+        // same view of what the default allocator is, but fails otherwise. Since\n+        // we don't have a way to express an allocator preference yet, work\n+        // around the issue in the case of a local rebuild with jemalloc disabled.\n+        if compiler.stage == 0 && build.local_rebuild && !build.config.use_jemalloc {\n+            features.push_str(\" force_alloc_system\");\n+        }\n+\n+        if compiler.stage != 0 && build.config.sanitizers {\n+            // This variable is used by the sanitizer runtime crates, e.g.\n+            // rustc_lsan, to build the sanitizer runtime from C code\n+            // When this variable is missing, those crates won't compile the C code,\n+            // so we don't set this variable during stage0 where llvm-config is\n+            // missing\n+            // We also only build the runtimes when --enable-sanitizers (or its\n+            // config.toml equivalent) is used\n+            cargo.env(\"LLVM_CONFIG\", build.llvm_config(target));\n+        }\n+\n+        cargo.arg(\"--features\").arg(features)\n+            .arg(\"--manifest-path\")\n+            .arg(build.src.join(\"src/libstd/Cargo.toml\"));\n+\n+        if let Some(target) = build.config.target_config.get(&target) {\n+            if let Some(ref jemalloc) = target.jemalloc {\n+                cargo.env(\"JEMALLOC_OVERRIDE\", jemalloc);\n+            }\n+        }\n+        if target.contains(\"musl\") {\n+            if let Some(p) = build.musl_root(target) {\n+                cargo.env(\"MUSL_ROOT\", p);\n+            }\n         }\n+\n+        run_cargo(build,\n+                &mut cargo,\n+                &libstd_stamp(build, compiler, target));\n+\n+        builder.ensure(StdLink {\n+            compiler: builder.compiler(compiler.stage, build.build),\n+            target_compiler: compiler,\n+            target: target,\n+        });\n     }\n+}\n \n-    run_cargo(build,\n-              &mut cargo,\n-              &libstd_stamp(build, &compiler, target));\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+struct StdLink {\n+    pub compiler: Compiler,\n+    pub target_compiler: Compiler,\n+    pub target: Interned<String>,\n }\n \n-/// Link all libstd rlibs/dylibs into the sysroot location.\n-///\n-/// Links those artifacts generated by `compiler` to a the `stage` compiler's\n-/// sysroot for the specified `host` and `target`.\n-///\n-/// Note that this assumes that `compiler` has already generated the libstd\n-/// libraries for `target`, and this method will find them in the relevant\n-/// output directory.\n-pub fn std_link(build: &Build,\n-                compiler: &Compiler,\n-                target_compiler: &Compiler,\n-                target: &str) {\n-    println!(\"Copying stage{} std from stage{} ({} -> {} / {})\",\n-             target_compiler.stage,\n-             compiler.stage,\n-             compiler.host,\n-             target_compiler.host,\n-             target);\n-    let libdir = build.sysroot_libdir(target_compiler, target);\n-    add_to_sysroot(&libdir, &libstd_stamp(build, compiler, target));\n-\n-    if target.contains(\"musl\") && !target.contains(\"mips\") {\n-        copy_musl_third_party_objects(build, target, &libdir);\n-    }\n-\n-    if build.config.sanitizers && compiler.stage != 0 && target == \"x86_64-apple-darwin\" {\n-        // The sanitizers are only built in stage1 or above, so the dylibs will\n-        // be missing in stage0 and causes panic. See the `std()` function above\n-        // for reason why the sanitizers are not built in stage0.\n-        copy_apple_sanitizer_dylibs(&build.native_dir(target), \"osx\", &libdir);\n+impl Step for StdLink {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n+    }\n+\n+    /// Link all libstd rlibs/dylibs into the sysroot location.\n+    ///\n+    /// Links those artifacts generated by `compiler` to a the `stage` compiler's\n+    /// sysroot for the specified `host` and `target`.\n+    ///\n+    /// Note that this assumes that `compiler` has already generated the libstd\n+    /// libraries for `target`, and this method will find them in the relevant\n+    /// output directory.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target_compiler = self.target_compiler;\n+        let target = self.target;\n+        println!(\"Copying stage{} std from stage{} ({} -> {} / {})\",\n+                target_compiler.stage,\n+                compiler.stage,\n+                &compiler.host,\n+                target_compiler.host,\n+                target);\n+        let libdir = builder.sysroot_libdir(target_compiler, target);\n+        add_to_sysroot(&libdir, &libstd_stamp(build, compiler, target));\n+\n+        if target.contains(\"musl\") && !target.contains(\"mips\") {\n+            copy_musl_third_party_objects(build, target, &libdir);\n+        }\n+\n+        if build.config.sanitizers && compiler.stage != 0 && target == \"x86_64-apple-darwin\" {\n+            // The sanitizers are only built in stage1 or above, so the dylibs will\n+            // be missing in stage0 and causes panic. See the `std()` function above\n+            // for reason why the sanitizers are not built in stage0.\n+            copy_apple_sanitizer_dylibs(&build.native_dir(target), \"osx\", &libdir);\n+        }\n     }\n }\n \n /// Copies the crt(1,i,n).o startup objects\n ///\n /// Only required for musl targets that statically link to libc\n-fn copy_musl_third_party_objects(build: &Build, target: &str, into: &Path) {\n+fn copy_musl_third_party_objects(build: &Build, target: Interned<String>, into: &Path) {\n     for &obj in &[\"crt1.o\", \"crti.o\", \"crtn.o\"] {\n         copy(&build.musl_root(target).unwrap().join(\"lib\").join(obj), &into.join(obj));\n     }\n@@ -147,192 +215,353 @@ fn copy_apple_sanitizer_dylibs(native_dir: &Path, platform: &str, into: &Path) {\n     }\n }\n \n-/// Build and prepare startup objects like rsbegin.o and rsend.o\n-///\n-/// These are primarily used on Windows right now for linking executables/dlls.\n-/// They don't require any library support as they're just plain old object\n-/// files, so we just use the nightly snapshot compiler to always build them (as\n-/// no other compilers are guaranteed to be available).\n-pub fn build_startup_objects(build: &Build, for_compiler: &Compiler, target: &str) {\n-    if !target.contains(\"pc-windows-gnu\") {\n-        return\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct StartupObjects {\n+    pub compiler: Compiler,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for StartupObjects {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/rtstartup\")\n     }\n \n-    let compiler = Compiler::new(0, &build.build);\n-    let compiler_path = build.compiler_path(&compiler);\n-    let src_dir = &build.src.join(\"src/rtstartup\");\n-    let dst_dir = &build.native_dir(target).join(\"rtstartup\");\n-    let sysroot_dir = &build.sysroot_libdir(for_compiler, target);\n-    t!(fs::create_dir_all(dst_dir));\n-    t!(fs::create_dir_all(sysroot_dir));\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(StartupObjects {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+            target: run.target,\n+        });\n+    }\n \n-    for file in &[\"rsbegin\", \"rsend\"] {\n-        let src_file = &src_dir.join(file.to_string() + \".rs\");\n-        let dst_file = &dst_dir.join(file.to_string() + \".o\");\n-        if !up_to_date(src_file, dst_file) {\n-            let mut cmd = Command::new(&compiler_path);\n-            build.run(cmd.env(\"RUSTC_BOOTSTRAP\", \"1\")\n-                        .arg(\"--cfg\").arg(format!(\"stage{}\", compiler.stage))\n-                        .arg(\"--target\").arg(target)\n-                        .arg(\"--emit=obj\")\n-                        .arg(\"--out-dir\").arg(dst_dir)\n-                        .arg(src_file));\n+    /// Build and prepare startup objects like rsbegin.o and rsend.o\n+    ///\n+    /// These are primarily used on Windows right now for linking executables/dlls.\n+    /// They don't require any library support as they're just plain old object\n+    /// files, so we just use the nightly snapshot compiler to always build them (as\n+    /// no other compilers are guaranteed to be available).\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let for_compiler = self.compiler;\n+        let target = self.target;\n+        if !target.contains(\"pc-windows-gnu\") {\n+            return\n         }\n \n-        copy(dst_file, &sysroot_dir.join(file.to_string() + \".o\"));\n-    }\n+        let src_dir = &build.src.join(\"src/rtstartup\");\n+        let dst_dir = &build.native_dir(target).join(\"rtstartup\");\n+        let sysroot_dir = &builder.sysroot_libdir(for_compiler, target);\n+        t!(fs::create_dir_all(dst_dir));\n+\n+        for file in &[\"rsbegin\", \"rsend\"] {\n+            let src_file = &src_dir.join(file.to_string() + \".rs\");\n+            let dst_file = &dst_dir.join(file.to_string() + \".o\");\n+            if !up_to_date(src_file, dst_file) {\n+                let mut cmd = Command::new(&build.initial_rustc);\n+                build.run(cmd.env(\"RUSTC_BOOTSTRAP\", \"1\")\n+                            .arg(\"--cfg\").arg(\"stage0\")\n+                            .arg(\"--target\").arg(target)\n+                            .arg(\"--emit=obj\")\n+                            .arg(\"-o\").arg(dst_file)\n+                            .arg(src_file));\n+            }\n+\n+            copy(dst_file, &sysroot_dir.join(file.to_string() + \".o\"));\n+        }\n \n-    for obj in [\"crt2.o\", \"dllcrt2.o\"].iter() {\n-        copy(&compiler_file(build.cc(target), obj), &sysroot_dir.join(obj));\n+        for obj in [\"crt2.o\", \"dllcrt2.o\"].iter() {\n+            copy(&compiler_file(build.cc(target), obj), &sysroot_dir.join(obj));\n+        }\n     }\n }\n \n-/// Build libtest.\n-///\n-/// This will build libtest and supporting libraries for a particular stage of\n-/// the build using the `compiler` targeting the `target` architecture. The\n-/// artifacts created will also be linked into the sysroot directory.\n-pub fn test(build: &Build, target: &str, compiler: &Compiler) {\n-    let _folder = build.fold_output(|| format!(\"stage{}-test\", compiler.stage));\n-    println!(\"Building stage{} test artifacts ({} -> {})\", compiler.stage,\n-             compiler.host, target);\n-    let out_dir = build.cargo_out(compiler, Mode::Libtest, target);\n-    build.clear_if_dirty(&out_dir, &libstd_stamp(build, compiler, target));\n-    let mut cargo = build.cargo(compiler, Mode::Libtest, target, \"build\");\n-    if let Some(target) = env::var_os(\"MACOSX_STD_DEPLOYMENT_TARGET\") {\n-        cargo.env(\"MACOSX_DEPLOYMENT_TARGET\", target);\n-    }\n-    cargo.arg(\"--manifest-path\")\n-         .arg(build.src.join(\"src/libtest/Cargo.toml\"));\n-    run_cargo(build,\n-              &mut cargo,\n-              &libtest_stamp(build, compiler, target));\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Test {\n+    pub compiler: Compiler,\n+    pub target: Interned<String>,\n }\n \n-/// Same as `std_link`, only for libtest\n-pub fn test_link(build: &Build,\n-                 compiler: &Compiler,\n-                 target_compiler: &Compiler,\n-                 target: &str) {\n-    println!(\"Copying stage{} test from stage{} ({} -> {} / {})\",\n-             target_compiler.stage,\n-             compiler.stage,\n-             compiler.host,\n-             target_compiler.host,\n-             target);\n-    add_to_sysroot(&build.sysroot_libdir(target_compiler, target),\n-                   &libtest_stamp(build, compiler, target));\n-}\n+impl Step for Test {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n \n-/// Build the compiler.\n-///\n-/// This will build the compiler for a particular stage of the build using\n-/// the `compiler` targeting the `target` architecture. The artifacts\n-/// created will also be linked into the sysroot directory.\n-pub fn rustc(build: &Build, target: &str, compiler: &Compiler) {\n-    let _folder = build.fold_output(|| format!(\"stage{}-rustc\", compiler.stage));\n-    println!(\"Building stage{} compiler artifacts ({} -> {})\",\n-             compiler.stage, compiler.host, target);\n-\n-    let out_dir = build.cargo_out(compiler, Mode::Librustc, target);\n-    build.clear_if_dirty(&out_dir, &libtest_stamp(build, compiler, target));\n-\n-    let mut cargo = build.cargo(compiler, Mode::Librustc, target, \"build\");\n-    cargo.arg(\"--features\").arg(build.rustc_features())\n-         .arg(\"--manifest-path\")\n-         .arg(build.src.join(\"src/rustc/Cargo.toml\"));\n-\n-    // Set some configuration variables picked up by build scripts and\n-    // the compiler alike\n-    cargo.env(\"CFG_RELEASE\", build.rust_release())\n-         .env(\"CFG_RELEASE_CHANNEL\", &build.config.channel)\n-         .env(\"CFG_VERSION\", build.rust_version())\n-         .env(\"CFG_PREFIX\", build.config.prefix.clone().unwrap_or_default());\n-\n-    if compiler.stage == 0 {\n-        cargo.env(\"CFG_LIBDIR_RELATIVE\", \"lib\");\n-    } else {\n-        let libdir_relative = build.config.libdir_relative.clone().unwrap_or(PathBuf::from(\"lib\"));\n-        cargo.env(\"CFG_LIBDIR_RELATIVE\", libdir_relative);\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/libtest\").krate(\"test\")\n     }\n \n-    // If we're not building a compiler with debugging information then remove\n-    // these two env vars which would be set otherwise.\n-    if build.config.rust_debuginfo_only_std {\n-        cargo.env_remove(\"RUSTC_DEBUGINFO\");\n-        cargo.env_remove(\"RUSTC_DEBUGINFO_LINES\");\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Test {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+            target: run.target,\n+        });\n     }\n \n-    if let Some(ref ver_date) = build.rust_info.commit_date() {\n-        cargo.env(\"CFG_VER_DATE\", ver_date);\n-    }\n-    if let Some(ref ver_hash) = build.rust_info.sha() {\n-        cargo.env(\"CFG_VER_HASH\", ver_hash);\n-    }\n-    if !build.unstable_features() {\n-        cargo.env(\"CFG_DISABLE_UNSTABLE_FEATURES\", \"1\");\n-    }\n-    // Flag that rust llvm is in use\n-    if build.is_rust_llvm(target) {\n-        cargo.env(\"LLVM_RUSTLLVM\", \"1\");\n+    /// Build libtest.\n+    ///\n+    /// This will build libtest and supporting libraries for a particular stage of\n+    /// the build using the `compiler` targeting the `target` architecture. The\n+    /// artifacts created will also be linked into the sysroot directory.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let compiler = self.compiler;\n+\n+        builder.ensure(Std { compiler, target });\n+\n+        if build.force_use_stage1(compiler, target) {\n+            builder.ensure(Test {\n+                compiler: builder.compiler(1, build.build),\n+                target: target,\n+            });\n+            println!(\"Uplifting stage1 test ({} -> {})\", &build.build, target);\n+            builder.ensure(TestLink {\n+                compiler: builder.compiler(1, build.build),\n+                target_compiler: compiler,\n+                target: target,\n+            });\n+            return;\n+        }\n+\n+        let _folder = build.fold_output(|| format!(\"stage{}-test\", compiler.stage));\n+        println!(\"Building stage{} test artifacts ({} -> {})\", compiler.stage,\n+                &compiler.host, target);\n+        let out_dir = build.cargo_out(compiler, Mode::Libtest, target);\n+        build.clear_if_dirty(&out_dir, &libstd_stamp(build, compiler, target));\n+        let mut cargo = builder.cargo(compiler, Mode::Libtest, target, \"build\");\n+        if let Some(target) = env::var_os(\"MACOSX_STD_DEPLOYMENT_TARGET\") {\n+            cargo.env(\"MACOSX_DEPLOYMENT_TARGET\", target);\n+        }\n+        cargo.arg(\"--manifest-path\")\n+            .arg(build.src.join(\"src/libtest/Cargo.toml\"));\n+        run_cargo(build,\n+                &mut cargo,\n+                &libtest_stamp(build, compiler, target));\n+\n+        builder.ensure(TestLink {\n+            compiler: builder.compiler(compiler.stage, build.build),\n+            target_compiler: compiler,\n+            target: target,\n+        });\n     }\n-    cargo.env(\"LLVM_CONFIG\", build.llvm_config(target));\n-    let target_config = build.config.target_config.get(target);\n-    if let Some(s) = target_config.and_then(|c| c.llvm_config.as_ref()) {\n-        cargo.env(\"CFG_LLVM_ROOT\", s);\n+}\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct TestLink {\n+    pub compiler: Compiler,\n+    pub target_compiler: Compiler,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for TestLink {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n     }\n-    // Building with a static libstdc++ is only supported on linux right now,\n-    // not for MSVC or macOS\n-    if build.config.llvm_static_stdcpp &&\n-       !target.contains(\"windows\") &&\n-       !target.contains(\"apple\") {\n-        cargo.env(\"LLVM_STATIC_STDCPP\",\n-                  compiler_file(build.cxx(target).unwrap(), \"libstdc++.a\"));\n+\n+    /// Same as `std_link`, only for libtest\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target_compiler = self.target_compiler;\n+        let target = self.target;\n+        println!(\"Copying stage{} test from stage{} ({} -> {} / {})\",\n+                target_compiler.stage,\n+                compiler.stage,\n+                &compiler.host,\n+                target_compiler.host,\n+                target);\n+        add_to_sysroot(&builder.sysroot_libdir(target_compiler, target),\n+                    &libtest_stamp(build, compiler, target));\n     }\n-    if build.config.llvm_link_shared {\n-        cargo.env(\"LLVM_LINK_SHARED\", \"1\");\n+}\n+\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Rustc {\n+    pub compiler: Compiler,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Rustc {\n+    type Output = ();\n+    const ONLY_HOSTS: bool = true;\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/librustc\").krate(\"rustc-main\")\n     }\n-    if let Some(ref s) = build.config.rustc_default_linker {\n-        cargo.env(\"CFG_DEFAULT_LINKER\", s);\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Rustc {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+            target: run.target,\n+        });\n     }\n-    if let Some(ref s) = build.config.rustc_default_ar {\n-        cargo.env(\"CFG_DEFAULT_AR\", s);\n+\n+    /// Build the compiler.\n+    ///\n+    /// This will build the compiler for a particular stage of the build using\n+    /// the `compiler` targeting the `target` architecture. The artifacts\n+    /// created will also be linked into the sysroot directory.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target = self.target;\n+\n+        builder.ensure(Test { compiler, target });\n+\n+        // Build LLVM for our target. This will implicitly build the host LLVM\n+        // if necessary.\n+        builder.ensure(native::Llvm { target });\n+\n+        if build.force_use_stage1(compiler, target) {\n+            builder.ensure(Rustc {\n+                compiler: builder.compiler(1, build.build),\n+                target: target,\n+            });\n+            println!(\"Uplifting stage1 rustc ({} -> {})\", &build.build, target);\n+            builder.ensure(RustcLink {\n+                compiler: builder.compiler(1, build.build),\n+                target_compiler: compiler,\n+                target,\n+            });\n+            return;\n+        }\n+\n+        // Ensure that build scripts have a std to link against.\n+        builder.ensure(Std {\n+            compiler: builder.compiler(self.compiler.stage, build.build),\n+            target: build.build,\n+        });\n+\n+        let _folder = build.fold_output(|| format!(\"stage{}-rustc\", compiler.stage));\n+        println!(\"Building stage{} compiler artifacts ({} -> {})\",\n+                 compiler.stage, &compiler.host, target);\n+\n+        let out_dir = build.cargo_out(compiler, Mode::Librustc, target);\n+        build.clear_if_dirty(&out_dir, &libtest_stamp(build, compiler, target));\n+\n+        let mut cargo = builder.cargo(compiler, Mode::Librustc, target, \"build\");\n+        cargo.arg(\"--features\").arg(build.rustc_features())\n+             .arg(\"--manifest-path\")\n+             .arg(build.src.join(\"src/rustc/Cargo.toml\"));\n+\n+        // Set some configuration variables picked up by build scripts and\n+        // the compiler alike\n+        cargo.env(\"CFG_RELEASE\", build.rust_release())\n+             .env(\"CFG_RELEASE_CHANNEL\", &build.config.channel)\n+             .env(\"CFG_VERSION\", build.rust_version())\n+             .env(\"CFG_PREFIX\", build.config.prefix.clone().unwrap_or_default());\n+\n+        if compiler.stage == 0 {\n+            cargo.env(\"CFG_LIBDIR_RELATIVE\", \"lib\");\n+        } else {\n+            let libdir_relative =\n+                build.config.libdir_relative.clone().unwrap_or(PathBuf::from(\"lib\"));\n+            cargo.env(\"CFG_LIBDIR_RELATIVE\", libdir_relative);\n+        }\n+\n+        // If we're not building a compiler with debugging information then remove\n+        // these two env vars which would be set otherwise.\n+        if build.config.rust_debuginfo_only_std {\n+            cargo.env_remove(\"RUSTC_DEBUGINFO\");\n+            cargo.env_remove(\"RUSTC_DEBUGINFO_LINES\");\n+        }\n+\n+        if let Some(ref ver_date) = build.rust_info.commit_date() {\n+            cargo.env(\"CFG_VER_DATE\", ver_date);\n+        }\n+        if let Some(ref ver_hash) = build.rust_info.sha() {\n+            cargo.env(\"CFG_VER_HASH\", ver_hash);\n+        }\n+        if !build.unstable_features() {\n+            cargo.env(\"CFG_DISABLE_UNSTABLE_FEATURES\", \"1\");\n+        }\n+        // Flag that rust llvm is in use\n+        if build.is_rust_llvm(target) {\n+            cargo.env(\"LLVM_RUSTLLVM\", \"1\");\n+        }\n+        cargo.env(\"LLVM_CONFIG\", build.llvm_config(target));\n+        let target_config = build.config.target_config.get(&target);\n+        if let Some(s) = target_config.and_then(|c| c.llvm_config.as_ref()) {\n+            cargo.env(\"CFG_LLVM_ROOT\", s);\n+        }\n+        // Building with a static libstdc++ is only supported on linux right now,\n+        // not for MSVC or macOS\n+        if build.config.llvm_static_stdcpp &&\n+           !target.contains(\"windows\") &&\n+           !target.contains(\"apple\") {\n+            cargo.env(\"LLVM_STATIC_STDCPP\",\n+                      compiler_file(build.cxx(target).unwrap(), \"libstdc++.a\"));\n+        }\n+        if build.config.llvm_link_shared {\n+            cargo.env(\"LLVM_LINK_SHARED\", \"1\");\n+        }\n+        if let Some(ref s) = build.config.rustc_default_linker {\n+            cargo.env(\"CFG_DEFAULT_LINKER\", s);\n+        }\n+        if let Some(ref s) = build.config.rustc_default_ar {\n+            cargo.env(\"CFG_DEFAULT_AR\", s);\n+        }\n+        run_cargo(build,\n+                  &mut cargo,\n+                  &librustc_stamp(build, compiler, target));\n+\n+        builder.ensure(RustcLink {\n+            compiler: builder.compiler(compiler.stage, build.build),\n+            target_compiler: compiler,\n+            target,\n+        });\n     }\n-    run_cargo(build,\n-              &mut cargo,\n-              &librustc_stamp(build, compiler, target));\n }\n \n-/// Same as `std_link`, only for librustc\n-pub fn rustc_link(build: &Build,\n-                  compiler: &Compiler,\n-                  target_compiler: &Compiler,\n-                  target: &str) {\n-    println!(\"Copying stage{} rustc from stage{} ({} -> {} / {})\",\n-             target_compiler.stage,\n-             compiler.stage,\n-             compiler.host,\n-             target_compiler.host,\n-             target);\n-    add_to_sysroot(&build.sysroot_libdir(target_compiler, target),\n-                   &librustc_stamp(build, compiler, target));\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+struct RustcLink {\n+    pub compiler: Compiler,\n+    pub target_compiler: Compiler,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for RustcLink {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n+    }\n+\n+    /// Same as `std_link`, only for librustc\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target_compiler = self.target_compiler;\n+        let target = self.target;\n+        println!(\"Copying stage{} rustc from stage{} ({} -> {} / {})\",\n+                 target_compiler.stage,\n+                 compiler.stage,\n+                 &compiler.host,\n+                 target_compiler.host,\n+                 target);\n+        add_to_sysroot(&builder.sysroot_libdir(target_compiler, target),\n+                       &librustc_stamp(build, compiler, target));\n+    }\n }\n \n /// Cargo's output path for the standard library in a given stage, compiled\n /// by a particular compiler for the specified target.\n-fn libstd_stamp(build: &Build, compiler: &Compiler, target: &str) -> PathBuf {\n+pub fn libstd_stamp(build: &Build, compiler: Compiler, target: Interned<String>) -> PathBuf {\n     build.cargo_out(compiler, Mode::Libstd, target).join(\".libstd.stamp\")\n }\n \n /// Cargo's output path for libtest in a given stage, compiled by a particular\n /// compiler for the specified target.\n-fn libtest_stamp(build: &Build, compiler: &Compiler, target: &str) -> PathBuf {\n+pub fn libtest_stamp(build: &Build, compiler: Compiler, target: Interned<String>) -> PathBuf {\n     build.cargo_out(compiler, Mode::Libtest, target).join(\".libtest.stamp\")\n }\n \n /// Cargo's output path for librustc in a given stage, compiled by a particular\n /// compiler for the specified target.\n-fn librustc_stamp(build: &Build, compiler: &Compiler, target: &str) -> PathBuf {\n+pub fn librustc_stamp(build: &Build, compiler: Compiler, target: Interned<String>) -> PathBuf {\n     build.cargo_out(compiler, Mode::Librustc, target).join(\".librustc.stamp\")\n }\n \n@@ -342,60 +571,141 @@ fn compiler_file(compiler: &Path, file: &str) -> PathBuf {\n     PathBuf::from(out.trim())\n }\n \n-pub fn create_sysroot(build: &Build, compiler: &Compiler) {\n-    let sysroot = build.sysroot(compiler);\n-    let _ = fs::remove_dir_all(&sysroot);\n-    t!(fs::create_dir_all(&sysroot));\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Sysroot {\n+    pub compiler: Compiler,\n }\n \n-/// Prepare a new compiler from the artifacts in `stage`\n-///\n-/// This will assemble a compiler in `build/$host/stage$stage`. The compiler\n-/// must have been previously produced by the `stage - 1` build.build\n-/// compiler.\n-pub fn assemble_rustc(build: &Build, stage: u32, host: &str) {\n-    // nothing to do in stage0\n-    if stage == 0 {\n-        return\n+impl Step for Sysroot {\n+    type Output = Interned<PathBuf>;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n     }\n \n-    println!(\"Copying stage{} compiler ({})\", stage, host);\n+    /// Returns the sysroot for the `compiler` specified that *this build system\n+    /// generates*.\n+    ///\n+    /// That is, the sysroot for the stage0 compiler is not what the compiler\n+    /// thinks it is by default, but it's the same as the default for stages\n+    /// 1-3.\n+    fn run(self, builder: &Builder) -> Interned<PathBuf> {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let sysroot = if compiler.stage == 0 {\n+            build.out.join(&compiler.host).join(\"stage0-sysroot\")\n+        } else {\n+            build.out.join(&compiler.host).join(format!(\"stage{}\", compiler.stage))\n+        };\n+        let _ = fs::remove_dir_all(&sysroot);\n+        t!(fs::create_dir_all(&sysroot));\n+        INTERNER.intern_path(sysroot)\n+    }\n+}\n \n-    // The compiler that we're assembling\n-    let target_compiler = Compiler::new(stage, host);\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct Assemble {\n+    /// The compiler which we will produce in this step. Assemble itself will\n+    /// take care of ensuring that the necessary prerequisites to do so exist,\n+    /// that is, this target can be a stage2 compiler and Assemble will build\n+    /// previous stages for you.\n+    pub target_compiler: Compiler,\n+}\n \n-    // The compiler that compiled the compiler we're assembling\n-    let build_compiler = Compiler::new(stage - 1, &build.build);\n+impl Step for Assemble {\n+    type Output = Compiler;\n \n-    // Link in all dylibs to the libdir\n-    let sysroot = build.sysroot(&target_compiler);\n-    let sysroot_libdir = sysroot.join(libdir(host));\n-    t!(fs::create_dir_all(&sysroot_libdir));\n-    let src_libdir = build.sysroot_libdir(&build_compiler, host);\n-    for f in t!(fs::read_dir(&src_libdir)).map(|f| t!(f)) {\n-        let filename = f.file_name().into_string().unwrap();\n-        if is_dylib(&filename) {\n-            copy(&f.path(), &sysroot_libdir.join(&filename));\n-        }\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/rustc\")\n     }\n \n-    let out_dir = build.cargo_out(&build_compiler, Mode::Librustc, host);\n+    /// Prepare a new compiler from the artifacts in `stage`\n+    ///\n+    /// This will assemble a compiler in `build/$host/stage$stage`. The compiler\n+    /// must have been previously produced by the `stage - 1` build.build\n+    /// compiler.\n+    fn run(self, builder: &Builder) -> Compiler {\n+        let build = builder.build;\n+        let target_compiler = self.target_compiler;\n+\n+        if target_compiler.stage == 0 {\n+            assert_eq!(build.build, target_compiler.host,\n+                \"Cannot obtain compiler for non-native build triple at stage 0\");\n+            // The stage 0 compiler for the build triple is always pre-built.\n+            return target_compiler;\n+        }\n+\n+        // Get the compiler that we'll use to bootstrap ourselves.\n+        let build_compiler = if target_compiler.host != build.build {\n+            // Build a compiler for the host platform. We cannot use the stage0\n+            // compiler for the host platform for this because it doesn't have\n+            // the libraries we need.  FIXME: Perhaps we should download those\n+            // libraries? It would make builds faster...\n+            // FIXME: It may be faster if we build just a stage 1\n+            // compiler and then use that to bootstrap this compiler\n+            // forward.\n+            builder.compiler(target_compiler.stage - 1, build.build)\n+        } else {\n+            // Build the compiler we'll use to build the stage requested. This\n+            // may build more than one compiler (going down to stage 0).\n+            builder.compiler(target_compiler.stage - 1, target_compiler.host)\n+        };\n+\n+        // Build the libraries for this compiler to link to (i.e., the libraries\n+        // it uses at runtime). NOTE: Crates the target compiler compiles don't\n+        // link to these. (FIXME: Is that correct? It seems to be correct most\n+        // of the time but I think we do link to these for stage2/bin compilers\n+        // when not performing a full bootstrap).\n+        if builder.build.flags.keep_stage.map_or(false, |s| target_compiler.stage <= s) {\n+            builder.verbose(\"skipping compilation of compiler due to --keep-stage\");\n+            let compiler = build_compiler;\n+            for stage in 0..min(target_compiler.stage, builder.flags.keep_stage.unwrap()) {\n+                let target_compiler = builder.compiler(stage, target_compiler.host);\n+                let target = target_compiler.host;\n+                builder.ensure(StdLink { compiler, target_compiler, target });\n+                builder.ensure(TestLink { compiler, target_compiler, target });\n+                builder.ensure(RustcLink { compiler, target_compiler, target });\n+            }\n+        } else {\n+            builder.ensure(Rustc { compiler: build_compiler, target: target_compiler.host });\n+        }\n \n-    // Link the compiler binary itself into place\n-    let rustc = out_dir.join(exe(\"rustc\", host));\n-    let bindir = sysroot.join(\"bin\");\n-    t!(fs::create_dir_all(&bindir));\n-    let compiler = build.compiler_path(&target_compiler);\n-    let _ = fs::remove_file(&compiler);\n-    copy(&rustc, &compiler);\n+        let stage = target_compiler.stage;\n+        let host = target_compiler.host;\n+        println!(\"Assembling stage{} compiler ({})\", stage, host);\n+\n+        // Link in all dylibs to the libdir\n+        let sysroot = builder.sysroot(target_compiler);\n+        let sysroot_libdir = sysroot.join(libdir(&*host));\n+        t!(fs::create_dir_all(&sysroot_libdir));\n+        let src_libdir = builder.sysroot_libdir(build_compiler, host);\n+        for f in t!(fs::read_dir(&src_libdir)).map(|f| t!(f)) {\n+            let filename = f.file_name().into_string().unwrap();\n+            if is_dylib(&filename) {\n+                copy(&f.path(), &sysroot_libdir.join(&filename));\n+            }\n+        }\n \n-    // See if rustdoc exists to link it into place\n-    let rustdoc = exe(\"rustdoc\", host);\n-    let rustdoc_src = out_dir.join(&rustdoc);\n-    let rustdoc_dst = bindir.join(&rustdoc);\n-    if fs::metadata(&rustdoc_src).is_ok() {\n-        let _ = fs::remove_file(&rustdoc_dst);\n-        copy(&rustdoc_src, &rustdoc_dst);\n+        let out_dir = build.cargo_out(build_compiler, Mode::Librustc, host);\n+\n+        // Link the compiler binary itself into place\n+        let rustc = out_dir.join(exe(\"rustc\", &*host));\n+        let bindir = sysroot.join(\"bin\");\n+        t!(fs::create_dir_all(&bindir));\n+        let compiler = builder.rustc(target_compiler);\n+        let _ = fs::remove_file(&compiler);\n+        copy(&rustc, &compiler);\n+\n+        // See if rustdoc exists to link it into place\n+        let rustdoc = exe(\"rustdoc\", &*host);\n+        let rustdoc_src = out_dir.join(&rustdoc);\n+        let rustdoc_dst = bindir.join(&rustdoc);\n+        if fs::metadata(&rustdoc_src).is_ok() {\n+            let _ = fs::remove_file(&rustdoc_dst);\n+            copy(&rustdoc_src, &rustdoc_dst);\n+        }\n+\n+        target_compiler\n     }\n }\n \n@@ -418,64 +728,6 @@ fn add_to_sysroot(sysroot_dst: &Path, stamp: &Path) {\n     }\n }\n \n-/// Build a tool in `src/tools`\n-///\n-/// This will build the specified tool with the specified `host` compiler in\n-/// `stage` into the normal cargo output directory.\n-pub fn maybe_clean_tools(build: &Build, stage: u32, target: &str, mode: Mode) {\n-    let compiler = Compiler::new(stage, &build.build);\n-\n-    let stamp = match mode {\n-        Mode::Libstd => libstd_stamp(build, &compiler, target),\n-        Mode::Libtest => libtest_stamp(build, &compiler, target),\n-        Mode::Librustc => librustc_stamp(build, &compiler, target),\n-        _ => panic!(),\n-    };\n-    let out_dir = build.cargo_out(&compiler, Mode::Tool, target);\n-    build.clear_if_dirty(&out_dir, &stamp);\n-}\n-\n-/// Build a tool in `src/tools`\n-///\n-/// This will build the specified tool with the specified `host` compiler in\n-/// `stage` into the normal cargo output directory.\n-pub fn tool(build: &Build, stage: u32, target: &str, tool: &str) {\n-    let _folder = build.fold_output(|| format!(\"stage{}-{}\", stage, tool));\n-    println!(\"Building stage{} tool {} ({})\", stage, tool, target);\n-\n-    let compiler = Compiler::new(stage, &build.build);\n-\n-    let mut cargo = build.cargo(&compiler, Mode::Tool, target, \"build\");\n-    let dir = build.src.join(\"src/tools\").join(tool);\n-    cargo.arg(\"--manifest-path\").arg(dir.join(\"Cargo.toml\"));\n-\n-    // We don't want to build tools dynamically as they'll be running across\n-    // stages and such and it's just easier if they're not dynamically linked.\n-    cargo.env(\"RUSTC_NO_PREFER_DYNAMIC\", \"1\");\n-\n-    if let Some(dir) = build.openssl_install_dir(target) {\n-        cargo.env(\"OPENSSL_STATIC\", \"1\");\n-        cargo.env(\"OPENSSL_DIR\", dir);\n-        cargo.env(\"LIBZ_SYS_STATIC\", \"1\");\n-    }\n-\n-    cargo.env(\"CFG_RELEASE_CHANNEL\", &build.config.channel);\n-\n-    let info = GitInfo::new(&dir);\n-    if let Some(sha) = info.sha() {\n-        cargo.env(\"CFG_COMMIT_HASH\", sha);\n-    }\n-    if let Some(sha_short) = info.sha_short() {\n-        cargo.env(\"CFG_SHORT_COMMIT_HASH\", sha_short);\n-    }\n-    if let Some(date) = info.commit_date() {\n-        cargo.env(\"CFG_COMMIT_DATE\", date);\n-    }\n-\n-    build.run(&mut cargo);\n-}\n-\n-\n // Avoiding a dependency on winapi to keep compile times down\n #[cfg(unix)]\n fn stderr_isatty() -> bool {\n@@ -535,18 +787,18 @@ fn run_cargo(build: &Build, cargo: &mut Command, stamp: &Path) {\n     let stdout = BufReader::new(child.stdout.take().unwrap());\n     for line in stdout.lines() {\n         let line = t!(line);\n-        let json = if line.starts_with(\"{\") {\n-            t!(line.parse::<json::Json>())\n+        let json: serde_json::Value = if line.starts_with(\"{\") {\n+            t!(serde_json::from_str(&line))\n         } else {\n             // If this was informational, just print it out and continue\n             println!(\"{}\", line);\n             continue\n         };\n-        if json.find(\"reason\").and_then(|j| j.as_string()) != Some(\"compiler-artifact\") {\n+        if json[\"reason\"].as_str() != Some(\"compiler-artifact\") {\n             continue\n         }\n         for filename in json[\"filenames\"].as_array().unwrap() {\n-            let filename = filename.as_string().unwrap();\n+            let filename = filename.as_str().unwrap();\n             // Skip files like executables\n             if !filename.ends_with(\".rlib\") &&\n                !filename.ends_with(\".lib\") &&"}, {"sha": "b0c58235fc31e8f20747c8bd698ad0e3b68a5903", "filename": "src/bootstrap/config.rs", "status": "modified", "additions": 67, "deletions": 79, "changes": 146, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fconfig.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -21,9 +21,9 @@ use std::path::PathBuf;\n use std::process;\n \n use num_cpus;\n-use rustc_serialize::Decodable;\n-use toml::{Parser, Decoder, Value};\n+use toml;\n use util::{exe, push_exe_path};\n+use cache::{INTERNER, Interned};\n \n /// Global configuration for the entire build and/or bootstrap.\n ///\n@@ -46,7 +46,7 @@ pub struct Config {\n     pub docs: bool,\n     pub locked_deps: bool,\n     pub vendor: bool,\n-    pub target_config: HashMap<String, Target>,\n+    pub target_config: HashMap<Interned<String>, Target>,\n     pub full_bootstrap: bool,\n     pub extended: bool,\n     pub sanitizers: bool,\n@@ -78,9 +78,9 @@ pub struct Config {\n     pub rust_debuginfo_tests: bool,\n     pub rust_dist_src: bool,\n \n-    pub build: String,\n-    pub host: Vec<String>,\n-    pub target: Vec<String>,\n+    pub build: Interned<String>,\n+    pub host: Vec<Interned<String>>,\n+    pub target: Vec<Interned<String>>,\n     pub local_rebuild: bool,\n \n     // dist misc\n@@ -138,7 +138,8 @@ pub struct Target {\n /// This structure uses `Decodable` to automatically decode a TOML configuration\n /// file into this format, and then this is traversed and written into the above\n /// `Config` structure.\n-#[derive(RustcDecodable, Default)]\n+#[derive(Deserialize, Default)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct TomlConfig {\n     build: Option<Build>,\n     install: Option<Install>,\n@@ -149,10 +150,13 @@ struct TomlConfig {\n }\n \n /// TOML representation of various global build decisions.\n-#[derive(RustcDecodable, Default, Clone)]\n+#[derive(Deserialize, Default, Clone)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct Build {\n     build: Option<String>,\n+    #[serde(default)]\n     host: Vec<String>,\n+    #[serde(default)]\n     target: Vec<String>,\n     cargo: Option<String>,\n     rustc: Option<String>,\n@@ -174,7 +178,8 @@ struct Build {\n }\n \n /// TOML representation of various global install decisions.\n-#[derive(RustcDecodable, Default, Clone)]\n+#[derive(Deserialize, Default, Clone)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct Install {\n     prefix: Option<String>,\n     sysconfdir: Option<String>,\n@@ -185,7 +190,8 @@ struct Install {\n }\n \n /// TOML representation of how the LLVM build is configured.\n-#[derive(RustcDecodable, Default)]\n+#[derive(Deserialize, Default)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct Llvm {\n     ccache: Option<StringOrBool>,\n     ninja: Option<bool>,\n@@ -200,15 +206,17 @@ struct Llvm {\n     clean_rebuild: Option<bool>,\n }\n \n-#[derive(RustcDecodable, Default, Clone)]\n+#[derive(Deserialize, Default, Clone)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct Dist {\n     sign_folder: Option<String>,\n     gpg_password_file: Option<String>,\n     upload_addr: Option<String>,\n     src_tarball: Option<bool>,\n }\n \n-#[derive(RustcDecodable)]\n+#[derive(Deserialize)]\n+#[serde(untagged)]\n enum StringOrBool {\n     String(String),\n     Bool(bool),\n@@ -221,7 +229,8 @@ impl Default for StringOrBool {\n }\n \n /// TOML representation of how the Rust build is configured.\n-#[derive(RustcDecodable, Default)]\n+#[derive(Deserialize, Default)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct Rust {\n     optimize: Option<bool>,\n     codegen_units: Option<u32>,\n@@ -243,7 +252,8 @@ struct Rust {\n }\n \n /// TOML representation of how each build target is configured.\n-#[derive(RustcDecodable, Default)]\n+#[derive(Deserialize, Default)]\n+#[serde(deny_unknown_fields, rename_all = \"kebab-case\")]\n struct TomlTarget {\n     llvm_config: Option<String>,\n     jemalloc: Option<String>,\n@@ -266,50 +276,39 @@ impl Config {\n         config.docs = true;\n         config.rust_rpath = true;\n         config.rust_codegen_units = 1;\n-        config.build = build.to_string();\n+        config.build = INTERNER.intern_str(build);\n         config.channel = \"dev\".to_string();\n         config.codegen_tests = true;\n         config.rust_dist_src = true;\n \n         let toml = file.map(|file| {\n             let mut f = t!(File::open(&file));\n-            let mut toml = String::new();\n-            t!(f.read_to_string(&mut toml));\n-            let mut p = Parser::new(&toml);\n-            let table = match p.parse() {\n-                Some(table) => table,\n-                None => {\n-                    println!(\"failed to parse TOML configuration '{}':\", file.to_str().unwrap());\n-                    for err in p.errors.iter() {\n-                        let (loline, locol) = p.to_linecol(err.lo);\n-                        let (hiline, hicol) = p.to_linecol(err.hi);\n-                        println!(\"{}:{}-{}:{}: {}\", loline, locol, hiline,\n-                                 hicol, err.desc);\n-                    }\n-                    process::exit(2);\n-                }\n-            };\n-            let mut d = Decoder::new(Value::Table(table));\n-            match Decodable::decode(&mut d) {\n-                Ok(cfg) => cfg,\n-                Err(e) => {\n-                    println!(\"failed to decode TOML: {}\", e);\n+            let mut contents = String::new();\n+            t!(f.read_to_string(&mut contents));\n+            match toml::from_str(&contents) {\n+                Ok(table) => table,\n+                Err(err) => {\n+                    println!(\"failed to parse TOML configuration '{}': {}\",\n+                        file.display(), err);\n                     process::exit(2);\n                 }\n             }\n         }).unwrap_or_else(|| TomlConfig::default());\n \n         let build = toml.build.clone().unwrap_or(Build::default());\n-        set(&mut config.build, build.build.clone());\n+        set(&mut config.build, build.build.clone().map(|x| INTERNER.intern_string(x)));\n         config.host.push(config.build.clone());\n         for host in build.host.iter() {\n-            if !config.host.contains(host) {\n-                config.host.push(host.clone());\n+            let host = INTERNER.intern_str(host);\n+            if !config.host.contains(&host) {\n+                config.host.push(host);\n             }\n         }\n-        for target in config.host.iter().chain(&build.target) {\n-            if !config.target.contains(target) {\n-                config.target.push(target.clone());\n+        for target in config.host.iter().cloned()\n+            .chain(build.target.iter().map(|s| INTERNER.intern_str(s)))\n+        {\n+            if !config.target.contains(&target) {\n+                config.target.push(target);\n             }\n         }\n         config.nodejs = build.nodejs.map(PathBuf::from);\n@@ -402,7 +401,7 @@ impl Config {\n                 target.musl_root = cfg.musl_root.clone().map(PathBuf::from);\n                 target.qemu_rootfs = cfg.qemu_rootfs.clone().map(PathBuf::from);\n \n-                config.target_config.insert(triple.clone(), target);\n+                config.target_config.insert(INTERNER.intern_string(triple.clone()), target);\n             }\n         }\n \n@@ -504,13 +503,13 @@ impl Config {\n             }\n \n             match key {\n-                \"CFG_BUILD\" if value.len() > 0 => self.build = value.to_string(),\n+                \"CFG_BUILD\" if value.len() > 0 => self.build = INTERNER.intern_str(value),\n                 \"CFG_HOST\" if value.len() > 0 => {\n-                    self.host.extend(value.split(\" \").map(|s| s.to_string()));\n+                    self.host.extend(value.split(\" \").map(|s| INTERNER.intern_str(s)));\n \n                 }\n                 \"CFG_TARGET\" if value.len() > 0 => {\n-                    self.target.extend(value.split(\" \").map(|s| s.to_string()));\n+                    self.target.extend(value.split(\" \").map(|s| INTERNER.intern_str(s)));\n                 }\n                 \"CFG_EXPERIMENTAL_TARGETS\" if value.len() > 0 => {\n                     self.llvm_experimental_targets = Some(value.to_string());\n@@ -519,33 +518,28 @@ impl Config {\n                     self.musl_root = Some(parse_configure_path(value));\n                 }\n                 \"CFG_MUSL_ROOT_X86_64\" if value.len() > 0 => {\n-                    let target = \"x86_64-unknown-linux-musl\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"x86_64-unknown-linux-musl\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.musl_root = Some(parse_configure_path(value));\n                 }\n                 \"CFG_MUSL_ROOT_I686\" if value.len() > 0 => {\n-                    let target = \"i686-unknown-linux-musl\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"i686-unknown-linux-musl\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.musl_root = Some(parse_configure_path(value));\n                 }\n                 \"CFG_MUSL_ROOT_ARM\" if value.len() > 0 => {\n-                    let target = \"arm-unknown-linux-musleabi\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"arm-unknown-linux-musleabi\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.musl_root = Some(parse_configure_path(value));\n                 }\n                 \"CFG_MUSL_ROOT_ARMHF\" if value.len() > 0 => {\n-                    let target = \"arm-unknown-linux-musleabihf\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"arm-unknown-linux-musleabihf\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.musl_root = Some(parse_configure_path(value));\n                 }\n                 \"CFG_MUSL_ROOT_ARMV7\" if value.len() > 0 => {\n-                    let target = \"armv7-unknown-linux-musleabihf\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"armv7-unknown-linux-musleabihf\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.musl_root = Some(parse_configure_path(value));\n                 }\n                 \"CFG_DEFAULT_AR\" if value.len() > 0 => {\n@@ -593,33 +587,28 @@ impl Config {\n                     target.jemalloc = Some(parse_configure_path(value).join(\"libjemalloc_pic.a\"));\n                 }\n                 \"CFG_ARM_LINUX_ANDROIDEABI_NDK\" if value.len() > 0 => {\n-                    let target = \"arm-linux-androideabi\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"arm-linux-androideabi\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.ndk = Some(parse_configure_path(value));\n                 }\n                 \"CFG_ARMV7_LINUX_ANDROIDEABI_NDK\" if value.len() > 0 => {\n-                    let target = \"armv7-linux-androideabi\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"armv7-linux-androideabi\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.ndk = Some(parse_configure_path(value));\n                 }\n                 \"CFG_I686_LINUX_ANDROID_NDK\" if value.len() > 0 => {\n-                    let target = \"i686-linux-android\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"i686-linux-android\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.ndk = Some(parse_configure_path(value));\n                 }\n                 \"CFG_AARCH64_LINUX_ANDROID_NDK\" if value.len() > 0 => {\n-                    let target = \"aarch64-linux-android\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"aarch64-linux-android\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.ndk = Some(parse_configure_path(value));\n                 }\n                 \"CFG_X86_64_LINUX_ANDROID_NDK\" if value.len() > 0 => {\n-                    let target = \"x86_64-linux-android\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"x86_64-linux-android\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.ndk = Some(parse_configure_path(value));\n                 }\n                 \"CFG_LOCAL_RUST_ROOT\" if value.len() > 0 => {\n@@ -643,9 +632,8 @@ impl Config {\n                                                .collect();\n                 }\n                 \"CFG_QEMU_ARMHF_ROOTFS\" if value.len() > 0 => {\n-                    let target = \"arm-unknown-linux-gnueabihf\".to_string();\n-                    let target = self.target_config.entry(target)\n-                                     .or_insert(Target::default());\n+                    let target = INTERNER.intern_str(\"arm-unknown-linux-gnueabihf\");\n+                    let target = self.target_config.entry(target).or_insert(Target::default());\n                     target.qemu_rootfs = Some(parse_configure_path(value));\n                 }\n                 _ => {}"}, {"sha": "cdaab9d9c8d9e5b7a8f2ac73279e3a933f5b0d5f", "filename": "src/bootstrap/dist.rs", "status": "modified", "additions": 1171, "deletions": 853, "changes": 2024, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fdist.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fdist.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fdist.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -29,6 +29,10 @@ use build_helper::output;\n use {Build, Compiler, Mode};\n use channel;\n use util::{cp_r, libdir, is_dylib, cp_filtered, copy, exe};\n+use builder::{Builder, RunConfig, ShouldRun, Step};\n+use compile;\n+use tool::{self, Tool};\n+use cache::{INTERNER, Interned};\n \n pub fn pkgname(build: &Build, component: &str) -> String {\n     if component == \"cargo\" {\n@@ -49,50 +53,81 @@ pub fn tmpdir(build: &Build) -> PathBuf {\n     build.out.join(\"tmp/dist\")\n }\n \n-fn rust_installer(build: &Build) -> Command {\n-    build.tool_cmd(&Compiler::new(0, &build.build), \"rust-installer\")\n+fn rust_installer(builder: &Builder) -> Command {\n+    builder.tool_cmd(Tool::RustInstaller)\n }\n \n-/// Builds the `rust-docs` installer component.\n-///\n-/// Slurps up documentation from the `stage`'s `host`.\n-pub fn docs(build: &Build, stage: u32, host: &str) {\n-    println!(\"Dist docs stage{} ({})\", stage, host);\n-    if !build.config.docs {\n-        println!(\"\\tskipping - docs disabled\");\n-        return\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Docs {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Docs {\n+    type Output = Option<PathBuf>;\n+    const DEFAULT: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/doc\")\n     }\n \n-    let name = pkgname(build, \"rust-docs\");\n-    let image = tmpdir(build).join(format!(\"{}-{}-image\", name, host));\n-    let _ = fs::remove_dir_all(&image);\n-\n-    let dst = image.join(\"share/doc/rust/html\");\n-    t!(fs::create_dir_all(&dst));\n-    let src = build.out.join(host).join(\"doc\");\n-    cp_r(&src, &dst);\n-\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust-Documentation\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=Rust-documentation-is-installed.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(format!(\"--package-name={}-{}\", name, host))\n-       .arg(\"--component-name=rust-docs\")\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\")\n-       .arg(\"--bulk-dirs=share/doc/rust/html\");\n-    build.run(&mut cmd);\n-    t!(fs::remove_dir_all(&image));\n-\n-    // As part of this step, *also* copy the docs directory to a directory which\n-    // buildbot typically uploads.\n-    if host == build.build {\n-        let dst = distdir(build).join(\"doc\").join(build.rust_package_vers());\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Docs {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    /// Builds the `rust-docs` installer component.\n+    ///\n+    /// Slurps up documentation from the `stage`'s `target`.\n+    fn run(self, builder: &Builder) -> Option<PathBuf> {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+\n+        builder.default_doc(None);\n+\n+        println!(\"Dist docs stage{} ({})\", stage, target);\n+        if !build.config.docs {\n+            println!(\"\\tskipping - docs disabled\");\n+            return None;\n+        }\n+\n+        let name = pkgname(build, \"rust-docs\");\n+        let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n+        let _ = fs::remove_dir_all(&image);\n+\n+        let dst = image.join(\"share/doc/rust/html\");\n         t!(fs::create_dir_all(&dst));\n+        let src = build.out.join(target).join(\"doc\");\n         cp_r(&src, &dst);\n+\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust-Documentation\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=Rust-documentation-is-installed.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(\"--component-name=rust-docs\")\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\")\n+           .arg(\"--bulk-dirs=share/doc/rust/html\");\n+        build.run(&mut cmd);\n+        t!(fs::remove_dir_all(&image));\n+\n+        // As part of this step, *also* copy the docs directory to a directory which\n+        // buildbot typically uploads.\n+        if target == build.build {\n+            let dst = distdir(build).join(\"doc\").join(build.rust_package_vers());\n+            t!(fs::create_dir_all(&dst));\n+            cp_r(&src, &dst);\n+        }\n+\n+        Some(distdir(build).join(format!(\"{}-{}.tar.gz\", name, target)))\n     }\n }\n \n@@ -115,7 +150,9 @@ fn find_files(files: &[&str], path: &[PathBuf]) -> Vec<PathBuf> {\n     found\n }\n \n-fn make_win_dist(rust_root: &Path, plat_root: &Path, target_triple: &str, build: &Build) {\n+fn make_win_dist(\n+    rust_root: &Path, plat_root: &Path, target_triple: Interned<String>, build: &Build\n+) {\n     //Ask gcc where it keeps its stuff\n     let mut cmd = Command::new(build.cc(target_triple));\n     cmd.arg(\"-print-search-dirs\");\n@@ -222,262 +259,403 @@ fn make_win_dist(rust_root: &Path, plat_root: &Path, target_triple: &str, build:\n     }\n }\n \n-/// Build the `rust-mingw` installer component.\n-///\n-/// This contains all the bits and pieces to run the MinGW Windows targets\n-/// without any extra installed software (e.g. we bundle gcc, libraries, etc).\n-pub fn mingw(build: &Build, host: &str) {\n-    println!(\"Dist mingw ({})\", host);\n-    let name = pkgname(build, \"rust-mingw\");\n-    let image = tmpdir(build).join(format!(\"{}-{}-image\", name, host));\n-    let _ = fs::remove_dir_all(&image);\n-    t!(fs::create_dir_all(&image));\n-\n-    // The first argument is a \"temporary directory\" which is just\n-    // thrown away (this contains the runtime DLLs included in the rustc package\n-    // above) and the second argument is where to place all the MinGW components\n-    // (which is what we want).\n-    make_win_dist(&tmpdir(build), &image, host, &build);\n-\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust-MinGW\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=Rust-MinGW-is-installed.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(format!(\"--package-name={}-{}\", name, host))\n-       .arg(\"--component-name=rust-mingw\")\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n-    t!(fs::remove_dir_all(&image));\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Mingw {\n+    target: Interned<String>,\n }\n \n-/// Creates the `rustc` installer component.\n-pub fn rustc(build: &Build, stage: u32, host: &str) {\n-    println!(\"Dist rustc stage{} ({})\", stage, host);\n-    let name = pkgname(build, \"rustc\");\n-    let image = tmpdir(build).join(format!(\"{}-{}-image\", name, host));\n-    let _ = fs::remove_dir_all(&image);\n-    let overlay = tmpdir(build).join(format!(\"{}-{}-overlay\", name, host));\n-    let _ = fs::remove_dir_all(&overlay);\n-\n-    // Prepare the rustc \"image\", what will actually end up getting installed\n-    prepare_image(build, stage, host, &image);\n-\n-    // Prepare the overlay which is part of the tarball but won't actually be\n-    // installed\n-    let cp = |file: &str| {\n-        install(&build.src.join(file), &overlay, 0o644);\n-    };\n-    cp(\"COPYRIGHT\");\n-    cp(\"LICENSE-APACHE\");\n-    cp(\"LICENSE-MIT\");\n-    cp(\"README.md\");\n-    // tiny morsel of metadata is used by rust-packaging\n-    let version = build.rust_version();\n-    t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n-\n-    // On MinGW we've got a few runtime DLL dependencies that we need to\n-    // include. The first argument to this script is where to put these DLLs\n-    // (the image we're creating), and the second argument is a junk directory\n-    // to ignore all other MinGW stuff the script creates.\n-    //\n-    // On 32-bit MinGW we're always including a DLL which needs some extra\n-    // licenses to distribute. On 64-bit MinGW we don't actually distribute\n-    // anything requiring us to distribute a license, but it's likely the\n-    // install will *also* include the rust-mingw package, which also needs\n-    // licenses, so to be safe we just include it here in all MinGW packages.\n-    if host.contains(\"pc-windows-gnu\") {\n-        make_win_dist(&image, &tmpdir(build), host, build);\n-\n-        let dst = image.join(\"share/doc\");\n-        t!(fs::create_dir_all(&dst));\n-        cp_r(&build.src.join(\"src/etc/third-party\"), &dst);\n+impl Step for Mingw {\n+    type Output = Option<PathBuf>;\n+    const DEFAULT: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n     }\n \n-    // Finally, wrap everything up in a nice tarball!\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=Rust-is-ready-to-roll.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(\"--non-installed-overlay\").arg(&overlay)\n-       .arg(format!(\"--package-name={}-{}\", name, host))\n-       .arg(\"--component-name=rustc\")\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n-    t!(fs::remove_dir_all(&image));\n-    t!(fs::remove_dir_all(&overlay));\n-\n-    fn prepare_image(build: &Build, stage: u32, host: &str, image: &Path) {\n-        let src = build.sysroot(&Compiler::new(stage, host));\n-        let libdir = libdir(host);\n-\n-        // Copy rustc/rustdoc binaries\n-        t!(fs::create_dir_all(image.join(\"bin\")));\n-        cp_r(&src.join(\"bin\"), &image.join(\"bin\"));\n-\n-        // Copy runtime DLLs needed by the compiler\n-        if libdir != \"bin\" {\n-            for entry in t!(src.join(libdir).read_dir()).map(|e| t!(e)) {\n-                let name = entry.file_name();\n-                if let Some(s) = name.to_str() {\n-                    if is_dylib(s) {\n-                        install(&entry.path(), &image.join(libdir), 0o644);\n-                    }\n-                }\n-            }\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Mingw { target: run.target });\n+    }\n+\n+    /// Build the `rust-mingw` installer component.\n+    ///\n+    /// This contains all the bits and pieces to run the MinGW Windows targets\n+    /// without any extra installed software (e.g. we bundle gcc, libraries, etc).\n+    fn run(self, builder: &Builder) -> Option<PathBuf> {\n+        let build = builder.build;\n+        let target = self.target;\n+\n+        if !target.contains(\"pc-windows-gnu\") {\n+            return None;\n         }\n \n-        // Man pages\n-        t!(fs::create_dir_all(image.join(\"share/man/man1\")));\n-        cp_r(&build.src.join(\"man\"), &image.join(\"share/man/man1\"));\n+        println!(\"Dist mingw ({})\", target);\n+        let name = pkgname(build, \"rust-mingw\");\n+        let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n+        let _ = fs::remove_dir_all(&image);\n+        t!(fs::create_dir_all(&image));\n+\n+        // The first argument is a \"temporary directory\" which is just\n+        // thrown away (this contains the runtime DLLs included in the rustc package\n+        // above) and the second argument is where to place all the MinGW components\n+        // (which is what we want).\n+        make_win_dist(&tmpdir(build), &image, target, &build);\n+\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust-MinGW\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=Rust-MinGW-is-installed.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(\"--component-name=rust-mingw\")\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n+        build.run(&mut cmd);\n+        t!(fs::remove_dir_all(&image));\n+        Some(distdir(build).join(format!(\"{}-{}.tar.gz\", name, target)))\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Rustc {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Rustc {\n+    type Output = PathBuf;\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/librustc\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Rustc {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n \n-        // Debugger scripts\n-        debugger_scripts(build, &image, host);\n+    /// Creates the `rustc` installer component.\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n \n-        // Misc license info\n+        let compiler = builder.ensure(compile::Assemble {\n+            target_compiler: builder.compiler(stage, build.build),\n+        });\n+\n+        println!(\"Dist rustc stage{} ({})\", stage, target);\n+        let name = pkgname(build, \"rustc\");\n+        let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n+        let _ = fs::remove_dir_all(&image);\n+        let overlay = tmpdir(build).join(format!(\"{}-{}-overlay\", name, target));\n+        let _ = fs::remove_dir_all(&overlay);\n+\n+        // Prepare the rustc \"image\", what will actually end up getting installed\n+        prepare_image(builder, compiler, target, &image);\n+\n+        // Prepare the overlay which is part of the tarball but won't actually be\n+        // installed\n         let cp = |file: &str| {\n-            install(&build.src.join(file), &image.join(\"share/doc/rust\"), 0o644);\n+            install(&build.src.join(file), &overlay, 0o644);\n         };\n         cp(\"COPYRIGHT\");\n         cp(\"LICENSE-APACHE\");\n         cp(\"LICENSE-MIT\");\n         cp(\"README.md\");\n+        // tiny morsel of metadata is used by rust-packaging\n+        let version = build.rust_version();\n+        t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n+\n+        // On MinGW we've got a few runtime DLL dependencies that we need to\n+        // include. The first argument to this script is where to put these DLLs\n+        // (the image we're creating), and the second argument is a junk directory\n+        // to ignore all other MinGW stuff the script creates.\n+        //\n+        // On 32-bit MinGW we're always including a DLL which needs some extra\n+        // licenses to distribute. On 64-bit MinGW we don't actually distribute\n+        // anything requiring us to distribute a license, but it's likely the\n+        // install will *also* include the rust-mingw package, which also needs\n+        // licenses, so to be safe we just include it here in all MinGW packages.\n+        if target.contains(\"pc-windows-gnu\") {\n+            make_win_dist(&image, &tmpdir(build), target, build);\n+\n+            let dst = image.join(\"share/doc\");\n+            t!(fs::create_dir_all(&dst));\n+            cp_r(&build.src.join(\"src/etc/third-party\"), &dst);\n+        }\n+\n+        // Finally, wrap everything up in a nice tarball!\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=Rust-is-ready-to-roll.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(\"--non-installed-overlay\").arg(&overlay)\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(\"--component-name=rustc\")\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n+        build.run(&mut cmd);\n+        t!(fs::remove_dir_all(&image));\n+        t!(fs::remove_dir_all(&overlay));\n+\n+        return distdir(build).join(format!(\"{}-{}.tar.gz\", name, target));\n+\n+        fn prepare_image(\n+            builder: &Builder, compiler: Compiler, target: Interned<String>, image: &Path\n+        ) {\n+            let build = builder.build;\n+            let src = builder.sysroot(compiler);\n+            let libdir = libdir(&target);\n+\n+            // Copy rustc/rustdoc binaries\n+            t!(fs::create_dir_all(image.join(\"bin\")));\n+            cp_r(&src.join(\"bin\"), &image.join(\"bin\"));\n+\n+            // Copy runtime DLLs needed by the compiler\n+            if libdir != \"bin\" {\n+                for entry in t!(src.join(libdir).read_dir()).map(|e| t!(e)) {\n+                    let name = entry.file_name();\n+                    if let Some(s) = name.to_str() {\n+                        if is_dylib(s) {\n+                            install(&entry.path(), &image.join(libdir), 0o644);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Man pages\n+            t!(fs::create_dir_all(image.join(\"share/man/man1\")));\n+            cp_r(&build.src.join(\"man\"), &image.join(\"share/man/man1\"));\n+\n+            // Debugger scripts\n+            builder.ensure(DebuggerScripts {\n+                sysroot: INTERNER.intern_path(image.to_owned()),\n+                target: target,\n+            });\n+\n+            // Misc license info\n+            let cp = |file: &str| {\n+                install(&build.src.join(file), &image.join(\"share/doc/rust\"), 0o644);\n+            };\n+            cp(\"COPYRIGHT\");\n+            cp(\"LICENSE-APACHE\");\n+            cp(\"LICENSE-MIT\");\n+            cp(\"README.md\");\n+        }\n     }\n }\n \n-/// Copies debugger scripts for `host` into the `sysroot` specified.\n-pub fn debugger_scripts(build: &Build,\n-                        sysroot: &Path,\n-                        host: &str) {\n-    let dst = sysroot.join(\"lib/rustlib/etc\");\n-    t!(fs::create_dir_all(&dst));\n-    let cp_debugger_script = |file: &str| {\n-        install(&build.src.join(\"src/etc/\").join(file), &dst, 0o644);\n-    };\n-    if host.contains(\"windows-msvc\") {\n-        // windbg debugger scripts\n-        install(&build.src.join(\"src/etc/rust-windbg.cmd\"), &sysroot.join(\"bin\"),\n-            0o755);\n-\n-        cp_debugger_script(\"natvis/liballoc.natvis\");\n-        cp_debugger_script(\"natvis/libcore.natvis\");\n-    } else {\n-        cp_debugger_script(\"debugger_pretty_printers_common.py\");\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct DebuggerScripts {\n+    pub sysroot: Interned<PathBuf>,\n+    pub target: Interned<String>,\n+}\n \n-        // gdb debugger scripts\n-        install(&build.src.join(\"src/etc/rust-gdb\"), &sysroot.join(\"bin\"),\n-                0o755);\n+impl Step for DebuggerScripts {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/lldb_batchmode.py\")\n+    }\n \n-        cp_debugger_script(\"gdb_load_rust_pretty_printers.py\");\n-        cp_debugger_script(\"gdb_rust_pretty_printing.py\");\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(DebuggerScripts {\n+            sysroot: run.builder.sysroot(run.builder.compiler(run.builder.top_stage, run.host)),\n+            target: run.target,\n+        });\n+    }\n \n-        // lldb debugger scripts\n-        install(&build.src.join(\"src/etc/rust-lldb\"), &sysroot.join(\"bin\"),\n+    /// Copies debugger scripts for `target` into the `sysroot` specified.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let sysroot = self.sysroot;\n+        let dst = sysroot.join(\"lib/rustlib/etc\");\n+        t!(fs::create_dir_all(&dst));\n+        let cp_debugger_script = |file: &str| {\n+            install(&build.src.join(\"src/etc/\").join(file), &dst, 0o644);\n+        };\n+        if target.contains(\"windows-msvc\") {\n+            // windbg debugger scripts\n+            install(&build.src.join(\"src/etc/rust-windbg.cmd\"), &sysroot.join(\"bin\"),\n                 0o755);\n \n-        cp_debugger_script(\"lldb_rust_formatters.py\");\n+            cp_debugger_script(\"natvis/liballoc.natvis\");\n+            cp_debugger_script(\"natvis/libcore.natvis\");\n+        } else {\n+            cp_debugger_script(\"debugger_pretty_printers_common.py\");\n+\n+            // gdb debugger scripts\n+            install(&build.src.join(\"src/etc/rust-gdb\"), &sysroot.join(\"bin\"),\n+                    0o755);\n+\n+            cp_debugger_script(\"gdb_load_rust_pretty_printers.py\");\n+            cp_debugger_script(\"gdb_rust_pretty_printing.py\");\n+\n+            // lldb debugger scripts\n+            install(&build.src.join(\"src/etc/rust-lldb\"), &sysroot.join(\"bin\"),\n+                    0o755);\n+\n+            cp_debugger_script(\"lldb_rust_formatters.py\");\n+        }\n     }\n }\n \n-/// Creates the `rust-std` installer component as compiled by `compiler` for the\n-/// target `target`.\n-pub fn std(build: &Build, compiler: &Compiler, target: &str) {\n-    println!(\"Dist std stage{} ({} -> {})\", compiler.stage, compiler.host,\n-             target);\n-\n-    // The only true set of target libraries came from the build triple, so\n-    // let's reduce redundant work by only producing archives from that host.\n-    if compiler.host != build.build {\n-        println!(\"\\tskipping, not a build host\");\n-        return\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Std {\n+    pub compiler: Compiler,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Std {\n+    type Output = Option<PathBuf>;\n+    const DEFAULT: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/libstd\")\n     }\n \n-    let name = pkgname(build, \"rust-std\");\n-    let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n-    let _ = fs::remove_dir_all(&image);\n-\n-    let dst = image.join(\"lib/rustlib\").join(target);\n-    t!(fs::create_dir_all(&dst));\n-    let mut src = build.sysroot_libdir(compiler, target);\n-    src.pop(); // Remove the trailing /lib folder from the sysroot_libdir\n-    cp_r(&src, &dst);\n-\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=std-is-standing-at-the-ready.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(format!(\"--package-name={}-{}\", name, target))\n-       .arg(format!(\"--component-name=rust-std-{}\", target))\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n-    t!(fs::remove_dir_all(&image));\n-}\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Std {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) -> Option<PathBuf> {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target = self.target;\n \n-/// The path to the complete rustc-src tarball\n-pub fn rust_src_location(build: &Build) -> PathBuf {\n-    let plain_name = format!(\"rustc-{}-src\", build.rust_package_vers());\n-    distdir(build).join(&format!(\"{}.tar.gz\", plain_name))\n+        println!(\"Dist std stage{} ({} -> {})\", compiler.stage, &compiler.host,\n+                 target);\n+\n+        // The only true set of target libraries came from the build triple, so\n+        // let's reduce redundant work by only producing archives from that host.\n+        if compiler.host != build.build {\n+            println!(\"\\tskipping, not a build host\");\n+            return None;\n+        }\n+\n+        // We want to package up as many target libraries as possible\n+        // for the `rust-std` package, so if this is a host target we\n+        // depend on librustc and otherwise we just depend on libtest.\n+        if build.config.host.iter().any(|t| t == target) {\n+            builder.ensure(compile::Rustc { compiler, target });\n+        } else {\n+            builder.ensure(compile::Test { compiler, target });\n+        }\n+\n+        let name = pkgname(build, \"rust-std\");\n+        let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n+        let _ = fs::remove_dir_all(&image);\n+\n+        let dst = image.join(\"lib/rustlib\").join(target);\n+        t!(fs::create_dir_all(&dst));\n+        let mut src = builder.sysroot_libdir(compiler, target).to_path_buf();\n+        src.pop(); // Remove the trailing /lib folder from the sysroot_libdir\n+        cp_r(&src, &dst);\n+\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=std-is-standing-at-the-ready.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(format!(\"--component-name=rust-std-{}\", target))\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n+        build.run(&mut cmd);\n+        t!(fs::remove_dir_all(&image));\n+        Some(distdir(build).join(format!(\"{}-{}.tar.gz\", name, target)))\n+    }\n }\n \n-/// The path to the rust-src component installer\n-pub fn rust_src_installer(build: &Build) -> PathBuf {\n-    let name = pkgname(build, \"rust-src\");\n-    distdir(build).join(&format!(\"{}.tar.gz\", name))\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Analysis {\n+    pub compiler: Compiler,\n+    pub target: Interned<String>,\n }\n \n-/// Creates a tarball of save-analysis metadata, if available.\n-pub fn analysis(build: &Build, compiler: &Compiler, target: &str) {\n-    assert!(build.config.extended);\n-    println!(\"Dist analysis\");\n+impl Step for Analysis {\n+    type Output = Option<PathBuf>;\n+    const DEFAULT: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n \n-    if compiler.host != build.build {\n-        println!(\"\\tskipping, not a build host\");\n-        return;\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"analysis\").default_condition(builder.build.config.extended)\n     }\n \n-    // Package save-analysis from stage1 if not doing a full bootstrap, as the\n-    // stage2 artifacts is simply copied from stage1 in that case.\n-    let compiler = if build.force_use_stage1(compiler, target) {\n-        Compiler::new(1, compiler.host)\n-    } else {\n-        compiler.clone()\n-    };\n-\n-    let name = pkgname(build, \"rust-analysis\");\n-    let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n-\n-    let src = build.stage_out(&compiler, Mode::Libstd).join(target).join(\"release\").join(\"deps\");\n-\n-    let image_src = src.join(\"save-analysis\");\n-    let dst = image.join(\"lib/rustlib\").join(target).join(\"analysis\");\n-    t!(fs::create_dir_all(&dst));\n-    println!(\"image_src: {:?}, dst: {:?}\", image_src, dst);\n-    cp_r(&image_src, &dst);\n-\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=save-analysis-saved.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(format!(\"--package-name={}-{}\", name, target))\n-       .arg(format!(\"--component-name=rust-analysis-{}\", target))\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n-    t!(fs::remove_dir_all(&image));\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Analysis {\n+            compiler: run.builder.compiler(run.builder.top_stage, run.host),\n+            target: run.target,\n+        });\n+    }\n+\n+    /// Creates a tarball of save-analysis metadata, if available.\n+    fn run(self, builder: &Builder) -> Option<PathBuf> {\n+        let build = builder.build;\n+        let compiler = self.compiler;\n+        let target = self.target;\n+        assert!(build.config.extended);\n+        println!(\"Dist analysis\");\n+\n+        if &compiler.host != build.build {\n+            println!(\"\\tskipping, not a build host\");\n+            return None;\n+        }\n+\n+        // Package save-analysis from stage1 if not doing a full bootstrap, as the\n+        // stage2 artifacts is simply copied from stage1 in that case.\n+        let compiler = if build.force_use_stage1(compiler, target) {\n+            builder.compiler(1, compiler.host)\n+        } else {\n+            compiler.clone()\n+        };\n+\n+        let name = pkgname(build, \"rust-analysis\");\n+        let image = tmpdir(build).join(format!(\"{}-{}-image\", name, target));\n+\n+        let src = build.stage_out(compiler, Mode::Libstd)\n+            .join(target).join(\"release\").join(\"deps\");\n+\n+        let image_src = src.join(\"save-analysis\");\n+        let dst = image.join(\"lib/rustlib\").join(target).join(\"analysis\");\n+        t!(fs::create_dir_all(&dst));\n+        println!(\"image_src: {:?}, dst: {:?}\", image_src, dst);\n+        cp_r(&image_src, &dst);\n+\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=save-analysis-saved.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(format!(\"--component-name=rust-analysis-{}\", target))\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n+        build.run(&mut cmd);\n+        t!(fs::remove_dir_all(&image));\n+        Some(distdir(build).join(format!(\"{}-{}.tar.gz\", name, target)))\n+    }\n }\n \n fn copy_src_dirs(build: &Build, src_dirs: &[&str], exclude_dirs: &[&str], dst_dir: &Path) {\n@@ -520,149 +698,196 @@ fn copy_src_dirs(build: &Build, src_dirs: &[&str], exclude_dirs: &[&str], dst_di\n     }\n }\n \n-/// Creates the `rust-src` installer component\n-pub fn rust_src(build: &Build) {\n-    println!(\"Dist src\");\n-\n-    let name = pkgname(build, \"rust-src\");\n-    let image = tmpdir(build).join(format!(\"{}-image\", name));\n-    let _ = fs::remove_dir_all(&image);\n-\n-    let dst = image.join(\"lib/rustlib/src\");\n-    let dst_src = dst.join(\"rust\");\n-    t!(fs::create_dir_all(&dst_src));\n-\n-    // This is the reduced set of paths which will become the rust-src component\n-    // (essentially libstd and all of its path dependencies)\n-    let std_src_dirs = [\n-        \"src/build_helper\",\n-        \"src/liballoc\",\n-        \"src/liballoc_jemalloc\",\n-        \"src/liballoc_system\",\n-        \"src/libbacktrace\",\n-        \"src/libcollections\",\n-        \"src/libcompiler_builtins\",\n-        \"src/libcore\",\n-        \"src/liblibc\",\n-        \"src/libpanic_abort\",\n-        \"src/libpanic_unwind\",\n-        \"src/librand\",\n-        \"src/librustc_asan\",\n-        \"src/librustc_lsan\",\n-        \"src/librustc_msan\",\n-        \"src/librustc_tsan\",\n-        \"src/libstd\",\n-        \"src/libstd_unicode\",\n-        \"src/libunwind\",\n-        \"src/rustc/compiler_builtins_shim\",\n-        \"src/rustc/libc_shim\",\n-        \"src/libtest\",\n-        \"src/libterm\",\n-        \"src/jemalloc\",\n-        \"src/libprofiler_builtins\",\n-    ];\n-    let std_src_dirs_exclude = [\n-        \"src/compiler-rt/test\",\n-        \"src/jemalloc/test/unit\",\n-    ];\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Src;\n+\n+impl Step for Src {\n+    /// The output path of the src installer tarball\n+    type Output = PathBuf;\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+    const ONLY_BUILD: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Src);\n+    }\n+\n+    /// Creates the `rust-src` installer component\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        let build = builder.build;\n+        println!(\"Dist src\");\n+\n+        let name = pkgname(build, \"rust-src\");\n+        let image = tmpdir(build).join(format!(\"{}-image\", name));\n+        let _ = fs::remove_dir_all(&image);\n+\n+        let dst = image.join(\"lib/rustlib/src\");\n+        let dst_src = dst.join(\"rust\");\n+        t!(fs::create_dir_all(&dst_src));\n+\n+        // This is the reduced set of paths which will become the rust-src component\n+        // (essentially libstd and all of its path dependencies)\n+        let std_src_dirs = [\n+            \"src/build_helper\",\n+            \"src/liballoc\",\n+            \"src/liballoc_jemalloc\",\n+            \"src/liballoc_system\",\n+            \"src/libbacktrace\",\n+            \"src/libcollections\",\n+            \"src/libcompiler_builtins\",\n+            \"src/libcore\",\n+            \"src/liblibc\",\n+            \"src/libpanic_abort\",\n+            \"src/libpanic_unwind\",\n+            \"src/librand\",\n+            \"src/librustc_asan\",\n+            \"src/librustc_lsan\",\n+            \"src/librustc_msan\",\n+            \"src/librustc_tsan\",\n+            \"src/libstd\",\n+            \"src/libstd_unicode\",\n+            \"src/libunwind\",\n+            \"src/rustc/compiler_builtins_shim\",\n+            \"src/rustc/libc_shim\",\n+            \"src/libtest\",\n+            \"src/libterm\",\n+            \"src/jemalloc\",\n+            \"src/libprofiler_builtins\",\n+        ];\n+        let std_src_dirs_exclude = [\n+            \"src/compiler-rt/test\",\n+            \"src/jemalloc/test/unit\",\n+        ];\n+\n+        copy_src_dirs(build, &std_src_dirs[..], &std_src_dirs_exclude[..], &dst_src);\n+\n+        // Create source tarball in rust-installer format\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=Awesome-Source.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(format!(\"--package-name={}\", name))\n+           .arg(\"--component-name=rust-src\")\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n+        build.run(&mut cmd);\n \n-    copy_src_dirs(build, &std_src_dirs[..], &std_src_dirs_exclude[..], &dst_src);\n-\n-    // Create source tarball in rust-installer format\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=Awesome-Source.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(format!(\"--package-name={}\", name))\n-       .arg(\"--component-name=rust-src\")\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n-\n-    t!(fs::remove_dir_all(&image));\n+        t!(fs::remove_dir_all(&image));\n+        distdir(build).join(&format!(\"{}.tar.gz\", name))\n+    }\n }\n \n const CARGO_VENDOR_VERSION: &str = \"0.1.4\";\n \n-/// Creates the plain source tarball\n-pub fn plain_source_tarball(build: &Build) {\n-    println!(\"Create plain source tarball\");\n-\n-    // Make sure that the root folder of tarball has the correct name\n-    let plain_name = format!(\"{}-src\", pkgname(build, \"rustc\"));\n-    let plain_dst_src = tmpdir(build).join(&plain_name);\n-    let _ = fs::remove_dir_all(&plain_dst_src);\n-    t!(fs::create_dir_all(&plain_dst_src));\n-\n-    // This is the set of root paths which will become part of the source package\n-    let src_files = [\n-        \"COPYRIGHT\",\n-        \"LICENSE-APACHE\",\n-        \"LICENSE-MIT\",\n-        \"CONTRIBUTING.md\",\n-        \"README.md\",\n-        \"RELEASES.md\",\n-        \"configure\",\n-        \"x.py\",\n-    ];\n-    let src_dirs = [\n-        \"man\",\n-        \"src\",\n-    ];\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct PlainSourceTarball;\n \n-    copy_src_dirs(build, &src_dirs[..], &[], &plain_dst_src);\n+impl Step for PlainSourceTarball {\n+    /// Produces the location of the tarball generated\n+    type Output = PathBuf;\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+    const ONLY_BUILD: bool = true;\n \n-    // Copy the files normally\n-    for item in &src_files {\n-        copy(&build.src.join(item), &plain_dst_src.join(item));\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src\").default_condition(builder.config.rust_dist_src)\n     }\n \n-    // Create the version file\n-    write_file(&plain_dst_src.join(\"version\"), build.rust_version().as_bytes());\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(PlainSourceTarball);\n+    }\n+\n+    /// Creates the plain source tarball\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        let build = builder.build;\n+        println!(\"Create plain source tarball\");\n+\n+        // Make sure that the root folder of tarball has the correct name\n+        let plain_name = format!(\"{}-src\", pkgname(build, \"rustc\"));\n+        let plain_dst_src = tmpdir(build).join(&plain_name);\n+        let _ = fs::remove_dir_all(&plain_dst_src);\n+        t!(fs::create_dir_all(&plain_dst_src));\n+\n+        // This is the set of root paths which will become part of the source package\n+        let src_files = [\n+            \"COPYRIGHT\",\n+            \"LICENSE-APACHE\",\n+            \"LICENSE-MIT\",\n+            \"CONTRIBUTING.md\",\n+            \"README.md\",\n+            \"RELEASES.md\",\n+            \"configure\",\n+            \"x.py\",\n+        ];\n+        let src_dirs = [\n+            \"man\",\n+            \"src\",\n+        ];\n \n-    // If we're building from git sources, we need to vendor a complete distribution.\n-    if build.rust_info.is_git() {\n-        // Get cargo-vendor installed, if it isn't already.\n-        let mut has_cargo_vendor = false;\n-        let mut cmd = Command::new(&build.initial_cargo);\n-        for line in output(cmd.arg(\"install\").arg(\"--list\")).lines() {\n-            has_cargo_vendor |= line.starts_with(\"cargo-vendor \");\n+        copy_src_dirs(build, &src_dirs[..], &[], &plain_dst_src);\n+\n+        // Copy the files normally\n+        for item in &src_files {\n+            copy(&build.src.join(item), &plain_dst_src.join(item));\n         }\n-        if !has_cargo_vendor {\n+\n+        // Create the version file\n+        write_file(&plain_dst_src.join(\"version\"), build.rust_version().as_bytes());\n+\n+        // If we're building from git sources, we need to vendor a complete distribution.\n+        if build.rust_info.is_git() {\n+            // Get cargo-vendor installed, if it isn't already.\n+            let mut has_cargo_vendor = false;\n             let mut cmd = Command::new(&build.initial_cargo);\n-            cmd.arg(\"install\")\n-               .arg(\"--force\")\n-               .arg(\"--debug\")\n-               .arg(\"--vers\").arg(CARGO_VENDOR_VERSION)\n-               .arg(\"cargo-vendor\")\n-               .env(\"RUSTC\", &build.initial_rustc);\n+            for line in output(cmd.arg(\"install\").arg(\"--list\")).lines() {\n+                has_cargo_vendor |= line.starts_with(\"cargo-vendor \");\n+            }\n+            if !has_cargo_vendor {\n+                let mut cmd = Command::new(&build.initial_cargo);\n+                cmd.arg(\"install\")\n+                   .arg(\"--force\")\n+                   .arg(\"--debug\")\n+                   .arg(\"--vers\").arg(CARGO_VENDOR_VERSION)\n+                   .arg(\"cargo-vendor\")\n+                   .env(\"RUSTC\", &build.initial_rustc);\n+                build.run(&mut cmd);\n+            }\n+\n+            // Vendor all Cargo dependencies\n+            let mut cmd = Command::new(&build.initial_cargo);\n+            cmd.arg(\"vendor\")\n+               .current_dir(&plain_dst_src.join(\"src\"));\n             build.run(&mut cmd);\n         }\n \n-        // Vendor all Cargo dependencies\n-        let mut cmd = Command::new(&build.initial_cargo);\n-        cmd.arg(\"vendor\")\n-           .current_dir(&plain_dst_src.join(\"src\"));\n+        // Create plain source tarball\n+        let plain_name = format!(\"rustc-{}-src\", build.rust_package_vers());\n+        let mut tarball = distdir(build).join(&format!(\"{}.tar.gz\", plain_name));\n+        tarball.set_extension(\"\"); // strip .gz\n+        tarball.set_extension(\"\"); // strip .tar\n+        if let Some(dir) = tarball.parent() {\n+            t!(fs::create_dir_all(dir));\n+        }\n+        println!(\"running installer\");\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"tarball\")\n+           .arg(\"--input\").arg(&plain_name)\n+           .arg(\"--output\").arg(&tarball)\n+           .arg(\"--work-dir=.\")\n+           .current_dir(tmpdir(build));\n         build.run(&mut cmd);\n+        distdir(build).join(&format!(\"{}.tar.gz\", plain_name))\n     }\n-\n-    // Create plain source tarball\n-    let mut tarball = rust_src_location(build);\n-    tarball.set_extension(\"\"); // strip .gz\n-    tarball.set_extension(\"\"); // strip .tar\n-    if let Some(dir) = tarball.parent() {\n-        t!(fs::create_dir_all(dir));\n-    }\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"tarball\")\n-       .arg(\"--input\").arg(&plain_name)\n-       .arg(\"--output\").arg(&tarball)\n-       .arg(\"--work-dir=.\")\n-       .current_dir(tmpdir(build));\n-    build.run(&mut cmd);\n }\n \n fn install(src: &Path, dstdir: &Path, perms: u32) {\n@@ -704,471 +929,546 @@ fn write_file(path: &Path, data: &[u8]) {\n     t!(vf.write_all(data));\n }\n \n-pub fn cargo(build: &Build, stage: u32, target: &str) {\n-    println!(\"Dist cargo stage{} ({})\", stage, target);\n-    let compiler = Compiler::new(stage, &build.build);\n-\n-    let src = build.src.join(\"src/tools/cargo\");\n-    let etc = src.join(\"src/etc\");\n-    let release_num = build.release_num(\"cargo\");\n-    let name = pkgname(build, \"cargo\");\n-    let version = build.cargo_info.version(build, &release_num);\n-\n-    let tmp = tmpdir(build);\n-    let image = tmp.join(\"cargo-image\");\n-    drop(fs::remove_dir_all(&image));\n-    t!(fs::create_dir_all(&image));\n-\n-    // Prepare the image directory\n-    t!(fs::create_dir_all(image.join(\"share/zsh/site-functions\")));\n-    t!(fs::create_dir_all(image.join(\"etc/bash_completion.d\")));\n-    let cargo = build.cargo_out(&compiler, Mode::Tool, target)\n-                     .join(exe(\"cargo\", target));\n-    install(&cargo, &image.join(\"bin\"), 0o755);\n-    for man in t!(etc.join(\"man\").read_dir()) {\n-        let man = t!(man);\n-        install(&man.path(), &image.join(\"share/man/man1\"), 0o644);\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Cargo {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Cargo {\n+    type Output = PathBuf;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"cargo\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Cargo {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+\n+        builder.ensure(tool::Cargo { stage, target });\n+\n+        println!(\"Dist cargo stage{} ({})\", stage, target);\n+        let compiler = builder.compiler(stage, build.build);\n+\n+        let src = build.src.join(\"src/tools/cargo\");\n+        let etc = src.join(\"src/etc\");\n+        let release_num = build.release_num(\"cargo\");\n+        let name = pkgname(build, \"cargo\");\n+        let version = builder.cargo_info.version(build, &release_num);\n+\n+        let tmp = tmpdir(build);\n+        let image = tmp.join(\"cargo-image\");\n+        drop(fs::remove_dir_all(&image));\n+        t!(fs::create_dir_all(&image));\n+\n+        // Prepare the image directory\n+        t!(fs::create_dir_all(image.join(\"share/zsh/site-functions\")));\n+        t!(fs::create_dir_all(image.join(\"etc/bash_completion.d\")));\n+        let cargo = build.cargo_out(compiler, Mode::Tool, target)\n+                         .join(exe(\"cargo\", &target));\n+        install(&cargo, &image.join(\"bin\"), 0o755);\n+        for man in t!(etc.join(\"man\").read_dir()) {\n+            let man = t!(man);\n+            install(&man.path(), &image.join(\"share/man/man1\"), 0o644);\n+        }\n+        install(&etc.join(\"_cargo\"), &image.join(\"share/zsh/site-functions\"), 0o644);\n+        copy(&etc.join(\"cargo.bashcomp.sh\"),\n+             &image.join(\"etc/bash_completion.d/cargo\"));\n+        let doc = image.join(\"share/doc/cargo\");\n+        install(&src.join(\"README.md\"), &doc, 0o644);\n+        install(&src.join(\"LICENSE-MIT\"), &doc, 0o644);\n+        install(&src.join(\"LICENSE-APACHE\"), &doc, 0o644);\n+        install(&src.join(\"LICENSE-THIRD-PARTY\"), &doc, 0o644);\n+\n+        // Prepare the overlay\n+        let overlay = tmp.join(\"cargo-overlay\");\n+        drop(fs::remove_dir_all(&overlay));\n+        t!(fs::create_dir_all(&overlay));\n+        install(&src.join(\"README.md\"), &overlay, 0o644);\n+        install(&src.join(\"LICENSE-MIT\"), &overlay, 0o644);\n+        install(&src.join(\"LICENSE-APACHE\"), &overlay, 0o644);\n+        install(&src.join(\"LICENSE-THIRD-PARTY\"), &overlay, 0o644);\n+        t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n+\n+        // Generate the installer tarball\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=Rust-is-ready-to-roll.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(\"--non-installed-overlay\").arg(&overlay)\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(\"--component-name=cargo\")\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n+        build.run(&mut cmd);\n+        distdir(build).join(format!(\"{}-{}.tar.gz\", name, target))\n     }\n-    install(&etc.join(\"_cargo\"), &image.join(\"share/zsh/site-functions\"), 0o644);\n-    copy(&etc.join(\"cargo.bashcomp.sh\"),\n-         &image.join(\"etc/bash_completion.d/cargo\"));\n-    let doc = image.join(\"share/doc/cargo\");\n-    install(&src.join(\"README.md\"), &doc, 0o644);\n-    install(&src.join(\"LICENSE-MIT\"), &doc, 0o644);\n-    install(&src.join(\"LICENSE-APACHE\"), &doc, 0o644);\n-    install(&src.join(\"LICENSE-THIRD-PARTY\"), &doc, 0o644);\n-\n-    // Prepare the overlay\n-    let overlay = tmp.join(\"cargo-overlay\");\n-    drop(fs::remove_dir_all(&overlay));\n-    t!(fs::create_dir_all(&overlay));\n-    install(&src.join(\"README.md\"), &overlay, 0o644);\n-    install(&src.join(\"LICENSE-MIT\"), &overlay, 0o644);\n-    install(&src.join(\"LICENSE-APACHE\"), &overlay, 0o644);\n-    install(&src.join(\"LICENSE-THIRD-PARTY\"), &overlay, 0o644);\n-    t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n-\n-    // Generate the installer tarball\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=Rust-is-ready-to-roll.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(\"--non-installed-overlay\").arg(&overlay)\n-       .arg(format!(\"--package-name={}-{}\", name, target))\n-       .arg(\"--component-name=cargo\")\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n }\n \n-pub fn rls(build: &Build, stage: u32, target: &str) {\n-    assert!(build.config.extended);\n-    println!(\"Dist RLS stage{} ({})\", stage, target);\n-    let compiler = Compiler::new(stage, &build.build);\n-\n-    let src = build.src.join(\"src/tools/rls\");\n-    let release_num = build.release_num(\"rls\");\n-    let name = pkgname(build, \"rls\");\n-    let version = build.rls_info.version(build, &release_num);\n-\n-    let tmp = tmpdir(build);\n-    let image = tmp.join(\"rls-image\");\n-    drop(fs::remove_dir_all(&image));\n-    t!(fs::create_dir_all(&image));\n-\n-    // Prepare the image directory\n-    let rls = build.cargo_out(&compiler, Mode::Tool, target)\n-                     .join(exe(\"rls\", target));\n-    install(&rls, &image.join(\"bin\"), 0o755);\n-    let doc = image.join(\"share/doc/rls\");\n-    install(&src.join(\"README.md\"), &doc, 0o644);\n-    install(&src.join(\"LICENSE-MIT\"), &doc, 0o644);\n-    install(&src.join(\"LICENSE-APACHE\"), &doc, 0o644);\n-\n-    // Prepare the overlay\n-    let overlay = tmp.join(\"rls-overlay\");\n-    drop(fs::remove_dir_all(&overlay));\n-    t!(fs::create_dir_all(&overlay));\n-    install(&src.join(\"README.md\"), &overlay, 0o644);\n-    install(&src.join(\"LICENSE-MIT\"), &overlay, 0o644);\n-    install(&src.join(\"LICENSE-APACHE\"), &overlay, 0o644);\n-    t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n-\n-    // Generate the installer tarball\n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"generate\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=RLS-ready-to-serve.\")\n-       .arg(\"--image-dir\").arg(&image)\n-       .arg(\"--work-dir\").arg(&tmpdir(build))\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(\"--non-installed-overlay\").arg(&overlay)\n-       .arg(format!(\"--package-name={}-{}\", name, target))\n-       .arg(\"--component-name=rls\")\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n-    build.run(&mut cmd);\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Rls {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n }\n \n-/// Creates a combined installer for the specified target in the provided stage.\n-pub fn extended(build: &Build, stage: u32, target: &str) {\n-    println!(\"Dist extended stage{} ({})\", stage, target);\n-\n-    let dist = distdir(build);\n-    let rustc_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                            pkgname(build, \"rustc\"),\n-                                            target));\n-    let cargo_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                            pkgname(build, \"cargo\"),\n-                                            target));\n-    let rls_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                          pkgname(build, \"rls\"),\n-                                          target));\n-    let analysis_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                               pkgname(build, \"rust-analysis\"),\n-                                               target));\n-    let docs_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                           pkgname(build, \"rust-docs\"),\n-                                           target));\n-    let mingw_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                            pkgname(build, \"rust-mingw\"),\n-                                            target));\n-    let std_installer = dist.join(format!(\"{}-{}.tar.gz\",\n-                                          pkgname(build, \"rust-std\"),\n-                                          target));\n-\n-    let tmp = tmpdir(build);\n-    let overlay = tmp.join(\"extended-overlay\");\n-    let etc = build.src.join(\"src/etc/installer\");\n-    let work = tmp.join(\"work\");\n-\n-    let _ = fs::remove_dir_all(&overlay);\n-    install(&build.src.join(\"COPYRIGHT\"), &overlay, 0o644);\n-    install(&build.src.join(\"LICENSE-APACHE\"), &overlay, 0o644);\n-    install(&build.src.join(\"LICENSE-MIT\"), &overlay, 0o644);\n-    let version = build.rust_version();\n-    t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n-    install(&etc.join(\"README.md\"), &overlay, 0o644);\n-\n-    // When rust-std package split from rustc, we needed to ensure that during\n-    // upgrades rustc was upgraded before rust-std. To avoid rustc clobbering\n-    // the std files during uninstall. To do this ensure that rustc comes\n-    // before rust-std in the list below.\n-    let mut tarballs = vec![rustc_installer, cargo_installer, rls_installer,\n-                            analysis_installer, docs_installer, std_installer];\n-    if target.contains(\"pc-windows-gnu\") {\n-        tarballs.push(mingw_installer);\n-    }\n-    let mut input_tarballs = tarballs[0].as_os_str().to_owned();\n-    for tarball in &tarballs[1..] {\n-        input_tarballs.push(\",\");\n-        input_tarballs.push(tarball);\n+impl Step for Rls {\n+    type Output = PathBuf;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"rls\")\n     }\n \n-    let mut cmd = rust_installer(build);\n-    cmd.arg(\"combine\")\n-       .arg(\"--product-name=Rust\")\n-       .arg(\"--rel-manifest-dir=rustlib\")\n-       .arg(\"--success-message=Rust-is-ready-to-roll.\")\n-       .arg(\"--work-dir\").arg(&work)\n-       .arg(\"--output-dir\").arg(&distdir(build))\n-       .arg(format!(\"--package-name={}-{}\", pkgname(build, \"rust\"), target))\n-       .arg(\"--legacy-manifest-dirs=rustlib,cargo\")\n-       .arg(\"--input-tarballs\").arg(input_tarballs)\n-       .arg(\"--non-installed-overlay\").arg(&overlay);\n-    build.run(&mut cmd);\n-\n-    let mut license = String::new();\n-    t!(t!(File::open(build.src.join(\"COPYRIGHT\"))).read_to_string(&mut license));\n-    license.push_str(\"\\n\");\n-    t!(t!(File::open(build.src.join(\"LICENSE-APACHE\"))).read_to_string(&mut license));\n-    license.push_str(\"\\n\");\n-    t!(t!(File::open(build.src.join(\"LICENSE-MIT\"))).read_to_string(&mut license));\n-\n-    let rtf = r\"{\\rtf1\\ansi\\deff0{\\fonttbl{\\f0\\fnil\\fcharset0 Arial;}}\\nowwrap\\fs18\";\n-    let mut rtf = rtf.to_string();\n-    rtf.push_str(\"\\n\");\n-    for line in license.lines() {\n-        rtf.push_str(line);\n-        rtf.push_str(\"\\\\line \");\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Rls {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n     }\n-    rtf.push_str(\"}\");\n-\n-    if target.contains(\"apple-darwin\") {\n-        let pkg = tmp.join(\"pkg\");\n-        let _ = fs::remove_dir_all(&pkg);\n-        t!(fs::create_dir_all(pkg.join(\"rustc\")));\n-        t!(fs::create_dir_all(pkg.join(\"cargo\")));\n-        t!(fs::create_dir_all(pkg.join(\"rust-docs\")));\n-        t!(fs::create_dir_all(pkg.join(\"rust-std\")));\n-        t!(fs::create_dir_all(pkg.join(\"rls\")));\n-        t!(fs::create_dir_all(pkg.join(\"rust-analysis\")));\n-\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rustc\"), target)),\n-             &pkg.join(\"rustc\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"cargo\"), target)),\n-             &pkg.join(\"cargo\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-docs\"), target)),\n-             &pkg.join(\"rust-docs\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-std\"), target)),\n-             &pkg.join(\"rust-std\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rls\"), target)),\n-             &pkg.join(\"rls\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-analysis\"), target)),\n-             &pkg.join(\"rust-analysis\"));\n-\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rustc\"), 0o755);\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"cargo\"), 0o755);\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rust-docs\"), 0o755);\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rust-std\"), 0o755);\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rls\"), 0o755);\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rust-analysis\"), 0o755);\n-\n-        let pkgbuild = |component: &str| {\n-            let mut cmd = Command::new(\"pkgbuild\");\n-            cmd.arg(\"--identifier\").arg(format!(\"org.rust-lang.{}\", component))\n-               .arg(\"--scripts\").arg(pkg.join(component))\n-               .arg(\"--nopayload\")\n-               .arg(pkg.join(component).with_extension(\"pkg\"));\n-            build.run(&mut cmd);\n-        };\n-        pkgbuild(\"rustc\");\n-        pkgbuild(\"cargo\");\n-        pkgbuild(\"rust-docs\");\n-        pkgbuild(\"rust-std\");\n-        pkgbuild(\"rls\");\n-        pkgbuild(\"rust-analysis\");\n-\n-        // create an 'uninstall' package\n-        install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"uninstall\"), 0o755);\n-        pkgbuild(\"uninstall\");\n-\n-        t!(fs::create_dir_all(pkg.join(\"res\")));\n-        t!(t!(File::create(pkg.join(\"res/LICENSE.txt\"))).write_all(license.as_bytes()));\n-        install(&etc.join(\"gfx/rust-logo.png\"), &pkg.join(\"res\"), 0o644);\n-        let mut cmd = Command::new(\"productbuild\");\n-        cmd.arg(\"--distribution\").arg(etc.join(\"pkg/Distribution.xml\"))\n-           .arg(\"--resources\").arg(pkg.join(\"res\"))\n-           .arg(distdir(build).join(format!(\"{}-{}.pkg\",\n-                                             pkgname(build, \"rust\"),\n-                                             target)))\n-           .arg(\"--package-path\").arg(&pkg);\n+\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        assert!(build.config.extended);\n+\n+        builder.ensure(tool::Rls { stage, target });\n+\n+        println!(\"Dist RLS stage{} ({})\", stage, target);\n+        let compiler = builder.compiler(stage, build.build);\n+\n+        let src = build.src.join(\"src/tools/rls\");\n+        let release_num = build.release_num(\"rls\");\n+        let name = pkgname(build, \"rls\");\n+        let version = build.rls_info.version(build, &release_num);\n+\n+        let tmp = tmpdir(build);\n+        let image = tmp.join(\"rls-image\");\n+        drop(fs::remove_dir_all(&image));\n+        t!(fs::create_dir_all(&image));\n+\n+        // Prepare the image directory\n+        let rls = build.cargo_out(compiler, Mode::Tool, target)\n+                         .join(exe(\"rls\", &target));\n+        install(&rls, &image.join(\"bin\"), 0o755);\n+        let doc = image.join(\"share/doc/rls\");\n+        install(&src.join(\"README.md\"), &doc, 0o644);\n+        install(&src.join(\"LICENSE-MIT\"), &doc, 0o644);\n+        install(&src.join(\"LICENSE-APACHE\"), &doc, 0o644);\n+\n+        // Prepare the overlay\n+        let overlay = tmp.join(\"rls-overlay\");\n+        drop(fs::remove_dir_all(&overlay));\n+        t!(fs::create_dir_all(&overlay));\n+        install(&src.join(\"README.md\"), &overlay, 0o644);\n+        install(&src.join(\"LICENSE-MIT\"), &overlay, 0o644);\n+        install(&src.join(\"LICENSE-APACHE\"), &overlay, 0o644);\n+        t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n+\n+        // Generate the installer tarball\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"generate\")\n+           .arg(\"--product-name=Rust\")\n+           .arg(\"--rel-manifest-dir=rustlib\")\n+           .arg(\"--success-message=RLS-ready-to-serve.\")\n+           .arg(\"--image-dir\").arg(&image)\n+           .arg(\"--work-dir\").arg(&tmpdir(build))\n+           .arg(\"--output-dir\").arg(&distdir(build))\n+           .arg(\"--non-installed-overlay\").arg(&overlay)\n+           .arg(format!(\"--package-name={}-{}\", name, target))\n+           .arg(\"--component-name=rls\")\n+           .arg(\"--legacy-manifest-dirs=rustlib,cargo\");\n         build.run(&mut cmd);\n+        distdir(build).join(format!(\"{}-{}.tar.gz\", name, target))\n     }\n+}\n \n-    if target.contains(\"windows\") {\n-        let exe = tmp.join(\"exe\");\n-        let _ = fs::remove_dir_all(&exe);\n-        t!(fs::create_dir_all(exe.join(\"rustc\")));\n-        t!(fs::create_dir_all(exe.join(\"cargo\")));\n-        t!(fs::create_dir_all(exe.join(\"rls\")));\n-        t!(fs::create_dir_all(exe.join(\"rust-analysis\")));\n-        t!(fs::create_dir_all(exe.join(\"rust-docs\")));\n-        t!(fs::create_dir_all(exe.join(\"rust-std\")));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rustc\"), target))\n-                  .join(\"rustc\"),\n-             &exe.join(\"rustc\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"cargo\"), target))\n-                  .join(\"cargo\"),\n-             &exe.join(\"cargo\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-docs\"), target))\n-                  .join(\"rust-docs\"),\n-             &exe.join(\"rust-docs\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-std\"), target))\n-                  .join(format!(\"rust-std-{}\", target)),\n-             &exe.join(\"rust-std\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rls\"), target))\n-                  .join(\"rls\"),\n-             &exe.join(\"rls\"));\n-        cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-analysis\"), target))\n-                  .join(format!(\"rust-analysis-{}\", target)),\n-             &exe.join(\"rust-analysis\"));\n-\n-        t!(fs::remove_file(exe.join(\"rustc/manifest.in\")));\n-        t!(fs::remove_file(exe.join(\"cargo/manifest.in\")));\n-        t!(fs::remove_file(exe.join(\"rust-docs/manifest.in\")));\n-        t!(fs::remove_file(exe.join(\"rust-std/manifest.in\")));\n-        t!(fs::remove_file(exe.join(\"rls/manifest.in\")));\n-        t!(fs::remove_file(exe.join(\"rust-analysis/manifest.in\")));\n-\n-        if target.contains(\"windows-gnu\") {\n-            t!(fs::create_dir_all(exe.join(\"rust-mingw\")));\n-            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-mingw\"), target))\n-                      .join(\"rust-mingw\"),\n-                 &exe.join(\"rust-mingw\"));\n-            t!(fs::remove_file(exe.join(\"rust-mingw/manifest.in\")));\n-        }\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Extended {\n+    stage: u32,\n+    target: Interned<String>,\n+}\n+\n+impl Step for Extended {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_BUILD_TARGETS: bool = true;\n+    const ONLY_HOSTS: bool = true;\n \n-        install(&etc.join(\"exe/rust.iss\"), &exe, 0o644);\n-        install(&etc.join(\"exe/modpath.iss\"), &exe, 0o644);\n-        install(&etc.join(\"exe/upgrade.iss\"), &exe, 0o644);\n-        install(&etc.join(\"gfx/rust-logo.ico\"), &exe, 0o644);\n-        t!(t!(File::create(exe.join(\"LICENSE.txt\"))).write_all(license.as_bytes()));\n-\n-        // Generate exe installer\n-        let mut cmd = Command::new(\"iscc\");\n-        cmd.arg(\"rust.iss\")\n-           .current_dir(&exe);\n-        if target.contains(\"windows-gnu\") {\n-            cmd.arg(\"/dMINGW\");\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"cargo\").default_condition(builder.config.extended)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Extended {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    /// Creates a combined installer for the specified target in the provided stage.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        let compiler = builder.compiler(stage, build.build);\n+\n+        println!(\"Dist extended stage{} ({})\", stage, target);\n+\n+        let rustc_installer = builder.ensure(Rustc { stage, target });\n+        let cargo_installer = builder.ensure(Cargo { stage, target });\n+        let rls_installer = builder.ensure(Rls { stage, target });\n+        let analysis_installer = builder.ensure(Analysis { compiler, target }).unwrap();\n+        let docs_installer = builder.ensure(Docs { stage, target }).unwrap();\n+        let mingw_installer = builder.ensure(Mingw { target });\n+        let std_installer = builder.ensure(Std { compiler, target }).unwrap();\n+\n+        let tmp = tmpdir(build);\n+        let overlay = tmp.join(\"extended-overlay\");\n+        let etc = build.src.join(\"src/etc/installer\");\n+        let work = tmp.join(\"work\");\n+\n+        let _ = fs::remove_dir_all(&overlay);\n+        install(&build.src.join(\"COPYRIGHT\"), &overlay, 0o644);\n+        install(&build.src.join(\"LICENSE-APACHE\"), &overlay, 0o644);\n+        install(&build.src.join(\"LICENSE-MIT\"), &overlay, 0o644);\n+        let version = build.rust_version();\n+        t!(t!(File::create(overlay.join(\"version\"))).write_all(version.as_bytes()));\n+        install(&etc.join(\"README.md\"), &overlay, 0o644);\n+\n+        // When rust-std package split from rustc, we needed to ensure that during\n+        // upgrades rustc was upgraded before rust-std. To avoid rustc clobbering\n+        // the std files during uninstall. To do this ensure that rustc comes\n+        // before rust-std in the list below.\n+        let mut tarballs = vec![rustc_installer, cargo_installer, rls_installer,\n+                                analysis_installer, docs_installer, std_installer];\n+        if target.contains(\"pc-windows-gnu\") {\n+            tarballs.push(mingw_installer.unwrap());\n+        }\n+        let mut input_tarballs = tarballs[0].as_os_str().to_owned();\n+        for tarball in &tarballs[1..] {\n+            input_tarballs.push(\",\");\n+            input_tarballs.push(tarball);\n         }\n-        add_env(build, &mut cmd, target);\n+\n+        let mut cmd = rust_installer(builder);\n+        cmd.arg(\"combine\")\n+            .arg(\"--product-name=Rust\")\n+            .arg(\"--rel-manifest-dir=rustlib\")\n+            .arg(\"--success-message=Rust-is-ready-to-roll.\")\n+            .arg(\"--work-dir\").arg(&work)\n+            .arg(\"--output-dir\").arg(&distdir(build))\n+            .arg(format!(\"--package-name={}-{}\", pkgname(build, \"rust\"), target))\n+            .arg(\"--legacy-manifest-dirs=rustlib,cargo\")\n+            .arg(\"--input-tarballs\").arg(input_tarballs)\n+            .arg(\"--non-installed-overlay\").arg(&overlay);\n         build.run(&mut cmd);\n-        install(&exe.join(format!(\"{}-{}.exe\", pkgname(build, \"rust\"), target)),\n-                &distdir(build),\n-                0o755);\n \n-        // Generate msi installer\n-        let wix = PathBuf::from(env::var_os(\"WIX\").unwrap());\n-        let heat = wix.join(\"bin/heat.exe\");\n-        let candle = wix.join(\"bin/candle.exe\");\n-        let light = wix.join(\"bin/light.exe\");\n-\n-        let heat_flags = [\"-nologo\", \"-gg\", \"-sfrag\", \"-srd\", \"-sreg\"];\n-        build.run(Command::new(&heat)\n-                        .current_dir(&exe)\n-                        .arg(\"dir\")\n-                        .arg(\"rustc\")\n-                        .args(&heat_flags)\n-                        .arg(\"-cg\").arg(\"RustcGroup\")\n-                        .arg(\"-dr\").arg(\"Rustc\")\n-                        .arg(\"-var\").arg(\"var.RustcDir\")\n-                        .arg(\"-out\").arg(exe.join(\"RustcGroup.wxs\")));\n-        build.run(Command::new(&heat)\n-                        .current_dir(&exe)\n-                        .arg(\"dir\")\n-                        .arg(\"rust-docs\")\n-                        .args(&heat_flags)\n-                        .arg(\"-cg\").arg(\"DocsGroup\")\n-                        .arg(\"-dr\").arg(\"Docs\")\n-                        .arg(\"-var\").arg(\"var.DocsDir\")\n-                        .arg(\"-out\").arg(exe.join(\"DocsGroup.wxs\"))\n-                        .arg(\"-t\").arg(etc.join(\"msi/squash-components.xsl\")));\n-        build.run(Command::new(&heat)\n-                        .current_dir(&exe)\n-                        .arg(\"dir\")\n-                        .arg(\"cargo\")\n-                        .args(&heat_flags)\n-                        .arg(\"-cg\").arg(\"CargoGroup\")\n-                        .arg(\"-dr\").arg(\"Cargo\")\n-                        .arg(\"-var\").arg(\"var.CargoDir\")\n-                        .arg(\"-out\").arg(exe.join(\"CargoGroup.wxs\"))\n-                        .arg(\"-t\").arg(etc.join(\"msi/remove-duplicates.xsl\")));\n-        build.run(Command::new(&heat)\n-                        .current_dir(&exe)\n-                        .arg(\"dir\")\n-                        .arg(\"rust-std\")\n-                        .args(&heat_flags)\n-                        .arg(\"-cg\").arg(\"StdGroup\")\n-                        .arg(\"-dr\").arg(\"Std\")\n-                        .arg(\"-var\").arg(\"var.StdDir\")\n-                        .arg(\"-out\").arg(exe.join(\"StdGroup.wxs\")));\n-        build.run(Command::new(&heat)\n-                        .current_dir(&exe)\n-                        .arg(\"dir\")\n-                        .arg(\"rls\")\n-                        .args(&heat_flags)\n-                        .arg(\"-cg\").arg(\"RlsGroup\")\n-                        .arg(\"-dr\").arg(\"Rls\")\n-                        .arg(\"-var\").arg(\"var.RlsDir\")\n-                        .arg(\"-out\").arg(exe.join(\"RlsGroup.wxs\"))\n-                        .arg(\"-t\").arg(etc.join(\"msi/remove-duplicates.xsl\")));\n-        build.run(Command::new(&heat)\n-                        .current_dir(&exe)\n-                        .arg(\"dir\")\n-                        .arg(\"rust-analysis\")\n-                        .args(&heat_flags)\n-                        .arg(\"-cg\").arg(\"AnalysisGroup\")\n-                        .arg(\"-dr\").arg(\"Analysis\")\n-                        .arg(\"-var\").arg(\"var.AnalysisDir\")\n-                        .arg(\"-out\").arg(exe.join(\"AnalysisGroup.wxs\"))\n-                        .arg(\"-t\").arg(etc.join(\"msi/remove-duplicates.xsl\")));\n-        if target.contains(\"windows-gnu\") {\n+        let mut license = String::new();\n+        t!(t!(File::open(build.src.join(\"COPYRIGHT\"))).read_to_string(&mut license));\n+        license.push_str(\"\\n\");\n+        t!(t!(File::open(build.src.join(\"LICENSE-APACHE\"))).read_to_string(&mut license));\n+        license.push_str(\"\\n\");\n+        t!(t!(File::open(build.src.join(\"LICENSE-MIT\"))).read_to_string(&mut license));\n+\n+        let rtf = r\"{\\rtf1\\ansi\\deff0{\\fonttbl{\\f0\\fnil\\fcharset0 Arial;}}\\nowwrap\\fs18\";\n+        let mut rtf = rtf.to_string();\n+        rtf.push_str(\"\\n\");\n+        for line in license.lines() {\n+            rtf.push_str(line);\n+            rtf.push_str(\"\\\\line \");\n+        }\n+        rtf.push_str(\"}\");\n+\n+        if target.contains(\"apple-darwin\") {\n+            let pkg = tmp.join(\"pkg\");\n+            let _ = fs::remove_dir_all(&pkg);\n+            t!(fs::create_dir_all(pkg.join(\"rustc\")));\n+            t!(fs::create_dir_all(pkg.join(\"cargo\")));\n+            t!(fs::create_dir_all(pkg.join(\"rust-docs\")));\n+            t!(fs::create_dir_all(pkg.join(\"rust-std\")));\n+            t!(fs::create_dir_all(pkg.join(\"rls\")));\n+            t!(fs::create_dir_all(pkg.join(\"rust-analysis\")));\n+\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rustc\"), target)),\n+                    &pkg.join(\"rustc\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"cargo\"), target)),\n+                    &pkg.join(\"cargo\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-docs\"), target)),\n+                    &pkg.join(\"rust-docs\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-std\"), target)),\n+                    &pkg.join(\"rust-std\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rls\"), target)),\n+                    &pkg.join(\"rls\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-analysis\"), target)),\n+                    &pkg.join(\"rust-analysis\"));\n+\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rustc\"), 0o755);\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"cargo\"), 0o755);\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rust-docs\"), 0o755);\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rust-std\"), 0o755);\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rls\"), 0o755);\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"rust-analysis\"), 0o755);\n+\n+            let pkgbuild = |component: &str| {\n+                let mut cmd = Command::new(\"pkgbuild\");\n+                cmd.arg(\"--identifier\").arg(format!(\"org.rust-lang.{}\", component))\n+                    .arg(\"--scripts\").arg(pkg.join(component))\n+                    .arg(\"--nopayload\")\n+                    .arg(pkg.join(component).with_extension(\"pkg\"));\n+                build.run(&mut cmd);\n+            };\n+            pkgbuild(\"rustc\");\n+            pkgbuild(\"cargo\");\n+            pkgbuild(\"rust-docs\");\n+            pkgbuild(\"rust-std\");\n+            pkgbuild(\"rls\");\n+            pkgbuild(\"rust-analysis\");\n+\n+            // create an 'uninstall' package\n+            install(&etc.join(\"pkg/postinstall\"), &pkg.join(\"uninstall\"), 0o755);\n+            pkgbuild(\"uninstall\");\n+\n+            t!(fs::create_dir_all(pkg.join(\"res\")));\n+            t!(t!(File::create(pkg.join(\"res/LICENSE.txt\"))).write_all(license.as_bytes()));\n+            install(&etc.join(\"gfx/rust-logo.png\"), &pkg.join(\"res\"), 0o644);\n+            let mut cmd = Command::new(\"productbuild\");\n+            cmd.arg(\"--distribution\").arg(etc.join(\"pkg/Distribution.xml\"))\n+                .arg(\"--resources\").arg(pkg.join(\"res\"))\n+                .arg(distdir(build).join(format!(\"{}-{}.pkg\",\n+                                                    pkgname(build, \"rust\"),\n+                                                    target)))\n+                .arg(\"--package-path\").arg(&pkg);\n+            build.run(&mut cmd);\n+        }\n+\n+        if target.contains(\"windows\") {\n+            let exe = tmp.join(\"exe\");\n+            let _ = fs::remove_dir_all(&exe);\n+            t!(fs::create_dir_all(exe.join(\"rustc\")));\n+            t!(fs::create_dir_all(exe.join(\"cargo\")));\n+            t!(fs::create_dir_all(exe.join(\"rls\")));\n+            t!(fs::create_dir_all(exe.join(\"rust-analysis\")));\n+            t!(fs::create_dir_all(exe.join(\"rust-docs\")));\n+            t!(fs::create_dir_all(exe.join(\"rust-std\")));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rustc\"), target))\n+                        .join(\"rustc\"),\n+                    &exe.join(\"rustc\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"cargo\"), target))\n+                        .join(\"cargo\"),\n+                    &exe.join(\"cargo\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-docs\"), target))\n+                        .join(\"rust-docs\"),\n+                    &exe.join(\"rust-docs\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-std\"), target))\n+                        .join(format!(\"rust-std-{}\", target)),\n+                    &exe.join(\"rust-std\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rls\"), target))\n+                        .join(\"rls\"),\n+                    &exe.join(\"rls\"));\n+            cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-analysis\"), target))\n+                        .join(format!(\"rust-analysis-{}\", target)),\n+                    &exe.join(\"rust-analysis\"));\n+\n+            t!(fs::remove_file(exe.join(\"rustc/manifest.in\")));\n+            t!(fs::remove_file(exe.join(\"cargo/manifest.in\")));\n+            t!(fs::remove_file(exe.join(\"rust-docs/manifest.in\")));\n+            t!(fs::remove_file(exe.join(\"rust-std/manifest.in\")));\n+            t!(fs::remove_file(exe.join(\"rls/manifest.in\")));\n+            t!(fs::remove_file(exe.join(\"rust-analysis/manifest.in\")));\n+\n+            if target.contains(\"windows-gnu\") {\n+                t!(fs::create_dir_all(exe.join(\"rust-mingw\")));\n+                cp_r(&work.join(&format!(\"{}-{}\", pkgname(build, \"rust-mingw\"), target))\n+                            .join(\"rust-mingw\"),\n+                        &exe.join(\"rust-mingw\"));\n+                t!(fs::remove_file(exe.join(\"rust-mingw/manifest.in\")));\n+            }\n+\n+            install(&etc.join(\"exe/rust.iss\"), &exe, 0o644);\n+            install(&etc.join(\"exe/modpath.iss\"), &exe, 0o644);\n+            install(&etc.join(\"exe/upgrade.iss\"), &exe, 0o644);\n+            install(&etc.join(\"gfx/rust-logo.ico\"), &exe, 0o644);\n+            t!(t!(File::create(exe.join(\"LICENSE.txt\"))).write_all(license.as_bytes()));\n+\n+            // Generate exe installer\n+            let mut cmd = Command::new(\"iscc\");\n+            cmd.arg(\"rust.iss\")\n+                .current_dir(&exe);\n+            if target.contains(\"windows-gnu\") {\n+                cmd.arg(\"/dMINGW\");\n+            }\n+            add_env(build, &mut cmd, target);\n+            build.run(&mut cmd);\n+            install(&exe.join(format!(\"{}-{}.exe\", pkgname(build, \"rust\"), target)),\n+                    &distdir(build),\n+                    0o755);\n+\n+            // Generate msi installer\n+            let wix = PathBuf::from(env::var_os(\"WIX\").unwrap());\n+            let heat = wix.join(\"bin/heat.exe\");\n+            let candle = wix.join(\"bin/candle.exe\");\n+            let light = wix.join(\"bin/light.exe\");\n+\n+            let heat_flags = [\"-nologo\", \"-gg\", \"-sfrag\", \"-srd\", \"-sreg\"];\n             build.run(Command::new(&heat)\n                             .current_dir(&exe)\n                             .arg(\"dir\")\n-                            .arg(\"rust-mingw\")\n+                            .arg(\"rustc\")\n                             .args(&heat_flags)\n-                            .arg(\"-cg\").arg(\"GccGroup\")\n-                            .arg(\"-dr\").arg(\"Gcc\")\n-                            .arg(\"-var\").arg(\"var.GccDir\")\n-                            .arg(\"-out\").arg(exe.join(\"GccGroup.wxs\")));\n-        }\n+                            .arg(\"-cg\").arg(\"RustcGroup\")\n+                            .arg(\"-dr\").arg(\"Rustc\")\n+                            .arg(\"-var\").arg(\"var.RustcDir\")\n+                            .arg(\"-out\").arg(exe.join(\"RustcGroup.wxs\")));\n+            build.run(Command::new(&heat)\n+                            .current_dir(&exe)\n+                            .arg(\"dir\")\n+                            .arg(\"rust-docs\")\n+                            .args(&heat_flags)\n+                            .arg(\"-cg\").arg(\"DocsGroup\")\n+                            .arg(\"-dr\").arg(\"Docs\")\n+                            .arg(\"-var\").arg(\"var.DocsDir\")\n+                            .arg(\"-out\").arg(exe.join(\"DocsGroup.wxs\"))\n+                            .arg(\"-t\").arg(etc.join(\"msi/squash-components.xsl\")));\n+            build.run(Command::new(&heat)\n+                            .current_dir(&exe)\n+                            .arg(\"dir\")\n+                            .arg(\"cargo\")\n+                            .args(&heat_flags)\n+                            .arg(\"-cg\").arg(\"CargoGroup\")\n+                            .arg(\"-dr\").arg(\"Cargo\")\n+                            .arg(\"-var\").arg(\"var.CargoDir\")\n+                            .arg(\"-out\").arg(exe.join(\"CargoGroup.wxs\"))\n+                            .arg(\"-t\").arg(etc.join(\"msi/remove-duplicates.xsl\")));\n+            build.run(Command::new(&heat)\n+                            .current_dir(&exe)\n+                            .arg(\"dir\")\n+                            .arg(\"rust-std\")\n+                            .args(&heat_flags)\n+                            .arg(\"-cg\").arg(\"StdGroup\")\n+                            .arg(\"-dr\").arg(\"Std\")\n+                            .arg(\"-var\").arg(\"var.StdDir\")\n+                            .arg(\"-out\").arg(exe.join(\"StdGroup.wxs\")));\n+            build.run(Command::new(&heat)\n+                            .current_dir(&exe)\n+                            .arg(\"dir\")\n+                            .arg(\"rls\")\n+                            .args(&heat_flags)\n+                            .arg(\"-cg\").arg(\"RlsGroup\")\n+                            .arg(\"-dr\").arg(\"Rls\")\n+                            .arg(\"-var\").arg(\"var.RlsDir\")\n+                            .arg(\"-out\").arg(exe.join(\"RlsGroup.wxs\"))\n+                            .arg(\"-t\").arg(etc.join(\"msi/remove-duplicates.xsl\")));\n+            build.run(Command::new(&heat)\n+                            .current_dir(&exe)\n+                            .arg(\"dir\")\n+                            .arg(\"rust-analysis\")\n+                            .args(&heat_flags)\n+                            .arg(\"-cg\").arg(\"AnalysisGroup\")\n+                            .arg(\"-dr\").arg(\"Analysis\")\n+                            .arg(\"-var\").arg(\"var.AnalysisDir\")\n+                            .arg(\"-out\").arg(exe.join(\"AnalysisGroup.wxs\"))\n+                            .arg(\"-t\").arg(etc.join(\"msi/remove-duplicates.xsl\")));\n+            if target.contains(\"windows-gnu\") {\n+                build.run(Command::new(&heat)\n+                                .current_dir(&exe)\n+                                .arg(\"dir\")\n+                                .arg(\"rust-mingw\")\n+                                .args(&heat_flags)\n+                                .arg(\"-cg\").arg(\"GccGroup\")\n+                                .arg(\"-dr\").arg(\"Gcc\")\n+                                .arg(\"-var\").arg(\"var.GccDir\")\n+                                .arg(\"-out\").arg(exe.join(\"GccGroup.wxs\")));\n+            }\n \n-        let candle = |input: &Path| {\n-            let output = exe.join(input.file_stem().unwrap())\n-                            .with_extension(\"wixobj\");\n-            let arch = if target.contains(\"x86_64\") {\"x64\"} else {\"x86\"};\n-            let mut cmd = Command::new(&candle);\n-            cmd.current_dir(&exe)\n-               .arg(\"-nologo\")\n-               .arg(\"-dRustcDir=rustc\")\n-               .arg(\"-dDocsDir=rust-docs\")\n-               .arg(\"-dCargoDir=cargo\")\n-               .arg(\"-dStdDir=rust-std\")\n-               .arg(\"-dRlsDir=rls\")\n-               .arg(\"-dAnalysisDir=rust-analysis\")\n-               .arg(\"-arch\").arg(&arch)\n-               .arg(\"-out\").arg(&output)\n-               .arg(&input);\n-            add_env(build, &mut cmd, target);\n+            let candle = |input: &Path| {\n+                let output = exe.join(input.file_stem().unwrap())\n+                                .with_extension(\"wixobj\");\n+                let arch = if target.contains(\"x86_64\") {\"x64\"} else {\"x86\"};\n+                let mut cmd = Command::new(&candle);\n+                cmd.current_dir(&exe)\n+                    .arg(\"-nologo\")\n+                    .arg(\"-dRustcDir=rustc\")\n+                    .arg(\"-dDocsDir=rust-docs\")\n+                    .arg(\"-dCargoDir=cargo\")\n+                    .arg(\"-dStdDir=rust-std\")\n+                    .arg(\"-dRlsDir=rls\")\n+                    .arg(\"-dAnalysisDir=rust-analysis\")\n+                    .arg(\"-arch\").arg(&arch)\n+                    .arg(\"-out\").arg(&output)\n+                    .arg(&input);\n+                add_env(build, &mut cmd, target);\n+\n+                if target.contains(\"windows-gnu\") {\n+                    cmd.arg(\"-dGccDir=rust-mingw\");\n+                }\n+                build.run(&mut cmd);\n+            };\n+            candle(&etc.join(\"msi/rust.wxs\"));\n+            candle(&etc.join(\"msi/ui.wxs\"));\n+            candle(&etc.join(\"msi/rustwelcomedlg.wxs\"));\n+            candle(\"RustcGroup.wxs\".as_ref());\n+            candle(\"DocsGroup.wxs\".as_ref());\n+            candle(\"CargoGroup.wxs\".as_ref());\n+            candle(\"StdGroup.wxs\".as_ref());\n+            candle(\"RlsGroup.wxs\".as_ref());\n+            candle(\"AnalysisGroup.wxs\".as_ref());\n \n             if target.contains(\"windows-gnu\") {\n-               cmd.arg(\"-dGccDir=rust-mingw\");\n+                candle(\"GccGroup.wxs\".as_ref());\n             }\n-            build.run(&mut cmd);\n-        };\n-        candle(&etc.join(\"msi/rust.wxs\"));\n-        candle(&etc.join(\"msi/ui.wxs\"));\n-        candle(&etc.join(\"msi/rustwelcomedlg.wxs\"));\n-        candle(\"RustcGroup.wxs\".as_ref());\n-        candle(\"DocsGroup.wxs\".as_ref());\n-        candle(\"CargoGroup.wxs\".as_ref());\n-        candle(\"StdGroup.wxs\".as_ref());\n-        candle(\"RlsGroup.wxs\".as_ref());\n-        candle(\"AnalysisGroup.wxs\".as_ref());\n-\n-        if target.contains(\"windows-gnu\") {\n-            candle(\"GccGroup.wxs\".as_ref());\n-        }\n \n-        t!(t!(File::create(exe.join(\"LICENSE.rtf\"))).write_all(rtf.as_bytes()));\n-        install(&etc.join(\"gfx/banner.bmp\"), &exe, 0o644);\n-        install(&etc.join(\"gfx/dialogbg.bmp\"), &exe, 0o644);\n-\n-        let filename = format!(\"{}-{}.msi\", pkgname(build, \"rust\"), target);\n-        let mut cmd = Command::new(&light);\n-        cmd.arg(\"-nologo\")\n-           .arg(\"-ext\").arg(\"WixUIExtension\")\n-           .arg(\"-ext\").arg(\"WixUtilExtension\")\n-           .arg(\"-out\").arg(exe.join(&filename))\n-           .arg(\"rust.wixobj\")\n-           .arg(\"ui.wixobj\")\n-           .arg(\"rustwelcomedlg.wixobj\")\n-           .arg(\"RustcGroup.wixobj\")\n-           .arg(\"DocsGroup.wixobj\")\n-           .arg(\"CargoGroup.wixobj\")\n-           .arg(\"StdGroup.wixobj\")\n-           .arg(\"RlsGroup.wixobj\")\n-           .arg(\"AnalysisGroup.wixobj\")\n-           .current_dir(&exe);\n-\n-        if target.contains(\"windows-gnu\") {\n-           cmd.arg(\"GccGroup.wixobj\");\n-        }\n-        // ICE57 wrongly complains about the shortcuts\n-        cmd.arg(\"-sice:ICE57\");\n+            t!(t!(File::create(exe.join(\"LICENSE.rtf\"))).write_all(rtf.as_bytes()));\n+            install(&etc.join(\"gfx/banner.bmp\"), &exe, 0o644);\n+            install(&etc.join(\"gfx/dialogbg.bmp\"), &exe, 0o644);\n+\n+            let filename = format!(\"{}-{}.msi\", pkgname(build, \"rust\"), target);\n+            let mut cmd = Command::new(&light);\n+            cmd.arg(\"-nologo\")\n+                .arg(\"-ext\").arg(\"WixUIExtension\")\n+                .arg(\"-ext\").arg(\"WixUtilExtension\")\n+                .arg(\"-out\").arg(exe.join(&filename))\n+                .arg(\"rust.wixobj\")\n+                .arg(\"ui.wixobj\")\n+                .arg(\"rustwelcomedlg.wixobj\")\n+                .arg(\"RustcGroup.wixobj\")\n+                .arg(\"DocsGroup.wixobj\")\n+                .arg(\"CargoGroup.wixobj\")\n+                .arg(\"StdGroup.wixobj\")\n+                .arg(\"RlsGroup.wixobj\")\n+                .arg(\"AnalysisGroup.wixobj\")\n+                .current_dir(&exe);\n \n-        build.run(&mut cmd);\n+            if target.contains(\"windows-gnu\") {\n+                cmd.arg(\"GccGroup.wixobj\");\n+            }\n+            // ICE57 wrongly complains about the shortcuts\n+            cmd.arg(\"-sice:ICE57\");\n+\n+            build.run(&mut cmd);\n \n-        t!(fs::rename(exe.join(&filename), distdir(build).join(&filename)));\n+            t!(fs::rename(exe.join(&filename), distdir(build).join(&filename)));\n+        }\n     }\n }\n \n-fn add_env(build: &Build, cmd: &mut Command, target: &str) {\n+fn add_env(build: &Build, cmd: &mut Command, target: Interned<String>) {\n     let mut parts = channel::CFG_RELEASE_NUM.split('.');\n     cmd.env(\"CFG_RELEASE_INFO\", build.rust_version())\n        .env(\"CFG_RELEASE_NUM\", channel::CFG_RELEASE_NUM)\n@@ -1198,35 +1498,53 @@ fn add_env(build: &Build, cmd: &mut Command, target: &str) {\n     }\n }\n \n-pub fn hash_and_sign(build: &Build) {\n-    let compiler = Compiler::new(0, &build.build);\n-    let mut cmd = build.tool_cmd(&compiler, \"build-manifest\");\n-    let sign = build.config.dist_sign_folder.as_ref().unwrap_or_else(|| {\n-        panic!(\"\\n\\nfailed to specify `dist.sign-folder` in `config.toml`\\n\\n\")\n-    });\n-    let addr = build.config.dist_upload_addr.as_ref().unwrap_or_else(|| {\n-        panic!(\"\\n\\nfailed to specify `dist.upload-addr` in `config.toml`\\n\\n\")\n-    });\n-    let file = build.config.dist_gpg_password_file.as_ref().unwrap_or_else(|| {\n-        panic!(\"\\n\\nfailed to specify `dist.gpg-password-file` in `config.toml`\\n\\n\")\n-    });\n-    let mut pass = String::new();\n-    t!(t!(File::open(&file)).read_to_string(&mut pass));\n-\n-    let today = output(Command::new(\"date\").arg(\"+%Y-%m-%d\"));\n-\n-    cmd.arg(sign);\n-    cmd.arg(distdir(build));\n-    cmd.arg(today.trim());\n-    cmd.arg(build.rust_package_vers());\n-    cmd.arg(build.package_vers(&build.release_num(\"cargo\")));\n-    cmd.arg(build.package_vers(&build.release_num(\"rls\")));\n-    cmd.arg(addr);\n-\n-    t!(fs::create_dir_all(distdir(build)));\n-\n-    let mut child = t!(cmd.stdin(Stdio::piped()).spawn());\n-    t!(child.stdin.take().unwrap().write_all(pass.as_bytes()));\n-    let status = t!(child.wait());\n-    assert!(status.success());\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct HashSign;\n+\n+impl Step for HashSign {\n+    type Output = ();\n+    const ONLY_BUILD_TARGETS: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+    const ONLY_BUILD: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"hash-and-sign\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(HashSign);\n+    }\n+\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let mut cmd = builder.tool_cmd(Tool::BuildManifest);\n+        let sign = build.config.dist_sign_folder.as_ref().unwrap_or_else(|| {\n+            panic!(\"\\n\\nfailed to specify `dist.sign-folder` in `config.toml`\\n\\n\")\n+        });\n+        let addr = build.config.dist_upload_addr.as_ref().unwrap_or_else(|| {\n+            panic!(\"\\n\\nfailed to specify `dist.upload-addr` in `config.toml`\\n\\n\")\n+        });\n+        let file = build.config.dist_gpg_password_file.as_ref().unwrap_or_else(|| {\n+            panic!(\"\\n\\nfailed to specify `dist.gpg-password-file` in `config.toml`\\n\\n\")\n+        });\n+        let mut pass = String::new();\n+        t!(t!(File::open(&file)).read_to_string(&mut pass));\n+\n+        let today = output(Command::new(\"date\").arg(\"+%Y-%m-%d\"));\n+\n+        cmd.arg(sign);\n+        cmd.arg(distdir(build));\n+        cmd.arg(today.trim());\n+        cmd.arg(build.rust_package_vers());\n+        cmd.arg(build.package_vers(&build.release_num(\"cargo\")));\n+        cmd.arg(build.package_vers(&build.release_num(\"rls\")));\n+        cmd.arg(addr);\n+\n+        t!(fs::create_dir_all(distdir(build)));\n+\n+        let mut child = t!(cmd.stdin(Stdio::piped()).spawn());\n+        t!(child.stdin.take().unwrap().write_all(pass.as_bytes()));\n+        let status = t!(child.wait());\n+        assert!(status.success());\n+    }\n }"}, {"sha": "8834fa24d698314a9e92915484bafdb61f574ea5", "filename": "src/bootstrap/doc.rs", "status": "modified", "additions": 588, "deletions": 269, "changes": 857, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fdoc.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -20,86 +20,233 @@\n use std::fs::{self, File};\n use std::io::prelude::*;\n use std::io;\n-use std::path::Path;\n+use std::path::{PathBuf, Path};\n use std::process::Command;\n \n-use {Build, Compiler, Mode};\n-use util::{cp_r, symlink_dir};\n+use Mode;\n use build_helper::up_to_date;\n \n-/// Invoke `rustbook` for `target` for the doc book `name`.\n-///\n-/// This will not actually generate any documentation if the documentation has\n-/// already been generated.\n-pub fn rustbook(build: &Build, target: &str, name: &str) {\n-    let src = build.src.join(\"src/doc\");\n-    rustbook_src(build, target, name, &src);\n+use util::{cp_r, symlink_dir};\n+use builder::{Builder, RunConfig, ShouldRun, Step};\n+use tool::Tool;\n+use compile;\n+use cache::{INTERNER, Interned};\n+\n+macro_rules! book {\n+    ($($name:ident, $path:expr, $book_name:expr;)+) => {\n+        $(\n+            #[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+        pub struct $name {\n+            target: Interned<String>,\n+        }\n+\n+        impl Step for $name {\n+            type Output = ();\n+            const DEFAULT: bool = true;\n+\n+            fn should_run(run: ShouldRun) -> ShouldRun {\n+                let builder = run.builder;\n+                run.path($path).default_condition(builder.build.config.docs)\n+            }\n+\n+            fn make_run(run: RunConfig) {\n+                run.builder.ensure($name {\n+                    target: run.target,\n+                });\n+            }\n+\n+            fn run(self, builder: &Builder) {\n+                builder.ensure(Rustbook {\n+                    target: self.target,\n+                    name: INTERNER.intern_str($book_name),\n+                })\n+            }\n+        }\n+        )+\n+    }\n }\n \n-/// Invoke `rustbook` for `target` for the doc book `name` from the `src` path.\n-///\n-/// This will not actually generate any documentation if the documentation has\n-/// already been generated.\n-pub fn rustbook_src(build: &Build, target: &str, name: &str, src: &Path) {\n-    let out = build.doc_out(target);\n-    t!(fs::create_dir_all(&out));\n-\n-    let out = out.join(name);\n-    let compiler = Compiler::new(0, &build.build);\n-    let src = src.join(name);\n-    let index = out.join(\"index.html\");\n-    let rustbook = build.tool(&compiler, \"rustbook\");\n-    if up_to_date(&src, &index) && up_to_date(&rustbook, &index) {\n-        return\n+book!(\n+    Nomicon, \"src/doc/book\", \"nomicon\";\n+    Reference, \"src/doc/reference\", \"reference\";\n+);\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+struct Rustbook {\n+    target: Interned<String>,\n+    name: Interned<String>,\n+}\n+\n+impl Step for Rustbook {\n+    type Output = ();\n+\n+    // rustbook is never directly called, and only serves as a shim for the nomicon and the\n+    // reference.\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n+    }\n+\n+    /// Invoke `rustbook` for `target` for the doc book `name`.\n+    ///\n+    /// This will not actually generate any documentation if the documentation has\n+    /// already been generated.\n+    fn run(self, builder: &Builder) {\n+        let src = builder.build.src.join(\"src/doc\");\n+        builder.ensure(RustbookSrc {\n+            target: self.target,\n+            name: self.name,\n+            src: INTERNER.intern_path(src),\n+        });\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct UnstableBook {\n+    target: Interned<String>,\n+}\n+\n+impl Step for UnstableBook {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/doc/unstable-book\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(UnstableBook {\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) {\n+        builder.ensure(UnstableBookGen {\n+            target: self.target,\n+        });\n+        builder.ensure(RustbookSrc {\n+            target: self.target,\n+            name: INTERNER.intern_str(\"unstable-book\"),\n+            src: builder.build.md_doc_out(self.target),\n+        })\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+struct RustbookSrc {\n+    target: Interned<String>,\n+    name: Interned<String>,\n+    src: Interned<PathBuf>,\n+}\n+\n+impl Step for RustbookSrc {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n     }\n-    println!(\"Rustbook ({}) - {}\", target, name);\n-    let _ = fs::remove_dir_all(&out);\n-    build.run(build.tool_cmd(&compiler, \"rustbook\")\n-                   .arg(\"build\")\n-                   .arg(&src)\n-                   .arg(\"-d\")\n-                   .arg(out));\n+\n+    /// Invoke `rustbook` for `target` for the doc book `name` from the `src` path.\n+    ///\n+    /// This will not actually generate any documentation if the documentation has\n+    /// already been generated.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let name = self.name;\n+        let src = self.src;\n+        let out = build.doc_out(target);\n+        t!(fs::create_dir_all(&out));\n+\n+        let out = out.join(name);\n+        let src = src.join(name);\n+        let index = out.join(\"index.html\");\n+        let rustbook = builder.tool_exe(Tool::Rustbook);\n+        if up_to_date(&src, &index) && up_to_date(&rustbook, &index) {\n+            return\n+        }\n+        println!(\"Rustbook ({}) - {}\", target, name);\n+        let _ = fs::remove_dir_all(&out);\n+        build.run(builder.tool_cmd(Tool::Rustbook)\n+                       .arg(\"build\")\n+                       .arg(&src)\n+                       .arg(\"-d\")\n+                       .arg(out));\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct TheBook {\n+    target: Interned<String>,\n+    name: &'static str,\n }\n \n-/// Build the book and associated stuff.\n-///\n-/// We need to build:\n-///\n-/// * Book (first edition)\n-/// * Book (second edition)\n-/// * Index page\n-/// * Redirect pages\n-pub fn book(build: &Build, target: &str, name: &str) {\n-    // build book first edition\n-    rustbook(build, target, &format!(\"{}/first-edition\", name));\n-\n-    // build book second edition\n-    rustbook(build, target, &format!(\"{}/second-edition\", name));\n-\n-    // build the index page\n-    let index = format!(\"{}/index.md\", name);\n-    println!(\"Documenting book index ({})\", target);\n-    invoke_rustdoc(build, target, &index);\n-\n-    // build the redirect pages\n-    println!(\"Documenting book redirect pages ({})\", target);\n-    for file in t!(fs::read_dir(build.src.join(\"src/doc/book/redirects\"))) {\n-        let file = t!(file);\n-        let path = file.path();\n-        let path = path.to_str().unwrap();\n-\n-        invoke_rustdoc(build, target, path);\n+impl Step for TheBook {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/doc/book\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(TheBook {\n+            target: run.target,\n+            name: \"book\",\n+        });\n+    }\n+\n+    /// Build the book and associated stuff.\n+    ///\n+    /// We need to build:\n+    ///\n+    /// * Book (first edition)\n+    /// * Book (second edition)\n+    /// * Index page\n+    /// * Redirect pages\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let name = self.name;\n+        // build book first edition\n+        builder.ensure(Rustbook {\n+            target: target,\n+            name: INTERNER.intern_string(format!(\"{}/first-edition\", name)),\n+        });\n+\n+        // build book second edition\n+        builder.ensure(Rustbook {\n+            target: target,\n+            name: INTERNER.intern_string(format!(\"{}/second-edition\", name)),\n+        });\n+\n+        // build the index page\n+        let index = format!(\"{}/index.md\", name);\n+        println!(\"Documenting book index ({})\", target);\n+        invoke_rustdoc(builder, target, &index);\n+\n+        // build the redirect pages\n+        println!(\"Documenting book redirect pages ({})\", target);\n+        for file in t!(fs::read_dir(build.src.join(\"src/doc/book/redirects\"))) {\n+            let file = t!(file);\n+            let path = file.path();\n+            let path = path.to_str().unwrap();\n+\n+            invoke_rustdoc(builder, target, path);\n+        }\n     }\n }\n \n-fn invoke_rustdoc(build: &Build, target: &str, markdown: &str) {\n+fn invoke_rustdoc(builder: &Builder, target: Interned<String>, markdown: &str) {\n+    let build = builder.build;\n     let out = build.doc_out(target);\n \n-    let compiler = Compiler::new(0, &build.build);\n+    let compiler = builder.compiler(0, build.build);\n \n     let path = build.src.join(\"src/doc\").join(markdown);\n \n-    let rustdoc = build.rustdoc(&compiler);\n+    let rustdoc = builder.rustdoc(compiler);\n \n     let favicon = build.src.join(\"src/doc/favicon.inc\");\n     let footer = build.src.join(\"src/doc/footer.inc\");\n@@ -118,7 +265,7 @@ fn invoke_rustdoc(build: &Build, target: &str, markdown: &str) {\n \n     let mut cmd = Command::new(&rustdoc);\n \n-    build.add_rustc_lib_path(&compiler, &mut cmd);\n+    builder.add_rustc_lib_path(compiler, &mut cmd);\n \n     let out = out.join(\"book\");\n \n@@ -137,242 +284,414 @@ fn invoke_rustdoc(build: &Build, target: &str, markdown: &str) {\n     build.run(&mut cmd);\n }\n \n-/// Generates all standalone documentation as compiled by the rustdoc in `stage`\n-/// for the `target` into `out`.\n-///\n-/// This will list all of `src/doc` looking for markdown files and appropriately\n-/// perform transformations like substituting `VERSION`, `SHORT_HASH`, and\n-/// `STAMP` alongw ith providing the various header/footer HTML we've cutomized.\n-///\n-/// In the end, this is just a glorified wrapper around rustdoc!\n-pub fn standalone(build: &Build, target: &str) {\n-    println!(\"Documenting standalone ({})\", target);\n-    let out = build.doc_out(target);\n-    t!(fs::create_dir_all(&out));\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Standalone {\n+    target: Interned<String>,\n+}\n \n-    let compiler = Compiler::new(0, &build.build);\n+impl Step for Standalone {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n \n-    let favicon = build.src.join(\"src/doc/favicon.inc\");\n-    let footer = build.src.join(\"src/doc/footer.inc\");\n-    let full_toc = build.src.join(\"src/doc/full-toc.inc\");\n-    t!(fs::copy(build.src.join(\"src/doc/rust.css\"), out.join(\"rust.css\")));\n-\n-    let version_input = build.src.join(\"src/doc/version_info.html.template\");\n-    let version_info = out.join(\"version_info.html\");\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/doc\").default_condition(builder.build.config.docs)\n+    }\n \n-    if !up_to_date(&version_input, &version_info) {\n-        let mut info = String::new();\n-        t!(t!(File::open(&version_input)).read_to_string(&mut info));\n-        let info = info.replace(\"VERSION\", &build.rust_release())\n-                       .replace(\"SHORT_HASH\", build.rust_info.sha_short().unwrap_or(\"\"))\n-                       .replace(\"STAMP\", build.rust_info.sha().unwrap_or(\"\"));\n-        t!(t!(File::create(&version_info)).write_all(info.as_bytes()));\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Standalone {\n+            target: run.target,\n+        });\n     }\n \n-    for file in t!(fs::read_dir(build.src.join(\"src/doc\"))) {\n-        let file = t!(file);\n-        let path = file.path();\n-        let filename = path.file_name().unwrap().to_str().unwrap();\n-        if !filename.ends_with(\".md\") || filename == \"README.md\" {\n-            continue\n+    /// Generates all standalone documentation as compiled by the rustdoc in `stage`\n+    /// for the `target` into `out`.\n+    ///\n+    /// This will list all of `src/doc` looking for markdown files and appropriately\n+    /// perform transformations like substituting `VERSION`, `SHORT_HASH`, and\n+    /// `STAMP` alongw ith providing the various header/footer HTML we've cutomized.\n+    ///\n+    /// In the end, this is just a glorified wrapper around rustdoc!\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        println!(\"Documenting standalone ({})\", target);\n+        let out = build.doc_out(target);\n+        t!(fs::create_dir_all(&out));\n+\n+        let compiler = builder.compiler(0, build.build);\n+\n+        let favicon = build.src.join(\"src/doc/favicon.inc\");\n+        let footer = build.src.join(\"src/doc/footer.inc\");\n+        let full_toc = build.src.join(\"src/doc/full-toc.inc\");\n+        t!(fs::copy(build.src.join(\"src/doc/rust.css\"), out.join(\"rust.css\")));\n+\n+        let version_input = build.src.join(\"src/doc/version_info.html.template\");\n+        let version_info = out.join(\"version_info.html\");\n+\n+        if !up_to_date(&version_input, &version_info) {\n+            let mut info = String::new();\n+            t!(t!(File::open(&version_input)).read_to_string(&mut info));\n+            let info = info.replace(\"VERSION\", &build.rust_release())\n+                           .replace(\"SHORT_HASH\", build.rust_info.sha_short().unwrap_or(\"\"))\n+                           .replace(\"STAMP\", build.rust_info.sha().unwrap_or(\"\"));\n+            t!(t!(File::create(&version_info)).write_all(info.as_bytes()));\n         }\n \n-        let html = out.join(filename).with_extension(\"html\");\n-        let rustdoc = build.rustdoc(&compiler);\n-        if up_to_date(&path, &html) &&\n-           up_to_date(&footer, &html) &&\n-           up_to_date(&favicon, &html) &&\n-           up_to_date(&full_toc, &html) &&\n-           up_to_date(&version_info, &html) &&\n-           up_to_date(&rustdoc, &html) {\n-            continue\n+        for file in t!(fs::read_dir(build.src.join(\"src/doc\"))) {\n+            let file = t!(file);\n+            let path = file.path();\n+            let filename = path.file_name().unwrap().to_str().unwrap();\n+            if !filename.ends_with(\".md\") || filename == \"README.md\" {\n+                continue\n+            }\n+\n+            let html = out.join(filename).with_extension(\"html\");\n+            let rustdoc = builder.rustdoc(compiler);\n+            if up_to_date(&path, &html) &&\n+               up_to_date(&footer, &html) &&\n+               up_to_date(&favicon, &html) &&\n+               up_to_date(&full_toc, &html) &&\n+               up_to_date(&version_info, &html) &&\n+               up_to_date(&rustdoc, &html) {\n+                continue\n+            }\n+\n+            let mut cmd = Command::new(&rustdoc);\n+            builder.add_rustc_lib_path(compiler, &mut cmd);\n+            cmd.arg(\"--html-after-content\").arg(&footer)\n+               .arg(\"--html-before-content\").arg(&version_info)\n+               .arg(\"--html-in-header\").arg(&favicon)\n+               .arg(\"--markdown-playground-url\")\n+               .arg(\"https://play.rust-lang.org/\")\n+               .arg(\"-o\").arg(&out)\n+               .arg(&path);\n+\n+            if filename == \"not_found.md\" {\n+                cmd.arg(\"--markdown-no-toc\")\n+                   .arg(\"--markdown-css\")\n+                   .arg(\"https://doc.rust-lang.org/rust.css\");\n+            } else {\n+                cmd.arg(\"--markdown-css\").arg(\"rust.css\");\n+            }\n+            build.run(&mut cmd);\n         }\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Std {\n+    stage: u32,\n+    target: Interned<String>,\n+}\n+\n+impl Step for Std {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n \n-        let mut cmd = Command::new(&rustdoc);\n-        build.add_rustc_lib_path(&compiler, &mut cmd);\n-        cmd.arg(\"--html-after-content\").arg(&footer)\n-           .arg(\"--html-before-content\").arg(&version_info)\n-           .arg(\"--html-in-header\").arg(&favicon)\n-           .arg(\"--markdown-playground-url\")\n-           .arg(\"https://play.rust-lang.org/\")\n-           .arg(\"-o\").arg(&out)\n-           .arg(&path);\n-\n-        if filename == \"not_found.md\" {\n-            cmd.arg(\"--markdown-no-toc\")\n-               .arg(\"--markdown-css\")\n-               .arg(\"https://doc.rust-lang.org/rust.css\");\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.krate(\"std\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Std {\n+            stage: run.builder.top_stage,\n+            target: run.target\n+        });\n+    }\n+\n+    /// Compile all standard library documentation.\n+    ///\n+    /// This will generate all documentation for the standard library and its\n+    /// dependencies. This is largely just a wrapper around `cargo doc`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        println!(\"Documenting stage{} std ({})\", stage, target);\n+        let out = build.doc_out(target);\n+        t!(fs::create_dir_all(&out));\n+        let compiler = builder.compiler(stage, build.build);\n+        let compiler = if build.force_use_stage1(compiler, target) {\n+            builder.compiler(1, compiler.host)\n         } else {\n-            cmd.arg(\"--markdown-css\").arg(\"rust.css\");\n+            compiler\n+        };\n+\n+        builder.ensure(compile::Std { compiler, target });\n+        let out_dir = build.stage_out(compiler, Mode::Libstd)\n+                           .join(target).join(\"doc\");\n+        let rustdoc = builder.rustdoc(compiler);\n+\n+        // Here what we're doing is creating a *symlink* (directory junction on\n+        // Windows) to the final output location. This is not done as an\n+        // optimization but rather for correctness. We've got three trees of\n+        // documentation, one for std, one for test, and one for rustc. It's then\n+        // our job to merge them all together.\n+        //\n+        // Unfortunately rustbuild doesn't know nearly as well how to merge doc\n+        // trees as rustdoc does itself, so instead of actually having three\n+        // separate trees we just have rustdoc output to the same location across\n+        // all of them.\n+        //\n+        // This way rustdoc generates output directly into the output, and rustdoc\n+        // will also directly handle merging.\n+        let my_out = build.crate_doc_out(target);\n+        build.clear_if_dirty(&my_out, &rustdoc);\n+        t!(symlink_dir_force(&my_out, &out_dir));\n+\n+        let mut cargo = builder.cargo(compiler, Mode::Libstd, target, \"doc\");\n+        cargo.arg(\"--manifest-path\")\n+             .arg(build.src.join(\"src/libstd/Cargo.toml\"))\n+             .arg(\"--features\").arg(build.std_features());\n+\n+        // We don't want to build docs for internal std dependencies unless\n+        // in compiler-docs mode. When not in that mode, we whitelist the crates\n+        // for which docs must be built.\n+        if !build.config.compiler_docs {\n+            cargo.arg(\"--no-deps\");\n+            for krate in &[\"alloc\", \"collections\", \"core\", \"std\", \"std_unicode\"] {\n+                cargo.arg(\"-p\").arg(krate);\n+                // Create all crate output directories first to make sure rustdoc uses\n+                // relative links.\n+                // FIXME: Cargo should probably do this itself.\n+                t!(fs::create_dir_all(out_dir.join(krate)));\n+            }\n         }\n-        build.run(&mut cmd);\n+\n+\n+        build.run(&mut cargo);\n+        cp_r(&my_out, &out);\n     }\n }\n \n-/// Compile all standard library documentation.\n-///\n-/// This will generate all documentation for the standard library and its\n-/// dependencies. This is largely just a wrapper around `cargo doc`.\n-pub fn std(build: &Build, stage: u32, target: &str) {\n-    println!(\"Documenting stage{} std ({})\", stage, target);\n-    let out = build.doc_out(target);\n-    t!(fs::create_dir_all(&out));\n-    let compiler = Compiler::new(stage, &build.build);\n-    let compiler = if build.force_use_stage1(&compiler, target) {\n-        Compiler::new(1, compiler.host)\n-    } else {\n-        compiler\n-    };\n-    let out_dir = build.stage_out(&compiler, Mode::Libstd)\n-                       .join(target).join(\"doc\");\n-    let rustdoc = build.rustdoc(&compiler);\n-\n-    // Here what we're doing is creating a *symlink* (directory junction on\n-    // Windows) to the final output location. This is not done as an\n-    // optimization but rather for correctness. We've got three trees of\n-    // documentation, one for std, one for test, and one for rustc. It's then\n-    // our job to merge them all together.\n-    //\n-    // Unfortunately rustbuild doesn't know nearly as well how to merge doc\n-    // trees as rustdoc does itself, so instead of actually having three\n-    // separate trees we just have rustdoc output to the same location across\n-    // all of them.\n-    //\n-    // This way rustdoc generates output directly into the output, and rustdoc\n-    // will also directly handle merging.\n-    let my_out = build.crate_doc_out(target);\n-    build.clear_if_dirty(&my_out, &rustdoc);\n-    t!(symlink_dir_force(&my_out, &out_dir));\n-\n-    let mut cargo = build.cargo(&compiler, Mode::Libstd, target, \"doc\");\n-    cargo.arg(\"--manifest-path\")\n-         .arg(build.src.join(\"src/libstd/Cargo.toml\"))\n-         .arg(\"--features\").arg(build.std_features());\n-\n-    // We don't want to build docs for internal std dependencies unless\n-    // in compiler-docs mode. When not in that mode, we whitelist the crates\n-    // for which docs must be built.\n-    if !build.config.compiler_docs {\n-        cargo.arg(\"--no-deps\");\n-        for krate in &[\"alloc\", \"collections\", \"core\", \"std\", \"std_unicode\"] {\n-            cargo.arg(\"-p\").arg(krate);\n-            // Create all crate output directories first to make sure rustdoc uses\n-            // relative links.\n-            // FIXME: Cargo should probably do this itself.\n-            t!(fs::create_dir_all(out_dir.join(krate)));\n-        }\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Test {\n+    stage: u32,\n+    target: Interned<String>,\n+}\n+\n+impl Step for Test {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.krate(\"test\").default_condition(builder.config.compiler_docs)\n     }\n \n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Test {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n \n-    build.run(&mut cargo);\n-    cp_r(&my_out, &out);\n+    /// Compile all libtest documentation.\n+    ///\n+    /// This will generate all documentation for libtest and its dependencies. This\n+    /// is largely just a wrapper around `cargo doc`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        println!(\"Documenting stage{} test ({})\", stage, target);\n+        let out = build.doc_out(target);\n+        t!(fs::create_dir_all(&out));\n+        let compiler = builder.compiler(stage, build.build);\n+        let compiler = if build.force_use_stage1(compiler, target) {\n+            builder.compiler(1, compiler.host)\n+        } else {\n+            compiler\n+        };\n+\n+        // Build libstd docs so that we generate relative links\n+        builder.ensure(Std { stage, target });\n+\n+        builder.ensure(compile::Test { compiler, target });\n+        let out_dir = build.stage_out(compiler, Mode::Libtest)\n+                           .join(target).join(\"doc\");\n+        let rustdoc = builder.rustdoc(compiler);\n+\n+        // See docs in std above for why we symlink\n+        let my_out = build.crate_doc_out(target);\n+        build.clear_if_dirty(&my_out, &rustdoc);\n+        t!(symlink_dir_force(&my_out, &out_dir));\n+\n+        let mut cargo = builder.cargo(compiler, Mode::Libtest, target, \"doc\");\n+        cargo.arg(\"--manifest-path\")\n+             .arg(build.src.join(\"src/libtest/Cargo.toml\"));\n+        build.run(&mut cargo);\n+        cp_r(&my_out, &out);\n+    }\n }\n \n-/// Compile all libtest documentation.\n-///\n-/// This will generate all documentation for libtest and its dependencies. This\n-/// is largely just a wrapper around `cargo doc`.\n-pub fn test(build: &Build, stage: u32, target: &str) {\n-    println!(\"Documenting stage{} test ({})\", stage, target);\n-    let out = build.doc_out(target);\n-    t!(fs::create_dir_all(&out));\n-    let compiler = Compiler::new(stage, &build.build);\n-    let compiler = if build.force_use_stage1(&compiler, target) {\n-        Compiler::new(1, compiler.host)\n-    } else {\n-        compiler\n-    };\n-    let out_dir = build.stage_out(&compiler, Mode::Libtest)\n-                       .join(target).join(\"doc\");\n-    let rustdoc = build.rustdoc(&compiler);\n-\n-    // See docs in std above for why we symlink\n-    let my_out = build.crate_doc_out(target);\n-    build.clear_if_dirty(&my_out, &rustdoc);\n-    t!(symlink_dir_force(&my_out, &out_dir));\n-\n-    let mut cargo = build.cargo(&compiler, Mode::Libtest, target, \"doc\");\n-    cargo.arg(\"--manifest-path\")\n-         .arg(build.src.join(\"src/libtest/Cargo.toml\"));\n-    build.run(&mut cargo);\n-    cp_r(&my_out, &out);\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Rustc {\n+    stage: u32,\n+    target: Interned<String>,\n }\n \n-/// Generate all compiler documentation.\n-///\n-/// This will generate all documentation for the compiler libraries and their\n-/// dependencies. This is largely just a wrapper around `cargo doc`.\n-pub fn rustc(build: &Build, stage: u32, target: &str) {\n-    println!(\"Documenting stage{} compiler ({})\", stage, target);\n-    let out = build.doc_out(target);\n-    t!(fs::create_dir_all(&out));\n-    let compiler = Compiler::new(stage, &build.build);\n-    let compiler = if build.force_use_stage1(&compiler, target) {\n-        Compiler::new(1, compiler.host)\n-    } else {\n-        compiler\n-    };\n-    let out_dir = build.stage_out(&compiler, Mode::Librustc)\n-                       .join(target).join(\"doc\");\n-    let rustdoc = build.rustdoc(&compiler);\n-\n-    // See docs in std above for why we symlink\n-    let my_out = build.crate_doc_out(target);\n-    build.clear_if_dirty(&my_out, &rustdoc);\n-    t!(symlink_dir_force(&my_out, &out_dir));\n-\n-    let mut cargo = build.cargo(&compiler, Mode::Librustc, target, \"doc\");\n-    cargo.arg(\"--manifest-path\")\n-         .arg(build.src.join(\"src/rustc/Cargo.toml\"))\n-         .arg(\"--features\").arg(build.rustc_features());\n-\n-    if build.config.compiler_docs {\n-        // src/rustc/Cargo.toml contains bin crates called rustc and rustdoc\n-        // which would otherwise overwrite the docs for the real rustc and\n-        // rustdoc lib crates.\n-        cargo.arg(\"-p\").arg(\"rustc_driver\")\n-             .arg(\"-p\").arg(\"rustdoc\");\n-    } else {\n-        // Like with libstd above if compiler docs aren't enabled then we're not\n-        // documenting internal dependencies, so we have a whitelist.\n-        cargo.arg(\"--no-deps\");\n-        for krate in &[\"proc_macro\"] {\n-            cargo.arg(\"-p\").arg(krate);\n+impl Step for Rustc {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.krate(\"rustc-main\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Rustc {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    /// Generate all compiler documentation.\n+    ///\n+    /// This will generate all documentation for the compiler libraries and their\n+    /// dependencies. This is largely just a wrapper around `cargo doc`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        println!(\"Documenting stage{} compiler ({})\", stage, target);\n+        let out = build.doc_out(target);\n+        t!(fs::create_dir_all(&out));\n+        let compiler = builder.compiler(stage, build.build);\n+        let compiler = if build.force_use_stage1(compiler, target) {\n+            builder.compiler(1, compiler.host)\n+        } else {\n+            compiler\n+        };\n+\n+        // Build libstd docs so that we generate relative links\n+        builder.ensure(Std { stage, target });\n+\n+        builder.ensure(compile::Rustc { compiler, target });\n+        let out_dir = build.stage_out(compiler, Mode::Librustc)\n+                           .join(target).join(\"doc\");\n+        let rustdoc = builder.rustdoc(compiler);\n+\n+        // See docs in std above for why we symlink\n+        let my_out = build.crate_doc_out(target);\n+        build.clear_if_dirty(&my_out, &rustdoc);\n+        t!(symlink_dir_force(&my_out, &out_dir));\n+\n+        let mut cargo = builder.cargo(compiler, Mode::Librustc, target, \"doc\");\n+        cargo.arg(\"--manifest-path\")\n+             .arg(build.src.join(\"src/rustc/Cargo.toml\"))\n+             .arg(\"--features\").arg(build.rustc_features());\n+\n+        if build.config.compiler_docs {\n+            // src/rustc/Cargo.toml contains bin crates called rustc and rustdoc\n+            // which would otherwise overwrite the docs for the real rustc and\n+            // rustdoc lib crates.\n+            cargo.arg(\"-p\").arg(\"rustc_driver\")\n+                 .arg(\"-p\").arg(\"rustdoc\");\n+        } else {\n+            // Like with libstd above if compiler docs aren't enabled then we're not\n+            // documenting internal dependencies, so we have a whitelist.\n+            cargo.arg(\"--no-deps\");\n+            for krate in &[\"proc_macro\"] {\n+                cargo.arg(\"-p\").arg(krate);\n+            }\n         }\n+\n+        build.run(&mut cargo);\n+        cp_r(&my_out, &out);\n     }\n+}\n \n-    build.run(&mut cargo);\n-    cp_r(&my_out, &out);\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct ErrorIndex {\n+    target: Interned<String>,\n }\n \n-/// Generates the HTML rendered error-index by running the\n-/// `error_index_generator` tool.\n-pub fn error_index(build: &Build, target: &str) {\n-    println!(\"Documenting error index ({})\", target);\n-    let out = build.doc_out(target);\n-    t!(fs::create_dir_all(&out));\n-    let compiler = Compiler::new(0, &build.build);\n-    let mut index = build.tool_cmd(&compiler, \"error_index_generator\");\n-    index.arg(\"html\");\n-    index.arg(out.join(\"error-index.html\"));\n+impl Step for ErrorIndex {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/tools/error_index_generator\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(ErrorIndex {\n+            target: run.target,\n+        });\n+    }\n+\n+    /// Generates the HTML rendered error-index by running the\n+    /// `error_index_generator` tool.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+\n+        builder.ensure(compile::Rustc {\n+            compiler: builder.compiler(0, build.build),\n+            target,\n+        });\n+\n+        println!(\"Documenting error index ({})\", target);\n+        let out = build.doc_out(target);\n+        t!(fs::create_dir_all(&out));\n+        let mut index = builder.tool_cmd(Tool::ErrorIndex);\n+        index.arg(\"html\");\n+        index.arg(out.join(\"error-index.html\"));\n \n-    // FIXME: shouldn't have to pass this env var\n-    index.env(\"CFG_BUILD\", &build.build);\n+        // FIXME: shouldn't have to pass this env var\n+        index.env(\"CFG_BUILD\", &build.build);\n \n-    build.run(&mut index);\n+        build.run(&mut index);\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct UnstableBookGen {\n+    target: Interned<String>,\n }\n \n-pub fn unstable_book_gen(build: &Build, target: &str) {\n-    println!(\"Generating unstable book md files ({})\", target);\n-    let out = build.md_doc_out(target).join(\"unstable-book\");\n-    t!(fs::create_dir_all(&out));\n-    t!(fs::remove_dir_all(&out));\n-    let compiler = Compiler::new(0, &build.build);\n-    let mut cmd = build.tool_cmd(&compiler, \"unstable-book-gen\");\n-    cmd.arg(build.src.join(\"src\"));\n-    cmd.arg(out);\n+impl Step for UnstableBookGen {\n+    type Output = ();\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n \n-    build.run(&mut cmd);\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/tools/unstable-book-gen\").default_condition(builder.build.config.docs)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(UnstableBookGen {\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+\n+        builder.ensure(compile::Std {\n+            compiler: builder.compiler(builder.top_stage, build.build),\n+            target,\n+        });\n+\n+        println!(\"Generating unstable book md files ({})\", target);\n+        let out = build.md_doc_out(target).join(\"unstable-book\");\n+        t!(fs::create_dir_all(&out));\n+        t!(fs::remove_dir_all(&out));\n+        let mut cmd = builder.tool_cmd(Tool::UnstableBookGen);\n+        cmd.arg(build.src.join(\"src\"));\n+        cmd.arg(out);\n+\n+        build.run(&mut cmd);\n+    }\n }\n \n fn symlink_dir_force(src: &Path, dst: &Path) -> io::Result<()> {"}, {"sha": "1a3a008ed26147c00d97c47c3b1eaf452ced02ae", "filename": "src/bootstrap/flags.rs", "status": "modified", "additions": 15, "deletions": 12, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fflags.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fflags.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fflags.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -23,17 +23,19 @@ use getopts::Options;\n use Build;\n use config::Config;\n use metadata;\n-use step;\n+use builder::Builder;\n+\n+use cache::{Interned, INTERNER};\n \n /// Deserialized version of all flags for this compile.\n pub struct Flags {\n     pub verbose: usize, // verbosity level: 0 == not verbose, 1 == verbose, 2 == very verbose\n     pub on_fail: Option<String>,\n     pub stage: Option<u32>,\n     pub keep_stage: Option<u32>,\n-    pub build: String,\n-    pub host: Vec<String>,\n-    pub target: Vec<String>,\n+    pub build: Interned<String>,\n+    pub host: Vec<Interned<String>>,\n+    pub target: Vec<Interned<String>>,\n     pub config: Option<PathBuf>,\n     pub src: PathBuf,\n     pub jobs: Option<u32>,\n@@ -246,10 +248,9 @@ Arguments:\n             config.build = flags.build.clone();\n             let mut build = Build::new(flags, config);\n             metadata::build(&mut build);\n-            let maybe_rules_help = step::build_rules(&build).get_help(subcommand);\n-            if maybe_rules_help.is_some() {\n-                extra_help.push_str(maybe_rules_help.unwrap().as_str());\n-            }\n+\n+            let maybe_rules_help = Builder::get_help(&build, subcommand.as_str());\n+            extra_help.push_str(maybe_rules_help.unwrap_or_default().as_str());\n         } else {\n             extra_help.push_str(format!(\"Run `./x.py {} -h -v` to see a list of available paths.\",\n                      subcommand).as_str());\n@@ -319,11 +320,13 @@ Arguments:\n             stage: stage,\n             on_fail: matches.opt_str(\"on-fail\"),\n             keep_stage: matches.opt_str(\"keep-stage\").map(|j| j.parse().unwrap()),\n-            build: matches.opt_str(\"build\").unwrap_or_else(|| {\n+            build: INTERNER.intern_string(matches.opt_str(\"build\").unwrap_or_else(|| {\n                 env::var(\"BUILD\").unwrap()\n-            }),\n-            host: split(matches.opt_strs(\"host\")),\n-            target: split(matches.opt_strs(\"target\")),\n+            })),\n+            host: split(matches.opt_strs(\"host\"))\n+                .into_iter().map(|x| INTERNER.intern_string(x)).collect::<Vec<_>>(),\n+            target: split(matches.opt_strs(\"target\"))\n+                .into_iter().map(|x| INTERNER.intern_string(x)).collect::<Vec<_>>(),\n             config: cfg_file,\n             src: src,\n             jobs: matches.opt_str(\"jobs\").map(|j| j.parse().unwrap()),"}, {"sha": "85402e875d9adad28ec64481e28ae799aad065b5", "filename": "src/bootstrap/install.rs", "status": "modified", "additions": 162, "deletions": 105, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Finstall.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Finstall.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Finstall.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -18,121 +18,99 @@ use std::fs;\n use std::path::{Path, PathBuf, Component};\n use std::process::Command;\n \n-use Build;\n-use dist::{pkgname, sanitize_sh, tmpdir};\n-\n-pub struct Installer<'a> {\n-    build: &'a Build,\n-    prefix: PathBuf,\n-    sysconfdir: PathBuf,\n-    docdir: PathBuf,\n-    bindir: PathBuf,\n-    libdir: PathBuf,\n-    mandir: PathBuf,\n-    empty_dir: PathBuf,\n-}\n+use dist::{self, pkgname, sanitize_sh, tmpdir};\n \n-impl<'a> Drop for Installer<'a> {\n-    fn drop(&mut self) {\n-        t!(fs::remove_dir_all(&self.empty_dir));\n-    }\n-}\n+use builder::{Builder, RunConfig, ShouldRun, Step};\n+use cache::Interned;\n \n-impl<'a> Installer<'a> {\n-    pub fn new(build: &'a Build) -> Installer<'a> {\n-        let prefix_default = PathBuf::from(\"/usr/local\");\n-        let sysconfdir_default = PathBuf::from(\"/etc\");\n-        let docdir_default = PathBuf::from(\"share/doc/rust\");\n-        let bindir_default = PathBuf::from(\"bin\");\n-        let libdir_default = PathBuf::from(\"lib\");\n-        let mandir_default = PathBuf::from(\"share/man\");\n-        let prefix = build.config.prefix.as_ref().unwrap_or(&prefix_default);\n-        let sysconfdir = build.config.sysconfdir.as_ref().unwrap_or(&sysconfdir_default);\n-        let docdir = build.config.docdir.as_ref().unwrap_or(&docdir_default);\n-        let bindir = build.config.bindir.as_ref().unwrap_or(&bindir_default);\n-        let libdir = build.config.libdir.as_ref().unwrap_or(&libdir_default);\n-        let mandir = build.config.mandir.as_ref().unwrap_or(&mandir_default);\n-\n-        let sysconfdir = prefix.join(sysconfdir);\n-        let docdir = prefix.join(docdir);\n-        let bindir = prefix.join(bindir);\n-        let libdir = prefix.join(libdir);\n-        let mandir = prefix.join(mandir);\n-\n-        let destdir = env::var_os(\"DESTDIR\").map(PathBuf::from);\n-\n-        let prefix = add_destdir(&prefix, &destdir);\n-        let sysconfdir = add_destdir(&sysconfdir, &destdir);\n-        let docdir = add_destdir(&docdir, &destdir);\n-        let bindir = add_destdir(&bindir, &destdir);\n-        let libdir = add_destdir(&libdir, &destdir);\n-        let mandir = add_destdir(&mandir, &destdir);\n-\n-        let empty_dir = build.out.join(\"tmp/empty_dir\");\n-\n-        t!(fs::create_dir_all(&empty_dir));\n-\n-        Installer {\n-            build,\n-            prefix,\n-            sysconfdir,\n-            docdir,\n-            bindir,\n-            libdir,\n-            mandir,\n-            empty_dir,\n-        }\n-    }\n+pub fn install_docs(builder: &Builder, stage: u32, host: Interned<String>) {\n+    install_sh(builder, \"docs\", \"rust-docs\", stage, Some(host));\n+}\n \n-    pub fn install_docs(&self, stage: u32, host: &str) {\n-        self.install_sh(\"docs\", \"rust-docs\", stage, Some(host));\n+pub fn install_std(builder: &Builder, stage: u32) {\n+    for target in builder.build.config.target.iter() {\n+        install_sh(builder, \"std\", \"rust-std\", stage, Some(*target));\n     }\n+}\n \n-    pub fn install_std(&self, stage: u32) {\n-        for target in self.build.config.target.iter() {\n-            self.install_sh(\"std\", \"rust-std\", stage, Some(target));\n-        }\n-    }\n+pub fn install_cargo(builder: &Builder, stage: u32, host: Interned<String>) {\n+    install_sh(builder, \"cargo\", \"cargo\", stage, Some(host));\n+}\n \n-    pub fn install_cargo(&self, stage: u32, host: &str) {\n-        self.install_sh(\"cargo\", \"cargo\", stage, Some(host));\n-    }\n+pub fn install_rls(builder: &Builder, stage: u32, host: Interned<String>) {\n+    install_sh(builder, \"rls\", \"rls\", stage, Some(host));\n+}\n \n-    pub fn install_rls(&self, stage: u32, host: &str) {\n-        self.install_sh(\"rls\", \"rls\", stage, Some(host));\n-    }\n+pub fn install_analysis(builder: &Builder, stage: u32, host: Interned<String>) {\n+    install_sh(builder, \"analysis\", \"rust-analysis\", stage, Some(host));\n+}\n \n-    pub fn install_analysis(&self, stage: u32, host: &str) {\n-        self.install_sh(\"analysis\", \"rust-analysis\", stage, Some(host));\n-    }\n+pub fn install_src(builder: &Builder, stage: u32) {\n+    install_sh(builder, \"src\", \"rust-src\", stage, None);\n+}\n+pub fn install_rustc(builder: &Builder, stage: u32, host: Interned<String>) {\n+    install_sh(builder, \"rustc\", \"rustc\", stage, Some(host));\n+}\n \n-    pub fn install_src(&self, stage: u32) {\n-        self.install_sh(\"src\", \"rust-src\", stage, None);\n-    }\n-    pub fn install_rustc(&self, stage: u32, host: &str) {\n-        self.install_sh(\"rustc\", \"rustc\", stage, Some(host));\n-    }\n+fn install_sh(\n+    builder: &Builder,\n+    package: &str,\n+    name: &str,\n+    stage: u32,\n+    host: Option<Interned<String>>\n+) {\n+    let build = builder.build;\n+    println!(\"Install {} stage{} ({:?})\", package, stage, host);\n+\n+    let prefix_default = PathBuf::from(\"/usr/local\");\n+    let sysconfdir_default = PathBuf::from(\"/etc\");\n+    let docdir_default = PathBuf::from(\"share/doc/rust\");\n+    let bindir_default = PathBuf::from(\"bin\");\n+    let libdir_default = PathBuf::from(\"lib\");\n+    let mandir_default = PathBuf::from(\"share/man\");\n+    let prefix = build.config.prefix.as_ref().unwrap_or(&prefix_default);\n+    let sysconfdir = build.config.sysconfdir.as_ref().unwrap_or(&sysconfdir_default);\n+    let docdir = build.config.docdir.as_ref().unwrap_or(&docdir_default);\n+    let bindir = build.config.bindir.as_ref().unwrap_or(&bindir_default);\n+    let libdir = build.config.libdir.as_ref().unwrap_or(&libdir_default);\n+    let mandir = build.config.mandir.as_ref().unwrap_or(&mandir_default);\n+\n+    let sysconfdir = prefix.join(sysconfdir);\n+    let docdir = prefix.join(docdir);\n+    let bindir = prefix.join(bindir);\n+    let libdir = prefix.join(libdir);\n+    let mandir = prefix.join(mandir);\n+\n+    let destdir = env::var_os(\"DESTDIR\").map(PathBuf::from);\n+\n+    let prefix = add_destdir(&prefix, &destdir);\n+    let sysconfdir = add_destdir(&sysconfdir, &destdir);\n+    let docdir = add_destdir(&docdir, &destdir);\n+    let bindir = add_destdir(&bindir, &destdir);\n+    let libdir = add_destdir(&libdir, &destdir);\n+    let mandir = add_destdir(&mandir, &destdir);\n+\n+    let empty_dir = build.out.join(\"tmp/empty_dir\");\n+\n+    t!(fs::create_dir_all(&empty_dir));\n+    let package_name = if let Some(host) = host {\n+        format!(\"{}-{}\", pkgname(build, name), host)\n+    } else {\n+        pkgname(build, name)\n+    };\n \n-    fn install_sh(&self, package: &str, name: &str, stage: u32, host: Option<&str>) {\n-        println!(\"Install {} stage{} ({:?})\", package, stage, host);\n-        let package_name = if let Some(host) = host {\n-            format!(\"{}-{}\", pkgname(self.build, name), host)\n-        } else {\n-            pkgname(self.build, name)\n-        };\n-\n-        let mut cmd = Command::new(\"sh\");\n-        cmd.current_dir(&self.empty_dir)\n-           .arg(sanitize_sh(&tmpdir(self.build).join(&package_name).join(\"install.sh\")))\n-           .arg(format!(\"--prefix={}\", sanitize_sh(&self.prefix)))\n-           .arg(format!(\"--sysconfdir={}\", sanitize_sh(&self.sysconfdir)))\n-           .arg(format!(\"--docdir={}\", sanitize_sh(&self.docdir)))\n-           .arg(format!(\"--bindir={}\", sanitize_sh(&self.bindir)))\n-           .arg(format!(\"--libdir={}\", sanitize_sh(&self.libdir)))\n-           .arg(format!(\"--mandir={}\", sanitize_sh(&self.mandir)))\n-           .arg(\"--disable-ldconfig\");\n-        self.build.run(&mut cmd);\n-    }\n+    let mut cmd = Command::new(\"sh\");\n+    cmd.current_dir(&empty_dir)\n+        .arg(sanitize_sh(&tmpdir(build).join(&package_name).join(\"install.sh\")))\n+        .arg(format!(\"--prefix={}\", sanitize_sh(&prefix)))\n+        .arg(format!(\"--sysconfdir={}\", sanitize_sh(&sysconfdir)))\n+        .arg(format!(\"--docdir={}\", sanitize_sh(&docdir)))\n+        .arg(format!(\"--bindir={}\", sanitize_sh(&bindir)))\n+        .arg(format!(\"--libdir={}\", sanitize_sh(&libdir)))\n+        .arg(format!(\"--mandir={}\", sanitize_sh(&mandir)))\n+        .arg(\"--disable-ldconfig\");\n+    build.run(&mut cmd);\n+    t!(fs::remove_dir_all(&empty_dir));\n }\n \n fn add_destdir(path: &Path, destdir: &Option<PathBuf>) -> PathBuf {\n@@ -148,3 +126,82 @@ fn add_destdir(path: &Path, destdir: &Option<PathBuf>) -> PathBuf {\n     }\n     ret\n }\n+\n+macro_rules! install {\n+    (($sel:ident, $builder:ident, $_config:ident),\n+       $($name:ident,\n+       $path:expr,\n+       $default_cond:expr,\n+       only_hosts: $only_hosts:expr,\n+       $run_item:block $(, $c:ident)*;)+) => {\n+        $(\n+            #[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+        pub struct $name {\n+            pub stage: u32,\n+            pub target: Interned<String>,\n+            pub host: Interned<String>,\n+        }\n+\n+        impl Step for $name {\n+            type Output = ();\n+            const DEFAULT: bool = true;\n+            const ONLY_BUILD_TARGETS: bool = true;\n+            const ONLY_HOSTS: bool = $only_hosts;\n+            $(const $c: bool = true;)*\n+\n+            fn should_run(run: ShouldRun) -> ShouldRun {\n+                let $_config = &run.builder.config;\n+                run.path($path).default_condition($default_cond)\n+            }\n+\n+            fn make_run(run: RunConfig) {\n+                run.builder.ensure($name {\n+                    stage: run.builder.top_stage,\n+                    target: run.target,\n+                    host: run.host,\n+                });\n+            }\n+\n+            fn run($sel, $builder: &Builder) {\n+                $run_item\n+            }\n+        })+\n+    }\n+}\n+\n+install!((self, builder, _config),\n+    Docs, \"src/doc\", _config.docs, only_hosts: false, {\n+        builder.ensure(dist::Docs { stage: self.stage, target: self.target });\n+        install_docs(builder, self.stage, self.target);\n+    };\n+    Std, \"src/libstd\", true, only_hosts: true, {\n+        builder.ensure(dist::Std {\n+            compiler: builder.compiler(self.stage, self.host),\n+            target: self.target\n+        });\n+        install_std(builder, self.stage);\n+    };\n+    Cargo, \"cargo\", _config.extended, only_hosts: true, {\n+        builder.ensure(dist::Cargo { stage: self.stage, target: self.target });\n+        install_cargo(builder, self.stage, self.target);\n+    };\n+    Rls, \"rls\", _config.extended, only_hosts: true, {\n+        builder.ensure(dist::Rls { stage: self.stage, target: self.target });\n+        install_rls(builder, self.stage, self.target);\n+    };\n+    Analysis, \"analysis\", _config.extended, only_hosts: false, {\n+        builder.ensure(dist::Analysis {\n+            compiler: builder.compiler(self.stage, self.host),\n+            target: self.target\n+        });\n+        install_analysis(builder, self.stage, self.target);\n+    };\n+    Src, \"src\", _config.extended, only_hosts: true, {\n+        builder.ensure(dist::Src);\n+        install_src(builder, self.stage);\n+    }, ONLY_BUILD;\n+    Rustc, \"src/librustc\", _config.extended, only_hosts: true, {\n+        builder.ensure(dist::Rustc { stage: self.stage, target: self.target });\n+        install_rustc(builder, self.stage, self.target);\n+    };\n+);"}, {"sha": "5b5ef3f07f98e839caf20904532bc2a2e4f33f98", "filename": "src/bootstrap/lib.rs", "status": "modified", "additions": 169, "deletions": 384, "changes": 553, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Flib.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -23,38 +23,87 @@\n //!\n //! ## Architecture\n //!\n-//! Although this build system defers most of the complicated logic to Cargo\n-//! itself, it still needs to maintain a list of targets and dependencies which\n-//! it can itself perform. Rustbuild is made up of a list of rules with\n-//! dependencies amongst them (created in the `step` module) and then knows how\n-//! to execute each in sequence. Each time rustbuild is invoked, it will simply\n-//! iterate through this list of steps and execute each serially in turn.  For\n-//! each step rustbuild relies on the step internally being incremental and\n+//! The build system defers most of the complicated logic managing invocations\n+//! of rustc and rustdoc to Cargo itself. However, moving through various stages\n+//! and copying artifacts is still necessary for it to do. Each time rustbuild\n+//! is invoked, it will iterate through the list of predefined steps and execute\n+//! each serially in turn if it matches the paths passed or is a default rule.\n+//! For each step rustbuild relies on the step internally being incremental and\n //! parallel. Note, though, that the `-j` parameter to rustbuild gets forwarded\n //! to appropriate test harnesses and such.\n //!\n //! Most of the \"meaty\" steps that matter are backed by Cargo, which does indeed\n //! have its own parallelism and incremental management. Later steps, like\n //! tests, aren't incremental and simply run the entire suite currently.\n+//! However, compiletest itself tries to avoid running tests when the artifacts\n+//! that are involved (mainly the compiler) haven't changed.\n //!\n //! When you execute `x.py build`, the steps which are executed are:\n //!\n //! * First, the python script is run. This will automatically download the\n-//!   stage0 rustc and cargo according to `src/stage0.txt`, or using the cached\n+//!   stage0 rustc and cargo according to `src/stage0.txt`, or use the cached\n //!   versions if they're available. These are then used to compile rustbuild\n //!   itself (using Cargo). Finally, control is then transferred to rustbuild.\n //!\n //! * Rustbuild takes over, performs sanity checks, probes the environment,\n-//!   reads configuration, builds up a list of steps, and then starts executing\n-//!   them.\n+//!   reads configuration, and starts executing steps as it reads the command\n+//!   line arguments (paths) or going through the default rules.\n //!\n-//! * The stage0 libstd is compiled\n-//! * The stage0 libtest is compiled\n-//! * The stage0 librustc is compiled\n-//! * The stage1 compiler is assembled\n-//! * The stage1 libstd, libtest, librustc are compiled\n-//! * The stage2 compiler is assembled\n-//! * The stage2 libstd, libtest, librustc are compiled\n+//!   The build output will be something like the following:\n+//!\n+//!   Building stage0 std artifacts\n+//!   Copying stage0 std\n+//!   Building stage0 test artifacts\n+//!   Copying stage0 test\n+//!   Building stage0 compiler artifacts\n+//!   Copying stage0 rustc\n+//!   Assembling stage1 compiler\n+//!   Building stage1 std artifacts\n+//!   Copying stage1 std\n+//!   Building stage1 test artifacts\n+//!   Copying stage1 test\n+//!   Building stage1 compiler artifacts\n+//!   Copying stage1 rustc\n+//!   Assembling stage2 compiler\n+//!   Uplifting stage1 std\n+//!   Uplifting stage1 test\n+//!   Uplifting stage1 rustc\n+//!\n+//! Let's disect that a little:\n+//!\n+//! ## Building stage0 {std,test,compiler} artifacts\n+//!\n+//! These steps use the provided (downloaded, usually) compiler to compile the\n+//! local Rust source into libraries we can use.\n+//!\n+//! ## Copying stage0 {std,test,rustc}\n+//!\n+//! This copies the build output from Cargo into\n+//! `build/$HOST/stage0-sysroot/lib/rustlib/$ARCH/lib`. FIXME: This step's\n+//! documentation should be expanded -- the information already here may be\n+//! incorrect.\n+//!\n+//! ## Assembling stage1 compiler\n+//!\n+//! This copies the libraries we built in \"building stage0 ... artifacts\" into\n+//! the stage1 compiler's lib directory. These are the host libraries that the\n+//! compiler itself uses to run. These aren't actually used by artifacts the new\n+//! compiler generates. This step also copies the rustc and rustdoc binaries we\n+//! generated into build/$HOST/stage/bin.\n+//!\n+//! The stage1/bin/rustc is a fully functional compiler, but it doesn't yet have\n+//! any libraries to link built binaries or libraries to. The next 3 steps will\n+//! provide those libraries for it; they are mostly equivalent to constructing\n+//! the stage1/bin compiler so we don't go through them individually.\n+//!\n+//! ## Uplifting stage1 {std,test,rustc}\n+//!\n+//! This step copies the libraries from the stage1 compiler sysroot into the\n+//! stage2 compiler. This is done to avoid rebuilding the compiler; libraries\n+//! we'd build in this step should be identical (in function, if not necessarily\n+//! identical on disk) so there's no need to recompile the compiler again. Note\n+//! that if you want to, you can enable the full-bootstrap option to change this\n+//! behavior.\n //!\n //! Each step is driven by a separate Cargo project and rustbuild orchestrates\n //! copying files between steps and otherwise preparing for Cargo to run.\n@@ -65,33 +114,39 @@\n //! also check out the `src/bootstrap/README.md` file for more information.\n \n #![deny(warnings)]\n+#![allow(stable_features)]\n+#![feature(associated_consts)]\n \n #[macro_use]\n extern crate build_helper;\n+#[macro_use]\n+extern crate serde_derive;\n+#[macro_use]\n+extern crate lazy_static;\n+extern crate serde;\n+extern crate serde_json;\n extern crate cmake;\n extern crate filetime;\n extern crate gcc;\n extern crate getopts;\n extern crate num_cpus;\n-extern crate rustc_serialize;\n extern crate toml;\n \n #[cfg(unix)]\n extern crate libc;\n \n use std::cell::Cell;\n use std::cmp;\n-use std::collections::HashMap;\n+use std::collections::{HashSet, HashMap};\n use std::env;\n-use std::ffi::OsString;\n use std::fs::{self, File};\n use std::io::Read;\n use std::path::{PathBuf, Path};\n use std::process::Command;\n \n use build_helper::{run_silent, run_suppressed, try_run_silent, try_run_suppressed, output, mtime};\n \n-use util::{exe, libdir, add_lib_path, OutputFolder, CiEnv};\n+use util::{exe, libdir, OutputFolder, CiEnv};\n \n mod cc;\n mod channel;\n@@ -106,8 +161,10 @@ mod flags;\n mod install;\n mod native;\n mod sanity;\n-mod step;\n pub mod util;\n+mod builder;\n+mod cache;\n+mod tool;\n \n #[cfg(windows)]\n mod job;\n@@ -131,16 +188,17 @@ mod job {\n \n pub use config::Config;\n pub use flags::{Flags, Subcommand};\n+use cache::{Interned, INTERNER};\n \n /// A structure representing a Rust compiler.\n ///\n /// Each compiler has a `stage` that it is associated with and a `host` that\n /// corresponds to the platform the compiler runs on. This structure is used as\n /// a parameter to many methods below.\n #[derive(Eq, PartialEq, Clone, Copy, Hash, Debug)]\n-pub struct Compiler<'a> {\n+pub struct Compiler {\n     stage: u32,\n-    host: &'a str,\n+    host: Interned<String>,\n }\n \n /// Global configuration for the build system.\n@@ -171,9 +229,9 @@ pub struct Build {\n     verbosity: usize,\n \n     // Targets for which to build.\n-    build: String,\n-    hosts: Vec<String>,\n-    targets: Vec<String>,\n+    build: Interned<String>,\n+    hosts: Vec<Interned<String>>,\n+    targets: Vec<Interned<String>>,\n \n     // Stage 0 (downloaded) compiler and cargo or their local rust equivalents.\n     initial_rustc: PathBuf,\n@@ -185,20 +243,20 @@ pub struct Build {\n \n     // Runtime state filled in later on\n     // target -> (cc, ar)\n-    cc: HashMap<String, (gcc::Tool, Option<PathBuf>)>,\n+    cc: HashMap<Interned<String>, (gcc::Tool, Option<PathBuf>)>,\n     // host -> (cc, ar)\n-    cxx: HashMap<String, gcc::Tool>,\n-    crates: HashMap<String, Crate>,\n+    cxx: HashMap<Interned<String>, gcc::Tool>,\n+    crates: HashMap<Interned<String>, Crate>,\n     is_sudo: bool,\n     ci_env: CiEnv,\n     delayed_failures: Cell<usize>,\n }\n \n #[derive(Debug)]\n struct Crate {\n-    name: String,\n+    name: Interned<String>,\n     version: String,\n-    deps: Vec<String>,\n+    deps: Vec<Interned<String>>,\n     path: PathBuf,\n     doc_step: String,\n     build_step: String,\n@@ -210,7 +268,7 @@ struct Crate {\n ///\n /// These entries currently correspond to the various output directories of the\n /// build system, with each mod generating output in a different directory.\n-#[derive(Clone, Copy, PartialEq, Eq)]\n+#[derive(Debug, Hash, Clone, Copy, PartialEq, Eq)]\n pub enum Mode {\n     /// Build the standard library, placing output in the \"stageN-std\" directory.\n     Libstd,\n@@ -299,12 +357,6 @@ impl Build {\n         }\n     }\n \n-    fn build_slice(&self) -> &[String] {\n-        unsafe {\n-            std::slice::from_raw_parts(&self.build, 1)\n-        }\n-    }\n-\n     /// Executes the entire build, as configured by the flags and configuration.\n     pub fn build(&mut self) {\n         unsafe {\n@@ -333,7 +385,7 @@ impl Build {\n         self.verbose(\"learning about cargo\");\n         metadata::build(self);\n \n-        step::run(self);\n+        builder::Builder::run(&self);\n     }\n \n     /// Clear out `dir` if `input` is newer.\n@@ -351,242 +403,6 @@ impl Build {\n         t!(File::create(stamp));\n     }\n \n-    /// Prepares an invocation of `cargo` to be run.\n-    ///\n-    /// This will create a `Command` that represents a pending execution of\n-    /// Cargo. This cargo will be configured to use `compiler` as the actual\n-    /// rustc compiler, its output will be scoped by `mode`'s output directory,\n-    /// it will pass the `--target` flag for the specified `target`, and will be\n-    /// executing the Cargo command `cmd`.\n-    fn cargo(&self,\n-             compiler: &Compiler,\n-             mode: Mode,\n-             target: &str,\n-             cmd: &str) -> Command {\n-        let mut cargo = Command::new(&self.initial_cargo);\n-        let out_dir = self.stage_out(compiler, mode);\n-        cargo.env(\"CARGO_TARGET_DIR\", out_dir)\n-             .arg(cmd)\n-             .arg(\"-j\").arg(self.jobs().to_string())\n-             .arg(\"--target\").arg(target);\n-\n-        // FIXME: Temporary fix for https://github.com/rust-lang/cargo/issues/3005\n-        // Force cargo to output binaries with disambiguating hashes in the name\n-        cargo.env(\"__CARGO_DEFAULT_LIB_METADATA\", &self.config.channel);\n-\n-        let stage;\n-        if compiler.stage == 0 && self.local_rebuild {\n-            // Assume the local-rebuild rustc already has stage1 features.\n-            stage = 1;\n-        } else {\n-            stage = compiler.stage;\n-        }\n-\n-        // Customize the compiler we're running. Specify the compiler to cargo\n-        // as our shim and then pass it some various options used to configure\n-        // how the actual compiler itself is called.\n-        //\n-        // These variables are primarily all read by\n-        // src/bootstrap/bin/{rustc.rs,rustdoc.rs}\n-        cargo.env(\"RUSTBUILD_NATIVE_DIR\", self.native_dir(target))\n-             .env(\"RUSTC\", self.out.join(\"bootstrap/debug/rustc\"))\n-             .env(\"RUSTC_REAL\", self.compiler_path(compiler))\n-             .env(\"RUSTC_STAGE\", stage.to_string())\n-             .env(\"RUSTC_CODEGEN_UNITS\",\n-                  self.config.rust_codegen_units.to_string())\n-             .env(\"RUSTC_DEBUG_ASSERTIONS\",\n-                  self.config.rust_debug_assertions.to_string())\n-             .env(\"RUSTC_SYSROOT\", self.sysroot(compiler))\n-             .env(\"RUSTC_LIBDIR\", self.rustc_libdir(compiler))\n-             .env(\"RUSTC_RPATH\", self.config.rust_rpath.to_string())\n-             .env(\"RUSTDOC\", self.out.join(\"bootstrap/debug/rustdoc\"))\n-             .env(\"RUSTDOC_REAL\", self.rustdoc(compiler))\n-             .env(\"RUSTC_FLAGS\", self.rustc_flags(target).join(\" \"));\n-\n-        if mode != Mode::Tool {\n-            // Tools don't get debuginfo right now, e.g. cargo and rls don't\n-            // get compiled with debuginfo.\n-            cargo.env(\"RUSTC_DEBUGINFO\", self.config.rust_debuginfo.to_string())\n-                 .env(\"RUSTC_DEBUGINFO_LINES\", self.config.rust_debuginfo_lines.to_string())\n-                 .env(\"RUSTC_FORCE_UNSTABLE\", \"1\");\n-\n-            // Currently the compiler depends on crates from crates.io, and\n-            // then other crates can depend on the compiler (e.g. proc-macro\n-            // crates). Let's say, for example that rustc itself depends on the\n-            // bitflags crate. If an external crate then depends on the\n-            // bitflags crate as well, we need to make sure they don't\n-            // conflict, even if they pick the same verison of bitflags. We'll\n-            // want to make sure that e.g. a plugin and rustc each get their\n-            // own copy of bitflags.\n-\n-            // Cargo ensures that this works in general through the -C metadata\n-            // flag. This flag will frob the symbols in the binary to make sure\n-            // they're different, even though the source code is the exact\n-            // same. To solve this problem for the compiler we extend Cargo's\n-            // already-passed -C metadata flag with our own. Our rustc.rs\n-            // wrapper around the actual rustc will detect -C metadata being\n-            // passed and frob it with this extra string we're passing in.\n-            cargo.env(\"RUSTC_METADATA_SUFFIX\", \"rustc\");\n-        }\n-\n-        // Enable usage of unstable features\n-        cargo.env(\"RUSTC_BOOTSTRAP\", \"1\");\n-        self.add_rust_test_threads(&mut cargo);\n-\n-        // Almost all of the crates that we compile as part of the bootstrap may\n-        // have a build script, including the standard library. To compile a\n-        // build script, however, it itself needs a standard library! This\n-        // introduces a bit of a pickle when we're compiling the standard\n-        // library itself.\n-        //\n-        // To work around this we actually end up using the snapshot compiler\n-        // (stage0) for compiling build scripts of the standard library itself.\n-        // The stage0 compiler is guaranteed to have a libstd available for use.\n-        //\n-        // For other crates, however, we know that we've already got a standard\n-        // library up and running, so we can use the normal compiler to compile\n-        // build scripts in that situation.\n-        if mode == Mode::Libstd {\n-            cargo.env(\"RUSTC_SNAPSHOT\", &self.initial_rustc)\n-                 .env(\"RUSTC_SNAPSHOT_LIBDIR\", self.rustc_snapshot_libdir());\n-        } else {\n-            cargo.env(\"RUSTC_SNAPSHOT\", self.compiler_path(compiler))\n-                 .env(\"RUSTC_SNAPSHOT_LIBDIR\", self.rustc_libdir(compiler));\n-        }\n-\n-        // Ignore incremental modes except for stage0, since we're\n-        // not guaranteeing correctness across builds if the compiler\n-        // is changing under your feet.`\n-        if self.flags.incremental && compiler.stage == 0 {\n-            let incr_dir = self.incremental_dir(compiler);\n-            cargo.env(\"RUSTC_INCREMENTAL\", incr_dir);\n-        }\n-\n-        if let Some(ref on_fail) = self.flags.on_fail {\n-            cargo.env(\"RUSTC_ON_FAIL\", on_fail);\n-        }\n-\n-        cargo.env(\"RUSTC_VERBOSE\", format!(\"{}\", self.verbosity));\n-\n-        // Specify some various options for build scripts used throughout\n-        // the build.\n-        //\n-        // FIXME: the guard against msvc shouldn't need to be here\n-        if !target.contains(\"msvc\") {\n-            cargo.env(format!(\"CC_{}\", target), self.cc(target))\n-                 .env(format!(\"AR_{}\", target), self.ar(target).unwrap()) // only msvc is None\n-                 .env(format!(\"CFLAGS_{}\", target), self.cflags(target).join(\" \"));\n-\n-            if let Ok(cxx) = self.cxx(target) {\n-                 cargo.env(format!(\"CXX_{}\", target), cxx);\n-            }\n-        }\n-\n-        if mode == Mode::Libstd &&\n-           self.config.extended &&\n-           compiler.is_final_stage(self) {\n-            cargo.env(\"RUSTC_SAVE_ANALYSIS\", \"api\".to_string());\n-        }\n-\n-        // When being built Cargo will at some point call `nmake.exe` on Windows\n-        // MSVC. Unfortunately `nmake` will read these two environment variables\n-        // below and try to intepret them. We're likely being run, however, from\n-        // MSYS `make` which uses the same variables.\n-        //\n-        // As a result, to prevent confusion and errors, we remove these\n-        // variables from our environment to prevent passing MSYS make flags to\n-        // nmake, causing it to blow up.\n-        if cfg!(target_env = \"msvc\") {\n-            cargo.env_remove(\"MAKE\");\n-            cargo.env_remove(\"MAKEFLAGS\");\n-        }\n-\n-        // Environment variables *required* throughout the build\n-        //\n-        // FIXME: should update code to not require this env var\n-        cargo.env(\"CFG_COMPILER_HOST_TRIPLE\", target);\n-\n-        if self.is_verbose() {\n-            cargo.arg(\"-v\");\n-        }\n-        // FIXME: cargo bench does not accept `--release`\n-        if self.config.rust_optimize && cmd != \"bench\" {\n-            cargo.arg(\"--release\");\n-        }\n-        if self.config.locked_deps {\n-            cargo.arg(\"--locked\");\n-        }\n-        if self.config.vendor || self.is_sudo {\n-            cargo.arg(\"--frozen\");\n-        }\n-\n-        self.ci_env.force_coloring_in_ci(&mut cargo);\n-\n-        cargo\n-    }\n-\n-    /// Get a path to the compiler specified.\n-    fn compiler_path(&self, compiler: &Compiler) -> PathBuf {\n-        if compiler.is_snapshot(self) {\n-            self.initial_rustc.clone()\n-        } else {\n-            self.sysroot(compiler).join(\"bin\").join(exe(\"rustc\", compiler.host))\n-        }\n-    }\n-\n-    /// Get the specified tool built by the specified compiler\n-    fn tool(&self, compiler: &Compiler, tool: &str) -> PathBuf {\n-        self.cargo_out(compiler, Mode::Tool, compiler.host)\n-            .join(exe(tool, compiler.host))\n-    }\n-\n-    /// Get the `rustdoc` executable next to the specified compiler\n-    fn rustdoc(&self, compiler: &Compiler) -> PathBuf {\n-        let mut rustdoc = self.compiler_path(compiler);\n-        rustdoc.pop();\n-        rustdoc.push(exe(\"rustdoc\", compiler.host));\n-        rustdoc\n-    }\n-\n-    /// Get a `Command` which is ready to run `tool` in `stage` built for\n-    /// `host`.\n-    fn tool_cmd(&self, compiler: &Compiler, tool: &str) -> Command {\n-        let mut cmd = Command::new(self.tool(&compiler, tool));\n-        self.prepare_tool_cmd(compiler, &mut cmd);\n-        cmd\n-    }\n-\n-    /// Prepares the `cmd` provided to be able to run the `compiler` provided.\n-    ///\n-    /// Notably this munges the dynamic library lookup path to point to the\n-    /// right location to run `compiler`.\n-    fn prepare_tool_cmd(&self, compiler: &Compiler, cmd: &mut Command) {\n-        let host = compiler.host;\n-        let mut paths = vec![\n-            self.sysroot_libdir(compiler, compiler.host),\n-            self.cargo_out(compiler, Mode::Tool, host).join(\"deps\"),\n-        ];\n-\n-        // On MSVC a tool may invoke a C compiler (e.g. compiletest in run-make\n-        // mode) and that C compiler may need some extra PATH modification. Do\n-        // so here.\n-        if compiler.host.contains(\"msvc\") {\n-            let curpaths = env::var_os(\"PATH\").unwrap_or(OsString::new());\n-            let curpaths = env::split_paths(&curpaths).collect::<Vec<_>>();\n-            for &(ref k, ref v) in self.cc[compiler.host].0.env() {\n-                if k != \"PATH\" {\n-                    continue\n-                }\n-                for path in env::split_paths(v) {\n-                    if !curpaths.contains(&path) {\n-                        paths.push(path);\n-                    }\n-                }\n-            }\n-        }\n-        add_lib_path(paths, cmd);\n-    }\n-\n     /// Get the space-separated set of activated features for the standard\n     /// library.\n     fn std_features(&self) -> String {\n@@ -622,94 +438,67 @@ impl Build {\n         if self.config.rust_optimize {\"release\"} else {\"debug\"}\n     }\n \n-    /// Returns the sysroot for the `compiler` specified that *this build system\n-    /// generates*.\n-    ///\n-    /// That is, the sysroot for the stage0 compiler is not what the compiler\n-    /// thinks it is by default, but it's the same as the default for stages\n-    /// 1-3.\n-    fn sysroot(&self, compiler: &Compiler) -> PathBuf {\n-        if compiler.stage == 0 {\n-            self.out.join(compiler.host).join(\"stage0-sysroot\")\n-        } else {\n-            self.out.join(compiler.host).join(format!(\"stage{}\", compiler.stage))\n-        }\n-    }\n-\n     /// Get the directory for incremental by-products when using the\n     /// given compiler.\n-    fn incremental_dir(&self, compiler: &Compiler) -> PathBuf {\n-        self.out.join(compiler.host).join(format!(\"stage{}-incremental\", compiler.stage))\n-    }\n-\n-    /// Returns the libdir where the standard library and other artifacts are\n-    /// found for a compiler's sysroot.\n-    fn sysroot_libdir(&self, compiler: &Compiler, target: &str) -> PathBuf {\n-        if compiler.stage >= 2 {\n-            if let Some(ref libdir_relative) = self.config.libdir_relative {\n-                return self.sysroot(compiler).join(libdir_relative)\n-                    .join(\"rustlib\").join(target).join(\"lib\")\n-            }\n-        }\n-       self.sysroot(compiler).join(\"lib\").join(\"rustlib\")\n-           .join(target).join(\"lib\")\n+    fn incremental_dir(&self, compiler: Compiler) -> PathBuf {\n+        self.out.join(&*compiler.host).join(format!(\"stage{}-incremental\", compiler.stage))\n     }\n \n     /// Returns the root directory for all output generated in a particular\n     /// stage when running with a particular host compiler.\n     ///\n     /// The mode indicates what the root directory is for.\n-    fn stage_out(&self, compiler: &Compiler, mode: Mode) -> PathBuf {\n+    fn stage_out(&self, compiler: Compiler, mode: Mode) -> PathBuf {\n         let suffix = match mode {\n             Mode::Libstd => \"-std\",\n             Mode::Libtest => \"-test\",\n             Mode::Tool => \"-tools\",\n             Mode::Librustc => \"-rustc\",\n         };\n-        self.out.join(compiler.host)\n+        self.out.join(&*compiler.host)\n                 .join(format!(\"stage{}{}\", compiler.stage, suffix))\n     }\n \n     /// Returns the root output directory for all Cargo output in a given stage,\n     /// running a particular compiler, wehther or not we're building the\n     /// standard library, and targeting the specified architecture.\n     fn cargo_out(&self,\n-                 compiler: &Compiler,\n+                 compiler: Compiler,\n                  mode: Mode,\n-                 target: &str) -> PathBuf {\n-        self.stage_out(compiler, mode).join(target).join(self.cargo_dir())\n+                 target: Interned<String>) -> PathBuf {\n+        self.stage_out(compiler, mode).join(&*target).join(self.cargo_dir())\n     }\n \n     /// Root output directory for LLVM compiled for `target`\n     ///\n     /// Note that if LLVM is configured externally then the directory returned\n     /// will likely be empty.\n-    fn llvm_out(&self, target: &str) -> PathBuf {\n-        self.out.join(target).join(\"llvm\")\n+    fn llvm_out(&self, target: Interned<String>) -> PathBuf {\n+        self.out.join(&*target).join(\"llvm\")\n     }\n \n     /// Output directory for all documentation for a target\n-    fn doc_out(&self, target: &str) -> PathBuf {\n-        self.out.join(target).join(\"doc\")\n+    fn doc_out(&self, target: Interned<String>) -> PathBuf {\n+        self.out.join(&*target).join(\"doc\")\n     }\n \n     /// Output directory for some generated md crate documentation for a target (temporary)\n-    fn md_doc_out(&self, target: &str) -> PathBuf {\n-        self.out.join(target).join(\"md-doc\")\n+    fn md_doc_out(&self, target: Interned<String>) -> Interned<PathBuf> {\n+        INTERNER.intern_path(self.out.join(&*target).join(\"md-doc\"))\n     }\n \n     /// Output directory for all crate documentation for a target (temporary)\n     ///\n     /// The artifacts here are then copied into `doc_out` above.\n-    fn crate_doc_out(&self, target: &str) -> PathBuf {\n-        self.out.join(target).join(\"crate-docs\")\n+    fn crate_doc_out(&self, target: Interned<String>) -> PathBuf {\n+        self.out.join(&*target).join(\"crate-docs\")\n     }\n \n     /// Returns true if no custom `llvm-config` is set for the specified target.\n     ///\n     /// If no custom `llvm-config` was specified then Rust's llvm will be used.\n-    fn is_rust_llvm(&self, target: &str) -> bool {\n-        match self.config.target_config.get(target) {\n+    fn is_rust_llvm(&self, target: Interned<String>) -> bool {\n+        match self.config.target_config.get(&target) {\n             Some(ref c) => c.llvm_config.is_none(),\n             None => true\n         }\n@@ -719,25 +508,25 @@ impl Build {\n     ///\n     /// If a custom `llvm-config` was specified for target then that's returned\n     /// instead.\n-    fn llvm_config(&self, target: &str) -> PathBuf {\n-        let target_config = self.config.target_config.get(target);\n+    fn llvm_config(&self, target: Interned<String>) -> PathBuf {\n+        let target_config = self.config.target_config.get(&target);\n         if let Some(s) = target_config.and_then(|c| c.llvm_config.as_ref()) {\n             s.clone()\n         } else {\n-            self.llvm_out(&self.config.build).join(\"bin\")\n-                .join(exe(\"llvm-config\", target))\n+            self.llvm_out(self.config.build).join(\"bin\")\n+                .join(exe(\"llvm-config\", &*target))\n         }\n     }\n \n     /// Returns the path to `FileCheck` binary for the specified target\n-    fn llvm_filecheck(&self, target: &str) -> PathBuf {\n-        let target_config = self.config.target_config.get(target);\n+    fn llvm_filecheck(&self, target: Interned<String>) -> PathBuf {\n+        let target_config = self.config.target_config.get(&target);\n         if let Some(s) = target_config.and_then(|c| c.llvm_config.as_ref()) {\n             let llvm_bindir = output(Command::new(s).arg(\"--bindir\"));\n-            Path::new(llvm_bindir.trim()).join(exe(\"FileCheck\", target))\n+            Path::new(llvm_bindir.trim()).join(exe(\"FileCheck\", &*target))\n         } else {\n-            let base = self.llvm_out(&self.config.build).join(\"build\");\n-            let exe = exe(\"FileCheck\", target);\n+            let base = self.llvm_out(self.config.build).join(\"build\");\n+            let exe = exe(\"FileCheck\", &*target);\n             if !self.config.ninja && self.config.build.contains(\"msvc\") {\n                 base.join(\"Release/bin\").join(exe)\n             } else {\n@@ -747,49 +536,23 @@ impl Build {\n     }\n \n     /// Directory for libraries built from C/C++ code and shared between stages.\n-    fn native_dir(&self, target: &str) -> PathBuf {\n-        self.out.join(target).join(\"native\")\n+    fn native_dir(&self, target: Interned<String>) -> PathBuf {\n+        self.out.join(&*target).join(\"native\")\n     }\n \n     /// Root output directory for rust_test_helpers library compiled for\n     /// `target`\n-    fn test_helpers_out(&self, target: &str) -> PathBuf {\n+    fn test_helpers_out(&self, target: Interned<String>) -> PathBuf {\n         self.native_dir(target).join(\"rust-test-helpers\")\n     }\n \n-    /// Adds the compiler's directory of dynamic libraries to `cmd`'s dynamic\n-    /// library lookup path.\n-    fn add_rustc_lib_path(&self, compiler: &Compiler, cmd: &mut Command) {\n-        // Windows doesn't need dylib path munging because the dlls for the\n-        // compiler live next to the compiler and the system will find them\n-        // automatically.\n-        if cfg!(windows) {\n-            return\n-        }\n-\n-        add_lib_path(vec![self.rustc_libdir(compiler)], cmd);\n-    }\n-\n     /// Adds the `RUST_TEST_THREADS` env var if necessary\n     fn add_rust_test_threads(&self, cmd: &mut Command) {\n         if env::var_os(\"RUST_TEST_THREADS\").is_none() {\n             cmd.env(\"RUST_TEST_THREADS\", self.jobs().to_string());\n         }\n     }\n \n-    /// Returns the compiler's libdir where it stores the dynamic libraries that\n-    /// it itself links against.\n-    ///\n-    /// For example this returns `<sysroot>/lib` on Unix and `<sysroot>/bin` on\n-    /// Windows.\n-    fn rustc_libdir(&self, compiler: &Compiler) -> PathBuf {\n-        if compiler.is_snapshot(self) {\n-            self.rustc_snapshot_libdir()\n-        } else {\n-            self.sysroot(compiler).join(libdir(compiler.host))\n-        }\n-    }\n-\n     /// Returns the libdir of the snapshot compiler.\n     fn rustc_snapshot_libdir(&self) -> PathBuf {\n         self.initial_rustc.parent().unwrap().parent().unwrap()\n@@ -846,16 +609,16 @@ impl Build {\n     }\n \n     /// Returns the path to the C compiler for the target specified.\n-    fn cc(&self, target: &str) -> &Path {\n-        self.cc[target].0.path()\n+    fn cc(&self, target: Interned<String>) -> &Path {\n+        self.cc[&target].0.path()\n     }\n \n     /// Returns a list of flags to pass to the C compiler for the target\n     /// specified.\n-    fn cflags(&self, target: &str) -> Vec<String> {\n+    fn cflags(&self, target: Interned<String>) -> Vec<String> {\n         // Filter out -O and /O (the optimization flags) that we picked up from\n         // gcc-rs because the build scripts will determine that for themselves.\n-        let mut base = self.cc[target].0.args().iter()\n+        let mut base = self.cc[&target].0.args().iter()\n                            .map(|s| s.to_string_lossy().into_owned())\n                            .filter(|s| !s.starts_with(\"-O\") && !s.starts_with(\"/O\"))\n                            .collect::<Vec<_>>();\n@@ -871,20 +634,20 @@ impl Build {\n         // Work around an apparently bad MinGW / GCC optimization,\n         // See: http://lists.llvm.org/pipermail/cfe-dev/2016-December/051980.html\n         // See: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78936\n-        if target == \"i686-pc-windows-gnu\" {\n+        if &*target == \"i686-pc-windows-gnu\" {\n             base.push(\"-fno-omit-frame-pointer\".into());\n         }\n         base\n     }\n \n     /// Returns the path to the `ar` archive utility for the target specified.\n-    fn ar(&self, target: &str) -> Option<&Path> {\n-        self.cc[target].1.as_ref().map(|p| &**p)\n+    fn ar(&self, target: Interned<String>) -> Option<&Path> {\n+        self.cc[&target].1.as_ref().map(|p| &**p)\n     }\n \n     /// Returns the path to the C++ compiler for the target specified.\n-    fn cxx(&self, target: &str) -> Result<&Path, String> {\n-        match self.cxx.get(target) {\n+    fn cxx(&self, target: Interned<String>) -> Result<&Path, String> {\n+        match self.cxx.get(&target) {\n             Some(p) => Ok(p.path()),\n             None => Err(format!(\n                     \"target `{}` is not configured as a host, only as a target\",\n@@ -893,7 +656,7 @@ impl Build {\n     }\n \n     /// Returns flags to pass to the compiler to generate code for `target`.\n-    fn rustc_flags(&self, target: &str) -> Vec<String> {\n+    fn rustc_flags(&self, target: Interned<String>) -> Vec<String> {\n         // New flags should be added here with great caution!\n         //\n         // It's quite unfortunate to **require** flags to generate code for a\n@@ -910,16 +673,16 @@ impl Build {\n     }\n \n     /// Returns the \"musl root\" for this `target`, if defined\n-    fn musl_root(&self, target: &str) -> Option<&Path> {\n-        self.config.target_config.get(target)\n+    fn musl_root(&self, target: Interned<String>) -> Option<&Path> {\n+        self.config.target_config.get(&target)\n             .and_then(|t| t.musl_root.as_ref())\n             .or(self.config.musl_root.as_ref())\n             .map(|p| &**p)\n     }\n \n     /// Returns whether the target will be tested using the `remote-test-client`\n     /// and `remote-test-server` binaries.\n-    fn remote_tested(&self, target: &str) -> bool {\n+    fn remote_tested(&self, target: Interned<String>) -> bool {\n         self.qemu_rootfs(target).is_some() || target.contains(\"android\") ||\n         env::var_os(\"TEST_DEVICE_ADDR\").is_some()\n     }\n@@ -929,8 +692,8 @@ impl Build {\n     ///\n     /// If `Some` is returned then that means that tests for this target are\n     /// emulated with QEMU and binaries will need to be shipped to the emulator.\n-    fn qemu_rootfs(&self, target: &str) -> Option<&Path> {\n-        self.config.target_config.get(target)\n+    fn qemu_rootfs(&self, target: Interned<String>) -> Option<&Path> {\n+        self.config.target_config.get(&target)\n             .and_then(|t| t.qemu_rootfs.as_ref())\n             .map(|p| &**p)\n     }\n@@ -958,28 +721,28 @@ impl Build {\n     ///\n     /// When all of these conditions are met the build will lift artifacts from\n     /// the previous stage forward.\n-    fn force_use_stage1(&self, compiler: &Compiler, target: &str) -> bool {\n+    fn force_use_stage1(&self, compiler: Compiler, target: Interned<String>) -> bool {\n         !self.config.full_bootstrap &&\n             compiler.stage >= 2 &&\n-            self.config.host.iter().any(|h| h == target)\n+            self.config.host.iter().any(|h| *h == target)\n     }\n \n     /// Returns the directory that OpenSSL artifacts are compiled into if\n     /// configured to do so.\n-    fn openssl_dir(&self, target: &str) -> Option<PathBuf> {\n+    fn openssl_dir(&self, target: Interned<String>) -> Option<PathBuf> {\n         // OpenSSL not used on Windows\n         if target.contains(\"windows\") {\n             None\n         } else if self.config.openssl_static {\n-            Some(self.out.join(target).join(\"openssl\"))\n+            Some(self.out.join(&*target).join(\"openssl\"))\n         } else {\n             None\n         }\n     }\n \n     /// Returns the directory that OpenSSL artifacts are installed into if\n     /// configured as such.\n-    fn openssl_install_dir(&self, target: &str) -> Option<PathBuf> {\n+    fn openssl_install_dir(&self, target: Interned<String>) -> Option<PathBuf> {\n         self.openssl_dir(target).map(|p| p.join(\"install\"))\n     }\n \n@@ -1078,24 +841,46 @@ impl Build {\n             None\n         }\n     }\n+\n+    /// Get a list of crates from a root crate.\n+    ///\n+    /// Returns Vec<(crate, path to crate, is_root_crate)>\n+    fn crates(&self, root: &str) -> Vec<(Interned<String>, &Path)> {\n+        let interned = INTERNER.intern_string(root.to_owned());\n+        let mut ret = Vec::new();\n+        let mut list = vec![interned];\n+        let mut visited = HashSet::new();\n+        while let Some(krate) = list.pop() {\n+            let krate = &self.crates[&krate];\n+            // If we can't strip prefix, then out-of-tree path\n+            let path = krate.path.strip_prefix(&self.src).unwrap_or(&krate.path);\n+            ret.push((krate.name, path));\n+            for dep in &krate.deps {\n+                if visited.insert(dep) && dep != \"build_helper\" {\n+                    list.push(*dep);\n+                }\n+            }\n+        }\n+        ret\n+    }\n }\n \n-impl<'a> Compiler<'a> {\n-    /// Creates a new complier for the specified stage/host\n-    fn new(stage: u32, host: &'a str) -> Compiler<'a> {\n-        Compiler { stage: stage, host: host }\n+impl<'a> Compiler {\n+    pub fn with_stage(mut self, stage: u32) -> Compiler {\n+        self.stage = stage;\n+        self\n     }\n \n     /// Returns whether this is a snapshot compiler for `build`'s configuration\n-    fn is_snapshot(&self, build: &Build) -> bool {\n+    pub fn is_snapshot(&self, build: &Build) -> bool {\n         self.stage == 0 && self.host == build.build\n     }\n \n     /// Returns if this compiler should be treated as a final stage one in the\n     /// current build session.\n     /// This takes into account whether we're performing a full bootstrap or\n     /// not; don't directly compare the stage with `2`!\n-    fn is_final_stage(&self, build: &Build) -> bool {\n+    pub fn is_final_stage(&self, build: &Build) -> bool {\n         let final_stage = if build.config.full_bootstrap { 2 } else { 1 };\n         self.stage >= final_stage\n     }"}, {"sha": "ad555be877ae4cf7b364cfb3f376f8482ab8f500", "filename": "src/bootstrap/metadata.rs", "status": "modified", "additions": 16, "deletions": 14, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fmetadata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fmetadata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fmetadata.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -13,17 +13,18 @@ use std::process::Command;\n use std::path::PathBuf;\n \n use build_helper::output;\n-use rustc_serialize::json;\n+use serde_json;\n \n use {Build, Crate};\n+use cache::INTERNER;\n \n-#[derive(RustcDecodable)]\n+#[derive(Deserialize)]\n struct Output {\n     packages: Vec<Package>,\n     resolve: Resolve,\n }\n \n-#[derive(RustcDecodable)]\n+#[derive(Deserialize)]\n struct Package {\n     id: String,\n     name: String,\n@@ -32,12 +33,12 @@ struct Package {\n     manifest_path: String,\n }\n \n-#[derive(RustcDecodable)]\n+#[derive(Deserialize)]\n struct Resolve {\n     nodes: Vec<ResolveNode>,\n }\n \n-#[derive(RustcDecodable)]\n+#[derive(Deserialize)]\n struct ResolveNode {\n     id: String,\n     dependencies: Vec<String>,\n@@ -61,19 +62,20 @@ fn build_krate(build: &mut Build, krate: &str) {\n          .arg(\"--format-version\").arg(\"1\")\n          .arg(\"--manifest-path\").arg(build.src.join(krate).join(\"Cargo.toml\"));\n     let output = output(&mut cargo);\n-    let output: Output = json::decode(&output).unwrap();\n+    let output: Output = serde_json::from_str(&output).unwrap();\n     let mut id2name = HashMap::new();\n     for package in output.packages {\n         if package.source.is_none() {\n-            id2name.insert(package.id, package.name.clone());\n+            let name = INTERNER.intern_string(package.name);\n+            id2name.insert(package.id, name);\n             let mut path = PathBuf::from(package.manifest_path);\n             path.pop();\n-            build.crates.insert(package.name.clone(), Crate {\n-                build_step: format!(\"build-crate-{}\", package.name),\n-                doc_step: format!(\"doc-crate-{}\", package.name),\n-                test_step: format!(\"test-crate-{}\", package.name),\n-                bench_step: format!(\"bench-crate-{}\", package.name),\n-                name: package.name,\n+            build.crates.insert(name, Crate {\n+                build_step: format!(\"build-crate-{}\", name),\n+                doc_step: format!(\"doc-crate-{}\", name),\n+                test_step: format!(\"test-crate-{}\", name),\n+                bench_step: format!(\"bench-crate-{}\", name),\n+                name: name,\n                 version: package.version,\n                 deps: Vec::new(),\n                 path: path,\n@@ -93,7 +95,7 @@ fn build_krate(build: &mut Build, krate: &str) {\n                 Some(dep) => dep,\n                 None => continue,\n             };\n-            krate.deps.push(dep.clone());\n+            krate.deps.push(*dep);\n         }\n     }\n }"}, {"sha": "f0dfd857ab619147b41e72e441d461b13c3cd434", "filename": "src/bootstrap/native.rs", "status": "modified", "additions": 339, "deletions": 285, "changes": 624, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fnative.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fnative.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fnative.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -32,174 +32,193 @@ use gcc;\n use Build;\n use util;\n use build_helper::up_to_date;\n+use builder::{Builder, RunConfig, ShouldRun, Step};\n+use cache::Interned;\n \n-/// Compile LLVM for `target`.\n-pub fn llvm(build: &Build, target: &str) {\n-    // If we're using a custom LLVM bail out here, but we can only use a\n-    // custom LLVM for the build triple.\n-    if let Some(config) = build.config.target_config.get(target) {\n-        if let Some(ref s) = config.llvm_config {\n-            return check_llvm_version(build, s);\n-        }\n-    }\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Llvm {\n+    pub target: Interned<String>,\n+}\n \n-    let rebuild_trigger = build.src.join(\"src/rustllvm/llvm-rebuild-trigger\");\n-    let mut rebuild_trigger_contents = String::new();\n-    t!(t!(File::open(&rebuild_trigger)).read_to_string(&mut rebuild_trigger_contents));\n+impl Step for Llvm {\n+    type Output = ();\n+    const ONLY_HOSTS: bool = true;\n \n-    let out_dir = build.llvm_out(target);\n-    let done_stamp = out_dir.join(\"llvm-finished-building\");\n-    if done_stamp.exists() {\n-        let mut done_contents = String::new();\n-        t!(t!(File::open(&done_stamp)).read_to_string(&mut done_contents));\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/llvm\")\n+    }\n \n-        // If LLVM was already built previously and contents of the rebuild-trigger file\n-        // didn't change from the previous build, then no action is required.\n-        if done_contents == rebuild_trigger_contents {\n-            return\n+    /// Compile LLVM for `target`.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        // If we're using a custom LLVM bail out here, but we can only use a\n+        // custom LLVM for the build triple.\n+        if let Some(config) = build.config.target_config.get(&target) {\n+            if let Some(ref s) = config.llvm_config {\n+                return check_llvm_version(build, s);\n+            }\n         }\n-    }\n-    if build.config.llvm_clean_rebuild {\n-        drop(fs::remove_dir_all(&out_dir));\n-    }\n \n-    let _folder = build.fold_output(|| \"llvm\");\n-    println!(\"Building LLVM for {}\", target);\n-    let _time = util::timeit();\n-    t!(fs::create_dir_all(&out_dir));\n+        let rebuild_trigger = build.src.join(\"src/rustllvm/llvm-rebuild-trigger\");\n+        let mut rebuild_trigger_contents = String::new();\n+        t!(t!(File::open(&rebuild_trigger)).read_to_string(&mut rebuild_trigger_contents));\n \n-    // http://llvm.org/docs/CMake.html\n-    let mut cfg = cmake::Config::new(build.src.join(\"src/llvm\"));\n-    if build.config.ninja {\n-        cfg.generator(\"Ninja\");\n-    }\n+        let out_dir = build.llvm_out(target);\n+        let done_stamp = out_dir.join(\"llvm-finished-building\");\n+        if done_stamp.exists() {\n+            let mut done_contents = String::new();\n+            t!(t!(File::open(&done_stamp)).read_to_string(&mut done_contents));\n \n-    let profile = match (build.config.llvm_optimize, build.config.llvm_release_debuginfo) {\n-        (false, _) => \"Debug\",\n-        (true, false) => \"Release\",\n-        (true, true) => \"RelWithDebInfo\",\n-    };\n-\n-    // NOTE: remember to also update `config.toml.example` when changing the defaults!\n-    let llvm_targets = match build.config.llvm_targets {\n-        Some(ref s) => s,\n-        None => \"X86;ARM;AArch64;Mips;PowerPC;SystemZ;JSBackend;MSP430;Sparc;NVPTX;Hexagon\",\n-    };\n-\n-    let llvm_exp_targets = match build.config.llvm_experimental_targets {\n-        Some(ref s) => s,\n-        None => \"\",\n-    };\n-\n-    let assertions = if build.config.llvm_assertions {\"ON\"} else {\"OFF\"};\n-\n-    cfg.target(target)\n-       .host(&build.build)\n-       .out_dir(&out_dir)\n-       .profile(profile)\n-       .define(\"LLVM_ENABLE_ASSERTIONS\", assertions)\n-       .define(\"LLVM_TARGETS_TO_BUILD\", llvm_targets)\n-       .define(\"LLVM_EXPERIMENTAL_TARGETS_TO_BUILD\", llvm_exp_targets)\n-       .define(\"LLVM_INCLUDE_EXAMPLES\", \"OFF\")\n-       .define(\"LLVM_INCLUDE_TESTS\", \"OFF\")\n-       .define(\"LLVM_INCLUDE_DOCS\", \"OFF\")\n-       .define(\"LLVM_ENABLE_ZLIB\", \"OFF\")\n-       .define(\"WITH_POLLY\", \"OFF\")\n-       .define(\"LLVM_ENABLE_TERMINFO\", \"OFF\")\n-       .define(\"LLVM_ENABLE_LIBEDIT\", \"OFF\")\n-       .define(\"LLVM_PARALLEL_COMPILE_JOBS\", build.jobs().to_string())\n-       .define(\"LLVM_TARGET_ARCH\", target.split('-').next().unwrap())\n-       .define(\"LLVM_DEFAULT_TARGET_TRIPLE\", target);\n-\n-    if target.contains(\"msvc\") {\n-        cfg.define(\"LLVM_USE_CRT_DEBUG\", \"MT\");\n-        cfg.define(\"LLVM_USE_CRT_RELEASE\", \"MT\");\n-        cfg.define(\"LLVM_USE_CRT_RELWITHDEBINFO\", \"MT\");\n-        cfg.static_crt(true);\n-    }\n+            // If LLVM was already built previously and contents of the rebuild-trigger file\n+            // didn't change from the previous build, then no action is required.\n+            if done_contents == rebuild_trigger_contents {\n+                return\n+            }\n+        }\n+        if build.config.llvm_clean_rebuild {\n+            drop(fs::remove_dir_all(&out_dir));\n+        }\n \n-    if target.starts_with(\"i686\") {\n-        cfg.define(\"LLVM_BUILD_32_BITS\", \"ON\");\n-    }\n+        let _folder = build.fold_output(|| \"llvm\");\n+        println!(\"Building LLVM for {}\", target);\n+        let _time = util::timeit();\n+        t!(fs::create_dir_all(&out_dir));\n \n-    if let Some(num_linkers) = build.config.llvm_link_jobs {\n-        if num_linkers > 0 {\n-            cfg.define(\"LLVM_PARALLEL_LINK_JOBS\", num_linkers.to_string());\n+        // http://llvm.org/docs/CMake.html\n+        let mut cfg = cmake::Config::new(build.src.join(\"src/llvm\"));\n+        if build.config.ninja {\n+            cfg.generator(\"Ninja\");\n         }\n-    }\n \n-    // http://llvm.org/docs/HowToCrossCompileLLVM.html\n-    if target != build.build {\n-        // FIXME: if the llvm root for the build triple is overridden then we\n-        //        should use llvm-tblgen from there, also should verify that it\n-        //        actually exists most of the time in normal installs of LLVM.\n-        let host = build.llvm_out(&build.build).join(\"bin/llvm-tblgen\");\n-        cfg.define(\"CMAKE_CROSSCOMPILING\", \"True\")\n-           .define(\"LLVM_TABLEGEN\", &host);\n-    }\n+        let profile = match (build.config.llvm_optimize, build.config.llvm_release_debuginfo) {\n+            (false, _) => \"Debug\",\n+            (true, false) => \"Release\",\n+            (true, true) => \"RelWithDebInfo\",\n+        };\n+\n+        // NOTE: remember to also update `config.toml.example` when changing the defaults!\n+        let llvm_targets = match build.config.llvm_targets {\n+            Some(ref s) => s,\n+            None => \"X86;ARM;AArch64;Mips;PowerPC;SystemZ;JSBackend;MSP430;Sparc;NVPTX;Hexagon\",\n+        };\n+\n+        let llvm_exp_targets = match build.config.llvm_experimental_targets {\n+            Some(ref s) => s,\n+            None => \"\",\n+        };\n+\n+        let assertions = if build.config.llvm_assertions {\"ON\"} else {\"OFF\"};\n+\n+        cfg.target(&target)\n+           .host(&build.build)\n+           .out_dir(&out_dir)\n+           .profile(profile)\n+           .define(\"LLVM_ENABLE_ASSERTIONS\", assertions)\n+           .define(\"LLVM_TARGETS_TO_BUILD\", llvm_targets)\n+           .define(\"LLVM_EXPERIMENTAL_TARGETS_TO_BUILD\", llvm_exp_targets)\n+           .define(\"LLVM_INCLUDE_EXAMPLES\", \"OFF\")\n+           .define(\"LLVM_INCLUDE_TESTS\", \"OFF\")\n+           .define(\"LLVM_INCLUDE_DOCS\", \"OFF\")\n+           .define(\"LLVM_ENABLE_ZLIB\", \"OFF\")\n+           .define(\"WITH_POLLY\", \"OFF\")\n+           .define(\"LLVM_ENABLE_TERMINFO\", \"OFF\")\n+           .define(\"LLVM_ENABLE_LIBEDIT\", \"OFF\")\n+           .define(\"LLVM_PARALLEL_COMPILE_JOBS\", build.jobs().to_string())\n+           .define(\"LLVM_TARGET_ARCH\", target.split('-').next().unwrap())\n+           .define(\"LLVM_DEFAULT_TARGET_TRIPLE\", target);\n \n-    let sanitize_cc = |cc: &Path| {\n         if target.contains(\"msvc\") {\n-            OsString::from(cc.to_str().unwrap().replace(\"\\\\\", \"/\"))\n-        } else {\n-            cc.as_os_str().to_owned()\n+            cfg.define(\"LLVM_USE_CRT_DEBUG\", \"MT\");\n+            cfg.define(\"LLVM_USE_CRT_RELEASE\", \"MT\");\n+            cfg.define(\"LLVM_USE_CRT_RELWITHDEBINFO\", \"MT\");\n+            cfg.static_crt(true);\n         }\n-    };\n \n-    let configure_compilers = |cfg: &mut cmake::Config| {\n-        // MSVC with CMake uses msbuild by default which doesn't respect these\n-        // vars that we'd otherwise configure. In that case we just skip this\n-        // entirely.\n-        if target.contains(\"msvc\") && !build.config.ninja {\n-            return\n+        if target.starts_with(\"i686\") {\n+            cfg.define(\"LLVM_BUILD_32_BITS\", \"ON\");\n+        }\n+\n+        if let Some(num_linkers) = build.config.llvm_link_jobs {\n+            if num_linkers > 0 {\n+                cfg.define(\"LLVM_PARALLEL_LINK_JOBS\", num_linkers.to_string());\n+            }\n         }\n \n-        let cc = build.cc(target);\n-        let cxx = build.cxx(target).unwrap();\n-\n-        // Handle msvc + ninja + ccache specially (this is what the bots use)\n-        if target.contains(\"msvc\") &&\n-           build.config.ninja &&\n-           build.config.ccache.is_some() {\n-            let mut cc = env::current_exe().expect(\"failed to get cwd\");\n-            cc.set_file_name(\"sccache-plus-cl.exe\");\n-\n-           cfg.define(\"CMAKE_C_COMPILER\", sanitize_cc(&cc))\n-              .define(\"CMAKE_CXX_COMPILER\", sanitize_cc(&cc));\n-           cfg.env(\"SCCACHE_PATH\",\n-                   build.config.ccache.as_ref().unwrap())\n-              .env(\"SCCACHE_TARGET\", target);\n-\n-        // If ccache is configured we inform the build a little differently hwo\n-        // to invoke ccache while also invoking our compilers.\n-        } else if let Some(ref ccache) = build.config.ccache {\n-           cfg.define(\"CMAKE_C_COMPILER\", ccache)\n-              .define(\"CMAKE_C_COMPILER_ARG1\", sanitize_cc(cc))\n-              .define(\"CMAKE_CXX_COMPILER\", ccache)\n-              .define(\"CMAKE_CXX_COMPILER_ARG1\", sanitize_cc(cxx));\n-        } else {\n-           cfg.define(\"CMAKE_C_COMPILER\", sanitize_cc(cc))\n-              .define(\"CMAKE_CXX_COMPILER\", sanitize_cc(cxx));\n+        // http://llvm.org/docs/HowToCrossCompileLLVM.html\n+        if target != build.build {\n+            builder.ensure(Llvm { target: build.build });\n+            // FIXME: if the llvm root for the build triple is overridden then we\n+            //        should use llvm-tblgen from there, also should verify that it\n+            //        actually exists most of the time in normal installs of LLVM.\n+            let host = build.llvm_out(build.build).join(\"bin/llvm-tblgen\");\n+            cfg.define(\"CMAKE_CROSSCOMPILING\", \"True\")\n+               .define(\"LLVM_TABLEGEN\", &host);\n         }\n \n-        cfg.build_arg(\"-j\").build_arg(build.jobs().to_string());\n-        cfg.define(\"CMAKE_C_FLAGS\", build.cflags(target).join(\" \"));\n-        cfg.define(\"CMAKE_CXX_FLAGS\", build.cflags(target).join(\" \"));\n-    };\n+        let sanitize_cc = |cc: &Path| {\n+            if target.contains(\"msvc\") {\n+                OsString::from(cc.to_str().unwrap().replace(\"\\\\\", \"/\"))\n+            } else {\n+                cc.as_os_str().to_owned()\n+            }\n+        };\n+\n+        let configure_compilers = |cfg: &mut cmake::Config| {\n+            // MSVC with CMake uses msbuild by default which doesn't respect these\n+            // vars that we'd otherwise configure. In that case we just skip this\n+            // entirely.\n+            if target.contains(\"msvc\") && !build.config.ninja {\n+                return\n+            }\n \n-    configure_compilers(&mut cfg);\n+            let cc = build.cc(target);\n+            let cxx = build.cxx(target).unwrap();\n+\n+            // Handle msvc + ninja + ccache specially (this is what the bots use)\n+            if target.contains(\"msvc\") &&\n+               build.config.ninja &&\n+               build.config.ccache.is_some() {\n+                let mut cc = env::current_exe().expect(\"failed to get cwd\");\n+                cc.set_file_name(\"sccache-plus-cl.exe\");\n+\n+               cfg.define(\"CMAKE_C_COMPILER\", sanitize_cc(&cc))\n+                  .define(\"CMAKE_CXX_COMPILER\", sanitize_cc(&cc));\n+               cfg.env(\"SCCACHE_PATH\",\n+                       build.config.ccache.as_ref().unwrap())\n+                  .env(\"SCCACHE_TARGET\", target);\n+\n+            // If ccache is configured we inform the build a little differently hwo\n+            // to invoke ccache while also invoking our compilers.\n+            } else if let Some(ref ccache) = build.config.ccache {\n+               cfg.define(\"CMAKE_C_COMPILER\", ccache)\n+                  .define(\"CMAKE_C_COMPILER_ARG1\", sanitize_cc(cc))\n+                  .define(\"CMAKE_CXX_COMPILER\", ccache)\n+                  .define(\"CMAKE_CXX_COMPILER_ARG1\", sanitize_cc(cxx));\n+            } else {\n+               cfg.define(\"CMAKE_C_COMPILER\", sanitize_cc(cc))\n+                  .define(\"CMAKE_CXX_COMPILER\", sanitize_cc(cxx));\n+            }\n \n-    if env::var_os(\"SCCACHE_ERROR_LOG\").is_some() {\n-        cfg.env(\"RUST_LOG\", \"sccache=warn\");\n-    }\n+            cfg.build_arg(\"-j\").build_arg(build.jobs().to_string());\n+            cfg.define(\"CMAKE_C_FLAGS\", build.cflags(target).join(\" \"));\n+            cfg.define(\"CMAKE_CXX_FLAGS\", build.cflags(target).join(\" \"));\n+        };\n \n-    // FIXME: we don't actually need to build all LLVM tools and all LLVM\n-    //        libraries here, e.g. we just want a few components and a few\n-    //        tools. Figure out how to filter them down and only build the right\n-    //        tools and libs on all platforms.\n-    cfg.build();\n+        configure_compilers(&mut cfg);\n \n-    t!(t!(File::create(&done_stamp)).write_all(rebuild_trigger_contents.as_bytes()));\n+        if env::var_os(\"SCCACHE_ERROR_LOG\").is_some() {\n+            cfg.env(\"RUST_LOG\", \"sccache=warn\");\n+        }\n+\n+        // FIXME: we don't actually need to build all LLVM tools and all LLVM\n+        //        libraries here, e.g. we just want a few components and a few\n+        //        tools. Figure out how to filter them down and only build the right\n+        //        tools and libs on all platforms.\n+        cfg.build();\n+\n+        t!(t!(File::create(&done_stamp)).write_all(rebuild_trigger_contents.as_bytes()));\n+    }\n }\n \n fn check_llvm_version(build: &Build, llvm_config: &Path) {\n@@ -216,161 +235,196 @@ fn check_llvm_version(build: &Build, llvm_config: &Path) {\n     panic!(\"\\n\\nbad LLVM version: {}, need >=3.5\\n\\n\", version)\n }\n \n-/// Compiles the `rust_test_helpers.c` library which we used in various\n-/// `run-pass` test suites for ABI testing.\n-pub fn test_helpers(build: &Build, target: &str) {\n-    let dst = build.test_helpers_out(target);\n-    let src = build.src.join(\"src/rt/rust_test_helpers.c\");\n-    if up_to_date(&src, &dst.join(\"librust_test_helpers.a\")) {\n-        return\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct TestHelpers {\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for TestHelpers {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/rt/rust_test_helpers.c\")\n     }\n \n-    let _folder = build.fold_output(|| \"build_test_helpers\");\n-    println!(\"Building test helpers\");\n-    t!(fs::create_dir_all(&dst));\n-    let mut cfg = gcc::Config::new();\n-\n-    // We may have found various cross-compilers a little differently due to our\n-    // extra configuration, so inform gcc of these compilers. Note, though, that\n-    // on MSVC we still need gcc's detection of env vars (ugh).\n-    if !target.contains(\"msvc\") {\n-        if let Some(ar) = build.ar(target) {\n-            cfg.archiver(ar);\n-        }\n-        cfg.compiler(build.cc(target));\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(TestHelpers { target: run.target })\n     }\n \n-    cfg.cargo_metadata(false)\n-       .out_dir(&dst)\n-       .target(target)\n-       .host(&build.build)\n-       .opt_level(0)\n-       .debug(false)\n-       .file(build.src.join(\"src/rt/rust_test_helpers.c\"))\n-       .compile(\"librust_test_helpers.a\");\n+    /// Compiles the `rust_test_helpers.c` library which we used in various\n+    /// `run-pass` test suites for ABI testing.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let dst = build.test_helpers_out(target);\n+        let src = build.src.join(\"src/rt/rust_test_helpers.c\");\n+        if up_to_date(&src, &dst.join(\"librust_test_helpers.a\")) {\n+            return\n+        }\n+\n+        let _folder = build.fold_output(|| \"build_test_helpers\");\n+        println!(\"Building test helpers\");\n+        t!(fs::create_dir_all(&dst));\n+        let mut cfg = gcc::Config::new();\n+\n+        // We may have found various cross-compilers a little differently due to our\n+        // extra configuration, so inform gcc of these compilers. Note, though, that\n+        // on MSVC we still need gcc's detection of env vars (ugh).\n+        if !target.contains(\"msvc\") {\n+            if let Some(ar) = build.ar(target) {\n+                cfg.archiver(ar);\n+            }\n+            cfg.compiler(build.cc(target));\n+        }\n+\n+        cfg.cargo_metadata(false)\n+           .out_dir(&dst)\n+           .target(&target)\n+           .host(&build.build)\n+           .opt_level(0)\n+           .debug(false)\n+           .file(build.src.join(\"src/rt/rust_test_helpers.c\"))\n+           .compile(\"librust_test_helpers.a\");\n+    }\n }\n+\n const OPENSSL_VERS: &'static str = \"1.0.2k\";\n const OPENSSL_SHA256: &'static str =\n     \"6b3977c61f2aedf0f96367dcfb5c6e578cf37e7b8d913b4ecb6643c3cb88d8c0\";\n \n-pub fn openssl(build: &Build, target: &str) {\n-    let out = match build.openssl_dir(target) {\n-        Some(dir) => dir,\n-        None => return,\n-    };\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Openssl {\n+    pub target: Interned<String>,\n+}\n \n-    let stamp = out.join(\".stamp\");\n-    let mut contents = String::new();\n-    drop(File::open(&stamp).and_then(|mut f| f.read_to_string(&mut contents)));\n-    if contents == OPENSSL_VERS {\n-        return\n+impl Step for Openssl {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n     }\n-    t!(fs::create_dir_all(&out));\n-\n-    let name = format!(\"openssl-{}.tar.gz\", OPENSSL_VERS);\n-    let tarball = out.join(&name);\n-    if !tarball.exists() {\n-        let tmp = tarball.with_extension(\"tmp\");\n-        // originally from https://www.openssl.org/source/...\n-        let url = format!(\"https://s3.amazonaws.com/rust-lang-ci/rust-ci-mirror/{}\",\n-                          name);\n-        let mut ok = false;\n-        for _ in 0..3 {\n-            let status = Command::new(\"curl\")\n-                            .arg(\"-o\").arg(&tmp)\n-                            .arg(&url)\n-                            .status()\n-                            .expect(\"failed to spawn curl\");\n-            if status.success() {\n-                ok = true;\n-                break\n-            }\n+\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let target = self.target;\n+        let out = match build.openssl_dir(target) {\n+            Some(dir) => dir,\n+            None => return,\n+        };\n+\n+        let stamp = out.join(\".stamp\");\n+        let mut contents = String::new();\n+        drop(File::open(&stamp).and_then(|mut f| f.read_to_string(&mut contents)));\n+        if contents == OPENSSL_VERS {\n+            return\n         }\n-        if !ok {\n-            panic!(\"failed to download openssl source\")\n+        t!(fs::create_dir_all(&out));\n+\n+        let name = format!(\"openssl-{}.tar.gz\", OPENSSL_VERS);\n+        let tarball = out.join(&name);\n+        if !tarball.exists() {\n+            let tmp = tarball.with_extension(\"tmp\");\n+            // originally from https://www.openssl.org/source/...\n+            let url = format!(\"https://s3.amazonaws.com/rust-lang-ci/rust-ci-mirror/{}\",\n+                              name);\n+            let mut ok = false;\n+            for _ in 0..3 {\n+                let status = Command::new(\"curl\")\n+                                .arg(\"-o\").arg(&tmp)\n+                                .arg(&url)\n+                                .status()\n+                                .expect(\"failed to spawn curl\");\n+                if status.success() {\n+                    ok = true;\n+                    break\n+                }\n+            }\n+            if !ok {\n+                panic!(\"failed to download openssl source\")\n+            }\n+            let mut shasum = if target.contains(\"apple\") {\n+                let mut cmd = Command::new(\"shasum\");\n+                cmd.arg(\"-a\").arg(\"256\");\n+                cmd\n+            } else {\n+                Command::new(\"sha256sum\")\n+            };\n+            let output = output(&mut shasum.arg(&tmp));\n+            let found = output.split_whitespace().next().unwrap();\n+            if found != OPENSSL_SHA256 {\n+                panic!(\"downloaded openssl sha256 different\\n\\\n+                        expected: {}\\n\\\n+                        found:    {}\\n\", OPENSSL_SHA256, found);\n+            }\n+            t!(fs::rename(&tmp, &tarball));\n         }\n-        let mut shasum = if target.contains(\"apple\") {\n-            let mut cmd = Command::new(\"shasum\");\n-            cmd.arg(\"-a\").arg(\"256\");\n-            cmd\n-        } else {\n-            Command::new(\"sha256sum\")\n+        let obj = out.join(format!(\"openssl-{}\", OPENSSL_VERS));\n+        let dst = build.openssl_install_dir(target).unwrap();\n+        drop(fs::remove_dir_all(&obj));\n+        drop(fs::remove_dir_all(&dst));\n+        build.run(Command::new(\"tar\").arg(\"xf\").arg(&tarball).current_dir(&out));\n+\n+        let mut configure = Command::new(obj.join(\"Configure\"));\n+        configure.arg(format!(\"--prefix={}\", dst.display()));\n+        configure.arg(\"no-dso\");\n+        configure.arg(\"no-ssl2\");\n+        configure.arg(\"no-ssl3\");\n+\n+        let os = match &*target {\n+            \"aarch64-linux-android\" => \"linux-aarch64\",\n+            \"aarch64-unknown-linux-gnu\" => \"linux-aarch64\",\n+            \"arm-linux-androideabi\" => \"android\",\n+            \"arm-unknown-linux-gnueabi\" => \"linux-armv4\",\n+            \"arm-unknown-linux-gnueabihf\" => \"linux-armv4\",\n+            \"armv7-linux-androideabi\" => \"android-armv7\",\n+            \"armv7-unknown-linux-gnueabihf\" => \"linux-armv4\",\n+            \"i686-apple-darwin\" => \"darwin-i386-cc\",\n+            \"i686-linux-android\" => \"android-x86\",\n+            \"i686-unknown-freebsd\" => \"BSD-x86-elf\",\n+            \"i686-unknown-linux-gnu\" => \"linux-elf\",\n+            \"i686-unknown-linux-musl\" => \"linux-elf\",\n+            \"mips-unknown-linux-gnu\" => \"linux-mips32\",\n+            \"mips64-unknown-linux-gnuabi64\" => \"linux64-mips64\",\n+            \"mips64el-unknown-linux-gnuabi64\" => \"linux64-mips64\",\n+            \"mipsel-unknown-linux-gnu\" => \"linux-mips32\",\n+            \"powerpc-unknown-linux-gnu\" => \"linux-ppc\",\n+            \"powerpc64-unknown-linux-gnu\" => \"linux-ppc64\",\n+            \"powerpc64le-unknown-linux-gnu\" => \"linux-ppc64le\",\n+            \"s390x-unknown-linux-gnu\" => \"linux64-s390x\",\n+            \"x86_64-apple-darwin\" => \"darwin64-x86_64-cc\",\n+            \"x86_64-linux-android\" => \"linux-x86_64\",\n+            \"x86_64-unknown-freebsd\" => \"BSD-x86_64\",\n+            \"x86_64-unknown-linux-gnu\" => \"linux-x86_64\",\n+            \"x86_64-unknown-linux-musl\" => \"linux-x86_64\",\n+            \"x86_64-unknown-netbsd\" => \"BSD-x86_64\",\n+            _ => panic!(\"don't know how to configure OpenSSL for {}\", target),\n         };\n-        let output = output(&mut shasum.arg(&tmp));\n-        let found = output.split_whitespace().next().unwrap();\n-        if found != OPENSSL_SHA256 {\n-            panic!(\"downloaded openssl sha256 different\\n\\\n-                    expected: {}\\n\\\n-                    found:    {}\\n\", OPENSSL_SHA256, found);\n+        configure.arg(os);\n+        configure.env(\"CC\", build.cc(target));\n+        for flag in build.cflags(target) {\n+            configure.arg(flag);\n         }\n-        t!(fs::rename(&tmp, &tarball));\n-    }\n-    let obj = out.join(format!(\"openssl-{}\", OPENSSL_VERS));\n-    let dst = build.openssl_install_dir(target).unwrap();\n-    drop(fs::remove_dir_all(&obj));\n-    drop(fs::remove_dir_all(&dst));\n-    build.run(Command::new(\"tar\").arg(\"xf\").arg(&tarball).current_dir(&out));\n-\n-    let mut configure = Command::new(obj.join(\"Configure\"));\n-    configure.arg(format!(\"--prefix={}\", dst.display()));\n-    configure.arg(\"no-dso\");\n-    configure.arg(\"no-ssl2\");\n-    configure.arg(\"no-ssl3\");\n-\n-    let os = match target {\n-        \"aarch64-linux-android\" => \"linux-aarch64\",\n-        \"aarch64-unknown-linux-gnu\" => \"linux-aarch64\",\n-        \"arm-linux-androideabi\" => \"android\",\n-        \"arm-unknown-linux-gnueabi\" => \"linux-armv4\",\n-        \"arm-unknown-linux-gnueabihf\" => \"linux-armv4\",\n-        \"armv7-linux-androideabi\" => \"android-armv7\",\n-        \"armv7-unknown-linux-gnueabihf\" => \"linux-armv4\",\n-        \"i686-apple-darwin\" => \"darwin-i386-cc\",\n-        \"i686-linux-android\" => \"android-x86\",\n-        \"i686-unknown-freebsd\" => \"BSD-x86-elf\",\n-        \"i686-unknown-linux-gnu\" => \"linux-elf\",\n-        \"i686-unknown-linux-musl\" => \"linux-elf\",\n-        \"mips-unknown-linux-gnu\" => \"linux-mips32\",\n-        \"mips64-unknown-linux-gnuabi64\" => \"linux64-mips64\",\n-        \"mips64el-unknown-linux-gnuabi64\" => \"linux64-mips64\",\n-        \"mipsel-unknown-linux-gnu\" => \"linux-mips32\",\n-        \"powerpc-unknown-linux-gnu\" => \"linux-ppc\",\n-        \"powerpc64-unknown-linux-gnu\" => \"linux-ppc64\",\n-        \"powerpc64le-unknown-linux-gnu\" => \"linux-ppc64le\",\n-        \"s390x-unknown-linux-gnu\" => \"linux64-s390x\",\n-        \"x86_64-apple-darwin\" => \"darwin64-x86_64-cc\",\n-        \"x86_64-linux-android\" => \"linux-x86_64\",\n-        \"x86_64-unknown-freebsd\" => \"BSD-x86_64\",\n-        \"x86_64-unknown-linux-gnu\" => \"linux-x86_64\",\n-        \"x86_64-unknown-linux-musl\" => \"linux-x86_64\",\n-        \"x86_64-unknown-netbsd\" => \"BSD-x86_64\",\n-        _ => panic!(\"don't know how to configure OpenSSL for {}\", target),\n-    };\n-    configure.arg(os);\n-    configure.env(\"CC\", build.cc(target));\n-    for flag in build.cflags(target) {\n-        configure.arg(flag);\n-    }\n-    // There is no specific os target for android aarch64 or x86_64,\n-    // so we need to pass some extra cflags\n-    if target == \"aarch64-linux-android\" || target == \"x86_64-linux-android\" {\n-        configure.arg(\"-mandroid\");\n-        configure.arg(\"-fomit-frame-pointer\");\n-    }\n-    // Make PIE binaries\n-    // Non-PIE linker support was removed in Lollipop\n-    // https://source.android.com/security/enhancements/enhancements50\n-    if target == \"i686-linux-android\" {\n-        configure.arg(\"no-asm\");\n+        // There is no specific os target for android aarch64 or x86_64,\n+        // so we need to pass some extra cflags\n+        if target == \"aarch64-linux-android\" || target == \"x86_64-linux-android\" {\n+            configure.arg(\"-mandroid\");\n+            configure.arg(\"-fomit-frame-pointer\");\n+        }\n+        // Make PIE binaries\n+        // Non-PIE linker support was removed in Lollipop\n+        // https://source.android.com/security/enhancements/enhancements50\n+        if target == \"i686-linux-android\" {\n+            configure.arg(\"no-asm\");\n+        }\n+        configure.current_dir(&obj);\n+        println!(\"Configuring openssl for {}\", target);\n+        build.run_quiet(&mut configure);\n+        println!(\"Building openssl for {}\", target);\n+        build.run_quiet(Command::new(\"make\").arg(\"-j1\").current_dir(&obj));\n+        println!(\"Installing openssl for {}\", target);\n+        build.run_quiet(Command::new(\"make\").arg(\"install\").current_dir(&obj));\n+\n+        let mut f = t!(File::create(&stamp));\n+        t!(f.write_all(OPENSSL_VERS.as_bytes()));\n     }\n-    configure.current_dir(&obj);\n-    println!(\"Configuring openssl for {}\", target);\n-    build.run_quiet(&mut configure);\n-    println!(\"Building openssl for {}\", target);\n-    build.run_quiet(Command::new(\"make\").arg(\"-j1\").current_dir(&obj));\n-    println!(\"Installing openssl for {}\", target);\n-    build.run_quiet(Command::new(\"make\").arg(\"install\").current_dir(&obj));\n-\n-    let mut f = t!(File::create(&stamp));\n-    t!(f.write_all(OPENSSL_VERS.as_bytes()));\n }"}, {"sha": "7063b28f19d012343e32813d7f4d208aab0c90a1", "filename": "src/bootstrap/sanity.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fsanity.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Fsanity.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fsanity.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -122,14 +122,14 @@ pub fn check(build: &mut Build) {\n             continue;\n         }\n \n-        cmd_finder.must_have(build.cc(target));\n-        if let Some(ar) = build.ar(target) {\n+        cmd_finder.must_have(build.cc(*target));\n+        if let Some(ar) = build.ar(*target) {\n             cmd_finder.must_have(ar);\n         }\n     }\n \n     for host in build.config.host.iter() {\n-        cmd_finder.must_have(build.cxx(host).unwrap());\n+        cmd_finder.must_have(build.cxx(*host).unwrap());\n \n         // The msvc hosts don't use jemalloc, turn it off globally to\n         // avoid packaging the dummy liballoc_jemalloc on that platform.\n@@ -139,7 +139,7 @@ pub fn check(build: &mut Build) {\n     }\n \n     // Externally configured LLVM requires FileCheck to exist\n-    let filecheck = build.llvm_filecheck(&build.build);\n+    let filecheck = build.llvm_filecheck(build.build);\n     if !filecheck.starts_with(&build.out) && !filecheck.exists() && build.config.codegen_tests {\n         panic!(\"FileCheck executable {:?} does not exist\", filecheck);\n     }\n@@ -153,7 +153,7 @@ pub fn check(build: &mut Build) {\n \n         // Make sure musl-root is valid if specified\n         if target.contains(\"musl\") && !target.contains(\"mips\") {\n-            match build.musl_root(target) {\n+            match build.musl_root(*target) {\n                 Some(root) => {\n                     if fs::metadata(root.join(\"lib/libc.a\")).is_err() {\n                         panic!(\"couldn't find libc.a in musl dir: {}\","}, {"sha": "a1b26f44b7de132317834581a4fdddf1eaf05188", "filename": "src/bootstrap/step.rs", "status": "removed", "additions": 0, "deletions": 1820, "changes": 1820, "blob_url": "https://github.com/rust-lang/rust/blob/f8d485f53dbe87e0d7b4ad14904fd7b0447a8cbe/src%2Fbootstrap%2Fstep.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8d485f53dbe87e0d7b4ad14904fd7b0447a8cbe/src%2Fbootstrap%2Fstep.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fstep.rs?ref=f8d485f53dbe87e0d7b4ad14904fd7b0447a8cbe", "patch": "@@ -1,1820 +0,0 @@\n-// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Definition of steps of the build system.\n-//!\n-//! This is where some of the real meat of rustbuild is located, in how we\n-//! define targets and the dependencies amongst them. This file can sort of be\n-//! viewed as just defining targets in a makefile which shell out to predefined\n-//! functions elsewhere about how to execute the target.\n-//!\n-//! The primary function here you're likely interested in is the `build_rules`\n-//! function. This will create a `Rules` structure which basically just lists\n-//! everything that rustbuild can do. Each rule has a human-readable name, a\n-//! path associated with it, some dependencies, and then a closure of how to\n-//! actually perform the rule.\n-//!\n-//! All steps below are defined in self-contained units, so adding a new target\n-//! to the build system should just involve adding the meta information here\n-//! along with the actual implementation elsewhere. You can find more comments\n-//! about how to define rules themselves below.\n-\n-use std::collections::{BTreeMap, HashSet, HashMap};\n-use std::mem;\n-use std::path::PathBuf;\n-use std::process;\n-\n-use check::{self, TestKind};\n-use compile;\n-use dist;\n-use doc;\n-use flags::Subcommand;\n-use install;\n-use native;\n-use {Compiler, Build, Mode};\n-\n-pub fn run(build: &Build) {\n-    let rules = build_rules(build);\n-    let steps = rules.plan();\n-    rules.run(&steps);\n-}\n-\n-pub fn build_rules<'a>(build: &'a Build) -> Rules {\n-    let mut rules = Rules::new(build);\n-\n-    // This is the first rule that we're going to define for rustbuild, which is\n-    // used to compile LLVM itself. All rules are added through the `rules`\n-    // structure created above and are configured through a builder-style\n-    // interface.\n-    //\n-    // First up we see the `build` method. This represents a rule that's part of\n-    // the top-level `build` subcommand. For example `./x.py build` is what this\n-    // is associating with. Note that this is normally only relevant if you flag\n-    // a rule as `default`, which we'll talk about later.\n-    //\n-    // Next up we'll see two arguments to this method:\n-    //\n-    // * `llvm` - this is the \"human readable\" name of this target. This name is\n-    //            not accessed anywhere outside this file itself (e.g. not in\n-    //            the CLI nor elsewhere in rustbuild). The purpose of this is to\n-    //            easily define dependencies between rules. That is, other rules\n-    //            will depend on this with the name \"llvm\".\n-    // * `src/llvm` - this is the relevant path to the rule that we're working\n-    //                with. This path is the engine behind how commands like\n-    //                `./x.py build src/llvm` work. This should typically point\n-    //                to the relevant component, but if there's not really a\n-    //                path to be assigned here you can pass something like\n-    //                `path/to/nowhere` to ignore it.\n-    //\n-    // After we create the rule with the `build` method we can then configure\n-    // various aspects of it. For example this LLVM rule uses `.host(true)` to\n-    // flag that it's a rule only for host targets. In other words, LLVM isn't\n-    // compiled for targets configured through `--target` (e.g. those we're just\n-    // building a standard library for).\n-    //\n-    // Next up the `dep` method will add a dependency to this rule. The closure\n-    // is yielded the step that represents executing the `llvm` rule itself\n-    // (containing information like stage, host, target, ...) and then it must\n-    // return a target that the step depends on. Here LLVM is actually\n-    // interesting where a cross-compiled LLVM depends on the host LLVM, but\n-    // otherwise it has no dependencies.\n-    //\n-    // To handle this we do a bit of dynamic dispatch to see what the dependency\n-    // is. If we're building a LLVM for the build triple, then we don't actually\n-    // have any dependencies! To do that we return a dependency on the `Step::noop()`\n-    // target which does nothing.\n-    //\n-    // If we're build a cross-compiled LLVM, however, we need to assemble the\n-    // libraries from the previous compiler. This step has the same name as\n-    // ours (llvm) but we want it for a different target, so we use the\n-    // builder-style methods on `Step` to configure this target to the build\n-    // triple.\n-    //\n-    // Finally, to finish off this rule, we define how to actually execute it.\n-    // That logic is all defined in the `native` module so we just delegate to\n-    // the relevant function there. The argument to the closure passed to `run`\n-    // is a `Step` (defined below) which encapsulates information like the\n-    // stage, target, host, etc.\n-    rules.build(\"llvm\", \"src/llvm\")\n-         .host(true)\n-         .dep(move |s| {\n-             if s.target == build.build {\n-                 Step::noop()\n-             } else {\n-                 s.target(&build.build)\n-             }\n-         })\n-         .run(move |s| native::llvm(build, s.target));\n-\n-    // Ok! After that example rule  that's hopefully enough to explain what's\n-    // going on here. You can check out the API docs below and also see a bunch\n-    // more examples of rules directly below as well.\n-\n-    // the compiler with no target libraries ready to go\n-    rules.build(\"rustc\", \"src/rustc\")\n-         .dep(|s| s.name(\"create-sysroot\").target(s.host))\n-         .dep(move |s| {\n-             if s.stage == 0 {\n-                 Step::noop()\n-             } else {\n-                 s.name(\"librustc\")\n-                  .host(&build.build)\n-                  .stage(s.stage - 1)\n-             }\n-         })\n-         .run(move |s| compile::assemble_rustc(build, s.stage, s.target));\n-\n-    // Helper for loading an entire DAG of crates, rooted at `name`\n-    let krates = |name: &str| {\n-        let mut ret = Vec::new();\n-        let mut list = vec![name];\n-        let mut visited = HashSet::new();\n-        while let Some(krate) = list.pop() {\n-            let default = krate == name;\n-            let krate = &build.crates[krate];\n-            let path = krate.path.strip_prefix(&build.src)\n-                // This handles out of tree paths\n-                .unwrap_or(&krate.path);\n-            ret.push((krate, path.to_str().unwrap(), default));\n-            for dep in krate.deps.iter() {\n-                if visited.insert(dep) && dep != \"build_helper\" {\n-                    list.push(dep);\n-                }\n-            }\n-        }\n-        ret\n-    };\n-\n-    // ========================================================================\n-    // Crate compilations\n-    //\n-    // Tools used during the build system but not shipped\n-    rules.build(\"create-sysroot\", \"path/to/nowhere\")\n-         .run(move |s| compile::create_sysroot(build, &s.compiler()));\n-\n-    // These rules are \"pseudo rules\" that don't actually do any work\n-    // themselves, but represent a complete sysroot with the relevant compiler\n-    // linked into place.\n-    //\n-    // That is, depending on \"libstd\" means that when the rule is completed then\n-    // the `stage` sysroot for the compiler `host` will be available with a\n-    // standard library built for `target` linked in place. Not all rules need\n-    // the compiler itself to be available, just the standard library, so\n-    // there's a distinction between the two.\n-    rules.build(\"libstd\", \"src/libstd\")\n-         .dep(|s| s.name(\"rustc\").target(s.host))\n-         .dep(|s| s.name(\"libstd-link\"));\n-    rules.build(\"libtest\", \"src/libtest\")\n-         .dep(|s| s.name(\"libstd\"))\n-         .dep(|s| s.name(\"libtest-link\"))\n-         .default(true);\n-    rules.build(\"librustc\", \"src/librustc\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .dep(|s| s.name(\"librustc-link\"))\n-         .host(true)\n-         .default(true);\n-\n-    // Helper method to define the rules to link a crate into its place in the\n-    // sysroot.\n-    //\n-    // The logic here is a little subtle as there's a few cases to consider.\n-    // Not all combinations of (stage, host, target) actually require something\n-    // to be compiled, but rather libraries could get propagated from a\n-    // different location. For example:\n-    //\n-    // * Any crate with a `host` that's not the build triple will not actually\n-    //   compile something. A different `host` means that the build triple will\n-    //   actually compile the libraries, and then we'll copy them over from the\n-    //   build triple to the `host` directory.\n-    //\n-    // * Some crates aren't even compiled by the build triple, but may be copied\n-    //   from previous stages. For example if we're not doing a full bootstrap\n-    //   then we may just depend on the stage1 versions of libraries to be\n-    //   available to get linked forward.\n-    //\n-    // * Finally, there are some cases, however, which do indeed comiple crates\n-    //   and link them into place afterwards.\n-    //\n-    // The rule definition below mirrors these three cases. The `dep` method\n-    // calculates the correct dependency which either comes from stage1, a\n-    // different compiler, or from actually building the crate itself (the `dep`\n-    // rule). The `run` rule then mirrors these three cases and links the cases\n-    // forward into the compiler sysroot specified from the correct location.\n-    fn crate_rule<'a, 'b>(build: &'a Build,\n-                          rules: &'b mut Rules<'a>,\n-                          krate: &'a str,\n-                          dep: &'a str,\n-                          link: fn(&Build, &Compiler, &Compiler, &str))\n-                          -> RuleBuilder<'a, 'b> {\n-        let mut rule = rules.build(&krate, \"path/to/nowhere\");\n-        rule.dep(move |s| {\n-                if build.force_use_stage1(&s.compiler(), s.target) {\n-                    s.host(&build.build).stage(1)\n-                } else if s.host == build.build {\n-                    s.name(dep)\n-                } else {\n-                    s.host(&build.build)\n-                }\n-            })\n-            .run(move |s| {\n-                if build.force_use_stage1(&s.compiler(), s.target) {\n-                    link(build,\n-                         &s.stage(1).host(&build.build).compiler(),\n-                         &s.compiler(),\n-                         s.target)\n-                } else if s.host == build.build {\n-                    link(build, &s.compiler(), &s.compiler(), s.target)\n-                } else {\n-                    link(build,\n-                         &s.host(&build.build).compiler(),\n-                         &s.compiler(),\n-                         s.target)\n-                }\n-            });\n-            rule\n-    }\n-\n-    // Similar to the `libstd`, `libtest`, and `librustc` rules above, except\n-    // these rules only represent the libraries being available in the sysroot,\n-    // not the compiler itself. This is done as not all rules need a compiler in\n-    // the sysroot, but may just need the libraries.\n-    //\n-    // All of these rules use the helper definition above.\n-    crate_rule(build,\n-               &mut rules,\n-               \"libstd-link\",\n-               \"build-crate-std\",\n-               compile::std_link)\n-        .dep(|s| s.name(\"startup-objects\"))\n-        .dep(|s| s.name(\"create-sysroot\").target(s.host));\n-    crate_rule(build,\n-               &mut rules,\n-               \"libtest-link\",\n-               \"build-crate-test\",\n-               compile::test_link)\n-        .dep(|s| s.name(\"libstd-link\"));\n-    crate_rule(build,\n-               &mut rules,\n-               \"librustc-link\",\n-               \"build-crate-rustc-main\",\n-               compile::rustc_link)\n-        .dep(|s| s.name(\"libtest-link\"));\n-\n-    for (krate, path, _default) in krates(\"std\") {\n-        rules.build(&krate.build_step, path)\n-             .dep(|s| s.name(\"startup-objects\"))\n-             .dep(move |s| s.name(\"rustc\").host(&build.build).target(s.host))\n-             .run(move |s| compile::std(build, s.target, &s.compiler()));\n-    }\n-    for (krate, path, _default) in krates(\"test\") {\n-        rules.build(&krate.build_step, path)\n-             .dep(|s| s.name(\"libstd-link\"))\n-             .run(move |s| compile::test(build, s.target, &s.compiler()));\n-    }\n-    for (krate, path, _default) in krates(\"rustc-main\") {\n-        rules.build(&krate.build_step, path)\n-             .dep(|s| s.name(\"libtest-link\"))\n-             .dep(move |s| s.name(\"llvm\").host(&build.build).stage(0))\n-             .dep(|s| s.name(\"may-run-build-script\"))\n-             .run(move |s| compile::rustc(build, s.target, &s.compiler()));\n-    }\n-\n-    // Crates which have build scripts need to rely on this rule to ensure that\n-    // the necessary prerequisites for a build script are linked and located in\n-    // place.\n-    rules.build(\"may-run-build-script\", \"path/to/nowhere\")\n-         .dep(move |s| {\n-             s.name(\"libstd-link\")\n-              .host(&build.build)\n-              .target(&build.build)\n-         });\n-    rules.build(\"startup-objects\", \"src/rtstartup\")\n-         .dep(|s| s.name(\"create-sysroot\").target(s.host))\n-         .run(move |s| compile::build_startup_objects(build, &s.compiler(), s.target));\n-\n-    // ========================================================================\n-    // Test targets\n-    //\n-    // Various unit tests and tests suites we can run\n-    {\n-        let mut suite = |name, path, mode, dir| {\n-            rules.test(name, path)\n-                 .dep(|s| s.name(\"libtest\"))\n-                 .dep(|s| s.name(\"tool-compiletest\").target(s.host).stage(0))\n-                 .dep(|s| s.name(\"test-helpers\"))\n-                 .dep(|s| s.name(\"remote-copy-libs\"))\n-                 .default(mode != \"pretty\") // pretty tests don't run everywhere\n-                 .run(move |s| {\n-                     check::compiletest(build, &s.compiler(), s.target, mode, dir)\n-                 });\n-        };\n-\n-        suite(\"check-ui\", \"src/test/ui\", \"ui\", \"ui\");\n-        suite(\"check-rpass\", \"src/test/run-pass\", \"run-pass\", \"run-pass\");\n-        suite(\"check-cfail\", \"src/test/compile-fail\", \"compile-fail\", \"compile-fail\");\n-        suite(\"check-pfail\", \"src/test/parse-fail\", \"parse-fail\", \"parse-fail\");\n-        suite(\"check-rfail\", \"src/test/run-fail\", \"run-fail\", \"run-fail\");\n-        suite(\"check-rpass-valgrind\", \"src/test/run-pass-valgrind\",\n-              \"run-pass-valgrind\", \"run-pass-valgrind\");\n-        suite(\"check-mir-opt\", \"src/test/mir-opt\", \"mir-opt\", \"mir-opt\");\n-        if build.config.codegen_tests {\n-            suite(\"check-codegen\", \"src/test/codegen\", \"codegen\", \"codegen\");\n-        }\n-        suite(\"check-codegen-units\", \"src/test/codegen-units\", \"codegen-units\",\n-              \"codegen-units\");\n-        suite(\"check-incremental\", \"src/test/incremental\", \"incremental\",\n-              \"incremental\");\n-    }\n-\n-    if build.build.contains(\"msvc\") {\n-        // nothing to do for debuginfo tests\n-    } else {\n-        rules.test(\"check-debuginfo-lldb\", \"src/test/debuginfo-lldb\")\n-             .dep(|s| s.name(\"libtest\"))\n-             .dep(|s| s.name(\"tool-compiletest\").target(s.host).stage(0))\n-             .dep(|s| s.name(\"test-helpers\"))\n-             .dep(|s| s.name(\"debugger-scripts\"))\n-             .run(move |s| check::compiletest(build, &s.compiler(), s.target,\n-                                         \"debuginfo-lldb\", \"debuginfo\"));\n-        rules.test(\"check-debuginfo-gdb\", \"src/test/debuginfo-gdb\")\n-             .dep(|s| s.name(\"libtest\"))\n-             .dep(|s| s.name(\"tool-compiletest\").target(s.host).stage(0))\n-             .dep(|s| s.name(\"test-helpers\"))\n-             .dep(|s| s.name(\"debugger-scripts\"))\n-             .dep(|s| s.name(\"remote-copy-libs\"))\n-             .run(move |s| check::compiletest(build, &s.compiler(), s.target,\n-                                         \"debuginfo-gdb\", \"debuginfo\"));\n-        let mut rule = rules.test(\"check-debuginfo\", \"src/test/debuginfo\");\n-        rule.default(true);\n-        if build.build.contains(\"apple\") {\n-            rule.dep(|s| s.name(\"check-debuginfo-lldb\"));\n-        } else {\n-            rule.dep(|s| s.name(\"check-debuginfo-gdb\"));\n-        }\n-    }\n-\n-    rules.test(\"debugger-scripts\", \"src/etc/lldb_batchmode.py\")\n-         .run(move |s| dist::debugger_scripts(build, &build.sysroot(&s.compiler()),\n-                                         s.target));\n-\n-    {\n-        let mut suite = |name, path, mode, dir| {\n-            rules.test(name, path)\n-                 .dep(|s| s.name(\"librustc\"))\n-                 .dep(|s| s.name(\"test-helpers\"))\n-                 .dep(|s| s.name(\"tool-compiletest\").target(s.host).stage(0))\n-                 .default(mode != \"pretty\")\n-                 .host(true)\n-                 .run(move |s| {\n-                     check::compiletest(build, &s.compiler(), s.target, mode, dir)\n-                 });\n-        };\n-\n-        suite(\"check-ui-full\", \"src/test/ui-fulldeps\", \"ui\", \"ui-fulldeps\");\n-        suite(\"check-rpass-full\", \"src/test/run-pass-fulldeps\",\n-              \"run-pass\", \"run-pass-fulldeps\");\n-        suite(\"check-rfail-full\", \"src/test/run-fail-fulldeps\",\n-              \"run-fail\", \"run-fail-fulldeps\");\n-        suite(\"check-cfail-full\", \"src/test/compile-fail-fulldeps\",\n-              \"compile-fail\", \"compile-fail-fulldeps\");\n-        suite(\"check-rmake\", \"src/test/run-make\", \"run-make\", \"run-make\");\n-        suite(\"check-rustdoc\", \"src/test/rustdoc\", \"rustdoc\", \"rustdoc\");\n-        suite(\"check-pretty\", \"src/test/pretty\", \"pretty\", \"pretty\");\n-        suite(\"check-pretty-rpass\", \"src/test/run-pass/pretty\", \"pretty\",\n-              \"run-pass\");\n-        suite(\"check-pretty-rfail\", \"src/test/run-fail/pretty\", \"pretty\",\n-              \"run-fail\");\n-        suite(\"check-pretty-valgrind\", \"src/test/run-pass-valgrind/pretty\", \"pretty\",\n-              \"run-pass-valgrind\");\n-        suite(\"check-pretty-rpass-full\", \"src/test/run-pass-fulldeps/pretty\",\n-              \"pretty\", \"run-pass-fulldeps\");\n-        suite(\"check-pretty-rfail-full\", \"src/test/run-fail-fulldeps/pretty\",\n-              \"pretty\", \"run-fail-fulldeps\");\n-    }\n-\n-    for (krate, path, _default) in krates(\"std\") {\n-        rules.test(&krate.test_step, path)\n-             .dep(|s| s.name(\"libtest\"))\n-             .dep(|s| s.name(\"remote-copy-libs\"))\n-             .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                        Mode::Libstd, TestKind::Test,\n-                                        Some(&krate.name)));\n-    }\n-    rules.test(\"check-std-all\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .dep(|s| s.name(\"remote-copy-libs\"))\n-         .default(true)\n-         .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                    Mode::Libstd, TestKind::Test, None));\n-\n-    // std benchmarks\n-    for (krate, path, _default) in krates(\"std\") {\n-        rules.bench(&krate.bench_step, path)\n-             .dep(|s| s.name(\"libtest\"))\n-             .dep(|s| s.name(\"remote-copy-libs\"))\n-             .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                        Mode::Libstd, TestKind::Bench,\n-                                        Some(&krate.name)));\n-    }\n-    rules.bench(\"bench-std-all\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .dep(|s| s.name(\"remote-copy-libs\"))\n-         .default(true)\n-         .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                    Mode::Libstd, TestKind::Bench, None));\n-\n-    for (krate, path, _default) in krates(\"test\") {\n-        rules.test(&krate.test_step, path)\n-             .dep(|s| s.name(\"libtest\"))\n-             .dep(|s| s.name(\"remote-copy-libs\"))\n-             .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                        Mode::Libtest, TestKind::Test,\n-                                        Some(&krate.name)));\n-    }\n-    rules.test(\"check-test-all\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .dep(|s| s.name(\"remote-copy-libs\"))\n-         .default(true)\n-         .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                    Mode::Libtest, TestKind::Test, None));\n-    for (krate, path, _default) in krates(\"rustc-main\") {\n-        rules.test(&krate.test_step, path)\n-             .dep(|s| s.name(\"librustc\"))\n-             .dep(|s| s.name(\"remote-copy-libs\"))\n-             .host(true)\n-             .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                        Mode::Librustc, TestKind::Test,\n-                                        Some(&krate.name)));\n-    }\n-    rules.test(\"check-rustc-all\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"librustc\"))\n-         .dep(|s| s.name(\"remote-copy-libs\"))\n-         .default(true)\n-         .host(true)\n-         .run(move |s| check::krate(build, &s.compiler(), s.target,\n-                                    Mode::Librustc, TestKind::Test, None));\n-\n-    rules.test(\"check-linkchecker\", \"src/tools/linkchecker\")\n-         .dep(|s| s.name(\"tool-linkchecker\").stage(0))\n-         .dep(|s| s.name(\"default:doc\"))\n-         .default(build.config.docs)\n-         .host(true)\n-         .run(move |s| check::linkcheck(build, s.target));\n-    rules.test(\"check-cargotest\", \"src/tools/cargotest\")\n-         .dep(|s| s.name(\"tool-cargotest\").stage(0))\n-         .dep(|s| s.name(\"librustc\"))\n-         .host(true)\n-         .run(move |s| check::cargotest(build, s.stage, s.target));\n-    rules.test(\"check-cargo\", \"src/tools/cargo\")\n-         .dep(|s| s.name(\"tool-cargo\"))\n-         .host(true)\n-         .run(move |s| check::cargo(build, s.stage, s.target));\n-    rules.test(\"check-rls\", \"src/tools/rls\")\n-         .dep(|s| s.name(\"tool-rls\"))\n-         .host(true)\n-         .run(move |s| check::rls(build, s.stage, s.target));\n-    rules.test(\"check-tidy\", \"src/tools/tidy\")\n-         .dep(|s| s.name(\"tool-tidy\").stage(0))\n-         .default(true)\n-         .host(true)\n-         .only_build(true)\n-         .run(move |s| check::tidy(build, s.target));\n-    rules.test(\"check-error-index\", \"src/tools/error_index_generator\")\n-         .dep(|s| s.name(\"libstd\"))\n-         .dep(|s| s.name(\"tool-error-index\").host(s.host).stage(0))\n-         .default(true)\n-         .host(true)\n-         .run(move |s| check::error_index(build, &s.compiler()));\n-    rules.test(\"check-docs\", \"src/doc\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .default(true)\n-         .host(true)\n-         .run(move |s| check::docs(build, &s.compiler()));\n-    rules.test(\"check-distcheck\", \"distcheck\")\n-         .dep(|s| s.name(\"dist-plain-source-tarball\"))\n-         .dep(|s| s.name(\"dist-src\"))\n-         .run(move |_| check::distcheck(build));\n-\n-    rules.build(\"test-helpers\", \"src/rt/rust_test_helpers.c\")\n-         .run(move |s| native::test_helpers(build, s.target));\n-    rules.build(\"openssl\", \"path/to/nowhere\")\n-         .run(move |s| native::openssl(build, s.target));\n-\n-    // Some test suites are run inside emulators or on remote devices, and most\n-    // of our test binaries are linked dynamically which means we need to ship\n-    // the standard library and such to the emulator ahead of time. This step\n-    // represents this and is a dependency of all test suites.\n-    //\n-    // Most of the time this step is a noop (the `check::emulator_copy_libs`\n-    // only does work if necessary). For some steps such as shipping data to\n-    // QEMU we have to build our own tools so we've got conditional dependencies\n-    // on those programs as well. Note that the remote test client is built for\n-    // the build target (us) and the server is built for the target.\n-    rules.test(\"remote-copy-libs\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .dep(move |s| {\n-             if build.remote_tested(s.target) {\n-                s.name(\"tool-remote-test-client\").target(s.host).stage(0)\n-             } else {\n-                 Step::noop()\n-             }\n-         })\n-         .dep(move |s| {\n-             if build.remote_tested(s.target) {\n-                s.name(\"tool-remote-test-server\")\n-             } else {\n-                 Step::noop()\n-             }\n-         })\n-         .run(move |s| check::remote_copy_libs(build, &s.compiler(), s.target));\n-\n-    rules.test(\"check-bootstrap\", \"src/bootstrap\")\n-         .default(true)\n-         .host(true)\n-         .only_build(true)\n-         .run(move |_| check::bootstrap(build));\n-\n-    // ========================================================================\n-    // Build tools\n-    //\n-    // Tools used during the build system but not shipped\n-    rules.build(\"tool-rustbook\", \"src/tools/rustbook\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"librustc-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"rustbook\"));\n-    rules.build(\"tool-error-index\", \"src/tools/error_index_generator\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"librustc-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"error_index_generator\"));\n-    rules.build(\"tool-unstable-book-gen\", \"src/tools/unstable-book-gen\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"unstable-book-gen\"));\n-    rules.build(\"tool-tidy\", \"src/tools/tidy\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"tidy\"));\n-    rules.build(\"tool-linkchecker\", \"src/tools/linkchecker\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"linkchecker\"));\n-    rules.build(\"tool-cargotest\", \"src/tools/cargotest\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"cargotest\"));\n-    rules.build(\"tool-compiletest\", \"src/tools/compiletest\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libtest-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"compiletest\"));\n-    rules.build(\"tool-build-manifest\", \"src/tools/build-manifest\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"build-manifest\"));\n-    rules.build(\"tool-remote-test-server\", \"src/tools/remote-test-server\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"remote-test-server\"));\n-    rules.build(\"tool-remote-test-client\", \"src/tools/remote-test-client\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"remote-test-client\"));\n-    rules.build(\"tool-rust-installer\", \"src/tools/rust-installer\")\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"rust-installer\"));\n-    rules.build(\"tool-cargo\", \"src/tools/cargo\")\n-         .host(true)\n-         .default(build.config.extended)\n-         .dep(|s| s.name(\"maybe-clean-tools\"))\n-         .dep(|s| s.name(\"libstd-tool\"))\n-         .dep(|s| s.stage(0).host(s.target).name(\"openssl\"))\n-         .dep(move |s| {\n-             // Cargo depends on procedural macros, which requires a full host\n-             // compiler to be available, so we need to depend on that.\n-             s.name(\"librustc-link\")\n-              .target(&build.build)\n-              .host(&build.build)\n-         })\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"cargo\"));\n-    rules.build(\"tool-rls\", \"src/tools/rls\")\n-         .host(true)\n-         .default(build.config.extended)\n-         .dep(|s| s.name(\"librustc-tool\"))\n-         .dep(|s| s.stage(0).host(s.target).name(\"openssl\"))\n-         .dep(move |s| {\n-             // rls, like cargo, uses procedural macros\n-             s.name(\"librustc-link\")\n-              .target(&build.build)\n-              .host(&build.build)\n-         })\n-         .run(move |s| compile::tool(build, s.stage, s.target, \"rls\"));\n-\n-    // \"pseudo rule\" which represents completely cleaning out the tools dir in\n-    // one stage. This needs to happen whenever a dependency changes (e.g.\n-    // libstd, libtest, librustc) and all of the tool compilations above will\n-    // be sequenced after this rule.\n-    rules.build(\"maybe-clean-tools\", \"path/to/nowhere\")\n-         .after(\"librustc-tool\")\n-         .after(\"libtest-tool\")\n-         .after(\"libstd-tool\");\n-\n-    rules.build(\"librustc-tool\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"librustc\"))\n-         .run(move |s| compile::maybe_clean_tools(build, s.stage, s.target, Mode::Librustc));\n-    rules.build(\"libtest-tool\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"libtest\"))\n-         .run(move |s| compile::maybe_clean_tools(build, s.stage, s.target, Mode::Libtest));\n-    rules.build(\"libstd-tool\", \"path/to/nowhere\")\n-         .dep(|s| s.name(\"libstd\"))\n-         .run(move |s| compile::maybe_clean_tools(build, s.stage, s.target, Mode::Libstd));\n-\n-    // ========================================================================\n-    // Documentation targets\n-    rules.doc(\"doc-book\", \"src/doc/book\")\n-         .dep(move |s| {\n-             s.name(\"tool-rustbook\")\n-              .host(&build.build)\n-              .target(&build.build)\n-              .stage(0)\n-         })\n-         .default(build.config.docs)\n-         .run(move |s| doc::book(build, s.target, \"book\"));\n-    rules.doc(\"doc-nomicon\", \"src/doc/nomicon\")\n-         .dep(move |s| {\n-             s.name(\"tool-rustbook\")\n-              .host(&build.build)\n-              .target(&build.build)\n-              .stage(0)\n-         })\n-         .default(build.config.docs)\n-         .run(move |s| doc::rustbook(build, s.target, \"nomicon\"));\n-    rules.doc(\"doc-reference\", \"src/doc/reference\")\n-         .dep(move |s| {\n-             s.name(\"tool-rustbook\")\n-              .host(&build.build)\n-              .target(&build.build)\n-              .stage(0)\n-         })\n-         .default(build.config.docs)\n-         .run(move |s| doc::rustbook(build, s.target, \"reference\"));\n-    rules.doc(\"doc-unstable-book\", \"src/doc/unstable-book\")\n-         .dep(move |s| {\n-             s.name(\"tool-rustbook\")\n-              .host(&build.build)\n-              .target(&build.build)\n-              .stage(0)\n-         })\n-         .dep(move |s| s.name(\"doc-unstable-book-gen\"))\n-         .default(build.config.docs)\n-         .run(move |s| doc::rustbook_src(build,\n-                                         s.target,\n-                                         \"unstable-book\",\n-                                         &build.md_doc_out(s.target)));\n-    rules.doc(\"doc-standalone\", \"src/doc\")\n-         .dep(move |s| {\n-             s.name(\"rustc\")\n-              .host(&build.build)\n-              .target(&build.build)\n-              .stage(0)\n-         })\n-         .default(build.config.docs)\n-         .run(move |s| doc::standalone(build, s.target));\n-    rules.doc(\"doc-error-index\", \"src/tools/error_index_generator\")\n-         .dep(move |s| s.name(\"tool-error-index\").target(&build.build).stage(0))\n-         .dep(move |s| s.name(\"librustc-link\"))\n-         .default(build.config.docs)\n-         .host(true)\n-         .run(move |s| doc::error_index(build, s.target));\n-    rules.doc(\"doc-unstable-book-gen\", \"src/tools/unstable-book-gen\")\n-         .dep(move |s| {\n-             s.name(\"tool-unstable-book-gen\")\n-              .host(&build.build)\n-              .target(&build.build)\n-              .stage(0)\n-         })\n-         .dep(move |s| s.name(\"libstd-link\"))\n-         .default(build.config.docs)\n-         .host(true)\n-         .run(move |s| doc::unstable_book_gen(build, s.target));\n-    for (krate, path, default) in krates(\"std\") {\n-        rules.doc(&krate.doc_step, path)\n-             .dep(|s| s.name(\"libstd-link\"))\n-             .default(default && build.config.docs)\n-             .run(move |s| doc::std(build, s.stage, s.target));\n-    }\n-    for (krate, path, default) in krates(\"test\") {\n-        rules.doc(&krate.doc_step, path)\n-             .dep(|s| s.name(\"libtest-link\"))\n-             // Needed so rustdoc generates relative links to std.\n-             .dep(|s| s.name(\"doc-crate-std\"))\n-             .default(default && build.config.compiler_docs)\n-             .run(move |s| doc::test(build, s.stage, s.target));\n-    }\n-    for (krate, path, default) in krates(\"rustc-main\") {\n-        rules.doc(&krate.doc_step, path)\n-             .dep(|s| s.name(\"librustc-link\"))\n-             // Needed so rustdoc generates relative links to std.\n-             .dep(|s| s.name(\"doc-crate-std\"))\n-             .host(true)\n-             .default(default && build.config.docs)\n-             .run(move |s| doc::rustc(build, s.stage, s.target));\n-    }\n-\n-    // ========================================================================\n-    // Distribution targets\n-    rules.dist(\"dist-rustc\", \"src/librustc\")\n-         .dep(move |s| s.name(\"rustc\").host(&build.build))\n-         .host(true)\n-         .only_host_build(true)\n-         .default(true)\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::rustc(build, s.stage, s.target));\n-    rules.dist(\"dist-std\", \"src/libstd\")\n-         .dep(move |s| {\n-             // We want to package up as many target libraries as possible\n-             // for the `rust-std` package, so if this is a host target we\n-             // depend on librustc and otherwise we just depend on libtest.\n-             if build.config.host.iter().any(|t| t == s.target) {\n-                 s.name(\"librustc-link\")\n-             } else {\n-                 s.name(\"libtest-link\")\n-             }\n-         })\n-         .default(true)\n-         .only_host_build(true)\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::std(build, &s.compiler(), s.target));\n-    rules.dist(\"dist-mingw\", \"path/to/nowhere\")\n-         .default(true)\n-         .only_host_build(true)\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| {\n-             if s.target.contains(\"pc-windows-gnu\") {\n-                 dist::mingw(build, s.target)\n-             }\n-         });\n-    rules.dist(\"dist-plain-source-tarball\", \"src\")\n-         .default(build.config.rust_dist_src)\n-         .host(true)\n-         .only_build(true)\n-         .only_host_build(true)\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |_| dist::plain_source_tarball(build));\n-    rules.dist(\"dist-src\", \"src\")\n-         .default(true)\n-         .host(true)\n-         .only_build(true)\n-         .only_host_build(true)\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |_| dist::rust_src(build));\n-    rules.dist(\"dist-docs\", \"src/doc\")\n-         .default(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"default:doc\"))\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::docs(build, s.stage, s.target));\n-    rules.dist(\"dist-analysis\", \"analysis\")\n-         .default(build.config.extended)\n-         .dep(|s| s.name(\"dist-std\"))\n-         .only_host_build(true)\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::analysis(build, &s.compiler(), s.target));\n-    rules.dist(\"dist-rls\", \"rls\")\n-         .host(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"tool-rls\"))\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::rls(build, s.stage, s.target));\n-    rules.dist(\"dist-cargo\", \"cargo\")\n-         .host(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"tool-cargo\"))\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::cargo(build, s.stage, s.target));\n-    rules.dist(\"dist-extended\", \"extended\")\n-         .default(build.config.extended)\n-         .host(true)\n-         .only_host_build(true)\n-         .dep(|d| d.name(\"dist-std\"))\n-         .dep(|d| d.name(\"dist-rustc\"))\n-         .dep(|d| d.name(\"dist-mingw\"))\n-         .dep(|d| d.name(\"dist-docs\"))\n-         .dep(|d| d.name(\"dist-cargo\"))\n-         .dep(|d| d.name(\"dist-rls\"))\n-         .dep(|d| d.name(\"dist-analysis\"))\n-         .dep(move |s| tool_rust_installer(build, s))\n-         .run(move |s| dist::extended(build, s.stage, s.target));\n-\n-    rules.dist(\"dist-sign\", \"hash-and-sign\")\n-         .host(true)\n-         .only_build(true)\n-         .only_host_build(true)\n-         .dep(move |s| s.name(\"tool-build-manifest\").target(&build.build).stage(0))\n-         .run(move |_| dist::hash_and_sign(build));\n-\n-    rules.install(\"install-docs\", \"src/doc\")\n-         .default(build.config.docs)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-docs\"))\n-         .run(move |s| install::Installer::new(build).install_docs(s.stage, s.target));\n-    rules.install(\"install-std\", \"src/libstd\")\n-         .default(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-std\"))\n-         .run(move |s| install::Installer::new(build).install_std(s.stage));\n-    rules.install(\"install-cargo\", \"cargo\")\n-         .default(build.config.extended)\n-         .host(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-cargo\"))\n-         .run(move |s| install::Installer::new(build).install_cargo(s.stage, s.target));\n-    rules.install(\"install-rls\", \"rls\")\n-         .default(build.config.extended)\n-         .host(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-rls\"))\n-         .run(move |s| install::Installer::new(build).install_rls(s.stage, s.target));\n-    rules.install(\"install-analysis\", \"analysis\")\n-         .default(build.config.extended)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-analysis\"))\n-         .run(move |s| install::Installer::new(build).install_analysis(s.stage, s.target));\n-    rules.install(\"install-src\", \"src\")\n-         .default(build.config.extended)\n-         .host(true)\n-         .only_build(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-src\"))\n-         .run(move |s| install::Installer::new(build).install_src(s.stage));\n-    rules.install(\"install-rustc\", \"src/librustc\")\n-         .default(true)\n-         .host(true)\n-         .only_host_build(true)\n-         .dep(|s| s.name(\"dist-rustc\"))\n-         .run(move |s| install::Installer::new(build).install_rustc(s.stage, s.target));\n-\n-    rules.verify();\n-    return rules;\n-\n-    /// Helper to depend on a stage0 build-only rust-installer tool.\n-    fn tool_rust_installer<'a>(build: &'a Build, step: &Step<'a>) -> Step<'a> {\n-        step.name(\"tool-rust-installer\")\n-            .host(&build.build)\n-            .target(&build.build)\n-            .stage(0)\n-    }\n-}\n-\n-#[derive(PartialEq, Eq, Hash, Clone, Debug)]\n-struct Step<'a> {\n-    /// Human readable name of the rule this step is executing. Possible names\n-    /// are all defined above in `build_rules`.\n-    name: &'a str,\n-\n-    /// The stage this step is executing in. This is typically 0, 1, or 2.\n-    stage: u32,\n-\n-    /// This step will likely involve a compiler, and the target that compiler\n-    /// itself is built for is called the host, this variable. Typically this is\n-    /// the target of the build machine itself.\n-    host: &'a str,\n-\n-    /// The target that this step represents generating. If you're building a\n-    /// standard library for a new suite of targets, for example, this'll be set\n-    /// to those targets.\n-    target: &'a str,\n-}\n-\n-impl<'a> Step<'a> {\n-    fn noop() -> Step<'a> {\n-        Step { name: \"\", stage: 0, host: \"\", target: \"\" }\n-    }\n-\n-    /// Creates a new step which is the same as this, except has a new name.\n-    fn name(&self, name: &'a str) -> Step<'a> {\n-        Step { name: name, ..*self }\n-    }\n-\n-    /// Creates a new step which is the same as this, except has a new stage.\n-    fn stage(&self, stage: u32) -> Step<'a> {\n-        Step { stage: stage, ..*self }\n-    }\n-\n-    /// Creates a new step which is the same as this, except has a new host.\n-    fn host(&self, host: &'a str) -> Step<'a> {\n-        Step { host: host, ..*self }\n-    }\n-\n-    /// Creates a new step which is the same as this, except has a new target.\n-    fn target(&self, target: &'a str) -> Step<'a> {\n-        Step { target: target, ..*self }\n-    }\n-\n-    /// Returns the `Compiler` structure that this step corresponds to.\n-    fn compiler(&self) -> Compiler<'a> {\n-        Compiler::new(self.stage, self.host)\n-    }\n-}\n-\n-struct Rule<'a> {\n-    /// The human readable name of this target, defined in `build_rules`.\n-    name: &'a str,\n-\n-    /// The path associated with this target, used in the `./x.py` driver for\n-    /// easy and ergonomic specification of what to do.\n-    path: &'a str,\n-\n-    /// The \"kind\" of top-level command that this rule is associated with, only\n-    /// relevant if this is a default rule.\n-    kind: Kind,\n-\n-    /// List of dependencies this rule has. Each dependency is a function from a\n-    /// step that's being executed to another step that should be executed.\n-    deps: Vec<Box<Fn(&Step<'a>) -> Step<'a> + 'a>>,\n-\n-    /// How to actually execute this rule. Takes a step with contextual\n-    /// information and then executes it.\n-    run: Box<Fn(&Step<'a>) + 'a>,\n-\n-    /// Whether or not this is a \"default\" rule. That basically means that if\n-    /// you run, for example, `./x.py test` whether it's included or not.\n-    default: bool,\n-\n-    /// Whether or not this is a \"host\" rule, or in other words whether this is\n-    /// only intended for compiler hosts and not for targets that are being\n-    /// generated.\n-    host: bool,\n-\n-    /// Whether this rule is only for steps where the host is the build triple,\n-    /// not anything in hosts or targets.\n-    only_host_build: bool,\n-\n-    /// Whether this rule is only for the build triple, not anything in hosts or\n-    /// targets.\n-    only_build: bool,\n-\n-    /// A list of \"order only\" dependencies. This rules does not actually\n-    /// depend on these rules, but if they show up in the dependency graph then\n-    /// this rule must be executed after all these rules.\n-    after: Vec<&'a str>,\n-}\n-\n-#[derive(PartialEq)]\n-enum Kind {\n-    Build,\n-    Test,\n-    Bench,\n-    Dist,\n-    Doc,\n-    Install,\n-}\n-\n-impl<'a> Rule<'a> {\n-    fn new(name: &'a str, path: &'a str, kind: Kind) -> Rule<'a> {\n-        Rule {\n-            name: name,\n-            deps: Vec::new(),\n-            run: Box::new(|_| ()),\n-            path: path,\n-            kind: kind,\n-            default: false,\n-            host: false,\n-            only_host_build: false,\n-            only_build: false,\n-            after: Vec::new(),\n-        }\n-    }\n-}\n-\n-/// Builder pattern returned from the various methods on `Rules` which will add\n-/// the rule to the internal list on `Drop`.\n-struct RuleBuilder<'a: 'b, 'b> {\n-    rules: &'b mut Rules<'a>,\n-    rule: Rule<'a>,\n-}\n-\n-impl<'a, 'b> RuleBuilder<'a, 'b> {\n-    fn dep<F>(&mut self, f: F) -> &mut Self\n-        where F: Fn(&Step<'a>) -> Step<'a> + 'a,\n-    {\n-        self.rule.deps.push(Box::new(f));\n-        self\n-    }\n-\n-    fn after(&mut self, step: &'a str) -> &mut Self {\n-        self.rule.after.push(step);\n-        self\n-    }\n-\n-    fn run<F>(&mut self, f: F) -> &mut Self\n-        where F: Fn(&Step<'a>) + 'a,\n-    {\n-        self.rule.run = Box::new(f);\n-        self\n-    }\n-\n-    fn default(&mut self, default: bool) -> &mut Self {\n-        self.rule.default = default;\n-        self\n-    }\n-\n-    fn host(&mut self, host: bool) -> &mut Self {\n-        self.rule.host = host;\n-        self\n-    }\n-\n-    fn only_build(&mut self, only_build: bool) -> &mut Self {\n-        self.rule.only_build = only_build;\n-        self\n-    }\n-\n-    fn only_host_build(&mut self, only_host_build: bool) -> &mut Self {\n-        self.rule.only_host_build = only_host_build;\n-        self\n-    }\n-}\n-\n-impl<'a, 'b> Drop for RuleBuilder<'a, 'b> {\n-    fn drop(&mut self) {\n-        let rule = mem::replace(&mut self.rule, Rule::new(\"\", \"\", Kind::Build));\n-        let prev = self.rules.rules.insert(rule.name, rule);\n-        if let Some(prev) = prev {\n-            panic!(\"duplicate rule named: {}\", prev.name);\n-        }\n-    }\n-}\n-\n-pub struct Rules<'a> {\n-    build: &'a Build,\n-    sbuild: Step<'a>,\n-    rules: BTreeMap<&'a str, Rule<'a>>,\n-}\n-\n-impl<'a> Rules<'a> {\n-    fn new(build: &'a Build) -> Rules<'a> {\n-        Rules {\n-            build: build,\n-            sbuild: Step {\n-                stage: build.flags.stage.unwrap_or(2),\n-                target: &build.build,\n-                host: &build.build,\n-                name: \"\",\n-            },\n-            rules: BTreeMap::new(),\n-        }\n-    }\n-\n-    /// Creates a new rule of `Kind::Build` with the specified human readable\n-    /// name and path associated with it.\n-    ///\n-    /// The builder returned should be configured further with information such\n-    /// as how to actually run this rule.\n-    fn build<'b>(&'b mut self, name: &'a str, path: &'a str)\n-                 -> RuleBuilder<'a, 'b> {\n-        self.rule(name, path, Kind::Build)\n-    }\n-\n-    /// Same as `build`, but for `Kind::Test`.\n-    fn test<'b>(&'b mut self, name: &'a str, path: &'a str)\n-                -> RuleBuilder<'a, 'b> {\n-        self.rule(name, path, Kind::Test)\n-    }\n-\n-    /// Same as `build`, but for `Kind::Bench`.\n-    fn bench<'b>(&'b mut self, name: &'a str, path: &'a str)\n-                -> RuleBuilder<'a, 'b> {\n-        self.rule(name, path, Kind::Bench)\n-    }\n-\n-    /// Same as `build`, but for `Kind::Doc`.\n-    fn doc<'b>(&'b mut self, name: &'a str, path: &'a str)\n-               -> RuleBuilder<'a, 'b> {\n-        self.rule(name, path, Kind::Doc)\n-    }\n-\n-    /// Same as `build`, but for `Kind::Dist`.\n-    fn dist<'b>(&'b mut self, name: &'a str, path: &'a str)\n-                -> RuleBuilder<'a, 'b> {\n-        self.rule(name, path, Kind::Dist)\n-    }\n-\n-    /// Same as `build`, but for `Kind::Install`.\n-    fn install<'b>(&'b mut self, name: &'a str, path: &'a str)\n-                -> RuleBuilder<'a, 'b> {\n-        self.rule(name, path, Kind::Install)\n-    }\n-\n-    fn rule<'b>(&'b mut self,\n-                name: &'a str,\n-                path: &'a str,\n-                kind: Kind) -> RuleBuilder<'a, 'b> {\n-        RuleBuilder {\n-            rules: self,\n-            rule: Rule::new(name, path, kind),\n-        }\n-    }\n-\n-    /// Verify the dependency graph defined by all our rules are correct, e.g.\n-    /// everything points to a valid something else.\n-    fn verify(&self) {\n-        for rule in self.rules.values() {\n-            for dep in rule.deps.iter() {\n-                let dep = dep(&self.sbuild.name(rule.name));\n-                if self.rules.contains_key(&dep.name) || dep.name.starts_with(\"default:\") {\n-                    continue\n-                }\n-                if dep == Step::noop() {\n-                    continue\n-                }\n-                panic!(\"\\\n-\n-invalid rule dependency graph detected, was a rule added and maybe typo'd?\n-\n-    `{}` depends on `{}` which does not exist\n-\n-\", rule.name, dep.name);\n-            }\n-        }\n-    }\n-\n-    pub fn get_help(&self, command: &str) -> Option<String> {\n-        let kind = match command {\n-            \"build\" => Kind::Build,\n-            \"doc\" => Kind::Doc,\n-            \"test\" => Kind::Test,\n-            \"bench\" => Kind::Bench,\n-            \"dist\" => Kind::Dist,\n-            \"install\" => Kind::Install,\n-            _ => return None,\n-        };\n-        let rules = self.rules.values().filter(|r| r.kind == kind);\n-        let rules = rules.filter(|r| !r.path.contains(\"nowhere\"));\n-        let mut rules = rules.collect::<Vec<_>>();\n-        rules.sort_by_key(|r| r.path);\n-\n-        let mut help_string = String::from(\"Available paths:\\n\");\n-        for rule in rules {\n-            help_string.push_str(format!(\"    ./x.py {} {}\\n\", command, rule.path).as_str());\n-        }\n-        Some(help_string)\n-    }\n-\n-    /// Construct the top-level build steps that we're going to be executing,\n-    /// given the subcommand that our build is performing.\n-    fn plan(&self) -> Vec<Step<'a>> {\n-        // Ok, the logic here is pretty subtle, and involves quite a few\n-        // conditionals. The basic idea here is to:\n-        //\n-        // 1. First, filter all our rules to the relevant ones. This means that\n-        //    the command specified corresponds to one of our `Kind` variants,\n-        //    and we filter all rules based on that.\n-        //\n-        // 2. Next, we determine which rules we're actually executing. If a\n-        //    number of path filters were specified on the command line we look\n-        //    for those, otherwise we look for anything tagged `default`.\n-        //    Here we also compute the priority of each rule based on how early\n-        //    in the command line the matching path filter showed up.\n-        //\n-        // 3. Finally, we generate some steps with host and target information.\n-        //\n-        // The last step is by far the most complicated and subtle. The basic\n-        // thinking here is that we want to take the cartesian product of\n-        // specified hosts and targets and build rules with that. The list of\n-        // hosts and targets, if not specified, come from the how this build was\n-        // configured. If the rule we're looking at is a host-only rule the we\n-        // ignore the list of targets and instead consider the list of hosts\n-        // also the list of targets.\n-        //\n-        // Once the host and target lists are generated we take the cartesian\n-        // product of the two and then create a step based off them. Note that\n-        // the stage each step is associated was specified with the `--step`\n-        // flag on the command line.\n-        let (kind, paths) = match self.build.flags.cmd {\n-            Subcommand::Build { ref paths } => (Kind::Build, &paths[..]),\n-            Subcommand::Doc { ref paths } => (Kind::Doc, &paths[..]),\n-            Subcommand::Test { ref paths, .. } => (Kind::Test, &paths[..]),\n-            Subcommand::Bench { ref paths, .. } => (Kind::Bench, &paths[..]),\n-            Subcommand::Dist { ref paths } => (Kind::Dist, &paths[..]),\n-            Subcommand::Install { ref paths } => (Kind::Install, &paths[..]),\n-            Subcommand::Clean => panic!(),\n-        };\n-\n-        let mut rules: Vec<_> = self.rules.values().filter_map(|rule| {\n-            if rule.kind != kind {\n-                return None;\n-            }\n-\n-            if paths.len() == 0 && rule.default {\n-                Some((rule, 0))\n-            } else {\n-                paths.iter()\n-                     .position(|path| path.ends_with(rule.path))\n-                     .map(|priority| (rule, priority))\n-            }\n-        }).collect();\n-\n-        if rules.is_empty() &&\n-           !paths.get(0).unwrap_or(&PathBuf::new())\n-                 .ends_with(\"nonexistent/path/to/trigger/cargo/metadata\") {\n-            println!(\"\\nNothing to run...\\n\");\n-            process::exit(1);\n-        }\n-\n-        rules.sort_by_key(|&(_, priority)| priority);\n-\n-        rules.into_iter().flat_map(|(rule, _)| {\n-            let hosts = if rule.only_host_build || rule.only_build {\n-                self.build.build_slice()\n-            } else {\n-                &self.build.hosts\n-            };\n-            // Determine the actual targets participating in this rule.\n-            // NOTE: We should keep the full projection from build triple to\n-            // the hosts for the dist steps, now that the hosts array above is\n-            // truncated to avoid duplication of work in that case. Therefore\n-            // the original non-shadowed hosts array is used below.\n-            let arr = if rule.host {\n-                // If --target was specified but --host wasn't specified,\n-                // don't run any host-only tests.\n-                if self.build.flags.host.len() > 0 {\n-                    &self.build.hosts\n-                } else if self.build.flags.target.len() > 0 {\n-                    &[]\n-                } else if rule.only_build {\n-                    self.build.build_slice()\n-                } else {\n-                    &self.build.hosts\n-                }\n-            } else {\n-                &self.build.targets\n-            };\n-\n-            hosts.iter().flat_map(move |host| {\n-                arr.iter().map(move |target| {\n-                    self.sbuild.name(rule.name).target(target).host(host)\n-                })\n-            })\n-        }).collect()\n-    }\n-\n-    /// Execute all top-level targets indicated by `steps`.\n-    ///\n-    /// This will take the list returned by `plan` and then execute each step\n-    /// along with all required dependencies as it goes up the chain.\n-    fn run(&self, steps: &[Step<'a>]) {\n-        self.build.verbose(\"bootstrap top targets:\");\n-        for step in steps.iter() {\n-            self.build.verbose(&format!(\"\\t{:?}\", step));\n-        }\n-\n-        // Using `steps` as the top-level targets, make a topological ordering\n-        // of what we need to do.\n-        let order = self.expand(steps);\n-\n-        // Print out what we're doing for debugging\n-        self.build.verbose(\"bootstrap build plan:\");\n-        for step in order.iter() {\n-            self.build.verbose(&format!(\"\\t{:?}\", step));\n-        }\n-\n-        // And finally, iterate over everything and execute it.\n-        for step in order.iter() {\n-            if self.build.flags.keep_stage.map_or(false, |s| step.stage <= s) {\n-                self.build.verbose(&format!(\"keeping step {:?}\", step));\n-                continue;\n-            }\n-            self.build.verbose(&format!(\"executing step {:?}\", step));\n-            (self.rules[step.name].run)(step);\n-        }\n-\n-        // Check for postponed failures from `test --no-fail-fast`.\n-        let failures = self.build.delayed_failures.get();\n-        if failures > 0 {\n-            println!(\"\\n{} command(s) did not execute successfully.\\n\", failures);\n-            process::exit(1);\n-        }\n-    }\n-\n-    /// From the top level targets `steps` generate a topological ordering of\n-    /// all steps needed to run those steps.\n-    fn expand(&self, steps: &[Step<'a>]) -> Vec<Step<'a>> {\n-        // First up build a graph of steps and their dependencies. The `nodes`\n-        // map is a map from step to a unique number. The `edges` map is a\n-        // map from these unique numbers to a list of other numbers,\n-        // representing dependencies.\n-        let mut nodes = HashMap::new();\n-        nodes.insert(Step::noop(), 0);\n-        let mut edges = HashMap::new();\n-        edges.insert(0, HashSet::new());\n-        for step in steps {\n-            self.build_graph(step.clone(), &mut nodes, &mut edges);\n-        }\n-\n-        // Now that we've built up the actual dependency graph, draw more\n-        // dependency edges to satisfy the `after` dependencies field for each\n-        // rule.\n-        self.satisfy_after_deps(&nodes, &mut edges);\n-\n-        // And finally, perform a topological sort to return a list of steps to\n-        // execute.\n-        let mut order = Vec::new();\n-        let mut visited = HashSet::new();\n-        visited.insert(0);\n-        let idx_to_node = nodes.iter().map(|p| (*p.1, p.0)).collect::<HashMap<_, _>>();\n-        for idx in 0..nodes.len() {\n-            self.topo_sort(idx, &idx_to_node, &edges, &mut visited, &mut order);\n-        }\n-        order\n-    }\n-\n-    /// Builds the dependency graph rooted at `step`.\n-    ///\n-    /// The `nodes` and `edges` maps are filled out according to the rule\n-    /// described by `step.name`.\n-    fn build_graph(&self,\n-                   step: Step<'a>,\n-                   nodes: &mut HashMap<Step<'a>, usize>,\n-                   edges: &mut HashMap<usize, HashSet<usize>>) -> usize {\n-        use std::collections::hash_map::Entry;\n-\n-        let idx = nodes.len();\n-        match nodes.entry(step.clone()) {\n-            Entry::Vacant(e) => { e.insert(idx); }\n-            Entry::Occupied(e) => return *e.get(),\n-        }\n-\n-        let mut deps = Vec::new();\n-        for dep in self.rules[step.name].deps.iter() {\n-            let dep = dep(&step);\n-            if dep.name.starts_with(\"default:\") {\n-                let kind = match &dep.name[8..] {\n-                    \"doc\" => Kind::Doc,\n-                    \"dist\" => Kind::Dist,\n-                    kind => panic!(\"unknown kind: `{}`\", kind),\n-                };\n-                let host = self.build.config.host.iter().any(|h| h == dep.target);\n-                let rules = self.rules.values().filter(|r| r.default);\n-                for rule in rules.filter(|r| r.kind == kind && (!r.host || host)) {\n-                    deps.push(self.build_graph(dep.name(rule.name), nodes, edges));\n-                }\n-            } else {\n-                deps.push(self.build_graph(dep, nodes, edges));\n-            }\n-        }\n-\n-        edges.entry(idx).or_insert(HashSet::new()).extend(deps);\n-        idx\n-    }\n-\n-    /// Given a dependency graph with a finished list of `nodes`, fill out more\n-    /// dependency `edges`.\n-    ///\n-    /// This is the step which satisfies all `after` listed dependencies in\n-    /// `Rule` above.\n-    fn satisfy_after_deps(&self,\n-                          nodes: &HashMap<Step<'a>, usize>,\n-                          edges: &mut HashMap<usize, HashSet<usize>>) {\n-        // Reverse map from the name of a step to the node indices that it\n-        // appears at.\n-        let mut name_to_idx = HashMap::new();\n-        for (step, &idx) in nodes {\n-            name_to_idx.entry(step.name).or_insert(Vec::new()).push(idx);\n-        }\n-\n-        for (step, idx) in nodes {\n-            if *step == Step::noop() {\n-                continue\n-            }\n-            for after in self.rules[step.name].after.iter() {\n-                // This is the critical piece of an `after` dependency. If the\n-                // dependency isn't actually in our graph then no edge is drawn,\n-                // only if it's already present do we draw the edges.\n-                if let Some(idxs) = name_to_idx.get(after) {\n-                    edges.get_mut(idx).unwrap()\n-                         .extend(idxs.iter().cloned());\n-                }\n-            }\n-        }\n-    }\n-\n-    fn topo_sort(&self,\n-                 cur: usize,\n-                 nodes: &HashMap<usize, &Step<'a>>,\n-                 edges: &HashMap<usize, HashSet<usize>>,\n-                 visited: &mut HashSet<usize>,\n-                 order: &mut Vec<Step<'a>>) {\n-        if !visited.insert(cur) {\n-            return\n-        }\n-        for dep in edges[&cur].iter() {\n-            self.topo_sort(*dep, nodes, edges, visited, order);\n-        }\n-        order.push(nodes[&cur].clone());\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use std::env;\n-\n-    use Build;\n-    use config::Config;\n-    use flags::Flags;\n-\n-    fn build(args: &[&str],\n-             extra_host: &[&str],\n-             extra_target: &[&str]) -> Build {\n-        build_(args, extra_host, extra_target, true)\n-    }\n-\n-    fn build_(args: &[&str],\n-              extra_host: &[&str],\n-              extra_target: &[&str],\n-              docs: bool) -> Build {\n-        let mut args = args.iter().map(|s| s.to_string()).collect::<Vec<_>>();\n-        args.push(\"--build\".to_string());\n-        args.push(\"A\".to_string());\n-        let flags = Flags::parse(&args);\n-\n-        let mut config = Config::default();\n-        config.docs = docs;\n-        config.build = \"A\".to_string();\n-        config.host = vec![config.build.clone()];\n-        config.host.extend(extra_host.iter().map(|s| s.to_string()));\n-        config.target = config.host.clone();\n-        config.target.extend(extra_target.iter().map(|s| s.to_string()));\n-\n-        let mut build = Build::new(flags, config);\n-        let cwd = env::current_dir().unwrap();\n-        build.crates.insert(\"std\".to_string(), ::Crate {\n-            name: \"std\".to_string(),\n-            deps: Vec::new(),\n-            path: cwd.join(\"src/std\"),\n-            doc_step: \"doc-crate-std\".to_string(),\n-            build_step: \"build-crate-std\".to_string(),\n-            test_step: \"test-crate-std\".to_string(),\n-            bench_step: \"bench-crate-std\".to_string(),\n-            version: String::new(),\n-        });\n-        build.crates.insert(\"test\".to_string(), ::Crate {\n-            name: \"test\".to_string(),\n-            deps: Vec::new(),\n-            path: cwd.join(\"src/test\"),\n-            doc_step: \"doc-crate-test\".to_string(),\n-            build_step: \"build-crate-test\".to_string(),\n-            test_step: \"test-crate-test\".to_string(),\n-            bench_step: \"bench-crate-test\".to_string(),\n-            version: String::new(),\n-        });\n-        build.crates.insert(\"rustc-main\".to_string(), ::Crate {\n-            name: \"rustc-main\".to_string(),\n-            deps: Vec::new(),\n-            version: String::new(),\n-            path: cwd.join(\"src/rustc-main\"),\n-            doc_step: \"doc-crate-rustc-main\".to_string(),\n-            build_step: \"build-crate-rustc-main\".to_string(),\n-            test_step: \"test-crate-rustc-main\".to_string(),\n-            bench_step: \"bench-crate-rustc-main\".to_string(),\n-        });\n-        return build\n-    }\n-\n-    #[test]\n-    fn dist_baseline() {\n-        let build = build(&[\"dist\"], &[], &[]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-        assert!(plan.iter().all(|s| s.host == \"A\" ));\n-        assert!(plan.iter().all(|s| s.target == \"A\" ));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        assert!(plan.contains(&step.name(\"dist-docs\")));\n-        assert!(plan.contains(&step.name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.name(\"dist-std\")));\n-        assert!(plan.contains(&step.name(\"dist-src\")));\n-    }\n-\n-    #[test]\n-    fn dist_with_targets() {\n-        let build = build(&[\"dist\"], &[], &[\"B\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-        assert!(plan.iter().all(|s| s.host == \"A\" ));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        assert!(plan.contains(&step.name(\"dist-docs\")));\n-        assert!(plan.contains(&step.name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.name(\"dist-std\")));\n-        assert!(plan.contains(&step.name(\"dist-src\")));\n-\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-docs\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-mingw\")));\n-        assert!(!plan.contains(&step.target(\"B\").name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-std\")));\n-        assert!(!plan.contains(&step.target(\"B\").name(\"dist-src\")));\n-    }\n-\n-    #[test]\n-    fn dist_with_hosts() {\n-        let build = build(&[\"dist\"], &[\"B\"], &[]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        assert!(!plan.iter().any(|s| s.host == \"B\"));\n-\n-        assert!(plan.contains(&step.name(\"dist-docs\")));\n-        assert!(plan.contains(&step.name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.name(\"dist-std\")));\n-        assert!(plan.contains(&step.name(\"dist-src\")));\n-\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-docs\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-std\")));\n-        assert!(!plan.contains(&step.target(\"B\").name(\"dist-src\")));\n-    }\n-\n-    #[test]\n-    fn dist_with_targets_and_hosts() {\n-        let build = build(&[\"dist\"], &[\"B\"], &[\"C\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        assert!(!plan.iter().any(|s| s.host == \"B\"));\n-        assert!(!plan.iter().any(|s| s.host == \"C\"));\n-\n-        assert!(plan.contains(&step.name(\"dist-docs\")));\n-        assert!(plan.contains(&step.name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.name(\"dist-std\")));\n-        assert!(plan.contains(&step.name(\"dist-src\")));\n-\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-docs\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-std\")));\n-        assert!(!plan.contains(&step.target(\"B\").name(\"dist-src\")));\n-\n-        assert!(plan.contains(&step.target(\"C\").name(\"dist-docs\")));\n-        assert!(plan.contains(&step.target(\"C\").name(\"dist-mingw\")));\n-        assert!(!plan.contains(&step.target(\"C\").name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.target(\"C\").name(\"dist-std\")));\n-        assert!(!plan.contains(&step.target(\"C\").name(\"dist-src\")));\n-    }\n-\n-    #[test]\n-    fn dist_target_with_target_flag() {\n-        let build = build(&[\"dist\", \"--target=C\"], &[\"B\"], &[\"C\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        assert!(!plan.iter().any(|s| s.target == \"A\"));\n-        assert!(!plan.iter().any(|s| s.target == \"B\"));\n-        assert!(!plan.iter().any(|s| s.host == \"B\"));\n-        assert!(!plan.iter().any(|s| s.host == \"C\"));\n-\n-        assert!(plan.contains(&step.target(\"C\").name(\"dist-docs\")));\n-        assert!(plan.contains(&step.target(\"C\").name(\"dist-mingw\")));\n-        assert!(!plan.contains(&step.target(\"C\").name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.target(\"C\").name(\"dist-std\")));\n-        assert!(!plan.contains(&step.target(\"C\").name(\"dist-src\")));\n-    }\n-\n-    #[test]\n-    fn dist_host_with_target_flag() {\n-        let build = build(&[\"dist\", \"--host=B\", \"--target=B\"], &[\"B\"], &[\"C\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        assert!(!plan.iter().any(|s| s.target == \"A\"));\n-        assert!(!plan.iter().any(|s| s.target == \"C\"));\n-        assert!(!plan.iter().any(|s| s.host == \"B\"));\n-        assert!(!plan.iter().any(|s| s.host == \"C\"));\n-\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-docs\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-mingw\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-rustc\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-std\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"dist-src\")));\n-\n-        let all = rules.expand(&plan);\n-        println!(\"all rules: {:#?}\", all);\n-        assert!(!all.contains(&step.name(\"rustc\")));\n-        assert!(!all.contains(&step.name(\"build-crate-test\").stage(1)));\n-\n-        // all stage0 compiles should be for the build target, A\n-        for step in all.iter().filter(|s| s.stage == 0) {\n-            if !step.name.contains(\"build-crate\") {\n-                continue\n-            }\n-            println!(\"step: {:?}\", step);\n-            assert!(step.host != \"B\");\n-            assert!(step.target != \"B\");\n-            assert!(step.host != \"C\");\n-            assert!(step.target != \"C\");\n-        }\n-    }\n-\n-    #[test]\n-    fn build_default() {\n-        let build = build(&[\"build\"], &[\"B\"], &[\"C\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-\n-        let step = super::Step {\n-            name: \"\",\n-            stage: 2,\n-            host: &build.build,\n-            target: &build.build,\n-        };\n-\n-        // rustc built for all for of (A, B) x (A, B)\n-        assert!(plan.contains(&step.name(\"librustc\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"librustc\")));\n-        assert!(plan.contains(&step.host(\"B\").target(\"A\").name(\"librustc\")));\n-        assert!(plan.contains(&step.host(\"B\").target(\"B\").name(\"librustc\")));\n-\n-        // rustc never built for C\n-        assert!(!plan.iter().any(|s| {\n-            s.name.contains(\"rustc\") && (s.host == \"C\" || s.target == \"C\")\n-        }));\n-\n-        // test built for everything\n-        assert!(plan.contains(&step.name(\"libtest\")));\n-        assert!(plan.contains(&step.target(\"B\").name(\"libtest\")));\n-        assert!(plan.contains(&step.host(\"B\").target(\"A\").name(\"libtest\")));\n-        assert!(plan.contains(&step.host(\"B\").target(\"B\").name(\"libtest\")));\n-        assert!(plan.contains(&step.host(\"A\").target(\"C\").name(\"libtest\")));\n-        assert!(plan.contains(&step.host(\"B\").target(\"C\").name(\"libtest\")));\n-\n-        let all = rules.expand(&plan);\n-        println!(\"all rules: {:#?}\", all);\n-        assert!(all.contains(&step.name(\"rustc\")));\n-        assert!(all.contains(&step.name(\"libstd\")));\n-    }\n-\n-    #[test]\n-    fn build_filtered() {\n-        let build = build(&[\"build\", \"--target=C\"], &[\"B\"], &[\"C\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-\n-        assert!(!plan.iter().any(|s| s.name.contains(\"rustc\")));\n-        assert!(plan.iter().all(|s| {\n-            !s.name.contains(\"test\") || s.target == \"C\"\n-        }));\n-    }\n-\n-    #[test]\n-    fn test_default() {\n-        let build = build(&[\"test\"], &[], &[]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-        assert!(plan.iter().all(|s| s.host == \"A\"));\n-        assert!(plan.iter().all(|s| s.target == \"A\"));\n-\n-        assert!(plan.iter().any(|s| s.name.contains(\"-ui\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"cfail\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"cfail-full\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"codegen-units\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"debuginfo\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"docs\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"error-index\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"incremental\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"linkchecker\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"mir-opt\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"pfail\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rfail\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rfail-full\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rmake\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rpass\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rpass-full\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rustc-all\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rustdoc\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"std-all\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"test-all\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"tidy\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"valgrind\")));\n-    }\n-\n-    #[test]\n-    fn test_with_a_target() {\n-        let build = build(&[\"test\", \"--target=C\"], &[], &[\"C\"]);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(plan.iter().all(|s| s.stage == 2));\n-        assert!(plan.iter().all(|s| s.host == \"A\"));\n-        assert!(plan.iter().all(|s| s.target == \"C\"));\n-\n-        assert!(plan.iter().any(|s| s.name.contains(\"-ui\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"ui-full\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"cfail\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"cfail-full\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"codegen-units\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"debuginfo\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"docs\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"error-index\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"incremental\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"linkchecker\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"mir-opt\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"pfail\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rfail\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"rfail-full\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"rmake\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"rpass\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"rpass-full\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"rustc-all\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"rustdoc\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"std-all\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"test-all\")));\n-        assert!(!plan.iter().any(|s| s.name.contains(\"tidy\")));\n-        assert!(plan.iter().any(|s| s.name.contains(\"valgrind\")));\n-    }\n-\n-    #[test]\n-    fn test_disable_docs() {\n-        let build = build_(&[\"test\"], &[], &[], false);\n-        let rules = super::build_rules(&build);\n-        let plan = rules.plan();\n-        println!(\"rules: {:#?}\", plan);\n-        assert!(!plan.iter().any(|s| {\n-            s.name.contains(\"doc-\") || s.name.contains(\"default:doc\")\n-        }));\n-        // none of the dependencies should be a doc rule either\n-        assert!(!plan.iter().any(|s| {\n-            rules.rules[s.name].deps.iter().any(|dep| {\n-                let dep = dep(&rules.sbuild.name(s.name));\n-                dep.name.contains(\"doc-\") || dep.name.contains(\"default:doc\")\n-            })\n-        }));\n-    }\n-}"}, {"sha": "b31d891051cf751ad5a7de02ef911972dc743838", "filename": "src/bootstrap/tool.rs", "status": "added", "additions": 353, "deletions": 0, "changes": 353, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Ftool.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Fbootstrap%2Ftool.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Ftool.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -0,0 +1,353 @@\n+// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use std::env;\n+use std::path::PathBuf;\n+use std::process::Command;\n+\n+use Mode;\n+use Compiler;\n+use builder::{Step, RunConfig, ShouldRun, Builder};\n+use util::{exe, add_lib_path};\n+use compile::{self, libtest_stamp, libstd_stamp, librustc_stamp};\n+use native;\n+use channel::GitInfo;\n+use cache::Interned;\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct CleanTools {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+    pub mode: Mode,\n+}\n+\n+impl Step for CleanTools {\n+    type Output = ();\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n+    }\n+\n+    /// Build a tool in `src/tools`\n+    ///\n+    /// This will build the specified tool with the specified `host` compiler in\n+    /// `stage` into the normal cargo output directory.\n+    fn run(self, builder: &Builder) {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        let mode = self.mode;\n+\n+        let compiler = builder.compiler(stage, build.build);\n+\n+        let stamp = match mode {\n+            Mode::Libstd => libstd_stamp(build, compiler, target),\n+            Mode::Libtest => libtest_stamp(build, compiler, target),\n+            Mode::Librustc => librustc_stamp(build, compiler, target),\n+            _ => panic!(),\n+        };\n+        let out_dir = build.cargo_out(compiler, Mode::Tool, target);\n+        build.clear_if_dirty(&out_dir, &stamp);\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct ToolBuild {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+    pub tool: &'static str,\n+    pub mode: Mode,\n+}\n+\n+impl Step for ToolBuild {\n+    type Output = PathBuf;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.never()\n+    }\n+\n+    /// Build a tool in `src/tools`\n+    ///\n+    /// This will build the specified tool with the specified `host` compiler in\n+    /// `stage` into the normal cargo output directory.\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        let build = builder.build;\n+        let stage = self.stage;\n+        let target = self.target;\n+        let tool = self.tool;\n+\n+        let compiler = builder.compiler(stage, build.build);\n+        builder.ensure(CleanTools { stage, target, mode: self.mode });\n+        match self.mode {\n+            Mode::Libstd => builder.ensure(compile::Std { compiler, target }),\n+            Mode::Libtest => builder.ensure(compile::Test { compiler, target }),\n+            Mode::Librustc => builder.ensure(compile::Rustc { compiler, target }),\n+            Mode::Tool => panic!(\"unexpected Mode::Tool for tool build\")\n+        }\n+\n+        let _folder = build.fold_output(|| format!(\"stage{}-{}\", stage, tool));\n+        println!(\"Building stage{} tool {} ({})\", stage, tool, target);\n+\n+        let mut cargo = builder.cargo(compiler, Mode::Tool, target, \"build\");\n+        let dir = build.src.join(\"src/tools\").join(tool);\n+        cargo.arg(\"--manifest-path\").arg(dir.join(\"Cargo.toml\"));\n+\n+        // We don't want to build tools dynamically as they'll be running across\n+        // stages and such and it's just easier if they're not dynamically linked.\n+        cargo.env(\"RUSTC_NO_PREFER_DYNAMIC\", \"1\");\n+\n+        if let Some(dir) = build.openssl_install_dir(target) {\n+            cargo.env(\"OPENSSL_STATIC\", \"1\");\n+            cargo.env(\"OPENSSL_DIR\", dir);\n+            cargo.env(\"LIBZ_SYS_STATIC\", \"1\");\n+        }\n+\n+        cargo.env(\"CFG_RELEASE_CHANNEL\", &build.config.channel);\n+\n+        let info = GitInfo::new(&dir);\n+        if let Some(sha) = info.sha() {\n+            cargo.env(\"CFG_COMMIT_HASH\", sha);\n+        }\n+        if let Some(sha_short) = info.sha_short() {\n+            cargo.env(\"CFG_SHORT_COMMIT_HASH\", sha_short);\n+        }\n+        if let Some(date) = info.commit_date() {\n+            cargo.env(\"CFG_COMMIT_DATE\", date);\n+        }\n+\n+        build.run(&mut cargo);\n+        build.cargo_out(compiler, Mode::Tool, target).join(exe(tool, &compiler.host))\n+    }\n+}\n+\n+macro_rules! tool {\n+    ($($name:ident, $path:expr, $tool_name:expr, $mode:expr;)+) => {\n+        #[derive(Copy, Clone)]\n+        pub enum Tool {\n+            $(\n+                $name,\n+            )+\n+        }\n+\n+        impl<'a> Builder<'a> {\n+            pub fn tool_exe(&self, tool: Tool) -> PathBuf {\n+                match tool {\n+                    $(Tool::$name =>\n+                        self.ensure($name {\n+                            stage: 0,\n+                            target: self.build.build,\n+                        }),\n+                    )+\n+                }\n+            }\n+        }\n+\n+        $(\n+            #[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+        pub struct $name {\n+            pub stage: u32,\n+            pub target: Interned<String>,\n+        }\n+\n+        impl Step for $name {\n+            type Output = PathBuf;\n+\n+            fn should_run(run: ShouldRun) -> ShouldRun {\n+                run.path($path)\n+            }\n+\n+            fn make_run(run: RunConfig) {\n+                run.builder.ensure($name {\n+                    stage: run.builder.top_stage,\n+                    target: run.target,\n+                });\n+            }\n+\n+            fn run(self, builder: &Builder) -> PathBuf {\n+                builder.ensure(ToolBuild {\n+                    stage: self.stage,\n+                    target: self.target,\n+                    tool: $tool_name,\n+                    mode: $mode,\n+                })\n+            }\n+        }\n+        )+\n+    }\n+}\n+\n+tool!(\n+    Rustbook, \"src/tools/rustbook\", \"rustbook\", Mode::Librustc;\n+    ErrorIndex, \"src/tools/error_index_generator\", \"error_index_generator\", Mode::Librustc;\n+    UnstableBookGen, \"src/tools/unstable-book-gen\", \"unstable-book-gen\", Mode::Libstd;\n+    Tidy, \"src/tools/tidy\", \"tidy\", Mode::Libstd;\n+    Linkchecker, \"src/tools/linkchecker\", \"linkchecker\", Mode::Libstd;\n+    CargoTest, \"src/tools/cargotest\", \"cargotest\", Mode::Libstd;\n+    Compiletest, \"src/tools/compiletest\", \"compiletest\", Mode::Libtest;\n+    BuildManifest, \"src/tools/build-manifest\", \"build-manifest\", Mode::Librustc;\n+    RemoteTestClient, \"src/tools/remote-test-client\", \"remote-test-client\", Mode::Libstd;\n+    RustInstaller, \"src/tools/rust-installer\", \"rust-installer\", Mode::Libstd;\n+);\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct RemoteTestServer {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for RemoteTestServer {\n+    type Output = PathBuf;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        run.path(\"src/tools/remote-test-server\")\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(RemoteTestServer {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        builder.ensure(ToolBuild {\n+            stage: self.stage,\n+            target: self.target,\n+            tool: \"remote-test-server\",\n+            mode: Mode::Libstd,\n+        })\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Cargo {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Cargo {\n+    type Output = PathBuf;\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/tools/cargo\").default_condition(builder.build.config.extended)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Cargo {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        builder.ensure(native::Openssl {\n+            target: self.target,\n+        });\n+        // Cargo depends on procedural macros, which requires a full host\n+        // compiler to be available, so we need to depend on that.\n+        builder.ensure(compile::Rustc {\n+            compiler: builder.compiler(self.stage, builder.build.build),\n+            target: builder.build.build,\n+        });\n+        builder.ensure(ToolBuild {\n+            stage: self.stage,\n+            target: self.target,\n+            tool: \"cargo\",\n+            mode: Mode::Libstd,\n+        })\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq)]\n+pub struct Rls {\n+    pub stage: u32,\n+    pub target: Interned<String>,\n+}\n+\n+impl Step for Rls {\n+    type Output = PathBuf;\n+    const DEFAULT: bool = true;\n+    const ONLY_HOSTS: bool = true;\n+\n+    fn should_run(run: ShouldRun) -> ShouldRun {\n+        let builder = run.builder;\n+        run.path(\"src/tools/rls\").default_condition(builder.build.config.extended)\n+    }\n+\n+    fn make_run(run: RunConfig) {\n+        run.builder.ensure(Rls {\n+            stage: run.builder.top_stage,\n+            target: run.target,\n+        });\n+    }\n+\n+    fn run(self, builder: &Builder) -> PathBuf {\n+        builder.ensure(native::Openssl {\n+            target: self.target,\n+        });\n+        // RLS depends on procedural macros, which requires a full host\n+        // compiler to be available, so we need to depend on that.\n+        builder.ensure(compile::Rustc {\n+            compiler: builder.compiler(self.stage, builder.build.build),\n+            target: builder.build.build,\n+        });\n+        builder.ensure(ToolBuild {\n+            stage: self.stage,\n+            target: self.target,\n+            tool: \"rls\",\n+            mode: Mode::Librustc,\n+        })\n+    }\n+}\n+\n+impl<'a> Builder<'a> {\n+    /// Get a `Command` which is ready to run `tool` in `stage` built for\n+    /// `host`.\n+    pub fn tool_cmd(&self, tool: Tool) -> Command {\n+        let mut cmd = Command::new(self.tool_exe(tool));\n+        let compiler = self.compiler(0, self.build.build);\n+        self.prepare_tool_cmd(compiler, &mut cmd);\n+        cmd\n+    }\n+\n+    /// Prepares the `cmd` provided to be able to run the `compiler` provided.\n+    ///\n+    /// Notably this munges the dynamic library lookup path to point to the\n+    /// right location to run `compiler`.\n+    fn prepare_tool_cmd(&self, compiler: Compiler, cmd: &mut Command) {\n+        let host = &compiler.host;\n+        let mut paths: Vec<PathBuf> = vec![\n+            PathBuf::from(&self.sysroot_libdir(compiler, compiler.host)),\n+            self.cargo_out(compiler, Mode::Tool, *host).join(\"deps\"),\n+        ];\n+\n+        // On MSVC a tool may invoke a C compiler (e.g. compiletest in run-make\n+        // mode) and that C compiler may need some extra PATH modification. Do\n+        // so here.\n+        if compiler.host.contains(\"msvc\") {\n+            let curpaths = env::var_os(\"PATH\").unwrap_or_default();\n+            let curpaths = env::split_paths(&curpaths).collect::<Vec<_>>();\n+            for &(ref k, ref v) in self.cc[&compiler.host].0.env() {\n+                if k != \"PATH\" {\n+                    continue\n+                }\n+                for path in env::split_paths(v) {\n+                    if !curpaths.contains(&path) {\n+                        paths.push(path);\n+                    }\n+                }\n+            }\n+        }\n+        add_lib_path(paths, cmd);\n+    }\n+}"}, {"sha": "844b7aad72fde3732763bfeafd67588e4e9e64c7", "filename": "src/tools/build-manifest/Cargo.toml", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Ftools%2Fbuild-manifest%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Ftools%2Fbuild-manifest%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fbuild-manifest%2FCargo.toml?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -4,5 +4,6 @@ version = \"0.1.0\"\n authors = [\"Alex Crichton <alex@alexcrichton.com>\"]\n \n [dependencies]\n-toml = \"0.1\"\n-rustc-serialize = \"0.3\"\n+toml = \"0.4\"\n+serde = \"1.0\"\n+serde_derive = \"1.0\""}, {"sha": "b8efb88acfbdce3de9fc1ac64269ca5c56dcc87c", "filename": "src/tools/build-manifest/src/main.rs", "status": "modified", "additions": 13, "deletions": 21, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Ftools%2Fbuild-manifest%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d22af87d812d9a132f0a030753a5cdf53c87ee8/src%2Ftools%2Fbuild-manifest%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fbuild-manifest%2Fsrc%2Fmain.rs?ref=8d22af87d812d9a132f0a030753a5cdf53c87ee8", "patch": "@@ -9,7 +9,9 @@\n // except according to those terms.\n \n extern crate toml;\n-extern crate rustc_serialize;\n+#[macro_use]\n+extern crate serde_derive;\n+extern crate serde;\n \n use std::collections::BTreeMap;\n use std::env;\n@@ -99,19 +101,21 @@ static MINGW: &'static [&'static str] = &[\n     \"x86_64-pc-windows-gnu\",\n ];\n \n+#[derive(Serialize)]\n+#[serde(rename_all = \"kebab-case\")]\n struct Manifest {\n     manifest_version: String,\n     date: String,\n     pkg: BTreeMap<String, Package>,\n }\n \n-#[derive(RustcEncodable)]\n+#[derive(Serialize)]\n struct Package {\n     version: String,\n     target: BTreeMap<String, Target>,\n }\n \n-#[derive(RustcEncodable)]\n+#[derive(Serialize)]\n struct Target {\n     available: bool,\n     url: Option<String>,\n@@ -136,7 +140,7 @@ impl Target {\n     }\n }\n \n-#[derive(RustcEncodable)]\n+#[derive(Serialize)]\n struct Component {\n     pkg: String,\n     target: String,\n@@ -199,28 +203,16 @@ impl Builder {\n         self.rls_version = self.version(\"rls\", \"x86_64-unknown-linux-gnu\");\n \n         self.digest_and_sign();\n-        let Manifest { manifest_version, date, pkg } = self.build_manifest();\n-\n-        // Unfortunately we can't use derive(RustcEncodable) here because the\n-        // version field is called `manifest-version`, not `manifest_version`.\n-        // In lieu of that just create the table directly here with a `BTreeMap`\n-        // and wrap it up in a `Value::Table`.\n-        let mut manifest = BTreeMap::new();\n-        manifest.insert(\"manifest-version\".to_string(),\n-                        toml::Value::String(manifest_version));\n-        manifest.insert(\"date\".to_string(), toml::Value::String(date.clone()));\n-        manifest.insert(\"pkg\".to_string(), toml::encode(&pkg));\n-        let manifest = toml::Value::Table(manifest).to_string();\n-\n+        let manifest = self.build_manifest();\n         let filename = format!(\"channel-rust-{}.toml\", self.rust_release);\n-        self.write_manifest(&manifest, &filename);\n+        self.write_manifest(&toml::to_string(&manifest).unwrap(), &filename);\n \n         let filename = format!(\"channel-rust-{}-date.txt\", self.rust_release);\n-        self.write_date_stamp(&date, &filename);\n+        self.write_date_stamp(&manifest.date, &filename);\n \n         if self.rust_release != \"beta\" && self.rust_release != \"nightly\" {\n-            self.write_manifest(&manifest, \"channel-rust-stable.toml\");\n-            self.write_date_stamp(&date, \"channel-rust-stable-date.txt\");\n+            self.write_manifest(&toml::to_string(&manifest).unwrap(), \"channel-rust-stable.toml\");\n+            self.write_date_stamp(&manifest.date, \"channel-rust-stable-date.txt\");\n         }\n     }\n "}]}