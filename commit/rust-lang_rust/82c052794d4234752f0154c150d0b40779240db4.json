{"sha": "82c052794d4234752f0154c150d0b40779240db4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjgyYzA1Mjc5NGQ0MjM0NzUyZjAxNTRjMTUwZDBiNDA3NzkyNDBkYjQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-09-05T17:36:25Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-09-05T17:36:25Z"}, "message": "auto merge of #16628 : pczarn/rust/hashmap-opt, r=nikomatsakis\n\nThis is #15720, rebased and reopened.\r\n\r\ncc @nikomatsakis", "tree": {"sha": "e3005b0c477dd47087b10d1243822592d40522ac", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e3005b0c477dd47087b10d1243822592d40522ac"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/82c052794d4234752f0154c150d0b40779240db4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/82c052794d4234752f0154c150d0b40779240db4", "html_url": "https://github.com/rust-lang/rust/commit/82c052794d4234752f0154c150d0b40779240db4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/82c052794d4234752f0154c150d0b40779240db4/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "074d3da7b09883658cd0d52d53ebac7ee74e9e28", "url": "https://api.github.com/repos/rust-lang/rust/commits/074d3da7b09883658cd0d52d53ebac7ee74e9e28", "html_url": "https://github.com/rust-lang/rust/commit/074d3da7b09883658cd0d52d53ebac7ee74e9e28"}, {"sha": "0ad4644ae1474b5443e34d273e5553612c6d9364", "url": "https://api.github.com/repos/rust-lang/rust/commits/0ad4644ae1474b5443e34d273e5553612c6d9364", "html_url": "https://github.com/rust-lang/rust/commit/0ad4644ae1474b5443e34d273e5553612c6d9364"}], "stats": {"total": 6908, "additions": 3800, "deletions": 3108}, "files": [{"sha": "18e44cbac373f3ea0ac9683393073f15f781d376", "filename": "src/librustc/lint/context.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibrustc%2Flint%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibrustc%2Flint%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flint%2Fcontext.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -103,7 +103,9 @@ impl LintStore {\n     }\n \n     pub fn get_lint_groups<'t>(&'t self) -> Vec<(&'static str, Vec<LintId>, bool)> {\n-        self.lint_groups.iter().map(|(k, &(ref v, b))| (*k, v.clone(), b)).collect()\n+        self.lint_groups.iter().map(|(k, v)| (*k,\n+                                              v.ref0().clone(),\n+                                              *v.ref1())).collect()\n     }\n \n     pub fn register_pass(&mut self, sess: Option<&Session>,\n@@ -210,7 +212,7 @@ impl LintStore {\n             match self.by_name.find_equiv(&lint_name.as_slice()) {\n                 Some(&lint_id) => self.set_level(lint_id, (level, CommandLine)),\n                 None => {\n-                    match self.lint_groups.iter().map(|(&x, &(ref y, _))| (x, y.clone()))\n+                    match self.lint_groups.iter().map(|(&x, pair)| (x, pair.ref0().clone()))\n                                                  .collect::<HashMap<&'static str, Vec<LintId>>>()\n                                                  .find_equiv(&lint_name.as_slice()) {\n                         Some(v) => {"}, {"sha": "77e0a641e181debad96d0dc28ad9e4fb404f7d86", "filename": "src/librustdoc/html/render.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibrustdoc%2Fhtml%2Frender.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibrustdoc%2Fhtml%2Frender.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Frender.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -312,7 +312,7 @@ pub fn run(mut krate: clean::Crate, external_html: &ExternalHtml, dst: Path) ->\n     }).unwrap_or(HashMap::new());\n     let mut cache = Cache {\n         impls: HashMap::new(),\n-        external_paths: paths.iter().map(|(&k, &(ref v, _))| (k, v.clone()))\n+        external_paths: paths.iter().map(|(&k, v)| (k, v.ref0().clone()))\n                              .collect(),\n         paths: paths,\n         implementors: HashMap::new(),"}, {"sha": "1985128c4e307c4017962ce06d88f8be29ce91b0", "filename": "src/libstd/collections/hashmap.rs", "status": "removed", "additions": 0, "deletions": 3105, "changes": 3105, "blob_url": "https://github.com/rust-lang/rust/blob/074d3da7b09883658cd0d52d53ebac7ee74e9e28/src%2Flibstd%2Fcollections%2Fhashmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/074d3da7b09883658cd0d52d53ebac7ee74e9e28/src%2Flibstd%2Fcollections%2Fhashmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap.rs?ref=074d3da7b09883658cd0d52d53ebac7ee74e9e28"}, {"sha": "21bbb38f4893671686fff78f2230e2a42c09a6ba", "filename": "src/libstd/collections/hashmap/bench.rs", "status": "added", "additions": 130, "deletions": 0, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fbench.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fbench.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fbench.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -0,0 +1,130 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![cfg(test)]\n+\n+extern crate test;\n+use prelude::*;\n+\n+use self::test::Bencher;\n+use iter::{range_inclusive};\n+\n+#[bench]\n+fn new_drop(b : &mut Bencher) {\n+    use super::HashMap;\n+\n+    b.iter(|| {\n+        let m : HashMap<int, int> = HashMap::new();\n+        assert_eq!(m.len(), 0);\n+    })\n+}\n+\n+#[bench]\n+fn new_insert_drop(b : &mut Bencher) {\n+    use super::HashMap;\n+\n+    b.iter(|| {\n+        let mut m = HashMap::new();\n+        m.insert(0i, 0i);\n+        assert_eq!(m.len(), 1);\n+    })\n+}\n+\n+#[bench]\n+fn grow_by_insertion(b: &mut Bencher) {\n+    use super::HashMap;\n+\n+    let mut m = HashMap::new();\n+\n+    for i in range_inclusive(1i, 1000) {\n+        m.insert(i, i);\n+    }\n+\n+    let mut k = 1001;\n+\n+    b.iter(|| {\n+        m.insert(k, k);\n+        k += 1;\n+    });\n+}\n+\n+#[bench]\n+fn find_existing(b: &mut Bencher) {\n+    use super::HashMap;\n+\n+    let mut m = HashMap::new();\n+\n+    for i in range_inclusive(1i, 1000) {\n+        m.insert(i, i);\n+    }\n+\n+    b.iter(|| {\n+        for i in range_inclusive(1i, 1000) {\n+            m.contains_key(&i);\n+        }\n+    });\n+}\n+\n+#[bench]\n+fn find_nonexisting(b: &mut Bencher) {\n+    use super::HashMap;\n+\n+    let mut m = HashMap::new();\n+\n+    for i in range_inclusive(1i, 1000) {\n+        m.insert(i, i);\n+    }\n+\n+    b.iter(|| {\n+        for i in range_inclusive(1001i, 2000) {\n+            m.contains_key(&i);\n+        }\n+    });\n+}\n+\n+#[bench]\n+fn hashmap_as_queue(b: &mut Bencher) {\n+    use super::HashMap;\n+\n+    let mut m = HashMap::new();\n+\n+    for i in range_inclusive(1i, 1000) {\n+        m.insert(i, i);\n+    }\n+\n+    let mut k = 1i;\n+\n+    b.iter(|| {\n+        m.pop(&k);\n+        m.insert(k + 1000, k + 1000);\n+        k += 1;\n+    });\n+}\n+\n+#[bench]\n+fn find_pop_insert(b: &mut Bencher) {\n+    use super::HashMap;\n+\n+    let mut m = HashMap::new();\n+\n+    for i in range_inclusive(1i, 1000) {\n+        m.insert(i, i);\n+    }\n+\n+    let mut k = 1i;\n+\n+    b.iter(|| {\n+        m.find(&(k + 400));\n+        m.find(&(k + 2000));\n+        m.pop(&k);\n+        m.insert(k + 1000, k + 1000);\n+        k += 1;\n+    })\n+}"}, {"sha": "a50c6a59f7e04b463411fcbb00f1a073c6b16e95", "filename": "src/libstd/collections/hashmap/map.rs", "status": "added", "additions": 2017, "deletions": 0, "changes": 2017, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fmap.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -0,0 +1,2017 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+//\n+// ignore-lexer-test FIXME #15883\n+\n+use clone::Clone;\n+use cmp::{max, Eq, Equiv, PartialEq};\n+use collections::{Collection, Mutable, MutableSet, Map, MutableMap};\n+use default::Default;\n+use fmt::Show;\n+use fmt;\n+use hash::{Hash, Hasher, RandomSipHasher};\n+use iter::{Iterator, FromIterator, Extendable};\n+use iter;\n+use mem::replace;\n+use num;\n+use ops::{Deref, DerefMut};\n+use option::{Some, None, Option};\n+use result::{Ok, Err};\n+use ops::Index;\n+\n+use super::table;\n+use super::table::{\n+    Bucket,\n+    Empty,\n+    Full,\n+    FullBucket,\n+    FullBucketImm,\n+    FullBucketMut,\n+    RawTable,\n+    SafeHash\n+};\n+\n+static INITIAL_LOG2_CAP: uint = 5;\n+pub static INITIAL_CAPACITY: uint = 1 << INITIAL_LOG2_CAP; // 2^5\n+\n+/// The default behavior of HashMap implements a load factor of 90.9%.\n+/// This behavior is characterized by the following conditions:\n+///\n+/// - if size > 0.909 * capacity: grow\n+/// - if size < 0.25 * capacity: shrink (if this won't bring capacity lower\n+///   than the minimum)\n+#[deriving(Clone)]\n+struct DefaultResizePolicy {\n+    /// Doubled minimal capacity. The capacity must never drop below\n+    /// the minimum capacity. (The check happens before the capacity\n+    /// is potentially halved.)\n+    minimum_capacity2: uint\n+}\n+\n+impl DefaultResizePolicy {\n+    fn new(new_capacity: uint) -> DefaultResizePolicy {\n+        DefaultResizePolicy {\n+            minimum_capacity2: new_capacity << 1\n+        }\n+    }\n+\n+    #[inline]\n+    fn capacity_range(&self, new_size: uint) -> (uint, uint) {\n+        // Here, we are rephrasing the logic by specifying the ranges:\n+        //\n+        // - if `size * 1.1 < cap < size * 4`: don't resize\n+        // - if `cap < minimum_capacity * 2`: don't shrink\n+        // - otherwise, resize accordingly\n+        ((new_size * 11) / 10, max(new_size << 2, self.minimum_capacity2))\n+    }\n+\n+    #[inline]\n+    fn reserve(&mut self, new_capacity: uint) {\n+        self.minimum_capacity2 = new_capacity << 1;\n+    }\n+}\n+\n+// The main performance trick in this hashmap is called Robin Hood Hashing.\n+// It gains its excellent performance from one essential operation:\n+//\n+//    If an insertion collides with an existing element, and that element's\n+//    \"probe distance\" (how far away the element is from its ideal location)\n+//    is higher than how far we've already probed, swap the elements.\n+//\n+// This massively lowers variance in probe distance, and allows us to get very\n+// high load factors with good performance. The 90% load factor I use is rather\n+// conservative.\n+//\n+// > Why a load factor of approximately 90%?\n+//\n+// In general, all the distances to initial buckets will converge on the mean.\n+// At a load factor of \u03b1, the odds of finding the target bucket after k\n+// probes is approximately 1-\u03b1^k. If we set this equal to 50% (since we converge\n+// on the mean) and set k=8 (64-byte cache line / 8-byte hash), \u03b1=0.92. I round\n+// this down to make the math easier on the CPU and avoid its FPU.\n+// Since on average we start the probing in the middle of a cache line, this\n+// strategy pulls in two cache lines of hashes on every lookup. I think that's\n+// pretty good, but if you want to trade off some space, it could go down to one\n+// cache line on average with an \u03b1 of 0.84.\n+//\n+// > Wait, what? Where did you get 1-\u03b1^k from?\n+//\n+// On the first probe, your odds of a collision with an existing element is \u03b1.\n+// The odds of doing this twice in a row is approximately \u03b1^2. For three times,\n+// \u03b1^3, etc. Therefore, the odds of colliding k times is \u03b1^k. The odds of NOT\n+// colliding after k tries is 1-\u03b1^k.\n+//\n+// The paper from 1986 cited below mentions an implementation which keeps track\n+// of the distance-to-initial-bucket histogram. This approach is not suitable\n+// for modern architectures because it requires maintaining an internal data\n+// structure. This allows very good first guesses, but we are most concerned\n+// with guessing entire cache lines, not individual indexes. Furthermore, array\n+// accesses are no longer linear and in one direction, as we have now. There\n+// is also memory and cache pressure that this would entail that would be very\n+// difficult to properly see in a microbenchmark.\n+//\n+// Future Improvements (FIXME!)\n+// ============================\n+//\n+// Allow the load factor to be changed dynamically and/or at initialization.\n+//\n+// Also, would it be possible for us to reuse storage when growing the\n+// underlying table? This is exactly the use case for 'realloc', and may\n+// be worth exploring.\n+//\n+// Future Optimizations (FIXME!)\n+// =============================\n+//\n+// Another possible design choice that I made without any real reason is\n+// parameterizing the raw table over keys and values. Technically, all we need\n+// is the size and alignment of keys and values, and the code should be just as\n+// efficient (well, we might need one for power-of-two size and one for not...).\n+// This has the potential to reduce code bloat in rust executables, without\n+// really losing anything except 4 words (key size, key alignment, val size,\n+// val alignment) which can be passed in to every call of a `RawTable` function.\n+// This would definitely be an avenue worth exploring if people start complaining\n+// about the size of rust executables.\n+//\n+// Annotate exceedingly likely branches in `table::make_hash`\n+// and `search_hashed_generic` to reduce instruction cache pressure\n+// and mispredictions once it becomes possible (blocked on issue #11092).\n+//\n+// Shrinking the table could simply reallocate in place after moving buckets\n+// to the first half.\n+//\n+// The growth algorithm (fragment of the Proof of Correctness)\n+// --------------------\n+//\n+// The growth algorithm is basically a fast path of the naive reinsertion-\n+// during-resize algorithm. Other paths should never be taken.\n+//\n+// Consider growing a robin hood hashtable of capacity n. Normally, we do this\n+// by allocating a new table of capacity `2n`, and then individually reinsert\n+// each element in the old table into the new one. This guarantees that the\n+// new table is a valid robin hood hashtable with all the desired statistical\n+// properties. Remark that the order we reinsert the elements in should not\n+// matter. For simplicity and efficiency, we will consider only linear\n+// reinsertions, which consist of reinserting all elements in the old table\n+// into the new one by increasing order of index. However we will not be\n+// starting our reinsertions from index 0 in general. If we start from index\n+// i, for the purpose of reinsertion we will consider all elements with real\n+// index j < i to have virtual index n + j.\n+//\n+// Our hash generation scheme consists of generating a 64-bit hash and\n+// truncating the most significant bits. When moving to the new table, we\n+// simply introduce a new bit to the front of the hash. Therefore, if an\n+// elements has ideal index i in the old table, it can have one of two ideal\n+// locations in the new table. If the new bit is 0, then the new ideal index\n+// is i. If the new bit is 1, then the new ideal index is n + i. Intutively,\n+// we are producing two independent tables of size n, and for each element we\n+// independently choose which table to insert it into with equal probability.\n+// However the rather than wrapping around themselves on overflowing their\n+// indexes, the first table overflows into the first, and the first into the\n+// second. Visually, our new table will look something like:\n+//\n+// [yy_xxx_xxxx_xxx|xx_yyy_yyyy_yyy]\n+//\n+// Where x's are elements inserted into the first table, y's are elements\n+// inserted into the second, and _'s are empty sections. We now define a few\n+// key concepts that we will use later. Note that this is a very abstract\n+// perspective of the table. A real resized table would be at least half\n+// empty.\n+//\n+// Theorem: A linear robin hood reinsertion from the first ideal element\n+// produces identical results to a linear naive reinsertion from the same\n+// element.\n+//\n+// FIXME(Gankro, pczarn): review the proof and put it all in a separate doc.rs\n+\n+/// A hash map implementation which uses linear probing with Robin\n+/// Hood bucket stealing.\n+///\n+/// The hashes are all keyed by the task-local random number generator\n+/// on creation by default. This means that the ordering of the keys is\n+/// randomized, but makes the tables more resistant to\n+/// denial-of-service attacks (Hash DoS). This behaviour can be\n+/// overridden with one of the constructors.\n+///\n+/// It is required that the keys implement the `Eq` and `Hash` traits, although\n+/// this can frequently be achieved by using `#[deriving(Eq, Hash)]`.\n+///\n+/// Relevant papers/articles:\n+///\n+/// 1. Pedro Celis. [\"Robin Hood Hashing\"](https://cs.uwaterloo.ca/research/tr/1986/CS-86-14.pdf)\n+/// 2. Emmanuel Goossaert. [\"Robin Hood\n+///    hashing\"](http://codecapsule.com/2013/11/11/robin-hood-hashing/)\n+/// 3. Emmanuel Goossaert. [\"Robin Hood hashing: backward shift\n+///    deletion\"](http://codecapsule.com/2013/11/17/robin-hood-hashing-backward-shift-deletion/)\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::collections::HashMap;\n+///\n+/// // type inference lets us omit an explicit type signature (which\n+/// // would be `HashMap<&str, &str>` in this example).\n+/// let mut book_reviews = HashMap::new();\n+///\n+/// // review some books.\n+/// book_reviews.insert(\"Adventures of Huckleberry Finn\",    \"My favorite book.\");\n+/// book_reviews.insert(\"Grimms' Fairy Tales\",               \"Masterpiece.\");\n+/// book_reviews.insert(\"Pride and Prejudice\",               \"Very enjoyable.\");\n+/// book_reviews.insert(\"The Adventures of Sherlock Holmes\", \"Eye lyked it alot.\");\n+///\n+/// // check for a specific one.\n+/// if !book_reviews.contains_key(&(\"Les Mis\u00e9rables\")) {\n+///     println!(\"We've got {} reviews, but Les Mis\u00e9rables ain't one.\",\n+///              book_reviews.len());\n+/// }\n+///\n+/// // oops, this review has a lot of spelling mistakes, let's delete it.\n+/// book_reviews.remove(&(\"The Adventures of Sherlock Holmes\"));\n+///\n+/// // look up the values associated with some keys.\n+/// let to_find = [\"Pride and Prejudice\", \"Alice's Adventure in Wonderland\"];\n+/// for book in to_find.iter() {\n+///     match book_reviews.find(book) {\n+///         Some(review) => println!(\"{}: {}\", *book, *review),\n+///         None => println!(\"{} is unreviewed.\", *book)\n+///     }\n+/// }\n+///\n+/// // iterate over everything.\n+/// for (book, review) in book_reviews.iter() {\n+///     println!(\"{}: \\\"{}\\\"\", *book, *review);\n+/// }\n+/// ```\n+///\n+/// The easiest way to use `HashMap` with a custom type is to derive `Eq` and `Hash`.\n+/// We must also derive `PartialEq`.\n+///\n+/// ```\n+/// use std::collections::HashMap;\n+///\n+/// #[deriving(Hash, Eq, PartialEq, Show)]\n+/// struct Viking<'a> {\n+///     name: &'a str,\n+///     power: uint,\n+/// }\n+///\n+/// let mut vikings = HashMap::new();\n+///\n+/// vikings.insert(\"Norway\", Viking { name: \"Einar\", power: 9u });\n+/// vikings.insert(\"Denmark\", Viking { name: \"Olaf\", power: 4u });\n+/// vikings.insert(\"Iceland\", Viking { name: \"Harald\", power: 8u });\n+///\n+/// // Use derived implementation to print the vikings.\n+/// for (land, viking) in vikings.iter() {\n+///     println!(\"{} at {}\", viking, land);\n+/// }\n+/// ```\n+#[deriving(Clone)]\n+pub struct HashMap<K, V, H = RandomSipHasher> {\n+    // All hashes are keyed on these values, to prevent hash collision attacks.\n+    hasher: H,\n+\n+    table: RawTable<K, V>,\n+\n+    // We keep this at the end since it might as well have tail padding.\n+    resize_policy: DefaultResizePolicy,\n+}\n+\n+/// Search for a pre-hashed key.\n+fn search_hashed_generic<K, V, M: Deref<RawTable<K, V>>>(table: M,\n+                                                         hash: &SafeHash,\n+                                                         is_match: |&K| -> bool)\n+                                                         -> SearchResult<K, V, M> {\n+    let size = table.size();\n+    let mut probe = Bucket::new(table, hash);\n+    let ib = probe.index();\n+\n+    while probe.index() != ib + size {\n+        let full = match probe.peek() {\n+            Empty(b) => return TableRef(b.into_table()), // hit an empty bucket\n+            Full(b) => b\n+        };\n+\n+        if full.distance() + ib < full.index() {\n+            // We can finish the search early if we hit any bucket\n+            // with a lower distance to initial bucket than we've probed.\n+            return TableRef(full.into_table());\n+        }\n+\n+        // If the hash doesn't match, it can't be this one..\n+        if *hash == full.hash() {\n+            let matched = {\n+                let (k, _) = full.read();\n+                is_match(k)\n+            };\n+\n+            // If the key doesn't match, it can't be this one..\n+            if matched {\n+                return FoundExisting(full);\n+            }\n+        }\n+\n+        probe = full.next();\n+    }\n+\n+    TableRef(probe.into_table())\n+}\n+\n+fn search_hashed<K: Eq, V, M: Deref<RawTable<K, V>>>(table: M, hash: &SafeHash, k: &K)\n+                                                     -> SearchResult<K, V, M> {\n+    search_hashed_generic(table, hash, |k_| *k == *k_)\n+}\n+\n+fn pop_internal<K, V>(starting_bucket: FullBucketMut<K, V>) -> V {\n+    let (empty, _k, retval) = starting_bucket.take();\n+    let mut gap = match empty.gap_peek() {\n+        Some(b) => b,\n+        None => return retval\n+    };\n+\n+    while gap.full().distance() != 0 {\n+        gap = match gap.shift() {\n+            Some(b) => b,\n+            None => break\n+        };\n+    }\n+\n+    // Now we've done all our shifting. Return the value we grabbed earlier.\n+    return retval;\n+}\n+\n+/// Perform robin hood bucket stealing at the given `bucket`. You must\n+/// also pass the position of that bucket's initial bucket so we don't have\n+/// to recalculate it.\n+///\n+/// `hash`, `k`, and `v` are the elements to \"robin hood\" into the hashtable.\n+fn robin_hood<'a, K: 'a, V: 'a>(mut bucket: FullBucketMut<'a, K, V>,\n+                        mut ib: uint,\n+                        mut hash: SafeHash,\n+                        mut k: K,\n+                        mut v: V)\n+                        -> &'a mut V {\n+    let starting_index = bucket.index();\n+    let size = {\n+        let table = bucket.table(); // FIXME \"lifetime too short\".\n+        table.size()\n+    };\n+    // There can be at most `size - dib` buckets to displace, because\n+    // in the worst case, there are `size` elements and we already are\n+    // `distance` buckets away from the initial one.\n+    let idx_end = starting_index + size - bucket.distance();\n+\n+    loop {\n+        let (old_hash, old_key, old_val) = bucket.replace(hash, k, v);\n+        loop {\n+            let probe = bucket.next();\n+            assert!(probe.index() != idx_end);\n+\n+            let full_bucket = match probe.peek() {\n+                table::Empty(bucket) => {\n+                    // Found a hole!\n+                    let b = bucket.put(old_hash, old_key, old_val);\n+                    // Now that it's stolen, just read the value's pointer\n+                    // right out of the table!\n+                    let (_, v) = Bucket::at_index(b.into_table(), starting_index).peek()\n+                                                                                 .expect_full()\n+                                                                                 .into_mut_refs();\n+                    return v;\n+                },\n+                table::Full(bucket) => bucket\n+            };\n+\n+            let probe_ib = full_bucket.index() - full_bucket.distance();\n+\n+            bucket = full_bucket;\n+\n+            // Robin hood! Steal the spot.\n+            if ib < probe_ib {\n+                ib = probe_ib;\n+                hash = old_hash;\n+                k = old_key;\n+                v = old_val;\n+                break;\n+            }\n+        }\n+    }\n+}\n+\n+/// A result that works like Option<FullBucket<..>> but preserves\n+/// the reference that grants us access to the table in any case.\n+enum SearchResult<K, V, M> {\n+    // This is an entry that holds the given key:\n+    FoundExisting(FullBucket<K, V, M>),\n+\n+    // There was no such entry. The reference is given back:\n+    TableRef(M)\n+}\n+\n+impl<K, V, M> SearchResult<K, V, M> {\n+    fn into_option(self) -> Option<FullBucket<K, V, M>> {\n+        match self {\n+            FoundExisting(bucket) => Some(bucket),\n+            TableRef(_) => None\n+        }\n+    }\n+}\n+\n+/// A newtyped mutable reference to the hashmap that allows e.g. Deref to be\n+/// implemented without making changes to the visible interface of HashMap.\n+/// Used internally because it's accepted by the search functions above.\n+struct MapMutRef<'a, K: 'a, V: 'a, H: 'a> {\n+    map_ref: &'a mut HashMap<K, V, H>\n+}\n+\n+impl<'a, K, V, H> Deref<RawTable<K, V>> for MapMutRef<'a, K, V, H> {\n+    fn deref(&self) -> &RawTable<K, V> {\n+        &self.map_ref.table\n+    }\n+}\n+\n+impl<'a, K, V, H> DerefMut<RawTable<K, V>> for MapMutRef<'a, K, V, H> {\n+    fn deref_mut(&mut self) -> &mut RawTable<K, V> {\n+        &mut self.map_ref.table\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n+    fn make_hash<X: Hash<S>>(&self, x: &X) -> SafeHash {\n+        table::make_hash(&self.hasher, x)\n+    }\n+\n+    fn search_equiv<'a, Q: Hash<S> + Equiv<K>>(&'a self, q: &Q)\n+                    -> Option<FullBucketImm<'a, K, V>> {\n+        let hash = self.make_hash(q);\n+        search_hashed_generic(&self.table, &hash, |k| q.equiv(k)).into_option()\n+    }\n+\n+    fn search_equiv_mut<'a, Q: Hash<S> + Equiv<K>>(&'a mut self, q: &Q)\n+                    -> Option<FullBucketMut<'a, K, V>> {\n+        let hash = self.make_hash(q);\n+        search_hashed_generic(&mut self.table, &hash, |k| q.equiv(k)).into_option()\n+    }\n+\n+    /// Search for a key, yielding the index if it's found in the hashtable.\n+    /// If you already have the hash for the key lying around, use\n+    /// search_hashed.\n+    fn search<'a>(&'a self, k: &K) -> Option<FullBucketImm<'a, K, V>> {\n+        let hash = self.make_hash(k);\n+        search_hashed(&self.table, &hash, k).into_option()\n+    }\n+\n+    fn search_mut<'a>(&'a mut self, k: &K) -> Option<FullBucketMut<'a, K, V>> {\n+        let hash = self.make_hash(k);\n+        search_hashed(&mut self.table, &hash, k).into_option()\n+    }\n+\n+    // The caller should ensure that invariants by Robin Hood Hashing hold.\n+    fn insert_hashed_ordered(&mut self, hash: SafeHash, k: K, v: V) {\n+        let cap = self.table.capacity();\n+        let mut buckets = Bucket::new(&mut self.table, &hash);\n+        let ib = buckets.index();\n+\n+        while buckets.index() != ib + cap {\n+            // We don't need to compare hashes for value swap.\n+            // Not even DIBs for Robin Hood.\n+            buckets = match buckets.peek() {\n+                Empty(empty) => {\n+                    empty.put(hash, k, v);\n+                    return;\n+                }\n+                Full(b) => b.into_bucket()\n+            };\n+            buckets.next();\n+        }\n+        fail!(\"Internal HashMap error: Out of space.\");\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> Collection for HashMap<K, V, H> {\n+    /// Return the number of elements in the map.\n+    fn len(&self) -> uint { self.table.size() }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> Mutable for HashMap<K, V, H> {\n+    /// Clear the map, removing all key-value pairs. Keeps the allocated memory\n+    /// for reuse.\n+    fn clear(&mut self) {\n+        // Prevent reallocations from happening from now on. Makes it possible\n+        // for the map to be reused but has a downside: reserves permanently.\n+        self.resize_policy.reserve(self.table.size());\n+\n+        let cap = self.table.capacity();\n+        let mut buckets = Bucket::first(&mut self.table);\n+\n+        while buckets.index() != cap {\n+            buckets = match buckets.peek() {\n+                Empty(b)  => b.next(),\n+                Full(full) => {\n+                    let (b, _, _) = full.take();\n+                    b.next()\n+                }\n+            };\n+        }\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> Map<K, V> for HashMap<K, V, H> {\n+    fn find<'a>(&'a self, k: &K) -> Option<&'a V> {\n+        self.search(k).map(|bucket| {\n+            let (_, v) = bucket.into_refs();\n+            v\n+        })\n+    }\n+\n+    fn contains_key(&self, k: &K) -> bool {\n+        self.search(k).is_some()\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> MutableMap<K, V> for HashMap<K, V, H> {\n+    fn find_mut<'a>(&'a mut self, k: &K) -> Option<&'a mut V> {\n+        match self.search_mut(k) {\n+            Some(bucket) => {\n+                let (_, v) = bucket.into_mut_refs();\n+                Some(v)\n+            }\n+            _ => None\n+        }\n+    }\n+\n+    fn swap(&mut self, k: K, v: V) -> Option<V> {\n+        let hash = self.make_hash(&k);\n+        let potential_new_size = self.table.size() + 1;\n+        self.make_some_room(potential_new_size);\n+\n+        let mut retval = None;\n+        self.insert_or_replace_with(hash, k, v, |_, val_ref, val| {\n+            retval = Some(replace(val_ref, val));\n+        });\n+        retval\n+    }\n+\n+\n+    fn pop(&mut self, k: &K) -> Option<V> {\n+        if self.table.size() == 0 {\n+            return None\n+        }\n+\n+        let potential_new_size = self.table.size() - 1;\n+        self.make_some_room(potential_new_size);\n+\n+        self.search_mut(k).map(|bucket| {\n+            pop_internal(bucket)\n+        })\n+    }\n+}\n+\n+impl<K: Hash + Eq, V> HashMap<K, V, RandomSipHasher> {\n+    /// Create an empty HashMap.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let mut map: HashMap<&str, int> = HashMap::with_capacity(10);\n+    /// ```\n+    #[inline]\n+    pub fn new() -> HashMap<K, V, RandomSipHasher> {\n+        let hasher = RandomSipHasher::new();\n+        HashMap::with_hasher(hasher)\n+    }\n+\n+    /// Creates an empty hash map with the given initial capacity.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let mut map: HashMap<&str, int> = HashMap::with_capacity(10);\n+    /// ```\n+    #[inline]\n+    pub fn with_capacity(capacity: uint) -> HashMap<K, V, RandomSipHasher> {\n+        let hasher = RandomSipHasher::new();\n+        HashMap::with_capacity_and_hasher(capacity, hasher)\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n+    /// Creates an empty hashmap which will use the given hasher to hash keys.\n+    ///\n+    /// The creates map has the default initial capacity.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// use std::hash::sip::SipHasher;\n+    ///\n+    /// let h = SipHasher::new();\n+    /// let mut map = HashMap::with_hasher(h);\n+    /// map.insert(1i, 2u);\n+    /// ```\n+    #[inline]\n+    pub fn with_hasher(hasher: H) -> HashMap<K, V, H> {\n+        HashMap {\n+            hasher:        hasher,\n+            resize_policy: DefaultResizePolicy::new(INITIAL_CAPACITY),\n+            table:         RawTable::new(0),\n+        }\n+    }\n+\n+    /// Create an empty HashMap with space for at least `capacity`\n+    /// elements, using `hasher` to hash the keys.\n+    ///\n+    /// Warning: `hasher` is normally randomly generated, and\n+    /// is designed to allow HashMaps to be resistant to attacks that\n+    /// cause many collisions and very poor performance. Setting it\n+    /// manually using this function can expose a DoS attack vector.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// use std::hash::sip::SipHasher;\n+    ///\n+    /// let h = SipHasher::new();\n+    /// let mut map = HashMap::with_capacity_and_hasher(10, h);\n+    /// map.insert(1i, 2u);\n+    /// ```\n+    #[inline]\n+    pub fn with_capacity_and_hasher(capacity: uint, hasher: H) -> HashMap<K, V, H> {\n+        let cap = num::next_power_of_two(max(INITIAL_CAPACITY, capacity));\n+        HashMap {\n+            hasher:        hasher,\n+            resize_policy: DefaultResizePolicy::new(cap),\n+            table:         RawTable::new(cap),\n+        }\n+    }\n+\n+    /// The hashtable will never try to shrink below this size. You can use\n+    /// this function to reduce reallocations if your hashtable frequently\n+    /// grows and shrinks by large amounts.\n+    ///\n+    /// This function has no effect on the operational semantics of the\n+    /// hashtable, only on performance.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let mut map: HashMap<&str, int> = HashMap::new();\n+    /// map.reserve(10);\n+    /// ```\n+    pub fn reserve(&mut self, new_minimum_capacity: uint) {\n+        let cap = num::next_power_of_two(\n+            max(INITIAL_CAPACITY, new_minimum_capacity));\n+\n+        self.resize_policy.reserve(cap);\n+\n+        if self.table.capacity() < cap {\n+            self.resize(cap);\n+        }\n+    }\n+\n+    /// Resizes the internal vectors to a new capacity. It's your responsibility to:\n+    ///   1) Make sure the new capacity is enough for all the elements, accounting\n+    ///      for the load factor.\n+    ///   2) Ensure new_capacity is a power of two.\n+    fn resize(&mut self, new_capacity: uint) {\n+        assert!(self.table.size() <= new_capacity);\n+        assert!(num::is_power_of_two(new_capacity));\n+\n+        let mut old_table = replace(&mut self.table, RawTable::new(new_capacity));\n+        let old_size = old_table.size();\n+\n+        if old_table.capacity() == 0 || old_table.size() == 0 {\n+            return;\n+        }\n+\n+        if new_capacity < old_table.capacity() {\n+            // Shrink the table. Naive algorithm for resizing:\n+            for (h, k, v) in old_table.move_iter() {\n+                self.insert_hashed_nocheck(h, k, v);\n+            }\n+        } else {\n+            // Grow the table.\n+            // Specialization of the other branch.\n+            let mut bucket = Bucket::first(&mut old_table);\n+\n+            // \"So a few of the first shall be last: for many be called,\n+            // but few chosen.\"\n+            //\n+            // We'll most likely encounter a few buckets at the beginning that\n+            // have their initial buckets near the end of the table. They were\n+            // placed at the beginning as the probe wrapped around the table\n+            // during insertion. We must skip forward to a bucket that won't\n+            // get reinserted too early and won't unfairly steal others spot.\n+            // This eliminates the need for robin hood.\n+            loop {\n+                bucket = match bucket.peek() {\n+                    Full(full) => {\n+                        if full.distance() == 0 {\n+                            // This bucket occupies its ideal spot.\n+                            // It indicates the start of another \"cluster\".\n+                            bucket = full.into_bucket();\n+                            break;\n+                        }\n+                        // Leaving this bucket in the last cluster for later.\n+                        full.into_bucket()\n+                    }\n+                    Empty(b) => {\n+                        // Encountered a hole between clusters.\n+                        b.into_bucket()\n+                    }\n+                };\n+                bucket.next();\n+            }\n+\n+            // This is how the buckets might be laid out in memory:\n+            // ($ marks an initialized bucket)\n+            //  ________________\n+            // |$$$_$$$$$$_$$$$$|\n+            //\n+            // But we've skipped the entire initial cluster of buckets\n+            // and will continue iteration in this order:\n+            //  ________________\n+            //     |$$$$$$_$$$$$\n+            //                  ^ wrap around once end is reached\n+            //  ________________\n+            //  $$$_____________|\n+            //    ^ exit once table.size == 0\n+            loop {\n+                bucket = match bucket.peek() {\n+                    Full(bucket) => {\n+                        let h = bucket.hash();\n+                        let (b, k, v) = bucket.take();\n+                        self.insert_hashed_ordered(h, k, v);\n+                        {\n+                            let t = b.table(); // FIXME \"lifetime too short\".\n+                            if t.size() == 0 { break }\n+                        };\n+                        b.into_bucket()\n+                    }\n+                    Empty(b) => b.into_bucket()\n+                };\n+                bucket.next();\n+            }\n+        }\n+\n+        assert_eq!(self.table.size(), old_size);\n+    }\n+\n+    /// Performs any necessary resize operations, such that there's space for\n+    /// new_size elements.\n+    fn make_some_room(&mut self, new_size: uint) {\n+        let (grow_at, shrink_at) = self.resize_policy.capacity_range(new_size);\n+        let cap = self.table.capacity();\n+\n+        // An invalid value shouldn't make us run out of space.\n+        debug_assert!(grow_at >= new_size);\n+\n+        if cap <= grow_at {\n+            let new_capacity = max(cap << 1, INITIAL_CAPACITY);\n+            self.resize(new_capacity);\n+        } else if shrink_at <= cap {\n+            let new_capacity = cap >> 1;\n+            self.resize(new_capacity);\n+        }\n+    }\n+\n+    /// Insert a pre-hashed key-value pair, without first checking\n+    /// that there's enough room in the buckets. Returns a reference to the\n+    /// newly insert value.\n+    ///\n+    /// If the key already exists, the hashtable will be returned untouched\n+    /// and a reference to the existing element will be returned.\n+    fn insert_hashed_nocheck(&mut self, hash: SafeHash, k: K, v: V) -> &mut V {\n+        self.insert_or_replace_with(hash, k, v, |_, _, _| ())\n+    }\n+\n+    fn insert_or_replace_with<'a>(&'a mut self,\n+                                  hash: SafeHash,\n+                                  k: K,\n+                                  v: V,\n+                                  found_existing: |&mut K, &mut V, V|)\n+                                  -> &'a mut V {\n+        // Worst case, we'll find one empty bucket among `size + 1` buckets.\n+        let size = self.table.size();\n+        let mut probe = Bucket::new(&mut self.table, &hash);\n+        let ib = probe.index();\n+\n+        loop {\n+            let mut bucket = match probe.peek() {\n+                Empty(bucket) => {\n+                    // Found a hole!\n+                    let bucket = bucket.put(hash, k, v);\n+                    let (_, val) = bucket.into_mut_refs();\n+                    return val;\n+                },\n+                Full(bucket) => bucket\n+            };\n+\n+            if bucket.hash() == hash {\n+                let found_match = {\n+                    let (bucket_k, _) = bucket.read_mut();\n+                    k == *bucket_k\n+                };\n+                if found_match {\n+                    let (bucket_k, bucket_v) = bucket.into_mut_refs();\n+                    debug_assert!(k == *bucket_k);\n+                    // Key already exists. Get its reference.\n+                    found_existing(bucket_k, bucket_v, v);\n+                    return bucket_v;\n+                }\n+            }\n+\n+            let robin_ib = bucket.index() as int - bucket.distance() as int;\n+\n+            if (ib as int) < robin_ib {\n+                // Found a luckier bucket than me. Better steal his spot.\n+                return robin_hood(bucket, robin_ib as uint, hash, k, v);\n+            }\n+\n+            probe = bucket.next();\n+            assert!(probe.index() != ib + size + 1);\n+        }\n+    }\n+\n+    /// Inserts an element which has already been hashed, returning a reference\n+    /// to that element inside the hashtable. This is more efficient that using\n+    /// `insert`, since the key will not be rehashed.\n+    fn insert_hashed(&mut self, hash: SafeHash, k: K, v: V) -> &mut V {\n+        let potential_new_size = self.table.size() + 1;\n+        self.make_some_room(potential_new_size);\n+        self.insert_hashed_nocheck(hash, k, v)\n+    }\n+\n+    /// Return the value corresponding to the key in the map, or insert\n+    /// and return the value if it doesn't exist.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let mut map = HashMap::new();\n+    ///\n+    /// // Insert 1i with key \"a\"\n+    /// assert_eq!(*map.find_or_insert(\"a\", 1i), 1);\n+    ///\n+    /// // Find the existing key\n+    /// assert_eq!(*map.find_or_insert(\"a\", -2), 1);\n+    /// ```\n+    pub fn find_or_insert(&mut self, k: K, v: V) -> &mut V {\n+        self.find_with_or_insert_with(k, v, |_k, _v, _a| (), |_k, a| a)\n+    }\n+\n+    /// Return the value corresponding to the key in the map, or create,\n+    /// insert, and return a new value if it doesn't exist.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let mut map = HashMap::new();\n+    ///\n+    /// // Insert 10 with key 2\n+    /// assert_eq!(*map.find_or_insert_with(2i, |&key| 5 * key as uint), 10u);\n+    ///\n+    /// // Find the existing key\n+    /// assert_eq!(*map.find_or_insert_with(2, |&key| key as uint), 10);\n+    /// ```\n+    pub fn find_or_insert_with<'a>(&'a mut self, k: K, f: |&K| -> V)\n+                               -> &'a mut V {\n+        self.find_with_or_insert_with(k, (), |_k, _v, _a| (), |k, _a| f(k))\n+    }\n+\n+    /// Insert a key-value pair into the map if the key is not already present.\n+    /// Otherwise, modify the existing value for the key.\n+    /// Returns the new or modified value for the key.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// let mut map = HashMap::new();\n+    ///\n+    /// // Insert 2 with key \"a\"\n+    /// assert_eq!(*map.insert_or_update_with(\"a\", 2u, |_key, val| *val = 3), 2);\n+    ///\n+    /// // Update and return the existing value\n+    /// assert_eq!(*map.insert_or_update_with(\"a\", 9, |_key, val| *val = 7), 7);\n+    /// assert_eq!(map[\"a\"], 7);\n+    /// ```\n+    pub fn insert_or_update_with<'a>(\n+                                 &'a mut self,\n+                                 k: K,\n+                                 v: V,\n+                                 f: |&K, &mut V|)\n+                                 -> &'a mut V {\n+        let potential_new_size = self.table.size() + 1;\n+        self.make_some_room(potential_new_size);\n+\n+        let hash = self.make_hash(&k);\n+        self.insert_or_replace_with(hash, k, v, |kref, vref, _v| f(kref, vref))\n+    }\n+\n+    /// Modify and return the value corresponding to the key in the map, or\n+    /// insert and return a new value if it doesn't exist.\n+    ///\n+    /// This method allows for all insertion behaviours of a hashmap;\n+    /// see methods like\n+    /// [`insert`](../trait.MutableMap.html#tymethod.insert),\n+    /// [`find_or_insert`](#method.find_or_insert) and\n+    /// [`insert_or_update_with`](#method.insert_or_update_with)\n+    /// for less general and more friendly variations of this.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// // map some strings to vectors of strings\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a key\", vec![\"value\"]);\n+    /// map.insert(\"z key\", vec![\"value\"]);\n+    ///\n+    /// let new = vec![\"a key\", \"b key\", \"z key\"];\n+    ///\n+    /// for k in new.move_iter() {\n+    ///     map.find_with_or_insert_with(\n+    ///         k, \"new value\",\n+    ///         // if the key does exist either prepend or append this\n+    ///         // new value based on the first letter of the key.\n+    ///         |key, already, new| {\n+    ///             if key.as_slice().starts_with(\"z\") {\n+    ///                 already.insert(0, new);\n+    ///             } else {\n+    ///                 already.push(new);\n+    ///             }\n+    ///         },\n+    ///         // if the key doesn't exist in the map yet, add it in\n+    ///         // the obvious way.\n+    ///         |_k, v| vec![v]);\n+    /// }\n+    ///\n+    /// assert_eq!(map.len(), 3);\n+    /// assert_eq!(map[\"a key\"], vec![\"value\", \"new value\"]);\n+    /// assert_eq!(map[\"b key\"], vec![\"new value\"]);\n+    /// assert_eq!(map[\"z key\"], vec![\"new value\", \"value\"]);\n+    /// ```\n+    pub fn find_with_or_insert_with<'a, A>(&'a mut self,\n+                                           k: K,\n+                                           a: A,\n+                                           found: |&K, &mut V, A|,\n+                                           not_found: |&K, A| -> V)\n+                                          -> &'a mut V\n+    {\n+        let hash = self.make_hash(&k);\n+        let this = MapMutRef { map_ref: self };\n+\n+        match search_hashed(this, &hash, &k) {\n+            FoundExisting(bucket) => {\n+                let (_, v_ref) = bucket.into_mut_refs();\n+                found(&k, v_ref, a);\n+                v_ref\n+            }\n+            TableRef(this) => {\n+                let v = not_found(&k, a);\n+                this.map_ref.insert_hashed(hash, k, v)\n+            }\n+        }\n+    }\n+\n+    /// Retrieves a value for the given key.\n+    /// See [`find`](../trait.Map.html#tymethod.find) for a non-failing alternative.\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if the key is not present.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// #![allow(deprecated)]\n+    ///\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// assert_eq!(map.get(&\"a\"), &1);\n+    /// ```\n+    #[deprecated = \"prefer indexing instead, e.g., map[key]\"]\n+    pub fn get<'a>(&'a self, k: &K) -> &'a V {\n+        match self.find(k) {\n+            Some(v) => v,\n+            None => fail!(\"no entry found for key\")\n+        }\n+    }\n+\n+    /// Retrieves a mutable value for the given key.\n+    /// See [`find_mut`](../trait.MutableMap.html#tymethod.find_mut) for a non-failing alternative.\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if the key is not present.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// {\n+    ///     // val will freeze map to prevent usage during its lifetime\n+    ///     let val = map.get_mut(&\"a\");\n+    ///     *val = 40;\n+    /// }\n+    /// assert_eq!(map[\"a\"], 40);\n+    ///\n+    /// // A more direct way could be:\n+    /// *map.get_mut(&\"a\") = -2;\n+    /// assert_eq!(map[\"a\"], -2);\n+    /// ```\n+    pub fn get_mut<'a>(&'a mut self, k: &K) -> &'a mut V {\n+        match self.find_mut(k) {\n+            Some(v) => v,\n+            None => fail!(\"no entry found for key\")\n+        }\n+    }\n+\n+    /// Return true if the map contains a value for the specified key,\n+    /// using equivalence.\n+    ///\n+    /// See [pop_equiv](#method.pop_equiv) for an extended example.\n+    pub fn contains_key_equiv<Q: Hash<S> + Equiv<K>>(&self, key: &Q) -> bool {\n+        self.search_equiv(key).is_some()\n+    }\n+\n+    /// Return the value corresponding to the key in the map, using\n+    /// equivalence.\n+    ///\n+    /// See [pop_equiv](#method.pop_equiv) for an extended example.\n+    pub fn find_equiv<'a, Q: Hash<S> + Equiv<K>>(&'a self, k: &Q) -> Option<&'a V> {\n+        match self.search_equiv(k) {\n+            None      => None,\n+            Some(bucket) => {\n+                let (_, v_ref) = bucket.into_refs();\n+                Some(v_ref)\n+            }\n+        }\n+    }\n+\n+    /// Remove an equivalent key from the map, returning the value at the\n+    /// key if the key was previously in the map.\n+    ///\n+    /// # Example\n+    ///\n+    /// This is a slightly silly example where we define the number's\n+    /// parity as the equivalence class. It is important that the\n+    /// values hash the same, which is why we implement `Hash`.\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    /// use std::hash::Hash;\n+    /// use std::hash::sip::SipState;\n+    ///\n+    /// #[deriving(Eq, PartialEq)]\n+    /// struct EvenOrOdd {\n+    ///     num: uint\n+    /// };\n+    ///\n+    /// impl Hash for EvenOrOdd {\n+    ///     fn hash(&self, state: &mut SipState) {\n+    ///         let parity = self.num % 2;\n+    ///         parity.hash(state);\n+    ///     }\n+    /// }\n+    ///\n+    /// impl Equiv<EvenOrOdd> for EvenOrOdd {\n+    ///     fn equiv(&self, other: &EvenOrOdd) -> bool {\n+    ///         self.num % 2 == other.num % 2\n+    ///     }\n+    /// }\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(EvenOrOdd { num: 3 }, \"foo\");\n+    ///\n+    /// assert!(map.contains_key_equiv(&EvenOrOdd { num: 1 }));\n+    /// assert!(!map.contains_key_equiv(&EvenOrOdd { num: 4 }));\n+    ///\n+    /// assert_eq!(map.find_equiv(&EvenOrOdd { num: 5 }), Some(&\"foo\"));\n+    /// assert_eq!(map.find_equiv(&EvenOrOdd { num: 2 }), None);\n+    ///\n+    /// assert_eq!(map.pop_equiv(&EvenOrOdd { num: 1 }), Some(\"foo\"));\n+    /// assert_eq!(map.pop_equiv(&EvenOrOdd { num: 2 }), None);\n+    ///\n+    /// ```\n+    #[experimental]\n+    pub fn pop_equiv<Q:Hash<S> + Equiv<K>>(&mut self, k: &Q) -> Option<V> {\n+        if self.table.size() == 0 {\n+            return None\n+        }\n+\n+        let potential_new_size = self.table.size() - 1;\n+        self.make_some_room(potential_new_size);\n+\n+        match self.search_equiv_mut(k) {\n+            Some(bucket) => {\n+                Some(pop_internal(bucket))\n+            }\n+            _ => None\n+        }\n+    }\n+\n+    /// An iterator visiting all keys in arbitrary order.\n+    /// Iterator element type is `&'a K`.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// map.insert(\"b\", 2);\n+    /// map.insert(\"c\", 3);\n+    ///\n+    /// for key in map.keys() {\n+    ///     println!(\"{}\", key);\n+    /// }\n+    /// ```\n+    pub fn keys(&self) -> Keys<K, V> {\n+        self.iter().map(|(k, _v)| k)\n+    }\n+\n+    /// An iterator visiting all values in arbitrary order.\n+    /// Iterator element type is `&'a V`.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// map.insert(\"b\", 2);\n+    /// map.insert(\"c\", 3);\n+    ///\n+    /// for key in map.values() {\n+    ///     println!(\"{}\", key);\n+    /// }\n+    /// ```\n+    pub fn values(&self) -> Values<K, V> {\n+        self.iter().map(|(_k, v)| v)\n+    }\n+\n+    /// An iterator visiting all key-value pairs in arbitrary order.\n+    /// Iterator element type is `(&'a K, &'a V)`.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// map.insert(\"b\", 2);\n+    /// map.insert(\"c\", 3);\n+    ///\n+    /// for (key, val) in map.iter() {\n+    ///     println!(\"key: {} val: {}\", key, val);\n+    /// }\n+    /// ```\n+    pub fn iter(&self) -> Entries<K, V> {\n+        Entries { inner: self.table.iter() }\n+    }\n+\n+    /// An iterator visiting all key-value pairs in arbitrary order,\n+    /// with mutable references to the values.\n+    /// Iterator element type is `(&'a K, &'a mut V)`.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// map.insert(\"b\", 2);\n+    /// map.insert(\"c\", 3);\n+    ///\n+    /// // Update all values\n+    /// for (_, val) in map.mut_iter() {\n+    ///     *val *= 2;\n+    /// }\n+    ///\n+    /// for (key, val) in map.iter() {\n+    ///     println!(\"key: {} val: {}\", key, val);\n+    /// }\n+    /// ```\n+    pub fn mut_iter(&mut self) -> MutEntries<K, V> {\n+        MutEntries { inner: self.table.mut_iter() }\n+    }\n+\n+    /// Creates a consuming iterator, that is, one that moves each key-value\n+    /// pair out of the map in arbitrary order. The map cannot be used after\n+    /// calling this.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map = HashMap::new();\n+    /// map.insert(\"a\", 1i);\n+    /// map.insert(\"b\", 2);\n+    /// map.insert(\"c\", 3);\n+    ///\n+    /// // Not possible with .iter()\n+    /// let vec: Vec<(&str, int)> = map.move_iter().collect();\n+    /// ```\n+    pub fn move_iter(self) -> MoveEntries<K, V> {\n+        MoveEntries {\n+            inner: self.table.move_iter().map(|(_, k, v)| (k, v))\n+        }\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V: Clone, S, H: Hasher<S>> HashMap<K, V, H> {\n+    /// Return a copy of the value corresponding to the key.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map: HashMap<uint, String> = HashMap::new();\n+    /// map.insert(1u, \"foo\".to_string());\n+    /// let s: String = map.find_copy(&1).unwrap();\n+    /// ```\n+    pub fn find_copy(&self, k: &K) -> Option<V> {\n+        self.find(k).map(|v| (*v).clone())\n+    }\n+\n+    /// Return a copy of the value corresponding to the key.\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if the key is not present.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashMap;\n+    ///\n+    /// let mut map: HashMap<uint, String> = HashMap::new();\n+    /// map.insert(1u, \"foo\".to_string());\n+    /// let s: String = map.get_copy(&1);\n+    /// ```\n+    pub fn get_copy(&self, k: &K) -> V {\n+        (*self.get(k)).clone()\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V: PartialEq, S, H: Hasher<S>> PartialEq for HashMap<K, V, H> {\n+    fn eq(&self, other: &HashMap<K, V, H>) -> bool {\n+        if self.len() != other.len() { return false; }\n+\n+        self.iter().all(|(key, value)|\n+            other.find(key).map_or(false, |v| *value == *v)\n+        )\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V: Eq, S, H: Hasher<S>> Eq for HashMap<K, V, H> {}\n+\n+impl<K: Eq + Hash<S> + Show, V: Show, S, H: Hasher<S>> Show for HashMap<K, V, H> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        try!(write!(f, \"{{\"));\n+\n+        for (i, (k, v)) in self.iter().enumerate() {\n+            if i != 0 { try!(write!(f, \", \")); }\n+            try!(write!(f, \"{}: {}\", *k, *v));\n+        }\n+\n+        write!(f, \"}}\")\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S> + Default> Default for HashMap<K, V, H> {\n+    fn default() -> HashMap<K, V, H> {\n+        HashMap::with_hasher(Default::default())\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> Index<K, V> for HashMap<K, V, H> {\n+    #[inline]\n+    fn index<'a>(&'a self, index: &K) -> &'a V {\n+        self.get(index)\n+    }\n+}\n+\n+// FIXME(#12825) Indexing will always try IndexMut first and that causes issues.\n+/*impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> ops::IndexMut<K, V> for HashMap<K, V, H> {\n+    #[inline]\n+    fn index_mut<'a>(&'a mut self, index: &K) -> &'a mut V {\n+        self.get_mut(index)\n+    }\n+}*/\n+\n+/// HashMap iterator\n+pub struct Entries<'a, K: 'a, V: 'a> {\n+    inner: table::Entries<'a, K, V>\n+}\n+\n+/// HashMap mutable values iterator\n+pub struct MutEntries<'a, K: 'a, V: 'a> {\n+    inner: table::MutEntries<'a, K, V>\n+}\n+\n+/// HashMap move iterator\n+pub struct MoveEntries<K, V> {\n+    inner: iter::Map<'static, (SafeHash, K, V), (K, V), table::MoveEntries<K, V>>\n+}\n+\n+impl<'a, K, V> Iterator<(&'a K, &'a V)> for Entries<'a, K, V> {\n+    #[inline]\n+    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n+        self.inner.next()\n+    }\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        self.inner.size_hint()\n+    }\n+}\n+\n+impl<'a, K, V> Iterator<(&'a K, &'a mut V)> for MutEntries<'a, K, V> {\n+    #[inline]\n+    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n+        self.inner.next()\n+    }\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        self.inner.size_hint()\n+    }\n+}\n+\n+impl<K, V> Iterator<(K, V)> for MoveEntries<K, V> {\n+    #[inline]\n+    fn next(&mut self) -> Option<(K, V)> {\n+        self.inner.next()\n+    }\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        self.inner.size_hint()\n+    }\n+}\n+\n+/// HashMap keys iterator\n+pub type Keys<'a, K, V> =\n+    iter::Map<'static, (&'a K, &'a V), &'a K, Entries<'a, K, V>>;\n+\n+/// HashMap values iterator\n+pub type Values<'a, K, V> =\n+    iter::Map<'static, (&'a K, &'a V), &'a V, Entries<'a, K, V>>;\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S> + Default> FromIterator<(K, V)> for HashMap<K, V, H> {\n+    fn from_iter<T: Iterator<(K, V)>>(iter: T) -> HashMap<K, V, H> {\n+        let (lower, _) = iter.size_hint();\n+        let mut map = HashMap::with_capacity_and_hasher(lower, Default::default());\n+        map.extend(iter);\n+        map\n+    }\n+}\n+\n+impl<K: Eq + Hash<S>, V, S, H: Hasher<S> + Default> Extendable<(K, V)> for HashMap<K, V, H> {\n+    fn extend<T: Iterator<(K, V)>>(&mut self, mut iter: T) {\n+        for (k, v) in iter {\n+            self.insert(k, v);\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test_map {\n+    use prelude::*;\n+\n+    use super::HashMap;\n+    use cmp::Equiv;\n+    use hash;\n+    use iter::{Iterator,range_inclusive,range_step_inclusive};\n+    use cell::RefCell;\n+\n+    struct KindaIntLike(int);\n+\n+    impl Equiv<int> for KindaIntLike {\n+        fn equiv(&self, other: &int) -> bool {\n+            let KindaIntLike(this) = *self;\n+            this == *other\n+        }\n+    }\n+    impl<S: hash::Writer> hash::Hash<S> for KindaIntLike {\n+        fn hash(&self, state: &mut S) {\n+            let KindaIntLike(this) = *self;\n+            this.hash(state)\n+        }\n+    }\n+\n+    #[test]\n+    fn test_create_capacity_zero() {\n+        let mut m = HashMap::with_capacity(0);\n+\n+        assert!(m.insert(1i, 1i));\n+\n+        assert!(m.contains_key(&1));\n+        assert!(!m.contains_key(&0));\n+    }\n+\n+    #[test]\n+    fn test_insert() {\n+        let mut m = HashMap::new();\n+        assert_eq!(m.len(), 0);\n+        assert!(m.insert(1i, 2i));\n+        assert_eq!(m.len(), 1);\n+        assert!(m.insert(2i, 4i));\n+        assert_eq!(m.len(), 2);\n+        assert_eq!(*m.find(&1).unwrap(), 2);\n+        assert_eq!(*m.find(&2).unwrap(), 4);\n+    }\n+\n+    local_data_key!(drop_vector: RefCell<Vec<int>>)\n+\n+    #[deriving(Hash, PartialEq, Eq)]\n+    struct Dropable {\n+        k: uint\n+    }\n+\n+    impl Dropable {\n+        fn new(k: uint) -> Dropable {\n+            let v = drop_vector.get().unwrap();\n+            v.borrow_mut().as_mut_slice()[k] += 1;\n+\n+            Dropable { k: k }\n+        }\n+    }\n+\n+    impl Drop for Dropable {\n+        fn drop(&mut self) {\n+            let v = drop_vector.get().unwrap();\n+            v.borrow_mut().as_mut_slice()[self.k] -= 1;\n+        }\n+    }\n+\n+    impl Clone for Dropable {\n+        fn clone(&self) -> Dropable {\n+            Dropable::new(self.k)\n+        }\n+    }\n+\n+    #[test]\n+    fn test_drops() {\n+        drop_vector.replace(Some(RefCell::new(Vec::from_elem(200, 0i))));\n+\n+        {\n+            let mut m = HashMap::new();\n+\n+            let v = drop_vector.get().unwrap();\n+            for i in range(0u, 200) {\n+                assert_eq!(v.borrow().as_slice()[i], 0);\n+            }\n+            drop(v);\n+\n+            for i in range(0u, 100) {\n+                let d1 = Dropable::new(i);\n+                let d2 = Dropable::new(i+100);\n+                m.insert(d1, d2);\n+            }\n+\n+            let v = drop_vector.get().unwrap();\n+            for i in range(0u, 200) {\n+                assert_eq!(v.borrow().as_slice()[i], 1);\n+            }\n+            drop(v);\n+\n+            for i in range(0u, 50) {\n+                let k = Dropable::new(i);\n+                let v = m.pop(&k);\n+\n+                assert!(v.is_some());\n+\n+                let v = drop_vector.get().unwrap();\n+                assert_eq!(v.borrow().as_slice()[i], 1);\n+                assert_eq!(v.borrow().as_slice()[i+100], 1);\n+            }\n+\n+            let v = drop_vector.get().unwrap();\n+            for i in range(0u, 50) {\n+                assert_eq!(v.borrow().as_slice()[i], 0);\n+                assert_eq!(v.borrow().as_slice()[i+100], 0);\n+            }\n+\n+            for i in range(50u, 100) {\n+                assert_eq!(v.borrow().as_slice()[i], 1);\n+                assert_eq!(v.borrow().as_slice()[i+100], 1);\n+            }\n+        }\n+\n+        let v = drop_vector.get().unwrap();\n+        for i in range(0u, 200) {\n+            assert_eq!(v.borrow().as_slice()[i], 0);\n+        }\n+    }\n+\n+    #[test]\n+    fn test_move_iter_drops() {\n+        drop_vector.replace(Some(RefCell::new(Vec::from_elem(200, 0i))));\n+\n+        let hm = {\n+            let mut hm = HashMap::new();\n+\n+            let v = drop_vector.get().unwrap();\n+            for i in range(0u, 200) {\n+                assert_eq!(v.borrow().as_slice()[i], 0);\n+            }\n+            drop(v);\n+\n+            for i in range(0u, 100) {\n+                let d1 = Dropable::new(i);\n+                let d2 = Dropable::new(i+100);\n+                hm.insert(d1, d2);\n+            }\n+\n+            let v = drop_vector.get().unwrap();\n+            for i in range(0u, 200) {\n+                assert_eq!(v.borrow().as_slice()[i], 1);\n+            }\n+            drop(v);\n+\n+            hm\n+        };\n+\n+        // By the way, ensure that cloning doesn't screw up the dropping.\n+        drop(hm.clone());\n+\n+        {\n+            let mut half = hm.move_iter().take(50);\n+\n+            let v = drop_vector.get().unwrap();\n+            for i in range(0u, 200) {\n+                assert_eq!(v.borrow().as_slice()[i], 1);\n+            }\n+            drop(v);\n+\n+            for _ in half {}\n+\n+            let v = drop_vector.get().unwrap();\n+            let nk = range(0u, 100).filter(|&i| {\n+                v.borrow().as_slice()[i] == 1\n+            }).count();\n+\n+            let nv = range(0u, 100).filter(|&i| {\n+                v.borrow().as_slice()[i+100] == 1\n+            }).count();\n+\n+            assert_eq!(nk, 50);\n+            assert_eq!(nv, 50);\n+        };\n+\n+        let v = drop_vector.get().unwrap();\n+        for i in range(0u, 200) {\n+            assert_eq!(v.borrow().as_slice()[i], 0);\n+        }\n+    }\n+\n+    #[test]\n+    fn test_empty_pop() {\n+        let mut m: HashMap<int, bool> = HashMap::new();\n+        assert_eq!(m.pop(&0), None);\n+    }\n+\n+    #[test]\n+    fn test_lots_of_insertions() {\n+        let mut m = HashMap::new();\n+\n+        // Try this a few times to make sure we never screw up the hashmap's\n+        // internal state.\n+        for _ in range(0i, 10) {\n+            assert!(m.is_empty());\n+\n+            for i in range_inclusive(1i, 1000) {\n+                assert!(m.insert(i, i));\n+\n+                for j in range_inclusive(1, i) {\n+                    let r = m.find(&j);\n+                    assert_eq!(r, Some(&j));\n+                }\n+\n+                for j in range_inclusive(i+1, 1000) {\n+                    let r = m.find(&j);\n+                    assert_eq!(r, None);\n+                }\n+            }\n+\n+            for i in range_inclusive(1001i, 2000) {\n+                assert!(!m.contains_key(&i));\n+            }\n+\n+            // remove forwards\n+            for i in range_inclusive(1i, 1000) {\n+                assert!(m.remove(&i));\n+\n+                for j in range_inclusive(1, i) {\n+                    assert!(!m.contains_key(&j));\n+                }\n+\n+                for j in range_inclusive(i+1, 1000) {\n+                    assert!(m.contains_key(&j));\n+                }\n+            }\n+\n+            for i in range_inclusive(1i, 1000) {\n+                assert!(!m.contains_key(&i));\n+            }\n+\n+            for i in range_inclusive(1i, 1000) {\n+                assert!(m.insert(i, i));\n+            }\n+\n+            // remove backwards\n+            for i in range_step_inclusive(1000i, 1, -1) {\n+                assert!(m.remove(&i));\n+\n+                for j in range_inclusive(i, 1000) {\n+                    assert!(!m.contains_key(&j));\n+                }\n+\n+                for j in range_inclusive(1, i-1) {\n+                    assert!(m.contains_key(&j));\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn test_find_mut() {\n+        let mut m = HashMap::new();\n+        assert!(m.insert(1i, 12i));\n+        assert!(m.insert(2i, 8i));\n+        assert!(m.insert(5i, 14i));\n+        let new = 100;\n+        match m.find_mut(&5) {\n+            None => fail!(), Some(x) => *x = new\n+        }\n+        assert_eq!(m.find(&5), Some(&new));\n+    }\n+\n+    #[test]\n+    fn test_insert_overwrite() {\n+        let mut m = HashMap::new();\n+        assert!(m.insert(1i, 2i));\n+        assert_eq!(*m.find(&1).unwrap(), 2);\n+        assert!(!m.insert(1i, 3i));\n+        assert_eq!(*m.find(&1).unwrap(), 3);\n+    }\n+\n+    #[test]\n+    fn test_insert_conflicts() {\n+        let mut m = HashMap::with_capacity(4);\n+        assert!(m.insert(1i, 2i));\n+        assert!(m.insert(5i, 3i));\n+        assert!(m.insert(9i, 4i));\n+        assert_eq!(*m.find(&9).unwrap(), 4);\n+        assert_eq!(*m.find(&5).unwrap(), 3);\n+        assert_eq!(*m.find(&1).unwrap(), 2);\n+    }\n+\n+    #[test]\n+    fn test_update_with() {\n+        let mut m = HashMap::with_capacity(4);\n+        assert!(m.insert(1i, 2i));\n+\n+        for i in range(1i, 1000) {\n+            assert_eq!(\n+                i + 2,\n+                *m.insert_or_update_with(i + 1, i + 2, |_k, _v| {\n+                    fail!(\"Key not yet present\");\n+                })\n+            );\n+            assert_eq!(\n+                i + 1,\n+                *m.insert_or_update_with(i, i + 3, |k, v| {\n+                    assert_eq!(*k, i);\n+                    assert_eq!(*v, i + 1);\n+                })\n+            );\n+        }\n+    }\n+\n+    #[test]\n+    fn test_conflict_remove() {\n+        let mut m = HashMap::with_capacity(4);\n+        assert!(m.insert(1i, 2i));\n+        assert_eq!(*m.find(&1).unwrap(), 2);\n+        assert!(m.insert(5, 3));\n+        assert_eq!(*m.find(&1).unwrap(), 2);\n+        assert_eq!(*m.find(&5).unwrap(), 3);\n+        assert!(m.insert(9, 4));\n+        assert_eq!(*m.find(&1).unwrap(), 2);\n+        assert_eq!(*m.find(&5).unwrap(), 3);\n+        assert_eq!(*m.find(&9).unwrap(), 4);\n+        assert!(m.remove(&1));\n+        assert_eq!(*m.find(&9).unwrap(), 4);\n+        assert_eq!(*m.find(&5).unwrap(), 3);\n+    }\n+\n+    #[test]\n+    fn test_is_empty() {\n+        let mut m = HashMap::with_capacity(4);\n+        assert!(m.insert(1i, 2i));\n+        assert!(!m.is_empty());\n+        assert!(m.remove(&1));\n+        assert!(m.is_empty());\n+    }\n+\n+    #[test]\n+    fn test_pop() {\n+        let mut m = HashMap::new();\n+        m.insert(1i, 2i);\n+        assert_eq!(m.pop(&1), Some(2));\n+        assert_eq!(m.pop(&1), None);\n+    }\n+\n+    #[test]\n+    #[allow(experimental)]\n+    fn test_pop_equiv() {\n+        let mut m = HashMap::new();\n+        m.insert(1i, 2i);\n+        assert_eq!(m.pop_equiv(&KindaIntLike(1)), Some(2));\n+        assert_eq!(m.pop_equiv(&KindaIntLike(1)), None);\n+    }\n+\n+    #[test]\n+    fn test_swap() {\n+        let mut m = HashMap::new();\n+        assert_eq!(m.swap(1i, 2i), None);\n+        assert_eq!(m.swap(1i, 3i), Some(2));\n+        assert_eq!(m.swap(1i, 4i), Some(3));\n+    }\n+\n+    #[test]\n+    fn test_iterate() {\n+        let mut m = HashMap::with_capacity(4);\n+        for i in range(0u, 32) {\n+            assert!(m.insert(i, i*2));\n+        }\n+        assert_eq!(m.len(), 32);\n+\n+        let mut observed: u32 = 0;\n+\n+        for (k, v) in m.iter() {\n+            assert_eq!(*v, *k * 2);\n+            observed |= 1 << *k;\n+        }\n+        assert_eq!(observed, 0xFFFF_FFFF);\n+    }\n+\n+    #[test]\n+    fn test_keys() {\n+        let vec = vec![(1i, 'a'), (2i, 'b'), (3i, 'c')];\n+        let map = vec.move_iter().collect::<HashMap<int, char>>();\n+        let keys = map.keys().map(|&k| k).collect::<Vec<int>>();\n+        assert_eq!(keys.len(), 3);\n+        assert!(keys.contains(&1));\n+        assert!(keys.contains(&2));\n+        assert!(keys.contains(&3));\n+    }\n+\n+    #[test]\n+    fn test_values() {\n+        let vec = vec![(1i, 'a'), (2i, 'b'), (3i, 'c')];\n+        let map = vec.move_iter().collect::<HashMap<int, char>>();\n+        let values = map.values().map(|&v| v).collect::<Vec<char>>();\n+        assert_eq!(values.len(), 3);\n+        assert!(values.contains(&'a'));\n+        assert!(values.contains(&'b'));\n+        assert!(values.contains(&'c'));\n+    }\n+\n+    #[test]\n+    fn test_find() {\n+        let mut m = HashMap::new();\n+        assert!(m.find(&1i).is_none());\n+        m.insert(1i, 2i);\n+        match m.find(&1) {\n+            None => fail!(),\n+            Some(v) => assert_eq!(*v, 2)\n+        }\n+    }\n+\n+    #[test]\n+    fn test_find_copy() {\n+        let mut m = HashMap::new();\n+        assert!(m.find(&1i).is_none());\n+\n+        for i in range(1i, 10000) {\n+            m.insert(i, i + 7);\n+            match m.find_copy(&i) {\n+                None => fail!(),\n+                Some(v) => assert_eq!(v, i + 7)\n+            }\n+            for j in range(1i, i/100) {\n+                match m.find_copy(&j) {\n+                    None => fail!(),\n+                    Some(v) => assert_eq!(v, j + 7)\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn test_eq() {\n+        let mut m1 = HashMap::new();\n+        m1.insert(1i, 2i);\n+        m1.insert(2i, 3i);\n+        m1.insert(3i, 4i);\n+\n+        let mut m2 = HashMap::new();\n+        m2.insert(1i, 2i);\n+        m2.insert(2i, 3i);\n+\n+        assert!(m1 != m2);\n+\n+        m2.insert(3i, 4i);\n+\n+        assert_eq!(m1, m2);\n+    }\n+\n+    #[test]\n+    fn test_show() {\n+        let mut map: HashMap<int, int> = HashMap::new();\n+        let empty: HashMap<int, int> = HashMap::new();\n+\n+        map.insert(1i, 2i);\n+        map.insert(3i, 4i);\n+\n+        let map_str = format!(\"{}\", map);\n+\n+        assert!(map_str == \"{1: 2, 3: 4}\".to_string() || map_str == \"{3: 4, 1: 2}\".to_string());\n+        assert_eq!(format!(\"{}\", empty), \"{}\".to_string());\n+    }\n+\n+    #[test]\n+    fn test_expand() {\n+        let mut m = HashMap::new();\n+\n+        assert_eq!(m.len(), 0);\n+        assert!(m.is_empty());\n+\n+        let mut i = 0u;\n+        let old_cap = m.table.capacity();\n+        while old_cap == m.table.capacity() {\n+            m.insert(i, i);\n+            i += 1;\n+        }\n+\n+        assert_eq!(m.len(), i);\n+        assert!(!m.is_empty());\n+    }\n+\n+    #[test]\n+    fn test_resize_policy() {\n+        let mut m = HashMap::new();\n+\n+        assert_eq!(m.len(), 0);\n+        assert_eq!(m.table.capacity(), 0);\n+        assert!(m.is_empty());\n+\n+        m.insert(0, 0);\n+        m.remove(&0);\n+        assert!(m.is_empty());\n+        let initial_cap = m.table.capacity();\n+        m.reserve(initial_cap * 2);\n+        let cap = m.table.capacity();\n+\n+        assert_eq!(cap, initial_cap * 2);\n+\n+        let mut i = 0u;\n+        for _ in range(0, cap * 3 / 4) {\n+            m.insert(i, i);\n+            i += 1;\n+        }\n+        // three quarters full\n+\n+        assert_eq!(m.len(), i);\n+        assert_eq!(m.table.capacity(), cap);\n+\n+        for _ in range(0, cap / 4) {\n+            m.insert(i, i);\n+            i += 1;\n+        }\n+        // half full\n+\n+        let new_cap = m.table.capacity();\n+        assert_eq!(new_cap, cap * 2);\n+\n+        for _ in range(0, cap / 2 - 1) {\n+            i -= 1;\n+            m.remove(&i);\n+            assert_eq!(m.table.capacity(), new_cap);\n+        }\n+        // A little more than one quarter full.\n+        // Shrinking starts as we remove more elements:\n+        for _ in range(0, cap / 2 - 1) {\n+            i -= 1;\n+            m.remove(&i);\n+        }\n+\n+        assert_eq!(m.len(), i);\n+        assert!(!m.is_empty());\n+        assert_eq!(m.table.capacity(), cap);\n+    }\n+\n+    #[test]\n+    fn test_find_equiv() {\n+        let mut m = HashMap::new();\n+\n+        let (foo, bar, baz) = (1i,2i,3i);\n+        m.insert(\"foo\".to_string(), foo);\n+        m.insert(\"bar\".to_string(), bar);\n+        m.insert(\"baz\".to_string(), baz);\n+\n+\n+        assert_eq!(m.find_equiv(&(\"foo\")), Some(&foo));\n+        assert_eq!(m.find_equiv(&(\"bar\")), Some(&bar));\n+        assert_eq!(m.find_equiv(&(\"baz\")), Some(&baz));\n+\n+        assert_eq!(m.find_equiv(&(\"qux\")), None);\n+    }\n+\n+    #[test]\n+    fn test_from_iter() {\n+        let xs = [(1i, 1i), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n+\n+        let map: HashMap<int, int> = xs.iter().map(|&x| x).collect();\n+\n+        for &(k, v) in xs.iter() {\n+            assert_eq!(map.find(&k), Some(&v));\n+        }\n+    }\n+\n+    #[test]\n+    fn test_size_hint() {\n+        let xs = [(1i, 1i), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n+\n+        let map: HashMap<int, int> = xs.iter().map(|&x| x).collect();\n+\n+        let mut iter = map.iter();\n+\n+        for _ in iter.by_ref().take(3) {}\n+\n+        assert_eq!(iter.size_hint(), (3, Some(3)));\n+    }\n+\n+    #[test]\n+    fn test_mut_size_hint() {\n+        let xs = [(1i, 1i), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)];\n+\n+        let mut map: HashMap<int, int> = xs.iter().map(|&x| x).collect();\n+\n+        let mut iter = map.mut_iter();\n+\n+        for _ in iter.by_ref().take(3) {}\n+\n+        assert_eq!(iter.size_hint(), (3, Some(3)));\n+    }\n+\n+    #[test]\n+    fn test_index() {\n+        let mut map: HashMap<int, int> = HashMap::new();\n+\n+        map.insert(1, 2);\n+        map.insert(2, 1);\n+        map.insert(3, 4);\n+\n+        assert_eq!(map[2], 1);\n+    }\n+\n+    #[test]\n+    #[should_fail]\n+    fn test_index_nonexistent() {\n+        let mut map: HashMap<int, int> = HashMap::new();\n+\n+        map.insert(1, 2);\n+        map.insert(2, 1);\n+        map.insert(3, 4);\n+\n+        map[4];\n+    }\n+}"}, {"sha": "b5612ce0f077d05cf8f525c2983ec1c836085cb2", "filename": "src/libstd/collections/hashmap/mod.rs", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fmod.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -0,0 +1,28 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Unordered containers, implemented as hash-tables\n+\n+pub use self::map::HashMap;\n+pub use self::map::Entries;\n+pub use self::map::MutEntries;\n+pub use self::map::MoveEntries;\n+pub use self::map::Keys;\n+pub use self::map::Values;\n+pub use self::map::INITIAL_CAPACITY;\n+pub use self::set::HashSet;\n+pub use self::set::SetItems;\n+pub use self::set::SetMoveItems;\n+pub use self::set::SetAlgebraItems;\n+\n+mod bench;\n+mod map;\n+mod set;\n+mod table;"}, {"sha": "4a2a04cbc9f66b0ee452926fc5cda3361e39e37a", "filename": "src/libstd/collections/hashmap/set.rs", "status": "added", "additions": 703, "deletions": 0, "changes": 703, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fset.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Fset.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fset.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -0,0 +1,703 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+//\n+// ignore-lexer-test FIXME #15883\n+\n+use clone::Clone;\n+use cmp::{Eq, Equiv, PartialEq};\n+use collections::{Collection, Mutable, Set, MutableSet, Map, MutableMap};\n+use default::Default;\n+use fmt::Show;\n+use fmt;\n+use hash::{Hash, Hasher, RandomSipHasher};\n+use iter::{Iterator, FromIterator, FilterMap, Chain, Repeat, Zip, Extendable};\n+use iter;\n+use option::{Some, None};\n+use result::{Ok, Err};\n+\n+use super::{HashMap, Entries, MoveEntries, INITIAL_CAPACITY};\n+\n+\n+// Future Optimization (FIXME!)\n+// =============================\n+//\n+// Iteration over zero sized values is a noop. There is no need\n+// for `bucket.val` in the case of HashSet. I suppose we would need HKT\n+// to get rid of it properly.\n+\n+/// An implementation of a hash set using the underlying representation of a\n+/// HashMap where the value is (). As with the `HashMap` type, a `HashSet`\n+/// requires that the elements implement the `Eq` and `Hash` traits.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::collections::HashSet;\n+/// // Type inference lets us omit an explicit type signature (which\n+/// // would be `HashSet<&str>` in this example).\n+/// let mut books = HashSet::new();\n+///\n+/// // Add some books.\n+/// books.insert(\"A Dance With Dragons\");\n+/// books.insert(\"To Kill a Mockingbird\");\n+/// books.insert(\"The Odyssey\");\n+/// books.insert(\"The Great Gatsby\");\n+///\n+/// // Check for a specific one.\n+/// if !books.contains(&(\"The Winds of Winter\")) {\n+///     println!(\"We have {} books, but The Winds of Winter ain't one.\",\n+///              books.len());\n+/// }\n+///\n+/// // Remove a book.\n+/// books.remove(&\"The Odyssey\");\n+///\n+/// // Iterate over everything.\n+/// for book in books.iter() {\n+///     println!(\"{}\", *book);\n+/// }\n+/// ```\n+///\n+/// The easiest way to use `HashSet` with a custom type is to derive\n+/// `Eq` and `Hash`. We must also derive `PartialEq`, this will in the\n+/// future be implied by `Eq`.\n+///\n+/// ```\n+/// use std::collections::HashSet;\n+/// #[deriving(Hash, Eq, PartialEq, Show)]\n+/// struct Viking<'a> {\n+///     name: &'a str,\n+///     power: uint,\n+/// }\n+///\n+/// let mut vikings = HashSet::new();\n+///\n+/// vikings.insert(Viking { name: \"Einar\", power: 9u });\n+/// vikings.insert(Viking { name: \"Einar\", power: 9u });\n+/// vikings.insert(Viking { name: \"Olaf\", power: 4u });\n+/// vikings.insert(Viking { name: \"Harald\", power: 8u });\n+///\n+/// // Use derived implementation to print the vikings.\n+/// for x in vikings.iter() {\n+///     println!(\"{}\", x);\n+/// }\n+/// ```\n+#[deriving(Clone)]\n+pub struct HashSet<T, H = RandomSipHasher> {\n+    map: HashMap<T, (), H>\n+}\n+\n+impl<T: Hash + Eq> HashSet<T, RandomSipHasher> {\n+    /// Create an empty HashSet.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let mut set: HashSet<int> = HashSet::new();\n+    /// ```\n+    #[inline]\n+    pub fn new() -> HashSet<T, RandomSipHasher> {\n+        HashSet::with_capacity(INITIAL_CAPACITY)\n+    }\n+\n+    /// Create an empty HashSet with space for at least `n` elements in\n+    /// the hash table.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let mut set: HashSet<int> = HashSet::with_capacity(10);\n+    /// ```\n+    #[inline]\n+    pub fn with_capacity(capacity: uint) -> HashSet<T, RandomSipHasher> {\n+        HashSet { map: HashMap::with_capacity(capacity) }\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> HashSet<T, H> {\n+    /// Creates a new empty hash set which will use the given hasher to hash\n+    /// keys.\n+    ///\n+    /// The hash set is also created with the default initial capacity.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// use std::hash::sip::SipHasher;\n+    ///\n+    /// let h = SipHasher::new();\n+    /// let mut set = HashSet::with_hasher(h);\n+    /// set.insert(2u);\n+    /// ```\n+    #[inline]\n+    pub fn with_hasher(hasher: H) -> HashSet<T, H> {\n+        HashSet::with_capacity_and_hasher(INITIAL_CAPACITY, hasher)\n+    }\n+\n+    /// Create an empty HashSet with space for at least `capacity`\n+    /// elements in the hash table, using `hasher` to hash the keys.\n+    ///\n+    /// Warning: `hasher` is normally randomly generated, and\n+    /// is designed to allow `HashSet`s to be resistant to attacks that\n+    /// cause many collisions and very poor performance. Setting it\n+    /// manually using this function can expose a DoS attack vector.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// use std::hash::sip::SipHasher;\n+    ///\n+    /// let h = SipHasher::new();\n+    /// let mut set = HashSet::with_capacity_and_hasher(10u, h);\n+    /// set.insert(1i);\n+    /// ```\n+    #[inline]\n+    pub fn with_capacity_and_hasher(capacity: uint, hasher: H) -> HashSet<T, H> {\n+        HashSet { map: HashMap::with_capacity_and_hasher(capacity, hasher) }\n+    }\n+\n+    /// Reserve space for at least `n` elements in the hash table.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let mut set: HashSet<int> = HashSet::new();\n+    /// set.reserve(10);\n+    /// ```\n+    pub fn reserve(&mut self, n: uint) {\n+        self.map.reserve(n)\n+    }\n+\n+    /// Returns true if the hash set contains a value equivalent to the\n+    /// given query value.\n+    ///\n+    /// # Example\n+    ///\n+    /// This is a slightly silly example where we define the number's\n+    /// parity as the equivilance class. It is important that the\n+    /// values hash the same, which is why we implement `Hash`.\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// use std::hash::Hash;\n+    /// use std::hash::sip::SipState;\n+    ///\n+    /// #[deriving(Eq, PartialEq)]\n+    /// struct EvenOrOdd {\n+    ///     num: uint\n+    /// };\n+    ///\n+    /// impl Hash for EvenOrOdd {\n+    ///     fn hash(&self, state: &mut SipState) {\n+    ///         let parity = self.num % 2;\n+    ///         parity.hash(state);\n+    ///     }\n+    /// }\n+    ///\n+    /// impl Equiv<EvenOrOdd> for EvenOrOdd {\n+    ///     fn equiv(&self, other: &EvenOrOdd) -> bool {\n+    ///         self.num % 2 == other.num % 2\n+    ///     }\n+    /// }\n+    ///\n+    /// let mut set = HashSet::new();\n+    /// set.insert(EvenOrOdd { num: 3u });\n+    ///\n+    /// assert!(set.contains_equiv(&EvenOrOdd { num: 3u }));\n+    /// assert!(set.contains_equiv(&EvenOrOdd { num: 5u }));\n+    /// assert!(!set.contains_equiv(&EvenOrOdd { num: 4u }));\n+    /// assert!(!set.contains_equiv(&EvenOrOdd { num: 2u }));\n+    ///\n+    /// ```\n+    pub fn contains_equiv<Q: Hash<S> + Equiv<T>>(&self, value: &Q) -> bool {\n+      self.map.contains_key_equiv(value)\n+    }\n+\n+    /// An iterator visiting all elements in arbitrary order.\n+    /// Iterator element type is &'a T.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let mut set = HashSet::new();\n+    /// set.insert(\"a\");\n+    /// set.insert(\"b\");\n+    ///\n+    /// // Will print in an arbitrary order.\n+    /// for x in set.iter() {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    /// ```\n+    pub fn iter<'a>(&'a self) -> SetItems<'a, T> {\n+        self.map.keys()\n+    }\n+\n+    /// Creates a consuming iterator, that is, one that moves each value out\n+    /// of the set in arbitrary order. The set cannot be used after calling\n+    /// this.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let mut set = HashSet::new();\n+    /// set.insert(\"a\".to_string());\n+    /// set.insert(\"b\".to_string());\n+    ///\n+    /// // Not possible to collect to a Vec<String> with a regular `.iter()`.\n+    /// let v: Vec<String> = set.move_iter().collect();\n+    ///\n+    /// // Will print in an arbitrary order.\n+    /// for x in v.iter() {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    /// ```\n+    pub fn move_iter(self) -> SetMoveItems<T> {\n+        self.map.move_iter().map(|(k, _)| k)\n+    }\n+\n+    /// Visit the values representing the difference.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let a: HashSet<int> = [1i, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: HashSet<int> = [4i, 2, 3, 4].iter().map(|&x| x).collect();\n+    ///\n+    /// // Can be seen as `a - b`.\n+    /// for x in a.difference(&b) {\n+    ///     println!(\"{}\", x); // Print 1\n+    /// }\n+    ///\n+    /// let diff: HashSet<int> = a.difference(&b).map(|&x| x).collect();\n+    /// assert_eq!(diff, [1i].iter().map(|&x| x).collect());\n+    ///\n+    /// // Note that difference is not symmetric,\n+    /// // and `b - a` means something else:\n+    /// let diff: HashSet<int> = b.difference(&a).map(|&x| x).collect();\n+    /// assert_eq!(diff, [4i].iter().map(|&x| x).collect());\n+    /// ```\n+    pub fn difference<'a>(&'a self, other: &'a HashSet<T, H>) -> SetAlgebraItems<'a, T, H> {\n+        Repeat::new(other).zip(self.iter())\n+            .filter_map(|(other, elt)| {\n+                if !other.contains(elt) { Some(elt) } else { None }\n+            })\n+    }\n+\n+    /// Visit the values representing the symmetric difference.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let a: HashSet<int> = [1i, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: HashSet<int> = [4i, 2, 3, 4].iter().map(|&x| x).collect();\n+    ///\n+    /// // Print 1, 4 in arbitrary order.\n+    /// for x in a.symmetric_difference(&b) {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    ///\n+    /// let diff1: HashSet<int> = a.symmetric_difference(&b).map(|&x| x).collect();\n+    /// let diff2: HashSet<int> = b.symmetric_difference(&a).map(|&x| x).collect();\n+    ///\n+    /// assert_eq!(diff1, diff2);\n+    /// assert_eq!(diff1, [1i, 4].iter().map(|&x| x).collect());\n+    /// ```\n+    pub fn symmetric_difference<'a>(&'a self, other: &'a HashSet<T, H>)\n+        -> Chain<SetAlgebraItems<'a, T, H>, SetAlgebraItems<'a, T, H>> {\n+        self.difference(other).chain(other.difference(self))\n+    }\n+\n+    /// Visit the values representing the intersection.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let a: HashSet<int> = [1i, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: HashSet<int> = [4i, 2, 3, 4].iter().map(|&x| x).collect();\n+    ///\n+    /// // Print 2, 3 in arbitrary order.\n+    /// for x in a.intersection(&b) {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    ///\n+    /// let diff: HashSet<int> = a.intersection(&b).map(|&x| x).collect();\n+    /// assert_eq!(diff, [2i, 3].iter().map(|&x| x).collect());\n+    /// ```\n+    pub fn intersection<'a>(&'a self, other: &'a HashSet<T, H>)\n+        -> SetAlgebraItems<'a, T, H> {\n+        Repeat::new(other).zip(self.iter())\n+            .filter_map(|(other, elt)| {\n+                if other.contains(elt) { Some(elt) } else { None }\n+            })\n+    }\n+\n+    /// Visit the values representing the union.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::HashSet;\n+    /// let a: HashSet<int> = [1i, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: HashSet<int> = [4i, 2, 3, 4].iter().map(|&x| x).collect();\n+    ///\n+    /// // Print 1, 2, 3, 4 in arbitrary order.\n+    /// for x in a.union(&b) {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    ///\n+    /// let diff: HashSet<int> = a.union(&b).map(|&x| x).collect();\n+    /// assert_eq!(diff, [1i, 2, 3, 4].iter().map(|&x| x).collect());\n+    /// ```\n+    pub fn union<'a>(&'a self, other: &'a HashSet<T, H>)\n+        -> Chain<SetItems<'a, T>, SetAlgebraItems<'a, T, H>> {\n+        self.iter().chain(other.difference(self))\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> PartialEq for HashSet<T, H> {\n+    fn eq(&self, other: &HashSet<T, H>) -> bool {\n+        if self.len() != other.len() { return false; }\n+\n+        self.iter().all(|key| other.contains(key))\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> Eq for HashSet<T, H> {}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> Collection for HashSet<T, H> {\n+    fn len(&self) -> uint { self.map.len() }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> Mutable for HashSet<T, H> {\n+    fn clear(&mut self) { self.map.clear() }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> Set<T> for HashSet<T, H> {\n+    fn contains(&self, value: &T) -> bool { self.map.contains_key(value) }\n+\n+    fn is_disjoint(&self, other: &HashSet<T, H>) -> bool {\n+        self.iter().all(|v| !other.contains(v))\n+    }\n+\n+    fn is_subset(&self, other: &HashSet<T, H>) -> bool {\n+        self.iter().all(|v| other.contains(v))\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S>> MutableSet<T> for HashSet<T, H> {\n+    fn insert(&mut self, value: T) -> bool { self.map.insert(value, ()) }\n+\n+    fn remove(&mut self, value: &T) -> bool { self.map.remove(value) }\n+}\n+\n+impl<T: Eq + Hash<S> + fmt::Show, S, H: Hasher<S>> fmt::Show for HashSet<T, H> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        try!(write!(f, \"{{\"));\n+\n+        for (i, x) in self.iter().enumerate() {\n+            if i != 0 { try!(write!(f, \", \")); }\n+            try!(write!(f, \"{}\", *x));\n+        }\n+\n+        write!(f, \"}}\")\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S> + Default> FromIterator<T> for HashSet<T, H> {\n+    fn from_iter<I: Iterator<T>>(iter: I) -> HashSet<T, H> {\n+        let (lower, _) = iter.size_hint();\n+        let mut set = HashSet::with_capacity_and_hasher(lower, Default::default());\n+        set.extend(iter);\n+        set\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S> + Default> Extendable<T> for HashSet<T, H> {\n+    fn extend<I: Iterator<T>>(&mut self, mut iter: I) {\n+        for k in iter {\n+            self.insert(k);\n+        }\n+    }\n+}\n+\n+impl<T: Eq + Hash<S>, S, H: Hasher<S> + Default> Default for HashSet<T, H> {\n+    fn default() -> HashSet<T, H> {\n+        HashSet::with_hasher(Default::default())\n+    }\n+}\n+\n+/// HashSet iterator\n+pub type SetItems<'a, K> =\n+    iter::Map<'static, (&'a K, &'a ()), &'a K, Entries<'a, K, ()>>;\n+\n+/// HashSet move iterator\n+pub type SetMoveItems<K> =\n+    iter::Map<'static, (K, ()), K, MoveEntries<K, ()>>;\n+\n+// `Repeat` is used to feed the filter closure an explicit capture\n+// of a reference to the other set\n+/// Set operations iterator\n+pub type SetAlgebraItems<'a, T, H> =\n+    FilterMap<'static, (&'a HashSet<T, H>, &'a T), &'a T,\n+              Zip<Repeat<&'a HashSet<T, H>>, SetItems<'a, T>>>;\n+\n+#[cfg(test)]\n+mod test_set {\n+    use prelude::*;\n+\n+    use super::HashSet;\n+    use slice::ImmutablePartialEqSlice;\n+    use collections::Collection;\n+\n+    #[test]\n+    fn test_disjoint() {\n+        let mut xs = HashSet::new();\n+        let mut ys = HashSet::new();\n+        assert!(xs.is_disjoint(&ys));\n+        assert!(ys.is_disjoint(&xs));\n+        assert!(xs.insert(5i));\n+        assert!(ys.insert(11i));\n+        assert!(xs.is_disjoint(&ys));\n+        assert!(ys.is_disjoint(&xs));\n+        assert!(xs.insert(7));\n+        assert!(xs.insert(19));\n+        assert!(xs.insert(4));\n+        assert!(ys.insert(2));\n+        assert!(ys.insert(-11));\n+        assert!(xs.is_disjoint(&ys));\n+        assert!(ys.is_disjoint(&xs));\n+        assert!(ys.insert(7));\n+        assert!(!xs.is_disjoint(&ys));\n+        assert!(!ys.is_disjoint(&xs));\n+    }\n+\n+    #[test]\n+    fn test_subset_and_superset() {\n+        let mut a = HashSet::new();\n+        assert!(a.insert(0i));\n+        assert!(a.insert(5));\n+        assert!(a.insert(11));\n+        assert!(a.insert(7));\n+\n+        let mut b = HashSet::new();\n+        assert!(b.insert(0i));\n+        assert!(b.insert(7));\n+        assert!(b.insert(19));\n+        assert!(b.insert(250));\n+        assert!(b.insert(11));\n+        assert!(b.insert(200));\n+\n+        assert!(!a.is_subset(&b));\n+        assert!(!a.is_superset(&b));\n+        assert!(!b.is_subset(&a));\n+        assert!(!b.is_superset(&a));\n+\n+        assert!(b.insert(5));\n+\n+        assert!(a.is_subset(&b));\n+        assert!(!a.is_superset(&b));\n+        assert!(!b.is_subset(&a));\n+        assert!(b.is_superset(&a));\n+    }\n+\n+    #[test]\n+    fn test_iterate() {\n+        let mut a = HashSet::new();\n+        for i in range(0u, 32) {\n+            assert!(a.insert(i));\n+        }\n+        let mut observed: u32 = 0;\n+        for k in a.iter() {\n+            observed |= 1 << *k;\n+        }\n+        assert_eq!(observed, 0xFFFF_FFFF);\n+    }\n+\n+    #[test]\n+    fn test_intersection() {\n+        let mut a = HashSet::new();\n+        let mut b = HashSet::new();\n+\n+        assert!(a.insert(11i));\n+        assert!(a.insert(1));\n+        assert!(a.insert(3));\n+        assert!(a.insert(77));\n+        assert!(a.insert(103));\n+        assert!(a.insert(5));\n+        assert!(a.insert(-5));\n+\n+        assert!(b.insert(2i));\n+        assert!(b.insert(11));\n+        assert!(b.insert(77));\n+        assert!(b.insert(-9));\n+        assert!(b.insert(-42));\n+        assert!(b.insert(5));\n+        assert!(b.insert(3));\n+\n+        let mut i = 0;\n+        let expected = [3, 5, 11, 77];\n+        for x in a.intersection(&b) {\n+            assert!(expected.contains(x));\n+            i += 1\n+        }\n+        assert_eq!(i, expected.len());\n+    }\n+\n+    #[test]\n+    fn test_difference() {\n+        let mut a = HashSet::new();\n+        let mut b = HashSet::new();\n+\n+        assert!(a.insert(1i));\n+        assert!(a.insert(3));\n+        assert!(a.insert(5));\n+        assert!(a.insert(9));\n+        assert!(a.insert(11));\n+\n+        assert!(b.insert(3i));\n+        assert!(b.insert(9));\n+\n+        let mut i = 0;\n+        let expected = [1, 5, 11];\n+        for x in a.difference(&b) {\n+            assert!(expected.contains(x));\n+            i += 1\n+        }\n+        assert_eq!(i, expected.len());\n+    }\n+\n+    #[test]\n+    fn test_symmetric_difference() {\n+        let mut a = HashSet::new();\n+        let mut b = HashSet::new();\n+\n+        assert!(a.insert(1i));\n+        assert!(a.insert(3));\n+        assert!(a.insert(5));\n+        assert!(a.insert(9));\n+        assert!(a.insert(11));\n+\n+        assert!(b.insert(-2i));\n+        assert!(b.insert(3));\n+        assert!(b.insert(9));\n+        assert!(b.insert(14));\n+        assert!(b.insert(22));\n+\n+        let mut i = 0;\n+        let expected = [-2, 1, 5, 11, 14, 22];\n+        for x in a.symmetric_difference(&b) {\n+            assert!(expected.contains(x));\n+            i += 1\n+        }\n+        assert_eq!(i, expected.len());\n+    }\n+\n+    #[test]\n+    fn test_union() {\n+        let mut a = HashSet::new();\n+        let mut b = HashSet::new();\n+\n+        assert!(a.insert(1i));\n+        assert!(a.insert(3));\n+        assert!(a.insert(5));\n+        assert!(a.insert(9));\n+        assert!(a.insert(11));\n+        assert!(a.insert(16));\n+        assert!(a.insert(19));\n+        assert!(a.insert(24));\n+\n+        assert!(b.insert(-2i));\n+        assert!(b.insert(1));\n+        assert!(b.insert(5));\n+        assert!(b.insert(9));\n+        assert!(b.insert(13));\n+        assert!(b.insert(19));\n+\n+        let mut i = 0;\n+        let expected = [-2, 1, 3, 5, 9, 11, 13, 16, 19, 24];\n+        for x in a.union(&b) {\n+            assert!(expected.contains(x));\n+            i += 1\n+        }\n+        assert_eq!(i, expected.len());\n+    }\n+\n+    #[test]\n+    fn test_from_iter() {\n+        let xs = [1i, 2, 3, 4, 5, 6, 7, 8, 9];\n+\n+        let set: HashSet<int> = xs.iter().map(|&x| x).collect();\n+\n+        for x in xs.iter() {\n+            assert!(set.contains(x));\n+        }\n+    }\n+\n+    #[test]\n+    fn test_move_iter() {\n+        let hs = {\n+            let mut hs = HashSet::new();\n+\n+            hs.insert('a');\n+            hs.insert('b');\n+\n+            hs\n+        };\n+\n+        let v = hs.move_iter().collect::<Vec<char>>();\n+        assert!(['a', 'b'] == v.as_slice() || ['b', 'a'] == v.as_slice());\n+    }\n+\n+    #[test]\n+    fn test_eq() {\n+        // These constants once happened to expose a bug in insert().\n+        // I'm keeping them around to prevent a regression.\n+        let mut s1 = HashSet::new();\n+\n+        s1.insert(1i);\n+        s1.insert(2);\n+        s1.insert(3);\n+\n+        let mut s2 = HashSet::new();\n+\n+        s2.insert(1i);\n+        s2.insert(2);\n+\n+        assert!(s1 != s2);\n+\n+        s2.insert(3);\n+\n+        assert_eq!(s1, s2);\n+    }\n+\n+    #[test]\n+    fn test_show() {\n+        let mut set: HashSet<int> = HashSet::new();\n+        let empty: HashSet<int> = HashSet::new();\n+\n+        set.insert(1i);\n+        set.insert(2);\n+\n+        let set_str = format!(\"{}\", set);\n+\n+        assert!(set_str == \"{1, 2}\".to_string() || set_str == \"{2, 1}\".to_string());\n+        assert_eq!(format!(\"{}\", empty), \"{}\".to_string());\n+    }\n+}"}, {"sha": "2edb8cd092e0c61e4107f0b17c3feb0ec59beb4c", "filename": "src/libstd/collections/hashmap/table.rs", "status": "added", "additions": 896, "deletions": 0, "changes": 896, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Ftable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Flibstd%2Fcollections%2Fhashmap%2Ftable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Ftable.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -0,0 +1,896 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+//\n+// ignore-lexer-test FIXME #15883\n+\n+use clone::Clone;\n+use cmp;\n+use hash::{Hash, Hasher};\n+use iter::{Iterator, count};\n+use kinds::marker;\n+use mem::{min_align_of, size_of};\n+use mem;\n+use num::{CheckedAdd, CheckedMul, is_power_of_two};\n+use ops::{Deref, DerefMut, Drop};\n+use option::{Some, None, Option};\n+use ptr::{RawPtr, copy_nonoverlapping_memory, zero_memory};\n+use ptr;\n+use rt::heap::{allocate, deallocate};\n+\n+static EMPTY_BUCKET: u64 = 0u64;\n+\n+/// The raw hashtable, providing safe-ish access to the unzipped and highly\n+/// optimized arrays of hashes, keys, and values.\n+///\n+/// This design uses less memory and is a lot faster than the naive\n+/// `Vec<Option<u64, K, V>>`, because we don't pay for the overhead of an\n+/// option on every element, and we get a generally more cache-aware design.\n+///\n+/// Essential invariants of this structure:\n+///\n+///   - if t.hashes[i] == EMPTY_BUCKET, then `Bucket::at_index(&t, i).raw`\n+///     points to 'undefined' contents. Don't read from it. This invariant is\n+///     enforced outside this module with the `EmptyBucket`, `FullBucket`,\n+///     and `SafeHash` types.\n+///\n+///   - An `EmptyBucket` is only constructed at an index with\n+///     a hash of EMPTY_BUCKET.\n+///\n+///   - A `FullBucket` is only constructed at an index with a\n+///     non-EMPTY_BUCKET hash.\n+///\n+///   - A `SafeHash` is only constructed for non-`EMPTY_BUCKET` hash. We get\n+///     around hashes of zero by changing them to 0x8000_0000_0000_0000,\n+///     which will likely map to the same bucket, while not being confused\n+///     with \"empty\".\n+///\n+///   - All three \"arrays represented by pointers\" are the same length:\n+///     `capacity`. This is set at creation and never changes. The arrays\n+///     are unzipped to save space (we don't have to pay for the padding\n+///     between odd sized elements, such as in a map from u64 to u8), and\n+///     be more cache aware (scanning through 8 hashes brings in at most\n+///     2 cache lines, since they're all right beside each other).\n+///\n+/// You can kind of think of this module/data structure as a safe wrapper\n+/// around just the \"table\" part of the hashtable. It enforces some\n+/// invariants at the type level and employs some performance trickery,\n+/// but in general is just a tricked out `Vec<Option<u64, K, V>>`.\n+#[unsafe_no_drop_flag]\n+pub struct RawTable<K, V> {\n+    capacity: uint,\n+    size:     uint,\n+    hashes:   *mut u64,\n+    // Because K/V do not appear directly in any of the types in the struct,\n+    // inform rustc that in fact instances of K and V are reachable from here.\n+    marker:   marker::CovariantType<(K,V)>,\n+}\n+\n+struct RawBucket<K, V> {\n+    hash: *mut u64,\n+    key:  *mut K,\n+    val:  *mut V\n+}\n+\n+pub struct Bucket<K, V, M> {\n+    raw:   RawBucket<K, V>,\n+    idx:   uint,\n+    table: M\n+}\n+\n+pub struct EmptyBucket<K, V, M> {\n+    raw:   RawBucket<K, V>,\n+    idx:   uint,\n+    table: M\n+}\n+\n+pub struct FullBucket<K, V, M> {\n+    raw:   RawBucket<K, V>,\n+    idx:   uint,\n+    table: M\n+}\n+\n+pub type EmptyBucketImm<'table, K, V> = EmptyBucket<K, V, &'table RawTable<K, V>>;\n+pub type  FullBucketImm<'table, K, V> =  FullBucket<K, V, &'table RawTable<K, V>>;\n+\n+pub type EmptyBucketMut<'table, K, V> = EmptyBucket<K, V, &'table mut RawTable<K, V>>;\n+pub type  FullBucketMut<'table, K, V> =  FullBucket<K, V, &'table mut RawTable<K, V>>;\n+\n+pub enum BucketState<K, V, M> {\n+    Empty(EmptyBucket<K, V, M>),\n+    Full(FullBucket<K, V, M>),\n+}\n+\n+// A GapThenFull encapsulates the state of two consecutive buckets at once.\n+// The first bucket, called the gap, is known to be empty.\n+// The second bucket is full.\n+struct GapThenFull<K, V, M> {\n+    gap: EmptyBucket<K, V, ()>,\n+    full: FullBucket<K, V, M>,\n+}\n+\n+/// A hash that is not zero, since we use a hash of zero to represent empty\n+/// buckets.\n+#[deriving(PartialEq)]\n+pub struct SafeHash {\n+    hash: u64,\n+}\n+\n+impl SafeHash {\n+    /// Peek at the hash value, which is guaranteed to be non-zero.\n+    #[inline(always)]\n+    pub fn inspect(&self) -> u64 { self.hash }\n+}\n+\n+/// We need to remove hashes of 0. That's reserved for empty buckets.\n+/// This function wraps up `hash_keyed` to be the only way outside this\n+/// module to generate a SafeHash.\n+pub fn make_hash<T: Hash<S>, S, H: Hasher<S>>(hasher: &H, t: &T) -> SafeHash {\n+    match hasher.hash(t) {\n+        // This constant is exceedingly likely to hash to the same\n+        // bucket, but it won't be counted as empty! Just so we can maintain\n+        // our precious uniform distribution of initial indexes.\n+        EMPTY_BUCKET => SafeHash { hash: 0x8000_0000_0000_0000 },\n+        h            => SafeHash { hash: h },\n+    }\n+}\n+\n+// `replace` casts a `*u64` to a `*SafeHash`. Since we statically\n+// ensure that a `FullBucket` points to an index with a non-zero hash,\n+// and a `SafeHash` is just a `u64` with a different name, this is\n+// safe.\n+//\n+// This test ensures that a `SafeHash` really IS the same size as a\n+// `u64`. If you need to change the size of `SafeHash` (and\n+// consequently made this test fail), `replace` needs to be\n+// modified to no longer assume this.\n+#[test]\n+fn can_alias_safehash_as_u64() {\n+    assert_eq!(size_of::<SafeHash>(), size_of::<u64>())\n+}\n+\n+impl<K, V> RawBucket<K, V> {\n+    unsafe fn offset(self, count: int) -> RawBucket<K, V> {\n+        RawBucket {\n+            hash: self.hash.offset(count),\n+            key:  self.key.offset(count),\n+            val:  self.val.offset(count),\n+        }\n+    }\n+}\n+\n+// For parameterizing over mutability.\n+impl<'t, K, V> Deref<RawTable<K, V>> for &'t RawTable<K, V> {\n+    fn deref(&self) -> &RawTable<K, V> {\n+        &**self\n+    }\n+}\n+\n+impl<'t, K, V> Deref<RawTable<K, V>> for &'t mut RawTable<K, V> {\n+    fn deref(&self) -> &RawTable<K,V> {\n+        &**self\n+    }\n+}\n+\n+impl<'t, K, V> DerefMut<RawTable<K, V>> for &'t mut RawTable<K, V> {\n+    fn deref_mut(&mut self) -> &mut RawTable<K,V> {\n+        &mut **self\n+    }\n+}\n+\n+// Buckets hold references to the table.\n+impl<K, V, M> FullBucket<K, V, M> {\n+    /// Borrow a reference to the table.\n+    pub fn table(&self) -> &M {\n+        &self.table\n+    }\n+    /// Move out the reference to the table.\n+    pub fn into_table(self) -> M {\n+        self.table\n+    }\n+    /// Get the raw index.\n+    pub fn index(&self) -> uint {\n+        self.idx\n+    }\n+}\n+\n+impl<K, V, M> EmptyBucket<K, V, M> {\n+    /// Borrow a reference to the table.\n+    pub fn table(&self) -> &M {\n+        &self.table\n+    }\n+    /// Move out the reference to the table.\n+    pub fn into_table(self) -> M {\n+        self.table\n+    }\n+}\n+\n+impl<K, V, M> Bucket<K, V, M> {\n+    /// Move out the reference to the table.\n+    pub fn into_table(self) -> M {\n+        self.table\n+    }\n+    /// Get the raw index.\n+    pub fn index(&self) -> uint {\n+        self.idx\n+    }\n+}\n+\n+impl<K, V, M: Deref<RawTable<K, V>>> Bucket<K, V, M> {\n+    pub fn new(table: M, hash: &SafeHash) -> Bucket<K, V, M> {\n+        Bucket::at_index(table, hash.inspect() as uint)\n+    }\n+\n+    pub fn at_index(table: M, ib_index: uint) -> Bucket<K, V, M> {\n+        let ib_index = ib_index & (table.capacity() - 1);\n+        Bucket {\n+            raw: unsafe {\n+               table.first_bucket_raw().offset(ib_index as int)\n+            },\n+            idx: ib_index,\n+            table: table\n+        }\n+    }\n+\n+    pub fn first(table: M) -> Bucket<K, V, M> {\n+        Bucket {\n+            raw: table.first_bucket_raw(),\n+            idx: 0,\n+            table: table\n+        }\n+    }\n+\n+    /// Reads a bucket at a given index, returning an enum indicating whether\n+    /// it's initialized or not. You need to match on this enum to get\n+    /// the appropriate types to call most of the other functions in\n+    /// this module.\n+    pub fn peek(self) -> BucketState<K, V, M> {\n+        match unsafe { *self.raw.hash } {\n+            EMPTY_BUCKET =>\n+                Empty(EmptyBucket {\n+                    raw: self.raw,\n+                    idx: self.idx,\n+                    table: self.table\n+                }),\n+            _ =>\n+                Full(FullBucket {\n+                    raw: self.raw,\n+                    idx: self.idx,\n+                    table: self.table\n+                })\n+        }\n+    }\n+\n+    /// Modifies the bucket pointer in place to make it point to the next slot.\n+    pub fn next(&mut self) {\n+        // Branchless bucket iteration step.\n+        // As we reach the end of the table...\n+        // We take the current idx:          0111111b\n+        // Xor it by its increment:        ^ 1000000b\n+        //                               ------------\n+        //                                   1111111b\n+        // Then AND with the capacity:     & 1000000b\n+        //                               ------------\n+        // to get the backwards offset:      1000000b\n+        // ... and it's zero at all other times.\n+        let maybe_wraparound_dist = (self.idx ^ (self.idx + 1)) & self.table.capacity();\n+        // Finally, we obtain the offset 1 or the offset -cap + 1.\n+        let dist = 1i - (maybe_wraparound_dist as int);\n+\n+        self.idx += 1;\n+\n+        unsafe {\n+            self.raw = self.raw.offset(dist);\n+        }\n+    }\n+}\n+\n+impl<K, V, M: Deref<RawTable<K, V>>> EmptyBucket<K, V, M> {\n+    #[inline]\n+    pub fn next(self) -> Bucket<K, V, M> {\n+        let mut bucket = self.into_bucket();\n+        bucket.next();\n+        bucket\n+    }\n+\n+    #[inline]\n+    pub fn into_bucket(self) -> Bucket<K, V, M> {\n+        Bucket {\n+            raw: self.raw,\n+            idx: self.idx,\n+            table: self.table\n+        }\n+    }\n+\n+    pub fn gap_peek(self) -> Option<GapThenFull<K, V, M>> {\n+        let gap = EmptyBucket {\n+            raw: self.raw,\n+            idx: self.idx,\n+            table: ()\n+        };\n+\n+        match self.next().peek() {\n+            Full(bucket) => {\n+                Some(GapThenFull {\n+                    gap: gap,\n+                    full: bucket\n+                })\n+            }\n+            Empty(..) => None\n+        }\n+    }\n+}\n+\n+impl<K, V, M: DerefMut<RawTable<K, V>>> EmptyBucket<K, V, M> {\n+    /// Puts given key and value pair, along with the key's hash,\n+    /// into this bucket in the hashtable. Note how `self` is 'moved' into\n+    /// this function, because this slot will no longer be empty when\n+    /// we return! A `FullBucket` is returned for later use, pointing to\n+    /// the newly-filled slot in the hashtable.\n+    ///\n+    /// Use `make_hash` to construct a `SafeHash` to pass to this function.\n+    pub fn put(mut self, hash: SafeHash, key: K, value: V)\n+               -> FullBucket<K, V, M> {\n+        unsafe {\n+            *self.raw.hash = hash.inspect();\n+            ptr::write(self.raw.key, key);\n+            ptr::write(self.raw.val, value);\n+        }\n+\n+        self.table.size += 1;\n+\n+        FullBucket { raw: self.raw, idx: self.idx, table: self.table }\n+    }\n+}\n+\n+impl<K, V, M: Deref<RawTable<K, V>>> FullBucket<K, V, M> {\n+    #[inline]\n+    pub fn next(self) -> Bucket<K, V, M> {\n+        let mut bucket = self.into_bucket();\n+        bucket.next();\n+        bucket\n+    }\n+\n+    #[inline]\n+    pub fn into_bucket(self) -> Bucket<K, V, M> {\n+        Bucket {\n+            raw: self.raw,\n+            idx: self.idx,\n+            table: self.table\n+        }\n+    }\n+\n+    /// Get the distance between this bucket and the 'ideal' location\n+    /// as determined by the key's hash stored in it.\n+    ///\n+    /// In the cited blog posts above, this is called the \"distance to\n+    /// initial bucket\", or DIB. Also known as \"probe count\".\n+    pub fn distance(&self) -> uint {\n+        // Calculates the distance one has to travel when going from\n+        // `hash mod capacity` onwards to `idx mod capacity`, wrapping around\n+        // if the destination is not reached before the end of the table.\n+        (self.idx - self.hash().inspect() as uint) & (self.table.capacity() - 1)\n+    }\n+\n+    #[inline]\n+    pub fn hash(&self) -> SafeHash {\n+        unsafe {\n+            SafeHash {\n+                hash: *self.raw.hash\n+            }\n+        }\n+    }\n+\n+    /// Gets references to the key and value at a given index.\n+    pub fn read(&self) -> (&K, &V) {\n+        unsafe {\n+            (&*self.raw.key,\n+             &*self.raw.val)\n+        }\n+    }\n+}\n+\n+impl<K, V, M: DerefMut<RawTable<K, V>>> FullBucket<K, V, M> {\n+    /// Removes this bucket's key and value from the hashtable.\n+    ///\n+    /// This works similarly to `put`, building an `EmptyBucket` out of the\n+    /// taken bucket.\n+    pub fn take(mut self) -> (EmptyBucket<K, V, M>, K, V) {\n+        let key = self.raw.key as *const K;\n+        let val = self.raw.val as *const V;\n+\n+        self.table.size -= 1;\n+\n+        unsafe {\n+            *self.raw.hash = EMPTY_BUCKET;\n+            (\n+                EmptyBucket {\n+                    raw: self.raw,\n+                    idx: self.idx,\n+                    table: self.table\n+                },\n+                ptr::read(key),\n+                ptr::read(val)\n+            )\n+        }\n+    }\n+\n+    pub fn replace(&mut self, h: SafeHash, k: K, v: V) -> (SafeHash, K, V) {\n+        unsafe {\n+            let old_hash = ptr::replace(self.raw.hash as *mut SafeHash, h);\n+            let old_key  = ptr::replace(self.raw.key,  k);\n+            let old_val  = ptr::replace(self.raw.val,  v);\n+\n+            (old_hash, old_key, old_val)\n+        }\n+    }\n+\n+    /// Gets mutable references to the key and value at a given index.\n+    pub fn read_mut(&mut self) -> (&mut K, &mut V) {\n+        unsafe {\n+            (&mut *self.raw.key,\n+             &mut *self.raw.val)\n+        }\n+    }\n+}\n+\n+impl<'t, K, V, M: Deref<RawTable<K, V>> + 't> FullBucket<K, V, M> {\n+    /// Exchange a bucket state for immutable references into the table.\n+    /// Because the underlying reference to the table is also consumed,\n+    /// no further changes to the structure of the table are possible;\n+    /// in exchange for this, the returned references have a longer lifetime\n+    /// than the references returned by `read()`.\n+    pub fn into_refs(self) -> (&'t K, &'t V) {\n+        unsafe {\n+            (&*self.raw.key,\n+             &*self.raw.val)\n+        }\n+    }\n+}\n+\n+impl<'t, K, V, M: DerefMut<RawTable<K, V>> + 't> FullBucket<K, V, M> {\n+    /// This works similarly to `into_refs`, exchanging a bucket state\n+    /// for mutable references into the table.\n+    pub fn into_mut_refs(self) -> (&'t mut K, &'t mut V) {\n+        unsafe {\n+            (&mut *self.raw.key,\n+             &mut *self.raw.val)\n+        }\n+    }\n+}\n+\n+impl<K, V, M> BucketState<K, V, M> {\n+    // For convenience.\n+    pub fn expect_full(self) -> FullBucket<K, V, M> {\n+        match self {\n+            Full(full) => full,\n+            Empty(..) => fail!(\"Expected full bucket\")\n+        }\n+    }\n+}\n+\n+impl<K, V, M: Deref<RawTable<K, V>>> GapThenFull<K, V, M> {\n+    #[inline]\n+    pub fn full(&self) -> &FullBucket<K, V, M> {\n+        &self.full\n+    }\n+\n+    pub fn shift(mut self) -> Option<GapThenFull<K, V, M>> {\n+        unsafe {\n+            *self.gap.raw.hash = mem::replace(&mut *self.full.raw.hash, EMPTY_BUCKET);\n+            copy_nonoverlapping_memory(self.gap.raw.key, self.full.raw.key as *const K, 1);\n+            copy_nonoverlapping_memory(self.gap.raw.val, self.full.raw.val as *const V, 1);\n+        }\n+\n+        let FullBucket { raw: prev_raw, idx: prev_idx, .. } = self.full;\n+\n+        match self.full.next().peek() {\n+            Full(bucket) => {\n+                self.gap.raw = prev_raw;\n+                self.gap.idx = prev_idx;\n+\n+                self.full = bucket;\n+\n+                Some(self)\n+            }\n+            Empty(..) => None\n+        }\n+    }\n+}\n+\n+\n+/// Rounds up to a multiple of a power of two. Returns the closest multiple\n+/// of `target_alignment` that is higher or equal to `unrounded`.\n+///\n+/// # Failure\n+///\n+/// Fails if `target_alignment` is not a power of two.\n+fn round_up_to_next(unrounded: uint, target_alignment: uint) -> uint {\n+    assert!(is_power_of_two(target_alignment));\n+    (unrounded + target_alignment - 1) & !(target_alignment - 1)\n+}\n+\n+#[test]\n+fn test_rounding() {\n+    assert_eq!(round_up_to_next(0, 4), 0);\n+    assert_eq!(round_up_to_next(1, 4), 4);\n+    assert_eq!(round_up_to_next(2, 4), 4);\n+    assert_eq!(round_up_to_next(3, 4), 4);\n+    assert_eq!(round_up_to_next(4, 4), 4);\n+    assert_eq!(round_up_to_next(5, 4), 8);\n+}\n+\n+// Returns a tuple of (key_offset, val_offset),\n+// from the start of a mallocated array.\n+fn calculate_offsets(hashes_size: uint,\n+                     keys_size: uint, keys_align: uint,\n+                     vals_align: uint)\n+                     -> (uint, uint) {\n+    let keys_offset = round_up_to_next(hashes_size, keys_align);\n+    let end_of_keys = keys_offset + keys_size;\n+\n+    let vals_offset = round_up_to_next(end_of_keys, vals_align);\n+\n+    (keys_offset, vals_offset)\n+}\n+\n+// Returns a tuple of (minimum required malloc alignment, hash_offset,\n+// array_size), from the start of a mallocated array.\n+fn calculate_allocation(hash_size: uint, hash_align: uint,\n+                        keys_size: uint, keys_align: uint,\n+                        vals_size: uint, vals_align: uint)\n+                        -> (uint, uint, uint) {\n+    let hash_offset = 0;\n+    let (_, vals_offset) = calculate_offsets(hash_size,\n+                                             keys_size, keys_align,\n+                                                        vals_align);\n+    let end_of_vals = vals_offset + vals_size;\n+\n+    let min_align = cmp::max(hash_align, cmp::max(keys_align, vals_align));\n+\n+    (min_align, hash_offset, end_of_vals)\n+}\n+\n+#[test]\n+fn test_offset_calculation() {\n+    assert_eq!(calculate_allocation(128, 8, 15, 1, 4,  4), (8, 0, 148));\n+    assert_eq!(calculate_allocation(3,   1, 2,  1, 1,  1), (1, 0, 6));\n+    assert_eq!(calculate_allocation(6,   2, 12, 4, 24, 8), (8, 0, 48));\n+    assert_eq!(calculate_offsets(128, 15, 1, 4), (128, 144));\n+    assert_eq!(calculate_offsets(3,   2,  1, 1), (3,   5));\n+    assert_eq!(calculate_offsets(6,   12, 4, 8), (8,   24));\n+}\n+\n+impl<K, V> RawTable<K, V> {\n+    /// Does not initialize the buckets. The caller should ensure they,\n+    /// at the very least, set every hash to EMPTY_BUCKET.\n+    unsafe fn new_uninitialized(capacity: uint) -> RawTable<K, V> {\n+        if capacity == 0 {\n+            return RawTable {\n+                size: 0,\n+                capacity: 0,\n+                hashes: 0 as *mut u64,\n+                marker: marker::CovariantType,\n+            };\n+        }\n+        // No need for `checked_mul` before a more restrictive check performed\n+        // later in this method.\n+        let hashes_size = capacity * size_of::<u64>();\n+        let keys_size   = capacity * size_of::< K >();\n+        let vals_size   = capacity * size_of::< V >();\n+\n+        // Allocating hashmaps is a little tricky. We need to allocate three\n+        // arrays, but since we know their sizes and alignments up front,\n+        // we just allocate a single array, and then have the subarrays\n+        // point into it.\n+        //\n+        // This is great in theory, but in practice getting the alignment\n+        // right is a little subtle. Therefore, calculating offsets has been\n+        // factored out into a different function.\n+        let (malloc_alignment, hash_offset, size) =\n+            calculate_allocation(\n+                hashes_size, min_align_of::<u64>(),\n+                keys_size,   min_align_of::< K >(),\n+                vals_size,   min_align_of::< V >());\n+\n+        // One check for overflow that covers calculation and rounding of size.\n+        let size_of_bucket = size_of::<u64>().checked_add(&size_of::<K>()).unwrap()\n+                                             .checked_add(&size_of::<V>()).unwrap();\n+        assert!(size >= capacity.checked_mul(&size_of_bucket)\n+                                .expect(\"capacity overflow\"),\n+                \"capacity overflow\");\n+\n+        let buffer = allocate(size, malloc_alignment);\n+\n+        let hashes = buffer.offset(hash_offset as int) as *mut u64;\n+\n+        RawTable {\n+            capacity: capacity,\n+            size:     0,\n+            hashes:   hashes,\n+            marker:   marker::CovariantType,\n+        }\n+    }\n+\n+    fn first_bucket_raw(&self) -> RawBucket<K, V> {\n+        let hashes_size = self.capacity * size_of::<u64>();\n+        let keys_size = self.capacity * size_of::<K>();\n+\n+        let buffer = self.hashes as *mut u8;\n+        let (keys_offset, vals_offset) = calculate_offsets(hashes_size,\n+                                                           keys_size, min_align_of::<K>(),\n+                                                           min_align_of::<V>());\n+\n+        unsafe {\n+            RawBucket {\n+                hash: self.hashes,\n+                key:  buffer.offset(keys_offset as int) as *mut K,\n+                val:  buffer.offset(vals_offset as int) as *mut V\n+            }\n+        }\n+    }\n+\n+    /// Creates a new raw table from a given capacity. All buckets are\n+    /// initially empty.\n+    #[allow(experimental)]\n+    pub fn new(capacity: uint) -> RawTable<K, V> {\n+        unsafe {\n+            let ret = RawTable::new_uninitialized(capacity);\n+            zero_memory(ret.hashes, capacity);\n+            ret\n+        }\n+    }\n+\n+    /// The hashtable's capacity, similar to a vector's.\n+    pub fn capacity(&self) -> uint {\n+        self.capacity\n+    }\n+\n+    /// The number of elements ever `put` in the hashtable, minus the number\n+    /// of elements ever `take`n.\n+    pub fn size(&self) -> uint {\n+        self.size\n+    }\n+\n+    fn raw_buckets(&self) -> RawBuckets<K, V> {\n+        RawBuckets {\n+            raw: self.first_bucket_raw(),\n+            hashes_end: unsafe {\n+                self.hashes.offset(self.capacity as int)\n+            }\n+        }\n+    }\n+\n+    pub fn iter(&self) -> Entries<K, V> {\n+        Entries {\n+            iter: self.raw_buckets(),\n+            elems_left: self.size(),\n+        }\n+    }\n+\n+    pub fn mut_iter(&mut self) -> MutEntries<K, V> {\n+        MutEntries {\n+            iter: self.raw_buckets(),\n+            elems_left: self.size(),\n+        }\n+    }\n+\n+    pub fn move_iter(self) -> MoveEntries<K, V> {\n+        MoveEntries {\n+            iter: self.raw_buckets(),\n+            table: self,\n+        }\n+    }\n+\n+    /// Returns an iterator that copies out each entry. Used while the table\n+    /// is being dropped.\n+    unsafe fn rev_move_buckets(&mut self) -> RevMoveBuckets<K, V> {\n+        let raw_bucket = self.first_bucket_raw();\n+        RevMoveBuckets {\n+            raw: raw_bucket.offset(self.capacity as int),\n+            hashes_end: raw_bucket.hash,\n+            elems_left: self.size\n+        }\n+    }\n+}\n+\n+/// A raw iterator. The basis for some other iterators in this module. Although\n+/// this interface is safe, it's not used outside this module.\n+struct RawBuckets<'a, K, V> {\n+    raw: RawBucket<K, V>,\n+    hashes_end: *mut u64\n+}\n+\n+impl<'a, K, V> Iterator<RawBucket<K, V>> for RawBuckets<'a, K, V> {\n+    fn next(&mut self) -> Option<RawBucket<K, V>> {\n+        while self.raw.hash != self.hashes_end {\n+            unsafe {\n+                // We are swapping out the pointer to a bucket and replacing\n+                // it with the pointer to the next one.\n+                let prev = ptr::replace(&mut self.raw, self.raw.offset(1));\n+                if *prev.hash != EMPTY_BUCKET {\n+                    return Some(prev);\n+                }\n+            }\n+        }\n+\n+        None\n+    }\n+}\n+\n+/// An iterator that moves out buckets in reverse order. It leaves the table\n+/// in an an inconsistent state and should only be used for dropping\n+/// the table's remaining entries. It's used in the implementation of Drop.\n+struct RevMoveBuckets<'a, K, V> {\n+    raw: RawBucket<K, V>,\n+    hashes_end: *mut u64,\n+    elems_left: uint\n+}\n+\n+impl<'a, K, V> Iterator<(K, V)> for RevMoveBuckets<'a, K, V> {\n+    fn next(&mut self) -> Option<(K, V)> {\n+        if self.elems_left == 0 {\n+            return None;\n+        }\n+\n+        loop {\n+            debug_assert!(self.raw.hash != self.hashes_end);\n+\n+            unsafe {\n+                self.raw = self.raw.offset(-1);\n+\n+                if *self.raw.hash != EMPTY_BUCKET {\n+                    self.elems_left -= 1;\n+                    return Some((\n+                        ptr::read(self.raw.key as *const K),\n+                        ptr::read(self.raw.val as *const V)\n+                    ));\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Iterator over shared references to entries in a table.\n+pub struct Entries<'a, K: 'a, V: 'a> {\n+    iter: RawBuckets<'a, K, V>,\n+    elems_left: uint,\n+}\n+\n+/// Iterator over mutable references to entries in a table.\n+pub struct MutEntries<'a, K: 'a, V: 'a> {\n+    iter: RawBuckets<'a, K, V>,\n+    elems_left: uint,\n+}\n+\n+/// Iterator over the entries in a table, consuming the table.\n+pub struct MoveEntries<K, V> {\n+    table: RawTable<K, V>,\n+    iter: RawBuckets<'static, K, V>\n+}\n+\n+impl<'a, K, V> Iterator<(&'a K, &'a V)> for Entries<'a, K, V> {\n+    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n+        self.iter.next().map(|bucket| {\n+            self.elems_left -= 1;\n+            unsafe {\n+                (&*bucket.key,\n+                 &*bucket.val)\n+            }\n+        })\n+    }\n+\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        (self.elems_left, Some(self.elems_left))\n+    }\n+}\n+\n+impl<'a, K, V> Iterator<(&'a K, &'a mut V)> for MutEntries<'a, K, V> {\n+    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n+        self.iter.next().map(|bucket| {\n+            self.elems_left -= 1;\n+            unsafe {\n+                (&*bucket.key,\n+                 &mut *bucket.val)\n+            }\n+        })\n+    }\n+\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        (self.elems_left, Some(self.elems_left))\n+    }\n+}\n+\n+impl<K, V> Iterator<(SafeHash, K, V)> for MoveEntries<K, V> {\n+    fn next(&mut self) -> Option<(SafeHash, K, V)> {\n+        self.iter.next().map(|bucket| {\n+            self.table.size -= 1;\n+            unsafe {\n+                (\n+                    SafeHash {\n+                        hash: *bucket.hash,\n+                    },\n+                    ptr::read(bucket.key as *const K),\n+                    ptr::read(bucket.val as *const V)\n+                )\n+            }\n+        })\n+    }\n+\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        let size = self.table.size();\n+        (size, Some(size))\n+    }\n+}\n+\n+impl<K: Clone, V: Clone> Clone for RawTable<K, V> {\n+    fn clone(&self) -> RawTable<K, V> {\n+        unsafe {\n+            let mut new_ht = RawTable::new_uninitialized(self.capacity());\n+\n+            {\n+                let cap = self.capacity();\n+                let mut new_buckets = Bucket::first(&mut new_ht);\n+                let mut buckets = Bucket::first(self);\n+                while buckets.index() != cap {\n+                    match buckets.peek() {\n+                        Full(full) => {\n+                            let (h, k, v) = {\n+                                let (k, v) = full.read();\n+                                (full.hash(), k.clone(), v.clone())\n+                            };\n+                            *new_buckets.raw.hash = h.inspect();\n+                            mem::overwrite(new_buckets.raw.key, k);\n+                            mem::overwrite(new_buckets.raw.val, v);\n+                        }\n+                        Empty(..) => {\n+                            *new_buckets.raw.hash = EMPTY_BUCKET;\n+                        }\n+                    }\n+                    new_buckets.next();\n+                    buckets.next();\n+                }\n+            };\n+\n+            new_ht.size = self.size();\n+\n+            new_ht\n+        }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<K, V> Drop for RawTable<K, V> {\n+    fn drop(&mut self) {\n+        if self.hashes.is_null() {\n+            return;\n+        }\n+        // This is done in reverse because we've likely partially taken\n+        // some elements out with `.move_iter()` from the front.\n+        // Check if the size is 0, so we don't do a useless scan when\n+        // dropping empty tables such as on resize.\n+        // Also avoid double drop of elements that have been already moved out.\n+        unsafe {\n+            for _ in self.rev_move_buckets() {}\n+        }\n+\n+        let hashes_size = self.capacity * size_of::<u64>();\n+        let keys_size = self.capacity * size_of::<K>();\n+        let vals_size = self.capacity * size_of::<V>();\n+        let (align, _, size) = calculate_allocation(hashes_size, min_align_of::<u64>(),\n+                                                    keys_size, min_align_of::<K>(),\n+                                                    vals_size, min_align_of::<V>());\n+\n+        unsafe {\n+            deallocate(self.hashes as *mut u8, size, align);\n+            // Remember how everything was allocated out of one buffer\n+            // during initialization? We only need one call to free here.\n+        }\n+    }\n+}"}, {"sha": "f68b511d0aa0ddc7b9df6ed23ecea27dcf5cfa33", "filename": "src/test/run-fail/hashmap-capacity-overflow.rs", "status": "added", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/82c052794d4234752f0154c150d0b40779240db4/src%2Ftest%2Frun-fail%2Fhashmap-capacity-overflow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82c052794d4234752f0154c150d0b40779240db4/src%2Ftest%2Frun-fail%2Fhashmap-capacity-overflow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-fail%2Fhashmap-capacity-overflow.rs?ref=82c052794d4234752f0154c150d0b40779240db4", "patch": "@@ -0,0 +1,21 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// error-pattern:capacity overflow\n+\n+use std::collections::hashmap::HashMap;\n+use std::uint;\n+use std::mem::size_of;\n+\n+fn main() {\n+    let threshold = uint::MAX / size_of::<(u64, u64, u64)>();\n+    let mut h = HashMap::<u64, u64>::with_capacity(threshold + 100);\n+    h.insert(0, 0);\n+}"}]}