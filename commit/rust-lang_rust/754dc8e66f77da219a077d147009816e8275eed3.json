{"sha": "754dc8e66f77da219a077d147009816e8275eed3", "node_id": "C_kwDOAAsO6NoAKDc1NGRjOGU2NmY3N2RhMjE5YTA3N2QxNDcwMDk4MTZlODI3NWVlZDM", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-18T22:53:41Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-20T23:09:24Z"}, "message": "Move items into `TtParser` as `Vec`s.\n\nBy putting them in `TtParser`, we can reuse them for every rule in a\nmacro. With that done, they can be `SmallVec` instead of `Vec`, and this\nis a performance win because these vectors are hot and `SmallVec`\noperations are a bit slower due to always needing an \"inline or heap?\"\ncheck.", "tree": {"sha": "386116921add72627099af690558458eeefe4026", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/386116921add72627099af690558458eeefe4026"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/754dc8e66f77da219a077d147009816e8275eed3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/754dc8e66f77da219a077d147009816e8275eed3", "html_url": "https://github.com/rust-lang/rust/commit/754dc8e66f77da219a077d147009816e8275eed3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/754dc8e66f77da219a077d147009816e8275eed3/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "cedb787f6e92fb079be75a9f2c00a808195543a9", "url": "https://api.github.com/repos/rust-lang/rust/commits/cedb787f6e92fb079be75a9f2c00a808195543a9", "html_url": "https://github.com/rust-lang/rust/commit/cedb787f6e92fb079be75a9f2c00a808195543a9"}], "stats": {"total": 101, "additions": 43, "deletions": 58}, "files": [{"sha": "674cf8554f20aa3896180f4397380747b8509a2f", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 41, "deletions": 56, "changes": 97, "blob_url": "https://github.com/rust-lang/rust/blob/754dc8e66f77da219a077d147009816e8275eed3/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/754dc8e66f77da219a077d147009816e8275eed3/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=754dc8e66f77da219a077d147009816e8275eed3", "patch": "@@ -428,17 +428,26 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n     }\n }\n \n-pub struct TtParser {\n+// Note: the item vectors could be created and dropped within `parse_tt`, but to avoid excess\n+// allocations we have a single vector fo each kind that is cleared and reused repeatedly.\n+pub struct TtParser<'tt> {\n     macro_name: Ident,\n \n+    /// The set of current items to be processed. This should be empty by the end of a successful\n+    /// execution of `parse_tt_inner`.\n     cur_items: Vec<Box<MatcherPos<'tt>>>,\n+\n+    /// The set of newly generated items. These are used to replenish `cur_items` in the function\n+    /// `parse_tt`.\n     next_items: Vec<Box<MatcherPos<'tt>>>,\n+\n+    /// The set of items that are waiting for the black-box parser.\n     bb_items: Vec<Box<MatcherPos<'tt>>>,\n }\n \n-impl TtParser {\n+impl<'tt> TtParser<'tt> {\n     pub(super) fn new(macro_name: Ident) -> Self {\n-        Self { macro_name }\n+        Self { macro_name, cur_items: vec![], next_items: vec![], bb_items: vec![] }\n     }\n \n     /// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n@@ -447,33 +456,21 @@ impl TtParser {\n     /// For more info about the how this happens, see the module-level doc comments and the inline\n     /// comments of this function.\n     ///\n-    /// # Parameters\n-    ///\n-    /// - `cur_items`: the set of current items to be processed. This should be empty by the end of\n-    ///   a successful execution of this function.\n-    /// - `next_items`: the set of newly generated items. These are used to replenish `cur_items` in\n-    ///   the function `parse`.\n-    /// - `bb_items`: the set of items that are waiting for the black-box parser.\n-    /// - `token`: the current token of the parser.\n-    ///\n     /// # Returns\n     ///\n     /// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept\n     /// track of through the items generated.\n-    fn parse_tt_inner<'tt>(\n-        &self,\n+    fn parse_tt_inner(\n+        &mut self,\n         sess: &ParseSess,\n         ms: &[TokenTree],\n-        cur_items: &mut SmallVec<[Box<MatcherPos<'tt>>; 1]>,\n-        next_items: &mut SmallVec<[Box<MatcherPos<'tt>>; 1]>,\n-        bb_items: &mut SmallVec<[Box<MatcherPos<'tt>>; 1]>,\n         token: &Token,\n     ) -> Option<NamedParseResult> {\n         // Matcher positions that would be valid if the macro invocation was over now. Only\n         // modified if `token == Eof`.\n         let mut eof_items = EofItems::None;\n \n-        while let Some(mut item) = cur_items.pop() {\n+        while let Some(mut item) = self.cur_items.pop() {\n             // When unzipped trees end, remove them. This corresponds to backtracking out of a\n             // delimited submatcher into which we already descended. When backtracking out again, we\n             // need to advance the \"dot\" past the delimiters in the outer matcher.\n@@ -506,11 +503,11 @@ impl TtParser {\n                             for idx in item.match_cur..item.match_cur + seq.num_captures {\n                                 new_item.push_match(idx, MatchedSeq(Lrc::new(smallvec![])));\n                             }\n-                            cur_items.push(new_item);\n+                            self.cur_items.push(new_item);\n                         }\n \n                         // Allow for the possibility of one or more matches of this sequence.\n-                        cur_items.push(box MatcherPos::repetition(item, sp, seq));\n+                        self.cur_items.push(box MatcherPos::repetition(item, sp, seq));\n                     }\n \n                     TokenTree::MetaVarDecl(span, _, None) => {\n@@ -527,7 +524,7 @@ impl TtParser {\n                         // We use the span of the metavariable declaration to determine any\n                         // edition-specific matching behavior for non-terminals.\n                         if Parser::nonterminal_may_begin_with(kind, token) {\n-                            bb_items.push(item);\n+                            self.bb_items.push(item);\n                         }\n                     }\n \n@@ -541,7 +538,7 @@ impl TtParser {\n                         let idx = item.idx;\n                         item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n                         item.idx = 0;\n-                        cur_items.push(item);\n+                        self.cur_items.push(item);\n                     }\n \n                     TokenTree::Token(t) => {\n@@ -553,7 +550,7 @@ impl TtParser {\n                         // `cur_items` will match.\n                         if token_name_eq(&t, token) {\n                             item.idx += 1;\n-                            next_items.push(item);\n+                            self.next_items.push(item);\n                         }\n                     }\n \n@@ -576,23 +573,23 @@ impl TtParser {\n                     }\n                     new_pos.match_cur = item.match_hi;\n                     new_pos.idx += 1;\n-                    cur_items.push(new_pos);\n+                    self.cur_items.push(new_pos);\n                 }\n \n                 if idx == len && repetition.sep.is_some() {\n                     if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n                         // The matcher has a separator, and it matches the current token. We can\n                         // advance past the separator token.\n                         item.idx += 1;\n-                        next_items.push(item);\n+                        self.next_items.push(item);\n                     }\n                 } else if repetition.seq_op != mbe::KleeneOp::ZeroOrOne {\n                     // We don't need a separator. Move the \"dot\" back to the beginning of the\n                     // matcher and try to match again UNLESS we are only allowed to have _one_\n                     // repetition.\n                     item.match_cur = item.match_lo;\n                     item.idx = 0;\n-                    cur_items.push(item);\n+                    self.cur_items.push(item);\n                 }\n             } else {\n                 // We are past the end of the matcher, and not in a repetition. Look for end of\n@@ -635,41 +632,33 @@ impl TtParser {\n     /// Use the given slice of token trees (`ms`) as a matcher. Match the token stream from the\n     /// given `parser` against it and return the match.\n     pub(super) fn parse_tt(\n-        &self,\n+        &mut self,\n         parser: &mut Cow<'_, Parser<'_>>,\n-        ms: &[TokenTree],\n+        ms: &'tt [TokenTree],\n     ) -> NamedParseResult {\n         // A queue of possible matcher positions. We initialize it with the matcher position in\n         // which the \"dot\" is before the first token of the first token tree in `ms`.\n         // `parse_tt_inner` then processes all of these possible matcher positions and produces\n         // possible next positions into `next_items`. After some post-processing, the contents of\n         // `next_items` replenish `cur_items` and we start over again.\n-        let mut cur_items = smallvec![box MatcherPos::new(ms)];\n+        self.cur_items.clear();\n+        self.cur_items.push(box MatcherPos::new(ms));\n \n         loop {\n-            let mut next_items = SmallVec::new();\n-\n-            // Matcher positions black-box parsed by `Parser`.\n-            let mut bb_items = SmallVec::new();\n+            self.next_items.clear();\n+            self.bb_items.clear();\n \n             // Process `cur_items` until either we have finished the input or we need to get some\n             // parsing from the black-box parser done.\n-            if let Some(result) = self.parse_tt_inner(\n-                parser.sess,\n-                ms,\n-                &mut cur_items,\n-                &mut next_items,\n-                &mut bb_items,\n-                &parser.token,\n-            ) {\n+            if let Some(result) = self.parse_tt_inner(parser.sess, ms, &parser.token) {\n                 return result;\n             }\n \n             // `parse_tt_inner` handled all cur_items, so it's empty.\n-            assert!(cur_items.is_empty());\n+            assert!(self.cur_items.is_empty());\n \n             // Error messages here could be improved with links to original rules.\n-            match (next_items.len(), bb_items.len()) {\n+            match (self.next_items.len(), self.bb_items.len()) {\n                 (0, 0) => {\n                     // There are no possible next positions AND we aren't waiting for the black-box\n                     // parser: syntax error.\n@@ -682,13 +671,13 @@ impl TtParser {\n                 (_, 0) => {\n                     // Dump all possible `next_items` into `cur_items` for the next iteration. Then\n                     // process the next token.\n-                    cur_items.extend(next_items.drain(..));\n+                    self.cur_items.extend(self.next_items.drain(..));\n                     parser.to_mut().bump();\n                 }\n \n                 (0, 1) => {\n                     // We need to call the black-box parser to get some nonterminal.\n-                    let mut item = bb_items.pop().unwrap();\n+                    let mut item = self.bb_items.pop().unwrap();\n                     if let TokenTree::MetaVarDecl(span, _, Some(kind)) =\n                         item.top_elts.get_tt(item.idx)\n                     {\n@@ -714,26 +703,22 @@ impl TtParser {\n                     } else {\n                         unreachable!()\n                     }\n-                    cur_items.push(item);\n+                    self.cur_items.push(item);\n                 }\n \n                 (_, _) => {\n                     // Too many possibilities!\n-                    return self.ambiguity_error(next_items, bb_items, parser.token.span);\n+                    return self.ambiguity_error(parser.token.span);\n                 }\n             }\n \n-            assert!(!cur_items.is_empty());\n+            assert!(!self.cur_items.is_empty());\n         }\n     }\n \n-    fn ambiguity_error<'tt>(\n-        &self,\n-        next_items: SmallVec<[Box<MatcherPos<'tt>>; 1]>,\n-        bb_items: SmallVec<[Box<MatcherPos<'tt>>; 1]>,\n-        token_span: rustc_span::Span,\n-    ) -> NamedParseResult {\n-        let nts = bb_items\n+    fn ambiguity_error(&self, token_span: rustc_span::Span) -> NamedParseResult {\n+        let nts = self\n+            .bb_items\n             .iter()\n             .map(|item| match item.top_elts.get_tt(item.idx) {\n                 TokenTree::MetaVarDecl(_, bind, Some(kind)) => {\n@@ -749,7 +734,7 @@ impl TtParser {\n             format!(\n                 \"local ambiguity when calling macro `{}`: multiple parsing options: {}\",\n                 self.macro_name,\n-                match next_items.len() {\n+                match self.next_items.len() {\n                     0 => format!(\"built-in NTs {}.\", nts),\n                     1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n                     n => format!(\"built-in NTs {} or {} other options.\", nts, n),"}, {"sha": "db4d55256b6c0ff6771ee435952d101d743562a7", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/754dc8e66f77da219a077d147009816e8275eed3/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/754dc8e66f77da219a077d147009816e8275eed3/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=754dc8e66f77da219a077d147009816e8275eed3", "patch": "@@ -245,7 +245,7 @@ fn generic_extension<'cx>(\n     // this situation.)\n     let parser = parser_from_cx(sess, arg.clone());\n \n-    let tt_parser = TtParser::new(name);\n+    let mut tt_parser = TtParser::new(name);\n     for (i, lhs) in lhses.iter().enumerate() {\n         // try each arm's matchers\n         let lhs_tt = match *lhs {\n@@ -447,7 +447,7 @@ pub fn compile_declarative_macro(\n     ];\n \n     let parser = Parser::new(&sess.parse_sess, body, true, rustc_parse::MACRO_ARGUMENTS);\n-    let tt_parser = TtParser::new(def.ident);\n+    let mut tt_parser = TtParser::new(def.ident);\n     let argument_map = match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), &argument_gram) {\n         Success(m) => m,\n         Failure(token, msg) => {"}]}