{"sha": "52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "node_id": "C_kwDOAAsO6NoAKDUyYTZhYzk2YjBhMmEyNzA0MDBkNzViYTllZDNhYTgyOTgyNmI1ZGI", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-07-18T11:55:11Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-07-18T11:55:11Z"}, "message": "move atomic intrinsics to their own file", "tree": {"sha": "b643a37bed13877d4cf56174460c80b32f092206", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b643a37bed13877d4cf56174460c80b32f092206"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "html_url": "https://github.com/rust-lang/rust/commit/52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5a4d71faad15cc62407c4d3134337978f4a482f2", "url": "https://api.github.com/repos/rust-lang/rust/commits/5a4d71faad15cc62407c4d3134337978f4a482f2", "html_url": "https://github.com/rust-lang/rust/commit/5a4d71faad15cc62407c4d3134337978f4a482f2"}], "stats": {"total": 921, "additions": 473, "deletions": 448}, "files": [{"sha": "362bcc35eade2c6e252a1c71d6ecc420dcb209e8", "filename": "rust-version", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/rust-version", "raw_url": "https://github.com/rust-lang/rust/raw/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/rust-version", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/rust-version?ref=52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "patch": "@@ -1 +1 @@\n-db41351753df840773ca628d8daa040e95d00eef\n+880416180b0a9ee1141c07d4d17667edb77daebd"}, {"sha": "80281d37de9a55b7ba2f3988ded1dc56c8b7d9e2", "filename": "src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "patch": "@@ -62,6 +62,7 @@ pub use rustc_const_eval::interpret::{self, AllocMap, PlaceTy};\n pub use crate::shims::dlsym::{Dlsym, EvalContextExt as _};\n pub use crate::shims::env::{EnvVars, EvalContextExt as _};\n pub use crate::shims::foreign_items::EvalContextExt as _;\n+pub use crate::shims::intrinsics::atomic::EvalContextExt as _;\n pub use crate::shims::intrinsics::EvalContextExt as _;\n pub use crate::shims::os_str::EvalContextExt as _;\n pub use crate::shims::panic::{CatchUnwindData, EvalContextExt as _};"}, {"sha": "2ba591127cea49192283825b60c2dc259b220fa4", "filename": "src/shims/intrinsics/atomic.rs", "status": "added", "additions": 437, "deletions": 0, "changes": 437, "blob_url": "https://github.com/rust-lang/rust/blob/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/src%2Fshims%2Fintrinsics%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/src%2Fshims%2Fintrinsics%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fintrinsics%2Fatomic.rs?ref=52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "patch": "@@ -0,0 +1,437 @@\n+use rustc_middle::{mir, mir::BinOp};\n+use rustc_target::abi::Align;\n+\n+use crate::*;\n+use helpers::check_arg_count;\n+\n+pub enum AtomicOp {\n+    MirOp(mir::BinOp, bool),\n+    Max,\n+    Min,\n+}\n+\n+impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n+pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n+    /// Calls the atomic intrinsic `intrinsic`; the `atomic_` prefix has already been removed.\n+    fn emulate_atomic_intrinsic(\n+        &mut self,\n+        intrinsic_name: &str,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        match intrinsic_name {\n+            // Atomic operations\n+            \"load_seqcst\" => this.atomic_load(args, dest, AtomicReadOrd::SeqCst)?,\n+            \"load_relaxed\" => this.atomic_load(args, dest, AtomicReadOrd::Relaxed)?,\n+            \"load_acquire\" => this.atomic_load(args, dest, AtomicReadOrd::Acquire)?,\n+\n+            \"store_seqcst\" => this.atomic_store(args, AtomicWriteOrd::SeqCst)?,\n+            \"store_relaxed\" => this.atomic_store(args, AtomicWriteOrd::Relaxed)?,\n+            \"store_release\" => this.atomic_store(args, AtomicWriteOrd::Release)?,\n+\n+            \"fence_acquire\" => this.atomic_fence(args, AtomicFenceOrd::Acquire)?,\n+            \"fence_release\" => this.atomic_fence(args, AtomicFenceOrd::Release)?,\n+            \"fence_acqrel\" => this.atomic_fence(args, AtomicFenceOrd::AcqRel)?,\n+            \"fence_seqcst\" => this.atomic_fence(args, AtomicFenceOrd::SeqCst)?,\n+\n+            \"singlethreadfence_acquire\" => this.compiler_fence(args, AtomicFenceOrd::Acquire)?,\n+            \"singlethreadfence_release\" => this.compiler_fence(args, AtomicFenceOrd::Release)?,\n+            \"singlethreadfence_acqrel\" => this.compiler_fence(args, AtomicFenceOrd::AcqRel)?,\n+            \"singlethreadfence_seqcst\" => this.compiler_fence(args, AtomicFenceOrd::SeqCst)?,\n+\n+            \"xchg_seqcst\" => this.atomic_exchange(args, dest, AtomicRwOrd::SeqCst)?,\n+            \"xchg_acquire\" => this.atomic_exchange(args, dest, AtomicRwOrd::Acquire)?,\n+            \"xchg_release\" => this.atomic_exchange(args, dest, AtomicRwOrd::Release)?,\n+            \"xchg_acqrel\" => this.atomic_exchange(args, dest, AtomicRwOrd::AcqRel)?,\n+            \"xchg_relaxed\" => this.atomic_exchange(args, dest, AtomicRwOrd::Relaxed)?,\n+\n+            #[rustfmt::skip]\n+            \"cxchg_seqcst_seqcst\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"cxchg_acquire_acquire\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"cxchg_release_relaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Release, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchg_acqrel_acquire\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"cxchg_relaxed_relaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Relaxed, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchg_acquire_relaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchg_acqrel_relaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchg_seqcst_relaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchg_seqcst_acquire\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Acquire)?,\n+\n+            #[rustfmt::skip]\n+            \"cxchgweak_seqcst_seqcst\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_acquire_acquire\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_release_relaxed\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Release, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_acqrel_acquire\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_relaxed_relaxed\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Relaxed, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_acquire_relaxed\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_acqrel_relaxed\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_seqcst_relaxed\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"cxchgweak_seqcst_acquire\" =>\n+                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Acquire)?,\n+\n+            #[rustfmt::skip]\n+            \"or_seqcst\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"or_acquire\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"or_release\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::Release)?,\n+            #[rustfmt::skip]\n+            \"or_acqrel\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::AcqRel)?,\n+            #[rustfmt::skip]\n+            \"or_relaxed\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"xor_seqcst\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"xor_acquire\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"xor_release\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::Release)?,\n+            #[rustfmt::skip]\n+            \"xor_acqrel\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::AcqRel)?,\n+            #[rustfmt::skip]\n+            \"xor_relaxed\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"and_seqcst\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"and_acquire\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"and_release\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::Release)?,\n+            #[rustfmt::skip]\n+            \"and_acqrel\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::AcqRel)?,\n+            #[rustfmt::skip]\n+            \"and_relaxed\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"nand_seqcst\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"nand_acquire\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"nand_release\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::Release)?,\n+            #[rustfmt::skip]\n+            \"nand_acqrel\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::AcqRel)?,\n+            #[rustfmt::skip]\n+            \"nand_relaxed\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"xadd_seqcst\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"xadd_acquire\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"xadd_release\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::Release)?,\n+            #[rustfmt::skip]\n+            \"xadd_acqrel\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::AcqRel)?,\n+            #[rustfmt::skip]\n+            \"xadd_relaxed\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::Relaxed)?,\n+            #[rustfmt::skip]\n+            \"xsub_seqcst\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::SeqCst)?,\n+            #[rustfmt::skip]\n+            \"xsub_acquire\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::Acquire)?,\n+            #[rustfmt::skip]\n+            \"xsub_release\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::Release)?,\n+            #[rustfmt::skip]\n+            \"xsub_acqrel\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::AcqRel)?,\n+            #[rustfmt::skip]\n+            \"xsub_relaxed\" =>\n+                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::Relaxed)?,\n+\n+            \"min_seqcst\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::SeqCst)?,\n+            \"min_acquire\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Acquire)?,\n+            \"min_release\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Release)?,\n+            \"min_acqrel\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::AcqRel)?,\n+            \"min_relaxed\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Relaxed)?,\n+            \"max_seqcst\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::SeqCst)?,\n+            \"max_acquire\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Acquire)?,\n+            \"max_release\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Release)?,\n+            \"max_acqrel\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::AcqRel)?,\n+            \"max_relaxed\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Relaxed)?,\n+            \"umin_seqcst\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::SeqCst)?,\n+            \"umin_acquire\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Acquire)?,\n+            \"umin_release\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Release)?,\n+            \"umin_acqrel\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::AcqRel)?,\n+            \"umin_relaxed\" => this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Relaxed)?,\n+            \"umax_seqcst\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::SeqCst)?,\n+            \"umax_acquire\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Acquire)?,\n+            \"umax_release\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Release)?,\n+            \"umax_acqrel\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::AcqRel)?,\n+            \"umax_relaxed\" => this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Relaxed)?,\n+\n+            name => throw_unsup_format!(\"unimplemented intrinsic: `atomic_{name}`\"),\n+        }\n+        Ok(())\n+    }\n+\n+    fn atomic_load(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        atomic: AtomicReadOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        let [place] = check_arg_count(args)?;\n+        let place = this.deref_operand(place)?;\n+\n+        // make sure it fits into a scalar; otherwise it cannot be atomic\n+        let val = this.read_scalar_atomic(&place, atomic)?;\n+\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+        // Perform regular access.\n+        this.write_scalar(val, dest)?;\n+        Ok(())\n+    }\n+\n+    fn atomic_store(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        atomic: AtomicWriteOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        let [place, val] = check_arg_count(args)?;\n+        let place = this.deref_operand(place)?;\n+        let val = this.read_scalar(val)?; // make sure it fits into a scalar; otherwise it cannot be atomic\n+\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+\n+        // Perform atomic store\n+        this.write_scalar_atomic(val, &place, atomic)?;\n+        Ok(())\n+    }\n+\n+    fn compiler_fence(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        atomic: AtomicFenceOrd,\n+    ) -> InterpResult<'tcx> {\n+        let [] = check_arg_count(args)?;\n+        let _ = atomic;\n+        //FIXME: compiler fences are currently ignored\n+        Ok(())\n+    }\n+\n+    fn atomic_fence(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        atomic: AtomicFenceOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        let [] = check_arg_count(args)?;\n+        this.validate_atomic_fence(atomic)?;\n+        Ok(())\n+    }\n+\n+    fn atomic_op(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        atomic_op: AtomicOp,\n+        atomic: AtomicRwOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        let [place, rhs] = check_arg_count(args)?;\n+        let place = this.deref_operand(place)?;\n+\n+        if !place.layout.ty.is_integral() && !place.layout.ty.is_unsafe_ptr() {\n+            span_bug!(\n+                this.cur_span(),\n+                \"atomic arithmetic operations only work on integer and raw pointer types\",\n+            );\n+        }\n+        let rhs = this.read_immediate(rhs)?;\n+\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+\n+        match atomic_op {\n+            AtomicOp::Min => {\n+                let old = this.atomic_min_max_scalar(&place, rhs, true, atomic)?;\n+                this.write_immediate(*old, dest)?; // old value is returned\n+                Ok(())\n+            }\n+            AtomicOp::Max => {\n+                let old = this.atomic_min_max_scalar(&place, rhs, false, atomic)?;\n+                this.write_immediate(*old, dest)?; // old value is returned\n+                Ok(())\n+            }\n+            AtomicOp::MirOp(op, neg) => {\n+                let old = this.atomic_op_immediate(&place, &rhs, op, neg, atomic)?;\n+                this.write_immediate(*old, dest)?; // old value is returned\n+                Ok(())\n+            }\n+        }\n+    }\n+\n+    fn atomic_exchange(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        atomic: AtomicRwOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        let [place, new] = check_arg_count(args)?;\n+        let place = this.deref_operand(place)?;\n+        let new = this.read_scalar(new)?;\n+\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+\n+        let old = this.atomic_exchange_scalar(&place, new, atomic)?;\n+        this.write_scalar(old, dest)?; // old value is returned\n+        Ok(())\n+    }\n+\n+    fn atomic_compare_exchange_impl(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        success: AtomicRwOrd,\n+        fail: AtomicReadOrd,\n+        can_fail_spuriously: bool,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        let [place, expect_old, new] = check_arg_count(args)?;\n+        let place = this.deref_operand(place)?;\n+        let expect_old = this.read_immediate(expect_old)?; // read as immediate for the sake of `binary_op()`\n+        let new = this.read_scalar(new)?;\n+\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+\n+        let old = this.atomic_compare_exchange_scalar(\n+            &place,\n+            &expect_old,\n+            new,\n+            success,\n+            fail,\n+            can_fail_spuriously,\n+        )?;\n+\n+        // Return old value.\n+        this.write_immediate(old, dest)?;\n+        Ok(())\n+    }\n+\n+    fn atomic_compare_exchange(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        success: AtomicRwOrd,\n+        fail: AtomicReadOrd,\n+    ) -> InterpResult<'tcx> {\n+        self.atomic_compare_exchange_impl(args, dest, success, fail, false)\n+    }\n+\n+    fn atomic_compare_exchange_weak(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        success: AtomicRwOrd,\n+        fail: AtomicReadOrd,\n+    ) -> InterpResult<'tcx> {\n+        self.atomic_compare_exchange_impl(args, dest, success, fail, true)\n+    }\n+}"}, {"sha": "6195147259af2668de83a79e1e92e6e0423d139d", "filename": "src/shims/intrinsics/mod.rs", "status": "renamed", "additions": 34, "deletions": 447, "changes": 481, "blob_url": "https://github.com/rust-lang/rust/blob/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/src%2Fshims%2Fintrinsics%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52a6ac96b0a2a270400d75ba9ed3aa829826b5db/src%2Fshims%2Fintrinsics%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fintrinsics%2Fmod.rs?ref=52a6ac96b0a2a270400d75ba9ed3aa829826b5db", "patch": "@@ -1,21 +1,17 @@\n+pub mod atomic;\n+\n use std::iter;\n \n use log::trace;\n \n use rustc_apfloat::{Float, Round};\n use rustc_middle::ty::layout::{HasParamEnv, IntegerExt, LayoutOf};\n-use rustc_middle::{mir, mir::BinOp, ty, ty::FloatTy};\n-use rustc_target::abi::{Align, Endian, HasDataLayout, Integer, Size};\n+use rustc_middle::{mir, ty, ty::FloatTy};\n+use rustc_target::abi::{Endian, HasDataLayout, Integer, Size};\n \n use crate::*;\n use helpers::check_arg_count;\n \n-pub enum AtomicOp {\n-    MirOp(mir::BinOp, bool),\n-    Max,\n-    Min,\n-}\n-\n impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n     fn call_intrinsic(\n@@ -28,19 +24,46 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n \n+        // See if the core engine can handle this intrinsic.\n         if this.emulate_intrinsic(instance, args, dest, ret)? {\n             return Ok(());\n         }\n \n-        // All supported intrinsics have a return place.\n+        // All remaining supported intrinsics have a return place.\n         let intrinsic_name = this.tcx.item_name(instance.def_id());\n         let intrinsic_name = intrinsic_name.as_str();\n         let ret = match ret {\n             None => throw_unsup_format!(\"unimplemented (diverging) intrinsic: `{intrinsic_name}`\"),\n             Some(p) => p,\n         };\n \n-        // Then handle terminating intrinsics.\n+        // Some intrinsics are special and need the \"ret\".\n+        match intrinsic_name {\n+            \"try\" => return this.handle_try(args, dest, ret),\n+            _ => {}\n+        }\n+\n+        // The rest jumps to `ret` immediately.\n+        this.emulate_intrinsic_by_name(intrinsic_name, args, dest)?;\n+\n+        trace!(\"{:?}\", this.dump_place(**dest));\n+        this.go_to_block(ret);\n+        Ok(())\n+    }\n+\n+    /// Emulates a Miri-supported intrinsic (not supported by the core engine).\n+    fn emulate_intrinsic_by_name(\n+        &mut self,\n+        intrinsic_name: &str,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        if let Some(name) = intrinsic_name.strip_prefix(\"atomic_\") {\n+            return this.emulate_atomic_intrinsic(name, args, dest);\n+        }\n+\n         match intrinsic_name {\n             // Miri overwriting CTFE intrinsics.\n             \"ptr_guaranteed_eq\" => {\n@@ -78,7 +101,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n             \"write_bytes\" | \"volatile_set_memory\" => {\n                 let [ptr, val_byte, count] = check_arg_count(args)?;\n-                let ty = instance.substs.type_at(0);\n+                let ty = ptr.layout.ty.builtin_deref(true).unwrap().ty;\n                 let ty_layout = this.layout_of(ty)?;\n                 let val_byte = this.read_scalar(val_byte)?.to_u8()?;\n                 let ptr = this.read_pointer(ptr)?;\n@@ -859,230 +882,12 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 this.write_int(res, dest)?;\n             }\n \n-            // Atomic operations\n-            \"atomic_load_seqcst\" => this.atomic_load(args, dest, AtomicReadOrd::SeqCst)?,\n-            \"atomic_load_relaxed\" => this.atomic_load(args, dest, AtomicReadOrd::Relaxed)?,\n-            \"atomic_load_acquire\" => this.atomic_load(args, dest, AtomicReadOrd::Acquire)?,\n-\n-            \"atomic_store_seqcst\" => this.atomic_store(args, AtomicWriteOrd::SeqCst)?,\n-            \"atomic_store_relaxed\" => this.atomic_store(args, AtomicWriteOrd::Relaxed)?,\n-            \"atomic_store_release\" => this.atomic_store(args, AtomicWriteOrd::Release)?,\n-\n-            \"atomic_fence_acquire\" => this.atomic_fence(args, AtomicFenceOrd::Acquire)?,\n-            \"atomic_fence_release\" => this.atomic_fence(args, AtomicFenceOrd::Release)?,\n-            \"atomic_fence_acqrel\" => this.atomic_fence(args, AtomicFenceOrd::AcqRel)?,\n-            \"atomic_fence_seqcst\" => this.atomic_fence(args, AtomicFenceOrd::SeqCst)?,\n-\n-            \"atomic_singlethreadfence_acquire\" =>\n-                this.compiler_fence(args, AtomicFenceOrd::Acquire)?,\n-            \"atomic_singlethreadfence_release\" =>\n-                this.compiler_fence(args, AtomicFenceOrd::Release)?,\n-            \"atomic_singlethreadfence_acqrel\" =>\n-                this.compiler_fence(args, AtomicFenceOrd::AcqRel)?,\n-            \"atomic_singlethreadfence_seqcst\" =>\n-                this.compiler_fence(args, AtomicFenceOrd::SeqCst)?,\n-\n-            \"atomic_xchg_seqcst\" => this.atomic_exchange(args, dest, AtomicRwOrd::SeqCst)?,\n-            \"atomic_xchg_acquire\" => this.atomic_exchange(args, dest, AtomicRwOrd::Acquire)?,\n-            \"atomic_xchg_release\" => this.atomic_exchange(args, dest, AtomicRwOrd::Release)?,\n-            \"atomic_xchg_acqrel\" => this.atomic_exchange(args, dest, AtomicRwOrd::AcqRel)?,\n-            \"atomic_xchg_relaxed\" => this.atomic_exchange(args, dest, AtomicRwOrd::Relaxed)?,\n-\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_seqcst_seqcst\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_acquire_acquire\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_release_relaxed\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Release, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_acqrel_acquire\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_relaxed_relaxed\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Relaxed, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_acquire_relaxed\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_acqrel_relaxed\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_seqcst_relaxed\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchg_seqcst_acquire\" =>\n-                this.atomic_compare_exchange(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Acquire)?,\n-\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_seqcst_seqcst\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_acquire_acquire\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_release_relaxed\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Release, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_acqrel_acquire\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_relaxed_relaxed\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Relaxed, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_acquire_relaxed\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::Acquire, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_acqrel_relaxed\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::AcqRel, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_seqcst_relaxed\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_cxchgweak_seqcst_acquire\" =>\n-                this.atomic_compare_exchange_weak(args, dest, AtomicRwOrd::SeqCst, AtomicReadOrd::Acquire)?,\n-\n-            #[rustfmt::skip]\n-            \"atomic_or_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_or_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_or_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::Release)?,\n-            #[rustfmt::skip]\n-            \"atomic_or_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::AcqRel)?,\n-            #[rustfmt::skip]\n-            \"atomic_or_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitOr, false), AtomicRwOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_xor_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_xor_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_xor_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::Release)?,\n-            #[rustfmt::skip]\n-            \"atomic_xor_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::AcqRel)?,\n-            #[rustfmt::skip]\n-            \"atomic_xor_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitXor, false), AtomicRwOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_and_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_and_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_and_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::Release)?,\n-            #[rustfmt::skip]\n-            \"atomic_and_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::AcqRel)?,\n-            #[rustfmt::skip]\n-            \"atomic_and_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, false), AtomicRwOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_nand_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_nand_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_nand_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::Release)?,\n-            #[rustfmt::skip]\n-            \"atomic_nand_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::AcqRel)?,\n-            #[rustfmt::skip]\n-            \"atomic_nand_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::BitAnd, true), AtomicRwOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_xadd_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_xadd_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_xadd_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::Release)?,\n-            #[rustfmt::skip]\n-            \"atomic_xadd_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::AcqRel)?,\n-            #[rustfmt::skip]\n-            \"atomic_xadd_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Add, false), AtomicRwOrd::Relaxed)?,\n-            #[rustfmt::skip]\n-            \"atomic_xsub_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::SeqCst)?,\n-            #[rustfmt::skip]\n-            \"atomic_xsub_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::Acquire)?,\n-            #[rustfmt::skip]\n-            \"atomic_xsub_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::Release)?,\n-            #[rustfmt::skip]\n-            \"atomic_xsub_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::AcqRel)?,\n-            #[rustfmt::skip]\n-            \"atomic_xsub_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::MirOp(BinOp::Sub, false), AtomicRwOrd::Relaxed)?,\n-            \"atomic_min_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::SeqCst)?,\n-            \"atomic_min_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Acquire)?,\n-            \"atomic_min_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Release)?,\n-            \"atomic_min_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::AcqRel)?,\n-            \"atomic_min_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Relaxed)?,\n-            \"atomic_max_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::SeqCst)?,\n-            \"atomic_max_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Acquire)?,\n-            \"atomic_max_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Release)?,\n-            \"atomic_max_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::AcqRel)?,\n-            \"atomic_max_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Relaxed)?,\n-            \"atomic_umin_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::SeqCst)?,\n-            \"atomic_umin_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Acquire)?,\n-            \"atomic_umin_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Release)?,\n-            \"atomic_umin_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::AcqRel)?,\n-            \"atomic_umin_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::Min, AtomicRwOrd::Relaxed)?,\n-            \"atomic_umax_seqcst\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::SeqCst)?,\n-            \"atomic_umax_acquire\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Acquire)?,\n-            \"atomic_umax_release\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Release)?,\n-            \"atomic_umax_acqrel\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::AcqRel)?,\n-            \"atomic_umax_relaxed\" =>\n-                this.atomic_op(args, dest, AtomicOp::Max, AtomicRwOrd::Relaxed)?,\n-\n             // Other\n             \"exact_div\" => {\n                 let [num, denom] = check_arg_count(args)?;\n                 this.exact_div(&this.read_immediate(num)?, &this.read_immediate(denom)?, dest)?;\n             }\n \n-            \"try\" => return this.handle_try(args, dest, ret),\n-\n             \"breakpoint\" => {\n                 let [] = check_arg_count(args)?;\n                 // normally this would raise a SIGTRAP, which aborts if no debugger is connected\n@@ -1092,227 +897,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             name => throw_unsup_format!(\"unimplemented intrinsic: `{name}`\"),\n         }\n \n-        trace!(\"{:?}\", this.dump_place(**dest));\n-        this.go_to_block(ret);\n-        Ok(())\n-    }\n-\n-    fn atomic_load(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        dest: &PlaceTy<'tcx, Tag>,\n-        atomic: AtomicReadOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-\n-        let [place] = check_arg_count(args)?;\n-        let place = this.deref_operand(place)?;\n-\n-        // make sure it fits into a scalar; otherwise it cannot be atomic\n-        let val = this.read_scalar_atomic(&place, atomic)?;\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-        // Perform regular access.\n-        this.write_scalar(val, dest)?;\n-        Ok(())\n-    }\n-\n-    fn atomic_store(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        atomic: AtomicWriteOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-\n-        let [place, val] = check_arg_count(args)?;\n-        let place = this.deref_operand(place)?;\n-        let val = this.read_scalar(val)?; // make sure it fits into a scalar; otherwise it cannot be atomic\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n-        // Perform atomic store\n-        this.write_scalar_atomic(val, &place, atomic)?;\n-        Ok(())\n-    }\n-\n-    fn compiler_fence(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        atomic: AtomicFenceOrd,\n-    ) -> InterpResult<'tcx> {\n-        let [] = check_arg_count(args)?;\n-        let _ = atomic;\n-        //FIXME: compiler fences are currently ignored\n         Ok(())\n     }\n \n-    fn atomic_fence(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        atomic: AtomicFenceOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-        let [] = check_arg_count(args)?;\n-        this.validate_atomic_fence(atomic)?;\n-        Ok(())\n-    }\n-\n-    fn atomic_op(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        dest: &PlaceTy<'tcx, Tag>,\n-        atomic_op: AtomicOp,\n-        atomic: AtomicRwOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-\n-        let [place, rhs] = check_arg_count(args)?;\n-        let place = this.deref_operand(place)?;\n-\n-        if !place.layout.ty.is_integral() && !place.layout.ty.is_unsafe_ptr() {\n-            span_bug!(\n-                this.cur_span(),\n-                \"atomic arithmetic operations only work on integer and raw pointer types\",\n-            );\n-        }\n-        let rhs = this.read_immediate(rhs)?;\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n-        match atomic_op {\n-            AtomicOp::Min => {\n-                let old = this.atomic_min_max_scalar(&place, rhs, true, atomic)?;\n-                this.write_immediate(*old, dest)?; // old value is returned\n-                Ok(())\n-            }\n-            AtomicOp::Max => {\n-                let old = this.atomic_min_max_scalar(&place, rhs, false, atomic)?;\n-                this.write_immediate(*old, dest)?; // old value is returned\n-                Ok(())\n-            }\n-            AtomicOp::MirOp(op, neg) => {\n-                let old = this.atomic_op_immediate(&place, &rhs, op, neg, atomic)?;\n-                this.write_immediate(*old, dest)?; // old value is returned\n-                Ok(())\n-            }\n-        }\n-    }\n-\n-    fn atomic_exchange(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        dest: &PlaceTy<'tcx, Tag>,\n-        atomic: AtomicRwOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-\n-        let [place, new] = check_arg_count(args)?;\n-        let place = this.deref_operand(place)?;\n-        let new = this.read_scalar(new)?;\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n-        let old = this.atomic_exchange_scalar(&place, new, atomic)?;\n-        this.write_scalar(old, dest)?; // old value is returned\n-        Ok(())\n-    }\n-\n-    fn atomic_compare_exchange_impl(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        dest: &PlaceTy<'tcx, Tag>,\n-        success: AtomicRwOrd,\n-        fail: AtomicReadOrd,\n-        can_fail_spuriously: bool,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-\n-        let [place, expect_old, new] = check_arg_count(args)?;\n-        let place = this.deref_operand(place)?;\n-        let expect_old = this.read_immediate(expect_old)?; // read as immediate for the sake of `binary_op()`\n-        let new = this.read_scalar(new)?;\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n-        let old = this.atomic_compare_exchange_scalar(\n-            &place,\n-            &expect_old,\n-            new,\n-            success,\n-            fail,\n-            can_fail_spuriously,\n-        )?;\n-\n-        // Return old value.\n-        this.write_immediate(old, dest)?;\n-        Ok(())\n-    }\n-\n-    fn atomic_compare_exchange(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        dest: &PlaceTy<'tcx, Tag>,\n-        success: AtomicRwOrd,\n-        fail: AtomicReadOrd,\n-    ) -> InterpResult<'tcx> {\n-        self.atomic_compare_exchange_impl(args, dest, success, fail, false)\n-    }\n-\n-    fn atomic_compare_exchange_weak(\n-        &mut self,\n-        args: &[OpTy<'tcx, Tag>],\n-        dest: &PlaceTy<'tcx, Tag>,\n-        success: AtomicRwOrd,\n-        fail: AtomicReadOrd,\n-    ) -> InterpResult<'tcx> {\n-        self.atomic_compare_exchange_impl(args, dest, success, fail, true)\n-    }\n-\n     fn float_to_int_unchecked<F>(\n         &self,\n         f: F,", "previous_filename": "src/shims/intrinsics.rs"}]}