{"sha": "020313dd8506d3704a71d2ec1499f0e7ee93f3dd", "node_id": "MDY6Q29tbWl0NzI0NzEyOjAyMDMxM2RkODUwNmQzNzA0YTcxZDJlYzE0OTlmMGU3ZWU5M2YzZGQ=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2018-11-07T15:56:25Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2018-11-15T08:35:40Z"}, "message": "make freezing inherently part of the high-level reactivate/initiate operations", "tree": {"sha": "08db9cabaf03118e819600f08868525a71884d2e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/08db9cabaf03118e819600f08868525a71884d2e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/020313dd8506d3704a71d2ec1499f0e7ee93f3dd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/020313dd8506d3704a71d2ec1499f0e7ee93f3dd", "html_url": "https://github.com/rust-lang/rust/commit/020313dd8506d3704a71d2ec1499f0e7ee93f3dd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/020313dd8506d3704a71d2ec1499f0e7ee93f3dd/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "09919c2b596b19ad36850b77d8f6ea00b3b60612", "url": "https://api.github.com/repos/rust-lang/rust/commits/09919c2b596b19ad36850b77d8f6ea00b3b60612", "html_url": "https://github.com/rust-lang/rust/commit/09919c2b596b19ad36850b77d8f6ea00b3b60612"}], "stats": {"total": 234, "additions": 125, "deletions": 109}, "files": [{"sha": "31e297295703541b4feb2e7f3927827e6d86e0f1", "filename": "src/helpers.rs", "status": "modified", "additions": 22, "deletions": 13, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/020313dd8506d3704a71d2ec1499f0e7ee93f3dd/src%2Fhelpers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/020313dd8506d3704a71d2ec1499f0e7ee93f3dd/src%2Fhelpers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fhelpers.rs?ref=020313dd8506d3704a71d2ec1499f0e7ee93f3dd", "patch": "@@ -33,13 +33,13 @@ impl<Tag> ScalarExt for ScalarMaybeUndef<Tag> {\n pub trait EvalContextExt<'tcx> {\n     fn resolve_path(&self, path: &[&str]) -> EvalResult<'tcx, ty::Instance<'tcx>>;\n \n-    /// Visit the memory covered by `place` that is frozen -- i.e., NOT\n-    /// what is inside an `UnsafeCell`.\n-    fn visit_frozen(\n+    /// Visit the memory covered by `place`, sensitive to freezing:  The 3rd parameter\n+    /// will be true if this is frozen, false if this is in an `UnsafeCell`.\n+    fn visit_freeze_sensitive(\n         &self,\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n-        action: impl FnMut(Pointer<Borrow>, Size) -> EvalResult<'tcx>,\n+        action: impl FnMut(Pointer<Borrow>, Size, bool) -> EvalResult<'tcx>,\n     ) -> EvalResult<'tcx>;\n }\n \n@@ -79,13 +79,11 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n             })\n     }\n \n-    /// Visit the memory covered by `place` that is frozen -- i.e., NOT\n-    /// what is inside an `UnsafeCell`.\n-    fn visit_frozen(\n+    fn visit_freeze_sensitive(\n         &self,\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n-        mut frozen_action: impl FnMut(Pointer<Borrow>, Size) -> EvalResult<'tcx>,\n+        mut action: impl FnMut(Pointer<Borrow>, Size, bool) -> EvalResult<'tcx>,\n     ) -> EvalResult<'tcx> {\n         trace!(\"visit_frozen(place={:?}, size={:?})\", *place, size);\n         debug_assert_eq!(size,\n@@ -99,18 +97,29 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n         let mut end_ptr = place.ptr;\n         // Called when we detected an `UnsafeCell` at the given offset and size.\n         // Calls `action` and advances `end_ptr`.\n-        let mut unsafe_cell_action = |unsafe_cell_offset, unsafe_cell_size| {\n+        let mut unsafe_cell_action = |unsafe_cell_ptr: Scalar<Borrow>, unsafe_cell_size: Size| {\n+            if unsafe_cell_size != Size::ZERO {\n+                debug_assert_eq!(unsafe_cell_ptr.to_ptr().unwrap().alloc_id,\n+                    end_ptr.to_ptr().unwrap().alloc_id);\n+                debug_assert_eq!(unsafe_cell_ptr.to_ptr().unwrap().tag,\n+                    end_ptr.to_ptr().unwrap().tag);\n+            }\n             // We assume that we are given the fields in increasing offset order,\n             // and nothing else changes.\n+            let unsafe_cell_offset = unsafe_cell_ptr.get_ptr_offset(self);\n             let end_offset = end_ptr.get_ptr_offset(self);\n             assert!(unsafe_cell_offset >= end_offset);\n             let frozen_size = unsafe_cell_offset - end_offset;\n             // Everything between the end_ptr and this `UnsafeCell` is frozen.\n             if frozen_size != Size::ZERO {\n-                frozen_action(end_ptr.to_ptr()?, frozen_size)?;\n+                action(end_ptr.to_ptr()?, frozen_size, /*frozen*/true)?;\n+            }\n+            // This `UnsafeCell` is NOT frozen.\n+            if unsafe_cell_size != Size::ZERO {\n+                action(unsafe_cell_ptr.to_ptr()?, unsafe_cell_size, /*frozen*/false)?;\n             }\n             // Update end end_ptr.\n-            end_ptr = end_ptr.ptr_wrapping_offset(frozen_size+unsafe_cell_size, self);\n+            end_ptr = unsafe_cell_ptr.ptr_wrapping_offset(unsafe_cell_size, self);\n             // Done\n             Ok(())\n         };\n@@ -126,7 +135,7 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n                         .unwrap_or_else(|| place.layout.size_and_align());\n                     // Now handle this `UnsafeCell`, unless it is empty.\n                     if unsafe_cell_size != Size::ZERO {\n-                        unsafe_cell_action(place.ptr.get_ptr_offset(self), unsafe_cell_size)\n+                        unsafe_cell_action(place.ptr, unsafe_cell_size)\n                     } else {\n                         Ok(())\n                     }\n@@ -136,7 +145,7 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for EvalContext<'a, 'mir, 'tcx, super:\n         }\n         // The part between the end_ptr and the end of the place is also frozen.\n         // So pretend there is a 0-sized `UnsafeCell` at the end.\n-        unsafe_cell_action(place.ptr.get_ptr_offset(self) + size, Size::ZERO)?;\n+        unsafe_cell_action(place.ptr.ptr_wrapping_offset(size, self), Size::ZERO)?;\n         // Done!\n         return Ok(());\n "}, {"sha": "ab0c3f8994c5187013f139cfe4d5b6aad7ecd081", "filename": "src/stacked_borrows.rs", "status": "modified", "additions": 103, "deletions": 96, "changes": 199, "blob_url": "https://github.com/rust-lang/rust/blob/020313dd8506d3704a71d2ec1499f0e7ee93f3dd/src%2Fstacked_borrows.rs", "raw_url": "https://github.com/rust-lang/rust/raw/020313dd8506d3704a71d2ec1499f0e7ee93f3dd/src%2Fstacked_borrows.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstacked_borrows.rs?ref=020313dd8506d3704a71d2ec1499f0e7ee93f3dd", "patch": "@@ -217,10 +217,12 @@ impl<'tcx> Stack {\n \n     /// Initiate `bor`; mostly this means pushing.\n     /// This operation cannot fail; it is up to the caller to ensure that the precondition\n-    /// is met: We cannot push onto frozen stacks.\n+    /// is met: We cannot push `Uniq` onto frozen stacks.\n+    /// Crucially, this makes pushing a `Shr` onto a frozen location a NOP.  We do not want\n+    /// such a location to get mutably shared this way!\n     fn initiate(&mut self, bor: Borrow) {\n         if let Some(_) = self.frozen_since {\n-            // \"Pushing\" a Shr or Frz on top is redundant.\n+            // A frozen location, we won't change anything here!\n             match bor {\n                 Borrow::Uniq(_) => bug!(\"Trying to create unique ref to frozen location\"),\n                 Borrow::Shr(_) => trace!(\"initiate: New shared ref to frozen location is a NOP\"),\n@@ -272,46 +274,49 @@ impl State {\n \n /// Higher-level operations\n impl<'tcx> Stacks {\n-    /// The single most important operation: Make sure that using `ptr` is okay,\n-    /// and if `new_bor` is present then make that the new current borrow.\n-    fn use_and_maybe_re_borrow(\n+    /// `ptr` got used, reflect that in the stack.\n+    fn reactivate(\n         &self,\n         ptr: Pointer<Borrow>,\n         size: Size,\n         usage: UsageKind,\n-        new_bor: Option<Borrow>,\n     ) -> EvalResult<'tcx> {\n-        trace!(\"use_and_maybe_re_borrow of tag {:?} as {:?}, new {:?}: {:?}, size {}\",\n-            ptr.tag, usage, new_bor, ptr, size.bytes());\n+        trace!(\"use_borrow of tag {:?} as {:?}: {:?}, size {}\",\n+            ptr.tag, usage, ptr, size.bytes());\n         let mut stacks = self.stacks.borrow_mut();\n         for stack in stacks.iter_mut(ptr.offset, size) {\n             stack.reactivate(ptr.tag, usage == UsageKind::Write)?;\n-            if let Some(new_bor) = new_bor {\n-                stack.initiate(new_bor);\n-            }\n         }\n         Ok(())\n     }\n \n-    /// Freeze the given memory range.\n-    fn freeze(\n+    /// Create a new borrow, the ptr must already have the new tag.\n+    /// Also freezes the location if `freeze` is set and the tag is a timestamped `Shr`.\n+    fn initiate(\n         &self,\n         ptr: Pointer<Borrow>,\n         size: Size,\n-        bor_t: Timestamp\n-    ) -> EvalResult<'tcx> {\n+        freeze: bool,\n+    ) {\n+        trace!(\"reborrow for tag {:?}: {:?}, size {}\",\n+            ptr.tag, ptr, size.bytes());\n         let mut stacks = self.stacks.borrow_mut();\n         for stack in stacks.iter_mut(ptr.offset, size) {\n-            stack.freeze(bor_t);\n+            stack.initiate(ptr.tag);\n+            if freeze {\n+                if let Borrow::Shr(Some(bor_t)) = ptr.tag {\n+                    stack.freeze(bor_t);\n+                }\n+            }\n         }\n-        Ok(())\n     }\n \n     /// Check that this stack is fine with being dereferenced\n     fn check_deref(\n         &self,\n         ptr: Pointer<Borrow>,\n         size: Size,\n+        frozen: bool,\n     ) -> EvalResult<'tcx> {\n         let mut stacks = self.stacks.borrow_mut();\n         // We need `iter_mut` because `iter` would skip gaps!\n@@ -323,20 +328,14 @@ impl<'tcx> Stacks {\n                     err\n                 )))\n             }\n-        }\n-        Ok(())\n-    }\n-\n-    /// Check that this stack is appropriately frozen\n-    fn check_frozen(\n-        &self,\n-        ptr: Pointer<Borrow>,\n-        size: Size,\n-        bor_t: Timestamp\n-    ) -> EvalResult<'tcx> {\n-        let mut stacks = self.stacks.borrow_mut();\n-        for stack in stacks.iter_mut(ptr.offset, size) {\n-            stack.check_frozen(bor_t)?;\n+            // Sometimes we also need to be frozen.\n+            if frozen {\n+                // Even shared refs can have uniq tags (after transmute).  That's not an error\n+                // but they do not get any freezing benefits.\n+                if let Borrow::Shr(Some(bor_t)) = ptr.tag {\n+                    stack.check_frozen(bor_t)?;\n+                }\n+            }\n         }\n         Ok(())\n     }\n@@ -351,7 +350,7 @@ impl AllocationExtra<Borrow> for Stacks {\n         size: Size,\n     ) -> EvalResult<'tcx> {\n         // Reads behave exactly like the first half of a reborrow-to-shr\n-        alloc.extra.use_and_maybe_re_borrow(ptr, size, UsageKind::Read, None)\n+        alloc.extra.reactivate(ptr, size, UsageKind::Read)\n     }\n \n     #[inline(always)]\n@@ -361,7 +360,7 @@ impl AllocationExtra<Borrow> for Stacks {\n         size: Size,\n     ) -> EvalResult<'tcx> {\n         // Writes behave exactly like the first half of a reborrow-to-mut\n-        alloc.extra.use_and_maybe_re_borrow(ptr, size, UsageKind::Write, None)\n+        alloc.extra.reactivate(ptr, size, UsageKind::Read)\n     }\n \n     #[inline(always)]\n@@ -371,7 +370,7 @@ impl AllocationExtra<Borrow> for Stacks {\n         size: Size,\n     ) -> EvalResult<'tcx> {\n         // This is like mutating\n-        alloc.extra.use_and_maybe_re_borrow(ptr, size, UsageKind::Write, None)\n+        alloc.extra.reactivate(ptr, size, UsageKind::Write)\n         // FIXME: Error out of there are any barriers?\n     }\n }\n@@ -429,6 +428,35 @@ pub trait EvalContextExt<'tcx> {\n }\n \n impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n+    fn tag_new_allocation(\n+        &mut self,\n+        id: AllocId,\n+        kind: MemoryKind<MiriMemoryKind>,\n+    ) -> Borrow {\n+        let time = match kind {\n+            MemoryKind::Stack => {\n+                // New unique borrow. This `Uniq` is not accessible by the program,\n+                // so it will only ever be used when using the local directly (i.e.,\n+                // not through a pointer).  IOW, whenever we directly use a local this will pop\n+                // everything else off the stack, invalidating all previous pointers\n+                // and, in particular, *all* raw pointers.  This subsumes the explicit\n+                // `reset` which the blog post [1] says to perform when accessing a local.\n+                //\n+                // [1] https://www.ralfj.de/blog/2018/08/07/stacked-borrows.html\n+                self.machine.stacked_borrows.increment_clock()\n+            }\n+            _ => {\n+                // Nothing to do for everything else\n+                return Borrow::default()\n+            }\n+        };\n+        // Make this the active borrow for this allocation\n+        let alloc = self.memory_mut().get_mut(id).expect(\"This is a new allocation, it must still exist\");\n+        let size = Size::from_bytes(alloc.bytes.len() as u64);\n+        alloc.extra.first_item(BorStackItem::Uniq(time), size);\n+        Borrow::Uniq(time)\n+    }\n+\n     /// Called for value-to-place conversion.\n     ///\n     /// Note that this does NOT mean that all this memory will actually get accessed/referenced!\n@@ -449,8 +477,8 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         // That can transmute a raw ptr to a (shared/mut) ref, and a mut ref to a shared one.\n         match (usage, ptr.tag) {\n             (UsageKind::Raw, _) => {\n-                // Don't use the tag, this is a raw access!  Even if there is a tag,\n-                // that means transmute happened and we ignore the tag.\n+                // Don't use the tag, this is a raw access!  They should happen tagless.\n+                // This does mean, however, that `&*foo` is *not* a NOP *if* `foo` is a raw ptr.\n                 // Also don't do any further validation, this is raw after all.\n                 return Ok(Borrow::default());\n             }\n@@ -478,50 +506,41 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n             }\n         }\n \n-        // If we got here, we do some checking, *but* we leave the tag unchanged.\n+        // Get the allocation\n         self.memory().check_bounds(ptr, size, false)?;\n         let alloc = self.memory().get(ptr.alloc_id).expect(\"We checked that the ptr is fine!\");\n-        alloc.extra.check_deref(ptr, size)?;\n-        // Maybe check frozen stuff\n-        if let Borrow::Shr(Some(bor_t)) = ptr.tag {\n-            self.visit_frozen(place, size, |frz_ptr, size| {\n-                debug_assert_eq!(frz_ptr.alloc_id, ptr.alloc_id);\n-                // Are you frozen?\n-                alloc.extra.check_frozen(frz_ptr, size, bor_t)\n+        // If we got here, we do some checking, *but* we leave the tag unchanged.\n+        if let Borrow::Shr(Some(_)) = ptr.tag {\n+            // We need a frozen-sensitive check\n+            self.visit_freeze_sensitive(place, size, |cur_ptr, size, frozen| {\n+                alloc.extra.check_deref(cur_ptr, size, frozen)\n             })?;\n+        } else {\n+            // Just treat this as one big chunk\n+            alloc.extra.check_deref(ptr, size, /*frozen*/false)?;\n         }\n \n         // All is good, and do not change the tag\n         Ok(ptr.tag)\n     }\n \n-    fn tag_new_allocation(\n+    /// The given place may henceforth be accessed through raw pointers.\n+    fn escape_to_raw(\n         &mut self,\n-        id: AllocId,\n-        kind: MemoryKind<MiriMemoryKind>,\n-    ) -> Borrow {\n-        let time = match kind {\n-            MemoryKind::Stack => {\n-                // New unique borrow. This `Uniq` is not accessible by the program,\n-                // so it will only ever be used when using the local directly (i.e.,\n-                // not through a pointer).  IOW, whenever we directly use a local this will pop\n-                // everything else off the stack, invalidating all previous pointers\n-                // and, in particular, *all* raw pointers.  This subsumes the explicit\n-                // `reset` which the blog post [1] says to perform when accessing a local.\n-                //\n-                // [1] https://www.ralfj.de/blog/2018/08/07/stacked-borrows.html\n-                self.machine.stacked_borrows.increment_clock()\n-            }\n-            _ => {\n-                // Nothing to do for everything else\n-                return Borrow::default()\n-            }\n-        };\n-        // Make this the active borrow for this allocation\n-        let alloc = self.memory_mut().get_mut(id).expect(\"This is a new allocation, it must still exist\");\n-        let size = Size::from_bytes(alloc.bytes.len() as u64);\n-        alloc.extra.first_item(BorStackItem::Uniq(time), size);\n-        Borrow::Uniq(time)\n+        place: MPlaceTy<'tcx, Borrow>,\n+        size: Size,\n+    ) -> EvalResult<'tcx> {\n+        trace!(\"self: {:?} is now accessible by raw pointers\", *place);\n+        // Get the allocation\n+        let mut ptr = place.ptr.to_ptr()?;\n+        self.memory().check_bounds(ptr, size, false)?; // `ptr_dereference` wouldn't do any checks if this is a raw ptr\n+        let alloc = self.memory().get(ptr.alloc_id).expect(\"We checked that the ptr is fine!\");\n+        // Re-borrow to raw.  This is a NOP for shared borrows, but we do not know the borrow\n+        // type here and that's also okay.  Freezing does not matter here.\n+        alloc.extra.reactivate(ptr, size, UsageKind::Raw)?;\n+        ptr.tag = Borrow::default();\n+        alloc.extra.initiate(ptr, size, /*freeze*/false);\n+        Ok(())\n     }\n \n     fn retag_ptr(\n@@ -546,25 +565,28 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n             hir::MutMutable => Borrow::Uniq(time),\n             hir::MutImmutable => Borrow::Shr(Some(time)),\n         };\n+        let new_ptr = Pointer::new_with_tag(ptr.alloc_id, ptr.offset, new_bor);\n         trace!(\"retag: Creating new reference ({:?}) for {:?} (pointee {}): {:?}\",\n             mutbl, ptr, place.layout.ty, new_bor);\n \n-        // Update the stacks.  First create a new borrow, then maybe freeze stuff.\n+        // Get the allocation\n         self.memory().check_bounds(ptr, size, false)?; // `ptr_dereference` wouldn't do any checks if this is a raw ptr\n         let alloc = self.memory().get(ptr.alloc_id).expect(\"We checked that the ptr is fine!\");\n-        alloc.extra.use_and_maybe_re_borrow(ptr, size, Some(mutbl).into(), Some(new_bor))?;\n-        // Maybe freeze stuff\n-        if let Borrow::Shr(Some(bor_t)) = new_bor {\n-            self.visit_frozen(place, size, |frz_ptr, size| {\n-                debug_assert_eq!(frz_ptr.alloc_id, ptr.alloc_id);\n-                // Be frozen!\n-                alloc.extra.freeze(frz_ptr, size, bor_t)\n+        // Update the stacks.  First use old borrow, then initiate new one.\n+        alloc.extra.reactivate(ptr, size, Some(mutbl).into())?;\n+        if mutbl == hir::MutImmutable {\n+            // We need a frozen-sensitive initiate\n+            self.visit_freeze_sensitive(place, size, |mut cur_ptr, size, frozen| {\n+                cur_ptr.tag = new_bor;\n+                Ok(alloc.extra.initiate(cur_ptr, size, frozen))\n             })?;\n+        } else {\n+            // Just treat this as one big chunk\n+            alloc.extra.initiate(new_ptr, size, /*frozen*/false);\n         }\n \n-        // Compute the new value and return that\n-        let new_ptr = Scalar::Ptr(Pointer::new_with_tag(ptr.alloc_id, ptr.offset, new_bor));\n-        let new_place = MemPlace { ptr: new_ptr, ..*place };\n+        // Return new ptr\n+        let new_place = MemPlace { ptr: Scalar::Ptr(new_ptr), ..*place };\n         Ok(new_place.to_ref())\n     }\n \n@@ -586,19 +608,4 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         self.write_immediate(val, place)?;\n         Ok(())\n     }\n-\n-    fn escape_to_raw(\n-        &mut self,\n-        place: MPlaceTy<'tcx, Borrow>,\n-        size: Size,\n-    ) -> EvalResult<'tcx> {\n-        trace!(\"self: {:?} is now accessible by raw pointers\", *place);\n-        // Re-borrow to raw.  This is a NOP for shared borrows, but we do not know the borrow\n-        // type here and that's also okay.\n-        let ptr = place.ptr.to_ptr()?;\n-        self.memory().check_bounds(ptr, size, false)?; // `ptr_dereference` wouldn't do any checks if this is a raw ptr\n-        let alloc = self.memory().get(ptr.alloc_id).expect(\"We checked that the ptr is fine!\");\n-        alloc.extra.use_and_maybe_re_borrow(ptr, size, UsageKind::Raw, Some(Borrow::default()))?;\n-        Ok(())\n-    }\n }"}]}