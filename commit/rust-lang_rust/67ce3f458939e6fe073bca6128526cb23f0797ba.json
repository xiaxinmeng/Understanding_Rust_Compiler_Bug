{"sha": "67ce3f458939e6fe073bca6128526cb23f0797ba", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY3Y2UzZjQ1ODkzOWU2ZmUwNzNiY2E2MTI4NTI2Y2IyM2YwNzk3YmE=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-05T10:25:26Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-06T11:04:02Z"}, "message": "syntax: Switch function parameter order in `TokenTree::token`", "tree": {"sha": "f75ff347f2fe08e2bbe42b4455dd9a08bb858619", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f75ff347f2fe08e2bbe42b4455dd9a08bb858619"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/67ce3f458939e6fe073bca6128526cb23f0797ba", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/67ce3f458939e6fe073bca6128526cb23f0797ba", "html_url": "https://github.com/rust-lang/rust/commit/67ce3f458939e6fe073bca6128526cb23f0797ba", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/67ce3f458939e6fe073bca6128526cb23f0797ba/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "350a34f85c0ed53315a2114f0001cfea4fe116d9", "url": "https://api.github.com/repos/rust-lang/rust/commits/350a34f85c0ed53315a2114f0001cfea4fe116d9", "html_url": "https://github.com/rust-lang/rust/commit/350a34f85c0ed53315a2114f0001cfea4fe116d9"}], "stats": {"total": 125, "additions": 63, "deletions": 62}, "files": [{"sha": "8c9bed57bfdfd4ee0a98430c4a01b2665001c003", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -465,10 +465,10 @@ impl MetaItem {\n                 let mod_sep_span = Span::new(last_pos,\n                                              segment.ident.span.lo(),\n                                              segment.ident.span.ctxt());\n-                idents.push(TokenTree::token(mod_sep_span, token::ModSep).into());\n+                idents.push(TokenTree::token(token::ModSep, mod_sep_span).into());\n             }\n-            idents.push(TokenTree::token(segment.ident.span,\n-                                         TokenKind::from_ast_ident(segment.ident)).into());\n+            idents.push(TokenTree::token(TokenKind::from_ast_ident(segment.ident),\n+                                         segment.ident.span).into());\n             last_pos = segment.ident.span.hi();\n         }\n         self.node.tokens(self.span).append_to_tree_and_joint_vec(&mut idents);\n@@ -532,15 +532,15 @@ impl MetaItemKind {\n         match *self {\n             MetaItemKind::Word => TokenStream::empty(),\n             MetaItemKind::NameValue(ref lit) => {\n-                let mut vec = vec![TokenTree::token(span, token::Eq).into()];\n+                let mut vec = vec![TokenTree::token(token::Eq, span).into()];\n                 lit.tokens().append_to_tree_and_joint_vec(&mut vec);\n                 TokenStream::new(vec)\n             }\n             MetaItemKind::List(ref list) => {\n                 let mut tokens = Vec::new();\n                 for (i, item) in list.iter().enumerate() {\n                     if i > 0 {\n-                        tokens.push(TokenTree::token(span, token::Comma).into());\n+                        tokens.push(TokenTree::token(token::Comma, span).into());\n                     }\n                     item.tokens().append_to_tree_and_joint_vec(&mut tokens);\n                 }"}, {"sha": "61c736662c71e3d09db17455f3044a9e8ac0c3ea", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -268,8 +268,9 @@ impl<F> TTMacroExpander for F\n                 if let tokenstream::TokenTree::Token(token) = tt {\n                     if let token::Interpolated(nt) = &token.kind {\n                         if let token::NtIdent(ident, is_raw) = **nt {\n-                            *tt = tokenstream::TokenTree::token(ident.span,\n-                                                                token::Ident(ident.name, is_raw));\n+                            *tt = tokenstream::TokenTree::token(\n+                                token::Ident(ident.name, is_raw), ident.span\n+                            );\n                         }\n                     }\n                 }"}, {"sha": "7cd847eac469039e7e4b0c1c7157db09b673645a", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -585,14 +585,14 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             }\n             AttrProcMacro(ref mac, ..) => {\n                 self.gate_proc_macro_attr_item(attr.span, &item);\n-                let item_tok = TokenTree::token(DUMMY_SP, token::Interpolated(Lrc::new(match item {\n+                let item_tok = TokenTree::token(token::Interpolated(Lrc::new(match item {\n                     Annotatable::Item(item) => token::NtItem(item),\n                     Annotatable::TraitItem(item) => token::NtTraitItem(item.into_inner()),\n                     Annotatable::ImplItem(item) => token::NtImplItem(item.into_inner()),\n                     Annotatable::ForeignItem(item) => token::NtForeignItem(item.into_inner()),\n                     Annotatable::Stmt(stmt) => token::NtStmt(stmt.into_inner()),\n                     Annotatable::Expr(expr) => token::NtExpr(expr),\n-                }))).into();\n+                })), DUMMY_SP).into();\n                 let input = self.extract_proc_macro_attr_input(attr.tokens, attr.span);\n                 let tok_result = mac.expand(self.cx, attr.span, input, item_tok);\n                 let res = self.parse_ast_fragment(tok_result, invoc.fragment_kind,"}, {"sha": "d25339a78f43c1f56bd243b6dabf6326c264f4e0", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -270,7 +270,7 @@ pub fn compile(\n         quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n             tts: vec![\n                 quoted::TokenTree::MetaVarDecl(DUMMY_SP, lhs_nm, ast::Ident::from_str(\"tt\")),\n-                quoted::TokenTree::token(DUMMY_SP, token::FatArrow),\n+                quoted::TokenTree::token(token::FatArrow, DUMMY_SP),\n                 quoted::TokenTree::MetaVarDecl(DUMMY_SP, rhs_nm, ast::Ident::from_str(\"tt\")),\n             ],\n             separator: Some(if body.legacy { token::Semi } else { token::Comma }),\n@@ -279,7 +279,7 @@ pub fn compile(\n         })),\n         // to phase into semicolon-termination instead of semicolon-separation\n         quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n-            tts: vec![quoted::TokenTree::token(DUMMY_SP, token::Semi)],\n+            tts: vec![quoted::TokenTree::token(token::Semi, DUMMY_SP)],\n             separator: None,\n             op: quoted::KleeneOp::ZeroOrMore,\n             num_captures: 0\n@@ -613,7 +613,7 @@ impl FirstSets {\n \n                         if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n                                                         subfirst.maybe_empty) {\n-                            first.add_one_maybe(TokenTree::token(sp.entire(), sep.clone()));\n+                            first.add_one_maybe(TokenTree::token(sep.clone(), sp.entire()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n@@ -663,7 +663,7 @@ impl FirstSets {\n \n                             if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n                                                             subfirst.maybe_empty) {\n-                                first.add_one_maybe(TokenTree::token(sp.entire(), sep.clone()));\n+                                first.add_one_maybe(TokenTree::token(sep.clone(), sp.entire()));\n                             }\n \n                             assert!(first.maybe_empty);\n@@ -869,7 +869,7 @@ fn check_matcher_core(sess: &ParseSess,\n                 let mut new;\n                 let my_suffix = if let Some(ref u) = seq_rep.separator {\n                     new = suffix_first.clone();\n-                    new.add_one_maybe(TokenTree::token(sp.entire(), u.clone()));\n+                    new.add_one_maybe(TokenTree::token(u.clone(), sp.entire()));\n                     &new\n                 } else {\n                     &suffix_first"}, {"sha": "b4672fb4a58b74534bdd1b13f56657895b3820e3", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -40,7 +40,7 @@ impl Delimited {\n         } else {\n             span.with_lo(span.lo() + BytePos(self.delim.len() as u32))\n         };\n-        TokenTree::token(open_span, self.open_token())\n+        TokenTree::token(self.open_token(), open_span)\n     }\n \n     /// Returns a `self::TokenTree` with a `Span` corresponding to the closing delimiter.\n@@ -50,7 +50,7 @@ impl Delimited {\n         } else {\n             span.with_lo(span.hi() - BytePos(self.delim.len() as u32))\n         };\n-        TokenTree::token(close_span, self.close_token())\n+        TokenTree::token(self.close_token(), close_span)\n     }\n }\n \n@@ -153,7 +153,7 @@ impl TokenTree {\n         }\n     }\n \n-    crate fn token(span: Span, kind: TokenKind) -> TokenTree {\n+    crate fn token(kind: TokenKind, span: Span) -> TokenTree {\n         TokenTree::Token(Token::new(kind, span))\n     }\n }\n@@ -325,7 +325,7 @@ where\n                 let (ident, is_raw) = token.ident().unwrap();\n                 let span = ident.span.with_lo(span.lo());\n                 if ident.name == kw::Crate && !is_raw {\n-                    TokenTree::token(span, token::Ident(kw::DollarCrate, is_raw))\n+                    TokenTree::token(token::Ident(kw::DollarCrate, is_raw), span)\n                 } else {\n                     TokenTree::MetaVar(span, ident)\n                 }\n@@ -342,7 +342,7 @@ where\n             }\n \n             // There are no more tokens. Just return the `$` we already have.\n-            None => TokenTree::token(span, token::Dollar),\n+            None => TokenTree::token(token::Dollar, span),\n         },\n \n         // `tree` is an arbitrary token. Keep it."}, {"sha": "b382893ce4ece0aff8ee02cf00064944c5379357", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -119,7 +119,7 @@ pub fn transcribe(\n                             Some((tt, _)) => tt.span(),\n                             None => DUMMY_SP,\n                         };\n-                        result.push(TokenTree::token(prev_span, sep).into());\n+                        result.push(TokenTree::token(sep, prev_span).into());\n                     }\n                     continue;\n                 }\n@@ -225,7 +225,7 @@ pub fn transcribe(\n                             result.push(tt.clone().into());\n                         } else {\n                             sp = sp.apply_mark(cx.current_expansion.mark);\n-                            let token = TokenTree::token(sp, token::Interpolated(nt.clone()));\n+                            let token = TokenTree::token(token::Interpolated(nt.clone()), sp);\n                             result.push(token.into());\n                         }\n                     } else {\n@@ -241,8 +241,8 @@ pub fn transcribe(\n                     let ident =\n                         Ident::new(ident.name, ident.span.apply_mark(cx.current_expansion.mark));\n                     sp = sp.apply_mark(cx.current_expansion.mark);\n-                    result.push(TokenTree::token(sp, token::Dollar).into());\n-                    result.push(TokenTree::token(sp, token::TokenKind::from_ast_ident(ident)).into());\n+                    result.push(TokenTree::token(token::Dollar, sp).into());\n+                    result.push(TokenTree::token(token::TokenKind::from_ast_ident(ident), sp).into());\n                 }\n             }\n "}, {"sha": "d83b76f4d236610be39f7408e1bea25d4dece762", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -157,7 +157,7 @@ impl<'a> Parser<'a> {\n                self.check(&token::OpenDelim(DelimToken::Brace)) {\n                    self.parse_token_tree().into()\n             } else if self.eat(&token::Eq) {\n-                let eq = TokenTree::token(self.prev_span, token::Eq);\n+                let eq = TokenTree::token(token::Eq, self.prev_span);\n                 let mut is_interpolated_expr = false;\n                 if let token::Interpolated(nt) = &self.token.kind {\n                     if let token::NtExpr(..) = **nt {"}, {"sha": "4979a4dd27f4a39fecda7c18a9511b88f6dc38c5", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -261,7 +261,7 @@ impl Lit {\n             token::Bool => token::Ident(self.token.symbol, false),\n             _ => token::Literal(self.token),\n         };\n-        TokenTree::token(self.span, token).into()\n+        TokenTree::token(token, self.span).into()\n     }\n }\n "}, {"sha": "8d3518d0373686b8eb28b0c0e25234803e670cbf", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -476,23 +476,23 @@ mod tests {\n             let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n \n             let expected = TokenStream::new(vec![\n-                TokenTree::token(sp(0, 2), token::Ident(kw::Fn, false)).into(),\n-                TokenTree::token(sp(3, 4), token::Ident(Name::intern(\"a\"), false)).into(),\n+                TokenTree::token(token::Ident(kw::Fn, false), sp(0, 2)).into(),\n+                TokenTree::token(token::Ident(Name::intern(\"a\"), false), sp(3, 4)).into(),\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(5, 6), sp(13, 14)),\n                     token::DelimToken::Paren,\n                     TokenStream::new(vec![\n-                        TokenTree::token(sp(6, 7), token::Ident(Name::intern(\"b\"), false)).into(),\n-                        TokenTree::token(sp(8, 9), token::Colon).into(),\n-                        TokenTree::token(sp(10, 13), token::Ident(sym::i32, false)).into(),\n+                        TokenTree::token(token::Ident(Name::intern(\"b\"), false), sp(6, 7)).into(),\n+                        TokenTree::token(token::Colon, sp(8, 9)).into(),\n+                        TokenTree::token(token::Ident(sym::i32, false), sp(10, 13)).into(),\n                     ]).into(),\n                 ).into(),\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(15, 16), sp(20, 21)),\n                     token::DelimToken::Brace,\n                     TokenStream::new(vec![\n-                        TokenTree::token(sp(17, 18), token::Ident(Name::intern(\"b\"), false)).into(),\n-                        TokenTree::token(sp(18, 19), token::Semi).into(),\n+                        TokenTree::token(token::Ident(Name::intern(\"b\"), false), sp(17, 18)).into(),\n+                        TokenTree::token(token::Semi, sp(18, 19)).into(),\n                     ]).into(),\n                 ).into()\n             ]);"}, {"sha": "e9e908eb858c876f3a8fdd0f271e734354999a28", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -362,11 +362,11 @@ impl TokenCursor {\n             delim_span,\n             token::Bracket,\n             [\n-                TokenTree::token(sp, token::Ident(sym::doc, false)),\n-                TokenTree::token(sp, token::Eq),\n-                TokenTree::token(sp, token::TokenKind::lit(\n+                TokenTree::token(token::Ident(sym::doc, false), sp),\n+                TokenTree::token(token::Eq, sp),\n+                TokenTree::token(token::TokenKind::lit(\n                     token::StrRaw(num_of_hashes), Symbol::intern(&stripped), None\n-                )),\n+                ), sp),\n             ]\n             .iter().cloned().collect::<TokenStream>().into(),\n         );\n@@ -375,10 +375,10 @@ impl TokenCursor {\n             delim_span,\n             token::NoDelim,\n             &if doc_comment_style(&name.as_str()) == AttrStyle::Inner {\n-                [TokenTree::token(sp, token::Pound), TokenTree::token(sp, token::Not), body]\n+                [TokenTree::token(token::Pound, sp), TokenTree::token(token::Not, sp), body]\n                     .iter().cloned().collect::<TokenStream>().into()\n             } else {\n-                [TokenTree::token(sp, token::Pound), body]\n+                [TokenTree::token(token::Pound, sp), body]\n                     .iter().cloned().collect::<TokenStream>().into()\n             },\n         )));\n@@ -4344,7 +4344,7 @@ impl<'a> Parser<'a> {\n                     };\n                     TokenStream::new(vec![\n                         args.into(),\n-                        TokenTree::token(token_lo.to(self.prev_span), token::FatArrow).into(),\n+                        TokenTree::token(token::FatArrow, token_lo.to(self.prev_span)).into(),\n                         body.into(),\n                     ])\n                 } else {"}, {"sha": "58c30a07e3e1bc7f21dad99dcbc35a5f38cc925d", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -763,10 +763,10 @@ impl Nonterminal {\n                 prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span)\n             }\n             Nonterminal::NtIdent(ident, is_raw) => {\n-                Some(TokenTree::token(ident.span, Ident(ident.name, is_raw)).into())\n+                Some(TokenTree::token(Ident(ident.name, is_raw), ident.span).into())\n             }\n             Nonterminal::NtLifetime(ident) => {\n-                Some(TokenTree::token(ident.span, Lifetime(ident.name)).into())\n+                Some(TokenTree::token(Lifetime(ident.name), ident.span).into())\n             }\n             Nonterminal::NtTT(ref tt) => {\n                 Some(tt.clone().into())\n@@ -852,7 +852,7 @@ fn prepend_attrs(sess: &ParseSess,\n         if attr.path.segments.len() == 1 && attr.path.segments[0].args.is_none() {\n             let ident = attr.path.segments[0].ident;\n             let token = Ident(ident.name, ident.as_str().starts_with(\"r#\"));\n-            brackets.push(tokenstream::TokenTree::token(ident.span, token));\n+            brackets.push(tokenstream::TokenTree::token(token, ident.span));\n \n         // ... and for more complicated paths, fall back to a reparse hack that\n         // should eventually be removed.\n@@ -866,7 +866,7 @@ fn prepend_attrs(sess: &ParseSess,\n         // The span we list here for `#` and for `[ ... ]` are both wrong in\n         // that it encompasses more than each token, but it hopefully is \"good\n         // enough\" for now at least.\n-        builder.push(tokenstream::TokenTree::token(attr.span, Pound));\n+        builder.push(tokenstream::TokenTree::token(Pound, attr.span));\n         let delim_span = DelimSpan::from_single(attr.span);\n         builder.push(tokenstream::TokenTree::Delimited(\n             delim_span, DelimToken::Bracket, brackets.build().into()));"}, {"sha": "b4643229285cde97a070333c5b723e2e9f1cdaf9", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -138,7 +138,7 @@ impl TokenTree {\n         TokenStream::new(vec![(self, Joint)])\n     }\n \n-    pub fn token(span: Span, kind: TokenKind) -> TokenTree {\n+    pub fn token(kind: TokenKind, span: Span) -> TokenTree {\n         TokenTree::Token(Token::new(kind, span))\n     }\n \n@@ -149,7 +149,7 @@ impl TokenTree {\n         } else {\n             span.with_hi(span.lo() + BytePos(delim.len() as u32))\n         };\n-        TokenTree::token(open_span, token::OpenDelim(delim))\n+        TokenTree::token(token::OpenDelim(delim), open_span)\n     }\n \n     /// Returns the closing delimiter as a token tree.\n@@ -159,7 +159,7 @@ impl TokenTree {\n         } else {\n             span.with_lo(span.hi() - BytePos(delim.len() as u32))\n         };\n-        TokenTree::token(close_span, token::CloseDelim(delim))\n+        TokenTree::token(token::CloseDelim(delim), close_span)\n     }\n }\n \n@@ -212,7 +212,7 @@ impl TokenStream {\n                         _ => continue,\n                     };\n                     let sp = sp.shrink_to_hi();\n-                    let comma = (TokenTree::token(sp, token::Comma), NonJoint);\n+                    let comma = (TokenTree::token(token::Comma, sp), NonJoint);\n                     suggestion = Some((pos, comma, sp));\n                 }\n             }\n@@ -433,7 +433,7 @@ impl TokenStreamBuilder {\n                     let last_stream = self.0.pop().unwrap();\n                     self.push_all_but_last_tree(&last_stream);\n                     let glued_span = last_token.span.to(token.span);\n-                    let glued_tt = TokenTree::token(glued_span, glued_tok);\n+                    let glued_tt = TokenTree::token(glued_tok, glued_span);\n                     let glued_tokenstream = TokenStream::new(vec![(glued_tt, is_joint)]);\n                     self.0.push(glued_tokenstream);\n                     self.push_all_but_first_tree(&stream);\n@@ -660,7 +660,7 @@ mod tests {\n         with_default_globals(|| {\n             let test0: TokenStream = Vec::<TokenTree>::new().into_iter().collect();\n             let test1: TokenStream =\n-                TokenTree::token(sp(0, 1), token::Ident(Name::intern(\"a\"), false)).into();\n+                TokenTree::token(token::Ident(Name::intern(\"a\"), false), sp(0, 1)).into();\n             let test2 = string_to_ts(\"foo(bar::baz)\");\n \n             assert_eq!(test0.is_empty(), true);\n@@ -673,9 +673,9 @@ mod tests {\n     fn test_dotdotdot() {\n         with_default_globals(|| {\n             let mut builder = TokenStreamBuilder::new();\n-            builder.push(TokenTree::token(sp(0, 1), token::Dot).joint());\n-            builder.push(TokenTree::token(sp(1, 2), token::Dot).joint());\n-            builder.push(TokenTree::token(sp(2, 3), token::Dot));\n+            builder.push(TokenTree::token(token::Dot, sp(0, 1)).joint());\n+            builder.push(TokenTree::token(token::Dot, sp(1, 2)).joint());\n+            builder.push(TokenTree::token(token::Dot, sp(2, 3)));\n             let stream = builder.build();\n             assert!(stream.eq_unspanned(&string_to_ts(\"...\")));\n             assert_eq!(stream.trees().count(), 1);"}, {"sha": "ce1e3276af39bacc453d6da2d18301fb8cea7d5f", "filename": "src/libsyntax_ext/assert.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax_ext%2Fassert.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax_ext%2Fassert.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fassert.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -30,11 +30,11 @@ pub fn expand_assert<'cx>(\n         path: Path::from_ident(Ident::new(sym::panic, sp)),\n         tts: custom_message.unwrap_or_else(|| {\n             TokenStream::from(TokenTree::token(\n-                DUMMY_SP,\n                 TokenKind::lit(token::Str, Symbol::intern(&format!(\n                     \"assertion failed: {}\",\n                     pprust::expr_to_string(&cond_expr).escape_debug()\n                 )), None),\n+                DUMMY_SP,\n             ))\n         }).into(),\n         delim: MacDelimiter::Parenthesis,"}, {"sha": "98465d75e4680e9d31beb6665f871e22e0ade22b", "filename": "src/libsyntax_ext/deriving/custom.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -69,7 +69,7 @@ impl MultiItemModifier for ProcMacroDerive {\n         MarkAttrs(&self.attrs).visit_item(&item);\n \n         let token = token::Interpolated(Lrc::new(token::NtItem(item)));\n-        let input = tokenstream::TokenTree::token(DUMMY_SP, token).into();\n+        let input = tokenstream::TokenTree::token(token, DUMMY_SP).into();\n \n         let server = proc_macro_server::Rustc::new(ecx);\n         let stream = match self.client.run(&EXEC_STRATEGY, server, input) {"}, {"sha": "00a420d3fa89922c9cd1758a5a99c9163e3700ac", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/67ce3f458939e6fe073bca6128526cb23f0797ba/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=67ce3f458939e6fe073bca6128526cb23f0797ba", "patch": "@@ -163,7 +163,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n                     TokenKind::lit(token::Str, Symbol::intern(&escaped), None),\n                 ]\n                 .into_iter()\n-                .map(|kind| tokenstream::TokenTree::token(span, kind))\n+                .map(|kind| tokenstream::TokenTree::token(kind, span))\n                 .collect();\n                 stack.push(TokenTree::Group(Group {\n                     delimiter: Delimiter::Bracket,\n@@ -210,7 +210,7 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n                 .into();\n             }\n             TokenTree::Ident(self::Ident { sym, is_raw, span }) => {\n-                return tokenstream::TokenTree::token(span, Ident(sym, is_raw)).into();\n+                return tokenstream::TokenTree::token(Ident(sym, is_raw), span).into();\n             }\n             TokenTree::Literal(self::Literal {\n                 lit: token::Lit { kind: token::Integer, symbol, suffix },\n@@ -219,8 +219,8 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n                 let minus = BinOp(BinOpToken::Minus);\n                 let symbol = Symbol::intern(&symbol.as_str()[1..]);\n                 let integer = TokenKind::lit(token::Integer, symbol, suffix);\n-                let a = tokenstream::TokenTree::token(span, minus);\n-                let b = tokenstream::TokenTree::token(span, integer);\n+                let a = tokenstream::TokenTree::token(minus, span);\n+                let b = tokenstream::TokenTree::token(integer, span);\n                 return vec![a, b].into_iter().collect();\n             }\n             TokenTree::Literal(self::Literal {\n@@ -230,12 +230,12 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n                 let minus = BinOp(BinOpToken::Minus);\n                 let symbol = Symbol::intern(&symbol.as_str()[1..]);\n                 let float = TokenKind::lit(token::Float, symbol, suffix);\n-                let a = tokenstream::TokenTree::token(span, minus);\n-                let b = tokenstream::TokenTree::token(span, float);\n+                let a = tokenstream::TokenTree::token(minus, span);\n+                let b = tokenstream::TokenTree::token(float, span);\n                 return vec![a, b].into_iter().collect();\n             }\n             TokenTree::Literal(self::Literal { lit, span }) => {\n-                return tokenstream::TokenTree::token(span, Literal(lit)).into()\n+                return tokenstream::TokenTree::token(Literal(lit), span).into()\n             }\n         };\n \n@@ -265,7 +265,7 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n             _ => unreachable!(),\n         };\n \n-        let tree = tokenstream::TokenTree::token(span, kind);\n+        let tree = tokenstream::TokenTree::token(kind, span);\n         TokenStream::new(vec![(tree, if joint { Joint } else { NonJoint })])\n     }\n }"}]}