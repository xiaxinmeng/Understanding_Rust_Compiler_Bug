{"sha": "88de2e111504439f76315548dd3e442999b46e95", "node_id": "C_kwDOAAsO6NoAKDg4ZGUyZTExMTUwNDQzOWY3NjMxNTU0OGRkM2U0NDI5OTliNDZlOTU", "commit": {"author": {"name": "yukang", "email": "moorekang@gmail.com", "date": "2023-02-22T06:09:57Z"}, "committer": {"name": "yukang", "email": "moorekang@gmail.com", "date": "2023-02-28T07:57:17Z"}, "message": "no need to return unmatched_delims from tokentrees", "tree": {"sha": "be975670d4d641d28ee45969c941664b276754f1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/be975670d4d641d28ee45969c941664b276754f1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/88de2e111504439f76315548dd3e442999b46e95", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/88de2e111504439f76315548dd3e442999b46e95", "html_url": "https://github.com/rust-lang/rust/commit/88de2e111504439f76315548dd3e442999b46e95", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/88de2e111504439f76315548dd3e442999b46e95/comments", "author": {"login": "chenyukang", "id": 230646, "node_id": "MDQ6VXNlcjIzMDY0Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/230646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenyukang", "html_url": "https://github.com/chenyukang", "followers_url": "https://api.github.com/users/chenyukang/followers", "following_url": "https://api.github.com/users/chenyukang/following{/other_user}", "gists_url": "https://api.github.com/users/chenyukang/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenyukang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenyukang/subscriptions", "organizations_url": "https://api.github.com/users/chenyukang/orgs", "repos_url": "https://api.github.com/users/chenyukang/repos", "events_url": "https://api.github.com/users/chenyukang/events{/privacy}", "received_events_url": "https://api.github.com/users/chenyukang/received_events", "type": "User", "site_admin": false}, "committer": {"login": "chenyukang", "id": 230646, "node_id": "MDQ6VXNlcjIzMDY0Ng==", "avatar_url": "https://avatars.githubusercontent.com/u/230646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenyukang", "html_url": "https://github.com/chenyukang", "followers_url": "https://api.github.com/users/chenyukang/followers", "following_url": "https://api.github.com/users/chenyukang/following{/other_user}", "gists_url": "https://api.github.com/users/chenyukang/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenyukang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenyukang/subscriptions", "organizations_url": "https://api.github.com/users/chenyukang/orgs", "repos_url": "https://api.github.com/users/chenyukang/repos", "events_url": "https://api.github.com/users/chenyukang/events{/privacy}", "received_events_url": "https://api.github.com/users/chenyukang/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9ce7472db46f62bbc328dbe9e627d4a85a11913c", "url": "https://api.github.com/repos/rust-lang/rust/commits/9ce7472db46f62bbc328dbe9e627d4a85a11913c", "html_url": "https://github.com/rust-lang/rust/commit/9ce7472db46f62bbc328dbe9e627d4a85a11913c"}], "stats": {"total": 17, "additions": 6, "deletions": 11}, "files": [{"sha": "480d95b77e901f540c12fd1a560fdf1f342b8fe1", "filename": "compiler/rustc_expand/src/tests.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/88de2e111504439f76315548dd3e442999b46e95/compiler%2Frustc_expand%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/88de2e111504439f76315548dd3e442999b46e95/compiler%2Frustc_expand%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Ftests.rs?ref=88de2e111504439f76315548dd3e442999b46e95", "patch": "@@ -43,7 +43,6 @@ pub(crate) fn string_to_stream(source_str: String) -> TokenStream {\n         ps.source_map().new_source_file(PathBuf::from(\"bogofile\").into(), source_str),\n         None,\n     )\n-    .0\n }\n \n /// Parses a string, returns a crate."}, {"sha": "eede09910108325c5d6e454df66f357b064b66eb", "filename": "compiler/rustc_parse/src/lib.rs", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/88de2e111504439f76315548dd3e442999b46e95/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/88de2e111504439f76315548dd3e442999b46e95/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flib.rs?ref=88de2e111504439f76315548dd3e442999b46e95", "patch": "@@ -30,7 +30,7 @@ pub const MACRO_ARGUMENTS: Option<&str> = Some(\"macro arguments\");\n \n #[macro_use]\n pub mod parser;\n-use parser::{emit_unclosed_delims, make_unclosed_delims_error, Parser};\n+use parser::{make_unclosed_delims_error, Parser};\n pub mod lexer;\n pub mod validate_attr;\n \n@@ -96,10 +96,7 @@ pub fn parse_stream_from_source_str(\n     sess: &ParseSess,\n     override_span: Option<Span>,\n ) -> TokenStream {\n-    let (stream, mut errors) =\n-        source_file_to_stream(sess, sess.source_map().new_source_file(name, source), override_span);\n-    emit_unclosed_delims(&mut errors, &sess);\n-    stream\n+    source_file_to_stream(sess, sess.source_map().new_source_file(name, source), override_span)\n }\n \n /// Creates a new parser from a source string.\n@@ -135,9 +132,8 @@ fn maybe_source_file_to_parser(\n     source_file: Lrc<SourceFile>,\n ) -> Result<Parser<'_>, Vec<Diagnostic>> {\n     let end_pos = source_file.end_pos;\n-    let (stream, unclosed_delims) = maybe_file_to_stream(sess, source_file, None)?;\n+    let stream = maybe_file_to_stream(sess, source_file, None)?;\n     let mut parser = stream_to_parser(sess, stream, None);\n-    parser.unclosed_delims = unclosed_delims;\n     if parser.token == token::Eof {\n         parser.token.span = Span::new(end_pos, end_pos, parser.token.span.ctxt(), None);\n     }\n@@ -182,7 +178,7 @@ pub fn source_file_to_stream(\n     sess: &ParseSess,\n     source_file: Lrc<SourceFile>,\n     override_span: Option<Span>,\n-) -> (TokenStream, Vec<lexer::UnmatchedDelim>) {\n+) -> TokenStream {\n     panictry_buffer!(&sess.span_diagnostic, maybe_file_to_stream(sess, source_file, override_span))\n }\n \n@@ -192,7 +188,7 @@ pub fn maybe_file_to_stream(\n     sess: &ParseSess,\n     source_file: Lrc<SourceFile>,\n     override_span: Option<Span>,\n-) -> Result<(TokenStream, Vec<lexer::UnmatchedDelim>), Vec<Diagnostic>> {\n+) -> Result<TokenStream, Vec<Diagnostic>> {\n     let src = source_file.src.as_ref().unwrap_or_else(|| {\n         sess.span_diagnostic.bug(&format!(\n             \"cannot lex `source_file` without source: {}\",\n@@ -204,7 +200,7 @@ pub fn maybe_file_to_stream(\n         lexer::parse_token_trees(sess, src.as_str(), source_file.start_pos, override_span);\n \n     match token_trees {\n-        Ok(stream) if unmatched_delims.is_empty() => Ok((stream, unmatched_delims)),\n+        Ok(stream) if unmatched_delims.is_empty() => Ok(stream),\n         _ => {\n             // Return error if there are unmatched delimiters or unclosng delimiters.\n             // We emit delimiter mismatch errors first, then emit the unclosing delimiter mismatch"}]}