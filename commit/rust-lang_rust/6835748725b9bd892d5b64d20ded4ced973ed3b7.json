{"sha": "6835748725b9bd892d5b64d20ded4ced973ed3b7", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY4MzU3NDg3MjViOWJkODkyZDViNjRkMjBkZWQ0Y2VkOTczZWQzYjc=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-05-22T04:17:20Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-05-22T04:17:20Z"}, "message": "Auto merge of #50838 - alexcrichton:token-impls, r=eddyb\n\nrustc: Fix joint-ness of stringified token-streams\n\nThis commit fixes `StringReader`'s parsing of tokens which have been stringified\nthrough procedural macros. Whether or not a token tree is joint is defined by\nspan information, but when working with procedural macros these spans are often\ndummy and/or overridden which means that they end up considering all operators\njoint if they can!\n\nThe fix here is to track the raw source span as opposed to the overridden span.\nWith this information we can more accurately classify `Punct` structs as either\njoint or not.\n\nCloses #50700", "tree": {"sha": "4b7efcf3ff5f1606042ee091ad22fd7c77690c0f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4b7efcf3ff5f1606042ee091ad22fd7c77690c0f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6835748725b9bd892d5b64d20ded4ced973ed3b7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6835748725b9bd892d5b64d20ded4ced973ed3b7", "html_url": "https://github.com/rust-lang/rust/commit/6835748725b9bd892d5b64d20ded4ced973ed3b7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6835748725b9bd892d5b64d20ded4ced973ed3b7/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "38fd7ea50adf894ae6235abba883ea9981996af9", "url": "https://api.github.com/repos/rust-lang/rust/commits/38fd7ea50adf894ae6235abba883ea9981996af9", "html_url": "https://github.com/rust-lang/rust/commit/38fd7ea50adf894ae6235abba883ea9981996af9"}, {"sha": "0ee031ab9668c52c05e189c4e9380901d7d1e579", "url": "https://api.github.com/repos/rust-lang/rust/commits/0ee031ab9668c52c05e189c4e9380901d7d1e579", "html_url": "https://github.com/rust-lang/rust/commit/0ee031ab9668c52c05e189c4e9380901d7d1e579"}], "stats": {"total": 134, "additions": 117, "deletions": 17}, "files": [{"sha": "a9dd234e1adc8dce3e2acbf665f4b90b11011dea", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 28, "deletions": 6, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=6835748725b9bd892d5b64d20ded4ced973ed3b7", "patch": "@@ -34,7 +34,10 @@ pub struct TokenAndSpan {\n \n impl Default for TokenAndSpan {\n     fn default() -> Self {\n-        TokenAndSpan { tok: token::Whitespace, sp: syntax_pos::DUMMY_SP }\n+        TokenAndSpan {\n+            tok: token::Whitespace,\n+            sp: syntax_pos::DUMMY_SP,\n+        }\n     }\n }\n \n@@ -54,22 +57,30 @@ pub struct StringReader<'a> {\n     /// If part of a filemap is being re-lexed, this should be set to false.\n     pub save_new_lines_and_multibyte: bool,\n     // cached:\n-    pub peek_tok: token::Token,\n-    pub peek_span: Span,\n+    peek_tok: token::Token,\n+    peek_span: Span,\n+    peek_span_src_raw: Span,\n     pub fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.filemap.src.as_ref().unwrap()` all the time.\n     src: Lrc<String>,\n     /// Stack of open delimiters and their spans. Used for error message.\n     token: token::Token,\n     span: Span,\n+    /// The raw source span which *does not* take `override_span` into account\n+    span_src_raw: Span,\n     open_braces: Vec<(token::DelimToken, Span)>,\n     pub override_span: Option<Span>,\n }\n \n impl<'a> StringReader<'a> {\n     fn mk_sp(&self, lo: BytePos, hi: BytePos) -> Span {\n-        unwrap_or!(self.override_span, Span::new(lo, hi, NO_EXPANSION))\n+        self.mk_sp_and_raw(lo, hi).0\n+    }\n+    fn mk_sp_and_raw(&self, lo: BytePos, hi: BytePos) -> (Span, Span) {\n+        let raw = Span::new(lo, hi, NO_EXPANSION);\n+        let real = unwrap_or!(self.override_span, raw);\n+        (real, raw)\n     }\n     fn mk_ident(&self, string: &str) -> Ident {\n         let mut ident = Ident::from_str(string);\n@@ -121,6 +132,7 @@ impl<'a> StringReader<'a> {\n             sp: self.peek_span,\n         };\n         self.advance_token()?;\n+        self.span_src_raw = self.peek_span_src_raw;\n         Ok(ret_val)\n     }\n \n@@ -182,10 +194,12 @@ impl<'a> StringReader<'a> {\n             // dummy values; not read\n             peek_tok: token::Eof,\n             peek_span: syntax_pos::DUMMY_SP,\n+            peek_span_src_raw: syntax_pos::DUMMY_SP,\n             src,\n             fatal_errs: Vec::new(),\n             token: token::Eof,\n             span: syntax_pos::DUMMY_SP,\n+            span_src_raw: syntax_pos::DUMMY_SP,\n             open_braces: Vec::new(),\n             override_span,\n         }\n@@ -328,17 +342,25 @@ impl<'a> StringReader<'a> {\n     fn advance_token(&mut self) -> Result<(), ()> {\n         match self.scan_whitespace_or_comment() {\n             Some(comment) => {\n+                self.peek_span_src_raw = comment.sp;\n                 self.peek_span = comment.sp;\n                 self.peek_tok = comment.tok;\n             }\n             None => {\n                 if self.is_eof() {\n                     self.peek_tok = token::Eof;\n-                    self.peek_span = self.mk_sp(self.filemap.end_pos, self.filemap.end_pos);\n+                    let (real, raw) = self.mk_sp_and_raw(\n+                        self.filemap.end_pos,\n+                        self.filemap.end_pos,\n+                    );\n+                    self.peek_span = real;\n+                    self.peek_span_src_raw = raw;\n                 } else {\n                     let start_bytepos = self.pos;\n                     self.peek_tok = self.next_token_inner()?;\n-                    self.peek_span = self.mk_sp(start_bytepos, self.pos);\n+                    let (real, raw) = self.mk_sp_and_raw(start_bytepos, self.pos);\n+                    self.peek_span = real;\n+                    self.peek_span_src_raw = raw;\n                 };\n             }\n         }"}, {"sha": "278b8c991f7b8a7c04b60fc844fc44c9031a8eac", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 12, "deletions": 11, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=6835748725b9bd892d5b64d20ded4ced973ed3b7", "patch": "@@ -18,9 +18,7 @@ impl<'a> StringReader<'a> {\n     pub fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n         let mut tts = Vec::new();\n         while self.token != token::Eof {\n-            let tree = self.parse_token_tree()?;\n-            let is_joint = tree.span().hi() == self.span.lo() && token::is_op(&self.token);\n-            tts.push(if is_joint { tree.joint() } else { tree.into() });\n+            tts.push(self.parse_token_tree()?);\n         }\n         Ok(TokenStream::concat(tts))\n     }\n@@ -32,19 +30,17 @@ impl<'a> StringReader<'a> {\n             if let token::CloseDelim(..) = self.token {\n                 return TokenStream::concat(tts);\n             }\n-            let tree = match self.parse_token_tree() {\n-                Ok(tree) => tree,\n+            match self.parse_token_tree() {\n+                Ok(tree) => tts.push(tree),\n                 Err(mut e) => {\n                     e.emit();\n                     return TokenStream::concat(tts);\n                 }\n-            };\n-            let is_joint = tree.span().hi() == self.span.lo() && token::is_op(&self.token);\n-            tts.push(if is_joint { tree.joint() } else { tree.into() });\n+            }\n         }\n     }\n \n-    fn parse_token_tree(&mut self) -> PResult<'a, TokenTree> {\n+    fn parse_token_tree(&mut self) -> PResult<'a, TokenStream> {\n         match self.token {\n             token::Eof => {\n                 let msg = \"this file contains an un-closed delimiter\";\n@@ -115,7 +111,7 @@ impl<'a> StringReader<'a> {\n                 Ok(TokenTree::Delimited(span, Delimited {\n                     delim,\n                     tts: tts.into(),\n-                }))\n+                }).into())\n             },\n             token::CloseDelim(_) => {\n                 // An unexpected closing delimiter (i.e., there is no\n@@ -127,8 +123,13 @@ impl<'a> StringReader<'a> {\n             },\n             _ => {\n                 let tt = TokenTree::Token(self.span, self.token.clone());\n+                // Note that testing for joint-ness here is done via the raw\n+                // source span as the joint-ness is a property of the raw source\n+                // rather than wanting to take `override_span` into account.\n+                let raw = self.span_src_raw;\n                 self.real_token();\n-                Ok(tt)\n+                let is_joint = raw.hi() == self.span_src_raw.lo() && token::is_op(&self.token);\n+                Ok(if is_joint { tt.joint() } else { tt.into() })\n             }\n         }\n     }"}, {"sha": "034be6a6864ce48de8baae31f305f726f86f5b52", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=6835748725b9bd892d5b64d20ded4ced973ed3b7", "patch": "@@ -581,6 +581,8 @@ impl Token {\n             if tokens.probably_equal_for_proc_macro(&tokens_for_real) {\n                 return tokens\n             }\n+            info!(\"cached tokens found, but they're not \\\"probably equal\\\", \\\n+                   going with stringified version\");\n         }\n         return tokens_for_real\n     }"}, {"sha": "062a914534f13c13082a9d87ba82675d9042f95d", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/not-joint.rs", "status": "added", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnot-joint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnot-joint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnot-joint.rs?ref=6835748725b9bd892d5b64d20ded4ced973ed3b7", "patch": "@@ -0,0 +1,40 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// no-prefer-dynamic\n+\n+#![crate_type = \"proc-macro\"]\n+#![feature(proc_macro)]\n+\n+extern crate proc_macro;\n+\n+use proc_macro::*;\n+\n+#[proc_macro]\n+pub fn tokens(input: TokenStream) -> TokenStream {\n+    assert_nothing_joint(input);\n+    TokenStream::empty()\n+}\n+\n+#[proc_macro_attribute]\n+pub fn nothing(_: TokenStream, input: TokenStream) -> TokenStream {\n+    assert_nothing_joint(input);\n+    TokenStream::empty()\n+}\n+\n+fn assert_nothing_joint(s: TokenStream) {\n+    for tt in s {\n+        match tt {\n+            TokenTree::Group(g) => assert_nothing_joint(g.stream()),\n+            TokenTree::Punct(p) => assert_eq!(p.spacing(), Spacing::Alone),\n+            _ => {}\n+        }\n+    }\n+}"}, {"sha": "34dfae9f1580a9e9baf9ff98da4a75d1f9c2d828", "filename": "src/test/run-pass-fulldeps/proc-macro/not-joint.rs", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fnot-joint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6835748725b9bd892d5b64d20ded4ced973ed3b7/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fnot-joint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fnot-joint.rs?ref=6835748725b9bd892d5b64d20ded4ced973ed3b7", "patch": "@@ -0,0 +1,35 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:not-joint.rs\n+\n+#![feature(proc_macro)]\n+\n+extern crate not_joint as bar;\n+use bar::{tokens, nothing};\n+\n+tokens![< -];\n+\n+#[nothing]\n+a![< -];\n+\n+#[nothing]\n+b!{< -}\n+\n+#[nothing]\n+c!(< -);\n+\n+#[nothing]\n+fn foo() {\n+    //! dox\n+    let x = 2 < - 3;\n+}\n+\n+fn main() {}"}]}