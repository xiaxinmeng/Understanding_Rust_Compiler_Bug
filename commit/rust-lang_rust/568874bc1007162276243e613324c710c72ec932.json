{"sha": "568874bc1007162276243e613324c710c72ec932", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU2ODg3NGJjMTAwNzE2MjI3NjI0M2U2MTMzMjRjNzEwYzcyZWM5MzI=", "commit": {"author": {"name": "Mark-Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2016-11-07T02:37:56Z"}, "committer": {"name": "Mark-Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2016-11-12T13:42:40Z"}, "message": "Cleanup macro_parser::parse, removing a few clones.", "tree": {"sha": "1d2a48d6c56cb66305fffc8273e3c9fe37a50e0e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1d2a48d6c56cb66305fffc8273e3c9fe37a50e0e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/568874bc1007162276243e613324c710c72ec932", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/568874bc1007162276243e613324c710c72ec932", "html_url": "https://github.com/rust-lang/rust/commit/568874bc1007162276243e613324c710c72ec932", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/568874bc1007162276243e613324c710c72ec932/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f3af8c8505255555023e4cb7c6c4f297ce22d80d", "url": "https://api.github.com/repos/rust-lang/rust/commits/f3af8c8505255555023e4cb7c6c4f297ce22d80d", "html_url": "https://github.com/rust-lang/rust/commit/f3af8c8505255555023e4cb7c6c4f297ce22d80d"}], "stats": {"total": 86, "additions": 35, "deletions": 51}, "files": [{"sha": "da9692391dd87942df4041d2f1b815b7907f8276", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 35, "deletions": 51, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/568874bc1007162276243e613324c710c72ec932/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/568874bc1007162276243e613324c710c72ec932/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=568874bc1007162276243e613324c710c72ec932", "patch": "@@ -287,15 +287,8 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n         let mut next_eis = Vec::new(); // or proceed normally\n         let mut eof_eis = Vec::new();\n \n-        let (sp, tok) = (parser.span, parser.token.clone());\n-\n-        /* we append new items to this while we go */\n-        loop {\n-            let mut ei = match cur_eis.pop() {\n-                None => break, /* for each Earley Item */\n-                Some(ei) => ei,\n-            };\n-\n+        // for each Earley item\n+        while let Some(mut ei) = cur_eis.pop() {\n             // When unzipped trees end, remove them\n             while ei.idx >= ei.top_elts.len() {\n                 match ei.stack.pop() {\n@@ -317,7 +310,6 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n                     // hack: a matcher sequence is repeating iff it has a\n                     // parent (the top level is just a container)\n \n-\n                     // disregard separator, try to go up\n                     // (remove this condition to make trailing seps ok)\n                     if idx == len {\n@@ -334,10 +326,10 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n \n                         // Only touch the binders we have actually bound\n                         for idx in ei.match_lo..ei.match_hi {\n-                            let sub = (ei.matches[idx]).clone();\n-                            (&mut new_pos.matches[idx])\n+                            let sub = ei.matches[idx].clone();\n+                            new_pos.matches[idx]\n                                    .push(Rc::new(MatchedSeq(sub, mk_sp(ei.sp_lo,\n-                                                                       sp.hi))));\n+                                                                       parser.span.hi))));\n                         }\n \n                         new_pos.match_cur = ei.match_hi;\n@@ -347,25 +339,21 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n \n                     // can we go around again?\n \n-                    // the *_t vars are workarounds for the lack of unary move\n-                    match ei.sep {\n-                        Some(ref t) if idx == len => { // we need a separator\n-                            // i'm conflicted about whether this should be hygienic....\n-                            // though in this case, if the separators are never legal\n-                            // idents, it shouldn't matter.\n-                            if token_name_eq(&tok, t) { //pass the separator\n-                                let mut ei_t = ei.clone();\n-                                // ei_t.match_cur = ei_t.match_lo;\n-                                ei_t.idx += 1;\n-                                next_eis.push(ei_t);\n-                            }\n-                        }\n-                        _ => { // we don't need a separator\n-                            let mut ei_t = ei;\n-                            ei_t.match_cur = ei_t.match_lo;\n-                            ei_t.idx = 0;\n-                            cur_eis.push(ei_t);\n+                    // Check if we need a separator\n+                    if idx == len && ei.sep.is_some() {\n+                        if ei.sep.as_ref().map(|ref sep| token_name_eq(&parser.token, sep))\n+                            .unwrap_or(false) {\n+                            // i'm conflicted about whether this should be hygienic....  though in\n+                            // this case, if the separators are never legal idents, it shouldn't\n+                            // matter.\n+                            // ei.match_cur = ei.match_lo;\n+                            ei.idx += 1;\n+                            next_eis.push(ei);\n                         }\n+                    } else { // we don't need a separator\n+                        ei.match_cur = ei.match_lo;\n+                        ei.idx = 0;\n+                        cur_eis.push(ei);\n                     }\n                 } else {\n                     eof_eis.push(ei);\n@@ -380,32 +368,31 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n                             new_ei.idx += 1;\n                             //we specifically matched zero repeats.\n                             for idx in ei.match_cur..ei.match_cur + seq.num_captures {\n-                                (&mut new_ei.matches[idx]).push(Rc::new(MatchedSeq(vec![], sp)));\n+                                new_ei.matches[idx].push(Rc::new(MatchedSeq(vec![], sp)));\n                             }\n \n                             cur_eis.push(new_ei);\n                         }\n \n                         let matches: Vec<_> = (0..ei.matches.len())\n                             .map(|_| Vec::new()).collect();\n-                        let ei_t = ei;\n                         cur_eis.push(Box::new(MatcherPos {\n                             stack: vec![],\n                             sep: seq.separator.clone(),\n                             idx: 0,\n                             matches: matches,\n-                            match_lo: ei_t.match_cur,\n-                            match_cur: ei_t.match_cur,\n-                            match_hi: ei_t.match_cur + seq.num_captures,\n-                            up: Some(ei_t),\n+                            match_lo: ei.match_cur,\n+                            match_cur: ei.match_cur,\n+                            match_hi: ei.match_cur + seq.num_captures,\n+                            up: Some(ei),\n                             sp_lo: sp.lo,\n                             top_elts: Tt(TokenTree::Sequence(sp, seq)),\n                         }));\n                     }\n                     TokenTree::Token(_, MatchNt(..)) => {\n                         // Built-in nonterminals never start with these tokens,\n                         // so we can eliminate them from consideration.\n-                        match tok {\n+                        match parser.token {\n                             token::CloseDelim(_) => {},\n                             _ => bb_eis.push(ei),\n                         }\n@@ -424,28 +411,25 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n                         cur_eis.push(ei);\n                     }\n                     TokenTree::Token(_, ref t) => {\n-                        if token_name_eq(t,&tok) {\n-                            let mut ei_t = ei.clone();\n-                            ei_t.idx += 1;\n-                            next_eis.push(ei_t);\n+                        if token_name_eq(t, &parser.token) {\n+                            ei.idx += 1;\n+                            next_eis.push(ei);\n                         }\n                     }\n                 }\n             }\n         }\n \n         /* error messages here could be improved with links to orig. rules */\n-        if token_name_eq(&tok, &token::Eof) {\n+        if token_name_eq(&parser.token, &token::Eof) {\n             if eof_eis.len() == 1 {\n-                let mut v = Vec::new();\n-                for dv in &mut (&mut eof_eis[0]).matches {\n-                    v.push(dv.pop().unwrap());\n-                }\n+                let v = eof_eis[0].matches.iter_mut()\n+                    .map(|dv| dv.pop().unwrap()).collect::<Vec<_>>();\n                 return nameize(sess, ms, &v[..]);\n             } else if eof_eis.len() > 1 {\n-                return Error(sp, \"ambiguity: multiple successful parses\".to_string());\n+                return Error(parser.span, \"ambiguity: multiple successful parses\".to_string());\n             } else {\n-                return Failure(sp, token::Eof);\n+                return Failure(parser.span, token::Eof);\n             }\n         } else {\n             if (!bb_eis.is_empty() && !next_eis.is_empty())\n@@ -457,7 +441,7 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n                     _ => panic!()\n                 }).collect::<Vec<String>>().join(\" or \");\n \n-                return Error(sp, format!(\n+                return Error(parser.span, format!(\n                     \"local ambiguity: multiple parsing options: {}\",\n                     match next_eis.len() {\n                         0 => format!(\"built-in NTs {}.\", nts),\n@@ -466,7 +450,7 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n                     }\n                 ))\n             } else if bb_eis.is_empty() && next_eis.is_empty() {\n-                return Failure(sp, tok);\n+                return Failure(parser.span, parser.token);\n             } else if !next_eis.is_empty() {\n                 /* Now process the next token */\n                 while !next_eis.is_empty() {"}]}