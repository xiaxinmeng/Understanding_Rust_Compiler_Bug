{"sha": "457a7a83c13fd803b47a5842686cee13eba47d6e", "node_id": "C_kwDOAAsO6NoAKDQ1N2E3YTgzYzEzZmQ4MDNiNDdhNTg0MjY4NmNlZTEzZWJhNDdkNmU", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2023-05-05T09:44:37Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2023-05-05T09:44:37Z"}, "message": "Auto merge of #2876 - RalfJung:varnames, r=RalfJung\n\nclearer variable names in data_race", "tree": {"sha": "c17749f3580912897fc1610b6cc50e891db3a098", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c17749f3580912897fc1610b6cc50e891db3a098"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/457a7a83c13fd803b47a5842686cee13eba47d6e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/457a7a83c13fd803b47a5842686cee13eba47d6e", "html_url": "https://github.com/rust-lang/rust/commit/457a7a83c13fd803b47a5842686cee13eba47d6e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/457a7a83c13fd803b47a5842686cee13eba47d6e/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "42b14dc22313a9e21572f8c9de0f776164eefb42", "url": "https://api.github.com/repos/rust-lang/rust/commits/42b14dc22313a9e21572f8c9de0f776164eefb42", "html_url": "https://github.com/rust-lang/rust/commit/42b14dc22313a9e21572f8c9de0f776164eefb42"}, {"sha": "fd308627acd6a6481a28e9e50a9ca80b66298045", "url": "https://api.github.com/repos/rust-lang/rust/commits/fd308627acd6a6481a28e9e50a9ca80b66298045", "html_url": "https://github.com/rust-lang/rust/commit/fd308627acd6a6481a28e9e50a9ca80b66298045"}], "stats": {"total": 172, "additions": 98, "deletions": 74}, "files": [{"sha": "9e4411afe9a17096949ba9800d790f75bd779a0a", "filename": "src/tools/miri/src/concurrency/data_race.rs", "status": "modified", "additions": 96, "deletions": 70, "changes": 166, "blob_url": "https://github.com/rust-lang/rust/blob/457a7a83c13fd803b47a5842686cee13eba47d6e/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fdata_race.rs", "raw_url": "https://github.com/rust-lang/rust/raw/457a7a83c13fd803b47a5842686cee13eba47d6e/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fdata_race.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fdata_race.rs?ref=457a7a83c13fd803b47a5842686cee13eba47d6e", "patch": "@@ -275,20 +275,20 @@ impl MemoryCellClocks {\n     /// not used previously as atomic memory.\n     fn load_acquire(\n         &mut self,\n-        clocks: &mut ThreadClockSet,\n+        thread_clocks: &mut ThreadClockSet,\n         index: VectorIdx,\n     ) -> Result<(), DataRace> {\n-        self.atomic_read_detect(clocks, index)?;\n+        self.atomic_read_detect(thread_clocks, index)?;\n         if let Some(atomic) = self.atomic() {\n-            clocks.clock.join(&atomic.sync_vector);\n+            thread_clocks.clock.join(&atomic.sync_vector);\n         }\n         Ok(())\n     }\n \n     /// Checks if the memory cell access is ordered with all prior atomic reads and writes\n-    fn race_free_with_atomic(&self, clocks: &ThreadClockSet) -> bool {\n+    fn race_free_with_atomic(&self, thread_clocks: &ThreadClockSet) -> bool {\n         if let Some(atomic) = self.atomic() {\n-            atomic.read_vector <= clocks.clock && atomic.write_vector <= clocks.clock\n+            atomic.read_vector <= thread_clocks.clock && atomic.write_vector <= thread_clocks.clock\n         } else {\n             true\n         }\n@@ -299,81 +299,97 @@ impl MemoryCellClocks {\n     /// not used previously as atomic memory.\n     fn load_relaxed(\n         &mut self,\n-        clocks: &mut ThreadClockSet,\n+        thread_clocks: &mut ThreadClockSet,\n         index: VectorIdx,\n     ) -> Result<(), DataRace> {\n-        self.atomic_read_detect(clocks, index)?;\n+        self.atomic_read_detect(thread_clocks, index)?;\n         if let Some(atomic) = self.atomic() {\n-            clocks.fence_acquire.join(&atomic.sync_vector);\n+            thread_clocks.fence_acquire.join(&atomic.sync_vector);\n         }\n         Ok(())\n     }\n \n     /// Update the memory cell data-race tracking for atomic\n     /// store release semantics.\n-    fn store_release(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n-        self.atomic_write_detect(clocks, index)?;\n+    fn store_release(\n+        &mut self,\n+        thread_clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n+        self.atomic_write_detect(thread_clocks, index)?;\n         let atomic = self.atomic_mut();\n-        atomic.sync_vector.clone_from(&clocks.clock);\n+        atomic.sync_vector.clone_from(&thread_clocks.clock);\n         Ok(())\n     }\n \n     /// Update the memory cell data-race tracking for atomic\n     /// store relaxed semantics.\n-    fn store_relaxed(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n-        self.atomic_write_detect(clocks, index)?;\n+    fn store_relaxed(\n+        &mut self,\n+        thread_clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n+        self.atomic_write_detect(thread_clocks, index)?;\n \n         // The handling of release sequences was changed in C++20 and so\n         // the code here is different to the paper since now all relaxed\n         // stores block release sequences. The exception for same-thread\n         // relaxed stores has been removed.\n         let atomic = self.atomic_mut();\n-        atomic.sync_vector.clone_from(&clocks.fence_release);\n+        atomic.sync_vector.clone_from(&thread_clocks.fence_release);\n         Ok(())\n     }\n \n     /// Update the memory cell data-race tracking for atomic\n     /// store release semantics for RMW operations.\n-    fn rmw_release(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n-        self.atomic_write_detect(clocks, index)?;\n+    fn rmw_release(\n+        &mut self,\n+        thread_clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n+        self.atomic_write_detect(thread_clocks, index)?;\n         let atomic = self.atomic_mut();\n-        atomic.sync_vector.join(&clocks.clock);\n+        atomic.sync_vector.join(&thread_clocks.clock);\n         Ok(())\n     }\n \n     /// Update the memory cell data-race tracking for atomic\n     /// store relaxed semantics for RMW operations.\n-    fn rmw_relaxed(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n-        self.atomic_write_detect(clocks, index)?;\n+    fn rmw_relaxed(\n+        &mut self,\n+        thread_clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n+        self.atomic_write_detect(thread_clocks, index)?;\n         let atomic = self.atomic_mut();\n-        atomic.sync_vector.join(&clocks.fence_release);\n+        atomic.sync_vector.join(&thread_clocks.fence_release);\n         Ok(())\n     }\n \n     /// Detect data-races with an atomic read, caused by a non-atomic write that does\n     /// not happen-before the atomic-read.\n     fn atomic_read_detect(\n         &mut self,\n-        clocks: &ThreadClockSet,\n+        thread_clocks: &ThreadClockSet,\n         index: VectorIdx,\n     ) -> Result<(), DataRace> {\n-        log::trace!(\"Atomic read with vectors: {:#?} :: {:#?}\", self, clocks);\n+        log::trace!(\"Atomic read with vectors: {:#?} :: {:#?}\", self, thread_clocks);\n         let atomic = self.atomic_mut();\n-        atomic.read_vector.set_at_index(&clocks.clock, index);\n-        if self.write <= clocks.clock[self.write_index] { Ok(()) } else { Err(DataRace) }\n+        atomic.read_vector.set_at_index(&thread_clocks.clock, index);\n+        if self.write <= thread_clocks.clock[self.write_index] { Ok(()) } else { Err(DataRace) }\n     }\n \n     /// Detect data-races with an atomic write, either with a non-atomic read or with\n     /// a non-atomic write.\n     fn atomic_write_detect(\n         &mut self,\n-        clocks: &ThreadClockSet,\n+        thread_clocks: &ThreadClockSet,\n         index: VectorIdx,\n     ) -> Result<(), DataRace> {\n-        log::trace!(\"Atomic write with vectors: {:#?} :: {:#?}\", self, clocks);\n+        log::trace!(\"Atomic write with vectors: {:#?} :: {:#?}\", self, thread_clocks);\n         let atomic = self.atomic_mut();\n-        atomic.write_vector.set_at_index(&clocks.clock, index);\n-        if self.write <= clocks.clock[self.write_index] && self.read <= clocks.clock {\n+        atomic.write_vector.set_at_index(&thread_clocks.clock, index);\n+        if self.write <= thread_clocks.clock[self.write_index] && self.read <= thread_clocks.clock {\n             Ok(())\n         } else {\n             Err(DataRace)\n@@ -384,21 +400,21 @@ impl MemoryCellClocks {\n     /// returns true if a data-race is detected.\n     fn read_race_detect(\n         &mut self,\n-        clocks: &mut ThreadClockSet,\n+        thread_clocks: &mut ThreadClockSet,\n         index: VectorIdx,\n         current_span: Span,\n     ) -> Result<(), DataRace> {\n-        log::trace!(\"Unsynchronized read with vectors: {:#?} :: {:#?}\", self, clocks);\n+        log::trace!(\"Unsynchronized read with vectors: {:#?} :: {:#?}\", self, thread_clocks);\n         if !current_span.is_dummy() {\n-            clocks.clock[index].span = current_span;\n+            thread_clocks.clock[index].span = current_span;\n         }\n-        if self.write <= clocks.clock[self.write_index] {\n+        if self.write <= thread_clocks.clock[self.write_index] {\n             let race_free = if let Some(atomic) = self.atomic() {\n-                atomic.write_vector <= clocks.clock\n+                atomic.write_vector <= thread_clocks.clock\n             } else {\n                 true\n             };\n-            self.read.set_at_index(&clocks.clock, index);\n+            self.read.set_at_index(&thread_clocks.clock, index);\n             if race_free { Ok(()) } else { Err(DataRace) }\n         } else {\n             Err(DataRace)\n@@ -409,22 +425,23 @@ impl MemoryCellClocks {\n     /// returns true if a data-race is detected.\n     fn write_race_detect(\n         &mut self,\n-        clocks: &mut ThreadClockSet,\n+        thread_clocks: &mut ThreadClockSet,\n         index: VectorIdx,\n         write_type: WriteType,\n         current_span: Span,\n     ) -> Result<(), DataRace> {\n-        log::trace!(\"Unsynchronized write with vectors: {:#?} :: {:#?}\", self, clocks);\n+        log::trace!(\"Unsynchronized write with vectors: {:#?} :: {:#?}\", self, thread_clocks);\n         if !current_span.is_dummy() {\n-            clocks.clock[index].span = current_span;\n+            thread_clocks.clock[index].span = current_span;\n         }\n-        if self.write <= clocks.clock[self.write_index] && self.read <= clocks.clock {\n+        if self.write <= thread_clocks.clock[self.write_index] && self.read <= thread_clocks.clock {\n             let race_free = if let Some(atomic) = self.atomic() {\n-                atomic.write_vector <= clocks.clock && atomic.read_vector <= clocks.clock\n+                atomic.write_vector <= thread_clocks.clock\n+                    && atomic.read_vector <= thread_clocks.clock\n             } else {\n                 true\n             };\n-            self.write = clocks.clock[index];\n+            self.write = thread_clocks.clock[index];\n             self.write_index = index;\n             self.write_type = write_type;\n             if race_free {\n@@ -764,24 +781,24 @@ impl VClockAlloc {\n     fn report_data_race<'tcx>(\n         global: &GlobalState,\n         thread_mgr: &ThreadManager<'_, '_>,\n-        range: &MemoryCellClocks,\n+        mem_clocks: &MemoryCellClocks,\n         action: &str,\n         is_atomic: bool,\n         ptr_dbg: Pointer<AllocId>,\n     ) -> InterpResult<'tcx> {\n         let (current_index, current_clocks) = global.current_thread_state(thread_mgr);\n         let write_clock;\n-        let (other_action, other_thread, other_clock) = if range.write\n-            > current_clocks.clock[range.write_index]\n+        let (other_action, other_thread, other_clock) = if mem_clocks.write\n+            > current_clocks.clock[mem_clocks.write_index]\n         {\n             // Convert the write action into the vector clock it\n             // represents for diagnostic purposes.\n-            write_clock = VClock::new_with_index(range.write_index, range.write);\n-            (range.write_type.get_descriptor(), range.write_index, &write_clock)\n-        } else if let Some(idx) = Self::find_gt_index(&range.read, &current_clocks.clock) {\n-            (\"Read\", idx, &range.read)\n+            write_clock = VClock::new_with_index(mem_clocks.write_index, mem_clocks.write);\n+            (mem_clocks.write_type.get_descriptor(), mem_clocks.write_index, &write_clock)\n+        } else if let Some(idx) = Self::find_gt_index(&mem_clocks.read, &current_clocks.clock) {\n+            (\"Read\", idx, &mem_clocks.read)\n         } else if !is_atomic {\n-            if let Some(atomic) = range.atomic() {\n+            if let Some(atomic) = mem_clocks.atomic() {\n                 if let Some(idx) = Self::find_gt_index(&atomic.write_vector, &current_clocks.clock)\n                 {\n                     (\"Atomic Store\", idx, &atomic.write_vector)\n@@ -832,10 +849,10 @@ impl VClockAlloc {\n         thread_mgr: &ThreadManager<'_, '_>,\n     ) -> bool {\n         if global.race_detecting() {\n-            let (_, clocks) = global.current_thread_state(thread_mgr);\n+            let (_, thread_clocks) = global.current_thread_state(thread_mgr);\n             let alloc_ranges = self.alloc_ranges.borrow();\n-            for (_, range) in alloc_ranges.iter(range.start, range.size) {\n-                if !range.race_free_with_atomic(&clocks) {\n+            for (_, mem_clocks) in alloc_ranges.iter(range.start, range.size) {\n+                if !mem_clocks.race_free_with_atomic(&thread_clocks) {\n                     return false;\n                 }\n             }\n@@ -857,16 +874,18 @@ impl VClockAlloc {\n         let current_span = machine.current_span();\n         let global = machine.data_race.as_ref().unwrap();\n         if global.race_detecting() {\n-            let (index, mut clocks) = global.current_thread_state_mut(&machine.threads);\n+            let (index, mut thread_clocks) = global.current_thread_state_mut(&machine.threads);\n             let mut alloc_ranges = self.alloc_ranges.borrow_mut();\n-            for (offset, range) in alloc_ranges.iter_mut(range.start, range.size) {\n-                if let Err(DataRace) = range.read_race_detect(&mut clocks, index, current_span) {\n-                    drop(clocks);\n+            for (offset, mem_clocks) in alloc_ranges.iter_mut(range.start, range.size) {\n+                if let Err(DataRace) =\n+                    mem_clocks.read_race_detect(&mut thread_clocks, index, current_span)\n+                {\n+                    drop(thread_clocks);\n                     // Report data-race.\n                     return Self::report_data_race(\n                         global,\n                         &machine.threads,\n-                        range,\n+                        mem_clocks,\n                         \"Read\",\n                         false,\n                         Pointer::new(alloc_id, offset),\n@@ -890,17 +909,22 @@ impl VClockAlloc {\n         let current_span = machine.current_span();\n         let global = machine.data_race.as_mut().unwrap();\n         if global.race_detecting() {\n-            let (index, mut clocks) = global.current_thread_state_mut(&machine.threads);\n-            for (offset, range) in self.alloc_ranges.get_mut().iter_mut(range.start, range.size) {\n-                if let Err(DataRace) =\n-                    range.write_race_detect(&mut clocks, index, write_type, current_span)\n-                {\n-                    drop(clocks);\n+            let (index, mut thread_clocks) = global.current_thread_state_mut(&machine.threads);\n+            for (offset, mem_clocks) in\n+                self.alloc_ranges.get_mut().iter_mut(range.start, range.size)\n+            {\n+                if let Err(DataRace) = mem_clocks.write_race_detect(\n+                    &mut thread_clocks,\n+                    index,\n+                    write_type,\n+                    current_span,\n+                ) {\n+                    drop(thread_clocks);\n                     // Report data-race\n                     return Self::report_data_race(\n                         global,\n                         &machine.threads,\n-                        range,\n+                        mem_clocks,\n                         write_type.get_descriptor(),\n                         false,\n                         Pointer::new(alloc_id, offset),\n@@ -1125,16 +1149,17 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriInterpCxExt<'mir, 'tcx> {\n                 data_race.maybe_perform_sync_operation(\n                     &this.machine.threads,\n                     current_span,\n-                    |index, mut clocks| {\n-                        for (offset, range) in\n+                    |index, mut thread_clocks| {\n+                        for (offset, mem_clocks) in\n                             alloc_meta.alloc_ranges.borrow_mut().iter_mut(base_offset, size)\n                         {\n-                            if let Err(DataRace) = op(range, &mut clocks, index, atomic) {\n-                                mem::drop(clocks);\n+                            if let Err(DataRace) = op(mem_clocks, &mut thread_clocks, index, atomic)\n+                            {\n+                                mem::drop(thread_clocks);\n                                 return VClockAlloc::report_data_race(\n                                     data_race,\n                                     &this.machine.threads,\n-                                    range,\n+                                    mem_clocks,\n                                     description,\n                                     true,\n                                     Pointer::new(alloc_id, offset),\n@@ -1150,13 +1175,14 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriInterpCxExt<'mir, 'tcx> {\n \n                 // Log changes to atomic memory.\n                 if log::log_enabled!(log::Level::Trace) {\n-                    for (_offset, range) in alloc_meta.alloc_ranges.borrow().iter(base_offset, size)\n+                    for (_offset, mem_clocks) in\n+                        alloc_meta.alloc_ranges.borrow().iter(base_offset, size)\n                     {\n                         log::trace!(\n                             \"Updated atomic memory({:?}, size={}) to {:#?}\",\n                             place.ptr,\n                             size.bytes(),\n-                            range.atomic_ops\n+                            mem_clocks.atomic_ops\n                         );\n                     }\n                 }"}, {"sha": "5da5497f9829f05773521bc80ffadb7f6753110c", "filename": "src/tools/miri/tests/pass/concurrency/windows_join_multiple.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/457a7a83c13fd803b47a5842686cee13eba47d6e/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fconcurrency%2Fwindows_join_multiple.rs", "raw_url": "https://github.com/rust-lang/rust/raw/457a7a83c13fd803b47a5842686cee13eba47d6e/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fconcurrency%2Fwindows_join_multiple.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fconcurrency%2Fwindows_join_multiple.rs?ref=457a7a83c13fd803b47a5842686cee13eba47d6e", "patch": "@@ -22,10 +22,8 @@ fn main() {\n     })\n     .into_raw_handle() as usize;\n \n-    let waiter = move || {\n-        unsafe {\n-            assert_eq!(WaitForSingleObject(blocker, INFINITE), 0);\n-        }\n+    let waiter = move || unsafe {\n+        assert_eq!(WaitForSingleObject(blocker, INFINITE), 0);\n     };\n \n     let waiter1 = thread::spawn(waiter);"}]}