{"sha": "b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "node_id": "C_kwDOAAsO6NoAKGI3YjdmMjcxNmVlMTY1NWE2OTZkM2Q2NGMzZTEyNjM4ZDBkZDE5YzA", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-11-11T04:54:59Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-11-11T04:54:59Z"}, "message": "Auto merge of #103898 - Nilstrieb:match-macro, r=nnethercote\n\nRetry failed macro matching for diagnostics\n\nWhen a declarative macro fails to match, retry the matching to collect diagnostic info instead of collecting it on the fly in the hot path. Split out of #103439.\n\nYou made a bunch of changes to declarative macro matching, so\nr? `@nnethercote`\n\nThis change should produce a few small perf wins: https://github.com/rust-lang/rust/pull/103439#issuecomment-1294249602", "tree": {"sha": "a90e272626aff80a1944b55da920c24f5c2e9de7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a90e272626aff80a1944b55da920c24f5c2e9de7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "html_url": "https://github.com/rust-lang/rust/commit/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5b82ea74b705799665b5a676b162f30d26f5108c", "url": "https://api.github.com/repos/rust-lang/rust/commits/5b82ea74b705799665b5a676b162f30d26f5108c", "html_url": "https://github.com/rust-lang/rust/commit/5b82ea74b705799665b5a676b162f30d26f5108c"}, {"sha": "ebfa2ab68e806ce4eecb09525b82724a064c1de3", "url": "https://api.github.com/repos/rust-lang/rust/commits/ebfa2ab68e806ce4eecb09525b82724a064c1de3", "html_url": "https://github.com/rust-lang/rust/commit/ebfa2ab68e806ce4eecb09525b82724a064c1de3"}], "stats": {"total": 432, "additions": 289, "deletions": 143}, "files": [{"sha": "63bafd7b046fb173275548d333b098ddfd4ab06a", "filename": "compiler/rustc_expand/src/mbe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs?ref=b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "patch": "@@ -52,7 +52,7 @@ impl KleeneToken {\n /// A Kleene-style [repetition operator](https://en.wikipedia.org/wiki/Kleene_star)\n /// for token sequences.\n #[derive(Clone, PartialEq, Encodable, Decodable, Debug, Copy)]\n-enum KleeneOp {\n+pub(crate) enum KleeneOp {\n     /// Kleene star (`*`) for zero or more repetitions\n     ZeroOrMore,\n     /// Kleene plus (`+`) for one or more repetitions"}, {"sha": "95cec8d7ae29992455c0e1ee9638ff941d5c71cc", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 32, "deletions": 21, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "patch": "@@ -73,17 +73,17 @@\n pub(crate) use NamedMatch::*;\n pub(crate) use ParseResult::*;\n \n-use crate::mbe::{KleeneOp, TokenTree};\n+use crate::mbe::{macro_rules::Tracker, KleeneOp, TokenTree};\n \n use rustc_ast::token::{self, DocComment, Nonterminal, NonterminalKind, Token};\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::sync::Lrc;\n+use rustc_errors::ErrorGuaranteed;\n use rustc_lint_defs::pluralize;\n use rustc_parse::parser::{NtOrTt, Parser};\n+use rustc_span::symbol::Ident;\n use rustc_span::symbol::MacroRulesNormalizedIdent;\n use rustc_span::Span;\n-\n-use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::Lrc;\n-use rustc_span::symbol::Ident;\n use std::borrow::Cow;\n use std::collections::hash_map::Entry::{Occupied, Vacant};\n \n@@ -96,7 +96,8 @@ use std::collections::hash_map::Entry::{Occupied, Vacant};\n ///\n /// This means a matcher can be represented by `&[MatcherLoc]`, and traversal mostly involves\n /// simply incrementing the current matcher position index by one.\n-pub(super) enum MatcherLoc {\n+#[derive(Debug)]\n+pub(crate) enum MatcherLoc {\n     Token {\n         token: Token,\n     },\n@@ -270,13 +271,17 @@ pub(crate) enum ParseResult<T> {\n     Failure(Token, &'static str),\n     /// Fatal error (malformed macro?). Abort compilation.\n     Error(rustc_span::Span, String),\n-    ErrorReported,\n+    ErrorReported(ErrorGuaranteed),\n }\n \n /// A `ParseResult` where the `Success` variant contains a mapping of\n /// `MacroRulesNormalizedIdent`s to `NamedMatch`es. This represents the mapping\n /// of metavars to the token trees they bind to.\n-pub(crate) type NamedParseResult = ParseResult<FxHashMap<MacroRulesNormalizedIdent, NamedMatch>>;\n+pub(crate) type NamedParseResult = ParseResult<NamedMatches>;\n+\n+/// Contains a mapping of `MacroRulesNormalizedIdent`s to `NamedMatch`es.\n+/// This represents the mapping of metavars to the token trees they bind to.\n+pub(crate) type NamedMatches = FxHashMap<MacroRulesNormalizedIdent, NamedMatch>;\n \n /// Count how many metavars declarations are in `matcher`.\n pub(super) fn count_metavar_decls(matcher: &[TokenTree]) -> usize {\n@@ -400,17 +405,21 @@ impl TtParser {\n     ///\n     /// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept\n     /// track of through the mps generated.\n-    fn parse_tt_inner(\n+    fn parse_tt_inner<'matcher, T: Tracker<'matcher>>(\n         &mut self,\n-        matcher: &[MatcherLoc],\n+        matcher: &'matcher [MatcherLoc],\n         token: &Token,\n+        track: &mut T,\n     ) -> Option<NamedParseResult> {\n         // Matcher positions that would be valid if the macro invocation was over now. Only\n         // modified if `token == Eof`.\n         let mut eof_mps = EofMatcherPositions::None;\n \n         while let Some(mut mp) = self.cur_mps.pop() {\n-            match &matcher[mp.idx] {\n+            let matcher_loc = &matcher[mp.idx];\n+            track.before_match_loc(self, matcher_loc);\n+\n+            match matcher_loc {\n                 MatcherLoc::Token { token: t } => {\n                     // If it's a doc comment, we just ignore it and move on to the next tt in the\n                     // matcher. This is a bug, but #95267 showed that existing programs rely on\n@@ -450,7 +459,7 @@ impl TtParser {\n                         // Try zero matches of this sequence, by skipping over it.\n                         self.cur_mps.push(MatcherPos {\n                             idx: idx_first_after,\n-                            matches: mp.matches.clone(), // a cheap clone\n+                            matches: Lrc::clone(&mp.matches),\n                         });\n                     }\n \n@@ -463,8 +472,8 @@ impl TtParser {\n                     // sequence. If that's not possible, `ending_mp` will fail quietly when it is\n                     // processed next time around the loop.\n                     let ending_mp = MatcherPos {\n-                        idx: mp.idx + 1,             // +1 skips the Kleene op\n-                        matches: mp.matches.clone(), // a cheap clone\n+                        idx: mp.idx + 1, // +1 skips the Kleene op\n+                        matches: Lrc::clone(&mp.matches),\n                     };\n                     self.cur_mps.push(ending_mp);\n \n@@ -479,8 +488,8 @@ impl TtParser {\n                     // separator yet. Try ending the sequence. If that's not possible, `ending_mp`\n                     // will fail quietly when it is processed next time around the loop.\n                     let ending_mp = MatcherPos {\n-                        idx: mp.idx + 2,             // +2 skips the separator and the Kleene op\n-                        matches: mp.matches.clone(), // a cheap clone\n+                        idx: mp.idx + 2, // +2 skips the separator and the Kleene op\n+                        matches: Lrc::clone(&mp.matches),\n                     };\n                     self.cur_mps.push(ending_mp);\n \n@@ -552,10 +561,11 @@ impl TtParser {\n     }\n \n     /// Match the token stream from `parser` against `matcher`.\n-    pub(super) fn parse_tt(\n+    pub(super) fn parse_tt<'matcher, T: Tracker<'matcher>>(\n         &mut self,\n         parser: &mut Cow<'_, Parser<'_>>,\n-        matcher: &[MatcherLoc],\n+        matcher: &'matcher [MatcherLoc],\n+        track: &mut T,\n     ) -> NamedParseResult {\n         // A queue of possible matcher positions. We initialize it with the matcher position in\n         // which the \"dot\" is before the first token of the first token tree in `matcher`.\n@@ -571,7 +581,8 @@ impl TtParser {\n \n             // Process `cur_mps` until either we have finished the input or we need to get some\n             // parsing from the black-box parser done.\n-            if let Some(res) = self.parse_tt_inner(matcher, &parser.token) {\n+            let res = self.parse_tt_inner(matcher, &parser.token, track);\n+            if let Some(res) = res {\n                 return res;\n             }\n \n@@ -612,14 +623,14 @@ impl TtParser {\n                         // edition-specific matching behavior for non-terminals.\n                         let nt = match parser.to_mut().parse_nonterminal(kind) {\n                             Err(mut err) => {\n-                                err.span_label(\n+                                let guarantee = err.span_label(\n                                     span,\n                                     format!(\n                                         \"while parsing argument for this `{kind}` macro fragment\"\n                                     ),\n                                 )\n                                 .emit();\n-                                return ErrorReported;\n+                                return ErrorReported(guarantee);\n                             }\n                             Ok(nt) => nt,\n                         };"}, {"sha": "99af91072882efc99011b95871c34c32e80a6be7", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 256, "deletions": 121, "changes": 377, "blob_url": "https://github.com/rust-lang/rust/blob/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b7b7f2716ee1655a696d3d64c3e12638d0dd19c0/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=b7b7f2716ee1655a696d3d64c3e12638d0dd19c0", "patch": "@@ -14,7 +14,9 @@ use rustc_ast::{NodeId, DUMMY_NODE_ID};\n use rustc_ast_pretty::pprust;\n use rustc_attr::{self as attr, TransparencyError};\n use rustc_data_structures::fx::{FxHashMap, FxIndexMap};\n-use rustc_errors::{Applicability, Diagnostic, DiagnosticBuilder, DiagnosticMessage};\n+use rustc_errors::{\n+    Applicability, Diagnostic, DiagnosticBuilder, DiagnosticMessage, ErrorGuaranteed,\n+};\n use rustc_feature::Features;\n use rustc_lint_defs::builtin::{\n     RUST_2021_INCOMPATIBLE_OR_PATTERNS, SEMICOLON_IN_EXPRESSIONS_FROM_MACROS,\n@@ -33,6 +35,8 @@ use std::borrow::Cow;\n use std::collections::hash_map::Entry;\n use std::{mem, slice};\n \n+use super::macro_parser::{NamedMatches, NamedParseResult};\n+\n pub(crate) struct ParserAnyMacro<'a> {\n     parser: Parser<'a>,\n \n@@ -205,8 +209,32 @@ fn trace_macros_note(cx_expansions: &mut FxIndexMap<Span, Vec<String>>, sp: Span\n     cx_expansions.entry(sp).or_default().push(message);\n }\n \n+pub(super) trait Tracker<'matcher> {\n+    /// This is called before trying to match next MatcherLoc on the current token.\n+    fn before_match_loc(&mut self, parser: &TtParser, matcher: &'matcher MatcherLoc);\n+\n+    /// This is called after an arm has been parsed, either successfully or unsuccessfully. When this is called,\n+    /// `before_match_loc` was called at least once (with a `MatcherLoc::Eof`).\n+    fn after_arm(&mut self, result: &NamedParseResult);\n+\n+    /// For tracing.\n+    fn description() -> &'static str;\n+}\n+\n+/// A noop tracker that is used in the hot path of the expansion, has zero overhead thanks to monomorphization.\n+struct NoopTracker;\n+\n+impl<'matcher> Tracker<'matcher> for NoopTracker {\n+    fn before_match_loc(&mut self, _: &TtParser, _: &'matcher MatcherLoc) {}\n+    fn after_arm(&mut self, _: &NamedParseResult) {}\n+    fn description() -> &'static str {\n+        \"none\"\n+    }\n+}\n+\n /// Expands the rules based macro defined by `lhses` and `rhses` for a given\n /// input `arg`.\n+#[instrument(skip(cx, transparency, arg, lhses, rhses))]\n fn expand_macro<'cx>(\n     cx: &'cx mut ExtCtxt<'_>,\n     sp: Span,\n@@ -228,9 +256,188 @@ fn expand_macro<'cx>(\n         trace_macros_note(&mut cx.expansions, sp, msg);\n     }\n \n-    // Which arm's failure should we report? (the one furthest along)\n-    let mut best_failure: Option<(Token, &str)> = None;\n+    // Track nothing for the best performance.\n+    let try_success_result = try_match_macro(sess, name, &arg, lhses, &mut NoopTracker);\n+\n+    match try_success_result {\n+        Ok((i, named_matches)) => {\n+            let (rhs, rhs_span): (&mbe::Delimited, DelimSpan) = match &rhses[i] {\n+                mbe::TokenTree::Delimited(span, delimited) => (&delimited, *span),\n+                _ => cx.span_bug(sp, \"malformed macro rhs\"),\n+            };\n+            let arm_span = rhses[i].span();\n+\n+            let rhs_spans = rhs.tts.iter().map(|t| t.span()).collect::<Vec<_>>();\n+            // rhs has holes ( `$id` and `$(...)` that need filled)\n+            let mut tts = match transcribe(cx, &named_matches, &rhs, rhs_span, transparency) {\n+                Ok(tts) => tts,\n+                Err(mut err) => {\n+                    err.emit();\n+                    return DummyResult::any(arm_span);\n+                }\n+            };\n+\n+            // Replace all the tokens for the corresponding positions in the macro, to maintain\n+            // proper positions in error reporting, while maintaining the macro_backtrace.\n+            if rhs_spans.len() == tts.len() {\n+                tts = tts.map_enumerated(|i, tt| {\n+                    let mut tt = tt.clone();\n+                    let mut sp = rhs_spans[i];\n+                    sp = sp.with_ctxt(tt.span().ctxt());\n+                    tt.set_span(sp);\n+                    tt\n+                });\n+            }\n+\n+            if cx.trace_macros() {\n+                let msg = format!(\"to `{}`\", pprust::tts_to_string(&tts));\n+                trace_macros_note(&mut cx.expansions, sp, msg);\n+            }\n+\n+            let mut p = Parser::new(sess, tts, false, None);\n+            p.last_type_ascription = cx.current_expansion.prior_type_ascription;\n+\n+            if is_local {\n+                cx.resolver.record_macro_rule_usage(node_id, i);\n+            }\n+\n+            // Let the context choose how to interpret the result.\n+            // Weird, but useful for X-macros.\n+            return Box::new(ParserAnyMacro {\n+                parser: p,\n+\n+                // Pass along the original expansion site and the name of the macro\n+                // so we can print a useful error message if the parse of the expanded\n+                // macro leaves unparsed tokens.\n+                site_span: sp,\n+                macro_ident: name,\n+                lint_node_id: cx.current_expansion.lint_node_id,\n+                is_trailing_mac: cx.current_expansion.is_trailing_mac,\n+                arm_span,\n+                is_local,\n+            });\n+        }\n+        Err(CanRetry::No(_)) => {\n+            debug!(\"Will not retry matching as an error was emitted already\");\n+            return DummyResult::any(sp);\n+        }\n+        Err(CanRetry::Yes) => {\n+            // Retry and emit a better error below.\n+        }\n+    }\n+\n+    // An error occurred, try the expansion again, tracking the expansion closely for better diagnostics.\n+    let mut tracker = CollectTrackerAndEmitter::new(cx, sp);\n+\n+    let try_success_result = try_match_macro(sess, name, &arg, lhses, &mut tracker);\n+    assert!(try_success_result.is_err(), \"Macro matching returned a success on the second try\");\n+\n+    if let Some(result) = tracker.result {\n+        // An irrecoverable error occured and has been emitted.\n+        return result;\n+    }\n+\n+    let Some((token, label)) = tracker.best_failure else {\n+        return tracker.result.expect(\"must have encountered Error or ErrorReported\");\n+    };\n+\n+    let span = token.span.substitute_dummy(sp);\n+\n+    let mut err = cx.struct_span_err(span, &parse_failure_msg(&token));\n+    err.span_label(span, label);\n+    if !def_span.is_dummy() && !cx.source_map().is_imported(def_span) {\n+        err.span_label(cx.source_map().guess_head_span(def_span), \"when calling this macro\");\n+    }\n+\n+    annotate_doc_comment(&mut err, sess.source_map(), span);\n+\n+    // Check whether there's a missing comma in this macro call, like `println!(\"{}\" a);`\n+    if let Some((arg, comma_span)) = arg.add_comma() {\n+        for lhs in lhses {\n+            let parser = parser_from_cx(sess, arg.clone());\n+            let mut tt_parser = TtParser::new(name);\n+\n+            if let Success(_) =\n+                tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs, &mut NoopTracker)\n+            {\n+                if comma_span.is_dummy() {\n+                    err.note(\"you might be missing a comma\");\n+                } else {\n+                    err.span_suggestion_short(\n+                        comma_span,\n+                        \"missing comma here\",\n+                        \", \",\n+                        Applicability::MachineApplicable,\n+                    );\n+                }\n+            }\n+        }\n+    }\n+    err.emit();\n+    cx.trace_macros_diag();\n+    DummyResult::any(sp)\n+}\n+\n+/// The tracker used for the slow error path that collects useful info for diagnostics.\n+struct CollectTrackerAndEmitter<'a, 'cx> {\n+    cx: &'a mut ExtCtxt<'cx>,\n+    /// Which arm's failure should we report? (the one furthest along)\n+    best_failure: Option<(Token, &'static str)>,\n+    root_span: Span,\n+    result: Option<Box<dyn MacResult + 'cx>>,\n+}\n+\n+impl<'a, 'cx, 'matcher> Tracker<'matcher> for CollectTrackerAndEmitter<'a, 'cx> {\n+    fn before_match_loc(&mut self, _parser: &TtParser, _matcher: &'matcher MatcherLoc) {\n+        // Empty for now.\n+    }\n+\n+    fn after_arm(&mut self, result: &NamedParseResult) {\n+        match result {\n+            Success(_) => {\n+                unreachable!(\"should not collect detailed info for successful macro match\");\n+            }\n+            Failure(token, msg) => match self.best_failure {\n+                Some((ref best_token, _)) if best_token.span.lo() >= token.span.lo() => {}\n+                _ => self.best_failure = Some((token.clone(), msg)),\n+            },\n+            Error(err_sp, msg) => {\n+                let span = err_sp.substitute_dummy(self.root_span);\n+                self.cx.struct_span_err(span, msg).emit();\n+                self.result = Some(DummyResult::any(span));\n+            }\n+            ErrorReported(_) => self.result = Some(DummyResult::any(self.root_span)),\n+        }\n+    }\n+\n+    fn description() -> &'static str {\n+        \"detailed\"\n+    }\n+}\n+\n+impl<'a, 'cx> CollectTrackerAndEmitter<'a, 'cx> {\n+    fn new(cx: &'a mut ExtCtxt<'cx>, root_span: Span) -> Self {\n+        Self { cx, best_failure: None, root_span, result: None }\n+    }\n+}\n+\n+enum CanRetry {\n+    Yes,\n+    /// We are not allowed to retry macro expansion as a fatal error has been emitted already.\n+    No(ErrorGuaranteed),\n+}\n \n+/// Try expanding the macro. Returns the index of the successful arm and its named_matches if it was successful,\n+/// and nothing if it failed. On failure, it's the callers job to use `track` accordingly to record all errors\n+/// correctly.\n+#[instrument(level = \"debug\", skip(sess, arg, lhses, track), fields(tracking = %T::description()))]\n+fn try_match_macro<'matcher, T: Tracker<'matcher>>(\n+    sess: &ParseSess,\n+    name: Ident,\n+    arg: &TokenStream,\n+    lhses: &'matcher [Vec<MatcherLoc>],\n+    track: &mut T,\n+) -> Result<(usize, NamedMatches), CanRetry> {\n     // We create a base parser that can be used for the \"black box\" parts.\n     // Every iteration needs a fresh copy of that parser. However, the parser\n     // is not mutated on many of the iterations, particularly when dealing with\n@@ -252,125 +459,52 @@ fn expand_macro<'cx>(\n     // this situation.)\n     // FIXME(Nilstrieb): Stop recovery from happening on this parser and retry later with recovery if the macro failed to match.\n     let parser = parser_from_cx(sess, arg.clone());\n-\n     // Try each arm's matchers.\n     let mut tt_parser = TtParser::new(name);\n     for (i, lhs) in lhses.iter().enumerate() {\n+        let _tracing_span = trace_span!(\"Matching arm\", %i);\n+\n         // Take a snapshot of the state of pre-expansion gating at this point.\n         // This is used so that if a matcher is not `Success(..)`ful,\n         // then the spans which became gated when parsing the unsuccessful matcher\n         // are not recorded. On the first `Success(..)`ful matcher, the spans are merged.\n         let mut gated_spans_snapshot = mem::take(&mut *sess.gated_spans.spans.borrow_mut());\n \n-        match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs) {\n+        let result = tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs, track);\n+\n+        track.after_arm(&result);\n+\n+        match result {\n             Success(named_matches) => {\n+                debug!(\"Parsed arm successfully\");\n                 // The matcher was `Success(..)`ful.\n                 // Merge the gated spans from parsing the matcher with the pre-existing ones.\n                 sess.gated_spans.merge(gated_spans_snapshot);\n \n-                let (rhs, rhs_span): (&mbe::Delimited, DelimSpan) = match &rhses[i] {\n-                    mbe::TokenTree::Delimited(span, delimited) => (&delimited, *span),\n-                    _ => cx.span_bug(sp, \"malformed macro rhs\"),\n-                };\n-                let arm_span = rhses[i].span();\n-\n-                let rhs_spans = rhs.tts.iter().map(|t| t.span()).collect::<Vec<_>>();\n-                // rhs has holes ( `$id` and `$(...)` that need filled)\n-                let mut tts = match transcribe(cx, &named_matches, &rhs, rhs_span, transparency) {\n-                    Ok(tts) => tts,\n-                    Err(mut err) => {\n-                        err.emit();\n-                        return DummyResult::any(arm_span);\n-                    }\n-                };\n-\n-                // Replace all the tokens for the corresponding positions in the macro, to maintain\n-                // proper positions in error reporting, while maintaining the macro_backtrace.\n-                if rhs_spans.len() == tts.len() {\n-                    tts = tts.map_enumerated(|i, tt| {\n-                        let mut tt = tt.clone();\n-                        let mut sp = rhs_spans[i];\n-                        sp = sp.with_ctxt(tt.span().ctxt());\n-                        tt.set_span(sp);\n-                        tt\n-                    });\n-                }\n-\n-                if cx.trace_macros() {\n-                    let msg = format!(\"to `{}`\", pprust::tts_to_string(&tts));\n-                    trace_macros_note(&mut cx.expansions, sp, msg);\n-                }\n-\n-                let mut p = Parser::new(sess, tts, false, None);\n-                p.last_type_ascription = cx.current_expansion.prior_type_ascription;\n-\n-                if is_local {\n-                    cx.resolver.record_macro_rule_usage(node_id, i);\n-                }\n-\n-                // Let the context choose how to interpret the result.\n-                // Weird, but useful for X-macros.\n-                return Box::new(ParserAnyMacro {\n-                    parser: p,\n-\n-                    // Pass along the original expansion site and the name of the macro\n-                    // so we can print a useful error message if the parse of the expanded\n-                    // macro leaves unparsed tokens.\n-                    site_span: sp,\n-                    macro_ident: name,\n-                    lint_node_id: cx.current_expansion.lint_node_id,\n-                    is_trailing_mac: cx.current_expansion.is_trailing_mac,\n-                    arm_span,\n-                    is_local,\n-                });\n+                return Ok((i, named_matches));\n             }\n-            Failure(token, msg) => match best_failure {\n-                Some((ref best_token, _)) if best_token.span.lo() >= token.span.lo() => {}\n-                _ => best_failure = Some((token, msg)),\n-            },\n-            Error(err_sp, ref msg) => {\n-                let span = err_sp.substitute_dummy(sp);\n-                cx.struct_span_err(span, &msg).emit();\n-                return DummyResult::any(span);\n+            Failure(_, _) => {\n+                trace!(\"Failed to match arm, trying the next one\");\n+                // Try the next arm.\n+            }\n+            Error(_, _) => {\n+                debug!(\"Fatal error occurred during matching\");\n+                // We haven't emitted an error yet, so we can retry.\n+                return Err(CanRetry::Yes);\n+            }\n+            ErrorReported(guarantee) => {\n+                debug!(\"Fatal error occurred and was reported during matching\");\n+                // An error has been reported already, we cannot retry as that would cause duplicate errors.\n+                return Err(CanRetry::No(guarantee));\n             }\n-            ErrorReported => return DummyResult::any(sp),\n         }\n \n         // The matcher was not `Success(..)`ful.\n         // Restore to the state before snapshotting and maybe try again.\n         mem::swap(&mut gated_spans_snapshot, &mut sess.gated_spans.spans.borrow_mut());\n     }\n-    drop(parser);\n \n-    let (token, label) = best_failure.expect(\"ran no matchers\");\n-    let span = token.span.substitute_dummy(sp);\n-    let mut err = cx.struct_span_err(span, &parse_failure_msg(&token));\n-    err.span_label(span, label);\n-    if !def_span.is_dummy() && !cx.source_map().is_imported(def_span) {\n-        err.span_label(cx.source_map().guess_head_span(def_span), \"when calling this macro\");\n-    }\n-    annotate_doc_comment(&mut err, sess.source_map(), span);\n-    // Check whether there's a missing comma in this macro call, like `println!(\"{}\" a);`\n-    if let Some((arg, comma_span)) = arg.add_comma() {\n-        for lhs in lhses {\n-            let parser = parser_from_cx(sess, arg.clone());\n-            if let Success(_) = tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs) {\n-                if comma_span.is_dummy() {\n-                    err.note(\"you might be missing a comma\");\n-                } else {\n-                    err.span_suggestion_short(\n-                        comma_span,\n-                        \"missing comma here\",\n-                        \", \",\n-                        Applicability::MachineApplicable,\n-                    );\n-                }\n-            }\n-        }\n-    }\n-    err.emit();\n-    cx.trace_macros_diag();\n-    DummyResult::any(sp)\n+    Err(CanRetry::Yes)\n }\n \n // Note that macro-by-example's input is also matched against a token tree:\n@@ -452,28 +586,29 @@ pub fn compile_declarative_macro(\n     let parser = Parser::new(&sess.parse_sess, body, true, rustc_parse::MACRO_ARGUMENTS);\n     let mut tt_parser =\n         TtParser::new(Ident::with_dummy_span(if macro_rules { kw::MacroRules } else { kw::Macro }));\n-    let argument_map = match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), &argument_gram) {\n-        Success(m) => m,\n-        Failure(token, msg) => {\n-            let s = parse_failure_msg(&token);\n-            let sp = token.span.substitute_dummy(def.span);\n-            let mut err = sess.parse_sess.span_diagnostic.struct_span_err(sp, &s);\n-            err.span_label(sp, msg);\n-            annotate_doc_comment(&mut err, sess.source_map(), sp);\n-            err.emit();\n-            return dummy_syn_ext();\n-        }\n-        Error(sp, msg) => {\n-            sess.parse_sess\n-                .span_diagnostic\n-                .struct_span_err(sp.substitute_dummy(def.span), &msg)\n-                .emit();\n-            return dummy_syn_ext();\n-        }\n-        ErrorReported => {\n-            return dummy_syn_ext();\n-        }\n-    };\n+    let argument_map =\n+        match tt_parser.parse_tt(&mut Cow::Owned(parser), &argument_gram, &mut NoopTracker) {\n+            Success(m) => m,\n+            Failure(token, msg) => {\n+                let s = parse_failure_msg(&token);\n+                let sp = token.span.substitute_dummy(def.span);\n+                let mut err = sess.parse_sess.span_diagnostic.struct_span_err(sp, &s);\n+                err.span_label(sp, msg);\n+                annotate_doc_comment(&mut err, sess.source_map(), sp);\n+                err.emit();\n+                return dummy_syn_ext();\n+            }\n+            Error(sp, msg) => {\n+                sess.parse_sess\n+                    .span_diagnostic\n+                    .struct_span_err(sp.substitute_dummy(def.span), &msg)\n+                    .emit();\n+                return dummy_syn_ext();\n+            }\n+            ErrorReported(_) => {\n+                return dummy_syn_ext();\n+            }\n+        };\n \n     let mut valid = true;\n "}]}