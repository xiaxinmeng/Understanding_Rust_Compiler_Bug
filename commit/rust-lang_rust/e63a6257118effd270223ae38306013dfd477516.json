{"sha": "e63a6257118effd270223ae38306013dfd477516", "node_id": "C_kwDOAAsO6NoAKGU2M2E2MjU3MTE4ZWZmZDI3MDIyM2FlMzgzMDYwMTNkZmQ0Nzc1MTY", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-08-27T18:11:19Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-08-27T18:11:19Z"}, "message": "interpret: rename relocation \u2192 provenance", "tree": {"sha": "618e4d93af0c7ef89d1a7f64568751e92de36d3a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/618e4d93af0c7ef89d1a7f64568751e92de36d3a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e63a6257118effd270223ae38306013dfd477516", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e63a6257118effd270223ae38306013dfd477516", "html_url": "https://github.com/rust-lang/rust/commit/e63a6257118effd270223ae38306013dfd477516", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e63a6257118effd270223ae38306013dfd477516/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "332cc8fb752fe98c21837ed6f3571f6adb0d08b8", "url": "https://api.github.com/repos/rust-lang/rust/commits/332cc8fb752fe98c21837ed6f3571f6adb0d08b8", "html_url": "https://github.com/rust-lang/rust/commit/332cc8fb752fe98c21837ed6f3571f6adb0d08b8"}], "stats": {"total": 325, "additions": 161, "deletions": 164}, "files": [{"sha": "4f1531139322b96ebccf2f7133d839a0a7c751b5", "filename": "compiler/rustc_codegen_cranelift/src/constant.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_codegen_cranelift%2Fsrc%2Fconstant.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_codegen_cranelift%2Fsrc%2Fconstant.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_cranelift%2Fsrc%2Fconstant.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -430,7 +430,7 @@ fn define_all_allocs(tcx: TyCtxt<'_>, module: &mut dyn Module, cx: &mut Constant\n         let bytes = alloc.inspect_with_uninit_and_ptr_outside_interpreter(0..alloc.len()).to_vec();\n         data_ctx.define(bytes.into_boxed_slice());\n \n-        for &(offset, alloc_id) in alloc.relocations().iter() {\n+        for &(offset, alloc_id) in alloc.provenance().iter() {\n             let addend = {\n                 let endianness = tcx.data_layout.endian;\n                 let offset = offset.bytes() as usize;"}, {"sha": "356c03ee3c189cadeacc111f37403d29911ba704", "filename": "compiler/rustc_codegen_gcc/src/consts.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_codegen_gcc%2Fsrc%2Fconsts.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_codegen_gcc%2Fsrc%2Fconsts.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_gcc%2Fsrc%2Fconsts.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -127,7 +127,7 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n             //\n             // We could remove this hack whenever we decide to drop macOS 10.10 support.\n             if self.tcx.sess.target.options.is_like_osx {\n-                // The `inspect` method is okay here because we checked relocations, and\n+                // The `inspect` method is okay here because we checked for provenance, and\n                 // because we are doing this access to inspect the final interpreter state\n                 // (not as part of the interpreter execution).\n                 //\n@@ -296,17 +296,17 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n \n pub fn const_alloc_to_gcc<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, alloc: ConstAllocation<'tcx>) -> RValue<'gcc> {\n     let alloc = alloc.inner();\n-    let mut llvals = Vec::with_capacity(alloc.relocations().len() + 1);\n+    let mut llvals = Vec::with_capacity(alloc.provenance().len() + 1);\n     let dl = cx.data_layout();\n     let pointer_size = dl.pointer_size.bytes() as usize;\n \n     let mut next_offset = 0;\n-    for &(offset, alloc_id) in alloc.relocations().iter() {\n+    for &(offset, alloc_id) in alloc.provenance().iter() {\n         let offset = offset.bytes();\n         assert_eq!(offset as usize as u64, offset);\n         let offset = offset as usize;\n         if offset > next_offset {\n-            // This `inspect` is okay since we have checked that it is not within a relocation, it\n+            // This `inspect` is okay since we have checked that it is not within a pointer with provenance, it\n             // is within the bounds of the allocation, and it doesn't affect interpreter execution\n             // (we inspect the result after interpreter execution). Any undef byte is replaced with\n             // some arbitrary byte value.\n@@ -319,7 +319,7 @@ pub fn const_alloc_to_gcc<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, alloc: ConstAl\n             read_target_uint( dl.endian,\n                 // This `inspect` is okay since it is within the bounds of the allocation, it doesn't\n                 // affect interpreter execution (we inspect the result after interpreter execution),\n-                // and we properly interpret the relocation as a relocation pointer offset.\n+                // and we properly interpret the provenance as a relocation pointer offset.\n                 alloc.inspect_with_uninit_and_ptr_outside_interpreter(offset..(offset + pointer_size)),\n             )\n             .expect(\"const_alloc_to_llvm: could not read relocation pointer\")\n@@ -336,7 +336,7 @@ pub fn const_alloc_to_gcc<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, alloc: ConstAl\n     }\n     if alloc.len() >= next_offset {\n         let range = next_offset..alloc.len();\n-        // This `inspect` is okay since we have check that it is after all relocations, it is\n+        // This `inspect` is okay since we have check that it is after all provenance, it is\n         // within the bounds of the allocation, and it doesn't affect interpreter execution (we\n         // inspect the result after interpreter execution). Any undef byte is replaced with some\n         // arbitrary byte value."}, {"sha": "d3e33da27993c6b3286765128fd0b7ca6ce04952", "filename": "compiler/rustc_codegen_llvm/src/consts.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -27,12 +27,12 @@ use tracing::debug;\n \n pub fn const_alloc_to_llvm<'ll>(cx: &CodegenCx<'ll, '_>, alloc: ConstAllocation<'_>) -> &'ll Value {\n     let alloc = alloc.inner();\n-    let mut llvals = Vec::with_capacity(alloc.relocations().len() + 1);\n+    let mut llvals = Vec::with_capacity(alloc.provenance().len() + 1);\n     let dl = cx.data_layout();\n     let pointer_size = dl.pointer_size.bytes() as usize;\n \n-    // Note: this function may call `inspect_with_uninit_and_ptr_outside_interpreter`,\n-    // so `range` must be within the bounds of `alloc` and not contain or overlap a relocation.\n+    // Note: this function may call `inspect_with_uninit_and_ptr_outside_interpreter`, so `range`\n+    // must be within the bounds of `alloc` and not contain or overlap a pointer provenance.\n     fn append_chunks_of_init_and_uninit_bytes<'ll, 'a, 'b>(\n         llvals: &mut Vec<&'ll Value>,\n         cx: &'a CodegenCx<'ll, 'b>,\n@@ -79,12 +79,12 @@ pub fn const_alloc_to_llvm<'ll>(cx: &CodegenCx<'ll, '_>, alloc: ConstAllocation<\n     }\n \n     let mut next_offset = 0;\n-    for &(offset, alloc_id) in alloc.relocations().iter() {\n+    for &(offset, alloc_id) in alloc.provenance().iter() {\n         let offset = offset.bytes();\n         assert_eq!(offset as usize as u64, offset);\n         let offset = offset as usize;\n         if offset > next_offset {\n-            // This `inspect` is okay since we have checked that it is not within a relocation, it\n+            // This `inspect` is okay since we have checked that there is no provenance, it\n             // is within the bounds of the allocation, and it doesn't affect interpreter execution\n             // (we inspect the result after interpreter execution).\n             append_chunks_of_init_and_uninit_bytes(&mut llvals, cx, alloc, next_offset..offset);\n@@ -93,7 +93,7 @@ pub fn const_alloc_to_llvm<'ll>(cx: &CodegenCx<'ll, '_>, alloc: ConstAllocation<\n             dl.endian,\n             // This `inspect` is okay since it is within the bounds of the allocation, it doesn't\n             // affect interpreter execution (we inspect the result after interpreter execution),\n-            // and we properly interpret the relocation as a relocation pointer offset.\n+            // and we properly interpret the provenance as a relocation pointer offset.\n             alloc.inspect_with_uninit_and_ptr_outside_interpreter(offset..(offset + pointer_size)),\n         )\n         .expect(\"const_alloc_to_llvm: could not read relocation pointer\")\n@@ -121,7 +121,7 @@ pub fn const_alloc_to_llvm<'ll>(cx: &CodegenCx<'ll, '_>, alloc: ConstAllocation<\n     }\n     if alloc.len() >= next_offset {\n         let range = next_offset..alloc.len();\n-        // This `inspect` is okay since we have check that it is after all relocations, it is\n+        // This `inspect` is okay since we have check that it is after all provenance, it is\n         // within the bounds of the allocation, and it doesn't affect interpreter execution (we\n         // inspect the result after interpreter execution).\n         append_chunks_of_init_and_uninit_bytes(&mut llvals, cx, alloc, range);\n@@ -479,15 +479,15 @@ impl<'ll> StaticMethods for CodegenCx<'ll, '_> {\n                 //\n                 // We could remove this hack whenever we decide to drop macOS 10.10 support.\n                 if self.tcx.sess.target.is_like_osx {\n-                    // The `inspect` method is okay here because we checked relocations, and\n+                    // The `inspect` method is okay here because we checked for provenance, and\n                     // because we are doing this access to inspect the final interpreter state\n                     // (not as part of the interpreter execution).\n                     //\n                     // FIXME: This check requires that the (arbitrary) value of undefined bytes\n                     // happens to be zero. Instead, we should only check the value of defined bytes\n                     // and set all undefined bytes to zero if this allocation is headed for the\n                     // BSS.\n-                    let all_bytes_are_zero = alloc.relocations().is_empty()\n+                    let all_bytes_are_zero = alloc.provenance().is_empty()\n                         && alloc\n                             .inspect_with_uninit_and_ptr_outside_interpreter(0..alloc.len())\n                             .iter()\n@@ -511,9 +511,9 @@ impl<'ll> StaticMethods for CodegenCx<'ll, '_> {\n                         section.as_str().as_ptr().cast(),\n                         section.as_str().len() as c_uint,\n                     );\n-                    assert!(alloc.relocations().is_empty());\n+                    assert!(alloc.provenance().is_empty());\n \n-                    // The `inspect` method is okay here because we checked relocations, and\n+                    // The `inspect` method is okay here because we checked for provenance, and\n                     // because we are doing this access to inspect the final interpreter state (not\n                     // as part of the interpreter execution).\n                     let bytes ="}, {"sha": "66ab3f15716f2e5d7eb93782df478f32bf5f50e2", "filename": "compiler/rustc_const_eval/src/interpret/intern.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fintern.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fintern.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fintern.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -134,7 +134,7 @@ fn intern_shallow<'rt, 'mir, 'tcx, M: CompileTimeMachine<'mir, 'tcx, const_eval:\n         alloc.mutability = Mutability::Not;\n     };\n     // link the alloc id to the actual allocation\n-    leftover_allocations.extend(alloc.relocations().iter().map(|&(_, alloc_id)| alloc_id));\n+    leftover_allocations.extend(alloc.provenance().iter().map(|&(_, alloc_id)| alloc_id));\n     let alloc = tcx.intern_const_alloc(alloc);\n     tcx.set_alloc_id_memory(alloc_id, alloc);\n     None\n@@ -191,10 +191,10 @@ impl<'rt, 'mir, 'tcx: 'mir, M: CompileTimeMachine<'mir, 'tcx, const_eval::Memory\n                     return Ok(true);\n                 };\n \n-                // If there are no relocations in this allocation, it does not contain references\n+                // If there is no provenance in this allocation, it does not contain references\n                 // that point to another allocation, and we can avoid the interning walk.\n                 if let Some(alloc) = self.ecx.get_ptr_alloc(mplace.ptr, size, align)? {\n-                    if !alloc.has_relocations() {\n+                    if !alloc.has_provenance() {\n                         return Ok(false);\n                     }\n                 } else {\n@@ -233,8 +233,8 @@ impl<'rt, 'mir, 'tcx: 'mir, M: CompileTimeMachine<'mir, 'tcx, const_eval::Memory\n     }\n \n     fn visit_value(&mut self, mplace: &MPlaceTy<'tcx>) -> InterpResult<'tcx> {\n-        // Handle Reference types, as these are the only relocations supported by const eval.\n-        // Raw pointers (and boxes) are handled by the `leftover_relocations` logic.\n+        // Handle Reference types, as these are the only types with provenance supported by const eval.\n+        // Raw pointers (and boxes) are handled by the `leftover_allocations` logic.\n         let tcx = self.ecx.tcx;\n         let ty = mplace.layout.ty;\n         if let ty::Ref(_, referenced_ty, ref_mutability) = *ty.kind() {\n@@ -410,7 +410,7 @@ pub fn intern_const_alloc_recursive<\n             // references and a `leftover_allocations` set (where we only have a todo-list here).\n             // So we hand-roll the interning logic here again.\n             match intern_kind {\n-                // Statics may contain mutable allocations even behind relocations.\n+                // Statics may point to mutable allocations.\n                 // Even for immutable statics it would be ok to have mutable allocations behind\n                 // raw pointers, e.g. for `static FOO: *const AtomicUsize = &AtomicUsize::new(42)`.\n                 InternKind::Static(_) => {}\n@@ -441,7 +441,7 @@ pub fn intern_const_alloc_recursive<\n             }\n             let alloc = tcx.intern_const_alloc(alloc);\n             tcx.set_alloc_id_memory(alloc_id, alloc);\n-            for &(_, alloc_id) in alloc.inner().relocations().iter() {\n+            for &(_, alloc_id) in alloc.inner().provenance().iter() {\n                 if leftover_allocations.insert(alloc_id) {\n                     todo.push(alloc_id);\n                 }"}, {"sha": "ae7c0347efc02d0d2cbeff7f87148a4a8e95b940", "filename": "compiler/rustc_const_eval/src/interpret/machine.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmachine.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -326,7 +326,7 @@ pub trait Machine<'mir, 'tcx>: Sized {\n     /// cache the result. (This relies on `AllocMap::get_or` being able to add the\n     /// owned allocation to the map even when the map is shared.)\n     ///\n-    /// This must only fail if `alloc` contains relocations.\n+    /// This must only fail if `alloc` contains provenance.\n     fn adjust_allocation<'b>(\n         ecx: &InterpCx<'mir, 'tcx, Self>,\n         id: AllocId,"}, {"sha": "f84c6017dbf6dacf71817fb9760ef8abf5c6bf37", "filename": "compiler/rustc_const_eval/src/interpret/memory.rs", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmemory.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -214,7 +214,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         self.allocate_raw_ptr(alloc, kind).unwrap()\n     }\n \n-    /// This can fail only of `alloc` contains relocations.\n+    /// This can fail only of `alloc` contains provenance.\n     pub fn allocate_raw_ptr(\n         &mut self,\n         alloc: Allocation,\n@@ -794,10 +794,10 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             todo.extend(static_roots);\n             while let Some(id) = todo.pop() {\n                 if reachable.insert(id) {\n-                    // This is a new allocation, add its relocations to `todo`.\n+                    // This is a new allocation, add the allocation it points to to `todo`.\n                     if let Some((_, alloc)) = self.memory.alloc_map.get(id) {\n                         todo.extend(\n-                            alloc.relocations().values().filter_map(|prov| prov.get_alloc_id()),\n+                            alloc.provenance().values().filter_map(|prov| prov.get_alloc_id()),\n                         );\n                     }\n                 }\n@@ -833,7 +833,7 @@ impl<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> std::fmt::Debug for DumpAllocs<'a,\n             allocs_to_print: &mut VecDeque<AllocId>,\n             alloc: &Allocation<Prov, Extra>,\n         ) -> std::fmt::Result {\n-            for alloc_id in alloc.relocations().values().filter_map(|prov| prov.get_alloc_id()) {\n+            for alloc_id in alloc.provenance().values().filter_map(|prov| prov.get_alloc_id()) {\n                 allocs_to_print.push_back(alloc_id);\n             }\n             write!(fmt, \"{}\", display_allocation(tcx, alloc))\n@@ -960,9 +960,9 @@ impl<'tcx, 'a, Prov: Provenance, Extra> AllocRef<'a, 'tcx, Prov, Extra> {\n             .map_err(|e| e.to_interp_error(self.alloc_id))?)\n     }\n \n-    /// Returns whether the allocation has relocations for the entire range of the `AllocRef`.\n-    pub(crate) fn has_relocations(&self) -> bool {\n-        self.alloc.has_relocations(&self.tcx, self.range)\n+    /// Returns whether the allocation has provenance anywhere in the range of the `AllocRef`.\n+    pub(crate) fn has_provenance(&self) -> bool {\n+        self.alloc.range_has_provenance(&self.tcx, self.range)\n     }\n }\n \n@@ -1078,17 +1078,17 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             return Ok(());\n         };\n \n-        // This checks relocation edges on the src, which needs to happen before\n-        // `prepare_relocation_copy`.\n+        // This checks provenance edges on the src, which needs to happen before\n+        // `prepare_provenance_copy`.\n         let src_bytes = src_alloc\n             .get_bytes_with_uninit_and_ptr(&tcx, src_range)\n             .map_err(|e| e.to_interp_error(src_alloc_id))?\n             .as_ptr(); // raw ptr, so we can also get a ptr to the destination allocation\n-        // first copy the relocations to a temporary buffer, because\n-        // `get_bytes_mut` will clear the relocations, which is correct,\n-        // since we don't want to keep any relocations at the target.\n-        let relocations =\n-            src_alloc.prepare_relocation_copy(self, src_range, dest_offset, num_copies);\n+        // first copy the provenance to a temporary buffer, because\n+        // `get_bytes_mut` will clear the provenance, which is correct,\n+        // since we don't want to keep any provenance at the target.\n+        let provenance =\n+            src_alloc.prepare_provenance_copy(self, src_range, dest_offset, num_copies);\n         // Prepare a copy of the initialization mask.\n         let compressed = src_alloc.compress_uninit_range(src_range);\n \n@@ -1117,7 +1117,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             dest_alloc\n                 .write_uninit(&tcx, dest_range)\n                 .map_err(|e| e.to_interp_error(dest_alloc_id))?;\n-            // We can forget about the relocations, this is all not initialized anyway.\n+            // We can forget about the provenance, this is all not initialized anyway.\n             return Ok(());\n         }\n \n@@ -1161,8 +1161,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             alloc_range(dest_offset, size), // just a single copy (i.e., not full `dest_range`)\n             num_copies,\n         );\n-        // copy the relocations to the destination\n-        dest_alloc.mark_relocation_range(relocations);\n+        // copy the provenance to the destination\n+        dest_alloc.mark_provenance_range(provenance);\n \n         Ok(())\n     }"}, {"sha": "cc39e434225f6b8e65b9302f0b5c12de95f42024", "filename": "compiler/rustc_middle/src/mir/interpret/allocation.rs", "status": "modified", "additions": 90, "deletions": 91, "changes": 181, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -34,11 +34,11 @@ pub struct Allocation<Prov = AllocId, Extra = ()> {\n     /// The actual bytes of the allocation.\n     /// Note that the bytes of a pointer represent the offset of the pointer.\n     bytes: Box<[u8]>,\n-    /// Maps from byte addresses to extra data for each pointer.\n+    /// Maps from byte addresses to extra provenance data for each pointer.\n     /// Only the first byte of a pointer is inserted into the map; i.e.,\n     /// every entry in this map applies to `pointer_size` consecutive bytes starting\n     /// at the given offset.\n-    relocations: Relocations<Prov>,\n+    provenance: ProvenanceMap<Prov>,\n     /// Denotes which part of this allocation is initialized.\n     init_mask: InitMask,\n     /// The alignment of the allocation to detect unaligned reads.\n@@ -84,7 +84,7 @@ impl hash::Hash for Allocation {\n         }\n \n         // Hash the other fields as usual.\n-        self.relocations.hash(state);\n+        self.provenance.hash(state);\n         self.init_mask.hash(state);\n         self.align.hash(state);\n         self.mutability.hash(state);\n@@ -211,7 +211,7 @@ impl<Prov> Allocation<Prov> {\n         let size = Size::from_bytes(bytes.len());\n         Self {\n             bytes,\n-            relocations: Relocations::new(),\n+            provenance: ProvenanceMap::new(),\n             init_mask: InitMask::new(size, true),\n             align,\n             mutability,\n@@ -246,7 +246,7 @@ impl<Prov> Allocation<Prov> {\n         let bytes = unsafe { bytes.assume_init() };\n         Ok(Allocation {\n             bytes,\n-            relocations: Relocations::new(),\n+            provenance: ProvenanceMap::new(),\n             init_mask: InitMask::new(size, false),\n             align,\n             mutability: Mutability::Mut,\n@@ -266,22 +266,22 @@ impl Allocation {\n     ) -> Result<Allocation<Prov, Extra>, Err> {\n         // Compute new pointer provenance, which also adjusts the bytes.\n         let mut bytes = self.bytes;\n-        let mut new_relocations = Vec::with_capacity(self.relocations.0.len());\n+        let mut new_provenance = Vec::with_capacity(self.provenance.0.len());\n         let ptr_size = cx.data_layout().pointer_size.bytes_usize();\n         let endian = cx.data_layout().endian;\n-        for &(offset, alloc_id) in self.relocations.iter() {\n+        for &(offset, alloc_id) in self.provenance.iter() {\n             let idx = offset.bytes_usize();\n             let ptr_bytes = &mut bytes[idx..idx + ptr_size];\n             let bits = read_target_uint(endian, ptr_bytes).unwrap();\n             let (ptr_prov, ptr_offset) =\n                 adjust_ptr(Pointer::new(alloc_id, Size::from_bytes(bits)))?.into_parts();\n             write_target_uint(endian, ptr_bytes, ptr_offset.bytes().into()).unwrap();\n-            new_relocations.push((offset, ptr_prov));\n+            new_provenance.push((offset, ptr_prov));\n         }\n         // Create allocation.\n         Ok(Allocation {\n             bytes,\n-            relocations: Relocations::from_presorted(new_relocations),\n+            provenance: ProvenanceMap::from_presorted(new_provenance),\n             init_mask: self.init_mask,\n             align: self.align,\n             mutability: self.mutability,\n@@ -300,8 +300,8 @@ impl<Prov, Extra> Allocation<Prov, Extra> {\n         Size::from_bytes(self.len())\n     }\n \n-    /// Looks at a slice which may describe uninitialized bytes or describe a relocation. This differs\n-    /// from `get_bytes_with_uninit_and_ptr` in that it does no relocation checks (even on the\n+    /// Looks at a slice which may contain uninitialized bytes or provenance. This differs\n+    /// from `get_bytes_with_uninit_and_ptr` in that it does no provenance checks (even on the\n     /// edges) at all.\n     /// This must not be used for reads affecting the interpreter execution.\n     pub fn inspect_with_uninit_and_ptr_outside_interpreter(&self, range: Range<usize>) -> &[u8] {\n@@ -313,23 +313,23 @@ impl<Prov, Extra> Allocation<Prov, Extra> {\n         &self.init_mask\n     }\n \n-    /// Returns the relocation list.\n-    pub fn relocations(&self) -> &Relocations<Prov> {\n-        &self.relocations\n+    /// Returns the provenance map.\n+    pub fn provenance(&self) -> &ProvenanceMap<Prov> {\n+        &self.provenance\n     }\n }\n \n /// Byte accessors.\n impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     /// This is the entirely abstraction-violating way to just grab the raw bytes without\n-    /// caring about relocations. It just deduplicates some code between `read_scalar`\n+    /// caring about provenance. It just deduplicates some code between `read_scalar`\n     /// and `get_bytes_internal`.\n     fn get_bytes_even_more_internal(&self, range: AllocRange) -> &[u8] {\n         &self.bytes[range.start.bytes_usize()..range.end().bytes_usize()]\n     }\n \n     /// The last argument controls whether we error out when there are uninitialized or pointer\n-    /// bytes. However, we *always* error when there are relocations overlapping the edges of the\n+    /// bytes. However, we *always* error when there is provenance overlapping the edges of the\n     /// range.\n     ///\n     /// You should never call this, call `get_bytes` or `get_bytes_with_uninit_and_ptr` instead,\n@@ -347,10 +347,10 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     ) -> AllocResult<&[u8]> {\n         if check_init_and_ptr {\n             self.check_init(range)?;\n-            self.check_relocations(cx, range)?;\n+            self.check_provenance(cx, range)?;\n         } else {\n-            // We still don't want relocations on the *edges*.\n-            self.check_relocation_edges(cx, range)?;\n+            // We still don't want provenance on the *edges*.\n+            self.check_provenance_edges(cx, range)?;\n         }\n \n         Ok(self.get_bytes_even_more_internal(range))\n@@ -368,7 +368,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     }\n \n     /// It is the caller's responsibility to handle uninitialized and pointer bytes.\n-    /// However, this still checks that there are no relocations on the *edges*.\n+    /// However, this still checks that there is no provenance on the *edges*.\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n     #[inline]\n@@ -380,7 +380,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         self.get_bytes_internal(cx, range, false)\n     }\n \n-    /// Just calling this already marks everything as defined and removes relocations,\n+    /// Just calling this already marks everything as defined and removes provenance,\n     /// so be sure to actually put data there!\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n@@ -392,7 +392,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         range: AllocRange,\n     ) -> AllocResult<&mut [u8]> {\n         self.mark_init(range, true);\n-        self.clear_relocations(cx, range)?;\n+        self.clear_provenance(cx, range)?;\n \n         Ok(&mut self.bytes[range.start.bytes_usize()..range.end().bytes_usize()])\n     }\n@@ -404,7 +404,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         range: AllocRange,\n     ) -> AllocResult<*mut [u8]> {\n         self.mark_init(range, true);\n-        self.clear_relocations(cx, range)?;\n+        self.clear_provenance(cx, range)?;\n \n         assert!(range.end().bytes_usize() <= self.bytes.len()); // need to do our own bounds-check\n         let begin_ptr = self.bytes.as_mut_ptr().wrapping_add(range.start.bytes_usize());\n@@ -415,7 +415,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n \n /// Reading and writing.\n impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n-    /// Validates that this memory range is initiailized and contains no relocations.\n+    /// Validates that this memory range is initiailized and contains no provenance.\n     pub fn check_bytes(&self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n         // This implicitly does all the checking we are asking for.\n         self.get_bytes(cx, range)?;\n@@ -447,17 +447,17 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n             return Err(AllocError::InvalidUninitBytes(None));\n         }\n \n-        // If we are doing a pointer read, and there is a relocation exactly where we\n-        // are reading, then we can put data and relocation back together and return that.\n-        if read_provenance && let Some(&prov) = self.relocations.get(&range.start) {\n-            // We already checked init and relocations, so we can use this function.\n+        // If we are doing a pointer read, and there is provenance exactly where we\n+        // are reading, then we can put data and provenance back together and return that.\n+        if read_provenance && let Some(&prov) = self.provenance.get(&range.start) {\n+            // We already checked init and provenance, so we can use this function.\n             let bytes = self.get_bytes_even_more_internal(range);\n             let bits = read_target_uint(cx.data_layout().endian, bytes).unwrap();\n             let ptr = Pointer::new(prov, Size::from_bytes(bits));\n             return Ok(Scalar::from_pointer(ptr, cx));\n         }\n \n-        // If we are *not* reading a pointer, and we can just ignore relocations,\n+        // If we are *not* reading a pointer, and we can just ignore provenance,\n         // then do exactly that.\n         if !read_provenance && Prov::OFFSET_IS_ADDR {\n             // We just strip provenance.\n@@ -469,8 +469,8 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         // It's complicated. Better make sure there is no provenance anywhere.\n         // FIXME: If !OFFSET_IS_ADDR, this is the best we can do. But if OFFSET_IS_ADDR, then\n         // `read_pointer` is true and we ideally would distinguish the following two cases:\n-        // - The entire `range` is covered by 2 relocations for the same provenance.\n-        //   Then we should return a pointer with that provenance.\n+        // - The entire `range` is covered by the same provenance, stored in two separate entries of\n+        //   the provenance map. Then we should return a pointer with that provenance.\n         // - The range has inhomogeneous provenance. Then we should return just the\n         //   underlying bits.\n         let bytes = self.get_bytes(cx, range)?;\n@@ -508,9 +508,9 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         let dst = self.get_bytes_mut(cx, range)?;\n         write_target_uint(endian, dst, bytes).unwrap();\n \n-        // See if we have to also write a relocation.\n+        // See if we have to also store some provenance.\n         if let Some(provenance) = provenance {\n-            self.relocations.0.insert(range.start, provenance);\n+            self.provenance.0.insert(range.start, provenance);\n         }\n \n         Ok(())\n@@ -519,64 +519,64 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     /// Write \"uninit\" to the given memory range.\n     pub fn write_uninit(&mut self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n         self.mark_init(range, false);\n-        self.clear_relocations(cx, range)?;\n+        self.clear_provenance(cx, range)?;\n         return Ok(());\n     }\n }\n \n-/// Relocations.\n+/// Provenance.\n impl<Prov: Copy, Extra> Allocation<Prov, Extra> {\n-    /// Returns all relocations overlapping with the given pointer-offset pair.\n-    fn get_relocations(&self, cx: &impl HasDataLayout, range: AllocRange) -> &[(Size, Prov)] {\n+    /// Returns all provenance overlapping with the given pointer-offset pair.\n+    fn range_get_provenance(&self, cx: &impl HasDataLayout, range: AllocRange) -> &[(Size, Prov)] {\n         // We have to go back `pointer_size - 1` bytes, as that one would still overlap with\n         // the beginning of this range.\n         let start = range.start.bytes().saturating_sub(cx.data_layout().pointer_size.bytes() - 1);\n-        self.relocations.range(Size::from_bytes(start)..range.end())\n+        self.provenance.range(Size::from_bytes(start)..range.end())\n     }\n \n-    /// Returns whether this allocation has relocations overlapping with the given range.\n+    /// Returns whether this allocation has progrnance overlapping with the given range.\n     ///\n-    /// Note: this function exists to allow `get_relocations` to be private, in order to somewhat\n-    /// limit access to relocations outside of the `Allocation` abstraction.\n+    /// Note: this function exists to allow `range_get_provenance` to be private, in order to somewhat\n+    /// limit access to provenance outside of the `Allocation` abstraction.\n     ///\n-    pub fn has_relocations(&self, cx: &impl HasDataLayout, range: AllocRange) -> bool {\n-        !self.get_relocations(cx, range).is_empty()\n+    pub fn range_has_provenance(&self, cx: &impl HasDataLayout, range: AllocRange) -> bool {\n+        !self.range_get_provenance(cx, range).is_empty()\n     }\n \n-    /// Checks that there are no relocations overlapping with the given range.\n+    /// Checks that there is no provenance overlapping with the given range.\n     #[inline(always)]\n-    fn check_relocations(&self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n-        if self.has_relocations(cx, range) { Err(AllocError::ReadPointerAsBytes) } else { Ok(()) }\n+    fn check_provenance(&self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n+        if self.range_has_provenance(cx, range) { Err(AllocError::ReadPointerAsBytes) } else { Ok(()) }\n     }\n \n-    /// Removes all relocations inside the given range.\n-    /// If there are relocations overlapping with the edges, they\n+    /// Removes all provenance inside the given range.\n+    /// If there is provenance overlapping with the edges, it\n     /// are removed as well *and* the bytes they cover are marked as\n     /// uninitialized. This is a somewhat odd \"spooky action at a distance\",\n     /// but it allows strictly more code to run than if we would just error\n     /// immediately in that case.\n-    fn clear_relocations(&mut self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult\n+    fn clear_provenance(&mut self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult\n     where\n         Prov: Provenance,\n     {\n-        // Find the start and end of the given range and its outermost relocations.\n+        // Find the start and end of the given range and its outermost provenance.\n         let (first, last) = {\n-            // Find all relocations overlapping the given range.\n-            let relocations = self.get_relocations(cx, range);\n-            if relocations.is_empty() {\n+            // Find all provenance overlapping the given range.\n+            let provenance = self.range_get_provenance(cx, range);\n+            if provenance.is_empty() {\n                 return Ok(());\n             }\n \n             (\n-                relocations.first().unwrap().0,\n-                relocations.last().unwrap().0 + cx.data_layout().pointer_size,\n+                provenance.first().unwrap().0,\n+                provenance.last().unwrap().0 + cx.data_layout().pointer_size,\n             )\n         };\n         let start = range.start;\n         let end = range.end();\n \n-        // We need to handle clearing the relocations from parts of a pointer.\n-        // FIXME: Miri should preserve partial relocations; see\n+        // We need to handle clearing the provenance from parts of a pointer.\n+        // FIXME: Miri should preserve partial provenance; see\n         // https://github.com/rust-lang/miri/issues/2181.\n         if first < start {\n             if Prov::ERR_ON_PARTIAL_PTR_OVERWRITE {\n@@ -599,78 +599,77 @@ impl<Prov: Copy, Extra> Allocation<Prov, Extra> {\n             self.init_mask.set_range(end, last, false);\n         }\n \n-        // Forget all the relocations.\n-        // Since relocations do not overlap, we know that removing until `last` (exclusive) is fine,\n-        // i.e., this will not remove any other relocations just after the ones we care about.\n-        self.relocations.0.remove_range(first..last);\n+        // Forget all the provenance.\n+        // Since provenance do not overlap, we know that removing until `last` (exclusive) is fine,\n+        // i.e., this will not remove any other provenance just after the ones we care about.\n+        self.provenance.0.remove_range(first..last);\n \n         Ok(())\n     }\n \n-    /// Errors if there are relocations overlapping with the edges of the\n-    /// given memory range.\n+    /// Errors if there is provenance overlapping with the edges of the given memory range.\n     #[inline]\n-    fn check_relocation_edges(&self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n-        self.check_relocations(cx, alloc_range(range.start, Size::ZERO))?;\n-        self.check_relocations(cx, alloc_range(range.end(), Size::ZERO))?;\n+    fn check_provenance_edges(&self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n+        self.check_provenance(cx, alloc_range(range.start, Size::ZERO))?;\n+        self.check_provenance(cx, alloc_range(range.end(), Size::ZERO))?;\n         Ok(())\n     }\n }\n \n-/// \"Relocations\" stores the provenance information of pointers stored in memory.\n+/// Stores the provenance information of pointers stored in memory.\n #[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, TyEncodable, TyDecodable)]\n-pub struct Relocations<Prov = AllocId>(SortedMap<Size, Prov>);\n+pub struct ProvenanceMap<Prov = AllocId>(SortedMap<Size, Prov>);\n \n-impl<Prov> Relocations<Prov> {\n+impl<Prov> ProvenanceMap<Prov> {\n     pub fn new() -> Self {\n-        Relocations(SortedMap::new())\n+        ProvenanceMap(SortedMap::new())\n     }\n \n-    // The caller must guarantee that the given relocations are already sorted\n+    // The caller must guarantee that the given provenance list is already sorted\n     // by address and contain no duplicates.\n     pub fn from_presorted(r: Vec<(Size, Prov)>) -> Self {\n-        Relocations(SortedMap::from_presorted_elements(r))\n+        ProvenanceMap(SortedMap::from_presorted_elements(r))\n     }\n }\n \n-impl<Prov> Deref for Relocations<Prov> {\n+impl<Prov> Deref for ProvenanceMap<Prov> {\n     type Target = SortedMap<Size, Prov>;\n \n     fn deref(&self) -> &Self::Target {\n         &self.0\n     }\n }\n \n-/// A partial, owned list of relocations to transfer into another allocation.\n+/// A partial, owned list of provenance to transfer into another allocation.\n ///\n /// Offsets are already adjusted to the destination allocation.\n-pub struct AllocationRelocations<Prov> {\n-    dest_relocations: Vec<(Size, Prov)>,\n+pub struct AllocationProvenance<Prov> {\n+    dest_provenance: Vec<(Size, Prov)>,\n }\n \n impl<Prov: Copy, Extra> Allocation<Prov, Extra> {\n-    pub fn prepare_relocation_copy(\n+    pub fn prepare_provenance_copy(\n         &self,\n         cx: &impl HasDataLayout,\n         src: AllocRange,\n         dest: Size,\n         count: u64,\n-    ) -> AllocationRelocations<Prov> {\n-        let relocations = self.get_relocations(cx, src);\n-        if relocations.is_empty() {\n-            return AllocationRelocations { dest_relocations: Vec::new() };\n+    ) -> AllocationProvenance<Prov> {\n+        let provenance = self.range_get_provenance(cx, src);\n+        if provenance.is_empty() {\n+            return AllocationProvenance { dest_provenance: Vec::new() };\n         }\n \n         let size = src.size;\n-        let mut new_relocations = Vec::with_capacity(relocations.len() * (count as usize));\n+        let mut new_provenance = Vec::with_capacity(provenance.len() * (count as usize));\n \n         // If `count` is large, this is rather wasteful -- we are allocating a big array here, which\n         // is mostly filled with redundant information since it's just N copies of the same `Prov`s\n-        // at slightly adjusted offsets. The reason we do this is so that in `mark_relocation_range`\n+        // at slightly adjusted offsets. The reason we do this is so that in `mark_provenance_range`\n         // we can use `insert_presorted`. That wouldn't work with an `Iterator` that just produces\n-        // the right sequence of relocations for all N copies.\n+        // the right sequence of provenance for all N copies.\n         for i in 0..count {\n-            new_relocations.extend(relocations.iter().map(|&(offset, reloc)| {\n+            new_provenance.extend(provenance.iter().map(|&(offset, reloc)| {\n                 // compute offset for current repetition\n                 let dest_offset = dest + size * i; // `Size` operations\n                 (\n@@ -681,17 +680,17 @@ impl<Prov: Copy, Extra> Allocation<Prov, Extra> {\n             }));\n         }\n \n-        AllocationRelocations { dest_relocations: new_relocations }\n+        AllocationProvenance { dest_provenance: new_provenance }\n     }\n \n-    /// Applies a relocation copy.\n-    /// The affected range, as defined in the parameters to `prepare_relocation_copy` is expected\n-    /// to be clear of relocations.\n+    /// Applies a provenance copy.\n+    /// The affected range, as defined in the parameters to `prepare_provenance_copy` is expected\n+    /// to be clear of provenance.\n     ///\n     /// This is dangerous to use as it can violate internal `Allocation` invariants!\n     /// It only exists to support an efficient implementation of `mem_copy_repeatedly`.\n-    pub fn mark_relocation_range(&mut self, relocations: AllocationRelocations<Prov>) {\n-        self.relocations.0.insert_presorted(relocations.dest_relocations);\n+    pub fn mark_provenance_range(&mut self, provenance: AllocationProvenance<Prov>) {\n+        self.provenance.0.insert_presorted(provenance.dest_provenance);\n     }\n }\n "}, {"sha": "0fc1217d571969c6f1fd4954631d04ed8eff1def", "filename": "compiler/rustc_middle/src/mir/interpret/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -128,7 +128,7 @@ pub use self::value::{get_slice_bytes, ConstAlloc, ConstValue, Scalar};\n \n pub use self::allocation::{\n     alloc_range, AllocRange, Allocation, ConstAllocation, InitChunk, InitChunkIter, InitMask,\n-    Relocations,\n+    ProvenanceMap,\n };\n \n pub use self::pointer::{Pointer, PointerArithmetic, Provenance};"}, {"sha": "1ba16025e32189ae2b9f27a8260937a70698069d", "filename": "compiler/rustc_middle/src/mir/interpret/value.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fvalue.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -130,9 +130,7 @@ pub enum Scalar<Prov = AllocId> {\n     /// The raw bytes of a simple value.\n     Int(ScalarInt),\n \n-    /// A pointer into an `Allocation`. An `Allocation` in the `memory` module has a list of\n-    /// relocations, but a `Scalar` is only large enough to contain one, so we just represent the\n-    /// relocation and its associated offset together as a `Pointer` here.\n+    /// A pointer.\n     ///\n     /// We also store the size of the pointer, such that a `Scalar` always knows how big it is.\n     /// The size is always the pointer size of the current target, but this is not information"}, {"sha": "4e886ff15921838525e67b02799b22d5a1e0c290", "filename": "compiler/rustc_middle/src/mir/mod.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmod.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -2692,8 +2692,8 @@ fn pretty_print_const_value<'tcx>(\n                 match inner.kind() {\n                     ty::Slice(t) => {\n                         if *t == u8_type {\n-                            // The `inspect` here is okay since we checked the bounds, and there are\n-                            // no relocations (we have an active slice reference here). We don't use\n+                            // The `inspect` here is okay since we checked the bounds, and `u8` carries\n+                            // no provenance (we have an active slice reference here). We don't use\n                             // this result to affect interpreter execution.\n                             let byte_str = data\n                                 .inner()\n@@ -2703,8 +2703,8 @@ fn pretty_print_const_value<'tcx>(\n                         }\n                     }\n                     ty::Str => {\n-                        // The `inspect` here is okay since we checked the bounds, and there are no\n-                        // relocations (we have an active `str` reference here). We don't use this\n+                        // The `inspect` here is okay since we checked the bounds, and `str` carries\n+                        // no provenance (we have an active `str` reference here). We don't use this\n                         // result to affect interpreter execution.\n                         let slice = data\n                             .inner()"}, {"sha": "cd566681edf24d8c2ee817434a92e3a2474df1ea", "filename": "compiler/rustc_middle/src/mir/pretty.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fpretty.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -676,7 +676,7 @@ pub fn write_allocations<'tcx>(\n     fn alloc_ids_from_alloc(\n         alloc: ConstAllocation<'_>,\n     ) -> impl DoubleEndedIterator<Item = AllocId> + '_ {\n-        alloc.inner().relocations().values().map(|id| *id)\n+        alloc.inner().provenance().values().map(|id| *id)\n     }\n \n     fn alloc_ids_from_const_val(val: ConstValue<'_>) -> impl Iterator<Item = AllocId> + '_ {\n@@ -778,7 +778,7 @@ pub fn write_allocations<'tcx>(\n /// If the allocation is small enough to fit into a single line, no start address is given.\n /// After the hex dump, an ascii dump follows, replacing all unprintable characters (control\n /// characters or characters whose value is larger than 127) with a `.`\n-/// This also prints relocations adequately.\n+/// This also prints provenance adequately.\n pub fn display_allocation<'a, 'tcx, Prov, Extra>(\n     tcx: TyCtxt<'tcx>,\n     alloc: &'a Allocation<Prov, Extra>,\n@@ -873,34 +873,34 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n         if i != line_start {\n             write!(w, \" \")?;\n         }\n-        if let Some(&prov) = alloc.relocations().get(&i) {\n-            // Memory with a relocation must be defined\n+        if let Some(&prov) = alloc.provenance().get(&i) {\n+            // Memory with provenance must be defined\n             assert!(alloc.init_mask().is_range_initialized(i, i + ptr_size).is_ok());\n             let j = i.bytes_usize();\n             let offset = alloc\n                 .inspect_with_uninit_and_ptr_outside_interpreter(j..j + ptr_size.bytes_usize());\n             let offset = read_target_uint(tcx.data_layout.endian, offset).unwrap();\n             let offset = Size::from_bytes(offset);\n-            let relocation_width = |bytes| bytes * 3;\n+            let provenance_width = |bytes| bytes * 3;\n             let ptr = Pointer::new(prov, offset);\n             let mut target = format!(\"{:?}\", ptr);\n-            if target.len() > relocation_width(ptr_size.bytes_usize() - 1) {\n+            if target.len() > provenance_width(ptr_size.bytes_usize() - 1) {\n                 // This is too long, try to save some space.\n                 target = format!(\"{:#?}\", ptr);\n             }\n             if ((i - line_start) + ptr_size).bytes_usize() > BYTES_PER_LINE {\n-                // This branch handles the situation where a relocation starts in the current line\n+                // This branch handles the situation where a provenance starts in the current line\n                 // but ends in the next one.\n                 let remainder = Size::from_bytes(BYTES_PER_LINE) - (i - line_start);\n                 let overflow = ptr_size - remainder;\n-                let remainder_width = relocation_width(remainder.bytes_usize()) - 2;\n-                let overflow_width = relocation_width(overflow.bytes_usize() - 1) + 1;\n+                let remainder_width = provenance_width(remainder.bytes_usize()) - 2;\n+                let overflow_width = provenance_width(overflow.bytes_usize() - 1) + 1;\n                 ascii.push('\u257e');\n                 for _ in 0..remainder.bytes() - 1 {\n                     ascii.push('\u2500');\n                 }\n                 if overflow_width > remainder_width && overflow_width >= target.len() {\n-                    // The case where the relocation fits into the part in the next line\n+                    // The case where the provenance fits into the part in the next line\n                     write!(w, \"\u257e{0:\u2500^1$}\", \"\", remainder_width)?;\n                     line_start =\n                         write_allocation_newline(w, line_start, &ascii, pos_width, prefix)?;\n@@ -921,11 +921,11 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n                 i += ptr_size;\n                 continue;\n             } else {\n-                // This branch handles a relocation that starts and ends in the current line.\n-                let relocation_width = relocation_width(ptr_size.bytes_usize() - 1);\n-                oversized_ptr(&mut target, relocation_width);\n+                // This branch handles a provenance that starts and ends in the current line.\n+                let provenance_width = provenance_width(ptr_size.bytes_usize() - 1);\n+                oversized_ptr(&mut target, provenance_width);\n                 ascii.push('\u257e');\n-                write!(w, \"\u257e{0:\u2500^1$}\u257c\", target, relocation_width)?;\n+                write!(w, \"\u257e{0:\u2500^1$}\u257c\", target, provenance_width)?;\n                 for _ in 0..ptr_size.bytes() - 2 {\n                     ascii.push('\u2500');\n                 }\n@@ -935,7 +935,7 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n         } else if alloc.init_mask().is_range_initialized(i, i + Size::from_bytes(1)).is_ok() {\n             let j = i.bytes_usize();\n \n-            // Checked definedness (and thus range) and relocations. This access also doesn't\n+            // Checked definedness (and thus range) and provenance. This access also doesn't\n             // influence interpreter execution but is only for debugging.\n             let c = alloc.inspect_with_uninit_and_ptr_outside_interpreter(j..j + 1)[0];\n             write!(w, \"{:02x}\", c)?;"}, {"sha": "d1c0d62ac6e005aaa90562cd2e382b1409e74c7e", "filename": "compiler/rustc_middle/src/ty/impls_ty.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fty%2Fimpls_ty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_middle%2Fsrc%2Fty%2Fimpls_ty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fimpls_ty.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -113,7 +113,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for mir::interpret::AllocId {\n }\n \n // `Relocations` with default type parameters is a sorted map.\n-impl<'a, Prov> HashStable<StableHashingContext<'a>> for mir::interpret::Relocations<Prov>\n+impl<'a, Prov> HashStable<StableHashingContext<'a>> for mir::interpret::ProvenanceMap<Prov>\n where\n     Prov: HashStable<StableHashingContext<'a>>,\n {"}, {"sha": "5f5540495e93836a6e88eefc64b239887c2ed9ce", "filename": "compiler/rustc_monomorphize/src/collector.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_monomorphize%2Fsrc%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_monomorphize%2Fsrc%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_monomorphize%2Fsrc%2Fcollector.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -461,7 +461,7 @@ fn collect_items_rec<'tcx>(\n             recursion_depth_reset = None;\n \n             if let Ok(alloc) = tcx.eval_static_initializer(def_id) {\n-                for &id in alloc.inner().relocations().values() {\n+                for &id in alloc.inner().provenance().values() {\n                     collect_miri(tcx, id, &mut neighbors);\n                 }\n             }\n@@ -1424,7 +1424,7 @@ fn collect_miri<'tcx>(tcx: TyCtxt<'tcx>, alloc_id: AllocId, output: &mut MonoIte\n         }\n         GlobalAlloc::Memory(alloc) => {\n             trace!(\"collecting {:?} with {:#?}\", alloc_id, alloc);\n-            for &inner in alloc.inner().relocations().values() {\n+            for &inner in alloc.inner().provenance().values() {\n                 rustc_data_structures::stack::ensure_sufficient_stack(|| {\n                     collect_miri(tcx, inner, output);\n                 });\n@@ -1463,7 +1463,7 @@ fn collect_const_value<'tcx>(\n     match value {\n         ConstValue::Scalar(Scalar::Ptr(ptr, _size)) => collect_miri(tcx, ptr.provenance, output),\n         ConstValue::Slice { data: alloc, start: _, end: _ } | ConstValue::ByRef { alloc, .. } => {\n-            for &id in alloc.inner().relocations().values() {\n+            for &id in alloc.inner().provenance().values() {\n                 collect_miri(tcx, id, output);\n             }\n         }"}, {"sha": "f8d839b64838020a6473b1742c38526c175dfb7d", "filename": "compiler/rustc_typeck/src/check/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_typeck%2Fsrc%2Fcheck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e63a6257118effd270223ae38306013dfd477516/compiler%2Frustc_typeck%2Fsrc%2Fcheck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_typeck%2Fsrc%2Fcheck%2Fmod.rs?ref=e63a6257118effd270223ae38306013dfd477516", "patch": "@@ -542,13 +542,13 @@ fn maybe_check_static_with_link_section(tcx: TyCtxt<'_>, id: LocalDefId) {\n     // For the wasm32 target statics with `#[link_section]` are placed into custom\n     // sections of the final output file, but this isn't link custom sections of\n     // other executable formats. Namely we can only embed a list of bytes,\n-    // nothing with pointers to anything else or relocations. If any relocation\n-    // show up, reject them here.\n+    // nothing with provenance (pointers to anything else). If any provenance\n+    // show up, reject it here.\n     // `#[link_section]` may contain arbitrary, or even undefined bytes, but it is\n     // the consumer's responsibility to ensure all bytes that have been read\n     // have defined values.\n     if let Ok(alloc) = tcx.eval_static_initializer(id.to_def_id())\n-        && alloc.inner().relocations().len() != 0\n+        && alloc.inner().provenance().len() != 0\n     {\n         let msg = \"statics with a custom `#[link_section]` must be a \\\n                         simple list of bytes on the wasm target with no \\"}]}