{"sha": "f1c32c10c476c5a77c662ce70cb04639cda3eb4b", "node_id": "C_kwDOAAsO6NoAKGYxYzMyYzEwYzQ3NmM1YTc3YzY2MmNlNzBjYjA0NjM5Y2RhM2ViNGI", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-04-19T07:01:26Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-04-19T22:33:25Z"}, "message": "Move desugaring code into its own function.\n\nIt's not hot, so shouldn't be within the always inlined part.", "tree": {"sha": "88eb4217c8ea15a0d11d89f8b6d1f1c2d476d557", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/88eb4217c8ea15a0d11d89f8b6d1f1c2d476d557"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f1c32c10c476c5a77c662ce70cb04639cda3eb4b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f1c32c10c476c5a77c662ce70cb04639cda3eb4b", "html_url": "https://github.com/rust-lang/rust/commit/f1c32c10c476c5a77c662ce70cb04639cda3eb4b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f1c32c10c476c5a77c662ce70cb04639cda3eb4b/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d235ac7801367afcdd0712c43dd53fab7d6ff95b", "url": "https://api.github.com/repos/rust-lang/rust/commits/d235ac7801367afcdd0712c43dd53fab7d6ff95b", "html_url": "https://github.com/rust-lang/rust/commit/d235ac7801367afcdd0712c43dd53fab7d6ff95b"}], "stats": {"total": 127, "additions": 60, "deletions": 67}, "files": [{"sha": "925d6ac405b92f28371ef65f28d0cf5eaf18ab1c", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 60, "deletions": 67, "changes": 127, "blob_url": "https://github.com/rust-lang/rust/blob/f1c32c10c476c5a77c662ce70cb04639cda3eb4b/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1c32c10c476c5a77c662ce70cb04639cda3eb4b/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=f1c32c10c476c5a77c662ce70cb04639cda3eb4b", "patch": "@@ -261,25 +261,28 @@ impl TokenCursor {\n     /// This always-inlined version should only be used on hot code paths.\n     #[inline(always)]\n     fn inlined_next(&mut self, desugar_doc_comments: bool) -> (Token, Spacing) {\n-        let (token, spacing) = loop {\n+        loop {\n             if !self.frame.open_delim {\n                 self.frame.open_delim = true;\n                 return (\n                     Token::new(token::OpenDelim(self.frame.delim), self.frame.span.open),\n                     Spacing::Alone,\n                 );\n             } else if let Some((tree, spacing)) = self.frame.tree_cursor.next_with_spacing() {\n-                match tree {\n-                    TokenTree::Token(token) => {\n-                        break (token, spacing);\n-                    }\n+                return match tree {\n+                    TokenTree::Token(token) => match (desugar_doc_comments, &token) {\n+                        (true, &Token { kind: token::DocComment(_, attr_style, data), span }) => {\n+                            self.desugar(attr_style, data, span)\n+                        }\n+                        _ => (token, spacing),\n+                    },\n                     TokenTree::Delimited(sp, delim, tts) => {\n                         // Set `open_delim` to true here because we deal with it immediately.\n                         let frame = TokenCursorFrame::new(sp, delim, true, tts, false);\n                         self.stack.push(mem::replace(&mut self.frame, frame));\n-                        return (Token::new(token::OpenDelim(delim), sp.open), Spacing::Alone);\n+                        (Token::new(token::OpenDelim(delim), sp.open), Spacing::Alone)\n                     }\n-                }\n+                };\n             } else if !self.frame.close_delim {\n                 self.frame.close_delim = true;\n                 return (\n@@ -291,69 +294,59 @@ impl TokenCursor {\n             } else {\n                 return (Token::new(token::Eof, DUMMY_SP), Spacing::Alone);\n             }\n-        };\n+        }\n+    }\n \n-        match (desugar_doc_comments, &token) {\n-            (true, &Token { kind: token::DocComment(_, attr_style, data), span }) => {\n-                // Searches for the occurrences of `\"#*` and returns the minimum number of `#`s\n-                // required to wrap the text.\n-                let mut num_of_hashes = 0;\n-                let mut count = 0;\n-                for ch in data.as_str().chars() {\n-                    count = match ch {\n-                        '\"' => 1,\n-                        '#' if count > 0 => count + 1,\n-                        _ => 0,\n-                    };\n-                    num_of_hashes = cmp::max(num_of_hashes, count);\n-                }\n+    fn desugar(&mut self, attr_style: AttrStyle, data: Symbol, span: Span) -> (Token, Spacing) {\n+        // Searches for the occurrences of `\"#*` and returns the minimum number of `#`s\n+        // required to wrap the text.\n+        let mut num_of_hashes = 0;\n+        let mut count = 0;\n+        for ch in data.as_str().chars() {\n+            count = match ch {\n+                '\"' => 1,\n+                '#' if count > 0 => count + 1,\n+                _ => 0,\n+            };\n+            num_of_hashes = cmp::max(num_of_hashes, count);\n+        }\n \n-                let delim_span = DelimSpan::from_single(span);\n-                let body = TokenTree::Delimited(\n-                    delim_span,\n-                    token::Bracket,\n-                    [\n-                        TokenTree::token(token::Ident(sym::doc, false), span),\n-                        TokenTree::token(token::Eq, span),\n-                        TokenTree::token(\n-                            TokenKind::lit(token::StrRaw(num_of_hashes), data, None),\n-                            span,\n-                        ),\n-                    ]\n-                    .iter()\n-                    .cloned()\n-                    .collect::<TokenStream>(),\n-                );\n+        let delim_span = DelimSpan::from_single(span);\n+        let body = TokenTree::Delimited(\n+            delim_span,\n+            token::Bracket,\n+            [\n+                TokenTree::token(token::Ident(sym::doc, false), span),\n+                TokenTree::token(token::Eq, span),\n+                TokenTree::token(TokenKind::lit(token::StrRaw(num_of_hashes), data, None), span),\n+            ]\n+            .iter()\n+            .cloned()\n+            .collect::<TokenStream>(),\n+        );\n \n-                self.stack.push(mem::replace(\n-                    &mut self.frame,\n-                    TokenCursorFrame::new(\n-                        delim_span,\n-                        token::NoDelim,\n-                        false,\n-                        if attr_style == AttrStyle::Inner {\n-                            [\n-                                TokenTree::token(token::Pound, span),\n-                                TokenTree::token(token::Not, span),\n-                                body,\n-                            ]\n-                            .iter()\n-                            .cloned()\n-                            .collect::<TokenStream>()\n-                        } else {\n-                            [TokenTree::token(token::Pound, span), body]\n-                                .iter()\n-                                .cloned()\n-                                .collect::<TokenStream>()\n-                        },\n-                        false,\n-                    ),\n-                ));\n-\n-                self.next(/* desugar_doc_comments */ false)\n-            }\n-            _ => (token, spacing),\n-        }\n+        self.stack.push(mem::replace(\n+            &mut self.frame,\n+            TokenCursorFrame::new(\n+                delim_span,\n+                token::NoDelim,\n+                false,\n+                if attr_style == AttrStyle::Inner {\n+                    [TokenTree::token(token::Pound, span), TokenTree::token(token::Not, span), body]\n+                        .iter()\n+                        .cloned()\n+                        .collect::<TokenStream>()\n+                } else {\n+                    [TokenTree::token(token::Pound, span), body]\n+                        .iter()\n+                        .cloned()\n+                        .collect::<TokenStream>()\n+                },\n+                false,\n+            ),\n+        ));\n+\n+        self.next(/* desugar_doc_comments */ false)\n     }\n }\n "}]}