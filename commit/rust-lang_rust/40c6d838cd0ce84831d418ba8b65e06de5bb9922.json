{"sha": "40c6d838cd0ce84831d418ba8b65e06de5bb9922", "node_id": "C_kwDOAAsO6NoAKDQwYzZkODM4Y2QwY2U4NDgzMWQ0MThiYThiNjVlMDZkZTViYjk5MjI", "commit": {"author": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2022-04-27T00:34:58Z"}, "committer": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2022-05-05T18:01:35Z"}, "message": "Don't cache results of coinductive cycle\n\nFixes #96319\n\nThe logic around handling co-inductive cycles in the evaluation cache\nis confusing and error prone. Fortunately, a perf run showed that it\ndoesn't actually appear to improve performance, so we can simplify\nthis code (and eliminate a source of ICEs) by just skipping caching\nthe evaluation results for co-inductive cycle participants.\n\nThis commit makes no changes to any of the other logic around\nco-inductive cycle handling. Thus, while this commit could\npotentially expose latent bugs that were being hidden by\ncaching, it should not introduce any new bugs.", "tree": {"sha": "4eaa0529b07236461582a772a937f7213ea072c6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4eaa0529b07236461582a772a937f7213ea072c6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/40c6d838cd0ce84831d418ba8b65e06de5bb9922", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE7J9Gc3TfBwj2K399tAh+UQ6YsWQFAmJ0EUoACgkQtAh+UQ6Y\nsWT6+RAAj/ZkhJFMwcEw7R7WLnCnKXmIFYKHr9Dpuyu89vjyYNfmJSe7heNrd2cy\naem2RjgkjXQp8giZ12yAy8LW+Go1hgr/GYTbm6a8wxmZ28CN8V/mEO1XZp9wuRi8\ncfuW9PfFRY/9WlbDjmfOXZn96PXl7r0G4JOWhVERT5fZ56CRG6HgM5wvB1JoFzBT\nAudlaJxa58STcvsv0IxYgMylPMWlEJpr2Nk5TtYC1ZcS3GtJsoF/5JbymnP+GCUL\nDEp81Ks38jBc2pBMqGtJOdZS6d93TmUgdjQ7IAbDAkcPG33qTBJVBUmn3GmosQsu\nO4AqAjBrkRMshd53Sgm4J31WYYJIY3gBg9f9ePsr7aZbUuzLp+07lIiaK13mQY7A\n/In58QGsHOqpy6FixSwHkV8RnrOrjJU1C8wnP3ff7ZDVrilJHXbxgFjnqy7mhbbD\nebsAhLN+Jao8UlWOy3LResSpP6/9x3wRTP9Vj4NQUaXg36h41GowV5s0Tr49TuJK\ndXUJPIXSppTly5GvY2AzsLaPdmPefrG5xwh9ggS1mVsNWjZ/GkaIZiWw8YMh9GTC\nYmE228Rd7NX9NzOS8ZrlAHHPzRl2GlDtf8GSi9mmVJREqC9zBTpoX65l8+5HHX+g\ni/ENMs90SebkQ4AA8tQmsBR9xUkxEmVedHZ2/eMuCHRwZepCS88=\n=ywJD\n-----END PGP SIGNATURE-----", "payload": "tree 4eaa0529b07236461582a772a937f7213ea072c6\nparent a7d6768e3b60209d4195c822ea3247482909b604\nauthor Aaron Hill <aa1ronham@gmail.com> 1651019698 -0400\ncommitter Aaron Hill <aa1ronham@gmail.com> 1651773695 -0400\n\nDon't cache results of coinductive cycle\n\nFixes #96319\n\nThe logic around handling co-inductive cycles in the evaluation cache\nis confusing and error prone. Fortunately, a perf run showed that it\ndoesn't actually appear to improve performance, so we can simplify\nthis code (and eliminate a source of ICEs) by just skipping caching\nthe evaluation results for co-inductive cycle participants.\n\nThis commit makes no changes to any of the other logic around\nco-inductive cycle handling. Thus, while this commit could\npotentially expose latent bugs that were being hidden by\ncaching, it should not introduce any new bugs.\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/40c6d838cd0ce84831d418ba8b65e06de5bb9922", "html_url": "https://github.com/rust-lang/rust/commit/40c6d838cd0ce84831d418ba8b65e06de5bb9922", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/40c6d838cd0ce84831d418ba8b65e06de5bb9922/comments", "author": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a7d6768e3b60209d4195c822ea3247482909b604", "url": "https://api.github.com/repos/rust-lang/rust/commits/a7d6768e3b60209d4195c822ea3247482909b604", "html_url": "https://github.com/rust-lang/rust/commit/a7d6768e3b60209d4195c822ea3247482909b604"}], "stats": {"total": 77, "additions": 18, "deletions": 59}, "files": [{"sha": "b4b367fe7c1904e6eb7dd0e01c3207ec83fd0d2b", "filename": "compiler/rustc_trait_selection/src/traits/select/mod.rs", "status": "modified", "additions": 18, "deletions": 59, "changes": 77, "blob_url": "https://github.com/rust-lang/rust/blob/40c6d838cd0ce84831d418ba8b65e06de5bb9922/compiler%2Frustc_trait_selection%2Fsrc%2Ftraits%2Fselect%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/40c6d838cd0ce84831d418ba8b65e06de5bb9922/compiler%2Frustc_trait_selection%2Fsrc%2Ftraits%2Fselect%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_trait_selection%2Fsrc%2Ftraits%2Fselect%2Fmod.rs?ref=40c6d838cd0ce84831d418ba8b65e06de5bb9922", "patch": "@@ -741,39 +741,7 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         if reached_depth >= stack.depth {\n             debug!(?result, \"CACHE MISS\");\n             self.insert_evaluation_cache(param_env, fresh_trait_pred, dep_node, result);\n-\n-            stack.cache().on_completion(\n-                stack.dfn,\n-                |fresh_trait_pred, provisional_result, provisional_dep_node| {\n-                    // Create a new `DepNode` that has dependencies on:\n-                    // * The `DepNode` for the original evaluation that resulted in a provisional cache\n-                    // entry being crated\n-                    // * The `DepNode` for the *current* evaluation, which resulted in us completing\n-                    // provisional caches entries and inserting them into the evaluation cache\n-                    //\n-                    // This ensures that when a query reads this entry from the evaluation cache,\n-                    // it will end up (transitively) depending on all of the incr-comp dependencies\n-                    // created during the evaluation of this trait. For example, evaluating a trait\n-                    // will usually require us to invoke `type_of(field_def_id)` to determine the\n-                    // constituent types, and we want any queries reading from this evaluation\n-                    // cache entry to end up with a transitive `type_of(field_def_id`)` dependency.\n-                    //\n-                    // By using `in_task`, we're also creating an edge from the *current* query\n-                    // to the newly-created `combined_dep_node`. This is probably redundant,\n-                    // but it's better to add too many dep graph edges than to add too few\n-                    // dep graph edges.\n-                    let ((), combined_dep_node) = self.in_task(|this| {\n-                        this.tcx().dep_graph.read_index(provisional_dep_node);\n-                        this.tcx().dep_graph.read_index(dep_node);\n-                    });\n-                    self.insert_evaluation_cache(\n-                        param_env,\n-                        fresh_trait_pred,\n-                        combined_dep_node,\n-                        provisional_result.max(result),\n-                    );\n-                },\n-            );\n+            stack.cache().on_completion(stack.dfn);\n         } else {\n             debug!(?result, \"PROVISIONAL\");\n             debug!(\n@@ -782,13 +750,7 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n                 fresh_trait_pred, stack.depth, reached_depth,\n             );\n \n-            stack.cache().insert_provisional(\n-                stack.dfn,\n-                reached_depth,\n-                fresh_trait_pred,\n-                result,\n-                dep_node,\n-            );\n+            stack.cache().insert_provisional(stack.dfn, reached_depth, fresh_trait_pred, result);\n         }\n \n         Ok(result)\n@@ -2531,11 +2493,6 @@ struct ProvisionalEvaluation {\n     from_dfn: usize,\n     reached_depth: usize,\n     result: EvaluationResult,\n-    /// The `DepNodeIndex` created for the `evaluate_stack` call for this provisional\n-    /// evaluation. When we create an entry in the evaluation cache using this provisional\n-    /// cache entry (see `on_completion`), we use this `dep_node` to ensure that future reads from\n-    /// the cache will have all of the necessary incr comp dependencies tracked.\n-    dep_node: DepNodeIndex,\n }\n \n impl<'tcx> Default for ProvisionalEvaluationCache<'tcx> {\n@@ -2578,7 +2535,6 @@ impl<'tcx> ProvisionalEvaluationCache<'tcx> {\n         reached_depth: usize,\n         fresh_trait_pred: ty::PolyTraitPredicate<'tcx>,\n         result: EvaluationResult,\n-        dep_node: DepNodeIndex,\n     ) {\n         debug!(?from_dfn, ?fresh_trait_pred, ?result, \"insert_provisional\");\n \n@@ -2604,10 +2560,7 @@ impl<'tcx> ProvisionalEvaluationCache<'tcx> {\n             }\n         }\n \n-        map.insert(\n-            fresh_trait_pred,\n-            ProvisionalEvaluation { from_dfn, reached_depth, result, dep_node },\n-        );\n+        map.insert(fresh_trait_pred, ProvisionalEvaluation { from_dfn, reached_depth, result });\n     }\n \n     /// Invoked when the node with dfn `dfn` does not get a successful\n@@ -2633,8 +2586,7 @@ impl<'tcx> ProvisionalEvaluationCache<'tcx> {\n     /// Invoked when the node at depth `depth` completed without\n     /// depending on anything higher in the stack (if that completion\n     /// was a failure, then `on_failure` should have been invoked\n-    /// already). The callback `op` will be invoked for each\n-    /// provisional entry that we can now confirm.\n+    /// already).\n     ///\n     /// Note that we may still have provisional cache items remaining\n     /// in the cache when this is done. For example, if there is a\n@@ -2655,19 +2607,26 @@ impl<'tcx> ProvisionalEvaluationCache<'tcx> {\n     /// would be 2, representing the C node, and hence we would\n     /// remove the result for D, which has DFN 3, but not the results for\n     /// A and B, which have DFNs 0 and 1 respectively).\n-    fn on_completion(\n-        &self,\n-        dfn: usize,\n-        mut op: impl FnMut(ty::PolyTraitPredicate<'tcx>, EvaluationResult, DepNodeIndex),\n-    ) {\n+    ///\n+    /// Note that we *do not* attempt to cache these cycle participants\n+    /// in the evaluation cache. Doing so would require carefully computing\n+    /// the correct `DepNode` to store in the cache entry:\n+    /// cycle participants may implicitly depend on query results\n+    /// related to other participants in the cycle, due to our logic\n+    /// which examines the evaluation stack.\n+    ///\n+    /// We used to try to perform this caching,\n+    /// but it lead to multiple incremental compilation ICEs\n+    /// (see #92987 and #96319), and was very hard to understand.\n+    /// Fortunately, removing the caching didn't seem to\n+    /// have a performance impact in practice.\n+    fn on_completion(&self, dfn: usize) {\n         debug!(?dfn, \"on_completion\");\n \n         for (fresh_trait_pred, eval) in\n             self.map.borrow_mut().drain_filter(|_k, eval| eval.from_dfn >= dfn)\n         {\n             debug!(?fresh_trait_pred, ?eval, \"on_completion\");\n-\n-            op(fresh_trait_pred, eval.result, eval.dep_node);\n         }\n     }\n }"}]}