{"sha": "0a4065d12df88409da6767c398e6c837f53844d6", "node_id": "C_kwDOAAsO6NoAKDBhNDA2NWQxMmRmODg0MDlkYTY3NjdjMzk4ZTZjODM3ZjUzODQ0ZDY", "commit": {"author": {"name": "Florian Diebold", "email": "flodiebold@gmail.com", "date": "2022-07-16T10:38:33Z"}, "committer": {"name": "Florian Diebold", "email": "flodiebold@gmail.com", "date": "2022-07-16T11:03:32Z"}, "message": "Improve syntax fixup a bit, handle incomplete `if`\n\n- allow appending tokens after a token, not just a node\n- allow inserting delimiters (and remove them again)\n- fix up `if {}` and `if` without anything following", "tree": {"sha": "d69daf3d5bddbc0babb0275c46d0bf9dcb95d460", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d69daf3d5bddbc0babb0275c46d0bf9dcb95d460"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0a4065d12df88409da6767c398e6c837f53844d6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0a4065d12df88409da6767c398e6c837f53844d6", "html_url": "https://github.com/rust-lang/rust/commit/0a4065d12df88409da6767c398e6c837f53844d6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0a4065d12df88409da6767c398e6c837f53844d6/comments", "author": {"login": "flodiebold", "id": 906069, "node_id": "MDQ6VXNlcjkwNjA2OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/906069?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flodiebold", "html_url": "https://github.com/flodiebold", "followers_url": "https://api.github.com/users/flodiebold/followers", "following_url": "https://api.github.com/users/flodiebold/following{/other_user}", "gists_url": "https://api.github.com/users/flodiebold/gists{/gist_id}", "starred_url": "https://api.github.com/users/flodiebold/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flodiebold/subscriptions", "organizations_url": "https://api.github.com/users/flodiebold/orgs", "repos_url": "https://api.github.com/users/flodiebold/repos", "events_url": "https://api.github.com/users/flodiebold/events{/privacy}", "received_events_url": "https://api.github.com/users/flodiebold/received_events", "type": "User", "site_admin": false}, "committer": {"login": "flodiebold", "id": 906069, "node_id": "MDQ6VXNlcjkwNjA2OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/906069?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flodiebold", "html_url": "https://github.com/flodiebold", "followers_url": "https://api.github.com/users/flodiebold/followers", "following_url": "https://api.github.com/users/flodiebold/following{/other_user}", "gists_url": "https://api.github.com/users/flodiebold/gists{/gist_id}", "starred_url": "https://api.github.com/users/flodiebold/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flodiebold/subscriptions", "organizations_url": "https://api.github.com/users/flodiebold/orgs", "repos_url": "https://api.github.com/users/flodiebold/repos", "events_url": "https://api.github.com/users/flodiebold/events{/privacy}", "received_events_url": "https://api.github.com/users/flodiebold/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "96481b7786fb1a987c2e912769ee5269fffbea0c", "url": "https://api.github.com/repos/rust-lang/rust/commits/96481b7786fb1a987c2e912769ee5269fffbea0c", "html_url": "https://github.com/rust-lang/rust/commit/96481b7786fb1a987c2e912769ee5269fffbea0c"}], "stats": {"total": 154, "additions": 120, "deletions": 34}, "files": [{"sha": "bd60c3d26868cb347a8b8a4242f71f89664d3f05", "filename": "crates/hir-expand/src/db.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0a4065d12df88409da6767c398e6c837f53844d6/crates%2Fhir-expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a4065d12df88409da6767c398e6c837f53844d6/crates%2Fhir-expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Fdb.rs?ref=0a4065d12df88409da6767c398e6c837f53844d6", "patch": "@@ -150,7 +150,7 @@ pub fn expand_speculative(\n     // Build the subtree and token mapping for the speculative args\n     let censor = censor_for_macro_input(&loc, speculative_args);\n     let mut fixups = fixup::fixup_syntax(speculative_args);\n-    fixups.replace.extend(censor.into_iter().map(|node| (node, Vec::new())));\n+    fixups.replace.extend(censor.into_iter().map(|node| (node.into(), Vec::new())));\n     let (mut tt, spec_args_tmap, _) = mbe::syntax_node_to_token_tree_with_modifications(\n         speculative_args,\n         fixups.token_map,\n@@ -295,7 +295,7 @@ fn macro_arg(\n     let node = SyntaxNode::new_root(arg);\n     let censor = censor_for_macro_input(&loc, &node);\n     let mut fixups = fixup::fixup_syntax(&node);\n-    fixups.replace.extend(censor.into_iter().map(|node| (node, Vec::new())));\n+    fixups.replace.extend(censor.into_iter().map(|node| (node.into(), Vec::new())));\n     let (mut tt, tmap, _) = mbe::syntax_node_to_token_tree_with_modifications(\n         &node,\n         fixups.token_map,"}, {"sha": "9999790fae727631460c91ff3c7120b9ed1171df", "filename": "crates/hir-expand/src/fixup.rs", "status": "modified", "additions": 91, "deletions": 10, "changes": 101, "blob_url": "https://github.com/rust-lang/rust/blob/0a4065d12df88409da6767c398e6c837f53844d6/crates%2Fhir-expand%2Fsrc%2Ffixup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a4065d12df88409da6767c398e6c837f53844d6/crates%2Fhir-expand%2Fsrc%2Ffixup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Ffixup.rs?ref=0a4065d12df88409da6767c398e6c837f53844d6", "patch": "@@ -6,7 +6,7 @@ use mbe::{SyntheticToken, SyntheticTokenId, TokenMap};\n use rustc_hash::FxHashMap;\n use syntax::{\n     ast::{self, AstNode},\n-    match_ast, SyntaxKind, SyntaxNode, TextRange,\n+    match_ast, SyntaxElement, SyntaxKind, SyntaxNode, TextRange,\n };\n use tt::Subtree;\n \n@@ -15,8 +15,8 @@ use tt::Subtree;\n /// reverse those changes afterwards, and a token map.\n #[derive(Debug)]\n pub(crate) struct SyntaxFixups {\n-    pub(crate) append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-    pub(crate) replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n+    pub(crate) append: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n+    pub(crate) replace: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n     pub(crate) undo_info: SyntaxFixupUndoInfo,\n     pub(crate) token_map: TokenMap,\n     pub(crate) next_id: u32,\n@@ -31,8 +31,8 @@ pub struct SyntaxFixupUndoInfo {\n const EMPTY_ID: SyntheticTokenId = SyntheticTokenId(!0);\n \n pub(crate) fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n-    let mut append = FxHashMap::default();\n-    let mut replace = FxHashMap::default();\n+    let mut append = FxHashMap::<SyntaxElement, _>::default();\n+    let mut replace = FxHashMap::<SyntaxElement, _>::default();\n     let mut preorder = node.preorder();\n     let mut original = Vec::new();\n     let mut token_map = TokenMap::default();\n@@ -63,7 +63,7 @@ pub(crate) fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n                 range: node.text_range(),\n                 id: SyntheticTokenId(idx),\n             };\n-            replace.insert(node.clone(), vec![replacement]);\n+            replace.insert(node.clone().into(), vec![replacement]);\n             preorder.skip_subtree();\n             continue;\n         }\n@@ -75,7 +75,7 @@ pub(crate) fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n                 ast::FieldExpr(it) => {\n                     if it.name_ref().is_none() {\n                         // incomplete field access: some_expr.|\n-                        append.insert(node.clone(), vec![\n+                        append.insert(node.clone().into(), vec![\n                             SyntheticToken {\n                                 kind: SyntaxKind::IDENT,\n                                 text: \"__ra_fixup\".into(),\n@@ -87,7 +87,7 @@ pub(crate) fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n                 },\n                 ast::ExprStmt(it) => {\n                     if it.semicolon_token().is_none() {\n-                        append.insert(node.clone(), vec![\n+                        append.insert(node.clone().into(), vec![\n                             SyntheticToken {\n                                 kind: SyntaxKind::SEMICOLON,\n                                 text: \";\".into(),\n@@ -99,7 +99,7 @@ pub(crate) fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n                 },\n                 ast::LetStmt(it) => {\n                     if it.semicolon_token().is_none() {\n-                        append.insert(node.clone(), vec![\n+                        append.insert(node.clone().into(), vec![\n                             SyntheticToken {\n                                 kind: SyntaxKind::SEMICOLON,\n                                 text: \";\".into(),\n@@ -109,6 +109,41 @@ pub(crate) fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n                         ]);\n                     }\n                 },\n+                ast::IfExpr(it) => {\n+                    if it.condition().is_none() {\n+                        // insert placeholder token after the if token\n+                        let if_token = match it.if_token() {\n+                            Some(t) => t,\n+                            None => continue,\n+                        };\n+                        append.insert(if_token.into(), vec![\n+                            SyntheticToken {\n+                                kind: SyntaxKind::IDENT,\n+                                text: \"__ra_fixup\".into(),\n+                                range: end_range,\n+                                id: EMPTY_ID,\n+                            },\n+                        ]);\n+                    }\n+                    if it.then_branch().is_none() {\n+                        append.insert(node.clone().into(), vec![\n+                            SyntheticToken {\n+                                kind: SyntaxKind::L_CURLY,\n+                                text: \"{\".into(),\n+                                range: end_range,\n+                                id: EMPTY_ID,\n+                            },\n+                            SyntheticToken {\n+                                kind: SyntaxKind::R_CURLY,\n+                                text: \"}\".into(),\n+                                range: end_range,\n+                                id: EMPTY_ID,\n+                            },\n+                        ]);\n+                    }\n+                },\n+                // FIXME: foo::\n+                // FIXME: for, loop, match etc.\n                 _ => (),\n             }\n         }\n@@ -144,7 +179,10 @@ pub(crate) fn reverse_fixups(\n             token_map.synthetic_token_id(leaf.id()).is_none()\n                 || token_map.synthetic_token_id(leaf.id()) != Some(EMPTY_ID)\n         }\n-        _ => true,\n+        tt::TokenTree::Subtree(st) => st.delimiter.map_or(true, |d| {\n+            token_map.synthetic_token_id(d.id).is_none()\n+                || token_map.synthetic_token_id(d.id) != Some(EMPTY_ID)\n+        }),\n     });\n     tt.token_trees.iter_mut().for_each(|tt| match tt {\n         tt::TokenTree::Subtree(tt) => reverse_fixups(tt, token_map, undo_info),\n@@ -295,6 +333,49 @@ fn foo() {\n \"#,\n             expect![[r#\"\n fn foo () {__ra_fixup ;}\n+\"#]],\n+        )\n+    }\n+\n+    #[test]\n+    fn fixup_if_1() {\n+        check(\n+            r#\"\n+fn foo() {\n+    if a\n+}\n+\"#,\n+            expect![[r#\"\n+fn foo () {if a {}}\n+\"#]],\n+        )\n+    }\n+\n+    #[test]\n+    fn fixup_if_2() {\n+        check(\n+            r#\"\n+fn foo() {\n+    if\n+}\n+\"#,\n+            expect![[r#\"\n+fn foo () {if __ra_fixup {}}\n+\"#]],\n+        )\n+    }\n+\n+    #[test]\n+    fn fixup_if_3() {\n+        check(\n+            r#\"\n+fn foo() {\n+    if {}\n+}\n+\"#,\n+            // the {} gets parsed as the condition, I think?\n+            expect![[r#\"\n+fn foo () {if {} {}}\n \"#]],\n         )\n     }"}, {"sha": "aca6ecd424e40021b1c3e90482b9595e8537908d", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 27, "deletions": 22, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/0a4065d12df88409da6767c398e6c837f53844d6/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a4065d12df88409da6767c398e6c837f53844d6/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=0a4065d12df88409da6767c398e6c837f53844d6", "patch": "@@ -31,8 +31,8 @@ pub fn syntax_node_to_token_tree_with_modifications(\n     node: &SyntaxNode,\n     existing_token_map: TokenMap,\n     next_id: u32,\n-    replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-    append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n+    replace: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n+    append: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n ) -> (tt::Subtree, TokenMap, u32) {\n     let global_offset = node.text_range().start();\n     let mut c = Convertor::new(node, global_offset, existing_token_map, next_id, replace, append);\n@@ -221,7 +221,7 @@ fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n \n             if let Some(kind) = delim {\n                 let mut subtree = tt::Subtree::default();\n-                let (id, idx) = conv.id_alloc().open_delim(range);\n+                let (id, idx) = conv.id_alloc().open_delim(range, synth_id);\n                 subtree.delimiter = Some(tt::Delimiter { id, kind });\n                 stack.push(StackEntry { subtree, idx, open_range: range });\n                 continue;\n@@ -404,14 +404,21 @@ impl TokenIdAlloc {\n         token_id\n     }\n \n-    fn open_delim(&mut self, open_abs_range: TextRange) -> (tt::TokenId, usize) {\n+    fn open_delim(\n+        &mut self,\n+        open_abs_range: TextRange,\n+        synthetic_id: Option<SyntheticTokenId>,\n+    ) -> (tt::TokenId, usize) {\n         let token_id = tt::TokenId(self.next_id);\n         self.next_id += 1;\n         let idx = self.map.insert_delim(\n             token_id,\n             open_abs_range - self.global_offset,\n             open_abs_range - self.global_offset,\n         );\n+        if let Some(id) = synthetic_id {\n+            self.map.insert_synthetic(token_id, id);\n+        }\n         (token_id, idx)\n     }\n \n@@ -511,8 +518,8 @@ struct Convertor {\n     current: Option<SyntaxToken>,\n     current_synthetic: Vec<SyntheticToken>,\n     preorder: PreorderWithTokens,\n-    replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-    append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n+    replace: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n+    append: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n     range: TextRange,\n     punct_offset: Option<(SyntaxToken, TextSize)>,\n }\n@@ -523,8 +530,8 @@ impl Convertor {\n         global_offset: TextSize,\n         existing_token_map: TokenMap,\n         next_id: u32,\n-        mut replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-        mut append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n+        mut replace: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n+        mut append: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n     ) -> Convertor {\n         let range = node.text_range();\n         let mut preorder = node.preorder_with_tokens();\n@@ -543,34 +550,32 @@ impl Convertor {\n \n     fn next_token(\n         preorder: &mut PreorderWithTokens,\n-        replace: &mut FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-        append: &mut FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n+        replace: &mut FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n+        append: &mut FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n     ) -> (Option<SyntaxToken>, Vec<SyntheticToken>) {\n         while let Some(ev) = preorder.next() {\n             let ele = match ev {\n                 WalkEvent::Enter(ele) => ele,\n-                WalkEvent::Leave(SyntaxElement::Node(node)) => {\n-                    if let Some(mut v) = append.remove(&node) {\n+                WalkEvent::Leave(ele) => {\n+                    if let Some(mut v) = append.remove(&ele) {\n                         if !v.is_empty() {\n                             v.reverse();\n                             return (None, v);\n                         }\n                     }\n                     continue;\n                 }\n-                _ => continue,\n             };\n+            if let Some(mut v) = replace.remove(&ele) {\n+                preorder.skip_subtree();\n+                if !v.is_empty() {\n+                    v.reverse();\n+                    return (None, v);\n+                }\n+            }\n             match ele {\n                 SyntaxElement::Token(t) => return (Some(t), Vec::new()),\n-                SyntaxElement::Node(node) => {\n-                    if let Some(mut v) = replace.remove(&node) {\n-                        preorder.skip_subtree();\n-                        if !v.is_empty() {\n-                            v.reverse();\n-                            return (None, v);\n-                        }\n-                    }\n-                }\n+                _ => {}\n             }\n         }\n         (None, Vec::new())"}]}