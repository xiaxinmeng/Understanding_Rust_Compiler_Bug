{"sha": "a8adf7685a4ddd16e985d34d9838a75a04ca4181", "node_id": "C_kwDOAAsO6NoAKGE4YWRmNzY4NWE0ZGRkMTZlOTg1ZDM0ZDk4MzhhNzVhMDRjYTQxODE", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-03-18T12:34:05Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-03-18T12:34:05Z"}, "message": "Auto merge of #95067 - nnethercote:parse_tt-more-refactoring, r=petrochenkov\n\nStill more refactoring of `parse_tt`\n\nr? `@petrochenkov`", "tree": {"sha": "fab79905362b925c6a5f7db8891902955a1aba64", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fab79905362b925c6a5f7db8891902955a1aba64"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a8adf7685a4ddd16e985d34d9838a75a04ca4181", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a8adf7685a4ddd16e985d34d9838a75a04ca4181", "html_url": "https://github.com/rust-lang/rust/commit/a8adf7685a4ddd16e985d34d9838a75a04ca4181", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a8adf7685a4ddd16e985d34d9838a75a04ca4181/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "691d1c1e12602c57237e9ccddac406ebd0c54082", "url": "https://api.github.com/repos/rust-lang/rust/commits/691d1c1e12602c57237e9ccddac406ebd0c54082", "html_url": "https://github.com/rust-lang/rust/commit/691d1c1e12602c57237e9ccddac406ebd0c54082"}, {"sha": "440a6855757d0a0166d5d08c00d91d7d0217fd56", "url": "https://api.github.com/repos/rust-lang/rust/commits/440a6855757d0a0166d5d08c00d91d7d0217fd56", "html_url": "https://github.com/rust-lang/rust/commit/440a6855757d0a0166d5d08c00d91d7d0217fd56"}], "stats": {"total": 266, "additions": 124, "deletions": 142}, "files": [{"sha": "8cc81f1eca8900ef0125195783bfe745745df88b", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 124, "deletions": 142, "changes": 266, "blob_url": "https://github.com/rust-lang/rust/blob/a8adf7685a4ddd16e985d34d9838a75a04ca4181/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a8adf7685a4ddd16e985d34d9838a75a04ca4181/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=a8adf7685a4ddd16e985d34d9838a75a04ca4181", "patch": "@@ -74,7 +74,7 @@ crate use NamedMatch::*;\n crate use ParseResult::*;\n use TokenTreeOrTokenTreeSlice::*;\n \n-use crate::mbe::{self, TokenTree};\n+use crate::mbe::{self, DelimSpan, SequenceRepetition, TokenTree};\n \n use rustc_ast::token::{self, DocComment, Nonterminal, Token};\n use rustc_parse::parser::Parser;\n@@ -93,28 +93,28 @@ use std::ops::{Deref, DerefMut};\n \n // To avoid costly uniqueness checks, we require that `MatchSeq` always has a nonempty body.\n \n-/// Either a sequence of token trees or a single one. This is used as the representation of the\n-/// sequence of tokens that make up a matcher.\n+/// Either a slice of token trees or a single one. This is used as the representation of the\n+/// token trees that make up a matcher.\n #[derive(Clone)]\n enum TokenTreeOrTokenTreeSlice<'tt> {\n     Tt(TokenTree),\n-    TtSeq(&'tt [TokenTree]),\n+    TtSlice(&'tt [TokenTree]),\n }\n \n impl<'tt> TokenTreeOrTokenTreeSlice<'tt> {\n     /// Returns the number of constituent top-level token trees of `self` (top-level in that it\n     /// will not recursively descend into subtrees).\n     fn len(&self) -> usize {\n         match *self {\n-            TtSeq(ref v) => v.len(),\n+            TtSlice(ref v) => v.len(),\n             Tt(ref tt) => tt.len(),\n         }\n     }\n \n     /// The `index`-th token tree of `self`.\n     fn get_tt(&self, index: usize) -> TokenTree {\n         match *self {\n-            TtSeq(ref v) => v[index].clone(),\n+            TtSlice(ref v) => v[index].clone(),\n             Tt(ref tt) => tt.get_tt(index),\n         }\n     }\n@@ -154,7 +154,7 @@ type NamedMatchVec = SmallVec<[NamedMatch; 4]>;\n /// lifetime. By separating `'tt` from `'root`, we can show that.\n #[derive(Clone)]\n struct MatcherPos<'root, 'tt> {\n-    /// The token or sequence of tokens that make up the matcher. `elts` is short for \"elements\".\n+    /// The token or slice of tokens that make up the matcher. `elts` is short for \"elements\".\n     top_elts: TokenTreeOrTokenTreeSlice<'tt>,\n \n     /// The position of the \"dot\" in this matcher\n@@ -203,21 +203,32 @@ struct MatcherPos<'root, 'tt> {\n rustc_data_structures::static_assert_size!(MatcherPos<'_, '_>, 240);\n \n impl<'root, 'tt> MatcherPos<'root, 'tt> {\n+    /// `len` `Vec`s (initially shared and empty) that will store matches of metavars.\n+    fn create_matches(len: usize) -> Box<[Lrc<NamedMatchVec>]> {\n+        if len == 0 {\n+            vec![]\n+        } else {\n+            let empty_matches = Lrc::new(SmallVec::new());\n+            vec![empty_matches; len]\n+        }\n+        .into_boxed_slice()\n+    }\n+\n     /// Generates the top-level matcher position in which the \"dot\" is before the first token of\n     /// the matcher `ms`.\n     fn new(ms: &'tt [TokenTree]) -> Self {\n         let match_idx_hi = count_names(ms);\n         MatcherPos {\n             // Start with the top level matcher given to us.\n-            top_elts: TtSeq(ms),\n+            top_elts: TtSlice(ms),\n \n             // The \"dot\" is before the first token of the matcher.\n             idx: 0,\n \n             // Initialize `matches` to a bunch of empty `Vec`s -- one for each metavar in\n             // `top_elts`. `match_lo` for `top_elts` is 0 and `match_hi` is `match_idx_hi`.\n             // `match_cur` is 0 since we haven't actually matched anything yet.\n-            matches: create_matches(match_idx_hi),\n+            matches: Self::create_matches(match_idx_hi),\n             match_lo: 0,\n             match_cur: 0,\n             match_hi: match_idx_hi,\n@@ -230,6 +241,27 @@ impl<'root, 'tt> MatcherPos<'root, 'tt> {\n         }\n     }\n \n+    fn repetition(\n+        up: MatcherPosHandle<'root, 'tt>,\n+        sp: DelimSpan,\n+        seq: Lrc<SequenceRepetition>,\n+    ) -> Self {\n+        MatcherPos {\n+            stack: smallvec![],\n+            idx: 0,\n+            matches: Self::create_matches(up.matches.len()),\n+            match_lo: up.match_cur,\n+            match_cur: up.match_cur,\n+            match_hi: up.match_cur + seq.num_captures,\n+            repetition: Some(MatcherPosRepetition {\n+                up,\n+                sep: seq.separator.clone(),\n+                seq_op: seq.kleene.op,\n+            }),\n+            top_elts: Tt(TokenTree::Sequence(sp, seq)),\n+        }\n+    }\n+\n     /// Adds `m` as a named match for the `idx`-th metavar.\n     fn push_match(&mut self, idx: usize, m: NamedMatch) {\n         let matches = Lrc::make_mut(&mut self.matches[idx]);\n@@ -336,17 +368,6 @@ pub(super) fn count_names(ms: &[TokenTree]) -> usize {\n     })\n }\n \n-/// `len` `Vec`s (initially shared and empty) that will store matches of metavars.\n-fn create_matches(len: usize) -> Box<[Lrc<NamedMatchVec>]> {\n-    if len == 0 {\n-        vec![]\n-    } else {\n-        let empty_matches = Lrc::new(SmallVec::new());\n-        vec![empty_matches; len]\n-    }\n-    .into_boxed_slice()\n-}\n-\n /// `NamedMatch` is a pattern-match result for a single `token::MATCH_NONTERMINAL`:\n /// so it is associated with a single ident in a parse, and all\n /// `MatchedNonterminal`s in the `NamedMatch` have the same non-terminal type\n@@ -401,7 +422,7 @@ crate enum NamedMatch {\n     MatchedNonterminal(Lrc<Nonterminal>),\n }\n \n-/// Takes a sequence of token trees `ms` representing a matcher which successfully matched input\n+/// Takes a slice of token trees `ms` representing a matcher which successfully matched input\n /// and an iterator of items that matched input and produces a `NamedParseResult`.\n fn nameize<I: Iterator<Item = NamedMatch>>(\n     sess: &ParseSess,\n@@ -472,7 +493,7 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n }\n \n /// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n-/// produce more items in `next_items`, `eof_items`, and `bb_items`.\n+/// produce more items in `next_items` and `bb_items`.\n ///\n /// For more info about the how this happens, see the module-level doc comments and the inline\n /// comments of this function.\n@@ -498,14 +519,14 @@ fn parse_tt_inner<'root, 'tt>(\n     bb_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n     token: &Token,\n ) -> Option<NamedParseResult> {\n-    // Matcher positions that would be valid if the macro invocation was over now\n+    // Matcher positions that would be valid if the macro invocation was over now. Only modified if\n+    // `token == Eof`.\n     let mut eof_items = EofItems::None;\n \n-    // Pop items from `cur_items` until it is empty.\n     while let Some(mut item) = cur_items.pop() {\n         // When unzipped trees end, remove them. This corresponds to backtracking out of a\n-        // delimited submatcher into which we already descended. In backtracking out again, we need\n-        // to advance the \"dot\" past the delimiters in the outer matcher.\n+        // delimited submatcher into which we already descended. When backtracking out again, we\n+        // need to advance the \"dot\" past the delimiters in the outer matcher.\n         while item.idx >= item.top_elts.len() {\n             match item.stack.pop() {\n                 Some(MatcherTtFrame { elts, idx }) => {\n@@ -521,76 +542,13 @@ fn parse_tt_inner<'root, 'tt>(\n         let idx = item.idx;\n         let len = item.top_elts.len();\n \n-        // If `idx >= len`, then we are at or past the end of the matcher of `item`.\n-        if idx >= len {\n-            // We are repeating iff there is a parent. If the matcher is inside of a repetition,\n-            // then we could be at the end of a sequence or at the beginning of the next\n-            // repetition.\n-            if let Some(repetition) = &item.repetition {\n-                debug_assert!(matches!(item.top_elts, Tt(TokenTree::Sequence(..))));\n-\n-                // At this point, regardless of whether there is a separator, we should add all\n-                // matches from the complete repetition of the sequence to the shared, top-level\n-                // `matches` list (actually, `up.matches`, which could itself not be the top-level,\n-                // but anyway...). Moreover, we add another item to `cur_items` in which the \"dot\"\n-                // is at the end of the `up` matcher. This ensures that the \"dot\" in the `up`\n-                // matcher is also advanced sufficiently.\n-                //\n-                // NOTE: removing the condition `idx == len` allows trailing separators.\n-                if idx == len {\n-                    // Get the `up` matcher\n-                    let mut new_pos = repetition.up.clone();\n-\n-                    // Add matches from this repetition to the `matches` of `up`\n-                    for idx in item.match_lo..item.match_hi {\n-                        let sub = item.matches[idx].clone();\n-                        new_pos.push_match(idx, MatchedSeq(sub));\n-                    }\n-\n-                    // Move the \"dot\" past the repetition in `up`\n-                    new_pos.match_cur = item.match_hi;\n-                    new_pos.idx += 1;\n-                    cur_items.push(new_pos);\n-                }\n-\n-                // Check if we need a separator.\n-                if idx == len && repetition.sep.is_some() {\n-                    // We have a separator, and it is the current token. We can advance past the\n-                    // separator token.\n-                    if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n-                        item.idx += 1;\n-                        next_items.push(item);\n-                    }\n-                } else if repetition.seq_op != mbe::KleeneOp::ZeroOrOne {\n-                    // We don't need a separator. Move the \"dot\" back to the beginning of the\n-                    // matcher and try to match again UNLESS we are only allowed to have _one_\n-                    // repetition.\n-                    item.match_cur = item.match_lo;\n-                    item.idx = 0;\n-                    cur_items.push(item);\n-                }\n-            } else {\n-                // If we are not in a repetition, then being at the end of a matcher means that we\n-                // have reached the potential end of the input.\n-                eof_items = match eof_items {\n-                    EofItems::None => EofItems::One(item),\n-                    EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n-                }\n-            }\n-        } else {\n-            // We are in the middle of a matcher. Look at what token in the matcher we are trying\n-            // to match the current token (`token`) against. Depending on that, we may generate new\n-            // items.\n+        if idx < len {\n+            // We are in the middle of a matcher. Compare the matcher's current tt against `token`.\n             match item.top_elts.get_tt(idx) {\n-                // Need to descend into a sequence\n                 TokenTree::Sequence(sp, seq) => {\n-                    // Examine the case where there are 0 matches of this sequence. We are\n-                    // implicitly disallowing OneOrMore from having 0 matches here. Thus, that will\n-                    // result in a \"no rules expected token\" error by virtue of this matcher not\n-                    // working.\n-                    if seq.kleene.op == mbe::KleeneOp::ZeroOrMore\n-                        || seq.kleene.op == mbe::KleeneOp::ZeroOrOne\n-                    {\n+                    let op = seq.kleene.op;\n+                    if op == mbe::KleeneOp::ZeroOrMore || op == mbe::KleeneOp::ZeroOrOne {\n+                        // Allow for the possibility of zero matches of this sequence.\n                         let mut new_item = item.clone();\n                         new_item.match_cur += seq.num_captures;\n                         new_item.idx += 1;\n@@ -600,32 +558,19 @@ fn parse_tt_inner<'root, 'tt>(\n                         cur_items.push(new_item);\n                     }\n \n-                    let matches = create_matches(item.matches.len());\n-                    cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos {\n-                        stack: smallvec![],\n-                        idx: 0,\n-                        matches,\n-                        match_lo: item.match_cur,\n-                        match_cur: item.match_cur,\n-                        match_hi: item.match_cur + seq.num_captures,\n-                        repetition: Some(MatcherPosRepetition {\n-                            up: item,\n-                            sep: seq.separator.clone(),\n-                            seq_op: seq.kleene.op,\n-                        }),\n-                        top_elts: Tt(TokenTree::Sequence(sp, seq)),\n-                    })));\n+                    // Allow for the possibility of one or more matches of this sequence.\n+                    cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos::repetition(\n+                        item, sp, seq,\n+                    ))));\n                 }\n \n-                // We need to match a metavar (but the identifier is invalid)... this is an error\n                 TokenTree::MetaVarDecl(span, _, None) => {\n+                    // E.g. `$e` instead of `$e:expr`.\n                     if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n                         return Some(Error(span, \"missing fragment specifier\".to_string()));\n                     }\n                 }\n \n-                // We need to match a metavar with a valid ident... call out to the black-box\n-                // parser by adding an item to `bb_items`.\n                 TokenTree::MetaVarDecl(_, _, Some(kind)) => {\n                     // Built-in nonterminals never start with these tokens, so we can eliminate\n                     // them from consideration.\n@@ -637,40 +582,82 @@ fn parse_tt_inner<'root, 'tt>(\n                     }\n                 }\n \n-                // We need to descend into a delimited submatcher or a doc comment. To do this, we\n-                // push the current matcher onto a stack and push a new item containing the\n-                // submatcher onto `cur_items`.\n-                //\n-                // At the beginning of the loop, if we reach the end of the delimited submatcher,\n-                // we pop the stack to backtrack out of the descent.\n                 seq @ (TokenTree::Delimited(..)\n                 | TokenTree::Token(Token { kind: DocComment(..), .. })) => {\n+                    // To descend into a delimited submatcher or a doc comment, we push the current\n+                    // matcher onto a stack and push a new item containing the submatcher onto\n+                    // `cur_items`.\n+                    //\n+                    // At the beginning of the loop, if we reach the end of the delimited\n+                    // submatcher, we pop the stack to backtrack out of the descent.\n                     let lower_elts = mem::replace(&mut item.top_elts, Tt(seq));\n                     let idx = item.idx;\n                     item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n                     item.idx = 0;\n                     cur_items.push(item);\n                 }\n \n-                // We just matched a normal token. We can just advance the parser.\n-                TokenTree::Token(t) if token_name_eq(&t, token) => {\n-                    item.idx += 1;\n-                    next_items.push(item);\n+                TokenTree::Token(t) => {\n+                    // If the token matches, we can just advance the parser. Otherwise, this match\n+                    // hash failed, there is nothing to do, and hopefully another item in\n+                    // `cur_items` will match.\n+                    if token_name_eq(&t, token) {\n+                        item.idx += 1;\n+                        next_items.push(item);\n+                    }\n                 }\n \n-                // There was another token that was not `token`... This means we can't add any\n-                // rules. NOTE that this is not necessarily an error unless _all_ items in\n-                // `cur_items` end up doing this. There may still be some other matchers that do\n-                // end up working out.\n-                TokenTree::Token(..) => {}\n-\n+                // These cannot appear in a matcher.\n                 TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n             }\n+        } else if let Some(repetition) = &item.repetition {\n+            // We are past the end of a repetition.\n+            debug_assert!(idx <= len + 1);\n+            debug_assert!(matches!(item.top_elts, Tt(TokenTree::Sequence(..))));\n+\n+            if idx == len {\n+                // Add all matches from the sequence to `up`, and move the \"dot\" past the\n+                // repetition in `up`. This allows for the case where the sequence matching is\n+                // finished.\n+                let mut new_pos = repetition.up.clone();\n+                for idx in item.match_lo..item.match_hi {\n+                    let sub = item.matches[idx].clone();\n+                    new_pos.push_match(idx, MatchedSeq(sub));\n+                }\n+                new_pos.match_cur = item.match_hi;\n+                new_pos.idx += 1;\n+                cur_items.push(new_pos);\n+            }\n+\n+            if idx == len && repetition.sep.is_some() {\n+                if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n+                    // The matcher has a separator, and it matches the current token. We can\n+                    // advance past the separator token.\n+                    item.idx += 1;\n+                    next_items.push(item);\n+                }\n+            } else if repetition.seq_op != mbe::KleeneOp::ZeroOrOne {\n+                // We don't need a separator. Move the \"dot\" back to the beginning of the\n+                // matcher and try to match again UNLESS we are only allowed to have _one_\n+                // repetition.\n+                item.match_cur = item.match_lo;\n+                item.idx = 0;\n+                cur_items.push(item);\n+            }\n+        } else {\n+            // We are past the end of the matcher, and not in a repetition. Look for end of input.\n+            debug_assert_eq!(idx, len);\n+            if *token == token::Eof {\n+                eof_items = match eof_items {\n+                    EofItems::None => EofItems::One(item),\n+                    EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n+                }\n+            }\n         }\n     }\n \n-    // If we reached the EOF, check that there is EXACTLY ONE possible matcher. Otherwise,\n-    // either the parse is ambiguous (which should never happen) or there is a syntax error.\n+    // If we reached the end of input, check that there is EXACTLY ONE possible matcher. Otherwise,\n+    // either the parse is ambiguous (which is an error) or there is a syntax error.\n     if *token == token::Eof {\n         Some(match eof_items {\n             EofItems::One(mut eof_item) => {\n@@ -694,8 +681,8 @@ fn parse_tt_inner<'root, 'tt>(\n     }\n }\n \n-/// Use the given sequence of token trees (`ms`) as a matcher. Match the token\n-/// stream from the given `parser` against it and return the match.\n+/// Use the given slice of token trees (`ms`) as a matcher. Match the token stream from the given\n+/// `parser` against it and return the match.\n pub(super) fn parse_tt(\n     parser: &mut Cow<'_, Parser<'_>>,\n     ms: &[TokenTree],\n@@ -707,20 +694,19 @@ pub(super) fn parse_tt(\n     // `next_items`. After some post-processing, the contents of `next_items` replenish `cur_items`\n     // and we start over again.\n     //\n-    // This MatcherPos instance is allocated on the stack. All others -- and\n-    // there are frequently *no* others! -- are allocated on the heap.\n+    // This MatcherPos instance is allocated on the stack. All others -- and there are frequently\n+    // *no* others! -- are allocated on the heap.\n     let mut initial = MatcherPos::new(ms);\n     let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n \n     loop {\n         let mut next_items = SmallVec::new();\n \n-        // Matcher positions black-box parsed by parser.rs (`parser`)\n+        // Matcher positions black-box parsed by `Parser`.\n         let mut bb_items = SmallVec::new();\n \n         // Process `cur_items` until either we have finished the input or we need to get some\n-        // parsing from the black-box parser done. The result is that `next_items` will contain a\n-        // bunch of possible next matcher positions in `next_items`.\n+        // parsing from the black-box parser done.\n         if let Some(result) = parse_tt_inner(\n             parser.sess,\n             ms,\n@@ -735,10 +721,7 @@ pub(super) fn parse_tt(\n         // `parse_tt_inner` handled all cur_items, so it's empty.\n         assert!(cur_items.is_empty());\n \n-        // We need to do some post processing after the `parse_tt_inner`.\n-        //\n         // Error messages here could be improved with links to original rules.\n-\n         match (next_items.len(), bb_items.len()) {\n             (0, 0) => {\n                 // There are no possible next positions AND we aren't waiting for the black-box\n@@ -782,8 +765,7 @@ pub(super) fn parse_tt(\n             }\n \n             (_, _) => {\n-                // We need to call the black-box parser to get some nonterminal, but something is\n-                // wrong.\n+                // Too many possibilities!\n                 return bb_items_ambiguity_error(\n                     macro_name,\n                     next_items,"}]}