{"sha": "c76590cb145c60b72b972f0fc88a66dd66e85ffa", "node_id": "MDY6Q29tbWl0NzI0NzEyOmM3NjU5MGNiMTQ1YzYwYjcyYjk3MmYwZmM4OGE2NmRkNjZlODVmZmE=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-12-21T08:04:00Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-12-21T17:26:42Z"}, "message": "rollup merge of #19944: steveklabnik/doc_sync_arc\n\nTake the docs from Rc<T>, apply them to Arc<T>, and fix some line lengths.", "tree": {"sha": "6d78b324deeb53e1035658611908daeb9e1ec8de", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6d78b324deeb53e1035658611908daeb9e1ec8de"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c76590cb145c60b72b972f0fc88a66dd66e85ffa", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c76590cb145c60b72b972f0fc88a66dd66e85ffa", "html_url": "https://github.com/rust-lang/rust/commit/c76590cb145c60b72b972f0fc88a66dd66e85ffa", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c76590cb145c60b72b972f0fc88a66dd66e85ffa/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "264088c1ee0aa6ffa37c3dda34a3d096bb31901e", "url": "https://api.github.com/repos/rust-lang/rust/commits/264088c1ee0aa6ffa37c3dda34a3d096bb31901e", "html_url": "https://github.com/rust-lang/rust/commit/264088c1ee0aa6ffa37c3dda34a3d096bb31901e"}, {"sha": "6875eb574802c4ea7da5b83bfc690bd1118be364", "url": "https://api.github.com/repos/rust-lang/rust/commits/6875eb574802c4ea7da5b83bfc690bd1118be364", "html_url": "https://github.com/rust-lang/rust/commit/6875eb574802c4ea7da5b83bfc690bd1118be364"}], "stats": {"total": 417, "additions": 329, "deletions": 88}, "files": [{"sha": "32d9097c45e2ae18e0238e168dc5602c4fb89a3c", "filename": "src/liballoc/arc.rs", "status": "modified", "additions": 315, "deletions": 71, "changes": 386, "blob_url": "https://github.com/rust-lang/rust/blob/c76590cb145c60b72b972f0fc88a66dd66e85ffa/src%2Fliballoc%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c76590cb145c60b72b972f0fc88a66dd66e85ffa/src%2Fliballoc%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Farc.rs?ref=c76590cb145c60b72b972f0fc88a66dd66e85ffa", "patch": "@@ -10,8 +10,61 @@\n \n #![stable]\n \n-//! Concurrency-enabled mechanisms for sharing mutable and/or immutable state\n-//! between tasks.\n+//! Threadsafe reference-counted boxes (the `Arc<T>` type).\n+//!\n+//! The `Arc<T>` type provides shared ownership of an immutable value. Destruction is\n+//! deterministic, and will occur as soon as the last owner is gone. It is marked as `Send` because\n+//! it uses atomic reference counting.\n+//!\n+//! If you do not need thread-safety, and just need shared ownership, consider the [`Rc<T>`\n+//! type](../rc/struct.Rc.html). It is the same as `Arc<T>`, but does not use atomics, making it\n+//! both thread-unsafe as well as significantly faster when updating the reference count.\n+//!\n+//! The `downgrade` method can be used to create a non-owning `Weak<T>` pointer to the box. A\n+//! `Weak<T>` pointer can be upgraded to an `Arc<T>` pointer, but will return `None` if the value\n+//! has already been dropped.\n+//!\n+//! For example, a tree with parent pointers can be represented by putting the nodes behind strong\n+//! `Arc<T>` pointers, and then storing the parent pointers as `Weak<T>` pointers.\n+//!\n+//! # Examples\n+//!\n+//! Sharing some immutable data between tasks:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! let five = Arc::new(5i);\n+//!\n+//! for i in range(0u, 10) {\n+//!     let five = five.clone();\n+//!\n+//!     spawn(move || {\n+//!         println!(\"{}\", five);\n+//!     });\n+//! }\n+//! ```\n+//!\n+//! Sharing mutable data safely between tasks with a `Mutex`:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//! use std::sync::Mutex;\n+//!\n+//! let five = Arc::new(Mutex::new(5i));\n+//!\n+//! for _ in range(0u, 10) {\n+//!     let five = five.clone();\n+//!\n+//!     spawn(move || {\n+//!         let mut number = five.lock();\n+//!\n+//!         number += 1;\n+//!\n+//!         println!(\"{}\", *number); // prints 6\n+//!     });\n+//! }\n+//! ```\n \n use core::atomic;\n use core::borrow::BorrowFrom;\n@@ -33,9 +86,8 @@ use heap::deallocate;\n ///\n /// # Example\n ///\n-/// In this example, a large vector of floats is shared between several tasks.\n-/// With simple pipes, without `Arc`, a copy would have to be made for each\n-/// task.\n+/// In this example, a large vector of floats is shared between several tasks. With simple pipes,\n+/// without `Arc`, a copy would have to be made for each task.\n ///\n /// ```rust\n /// use std::sync::Arc;\n@@ -66,8 +118,8 @@ pub struct Arc<T> {\n \n /// A weak pointer to an `Arc`.\n ///\n-/// Weak pointers will not keep the data inside of the `Arc` alive, and can be\n-/// used to break cycles between `Arc` pointers.\n+/// Weak pointers will not keep the data inside of the `Arc` alive, and can be used to break cycles\n+/// between `Arc` pointers.\n #[unsafe_no_drop_flag]\n #[experimental = \"Weak pointers may not belong in this module.\"]\n pub struct Weak<T> {\n@@ -83,7 +135,15 @@ struct ArcInner<T> {\n }\n \n impl<T: Sync + Send> Arc<T> {\n-    /// Creates an atomically reference counted wrapper.\n+    /// Constructs a new `Arc<T>`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    /// ```\n     #[inline]\n     #[stable]\n     pub fn new(data: T) -> Arc<T> {\n@@ -97,11 +157,17 @@ impl<T: Sync + Send> Arc<T> {\n         Arc { _ptr: unsafe { mem::transmute(x) } }\n     }\n \n-    /// Downgrades a strong pointer to a weak pointer.\n+    /// Downgrades the `Arc<T>` to a `Weak<T>` reference.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n     ///\n-    /// Weak pointers will not keep the data alive. Once all strong references\n-    /// to the underlying data have been dropped, the data itself will be\n-    /// destroyed.\n+    /// let weak_five = five.downgrade();\n+    /// ```\n     #[experimental = \"Weak pointers may not belong in this module.\"]\n     pub fn downgrade(&self) -> Weak<T> {\n         // See the clone() impl for why this is relaxed\n@@ -113,11 +179,10 @@ impl<T: Sync + Send> Arc<T> {\n impl<T> Arc<T> {\n     #[inline]\n     fn inner(&self) -> &ArcInner<T> {\n-        // This unsafety is ok because while this arc is alive we're guaranteed\n-        // that the inner pointer is valid. Furthermore, we know that the\n-        // `ArcInner` structure itself is `Sync` because the inner data is\n-        // `Sync` as well, so we're ok loaning out an immutable pointer to\n-        // these contents.\n+        // This unsafety is ok because while this arc is alive we're guaranteed that the inner\n+        // pointer is valid. Furthermore, we know that the `ArcInner` structure itself is `Sync`\n+        // because the inner data is `Sync` as well, so we're ok loaning out an immutable pointer\n+        // to these contents.\n         unsafe { &*self._ptr }\n     }\n }\n@@ -134,22 +199,28 @@ pub fn strong_count<T>(this: &Arc<T>) -> uint { this.inner().strong.load(atomic:\n \n #[unstable = \"waiting on stability of Clone\"]\n impl<T> Clone for Arc<T> {\n-    /// Duplicate an atomically reference counted wrapper.\n+    /// Makes a clone of the `Arc<T>`.\n     ///\n-    /// The resulting two `Arc` objects will point to the same underlying data\n-    /// object. However, one of the `Arc` objects can be sent to another task,\n-    /// allowing them to share the underlying data.\n+    /// This increases the strong reference count.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five.clone();\n+    /// ```\n     #[inline]\n     fn clone(&self) -> Arc<T> {\n-        // Using a relaxed ordering is alright here, as knowledge of the\n-        // original reference prevents other threads from erroneously deleting\n-        // the object.\n+        // Using a relaxed ordering is alright here, as knowledge of the original reference\n+        // prevents other threads from erroneously deleting the object.\n         //\n-        // As explained in the [Boost documentation][1], Increasing the\n-        // reference counter can always be done with memory_order_relaxed: New\n-        // references to an object can only be formed from an existing\n-        // reference, and passing an existing reference from one thread to\n-        // another must already provide any required synchronization.\n+        // As explained in the [Boost documentation][1], Increasing the reference counter can\n+        // always be done with memory_order_relaxed: New references to an object can only be formed\n+        // from an existing reference, and passing an existing reference from one thread to another\n+        // must already provide any required synchronization.\n         //\n         // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n         self.inner().strong.fetch_add(1, atomic::Relaxed);\n@@ -172,26 +243,33 @@ impl<T> Deref<T> for Arc<T> {\n }\n \n impl<T: Send + Sync + Clone> Arc<T> {\n-    /// Acquires a mutable pointer to the inner contents by guaranteeing that\n-    /// the reference count is one (no sharing is possible).\n+    /// Make a mutable reference from the given `Arc<T>`.\n+    ///\n+    /// This is also referred to as a copy-on-write operation because the inner data is cloned if\n+    /// the reference count is greater than one.\n     ///\n-    /// This is also referred to as a copy-on-write operation because the inner\n-    /// data is cloned if the reference count is greater than one.\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let mut five = Arc::new(5i);\n+    ///\n+    /// let mut_five = five.make_unique();\n+    /// ```\n     #[inline]\n     #[experimental]\n     pub fn make_unique(&mut self) -> &mut T {\n-        // Note that we hold a strong reference, which also counts as\n-        // a weak reference, so we only clone if there is an\n-        // additional reference of either kind.\n+        // Note that we hold a strong reference, which also counts as a weak reference, so we only\n+        // clone if there is an additional reference of either kind.\n         if self.inner().strong.load(atomic::SeqCst) != 1 ||\n            self.inner().weak.load(atomic::SeqCst) != 1 {\n             *self = Arc::new((**self).clone())\n         }\n-        // This unsafety is ok because we're guaranteed that the pointer\n-        // returned is the *only* pointer that will ever be returned to T. Our\n-        // reference count is guaranteed to be 1 at this point, and we required\n-        // the Arc itself to be `mut`, so we're returning the only possible\n-        // reference to the inner data.\n+        // This unsafety is ok because we're guaranteed that the pointer returned is the *only*\n+        // pointer that will ever be returned to T. Our reference count is guaranteed to be 1 at\n+        // this point, and we required the Arc itself to be `mut`, so we're returning the only\n+        // possible reference to the inner data.\n         let inner = unsafe { &mut *self._ptr };\n         &mut inner.data\n     }\n@@ -200,38 +278,59 @@ impl<T: Send + Sync + Clone> Arc<T> {\n #[unsafe_destructor]\n #[experimental = \"waiting on stability of Drop\"]\n impl<T: Sync + Send> Drop for Arc<T> {\n+    /// Drops the `Arc<T>`.\n+    ///\n+    /// This will decrement the strong reference count. If the strong reference count becomes zero\n+    /// and the only other references are `Weak<T>` ones, `drop`s the inner value.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// {\n+    ///     let five = Arc::new(5i);\n+    ///\n+    ///     // stuff\n+    ///\n+    ///     drop(five); // explict drop\n+    /// }\n+    /// {\n+    ///     let five = Arc::new(5i);\n+    ///\n+    ///     // stuff\n+    ///\n+    /// } // implicit drop\n+    /// ```\n     fn drop(&mut self) {\n-        // This structure has #[unsafe_no_drop_flag], so this drop glue may run\n-        // more than once (but it is guaranteed to be zeroed after the first if\n-        // it's run more than once)\n+        // This structure has #[unsafe_no_drop_flag], so this drop glue may run more than once (but\n+        // it is guaranteed to be zeroed after the first if it's run more than once)\n         if self._ptr.is_null() { return }\n \n-        // Because `fetch_sub` is already atomic, we do not need to synchronize\n-        // with other threads unless we are going to delete the object. This\n-        // same logic applies to the below `fetch_sub` to the `weak` count.\n+        // Because `fetch_sub` is already atomic, we do not need to synchronize with other threads\n+        // unless we are going to delete the object. This same logic applies to the below\n+        // `fetch_sub` to the `weak` count.\n         if self.inner().strong.fetch_sub(1, atomic::Release) != 1 { return }\n \n-        // This fence is needed to prevent reordering of use of the data and\n-        // deletion of the data. Because it is marked `Release`, the\n-        // decreasing of the reference count synchronizes with this `Acquire`\n-        // fence. This means that use of the data happens before decreasing\n-        // the reference count, which happens before this fence, which\n-        // happens before the deletion of the data.\n+        // This fence is needed to prevent reordering of use of the data and deletion of the data.\n+        // Because it is marked `Release`, the decreasing of the reference count synchronizes with\n+        // this `Acquire` fence. This means that use of the data happens before decreasing the\n+        // reference count, which happens before this fence, which happens before the deletion of\n+        // the data.\n         //\n         // As explained in the [Boost documentation][1],\n         //\n-        // It is important to enforce any possible access to the object in\n-        // one thread (through an existing reference) to *happen before*\n-        // deleting the object in a different thread. This is achieved by a\n-        // \"release\" operation after dropping a reference (any access to the\n-        // object through this reference must obviously happened before),\n-        // and an \"acquire\" operation before deleting the object.\n+        // > It is important to enforce any possible access to the object in one thread (through an\n+        // > existing reference) to *happen before* deleting the object in a different thread. This\n+        // > is achieved by a \"release\" operation after dropping a reference (any access to the\n+        // > object through this reference must obviously happened before), and an \"acquire\"\n+        // > operation before deleting the object.\n         //\n         // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n         atomic::fence(atomic::Acquire);\n \n-        // Destroy the data at this time, even though we may not free the box\n-        // allocation itself (there may still be weak pointers lying around).\n+        // Destroy the data at this time, even though we may not free the box allocation itself\n+        // (there may still be weak pointers lying around).\n         unsafe { drop(ptr::read(&self.inner().data)); }\n \n         if self.inner().weak.fetch_sub(1, atomic::Release) == 1 {\n@@ -244,14 +343,26 @@ impl<T: Sync + Send> Drop for Arc<T> {\n \n #[experimental = \"Weak pointers may not belong in this module.\"]\n impl<T: Sync + Send> Weak<T> {\n-    /// Attempts to upgrade this weak reference to a strong reference.\n+    /// Upgrades a weak reference to a strong reference.\n+    ///\n+    /// Upgrades the `Weak<T>` reference to an `Arc<T>`, if possible.\n+    ///\n+    /// Returns `None` if there were no strong references and the data was destroyed.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n     ///\n-    /// This method will not upgrade this reference if the strong reference count has already\n-    /// reached 0, but if there are still other active strong references this function will return\n-    /// a new strong reference to the data.\n+    /// let weak_five = five.downgrade();\n+    ///\n+    /// let strong_five: Option<Arc<_>> = weak_five.upgrade();\n+    /// ```\n     pub fn upgrade(&self) -> Option<Arc<T>> {\n-        // We use a CAS loop to increment the strong count instead of a\n-        // fetch_add because once the count hits 0 is must never be above 0.\n+        // We use a CAS loop to increment the strong count instead of a fetch_add because once the\n+        // count hits 0 is must never be above 0.\n         let inner = self.inner();\n         loop {\n             let n = inner.strong.load(atomic::SeqCst);\n@@ -270,6 +381,19 @@ impl<T: Sync + Send> Weak<T> {\n \n #[experimental = \"Weak pointers may not belong in this module.\"]\n impl<T: Sync + Send> Clone for Weak<T> {\n+    /// Makes a clone of the `Weak<T>`.\n+    ///\n+    /// This increases the weak reference count.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let weak_five = Arc::new(5i).downgrade();\n+    ///\n+    /// weak_five.clone();\n+    /// ```\n     #[inline]\n     fn clone(&self) -> Weak<T> {\n         // See comments in Arc::clone() for why this is relaxed\n@@ -281,13 +405,37 @@ impl<T: Sync + Send> Clone for Weak<T> {\n #[unsafe_destructor]\n #[experimental = \"Weak pointers may not belong in this module.\"]\n impl<T: Sync + Send> Drop for Weak<T> {\n+    /// Drops the `Weak<T>`.\n+    ///\n+    /// This will decrement the weak reference count.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// {\n+    ///     let five = Arc::new(5i);\n+    ///     let weak_five = five.downgrade();\n+    ///\n+    ///     // stuff\n+    ///\n+    ///     drop(weak_five); // explict drop\n+    /// }\n+    /// {\n+    ///     let five = Arc::new(5i);\n+    ///     let weak_five = five.downgrade();\n+    ///\n+    ///     // stuff\n+    ///\n+    /// } // implicit drop\n+    /// ```\n     fn drop(&mut self) {\n         // see comments above for why this check is here\n         if self._ptr.is_null() { return }\n \n-        // If we find out that we were the last weak pointer, then its time to\n-        // deallocate the data entirely. See the discussion in Arc::drop() about\n-        // the memory orderings\n+        // If we find out that we were the last weak pointer, then its time to deallocate the data\n+        // entirely. See the discussion in Arc::drop() about the memory orderings\n         if self.inner().weak.fetch_sub(1, atomic::Release) == 1 {\n             atomic::fence(atomic::Acquire);\n             unsafe { deallocate(self._ptr as *mut u8, size_of::<ArcInner<T>>(),\n@@ -298,18 +446,114 @@ impl<T: Sync + Send> Drop for Weak<T> {\n \n #[unstable = \"waiting on PartialEq\"]\n impl<T: PartialEq> PartialEq for Arc<T> {\n+    /// Equality for two `Arc<T>`s.\n+    ///\n+    /// Two `Arc<T>`s are equal if their inner value are equal.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five == Arc::new(5i);\n+    /// ```\n     fn eq(&self, other: &Arc<T>) -> bool { *(*self) == *(*other) }\n+\n+    /// Inequality for two `Arc<T>`s.\n+    ///\n+    /// Two `Arc<T>`s are unequal if their inner value are unequal.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five != Arc::new(5i);\n+    /// ```\n     fn ne(&self, other: &Arc<T>) -> bool { *(*self) != *(*other) }\n }\n #[unstable = \"waiting on PartialOrd\"]\n impl<T: PartialOrd> PartialOrd for Arc<T> {\n+    /// Partial comparison for two `Arc<T>`s.\n+    ///\n+    /// The two are compared by calling `partial_cmp()` on their inner values.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five.partial_cmp(&Arc::new(5i));\n+    /// ```\n     fn partial_cmp(&self, other: &Arc<T>) -> Option<Ordering> {\n         (**self).partial_cmp(&**other)\n     }\n+\n+    /// Less-than comparison for two `Arc<T>`s.\n+    ///\n+    /// The two are compared by calling `<` on their inner values.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five < Arc::new(5i);\n+    /// ```\n     fn lt(&self, other: &Arc<T>) -> bool { *(*self) < *(*other) }\n+\n+    /// 'Less-than or equal to' comparison for two `Arc<T>`s.\n+    ///\n+    /// The two are compared by calling `<=` on their inner values.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five <= Arc::new(5i);\n+    /// ```\n     fn le(&self, other: &Arc<T>) -> bool { *(*self) <= *(*other) }\n-    fn ge(&self, other: &Arc<T>) -> bool { *(*self) >= *(*other) }\n+\n+    /// Greater-than comparison for two `Arc<T>`s.\n+    ///\n+    /// The two are compared by calling `>` on their inner values.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five > Arc::new(5i);\n+    /// ```\n     fn gt(&self, other: &Arc<T>) -> bool { *(*self) > *(*other) }\n+\n+    /// 'Greater-than or equal to' comparison for two `Arc<T>`s.\n+    ///\n+    /// The two are compared by calling `>=` on their inner values.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::Arc;\n+    ///\n+    /// let five = Arc::new(5i);\n+    ///\n+    /// five >= Arc::new(5i);\n+    /// ```\n+    fn ge(&self, other: &Arc<T>) -> bool { *(*self) >= *(*other) }\n }\n #[unstable = \"waiting on Ord\"]\n impl<T: Ord> Ord for Arc<T> {"}, {"sha": "2ee4483a9191d4288f9783529b4fc4a306ff6d38", "filename": "src/liballoc/rc.rs", "status": "modified", "additions": 14, "deletions": 17, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/c76590cb145c60b72b972f0fc88a66dd66e85ffa/src%2Fliballoc%2Frc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c76590cb145c60b72b972f0fc88a66dd66e85ffa/src%2Fliballoc%2Frc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Frc.rs?ref=c76590cb145c60b72b972f0fc88a66dd66e85ffa", "patch": "@@ -168,12 +168,12 @@ struct RcBox<T> {\n \n /// An immutable reference-counted pointer type.\n ///\n-/// See the [module level documentation](../index.html) for more.\n+/// See the [module level documentation](../index.html) for more details.\n #[unsafe_no_drop_flag]\n #[stable]\n pub struct Rc<T> {\n-    // FIXME #12808: strange names to try to avoid interfering with\n-    // field accesses of the contained type via Deref\n+    // FIXME #12808: strange names to try to avoid interfering with field accesses of the contained\n+    // type via Deref\n     _ptr: *mut RcBox<T>,\n     _nosend: marker::NoSend,\n     _noshare: marker::NoSync\n@@ -193,11 +193,9 @@ impl<T> Rc<T> {\n     pub fn new(value: T) -> Rc<T> {\n         unsafe {\n             Rc {\n-                // there is an implicit weak pointer owned by all the\n-                // strong pointers, which ensures that the weak\n-                // destructor never frees the allocation while the\n-                // strong destructor is running, even if the weak\n-                // pointer is stored inside the strong one.\n+                // there is an implicit weak pointer owned by all the strong pointers, which\n+                // ensures that the weak destructor never frees the allocation while the strong\n+                // destructor is running, even if the weak pointer is stored inside the strong one.\n                 _ptr: transmute(box RcBox {\n                     value: value,\n                     strong: Cell::new(1),\n@@ -341,11 +339,10 @@ impl<T: Clone> Rc<T> {\n         if !is_unique(self) {\n             *self = Rc::new((**self).clone())\n         }\n-        // This unsafety is ok because we're guaranteed that the pointer\n-        // returned is the *only* pointer that will ever be returned to T. Our\n-        // reference count is guaranteed to be 1 at this point, and we required\n-        // the `Rc<T>` itself to be `mut`, so we're returning the only possible\n-        // reference to the inner value.\n+        // This unsafety is ok because we're guaranteed that the pointer returned is the *only*\n+        // pointer that will ever be returned to T. Our reference count is guaranteed to be 1 at\n+        // this point, and we required the `Rc<T>` itself to be `mut`, so we're returning the only\n+        // possible reference to the inner value.\n         let inner = unsafe { &mut *self._ptr };\n         &mut inner.value\n     }\n@@ -399,8 +396,8 @@ impl<T> Drop for Rc<T> {\n                 if self.strong() == 0 {\n                     ptr::read(&**self); // destroy the contained object\n \n-                    // remove the implicit \"strong weak\" pointer now\n-                    // that we've destroyed the contents.\n+                    // remove the implicit \"strong weak\" pointer now that we've destroyed the\n+                    // contents.\n                     self.dec_weak();\n \n                     if self.weak() == 0 {\n@@ -687,8 +684,8 @@ impl<T> Drop for Weak<T> {\n         unsafe {\n             if !self._ptr.is_null() {\n                 self.dec_weak();\n-                // the weak count starts at 1, and will only go to\n-                // zero if all the strong pointers have disappeared.\n+                // the weak count starts at 1, and will only go to zero if all the strong pointers\n+                // have disappeared.\n                 if self.weak() == 0 {\n                     deallocate(self._ptr as *mut u8, size_of::<RcBox<T>>(),\n                                min_align_of::<RcBox<T>>())"}]}