{"sha": "27cc0db7a248308fc2634ac68d7608a20b4a1c09", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI3Y2MwZGI3YTI0ODMwOGZjMjYzNGFjNjhkNzYwOGEyMGI0YTFjMDk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-05-23T13:28:27Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-05-23T13:28:27Z"}, "message": "Auto merge of #60965 - petrochenkov:lit3, r=matklad\n\nsyntax: Continue refactoring literals\n\nA follow up to https://github.com/rust-lang/rust/pull/60679.\n\nhttps://github.com/rust-lang/rust/commit/a2fd002bd5a91ba7997057724b72b9dac8fae550: Similarly to `EscapeError`, literal parsing now produces a `LitError`.\nThis way we can get rid of `diag: Option<(Span, &Handler)>` in interfaces while leaving attr/mod alone.\n\nhttps://github.com/rust-lang/rust/commit/d9516d11208456d4a17fe68a34c1d0a00334e62c: Gathers all components of a literal token in a single struct.", "tree": {"sha": "fa99e0dafd4ffae806ccad46fd9f26348d1a17bc", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fa99e0dafd4ffae806ccad46fd9f26348d1a17bc"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/27cc0db7a248308fc2634ac68d7608a20b4a1c09", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/27cc0db7a248308fc2634ac68d7608a20b4a1c09", "html_url": "https://github.com/rust-lang/rust/commit/27cc0db7a248308fc2634ac68d7608a20b4a1c09", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/27cc0db7a248308fc2634ac68d7608a20b4a1c09/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f688ba608923bdbf6b46ec65af2f6464b6233a75", "url": "https://api.github.com/repos/rust-lang/rust/commits/f688ba608923bdbf6b46ec65af2f6464b6233a75", "html_url": "https://github.com/rust-lang/rust/commit/f688ba608923bdbf6b46ec65af2f6464b6233a75"}, {"sha": "90d15e770419fb4ae8e120909baafc35ef243947", "url": "https://api.github.com/repos/rust-lang/rust/commits/90d15e770419fb4ae8e120909baafc35ef243947", "html_url": "https://github.com/rust-lang/rust/commit/90d15e770419fb4ae8e120909baafc35ef243947"}], "stats": {"total": 1084, "additions": 526, "deletions": 558}, "files": [{"sha": "c5337381a3d4f3dc7ae1722a361288d82ab7bbeb", "filename": "src/librustc/hir/print.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibrustc%2Fhir%2Fprint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibrustc%2Fhir%2Fprint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fprint.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1249,8 +1249,7 @@ impl<'a> State<'a> {\n \n     fn print_literal(&mut self, lit: &hir::Lit) -> io::Result<()> {\n         self.maybe_print_comment(lit.span.lo())?;\n-        let (token, suffix) = lit.node.to_lit_token();\n-        self.writer().word(pprust::literal_to_string(token, suffix))\n+        self.writer().word(pprust::literal_to_string(lit.node.to_lit_token()))\n     }\n \n     pub fn print_expr(&mut self, expr: &hir::Expr) -> io::Result<()> {"}, {"sha": "af53f686ae5481409b9e526c75a14c7fcd4747fc", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 18, "deletions": 16, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -165,7 +165,6 @@ impl_stable_hash_for!(enum ::syntax::ast::LitIntType {\n impl_stable_hash_for!(struct ::syntax::ast::Lit {\n     node,\n     token,\n-    suffix,\n     span\n });\n \n@@ -288,17 +287,23 @@ for tokenstream::TokenStream {\n     }\n }\n \n-impl_stable_hash_for!(enum token::Lit {\n-    Bool(val),\n-    Byte(val),\n-    Char(val),\n-    Err(val),\n-    Integer(val),\n-    Float(val),\n-    Str_(val),\n-    ByteStr(val),\n-    StrRaw(val, n),\n-    ByteStrRaw(val, n)\n+impl_stable_hash_for!(enum token::LitKind {\n+    Bool,\n+    Byte,\n+    Char,\n+    Integer,\n+    Float,\n+    Str,\n+    ByteStr,\n+    StrRaw(n),\n+    ByteStrRaw(n),\n+    Err\n+});\n+\n+impl_stable_hash_for!(struct token::Lit {\n+    kind,\n+    symbol,\n+    suffix\n });\n \n fn hash_token<'a, 'gcx, W: StableHasherResult>(\n@@ -348,10 +353,7 @@ fn hash_token<'a, 'gcx, W: StableHasherResult>(\n         token::Token::CloseDelim(delim_token) => {\n             std_hash::Hash::hash(&delim_token, hasher);\n         }\n-        token::Token::Literal(lit, opt_name) => {\n-            lit.hash_stable(hcx, hasher);\n-            opt_name.hash_stable(hcx, hasher);\n-        }\n+        token::Token::Literal(lit) => lit.hash_stable(hcx, hasher),\n \n         token::Token::Ident(ident, is_raw) => {\n             ident.name.hash_stable(hcx, hasher);"}, {"sha": "932419c78f22c1f03d6d09828e53e51d5e39b966", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -310,17 +310,17 @@ impl<'a> Classifier<'a> {\n                 }\n             }\n \n-            token::Literal(lit, _suf) => {\n-                match lit {\n+            token::Literal(lit) => {\n+                match lit.kind {\n                     // Text literals.\n-                    token::Byte(..) | token::Char(..) | token::Err(..) |\n-                        token::ByteStr(..) | token::ByteStrRaw(..) |\n-                        token::Str_(..) | token::StrRaw(..) => Class::String,\n+                    token::Byte | token::Char | token::Err |\n+                    token::ByteStr | token::ByteStrRaw(..) |\n+                    token::Str | token::StrRaw(..) => Class::String,\n \n                     // Number literals.\n-                    token::Integer(..) | token::Float(..) => Class::Number,\n+                    token::Integer | token::Float => Class::Number,\n \n-                    token::Bool(..) => panic!(\"literal token contains `Lit::Bool`\"),\n+                    token::Bool => panic!(\"literal token contains `Lit::Bool`\"),\n                 }\n             }\n "}, {"sha": "84ef0468cac7a420db1f694a6535b00c20cdcb6e", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1347,8 +1347,6 @@ pub enum StrStyle {\n pub struct Lit {\n     /// The original literal token as written in source code.\n     pub token: token::Lit,\n-    /// The original literal suffix as written in source code.\n-    pub suffix: Option<Symbol>,\n     /// The \"semantic\" representation of the literal lowered from the original tokens.\n     /// Strings are unescaped, hexadecimal forms are eliminated, etc.\n     /// FIXME: Remove this and only create the semantic representation during lowering to HIR."}, {"sha": "2f75a8c9db57e453f9165f5bb5819aef15c06791", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -554,7 +554,7 @@ impl MetaItemKind {\n             Some(TokenTree::Token(_, token::Eq)) => {\n                 tokens.next();\n                 return if let Some(TokenTree::Token(span, token)) = tokens.next() {\n-                    Lit::from_token(&token, span, None).map(MetaItemKind::NameValue)\n+                    Lit::from_token(&token, span).ok().map(MetaItemKind::NameValue)\n                 } else {\n                     None\n                 };\n@@ -599,7 +599,7 @@ impl NestedMetaItem {\n         where I: Iterator<Item = TokenTree>,\n     {\n         if let Some(TokenTree::Token(span, token)) = tokens.peek().cloned() {\n-            if let Some(lit) = Lit::from_token(&token, span, None) {\n+            if let Ok(lit) = Lit::from_token(&token, span) {\n                 tokens.next();\n                 return Some(NestedMetaItem::Literal(lit));\n             }"}, {"sha": "0c57c23b2b5c4102e61a83e5be5f4e99fafb46b4", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -77,8 +77,8 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt<'_>,\n         },\n         (3, Some(&TokenTree::Token(_, token::Ident(ref code, _))),\n             Some(&TokenTree::Token(_, token::Comma)),\n-            Some(&TokenTree::Token(_, token::Literal(token::StrRaw(description, _), None)))) => {\n-            (code, Some(description))\n+            Some(&TokenTree::Token(_, token::Literal(token::Lit { symbol, .. })))) => {\n+            (code, Some(symbol))\n         }\n         _ => unreachable!()\n     };"}, {"sha": "deb76d6d70a33f319d49ff15897cbfdcd4715d5c", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 51, "deletions": 54, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,5 +1,6 @@\n use crate::ast::{self, Ident};\n-use crate::parse::{token, ParseSess};\n+use crate::parse::ParseSess;\n+use crate::parse::token::{self, Token};\n use crate::symbol::Symbol;\n use crate::parse::unescape;\n use crate::parse::unescape_error_reporting::{emit_unescape_error, push_escaped_char};\n@@ -21,7 +22,7 @@ mod unicode_chars;\n \n #[derive(Clone, Debug)]\n pub struct TokenAndSpan {\n-    pub tok: token::Token,\n+    pub tok: Token,\n     pub sp: Span,\n }\n \n@@ -55,7 +56,7 @@ pub struct StringReader<'a> {\n     /// Stop reading src at this index.\n     crate end_src_index: usize,\n     // cached:\n-    peek_tok: token::Token,\n+    peek_tok: Token,\n     peek_span: Span,\n     peek_span_src_raw: Span,\n     fatal_errs: Vec<DiagnosticBuilder<'a>>,\n@@ -726,7 +727,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     /// Lex a LIT_INTEGER or a LIT_FLOAT\n-    fn scan_number(&mut self, c: char) -> token::Lit {\n+    fn scan_number(&mut self, c: char) -> (token::LitKind, Symbol) {\n         let mut base = 10;\n         let start_bpos = self.pos;\n         self.bump();\n@@ -753,7 +754,7 @@ impl<'a> StringReader<'a> {\n                 }\n                 _ => {\n                     // just a 0\n-                    return token::Integer(self.name_from(start_bpos));\n+                    return (token::Integer, self.name_from(start_bpos));\n                 }\n             }\n         } else if c.is_digit(10) {\n@@ -765,7 +766,7 @@ impl<'a> StringReader<'a> {\n         if num_digits == 0 {\n             self.err_span_(start_bpos, self.pos, \"no valid digits found for number\");\n \n-            return token::Integer(Symbol::intern(\"0\"));\n+            return (token::Integer, Symbol::intern(\"0\"));\n         }\n \n         // might be a float, but don't be greedy if this is actually an\n@@ -783,17 +784,17 @@ impl<'a> StringReader<'a> {\n             let pos = self.pos;\n             self.check_float_base(start_bpos, pos, base);\n \n-            token::Float(self.name_from(start_bpos))\n+            (token::Float, self.name_from(start_bpos))\n         } else {\n             // it might be a float if it has an exponent\n             if self.ch_is('e') || self.ch_is('E') {\n                 self.scan_float_exponent();\n                 let pos = self.pos;\n                 self.check_float_base(start_bpos, pos, base);\n-                return token::Float(self.name_from(start_bpos));\n+                return (token::Float, self.name_from(start_bpos));\n             }\n             // but we certainly have an integer!\n-            token::Integer(self.name_from(start_bpos))\n+            (token::Integer, self.name_from(start_bpos))\n         }\n     }\n \n@@ -846,7 +847,7 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    fn binop(&mut self, op: token::BinOpToken) -> token::Token {\n+    fn binop(&mut self, op: token::BinOpToken) -> Token {\n         self.bump();\n         if self.ch_is('=') {\n             self.bump();\n@@ -858,7 +859,7 @@ impl<'a> StringReader<'a> {\n \n     /// Returns the next token from the string, advances the input past that\n     /// token, and updates the interner\n-    fn next_token_inner(&mut self) -> Result<token::Token, ()> {\n+    fn next_token_inner(&mut self) -> Result<Token, ()> {\n         let c = self.ch;\n \n         if ident_start(c) {\n@@ -912,10 +913,10 @@ impl<'a> StringReader<'a> {\n         }\n \n         if is_dec_digit(c) {\n-            let num = self.scan_number(c.unwrap());\n+            let (kind, symbol) = self.scan_number(c.unwrap());\n             let suffix = self.scan_optional_raw_name();\n-            debug!(\"next_token_inner: scanned number {:?}, {:?}\", num, suffix);\n-            return Ok(token::Literal(num, suffix));\n+            debug!(\"next_token_inner: scanned number {:?}, {:?}, {:?}\", kind, symbol, suffix);\n+            return Ok(Token::lit(kind, symbol, suffix));\n         }\n \n         match c.expect(\"next_token_inner called at EOF\") {\n@@ -1073,10 +1074,10 @@ impl<'a> StringReader<'a> {\n                     // lifetimes shouldn't end with a single quote\n                     // if we find one, then this is an invalid character literal\n                     if self.ch_is('\\'') {\n-                        let id = self.name_from(start);\n+                        let symbol = self.name_from(start);\n                         self.bump();\n                         self.validate_char_escape(start_with_quote);\n-                        return Ok(token::Literal(token::Char(id), None))\n+                        return Ok(Token::lit(token::Char, symbol, None));\n                     }\n \n                     // Include the leading `'` in the real identifier, for macro\n@@ -1098,43 +1099,43 @@ impl<'a> StringReader<'a> {\n                     return Ok(token::Lifetime(ident));\n                 }\n                 let msg = \"unterminated character literal\";\n-                let id = self.scan_single_quoted_string(start_with_quote, msg);\n+                let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n                 self.validate_char_escape(start_with_quote);\n                 let suffix = self.scan_optional_raw_name();\n-                Ok(token::Literal(token::Char(id), suffix))\n+                Ok(Token::lit(token::Char, symbol, suffix))\n             }\n             'b' => {\n                 self.bump();\n-                let lit = match self.ch {\n+                let (kind, symbol) = match self.ch {\n                     Some('\\'') => {\n                         let start_with_quote = self.pos;\n                         self.bump();\n                         let msg = \"unterminated byte constant\";\n-                        let id = self.scan_single_quoted_string(start_with_quote, msg);\n+                        let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n                         self.validate_byte_escape(start_with_quote);\n-                        token::Byte(id)\n+                        (token::Byte, symbol)\n                     },\n                     Some('\"') => {\n                         let start_with_quote = self.pos;\n                         let msg = \"unterminated double quote byte string\";\n-                        let id = self.scan_double_quoted_string(msg);\n+                        let symbol = self.scan_double_quoted_string(msg);\n                         self.validate_byte_str_escape(start_with_quote);\n-                        token::ByteStr(id)\n+                        (token::ByteStr, symbol)\n                     },\n                     Some('r') => self.scan_raw_byte_string(),\n                     _ => unreachable!(),  // Should have been a token::Ident above.\n                 };\n                 let suffix = self.scan_optional_raw_name();\n \n-                Ok(token::Literal(lit, suffix))\n+                Ok(Token::lit(kind, symbol, suffix))\n             }\n             '\"' => {\n                 let start_with_quote = self.pos;\n                 let msg = \"unterminated double quote string\";\n-                let id = self.scan_double_quoted_string(msg);\n+                let symbol = self.scan_double_quoted_string(msg);\n                 self.validate_str_escape(start_with_quote);\n                 let suffix = self.scan_optional_raw_name();\n-                Ok(token::Literal(token::Str_(id), suffix))\n+                Ok(Token::lit(token::Str, symbol, suffix))\n             }\n             'r' => {\n                 let start_bpos = self.pos;\n@@ -1205,14 +1206,14 @@ impl<'a> StringReader<'a> {\n                 }\n \n                 self.bump();\n-                let id = if valid {\n+                let symbol = if valid {\n                     self.name_from_to(content_start_bpos, content_end_bpos)\n                 } else {\n                     Symbol::intern(\"??\")\n                 };\n                 let suffix = self.scan_optional_raw_name();\n \n-                Ok(token::Literal(token::StrRaw(id, hash_count), suffix))\n+                Ok(Token::lit(token::StrRaw(hash_count), symbol, suffix))\n             }\n             '-' => {\n                 if self.nextch_is('>') {\n@@ -1366,7 +1367,7 @@ impl<'a> StringReader<'a> {\n         id\n     }\n \n-    fn scan_raw_byte_string(&mut self) -> token::Lit {\n+    fn scan_raw_byte_string(&mut self) -> (token::LitKind, Symbol) {\n         let start_bpos = self.pos;\n         self.bump();\n         let mut hash_count = 0;\n@@ -1423,7 +1424,7 @@ impl<'a> StringReader<'a> {\n \n         self.bump();\n \n-        token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos), hash_count)\n+        (token::ByteStrRaw(hash_count), self.name_from_to(content_start_bpos, content_end_bpos))\n     }\n \n     fn validate_char_escape(&self, start_with_quote: BytePos) {\n@@ -1637,15 +1638,19 @@ mod tests {\n \n     // check that the given reader produces the desired stream\n     // of tokens (stop checking after exhausting the expected vec)\n-    fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<token::Token>) {\n+    fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<Token>) {\n         for expected_tok in &expected {\n             assert_eq!(&string_reader.next_token().tok, expected_tok);\n         }\n     }\n \n     // make the identifier by looking up the string in the interner\n-    fn mk_ident(id: &str) -> token::Token {\n-        token::Token::from_ast_ident(Ident::from_str(id))\n+    fn mk_ident(id: &str) -> Token {\n+        Token::from_ast_ident(Ident::from_str(id))\n+    }\n+\n+    fn mk_lit(kind: token::LitKind, symbol: &str, suffix: Option<&str>) -> Token {\n+        Token::lit(kind, Symbol::intern(symbol), suffix.map(Symbol::intern))\n     }\n \n     #[test]\n@@ -1694,7 +1699,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"'a'\".to_string()).next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+                       mk_lit(token::Char, \"a\", None));\n         })\n     }\n \n@@ -1704,7 +1709,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"' '\".to_string()).next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\" \")), None));\n+                       mk_lit(token::Char, \" \", None));\n         })\n     }\n \n@@ -1714,7 +1719,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\"\\\\n\")), None));\n+                       mk_lit(token::Char, \"\\\\n\", None));\n         })\n     }\n \n@@ -1724,7 +1729,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"'abc\".to_string()).next_token().tok,\n-                    token::Lifetime(Ident::from_str(\"'abc\")));\n+                       token::Lifetime(Ident::from_str(\"'abc\")));\n         })\n     }\n \n@@ -1733,10 +1738,8 @@ mod tests {\n         with_default_globals(|| {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n-            assert_eq!(setup(&sm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n-                        .next_token()\n-                        .tok,\n-                    token::Literal(token::StrRaw(Symbol::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n+            assert_eq!(setup(&sm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token().tok,\n+                       mk_lit(token::StrRaw(3), \"\\\"#a\\\\b\\x00c\\\"\", None));\n         })\n     }\n \n@@ -1748,18 +1751,16 @@ mod tests {\n             macro_rules! test {\n                 ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n                     assert_eq!(setup(&sm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n-                            token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n-                                            Some(Symbol::intern(\"suffix\"))));\n+                               mk_lit(token::$tok_type, $tok_contents, Some(\"suffix\")));\n                     // with a whitespace separator:\n                     assert_eq!(setup(&sm, &sh, format!(\"{} suffix\", $input)).next_token().tok,\n-                            token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n-                                            None));\n+                               mk_lit(token::$tok_type, $tok_contents, None));\n                 }}\n             }\n \n             test!(\"'a'\", Char, \"a\");\n             test!(\"b'a'\", Byte, \"a\");\n-            test!(\"\\\"a\\\"\", Str_, \"a\");\n+            test!(\"\\\"a\\\"\", Str, \"a\");\n             test!(\"b\\\"a\\\"\", ByteStr, \"a\");\n             test!(\"1234\", Integer, \"1234\");\n             test!(\"0b101\", Integer, \"0b101\");\n@@ -1768,14 +1769,11 @@ mod tests {\n             test!(\"1.0e10\", Float, \"1.0e10\");\n \n             assert_eq!(setup(&sm, &sh, \"2us\".to_string()).next_token().tok,\n-                    token::Literal(token::Integer(Symbol::intern(\"2\")),\n-                                    Some(Symbol::intern(\"us\"))));\n+                       mk_lit(token::Integer, \"2\", Some(\"us\")));\n             assert_eq!(setup(&sm, &sh, \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n-                    token::Literal(token::StrRaw(Symbol::intern(\"raw\"), 3),\n-                                    Some(Symbol::intern(\"suffix\"))));\n+                       mk_lit(token::StrRaw(3), \"raw\", Some(\"suffix\")));\n             assert_eq!(setup(&sm, &sh, \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n-                    token::Literal(token::ByteStrRaw(Symbol::intern(\"raw\"), 3),\n-                                    Some(Symbol::intern(\"suffix\"))));\n+                       mk_lit(token::ByteStrRaw(3), \"raw\", Some(\"suffix\")));\n         })\n     }\n \n@@ -1796,8 +1794,7 @@ mod tests {\n                 token::Comment => {}\n                 _ => panic!(\"expected a comment!\"),\n             }\n-            assert_eq!(lexer.next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+            assert_eq!(lexer.next_token().tok, mk_lit(token::Char, \"a\", None));\n         })\n     }\n "}, {"sha": "0305b1f59b94652e4f1027bdd10af7c85fbf4d1d", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 277, "deletions": 306, "changes": 583, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -6,7 +6,7 @@ use crate::parse::PResult;\n use crate::parse::token::{self, Token};\n use crate::parse::unescape::{unescape_str, unescape_char, unescape_byte_str, unescape_byte};\n use crate::print::pprust;\n-use crate::symbol::{kw, Symbol};\n+use crate::symbol::{kw, sym, Symbol};\n use crate::tokenstream::{TokenStream, TokenTree};\n \n use errors::{Applicability, Handler};\n@@ -16,197 +16,247 @@ use syntax_pos::Span;\n \n use std::ascii;\n \n-macro_rules! err {\n-    ($opt_diag:expr, |$span:ident, $diag:ident| $($body:tt)*) => {\n-        match $opt_diag {\n-            Some(($span, $diag)) => { $($body)* }\n-            None => return None,\n+crate enum LitError {\n+    NotLiteral,\n+    LexerError,\n+    InvalidSuffix,\n+    InvalidIntSuffix,\n+    InvalidFloatSuffix,\n+    NonDecimalFloat(u32),\n+    IntTooLarge,\n+}\n+\n+impl LitError {\n+    fn report(&self, diag: &Handler, lit: token::Lit, span: Span) {\n+        let token::Lit { kind, suffix, .. } = lit;\n+        match *self {\n+            // `NotLiteral` is not an error by itself, so we don't report\n+            // it and give the parser opportunity to try something else.\n+            LitError::NotLiteral => {}\n+            // `LexerError` *is* an error, but it was already reported\n+            // by lexer, so here we don't report it the second time.\n+            LitError::LexerError => {}\n+            LitError::InvalidSuffix => {\n+                expect_no_suffix(\n+                    diag, span, &format!(\"{} {} literal\", kind.article(), kind.descr()), suffix\n+                );\n+            }\n+            LitError::InvalidIntSuffix => {\n+                let suf = suffix.expect(\"suffix error with no suffix\").as_str();\n+                if looks_like_width_suffix(&['i', 'u'], &suf) {\n+                    // If it looks like a width, try to be helpful.\n+                    let msg = format!(\"invalid width `{}` for integer literal\", &suf[1..]);\n+                    diag.struct_span_err(span, &msg)\n+                        .help(\"valid widths are 8, 16, 32, 64 and 128\")\n+                        .emit();\n+                } else {\n+                    let msg = format!(\"invalid suffix `{}` for integer literal\", suf);\n+                    diag.struct_span_err(span, &msg)\n+                        .span_label(span, format!(\"invalid suffix `{}`\", suf))\n+                        .help(\"the suffix must be one of the integral types (`u32`, `isize`, etc)\")\n+                        .emit();\n+                }\n+            }\n+            LitError::InvalidFloatSuffix => {\n+                let suf = suffix.expect(\"suffix error with no suffix\").as_str();\n+                if looks_like_width_suffix(&['f'], &suf) {\n+                    // If it looks like a width, try to be helpful.\n+                    let msg = format!(\"invalid width `{}` for float literal\", &suf[1..]);\n+                    diag.struct_span_err(span, &msg)\n+                        .help(\"valid widths are 32 and 64\")\n+                        .emit();\n+                } else {\n+                    let msg = format!(\"invalid suffix `{}` for float literal\", suf);\n+                    diag.struct_span_err(span, &msg)\n+                        .span_label(span, format!(\"invalid suffix `{}`\", suf))\n+                        .help(\"valid suffixes are `f32` and `f64`\")\n+                        .emit();\n+                }\n+            }\n+            LitError::NonDecimalFloat(base) => {\n+                let descr = match base {\n+                    16 => \"hexadecimal\",\n+                    8 => \"octal\",\n+                    2 => \"binary\",\n+                    _ => unreachable!(),\n+                };\n+                diag.struct_span_err(span, &format!(\"{} float literal is not supported\", descr))\n+                    .span_label(span, \"not supported\")\n+                    .emit();\n+            }\n+            LitError::IntTooLarge => {\n+                diag.struct_span_err(span, \"integer literal is too large\")\n+                    .emit();\n+            }\n         }\n     }\n }\n \n impl LitKind {\n-    /// Converts literal token with a suffix into a semantic literal.\n-    /// Works speculatively and may return `None` if diagnostic handler is not passed.\n-    /// If diagnostic handler is passed, always returns `Some`,\n-    /// possibly after reporting non-fatal errors and recovery.\n-    fn from_lit_token(\n-        lit: token::Lit,\n-        suf: Option<Symbol>,\n-        diag: Option<(Span, &Handler)>\n-    ) -> Option<LitKind> {\n-        if suf.is_some() && !lit.may_have_suffix() {\n-            err!(diag, |span, diag| {\n-                expect_no_suffix(span, diag, &format!(\"a {}\", lit.literal_name()), suf)\n-            });\n+    /// Converts literal token into a semantic literal.\n+    fn from_lit_token(lit: token::Lit) -> Result<LitKind, LitError> {\n+        let token::Lit { kind, symbol, suffix } = lit;\n+        if suffix.is_some() && !kind.may_have_suffix() {\n+            return Err(LitError::InvalidSuffix);\n         }\n \n-        Some(match lit {\n-            token::Bool(i) => {\n-                assert!(i == kw::True || i == kw::False);\n-                LitKind::Bool(i == kw::True)\n+        Ok(match kind {\n+            token::Bool => {\n+                assert!(symbol == kw::True || symbol == kw::False);\n+                LitKind::Bool(symbol == kw::True)\n             }\n-            token::Byte(i) => {\n-                match unescape_byte(&i.as_str()) {\n-                    Ok(c) => LitKind::Byte(c),\n-                    Err(_) => LitKind::Err(i),\n-                }\n-            },\n-            token::Char(i) => {\n-                match unescape_char(&i.as_str()) {\n-                    Ok(c) => LitKind::Char(c),\n-                    Err(_) => LitKind::Err(i),\n-                }\n-            },\n-            token::Err(i) => LitKind::Err(i),\n+            token::Byte => return unescape_byte(&symbol.as_str())\n+                .map(LitKind::Byte).map_err(|_| LitError::LexerError),\n+            token::Char => return unescape_char(&symbol.as_str())\n+                .map(LitKind::Char).map_err(|_| LitError::LexerError),\n \n             // There are some valid suffixes for integer and float literals,\n             // so all the handling is done internally.\n-            token::Integer(s) => return integer_lit(&s.as_str(), suf, diag),\n-            token::Float(s) => return float_lit(&s.as_str(), suf, diag),\n+            token::Integer => return integer_lit(symbol, suffix),\n+            token::Float => return float_lit(symbol, suffix),\n \n-            token::Str_(mut sym) => {\n+            token::Str => {\n                 // If there are no characters requiring special treatment we can\n-                // reuse the symbol from the Token. Otherwise, we must generate a\n+                // reuse the symbol from the token. Otherwise, we must generate a\n                 // new symbol because the string in the LitKind is different to the\n-                // string in the Token.\n-                let mut has_error = false;\n-                let s = &sym.as_str();\n-                if s.as_bytes().iter().any(|&c| c == b'\\\\' || c == b'\\r') {\n+                // string in the token.\n+                let s = symbol.as_str();\n+                let symbol = if s.contains(&['\\\\', '\\r'][..]) {\n                     let mut buf = String::with_capacity(s.len());\n-                    unescape_str(s, &mut |_, unescaped_char| {\n+                    let mut error = Ok(());\n+                    unescape_str(&s, &mut |_, unescaped_char| {\n                         match unescaped_char {\n                             Ok(c) => buf.push(c),\n-                            Err(_) => has_error = true,\n+                            Err(_) => error = Err(LitError::LexerError),\n                         }\n                     });\n-                    if has_error {\n-                        return Some(LitKind::Err(sym));\n-                    }\n-                    sym = Symbol::intern(&buf)\n-                }\n-\n-                LitKind::Str(sym, ast::StrStyle::Cooked)\n+                    error?;\n+                    Symbol::intern(&buf)\n+                } else {\n+                    symbol\n+                };\n+                LitKind::Str(symbol, ast::StrStyle::Cooked)\n             }\n-            token::StrRaw(mut sym, n) => {\n+            token::StrRaw(n) => {\n                 // Ditto.\n-                let s = &sym.as_str();\n-                if s.contains('\\r') {\n-                    sym = Symbol::intern(&raw_str_lit(s));\n-                }\n-                LitKind::Str(sym, ast::StrStyle::Raw(n))\n+                let s = symbol.as_str();\n+                let symbol = if s.contains('\\r') {\n+                    Symbol::intern(&raw_str_lit(&s))\n+                } else {\n+                    symbol\n+                };\n+                LitKind::Str(symbol, ast::StrStyle::Raw(n))\n             }\n-            token::ByteStr(i) => {\n-                let s = &i.as_str();\n+            token::ByteStr => {\n+                let s = symbol.as_str();\n                 let mut buf = Vec::with_capacity(s.len());\n-                let mut has_error = false;\n-                unescape_byte_str(s, &mut |_, unescaped_byte| {\n+                let mut error = Ok(());\n+                unescape_byte_str(&s, &mut |_, unescaped_byte| {\n                     match unescaped_byte {\n                         Ok(c) => buf.push(c),\n-                        Err(_) => has_error = true,\n+                        Err(_) => error = Err(LitError::LexerError),\n                     }\n                 });\n-                if has_error {\n-                    return Some(LitKind::Err(i));\n-                }\n+                error?;\n                 buf.shrink_to_fit();\n                 LitKind::ByteStr(Lrc::new(buf))\n             }\n-            token::ByteStrRaw(i, _) => {\n-                LitKind::ByteStr(Lrc::new(i.to_string().into_bytes()))\n-            }\n+            token::ByteStrRaw(_) => LitKind::ByteStr(Lrc::new(symbol.to_string().into_bytes())),\n+            token::Err => LitKind::Err(symbol),\n         })\n     }\n \n     /// Attempts to recover a token from semantic literal.\n     /// This function is used when the original token doesn't exist (e.g. the literal is created\n     /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n-    pub fn to_lit_token(&self) -> (token::Lit, Option<Symbol>) {\n-        match *self {\n+    pub fn to_lit_token(&self) -> token::Lit {\n+        let (kind, symbol, suffix) = match *self {\n             LitKind::Str(string, ast::StrStyle::Cooked) => {\n                 let escaped = string.as_str().escape_default().to_string();\n-                (token::Lit::Str_(Symbol::intern(&escaped)), None)\n+                (token::Str, Symbol::intern(&escaped), None)\n             }\n             LitKind::Str(string, ast::StrStyle::Raw(n)) => {\n-                (token::Lit::StrRaw(string, n), None)\n+                (token::StrRaw(n), string, None)\n             }\n             LitKind::ByteStr(ref bytes) => {\n                 let string = bytes.iter().cloned().flat_map(ascii::escape_default)\n                     .map(Into::<char>::into).collect::<String>();\n-                (token::Lit::ByteStr(Symbol::intern(&string)), None)\n+                (token::ByteStr, Symbol::intern(&string), None)\n             }\n             LitKind::Byte(byte) => {\n                 let string: String = ascii::escape_default(byte).map(Into::<char>::into).collect();\n-                (token::Lit::Byte(Symbol::intern(&string)), None)\n+                (token::Byte, Symbol::intern(&string), None)\n             }\n             LitKind::Char(ch) => {\n                 let string: String = ch.escape_default().map(Into::<char>::into).collect();\n-                (token::Lit::Char(Symbol::intern(&string)), None)\n+                (token::Char, Symbol::intern(&string), None)\n             }\n             LitKind::Int(n, ty) => {\n                 let suffix = match ty {\n                     ast::LitIntType::Unsigned(ty) => Some(Symbol::intern(ty.ty_to_string())),\n                     ast::LitIntType::Signed(ty) => Some(Symbol::intern(ty.ty_to_string())),\n                     ast::LitIntType::Unsuffixed => None,\n                 };\n-                (token::Lit::Integer(Symbol::intern(&n.to_string())), suffix)\n+                (token::Integer, Symbol::intern(&n.to_string()), suffix)\n             }\n             LitKind::Float(symbol, ty) => {\n-                (token::Lit::Float(symbol), Some(Symbol::intern(ty.ty_to_string())))\n+                (token::Float, symbol, Some(Symbol::intern(ty.ty_to_string())))\n+            }\n+            LitKind::FloatUnsuffixed(symbol) => {\n+                (token::Float, symbol, None)\n             }\n-            LitKind::FloatUnsuffixed(symbol) => (token::Lit::Float(symbol), None),\n             LitKind::Bool(value) => {\n-                let kw = if value { kw::True } else { kw::False };\n-                (token::Lit::Bool(kw), None)\n+                let symbol = if value { kw::True } else { kw::False };\n+                (token::Bool, symbol, None)\n             }\n-            LitKind::Err(val) => (token::Lit::Err(val), None),\n-        }\n+            LitKind::Err(symbol) => {\n+                (token::Err, symbol, None)\n+            }\n+        };\n+\n+        token::Lit::new(kind, symbol, suffix)\n     }\n }\n \n impl Lit {\n-    /// Converts literal token with a suffix into an AST literal.\n-    /// Works speculatively and may return `None` if diagnostic handler is not passed.\n-    /// If diagnostic handler is passed, may return `Some`,\n-    /// possibly after reporting non-fatal errors and recovery, or `None` for irrecoverable errors.\n-    crate fn from_token(\n-        token: &token::Token,\n-        span: Span,\n-        diag: Option<(Span, &Handler)>,\n-    ) -> Option<Lit> {\n-        let (token, suffix) = match *token {\n+    /// Converts literal token into an AST literal.\n+    fn from_lit_token(token: token::Lit, span: Span) -> Result<Lit, LitError> {\n+        Ok(Lit { token, node: LitKind::from_lit_token(token)?, span })\n+    }\n+\n+    /// Converts arbitrary token into an AST literal.\n+    crate fn from_token(token: &Token, span: Span) -> Result<Lit, LitError> {\n+        let lit = match *token {\n             token::Ident(ident, false) if ident.name == kw::True || ident.name == kw::False =>\n-                (token::Bool(ident.name), None),\n-            token::Literal(token, suffix) =>\n-                (token, suffix),\n+                token::Lit::new(token::Bool, ident.name, None),\n+            token::Literal(lit) =>\n+                lit,\n             token::Interpolated(ref nt) => {\n                 if let token::NtExpr(expr) | token::NtLiteral(expr) = &**nt {\n                     if let ast::ExprKind::Lit(lit) = &expr.node {\n-                        return Some(lit.clone());\n+                        return Ok(lit.clone());\n                     }\n                 }\n-                return None;\n+                return Err(LitError::NotLiteral);\n             }\n-            _ => return None,\n+            _ => return Err(LitError::NotLiteral)\n         };\n \n-        let node = LitKind::from_lit_token(token, suffix, diag)?;\n-        Some(Lit { node, token, suffix, span })\n+        Lit::from_lit_token(lit, span)\n     }\n \n     /// Attempts to recover an AST literal from semantic literal.\n     /// This function is used when the original token doesn't exist (e.g. the literal is created\n     /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n     pub fn from_lit_kind(node: LitKind, span: Span) -> Lit {\n-        let (token, suffix) = node.to_lit_token();\n-        Lit { node, token, suffix, span }\n+        Lit { token: node.to_lit_token(), node, span }\n     }\n \n     /// Losslessly convert an AST literal into a token stream.\n     crate fn tokens(&self) -> TokenStream {\n-        let token = match self.token {\n-            token::Bool(symbol) => Token::Ident(Ident::with_empty_ctxt(symbol), false),\n-            token => Token::Literal(token, self.suffix),\n+        let token = match self.token.kind {\n+            token::Bool => token::Ident(Ident::new(self.token.symbol, self.span), false),\n+            _ => token::Literal(self.token),\n         };\n         TokenTree::Token(self.span, token).into()\n     }\n@@ -215,24 +265,22 @@ impl Lit {\n impl<'a> Parser<'a> {\n     /// Matches `lit = true | false | token_lit`.\n     crate fn parse_lit(&mut self) -> PResult<'a, Lit> {\n-        let diag = Some((self.span, &self.sess.span_diagnostic));\n-        if let Some(lit) = Lit::from_token(&self.token, self.span, diag) {\n-            self.bump();\n-            return Ok(lit);\n-        } else if self.token == token::Dot {\n-            // Recover `.4` as `0.4`.\n-            let recovered = self.look_ahead(1, |t| {\n-                if let token::Literal(token::Integer(val), suf) = *t {\n+        let mut recovered = None;\n+        if self.token == token::Dot {\n+            // Attempt to recover `.4` as `0.4`.\n+            recovered = self.look_ahead(1, |t| {\n+                if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = *t {\n                     let next_span = self.look_ahead_span(1);\n                     if self.span.hi() == next_span.lo() {\n-                        let sym = String::from(\"0.\") + &val.as_str();\n-                        let token = token::Literal(token::Float(Symbol::intern(&sym)), suf);\n+                        let s = String::from(\"0.\") + &symbol.as_str();\n+                        let token = Token::lit(token::Float, Symbol::intern(&s), suffix);\n                         return Some((token, self.span.to(next_span)));\n                     }\n                 }\n                 None\n             });\n-            if let Some((token, span)) = recovered {\n+            if let Some((ref token, span)) = recovered {\n+                self.bump();\n                 self.diagnostic()\n                     .struct_span_err(span, \"float literals must have an integer part\")\n                     .span_suggestion(\n@@ -242,63 +290,68 @@ impl<'a> Parser<'a> {\n                         Applicability::MachineApplicable,\n                     )\n                     .emit();\n-                let diag = Some((span, &self.sess.span_diagnostic));\n-                if let Some(lit) = Lit::from_token(&token, span, diag) {\n-                    self.bump();\n-                    self.bump();\n-                    return Ok(lit);\n-                }\n             }\n         }\n \n-        Err(self.span_fatal(self.span, &format!(\"unexpected token: {}\", self.this_token_descr())))\n-    }\n-}\n+        let (token, span) = recovered.as_ref().map_or((&self.token, self.span),\n+                                                      |(token, span)| (token, *span));\n \n-crate fn expect_no_suffix(sp: Span, diag: &Handler, kind: &str, suffix: Option<ast::Name>) {\n-    match suffix {\n-        None => {/* everything ok */}\n-        Some(suf) => {\n-            let text = suf.as_str();\n-            if text.is_empty() {\n-                diag.span_bug(sp, \"found empty literal suffix in Some\")\n+        match Lit::from_token(token, span) {\n+            Ok(lit) => {\n+                self.bump();\n+                Ok(lit)\n+            }\n+            Err(LitError::NotLiteral) => {\n+                let msg = format!(\"unexpected token: {}\", self.this_token_descr());\n+                Err(self.span_fatal(span, &msg))\n+            }\n+            Err(err) => {\n+                let lit = token.expect_lit();\n+                self.bump();\n+                err.report(&self.sess.span_diagnostic, lit, span);\n+                let lit = token::Lit::new(token::Err, lit.symbol, lit.suffix);\n+                Lit::from_lit_token(lit, span).map_err(|_| unreachable!())\n             }\n-            let mut err = if kind == \"a tuple index\" &&\n-                [\"i32\", \"u32\", \"isize\", \"usize\"].contains(&text.to_string().as_str())\n-            {\n-                // #59553: warn instead of reject out of hand to allow the fix to percolate\n-                // through the ecosystem when people fix their macros\n-                let mut err = diag.struct_span_warn(\n-                    sp,\n-                    &format!(\"suffixes on {} are invalid\", kind),\n-                );\n-                err.note(&format!(\n-                    \"`{}` is *temporarily* accepted on tuple index fields as it was \\\n-                        incorrectly accepted on stable for a few releases\",\n-                    text,\n-                ));\n-                err.help(\n-                    \"on proc macros, you'll want to use `syn::Index::from` or \\\n-                        `proc_macro::Literal::*_unsuffixed` for code that will desugar \\\n-                        to tuple field access\",\n-                );\n-                err.note(\n-                    \"for more context, see https://github.com/rust-lang/rust/issues/60210\",\n-                );\n-                err\n-            } else {\n-                diag.struct_span_err(sp, &format!(\"suffixes on {} are invalid\", kind))\n-            };\n-            err.span_label(sp, format!(\"invalid suffix `{}`\", text));\n-            err.emit();\n         }\n     }\n }\n \n+crate fn expect_no_suffix(diag: &Handler, sp: Span, kind: &str, suffix: Option<Symbol>) {\n+    if let Some(suf) = suffix {\n+        let mut err = if kind == \"a tuple index\" &&\n+                         [sym::i32, sym::u32, sym::isize, sym::usize].contains(&suf) {\n+            // #59553: warn instead of reject out of hand to allow the fix to percolate\n+            // through the ecosystem when people fix their macros\n+            let mut err = diag.struct_span_warn(\n+                sp,\n+                &format!(\"suffixes on {} are invalid\", kind),\n+            );\n+            err.note(&format!(\n+                \"`{}` is *temporarily* accepted on tuple index fields as it was \\\n+                    incorrectly accepted on stable for a few releases\",\n+                suf,\n+            ));\n+            err.help(\n+                \"on proc macros, you'll want to use `syn::Index::from` or \\\n+                    `proc_macro::Literal::*_unsuffixed` for code that will desugar \\\n+                    to tuple field access\",\n+            );\n+            err.note(\n+                \"for more context, see https://github.com/rust-lang/rust/issues/60210\",\n+            );\n+            err\n+        } else {\n+            diag.struct_span_err(sp, &format!(\"suffixes on {} are invalid\", kind))\n+        };\n+        err.span_label(sp, format!(\"invalid suffix `{}`\", suf));\n+        err.emit();\n+    }\n+}\n+\n /// Parses a string representing a raw string literal into its final form. The\n /// only operation this does is convert embedded CRLF into a single LF.\n fn raw_str_lit(lit: &str) -> String {\n-    debug!(\"raw_str_lit: given {}\", lit.escape_default());\n+    debug!(\"raw_str_lit: {:?}\", lit);\n     let mut res = String::with_capacity(lit.len());\n \n     let mut chars = lit.chars().peekable();\n@@ -318,169 +371,87 @@ fn raw_str_lit(lit: &str) -> String {\n     res\n }\n \n-// check if `s` looks like i32 or u1234 etc.\n+// Checks if `s` looks like i32 or u1234 etc.\n fn looks_like_width_suffix(first_chars: &[char], s: &str) -> bool {\n-    s.starts_with(first_chars) && s[1..].chars().all(|c| c.is_ascii_digit())\n+    s.len() > 1 && s.starts_with(first_chars) && s[1..].chars().all(|c| c.is_ascii_digit())\n }\n \n-fn filtered_float_lit(data: Symbol, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                      -> Option<LitKind> {\n-    debug!(\"filtered_float_lit: {}, {:?}\", data, suffix);\n-    let suffix = match suffix {\n-        Some(suffix) => suffix,\n-        None => return Some(LitKind::FloatUnsuffixed(data)),\n-    };\n-\n-    Some(match &*suffix.as_str() {\n-        \"f32\" => LitKind::Float(data, ast::FloatTy::F32),\n-        \"f64\" => LitKind::Float(data, ast::FloatTy::F64),\n-        suf => {\n-            err!(diag, |span, diag| {\n-                if suf.len() >= 2 && looks_like_width_suffix(&['f'], suf) {\n-                    // if it looks like a width, lets try to be helpful.\n-                    let msg = format!(\"invalid width `{}` for float literal\", &suf[1..]);\n-                    diag.struct_span_err(span, &msg).help(\"valid widths are 32 and 64\").emit()\n-                } else {\n-                    let msg = format!(\"invalid suffix `{}` for float literal\", suf);\n-                    diag.struct_span_err(span, &msg)\n-                        .span_label(span, format!(\"invalid suffix `{}`\", suf))\n-                        .help(\"valid suffixes are `f32` and `f64`\")\n-                        .emit();\n-                }\n-            });\n+fn strip_underscores(symbol: Symbol) -> Symbol {\n+    // Do not allocate a new string unless necessary.\n+    let s = symbol.as_str();\n+    if s.contains('_') {\n+        let mut s = s.to_string();\n+        s.retain(|c| c != '_');\n+        return Symbol::intern(&s);\n+    }\n+    symbol\n+}\n \n-            LitKind::FloatUnsuffixed(data)\n+fn filtered_float_lit(symbol: Symbol, suffix: Option<Symbol>, base: u32)\n+                      -> Result<LitKind, LitError> {\n+    debug!(\"filtered_float_lit: {:?}, {:?}, {:?}\", symbol, suffix, base);\n+    if base != 10 {\n+        return Err(LitError::NonDecimalFloat(base));\n+    }\n+    Ok(match suffix {\n+        Some(suf) => match suf {\n+            sym::f32 => LitKind::Float(symbol, ast::FloatTy::F32),\n+            sym::f64 => LitKind::Float(symbol, ast::FloatTy::F64),\n+            _ => return Err(LitError::InvalidFloatSuffix),\n         }\n+        None => LitKind::FloatUnsuffixed(symbol)\n     })\n }\n-fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                 -> Option<LitKind> {\n-    debug!(\"float_lit: {:?}, {:?}\", s, suffix);\n-    // FIXME #2252: bounds checking float literals is deferred until trans\n-\n-    // Strip underscores without allocating a new String unless necessary.\n-    let s2;\n-    let s = if s.chars().any(|c| c == '_') {\n-        s2 = s.chars().filter(|&c| c != '_').collect::<String>();\n-        &s2\n-    } else {\n-        s\n-    };\n \n-    filtered_float_lit(Symbol::intern(s), suffix, diag)\n+fn float_lit(symbol: Symbol, suffix: Option<Symbol>) -> Result<LitKind, LitError> {\n+    debug!(\"float_lit: {:?}, {:?}\", symbol, suffix);\n+    filtered_float_lit(strip_underscores(symbol), suffix, 10)\n }\n \n-fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                   -> Option<LitKind> {\n-    // s can only be ascii, byte indexing is fine\n-\n-    // Strip underscores without allocating a new String unless necessary.\n-    let s2;\n-    let mut s = if s.chars().any(|c| c == '_') {\n-        s2 = s.chars().filter(|&c| c != '_').collect::<String>();\n-        &s2\n-    } else {\n-        s\n-    };\n-\n-    debug!(\"integer_lit: {}, {:?}\", s, suffix);\n+fn integer_lit(symbol: Symbol, suffix: Option<Symbol>) -> Result<LitKind, LitError> {\n+    debug!(\"integer_lit: {:?}, {:?}\", symbol, suffix);\n+    let symbol = strip_underscores(symbol);\n+    let s = symbol.as_str();\n \n     let mut base = 10;\n-    let orig = s;\n-    let mut ty = ast::LitIntType::Unsuffixed;\n-\n-    if s.starts_with('0') && s.len() > 1 {\n+    if s.len() > 1 && s.as_bytes()[0] == b'0' {\n         match s.as_bytes()[1] {\n             b'x' => base = 16,\n             b'o' => base = 8,\n             b'b' => base = 2,\n-            _ => { }\n+            _ => {}\n         }\n     }\n \n-    // 1f64 and 2f32 etc. are valid float literals.\n-    if let Some(suf) = suffix {\n-        if looks_like_width_suffix(&['f'], &suf.as_str()) {\n-            let err = match base {\n-                16 => Some(\"hexadecimal float literal is not supported\"),\n-                8 => Some(\"octal float literal is not supported\"),\n-                2 => Some(\"binary float literal is not supported\"),\n-                _ => None,\n-            };\n-            if let Some(err) = err {\n-                err!(diag, |span, diag| {\n-                    diag.struct_span_err(span, err)\n-                        .span_label(span, \"not supported\")\n-                        .emit();\n-                });\n-            }\n-            return filtered_float_lit(Symbol::intern(s), Some(suf), diag)\n-        }\n-    }\n-\n-    if base != 10 {\n-        s = &s[2..];\n-    }\n-\n-    if let Some(suf) = suffix {\n-        if suf.as_str().is_empty() {\n-            err!(diag, |span, diag| diag.span_bug(span, \"found empty literal suffix in Some\"));\n-        }\n-        ty = match &*suf.as_str() {\n-            \"isize\" => ast::LitIntType::Signed(ast::IntTy::Isize),\n-            \"i8\"  => ast::LitIntType::Signed(ast::IntTy::I8),\n-            \"i16\" => ast::LitIntType::Signed(ast::IntTy::I16),\n-            \"i32\" => ast::LitIntType::Signed(ast::IntTy::I32),\n-            \"i64\" => ast::LitIntType::Signed(ast::IntTy::I64),\n-            \"i128\" => ast::LitIntType::Signed(ast::IntTy::I128),\n-            \"usize\" => ast::LitIntType::Unsigned(ast::UintTy::Usize),\n-            \"u8\"  => ast::LitIntType::Unsigned(ast::UintTy::U8),\n-            \"u16\" => ast::LitIntType::Unsigned(ast::UintTy::U16),\n-            \"u32\" => ast::LitIntType::Unsigned(ast::UintTy::U32),\n-            \"u64\" => ast::LitIntType::Unsigned(ast::UintTy::U64),\n-            \"u128\" => ast::LitIntType::Unsigned(ast::UintTy::U128),\n-            suf => {\n-                // i<digits> and u<digits> look like widths, so lets\n-                // give an error message along those lines\n-                err!(diag, |span, diag| {\n-                    if looks_like_width_suffix(&['i', 'u'], suf) {\n-                        let msg = format!(\"invalid width `{}` for integer literal\", &suf[1..]);\n-                        diag.struct_span_err(span, &msg)\n-                            .help(\"valid widths are 8, 16, 32, 64 and 128\")\n-                            .emit();\n-                    } else {\n-                        let msg = format!(\"invalid suffix `{}` for numeric literal\", suf);\n-                        diag.struct_span_err(span, &msg)\n-                            .span_label(span, format!(\"invalid suffix `{}`\", suf))\n-                            .help(\"the suffix must be one of the integral types \\\n-                                   (`u32`, `isize`, etc)\")\n-                            .emit();\n-                    }\n-                });\n-\n-                ty\n-            }\n+    let ty = match suffix {\n+        Some(suf) => match suf {\n+            sym::isize => ast::LitIntType::Signed(ast::IntTy::Isize),\n+            sym::i8  => ast::LitIntType::Signed(ast::IntTy::I8),\n+            sym::i16 => ast::LitIntType::Signed(ast::IntTy::I16),\n+            sym::i32 => ast::LitIntType::Signed(ast::IntTy::I32),\n+            sym::i64 => ast::LitIntType::Signed(ast::IntTy::I64),\n+            sym::i128 => ast::LitIntType::Signed(ast::IntTy::I128),\n+            sym::usize => ast::LitIntType::Unsigned(ast::UintTy::Usize),\n+            sym::u8  => ast::LitIntType::Unsigned(ast::UintTy::U8),\n+            sym::u16 => ast::LitIntType::Unsigned(ast::UintTy::U16),\n+            sym::u32 => ast::LitIntType::Unsigned(ast::UintTy::U32),\n+            sym::u64 => ast::LitIntType::Unsigned(ast::UintTy::U64),\n+            sym::u128 => ast::LitIntType::Unsigned(ast::UintTy::U128),\n+            // `1f64` and `2f32` etc. are valid float literals, and\n+            // `fxxx` looks more like an invalid float literal than invalid integer literal.\n+            _ if suf.as_str().starts_with('f') => return filtered_float_lit(symbol, suffix, base),\n+            _ => return Err(LitError::InvalidIntSuffix),\n         }\n-    }\n-\n-    debug!(\"integer_lit: the type is {:?}, base {:?}, the new string is {:?}, the original \\\n-           string was {:?}, the original suffix was {:?}\", ty, base, s, orig, suffix);\n-\n-    Some(match u128::from_str_radix(s, base) {\n-        Ok(r) => LitKind::Int(r, ty),\n-        Err(_) => {\n-            // small bases are lexed as if they were base 10, e.g, the string\n-            // might be `0b10201`. This will cause the conversion above to fail,\n-            // but these cases have errors in the lexer: we don't want to emit\n-            // two errors, and we especially don't want to emit this error since\n-            // it isn't necessarily true.\n-            let already_errored = base < 10 &&\n-                s.chars().any(|c| c.to_digit(10).map_or(false, |d| d >= base));\n+        _ => ast::LitIntType::Unsuffixed\n+    };\n \n-            if !already_errored {\n-                err!(diag, |span, diag| diag.span_err(span, \"int literal is too large\"));\n-            }\n-            LitKind::Int(0, ty)\n-        }\n+    let s = &s[if base != 10 { 2 } else { 0 } ..];\n+    u128::from_str_radix(s, base).map(|i| LitKind::Int(i, ty)).map_err(|_| {\n+        // Small bases are lexed as if they were base 10, e.g, the string\n+        // might be `0b10201`. This will cause the conversion above to fail,\n+        // but these kinds of errors are already reported by the lexer.\n+        let from_lexer =\n+            base < 10 && s.chars().any(|c| c.to_digit(10).map_or(false, |d| d >= base));\n+        if from_lexer { LitError::LexerError } else { LitError::IntTooLarge }\n     })\n }"}, {"sha": "ae3665c834bd3e9c0b949a5281d3f4ff9eac5d34", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 24, "deletions": 19, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -352,10 +352,12 @@ impl TokenCursor {\n         let body = TokenTree::Delimited(\n             delim_span,\n             token::Bracket,\n-            [TokenTree::Token(sp, token::Ident(ast::Ident::with_empty_ctxt(sym::doc), false)),\n-             TokenTree::Token(sp, token::Eq),\n-             TokenTree::Token(sp, token::Literal(\n-                token::StrRaw(Symbol::intern(&stripped), num_of_hashes), None))\n+            [\n+                TokenTree::Token(sp, token::Ident(ast::Ident::with_empty_ctxt(sym::doc), false)),\n+                TokenTree::Token(sp, token::Eq),\n+                TokenTree::Token(sp, token::Token::lit(\n+                    token::StrRaw(num_of_hashes), Symbol::intern(&stripped), None\n+                )),\n             ]\n             .iter().cloned().collect::<TokenStream>().into(),\n         );\n@@ -1054,7 +1056,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn expect_no_suffix(&self, sp: Span, kind: &str, suffix: Option<ast::Name>) {\n-        literal::expect_no_suffix(sp, &self.sess.span_diagnostic, kind, suffix)\n+        literal::expect_no_suffix(&self.sess.span_diagnostic, sp, kind, suffix)\n     }\n \n     /// Attempts to consume a `<`. If `<<` is seen, replaces it with a single\n@@ -2241,10 +2243,10 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_field_name(&mut self) -> PResult<'a, Ident> {\n-        if let token::Literal(token::Integer(name), suffix) = self.token {\n+        if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = self.token {\n             self.expect_no_suffix(self.span, \"a tuple index\", suffix);\n             self.bump();\n-            Ok(Ident::new(name, self.prev_span))\n+            Ok(Ident::new(symbol, self.prev_span))\n         } else {\n             self.parse_ident_common(false)\n         }\n@@ -3045,19 +3047,19 @@ impl<'a> Parser<'a> {\n                     token::Ident(..) => {\n                         e = self.parse_dot_suffix(e, lo)?;\n                     }\n-                    token::Literal(token::Integer(name), suffix) => {\n+                    token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) => {\n                         let span = self.span;\n                         self.bump();\n-                        let field = ExprKind::Field(e, Ident::new(name, span));\n+                        let field = ExprKind::Field(e, Ident::new(symbol, span));\n                         e = self.mk_expr(lo.to(span), field, ThinVec::new());\n \n                         self.expect_no_suffix(span, \"a tuple index\", suffix);\n                     }\n-                    token::Literal(token::Float(n), _suf) => {\n+                    token::Literal(token::Lit { kind: token::Float, symbol, .. }) => {\n                       self.bump();\n-                      let fstr = n.as_str();\n-                      let mut err = self.diagnostic()\n-                          .struct_span_err(self.prev_span, &format!(\"unexpected token: `{}`\", n));\n+                      let fstr = symbol.as_str();\n+                      let msg = format!(\"unexpected token: `{}`\", symbol);\n+                      let mut err = self.diagnostic().struct_span_err(self.prev_span, &msg);\n                       err.span_label(self.prev_span, \"unexpected token\");\n                       if fstr.chars().all(|x| \"0123456789.\".contains(x)) {\n                           let float = match fstr.parse::<f64>().ok() {\n@@ -7557,11 +7559,12 @@ impl<'a> Parser<'a> {\n     /// the `extern` keyword, if one is found.\n     fn parse_opt_abi(&mut self) -> PResult<'a, Option<Abi>> {\n         match self.token {\n-            token::Literal(token::Str_(s), suf) | token::Literal(token::StrRaw(s, _), suf) => {\n+            token::Literal(token::Lit { kind: token::Str, symbol, suffix }) |\n+            token::Literal(token::Lit { kind: token::StrRaw(..), symbol, suffix }) => {\n                 let sp = self.span;\n-                self.expect_no_suffix(sp, \"an ABI spec\", suf);\n+                self.expect_no_suffix(sp, \"an ABI spec\", suffix);\n                 self.bump();\n-                match abi::lookup(&s.as_str()) {\n+                match abi::lookup(&symbol.as_str()) {\n                     Some(abi) => Ok(Some(abi)),\n                     None => {\n                         let prev_span = self.prev_span;\n@@ -7570,7 +7573,7 @@ impl<'a> Parser<'a> {\n                             prev_span,\n                             E0703,\n                             \"invalid ABI: found `{}`\",\n-                            s);\n+                            symbol);\n                         err.span_label(prev_span, \"invalid ABI\");\n                         err.help(&format!(\"valid ABIs: {}\", abi::all_names().join(\", \")));\n                         err.emit();\n@@ -8370,8 +8373,10 @@ impl<'a> Parser<'a> {\n \n     pub fn parse_optional_str(&mut self) -> Option<(Symbol, ast::StrStyle, Option<ast::Name>)> {\n         let ret = match self.token {\n-            token::Literal(token::Str_(s), suf) => (s, ast::StrStyle::Cooked, suf),\n-            token::Literal(token::StrRaw(s, n), suf) => (s, ast::StrStyle::Raw(n), suf),\n+            token::Literal(token::Lit { kind: token::Str, symbol, suffix }) =>\n+                (symbol, ast::StrStyle::Cooked, suffix),\n+            token::Literal(token::Lit { kind: token::StrRaw(n), symbol, suffix }) =>\n+                (symbol, ast::StrStyle::Raw(n), suffix),\n             _ => return None\n         };\n         self.bump();"}, {"sha": "e5361b2db4e9e4b29cb529257c90b2dcea4d6435", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 60, "deletions": 38, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,7 +1,7 @@\n pub use BinOpToken::*;\n pub use Nonterminal::*;\n pub use DelimToken::*;\n-pub use Lit::*;\n+pub use LitKind::*;\n pub use Token::*;\n \n use crate::ast::{self};\n@@ -59,48 +59,61 @@ impl DelimToken {\n     }\n }\n \n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n-pub enum Lit {\n-    Bool(ast::Name), // AST only, must never appear in a `Token`\n-    Byte(ast::Name),\n-    Char(ast::Name),\n-    Err(ast::Name),\n-    Integer(ast::Name),\n-    Float(ast::Name),\n-    Str_(ast::Name),\n-    StrRaw(ast::Name, u16), /* raw str delimited by n hash symbols */\n-    ByteStr(ast::Name),\n-    ByteStrRaw(ast::Name, u16), /* raw byte str delimited by n hash symbols */\n+#[derive(Clone, Copy, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n+pub enum LitKind {\n+    Bool, // AST only, must never appear in a `Token`\n+    Byte,\n+    Char,\n+    Integer,\n+    Float,\n+    Str,\n+    StrRaw(u16), // raw string delimited by `n` hash symbols\n+    ByteStr,\n+    ByteStrRaw(u16), // raw byte string delimited by `n` hash symbols\n+    Err,\n }\n \n-#[cfg(target_arch = \"x86_64\")]\n-static_assert_size!(Lit, 8);\n+/// A literal token.\n+#[derive(Clone, Copy, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n+pub struct Lit {\n+    pub kind: LitKind,\n+    pub symbol: Symbol,\n+    pub suffix: Option<Symbol>,\n+}\n \n-impl Lit {\n-    crate fn literal_name(&self) -> &'static str {\n-        match *self {\n-            Bool(_) => panic!(\"literal token contains `Lit::Bool`\"),\n-            Byte(_) => \"byte literal\",\n-            Char(_) => \"char literal\",\n-            Err(_) => \"invalid literal\",\n-            Integer(_) => \"integer literal\",\n-            Float(_) => \"float literal\",\n-            Str_(_) | StrRaw(..) => \"string literal\",\n-            ByteStr(_) | ByteStrRaw(..) => \"byte string literal\"\n+impl LitKind {\n+    /// An English article for the literal token kind.\n+    crate fn article(self) -> &'static str {\n+        match self {\n+            Integer | Err => \"an\",\n+            _ => \"a\",\n         }\n     }\n \n-    crate fn may_have_suffix(&self) -> bool {\n-        match *self {\n-            Integer(..) | Float(..) => true,\n+    crate fn descr(self) -> &'static str {\n+        match self {\n+            Bool => panic!(\"literal token contains `Lit::Bool`\"),\n+            Byte => \"byte\",\n+            Char => \"char\",\n+            Integer => \"integer\",\n+            Float => \"float\",\n+            Str | StrRaw(..) => \"string\",\n+            ByteStr | ByteStrRaw(..) => \"byte string\",\n+            Err => \"error\",\n+        }\n+    }\n+\n+    crate fn may_have_suffix(self) -> bool {\n+        match self {\n+            Integer | Float | Err => true,\n             _ => false,\n         }\n     }\n+}\n \n-    // See comments in `Nonterminal::to_tokenstream` for why we care about\n-    // *probably* equal here rather than actual equality\n-    fn probably_equal_for_proc_macro(&self, other: &Lit) -> bool {\n-        mem::discriminant(self) == mem::discriminant(other)\n+impl Lit {\n+    pub fn new(kind: LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Lit {\n+        Lit { kind, symbol, suffix }\n     }\n }\n \n@@ -193,7 +206,7 @@ pub enum Token {\n     CloseDelim(DelimToken),\n \n     /* Literals */\n-    Literal(Lit, Option<ast::Name>),\n+    Literal(Lit),\n \n     /* Name components */\n     Ident(ast::Ident, /* is_raw */ bool),\n@@ -310,6 +323,10 @@ impl Token {\n         self == &Question || self == &OpenDelim(Paren)\n     }\n \n+    pub fn lit(kind: LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Token {\n+        Literal(Lit::new(kind, symbol, suffix))\n+    }\n+\n     /// Returns `true` if the token is any literal\n     crate fn is_lit(&self) -> bool {\n         match *self {\n@@ -318,6 +335,13 @@ impl Token {\n         }\n     }\n \n+    crate fn expect_lit(&self) -> Lit {\n+        match *self {\n+            Literal(lit) => lit,\n+            _=> panic!(\"`expect_lit` called on non-literal\"),\n+        }\n+    }\n+\n     /// Returns `true` if the token is any literal, a minus (which can prefix a literal,\n     /// for example a '-42', or one of the boolean idents).\n     crate fn can_begin_literal_or_bool(&self) -> bool {\n@@ -564,15 +588,13 @@ impl Token {\n             (&DocComment(a), &DocComment(b)) |\n             (&Shebang(a), &Shebang(b)) => a == b,\n \n+            (&Literal(a), &Literal(b)) => a == b,\n+\n             (&Lifetime(a), &Lifetime(b)) => a.name == b.name,\n             (&Ident(a, b), &Ident(c, d)) => b == d && (a.name == c.name ||\n                                                        a.name == kw::DollarCrate ||\n                                                        c.name == kw::DollarCrate),\n \n-            (&Literal(ref a, b), &Literal(ref c, d)) => {\n-                b == d && a.probably_equal_for_proc_macro(c)\n-            }\n-\n             (&Interpolated(_), &Interpolated(_)) => false,\n \n             _ => panic!(\"forgot to add a token?\"),"}, {"sha": "88a5033f3b55f43d7330d06dc42e9f1b7c7e772d", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 19, "deletions": 18, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -163,22 +163,23 @@ fn binop_to_string(op: BinOpToken) -> &'static str {\n     }\n }\n \n-pub fn literal_to_string(lit: token::Lit, suffix: Option<ast::Name>) -> String {\n-    let mut out = match lit {\n-        token::Byte(b)           => format!(\"b'{}'\", b),\n-        token::Char(c)           => format!(\"'{}'\", c),\n-        token::Err(c)            => format!(\"'{}'\", c),\n-        token::Bool(c)           |\n-        token::Float(c)          |\n-        token::Integer(c)        => c.to_string(),\n-        token::Str_(s)           => format!(\"\\\"{}\\\"\", s),\n-        token::StrRaw(s, n)      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n-                                            delim=\"#\".repeat(n as usize),\n-                                            string=s),\n-        token::ByteStr(v)        => format!(\"b\\\"{}\\\"\", v),\n-        token::ByteStrRaw(s, n)  => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n-                                            delim=\"#\".repeat(n as usize),\n-                                            string=s),\n+pub fn literal_to_string(lit: token::Lit) -> String {\n+    let token::Lit { kind, symbol, suffix } = lit;\n+    let mut out = match kind {\n+        token::Byte          => format!(\"b'{}'\", symbol),\n+        token::Char          => format!(\"'{}'\", symbol),\n+        token::Bool          |\n+        token::Float         |\n+        token::Integer       => symbol.to_string(),\n+        token::Str           => format!(\"\\\"{}\\\"\", symbol),\n+        token::StrRaw(n)     => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n+                                        delim=\"#\".repeat(n as usize),\n+                                        string=symbol),\n+        token::ByteStr       => format!(\"b\\\"{}\\\"\", symbol),\n+        token::ByteStrRaw(n) => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n+                                        delim=\"#\".repeat(n as usize),\n+                                        string=symbol),\n+        token::Err           => format!(\"'{}'\", symbol),\n     };\n \n     if let Some(suffix) = suffix {\n@@ -231,7 +232,7 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::SingleQuote          => \"'\".to_string(),\n \n         /* Literals */\n-        token::Literal(lit, suf) => literal_to_string(lit, suf),\n+        token::Literal(lit) => literal_to_string(lit),\n \n         /* Name components */\n         token::Ident(s, false)      => s.to_string(),\n@@ -571,7 +572,7 @@ pub trait PrintState<'a> {\n \n     fn print_literal(&mut self, lit: &ast::Lit) -> io::Result<()> {\n         self.maybe_print_comment(lit.span.lo())?;\n-        self.writer().word(literal_to_string(lit.token, lit.suffix))\n+        self.writer().word(literal_to_string(lit.token))\n     }\n \n     fn print_string(&mut self, st: &str,"}, {"sha": "a11cd9c6f761dbab4b714eb77e5b73f46381c1d8", "filename": "src/libsyntax_ext/assert.rs", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax_ext%2Fassert.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax_ext%2Fassert.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fassert.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -4,7 +4,7 @@ use syntax::ast::{self, *};\n use syntax::source_map::Spanned;\n use syntax::ext::base::*;\n use syntax::ext::build::AstBuilder;\n-use syntax::parse::token;\n+use syntax::parse::token::{self, Token};\n use syntax::parse::parser::Parser;\n use syntax::print::pprust;\n use syntax::ptr::P;\n@@ -31,13 +31,10 @@ pub fn expand_assert<'cx>(\n         tts: custom_message.unwrap_or_else(|| {\n             TokenStream::from(TokenTree::Token(\n                 DUMMY_SP,\n-                token::Literal(\n-                    token::Lit::Str_(Name::intern(&format!(\n-                        \"assertion failed: {}\",\n-                        pprust::expr_to_string(&cond_expr).escape_debug()\n-                    ))),\n-                    None,\n-                ),\n+                Token::lit(token::Str, Symbol::intern(&format!(\n+                    \"assertion failed: {}\",\n+                    pprust::expr_to_string(&cond_expr).escape_debug()\n+                )), None),\n             ))\n         }).into(),\n         delim: MacDelimiter::Parenthesis,\n@@ -106,7 +103,7 @@ fn parse_assert<'a>(\n     //\n     // Parse this as an actual message, and suggest inserting a comma. Eventually, this should be\n     // turned into an error.\n-    let custom_message = if let token::Literal(token::Lit::Str_(_), _) = parser.token {\n+    let custom_message = if let token::Literal(token::Lit { kind: token::Str, .. }) = parser.token {\n         let mut err = cx.struct_span_warn(parser.span, \"unexpected string literal\");\n         let comma_span = cx.source_map().next_point(parser.prev_span);\n         err.span_suggestion_short("}, {"sha": "beac92894b77ad7b0e803860cf515b6e3bfd21d9", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 27, "deletions": 55, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -150,7 +150,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n                 stack.push(tt!(Ident::new(ident.name, false)));\n                 tt!(Punct::new('\\'', true))\n             }\n-            Literal(lit, suffix) => tt!(Literal { lit, suffix }),\n+            Literal(lit) => tt!(Literal { lit }),\n             DocComment(c) => {\n                 let style = comments::doc_comment_style(&c.as_str());\n                 let stripped = comments::strip_doc_comment_decoration(&c.as_str());\n@@ -161,7 +161,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n                 let stream = vec![\n                     Ident(ast::Ident::new(Symbol::intern(\"doc\"), span), false),\n                     Eq,\n-                    Literal(Lit::Str_(Symbol::intern(&escaped)), None),\n+                    Token::lit(token::Str, Symbol::intern(&escaped), None),\n                 ]\n                 .into_iter()\n                 .map(|token| tokenstream::TokenTree::Token(span, token))\n@@ -215,31 +215,29 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n                 return tokenstream::TokenTree::Token(span, token).into();\n             }\n             TokenTree::Literal(self::Literal {\n-                lit: Lit::Integer(ref a),\n-                suffix,\n+                lit: token::Lit { kind: token::Integer, symbol, suffix },\n                 span,\n-            }) if a.as_str().starts_with(\"-\") => {\n+            }) if symbol.as_str().starts_with(\"-\") => {\n                 let minus = BinOp(BinOpToken::Minus);\n-                let integer = Symbol::intern(&a.as_str()[1..]);\n-                let integer = Literal(Lit::Integer(integer), suffix);\n+                let symbol = Symbol::intern(&symbol.as_str()[1..]);\n+                let integer = Token::lit(token::Integer, symbol, suffix);\n                 let a = tokenstream::TokenTree::Token(span, minus);\n                 let b = tokenstream::TokenTree::Token(span, integer);\n                 return vec![a, b].into_iter().collect();\n             }\n             TokenTree::Literal(self::Literal {\n-                lit: Lit::Float(ref a),\n-                suffix,\n+                lit: token::Lit { kind: token::Float, symbol, suffix },\n                 span,\n-            }) if a.as_str().starts_with(\"-\") => {\n+            }) if symbol.as_str().starts_with(\"-\") => {\n                 let minus = BinOp(BinOpToken::Minus);\n-                let float = Symbol::intern(&a.as_str()[1..]);\n-                let float = Literal(Lit::Float(float), suffix);\n+                let symbol = Symbol::intern(&symbol.as_str()[1..]);\n+                let float = Token::lit(token::Float, symbol, suffix);\n                 let a = tokenstream::TokenTree::Token(span, minus);\n                 let b = tokenstream::TokenTree::Token(span, float);\n                 return vec![a, b].into_iter().collect();\n             }\n-            TokenTree::Literal(self::Literal { lit, suffix, span }) => {\n-                return tokenstream::TokenTree::Token(span, Literal(lit, suffix)).into()\n+            TokenTree::Literal(self::Literal { lit, span }) => {\n+                return tokenstream::TokenTree::Token(span, Literal(lit)).into()\n             }\n         };\n \n@@ -355,7 +353,6 @@ impl Ident {\n #[derive(Clone, Debug)]\n pub struct Literal {\n     lit: token::Lit,\n-    suffix: Option<Symbol>,\n     span: Span,\n }\n \n@@ -381,6 +378,13 @@ impl<'a> Rustc<'a> {\n             call_site: to_span(Transparency::Transparent),\n         }\n     }\n+\n+    fn lit(&mut self, kind: token::LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Literal {\n+        Literal {\n+            lit: token::Lit::new(kind, symbol, suffix),\n+            span: server::Span::call_site(self),\n+        }\n+    }\n }\n \n impl server::Types for Rustc<'_> {\n@@ -536,59 +540,31 @@ impl server::Literal for Rustc<'_> {\n         format!(\"{:?}\", literal)\n     }\n     fn integer(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Integer(Symbol::intern(n)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Integer, Symbol::intern(n), None)\n     }\n     fn typed_integer(&mut self, n: &str, kind: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Integer(Symbol::intern(n)),\n-            suffix: Some(Symbol::intern(kind)),\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Integer, Symbol::intern(n), Some(Symbol::intern(kind)))\n     }\n     fn float(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Float(Symbol::intern(n)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Float, Symbol::intern(n), None)\n     }\n     fn f32(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Float(Symbol::intern(n)),\n-            suffix: Some(Symbol::intern(\"f32\")),\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Float, Symbol::intern(n), Some(Symbol::intern(\"f32\")))\n     }\n     fn f64(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Float(Symbol::intern(n)),\n-            suffix: Some(Symbol::intern(\"f64\")),\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Float, Symbol::intern(n), Some(Symbol::intern(\"f64\")))\n     }\n     fn string(&mut self, string: &str) -> Self::Literal {\n         let mut escaped = String::new();\n         for ch in string.chars() {\n             escaped.extend(ch.escape_debug());\n         }\n-        Literal {\n-            lit: token::Lit::Str_(Symbol::intern(&escaped)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Str, Symbol::intern(&escaped), None)\n     }\n     fn character(&mut self, ch: char) -> Self::Literal {\n         let mut escaped = String::new();\n         escaped.extend(ch.escape_unicode());\n-        Literal {\n-            lit: token::Lit::Char(Symbol::intern(&escaped)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Char, Symbol::intern(&escaped), None)\n     }\n     fn byte_string(&mut self, bytes: &[u8]) -> Self::Literal {\n         let string = bytes\n@@ -597,11 +573,7 @@ impl server::Literal for Rustc<'_> {\n             .flat_map(ascii::escape_default)\n             .map(Into::<char>::into)\n             .collect::<String>();\n-        Literal {\n-            lit: token::Lit::ByteStr(Symbol::intern(&string)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::ByteStr, Symbol::intern(&string), None)\n     }\n     fn span(&mut self, literal: &Self::Literal) -> Self::Span {\n         literal.span"}, {"sha": "b1e1a056db4adaa736f8cd057adc33bc520c8835", "filename": "src/libsyntax_pos/symbol.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax_pos%2Fsymbol.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Flibsyntax_pos%2Fsymbol.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fsymbol.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -246,6 +246,8 @@ symbols! {\n         extern_prelude,\n         extern_types,\n         f16c_target_feature,\n+        f32,\n+        f64,\n         feature,\n         ffi_returns_twice,\n         field_init_shorthand,"}, {"sha": "ccfe60e964b2e9b1c056a65fa0e92aa44c6d4bef", "filename": "src/test/ui/old-suffixes-are-really-forbidden.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fold-suffixes-are-really-forbidden.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fold-suffixes-are-really-forbidden.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fold-suffixes-are-really-forbidden.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,12 +1,12 @@\n-error: invalid suffix `is` for numeric literal\n+error: invalid suffix `is` for integer literal\n   --> $DIR/old-suffixes-are-really-forbidden.rs:2:13\n    |\n LL |     let a = 1_is;\n    |             ^^^^ invalid suffix `is`\n    |\n    = help: the suffix must be one of the integral types (`u32`, `isize`, etc)\n \n-error: invalid suffix `us` for numeric literal\n+error: invalid suffix `us` for integer literal\n   --> $DIR/old-suffixes-are-really-forbidden.rs:3:13\n    |\n LL |     let b = 2_us;"}, {"sha": "151c6e1527ff566aa23bd7fda87327591c8ed65e", "filename": "src/test/ui/parser/bad-lit-suffixes.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fbad-lit-suffixes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fbad-lit-suffixes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fbad-lit-suffixes.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -22,8 +22,8 @@ fn main() {\n     1234f1024; //~ ERROR invalid width `1024` for float literal\n     1234.5f1024; //~ ERROR invalid width `1024` for float literal\n \n-    1234suffix; //~ ERROR invalid suffix `suffix` for numeric literal\n-    0b101suffix; //~ ERROR invalid suffix `suffix` for numeric literal\n+    1234suffix; //~ ERROR invalid suffix `suffix` for integer literal\n+    0b101suffix; //~ ERROR invalid suffix `suffix` for integer literal\n     1.0suffix; //~ ERROR invalid suffix `suffix` for float literal\n     1.0e10suffix; //~ ERROR invalid suffix `suffix` for float literal\n }"}, {"sha": "e53b1498332d113f351f3d75c242fecb320358cc", "filename": "src/test/ui/parser/bad-lit-suffixes.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fbad-lit-suffixes.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fbad-lit-suffixes.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fbad-lit-suffixes.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -78,15 +78,15 @@ LL |     1234.5f1024;\n    |\n    = help: valid widths are 32 and 64\n \n-error: invalid suffix `suffix` for numeric literal\n+error: invalid suffix `suffix` for integer literal\n   --> $DIR/bad-lit-suffixes.rs:25:5\n    |\n LL |     1234suffix;\n    |     ^^^^^^^^^^ invalid suffix `suffix`\n    |\n    = help: the suffix must be one of the integral types (`u32`, `isize`, etc)\n \n-error: invalid suffix `suffix` for numeric literal\n+error: invalid suffix `suffix` for integer literal\n   --> $DIR/bad-lit-suffixes.rs:26:5\n    |\n LL |     0b101suffix;"}, {"sha": "666ca9350597674a8d631b8bab35eb5d75111985", "filename": "src/test/ui/parser/int-literal-too-large-span.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fint-literal-too-large-span.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fint-literal-too-large-span.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fint-literal-too-large-span.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -2,6 +2,6 @@\n \n fn main() {\n     9999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999\n-    //~^ ERROR int literal is too large\n+    //~^ ERROR integer literal is too large\n         ; // the span shouldn't point to this.\n }"}, {"sha": "7cae85fc9fe6d433731e5f6f702a1fbe06ed15da", "filename": "src/test/ui/parser/int-literal-too-large-span.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fint-literal-too-large-span.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fint-literal-too-large-span.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fint-literal-too-large-span.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,4 +1,4 @@\n-error: int literal is too large\n+error: integer literal is too large\n   --> $DIR/int-literal-too-large-span.rs:4:5\n    |\n LL |     9999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999"}, {"sha": "3c239c73b9d708bb44c82331d0fe9a16e650107f", "filename": "src/test/ui/parser/issue-5544-a.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-a.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-a.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fissue-5544-a.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,4 +1,4 @@\n fn main() {\n     let __isize = 340282366920938463463374607431768211456; // 2^128\n-    //~^ ERROR int literal is too large\n+    //~^ ERROR integer literal is too large\n }"}, {"sha": "de579c3c134e511d8a7e5e1bc6b8409591303d7f", "filename": "src/test/ui/parser/issue-5544-a.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-a.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-a.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fissue-5544-a.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,4 +1,4 @@\n-error: int literal is too large\n+error: integer literal is too large\n   --> $DIR/issue-5544-a.rs:2:19\n    |\n LL |     let __isize = 340282366920938463463374607431768211456; // 2^128"}, {"sha": "93f2ff271364e0c935034c038c7121600fc48c0c", "filename": "src/test/ui/parser/issue-5544-b.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-b.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-b.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fissue-5544-b.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,4 +1,4 @@\n fn main() {\n     let __isize = 0xffff_ffff_ffff_ffff_ffff_ffff_ffff_ffff_ff;\n-    //~^ ERROR int literal is too large\n+    //~^ ERROR integer literal is too large\n }"}, {"sha": "7df212dedfede1fb6dd496297eb0713a47ebfac4", "filename": "src/test/ui/parser/issue-5544-b.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-b.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fissue-5544-b.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fissue-5544-b.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -1,4 +1,4 @@\n-error: int literal is too large\n+error: integer literal is too large\n   --> $DIR/issue-5544-b.rs:2:19\n    |\n LL |     let __isize = 0xffff_ffff_ffff_ffff_ffff_ffff_ffff_ffff_ff;"}, {"sha": "67134c14cded3688ae0659e6bdd877cba7a37d3f", "filename": "src/test/ui/parser/lex-bad-numeric-literals.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -13,8 +13,10 @@ fn main() {\n     0o; //~ ERROR: no valid digits\n     1e+; //~ ERROR: expected at least one digit in exponent\n     0x539.0; //~ ERROR: hexadecimal float literal is not supported\n-    9900000000000000000000000000999999999999999999999999999999; //~ ERROR: int literal is too large\n-    9900000000000000000000000000999999999999999999999999999999; //~ ERROR: int literal is too large\n+    9900000000000000000000000000999999999999999999999999999999;\n+    //~^ ERROR: integer literal is too large\n+    9900000000000000000000000000999999999999999999999999999999;\n+    //~^ ERROR: integer literal is too large\n     0x; //~ ERROR: no valid digits\n     0xu32; //~ ERROR: no valid digits\n     0ou32; //~ ERROR: no valid digits"}, {"sha": "6d6cd3cc17129928db8b97a97233823bb2151ea6", "filename": "src/test/ui/parser/lex-bad-numeric-literals.stderr", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -65,43 +65,43 @@ LL |     0x539.0;\n    |     ^^^^^^^\n \n error: no valid digits found for number\n-  --> $DIR/lex-bad-numeric-literals.rs:18:5\n+  --> $DIR/lex-bad-numeric-literals.rs:20:5\n    |\n LL |     0x;\n    |     ^^\n \n error: no valid digits found for number\n-  --> $DIR/lex-bad-numeric-literals.rs:19:5\n+  --> $DIR/lex-bad-numeric-literals.rs:21:5\n    |\n LL |     0xu32;\n    |     ^^\n \n error: no valid digits found for number\n-  --> $DIR/lex-bad-numeric-literals.rs:20:5\n+  --> $DIR/lex-bad-numeric-literals.rs:22:5\n    |\n LL |     0ou32;\n    |     ^^\n \n error: no valid digits found for number\n-  --> $DIR/lex-bad-numeric-literals.rs:21:5\n+  --> $DIR/lex-bad-numeric-literals.rs:23:5\n    |\n LL |     0bu32;\n    |     ^^\n \n error: no valid digits found for number\n-  --> $DIR/lex-bad-numeric-literals.rs:22:5\n+  --> $DIR/lex-bad-numeric-literals.rs:24:5\n    |\n LL |     0b;\n    |     ^^\n \n error: octal float literal is not supported\n-  --> $DIR/lex-bad-numeric-literals.rs:24:5\n+  --> $DIR/lex-bad-numeric-literals.rs:26:5\n    |\n LL |     0o123.456;\n    |     ^^^^^^^^^\n \n error: binary float literal is not supported\n-  --> $DIR/lex-bad-numeric-literals.rs:26:5\n+  --> $DIR/lex-bad-numeric-literals.rs:28:5\n    |\n LL |     0b111.101;\n    |     ^^^^^^^^^\n@@ -112,26 +112,26 @@ error: octal float literal is not supported\n LL |     0o2f32;\n    |     ^^^^^^ not supported\n \n-error: int literal is too large\n+error: integer literal is too large\n   --> $DIR/lex-bad-numeric-literals.rs:16:5\n    |\n LL |     9900000000000000000000000000999999999999999999999999999999;\n    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n \n-error: int literal is too large\n-  --> $DIR/lex-bad-numeric-literals.rs:17:5\n+error: integer literal is too large\n+  --> $DIR/lex-bad-numeric-literals.rs:18:5\n    |\n LL |     9900000000000000000000000000999999999999999999999999999999;\n    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n \n error: octal float literal is not supported\n-  --> $DIR/lex-bad-numeric-literals.rs:23:5\n+  --> $DIR/lex-bad-numeric-literals.rs:25:5\n    |\n LL |     0o123f64;\n    |     ^^^^^^^^ not supported\n \n error: binary float literal is not supported\n-  --> $DIR/lex-bad-numeric-literals.rs:25:5\n+  --> $DIR/lex-bad-numeric-literals.rs:27:5\n    |\n LL |     0b101f64;\n    |     ^^^^^^^^ not supported"}, {"sha": "052cb4934f503ce3de402d5e088645b79e8d3728", "filename": "src/test/ui/parser/no-binary-float-literal.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fno-binary-float-literal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fno-binary-float-literal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fno-binary-float-literal.rs?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -4,5 +4,5 @@ fn main() {\n     0b101.010;\n     //~^ ERROR binary float literal is not supported\n     0b101p4f64;\n-    //~^ ERROR invalid suffix `p4f64` for numeric literal\n+    //~^ ERROR invalid suffix `p4f64` for integer literal\n }"}, {"sha": "65b129b5827ceffbc18c7b38f1728270eb7f97cf", "filename": "src/test/ui/parser/no-binary-float-literal.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fno-binary-float-literal.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27cc0db7a248308fc2634ac68d7608a20b4a1c09/src%2Ftest%2Fui%2Fparser%2Fno-binary-float-literal.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fno-binary-float-literal.stderr?ref=27cc0db7a248308fc2634ac68d7608a20b4a1c09", "patch": "@@ -10,7 +10,7 @@ error: binary float literal is not supported\n LL |     0b101010f64;\n    |     ^^^^^^^^^^^ not supported\n \n-error: invalid suffix `p4f64` for numeric literal\n+error: invalid suffix `p4f64` for integer literal\n   --> $DIR/no-binary-float-literal.rs:6:5\n    |\n LL |     0b101p4f64;"}]}