{"sha": "7c5ea621560d55b00f046b2b474bb7ce554a4d73", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdjNWVhNjIxNTYwZDU1YjAwZjA0NmIyYjQ3NGJiN2NlNTU0YTRkNzM=", "commit": {"author": {"name": "Scott Olson", "email": "scott@solson.me", "date": "2016-03-05T06:48:23Z"}, "committer": {"name": "Scott Olson", "email": "scott@solson.me", "date": "2016-03-05T06:48:23Z"}, "message": "Move memory module to its own file.", "tree": {"sha": "7519982aded2b61191cf2b0e9ad8d0d36335108c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7519982aded2b61191cf2b0e9ad8d0d36335108c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7c5ea621560d55b00f046b2b474bb7ce554a4d73", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7c5ea621560d55b00f046b2b474bb7ce554a4d73", "html_url": "https://github.com/rust-lang/rust/commit/7c5ea621560d55b00f046b2b474bb7ce554a4d73", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7c5ea621560d55b00f046b2b474bb7ce554a4d73/comments", "author": {"login": "solson", "id": 26806, "node_id": "MDQ6VXNlcjI2ODA2", "avatar_url": "https://avatars.githubusercontent.com/u/26806?v=4", "gravatar_id": "", "url": "https://api.github.com/users/solson", "html_url": "https://github.com/solson", "followers_url": "https://api.github.com/users/solson/followers", "following_url": "https://api.github.com/users/solson/following{/other_user}", "gists_url": "https://api.github.com/users/solson/gists{/gist_id}", "starred_url": "https://api.github.com/users/solson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/solson/subscriptions", "organizations_url": "https://api.github.com/users/solson/orgs", "repos_url": "https://api.github.com/users/solson/repos", "events_url": "https://api.github.com/users/solson/events{/privacy}", "received_events_url": "https://api.github.com/users/solson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "solson", "id": 26806, "node_id": "MDQ6VXNlcjI2ODA2", "avatar_url": "https://avatars.githubusercontent.com/u/26806?v=4", "gravatar_id": "", "url": "https://api.github.com/users/solson", "html_url": "https://github.com/solson", "followers_url": "https://api.github.com/users/solson/followers", "following_url": "https://api.github.com/users/solson/following{/other_user}", "gists_url": "https://api.github.com/users/solson/gists{/gist_id}", "starred_url": "https://api.github.com/users/solson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/solson/subscriptions", "organizations_url": "https://api.github.com/users/solson/orgs", "repos_url": "https://api.github.com/users/solson/repos", "events_url": "https://api.github.com/users/solson/events{/privacy}", "received_events_url": "https://api.github.com/users/solson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a29a6e0db9f2cd702c8bf3157234e5410c905c70", "url": "https://api.github.com/repos/rust-lang/rust/commits/a29a6e0db9f2cd702c8bf3157234e5410c905c70", "html_url": "https://github.com/rust-lang/rust/commit/a29a6e0db9f2cd702c8bf3157234e5410c905c70"}], "stats": {"total": 327, "additions": 163, "deletions": 164}, "files": [{"sha": "2d97de1032d6896970702388be9e3171412f6c5d", "filename": "src/interpreter.rs", "status": "modified", "additions": 2, "deletions": 164, "changes": 166, "blob_url": "https://github.com/rust-lang/rust/blob/7c5ea621560d55b00f046b2b474bb7ce554a4d73/src%2Finterpreter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7c5ea621560d55b00f046b2b474bb7ce554a4d73/src%2Finterpreter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Finterpreter.rs?ref=7c5ea621560d55b00f046b2b474bb7ce554a4d73", "patch": "@@ -16,171 +16,9 @@ use std::iter;\n use syntax::ast::Attribute;\n use syntax::attr::AttrMetaMethods;\n \n-const TRACE_EXECUTION: bool = true;\n-\n-mod memory {\n-    use byteorder;\n-    use byteorder::ByteOrder;\n-    use rustc::middle::ty;\n-    use std::collections::HashMap;\n-    use std::mem;\n-    use std::ops::Add;\n-    use std::ptr;\n-    use super::{EvalError, EvalResult};\n-\n-    pub struct Memory {\n-        next_id: u64,\n-        alloc_map: HashMap<u64, Allocation>,\n-    }\n-\n-    #[derive(Copy, Clone, Debug, Eq, PartialEq)]\n-    pub struct AllocId(u64);\n-\n-    // TODO(tsion): Shouldn't clone Allocation. (Audit the rest of the code.)\n-    #[derive(Clone, Debug)]\n-    pub struct Allocation {\n-        pub bytes: Vec<u8>,\n-        // TODO(tsion): relocations\n-        // TODO(tsion): undef mask\n-    }\n-\n-    #[derive(Clone, Debug, PartialEq, Eq)]\n-    pub struct Pointer {\n-        pub alloc_id: AllocId,\n-        pub offset: usize,\n-        pub repr: Repr,\n-    }\n-\n-    #[derive(Clone, Debug, PartialEq, Eq)]\n-    pub struct FieldRepr {\n-        pub offset: usize,\n-        pub repr: Repr,\n-    }\n-\n-    #[derive(Clone, Debug, PartialEq, Eq)]\n-    pub enum Repr {\n-        Int,\n-        Aggregate {\n-            size: usize,\n-            fields: Vec<FieldRepr>,\n-        },\n-    }\n-\n-    impl Memory {\n-        pub fn new() -> Self {\n-            Memory { next_id: 0, alloc_map: HashMap::new() }\n-        }\n-\n-        pub fn allocate_raw(&mut self, size: usize) -> AllocId {\n-            let id = AllocId(self.next_id);\n-            let alloc = Allocation { bytes: vec![0; size] };\n-            self.alloc_map.insert(self.next_id, alloc);\n-            self.next_id += 1;\n-            id\n-        }\n-\n-        pub fn allocate(&mut self, repr: Repr) -> Pointer {\n-            Pointer {\n-                alloc_id: self.allocate_raw(repr.size()),\n-                offset: 0,\n-                repr: repr,\n-            }\n-        }\n-\n-        pub fn get(&self, id: AllocId) -> EvalResult<&Allocation> {\n-            self.alloc_map.get(&id.0).ok_or(EvalError::DanglingPointerDeref)\n-        }\n-\n-        pub fn get_mut(&mut self, id: AllocId) -> EvalResult<&mut Allocation> {\n-            self.alloc_map.get_mut(&id.0).ok_or(EvalError::DanglingPointerDeref)\n-        }\n-\n-        fn get_bytes(&self, ptr: &Pointer, size: usize) -> EvalResult<&[u8]> {\n-            let alloc = try!(self.get(ptr.alloc_id));\n-            try!(alloc.check_bytes(ptr.offset, ptr.offset + size));\n-            Ok(&alloc.bytes[ptr.offset..ptr.offset + size])\n-        }\n-\n-        fn get_bytes_mut(&mut self, ptr: &Pointer, size: usize) -> EvalResult<&mut [u8]> {\n-            let alloc = try!(self.get_mut(ptr.alloc_id));\n-            try!(alloc.check_bytes(ptr.offset, ptr.offset + size));\n-            Ok(&mut alloc.bytes[ptr.offset..ptr.offset + size])\n-        }\n-\n-        pub fn copy(&mut self, src: &Pointer, dest: &Pointer, size: usize) -> EvalResult<()> {\n-            let src_bytes = try!(self.get_bytes_mut(src, size)).as_mut_ptr();\n-            let dest_bytes = try!(self.get_bytes_mut(dest, size)).as_mut_ptr();\n+use memory::{self, Pointer, Repr, Allocation};\n \n-            // SAFE: The above indexing would have panicked if there weren't at least `size` bytes\n-            // behind `src` and `dest`. Also, we use the overlapping-safe `ptr::copy` if `src` and\n-            // `dest` could possibly overlap.\n-            unsafe {\n-                if src.alloc_id == dest.alloc_id {\n-                    ptr::copy(src_bytes, dest_bytes, size);\n-                } else {\n-                    ptr::copy_nonoverlapping(src_bytes, dest_bytes, size);\n-                }\n-            }\n-\n-            Ok(())\n-        }\n-\n-        pub fn read_int(&self, ptr: &Pointer) -> EvalResult<i64> {\n-            let bytes = try!(self.get_bytes(ptr, Repr::Int.size()));\n-            Ok(byteorder::NativeEndian::read_i64(bytes))\n-        }\n-\n-        pub fn write_int(&mut self, ptr: &Pointer, n: i64) -> EvalResult<()> {\n-            let bytes = try!(self.get_bytes_mut(ptr, Repr::Int.size()));\n-            Ok(byteorder::NativeEndian::write_i64(bytes, n))\n-        }\n-    }\n-\n-    impl Allocation {\n-        fn check_bytes(&self, start: usize, end: usize) -> EvalResult<()> {\n-            if start >= self.bytes.len() || end > self.bytes.len() {\n-                return Err(EvalError::PointerOutOfBounds);\n-            }\n-            Ok(())\n-        }\n-    }\n-\n-    impl Pointer {\n-        pub fn offset(&self, i: usize) -> Self {\n-            Pointer { offset: self.offset + i, ..self.clone() }\n-        }\n-    }\n-\n-    impl Repr {\n-        // TODO(tsion): Cache these outputs.\n-        pub fn from_ty(ty: ty::Ty) -> Self {\n-            match ty.sty {\n-                ty::TyInt(_) => Repr::Int,\n-\n-                ty::TyTuple(ref fields) => {\n-                    let mut size = 0;\n-                    let fields = fields.iter().map(|ty| {\n-                        let repr = Repr::from_ty(ty);\n-                        let old_size = size;\n-                        size += repr.size();\n-                        FieldRepr { offset: old_size, repr: repr }\n-                    }).collect();\n-                    Repr::Aggregate { size: size, fields: fields }\n-                },\n-\n-                _ => unimplemented!(),\n-            }\n-        }\n-\n-        pub fn size(&self) -> usize {\n-            match *self {\n-                Repr::Int => mem::size_of::<i64>(),\n-                Repr::Aggregate { size, .. } => size,\n-            }\n-        }\n-    }\n-}\n-use self::memory::{Pointer, Repr, Allocation};\n+const TRACE_EXECUTION: bool = true;\n \n #[derive(Clone, Debug)]\n pub enum EvalError {"}, {"sha": "036b87c2c7f69c77343ee18d85cf16fcecc475ef", "filename": "src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/7c5ea621560d55b00f046b2b474bb7ce554a4d73/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7c5ea621560d55b00f046b2b474bb7ce554a4d73/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=7c5ea621560d55b00f046b2b474bb7ce554a4d73", "patch": "@@ -6,3 +6,4 @@ extern crate rustc_mir;\n extern crate syntax;\n \n pub mod interpreter;\n+mod memory;"}, {"sha": "0fe2b735671b082d8ef6500ff1abec66c730cd6d", "filename": "src/memory.rs", "status": "added", "additions": 160, "deletions": 0, "changes": 160, "blob_url": "https://github.com/rust-lang/rust/blob/7c5ea621560d55b00f046b2b474bb7ce554a4d73/src%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7c5ea621560d55b00f046b2b474bb7ce554a4d73/src%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fmemory.rs?ref=7c5ea621560d55b00f046b2b474bb7ce554a4d73", "patch": "@@ -0,0 +1,160 @@\n+use byteorder;\n+use byteorder::ByteOrder;\n+use rustc::middle::ty;\n+use std::collections::HashMap;\n+use std::mem;\n+use std::ptr;\n+\n+use interpreter::{EvalError, EvalResult};\n+\n+pub struct Memory {\n+    next_id: u64,\n+    alloc_map: HashMap<u64, Allocation>,\n+}\n+\n+#[derive(Copy, Clone, Debug, Eq, PartialEq)]\n+pub struct AllocId(u64);\n+\n+// TODO(tsion): Shouldn't clone Allocation. (Audit the rest of the code.)\n+#[derive(Clone, Debug)]\n+pub struct Allocation {\n+    pub bytes: Vec<u8>,\n+    // TODO(tsion): relocations\n+    // TODO(tsion): undef mask\n+}\n+\n+#[derive(Clone, Debug, PartialEq, Eq)]\n+pub struct Pointer {\n+    pub alloc_id: AllocId,\n+    pub offset: usize,\n+    pub repr: Repr,\n+}\n+\n+#[derive(Clone, Debug, PartialEq, Eq)]\n+pub struct FieldRepr {\n+    pub offset: usize,\n+    pub repr: Repr,\n+}\n+\n+#[derive(Clone, Debug, PartialEq, Eq)]\n+pub enum Repr {\n+    Int,\n+    Aggregate {\n+        size: usize,\n+        fields: Vec<FieldRepr>,\n+    },\n+}\n+\n+impl Memory {\n+    pub fn new() -> Self {\n+        Memory { next_id: 0, alloc_map: HashMap::new() }\n+    }\n+\n+    pub fn allocate_raw(&mut self, size: usize) -> AllocId {\n+        let id = AllocId(self.next_id);\n+        let alloc = Allocation { bytes: vec![0; size] };\n+        self.alloc_map.insert(self.next_id, alloc);\n+        self.next_id += 1;\n+        id\n+    }\n+\n+    pub fn allocate(&mut self, repr: Repr) -> Pointer {\n+        Pointer {\n+            alloc_id: self.allocate_raw(repr.size()),\n+            offset: 0,\n+            repr: repr,\n+        }\n+    }\n+\n+    pub fn get(&self, id: AllocId) -> EvalResult<&Allocation> {\n+        self.alloc_map.get(&id.0).ok_or(EvalError::DanglingPointerDeref)\n+    }\n+\n+    pub fn get_mut(&mut self, id: AllocId) -> EvalResult<&mut Allocation> {\n+        self.alloc_map.get_mut(&id.0).ok_or(EvalError::DanglingPointerDeref)\n+    }\n+\n+    fn get_bytes(&self, ptr: &Pointer, size: usize) -> EvalResult<&[u8]> {\n+        let alloc = try!(self.get(ptr.alloc_id));\n+        try!(alloc.check_bytes(ptr.offset, ptr.offset + size));\n+        Ok(&alloc.bytes[ptr.offset..ptr.offset + size])\n+    }\n+\n+    fn get_bytes_mut(&mut self, ptr: &Pointer, size: usize) -> EvalResult<&mut [u8]> {\n+        let alloc = try!(self.get_mut(ptr.alloc_id));\n+        try!(alloc.check_bytes(ptr.offset, ptr.offset + size));\n+        Ok(&mut alloc.bytes[ptr.offset..ptr.offset + size])\n+    }\n+\n+    pub fn copy(&mut self, src: &Pointer, dest: &Pointer, size: usize) -> EvalResult<()> {\n+        let src_bytes = try!(self.get_bytes_mut(src, size)).as_mut_ptr();\n+        let dest_bytes = try!(self.get_bytes_mut(dest, size)).as_mut_ptr();\n+\n+        // SAFE: The above indexing would have panicked if there weren't at least `size` bytes\n+        // behind `src` and `dest`. Also, we use the overlapping-safe `ptr::copy` if `src` and\n+        // `dest` could possibly overlap.\n+        unsafe {\n+            if src.alloc_id == dest.alloc_id {\n+                ptr::copy(src_bytes, dest_bytes, size);\n+            } else {\n+                ptr::copy_nonoverlapping(src_bytes, dest_bytes, size);\n+            }\n+        }\n+\n+        Ok(())\n+    }\n+\n+    pub fn read_int(&self, ptr: &Pointer) -> EvalResult<i64> {\n+        let bytes = try!(self.get_bytes(ptr, Repr::Int.size()));\n+        Ok(byteorder::NativeEndian::read_i64(bytes))\n+    }\n+\n+    pub fn write_int(&mut self, ptr: &Pointer, n: i64) -> EvalResult<()> {\n+        let bytes = try!(self.get_bytes_mut(ptr, Repr::Int.size()));\n+        Ok(byteorder::NativeEndian::write_i64(bytes, n))\n+    }\n+}\n+\n+impl Allocation {\n+    fn check_bytes(&self, start: usize, end: usize) -> EvalResult<()> {\n+        if start >= self.bytes.len() || end > self.bytes.len() {\n+            return Err(EvalError::PointerOutOfBounds);\n+        }\n+        Ok(())\n+    }\n+}\n+\n+impl Pointer {\n+    pub fn offset(&self, i: usize) -> Self {\n+        Pointer { offset: self.offset + i, ..self.clone() }\n+    }\n+}\n+\n+impl Repr {\n+    // TODO(tsion): Cache these outputs.\n+    pub fn from_ty(ty: ty::Ty) -> Self {\n+        match ty.sty {\n+            ty::TyInt(_) => Repr::Int,\n+\n+            ty::TyTuple(ref fields) => {\n+                let mut size = 0;\n+                let fields = fields.iter().map(|ty| {\n+                    let repr = Repr::from_ty(ty);\n+                    let old_size = size;\n+                    size += repr.size();\n+                    FieldRepr { offset: old_size, repr: repr }\n+                }).collect();\n+                Repr::Aggregate { size: size, fields: fields }\n+            },\n+\n+            _ => unimplemented!(),\n+        }\n+    }\n+\n+    pub fn size(&self) -> usize {\n+        match *self {\n+            Repr::Int => mem::size_of::<i64>(),\n+            Repr::Aggregate { size, .. } => size,\n+        }\n+    }\n+}"}]}