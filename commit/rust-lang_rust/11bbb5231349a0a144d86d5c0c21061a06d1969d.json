{"sha": "11bbb5231349a0a144d86d5c0c21061a06d1969d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjExYmJiNTIzMTM0OWEwYTE0NGQ4NmQ1YzBjMjEwNjFhMDZkMTk2OWQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-09-06T23:58:16Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-09-06T23:58:16Z"}, "message": "Auto merge of #83214 - cjgillot:dep-map, r=michaelwoerister\n\nMmap the incremental data instead of reading it.\n\nInstead of reading the full incremental state using `fs::read_file`, we memmap it using a private read-only file-backed map.\nThis allows the system to reclaim any memory we are not using, while ensuring we are not polluted by\noutside modifications to the file.\n\nSuggested in https://github.com/rust-lang/rust/pull/83036#issuecomment-800458082 by `@bjorn3`", "tree": {"sha": "70bcc7e4fddcbc40043ae83f99c9955dce8a8f55", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/70bcc7e4fddcbc40043ae83f99c9955dce8a8f55"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/11bbb5231349a0a144d86d5c0c21061a06d1969d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/11bbb5231349a0a144d86d5c0c21061a06d1969d", "html_url": "https://github.com/rust-lang/rust/commit/11bbb5231349a0a144d86d5c0c21061a06d1969d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/11bbb5231349a0a144d86d5c0c21061a06d1969d/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1698e3cac54aa8691d4e9e207567672af8231cb6", "url": "https://api.github.com/repos/rust-lang/rust/commits/1698e3cac54aa8691d4e9e207567672af8231cb6", "html_url": "https://github.com/rust-lang/rust/commit/1698e3cac54aa8691d4e9e207567672af8231cb6"}, {"sha": "bcefd487c380b113d81ac066ea9b3b4b65e9efe7", "url": "https://api.github.com/repos/rust-lang/rust/commits/bcefd487c380b113d81ac066ea9b3b4b65e9efe7", "html_url": "https://github.com/rust-lang/rust/commit/bcefd487c380b113d81ac066ea9b3b4b65e9efe7"}], "stats": {"total": 211, "additions": 123, "deletions": 88}, "files": [{"sha": "572a4fc69717380aa6a8867a175425fd270da670", "filename": "compiler/rustc_incremental/src/persist/file_format.rs", "status": "modified", "additions": 71, "deletions": 7, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffile_format.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffile_format.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffile_format.rs?ref=11bbb5231349a0a144d86d5c0c21061a06d1969d", "patch": "@@ -12,10 +12,12 @@\n use std::env;\n use std::fs;\n use std::io::{self, Read};\n-use std::path::Path;\n+use std::path::{Path, PathBuf};\n \n+use rustc_data_structures::memmap::Mmap;\n use rustc_serialize::opaque::{FileEncodeResult, FileEncoder};\n use rustc_serialize::Encoder;\n+use rustc_session::Session;\n \n /// The first few bytes of files generated by incremental compilation.\n const FILE_MAGIC: &[u8] = b\"RSIC\";\n@@ -28,7 +30,7 @@ const HEADER_FORMAT_VERSION: u16 = 0;\n /// the Git commit hash.\n const RUSTC_VERSION: Option<&str> = option_env!(\"CFG_VERSION\");\n \n-pub fn write_file_header(stream: &mut FileEncoder, nightly_build: bool) -> FileEncodeResult {\n+pub(crate) fn write_file_header(stream: &mut FileEncoder, nightly_build: bool) -> FileEncodeResult {\n     stream.emit_raw_bytes(FILE_MAGIC)?;\n     stream.emit_raw_bytes(&[\n         (HEADER_FORMAT_VERSION >> 0) as u8,\n@@ -41,6 +43,61 @@ pub fn write_file_header(stream: &mut FileEncoder, nightly_build: bool) -> FileE\n     stream.emit_raw_bytes(rustc_version.as_bytes())\n }\n \n+pub(crate) fn save_in<F>(sess: &Session, path_buf: PathBuf, name: &str, encode: F)\n+where\n+    F: FnOnce(&mut FileEncoder) -> FileEncodeResult,\n+{\n+    debug!(\"save: storing data in {}\", path_buf.display());\n+\n+    // Delete the old file, if any.\n+    // Note: It's important that we actually delete the old file and not just\n+    // truncate and overwrite it, since it might be a shared hard-link, the\n+    // underlying data of which we don't want to modify.\n+    //\n+    // We have to ensure we have dropped the memory maps to this file\n+    // before performing this removal.\n+    match fs::remove_file(&path_buf) {\n+        Ok(()) => {\n+            debug!(\"save: remove old file\");\n+        }\n+        Err(err) if err.kind() == io::ErrorKind::NotFound => (),\n+        Err(err) => {\n+            sess.err(&format!(\n+                \"unable to delete old {} at `{}`: {}\",\n+                name,\n+                path_buf.display(),\n+                err\n+            ));\n+            return;\n+        }\n+    }\n+\n+    let mut encoder = match FileEncoder::new(&path_buf) {\n+        Ok(encoder) => encoder,\n+        Err(err) => {\n+            sess.err(&format!(\"failed to create {} at `{}`: {}\", name, path_buf.display(), err));\n+            return;\n+        }\n+    };\n+\n+    if let Err(err) = write_file_header(&mut encoder, sess.is_nightly_build()) {\n+        sess.err(&format!(\"failed to write {} header to `{}`: {}\", name, path_buf.display(), err));\n+        return;\n+    }\n+\n+    if let Err(err) = encode(&mut encoder) {\n+        sess.err(&format!(\"failed to write {} to `{}`: {}\", name, path_buf.display(), err));\n+        return;\n+    }\n+\n+    if let Err(err) = encoder.flush() {\n+        sess.err(&format!(\"failed to flush {} to `{}`: {}\", name, path_buf.display(), err));\n+        return;\n+    }\n+\n+    debug!(\"save: data written to disk successfully\");\n+}\n+\n /// Reads the contents of a file with a file header as defined in this module.\n ///\n /// - Returns `Ok(Some(data, pos))` if the file existed and was generated by a\n@@ -54,14 +111,21 @@ pub fn read_file(\n     report_incremental_info: bool,\n     path: &Path,\n     nightly_build: bool,\n-) -> io::Result<Option<(Vec<u8>, usize)>> {\n-    let data = match fs::read(path) {\n-        Ok(data) => data,\n+) -> io::Result<Option<(Mmap, usize)>> {\n+    let file = match fs::File::open(path) {\n+        Ok(file) => file,\n         Err(err) if err.kind() == io::ErrorKind::NotFound => return Ok(None),\n         Err(err) => return Err(err),\n     };\n+    // SAFETY: This process must not modify nor remove the backing file while the memory map lives.\n+    // For the dep-graph and the work product index, it is as soon as the decoding is done.\n+    // For the query result cache, the memory map is dropped in save_dep_graph before calling\n+    // save_in and trying to remove the backing file.\n+    //\n+    // There is no way to prevent another process from modifying this file.\n+    let mmap = unsafe { Mmap::map(file) }?;\n \n-    let mut file = io::Cursor::new(data);\n+    let mut file = io::Cursor::new(&*mmap);\n \n     // Check FILE_MAGIC\n     {\n@@ -103,7 +167,7 @@ pub fn read_file(\n     }\n \n     let post_header_start_pos = file.position() as usize;\n-    Ok(Some((file.into_inner(), post_header_start_pos)))\n+    Ok(Some((mmap, post_header_start_pos)))\n }\n \n fn report_format_mismatch(report_incremental_info: bool, file: &Path, message: &str) {"}, {"sha": "4d38556e5d2145aa4ee34f275b88b6f4a739d368", "filename": "compiler/rustc_incremental/src/persist/load.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fload.rs?ref=11bbb5231349a0a144d86d5c0c21061a06d1969d", "patch": "@@ -1,6 +1,7 @@\n //! Code to save/load the dep-graph from files.\n \n use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::memmap::Mmap;\n use rustc_middle::dep_graph::{SerializedDepGraph, WorkProduct, WorkProductId};\n use rustc_middle::ty::OnDiskCache;\n use rustc_serialize::opaque::Decoder;\n@@ -48,7 +49,7 @@ fn load_data(\n     report_incremental_info: bool,\n     path: &Path,\n     nightly_build: bool,\n-) -> LoadResult<(Vec<u8>, usize)> {\n+) -> LoadResult<(Mmap, usize)> {\n     match file_format::read_file(report_incremental_info, path, nightly_build) {\n         Ok(Some(data_and_pos)) => LoadResult::Ok { data: data_and_pos },\n         Ok(None) => {"}, {"sha": "6c683058b12d668945278790ed3e26ed76e10168", "filename": "compiler/rustc_incremental/src/persist/save.rs", "status": "modified", "additions": 11, "deletions": 56, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fsave.rs?ref=11bbb5231349a0a144d86d5c0c21061a06d1969d", "patch": "@@ -6,8 +6,6 @@ use rustc_serialize::opaque::{FileEncodeResult, FileEncoder};\n use rustc_serialize::Encodable as RustcEncodable;\n use rustc_session::Session;\n use std::fs;\n-use std::io;\n-use std::path::PathBuf;\n \n use super::data::*;\n use super::dirty_clean;\n@@ -44,7 +42,14 @@ pub fn save_dep_graph(tcx: TyCtxt<'_>) {\n         join(\n             move || {\n                 sess.time(\"incr_comp_persist_result_cache\", || {\n-                    save_in(sess, query_cache_path, \"query cache\", |e| encode_query_cache(tcx, e));\n+                    // Drop the memory map so that we can remove the file and write to it.\n+                    if let Some(odc) = &tcx.on_disk_cache {\n+                        odc.drop_serialized_data(tcx);\n+                    }\n+\n+                    file_format::save_in(sess, query_cache_path, \"query cache\", |e| {\n+                        encode_query_cache(tcx, e)\n+                    });\n                 });\n             },\n             move || {\n@@ -86,7 +91,9 @@ pub fn save_work_product_index(\n     debug!(\"save_work_product_index()\");\n     dep_graph.assert_ignored();\n     let path = work_products_path(sess);\n-    save_in(sess, path, \"work product index\", |e| encode_work_product_index(&new_work_products, e));\n+    file_format::save_in(sess, path, \"work product index\", |e| {\n+        encode_work_product_index(&new_work_products, e)\n+    });\n \n     // We also need to clean out old work-products, as not all of them are\n     // deleted during invalidation. Some object files don't change their\n@@ -113,58 +120,6 @@ pub fn save_work_product_index(\n     });\n }\n \n-pub(crate) fn save_in<F>(sess: &Session, path_buf: PathBuf, name: &str, encode: F)\n-where\n-    F: FnOnce(&mut FileEncoder) -> FileEncodeResult,\n-{\n-    debug!(\"save: storing data in {}\", path_buf.display());\n-\n-    // Delete the old file, if any.\n-    // Note: It's important that we actually delete the old file and not just\n-    // truncate and overwrite it, since it might be a shared hard-link, the\n-    // underlying data of which we don't want to modify\n-    match fs::remove_file(&path_buf) {\n-        Ok(()) => {\n-            debug!(\"save: remove old file\");\n-        }\n-        Err(err) if err.kind() == io::ErrorKind::NotFound => (),\n-        Err(err) => {\n-            sess.err(&format!(\n-                \"unable to delete old {} at `{}`: {}\",\n-                name,\n-                path_buf.display(),\n-                err\n-            ));\n-            return;\n-        }\n-    }\n-\n-    let mut encoder = match FileEncoder::new(&path_buf) {\n-        Ok(encoder) => encoder,\n-        Err(err) => {\n-            sess.err(&format!(\"failed to create {} at `{}`: {}\", name, path_buf.display(), err));\n-            return;\n-        }\n-    };\n-\n-    if let Err(err) = file_format::write_file_header(&mut encoder, sess.is_nightly_build()) {\n-        sess.err(&format!(\"failed to write {} header to `{}`: {}\", name, path_buf.display(), err));\n-        return;\n-    }\n-\n-    if let Err(err) = encode(&mut encoder) {\n-        sess.err(&format!(\"failed to write {} to `{}`: {}\", name, path_buf.display(), err));\n-        return;\n-    }\n-\n-    if let Err(err) = encoder.flush() {\n-        sess.err(&format!(\"failed to flush {} to `{}`: {}\", name, path_buf.display(), err));\n-        return;\n-    }\n-\n-    debug!(\"save: data written to disk successfully\");\n-}\n-\n fn encode_work_product_index(\n     work_products: &FxHashMap<WorkProductId, WorkProduct>,\n     encoder: &mut FileEncoder,"}, {"sha": "1f5057d1da22ff9c73bc66f79eb2f13b919ed801", "filename": "compiler/rustc_middle/src/ty/context.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs?ref=11bbb5231349a0a144d86d5c0c21061a06d1969d", "patch": "@@ -27,6 +27,7 @@ use crate::ty::{\n use rustc_ast as ast;\n use rustc_attr as attr;\n use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+use rustc_data_structures::memmap::Mmap;\n use rustc_data_structures::profiling::SelfProfilerRef;\n use rustc_data_structures::sharded::{IntoPointer, ShardedHashMap};\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n@@ -71,7 +72,7 @@ use std::sync::Arc;\n \n pub trait OnDiskCache<'tcx>: rustc_data_structures::sync::Sync {\n     /// Creates a new `OnDiskCache` instance from the serialized data in `data`.\n-    fn new(sess: &'tcx Session, data: Vec<u8>, start_pos: usize) -> Self\n+    fn new(sess: &'tcx Session, data: Mmap, start_pos: usize) -> Self\n     where\n         Self: Sized;\n \n@@ -100,6 +101,8 @@ pub trait OnDiskCache<'tcx>: rustc_data_structures::sync::Sync {\n     fn register_reused_dep_node(&self, tcx: TyCtxt<'tcx>, dep_node: &DepNode);\n     fn store_foreign_def_id_hash(&self, def_id: DefId, hash: DefPathHash);\n \n+    fn drop_serialized_data(&self, tcx: TyCtxt<'tcx>);\n+\n     fn serialize(&self, tcx: TyCtxt<'tcx>, encoder: &mut FileEncoder) -> FileEncodeResult;\n }\n "}, {"sha": "5c2803c67e73fca87c75741741946820689356e2", "filename": "compiler/rustc_query_impl/src/on_disk_cache.rs", "status": "modified", "additions": 35, "deletions": 23, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_query_impl%2Fsrc%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bbb5231349a0a144d86d5c0c21061a06d1969d/compiler%2Frustc_query_impl%2Fsrc%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Fon_disk_cache.rs?ref=11bbb5231349a0a144d86d5c0c21061a06d1969d", "patch": "@@ -1,6 +1,7 @@\n use crate::QueryCtxt;\n use rustc_data_structures::fx::{FxHashMap, FxHashSet, FxIndexSet};\n-use rustc_data_structures::sync::{HashMapExt, Lock, Lrc, OnceCell};\n+use rustc_data_structures::memmap::Mmap;\n+use rustc_data_structures::sync::{HashMapExt, Lock, Lrc, OnceCell, RwLock};\n use rustc_data_structures::unhash::UnhashMap;\n use rustc_hir::def_id::{CrateNum, DefId, DefIndex, LocalDefId, StableCrateId, LOCAL_CRATE};\n use rustc_hir::definitions::DefPathHash;\n@@ -42,7 +43,7 @@ const TAG_EXPN_DATA: u8 = 1;\n /// any side effects that have been emitted during a query.\n pub struct OnDiskCache<'sess> {\n     // The complete cache data in serialized form.\n-    serialized_data: Vec<u8>,\n+    serialized_data: RwLock<Option<Mmap>>,\n \n     // Collects all `QuerySideEffects` created during the current compilation\n     // session.\n@@ -182,7 +183,8 @@ impl EncodedSourceFileId {\n }\n \n impl<'sess> rustc_middle::ty::OnDiskCache<'sess> for OnDiskCache<'sess> {\n-    fn new(sess: &'sess Session, data: Vec<u8>, start_pos: usize) -> Self {\n+    /// Creates a new `OnDiskCache` instance from the serialized data in `data`.\n+    fn new(sess: &'sess Session, data: Mmap, start_pos: usize) -> Self {\n         debug_assert!(sess.opts.incremental.is_some());\n \n         // Wrap in a scope so we can borrow `data`.\n@@ -204,7 +206,7 @@ impl<'sess> rustc_middle::ty::OnDiskCache<'sess> for OnDiskCache<'sess> {\n         };\n \n         Self {\n-            serialized_data: data,\n+            serialized_data: RwLock::new(Some(data)),\n             file_index_to_stable_id: footer.file_index_to_stable_id,\n             file_index_to_file: Default::default(),\n             cnum_map: OnceCell::new(),\n@@ -225,7 +227,7 @@ impl<'sess> rustc_middle::ty::OnDiskCache<'sess> for OnDiskCache<'sess> {\n \n     fn new_empty(source_map: &'sess SourceMap) -> Self {\n         Self {\n-            serialized_data: Vec::new(),\n+            serialized_data: RwLock::new(None),\n             file_index_to_stable_id: Default::default(),\n             file_index_to_file: Default::default(),\n             cnum_map: OnceCell::new(),\n@@ -244,7 +246,31 @@ impl<'sess> rustc_middle::ty::OnDiskCache<'sess> for OnDiskCache<'sess> {\n         }\n     }\n \n-    fn serialize(&self, tcx: TyCtxt<'sess>, encoder: &mut FileEncoder) -> FileEncodeResult {\n+    /// Execute all cache promotions and release the serialized backing Mmap.\n+    ///\n+    /// Cache promotions require invoking queries, which needs to read the serialized data.\n+    /// In order to serialize the new on-disk cache, the former on-disk cache file needs to be\n+    /// deleted, hence we won't be able to refer to its memmapped data.\n+    fn drop_serialized_data(&self, tcx: TyCtxt<'tcx>) {\n+        // Register any dep nodes that we reused from the previous session,\n+        // but didn't `DepNode::construct` in this session. This ensures\n+        // that their `DefPathHash` to `RawDefId` mappings are registered\n+        // in 'latest_foreign_def_path_hashes' if necessary, since that\n+        // normally happens in `DepNode::construct`.\n+        tcx.dep_graph.register_reused_dep_nodes(tcx);\n+\n+        // Load everything into memory so we can write it out to the on-disk\n+        // cache. The vast majority of cacheable query results should already\n+        // be in memory, so this should be a cheap operation.\n+        // Do this *before* we clone 'latest_foreign_def_path_hashes', since\n+        // loading existing queries may cause us to create new DepNodes, which\n+        // may in turn end up invoking `store_foreign_def_id_hash`\n+        tcx.dep_graph.exec_cache_promotions(QueryCtxt::from_tcx(tcx));\n+\n+        *self.serialized_data.write() = None;\n+    }\n+\n+    fn serialize<'tcx>(&self, tcx: TyCtxt<'tcx>, encoder: &mut FileEncoder) -> FileEncodeResult {\n         // Serializing the `DepGraph` should not modify it.\n         tcx.dep_graph.with_ignore(|| {\n             // Allocate `SourceFileIndex`es.\n@@ -266,21 +292,6 @@ impl<'sess> rustc_middle::ty::OnDiskCache<'sess> for OnDiskCache<'sess> {\n                 (file_to_file_index, file_index_to_stable_id)\n             };\n \n-            // Register any dep nodes that we reused from the previous session,\n-            // but didn't `DepNode::construct` in this session. This ensures\n-            // that their `DefPathHash` to `RawDefId` mappings are registered\n-            // in 'latest_foreign_def_path_hashes' if necessary, since that\n-            // normally happens in `DepNode::construct`.\n-            tcx.dep_graph.register_reused_dep_nodes(tcx);\n-\n-            // Load everything into memory so we can write it out to the on-disk\n-            // cache. The vast majority of cacheable query results should already\n-            // be in memory, so this should be a cheap operation.\n-            // Do this *before* we clone 'latest_foreign_def_path_hashes', since\n-            // loading existing queries may cause us to create new DepNodes, which\n-            // may in turn end up invoking `store_foreign_def_id_hash`\n-            tcx.dep_graph.exec_cache_promotions(QueryCtxt::from_tcx(tcx));\n-\n             let latest_foreign_def_path_hashes = self.latest_foreign_def_path_hashes.lock().clone();\n             let hygiene_encode_context = HygieneEncodeContext::default();\n \n@@ -564,7 +575,7 @@ impl<'sess> OnDiskCache<'sess> {\n         })\n     }\n \n-    fn with_decoder<'a, 'tcx, T, F: FnOnce(&mut CacheDecoder<'sess, 'tcx>) -> T>(\n+    fn with_decoder<'a, 'tcx, T, F: for<'s> FnOnce(&mut CacheDecoder<'s, 'tcx>) -> T>(\n         &'sess self,\n         tcx: TyCtxt<'tcx>,\n         pos: AbsoluteBytePos,\n@@ -575,9 +586,10 @@ impl<'sess> OnDiskCache<'sess> {\n     {\n         let cnum_map = self.cnum_map.get_or_init(|| Self::compute_cnum_map(tcx));\n \n+        let serialized_data = self.serialized_data.read();\n         let mut decoder = CacheDecoder {\n             tcx,\n-            opaque: opaque::Decoder::new(&self.serialized_data[..], pos.to_usize()),\n+            opaque: opaque::Decoder::new(serialized_data.as_deref().unwrap_or(&[]), pos.to_usize()),\n             source_map: self.source_map,\n             cnum_map,\n             file_index_to_file: &self.file_index_to_file,"}]}