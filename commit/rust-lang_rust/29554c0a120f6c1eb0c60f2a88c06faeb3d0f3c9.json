{"sha": "29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9", "node_id": "C_kwDOAAsO6NoAKDI5NTU0YzBhMTIwZjZjMWViMGM2MGYyYTg4YzA2ZmFlYjNkMGYzYzk", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-10T14:02:45Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-10T14:02:45Z"}, "message": "Auto merge of #98463 - mystor:expand_expr_bool, r=eddyb\n\nproc_macro: Fix expand_expr expansion of bool literals\n\nPreviously, the expand_expr method would expand bool literals as a\n`Literal` token containing a `LitKind::Bool`, rather than as an `Ident`.\nThis is not a valid token, and the `LitKind::Bool` case needs to be\nhandled seperately.\n\nTests were added to more deeply compare the streams in the expand-expr\ntest suite to catch mistakes like this in the future.", "tree": {"sha": "a1c97773965a554cfc3d5fc958d832f3c67014df", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a1c97773965a554cfc3d5fc958d832f3c67014df"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9", "html_url": "https://github.com/rust-lang/rust/commit/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "268be96d6db196d79a1b2b8299a0485496e5a7ab", "url": "https://api.github.com/repos/rust-lang/rust/commits/268be96d6db196d79a1b2b8299a0485496e5a7ab", "html_url": "https://github.com/rust-lang/rust/commit/268be96d6db196d79a1b2b8299a0485496e5a7ab"}, {"sha": "fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "url": "https://api.github.com/repos/rust-lang/rust/commits/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "html_url": "https://github.com/rust-lang/rust/commit/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad"}], "stats": {"total": 75, "additions": 74, "deletions": 1}, "files": [{"sha": "411d6be9c44f43ce33a97632106cc00a759d79cb", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9", "patch": "@@ -426,6 +426,10 @@ impl server::TokenStream for Rustc<'_, '_> {\n         // We don't use `TokenStream::from_ast` as the tokenstream currently cannot\n         // be recovered in the general case.\n         match &expr.kind {\n+            ast::ExprKind::Lit(l) if l.token.kind == token::Bool => {\n+                Ok(tokenstream::TokenTree::token(token::Ident(l.token.symbol, false), l.span)\n+                    .into())\n+            }\n             ast::ExprKind::Lit(l) => {\n                 Ok(tokenstream::TokenTree::token(token::Literal(l.token), l.span).into())\n             }"}, {"sha": "5463e79d74e0a262eefcbcc5bfca58d53f702f4f", "filename": "src/test/ui/proc-macro/auxiliary/expand-expr.rs", "status": "modified", "additions": 70, "deletions": 1, "changes": 71, "blob_url": "https://github.com/rust-lang/rust/blob/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fexpand-expr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fexpand-expr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fexpand-expr.rs?ref=29554c0a120f6c1eb0c60f2a88c06faeb3d0f3c9", "patch": "@@ -10,6 +10,72 @@ extern crate proc_macro;\n use proc_macro::*;\n use std::str::FromStr;\n \n+// Flatten the TokenStream, removing any toplevel `Delimiter::None`s for\n+// comparison.\n+fn flatten(ts: TokenStream) -> Vec<TokenTree> {\n+    ts.into_iter()\n+        .flat_map(|tt| match &tt {\n+            TokenTree::Group(group) if group.delimiter() == Delimiter::None => {\n+                flatten(group.stream())\n+            }\n+            _ => vec![tt],\n+        })\n+        .collect()\n+}\n+\n+// Assert that two TokenStream values are roughly equal to one-another.\n+fn assert_ts_eq(lhs: &TokenStream, rhs: &TokenStream) {\n+    let ltts = flatten(lhs.clone());\n+    let rtts = flatten(rhs.clone());\n+\n+    if ltts.len() != rtts.len() {\n+        panic!(\n+            \"expected the same number of tts ({} == {})\\nlhs:\\n{:#?}\\nrhs:\\n{:#?}\",\n+            ltts.len(),\n+            rtts.len(),\n+            lhs,\n+            rhs\n+        )\n+    }\n+\n+    for (ltt, rtt) in ltts.iter().zip(&rtts) {\n+        match (ltt, rtt) {\n+            (TokenTree::Group(l), TokenTree::Group(r)) => {\n+                assert_eq!(\n+                    l.delimiter(),\n+                    r.delimiter(),\n+                    \"expected delimiters to match for {:?} and {:?}\",\n+                    l,\n+                    r\n+                );\n+                assert_ts_eq(&l.stream(), &r.stream());\n+            }\n+            (TokenTree::Punct(l), TokenTree::Punct(r)) => assert_eq!(\n+                (l.as_char(), l.spacing()),\n+                (r.as_char(), r.spacing()),\n+                \"expected punct to match for {:?} and {:?}\",\n+                l,\n+                r\n+            ),\n+            (TokenTree::Ident(l), TokenTree::Ident(r)) => assert_eq!(\n+                l.to_string(),\n+                r.to_string(),\n+                \"expected ident to match for {:?} and {:?}\",\n+                l,\n+                r\n+            ),\n+            (TokenTree::Literal(l), TokenTree::Literal(r)) => assert_eq!(\n+                l.to_string(),\n+                r.to_string(),\n+                \"expected literal to match for {:?} and {:?}\",\n+                l,\n+                r\n+            ),\n+            (l, r) => panic!(\"expected type to match for {:?} and {:?}\", l, r),\n+        }\n+    }\n+}\n+\n #[proc_macro]\n pub fn expand_expr_is(input: TokenStream) -> TokenStream {\n     let mut iter = input.into_iter();\n@@ -31,6 +97,9 @@ pub fn expand_expr_is(input: TokenStream) -> TokenStream {\n         expanded.to_string()\n     );\n \n+    // Also compare the raw tts to make sure they line up.\n+    assert_ts_eq(&expected, &expanded);\n+\n     TokenStream::new()\n }\n \n@@ -48,7 +117,7 @@ pub fn check_expand_expr_file(ts: TokenStream) -> TokenStream {\n     // invocation expand to the same literal.\n     let input_t = ts.expand_expr().expect(\"expand_expr failed on macro input\").to_string();\n     let parse_t = TokenStream::from_str(\"file!{}\")\n-    .unwrap()\n+        .unwrap()\n         .expand_expr()\n         .expect(\"expand_expr failed on internal macro\")\n         .to_string();"}]}