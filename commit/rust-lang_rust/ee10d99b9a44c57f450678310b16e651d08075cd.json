{"sha": "ee10d99b9a44c57f450678310b16e651d08075cd", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVlMTBkOTliOWE0NGM1N2Y0NTA2NzgzMTBiMTZlNjUxZDA4MDc1Y2Q=", "commit": {"author": {"name": "Andy Russell", "email": "arussell123@gmail.com", "date": "2018-12-15T17:56:45Z"}, "committer": {"name": "Andy Russell", "email": "arussell123@gmail.com", "date": "2019-01-15T01:29:39Z"}, "message": "generalize markdown to source span calculation", "tree": {"sha": "325fc794c4a7508335de6de76806447d302c0a02", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/325fc794c4a7508335de6de76806447d302c0a02"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ee10d99b9a44c57f450678310b16e651d08075cd", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQFKBAABCAA0FiEELriChyEaiMu0yCg7viIhAz7bw3QFAlw9N4MWHGFydXNzZWxs\nMTIzQGdtYWlsLmNvbQAKCRC+IiEDPtvDdNJ5B/96kKuP5Cax0Ddq9J4FmizaaJN+\nFxhxc36rqPB0QuJivDoJU3DL9HgFtop5K3ro5yE73cqG2GPcUu7IxJyL4xdMFYEJ\nH8qYc9FNDGh6rm9Yawu6vTu9WGUfFsOAGGIl2W4uMunq3lBqVrukoYl6zJgxPQcI\nyh0boRtlzzUBjKR8hGdZFzcQByzAXjAfYLBypmMoQPtYvYe6HQ9pnbSiRu6W4jKj\nWRHQ4oqXSiLKrUxDcpE6pxpGBQcaem6EWoipoPxxBSZ9/sJQiEhG1rxEnMhAt318\n7oeMHuhAQfK2luPqGc80Vz1mo/9qnIY0KoM3xcMDRWWikPX6cj9RHhd4It10\n=amC8\n-----END PGP SIGNATURE-----", "payload": "tree 325fc794c4a7508335de6de76806447d302c0a02\nparent 03acbd71c977cd63ce5f39ba9b6fe9ffd578785a\nauthor Andy Russell <arussell123@gmail.com> 1544896605 -0500\ncommitter Andy Russell <arussell123@gmail.com> 1547515779 -0500\n\ngeneralize markdown to source span calculation\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ee10d99b9a44c57f450678310b16e651d08075cd", "html_url": "https://github.com/rust-lang/rust/commit/ee10d99b9a44c57f450678310b16e651d08075cd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ee10d99b9a44c57f450678310b16e651d08075cd/comments", "author": {"login": "euclio", "id": 1372438, "node_id": "MDQ6VXNlcjEzNzI0Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1372438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/euclio", "html_url": "https://github.com/euclio", "followers_url": "https://api.github.com/users/euclio/followers", "following_url": "https://api.github.com/users/euclio/following{/other_user}", "gists_url": "https://api.github.com/users/euclio/gists{/gist_id}", "starred_url": "https://api.github.com/users/euclio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/euclio/subscriptions", "organizations_url": "https://api.github.com/users/euclio/orgs", "repos_url": "https://api.github.com/users/euclio/repos", "events_url": "https://api.github.com/users/euclio/events{/privacy}", "received_events_url": "https://api.github.com/users/euclio/received_events", "type": "User", "site_admin": false}, "committer": {"login": "euclio", "id": 1372438, "node_id": "MDQ6VXNlcjEzNzI0Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1372438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/euclio", "html_url": "https://github.com/euclio", "followers_url": "https://api.github.com/users/euclio/followers", "following_url": "https://api.github.com/users/euclio/following{/other_user}", "gists_url": "https://api.github.com/users/euclio/gists{/gist_id}", "starred_url": "https://api.github.com/users/euclio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/euclio/subscriptions", "organizations_url": "https://api.github.com/users/euclio/orgs", "repos_url": "https://api.github.com/users/euclio/repos", "events_url": "https://api.github.com/users/euclio/events{/privacy}", "received_events_url": "https://api.github.com/users/euclio/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "03acbd71c977cd63ce5f39ba9b6fe9ffd578785a", "url": "https://api.github.com/repos/rust-lang/rust/commits/03acbd71c977cd63ce5f39ba9b6fe9ffd578785a", "html_url": "https://github.com/rust-lang/rust/commit/03acbd71c977cd63ce5f39ba9b6fe9ffd578785a"}], "stats": {"total": 146, "additions": 87, "deletions": 59}, "files": [{"sha": "56d66712660653842d9442b765d653c4aed0f1c4", "filename": "src/librustdoc/passes/collect_intra_doc_links.rs", "status": "modified", "additions": 4, "deletions": 59, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/ee10d99b9a44c57f450678310b16e651d08075cd/src%2Flibrustdoc%2Fpasses%2Fcollect_intra_doc_links.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee10d99b9a44c57f450678310b16e651d08075cd/src%2Flibrustdoc%2Fpasses%2Fcollect_intra_doc_links.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fpasses%2Fcollect_intra_doc_links.rs?ref=ee10d99b9a44c57f450678310b16e651d08075cd", "patch": "@@ -451,17 +451,9 @@ pub fn span_of_attrs(attrs: &Attributes) -> syntax_pos::Span {\n \n /// Reports a resolution failure diagnostic.\n ///\n-/// Ideally we can report the diagnostic with the actual span in the source where the link failure\n-/// occurred. However, there's a mismatch between the span in the source code and the span in the\n-/// markdown, so we have to do a bit of work to figure out the correspondence.\n-///\n-/// It's not too hard to find the span for sugared doc comments (`///` and `/**`), because the\n-/// source will match the markdown exactly, excluding the comment markers. However, it's much more\n-/// difficult to calculate the spans for unsugared docs, because we have to deal with escaping and\n-/// other source features. So, we attempt to find the exact source span of the resolution failure\n-/// in sugared docs, but use the span of the documentation attributes themselves for unsugared\n-/// docs. Because this span might be overly large, we display the markdown line containing the\n-/// failure as a note.\n+/// If we cannot find the exact source span of the resolution failure, we use the span of the\n+/// documentation attributes themselves. This is a little heavy-handed, so we display the markdown\n+/// line containing the failure as a note as well.\n fn resolution_failure(\n     cx: &DocContext,\n     attrs: &Attributes,\n@@ -473,54 +465,7 @@ fn resolution_failure(\n     let msg = format!(\"`[{}]` cannot be resolved, ignoring it...\", path_str);\n \n     let mut diag = if let Some(link_range) = link_range {\n-        let src = cx.sess().source_map().span_to_snippet(sp);\n-        let is_all_sugared_doc = attrs.doc_strings.iter().all(|frag| match frag {\n-            DocFragment::SugaredDoc(..) => true,\n-            _ => false,\n-        });\n-\n-        if let (Ok(src), true) = (src, is_all_sugared_doc) {\n-            // The number of markdown lines up to and including the resolution failure.\n-            let num_lines = dox[..link_range.start].lines().count();\n-\n-            // We use `split_terminator('\\n')` instead of `lines()` when counting bytes to ensure\n-            // that DOS-style line endings do not cause the spans to be calculated incorrectly.\n-            let mut src_lines = src.split_terminator('\\n');\n-            let mut md_lines = dox.split_terminator('\\n').take(num_lines).peekable();\n-\n-            // The number of bytes from the start of the source span to the resolution failure that\n-            // are *not* part of the markdown, like comment markers.\n-            let mut extra_src_bytes = 0;\n-\n-            while let Some(md_line) = md_lines.next() {\n-                loop {\n-                    let source_line = src_lines\n-                        .next()\n-                        .expect(\"could not find markdown line in source\");\n-\n-                    match source_line.find(md_line) {\n-                        Some(offset) => {\n-                            extra_src_bytes += if md_lines.peek().is_some() {\n-                                source_line.len() - md_line.len()\n-                            } else {\n-                                offset\n-                            };\n-                            break;\n-                        }\n-                        None => {\n-                            // Since this is a source line that doesn't include a markdown line,\n-                            // we have to count the newline that we split from earlier.\n-                            extra_src_bytes += source_line.len() + 1;\n-                        }\n-                    }\n-                }\n-            }\n-\n-            let sp = sp.from_inner_byte_pos(\n-                link_range.start + extra_src_bytes,\n-                link_range.end + extra_src_bytes,\n-            );\n-\n+        if let Some(sp) = super::source_span_for_markdown_range(cx, dox, &link_range, attrs) {\n             let mut diag = cx.tcx.struct_span_lint_node(\n                 lint::builtin::INTRA_DOC_LINK_RESOLUTION_FAILURE,\n                 NodeId::from_u32(0),"}, {"sha": "23581d005116614b4dc3324047aad6061f1f1579", "filename": "src/librustdoc/passes/mod.rs", "status": "modified", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/ee10d99b9a44c57f450678310b16e651d08075cd/src%2Flibrustdoc%2Fpasses%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee10d99b9a44c57f450678310b16e651d08075cd/src%2Flibrustdoc%2Fpasses%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fpasses%2Fmod.rs?ref=ee10d99b9a44c57f450678310b16e651d08075cd", "patch": "@@ -8,6 +8,8 @@ use rustc::util::nodemap::DefIdSet;\n use std::mem;\n use std::fmt;\n use syntax::ast::NodeId;\n+use syntax_pos::Span;\n+use std::ops::Range;\n \n use clean::{self, GetDefId, Item};\n use core::{DocContext, DocAccessLevels};\n@@ -396,3 +398,84 @@ pub fn look_for_tests<'a, 'tcx: 'a, 'rcx: 'a>(\n         }\n     }\n }\n+\n+/// Attempts to match a range of bytes from parsed markdown to a `Span` in the source code.\n+///\n+/// This method will return `None` if we cannot construct a span from the source map or if the\n+/// attributes are not all sugared doc comments. It's difficult to calculate the correct span in\n+/// that case due to escaping and other source features.\n+crate fn source_span_for_markdown_range(\n+    cx: &DocContext,\n+    markdown: &str,\n+    md_range: &Range<usize>,\n+    attrs: &clean::Attributes,\n+) -> Option<Span> {\n+    let is_all_sugared_doc = attrs.doc_strings.iter().all(|frag| match frag {\n+        clean::DocFragment::SugaredDoc(..) => true,\n+        _ => false,\n+    });\n+\n+    if !is_all_sugared_doc {\n+        return None;\n+    }\n+\n+    let snippet = cx\n+        .sess()\n+        .source_map()\n+        .span_to_snippet(span_of_attrs(attrs))\n+        .ok()?;\n+\n+    let starting_line = markdown[..md_range.start].lines().count() - 1;\n+    let ending_line = markdown[..md_range.end].lines().count() - 1;\n+\n+    // We use `split_terminator('\\n')` instead of `lines()` when counting bytes so that we only\n+    // we can treat CRLF and LF line endings the same way.\n+    let mut src_lines = snippet.split_terminator('\\n');\n+    let md_lines = markdown.split_terminator('\\n');\n+\n+    // The number of bytes from the source span to the markdown span that are not part\n+    // of the markdown, like comment markers.\n+    let mut start_bytes = 0;\n+    let mut end_bytes = 0;\n+\n+    'outer: for (line_no, md_line) in md_lines.enumerate() {\n+        loop {\n+            let source_line = src_lines.next().expect(\"could not find markdown in source\");\n+            match source_line.find(md_line) {\n+                Some(offset) => {\n+                    if line_no == starting_line {\n+                        start_bytes += offset;\n+\n+                        if starting_line == ending_line {\n+                            break 'outer;\n+                        }\n+                    } else if line_no == ending_line {\n+                        end_bytes += offset;\n+                        break 'outer;\n+                    } else if line_no < starting_line {\n+                        start_bytes += source_line.len() - md_line.len();\n+                    } else {\n+                        end_bytes += source_line.len() - md_line.len();\n+                    }\n+                    break;\n+                }\n+                None => {\n+                    // Since this is a source line that doesn't include a markdown line,\n+                    // we have to count the newline that we split from earlier.\n+                    if line_no <= starting_line {\n+                        start_bytes += source_line.len() + 1;\n+                    } else {\n+                        end_bytes += source_line.len() + 1;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    let sp = span_of_attrs(attrs).from_inner_byte_pos(\n+        md_range.start + start_bytes,\n+        md_range.end + start_bytes + end_bytes,\n+    );\n+\n+    Some(sp)\n+}"}]}