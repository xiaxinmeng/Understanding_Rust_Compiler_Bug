{"sha": "4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRmNWJmZjk5M2I0NGM0MTJiYjU3YWZlMmQ2YzM3MDlmNTM3MWUzZDQ=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-09-20T00:57:32Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-09-20T02:08:32Z"}, "message": "core: Decompose task into more submodules", "tree": {"sha": "b44086009278c0d3c6e5f7bef5131807a56d7da3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b44086009278c0d3c6e5f7bef5131807a56d7da3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "html_url": "https://github.com/rust-lang/rust/commit/4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "591c152dfc07bc43b132f6ec0f24f2d5e8e06620", "url": "https://api.github.com/repos/rust-lang/rust/commits/591c152dfc07bc43b132f6ec0f24f2d5e8e06620", "html_url": "https://github.com/rust-lang/rust/commit/591c152dfc07bc43b132f6ec0f24f2d5e8e06620"}], "stats": {"total": 1572, "additions": 789, "deletions": 783}, "files": [{"sha": "f6701dfbf034493afac8045f54a6313120c6f6c4", "filename": "src/libcore/core.rc", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Fcore.rc", "raw_url": "https://github.com/rust-lang/rust/raw/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Fcore.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fcore.rc?ref=4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "patch": "@@ -222,6 +222,8 @@ mod comm;\n mod task {\n     mod local_data;\n     mod local_data_priv;\n+    mod spawn;\n+    mod rt;\n }\n mod future;\n mod pipes;"}, {"sha": "bcb7cb284c1c6d1bb73ba67367954fbd8beda599", "filename": "src/libcore/task.rs", "status": "modified", "additions": 29, "deletions": 776, "changes": 805, "blob_url": "https://github.com/rust-lang/rust/blob/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftask.rs?ref=4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "patch": "@@ -75,9 +75,8 @@ export ThreadPerTask;\n export ManualThreads;\n export PlatformThread;\n \n-macro_rules! move_it (\n-    { $x:expr } => { unsafe { let y <- *ptr::addr_of($x); move y } }\n-)\n+use rt::task_id;\n+use rt::rust_task;\n \n /// A handle to a task\n enum Task {\n@@ -498,7 +497,7 @@ impl TaskBuilder {\n             mut notify_chan: move notify_chan,\n             sched: x.opts.sched\n         };\n-        spawn_raw(move opts, x.gen_body(move f));\n+        spawn::spawn_raw(move opts, x.gen_body(move f));\n     }\n     /// Runs a task, while transfering ownership of one argument to the child.\n     fn spawn_with<A: Send>(+arg: A, +f: fn~(+A)) {\n@@ -698,8 +697,8 @@ fn try<T:Send>(+f: fn~() -> T) -> Result<T,()> {\n fn yield() {\n     //! Yield control to the task scheduler\n \n-    let task_ = rustrt::rust_get_task();\n-    let killed = rustrt::rust_task_yield(task_);\n+    let task_ = rt::rust_get_task();\n+    let killed = rt::rust_task_yield(task_);\n     if killed && !failing() {\n         fail ~\"killed\";\n     }\n@@ -708,13 +707,13 @@ fn yield() {\n fn failing() -> bool {\n     //! True if the running task has failed\n \n-    rustrt::rust_task_is_unwinding(rustrt::rust_get_task())\n+    rt::rust_task_is_unwinding(rt::rust_get_task())\n }\n \n fn get_task() -> Task {\n     //! Get a handle to the running task\n \n-    TaskHandle(rustrt::get_task_id())\n+    TaskHandle(rt::get_task_id())\n }\n \n /**\n@@ -735,7 +734,7 @@ fn get_task() -> Task {\n unsafe fn unkillable<U>(f: fn() -> U) -> U {\n     struct AllowFailure {\n         t: *rust_task,\n-        drop { rustrt::rust_task_allow_kill(self.t); }\n+        drop { rt::rust_task_allow_kill(self.t); }\n     }\n \n     fn AllowFailure(t: *rust_task) -> AllowFailure{\n@@ -744,17 +743,17 @@ unsafe fn unkillable<U>(f: fn() -> U) -> U {\n         }\n     }\n \n-    let t = rustrt::rust_get_task();\n+    let t = rt::rust_get_task();\n     let _allow_failure = AllowFailure(t);\n-    rustrt::rust_task_inhibit_kill(t);\n+    rt::rust_task_inhibit_kill(t);\n     f()\n }\n \n /// The inverse of unkillable. Only ever to be used nested in unkillable().\n unsafe fn rekillable<U>(f: fn() -> U) -> U {\n     struct DisallowFailure {\n         t: *rust_task,\n-        drop { rustrt::rust_task_inhibit_kill(self.t); }\n+        drop { rt::rust_task_inhibit_kill(self.t); }\n     }\n \n     fn DisallowFailure(t: *rust_task) -> DisallowFailure {\n@@ -763,9 +762,9 @@ unsafe fn rekillable<U>(f: fn() -> U) -> U {\n         }\n     }\n \n-    let t = rustrt::rust_get_task();\n+    let t = rt::rust_get_task();\n     let _allow_failure = DisallowFailure(t);\n-    rustrt::rust_task_allow_kill(t);\n+    rt::rust_task_allow_kill(t);\n     f()\n }\n \n@@ -777,8 +776,8 @@ unsafe fn atomically<U>(f: fn() -> U) -> U {\n     struct DeferInterrupts {\n         t: *rust_task,\n         drop {\n-            rustrt::rust_task_allow_yield(self.t);\n-            rustrt::rust_task_allow_kill(self.t);\n+            rt::rust_task_allow_yield(self.t);\n+            rt::rust_task_allow_kill(self.t);\n         }\n     }\n \n@@ -788,712 +787,13 @@ unsafe fn atomically<U>(f: fn() -> U) -> U {\n         }\n     }\n \n-    let t = rustrt::rust_get_task();\n+    let t = rt::rust_get_task();\n     let _interrupts = DeferInterrupts(t);\n-    rustrt::rust_task_inhibit_kill(t);\n-    rustrt::rust_task_inhibit_yield(t);\n+    rt::rust_task_inhibit_kill(t);\n+    rt::rust_task_inhibit_yield(t);\n     f()\n }\n \n-/* **************************************************************************\n- * Spawning & linked failure\n- *\n- * Several data structures are involved in task management to allow properly\n- * propagating failure across linked/supervised tasks.\n- *\n- * (1) The \"taskgroup_arc\" is an unsafe::exclusive which contains a hashset of\n- *     all tasks that are part of the group. Some tasks are 'members', which\n- *     means if they fail, they will kill everybody else in the taskgroup.\n- *     Other tasks are 'descendants', which means they will not kill tasks\n- *     from this group, but can be killed by failing members.\n- *\n- *     A new one of these is created each spawn_linked or spawn_supervised.\n- *\n- * (2) The \"tcb\" is a per-task control structure that tracks a task's spawn\n- *     configuration. It contains a reference to its taskgroup_arc, a\n- *     reference to its node in the ancestor list (below), a flag for\n- *     whether it's part of the 'main'/'root' taskgroup, and an optionally\n- *     configured notification port. These are stored in TLS.\n- *\n- * (3) The \"ancestor_list\" is a cons-style list of unsafe::exclusives which\n- *     tracks 'generations' of taskgroups -- a group's ancestors are groups\n- *     which (directly or transitively) spawn_supervised-ed them. Each task\n- *     is recorded in the 'descendants' of each of its ancestor groups.\n- *\n- *     Spawning a supervised task is O(n) in the number of generations still\n- *     alive, and exiting (by success or failure) that task is also O(n).\n- *\n- * This diagram depicts the references between these data structures:\n- *\n- *          linked_________________________________\n- *        ___/                   _________         \\___\n- *       /   \\                  | group X |        /   \\\n- *      (  A  ) - - - - - - - > | {A,B} {}|< - - -(  B  )\n- *       \\___/                  |_________|        \\___/\n- *      unlinked\n- *         |      __ (nil)\n- *         |      //|                         The following code causes this:\n- *         |__   //   /\\         _________\n- *        /   \\ //    ||        | group Y |     fn taskA() {\n- *       (  C  )- - - ||- - - > |{C} {D,E}|         spawn(taskB);\n- *        \\___/      /  \\=====> |_________|         spawn_unlinked(taskC);\n- *      supervise   /gen \\                          ...\n- *         |    __  \\ 00 /                      }\n- *         |    //|  \\__/                       fn taskB() { ... }\n- *         |__ //     /\\         _________      fn taskC() {\n- *        /   \\/      ||        | group Z |         spawn_supervised(taskD);\n- *       (  D  )- - - ||- - - > | {D} {E} |         ...\n- *        \\___/      /  \\=====> |_________|     }\n- *      supervise   /gen \\                      fn taskD() {\n- *         |    __  \\ 01 /                          spawn_supervised(taskE);\n- *         |    //|  \\__/                           ...\n- *         |__ //                _________      }\n- *        /   \\/                | group W |     fn taskE() { ... }\n- *       (  E  )- - - - - - - > | {E}  {} |\n- *        \\___/                 |_________|\n- *\n- *        \"tcb\"               \"taskgroup_arc\"\n- *             \"ancestor_list\"\n- *\n- ****************************************************************************/\n-\n-#[allow(non_camel_case_types)] // runtime type\n-type sched_id = int;\n-#[allow(non_camel_case_types)] // runtime type\n-type task_id = int;\n-\n-// These are both opaque runtime/compiler types that we don't know the\n-// structure of and should only deal with via unsafe pointer\n-#[allow(non_camel_case_types)] // runtime type\n-type rust_task = libc::c_void;\n-#[allow(non_camel_case_types)] // runtime type\n-type rust_closure = libc::c_void;\n-\n-type TaskSet = send_map::linear::LinearMap<*rust_task,()>;\n-\n-fn new_taskset() -> TaskSet {\n-    send_map::linear::LinearMap()\n-}\n-fn taskset_insert(tasks: &mut TaskSet, task: *rust_task) {\n-    let didnt_overwrite = tasks.insert(task, ());\n-    assert didnt_overwrite;\n-}\n-fn taskset_remove(tasks: &mut TaskSet, task: *rust_task) {\n-    let was_present = tasks.remove(&task);\n-    assert was_present;\n-}\n-fn taskset_each(tasks: &TaskSet, blk: fn(+*rust_task) -> bool) {\n-    tasks.each_key(|k| blk(*k))\n-}\n-\n-// One of these per group of linked-failure tasks.\n-type TaskGroupData = {\n-    // All tasks which might kill this group. When this is empty, the group\n-    // can be \"GC\"ed (i.e., its link in the ancestor list can be removed).\n-    mut members:     TaskSet,\n-    // All tasks unidirectionally supervised by (directly or transitively)\n-    // tasks in this group.\n-    mut descendants: TaskSet,\n-};\n-type TaskGroupArc = private::Exclusive<Option<TaskGroupData>>;\n-\n-type TaskGroupInner = &mut Option<TaskGroupData>;\n-\n-// A taskgroup is 'dead' when nothing can cause it to fail; only members can.\n-pure fn taskgroup_is_dead(tg: &TaskGroupData) -> bool {\n-    (&tg.members).is_empty()\n-}\n-\n-// A list-like structure by which taskgroups keep track of all ancestor groups\n-// which may kill them. Needed for tasks to be able to remove themselves from\n-// ancestor groups upon exit. The list has a node for each \"generation\", and\n-// ends either at the root taskgroup (which has no ancestors) or at a\n-// taskgroup which was spawned-unlinked. Tasks from intermediate generations\n-// have references to the middle of the list; when intermediate generations\n-// die, their node in the list will be collected at a descendant's spawn-time.\n-type AncestorNode = {\n-    // Since the ancestor list is recursive, we end up with references to\n-    // exclusives within other exclusives. This is dangerous business (if\n-    // circular references arise, deadlock and memory leaks are imminent).\n-    // Hence we assert that this counter monotonically decreases as we\n-    // approach the tail of the list.\n-    // FIXME(#3068): Make the generation counter togglable with #[cfg(debug)].\n-    generation:       uint,\n-    // Should really be an immutable non-option. This way appeases borrowck.\n-    mut parent_group: Option<TaskGroupArc>,\n-    // Recursive rest of the list.\n-    mut ancestors:    AncestorList,\n-};\n-enum AncestorList = Option<private::Exclusive<AncestorNode>>;\n-\n-// Accessors for taskgroup arcs and ancestor arcs that wrap the unsafety.\n-#[inline(always)]\n-fn access_group<U>(x: &TaskGroupArc, blk: fn(TaskGroupInner) -> U) -> U {\n-    unsafe { x.with(blk) }\n-}\n-\n-#[inline(always)]\n-fn access_ancestors<U>(x: &private::Exclusive<AncestorNode>,\n-                       blk: fn(x: &mut AncestorNode) -> U) -> U {\n-    unsafe { x.with(blk) }\n-}\n-\n-// Iterates over an ancestor list.\n-// (1) Runs forward_blk on each ancestral taskgroup in the list\n-// (2) If forward_blk \"break\"s, runs optional bail_blk on all ancestral\n-//     taskgroups that forward_blk already ran on successfully (Note: bail_blk\n-//     is NOT called on the block that forward_blk broke on!).\n-// (3) As a bonus, coalesces away all 'dead' taskgroup nodes in the list.\n-// FIXME(#2190): Change Option<fn@(...)> to Option<fn&(...)>, to save on\n-// allocations. Once that bug is fixed, changing the sigil should suffice.\n-fn each_ancestor(list:        &mut AncestorList,\n-                 bail_opt:    Option<fn@(TaskGroupInner)>,\n-                 forward_blk: fn(TaskGroupInner) -> bool)\n-        -> bool {\n-    // \"Kickoff\" call - there was no last generation.\n-    return !coalesce(list, bail_opt, forward_blk, uint::max_value);\n-\n-    // Recursively iterates, and coalesces afterwards if needed. Returns\n-    // whether or not unwinding is needed (i.e., !successful iteration).\n-    fn coalesce(list:            &mut AncestorList,\n-                bail_opt:        Option<fn@(TaskGroupInner)>,\n-                forward_blk:     fn(TaskGroupInner) -> bool,\n-                last_generation: uint) -> bool {\n-        // Need to swap the list out to use it, to appease borrowck.\n-        let tmp_list = util::replace(list, AncestorList(None));\n-        let (coalesce_this, early_break) =\n-            iterate(&tmp_list, bail_opt, forward_blk, last_generation);\n-        // What should our next ancestor end up being?\n-        if coalesce_this.is_some() {\n-            // Needed coalesce. Our next ancestor becomes our old\n-            // ancestor's next ancestor. (\"next = old_next->next;\")\n-            *list <- option::unwrap(move coalesce_this);\n-        } else {\n-            // No coalesce; restore from tmp. (\"next = old_next;\")\n-            *list <- tmp_list;\n-        }\n-        return early_break;\n-    }\n-\n-    // Returns an optional list-to-coalesce and whether unwinding is needed.\n-    // Option<ancestor_list>:\n-    //     Whether or not the ancestor taskgroup being iterated over is\n-    //     dead or not; i.e., it has no more tasks left in it, whether or not\n-    //     it has descendants. If dead, the caller shall coalesce it away.\n-    // bool:\n-    //     True if the supplied block did 'break', here or in any recursive\n-    //     calls. If so, must call the unwinder on all previous nodes.\n-    fn iterate(ancestors:       &AncestorList,\n-               bail_opt:        Option<fn@(TaskGroupInner)>,\n-               forward_blk:     fn(TaskGroupInner) -> bool,\n-               last_generation: uint) -> (Option<AncestorList>, bool) {\n-        // At each step of iteration, three booleans are at play which govern\n-        // how the iteration should behave.\n-        // 'nobe_is_dead' - Should the list should be coalesced at this point?\n-        //                  Largely unrelated to the other two.\n-        // 'need_unwind'  - Should we run the bail_blk at this point? (i.e.,\n-        //                  do_continue was false not here, but down the line)\n-        // 'do_continue'  - Did the forward_blk succeed at this point? (i.e.,\n-        //                  should we recurse? or should our callers unwind?)\n-\n-        // The map defaults to None, because if ancestors is None, we're at\n-        // the end of the list, which doesn't make sense to coalesce.\n-        return do (**ancestors).map_default((None,false)) |ancestor_arc| {\n-            // NB: Takes a lock! (this ancestor node)\n-            do access_ancestors(&ancestor_arc) |nobe| {\n-                // Check monotonicity\n-                assert last_generation > nobe.generation;\n-                /*##########################################################*\n-                 * Step 1: Look at this ancestor group (call iterator block).\n-                 *##########################################################*/\n-                let mut nobe_is_dead = false;\n-                let do_continue =\n-                    // NB: Takes a lock! (this ancestor node's parent group)\n-                    do with_parent_tg(&mut nobe.parent_group) |tg_opt| {\n-                        // Decide whether this group is dead. Note that the\n-                        // group being *dead* is disjoint from it *failing*.\n-                        nobe_is_dead = match *tg_opt {\n-                            Some(ref tg) => taskgroup_is_dead(tg),\n-                            None => nobe_is_dead\n-                        };\n-                        // Call iterator block. (If the group is dead, it's\n-                        // safe to skip it. This will leave our *rust_task\n-                        // hanging around in the group even after it's freed,\n-                        // but that's ok because, by virtue of the group being\n-                        // dead, nobody will ever kill-all (foreach) over it.)\n-                        if nobe_is_dead { true } else { forward_blk(tg_opt) }\n-                    };\n-                /*##########################################################*\n-                 * Step 2: Recurse on the rest of the list; maybe coalescing.\n-                 *##########################################################*/\n-                // 'need_unwind' is only set if blk returned true above, *and*\n-                // the recursive call early-broke.\n-                let mut need_unwind = false;\n-                if do_continue {\n-                    // NB: Takes many locks! (ancestor nodes & parent groups)\n-                    need_unwind = coalesce(&mut nobe.ancestors, bail_opt,\n-                                           forward_blk, nobe.generation);\n-                }\n-                /*##########################################################*\n-                 * Step 3: Maybe unwind; compute return info for our caller.\n-                 *##########################################################*/\n-                if need_unwind && !nobe_is_dead {\n-                    do bail_opt.iter |bail_blk| {\n-                        do with_parent_tg(&mut nobe.parent_group) |tg_opt| {\n-                            bail_blk(tg_opt)\n-                        }\n-                    }\n-                }\n-                // Decide whether our caller should unwind.\n-                need_unwind = need_unwind || !do_continue;\n-                // Tell caller whether or not to coalesce and/or unwind\n-                if nobe_is_dead {\n-                    // Swap the list out here; the caller replaces us with it.\n-                    let rest = util::replace(&mut nobe.ancestors,\n-                                             AncestorList(None));\n-                    (Some(move rest), need_unwind)\n-                } else {\n-                    (None, need_unwind)\n-                }\n-            }\n-        };\n-\n-        // Wrapper around exclusive::with that appeases borrowck.\n-        fn with_parent_tg<U>(parent_group: &mut Option<TaskGroupArc>,\n-                             blk: fn(TaskGroupInner) -> U) -> U {\n-            // If this trips, more likely the problem is 'blk' failed inside.\n-            let tmp_arc = option::swap_unwrap(parent_group);\n-            let result = do access_group(&tmp_arc) |tg_opt| { blk(tg_opt) };\n-            *parent_group <- Some(move tmp_arc);\n-            move result\n-        }\n-    }\n-}\n-\n-// One of these per task.\n-struct TCB {\n-    me:            *rust_task,\n-    // List of tasks with whose fates this one's is intertwined.\n-    tasks:         TaskGroupArc, // 'none' means the group has failed.\n-    // Lists of tasks who will kill us if they fail, but whom we won't kill.\n-    mut ancestors: AncestorList,\n-    is_main:       bool,\n-    notifier:      Option<AutoNotify>,\n-    // Runs on task exit.\n-    drop {\n-        // If we are failing, the whole taskgroup needs to die.\n-        if rustrt::rust_task_is_unwinding(self.me) {\n-            self.notifier.iter(|x| { x.failed = true; });\n-            // Take everybody down with us.\n-            do access_group(&self.tasks) |tg| {\n-                kill_taskgroup(tg, self.me, self.is_main);\n-            }\n-        } else {\n-            // Remove ourselves from the group(s).\n-            do access_group(&self.tasks) |tg| {\n-                leave_taskgroup(tg, self.me, true);\n-            }\n-        }\n-        // It doesn't matter whether this happens before or after dealing with\n-        // our own taskgroup, so long as both happen before we die. We need to\n-        // remove ourself from every ancestor we can, so no cleanup; no break.\n-        for each_ancestor(&mut self.ancestors, None) |ancestor_group| {\n-            leave_taskgroup(ancestor_group, self.me, false);\n-        };\n-    }\n-}\n-\n-fn TCB(me: *rust_task, +tasks: TaskGroupArc, +ancestors: AncestorList,\n-       is_main: bool, +notifier: Option<AutoNotify>) -> TCB {\n-\n-    let notifier = move notifier;\n-    notifier.iter(|x| { x.failed = false; });\n-\n-    TCB {\n-        me: me,\n-        tasks: tasks,\n-        ancestors: ancestors,\n-        is_main: is_main,\n-        notifier: move notifier\n-    }\n-}\n-\n-struct AutoNotify {\n-    notify_chan: Chan<Notification>,\n-    mut failed:  bool,\n-    drop {\n-        let result = if self.failed { Failure } else { Success };\n-        self.notify_chan.send(Exit(get_task(), result));\n-    }\n-}\n-\n-fn AutoNotify(+chan: Chan<Notification>) -> AutoNotify {\n-    AutoNotify {\n-        notify_chan: chan,\n-        failed: true // Un-set above when taskgroup successfully made.\n-    }\n-}\n-\n-fn enlist_in_taskgroup(state: TaskGroupInner, me: *rust_task,\n-                       is_member: bool) -> bool {\n-    let newstate = util::replace(state, None);\n-    // If 'None', the group was failing. Can't enlist.\n-    if newstate.is_some() {\n-        let group = option::unwrap(move newstate);\n-        taskset_insert(if is_member { &mut group.members }\n-                       else         { &mut group.descendants }, me);\n-        *state = Some(move group);\n-        true\n-    } else {\n-        false\n-    }\n-}\n-\n-// NB: Runs in destructor/post-exit context. Can't 'fail'.\n-fn leave_taskgroup(state: TaskGroupInner, me: *rust_task, is_member: bool) {\n-    let newstate = util::replace(state, None);\n-    // If 'None', already failing and we've already gotten a kill signal.\n-    if newstate.is_some() {\n-        let group = option::unwrap(move newstate);\n-        taskset_remove(if is_member { &mut group.members }\n-                       else         { &mut group.descendants }, me);\n-        *state = Some(move group);\n-    }\n-}\n-\n-// NB: Runs in destructor/post-exit context. Can't 'fail'.\n-fn kill_taskgroup(state: TaskGroupInner, me: *rust_task, is_main: bool) {\n-    // NB: We could do the killing iteration outside of the group arc, by\n-    // having \"let mut newstate\" here, swapping inside, and iterating after.\n-    // But that would let other exiting tasks fall-through and exit while we\n-    // were trying to kill them, causing potential use-after-free. A task's\n-    // presence in the arc guarantees it's alive only while we hold the lock,\n-    // so if we're failing, all concurrently exiting tasks must wait for us.\n-    // To do it differently, we'd have to use the runtime's task refcounting,\n-    // but that could leave task structs around long after their task exited.\n-    let newstate = util::replace(state, None);\n-    // Might already be None, if Somebody is failing simultaneously.\n-    // That's ok; only one task needs to do the dirty work. (Might also\n-    // see 'None' if Somebody already failed and we got a kill signal.)\n-    if newstate.is_some() {\n-        let group = option::unwrap(move newstate);\n-        for taskset_each(&group.members) |+sibling| {\n-            // Skip self - killing ourself won't do much good.\n-            if sibling != me {\n-                rustrt::rust_task_kill_other(sibling);\n-            }\n-        }\n-        for taskset_each(&group.descendants) |+child| {\n-            assert child != me;\n-            rustrt::rust_task_kill_other(child);\n-        }\n-        // Only one task should ever do this.\n-        if is_main {\n-            rustrt::rust_task_kill_all(me);\n-        }\n-        // Do NOT restore state to Some(..)! It stays None to indicate\n-        // that the whole taskgroup is failing, to forbid new spawns.\n-    }\n-    // (note: multiple tasks may reach this point)\n-}\n-\n-// FIXME (#2912): Work around core-vs-coretest function duplication. Can't use\n-// a proper closure because the #[test]s won't understand. Have to fake it.\n-macro_rules! taskgroup_key (\n-    // Use a \"code pointer\" value that will never be a real code pointer.\n-    () => (cast::transmute((-2 as uint, 0u)))\n-)\n-\n-fn gen_child_taskgroup(linked: bool, supervised: bool)\n-        -> (TaskGroupArc, AncestorList, bool) {\n-    let spawner = rustrt::rust_get_task();\n-    /*######################################################################*\n-     * Step 1. Get spawner's taskgroup info.\n-     *######################################################################*/\n-    let spawner_group = match unsafe { local_get(spawner,\n-                                                 taskgroup_key!()) } {\n-        None => {\n-            // Main task, doing first spawn ever. Lazily initialise here.\n-            let mut members = new_taskset();\n-            taskset_insert(&mut members, spawner);\n-            let tasks =\n-                private::exclusive(Some({ mut members:     move members,\n-                                         mut descendants: new_taskset() }));\n-            // Main task/group has no ancestors, no notifier, etc.\n-            let group =\n-                @TCB(spawner, move tasks, AncestorList(None), true, None);\n-            unsafe {\n-                local_set(spawner, taskgroup_key!(), group);\n-            }\n-            group\n-        }\n-        Some(group) => group\n-    };\n-    /*######################################################################*\n-     * Step 2. Process spawn options for child.\n-     *######################################################################*/\n-    return if linked {\n-        // Child is in the same group as spawner.\n-        let g = spawner_group.tasks.clone();\n-        // Child's ancestors are spawner's ancestors.\n-        let a = share_ancestors(&mut spawner_group.ancestors);\n-        // Propagate main-ness.\n-        (move g, move a, spawner_group.is_main)\n-    } else {\n-        // Child is in a separate group from spawner.\n-        let g = private::exclusive(Some({ mut members:     new_taskset(),\n-                                         mut descendants: new_taskset() }));\n-        let a = if supervised {\n-            // Child's ancestors start with the spawner.\n-            let old_ancestors = share_ancestors(&mut spawner_group.ancestors);\n-            // FIXME(#3068) - The generation counter is only used for a debug\n-            // assertion, but initialising it requires locking a mutex. Hence\n-            // it should be enabled only in debug builds.\n-            let new_generation =\n-                match *old_ancestors {\n-                    Some(arc) => access_ancestors(&arc, |a| a.generation+1),\n-                    None      => 0 // the actual value doesn't really matter.\n-                };\n-            assert new_generation < uint::max_value;\n-            // Build a new node in the ancestor list.\n-            AncestorList(Some(private::exclusive(\n-                { generation:       new_generation,\n-                  mut parent_group: Some(spawner_group.tasks.clone()),\n-                  mut ancestors:    move old_ancestors })))\n-        } else {\n-            // Child has no ancestors.\n-            AncestorList(None)\n-        };\n-        (move g, move a, false)\n-    };\n-\n-    fn share_ancestors(ancestors: &mut AncestorList) -> AncestorList {\n-        // Appease the borrow-checker. Really this wants to be written as:\n-        // match ancestors\n-        //    Some(ancestor_arc) { ancestor_list(Some(ancestor_arc.clone())) }\n-        //    None               { ancestor_list(None) }\n-        let tmp = util::replace(&mut **ancestors, None);\n-        if tmp.is_some() {\n-            let ancestor_arc = option::unwrap(move tmp);\n-            let result = ancestor_arc.clone();\n-            **ancestors <- Some(move ancestor_arc);\n-            AncestorList(Some(move result))\n-        } else {\n-            AncestorList(None)\n-        }\n-    }\n-}\n-\n-fn spawn_raw(+opts: TaskOpts, +f: fn~()) {\n-    let (child_tg, ancestors, is_main) =\n-        gen_child_taskgroup(opts.linked, opts.supervised);\n-\n-    unsafe {\n-        let child_data = ~mut Some((move child_tg, move ancestors, move f));\n-        // Being killed with the unsafe task/closure pointers would leak them.\n-        do unkillable {\n-            // Agh. Get move-mode items into the closure. FIXME (#2829)\n-            let (child_tg, ancestors, f) = option::swap_unwrap(child_data);\n-            // Create child task.\n-            let new_task = match opts.sched {\n-              None             => rustrt::new_task(),\n-              Some(sched_opts) => new_task_in_new_sched(sched_opts)\n-            };\n-            assert !new_task.is_null();\n-            // Getting killed after here would leak the task.\n-            let mut notify_chan = if opts.notify_chan.is_none() {\n-                None\n-            } else {\n-                Some(option::swap_unwrap(&mut opts.notify_chan))\n-            };\n-\n-            let child_wrapper = make_child_wrapper(new_task, move child_tg,\n-                  move ancestors, is_main, move notify_chan, move f);\n-            let fptr = ptr::addr_of(child_wrapper);\n-            let closure: *rust_closure = cast::reinterpret_cast(&fptr);\n-\n-            // Getting killed between these two calls would free the child's\n-            // closure. (Reordering them wouldn't help - then getting killed\n-            // between them would leak.)\n-            rustrt::start_task(new_task, closure);\n-            cast::forget(move child_wrapper);\n-        }\n-    }\n-\n-    // This function returns a closure-wrapper that we pass to the child task.\n-    // (1) It sets up the notification channel.\n-    // (2) It attempts to enlist in the child's group and all ancestor groups.\n-    // (3a) If any of those fails, it leaves all groups, and does nothing.\n-    // (3b) Otherwise it builds a task control structure and puts it in TLS,\n-    // (4) ...and runs the provided body function.\n-    fn make_child_wrapper(child: *rust_task, +child_arc: TaskGroupArc,\n-                          +ancestors: AncestorList, is_main: bool,\n-                          +notify_chan: Option<Chan<Notification>>,\n-                          +f: fn~()) -> fn~() {\n-        let child_data = ~mut Some((move child_arc, move ancestors));\n-        return fn~(move notify_chan, move child_data, move f) {\n-            // Agh. Get move-mode items into the closure. FIXME (#2829)\n-            let mut (child_arc, ancestors) = option::swap_unwrap(child_data);\n-            // Child task runs this code.\n-\n-            // Even if the below code fails to kick the child off, we must\n-            // send Something on the notify channel.\n-\n-            //let mut notifier = None;//notify_chan.map(|c| AutoNotify(c));\n-            let notifier = match notify_chan {\n-                Some(notify_chan_value) => {\n-                    let moved_ncv = move_it!(notify_chan_value);\n-                    Some(AutoNotify(move moved_ncv))\n-                }\n-                _ => None\n-            };\n-\n-            if enlist_many(child, &child_arc, &mut ancestors) {\n-                let group = @TCB(child, move child_arc, move ancestors,\n-                                 is_main, move notifier);\n-                unsafe {\n-                    local_set(child, taskgroup_key!(), group);\n-                }\n-\n-                // Run the child's body.\n-                f();\n-\n-                // TLS cleanup code will exit the taskgroup.\n-            }\n-\n-            // Run the box annihilator.\n-            // XXX: Crashy.\n-            // unsafe { cleanup::annihilate(); }\n-        };\n-\n-        // Set up membership in taskgroup and descendantship in all ancestor\n-        // groups. If any enlistment fails, Some task was already failing, so\n-        // don't let the child task run, and undo every successful enlistment.\n-        fn enlist_many(child: *rust_task, child_arc: &TaskGroupArc,\n-                       ancestors: &mut AncestorList) -> bool {\n-            // Join this taskgroup.\n-            let mut result =\n-                do access_group(child_arc) |child_tg| {\n-                    enlist_in_taskgroup(child_tg, child, true) // member\n-                };\n-            if result {\n-                // Unwinding function in case any ancestral enlisting fails\n-                let bail = |tg: TaskGroupInner| {\n-                    leave_taskgroup(tg, child, false)\n-                };\n-                // Attempt to join every ancestor group.\n-                result =\n-                    for each_ancestor(ancestors, Some(bail)) |ancestor_tg| {\n-                        // Enlist as a descendant, not as an actual member.\n-                        // Descendants don't kill ancestor groups on failure.\n-                        if !enlist_in_taskgroup(ancestor_tg, child, false) {\n-                            break;\n-                        }\n-                    };\n-                // If any ancestor group fails, need to exit this group too.\n-                if !result {\n-                    do access_group(child_arc) |child_tg| {\n-                        leave_taskgroup(child_tg, child, true); // member\n-                    }\n-                }\n-            }\n-            result\n-        }\n-    }\n-\n-    fn new_task_in_new_sched(opts: SchedOpts) -> *rust_task {\n-        if opts.foreign_stack_size != None {\n-            fail ~\"foreign_stack_size scheduler option unimplemented\";\n-        }\n-\n-        let num_threads = match opts.mode {\n-          SingleThreaded => 1u,\n-          ThreadPerCore => rustrt::rust_num_threads(),\n-          ThreadPerTask => {\n-            fail ~\"ThreadPerTask scheduling mode unimplemented\"\n-          }\n-          ManualThreads(threads) => {\n-            if threads == 0u {\n-                fail ~\"can not create a scheduler with no threads\";\n-            }\n-            threads\n-          }\n-          PlatformThread => 0u /* Won't be used */\n-        };\n-\n-        let sched_id = if opts.mode != PlatformThread {\n-            rustrt::rust_new_sched(num_threads)\n-        } else {\n-            rustrt::rust_osmain_sched_id()\n-        };\n-        rustrt::rust_new_task_in_sched(sched_id)\n-    }\n-}\n-\n-extern mod rustrt {\n-    #[rust_stack]\n-    fn rust_task_yield(task: *rust_task) -> bool;\n-\n-    fn rust_get_sched_id() -> sched_id;\n-    fn rust_new_sched(num_threads: libc::uintptr_t) -> sched_id;\n-    fn rust_sched_threads() -> libc::size_t;\n-    fn rust_sched_current_nonlazy_threads() -> libc::size_t;\n-    fn rust_num_threads() -> libc::uintptr_t;\n-\n-    fn get_task_id() -> task_id;\n-    #[rust_stack]\n-    fn rust_get_task() -> *rust_task;\n-\n-    fn new_task() -> *rust_task;\n-    fn rust_new_task_in_sched(id: sched_id) -> *rust_task;\n-\n-    fn start_task(task: *rust_task, closure: *rust_closure);\n-\n-    fn rust_task_is_unwinding(task: *rust_task) -> bool;\n-    fn rust_osmain_sched_id() -> sched_id;\n-    #[rust_stack]\n-    fn rust_task_inhibit_kill(t: *rust_task);\n-    #[rust_stack]\n-    fn rust_task_allow_kill(t: *rust_task);\n-    #[rust_stack]\n-    fn rust_task_inhibit_yield(t: *rust_task);\n-    #[rust_stack]\n-    fn rust_task_allow_yield(t: *rust_task);\n-    fn rust_task_kill_other(task: *rust_task);\n-    fn rust_task_kill_all(task: *rust_task);\n-\n-    #[rust_stack]\n-    fn rust_get_task_local_data(task: *rust_task) -> *libc::c_void;\n-    #[rust_stack]\n-    fn rust_set_task_local_data(task: *rust_task, map: *libc::c_void);\n-    #[rust_stack]\n-    fn rust_task_local_data_atexit(task: *rust_task, cleanup_fn: *u8);\n-}\n-\n-\n-#[test]\n-fn test_spawn_raw_simple() {\n-    let po = comm::Port();\n-    let ch = comm::Chan(po);\n-    do spawn_raw(default_task_opts()) {\n-        comm::send(ch, ());\n-    }\n-    comm::recv(po);\n-}\n-\n-#[test]\n-#[ignore(cfg(windows))]\n-fn test_spawn_raw_unsupervise() {\n-    let opts = {\n-        linked: false,\n-        mut notify_chan: None,\n-        .. default_task_opts()\n-    };\n-    do spawn_raw(opts) {\n-        fail;\n-    }\n-}\n-\n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_cant_dup_task_builder() {\n     let b = task().unlinked();\n@@ -1655,43 +955,6 @@ fn test_spawn_linked_sup_propagate_sibling() {\n     fail;\n }\n \n-#[test]\n-#[ignore(cfg(windows))]\n-fn test_spawn_raw_notify_success() {\n-    let (task_ch, task_po) = pipes::stream();\n-    let (notify_ch, notify_po) = pipes::stream();\n-\n-    let opts = {\n-        notify_chan: Some(move notify_ch),\n-        .. default_task_opts()\n-    };\n-    do spawn_raw(opts) |move task_ch| {\n-        task_ch.send(get_task());\n-    }\n-    let task_ = task_po.recv();\n-    assert notify_po.recv() == Exit(task_, Success);\n-}\n-\n-#[test]\n-#[ignore(cfg(windows))]\n-fn test_spawn_raw_notify_failure() {\n-    // New bindings for these\n-    let (task_ch, task_po) = pipes::stream();\n-    let (notify_ch, notify_po) = pipes::stream();\n-\n-    let opts = {\n-        linked: false,\n-        notify_chan: Some(notify_ch),\n-        .. default_task_opts()\n-    };\n-    do spawn_raw(opts) {\n-        task_ch.send(get_task());\n-        fail;\n-    }\n-    let task_ = task_po.recv();\n-    assert notify_po.recv() == Exit(task_, Failure);\n-}\n-\n #[test]\n fn test_run_basic() {\n     let po = comm::Port();\n@@ -1798,10 +1061,10 @@ fn test_spawn_sched() {\n     let ch = comm::Chan(po);\n \n     fn f(i: int, ch: comm::Chan<()>) {\n-        let parent_sched_id = rustrt::rust_get_sched_id();\n+        let parent_sched_id = rt::rust_get_sched_id();\n \n         do spawn_sched(SingleThreaded) {\n-            let child_sched_id = rustrt::rust_get_sched_id();\n+            let child_sched_id = rt::rust_get_sched_id();\n             assert parent_sched_id != child_sched_id;\n \n             if (i == 0) {\n@@ -1822,9 +1085,9 @@ fn test_spawn_sched_childs_on_same_sched() {\n     let ch = comm::Chan(po);\n \n     do spawn_sched(SingleThreaded) {\n-        let parent_sched_id = rustrt::rust_get_sched_id();\n+        let parent_sched_id = rt::rust_get_sched_id();\n         do spawn {\n-            let child_sched_id = rustrt::rust_get_sched_id();\n+            let child_sched_id = rt::rust_get_sched_id();\n             // This should be on the same scheduler\n             assert parent_sched_id == child_sched_id;\n             comm::send(ch, ());\n@@ -1987,13 +1250,8 @@ fn test_unkillable() {\n     let po = comm::Port();\n     let ch = po.chan();\n \n-    let opts = {\n-        let mut opts = default_task_opts();\n-        opts.linked = false;\n-        move opts\n-    };\n     // We want to do this after failing\n-    do spawn_raw(opts) {\n+    do spawn_unlinked {\n         for iter::repeat(10u) { yield() }\n         ch.send(());\n     }\n@@ -2028,12 +1286,7 @@ fn test_unkillable_nested() {\n     let (ch, po) = pipes::stream();\n \n     // We want to do this after failing\n-    let opts = {\n-        let mut opts = default_task_opts();\n-        opts.linked = false;\n-        move opts\n-    };\n-    do spawn_raw(opts) {\n+    do spawn_unlinked {\n         for iter::repeat(10u) { yield() }\n         ch.send(());\n     }\n@@ -2099,8 +1352,8 @@ fn test_sched_thread_per_core() {\n     let (chan, port) = pipes::stream();\n \n     do spawn_sched(ThreadPerCore) {\n-        let cores = rustrt::rust_num_threads();\n-        let reported_threads = rustrt::rust_sched_threads();\n+        let cores = rt::rust_num_threads();\n+        let reported_threads = rt::rust_sched_threads();\n         assert(cores as uint == reported_threads as uint);\n         chan.send(());\n     }\n@@ -2113,9 +1366,9 @@ fn test_spawn_thread_on_demand() {\n     let (chan, port) = pipes::stream();\n \n     do spawn_sched(ManualThreads(2)) {\n-        let max_threads = rustrt::rust_sched_threads();\n+        let max_threads = rt::rust_sched_threads();\n         assert(max_threads as int == 2);\n-        let running_threads = rustrt::rust_sched_current_nonlazy_threads();\n+        let running_threads = rt::rust_sched_current_nonlazy_threads();\n         assert(running_threads as int == 1);\n \n         let (chan2, port2) = pipes::stream();\n@@ -2124,7 +1377,7 @@ fn test_spawn_thread_on_demand() {\n             chan2.send(());\n         }\n \n-        let running_threads2 = rustrt::rust_sched_current_nonlazy_threads();\n+        let running_threads2 = rt::rust_sched_current_nonlazy_threads();\n         assert(running_threads2 as int == 2);\n \n         port2.recv();"}, {"sha": "3a85055eb023e5fccda3c189c6d284fdce83934b", "filename": "src/libcore/task/local_data.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Flocal_data.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Flocal_data.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftask%2Flocal_data.rs?ref=4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "patch": "@@ -52,7 +52,7 @@ type LocalDataKey<T: Owned> = &fn(+@T);\n unsafe fn local_data_pop<T: Owned>(\n     key: LocalDataKey<T>) -> Option<@T> {\n \n-    local_pop(rustrt::rust_get_task(), key)\n+    local_pop(rt::rust_get_task(), key)\n }\n /**\n  * Retrieve a task-local data value. It will also be kept alive in the\n@@ -61,7 +61,7 @@ unsafe fn local_data_pop<T: Owned>(\n unsafe fn local_data_get<T: Owned>(\n     key: LocalDataKey<T>) -> Option<@T> {\n \n-    local_get(rustrt::rust_get_task(), key)\n+    local_get(rt::rust_get_task(), key)\n }\n /**\n  * Store a value in task-local data. If this key already has a value,\n@@ -70,7 +70,7 @@ unsafe fn local_data_get<T: Owned>(\n unsafe fn local_data_set<T: Owned>(\n     key: LocalDataKey<T>, +data: @T) {\n \n-    local_set(rustrt::rust_get_task(), key, data)\n+    local_set(rt::rust_get_task(), key, data)\n }\n /**\n  * Modify a task-local data value. If the function returns 'None', the\n@@ -80,7 +80,7 @@ unsafe fn local_data_modify<T: Owned>(\n     key: LocalDataKey<T>,\n     modify_fn: fn(Option<@T>) -> Option<@T>) {\n \n-    local_modify(rustrt::rust_get_task(), key, modify_fn)\n+    local_modify(rt::rust_get_task(), key, modify_fn)\n }\n \n #[test]"}, {"sha": "ee02e2ca6e7f8dc906be644ba00057922d437817", "filename": "src/libcore/task/local_data_priv.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Flocal_data_priv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Flocal_data_priv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftask%2Flocal_data_priv.rs?ref=4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "patch": "@@ -1,6 +1,7 @@\n #[doc(hidden)]; // FIXME #3538\n \n use local_data::LocalDataKey;\n+use rt::rust_task;\n \n trait LocalData { }\n impl<T: Owned> @T: LocalData { }\n@@ -34,13 +35,13 @@ unsafe fn get_task_local_map(task: *rust_task) -> TaskLocalMap {\n     // NOTE: The map's box lives in TLS invisibly referenced once. Each time\n     // we retrieve it for get/set, we make another reference, which get/set\n     // drop when they finish. No \"re-storing after modifying\" is needed.\n-    let map_ptr = rustrt::rust_get_task_local_data(task);\n+    let map_ptr = rt::rust_get_task_local_data(task);\n     if map_ptr.is_null() {\n         let map: TaskLocalMap = @dvec::DVec();\n         // Use reinterpret_cast -- transmute would take map away from us also.\n-        rustrt::rust_set_task_local_data(\n+        rt::rust_set_task_local_data(\n             task, cast::reinterpret_cast(&map));\n-        rustrt::rust_task_local_data_atexit(task, cleanup_task_local_map);\n+        rt::rust_task_local_data_atexit(task, cleanup_task_local_map);\n         // Also need to reference it an extra time to keep it for now.\n         cast::bump_box_refcount(map);\n         map"}, {"sha": "b1f7b99bd0715da656c9677415233ca1b3510e52", "filename": "src/libcore/task/rt.rs", "status": "added", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Frt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Frt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftask%2Frt.rs?ref=4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "patch": "@@ -0,0 +1,59 @@\n+/*!\n+\n+The task interface to the runtime\n+\n+*/\n+\n+#[doc(hidden)]; // FIXME #3538\n+\n+#[allow(non_camel_case_types)] // runtime type\n+type sched_id = int;\n+#[allow(non_camel_case_types)] // runtime type\n+type task_id = int;\n+\n+// These are both opaque runtime/compiler types that we don't know the\n+// structure of and should only deal with via unsafe pointer\n+#[allow(non_camel_case_types)] // runtime type\n+type rust_task = libc::c_void;\n+#[allow(non_camel_case_types)] // runtime type\n+type rust_closure = libc::c_void;\n+\n+extern {\n+    #[rust_stack]\n+    fn rust_task_yield(task: *rust_task) -> bool;\n+\n+    fn rust_get_sched_id() -> sched_id;\n+    fn rust_new_sched(num_threads: libc::uintptr_t) -> sched_id;\n+    fn rust_sched_threads() -> libc::size_t;\n+    fn rust_sched_current_nonlazy_threads() -> libc::size_t;\n+    fn rust_num_threads() -> libc::uintptr_t;\n+\n+    fn get_task_id() -> task_id;\n+    #[rust_stack]\n+    fn rust_get_task() -> *rust_task;\n+\n+    fn new_task() -> *rust_task;\n+    fn rust_new_task_in_sched(id: sched_id) -> *rust_task;\n+\n+    fn start_task(task: *rust_task, closure: *rust_closure);\n+\n+    fn rust_task_is_unwinding(task: *rust_task) -> bool;\n+    fn rust_osmain_sched_id() -> sched_id;\n+    #[rust_stack]\n+    fn rust_task_inhibit_kill(t: *rust_task);\n+    #[rust_stack]\n+    fn rust_task_allow_kill(t: *rust_task);\n+    #[rust_stack]\n+    fn rust_task_inhibit_yield(t: *rust_task);\n+    #[rust_stack]\n+    fn rust_task_allow_yield(t: *rust_task);\n+    fn rust_task_kill_other(task: *rust_task);\n+    fn rust_task_kill_all(task: *rust_task);\n+\n+    #[rust_stack]\n+    fn rust_get_task_local_data(task: *rust_task) -> *libc::c_void;\n+    #[rust_stack]\n+    fn rust_set_task_local_data(task: *rust_task, map: *libc::c_void);\n+    #[rust_stack]\n+    fn rust_task_local_data_atexit(task: *rust_task, cleanup_fn: *u8);\n+}"}, {"sha": "40364acf29a57d62ec98bf3d2092a6a447c72de3", "filename": "src/libcore/task/spawn.rs", "status": "added", "additions": 691, "deletions": 0, "changes": 691, "blob_url": "https://github.com/rust-lang/rust/blob/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4f5bff993b44c412bb57afe2d6c3709f5371e3d4/src%2Flibcore%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftask%2Fspawn.rs?ref=4f5bff993b44c412bb57afe2d6c3709f5371e3d4", "patch": "@@ -0,0 +1,691 @@\n+/*!**************************************************************************\n+ * Spawning & linked failure\n+ *\n+ * Several data structures are involved in task management to allow properly\n+ * propagating failure across linked/supervised tasks.\n+ *\n+ * (1) The \"taskgroup_arc\" is an unsafe::exclusive which contains a hashset of\n+ *     all tasks that are part of the group. Some tasks are 'members', which\n+ *     means if they fail, they will kill everybody else in the taskgroup.\n+ *     Other tasks are 'descendants', which means they will not kill tasks\n+ *     from this group, but can be killed by failing members.\n+ *\n+ *     A new one of these is created each spawn_linked or spawn_supervised.\n+ *\n+ * (2) The \"tcb\" is a per-task control structure that tracks a task's spawn\n+ *     configuration. It contains a reference to its taskgroup_arc, a\n+ *     reference to its node in the ancestor list (below), a flag for\n+ *     whether it's part of the 'main'/'root' taskgroup, and an optionally\n+ *     configured notification port. These are stored in TLS.\n+ *\n+ * (3) The \"ancestor_list\" is a cons-style list of unsafe::exclusives which\n+ *     tracks 'generations' of taskgroups -- a group's ancestors are groups\n+ *     which (directly or transitively) spawn_supervised-ed them. Each task\n+ *     is recorded in the 'descendants' of each of its ancestor groups.\n+ *\n+ *     Spawning a supervised task is O(n) in the number of generations still\n+ *     alive, and exiting (by success or failure) that task is also O(n).\n+ *\n+ * This diagram depicts the references between these data structures:\n+ *\n+ *          linked_________________________________\n+ *        ___/                   _________         \\___\n+ *       /   \\                  | group X |        /   \\\n+ *      (  A  ) - - - - - - - > | {A,B} {}|< - - -(  B  )\n+ *       \\___/                  |_________|        \\___/\n+ *      unlinked\n+ *         |      __ (nil)\n+ *         |      //|                         The following code causes this:\n+ *         |__   //   /\\         _________\n+ *        /   \\ //    ||        | group Y |     fn taskA() {\n+ *       (  C  )- - - ||- - - > |{C} {D,E}|         spawn(taskB);\n+ *        \\___/      /  \\=====> |_________|         spawn_unlinked(taskC);\n+ *      supervise   /gen \\                          ...\n+ *         |    __  \\ 00 /                      }\n+ *         |    //|  \\__/                       fn taskB() { ... }\n+ *         |__ //     /\\         _________      fn taskC() {\n+ *        /   \\/      ||        | group Z |         spawn_supervised(taskD);\n+ *       (  D  )- - - ||- - - > | {D} {E} |         ...\n+ *        \\___/      /  \\=====> |_________|     }\n+ *      supervise   /gen \\                      fn taskD() {\n+ *         |    __  \\ 01 /                          spawn_supervised(taskE);\n+ *         |    //|  \\__/                           ...\n+ *         |__ //                _________      }\n+ *        /   \\/                | group W |     fn taskE() { ... }\n+ *       (  E  )- - - - - - - > | {E}  {} |\n+ *        \\___/                 |_________|\n+ *\n+ *        \"tcb\"               \"taskgroup_arc\"\n+ *             \"ancestor_list\"\n+ *\n+ ****************************************************************************/\n+\n+#[doc(hidden)]; // FIXME #3538\n+\n+use rt::rust_task;\n+use rt::rust_closure;\n+\n+macro_rules! move_it (\n+    { $x:expr } => { unsafe { let y <- *ptr::addr_of($x); move y } }\n+)\n+\n+type TaskSet = send_map::linear::LinearMap<*rust_task,()>;\n+\n+fn new_taskset() -> TaskSet {\n+    send_map::linear::LinearMap()\n+}\n+fn taskset_insert(tasks: &mut TaskSet, task: *rust_task) {\n+    let didnt_overwrite = tasks.insert(task, ());\n+    assert didnt_overwrite;\n+}\n+fn taskset_remove(tasks: &mut TaskSet, task: *rust_task) {\n+    let was_present = tasks.remove(&task);\n+    assert was_present;\n+}\n+fn taskset_each(tasks: &TaskSet, blk: fn(+*rust_task) -> bool) {\n+    tasks.each_key(|k| blk(*k))\n+}\n+\n+// One of these per group of linked-failure tasks.\n+type TaskGroupData = {\n+    // All tasks which might kill this group. When this is empty, the group\n+    // can be \"GC\"ed (i.e., its link in the ancestor list can be removed).\n+    mut members:     TaskSet,\n+    // All tasks unidirectionally supervised by (directly or transitively)\n+    // tasks in this group.\n+    mut descendants: TaskSet,\n+};\n+type TaskGroupArc = private::Exclusive<Option<TaskGroupData>>;\n+\n+type TaskGroupInner = &mut Option<TaskGroupData>;\n+\n+// A taskgroup is 'dead' when nothing can cause it to fail; only members can.\n+pure fn taskgroup_is_dead(tg: &TaskGroupData) -> bool {\n+    (&tg.members).is_empty()\n+}\n+\n+// A list-like structure by which taskgroups keep track of all ancestor groups\n+// which may kill them. Needed for tasks to be able to remove themselves from\n+// ancestor groups upon exit. The list has a node for each \"generation\", and\n+// ends either at the root taskgroup (which has no ancestors) or at a\n+// taskgroup which was spawned-unlinked. Tasks from intermediate generations\n+// have references to the middle of the list; when intermediate generations\n+// die, their node in the list will be collected at a descendant's spawn-time.\n+type AncestorNode = {\n+    // Since the ancestor list is recursive, we end up with references to\n+    // exclusives within other exclusives. This is dangerous business (if\n+    // circular references arise, deadlock and memory leaks are imminent).\n+    // Hence we assert that this counter monotonically decreases as we\n+    // approach the tail of the list.\n+    // FIXME(#3068): Make the generation counter togglable with #[cfg(debug)].\n+    generation:       uint,\n+    // Should really be an immutable non-option. This way appeases borrowck.\n+    mut parent_group: Option<TaskGroupArc>,\n+    // Recursive rest of the list.\n+    mut ancestors:    AncestorList,\n+};\n+enum AncestorList = Option<private::Exclusive<AncestorNode>>;\n+\n+// Accessors for taskgroup arcs and ancestor arcs that wrap the unsafety.\n+#[inline(always)]\n+fn access_group<U>(x: &TaskGroupArc, blk: fn(TaskGroupInner) -> U) -> U {\n+    unsafe { x.with(blk) }\n+}\n+\n+#[inline(always)]\n+fn access_ancestors<U>(x: &private::Exclusive<AncestorNode>,\n+                       blk: fn(x: &mut AncestorNode) -> U) -> U {\n+    unsafe { x.with(blk) }\n+}\n+\n+// Iterates over an ancestor list.\n+// (1) Runs forward_blk on each ancestral taskgroup in the list\n+// (2) If forward_blk \"break\"s, runs optional bail_blk on all ancestral\n+//     taskgroups that forward_blk already ran on successfully (Note: bail_blk\n+//     is NOT called on the block that forward_blk broke on!).\n+// (3) As a bonus, coalesces away all 'dead' taskgroup nodes in the list.\n+// FIXME(#2190): Change Option<fn@(...)> to Option<fn&(...)>, to save on\n+// allocations. Once that bug is fixed, changing the sigil should suffice.\n+fn each_ancestor(list:        &mut AncestorList,\n+                 bail_opt:    Option<fn@(TaskGroupInner)>,\n+                 forward_blk: fn(TaskGroupInner) -> bool)\n+        -> bool {\n+    // \"Kickoff\" call - there was no last generation.\n+    return !coalesce(list, bail_opt, forward_blk, uint::max_value);\n+\n+    // Recursively iterates, and coalesces afterwards if needed. Returns\n+    // whether or not unwinding is needed (i.e., !successful iteration).\n+    fn coalesce(list:            &mut AncestorList,\n+                bail_opt:        Option<fn@(TaskGroupInner)>,\n+                forward_blk:     fn(TaskGroupInner) -> bool,\n+                last_generation: uint) -> bool {\n+        // Need to swap the list out to use it, to appease borrowck.\n+        let tmp_list = util::replace(list, AncestorList(None));\n+        let (coalesce_this, early_break) =\n+            iterate(&tmp_list, bail_opt, forward_blk, last_generation);\n+        // What should our next ancestor end up being?\n+        if coalesce_this.is_some() {\n+            // Needed coalesce. Our next ancestor becomes our old\n+            // ancestor's next ancestor. (\"next = old_next->next;\")\n+            *list <- option::unwrap(move coalesce_this);\n+        } else {\n+            // No coalesce; restore from tmp. (\"next = old_next;\")\n+            *list <- tmp_list;\n+        }\n+        return early_break;\n+    }\n+\n+    // Returns an optional list-to-coalesce and whether unwinding is needed.\n+    // Option<ancestor_list>:\n+    //     Whether or not the ancestor taskgroup being iterated over is\n+    //     dead or not; i.e., it has no more tasks left in it, whether or not\n+    //     it has descendants. If dead, the caller shall coalesce it away.\n+    // bool:\n+    //     True if the supplied block did 'break', here or in any recursive\n+    //     calls. If so, must call the unwinder on all previous nodes.\n+    fn iterate(ancestors:       &AncestorList,\n+               bail_opt:        Option<fn@(TaskGroupInner)>,\n+               forward_blk:     fn(TaskGroupInner) -> bool,\n+               last_generation: uint) -> (Option<AncestorList>, bool) {\n+        // At each step of iteration, three booleans are at play which govern\n+        // how the iteration should behave.\n+        // 'nobe_is_dead' - Should the list should be coalesced at this point?\n+        //                  Largely unrelated to the other two.\n+        // 'need_unwind'  - Should we run the bail_blk at this point? (i.e.,\n+        //                  do_continue was false not here, but down the line)\n+        // 'do_continue'  - Did the forward_blk succeed at this point? (i.e.,\n+        //                  should we recurse? or should our callers unwind?)\n+\n+        // The map defaults to None, because if ancestors is None, we're at\n+        // the end of the list, which doesn't make sense to coalesce.\n+        return do (**ancestors).map_default((None,false)) |ancestor_arc| {\n+            // NB: Takes a lock! (this ancestor node)\n+            do access_ancestors(&ancestor_arc) |nobe| {\n+                // Check monotonicity\n+                assert last_generation > nobe.generation;\n+                /*##########################################################*\n+                 * Step 1: Look at this ancestor group (call iterator block).\n+                 *##########################################################*/\n+                let mut nobe_is_dead = false;\n+                let do_continue =\n+                    // NB: Takes a lock! (this ancestor node's parent group)\n+                    do with_parent_tg(&mut nobe.parent_group) |tg_opt| {\n+                        // Decide whether this group is dead. Note that the\n+                        // group being *dead* is disjoint from it *failing*.\n+                        nobe_is_dead = match *tg_opt {\n+                            Some(ref tg) => taskgroup_is_dead(tg),\n+                            None => nobe_is_dead\n+                        };\n+                        // Call iterator block. (If the group is dead, it's\n+                        // safe to skip it. This will leave our *rust_task\n+                        // hanging around in the group even after it's freed,\n+                        // but that's ok because, by virtue of the group being\n+                        // dead, nobody will ever kill-all (foreach) over it.)\n+                        if nobe_is_dead { true } else { forward_blk(tg_opt) }\n+                    };\n+                /*##########################################################*\n+                 * Step 2: Recurse on the rest of the list; maybe coalescing.\n+                 *##########################################################*/\n+                // 'need_unwind' is only set if blk returned true above, *and*\n+                // the recursive call early-broke.\n+                let mut need_unwind = false;\n+                if do_continue {\n+                    // NB: Takes many locks! (ancestor nodes & parent groups)\n+                    need_unwind = coalesce(&mut nobe.ancestors, bail_opt,\n+                                           forward_blk, nobe.generation);\n+                }\n+                /*##########################################################*\n+                 * Step 3: Maybe unwind; compute return info for our caller.\n+                 *##########################################################*/\n+                if need_unwind && !nobe_is_dead {\n+                    do bail_opt.iter |bail_blk| {\n+                        do with_parent_tg(&mut nobe.parent_group) |tg_opt| {\n+                            bail_blk(tg_opt)\n+                        }\n+                    }\n+                }\n+                // Decide whether our caller should unwind.\n+                need_unwind = need_unwind || !do_continue;\n+                // Tell caller whether or not to coalesce and/or unwind\n+                if nobe_is_dead {\n+                    // Swap the list out here; the caller replaces us with it.\n+                    let rest = util::replace(&mut nobe.ancestors,\n+                                             AncestorList(None));\n+                    (Some(move rest), need_unwind)\n+                } else {\n+                    (None, need_unwind)\n+                }\n+            }\n+        };\n+\n+        // Wrapper around exclusive::with that appeases borrowck.\n+        fn with_parent_tg<U>(parent_group: &mut Option<TaskGroupArc>,\n+                             blk: fn(TaskGroupInner) -> U) -> U {\n+            // If this trips, more likely the problem is 'blk' failed inside.\n+            let tmp_arc = option::swap_unwrap(parent_group);\n+            let result = do access_group(&tmp_arc) |tg_opt| { blk(tg_opt) };\n+            *parent_group <- Some(move tmp_arc);\n+            move result\n+        }\n+    }\n+}\n+\n+// One of these per task.\n+struct TCB {\n+    me:            *rust_task,\n+    // List of tasks with whose fates this one's is intertwined.\n+    tasks:         TaskGroupArc, // 'none' means the group has failed.\n+    // Lists of tasks who will kill us if they fail, but whom we won't kill.\n+    mut ancestors: AncestorList,\n+    is_main:       bool,\n+    notifier:      Option<AutoNotify>,\n+    // Runs on task exit.\n+    drop {\n+        // If we are failing, the whole taskgroup needs to die.\n+        if rt::rust_task_is_unwinding(self.me) {\n+            self.notifier.iter(|x| { x.failed = true; });\n+            // Take everybody down with us.\n+            do access_group(&self.tasks) |tg| {\n+                kill_taskgroup(tg, self.me, self.is_main);\n+            }\n+        } else {\n+            // Remove ourselves from the group(s).\n+            do access_group(&self.tasks) |tg| {\n+                leave_taskgroup(tg, self.me, true);\n+            }\n+        }\n+        // It doesn't matter whether this happens before or after dealing with\n+        // our own taskgroup, so long as both happen before we die. We need to\n+        // remove ourself from every ancestor we can, so no cleanup; no break.\n+        for each_ancestor(&mut self.ancestors, None) |ancestor_group| {\n+            leave_taskgroup(ancestor_group, self.me, false);\n+        };\n+    }\n+}\n+\n+fn TCB(me: *rust_task, +tasks: TaskGroupArc, +ancestors: AncestorList,\n+       is_main: bool, +notifier: Option<AutoNotify>) -> TCB {\n+\n+    let notifier = move notifier;\n+    notifier.iter(|x| { x.failed = false; });\n+\n+    TCB {\n+        me: me,\n+        tasks: tasks,\n+        ancestors: ancestors,\n+        is_main: is_main,\n+        notifier: move notifier\n+    }\n+}\n+\n+struct AutoNotify {\n+    notify_chan: Chan<Notification>,\n+    mut failed:  bool,\n+    drop {\n+        let result = if self.failed { Failure } else { Success };\n+        self.notify_chan.send(Exit(get_task(), result));\n+    }\n+}\n+\n+fn AutoNotify(+chan: Chan<Notification>) -> AutoNotify {\n+    AutoNotify {\n+        notify_chan: chan,\n+        failed: true // Un-set above when taskgroup successfully made.\n+    }\n+}\n+\n+fn enlist_in_taskgroup(state: TaskGroupInner, me: *rust_task,\n+                       is_member: bool) -> bool {\n+    let newstate = util::replace(state, None);\n+    // If 'None', the group was failing. Can't enlist.\n+    if newstate.is_some() {\n+        let group = option::unwrap(move newstate);\n+        taskset_insert(if is_member { &mut group.members }\n+                       else         { &mut group.descendants }, me);\n+        *state = Some(move group);\n+        true\n+    } else {\n+        false\n+    }\n+}\n+\n+// NB: Runs in destructor/post-exit context. Can't 'fail'.\n+fn leave_taskgroup(state: TaskGroupInner, me: *rust_task, is_member: bool) {\n+    let newstate = util::replace(state, None);\n+    // If 'None', already failing and we've already gotten a kill signal.\n+    if newstate.is_some() {\n+        let group = option::unwrap(move newstate);\n+        taskset_remove(if is_member { &mut group.members }\n+                       else         { &mut group.descendants }, me);\n+        *state = Some(move group);\n+    }\n+}\n+\n+// NB: Runs in destructor/post-exit context. Can't 'fail'.\n+fn kill_taskgroup(state: TaskGroupInner, me: *rust_task, is_main: bool) {\n+    // NB: We could do the killing iteration outside of the group arc, by\n+    // having \"let mut newstate\" here, swapping inside, and iterating after.\n+    // But that would let other exiting tasks fall-through and exit while we\n+    // were trying to kill them, causing potential use-after-free. A task's\n+    // presence in the arc guarantees it's alive only while we hold the lock,\n+    // so if we're failing, all concurrently exiting tasks must wait for us.\n+    // To do it differently, we'd have to use the runtime's task refcounting,\n+    // but that could leave task structs around long after their task exited.\n+    let newstate = util::replace(state, None);\n+    // Might already be None, if Somebody is failing simultaneously.\n+    // That's ok; only one task needs to do the dirty work. (Might also\n+    // see 'None' if Somebody already failed and we got a kill signal.)\n+    if newstate.is_some() {\n+        let group = option::unwrap(move newstate);\n+        for taskset_each(&group.members) |+sibling| {\n+            // Skip self - killing ourself won't do much good.\n+            if sibling != me {\n+                rt::rust_task_kill_other(sibling);\n+            }\n+        }\n+        for taskset_each(&group.descendants) |+child| {\n+            assert child != me;\n+            rt::rust_task_kill_other(child);\n+        }\n+        // Only one task should ever do this.\n+        if is_main {\n+            rt::rust_task_kill_all(me);\n+        }\n+        // Do NOT restore state to Some(..)! It stays None to indicate\n+        // that the whole taskgroup is failing, to forbid new spawns.\n+    }\n+    // (note: multiple tasks may reach this point)\n+}\n+\n+// FIXME (#2912): Work around core-vs-coretest function duplication. Can't use\n+// a proper closure because the #[test]s won't understand. Have to fake it.\n+macro_rules! taskgroup_key (\n+    // Use a \"code pointer\" value that will never be a real code pointer.\n+    () => (cast::transmute((-2 as uint, 0u)))\n+)\n+\n+fn gen_child_taskgroup(linked: bool, supervised: bool)\n+        -> (TaskGroupArc, AncestorList, bool) {\n+    let spawner = rt::rust_get_task();\n+    /*######################################################################*\n+     * Step 1. Get spawner's taskgroup info.\n+     *######################################################################*/\n+    let spawner_group = match unsafe { local_get(spawner,\n+                                                 taskgroup_key!()) } {\n+        None => {\n+            // Main task, doing first spawn ever. Lazily initialise here.\n+            let mut members = new_taskset();\n+            taskset_insert(&mut members, spawner);\n+            let tasks =\n+                private::exclusive(Some({ mut members:     move members,\n+                                         mut descendants: new_taskset() }));\n+            // Main task/group has no ancestors, no notifier, etc.\n+            let group =\n+                @TCB(spawner, move tasks, AncestorList(None), true, None);\n+            unsafe {\n+                local_set(spawner, taskgroup_key!(), group);\n+            }\n+            group\n+        }\n+        Some(group) => group\n+    };\n+    /*######################################################################*\n+     * Step 2. Process spawn options for child.\n+     *######################################################################*/\n+    return if linked {\n+        // Child is in the same group as spawner.\n+        let g = spawner_group.tasks.clone();\n+        // Child's ancestors are spawner's ancestors.\n+        let a = share_ancestors(&mut spawner_group.ancestors);\n+        // Propagate main-ness.\n+        (move g, move a, spawner_group.is_main)\n+    } else {\n+        // Child is in a separate group from spawner.\n+        let g = private::exclusive(Some({ mut members:     new_taskset(),\n+                                         mut descendants: new_taskset() }));\n+        let a = if supervised {\n+            // Child's ancestors start with the spawner.\n+            let old_ancestors = share_ancestors(&mut spawner_group.ancestors);\n+            // FIXME(#3068) - The generation counter is only used for a debug\n+            // assertion, but initialising it requires locking a mutex. Hence\n+            // it should be enabled only in debug builds.\n+            let new_generation =\n+                match *old_ancestors {\n+                    Some(arc) => access_ancestors(&arc, |a| a.generation+1),\n+                    None      => 0 // the actual value doesn't really matter.\n+                };\n+            assert new_generation < uint::max_value;\n+            // Build a new node in the ancestor list.\n+            AncestorList(Some(private::exclusive(\n+                { generation:       new_generation,\n+                  mut parent_group: Some(spawner_group.tasks.clone()),\n+                  mut ancestors:    move old_ancestors })))\n+        } else {\n+            // Child has no ancestors.\n+            AncestorList(None)\n+        };\n+        (move g, move a, false)\n+    };\n+\n+    fn share_ancestors(ancestors: &mut AncestorList) -> AncestorList {\n+        // Appease the borrow-checker. Really this wants to be written as:\n+        // match ancestors\n+        //    Some(ancestor_arc) { ancestor_list(Some(ancestor_arc.clone())) }\n+        //    None               { ancestor_list(None) }\n+        let tmp = util::replace(&mut **ancestors, None);\n+        if tmp.is_some() {\n+            let ancestor_arc = option::unwrap(move tmp);\n+            let result = ancestor_arc.clone();\n+            **ancestors <- Some(move ancestor_arc);\n+            AncestorList(Some(move result))\n+        } else {\n+            AncestorList(None)\n+        }\n+    }\n+}\n+\n+fn spawn_raw(+opts: TaskOpts, +f: fn~()) {\n+    let (child_tg, ancestors, is_main) =\n+        gen_child_taskgroup(opts.linked, opts.supervised);\n+\n+    unsafe {\n+        let child_data = ~mut Some((move child_tg, move ancestors, move f));\n+        // Being killed with the unsafe task/closure pointers would leak them.\n+        do unkillable {\n+            // Agh. Get move-mode items into the closure. FIXME (#2829)\n+            let (child_tg, ancestors, f) = option::swap_unwrap(child_data);\n+            // Create child task.\n+            let new_task = match opts.sched {\n+              None             => rt::new_task(),\n+              Some(sched_opts) => new_task_in_new_sched(sched_opts)\n+            };\n+            assert !new_task.is_null();\n+            // Getting killed after here would leak the task.\n+            let mut notify_chan = if opts.notify_chan.is_none() {\n+                None\n+            } else {\n+                Some(option::swap_unwrap(&mut opts.notify_chan))\n+            };\n+\n+            let child_wrapper = make_child_wrapper(new_task, move child_tg,\n+                  move ancestors, is_main, move notify_chan, move f);\n+            let fptr = ptr::addr_of(child_wrapper);\n+            let closure: *rust_closure = cast::reinterpret_cast(&fptr);\n+\n+            // Getting killed between these two calls would free the child's\n+            // closure. (Reordering them wouldn't help - then getting killed\n+            // between them would leak.)\n+            rt::start_task(new_task, closure);\n+            cast::forget(move child_wrapper);\n+        }\n+    }\n+\n+    // This function returns a closure-wrapper that we pass to the child task.\n+    // (1) It sets up the notification channel.\n+    // (2) It attempts to enlist in the child's group and all ancestor groups.\n+    // (3a) If any of those fails, it leaves all groups, and does nothing.\n+    // (3b) Otherwise it builds a task control structure and puts it in TLS,\n+    // (4) ...and runs the provided body function.\n+    fn make_child_wrapper(child: *rust_task, +child_arc: TaskGroupArc,\n+                          +ancestors: AncestorList, is_main: bool,\n+                          +notify_chan: Option<Chan<Notification>>,\n+                          +f: fn~()) -> fn~() {\n+        let child_data = ~mut Some((move child_arc, move ancestors));\n+        return fn~(move notify_chan, move child_data, move f) {\n+            // Agh. Get move-mode items into the closure. FIXME (#2829)\n+            let mut (child_arc, ancestors) = option::swap_unwrap(child_data);\n+            // Child task runs this code.\n+\n+            // Even if the below code fails to kick the child off, we must\n+            // send Something on the notify channel.\n+\n+            //let mut notifier = None;//notify_chan.map(|c| AutoNotify(c));\n+            let notifier = match notify_chan {\n+                Some(notify_chan_value) => {\n+                    let moved_ncv = move_it!(notify_chan_value);\n+                    Some(AutoNotify(move moved_ncv))\n+                }\n+                _ => None\n+            };\n+\n+            if enlist_many(child, &child_arc, &mut ancestors) {\n+                let group = @TCB(child, move child_arc, move ancestors,\n+                                 is_main, move notifier);\n+                unsafe {\n+                    local_set(child, taskgroup_key!(), group);\n+                }\n+\n+                // Run the child's body.\n+                f();\n+\n+                // TLS cleanup code will exit the taskgroup.\n+            }\n+\n+            // Run the box annihilator.\n+            // XXX: Crashy.\n+            // unsafe { cleanup::annihilate(); }\n+        };\n+\n+        // Set up membership in taskgroup and descendantship in all ancestor\n+        // groups. If any enlistment fails, Some task was already failing, so\n+        // don't let the child task run, and undo every successful enlistment.\n+        fn enlist_many(child: *rust_task, child_arc: &TaskGroupArc,\n+                       ancestors: &mut AncestorList) -> bool {\n+            // Join this taskgroup.\n+            let mut result =\n+                do access_group(child_arc) |child_tg| {\n+                    enlist_in_taskgroup(child_tg, child, true) // member\n+                };\n+            if result {\n+                // Unwinding function in case any ancestral enlisting fails\n+                let bail = |tg: TaskGroupInner| {\n+                    leave_taskgroup(tg, child, false)\n+                };\n+                // Attempt to join every ancestor group.\n+                result =\n+                    for each_ancestor(ancestors, Some(bail)) |ancestor_tg| {\n+                        // Enlist as a descendant, not as an actual member.\n+                        // Descendants don't kill ancestor groups on failure.\n+                        if !enlist_in_taskgroup(ancestor_tg, child, false) {\n+                            break;\n+                        }\n+                    };\n+                // If any ancestor group fails, need to exit this group too.\n+                if !result {\n+                    do access_group(child_arc) |child_tg| {\n+                        leave_taskgroup(child_tg, child, true); // member\n+                    }\n+                }\n+            }\n+            result\n+        }\n+    }\n+\n+    fn new_task_in_new_sched(opts: SchedOpts) -> *rust_task {\n+        if opts.foreign_stack_size != None {\n+            fail ~\"foreign_stack_size scheduler option unimplemented\";\n+        }\n+\n+        let num_threads = match opts.mode {\n+          SingleThreaded => 1u,\n+          ThreadPerCore => rt::rust_num_threads(),\n+          ThreadPerTask => {\n+            fail ~\"ThreadPerTask scheduling mode unimplemented\"\n+          }\n+          ManualThreads(threads) => {\n+            if threads == 0u {\n+                fail ~\"can not create a scheduler with no threads\";\n+            }\n+            threads\n+          }\n+          PlatformThread => 0u /* Won't be used */\n+        };\n+\n+        let sched_id = if opts.mode != PlatformThread {\n+            rt::rust_new_sched(num_threads)\n+        } else {\n+            rt::rust_osmain_sched_id()\n+        };\n+        rt::rust_new_task_in_sched(sched_id)\n+    }\n+}\n+\n+#[test]\n+fn test_spawn_raw_simple() {\n+    let po = comm::Port();\n+    let ch = comm::Chan(po);\n+    do spawn_raw(default_task_opts()) {\n+        comm::send(ch, ());\n+    }\n+    comm::recv(po);\n+}\n+\n+#[test]\n+#[ignore(cfg(windows))]\n+fn test_spawn_raw_unsupervise() {\n+    let opts = {\n+        linked: false,\n+        mut notify_chan: None,\n+        .. default_task_opts()\n+    };\n+    do spawn_raw(opts) {\n+        fail;\n+    }\n+}\n+\n+#[test]\n+#[ignore(cfg(windows))]\n+fn test_spawn_raw_notify_success() {\n+    let (task_ch, task_po) = pipes::stream();\n+    let (notify_ch, notify_po) = pipes::stream();\n+\n+    let opts = {\n+        notify_chan: Some(move notify_ch),\n+        .. default_task_opts()\n+    };\n+    do spawn_raw(opts) |move task_ch| {\n+        task_ch.send(get_task());\n+    }\n+    let task_ = task_po.recv();\n+    assert notify_po.recv() == Exit(task_, Success);\n+}\n+\n+#[test]\n+#[ignore(cfg(windows))]\n+fn test_spawn_raw_notify_failure() {\n+    // New bindings for these\n+    let (task_ch, task_po) = pipes::stream();\n+    let (notify_ch, notify_po) = pipes::stream();\n+\n+    let opts = {\n+        linked: false,\n+        notify_chan: Some(notify_ch),\n+        .. default_task_opts()\n+    };\n+    do spawn_raw(opts) {\n+        task_ch.send(get_task());\n+        fail;\n+    }\n+    let task_ = task_po.recv();\n+    assert notify_po.recv() == Exit(task_, Failure);\n+}"}]}