{"sha": "547a930835be262ebea5e499dba7555a8a47b992", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU0N2E5MzA4MzViZTI2MmViZWE1ZTQ5OWRiYTc1NTVhOGE0N2I5OTI=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-07-04T10:25:50Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-07-04T23:42:35Z"}, "message": "Revert \"Change `fold_tt` and `fold_tts` to take token trees by value (instead of by reference)\"\n\nThis reverts commit 5bf7970ac70b4e7781e7b2f3816720aa62fac6fd.", "tree": {"sha": "cb767c17cf669224da4461a41aff4aee07e647bf", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cb767c17cf669224da4461a41aff4aee07e647bf"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/547a930835be262ebea5e499dba7555a8a47b992", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/547a930835be262ebea5e499dba7555a8a47b992", "html_url": "https://github.com/rust-lang/rust/commit/547a930835be262ebea5e499dba7555a8a47b992", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/547a930835be262ebea5e499dba7555a8a47b992/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c2b56fb7a0c24e04227318ca7e5950e9289ee3e4", "url": "https://api.github.com/repos/rust-lang/rust/commits/c2b56fb7a0c24e04227318ca7e5950e9289ee3e4", "html_url": "https://github.com/rust-lang/rust/commit/c2b56fb7a0c24e04227318ca7e5950e9289ee3e4"}], "stats": {"total": 125, "additions": 72, "deletions": 53}, "files": [{"sha": "540ea0636cf73684112fc7e2392658b7a33c3a2d", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -237,7 +237,7 @@ fn expand_mac_invoc<T>(mac: ast::Mac, ident: Option<Ident>, attrs: Vec<ast::Attr\n                     },\n                 });\n \n-                let marked_tts = mark_tts(tts, mark);\n+                let marked_tts = mark_tts(&tts, mark);\n                 Some(expandfun.expand(fld.cx, call_site, &marked_tts))\n             }\n \n@@ -257,7 +257,7 @@ fn expand_mac_invoc<T>(mac: ast::Mac, ident: Option<Ident>, attrs: Vec<ast::Attr\n                     }\n                 });\n \n-                let marked_tts = mark_tts(tts, mark);\n+                let marked_tts = mark_tts(&tts, mark);\n                 Some(expander.expand(fld.cx, call_site, ident, marked_tts))\n             }\n \n@@ -1126,7 +1126,7 @@ impl Folder for Marker {\n         Spanned {\n             node: Mac_ {\n                 path: self.fold_path(node.path),\n-                tts: self.fold_tts(node.tts),\n+                tts: self.fold_tts(&node.tts),\n             },\n             span: self.new_span(span),\n         }\n@@ -1141,7 +1141,7 @@ impl Folder for Marker {\n }\n \n // apply a given mark to the given token trees. Used prior to expansion of a macro.\n-fn mark_tts(tts: Vec<TokenTree>, m: Mrk) -> Vec<TokenTree> {\n+fn mark_tts(tts: &[TokenTree], m: Mrk) -> Vec<TokenTree> {\n     noop_fold_tts(tts, &mut Marker{mark:m, expn_id: None})\n }\n "}, {"sha": "ffc950d76dd27f43047bb06e54def08e5f265266", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 11, "deletions": 5, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -32,6 +32,7 @@ pub mod rt {\n     use ext::base::ExtCtxt;\n     use parse::{self, token, classify};\n     use ptr::P;\n+    use std::rc::Rc;\n \n     use tokenstream::{self, TokenTree};\n \n@@ -215,12 +216,12 @@ pub mod rt {\n             if self.node.style == ast::AttrStyle::Inner {\n                 r.push(TokenTree::Token(self.span, token::Not));\n             }\n-            r.push(TokenTree::Delimited(self.span, tokenstream::Delimited {\n+            r.push(TokenTree::Delimited(self.span, Rc::new(tokenstream::Delimited {\n                 delim: token::Bracket,\n                 open_span: self.span,\n                 tts: self.node.value.to_tokens(cx),\n                 close_span: self.span,\n-            }));\n+            })));\n             r\n         }\n     }\n@@ -235,12 +236,12 @@ pub mod rt {\n \n     impl ToTokens for () {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Delimited(DUMMY_SP, tokenstream::Delimited {\n+            vec![TokenTree::Delimited(DUMMY_SP, Rc::new(tokenstream::Delimited {\n                 delim: token::Paren,\n                 open_span: DUMMY_SP,\n                 tts: vec![],\n                 close_span: DUMMY_SP,\n-            })]\n+            }))]\n         }\n     }\n \n@@ -791,9 +792,14 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, matcher: bool) -> Vec<ast::Stm\n                                 id_ext(\"tokenstream\"),\n                                 id_ext(\"SequenceRepetition\")];\n             let e_seq_struct = cx.expr_struct(sp, cx.path_global(sp, seq_path), fields);\n+            let e_rc_new = cx.expr_call_global(sp, vec![id_ext(\"std\"),\n+                                                        id_ext(\"rc\"),\n+                                                        id_ext(\"Rc\"),\n+                                                        id_ext(\"new\")],\n+                                                   vec![e_seq_struct]);\n             let e_tok = cx.expr_call(sp,\n                                      mk_tt_path(cx, sp, \"Sequence\"),\n-                                     vec!(e_sp, e_seq_struct));\n+                                     vec!(e_sp, e_rc_new));\n             let e_push =\n                 cx.expr_method_call(sp,\n                                     cx.expr_ident(sp, id_ext(\"tt\")),"}, {"sha": "84572b84963f3812511a2efdb4c8622d875a4297", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -28,6 +28,7 @@ use util::small_vector::SmallVector;\n use std::cell::RefCell;\n use std::collections::{HashMap};\n use std::collections::hash_map::{Entry};\n+use std::rc::Rc;\n \n struct ParserAnyMacro<'a> {\n     parser: RefCell<Parser<'a>>,\n@@ -262,7 +263,7 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n     let match_lhs_tok = MatchNt(lhs_nm, token::str_to_ident(\"tt\"));\n     let match_rhs_tok = MatchNt(rhs_nm, token::str_to_ident(\"tt\"));\n     let argument_gram = vec![\n-        TokenTree::Sequence(DUMMY_SP, tokenstream::SequenceRepetition {\n+        TokenTree::Sequence(DUMMY_SP, Rc::new(tokenstream::SequenceRepetition {\n             tts: vec![\n                 TokenTree::Token(DUMMY_SP, match_lhs_tok),\n                 TokenTree::Token(DUMMY_SP, token::FatArrow),\n@@ -271,14 +272,14 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n             separator: Some(token::Semi),\n             op: tokenstream::KleeneOp::OneOrMore,\n             num_captures: 2,\n-        }),\n+        })),\n         // to phase into semicolon-termination instead of semicolon-separation\n-        TokenTree::Sequence(DUMMY_SP, tokenstream::SequenceRepetition {\n+        TokenTree::Sequence(DUMMY_SP, Rc::new(tokenstream::SequenceRepetition {\n             tts: vec![TokenTree::Token(DUMMY_SP, token::Semi)],\n             separator: None,\n             op: tokenstream::KleeneOp::ZeroOrMore,\n             num_captures: 0\n-        }),\n+        })),\n     ];\n \n     // Parse the macro_rules! invocation (`none` is for no interpolations):"}, {"sha": "9c493948d604ca02cd3ef48f9e66d094e99ea8eb", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -79,11 +79,11 @@ pub fn new_tt_reader_with_doc_flag(sp_diag: &Handler,\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n         stack: vec!(TtFrame {\n-            forest: TokenTree::Sequence(DUMMY_SP, tokenstream::SequenceRepetition {\n+            forest: TokenTree::Sequence(DUMMY_SP, Rc::new(tokenstream::SequenceRepetition {\n                 tts: src,\n                 // doesn't matter. This merely holds the root unzipping.\n                 separator: None, op: tokenstream::KleeneOp::ZeroOrMore, num_captures: 0\n-            }),\n+            })),\n             idx: 0,\n             dotdotdoted: false,\n             sep: None,"}, {"sha": "ac3d643b185cac725fd7139d14ae4541970a3be6", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 27, "deletions": 19, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -28,6 +28,8 @@ use tokenstream::*;\n use util::small_vector::SmallVector;\n use util::move_map::MoveMap;\n \n+use std::rc::Rc;\n+\n pub trait Folder : Sized {\n     // Any additions to this trait should happen in form\n     // of a call to a public `noop_*` function that only calls\n@@ -222,11 +224,11 @@ pub trait Folder : Sized {\n         noop_fold_ty_params(tps, self)\n     }\n \n-    fn fold_tt(&mut self, tt: TokenTree) -> TokenTree {\n+    fn fold_tt(&mut self, tt: &TokenTree) -> TokenTree {\n         noop_fold_tt(tt, self)\n     }\n \n-    fn fold_tts(&mut self, tts: Vec<TokenTree>) -> Vec<TokenTree> {\n+    fn fold_tts(&mut self, tts: &[TokenTree]) -> Vec<TokenTree> {\n         noop_fold_tts(tts, self)\n     }\n \n@@ -501,7 +503,7 @@ pub fn noop_fold_mac<T: Folder>(Spanned {node, span}: Mac, fld: &mut T) -> Mac {\n     Spanned {\n         node: Mac_ {\n             path: fld.fold_path(node.path),\n-            tts: fld.fold_tts(node.tts),\n+            tts: fld.fold_tts(&node.tts),\n         },\n         span: fld.new_span(span)\n     }\n@@ -528,26 +530,32 @@ pub fn noop_fold_arg<T: Folder>(Arg {id, pat, ty}: Arg, fld: &mut T) -> Arg {\n     }\n }\n \n-pub fn noop_fold_tt<T: Folder>(tt: TokenTree, fld: &mut T) -> TokenTree {\n-    match tt {\n+pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n+    match *tt {\n         TokenTree::Token(span, ref tok) =>\n             TokenTree::Token(span, fld.fold_token(tok.clone())),\n-        TokenTree::Delimited(span, delimed) => TokenTree::Delimited(span, Delimited {\n-            delim: delimed.delim,\n-            open_span: delimed.open_span,\n-            tts: fld.fold_tts(delimed.tts),\n-            close_span: delimed.close_span,\n-        }),\n-        TokenTree::Sequence(span, seq) => TokenTree::Sequence(span, SequenceRepetition {\n-            tts: fld.fold_tts(seq.tts),\n-            separator: seq.separator.clone().map(|tok| fld.fold_token(tok)),\n-            ..seq\n-        }),\n+        TokenTree::Delimited(span, ref delimed) => {\n+            TokenTree::Delimited(span, Rc::new(\n+                            Delimited {\n+                                delim: delimed.delim,\n+                                open_span: delimed.open_span,\n+                                tts: fld.fold_tts(&delimed.tts),\n+                                close_span: delimed.close_span,\n+                            }\n+                        ))\n+        },\n+        TokenTree::Sequence(span, ref seq) =>\n+            TokenTree::Sequence(span,\n+                       Rc::new(SequenceRepetition {\n+                           tts: fld.fold_tts(&seq.tts),\n+                           separator: seq.separator.clone().map(|tok| fld.fold_token(tok)),\n+                           ..**seq\n+                       })),\n     }\n }\n \n-pub fn noop_fold_tts<T: Folder>(tts: Vec<TokenTree>, fld: &mut T) -> Vec<TokenTree> {\n-    tts.move_map(|tt| fld.fold_tt(tt))\n+pub fn noop_fold_tts<T: Folder>(tts: &[TokenTree], fld: &mut T) -> Vec<TokenTree> {\n+    tts.iter().map(|tt| fld.fold_tt(tt)).collect()\n }\n \n // apply ident folder if it's an ident, apply other folds to interpolated nodes\n@@ -605,7 +613,7 @@ pub fn noop_fold_interpolated<T: Folder>(nt: token::Nonterminal, fld: &mut T)\n             token::NtIdent(Box::new(Spanned::<Ident>{node: fld.fold_ident(id.node), ..*id})),\n         token::NtMeta(meta_item) => token::NtMeta(fld.fold_meta_item(meta_item)),\n         token::NtPath(path) => token::NtPath(Box::new(fld.fold_path(*path))),\n-        token::NtTT(tt) => token::NtTT(tt.map(|tt| fld.fold_tt(tt))),\n+        token::NtTT(tt) => token::NtTT(P(fld.fold_tt(&tt))),\n         token::NtArm(arm) => token::NtArm(fld.fold_arm(arm)),\n         token::NtImplItem(arm) =>\n             token::NtImplItem(arm.map(|arm| fld.fold_impl_item(arm)"}, {"sha": "9502bc48a3e110f84e0ddf107a3a3181ec92c06d", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -662,6 +662,7 @@ pub fn integer_lit(s: &str,\n #[cfg(test)]\n mod tests {\n     use super::*;\n+    use std::rc::Rc;\n     use syntax_pos::{Span, BytePos, Pos, NO_EXPANSION};\n     use codemap::Spanned;\n     use ast::{self, PatKind};\n@@ -763,7 +764,7 @@ mod tests {\n                             )\n                             if first_delimed.delim == token::Paren\n                             && ident.name.as_str() == \"a\" => {},\n-                            _ => panic!(\"value 3: {:?}\", *first_delimed),\n+                            _ => panic!(\"value 3: {:?}\", **first_delimed),\n                         }\n                         let tts = &second_delimed.tts[..];\n                         match (tts.len(), tts.get(0), tts.get(1)) {\n@@ -774,10 +775,10 @@ mod tests {\n                             )\n                             if second_delimed.delim == token::Paren\n                             && ident.name.as_str() == \"a\" => {},\n-                            _ => panic!(\"value 4: {:?}\", *second_delimed),\n+                            _ => panic!(\"value 4: {:?}\", **second_delimed),\n                         }\n                     },\n-                    _ => panic!(\"value 2: {:?}\", *macro_delimed),\n+                    _ => panic!(\"value 2: {:?}\", **macro_delimed),\n                 }\n             },\n             _ => panic!(\"value: {:?}\",tts),\n@@ -793,7 +794,7 @@ mod tests {\n             TokenTree::Token(sp(3, 4), token::Ident(str_to_ident(\"a\"))),\n             TokenTree::Delimited(\n                 sp(5, 14),\n-                tokenstream::Delimited {\n+                Rc::new(tokenstream::Delimited {\n                     delim: token::DelimToken::Paren,\n                     open_span: sp(5, 6),\n                     tts: vec![\n@@ -802,18 +803,18 @@ mod tests {\n                         TokenTree::Token(sp(10, 13), token::Ident(str_to_ident(\"i32\"))),\n                     ],\n                     close_span: sp(13, 14),\n-                }),\n+                })),\n             TokenTree::Delimited(\n                 sp(15, 21),\n-                tokenstream::Delimited {\n+                Rc::new(tokenstream::Delimited {\n                     delim: token::DelimToken::Brace,\n                     open_span: sp(15, 16),\n                     tts: vec![\n                         TokenTree::Token(sp(17, 18), token::Ident(str_to_ident(\"b\"))),\n                         TokenTree::Token(sp(18, 19), token::Semi),\n                     ],\n                     close_span: sp(20, 21),\n-                })\n+                }))\n         ];\n \n         assert_eq!(tts, expected);"}, {"sha": "4d4114bfe30ae6c2ea967765d26504101ec987b3", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -2688,12 +2688,13 @@ impl<'a> Parser<'a> {\n                     )?;\n                     let (sep, repeat) = self.parse_sep_and_kleene_op()?;\n                     let name_num = macro_parser::count_names(&seq);\n-                    return Ok(TokenTree::Sequence(mk_sp(sp.lo, seq_span.hi), SequenceRepetition {\n-                        tts: seq,\n-                        separator: sep,\n-                        op: repeat,\n-                        num_captures: name_num\n-                    }));\n+                    return Ok(TokenTree::Sequence(mk_sp(sp.lo, seq_span.hi),\n+                                      Rc::new(SequenceRepetition {\n+                                          tts: seq,\n+                                          separator: sep,\n+                                          op: repeat,\n+                                          num_captures: name_num\n+                                      })));\n                 } else if self.token.is_keyword(keywords::Crate) {\n                     self.bump();\n                     return Ok(TokenTree::Token(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar)));\n@@ -2849,12 +2850,12 @@ impl<'a> Parser<'a> {\n                     _ => {}\n                 }\n \n-                Ok(TokenTree::Delimited(span, Delimited {\n+                Ok(TokenTree::Delimited(span, Rc::new(Delimited {\n                     delim: delim,\n                     open_span: open_span,\n                     tts: tts,\n                     close_span: close_span,\n-                }))\n+                })))\n             },\n             _ => {\n                 // invariants: the current token is not a left-delimiter,"}, {"sha": "f0f0a7bc580d3b6883f8fabc91d00cf40810aeff", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/547a930835be262ebea5e499dba7555a8a47b992/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=547a930835be262ebea5e499dba7555a8a47b992", "patch": "@@ -21,6 +21,8 @@ use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use parse::lexer;\n use parse::token;\n \n+use std::rc::Rc;\n+\n /// A delimited sequence of token trees\n #[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n pub struct Delimited {\n@@ -94,13 +96,13 @@ pub enum TokenTree {\n     /// A single token\n     Token(Span, token::Token),\n     /// A delimited sequence of token trees\n-    Delimited(Span, Delimited),\n+    Delimited(Span, Rc<Delimited>),\n \n     // This only makes sense in MBE macros.\n \n     /// A kleene-style repetition sequence with a span\n     // FIXME(eddyb) #12938 Use DST.\n-    Sequence(Span, SequenceRepetition),\n+    Sequence(Span, Rc<SequenceRepetition>),\n }\n \n impl TokenTree {\n@@ -149,15 +151,15 @@ impl TokenTree {\n                     Some(*cnt)\n                 }).max().unwrap_or(0);\n \n-                TokenTree::Delimited(sp, Delimited {\n+                TokenTree::Delimited(sp, Rc::new(Delimited {\n                     delim: token::Bracket,\n                     open_span: sp,\n                     tts: vec![TokenTree::Token(sp, token::Ident(token::str_to_ident(\"doc\"))),\n                               TokenTree::Token(sp, token::Eq),\n                               TokenTree::Token(sp, token::Literal(\n                                   token::StrRaw(token::intern(&stripped), num_of_hashes), None))],\n                     close_span: sp,\n-                })\n+                }))\n             }\n             (&TokenTree::Delimited(_, ref delimed), _) => {\n                 if index == 0 {"}]}