{"sha": "e329b7742b343413ad248973c3764061d363b76e", "node_id": "C_kwDOAAsO6NoAKGUzMjliNzc0MmIzNDM0MTNhZDI0ODk3M2MzNzY0MDYxZDM2M2I3NmU", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-10-17T09:15:56Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-10-17T09:15:56Z"}, "message": "Reorder CompletionContext functions", "tree": {"sha": "24b3557e7f91d705d546702a9c7296b75b62c18e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/24b3557e7f91d705d546702a9c7296b75b62c18e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e329b7742b343413ad248973c3764061d363b76e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e329b7742b343413ad248973c3764061d363b76e", "html_url": "https://github.com/rust-lang/rust/commit/e329b7742b343413ad248973c3764061d363b76e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e329b7742b343413ad248973c3764061d363b76e/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "791a2afbf957332234008fcc2286fa876a480f61", "url": "https://api.github.com/repos/rust-lang/rust/commits/791a2afbf957332234008fcc2286fa876a480f61", "html_url": "https://github.com/rust-lang/rust/commit/791a2afbf957332234008fcc2286fa876a480f61"}], "stats": {"total": 576, "additions": 290, "deletions": 286}, "files": [{"sha": "4e3abff3b3f86223dd54278b9217c9286aedd9fa", "filename": "crates/ide_completion/src/context.rs", "status": "modified", "additions": 290, "deletions": 286, "changes": 576, "blob_url": "https://github.com/rust-lang/rust/blob/e329b7742b343413ad248973c3764061d363b76e/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e329b7742b343413ad248973c3764061d363b76e/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcontext.rs?ref=e329b7742b343413ad248973c3764061d363b76e", "patch": "@@ -120,153 +120,6 @@ pub(crate) struct CompletionContext<'a> {\n }\n \n impl<'a> CompletionContext<'a> {\n-    pub(super) fn new(\n-        db: &'a RootDatabase,\n-        position: FilePosition,\n-        config: &'a CompletionConfig,\n-    ) -> Option<CompletionContext<'a>> {\n-        let sema = Semantics::new(db);\n-\n-        let original_file = sema.parse(position.file_id);\n-\n-        // Insert a fake ident to get a valid parse tree. We will use this file\n-        // to determine context, though the original_file will be used for\n-        // actual completion.\n-        let file_with_fake_ident = {\n-            let parse = db.parse(position.file_id);\n-            let edit = Indel::insert(position.offset, \"intellijRulezz\".to_string());\n-            parse.reparse(&edit).tree()\n-        };\n-        let fake_ident_token =\n-            file_with_fake_ident.syntax().token_at_offset(position.offset).right_biased().unwrap();\n-\n-        let original_token =\n-            original_file.syntax().token_at_offset(position.offset).left_biased()?;\n-        let token = sema.descend_into_macros_single(original_token.clone());\n-        let scope = sema.scope_at_offset(&token, position.offset);\n-        let krate = scope.krate();\n-        let mut locals = vec![];\n-        scope.process_all_names(&mut |name, scope| {\n-            if let ScopeDef::Local(local) = scope {\n-                locals.push((name, local));\n-            }\n-        });\n-        let mut ctx = CompletionContext {\n-            sema,\n-            scope,\n-            db,\n-            config,\n-            position,\n-            original_token,\n-            token,\n-            krate,\n-            expected_name: None,\n-            expected_type: None,\n-            function_def: None,\n-            impl_def: None,\n-            name_syntax: None,\n-            lifetime_ctx: None,\n-            pattern_ctx: None,\n-            completion_location: None,\n-            prev_sibling: None,\n-            attribute_under_caret: None,\n-            previous_token: None,\n-            path_context: None,\n-            locals,\n-            incomplete_let: false,\n-            no_completion_required: false,\n-        };\n-        ctx.expand_and_fill(\n-            original_file.syntax().clone(),\n-            file_with_fake_ident.syntax().clone(),\n-            position.offset,\n-            fake_ident_token,\n-        );\n-        Some(ctx)\n-    }\n-\n-    /// Do the attribute expansion at the current cursor position for both original file and fake file\n-    /// as long as possible. As soon as one of the two expansions fail we stop to stay in sync.\n-    fn expand_and_fill(\n-        &mut self,\n-        mut original_file: SyntaxNode,\n-        mut speculative_file: SyntaxNode,\n-        mut offset: TextSize,\n-        mut fake_ident_token: SyntaxToken,\n-    ) {\n-        loop {\n-            // Expand attributes\n-            if let (Some(actual_item), Some(item_with_fake_ident)) = (\n-                find_node_at_offset::<ast::Item>(&original_file, offset),\n-                find_node_at_offset::<ast::Item>(&speculative_file, offset),\n-            ) {\n-                match (\n-                    self.sema.expand_attr_macro(&actual_item),\n-                    self.sema.speculative_expand_attr_macro(\n-                        &actual_item,\n-                        &item_with_fake_ident,\n-                        fake_ident_token.clone(),\n-                    ),\n-                ) {\n-                    (Some(actual_expansion), Some(speculative_expansion)) => {\n-                        let new_offset = speculative_expansion.1.text_range().start();\n-                        if new_offset > actual_expansion.text_range().end() {\n-                            break;\n-                        }\n-                        original_file = actual_expansion;\n-                        speculative_file = speculative_expansion.0;\n-                        fake_ident_token = speculative_expansion.1;\n-                        offset = new_offset;\n-                        continue;\n-                    }\n-                    (None, None) => (),\n-                    _ => break,\n-                }\n-            }\n-\n-            // Expand fn-like macro calls\n-            if let (Some(actual_macro_call), Some(macro_call_with_fake_ident)) = (\n-                find_node_at_offset::<ast::MacroCall>(&original_file, offset),\n-                find_node_at_offset::<ast::MacroCall>(&speculative_file, offset),\n-            ) {\n-                let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n-                let mac_call_path1 =\n-                    macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n-                if mac_call_path0 != mac_call_path1 {\n-                    break;\n-                }\n-                let speculative_args = match macro_call_with_fake_ident.token_tree() {\n-                    Some(tt) => tt,\n-                    None => break,\n-                };\n-\n-                if let (Some(actual_expansion), Some(speculative_expansion)) = (\n-                    self.sema.expand(&actual_macro_call),\n-                    self.sema.speculative_expand(\n-                        &actual_macro_call,\n-                        &speculative_args,\n-                        fake_ident_token,\n-                    ),\n-                ) {\n-                    let new_offset = speculative_expansion.1.text_range().start();\n-                    if new_offset > actual_expansion.text_range().end() {\n-                        break;\n-                    }\n-                    original_file = actual_expansion;\n-                    speculative_file = speculative_expansion.0;\n-                    fake_ident_token = speculative_expansion.1;\n-                    offset = new_offset;\n-                } else {\n-                    break;\n-                }\n-            } else {\n-                break;\n-            }\n-        }\n-\n-        self.fill(&original_file, speculative_file, offset);\n-    }\n-\n     /// Checks whether completions in that particular case don't make much sense.\n     /// Examples:\n     /// - `fn $0` -- we expect function name, it's unlikely that \"hint\" will be helpful.\n@@ -491,6 +344,156 @@ impl<'a> CompletionContext<'a> {\n \n         false\n     }\n+}\n+\n+// CompletionContext construction\n+impl<'a> CompletionContext<'a> {\n+    pub(super) fn new(\n+        db: &'a RootDatabase,\n+        position: FilePosition,\n+        config: &'a CompletionConfig,\n+    ) -> Option<CompletionContext<'a>> {\n+        let sema = Semantics::new(db);\n+\n+        let original_file = sema.parse(position.file_id);\n+\n+        // Insert a fake ident to get a valid parse tree. We will use this file\n+        // to determine context, though the original_file will be used for\n+        // actual completion.\n+        let file_with_fake_ident = {\n+            let parse = db.parse(position.file_id);\n+            let edit = Indel::insert(position.offset, \"intellijRulezz\".to_string());\n+            parse.reparse(&edit).tree()\n+        };\n+        let fake_ident_token =\n+            file_with_fake_ident.syntax().token_at_offset(position.offset).right_biased().unwrap();\n+\n+        let original_token =\n+            original_file.syntax().token_at_offset(position.offset).left_biased()?;\n+        let token = sema.descend_into_macros_single(original_token.clone());\n+        let scope = sema.scope_at_offset(&token, position.offset);\n+        let krate = scope.krate();\n+        let mut locals = vec![];\n+        scope.process_all_names(&mut |name, scope| {\n+            if let ScopeDef::Local(local) = scope {\n+                locals.push((name, local));\n+            }\n+        });\n+        let mut ctx = CompletionContext {\n+            sema,\n+            scope,\n+            db,\n+            config,\n+            position,\n+            original_token,\n+            token,\n+            krate,\n+            expected_name: None,\n+            expected_type: None,\n+            function_def: None,\n+            impl_def: None,\n+            name_syntax: None,\n+            lifetime_ctx: None,\n+            pattern_ctx: None,\n+            completion_location: None,\n+            prev_sibling: None,\n+            attribute_under_caret: None,\n+            previous_token: None,\n+            path_context: None,\n+            locals,\n+            incomplete_let: false,\n+            no_completion_required: false,\n+        };\n+        ctx.expand_and_fill(\n+            original_file.syntax().clone(),\n+            file_with_fake_ident.syntax().clone(),\n+            position.offset,\n+            fake_ident_token,\n+        );\n+        Some(ctx)\n+    }\n+\n+    /// Do the attribute expansion at the current cursor position for both original file and fake file\n+    /// as long as possible. As soon as one of the two expansions fail we stop to stay in sync.\n+    fn expand_and_fill(\n+        &mut self,\n+        mut original_file: SyntaxNode,\n+        mut speculative_file: SyntaxNode,\n+        mut offset: TextSize,\n+        mut fake_ident_token: SyntaxToken,\n+    ) {\n+        loop {\n+            // Expand attributes\n+            if let (Some(actual_item), Some(item_with_fake_ident)) = (\n+                find_node_at_offset::<ast::Item>(&original_file, offset),\n+                find_node_at_offset::<ast::Item>(&speculative_file, offset),\n+            ) {\n+                match (\n+                    self.sema.expand_attr_macro(&actual_item),\n+                    self.sema.speculative_expand_attr_macro(\n+                        &actual_item,\n+                        &item_with_fake_ident,\n+                        fake_ident_token.clone(),\n+                    ),\n+                ) {\n+                    (Some(actual_expansion), Some(speculative_expansion)) => {\n+                        let new_offset = speculative_expansion.1.text_range().start();\n+                        if new_offset > actual_expansion.text_range().end() {\n+                            break;\n+                        }\n+                        original_file = actual_expansion;\n+                        speculative_file = speculative_expansion.0;\n+                        fake_ident_token = speculative_expansion.1;\n+                        offset = new_offset;\n+                        continue;\n+                    }\n+                    (None, None) => (),\n+                    _ => break,\n+                }\n+            }\n+\n+            // Expand fn-like macro calls\n+            if let (Some(actual_macro_call), Some(macro_call_with_fake_ident)) = (\n+                find_node_at_offset::<ast::MacroCall>(&original_file, offset),\n+                find_node_at_offset::<ast::MacroCall>(&speculative_file, offset),\n+            ) {\n+                let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n+                let mac_call_path1 =\n+                    macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n+                if mac_call_path0 != mac_call_path1 {\n+                    break;\n+                }\n+                let speculative_args = match macro_call_with_fake_ident.token_tree() {\n+                    Some(tt) => tt,\n+                    None => break,\n+                };\n+\n+                if let (Some(actual_expansion), Some(speculative_expansion)) = (\n+                    self.sema.expand(&actual_macro_call),\n+                    self.sema.speculative_expand(\n+                        &actual_macro_call,\n+                        &speculative_args,\n+                        fake_ident_token,\n+                    ),\n+                ) {\n+                    let new_offset = speculative_expansion.1.text_range().start();\n+                    if new_offset > actual_expansion.text_range().end() {\n+                        break;\n+                    }\n+                    original_file = actual_expansion;\n+                    speculative_file = speculative_expansion.0;\n+                    fake_ident_token = speculative_expansion.1;\n+                    offset = new_offset;\n+                } else {\n+                    break;\n+                }\n+            } else {\n+                break;\n+            }\n+        }\n+\n+        self.fill(&original_file, speculative_file, offset);\n+    }\n \n     fn expected_type_and_name(&self) -> (Option<Type>, Option<NameOrNameRef>) {\n         let mut node = match self.token.parent() {\n@@ -658,170 +661,171 @@ impl<'a> CompletionContext<'a> {\n             .find_map(ast::Fn::cast);\n         match name_like {\n             ast::NameLike::Lifetime(lifetime) => {\n-                self.classify_lifetime(original_file, lifetime, offset);\n+                self.lifetime_ctx =\n+                    Self::classify_lifetime(&self.sema, original_file, lifetime, offset);\n             }\n             ast::NameLike::NameRef(name_ref) => {\n-                self.classify_name_ref(original_file, name_ref);\n+                self.path_context = Self::classify_name_ref(&self.sema, original_file, name_ref);\n             }\n             ast::NameLike::Name(name) => {\n-                self.classify_name(name);\n+                self.pattern_ctx = Self::classify_name(&self.sema, name);\n             }\n         }\n     }\n \n     fn classify_lifetime(\n-        &mut self,\n+        sema: &Semantics<RootDatabase>,\n         original_file: &SyntaxNode,\n         lifetime: ast::Lifetime,\n         offset: TextSize,\n-    ) {\n-        if let Some(parent) = lifetime.syntax().parent() {\n-            if parent.kind() == ERROR {\n-                return;\n+    ) -> Option<LifetimeContext> {\n+        let parent = lifetime.syntax().parent()?;\n+        if parent.kind() == ERROR {\n+            return None;\n+        }\n+\n+        Some(match_ast! {\n+            match parent {\n+                ast::LifetimeParam(_it) => LifetimeContext::LifetimeParam(sema.find_node_at_offset_with_macros(original_file, offset)),\n+                ast::BreakExpr(_it) => LifetimeContext::LabelRef,\n+                ast::ContinueExpr(_it) => LifetimeContext::LabelRef,\n+                ast::Label(_it) => LifetimeContext::LabelDef,\n+                _ => LifetimeContext::Lifetime,\n             }\n+        })\n+    }\n \n-            self.lifetime_ctx = Some(match_ast! {\n-                match parent {\n-                    ast::LifetimeParam(_it) => LifetimeContext::LifetimeParam(self.sema.find_node_at_offset_with_macros(original_file, offset)),\n-                    ast::BreakExpr(_it) => LifetimeContext::LabelRef,\n-                    ast::ContinueExpr(_it) => LifetimeContext::LabelRef,\n-                    ast::Label(_it) => LifetimeContext::LabelDef,\n-                    _ => LifetimeContext::Lifetime,\n+    fn classify_name(_sema: &Semantics<RootDatabase>, name: ast::Name) -> Option<PatternContext> {\n+        let bind_pat = name.syntax().parent().and_then(ast::IdentPat::cast)?;\n+        let is_name_in_field_pat = bind_pat\n+            .syntax()\n+            .parent()\n+            .and_then(ast::RecordPatField::cast)\n+            .map_or(false, |pat_field| pat_field.name_ref().is_none());\n+        if is_name_in_field_pat {\n+            return None;\n+        }\n+        if !bind_pat.is_simple_ident() {\n+            return None;\n+        }\n+        let mut is_param = None;\n+        let refutability = bind_pat\n+            .syntax()\n+            .ancestors()\n+            .skip_while(|it| ast::Pat::can_cast(it.kind()))\n+            .next()\n+            .map_or(PatternRefutability::Irrefutable, |node| {\n+                match_ast! {\n+                    match node {\n+                        ast::LetStmt(__) => PatternRefutability::Irrefutable,\n+                        ast::Param(param) => {\n+                            let is_closure_param = param\n+                                .syntax()\n+                                .ancestors()\n+                                .nth(2)\n+                                .and_then(ast::ClosureExpr::cast)\n+                                .is_some();\n+                            is_param = Some(if is_closure_param {\n+                                ParamKind::Closure\n+                            } else {\n+                                ParamKind::Function\n+                            });\n+                            PatternRefutability::Irrefutable\n+                        },\n+                        ast::MatchArm(__) => PatternRefutability::Refutable,\n+                        ast::Condition(__) => PatternRefutability::Refutable,\n+                        ast::ForExpr(__) => PatternRefutability::Irrefutable,\n+                        _ => PatternRefutability::Irrefutable,\n+                    }\n                 }\n             });\n-        }\n+        Some(PatternContext { refutability, is_param })\n     }\n \n-    fn classify_name(&mut self, name: ast::Name) {\n-        if let Some(bind_pat) = name.syntax().parent().and_then(ast::IdentPat::cast) {\n-            let is_name_in_field_pat = bind_pat\n-                .syntax()\n-                .parent()\n-                .and_then(ast::RecordPatField::cast)\n-                .map_or(false, |pat_field| pat_field.name_ref().is_none());\n-            if is_name_in_field_pat {\n-                return;\n-            }\n-            if bind_pat.is_simple_ident() {\n-                let mut is_param = None;\n-                let refutability = bind_pat\n-                    .syntax()\n-                    .ancestors()\n-                    .skip_while(|it| ast::Pat::can_cast(it.kind()))\n-                    .next()\n-                    .map_or(PatternRefutability::Irrefutable, |node| {\n-                        match_ast! {\n-                            match node {\n-                                ast::LetStmt(__) => PatternRefutability::Irrefutable,\n-                                ast::Param(param) => {\n-                                    let is_closure_param = param\n-                                        .syntax()\n-                                        .ancestors()\n-                                        .nth(2)\n-                                        .and_then(ast::ClosureExpr::cast)\n-                                        .is_some();\n-                                    is_param = Some(if is_closure_param {\n-                                        ParamKind::Closure\n-                                    } else {\n-                                        ParamKind::Function\n-                                    });\n-                                    PatternRefutability::Irrefutable\n-                                },\n-                                ast::MatchArm(__) => PatternRefutability::Refutable,\n-                                ast::Condition(__) => PatternRefutability::Refutable,\n-                                ast::ForExpr(__) => PatternRefutability::Irrefutable,\n-                                _ => PatternRefutability::Irrefutable,\n-                            }\n-                        }\n-                    });\n-                self.pattern_ctx = Some(PatternContext { refutability, is_param });\n-            }\n+    fn classify_name_ref(\n+        _sema: &Semantics<RootDatabase>,\n+        original_file: &SyntaxNode,\n+        name_ref: ast::NameRef,\n+    ) -> Option<PathCompletionContext> {\n+        let parent = name_ref.syntax().parent()?;\n+        let segment = ast::PathSegment::cast(parent)?;\n+\n+        let mut path_ctx = PathCompletionContext {\n+            call_kind: None,\n+            is_trivial_path: false,\n+            qualifier: None,\n+            has_type_args: false,\n+            can_be_stmt: false,\n+            in_loop_body: false,\n+            use_tree_parent: false,\n+            kind: None,\n+        };\n+        path_ctx.in_loop_body = is_in_loop_body(name_ref.syntax());\n+        let path = segment.parent_path();\n+\n+        if let Some(p) = path.syntax().parent() {\n+            path_ctx.call_kind = match_ast! {\n+                match p {\n+                    ast::PathExpr(it) => it.syntax().parent().and_then(ast::CallExpr::cast).map(|_| CallKind::Expr),\n+                    ast::MacroCall(it) => it.excl_token().and(Some(CallKind::Mac)),\n+                    ast::TupleStructPat(_it) => Some(CallKind::Pat),\n+                    _ => None\n+                }\n+            };\n         }\n-    }\n \n-    fn classify_name_ref(&mut self, original_file: &SyntaxNode, name_ref: ast::NameRef) {\n-        let parent = match name_ref.syntax().parent() {\n-            Some(it) => it,\n-            None => return,\n-        };\n+        if let Some(parent) = path.syntax().parent() {\n+            path_ctx.kind = match_ast! {\n+                match parent {\n+                    ast::PathType(_it) => Some(PathKind::Type),\n+                    ast::PathExpr(_it) => Some(PathKind::Expr),\n+                    _ => None,\n+                }\n+            };\n+        }\n+        path_ctx.has_type_args = segment.generic_arg_list().is_some();\n+\n+        if let Some((path, use_tree_parent)) = path_or_use_tree_qualifier(&path) {\n+            path_ctx.use_tree_parent = use_tree_parent;\n+            path_ctx.qualifier = path\n+                .segment()\n+                .and_then(|it| {\n+                    find_node_with_range::<ast::PathSegment>(\n+                        original_file,\n+                        it.syntax().text_range(),\n+                    )\n+                })\n+                .map(|it| it.parent_path());\n+            return Some(path_ctx);\n+        }\n \n-        if let Some(segment) = ast::PathSegment::cast(parent) {\n-            let path_ctx = self.path_context.get_or_insert(PathCompletionContext {\n-                call_kind: None,\n-                is_trivial_path: false,\n-                qualifier: None,\n-                has_type_args: false,\n-                can_be_stmt: false,\n-                in_loop_body: false,\n-                use_tree_parent: false,\n-                kind: None,\n-            });\n-            path_ctx.in_loop_body = is_in_loop_body(name_ref.syntax());\n-            let path = segment.parent_path();\n-\n-            if let Some(p) = path.syntax().parent() {\n-                path_ctx.call_kind = match_ast! {\n-                    match p {\n-                        ast::PathExpr(it) => it.syntax().parent().and_then(ast::CallExpr::cast).map(|_| CallKind::Expr),\n-                        ast::MacroCall(it) => it.excl_token().and(Some(CallKind::Mac)),\n-                        ast::TupleStructPat(_it) => Some(CallKind::Pat),\n-                        _ => None\n-                    }\n-                };\n+        if let Some(segment) = path.segment() {\n+            if segment.coloncolon_token().is_some() {\n+                return Some(path_ctx);\n             }\n+        }\n \n-            if let Some(parent) = path.syntax().parent() {\n-                path_ctx.kind = match_ast! {\n-                    match parent {\n-                        ast::PathType(_it) => Some(PathKind::Type),\n-                        ast::PathExpr(_it) => Some(PathKind::Expr),\n-                        _ => None,\n-                    }\n-                };\n-            }\n-            path_ctx.has_type_args = segment.generic_arg_list().is_some();\n-\n-            if let Some((path, use_tree_parent)) = path_or_use_tree_qualifier(&path) {\n-                path_ctx.use_tree_parent = use_tree_parent;\n-                path_ctx.qualifier = path\n-                    .segment()\n-                    .and_then(|it| {\n-                        find_node_with_range::<ast::PathSegment>(\n-                            original_file,\n-                            it.syntax().text_range(),\n-                        )\n-                    })\n-                    .map(|it| it.parent_path());\n-                return;\n-            }\n+        path_ctx.is_trivial_path = true;\n \n-            if let Some(segment) = path.segment() {\n-                if segment.coloncolon_token().is_some() {\n-                    return;\n+        // Find either enclosing expr statement (thing with `;`) or a\n+        // block. If block, check that we are the last expr.\n+        path_ctx.can_be_stmt = name_ref\n+            .syntax()\n+            .ancestors()\n+            .find_map(|node| {\n+                if let Some(stmt) = ast::ExprStmt::cast(node.clone()) {\n+                    return Some(stmt.syntax().text_range() == name_ref.syntax().text_range());\n                 }\n-            }\n-\n-            path_ctx.is_trivial_path = true;\n-\n-            // Find either enclosing expr statement (thing with `;`) or a\n-            // block. If block, check that we are the last expr.\n-            path_ctx.can_be_stmt = name_ref\n-                .syntax()\n-                .ancestors()\n-                .find_map(|node| {\n-                    if let Some(stmt) = ast::ExprStmt::cast(node.clone()) {\n-                        return Some(stmt.syntax().text_range() == name_ref.syntax().text_range());\n-                    }\n-                    if let Some(stmt_list) = ast::StmtList::cast(node) {\n-                        return Some(\n-                            stmt_list.tail_expr().map(|e| e.syntax().text_range())\n-                                == Some(name_ref.syntax().text_range()),\n-                        );\n-                    }\n-                    None\n-                })\n-                .unwrap_or(false);\n-        }\n+                if let Some(stmt_list) = ast::StmtList::cast(node) {\n+                    return Some(\n+                        stmt_list.tail_expr().map(|e| e.syntax().text_range())\n+                            == Some(name_ref.syntax().text_range()),\n+                    );\n+                }\n+                None\n+            })\n+            .unwrap_or(false);\n+        Some(path_ctx)\n     }\n }\n "}]}