{"sha": "064f8885d5e1d38673783d626d9d3fc1b7b909f4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA2NGY4ODg1ZDVlMWQzODY3Mzc4M2Q2MjZkOWQzZmMxYjdiOTA5ZjQ=", "commit": {"author": {"name": "Mark Rousskov", "email": "mark.simulacrum@gmail.com", "date": "2020-01-13T21:40:19Z"}, "committer": {"name": "Mark Rousskov", "email": "mark.simulacrum@gmail.com", "date": "2020-01-15T00:11:15Z"}, "message": "Add unicode table generator", "tree": {"sha": "21cc860a9cad4b8ffd19709442aa1d061479d8c5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/21cc860a9cad4b8ffd19709442aa1d061479d8c5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/064f8885d5e1d38673783d626d9d3fc1b7b909f4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/064f8885d5e1d38673783d626d9d3fc1b7b909f4", "html_url": "https://github.com/rust-lang/rust/commit/064f8885d5e1d38673783d626d9d3fc1b7b909f4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/064f8885d5e1d38673783d626d9d3fc1b7b909f4/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8a87b945b27b5670ac5ed665bbb0fccc1b88a0a0", "url": "https://api.github.com/repos/rust-lang/rust/commits/8a87b945b27b5670ac5ed665bbb0fccc1b88a0a0", "html_url": "https://github.com/rust-lang/rust/commit/8a87b945b27b5670ac5ed665bbb0fccc1b88a0a0"}], "stats": {"total": 572, "additions": 564, "deletions": 8}, "files": [{"sha": "d9761ce40927ce92d29daa23b4496e04b9e97e4f", "filename": ".gitignore", "status": "modified", "additions": 1, "deletions": 8, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/.gitignore", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/.gitignore", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.gitignore?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -34,14 +34,7 @@ __pycache__/\n # Created by default with `src/ci/docker/run.sh`:\n /obj/\n /rustllvm/\n-/src/libcore/unicode/DerivedCoreProperties.txt\n-/src/libcore/unicode/DerivedNormalizationProps.txt\n-/src/libcore/unicode/PropList.txt\n-/src/libcore/unicode/ReadMe.txt\n-/src/libcore/unicode/Scripts.txt\n-/src/libcore/unicode/SpecialCasing.txt\n-/src/libcore/unicode/UnicodeData.txt\n-/src/libcore/unicode/downloaded\n+/unicode-downloads\n /target/\n # Generated by compiletest for incremental:\n /tmp/"}, {"sha": "3f1058645d2646f5f15b5c93aa024a95de439c78", "filename": "Cargo.lock", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -4930,6 +4930,16 @@ version = \"1.10.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"612d636f949607bdf9b123b4a6f6d966dedf3ff669f7f045890d3a4a73948169\"\n \n+[[package]]\n+name = \"ucd-parse\"\n+version = \"0.1.4\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"ca6b52bf4da6512f0f07785a04769222e50d29639e7ecd016b7806fd2de306b4\"\n+dependencies = [\n+ \"lazy_static 1.3.0\",\n+ \"regex\",\n+]\n+\n [[package]]\n name = \"ucd-trie\"\n version = \"0.1.1\"\n@@ -4951,6 +4961,13 @@ dependencies = [\n  \"version_check 0.1.5\",\n ]\n \n+[[package]]\n+name = \"unicode-bdd\"\n+version = \"0.1.0\"\n+dependencies = [\n+ \"ucd-parse\",\n+]\n+\n [[package]]\n name = \"unicode-bidi\"\n version = \"0.3.4\""}, {"sha": "9d5c27b96df5d435daaded1ece44d1c8b6b613c1", "filename": "Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/Cargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/Cargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.toml?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -23,6 +23,7 @@ members = [\n   \"src/tools/rustfmt\",\n   \"src/tools/miri\",\n   \"src/tools/rustdoc-themes\",\n+  \"src/tools/unicode-table-generator\",\n ]\n exclude = [\n   \"build\","}, {"sha": "92344cdfc89eed1a9c889f6402ce3f508e70fc02", "filename": "src/tools/unicode-table-generator/Cargo.toml", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2FCargo.toml?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -0,0 +1,10 @@\n+[package]\n+name = \"unicode-bdd\"\n+version = \"0.1.0\"\n+authors = [\"Mark Rousskov <mark.simulacrum@gmail.com>\"]\n+edition = \"2018\"\n+\n+# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n+\n+[dependencies]\n+ucd-parse = \"0.1.3\""}, {"sha": "01f199c213e02441bf3d15393b80dacbafff1a2e", "filename": "src/tools/unicode-table-generator/src/case_mapping.rs", "status": "added", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fcase_mapping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fcase_mapping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fcase_mapping.rs?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -0,0 +1,62 @@\n+use crate::{fmt_list, UnicodeData};\n+use std::fmt;\n+\n+pub(crate) fn generate_case_mapping(data: &UnicodeData) -> String {\n+    let mut file = String::new();\n+\n+    file.push_str(HEADER.trim_start());\n+\n+    let decl_type = \"&[(char, [char; 3])]\";\n+\n+    file.push_str(&format!(\n+        \"static LOWERCASE_TABLE: {} = &[{}];\",\n+        decl_type,\n+        fmt_list(data.to_lower.iter().map(to_mapping))\n+    ));\n+    file.push_str(\"\\n\\n\");\n+    file.push_str(&format!(\n+        \"static UPPERCASE_TABLE: {} = &[{}];\",\n+        decl_type,\n+        fmt_list(data.to_upper.iter().map(to_mapping))\n+    ));\n+    file\n+}\n+\n+fn to_mapping((key, (a, b, c)): (&u32, &(u32, u32, u32))) -> (CharEscape, [CharEscape; 3]) {\n+    (\n+        CharEscape(std::char::from_u32(*key).unwrap()),\n+        [\n+            CharEscape(std::char::from_u32(*a).unwrap()),\n+            CharEscape(std::char::from_u32(*b).unwrap()),\n+            CharEscape(std::char::from_u32(*c).unwrap()),\n+        ],\n+    )\n+}\n+\n+struct CharEscape(char);\n+\n+impl fmt::Debug for CharEscape {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        write!(f, \"'{}'\", self.0.escape_default())\n+    }\n+}\n+\n+static HEADER: &str = \"\n+pub fn to_lower(c: char) -> [char; 3] {\n+    match bsearch_case_table(c, LOWERCASE_TABLE) {\n+        None => [c, '\\\\0', '\\\\0'],\n+        Some(index) => LOWERCASE_TABLE[index].1,\n+    }\n+}\n+\n+pub fn to_upper(c: char) -> [char; 3] {\n+    match bsearch_case_table(c, UPPERCASE_TABLE) {\n+        None => [c, '\\\\0', '\\\\0'],\n+        Some(index) => UPPERCASE_TABLE[index].1,\n+    }\n+}\n+\n+fn bsearch_case_table(c: char, table: &[(char, [char; 3])]) -> Option<usize> {\n+    table.binary_search_by(|&(key, _)| key.cmp(&c)).ok()\n+}\n+\";"}, {"sha": "be8508e3973a2486bc6f1b43d58371a7f5bfa23d", "filename": "src/tools/unicode-table-generator/src/main.rs", "status": "added", "additions": 261, "deletions": 0, "changes": 261, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fmain.rs?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -0,0 +1,261 @@\n+use std::collections::{BTreeMap, HashMap};\n+use std::ops::Range;\n+use ucd_parse::Codepoints;\n+\n+mod case_mapping;\n+mod raw_emitter;\n+mod unicode_download;\n+\n+use raw_emitter::{emit_codepoints, RawEmitter};\n+\n+static PROPERTIES: &[&str] = &[\n+    \"Alphabetic\",\n+    \"Lowercase\",\n+    \"Uppercase\",\n+    \"Cased\",\n+    \"Case_Ignorable\",\n+    \"Grapheme_Extend\",\n+    \"White_Space\",\n+    \"Cc\",\n+    \"N\",\n+];\n+\n+struct UnicodeData {\n+    ranges: Vec<(&'static str, Vec<Range<u32>>)>,\n+    to_upper: BTreeMap<u32, (u32, u32, u32)>,\n+    to_lower: BTreeMap<u32, (u32, u32, u32)>,\n+}\n+\n+fn to_mapping(origin: u32, codepoints: Vec<ucd_parse::Codepoint>) -> Option<(u32, u32, u32)> {\n+    let mut a = None;\n+    let mut b = None;\n+    let mut c = None;\n+\n+    for codepoint in codepoints {\n+        if origin == codepoint.value() {\n+            return None;\n+        }\n+\n+        if a.is_none() {\n+            a = Some(codepoint.value());\n+        } else if b.is_none() {\n+            b = Some(codepoint.value());\n+        } else if c.is_none() {\n+            c = Some(codepoint.value());\n+        } else {\n+            panic!(\"more than 3 mapped codepoints\")\n+        }\n+    }\n+\n+    Some((a.unwrap(), b.unwrap_or(0), c.unwrap_or(0)))\n+}\n+\n+static UNICODE_DIRECTORY: &str = \"unicode-downloads\";\n+\n+fn load_data() -> UnicodeData {\n+    unicode_download::fetch_latest();\n+\n+    let mut properties = HashMap::new();\n+    for row in ucd_parse::parse::<_, ucd_parse::CoreProperty>(&UNICODE_DIRECTORY).unwrap() {\n+        if let Some(name) = PROPERTIES.iter().find(|prop| **prop == row.property.as_str()) {\n+            properties.entry(*name).or_insert_with(Vec::new).push(row.codepoints);\n+        }\n+    }\n+    for row in ucd_parse::parse::<_, ucd_parse::Property>(&UNICODE_DIRECTORY).unwrap() {\n+        if let Some(name) = PROPERTIES.iter().find(|prop| **prop == row.property.as_str()) {\n+            properties.entry(*name).or_insert_with(Vec::new).push(row.codepoints);\n+        }\n+    }\n+\n+    let mut to_lower = BTreeMap::new();\n+    let mut to_upper = BTreeMap::new();\n+    for row in ucd_parse::UnicodeDataExpander::new(\n+        ucd_parse::parse::<_, ucd_parse::UnicodeData>(&UNICODE_DIRECTORY).unwrap(),\n+    ) {\n+        let general_category = if [\"Nd\", \"Nl\", \"No\"].contains(&row.general_category.as_str()) {\n+            \"N\"\n+        } else {\n+            row.general_category.as_str()\n+        };\n+        if let Some(name) = PROPERTIES.iter().find(|prop| **prop == general_category) {\n+            properties\n+                .entry(*name)\n+                .or_insert_with(Vec::new)\n+                .push(Codepoints::Single(row.codepoint));\n+        }\n+\n+        if let Some(mapped) = row.simple_lowercase_mapping {\n+            if mapped != row.codepoint {\n+                to_lower.insert(row.codepoint.value(), (mapped.value(), 0, 0));\n+            }\n+        }\n+        if let Some(mapped) = row.simple_uppercase_mapping {\n+            if mapped != row.codepoint {\n+                to_upper.insert(row.codepoint.value(), (mapped.value(), 0, 0));\n+            }\n+        }\n+    }\n+\n+    for row in ucd_parse::parse::<_, ucd_parse::SpecialCaseMapping>(&UNICODE_DIRECTORY).unwrap() {\n+        if !row.conditions.is_empty() {\n+            // Skip conditional case mappings\n+            continue;\n+        }\n+\n+        let key = row.codepoint.value();\n+        if let Some(lower) = to_mapping(key, row.lowercase) {\n+            to_lower.insert(key, lower);\n+        }\n+        if let Some(upper) = to_mapping(key, row.uppercase) {\n+            to_upper.insert(key, upper);\n+        }\n+    }\n+\n+    let mut properties: HashMap<&'static str, Vec<Range<u32>>> = properties\n+        .into_iter()\n+        .map(|(k, v)| {\n+            (\n+                k,\n+                v.into_iter()\n+                    .flat_map(|codepoints| match codepoints {\n+                        Codepoints::Single(c) => c\n+                            .scalar()\n+                            .map(|ch| (ch as u32..ch as u32 + 1))\n+                            .into_iter()\n+                            .collect::<Vec<_>>(),\n+                        Codepoints::Range(c) => c\n+                            .into_iter()\n+                            .flat_map(|c| c.scalar().map(|ch| (ch as u32..ch as u32 + 1)))\n+                            .collect::<Vec<_>>(),\n+                    })\n+                    .collect::<Vec<Range<u32>>>(),\n+            )\n+        })\n+        .collect();\n+\n+    for ranges in properties.values_mut() {\n+        merge_ranges(ranges);\n+    }\n+\n+    let mut properties = properties.into_iter().collect::<Vec<_>>();\n+    properties.sort_by_key(|p| p.0);\n+    UnicodeData { ranges: properties, to_lower, to_upper }\n+}\n+\n+fn main() {\n+    let write_location = std::env::args().nth(1).unwrap_or_else(|| {\n+        eprintln!(\"Must provide path to write unicode tables to\");\n+        eprintln!(\n+            \"e.g. {} src/libcore/unicode/unicode_data.rs\",\n+            std::env::args().nth(0).unwrap_or_default()\n+        );\n+        std::process::exit(1);\n+    });\n+\n+    let unicode_data = load_data();\n+    let ranges_by_property = &unicode_data.ranges;\n+\n+    let mut total_bytes = 0;\n+    let mut modules = Vec::new();\n+    for (property, ranges) in ranges_by_property {\n+        let datapoints = ranges.iter().map(|r| r.end - r.start).sum::<u32>();\n+        let mut emitter = RawEmitter::new();\n+        emit_codepoints(&mut emitter, &ranges);\n+\n+        modules.push((property.to_lowercase().to_string(), emitter.file));\n+        println!(\"{:15}: {} bytes, {} codepoints\", property, emitter.bytes_used, datapoints,);\n+        total_bytes += emitter.bytes_used;\n+    }\n+\n+    let mut table_file = String::new();\n+\n+    table_file.push_str(\n+        \"///! This file is generated by src/tools/unicode-table-generator; do not edit manually!\\n\",\n+    );\n+\n+    table_file.push_str(\"use super::range_search;\\n\\n\");\n+\n+    table_file.push_str(&version());\n+\n+    table_file.push('\\n');\n+\n+    modules.push((String::from(\"conversions\"), case_mapping::generate_case_mapping(&unicode_data)));\n+\n+    for (name, contents) in modules {\n+        table_file.push_str(\"#[rustfmt::skip]\\n\");\n+        table_file.push_str(&format!(\"pub mod {} {{\\n\", name));\n+        for line in contents.lines() {\n+            if !line.trim().is_empty() {\n+                table_file.push_str(\"    \");\n+                table_file.push_str(&line);\n+            }\n+            table_file.push('\\n');\n+        }\n+        table_file.push_str(\"}\\n\\n\");\n+    }\n+\n+    std::fs::write(&write_location, format!(\"{}\\n\", table_file.trim_end())).unwrap();\n+\n+    println!(\"Total table sizes: {} bytes\", total_bytes);\n+}\n+\n+fn version() -> String {\n+    let mut out = String::new();\n+    out.push_str(\"pub const UNICODE_VERSION: (u32, u32, u32) = \");\n+\n+    let readme =\n+        std::fs::read_to_string(std::path::Path::new(UNICODE_DIRECTORY).join(\"ReadMe.txt\"))\n+            .unwrap();\n+\n+    let prefix = \"for Version \";\n+    let start = readme.find(prefix).unwrap() + prefix.len();\n+    let end = readme.find(\" of the Unicode Standard.\").unwrap();\n+    let version =\n+        readme[start..end].split('.').map(|v| v.parse::<u32>().expect(&v)).collect::<Vec<_>>();\n+    let [major, minor, micro] = [version[0], version[1], version[2]];\n+\n+    out.push_str(&format!(\"({}, {}, {});\\n\", major, minor, micro));\n+    out\n+}\n+\n+fn fmt_list<V: std::fmt::Debug>(values: impl IntoIterator<Item = V>) -> String {\n+    let pieces = values.into_iter().map(|b| format!(\"{:?}, \", b)).collect::<Vec<_>>();\n+    let mut out = String::new();\n+    let mut line = format!(\"\\n    \");\n+    for piece in pieces {\n+        if line.len() + piece.len() < 98 {\n+            line.push_str(&piece);\n+        } else {\n+            out.push_str(line.trim_end());\n+            out.push('\\n');\n+            line = format!(\"    {}\", piece);\n+        }\n+    }\n+    out.push_str(line.trim_end());\n+    out.push('\\n');\n+    out\n+}\n+\n+fn merge_ranges(ranges: &mut Vec<Range<u32>>) {\n+    loop {\n+        let mut new_ranges = Vec::new();\n+        let mut idx_iter = 0..(ranges.len() - 1);\n+        while let Some(idx) = idx_iter.next() {\n+            let cur = ranges[idx].clone();\n+            let next = ranges[idx + 1].clone();\n+            if cur.end == next.start {\n+                let _ = idx_iter.next(); // skip next as we're merging it in\n+                new_ranges.push(cur.start..next.end);\n+            } else {\n+                new_ranges.push(cur);\n+            }\n+        }\n+        new_ranges.push(ranges.last().unwrap().clone());\n+        if new_ranges.len() == ranges.len() {\n+            *ranges = new_ranges;\n+            break;\n+        } else {\n+            *ranges = new_ranges;\n+        }\n+    }\n+}"}, {"sha": "3e60ce13f9223fc24082eb167bfa5f6bb9e36f8a", "filename": "src/tools/unicode-table-generator/src/raw_emitter.rs", "status": "added", "additions": 170, "deletions": 0, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fraw_emitter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fraw_emitter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fraw_emitter.rs?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -0,0 +1,170 @@\n+//! This implements the core logic of the compression scheme used to compactly\n+//! encode the Unicode character classes.\n+//!\n+//! The primary idea is that we 'flatten' the Unicode ranges into an enormous\n+//! bitset. To represent any arbitrary codepoint in a raw bitset, we would need\n+//! over 17 kilobytes of data per character set -- way too much for our\n+//! purposes.\n+//!\n+//! We have two primary goals with the encoding: we want to be compact, because\n+//! these tables often end up in ~every Rust program (especially the\n+//! grapheme_extend table, used for str debugging), including those for embedded\n+//! targets (where space is important). We also want to be relatively fast,\n+//! though this is more of a nice to have rather than a key design constraint.\n+//! In practice, due to modern processor design these two are closely related.\n+//!\n+//! The encoding scheme here compresses the bitset by first deduplicating the\n+//! \"words\" (64 bits on all platforms). In practice very few words are present\n+//! in most data sets.\n+//!\n+//! This gives us an array that maps `u8 -> word` (if we ever went beyond 256\n+//! words, we could go to u16 -> word or have some dual compression scheme\n+//! mapping into two separate sets; currently this is not dealt with).\n+//!\n+//! With that scheme, we now have a single byte for every 64 codepoints. We\n+//! further group these by 16 (arbitrarily chosen), and again deduplicate and\n+//! store in an array (u8 -> [u8; 16]).\n+//!\n+//! The indices into this array represent ranges of 64*16 = 1024 codepoints.\n+//!\n+//! This already reduces the top-level array to at most 1,086 bytes, but in\n+//! practice we usually can encode in far fewer (the first couple Unicode planes\n+//! are dense).\n+//!\n+//! The last byte of this top-level array is pulled out to a separate static\n+//! and trailing zeros are dropped; this is simply because grapheme_extend and\n+//! case_ignorable have a single entry in the 896th entry, so this shrinks them\n+//! down considerably.\n+\n+use crate::fmt_list;\n+use std::collections::{BTreeSet, HashMap};\n+use std::convert::TryFrom;\n+use std::fmt::Write;\n+use std::ops::Range;\n+\n+pub struct RawEmitter {\n+    pub file: String,\n+    pub bytes_used: usize,\n+}\n+\n+impl RawEmitter {\n+    pub fn new() -> RawEmitter {\n+        RawEmitter { file: String::new(), bytes_used: 0 }\n+    }\n+\n+    fn blank_line(&mut self) {\n+        if self.file.is_empty() || self.file.ends_with(\"\\n\\n\") {\n+            return;\n+        }\n+        writeln!(&mut self.file, \"\").unwrap();\n+    }\n+\n+    fn emit_bitset(&mut self, words: &[u64]) {\n+        let unique_words =\n+            words.iter().cloned().collect::<BTreeSet<_>>().into_iter().collect::<Vec<_>>();\n+        if unique_words.len() > u8::max_value() as usize {\n+            panic!(\"cannot pack {} into 8 bits\", unique_words.len());\n+        }\n+\n+        let word_indices = unique_words\n+            .iter()\n+            .cloned()\n+            .enumerate()\n+            .map(|(idx, word)| (word, u8::try_from(idx).unwrap()))\n+            .collect::<HashMap<_, _>>();\n+\n+        let mut idx = words.iter().map(|w| word_indices[w]).collect::<Vec<u8>>();\n+        let chunk_length = 16;\n+        for _ in 0..(chunk_length - (idx.len() % chunk_length)) {\n+            assert_eq!(unique_words[0], 0, \"first word is all zeros\");\n+            // pad out bitset index with zero words so we have all chunks of 16\n+            idx.push(0);\n+        }\n+\n+        let mut chunks = BTreeSet::new();\n+        for chunk in idx.chunks(chunk_length) {\n+            chunks.insert(chunk);\n+        }\n+        let chunk_map = chunks\n+            .clone()\n+            .into_iter()\n+            .enumerate()\n+            .map(|(idx, chunk)| (chunk, idx))\n+            .collect::<HashMap<_, _>>();\n+        let mut chunk_indices = Vec::new();\n+        for chunk in idx.chunks(chunk_length) {\n+            chunk_indices.push(chunk_map[chunk]);\n+        }\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET_LAST_CHUNK_MAP: (u16, u8) = ({}, {});\",\n+            chunk_indices.len() - 1,\n+            chunk_indices.pop().unwrap(),\n+        )\n+        .unwrap();\n+        self.bytes_used += 3;\n+        // Strip out the empty pieces, presuming our above pop() made us now\n+        // have some trailing zeros.\n+        assert_eq!(unique_words[0], 0, \"first word is all zeros\");\n+        while let Some(0) = chunk_indices.last() {\n+            chunk_indices.pop();\n+        }\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET_CHUNKS_MAP: [u8; {}] = [{}];\",\n+            chunk_indices.len(),\n+            fmt_list(&chunk_indices),\n+        )\n+        .unwrap();\n+        self.bytes_used += chunk_indices.len();\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET_INDEX_CHUNKS: [[u8; 16]; {}] = [{}];\",\n+            chunks.len(),\n+            fmt_list(chunks.iter()),\n+        )\n+        .unwrap();\n+        self.bytes_used += 16 * chunks.len();\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET: [u64; {}] = [{}];\",\n+            unique_words.len(),\n+            fmt_list(&unique_words),\n+        )\n+        .unwrap();\n+        self.bytes_used += 8 * unique_words.len();\n+    }\n+\n+    pub fn emit_lookup(&mut self) {\n+        writeln!(&mut self.file, \"pub fn lookup(c: char) -> bool {{\").unwrap();\n+        writeln!(&mut self.file, \"    super::range_search(\",).unwrap();\n+        writeln!(&mut self.file, \"        c as u32,\").unwrap();\n+        writeln!(&mut self.file, \"        &BITSET_CHUNKS_MAP,\").unwrap();\n+        writeln!(&mut self.file, \"        BITSET_LAST_CHUNK_MAP,\").unwrap();\n+        writeln!(&mut self.file, \"        &BITSET_INDEX_CHUNKS,\").unwrap();\n+        writeln!(&mut self.file, \"        &BITSET,\").unwrap();\n+        writeln!(&mut self.file, \"    )\").unwrap();\n+        writeln!(&mut self.file, \"}}\").unwrap();\n+    }\n+}\n+\n+pub fn emit_codepoints(emitter: &mut RawEmitter, ranges: &[Range<u32>]) {\n+    emitter.blank_line();\n+\n+    let last_code_point = ranges.last().unwrap().end;\n+    // bitset for every bit in the codepoint range\n+    //\n+    // + 2 to ensure an all zero word to use for padding\n+    let mut buckets = vec![0u64; (last_code_point as usize / 64) + 2];\n+    for range in ranges {\n+        for codepoint in range.clone() {\n+            let bucket = codepoint as usize / 64;\n+            let bit = codepoint as u64 % 64;\n+            buckets[bucket] |= 1 << bit;\n+        }\n+    }\n+\n+    emitter.emit_bitset(&buckets);\n+    emitter.blank_line();\n+    emitter.emit_lookup();\n+}"}, {"sha": "3f6de9ea3bbd78b05b7f807876312da38f936e4e", "filename": "src/tools/unicode-table-generator/src/unicode_download.rs", "status": "added", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Funicode_download.rs", "raw_url": "https://github.com/rust-lang/rust/raw/064f8885d5e1d38673783d626d9d3fc1b7b909f4/src%2Ftools%2Funicode-table-generator%2Fsrc%2Funicode_download.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Funicode_download.rs?ref=064f8885d5e1d38673783d626d9d3fc1b7b909f4", "patch": "@@ -0,0 +1,42 @@\n+use crate::UNICODE_DIRECTORY;\n+use std::path::Path;\n+use std::process::Command;\n+\n+static URL_PREFIX: &str = \"https://www.unicode.org/Public/UCD/latest/ucd/\";\n+\n+static README: &str = \"ReadMe.txt\";\n+\n+static RESOURCES: &[&str] =\n+    &[\"DerivedCoreProperties.txt\", \"PropList.txt\", \"UnicodeData.txt\", \"SpecialCasing.txt\"];\n+\n+pub fn fetch_latest() {\n+    let directory = Path::new(UNICODE_DIRECTORY);\n+    if let Err(e) = std::fs::create_dir_all(directory) {\n+        if e.kind() != std::io::ErrorKind::AlreadyExists {\n+            panic!(\"Failed to create {:?}: {}\", UNICODE_DIRECTORY, e);\n+        }\n+    }\n+    let output = Command::new(\"curl\").arg(URL_PREFIX.to_owned() + README).output().unwrap();\n+    if !output.status.success() {\n+        panic!(\n+            \"Failed to run curl to fetch readme: stderr: {}\",\n+            String::from_utf8_lossy(&output.stderr)\n+        );\n+    }\n+    let current = std::fs::read_to_string(directory.join(README)).unwrap_or_default();\n+    if current.as_bytes() != &output.stdout[..] {\n+        std::fs::write(directory.join(README), output.stdout).unwrap();\n+    }\n+\n+    for resource in RESOURCES {\n+        let output = Command::new(\"curl\").arg(URL_PREFIX.to_owned() + resource).output().unwrap();\n+        if !output.status.success() {\n+            panic!(\n+                \"Failed to run curl to fetch {}: stderr: {}\",\n+                resource,\n+                String::from_utf8_lossy(&output.stderr)\n+            );\n+        }\n+        std::fs::write(directory.join(resource), output.stdout).unwrap();\n+    }\n+}"}]}