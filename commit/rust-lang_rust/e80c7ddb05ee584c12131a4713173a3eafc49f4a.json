{"sha": "e80c7ddb05ee584c12131a4713173a3eafc49f4a", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU4MGM3ZGRiMDVlZTU4NGMxMjEzMWE0NzEzMTczYTNlYWZjNDlmNGE=", "commit": {"author": {"name": "Nicholas Nethercote", "email": "nnethercote@mozilla.com", "date": "2018-12-11T23:01:08Z"}, "committer": {"name": "Nicholas Nethercote", "email": "nnethercote@mozilla.com", "date": "2018-12-12T09:36:00Z"}, "message": "Rename `TokenStream::concat` and remove `TokenStream::concat_rc_vec`.\n\n`TokenStream::new` is a better name for the former, and the latter is\nnow just equivalent to `TokenStream::Stream`.", "tree": {"sha": "20bcd4aa3ddb48334f1d872e1a1e8c26afcc7398", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/20bcd4aa3ddb48334f1d872e1a1e8c26afcc7398"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e80c7ddb05ee584c12131a4713173a3eafc49f4a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e80c7ddb05ee584c12131a4713173a3eafc49f4a", "html_url": "https://github.com/rust-lang/rust/commit/e80c7ddb05ee584c12131a4713173a3eafc49f4a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e80c7ddb05ee584c12131a4713173a3eafc49f4a/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "07c12fa89e297bf5940f903dea8186a0a33f9d82", "url": "https://api.github.com/repos/rust-lang/rust/commits/07c12fa89e297bf5940f903dea8186a0a33f9d82", "html_url": "https://github.com/rust-lang/rust/commit/07c12fa89e297bf5940f903dea8186a0a33f9d82"}], "stats": {"total": 64, "additions": 30, "deletions": 34}, "files": [{"sha": "73cbe49f43b049ee955b140d0e3e547e3ed1eb2f", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -483,7 +483,7 @@ impl MetaItem {\n             last_pos = segment.ident.span.hi();\n         }\n         idents.push(self.node.tokens(self.span));\n-        TokenStream::concat(idents)\n+        TokenStream::new(idents)\n     }\n \n     fn from_tokens<I>(tokens: &mut iter::Peekable<I>) -> Option<MetaItem>\n@@ -539,7 +539,7 @@ impl MetaItemKind {\n         match *self {\n             MetaItemKind::Word => TokenStream::empty(),\n             MetaItemKind::NameValue(ref lit) => {\n-                TokenStream::concat(vec![TokenTree::Token(span, Token::Eq).into(), lit.tokens()])\n+                TokenStream::new(vec![TokenTree::Token(span, Token::Eq).into(), lit.tokens()])\n             }\n             MetaItemKind::List(ref list) => {\n                 let mut tokens = Vec::new();\n@@ -552,7 +552,7 @@ impl MetaItemKind {\n                 TokenTree::Delimited(\n                     DelimSpan::from_single(span),\n                     token::Paren,\n-                    TokenStream::concat(tokens).into(),\n+                    TokenStream::new(tokens).into(),\n                 ).into()\n             }\n         }"}, {"sha": "5820b49ab621636bb19735b3e4ae045121ad6198", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -247,7 +247,7 @@ pub mod rt {\n \n             let delim_span = DelimSpan::from_single(self.span);\n             r.push(TokenTree::Delimited(\n-                delim_span, token::Bracket, TokenStream::concat(inner).into()\n+                delim_span, token::Bracket, TokenStream::new(inner).into()\n             ));\n             r\n         }"}, {"sha": "a63abd40495136e457d055dca0fb088837973488", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -103,12 +103,12 @@ pub fn transcribe(cx: &ExtCtxt,\n                 }\n                 Frame::Delimited { forest, span, .. } => {\n                     if result_stack.is_empty() {\n-                        return TokenStream::concat(result);\n+                        return TokenStream::new(result);\n                     }\n                     let tree = TokenTree::Delimited(\n                         span,\n                         forest.delim,\n-                        TokenStream::concat(result).into(),\n+                        TokenStream::new(result).into(),\n                     );\n                     result = result_stack.pop().unwrap();\n                     result.push(tree.into());"}, {"sha": "1bd0656846bcea90ebddb47a26b56e74e9ff06d5", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -170,7 +170,7 @@ impl<'a> Parser<'a> {\n                     token::CloseDelim(_) | token::Eof => self.unexpected()?,\n                     _ => self.parse_token_tree(),\n                 };\n-                TokenStream::concat(vec![eq.into(), tree.into()])\n+                TokenStream::new(vec![eq.into(), tree.into()])\n             } else {\n                 TokenStream::empty()\n             };"}, {"sha": "0906c25cab36103e9d38ec30541d6eaabba1ad3b", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -22,22 +22,22 @@ impl<'a> StringReader<'a> {\n             tts.push(self.parse_token_tree()?);\n         }\n \n-        Ok(TokenStream::concat(tts))\n+        Ok(TokenStream::new(tts))\n     }\n \n     // Parse a stream of tokens into a list of `TokenTree`s, up to a `CloseDelim`.\n     fn parse_token_trees_until_close_delim(&mut self) -> TokenStream {\n         let mut tts = vec![];\n         loop {\n             if let token::CloseDelim(..) = self.token {\n-                return TokenStream::concat(tts);\n+                return TokenStream::new(tts);\n             }\n \n             match self.parse_token_tree() {\n                 Ok(tree) => tts.push(tree),\n                 Err(mut e) => {\n                     e.emit();\n-                    return TokenStream::concat(tts);\n+                    return TokenStream::new(tts);\n                 }\n             }\n         }"}, {"sha": "a1685d537c8bb04b5571a784cafb6118e6a0f6a9", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -842,13 +842,13 @@ mod tests {\n         with_globals(|| {\n             let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n \n-            let expected = TokenStream::concat(vec![\n+            let expected = TokenStream::new(vec![\n                 TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"), false)).into(),\n                 TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"), false)).into(),\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(5, 6), sp(13, 14)),\n                     token::DelimToken::Paren,\n-                    TokenStream::concat(vec![\n+                    TokenStream::new(vec![\n                         TokenTree::Token(sp(6, 7),\n                                          token::Ident(Ident::from_str(\"b\"), false)).into(),\n                         TokenTree::Token(sp(8, 9), token::Colon).into(),\n@@ -859,7 +859,7 @@ mod tests {\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(15, 16), sp(20, 21)),\n                     token::DelimToken::Brace,\n-                    TokenStream::concat(vec![\n+                    TokenStream::new(vec![\n                         TokenTree::Token(sp(17, 18),\n                                          token::Ident(Ident::from_str(\"b\"), false)).into(),\n                         TokenTree::Token(sp(18, 19), token::Semi).into(),"}, {"sha": "4e209f580248d7f38ee00303eae03a0240f9a9d0", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -2928,7 +2928,7 @@ impl<'a> Parser<'a> {\n                 _ => result.push(self.parse_token_tree().into()),\n             }\n         }\n-        TokenStream::concat(result)\n+        TokenStream::new(result)\n     }\n \n     /// Parse a prefix-unary-operator expr\n@@ -4624,7 +4624,7 @@ impl<'a> Parser<'a> {\n                         self.unexpected()?;\n                         unreachable!()\n                     };\n-                    TokenStream::concat(vec![\n+                    TokenStream::new(vec![\n                         args.into(),\n                         TokenTree::Token(token_lo.to(self.prev_span), token::FatArrow).into(),\n                         body.into(),"}, {"sha": "c11ef33f931d8ab94a82ba8ceca62795333595f1", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 15, "deletions": 19, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e80c7ddb05ee584c12131a4713173a3eafc49f4a/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=e80c7ddb05ee584c12131a4713173a3eafc49f4a", "patch": "@@ -195,7 +195,7 @@ impl TokenStream {\n                 new_stream.extend_from_slice(parts.0);\n                 new_stream.push(comma);\n                 new_stream.extend_from_slice(parts.1);\n-                return Some((TokenStream::concat(new_stream), sp));\n+                return Some((TokenStream::new(new_stream), sp));\n             }\n         }\n         None\n@@ -216,7 +216,7 @@ impl From<Token> for TokenStream {\n \n impl<T: Into<TokenStream>> iter::FromIterator<T> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n-        TokenStream::concat(iter.into_iter().map(Into::into).collect::<Vec<_>>())\n+        TokenStream::new(iter.into_iter().map(Into::into).collect::<Vec<_>>())\n     }\n }\n \n@@ -265,7 +265,7 @@ impl Extend<TokenStream> for TokenStream {\n         // Build the resulting token stream. If it contains more than one token,\n         // preserve capacity in the vector in anticipation of the caller\n         // performing additional calls to extend.\n-        *self = TokenStream::concat(builder.0);\n+        *self = TokenStream::new(builder.0);\n     }\n }\n \n@@ -297,18 +297,14 @@ impl TokenStream {\n         }\n     }\n \n-    pub fn concat(mut streams: Vec<TokenStream>) -> TokenStream {\n+    pub fn new(mut streams: Vec<TokenStream>) -> TokenStream {\n         match streams.len() {\n             0 => TokenStream::empty(),\n             1 => streams.pop().unwrap(),\n-            _ => TokenStream::concat_rc_vec(Lrc::new(streams)),\n+            _ => TokenStream::Stream(Lrc::new(streams)),\n         }\n     }\n \n-    fn concat_rc_vec(streams: Lrc<Vec<TokenStream>>) -> TokenStream {\n-        TokenStream::Stream(streams)\n-    }\n-\n     pub fn trees(&self) -> Cursor {\n         self.clone().into_trees()\n     }\n@@ -389,7 +385,7 @@ impl TokenStream {\n             });\n             i += 1;\n         }\n-        TokenStream::concat(result)\n+        TokenStream::new(result)\n     }\n \n     pub fn map<F: FnMut(TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n@@ -402,7 +398,7 @@ impl TokenStream {\n                 _ => unreachable!()\n             });\n         }\n-        TokenStream::concat(result)\n+        TokenStream::new(result)\n     }\n \n     fn first_tree_and_joint(&self) -> Option<(TokenTree, bool)> {\n@@ -461,7 +457,7 @@ impl TokenStreamBuilder {\n     }\n \n     pub fn build(self) -> TokenStream {\n-        TokenStream::concat(self.0)\n+        TokenStream::new(self.0)\n     }\n \n     fn push_all_but_last_tree(&mut self, stream: &TokenStream) {\n@@ -470,7 +466,7 @@ impl TokenStreamBuilder {\n             match len {\n                 1 => {}\n                 2 => self.0.push(streams[0].clone().into()),\n-                _ => self.0.push(TokenStream::concat(streams[0 .. len - 1].to_vec())),\n+                _ => self.0.push(TokenStream::new(streams[0 .. len - 1].to_vec())),\n             }\n             self.push_all_but_last_tree(&streams[len - 1])\n         }\n@@ -482,7 +478,7 @@ impl TokenStreamBuilder {\n             match len {\n                 1 => {}\n                 2 => self.0.push(streams[1].clone().into()),\n-                _ => self.0.push(TokenStream::concat(streams[1 .. len].to_vec())),\n+                _ => self.0.push(TokenStream::new(streams[1 .. len].to_vec())),\n             }\n             self.push_all_but_first_tree(&streams[0])\n         }\n@@ -577,7 +573,7 @@ impl Cursor {\n             _ if stream.is_empty() => return,\n             CursorKind::Empty => *self = stream.trees(),\n             CursorKind::Tree(_, consumed) | CursorKind::JointTree(_, consumed) => {\n-                *self = TokenStream::concat(vec![self.original_stream(), stream]).trees();\n+                *self = TokenStream::new(vec![self.original_stream(), stream]).trees();\n                 if consumed {\n                     self.next();\n                 }\n@@ -593,10 +589,10 @@ impl Cursor {\n             CursorKind::Empty => TokenStream::empty(),\n             CursorKind::Tree(ref tree, _) => tree.clone().into(),\n             CursorKind::JointTree(ref tree, _) => tree.clone().joint(),\n-            CursorKind::Stream(ref cursor) => TokenStream::concat_rc_vec({\n+            CursorKind::Stream(ref cursor) => TokenStream::Stream(\n                 cursor.stack.get(0).cloned().map(|(stream, _)| stream)\n                     .unwrap_or_else(|| cursor.stream.clone())\n-            }),\n+            ),\n         }\n     }\n \n@@ -664,7 +660,7 @@ impl From<TokenStream> for ThinTokenStream {\n \n impl From<ThinTokenStream> for TokenStream {\n     fn from(stream: ThinTokenStream) -> TokenStream {\n-        stream.0.map(TokenStream::concat_rc_vec).unwrap_or_else(TokenStream::empty)\n+        stream.0.map(TokenStream::Stream).unwrap_or_else(TokenStream::empty)\n     }\n }\n \n@@ -763,7 +759,7 @@ mod tests {\n             let test_res = string_to_ts(\"foo::bar::baz\");\n             let test_fst = string_to_ts(\"foo::bar\");\n             let test_snd = string_to_ts(\"::baz\");\n-            let eq_res = TokenStream::concat(vec![test_fst, test_snd]);\n+            let eq_res = TokenStream::new(vec![test_fst, test_snd]);\n             assert_eq!(test_res.trees().count(), 5);\n             assert_eq!(eq_res.trees().count(), 5);\n             assert_eq!(test_res.eq_unspanned(&eq_res), true);"}]}