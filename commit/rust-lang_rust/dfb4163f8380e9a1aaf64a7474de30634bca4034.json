{"sha": "dfb4163f8380e9a1aaf64a7474de30634bca4034", "node_id": "MDY6Q29tbWl0NzI0NzEyOmRmYjQxNjNmODM4MGU5YTFhYWY2NGE3NDc0ZGUzMDYzNGJjYTQwMzQ=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-22T17:39:58Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-25T22:53:30Z"}, "message": "Use standard capitalisation for TokenTree variants", "tree": {"sha": "4ba675a96bc22eb7c3e64f796f1753ff681b9fdd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4ba675a96bc22eb7c3e64f796f1753ff681b9fdd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/dfb4163f8380e9a1aaf64a7474de30634bca4034", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/dfb4163f8380e9a1aaf64a7474de30634bca4034", "html_url": "https://github.com/rust-lang/rust/commit/dfb4163f8380e9a1aaf64a7474de30634bca4034", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/dfb4163f8380e9a1aaf64a7474de30634bca4034/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6a50b4d018b0e44b9e12560030ca7fb240107a68", "url": "https://api.github.com/repos/rust-lang/rust/commits/6a50b4d018b0e44b9e12560030ca7fb240107a68", "html_url": "https://github.com/rust-lang/rust/commit/6a50b4d018b0e44b9e12560030ca7fb240107a68"}], "stats": {"total": 190, "additions": 95, "deletions": 95}, "files": [{"sha": "83a5697f75a69d92c5283a2d9ba91a2c35bc957d", "filename": "src/doc/guide-plugin.md", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Fdoc%2Fguide-plugin.md", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Fdoc%2Fguide-plugin.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fguide-plugin.md?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -56,7 +56,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{IDENT, get_ident};\n-use syntax::ast::{TokenTree, TTToken};\n+use syntax::ast::{TokenTree, TtToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n use syntax::ext::build::AstBuilder;  // trait for expr_uint\n use rustc::plugin::Registry;\n@@ -71,7 +71,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TTToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n+        [TtToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}, {"sha": "f87c7cf021547d0a02cc7bfc1213e50232086e71", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -25,7 +25,7 @@ use std::rc::Rc;\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n #[cfg(stage0)]\n-pub use self::TTToken as TTTok;\n+pub use self::TtToken as TTTok;\n \n // FIXME #6993: in librustc, uses of \"ident\" should be replaced\n // by just \"Name\".\n@@ -603,9 +603,9 @@ pub struct Delimiter {\n }\n \n impl Delimiter {\n-    /// Convert the delimiter to a `TTToken`\n+    /// Convert the delimiter to a `TtToken`\n     pub fn to_tt(&self) -> TokenTree {\n-        TTToken(self.span, self.token.clone())\n+        TtToken(self.span, self.token.clone())\n     }\n }\n \n@@ -617,41 +617,41 @@ impl Delimiter {\n /// If the syntax extension is an MBE macro, it will attempt to match its\n /// LHS \"matchers\" against the provided token tree, and if it finds a\n /// match, will transcribe the RHS token tree, splicing in any captured\n-/// `macro_parser::matched_nonterminals` into the `TTNonterminal`s it finds.\n+/// `macro_parser::matched_nonterminals` into the `TtNonterminal`s it finds.\n ///\n-/// The RHS of an MBE macro is the only place a `TTNonterminal` or `TTSequence`\n+/// The RHS of an MBE macro is the only place a `TtNonterminal` or `TtSequence`\n /// makes any real sense. You could write them elsewhere but nothing\n /// else knows what to do with them, so you'll probably get a syntax\n /// error.\n #[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n pub enum TokenTree {\n     /// A single token\n-    TTToken(Span, ::parse::token::Token),\n+    TtToken(Span, ::parse::token::Token),\n     /// A delimited sequence of token trees\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTDelimited(Span, Delimiter, Rc<Vec<TokenTree>>, Delimiter),\n+    TtDelimited(Span, Delimiter, Rc<Vec<TokenTree>>, Delimiter),\n \n     // These only make sense for right-hand-sides of MBE macros:\n \n     /// A kleene-style repetition sequence with a span, a `TTForest`,\n     /// an optional separator, and a boolean where true indicates\n     /// zero or more (..), and false indicates one or more (+).\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTSequence(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, bool),\n+    TtSequence(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, bool),\n \n     /// A syntactic variable that will be filled in by macro expansion.\n-    TTNonterminal(Span, Ident)\n+    TtNonterminal(Span, Ident)\n }\n \n impl TokenTree {\n     /// Returns the `Span` corresponding to this token tree.\n     pub fn get_span(&self) -> Span {\n         match *self {\n-            TTToken(span, _)           => span,\n-            TTDelimited(span, _, _, _) => span,\n-            TTSequence(span, _, _, _)  => span,\n-            TTNonterminal(span, _)     => span,\n+            TtToken(span, _)           => span,\n+            TtDelimited(span, _, _, _) => span,\n+            TtSequence(span, _, _, _)  => span,\n+            TtNonterminal(span, _)     => span,\n         }\n     }\n }"}, {"sha": "b8795ad5be80fa12211ca1a34b99deb01afbd995", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -50,7 +50,7 @@ pub fn expand_diagnostic_used<'cx>(ecx: &'cx mut ExtCtxt,\n                                    token_tree: &[TokenTree])\n                                    -> Box<MacResult+'cx> {\n     let code = match token_tree {\n-        [ast::TTToken(_, token::IDENT(code, _))] => code,\n+        [ast::TtToken(_, token::IDENT(code, _))] => code,\n         _ => unreachable!()\n     };\n     with_registered_diagnostics(|diagnostics| {\n@@ -82,12 +82,12 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n                                        token_tree: &[TokenTree])\n                                        -> Box<MacResult+'cx> {\n     let (code, description) = match token_tree {\n-        [ast::TTToken(_, token::IDENT(ref code, _))] => {\n+        [ast::TtToken(_, token::IDENT(ref code, _))] => {\n             (code, None)\n         },\n-        [ast::TTToken(_, token::IDENT(ref code, _)),\n-         ast::TTToken(_, token::COMMA),\n-         ast::TTToken(_, token::LIT_STR_RAW(description, _))] => {\n+        [ast::TtToken(_, token::IDENT(ref code, _)),\n+         ast::TtToken(_, token::COMMA),\n+         ast::TtToken(_, token::LIT_STR_RAW(description, _))] => {\n             (code, Some(description))\n         }\n         _ => unreachable!()\n@@ -110,7 +110,7 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n                                           token_tree: &[TokenTree])\n                                           -> Box<MacResult+'cx> {\n     let name = match token_tree {\n-        [ast::TTToken(_, token::IDENT(ref name, _))] => name,\n+        [ast::TtToken(_, token::IDENT(ref name, _))] => name,\n         _ => unreachable!()\n     };\n "}, {"sha": "64c8068607aa011259e14c0528419e248ef1a25f", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -684,8 +684,8 @@ pub fn get_single_str_from_tts(cx: &ExtCtxt,\n         cx.span_err(sp, format!(\"{} takes 1 argument.\", name).as_slice());\n     } else {\n         match tts[0] {\n-            ast::TTToken(_, token::LIT_STR(ident)) => return Some(parse::str_lit(ident.as_str())),\n-            ast::TTToken(_, token::LIT_STR_RAW(ident, _)) => {\n+            ast::TtToken(_, token::LIT_STR(ident)) => return Some(parse::str_lit(ident.as_str())),\n+            ast::TtToken(_, token::LIT_STR_RAW(ident, _)) => {\n                 return Some(parse::raw_str_lit(ident.as_str()))\n             }\n             _ => {"}, {"sha": "e12f9ee133a328171a687b423d7b40b6ba3a576e", "filename": "src/libsyntax/ext/concat_idents.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fconcat_idents.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -23,15 +23,15 @@ pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]\n     for (i, e) in tts.iter().enumerate() {\n         if i & 1 == 1 {\n             match *e {\n-                ast::TTToken(_, token::COMMA) => (),\n+                ast::TtToken(_, token::COMMA) => (),\n                 _ => {\n                     cx.span_err(sp, \"concat_idents! expecting comma.\");\n                     return DummyResult::expr(sp);\n                 }\n             }\n         } else {\n             match *e {\n-                ast::TTToken(_, token::IDENT(ident,_)) => {\n+                ast::TtToken(_, token::IDENT(ident,_)) => {\n                     res_str.push_str(token::get_ident(ident).get())\n                 }\n                 _ => {"}, {"sha": "5c4290d217bfd70faa92fa567ee2797c92133702", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -23,7 +23,7 @@ use ptr::P;\n *\n * This is registered as a set of expression syntax extension called quote!\n * that lifts its argument token-tree to an AST representing the\n-* construction of the same token tree, with ast::TTNonterminal nodes\n+* construction of the same token tree, with ast::TtNonterminal nodes\n * interpreted as antiquotes (splices).\n *\n */\n@@ -639,10 +639,10 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n \n fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n     match *tt {\n-        ast::TTToken(sp, ref tok) => {\n+        ast::TtToken(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n             let e_tok = cx.expr_call(sp,\n-                                     mk_ast_path(cx, sp, \"TTToken\"),\n+                                     mk_ast_path(cx, sp, \"TtToken\"),\n                                      vec!(e_sp, mk_token(cx, sp, tok)));\n             let e_push =\n                 cx.expr_method_call(sp,\n@@ -651,14 +651,14 @@ fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n                                     vec!(e_tok));\n             vec!(cx.stmt_expr(e_push))\n         },\n-        ast::TTDelimited(sp, ref open, ref tts, ref close) => {\n+        ast::TtDelimited(sp, ref open, ref tts, ref close) => {\n             mk_tt(cx, sp, &open.to_tt()).into_iter()\n                 .chain(tts.iter().flat_map(|tt| mk_tt(cx, sp, tt).into_iter()))\n                 .chain(mk_tt(cx, sp, &close.to_tt()).into_iter())\n                 .collect()\n         },\n-        ast::TTSequence(..) => fail!(\"TTSequence in quote!\"),\n-        ast::TTNonterminal(sp, ident) => {\n+        ast::TtSequence(..) => fail!(\"TtSequence in quote!\"),\n+        ast::TtNonterminal(sp, ident) => {\n             // tt.extend($ident.to_tokens(ext_cx).into_iter())\n \n             let e_to_toks =\n@@ -692,7 +692,7 @@ fn mk_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n               -> (P<ast::Expr>, P<ast::Expr>) {\n     // NB: It appears that the main parser loses its mind if we consider\n-    // $foo as a TTNonterminal during the main parse, so we have to re-parse\n+    // $foo as a TtNonterminal during the main parse, so we have to re-parse\n     // under quote_depth > 0. This is silly and should go away; the _guess_ is\n     // it has to do with transition away from supporting old-style macros, so\n     // try removing it when enough of them are gone."}, {"sha": "abf798ddacb3a12c36895d32f77b9c21033e347a", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -20,10 +20,10 @@ pub fn expand_trace_macros(cx: &mut ExtCtxt,\n                            tt: &[ast::TokenTree])\n                            -> Box<base::MacResult+'static> {\n     match tt {\n-        [ast::TTToken(_, ref tok)] if is_keyword(keywords::True, tok) => {\n+        [ast::TtToken(_, ref tok)] if is_keyword(keywords::True, tok) => {\n             cx.set_trace_macros(true);\n         }\n-        [ast::TTToken(_, ref tok)] if is_keyword(keywords::False, tok) => {\n+        [ast::TtToken(_, ref tok)] if is_keyword(keywords::False, tok) => {\n             cx.set_trace_macros(false);\n         }\n         _ => cx.span_err(sp, \"trace_macros! accepts only `true` or `false`\"),"}, {"sha": "75ad2e0fde88472e46060d3e64e8b8de7297b011", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TTDelimited};\n+use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TtDelimited};\n use ast;\n use codemap::{Span, Spanned, DUMMY_SP};\n use ext::base::{ExtCtxt, MacResult, MacroDef};\n@@ -172,7 +172,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     MatchedNonterminal(NtTT(ref tt)) => {\n                         match **tt {\n                             // ignore delimiters\n-                            TTDelimited(_, _, ref tts, _) => (**tts).clone(),\n+                            TtDelimited(_, _, ref tts, _) => (**tts).clone(),\n                             _ => cx.span_fatal(sp, \"macro rhs must be delimited\"),\n                         }\n                     },"}, {"sha": "59b87afe0ee082f595a223fcac4ebbab190fadde", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -9,7 +9,7 @@\n // except according to those terms.\n \n use ast;\n-use ast::{TokenTree, TTDelimited, TTToken, TTSequence, TTNonterminal, Ident};\n+use ast::{TokenTree, TtDelimited, TtToken, TtSequence, TtNonterminal, Ident};\n use codemap::{Span, DUMMY_SP};\n use diagnostic::SpanHandler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n@@ -45,7 +45,7 @@ pub struct TtReader<'a> {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TTSequence`s and `TTNonterminal`s, `interp` can (and\n+/// `src` contains no `TtSequence`s and `TtNonterminal`s, `interp` can (and\n /// should) be none.\n pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n                          interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n@@ -130,13 +130,13 @@ fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n     match *t {\n         // The opening and closing delimiters are both tokens, so they are\n         // treated as `LisUnconstrained`.\n-        TTDelimited(_, _, ref tts, _) | TTSequence(_, ref tts, _, _) => {\n+        TtDelimited(_, _, ref tts, _) | TtSequence(_, ref tts, _, _) => {\n             tts.iter().fold(LisUnconstrained, |size, tt| {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n-        TTToken(..) => LisUnconstrained,\n-        TTNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n+        TtToken(..) => LisUnconstrained,\n+        TtNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n             MatchedNonterminal(_) => LisUnconstrained,\n             MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name)\n         },\n@@ -194,15 +194,15 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             }\n         }\n     }\n-    loop { /* because it's easiest, this handles `TTDelimited` not starting\n-              with a `TTToken`, even though it won't happen */\n+    loop { /* because it's easiest, this handles `TtDelimited` not starting\n+              with a `TtToken`, even though it won't happen */\n         let t = {\n             let frame = r.stack.last().unwrap();\n             // FIXME(pcwalton): Bad copy.\n             (*frame.forest)[frame.idx].clone()\n         };\n         match t {\n-            TTDelimited(_, open, tts, close) => {\n+            TtDelimited(_, open, tts, close) => {\n                 let mut forest = Vec::with_capacity(1 + tts.len() + 1);\n                 forest.push(open.to_tt());\n                 forest.extend(tts.iter().map(|x| (*x).clone()));\n@@ -216,15 +216,15 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 });\n                 // if this could be 0-length, we'd need to potentially recur here\n             }\n-            TTToken(sp, tok) => {\n+            TtToken(sp, tok) => {\n                 r.cur_span = sp;\n                 r.cur_tok = tok;\n                 r.stack.last_mut().unwrap().idx += 1;\n                 return ret_val;\n             }\n-            TTSequence(sp, tts, sep, zerok) => {\n+            TtSequence(sp, tts, sep, zerok) => {\n                 // FIXME(pcwalton): Bad copy.\n-                match lockstep_iter_size(&TTSequence(sp, tts.clone(), sep.clone(), zerok), r) {\n+                match lockstep_iter_size(&TtSequence(sp, tts.clone(), sep.clone(), zerok), r) {\n                     LisUnconstrained => {\n                         r.sp_diag.span_fatal(\n                             sp.clone(), /* blame macro writer */\n@@ -259,7 +259,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n-            TTNonterminal(sp, ident) => {\n+            TtNonterminal(sp, ident) => {\n                 r.stack.last_mut().unwrap().idx += 1;\n                 match *lookup_cur_matched(r, ident) {\n                     /* sidestep the interpolation tricks for ident because"}, {"sha": "2dfa69b1f38208f2ad21a59206efdd6231789ea0", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -569,10 +569,10 @@ pub fn noop_fold_arg<T: Folder>(Arg {id, pat, ty}: Arg, fld: &mut T) -> Arg {\n \n pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n     match *tt {\n-        TTToken(span, ref tok) =>\n-            TTToken(span, fld.fold_token(tok.clone())),\n-        TTDelimited(span, ref open, ref tts, ref close) =>\n-            TTDelimited(span,\n+        TtToken(span, ref tok) =>\n+            TtToken(span, fld.fold_token(tok.clone())),\n+        TtDelimited(span, ref open, ref tts, ref close) =>\n+            TtDelimited(span,\n                         Delimiter {\n                             span: open.span,\n                             token: fld.fold_token(open.token.clone())\n@@ -582,13 +582,13 @@ pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n                             span: close.span,\n                             token: fld.fold_token(close.token.clone())\n                         }),\n-        TTSequence(span, ref pattern, ref sep, is_optional) =>\n-            TTSequence(span,\n+        TtSequence(span, ref pattern, ref sep, is_optional) =>\n+            TtSequence(span,\n                        Rc::new(fld.fold_tts(pattern.as_slice())),\n                        sep.clone().map(|tok| fld.fold_token(tok)),\n                        is_optional),\n-        TTNonterminal(sp,ref ident) =>\n-            TTNonterminal(sp,fld.fold_ident(*ident))\n+        TtNonterminal(sp,ref ident) =>\n+            TtNonterminal(sp,fld.fold_ident(*ident))\n     }\n }\n "}, {"sha": "d7438f11a94684c9510a55f2e1a2707099d677c8", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -793,29 +793,29 @@ mod test {\n         let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n         let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n-            [ast::TTToken(_, _),\n-             ast::TTToken(_, token::NOT),\n-             ast::TTToken(_, _),\n-             ast::TTDelimited(_, ast::TTToken(_, token::LPAREN),\n+            [ast::TtToken(_, _),\n+             ast::TtToken(_, token::NOT),\n+             ast::TtToken(_, _),\n+             ast::TtDelimited(_, ast::TtToken(_, token::LPAREN),\n                           ref delim_elts,\n-                          ast::TTToken(_, token::RPAREN))] => {\n+                          ast::TtToken(_, token::RPAREN))] => {\n                 let delim_elts: &[ast::TokenTree] = delim_elts.as_slice();\n                 match delim_elts {\n-                    [ast::TTDelimited(_, ast::TTToken(_, token::LPAREN),\n+                    [ast::TtDelimited(_, ast::TtToken(_, token::LPAREN),\n                                   ref first_set,\n-                                  ast::TTToken(_, token::RPAREN)),\n-                     ast::TTToken(_, token::FAT_ARROW),\n-                     ast::TTDelimited(_, ast::TTToken(_, token::LPAREN),\n+                                  ast::TtToken(_, token::RPAREN)),\n+                     ast::TtToken(_, token::FAT_ARROW),\n+                     ast::TtDelimited(_, ast::TtToken(_, token::LPAREN),\n                                   ref second_set,\n-                                  ast::TTToken(_, token::RPAREN))] => {\n+                                  ast::TtToken(_, token::RPAREN))] => {\n                         let first_set: &[ast::TokenTree] =\n                             first_set.as_slice();\n                         match first_set {\n-                            [ast::TTToken(_, token::DOLLAR), ast::TTToken(_, _)] => {\n+                            [ast::TtToken(_, token::DOLLAR), ast::TtToken(_, _)] => {\n                                 let second_set: &[ast::TokenTree] =\n                                     second_set.as_slice();\n                                 match second_set {\n-                                    [ast::TTToken(_, token::DOLLAR), ast::TTToken(_, _)] => {\n+                                    [ast::TtToken(_, token::DOLLAR), ast::TtToken(_, _)] => {\n                                         assert_eq!(\"correct\",\"correct\")\n                                     }\n                                     _ => assert_eq!(\"wrong 4\",\"correct\")\n@@ -845,7 +845,7 @@ mod test {\n         assert_eq!(json::encode(&tts),\n         \"[\\\n     {\\\n-        \\\"variant\\\":\\\"TTToken\\\",\\\n+        \\\"variant\\\":\\\"TtToken\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n             {\\\n@@ -858,7 +858,7 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTToken\\\",\\\n+        \\\"variant\\\":\\\"TtToken\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n             {\\\n@@ -871,18 +871,18 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTDelimited\\\",\\\n+        \\\"variant\\\":\\\"TtDelimited\\\",\\\n         \\\"fields\\\":[\\\n             [\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"LPAREN\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         {\\\n@@ -895,14 +895,14 @@ mod test {\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"COLON\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         {\\\n@@ -915,7 +915,7 @@ mod test {\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"RPAREN\\\"\\\n@@ -925,18 +925,18 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTDelimited\\\",\\\n+        \\\"variant\\\":\\\"TtDelimited\\\",\\\n         \\\"fields\\\":[\\\n             [\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"LBRACE\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         {\\\n@@ -949,14 +949,14 @@ mod test {\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"SEMI\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTToken\\\",\\\n+                    \\\"variant\\\":\\\"TtToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"RBRACE\\\"\\"}, {"sha": "ebca362b9d8571460f24cd45691cde3eeb8e68f7", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -48,8 +48,8 @@ use ast::{StmtExpr, StmtSemi, StmtMac, StructDef, StructField};\n use ast::{StructVariantKind, BiSub};\n use ast::StrStyle;\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n-use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TTDelimited, TTSequence, TTToken};\n-use ast::{TTNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n+use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TtDelimited, TtSequence, TtToken};\n+use ast::{TtNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n use ast::{TypeField, TyFixedLengthVec, TyClosure, TyProc, TyBareFn};\n use ast::{TyTypeof, TyInfer, TypeMethod};\n use ast::{TyNil, TyParam, TyParamBound, TyParen, TyPath, TyPtr, TyQPath};\n@@ -2526,8 +2526,8 @@ impl<'a> Parser<'a> {\n     /// parse a single token tree from the input.\n     pub fn parse_token_tree(&mut self) -> TokenTree {\n         // FIXME #6994: currently, this is too eager. It\n-        // parses token trees but also identifies TTSequence's\n-        // and TTNonterminal's; it's too early to know yet\n+        // parses token trees but also identifies TtSequence's\n+        // and TtNonterminal's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n         maybe_whole!(deref self, NtTT);\n@@ -2568,13 +2568,13 @@ impl<'a> Parser<'a> {\n                     let seq = match seq {\n                         Spanned { node, .. } => node,\n                     };\n-                    TTSequence(mk_sp(sp.lo, p.span.hi), Rc::new(seq), s, z)\n+                    TtSequence(mk_sp(sp.lo, p.span.hi), Rc::new(seq), s, z)\n                 } else {\n-                    TTNonterminal(sp, p.parse_ident())\n+                    TtNonterminal(sp, p.parse_ident())\n                 }\n               }\n               _ => {\n-                  TTToken(p.span, p.bump_and_get())\n+                  TtToken(p.span, p.bump_and_get())\n               }\n             }\n         }\n@@ -2615,7 +2615,7 @@ impl<'a> Parser<'a> {\n                 // Expand to cover the entire delimited token tree\n                 let span = Span { hi: self.span.hi, ..pre_span };\n \n-                TTDelimited(span, open, Rc::new(tts), close)\n+                TtDelimited(span, open, Rc::new(tts), close)\n             }\n             _ => parse_non_delim_tt_tok(self)\n         }"}, {"sha": "e3b7a16410886bc6f2bdd6d5fd2eab193702efd0", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -1020,14 +1020,14 @@ impl<'a> State<'a> {\n     /// expression arguments as expressions). It can be done! I think.\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> IoResult<()> {\n         match *tt {\n-            ast::TTDelimited(_, ref open, ref tts, ref close) => {\n+            ast::TtDelimited(_, ref open, ref tts, ref close) => {\n                 try!(word(&mut self.s, parse::token::to_string(&open.token).as_slice()));\n                 try!(space(&mut self.s));\n                 try!(self.print_tts(tts.as_slice()));\n                 try!(space(&mut self.s));\n                 word(&mut self.s, parse::token::to_string(&close.token).as_slice())\n             },\n-            ast::TTToken(_, ref tk) => {\n+            ast::TtToken(_, ref tk) => {\n                 try!(word(&mut self.s, parse::token::to_string(tk).as_slice()));\n                 match *tk {\n                     parse::token::DOC_COMMENT(..) => {\n@@ -1036,7 +1036,7 @@ impl<'a> State<'a> {\n                     _ => Ok(())\n                 }\n             }\n-            ast::TTSequence(_, ref tts, ref sep, zerok) => {\n+            ast::TtSequence(_, ref tts, ref sep, zerok) => {\n                 try!(word(&mut self.s, \"$(\"));\n                 for tt_elt in (*tts).iter() {\n                     try!(self.print_tt(tt_elt));\n@@ -1051,7 +1051,7 @@ impl<'a> State<'a> {\n                 }\n                 word(&mut self.s, if zerok { \"*\" } else { \"+\" })\n             }\n-            ast::TTNonterminal(_, name) => {\n+            ast::TtNonterminal(_, name) => {\n                 try!(word(&mut self.s, \"$\"));\n                 self.print_ident(name)\n             }"}, {"sha": "40ed3a35ddf134bb6b6f9b174bb704d800738314", "filename": "src/test/auxiliary/roman_numerals.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dfb4163f8380e9a1aaf64a7474de30634bca4034/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Froman_numerals.rs?ref=dfb4163f8380e9a1aaf64a7474de30634bca4034", "patch": "@@ -18,7 +18,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{IDENT, get_ident};\n-use syntax::ast::{TokenTree, TTToken};\n+use syntax::ast::{TokenTree, TtToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n use syntax::ext::build::AstBuilder;  // trait for expr_uint\n use rustc::plugin::Registry;\n@@ -39,7 +39,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TTToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n+        [TtToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}]}