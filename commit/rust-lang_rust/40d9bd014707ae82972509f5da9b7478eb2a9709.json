{"sha": "40d9bd014707ae82972509f5da9b7478eb2a9709", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQwZDliZDAxNDcwN2FlODI5NzI1MDlmNWRhOWI3NDc4ZWIyYTk3MDk=", "commit": {"author": {"name": "ljedrz", "email": "ljedrz@gmail.com", "date": "2018-08-12T13:43:51Z"}, "committer": {"name": "ljedrz", "email": "ljedrz@gmail.com", "date": "2018-08-13T10:57:25Z"}, "message": "A few cleanups and minor improvements for the lexer", "tree": {"sha": "413fb17721a5e64c39411e3033ad20bf5493ee50", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/413fb17721a5e64c39411e3033ad20bf5493ee50"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/40d9bd014707ae82972509f5da9b7478eb2a9709", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/40d9bd014707ae82972509f5da9b7478eb2a9709", "html_url": "https://github.com/rust-lang/rust/commit/40d9bd014707ae82972509f5da9b7478eb2a9709", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/40d9bd014707ae82972509f5da9b7478eb2a9709/comments", "author": {"login": "ljedrz", "id": 3750347, "node_id": "MDQ6VXNlcjM3NTAzNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/3750347?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ljedrz", "html_url": "https://github.com/ljedrz", "followers_url": "https://api.github.com/users/ljedrz/followers", "following_url": "https://api.github.com/users/ljedrz/following{/other_user}", "gists_url": "https://api.github.com/users/ljedrz/gists{/gist_id}", "starred_url": "https://api.github.com/users/ljedrz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ljedrz/subscriptions", "organizations_url": "https://api.github.com/users/ljedrz/orgs", "repos_url": "https://api.github.com/users/ljedrz/repos", "events_url": "https://api.github.com/users/ljedrz/events{/privacy}", "received_events_url": "https://api.github.com/users/ljedrz/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ljedrz", "id": 3750347, "node_id": "MDQ6VXNlcjM3NTAzNDc=", "avatar_url": "https://avatars.githubusercontent.com/u/3750347?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ljedrz", "html_url": "https://github.com/ljedrz", "followers_url": "https://api.github.com/users/ljedrz/followers", "following_url": "https://api.github.com/users/ljedrz/following{/other_user}", "gists_url": "https://api.github.com/users/ljedrz/gists{/gist_id}", "starred_url": "https://api.github.com/users/ljedrz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ljedrz/subscriptions", "organizations_url": "https://api.github.com/users/ljedrz/orgs", "repos_url": "https://api.github.com/users/ljedrz/repos", "events_url": "https://api.github.com/users/ljedrz/events{/privacy}", "received_events_url": "https://api.github.com/users/ljedrz/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0aa8d0320266b5579428312095fe49af05ada972", "url": "https://api.github.com/repos/rust-lang/rust/commits/0aa8d0320266b5579428312095fe49af05ada972", "html_url": "https://github.com/rust-lang/rust/commit/0aa8d0320266b5579428312095fe49af05ada972"}], "stats": {"total": 208, "additions": 134, "deletions": 74}, "files": [{"sha": "2c53dbdc402a5b2c415919adb12382a10d9efd5e", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 16, "deletions": 6, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=40d9bd014707ae82972509f5da9b7478eb2a9709", "patch": "@@ -63,6 +63,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n         if !lines.is_empty() && lines[0].chars().all(|c| c == '*') {\n             i += 1;\n         }\n+\n         while i < j && lines[i].trim().is_empty() {\n             i += 1;\n         }\n@@ -74,9 +75,11 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n                .all(|c| c == '*') {\n             j -= 1;\n         }\n+\n         while j > i && lines[j - 1].trim().is_empty() {\n             j -= 1;\n         }\n+\n         lines[i..j].to_vec()\n     }\n \n@@ -85,6 +88,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n         let mut i = usize::MAX;\n         let mut can_trim = true;\n         let mut first = true;\n+\n         for line in &lines {\n             for (j, c) in line.chars().enumerate() {\n                 if j > i || !\"* \\t\".contains(c) {\n@@ -119,7 +123,8 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n     }\n \n     // one-line comments lose their prefix\n-    const ONELINERS: &'static [&'static str] = &[\"///!\", \"///\", \"//!\", \"//\"];\n+    const ONELINERS: &[&str] = &[\"///!\", \"///\", \"//!\", \"//\"];\n+\n     for prefix in ONELINERS {\n         if comment.starts_with(*prefix) {\n             return (&comment[prefix.len()..]).to_string();\n@@ -205,6 +210,7 @@ fn all_whitespace(s: &str, col: CharPos) -> Option<usize> {\n     let len = s.len();\n     let mut col = col.to_usize();\n     let mut cursor: usize = 0;\n+\n     while col > 0 && cursor < len {\n         let ch = char_at(s, cursor);\n         if !ch.is_whitespace() {\n@@ -213,7 +219,8 @@ fn all_whitespace(s: &str, col: CharPos) -> Option<usize> {\n         cursor += ch.len_utf8();\n         col -= 1;\n     }\n-    return Some(cursor);\n+\n+    Some(cursor)\n }\n \n fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<String>, s: String, col: CharPos) {\n@@ -246,11 +253,13 @@ fn read_block_comment(rdr: &mut StringReader,\n         \"src_index={}, end_src_index={}, line_begin_pos={}\",\n         src_index, end_src_index, rdr.filemap.line_begin_pos(rdr.pos).to_u32());\n     let mut n = 0;\n+\n     while src_index < end_src_index {\n         let c = char_at(&rdr.src, src_index);\n         src_index += c.len_utf8();\n         n += 1;\n     }\n+\n     let col = CharPos(n);\n \n     rdr.bump();\n@@ -358,10 +367,10 @@ pub struct Literal {\n // it appears this function is called only from pprust... that's\n // probably not a good thing.\n pub fn gather_comments_and_literals(sess: &ParseSess, path: FileName, srdr: &mut dyn Read)\n-                                    -> (Vec<Comment>, Vec<Literal>) {\n-    let mut src = Vec::new();\n-    srdr.read_to_end(&mut src).unwrap();\n-    let src = String::from_utf8(src).unwrap();\n+    -> (Vec<Comment>, Vec<Literal>)\n+{\n+    let mut src = String::new();\n+    srdr.read_to_string(&mut src).unwrap();\n     let cm = CodeMap::new(sess.codemap().path_mapping().clone());\n     let filemap = cm.new_filemap(path, src);\n     let mut rdr = lexer::StringReader::new_raw(sess, filemap, None);\n@@ -370,6 +379,7 @@ pub fn gather_comments_and_literals(sess: &ParseSess, path: FileName, srdr: &mut\n     let mut literals: Vec<Literal> = Vec::new();\n     let mut code_to_the_left = false; // Only code\n     let mut anything_to_the_left = false; // Code or comments\n+\n     while !rdr.is_eof() {\n         loop {\n             // Eat all the whitespace and count blank lines."}, {"sha": "5913c63bfaa5f6f238c0bbff004d3685deb98a6d", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 112, "deletions": 67, "changes": 179, "blob_url": "https://github.com/rust-lang/rust/blob/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=40d9bd014707ae82972509f5da9b7478eb2a9709", "patch": "@@ -73,23 +73,23 @@ impl<'a> StringReader<'a> {\n     fn mk_sp(&self, lo: BytePos, hi: BytePos) -> Span {\n         self.mk_sp_and_raw(lo, hi).0\n     }\n+\n     fn mk_sp_and_raw(&self, lo: BytePos, hi: BytePos) -> (Span, Span) {\n         let raw = Span::new(lo, hi, NO_EXPANSION);\n-        let real = unwrap_or!(self.override_span, raw);\n+        let real = self.override_span.unwrap_or(raw);\n+\n         (real, raw)\n     }\n+\n     fn mk_ident(&self, string: &str) -> Ident {\n         let mut ident = Ident::from_str(string);\n         if let Some(span) = self.override_span {\n             ident.span = span;\n         }\n+\n         ident\n     }\n \n-    fn next_token(&mut self) -> TokenAndSpan where Self: Sized {\n-        let res = self.try_next_token();\n-        self.unwrap_or_abort(res)\n-    }\n     fn unwrap_or_abort(&mut self, res: Result<TokenAndSpan, ()>) -> TokenAndSpan {\n         match res {\n             Ok(tok) => tok,\n@@ -99,6 +99,25 @@ impl<'a> StringReader<'a> {\n             }\n         }\n     }\n+\n+    fn next_token(&mut self) -> TokenAndSpan where Self: Sized {\n+        let res = self.try_next_token();\n+        self.unwrap_or_abort(res)\n+    }\n+\n+    /// Return the next token. EFFECT: advances the string_reader.\n+    pub fn try_next_token(&mut self) -> Result<TokenAndSpan, ()> {\n+        assert!(self.fatal_errs.is_empty());\n+        let ret_val = TokenAndSpan {\n+            tok: replace(&mut self.peek_tok, token::Whitespace),\n+            sp: self.peek_span,\n+        };\n+        self.advance_token()?;\n+        self.span_src_raw = self.peek_span_src_raw;\n+\n+        Ok(ret_val)\n+    }\n+\n     fn try_real_token(&mut self) -> Result<TokenAndSpan, ()> {\n         let mut t = self.try_next_token()?;\n         loop {\n@@ -109,49 +128,48 @@ impl<'a> StringReader<'a> {\n                 _ => break,\n             }\n         }\n+\n         self.token = t.tok.clone();\n         self.span = t.sp;\n+\n         Ok(t)\n     }\n+\n     pub fn real_token(&mut self) -> TokenAndSpan {\n         let res = self.try_real_token();\n         self.unwrap_or_abort(res)\n     }\n+\n+    #[inline]\n     fn is_eof(&self) -> bool {\n         self.ch.is_none()\n     }\n-    /// Return the next token. EFFECT: advances the string_reader.\n-    pub fn try_next_token(&mut self) -> Result<TokenAndSpan, ()> {\n-        assert!(self.fatal_errs.is_empty());\n-        let ret_val = TokenAndSpan {\n-            tok: replace(&mut self.peek_tok, token::Whitespace),\n-            sp: self.peek_span,\n-        };\n-        self.advance_token()?;\n-        self.span_src_raw = self.peek_span_src_raw;\n-        Ok(ret_val)\n-    }\n \n     fn fail_unterminated_raw_string(&self, pos: BytePos, hash_count: u16) {\n         let mut err = self.struct_span_fatal(pos, pos, \"unterminated raw string\");\n         err.span_label(self.mk_sp(pos, pos), \"unterminated raw string\");\n+\n         if hash_count > 0 {\n             err.note(&format!(\"this raw string should be terminated with `\\\"{}`\",\n                               \"#\".repeat(hash_count as usize)));\n         }\n+\n         err.emit();\n         FatalError.raise();\n     }\n \n     fn fatal(&self, m: &str) -> FatalError {\n         self.fatal_span(self.peek_span, m)\n     }\n+\n     pub fn emit_fatal_errors(&mut self) {\n         for err in &mut self.fatal_errs {\n             err.emit();\n         }\n+\n         self.fatal_errs.clear();\n     }\n+\n     pub fn peek(&self) -> TokenAndSpan {\n         // FIXME(pcwalton): Bad copy!\n         TokenAndSpan {\n@@ -161,15 +179,18 @@ impl<'a> StringReader<'a> {\n     }\n \n     /// For comments.rs, which hackily pokes into next_pos and ch\n-    fn new_raw(sess: &'a ParseSess, filemap: Lrc<syntax_pos::FileMap>,\n-                   override_span: Option<Span>) -> Self {\n+    fn new_raw(sess: &'a ParseSess, filemap: Lrc<syntax_pos::FileMap>, override_span: Option<Span>)\n+        -> Self\n+    {\n         let mut sr = StringReader::new_raw_internal(sess, filemap, override_span);\n         sr.bump();\n+\n         sr\n     }\n \n     fn new_raw_internal(sess: &'a ParseSess, filemap: Lrc<syntax_pos::FileMap>,\n-                        override_span: Option<Span>) -> Self {\n+        override_span: Option<Span>) -> Self\n+    {\n         if filemap.src.is_none() {\n             sess.span_diagnostic.bug(&format!(\"Cannot lex filemap without source: {}\",\n                                               filemap.name));\n@@ -199,12 +220,14 @@ impl<'a> StringReader<'a> {\n     }\n \n     pub fn new(sess: &'a ParseSess, filemap: Lrc<syntax_pos::FileMap>, override_span: Option<Span>)\n-               -> Self {\n+        -> Self\n+    {\n         let mut sr = StringReader::new_raw(sess, filemap, override_span);\n         if sr.advance_token().is_err() {\n             sr.emit_fatal_errors();\n             FatalError.raise();\n         }\n+\n         sr\n     }\n \n@@ -229,9 +252,11 @@ impl<'a> StringReader<'a> {\n             sr.emit_fatal_errors();\n             FatalError.raise();\n         }\n+\n         sr\n     }\n \n+    #[inline]\n     fn ch_is(&self, c: char) -> bool {\n         self.ch == Some(c)\n     }\n@@ -276,26 +301,23 @@ impl<'a> StringReader<'a> {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n         Self::push_escaped_char_for_msg(&mut m, c);\n+\n         self.fatal_span_(from_pos, to_pos, &m[..])\n     }\n \n-    fn struct_span_fatal(&self,\n-                         from_pos: BytePos,\n-                         to_pos: BytePos,\n-                         m: &str)\n-                         -> DiagnosticBuilder<'a> {\n+    fn struct_span_fatal(&self, from_pos: BytePos, to_pos: BytePos, m: &str)\n+        -> DiagnosticBuilder<'a>\n+    {\n         self.sess.span_diagnostic.struct_span_fatal(self.mk_sp(from_pos, to_pos), m)\n     }\n \n-    fn struct_fatal_span_char(&self,\n-                              from_pos: BytePos,\n-                              to_pos: BytePos,\n-                              m: &str,\n-                              c: char)\n-                              -> DiagnosticBuilder<'a> {\n+    fn struct_fatal_span_char(&self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char)\n+        -> DiagnosticBuilder<'a>\n+    {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n         Self::push_escaped_char_for_msg(&mut m, c);\n+\n         self.sess.span_diagnostic.struct_span_fatal(self.mk_sp(from_pos, to_pos), &m[..])\n     }\n \n@@ -307,15 +329,14 @@ impl<'a> StringReader<'a> {\n         Self::push_escaped_char_for_msg(&mut m, c);\n         self.err_span_(from_pos, to_pos, &m[..]);\n     }\n-    fn struct_err_span_char(&self,\n-                            from_pos: BytePos,\n-                            to_pos: BytePos,\n-                            m: &str,\n-                            c: char)\n-                            -> DiagnosticBuilder<'a> {\n+\n+    fn struct_err_span_char(&self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char)\n+        -> DiagnosticBuilder<'a>\n+    {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n         Self::push_escaped_char_for_msg(&mut m, c);\n+\n         self.sess.span_diagnostic.struct_span_err(self.mk_sp(from_pos, to_pos), &m[..])\n     }\n \n@@ -324,6 +345,7 @@ impl<'a> StringReader<'a> {\n     fn fatal_span_verbose(&self, from_pos: BytePos, to_pos: BytePos, mut m: String) -> FatalError {\n         m.push_str(\": \");\n         m.push_str(&self.src[self.src_index(from_pos)..self.src_index(to_pos)]);\n+\n         self.fatal_span_(from_pos, to_pos, &m[..])\n     }\n \n@@ -354,6 +376,7 @@ impl<'a> StringReader<'a> {\n                 };\n             }\n         }\n+\n         Ok(())\n     }\n \n@@ -468,6 +491,7 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n+    #[inline]\n     fn nextch_is(&self, c: char) -> bool {\n         self.nextch() == Some(c)\n     }\n@@ -484,6 +508,7 @@ impl<'a> StringReader<'a> {\n         None\n     }\n \n+    #[inline]\n     fn nextnextch_is(&self, c: char) -> bool {\n         self.nextnextch() == Some(c)\n     }\n@@ -493,8 +518,10 @@ impl<'a> StringReader<'a> {\n         if !ident_start(self.ch) {\n             return None;\n         }\n+\n         let start = self.pos;\n         self.bump();\n+\n         while ident_continue(self.ch) {\n             self.bump();\n         }\n@@ -709,6 +736,7 @@ impl<'a> StringReader<'a> {\n     fn scan_digits(&mut self, real_radix: u32, scan_radix: u32) -> usize {\n         assert!(real_radix <= scan_radix);\n         let mut len = 0;\n+\n         loop {\n             let c = self.ch;\n             if c == Some('_') {\n@@ -736,47 +764,44 @@ impl<'a> StringReader<'a> {\n \n     /// Lex a LIT_INTEGER or a LIT_FLOAT\n     fn scan_number(&mut self, c: char) -> token::Lit {\n-        let num_digits;\n         let mut base = 10;\n         let start_bpos = self.pos;\n-\n         self.bump();\n \n-        if c == '0' {\n+        let num_digits = if c == '0' {\n             match self.ch.unwrap_or('\\0') {\n                 'b' => {\n                     self.bump();\n                     base = 2;\n-                    num_digits = self.scan_digits(2, 10);\n+                    self.scan_digits(2, 10)\n                 }\n                 'o' => {\n                     self.bump();\n                     base = 8;\n-                    num_digits = self.scan_digits(8, 10);\n+                    self.scan_digits(8, 10)\n                 }\n                 'x' => {\n                     self.bump();\n                     base = 16;\n-                    num_digits = self.scan_digits(16, 16);\n+                    self.scan_digits(16, 16)\n                 }\n                 '0'..='9' | '_' | '.' | 'e' | 'E' => {\n-                    num_digits = self.scan_digits(10, 10) + 1;\n+                    self.scan_digits(10, 10) + 1\n                 }\n                 _ => {\n                     // just a 0\n                     return token::Integer(self.name_from(start_bpos));\n                 }\n             }\n         } else if c.is_digit(10) {\n-            num_digits = self.scan_digits(10, 10) + 1;\n+            self.scan_digits(10, 10) + 1\n         } else {\n-            num_digits = 0;\n-        }\n+            0\n+        };\n \n         if num_digits == 0 {\n-            self.err_span_(start_bpos,\n-                           self.pos,\n-                           \"no valid digits found for number\");\n+            self.err_span_(start_bpos, self.pos, \"no valid digits found for number\");\n+\n             return token::Integer(Symbol::intern(\"0\"));\n         }\n \n@@ -794,6 +819,7 @@ impl<'a> StringReader<'a> {\n             }\n             let pos = self.pos;\n             self.check_float_base(start_bpos, pos, base);\n+\n             token::Float(self.name_from(start_bpos))\n         } else {\n             // it might be a float if it has an exponent\n@@ -873,7 +899,8 @@ impl<'a> StringReader<'a> {\n                          first_source_char: char,\n                          ascii_only: bool,\n                          delim: char)\n-                         -> bool {\n+                         -> bool\n+    {\n         match first_source_char {\n             '\\\\' => {\n                 // '\\X' for some X must be a character constant:\n@@ -1008,6 +1035,7 @@ impl<'a> StringReader<'a> {\n                            \"overlong unicode escape (must have at most 6 hex digits)\");\n             valid = false;\n         }\n+\n         loop {\n             match self.ch {\n                 Some('}') => {\n@@ -1043,16 +1071,19 @@ impl<'a> StringReader<'a> {\n             }\n             self.bump();\n         }\n+\n         valid\n     }\n \n     /// Scan over a float exponent.\n     fn scan_float_exponent(&mut self) {\n         if self.ch_is('e') || self.ch_is('E') {\n             self.bump();\n+\n             if self.ch_is('-') || self.ch_is('+') {\n                 self.bump();\n             }\n+\n             if self.scan_digits(10, 10) == 0 {\n                 let mut err = self.struct_span_fatal(\n                     self.pos, self.next_pos,\n@@ -1125,6 +1156,7 @@ impl<'a> StringReader<'a> {\n                     ('b', Some('r'), Some('#')) => (false, false),\n                     _ => (true, false),\n                 };\n+\n             if is_ident_start {\n                 let raw_start = self.pos;\n                 if is_raw_ident {\n@@ -1135,23 +1167,27 @@ impl<'a> StringReader<'a> {\n \n                 let start = self.pos;\n                 self.bump();\n+\n                 while ident_continue(self.ch) {\n                     self.bump();\n                 }\n \n                 return Ok(self.with_str_from(start, |string| {\n                     // FIXME: perform NFKC normalization here. (Issue #2253)\n                     let ident = self.mk_ident(string);\n+\n                     if is_raw_ident && (ident.is_path_segment_keyword() ||\n                                         ident.name == keywords::Underscore.name()) {\n                         self.fatal_span_(raw_start, self.pos,\n                             &format!(\"`r#{}` is not currently supported.\", ident.name)\n                         ).raise();\n                     }\n+\n                     if is_raw_ident {\n                         let span = self.mk_sp(raw_start, self.pos);\n                         self.sess.raw_identifier_spans.borrow_mut().push(span);\n                     }\n+\n                     token::Ident(ident, is_raw_ident)\n                 }));\n             }\n@@ -1337,14 +1373,11 @@ impl<'a> StringReader<'a> {\n                     return Ok(token::Lifetime(ident));\n                 }\n \n-                let valid = self.scan_char_or_byte(start,\n-                                                   c2,\n-                                                   // ascii_only =\n-                                                   false,\n-                                                   '\\'');\n+                let valid = self.scan_char_or_byte(start, c2, /* ascii_only */ false, '\\'');\n \n                 if !self.ch_is('\\'') {\n                     let pos = self.pos;\n+\n                     loop {\n                         self.bump();\n                         if self.ch_is('\\'') {\n@@ -1370,6 +1403,7 @@ impl<'a> StringReader<'a> {\n                             break;\n                         }\n                     }\n+\n                     self.fatal_span_verbose(start_with_quote, pos,\n                         String::from(\"character literal may only contain one codepoint\")).raise();\n                 }\n@@ -1379,8 +1413,10 @@ impl<'a> StringReader<'a> {\n                 } else {\n                     Symbol::intern(\"0\")\n                 };\n+\n                 self.bump(); // advance ch past token\n                 let suffix = self.scan_optional_raw_name();\n+\n                 Ok(token::Literal(token::Char(id), suffix))\n             }\n             'b' => {\n@@ -1392,12 +1428,14 @@ impl<'a> StringReader<'a> {\n                     _ => unreachable!(),  // Should have been a token::Ident above.\n                 };\n                 let suffix = self.scan_optional_raw_name();\n+\n                 Ok(token::Literal(lit, suffix))\n             }\n             '\"' => {\n                 let start_bpos = self.pos;\n                 let mut valid = true;\n                 self.bump();\n+\n                 while !self.ch_is('\"') {\n                     if self.is_eof() {\n                         let last_bpos = self.pos;\n@@ -1409,11 +1447,7 @@ impl<'a> StringReader<'a> {\n                     let ch_start = self.pos;\n                     let ch = self.ch.unwrap();\n                     self.bump();\n-                    valid &= self.scan_char_or_byte(ch_start,\n-                                                    ch,\n-                                                    // ascii_only =\n-                                                    false,\n-                                                    '\"');\n+                    valid &= self.scan_char_or_byte(ch_start, ch, /* ascii_only */ false, '\"');\n                 }\n                 // adjust for the ASCII \" at the start of the literal\n                 let id = if valid {\n@@ -1423,6 +1457,7 @@ impl<'a> StringReader<'a> {\n                 };\n                 self.bump();\n                 let suffix = self.scan_optional_raw_name();\n+\n                 Ok(token::Literal(token::Str_(id), suffix))\n             }\n             'r' => {\n@@ -1492,13 +1527,15 @@ impl<'a> StringReader<'a> {\n                     }\n                     self.bump();\n                 }\n+\n                 self.bump();\n                 let id = if valid {\n                     self.name_from_to(content_start_bpos, content_end_bpos)\n                 } else {\n                     Symbol::intern(\"??\")\n                 };\n                 let suffix = self.scan_optional_raw_name();\n+\n                 Ok(token::Literal(token::StrRaw(id, hash_count), suffix))\n             }\n             '-' => {\n@@ -1555,6 +1592,7 @@ impl<'a> StringReader<'a> {\n                                                           c);\n                 unicode_chars::check_for_substitution(self, c, &mut err);\n                 self.fatal_errs.push(err);\n+\n                 Err(())\n             }\n         }\n@@ -1572,9 +1610,11 @@ impl<'a> StringReader<'a> {\n             val.push(self.ch.unwrap());\n             self.bump();\n         }\n+\n         if self.ch_is('\\n') {\n             self.bump();\n         }\n+\n         val\n     }\n \n@@ -1626,9 +1666,11 @@ impl<'a> StringReader<'a> {\n             Symbol::intern(\"?\")\n         };\n         self.bump(); // advance ch past token\n+\n         token::Byte(id)\n     }\n \n+    #[inline]\n     fn scan_byte_escape(&mut self, delim: char, below_0x7f_only: bool) -> bool {\n         self.scan_hex_digits(2, delim, below_0x7f_only)\n     }\n@@ -1653,12 +1695,14 @@ impl<'a> StringReader<'a> {\n                                             true,\n                                             '\"');\n         }\n+\n         let id = if valid {\n             self.name_from(start)\n         } else {\n             Symbol::intern(\"??\")\n         };\n         self.bump();\n+\n         token::ByteStr(id)\n     }\n \n@@ -1716,25 +1760,26 @@ impl<'a> StringReader<'a> {\n             }\n             self.bump();\n         }\n+\n         self.bump();\n-        token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos),\n-                                 hash_count)\n+\n+        token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos), hash_count)\n     }\n }\n \n // This tests the character for the unicode property 'PATTERN_WHITE_SPACE' which\n // is guaranteed to be forward compatible. http://unicode.org/reports/tr31/#R3\n+#[inline]\n crate fn is_pattern_whitespace(c: Option<char>) -> bool {\n     c.map_or(false, Pattern_White_Space)\n }\n \n+#[inline]\n fn in_range(c: Option<char>, lo: char, hi: char) -> bool {\n-    match c {\n-        Some(c) => lo <= c && c <= hi,\n-        _ => false,\n-    }\n+    c.map_or(false, |c| lo <= c && c <= hi)\n }\n \n+#[inline]\n fn is_dec_digit(c: Option<char>) -> bool {\n     in_range(c, '0', '9')\n }"}, {"sha": "1e7855e68ddc64efa04f6f738e11ae63e2b06881", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=40d9bd014707ae82972509f5da9b7478eb2a9709", "patch": "@@ -17,9 +17,11 @@ impl<'a> StringReader<'a> {\n     // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n     crate fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n         let mut tts = Vec::new();\n+\n         while self.token != token::Eof {\n             tts.push(self.parse_token_tree()?);\n         }\n+\n         Ok(TokenStream::concat(tts))\n     }\n \n@@ -30,6 +32,7 @@ impl<'a> StringReader<'a> {\n             if let token::CloseDelim(..) = self.token {\n                 return TokenStream::concat(tts);\n             }\n+\n             match self.parse_token_tree() {\n                 Ok(tree) => tts.push(tree),\n                 Err(mut e) => {\n@@ -48,6 +51,7 @@ impl<'a> StringReader<'a> {\n                 for &(_, sp) in &self.open_braces {\n                     err.span_help(sp, \"did you mean to close this delimiter?\");\n                 }\n+\n                 Err(err)\n             },\n             token::OpenDelim(delim) => {\n@@ -129,6 +133,7 @@ impl<'a> StringReader<'a> {\n                 let raw = self.span_src_raw;\n                 self.real_token();\n                 let is_joint = raw.hi() == self.span_src_raw.lo() && token::is_op(&self.token);\n+\n                 Ok(if is_joint { tt.joint() } else { tt.into() })\n             }\n         }"}, {"sha": "88ff8582da80194ec0c24936970cf8517f9f350b", "filename": "src/libsyntax/parse/lexer/unicode_chars.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/40d9bd014707ae82972509f5da9b7478eb2a9709/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs?ref=40d9bd014707ae82972509f5da9b7478eb2a9709", "patch": "@@ -15,7 +15,7 @@ use syntax_pos::{Span, NO_EXPANSION};\n use errors::DiagnosticBuilder;\n use super::StringReader;\n \n-const UNICODE_ARRAY: &'static [(char, &'static str, char)] = &[\n+const UNICODE_ARRAY: &[(char, &str, char)] = &[\n     ('\u2028', \"Line Separator\", ' '),\n     ('\u2029', \"Paragraph Separator\", ' '),\n     ('\u1680', \"Ogham Space mark\", ' '),"}]}