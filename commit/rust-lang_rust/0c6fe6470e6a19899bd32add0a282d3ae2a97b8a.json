{"sha": "0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjNmZlNjQ3MGU2YTE5ODk5YmQzMmFkZDBhMjgyZDNhZTJhOTdiOGE=", "commit": {"author": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-06-30T01:26:34Z"}, "committer": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-07-06T01:09:31Z"}, "message": "Macro By Example transcription of token trees with interpolations and dotdotdots.", "tree": {"sha": "4b9ac214483a3190ea5043adab6cb3f965515da2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4b9ac214483a3190ea5043adab6cb3f965515da2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "html_url": "https://github.com/rust-lang/rust/commit/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/comments", "author": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "committer": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f4fb975e4eeb88f5b92b75a5df1e4e6c19856b42", "url": "https://api.github.com/repos/rust-lang/rust/commits/f4fb975e4eeb88f5b92b75a5df1e4e6c19856b42", "html_url": "https://github.com/rust-lang/rust/commit/f4fb975e4eeb88f5b92b75a5df1e4e6c19856b42"}], "stats": {"total": 173, "additions": 141, "deletions": 32}, "files": [{"sha": "322338bf6a19544c6843c738b757ba16d1ab4d34", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "patch": "@@ -379,8 +379,8 @@ enum token_tree {\n     tt_delim(~[token_tree]),\n     tt_flat(span, token::token),\n     /* These only make sense for right-hand-sides of MBE macros*/\n-    tt_dotdotdot(~[token_tree]),\n-    tt_interpolate(ident)\n+    tt_dotdotdot(span, ~[token_tree]),\n+    tt_interpolate(span, ident)\n }\n \n "}, {"sha": "a9a99fc9b7299e12f299eba7dcdb2749dec57e82", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 122, "deletions": 25, "changes": 147, "blob_url": "https://github.com/rust-lang/rust/blob/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "patch": "@@ -1,9 +1,10 @@\n import util::interner::interner;\n import diagnostic::span_handler;\n-import ast::{tt_delim,tt_flat,tt_dotdotdot,tt_interpolate,ident};\n-import earley_parser::arb_depth;\n+import ast::{token_tree,tt_delim,tt_flat,tt_dotdotdot,tt_interpolate,ident};\n+import earley_parser::{arb_depth,seq,leaf};\n import codemap::span;\n-import parse::token::{EOF,token};\n+import parse::token::{EOF,ACTUALLY,token};\n+import std::map::{hashmap,box_str_hash};\n \n export tt_reader,  new_tt_reader, dup_tt_reader, tt_next_token;\n \n@@ -14,8 +15,9 @@ enum tt_frame_up { /* to break a circularity */\n /* TODO: figure out how to have a uniquely linked stack, and change to `~` */\n ///an unzipping of `token_tree`s\n type tt_frame = @{\n-    readme: [ast::token_tree]/~,\n+    readme: ~[ast::token_tree],\n     mut idx: uint,\n+    dotdotdoted: bool,\n     up: tt_frame_up\n };\n \n@@ -25,6 +27,8 @@ type tt_reader = @{\n     mut cur: tt_frame,\n     /* for MBE-style macro transcription */\n     interpolations: std::map::hashmap<ident, @arb_depth>,\n+    mut repeat_idx: ~[mut uint],\n+    mut repeat_len: ~[uint],\n     /* cached: */\n     mut cur_tok: token,\n     mut cur_span: span\n@@ -35,15 +39,16 @@ type tt_reader = @{\n  *  should) be none. */\n fn new_tt_reader(span_diagnostic: span_handler, itr: @interner<@str>,\n                  interp: option<std::map::hashmap<ident,@arb_depth>>,\n-                 src: [ast::token_tree]/~)\n+                 src: ~[ast::token_tree])\n     -> tt_reader {\n     let r = @{span_diagnostic: span_diagnostic, interner: itr,\n-              mut cur: @{readme: src, mut idx: 0u,\n+              mut cur: @{readme: src, mut idx: 0u, dotdotdoted: false,\n                          up: tt_frame_up(option::none)},\n               interpolations: alt interp { /* just a convienience */\n                 none { std::map::box_str_hash::<@arb_depth>() }\n                 some(x) { x }\n               },\n+              mut repeat_idx: ~[mut], mut repeat_len: ~[],\n               /* dummy values, never read: */\n               mut cur_tok: EOF,\n               mut cur_span: ast_util::mk_sp(0u,0u)\n@@ -53,7 +58,7 @@ fn new_tt_reader(span_diagnostic: span_handler, itr: @interner<@str>,\n }\n \n pure fn dup_tt_frame(&&f: tt_frame) -> tt_frame {\n-    @{readme: f.readme, mut idx: f.idx,\n+    @{readme: f.readme, mut idx: f.idx, dotdotdoted: f.dotdotdoted,\n       up: alt f.up {\n         tt_frame_up(some(up_frame)) {\n           tt_frame_up(some(dup_tt_frame(up_frame)))\n@@ -67,46 +72,138 @@ pure fn dup_tt_reader(&&r: tt_reader) -> tt_reader {\n     @{span_diagnostic: r.span_diagnostic, interner: r.interner,\n       mut cur: dup_tt_frame(r.cur),\n       interpolations: r.interpolations,\n+      mut repeat_idx: copy r.repeat_idx, mut repeat_len: copy r.repeat_len,\n       mut cur_tok: r.cur_tok, mut cur_span: r.cur_span}\n }\n \n \n+pure fn lookup_cur_ad_by_ad(r: tt_reader, start: @arb_depth) -> @arb_depth {\n+    pure fn red(&&ad: @arb_depth, &&idx: uint) -> @arb_depth {\n+        alt *ad {\n+          leaf(_) { ad /* end of the line; duplicate henceforth */ }\n+          seq(ads, _) { ads[idx] }\n+        }\n+    }\n+    vec::foldl(start, r.repeat_idx, red)\n+}\n+\n+fn lookup_cur_ad(r: tt_reader, name: ident) -> @arb_depth {\n+    lookup_cur_ad_by_ad(r, r.interpolations.get(name))\n+}\n+enum lis {\n+    lis_unconstrained, lis_constraint(uint, ident), lis_contradiction(str)\n+}\n+\n+fn lockstep_iter_size(&&t: token_tree, &&r: tt_reader) -> lis {\n+    fn lis_merge(lhs: lis, rhs: lis) -> lis {\n+        alt lhs {\n+          lis_unconstrained { rhs }\n+          lis_contradiction(_) { lhs }\n+          lis_constraint(l_len, l_id) {\n+            alt rhs {\n+              lis_unconstrained { lhs }\n+              lis_contradiction(_) { rhs }\n+              lis_constraint(r_len, _) if l_len == r_len { lhs }\n+              lis_constraint(r_len, r_id) {\n+                lis_contradiction(#fmt[\"Inconsistent lockstep iteration: \\\n+                                        '%s' has %u items, but '%s' has %u\",\n+                                       *l_id, l_len, *r_id, r_len])\n+              }\n+            }\n+          }\n+        }\n+    }\n+    alt t {\n+      tt_delim(tts) | tt_dotdotdot(_, tts) {\n+        vec::foldl(lis_unconstrained, tts, {|lis, tt|\n+            lis_merge(lis, lockstep_iter_size(tt, r)) })\n+      }\n+      tt_flat(*) { lis_unconstrained }\n+      tt_interpolate(_, name) {\n+        alt *lookup_cur_ad(r, name) {\n+          leaf(_) { lis_unconstrained }\n+          seq(ads, _) { lis_constraint(ads.len(), name) }\n+        }\n+      }\n+    }\n+}\n+\n+\n fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n     let ret_val = { tok: r.cur_tok, sp: r.cur_span };\n     if r.cur.idx >= vec::len(r.cur.readme) {\n-        /* done with this set; pop */\n-        alt r.cur.up {\n-          tt_frame_up(none) {\n-            r.cur_tok = EOF;\n-            ret ret_val;\n-          }\n-          tt_frame_up(some(tt_f)) {\n-            r.cur = tt_f;\n-            /* the above `if` would need to be a `while` if we didn't know\n-            that the last thing in a `tt_delim` is always a `tt_flat` */\n-            r.cur.idx += 1u;\n-          }\n+        /* done with this set; pop or repeat? */\n+        if ! r.cur.dotdotdoted\n+            || r.repeat_idx.last() == r.repeat_len.last() - 1 {\n+            if r.cur.dotdotdoted {\n+                vec::pop(r.repeat_idx); vec::pop(r.repeat_len);\n+            }\n+            alt r.cur.up {\n+              tt_frame_up(none) {\n+                r.cur_tok = EOF;\n+                ret ret_val;\n+              }\n+              tt_frame_up(some(tt_f)) {\n+                r.cur = tt_f;\n+                /* the outermost `if` would need to be a `while` if we\n+                didn't know that the last thing in a `tt_delim` is always\n+                a `tt_flat`, and that a `tt_dotdotdot` is never empty */\n+                r.cur.idx += 1u;\n+              }\n+            }\n+\n+        } else {\n+            r.cur.idx = 0u;\n+            r.repeat_idx[r.repeat_idx.len() - 1u] += 1u;\n         }\n     }\n     /* if `tt_delim`s could be 0-length, we'd need to be able to switch\n     between popping and pushing until we got to an actual `tt_flat` */\n     loop { /* because it's easiest, this handles `tt_delim` not starting\n     with a `tt_flat`, even though it won't happen */\n-        alt copy r.cur.readme[r.cur.idx] {\n+        alt r.cur.readme[r.cur.idx] {\n           tt_delim(tts) {\n-            r.cur = @{readme: tts, mut idx: 0u,\n+            r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: false,\n                       up: tt_frame_up(option::some(r.cur)) };\n           }\n           tt_flat(sp, tok) {\n             r.cur_span = sp; r.cur_tok = tok;\n             r.cur.idx += 1u;\n             ret ret_val;\n           }\n-          tt_dotdotdot(tts) {\n-            fail;\n+          tt_dotdotdot(sp, tts) {\n+            alt lockstep_iter_size(tt_dotdotdot(sp, tts), r) {\n+              lis_unconstrained {\n+                r.span_diagnostic.span_fatal(\n+                    copy r.cur_span, /* blame macro writer */\n+                    \"attempted to repeat an expression containing no syntax \\\n+                     variables matched as repeating at this depth\");\n+              }\n+              lis_contradiction(msg) { /* blame macro invoker */\n+                r.span_diagnostic.span_fatal(sp, msg);\n+              }\n+              lis_constraint(len, _) {\n+                vec::push(r.repeat_len, len);\n+                vec::push(r.repeat_idx, 0u);\n+                r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: true,\n+                      up: tt_frame_up(option::some(r.cur)) };\n+              }\n+            }\n           }\n-          tt_interpolate(ident) {\n-            fail;\n+          // TODO: think about span stuff here\n+          tt_interpolate(sp, ident) {\n+            alt *lookup_cur_ad(r, ident) {\n+              leaf(w_nt) {\n+                r.cur_span = sp; r.cur_tok = ACTUALLY(w_nt);\n+                ret ret_val;\n+              }\n+              seq(*) {\n+                r.span_diagnostic.span_fatal(\n+                    copy r.cur_span, /* blame the macro writer */\n+                    #fmt[\"variable '%s' is still repeating at this depth\",\n+                         *ident]);\n+              }\n+            }\n           }\n         }\n     }"}, {"sha": "4d564563d10b00ebe2c5ce638f65738dc72dbc44", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "patch": "@@ -1070,9 +1070,10 @@ class parser {\n \n         fn parse_tt_flat(p: parser, delim_ok: bool) -> token_tree {\n             if p.eat_keyword(\"many\") && p.quote_depth > 0u {\n-                ret tt_dotdotdot(\n-                    p.parse_seq(token::LPAREN, token::RPAREN, seq_sep_none(),\n-                                |p| p.parse_token_tree()).node);\n+                let seq = p.parse_seq(token::LPAREN, token::RPAREN,\n+                                      seq_sep_none(),\n+                                      |p| p.parse_token_tree());\n+                ret tt_dotdotdot(seq.span, seq.node);\n             }\n             alt p.token {\n               token::RPAREN | token::RBRACE | token::RBRACKET\n@@ -1086,7 +1087,8 @@ class parser {\n               /* we ought to allow different depths of unquotation */\n               token::DOLLAR if p.quote_depth > 0u {\n                 p.bump();\n-                ret tt_interpolate(p.parse_ident());\n+                let sp = p.span;\n+                ret tt_interpolate(sp, p.parse_ident());\n               }\n               _ { /* ok */ }\n             }"}, {"sha": "29a8fb18ebc8200040dda5109327bccff0ae2603", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6fe6470e6a19899bd32add0a282d3ae2a97b8a/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=0c6fe6470e6a19899bd32add0a282d3ae2a97b8a", "patch": "@@ -78,7 +78,8 @@ enum token {\n     IDENT(str_num, bool),\n     UNDERSCORE,\n \n-    //ACTUALLY(whole_nonterminal),\n+    /* For interpolation */\n+    ACTUALLY(whole_nt),\n \n     DOC_COMMENT(str_num),\n     EOF,\n@@ -181,6 +182,15 @@ fn to_str(in: interner<@str>, t: token) -> str {\n       /* Other */\n       DOC_COMMENT(s) { *interner::get(in, s) }\n       EOF { \"<eof>\" }\n+      ACTUALLY(w_nt) {\n+        \"an interpolated \" +\n+            alt w_nt {\n+              w_item(*) { \"item\" } w_block(*) { \"block\" }\n+              w_stmt(*) { \"statement\" } w_pat(*) { \"pattern\" }\n+              w_expr(*) { \"expression\" } w_ty(*) { \"type\" }\n+              w_ident(*) { \"identifier\" } w_path(*) { \"path\" }\n+        }\n+      }\n     }\n }\n "}]}