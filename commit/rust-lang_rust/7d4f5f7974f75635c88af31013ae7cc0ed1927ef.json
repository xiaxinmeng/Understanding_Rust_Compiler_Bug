{"sha": "7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdkNGY1Zjc5NzRmNzU2MzVjODhhZjMxMDEzYWU3Y2MwZWQxOTI3ZWY=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2018-08-09T13:04:53Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2018-08-22T06:50:46Z"}, "message": "Move some value-and-memory related things out of eval_context", "tree": {"sha": "afff6b64791ca975c775e39f1d40ddf0c7f4f47e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/afff6b64791ca975c775e39f1d40ddf0c7f4f47e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "html_url": "https://github.com/rust-lang/rust/commit/7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "786ccc336dc684cdb00402e84abe4a9bc53857cf", "url": "https://api.github.com/repos/rust-lang/rust/commits/786ccc336dc684cdb00402e84abe4a9bc53857cf", "html_url": "https://github.com/rust-lang/rust/commit/786ccc336dc684cdb00402e84abe4a9bc53857cf"}], "stats": {"total": 1547, "additions": 782, "deletions": 765}, "files": [{"sha": "f93607cecb9081e35125a8cb74df6f663854a4ee", "filename": "src/librustc_mir/interpret/eval_context.rs", "status": "modified", "additions": 10, "deletions": 762, "changes": 772, "blob_url": "https://github.com/rust-lang/rust/blob/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs?ref=7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "patch": "@@ -6,15 +6,15 @@ use rustc::hir::def_id::DefId;\n use rustc::hir::def::Def;\n use rustc::hir::map::definitions::DefPathData;\n use rustc::mir;\n-use rustc::ty::layout::{self, Size, Align, HasDataLayout, IntegerExt, LayoutOf, TyLayout, Primitive};\n+use rustc::ty::layout::{self, Size, Align, HasDataLayout, LayoutOf, TyLayout, Primitive};\n use rustc::ty::subst::{Subst, Substs};\n use rustc::ty::{self, Ty, TyCtxt, TypeAndMut};\n use rustc::ty::query::TyCtxtAt;\n use rustc_data_structures::fx::{FxHashSet, FxHasher};\n use rustc_data_structures::indexed_vec::{IndexVec, Idx};\n use rustc::mir::interpret::{\n     GlobalId, Value, Scalar, FrameInfo, AllocType,\n-    EvalResult, EvalErrorKind, Pointer, ConstValue,\n+    EvalResult, EvalErrorKind, Pointer,\n     ScalarMaybeUndef,\n };\n \n@@ -23,7 +23,7 @@ use syntax::ast::Mutability;\n \n use super::{Place, PlaceExtra, Memory,\n             HasMemory, MemoryKind,\n-            Machine};\n+            Machine, LocalValue};\n \n macro_rules! validation_failure{\n     ($what:expr, $where:expr, $details:expr) => {{\n@@ -119,21 +119,6 @@ pub struct Frame<'mir, 'tcx: 'mir> {\n     pub stmt: usize,\n }\n \n-#[derive(Copy, Clone, PartialEq, Eq, Hash)]\n-pub enum LocalValue {\n-    Dead,\n-    Live(Value),\n-}\n-\n-impl LocalValue {\n-    pub fn access(self) -> EvalResult<'static, Value> {\n-        match self {\n-            LocalValue::Dead => err!(DeadLocal),\n-            LocalValue::Live(val) => Ok(val),\n-        }\n-    }\n-}\n-\n impl<'mir, 'tcx: 'mir> Eq for Frame<'mir, 'tcx> {}\n \n impl<'mir, 'tcx: 'mir> PartialEq for Frame<'mir, 'tcx> {\n@@ -387,33 +372,6 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n         self.stack.len() - 1\n     }\n \n-    pub fn str_to_value(&mut self, s: &str) -> EvalResult<'tcx, Value> {\n-        let ptr = self.memory.allocate_bytes(s.as_bytes());\n-        Ok(Scalar::Ptr(ptr).to_value_with_len(s.len() as u64, self.tcx.tcx))\n-    }\n-\n-    pub fn const_to_value(\n-        &mut self,\n-        val: ConstValue<'tcx>,\n-    ) -> EvalResult<'tcx, Value> {\n-        match val {\n-            ConstValue::Unevaluated(def_id, substs) => {\n-                let instance = self.resolve(def_id, substs)?;\n-                self.read_global_as_value(GlobalId {\n-                    instance,\n-                    promoted: None,\n-                })\n-            }\n-            ConstValue::ByRef(alloc, offset) => {\n-                // FIXME: Allocate new AllocId for all constants inside\n-                let id = self.memory.allocate_value(alloc.clone(), MemoryKind::Stack)?;\n-                Ok(Value::ByRef(Pointer::new(id, offset).into(), alloc.align))\n-            },\n-            ConstValue::ScalarPair(a, b) => Ok(Value::ScalarPair(a.into(), b.into())),\n-            ConstValue::Scalar(val) => Ok(Value::Scalar(val.into())),\n-        }\n-    }\n-\n     pub(super) fn resolve(&self, def_id: DefId, substs: &'tcx Substs<'tcx>) -> EvalResult<'tcx, ty::Instance<'tcx>> {\n         trace!(\"resolve: {:?}, {:#?}\", def_id, substs);\n         trace!(\"substs: {:#?}\", self.substs());\n@@ -634,209 +592,6 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n         Ok(())\n     }\n \n-    pub fn deallocate_local(&mut self, local: LocalValue) -> EvalResult<'tcx> {\n-        // FIXME: should we tell the user that there was a local which was never written to?\n-        if let LocalValue::Live(Value::ByRef(ptr, _align)) = local {\n-            trace!(\"deallocating local\");\n-            let ptr = ptr.to_ptr()?;\n-            self.memory.dump_alloc(ptr.alloc_id);\n-            self.memory.deallocate_local(ptr)?;\n-        };\n-        Ok(())\n-    }\n-\n-    /// Evaluate an assignment statement.\n-    ///\n-    /// There is no separate `eval_rvalue` function. Instead, the code for handling each rvalue\n-    /// type writes its results directly into the memory specified by the place.\n-    pub(super) fn eval_rvalue_into_place(\n-        &mut self,\n-        rvalue: &mir::Rvalue<'tcx>,\n-        place: &mir::Place<'tcx>,\n-    ) -> EvalResult<'tcx> {\n-        let dest = self.eval_place(place)?;\n-        let dest_ty = self.place_ty(place);\n-        let dest_layout = self.layout_of(dest_ty)?;\n-\n-        use rustc::mir::Rvalue::*;\n-        match *rvalue {\n-            Use(ref operand) => {\n-                let value = self.eval_operand(operand)?.value;\n-                let valty = ValTy {\n-                    value,\n-                    ty: dest_ty,\n-                };\n-                self.write_value(valty, dest)?;\n-            }\n-\n-            BinaryOp(bin_op, ref left, ref right) => {\n-                let left = self.eval_operand(left)?;\n-                let right = self.eval_operand(right)?;\n-                self.intrinsic_overflowing(\n-                    bin_op,\n-                    left,\n-                    right,\n-                    dest,\n-                    dest_ty,\n-                )?;\n-            }\n-\n-            CheckedBinaryOp(bin_op, ref left, ref right) => {\n-                let left = self.eval_operand(left)?;\n-                let right = self.eval_operand(right)?;\n-                self.intrinsic_with_overflow(\n-                    bin_op,\n-                    left,\n-                    right,\n-                    dest,\n-                    dest_ty,\n-                )?;\n-            }\n-\n-            UnaryOp(un_op, ref operand) => {\n-                let val = self.eval_operand_to_scalar(operand)?;\n-                let val = self.unary_op(un_op, val, dest_layout)?;\n-                self.write_scalar(\n-                    dest,\n-                    val,\n-                    dest_ty,\n-                )?;\n-            }\n-\n-            Aggregate(ref kind, ref operands) => {\n-                let (dest, active_field_index) = match **kind {\n-                    mir::AggregateKind::Adt(adt_def, variant_index, _, active_field_index) => {\n-                        self.write_discriminant_value(dest_ty, dest, variant_index)?;\n-                        if adt_def.is_enum() {\n-                            (self.place_downcast(dest, variant_index)?, active_field_index)\n-                        } else {\n-                            (dest, active_field_index)\n-                        }\n-                    }\n-                    _ => (dest, None)\n-                };\n-\n-                let layout = self.layout_of(dest_ty)?;\n-                for (i, operand) in operands.iter().enumerate() {\n-                    let value = self.eval_operand(operand)?;\n-                    // Ignore zero-sized fields.\n-                    if !self.layout_of(value.ty)?.is_zst() {\n-                        let field_index = active_field_index.unwrap_or(i);\n-                        let (field_dest, _) = self.place_field(dest, mir::Field::new(field_index), layout)?;\n-                        self.write_value(value, field_dest)?;\n-                    }\n-                }\n-            }\n-\n-            Repeat(ref operand, _) => {\n-                let (elem_ty, length) = match dest_ty.sty {\n-                    ty::TyArray(elem_ty, n) => (elem_ty, n.unwrap_usize(self.tcx.tcx)),\n-                    _ => {\n-                        bug!(\n-                            \"tried to assign array-repeat to non-array type {:?}\",\n-                            dest_ty\n-                        )\n-                    }\n-                };\n-                let elem_size = self.layout_of(elem_ty)?.size;\n-                let value = self.eval_operand(operand)?.value;\n-\n-                let (dest, dest_align) = self.force_allocation(dest)?.to_ptr_align();\n-\n-                if length > 0 {\n-                    let dest = dest.unwrap_or_err()?;\n-                    //write the first value\n-                    self.write_value_to_ptr(value, dest, dest_align, elem_ty)?;\n-\n-                    if length > 1 {\n-                        let rest = dest.ptr_offset(elem_size * 1 as u64, &self)?;\n-                        self.memory.copy_repeatedly(dest, dest_align, rest, dest_align, elem_size, length - 1, false)?;\n-                    }\n-                }\n-            }\n-\n-            Len(ref place) => {\n-                // FIXME(CTFE): don't allow computing the length of arrays in const eval\n-                let src = self.eval_place(place)?;\n-                let ty = self.place_ty(place);\n-                let (_, len) = src.elem_ty_and_len(ty, self.tcx.tcx);\n-                let size = self.memory.pointer_size().bytes() as u8;\n-                self.write_scalar(\n-                    dest,\n-                    Scalar::Bits {\n-                        bits: len as u128,\n-                        size,\n-                    },\n-                    dest_ty,\n-                )?;\n-            }\n-\n-            Ref(_, _, ref place) => {\n-                let src = self.eval_place(place)?;\n-                // We ignore the alignment of the place here -- special handling for packed structs ends\n-                // at the `&` operator.\n-                let (ptr, _align, extra) = self.force_allocation(src)?.to_ptr_align_extra();\n-\n-                let val = match extra {\n-                    PlaceExtra::None => Value::Scalar(ptr),\n-                    PlaceExtra::Length(len) => ptr.to_value_with_len(len, self.tcx.tcx),\n-                    PlaceExtra::Vtable(vtable) => ptr.to_value_with_vtable(vtable),\n-                    PlaceExtra::DowncastVariant(..) => {\n-                        bug!(\"attempted to take a reference to an enum downcast place\")\n-                    }\n-                };\n-                let valty = ValTy {\n-                    value: val,\n-                    ty: dest_ty,\n-                };\n-                self.write_value(valty, dest)?;\n-            }\n-\n-            NullaryOp(mir::NullOp::Box, ty) => {\n-                let ty = self.monomorphize(ty, self.substs());\n-                M::box_alloc(self, ty, dest)?;\n-            }\n-\n-            NullaryOp(mir::NullOp::SizeOf, ty) => {\n-                let ty = self.monomorphize(ty, self.substs());\n-                let layout = self.layout_of(ty)?;\n-                assert!(!layout.is_unsized(),\n-                        \"SizeOf nullary MIR operator called for unsized type\");\n-                let size = self.memory.pointer_size().bytes() as u8;\n-                self.write_scalar(\n-                    dest,\n-                    Scalar::Bits {\n-                        bits: layout.size.bytes() as u128,\n-                        size,\n-                    },\n-                    dest_ty,\n-                )?;\n-            }\n-\n-            Cast(kind, ref operand, cast_ty) => {\n-                debug_assert_eq!(self.monomorphize(cast_ty, self.substs()), dest_ty);\n-                let src = self.eval_operand(operand)?;\n-                self.cast(src, kind, dest_ty, dest)?;\n-            }\n-\n-            Discriminant(ref place) => {\n-                let ty = self.place_ty(place);\n-                let layout = self.layout_of(ty)?;\n-                let place = self.eval_place(place)?;\n-                let discr_val = self.read_discriminant_value(place, layout)?;\n-                let size = self.layout_of(dest_ty).unwrap().size.bytes() as u8;\n-                self.write_scalar(dest, Scalar::Bits {\n-                    bits: discr_val,\n-                    size,\n-                }, dest_ty)?;\n-            }\n-        }\n-\n-        self.dump_local(dest);\n-\n-        Ok(())\n-    }\n-\n     pub(super) fn type_is_fat_ptr(&self, ty: Ty<'tcx>) -> bool {\n         match ty.sty {\n             ty::TyRawPtr(ty::TypeAndMut { ty, .. }) |\n@@ -846,213 +601,6 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n         }\n     }\n \n-    pub(super) fn eval_operand_to_scalar(\n-        &mut self,\n-        op: &mir::Operand<'tcx>,\n-    ) -> EvalResult<'tcx, Scalar> {\n-        let valty = self.eval_operand(op)?;\n-        self.value_to_scalar(valty)\n-    }\n-\n-    pub(crate) fn operands_to_args(\n-        &mut self,\n-        ops: &[mir::Operand<'tcx>],\n-    ) -> EvalResult<'tcx, Vec<ValTy<'tcx>>> {\n-        ops.into_iter()\n-            .map(|op| self.eval_operand(op))\n-            .collect()\n-    }\n-\n-    pub fn eval_operand(&mut self, op: &mir::Operand<'tcx>) -> EvalResult<'tcx, ValTy<'tcx>> {\n-        use rustc::mir::Operand::*;\n-        let ty = self.monomorphize(op.ty(self.mir(), *self.tcx), self.substs());\n-        match *op {\n-            // FIXME: do some more logic on `move` to invalidate the old location\n-            Copy(ref place) |\n-            Move(ref place) => {\n-                Ok(ValTy {\n-                    value: self.eval_and_read_place(place)?,\n-                    ty\n-                })\n-            },\n-\n-            Constant(ref constant) => {\n-                let value = self.const_to_value(constant.literal.val)?;\n-\n-                Ok(ValTy {\n-                    value,\n-                    ty,\n-                })\n-            }\n-        }\n-    }\n-\n-    /// reads a tag and produces the corresponding variant index\n-    pub fn read_discriminant_as_variant_index(\n-        &self,\n-        place: Place,\n-        layout: TyLayout<'tcx>,\n-    ) -> EvalResult<'tcx, usize> {\n-        match layout.variants {\n-            ty::layout::Variants::Single { index } => Ok(index),\n-            ty::layout::Variants::Tagged { .. } => {\n-                let discr_val = self.read_discriminant_value(place, layout)?;\n-                layout\n-                    .ty\n-                    .ty_adt_def()\n-                    .expect(\"tagged layout for non adt\")\n-                    .discriminants(self.tcx.tcx)\n-                    .position(|var| var.val == discr_val)\n-                    .ok_or_else(|| EvalErrorKind::InvalidDiscriminant.into())\n-            }\n-            ty::layout::Variants::NicheFilling { .. } => {\n-                let discr_val = self.read_discriminant_value(place, layout)?;\n-                assert_eq!(discr_val as usize as u128, discr_val);\n-                Ok(discr_val as usize)\n-            },\n-        }\n-    }\n-\n-    pub fn read_discriminant_value(\n-        &self,\n-        place: Place,\n-        layout: TyLayout<'tcx>,\n-    ) -> EvalResult<'tcx, u128> {\n-        trace!(\"read_discriminant_value {:#?}\", layout);\n-        if layout.abi == layout::Abi::Uninhabited {\n-            return Ok(0);\n-        }\n-\n-        match layout.variants {\n-            layout::Variants::Single { index } => {\n-                let discr_val = layout.ty.ty_adt_def().map_or(\n-                    index as u128,\n-                    |def| def.discriminant_for_variant(*self.tcx, index).val);\n-                return Ok(discr_val);\n-            }\n-            layout::Variants::Tagged { .. } |\n-            layout::Variants::NicheFilling { .. } => {},\n-        }\n-        let discr_place_val = self.read_place(place)?;\n-        let (discr_val, discr) = self.read_field(discr_place_val, None, mir::Field::new(0), layout)?;\n-        trace!(\"discr value: {:?}, {:?}\", discr_val, discr);\n-        let raw_discr = self.value_to_scalar(ValTy {\n-            value: discr_val,\n-            ty: discr.ty\n-        })?;\n-        let discr_val = match layout.variants {\n-            layout::Variants::Single { .. } => bug!(),\n-            // FIXME: should we catch invalid discriminants here?\n-            layout::Variants::Tagged { .. } => {\n-                if discr.ty.is_signed() {\n-                    let i = raw_discr.to_bits(discr.size)? as i128;\n-                    // going from layout tag type to typeck discriminant type\n-                    // requires first sign extending with the layout discriminant\n-                    let shift = 128 - discr.size.bits();\n-                    let sexted = (i << shift) >> shift;\n-                    // and then zeroing with the typeck discriminant type\n-                    let discr_ty = layout\n-                        .ty\n-                        .ty_adt_def().expect(\"tagged layout corresponds to adt\")\n-                        .repr\n-                        .discr_type();\n-                    let discr_ty = layout::Integer::from_attr(self.tcx.tcx, discr_ty);\n-                    let shift = 128 - discr_ty.size().bits();\n-                    let truncatee = sexted as u128;\n-                    (truncatee << shift) >> shift\n-                } else {\n-                    raw_discr.to_bits(discr.size)?\n-                }\n-            },\n-            layout::Variants::NicheFilling {\n-                dataful_variant,\n-                ref niche_variants,\n-                niche_start,\n-                ..\n-            } => {\n-                let variants_start = *niche_variants.start() as u128;\n-                let variants_end = *niche_variants.end() as u128;\n-                match raw_discr {\n-                    Scalar::Ptr(_) => {\n-                        assert!(niche_start == 0);\n-                        assert!(variants_start == variants_end);\n-                        dataful_variant as u128\n-                    },\n-                    Scalar::Bits { bits: raw_discr, size } => {\n-                        assert_eq!(size as u64, discr.size.bytes());\n-                        let discr = raw_discr.wrapping_sub(niche_start)\n-                            .wrapping_add(variants_start);\n-                        if variants_start <= discr && discr <= variants_end {\n-                            discr\n-                        } else {\n-                            dataful_variant as u128\n-                        }\n-                    },\n-                }\n-            }\n-        };\n-\n-        Ok(discr_val)\n-    }\n-\n-\n-    pub fn write_discriminant_value(\n-        &mut self,\n-        dest_ty: Ty<'tcx>,\n-        dest: Place,\n-        variant_index: usize,\n-    ) -> EvalResult<'tcx> {\n-        let layout = self.layout_of(dest_ty)?;\n-\n-        match layout.variants {\n-            layout::Variants::Single { index } => {\n-                if index != variant_index {\n-                    // If the layout of an enum is `Single`, all\n-                    // other variants are necessarily uninhabited.\n-                    assert_eq!(layout.for_variant(&self, variant_index).abi,\n-                               layout::Abi::Uninhabited);\n-                }\n-            }\n-            layout::Variants::Tagged { ref tag, .. } => {\n-                let discr_val = dest_ty.ty_adt_def().unwrap()\n-                    .discriminant_for_variant(*self.tcx, variant_index)\n-                    .val;\n-\n-                // raw discriminants for enums are isize or bigger during\n-                // their computation, but the in-memory tag is the smallest possible\n-                // representation\n-                let size = tag.value.size(self.tcx.tcx);\n-                let shift = 128 - size.bits();\n-                let discr_val = (discr_val << shift) >> shift;\n-\n-                let (discr_dest, tag) = self.place_field(dest, mir::Field::new(0), layout)?;\n-                self.write_scalar(discr_dest, Scalar::Bits {\n-                    bits: discr_val,\n-                    size: size.bytes() as u8,\n-                }, tag.ty)?;\n-            }\n-            layout::Variants::NicheFilling {\n-                dataful_variant,\n-                ref niche_variants,\n-                niche_start,\n-                ..\n-            } => {\n-                if variant_index != dataful_variant {\n-                    let (niche_dest, niche) =\n-                        self.place_field(dest, mir::Field::new(0), layout)?;\n-                    let niche_value = ((variant_index - niche_variants.start()) as u128)\n-                        .wrapping_add(niche_start);\n-                    self.write_scalar(niche_dest, Scalar::Bits {\n-                        bits: niche_value,\n-                        size: niche.size.bytes() as u8,\n-                    }, niche.ty)?;\n-                }\n-            }\n-        }\n-\n-        Ok(())\n-    }\n-\n     pub fn read_global_as_value(&mut self, gid: GlobalId<'tcx>) -> EvalResult<'tcx, Value> {\n         let cv = self.const_eval(gid)?;\n         self.const_to_value(cv.val)\n@@ -1067,228 +615,6 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n         self.tcx.const_eval(param_env.and(gid)).map_err(|err| EvalErrorKind::ReferencedConstant(err).into())\n     }\n \n-    pub fn allocate_place_for_value(\n-        &mut self,\n-        value: Value,\n-        layout: TyLayout<'tcx>,\n-        variant: Option<usize>,\n-    ) -> EvalResult<'tcx, Place> {\n-        let (ptr, align) = match value {\n-            Value::ByRef(ptr, align) => (ptr, align),\n-            Value::ScalarPair(..) | Value::Scalar(_) => {\n-                let ptr = self.alloc_ptr(layout)?.into();\n-                self.write_value_to_ptr(value, ptr, layout.align, layout.ty)?;\n-                (ptr, layout.align)\n-            },\n-        };\n-        Ok(Place::Ptr {\n-            ptr: ptr.into(),\n-            align,\n-            extra: variant.map_or(PlaceExtra::None, PlaceExtra::DowncastVariant),\n-        })\n-    }\n-\n-    pub fn force_allocation(&mut self, place: Place) -> EvalResult<'tcx, Place> {\n-        let new_place = match place {\n-            Place::Local { frame, local } => {\n-                match self.stack[frame].locals[local].access()? {\n-                    Value::ByRef(ptr, align) => {\n-                        Place::Ptr {\n-                            ptr: ptr.into(),\n-                            align,\n-                            extra: PlaceExtra::None,\n-                        }\n-                    }\n-                    val => {\n-                        let ty = self.stack[frame].mir.local_decls[local].ty;\n-                        let ty = self.monomorphize(ty, self.stack[frame].instance.substs);\n-                        let layout = self.layout_of(ty)?;\n-                        let ptr = self.alloc_ptr(layout)?;\n-                        self.stack[frame].locals[local] =\n-                            LocalValue::Live(Value::ByRef(ptr.into(), layout.align)); // it stays live\n-\n-                        let place = Place::from_ptr(ptr, layout.align);\n-                        self.write_value(ValTy { value: val, ty }, place)?;\n-                        place\n-                    }\n-                }\n-            }\n-            Place::Ptr { .. } => place,\n-        };\n-        Ok(new_place)\n-    }\n-\n-    /// ensures this Value is not a ByRef\n-    pub fn follow_by_ref_value(\n-        &self,\n-        value: Value,\n-        ty: Ty<'tcx>,\n-    ) -> EvalResult<'tcx, Value> {\n-        match value {\n-            Value::ByRef(ptr, align) => {\n-                self.read_value(ptr, align, ty)\n-            }\n-            other => Ok(other),\n-        }\n-    }\n-\n-    pub fn value_to_scalar(\n-        &self,\n-        ValTy { value, ty } : ValTy<'tcx>,\n-    ) -> EvalResult<'tcx, Scalar> {\n-        match self.follow_by_ref_value(value, ty)? {\n-            Value::ByRef { .. } => bug!(\"follow_by_ref_value can't result in `ByRef`\"),\n-\n-            Value::Scalar(scalar) => scalar.unwrap_or_err(),\n-\n-            Value::ScalarPair(..) => bug!(\"value_to_scalar can't work with fat pointers\"),\n-        }\n-    }\n-\n-    pub fn write_ptr(&mut self, dest: Place, val: Scalar, dest_ty: Ty<'tcx>) -> EvalResult<'tcx> {\n-        let valty = ValTy {\n-            value: val.to_value(),\n-            ty: dest_ty,\n-        };\n-        self.write_value(valty, dest)\n-    }\n-\n-    pub fn write_scalar(\n-        &mut self,\n-        dest: Place,\n-        val: impl Into<ScalarMaybeUndef>,\n-        dest_ty: Ty<'tcx>,\n-    ) -> EvalResult<'tcx> {\n-        let valty = ValTy {\n-            value: Value::Scalar(val.into()),\n-            ty: dest_ty,\n-        };\n-        self.write_value(valty, dest)\n-    }\n-\n-    pub fn write_value(\n-        &mut self,\n-        ValTy { value: src_val, ty: dest_ty } : ValTy<'tcx>,\n-        dest: Place,\n-    ) -> EvalResult<'tcx> {\n-        //trace!(\"Writing {:?} to {:?} at type {:?}\", src_val, dest, dest_ty);\n-        // Note that it is really important that the type here is the right one, and matches the type things are read at.\n-        // In case `src_val` is a `ScalarPair`, we don't do any magic here to handle padding properly, which is only\n-        // correct if we never look at this data with the wrong type.\n-\n-        match dest {\n-            Place::Ptr { ptr, align, extra } => {\n-                assert_eq!(extra, PlaceExtra::None);\n-                self.write_value_to_ptr(src_val, ptr.unwrap_or_err()?, align, dest_ty)\n-            }\n-\n-            Place::Local { frame, local } => {\n-                let old_val = self.stack[frame].locals[local].access()?;\n-                self.write_value_possibly_by_val(\n-                    src_val,\n-                    |this, val| this.stack[frame].set_local(local, val),\n-                    old_val,\n-                    dest_ty,\n-                )\n-            }\n-        }\n-    }\n-\n-    // The cases here can be a bit subtle. Read carefully!\n-    fn write_value_possibly_by_val<F: FnOnce(&mut Self, Value) -> EvalResult<'tcx>>(\n-        &mut self,\n-        src_val: Value,\n-        write_dest: F,\n-        old_dest_val: Value,\n-        dest_ty: Ty<'tcx>,\n-    ) -> EvalResult<'tcx> {\n-        // FIXME: this should be a layout check, not underlying value\n-        if let Value::ByRef(dest_ptr, align) = old_dest_val {\n-            // If the value is already `ByRef` (that is, backed by an `Allocation`),\n-            // then we must write the new value into this allocation, because there may be\n-            // other pointers into the allocation. These other pointers are logically\n-            // pointers into the local variable, and must be able to observe the change.\n-            //\n-            // Thus, it would be an error to replace the `ByRef` with a `ByVal`, unless we\n-            // knew for certain that there were no outstanding pointers to this allocation.\n-            self.write_value_to_ptr(src_val, dest_ptr, align, dest_ty)?;\n-        } else if let Value::ByRef(src_ptr, align) = src_val {\n-            // If the value is not `ByRef`, then we know there are no pointers to it\n-            // and we can simply overwrite the `Value` in the locals array directly.\n-            //\n-            // In this specific case, where the source value is `ByRef`, we must duplicate\n-            // the allocation, because this is a by-value operation. It would be incorrect\n-            // if they referred to the same allocation, since then a change to one would\n-            // implicitly change the other.\n-            //\n-            // It is a valid optimization to attempt reading a primitive value out of the\n-            // source and write that into the destination without making an allocation, so\n-            // we do so here.\n-            if let Ok(Some(src_val)) = self.try_read_value(src_ptr, align, dest_ty) {\n-                write_dest(self, src_val)?;\n-            } else {\n-                let layout = self.layout_of(dest_ty)?;\n-                let dest_ptr = self.alloc_ptr(layout)?.into();\n-                self.memory.copy(src_ptr, align.min(layout.align), dest_ptr, layout.align, layout.size, false)?;\n-                write_dest(self, Value::ByRef(dest_ptr, layout.align))?;\n-            }\n-        } else {\n-            // Finally, we have the simple case where neither source nor destination are\n-            // `ByRef`. We may simply copy the source value over the the destintion.\n-            write_dest(self, src_val)?;\n-        }\n-        Ok(())\n-    }\n-\n-    pub fn write_value_to_ptr(\n-        &mut self,\n-        value: Value,\n-        dest: Scalar,\n-        dest_align: Align,\n-        dest_ty: Ty<'tcx>,\n-    ) -> EvalResult<'tcx> {\n-        let layout = self.layout_of(dest_ty)?;\n-        trace!(\"write_value_to_ptr: {:#?}, {}, {:#?}\", value, dest_ty, layout);\n-        match value {\n-            Value::ByRef(ptr, align) => {\n-                self.memory.copy(ptr, align.min(layout.align), dest, dest_align.min(layout.align), layout.size, false)\n-            }\n-            Value::Scalar(scalar) => {\n-                let signed = match layout.abi {\n-                    layout::Abi::Scalar(ref scal) => match scal.value {\n-                        layout::Primitive::Int(_, signed) => signed,\n-                        _ => false,\n-                    },\n-                    _ => false,\n-                };\n-                self.memory.write_scalar(dest, dest_align, scalar, layout.size, layout.align, signed)\n-            }\n-            Value::ScalarPair(a_val, b_val) => {\n-                trace!(\"write_value_to_ptr valpair: {:#?}\", layout);\n-                let (a, b) = match layout.abi {\n-                    layout::Abi::ScalarPair(ref a, ref b) => (&a.value, &b.value),\n-                    _ => bug!(\"write_value_to_ptr: invalid ScalarPair layout: {:#?}\", layout)\n-                };\n-                let (a_size, b_size) = (a.size(&self), b.size(&self));\n-                let (a_align, b_align) = (a.align(&self), b.align(&self));\n-                let a_ptr = dest;\n-                let b_offset = a_size.abi_align(b_align);\n-                let b_ptr = dest.ptr_offset(b_offset, &self)?.into();\n-                // TODO: What about signedess?\n-                self.memory.write_scalar(a_ptr, dest_align, a_val, a_size, a_align, false)?;\n-                self.memory.write_scalar(b_ptr, dest_align, b_val, b_size, b_align, false)\n-            }\n-        }\n-    }\n-\n-    pub fn read_value(&self, ptr: Scalar, align: Align, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n-        if let Some(val) = self.try_read_value(ptr, align, ty)? {\n-            Ok(val)\n-        } else {\n-            bug!(\"primitive read failed for type: {:?}\", ty);\n-        }\n-    }\n-\n     fn validate_scalar(\n         &self,\n         value: ScalarMaybeUndef,\n@@ -1401,12 +727,14 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n                     mir::Field::new(0),\n                     layout,\n                 )?;\n-                let tag_value = match self.follow_by_ref_value(tag_value, tag_layout.ty)? {\n-                    Value::Scalar(val) => val,\n-                    _ => bug!(\"tag must be scalar\"),\n-                };\n+                let tag_value = self.value_to_scalar(ValTy {\n+                    value: tag_value,\n+                    ty: tag_layout.ty\n+                })?;\n                 let path = format!(\"{}.TAG\", path);\n-                self.validate_scalar(tag_value, size, tag, &path, tag_layout.ty)?;\n+                self.validate_scalar(\n+                    ScalarMaybeUndef::Scalar(tag_value), size, tag, &path, tag_layout.ty\n+                )?;\n                 let variant_index = self.read_discriminant_as_variant_index(\n                     Place::from_ptr(ptr, ptr_align),\n                     layout,\n@@ -1510,45 +838,6 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n         }\n     }\n \n-    pub fn try_read_by_ref(&self, mut val: Value, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n-        // Convert to ByVal or ScalarPair if possible\n-        if let Value::ByRef(ptr, align) = val {\n-            if let Some(read_val) = self.try_read_value(ptr, align, ty)? {\n-                val = read_val;\n-            }\n-        }\n-        Ok(val)\n-    }\n-\n-    pub fn try_read_value(&self, ptr: Scalar, ptr_align: Align, ty: Ty<'tcx>) -> EvalResult<'tcx, Option<Value>> {\n-        let layout = self.layout_of(ty)?;\n-        self.memory.check_align(ptr, ptr_align)?;\n-\n-        if layout.size.bytes() == 0 {\n-            return Ok(Some(Value::Scalar(ScalarMaybeUndef::Scalar(Scalar::Bits { bits: 0, size: 0 }))));\n-        }\n-\n-        let ptr = ptr.to_ptr()?;\n-\n-        match layout.abi {\n-            layout::Abi::Scalar(..) => {\n-                let scalar = self.memory.read_scalar(ptr, ptr_align, layout.size)?;\n-                Ok(Some(Value::Scalar(scalar)))\n-            }\n-            layout::Abi::ScalarPair(ref a, ref b) => {\n-                let (a, b) = (&a.value, &b.value);\n-                let (a_size, b_size) = (a.size(self), b.size(self));\n-                let a_ptr = ptr;\n-                let b_offset = a_size.abi_align(b.align(self));\n-                let b_ptr = ptr.offset(b_offset, self)?.into();\n-                let a_val = self.memory.read_scalar(a_ptr, ptr_align, a_size)?;\n-                let b_val = self.memory.read_scalar(b_ptr, ptr_align, b_size)?;\n-                Ok(Some(Value::ScalarPair(a_val, b_val)))\n-            }\n-            _ => Ok(None),\n-        }\n-    }\n-\n     pub fn frame(&self) -> &Frame<'mir, 'tcx> {\n         self.stack.last().expect(\"no call frames exist\")\n     }\n@@ -1869,45 +1158,4 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M\n             }\n         }\n     }\n-\n-    pub fn storage_live(&mut self, local: mir::Local) -> EvalResult<'tcx, LocalValue> {\n-        trace!(\"{:?} is now live\", local);\n-\n-        let ty = self.frame().mir.local_decls[local].ty;\n-        let init = self.init_value(ty)?;\n-        // StorageLive *always* kills the value that's currently stored\n-        Ok(mem::replace(&mut self.frame_mut().locals[local], LocalValue::Live(init)))\n-    }\n-\n-    fn init_value(&mut self, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n-        let ty = self.monomorphize(ty, self.substs());\n-        let layout = self.layout_of(ty)?;\n-        Ok(match layout.abi {\n-            layout::Abi::Scalar(..) => Value::Scalar(ScalarMaybeUndef::Undef),\n-            layout::Abi::ScalarPair(..) => Value::ScalarPair(\n-                ScalarMaybeUndef::Undef,\n-                ScalarMaybeUndef::Undef,\n-            ),\n-            _ => Value::ByRef(self.alloc_ptr(layout)?.into(), layout.align),\n-        })\n-    }\n-}\n-\n-impl<'mir, 'tcx> Frame<'mir, 'tcx> {\n-    fn set_local(&mut self, local: mir::Local, value: Value) -> EvalResult<'tcx> {\n-        match self.locals[local] {\n-            LocalValue::Dead => err!(DeadLocal),\n-            LocalValue::Live(ref mut local) => {\n-                *local = value;\n-                Ok(())\n-            }\n-        }\n-    }\n-\n-    /// Returns the old value of the local\n-    pub fn storage_dead(&mut self, local: mir::Local) -> LocalValue {\n-        trace!(\"{:?} is now dead\", local);\n-\n-        mem::replace(&mut self.locals[local], LocalValue::Dead)\n-    }\n }"}, {"sha": "1bae930fc3f50ad2dc9e5674e21d10a04d5de39a", "filename": "src/librustc_mir/interpret/mod.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmod.rs?ref=7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "patch": "@@ -10,6 +10,7 @@ mod operator;\n mod step;\n mod terminator;\n mod traits;\n+mod value;\n \n pub use self::eval_context::{\n     EvalContext, Frame, StackPopCleanup,\n@@ -36,6 +37,8 @@ pub use self::machine::Machine;\n \n pub use self::memory::{write_target_uint, write_target_int, read_target_uint};\n \n+use self::value::LocalValue;\n+\n use rustc::ty::layout::TyLayout;\n \n pub fn sign_extend(value: u128, layout: TyLayout<'_>) -> u128 {"}, {"sha": "27a5fcdaf2e27608cca80217ad388898afb6695f", "filename": "src/librustc_mir/interpret/step.rs", "status": "modified", "additions": 197, "deletions": 3, "changes": 200, "blob_url": "https://github.com/rust-lang/rust/blob/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Fstep.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Fstep.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fstep.rs?ref=7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "patch": "@@ -2,10 +2,12 @@\n //!\n //! The main entry point is the `step` method.\n \n-use rustc::mir;\n+use rustc::{mir, ty};\n+use rustc::ty::layout::LayoutOf;\n+use rustc::mir::interpret::{EvalResult, Scalar, Value};\n+use rustc_data_structures::indexed_vec::Idx;\n \n-use rustc::mir::interpret::EvalResult;\n-use super::{EvalContext, Machine};\n+use super::{EvalContext, Machine, PlaceExtra, ValTy};\n \n impl<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M> {\n     pub fn inc_step_counter_and_detect_loops(&mut self) -> EvalResult<'tcx, ()> {\n@@ -127,6 +129,198 @@ impl<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M> {\n         Ok(())\n     }\n \n+    /// Evaluate an assignment statement.\n+    ///\n+    /// There is no separate `eval_rvalue` function. Instead, the code for handling each rvalue\n+    /// type writes its results directly into the memory specified by the place.\n+    fn eval_rvalue_into_place(\n+        &mut self,\n+        rvalue: &mir::Rvalue<'tcx>,\n+        place: &mir::Place<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let dest = self.eval_place(place)?;\n+        let dest_ty = self.place_ty(place);\n+        let dest_layout = self.layout_of(dest_ty)?;\n+\n+        use rustc::mir::Rvalue::*;\n+        match *rvalue {\n+            Use(ref operand) => {\n+                let value = self.eval_operand(operand)?.value;\n+                let valty = ValTy {\n+                    value,\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)?;\n+            }\n+\n+            BinaryOp(bin_op, ref left, ref right) => {\n+                let left = self.eval_operand(left)?;\n+                let right = self.eval_operand(right)?;\n+                self.intrinsic_overflowing(\n+                    bin_op,\n+                    left,\n+                    right,\n+                    dest,\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            CheckedBinaryOp(bin_op, ref left, ref right) => {\n+                let left = self.eval_operand(left)?;\n+                let right = self.eval_operand(right)?;\n+                self.intrinsic_with_overflow(\n+                    bin_op,\n+                    left,\n+                    right,\n+                    dest,\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            UnaryOp(un_op, ref operand) => {\n+                let val = self.eval_operand_to_scalar(operand)?;\n+                let val = self.unary_op(un_op, val, dest_layout)?;\n+                self.write_scalar(\n+                    dest,\n+                    val,\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            Aggregate(ref kind, ref operands) => {\n+                let (dest, active_field_index) = match **kind {\n+                    mir::AggregateKind::Adt(adt_def, variant_index, _, active_field_index) => {\n+                        self.write_discriminant_value(dest_ty, dest, variant_index)?;\n+                        if adt_def.is_enum() {\n+                            (self.place_downcast(dest, variant_index)?, active_field_index)\n+                        } else {\n+                            (dest, active_field_index)\n+                        }\n+                    }\n+                    _ => (dest, None)\n+                };\n+\n+                let layout = self.layout_of(dest_ty)?;\n+                for (i, operand) in operands.iter().enumerate() {\n+                    let value = self.eval_operand(operand)?;\n+                    // Ignore zero-sized fields.\n+                    if !self.layout_of(value.ty)?.is_zst() {\n+                        let field_index = active_field_index.unwrap_or(i);\n+                        let (field_dest, _) = self.place_field(dest, mir::Field::new(field_index), layout)?;\n+                        self.write_value(value, field_dest)?;\n+                    }\n+                }\n+            }\n+\n+            Repeat(ref operand, _) => {\n+                let (elem_ty, length) = match dest_ty.sty {\n+                    ty::TyArray(elem_ty, n) => (elem_ty, n.unwrap_usize(self.tcx.tcx)),\n+                    _ => {\n+                        bug!(\n+                            \"tried to assign array-repeat to non-array type {:?}\",\n+                            dest_ty\n+                        )\n+                    }\n+                };\n+                let elem_size = self.layout_of(elem_ty)?.size;\n+                let value = self.eval_operand(operand)?.value;\n+\n+                let (dest, dest_align) = self.force_allocation(dest)?.to_ptr_align();\n+\n+                if length > 0 {\n+                    let dest = dest.unwrap_or_err()?;\n+                    //write the first value\n+                    self.write_value_to_ptr(value, dest, dest_align, elem_ty)?;\n+\n+                    if length > 1 {\n+                        let rest = dest.ptr_offset(elem_size * 1 as u64, &self)?;\n+                        self.memory.copy_repeatedly(dest, dest_align, rest, dest_align, elem_size, length - 1, false)?;\n+                    }\n+                }\n+            }\n+\n+            Len(ref place) => {\n+                // FIXME(CTFE): don't allow computing the length of arrays in const eval\n+                let src = self.eval_place(place)?;\n+                let ty = self.place_ty(place);\n+                let (_, len) = src.elem_ty_and_len(ty, self.tcx.tcx);\n+                let size = self.memory.pointer_size().bytes() as u8;\n+                self.write_scalar(\n+                    dest,\n+                    Scalar::Bits {\n+                        bits: len as u128,\n+                        size,\n+                    },\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            Ref(_, _, ref place) => {\n+                let src = self.eval_place(place)?;\n+                // We ignore the alignment of the place here -- special handling for packed structs ends\n+                // at the `&` operator.\n+                let (ptr, _align, extra) = self.force_allocation(src)?.to_ptr_align_extra();\n+\n+                let val = match extra {\n+                    PlaceExtra::None => Value::Scalar(ptr),\n+                    PlaceExtra::Length(len) => ptr.to_value_with_len(len, self.tcx.tcx),\n+                    PlaceExtra::Vtable(vtable) => ptr.to_value_with_vtable(vtable),\n+                    PlaceExtra::DowncastVariant(..) => {\n+                        bug!(\"attempted to take a reference to an enum downcast place\")\n+                    }\n+                };\n+                let valty = ValTy {\n+                    value: val,\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)?;\n+            }\n+\n+            NullaryOp(mir::NullOp::Box, ty) => {\n+                let ty = self.monomorphize(ty, self.substs());\n+                M::box_alloc(self, ty, dest)?;\n+            }\n+\n+            NullaryOp(mir::NullOp::SizeOf, ty) => {\n+                let ty = self.monomorphize(ty, self.substs());\n+                let layout = self.layout_of(ty)?;\n+                assert!(!layout.is_unsized(),\n+                        \"SizeOf nullary MIR operator called for unsized type\");\n+                let size = self.memory.pointer_size().bytes() as u8;\n+                self.write_scalar(\n+                    dest,\n+                    Scalar::Bits {\n+                        bits: layout.size.bytes() as u128,\n+                        size,\n+                    },\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            Cast(kind, ref operand, cast_ty) => {\n+                debug_assert_eq!(self.monomorphize(cast_ty, self.substs()), dest_ty);\n+                let src = self.eval_operand(operand)?;\n+                self.cast(src, kind, dest_ty, dest)?;\n+            }\n+\n+            Discriminant(ref place) => {\n+                let ty = self.place_ty(place);\n+                let layout = self.layout_of(ty)?;\n+                let place = self.eval_place(place)?;\n+                let discr_val = self.read_discriminant_value(place, layout)?;\n+                let size = self.layout_of(dest_ty).unwrap().size.bytes() as u8;\n+                self.write_scalar(dest, Scalar::Bits {\n+                    bits: discr_val,\n+                    size,\n+                }, dest_ty)?;\n+            }\n+        }\n+\n+        self.dump_local(dest);\n+\n+        Ok(())\n+    }\n+\n     fn terminator(&mut self, terminator: &mir::Terminator<'tcx>) -> EvalResult<'tcx> {\n         trace!(\"{:?}\", terminator.kind);\n         self.tcx.span = terminator.source_info.span;"}, {"sha": "c450901eec8b715ba419fd0dd6b66105bb2bf733", "filename": "src/librustc_mir/interpret/value.rs", "status": "added", "additions": 572, "deletions": 0, "changes": 572, "blob_url": "https://github.com/rust-lang/rust/blob/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d4f5f7974f75635c88af31013ae7cc0ed1927ef/src%2Flibrustc_mir%2Finterpret%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fvalue.rs?ref=7d4f5f7974f75635c88af31013ae7cc0ed1927ef", "patch": "@@ -0,0 +1,572 @@\n+//! Reading and writing values from/to memory, handling LocalValue and the ByRef optimization,\n+//! reading/writing discriminants\n+\n+use std::mem;\n+\n+use rustc::mir;\n+use rustc::ty::layout::{self, Size, Align, IntegerExt, LayoutOf, TyLayout, Primitive};\n+use rustc::ty::{self, Ty, TyCtxt, TypeAndMut};\n+use rustc_data_structures::indexed_vec::{IndexVec, Idx};\n+use rustc::mir::interpret::{\n+    GlobalId, Value, Scalar, FrameInfo, AllocType,\n+    EvalResult, EvalErrorKind, Pointer, ConstValue,\n+    ScalarMaybeUndef,\n+};\n+\n+use super::{Place, PlaceExtra, Memory, Frame,\n+            HasMemory, MemoryKind,\n+            Machine, ValTy, EvalContext};\n+\n+#[derive(Copy, Clone, PartialEq, Eq, Hash)]\n+pub enum LocalValue {\n+    Dead,\n+    Live(Value),\n+}\n+\n+impl LocalValue {\n+    pub fn access(self) -> EvalResult<'static, Value> {\n+        match self {\n+            LocalValue::Dead => err!(DeadLocal),\n+            LocalValue::Live(val) => Ok(val),\n+        }\n+    }\n+}\n+\n+impl<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> EvalContext<'a, 'mir, 'tcx, M> {\n+    pub fn write_ptr(&mut self, dest: Place, val: Scalar, dest_ty: Ty<'tcx>) -> EvalResult<'tcx> {\n+        let valty = ValTy {\n+            value: val.to_value(),\n+            ty: dest_ty,\n+        };\n+        self.write_value(valty, dest)\n+    }\n+\n+    pub fn write_scalar(\n+        &mut self,\n+        dest: Place,\n+        val: impl Into<ScalarMaybeUndef>,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let valty = ValTy {\n+            value: Value::Scalar(val.into()),\n+            ty: dest_ty,\n+        };\n+        self.write_value(valty, dest)\n+    }\n+\n+    pub fn write_value(\n+        &mut self,\n+        ValTy { value: src_val, ty: dest_ty } : ValTy<'tcx>,\n+        dest: Place,\n+    ) -> EvalResult<'tcx> {\n+        //trace!(\"Writing {:?} to {:?} at type {:?}\", src_val, dest, dest_ty);\n+        // Note that it is really important that the type here is the right one, and matches the type things are read at.\n+        // In case `src_val` is a `ScalarPair`, we don't do any magic here to handle padding properly, which is only\n+        // correct if we never look at this data with the wrong type.\n+\n+        match dest {\n+            Place::Ptr { ptr, align, extra } => {\n+                assert_eq!(extra, PlaceExtra::None);\n+                self.write_value_to_ptr(src_val, ptr.unwrap_or_err()?, align, dest_ty)\n+            }\n+\n+            Place::Local { frame, local } => {\n+                let old_val = self.stack[frame].locals[local].access()?;\n+                self.write_value_possibly_by_val(\n+                    src_val,\n+                    |this, val| this.stack[frame].set_local(local, val),\n+                    old_val,\n+                    dest_ty,\n+                )\n+            }\n+        }\n+    }\n+\n+    // The cases here can be a bit subtle. Read carefully!\n+    fn write_value_possibly_by_val<F: FnOnce(&mut Self, Value) -> EvalResult<'tcx>>(\n+        &mut self,\n+        src_val: Value,\n+        write_dest: F,\n+        old_dest_val: Value,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        // FIXME: this should be a layout check, not underlying value\n+        if let Value::ByRef(dest_ptr, align) = old_dest_val {\n+            // If the value is already `ByRef` (that is, backed by an `Allocation`),\n+            // then we must write the new value into this allocation, because there may be\n+            // other pointers into the allocation. These other pointers are logically\n+            // pointers into the local variable, and must be able to observe the change.\n+            //\n+            // Thus, it would be an error to replace the `ByRef` with a `ByVal`, unless we\n+            // knew for certain that there were no outstanding pointers to this allocation.\n+            self.write_value_to_ptr(src_val, dest_ptr, align, dest_ty)?;\n+        } else if let Value::ByRef(src_ptr, align) = src_val {\n+            // If the value is not `ByRef`, then we know there are no pointers to it\n+            // and we can simply overwrite the `Value` in the locals array directly.\n+            //\n+            // In this specific case, where the source value is `ByRef`, we must duplicate\n+            // the allocation, because this is a by-value operation. It would be incorrect\n+            // if they referred to the same allocation, since then a change to one would\n+            // implicitly change the other.\n+            //\n+            // It is a valid optimization to attempt reading a primitive value out of the\n+            // source and write that into the destination without making an allocation, so\n+            // we do so here.\n+            if let Ok(Some(src_val)) = self.try_read_value(src_ptr, align, dest_ty) {\n+                write_dest(self, src_val)?;\n+            } else {\n+                let layout = self.layout_of(dest_ty)?;\n+                let dest_ptr = self.alloc_ptr(layout)?.into();\n+                self.memory.copy(src_ptr, align.min(layout.align), dest_ptr, layout.align, layout.size, false)?;\n+                write_dest(self, Value::ByRef(dest_ptr, layout.align))?;\n+            }\n+        } else {\n+            // Finally, we have the simple case where neither source nor destination are\n+            // `ByRef`. We may simply copy the source value over the the destintion.\n+            write_dest(self, src_val)?;\n+        }\n+        Ok(())\n+    }\n+\n+    pub fn write_value_to_ptr(\n+        &mut self,\n+        value: Value,\n+        dest: Scalar,\n+        dest_align: Align,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let layout = self.layout_of(dest_ty)?;\n+        trace!(\"write_value_to_ptr: {:#?}, {}, {:#?}\", value, dest_ty, layout);\n+        match value {\n+            Value::ByRef(ptr, align) => {\n+                self.memory.copy(ptr, align.min(layout.align), dest, dest_align.min(layout.align), layout.size, false)\n+            }\n+            Value::Scalar(scalar) => {\n+                let signed = match layout.abi {\n+                    layout::Abi::Scalar(ref scal) => match scal.value {\n+                        layout::Primitive::Int(_, signed) => signed,\n+                        _ => false,\n+                    },\n+                    _ => false,\n+                };\n+                self.memory.write_scalar(dest, dest_align, scalar, layout.size, layout.align, signed)\n+            }\n+            Value::ScalarPair(a_val, b_val) => {\n+                trace!(\"write_value_to_ptr valpair: {:#?}\", layout);\n+                let (a, b) = match layout.abi {\n+                    layout::Abi::ScalarPair(ref a, ref b) => (&a.value, &b.value),\n+                    _ => bug!(\"write_value_to_ptr: invalid ScalarPair layout: {:#?}\", layout)\n+                };\n+                let (a_size, b_size) = (a.size(&self), b.size(&self));\n+                let (a_align, b_align) = (a.align(&self), b.align(&self));\n+                let a_ptr = dest;\n+                let b_offset = a_size.abi_align(b_align);\n+                let b_ptr = dest.ptr_offset(b_offset, &self)?.into();\n+                // TODO: What about signedess?\n+                self.memory.write_scalar(a_ptr, dest_align, a_val, a_size, a_align, false)?;\n+                self.memory.write_scalar(b_ptr, dest_align, b_val, b_size, b_align, false)\n+            }\n+        }\n+    }\n+\n+    pub fn try_read_value(&self, ptr: Scalar, ptr_align: Align, ty: Ty<'tcx>) -> EvalResult<'tcx, Option<Value>> {\n+        let layout = self.layout_of(ty)?;\n+        self.memory.check_align(ptr, ptr_align)?;\n+\n+        if layout.size.bytes() == 0 {\n+            return Ok(Some(Value::Scalar(ScalarMaybeUndef::Scalar(Scalar::Bits { bits: 0, size: 0 }))));\n+        }\n+\n+        let ptr = ptr.to_ptr()?;\n+\n+        match layout.abi {\n+            layout::Abi::Scalar(..) => {\n+                let scalar = self.memory.read_scalar(ptr, ptr_align, layout.size)?;\n+                Ok(Some(Value::Scalar(scalar)))\n+            }\n+            layout::Abi::ScalarPair(ref a, ref b) => {\n+                let (a, b) = (&a.value, &b.value);\n+                let (a_size, b_size) = (a.size(self), b.size(self));\n+                let a_ptr = ptr;\n+                let b_offset = a_size.abi_align(b.align(self));\n+                let b_ptr = ptr.offset(b_offset, self)?.into();\n+                let a_val = self.memory.read_scalar(a_ptr, ptr_align, a_size)?;\n+                let b_val = self.memory.read_scalar(b_ptr, ptr_align, b_size)?;\n+                Ok(Some(Value::ScalarPair(a_val, b_val)))\n+            }\n+            _ => Ok(None),\n+        }\n+    }\n+\n+    pub fn read_value(&self, ptr: Scalar, align: Align, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n+        if let Some(val) = self.try_read_value(ptr, align, ty)? {\n+            Ok(val)\n+        } else {\n+            bug!(\"primitive read failed for type: {:?}\", ty);\n+        }\n+    }\n+\n+    pub(super) fn eval_operand_to_scalar(\n+        &mut self,\n+        op: &mir::Operand<'tcx>,\n+    ) -> EvalResult<'tcx, Scalar> {\n+        let valty = self.eval_operand(op)?;\n+        self.value_to_scalar(valty)\n+    }\n+\n+    pub(crate) fn operands_to_args(\n+        &mut self,\n+        ops: &[mir::Operand<'tcx>],\n+    ) -> EvalResult<'tcx, Vec<ValTy<'tcx>>> {\n+        ops.into_iter()\n+            .map(|op| self.eval_operand(op))\n+            .collect()\n+    }\n+\n+    pub fn eval_operand(&mut self, op: &mir::Operand<'tcx>) -> EvalResult<'tcx, ValTy<'tcx>> {\n+        use rustc::mir::Operand::*;\n+        let ty = self.monomorphize(op.ty(self.mir(), *self.tcx), self.substs());\n+        match *op {\n+            // FIXME: do some more logic on `move` to invalidate the old location\n+            Copy(ref place) |\n+            Move(ref place) => {\n+                Ok(ValTy {\n+                    value: self.eval_and_read_place(place)?,\n+                    ty\n+                })\n+            },\n+\n+            Constant(ref constant) => {\n+                let value = self.const_to_value(constant.literal.val)?;\n+\n+                Ok(ValTy {\n+                    value,\n+                    ty,\n+                })\n+            }\n+        }\n+    }\n+\n+    pub fn deallocate_local(&mut self, local: LocalValue) -> EvalResult<'tcx> {\n+        // FIXME: should we tell the user that there was a local which was never written to?\n+        if let LocalValue::Live(Value::ByRef(ptr, _align)) = local {\n+            trace!(\"deallocating local\");\n+            let ptr = ptr.to_ptr()?;\n+            self.memory.dump_alloc(ptr.alloc_id);\n+            self.memory.deallocate_local(ptr)?;\n+        };\n+        Ok(())\n+    }\n+\n+    pub fn allocate_place_for_value(\n+        &mut self,\n+        value: Value,\n+        layout: TyLayout<'tcx>,\n+        variant: Option<usize>,\n+    ) -> EvalResult<'tcx, Place> {\n+        let (ptr, align) = match value {\n+            Value::ByRef(ptr, align) => (ptr, align),\n+            Value::ScalarPair(..) | Value::Scalar(_) => {\n+                let ptr = self.alloc_ptr(layout)?.into();\n+                self.write_value_to_ptr(value, ptr, layout.align, layout.ty)?;\n+                (ptr, layout.align)\n+            },\n+        };\n+        Ok(Place::Ptr {\n+            ptr: ptr.into(),\n+            align,\n+            extra: variant.map_or(PlaceExtra::None, PlaceExtra::DowncastVariant),\n+        })\n+    }\n+\n+    pub fn force_allocation(&mut self, place: Place) -> EvalResult<'tcx, Place> {\n+        let new_place = match place {\n+            Place::Local { frame, local } => {\n+                match self.stack[frame].locals[local].access()? {\n+                    Value::ByRef(ptr, align) => {\n+                        Place::Ptr {\n+                            ptr: ptr.into(),\n+                            align,\n+                            extra: PlaceExtra::None,\n+                        }\n+                    }\n+                    val => {\n+                        let ty = self.stack[frame].mir.local_decls[local].ty;\n+                        let ty = self.monomorphize(ty, self.stack[frame].instance.substs);\n+                        let layout = self.layout_of(ty)?;\n+                        let ptr = self.alloc_ptr(layout)?;\n+                        self.stack[frame].locals[local] =\n+                            LocalValue::Live(Value::ByRef(ptr.into(), layout.align)); // it stays live\n+\n+                        let place = Place::from_ptr(ptr, layout.align);\n+                        self.write_value(ValTy { value: val, ty }, place)?;\n+                        place\n+                    }\n+                }\n+            }\n+            Place::Ptr { .. } => place,\n+        };\n+        Ok(new_place)\n+    }\n+\n+    /// Convert to ByVal or ScalarPair *if possible*, leave `ByRef` otherwise\n+    pub fn try_read_by_ref(&self, mut val: Value, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n+        if let Value::ByRef(ptr, align) = val {\n+            if let Some(read_val) = self.try_read_value(ptr, align, ty)? {\n+                val = read_val;\n+            }\n+        }\n+        Ok(val)\n+    }\n+\n+    pub fn value_to_scalar(\n+        &self,\n+        ValTy { value, ty } : ValTy<'tcx>,\n+    ) -> EvalResult<'tcx, Scalar> {\n+        let value = match value {\n+            Value::ByRef(ptr, align) => self.read_value(ptr, align, ty)?,\n+            scalar_or_pair => scalar_or_pair,\n+        };\n+        match value {\n+            Value::ByRef(..) => bug!(\"read_value can't result in `ByRef`\"),\n+\n+            Value::Scalar(scalar) => scalar.unwrap_or_err(),\n+\n+            Value::ScalarPair(..) => bug!(\"value_to_scalar can't work with fat pointers\"),\n+        }\n+    }\n+\n+    pub fn storage_live(&mut self, local: mir::Local) -> EvalResult<'tcx, LocalValue> {\n+        trace!(\"{:?} is now live\", local);\n+\n+        let ty = self.frame().mir.local_decls[local].ty;\n+        let init = self.init_value(ty)?;\n+        // StorageLive *always* kills the value that's currently stored\n+        Ok(mem::replace(&mut self.frame_mut().locals[local], LocalValue::Live(init)))\n+    }\n+\n+    pub(super) fn init_value(&mut self, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n+        let ty = self.monomorphize(ty, self.substs());\n+        let layout = self.layout_of(ty)?;\n+        Ok(match layout.abi {\n+            layout::Abi::Scalar(..) => Value::Scalar(ScalarMaybeUndef::Undef),\n+            layout::Abi::ScalarPair(..) => Value::ScalarPair(\n+                ScalarMaybeUndef::Undef,\n+                ScalarMaybeUndef::Undef,\n+            ),\n+            _ => Value::ByRef(self.alloc_ptr(layout)?.into(), layout.align),\n+        })\n+    }\n+\n+    /// reads a tag and produces the corresponding variant index\n+    pub fn read_discriminant_as_variant_index(\n+        &self,\n+        place: Place,\n+        layout: TyLayout<'tcx>,\n+    ) -> EvalResult<'tcx, usize> {\n+        match layout.variants {\n+            ty::layout::Variants::Single { index } => Ok(index),\n+            ty::layout::Variants::Tagged { .. } => {\n+                let discr_val = self.read_discriminant_value(place, layout)?;\n+                layout\n+                    .ty\n+                    .ty_adt_def()\n+                    .expect(\"tagged layout for non adt\")\n+                    .discriminants(self.tcx.tcx)\n+                    .position(|var| var.val == discr_val)\n+                    .ok_or_else(|| EvalErrorKind::InvalidDiscriminant.into())\n+            }\n+            ty::layout::Variants::NicheFilling { .. } => {\n+                let discr_val = self.read_discriminant_value(place, layout)?;\n+                assert_eq!(discr_val as usize as u128, discr_val);\n+                Ok(discr_val as usize)\n+            },\n+        }\n+    }\n+\n+    pub fn read_discriminant_value(\n+        &self,\n+        place: Place,\n+        layout: TyLayout<'tcx>,\n+    ) -> EvalResult<'tcx, u128> {\n+        trace!(\"read_discriminant_value {:#?}\", layout);\n+        if layout.abi == layout::Abi::Uninhabited {\n+            return Ok(0);\n+        }\n+\n+        match layout.variants {\n+            layout::Variants::Single { index } => {\n+                let discr_val = layout.ty.ty_adt_def().map_or(\n+                    index as u128,\n+                    |def| def.discriminant_for_variant(*self.tcx, index).val);\n+                return Ok(discr_val);\n+            }\n+            layout::Variants::Tagged { .. } |\n+            layout::Variants::NicheFilling { .. } => {},\n+        }\n+        let discr_place_val = self.read_place(place)?;\n+        let (discr_val, discr) = self.read_field(discr_place_val, None, mir::Field::new(0), layout)?;\n+        trace!(\"discr value: {:?}, {:?}\", discr_val, discr);\n+        let raw_discr = self.value_to_scalar(ValTy {\n+            value: discr_val,\n+            ty: discr.ty\n+        })?;\n+        let discr_val = match layout.variants {\n+            layout::Variants::Single { .. } => bug!(),\n+            // FIXME: should we catch invalid discriminants here?\n+            layout::Variants::Tagged { .. } => {\n+                if discr.ty.is_signed() {\n+                    let i = raw_discr.to_bits(discr.size)? as i128;\n+                    // going from layout tag type to typeck discriminant type\n+                    // requires first sign extending with the layout discriminant\n+                    let shift = 128 - discr.size.bits();\n+                    let sexted = (i << shift) >> shift;\n+                    // and then zeroing with the typeck discriminant type\n+                    let discr_ty = layout\n+                        .ty\n+                        .ty_adt_def().expect(\"tagged layout corresponds to adt\")\n+                        .repr\n+                        .discr_type();\n+                    let discr_ty = layout::Integer::from_attr(self.tcx.tcx, discr_ty);\n+                    let shift = 128 - discr_ty.size().bits();\n+                    let truncatee = sexted as u128;\n+                    (truncatee << shift) >> shift\n+                } else {\n+                    raw_discr.to_bits(discr.size)?\n+                }\n+            },\n+            layout::Variants::NicheFilling {\n+                dataful_variant,\n+                ref niche_variants,\n+                niche_start,\n+                ..\n+            } => {\n+                let variants_start = *niche_variants.start() as u128;\n+                let variants_end = *niche_variants.end() as u128;\n+                match raw_discr {\n+                    Scalar::Ptr(_) => {\n+                        assert!(niche_start == 0);\n+                        assert!(variants_start == variants_end);\n+                        dataful_variant as u128\n+                    },\n+                    Scalar::Bits { bits: raw_discr, size } => {\n+                        assert_eq!(size as u64, discr.size.bytes());\n+                        let discr = raw_discr.wrapping_sub(niche_start)\n+                            .wrapping_add(variants_start);\n+                        if variants_start <= discr && discr <= variants_end {\n+                            discr\n+                        } else {\n+                            dataful_variant as u128\n+                        }\n+                    },\n+                }\n+            }\n+        };\n+\n+        Ok(discr_val)\n+    }\n+\n+\n+    pub fn write_discriminant_value(\n+        &mut self,\n+        dest_ty: Ty<'tcx>,\n+        dest: Place,\n+        variant_index: usize,\n+    ) -> EvalResult<'tcx> {\n+        let layout = self.layout_of(dest_ty)?;\n+\n+        match layout.variants {\n+            layout::Variants::Single { index } => {\n+                if index != variant_index {\n+                    // If the layout of an enum is `Single`, all\n+                    // other variants are necessarily uninhabited.\n+                    assert_eq!(layout.for_variant(&self, variant_index).abi,\n+                               layout::Abi::Uninhabited);\n+                }\n+            }\n+            layout::Variants::Tagged { ref tag, .. } => {\n+                let discr_val = dest_ty.ty_adt_def().unwrap()\n+                    .discriminant_for_variant(*self.tcx, variant_index)\n+                    .val;\n+\n+                // raw discriminants for enums are isize or bigger during\n+                // their computation, but the in-memory tag is the smallest possible\n+                // representation\n+                let size = tag.value.size(self.tcx.tcx);\n+                let shift = 128 - size.bits();\n+                let discr_val = (discr_val << shift) >> shift;\n+\n+                let (discr_dest, tag) = self.place_field(dest, mir::Field::new(0), layout)?;\n+                self.write_scalar(discr_dest, Scalar::Bits {\n+                    bits: discr_val,\n+                    size: size.bytes() as u8,\n+                }, tag.ty)?;\n+            }\n+            layout::Variants::NicheFilling {\n+                dataful_variant,\n+                ref niche_variants,\n+                niche_start,\n+                ..\n+            } => {\n+                if variant_index != dataful_variant {\n+                    let (niche_dest, niche) =\n+                        self.place_field(dest, mir::Field::new(0), layout)?;\n+                    let niche_value = ((variant_index - niche_variants.start()) as u128)\n+                        .wrapping_add(niche_start);\n+                    self.write_scalar(niche_dest, Scalar::Bits {\n+                        bits: niche_value,\n+                        size: niche.size.bytes() as u8,\n+                    }, niche.ty)?;\n+                }\n+            }\n+        }\n+\n+        Ok(())\n+    }\n+\n+    pub fn str_to_value(&mut self, s: &str) -> EvalResult<'tcx, Value> {\n+        let ptr = self.memory.allocate_bytes(s.as_bytes());\n+        Ok(Scalar::Ptr(ptr).to_value_with_len(s.len() as u64, self.tcx.tcx))\n+    }\n+\n+    pub fn const_to_value(\n+        &mut self,\n+        val: ConstValue<'tcx>,\n+    ) -> EvalResult<'tcx, Value> {\n+        match val {\n+            ConstValue::Unevaluated(def_id, substs) => {\n+                let instance = self.resolve(def_id, substs)?;\n+                self.read_global_as_value(GlobalId {\n+                    instance,\n+                    promoted: None,\n+                })\n+            }\n+            ConstValue::ByRef(alloc, offset) => {\n+                // FIXME: Allocate new AllocId for all constants inside\n+                let id = self.memory.allocate_value(alloc.clone(), MemoryKind::Stack)?;\n+                Ok(Value::ByRef(Pointer::new(id, offset).into(), alloc.align))\n+            },\n+            ConstValue::ScalarPair(a, b) => Ok(Value::ScalarPair(a.into(), b.into())),\n+            ConstValue::Scalar(val) => Ok(Value::Scalar(val.into())),\n+        }\n+    }\n+}\n+\n+impl<'mir, 'tcx> Frame<'mir, 'tcx> {\n+    pub(super) fn set_local(&mut self, local: mir::Local, value: Value) -> EvalResult<'tcx> {\n+        match self.locals[local] {\n+            LocalValue::Dead => err!(DeadLocal),\n+            LocalValue::Live(ref mut local) => {\n+                *local = value;\n+                Ok(())\n+            }\n+        }\n+    }\n+\n+    /// Returns the old value of the local\n+    pub fn storage_dead(&mut self, local: mir::Local) -> LocalValue {\n+        trace!(\"{:?} is now dead\", local);\n+\n+        mem::replace(&mut self.locals[local], LocalValue::Dead)\n+    }\n+}"}]}