{"sha": "4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQwNjZjOGVjNzE4ZDgzMzhjMmZkNmUwMGNiNjNlMDNkMzU0NGJjZDE=", "commit": {"author": {"name": "Mark Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2017-05-16T23:31:50Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2017-05-16T23:31:50Z"}, "message": "Rollup merge of #41957 - llogiq:clippy-libsyntax, r=petrochenkov\n\nFix some clippy warnings in libsyntax\n\nThis is mostly removing stray ampersands, needless returns and lifetimes. Basically a lot of small changes.", "tree": {"sha": "7c6d8f39d6a240fa52d1b33e67c16ffa51f5040e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7c6d8f39d6a240fa52d1b33e67c16ffa51f5040e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "html_url": "https://github.com/rust-lang/rust/commit/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8f61055c529d12a04ee077ad42a80b9f9b952cb1", "url": "https://api.github.com/repos/rust-lang/rust/commits/8f61055c529d12a04ee077ad42a80b9f9b952cb1", "html_url": "https://github.com/rust-lang/rust/commit/8f61055c529d12a04ee077ad42a80b9f9b952cb1"}, {"sha": "282b40249e158376fcc4682879be40fb80c4e36f", "url": "https://api.github.com/repos/rust-lang/rust/commits/282b40249e158376fcc4682879be40fb80c4e36f", "html_url": "https://github.com/rust-lang/rust/commit/282b40249e158376fcc4682879be40fb80c4e36f"}], "stats": {"total": 1042, "additions": 504, "deletions": 538}, "files": [{"sha": "24ce99208ed11bc9e89cda6408003e12fa3207d2", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -715,7 +715,7 @@ impl Stmt {\n             StmtKind::Mac(mac) => StmtKind::Mac(mac.map(|(mac, _style, attrs)| {\n                 (mac, MacStmtStyle::Semicolon, attrs)\n             })),\n-            node @ _ => node,\n+            node => node,\n         };\n         self\n     }\n@@ -1076,16 +1076,16 @@ impl LitKind {\n     pub fn is_unsuffixed(&self) -> bool {\n         match *self {\n             // unsuffixed variants\n-            LitKind::Str(..) => true,\n-            LitKind::ByteStr(..) => true,\n-            LitKind::Byte(..) => true,\n-            LitKind::Char(..) => true,\n-            LitKind::Int(_, LitIntType::Unsuffixed) => true,\n-            LitKind::FloatUnsuffixed(..) => true,\n+            LitKind::Str(..) |\n+            LitKind::ByteStr(..) |\n+            LitKind::Byte(..) |\n+            LitKind::Char(..) |\n+            LitKind::Int(_, LitIntType::Unsuffixed) |\n+            LitKind::FloatUnsuffixed(..) |\n             LitKind::Bool(..) => true,\n             // suffixed variants\n-            LitKind::Int(_, LitIntType::Signed(..)) => false,\n-            LitKind::Int(_, LitIntType::Unsigned(..)) => false,\n+            LitKind::Int(_, LitIntType::Signed(..)) |\n+            LitKind::Int(_, LitIntType::Unsigned(..)) |\n             LitKind::Float(..) => false,\n         }\n     }"}, {"sha": "45f891d8dc56db911f325fd6ff90b4034066e834", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -112,15 +112,15 @@ impl NestedMetaItem {\n     /// Returns the MetaItem if self is a NestedMetaItemKind::MetaItem.\n     pub fn meta_item(&self) -> Option<&MetaItem> {\n         match self.node {\n-            NestedMetaItemKind::MetaItem(ref item) => Some(&item),\n+            NestedMetaItemKind::MetaItem(ref item) => Some(item),\n             _ => None\n         }\n     }\n \n     /// Returns the Lit if self is a NestedMetaItemKind::Literal.\n     pub fn literal(&self) -> Option<&Lit> {\n         match self.node {\n-            NestedMetaItemKind::Literal(ref lit) => Some(&lit),\n+            NestedMetaItemKind::Literal(ref lit) => Some(lit),\n             _ => None\n         }\n     }\n@@ -259,7 +259,7 @@ impl MetaItem {\n         match self.node {\n             MetaItemKind::NameValue(ref v) => {\n                 match v.node {\n-                    LitKind::Str(ref s, _) => Some((*s).clone()),\n+                    LitKind::Str(ref s, _) => Some(*s),\n                     _ => None,\n                 }\n             },\n@@ -1217,9 +1217,10 @@ impl LitKind {\n                 Token::Literal(token::Lit::Float(symbol), Some(Symbol::intern(ty.ty_to_string())))\n             }\n             LitKind::FloatUnsuffixed(symbol) => Token::Literal(token::Lit::Float(symbol), None),\n-            LitKind::Bool(value) => Token::Ident(Ident::with_empty_ctxt(Symbol::intern(match value {\n-                true => \"true\",\n-                false => \"false\",\n+            LitKind::Bool(value) => Token::Ident(Ident::with_empty_ctxt(Symbol::intern(if value {\n+                \"true\"\n+            } else {\n+                \"false\"\n             }))),\n         }\n     }\n@@ -1261,7 +1262,7 @@ impl<T: HasAttrs> HasAttrs for Spanned<T> {\n \n impl HasAttrs for Vec<Attribute> {\n     fn attrs(&self) -> &[Attribute] {\n-        &self\n+        self\n     }\n     fn map_attrs<F: FnOnce(Vec<Attribute>) -> Vec<Attribute>>(self, f: F) -> Self {\n         f(self)\n@@ -1270,7 +1271,7 @@ impl HasAttrs for Vec<Attribute> {\n \n impl HasAttrs for ThinVec<Attribute> {\n     fn attrs(&self) -> &[Attribute] {\n-        &self\n+        self\n     }\n     fn map_attrs<F: FnOnce(Vec<Attribute>) -> Vec<Attribute>>(self, f: F) -> Self {\n         f(self.into()).into()"}, {"sha": "d32c3ec5f46b1f063bbcfa26ebea609d7b158178", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -485,7 +485,7 @@ impl CodeMap {\n         match self.span_to_snippet(sp) {\n             Ok(snippet) => {\n                 let snippet = snippet.split(c).nth(0).unwrap_or(\"\").trim_right();\n-                if snippet.len() > 0 && !snippet.contains('\\n') {\n+                if !snippet.is_empty() && !snippet.contains('\\n') {\n                     Span { hi: BytePos(sp.lo.0 + snippet.len() as u32), ..sp }\n                 } else {\n                     sp\n@@ -502,7 +502,7 @@ impl CodeMap {\n     pub fn get_filemap(&self, filename: &str) -> Option<Rc<FileMap>> {\n         for fm in self.files.borrow().iter() {\n             if filename == fm.name {\n-               (self.dep_tracking_callback.borrow())(&fm);\n+               (self.dep_tracking_callback.borrow())(fm);\n                 return Some(fm.clone());\n             }\n         }"}, {"sha": "2e98c7d962606cf524f7cbd718f008f507591b4e", "filename": "src/libsyntax/config.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fconfig.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -123,7 +123,7 @@ impl<'a> StripUnconfigured<'a> {\n                 return false;\n             }\n \n-            let mis = if !is_cfg(&attr) {\n+            let mis = if !is_cfg(attr) {\n                 return true;\n             } else if let Some(mis) = attr.meta_item_list() {\n                 mis\n@@ -150,7 +150,7 @@ impl<'a> StripUnconfigured<'a> {\n         // flag the offending attributes\n         for attr in attrs.iter() {\n             if !self.features.map(|features| features.stmt_expr_attributes).unwrap_or(true) {\n-                let mut err = feature_err(&self.sess,\n+                let mut err = feature_err(self.sess,\n                                           \"stmt_expr_attributes\",\n                                           attr.span,\n                                           GateIssue::Language,\n@@ -258,7 +258,7 @@ impl<'a> StripUnconfigured<'a> {\n     pub fn configure_struct_expr_field(&mut self, field: ast::Field) -> Option<ast::Field> {\n         if !self.features.map(|features| features.struct_field_attributes).unwrap_or(true) {\n             if !field.attrs.is_empty() {\n-                let mut err = feature_err(&self.sess,\n+                let mut err = feature_err(self.sess,\n                                           \"struct_field_attributes\",\n                                           field.span,\n                                           GateIssue::Language,\n@@ -290,7 +290,7 @@ impl<'a> StripUnconfigured<'a> {\n         for attr in attrs.iter() {\n             if !self.features.map(|features| features.struct_field_attributes).unwrap_or(true) {\n                 let mut err = feature_err(\n-                    &self.sess,\n+                    self.sess,\n                     \"struct_field_attributes\",\n                     attr.span,\n                     GateIssue::Language,"}, {"sha": "73aeb40df840064ae0ffd2ea79ee369a9939d498", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -120,7 +120,7 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n \n         // URLs can be unavoidably longer than the line limit, so we allow them.\n         // Allowed format is: `[name]: https://www.rust-lang.org/`\n-        let is_url = |l: &str| l.starts_with('[') && l.contains(\"]:\") && l.contains(\"http\");\n+        let is_url = |l: &str| l.starts_with(\"[\") && l.contains(\"]:\") && l.contains(\"http\");\n \n         if msg.lines().any(|line| line.len() > MAX_DESCRIPTION_WIDTH && !is_url(line)) {\n             ecx.span_err(span, &format!(\n@@ -177,7 +177,7 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n             if let Err(e) = output_metadata(ecx,\n                                             &target_triple,\n                                             &crate_name.name.as_str(),\n-                                            &diagnostics) {\n+                                            diagnostics) {\n                 ecx.span_bug(span, &format!(\n                     \"error writing metadata for triple `{}` and crate `{}`, error: {}, \\\n                      cause: {:?}\",\n@@ -227,7 +227,7 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n \n     MacEager::items(SmallVector::many(vec![\n         P(ast::Item {\n-            ident: name.clone(),\n+            ident: *name,\n             attrs: Vec::new(),\n             id: ast::DUMMY_NODE_ID,\n             node: ast::ItemKind::Const("}, {"sha": "31a7e0d58d0d8e20fe3c290bee248f9a3378fec2", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -635,8 +635,8 @@ pub struct ExpansionData {\n }\n \n /// One of these is made during expansion and incrementally updated as we go;\n-/// when a macro expansion occurs, the resulting nodes have the backtrace()\n-/// -> expn_info of their expansion context stored into their span.\n+/// when a macro expansion occurs, the resulting nodes have the `backtrace()\n+/// -> expn_info` of their expansion context stored into their span.\n pub struct ExtCtxt<'a> {\n     pub parse_sess: &'a parse::ParseSess,\n     pub ecfg: expand::ExpansionConfig<'a>,\n@@ -709,7 +709,7 @@ impl<'a> ExtCtxt<'a> {\n                 }\n                 ctxt = info.call_site.ctxt;\n                 last_macro = Some(info.call_site);\n-                return Some(());\n+                Some(())\n             }).is_none() {\n                 break\n             }\n@@ -770,9 +770,9 @@ impl<'a> ExtCtxt<'a> {\n     }\n     pub fn trace_macros_diag(&self) {\n         for (sp, notes) in self.expansions.iter() {\n-            let mut db = self.parse_sess.span_diagnostic.span_note_diag(*sp, &\"trace_macro\");\n+            let mut db = self.parse_sess.span_diagnostic.span_note_diag(*sp, \"trace_macro\");\n             for note in notes {\n-                db.note(&note);\n+                db.note(note);\n             }\n             db.emit();\n         }\n@@ -795,7 +795,7 @@ impl<'a> ExtCtxt<'a> {\n             v.push(self.ident_of(s));\n         }\n         v.extend(components.iter().map(|s| self.ident_of(s)));\n-        return v\n+        v\n     }\n     pub fn name_of(&self, st: &str) -> ast::Name {\n         Symbol::intern(st)"}, {"sha": "a56336795392597e5f9645f315a9304d28ba5fda", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 11, "deletions": 15, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -415,19 +415,19 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n \n         match *ext {\n             MultiModifier(ref mac) => {\n-                let meta = panictry!(attr.parse_meta(&self.cx.parse_sess));\n+                let meta = panictry!(attr.parse_meta(self.cx.parse_sess));\n                 let item = mac.expand(self.cx, attr.span, &meta, item);\n                 kind.expect_from_annotatables(item)\n             }\n             MultiDecorator(ref mac) => {\n                 let mut items = Vec::new();\n-                let meta = panictry!(attr.parse_meta(&self.cx.parse_sess));\n+                let meta = panictry!(attr.parse_meta(self.cx.parse_sess));\n                 mac.expand(self.cx, attr.span, &meta, &item, &mut |item| items.push(item));\n                 items.push(item);\n                 kind.expect_from_annotatables(items)\n             }\n             SyntaxExtension::AttrProcMacro(ref mac) => {\n-                let item_toks = stream_for_item(&item, &self.cx.parse_sess);\n+                let item_toks = stream_for_item(&item, self.cx.parse_sess);\n \n                 let span = Span { ctxt: self.cx.backtrace(), ..attr.span };\n                 let tok_result = mac.expand(self.cx, attr.span, attr.tokens, item_toks);\n@@ -439,7 +439,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             }\n             _ => {\n                 let msg = &format!(\"macro `{}` may not be used in attributes\", attr.path);\n-                self.cx.span_err(attr.span, &msg);\n+                self.cx.span_err(attr.span, msg);\n                 kind.dummy(attr.span)\n             }\n         }\n@@ -454,7 +454,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n         };\n         let path = &mac.node.path;\n \n-        let ident = ident.unwrap_or(keywords::Invalid.ident());\n+        let ident = ident.unwrap_or_else(|| keywords::Invalid.ident());\n         let marked_tts = noop_fold_tts(mac.node.stream(), &mut Marker(mark));\n         let opt_expanded = match *ext {\n             NormalTT(ref expandfun, exp_span, allow_internal_unstable) => {\n@@ -591,7 +591,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             }\n             _ => {\n                 let msg = &format!(\"macro `{}` may not be used for derive attributes\", attr.path);\n-                self.cx.span_err(span, &msg);\n+                self.cx.span_err(span, msg);\n                 kind.dummy(span)\n             }\n         }\n@@ -749,19 +749,15 @@ impl<'a, 'b> InvocationCollector<'a, 'b> {\n     fn check_attributes(&mut self, attrs: &[ast::Attribute]) {\n         let features = self.cx.ecfg.features.unwrap();\n         for attr in attrs.iter() {\n-            feature_gate::check_attribute(&attr, &self.cx.parse_sess, features);\n+            feature_gate::check_attribute(attr, self.cx.parse_sess, features);\n         }\n     }\n }\n \n pub fn find_attr_invoc(attrs: &mut Vec<ast::Attribute>) -> Option<ast::Attribute> {\n-    for i in 0 .. attrs.len() {\n-        if !attr::is_known(&attrs[i]) && !is_builtin_attr(&attrs[i]) {\n-             return Some(attrs.remove(i));\n-        }\n-    }\n-\n-    None\n+    attrs.iter()\n+         .position(|a| !attr::is_known(a) && !is_builtin_attr(a))\n+         .map(|i| attrs.remove(i))\n }\n \n // These are pretty nasty. Ideally, we would keep the tokens around, linked from\n@@ -923,7 +919,7 @@ impl<'a, 'b> Folder for InvocationCollector<'a, 'b> {\n                 let result = noop_fold_item(item, self);\n                 self.cx.current_expansion.module = orig_module;\n                 self.cx.current_expansion.directory_ownership = orig_directory_ownership;\n-                return result;\n+                result\n             }\n             // Ensure that test functions are accessible from the test harness.\n             ast::ItemKind::Fn(..) if self.cx.ecfg.should_test => {"}, {"sha": "85ae65e6b79ae3c5d8026385784be3bdbda0fdf2", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -23,7 +23,7 @@ use tokenstream::{TokenStream, TokenTree};\n ///\n /// This is registered as a set of expression syntax extension called quote!\n /// that lifts its argument token-tree to an AST representing the\n-/// construction of the same token tree, with token::SubstNt interpreted\n+/// construction of the same token tree, with `token::SubstNt` interpreted\n /// as antiquotes (splices).\n \n pub mod rt {\n@@ -389,7 +389,7 @@ pub fn unflatten(tts: Vec<TokenTree>) -> Vec<TokenTree> {\n                 result = results.pop().unwrap();\n                 result.push(tree);\n             }\n-            tree @ _ => result.push(tree),\n+            tree => result.push(tree),\n         }\n     }\n     result"}, {"sha": "4183583d66ffd1b34a7929b9729817ebab60dfd8", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -150,7 +150,7 @@ pub fn expand_include_str(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenT\n             cx.span_err(sp,\n                         &format!(\"{} wasn't a utf-8 file\",\n                                 file.display()));\n-            return DummyResult::expr(sp);\n+            DummyResult::expr(sp)\n         }\n     }\n }\n@@ -167,7 +167,7 @@ pub fn expand_include_bytes(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::Toke\n         Err(e) => {\n             cx.span_err(sp,\n                         &format!(\"couldn't read {}: {}\", file.display(), e));\n-            return DummyResult::expr(sp);\n+            DummyResult::expr(sp)\n         }\n         Ok(..) => {\n             // Add this input file to the code map to make it available as"}, {"sha": "bf66aa0f00bed42409ffbdc7ffe8cc3341d2a787", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 29, "deletions": 28, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -36,43 +36,47 @@\n //! repetitions indicated by Kleene stars. It only advances or calls out to the\n //! real Rust parser when no `cur_eis` items remain\n //!\n-//! Example: Start parsing `a a a a b` against [\u00b7 a $( a )* a b].\n+//! Example:\n //!\n-//! Remaining input: `a a a a b`\n+//! ```text, ignore\n+//! Start parsing a a a a b against [\u00b7 a $( a )* a b].\n+//!\n+//! Remaining input: a a a a b\n //! next_eis: [\u00b7 a $( a )* a b]\n //!\n-//! - - - Advance over an `a`. - - -\n+//! - - - Advance over an a. - - -\n //!\n-//! Remaining input: `a a a b`\n+//! Remaining input: a a a b\n //! cur: [a \u00b7 $( a )* a b]\n //! Descend/Skip (first item).\n //! next: [a $( \u00b7 a )* a b]  [a $( a )* \u00b7 a b].\n //!\n-//! - - - Advance over an `a`. - - -\n+//! - - - Advance over an a. - - -\n //!\n-//! Remaining input: `a a b`\n+//! Remaining input: a a b\n //! cur: [a $( a \u00b7 )* a b]  next: [a $( a )* a \u00b7 b]\n //! Finish/Repeat (first item)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n-//! - - - Advance over an `a`. - - - (this looks exactly like the last step)\n+//! - - - Advance over an a. - - - (this looks exactly like the last step)\n //!\n-//! Remaining input: `a b`\n+//! Remaining input: a b\n //! cur: [a $( a \u00b7 )* a b]  next: [a $( a )* a \u00b7 b]\n //! Finish/Repeat (first item)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n-//! - - - Advance over an `a`. - - - (this looks exactly like the last step)\n+//! - - - Advance over an a. - - - (this looks exactly like the last step)\n //!\n-//! Remaining input: `b`\n+//! Remaining input: b\n //! cur: [a $( a \u00b7 )* a b]  next: [a $( a )* a \u00b7 b]\n //! Finish/Repeat (first item)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]\n //!\n-//! - - - Advance over a `b`. - - -\n+//! - - - Advance over a b. - - -\n //!\n-//! Remaining input: ``\n+//! Remaining input: ''\n //! eof: [a $( a )* a b \u00b7]\n+//! ```\n \n pub use self::NamedMatch::*;\n pub use self::ParseResult::*;\n@@ -178,20 +182,20 @@ fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n     })\n }\n \n-/// NamedMatch is a pattern-match result for a single token::MATCH_NONTERMINAL:\n+/// `NamedMatch` is a pattern-match result for a single `token::MATCH_NONTERMINAL`:\n /// so it is associated with a single ident in a parse, and all\n-/// `MatchedNonterminal`s in the NamedMatch have the same nonterminal type\n-/// (expr, item, etc). Each leaf in a single NamedMatch corresponds to a\n-/// single token::MATCH_NONTERMINAL in the TokenTree that produced it.\n+/// `MatchedNonterminal`s in the `NamedMatch` have the same nonterminal type\n+/// (expr, item, etc). Each leaf in a single `NamedMatch` corresponds to a\n+/// single `token::MATCH_NONTERMINAL` in the `TokenTree` that produced it.\n ///\n-/// The in-memory structure of a particular NamedMatch represents the match\n+/// The in-memory structure of a particular `NamedMatch` represents the match\n /// that occurred when a particular subset of a matcher was applied to a\n /// particular token tree.\n ///\n-/// The width of each MatchedSeq in the NamedMatch, and the identity of the\n-/// `MatchedNonterminal`s, will depend on the token tree it was applied to:\n-/// each MatchedSeq corresponds to a single TTSeq in the originating\n-/// token tree. The depth of the NamedMatch structure will therefore depend\n+/// The width of each `MatchedSeq` in the `NamedMatch`, and the identity of\n+/// the `MatchedNonterminal`s, will depend on the token tree it was applied\n+/// to: each `MatchedSeq` corresponds to a single `TTSeq` in the originating\n+/// token tree. The depth of the `NamedMatch` structure will therefore depend\n /// only on the nesting depth of `ast::TTSeq`s in the originating\n /// token tree it was derived from.\n \n@@ -335,7 +339,7 @@ fn inner_parse_loop(sess: &ParseSess,\n                 // Check if we need a separator\n                 if idx == len && ei.sep.is_some() {\n                     // We have a separator, and it is the current token.\n-                    if ei.sep.as_ref().map(|ref sep| token_name_eq(&token, sep)).unwrap_or(false) {\n+                    if ei.sep.as_ref().map(|sep| token_name_eq(token, sep)).unwrap_or(false) {\n                         ei.idx += 1;\n                         next_eis.push(ei);\n                     }\n@@ -402,7 +406,7 @@ fn inner_parse_loop(sess: &ParseSess,\n                     cur_eis.push(ei);\n                 }\n                 TokenTree::Token(_, ref t) => {\n-                    if token_name_eq(t, &token) {\n+                    if token_name_eq(t, token) {\n                         ei.idx += 1;\n                         next_eis.push(ei);\n                     }\n@@ -486,11 +490,8 @@ pub fn parse(sess: &ParseSess, tts: TokenStream, ms: &[TokenTree], directory: Op\n }\n \n fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n-    match name {\n-        \"tt\" => {\n-            return token::NtTT(p.parse_token_tree());\n-        }\n-        _ => {}\n+    if name == \"tt\" {\n+        return token::NtTT(p.parse_token_tree());\n     }\n     // check at the beginning and the parser checks after each bump\n     p.process_potential_macro_variable();"}, {"sha": "4a307ab18a593b07e547b534b38fbc09bd8149b8", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 22, "deletions": 24, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -94,7 +94,7 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n                           -> Box<MacResult+'cx> {\n     if cx.trace_macros() {\n         let sp = sp.macro_backtrace().last().map(|trace| trace.call_site).unwrap_or(sp);\n-        let mut values: &mut Vec<String> = cx.expansions.entry(sp).or_insert(vec![]);\n+        let mut values: &mut Vec<String> = cx.expansions.entry(sp).or_insert_with(Vec::new);\n         values.push(format!(\"expands to `{}! {{ {} }}`\", name, arg));\n     }\n \n@@ -206,7 +206,7 @@ pub fn compile(sess: &ParseSess, features: &RefCell<Features>, def: &ast::Item)\n     let mut valid = true;\n \n     // Extract the arguments:\n-    let lhses = match **argument_map.get(&lhs_nm).unwrap() {\n+    let lhses = match *argument_map[&lhs_nm] {\n         MatchedSeq(ref s, _) => {\n             s.iter().map(|m| {\n                 if let MatchedNonterminal(ref nt) = **m {\n@@ -222,7 +222,7 @@ pub fn compile(sess: &ParseSess, features: &RefCell<Features>, def: &ast::Item)\n         _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n     };\n \n-    let rhses = match **argument_map.get(&rhs_nm).unwrap() {\n+    let rhses = match *argument_map[&rhs_nm] {\n         MatchedSeq(ref s, _) => {\n             s.iter().map(|m| {\n                 if let MatchedNonterminal(ref nt) = **m {\n@@ -260,13 +260,12 @@ fn check_lhs_nt_follows(sess: &ParseSess,\n                         lhs: &quoted::TokenTree) -> bool {\n     // lhs is going to be like TokenTree::Delimited(...), where the\n     // entire lhs is those tts. Or, it can be a \"bare sequence\", not wrapped in parens.\n-    match lhs {\n-        &quoted::TokenTree::Delimited(_, ref tts) => check_matcher(sess, features, &tts.tts),\n-        _ => {\n-            let msg = \"invalid macro matcher; matchers must be contained in balanced delimiters\";\n-            sess.span_diagnostic.span_err(lhs.span(), msg);\n-            false\n-        }\n+    if let quoted::TokenTree::Delimited(_, ref tts) = *lhs {\n+        check_matcher(sess, features, &tts.tts)\n+    } else {\n+        let msg = \"invalid macro matcher; matchers must be contained in balanced delimiters\";\n+        sess.span_diagnostic.span_err(lhs.span(), msg);\n+        false\n     }\n     // we don't abort on errors on rejection, the driver will do that for us\n     // after parsing/expansion. we can report every error in every macro this way.\n@@ -283,17 +282,15 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n                 return false;\n             },\n             TokenTree::Sequence(span, ref seq) => {\n-                if seq.separator.is_none() {\n-                    if seq.tts.iter().all(|seq_tt| {\n-                        match *seq_tt {\n-                            TokenTree::Sequence(_, ref sub_seq) =>\n-                                sub_seq.op == quoted::KleeneOp::ZeroOrMore,\n-                            _ => false,\n-                        }\n-                    }) {\n-                        sess.span_diagnostic.span_err(span, \"repetition matches empty token tree\");\n-                        return false;\n+                if seq.separator.is_none() && seq.tts.iter().all(|seq_tt| {\n+                    match *seq_tt {\n+                        TokenTree::Sequence(_, ref sub_seq) =>\n+                            sub_seq.op == quoted::KleeneOp::ZeroOrMore,\n+                        _ => false,\n                     }\n+                }) {\n+                    sess.span_diagnostic.span_err(span, \"repetition matches empty token tree\");\n+                    return false;\n                 }\n                 if !check_lhs_no_empty_seq(sess, &seq.tts) {\n                     return false;\n@@ -407,7 +404,7 @@ impl FirstSets {\n                 }\n             }\n \n-            return first;\n+            first\n         }\n     }\n \n@@ -469,7 +466,7 @@ impl FirstSets {\n         // we only exit the loop if `tts` was empty or if every\n         // element of `tts` matches the empty sequence.\n         assert!(first.maybe_empty);\n-        return first;\n+        first\n     }\n }\n \n@@ -579,7 +576,7 @@ fn check_matcher_core(sess: &ParseSess,\n         let build_suffix_first = || {\n             let mut s = first_sets.first(suffix);\n             if s.maybe_empty { s.add_all(follow); }\n-            return s;\n+            s\n         };\n \n         // (we build `suffix_first` on demand below; you can tell\n@@ -861,6 +858,7 @@ fn quoted_tt_to_string(tt: &quoted::TokenTree) -> String {\n     match *tt {\n         quoted::TokenTree::Token(_, ref tok) => ::print::pprust::token_to_string(tok),\n         quoted::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n-        _ => panic!(\"unexpected quoted::TokenTree::{Sequence or Delimited} in follow set checker\"),\n+        _ => panic!(\"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n+                     in follow set checker\"),\n     }\n }"}, {"sha": "fa65e9501c2bb793aa34c64956aaff717bb4227d", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 15, "deletions": 4, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -96,6 +96,17 @@ impl TokenTree {\n         }\n     }\n \n+    pub fn is_empty(&self) -> bool {\n+        match *self {\n+            TokenTree::Delimited(_, ref delimed) => match delimed.delim {\n+                token::NoDelim => delimed.tts.is_empty(),\n+                _ => false,\n+            },\n+            TokenTree::Sequence(_, ref seq) => seq.tts.is_empty(),\n+            _ => true,\n+        }\n+    }\n+\n     pub fn get_tt(&self, index: usize) -> TokenTree {\n         match (self, index) {\n             (&TokenTree::Delimited(_, ref delimed), _) if delimed.delim == token::NoDelim => {\n@@ -144,9 +155,9 @@ pub fn parse(input: tokenstream::TokenStream, expect_matchers: bool, sess: &Pars\n                             }\n                             _ => end_sp,\n                         },\n-                        tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n+                        tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n                     },\n-                    tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(start_sp),\n+                    tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(start_sp),\n                 };\n                 sess.missing_fragment_specifiers.borrow_mut().insert(span);\n                 result.push(TokenTree::MetaVarDecl(span, ident, keywords::Invalid.ident()));\n@@ -228,10 +239,10 @@ fn parse_sep_and_kleene_op<I>(input: &mut I, span: Span, sess: &ParseSess)\n                     Some(op) => return (Some(tok), op),\n                     None => span,\n                 },\n-                tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n+                tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n             }\n         },\n-        tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n+        tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n     };\n \n     sess.span_diagnostic.span_err(span, \"expected `*` or `+`\");"}, {"sha": "2a435bdea107f2d11d2bf22a0f20005dc0f589aa", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -121,20 +121,20 @@ pub fn transcribe(sp_diag: &Handler,\n                                          &repeats) {\n                     LockstepIterSize::Unconstrained => {\n                         panic!(sp_diag.span_fatal(\n-                            sp.clone(), /* blame macro writer */\n+                            sp, /* blame macro writer */\n                             \"attempted to repeat an expression \\\n                              containing no syntax \\\n                              variables matched as repeating at this depth\"));\n                     }\n                     LockstepIterSize::Contradiction(ref msg) => {\n                         // FIXME #2887 blame macro invoker instead\n-                        panic!(sp_diag.span_fatal(sp.clone(), &msg[..]));\n+                        panic!(sp_diag.span_fatal(sp, &msg[..]));\n                     }\n                     LockstepIterSize::Constraint(len, _) => {\n                         if len == 0 {\n                             if seq.op == quoted::KleeneOp::OneOrMore {\n                                 // FIXME #2887 blame invoker\n-                                panic!(sp_diag.span_fatal(sp.clone(),\n+                                panic!(sp_diag.span_fatal(sp,\n                                                           \"this must repeat at least once\"));\n                             }\n                         } else {"}, {"sha": "09090ab87313087ac393082c21f6f95a0c335a83", "filename": "src/libsyntax/feature_gate.rs", "status": "modified", "additions": 20, "deletions": 28, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Ffeature_gate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Ffeature_gate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -472,7 +472,7 @@ pub enum Stability {\n impl ::std::fmt::Debug for AttributeGate {\n     fn fmt(&self, fmt: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {\n         match *self {\n-            Gated(ref stab, ref name, ref expl, _) =>\n+            Gated(ref stab, name, expl, _) =>\n                 write!(fmt, \"Gated({:?}, {}, {})\", stab, name, expl),\n             Ungated => write!(fmt, \"Ungated\")\n         }\n@@ -816,7 +816,7 @@ pub const BUILTIN_ATTRIBUTES: &'static [(&'static str, AttributeType, AttributeG\n ];\n \n // cfg(...)'s that are feature gated\n-const GATED_CFGS: &'static [(&'static str, &'static str, fn(&Features) -> bool)] = &[\n+const GATED_CFGS: &[(&str, &str, fn(&Features) -> bool)] = &[\n     // (name in cfg, feature, function to check if the feature is enabled)\n     (\"target_feature\", \"cfg_target_feature\", cfg_fn!(cfg_target_feature)),\n     (\"target_vendor\", \"cfg_target_vendor\", cfg_fn!(cfg_target_vendor)),\n@@ -881,7 +881,7 @@ impl<'a> Context<'a> {\n         let name = unwrap_or!(attr.name(), return).as_str();\n         for &(n, ty, ref gateage) in BUILTIN_ATTRIBUTES {\n             if name == n {\n-                if let &Gated(_, ref name, ref desc, ref has_feature) = gateage {\n+                if let Gated(_, name, desc, ref has_feature) = *gateage {\n                     gate_feature_fn!(self, has_feature, attr.span, name, desc);\n                 }\n                 debug!(\"check_attribute: {:?} is builtin, {:?}, {:?}\", attr.path, ty, gateage);\n@@ -1098,7 +1098,7 @@ fn contains_novel_literal(item: &ast::MetaItem) -> bool {\n         NameValue(ref lit) => !lit.node.is_str(),\n         List(ref list) => list.iter().any(|li| {\n             match li.node {\n-                MetaItem(ref mi) => contains_novel_literal(&mi),\n+                MetaItem(ref mi) => contains_novel_literal(mi),\n                 Literal(_) => true,\n             }\n         }),\n@@ -1120,7 +1120,7 @@ impl<'a> Visitor<'a> for PostExpansionVisitor<'a> {\n             return\n         }\n \n-        let meta = panictry!(attr.parse_meta(&self.context.parse_sess));\n+        let meta = panictry!(attr.parse_meta(self.context.parse_sess));\n         if contains_novel_literal(&meta) {\n             gate_feature_post!(&self, attr_literals, attr.span,\n                                \"non-string literals in attributes, or string \\\n@@ -1216,14 +1216,11 @@ impl<'a> Visitor<'a> for PostExpansionVisitor<'a> {\n             }\n \n             ast::ItemKind::Impl(_, polarity, defaultness, _, _, _, _) => {\n-                match polarity {\n-                    ast::ImplPolarity::Negative => {\n-                        gate_feature_post!(&self, optin_builtin_traits,\n-                                           i.span,\n-                                           \"negative trait bounds are not yet fully implemented; \\\n-                                            use marker types for now\");\n-                    },\n-                    _ => {}\n+                if polarity == ast::ImplPolarity::Negative {\n+                    gate_feature_post!(&self, optin_builtin_traits,\n+                                       i.span,\n+                                       \"negative trait bounds are not yet fully implemented; \\\n+                                        use marker types for now\");\n                 }\n \n                 if let ast::Defaultness::Default = defaultness {\n@@ -1272,11 +1269,9 @@ impl<'a> Visitor<'a> for PostExpansionVisitor<'a> {\n \n     fn visit_fn_ret_ty(&mut self, ret_ty: &'a ast::FunctionRetTy) {\n         if let ast::FunctionRetTy::Ty(ref output_ty) = *ret_ty {\n-            match output_ty.node {\n-                ast::TyKind::Never => return,\n-                _ => (),\n-            };\n-            self.visit_ty(output_ty)\n+            if output_ty.node != ast::TyKind::Never {\n+                self.visit_ty(output_ty)\n+            }\n         }\n     }\n \n@@ -1373,17 +1368,14 @@ impl<'a> Visitor<'a> for PostExpansionVisitor<'a> {\n                 span: Span,\n                 _node_id: NodeId) {\n         // check for const fn declarations\n-        match fn_kind {\n-            FnKind::ItemFn(_, _, _, Spanned { node: ast::Constness::Const, .. }, _, _, _) => {\n-                gate_feature_post!(&self, const_fn, span, \"const fn is unstable\");\n-            }\n-            _ => {\n-                // stability of const fn methods are covered in\n-                // visit_trait_item and visit_impl_item below; this is\n-                // because default methods don't pass through this\n-                // point.\n-            }\n+        if let FnKind::ItemFn(_, _, _, Spanned { node: ast::Constness::Const, .. }, _, _, _) =\n+            fn_kind {\n+            gate_feature_post!(&self, const_fn, span, \"const fn is unstable\");\n         }\n+        // stability of const fn methods are covered in\n+        // visit_trait_item and visit_impl_item below; this is\n+        // because default methods don't pass through this\n+        // point.\n \n         match fn_kind {\n             FnKind::ItemFn(_, _, _, _, abi, _, _) |"}, {"sha": "f37dcfdde8985f7594b3381e8e7cf4e57a2a889f", "filename": "src/libsyntax/json.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fjson.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fjson.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fjson.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -337,7 +337,7 @@ impl DiagnosticSpanLine {\n                       })\n                      .collect()\n              })\n-            .unwrap_or(vec![])\n+            .unwrap_or_else(|_| vec![])\n     }\n }\n "}, {"sha": "082930777e598cfe4a9392e1dd7e18106ff648fa", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -62,7 +62,7 @@ impl<'a> Parser<'a> {\n                 _ => break,\n             }\n         }\n-        return Ok(attrs);\n+        Ok(attrs)\n     }\n \n     /// Matches `attribute = # ! [ meta_item ]`\n@@ -182,7 +182,7 @@ impl<'a> Parser<'a> {\n                     }\n \n                     let attr = self.parse_attribute(true)?;\n-                    assert!(attr.style == ast::AttrStyle::Inner);\n+                    assert_eq!(attr.style, ast::AttrStyle::Inner);\n                     attrs.push(attr);\n                 }\n                 token::DocComment(s) => {"}, {"sha": "0c6f09ba7666cb0ed6b5896194c75794f1f2d5d1", "filename": "src/libsyntax/parse/classify.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fclassify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fclassify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fclassify.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -43,14 +43,14 @@ pub fn expr_is_simple_block(e: &ast::Expr) -> bool {\n }\n \n /// this statement requires a semicolon after it.\n-/// note that in one case (stmt_semi), we've already\n+/// note that in one case (`stmt_semi`), we've already\n /// seen the semicolon, and thus don't need another.\n pub fn stmt_ends_with_semi(stmt: &ast::StmtKind) -> bool {\n     match *stmt {\n         ast::StmtKind::Local(_) => true,\n-        ast::StmtKind::Item(_) => false,\n         ast::StmtKind::Expr(ref e) => expr_requires_semi_to_be_stmt(e),\n-        ast::StmtKind::Semi(..) => false,\n+        ast::StmtKind::Item(_) |\n+        ast::StmtKind::Semi(..) |\n         ast::StmtKind::Mac(..) => false,\n     }\n }"}, {"sha": "fe931f7cf6a645f4025baea781dc4e5a89ac2460", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -12,7 +12,7 @@\n \n use parse::token;\n \n-/// SeqSep : a sequence separator (token)\n+/// `SeqSep` : a sequence separator (token)\n /// and whether a trailing separator is allowed.\n pub struct SeqSep {\n     pub sep: Option<token::Token>,"}, {"sha": "8b545d3b909e823c472a1224219a723ce53731cf", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -77,7 +77,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n         while j > i && lines[j - 1].trim().is_empty() {\n             j -= 1;\n         }\n-        lines[i..j].iter().cloned().collect()\n+        lines[i..j].to_vec()\n     }\n \n     /// remove a \"[ \\t]*\\*\" block from each line, if possible"}, {"sha": "0bcd457851890c6db66ecbae0d988c990cbf3865", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 61, "deletions": 61, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -144,7 +144,7 @@ impl<'a> StringReader<'a> {\n \n impl<'a> StringReader<'a> {\n     /// For comments.rs, which hackily pokes into next_pos and ch\n-    pub fn new_raw<'b>(sess: &'a ParseSess, filemap: Rc<syntax_pos::FileMap>) -> Self {\n+    pub fn new_raw(sess: &'a ParseSess, filemap: Rc<syntax_pos::FileMap>) -> Self {\n         let mut sr = StringReader::new_raw_internal(sess, filemap);\n         sr.bump();\n         sr\n@@ -180,7 +180,7 @@ impl<'a> StringReader<'a> {\n \n     pub fn new(sess: &'a ParseSess, filemap: Rc<syntax_pos::FileMap>) -> Self {\n         let mut sr = StringReader::new_raw(sess, filemap);\n-        if let Err(_) = sr.advance_token() {\n+        if sr.advance_token().is_err() {\n             sr.emit_fatal_errors();\n             panic!(FatalError);\n         }\n@@ -205,7 +205,7 @@ impl<'a> StringReader<'a> {\n \n         sr.bump();\n \n-        if let Err(_) = sr.advance_token() {\n+        if sr.advance_token().is_err() {\n             sr.emit_fatal_errors();\n             panic!(FatalError);\n         }\n@@ -525,7 +525,7 @@ impl<'a> StringReader<'a> {\n                         self.bump();\n                     }\n \n-                    return if doc_comment {\n+                    if doc_comment {\n                         self.with_str_from(start_bpos, |string| {\n                             // comments with only more \"/\"s are not doc comments\n                             let tok = if is_doc_comment(string) {\n@@ -544,7 +544,7 @@ impl<'a> StringReader<'a> {\n                             tok: token::Comment,\n                             sp: mk_sp(start_bpos, self.pos),\n                         })\n-                    };\n+                    }\n                 }\n                 Some('*') => {\n                     self.bump();\n@@ -764,7 +764,7 @@ impl<'a> StringReader<'a> {\n             }\n             let pos = self.pos;\n             self.check_float_base(start_bpos, pos, base);\n-            return token::Float(self.name_from(start_bpos));\n+            token::Float(self.name_from(start_bpos))\n         } else {\n             // it might be a float if it has an exponent\n             if self.ch_is('e') || self.ch_is('E') {\n@@ -774,7 +774,7 @@ impl<'a> StringReader<'a> {\n                 return token::Float(self.name_from(start_bpos));\n             }\n             // but we certainly have an integer!\n-            return token::Integer(self.name_from(start_bpos));\n+            token::Integer(self.name_from(start_bpos))\n         }\n     }\n \n@@ -1051,9 +1051,9 @@ impl<'a> StringReader<'a> {\n         self.bump();\n         if self.ch_is('=') {\n             self.bump();\n-            return token::BinOpEq(op);\n+            token::BinOpEq(op)\n         } else {\n-            return token::BinOp(op);\n+            token::BinOp(op)\n         }\n     }\n \n@@ -1100,15 +1100,15 @@ impl<'a> StringReader<'a> {\n             // One-byte tokens.\n             ';' => {\n                 self.bump();\n-                return Ok(token::Semi);\n+                Ok(token::Semi)\n             }\n             ',' => {\n                 self.bump();\n-                return Ok(token::Comma);\n+                Ok(token::Comma)\n             }\n             '.' => {\n                 self.bump();\n-                return if self.ch_is('.') {\n+                if self.ch_is('.') {\n                     self.bump();\n                     if self.ch_is('.') {\n                         self.bump();\n@@ -1118,105 +1118,105 @@ impl<'a> StringReader<'a> {\n                     }\n                 } else {\n                     Ok(token::Dot)\n-                };\n+                }\n             }\n             '(' => {\n                 self.bump();\n-                return Ok(token::OpenDelim(token::Paren));\n+                Ok(token::OpenDelim(token::Paren))\n             }\n             ')' => {\n                 self.bump();\n-                return Ok(token::CloseDelim(token::Paren));\n+                Ok(token::CloseDelim(token::Paren))\n             }\n             '{' => {\n                 self.bump();\n-                return Ok(token::OpenDelim(token::Brace));\n+                Ok(token::OpenDelim(token::Brace))\n             }\n             '}' => {\n                 self.bump();\n-                return Ok(token::CloseDelim(token::Brace));\n+                Ok(token::CloseDelim(token::Brace))\n             }\n             '[' => {\n                 self.bump();\n-                return Ok(token::OpenDelim(token::Bracket));\n+                Ok(token::OpenDelim(token::Bracket))\n             }\n             ']' => {\n                 self.bump();\n-                return Ok(token::CloseDelim(token::Bracket));\n+                Ok(token::CloseDelim(token::Bracket))\n             }\n             '@' => {\n                 self.bump();\n-                return Ok(token::At);\n+                Ok(token::At)\n             }\n             '#' => {\n                 self.bump();\n-                return Ok(token::Pound);\n+                Ok(token::Pound)\n             }\n             '~' => {\n                 self.bump();\n-                return Ok(token::Tilde);\n+                Ok(token::Tilde)\n             }\n             '?' => {\n                 self.bump();\n-                return Ok(token::Question);\n+                Ok(token::Question)\n             }\n             ':' => {\n                 self.bump();\n                 if self.ch_is(':') {\n                     self.bump();\n-                    return Ok(token::ModSep);\n+                    Ok(token::ModSep)\n                 } else {\n-                    return Ok(token::Colon);\n+                    Ok(token::Colon)\n                 }\n             }\n \n             '$' => {\n                 self.bump();\n-                return Ok(token::Dollar);\n+                Ok(token::Dollar)\n             }\n \n             // Multi-byte tokens.\n             '=' => {\n                 self.bump();\n                 if self.ch_is('=') {\n                     self.bump();\n-                    return Ok(token::EqEq);\n+                    Ok(token::EqEq)\n                 } else if self.ch_is('>') {\n                     self.bump();\n-                    return Ok(token::FatArrow);\n+                    Ok(token::FatArrow)\n                 } else {\n-                    return Ok(token::Eq);\n+                    Ok(token::Eq)\n                 }\n             }\n             '!' => {\n                 self.bump();\n                 if self.ch_is('=') {\n                     self.bump();\n-                    return Ok(token::Ne);\n+                    Ok(token::Ne)\n                 } else {\n-                    return Ok(token::Not);\n+                    Ok(token::Not)\n                 }\n             }\n             '<' => {\n                 self.bump();\n                 match self.ch.unwrap_or('\\x00') {\n                     '=' => {\n                         self.bump();\n-                        return Ok(token::Le);\n+                        Ok(token::Le)\n                     }\n                     '<' => {\n-                        return Ok(self.binop(token::Shl));\n+                        Ok(self.binop(token::Shl))\n                     }\n                     '-' => {\n                         self.bump();\n                         match self.ch.unwrap_or('\\x00') {\n                             _ => {\n-                                return Ok(token::LArrow);\n+                                Ok(token::LArrow)\n                             }\n                         }\n                     }\n                     _ => {\n-                        return Ok(token::Lt);\n+                        Ok(token::Lt)\n                     }\n                 }\n             }\n@@ -1225,13 +1225,13 @@ impl<'a> StringReader<'a> {\n                 match self.ch.unwrap_or('\\x00') {\n                     '=' => {\n                         self.bump();\n-                        return Ok(token::Ge);\n+                        Ok(token::Ge)\n                     }\n                     '>' => {\n-                        return Ok(self.binop(token::Shr));\n+                        Ok(self.binop(token::Shr))\n                     }\n                     _ => {\n-                        return Ok(token::Gt);\n+                        Ok(token::Gt)\n                     }\n                 }\n             }\n@@ -1301,7 +1301,7 @@ impl<'a> StringReader<'a> {\n                 };\n                 self.bump(); // advance ch past token\n                 let suffix = self.scan_optional_raw_name();\n-                return Ok(token::Literal(token::Char(id), suffix));\n+                Ok(token::Literal(token::Char(id), suffix))\n             }\n             'b' => {\n                 self.bump();\n@@ -1312,7 +1312,7 @@ impl<'a> StringReader<'a> {\n                     _ => unreachable!(),  // Should have been a token::Ident above.\n                 };\n                 let suffix = self.scan_optional_raw_name();\n-                return Ok(token::Literal(lit, suffix));\n+                Ok(token::Literal(lit, suffix))\n             }\n             '\"' => {\n                 let start_bpos = self.pos;\n@@ -1343,7 +1343,7 @@ impl<'a> StringReader<'a> {\n                 };\n                 self.bump();\n                 let suffix = self.scan_optional_raw_name();\n-                return Ok(token::Literal(token::Str_(id), suffix));\n+                Ok(token::Literal(token::Str_(id), suffix))\n             }\n             'r' => {\n                 let start_bpos = self.pos;\n@@ -1414,52 +1414,52 @@ impl<'a> StringReader<'a> {\n                     Symbol::intern(\"??\")\n                 };\n                 let suffix = self.scan_optional_raw_name();\n-                return Ok(token::Literal(token::StrRaw(id, hash_count), suffix));\n+                Ok(token::Literal(token::StrRaw(id, hash_count), suffix))\n             }\n             '-' => {\n                 if self.nextch_is('>') {\n                     self.bump();\n                     self.bump();\n-                    return Ok(token::RArrow);\n+                    Ok(token::RArrow)\n                 } else {\n-                    return Ok(self.binop(token::Minus));\n+                    Ok(self.binop(token::Minus))\n                 }\n             }\n             '&' => {\n                 if self.nextch_is('&') {\n                     self.bump();\n                     self.bump();\n-                    return Ok(token::AndAnd);\n+                    Ok(token::AndAnd)\n                 } else {\n-                    return Ok(self.binop(token::And));\n+                    Ok(self.binop(token::And))\n                 }\n             }\n             '|' => {\n                 match self.nextch() {\n                     Some('|') => {\n                         self.bump();\n                         self.bump();\n-                        return Ok(token::OrOr);\n+                        Ok(token::OrOr)\n                     }\n                     _ => {\n-                        return Ok(self.binop(token::Or));\n+                        Ok(self.binop(token::Or))\n                     }\n                 }\n             }\n             '+' => {\n-                return Ok(self.binop(token::Plus));\n+                Ok(self.binop(token::Plus))\n             }\n             '*' => {\n-                return Ok(self.binop(token::Star));\n+                Ok(self.binop(token::Star))\n             }\n             '/' => {\n-                return Ok(self.binop(token::Slash));\n+                Ok(self.binop(token::Slash))\n             }\n             '^' => {\n-                return Ok(self.binop(token::Caret));\n+                Ok(self.binop(token::Caret))\n             }\n             '%' => {\n-                return Ok(self.binop(token::Percent));\n+                Ok(self.binop(token::Percent))\n             }\n             c => {\n                 let last_bpos = self.pos;\n@@ -1468,7 +1468,7 @@ impl<'a> StringReader<'a> {\n                                                           bpos,\n                                                           \"unknown start of token\",\n                                                           c);\n-                unicode_chars::check_for_substitution(&self, c, &mut err);\n+                unicode_chars::check_for_substitution(self, c, &mut err);\n                 self.fatal_errs.push(err);\n                 Err(())\n             }\n@@ -1490,14 +1490,14 @@ impl<'a> StringReader<'a> {\n         if self.ch_is('\\n') {\n             self.bump();\n         }\n-        return val;\n+        val\n     }\n \n     fn read_one_line_comment(&mut self) -> String {\n         let val = self.read_to_eol();\n         assert!((val.as_bytes()[0] == b'/' && val.as_bytes()[1] == b'/') ||\n                 (val.as_bytes()[0] == b'#' && val.as_bytes()[1] == b'!'));\n-        return val;\n+        val\n     }\n \n     fn consume_non_eol_whitespace(&mut self) {\n@@ -1541,7 +1541,7 @@ impl<'a> StringReader<'a> {\n             Symbol::intern(\"?\")\n         };\n         self.bump(); // advance ch past token\n-        return token::Byte(id);\n+        token::Byte(id)\n     }\n \n     fn scan_byte_escape(&mut self, delim: char, below_0x7f_only: bool) -> bool {\n@@ -1574,7 +1574,7 @@ impl<'a> StringReader<'a> {\n             Symbol::intern(\"??\")\n         };\n         self.bump();\n-        return token::ByteStr(id);\n+        token::ByteStr(id)\n     }\n \n     fn scan_raw_byte_string(&mut self) -> token::Lit {\n@@ -1627,8 +1627,8 @@ impl<'a> StringReader<'a> {\n             self.bump();\n         }\n         self.bump();\n-        return token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos),\n-                                 hash_count);\n+        token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos),\n+                                 hash_count)\n     }\n }\n \n@@ -1646,7 +1646,7 @@ fn in_range(c: Option<char>, lo: char, hi: char) -> bool {\n }\n \n fn is_dec_digit(c: Option<char>) -> bool {\n-    return in_range(c, '0', '9');\n+    in_range(c, '0', '9')\n }\n \n pub fn is_doc_comment(s: &str) -> bool {"}, {"sha": "1eff819d755493f33f713b6281100591bab78413", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 68, "deletions": 79, "changes": 147, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -107,48 +107,48 @@ pub fn parse_crate_attrs_from_file<'a>(input: &Path, sess: &'a ParseSess)\n     parser.parse_inner_attributes()\n }\n \n-pub fn parse_crate_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n-                                       -> PResult<'a, ast::Crate> {\n+pub fn parse_crate_from_source_str(name: String, source: String, sess: &ParseSess)\n+                                       -> PResult<ast::Crate> {\n     new_parser_from_source_str(sess, name, source).parse_crate_mod()\n }\n \n-pub fn parse_crate_attrs_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n-                                             -> PResult<'a, Vec<ast::Attribute>> {\n+pub fn parse_crate_attrs_from_source_str(name: String, source: String, sess: &ParseSess)\n+                                             -> PResult<Vec<ast::Attribute>> {\n     new_parser_from_source_str(sess, name, source).parse_inner_attributes()\n }\n \n-pub fn parse_expr_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n-                                      -> PResult<'a, P<ast::Expr>> {\n+pub fn parse_expr_from_source_str(name: String, source: String, sess: &ParseSess)\n+                                      -> PResult<P<ast::Expr>> {\n     new_parser_from_source_str(sess, name, source).parse_expr()\n }\n \n /// Parses an item.\n ///\n /// Returns `Ok(Some(item))` when successful, `Ok(None)` when no item was found, and`Err`\n /// when a syntax error occurred.\n-pub fn parse_item_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n-                                      -> PResult<'a, Option<P<ast::Item>>> {\n+pub fn parse_item_from_source_str(name: String, source: String, sess: &ParseSess)\n+                                      -> PResult<Option<P<ast::Item>>> {\n     new_parser_from_source_str(sess, name, source).parse_item()\n }\n \n-pub fn parse_meta_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n-                                      -> PResult<'a, ast::MetaItem> {\n+pub fn parse_meta_from_source_str(name: String, source: String, sess: &ParseSess)\n+                                      -> PResult<ast::MetaItem> {\n     new_parser_from_source_str(sess, name, source).parse_meta_item()\n }\n \n-pub fn parse_stmt_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n-                                      -> PResult<'a, Option<ast::Stmt>> {\n+pub fn parse_stmt_from_source_str(name: String, source: String, sess: &ParseSess)\n+                                      -> PResult<Option<ast::Stmt>> {\n     new_parser_from_source_str(sess, name, source).parse_stmt()\n }\n \n-pub fn parse_stream_from_source_str<'a>(name: String, source: String, sess: &'a ParseSess)\n+pub fn parse_stream_from_source_str(name: String, source: String, sess: &ParseSess)\n                                         -> TokenStream {\n     filemap_to_stream(sess, sess.codemap().new_filemap(name, source))\n }\n \n // Create a new parser from a source string\n-pub fn new_parser_from_source_str<'a>(sess: &'a ParseSess, name: String, source: String)\n-                                      -> Parser<'a> {\n+pub fn new_parser_from_source_str(sess: &ParseSess, name: String, source: String)\n+                                      -> Parser {\n     filemap_to_parser(sess, sess.codemap().new_filemap(name, source))\n }\n \n@@ -173,7 +173,7 @@ pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n }\n \n /// Given a filemap and config, return a parser\n-pub fn filemap_to_parser<'a>(sess: &'a ParseSess, filemap: Rc<FileMap>, ) -> Parser<'a> {\n+pub fn filemap_to_parser(sess: & ParseSess, filemap: Rc<FileMap>, ) -> Parser {\n     let end_pos = filemap.end_pos;\n     let mut parser = stream_to_parser(sess, filemap_to_stream(sess, filemap));\n \n@@ -186,7 +186,7 @@ pub fn filemap_to_parser<'a>(sess: &'a ParseSess, filemap: Rc<FileMap>, ) -> Par\n \n // must preserve old name for now, because quote! from the *existing*\n // compiler expands into it\n-pub fn new_parser_from_tts<'a>(sess: &'a ParseSess, tts: Vec<TokenTree>) -> Parser<'a> {\n+pub fn new_parser_from_tts(sess: &ParseSess, tts: Vec<TokenTree>) -> Parser {\n     stream_to_parser(sess, tts.into_iter().collect())\n }\n \n@@ -216,8 +216,8 @@ pub fn filemap_to_stream(sess: &ParseSess, filemap: Rc<FileMap>) -> TokenStream\n     panictry!(srdr.parse_all_token_trees())\n }\n \n-/// Given stream and the ParseSess, produce a parser\n-pub fn stream_to_parser<'a>(sess: &'a ParseSess, stream: TokenStream) -> Parser<'a> {\n+/// Given stream and the `ParseSess`, produce a parser\n+pub fn stream_to_parser(sess: &ParseSess, stream: TokenStream) -> Parser {\n     Parser::new(sess, stream, None, false)\n }\n \n@@ -251,7 +251,7 @@ pub fn char_lit(lit: &str) -> (char, isize) {\n             (c, 4)\n         }\n         'u' => {\n-            assert!(lit.as_bytes()[2] == b'{');\n+            assert_eq!(lit.as_bytes()[2], b'{');\n             let idx = lit.find('}').unwrap();\n             let v = u32::from_str_radix(&lit[3..idx], 16).unwrap();\n             let c = char::from_u32(v).unwrap();\n@@ -287,51 +287,46 @@ pub fn str_lit(lit: &str) -> String {\n     }\n \n     let mut chars = lit.char_indices().peekable();\n-    loop {\n-        match chars.next() {\n-            Some((i, c)) => {\n-                match c {\n-                    '\\\\' => {\n-                        let ch = chars.peek().unwrap_or_else(|| {\n-                            panic!(\"{}\", error(i))\n-                        }).1;\n-\n-                        if ch == '\\n' {\n-                            eat(&mut chars);\n-                        } else if ch == '\\r' {\n-                            chars.next();\n-                            let ch = chars.peek().unwrap_or_else(|| {\n-                                panic!(\"{}\", error(i))\n-                            }).1;\n-\n-                            if ch != '\\n' {\n-                                panic!(\"lexer accepted bare CR\");\n-                            }\n-                            eat(&mut chars);\n-                        } else {\n-                            // otherwise, a normal escape\n-                            let (c, n) = char_lit(&lit[i..]);\n-                            for _ in 0..n - 1 { // we don't need to move past the first \\\n-                                chars.next();\n-                            }\n-                            res.push(c);\n-                        }\n-                    },\n-                    '\\r' => {\n-                        let ch = chars.peek().unwrap_or_else(|| {\n-                            panic!(\"{}\", error(i))\n-                        }).1;\n+    while let Some((i, c)) = chars.next() {\n+        match c {\n+            '\\\\' => {\n+                let ch = chars.peek().unwrap_or_else(|| {\n+                    panic!(\"{}\", error(i))\n+                }).1;\n+\n+                if ch == '\\n' {\n+                    eat(&mut chars);\n+                } else if ch == '\\r' {\n+                    chars.next();\n+                    let ch = chars.peek().unwrap_or_else(|| {\n+                        panic!(\"{}\", error(i))\n+                    }).1;\n \n-                        if ch != '\\n' {\n-                            panic!(\"lexer accepted bare CR\");\n-                        }\n+                    if ch != '\\n' {\n+                        panic!(\"lexer accepted bare CR\");\n+                    }\n+                    eat(&mut chars);\n+                } else {\n+                    // otherwise, a normal escape\n+                    let (c, n) = char_lit(&lit[i..]);\n+                    for _ in 0..n - 1 { // we don't need to move past the first \\\n                         chars.next();\n-                        res.push('\\n');\n                     }\n-                    c => res.push(c),\n+                    res.push(c);\n                 }\n             },\n-            None => break\n+            '\\r' => {\n+                let ch = chars.peek().unwrap_or_else(|| {\n+                    panic!(\"{}\", error(i))\n+                }).1;\n+\n+                if ch != '\\n' {\n+                    panic!(\"lexer accepted bare CR\");\n+                }\n+                chars.next();\n+                res.push('\\n');\n+            }\n+            c => res.push(c),\n         }\n     }\n \n@@ -346,22 +341,16 @@ pub fn raw_str_lit(lit: &str) -> String {\n     debug!(\"raw_str_lit: given {}\", escape_default(lit));\n     let mut res = String::with_capacity(lit.len());\n \n-    // FIXME #8372: This could be a for-loop if it didn't borrow the iterator\n     let mut chars = lit.chars().peekable();\n-    loop {\n-        match chars.next() {\n-            Some(c) => {\n-                if c == '\\r' {\n-                    if *chars.peek().unwrap() != '\\n' {\n-                        panic!(\"lexer accepted bare CR\");\n-                    }\n-                    chars.next();\n-                    res.push('\\n');\n-                } else {\n-                    res.push(c);\n-                }\n-            },\n-            None => break\n+    while let Some(c) = chars.next() {\n+        if c == '\\r' {\n+            if *chars.peek().unwrap() != '\\n' {\n+                panic!(\"lexer accepted bare CR\");\n+            }\n+            chars.next();\n+            res.push('\\n');\n+        } else {\n+            res.push(c);\n         }\n     }\n \n@@ -459,7 +448,7 @@ pub fn byte_lit(lit: &str) -> (u8, usize) {\n     if lit.len() == 1 {\n         (lit.as_bytes()[0], 1)\n     } else {\n-        assert!(lit.as_bytes()[0] == b'\\\\', err(0));\n+        assert_eq!(lit.as_bytes()[0], b'\\\\', \"{}\", err(0));\n         let b = match lit.as_bytes()[1] {\n             b'\"' => b'\"',\n             b'n' => b'\\n',\n@@ -480,7 +469,7 @@ pub fn byte_lit(lit: &str) -> (u8, usize) {\n                 }\n             }\n         };\n-        return (b, 2);\n+        (b, 2)\n     }\n }\n \n@@ -491,7 +480,7 @@ pub fn byte_str_lit(lit: &str) -> Rc<Vec<u8>> {\n     let error = |i| format!(\"lexer should have rejected {} at {}\", lit, i);\n \n     /// Eat everything up to a non-whitespace\n-    fn eat<'a, I: Iterator<Item=(usize, u8)>>(it: &mut iter::Peekable<I>) {\n+    fn eat<I: Iterator<Item=(usize, u8)>>(it: &mut iter::Peekable<I>) {\n         loop {\n             match it.peek().map(|x| x.1) {\n                 Some(b' ') | Some(b'\\n') | Some(b'\\r') | Some(b'\\t') => {\n@@ -578,7 +567,7 @@ pub fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler\n             if let Some(err) = err {\n                 err!(diag, |span, diag| diag.span_err(span, err));\n             }\n-            return filtered_float_lit(Symbol::intern(&s), Some(suf), diag)\n+            return filtered_float_lit(Symbol::intern(s), Some(suf), diag)\n         }\n     }\n "}, {"sha": "078e86aa2941f36a8c28332986dcf3772177c15a", "filename": "src/libsyntax/parse/obsolete.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fobsolete.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -59,7 +59,7 @@ impl<'a> ParserObsoleteMethods for parser::Parser<'a> {\n \n         if !self.obsolete_set.contains(&kind) &&\n             (error || self.sess.span_diagnostic.can_emit_warnings) {\n-            err.note(&format!(\"{}\", desc));\n+            err.note(desc);\n             self.obsolete_set.insert(kind);\n         }\n         err.emit();"}, {"sha": "4741f896d3cc0c8c6ce38501dd2e1cb1a7dcfe0e", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 33, "deletions": 36, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -248,7 +248,7 @@ impl TokenCursor {\n     fn next_desugared(&mut self) -> TokenAndSpan {\n         let (sp, name) = match self.next() {\n             TokenAndSpan { sp, tok: token::DocComment(name) } => (sp, name),\n-            tok @ _ => return tok,\n+            tok => return tok,\n         };\n \n         let stripped = strip_doc_comment_decoration(&name.as_str());\n@@ -354,7 +354,7 @@ pub enum Error {\n }\n \n impl Error {\n-    pub fn span_err<'a>(self, sp: Span, handler: &'a errors::Handler) -> DiagnosticBuilder<'a> {\n+    pub fn span_err(self, sp: Span, handler: &errors::Handler) -> DiagnosticBuilder {\n         match self {\n             Error::FileNotFoundForModule { ref mod_name,\n                                            ref default_path,\n@@ -478,9 +478,10 @@ impl<'a> Parser<'a> {\n     }\n \n     fn next_tok(&mut self) -> TokenAndSpan {\n-        let mut next = match self.desugar_doc_comments {\n-            true => self.token_cursor.next_desugared(),\n-            false => self.token_cursor.next(),\n+        let mut next = if self.desugar_doc_comments {\n+            self.token_cursor.next_desugared()\n+        } else {\n+            self.token_cursor.next()\n         };\n         if next.sp == syntax_pos::DUMMY_SP {\n             next.sp = self.prev_span;\n@@ -551,7 +552,7 @@ impl<'a> Parser<'a> {\n             // This might be a sign we need a connect method on Iterator.\n             let b = i.next()\n                      .map_or(\"\".to_string(), |t| t.to_string());\n-            i.enumerate().fold(b, |mut b, (i, ref a)| {\n+            i.enumerate().fold(b, |mut b, (i, a)| {\n                 if tokens.len() > 2 && i == tokens.len() - 2 {\n                     b.push_str(\", or \");\n                 } else if tokens.len() == 2 && i == tokens.len() - 2 {\n@@ -985,18 +986,15 @@ impl<'a> Parser<'a> {\n                 token::CloseDelim(..) | token::Eof => break,\n                 _ => {}\n             };\n-            match sep.sep {\n-                Some(ref t) => {\n-                    if first {\n-                        first = false;\n-                    } else {\n-                        if let Err(e) = self.expect(t) {\n-                            fe(e);\n-                            break;\n-                        }\n+            if let Some(ref t) = sep.sep {\n+                if first {\n+                    first = false;\n+                } else {\n+                    if let Err(e) = self.expect(t) {\n+                        fe(e);\n+                        break;\n                     }\n                 }\n-                _ => ()\n             }\n             if sep.trailing_sep_allowed && kets.iter().any(|k| self.check(k)) {\n                 break;\n@@ -1493,7 +1491,7 @@ impl<'a> Parser<'a> {\n         let sum_span = ty.span.to(self.prev_span);\n \n         let mut err = struct_span_err!(self.sess.span_diagnostic, sum_span, E0178,\n-            \"expected a path on the left-hand side of `+`, not `{}`\", pprust::ty_to_string(&ty));\n+            \"expected a path on the left-hand side of `+`, not `{}`\", pprust::ty_to_string(ty));\n \n         match ty.node {\n             TyKind::Rptr(ref lifetime, ref mut_ty) => {\n@@ -1547,7 +1545,7 @@ impl<'a> Parser<'a> {\n \n     pub fn is_named_argument(&mut self) -> bool {\n         let offset = match self.token {\n-            token::BinOp(token::And) => 1,\n+            token::BinOp(token::And) |\n             token::AndAnd => 1,\n             _ if self.token.is_keyword(keywords::Mut) => 1,\n             _ => 0\n@@ -3154,10 +3152,11 @@ impl<'a> Parser<'a> {\n \n         let attrs = self.parse_outer_attributes()?;\n         let pats = self.parse_pats()?;\n-        let mut guard = None;\n-        if self.eat_keyword(keywords::If) {\n-            guard = Some(self.parse_expr()?);\n-        }\n+        let guard = if self.eat_keyword(keywords::If) {\n+            Some(self.parse_expr()?)\n+        } else {\n+            None\n+        };\n         self.expect(&token::FatArrow)?;\n         let expr = self.parse_expr_res(RESTRICTION_STMT_EXPR, None)?;\n \n@@ -3600,10 +3599,11 @@ impl<'a> Parser<'a> {\n         let lo = self.span;\n         let pat = self.parse_pat()?;\n \n-        let mut ty = None;\n-        if self.eat(&token::Colon) {\n-            ty = Some(self.parse_ty()?);\n-        }\n+        let ty = if self.eat(&token::Colon) {\n+            Some(self.parse_ty()?)\n+        } else {\n+            None\n+        };\n         let init = self.parse_initializer()?;\n         Ok(P(ast::Local {\n             ty: ty,\n@@ -3929,7 +3929,7 @@ impl<'a> Parser<'a> {\n                 },\n                 None => {\n                     let unused_attrs = |attrs: &[_], s: &mut Self| {\n-                        if attrs.len() > 0 {\n+                        if !attrs.is_empty() {\n                             if s.prev_token_kind == PrevTokenKind::DocComment {\n                                 s.span_fatal_err(s.prev_span, Error::UselessDocComment).emit();\n                             } else {\n@@ -4815,7 +4815,7 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Not)?;\n             }\n \n-            self.complain_if_pub_macro(&vis, prev_span);\n+            self.complain_if_pub_macro(vis, prev_span);\n \n             // eat a matched-delimiter token tree:\n             *at_end = true;\n@@ -4917,13 +4917,10 @@ impl<'a> Parser<'a> {\n                 }\n             }\n         } else {\n-            match polarity {\n-                ast::ImplPolarity::Negative => {\n-                    // This is a negated type implementation\n-                    // `impl !MyType {}`, which is not allowed.\n-                    self.span_err(neg_span, \"inherent implementation can't be negated\");\n-                },\n-                _ => {}\n+            if polarity == ast::ImplPolarity::Negative {\n+                // This is a negated type implementation\n+                // `impl !MyType {}`, which is not allowed.\n+                self.span_err(neg_span, \"inherent implementation can't be negated\");\n             }\n             None\n         };\n@@ -5185,7 +5182,7 @@ impl<'a> Parser<'a> {\n                 let path_span = self.prev_span;\n                 let help_msg = format!(\"make this visible only to module `{}` with `in`:\", path);\n                 self.expect(&token::CloseDelim(token::Paren))?;  // `)`\n-                let mut err = self.span_fatal_help(path_span, &msg, &suggestion);\n+                let mut err = self.span_fatal_help(path_span, msg, suggestion);\n                 err.span_suggestion(path_span, &help_msg, format!(\"in {}\", path));\n                 err.emit();  // emit diagnostic, but continue with public visibility\n             }"}, {"sha": "77db604c56e118c0596364536b3b1ed3674a2f24", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 25, "deletions": 21, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -53,6 +53,10 @@ impl DelimToken {\n     pub fn len(self) -> usize {\n         if self == NoDelim { 0 } else { 1 }\n     }\n+\n+    pub fn is_empty(self) -> bool {\n+        self == NoDelim\n+    }\n }\n \n #[derive(Clone, RustcEncodable, RustcDecodable, PartialEq, Eq, Hash, Debug, Copy)]\n@@ -198,17 +202,17 @@ impl Token {\n     pub fn can_begin_expr(&self) -> bool {\n         match *self {\n             Ident(ident)                => ident_can_begin_expr(ident), // value name or keyword\n-            OpenDelim(..)               => true, // tuple, array or block\n-            Literal(..)                 => true, // literal\n-            Not                         => true, // operator not\n-            BinOp(Minus)                => true, // unary minus\n-            BinOp(Star)                 => true, // dereference\n-            BinOp(Or) | OrOr            => true, // closure\n-            BinOp(And)                  => true, // reference\n-            AndAnd                      => true, // double reference\n-            DotDot | DotDotDot          => true, // range notation\n-            Lt | BinOp(Shl)             => true, // associated path\n-            ModSep                      => true, // global path\n+            OpenDelim(..)               | // tuple, array or block\n+            Literal(..)                 | // literal\n+            Not                         | // operator not\n+            BinOp(Minus)                | // unary minus\n+            BinOp(Star)                 | // dereference\n+            BinOp(Or) | OrOr            | // closure\n+            BinOp(And)                  | // reference\n+            AndAnd                      | // double reference\n+            DotDot | DotDotDot          | // range notation\n+            Lt | BinOp(Shl)             | // associated path\n+            ModSep                      | // global path\n             Pound                       => true, // expression attributes\n             Interpolated(ref nt) => match **nt {\n                 NtIdent(..) | NtExpr(..) | NtBlock(..) | NtPath(..) => true,\n@@ -222,16 +226,16 @@ impl Token {\n     pub fn can_begin_type(&self) -> bool {\n         match *self {\n             Ident(ident)                => ident_can_begin_type(ident), // type name or keyword\n-            OpenDelim(Paren)            => true, // tuple\n-            OpenDelim(Bracket)          => true, // array\n-            Underscore                  => true, // placeholder\n-            Not                         => true, // never\n-            BinOp(Star)                 => true, // raw pointer\n-            BinOp(And)                  => true, // reference\n-            AndAnd                      => true, // double reference\n-            Question                    => true, // maybe bound in trait object\n-            Lifetime(..)                => true, // lifetime bound in trait object\n-            Lt | BinOp(Shl)             => true, // associated path\n+            OpenDelim(Paren)            | // tuple\n+            OpenDelim(Bracket)          | // array\n+            Underscore                  | // placeholder\n+            Not                         | // never\n+            BinOp(Star)                 | // raw pointer\n+            BinOp(And)                  | // reference\n+            AndAnd                      | // double reference\n+            Question                    | // maybe bound in trait object\n+            Lifetime(..)                | // lifetime bound in trait object\n+            Lt | BinOp(Shl)             | // associated path\n             ModSep                      => true, // global path\n             Interpolated(ref nt) => match **nt {\n                 NtIdent(..) | NtTy(..) | NtPath(..) => true,"}, {"sha": "e893c859247c6110790921f528c04c99f9403fae", "filename": "src/libsyntax/print/pp.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fprint%2Fpp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fprint%2Fpp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpp.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -113,22 +113,22 @@\n //! between using 'left' and 'right' terms to denote the wrapped-to-ring-buffer\n //! and point-in-infinite-stream senses freely.\n //!\n-//! There is a parallel ring buffer, 'size', that holds the calculated size of\n+//! There is a parallel ring buffer, `size`, that holds the calculated size of\n //! each token. Why calculated? Because for Begin/End pairs, the \"size\"\n //! includes everything between the pair. That is, the \"size\" of Begin is\n //! actually the sum of the sizes of everything between Begin and the paired\n-//! End that follows. Since that is arbitrarily far in the future, 'size' is\n+//! End that follows. Since that is arbitrarily far in the future, `size` is\n //! being rewritten regularly while the printer runs; in fact most of the\n-//! machinery is here to work out 'size' entries on the fly (and give up when\n+//! machinery is here to work out `size` entries on the fly (and give up when\n //! they're so obviously over-long that \"infinity\" is a good enough\n //! approximation for purposes of line breaking).\n //!\n //! The \"input side\" of the printer is managed as an abstract process called\n-//! SCAN, which uses 'scan_stack', to manage calculating 'size'. SCAN is, in\n+//! SCAN, which uses `scan_stack`, to manage calculating `size`. SCAN is, in\n //! other words, the process of calculating 'size' entries.\n //!\n //! The \"output side\" of the printer is managed by an abstract process called\n-//! PRINT, which uses 'print_stack', 'margin' and 'space' to figure out what to\n+//! PRINT, which uses `print_stack`, `margin` and `space` to figure out what to\n //! do with each token/size pair it consumes as it goes. It's trying to consume\n //! the entire buffered window, but can't output anything until the size is >=\n //! 0 (sizes are set to negative while they're pending calculation).\n@@ -409,7 +409,7 @@ impl<'a> Printer<'a> {\n     pub fn advance_right(&mut self) {\n         self.right += 1;\n         self.right %= self.buf_len;\n-        assert!(self.right != self.left);\n+        assert_ne!(self.right, self.left);\n     }\n     pub fn advance_left(&mut self) -> io::Result<()> {\n         debug!(\"advance_left Vec<{},{}>, sizeof({})={}\", self.left, self.right,"}, {"sha": "83c289ff80b9251bd2df854ebed1207b7f5a09f0", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 137, "deletions": 156, "changes": 293, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -233,7 +233,7 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::CloseDelim(token::Bracket) => \"]\".to_string(),\n         token::OpenDelim(token::Brace) => \"{\".to_string(),\n         token::CloseDelim(token::Brace) => \"}\".to_string(),\n-        token::OpenDelim(token::NoDelim) => \" \".to_string(),\n+        token::OpenDelim(token::NoDelim) |\n         token::CloseDelim(token::NoDelim) => \" \".to_string(),\n         token::Pound                => \"#\".to_string(),\n         token::Dollar               => \"$\".to_string(),\n@@ -244,7 +244,7 @@ pub fn token_to_string(tok: &Token) -> String {\n             let mut out = match lit {\n                 token::Byte(b)           => format!(\"b'{}'\", b),\n                 token::Char(c)           => format!(\"'{}'\", c),\n-                token::Float(c)          => c.to_string(),\n+                token::Float(c)          |\n                 token::Integer(c)        => c.to_string(),\n                 token::Str_(s)           => format!(\"\\\"{}\\\"\", s),\n                 token::StrRaw(s, n)      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n@@ -277,23 +277,23 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::Shebang(s)           => format!(\"/* shebang: {}*/\", s),\n \n         token::Interpolated(ref nt) => match **nt {\n-            token::NtExpr(ref e)        => expr_to_string(&e),\n-            token::NtMeta(ref e)        => meta_item_to_string(&e),\n-            token::NtTy(ref e)          => ty_to_string(&e),\n-            token::NtPath(ref e)        => path_to_string(&e),\n-            token::NtItem(ref e)        => item_to_string(&e),\n-            token::NtBlock(ref e)       => block_to_string(&e),\n-            token::NtStmt(ref e)        => stmt_to_string(&e),\n-            token::NtPat(ref e)         => pat_to_string(&e),\n+            token::NtExpr(ref e)        => expr_to_string(e),\n+            token::NtMeta(ref e)        => meta_item_to_string(e),\n+            token::NtTy(ref e)          => ty_to_string(e),\n+            token::NtPath(ref e)        => path_to_string(e),\n+            token::NtItem(ref e)        => item_to_string(e),\n+            token::NtBlock(ref e)       => block_to_string(e),\n+            token::NtStmt(ref e)        => stmt_to_string(e),\n+            token::NtPat(ref e)         => pat_to_string(e),\n             token::NtIdent(ref e)       => ident_to_string(e.node),\n             token::NtTT(ref tree)       => tt_to_string(tree.clone()),\n-            token::NtArm(ref e)         => arm_to_string(&e),\n-            token::NtImplItem(ref e)    => impl_item_to_string(&e),\n-            token::NtTraitItem(ref e)   => trait_item_to_string(&e),\n-            token::NtGenerics(ref e)    => generics_to_string(&e),\n-            token::NtWhereClause(ref e) => where_clause_to_string(&e),\n-            token::NtArg(ref e)         => arg_to_string(&e),\n-            token::NtVis(ref e)         => vis_to_string(&e),\n+            token::NtArm(ref e)         => arm_to_string(e),\n+            token::NtImplItem(ref e)    => impl_item_to_string(e),\n+            token::NtTraitItem(ref e)   => trait_item_to_string(e),\n+            token::NtGenerics(ref e)    => generics_to_string(e),\n+            token::NtWhereClause(ref e) => where_clause_to_string(e),\n+            token::NtArg(ref e)         => arg_to_string(e),\n+            token::NtVis(ref e)         => vis_to_string(e),\n         }\n     }\n }\n@@ -520,8 +520,7 @@ pub trait PrintState<'a> {\n \n         let mut result = None;\n \n-        if let &Some(ref lits) = self.literals()\n-        {\n+        if let Some(ref lits) = *self.literals() {\n             while cur_lit < lits.len() {\n                 let ltrl = (*lits)[cur_lit].clone();\n                 if ltrl.pos > pos { break; }\n@@ -618,11 +617,8 @@ pub trait PrintState<'a> {\n \n     fn print_literal(&mut self, lit: &ast::Lit) -> io::Result<()> {\n         self.maybe_print_comment(lit.span.lo)?;\n-        match self.next_lit(lit.span.lo) {\n-            Some(ref ltrl) => {\n-                return word(self.writer(), &(*ltrl).lit);\n-            }\n-            _ => ()\n+        if let Some(ref ltrl) = self.next_lit(lit.span.lo) {\n+            return word(self.writer(), &(*ltrl).lit);\n         }\n         match lit.node {\n             ast::LitKind::Str(st, style) => self.print_string(&st.as_str(), style),\n@@ -799,7 +795,7 @@ pub trait PrintState<'a> {\n                 self.popen()?;\n                 self.commasep(Consistent,\n                               &items[..],\n-                              |s, i| s.print_meta_list_item(&i))?;\n+                              |s, i| s.print_meta_list_item(i))?;\n                 self.pclose()?;\n             }\n         }\n@@ -982,14 +978,14 @@ impl<'a> State<'a> {\n \n     pub fn commasep_exprs(&mut self, b: Breaks,\n                           exprs: &[P<ast::Expr>]) -> io::Result<()> {\n-        self.commasep_cmnt(b, exprs, |s, e| s.print_expr(&e), |e| e.span)\n+        self.commasep_cmnt(b, exprs, |s, e| s.print_expr(e), |e| e.span)\n     }\n \n     pub fn print_mod(&mut self, _mod: &ast::Mod,\n                      attrs: &[ast::Attribute]) -> io::Result<()> {\n         self.print_inner_attributes(attrs)?;\n         for item in &_mod.items {\n-            self.print_item(&item)?;\n+            self.print_item(item)?;\n         }\n         Ok(())\n     }\n@@ -1018,7 +1014,7 @@ impl<'a> State<'a> {\n         match ty.node {\n             ast::TyKind::Slice(ref ty) => {\n                 word(&mut self.s, \"[\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 word(&mut self.s, \"]\")?;\n             }\n             ast::TyKind::Ptr(ref mt) => {\n@@ -1040,15 +1036,15 @@ impl<'a> State<'a> {\n             ast::TyKind::Tup(ref elts) => {\n                 self.popen()?;\n                 self.commasep(Inconsistent, &elts[..],\n-                              |s, ty| s.print_type(&ty))?;\n+                              |s, ty| s.print_type(ty))?;\n                 if elts.len() == 1 {\n                     word(&mut self.s, \",\")?;\n                 }\n                 self.pclose()?;\n             }\n             ast::TyKind::Paren(ref typ) => {\n                 self.popen()?;\n-                self.print_type(&typ)?;\n+                self.print_type(typ)?;\n                 self.pclose()?;\n             }\n             ast::TyKind::BareFn(ref f) => {\n@@ -1081,14 +1077,14 @@ impl<'a> State<'a> {\n             }\n             ast::TyKind::Array(ref ty, ref v) => {\n                 word(&mut self.s, \"[\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 word(&mut self.s, \"; \")?;\n-                self.print_expr(&v)?;\n+                self.print_expr(v)?;\n                 word(&mut self.s, \"]\")?;\n             }\n             ast::TyKind::Typeof(ref e) => {\n                 word(&mut self.s, \"typeof(\")?;\n-                self.print_expr(&e)?;\n+                self.print_expr(e)?;\n                 word(&mut self.s, \")\")?;\n             }\n             ast::TyKind::Infer => {\n@@ -1130,7 +1126,7 @@ impl<'a> State<'a> {\n                 }\n                 self.print_ident(item.ident)?;\n                 self.word_space(\":\")?;\n-                self.print_type(&t)?;\n+                self.print_type(t)?;\n                 word(&mut self.s, \";\")?;\n                 self.end()?; // end the head-ibox\n                 self.end() // end the outer cbox\n@@ -1187,7 +1183,7 @@ impl<'a> State<'a> {\n                 self.head(&visibility_qualified(&item.vis, \"extern crate\"))?;\n                 if let Some(p) = *optional_path {\n                     let val = p.as_str();\n-                    if val.contains(\"-\") {\n+                    if val.contains('-') {\n                         self.print_string(&val, ast::StrStyle::Cooked)?;\n                     } else {\n                         self.print_name(p)?;\n@@ -1203,7 +1199,7 @@ impl<'a> State<'a> {\n             }\n             ast::ItemKind::Use(ref vp) => {\n                 self.head(&visibility_qualified(&item.vis, \"use\"))?;\n-                self.print_view_path(&vp)?;\n+                self.print_view_path(vp)?;\n                 word(&mut self.s, \";\")?;\n                 self.end()?; // end inner head-block\n                 self.end()?; // end outer head-block\n@@ -1215,25 +1211,25 @@ impl<'a> State<'a> {\n                 }\n                 self.print_ident(item.ident)?;\n                 self.word_space(\":\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 space(&mut self.s)?;\n                 self.end()?; // end the head-ibox\n \n                 self.word_space(\"=\")?;\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 word(&mut self.s, \";\")?;\n                 self.end()?; // end the outer cbox\n             }\n             ast::ItemKind::Const(ref ty, ref expr) => {\n                 self.head(&visibility_qualified(&item.vis, \"const\"))?;\n                 self.print_ident(item.ident)?;\n                 self.word_space(\":\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 space(&mut self.s)?;\n                 self.end()?; // end the head-ibox\n \n                 self.word_space(\"=\")?;\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 word(&mut self.s, \";\")?;\n                 self.end()?; // end the outer cbox\n             }\n@@ -1249,7 +1245,7 @@ impl<'a> State<'a> {\n                     &item.vis\n                 )?;\n                 word(&mut self.s, \" \")?;\n-                self.print_block_with_attrs(&body, &item.attrs)?;\n+                self.print_block_with_attrs(body, &item.attrs)?;\n             }\n             ast::ItemKind::Mod(ref _mod) => {\n                 self.head(&visibility_qualified(&item.vis, \"mod\"))?;\n@@ -1282,7 +1278,7 @@ impl<'a> State<'a> {\n                 self.print_where_clause(&params.where_clause)?;\n                 space(&mut self.s)?;\n                 self.word_space(\"=\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 word(&mut self.s, \";\")?;\n                 self.end()?; // end the outer ibox\n             }\n@@ -1297,11 +1293,11 @@ impl<'a> State<'a> {\n             }\n             ast::ItemKind::Struct(ref struct_def, ref generics) => {\n                 self.head(&visibility_qualified(&item.vis, \"struct\"))?;\n-                self.print_struct(&struct_def, generics, item.ident, item.span, true)?;\n+                self.print_struct(struct_def, generics, item.ident, item.span, true)?;\n             }\n             ast::ItemKind::Union(ref struct_def, ref generics) => {\n                 self.head(&visibility_qualified(&item.vis, \"union\"))?;\n-                self.print_struct(&struct_def, generics, item.ident, item.span, true)?;\n+                self.print_struct(struct_def, generics, item.ident, item.span, true)?;\n             }\n             ast::ItemKind::DefaultImpl(unsafety, ref trait_ref) => {\n                 self.head(\"\")?;\n@@ -1333,11 +1329,8 @@ impl<'a> State<'a> {\n                     space(&mut self.s)?;\n                 }\n \n-                match polarity {\n-                    ast::ImplPolarity::Negative => {\n-                        word(&mut self.s, \"!\")?;\n-                    },\n-                    _ => {}\n+                if polarity == ast::ImplPolarity::Negative {\n+                    word(&mut self.s, \"!\")?;\n                 }\n \n                 if let Some(ref t) = *opt_trait {\n@@ -1346,7 +1339,7 @@ impl<'a> State<'a> {\n                     self.word_space(\"for\")?;\n                 }\n \n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 self.print_where_clause(&generics.where_clause)?;\n \n                 space(&mut self.s)?;\n@@ -1543,7 +1536,7 @@ impl<'a> State<'a> {\n             Some(ref d) => {\n                 space(&mut self.s)?;\n                 self.word_space(\"=\")?;\n-                self.print_expr(&d)\n+                self.print_expr(d)\n             }\n             _ => Ok(())\n         }\n@@ -1571,7 +1564,7 @@ impl<'a> State<'a> {\n         self.print_outer_attributes(&ti.attrs)?;\n         match ti.node {\n             ast::TraitItemKind::Const(ref ty, ref default) => {\n-                self.print_associated_const(ti.ident, &ty,\n+                self.print_associated_const(ti.ident, ty,\n                                             default.as_ref().map(|expr| &**expr),\n                                             &ast::Visibility::Inherited)?;\n             }\n@@ -1614,7 +1607,7 @@ impl<'a> State<'a> {\n         self.print_defaultness(ii.defaultness)?;\n         match ii.node {\n             ast::ImplItemKind::Const(ref ty, ref expr) => {\n-                self.print_associated_const(ii.ident, &ty, Some(&expr), &ii.vis)?;\n+                self.print_associated_const(ii.ident, ty, Some(expr), &ii.vis)?;\n             }\n             ast::ImplItemKind::Method(ref sig, ref body) => {\n                 self.head(\"\")?;\n@@ -1650,38 +1643,38 @@ impl<'a> State<'a> {\n                 self.word_nbsp(\"let\")?;\n \n                 self.ibox(INDENT_UNIT)?;\n-                self.print_local_decl(&loc)?;\n+                self.print_local_decl(loc)?;\n                 self.end()?;\n                 if let Some(ref init) = loc.init {\n                     self.nbsp()?;\n                     self.word_space(\"=\")?;\n-                    self.print_expr(&init)?;\n+                    self.print_expr(init)?;\n                 }\n                 word(&mut self.s, \";\")?;\n                 self.end()?;\n             }\n-            ast::StmtKind::Item(ref item) => self.print_item(&item)?,\n+            ast::StmtKind::Item(ref item) => self.print_item(item)?,\n             ast::StmtKind::Expr(ref expr) => {\n                 self.space_if_not_bol()?;\n-                self.print_expr_outer_attr_style(&expr, false)?;\n+                self.print_expr_outer_attr_style(expr, false)?;\n                 if parse::classify::expr_requires_semi_to_be_stmt(expr) {\n                     word(&mut self.s, \";\")?;\n                 }\n             }\n             ast::StmtKind::Semi(ref expr) => {\n                 self.space_if_not_bol()?;\n-                self.print_expr_outer_attr_style(&expr, false)?;\n+                self.print_expr_outer_attr_style(expr, false)?;\n                 word(&mut self.s, \";\")?;\n             }\n             ast::StmtKind::Mac(ref mac) => {\n                 let (ref mac, style, ref attrs) = **mac;\n                 self.space_if_not_bol()?;\n-                self.print_outer_attributes(&attrs)?;\n+                self.print_outer_attributes(attrs)?;\n                 let delim = match style {\n                     ast::MacStmtStyle::Braces => token::Brace,\n                     _ => token::Paren\n                 };\n-                self.print_mac(&mac, delim)?;\n+                self.print_mac(mac, delim)?;\n                 if style == ast::MacStmtStyle::Semicolon {\n                     word(&mut self.s, \";\")?;\n                 }\n@@ -1735,7 +1728,7 @@ impl<'a> State<'a> {\n                 ast::StmtKind::Expr(ref expr) if i == blk.stmts.len() - 1 => {\n                     self.maybe_print_comment(st.span.lo)?;\n                     self.space_if_not_bol()?;\n-                    self.print_expr_outer_attr_style(&expr, false)?;\n+                    self.print_expr_outer_attr_style(expr, false)?;\n                     self.maybe_print_trailing_comment(expr.span, Some(blk.span.hi))?;\n                 }\n                 _ => self.print_stmt(st)?,\n@@ -1755,30 +1748,30 @@ impl<'a> State<'a> {\n                         self.cbox(INDENT_UNIT - 1)?;\n                         self.ibox(0)?;\n                         word(&mut self.s, \" else if \")?;\n-                        self.print_expr(&i)?;\n+                        self.print_expr(i)?;\n                         space(&mut self.s)?;\n-                        self.print_block(&then)?;\n+                        self.print_block(then)?;\n                         self.print_else(e.as_ref().map(|e| &**e))\n                     }\n                     // \"another else-if-let\"\n                     ast::ExprKind::IfLet(ref pat, ref expr, ref then, ref e) => {\n                         self.cbox(INDENT_UNIT - 1)?;\n                         self.ibox(0)?;\n                         word(&mut self.s, \" else if let \")?;\n-                        self.print_pat(&pat)?;\n+                        self.print_pat(pat)?;\n                         space(&mut self.s)?;\n                         self.word_space(\"=\")?;\n-                        self.print_expr(&expr)?;\n+                        self.print_expr(expr)?;\n                         space(&mut self.s)?;\n-                        self.print_block(&then)?;\n+                        self.print_block(then)?;\n                         self.print_else(e.as_ref().map(|e| &**e))\n                     }\n                     // \"final else\"\n                     ast::ExprKind::Block(ref b) => {\n                         self.cbox(INDENT_UNIT - 1)?;\n                         self.ibox(0)?;\n                         word(&mut self.s, \" else \")?;\n-                        self.print_block(&b)\n+                        self.print_block(b)\n                     }\n                     // BLEAH, constraints would be great here\n                     _ => {\n@@ -1844,12 +1837,8 @@ impl<'a> State<'a> {\n                                       binop: ast::BinOp) -> bool {\n         match sub_expr.node {\n             ast::ExprKind::Binary(ref sub_op, _, _) => {\n-                if AssocOp::from_ast_binop(sub_op.node).precedence() <\n-                    AssocOp::from_ast_binop(binop.node).precedence() {\n-                    true\n-                } else {\n-                    false\n-                }\n+                AssocOp::from_ast_binop(sub_op.node).precedence() <\n+                    AssocOp::from_ast_binop(binop.node).precedence()\n             }\n             _ => true\n         }\n@@ -1929,7 +1918,7 @@ impl<'a> State<'a> {\n                     space(&mut self.s)?;\n                 }\n                 word(&mut self.s, \"..\")?;\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 self.end()?;\n             }\n             _ => if !fields.is_empty() {\n@@ -1969,7 +1958,7 @@ impl<'a> State<'a> {\n         if !tys.is_empty() {\n             word(&mut self.s, \"::<\")?;\n             self.commasep(Inconsistent, tys,\n-                          |s, ty| s.print_type(&ty))?;\n+                          |s, ty| s.print_type(ty))?;\n             word(&mut self.s, \">\")?;\n         }\n         self.print_call_post(base_args)\n@@ -2038,7 +2027,7 @@ impl<'a> State<'a> {\n                 self.print_expr_vec(&exprs[..], attrs)?;\n             }\n             ast::ExprKind::Repeat(ref element, ref count) => {\n-                self.print_expr_repeat(&element, &count, attrs)?;\n+                self.print_expr_repeat(element, count, attrs)?;\n             }\n             ast::ExprKind::Struct(ref path, ref fields, ref wth) => {\n                 self.print_expr_struct(path, &fields[..], wth, attrs)?;\n@@ -2047,79 +2036,79 @@ impl<'a> State<'a> {\n                 self.print_expr_tup(&exprs[..], attrs)?;\n             }\n             ast::ExprKind::Call(ref func, ref args) => {\n-                self.print_expr_call(&func, &args[..])?;\n+                self.print_expr_call(func, &args[..])?;\n             }\n             ast::ExprKind::MethodCall(ident, ref tys, ref args) => {\n                 self.print_expr_method_call(ident, &tys[..], &args[..])?;\n             }\n             ast::ExprKind::Binary(op, ref lhs, ref rhs) => {\n-                self.print_expr_binary(op, &lhs, &rhs)?;\n+                self.print_expr_binary(op, lhs, rhs)?;\n             }\n             ast::ExprKind::Unary(op, ref expr) => {\n-                self.print_expr_unary(op, &expr)?;\n+                self.print_expr_unary(op, expr)?;\n             }\n             ast::ExprKind::AddrOf(m, ref expr) => {\n-                self.print_expr_addr_of(m, &expr)?;\n+                self.print_expr_addr_of(m, expr)?;\n             }\n             ast::ExprKind::Lit(ref lit) => {\n-                self.print_literal(&lit)?;\n+                self.print_literal(lit)?;\n             }\n             ast::ExprKind::Cast(ref expr, ref ty) => {\n                 if let ast::ExprKind::Cast(..) = expr.node {\n-                    self.print_expr(&expr)?;\n+                    self.print_expr(expr)?;\n                 } else {\n-                    self.print_expr_maybe_paren(&expr)?;\n+                    self.print_expr_maybe_paren(expr)?;\n                 }\n                 space(&mut self.s)?;\n                 self.word_space(\"as\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n             }\n             ast::ExprKind::Type(ref expr, ref ty) => {\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 self.word_space(\":\")?;\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n             }\n             ast::ExprKind::If(ref test, ref blk, ref elseopt) => {\n-                self.print_if(&test, &blk, elseopt.as_ref().map(|e| &**e))?;\n+                self.print_if(test, blk, elseopt.as_ref().map(|e| &**e))?;\n             }\n             ast::ExprKind::IfLet(ref pat, ref expr, ref blk, ref elseopt) => {\n-                self.print_if_let(&pat, &expr, &blk, elseopt.as_ref().map(|e| &**e))?;\n+                self.print_if_let(pat, expr, blk, elseopt.as_ref().map(|e| &**e))?;\n             }\n             ast::ExprKind::While(ref test, ref blk, opt_ident) => {\n                 if let Some(ident) = opt_ident {\n                     self.print_ident(ident.node)?;\n                     self.word_space(\":\")?;\n                 }\n                 self.head(\"while\")?;\n-                self.print_expr(&test)?;\n+                self.print_expr(test)?;\n                 space(&mut self.s)?;\n-                self.print_block_with_attrs(&blk, attrs)?;\n+                self.print_block_with_attrs(blk, attrs)?;\n             }\n             ast::ExprKind::WhileLet(ref pat, ref expr, ref blk, opt_ident) => {\n                 if let Some(ident) = opt_ident {\n                     self.print_ident(ident.node)?;\n                     self.word_space(\":\")?;\n                 }\n                 self.head(\"while let\")?;\n-                self.print_pat(&pat)?;\n+                self.print_pat(pat)?;\n                 space(&mut self.s)?;\n                 self.word_space(\"=\")?;\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 space(&mut self.s)?;\n-                self.print_block_with_attrs(&blk, attrs)?;\n+                self.print_block_with_attrs(blk, attrs)?;\n             }\n             ast::ExprKind::ForLoop(ref pat, ref iter, ref blk, opt_ident) => {\n                 if let Some(ident) = opt_ident {\n                     self.print_ident(ident.node)?;\n                     self.word_space(\":\")?;\n                 }\n                 self.head(\"for\")?;\n-                self.print_pat(&pat)?;\n+                self.print_pat(pat)?;\n                 space(&mut self.s)?;\n                 self.word_space(\"in\")?;\n-                self.print_expr(&iter)?;\n+                self.print_expr(iter)?;\n                 space(&mut self.s)?;\n-                self.print_block_with_attrs(&blk, attrs)?;\n+                self.print_block_with_attrs(blk, attrs)?;\n             }\n             ast::ExprKind::Loop(ref blk, opt_ident) => {\n                 if let Some(ident) = opt_ident {\n@@ -2128,13 +2117,13 @@ impl<'a> State<'a> {\n                 }\n                 self.head(\"loop\")?;\n                 space(&mut self.s)?;\n-                self.print_block_with_attrs(&blk, attrs)?;\n+                self.print_block_with_attrs(blk, attrs)?;\n             }\n             ast::ExprKind::Match(ref expr, ref arms) => {\n                 self.cbox(INDENT_UNIT)?;\n                 self.ibox(4)?;\n                 self.word_nbsp(\"match\")?;\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 space(&mut self.s)?;\n                 self.bopen()?;\n                 self.print_inner_attributes_no_trailing_hardbreak(attrs)?;\n@@ -2146,7 +2135,7 @@ impl<'a> State<'a> {\n             ast::ExprKind::Closure(capture_clause, ref decl, ref body, _) => {\n                 self.print_capture_clause(capture_clause)?;\n \n-                self.print_fn_block_args(&decl)?;\n+                self.print_fn_block_args(decl)?;\n                 space(&mut self.s)?;\n                 self.print_expr(body)?;\n                 self.end()?; // need to close a box\n@@ -2161,48 +2150,48 @@ impl<'a> State<'a> {\n                 self.cbox(INDENT_UNIT)?;\n                 // head-box, will be closed by print-block after {\n                 self.ibox(0)?;\n-                self.print_block_with_attrs(&blk, attrs)?;\n+                self.print_block_with_attrs(blk, attrs)?;\n             }\n             ast::ExprKind::Assign(ref lhs, ref rhs) => {\n-                self.print_expr(&lhs)?;\n+                self.print_expr(lhs)?;\n                 space(&mut self.s)?;\n                 self.word_space(\"=\")?;\n-                self.print_expr(&rhs)?;\n+                self.print_expr(rhs)?;\n             }\n             ast::ExprKind::AssignOp(op, ref lhs, ref rhs) => {\n-                self.print_expr(&lhs)?;\n+                self.print_expr(lhs)?;\n                 space(&mut self.s)?;\n                 word(&mut self.s, op.node.to_string())?;\n                 self.word_space(\"=\")?;\n-                self.print_expr(&rhs)?;\n+                self.print_expr(rhs)?;\n             }\n             ast::ExprKind::Field(ref expr, id) => {\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 word(&mut self.s, \".\")?;\n                 self.print_ident(id.node)?;\n             }\n             ast::ExprKind::TupField(ref expr, id) => {\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 word(&mut self.s, \".\")?;\n                 self.print_usize(id.node)?;\n             }\n             ast::ExprKind::Index(ref expr, ref index) => {\n-                self.print_expr(&expr)?;\n+                self.print_expr(expr)?;\n                 word(&mut self.s, \"[\")?;\n-                self.print_expr(&index)?;\n+                self.print_expr(index)?;\n                 word(&mut self.s, \"]\")?;\n             }\n             ast::ExprKind::Range(ref start, ref end, limits) => {\n-                if let &Some(ref e) = start {\n-                    self.print_expr(&e)?;\n+                if let Some(ref e) = *start {\n+                    self.print_expr(e)?;\n                 }\n                 if limits == ast::RangeLimits::HalfOpen {\n                     word(&mut self.s, \"..\")?;\n                 } else {\n                     word(&mut self.s, \"...\")?;\n                 }\n-                if let &Some(ref e) = end {\n-                    self.print_expr(&e)?;\n+                if let Some(ref e) = *end {\n+                    self.print_expr(e)?;\n                 }\n             }\n             ast::ExprKind::Path(None, ref path) => {\n@@ -2233,12 +2222,9 @@ impl<'a> State<'a> {\n             }\n             ast::ExprKind::Ret(ref result) => {\n                 word(&mut self.s, \"return\")?;\n-                match *result {\n-                    Some(ref expr) => {\n-                        word(&mut self.s, \" \")?;\n-                        self.print_expr(&expr)?;\n-                    }\n-                    _ => ()\n+                if let Some(ref expr) = *result {\n+                    word(&mut self.s, \" \")?;\n+                    self.print_expr(expr)?;\n                 }\n             }\n             ast::ExprKind::InlineAsm(ref a) => {\n@@ -2268,7 +2254,7 @@ impl<'a> State<'a> {\n                 self.commasep(Inconsistent, &a.inputs, |s, &(co, ref o)| {\n                     s.print_string(&co.as_str(), ast::StrStyle::Cooked)?;\n                     s.popen()?;\n-                    s.print_expr(&o)?;\n+                    s.print_expr(o)?;\n                     s.pclose()?;\n                     Ok(())\n                 })?;\n@@ -2308,7 +2294,7 @@ impl<'a> State<'a> {\n             ast::ExprKind::Paren(ref e) => {\n                 self.popen()?;\n                 self.print_inner_attributes_inline(attrs)?;\n-                self.print_expr(&e)?;\n+                self.print_expr(e)?;\n                 self.pclose()?;\n             },\n             ast::ExprKind::Try(ref e) => {\n@@ -2318,7 +2304,7 @@ impl<'a> State<'a> {\n             ast::ExprKind::Catch(ref blk) => {\n                 self.head(\"do catch\")?;\n                 space(&mut self.s)?;\n-                self.print_block_with_attrs(&blk, attrs)?\n+                self.print_block_with_attrs(blk, attrs)?\n             }\n         }\n         self.ann.post(self, NodeExpr(expr))?;\n@@ -2329,7 +2315,7 @@ impl<'a> State<'a> {\n         self.print_pat(&loc.pat)?;\n         if let Some(ref ty) = loc.ty {\n             self.word_space(\":\")?;\n-            self.print_type(&ty)?;\n+            self.print_type(ty)?;\n         }\n         Ok(())\n     }\n@@ -2397,7 +2383,7 @@ impl<'a> State<'a> {\n             space(&mut self.s)?;\n             self.word_space(\"as\")?;\n             let depth = path.segments.len() - qself.position;\n-            self.print_path(&path, false, depth, false)?;\n+            self.print_path(path, false, depth, false)?;\n         }\n         word(&mut self.s, \">\")?;\n         word(&mut self.s, \"::\")?;\n@@ -2438,7 +2424,7 @@ impl<'a> State<'a> {\n                     self.commasep(\n                         Inconsistent,\n                         &data.types,\n-                        |s, ty| s.print_type(&ty))?;\n+                        |s, ty| s.print_type(ty))?;\n                         comma = true;\n                 }\n \n@@ -2461,13 +2447,13 @@ impl<'a> State<'a> {\n                 self.commasep(\n                     Inconsistent,\n                     &data.inputs,\n-                    |s, ty| s.print_type(&ty))?;\n+                    |s, ty| s.print_type(ty))?;\n                 word(&mut self.s, \")\")?;\n \n                 if let Some(ref ty) = data.output {\n                     self.space_if_not_bol()?;\n                     self.word_space(\"->\")?;\n-                    self.print_type(&ty)?;\n+                    self.print_type(ty)?;\n                 }\n             }\n         }\n@@ -2496,24 +2482,24 @@ impl<'a> State<'a> {\n                 self.print_ident(path1.node)?;\n                 if let Some(ref p) = *sub {\n                     word(&mut self.s, \"@\")?;\n-                    self.print_pat(&p)?;\n+                    self.print_pat(p)?;\n                 }\n             }\n             PatKind::TupleStruct(ref path, ref elts, ddpos) => {\n                 self.print_path(path, true, 0, false)?;\n                 self.popen()?;\n                 if let Some(ddpos) = ddpos {\n-                    self.commasep(Inconsistent, &elts[..ddpos], |s, p| s.print_pat(&p))?;\n+                    self.commasep(Inconsistent, &elts[..ddpos], |s, p| s.print_pat(p))?;\n                     if ddpos != 0 {\n                         self.word_space(\",\")?;\n                     }\n                     word(&mut self.s, \"..\")?;\n                     if ddpos != elts.len() {\n                         word(&mut self.s, \",\")?;\n-                        self.commasep(Inconsistent, &elts[ddpos..], |s, p| s.print_pat(&p))?;\n+                        self.commasep(Inconsistent, &elts[ddpos..], |s, p| s.print_pat(p))?;\n                     }\n                 } else {\n-                    self.commasep(Inconsistent, &elts[..], |s, p| s.print_pat(&p))?;\n+                    self.commasep(Inconsistent, &elts[..], |s, p| s.print_pat(p))?;\n                 }\n                 self.pclose()?;\n             }\n@@ -2549,17 +2535,17 @@ impl<'a> State<'a> {\n             PatKind::Tuple(ref elts, ddpos) => {\n                 self.popen()?;\n                 if let Some(ddpos) = ddpos {\n-                    self.commasep(Inconsistent, &elts[..ddpos], |s, p| s.print_pat(&p))?;\n+                    self.commasep(Inconsistent, &elts[..ddpos], |s, p| s.print_pat(p))?;\n                     if ddpos != 0 {\n                         self.word_space(\",\")?;\n                     }\n                     word(&mut self.s, \"..\")?;\n                     if ddpos != elts.len() {\n                         word(&mut self.s, \",\")?;\n-                        self.commasep(Inconsistent, &elts[ddpos..], |s, p| s.print_pat(&p))?;\n+                        self.commasep(Inconsistent, &elts[ddpos..], |s, p| s.print_pat(p))?;\n                     }\n                 } else {\n-                    self.commasep(Inconsistent, &elts[..], |s, p| s.print_pat(&p))?;\n+                    self.commasep(Inconsistent, &elts[..], |s, p| s.print_pat(p))?;\n                     if elts.len() == 1 {\n                         word(&mut self.s, \",\")?;\n                     }\n@@ -2568,41 +2554,41 @@ impl<'a> State<'a> {\n             }\n             PatKind::Box(ref inner) => {\n                 word(&mut self.s, \"box \")?;\n-                self.print_pat(&inner)?;\n+                self.print_pat(inner)?;\n             }\n             PatKind::Ref(ref inner, mutbl) => {\n                 word(&mut self.s, \"&\")?;\n                 if mutbl == ast::Mutability::Mutable {\n                     word(&mut self.s, \"mut \")?;\n                 }\n-                self.print_pat(&inner)?;\n+                self.print_pat(inner)?;\n             }\n             PatKind::Lit(ref e) => self.print_expr(&**e)?,\n             PatKind::Range(ref begin, ref end, ref end_kind) => {\n-                self.print_expr(&begin)?;\n+                self.print_expr(begin)?;\n                 space(&mut self.s)?;\n                 match *end_kind {\n                     RangeEnd::Included => word(&mut self.s, \"...\")?,\n                     RangeEnd::Excluded => word(&mut self.s, \"..\")?,\n                 }\n-                self.print_expr(&end)?;\n+                self.print_expr(end)?;\n             }\n             PatKind::Slice(ref before, ref slice, ref after) => {\n                 word(&mut self.s, \"[\")?;\n                 self.commasep(Inconsistent,\n                                    &before[..],\n-                                   |s, p| s.print_pat(&p))?;\n+                                   |s, p| s.print_pat(p))?;\n                 if let Some(ref p) = *slice {\n                     if !before.is_empty() { self.word_space(\",\")?; }\n                     if p.node != PatKind::Wild {\n-                        self.print_pat(&p)?;\n+                        self.print_pat(p)?;\n                     }\n                     word(&mut self.s, \"..\")?;\n                     if !after.is_empty() { self.word_space(\",\")?; }\n                 }\n                 self.commasep(Inconsistent,\n                                    &after[..],\n-                                   |s, p| s.print_pat(&p))?;\n+                                   |s, p| s.print_pat(p))?;\n                 word(&mut self.s, \"]\")?;\n             }\n             PatKind::Mac(ref m) => self.print_mac(m, token::Paren)?,\n@@ -2628,20 +2614,20 @@ impl<'a> State<'a> {\n                 space(&mut self.s)?;\n                 self.word_space(\"|\")?;\n             }\n-            self.print_pat(&p)?;\n+            self.print_pat(p)?;\n         }\n         space(&mut self.s)?;\n         if let Some(ref e) = arm.guard {\n             self.word_space(\"if\")?;\n-            self.print_expr(&e)?;\n+            self.print_expr(e)?;\n             space(&mut self.s)?;\n         }\n         self.word_space(\"=>\")?;\n \n         match arm.body.node {\n             ast::ExprKind::Block(ref blk) => {\n                 // the block will close the pattern's ibox\n-                self.print_block_unclosed_indent(&blk, INDENT_UNIT)?;\n+                self.print_block_unclosed_indent(blk, INDENT_UNIT)?;\n \n                 // If it is a user-provided unsafe block, print a comma after it\n                 if let BlockCheckMode::Unsafe(ast::UserProvided) = blk.rules {\n@@ -2673,7 +2659,7 @@ impl<'a> State<'a> {\n                 self.print_mutability(m)?;\n                 word(&mut self.s, \"self\")?;\n                 self.word_space(\":\")?;\n-                self.print_type(&typ)\n+                self.print_type(typ)\n             }\n         }\n     }\n@@ -2725,7 +2711,7 @@ impl<'a> State<'a> {\n         self.word_space(\"->\")?;\n         match decl.output {\n             ast::FunctionRetTy::Ty(ref ty) => {\n-                self.print_type(&ty)?;\n+                self.print_type(ty)?;\n                 self.maybe_print_comment(ty.span.lo)\n             }\n             ast::FunctionRetTy::Default(..) => unreachable!(),\n@@ -2839,7 +2825,7 @@ impl<'a> State<'a> {\n             Some(ref default) => {\n                 space(&mut self.s)?;\n                 self.word_space(\"=\")?;\n-                self.print_type(&default)\n+                self.print_type(default)\n             }\n             _ => Ok(())\n         }\n@@ -2865,7 +2851,7 @@ impl<'a> State<'a> {\n                                                                              ref bounds,\n                                                                              ..}) => {\n                     self.print_formal_lifetime_list(bound_lifetimes)?;\n-                    self.print_type(&bounded_ty)?;\n+                    self.print_type(bounded_ty)?;\n                     self.print_bounds(\":\", bounds)?;\n                 }\n                 ast::WherePredicate::RegionPredicate(ast::WhereRegionPredicate{ref lifetime,\n@@ -2977,7 +2963,7 @@ impl<'a> State<'a> {\n         match decl.output {\n             ast::FunctionRetTy::Default(..) => unreachable!(),\n             ast::FunctionRetTy::Ty(ref ty) =>\n-                self.print_type(&ty)?\n+                self.print_type(ty)?\n         }\n         self.end()?;\n \n@@ -3044,14 +3030,9 @@ impl<'a> State<'a> {\n         if self.next_comment().is_none() {\n             hardbreak(&mut self.s)?;\n         }\n-        loop {\n-            match self.next_comment() {\n-                Some(ref cmnt) => {\n-                    self.print_comment(cmnt)?;\n-                    self.cur_cmnt_and_lit.cur_cmnt += 1;\n-                }\n-                _ => break\n-            }\n+        while let Some(ref cmnt) = self.next_comment() {\n+            self.print_comment(cmnt)?;\n+            self.cur_cmnt_and_lit.cur_cmnt += 1;\n         }\n         Ok(())\n     }"}, {"sha": "8e257102e1c13367d281d01cce701e94bb0bacf5", "filename": "src/libsyntax/std_inject.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fstd_inject.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fstd_inject.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fstd_inject.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -18,7 +18,7 @@ use ptr::P;\n use tokenstream::TokenStream;\n \n /// Craft a span that will be ignored by the stability lint's\n-/// call to codemap's is_internal check.\n+/// call to codemap's `is_internal` check.\n /// The expanded code uses the unstable `#[prelude_import]` attribute.\n fn ignored_span(sp: Span) -> Span {\n     let mark = Mark::fresh();\n@@ -49,7 +49,7 @@ pub fn maybe_inject_crates_ref(mut krate: ast::Crate, alt_std_name: Option<Strin\n         None => return krate,\n     };\n \n-    let crate_name = Symbol::intern(&alt_std_name.unwrap_or(name.to_string()));\n+    let crate_name = Symbol::intern(&alt_std_name.unwrap_or_else(|| name.to_string()));\n \n     krate.module.items.insert(0, P(ast::Item {\n         attrs: vec![attr::mk_attr_outer(DUMMY_SP,"}, {"sha": "bb1a6ff65a596018a263bc7aa94e941e24da1b78", "filename": "src/libsyntax/test.rs", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftest.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -106,9 +106,8 @@ impl<'a> fold::Folder for TestHarnessGenerator<'a> {\n         // Add a special __test module to the crate that will contain code\n         // generated for the test harness\n         let (mod_, reexport) = mk_test_module(&mut self.cx);\n-        match reexport {\n-            Some(re) => folded.module.items.push(re),\n-            None => {}\n+        if let Some(re) = reexport {\n+            folded.module.items.push(re)\n         }\n         folded.module.items.push(mod_);\n         folded\n@@ -257,7 +256,7 @@ fn mk_reexport_mod(cx: &mut TestCtxt,\n     let parent = if parent == ast::DUMMY_NODE_ID { ast::CRATE_NODE_ID } else { parent };\n     cx.ext_cx.current_expansion.mark = cx.ext_cx.resolver.get_module_scope(parent);\n     let it = cx.ext_cx.monotonic_expander().fold_item(P(ast::Item {\n-        ident: sym.clone(),\n+        ident: sym,\n         attrs: Vec::new(),\n         id: ast::DUMMY_NODE_ID,\n         node: ast::ItemKind::Mod(reexport_mod),\n@@ -308,7 +307,7 @@ fn generate_test_harness(sess: &ParseSess,\n }\n \n /// Craft a span that will be ignored by the stability lint's\n-/// call to codemap's is_internal check.\n+/// call to codemap's `is_internal` check.\n /// The expanded code calls some unstable functions in the test crate.\n fn ignored_span(cx: &TestCtxt, sp: Span) -> Span {\n     Span { ctxt: cx.ctxt, ..sp }\n@@ -354,7 +353,7 @@ fn is_test_fn(cx: &TestCtxt, i: &ast::Item) -> bool {\n         }\n     }\n \n-    return has_test_attr && has_test_signature(i) == Yes;\n+    has_test_attr && has_test_signature(i) == Yes\n }\n \n fn is_bench_fn(cx: &TestCtxt, i: &ast::Item) -> bool {\n@@ -385,7 +384,7 @@ fn is_bench_fn(cx: &TestCtxt, i: &ast::Item) -> bool {\n                       `fn(&mut Bencher) -> ()`\");\n     }\n \n-    return has_bench_attr && has_test_signature(i);\n+    has_bench_attr && has_test_signature(i)\n }\n \n fn is_ignored(i: &ast::Item) -> bool {\n@@ -504,16 +503,14 @@ fn mk_main(cx: &mut TestCtxt) -> P<ast::Item> {\n                            ast::Unsafety::Normal,\n                            dummy_spanned(ast::Constness::NotConst),\n                            ::abi::Abi::Rust, ast::Generics::default(), main_body);\n-    let main = P(ast::Item {\n+    P(ast::Item {\n         ident: Ident::from_str(\"main\"),\n         attrs: vec![main_attr],\n         id: ast::DUMMY_NODE_ID,\n         node: main,\n         vis: ast::Visibility::Public,\n         span: sp\n-    });\n-\n-    return main;\n+    })\n }\n \n fn mk_test_module(cx: &mut TestCtxt) -> (P<ast::Item>, Option<P<ast::Item>>) {"}, {"sha": "9c1371a31fec7a9287f9f874c5d59defe042056e", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -10,16 +10,16 @@\n \n //! # Token Streams\n //!\n-//! TokenStreams represent syntactic objects before they are converted into ASTs.\n+//! `TokenStream`s represent syntactic objects before they are converted into ASTs.\n //! A `TokenStream` is, roughly speaking, a sequence (eg stream) of `TokenTree`s,\n //! which are themselves a single `Token` or a `Delimited` subsequence of tokens.\n //!\n //! ## Ownership\n-//! TokenStreams are persistent data structures constructed as ropes with reference\n-//! counted-children. In general, this means that calling an operation on a TokenStream\n-//! (such as `slice`) produces an entirely new TokenStream from the borrowed reference to\n-//! the original. This essentially coerces TokenStreams into 'views' of their subparts,\n-//! and a borrowed TokenStream is sufficient to build an owned TokenStream without taking\n+//! `TokenStreams` are persistent data structures constructed as ropes with reference\n+//! counted-children. In general, this means that calling an operation on a `TokenStream`\n+//! (such as `slice`) produces an entirely new `TokenStream` from the borrowed reference to\n+//! the original. This essentially coerces `TokenStream`s into 'views' of their subparts,\n+//! and a borrowed `TokenStream` is sufficient to build an owned `TokenStream` without taking\n //! ownership of the original.\n \n use syntax_pos::{BytePos, Span, DUMMY_SP};\n@@ -88,7 +88,7 @@ impl Delimited {\n /// If the syntax extension is an MBE macro, it will attempt to match its\n /// LHS token tree against the provided token tree, and if it finds a\n /// match, will transcribe the RHS token tree, splicing in any captured\n-/// macro_parser::matched_nonterminals into the `SubstNt`s it finds.\n+/// `macro_parser::matched_nonterminals` into the `SubstNt`s it finds.\n ///\n /// The RHS of an MBE macro is the only place `SubstNt`s are substituted.\n /// Nothing special happens to misnamed or misplaced `SubstNt`s."}, {"sha": "9307f3c58d4b0eb5d6942e9e8e6ee5ac23769688", "filename": "src/libsyntax/util/lev_distance.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Futil%2Flev_distance.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Futil%2Flev_distance.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Flev_distance.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -53,9 +53,10 @@ pub fn find_best_match_for_name<'a, T>(iter_names: T,\n     iter_names\n     .filter_map(|&name| {\n         let dist = lev_distance(lookup, &name.as_str());\n-        match dist <= max_dist {    // filter the unwanted cases\n-            true => Some((name, dist)),\n-            false => None,\n+        if dist <= max_dist {    // filter the unwanted cases\n+            Some((name, dist))\n+        } else {\n+            None\n         }\n     })\n     .min_by_key(|&(_, val)| val)    // extract the tuple containing the minimum edit distance"}, {"sha": "8cc37afa354ffbeed217349ae7d96cf01f1f0f28", "filename": "src/libsyntax/util/move_map.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Futil%2Fmove_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Futil%2Fmove_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fmove_map.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -37,10 +37,10 @@ impl<T> MoveMap<T> for Vec<T> {\n                 // move the read_i'th item out of the vector and map it\n                 // to an iterator\n                 let e = ptr::read(self.get_unchecked(read_i));\n-                let mut iter = f(e).into_iter();\n+                let iter = f(e).into_iter();\n                 read_i += 1;\n \n-                while let Some(e) = iter.next() {\n+                for e in iter {\n                     if write_i < read_i {\n                         ptr::write(self.get_unchecked_mut(write_i), e);\n                         write_i += 1;\n@@ -93,10 +93,10 @@ impl<T> MoveMap<T> for SmallVector<T> {\n                 // move the read_i'th item out of the vector and map it\n                 // to an iterator\n                 let e = ptr::read(self.get_unchecked(read_i));\n-                let mut iter = f(e).into_iter();\n+                let iter = f(e).into_iter();\n                 read_i += 1;\n \n-                while let Some(e) = iter.next() {\n+                for e in iter {\n                     if write_i < read_i {\n                         ptr::write(self.get_unchecked_mut(write_i), e);\n                         write_i += 1;"}, {"sha": "0b484a4e0af5b5fa21b17ee21f17a68db79c40d8", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4066c8ec718d8338c2fd6e00cb63e03d3544bcd1/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=4066c8ec718d8338c2fd6e00cb63e03d3544bcd1", "patch": "@@ -345,9 +345,7 @@ pub fn walk_ty<'a, V: Visitor<'a>>(visitor: &mut V, typ: &'a Ty) {\n             visitor.visit_ty(ty);\n             visitor.visit_expr(expression)\n         }\n-        TyKind::TraitObject(ref bounds) => {\n-            walk_list!(visitor, visit_ty_param_bound, bounds);\n-        }\n+        TyKind::TraitObject(ref bounds) |\n         TyKind::ImplTrait(ref bounds) => {\n             walk_list!(visitor, visit_ty_param_bound, bounds);\n         }\n@@ -542,7 +540,7 @@ pub fn walk_fn<'a, V>(visitor: &mut V, kind: FnKind<'a>, declaration: &'a FnDecl\n             walk_fn_decl(visitor, declaration);\n             visitor.visit_block(body);\n         }\n-        FnKind::Method(_, ref sig, _, body) => {\n+        FnKind::Method(_, sig, _, body) => {\n             visitor.visit_generics(&sig.generics);\n             walk_fn_decl(visitor, declaration);\n             visitor.visit_block(body);\n@@ -778,7 +776,7 @@ pub fn walk_expr<'a, V: Visitor<'a>>(visitor: &mut V, expression: &'a Expr) {\n         }\n         ExprKind::InlineAsm(ref ia) => {\n             for &(_, ref input) in &ia.inputs {\n-                visitor.visit_expr(&input)\n+                visitor.visit_expr(input)\n             }\n             for output in &ia.outputs {\n                 visitor.visit_expr(&output.expr)"}]}