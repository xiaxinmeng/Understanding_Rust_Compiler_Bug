{"sha": "3c5f8509581c1a3072496db04a6af32c76d1af61", "node_id": "MDY6Q29tbWl0NzI0NzEyOjNjNWY4NTA5NTgxYzFhMzA3MjQ5NmRiMDRhNmFmMzJjNzZkMWFmNjE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-03-31T04:09:43Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-03-31T04:09:43Z"}, "message": "Auto merge of #49472 - nikomatsakis:nll-optimize-constraint-prop-1, r=pnkfelix\n\noptimize NLL constraint propagation a little\n\nRemoves a bone-headed hot spot in NLL constant propagation; we were re-allocating the stack vector and hashmap as we repeated the DFS. This change shares those resources across each call.\n\nIt also modifies the constraint list to be a linked list; arguably I should revert that, though, as this didn't turn out to be a perf hit and perhaps the old code was clearer? (Still, the new style appeals to me.)\n\nr? @pnkfelix", "tree": {"sha": "9f85ecbcf0f07ef5788d35b54ea31ef4a8fa9b04", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9f85ecbcf0f07ef5788d35b54ea31ef4a8fa9b04"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3c5f8509581c1a3072496db04a6af32c76d1af61", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3c5f8509581c1a3072496db04a6af32c76d1af61", "html_url": "https://github.com/rust-lang/rust/commit/3c5f8509581c1a3072496db04a6af32c76d1af61", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3c5f8509581c1a3072496db04a6af32c76d1af61/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1c5283b47210e51978a32c6e76d0fb71b03e11f4", "url": "https://api.github.com/repos/rust-lang/rust/commits/1c5283b47210e51978a32c6e76d0fb71b03e11f4", "html_url": "https://github.com/rust-lang/rust/commit/1c5283b47210e51978a32c6e76d0fb71b03e11f4"}, {"sha": "ca8176d778cb1b89bf015b032872b6832be0cf8c", "url": "https://api.github.com/repos/rust-lang/rust/commits/ca8176d778cb1b89bf015b032872b6832be0cf8c", "html_url": "https://github.com/rust-lang/rust/commit/ca8176d778cb1b89bf015b032872b6832be0cf8c"}], "stats": {"total": 184, "additions": 136, "deletions": 48}, "files": [{"sha": "4fcd3118f91081db6587ef0e63fd4dbb382c7e02", "filename": "src/librustc_mir/borrow_check/nll/region_infer/dfs.rs", "status": "modified", "additions": 42, "deletions": 20, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fdfs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fdfs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fdfs.rs?ref=3c5f8509581c1a3072496db04a6af32c76d1af61", "patch": "@@ -18,9 +18,26 @@ use borrow_check::nll::region_infer::values::{RegionElementIndex, RegionValueEle\n use syntax::codemap::Span;\n use rustc::mir::{Location, Mir};\n use rustc::ty::RegionVid;\n-use rustc_data_structures::fx::FxHashSet;\n+use rustc_data_structures::bitvec::BitVector;\n+use rustc_data_structures::indexed_vec::Idx;\n+\n+pub(super) struct DfsStorage {\n+    stack: Vec<Location>,\n+    visited: BitVector,\n+}\n \n impl<'tcx> RegionInferenceContext<'tcx> {\n+    /// Creates dfs storage for use by dfs; this should be shared\n+    /// across as many calls to dfs as possible to amortize allocation\n+    /// costs.\n+    pub(super) fn new_dfs_storage(&self) -> DfsStorage {\n+        let num_elements = self.elements.num_elements();\n+        DfsStorage {\n+            stack: vec![],\n+            visited: BitVector::new(num_elements),\n+        }\n+    }\n+\n     /// Function used to satisfy or test a `R1: R2 @ P`\n     /// constraint. The core idea is that it performs a DFS starting\n     /// from `P`. The precise actions *during* that DFS depend on the\n@@ -34,25 +51,29 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n     /// - `Ok(false)` if the walk was completed with no changes;\n     /// - `Err(early)` if the walk was existed early by `op`. `earlyelem` is the\n     ///   value that `op` returned.\n-    pub(super) fn dfs<C>(&self, mir: &Mir<'tcx>, mut op: C) -> Result<bool, C::Early>\n+    #[inline(never)] // ensure dfs is identifiable in profiles\n+    pub(super) fn dfs<C>(\n+        &self,\n+        mir: &Mir<'tcx>,\n+        dfs: &mut DfsStorage,\n+        mut op: C,\n+    ) -> Result<bool, C::Early>\n     where\n         C: DfsOp,\n     {\n         let mut changed = false;\n \n-        let mut stack = vec![];\n-        let mut visited = FxHashSet();\n-\n-        stack.push(op.start_point());\n-        while let Some(p) = stack.pop() {\n+        dfs.visited.clear();\n+        dfs.stack.push(op.start_point());\n+        while let Some(p) = dfs.stack.pop() {\n             let point_index = self.elements.index(p);\n \n             if !op.source_region_contains(point_index) {\n                 debug!(\"            not in from-region\");\n                 continue;\n             }\n \n-            if !visited.insert(p) {\n+            if !dfs.visited.insert(point_index.index()) {\n                 debug!(\"            already visited\");\n                 continue;\n             }\n@@ -62,25 +83,27 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n \n             let block_data = &mir[p.block];\n \n-            let start_stack_len = stack.len();\n+            let start_stack_len = dfs.stack.len();\n \n             if p.statement_index < block_data.statements.len() {\n-                stack.push(Location {\n+                dfs.stack.push(Location {\n                     statement_index: p.statement_index + 1,\n                     ..p\n                 });\n             } else {\n-                stack.extend(block_data.terminator().successors().iter().map(\n-                    |&basic_block| {\n-                        Location {\n+                dfs.stack.extend(\n+                    block_data\n+                        .terminator()\n+                        .successors()\n+                        .iter()\n+                        .map(|&basic_block| Location {\n                             statement_index: 0,\n                             block: basic_block,\n-                        }\n-                    },\n-                ));\n+                        }),\n+                );\n             }\n \n-            if stack.len() == start_stack_len {\n+            if dfs.stack.len() == start_stack_len {\n                 // If we reach the END point in the graph, then copy\n                 // over any skolemized end points in the `from_region`\n                 // and make sure they are included in the `to_region`.\n@@ -229,9 +252,8 @@ impl<'v, 'tcx> DfsOp for TestTargetOutlivesSource<'v, 'tcx> {\n             // `X: ur_in_source`, OK.\n             if self.inferred_values\n                 .universal_regions_outlived_by(self.target_region)\n-                .any(|ur_in_target| {\n-                    self.universal_regions.outlives(ur_in_target, ur_in_source)\n-                }) {\n+                .any(|ur_in_target| self.universal_regions.outlives(ur_in_target, ur_in_source))\n+            {\n                 continue;\n             }\n "}, {"sha": "b0346abee5a5fbe83c67aee6fab39a668ecdb453", "filename": "src/librustc_mir/borrow_check/nll/region_infer/dump_mir.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fdump_mir.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fdump_mir.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fdump_mir.rs?ref=3c5f8509581c1a3072496db04a6af32c76d1af61", "patch": "@@ -84,6 +84,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n                 sub,\n                 point,\n                 span,\n+                next: _,\n             } = constraint;\n             with_msg(&format!(\n                 \"{:?}: {:?} @ {:?} due to {:?}\","}, {"sha": "6c4c02a36a0d73c3e0205145bccf8f0be1820542", "filename": "src/librustc_mir/borrow_check/nll/region_infer/graphviz.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fgraphviz.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fgraphviz.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fgraphviz.rs?ref=3c5f8509581c1a3072496db04a6af32c76d1af61", "patch": "@@ -55,7 +55,7 @@ impl<'this, 'tcx> dot::GraphWalk<'this> for RegionInferenceContext<'tcx> {\n         vids.into_cow()\n     }\n     fn edges(&'this self) -> dot::Edges<'this, Constraint> {\n-        (&self.constraints[..]).into_cow()\n+        (&self.constraints.raw[..]).into_cow()\n     }\n \n     // Render `a: b` as `a <- b`, indicating the flow"}, {"sha": "08391401cc696e45fc0252f5961ecf25a0778267", "filename": "src/librustc_mir/borrow_check/nll/region_infer/mod.rs", "status": "modified", "additions": 92, "deletions": 27, "changes": 119, "blob_url": "https://github.com/rust-lang/rust/blob/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3c5f8509581c1a3072496db04a6af32c76d1af61/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Fmod.rs?ref=3c5f8509581c1a3072496db04a6af32c76d1af61", "patch": "@@ -8,8 +8,6 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::collections::HashMap;\n-\n use super::universal_regions::UniversalRegions;\n use rustc::hir::def_id::DefId;\n use rustc::infer::InferCtxt;\n@@ -23,9 +21,9 @@ use rustc::mir::{ClosureOutlivesRequirement, ClosureOutlivesSubject, ClosureRegi\n                  Local, Location, Mir};\n use rustc::traits::ObligationCause;\n use rustc::ty::{self, RegionVid, Ty, TypeFoldable};\n-use rustc::util::common::ErrorReported;\n+use rustc::util::common::{self, ErrorReported};\n use rustc_data_structures::bitvec::BitVector;\n-use rustc_data_structures::indexed_vec::IndexVec;\n+use rustc_data_structures::indexed_vec::{Idx, IndexVec};\n use std::fmt;\n use std::rc::Rc;\n use syntax::ast;\n@@ -61,8 +59,15 @@ pub struct RegionInferenceContext<'tcx> {\n     /// until `solve` is invoked.\n     inferred_values: Option<RegionValues>,\n \n+    /// For each variable, stores the index of the first constraint\n+    /// where that variable appears on the RHS. This is the start of a\n+    /// 'linked list' threaded by the `next` field in `Constraint`.\n+    ///\n+    /// This map is build when values are inferred.\n+    dependency_map: Option<IndexVec<RegionVid, Option<ConstraintIndex>>>,\n+\n     /// The constraints we have accumulated and used during solving.\n-    constraints: Vec<Constraint>,\n+    constraints: IndexVec<ConstraintIndex, Constraint>,\n \n     /// Type constraints that we check after solving.\n     type_tests: Vec<TypeTest<'tcx>>,\n@@ -143,10 +148,22 @@ pub struct Constraint {\n     /// At this location.\n     point: Location,\n \n+    /// Later on, we thread the constraints onto a linked list\n+    /// grouped by their `sub` field. So if you had:\n+    ///\n+    /// Index | Constraint | Next Field\n+    /// ----- | ---------- | ----------\n+    /// 0     | `'a: 'b`   | Some(2)\n+    /// 1     | `'b: 'c`   | None\n+    /// 2     | `'c: 'b`   | None\n+    next: Option<ConstraintIndex>,\n+\n     /// Where did this constraint arise?\n     span: Span,\n }\n \n+newtype_index!(ConstraintIndex { DEBUG_FORMAT = \"ConstraintIndex({})\" });\n+\n /// A \"type test\" corresponds to an outlives constraint between a type\n /// and a lifetime, like `T: 'x` or `<T as Foo>::Bar: 'x`.  They are\n /// translated from the `Verify` region constraints in the ordinary\n@@ -259,7 +276,8 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             elements: elements.clone(),\n             liveness_constraints: RegionValues::new(elements, num_region_variables),\n             inferred_values: None,\n-            constraints: Vec::new(),\n+            dependency_map: None,\n+            constraints: IndexVec::new(),\n             type_tests: Vec::new(),\n             universal_regions,\n         };\n@@ -387,6 +405,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             sup,\n             sub,\n             point,\n+            next: None,\n         });\n     }\n \n@@ -403,10 +422,25 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         infcx: &InferCtxt<'_, 'gcx, 'tcx>,\n         mir: &Mir<'tcx>,\n         mir_def_id: DefId,\n+    ) -> Option<ClosureRegionRequirements<'gcx>> {\n+        common::time(\n+            infcx.tcx.sess,\n+            &format!(\"solve_nll_region_constraints({:?})\", mir_def_id),\n+            || self.solve_inner(infcx, mir, mir_def_id),\n+        )\n+    }\n+\n+    fn solve_inner<'gcx>(\n+        &mut self,\n+        infcx: &InferCtxt<'_, 'gcx, 'tcx>,\n+        mir: &Mir<'tcx>,\n+        mir_def_id: DefId,\n     ) -> Option<ClosureRegionRequirements<'gcx>> {\n         assert!(self.inferred_values.is_none(), \"values already inferred\");\n \n-        self.propagate_constraints(mir);\n+        let dfs_storage = &mut self.new_dfs_storage();\n+\n+        self.propagate_constraints(mir, dfs_storage);\n \n         // If this is a closure, we can propagate unsatisfied\n         // `outlives_requirements` to our creator, so create a vector\n@@ -419,7 +453,13 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             None\n         };\n \n-        self.check_type_tests(infcx, mir, mir_def_id, outlives_requirements.as_mut());\n+        self.check_type_tests(\n+            infcx,\n+            mir,\n+            dfs_storage,\n+            mir_def_id,\n+            outlives_requirements.as_mut(),\n+        );\n \n         self.check_universal_regions(infcx, mir_def_id, outlives_requirements.as_mut());\n \n@@ -439,20 +479,28 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n     /// Re-execute the region inference, this time tracking causal information.\n     /// This is significantly slower, so it is done only when an error is being reported.\n     pub(super) fn compute_causal_info(&self, mir: &Mir<'tcx>) -> RegionCausalInfo {\n-        let inferred_values = self.compute_region_values(mir, TrackCauses(true));\n+        let dfs_storage = &mut self.new_dfs_storage();\n+        let inferred_values = self.compute_region_values(mir, dfs_storage, TrackCauses(true));\n         RegionCausalInfo { inferred_values }\n     }\n \n     /// Propagate the region constraints: this will grow the values\n     /// for each region variable until all the constraints are\n     /// satisfied. Note that some values may grow **too** large to be\n     /// feasible, but we check this later.\n-    fn propagate_constraints(&mut self, mir: &Mir<'tcx>) {\n-        let inferred_values = self.compute_region_values(mir, TrackCauses(false));\n+    fn propagate_constraints(&mut self, mir: &Mir<'tcx>, dfs_storage: &mut dfs::DfsStorage) {\n+        self.dependency_map = Some(self.build_dependency_map());\n+        let inferred_values = self.compute_region_values(mir, dfs_storage, TrackCauses(false));\n         self.inferred_values = Some(inferred_values);\n     }\n \n-    fn compute_region_values(&self, mir: &Mir<'tcx>, track_causes: TrackCauses) -> RegionValues {\n+    #[inline(never)] // ensure dfs is identifiable in profiles\n+    fn compute_region_values(\n+        &self,\n+        mir: &Mir<'tcx>,\n+        dfs_storage: &mut dfs::DfsStorage,\n+        track_causes: TrackCauses,\n+    ) -> RegionValues {\n         debug!(\"compute_region_values()\");\n         debug!(\"compute_region_values: constraints={:#?}\", {\n             let mut constraints: Vec<_> = self.constraints.iter().collect();\n@@ -464,17 +512,17 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         // constraints we have accumulated.\n         let mut inferred_values = self.liveness_constraints.duplicate(track_causes);\n \n-        let dependency_map = self.build_dependency_map();\n+        let dependency_map = self.dependency_map.as_ref().unwrap();\n \n         // Constraints that may need to be repropagated (initially all):\n-        let mut dirty_list: Vec<_> = (0..self.constraints.len()).collect();\n+        let mut dirty_list: Vec<_> = self.constraints.indices().collect();\n \n         // Set to 0 for each constraint that is on the dirty list:\n         let mut clean_bit_vec = BitVector::new(dirty_list.len());\n \n         debug!(\"propagate_constraints: --------------------\");\n         while let Some(constraint_idx) = dirty_list.pop() {\n-            clean_bit_vec.insert(constraint_idx);\n+            clean_bit_vec.insert(constraint_idx.index());\n \n             let constraint = &self.constraints[constraint_idx];\n             debug!(\"propagate_constraints: constraint={:?}\", constraint);\n@@ -483,6 +531,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             // outlives constraint.\n             let Ok(made_changes) = self.dfs(\n                 mir,\n+                dfs_storage,\n                 CopyFromSourceToTarget {\n                     source_region: constraint.sub,\n                     target_region: constraint.sup,\n@@ -496,10 +545,12 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n                 debug!(\"propagate_constraints:   sub={:?}\", constraint.sub);\n                 debug!(\"propagate_constraints:   sup={:?}\", constraint.sup);\n \n-                for &dep_idx in dependency_map.get(&constraint.sup).unwrap_or(&vec![]) {\n-                    if clean_bit_vec.remove(dep_idx) {\n+                let mut opt_dep_idx = dependency_map[constraint.sup];\n+                while let Some(dep_idx) = opt_dep_idx {\n+                    if clean_bit_vec.remove(dep_idx.index()) {\n                         dirty_list.push(dep_idx);\n                     }\n+                    opt_dep_idx = self.constraints[dep_idx].next;\n                 }\n             }\n \n@@ -513,11 +564,15 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n     /// indices of constraints that need to be re-evaluated when X changes.\n     /// These are constraints like Y: X @ P -- so if X changed, we may\n     /// need to grow Y.\n-    fn build_dependency_map(&self) -> HashMap<RegionVid, Vec<usize>> {\n-        let mut map = HashMap::new();\n-\n-        for (idx, constraint) in self.constraints.iter().enumerate() {\n-            map.entry(constraint.sub).or_insert(Vec::new()).push(idx);\n+    #[inline(never)] // ensure dfs is identifiable in profiles\n+    fn build_dependency_map(&mut self) -> IndexVec<RegionVid, Option<ConstraintIndex>> {\n+        let mut map = IndexVec::from_elem(None, &self.definitions);\n+\n+        for (idx, constraint) in self.constraints.iter_enumerated_mut().rev() {\n+            let mut head = &mut map[constraint.sub];\n+            debug_assert!(constraint.next.is_none());\n+            constraint.next = *head;\n+            *head = Some(idx);\n         }\n \n         map\n@@ -531,6 +586,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         &self,\n         infcx: &InferCtxt<'_, 'gcx, 'tcx>,\n         mir: &Mir<'tcx>,\n+        dfs_storage: &mut dfs::DfsStorage,\n         mir_def_id: DefId,\n         mut propagated_outlives_requirements: Option<&mut Vec<ClosureOutlivesRequirement<'gcx>>>,\n     ) {\n@@ -539,7 +595,13 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         for type_test in &self.type_tests {\n             debug!(\"check_type_test: {:?}\", type_test);\n \n-            if self.eval_region_test(mir, type_test.point, type_test.lower_bound, &type_test.test) {\n+            if self.eval_region_test(\n+                mir,\n+                dfs_storage,\n+                type_test.point,\n+                type_test.lower_bound,\n+                &type_test.test,\n+            ) {\n                 continue;\n             }\n \n@@ -796,6 +858,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n     fn eval_region_test(\n         &self,\n         mir: &Mir<'tcx>,\n+        dfs_storage: &mut dfs::DfsStorage,\n         point: Location,\n         lower_bound: RegionVid,\n         test: &RegionTest,\n@@ -808,26 +871,27 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         match test {\n             RegionTest::IsOutlivedByAllRegionsIn(regions) => regions\n                 .iter()\n-                .all(|&r| self.eval_outlives(mir, r, lower_bound, point)),\n+                .all(|&r| self.eval_outlives(mir, dfs_storage, r, lower_bound, point)),\n \n             RegionTest::IsOutlivedByAnyRegionIn(regions) => regions\n                 .iter()\n-                .any(|&r| self.eval_outlives(mir, r, lower_bound, point)),\n+                .any(|&r| self.eval_outlives(mir, dfs_storage, r, lower_bound, point)),\n \n             RegionTest::Any(tests) => tests\n                 .iter()\n-                .any(|test| self.eval_region_test(mir, point, lower_bound, test)),\n+                .any(|test| self.eval_region_test(mir, dfs_storage, point, lower_bound, test)),\n \n             RegionTest::All(tests) => tests\n                 .iter()\n-                .all(|test| self.eval_region_test(mir, point, lower_bound, test)),\n+                .all(|test| self.eval_region_test(mir, dfs_storage, point, lower_bound, test)),\n         }\n     }\n \n     // Evaluate whether `sup_region: sub_region @ point`.\n     fn eval_outlives(\n         &self,\n         mir: &Mir<'tcx>,\n+        dfs_storage: &mut dfs::DfsStorage,\n         sup_region: RegionVid,\n         sub_region: RegionVid,\n         point: Location,\n@@ -843,6 +907,7 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n         // yield an `Err` result.\n         match self.dfs(\n             mir,\n+            dfs_storage,\n             TestTargetOutlivesSource {\n                 source_region: sub_region,\n                 target_region: sup_region,"}]}