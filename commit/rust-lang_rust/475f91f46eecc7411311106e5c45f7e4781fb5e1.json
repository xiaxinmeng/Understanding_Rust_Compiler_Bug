{"sha": "475f91f46eecc7411311106e5c45f7e4781fb5e1", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ3NWY5MWY0NmVlY2M3NDExMzExMTA2ZTVjNDVmN2U0NzgxZmI1ZTE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-11-06T21:11:06Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-11-06T21:11:06Z"}, "message": "Auto merge of #29582 - oli-obk:token_tree, r=sfackler", "tree": {"sha": "5e04ceda74d38896d4d2a5a926c6c954d612146b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5e04ceda74d38896d4d2a5a926c6c954d612146b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/475f91f46eecc7411311106e5c45f7e4781fb5e1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/475f91f46eecc7411311106e5c45f7e4781fb5e1", "html_url": "https://github.com/rust-lang/rust/commit/475f91f46eecc7411311106e5c45f7e4781fb5e1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/475f91f46eecc7411311106e5c45f7e4781fb5e1/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b14dc5bc1c4a9a652364235822505d28ec25950a", "url": "https://api.github.com/repos/rust-lang/rust/commits/b14dc5bc1c4a9a652364235822505d28ec25950a", "html_url": "https://github.com/rust-lang/rust/commit/b14dc5bc1c4a9a652364235822505d28ec25950a"}, {"sha": "fcc706790457e26bfa43377a0525bbc87cb0f3d1", "url": "https://api.github.com/repos/rust-lang/rust/commits/fcc706790457e26bfa43377a0525bbc87cb0f3d1", "html_url": "https://github.com/rust-lang/rust/commit/fcc706790457e26bfa43377a0525bbc87cb0f3d1"}], "stats": {"total": 428, "additions": 219, "deletions": 209}, "files": [{"sha": "42dfaa1a8090aaa214d0702214687ab85d586285", "filename": "src/doc/trpl/compiler-plugins.md", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Fdoc%2Ftrpl%2Fcompiler-plugins.md", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Fdoc%2Ftrpl%2Fcompiler-plugins.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftrpl%2Fcompiler-plugins.md?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -46,7 +46,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token;\n-use syntax::ast::{TokenTree, TtToken};\n+use syntax::ast::TokenTree;\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n use syntax::ext::build::AstBuilder;  // trait for expr_usize\n use rustc::plugin::Registry;\n@@ -61,7 +61,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TtToken(_, token::Ident(s, _))] => s.to_string(),\n+        [TokenTree::Token(_, token::Ident(s, _))] => s.to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}, {"sha": "8c9c883508703089eb2bf3c96beba6dc9113c15f", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 33, "deletions": 34, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -36,7 +36,6 @@ pub use self::Sign::*;\n pub use self::Stmt_::*;\n pub use self::StrStyle::*;\n pub use self::StructFieldKind::*;\n-pub use self::TokenTree::*;\n pub use self::TraitItem_::*;\n pub use self::Ty_::*;\n pub use self::TyParamBound::*;\n@@ -954,12 +953,12 @@ impl Delimited {\n \n     /// Returns the opening delimiter as a token tree.\n     pub fn open_tt(&self) -> TokenTree {\n-        TtToken(self.open_span, self.open_token())\n+        TokenTree::Token(self.open_span, self.open_token())\n     }\n \n     /// Returns the closing delimiter as a token tree.\n     pub fn close_tt(&self) -> TokenTree {\n-        TtToken(self.close_span, self.close_token())\n+        TokenTree::Token(self.close_span, self.close_token())\n     }\n }\n \n@@ -999,61 +998,61 @@ pub enum KleeneOp {\n #[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n pub enum TokenTree {\n     /// A single token\n-    TtToken(Span, token::Token),\n+    Token(Span, token::Token),\n     /// A delimited sequence of token trees\n-    TtDelimited(Span, Rc<Delimited>),\n+    Delimited(Span, Rc<Delimited>),\n \n     // This only makes sense in MBE macros.\n \n     /// A kleene-style repetition sequence with a span\n     // FIXME(eddyb) #12938 Use DST.\n-    TtSequence(Span, Rc<SequenceRepetition>),\n+    Sequence(Span, Rc<SequenceRepetition>),\n }\n \n impl TokenTree {\n     pub fn len(&self) -> usize {\n         match *self {\n-            TtToken(_, token::DocComment(name)) => {\n+            TokenTree::Token(_, token::DocComment(name)) => {\n                 match doc_comment_style(&name.as_str()) {\n                     AttrStyle::Outer => 2,\n                     AttrStyle::Inner => 3\n                 }\n             }\n-            TtToken(_, token::SpecialVarNt(..)) => 2,\n-            TtToken(_, token::MatchNt(..)) => 3,\n-            TtDelimited(_, ref delimed) => {\n+            TokenTree::Token(_, token::SpecialVarNt(..)) => 2,\n+            TokenTree::Token(_, token::MatchNt(..)) => 3,\n+            TokenTree::Delimited(_, ref delimed) => {\n                 delimed.tts.len() + 2\n             }\n-            TtSequence(_, ref seq) => {\n+            TokenTree::Sequence(_, ref seq) => {\n                 seq.tts.len()\n             }\n-            TtToken(..) => 0\n+            TokenTree::Token(..) => 0\n         }\n     }\n \n     pub fn get_tt(&self, index: usize) -> TokenTree {\n         match (self, index) {\n-            (&TtToken(sp, token::DocComment(_)), 0) => {\n-                TtToken(sp, token::Pound)\n+            (&TokenTree::Token(sp, token::DocComment(_)), 0) => {\n+                TokenTree::Token(sp, token::Pound)\n             }\n-            (&TtToken(sp, token::DocComment(name)), 1)\n+            (&TokenTree::Token(sp, token::DocComment(name)), 1)\n             if doc_comment_style(&name.as_str()) == AttrStyle::Inner => {\n-                TtToken(sp, token::Not)\n+                TokenTree::Token(sp, token::Not)\n             }\n-            (&TtToken(sp, token::DocComment(name)), _) => {\n+            (&TokenTree::Token(sp, token::DocComment(name)), _) => {\n                 let stripped = strip_doc_comment_decoration(&name.as_str());\n-                TtDelimited(sp, Rc::new(Delimited {\n+                TokenTree::Delimited(sp, Rc::new(Delimited {\n                     delim: token::Bracket,\n                     open_span: sp,\n-                    tts: vec![TtToken(sp, token::Ident(token::str_to_ident(\"doc\"),\n-                                                       token::Plain)),\n-                              TtToken(sp, token::Eq),\n-                              TtToken(sp, token::Literal(\n+                    tts: vec![TokenTree::Token(sp, token::Ident(token::str_to_ident(\"doc\"),\n+                                                                token::Plain)),\n+                              TokenTree::Token(sp, token::Eq),\n+                              TokenTree::Token(sp, token::Literal(\n                                   token::StrRaw(token::intern(&stripped), 0), None))],\n                     close_span: sp,\n                 }))\n             }\n-            (&TtDelimited(_, ref delimed), _) => {\n+            (&TokenTree::Delimited(_, ref delimed), _) => {\n                 if index == 0 {\n                     return delimed.open_tt();\n                 }\n@@ -1062,19 +1061,19 @@ impl TokenTree {\n                 }\n                 delimed.tts[index - 1].clone()\n             }\n-            (&TtToken(sp, token::SpecialVarNt(var)), _) => {\n-                let v = [TtToken(sp, token::Dollar),\n-                         TtToken(sp, token::Ident(token::str_to_ident(var.as_str()),\n+            (&TokenTree::Token(sp, token::SpecialVarNt(var)), _) => {\n+                let v = [TokenTree::Token(sp, token::Dollar),\n+                         TokenTree::Token(sp, token::Ident(token::str_to_ident(var.as_str()),\n                                                   token::Plain))];\n                 v[index].clone()\n             }\n-            (&TtToken(sp, token::MatchNt(name, kind, name_st, kind_st)), _) => {\n-                let v = [TtToken(sp, token::SubstNt(name, name_st)),\n-                         TtToken(sp, token::Colon),\n-                         TtToken(sp, token::Ident(kind, kind_st))];\n+            (&TokenTree::Token(sp, token::MatchNt(name, kind, name_st, kind_st)), _) => {\n+                let v = [TokenTree::Token(sp, token::SubstNt(name, name_st)),\n+                         TokenTree::Token(sp, token::Colon),\n+                         TokenTree::Token(sp, token::Ident(kind, kind_st))];\n                 v[index].clone()\n             }\n-            (&TtSequence(_, ref seq), _) => {\n+            (&TokenTree::Sequence(_, ref seq), _) => {\n                 seq.tts[index].clone()\n             }\n             _ => panic!(\"Cannot expand a token tree\")\n@@ -1084,9 +1083,9 @@ impl TokenTree {\n     /// Returns the `Span` corresponding to this token tree.\n     pub fn get_span(&self) -> Span {\n         match *self {\n-            TtToken(span, _)     => span,\n-            TtDelimited(span, _) => span,\n-            TtSequence(span, _)  => span,\n+            TokenTree::Token(span, _)     => span,\n+            TokenTree::Delimited(span, _) => span,\n+            TokenTree::Sequence(span, _)  => span,\n         }\n     }\n "}, {"sha": "be0d5729c7009fe738158e39765379f73e6c46f1", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -54,7 +54,7 @@ pub fn expand_diagnostic_used<'cx>(ecx: &'cx mut ExtCtxt,\n                                    token_tree: &[TokenTree])\n                                    -> Box<MacResult+'cx> {\n     let code = match (token_tree.len(), token_tree.get(0)) {\n-        (1, Some(&ast::TtToken(_, token::Ident(code, _)))) => code,\n+        (1, Some(&TokenTree::Token(_, token::Ident(code, _)))) => code,\n         _ => unreachable!()\n     };\n \n@@ -92,12 +92,12 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n         token_tree.get(1),\n         token_tree.get(2)\n     ) {\n-        (1, Some(&ast::TtToken(_, token::Ident(ref code, _))), None, None) => {\n+        (1, Some(&TokenTree::Token(_, token::Ident(ref code, _))), None, None) => {\n             (code, None)\n         },\n-        (3, Some(&ast::TtToken(_, token::Ident(ref code, _))),\n-            Some(&ast::TtToken(_, token::Comma)),\n-            Some(&ast::TtToken(_, token::Literal(token::StrRaw(description, _), None)))) => {\n+        (3, Some(&TokenTree::Token(_, token::Ident(ref code, _))),\n+            Some(&TokenTree::Token(_, token::Comma)),\n+            Some(&TokenTree::Token(_, token::Literal(token::StrRaw(description, _), None)))) => {\n             (code, Some(description))\n         }\n         _ => unreachable!()\n@@ -160,9 +160,9 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n     let (crate_name, name) = match (&token_tree[0], &token_tree[2]) {\n         (\n             // Crate name.\n-            &ast::TtToken(_, token::Ident(ref crate_name, _)),\n+            &TokenTree::Token(_, token::Ident(ref crate_name, _)),\n             // DIAGNOSTICS ident.\n-            &ast::TtToken(_, token::Ident(ref name, _))\n+            &TokenTree::Token(_, token::Ident(ref name, _))\n         ) => (*&crate_name, name),\n         _ => unreachable!()\n     };"}, {"sha": "e9e36546ad6db6c7ff035ad2de9f4f06b09b5560", "filename": "src/libsyntax/ext/concat_idents.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fconcat_idents.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast;\n+use ast::{self, TokenTree};\n use codemap::Span;\n use ext::base::*;\n use ext::base;\n@@ -17,7 +17,7 @@ use parse::token;\n use parse::token::str_to_ident;\n use ptr::P;\n \n-pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[TokenTree])\n                               -> Box<base::MacResult+'cx> {\n     if !cx.ecfg.enable_concat_idents() {\n         feature_gate::emit_feature_err(&cx.parse_sess.span_diagnostic,\n@@ -32,15 +32,15 @@ pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]\n     for (i, e) in tts.iter().enumerate() {\n         if i & 1 == 1 {\n             match *e {\n-                ast::TtToken(_, token::Comma) => {},\n+                TokenTree::Token(_, token::Comma) => {},\n                 _ => {\n                     cx.span_err(sp, \"concat_idents! expecting comma.\");\n                     return DummyResult::expr(sp);\n                 },\n             }\n         } else {\n             match *e {\n-                ast::TtToken(_, token::Ident(ident, _)) => {\n+                TokenTree::Token(_, token::Ident(ident, _)) => {\n                     res_str.push_str(&ident.name.as_str())\n                 },\n                 _ => {"}, {"sha": "5e1d233916419d7d9eb3812c1471ab21777654f1", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 53, "deletions": 46, "changes": 99, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast;\n+use ast::{self, TokenTree};\n use codemap::Span;\n use ext::base::ExtCtxt;\n use ext::base;\n@@ -71,67 +71,69 @@ pub mod rt {\n \n     impl ToTokens for ast::Ident {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(DUMMY_SP, token::Ident(*self, token::Plain))]\n+            vec![TokenTree::Token(DUMMY_SP, token::Ident(*self, token::Plain))]\n         }\n     }\n \n     impl ToTokens for ast::Path {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtPath(Box::new(self.clone()))))]\n+            vec![TokenTree::Token(DUMMY_SP,\n+                                  token::Interpolated(token::NtPath(Box::new(self.clone()))))]\n         }\n     }\n \n     impl ToTokens for ast::Ty {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtTy(P(self.clone()))))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtTy(P(self.clone()))))]\n         }\n     }\n \n     impl ToTokens for ast::Block {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtBlock(P(self.clone()))))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtBlock(P(self.clone()))))]\n         }\n     }\n \n     impl ToTokens for ast::Generics {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtGenerics(self.clone())))]\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtGenerics(self.clone())))]\n         }\n     }\n \n     impl ToTokens for ast::WhereClause {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtWhereClause(self.clone())))]\n+            vec![TokenTree::Token(DUMMY_SP,\n+                                  token::Interpolated(token::NtWhereClause(self.clone())))]\n         }\n     }\n \n     impl ToTokens for P<ast::Item> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtItem(self.clone())))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtItem(self.clone())))]\n         }\n     }\n \n     impl ToTokens for P<ast::ImplItem> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtImplItem(self.clone())))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtImplItem(self.clone())))]\n         }\n     }\n \n     impl ToTokens for P<ast::TraitItem> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtTraitItem(self.clone())))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtTraitItem(self.clone())))]\n         }\n     }\n \n     impl ToTokens for P<ast::Stmt> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let mut tts = vec![\n-                ast::TtToken(self.span, token::Interpolated(token::NtStmt(self.clone())))\n+                TokenTree::Token(self.span, token::Interpolated(token::NtStmt(self.clone())))\n             ];\n \n             // Some statements require a trailing semicolon.\n             if classify::stmt_ends_with_semi(&self.node) {\n-                tts.push(ast::TtToken(self.span, token::Semi));\n+                tts.push(TokenTree::Token(self.span, token::Semi));\n             }\n \n             tts\n@@ -140,19 +142,19 @@ pub mod rt {\n \n     impl ToTokens for P<ast::Expr> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtExpr(self.clone())))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtExpr(self.clone())))]\n         }\n     }\n \n     impl ToTokens for P<ast::Pat> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(self.span, token::Interpolated(token::NtPat(self.clone())))]\n+            vec![TokenTree::Token(self.span, token::Interpolated(token::NtPat(self.clone())))]\n         }\n     }\n \n     impl ToTokens for ast::Arm {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtArm(self.clone())))]\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtArm(self.clone())))]\n         }\n     }\n \n@@ -173,24 +175,24 @@ pub mod rt {\n         };\n     }\n \n-    impl_to_tokens_slice! { ast::Ty, [ast::TtToken(DUMMY_SP, token::Comma)] }\n+    impl_to_tokens_slice! { ast::Ty, [TokenTree::Token(DUMMY_SP, token::Comma)] }\n     impl_to_tokens_slice! { P<ast::Item>, [] }\n \n     impl ToTokens for P<ast::MetaItem> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtMeta(self.clone())))]\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtMeta(self.clone())))]\n         }\n     }\n \n     impl ToTokens for ast::Attribute {\n         fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n             let mut r = vec![];\n             // FIXME: The spans could be better\n-            r.push(ast::TtToken(self.span, token::Pound));\n+            r.push(TokenTree::Token(self.span, token::Pound));\n             if self.node.style == ast::AttrStyle::Inner {\n-                r.push(ast::TtToken(self.span, token::Not));\n+                r.push(TokenTree::Token(self.span, token::Not));\n             }\n-            r.push(ast::TtDelimited(self.span, Rc::new(ast::Delimited {\n+            r.push(TokenTree::Delimited(self.span, Rc::new(ast::Delimited {\n                 delim: token::Bracket,\n                 open_span: self.span,\n                 tts: self.node.value.to_tokens(cx),\n@@ -210,7 +212,7 @@ pub mod rt {\n \n     impl ToTokens for () {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![ast::TtDelimited(DUMMY_SP, Rc::new(ast::Delimited {\n+            vec![TokenTree::Delimited(DUMMY_SP, Rc::new(ast::Delimited {\n                 delim: token::Paren,\n                 open_span: DUMMY_SP,\n                 tts: vec![],\n@@ -278,7 +280,7 @@ pub mod rt {\n         fn parse_item(&self, s: String) -> P<ast::Item>;\n         fn parse_expr(&self, s: String) -> P<ast::Expr>;\n         fn parse_stmt(&self, s: String) -> P<ast::Stmt>;\n-        fn parse_tts(&self, s: String) -> Vec<ast::TokenTree>;\n+        fn parse_tts(&self, s: String) -> Vec<TokenTree>;\n     }\n \n     impl<'a> ExtParseUtils for ExtCtxt<'a> {\n@@ -305,7 +307,7 @@ pub mod rt {\n                                               self.parse_sess())\n         }\n \n-        fn parse_tts(&self, s: String) -> Vec<ast::TokenTree> {\n+        fn parse_tts(&self, s: String) -> Vec<TokenTree> {\n             parse::parse_tts_from_source_str(\"<quote expansion>\".to_string(),\n                                              s,\n                                              self.cfg(),\n@@ -316,7 +318,7 @@ pub mod rt {\n \n pub fn expand_quote_tokens<'cx>(cx: &'cx mut ExtCtxt,\n                                 sp: Span,\n-                                tts: &[ast::TokenTree])\n+                                tts: &[TokenTree])\n                                 -> Box<base::MacResult+'cx> {\n     let (cx_expr, expr) = expand_tts(cx, sp, tts);\n     let expanded = expand_wrapper(cx, sp, cx_expr, expr, &[&[\"syntax\", \"ext\", \"quote\", \"rt\"]]);\n@@ -325,55 +327,55 @@ pub fn expand_quote_tokens<'cx>(cx: &'cx mut ExtCtxt,\n \n pub fn expand_quote_expr<'cx>(cx: &'cx mut ExtCtxt,\n                               sp: Span,\n-                              tts: &[ast::TokenTree])\n+                              tts: &[TokenTree])\n                               -> Box<base::MacResult+'cx> {\n     let expanded = expand_parse_call(cx, sp, \"parse_expr_panic\", vec!(), tts);\n     base::MacEager::expr(expanded)\n }\n \n pub fn expand_quote_item<'cx>(cx: &mut ExtCtxt,\n                               sp: Span,\n-                              tts: &[ast::TokenTree])\n+                              tts: &[TokenTree])\n                               -> Box<base::MacResult+'cx> {\n     let expanded = expand_parse_call(cx, sp, \"parse_item_panic\", vec!(), tts);\n     base::MacEager::expr(expanded)\n }\n \n pub fn expand_quote_pat<'cx>(cx: &'cx mut ExtCtxt,\n                              sp: Span,\n-                             tts: &[ast::TokenTree])\n+                             tts: &[TokenTree])\n                              -> Box<base::MacResult+'cx> {\n     let expanded = expand_parse_call(cx, sp, \"parse_pat_panic\", vec!(), tts);\n     base::MacEager::expr(expanded)\n }\n \n pub fn expand_quote_arm(cx: &mut ExtCtxt,\n                         sp: Span,\n-                        tts: &[ast::TokenTree])\n+                        tts: &[TokenTree])\n                         -> Box<base::MacResult+'static> {\n     let expanded = expand_parse_call(cx, sp, \"parse_arm_panic\", vec!(), tts);\n     base::MacEager::expr(expanded)\n }\n \n pub fn expand_quote_ty(cx: &mut ExtCtxt,\n                        sp: Span,\n-                       tts: &[ast::TokenTree])\n+                       tts: &[TokenTree])\n                        -> Box<base::MacResult+'static> {\n     let expanded = expand_parse_call(cx, sp, \"parse_ty_panic\", vec!(), tts);\n     base::MacEager::expr(expanded)\n }\n \n pub fn expand_quote_stmt(cx: &mut ExtCtxt,\n                          sp: Span,\n-                         tts: &[ast::TokenTree])\n+                         tts: &[TokenTree])\n                          -> Box<base::MacResult+'static> {\n     let expanded = expand_parse_call(cx, sp, \"parse_stmt_panic\", vec!(), tts);\n     base::MacEager::expr(expanded)\n }\n \n pub fn expand_quote_attr(cx: &mut ExtCtxt,\n                          sp: Span,\n-                         tts: &[ast::TokenTree])\n+                         tts: &[TokenTree])\n                          -> Box<base::MacResult+'static> {\n     let expanded = expand_parse_call(cx, sp, \"parse_attribute_panic\",\n                                     vec!(cx.expr_bool(sp, true)), tts);\n@@ -383,7 +385,7 @@ pub fn expand_quote_attr(cx: &mut ExtCtxt,\n \n pub fn expand_quote_matcher(cx: &mut ExtCtxt,\n                             sp: Span,\n-                            tts: &[ast::TokenTree])\n+                            tts: &[TokenTree])\n                             -> Box<base::MacResult+'static> {\n     let (cx_expr, tts) = parse_arguments_to_quote(cx, tts);\n     let mut vector = mk_stmts_let(cx, sp);\n@@ -423,6 +425,11 @@ fn mk_name(cx: &ExtCtxt, sp: Span, ident: ast::Ident) -> P<ast::Expr> {\n                         vec!(e_str))\n }\n \n+fn mk_tt_path(cx: &ExtCtxt, sp: Span, name: &str) -> P<ast::Expr> {\n+    let idents = vec!(id_ext(\"syntax\"), id_ext(\"ast\"), id_ext(\"TokenTree\"), id_ext(name));\n+    cx.expr_path(cx.path_global(sp, idents))\n+}\n+\n fn mk_ast_path(cx: &ExtCtxt, sp: Span, name: &str) -> P<ast::Expr> {\n     let idents = vec!(id_ext(\"syntax\"), id_ext(\"ast\"), id_ext(name));\n     cx.expr_path(cx.path_global(sp, idents))\n@@ -591,9 +598,9 @@ fn expr_mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n     mk_token_path(cx, sp, name)\n }\n \n-fn statements_mk_tt(cx: &ExtCtxt, tt: &ast::TokenTree, matcher: bool) -> Vec<P<ast::Stmt>> {\n+fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, matcher: bool) -> Vec<P<ast::Stmt>> {\n     match *tt {\n-        ast::TtToken(sp, SubstNt(ident, _)) => {\n+        TokenTree::Token(sp, SubstNt(ident, _)) => {\n             // tt.extend($ident.to_tokens(ext_cx))\n \n             let e_to_toks =\n@@ -612,17 +619,17 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &ast::TokenTree, matcher: bool) -> Vec<P<a\n \n             vec!(cx.stmt_expr(e_push))\n         }\n-        ref tt @ ast::TtToken(_, MatchNt(..)) if !matcher => {\n+        ref tt @ TokenTree::Token(_, MatchNt(..)) if !matcher => {\n             let mut seq = vec![];\n             for i in 0..tt.len() {\n                 seq.push(tt.get_tt(i));\n             }\n             statements_mk_tts(cx, &seq[..], matcher)\n         }\n-        ast::TtToken(sp, ref tok) => {\n+        TokenTree::Token(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n             let e_tok = cx.expr_call(sp,\n-                                     mk_ast_path(cx, sp, \"TtToken\"),\n+                                     mk_tt_path(cx, sp, \"Token\"),\n                                      vec!(e_sp, expr_mk_token(cx, sp, tok)));\n             let e_push =\n                 cx.expr_method_call(sp,\n@@ -631,16 +638,16 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &ast::TokenTree, matcher: bool) -> Vec<P<a\n                                     vec!(e_tok));\n             vec!(cx.stmt_expr(e_push))\n         },\n-        ast::TtDelimited(_, ref delimed) => {\n+        TokenTree::Delimited(_, ref delimed) => {\n             statements_mk_tt(cx, &delimed.open_tt(), matcher).into_iter()\n                 .chain(delimed.tts.iter()\n                                   .flat_map(|tt| statements_mk_tt(cx, tt, matcher)))\n                 .chain(statements_mk_tt(cx, &delimed.close_tt(), matcher))\n                 .collect()\n         },\n-        ast::TtSequence(sp, ref seq) => {\n+        TokenTree::Sequence(sp, ref seq) => {\n             if !matcher {\n-                panic!(\"TtSequence in quote!\");\n+                panic!(\"TokenTree::Sequence in quote!\");\n             }\n \n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n@@ -671,7 +678,7 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &ast::TokenTree, matcher: bool) -> Vec<P<a\n                                                         id_ext(\"new\")],\n                                                    vec![e_seq_struct]);\n             let e_tok = cx.expr_call(sp,\n-                                     mk_ast_path(cx, sp, \"TtSequence\"),\n+                                     mk_tt_path(cx, sp, \"Sequence\"),\n                                      vec!(e_sp, e_rc_new));\n             let e_push =\n                 cx.expr_method_call(sp,\n@@ -683,8 +690,8 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &ast::TokenTree, matcher: bool) -> Vec<P<a\n     }\n }\n \n-fn parse_arguments_to_quote(cx: &ExtCtxt, tts: &[ast::TokenTree])\n-                            -> (P<ast::Expr>, Vec<ast::TokenTree>) {\n+fn parse_arguments_to_quote(cx: &ExtCtxt, tts: &[TokenTree])\n+                            -> (P<ast::Expr>, Vec<TokenTree>) {\n     // NB: It appears that the main parser loses its mind if we consider\n     // $foo as a SubstNt during the main parse, so we have to re-parse\n     // under quote_depth > 0. This is silly and should go away; the _guess_ is\n@@ -746,15 +753,15 @@ fn mk_stmts_let(cx: &ExtCtxt, sp: Span) -> Vec<P<ast::Stmt>> {\n     vec!(stmt_let_sp, stmt_let_tt)\n }\n \n-fn statements_mk_tts(cx: &ExtCtxt, tts: &[ast::TokenTree], matcher: bool) -> Vec<P<ast::Stmt>> {\n+fn statements_mk_tts(cx: &ExtCtxt, tts: &[TokenTree], matcher: bool) -> Vec<P<ast::Stmt>> {\n     let mut ss = Vec::new();\n     for tt in tts {\n         ss.extend(statements_mk_tt(cx, tt, matcher));\n     }\n     ss\n }\n \n-fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[TokenTree])\n               -> (P<ast::Expr>, P<ast::Expr>) {\n     let (cx_expr, tts) = parse_arguments_to_quote(cx, tts);\n \n@@ -790,7 +797,7 @@ fn expand_parse_call(cx: &ExtCtxt,\n                      sp: Span,\n                      parse_method: &str,\n                      arg_exprs: Vec<P<ast::Expr>> ,\n-                     tts: &[ast::TokenTree]) -> P<ast::Expr> {\n+                     tts: &[TokenTree]) -> P<ast::Expr> {\n     let (cx_expr, tts_expr) = expand_tts(cx, sp, tts);\n \n     let cfg_call = || cx.expr_method_call("}, {"sha": "628b88d13537aaf54f93800e99237ecf35c0894b", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast;\n+use ast::TokenTree;\n use codemap::Span;\n use ext::base::ExtCtxt;\n use ext::base;\n@@ -18,7 +18,7 @@ use parse::token::keywords;\n \n pub fn expand_trace_macros(cx: &mut ExtCtxt,\n                            sp: Span,\n-                           tt: &[ast::TokenTree])\n+                           tt: &[TokenTree])\n                            -> Box<base::MacResult+'static> {\n     if !cx.ecfg.enable_trace_macros() {\n         feature_gate::emit_feature_err(&cx.parse_sess.span_diagnostic,\n@@ -30,10 +30,10 @@ pub fn expand_trace_macros(cx: &mut ExtCtxt,\n     }\n \n     match (tt.len(), tt.first()) {\n-        (1, Some(&ast::TtToken(_, ref tok))) if tok.is_keyword(keywords::True) => {\n+        (1, Some(&TokenTree::Token(_, ref tok))) if tok.is_keyword(keywords::True) => {\n             cx.set_trace_macros(true);\n         }\n-        (1, Some(&ast::TtToken(_, ref tok))) if tok.is_keyword(keywords::False) => {\n+        (1, Some(&TokenTree::Token(_, ref tok))) if tok.is_keyword(keywords::False) => {\n             cx.set_trace_macros(false);\n         }\n         _ => cx.span_err(sp, \"trace_macros! accepts only `true` or `false`\"),"}, {"sha": "0e69edd7ad14e183bbe6786eb7daac562b5bcf0f", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 17, "deletions": 18, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -80,7 +80,6 @@ use self::TokenTreeOrTokenTreeVec::*;\n \n use ast;\n use ast::{TokenTree, Name};\n-use ast::{TtDelimited, TtSequence, TtToken};\n use codemap::{BytePos, mk_sp, Span};\n use codemap;\n use parse::lexer::*; //resolve bug?\n@@ -146,16 +145,16 @@ pub struct MatcherPos {\n pub fn count_names(ms: &[TokenTree]) -> usize {\n     ms.iter().fold(0, |count, elt| {\n         count + match elt {\n-            &TtSequence(_, ref seq) => {\n+            &TokenTree::Sequence(_, ref seq) => {\n                 seq.num_captures\n             }\n-            &TtDelimited(_, ref delim) => {\n+            &TokenTree::Delimited(_, ref delim) => {\n                 count_names(&delim.tts)\n             }\n-            &TtToken(_, MatchNt(..)) => {\n+            &TokenTree::Token(_, MatchNt(..)) => {\n                 1\n             }\n-            &TtToken(_, _) => 0,\n+            &TokenTree::Token(_, _) => 0,\n         }\n     })\n }\n@@ -205,17 +204,17 @@ pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n     fn n_rec(p_s: &ParseSess, m: &TokenTree, res: &[Rc<NamedMatch>],\n              ret_val: &mut HashMap<Name, Rc<NamedMatch>>, idx: &mut usize) {\n         match m {\n-            &TtSequence(_, ref seq) => {\n+            &TokenTree::Sequence(_, ref seq) => {\n                 for next_m in &seq.tts {\n                     n_rec(p_s, next_m, res, ret_val, idx)\n                 }\n             }\n-            &TtDelimited(_, ref delim) => {\n+            &TokenTree::Delimited(_, ref delim) => {\n                 for next_m in &delim.tts {\n                     n_rec(p_s, next_m, res, ret_val, idx)\n                 }\n             }\n-            &TtToken(sp, MatchNt(bind_name, _, _, _)) => {\n+            &TokenTree::Token(sp, MatchNt(bind_name, _, _, _)) => {\n                 match ret_val.entry(bind_name.name) {\n                     Vacant(spot) => {\n                         spot.insert(res[*idx].clone());\n@@ -229,8 +228,8 @@ pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n                     }\n                 }\n             }\n-            &TtToken(_, SubstNt(..)) => panic!(\"Cannot fill in a NT\"),\n-            &TtToken(_, _) => (),\n+            &TokenTree::Token(_, SubstNt(..)) => panic!(\"Cannot fill in a NT\"),\n+            &TokenTree::Token(_, _) => (),\n         }\n     }\n     let mut ret_val = HashMap::new();\n@@ -362,7 +361,7 @@ pub fn parse(sess: &ParseSess,\n             } else {\n                 match ei.top_elts.get_tt(idx) {\n                     /* need to descend into sequence */\n-                    TtSequence(sp, seq) => {\n+                    TokenTree::Sequence(sp, seq) => {\n                         if seq.op == ast::ZeroOrMore {\n                             let mut new_ei = ei.clone();\n                             new_ei.match_cur += seq.num_captures;\n@@ -388,21 +387,21 @@ pub fn parse(sess: &ParseSess,\n                             match_hi: ei_t.match_cur + seq.num_captures,\n                             up: Some(ei_t),\n                             sp_lo: sp.lo,\n-                            top_elts: Tt(TtSequence(sp, seq)),\n+                            top_elts: Tt(TokenTree::Sequence(sp, seq)),\n                         }));\n                     }\n-                    TtToken(_, MatchNt(..)) => {\n+                    TokenTree::Token(_, MatchNt(..)) => {\n                         // Built-in nonterminals never start with these tokens,\n                         // so we can eliminate them from consideration.\n                         match tok {\n                             token::CloseDelim(_) => {},\n                             _ => bb_eis.push(ei),\n                         }\n                     }\n-                    TtToken(sp, SubstNt(..)) => {\n+                    TokenTree::Token(sp, SubstNt(..)) => {\n                         return Error(sp, \"missing fragment specifier\".to_string())\n                     }\n-                    seq @ TtDelimited(..) | seq @ TtToken(_, DocComment(..)) => {\n+                    seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, DocComment(..)) => {\n                         let lower_elts = mem::replace(&mut ei.top_elts, Tt(seq));\n                         let idx = ei.idx;\n                         ei.stack.push(MatcherTtFrame {\n@@ -412,7 +411,7 @@ pub fn parse(sess: &ParseSess,\n                         ei.idx = 0;\n                         cur_eis.push(ei);\n                     }\n-                    TtToken(_, ref t) => {\n+                    TokenTree::Token(_, ref t) => {\n                         let mut ei_t = ei.clone();\n                         if token_name_eq(t,&tok) {\n                             ei_t.idx += 1;\n@@ -440,7 +439,7 @@ pub fn parse(sess: &ParseSess,\n             if (!bb_eis.is_empty() && !next_eis.is_empty())\n                 || bb_eis.len() > 1 {\n                 let nts = bb_eis.iter().map(|ei| match ei.top_elts.get_tt(ei.idx) {\n-                    TtToken(_, MatchNt(bind, name, _, _)) => {\n+                    TokenTree::Token(_, MatchNt(bind, name, _, _)) => {\n                         format!(\"{} ('{}')\", name, bind)\n                     }\n                     _ => panic!()\n@@ -468,7 +467,7 @@ pub fn parse(sess: &ParseSess,\n \n                 let mut ei = bb_eis.pop().unwrap();\n                 match ei.top_elts.get_tt(ei.idx) {\n-                    TtToken(span, MatchNt(_, ident, _, _)) => {\n+                    TokenTree::Token(span, MatchNt(_, ident, _, _)) => {\n                         let match_cur = ei.match_cur;\n                         (&mut ei.matches[match_cur]).push(Rc::new(MatchedNonterminal(\n                             parse_nt(&mut rust_parser, span, &ident.name.as_str()))));"}, {"sha": "4e5825d182905e2be703365bbeb8478e4be71d29", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 34, "deletions": 28, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{self, TokenTree, TtDelimited, TtSequence, TtToken};\n+use ast::{self, TokenTree};\n use codemap::{Span, DUMMY_SP};\n use ext::base::{ExtCtxt, MacResult, SyntaxExtension};\n use ext::base::{NormalTT, TTMacroExpander};\n@@ -26,6 +26,7 @@ use util::small_vector::SmallVector;\n \n use std::cell::RefCell;\n use std::rc::Rc;\n+use std::iter::once;\n \n struct ParserAnyMacro<'a> {\n     parser: RefCell<Parser<'a>>,\n@@ -171,7 +172,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n         match **lhs {\n           MatchedNonterminal(NtTT(ref lhs_tt)) => {\n             let lhs_tt = match **lhs_tt {\n-                TtDelimited(_, ref delim) => &delim.tts[..],\n+                TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n                 _ => panic!(cx.span_fatal(sp, \"malformed macro lhs\"))\n             };\n \n@@ -182,7 +183,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     MatchedNonterminal(NtTT(ref tt)) => {\n                         match **tt {\n                             // ignore delimiters\n-                            TtDelimited(_, ref delimed) => delimed.tts.clone(),\n+                            TokenTree::Delimited(_, ref delimed) => delimed.tts.clone(),\n                             _ => panic!(cx.span_fatal(sp, \"macro rhs must be delimited\")),\n                         }\n                     },\n@@ -243,21 +244,21 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n     let match_lhs_tok = MatchNt(lhs_nm, special_idents::tt, token::Plain, token::Plain);\n     let match_rhs_tok = MatchNt(rhs_nm, special_idents::tt, token::Plain, token::Plain);\n     let argument_gram = vec!(\n-        TtSequence(DUMMY_SP,\n+        TokenTree::Sequence(DUMMY_SP,\n                    Rc::new(ast::SequenceRepetition {\n                        tts: vec![\n-                           TtToken(DUMMY_SP, match_lhs_tok),\n-                           TtToken(DUMMY_SP, token::FatArrow),\n-                           TtToken(DUMMY_SP, match_rhs_tok)],\n+                           TokenTree::Token(DUMMY_SP, match_lhs_tok),\n+                           TokenTree::Token(DUMMY_SP, token::FatArrow),\n+                           TokenTree::Token(DUMMY_SP, match_rhs_tok)],\n                        separator: Some(token::Semi),\n                        op: ast::OneOrMore,\n                        num_captures: 2\n                    })),\n         //to phase into semicolon-termination instead of\n         //semicolon-separation\n-        TtSequence(DUMMY_SP,\n+        TokenTree::Sequence(DUMMY_SP,\n                    Rc::new(ast::SequenceRepetition {\n-                       tts: vec![TtToken(DUMMY_SP, token::Semi)],\n+                       tts: vec![TokenTree::Token(DUMMY_SP, token::Semi)],\n                        separator: None,\n                        op: ast::ZeroOrMore,\n                        num_captures: 0\n@@ -307,14 +308,14 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n }\n \n fn check_lhs_nt_follows(cx: &mut ExtCtxt, lhs: &NamedMatch, sp: Span) {\n-    // lhs is going to be like MatchedNonterminal(NtTT(TtDelimited(...))), where the entire lhs is\n-    // those tts. Or, it can be a \"bare sequence\", not wrapped in parens.\n+    // lhs is going to be like MatchedNonterminal(NtTT(TokenTree::Delimited(...))), where the\n+    // entire lhs is those tts. Or, it can be a \"bare sequence\", not wrapped in parens.\n     match lhs {\n         &MatchedNonterminal(NtTT(ref inner)) => match &**inner {\n-            &TtDelimited(_, ref tts) => {\n+            &TokenTree::Delimited(_, ref tts) => {\n                 check_matcher(cx, tts.tts.iter(), &Eof);\n             },\n-            tt @ &TtSequence(..) => {\n+            tt @ &TokenTree::Sequence(..) => {\n                 check_matcher(cx, Some(tt).into_iter(), &Eof);\n             },\n             _ => cx.span_err(sp, \"Invalid macro matcher; matchers must be contained \\\n@@ -327,7 +328,7 @@ fn check_lhs_nt_follows(cx: &mut ExtCtxt, lhs: &NamedMatch, sp: Span) {\n     // after parsing/expansion. we can report every error in every macro this way.\n }\n \n-// returns the last token that was checked, for TtSequence. this gets used later on.\n+// returns the last token that was checked, for TokenTree::Sequence. this gets used later on.\n fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n -> Option<(Span, Token)> where I: Iterator<Item=&'a TokenTree> {\n     use print::pprust::token_to_string;\n@@ -338,17 +339,17 @@ fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n     let mut tokens = matcher.peekable();\n     while let Some(token) = tokens.next() {\n         last = match *token {\n-            TtToken(sp, MatchNt(ref name, ref frag_spec, _, _)) => {\n+            TokenTree::Token(sp, MatchNt(ref name, ref frag_spec, _, _)) => {\n                 // ii. If T is a simple NT, look ahead to the next token T' in\n                 // M. If T' is in the set FOLLOW(NT), continue. Else; reject.\n                 if can_be_followed_by_any(&frag_spec.name.as_str()) {\n                     continue\n                 } else {\n                     let next_token = match tokens.peek() {\n                         // If T' closes a complex NT, replace T' with F\n-                        Some(&&TtToken(_, CloseDelim(_))) => follow.clone(),\n-                        Some(&&TtToken(_, ref tok)) => tok.clone(),\n-                        Some(&&TtSequence(sp, _)) => {\n+                        Some(&&TokenTree::Token(_, CloseDelim(_))) => follow.clone(),\n+                        Some(&&TokenTree::Token(_, ref tok)) => tok.clone(),\n+                        Some(&&TokenTree::Sequence(sp, _)) => {\n                             // Be conservative around sequences: to be\n                             // more specific, we would need to\n                             // consider FIRST sets, but also the\n@@ -366,12 +367,16 @@ fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n                             Eof\n                         },\n                         // die next iteration\n-                        Some(&&TtDelimited(_, ref delim)) => delim.close_token(),\n+                        Some(&&TokenTree::Delimited(_, ref delim)) => delim.close_token(),\n                         // else, we're at the end of the macro or sequence\n                         None => follow.clone()\n                     };\n \n-                    let tok = if let TtToken(_, ref tok) = *token { tok } else { unreachable!() };\n+                    let tok = if let TokenTree::Token(_, ref tok) = *token {\n+                        tok\n+                    } else {\n+                        unreachable!()\n+                    };\n \n                     // If T' is in the set FOLLOW(NT), continue. Else, reject.\n                     match (&next_token, is_in_follow(cx, &next_token, &frag_spec.name.as_str())) {\n@@ -391,7 +396,7 @@ fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n                     }\n                 }\n             },\n-            TtSequence(sp, ref seq) => {\n+            TokenTree::Sequence(sp, ref seq) => {\n                 // iii. Else, T is a complex NT.\n                 match seq.separator {\n                     // If T has the form $(...)U+ or $(...)U* for some token U,\n@@ -408,16 +413,17 @@ fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n                             // but conservatively correct.\n                             Some((span, tok)) => {\n                                 let fol = match tokens.peek() {\n-                                    Some(&&TtToken(_, ref tok)) => tok.clone(),\n-                                    Some(&&TtDelimited(_, ref delim)) => delim.close_token(),\n+                                    Some(&&TokenTree::Token(_, ref tok)) => tok.clone(),\n+                                    Some(&&TokenTree::Delimited(_, ref delim)) =>\n+                                        delim.close_token(),\n                                     Some(_) => {\n                                         cx.span_err(sp, \"sequence repetition followed by \\\n                                                 another sequence repetition, which is not allowed\");\n                                         Eof\n                                     },\n                                     None => Eof\n                                 };\n-                                check_matcher(cx, Some(&TtToken(span, tok.clone())).into_iter(),\n+                                check_matcher(cx, once(&TokenTree::Token(span, tok.clone())),\n                                               &fol)\n                             },\n                             None => last,\n@@ -428,8 +434,8 @@ fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n                     // sequence. If it accepts, continue, else, reject.\n                     None => {\n                         let fol = match tokens.peek() {\n-                            Some(&&TtToken(_, ref tok)) => tok.clone(),\n-                            Some(&&TtDelimited(_, ref delim)) => delim.close_token(),\n+                            Some(&&TokenTree::Token(_, ref tok)) => tok.clone(),\n+                            Some(&&TokenTree::Delimited(_, ref delim)) => delim.close_token(),\n                             Some(_) => {\n                                 cx.span_err(sp, \"sequence repetition followed by another \\\n                                              sequence repetition, which is not allowed\");\n@@ -441,11 +447,11 @@ fn check_matcher<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token)\n                     }\n                 }\n             },\n-            TtToken(..) => {\n+            TokenTree::Token(..) => {\n                 // i. If T is not an NT, continue.\n                 continue\n             },\n-            TtDelimited(_, ref tts) => {\n+            TokenTree::Delimited(_, ref tts) => {\n                 // if we don't pass in that close delimiter, we'll incorrectly consider the matcher\n                 // `{ $foo:ty }` as having a follow that isn't `RBrace`\n                 check_matcher(cx, tts.tts.iter(), &tts.close_token())"}, {"sha": "0fc31f3fd08af95871b5df5c0a090a72f8499cdf", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -10,7 +10,7 @@\n use self::LockstepIterSize::*;\n \n use ast;\n-use ast::{TokenTree, TtDelimited, TtToken, TtSequence, Ident, Name};\n+use ast::{TokenTree, Ident, Name};\n use codemap::{Span, DUMMY_SP};\n use diagnostic::SpanHandler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n@@ -53,7 +53,7 @@ pub struct TtReader<'a> {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TtSequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n+/// `src` contains no `TokenTree::Sequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n /// (and should) be None.\n pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n                          interp: Option<HashMap<Name, Rc<NamedMatch>>>,\n@@ -67,7 +67,7 @@ pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n /// like any other attribute which consists of `meta` and surrounding #[ ] tokens.\n ///\n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TtSequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n+/// `src` contains no `TokenTree::Sequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n /// (and should) be None.\n pub fn new_tt_reader_with_doc_flag<'a>(sp_diag: &'a SpanHandler,\n                                        interp: Option<HashMap<Name, Rc<NamedMatch>>>,\n@@ -78,7 +78,7 @@ pub fn new_tt_reader_with_doc_flag<'a>(sp_diag: &'a SpanHandler,\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n         stack: vec!(TtFrame {\n-            forest: TtSequence(DUMMY_SP, Rc::new(ast::SequenceRepetition {\n+            forest: TokenTree::Sequence(DUMMY_SP, Rc::new(ast::SequenceRepetition {\n                 tts: src,\n                 // doesn't matter. This merely holds the root unzipping.\n                 separator: None, op: ast::ZeroOrMore, num_captures: 0\n@@ -151,25 +151,25 @@ impl Add for LockstepIterSize {\n \n fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n     match *t {\n-        TtDelimited(_, ref delimed) => {\n+        TokenTree::Delimited(_, ref delimed) => {\n             delimed.tts.iter().fold(LisUnconstrained, |size, tt| {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n-        TtSequence(_, ref seq) => {\n+        TokenTree::Sequence(_, ref seq) => {\n             seq.tts.iter().fold(LisUnconstrained, |size, tt| {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n-        TtToken(_, SubstNt(name, _)) | TtToken(_, MatchNt(name, _, _, _)) =>\n+        TokenTree::Token(_, SubstNt(name, _)) | TokenTree::Token(_, MatchNt(name, _, _, _)) =>\n             match lookup_cur_matched(r, name) {\n                 Some(matched) => match *matched {\n                     MatchedNonterminal(_) => LisUnconstrained,\n                     MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name),\n                 },\n                 _ => LisUnconstrained\n             },\n-        TtToken(..) => LisUnconstrained,\n+        TokenTree::Token(..) => LisUnconstrained,\n     }\n }\n \n@@ -232,17 +232,17 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             }\n         }\n     }\n-    loop { /* because it's easiest, this handles `TtDelimited` not starting\n-              with a `TtToken`, even though it won't happen */\n+    loop { /* because it's easiest, this handles `TokenTree::Delimited` not starting\n+              with a `TokenTree::Token`, even though it won't happen */\n         let t = {\n             let frame = r.stack.last().unwrap();\n             // FIXME(pcwalton): Bad copy.\n             frame.forest.get_tt(frame.idx)\n         };\n         match t {\n-            TtSequence(sp, seq) => {\n+            TokenTree::Sequence(sp, seq) => {\n                 // FIXME(pcwalton): Bad copy.\n-                match lockstep_iter_size(&TtSequence(sp, seq.clone()),\n+                match lockstep_iter_size(&TokenTree::Sequence(sp, seq.clone()),\n                                          r) {\n                     LisUnconstrained => {\n                         panic!(r.sp_diag.span_fatal(\n@@ -272,20 +272,20 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                             idx: 0,\n                             dotdotdoted: true,\n                             sep: seq.separator.clone(),\n-                            forest: TtSequence(sp, seq),\n+                            forest: TokenTree::Sequence(sp, seq),\n                         });\n                     }\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n-            TtToken(sp, SubstNt(ident, namep)) => {\n+            TokenTree::Token(sp, SubstNt(ident, namep)) => {\n                 r.stack.last_mut().unwrap().idx += 1;\n                 match lookup_cur_matched(r, ident) {\n                     None => {\n                         r.cur_span = sp;\n                         r.cur_tok = SubstNt(ident, namep);\n                         return ret_val;\n-                        // this can't be 0 length, just like TtDelimited\n+                        // this can't be 0 length, just like TokenTree::Delimited\n                     }\n                     Some(cur_matched) => {\n                         match *cur_matched {\n@@ -313,8 +313,8 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                     }\n                 }\n             }\n-            // TtDelimited or any token that can be unzipped\n-            seq @ TtDelimited(..) | seq @ TtToken(_, MatchNt(..)) => {\n+            // TokenTree::Delimited or any token that can be unzipped\n+            seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, MatchNt(..)) => {\n                 // do not advance the idx yet\n                 r.stack.push(TtFrame {\n                    forest: seq,\n@@ -324,15 +324,15 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 });\n                 // if this could be 0-length, we'd need to potentially recur here\n             }\n-            TtToken(sp, DocComment(name)) if r.desugar_doc_comments => {\n+            TokenTree::Token(sp, DocComment(name)) if r.desugar_doc_comments => {\n                 r.stack.push(TtFrame {\n-                   forest: TtToken(sp, DocComment(name)),\n+                   forest: TokenTree::Token(sp, DocComment(name)),\n                    idx: 0,\n                    dotdotdoted: false,\n                    sep: None\n                 });\n             }\n-            TtToken(sp, token::SpecialVarNt(SpecialMacroVar::CrateMacroVar)) => {\n+            TokenTree::Token(sp, token::SpecialVarNt(SpecialMacroVar::CrateMacroVar)) => {\n                 r.stack.last_mut().unwrap().idx += 1;\n \n                 if r.imported_from.is_some() {\n@@ -344,7 +344,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n \n                 // otherwise emit nothing and proceed to the next token\n             }\n-            TtToken(sp, tok) => {\n+            TokenTree::Token(sp, tok) => {\n                 r.cur_span = sp;\n                 r.cur_tok = tok;\n                 r.stack.last_mut().unwrap().idx += 1;"}, {"sha": "cb16c95f9a3f4348e40dd9784bb46bb1db60ae4b", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -586,10 +586,10 @@ pub fn noop_fold_arg<T: Folder>(Arg {id, pat, ty}: Arg, fld: &mut T) -> Arg {\n \n pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n     match *tt {\n-        TtToken(span, ref tok) =>\n-            TtToken(span, fld.fold_token(tok.clone())),\n-        TtDelimited(span, ref delimed) => {\n-            TtDelimited(span, Rc::new(\n+        TokenTree::Token(span, ref tok) =>\n+            TokenTree::Token(span, fld.fold_token(tok.clone())),\n+        TokenTree::Delimited(span, ref delimed) => {\n+            TokenTree::Delimited(span, Rc::new(\n                             Delimited {\n                                 delim: delimed.delim,\n                                 open_span: delimed.open_span,\n@@ -598,8 +598,8 @@ pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n                             }\n                         ))\n         },\n-        TtSequence(span, ref seq) =>\n-            TtSequence(span,\n+        TokenTree::Sequence(span, ref seq) =>\n+            TokenTree::Sequence(span,\n                        Rc::new(SequenceRepetition {\n                            tts: fld.fold_tts(&seq.tts),\n                            separator: seq.separator.clone().map(|tok| fld.fold_token(tok)),"}, {"sha": "5c0ffb770b77be7c3b1b6831fdb606ebefb2c99e", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -669,7 +669,7 @@ mod tests {\n     use std::rc::Rc;\n     use codemap::{Span, BytePos, Pos, Spanned, NO_EXPANSION};\n     use owned_slice::OwnedSlice;\n-    use ast;\n+    use ast::{self, TokenTree};\n     use abi;\n     use attr::{first_attr_value_str_by_name, AttrMetaMethods};\n     use parse;\n@@ -739,28 +739,28 @@ mod tests {\n         match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n             (\n                 4,\n-                Some(&ast::TtToken(_, token::Ident(name_macro_rules, token::Plain))),\n-                Some(&ast::TtToken(_, token::Not)),\n-                Some(&ast::TtToken(_, token::Ident(name_zip, token::Plain))),\n-                Some(&ast::TtDelimited(_, ref macro_delimed)),\n+                Some(&TokenTree::Token(_, token::Ident(name_macro_rules, token::Plain))),\n+                Some(&TokenTree::Token(_, token::Not)),\n+                Some(&TokenTree::Token(_, token::Ident(name_zip, token::Plain))),\n+                Some(&TokenTree::Delimited(_, ref macro_delimed)),\n             )\n             if name_macro_rules.name.as_str() == \"macro_rules\"\n             && name_zip.name.as_str() == \"zip\" => {\n                 let tts = &macro_delimed.tts[..];\n                 match (tts.len(), tts.get(0), tts.get(1), tts.get(2)) {\n                     (\n                         3,\n-                        Some(&ast::TtDelimited(_, ref first_delimed)),\n-                        Some(&ast::TtToken(_, token::FatArrow)),\n-                        Some(&ast::TtDelimited(_, ref second_delimed)),\n+                        Some(&TokenTree::Delimited(_, ref first_delimed)),\n+                        Some(&TokenTree::Token(_, token::FatArrow)),\n+                        Some(&TokenTree::Delimited(_, ref second_delimed)),\n                     )\n                     if macro_delimed.delim == token::Paren => {\n                         let tts = &first_delimed.tts[..];\n                         match (tts.len(), tts.get(0), tts.get(1)) {\n                             (\n                                 2,\n-                                Some(&ast::TtToken(_, token::Dollar)),\n-                                Some(&ast::TtToken(_, token::Ident(ident, token::Plain))),\n+                                Some(&TokenTree::Token(_, token::Dollar)),\n+                                Some(&TokenTree::Token(_, token::Ident(ident, token::Plain))),\n                             )\n                             if first_delimed.delim == token::Paren\n                             && ident.name.as_str() == \"a\" => {},\n@@ -770,8 +770,8 @@ mod tests {\n                         match (tts.len(), tts.get(0), tts.get(1)) {\n                             (\n                                 2,\n-                                Some(&ast::TtToken(_, token::Dollar)),\n-                                Some(&ast::TtToken(_, token::Ident(ident, token::Plain))),\n+                                Some(&TokenTree::Token(_, token::Dollar)),\n+                                Some(&TokenTree::Token(_, token::Ident(ident, token::Plain))),\n                             )\n                             if second_delimed.delim == token::Paren\n                             && ident.name.as_str() == \"a\" => {},\n@@ -790,39 +790,39 @@ mod tests {\n         let tts = string_to_tts(\"fn a (b : i32) { b; }\".to_string());\n \n         let expected = vec![\n-            ast::TtToken(sp(0, 2),\n+            TokenTree::Token(sp(0, 2),\n                          token::Ident(str_to_ident(\"fn\"),\n                          token::IdentStyle::Plain)),\n-            ast::TtToken(sp(3, 4),\n+            TokenTree::Token(sp(3, 4),\n                          token::Ident(str_to_ident(\"a\"),\n                          token::IdentStyle::Plain)),\n-            ast::TtDelimited(\n+            TokenTree::Delimited(\n                 sp(5, 14),\n                 Rc::new(ast::Delimited {\n                     delim: token::DelimToken::Paren,\n                     open_span: sp(5, 6),\n                     tts: vec![\n-                        ast::TtToken(sp(6, 7),\n+                        TokenTree::Token(sp(6, 7),\n                                      token::Ident(str_to_ident(\"b\"),\n                                      token::IdentStyle::Plain)),\n-                        ast::TtToken(sp(8, 9),\n+                        TokenTree::Token(sp(8, 9),\n                                      token::Colon),\n-                        ast::TtToken(sp(10, 13),\n+                        TokenTree::Token(sp(10, 13),\n                                      token::Ident(str_to_ident(\"i32\"),\n                                      token::IdentStyle::Plain)),\n                     ],\n                     close_span: sp(13, 14),\n                 })),\n-            ast::TtDelimited(\n+            TokenTree::Delimited(\n                 sp(15, 21),\n                 Rc::new(ast::Delimited {\n                     delim: token::DelimToken::Brace,\n                     open_span: sp(15, 16),\n                     tts: vec![\n-                        ast::TtToken(sp(17, 18),\n+                        TokenTree::Token(sp(17, 18),\n                                      token::Ident(str_to_ident(\"b\"),\n                                      token::IdentStyle::Plain)),\n-                        ast::TtToken(sp(18, 19),\n+                        TokenTree::Token(sp(18, 19),\n                                      token::Semi)\n                     ],\n                     close_span: sp(20, 21),"}, {"sha": "0905f26f1474ff2d8386f2f6e5d48e391bad7f52", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -48,7 +48,6 @@ use ast::{StmtExpr, StmtSemi, StmtMac, VariantData, StructField};\n use ast::{BiSub, StrStyle};\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n use ast::{Delimited, SequenceRepetition, TokenTree, TraitItem, TraitRef};\n-use ast::{TtDelimited, TtSequence, TtToken};\n use ast::{Ty, Ty_, TypeBinding, TyMac};\n use ast::{TyFixedLengthVec, TyBareFn, TyTypeof, TyInfer};\n use ast::{TyParam, TyParamBound, TyParen, TyPath, TyPolyTraitRef, TyPtr};\n@@ -2428,7 +2427,7 @@ impl<'a> Parser<'a> {\n                     ));\n                     let (sep, repeat) = try!(self.parse_sep_and_kleene_op());\n                     let name_num = macro_parser::count_names(&seq);\n-                    return Ok(TtSequence(mk_sp(sp.lo, seq_span.hi),\n+                    return Ok(TokenTree::Sequence(mk_sp(sp.lo, seq_span.hi),\n                                       Rc::new(SequenceRepetition {\n                                           tts: seq,\n                                           separator: sep,\n@@ -2437,7 +2436,7 @@ impl<'a> Parser<'a> {\n                                       })));\n                 } else if self.token.is_keyword_allow_following_colon(keywords::Crate) {\n                     try!(self.bump());\n-                    return Ok(TtToken(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar)));\n+                    return Ok(TokenTree::Token(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar)));\n                 } else {\n                     sp = mk_sp(sp.lo, self.span.hi);\n                     let namep = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n@@ -2459,9 +2458,9 @@ impl<'a> Parser<'a> {\n             sp = mk_sp(sp.lo, self.span.hi);\n             let kindp = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n             let nt_kind = try!(self.parse_ident());\n-            Ok(TtToken(sp, MatchNt(name, nt_kind, namep, kindp)))\n+            Ok(TokenTree::Token(sp, MatchNt(name, nt_kind, namep, kindp)))\n         } else {\n-            Ok(TtToken(sp, SubstNt(name, namep)))\n+            Ok(TokenTree::Token(sp, SubstNt(name, namep)))\n         }\n     }\n \n@@ -2509,7 +2508,7 @@ impl<'a> Parser<'a> {\n     /// parse a single token tree from the input.\n     pub fn parse_token_tree(&mut self) -> PResult<TokenTree> {\n         // FIXME #6994: currently, this is too eager. It\n-        // parses token trees but also identifies TtSequence's\n+        // parses token trees but also identifies TokenType::Sequence's\n         // and token::SubstNt's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n@@ -2540,7 +2539,7 @@ impl<'a> Parser<'a> {\n                     p.parse_unquoted()\n                 }\n                 _ => {\n-                    Ok(TtToken(p.span, try!(p.bump_and_get())))\n+                    Ok(TokenTree::Token(p.span, try!(p.bump_and_get())))\n                 }\n             }\n         }\n@@ -2579,7 +2578,7 @@ impl<'a> Parser<'a> {\n                 // Expand to cover the entire delimited token tree\n                 let span = Span { hi: close_span.hi, ..pre_span };\n \n-                Ok(TtDelimited(span, Rc::new(Delimited {\n+                Ok(TokenTree::Delimited(span, Rc::new(Delimited {\n                     delim: delim,\n                     open_span: open_span,\n                     tts: tts,"}, {"sha": "fad0b7869f02d5e56c0455fef0254e97dcc68436", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -11,7 +11,7 @@\n pub use self::AnnNode::*;\n \n use abi;\n-use ast;\n+use ast::{self, TokenTree};\n use ast::{RegionTyParamBound, TraitTyParamBound, TraitBoundModifier};\n use ast_util;\n use util::parser::AssocOp;\n@@ -1452,7 +1452,7 @@ impl<'a> State<'a> {\n     /// expression arguments as expressions). It can be done! I think.\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> io::Result<()> {\n         match *tt {\n-            ast::TtToken(_, ref tk) => {\n+            TokenTree::Token(_, ref tk) => {\n                 try!(word(&mut self.s, &token_to_string(tk)));\n                 match *tk {\n                     parse::token::DocComment(..) => {\n@@ -1461,14 +1461,14 @@ impl<'a> State<'a> {\n                     _ => Ok(())\n                 }\n             }\n-            ast::TtDelimited(_, ref delimed) => {\n+            TokenTree::Delimited(_, ref delimed) => {\n                 try!(word(&mut self.s, &token_to_string(&delimed.open_token())));\n                 try!(space(&mut self.s));\n                 try!(self.print_tts(&delimed.tts));\n                 try!(space(&mut self.s));\n                 word(&mut self.s, &token_to_string(&delimed.close_token()))\n             },\n-            ast::TtSequence(_, ref seq) => {\n+            TokenTree::Sequence(_, ref seq) => {\n                 try!(word(&mut self.s, \"$(\"));\n                 for tt_elt in &seq.tts {\n                     try!(self.print_tt(tt_elt));\n@@ -1499,9 +1499,9 @@ impl<'a> State<'a> {\n             // There should be no space between the module name and the following `::` in paths,\n             // otherwise imported macros get re-parsed from crate metadata incorrectly (#20701)\n             suppress_space = match tt {\n-                &ast::TtToken(_, token::Ident(_, token::ModName)) |\n-                &ast::TtToken(_, token::MatchNt(_, _, _, token::ModName)) |\n-                &ast::TtToken(_, token::SubstNt(_, token::ModName)) => true,\n+                &TokenTree::Token(_, token::Ident(_, token::ModName)) |\n+                &TokenTree::Token(_, token::MatchNt(_, _, _, token::ModName)) |\n+                &TokenTree::Token(_, token::SubstNt(_, token::ModName)) => true,\n                 _ => false\n             }\n         }"}, {"sha": "a92361b8106d71068c4a7691c94f27c1472658d4", "filename": "src/test/auxiliary/procedural_mbe_matching.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Ftest%2Fauxiliary%2Fprocedural_mbe_matching.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Ftest%2Fauxiliary%2Fprocedural_mbe_matching.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Fprocedural_mbe_matching.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -18,7 +18,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{self, str_to_ident, NtExpr, NtPat};\n-use syntax::ast::{TokenTree, TtToken, Pat};\n+use syntax::ast::{TokenTree, Pat};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n use syntax::ext::build::AstBuilder;\n use syntax::ext::tt::macro_parser::{MatchedSeq, MatchedNonterminal};"}, {"sha": "3abc6f4a9f5d805f794fb33ab99f00fb7ead1537", "filename": "src/test/auxiliary/roman_numerals.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/475f91f46eecc7411311106e5c45f7e4781fb5e1/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Froman_numerals.rs?ref=475f91f46eecc7411311106e5c45f7e4781fb5e1", "patch": "@@ -18,7 +18,7 @@ extern crate syntax;\n extern crate rustc;\n \n use syntax::codemap::Span;\n-use syntax::ast::{TokenTree, TtToken};\n+use syntax::ast::TokenTree;\n use syntax::parse::token;\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n use syntax::ext::build::AstBuilder;  // trait for expr_usize\n@@ -40,7 +40,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TtToken(_, token::Ident(s, _))] => s.to_string(),\n+        [TokenTree::Token(_, token::Ident(s, _))] => s.to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}]}