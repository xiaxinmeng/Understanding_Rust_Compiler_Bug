{"sha": "351d46d3fb077d4fc824131cc9e2f95ace2df5de", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM1MWQ0NmQzZmIwNzdkNGZjODI0MTMxY2M5ZTJmOTVhY2UyZGY1ZGU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-04-30T16:21:43Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-04-30T16:21:43Z"}, "message": "Auto merge of #1284 - vakaras:add-threads-cr2, r=RalfJung\n\nImplement basic support for concurrency (Linux/macos only)\n\nChanges  (most new code is in `src/threads.rs` and `src/shims/foreign_items/posix.rs`):\n\n1. Move the stack from `Machine` to a newly created `Thread` struct.\n2. Add a `ThreadSet` struct that manages the threads.\n3. Change `canonical_alloc_id` to create a unique allocation id for each thread local and thread (the responsible struct is `ThreadLocalStorage`)\n4. Change the code to execute the thread local destructors immediately when a thread terminates.\n5. Add the most basic round-robin scheduler.\n\nThis pull request depends on [these changes to the compiler](https://github.com/rust-lang/rust/pull/70598).", "tree": {"sha": "8761a8a7c2e809b826252acbba42a2a0d5d5bd41", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8761a8a7c2e809b826252acbba42a2a0d5d5bd41"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/351d46d3fb077d4fc824131cc9e2f95ace2df5de", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/351d46d3fb077d4fc824131cc9e2f95ace2df5de", "html_url": "https://github.com/rust-lang/rust/commit/351d46d3fb077d4fc824131cc9e2f95ace2df5de", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/351d46d3fb077d4fc824131cc9e2f95ace2df5de/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7aecd7099d5e551de7dc2cdf34915951b6a33bbf", "url": "https://api.github.com/repos/rust-lang/rust/commits/7aecd7099d5e551de7dc2cdf34915951b6a33bbf", "html_url": "https://github.com/rust-lang/rust/commit/7aecd7099d5e551de7dc2cdf34915951b6a33bbf"}, {"sha": "48da0cf489c1cbbb309692db4049632d83740a8e", "url": "https://api.github.com/repos/rust-lang/rust/commits/48da0cf489c1cbbb309692db4049632d83740a8e", "html_url": "https://github.com/rust-lang/rust/commit/48da0cf489c1cbbb309692db4049632d83740a8e"}], "stats": {"total": 2218, "additions": 1946, "deletions": 272}, "files": [{"sha": "a64161809e642574859b399789427e398f60f0a1", "filename": "README.md", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/README.md", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/README.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/README.md?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -47,7 +47,9 @@ in your program, and cannot run all programs:\n * Miri runs the program as a platform-independent interpreter, so the program\n   has no access to most platform-specific APIs or FFI. A few APIs have been\n   implemented (such as printing to stdout) but most have not: for example, Miri\n-  currently does not support concurrency, or SIMD, or networking.\n+  currently does not support SIMD or networking.\n+* Miri currently does not check for data-races and most other concurrency\n+  related issues.\n \n [rust]: https://www.rust-lang.org/\n [mir]: https://github.com/rust-lang/rfcs/blob/master/text/1211-mir.md"}, {"sha": "b7c96dd7e98aac4f2b49aca09b954b63bc336018", "filename": "src/diagnostics.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdiagnostics.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -139,7 +139,7 @@ fn report_msg<'tcx, 'mir>(\n     mut helps: Vec<String>,\n     error: bool,\n ) {\n-    let span = if let Some(frame) = ecx.machine.stack.last() {\n+    let span = if let Some(frame) = ecx.active_thread_stack().last() {\n         frame.current_source_info().unwrap().span\n     } else {\n         DUMMY_SP\n@@ -171,7 +171,7 @@ fn report_msg<'tcx, 'mir>(\n \n     err.emit();\n \n-    for (i, frame) in ecx.machine.stack.iter().enumerate() {\n+    for (i, frame) in ecx.active_thread_stack().iter().enumerate() {\n         trace!(\"-------------------\");\n         trace!(\"Frame {}\", i);\n         trace!(\"    return: {:?}\", frame.return_place.map(|p| *p));"}, {"sha": "6352d06268654823651bd059664bf10394e5af4d", "filename": "src/eval.rs", "status": "modified", "additions": 15, "deletions": 5, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Feval.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -205,14 +205,24 @@ pub fn eval_main<'tcx>(tcx: TyCtxt<'tcx>, main_id: DefId, config: MiriConfig) ->\n     // Perform the main execution.\n     let res: InterpResult<'_, i64> = (|| {\n         // Main loop.\n-        while ecx.step()? {\n+        loop {\n+            match ecx.schedule()? {\n+                SchedulingAction::ExecuteStep => {\n+                    assert!(ecx.step()?, \"a terminated thread was scheduled for execution\");\n+                }\n+                SchedulingAction::ExecuteDtors => {\n+                    // This will either enable the thread again (so we go back\n+                    // to `ExecuteStep`), or determine that this thread is done\n+                    // for good.\n+                    ecx.schedule_next_tls_dtor_for_active_thread()?;\n+                }\n+                SchedulingAction::Stop => {\n+                    break;\n+                }\n+            }\n             ecx.process_diagnostics();\n         }\n-        // Read the return code pointer *before* we run TLS destructors, to assert\n-        // that it was written to by the time that `start` lang item returned.\n         let return_code = ecx.read_scalar(ret_place.into())?.not_undef()?.to_machine_isize(&ecx)?;\n-        // Global destructors.\n-        ecx.run_tls_dtors()?;\n         Ok(return_code)\n     })();\n "}, {"sha": "beee94b918b56775d63116a0b43fd9aa41913ec0", "filename": "src/lib.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -12,6 +12,7 @@ extern crate rustc_ast;\n #[macro_use] extern crate rustc_middle;\n extern crate rustc_data_structures;\n extern crate rustc_hir;\n+extern crate rustc_index;\n extern crate rustc_mir;\n extern crate rustc_span;\n extern crate rustc_target;\n@@ -26,6 +27,7 @@ mod operator;\n mod range_map;\n mod shims;\n mod stacked_borrows;\n+mod thread;\n \n // Make all those symbols available in the same place as our own.\n pub use rustc_mir::interpret::*;\n@@ -40,6 +42,7 @@ pub use crate::shims::intrinsics::EvalContextExt as IntrinsicsEvalContextExt;\n pub use crate::shims::os_str::EvalContextExt as OsStrEvalContextExt;\n pub use crate::shims::panic::{CatchUnwindData, EvalContextExt as PanicEvalContextExt};\n pub use crate::shims::sync::{EvalContextExt as SyncEvalContextExt};\n+pub use crate::shims::thread::EvalContextExt as ThreadShimsEvalContextExt;\n pub use crate::shims::time::EvalContextExt as TimeEvalContextExt;\n pub use crate::shims::tls::{EvalContextExt as TlsEvalContextExt, TlsData};\n pub use crate::shims::EvalContextExt as ShimsEvalContextExt;\n@@ -60,6 +63,9 @@ pub use crate::range_map::RangeMap;\n pub use crate::stacked_borrows::{\n     EvalContextExt as StackedBorEvalContextExt, Item, Permission, PtrId, Stack, Stacks, Tag,\n };\n+pub use crate::thread::{\n+    EvalContextExt as ThreadsEvalContextExt, SchedulingAction, ThreadId, ThreadManager, ThreadState,\n+};\n \n /// Insert rustc arguments at the beginning of the argument list that Miri wants to be\n /// set per default, for maximal validation power."}, {"sha": "3853f6559959655023dd9dcaaa0d044cce0efa5a", "filename": "src/machine.rs", "status": "modified", "additions": 15, "deletions": 9, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fmachine.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -251,8 +251,8 @@ pub struct Evaluator<'mir, 'tcx> {\n     /// The \"time anchor\" for this machine's monotone clock (for `Instant` simulation).\n     pub(crate) time_anchor: Instant,\n \n-    /// The call stack.\n-    pub(crate) stack: Vec<Frame<'mir, 'tcx, Tag, FrameData<'tcx>>>,\n+    /// The set of threads.\n+    pub(crate) threads: ThreadManager<'mir, 'tcx>,\n \n     /// Precomputed `TyLayout`s for primitive data types that are commonly used inside Miri.\n     pub(crate) layouts: PrimitiveLayouts<'tcx>,\n@@ -282,7 +282,7 @@ impl<'mir, 'tcx> Evaluator<'mir, 'tcx> {\n             panic_payload: None,\n             time_anchor: Instant::now(),\n             layouts,\n-            stack: Vec::default(),\n+            threads: ThreadManager::default(),\n         }\n     }\n }\n@@ -416,6 +416,14 @@ impl<'mir, 'tcx> Machine<'mir, 'tcx> for Evaluator<'mir, 'tcx> {\n         Ok(())\n     }\n \n+    fn adjust_global_const(\n+        ecx: &InterpCx<'mir, 'tcx, Self>,\n+        mut val: mir::interpret::ConstValue<'tcx>,\n+    ) -> InterpResult<'tcx, mir::interpret::ConstValue<'tcx>> {\n+        ecx.remap_thread_local_alloc_ids(&mut val)?;\n+        Ok(val)\n+    }\n+\n     fn canonical_alloc_id(mem: &Memory<'mir, 'tcx, Self>, id: AllocId) -> AllocId {\n         let tcx = mem.tcx;\n         // Figure out if this is an extern static, and if yes, which one.\n@@ -525,18 +533,16 @@ impl<'mir, 'tcx> Machine<'mir, 'tcx> for Evaluator<'mir, 'tcx> {\n         Ok(frame.with_extra(extra))\n     }\n \n-    #[inline(always)]\n     fn stack<'a>(\n-        ecx: &'a InterpCx<'mir, 'tcx, Self>,\n+        ecx: &'a InterpCx<'mir, 'tcx, Self>\n     ) -> &'a [Frame<'mir, 'tcx, Self::PointerTag, Self::FrameExtra>] {\n-        &ecx.machine.stack\n+        ecx.active_thread_stack()\n     }\n \n-    #[inline(always)]\n     fn stack_mut<'a>(\n-        ecx: &'a mut InterpCx<'mir, 'tcx, Self>,\n+        ecx: &'a mut InterpCx<'mir, 'tcx, Self>\n     ) -> &'a mut Vec<Frame<'mir, 'tcx, Self::PointerTag, Self::FrameExtra>> {\n-        &mut ecx.machine.stack\n+        ecx.active_thread_stack_mut()\n     }\n \n     #[inline(always)]"}, {"sha": "6e2a7a9fcb4fa49b0a164ef3b40ecf3b29154586", "filename": "src/shims/foreign_items/posix.rs", "status": "modified", "additions": 36, "deletions": 8, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fposix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fposix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fforeign_items%2Fposix.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -221,13 +221,15 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             }\n             \"pthread_getspecific\" => {\n                 let key = this.force_bits(this.read_scalar(args[0])?.not_undef()?, args[0].layout.size)?;\n-                let ptr = this.machine.tls.load_tls(key, this)?;\n+                let active_thread = this.get_active_thread()?;\n+                let ptr = this.machine.tls.load_tls(key, active_thread, this)?;\n                 this.write_scalar(ptr, dest)?;\n             }\n             \"pthread_setspecific\" => {\n                 let key = this.force_bits(this.read_scalar(args[0])?.not_undef()?, args[0].layout.size)?;\n+                let active_thread = this.get_active_thread()?;\n                 let new_ptr = this.read_scalar(args[1])?.not_undef()?;\n-                this.machine.tls.store_tls(key, this.test_null(new_ptr)?)?;\n+                this.machine.tls.store_tls(key, active_thread, this.test_null(new_ptr)?)?;\n \n                 // Return success (`0`).\n                 this.write_null(dest)?;\n@@ -291,9 +293,30 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 this.write_scalar(Scalar::from_i32(result), dest)?;\n             }\n \n-            // Better error for attempts to create a thread\n+            // Threading\n             \"pthread_create\" => {\n-                throw_unsup_format!(\"Miri does not support threading\");\n+                assert_eq!(args.len(), 4);\n+                let result = this.pthread_create(args[0], args[1], args[2], args[3])?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_join\" => {\n+                assert_eq!(args.len(), 2);\n+                let result = this.pthread_join(args[0], args[1])?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_detach\" => {\n+                assert_eq!(args.len(), 1);\n+                let result = this.pthread_detach(args[0])?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_self\" => {\n+                assert_eq!(args.len(), 0);\n+                this.pthread_self(dest)?;\n+            }\n+            \"sched_yield\" => {\n+                assert_eq!(args.len(), 0);\n+                let result = this.sched_yield()?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n             }\n \n             // Miscellaneous\n@@ -312,15 +335,11 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 // We do not support forking, so there is nothing to do here.\n                 this.write_null(dest)?;\n             }\n-            \"sched_yield\" => {\n-                this.write_null(dest)?;\n-            }\n \n             // Incomplete shims that we \"stub out\" just to get pre-main initialization code to work.\n             // These shims are enabled only when the caller is in the standard library.\n             | \"pthread_attr_init\"\n             | \"pthread_attr_destroy\"\n-            | \"pthread_self\"\n             | \"pthread_attr_setstacksize\"\n             | \"pthread_condattr_init\"\n             | \"pthread_condattr_setclock\"\n@@ -330,6 +349,15 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             => {\n                 this.write_null(dest)?;\n             }\n+            \"pthread_attr_getguardsize\" if this.frame().instance.to_string().starts_with(\"std::sys::unix::\")\n+            => {\n+                let guard_size = this.deref_operand(args[1])?;\n+                let guard_size_layout = this.libc_ty_layout(\"size_t\")?;\n+                this.write_scalar(Scalar::from_uint(crate::PAGE_SIZE, guard_size_layout.size), guard_size.into())?;\n+\n+                // Return success (`0`).\n+                this.write_null(dest)?;\n+            }\n \n             | \"signal\"\n             | \"sigaction\""}, {"sha": "eb58f7466089b2b3eaf14b5eecb249bb9d6c393a", "filename": "src/shims/foreign_items/posix/linux.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fposix%2Flinux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fposix%2Flinux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fforeign_items%2Fposix%2Flinux.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -75,6 +75,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 this.write_null(dest)?;\n             }\n \n+            // Threading\n+            \"prctl\" => {\n+                assert_eq!(args.len(), 5);\n+                let result = this.prctl(args[0], args[1], args[2], args[3], args[4])?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+\n             // Dynamically invoked syscalls\n             \"syscall\" => {\n                 let sys_getrandom = this"}, {"sha": "200b88f29c8f81f005cd09bfcb90aa9573c9f0c1", "filename": "src/shims/foreign_items/posix/macos.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fposix%2Fmacos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fposix%2Fmacos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fforeign_items%2Fposix%2Fmacos.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -82,7 +82,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 let dtor = this.read_scalar(args[0])?.not_undef()?;\n                 let dtor = this.memory.get_fn(dtor)?.as_instance()?;\n                 let data = this.read_scalar(args[1])?.not_undef()?;\n-                this.machine.tls.set_global_dtor(dtor, data)?;\n+                let active_thread = this.get_active_thread()?;\n+                this.machine.tls.set_thread_dtor(active_thread, dtor, data)?;\n             }\n \n             // Querying system information"}, {"sha": "a58444b21bff1d6bbd37a25e93f4b373a13aacda", "filename": "src/shims/foreign_items/windows.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fwindows.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fforeign_items%2Fwindows.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fforeign_items%2Fwindows.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -144,13 +144,15 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             }\n             \"TlsGetValue\" => {\n                 let key = u128::from(this.read_scalar(args[0])?.to_u32()?);\n-                let ptr = this.machine.tls.load_tls(key, this)?;\n+                let active_thread = this.get_active_thread()?;\n+                let ptr = this.machine.tls.load_tls(key, active_thread, this)?;\n                 this.write_scalar(ptr, dest)?;\n             }\n             \"TlsSetValue\" => {\n                 let key = u128::from(this.read_scalar(args[0])?.to_u32()?);\n+                let active_thread = this.get_active_thread()?;\n                 let new_ptr = this.read_scalar(args[1])?.not_undef()?;\n-                this.machine.tls.store_tls(key, this.test_null(new_ptr)?)?;\n+                this.machine.tls.store_tls(key, active_thread, this.test_null(new_ptr)?)?;\n \n                 // Return success (`1`).\n                 this.write_scalar(Scalar::from_i32(1), dest)?;"}, {"sha": "166d1a5456df1ab479c2da5380a0e1d1e0a199f4", "filename": "src/shims/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fmod.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -6,6 +6,7 @@ pub mod intrinsics;\n pub mod os_str;\n pub mod panic;\n pub mod sync;\n+pub mod thread;\n pub mod time;\n pub mod tls;\n "}, {"sha": "bc64b1e97a50e7e1d8db056f914dea3f219c29ed", "filename": "src/shims/sync.rs", "status": "modified", "additions": 283, "deletions": 161, "changes": 444, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fsync.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -1,7 +1,8 @@\n-use rustc_middle::ty::{TyKind, TypeAndMut};\n+use rustc_middle::ty::{layout::TyAndLayout, TyKind, TypeAndMut};\n use rustc_target::abi::{LayoutOf, Size};\n \n use crate::stacked_borrows::Tag;\n+use crate::thread::BlockSetId;\n use crate::*;\n \n fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n@@ -18,35 +19,56 @@ fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n     Ok(())\n }\n \n+fn get_at_offset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    op: OpTy<'tcx, Tag>,\n+    offset: u64,\n+    layout: TyAndLayout<'tcx>,\n+    min_size: u64,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the attr pointer is within bounds\n+    assert_ptr_target_min_size(ecx, op, min_size)?;\n+    let op_place = ecx.deref_operand(op)?;\n+    let value_place = op_place.offset(Size::from_bytes(offset), MemPlaceMeta::None, layout, ecx)?;\n+    ecx.read_scalar(value_place.into())\n+}\n+\n+fn set_at_offset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    op: OpTy<'tcx, Tag>,\n+    offset: u64,\n+    value: impl Into<ScalarMaybeUndef<Tag>>,\n+    layout: TyAndLayout<'tcx>,\n+    min_size: u64,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the attr pointer is within bounds\n+    assert_ptr_target_min_size(ecx, op, min_size)?;\n+    let op_place = ecx.deref_operand(op)?;\n+    let value_place = op_place.offset(Size::from_bytes(offset), MemPlaceMeta::None, layout, ecx)?;\n+    ecx.write_scalar(value.into(), value_place.into())\n+}\n+\n // pthread_mutexattr_t is either 4 or 8 bytes, depending on the platform.\n \n // Our chosen memory layout for emulation (does not have to match the platform layout!):\n // store an i32 in the first four bytes equal to the corresponding libc mutex kind constant\n // (e.g. PTHREAD_MUTEX_NORMAL).\n \n+const PTHREAD_MUTEXATTR_T_MIN_SIZE: u64 = 4;\n+\n fn mutexattr_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     attr_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the attr pointer is within bounds\n-    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n-    let attr_place = ecx.deref_operand(attr_op)?;\n-    let kind_place =\n-        attr_place.offset(Size::ZERO, MemPlaceMeta::None, ecx.machine.layouts.i32, ecx)?;\n-    ecx.read_scalar(kind_place.into())\n+    get_at_offset(ecx, attr_op, 0, ecx.machine.layouts.i32, PTHREAD_MUTEXATTR_T_MIN_SIZE)\n }\n \n fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     attr_op: OpTy<'tcx, Tag>,\n     kind: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the attr pointer is within bounds\n-    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n-    let attr_place = ecx.deref_operand(attr_op)?;\n-    let kind_place =\n-        attr_place.offset(Size::ZERO, MemPlaceMeta::None, ecx.machine.layouts.i32, ecx)?;\n-    ecx.write_scalar(kind.into(), kind_place.into())\n+    set_at_offset(ecx, attr_op, 0, kind, ecx.machine.layouts.i32, PTHREAD_MUTEXATTR_T_MIN_SIZE)\n }\n \n // pthread_mutex_t is between 24 and 48 bytes, depending on the platform.\n@@ -55,75 +77,90 @@ fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n // bytes 0-3: reserved for signature on macOS\n // (need to avoid this because it is set by static initializer macros)\n // bytes 4-7: count of how many times this mutex has been locked, as a u32\n+// bytes 8-11: when count > 0, id of the owner thread as a u32\n // bytes 12-15 or 16-19 (depending on platform): mutex kind, as an i32\n // (the kind has to be at its offset for compatibility with static initializer macros)\n+// bytes 20-23: when count > 0, id of the blockset in which the blocked threads\n+// are waiting or 0 if blockset is not yet assigned.\n+\n+const PTHREAD_MUTEX_T_MIN_SIZE: u64 = 24;\n \n fn mutex_get_locked_count<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let locked_count_place = mutex_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(locked_count_place.into())\n+    get_at_offset(ecx, mutex_op, 4, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n     locked_count: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let locked_count_place = mutex_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(locked_count.into(), locked_count_place.into())\n+    set_at_offset(ecx, mutex_op, 4, locked_count, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n+}\n+\n+fn mutex_get_owner<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    get_at_offset(ecx, mutex_op, 8, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n+}\n+\n+fn mutex_set_owner<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+    owner: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    set_at_offset(ecx, mutex_op, 8, owner, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n-    let kind_place = mutex_place.offset(\n-        Size::from_bytes(kind_offset),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.i32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(kind_place.into())\n+    let offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n+    get_at_offset(ecx, mutex_op, offset, ecx.machine.layouts.i32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_set_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n     kind: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n-    let kind_place = mutex_place.offset(\n-        Size::from_bytes(kind_offset),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.i32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(kind.into(), kind_place.into())\n+    let offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n+    set_at_offset(ecx, mutex_op, offset, kind, ecx.machine.layouts.i32, PTHREAD_MUTEX_T_MIN_SIZE)\n+}\n+\n+fn mutex_get_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    get_at_offset(ecx, mutex_op, 20, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n+}\n+\n+fn mutex_set_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+    blockset: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    set_at_offset(ecx, mutex_op, 20, blockset, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n+}\n+\n+fn mutex_get_or_create_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, BlockSetId> {\n+    let blockset = mutex_get_blockset(ecx, mutex_op)?.to_u32()?;\n+    if blockset == 0 {\n+        // 0 is a default value and also not a valid blockset id. Need to\n+        // allocate a new blockset.\n+        let blockset = ecx.create_blockset()?;\n+        mutex_set_blockset(ecx, mutex_op, blockset.to_u32_scalar())?;\n+        Ok(blockset)\n+    } else {\n+        Ok(BlockSetId::new(blockset))\n+    }\n }\n \n // pthread_rwlock_t is between 32 and 56 bytes, depending on the platform.\n@@ -133,71 +170,103 @@ fn mutex_set_kind<'mir, 'tcx: 'mir>(\n // (need to avoid this because it is set by static initializer macros)\n // bytes 4-7: reader count, as a u32\n // bytes 8-11: writer count, as a u32\n+// bytes 12-15: when writer or reader count > 0, id of the blockset in which the\n+// blocked writers are waiting or 0 if blockset is not yet assigned.\n+// bytes 16-20: when writer count > 0, id of the blockset in which the blocked\n+// readers are waiting or 0 if blockset is not yet assigned.\n+\n+const PTHREAD_RWLOCK_T_MIN_SIZE: u64 = 20;\n \n fn rwlock_get_readers<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let readers_place = rwlock_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(readers_place.into())\n+    get_at_offset(ecx, rwlock_op, 4, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_set_readers<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n     readers: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let readers_place = rwlock_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(readers.into(), readers_place.into())\n+    set_at_offset(ecx, rwlock_op, 4, readers, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_get_writers<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let writers_place = rwlock_place.offset(\n-        Size::from_bytes(8),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(writers_place.into())\n+    get_at_offset(ecx, rwlock_op, 8, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n     writers: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let writers_place = rwlock_place.offset(\n-        Size::from_bytes(8),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(writers.into(), writers_place.into())\n+    set_at_offset(ecx, rwlock_op, 8, writers, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+}\n+\n+fn rwlock_get_writer_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    get_at_offset(ecx, rwlock_op, 12, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+}\n+\n+fn rwlock_set_writer_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+    blockset: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    set_at_offset(ecx, rwlock_op, 12, blockset, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+}\n+\n+fn rwlock_get_or_create_writer_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, BlockSetId> {\n+    let blockset = rwlock_get_writer_blockset(ecx, rwlock_op)?.to_u32()?;\n+    if blockset == 0 {\n+        // 0 is a default value and also not a valid blockset id. Need to\n+        // allocate a new blockset.\n+        let blockset = ecx.create_blockset()?;\n+        rwlock_set_writer_blockset(ecx, rwlock_op, blockset.to_u32_scalar())?;\n+        Ok(blockset)\n+    } else {\n+        Ok(BlockSetId::new(blockset))\n+    }\n+}\n+\n+fn rwlock_get_reader_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    get_at_offset(ecx, rwlock_op, 16, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+}\n+\n+fn rwlock_set_reader_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+    blockset: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    set_at_offset(ecx, rwlock_op, 16, blockset, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+}\n+\n+fn rwlock_get_or_create_reader_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, BlockSetId> {\n+    let blockset = rwlock_get_reader_blockset(ecx, rwlock_op)?.to_u32()?;\n+    if blockset == 0 {\n+        // 0 is a default value and also not a valid blockset id. Need to\n+        // allocate a new blockset.\n+        let blockset = ecx.create_blockset()?;\n+        rwlock_set_reader_blockset(ecx, rwlock_op, blockset.to_u32_scalar())?;\n+        Ok(blockset)\n+    } else {\n+        Ok(BlockSetId::new(blockset))\n+    }\n }\n \n impl<'mir, 'tcx> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n@@ -265,31 +334,39 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n         let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n+        let active_thread = this.get_active_thread()?;\n \n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n-            if locked_count == 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n-                Ok(0)\n-            } else {\n-                throw_machine_stop!(TerminationInfo::Deadlock);\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n-            if locked_count == 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n+        if locked_count == 0 {\n+            // The mutex is unlocked. Let's lock it.\n+            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n+            mutex_set_owner(this, mutex_op, active_thread.to_u32_scalar())?;\n+            Ok(0)\n+        } else {\n+            // The mutex is locked. Let's check by whom.\n+            let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+            if owner_thread != active_thread {\n+                // Block the active thread.\n+                let blockset = mutex_get_or_create_blockset(this, mutex_op)?;\n+                this.block_active_thread(blockset)?;\n                 Ok(0)\n             } else {\n-                this.eval_libc_i32(\"EDEADLK\")\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-            match locked_count.checked_add(1) {\n-                Some(new_count) => {\n-                    mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                    Ok(0)\n+                // Trying to acquire the same mutex again.\n+                if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n+                    throw_machine_stop!(TerminationInfo::Deadlock);\n+                } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n+                    this.eval_libc_i32(\"EDEADLK\")\n+                } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n+                    match locked_count.checked_add(1) {\n+                        Some(new_count) => {\n+                            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n+                            Ok(0)\n+                        }\n+                        None => this.eval_libc_i32(\"EAGAIN\"),\n+                    }\n+                } else {\n+                    throw_ub_format!(\"called pthread_mutex_lock on an unsupported type of mutex\");\n                 }\n-                None => this.eval_libc_i32(\"EAGAIN\"),\n             }\n-        } else {\n-            throw_ub_format!(\"called pthread_mutex_lock on an unsupported type of mutex\");\n         }\n     }\n \n@@ -298,26 +375,36 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n         let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n+        let active_thread = this.get_active_thread()?;\n \n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?\n-            || kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?\n-        {\n-            if locked_count == 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n-                Ok(0)\n-            } else {\n+        if locked_count == 0 {\n+            // The mutex is unlocked. Let's lock it.\n+            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n+            mutex_set_owner(this, mutex_op, active_thread.to_u32_scalar())?;\n+            Ok(0)\n+        } else {\n+            let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+            if owner_thread != active_thread {\n                 this.eval_libc_i32(\"EBUSY\")\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-            match locked_count.checked_add(1) {\n-                Some(new_count) => {\n-                    mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                    Ok(0)\n+            } else {\n+                if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?\n+                    || kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?\n+                {\n+                    this.eval_libc_i32(\"EBUSY\")\n+                } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n+                    match locked_count.checked_add(1) {\n+                        Some(new_count) => {\n+                            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n+                            Ok(0)\n+                        }\n+                        None => this.eval_libc_i32(\"EAGAIN\"),\n+                    }\n+                } else {\n+                    throw_ub_format!(\n+                        \"called pthread_mutex_trylock on an unsupported type of mutex\"\n+                    );\n                 }\n-                None => this.eval_libc_i32(\"EAGAIN\"),\n             }\n-        } else {\n-            throw_ub_format!(\"called pthread_mutex_trylock on an unsupported type of mutex\");\n         }\n     }\n \n@@ -326,34 +413,41 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n         let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n-\n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n-            if locked_count != 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(0))?;\n-                Ok(0)\n+        let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+\n+        if owner_thread != this.get_active_thread()? {\n+            throw_ub_format!(\"called pthread_mutex_unlock on a mutex owned by another thread\");\n+        } else if locked_count == 1 {\n+            let blockset = mutex_get_or_create_blockset(this, mutex_op)?;\n+            if let Some(new_owner) = this.unblock_some_thread(blockset)? {\n+                // We have at least one thread waiting on this mutex. Transfer\n+                // ownership to it.\n+                mutex_set_owner(this, mutex_op, new_owner.to_u32_scalar())?;\n             } else {\n-                throw_ub_format!(\"unlocked a PTHREAD_MUTEX_NORMAL mutex that was not locked\");\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n-            if locked_count != 0 {\n+                // No thread is waiting on this mutex.\n+                mutex_set_owner(this, mutex_op, Scalar::from_u32(0))?;\n                 mutex_set_locked_count(this, mutex_op, Scalar::from_u32(0))?;\n-                Ok(0)\n-            } else {\n-                this.eval_libc_i32(\"EPERM\")\n             }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-            match locked_count.checked_sub(1) {\n-                Some(new_count) => {\n-                    mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                    Ok(0)\n-                }\n-                None => {\n-                    // locked_count was already zero\n-                    this.eval_libc_i32(\"EPERM\")\n+            Ok(0)\n+        } else {\n+            if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n+                throw_ub_format!(\"unlocked a PTHREAD_MUTEX_NORMAL mutex that was not locked\");\n+            } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n+                this.eval_libc_i32(\"EPERM\")\n+            } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n+                match locked_count.checked_sub(1) {\n+                    Some(new_count) => {\n+                        mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n+                        Ok(0)\n+                    }\n+                    None => {\n+                        // locked_count was already zero\n+                        this.eval_libc_i32(\"EPERM\")\n+                    }\n                 }\n+            } else {\n+                throw_ub_format!(\"called pthread_mutex_unlock on an unsupported type of mutex\");\n             }\n-        } else {\n-            throw_ub_format!(\"called pthread_mutex_unlock on an unsupported type of mutex\");\n         }\n     }\n \n@@ -366,6 +460,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         mutex_set_kind(this, mutex_op, ScalarMaybeUndef::Undef)?;\n         mutex_set_locked_count(this, mutex_op, ScalarMaybeUndef::Undef)?;\n+        mutex_set_blockset(this, mutex_op, ScalarMaybeUndef::Undef)?;\n \n         Ok(0)\n     }\n@@ -375,8 +470,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n         let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n+\n         if writers != 0 {\n-            throw_machine_stop!(TerminationInfo::Deadlock);\n+            // The lock is locked by a writer.\n+            assert_eq!(writers, 1);\n+            let reader_blockset = rwlock_get_or_create_reader_blockset(this, rwlock_op)?;\n+            this.block_active_thread(reader_blockset)?;\n+            Ok(0)\n         } else {\n             match readers.checked_add(1) {\n                 Some(new_readers) => {\n@@ -411,14 +511,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n         let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n-        if readers != 0 {\n-            throw_machine_stop!(TerminationInfo::Deadlock);\n-        } else if writers != 0 {\n-            throw_machine_stop!(TerminationInfo::Deadlock);\n+        let writer_blockset = rwlock_get_or_create_writer_blockset(this, rwlock_op)?;\n+        if readers != 0 || writers != 0 {\n+            this.block_active_thread(writer_blockset)?;\n         } else {\n             rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n-            Ok(0)\n         }\n+        Ok(0)\n     }\n \n     fn pthread_rwlock_trywrlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n@@ -434,16 +533,37 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         }\n     }\n \n+    // FIXME: We should check that this lock was locked by the active thread.\n     fn pthread_rwlock_unlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n         let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n         let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n+        let writer_blockset = rwlock_get_or_create_writer_blockset(this, rwlock_op)?;\n         if let Some(new_readers) = readers.checked_sub(1) {\n+            assert_eq!(writers, 0);\n             rwlock_set_readers(this, rwlock_op, Scalar::from_u32(new_readers))?;\n+            if new_readers == 0 {\n+                if let Some(_writer) = this.unblock_some_thread(writer_blockset)? {\n+                    rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n+                }\n+            }\n             Ok(0)\n         } else if writers != 0 {\n-            rwlock_set_writers(this, rwlock_op, Scalar::from_u32(0))?;\n+            let reader_blockset = rwlock_get_or_create_reader_blockset(this, rwlock_op)?;\n+            // We are prioritizing writers here against the readers. As a\n+            // result, not only readers can starve writers, but also writers can\n+            // starve readers.\n+            if let Some(_writer) = this.unblock_some_thread(writer_blockset)? {\n+                assert_eq!(writers, 1);\n+            } else {\n+                rwlock_set_writers(this, rwlock_op, Scalar::from_u32(0))?;\n+                let mut readers = 0;\n+                while let Some(_reader) = this.unblock_some_thread(reader_blockset)? {\n+                    readers += 1;\n+                }\n+                rwlock_set_readers(this, rwlock_op, Scalar::from_u32(readers))?\n+            }\n             Ok(0)\n         } else {\n             throw_ub_format!(\"unlocked an rwlock that was not locked\");\n@@ -461,6 +581,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         rwlock_set_readers(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n         rwlock_set_writers(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n+        rwlock_set_reader_blockset(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n+        rwlock_set_writer_blockset(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n \n         Ok(0)\n     }"}, {"sha": "2f553c1c729e85629a930ae399112834ba38a86b", "filename": "src/shims/thread.rs", "status": "added", "additions": 128, "deletions": 0, "changes": 128, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fthread.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,128 @@\n+use std::convert::TryInto;\n+\n+use crate::*;\n+use rustc_target::abi::LayoutOf;\n+\n+impl<'mir, 'tcx> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n+pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n+    fn pthread_create(\n+        &mut self,\n+        thread: OpTy<'tcx, Tag>,\n+        _attr: OpTy<'tcx, Tag>,\n+        start_routine: OpTy<'tcx, Tag>,\n+        arg: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        this.tcx.sess.warn(\n+            \"thread support is experimental. \\\n+             For example, Miri does not detect data races yet.\",\n+        );\n+\n+        let new_thread_id = this.create_thread()?;\n+        // Also switch to new thread so that we can push the first stackframe.\n+        let old_thread_id = this.set_active_thread(new_thread_id)?;\n+\n+        let thread_info_place = this.deref_operand(thread)?;\n+        this.write_scalar(\n+            Scalar::from_uint(new_thread_id.to_u32(), thread_info_place.layout.size),\n+            thread_info_place.into(),\n+        )?;\n+\n+        let fn_ptr = this.read_scalar(start_routine)?.not_undef()?;\n+        let instance = this.memory.get_fn(fn_ptr)?.as_instance()?;\n+\n+        let func_arg = this.read_immediate(arg)?;\n+\n+        // Note: the returned value is currently ignored (see the FIXME in\n+        // pthread_join below) because the Rust standard library does not use\n+        // it.\n+        let ret_place =\n+            this.allocate(this.layout_of(this.tcx.types.usize)?, MiriMemoryKind::Machine.into());\n+\n+        this.call_function(\n+            instance,\n+            &[*func_arg],\n+            Some(ret_place.into()),\n+            StackPopCleanup::None { cleanup: true },\n+        )?;\n+\n+        this.set_active_thread(old_thread_id)?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_join(\n+        &mut self,\n+        thread: OpTy<'tcx, Tag>,\n+        retval: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        if !this.is_null(this.read_scalar(retval)?.not_undef()?)? {\n+            // FIXME: implement reading the thread function's return place.\n+            throw_unsup_format!(\"Miri supports pthread_join only with retval==NULL\");\n+        }\n+\n+        let thread_id = this.read_scalar(thread)?.to_machine_usize(this)?;\n+        this.join_thread(thread_id.try_into().expect(\"thread ID should fit in u32\"))?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_detach(&mut self, thread: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let thread_id = this.read_scalar(thread)?.to_machine_usize(this)?;\n+        this.detach_thread(thread_id.try_into().expect(\"thread ID should fit in u32\"))?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_self(&mut self, dest: PlaceTy<'tcx, Tag>) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        let thread_id = this.get_active_thread()?;\n+        this.write_scalar(Scalar::from_uint(thread_id.to_u32(), dest.layout.size), dest)\n+    }\n+\n+    fn prctl(\n+        &mut self,\n+        option: OpTy<'tcx, Tag>,\n+        arg2: OpTy<'tcx, Tag>,\n+        _arg3: OpTy<'tcx, Tag>,\n+        _arg4: OpTy<'tcx, Tag>,\n+        _arg5: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let option = this.read_scalar(option)?.to_i32()?;\n+        if option == this.eval_libc_i32(\"PR_SET_NAME\")? {\n+            let address = this.read_scalar(arg2)?.not_undef()?;\n+            let mut name = this.memory.read_c_str(address)?.to_owned();\n+            // The name should be no more than 16 bytes, including the null\n+            // byte. Since `read_c_str` returns the string without the null\n+            // byte, we need to truncate to 15.\n+            name.truncate(15);\n+            this.set_active_thread_name(name)?;\n+        } else if option == this.eval_libc_i32(\"PR_GET_NAME\")? {\n+            let address = this.read_scalar(arg2)?.not_undef()?;\n+            let mut name = this.get_active_thread_name()?.to_vec();\n+            name.push(0u8);\n+            assert!(name.len() <= 16);\n+            this.memory.write_bytes(address, name)?;\n+        } else {\n+            throw_unsup_format!(\"unsupported prctl option {}\", option);\n+        }\n+\n+        Ok(0)\n+    }\n+\n+    fn sched_yield(&mut self) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        this.yield_active_thread()?;\n+\n+        Ok(0)\n+    }\n+}"}, {"sha": "f78b46ec3e7f0d340db3749618d7d9fb2e645200", "filename": "src/shims/tls.rs", "status": "modified", "additions": 221, "deletions": 77, "changes": 298, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Ftls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fshims%2Ftls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Ftls.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -1,25 +1,38 @@\n //! Implement thread-local storage.\n \n use std::collections::BTreeMap;\n+use std::collections::btree_map::Entry as BTreeEntry;\n+use std::collections::hash_map::Entry as HashMapEntry;\n \n use log::trace;\n \n+use rustc_data_structures::fx::FxHashMap;\n use rustc_middle::ty;\n use rustc_target::abi::{Size, HasDataLayout};\n \n-use crate::{HelpersEvalContextExt, InterpResult, MPlaceTy, Scalar, StackPopCleanup, Tag};\n+use crate::{\n+    HelpersEvalContextExt, InterpResult, MPlaceTy, Scalar, StackPopCleanup, Tag, ThreadId,\n+    ThreadsEvalContextExt,\n+};\n \n pub type TlsKey = u128;\n \n-#[derive(Copy, Clone, Debug)]\n+#[derive(Clone, Debug)]\n pub struct TlsEntry<'tcx> {\n     /// The data for this key. None is used to represent NULL.\n     /// (We normalize this early to avoid having to do a NULL-ptr-test each time we access the data.)\n-    /// Will eventually become a map from thread IDs to `Scalar`s, if we ever support more than one thread.\n-    data: Option<Scalar<Tag>>,\n+    data: BTreeMap<ThreadId, Scalar<Tag>>,\n     dtor: Option<ty::Instance<'tcx>>,\n }\n \n+#[derive(Clone, Debug)]\n+struct RunningDtorsState {\n+    /// The last TlsKey used to retrieve a TLS destructor. `None` means that we\n+    /// have not tried to retrieve a TLS destructor yet or that we already tried\n+    /// all keys.\n+    last_dtor_key: Option<TlsKey>,\n+}\n+\n #[derive(Debug)]\n pub struct TlsData<'tcx> {\n     /// The Key to use for the next thread-local allocation.\n@@ -28,20 +41,23 @@ pub struct TlsData<'tcx> {\n     /// pthreads-style thread-local storage.\n     keys: BTreeMap<TlsKey, TlsEntry<'tcx>>,\n \n-    /// A single global dtor (that's how things work on macOS) with a data argument.\n-    global_dtor: Option<(ty::Instance<'tcx>, Scalar<Tag>)>,\n+    /// A single per thread destructor of the thread local storage (that's how\n+    /// things work on macOS) with a data argument.\n+    macos_thread_dtors: BTreeMap<ThreadId, (ty::Instance<'tcx>, Scalar<Tag>)>,\n \n-    /// Whether we are in the \"destruct\" phase, during which some operations are UB.\n-    dtors_running: bool,\n+    /// State for currently running TLS dtors. If this map contains a key for a\n+    /// specific thread, it means that we are in the \"destruct\" phase, during\n+    /// which some operations are UB.\n+    dtors_running: FxHashMap<ThreadId, RunningDtorsState>,\n }\n \n impl<'tcx> Default for TlsData<'tcx> {\n     fn default() -> Self {\n         TlsData {\n             next_key: 1, // start with 1 as we must not use 0 on Windows\n             keys: Default::default(),\n-            global_dtor: None,\n-            dtors_running: false,\n+            macos_thread_dtors: Default::default(),\n+            dtors_running: Default::default(),\n         }\n     }\n }\n@@ -52,7 +68,7 @@ impl<'tcx> TlsData<'tcx> {\n     pub fn create_tls_key(&mut self, dtor: Option<ty::Instance<'tcx>>, max_size: Size) -> InterpResult<'tcx, TlsKey> {\n         let new_key = self.next_key;\n         self.next_key += 1;\n-        self.keys.insert(new_key, TlsEntry { data: None, dtor }).unwrap_none();\n+        self.keys.insert(new_key, TlsEntry { data: Default::default(), dtor }).unwrap_none();\n         trace!(\"New TLS key allocated: {} with dtor {:?}\", new_key, dtor);\n \n         if max_size.bits() < 128 && new_key >= (1u128 << max_size.bits() as u128) {\n@@ -74,38 +90,65 @@ impl<'tcx> TlsData<'tcx> {\n     pub fn load_tls(\n         &self,\n         key: TlsKey,\n+        thread_id: ThreadId,\n         cx: &impl HasDataLayout,\n     ) -> InterpResult<'tcx, Scalar<Tag>> {\n         match self.keys.get(&key) {\n-            Some(&TlsEntry { data, .. }) => {\n-                trace!(\"TLS key {} loaded: {:?}\", key, data);\n-                Ok(data.unwrap_or_else(|| Scalar::null_ptr(cx).into()))\n+            Some(TlsEntry { data, .. }) => {\n+                let value = data.get(&thread_id).copied();\n+                trace!(\"TLS key {} for thread {:?} loaded: {:?}\", key, thread_id, value);\n+                Ok(value.unwrap_or_else(|| Scalar::null_ptr(cx).into()))\n             }\n             None => throw_ub_format!(\"loading from a non-existing TLS key: {}\", key),\n         }\n     }\n \n-    pub fn store_tls(&mut self, key: TlsKey, new_data: Option<Scalar<Tag>>) -> InterpResult<'tcx> {\n+    pub fn store_tls(\n+        &mut self,\n+        key: TlsKey,\n+        thread_id: ThreadId,\n+        new_data: Option<Scalar<Tag>>\n+    ) -> InterpResult<'tcx> {\n         match self.keys.get_mut(&key) {\n             Some(TlsEntry { data, .. }) => {\n-                trace!(\"TLS key {} stored: {:?}\", key, new_data);\n-                *data = new_data;\n+                match new_data {\n+                    Some(scalar) => {\n+                        trace!(\"TLS key {} for thread {:?} stored: {:?}\", key, thread_id, scalar);\n+                        data.insert(thread_id, scalar);\n+                    }\n+                    None => {\n+                        trace!(\"TLS key {} for thread {:?} removed\", key, thread_id);\n+                        data.remove(&thread_id);\n+                    }\n+                }\n                 Ok(())\n             }\n             None => throw_ub_format!(\"storing to a non-existing TLS key: {}\", key),\n         }\n     }\n \n-    pub fn set_global_dtor(&mut self, dtor: ty::Instance<'tcx>, data: Scalar<Tag>) -> InterpResult<'tcx> {\n-        if self.dtors_running {\n+    /// Set the thread wide destructor of the thread local storage for the given\n+    /// thread. This function is used to implement `_tlv_atexit` shim on MacOS.\n+    ///\n+    /// Thread wide dtors are available only on MacOS. There is one destructor\n+    /// per thread as can be guessed from the following comment in the\n+    /// [`_tlv_atexit`\n+    /// implementation](https://github.com/opensource-apple/dyld/blob/195030646877261f0c8c7ad8b001f52d6a26f514/src/threadLocalVariables.c#L389):\n+    ///\n+    ///     // NOTE: this does not need locks because it only operates on current thread data\n+    pub fn set_thread_dtor(\n+        &mut self,\n+        thread: ThreadId,\n+        dtor: ty::Instance<'tcx>,\n+        data: Scalar<Tag>\n+    ) -> InterpResult<'tcx> {\n+        if self.dtors_running.contains_key(&thread) {\n             // UB, according to libstd docs.\n-            throw_ub_format!(\"setting global destructor while destructors are already running\");\n+            throw_ub_format!(\"setting thread's local storage destructor while destructors are already running\");\n         }\n-        if self.global_dtor.is_some() {\n-            throw_unsup_format!(\"setting more than one global destructor is not supported\");\n+        if self.macos_thread_dtors.insert(thread, (dtor, data)).is_some() {\n+            throw_unsup_format!(\"setting more than one thread local storage destructor for the same thread is not supported\");\n         }\n-\n-        self.global_dtor = Some((dtor, data));\n         Ok(())\n     }\n \n@@ -131,6 +174,7 @@ impl<'tcx> TlsData<'tcx> {\n     fn fetch_tls_dtor(\n         &mut self,\n         key: Option<TlsKey>,\n+        thread_id: ThreadId,\n     ) -> Option<(ty::Instance<'tcx>, Scalar<Tag>, TlsKey)> {\n         use std::collections::Bound::*;\n \n@@ -142,54 +186,85 @@ impl<'tcx> TlsData<'tcx> {\n         for (&key, TlsEntry { data, dtor }) in\n             thread_local.range_mut((start, Unbounded))\n         {\n-            if let Some(data_scalar) = *data {\n-                if let Some(dtor) = dtor {\n-                    let ret = Some((*dtor, data_scalar, key));\n-                    *data = None;\n-                    return ret;\n+            match data.entry(thread_id) {\n+                BTreeEntry::Occupied(entry) => {\n+                    if let Some(dtor) = dtor {\n+                        // Set TLS data to NULL, and call dtor with old value.\n+                        let data_scalar = entry.remove();\n+                        let ret = Some((*dtor, data_scalar, key));\n+                        return ret;\n+                    }\n                 }\n+                BTreeEntry::Vacant(_) => {}\n             }\n         }\n         None\n     }\n-}\n \n-impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n-pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n-    fn run_tls_dtors(&mut self) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-        assert!(!this.machine.tls.dtors_running, \"running TLS dtors twice\");\n-        this.machine.tls.dtors_running = true;\n-\n-        if this.tcx.sess.target.target.target_os == \"windows\" {\n-            // Windows has a special magic linker section that is run on certain events.\n-            // Instead of searching for that section and supporting arbitrary hooks in there\n-            // (that would be basically https://github.com/rust-lang/miri/issues/450),\n-            // we specifically look up the static in libstd that we know is placed\n-            // in that section.\n-            let thread_callback = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"thread_local\", \"p_thread_callback\"])?;\n-            let thread_callback = this.memory.get_fn(thread_callback.not_undef()?)?.as_instance()?;\n-\n-            // The signature of this function is `unsafe extern \"system\" fn(h: c::LPVOID, dwReason: c::DWORD, pv: c::LPVOID)`.\n-            let reason = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"c\", \"DLL_PROCESS_DETACH\"])?;\n-            let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n-            this.call_function(\n-                thread_callback,\n-                &[Scalar::null_ptr(this).into(), reason.into(), Scalar::null_ptr(this).into()],\n-                Some(ret_place),\n-                StackPopCleanup::None { cleanup: true },\n-            )?;\n-\n-            // step until out of stackframes\n-            this.run()?;\n+    /// Set that dtors are running for `thread`. It is guaranteed not to change\n+    /// the existing values stored in `dtors_running` for this thread. Returns\n+    /// `true` if dtors for `thread` are already running.\n+    fn set_dtors_running_for_thread(&mut self, thread: ThreadId) -> bool {\n+        match self.dtors_running.entry(thread) {\n+            HashMapEntry::Occupied(_) => true,\n+            HashMapEntry::Vacant(entry) => {\n+                // We cannot just do `self.dtors_running.insert` because that\n+                // would overwrite `last_dtor_key` with `None`.\n+                entry.insert(RunningDtorsState { last_dtor_key: None });\n+                false\n+            }\n+        }\n+    }\n \n-            // Windows doesn't have other destructors.\n-            return Ok(());\n+    /// Delete all TLS entries for the given thread. This function should be\n+    /// called after all TLS destructors have already finished.\n+    fn delete_all_thread_tls(&mut self, thread_id: ThreadId) {\n+        for TlsEntry { data, .. } in self.keys.values_mut() {\n+            data.remove(&thread_id);\n         }\n+    }\n+}\n \n-        // The macOS global dtor runs \"before any TLS slots get freed\", so do that first.\n-        if let Some((instance, data)) = this.machine.tls.global_dtor {\n-            trace!(\"Running global dtor {:?} on {:?}\", instance, data);\n+impl<'mir, 'tcx: 'mir> EvalContextPrivExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n+trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n+    /// Schedule TLS destructors for the main thread on Windows. The\n+    /// implementation assumes that we do not support concurrency on Windows\n+    /// yet.\n+    fn schedule_windows_tls_dtors(&mut self) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        let active_thread = this.get_active_thread()?;\n+        assert_eq!(this.get_total_thread_count()?, 1, \"concurrency on Windows not supported\");\n+        // Windows has a special magic linker section that is run on certain events.\n+        // Instead of searching for that section and supporting arbitrary hooks in there\n+        // (that would be basically https://github.com/rust-lang/miri/issues/450),\n+        // we specifically look up the static in libstd that we know is placed\n+        // in that section.\n+        let thread_callback = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"thread_local\", \"p_thread_callback\"])?;\n+        let thread_callback = this.memory.get_fn(thread_callback.not_undef()?)?.as_instance()?;\n+\n+        // The signature of this function is `unsafe extern \"system\" fn(h: c::LPVOID, dwReason: c::DWORD, pv: c::LPVOID)`.\n+        let reason = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"c\", \"DLL_THREAD_DETACH\"])?;\n+        let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n+        this.call_function(\n+            thread_callback,\n+            &[Scalar::null_ptr(this).into(), reason.into(), Scalar::null_ptr(this).into()],\n+            Some(ret_place),\n+            StackPopCleanup::None { cleanup: true },\n+        )?;\n+\n+        this.enable_thread(active_thread)?;\n+        Ok(())\n+    }\n+\n+    /// Schedule the MacOS thread destructor of the thread local storage to be\n+    /// executed. Returns `true` if scheduled.\n+    ///\n+    /// Note: It is safe to call this function also on other Unixes.\n+    fn schedule_macos_tls_dtor(&mut self) -> InterpResult<'tcx, bool> {\n+        let this = self.eval_context_mut();\n+        let thread_id = this.get_active_thread()?;\n+        if let Some((instance, data)) = this.machine.tls.macos_thread_dtors.remove(&thread_id) {\n+            trace!(\"Running macos dtor {:?} on {:?} at {:?}\", instance, data, thread_id);\n \n             let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n             this.call_function(\n@@ -199,14 +274,36 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 StackPopCleanup::None { cleanup: true },\n             )?;\n \n-            // step until out of stackframes\n-            this.run()?;\n+            // Enable the thread so that it steps through the destructor which\n+            // we just scheduled. Since we deleted the destructor, it is\n+            // guaranteed that we will schedule it again. The `dtors_running`\n+            // flag will prevent the code from adding the destructor again.\n+            this.enable_thread(thread_id)?;\n+            Ok(true)\n+        } else {\n+            Ok(false)\n         }\n+    }\n \n-        // Now run the \"keyed\" destructors.\n-        let mut dtor = this.machine.tls.fetch_tls_dtor(None);\n-        while let Some((instance, ptr, key)) = dtor {\n-            trace!(\"Running TLS dtor {:?} on {:?}\", instance, ptr);\n+    /// Schedule a pthread TLS destructor. Returns `true` if found\n+    /// a destructor to schedule, and `false` otherwise.\n+    fn schedule_next_pthread_tls_dtor(&mut self) -> InterpResult<'tcx, bool> {\n+        let this = self.eval_context_mut();\n+        let active_thread = this.get_active_thread()?;\n+\n+        assert!(this.has_terminated(active_thread)?, \"running TLS dtors for non-terminated thread\");\n+        // Fetch next dtor after `key`.\n+        let last_key = this.machine.tls.dtors_running[&active_thread].last_dtor_key.clone();\n+        let dtor = match this.machine.tls.fetch_tls_dtor(last_key, active_thread) {\n+            dtor @ Some(_) => dtor,\n+            // We ran each dtor once, start over from the beginning.\n+            None => {\n+                this.machine.tls.fetch_tls_dtor(None, active_thread)\n+            }\n+        };\n+        if let Some((instance, ptr, key)) = dtor {\n+            this.machine.tls.dtors_running.get_mut(&active_thread).unwrap().last_dtor_key = Some(key);\n+            trace!(\"Running TLS dtor {:?} on {:?} at {:?}\", instance, ptr, active_thread);\n             assert!(!this.is_null(ptr).unwrap(), \"data can't be NULL when dtor is called!\");\n \n             let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n@@ -217,16 +314,63 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 StackPopCleanup::None { cleanup: true },\n             )?;\n \n-            // step until out of stackframes\n-            this.run()?;\n+            this.enable_thread(active_thread)?;\n+            return Ok(true);\n+        }\n+        this.machine.tls.dtors_running.get_mut(&active_thread).unwrap().last_dtor_key = None;\n \n-            // Fetch next dtor after `key`.\n-            dtor = match this.machine.tls.fetch_tls_dtor(Some(key)) {\n-                dtor @ Some(_) => dtor,\n-                // We ran each dtor once, start over from the beginning.\n-                None => this.machine.tls.fetch_tls_dtor(None),\n-            };\n+        Ok(false)\n+    }\n+}\n+\n+impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n+pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n+\n+    /// Schedule an active thread's TLS destructor to run on the active thread.\n+    /// Note that this function does not run the destructors itself, it just\n+    /// schedules them one by one each time it is called and reenables the\n+    /// thread so that it can be executed normally by the main execution loop.\n+    ///\n+    /// FIXME: we do not support yet deallocation of thread local statics.\n+    /// Issue: https://github.com/rust-lang/miri/issues/1369\n+    ///\n+    /// Note: we consistently run TLS destructors for all threads, including the\n+    /// main thread. However, it is not clear that we should run the TLS\n+    /// destructors for the main thread. See issue:\n+    /// https://github.com/rust-lang/rust/issues/28129.\n+    fn schedule_next_tls_dtor_for_active_thread(&mut self) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        let active_thread = this.get_active_thread()?;\n+\n+        if !this.machine.tls.set_dtors_running_for_thread(active_thread) {\n+            // This is the first time we got asked to schedule a destructor. The\n+            // Windows schedule destructor function must be called exactly once,\n+            // this is why it is in this block.\n+            if this.tcx.sess.target.target.target_os == \"windows\" {\n+                // On Windows, we signal that the thread quit by starting the\n+                // relevant function, reenabling the thread, and going back to\n+                // the scheduler.\n+                this.schedule_windows_tls_dtors()?;\n+                return Ok(())\n+            }\n+        }\n+        // The macOS thread wide destructor runs \"before any TLS slots get\n+        // freed\", so do that first.\n+        if this.schedule_macos_tls_dtor()? {\n+            // We have scheduled a MacOS dtor to run on the thread. Execute it\n+            // to completion and come back here. Scheduling a destructor\n+            // destroys it, so we will not enter this branch again.\n+            return Ok(())\n         }\n+        if this.schedule_next_pthread_tls_dtor()? {\n+            // We have scheduled a pthread destructor and removed it from the\n+            // destructors list. Run it to completion and come back here.\n+            return Ok(())\n+        }\n+\n+        // All dtors done!\n+        this.machine.tls.delete_all_thread_tls(active_thread);\n+\n         Ok(())\n     }\n }"}, {"sha": "376920e225ba7f5d4cfc95e0b1cc5eea59bc83c7", "filename": "src/thread.rs", "status": "added", "additions": 611, "deletions": 0, "changes": 611, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/src%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fthread.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,611 @@\n+//! Implements threads.\n+\n+use std::cell::RefCell;\n+use std::convert::TryFrom;\n+use std::num::{NonZeroU32, TryFromIntError};\n+\n+use log::trace;\n+\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_hir::def_id::DefId;\n+use rustc_index::vec::{Idx, IndexVec};\n+use rustc_middle::{\n+    middle::codegen_fn_attrs::CodegenFnAttrFlags,\n+    mir,\n+    ty::{self, Instance},\n+};\n+\n+use crate::*;\n+\n+#[derive(Clone, Copy, Debug, PartialEq, Eq)]\n+pub enum SchedulingAction {\n+    /// Execute step on the active thread.\n+    ExecuteStep,\n+    /// Execute destructors of the active thread.\n+    ExecuteDtors,\n+    /// Stop the program.\n+    Stop,\n+}\n+\n+/// A thread identifier.\n+#[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n+pub struct ThreadId(u32);\n+\n+/// The main thread. When it terminates, the whole application terminates.\n+const MAIN_THREAD: ThreadId = ThreadId(0);\n+\n+impl ThreadId {\n+    pub fn to_u32(self) -> u32 {\n+        self.0\n+    }\n+}\n+\n+impl Idx for ThreadId {\n+    fn new(idx: usize) -> Self {\n+        ThreadId(u32::try_from(idx).unwrap())\n+    }\n+\n+    fn index(self) -> usize {\n+        usize::try_from(self.0).unwrap()\n+    }\n+}\n+\n+impl TryFrom<u64> for ThreadId {\n+    type Error = TryFromIntError;\n+    fn try_from(id: u64) -> Result<Self, Self::Error> {\n+        u32::try_from(id).map(|id_u32| Self(id_u32))\n+    }\n+}\n+\n+impl From<u32> for ThreadId {\n+    fn from(id: u32) -> Self {\n+        Self(id)\n+    }\n+}\n+\n+impl ThreadId {\n+    pub fn to_u32_scalar<'tcx>(&self) -> Scalar<Tag> {\n+        Scalar::from_u32(u32::try_from(self.0).unwrap())\n+    }\n+}\n+\n+/// An identifier of a set of blocked threads. 0 is used to indicate the absence\n+/// of a blockset identifier and, therefore, is not a valid identifier.\n+#[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n+pub struct BlockSetId(NonZeroU32);\n+\n+impl BlockSetId {\n+    /// Panics if `id` is 0.\n+    pub fn new(id: u32) -> Self {\n+        Self(NonZeroU32::new(id).expect(\"0 is not a valid blockset id\"))\n+    }\n+    pub fn to_u32_scalar<'tcx>(&self) -> Scalar<Tag> {\n+        Scalar::from_u32(self.0.get())\n+    }\n+}\n+\n+/// The state of a thread.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq)]\n+pub enum ThreadState {\n+    /// The thread is enabled and can be executed.\n+    Enabled,\n+    /// The thread tried to join the specified thread and is blocked until that\n+    /// thread terminates.\n+    BlockedOnJoin(ThreadId),\n+    /// The thread is blocked and belongs to the given blockset.\n+    Blocked(BlockSetId),\n+    /// The thread has terminated its execution (we do not delete terminated\n+    /// threads).\n+    Terminated,\n+}\n+\n+/// The join status of a thread.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq)]\n+enum ThreadJoinStatus {\n+    /// The thread can be joined.\n+    Joinable,\n+    /// A thread is detached if its join handle was destroyed and no other\n+    /// thread can join it.\n+    Detached,\n+    /// The thread was already joined by some thread and cannot be joined again.\n+    Joined,\n+}\n+\n+/// A thread.\n+pub struct Thread<'mir, 'tcx> {\n+    state: ThreadState,\n+    /// Name of the thread.\n+    thread_name: Option<Vec<u8>>,\n+    /// The virtual call stack.\n+    stack: Vec<Frame<'mir, 'tcx, Tag, FrameData<'tcx>>>,\n+    /// The join status.\n+    join_status: ThreadJoinStatus,\n+}\n+\n+impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n+    /// Check if the thread is done executing (no more stack frames). If yes,\n+    /// change the state to terminated and return `true`.\n+    fn check_terminated(&mut self) -> bool {\n+        if self.state == ThreadState::Enabled {\n+            if self.stack.is_empty() {\n+                self.state = ThreadState::Terminated;\n+                return true;\n+            }\n+        }\n+        false\n+    }\n+}\n+\n+impl<'mir, 'tcx> std::fmt::Debug for Thread<'mir, 'tcx> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        if let Some(ref name) = self.thread_name {\n+            write!(f, \"{}\", String::from_utf8_lossy(name))?;\n+        } else {\n+            write!(f, \"<unnamed>\")?;\n+        }\n+        write!(f, \"({:?}, {:?})\", self.state, self.join_status)\n+    }\n+}\n+\n+impl<'mir, 'tcx> Default for Thread<'mir, 'tcx> {\n+    fn default() -> Self {\n+        Self {\n+            state: ThreadState::Enabled,\n+            thread_name: None,\n+            stack: Vec::new(),\n+            join_status: ThreadJoinStatus::Joinable,\n+        }\n+    }\n+}\n+\n+/// A set of threads.\n+#[derive(Debug)]\n+pub struct ThreadManager<'mir, 'tcx> {\n+    /// Identifier of the currently active thread.\n+    active_thread: ThreadId,\n+    /// Threads used in the program.\n+    ///\n+    /// Note that this vector also contains terminated threads.\n+    threads: IndexVec<ThreadId, Thread<'mir, 'tcx>>,\n+    /// A counter used to generate unique identifiers for blocksets.\n+    blockset_counter: u32,\n+    /// A mapping from a thread-local static to an allocation id of a thread\n+    /// specific allocation.\n+    thread_local_alloc_ids: RefCell<FxHashMap<(DefId, ThreadId), AllocId>>,\n+    /// A flag that indicates that we should change the active thread.\n+    yield_active_thread: bool,\n+}\n+\n+impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n+    fn default() -> Self {\n+        let mut threads = IndexVec::new();\n+        // Create the main thread and add it to the list of threads.\n+        let mut main_thread = Thread::default();\n+        // The main thread can *not* be joined on.\n+        main_thread.join_status = ThreadJoinStatus::Detached;\n+        threads.push(main_thread);\n+        Self {\n+            active_thread: ThreadId::new(0),\n+            threads: threads,\n+            blockset_counter: 0,\n+            thread_local_alloc_ids: Default::default(),\n+            yield_active_thread: false,\n+        }\n+    }\n+}\n+\n+impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n+    /// Check if we have an allocation for the given thread local static for the\n+    /// active thread.\n+    fn get_thread_local_alloc_id(&self, def_id: DefId) -> Option<AllocId> {\n+        self.thread_local_alloc_ids.borrow().get(&(def_id, self.active_thread)).cloned()\n+    }\n+\n+    /// Set the allocation id as the allocation id of the given thread local\n+    /// static for the active thread.\n+    ///\n+    /// Panics if a thread local is initialized twice for the same thread.\n+    fn set_thread_local_alloc_id(&self, def_id: DefId, new_alloc_id: AllocId) {\n+        self.thread_local_alloc_ids\n+            .borrow_mut()\n+            .insert((def_id, self.active_thread), new_alloc_id)\n+            .unwrap_none();\n+    }\n+\n+    /// Borrow the stack of the active thread.\n+    fn active_thread_stack(&self) -> &[Frame<'mir, 'tcx, Tag, FrameData<'tcx>>] {\n+        &self.threads[self.active_thread].stack\n+    }\n+\n+    /// Mutably borrow the stack of the active thread.\n+    fn active_thread_stack_mut(&mut self) -> &mut Vec<Frame<'mir, 'tcx, Tag, FrameData<'tcx>>> {\n+        &mut self.threads[self.active_thread].stack\n+    }\n+\n+    /// Create a new thread and returns its id.\n+    fn create_thread(&mut self) -> ThreadId {\n+        let new_thread_id = ThreadId::new(self.threads.len());\n+        self.threads.push(Default::default());\n+        new_thread_id\n+    }\n+\n+    /// Set an active thread and return the id of the thread that was active before.\n+    fn set_active_thread_id(&mut self, id: ThreadId) -> ThreadId {\n+        let active_thread_id = self.active_thread;\n+        self.active_thread = id;\n+        assert!(self.active_thread.index() < self.threads.len());\n+        active_thread_id\n+    }\n+\n+    /// Get the id of the currently active thread.\n+    fn get_active_thread_id(&self) -> ThreadId {\n+        self.active_thread\n+    }\n+\n+    /// Get the total number of threads that were ever spawn by this program.\n+    fn get_total_thread_count(&self) -> usize {\n+        self.threads.len()\n+    }\n+\n+    /// Has the given thread terminated?\n+    fn has_terminated(&self, thread_id: ThreadId) -> bool {\n+        self.threads[thread_id].state == ThreadState::Terminated\n+    }\n+\n+    /// Enable the thread for execution. The thread must be terminated.\n+    fn enable_thread(&mut self, thread_id: ThreadId) {\n+        assert!(self.has_terminated(thread_id));\n+        self.threads[thread_id].state = ThreadState::Enabled;\n+    }\n+\n+    /// Get a mutable borrow of the currently active thread.\n+    fn active_thread_mut(&mut self) -> &mut Thread<'mir, 'tcx> {\n+        &mut self.threads[self.active_thread]\n+    }\n+\n+    /// Get a shared borrow of the currently active thread.\n+    fn active_thread_ref(&self) -> &Thread<'mir, 'tcx> {\n+        &self.threads[self.active_thread]\n+    }\n+\n+    /// Mark the thread as detached, which means that no other thread will try\n+    /// to join it and the thread is responsible for cleaning up.\n+    fn detach_thread(&mut self, id: ThreadId) -> InterpResult<'tcx> {\n+        if self.threads[id].join_status != ThreadJoinStatus::Joinable {\n+            throw_ub_format!(\"trying to detach thread that was already detached or joined\");\n+        }\n+        self.threads[id].join_status = ThreadJoinStatus::Detached;\n+        Ok(())\n+    }\n+\n+    /// Mark that the active thread tries to join the thread with `joined_thread_id`.\n+    fn join_thread(&mut self, joined_thread_id: ThreadId) -> InterpResult<'tcx> {\n+        if self.threads[joined_thread_id].join_status != ThreadJoinStatus::Joinable {\n+            throw_ub_format!(\"trying to join a detached or already joined thread\");\n+        }\n+        if joined_thread_id == self.active_thread {\n+            throw_ub_format!(\"trying to join itself\");\n+        }\n+        assert!(\n+            self.threads\n+                .iter()\n+                .all(|thread| thread.state != ThreadState::BlockedOnJoin(joined_thread_id)),\n+            \"a joinable thread already has threads waiting for its termination\"\n+        );\n+        // Mark the joined thread as being joined so that we detect if other\n+        // threads try to join it.\n+        self.threads[joined_thread_id].join_status = ThreadJoinStatus::Joined;\n+        if self.threads[joined_thread_id].state != ThreadState::Terminated {\n+            // The joined thread is still running, we need to wait for it.\n+            self.active_thread_mut().state = ThreadState::BlockedOnJoin(joined_thread_id);\n+            trace!(\n+                \"{:?} blocked on {:?} when trying to join\",\n+                self.active_thread,\n+                joined_thread_id\n+            );\n+        }\n+        Ok(())\n+    }\n+\n+    /// Set the name of the active thread.\n+    fn set_thread_name(&mut self, new_thread_name: Vec<u8>) {\n+        self.active_thread_mut().thread_name = Some(new_thread_name);\n+    }\n+\n+    /// Get the name of the active thread.\n+    fn get_thread_name(&self) -> &[u8] {\n+        if let Some(ref thread_name) = self.active_thread_ref().thread_name {\n+            thread_name\n+        } else {\n+            b\"<unnamed>\"\n+        }\n+    }\n+\n+    /// Allocate a new blockset id.\n+    fn create_blockset(&mut self) -> BlockSetId {\n+        self.blockset_counter = self.blockset_counter.checked_add(1).unwrap();\n+        BlockSetId::new(self.blockset_counter)\n+    }\n+\n+    /// Block the currently active thread and put it into the given blockset.\n+    fn block_active_thread(&mut self, set: BlockSetId) {\n+        let state = &mut self.active_thread_mut().state;\n+        assert_eq!(*state, ThreadState::Enabled);\n+        *state = ThreadState::Blocked(set);\n+    }\n+\n+    /// Unblock any one thread from the given blockset if it contains at least\n+    /// one. Return the id of the unblocked thread.\n+    fn unblock_some_thread(&mut self, set: BlockSetId) -> Option<ThreadId> {\n+        for (id, thread) in self.threads.iter_enumerated_mut() {\n+            if thread.state == ThreadState::Blocked(set) {\n+                trace!(\"unblocking {:?} in blockset {:?}\", id, set);\n+                thread.state = ThreadState::Enabled;\n+                return Some(id);\n+            }\n+        }\n+        None\n+    }\n+\n+    /// Change the active thread to some enabled thread.\n+    fn yield_active_thread(&mut self) {\n+        self.yield_active_thread = true;\n+    }\n+\n+    /// Decide which action to take next and on which thread.\n+    ///\n+    /// The currently implemented scheduling policy is the one that is commonly\n+    /// used in stateless model checkers such as Loom: run the active thread as\n+    /// long as we can and switch only when we have to (the active thread was\n+    /// blocked, terminated, or has explicitly asked to be preempted).\n+    fn schedule(&mut self) -> InterpResult<'tcx, SchedulingAction> {\n+        // Check whether the thread has **just** terminated (`check_terminated`\n+        // checks whether the thread has popped all its stack and if yes, sets\n+        // the thread state to terminated).\n+        if self.threads[self.active_thread].check_terminated() {\n+            // Check if we need to unblock any threads.\n+            for (i, thread) in self.threads.iter_enumerated_mut() {\n+                if thread.state == ThreadState::BlockedOnJoin(self.active_thread) {\n+                    trace!(\"unblocking {:?} because {:?} terminated\", i, self.active_thread);\n+                    thread.state = ThreadState::Enabled;\n+                }\n+            }\n+            return Ok(SchedulingAction::ExecuteDtors);\n+        }\n+        if self.threads[MAIN_THREAD].state == ThreadState::Terminated {\n+            // The main thread terminated; stop the program.\n+            if self.threads.iter().any(|thread| thread.state != ThreadState::Terminated) {\n+                // FIXME: This check should be either configurable or just emit\n+                // a warning. For example, it seems normal for a program to\n+                // terminate without waiting for its detached threads to\n+                // terminate. However, this case is not trivial to support\n+                // because we also probably do not want to consider the memory\n+                // owned by these threads as leaked.\n+                throw_unsup_format!(\"the main thread terminated without waiting for other threads\");\n+            }\n+            return Ok(SchedulingAction::Stop);\n+        }\n+        if self.threads[self.active_thread].state == ThreadState::Enabled\n+            && !self.yield_active_thread\n+        {\n+            // The currently active thread is still enabled, just continue with it.\n+            return Ok(SchedulingAction::ExecuteStep);\n+        }\n+        // We need to pick a new thread for execution.\n+        for (id, thread) in self.threads.iter_enumerated() {\n+            if thread.state == ThreadState::Enabled {\n+                if !self.yield_active_thread || id != self.active_thread {\n+                    self.active_thread = id;\n+                    break;\n+                }\n+            }\n+        }\n+        self.yield_active_thread = false;\n+        if self.threads[self.active_thread].state == ThreadState::Enabled {\n+            return Ok(SchedulingAction::ExecuteStep);\n+        }\n+        // We have not found a thread to execute.\n+        if self.threads.iter().all(|thread| thread.state == ThreadState::Terminated) {\n+            unreachable!();\n+        } else {\n+            throw_machine_stop!(TerminationInfo::Deadlock);\n+        }\n+    }\n+}\n+\n+// Public interface to thread management.\n+impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n+pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n+    /// A workaround for thread-local statics until\n+    /// https://github.com/rust-lang/rust/issues/70685 is fixed: change the\n+    /// thread-local allocation id with a freshly generated allocation id for\n+    /// the currently active thread.\n+    fn remap_thread_local_alloc_ids(\n+        &self,\n+        val: &mut mir::interpret::ConstValue<'tcx>,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_ref();\n+        match *val {\n+            mir::interpret::ConstValue::Scalar(Scalar::Ptr(ref mut ptr)) => {\n+                let alloc_id = ptr.alloc_id;\n+                let alloc = this.tcx.alloc_map.lock().get(alloc_id);\n+                let tcx = this.tcx;\n+                let is_thread_local = |def_id| {\n+                    tcx.codegen_fn_attrs(def_id).flags.contains(CodegenFnAttrFlags::THREAD_LOCAL)\n+                };\n+                match alloc {\n+                    Some(GlobalAlloc::Static(def_id)) if is_thread_local(def_id) => {\n+                        ptr.alloc_id = this.get_or_create_thread_local_alloc_id(def_id)?;\n+                    }\n+                    _ => {}\n+                }\n+            }\n+            _ => {\n+                // FIXME: Handling only `Scalar` seems to work for now, but at\n+                // least in principle thread-locals could be in any constant, so\n+                // we should also consider other cases. However, once\n+                // https://github.com/rust-lang/rust/issues/70685 gets fixed,\n+                // this code will have to be rewritten anyway.\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    /// Get a thread-specific allocation id for the given thread-local static.\n+    /// If needed, allocate a new one.\n+    ///\n+    /// FIXME: This method should be replaced as soon as\n+    /// https://github.com/rust-lang/rust/issues/70685 gets fixed.\n+    fn get_or_create_thread_local_alloc_id(&self, def_id: DefId) -> InterpResult<'tcx, AllocId> {\n+        let this = self.eval_context_ref();\n+        let tcx = this.tcx;\n+        if let Some(new_alloc_id) = this.machine.threads.get_thread_local_alloc_id(def_id) {\n+            // We already have a thread-specific allocation id for this\n+            // thread-local static.\n+            Ok(new_alloc_id)\n+        } else {\n+            // We need to allocate a thread-specific allocation id for this\n+            // thread-local static.\n+            //\n+            // At first, we invoke the `const_eval_raw` query and extract the\n+            // allocation from it. Unfortunately, we have to duplicate the code\n+            // from `Memory::get_global_alloc` that does this.\n+            //\n+            // Then we store the retrieved allocation back into the `alloc_map`\n+            // to get a fresh allocation id, which we can use as a\n+            // thread-specific allocation id for the thread-local static.\n+            if tcx.is_foreign_item(def_id) {\n+                throw_unsup_format!(\"foreign thread-local statics are not supported\");\n+            }\n+            // Invoke the `const_eval_raw` query.\n+            let instance = Instance::mono(tcx.tcx, def_id);\n+            let gid = GlobalId { instance, promoted: None };\n+            let raw_const =\n+                tcx.const_eval_raw(ty::ParamEnv::reveal_all().and(gid)).map_err(|err| {\n+                    // no need to report anything, the const_eval call takes care of that\n+                    // for statics\n+                    assert!(tcx.is_static(def_id));\n+                    err\n+                })?;\n+            let id = raw_const.alloc_id;\n+            // Extract the allocation from the query result.\n+            let mut alloc_map = tcx.alloc_map.lock();\n+            let allocation = alloc_map.unwrap_memory(id);\n+            // Create a new allocation id for the same allocation in this hacky\n+            // way. Internally, `alloc_map` deduplicates allocations, but this\n+            // is fine because Miri will make a copy before a first mutable\n+            // access.\n+            let new_alloc_id = alloc_map.create_memory_alloc(allocation);\n+            this.machine.threads.set_thread_local_alloc_id(def_id, new_alloc_id);\n+            Ok(new_alloc_id)\n+        }\n+    }\n+\n+    #[inline]\n+    fn create_thread(&mut self) -> InterpResult<'tcx, ThreadId> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.create_thread())\n+    }\n+\n+    #[inline]\n+    fn detach_thread(&mut self, thread_id: ThreadId) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.detach_thread(thread_id)\n+    }\n+\n+    #[inline]\n+    fn join_thread(&mut self, joined_thread_id: ThreadId) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.join_thread(joined_thread_id)\n+    }\n+\n+    #[inline]\n+    fn set_active_thread(&mut self, thread_id: ThreadId) -> InterpResult<'tcx, ThreadId> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.set_active_thread_id(thread_id))\n+    }\n+\n+    #[inline]\n+    fn get_active_thread(&self) -> InterpResult<'tcx, ThreadId> {\n+        let this = self.eval_context_ref();\n+        Ok(this.machine.threads.get_active_thread_id())\n+    }\n+\n+    #[inline]\n+    fn get_total_thread_count(&self) -> InterpResult<'tcx, usize> {\n+        let this = self.eval_context_ref();\n+        Ok(this.machine.threads.get_total_thread_count())\n+    }\n+\n+    #[inline]\n+    fn has_terminated(&self, thread_id: ThreadId) -> InterpResult<'tcx, bool> {\n+        let this = self.eval_context_ref();\n+        Ok(this.machine.threads.has_terminated(thread_id))\n+    }\n+\n+    #[inline]\n+    fn enable_thread(&mut self, thread_id: ThreadId) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.enable_thread(thread_id);\n+        Ok(())\n+    }\n+\n+    #[inline]\n+    fn active_thread_stack(&self) -> &[Frame<'mir, 'tcx, Tag, FrameData<'tcx>>] {\n+        let this = self.eval_context_ref();\n+        this.machine.threads.active_thread_stack()\n+    }\n+\n+    #[inline]\n+    fn active_thread_stack_mut(&mut self) -> &mut Vec<Frame<'mir, 'tcx, Tag, FrameData<'tcx>>> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.active_thread_stack_mut()\n+    }\n+\n+    #[inline]\n+    fn set_active_thread_name(&mut self, new_thread_name: Vec<u8>) -> InterpResult<'tcx, ()> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.set_thread_name(new_thread_name))\n+    }\n+\n+    #[inline]\n+    fn get_active_thread_name<'c>(&'c self) -> InterpResult<'tcx, &'c [u8]>\n+    where\n+        'mir: 'c,\n+    {\n+        let this = self.eval_context_ref();\n+        Ok(this.machine.threads.get_thread_name())\n+    }\n+\n+    #[inline]\n+    fn create_blockset(&mut self) -> InterpResult<'tcx, BlockSetId> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.create_blockset())\n+    }\n+\n+    #[inline]\n+    fn block_active_thread(&mut self, set: BlockSetId) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.block_active_thread(set))\n+    }\n+\n+    #[inline]\n+    fn unblock_some_thread(&mut self, set: BlockSetId) -> InterpResult<'tcx, Option<ThreadId>> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.unblock_some_thread(set))\n+    }\n+\n+    #[inline]\n+    fn yield_active_thread(&mut self) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.yield_active_thread();\n+        Ok(())\n+    }\n+\n+    /// Decide which action to take next and on which thread.\n+    #[inline]\n+    fn schedule(&mut self) -> InterpResult<'tcx, SchedulingAction> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.schedule()\n+    }\n+}"}, {"sha": "ea11691955ce7d3fdf0a2ea8a30e89fd714077ff", "filename": "tests/compile-fail/concurrency/libc_pthread_create_main_terminate.rs", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_create_main_terminate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_create_main_terminate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_create_main_terminate.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,23 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+// error-pattern: unsupported operation: the main thread terminated without waiting for other threads\n+\n+// Check that we terminate the program when the main thread terminates.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::{mem, ptr};\n+\n+extern \"C\" fn thread_start(_null: *mut libc::c_void) -> *mut libc::c_void {\n+    ptr::null_mut()\n+}\n+\n+fn main() {\n+    unsafe {\n+        let mut native: libc::pthread_t = mem::zeroed();\n+        let attr: libc::pthread_attr_t = mem::zeroed();\n+        // assert_eq!(libc::pthread_attr_init(&mut attr), 0); FIXME: this function is not yet implemented.\n+        assert_eq!(libc::pthread_create(&mut native, &attr, thread_start, ptr::null_mut()), 0);\n+    }\n+}"}, {"sha": "ad83fb2efef3dd1e10dca06e47a1cf140789791b", "filename": "tests/compile-fail/concurrency/libc_pthread_join_detached.rs", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_detached.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_detached.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_detached.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,24 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+// Joining a detached thread is undefined behavior.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::{mem, ptr};\n+\n+extern \"C\" fn thread_start(_null: *mut libc::c_void) -> *mut libc::c_void {\n+    ptr::null_mut()\n+}\n+\n+fn main() {\n+    unsafe {\n+        let mut native: libc::pthread_t = mem::zeroed();\n+        let attr: libc::pthread_attr_t = mem::zeroed();\n+        // assert_eq!(libc::pthread_attr_init(&mut attr), 0); FIXME: this function is not yet implemented.\n+        assert_eq!(libc::pthread_create(&mut native, &attr, thread_start, ptr::null_mut()), 0);\n+        assert_eq!(libc::pthread_detach(native), 0);\n+        assert_eq!(libc::pthread_join(native, ptr::null_mut()), 0); //~ ERROR: Undefined Behavior: trying to join a detached or already joined thread\n+    }\n+}"}, {"sha": "3ca04244969041510fec7cdbc3a0eebe301ecb48", "filename": "tests/compile-fail/concurrency/libc_pthread_join_joined.rs", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_joined.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_joined.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_joined.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,24 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+// Joining an already joined thread is undefined behavior.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::{mem, ptr};\n+\n+extern \"C\" fn thread_start(_null: *mut libc::c_void) -> *mut libc::c_void {\n+    ptr::null_mut()\n+}\n+\n+fn main() {\n+    unsafe {\n+        let mut native: libc::pthread_t = mem::zeroed();\n+        let attr: libc::pthread_attr_t = mem::zeroed();\n+        // assert_eq!(libc::pthread_attr_init(&mut attr), 0); FIXME: this function is not yet implemented.\n+        assert_eq!(libc::pthread_create(&mut native, &attr, thread_start, ptr::null_mut()), 0);\n+        assert_eq!(libc::pthread_join(native, ptr::null_mut()), 0);\n+        assert_eq!(libc::pthread_join(native, ptr::null_mut()), 0); //~ ERROR: Undefined Behavior: trying to join a detached or already joined thread\n+    }\n+}"}, {"sha": "69e1a68ef97ae4f30feb13aa0841611860125781", "filename": "tests/compile-fail/concurrency/libc_pthread_join_main.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_main.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_main.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_main.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,20 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+// Joining the main thread is undefined behavior.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::{ptr, thread};\n+\n+fn main() {\n+    let thread_id: libc::pthread_t = unsafe { libc::pthread_self() };\n+    let handle = thread::spawn(move || {\n+        unsafe {\n+            assert_eq!(libc::pthread_join(thread_id, ptr::null_mut()), 0); //~ ERROR: Undefined Behavior: trying to join a detached or already joined thread\n+        }\n+    });\n+    thread::yield_now();\n+    handle.join().unwrap();\n+}"}, {"sha": "f8a43cfcde6478eb5131aa459a61159599d6e037", "filename": "tests/compile-fail/concurrency/libc_pthread_join_multiple.rs", "status": "added", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_multiple.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_multiple.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_multiple.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,33 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+// Joining the same thread from multiple threads is undefined behavior.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::thread;\n+use std::{mem, ptr};\n+\n+extern \"C\" fn thread_start(_null: *mut libc::c_void) -> *mut libc::c_void {\n+    // Yield the thread several times so that other threads can join it.\n+    thread::yield_now();\n+    thread::yield_now();\n+    ptr::null_mut()\n+}\n+\n+fn main() {\n+    unsafe {\n+        let mut native: libc::pthread_t = mem::zeroed();\n+        let attr: libc::pthread_attr_t = mem::zeroed();\n+        // assert_eq!(libc::pthread_attr_init(&mut attr), 0); FIXME: this function is not yet implemented.\n+        assert_eq!(libc::pthread_create(&mut native, &attr, thread_start, ptr::null_mut()), 0);\n+        let mut native_copy: libc::pthread_t = mem::zeroed();\n+        ptr::copy_nonoverlapping(&native, &mut native_copy, 1);\n+        let handle = thread::spawn(move || {\n+            assert_eq!(libc::pthread_join(native_copy, ptr::null_mut()), 0); //~ ERROR: Undefined Behavior: trying to join a detached or already joined thread\n+        });\n+        assert_eq!(libc::pthread_join(native, ptr::null_mut()), 0);\n+        handle.join().unwrap();\n+    }\n+}"}, {"sha": "d765a95d8be7a31afac6cb348a4c0c65b1c3d8e2", "filename": "tests/compile-fail/concurrency/libc_pthread_join_self.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_self.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_self.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Flibc_pthread_join_self.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,20 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+// Joining itself is undefined behavior.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::{ptr, thread};\n+\n+fn main() {\n+    let handle = thread::spawn(|| {\n+        unsafe {\n+            let native: libc::pthread_t = libc::pthread_self();\n+            assert_eq!(libc::pthread_join(native, ptr::null_mut()), 0); //~ ERROR: Undefined Behavior: trying to join itself\n+        }\n+    });\n+    thread::yield_now();\n+    handle.join().unwrap();\n+}"}, {"sha": "f0e4ab3817d343580114f7283e311fa9cc87e285", "filename": "tests/compile-fail/concurrency/thread-spawn.rs", "status": "renamed", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Fthread-spawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fconcurrency%2Fthread-spawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fconcurrency%2Fthread-spawn.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -1,3 +1,6 @@\n+// ignore-linux: Only Windows is not supported.\n+// ignore-macos: Only Windows is not supported.\n+\n use std::thread;\n \n // error-pattern: Miri does not support threading", "previous_filename": "tests/compile-fail/thread-spawn.rs"}, {"sha": "5d04635a36c8883e1c5c4c9061cc51b5ae0fd16e", "filename": "tests/compile-fail/sync/libc_pthread_mutex_deadlock.rs", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_deadlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_deadlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_deadlock.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,32 @@\n+// ignore-windows: No libc on Windows\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::cell::UnsafeCell;\n+use std::sync::Arc;\n+use std::thread;\n+\n+struct Mutex(UnsafeCell<libc::pthread_mutex_t>);\n+\n+unsafe impl Send for Mutex {}\n+unsafe impl Sync for Mutex {}\n+\n+fn new_lock() -> Arc<Mutex> {\n+    Arc::new(Mutex(UnsafeCell::new(libc::PTHREAD_MUTEX_INITIALIZER)))\n+}\n+\n+fn main() {\n+    unsafe {\n+        let lock = new_lock();\n+        assert_eq!(libc::pthread_mutex_lock(lock.0.get() as *mut _), 0);\n+\n+        let lock_copy = lock.clone();\n+        thread::spawn(move || {\n+            assert_eq!(libc::pthread_mutex_lock(lock_copy.0.get() as *mut _), 0); //~ ERROR: deadlock\n+        })\n+        .join()\n+        .unwrap();\n+    }\n+}"}, {"sha": "3009721abe2e13ec3e57608e4e3e7855b1b3d449", "filename": "tests/compile-fail/sync/libc_pthread_mutex_wrong_owner.rs", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_wrong_owner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_wrong_owner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_wrong_owner.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,32 @@\n+// ignore-windows: No libc on Windows\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::cell::UnsafeCell;\n+use std::sync::Arc;\n+use std::thread;\n+\n+struct Mutex(UnsafeCell<libc::pthread_mutex_t>);\n+\n+unsafe impl Send for Mutex {}\n+unsafe impl Sync for Mutex {}\n+\n+fn new_lock() -> Arc<Mutex> {\n+    Arc::new(Mutex(UnsafeCell::new(libc::PTHREAD_MUTEX_INITIALIZER)))\n+}\n+\n+fn main() {\n+    unsafe {\n+        let lock = new_lock();\n+        assert_eq!(libc::pthread_mutex_lock(lock.0.get() as *mut _), 0);\n+\n+        let lock_copy = lock.clone();\n+        thread::spawn(move || {\n+            assert_eq!(libc::pthread_mutex_unlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: Undefined Behavior: called pthread_mutex_unlock on a mutex owned by another thread\n+        })\n+        .join()\n+        .unwrap();\n+    }\n+}"}, {"sha": "19dce431c8b1cb710dc8e4ad8080765667aa62e4", "filename": "tests/compile-fail/sync/libc_pthread_rwlock_write_read_deadlock.rs", "status": "modified", "additions": 22, "deletions": 3, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_read_deadlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_read_deadlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_read_deadlock.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -4,10 +4,29 @@\n \n extern crate libc;\n \n+use std::cell::UnsafeCell;\n+use std::sync::Arc;\n+use std::thread;\n+\n+struct RwLock(UnsafeCell<libc::pthread_rwlock_t>);\n+\n+unsafe impl Send for RwLock {}\n+unsafe impl Sync for RwLock {}\n+\n+fn new_lock() -> Arc<RwLock> {\n+    Arc::new(RwLock(UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER)))\n+}\n+\n fn main() {\n-    let rw = std::cell::UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER);\n     unsafe {\n-        assert_eq!(libc::pthread_rwlock_wrlock(rw.get()), 0);\n-        libc::pthread_rwlock_rdlock(rw.get()); //~ ERROR: deadlock\n+        let lock = new_lock();\n+        assert_eq!(libc::pthread_rwlock_rdlock(lock.0.get() as *mut _), 0);\n+\n+        let lock_copy = lock.clone();\n+        thread::spawn(move || {\n+            assert_eq!(libc::pthread_rwlock_wrlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: deadlock\n+        })\n+        .join()\n+        .unwrap();\n     }\n }"}, {"sha": "1b460e7174d28f40f8c56fc89fc15d7762ff4596", "filename": "tests/compile-fail/sync/libc_pthread_rwlock_write_read_deadlock_single_thread.rs", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_read_deadlock_single_thread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_read_deadlock_single_thread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_read_deadlock_single_thread.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,13 @@\n+// ignore-windows: No libc on Windows\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+fn main() {\n+    let rw = std::cell::UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER);\n+    unsafe {\n+        assert_eq!(libc::pthread_rwlock_wrlock(rw.get()), 0);\n+        libc::pthread_rwlock_rdlock(rw.get()); //~ ERROR: deadlock\n+    }\n+}"}, {"sha": "098c1c2fe26cc7b8ab0e2746bf05a1002f3d8389", "filename": "tests/compile-fail/sync/libc_pthread_rwlock_write_write_deadlock.rs", "status": "modified", "additions": 22, "deletions": 3, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_write_deadlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_write_deadlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_write_deadlock.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -4,10 +4,29 @@\n \n extern crate libc;\n \n+use std::cell::UnsafeCell;\n+use std::sync::Arc;\n+use std::thread;\n+\n+struct RwLock(UnsafeCell<libc::pthread_rwlock_t>);\n+\n+unsafe impl Send for RwLock {}\n+unsafe impl Sync for RwLock {}\n+\n+fn new_lock() -> Arc<RwLock> {\n+    Arc::new(RwLock(UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER)))\n+}\n+\n fn main() {\n-    let rw = std::cell::UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER);\n     unsafe {\n-        assert_eq!(libc::pthread_rwlock_wrlock(rw.get()), 0);\n-        libc::pthread_rwlock_wrlock(rw.get()); //~ ERROR: deadlock\n+        let lock = new_lock();\n+        assert_eq!(libc::pthread_rwlock_wrlock(lock.0.get() as *mut _), 0);\n+\n+        let lock_copy = lock.clone();\n+        thread::spawn(move || {\n+            assert_eq!(libc::pthread_rwlock_wrlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: deadlock\n+        })\n+        .join()\n+        .unwrap();\n     }\n }"}, {"sha": "cc327ec46bc2989ed0302bb1d91afec0230d6662", "filename": "tests/compile-fail/sync/libc_pthread_rwlock_write_write_deadlock_single_thread.rs", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_write_deadlock_single_thread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_write_deadlock_single_thread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_write_deadlock_single_thread.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,13 @@\n+// ignore-windows: No libc on Windows\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+fn main() {\n+    let rw = std::cell::UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER);\n+    unsafe {\n+        assert_eq!(libc::pthread_rwlock_wrlock(rw.get()), 0);\n+        libc::pthread_rwlock_wrlock(rw.get()); //~ ERROR: deadlock\n+    }\n+}"}, {"sha": "f5469712c5f55fe318b1ff1e6294b801f1d08e5d", "filename": "tests/run-pass/concurrency/locks.rs", "status": "added", "additions": 75, "deletions": 0, "changes": 75, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Flocks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Flocks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Flocks.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,75 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+use std::sync::{Arc, Mutex, RwLock};\n+use std::thread;\n+\n+fn check_mutex() {\n+    let data = Arc::new(Mutex::new(0));\n+    let mut threads = Vec::new();\n+\n+    for _ in 0..3 {\n+        let data = Arc::clone(&data);\n+        let thread = thread::spawn(move || {\n+            let mut data = data.lock().unwrap();\n+            thread::yield_now();\n+            *data += 1;\n+        });\n+        threads.push(thread);\n+    }\n+\n+    for thread in threads {\n+        thread.join().unwrap();\n+    }\n+\n+    assert!(data.try_lock().is_ok());\n+\n+    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n+    assert_eq!(data, 3);\n+}\n+\n+fn check_rwlock_write() {\n+    let data = Arc::new(RwLock::new(0));\n+    let mut threads = Vec::new();\n+\n+    for _ in 0..3 {\n+        let data = Arc::clone(&data);\n+        let thread = thread::spawn(move || {\n+            let mut data = data.write().unwrap();\n+            thread::yield_now();\n+            *data += 1;\n+        });\n+        threads.push(thread);\n+    }\n+\n+    for thread in threads {\n+        thread.join().unwrap();\n+    }\n+\n+    assert!(data.try_write().is_ok());\n+\n+    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n+    assert_eq!(data, 3);\n+}\n+\n+fn check_rwlock_read_no_deadlock() {\n+    let l1 = Arc::new(RwLock::new(0));\n+    let l2 = Arc::new(RwLock::new(0));\n+\n+    let l1_copy = Arc::clone(&l1);\n+    let l2_copy = Arc::clone(&l2);\n+    let _guard1 = l1.read().unwrap();\n+    let handle = thread::spawn(move || {\n+        let _guard2 = l2_copy.read().unwrap();\n+        thread::yield_now();\n+        let _guard1 = l1_copy.read().unwrap();\n+    });\n+    thread::yield_now();\n+    let _guard2 = l2.read().unwrap();\n+    handle.join().unwrap();\n+}\n+\n+fn main() {\n+    check_mutex();\n+    check_rwlock_write();\n+    check_rwlock_read_no_deadlock();\n+}"}, {"sha": "2dbfb7721d3683fb4d82c2ce771e3784be86fdc9", "filename": "tests/run-pass/concurrency/locks.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Flocks.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Flocks.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Flocks.stderr?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,2 @@\n+warning: thread support is experimental. For example, Miri does not detect data races yet.\n+"}, {"sha": "ad47bb144b58db6b9cd50e124ce7b2283b7d2757", "filename": "tests/run-pass/concurrency/simple.rs", "status": "added", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fsimple.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fsimple.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fsimple.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,61 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+use std::thread;\n+\n+fn create_and_detach() {\n+    thread::spawn(|| ());\n+}\n+\n+fn create_and_join() {\n+    thread::spawn(|| ()).join().unwrap();\n+}\n+\n+fn create_and_get_result() {\n+    let nine = thread::spawn(|| 5 + 4).join().unwrap();\n+    assert_eq!(nine, 9);\n+}\n+\n+fn create_and_leak_result() {\n+    thread::spawn(|| 7);\n+}\n+\n+fn create_nested_and_detach() {\n+    thread::spawn(|| {\n+        thread::spawn(|| ());\n+    });\n+}\n+\n+fn create_nested_and_join() {\n+    let handle = thread::spawn(|| thread::spawn(|| ()));\n+    let handle_nested = handle.join().unwrap();\n+    handle_nested.join().unwrap();\n+}\n+\n+fn create_move_in() {\n+    let x = String::from(\"Hello!\");\n+    thread::spawn(move || {\n+        assert_eq!(x.len(), 6);\n+    })\n+    .join()\n+    .unwrap();\n+}\n+\n+fn create_move_out() {\n+    let result = thread::spawn(|| {\n+        String::from(\"Hello!\")\n+    })\n+    .join()\n+    .unwrap();\n+    assert_eq!(result.len(), 6);\n+}\n+\n+fn main() {\n+    create_and_detach();\n+    create_and_join();\n+    create_and_get_result();\n+    create_and_leak_result();\n+    create_nested_and_detach();\n+    create_nested_and_join();\n+    create_move_in();\n+    create_move_out();\n+}"}, {"sha": "2dbfb7721d3683fb4d82c2ce771e3784be86fdc9", "filename": "tests/run-pass/concurrency/simple.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fsimple.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fsimple.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fsimple.stderr?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,2 @@\n+warning: thread support is experimental. For example, Miri does not detect data races yet.\n+"}, {"sha": "384c2ac9155b21969d34cc4cfcb3c6eafa620c59", "filename": "tests/run-pass/concurrency/thread_locals.rs", "status": "added", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fthread_locals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fthread_locals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fthread_locals.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,59 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+//! The main purpose of this test is to check that if we take a pointer to\n+//! thread's `t1` thread-local `A` and send it to another thread `t2`,\n+//! dereferencing the pointer on `t2` resolves to `t1`'s thread-local. In this\n+//! test, we also check that thread-locals act as per-thread statics.\n+\n+#![feature(thread_local)]\n+\n+use std::thread;\n+\n+#[thread_local]\n+static mut A: u8 = 0;\n+#[thread_local]\n+static mut B: u8 = 0;\n+static mut C: u8 = 0;\n+\n+unsafe fn get_a_ref() -> *mut u8 {\n+    &mut A\n+}\n+\n+struct Sender(*mut u8);\n+\n+unsafe impl Send for Sender {}\n+\n+fn main() {\n+    let ptr = unsafe {\n+        let x = get_a_ref();\n+        *x = 5;\n+        assert_eq!(A, 5);\n+        B = 15;\n+        C = 25;\n+        Sender(&mut A)\n+    };\n+\n+    thread::spawn(move || unsafe {\n+        assert_eq!(*ptr.0, 5);\n+        assert_eq!(A, 0);\n+        assert_eq!(B, 0);\n+        assert_eq!(C, 25);\n+        B = 14;\n+        C = 24;\n+        let y = get_a_ref();\n+        assert_eq!(*y, 0);\n+        *y = 4;\n+        assert_eq!(*ptr.0, 5);\n+        assert_eq!(A, 4);\n+        assert_eq!(*get_a_ref(), 4);\n+    })\n+    .join()\n+    .unwrap();\n+\n+    unsafe {\n+        assert_eq!(*get_a_ref(), 5);\n+        assert_eq!(A, 5);\n+        assert_eq!(B, 15);\n+        assert_eq!(C, 24);\n+    }\n+}"}, {"sha": "2dbfb7721d3683fb4d82c2ce771e3784be86fdc9", "filename": "tests/run-pass/concurrency/thread_locals.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fthread_locals.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Fthread_locals.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fthread_locals.stderr?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,2 @@\n+warning: thread support is experimental. For example, Miri does not detect data races yet.\n+"}, {"sha": "de2566de85c6ac04a2364798466c7046ca559042", "filename": "tests/run-pass/concurrency/tls_lib_drop.rs", "status": "added", "additions": 70, "deletions": 0, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,70 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+\n+use std::cell::RefCell;\n+use std::thread;\n+\n+struct TestCell {\n+    value: RefCell<u8>,\n+}\n+\n+impl Drop for TestCell {\n+    fn drop(&mut self) {\n+        println!(\"Dropping: {}\", self.value.borrow())\n+    }\n+}\n+\n+thread_local! {\n+    static A: TestCell = TestCell { value: RefCell::new(0) };\n+}\n+\n+/// Check that destructors of the library thread locals are executed immediately\n+/// after a thread terminates.\n+fn check_destructors() {\n+    thread::spawn(|| {\n+        A.with(|f| {\n+            assert_eq!(*f.value.borrow(), 0);\n+            *f.value.borrow_mut() = 5;\n+        });\n+    })\n+    .join()\n+    .unwrap();\n+    println!(\"Continue main.\")\n+}\n+\n+struct JoinCell {\n+    value: RefCell<Option<thread::JoinHandle<u8>>>,\n+}\n+\n+impl Drop for JoinCell {\n+    fn drop(&mut self) {\n+        let join_handle = self.value.borrow_mut().take().unwrap();\n+        println!(\"Joining: {}\", join_handle.join().unwrap());\n+    }\n+}\n+\n+thread_local! {\n+    static B: JoinCell = JoinCell { value: RefCell::new(None) };\n+}\n+\n+/// Check that the destructor can be blocked joining another thread.\n+fn check_blocking() {\n+    thread::spawn(|| {\n+        B.with(|f| {\n+            assert!(f.value.borrow().is_none());\n+            let handle = thread::spawn(|| 7);\n+            *f.value.borrow_mut() = Some(handle);\n+        });\n+    })\n+    .join()\n+    .unwrap();\n+    println!(\"Continue main 2.\");\n+    // Preempt the main thread so that the destructor gets executed and can join\n+    // the thread.\n+    thread::yield_now();\n+    thread::yield_now();\n+}\n+\n+fn main() {\n+    check_destructors();\n+    check_blocking();\n+}"}, {"sha": "2dbfb7721d3683fb4d82c2ce771e3784be86fdc9", "filename": "tests/run-pass/concurrency/tls_lib_drop.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.stderr?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,2 @@\n+warning: thread support is experimental. For example, Miri does not detect data races yet.\n+"}, {"sha": "d622c0ccce88260835a99ee647972e6e6d33ffa5", "filename": "tests/run-pass/concurrency/tls_lib_drop.stdout", "status": "added", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop.stdout?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,4 @@\n+Dropping: 5\n+Continue main.\n+Continue main 2.\n+Joining: 7"}, {"sha": "f232cee5bdd103359d89261937cfe0d754a7227d", "filename": "tests/run-pass/concurrency/tls_lib_drop_single_thread.rs", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop_single_thread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop_single_thread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop_single_thread.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,25 @@\n+//! Check that destructors of the thread locals are executed on all OSes.\n+\n+use std::cell::RefCell;\n+\n+struct TestCell {\n+    value: RefCell<u8>,\n+}\n+\n+impl Drop for TestCell {\n+    fn drop(&mut self) {\n+        eprintln!(\"Dropping: {}\", self.value.borrow())\n+    }\n+}\n+\n+thread_local! {\n+    static A: TestCell = TestCell { value: RefCell::new(0) };\n+}\n+\n+fn main() {\n+    A.with(|f| {\n+        assert_eq!(*f.value.borrow(), 0);\n+        *f.value.borrow_mut() = 5;\n+    });\n+    eprintln!(\"Continue main.\")\n+}"}, {"sha": "a9d705e5b9a2218a0787840b2332ba1c08f7432a", "filename": "tests/run-pass/concurrency/tls_lib_drop_single_thread.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop_single_thread.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop_single_thread.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Ftls_lib_drop_single_thread.stderr?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -0,0 +1,2 @@\n+Continue main.\n+Dropping: 5"}, {"sha": "04ca5c0b3b1a924cc91d1942e1f1b40dcff5c51e", "filename": "tests/run-pass/libc.rs", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Flibc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/351d46d3fb077d4fc824131cc9e2f95ace2df5de/tests%2Frun-pass%2Flibc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Flibc.rs?ref=351d46d3fb077d4fc824131cc9e2f95ace2df5de", "patch": "@@ -141,6 +141,30 @@ fn test_rwlock_libc_static_initializer() {\n     }\n }\n \n+/// Test whether the `prctl` shim correctly sets the thread name.\n+///\n+/// Note: `prctl` exists only on Linux.\n+#[cfg(target_os = \"linux\")]\n+fn test_prctl_thread_name() {\n+    use std::ffi::CString;\n+    use libc::c_long;\n+    unsafe {\n+        let mut buf = [255; 10];\n+        assert_eq!(libc::prctl(libc::PR_GET_NAME, buf.as_mut_ptr() as c_long, 0 as c_long, 0 as c_long, 0 as c_long), 0);\n+        assert_eq!(b\"<unnamed>\\0\", &buf);\n+        let thread_name = CString::new(\"hello\").expect(\"CString::new failed\");\n+        assert_eq!(libc::prctl(libc::PR_SET_NAME, thread_name.as_ptr() as c_long, 0 as c_long, 0 as c_long, 0 as c_long), 0);\n+        let mut buf = [255; 6];\n+        assert_eq!(libc::prctl(libc::PR_GET_NAME, buf.as_mut_ptr() as c_long, 0 as c_long, 0 as c_long, 0 as c_long), 0);\n+        assert_eq!(b\"hello\\0\", &buf);\n+        let long_thread_name = CString::new(\"01234567890123456789\").expect(\"CString::new failed\");\n+        assert_eq!(libc::prctl(libc::PR_SET_NAME, long_thread_name.as_ptr() as c_long, 0 as c_long, 0 as c_long, 0 as c_long), 0);\n+        let mut buf = [255; 16];\n+        assert_eq!(libc::prctl(libc::PR_GET_NAME, buf.as_mut_ptr() as c_long, 0 as c_long, 0 as c_long, 0 as c_long), 0);\n+        assert_eq!(b\"012345678901234\\0\", &buf);\n+    }\n+}\n+\n fn main() {\n     #[cfg(target_os = \"linux\")]\n     test_posix_fadvise();\n@@ -152,4 +176,7 @@ fn main() {\n \n     #[cfg(target_os = \"linux\")]\n     test_mutex_libc_static_initializer_recursive();\n+\n+    #[cfg(target_os = \"linux\")]\n+    test_prctl_thread_name();\n }"}]}