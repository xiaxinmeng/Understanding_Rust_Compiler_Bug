{"sha": "b8d6686ef3c2998d29c7ef531895ee05305cfef1", "node_id": "MDY6Q29tbWl0NzI0NzEyOmI4ZDY2ODZlZjNjMjk5OGQyOWM3ZWY1MzE4OTVlZTA1MzA1Y2ZlZjE=", "commit": {"author": {"name": "Mark-Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2016-11-11T23:28:47Z"}, "committer": {"name": "Mark-Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2016-11-12T13:42:40Z"}, "message": "Factor out inner current Earley item loop.\n\nChange multiple functions to be non-public.\nChange nameize to accept an iterator so as to avoid an allocation.", "tree": {"sha": "a530dcff85369d13f66fb62f7f7572703949d5be", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a530dcff85369d13f66fb62f7f7572703949d5be"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b8d6686ef3c2998d29c7ef531895ee05305cfef1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b8d6686ef3c2998d29c7ef531895ee05305cfef1", "html_url": "https://github.com/rust-lang/rust/commit/b8d6686ef3c2998d29c7ef531895ee05305cfef1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b8d6686ef3c2998d29c7ef531895ee05305cfef1/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "27c09864bd04bc3f65e8ce5721eaa5621ee9ac6a", "url": "https://api.github.com/repos/rust-lang/rust/commits/27c09864bd04bc3f65e8ce5721eaa5621ee9ac6a", "html_url": "https://github.com/rust-lang/rust/commit/27c09864bd04bc3f65e8ce5721eaa5621ee9ac6a"}], "stats": {"total": 299, "additions": 153, "deletions": 146}, "files": [{"sha": "3c57f7a05c29db63791a1fd2a10feaa87ed21e9b", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 153, "deletions": 146, "changes": 299, "blob_url": "https://github.com/rust-lang/rust/blob/b8d6686ef3c2998d29c7ef531895ee05305cfef1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b8d6686ef3c2998d29c7ef531895ee05305cfef1/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=b8d6686ef3c2998d29c7ef531895ee05305cfef1", "patch": "@@ -130,7 +130,7 @@ struct MatcherTtFrame {\n }\n \n #[derive(Clone)]\n-pub struct MatcherPos {\n+struct MatcherPos {\n     stack: Vec<MatcherTtFrame>,\n     top_elts: TokenTreeOrTokenTreeVec,\n     sep: Option<Token>,\n@@ -162,14 +162,13 @@ pub fn count_names(ms: &[TokenTree]) -> usize {\n     })\n }\n \n-pub fn initial_matcher_pos(ms: Vec<TokenTree>, sep: Option<Token>, lo: BytePos)\n-                           -> Box<MatcherPos> {\n+fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n     let match_idx_hi = count_names(&ms[..]);\n-    let matches: Vec<_> = (0..match_idx_hi).map(|_| Vec::new()).collect();\n+    let matches = create_matches(match_idx_hi);\n     Box::new(MatcherPos {\n         stack: vec![],\n         top_elts: TtSeq(ms),\n-        sep: sep,\n+        sep: None,\n         idx: 0,\n         up: None,\n         matches: matches,\n@@ -202,26 +201,25 @@ pub enum NamedMatch {\n     MatchedNonterminal(Rc<Nonterminal>)\n }\n \n-fn nameize(ms: &[TokenTree], res: &[Rc<NamedMatch>]) -> NamedParseResult {\n-    fn n_rec(m: &TokenTree, res: &[Rc<NamedMatch>],\n-             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>, idx: &mut usize)\n+fn nameize<I: Iterator<Item=Rc<NamedMatch>>>(ms: &[TokenTree], mut res: I) -> NamedParseResult {\n+    fn n_rec<I: Iterator<Item=Rc<NamedMatch>>>(m: &TokenTree, mut res: &mut I,\n+             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>)\n              -> Result<(), (syntax_pos::Span, String)> {\n         match *m {\n             TokenTree::Sequence(_, ref seq) => {\n                 for next_m in &seq.tts {\n-                    n_rec(next_m, res, ret_val, idx)?\n+                    n_rec(next_m, res.by_ref(), ret_val)?\n                 }\n             }\n             TokenTree::Delimited(_, ref delim) => {\n                 for next_m in &delim.tts {\n-                    n_rec(next_m, res, ret_val, idx)?;\n+                    n_rec(next_m, res.by_ref(), ret_val)?;\n                 }\n             }\n             TokenTree::Token(sp, MatchNt(bind_name, _)) => {\n                 match ret_val.entry(bind_name) {\n                     Vacant(spot) => {\n-                        spot.insert(res[*idx].clone());\n-                        *idx += 1;\n+                        spot.insert(res.next().unwrap());\n                     }\n                     Occupied(..) => {\n                         return Err((sp, format!(\"duplicated bind name: {}\", bind_name)))\n@@ -238,9 +236,8 @@ fn nameize(ms: &[TokenTree], res: &[Rc<NamedMatch>]) -> NamedParseResult {\n     }\n \n     let mut ret_val = HashMap::new();\n-    let mut idx = 0;\n     for m in ms {\n-        match n_rec(m, res, &mut ret_val, &mut idx) {\n+        match n_rec(m, res.by_ref(), &mut ret_val) {\n             Ok(_) => {},\n             Err((sp, msg)) => return Error(sp, msg),\n         }\n@@ -266,9 +263,8 @@ pub fn parse_failure_msg(tok: Token) -> String {\n     }\n }\n \n-/// Perform a token equality check, ignoring syntax context (that is, an\n-/// unhygienic comparison)\n-pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n+/// Perform a token equality check, ignoring syntax context (that is, an unhygienic comparison)\n+fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n     match (t1,t2) {\n         (&token::Ident(id1),&token::Ident(id2))\n         | (&token::Lifetime(id1),&token::Lifetime(id2)) =>\n@@ -277,154 +273,165 @@ pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n     }\n }\n \n-pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseResult {\n-    let mut parser = Parser::new_with_doc_flag(sess, Box::new(rdr), true);\n-    let mut cur_eis = SmallVector::one(initial_matcher_pos(ms.to_owned(), None, parser.span.lo));\n-\n-    loop {\n-        let mut bb_eis = Vec::new(); // black-box parsed by parser.rs\n-        let mut next_eis = Vec::new(); // or proceed normally\n-        let mut eof_eis = Vec::new();\n+fn create_matches(len: usize) -> Vec<Vec<Rc<NamedMatch>>> {\n+    (0..len).into_iter().map(|_| Vec::new()).collect()\n+}\n \n-        // for each Earley item\n-        while let Some(mut ei) = cur_eis.pop() {\n-            // When unzipped trees end, remove them\n-            while ei.idx >= ei.top_elts.len() {\n-                match ei.stack.pop() {\n-                    Some(MatcherTtFrame { elts, idx }) => {\n-                        ei.top_elts = elts;\n-                        ei.idx = idx + 1;\n-                    }\n-                    None => break\n+fn inner_parse_loop(cur_eis: &mut SmallVector<Box<MatcherPos>>,\n+                    next_eis: &mut Vec<Box<MatcherPos>>,\n+                    eof_eis: &mut Vec<Box<MatcherPos>>,\n+                    bb_eis: &mut Vec<Box<MatcherPos>>,\n+                    token: &Token, span: &syntax_pos::Span) -> ParseResult<()> {\n+    while let Some(mut ei) = cur_eis.pop() {\n+        // When unzipped trees end, remove them\n+        while ei.idx >= ei.top_elts.len() {\n+            match ei.stack.pop() {\n+                Some(MatcherTtFrame { elts, idx }) => {\n+                    ei.top_elts = elts;\n+                    ei.idx = idx + 1;\n                 }\n+                None => break\n             }\n+        }\n \n-            let idx = ei.idx;\n-            let len = ei.top_elts.len();\n-\n-            /* at end of sequence */\n-            if idx >= len {\n-                // can't move out of `match`es, so:\n-                if ei.up.is_some() {\n-                    // hack: a matcher sequence is repeating iff it has a\n-                    // parent (the top level is just a container)\n-\n-                    // disregard separator, try to go up\n-                    // (remove this condition to make trailing seps ok)\n-                    if idx == len {\n-                        // pop from the matcher position\n-\n-                        let mut new_pos = ei.up.clone().unwrap();\n-\n-                        // update matches (the MBE \"parse tree\") by appending\n-                        // each tree as a subtree.\n-\n-                        // I bet this is a perf problem: we're preemptively\n-                        // doing a lot of array work that will get thrown away\n-                        // most of the time.\n-\n-                        // Only touch the binders we have actually bound\n-                        for idx in ei.match_lo..ei.match_hi {\n-                            let sub = ei.matches[idx].clone();\n-                            new_pos.matches[idx]\n-                                   .push(Rc::new(MatchedSeq(sub, mk_sp(ei.sp_lo,\n-                                                                       parser.span.hi))));\n-                        }\n-\n-                        new_pos.match_cur = ei.match_hi;\n-                        new_pos.idx += 1;\n-                        cur_eis.push(new_pos);\n+        let idx = ei.idx;\n+        let len = ei.top_elts.len();\n+\n+        // at end of sequence\n+        if idx >= len {\n+            // We are repeating iff there is a parent\n+            if ei.up.is_some() {\n+                // Disregarding the separator, add the \"up\" case to the tokens that should be\n+                // examined.\n+                // (remove this condition to make trailing seps ok)\n+                if idx == len {\n+                    let mut new_pos = ei.up.clone().unwrap();\n+\n+                    // update matches (the MBE \"parse tree\") by appending\n+                    // each tree as a subtree.\n+\n+                    // I bet this is a perf problem: we're preemptively\n+                    // doing a lot of array work that will get thrown away\n+                    // most of the time.\n+\n+                    // Only touch the binders we have actually bound\n+                    for idx in ei.match_lo..ei.match_hi {\n+                        let sub = ei.matches[idx].clone();\n+                        new_pos.matches[idx]\n+                            .push(Rc::new(MatchedSeq(sub, mk_sp(ei.sp_lo,\n+                                                                span.hi))));\n                     }\n \n-                    // can we go around again?\n-\n-                    // Check if we need a separator\n-                    if idx == len && ei.sep.is_some() {\n-                        if ei.sep.as_ref().map(|ref sep| token_name_eq(&parser.token, sep))\n-                            .unwrap_or(false) {\n-                            // i'm conflicted about whether this should be hygienic....  though in\n-                            // this case, if the separators are never legal idents, it shouldn't\n-                            // matter.\n-                            // ei.match_cur = ei.match_lo;\n-                            ei.idx += 1;\n-                            next_eis.push(ei);\n-                        }\n-                    } else { // we don't need a separator\n-                        ei.match_cur = ei.match_lo;\n-                        ei.idx = 0;\n-                        cur_eis.push(ei);\n-                    }\n-                } else {\n-                    eof_eis.push(ei);\n+                    new_pos.match_cur = ei.match_hi;\n+                    new_pos.idx += 1;\n+                    cur_eis.push(new_pos);\n                 }\n-            } else {\n-                match ei.top_elts.get_tt(idx) {\n-                    /* need to descend into sequence */\n-                    TokenTree::Sequence(sp, seq) => {\n-                        if seq.op == tokenstream::KleeneOp::ZeroOrMore {\n-                            let mut new_ei = ei.clone();\n-                            new_ei.match_cur += seq.num_captures;\n-                            new_ei.idx += 1;\n-                            //we specifically matched zero repeats.\n-                            for idx in ei.match_cur..ei.match_cur + seq.num_captures {\n-                                new_ei.matches[idx].push(Rc::new(MatchedSeq(vec![], sp)));\n-                            }\n-\n-                            cur_eis.push(new_ei);\n-                        }\n \n-                        let matches: Vec<_> = (0..ei.matches.len())\n-                            .map(|_| Vec::new()).collect();\n-                        cur_eis.push(Box::new(MatcherPos {\n-                            stack: vec![],\n-                            sep: seq.separator.clone(),\n-                            idx: 0,\n-                            matches: matches,\n-                            match_lo: ei.match_cur,\n-                            match_cur: ei.match_cur,\n-                            match_hi: ei.match_cur + seq.num_captures,\n-                            up: Some(ei),\n-                            sp_lo: sp.lo,\n-                            top_elts: Tt(TokenTree::Sequence(sp, seq)),\n-                        }));\n+                // Check if we need a separator\n+                if idx == len && ei.sep.is_some() {\n+                    // We have a separator, and it is the current token.\n+                    if ei.sep.as_ref().map(|ref sep| token_name_eq(&token, sep)).unwrap_or(false) {\n+                        ei.idx += 1;\n+                        next_eis.push(ei);\n                     }\n-                    TokenTree::Token(_, MatchNt(..)) => {\n-                        // Built-in nonterminals never start with these tokens,\n-                        // so we can eliminate them from consideration.\n-                        match parser.token {\n-                            token::CloseDelim(_) => {},\n-                            _ => bb_eis.push(ei),\n+                } else { // we don't need a separator\n+                    ei.match_cur = ei.match_lo;\n+                    ei.idx = 0;\n+                    cur_eis.push(ei);\n+                }\n+            } else {\n+                // We aren't repeating, so we must be potentially at the end of the input.\n+                eof_eis.push(ei);\n+            }\n+        } else {\n+            match ei.top_elts.get_tt(idx) {\n+                /* need to descend into sequence */\n+                TokenTree::Sequence(sp, seq) => {\n+                    if seq.op == tokenstream::KleeneOp::ZeroOrMore {\n+                        // Examine the case where there are 0 matches of this sequence\n+                        let mut new_ei = ei.clone();\n+                        new_ei.match_cur += seq.num_captures;\n+                        new_ei.idx += 1;\n+                        for idx in ei.match_cur..ei.match_cur + seq.num_captures {\n+                            new_ei.matches[idx].push(Rc::new(MatchedSeq(vec![], sp)));\n                         }\n+                        cur_eis.push(new_ei);\n                     }\n-                    TokenTree::Token(sp, SubstNt(..)) => {\n-                        return Error(sp, \"missing fragment specifier\".to_string())\n-                    }\n-                    seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, DocComment(..)) => {\n-                        let lower_elts = mem::replace(&mut ei.top_elts, Tt(seq));\n-                        let idx = ei.idx;\n-                        ei.stack.push(MatcherTtFrame {\n-                            elts: lower_elts,\n-                            idx: idx,\n-                        });\n-                        ei.idx = 0;\n-                        cur_eis.push(ei);\n+\n+                    // Examine the case where there is at least one match of this sequence\n+                    let matches = create_matches(ei.matches.len());\n+                    cur_eis.push(Box::new(MatcherPos {\n+                        stack: vec![],\n+                        sep: seq.separator.clone(),\n+                        idx: 0,\n+                        matches: matches,\n+                        match_lo: ei.match_cur,\n+                        match_cur: ei.match_cur,\n+                        match_hi: ei.match_cur + seq.num_captures,\n+                        up: Some(ei),\n+                        sp_lo: sp.lo,\n+                        top_elts: Tt(TokenTree::Sequence(sp, seq)),\n+                    }));\n+                }\n+                TokenTree::Token(_, MatchNt(..)) => {\n+                    // Built-in nonterminals never start with these tokens,\n+                    // so we can eliminate them from consideration.\n+                    match *token {\n+                        token::CloseDelim(_) => {},\n+                        _ => bb_eis.push(ei),\n                     }\n-                    TokenTree::Token(_, ref t) => {\n-                        if token_name_eq(t, &parser.token) {\n-                            ei.idx += 1;\n-                            next_eis.push(ei);\n-                        }\n+                }\n+                TokenTree::Token(sp, SubstNt(..)) => {\n+                    return Error(sp, \"missing fragment specifier\".to_string())\n+                }\n+                seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, DocComment(..)) => {\n+                    let lower_elts = mem::replace(&mut ei.top_elts, Tt(seq));\n+                    let idx = ei.idx;\n+                    ei.stack.push(MatcherTtFrame {\n+                        elts: lower_elts,\n+                        idx: idx,\n+                    });\n+                    ei.idx = 0;\n+                    cur_eis.push(ei);\n+                }\n+                TokenTree::Token(_, ref t) => {\n+                    if token_name_eq(t, &token) {\n+                        ei.idx += 1;\n+                        next_eis.push(ei);\n                     }\n                 }\n             }\n         }\n+    }\n+\n+    Success(())\n+}\n+\n+pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseResult {\n+    let mut parser = Parser::new_with_doc_flag(sess, Box::new(rdr), true);\n+    let mut cur_eis = SmallVector::one(initial_matcher_pos(ms.to_owned(), parser.span.lo));\n+\n+    loop {\n+        let mut bb_eis = Vec::new(); // black-box parsed by parser.rs\n+        let mut next_eis = Vec::new(); // or proceed normally\n+\n+        // FIXME: Use SmallVector since in the successful case we will only have one\n+        let mut eof_eis = Vec::new();\n+\n+        match inner_parse_loop(&mut cur_eis, &mut next_eis, &mut eof_eis, &mut bb_eis,\n+                               &parser.token, &parser.span) {\n+            Success(_) => {},\n+            Failure(sp, tok) => return Failure(sp, tok),\n+            Error(sp, msg) => return Error(sp, msg),\n+        }\n+\n+        // inner parse loop handled all cur_eis, so it's empty\n+        assert!(cur_eis.is_empty());\n \n         /* error messages here could be improved with links to orig. rules */\n         if token_name_eq(&parser.token, &token::Eof) {\n             if eof_eis.len() == 1 {\n-                let v = eof_eis[0].matches.iter_mut()\n-                    .map(|dv| dv.pop().unwrap()).collect::<Vec<_>>();\n-                return nameize(ms, &v[..]);\n+                return nameize(ms, eof_eis[0].matches.iter_mut().map(|mut dv| dv.pop().unwrap()));\n             } else if eof_eis.len() > 1 {\n                 return Error(parser.span, \"ambiguity: multiple successful parses\".to_string());\n             } else {\n@@ -473,7 +480,7 @@ pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseRes\n     }\n }\n \n-pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n+fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n     match name {\n         \"tt\" => {\n             p.quote_depth += 1; //but in theory, non-quoted tts might be useful"}]}