{"sha": "84782c4e2681496d57f1ac91468d21df085b7782", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg0NzgyYzRlMjY4MTQ5NmQ1N2YxYWM5MTQ2OGQyMWRmMDg1Yjc3ODI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-08-06T08:31:28Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-08-06T08:31:28Z"}, "message": "auto merge of #16258 : aturon/rust/stabilize-atomics, r=alexcrichton\n\nThis commit stabilizes the `std::sync::atomics` module, renaming it to\r\n`std::sync::atomic` to match library precedent elsewhere, and tightening\r\nup behavior around incorrect memory ordering annotations.\r\n\r\nThe vast majority of the module is now `stable`. However, the\r\n`AtomicOption` type has been deprecated, since it is essentially unused\r\nand is not truly a primitive atomic type. It will eventually be replaced\r\nby a higher-level abstraction like MVars.\r\n\r\nDue to deprecations, this is a:\r\n\r\n[breaking-change]", "tree": {"sha": "d3de416e5827122ec85f0a02388a48ee760ee77e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d3de416e5827122ec85f0a02388a48ee760ee77e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/84782c4e2681496d57f1ac91468d21df085b7782", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/84782c4e2681496d57f1ac91468d21df085b7782", "html_url": "https://github.com/rust-lang/rust/commit/84782c4e2681496d57f1ac91468d21df085b7782", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/84782c4e2681496d57f1ac91468d21df085b7782/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "223c043110c0eb35847bca41e58c0ce11110d78a", "url": "https://api.github.com/repos/rust-lang/rust/commits/223c043110c0eb35847bca41e58c0ce11110d78a", "html_url": "https://github.com/rust-lang/rust/commit/223c043110c0eb35847bca41e58c0ce11110d78a"}, {"sha": "68bde0a07396efb415d61047c6b2a8183f47ef30", "url": "https://api.github.com/repos/rust-lang/rust/commits/68bde0a07396efb415d61047c6b2a8183f47ef30", "html_url": "https://github.com/rust-lang/rust/commit/68bde0a07396efb415d61047c6b2a8183f47ef30"}], "stats": {"total": 674, "additions": 366, "deletions": 308}, "files": [{"sha": "3b0ed52806008ebb7d67b522a73d866a36f3d400", "filename": "src/liballoc/arc.rs", "status": "modified", "additions": 28, "deletions": 28, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Fliballoc%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Fliballoc%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Farc.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -13,7 +13,7 @@\n //! Concurrency-enabled mechanisms for sharing mutable and/or immutable state\n //! between tasks.\n \n-use core::atomics;\n+use core::atomic;\n use core::clone::Clone;\n use core::kinds::{Share, Send};\n use core::mem::{min_align_of, size_of, drop};\n@@ -71,8 +71,8 @@ pub struct Weak<T> {\n }\n \n struct ArcInner<T> {\n-    strong: atomics::AtomicUint,\n-    weak: atomics::AtomicUint,\n+    strong: atomic::AtomicUint,\n+    weak: atomic::AtomicUint,\n     data: T,\n }\n \n@@ -84,8 +84,8 @@ impl<T: Share + Send> Arc<T> {\n         // Start the weak pointer count as 1 which is the weak pointer that's\n         // held by all the strong pointers (kinda), see std/rc.rs for more info\n         let x = box ArcInner {\n-            strong: atomics::AtomicUint::new(1),\n-            weak: atomics::AtomicUint::new(1),\n+            strong: atomic::AtomicUint::new(1),\n+            weak: atomic::AtomicUint::new(1),\n             data: data,\n         };\n         Arc { _ptr: unsafe { mem::transmute(x) } }\n@@ -109,7 +109,7 @@ impl<T: Share + Send> Arc<T> {\n     #[experimental = \"Weak pointers may not belong in this module.\"]\n     pub fn downgrade(&self) -> Weak<T> {\n         // See the clone() impl for why this is relaxed\n-        self.inner().weak.fetch_add(1, atomics::Relaxed);\n+        self.inner().weak.fetch_add(1, atomic::Relaxed);\n         Weak { _ptr: self._ptr }\n     }\n }\n@@ -134,7 +134,7 @@ impl<T: Share + Send> Clone for Arc<T> {\n         // another must already provide any required synchronization.\n         //\n         // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n-        self.inner().strong.fetch_add(1, atomics::Relaxed);\n+        self.inner().strong.fetch_add(1, atomic::Relaxed);\n         Arc { _ptr: self._ptr }\n     }\n }\n@@ -159,8 +159,8 @@ impl<T: Send + Share + Clone> Arc<T> {\n         // Note that we hold a strong reference, which also counts as\n         // a weak reference, so we only clone if there is an\n         // additional reference of either kind.\n-        if self.inner().strong.load(atomics::SeqCst) != 1 ||\n-           self.inner().weak.load(atomics::SeqCst) != 1 {\n+        if self.inner().strong.load(atomic::SeqCst) != 1 ||\n+           self.inner().weak.load(atomic::SeqCst) != 1 {\n             *self = Arc::new(self.deref().clone())\n         }\n         // This unsafety is ok because we're guaranteed that the pointer\n@@ -185,7 +185,7 @@ impl<T: Share + Send> Drop for Arc<T> {\n         // Because `fetch_sub` is already atomic, we do not need to synchronize\n         // with other threads unless we are going to delete the object. This\n         // same logic applies to the below `fetch_sub` to the `weak` count.\n-        if self.inner().strong.fetch_sub(1, atomics::Release) != 1 { return }\n+        if self.inner().strong.fetch_sub(1, atomic::Release) != 1 { return }\n \n         // This fence is needed to prevent reordering of use of the data and\n         // deletion of the data. Because it is marked `Release`, the\n@@ -204,14 +204,14 @@ impl<T: Share + Send> Drop for Arc<T> {\n         // and an \"acquire\" operation before deleting the object.\n         //\n         // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n-        atomics::fence(atomics::Acquire);\n+        atomic::fence(atomic::Acquire);\n \n         // Destroy the data at this time, even though we may not free the box\n         // allocation itself (there may still be weak pointers lying around).\n         unsafe { drop(ptr::read(&self.inner().data)); }\n \n-        if self.inner().weak.fetch_sub(1, atomics::Release) == 1 {\n-            atomics::fence(atomics::Acquire);\n+        if self.inner().weak.fetch_sub(1, atomic::Release) == 1 {\n+            atomic::fence(atomic::Acquire);\n             unsafe { deallocate(self._ptr as *mut u8, size_of::<ArcInner<T>>(),\n                                 min_align_of::<ArcInner<T>>()) }\n         }\n@@ -230,9 +230,9 @@ impl<T: Share + Send> Weak<T> {\n         // fetch_add because once the count hits 0 is must never be above 0.\n         let inner = self.inner();\n         loop {\n-            let n = inner.strong.load(atomics::SeqCst);\n+            let n = inner.strong.load(atomic::SeqCst);\n             if n == 0 { return None }\n-            let old = inner.strong.compare_and_swap(n, n + 1, atomics::SeqCst);\n+            let old = inner.strong.compare_and_swap(n, n + 1, atomic::SeqCst);\n             if old == n { return Some(Arc { _ptr: self._ptr }) }\n         }\n     }\n@@ -249,7 +249,7 @@ impl<T: Share + Send> Clone for Weak<T> {\n     #[inline]\n     fn clone(&self) -> Weak<T> {\n         // See comments in Arc::clone() for why this is relaxed\n-        self.inner().weak.fetch_add(1, atomics::Relaxed);\n+        self.inner().weak.fetch_add(1, atomic::Relaxed);\n         Weak { _ptr: self._ptr }\n     }\n }\n@@ -264,8 +264,8 @@ impl<T: Share + Send> Drop for Weak<T> {\n         // If we find out that we were the last weak pointer, then its time to\n         // deallocate the data entirely. See the discussion in Arc::drop() about\n         // the memory orderings\n-        if self.inner().weak.fetch_sub(1, atomics::Release) == 1 {\n-            atomics::fence(atomics::Acquire);\n+        if self.inner().weak.fetch_sub(1, atomic::Release) == 1 {\n+            atomic::fence(atomic::Acquire);\n             unsafe { deallocate(self._ptr as *mut u8, size_of::<ArcInner<T>>(),\n                                 min_align_of::<ArcInner<T>>()) }\n         }\n@@ -281,21 +281,21 @@ mod tests {\n     use std::mem::drop;\n     use std::ops::Drop;\n     use std::option::{Option, Some, None};\n-    use std::sync::atomics;\n+    use std::sync::atomic;\n     use std::task;\n     use std::vec::Vec;\n     use super::{Arc, Weak};\n     use std::sync::Mutex;\n \n-    struct Canary(*mut atomics::AtomicUint);\n+    struct Canary(*mut atomic::AtomicUint);\n \n     impl Drop for Canary\n     {\n         fn drop(&mut self) {\n             unsafe {\n                 match *self {\n                     Canary(c) => {\n-                        (*c).fetch_add(1, atomics::SeqCst);\n+                        (*c).fetch_add(1, atomic::SeqCst);\n                     }\n                 }\n             }\n@@ -413,20 +413,20 @@ mod tests {\n \n     #[test]\n     fn drop_arc() {\n-        let mut canary = atomics::AtomicUint::new(0);\n-        let x = Arc::new(Canary(&mut canary as *mut atomics::AtomicUint));\n+        let mut canary = atomic::AtomicUint::new(0);\n+        let x = Arc::new(Canary(&mut canary as *mut atomic::AtomicUint));\n         drop(x);\n-        assert!(canary.load(atomics::Acquire) == 1);\n+        assert!(canary.load(atomic::Acquire) == 1);\n     }\n \n     #[test]\n     fn drop_arc_weak() {\n-        let mut canary = atomics::AtomicUint::new(0);\n-        let arc = Arc::new(Canary(&mut canary as *mut atomics::AtomicUint));\n+        let mut canary = atomic::AtomicUint::new(0);\n+        let arc = Arc::new(Canary(&mut canary as *mut atomic::AtomicUint));\n         let arc_weak = arc.downgrade();\n-        assert!(canary.load(atomics::Acquire) == 0);\n+        assert!(canary.load(atomic::Acquire) == 0);\n         drop(arc);\n-        assert!(canary.load(atomics::Acquire) == 1);\n+        assert!(canary.load(atomic::Acquire) == 1);\n         drop(arc_weak);\n     }\n }"}, {"sha": "e248b934b69c5480a954ef22f3d5830cc6542490", "filename": "src/libcore/atomic.rs", "status": "renamed", "additions": 76, "deletions": 25, "changes": 101, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcore%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcore%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fatomic.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -10,29 +10,35 @@\n \n //! Core atomic primitives\n \n+#![stable]\n+\n use intrinsics;\n use std::kinds::marker;\n use cell::UnsafeCell;\n \n /// An atomic boolean type.\n+#[stable]\n pub struct AtomicBool {\n     v: UnsafeCell<uint>,\n     nocopy: marker::NoCopy\n }\n \n /// A signed atomic integer type, supporting basic atomic arithmetic operations\n+#[stable]\n pub struct AtomicInt {\n     v: UnsafeCell<int>,\n     nocopy: marker::NoCopy\n }\n \n /// An unsigned atomic integer type, supporting basic atomic arithmetic operations\n+#[stable]\n pub struct AtomicUint {\n     v: UnsafeCell<uint>,\n     nocopy: marker::NoCopy\n }\n \n /// An unsafe atomic pointer. Only supports basic atomic operations\n+#[stable]\n pub struct AtomicPtr<T> {\n     p: UnsafeCell<uint>,\n     nocopy: marker::NoCopy\n@@ -49,6 +55,7 @@ pub struct AtomicPtr<T> {\n /// Rust's memory orderings are the same as in C++[1].\n ///\n /// 1: http://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync\n+#[stable]\n pub enum Ordering {\n     /// No ordering constraints, only atomic operations\n     Relaxed,\n@@ -69,18 +76,22 @@ pub enum Ordering {\n }\n \n /// An `AtomicBool` initialized to `false`\n+#[unstable = \"may be renamed, pending conventions for static initalizers\"]\n pub static INIT_ATOMIC_BOOL: AtomicBool =\n         AtomicBool { v: UnsafeCell { value: 0 }, nocopy: marker::NoCopy };\n /// An `AtomicInt` initialized to `0`\n+#[unstable = \"may be renamed, pending conventions for static initalizers\"]\n pub static INIT_ATOMIC_INT: AtomicInt =\n         AtomicInt { v: UnsafeCell { value: 0 }, nocopy: marker::NoCopy };\n /// An `AtomicUint` initialized to `0`\n+#[unstable = \"may be renamed, pending conventions for static initalizers\"]\n pub static INIT_ATOMIC_UINT: AtomicUint =\n         AtomicUint { v: UnsafeCell { value: 0, }, nocopy: marker::NoCopy };\n \n // NB: Needs to be -1 (0b11111111...) to make fetch_nand work correctly\n static UINT_TRUE: uint = -1;\n \n+#[stable]\n impl AtomicBool {\n     /// Create a new `AtomicBool`\n     pub fn new(v: bool) -> AtomicBool {\n@@ -89,12 +100,20 @@ impl AtomicBool {\n     }\n \n     /// Load the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Release` or `AcqRel`.\n     #[inline]\n     pub fn load(&self, order: Ordering) -> bool {\n         unsafe { atomic_load(self.v.get() as *const uint, order) > 0 }\n     }\n \n     /// Store the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Acquire` or `AcqRel`.\n     #[inline]\n     pub fn store(&self, val: bool, order: Ordering) {\n         let val = if val { UINT_TRUE } else { 0 };\n@@ -120,7 +139,7 @@ impl AtomicBool {\n     ///\n     /// ```rust\n     /// use std::sync::Arc;\n-    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    /// use std::sync::atomic::{AtomicBool, SeqCst};\n     /// use std::task::deschedule;\n     ///\n     /// fn main() {\n@@ -170,7 +189,7 @@ impl AtomicBool {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    /// use std::sync::atomic::{AtomicBool, SeqCst};\n     ///\n     /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_and(false, SeqCst));\n@@ -200,7 +219,7 @@ impl AtomicBool {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    /// use std::sync::atomic::{AtomicBool, SeqCst};\n     ///\n     /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_nand(false, SeqCst));\n@@ -231,7 +250,7 @@ impl AtomicBool {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    /// use std::sync::atomic::{AtomicBool, SeqCst};\n     ///\n     /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_or(false, SeqCst));\n@@ -261,7 +280,7 @@ impl AtomicBool {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    /// use std::sync::atomic::{AtomicBool, SeqCst};\n     ///\n     /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_xor(false, SeqCst));\n@@ -283,19 +302,28 @@ impl AtomicBool {\n     }\n }\n \n+#[stable]\n impl AtomicInt {\n     /// Create a new `AtomicInt`\n     pub fn new(v: int) -> AtomicInt {\n         AtomicInt {v: UnsafeCell::new(v), nocopy: marker::NoCopy}\n     }\n \n     /// Load the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Release` or `AcqRel`.\n     #[inline]\n     pub fn load(&self, order: Ordering) -> int {\n         unsafe { atomic_load(self.v.get() as *const int, order) }\n     }\n \n     /// Store the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Acquire` or `AcqRel`.\n     #[inline]\n     pub fn store(&self, val: int, order: Ordering) {\n         unsafe { atomic_store(self.v.get(), val, order); }\n@@ -322,7 +350,7 @@ impl AtomicInt {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicInt, SeqCst};\n+    /// use std::sync::atomic::{AtomicInt, SeqCst};\n     ///\n     /// let foo = AtomicInt::new(0);\n     /// assert_eq!(0, foo.fetch_add(10, SeqCst));\n@@ -338,7 +366,7 @@ impl AtomicInt {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicInt, SeqCst};\n+    /// use std::sync::atomic::{AtomicInt, SeqCst};\n     ///\n     /// let foo = AtomicInt::new(0);\n     /// assert_eq!(0, foo.fetch_sub(10, SeqCst));\n@@ -354,7 +382,7 @@ impl AtomicInt {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0b101101);\n     /// assert_eq!(0b101101, foo.fetch_and(0b110011, SeqCst));\n@@ -369,7 +397,7 @@ impl AtomicInt {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0b101101);\n     /// assert_eq!(0b101101, foo.fetch_or(0b110011, SeqCst));\n@@ -384,7 +412,7 @@ impl AtomicInt {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0b101101);\n     /// assert_eq!(0b101101, foo.fetch_xor(0b110011, SeqCst));\n@@ -395,19 +423,28 @@ impl AtomicInt {\n     }\n }\n \n+#[stable]\n impl AtomicUint {\n     /// Create a new `AtomicUint`\n     pub fn new(v: uint) -> AtomicUint {\n         AtomicUint { v: UnsafeCell::new(v), nocopy: marker::NoCopy }\n     }\n \n     /// Load the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Release` or `AcqRel`.\n     #[inline]\n     pub fn load(&self, order: Ordering) -> uint {\n         unsafe { atomic_load(self.v.get() as *const uint, order) }\n     }\n \n     /// Store the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Acquire` or `AcqRel`.\n     #[inline]\n     pub fn store(&self, val: uint, order: Ordering) {\n         unsafe { atomic_store(self.v.get(), val, order); }\n@@ -434,7 +471,7 @@ impl AtomicUint {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0);\n     /// assert_eq!(0, foo.fetch_add(10, SeqCst));\n@@ -450,7 +487,7 @@ impl AtomicUint {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(10);\n     /// assert_eq!(10, foo.fetch_sub(10, SeqCst));\n@@ -466,7 +503,7 @@ impl AtomicUint {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0b101101);\n     /// assert_eq!(0b101101, foo.fetch_and(0b110011, SeqCst));\n@@ -481,7 +518,7 @@ impl AtomicUint {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0b101101);\n     /// assert_eq!(0b101101, foo.fetch_or(0b110011, SeqCst));\n@@ -496,7 +533,7 @@ impl AtomicUint {\n     /// # Examples\n     ///\n     /// ```\n-    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    /// use std::sync::atomic::{AtomicUint, SeqCst};\n     ///\n     /// let foo = AtomicUint::new(0b101101);\n     /// assert_eq!(0b101101, foo.fetch_xor(0b110011, SeqCst));\n@@ -507,13 +544,18 @@ impl AtomicUint {\n     }\n }\n \n+#[stable]\n impl<T> AtomicPtr<T> {\n     /// Create a new `AtomicPtr`\n     pub fn new(p: *mut T) -> AtomicPtr<T> {\n         AtomicPtr { p: UnsafeCell::new(p as uint), nocopy: marker::NoCopy }\n     }\n \n     /// Load the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Release` or `AcqRel`.\n     #[inline]\n     pub fn load(&self, order: Ordering) -> *mut T {\n         unsafe {\n@@ -522,6 +564,10 @@ impl<T> AtomicPtr<T> {\n     }\n \n     /// Store the value\n+    ///\n+    /// # Failure\n+    ///\n+    /// Fails if `order` is `Acquire` or `AcqRel`.\n     #[inline]\n     pub fn store(&self, ptr: *mut T, order: Ordering) {\n         unsafe { atomic_store(self.p.get(), ptr as uint, order); }\n@@ -552,7 +598,9 @@ unsafe fn atomic_store<T>(dst: *mut T, val: T, order:Ordering) {\n     match order {\n         Release => intrinsics::atomic_store_rel(dst, val),\n         Relaxed => intrinsics::atomic_store_relaxed(dst, val),\n-        _       => intrinsics::atomic_store(dst, val)\n+        SeqCst  => intrinsics::atomic_store(dst, val),\n+        Acquire => fail!(\"there is no such thing as an acquire store\"),\n+        AcqRel  => fail!(\"there is no such thing as an acquire/release store\"),\n     }\n }\n \n@@ -561,7 +609,9 @@ unsafe fn atomic_load<T>(dst: *const T, order:Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_load_acq(dst),\n         Relaxed => intrinsics::atomic_load_relaxed(dst),\n-        _       => intrinsics::atomic_load(dst)\n+        SeqCst  => intrinsics::atomic_load(dst),\n+        Release => fail!(\"there is no such thing as a release load\"),\n+        AcqRel  => fail!(\"there is no such thing as an acquire/release load\"),\n     }\n }\n \n@@ -572,7 +622,7 @@ unsafe fn atomic_swap<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_xchg_rel(dst, val),\n         AcqRel  => intrinsics::atomic_xchg_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_xchg_relaxed(dst, val),\n-        _       => intrinsics::atomic_xchg(dst, val)\n+        SeqCst  => intrinsics::atomic_xchg(dst, val)\n     }\n }\n \n@@ -584,7 +634,7 @@ unsafe fn atomic_add<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_xadd_rel(dst, val),\n         AcqRel  => intrinsics::atomic_xadd_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_xadd_relaxed(dst, val),\n-        _       => intrinsics::atomic_xadd(dst, val)\n+        SeqCst  => intrinsics::atomic_xadd(dst, val)\n     }\n }\n \n@@ -596,7 +646,7 @@ unsafe fn atomic_sub<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_xsub_rel(dst, val),\n         AcqRel  => intrinsics::atomic_xsub_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_xsub_relaxed(dst, val),\n-        _       => intrinsics::atomic_xsub(dst, val)\n+        SeqCst  => intrinsics::atomic_xsub(dst, val)\n     }\n }\n \n@@ -607,7 +657,7 @@ unsafe fn atomic_compare_and_swap<T>(dst: *mut T, old:T, new:T, order: Ordering)\n         Release => intrinsics::atomic_cxchg_rel(dst, old, new),\n         AcqRel  => intrinsics::atomic_cxchg_acqrel(dst, old, new),\n         Relaxed => intrinsics::atomic_cxchg_relaxed(dst, old, new),\n-        _       => intrinsics::atomic_cxchg(dst, old, new),\n+        SeqCst  => intrinsics::atomic_cxchg(dst, old, new),\n     }\n }\n \n@@ -618,7 +668,7 @@ unsafe fn atomic_and<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_and_rel(dst, val),\n         AcqRel  => intrinsics::atomic_and_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_and_relaxed(dst, val),\n-        _       => intrinsics::atomic_and(dst, val)\n+        SeqCst  => intrinsics::atomic_and(dst, val)\n     }\n }\n \n@@ -629,7 +679,7 @@ unsafe fn atomic_nand<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_nand_rel(dst, val),\n         AcqRel  => intrinsics::atomic_nand_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_nand_relaxed(dst, val),\n-        _       => intrinsics::atomic_nand(dst, val)\n+        SeqCst  => intrinsics::atomic_nand(dst, val)\n     }\n }\n \n@@ -641,7 +691,7 @@ unsafe fn atomic_or<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_or_rel(dst, val),\n         AcqRel  => intrinsics::atomic_or_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_or_relaxed(dst, val),\n-        _       => intrinsics::atomic_or(dst, val)\n+        SeqCst  => intrinsics::atomic_or(dst, val)\n     }\n }\n \n@@ -653,7 +703,7 @@ unsafe fn atomic_xor<T>(dst: *mut T, val: T, order: Ordering) -> T {\n         Release => intrinsics::atomic_xor_rel(dst, val),\n         AcqRel  => intrinsics::atomic_xor_acqrel(dst, val),\n         Relaxed => intrinsics::atomic_xor_relaxed(dst, val),\n-        _       => intrinsics::atomic_xor(dst, val)\n+        SeqCst  => intrinsics::atomic_xor(dst, val)\n     }\n }\n \n@@ -679,6 +729,7 @@ unsafe fn atomic_xor<T>(dst: *mut T, val: T, order: Ordering) -> T {\n ///\n /// Fails if `order` is `Relaxed`\n #[inline]\n+#[stable]\n pub fn fence(order: Ordering) {\n     unsafe {\n         match order {", "previous_filename": "src/libcore/atomics.rs"}, {"sha": "e4285ed597c8b0268e85dc823ee2ce9dd432dea1", "filename": "src/libcore/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcore%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcore%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Flib.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -113,7 +113,7 @@ pub mod ty {\n /* Core types and methods on primitives */\n \n pub mod any;\n-pub mod atomics;\n+pub mod atomic;\n pub mod bool;\n pub mod cell;\n pub mod char;"}, {"sha": "e8fae3fa6df65394f2117fa41edd58e09cc23b25", "filename": "src/libcoretest/atomic.rs", "status": "renamed", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcoretest%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcoretest%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcoretest%2Fatomic.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use core::atomics::*;\n+use core::atomic::*;\n \n #[test]\n fn bool_() {", "previous_filename": "src/libcoretest/atomics.rs"}, {"sha": "0b8ae09c9a3461ad10bb5393b5d1c28d8d180d6b", "filename": "src/libcoretest/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcoretest%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibcoretest%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcoretest%2Flib.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -14,7 +14,7 @@ extern crate test;\n extern crate libc;\n \n mod any;\n-mod atomics;\n+mod atomic;\n mod cell;\n mod char;\n mod cmp;"}, {"sha": "e48786f33745f00b2649a763fdc65ece3ce9b986", "filename": "src/libgreen/basic.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibgreen%2Fbasic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibgreen%2Fbasic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fbasic.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -16,7 +16,7 @@\n //! loop if no other one is provided (and M:N scheduling is desired).\n \n use alloc::arc::Arc;\n-use std::sync::atomics;\n+use std::sync::atomic;\n use std::mem;\n use std::rt::rtio::{EventLoop, IoFactory, RemoteCallback};\n use std::rt::rtio::{PausableIdleCallback, Callback};\n@@ -33,7 +33,7 @@ struct BasicLoop {\n     next_remote: uint,\n     messages: Arc<Exclusive<Vec<Message>>>,\n     idle: Option<Box<Callback + Send>>,\n-    idle_active: Option<Arc<atomics::AtomicBool>>,\n+    idle_active: Option<Arc<atomic::AtomicBool>>,\n }\n \n enum Message { RunRemote(uint), RemoveRemote(uint) }\n@@ -89,7 +89,7 @@ impl BasicLoop {\n     fn idle(&mut self) {\n         match self.idle {\n             Some(ref mut idle) => {\n-                if self.idle_active.get_ref().load(atomics::SeqCst) {\n+                if self.idle_active.get_ref().load(atomic::SeqCst) {\n                     idle.call();\n                 }\n             }\n@@ -98,7 +98,7 @@ impl BasicLoop {\n     }\n \n     fn has_idle(&self) -> bool {\n-        self.idle.is_some() && self.idle_active.get_ref().load(atomics::SeqCst)\n+        self.idle.is_some() && self.idle_active.get_ref().load(atomic::SeqCst)\n     }\n }\n \n@@ -136,7 +136,7 @@ impl EventLoop for BasicLoop {\n                               -> Box<PausableIdleCallback + Send> {\n         rtassert!(self.idle.is_none());\n         self.idle = Some(cb);\n-        let a = Arc::new(atomics::AtomicBool::new(true));\n+        let a = Arc::new(atomic::AtomicBool::new(true));\n         self.idle_active = Some(a.clone());\n         box BasicPausable { active: a } as Box<PausableIdleCallback + Send>\n     }\n@@ -183,21 +183,21 @@ impl Drop for BasicRemote {\n }\n \n struct BasicPausable {\n-    active: Arc<atomics::AtomicBool>,\n+    active: Arc<atomic::AtomicBool>,\n }\n \n impl PausableIdleCallback for BasicPausable {\n     fn pause(&mut self) {\n-        self.active.store(false, atomics::SeqCst);\n+        self.active.store(false, atomic::SeqCst);\n     }\n     fn resume(&mut self) {\n-        self.active.store(true, atomics::SeqCst);\n+        self.active.store(true, atomic::SeqCst);\n     }\n }\n \n impl Drop for BasicPausable {\n     fn drop(&mut self) {\n-        self.active.store(false, atomics::SeqCst);\n+        self.active.store(false, atomic::SeqCst);\n     }\n }\n "}, {"sha": "5c280a31db792565d3bc3b4940d9dc73804759a6", "filename": "src/libgreen/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibgreen%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibgreen%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Flib.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -232,7 +232,7 @@ use std::rt::rtio;\n use std::rt::thread::Thread;\n use std::rt::task::TaskOpts;\n use std::rt;\n-use std::sync::atomics::{SeqCst, AtomicUint, INIT_ATOMIC_UINT};\n+use std::sync::atomic::{SeqCst, AtomicUint, INIT_ATOMIC_UINT};\n use std::sync::deque;\n use std::task::{TaskBuilder, Spawner};\n "}, {"sha": "601758f8a25dfb207f8f68e28c7c31a26256a538", "filename": "src/libgreen/stack.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibgreen%2Fstack.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibgreen%2Fstack.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fstack.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -9,7 +9,7 @@\n // except according to those terms.\n \n use std::ptr;\n-use std::sync::atomics;\n+use std::sync::atomic;\n use std::os::{errno, page_size, MemoryMap, MapReadable, MapWritable,\n               MapNonStandardFlags, getenv};\n use libc;\n@@ -158,8 +158,8 @@ impl StackPool {\n }\n \n fn max_cached_stacks() -> uint {\n-    static mut AMT: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n-    match unsafe { AMT.load(atomics::SeqCst) } {\n+    static mut AMT: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n+    match unsafe { AMT.load(atomic::SeqCst) } {\n         0 => {}\n         n => return n - 1,\n     }\n@@ -169,7 +169,7 @@ fn max_cached_stacks() -> uint {\n     let amt = amt.unwrap_or(10);\n     // 0 is our sentinel value, so ensure that we'll never see 0 after\n     // initialization has run\n-    unsafe { AMT.store(amt + 1, atomics::SeqCst); }\n+    unsafe { AMT.store(amt + 1, atomic::SeqCst); }\n     return amt;\n }\n "}, {"sha": "87129bba845bf513e88aa0470a8991bbdc3679b8", "filename": "src/libnative/io/pipe_win32.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibnative%2Fio%2Fpipe_win32.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibnative%2Fio%2Fpipe_win32.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Fpipe_win32.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -92,7 +92,7 @@ use std::os;\n use std::ptr;\n use std::rt::rtio;\n use std::rt::rtio::{IoResult, IoError};\n-use std::sync::atomics;\n+use std::sync::atomic;\n use std::rt::mutex;\n \n use super::c;\n@@ -128,17 +128,17 @@ impl Drop for Event {\n struct Inner {\n     handle: libc::HANDLE,\n     lock: mutex::NativeMutex,\n-    read_closed: atomics::AtomicBool,\n-    write_closed: atomics::AtomicBool,\n+    read_closed: atomic::AtomicBool,\n+    write_closed: atomic::AtomicBool,\n }\n \n impl Inner {\n     fn new(handle: libc::HANDLE) -> Inner {\n         Inner {\n             handle: handle,\n             lock: unsafe { mutex::NativeMutex::new() },\n-            read_closed: atomics::AtomicBool::new(false),\n-            write_closed: atomics::AtomicBool::new(false),\n+            read_closed: atomic::AtomicBool::new(false),\n+            write_closed: atomic::AtomicBool::new(false),\n         }\n     }\n }\n@@ -326,11 +326,11 @@ impl UnixStream {\n     fn handle(&self) -> libc::HANDLE { self.inner.handle }\n \n     fn read_closed(&self) -> bool {\n-        self.inner.read_closed.load(atomics::SeqCst)\n+        self.inner.read_closed.load(atomic::SeqCst)\n     }\n \n     fn write_closed(&self) -> bool {\n-        self.inner.write_closed.load(atomics::SeqCst)\n+        self.inner.write_closed.load(atomic::SeqCst)\n     }\n \n     fn cancel_io(&self) -> IoResult<()> {\n@@ -525,14 +525,14 @@ impl rtio::RtioPipe for UnixStream {\n         // and 2 with a lock with respect to close_read(), we're guaranteed that\n         // no thread will erroneously sit in a read forever.\n         let _guard = unsafe { self.inner.lock.lock() };\n-        self.inner.read_closed.store(true, atomics::SeqCst);\n+        self.inner.read_closed.store(true, atomic::SeqCst);\n         self.cancel_io()\n     }\n \n     fn close_write(&mut self) -> IoResult<()> {\n         // see comments in close_read() for why this lock is necessary\n         let _guard = unsafe { self.inner.lock.lock() };\n-        self.inner.write_closed.store(true, atomics::SeqCst);\n+        self.inner.write_closed.store(true, atomic::SeqCst);\n         self.cancel_io()\n     }\n "}, {"sha": "06d48f2f886b8ea7796b6440b85f28e2127f66d6", "filename": "src/libnative/io/timer_unix.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibnative%2Fio%2Ftimer_unix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibnative%2Fio%2Ftimer_unix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Ftimer_unix.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -52,7 +52,7 @@ use std::os;\n use std::ptr;\n use std::rt::rtio;\n use std::rt::rtio::IoResult;\n-use std::sync::atomics;\n+use std::sync::atomic;\n use std::comm;\n \n use io::c;\n@@ -207,8 +207,8 @@ impl Timer {\n         // instead of ()\n         unsafe { HELPER.boot(|| {}, helper); }\n \n-        static mut ID: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n-        let id = unsafe { ID.fetch_add(1, atomics::Relaxed) };\n+        static mut ID: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n+        let id = unsafe { ID.fetch_add(1, atomic::Relaxed) };\n         Ok(Timer {\n             id: id,\n             inner: Some(box Inner {"}, {"sha": "8137669298124a3e74387380638b643ba73bd9cd", "filename": "src/librustrt/at_exit_imp.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Fat_exit_imp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Fat_exit_imp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Fat_exit_imp.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -17,21 +17,21 @@ use core::prelude::*;\n use alloc::boxed::Box;\n use collections::MutableSeq;\n use collections::vec::Vec;\n-use core::atomics;\n+use core::atomic;\n use core::mem;\n \n use exclusive::Exclusive;\n \n type Queue = Exclusive<Vec<proc():Send>>;\n \n-static mut QUEUE: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n-static mut RUNNING: atomics::AtomicBool = atomics::INIT_ATOMIC_BOOL;\n+static mut QUEUE: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n+static mut RUNNING: atomic::AtomicBool = atomic::INIT_ATOMIC_BOOL;\n \n pub fn init() {\n     let state: Box<Queue> = box Exclusive::new(Vec::new());\n     unsafe {\n-        rtassert!(!RUNNING.load(atomics::SeqCst));\n-        assert!(QUEUE.swap(mem::transmute(state), atomics::SeqCst) == 0);\n+        rtassert!(!RUNNING.load(atomic::SeqCst));\n+        assert!(QUEUE.swap(mem::transmute(state), atomic::SeqCst) == 0);\n     }\n }\n \n@@ -41,17 +41,17 @@ pub fn push(f: proc():Send) {\n         // all with respect to `run`, meaning that this could theoretically be a\n         // use-after-free. There's not much we can do to protect against that,\n         // however. Let's just assume a well-behaved runtime and go from there!\n-        rtassert!(!RUNNING.load(atomics::SeqCst));\n-        let queue = QUEUE.load(atomics::SeqCst);\n+        rtassert!(!RUNNING.load(atomic::SeqCst));\n+        let queue = QUEUE.load(atomic::SeqCst);\n         rtassert!(queue != 0);\n         (*(queue as *const Queue)).lock().push(f);\n     }\n }\n \n pub fn run() {\n     let cur = unsafe {\n-        rtassert!(!RUNNING.load(atomics::SeqCst));\n-        let queue = QUEUE.swap(0, atomics::SeqCst);\n+        rtassert!(!RUNNING.load(atomic::SeqCst));\n+        let queue = QUEUE.swap(0, atomic::SeqCst);\n         rtassert!(queue != 0);\n \n         let queue: Box<Queue> = mem::transmute(queue);"}, {"sha": "a88bc86828f82eeff793f89e149dfaf1924daf78", "filename": "src/librustrt/bookkeeping.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Fbookkeeping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Fbookkeeping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Fbookkeeping.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -18,12 +18,12 @@\n //! each respective runtime to make sure that they call increment() and\n //! decrement() manually.\n \n-use core::atomics;\n+use core::atomic;\n use core::ops::Drop;\n \n use mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n \n-static mut TASK_COUNT: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n+static mut TASK_COUNT: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n static mut TASK_LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n \n pub struct Token { _private: () }\n@@ -35,13 +35,13 @@ impl Drop for Token {\n /// Increment the number of live tasks, returning a token which will decrement\n /// the count when dropped.\n pub fn increment() -> Token {\n-    let _ = unsafe { TASK_COUNT.fetch_add(1, atomics::SeqCst) };\n+    let _ = unsafe { TASK_COUNT.fetch_add(1, atomic::SeqCst) };\n     Token { _private: () }\n }\n \n pub fn decrement() {\n     unsafe {\n-        if TASK_COUNT.fetch_sub(1, atomics::SeqCst) == 1 {\n+        if TASK_COUNT.fetch_sub(1, atomic::SeqCst) == 1 {\n             let guard = TASK_LOCK.lock();\n             guard.signal();\n         }\n@@ -53,7 +53,7 @@ pub fn decrement() {\n pub fn wait_for_other_tasks() {\n     unsafe {\n         let guard = TASK_LOCK.lock();\n-        while TASK_COUNT.load(atomics::SeqCst) > 0 {\n+        while TASK_COUNT.load(atomic::SeqCst) > 0 {\n             guard.wait();\n         }\n     }"}, {"sha": "08da9b8aad1b01424236bd4ddbee55c0ec2c2b71", "filename": "src/librustrt/mutex.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Fmutex.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -519,7 +519,7 @@ mod imp {\n #[cfg(windows)]\n mod imp {\n     use alloc::libc_heap::malloc_raw;\n-    use core::atomics;\n+    use core::atomic;\n     use core::ptr;\n     use libc::{HANDLE, BOOL, LPSECURITY_ATTRIBUTES, c_void, DWORD, LPCSTR};\n     use libc;\n@@ -533,20 +533,20 @@ mod imp {\n \n     pub struct Mutex {\n         // pointers for the lock/cond handles, atomically updated\n-        lock: atomics::AtomicUint,\n-        cond: atomics::AtomicUint,\n+        lock: atomic::AtomicUint,\n+        cond: atomic::AtomicUint,\n     }\n \n     pub static MUTEX_INIT: Mutex = Mutex {\n-        lock: atomics::INIT_ATOMIC_UINT,\n-        cond: atomics::INIT_ATOMIC_UINT,\n+        lock: atomic::INIT_ATOMIC_UINT,\n+        cond: atomic::INIT_ATOMIC_UINT,\n     };\n \n     impl Mutex {\n         pub unsafe fn new() -> Mutex {\n             Mutex {\n-                lock: atomics::AtomicUint::new(init_lock()),\n-                cond: atomics::AtomicUint::new(init_cond()),\n+                lock: atomic::AtomicUint::new(init_lock()),\n+                cond: atomic::AtomicUint::new(init_cond()),\n             }\n         }\n         pub unsafe fn lock(&self) {\n@@ -573,38 +573,38 @@ mod imp {\n         /// that no other thread is currently holding the lock or waiting on the\n         /// condition variable contained inside.\n         pub unsafe fn destroy(&self) {\n-            let lock = self.lock.swap(0, atomics::SeqCst);\n-            let cond = self.cond.swap(0, atomics::SeqCst);\n+            let lock = self.lock.swap(0, atomic::SeqCst);\n+            let cond = self.cond.swap(0, atomic::SeqCst);\n             if lock != 0 { free_lock(lock) }\n             if cond != 0 { free_cond(cond) }\n         }\n \n         unsafe fn getlock(&self) -> *mut c_void {\n-            match self.lock.load(atomics::SeqCst) {\n+            match self.lock.load(atomic::SeqCst) {\n                 0 => {}\n                 n => return n as *mut c_void\n             }\n             let lock = init_lock();\n-            match self.lock.compare_and_swap(0, lock, atomics::SeqCst) {\n+            match self.lock.compare_and_swap(0, lock, atomic::SeqCst) {\n                 0 => return lock as *mut c_void,\n                 _ => {}\n             }\n             free_lock(lock);\n-            return self.lock.load(atomics::SeqCst) as *mut c_void;\n+            return self.lock.load(atomic::SeqCst) as *mut c_void;\n         }\n \n         unsafe fn getcond(&self) -> *mut c_void {\n-            match self.cond.load(atomics::SeqCst) {\n+            match self.cond.load(atomic::SeqCst) {\n                 0 => {}\n                 n => return n as *mut c_void\n             }\n             let cond = init_cond();\n-            match self.cond.compare_and_swap(0, cond, atomics::SeqCst) {\n+            match self.cond.compare_and_swap(0, cond, atomic::SeqCst) {\n                 0 => return cond as *mut c_void,\n                 _ => {}\n             }\n             free_cond(cond);\n-            return self.cond.load(atomics::SeqCst) as *mut c_void;\n+            return self.cond.load(atomic::SeqCst) as *mut c_void;\n         }\n     }\n "}, {"sha": "881756c5266fcbe1f855690e773398d3af6a19b0", "filename": "src/librustrt/task.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Ftask.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -18,7 +18,7 @@ use core::prelude::*;\n use alloc::arc::Arc;\n use alloc::boxed::{BoxAny, Box};\n use core::any::Any;\n-use core::atomics::{AtomicUint, SeqCst};\n+use core::atomic::{AtomicUint, SeqCst};\n use core::iter::Take;\n use core::kinds::marker;\n use core::mem;"}, {"sha": "1f170bab28e0f420ef239cd1c04e4bc809bf5e85", "filename": "src/librustrt/unwind.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Funwind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibrustrt%2Funwind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Funwind.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -63,7 +63,7 @@ use alloc::boxed::Box;\n use collections::string::String;\n use collections::vec::Vec;\n use core::any::Any;\n-use core::atomics;\n+use core::atomic;\n use core::cmp;\n use core::fmt;\n use core::intrinsics;\n@@ -91,16 +91,16 @@ pub type Callback = fn(msg: &Any + Send, file: &'static str, line: uint);\n //\n // For more information, see below.\n static MAX_CALLBACKS: uint = 16;\n-static mut CALLBACKS: [atomics::AtomicUint, ..MAX_CALLBACKS] =\n-        [atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT,\n-         atomics::INIT_ATOMIC_UINT, atomics::INIT_ATOMIC_UINT];\n-static mut CALLBACK_CNT: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n+static mut CALLBACKS: [atomic::AtomicUint, ..MAX_CALLBACKS] =\n+        [atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT,\n+         atomic::INIT_ATOMIC_UINT, atomic::INIT_ATOMIC_UINT];\n+static mut CALLBACK_CNT: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n \n impl Unwinder {\n     pub fn new() -> Unwinder {\n@@ -469,11 +469,11 @@ fn begin_unwind_inner(msg: Box<Any + Send>, file_line: &(&'static str, uint)) ->\n     // callback. Additionally, CALLBACK_CNT may briefly be higher than\n     // MAX_CALLBACKS, so we're sure to clamp it as necessary.\n     let callbacks = unsafe {\n-        let amt = CALLBACK_CNT.load(atomics::SeqCst);\n+        let amt = CALLBACK_CNT.load(atomic::SeqCst);\n         CALLBACKS.slice_to(cmp::min(amt, MAX_CALLBACKS))\n     };\n     for cb in callbacks.iter() {\n-        match cb.load(atomics::SeqCst) {\n+        match cb.load(atomic::SeqCst) {\n             0 => {}\n             n => {\n                 let f: Callback = unsafe { mem::transmute(n) };\n@@ -521,18 +521,18 @@ fn begin_unwind_inner(msg: Box<Any + Send>, file_line: &(&'static str, uint)) ->\n /// currently possible to unregister a callback once it has been registered.\n #[experimental]\n pub unsafe fn register(f: Callback) -> bool {\n-    match CALLBACK_CNT.fetch_add(1, atomics::SeqCst) {\n+    match CALLBACK_CNT.fetch_add(1, atomic::SeqCst) {\n         // The invocation code has knowledge of this window where the count has\n         // been incremented, but the callback has not been stored. We're\n         // guaranteed that the slot we're storing into is 0.\n         n if n < MAX_CALLBACKS => {\n-            let prev = CALLBACKS[n].swap(mem::transmute(f), atomics::SeqCst);\n+            let prev = CALLBACKS[n].swap(mem::transmute(f), atomic::SeqCst);\n             rtassert!(prev == 0);\n             true\n         }\n         // If we accidentally bumped the count too high, pull it back.\n         _ => {\n-            CALLBACK_CNT.store(MAX_CALLBACKS, atomics::SeqCst);\n+            CALLBACK_CNT.store(MAX_CALLBACKS, atomic::SeqCst);\n             false\n         }\n     }"}, {"sha": "1d53ed814377e605b197e30966ef68ed088a2688", "filename": "src/libstd/io/tempfile.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fio%2Ftempfile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fio%2Ftempfile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Ftempfile.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -19,7 +19,7 @@ use option::{Option, None, Some};\n use os;\n use path::{Path, GenericPath};\n use result::{Ok, Err};\n-use sync::atomics;\n+use sync::atomic;\n \n #[cfg(stage0)]\n use iter::Iterator; // NOTE(stage0): Remove after snapshot.\n@@ -42,13 +42,13 @@ impl TempDir {\n             return TempDir::new_in(&os::make_absolute(tmpdir), suffix);\n         }\n \n-        static mut CNT: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n+        static mut CNT: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n \n         for _ in range(0u, 1000) {\n             let filename =\n                 format!(\"rs-{}-{}-{}\",\n                         unsafe { libc::getpid() },\n-                        unsafe { CNT.fetch_add(1, atomics::SeqCst) },\n+                        unsafe { CNT.fetch_add(1, atomic::SeqCst) },\n                         suffix);\n             let p = tmpdir.join(filename);\n             match fs::mkdir(&p, io::UserRWX) {"}, {"sha": "331cfa1a59ef9e5de8570c9cbf042f764533006b", "filename": "src/libstd/io/test.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fio%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fio%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Ftest.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -16,7 +16,7 @@ use libc;\n use os;\n use prelude::*;\n use std::io::net::ip::*;\n-use sync::atomics::{AtomicUint, INIT_ATOMIC_UINT, Relaxed};\n+use sync::atomic::{AtomicUint, INIT_ATOMIC_UINT, Relaxed};\n \n macro_rules! iotest (\n     { fn $name:ident() $b:block $(#[$a:meta])* } => ("}, {"sha": "6ba964441ee2a414c514f5e9143dfbbf31966fff", "filename": "src/libstd/os.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fos.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -48,7 +48,7 @@ use result::{Err, Ok, Result};\n use slice::{Vector, ImmutableVector, MutableVector, ImmutableEqVector};\n use str::{Str, StrSlice, StrAllocating};\n use string::String;\n-use sync::atomics::{AtomicInt, INIT_ATOMIC_INT, SeqCst};\n+use sync::atomic::{AtomicInt, INIT_ATOMIC_INT, SeqCst};\n use vec::Vec;\n \n #[cfg(unix)]"}, {"sha": "b86937e4213014a69bda32dd68eeaaaff93bb5bd", "filename": "src/libstd/rt/backtrace.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Frt%2Fbacktrace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Frt%2Fbacktrace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fbacktrace.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -20,17 +20,17 @@ use option::{Some, None};\n use os;\n use result::{Ok, Err};\n use str::StrSlice;\n-use sync::atomics;\n+use sync::atomic;\n use unicode::char::UnicodeChar;\n \n pub use self::imp::write;\n \n // For now logging is turned off by default, and this function checks to see\n // whether the magical environment variable is present to see if it's turned on.\n pub fn log_enabled() -> bool {\n-    static mut ENABLED: atomics::AtomicInt = atomics::INIT_ATOMIC_INT;\n+    static mut ENABLED: atomic::AtomicInt = atomic::INIT_ATOMIC_INT;\n     unsafe {\n-        match ENABLED.load(atomics::SeqCst) {\n+        match ENABLED.load(atomic::SeqCst) {\n             1 => return false,\n             2 => return true,\n             _ => {}\n@@ -41,7 +41,7 @@ pub fn log_enabled() -> bool {\n         Some(..) => 2,\n         None => 1,\n     };\n-    unsafe { ENABLED.store(val, atomics::SeqCst); }\n+    unsafe { ENABLED.store(val, atomic::SeqCst); }\n     val == 2\n }\n "}, {"sha": "ed24ed2a569c754564316a0255811129b75ddfab", "filename": "src/libstd/rt/util.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Frt%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Frt%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Futil.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -14,7 +14,7 @@ use libc::uintptr_t;\n use option::{Some, None, Option};\n use os;\n use str::Str;\n-use sync::atomics;\n+use sync::atomic;\n \n /// Dynamically inquire about whether we're running under V.\n /// You should usually not use this unless your test definitely\n@@ -41,16 +41,16 @@ pub fn limit_thread_creation_due_to_osx_and_valgrind() -> bool {\n }\n \n pub fn min_stack() -> uint {\n-    static mut MIN: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n-    match unsafe { MIN.load(atomics::SeqCst) } {\n+    static mut MIN: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n+    match unsafe { MIN.load(atomic::SeqCst) } {\n         0 => {}\n         n => return n - 1,\n     }\n     let amt = os::getenv(\"RUST_MIN_STACK\").and_then(|s| from_str(s.as_slice()));\n     let amt = amt.unwrap_or(2 * 1024 * 1024);\n     // 0 is our sentinel value, so ensure that we'll never see 0 after\n     // initialization has run\n-    unsafe { MIN.store(amt + 1, atomics::SeqCst); }\n+    unsafe { MIN.store(amt + 1, atomic::SeqCst); }\n     return amt;\n }\n "}, {"sha": "1d189f8d4bcbd023ab66489df67de95892b37411", "filename": "src/libstd/sync/mod.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fsync%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibstd%2Fsync%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmod.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -17,12 +17,18 @@\n \n #![experimental]\n \n-pub use core_sync::{atomics, deque, mpmc_bounded_queue, mpsc_queue, spsc_queue};\n+#[stable]\n+pub use core_sync::atomic;\n+\n+pub use core_sync::{deque, mpmc_bounded_queue, mpsc_queue, spsc_queue};\n pub use core_sync::{Arc, Weak, Mutex, MutexGuard, Condvar, Barrier};\n pub use core_sync::{RWLock, RWLockReadGuard, RWLockWriteGuard};\n pub use core_sync::{Semaphore, SemaphoreGuard};\n pub use core_sync::one::{Once, ONCE_INIT};\n \n+#[deprecated = \"use atomic instead\"]\n+pub use atomics = core_sync::atomic;\n+\n pub use self::future::Future;\n pub use self::task_pool::TaskPool;\n "}, {"sha": "101d869451c6d6107ab1d7521a102ceb6a6f0ab1", "filename": "src/libsync/atomic.rs", "status": "renamed", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fatomic.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -41,7 +41,7 @@\n //!\n //! ```\n //! use std::sync::Arc;\n-//! use std::sync::atomics::{AtomicUint, SeqCst};\n+//! use std::sync::atomic::{AtomicUint, SeqCst};\n //! use std::task::deschedule;\n //!\n //! fn main() {\n@@ -67,7 +67,7 @@\n //!\n //! ```\n //! use std::sync::Arc;\n-//! use std::sync::atomics::{AtomicOption, SeqCst};\n+//! use std::sync::atomic::{AtomicOption, SeqCst};\n //!\n //! fn main() {\n //!     struct BigObject;\n@@ -91,7 +91,7 @@\n //! Keep a global count of live tasks:\n //!\n //! ```\n-//! use std::sync::atomics::{AtomicUint, SeqCst, INIT_ATOMIC_UINT};\n+//! use std::sync::atomic::{AtomicUint, SeqCst, INIT_ATOMIC_UINT};\n //!\n //! static mut GLOBAL_TASK_COUNT: AtomicUint = INIT_ATOMIC_UINT;\n //!\n@@ -106,16 +106,18 @@ use core::prelude::*;\n use alloc::boxed::Box;\n use core::mem;\n \n-pub use core::atomics::{AtomicBool, AtomicInt, AtomicUint, AtomicPtr};\n-pub use core::atomics::{Ordering, Relaxed, Release, Acquire, AcqRel, SeqCst};\n-pub use core::atomics::{INIT_ATOMIC_BOOL, INIT_ATOMIC_INT, INIT_ATOMIC_UINT};\n-pub use core::atomics::fence;\n+pub use core::atomic::{AtomicBool, AtomicInt, AtomicUint, AtomicPtr};\n+pub use core::atomic::{Ordering, Relaxed, Release, Acquire, AcqRel, SeqCst};\n+pub use core::atomic::{INIT_ATOMIC_BOOL, INIT_ATOMIC_INT, INIT_ATOMIC_UINT};\n+pub use core::atomic::fence;\n \n /// An atomic, nullable unique pointer\n ///\n /// This can be used as the concurrency primitive for operations that transfer\n /// owned heap objects across tasks.\n #[unsafe_no_drop_flag]\n+#[deprecated = \"no longer used; will eventually be replaced by a higher-level\\\n+                concept like MVar\"]\n pub struct AtomicOption<T> {\n     p: AtomicUint,\n }\n@@ -227,4 +229,3 @@ mod test {\n         assert!(p.take(SeqCst) == Some(box 2));\n     }\n }\n-", "previous_filename": "src/libsync/atomics.rs"}, {"sha": "188bea83ac80f9968af8faf30b7cfdd81c44a9ea", "filename": "src/libsync/comm/oneshot.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Foneshot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Foneshot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fcomm%2Foneshot.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -39,7 +39,7 @@ use core::mem;\n use rustrt::local::Local;\n use rustrt::task::{Task, BlockedTask};\n \n-use atomics;\n+use atomic;\n use comm::Receiver;\n \n // Various states you can find a port in.\n@@ -49,7 +49,7 @@ static DISCONNECTED: uint = 2;\n \n pub struct Packet<T> {\n     // Internal state of the chan/port pair (stores the blocked task as well)\n-    state: atomics::AtomicUint,\n+    state: atomic::AtomicUint,\n     // One-shot data slot location\n     data: Option<T>,\n     // when used for the second time, a oneshot channel must be upgraded, and\n@@ -86,7 +86,7 @@ impl<T: Send> Packet<T> {\n         Packet {\n             data: None,\n             upgrade: NothingSent,\n-            state: atomics::AtomicUint::new(EMPTY),\n+            state: atomic::AtomicUint::new(EMPTY),\n         }\n     }\n \n@@ -100,7 +100,7 @@ impl<T: Send> Packet<T> {\n         self.data = Some(t);\n         self.upgrade = SendUsed;\n \n-        match self.state.swap(DATA, atomics::SeqCst) {\n+        match self.state.swap(DATA, atomic::SeqCst) {\n             // Sent the data, no one was waiting\n             EMPTY => Ok(()),\n \n@@ -136,11 +136,11 @@ impl<T: Send> Packet<T> {\n     pub fn recv(&mut self) -> Result<T, Failure<T>> {\n         // Attempt to not block the task (it's a little expensive). If it looks\n         // like we're not empty, then immediately go through to `try_recv`.\n-        if self.state.load(atomics::SeqCst) == EMPTY {\n+        if self.state.load(atomic::SeqCst) == EMPTY {\n             let t: Box<Task> = Local::take();\n             t.deschedule(1, |task| {\n                 let n = unsafe { task.cast_to_uint() };\n-                match self.state.compare_and_swap(EMPTY, n, atomics::SeqCst) {\n+                match self.state.compare_and_swap(EMPTY, n, atomic::SeqCst) {\n                     // Nothing on the channel, we legitimately block\n                     EMPTY => Ok(()),\n \n@@ -160,7 +160,7 @@ impl<T: Send> Packet<T> {\n     }\n \n     pub fn try_recv(&mut self) -> Result<T, Failure<T>> {\n-        match self.state.load(atomics::SeqCst) {\n+        match self.state.load(atomic::SeqCst) {\n             EMPTY => Err(Empty),\n \n             // We saw some data on the channel, but the channel can be used\n@@ -170,7 +170,7 @@ impl<T: Send> Packet<T> {\n             // the state changes under our feet we'd rather just see that state\n             // change.\n             DATA => {\n-                self.state.compare_and_swap(DATA, EMPTY, atomics::SeqCst);\n+                self.state.compare_and_swap(DATA, EMPTY, atomic::SeqCst);\n                 match self.data.take() {\n                     Some(data) => Ok(data),\n                     None => unreachable!(),\n@@ -207,7 +207,7 @@ impl<T: Send> Packet<T> {\n         };\n         self.upgrade = GoUp(up);\n \n-        match self.state.swap(DISCONNECTED, atomics::SeqCst) {\n+        match self.state.swap(DISCONNECTED, atomic::SeqCst) {\n             // If the channel is empty or has data on it, then we're good to go.\n             // Senders will check the data before the upgrade (in case we\n             // plastered over the DATA state).\n@@ -223,7 +223,7 @@ impl<T: Send> Packet<T> {\n     }\n \n     pub fn drop_chan(&mut self) {\n-        match self.state.swap(DISCONNECTED, atomics::SeqCst) {\n+        match self.state.swap(DISCONNECTED, atomic::SeqCst) {\n             DATA | DISCONNECTED | EMPTY => {}\n \n             // If someone's waiting, we gotta wake them up\n@@ -235,7 +235,7 @@ impl<T: Send> Packet<T> {\n     }\n \n     pub fn drop_port(&mut self) {\n-        match self.state.swap(DISCONNECTED, atomics::SeqCst) {\n+        match self.state.swap(DISCONNECTED, atomic::SeqCst) {\n             // An empty channel has nothing to do, and a remotely disconnected\n             // channel also has nothing to do b/c we're about to run the drop\n             // glue\n@@ -258,7 +258,7 @@ impl<T: Send> Packet<T> {\n     // If Ok, the value is whether this port has data, if Err, then the upgraded\n     // port needs to be checked instead of this one.\n     pub fn can_recv(&mut self) -> Result<bool, Receiver<T>> {\n-        match self.state.load(atomics::SeqCst) {\n+        match self.state.load(atomic::SeqCst) {\n             EMPTY => Ok(false), // Welp, we tried\n             DATA => Ok(true),   // we have some un-acquired data\n             DISCONNECTED if self.data.is_some() => Ok(true), // we have data\n@@ -283,7 +283,7 @@ impl<T: Send> Packet<T> {\n     // because there is data, or fail because there is an upgrade pending.\n     pub fn start_selection(&mut self, task: BlockedTask) -> SelectionResult<T> {\n         let n = unsafe { task.cast_to_uint() };\n-        match self.state.compare_and_swap(EMPTY, n, atomics::SeqCst) {\n+        match self.state.compare_and_swap(EMPTY, n, atomic::SeqCst) {\n             EMPTY => SelSuccess,\n             DATA => SelCanceled(unsafe { BlockedTask::cast_from_uint(n) }),\n             DISCONNECTED if self.data.is_some() => {\n@@ -317,7 +317,7 @@ impl<T: Send> Packet<T> {\n     //\n     // The return value indicates whether there's data on this port.\n     pub fn abort_selection(&mut self) -> Result<bool, Receiver<T>> {\n-        let state = match self.state.load(atomics::SeqCst) {\n+        let state = match self.state.load(atomic::SeqCst) {\n             // Each of these states means that no further activity will happen\n             // with regard to abortion selection\n             s @ EMPTY |\n@@ -326,7 +326,7 @@ impl<T: Send> Packet<T> {\n \n             // If we've got a blocked task, then use an atomic to gain ownership\n             // of it (may fail)\n-            n => self.state.compare_and_swap(n, EMPTY, atomics::SeqCst)\n+            n => self.state.compare_and_swap(n, EMPTY, atomic::SeqCst)\n         };\n \n         // Now that we've got ownership of our state, figure out what to do\n@@ -367,6 +367,6 @@ impl<T: Send> Packet<T> {\n #[unsafe_destructor]\n impl<T: Send> Drop for Packet<T> {\n     fn drop(&mut self) {\n-        assert_eq!(self.state.load(atomics::SeqCst), DISCONNECTED);\n+        assert_eq!(self.state.load(atomic::SeqCst), DISCONNECTED);\n     }\n }"}, {"sha": "979b0ebcf8f83decd12931f7de25a81d8e88e8de", "filename": "src/libsync/comm/shared.rs", "status": "modified", "additions": 45, "deletions": 45, "changes": 90, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Fshared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Fshared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fcomm%2Fshared.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -28,7 +28,7 @@ use rustrt::mutex::NativeMutex;\n use rustrt::task::{Task, BlockedTask};\n use rustrt::thread::Thread;\n \n-use atomics;\n+use atomic;\n use mpsc = mpsc_queue;\n \n static DISCONNECTED: int = int::MIN;\n@@ -40,17 +40,17 @@ static MAX_STEALS: int = 1 << 20;\n \n pub struct Packet<T> {\n     queue: mpsc::Queue<T>,\n-    cnt: atomics::AtomicInt, // How many items are on this channel\n+    cnt: atomic::AtomicInt, // How many items are on this channel\n     steals: int, // How many times has a port received without blocking?\n-    to_wake: atomics::AtomicUint, // Task to wake up\n+    to_wake: atomic::AtomicUint, // Task to wake up\n \n     // The number of channels which are currently using this packet.\n-    channels: atomics::AtomicInt,\n+    channels: atomic::AtomicInt,\n \n     // See the discussion in Port::drop and the channel send methods for what\n     // these are used for\n-    port_dropped: atomics::AtomicBool,\n-    sender_drain: atomics::AtomicInt,\n+    port_dropped: atomic::AtomicBool,\n+    sender_drain: atomic::AtomicInt,\n \n     // this lock protects various portions of this implementation during\n     // select()\n@@ -68,12 +68,12 @@ impl<T: Send> Packet<T> {\n     pub fn new() -> Packet<T> {\n         let p = Packet {\n             queue: mpsc::Queue::new(),\n-            cnt: atomics::AtomicInt::new(0),\n+            cnt: atomic::AtomicInt::new(0),\n             steals: 0,\n-            to_wake: atomics::AtomicUint::new(0),\n-            channels: atomics::AtomicInt::new(2),\n-            port_dropped: atomics::AtomicBool::new(false),\n-            sender_drain: atomics::AtomicInt::new(0),\n+            to_wake: atomic::AtomicUint::new(0),\n+            channels: atomic::AtomicInt::new(2),\n+            port_dropped: atomic::AtomicBool::new(false),\n+            sender_drain: atomic::AtomicInt::new(0),\n             select_lock: unsafe { NativeMutex::new() },\n         };\n         return p;\n@@ -96,11 +96,11 @@ impl<T: Send> Packet<T> {\n     pub fn inherit_blocker(&mut self, task: Option<BlockedTask>) {\n         match task {\n             Some(task) => {\n-                assert_eq!(self.cnt.load(atomics::SeqCst), 0);\n-                assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+                assert_eq!(self.cnt.load(atomic::SeqCst), 0);\n+                assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n                 self.to_wake.store(unsafe { task.cast_to_uint() },\n-                                   atomics::SeqCst);\n-                self.cnt.store(-1, atomics::SeqCst);\n+                                   atomic::SeqCst);\n+                self.cnt.store(-1, atomic::SeqCst);\n \n                 // This store is a little sketchy. What's happening here is\n                 // that we're transferring a blocker from a oneshot or stream\n@@ -138,7 +138,7 @@ impl<T: Send> Packet<T> {\n \n     pub fn send(&mut self, t: T) -> Result<(), T> {\n         // See Port::drop for what's going on\n-        if self.port_dropped.load(atomics::SeqCst) { return Err(t) }\n+        if self.port_dropped.load(atomic::SeqCst) { return Err(t) }\n \n         // Note that the multiple sender case is a little trickier\n         // semantically than the single sender case. The logic for\n@@ -165,12 +165,12 @@ impl<T: Send> Packet<T> {\n         // preflight check serves as the definitive \"this will never be\n         // received\". Once we get beyond this check, we have permanently\n         // entered the realm of \"this may be received\"\n-        if self.cnt.load(atomics::SeqCst) < DISCONNECTED + FUDGE {\n+        if self.cnt.load(atomic::SeqCst) < DISCONNECTED + FUDGE {\n             return Err(t)\n         }\n \n         self.queue.push(t);\n-        match self.cnt.fetch_add(1, atomics::SeqCst) {\n+        match self.cnt.fetch_add(1, atomic::SeqCst) {\n             -1 => {\n                 self.take_to_wake().wake().map(|t| t.reawaken());\n             }\n@@ -187,9 +187,9 @@ impl<T: Send> Packet<T> {\n             n if n < DISCONNECTED + FUDGE => {\n                 // see the comment in 'try' for a shared channel for why this\n                 // window of \"not disconnected\" is ok.\n-                self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                self.cnt.store(DISCONNECTED, atomic::SeqCst);\n \n-                if self.sender_drain.fetch_add(1, atomics::SeqCst) == 0 {\n+                if self.sender_drain.fetch_add(1, atomic::SeqCst) == 0 {\n                     loop {\n                         // drain the queue, for info on the thread yield see the\n                         // discussion in try_recv\n@@ -202,7 +202,7 @@ impl<T: Send> Packet<T> {\n                         }\n                         // maybe we're done, if we're not the last ones\n                         // here, then we need to go try again.\n-                        if self.sender_drain.fetch_sub(1, atomics::SeqCst) == 1 {\n+                        if self.sender_drain.fetch_sub(1, atomic::SeqCst) == 1 {\n                             break\n                         }\n                     }\n@@ -242,15 +242,15 @@ impl<T: Send> Packet<T> {\n \n     // Essentially the exact same thing as the stream decrement function.\n     fn decrement(&mut self, task: BlockedTask) -> Result<(), BlockedTask> {\n-        assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+        assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n         let n = unsafe { task.cast_to_uint() };\n-        self.to_wake.store(n, atomics::SeqCst);\n+        self.to_wake.store(n, atomic::SeqCst);\n \n         let steals = self.steals;\n         self.steals = 0;\n \n-        match self.cnt.fetch_sub(1 + steals, atomics::SeqCst) {\n-            DISCONNECTED => { self.cnt.store(DISCONNECTED, atomics::SeqCst); }\n+        match self.cnt.fetch_sub(1 + steals, atomic::SeqCst) {\n+            DISCONNECTED => { self.cnt.store(DISCONNECTED, atomic::SeqCst); }\n             // If we factor in our steals and notice that the channel has no\n             // data, we successfully sleep\n             n => {\n@@ -259,7 +259,7 @@ impl<T: Send> Packet<T> {\n             }\n         }\n \n-        self.to_wake.store(0, atomics::SeqCst);\n+        self.to_wake.store(0, atomic::SeqCst);\n         Err(unsafe { BlockedTask::cast_from_uint(n) })\n     }\n \n@@ -311,9 +311,9 @@ impl<T: Send> Packet<T> {\n             // might decrement steals.\n             Some(data) => {\n                 if self.steals > MAX_STEALS {\n-                    match self.cnt.swap(0, atomics::SeqCst) {\n+                    match self.cnt.swap(0, atomic::SeqCst) {\n                         DISCONNECTED => {\n-                            self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                            self.cnt.store(DISCONNECTED, atomic::SeqCst);\n                         }\n                         n => {\n                             let m = cmp::min(n, self.steals);\n@@ -330,7 +330,7 @@ impl<T: Send> Packet<T> {\n             // See the discussion in the stream implementation for why we try\n             // again.\n             None => {\n-                match self.cnt.load(atomics::SeqCst) {\n+                match self.cnt.load(atomic::SeqCst) {\n                     n if n != DISCONNECTED => Err(Empty),\n                     _ => {\n                         match self.queue.pop() {\n@@ -348,20 +348,20 @@ impl<T: Send> Packet<T> {\n     // Prepares this shared packet for a channel clone, essentially just bumping\n     // a refcount.\n     pub fn clone_chan(&mut self) {\n-        self.channels.fetch_add(1, atomics::SeqCst);\n+        self.channels.fetch_add(1, atomic::SeqCst);\n     }\n \n     // Decrement the reference count on a channel. This is called whenever a\n     // Chan is dropped and may end up waking up a receiver. It's the receiver's\n     // responsibility on the other end to figure out that we've disconnected.\n     pub fn drop_chan(&mut self) {\n-        match self.channels.fetch_sub(1, atomics::SeqCst) {\n+        match self.channels.fetch_sub(1, atomic::SeqCst) {\n             1 => {}\n             n if n > 1 => return,\n             n => fail!(\"bad number of channels left {}\", n),\n         }\n \n-        match self.cnt.swap(DISCONNECTED, atomics::SeqCst) {\n+        match self.cnt.swap(DISCONNECTED, atomic::SeqCst) {\n             -1 => { self.take_to_wake().wake().map(|t| t.reawaken()); }\n             DISCONNECTED => {}\n             n => { assert!(n >= 0); }\n@@ -371,11 +371,11 @@ impl<T: Send> Packet<T> {\n     // See the long discussion inside of stream.rs for why the queue is drained,\n     // and why it is done in this fashion.\n     pub fn drop_port(&mut self) {\n-        self.port_dropped.store(true, atomics::SeqCst);\n+        self.port_dropped.store(true, atomic::SeqCst);\n         let mut steals = self.steals;\n         while {\n             let cnt = self.cnt.compare_and_swap(\n-                            steals, DISCONNECTED, atomics::SeqCst);\n+                            steals, DISCONNECTED, atomic::SeqCst);\n             cnt != DISCONNECTED && cnt != steals\n         } {\n             // See the discussion in 'try_recv' for why we yield\n@@ -391,8 +391,8 @@ impl<T: Send> Packet<T> {\n \n     // Consumes ownership of the 'to_wake' field.\n     fn take_to_wake(&mut self) -> BlockedTask {\n-        let task = self.to_wake.load(atomics::SeqCst);\n-        self.to_wake.store(0, atomics::SeqCst);\n+        let task = self.to_wake.load(atomic::SeqCst);\n+        self.to_wake.store(0, atomic::SeqCst);\n         assert!(task != 0);\n         unsafe { BlockedTask::cast_from_uint(task) }\n     }\n@@ -407,15 +407,15 @@ impl<T: Send> Packet<T> {\n     // This is different than the stream version because there's no need to peek\n     // at the queue, we can just look at the local count.\n     pub fn can_recv(&mut self) -> bool {\n-        let cnt = self.cnt.load(atomics::SeqCst);\n+        let cnt = self.cnt.load(atomic::SeqCst);\n         cnt == DISCONNECTED || cnt - self.steals > 0\n     }\n \n     // increment the count on the channel (used for selection)\n     fn bump(&mut self, amt: int) -> int {\n-        match self.cnt.fetch_add(amt, atomics::SeqCst) {\n+        match self.cnt.fetch_add(amt, atomic::SeqCst) {\n             DISCONNECTED => {\n-                self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                self.cnt.store(DISCONNECTED, atomic::SeqCst);\n                 DISCONNECTED\n             }\n             n => n\n@@ -460,21 +460,21 @@ impl<T: Send> Packet<T> {\n         // the channel count and figure out what we should do to make it\n         // positive.\n         let steals = {\n-            let cnt = self.cnt.load(atomics::SeqCst);\n+            let cnt = self.cnt.load(atomic::SeqCst);\n             if cnt < 0 && cnt != DISCONNECTED {-cnt} else {0}\n         };\n         let prev = self.bump(steals + 1);\n \n         if prev == DISCONNECTED {\n-            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n             true\n         } else {\n             let cur = prev + steals + 1;\n             assert!(cur >= 0);\n             if prev < 0 {\n                 self.take_to_wake().trash();\n             } else {\n-                while self.to_wake.load(atomics::SeqCst) != 0 {\n+                while self.to_wake.load(atomic::SeqCst) != 0 {\n                     Thread::yield_now();\n                 }\n             }\n@@ -495,8 +495,8 @@ impl<T: Send> Drop for Packet<T> {\n         // disconnection, but also a proper fence before the read of\n         // `to_wake`, so this assert cannot be removed with also removing\n         // the `to_wake` assert.\n-        assert_eq!(self.cnt.load(atomics::SeqCst), DISCONNECTED);\n-        assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n-        assert_eq!(self.channels.load(atomics::SeqCst), 0);\n+        assert_eq!(self.cnt.load(atomic::SeqCst), DISCONNECTED);\n+        assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n+        assert_eq!(self.channels.load(atomic::SeqCst), 0);\n     }\n }"}, {"sha": "11c563301e08295584db629428b36212db8d0cf9", "filename": "src/libsync/comm/stream.rs", "status": "modified", "additions": 31, "deletions": 31, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Fstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Fstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fcomm%2Fstream.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -26,7 +26,7 @@ use rustrt::local::Local;\n use rustrt::task::{Task, BlockedTask};\n use rustrt::thread::Thread;\n \n-use atomics;\n+use atomic;\n use comm::Receiver;\n use spsc = spsc_queue;\n \n@@ -39,11 +39,11 @@ static MAX_STEALS: int = 1 << 20;\n pub struct Packet<T> {\n     queue: spsc::Queue<Message<T>>, // internal queue for all message\n \n-    cnt: atomics::AtomicInt, // How many items are on this channel\n+    cnt: atomic::AtomicInt, // How many items are on this channel\n     steals: int, // How many times has a port received without blocking?\n-    to_wake: atomics::AtomicUint, // Task to wake up\n+    to_wake: atomic::AtomicUint, // Task to wake up\n \n-    port_dropped: atomics::AtomicBool, // flag if the channel has been destroyed.\n+    port_dropped: atomic::AtomicBool, // flag if the channel has been destroyed.\n }\n \n pub enum Failure<T> {\n@@ -76,11 +76,11 @@ impl<T: Send> Packet<T> {\n         Packet {\n             queue: unsafe { spsc::Queue::new(128) },\n \n-            cnt: atomics::AtomicInt::new(0),\n+            cnt: atomic::AtomicInt::new(0),\n             steals: 0,\n-            to_wake: atomics::AtomicUint::new(0),\n+            to_wake: atomic::AtomicUint::new(0),\n \n-            port_dropped: atomics::AtomicBool::new(false),\n+            port_dropped: atomic::AtomicBool::new(false),\n         }\n     }\n \n@@ -89,7 +89,7 @@ impl<T: Send> Packet<T> {\n         // If the other port has deterministically gone away, then definitely\n         // must return the data back up the stack. Otherwise, the data is\n         // considered as being sent.\n-        if self.port_dropped.load(atomics::SeqCst) { return Err(t) }\n+        if self.port_dropped.load(atomic::SeqCst) { return Err(t) }\n \n         match self.do_send(Data(t)) {\n             UpSuccess | UpDisconnected => {},\n@@ -100,14 +100,14 @@ impl<T: Send> Packet<T> {\n     pub fn upgrade(&mut self, up: Receiver<T>) -> UpgradeResult {\n         // If the port has gone away, then there's no need to proceed any\n         // further.\n-        if self.port_dropped.load(atomics::SeqCst) { return UpDisconnected }\n+        if self.port_dropped.load(atomic::SeqCst) { return UpDisconnected }\n \n         self.do_send(GoUp(up))\n     }\n \n     fn do_send(&mut self, t: Message<T>) -> UpgradeResult {\n         self.queue.push(t);\n-        match self.cnt.fetch_add(1, atomics::SeqCst) {\n+        match self.cnt.fetch_add(1, atomic::SeqCst) {\n             // As described in the mod's doc comment, -1 == wakeup\n             -1 => UpWoke(self.take_to_wake()),\n             // As as described before, SPSC queues must be >= -2\n@@ -121,7 +121,7 @@ impl<T: Send> Packet<T> {\n             // will never remove this data. We can only have at most one item to\n             // drain (the port drains the rest).\n             DISCONNECTED => {\n-                self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                self.cnt.store(DISCONNECTED, atomic::SeqCst);\n                 let first = self.queue.pop();\n                 let second = self.queue.pop();\n                 assert!(second.is_none());\n@@ -140,8 +140,8 @@ impl<T: Send> Packet<T> {\n \n     // Consumes ownership of the 'to_wake' field.\n     fn take_to_wake(&mut self) -> BlockedTask {\n-        let task = self.to_wake.load(atomics::SeqCst);\n-        self.to_wake.store(0, atomics::SeqCst);\n+        let task = self.to_wake.load(atomic::SeqCst);\n+        self.to_wake.store(0, atomic::SeqCst);\n         assert!(task != 0);\n         unsafe { BlockedTask::cast_from_uint(task) }\n     }\n@@ -150,15 +150,15 @@ impl<T: Send> Packet<T> {\n     // back if it shouldn't sleep. Note that this is the location where we take\n     // steals into account.\n     fn decrement(&mut self, task: BlockedTask) -> Result<(), BlockedTask> {\n-        assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+        assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n         let n = unsafe { task.cast_to_uint() };\n-        self.to_wake.store(n, atomics::SeqCst);\n+        self.to_wake.store(n, atomic::SeqCst);\n \n         let steals = self.steals;\n         self.steals = 0;\n \n-        match self.cnt.fetch_sub(1 + steals, atomics::SeqCst) {\n-            DISCONNECTED => { self.cnt.store(DISCONNECTED, atomics::SeqCst); }\n+        match self.cnt.fetch_sub(1 + steals, atomic::SeqCst) {\n+            DISCONNECTED => { self.cnt.store(DISCONNECTED, atomic::SeqCst); }\n             // If we factor in our steals and notice that the channel has no\n             // data, we successfully sleep\n             n => {\n@@ -167,7 +167,7 @@ impl<T: Send> Packet<T> {\n             }\n         }\n \n-        self.to_wake.store(0, atomics::SeqCst);\n+        self.to_wake.store(0, atomic::SeqCst);\n         Err(unsafe { BlockedTask::cast_from_uint(n) })\n     }\n \n@@ -214,9 +214,9 @@ impl<T: Send> Packet<T> {\n             // adding back in whatever we couldn't factor into steals.\n             Some(data) => {\n                 if self.steals > MAX_STEALS {\n-                    match self.cnt.swap(0, atomics::SeqCst) {\n+                    match self.cnt.swap(0, atomic::SeqCst) {\n                         DISCONNECTED => {\n-                            self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                            self.cnt.store(DISCONNECTED, atomic::SeqCst);\n                         }\n                         n => {\n                             let m = cmp::min(n, self.steals);\n@@ -234,7 +234,7 @@ impl<T: Send> Packet<T> {\n             }\n \n             None => {\n-                match self.cnt.load(atomics::SeqCst) {\n+                match self.cnt.load(atomic::SeqCst) {\n                     n if n != DISCONNECTED => Err(Empty),\n \n                     // This is a little bit of a tricky case. We failed to pop\n@@ -263,7 +263,7 @@ impl<T: Send> Packet<T> {\n     pub fn drop_chan(&mut self) {\n         // Dropping a channel is pretty simple, we just flag it as disconnected\n         // and then wakeup a blocker if there is one.\n-        match self.cnt.swap(DISCONNECTED, atomics::SeqCst) {\n+        match self.cnt.swap(DISCONNECTED, atomic::SeqCst) {\n             -1 => { self.take_to_wake().wake().map(|t| t.reawaken()); }\n             DISCONNECTED => {}\n             n => { assert!(n >= 0); }\n@@ -290,7 +290,7 @@ impl<T: Send> Packet<T> {\n         // sends are gated on this flag, so we're immediately guaranteed that\n         // there are a bounded number of active sends that we'll have to deal\n         // with.\n-        self.port_dropped.store(true, atomics::SeqCst);\n+        self.port_dropped.store(true, atomic::SeqCst);\n \n         // Now that we're guaranteed to deal with a bounded number of senders,\n         // we need to drain the queue. This draining process happens atomically\n@@ -303,7 +303,7 @@ impl<T: Send> Packet<T> {\n         let mut steals = self.steals;\n         while {\n             let cnt = self.cnt.compare_and_swap(\n-                            steals, DISCONNECTED, atomics::SeqCst);\n+                            steals, DISCONNECTED, atomic::SeqCst);\n             cnt != DISCONNECTED && cnt != steals\n         } {\n             loop {\n@@ -348,9 +348,9 @@ impl<T: Send> Packet<T> {\n \n     // increment the count on the channel (used for selection)\n     fn bump(&mut self, amt: int) -> int {\n-        match self.cnt.fetch_add(amt, atomics::SeqCst) {\n+        match self.cnt.fetch_add(amt, atomic::SeqCst) {\n             DISCONNECTED => {\n-                self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                self.cnt.store(DISCONNECTED, atomic::SeqCst);\n                 DISCONNECTED\n             }\n             n => n\n@@ -400,7 +400,7 @@ impl<T: Send> Packet<T> {\n         // of time until the data is actually sent.\n         if was_upgrade {\n             assert_eq!(self.steals, 0);\n-            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n             return Ok(true)\n         }\n \n@@ -413,7 +413,7 @@ impl<T: Send> Packet<T> {\n         // If we were previously disconnected, then we know for sure that there\n         // is no task in to_wake, so just keep going\n         let has_data = if prev == DISCONNECTED {\n-            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n             true // there is data, that data is that we're disconnected\n         } else {\n             let cur = prev + steals + 1;\n@@ -436,7 +436,7 @@ impl<T: Send> Packet<T> {\n             if prev < 0 {\n                 self.take_to_wake().trash();\n             } else {\n-                while self.to_wake.load(atomics::SeqCst) != 0 {\n+                while self.to_wake.load(atomic::SeqCst) != 0 {\n                     Thread::yield_now();\n                 }\n             }\n@@ -475,7 +475,7 @@ impl<T: Send> Drop for Packet<T> {\n         // disconnection, but also a proper fence before the read of\n         // `to_wake`, so this assert cannot be removed with also removing\n         // the `to_wake` assert.\n-        assert_eq!(self.cnt.load(atomics::SeqCst), DISCONNECTED);\n-        assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+        assert_eq!(self.cnt.load(atomic::SeqCst), DISCONNECTED);\n+        assert_eq!(self.to_wake.load(atomic::SeqCst), 0);\n     }\n }"}, {"sha": "aef02f654c102132173ca6afb7e96a14530f631e", "filename": "src/libsync/comm/sync.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fcomm%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fcomm%2Fsync.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -44,12 +44,12 @@ use rustrt::local::Local;\n use rustrt::mutex::{NativeMutex, LockGuard};\n use rustrt::task::{Task, BlockedTask};\n \n-use atomics;\n+use atomic;\n \n pub struct Packet<T> {\n     /// Only field outside of the mutex. Just done for kicks, but mainly because\n     /// the other shared channel already had the code implemented\n-    channels: atomics::AtomicUint,\n+    channels: atomic::AtomicUint,\n \n     /// The state field is protected by this mutex\n     lock: NativeMutex,\n@@ -131,7 +131,7 @@ fn wakeup(task: BlockedTask, guard: LockGuard) {\n impl<T: Send> Packet<T> {\n     pub fn new(cap: uint) -> Packet<T> {\n         Packet {\n-            channels: atomics::AtomicUint::new(1),\n+            channels: atomic::AtomicUint::new(1),\n             lock: unsafe { NativeMutex::new() },\n             state: UnsafeCell::new(State {\n                 disconnected: false,\n@@ -303,12 +303,12 @@ impl<T: Send> Packet<T> {\n     // Prepares this shared packet for a channel clone, essentially just bumping\n     // a refcount.\n     pub fn clone_chan(&self) {\n-        self.channels.fetch_add(1, atomics::SeqCst);\n+        self.channels.fetch_add(1, atomic::SeqCst);\n     }\n \n     pub fn drop_chan(&self) {\n         // Only flag the channel as disconnected if we're the last channel\n-        match self.channels.fetch_sub(1, atomics::SeqCst) {\n+        match self.channels.fetch_sub(1, atomic::SeqCst) {\n             1 => {}\n             _ => return\n         }\n@@ -411,7 +411,7 @@ impl<T: Send> Packet<T> {\n #[unsafe_destructor]\n impl<T: Send> Drop for Packet<T> {\n     fn drop(&mut self) {\n-        assert_eq!(self.channels.load(atomics::SeqCst), 0);\n+        assert_eq!(self.channels.load(atomic::SeqCst), 0);\n         let (_g, state) = self.lock();\n         assert!(state.queue.dequeue().is_none());\n         assert!(state.canceled.is_none());"}, {"sha": "d5a05e7a68175a5e6a10668103d5dcaf89b7af11", "filename": "src/libsync/deque.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fdeque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fdeque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fdeque.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -61,7 +61,7 @@ use core::mem::{forget, min_align_of, size_of, transmute};\n use core::ptr;\n use rustrt::exclusive::Exclusive;\n \n-use atomics::{AtomicInt, AtomicPtr, SeqCst};\n+use atomic::{AtomicInt, AtomicPtr, SeqCst};\n \n // Once the queue is less than 1/K full, then it will be downsized. Note that\n // the deque requires that this number be less than 2.\n@@ -414,7 +414,7 @@ mod tests {\n     use std::rt::thread::Thread;\n     use std::rand;\n     use std::rand::Rng;\n-    use atomics::{AtomicBool, INIT_ATOMIC_BOOL, SeqCst,\n+    use atomic::{AtomicBool, INIT_ATOMIC_BOOL, SeqCst,\n                   AtomicUint, INIT_ATOMIC_UINT};\n     use std::vec;\n "}, {"sha": "de98f79093e4920ee49291930ea74d04a1a1ee38", "filename": "src/libsync/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Flib.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -49,7 +49,7 @@ pub use raw::{Semaphore, SemaphoreGuard};\n \n // Core building blocks for all primitives in this crate\n \n-pub mod atomics;\n+pub mod atomic;\n \n // Concurrent data structures\n "}, {"sha": "949ef3bc34c253bd944dab456eb63f44c1660b39", "filename": "src/libsync/mpmc_bounded_queue.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmpmc_bounded_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmpmc_bounded_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fmpmc_bounded_queue.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -37,7 +37,7 @@ use collections::Vec;\n use core::num::next_power_of_two;\n use core::cell::UnsafeCell;\n \n-use atomics::{AtomicUint,Relaxed,Release,Acquire};\n+use atomic::{AtomicUint,Relaxed,Release,Acquire};\n \n struct Node<T> {\n     sequence: AtomicUint,"}, {"sha": "1f7841de7c128995975ee49a46e230b76d117cae", "filename": "src/libsync/mpsc_intrusive.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmpsc_intrusive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmpsc_intrusive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fmpsc_intrusive.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -37,51 +37,51 @@\n \n use core::prelude::*;\n \n-use core::atomics;\n+use core::atomic;\n use core::mem;\n use core::cell::UnsafeCell;\n \n // NB: all links are done as AtomicUint instead of AtomicPtr to allow for static\n // initialization.\n \n pub struct Node<T> {\n-    pub next: atomics::AtomicUint,\n+    pub next: atomic::AtomicUint,\n     pub data: T,\n }\n \n pub struct DummyNode {\n-    pub next: atomics::AtomicUint,\n+    pub next: atomic::AtomicUint,\n }\n \n pub struct Queue<T> {\n-    pub head: atomics::AtomicUint,\n+    pub head: atomic::AtomicUint,\n     pub tail: UnsafeCell<*mut Node<T>>,\n     pub stub: DummyNode,\n }\n \n impl<T: Send> Queue<T> {\n     pub fn new() -> Queue<T> {\n         Queue {\n-            head: atomics::AtomicUint::new(0),\n+            head: atomic::AtomicUint::new(0),\n             tail: UnsafeCell::new(0 as *mut Node<T>),\n             stub: DummyNode {\n-                next: atomics::AtomicUint::new(0),\n+                next: atomic::AtomicUint::new(0),\n             },\n         }\n     }\n \n     pub unsafe fn push(&self, node: *mut Node<T>) {\n-        (*node).next.store(0, atomics::Release);\n-        let prev = self.head.swap(node as uint, atomics::AcqRel);\n+        (*node).next.store(0, atomic::Release);\n+        let prev = self.head.swap(node as uint, atomic::AcqRel);\n \n         // Note that this code is slightly modified to allow static\n         // initialization of these queues with rust's flavor of static\n         // initialization.\n         if prev == 0 {\n-            self.stub.next.store(node as uint, atomics::Release);\n+            self.stub.next.store(node as uint, atomic::Release);\n         } else {\n             let prev = prev as *mut Node<T>;\n-            (*prev).next.store(node as uint, atomics::Release);\n+            (*prev).next.store(node as uint, atomic::Release);\n         }\n     }\n \n@@ -103,26 +103,26 @@ impl<T: Send> Queue<T> {\n         let mut tail = if !tail.is_null() {tail} else {\n             mem::transmute(&self.stub)\n         };\n-        let mut next = (*tail).next(atomics::Relaxed);\n+        let mut next = (*tail).next(atomic::Relaxed);\n         if tail as uint == &self.stub as *const DummyNode as uint {\n             if next.is_null() {\n                 return None;\n             }\n             *self.tail.get() = next;\n             tail = next;\n-            next = (*next).next(atomics::Relaxed);\n+            next = (*next).next(atomic::Relaxed);\n         }\n         if !next.is_null() {\n             *self.tail.get() = next;\n             return Some(tail);\n         }\n-        let head = self.head.load(atomics::Acquire) as *mut Node<T>;\n+        let head = self.head.load(atomic::Acquire) as *mut Node<T>;\n         if tail != head {\n             return None;\n         }\n         let stub = mem::transmute(&self.stub);\n         self.push(stub);\n-        next = (*tail).next(atomics::Relaxed);\n+        next = (*tail).next(atomic::Relaxed);\n         if !next.is_null() {\n             *self.tail.get() = next;\n             return Some(tail);\n@@ -135,10 +135,10 @@ impl<T: Send> Node<T> {\n     pub fn new(t: T) -> Node<T> {\n         Node {\n             data: t,\n-            next: atomics::AtomicUint::new(0),\n+            next: atomic::AtomicUint::new(0),\n         }\n     }\n-    pub unsafe fn next(&self, ord: atomics::Ordering) -> *mut Node<T> {\n+    pub unsafe fn next(&self, ord: atomic::Ordering) -> *mut Node<T> {\n         mem::transmute::<uint, *mut Node<T>>(self.next.load(ord))\n     }\n }"}, {"sha": "012574808f3c673e97531c5e670cf323f49c796f", "filename": "src/libsync/mpsc_queue.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmpsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmpsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fmpsc_queue.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -46,7 +46,7 @@ use alloc::boxed::Box;\n use core::mem;\n use core::cell::UnsafeCell;\n \n-use atomics::{AtomicPtr, Release, Acquire, AcqRel, Relaxed};\n+use atomic::{AtomicPtr, Release, Acquire, AcqRel, Relaxed};\n \n /// A result of the `pop` function.\n pub enum PopResult<T> {"}, {"sha": "61d895dd40664d9276c4907bb5014c5616b5a0cf", "filename": "src/libsync/mutex.rs", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fmutex.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -60,7 +60,7 @@\n use core::prelude::*;\n \n use alloc::boxed::Box;\n-use core::atomics;\n+use core::atomic;\n use core::mem;\n use core::cell::UnsafeCell;\n use rustrt::local::Local;\n@@ -137,7 +137,7 @@ enum Flavor {\n /// ```\n pub struct StaticMutex {\n     /// Current set of flags on this mutex\n-    state: atomics::AtomicUint,\n+    state: atomic::AtomicUint,\n     /// an OS mutex used by native threads\n     lock: mutex::StaticNativeMutex,\n \n@@ -151,7 +151,7 @@ pub struct StaticMutex {\n     /// A concurrent mpsc queue used by green threads, along with a count used\n     /// to figure out when to dequeue and enqueue.\n     q: q::Queue<uint>,\n-    green_cnt: atomics::AtomicUint,\n+    green_cnt: atomic::AtomicUint,\n }\n \n /// An RAII implementation of a \"scoped lock\" of a mutex. When this structure is\n@@ -165,16 +165,16 @@ pub struct Guard<'a> {\n /// other mutex constants.\n pub static MUTEX_INIT: StaticMutex = StaticMutex {\n     lock: mutex::NATIVE_MUTEX_INIT,\n-    state: atomics::INIT_ATOMIC_UINT,\n+    state: atomic::INIT_ATOMIC_UINT,\n     flavor: UnsafeCell { value: Unlocked },\n     green_blocker: UnsafeCell { value: 0 },\n     native_blocker: UnsafeCell { value: 0 },\n-    green_cnt: atomics::INIT_ATOMIC_UINT,\n+    green_cnt: atomic::INIT_ATOMIC_UINT,\n     q: q::Queue {\n-        head: atomics::INIT_ATOMIC_UINT,\n+        head: atomic::INIT_ATOMIC_UINT,\n         tail: UnsafeCell { value: 0 as *mut q::Node<uint> },\n         stub: q::DummyNode {\n-            next: atomics::INIT_ATOMIC_UINT,\n+            next: atomic::INIT_ATOMIC_UINT,\n         }\n     }\n };\n@@ -185,7 +185,7 @@ impl StaticMutex {\n         // Attempt to steal the mutex from an unlocked state.\n         //\n         // FIXME: this can mess up the fairness of the mutex, seems bad\n-        match self.state.compare_and_swap(0, LOCKED, atomics::SeqCst) {\n+        match self.state.compare_and_swap(0, LOCKED, atomic::SeqCst) {\n             0 => {\n                 // After acquiring the mutex, we can safely access the inner\n                 // fields.\n@@ -230,7 +230,7 @@ impl StaticMutex {\n         // allow threads coming out of the native_lock function to try their\n         // best to not hit a cvar in deschedule.\n         let mut old = match self.state.compare_and_swap(0, LOCKED,\n-                                                        atomics::SeqCst) {\n+                                                        atomic::SeqCst) {\n             0 => {\n                 let flavor = if can_block {\n                     NativeAcquisition\n@@ -272,15 +272,15 @@ impl StaticMutex {\n                 if old & LOCKED != 0 {\n                     old = match self.state.compare_and_swap(old,\n                                                             old | native_bit,\n-                                                            atomics::SeqCst) {\n+                                                            atomic::SeqCst) {\n                         n if n == old => return Ok(()),\n                         n => n\n                     };\n                 } else {\n                     assert_eq!(old, 0);\n                     old = match self.state.compare_and_swap(old,\n                                                             old | LOCKED,\n-                                                            atomics::SeqCst) {\n+                                                            atomic::SeqCst) {\n                         n if n == old => {\n                             // After acquiring the lock, we have access to the\n                             // flavor field, and we've regained access to our\n@@ -330,7 +330,7 @@ impl StaticMutex {\n         //\n         // FIXME: There isn't a cancellation currently of an enqueue, forcing\n         //        the unlocker to spin for a bit.\n-        if self.green_cnt.fetch_add(1, atomics::SeqCst) == 0 {\n+        if self.green_cnt.fetch_add(1, atomic::SeqCst) == 0 {\n             Local::put(t);\n             return\n         }\n@@ -348,7 +348,7 @@ impl StaticMutex {\n     fn green_unlock(&self) {\n         // If we're the only green thread, then no need to check the queue,\n         // otherwise the fixme above forces us to spin for a bit.\n-        if self.green_cnt.fetch_sub(1, atomics::SeqCst) == 1 { return }\n+        if self.green_cnt.fetch_sub(1, atomic::SeqCst) == 1 { return }\n         let node;\n         loop {\n             match unsafe { self.q.pop() } {\n@@ -380,7 +380,7 @@ impl StaticMutex {\n         // of the outer mutex.\n         let flavor = unsafe { mem::replace(&mut *self.flavor.get(), Unlocked) };\n \n-        let mut state = self.state.load(atomics::SeqCst);\n+        let mut state = self.state.load(atomic::SeqCst);\n         let mut unlocked = false;\n         let task;\n         loop {\n@@ -412,7 +412,7 @@ impl StaticMutex {\n                     }\n                     unlocked = true;\n                 }\n-                match self.state.compare_and_swap(LOCKED, 0, atomics::SeqCst) {\n+                match self.state.compare_and_swap(LOCKED, 0, atomic::SeqCst) {\n                     LOCKED => return,\n                     n => { state = n; }\n                 }\n@@ -435,7 +435,7 @@ impl StaticMutex {\n         loop {\n             assert!(state & bit != 0);\n             let new = state ^ bit;\n-            match self.state.compare_and_swap(state, new, atomics::SeqCst) {\n+            match self.state.compare_and_swap(state, new, atomic::SeqCst) {\n                 n if n == state => break,\n                 n => { state = n; }\n             }\n@@ -462,11 +462,11 @@ impl Mutex {\n     pub fn new() -> Mutex {\n         Mutex {\n             lock: box StaticMutex {\n-                state: atomics::AtomicUint::new(0),\n+                state: atomic::AtomicUint::new(0),\n                 flavor: UnsafeCell::new(Unlocked),\n                 green_blocker: UnsafeCell::new(0),\n                 native_blocker: UnsafeCell::new(0),\n-                green_cnt: atomics::AtomicUint::new(0),\n+                green_cnt: atomic::AtomicUint::new(0),\n                 q: q::Queue::new(),\n                 lock: unsafe { mutex::StaticNativeMutex::new() },\n             }\n@@ -498,7 +498,7 @@ impl<'a> Guard<'a> {\n         if cfg!(debug) {\n             // once we've acquired a lock, it's ok to access the flavor\n             assert!(unsafe { *lock.flavor.get() != Unlocked });\n-            assert!(lock.state.load(atomics::SeqCst) & LOCKED != 0);\n+            assert!(lock.state.load(atomic::SeqCst) & LOCKED != 0);\n         }\n         Guard { lock: lock }\n     }"}, {"sha": "4594345d2a3f67c6caac8cdf602fbe9587d16708", "filename": "src/libsync/one.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fone.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fone.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fone.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -16,7 +16,7 @@\n use core::prelude::*;\n \n use core::int;\n-use core::atomics;\n+use core::atomic;\n \n use mutex::{StaticMutex, MUTEX_INIT};\n \n@@ -40,15 +40,15 @@ use mutex::{StaticMutex, MUTEX_INIT};\n /// ```\n pub struct Once {\n     mutex: StaticMutex,\n-    cnt: atomics::AtomicInt,\n-    lock_cnt: atomics::AtomicInt,\n+    cnt: atomic::AtomicInt,\n+    lock_cnt: atomic::AtomicInt,\n }\n \n /// Initialization value for static `Once` values.\n pub static ONCE_INIT: Once = Once {\n     mutex: MUTEX_INIT,\n-    cnt: atomics::INIT_ATOMIC_INT,\n-    lock_cnt: atomics::INIT_ATOMIC_INT,\n+    cnt: atomic::INIT_ATOMIC_INT,\n+    lock_cnt: atomic::INIT_ATOMIC_INT,\n };\n \n impl Once {\n@@ -63,7 +63,7 @@ impl Once {\n     /// has run and completed (it may not be the closure specified).\n     pub fn doit(&self, f: ||) {\n         // Optimize common path: load is much cheaper than fetch_add.\n-        if self.cnt.load(atomics::SeqCst) < 0 {\n+        if self.cnt.load(atomic::SeqCst) < 0 {\n             return\n         }\n \n@@ -94,27 +94,27 @@ impl Once {\n         // calling `doit` will return immediately before the initialization has\n         // completed.\n \n-        let prev = self.cnt.fetch_add(1, atomics::SeqCst);\n+        let prev = self.cnt.fetch_add(1, atomic::SeqCst);\n         if prev < 0 {\n             // Make sure we never overflow, we'll never have int::MIN\n             // simultaneous calls to `doit` to make this value go back to 0\n-            self.cnt.store(int::MIN, atomics::SeqCst);\n+            self.cnt.store(int::MIN, atomic::SeqCst);\n             return\n         }\n \n         // If the count is negative, then someone else finished the job,\n         // otherwise we run the job and record how many people will try to grab\n         // this lock\n         let guard = self.mutex.lock();\n-        if self.cnt.load(atomics::SeqCst) > 0 {\n+        if self.cnt.load(atomic::SeqCst) > 0 {\n             f();\n-            let prev = self.cnt.swap(int::MIN, atomics::SeqCst);\n-            self.lock_cnt.store(prev, atomics::SeqCst);\n+            let prev = self.cnt.swap(int::MIN, atomic::SeqCst);\n+            self.lock_cnt.store(prev, atomic::SeqCst);\n         }\n         drop(guard);\n \n         // Last one out cleans up after everyone else, no leaks!\n-        if self.lock_cnt.fetch_add(-1, atomics::SeqCst) == 1 {\n+        if self.lock_cnt.fetch_add(-1, atomic::SeqCst) == 1 {\n             unsafe { self.mutex.destroy() }\n         }\n     }"}, {"sha": "49f60fe6f005fb24f4369c1650fb0d37691a1a97", "filename": "src/libsync/raw.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fraw.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fraw.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fraw.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -17,7 +17,7 @@\n \n use core::prelude::*;\n \n-use core::atomics;\n+use core::atomic;\n use core::finally::Finally;\n use core::kinds::marker;\n use core::mem;\n@@ -458,7 +458,7 @@ pub struct RWLock {\n     //\n     // FIXME(#6598): The atomics module has no relaxed ordering flag, so I use\n     // acquire/release orderings superfluously. Change these someday.\n-    read_count: atomics::AtomicUint,\n+    read_count: atomic::AtomicUint,\n }\n \n /// An RAII helper which is created by acquiring a read lock on an RWLock. When\n@@ -490,7 +490,7 @@ impl RWLock {\n         RWLock {\n             order_lock: Semaphore::new(1),\n             access_lock: Sem::new_and_signal(1, num_condvars),\n-            read_count: atomics::AtomicUint::new(0),\n+            read_count: atomic::AtomicUint::new(0),\n         }\n     }\n \n@@ -499,7 +499,7 @@ impl RWLock {\n     /// this one.\n     pub fn read<'a>(&'a self) -> RWLockReadGuard<'a> {\n         let _guard = self.order_lock.access();\n-        let old_count = self.read_count.fetch_add(1, atomics::Acquire);\n+        let old_count = self.read_count.fetch_add(1, atomic::Acquire);\n         if old_count == 0 {\n             self.access_lock.acquire();\n         }\n@@ -575,7 +575,7 @@ impl<'a> RWLockWriteGuard<'a> {\n         // things from now on\n         unsafe { mem::forget(self) }\n \n-        let old_count = lock.read_count.fetch_add(1, atomics::Release);\n+        let old_count = lock.read_count.fetch_add(1, atomic::Release);\n         // If another reader was already blocking, we need to hand-off\n         // the \"reader cloud\" access lock to them.\n         if old_count != 0 {\n@@ -600,7 +600,7 @@ impl<'a> Drop for RWLockWriteGuard<'a> {\n #[unsafe_destructor]\n impl<'a> Drop for RWLockReadGuard<'a> {\n     fn drop(&mut self) {\n-        let old_count = self.lock.read_count.fetch_sub(1, atomics::Release);\n+        let old_count = self.lock.read_count.fetch_sub(1, atomic::Release);\n         assert!(old_count > 0);\n         if old_count == 1 {\n             // Note: this release used to be outside of a locked access"}, {"sha": "578e518cb8ff510b9a94168c9129dd7d1aa5e2bb", "filename": "src/libsync/spsc_queue.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fspsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Flibsync%2Fspsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fspsc_queue.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -42,7 +42,7 @@ use core::mem;\n use core::cell::UnsafeCell;\n use alloc::arc::Arc;\n \n-use atomics::{AtomicPtr, Relaxed, AtomicUint, Acquire, Release};\n+use atomic::{AtomicPtr, Relaxed, AtomicUint, Acquire, Release};\n \n // Node within the linked list queue of messages to send\n struct Node<T> {"}, {"sha": "fa2cf6bda33d71863652e3040839075f55cec68c", "filename": "src/test/compile-fail/std-uncopyable-atomics.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/84782c4e2681496d57f1ac91468d21df085b7782/src%2Ftest%2Fcompile-fail%2Fstd-uncopyable-atomics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84782c4e2681496d57f1ac91468d21df085b7782/src%2Ftest%2Fcompile-fail%2Fstd-uncopyable-atomics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fstd-uncopyable-atomics.rs?ref=84782c4e2681496d57f1ac91468d21df085b7782", "patch": "@@ -12,7 +12,7 @@\n \n #![feature(globs)]\n \n-use std::sync::atomics::*;\n+use std::sync::atomic::*;\n use std::ptr;\n \n fn main() {"}]}