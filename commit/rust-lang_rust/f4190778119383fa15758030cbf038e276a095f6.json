{"sha": "f4190778119383fa15758030cbf038e276a095f6", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY0MTkwNzc4MTE5MzgzZmExNTc1ODAzMGNiZjAzOGUyNzZhMDk1ZjY=", "commit": {"author": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2018-10-08T10:59:37Z"}, "committer": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2018-10-15T15:42:07Z"}, "message": "pacify the mercilous tidy with rustfmt", "tree": {"sha": "62b1785ab995ec5fd59a14ad4dec97532db7938a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/62b1785ab995ec5fd59a14ad4dec97532db7938a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f4190778119383fa15758030cbf038e276a095f6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f4190778119383fa15758030cbf038e276a095f6", "html_url": "https://github.com/rust-lang/rust/commit/f4190778119383fa15758030cbf038e276a095f6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f4190778119383fa15758030cbf038e276a095f6/comments", "author": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "be02f74ea9f6ba641358322f140c697a8842e79b", "url": "https://api.github.com/repos/rust-lang/rust/commits/be02f74ea9f6ba641358322f140c697a8842e79b", "html_url": "https://github.com/rust-lang/rust/commit/be02f74ea9f6ba641358322f140c697a8842e79b"}], "stats": {"total": 255, "additions": 129, "deletions": 126}, "files": [{"sha": "95ecec7d0d5cc5b7002e5356e04e27cebc285d14", "filename": "src/librustc/infer/mod.rs", "status": "modified", "additions": 7, "deletions": 11, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/f4190778119383fa15758030cbf038e276a095f6/src%2Flibrustc%2Finfer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4190778119383fa15758030cbf038e276a095f6/src%2Flibrustc%2Finfer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Finfer%2Fmod.rs?ref=f4190778119383fa15758030cbf038e276a095f6", "patch": "@@ -50,7 +50,6 @@ use self::region_constraints::{RegionConstraintCollector, RegionSnapshot};\n use self::type_variable::TypeVariableOrigin;\n use self::unify_key::ToType;\n \n-pub mod opaque_types;\n pub mod at;\n pub mod canonical;\n mod combine;\n@@ -63,6 +62,7 @@ mod higher_ranked;\n pub mod lattice;\n mod lexical_region_resolve;\n mod lub;\n+pub mod opaque_types;\n pub mod outlives;\n pub mod region_constraints;\n pub mod resolve;\n@@ -87,7 +87,7 @@ pub type FixupResult<T> = Result<T, FixupError>; // \"fixup result\"\n /// NLL borrow checker will also do -- it might be set to true.\n #[derive(Copy, Clone, Default, Debug)]\n pub struct SuppressRegionErrors {\n-    suppressed: bool\n+    suppressed: bool,\n }\n \n impl SuppressRegionErrors {\n@@ -101,15 +101,11 @@ impl SuppressRegionErrors {\n     pub fn when_nll_is_enabled(tcx: TyCtxt<'_, '_, '_>) -> Self {\n         match tcx.borrowck_mode() {\n             // If we're on AST or Migrate mode, report AST region errors\n-            BorrowckMode::Ast | BorrowckMode::Migrate => SuppressRegionErrors {\n-                suppressed: false\n-            },\n+            BorrowckMode::Ast | BorrowckMode::Migrate => SuppressRegionErrors { suppressed: false },\n \n             // If we're on MIR or Compare mode, don't report AST region errors as they should\n             // be reported by NLL\n-            BorrowckMode::Compare | BorrowckMode::Mir => SuppressRegionErrors {\n-                suppressed: true\n-            },\n+            BorrowckMode::Compare | BorrowckMode::Mir => SuppressRegionErrors { suppressed: true },\n         }\n     }\n }\n@@ -512,13 +508,13 @@ impl<'a, 'gcx, 'tcx> InferCtxtBuilder<'a, 'gcx, 'tcx> {\n         T: TypeFoldable<'tcx>,\n     {\n         self.enter(|infcx| {\n-            let (value, subst) = infcx.instantiate_canonical_with_fresh_inference_vars(span, canonical);\n+            let (value, subst) =\n+                infcx.instantiate_canonical_with_fresh_inference_vars(span, canonical);\n             f(infcx, value, subst)\n         })\n     }\n \n-    pub fn enter<R>(&'tcx mut self, f: impl for<'b> FnOnce(InferCtxt<'b, 'gcx, 'tcx>) -> R) -> R\n-    {\n+    pub fn enter<R>(&'tcx mut self, f: impl for<'b> FnOnce(InferCtxt<'b, 'gcx, 'tcx>) -> R) -> R {\n         let InferCtxtBuilder {\n             global_tcx,\n             ref arena,"}, {"sha": "ed61f07c4d83dda88a9c8bd40785ef67677f055b", "filename": "src/librustc_traits/dropck_outlives.rs", "status": "modified", "additions": 106, "deletions": 104, "changes": 210, "blob_url": "https://github.com/rust-lang/rust/blob/f4190778119383fa15758030cbf038e276a095f6/src%2Flibrustc_traits%2Fdropck_outlives.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4190778119383fa15758030cbf038e276a095f6/src%2Flibrustc_traits%2Fdropck_outlives.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_traits%2Fdropck_outlives.rs?ref=f4190778119383fa15758030cbf038e276a095f6", "patch": "@@ -34,117 +34,121 @@ fn dropck_outlives<'tcx>(\n ) -> Result<Lrc<Canonical<'tcx, QueryResponse<'tcx, DropckOutlivesResult<'tcx>>>>, NoSolution> {\n     debug!(\"dropck_outlives(goal={:#?})\", canonical_goal);\n \n-    tcx.infer_ctxt().enter_with_canonical(DUMMY_SP, &canonical_goal, |ref infcx, goal, canonical_inference_vars| {\n-        let tcx = infcx.tcx;\n-        let ParamEnvAnd {\n-            param_env,\n-            value: for_ty,\n-        } = goal;\n-\n-        let mut result = DropckOutlivesResult {\n-            kinds: vec![],\n-            overflows: vec![],\n-        };\n+    tcx.infer_ctxt().enter_with_canonical(\n+        DUMMY_SP,\n+        &canonical_goal,\n+        |ref infcx, goal, canonical_inference_vars| {\n+            let tcx = infcx.tcx;\n+            let ParamEnvAnd {\n+                param_env,\n+                value: for_ty,\n+            } = goal;\n+\n+            let mut result = DropckOutlivesResult {\n+                kinds: vec![],\n+                overflows: vec![],\n+            };\n \n-        // A stack of types left to process. Each round, we pop\n-        // something from the stack and invoke\n-        // `dtorck_constraint_for_ty`. This may produce new types that\n-        // have to be pushed on the stack. This continues until we have explored\n-        // all the reachable types from the type `for_ty`.\n-        //\n-        // Example: Imagine that we have the following code:\n-        //\n-        // ```rust\n-        // struct A {\n-        //     value: B,\n-        //     children: Vec<A>,\n-        // }\n-        //\n-        // struct B {\n-        //     value: u32\n-        // }\n-        //\n-        // fn f() {\n-        //   let a: A = ...;\n-        //   ..\n-        // } // here, `a` is dropped\n-        // ```\n-        //\n-        // at the point where `a` is dropped, we need to figure out\n-        // which types inside of `a` contain region data that may be\n-        // accessed by any destructors in `a`. We begin by pushing `A`\n-        // onto the stack, as that is the type of `a`. We will then\n-        // invoke `dtorck_constraint_for_ty` which will expand `A`\n-        // into the types of its fields `(B, Vec<A>)`. These will get\n-        // pushed onto the stack. Eventually, expanding `Vec<A>` will\n-        // lead to us trying to push `A` a second time -- to prevent\n-        // infinite recursion, we notice that `A` was already pushed\n-        // once and stop.\n-        let mut ty_stack = vec![(for_ty, 0)];\n-\n-        // Set used to detect infinite recursion.\n-        let mut ty_set = FxHashSet();\n-\n-        let fulfill_cx = &mut FulfillmentContext::new();\n-\n-        let cause = ObligationCause::dummy();\n-        while let Some((ty, depth)) = ty_stack.pop() {\n-            let DtorckConstraint {\n-                dtorck_types,\n-                outlives,\n-                overflows,\n-            } = dtorck_constraint_for_ty(tcx, DUMMY_SP, for_ty, depth, ty)?;\n-\n-            // \"outlives\" represent types/regions that may be touched\n-            // by a destructor.\n-            result.kinds.extend(outlives);\n-            result.overflows.extend(overflows);\n-\n-            // dtorck types are \"types that will get dropped but which\n-            // do not themselves define a destructor\", more or less. We have\n-            // to push them onto the stack to be expanded.\n-            for ty in dtorck_types {\n-                match infcx.at(&cause, param_env).normalize(&ty) {\n-                    Ok(Normalized {\n-                        value: ty,\n-                        obligations,\n-                    }) => {\n-                        fulfill_cx.register_predicate_obligations(infcx, obligations);\n-\n-                        debug!(\"dropck_outlives: ty from dtorck_types = {:?}\", ty);\n-\n-                        match ty.sty {\n-                            // All parameters live for the duration of the\n-                            // function.\n-                            ty::Param(..) => {}\n-\n-                            // A projection that we couldn't resolve - it\n-                            // might have a destructor.\n-                            ty::Projection(..) | ty::Opaque(..) => {\n-                                result.kinds.push(ty.into());\n-                            }\n+            // A stack of types left to process. Each round, we pop\n+            // something from the stack and invoke\n+            // `dtorck_constraint_for_ty`. This may produce new types that\n+            // have to be pushed on the stack. This continues until we have explored\n+            // all the reachable types from the type `for_ty`.\n+            //\n+            // Example: Imagine that we have the following code:\n+            //\n+            // ```rust\n+            // struct A {\n+            //     value: B,\n+            //     children: Vec<A>,\n+            // }\n+            //\n+            // struct B {\n+            //     value: u32\n+            // }\n+            //\n+            // fn f() {\n+            //   let a: A = ...;\n+            //   ..\n+            // } // here, `a` is dropped\n+            // ```\n+            //\n+            // at the point where `a` is dropped, we need to figure out\n+            // which types inside of `a` contain region data that may be\n+            // accessed by any destructors in `a`. We begin by pushing `A`\n+            // onto the stack, as that is the type of `a`. We will then\n+            // invoke `dtorck_constraint_for_ty` which will expand `A`\n+            // into the types of its fields `(B, Vec<A>)`. These will get\n+            // pushed onto the stack. Eventually, expanding `Vec<A>` will\n+            // lead to us trying to push `A` a second time -- to prevent\n+            // infinite recursion, we notice that `A` was already pushed\n+            // once and stop.\n+            let mut ty_stack = vec![(for_ty, 0)];\n+\n+            // Set used to detect infinite recursion.\n+            let mut ty_set = FxHashSet();\n+\n+            let fulfill_cx = &mut FulfillmentContext::new();\n+\n+            let cause = ObligationCause::dummy();\n+            while let Some((ty, depth)) = ty_stack.pop() {\n+                let DtorckConstraint {\n+                    dtorck_types,\n+                    outlives,\n+                    overflows,\n+                } = dtorck_constraint_for_ty(tcx, DUMMY_SP, for_ty, depth, ty)?;\n+\n+                // \"outlives\" represent types/regions that may be touched\n+                // by a destructor.\n+                result.kinds.extend(outlives);\n+                result.overflows.extend(overflows);\n+\n+                // dtorck types are \"types that will get dropped but which\n+                // do not themselves define a destructor\", more or less. We have\n+                // to push them onto the stack to be expanded.\n+                for ty in dtorck_types {\n+                    match infcx.at(&cause, param_env).normalize(&ty) {\n+                        Ok(Normalized {\n+                            value: ty,\n+                            obligations,\n+                        }) => {\n+                            fulfill_cx.register_predicate_obligations(infcx, obligations);\n+\n+                            debug!(\"dropck_outlives: ty from dtorck_types = {:?}\", ty);\n+\n+                            match ty.sty {\n+                                // All parameters live for the duration of the\n+                                // function.\n+                                ty::Param(..) => {}\n+\n+                                // A projection that we couldn't resolve - it\n+                                // might have a destructor.\n+                                ty::Projection(..) | ty::Opaque(..) => {\n+                                    result.kinds.push(ty.into());\n+                                }\n \n-                            _ => {\n-                                if ty_set.insert(ty) {\n-                                    ty_stack.push((ty, depth + 1));\n+                                _ => {\n+                                    if ty_set.insert(ty) {\n+                                        ty_stack.push((ty, depth + 1));\n+                                    }\n                                 }\n                             }\n                         }\n-                    }\n \n-                    // We don't actually expect to fail to normalize.\n-                    // That implies a WF error somewhere else.\n-                    Err(NoSolution) => {\n-                        return Err(NoSolution);\n+                        // We don't actually expect to fail to normalize.\n+                        // That implies a WF error somewhere else.\n+                        Err(NoSolution) => {\n+                            return Err(NoSolution);\n+                        }\n                     }\n                 }\n             }\n-        }\n \n-        debug!(\"dropck_outlives: result = {:#?}\", result);\n+            debug!(\"dropck_outlives: result = {:#?}\", result);\n \n-        infcx.make_canonicalized_query_response(canonical_inference_vars, result, fulfill_cx)\n-    })\n+            infcx.make_canonicalized_query_response(canonical_inference_vars, result, fulfill_cx)\n+        },\n+    )\n }\n \n /// Return a set of constraints that needs to be satisfied in\n@@ -192,8 +196,7 @@ fn dtorck_constraint_for_ty<'a, 'gcx, 'tcx>(\n             dtorck_constraint_for_ty(tcx, span, for_ty, depth + 1, ety)\n         }\n \n-        ty::Tuple(tys) => tys\n-            .iter()\n+        ty::Tuple(tys) => tys.iter()\n             .map(|ty| dtorck_constraint_for_ty(tcx, span, for_ty, depth + 1, ty))\n             .collect(),\n \n@@ -305,8 +308,7 @@ crate fn adt_dtorck_constraint<'a, 'tcx>(\n         return Ok(result);\n     }\n \n-    let mut result = def\n-        .all_fields()\n+    let mut result = def.all_fields()\n         .map(|field| tcx.type_of(field.did))\n         .map(|fty| dtorck_constraint_for_ty(tcx, span, fty, 0, fty))\n         .collect::<Result<DtorckConstraint, NoSolution>>()?;"}, {"sha": "15ef1106311b3ec9c657720c147ad3c19a9fb904", "filename": "src/librustc_traits/evaluate_obligation.rs", "status": "modified", "additions": 16, "deletions": 11, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/f4190778119383fa15758030cbf038e276a095f6/src%2Flibrustc_traits%2Fevaluate_obligation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4190778119383fa15758030cbf038e276a095f6/src%2Flibrustc_traits%2Fevaluate_obligation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_traits%2Fevaluate_obligation.rs?ref=f4190778119383fa15758030cbf038e276a095f6", "patch": "@@ -8,9 +8,10 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use rustc::traits::{EvaluationResult, Obligation, ObligationCause,\n-                    OverflowError, SelectionContext, TraitQueryMode};\n use rustc::traits::query::CanonicalPredicateGoal;\n+use rustc::traits::{\n+    EvaluationResult, Obligation, ObligationCause, OverflowError, SelectionContext, TraitQueryMode,\n+};\n use rustc::ty::query::Providers;\n use rustc::ty::{ParamEnvAnd, TyCtxt};\n use syntax::source_map::DUMMY_SP;\n@@ -26,15 +27,19 @@ fn evaluate_obligation<'tcx>(\n     tcx: TyCtxt<'_, 'tcx, 'tcx>,\n     canonical_goal: CanonicalPredicateGoal<'tcx>,\n ) -> Result<EvaluationResult, OverflowError> {\n-    tcx.infer_ctxt().enter_with_canonical(DUMMY_SP, &canonical_goal, |ref infcx, goal, _canonical_inference_vars| {\n-        let ParamEnvAnd {\n-            param_env,\n-            value: predicate,\n-        } = goal;\n+    tcx.infer_ctxt().enter_with_canonical(\n+        DUMMY_SP,\n+        &canonical_goal,\n+        |ref infcx, goal, _canonical_inference_vars| {\n+            let ParamEnvAnd {\n+                param_env,\n+                value: predicate,\n+            } = goal;\n \n-        let mut selcx = SelectionContext::with_query_mode(&infcx, TraitQueryMode::Canonical);\n-        let obligation = Obligation::new(ObligationCause::dummy(), param_env, predicate);\n+            let mut selcx = SelectionContext::with_query_mode(&infcx, TraitQueryMode::Canonical);\n+            let obligation = Obligation::new(ObligationCause::dummy(), param_env, predicate);\n \n-        selcx.evaluate_obligation_recursively(&obligation)\n-    })\n+            selcx.evaluate_obligation_recursively(&obligation)\n+        },\n+    )\n }"}]}