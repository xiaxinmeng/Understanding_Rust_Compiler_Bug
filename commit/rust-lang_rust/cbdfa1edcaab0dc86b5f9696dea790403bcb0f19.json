{"sha": "cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNiZGZhMWVkY2FhYjBkYzg2YjVmOTY5NmRlYTc5MDQwM2JjYjBmMTk=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2021-05-06T13:21:40Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2021-06-06T11:21:12Z"}, "message": "parser: Ensure that all nonterminals have tokens after parsing", "tree": {"sha": "dadfd42b3cf5c90a9746367f32ce9fea64f942e8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dadfd42b3cf5c90a9746367f32ce9fea64f942e8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "html_url": "https://github.com/rust-lang/rust/commit/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9a576175cc9a0aecb85d0764a4f66ee29e26e155", "url": "https://api.github.com/repos/rust-lang/rust/commits/9a576175cc9a0aecb85d0764a4f66ee29e26e155", "html_url": "https://github.com/rust-lang/rust/commit/9a576175cc9a0aecb85d0764a4f66ee29e26e155"}], "stats": {"total": 643, "additions": 612, "deletions": 31}, "files": [{"sha": "d586426d70ef053c4825ee567eb7289b2e48c18e", "filename": "compiler/rustc_ast/src/ast_like.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_ast%2Fsrc%2Fast_like.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_ast%2Fsrc%2Fast_like.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast_like.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -82,7 +82,8 @@ impl AstLike for crate::token::Nonterminal {\n             Nonterminal::NtMeta(attr_item) => attr_item.tokens_mut(),\n             Nonterminal::NtPath(path) => path.tokens_mut(),\n             Nonterminal::NtVis(vis) => vis.tokens_mut(),\n-            _ => panic!(\"Called tokens_mut on {:?}\", self),\n+            Nonterminal::NtBlock(block) => block.tokens_mut(),\n+            Nonterminal::NtIdent(..) | Nonterminal::NtLifetime(..) | Nonterminal::NtTT(..) => None,\n         }\n     }\n }"}, {"sha": "e1d0b84f4193f92a0ff002af50b24234b33b32a2", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 2, "deletions": 8, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -342,16 +342,10 @@ impl<'a> Parser<'a> {\n \n         // If we support tokens at all\n         if let Some(target_tokens) = ret.tokens_mut() {\n-            if let Some(target_tokens) = target_tokens {\n-                assert!(\n-                    !self.capture_cfg,\n-                    \"Encountered existing tokens with capture_cfg set: {:?}\",\n-                    target_tokens\n-                );\n-            } else {\n+            if target_tokens.is_none() {\n                 // Store se our newly captured tokens into the AST node\n                 *target_tokens = Some(tokens.clone());\n-            };\n+            }\n         }\n \n         let final_attrs = ret.attrs();"}, {"sha": "a764cf6bdb04e65dd821c0c962c5e6c4b543de16", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 1, "deletions": 11, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -94,17 +94,7 @@ impl<'a> Parser<'a> {\n \n     /// Parses an expression, forcing tokens to be collected\n     pub fn parse_expr_force_collect(&mut self) -> PResult<'a, P<Expr>> {\n-        // If we have outer attributes, then the call to `collect_tokens_trailing_token`\n-        // will be made for us.\n-        if matches!(self.token.kind, TokenKind::Pound | TokenKind::DocComment(..)) {\n-            self.parse_expr()\n-        } else {\n-            // If we don't have outer attributes, then we need to ensure\n-            // that collection happens by using `collect_tokens_no_attrs`.\n-            // Expression don't support custom inner attributes, so `parse_expr`\n-            // will never try to collect tokens if we don't have outer attributes.\n-            self.collect_tokens_no_attrs(|this| this.parse_expr())\n-        }\n+        self.collect_tokens_no_attrs(|this| this.parse_expr())\n     }\n \n     pub fn parse_anon_const_expr(&mut self) -> PResult<'a, AnonConst> {"}, {"sha": "cd9f84db5e55958005bcb3284c00c4fee3f63e89", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -63,6 +63,7 @@ enum BlockMode {\n \n /// Whether or not we should force collection of tokens for an AST node,\n /// regardless of whether or not it has attributes\n+#[derive(Clone, Copy, PartialEq)]\n pub enum ForceCollect {\n     Yes,\n     No,"}, {"sha": "30a6b61407f69a06cca09094e715dc028bed125d", "filename": "compiler/rustc_parse/src/parser/nonterminal.rs", "status": "modified", "additions": 15, "deletions": 2, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -1,5 +1,6 @@\n use rustc_ast::ptr::P;\n use rustc_ast::token::{self, Nonterminal, NonterminalKind, Token};\n+use rustc_ast::AstLike;\n use rustc_ast_pretty::pprust;\n use rustc_errors::PResult;\n use rustc_span::symbol::{kw, Ident};\n@@ -102,7 +103,7 @@ impl<'a> Parser<'a> {\n         // which requires having captured tokens available. Since we cannot determine\n         // in advance whether or not a proc-macro will be (transitively) invoked,\n         // we always capture tokens for any `Nonterminal` which needs them.\n-        Ok(match kind {\n+        let mut nt = match kind {\n             NonterminalKind::Item => match self.parse_item(ForceCollect::Yes)? {\n                 Some(item) => token::NtItem(item),\n                 None => {\n@@ -169,7 +170,19 @@ impl<'a> Parser<'a> {\n                     return Err(self.struct_span_err(self.token.span, msg));\n                 }\n             }\n-        })\n+        };\n+\n+        // If tokens are supported at all, they should be collected.\n+        if matches!(nt.tokens_mut(), Some(None)) {\n+            panic!(\n+                \"Missing tokens for nt {:?} at {:?}: {:?}\",\n+                nt,\n+                nt.span(),\n+                pprust::nonterminal_to_string(&nt)\n+            );\n+        }\n+\n+        Ok(nt)\n     }\n }\n "}, {"sha": "4f0dcfeb5dae06b2f4a858b427fed86ec5441cf5", "filename": "compiler/rustc_parse/src/parser/stmt.rs", "status": "modified", "additions": 14, "deletions": 9, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -73,7 +73,11 @@ impl<'a> Parser<'a> {\n             // or `auto trait` items. We aim to parse an arbitrary path `a::b` but not something\n             // that starts like a path (1 token), but it fact not a path.\n             // Also, we avoid stealing syntax from `parse_item_`.\n-            self.parse_stmt_path_start(lo, attrs, force_collect)?\n+            if force_collect == ForceCollect::Yes {\n+                self.collect_tokens_no_attrs(|this| this.parse_stmt_path_start(lo, attrs))\n+            } else {\n+                self.parse_stmt_path_start(lo, attrs)\n+            }?\n         } else if let Some(item) =\n             self.parse_item_common(attrs.clone(), false, true, |_| true, force_collect)?\n         {\n@@ -85,21 +89,22 @@ impl<'a> Parser<'a> {\n             self.mk_stmt(lo, StmtKind::Empty)\n         } else if self.token != token::CloseDelim(token::Brace) {\n             // Remainder are line-expr stmts.\n-            let e = self.parse_expr_res(Restrictions::STMT_EXPR, Some(attrs))?;\n+            let e = if force_collect == ForceCollect::Yes {\n+                self.collect_tokens_no_attrs(|this| {\n+                    this.parse_expr_res(Restrictions::STMT_EXPR, Some(attrs))\n+                })\n+            } else {\n+                self.parse_expr_res(Restrictions::STMT_EXPR, Some(attrs))\n+            }?;\n             self.mk_stmt(lo.to(e.span), StmtKind::Expr(e))\n         } else {\n             self.error_outer_attrs(&attrs.take_for_recovery());\n             return Ok(None);\n         }))\n     }\n \n-    fn parse_stmt_path_start(\n-        &mut self,\n-        lo: Span,\n-        attrs: AttrWrapper,\n-        force_collect: ForceCollect,\n-    ) -> PResult<'a, Stmt> {\n-        let stmt = self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n+    fn parse_stmt_path_start(&mut self, lo: Span, attrs: AttrWrapper) -> PResult<'a, Stmt> {\n+        let stmt = self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n             let path = this.parse_path(PathStyle::Expr)?;\n \n             if this.eat(&token::Not) {"}, {"sha": "d4067a3359271ee7f54866460399343fd49b45f5", "filename": "src/test/ui/proc-macro/expr-stmt-nonterminal-tokens.rs", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/src%2Ftest%2Fui%2Fproc-macro%2Fexpr-stmt-nonterminal-tokens.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/src%2Ftest%2Fui%2Fproc-macro%2Fexpr-stmt-nonterminal-tokens.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fexpr-stmt-nonterminal-tokens.rs?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -0,0 +1,37 @@\n+// check-pass\n+// aux-build:test-macros.rs\n+\n+#![feature(decl_macro)]\n+#![feature(stmt_expr_attributes)]\n+\n+#![no_std] // Don't load unnecessary hygiene information from std\n+extern crate std;\n+\n+#[macro_use]\n+extern crate test_macros;\n+\n+macro mac {\n+    (expr $expr:expr) => {\n+        #[derive(Print)]\n+        enum E {\n+            V = { let _ = $expr; 0 },\n+        }\n+    },\n+    (stmt $stmt:stmt) => {\n+        #[derive(Print)]\n+        enum E {\n+            V = { let _ = { $stmt }; 0 },\n+        }\n+    },\n+}\n+\n+const PATH: u8 = 2;\n+\n+fn main() {\n+    mac!(expr #[allow(warnings)] 0);\n+    mac!(stmt 0);\n+    mac!(stmt {});\n+    mac!(stmt PATH);\n+    mac!(stmt 0 + 1);\n+    mac!(stmt PATH + 1);\n+}"}, {"sha": "e37a483cb87bc0335194cbc6968e6671d558360a", "filename": "src/test/ui/proc-macro/expr-stmt-nonterminal-tokens.stdout", "status": "added", "additions": 540, "deletions": 0, "changes": 540, "blob_url": "https://github.com/rust-lang/rust/blob/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/src%2Ftest%2Fui%2Fproc-macro%2Fexpr-stmt-nonterminal-tokens.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/cbdfa1edcaab0dc86b5f9696dea790403bcb0f19/src%2Ftest%2Fui%2Fproc-macro%2Fexpr-stmt-nonterminal-tokens.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fexpr-stmt-nonterminal-tokens.stdout?ref=cbdfa1edcaab0dc86b5f9696dea790403bcb0f19", "patch": "@@ -0,0 +1,540 @@\n+PRINT-DERIVE INPUT (DISPLAY): enum E { V = { let _ = #[allow(warnings)] 0 ; 0 }, }\n+PRINT-DERIVE DEEP-RE-COLLECTED (DISPLAY): enum E { V = { let _ = #[allow(warnings)] #[allow(warnings)] 0 ; 0 }, }\n+PRINT-DERIVE INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"enum\",\n+        span: #4 bytes(299..303),\n+    },\n+    Ident {\n+        ident: \"E\",\n+        span: #4 bytes(304..305),\n+    },\n+    Group {\n+        delimiter: Brace,\n+        stream: TokenStream [\n+            Ident {\n+                ident: \"V\",\n+                span: #4 bytes(320..321),\n+            },\n+            Punct {\n+                ch: '=',\n+                spacing: Alone,\n+                span: #4 bytes(322..323),\n+            },\n+            Group {\n+                delimiter: Brace,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"let\",\n+                        span: #4 bytes(326..329),\n+                    },\n+                    Ident {\n+                        ident: \"_\",\n+                        span: #4 bytes(330..331),\n+                    },\n+                    Punct {\n+                        ch: '=',\n+                        spacing: Alone,\n+                        span: #4 bytes(332..333),\n+                    },\n+                    Group {\n+                        delimiter: None,\n+                        stream: TokenStream [\n+                            Punct {\n+                                ch: '#',\n+                                spacing: Alone,\n+                                span: #0 bytes(541..542),\n+                            },\n+                            Group {\n+                                delimiter: Bracket,\n+                                stream: TokenStream [\n+                                    Ident {\n+                                        ident: \"allow\",\n+                                        span: #0 bytes(543..548),\n+                                    },\n+                                    Group {\n+                                        delimiter: Parenthesis,\n+                                        stream: TokenStream [\n+                                            Ident {\n+                                                ident: \"warnings\",\n+                                                span: #0 bytes(549..557),\n+                                            },\n+                                        ],\n+                                        span: #0 bytes(548..558),\n+                                    },\n+                                ],\n+                                span: #0 bytes(542..559),\n+                            },\n+                            Punct {\n+                                ch: '#',\n+                                spacing: Alone,\n+                                span: #0 bytes(541..542),\n+                            },\n+                            Group {\n+                                delimiter: Bracket,\n+                                stream: TokenStream [\n+                                    Ident {\n+                                        ident: \"allow\",\n+                                        span: #0 bytes(543..548),\n+                                    },\n+                                    Group {\n+                                        delimiter: Parenthesis,\n+                                        stream: TokenStream [\n+                                            Ident {\n+                                                ident: \"warnings\",\n+                                                span: #0 bytes(549..557),\n+                                            },\n+                                        ],\n+                                        span: #0 bytes(548..558),\n+                                    },\n+                                ],\n+                                span: #0 bytes(542..559),\n+                            },\n+                            Literal {\n+                                kind: Integer,\n+                                symbol: \"0\",\n+                                suffix: None,\n+                                span: #0 bytes(560..561),\n+                            },\n+                        ],\n+                        span: #4 bytes(334..339),\n+                    },\n+                    Punct {\n+                        ch: ';',\n+                        spacing: Alone,\n+                        span: #4 bytes(339..340),\n+                    },\n+                    Literal {\n+                        kind: Integer,\n+                        symbol: \"0\",\n+                        suffix: None,\n+                        span: #4 bytes(341..342),\n+                    },\n+                ],\n+                span: #4 bytes(324..344),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: #4 bytes(344..345),\n+            },\n+        ],\n+        span: #4 bytes(306..355),\n+    },\n+]\n+PRINT-DERIVE INPUT (DISPLAY): enum E { V = { let _ = { 0; } ; 0 }, }\n+PRINT-DERIVE DEEP-RE-COLLECTED (DISPLAY): enum E { V = { let _ = { 0 } ; 0 }, }\n+PRINT-DERIVE INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"enum\",\n+        span: #8 bytes(423..427),\n+    },\n+    Ident {\n+        ident: \"E\",\n+        span: #8 bytes(428..429),\n+    },\n+    Group {\n+        delimiter: Brace,\n+        stream: TokenStream [\n+            Ident {\n+                ident: \"V\",\n+                span: #8 bytes(444..445),\n+            },\n+            Punct {\n+                ch: '=',\n+                spacing: Alone,\n+                span: #8 bytes(446..447),\n+            },\n+            Group {\n+                delimiter: Brace,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"let\",\n+                        span: #8 bytes(450..453),\n+                    },\n+                    Ident {\n+                        ident: \"_\",\n+                        span: #8 bytes(454..455),\n+                    },\n+                    Punct {\n+                        ch: '=',\n+                        spacing: Alone,\n+                        span: #8 bytes(456..457),\n+                    },\n+                    Group {\n+                        delimiter: Brace,\n+                        stream: TokenStream [\n+                            Group {\n+                                delimiter: None,\n+                                stream: TokenStream [\n+                                    Literal {\n+                                        kind: Integer,\n+                                        symbol: \"0\",\n+                                        suffix: None,\n+                                        span: #0 bytes(578..579),\n+                                    },\n+                                ],\n+                                span: #8 bytes(460..465),\n+                            },\n+                        ],\n+                        span: #8 bytes(458..467),\n+                    },\n+                    Punct {\n+                        ch: ';',\n+                        spacing: Alone,\n+                        span: #8 bytes(467..468),\n+                    },\n+                    Literal {\n+                        kind: Integer,\n+                        symbol: \"0\",\n+                        suffix: None,\n+                        span: #8 bytes(469..470),\n+                    },\n+                ],\n+                span: #8 bytes(448..472),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: #8 bytes(472..473),\n+            },\n+        ],\n+        span: #8 bytes(430..483),\n+    },\n+]\n+PRINT-DERIVE INPUT (DISPLAY): enum E { V = { let _ = { { } } ; 0 }, }\n+PRINT-DERIVE INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"enum\",\n+        span: #12 bytes(423..427),\n+    },\n+    Ident {\n+        ident: \"E\",\n+        span: #12 bytes(428..429),\n+    },\n+    Group {\n+        delimiter: Brace,\n+        stream: TokenStream [\n+            Ident {\n+                ident: \"V\",\n+                span: #12 bytes(444..445),\n+            },\n+            Punct {\n+                ch: '=',\n+                spacing: Alone,\n+                span: #12 bytes(446..447),\n+            },\n+            Group {\n+                delimiter: Brace,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"let\",\n+                        span: #12 bytes(450..453),\n+                    },\n+                    Ident {\n+                        ident: \"_\",\n+                        span: #12 bytes(454..455),\n+                    },\n+                    Punct {\n+                        ch: '=',\n+                        spacing: Alone,\n+                        span: #12 bytes(456..457),\n+                    },\n+                    Group {\n+                        delimiter: Brace,\n+                        stream: TokenStream [\n+                            Group {\n+                                delimiter: None,\n+                                stream: TokenStream [\n+                                    Group {\n+                                        delimiter: Brace,\n+                                        stream: TokenStream [],\n+                                        span: #0 bytes(596..598),\n+                                    },\n+                                ],\n+                                span: #12 bytes(460..465),\n+                            },\n+                        ],\n+                        span: #12 bytes(458..467),\n+                    },\n+                    Punct {\n+                        ch: ';',\n+                        spacing: Alone,\n+                        span: #12 bytes(467..468),\n+                    },\n+                    Literal {\n+                        kind: Integer,\n+                        symbol: \"0\",\n+                        suffix: None,\n+                        span: #12 bytes(469..470),\n+                    },\n+                ],\n+                span: #12 bytes(448..472),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: #12 bytes(472..473),\n+            },\n+        ],\n+        span: #12 bytes(430..483),\n+    },\n+]\n+PRINT-DERIVE INPUT (DISPLAY): enum E { V = { let _ = { PATH; } ; 0 }, }\n+PRINT-DERIVE DEEP-RE-COLLECTED (DISPLAY): enum E { V = { let _ = { PATH } ; 0 }, }\n+PRINT-DERIVE INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"enum\",\n+        span: #16 bytes(423..427),\n+    },\n+    Ident {\n+        ident: \"E\",\n+        span: #16 bytes(428..429),\n+    },\n+    Group {\n+        delimiter: Brace,\n+        stream: TokenStream [\n+            Ident {\n+                ident: \"V\",\n+                span: #16 bytes(444..445),\n+            },\n+            Punct {\n+                ch: '=',\n+                spacing: Alone,\n+                span: #16 bytes(446..447),\n+            },\n+            Group {\n+                delimiter: Brace,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"let\",\n+                        span: #16 bytes(450..453),\n+                    },\n+                    Ident {\n+                        ident: \"_\",\n+                        span: #16 bytes(454..455),\n+                    },\n+                    Punct {\n+                        ch: '=',\n+                        spacing: Alone,\n+                        span: #16 bytes(456..457),\n+                    },\n+                    Group {\n+                        delimiter: Brace,\n+                        stream: TokenStream [\n+                            Group {\n+                                delimiter: None,\n+                                stream: TokenStream [\n+                                    Ident {\n+                                        ident: \"PATH\",\n+                                        span: #0 bytes(615..619),\n+                                    },\n+                                ],\n+                                span: #16 bytes(460..465),\n+                            },\n+                        ],\n+                        span: #16 bytes(458..467),\n+                    },\n+                    Punct {\n+                        ch: ';',\n+                        spacing: Alone,\n+                        span: #16 bytes(467..468),\n+                    },\n+                    Literal {\n+                        kind: Integer,\n+                        symbol: \"0\",\n+                        suffix: None,\n+                        span: #16 bytes(469..470),\n+                    },\n+                ],\n+                span: #16 bytes(448..472),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: #16 bytes(472..473),\n+            },\n+        ],\n+        span: #16 bytes(430..483),\n+    },\n+]\n+PRINT-DERIVE INPUT (DISPLAY): enum E { V = { let _ = { 0 + 1; } ; 0 }, }\n+PRINT-DERIVE DEEP-RE-COLLECTED (DISPLAY): enum E { V = { let _ = { 0 + 1 } ; 0 }, }\n+PRINT-DERIVE INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"enum\",\n+        span: #20 bytes(423..427),\n+    },\n+    Ident {\n+        ident: \"E\",\n+        span: #20 bytes(428..429),\n+    },\n+    Group {\n+        delimiter: Brace,\n+        stream: TokenStream [\n+            Ident {\n+                ident: \"V\",\n+                span: #20 bytes(444..445),\n+            },\n+            Punct {\n+                ch: '=',\n+                spacing: Alone,\n+                span: #20 bytes(446..447),\n+            },\n+            Group {\n+                delimiter: Brace,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"let\",\n+                        span: #20 bytes(450..453),\n+                    },\n+                    Ident {\n+                        ident: \"_\",\n+                        span: #20 bytes(454..455),\n+                    },\n+                    Punct {\n+                        ch: '=',\n+                        spacing: Alone,\n+                        span: #20 bytes(456..457),\n+                    },\n+                    Group {\n+                        delimiter: Brace,\n+                        stream: TokenStream [\n+                            Group {\n+                                delimiter: None,\n+                                stream: TokenStream [\n+                                    Literal {\n+                                        kind: Integer,\n+                                        symbol: \"0\",\n+                                        suffix: None,\n+                                        span: #0 bytes(636..637),\n+                                    },\n+                                    Punct {\n+                                        ch: '+',\n+                                        spacing: Alone,\n+                                        span: #0 bytes(638..639),\n+                                    },\n+                                    Literal {\n+                                        kind: Integer,\n+                                        symbol: \"1\",\n+                                        suffix: None,\n+                                        span: #0 bytes(640..641),\n+                                    },\n+                                ],\n+                                span: #20 bytes(460..465),\n+                            },\n+                        ],\n+                        span: #20 bytes(458..467),\n+                    },\n+                    Punct {\n+                        ch: ';',\n+                        spacing: Alone,\n+                        span: #20 bytes(467..468),\n+                    },\n+                    Literal {\n+                        kind: Integer,\n+                        symbol: \"0\",\n+                        suffix: None,\n+                        span: #20 bytes(469..470),\n+                    },\n+                ],\n+                span: #20 bytes(448..472),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: #20 bytes(472..473),\n+            },\n+        ],\n+        span: #20 bytes(430..483),\n+    },\n+]\n+PRINT-DERIVE INPUT (DISPLAY): enum E { V = { let _ = { PATH + 1; } ; 0 }, }\n+PRINT-DERIVE DEEP-RE-COLLECTED (DISPLAY): enum E { V = { let _ = { PATH + 1 } ; 0 }, }\n+PRINT-DERIVE INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"enum\",\n+        span: #24 bytes(423..427),\n+    },\n+    Ident {\n+        ident: \"E\",\n+        span: #24 bytes(428..429),\n+    },\n+    Group {\n+        delimiter: Brace,\n+        stream: TokenStream [\n+            Ident {\n+                ident: \"V\",\n+                span: #24 bytes(444..445),\n+            },\n+            Punct {\n+                ch: '=',\n+                spacing: Alone,\n+                span: #24 bytes(446..447),\n+            },\n+            Group {\n+                delimiter: Brace,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"let\",\n+                        span: #24 bytes(450..453),\n+                    },\n+                    Ident {\n+                        ident: \"_\",\n+                        span: #24 bytes(454..455),\n+                    },\n+                    Punct {\n+                        ch: '=',\n+                        spacing: Alone,\n+                        span: #24 bytes(456..457),\n+                    },\n+                    Group {\n+                        delimiter: Brace,\n+                        stream: TokenStream [\n+                            Group {\n+                                delimiter: None,\n+                                stream: TokenStream [\n+                                    Ident {\n+                                        ident: \"PATH\",\n+                                        span: #0 bytes(658..662),\n+                                    },\n+                                    Punct {\n+                                        ch: '+',\n+                                        spacing: Alone,\n+                                        span: #0 bytes(663..664),\n+                                    },\n+                                    Literal {\n+                                        kind: Integer,\n+                                        symbol: \"1\",\n+                                        suffix: None,\n+                                        span: #0 bytes(665..666),\n+                                    },\n+                                ],\n+                                span: #24 bytes(460..465),\n+                            },\n+                        ],\n+                        span: #24 bytes(458..467),\n+                    },\n+                    Punct {\n+                        ch: ';',\n+                        spacing: Alone,\n+                        span: #24 bytes(467..468),\n+                    },\n+                    Literal {\n+                        kind: Integer,\n+                        symbol: \"0\",\n+                        suffix: None,\n+                        span: #24 bytes(469..470),\n+                    },\n+                ],\n+                span: #24 bytes(448..472),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: #24 bytes(472..473),\n+            },\n+        ],\n+        span: #24 bytes(430..483),\n+    },\n+]"}]}