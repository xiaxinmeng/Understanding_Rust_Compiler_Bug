{"sha": "257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI1N2E3M2NlODI3M2QwMjZmMmFmMWE1MDIxYWUyZDFhNGU3Yjk1ZTU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-05-22T00:31:29Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-05-22T00:31:29Z"}, "message": "auto merge of #14301 : alexcrichton/rust/remove-unsafe-arc, r=brson\n\nThis type can be built with `Arc<Unsafe<T>>` now that liballoc exists.", "tree": {"sha": "2f7d66fc0f7de80105252babe27757e7ea94951a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2f7d66fc0f7de80105252babe27757e7ea94951a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "html_url": "https://github.com/rust-lang/rust/commit/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5f3f0918ad70cd9b0bfcd2f93aea0218ec92fb87", "url": "https://api.github.com/repos/rust-lang/rust/commits/5f3f0918ad70cd9b0bfcd2f93aea0218ec92fb87", "html_url": "https://github.com/rust-lang/rust/commit/5f3f0918ad70cd9b0bfcd2f93aea0218ec92fb87"}, {"sha": "fdf935a5249edd0be0f14385a099963e43c7a29b", "url": "https://api.github.com/repos/rust-lang/rust/commits/fdf935a5249edd0be0f14385a099963e43c7a29b", "html_url": "https://github.com/rust-lang/rust/commit/fdf935a5249edd0be0f14385a099963e43c7a29b"}], "stats": {"total": 757, "additions": 280, "deletions": 477}, "files": [{"sha": "1ebebbe555e8bd5ae74c899ebc945f9dd502a7bf", "filename": "src/libgreen/basic.rs", "status": "modified", "additions": 19, "deletions": 33, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Fbasic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Fbasic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fbasic.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -15,6 +15,8 @@\n //! This implementation is also used as the fallback implementation of an event\n //! loop if no other one is provided (and M:N scheduling is desired).\n \n+use alloc::arc::Arc;\n+use std::sync::atomics;\n use std::mem;\n use std::rt::rtio::{EventLoop, IoFactory, RemoteCallback};\n use std::rt::rtio::{PausableIdleCallback, Callback};\n@@ -27,10 +29,11 @@ pub fn event_loop() -> Box<EventLoop:Send> {\n \n struct BasicLoop {\n     work: Vec<proc():Send>,             // pending work\n-    idle: Option<*mut BasicPausable>, // only one is allowed\n     remotes: Vec<(uint, Box<Callback:Send>)>,\n     next_remote: uint,\n     messages: Exclusive<Vec<Message>>,\n+    idle: Option<Box<Callback:Send>>,\n+    idle_active: Option<Arc<atomics::AtomicBool>>,\n }\n \n enum Message { RunRemote(uint), RemoveRemote(uint) }\n@@ -40,6 +43,7 @@ impl BasicLoop {\n         BasicLoop {\n             work: vec![],\n             idle: None,\n+            idle_active: None,\n             next_remote: 0,\n             remotes: vec![],\n             messages: Exclusive::new(vec![]),\n@@ -92,20 +96,18 @@ impl BasicLoop {\n \n     /// Run the idle callback if one is registered\n     fn idle(&mut self) {\n-        unsafe {\n-            match self.idle {\n-                Some(idle) => {\n-                    if (*idle).active {\n-                        (*idle).work.call();\n-                    }\n+        match self.idle {\n+            Some(ref mut idle) => {\n+                if self.idle_active.get_ref().load(atomics::SeqCst) {\n+                    idle.call();\n                 }\n-                None => {}\n             }\n+            None => {}\n         }\n     }\n \n     fn has_idle(&self) -> bool {\n-        unsafe { self.idle.is_some() && (**self.idle.get_ref()).active }\n+        self.idle.is_some() && self.idle_active.get_ref().load(atomics::SeqCst)\n     }\n }\n \n@@ -141,13 +143,11 @@ impl EventLoop for BasicLoop {\n     // FIXME: Seems like a really weird requirement to have an event loop provide.\n     fn pausable_idle_callback(&mut self, cb: Box<Callback:Send>)\n                               -> Box<PausableIdleCallback:Send> {\n-        let callback = box BasicPausable::new(self, cb);\n         rtassert!(self.idle.is_none());\n-        unsafe {\n-            let cb_ptr: &*mut BasicPausable = mem::transmute(&callback);\n-            self.idle = Some(*cb_ptr);\n-        }\n-        callback as Box<PausableIdleCallback:Send>\n+        self.idle = Some(cb);\n+        let a = Arc::new(atomics::AtomicBool::new(true));\n+        self.idle_active = Some(a.clone());\n+        box BasicPausable { active: a } as Box<PausableIdleCallback:Send>\n     }\n \n     fn remote_callback(&mut self, f: Box<Callback:Send>)\n@@ -196,35 +196,21 @@ impl Drop for BasicRemote {\n }\n \n struct BasicPausable {\n-    eloop: *mut BasicLoop,\n-    work: Box<Callback:Send>,\n-    active: bool,\n-}\n-\n-impl BasicPausable {\n-    fn new(eloop: &mut BasicLoop, cb: Box<Callback:Send>) -> BasicPausable {\n-        BasicPausable {\n-            active: false,\n-            work: cb,\n-            eloop: eloop,\n-        }\n-    }\n+    active: Arc<atomics::AtomicBool>,\n }\n \n impl PausableIdleCallback for BasicPausable {\n     fn pause(&mut self) {\n-        self.active = false;\n+        self.active.store(false, atomics::SeqCst);\n     }\n     fn resume(&mut self) {\n-        self.active = true;\n+        self.active.store(true, atomics::SeqCst);\n     }\n }\n \n impl Drop for BasicPausable {\n     fn drop(&mut self) {\n-        unsafe {\n-            (*self.eloop).idle = None;\n-        }\n+        self.active.store(false, atomics::SeqCst);\n     }\n }\n "}, {"sha": "39b6485716315171827904db4b1307c642ee3df1", "filename": "src/libgreen/lib.rs", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Flib.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -214,7 +214,9 @@\n #[cfg(test)] extern crate rustuv;\n extern crate rand;\n extern crate libc;\n+extern crate alloc;\n \n+use alloc::arc::Arc;\n use std::mem::replace;\n use std::os;\n use std::rt::rtio;\n@@ -223,7 +225,6 @@ use std::rt;\n use std::sync::atomics::{SeqCst, AtomicUint, INIT_ATOMIC_UINT};\n use std::sync::deque;\n use std::task::TaskOpts;\n-use std::sync::arc::UnsafeArc;\n \n use sched::{Shutdown, Scheduler, SchedHandle, TaskFromFriend, NewNeighbor};\n use sleeper_list::SleeperList;\n@@ -375,7 +376,7 @@ pub struct SchedPool {\n /// sending on a channel once the entire pool has been drained of all tasks.\n #[deriving(Clone)]\n struct TaskState {\n-    cnt: UnsafeArc<AtomicUint>,\n+    cnt: Arc<AtomicUint>,\n     done: Sender<()>,\n }\n \n@@ -434,7 +435,6 @@ impl SchedPool {\n                                             pool.sleepers.clone(),\n                                             pool.task_state.clone());\n             pool.handles.push(sched.make_handle());\n-            let sched = sched;\n             pool.threads.push(Thread::start(proc() { sched.bootstrap(); }));\n         }\n \n@@ -496,7 +496,6 @@ impl SchedPool {\n                                         self.task_state.clone());\n         let ret = sched.make_handle();\n         self.handles.push(sched.make_handle());\n-        let sched = sched;\n         self.threads.push(Thread::start(proc() { sched.bootstrap() }));\n \n         return ret;\n@@ -537,21 +536,21 @@ impl TaskState {\n     fn new() -> (Receiver<()>, TaskState) {\n         let (tx, rx) = channel();\n         (rx, TaskState {\n-            cnt: UnsafeArc::new(AtomicUint::new(0)),\n+            cnt: Arc::new(AtomicUint::new(0)),\n             done: tx,\n         })\n     }\n \n     fn increment(&mut self) {\n-        unsafe { (*self.cnt.get()).fetch_add(1, SeqCst); }\n+        self.cnt.fetch_add(1, SeqCst);\n     }\n \n     fn active(&self) -> bool {\n-        unsafe { (*self.cnt.get()).load(SeqCst) != 0 }\n+        self.cnt.load(SeqCst) != 0\n     }\n \n     fn decrement(&mut self) {\n-        let prev = unsafe { (*self.cnt.get()).fetch_sub(1, SeqCst) };\n+        let prev = self.cnt.fetch_sub(1, SeqCst);\n         if prev == 1 {\n             self.done.send(());\n         }"}, {"sha": "137c493364520e3f3440df88c905c26c105a0895", "filename": "src/libgreen/message_queue.rs", "status": "modified", "additions": 16, "deletions": 12, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Fmessage_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Fmessage_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fmessage_queue.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -8,8 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use alloc::arc::Arc;\n use mpsc = std::sync::mpsc_queue;\n-use std::sync::arc::UnsafeArc;\n+use std::kinds::marker;\n \n pub enum PopResult<T> {\n     Inconsistent,\n@@ -18,29 +19,32 @@ pub enum PopResult<T> {\n }\n \n pub fn queue<T: Send>() -> (Consumer<T>, Producer<T>) {\n-    let (a, b) = UnsafeArc::new2(mpsc::Queue::new());\n-    (Consumer { inner: a }, Producer { inner: b })\n+    let a = Arc::new(mpsc::Queue::new());\n+    (Consumer { inner: a.clone(), noshare: marker::NoShare },\n+     Producer { inner: a, noshare: marker::NoShare })\n }\n \n pub struct Producer<T> {\n-    inner: UnsafeArc<mpsc::Queue<T>>,\n+    inner: Arc<mpsc::Queue<T>>,\n+    noshare: marker::NoShare,\n }\n \n pub struct Consumer<T> {\n-    inner: UnsafeArc<mpsc::Queue<T>>,\n+    inner: Arc<mpsc::Queue<T>>,\n+    noshare: marker::NoShare,\n }\n \n impl<T: Send> Consumer<T> {\n-    pub fn pop(&mut self) -> PopResult<T> {\n-        match unsafe { (*self.inner.get()).pop() } {\n+    pub fn pop(&self) -> PopResult<T> {\n+        match self.inner.pop() {\n             mpsc::Inconsistent => Inconsistent,\n             mpsc::Empty => Empty,\n             mpsc::Data(t) => Data(t),\n         }\n     }\n \n-    pub fn casual_pop(&mut self) -> Option<T> {\n-        match unsafe { (*self.inner.get()).pop() } {\n+    pub fn casual_pop(&self) -> Option<T> {\n+        match self.inner.pop() {\n             mpsc::Inconsistent => None,\n             mpsc::Empty => None,\n             mpsc::Data(t) => Some(t),\n@@ -49,13 +53,13 @@ impl<T: Send> Consumer<T> {\n }\n \n impl<T: Send> Producer<T> {\n-    pub fn push(&mut self, t: T) {\n-        unsafe { (*self.inner.get()).push(t); }\n+    pub fn push(&self, t: T) {\n+        self.inner.push(t);\n     }\n }\n \n impl<T: Send> Clone for Producer<T> {\n     fn clone(&self) -> Producer<T> {\n-        Producer { inner: self.inner.clone() }\n+        Producer { inner: self.inner.clone(), noshare: marker::NoShare }\n     }\n }"}, {"sha": "d28e74a2b80b7c14d823c5a4175b822c43f5a76d", "filename": "src/libgreen/sched.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -1142,7 +1142,7 @@ mod test {\n \n         Thread::start(proc() {\n             let sleepers = SleeperList::new();\n-            let mut pool = BufferPool::new();\n+            let pool = BufferPool::new();\n             let (normal_worker, normal_stealer) = pool.deque();\n             let (special_worker, special_stealer) = pool.deque();\n             let queues = vec![normal_stealer, special_stealer];"}, {"sha": "5e357ec9cca0fac9478e280e1b8b999888c382cf", "filename": "src/libnative/io/file_unix.rs", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Ffile_unix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Ffile_unix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Ffile_unix.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -10,14 +10,14 @@\n \n //! Blocking posix-based file I/O\n \n+use alloc::arc::Arc;\n use libc::{c_int, c_void};\n use libc;\n use std::c_str::CString;\n use std::io::IoError;\n use std::io;\n use std::mem;\n use std::rt::rtio;\n-use std::sync::arc::UnsafeArc;\n \n use io::{IoResult, retry, keep_going};\n \n@@ -29,7 +29,7 @@ struct Inner {\n }\n \n pub struct FileDesc {\n-    inner: UnsafeArc<Inner>\n+    inner: Arc<Inner>\n }\n \n impl FileDesc {\n@@ -42,7 +42,7 @@ impl FileDesc {\n     /// Note that all I/O operations done on this object will be *blocking*, but\n     /// they do not require the runtime to be active.\n     pub fn new(fd: fd_t, close_on_drop: bool) -> FileDesc {\n-        FileDesc { inner: UnsafeArc::new(Inner {\n+        FileDesc { inner: Arc::new(Inner {\n             fd: fd,\n             close_on_drop: close_on_drop\n         }) }\n@@ -79,11 +79,7 @@ impl FileDesc {\n         }\n     }\n \n-    pub fn fd(&self) -> fd_t {\n-        // This unsafety is fine because we're just reading off the file\n-        // descriptor, no one is modifying this.\n-        unsafe { (*self.inner.get()).fd }\n-    }\n+    pub fn fd(&self) -> fd_t { self.inner.fd }\n }\n \n impl io::Reader for FileDesc {"}, {"sha": "9693f772170093a2b72ee9cae54b5d67dd4ba3e3", "filename": "src/libnative/io/file_win32.rs", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Ffile_win32.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Ffile_win32.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Ffile_win32.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -10,17 +10,17 @@\n \n //! Blocking win32-based file I/O\n \n+use alloc::arc::Arc;\n+use libc::{c_int, c_void};\n+use libc;\n use std::c_str::CString;\n use std::io::IoError;\n use std::io;\n-use libc::{c_int, c_void};\n-use libc;\n use std::mem;\n use std::os::win32::{as_utf16_p, fill_utf16_buf_and_decode};\n use std::ptr;\n use std::rt::rtio;\n use std::str;\n-use std::sync::arc::UnsafeArc;\n use std::vec;\n \n use io::IoResult;\n@@ -33,7 +33,7 @@ struct Inner {\n }\n \n pub struct FileDesc {\n-    inner: UnsafeArc<Inner>\n+    inner: Arc<Inner>\n }\n \n impl FileDesc {\n@@ -46,7 +46,7 @@ impl FileDesc {\n     /// Note that all I/O operations done on this object will be *blocking*, but\n     /// they do not require the runtime to be active.\n     pub fn new(fd: fd_t, close_on_drop: bool) -> FileDesc {\n-        FileDesc { inner: UnsafeArc::new(Inner {\n+        FileDesc { inner: Arc::new(Inner {\n             fd: fd,\n             close_on_drop: close_on_drop\n         }) }\n@@ -85,11 +85,7 @@ impl FileDesc {\n         Ok(())\n     }\n \n-    pub fn fd(&self) -> fd_t {\n-        // This unsafety is fine because we're just reading off the file\n-        // descriptor, no one is modifying this.\n-        unsafe { (*self.inner.get()).fd }\n-    }\n+    pub fn fd(&self) -> fd_t { self.inner.fd }\n \n     pub fn handle(&self) -> libc::HANDLE {\n         unsafe { libc::get_osfhandle(self.fd()) as libc::HANDLE }"}, {"sha": "cacd38c2efde31143e66ceb53b58c022d0e81cf2", "filename": "src/libnative/io/net.rs", "status": "modified", "additions": 9, "deletions": 15, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Fnet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Fnet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Fnet.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -8,12 +8,12 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use alloc::arc::Arc;\n use libc;\n use std::io::net::ip;\n use std::io;\n use std::mem;\n use std::rt::rtio;\n-use std::sync::arc::UnsafeArc;\n use std::unstable::mutex;\n \n use super::{IoResult, retry, keep_going};\n@@ -235,7 +235,7 @@ pub fn init() {\n ////////////////////////////////////////////////////////////////////////////////\n \n pub struct TcpStream {\n-    inner: UnsafeArc<Inner>,\n+    inner: Arc<Inner>,\n     read_deadline: u64,\n     write_deadline: u64,\n }\n@@ -282,16 +282,13 @@ impl TcpStream {\n \n     fn new(inner: Inner) -> TcpStream {\n         TcpStream {\n-            inner: UnsafeArc::new(inner),\n+            inner: Arc::new(inner),\n             read_deadline: 0,\n             write_deadline: 0,\n         }\n     }\n \n-    pub fn fd(&self) -> sock_t {\n-        // This unsafety is fine because it's just a read-only arc\n-        unsafe { (*self.inner.get()).fd }\n-    }\n+    pub fn fd(&self) -> sock_t { self.inner.fd }\n \n     fn set_nodelay(&mut self, nodelay: bool) -> IoResult<()> {\n         setsockopt(self.fd(), libc::IPPROTO_TCP, libc::TCP_NODELAY,\n@@ -329,7 +326,7 @@ impl TcpStream {\n     fn lock_nonblocking<'a>(&'a self) -> Guard<'a> {\n         let ret = Guard {\n             fd: self.fd(),\n-            guard: unsafe { (*self.inner.get()).lock.lock() },\n+            guard: unsafe { self.inner.lock.lock() },\n         };\n         assert!(util::set_nonblocking(self.fd(), true).is_ok());\n         ret\n@@ -536,7 +533,7 @@ impl rtio::RtioTcpAcceptor for TcpAcceptor {\n ////////////////////////////////////////////////////////////////////////////////\n \n pub struct UdpSocket {\n-    inner: UnsafeArc<Inner>,\n+    inner: Arc<Inner>,\n     read_deadline: u64,\n     write_deadline: u64,\n }\n@@ -545,7 +542,7 @@ impl UdpSocket {\n     pub fn bind(addr: ip::SocketAddr) -> IoResult<UdpSocket> {\n         let fd = try!(socket(addr, libc::SOCK_DGRAM));\n         let ret = UdpSocket {\n-            inner: UnsafeArc::new(Inner::new(fd)),\n+            inner: Arc::new(Inner::new(fd)),\n             read_deadline: 0,\n             write_deadline: 0,\n         };\n@@ -560,10 +557,7 @@ impl UdpSocket {\n         }\n     }\n \n-    pub fn fd(&self) -> sock_t {\n-        // unsafety is fine because it's just a read-only arc\n-        unsafe { (*self.inner.get()).fd }\n-    }\n+    pub fn fd(&self) -> sock_t { self.inner.fd }\n \n     pub fn set_broadcast(&mut self, on: bool) -> IoResult<()> {\n         setsockopt(self.fd(), libc::SOL_SOCKET, libc::SO_BROADCAST,\n@@ -603,7 +597,7 @@ impl UdpSocket {\n     fn lock_nonblocking<'a>(&'a self) -> Guard<'a> {\n         let ret = Guard {\n             fd: self.fd(),\n-            guard: unsafe { (*self.inner.get()).lock.lock() },\n+            guard: unsafe { self.inner.lock.lock() },\n         };\n         assert!(util::set_nonblocking(self.fd(), true).is_ok());\n         ret"}, {"sha": "a53a58b6cec434ddc2ad2ad11c930675062d849a", "filename": "src/libnative/io/pipe_unix.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Fpipe_unix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Fpipe_unix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Fpipe_unix.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -8,13 +8,13 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use alloc::arc::Arc;\n use libc;\n use std::c_str::CString;\n use std::intrinsics;\n use std::io;\n use std::mem;\n use std::rt::rtio;\n-use std::sync::arc::UnsafeArc;\n use std::unstable::mutex;\n \n use super::{IoResult, retry};\n@@ -108,7 +108,7 @@ fn bind(addr: &CString, ty: libc::c_int) -> IoResult<Inner> {\n ////////////////////////////////////////////////////////////////////////////////\n \n pub struct UnixStream {\n-    inner: UnsafeArc<Inner>,\n+    inner: Arc<Inner>,\n     read_deadline: u64,\n     write_deadline: u64,\n }\n@@ -117,19 +117,19 @@ impl UnixStream {\n     pub fn connect(addr: &CString,\n                    timeout: Option<u64>) -> IoResult<UnixStream> {\n         connect(addr, libc::SOCK_STREAM, timeout).map(|inner| {\n-            UnixStream::new(UnsafeArc::new(inner))\n+            UnixStream::new(Arc::new(inner))\n         })\n     }\n \n-    fn new(inner: UnsafeArc<Inner>) -> UnixStream {\n+    fn new(inner: Arc<Inner>) -> UnixStream {\n         UnixStream {\n             inner: inner,\n             read_deadline: 0,\n             write_deadline: 0,\n         }\n     }\n \n-    fn fd(&self) -> fd_t { unsafe { (*self.inner.get()).fd } }\n+    fn fd(&self) -> fd_t { self.inner.fd }\n \n     #[cfg(target_os = \"linux\")]\n     fn lock_nonblocking(&self) {}\n@@ -138,7 +138,7 @@ impl UnixStream {\n     fn lock_nonblocking<'a>(&'a self) -> net::Guard<'a> {\n         let ret = net::Guard {\n             fd: self.fd(),\n-            guard: unsafe { (*self.inner.get()).lock.lock() },\n+            guard: unsafe { self.inner.lock.lock() },\n         };\n         assert!(util::set_nonblocking(self.fd(), true).is_ok());\n         ret\n@@ -254,7 +254,7 @@ impl UnixAcceptor {\n                          &mut size as *mut libc::socklen_t) as libc::c_int\n         }) {\n             -1 => Err(super::last_error()),\n-            fd => Ok(UnixStream::new(UnsafeArc::new(Inner::new(fd))))\n+            fd => Ok(UnixStream::new(Arc::new(Inner::new(fd))))\n         }\n     }\n }"}, {"sha": "cd4cbf2c90f32e79f9971e37e6eca3de8d5d20a4", "filename": "src/libnative/io/pipe_win32.rs", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Fpipe_win32.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Fio%2Fpipe_win32.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Fpipe_win32.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -84,6 +84,7 @@\n //! the test suite passing (the suite is in libstd), and that's good enough for\n //! me!\n \n+use alloc::arc::Arc;\n use libc;\n use std::c_str::CString;\n use std::io;\n@@ -92,7 +93,6 @@ use std::os::win32::as_utf16_p;\n use std::os;\n use std::ptr;\n use std::rt::rtio;\n-use std::sync::arc::UnsafeArc;\n use std::sync::atomics;\n use std::unstable::mutex;\n \n@@ -195,7 +195,7 @@ pub fn await(handle: libc::HANDLE, deadline: u64,\n ////////////////////////////////////////////////////////////////////////////////\n \n pub struct UnixStream {\n-    inner: UnsafeArc<Inner>,\n+    inner: Arc<Inner>,\n     write: Option<Event>,\n     read: Option<Event>,\n     read_deadline: u64,\n@@ -273,7 +273,7 @@ impl UnixStream {\n                             Err(super::last_error())\n                         } else {\n                             Ok(UnixStream {\n-                                inner: UnsafeArc::new(inner),\n+                                inner: Arc::new(inner),\n                                 read: None,\n                                 write: None,\n                                 read_deadline: 0,\n@@ -317,14 +317,14 @@ impl UnixStream {\n         })\n     }\n \n-    fn handle(&self) -> libc::HANDLE { unsafe { (*self.inner.get()).handle } }\n+    fn handle(&self) -> libc::HANDLE { self.inner.handle }\n \n     fn read_closed(&self) -> bool {\n-        unsafe { (*self.inner.get()).read_closed.load(atomics::SeqCst) }\n+        self.inner.read_closed.load(atomics::SeqCst)\n     }\n \n     fn write_closed(&self) -> bool {\n-        unsafe { (*self.inner.get()).write_closed.load(atomics::SeqCst) }\n+        self.inner.write_closed.load(atomics::SeqCst)\n     }\n \n     fn cancel_io(&self) -> IoResult<()> {\n@@ -353,7 +353,7 @@ impl rtio::RtioPipe for UnixStream {\n         // acquire the lock.\n         //\n         // See comments in close_read() about why this lock is necessary.\n-        let guard = unsafe { (*self.inner.get()).lock.lock() };\n+        let guard = unsafe { self.inner.lock.lock() };\n         if self.read_closed() {\n             return Err(io::standard_error(io::EndOfFile))\n         }\n@@ -429,7 +429,7 @@ impl rtio::RtioPipe for UnixStream {\n             // going after we woke up.\n             //\n             // See comments in close_read() about why this lock is necessary.\n-            let guard = unsafe { (*self.inner.get()).lock.lock() };\n+            let guard = unsafe { self.inner.lock.lock() };\n             if self.write_closed() {\n                 return Err(io::standard_error(io::BrokenPipe))\n             }\n@@ -514,15 +514,15 @@ impl rtio::RtioPipe for UnixStream {\n         // close_read() between steps 1 and 2. By atomically executing steps 1\n         // and 2 with a lock with respect to close_read(), we're guaranteed that\n         // no thread will erroneously sit in a read forever.\n-        let _guard = unsafe { (*self.inner.get()).lock.lock() };\n-        unsafe { (*self.inner.get()).read_closed.store(true, atomics::SeqCst) }\n+        let _guard = unsafe { self.inner.lock.lock() };\n+        self.inner.read_closed.store(true, atomics::SeqCst);\n         self.cancel_io()\n     }\n \n     fn close_write(&mut self) -> IoResult<()> {\n         // see comments in close_read() for why this lock is necessary\n-        let _guard = unsafe { (*self.inner.get()).lock.lock() };\n-        unsafe { (*self.inner.get()).write_closed.store(true, atomics::SeqCst) }\n+        let _guard = unsafe { self.inner.lock.lock() };\n+        self.inner.write_closed.store(true, atomics::SeqCst);\n         self.cancel_io()\n     }\n \n@@ -683,7 +683,7 @@ impl UnixAcceptor {\n \n         // Transfer ownership of our handle into this stream\n         Ok(UnixStream {\n-            inner: UnsafeArc::new(Inner::new(handle)),\n+            inner: Arc::new(Inner::new(handle)),\n             read: None,\n             write: None,\n             read_deadline: 0,"}, {"sha": "634bf1dcedb07a2069143de8ac7977edc01fd48e", "filename": "src/libnative/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibnative%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Flib.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -57,6 +57,7 @@\n //    answer is that you don't need them)\n #![feature(macro_rules)]\n \n+extern crate alloc;\n extern crate libc;\n \n use std::os;"}, {"sha": "63d9aa7ead0a0a22c96a53a8cb1751865d3ec131", "filename": "src/librustuv/access.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Faccess.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Faccess.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Faccess.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -14,15 +14,16 @@\n /// It is assumed that all invocations of this struct happen on the same thread\n /// (the uv event loop).\n \n+use alloc::arc::Arc;\n use std::mem;\n use std::rt::local::Local;\n use std::rt::task::{BlockedTask, Task};\n-use std::sync::arc::UnsafeArc;\n+use std::ty::Unsafe;\n \n use homing::HomingMissile;\n \n pub struct Access {\n-    inner: UnsafeArc<Inner>,\n+    inner: Arc<Unsafe<Inner>>,\n }\n \n pub struct Guard<'a> {\n@@ -39,11 +40,11 @@ struct Inner {\n impl Access {\n     pub fn new() -> Access {\n         Access {\n-            inner: UnsafeArc::new(Inner {\n+            inner: Arc::new(Unsafe::new(Inner {\n                 queue: vec![],\n                 held: false,\n                 closed: false,\n-            })\n+            }))\n         }\n     }\n "}, {"sha": "0a6a305a3b78084c9d7a2ae4471a33c4e7ebc0d8", "filename": "src/librustuv/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Flib.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -46,6 +46,7 @@ via `close` and `delete` methods.\n #[cfg(test)] extern crate green;\n #[cfg(test)] extern crate realrustuv = \"rustuv\";\n extern crate libc;\n+extern crate alloc;\n \n use libc::{c_int, c_void};\n use std::fmt;"}, {"sha": "98ae865cb1da32c440c52d1aa8509b2e5d7057d0", "filename": "src/librustuv/queue.rs", "status": "modified", "additions": 13, "deletions": 20, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Fqueue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Fqueue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fqueue.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -20,10 +20,10 @@\n \n #![allow(dead_code)]\n \n+use alloc::arc::Arc;\n use libc::c_void;\n use std::mem;\n use std::rt::task::BlockedTask;\n-use std::sync::arc::UnsafeArc;\n use std::unstable::mutex::NativeMutex;\n use mpsc = std::sync::mpsc_queue;\n \n@@ -46,20 +46,20 @@ struct State {\n /// This structure is intended to be stored next to the event loop, and it is\n /// used to create new `Queue` structures.\n pub struct QueuePool {\n-    queue: UnsafeArc<State>,\n+    queue: Arc<State>,\n     refcnt: uint,\n }\n \n /// This type is used to send messages back to the original event loop.\n pub struct Queue {\n-    queue: UnsafeArc<State>,\n+    queue: Arc<State>,\n }\n \n extern fn async_cb(handle: *uvll::uv_async_t) {\n     let pool: &mut QueuePool = unsafe {\n         mem::transmute(uvll::get_data_for_uv_handle(handle))\n     };\n-    let state: &mut State = unsafe { mem::transmute(pool.queue.get()) };\n+    let state: &State = &*pool.queue;\n \n     // Remember that there is no guarantee about how many times an async\n     // callback is called with relation to the number of sends, so process the\n@@ -109,7 +109,7 @@ extern fn async_cb(handle: *uvll::uv_async_t) {\n impl QueuePool {\n     pub fn new(loop_: &mut Loop) -> Box<QueuePool> {\n         let handle = UvHandle::alloc(None::<AsyncWatcher>, uvll::UV_ASYNC);\n-        let state = UnsafeArc::new(State {\n+        let state = Arc::new(State {\n             handle: handle,\n             lock: unsafe {NativeMutex::new()},\n             queue: mpsc::Queue::new(),\n@@ -132,24 +132,20 @@ impl QueuePool {\n     pub fn queue(&mut self) -> Queue {\n         unsafe {\n             if self.refcnt == 0 {\n-                uvll::uv_ref((*self.queue.get()).handle);\n+                uvll::uv_ref(self.queue.handle);\n             }\n             self.refcnt += 1;\n         }\n         Queue { queue: self.queue.clone() }\n     }\n \n-    pub fn handle(&self) -> *uvll::uv_async_t {\n-        unsafe { (*self.queue.get()).handle }\n-    }\n+    pub fn handle(&self) -> *uvll::uv_async_t { self.queue.handle }\n }\n \n impl Queue {\n     pub fn push(&mut self, task: BlockedTask) {\n-        unsafe {\n-            (*self.queue.get()).queue.push(Task(task));\n-            uvll::uv_async_send((*self.queue.get()).handle);\n-        }\n+        self.queue.queue.push(Task(task));\n+        unsafe { uvll::uv_async_send(self.queue.handle); }\n     }\n }\n \n@@ -160,9 +156,7 @@ impl Clone for Queue {\n         // that the count is at least one (because we have a queue right here),\n         // and if the queue is dropped later on it'll see the increment for the\n         // decrement anyway.\n-        unsafe {\n-            (*self.queue.get()).queue.push(Increment);\n-        }\n+        self.queue.queue.push(Increment);\n         Queue { queue: self.queue.clone() }\n     }\n }\n@@ -172,10 +166,9 @@ impl Drop for Queue {\n         // See the comments in the async_cb function for why there is a lock\n         // that is acquired only on a drop.\n         unsafe {\n-            let state = self.queue.get();\n-            let _l = (*state).lock.lock();\n-            (*state).queue.push(Decrement);\n-            uvll::uv_async_send((*state).handle);\n+            let _l = self.queue.lock.lock();\n+            self.queue.queue.push(Decrement);\n+            uvll::uv_async_send(self.queue.handle);\n         }\n     }\n }"}, {"sha": "2a1a6b9f26d474fa2e07364dff65bd8b76cbf92f", "filename": "src/librustuv/rc.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Frc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibrustuv%2Frc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Frc.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -16,16 +16,17 @@\n /// the same underlying uv object, hence Rc is not used and this simple counter\n /// should suffice.\n \n-use std::sync::arc::UnsafeArc;\n+use alloc::arc::Arc;\n+use std::ty::Unsafe;\n \n pub struct Refcount {\n-    rc: UnsafeArc<uint>,\n+    rc: Arc<Unsafe<uint>>,\n }\n \n impl Refcount {\n     /// Creates a new refcount of 1\n     pub fn new() -> Refcount {\n-        Refcount { rc: UnsafeArc::new(1) }\n+        Refcount { rc: Arc::new(Unsafe::new(1)) }\n     }\n \n     fn increment(&self) {"}, {"sha": "fd5b92ba46913e26fe3468c16a62d45294925ad0", "filename": "src/libstd/comm/mod.rs", "status": "modified", "additions": 27, "deletions": 22, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fcomm%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fcomm%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fmod.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -271,6 +271,8 @@\n // And now that you've seen all the races that I found and attempted to fix,\n // here's the code for you to find some more!\n \n+use alloc::arc::Arc;\n+\n use cell::Cell;\n use clone::Clone;\n use iter::Iterator;\n@@ -283,7 +285,6 @@ use owned::Box;\n use result::{Ok, Err, Result};\n use rt::local::Local;\n use rt::task::{Task, BlockedTask};\n-use sync::arc::UnsafeArc;\n use ty::Unsafe;\n \n pub use comm::select::{Select, Handle};\n@@ -352,7 +353,7 @@ pub struct Sender<T> {\n /// The sending-half of Rust's synchronous channel type. This half can only be\n /// owned by one task, but it can be cloned to send to other tasks.\n pub struct SyncSender<T> {\n-    inner: UnsafeArc<sync::Packet<T>>,\n+    inner: Arc<Unsafe<sync::Packet<T>>>,\n     // can't share in an arc\n     marker: marker::NoShare,\n }\n@@ -386,10 +387,10 @@ pub enum TrySendError<T> {\n }\n \n enum Flavor<T> {\n-    Oneshot(UnsafeArc<oneshot::Packet<T>>),\n-    Stream(UnsafeArc<stream::Packet<T>>),\n-    Shared(UnsafeArc<shared::Packet<T>>),\n-    Sync(UnsafeArc<sync::Packet<T>>),\n+    Oneshot(Arc<Unsafe<oneshot::Packet<T>>>),\n+    Stream(Arc<Unsafe<stream::Packet<T>>>),\n+    Shared(Arc<Unsafe<shared::Packet<T>>>),\n+    Sync(Arc<Unsafe<sync::Packet<T>>>),\n }\n \n #[doc(hidden)]\n@@ -435,8 +436,8 @@ impl<T> UnsafeFlavor<T> for Receiver<T> {\n /// println!(\"{}\", rx.recv());\n /// ```\n pub fn channel<T: Send>() -> (Sender<T>, Receiver<T>) {\n-    let (a, b) = UnsafeArc::new2(oneshot::Packet::new());\n-    (Sender::new(Oneshot(b)), Receiver::new(Oneshot(a)))\n+    let a = Arc::new(Unsafe::new(oneshot::Packet::new()));\n+    (Sender::new(Oneshot(a.clone())), Receiver::new(Oneshot(a)))\n }\n \n /// Creates a new synchronous, bounded channel.\n@@ -471,8 +472,8 @@ pub fn channel<T: Send>() -> (Sender<T>, Receiver<T>) {\n /// assert_eq!(rx.recv(), 2);\n /// ```\n pub fn sync_channel<T: Send>(bound: uint) -> (SyncSender<T>, Receiver<T>) {\n-    let (a, b) = UnsafeArc::new2(sync::Packet::new(bound));\n-    (SyncSender::new(a), Receiver::new(Sync(b)))\n+    let a = Arc::new(Unsafe::new(sync::Packet::new(bound)));\n+    (SyncSender::new(a.clone()), Receiver::new(Sync(a)))\n }\n \n ////////////////////////////////////////////////////////////////////////////////\n@@ -557,13 +558,13 @@ impl<T: Send> Sender<T> {\n \n         let (new_inner, ret) = match *unsafe { self.inner() } {\n             Oneshot(ref p) => {\n-                let p = p.get();\n                 unsafe {\n+                    let p = p.get();\n                     if !(*p).sent() {\n                         return (*p).send(t);\n                     } else {\n-                        let (a, b) = UnsafeArc::new2(stream::Packet::new());\n-                        match (*p).upgrade(Receiver::new(Stream(b))) {\n+                        let a = Arc::new(Unsafe::new(stream::Packet::new()));\n+                        match (*p).upgrade(Receiver::new(Stream(a.clone()))) {\n                             oneshot::UpSuccess => {\n                                 let ret = (*a.get()).send(t);\n                                 (a, ret)\n@@ -598,17 +599,21 @@ impl<T: Send> Clone for Sender<T> {\n     fn clone(&self) -> Sender<T> {\n         let (packet, sleeper) = match *unsafe { self.inner() } {\n             Oneshot(ref p) => {\n-                let (a, b) = UnsafeArc::new2(shared::Packet::new());\n-                match unsafe { (*p.get()).upgrade(Receiver::new(Shared(a))) } {\n-                    oneshot::UpSuccess | oneshot::UpDisconnected => (b, None),\n-                    oneshot::UpWoke(task) => (b, Some(task))\n+                let a = Arc::new(Unsafe::new(shared::Packet::new()));\n+                match unsafe {\n+                    (*p.get()).upgrade(Receiver::new(Shared(a.clone())))\n+                } {\n+                    oneshot::UpSuccess | oneshot::UpDisconnected => (a, None),\n+                    oneshot::UpWoke(task) => (a, Some(task))\n                 }\n             }\n             Stream(ref p) => {\n-                let (a, b) = UnsafeArc::new2(shared::Packet::new());\n-                match unsafe { (*p.get()).upgrade(Receiver::new(Shared(a))) } {\n-                    stream::UpSuccess | stream::UpDisconnected => (b, None),\n-                    stream::UpWoke(task) => (b, Some(task)),\n+                let a = Arc::new(Unsafe::new(shared::Packet::new()));\n+                match unsafe {\n+                    (*p.get()).upgrade(Receiver::new(Shared(a.clone())))\n+                } {\n+                    stream::UpSuccess | stream::UpDisconnected => (a, None),\n+                    stream::UpWoke(task) => (a, Some(task)),\n                 }\n             }\n             Shared(ref p) => {\n@@ -645,7 +650,7 @@ impl<T: Send> Drop for Sender<T> {\n ////////////////////////////////////////////////////////////////////////////////\n \n impl<T: Send> SyncSender<T> {\n-    fn new(inner: UnsafeArc<sync::Packet<T>>) -> SyncSender<T> {\n+    fn new(inner: Arc<Unsafe<sync::Packet<T>>>) -> SyncSender<T> {\n         SyncSender { inner: inner, marker: marker::NoShare }\n     }\n "}, {"sha": "f9e8fd1e534bfca0815c67d746e6e676546fa6ee", "filename": "src/libstd/comm/oneshot.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fcomm%2Foneshot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fcomm%2Foneshot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Foneshot.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -15,7 +15,7 @@\n /// this type is to have one and exactly one allocation when the chan/port pair\n /// is created.\n ///\n-/// Another possible optimization would be to not use an UnsafeArc box because\n+/// Another possible optimization would be to not use an Arc box because\n /// in theory we know when the shared packet can be deallocated (no real need\n /// for the atomic reference counting), but I was having trouble how to destroy\n /// the data early in a drop of a Port."}, {"sha": "8968747d9908e53e974f6119163b5e3884c8659f", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -13,6 +13,8 @@\n //! local storage, and logging. Even a 'freestanding' Rust would likely want\n //! to implement this.\n \n+use alloc::arc::Arc;\n+\n use cleanup;\n use clone::Clone;\n use comm::Sender;\n@@ -32,7 +34,6 @@ use rt::local_heap::LocalHeap;\n use rt::rtio::LocalIo;\n use rt::unwind::Unwinder;\n use str::SendStr;\n-use sync::arc::UnsafeArc;\n use sync::atomics::{AtomicUint, SeqCst};\n use task::{TaskResult, TaskOpts};\n use unstable::finally::Finally;\n@@ -65,7 +66,7 @@ pub struct LocalStorage(pub Option<local_data::Map>);\n /// at any time.\n pub enum BlockedTask {\n     Owned(Box<Task>),\n-    Shared(UnsafeArc<AtomicUint>),\n+    Shared(Arc<AtomicUint>),\n }\n \n pub enum DeathAction {\n@@ -82,7 +83,7 @@ pub struct Death {\n }\n \n pub struct BlockedTasks {\n-    inner: UnsafeArc<AtomicUint>,\n+    inner: Arc<AtomicUint>,\n }\n \n impl Task {\n@@ -313,10 +314,10 @@ impl BlockedTask {\n     pub fn wake(self) -> Option<Box<Task>> {\n         match self {\n             Owned(task) => Some(task),\n-            Shared(arc) => unsafe {\n-                match (*arc.get()).swap(0, SeqCst) {\n+            Shared(arc) => {\n+                match arc.swap(0, SeqCst) {\n                     0 => None,\n-                    n => Some(mem::transmute(n)),\n+                    n => Some(unsafe { mem::transmute(n) }),\n                 }\n             }\n         }\n@@ -343,7 +344,7 @@ impl BlockedTask {\n         let arc = match self {\n             Owned(task) => {\n                 let flag = unsafe { AtomicUint::new(mem::transmute(task)) };\n-                UnsafeArc::new(flag)\n+                Arc::new(flag)\n             }\n             Shared(arc) => arc.clone(),\n         };\n@@ -375,7 +376,7 @@ impl BlockedTask {\n         if blocked_task_ptr & 0x1 == 0 {\n             Owned(mem::transmute(blocked_task_ptr))\n         } else {\n-            let ptr: Box<UnsafeArc<AtomicUint>> =\n+            let ptr: Box<Arc<AtomicUint>> =\n                 mem::transmute(blocked_task_ptr & !1);\n             Shared(*ptr)\n         }"}, {"sha": "7dcfe62ffb8a673ff603773ca627b290284bdb62", "filename": "src/libstd/sync/arc.rs", "status": "removed", "additions": 0, "deletions": 189, "changes": 189, "blob_url": "https://github.com/rust-lang/rust/blob/5f3f0918ad70cd9b0bfcd2f93aea0218ec92fb87/src%2Flibstd%2Fsync%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5f3f0918ad70cd9b0bfcd2f93aea0218ec92fb87/src%2Flibstd%2Fsync%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Farc.rs?ref=5f3f0918ad70cd9b0bfcd2f93aea0218ec92fb87", "patch": "@@ -1,189 +0,0 @@\n-// Copyright 2013-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Atomically reference counted data\n-//!\n-//! This modules contains the implementation of an atomically reference counted\n-//! pointer for the purpose of sharing data between tasks. This is obviously a\n-//! very unsafe primitive to use, but it has its use cases when implementing\n-//! concurrent data structures and similar tasks.\n-//!\n-//! Great care must be taken to ensure that data races do not arise through the\n-//! usage of `UnsafeArc`, and this often requires some form of external\n-//! synchronization. The only guarantee provided to you by this class is that\n-//! the underlying data will remain valid (not free'd) so long as the reference\n-//! count is greater than one.\n-\n-use clone::Clone;\n-use iter::Iterator;\n-use kinds::Send;\n-use mem;\n-use ops::Drop;\n-use owned::Box;\n-use ptr::RawPtr;\n-use sync::atomics::{fence, AtomicUint, Relaxed, Acquire, Release};\n-use ty::Unsafe;\n-use vec::Vec;\n-\n-/// An atomically reference counted pointer.\n-///\n-/// Enforces no shared-memory safety.\n-#[unsafe_no_drop_flag]\n-pub struct UnsafeArc<T> {\n-    data: *mut ArcData<T>,\n-}\n-\n-struct ArcData<T> {\n-    count: AtomicUint,\n-    data: Unsafe<T>,\n-}\n-\n-unsafe fn new_inner<T: Send>(data: T, refcount: uint) -> *mut ArcData<T> {\n-    let data = box ArcData {\n-                    count: AtomicUint::new(refcount),\n-                    data: Unsafe::new(data)\n-                 };\n-    mem::transmute(data)\n-}\n-\n-impl<T: Send> UnsafeArc<T> {\n-    /// Creates a new `UnsafeArc` which wraps the given data.\n-    pub fn new(data: T) -> UnsafeArc<T> {\n-        unsafe { UnsafeArc { data: new_inner(data, 1) } }\n-    }\n-\n-    /// As new(), but returns an extra pre-cloned handle.\n-    pub fn new2(data: T) -> (UnsafeArc<T>, UnsafeArc<T>) {\n-        unsafe {\n-            let ptr = new_inner(data, 2);\n-            (UnsafeArc { data: ptr }, UnsafeArc { data: ptr })\n-        }\n-    }\n-\n-    /// As new(), but returns a vector of as many pre-cloned handles as\n-    /// requested.\n-    pub fn newN(data: T, num_handles: uint) -> Vec<UnsafeArc<T>> {\n-        unsafe {\n-            if num_handles == 0 {\n-                vec![] // need to free data here\n-            } else {\n-                let ptr = new_inner(data, num_handles);\n-                let v = Vec::from_fn(num_handles, |_| UnsafeArc { data: ptr });\n-                v\n-            }\n-        }\n-    }\n-\n-    /// Gets a pointer to the inner shared data. Note that care must be taken to\n-    /// ensure that the outer `UnsafeArc` does not fall out of scope while this\n-    /// pointer is in use, otherwise it could possibly contain a use-after-free.\n-    #[inline]\n-    pub fn get(&self) -> *mut T {\n-        unsafe {\n-            debug_assert!((*self.data).count.load(Relaxed) > 0);\n-            return (*self.data).data.get();\n-        }\n-    }\n-\n-    /// Gets an immutable pointer to the inner shared data. This has the same\n-    /// caveats as the `get` method.\n-    #[inline]\n-    pub fn get_immut(&self) -> *T {\n-        unsafe {\n-            debug_assert!((*self.data).count.load(Relaxed) > 0);\n-            return (*self.data).data.get() as *T;\n-        }\n-    }\n-\n-    /// checks if this is the only reference to the arc protected data\n-    #[inline]\n-    pub fn is_owned(&self) -> bool {\n-        unsafe {\n-            (*self.data).count.load(Relaxed) == 1\n-        }\n-    }\n-}\n-\n-impl<T: Send> Clone for UnsafeArc<T> {\n-    fn clone(&self) -> UnsafeArc<T> {\n-        unsafe {\n-            // Using a relaxed ordering is alright here, as knowledge of the original reference\n-            // prevents other threads from erroneously deleting the object.\n-            //\n-            // As explained in the [Boost documentation][1],\n-            //  Increasing the reference counter can always be done with memory_order_relaxed: New\n-            //  references to an object can only be formed from an existing reference, and passing\n-            //  an existing reference from one thread to another must already provide any required\n-            //  synchronization.\n-            // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n-            let old_count = (*self.data).count.fetch_add(1, Relaxed);\n-            debug_assert!(old_count >= 1);\n-            return UnsafeArc { data: self.data };\n-        }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<T> Drop for UnsafeArc<T>{\n-    fn drop(&mut self) {\n-        unsafe {\n-            // Happens when destructing an unwrapper's handle and from\n-            // `#[unsafe_no_drop_flag]`\n-            if self.data.is_null() {\n-                return\n-            }\n-            // Because `fetch_sub` is already atomic, we do not need to synchronize with other\n-            // threads unless we are going to delete the object.\n-            let old_count = (*self.data).count.fetch_sub(1, Release);\n-            debug_assert!(old_count >= 1);\n-            if old_count == 1 {\n-                // This fence is needed to prevent reordering of use of the data and deletion of\n-                // the data. Because it is marked `Release`, the decreasing of the reference count\n-                // sychronizes with this `Acquire` fence. This means that use of the data happens\n-                // before decreasing the refernce count, which happens before this fence, which\n-                // happens before the deletion of the data.\n-                //\n-                // As explained in the [Boost documentation][1],\n-                //  It is important to enforce any possible access to the object in one thread\n-                //  (through an existing reference) to *happen before* deleting the object in a\n-                //  different thread. This is achieved by a \"release\" operation after dropping a\n-                //  reference (any access to the object through this reference must obviously\n-                //  happened before), and an \"acquire\" operation before deleting the object.\n-                // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n-                fence(Acquire);\n-                let _: Box<ArcData<T>> = mem::transmute(self.data);\n-            }\n-        }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use prelude::*;\n-    use super::UnsafeArc;\n-    use mem::size_of;\n-\n-    #[test]\n-    fn test_size() {\n-        assert_eq!(size_of::<UnsafeArc<[int, ..10]>>(), size_of::<*[int, ..10]>());\n-    }\n-\n-    #[test]\n-    fn arclike_newN() {\n-        // Tests that the many-refcounts-at-once constructors don't leak.\n-        let _ = UnsafeArc::new2(\"hello\".to_owned().to_owned());\n-        let x = UnsafeArc::newN(\"hello\".to_owned().to_owned(), 0);\n-        assert_eq!(x.len(), 0)\n-        let x = UnsafeArc::newN(\"hello\".to_owned().to_owned(), 1);\n-        assert_eq!(x.len(), 1)\n-        let x = UnsafeArc::newN(\"hello\".to_owned().to_owned(), 10);\n-        assert_eq!(x.len(), 10)\n-    }\n-}"}, {"sha": "a3fdc4d3eaff7e3d4b891794574b65d8a10ff912", "filename": "src/libstd/sync/deque.rs", "status": "modified", "additions": 49, "deletions": 46, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fdeque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fdeque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fdeque.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -48,20 +48,22 @@\n // FIXME: all atomic operations in this module use a SeqCst ordering. That is\n //      probably overkill\n \n+use alloc::arc::Arc;\n+\n use clone::Clone;\n use iter::{range, Iterator};\n use kinds::Send;\n+use kinds::marker;\n use mem::{forget, min_align_of, size_of, transmute};\n use ops::Drop;\n use option::{Option, Some, None};\n use owned::Box;\n use ptr::RawPtr;\n use ptr;\n+use rt::heap::{allocate, deallocate};\n use slice::ImmutableVector;\n-use sync::arc::UnsafeArc;\n use sync::atomics::{AtomicInt, AtomicPtr, SeqCst};\n use unstable::sync::Exclusive;\n-use rt::heap::{allocate, deallocate};\n use vec::Vec;\n \n // Once the queue is less than 1/K full, then it will be downsized. Note that\n@@ -87,14 +89,16 @@ struct Deque<T> {\n ///\n /// There may only be one worker per deque.\n pub struct Worker<T> {\n-    deque: UnsafeArc<Deque<T>>,\n+    deque: Arc<Deque<T>>,\n+    noshare: marker::NoShare,\n }\n \n /// The stealing half of the work-stealing deque. Stealers have access to the\n /// opposite end of the deque from the worker, and they only have access to the\n /// `steal` method.\n pub struct Stealer<T> {\n-    deque: UnsafeArc<Deque<T>>,\n+    deque: Arc<Deque<T>>,\n+    noshare: marker::NoShare,\n }\n \n /// When stealing some data, this is an enumeration of the possible outcomes.\n@@ -149,12 +153,14 @@ impl<T: Send> BufferPool<T> {\n \n     /// Allocates a new work-stealing deque which will send/receiving memory to\n     /// and from this buffer pool.\n-    pub fn deque(&mut self) -> (Worker<T>, Stealer<T>) {\n-        let (a, b) = UnsafeArc::new2(Deque::new(self.clone()));\n-        (Worker { deque: a }, Stealer { deque: b })\n+    pub fn deque(&self) -> (Worker<T>, Stealer<T>) {\n+        let a = Arc::new(Deque::new(self.clone()));\n+        let b = a.clone();\n+        (Worker { deque: a, noshare: marker::NoShare },\n+         Stealer { deque: b, noshare: marker::NoShare })\n     }\n \n-    fn alloc(&mut self, bits: int) -> Box<Buffer<T>> {\n+    fn alloc(&self, bits: int) -> Box<Buffer<T>> {\n         unsafe {\n             self.pool.with(|pool| {\n                 match pool.iter().position(|x| x.size() >= (1 << bits)) {\n@@ -165,7 +171,7 @@ impl<T: Send> BufferPool<T> {\n         }\n     }\n \n-    fn free(&mut self, buf: Box<Buffer<T>>) {\n+    fn free(&self, buf: Box<Buffer<T>>) {\n         unsafe {\n             let mut buf = Some(buf);\n             self.pool.with(|pool| {\n@@ -185,46 +191,48 @@ impl<T: Send> Clone for BufferPool<T> {\n \n impl<T: Send> Worker<T> {\n     /// Pushes data onto the front of this work queue.\n-    pub fn push(&mut self, t: T) {\n-        unsafe { (*self.deque.get()).push(t) }\n+    pub fn push(&self, t: T) {\n+        unsafe { self.deque.push(t) }\n     }\n     /// Pops data off the front of the work queue, returning `None` on an empty\n     /// queue.\n-    pub fn pop(&mut self) -> Option<T> {\n-        unsafe { (*self.deque.get()).pop() }\n+    pub fn pop(&self) -> Option<T> {\n+        unsafe { self.deque.pop() }\n     }\n \n     /// Gets access to the buffer pool that this worker is attached to. This can\n     /// be used to create more deques which share the same buffer pool as this\n     /// deque.\n-    pub fn pool<'a>(&'a mut self) -> &'a mut BufferPool<T> {\n-        unsafe { &mut (*self.deque.get()).pool }\n+    pub fn pool<'a>(&'a self) -> &'a BufferPool<T> {\n+        &self.deque.pool\n     }\n }\n \n impl<T: Send> Stealer<T> {\n     /// Steals work off the end of the queue (opposite of the worker's end)\n-    pub fn steal(&mut self) -> Stolen<T> {\n-        unsafe { (*self.deque.get()).steal() }\n+    pub fn steal(&self) -> Stolen<T> {\n+        unsafe { self.deque.steal() }\n     }\n \n     /// Gets access to the buffer pool that this stealer is attached to. This\n     /// can be used to create more deques which share the same buffer pool as\n     /// this deque.\n-    pub fn pool<'a>(&'a mut self) -> &'a mut BufferPool<T> {\n-        unsafe { &mut (*self.deque.get()).pool }\n+    pub fn pool<'a>(&'a self) -> &'a BufferPool<T> {\n+        &self.deque.pool\n     }\n }\n \n impl<T: Send> Clone for Stealer<T> {\n-    fn clone(&self) -> Stealer<T> { Stealer { deque: self.deque.clone() } }\n+    fn clone(&self) -> Stealer<T> {\n+        Stealer { deque: self.deque.clone(), noshare: marker::NoShare }\n+    }\n }\n \n // Almost all of this code can be found directly in the paper so I'm not\n // personally going to heavily comment what's going on here.\n \n impl<T: Send> Deque<T> {\n-    fn new(mut pool: BufferPool<T>) -> Deque<T> {\n+    fn new(pool: BufferPool<T>) -> Deque<T> {\n         let buf = pool.alloc(MIN_BITS);\n         Deque {\n             bottom: AtomicInt::new(0),\n@@ -234,7 +242,7 @@ impl<T: Send> Deque<T> {\n         }\n     }\n \n-    unsafe fn push(&mut self, data: T) {\n+    unsafe fn push(&self, data: T) {\n         let mut b = self.bottom.load(SeqCst);\n         let t = self.top.load(SeqCst);\n         let mut a = self.array.load(SeqCst);\n@@ -250,7 +258,7 @@ impl<T: Send> Deque<T> {\n         self.bottom.store(b + 1, SeqCst);\n     }\n \n-    unsafe fn pop(&mut self) -> Option<T> {\n+    unsafe fn pop(&self) -> Option<T> {\n         let b = self.bottom.load(SeqCst);\n         let a = self.array.load(SeqCst);\n         let b = b - 1;\n@@ -276,7 +284,7 @@ impl<T: Send> Deque<T> {\n         }\n     }\n \n-    unsafe fn steal(&mut self) -> Stolen<T> {\n+    unsafe fn steal(&self) -> Stolen<T> {\n         let t = self.top.load(SeqCst);\n         let old = self.array.load(SeqCst);\n         let b = self.bottom.load(SeqCst);\n@@ -298,7 +306,7 @@ impl<T: Send> Deque<T> {\n         }\n     }\n \n-    unsafe fn maybe_shrink(&mut self, b: int, t: int) {\n+    unsafe fn maybe_shrink(&self, b: int, t: int) {\n         let a = self.array.load(SeqCst);\n         if b - t < (*a).size() / K && b - t > (1 << MIN_BITS) {\n             self.swap_buffer(b, a, (*a).resize(b, t, -1));\n@@ -312,7 +320,7 @@ impl<T: Send> Deque<T> {\n     // after this method has called 'free' on it. The continued usage is simply\n     // a read followed by a forget, but we must make sure that the memory can\n     // continue to be read after we flag this buffer for reclamation.\n-    unsafe fn swap_buffer(&mut self, b: int, old: *mut Buffer<T>,\n+    unsafe fn swap_buffer(&self, b: int, old: *mut Buffer<T>,\n                           buf: Buffer<T>) -> *mut Buffer<T> {\n         let newbuf: *mut Buffer<T> = transmute(box buf);\n         self.array.store(newbuf, SeqCst);\n@@ -373,7 +381,7 @@ impl<T: Send> Buffer<T> {\n \n     // Unsafe because this unsafely overwrites possibly uninitialized or\n     // initialized data.\n-    unsafe fn put(&mut self, i: int, t: T) {\n+    unsafe fn put(&self, i: int, t: T) {\n         let ptr = self.storage.offset(i & self.mask());\n         ptr::copy_nonoverlapping_memory(ptr as *mut T, &t as *T, 1);\n         forget(t);\n@@ -382,7 +390,7 @@ impl<T: Send> Buffer<T> {\n     // Again, unsafe because this has incredibly dubious ownership violations.\n     // It is assumed that this buffer is immediately dropped.\n     unsafe fn resize(&self, b: int, t: int, delta: int) -> Buffer<T> {\n-        let mut buf = Buffer::new(self.log_size + delta);\n+        let buf = Buffer::new(self.log_size + delta);\n         for i in range(t, b) {\n             buf.put(i, self.get(i));\n         }\n@@ -415,8 +423,8 @@ mod tests {\n \n     #[test]\n     fn smoke() {\n-        let mut pool = BufferPool::new();\n-        let (mut w, mut s) = pool.deque();\n+        let pool = BufferPool::new();\n+        let (w, s) = pool.deque();\n         assert_eq!(w.pop(), None);\n         assert_eq!(s.steal(), Empty);\n         w.push(1);\n@@ -430,10 +438,9 @@ mod tests {\n     #[test]\n     fn stealpush() {\n         static AMT: int = 100000;\n-        let mut pool = BufferPool::<int>::new();\n-        let (mut w, s) = pool.deque();\n+        let pool = BufferPool::<int>::new();\n+        let (w, s) = pool.deque();\n         let t = Thread::start(proc() {\n-            let mut s = s;\n             let mut left = AMT;\n             while left > 0 {\n                 match s.steal() {\n@@ -456,10 +463,9 @@ mod tests {\n     #[test]\n     fn stealpush_large() {\n         static AMT: int = 100000;\n-        let mut pool = BufferPool::<(int, int)>::new();\n-        let (mut w, s) = pool.deque();\n+        let pool = BufferPool::<(int, int)>::new();\n+        let (w, s) = pool.deque();\n         let t = Thread::start(proc() {\n-            let mut s = s;\n             let mut left = AMT;\n             while left > 0 {\n                 match s.steal() {\n@@ -477,7 +483,7 @@ mod tests {\n         t.join();\n     }\n \n-    fn stampede(mut w: Worker<Box<int>>, s: Stealer<Box<int>>,\n+    fn stampede(w: Worker<Box<int>>, s: Stealer<Box<int>>,\n                 nthreads: int, amt: uint) {\n         for _ in range(0, amt) {\n             w.push(box 20);\n@@ -489,7 +495,6 @@ mod tests {\n             let s = s.clone();\n             Thread::start(proc() {\n                 unsafe {\n-                    let mut s = s;\n                     while (*unsafe_remaining).load(SeqCst) > 0 {\n                         match s.steal() {\n                             Data(box 20) => {\n@@ -518,15 +523,15 @@ mod tests {\n \n     #[test]\n     fn run_stampede() {\n-        let mut pool = BufferPool::<Box<int>>::new();\n+        let pool = BufferPool::<Box<int>>::new();\n         let (w, s) = pool.deque();\n         stampede(w, s, 8, 10000);\n     }\n \n     #[test]\n     fn many_stampede() {\n         static AMT: uint = 4;\n-        let mut pool = BufferPool::<Box<int>>::new();\n+        let pool = BufferPool::<Box<int>>::new();\n         let threads = range(0, AMT).map(|_| {\n             let (w, s) = pool.deque();\n             Thread::start(proc() {\n@@ -545,14 +550,13 @@ mod tests {\n         static NTHREADS: int = 8;\n         static mut DONE: AtomicBool = INIT_ATOMIC_BOOL;\n         static mut HITS: AtomicUint = INIT_ATOMIC_UINT;\n-        let mut pool = BufferPool::<int>::new();\n-        let (mut w, s) = pool.deque();\n+        let pool = BufferPool::<int>::new();\n+        let (w, s) = pool.deque();\n \n         let threads = range(0, NTHREADS).map(|_| {\n             let s = s.clone();\n             Thread::start(proc() {\n                 unsafe {\n-                    let mut s = s;\n                     loop {\n                         match s.steal() {\n                             Data(2) => { HITS.fetch_add(1, SeqCst); }\n@@ -604,8 +608,8 @@ mod tests {\n         static AMT: int = 10000;\n         static NTHREADS: int = 4;\n         static mut DONE: AtomicBool = INIT_ATOMIC_BOOL;\n-        let mut pool = BufferPool::<(int, uint)>::new();\n-        let (mut w, s) = pool.deque();\n+        let pool = BufferPool::<(int, uint)>::new();\n+        let (w, s) = pool.deque();\n \n         let (threads, hits) = vec::unzip(range(0, NTHREADS).map(|_| {\n             let s = s.clone();\n@@ -615,7 +619,6 @@ mod tests {\n             };\n             (Thread::start(proc() {\n                 unsafe {\n-                    let mut s = s;\n                     loop {\n                         match s.steal() {\n                             Data((1, 2)) => {"}, {"sha": "b2cf427edc8128cefca1ccc624a3f4ecadb99d27", "filename": "src/libstd/sync/mod.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmod.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -15,7 +15,6 @@\n //! and/or blocking at all, but rather provide the necessary tools to build\n //! other types of concurrent primitives.\n \n-pub mod arc;\n pub mod atomics;\n pub mod deque;\n pub mod mpmc_bounded_queue;"}, {"sha": "ffad9c1c583d8ae0bfc2c14d8436d6679f9ebc68", "filename": "src/libstd/sync/mpmc_bounded_queue.rs", "status": "modified", "additions": 30, "deletions": 26, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -29,13 +29,15 @@\n \n // http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue\n \n+use alloc::arc::Arc;\n+\n use clone::Clone;\n use kinds::Send;\n use num::next_power_of_two;\n use option::{Option, Some, None};\n-use sync::arc::UnsafeArc;\n use sync::atomics::{AtomicUint,Relaxed,Release,Acquire};\n use vec::Vec;\n+use ty::Unsafe;\n \n struct Node<T> {\n     sequence: AtomicUint,\n@@ -44,7 +46,7 @@ struct Node<T> {\n \n struct State<T> {\n     pad0: [u8, ..64],\n-    buffer: Vec<Node<T>>,\n+    buffer: Vec<Unsafe<Node<T>>>,\n     mask: uint,\n     pad1: [u8, ..64],\n     enqueue_pos: AtomicUint,\n@@ -54,7 +56,7 @@ struct State<T> {\n }\n \n pub struct Queue<T> {\n-    state: UnsafeArc<State<T>>,\n+    state: Arc<State<T>>,\n }\n \n impl<T: Send> State<T> {\n@@ -70,7 +72,7 @@ impl<T: Send> State<T> {\n             capacity\n         };\n         let buffer = Vec::from_fn(capacity, |i| {\n-            Node { sequence:AtomicUint::new(i), value: None }\n+            Unsafe::new(Node { sequence:AtomicUint::new(i), value: None })\n         });\n         State{\n             pad0: [0, ..64],\n@@ -84,19 +86,21 @@ impl<T: Send> State<T> {\n         }\n     }\n \n-    fn push(&mut self, value: T) -> bool {\n+    fn push(&self, value: T) -> bool {\n         let mask = self.mask;\n         let mut pos = self.enqueue_pos.load(Relaxed);\n         loop {\n-            let node = self.buffer.get_mut(pos & mask);\n-            let seq = node.sequence.load(Acquire);\n+            let node = self.buffer.get(pos & mask);\n+            let seq = unsafe { (*node.get()).sequence.load(Acquire) };\n             let diff: int = seq as int - pos as int;\n \n             if diff == 0 {\n                 let enqueue_pos = self.enqueue_pos.compare_and_swap(pos, pos+1, Relaxed);\n                 if enqueue_pos == pos {\n-                    node.value = Some(value);\n-                    node.sequence.store(pos+1, Release);\n+                    unsafe {\n+                        (*node.get()).value = Some(value);\n+                        (*node.get()).sequence.store(pos+1, Release);\n+                    }\n                     break\n                 } else {\n                     pos = enqueue_pos;\n@@ -110,19 +114,21 @@ impl<T: Send> State<T> {\n         true\n     }\n \n-    fn pop(&mut self) -> Option<T> {\n+    fn pop(&self) -> Option<T> {\n         let mask = self.mask;\n         let mut pos = self.dequeue_pos.load(Relaxed);\n         loop {\n-            let node = self.buffer.get_mut(pos & mask);\n-            let seq = node.sequence.load(Acquire);\n+            let node = self.buffer.get(pos & mask);\n+            let seq = unsafe { (*node.get()).sequence.load(Acquire) };\n             let diff: int = seq as int - (pos + 1) as int;\n             if diff == 0 {\n                 let dequeue_pos = self.dequeue_pos.compare_and_swap(pos, pos+1, Relaxed);\n                 if dequeue_pos == pos {\n-                    let value = node.value.take();\n-                    node.sequence.store(pos + mask + 1, Release);\n-                    return value\n+                    unsafe {\n+                        let value = (*node.get()).value.take();\n+                        (*node.get()).sequence.store(pos + mask + 1, Release);\n+                        return value\n+                    }\n                 } else {\n                     pos = dequeue_pos;\n                 }\n@@ -138,24 +144,22 @@ impl<T: Send> State<T> {\n impl<T: Send> Queue<T> {\n     pub fn with_capacity(capacity: uint) -> Queue<T> {\n         Queue{\n-            state: UnsafeArc::new(State::with_capacity(capacity))\n+            state: Arc::new(State::with_capacity(capacity))\n         }\n     }\n \n-    pub fn push(&mut self, value: T) -> bool {\n-        unsafe { (*self.state.get()).push(value) }\n+    pub fn push(&self, value: T) -> bool {\n+        self.state.push(value)\n     }\n \n-    pub fn pop(&mut self) -> Option<T> {\n-        unsafe { (*self.state.get()).pop() }\n+    pub fn pop(&self) -> Option<T> {\n+        self.state.pop()\n     }\n }\n \n impl<T: Send> Clone for Queue<T> {\n     fn clone(&self) -> Queue<T> {\n-        Queue {\n-            state: self.state.clone()\n-        }\n+        Queue { state: self.state.clone() }\n     }\n }\n \n@@ -169,15 +173,15 @@ mod tests {\n     fn test() {\n         let nthreads = 8u;\n         let nmsgs = 1000u;\n-        let mut q = Queue::with_capacity(nthreads*nmsgs);\n+        let q = Queue::with_capacity(nthreads*nmsgs);\n         assert_eq!(None, q.pop());\n         let (tx, rx) = channel();\n \n         for _ in range(0, nthreads) {\n             let q = q.clone();\n             let tx = tx.clone();\n             native::task::spawn(proc() {\n-                let mut q = q;\n+                let q = q;\n                 for i in range(0, nmsgs) {\n                     assert!(q.push(i));\n                 }\n@@ -191,7 +195,7 @@ mod tests {\n             completion_rxs.push(rx);\n             let q = q.clone();\n             native::task::spawn(proc() {\n-                let mut q = q;\n+                let q = q;\n                 let mut i = 0u;\n                 loop {\n                     match q.pop() {"}, {"sha": "4db24e82d3709a3e466431e355a15f6fab192e08", "filename": "src/libstd/sync/mpsc_queue.rs", "status": "modified", "additions": 16, "deletions": 14, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fmpsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fmpsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmpsc_queue.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -45,6 +45,7 @@ use option::{Option, None, Some};\n use owned::Box;\n use ptr::RawPtr;\n use sync::atomics::{AtomicPtr, Release, Acquire, AcqRel, Relaxed};\n+use ty::Unsafe;\n \n /// A result of the `pop` function.\n pub enum PopResult<T> {\n@@ -69,7 +70,7 @@ struct Node<T> {\n /// popper at a time (many pushers are allowed).\n pub struct Queue<T> {\n     head: AtomicPtr<Node<T>>,\n-    tail: *mut Node<T>,\n+    tail: Unsafe<*mut Node<T>>,\n }\n \n impl<T> Node<T> {\n@@ -88,12 +89,12 @@ impl<T: Send> Queue<T> {\n         let stub = unsafe { Node::new(None) };\n         Queue {\n             head: AtomicPtr::new(stub),\n-            tail: stub,\n+            tail: Unsafe::new(stub),\n         }\n     }\n \n     /// Pushes a new value onto this queue.\n-    pub fn push(&mut self, t: T) {\n+    pub fn push(&self, t: T) {\n         unsafe {\n             let n = Node::new(Some(t));\n             let prev = self.head.swap(n, AcqRel);\n@@ -111,13 +112,13 @@ impl<T: Send> Queue<T> {\n     ///\n     /// This inconsistent state means that this queue does indeed have data, but\n     /// it does not currently have access to it at this time.\n-    pub fn pop(&mut self) -> PopResult<T> {\n+    pub fn pop(&self) -> PopResult<T> {\n         unsafe {\n-            let tail = self.tail;\n+            let tail = *self.tail.get();\n             let next = (*tail).next.load(Acquire);\n \n             if !next.is_null() {\n-                self.tail = next;\n+                *self.tail.get() = next;\n                 assert!((*tail).value.is_none());\n                 assert!((*next).value.is_some());\n                 let ret = (*next).value.take_unwrap();\n@@ -131,7 +132,7 @@ impl<T: Send> Queue<T> {\n \n     /// Attempts to pop data from this queue, but doesn't attempt too hard. This\n     /// will canonicalize inconsistent states to a `None` value.\n-    pub fn casual_pop(&mut self) -> Option<T> {\n+    pub fn casual_pop(&self) -> Option<T> {\n         match self.pop() {\n             Data(t) => Some(t),\n             Empty | Inconsistent => None,\n@@ -143,7 +144,7 @@ impl<T: Send> Queue<T> {\n impl<T: Send> Drop for Queue<T> {\n     fn drop(&mut self) {\n         unsafe {\n-            let mut cur = self.tail;\n+            let mut cur = *self.tail.get();\n             while !cur.is_null() {\n                 let next = (*cur).next.load(Relaxed);\n                 let _: Box<Node<T>> = mem::transmute(cur);\n@@ -157,13 +158,14 @@ impl<T: Send> Drop for Queue<T> {\n mod tests {\n     use prelude::*;\n \n+    use alloc::arc::Arc;\n+\n     use native;\n     use super::{Queue, Data, Empty, Inconsistent};\n-    use sync::arc::UnsafeArc;\n \n     #[test]\n     fn test_full() {\n-        let mut q = Queue::new();\n+        let q = Queue::new();\n         q.push(box 1);\n         q.push(box 2);\n     }\n@@ -172,28 +174,28 @@ mod tests {\n     fn test() {\n         let nthreads = 8u;\n         let nmsgs = 1000u;\n-        let mut q = Queue::new();\n+        let q = Queue::new();\n         match q.pop() {\n             Empty => {}\n             Inconsistent | Data(..) => fail!()\n         }\n         let (tx, rx) = channel();\n-        let q = UnsafeArc::new(q);\n+        let q = Arc::new(q);\n \n         for _ in range(0, nthreads) {\n             let tx = tx.clone();\n             let q = q.clone();\n             native::task::spawn(proc() {\n                 for i in range(0, nmsgs) {\n-                    unsafe { (*q.get()).push(i); }\n+                    q.push(i);\n                 }\n                 tx.send(());\n             });\n         }\n \n         let mut i = 0u;\n         while i < nthreads * nmsgs {\n-            match unsafe { (*q.get()).pop() } {\n+            match q.pop() {\n                 Empty | Inconsistent => {},\n                 Data(_) => { i += 1 }\n             }"}, {"sha": "fb515c9db6e4a13ad3811361ee3ee0b801cbb6ed", "filename": "src/libstd/sync/spsc_queue.rs", "status": "modified", "additions": 37, "deletions": 33, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fspsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Fsync%2Fspsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fspsc_queue.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -40,6 +40,7 @@ use option::{Some, None, Option};\n use owned::Box;\n use ptr::RawPtr;\n use sync::atomics::{AtomicPtr, Relaxed, AtomicUint, Acquire, Release};\n+use ty::Unsafe;\n \n // Node within the linked list queue of messages to send\n struct Node<T> {\n@@ -51,18 +52,18 @@ struct Node<T> {\n }\n \n /// The single-producer single-consumer queue. This structure is not cloneable,\n-/// but it can be safely shared in an UnsafeArc if it is guaranteed that there\n+/// but it can be safely shared in an Arc if it is guaranteed that there\n /// is only one popper and one pusher touching the queue at any one point in\n /// time.\n pub struct Queue<T> {\n     // consumer fields\n-    tail: *mut Node<T>, // where to pop from\n+    tail: Unsafe<*mut Node<T>>, // where to pop from\n     tail_prev: AtomicPtr<Node<T>>, // where to pop from\n \n     // producer fields\n-    head: *mut Node<T>,      // where to push to\n-    first: *mut Node<T>,     // where to get new nodes from\n-    tail_copy: *mut Node<T>, // between first/tail\n+    head: Unsafe<*mut Node<T>>,      // where to push to\n+    first: Unsafe<*mut Node<T>>,     // where to get new nodes from\n+    tail_copy: Unsafe<*mut Node<T>>, // between first/tail\n \n     // Cache maintenance fields. Additions and subtractions are stored\n     // separately in order to allow them to use nonatomic addition/subtraction.\n@@ -101,11 +102,11 @@ impl<T: Send> Queue<T> {\n         let n2 = Node::new();\n         unsafe { (*n1).next.store(n2, Relaxed) }\n         Queue {\n-            tail: n2,\n+            tail: Unsafe::new(n2),\n             tail_prev: AtomicPtr::new(n1),\n-            head: n2,\n-            first: n1,\n-            tail_copy: n1,\n+            head: Unsafe::new(n2),\n+            first: Unsafe::new(n1),\n+            tail_copy: Unsafe::new(n1),\n             cache_bound: bound,\n             cache_additions: AtomicUint::new(0),\n             cache_subtractions: AtomicUint::new(0),\n@@ -114,43 +115,43 @@ impl<T: Send> Queue<T> {\n \n     /// Pushes a new value onto this queue. Note that to use this function\n     /// safely, it must be externally guaranteed that there is only one pusher.\n-    pub fn push(&mut self, t: T) {\n+    pub fn push(&self, t: T) {\n         unsafe {\n             // Acquire a node (which either uses a cached one or allocates a new\n             // one), and then append this to the 'head' node.\n             let n = self.alloc();\n             assert!((*n).value.is_none());\n             (*n).value = Some(t);\n             (*n).next.store(0 as *mut Node<T>, Relaxed);\n-            (*self.head).next.store(n, Release);\n-            self.head = n;\n+            (**self.head.get()).next.store(n, Release);\n+            *self.head.get() = n;\n         }\n     }\n \n-    unsafe fn alloc(&mut self) -> *mut Node<T> {\n+    unsafe fn alloc(&self) -> *mut Node<T> {\n         // First try to see if we can consume the 'first' node for our uses.\n         // We try to avoid as many atomic instructions as possible here, so\n         // the addition to cache_subtractions is not atomic (plus we're the\n         // only one subtracting from the cache).\n-        if self.first != self.tail_copy {\n+        if *self.first.get() != *self.tail_copy.get() {\n             if self.cache_bound > 0 {\n                 let b = self.cache_subtractions.load(Relaxed);\n                 self.cache_subtractions.store(b + 1, Relaxed);\n             }\n-            let ret = self.first;\n-            self.first = (*ret).next.load(Relaxed);\n+            let ret = *self.first.get();\n+            *self.first.get() = (*ret).next.load(Relaxed);\n             return ret;\n         }\n         // If the above fails, then update our copy of the tail and try\n         // again.\n-        self.tail_copy = self.tail_prev.load(Acquire);\n-        if self.first != self.tail_copy {\n+        *self.tail_copy.get() = self.tail_prev.load(Acquire);\n+        if *self.first.get() != *self.tail_copy.get() {\n             if self.cache_bound > 0 {\n                 let b = self.cache_subtractions.load(Relaxed);\n                 self.cache_subtractions.store(b + 1, Relaxed);\n             }\n-            let ret = self.first;\n-            self.first = (*ret).next.load(Relaxed);\n+            let ret = *self.first.get();\n+            *self.first.get() = (*ret).next.load(Relaxed);\n             return ret;\n         }\n         // If all of that fails, then we have to allocate a new node\n@@ -160,19 +161,19 @@ impl<T: Send> Queue<T> {\n \n     /// Attempts to pop a value from this queue. Remember that to use this type\n     /// safely you must ensure that there is only one popper at a time.\n-    pub fn pop(&mut self) -> Option<T> {\n+    pub fn pop(&self) -> Option<T> {\n         unsafe {\n             // The `tail` node is not actually a used node, but rather a\n             // sentinel from where we should start popping from. Hence, look at\n             // tail's next field and see if we can use it. If we do a pop, then\n             // the current tail node is a candidate for going into the cache.\n-            let tail = self.tail;\n+            let tail = *self.tail.get();\n             let next = (*tail).next.load(Acquire);\n             if next.is_null() { return None }\n             assert!((*next).value.is_some());\n             let ret = (*next).value.take();\n \n-            self.tail = next;\n+            *self.tail.get() = next;\n             if self.cache_bound == 0 {\n                 self.tail_prev.store(tail, Release);\n             } else {\n@@ -197,11 +198,11 @@ impl<T: Send> Queue<T> {\n \n     /// Attempts to peek at the head of the queue, returning `None` if the queue\n     /// has no data currently\n-    pub fn peek<'a>(&'a mut self) -> Option<&'a mut T> {\n+    pub fn peek<'a>(&'a self) -> Option<&'a mut T> {\n         // This is essentially the same as above with all the popping bits\n         // stripped out.\n         unsafe {\n-            let tail = self.tail;\n+            let tail = *self.tail.get();\n             let next = (*tail).next.load(Acquire);\n             if next.is_null() { return None }\n             return (*next).value.as_mut();\n@@ -213,7 +214,7 @@ impl<T: Send> Queue<T> {\n impl<T: Send> Drop for Queue<T> {\n     fn drop(&mut self) {\n         unsafe {\n-            let mut cur = self.first;\n+            let mut cur = *self.first.get();\n             while !cur.is_null() {\n                 let next = (*cur).next.load(Relaxed);\n                 let _n: Box<Node<T>> = mem::transmute(cur);\n@@ -226,13 +227,15 @@ impl<T: Send> Drop for Queue<T> {\n #[cfg(test)]\n mod test {\n     use prelude::*;\n+\n+    use alloc::arc::Arc;\n     use native;\n+\n     use super::Queue;\n-    use sync::arc::UnsafeArc;\n \n     #[test]\n     fn smoke() {\n-        let mut q = Queue::new(0);\n+        let q = Queue::new(0);\n         q.push(1);\n         q.push(2);\n         assert_eq!(q.pop(), Some(1));\n@@ -247,14 +250,14 @@ mod test {\n \n     #[test]\n     fn drop_full() {\n-        let mut q = Queue::new(0);\n+        let q = Queue::new(0);\n         q.push(box 1);\n         q.push(box 2);\n     }\n \n     #[test]\n     fn smoke_bound() {\n-        let mut q = Queue::new(1);\n+        let q = Queue::new(1);\n         q.push(1);\n         q.push(2);\n         assert_eq!(q.pop(), Some(1));\n@@ -273,12 +276,13 @@ mod test {\n         stress_bound(1);\n \n         fn stress_bound(bound: uint) {\n-            let (a, b) = UnsafeArc::new2(Queue::new(bound));\n+            let a = Arc::new(Queue::new(bound));\n+            let b = a.clone();\n             let (tx, rx) = channel();\n             native::task::spawn(proc() {\n                 for _ in range(0, 100000) {\n                     loop {\n-                        match unsafe { (*b.get()).pop() } {\n+                        match b.pop() {\n                             Some(1) => break,\n                             Some(_) => fail!(),\n                             None => {}\n@@ -288,7 +292,7 @@ mod test {\n                 tx.send(());\n             });\n             for _ in range(0, 100000) {\n-                unsafe { (*a.get()).push(1); }\n+                a.push(1);\n             }\n             rx.recv();\n         }"}, {"sha": "f0f7e40ce09b88ed4c5793f73f13e4af104bf4fd", "filename": "src/libstd/unstable/sync.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Funstable%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/257a73ce8273d026f2af1a5021ae2d1a4e7b95e5/src%2Flibstd%2Funstable%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fsync.rs?ref=257a73ce8273d026f2af1a5021ae2d1a4e7b95e5", "patch": "@@ -8,9 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use alloc::arc::Arc;\n+\n use clone::Clone;\n use kinds::Send;\n-use sync::arc::UnsafeArc;\n+use ty::Unsafe;\n use unstable::mutex::NativeMutex;\n \n struct ExData<T> {\n@@ -30,7 +32,7 @@ struct ExData<T> {\n  * need to block or deschedule while accessing shared state, use extra::sync::RWArc.\n  */\n pub struct Exclusive<T> {\n-    x: UnsafeArc<ExData<T>>\n+    x: Arc<Unsafe<ExData<T>>>\n }\n \n impl<T:Send> Clone for Exclusive<T> {\n@@ -48,7 +50,7 @@ impl<T:Send> Exclusive<T> {\n             data: user_data\n         };\n         Exclusive {\n-            x: UnsafeArc::new(data)\n+            x: Arc::new(Unsafe::new(data))\n         }\n     }\n "}]}