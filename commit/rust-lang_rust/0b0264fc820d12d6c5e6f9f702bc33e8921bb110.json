{"sha": "0b0264fc820d12d6c5e6f9f702bc33e8921bb110", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBiMDI2NGZjODIwZDEyZDZjNWU2ZjlmNzAyYmMzM2U4OTIxYmIxMTA=", "commit": {"author": {"name": "JCTyBlaidd", "email": "JCTyblaidd@users.noreply.github.com", "date": "2020-11-15T20:19:34Z"}, "committer": {"name": "JCTyBlaidd", "email": "JCTyblaidd@users.noreply.github.com", "date": "2020-11-15T20:19:34Z"}, "message": "Run rustfmt on vector_clock.rs and data_race.rs", "tree": {"sha": "04bbf8bd4d11cdfd632c51d8f384830d482dcb50", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/04bbf8bd4d11cdfd632c51d8f384830d482dcb50"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0b0264fc820d12d6c5e6f9f702bc33e8921bb110", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0b0264fc820d12d6c5e6f9f702bc33e8921bb110", "html_url": "https://github.com/rust-lang/rust/commit/0b0264fc820d12d6c5e6f9f702bc33e8921bb110", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0b0264fc820d12d6c5e6f9f702bc33e8921bb110/comments", "author": {"login": "JCTyblaidd", "id": 8288600, "node_id": "MDQ6VXNlcjgyODg2MDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8288600?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JCTyblaidd", "html_url": "https://github.com/JCTyblaidd", "followers_url": "https://api.github.com/users/JCTyblaidd/followers", "following_url": "https://api.github.com/users/JCTyblaidd/following{/other_user}", "gists_url": "https://api.github.com/users/JCTyblaidd/gists{/gist_id}", "starred_url": "https://api.github.com/users/JCTyblaidd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JCTyblaidd/subscriptions", "organizations_url": "https://api.github.com/users/JCTyblaidd/orgs", "repos_url": "https://api.github.com/users/JCTyblaidd/repos", "events_url": "https://api.github.com/users/JCTyblaidd/events{/privacy}", "received_events_url": "https://api.github.com/users/JCTyblaidd/received_events", "type": "User", "site_admin": false}, "committer": {"login": "JCTyblaidd", "id": 8288600, "node_id": "MDQ6VXNlcjgyODg2MDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8288600?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JCTyblaidd", "html_url": "https://github.com/JCTyblaidd", "followers_url": "https://api.github.com/users/JCTyblaidd/followers", "following_url": "https://api.github.com/users/JCTyblaidd/following{/other_user}", "gists_url": "https://api.github.com/users/JCTyblaidd/gists{/gist_id}", "starred_url": "https://api.github.com/users/JCTyblaidd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JCTyblaidd/subscriptions", "organizations_url": "https://api.github.com/users/JCTyblaidd/orgs", "repos_url": "https://api.github.com/users/JCTyblaidd/repos", "events_url": "https://api.github.com/users/JCTyblaidd/events{/privacy}", "received_events_url": "https://api.github.com/users/JCTyblaidd/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a3b7839bbdde0c5856720dc885250752aefd4207", "url": "https://api.github.com/repos/rust-lang/rust/commits/a3b7839bbdde0c5856720dc885250752aefd4207", "html_url": "https://github.com/rust-lang/rust/commit/a3b7839bbdde0c5856720dc885250752aefd4207"}], "stats": {"total": 664, "additions": 356, "deletions": 308}, "files": [{"sha": "b9542f6e2d62c91938d521283562027f93bc6564", "filename": "src/data_race.rs", "status": "modified", "additions": 232, "deletions": 199, "changes": 431, "blob_url": "https://github.com/rust-lang/rust/blob/0b0264fc820d12d6c5e6f9f702bc33e8921bb110/src%2Fdata_race.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b0264fc820d12d6c5e6f9f702bc33e8921bb110/src%2Fdata_race.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdata_race.rs?ref=0b0264fc820d12d6c5e6f9f702bc33e8921bb110", "patch": "@@ -11,7 +11,7 @@\n //! a data race occurs between two memory accesses if they are on different threads, at least one operation\n //! is non-atomic, at least one operation is a write and neither access happens-before the other. Read the link\n //! for full definition.\n-//! \n+//!\n //! This re-uses vector indexes for threads that are known to be unable to report data-races, this is valid\n //! because it only re-uses vector indexes once all currently-active (not-terminated) threads have an internal\n //! vector clock that happens-after the join operation of the candidate thread. Threads that have not been joined\n@@ -43,21 +43,21 @@\n //! read, write and deallocate functions and should be cleaned up in the future.\n \n use std::{\n-    fmt::Debug, rc::Rc,\n-    cell::{Cell, RefCell, Ref, RefMut}, mem\n+    cell::{Cell, Ref, RefCell, RefMut},\n+    fmt::Debug,\n+    mem,\n+    rc::Rc,\n };\n \n+use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use rustc_index::vec::{Idx, IndexVec};\n-use rustc_target::abi::Size;\n use rustc_middle::{mir, ty::layout::TyAndLayout};\n-use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n+use rustc_target::abi::Size;\n \n use crate::{\n-    MiriEvalContext, MiriEvalContextExt,\n-    ThreadId, Tag, RangeMap,\n-    InterpResult, Pointer, ScalarMaybeUninit,\n-    MPlaceTy, OpTy, MemPlaceMeta, ImmTy, Immediate,\n-    VClock, VSmallClockMap, VectorIdx, VTimestamp\n+    ImmTy, Immediate, InterpResult, MPlaceTy, MemPlaceMeta, MiriEvalContext, MiriEvalContextExt,\n+    OpTy, Pointer, RangeMap, ScalarMaybeUninit, Tag, ThreadId, VClock, VSmallClockMap, VTimestamp,\n+    VectorIdx,\n };\n \n pub type AllocExtra = VClockAlloc;\n@@ -89,7 +89,6 @@ pub enum AtomicWriteOp {\n     SeqCst,\n }\n \n-\n /// Valid atomic fence operations, subset of atomic::Ordering.\n #[derive(Copy, Clone, PartialEq, Eq, Debug)]\n pub enum AtomicFenceOp {\n@@ -99,14 +98,11 @@ pub enum AtomicFenceOp {\n     SeqCst,\n }\n \n-\n-\n /// The current set of vector clocks describing the state\n /// of a thread, contains the happens-before clock and\n /// additional metadata to model atomic fence operations.\n #[derive(Clone, Default, Debug)]\n struct ThreadClockSet {\n-\n     /// The increasing clock representing timestamps\n     /// that happen-before this thread.\n     clock: VClock,\n@@ -120,9 +116,7 @@ struct ThreadClockSet {\n     fence_release: VClock,\n }\n \n-\n impl ThreadClockSet {\n-\n     /// Apply the effects of a release fence to this\n     /// set of thread vector clocks.\n     #[inline]\n@@ -152,7 +146,6 @@ impl ThreadClockSet {\n     }\n }\n \n-\n /// Error returned by finding a data race\n /// should be elaborated upon.\n #[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n@@ -164,7 +157,6 @@ pub struct DataRace;\n /// exists on the memory cell.\n #[derive(Clone, PartialEq, Eq, Default, Debug)]\n struct AtomicMemoryCellClocks {\n-\n     /// The clock-vector of the timestamp of the last atomic\n     /// read operation performed by each thread.\n     /// This detects potential data-races between atomic read\n@@ -179,7 +171,7 @@ struct AtomicMemoryCellClocks {\n \n     /// Synchronization vector for acquire-release semantics\n     /// contains the vector of timestamps that will\n-    /// happen-before a thread if an acquire-load is \n+    /// happen-before a thread if an acquire-load is\n     /// performed on the data.\n     sync_vector: VClock,\n \n@@ -195,7 +187,6 @@ struct AtomicMemoryCellClocks {\n /// for data-race detection.\n #[derive(Clone, PartialEq, Eq, Debug)]\n struct MemoryCellClocks {\n-\n     /// The vector-clock timestamp of the last write\n     /// corresponding to the writing threads timestamp.\n     write: VTimestamp,\n@@ -215,7 +206,6 @@ struct MemoryCellClocks {\n     atomic_ops: Option<Box<AtomicMemoryCellClocks>>,\n }\n \n-\n /// Create a default memory cell clocks instance\n /// for uninitialized memory.\n impl Default for MemoryCellClocks {\n@@ -224,20 +214,18 @@ impl Default for MemoryCellClocks {\n             read: VClock::default(),\n             write: 0,\n             write_index: VectorIdx::MAX_INDEX,\n-            atomic_ops: None\n+            atomic_ops: None,\n         }\n     }\n }\n \n-\n impl MemoryCellClocks {\n-\n     /// Load the internal atomic memory cells if they exist.\n     #[inline]\n     fn atomic(&self) -> Option<&AtomicMemoryCellClocks> {\n         match &self.atomic_ops {\n             Some(op) => Some(&*op),\n-            None => None\n+            None => None,\n         }\n     }\n \n@@ -251,7 +239,11 @@ impl MemoryCellClocks {\n     /// Update memory cell data-race tracking for atomic\n     /// load acquire semantics, is a no-op if this memory was\n     /// not used previously as atomic memory.\n-    fn load_acquire(&mut self, clocks: &mut ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n+    fn load_acquire(\n+        &mut self,\n+        clocks: &mut ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n         self.atomic_read_detect(clocks, index)?;\n         if let Some(atomic) = self.atomic() {\n             clocks.clock.join(&atomic.sync_vector);\n@@ -262,15 +254,18 @@ impl MemoryCellClocks {\n     /// Update memory cell data-race tracking for atomic\n     /// load relaxed semantics, is a no-op if this memory was\n     /// not used previously as atomic memory.\n-    fn load_relaxed(&mut self, clocks: &mut ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n+    fn load_relaxed(\n+        &mut self,\n+        clocks: &mut ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n         self.atomic_read_detect(clocks, index)?;\n         if let Some(atomic) = self.atomic() {\n             clocks.fence_acquire.join(&atomic.sync_vector);\n         }\n         Ok(())\n     }\n \n-\n     /// Update the memory cell data-race tracking for atomic\n     /// store release semantics.\n     fn store_release(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n@@ -313,10 +308,14 @@ impl MemoryCellClocks {\n         atomic.sync_vector.join(&clocks.fence_release);\n         Ok(())\n     }\n-    \n+\n     /// Detect data-races with an atomic read, caused by a non-atomic write that does\n     /// not happen-before the atomic-read.\n-    fn atomic_read_detect(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n+    fn atomic_read_detect(\n+        &mut self,\n+        clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n         log::trace!(\"Atomic read with vectors: {:#?} :: {:#?}\", self, clocks);\n         if self.write <= clocks.clock[self.write_index] {\n             let atomic = self.atomic_mut();\n@@ -329,7 +328,11 @@ impl MemoryCellClocks {\n \n     /// Detect data-races with an atomic write, either with a non-atomic read or with\n     /// a non-atomic write.\n-    fn atomic_write_detect(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n+    fn atomic_write_detect(\n+        &mut self,\n+        clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n         log::trace!(\"Atomic write with vectors: {:#?} :: {:#?}\", self, clocks);\n         if self.write <= clocks.clock[self.write_index] && self.read <= clocks.clock {\n             let atomic = self.atomic_mut();\n@@ -342,7 +345,11 @@ impl MemoryCellClocks {\n \n     /// Detect races for non-atomic read operations at the current memory cell\n     /// returns true if a data-race is detected.\n-    fn read_race_detect(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n+    fn read_race_detect(\n+        &mut self,\n+        clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n         log::trace!(\"Unsynchronized read with vectors: {:#?} :: {:#?}\", self, clocks);\n         if self.write <= clocks.clock[self.write_index] {\n             let race_free = if let Some(atomic) = self.atomic() {\n@@ -363,7 +370,11 @@ impl MemoryCellClocks {\n \n     /// Detect races for non-atomic write operations at the current memory cell\n     /// returns true if a data-race is detected.\n-    fn write_race_detect(&mut self, clocks: &ThreadClockSet, index: VectorIdx)  -> Result<(), DataRace> {\n+    fn write_race_detect(\n+        &mut self,\n+        clocks: &ThreadClockSet,\n+        index: VectorIdx,\n+    ) -> Result<(), DataRace> {\n         log::trace!(\"Unsynchronized write with vectors: {:#?} :: {:#?}\", self, clocks);\n         if self.write <= clocks.clock[self.write_index] && self.read <= clocks.clock {\n             let race_free = if let Some(atomic) = self.atomic() {\n@@ -385,18 +396,16 @@ impl MemoryCellClocks {\n     }\n }\n \n-\n /// Evaluation context extensions.\n impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for MiriEvalContext<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n-\n     /// Atomic variant of read_scalar_at_offset.\n     fn read_scalar_at_offset_atomic(\n         &self,\n         op: OpTy<'tcx, Tag>,\n         offset: u64,\n         layout: TyAndLayout<'tcx>,\n-        atomic: AtomicReadOp\n+        atomic: AtomicReadOp,\n     ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n         let this = self.eval_context_ref();\n         let op_place = this.deref_operand(op)?;\n@@ -415,7 +424,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         offset: u64,\n         value: impl Into<ScalarMaybeUninit<Tag>>,\n         layout: TyAndLayout<'tcx>,\n-        atomic: AtomicWriteOp\n+        atomic: AtomicWriteOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         let op_place = this.deref_operand(op)?;\n@@ -429,46 +438,45 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n \n     /// Perform an atomic read operation at the memory location.\n     fn read_scalar_atomic(\n-        &self, place: MPlaceTy<'tcx, Tag>, atomic: AtomicReadOp\n+        &self,\n+        place: MPlaceTy<'tcx, Tag>,\n+        atomic: AtomicReadOp,\n     ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n         let this = self.eval_context_ref();\n-        let scalar = this.allow_data_races_ref(move |this| {\n-            this.read_scalar(place.into())\n-        })?;\n+        let scalar = this.allow_data_races_ref(move |this| this.read_scalar(place.into()))?;\n         self.validate_atomic_load(place, atomic)?;\n         Ok(scalar)\n     }\n \n     /// Perform an atomic write operation at the memory location.\n     fn write_scalar_atomic(\n-        &mut self, val: ScalarMaybeUninit<Tag>, dest: MPlaceTy<'tcx, Tag>,\n-        atomic: AtomicWriteOp\n+        &mut self,\n+        val: ScalarMaybeUninit<Tag>,\n+        dest: MPlaceTy<'tcx, Tag>,\n+        atomic: AtomicWriteOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        this.allow_data_races_mut(move |this| {\n-            this.write_scalar(val, dest.into())\n-        })?;\n+        this.allow_data_races_mut(move |this| this.write_scalar(val, dest.into()))?;\n         self.validate_atomic_store(dest, atomic)\n     }\n \n     /// Perform a atomic operation on a memory location.\n     fn atomic_op_immediate(\n         &mut self,\n-        place: MPlaceTy<'tcx, Tag>, rhs: ImmTy<'tcx, Tag>,\n-        op: mir::BinOp, neg: bool, atomic: AtomicRwOp\n+        place: MPlaceTy<'tcx, Tag>,\n+        rhs: ImmTy<'tcx, Tag>,\n+        op: mir::BinOp,\n+        neg: bool,\n+        atomic: AtomicRwOp,\n     ) -> InterpResult<'tcx, ImmTy<'tcx, Tag>> {\n         let this = self.eval_context_mut();\n \n-        let old = this.allow_data_races_mut(|this| {\n-            this.read_immediate(place. into())\n-        })?;        \n+        let old = this.allow_data_races_mut(|this| this.read_immediate(place.into()))?;\n \n         // Atomics wrap around on overflow.\n         let val = this.binary_op(op, old, rhs)?;\n         let val = if neg { this.unary_op(mir::UnOp::Not, val)? } else { val };\n-        this.allow_data_races_mut(|this| {\n-            this.write_immediate(*val, place.into())\n-        })?;\n+        this.allow_data_races_mut(|this| this.write_immediate(*val, place.into()))?;\n \n         this.validate_atomic_rmw(place, atomic)?;\n         Ok(old)\n@@ -478,17 +486,14 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     /// scalar value, the old value is returned.\n     fn atomic_exchange_scalar(\n         &mut self,\n-        place: MPlaceTy<'tcx, Tag>, new: ScalarMaybeUninit<Tag>,\n-        atomic: AtomicRwOp\n+        place: MPlaceTy<'tcx, Tag>,\n+        new: ScalarMaybeUninit<Tag>,\n+        atomic: AtomicRwOp,\n     ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n         let this = self.eval_context_mut();\n \n-        let old = this.allow_data_races_mut(|this| {\n-            this.read_scalar(place.into())\n-        })?;\n-        this.allow_data_races_mut(|this| {\n-            this.write_scalar(new, place.into())\n-        })?;\n+        let old = this.allow_data_races_mut(|this| this.read_scalar(place.into()))?;\n+        this.allow_data_races_mut(|this| this.write_scalar(new, place.into()))?;\n         this.validate_atomic_rmw(place, atomic)?;\n         Ok(old)\n     }\n@@ -497,19 +502,20 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     /// on success an atomic RMW operation is performed and on failure\n     /// only an atomic read occurs.\n     fn atomic_compare_exchange_scalar(\n-        &mut self, place: MPlaceTy<'tcx, Tag>,\n-        expect_old: ImmTy<'tcx, Tag>, new: ScalarMaybeUninit<Tag>,\n-        success: AtomicRwOp, fail: AtomicReadOp\n+        &mut self,\n+        place: MPlaceTy<'tcx, Tag>,\n+        expect_old: ImmTy<'tcx, Tag>,\n+        new: ScalarMaybeUninit<Tag>,\n+        success: AtomicRwOp,\n+        fail: AtomicReadOp,\n     ) -> InterpResult<'tcx, Immediate<Tag>> {\n         let this = self.eval_context_mut();\n \n         // Failure ordering cannot be stronger than success ordering, therefore first attempt\n         // to read with the failure ordering and if successfull then try again with the success\n         // read ordering and write in the success case.\n         // Read as immediate for the sake of `binary_op()`\n-        let old = this.allow_data_races_mut(|this| {\n-            this.read_immediate(place.into())\n-        })?; \n+        let old = this.allow_data_races_mut(|this| this.read_immediate(place.into()))?;\n \n         // `binary_op` will bail if either of them is not a scalar.\n         let eq = this.overflowing_binary_op(mir::BinOp::Eq, old, expect_old)?.0;\n@@ -519,9 +525,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         // if successful, perform a full rw-atomic validation\n         // otherwise treat this as an atomic load with the fail ordering.\n         if eq.to_bool()? {\n-            this.allow_data_races_mut(|this| {\n-                this.write_scalar(new, place.into())\n-            })?;\n+            this.allow_data_races_mut(|this| this.write_scalar(new, place.into()))?;\n             this.validate_atomic_rmw(place, success)?;\n         } else {\n             this.validate_atomic_load(place, fail)?;\n@@ -530,68 +534,74 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         // Return the old value.\n         Ok(res)\n     }\n-    \n-    \n+\n     /// Update the data-race detector for an atomic read occuring at the\n     /// associated memory-place and on the current thread.\n     fn validate_atomic_load(\n-        &self, place: MPlaceTy<'tcx, Tag>, atomic: AtomicReadOp\n+        &self,\n+        place: MPlaceTy<'tcx, Tag>,\n+        atomic: AtomicReadOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_ref();\n         this.validate_atomic_op(\n-            place, atomic, \"Atomic Load\",\n+            place,\n+            atomic,\n+            \"Atomic Load\",\n             move |memory, clocks, index, atomic| {\n                 if atomic == AtomicReadOp::Relaxed {\n                     memory.load_relaxed(&mut *clocks, index)\n                 } else {\n                     memory.load_acquire(&mut *clocks, index)\n                 }\n-            }\n+            },\n         )\n     }\n \n     /// Update the data-race detector for an atomic write occuring at the\n     /// associated memory-place and on the current thread.\n     fn validate_atomic_store(\n-        &mut self, place: MPlaceTy<'tcx, Tag>, atomic: AtomicWriteOp\n+        &mut self,\n+        place: MPlaceTy<'tcx, Tag>,\n+        atomic: AtomicWriteOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_ref();\n         this.validate_atomic_op(\n-            place, atomic, \"Atomic Store\",\n+            place,\n+            atomic,\n+            \"Atomic Store\",\n             move |memory, clocks, index, atomic| {\n                 if atomic == AtomicWriteOp::Relaxed {\n                     memory.store_relaxed(clocks, index)\n                 } else {\n                     memory.store_release(clocks, index)\n                 }\n-            }\n+            },\n         )\n     }\n \n     /// Update the data-race detector for an atomic read-modify-write occuring\n     /// at the associated memory place and on the current thread.\n     fn validate_atomic_rmw(\n-        &mut self, place: MPlaceTy<'tcx, Tag>, atomic: AtomicRwOp\n+        &mut self,\n+        place: MPlaceTy<'tcx, Tag>,\n+        atomic: AtomicRwOp,\n     ) -> InterpResult<'tcx> {\n         use AtomicRwOp::*;\n         let acquire = matches!(atomic, Acquire | AcqRel | SeqCst);\n         let release = matches!(atomic, Release | AcqRel | SeqCst);\n         let this = self.eval_context_ref();\n-        this.validate_atomic_op(\n-            place, atomic, \"Atomic RMW\",\n-            move |memory, clocks, index, _| {\n-                if acquire {\n-                    memory.load_acquire(clocks, index)?;\n-                } else {\n-                    memory.load_relaxed(clocks, index)?;\n-                }\n-                if release {\n-                    memory.rmw_release(clocks, index)\n-                } else {\n-                    memory.rmw_relaxed(clocks, index)\n-                }\n+        this.validate_atomic_op(place, atomic, \"Atomic RMW\", move |memory, clocks, index, _| {\n+            if acquire {\n+                memory.load_acquire(clocks, index)?;\n+            } else {\n+                memory.load_relaxed(clocks, index)?;\n             }\n-        )\n+            if release {\n+                memory.rmw_release(clocks, index)\n+            } else {\n+                memory.rmw_relaxed(clocks, index)\n+            }\n+        })\n     }\n \n     /// Update the data-race detector for an atomic fence on the current thread.\n@@ -620,12 +630,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     }\n }\n \n-\n-\n /// Vector clock metadata for a logical memory allocation.\n #[derive(Debug, Clone)]\n pub struct VClockAlloc {\n-\n     /// Range of Vector clocks, this gives each byte a potentially\n     /// unqiue set of vector clocks, but merges identical information\n     /// together for improved efficiency.\n@@ -635,16 +642,12 @@ pub struct VClockAlloc {\n     global: MemoryExtra,\n }\n \n-\n impl VClockAlloc {\n-\n     /// Create a new data-race allocation detector.\n     pub fn new_allocation(global: &MemoryExtra, len: Size) -> VClockAlloc {\n         VClockAlloc {\n             global: Rc::clone(global),\n-            alloc_ranges: RefCell::new(\n-                RangeMap::new(len, MemoryCellClocks::default())\n-            )\n+            alloc_ranges: RefCell::new(RangeMap::new(len, MemoryCellClocks::default())),\n         }\n     }\n \n@@ -653,27 +656,29 @@ impl VClockAlloc {\n     fn find_gt_index(l: &VClock, r: &VClock) -> Option<VectorIdx> {\n         let l_slice = l.as_slice();\n         let r_slice = r.as_slice();\n-        l_slice.iter().zip(r_slice.iter())\n+        l_slice\n+            .iter()\n+            .zip(r_slice.iter())\n             .enumerate()\n-            .find_map(|(idx, (&l, &r))| {\n-                if l > r { Some(idx) } else { None }\n-            }).or_else(|| {\n+            .find_map(|(idx, (&l, &r))| if l > r { Some(idx) } else { None })\n+            .or_else(|| {\n                 if l_slice.len() > r_slice.len() {\n-\n                     // By invariant, if l_slice is longer\n                     // then one element must be larger.\n                     // This just validates that this is true\n                     // and reports earlier elements first.\n                     let l_remainder_slice = &l_slice[r_slice.len()..];\n-                    let idx = l_remainder_slice.iter().enumerate()\n-                        .find_map(|(idx, &r)| {\n-                            if r == 0 { None } else { Some(idx) }\n-                        }).expect(\"Invalid VClock Invariant\");\n+                    let idx = l_remainder_slice\n+                        .iter()\n+                        .enumerate()\n+                        .find_map(|(idx, &r)| if r == 0 { None } else { Some(idx) })\n+                        .expect(\"Invalid VClock Invariant\");\n                     Some(idx)\n                 } else {\n                     None\n                 }\n-            }).map(|idx| VectorIdx::new(idx))\n+            })\n+            .map(|idx| VectorIdx::new(idx))\n     }\n \n     /// Report a data-race found in the program.\n@@ -684,39 +689,42 @@ impl VClockAlloc {\n     #[cold]\n     #[inline(never)]\n     fn report_data_race<'tcx>(\n-        global: &MemoryExtra, range: &MemoryCellClocks,\n-        action: &str, is_atomic: bool,\n-        pointer: Pointer<Tag>, len: Size\n+        global: &MemoryExtra,\n+        range: &MemoryCellClocks,\n+        action: &str,\n+        is_atomic: bool,\n+        pointer: Pointer<Tag>,\n+        len: Size,\n     ) -> InterpResult<'tcx> {\n         let (current_index, current_clocks) = global.current_thread_state();\n         let write_clock;\n-        let (\n-            other_action, other_thread, other_clock\n-        ) = if range.write > current_clocks.clock[range.write_index] {\n-\n+        let (other_action, other_thread, other_clock) = if range.write\n+            > current_clocks.clock[range.write_index]\n+        {\n             // Convert the write action into the vector clock it\n             // represents for diagnostic purposes.\n             write_clock = VClock::new_with_index(range.write_index, range.write);\n             (\"WRITE\", range.write_index, &write_clock)\n-        } else if let Some(idx) = Self::find_gt_index(\n-            &range.read, &current_clocks.clock\n-        ){\n+        } else if let Some(idx) = Self::find_gt_index(&range.read, &current_clocks.clock) {\n             (\"READ\", idx, &range.read)\n         } else if !is_atomic {\n             if let Some(atomic) = range.atomic() {\n-                if let Some(idx) = Self::find_gt_index(\n-                    &atomic.write_vector, &current_clocks.clock\n-                ) {\n+                if let Some(idx) = Self::find_gt_index(&atomic.write_vector, &current_clocks.clock)\n+                {\n                     (\"ATOMIC_STORE\", idx, &atomic.write_vector)\n-                } else if let Some(idx) = Self::find_gt_index(\n-                    &atomic.read_vector, &current_clocks.clock\n-                ) {\n+                } else if let Some(idx) =\n+                    Self::find_gt_index(&atomic.read_vector, &current_clocks.clock)\n+                {\n                     (\"ATOMIC_LOAD\", idx, &atomic.read_vector)\n                 } else {\n-                    unreachable!(\"Failed to report data-race for non-atomic operation: no race found\")\n+                    unreachable!(\n+                        \"Failed to report data-race for non-atomic operation: no race found\"\n+                    )\n                 }\n             } else {\n-                unreachable!(\"Failed to report data-race for non-atomic operation: no atomic component\")\n+                unreachable!(\n+                    \"Failed to report data-race for non-atomic operation: no atomic component\"\n+                )\n             }\n         } else {\n             unreachable!(\"Failed to report data-race for atomic operation\")\n@@ -725,15 +733,19 @@ impl VClockAlloc {\n         // Load elaborated thread information about the racing thread actions.\n         let current_thread_info = global.print_thread_metadata(current_index);\n         let other_thread_info = global.print_thread_metadata(other_thread);\n-        \n+\n         // Throw the data-race detection.\n         throw_ub_format!(\n             \"Data race detected between {} on {} and {} on {}, memory({:?},offset={},size={})\\\n             \\n\\t\\t -current vector clock = {:?}\\\n             \\n\\t\\t -conflicting timestamp = {:?}\",\n-            action, current_thread_info, \n-            other_action, other_thread_info,\n-            pointer.alloc_id, pointer.offset.bytes(), len.bytes(),\n+            action,\n+            current_thread_info,\n+            other_action,\n+            other_thread_info,\n+            pointer.alloc_id,\n+            pointer.offset.bytes(),\n+            len.bytes(),\n             current_clocks.clock,\n             other_clock\n         )\n@@ -748,12 +760,16 @@ impl VClockAlloc {\n         if self.global.multi_threaded.get() {\n             let (index, clocks) = self.global.current_thread_state();\n             let mut alloc_ranges = self.alloc_ranges.borrow_mut();\n-            for (_,range) in alloc_ranges.iter_mut(pointer.offset, len) {\n+            for (_, range) in alloc_ranges.iter_mut(pointer.offset, len) {\n                 if let Err(DataRace) = range.read_race_detect(&*clocks, index) {\n-\n                     // Report data-race.\n                     return Self::report_data_race(\n-                        &self.global,range, \"READ\", false, pointer, len\n+                        &self.global,\n+                        range,\n+                        \"READ\",\n+                        false,\n+                        pointer,\n+                        len,\n                     );\n                 }\n             }\n@@ -763,17 +779,25 @@ impl VClockAlloc {\n         }\n     }\n \n-\n     // Shared code for detecting data-races on unique access to a section of memory\n-    fn unique_access<'tcx>(&mut self, pointer: Pointer<Tag>, len: Size, action: &str) -> InterpResult<'tcx> {\n+    fn unique_access<'tcx>(\n+        &mut self,\n+        pointer: Pointer<Tag>,\n+        len: Size,\n+        action: &str,\n+    ) -> InterpResult<'tcx> {\n         if self.global.multi_threaded.get() {\n             let (index, clocks) = self.global.current_thread_state();\n-            for (_,range) in self.alloc_ranges.get_mut().iter_mut(pointer.offset, len) {\n+            for (_, range) in self.alloc_ranges.get_mut().iter_mut(pointer.offset, len) {\n                 if let Err(DataRace) = range.write_race_detect(&*clocks, index) {\n-                    \n                     // Report data-race\n                     return Self::report_data_race(\n-                        &self.global, range, action, false, pointer, len\n+                        &self.global,\n+                        range,\n+                        action,\n+                        false,\n+                        pointer,\n+                        len,\n                     );\n                 }\n             }\n@@ -802,7 +826,6 @@ impl VClockAlloc {\n \n impl<'mir, 'tcx: 'mir> EvalContextPrivExt<'mir, 'tcx> for MiriEvalContext<'mir, 'tcx> {}\n trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n-\n     // Temporarily allow data-races to occur, this should only be\n     // used if either one of the appropiate `validate_atomic` functions\n     // will be called to treat a memory access as atomic or if the memory\n@@ -827,7 +850,10 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     /// so should only be used for atomic operations or internal state that the program cannot\n     /// access.\n     #[inline]\n-    fn allow_data_races_mut<R>(&mut self, op: impl FnOnce(&mut MiriEvalContext<'mir, 'tcx>) -> R) -> R {\n+    fn allow_data_races_mut<R>(\n+        &mut self,\n+        op: impl FnOnce(&mut MiriEvalContext<'mir, 'tcx>) -> R,\n+    ) -> R {\n         let this = self.eval_context_mut();\n         let old = if let Some(data_race) = &this.memory.extra.data_race {\n             data_race.multi_threaded.replace(false)\n@@ -848,34 +874,49 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     /// FIXME: is this valid, or should get_raw_mut be used for\n     /// atomic-stores/atomic-rmw?\n     fn validate_atomic_op<A: Debug + Copy>(\n-        &self, place: MPlaceTy<'tcx, Tag>,\n-        atomic: A, description: &str,\n+        &self,\n+        place: MPlaceTy<'tcx, Tag>,\n+        atomic: A,\n+        description: &str,\n         mut op: impl FnMut(\n-            &mut MemoryCellClocks, &mut ThreadClockSet, VectorIdx, A\n-        ) -> Result<(), DataRace>\n+            &mut MemoryCellClocks,\n+            &mut ThreadClockSet,\n+            VectorIdx,\n+            A,\n+        ) -> Result<(), DataRace>,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_ref();\n         if let Some(data_race) = &this.memory.extra.data_race {\n             if data_race.multi_threaded.get() {\n-\n                 // Load and log the atomic operation.\n                 let place_ptr = place.ptr.assert_ptr();\n                 let size = place.layout.size;\n-                let alloc_meta =  &this.memory.get_raw(place_ptr.alloc_id)?.extra.data_race.as_ref().unwrap();\n+                let alloc_meta =\n+                    &this.memory.get_raw(place_ptr.alloc_id)?.extra.data_race.as_ref().unwrap();\n                 log::trace!(\n                     \"Atomic op({}) with ordering {:?} on memory({:?}, offset={}, size={})\",\n-                    description, &atomic, place_ptr.alloc_id, place_ptr.offset.bytes(), size.bytes()\n+                    description,\n+                    &atomic,\n+                    place_ptr.alloc_id,\n+                    place_ptr.offset.bytes(),\n+                    size.bytes()\n                 );\n \n                 // Perform the atomic operation.\n                 let data_race = &alloc_meta.global;\n                 data_race.maybe_perform_sync_operation(|index, mut clocks| {\n-                    for (_,range) in alloc_meta.alloc_ranges.borrow_mut().iter_mut(place_ptr.offset, size) {\n+                    for (_, range) in\n+                        alloc_meta.alloc_ranges.borrow_mut().iter_mut(place_ptr.offset, size)\n+                    {\n                         if let Err(DataRace) = op(range, &mut *clocks, index, atomic) {\n                             mem::drop(clocks);\n                             return VClockAlloc::report_data_race(\n-                                &alloc_meta.global, range, description, true,\n-                                place_ptr, size\n+                                &alloc_meta.global,\n+                                range,\n+                                description,\n+                                true,\n+                                place_ptr,\n+                                size,\n                             );\n                         }\n                     }\n@@ -884,10 +925,13 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n \n                 // Log changes to atomic memory.\n                 if log::log_enabled!(log::Level::Trace) {\n-                    for (_,range) in alloc_meta.alloc_ranges.borrow().iter(place_ptr.offset, size) {\n+                    for (_, range) in alloc_meta.alloc_ranges.borrow().iter(place_ptr.offset, size)\n+                    {\n                         log::trace!(\n                             \"Updated atomic memory({:?}, offset={}, size={}) to {:#?}\",\n-                            place.ptr.assert_ptr().alloc_id, place_ptr.offset.bytes(), size.bytes(),\n+                            place.ptr.assert_ptr().alloc_id,\n+                            place_ptr.offset.bytes(),\n+                            size.bytes(),\n                             range.atomic_ops\n                         );\n                     }\n@@ -896,14 +940,11 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         }\n         Ok(())\n     }\n-\n }\n \n-\n /// Extra metadata associated with a thread.\n #[derive(Debug, Clone, Default)]\n struct ThreadExtraState {\n-\n     /// The current vector index in use by the\n     /// thread currently, this is set to None\n     /// after the vector index has been re-used\n@@ -915,7 +956,7 @@ struct ThreadExtraState {\n     /// diagnostics when reporting detected data\n     /// races.\n     thread_name: Option<Box<str>>,\n-    \n+\n     /// Thread termination vector clock, this\n     /// is set on thread termination and is used\n     /// for joining on threads since the vector_index\n@@ -928,7 +969,6 @@ struct ThreadExtraState {\n /// with each of the threads.\n #[derive(Debug, Clone)]\n pub struct GlobalState {\n-\n     /// Set to true once the first additional\n     /// thread has launched, due to the dependency\n     /// between before and after a thread launch.\n@@ -966,7 +1006,7 @@ pub struct GlobalState {\n     /// if the number of active threads reduces to 1 and then\n     /// a join operation occures with the remaining main thread\n     /// then multi-threaded execution may be disabled.\n-    active_thread_count: Cell<usize>, \n+    active_thread_count: Cell<usize>,\n \n     /// This contains threads that have terminated, but not yet joined\n     /// and so cannot become re-use candidates until a join operation\n@@ -977,7 +1017,6 @@ pub struct GlobalState {\n }\n \n impl GlobalState {\n-\n     /// Create a new global state, setup with just thread-id=0\n     /// advanced to timestamp = 1.\n     pub fn new() -> Self {\n@@ -989,57 +1028,53 @@ impl GlobalState {\n             current_index: Cell::new(VectorIdx::new(0)),\n             active_thread_count: Cell::new(1),\n             reuse_candidates: RefCell::new(FxHashSet::default()),\n-            terminated_threads: RefCell::new(FxHashMap::default())\n+            terminated_threads: RefCell::new(FxHashMap::default()),\n         };\n \n         // Setup the main-thread since it is not explicitly created:\n         // uses vector index and thread-id 0, also the rust runtime gives\n         // the main-thread a name of \"main\".\n         let index = global_state.vector_clocks.borrow_mut().push(ThreadClockSet::default());\n         global_state.vector_info.borrow_mut().push(ThreadId::new(0));\n-        global_state.thread_info.borrow_mut().push(\n-            ThreadExtraState {\n-                vector_index: Some(index),\n-                thread_name: Some(\"main\".to_string().into_boxed_str()),\n-                termination_vector_clock: None\n-            }\n-        );\n+        global_state.thread_info.borrow_mut().push(ThreadExtraState {\n+            vector_index: Some(index),\n+            thread_name: Some(\"main\".to_string().into_boxed_str()),\n+            termination_vector_clock: None,\n+        });\n \n         global_state\n     }\n-    \n+\n     // Try to find vector index values that can potentially be re-used\n     // by a new thread instead of a new vector index being created.\n     fn find_vector_index_reuse_candidate(&self) -> Option<VectorIdx> {\n         let mut reuse = self.reuse_candidates.borrow_mut();\n         let vector_clocks = self.vector_clocks.borrow();\n         let vector_info = self.vector_info.borrow();\n         let terminated_threads = self.terminated_threads.borrow();\n-        for  &candidate in reuse.iter() {\n+        for &candidate in reuse.iter() {\n             let target_timestamp = vector_clocks[candidate].clock[candidate];\n             if vector_clocks.iter_enumerated().all(|(clock_idx, clock)| {\n-\n                 // The thread happens before the clock, and hence cannot report\n                 // a data-race with this the candidate index.\n                 let no_data_race = clock.clock[candidate] >= target_timestamp;\n \n                 // The vector represents a thread that has terminated and hence cannot\n                 // report a data-race with the candidate index.\n                 let thread_id = vector_info[clock_idx];\n-                let vector_terminated = reuse.contains(&clock_idx)\n-                    || terminated_threads.contains_key(&thread_id);\n+                let vector_terminated =\n+                    reuse.contains(&clock_idx) || terminated_threads.contains_key(&thread_id);\n \n                 // The vector index cannot report a race with the candidate index\n                 // and hence allows the candidate index to be re-used.\n                 no_data_race || vector_terminated\n             }) {\n-\n                 // All vector clocks for each vector index are equal to\n                 // the target timestamp, and the thread is known to have\n                 // terminated, therefore this vector clock index cannot\n                 // report any more data-races.\n                 assert!(reuse.remove(&candidate));\n-                return Some(candidate)\n+                return Some(candidate);\n             }\n         }\n         None\n@@ -1065,10 +1100,7 @@ impl GlobalState {\n \n         // Assign a vector index for the thread, attempting to re-use an old\n         // vector index that can no longer report any data-races if possible.\n-        let created_index = if let Some(\n-            reuse_index\n-        ) = self.find_vector_index_reuse_candidate() {\n-\n+        let created_index = if let Some(reuse_index) = self.find_vector_index_reuse_candidate() {\n             // Now re-configure the re-use candidate, increment the clock\n             // for the new sync use of the vector.\n             let mut vector_clocks = self.vector_clocks.borrow_mut();\n@@ -1086,7 +1118,6 @@ impl GlobalState {\n \n             reuse_index\n         } else {\n-\n             // No vector re-use candidates available, instead create\n             // a new vector index.\n             let mut vector_info = self.vector_info.borrow_mut();\n@@ -1125,13 +1156,16 @@ impl GlobalState {\n         let thread_info = self.thread_info.borrow();\n \n         // Load the vector clock of the current thread.\n-        let current_index = thread_info[current_thread].vector_index\n+        let current_index = thread_info[current_thread]\n+            .vector_index\n             .expect(\"Performed thread join on thread with no assigned vector\");\n         let current = &mut clocks_vec[current_index];\n \n         // Load the associated vector clock for the terminated thread.\n-        let join_clock = thread_info[join_thread].termination_vector_clock\n-            .as_ref().expect(\"Joined with thread but thread has not terminated\");\n+        let join_clock = thread_info[join_thread]\n+            .termination_vector_clock\n+            .as_ref()\n+            .expect(\"Joined with thread but thread has not terminated\");\n \n         // Pre increment clocks before atomic operation.\n         current.increment_clock(current_index);\n@@ -1147,13 +1181,12 @@ impl GlobalState {\n         // then test for potentially disabling multi-threaded execution.\n         let active_threads = self.active_thread_count.get();\n         if active_threads == 1 {\n-\n             // May potentially be able to disable multi-threaded execution.\n             let current_clock = &clocks_vec[current_index];\n-            if clocks_vec.iter_enumerated().all(|(idx, clocks)| {\n-                clocks.clock[idx] <= current_clock.clock[idx]\n-            }) {\n-\n+            if clocks_vec\n+                .iter_enumerated()\n+                .all(|(idx, clocks)| clocks.clock[idx] <= current_clock.clock[idx])\n+            {\n                 // The all thread termations happen-before the current clock\n                 // therefore no data-races can be reported until a new thread\n                 // is created, so disable multi-threaded execution.\n@@ -1180,7 +1213,7 @@ impl GlobalState {\n     #[inline]\n     pub fn thread_terminated(&self) {\n         let current_index = self.current_index();\n-        \n+\n         // Increment the clock to a unique termination timestamp.\n         let mut vector_clocks = self.vector_clocks.borrow_mut();\n         let current_clocks = &mut vector_clocks[current_index];\n@@ -1201,7 +1234,7 @@ impl GlobalState {\n         // occurs.\n         let mut termination = self.terminated_threads.borrow_mut();\n         termination.insert(current_thread, current_index);\n-            \n+\n         // Reduce the number of active threads, now that a thread has\n         // terminated.\n         let mut active_threads = self.active_thread_count.get();\n@@ -1215,7 +1248,8 @@ impl GlobalState {\n     #[inline]\n     pub fn thread_set_active(&self, thread: ThreadId) {\n         let thread_info = self.thread_info.borrow();\n-        let vector_idx = thread_info[thread].vector_index\n+        let vector_idx = thread_info[thread]\n+            .vector_index\n             .expect(\"Setting thread active with no assigned vector\");\n         self.current_index.set(vector_idx);\n     }\n@@ -1231,7 +1265,6 @@ impl GlobalState {\n         thread_info[thread].thread_name = Some(name);\n     }\n \n-\n     /// Attempt to perform a synchronized operation, this\n     /// will perform no operation if multi-threading is\n     /// not currently enabled.\n@@ -1240,7 +1273,8 @@ impl GlobalState {\n     /// detection between any happens-before edges the\n     /// operation may create.\n     fn maybe_perform_sync_operation<'tcx>(\n-        &self, op: impl FnOnce(VectorIdx, RefMut<'_,ThreadClockSet>) -> InterpResult<'tcx>,\n+        &self,\n+        op: impl FnOnce(VectorIdx, RefMut<'_, ThreadClockSet>) -> InterpResult<'tcx>,\n     ) -> InterpResult<'tcx> {\n         if self.multi_threaded.get() {\n             let (index, mut clocks) = self.current_thread_state_mut();\n@@ -1251,7 +1285,6 @@ impl GlobalState {\n         }\n         Ok(())\n     }\n-    \n \n     /// Internal utility to identify a thread stored internally\n     /// returns the id and the name for better diagnostics.\n@@ -1266,7 +1299,6 @@ impl GlobalState {\n         }\n     }\n \n-\n     /// Acquire a lock, express that the previous call of\n     /// `validate_lock_release` must happen before this.\n     pub fn validate_lock_acquire(&self, lock: &VClock, thread: ThreadId) {\n@@ -1300,7 +1332,8 @@ impl GlobalState {\n     /// used by the thread.\n     #[inline]\n     fn load_thread_state_mut(&self, thread: ThreadId) -> (VectorIdx, RefMut<'_, ThreadClockSet>) {\n-        let index = self.thread_info.borrow()[thread].vector_index\n+        let index = self.thread_info.borrow()[thread]\n+            .vector_index\n             .expect(\"Loading thread state for thread with no assigned vector\");\n         let ref_vector = self.vector_clocks.borrow_mut();\n         let clocks = RefMut::map(ref_vector, |vec| &mut vec[index]);"}, {"sha": "ddee98bcf624c274c9c9aa9d04d3be559776c8a1", "filename": "src/vector_clock.rs", "status": "modified", "additions": 124, "deletions": 109, "changes": 233, "blob_url": "https://github.com/rust-lang/rust/blob/0b0264fc820d12d6c5e6f9f702bc33e8921bb110/src%2Fvector_clock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b0264fc820d12d6c5e6f9f702bc33e8921bb110/src%2Fvector_clock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fvector_clock.rs?ref=0b0264fc820d12d6c5e6f9f702bc33e8921bb110", "patch": "@@ -1,10 +1,13 @@\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_index::vec::Idx;\n+use smallvec::SmallVec;\n use std::{\n-    fmt::{self, Debug}, cmp::Ordering, ops::Index,\n-    convert::TryFrom, mem\n+    cmp::Ordering,\n+    convert::TryFrom,\n+    fmt::{self, Debug},\n+    mem,\n+    ops::Index,\n };\n-use smallvec::SmallVec;\n-use rustc_index::vec::Idx;\n-use rustc_data_structures::fx::FxHashMap;\n \n /// A vector clock index, this is associated with a thread id\n /// but in some cases one vector index may be shared with\n@@ -13,18 +16,15 @@ use rustc_data_structures::fx::FxHashMap;\n pub struct VectorIdx(u32);\n \n impl VectorIdx {\n-\n     #[inline(always)]\n     pub fn to_u32(self) -> u32 {\n         self.0\n     }\n \n     pub const MAX_INDEX: VectorIdx = VectorIdx(u32::MAX);\n-\n }\n \n impl Idx for VectorIdx {\n-\n     #[inline]\n     fn new(idx: usize) -> Self {\n         VectorIdx(u32::try_from(idx).unwrap())\n@@ -34,16 +34,13 @@ impl Idx for VectorIdx {\n     fn index(self) -> usize {\n         usize::try_from(self.0).unwrap()\n     }\n-\n }\n \n impl From<u32> for VectorIdx {\n-\n     #[inline]\n     fn from(id: u32) -> Self {\n         Self(id)\n     }\n-\n }\n \n /// A sparse mapping of vector index values to vector clocks, this\n@@ -52,7 +49,7 @@ impl From<u32> for VectorIdx {\n /// This is used to store the set of currently active release\n /// sequences at a given memory location, since RMW operations\n /// allow for multiple release sequences to be active at once\n-/// and to be collapsed back to one active release sequence \n+/// and to be collapsed back to one active release sequence\n /// once a non RMW atomic store operation occurs.\n /// An all zero vector is considered to be equal to no\n /// element stored internally since it will never be\n@@ -63,26 +60,22 @@ pub struct VSmallClockMap(VSmallClockMapInner);\n \n #[derive(Clone)]\n enum VSmallClockMapInner {\n-\n     /// Zero or 1 vector elements, common\n     /// case for the sparse set.\n     /// The all zero vector clock is treated\n     /// as equal to the empty element.\n     Small(VectorIdx, VClock),\n \n     /// Hash-map of vector clocks.\n-    Large(FxHashMap<VectorIdx, VClock>)\n+    Large(FxHashMap<VectorIdx, VClock>),\n }\n \n impl VSmallClockMap {\n-\n     /// Remove all clock vectors from the map, setting them\n     /// to the zero vector.\n     pub fn clear(&mut self) {\n         match &mut self.0 {\n-            VSmallClockMapInner::Small(_, clock) => {\n-                clock.set_zero_vector()\n-            }\n+            VSmallClockMapInner::Small(_, clock) => clock.set_zero_vector(),\n             VSmallClockMapInner::Large(hash_map) => {\n                 hash_map.clear();\n             }\n@@ -95,12 +88,11 @@ impl VSmallClockMap {\n         match &mut self.0 {\n             VSmallClockMapInner::Small(small_idx, clock) => {\n                 if index != *small_idx {\n-\n                     // The zero-vector is considered to equal\n                     // the empty element.\n                     clock.set_zero_vector()\n                 }\n-            },\n+            }\n             VSmallClockMapInner::Large(hash_map) => {\n                 let value = hash_map.remove(&index).unwrap_or_default();\n                 self.0 = VSmallClockMapInner::Small(index, value);\n@@ -114,23 +106,20 @@ impl VSmallClockMap {\n         match &mut self.0 {\n             VSmallClockMapInner::Small(small_idx, small_clock) => {\n                 if small_clock.is_zero_vector() {\n-\n                     *small_idx = index;\n                     small_clock.clone_from(clock);\n                 } else if !clock.is_zero_vector() {\n-\n                     // Convert to using the hash-map representation.\n                     let mut hash_map = FxHashMap::default();\n                     hash_map.insert(*small_idx, mem::take(small_clock));\n                     hash_map.insert(index, clock.clone());\n                     self.0 = VSmallClockMapInner::Large(hash_map);\n                 }\n-            },\n-            VSmallClockMapInner::Large(hash_map) => {\n+            }\n+            VSmallClockMapInner::Large(hash_map) =>\n                 if !clock.is_zero_vector() {\n                     hash_map.insert(index, clock.clone());\n-                }\n-            }\n+                },\n         }\n     }\n \n@@ -144,51 +133,39 @@ impl VSmallClockMap {\n                 } else {\n                     None\n                 }\n-            },\n-            VSmallClockMapInner::Large(hash_map) => {\n-                hash_map.get(&index)\n             }\n+            VSmallClockMapInner::Large(hash_map) => hash_map.get(&index),\n         }\n     }\n }\n \n impl Default for VSmallClockMap {\n-\n     #[inline]\n     fn default() -> Self {\n-        VSmallClockMap(\n-            VSmallClockMapInner::Small(VectorIdx::new(0), VClock::default())\n-        )\n+        VSmallClockMap(VSmallClockMapInner::Small(VectorIdx::new(0), VClock::default()))\n     }\n-\n }\n \n impl Debug for VSmallClockMap {\n-\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         // Print the contents of the small vector clock set as the map\n         // of vector index to vector clock that they represent.\n         let mut map = f.debug_map();\n         match &self.0 {\n-            VSmallClockMapInner::Small(small_idx, small_clock) => {\n+            VSmallClockMapInner::Small(small_idx, small_clock) =>\n                 if !small_clock.is_zero_vector() {\n                     map.entry(&small_idx, &small_clock);\n-                }\n-            },\n-            VSmallClockMapInner::Large(hash_map) => {\n+                },\n+            VSmallClockMapInner::Large(hash_map) =>\n                 for (idx, elem) in hash_map.iter() {\n                     map.entry(idx, elem);\n-                }\n-            }\n+                },\n         }\n         map.finish()\n     }\n-\n }\n \n-\n impl PartialEq for VSmallClockMap {\n-\n     fn eq(&self, other: &Self) -> bool {\n         use VSmallClockMapInner::*;\n         match (&self.0, &other.0) {\n@@ -201,9 +178,7 @@ impl PartialEq for VSmallClockMap {\n                     i1 == i2 && c1 == c2\n                 }\n             }\n-            (Small(idx, clock), Large(hash_map)) |\n-            (Large(hash_map), Small(idx, clock)) => {\n-\n+            (Small(idx, clock), Large(hash_map)) | (Large(hash_map), Small(idx, clock)) => {\n                 if hash_map.len() == 0 {\n                     // Equal to the empty hash-map\n                     clock.is_zero_vector()\n@@ -215,18 +190,13 @@ impl PartialEq for VSmallClockMap {\n                     false\n                 }\n             }\n-            (Large(map1), Large(map2)) => {\n-                map1 == map2\n-            }\n+            (Large(map1), Large(map2)) => map1 == map2,\n         }\n     }\n-\n }\n \n impl Eq for VSmallClockMap {}\n \n-\n-\n /// The size of the vector-clock to store inline\n /// clock vectors larger than this will be stored on the heap\n const SMALL_VECTOR: usize = 4;\n@@ -249,7 +219,6 @@ pub type VTimestamp = u32;\n pub struct VClock(SmallVec<[VTimestamp; SMALL_VECTOR]>);\n \n impl VClock {\n-\n     /// Create a new vector-clock containing all zeros except\n     /// for a value at the given index\n     pub fn new_with_index(index: VectorIdx, timestamp: VTimestamp) -> VClock {\n@@ -316,11 +285,9 @@ impl VClock {\n     pub fn is_zero_vector(&self) -> bool {\n         self.0.is_empty()\n     }\n-\n }\n \n impl Clone for VClock {\n-\n     fn clone(&self) -> Self {\n         VClock(self.0.clone())\n     }\n@@ -334,13 +301,10 @@ impl Clone for VClock {\n         self.0.clear();\n         self.0.extend_from_slice(source_slice);\n     }\n-\n }\n \n impl PartialOrd for VClock {\n-\n     fn partial_cmp(&self, other: &VClock) -> Option<Ordering> {\n-\n         // Load the values as slices\n         let lhs_slice = self.as_slice();\n         let rhs_slice = other.as_slice();\n@@ -356,17 +320,19 @@ impl PartialOrd for VClock {\n         let mut iter = lhs_slice.iter().zip(rhs_slice.iter());\n         let mut order = match iter.next() {\n             Some((lhs, rhs)) => lhs.cmp(rhs),\n-            None => Ordering::Equal\n+            None => Ordering::Equal,\n         };\n         for (l, r) in iter {\n             match order {\n                 Ordering::Equal => order = l.cmp(r),\n-                Ordering::Less => if l > r {\n-                    return None\n-                },\n-                Ordering::Greater => if l < r {\n-                    return None\n-                }\n+                Ordering::Less =>\n+                    if l > r {\n+                        return None;\n+                    },\n+                Ordering::Greater =>\n+                    if l < r {\n+                        return None;\n+                    },\n             }\n         }\n \n@@ -383,14 +349,14 @@ impl PartialOrd for VClock {\n             // so the only valid values are Ordering::Less or None.\n             Ordering::Less => match order {\n                 Ordering::Less | Ordering::Equal => Some(Ordering::Less),\n-                Ordering::Greater => None\n-            }\n+                Ordering::Greater => None,\n+            },\n             // Left has at least 1 element > than the implicit 0,\n             // so the only valid values are Ordering::Greater or None.\n             Ordering::Greater => match order {\n                 Ordering::Greater | Ordering::Equal => Some(Ordering::Greater),\n-                Ordering::Less => None\n-            }\n+                Ordering::Less => None,\n+            },\n         }\n     }\n \n@@ -415,13 +381,13 @@ impl PartialOrd for VClock {\n             let mut equal = l_len == r_len;\n             for (&l, &r) in lhs_slice.iter().zip(rhs_slice.iter()) {\n                 if l > r {\n-                    return false\n+                    return false;\n                 } else if l < r {\n                     equal = false;\n                 }\n             }\n             !equal\n-         } else {\n+        } else {\n             false\n         }\n     }\n@@ -469,7 +435,7 @@ impl PartialOrd for VClock {\n             let mut equal = l_len == r_len;\n             for (&l, &r) in lhs_slice.iter().zip(rhs_slice.iter()) {\n                 if l < r {\n-                    return false\n+                    return false;\n                 } else if l > r {\n                     equal = false;\n                 }\n@@ -501,28 +467,24 @@ impl PartialOrd for VClock {\n             false\n         }\n     }\n-\n }\n \n impl Index<VectorIdx> for VClock {\n-\n     type Output = VTimestamp;\n \n     #[inline]\n     fn index(&self, index: VectorIdx) -> &VTimestamp {\n-       self.as_slice().get(index.to_u32() as usize).unwrap_or(&0)\n+        self.as_slice().get(index.to_u32() as usize).unwrap_or(&0)\n     }\n-\n }\n \n-\n /// Test vector clock ordering operations\n ///  data-race detection is tested in the external\n ///  test suite\n #[cfg(test)]\n mod tests {\n \n-    use super::{VClock, VTimestamp, VectorIdx, VSmallClockMap};\n+    use super::{VClock, VSmallClockMap, VTimestamp, VectorIdx};\n     use std::cmp::Ordering;\n \n     #[test]\n@@ -546,19 +508,43 @@ mod tests {\n         assert_order(&[1], &[1], Some(Ordering::Equal));\n         assert_order(&[1], &[2], Some(Ordering::Less));\n         assert_order(&[2], &[1], Some(Ordering::Greater));\n-        assert_order(&[1], &[1,2], Some(Ordering::Less));\n-        assert_order(&[2], &[1,2], None);\n+        assert_order(&[1], &[1, 2], Some(Ordering::Less));\n+        assert_order(&[2], &[1, 2], None);\n \n         // Misc tests\n         assert_order(&[400], &[0, 1], None);\n \n         // Large test\n-        assert_order(&[0,1,2,3,4,5,6,7,8,9,10], &[0,1,2,3,4,5,6,7,8,9,10,0,0,0], Some(Ordering::Equal));\n-        assert_order(&[0,1,2,3,4,5,6,7,8,9,10], &[0,1,2,3,4,5,6,7,8,9,10,0,1,0], Some(Ordering::Less));\n-        assert_order(&[0,1,2,3,4,5,6,7,8,9,11], &[0,1,2,3,4,5,6,7,8,9,10,0,0,0], Some(Ordering::Greater));\n-        assert_order(&[0,1,2,3,4,5,6,7,8,9,11], &[0,1,2,3,4,5,6,7,8,9,10,0,1,0], None);\n-        assert_order(&[0,1,2,3,4,5,6,7,8,9,9 ], &[0,1,2,3,4,5,6,7,8,9,10,0,0,0], Some(Ordering::Less));\n-        assert_order(&[0,1,2,3,4,5,6,7,8,9,9 ], &[0,1,2,3,4,5,6,7,8,9,10,0,1,0], Some(Ordering::Less));\n+        assert_order(\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0],\n+            Some(Ordering::Equal),\n+        );\n+        assert_order(\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 0],\n+            Some(Ordering::Less),\n+        );\n+        assert_order(\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11],\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0],\n+            Some(Ordering::Greater),\n+        );\n+        assert_order(\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11],\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 0],\n+            None,\n+        );\n+        assert_order(\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9],\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0],\n+            Some(Ordering::Less),\n+        );\n+        assert_order(\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9],\n+            &[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 0],\n+            Some(Ordering::Less),\n+        );\n     }\n \n     fn from_slice(mut slice: &[VTimestamp]) -> VClock {\n@@ -574,51 +560,81 @@ mod tests {\n \n         //Test partial_cmp\n         let compare = l.partial_cmp(&r);\n-        assert_eq!(compare, o, \"Invalid comparison\\n l: {:?}\\n r: {:?}\",l,r);\n+        assert_eq!(compare, o, \"Invalid comparison\\n l: {:?}\\n r: {:?}\", l, r);\n         let alt_compare = r.partial_cmp(&l);\n-        assert_eq!(alt_compare, o.map(Ordering::reverse), \"Invalid alt comparison\\n l: {:?}\\n r: {:?}\",l,r);\n+        assert_eq!(\n+            alt_compare,\n+            o.map(Ordering::reverse),\n+            \"Invalid alt comparison\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n+        );\n \n         //Test operators with faster implementations\n         assert_eq!(\n-            matches!(compare,Some(Ordering::Less)), l < r,\n-            \"Invalid (<):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(compare, Some(Ordering::Less)),\n+            l < r,\n+            \"Invalid (<):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(compare,Some(Ordering::Less) | Some(Ordering::Equal)), l <= r,\n-            \"Invalid (<=):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(compare, Some(Ordering::Less) | Some(Ordering::Equal)),\n+            l <= r,\n+            \"Invalid (<=):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(compare,Some(Ordering::Greater)), l > r,\n-            \"Invalid (>):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(compare, Some(Ordering::Greater)),\n+            l > r,\n+            \"Invalid (>):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(compare,Some(Ordering::Greater) | Some(Ordering::Equal)), l >= r,\n-            \"Invalid (>=):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(compare, Some(Ordering::Greater) | Some(Ordering::Equal)),\n+            l >= r,\n+            \"Invalid (>=):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(alt_compare,Some(Ordering::Less)), r < l,\n-            \"Invalid alt (<):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(alt_compare, Some(Ordering::Less)),\n+            r < l,\n+            \"Invalid alt (<):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(alt_compare,Some(Ordering::Less) | Some(Ordering::Equal)), r <= l,\n-            \"Invalid alt (<=):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(alt_compare, Some(Ordering::Less) | Some(Ordering::Equal)),\n+            r <= l,\n+            \"Invalid alt (<=):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(alt_compare,Some(Ordering::Greater)), r > l,\n-            \"Invalid alt (>):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(alt_compare, Some(Ordering::Greater)),\n+            r > l,\n+            \"Invalid alt (>):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n         assert_eq!(\n-            matches!(alt_compare,Some(Ordering::Greater) | Some(Ordering::Equal)), r >= l,\n-            \"Invalid alt (>=):\\n l: {:?}\\n r: {:?}\",l,r\n+            matches!(alt_compare, Some(Ordering::Greater) | Some(Ordering::Equal)),\n+            r >= l,\n+            \"Invalid alt (>=):\\n l: {:?}\\n r: {:?}\",\n+            l,\n+            r\n         );\n     }\n \n     #[test]\n     pub fn test_vclock_set() {\n         let mut map = VSmallClockMap::default();\n-        let v1 = from_slice(&[3,0,1]);\n-        let v2 = from_slice(&[4,2,3]);\n-        let v3 = from_slice(&[4,8,3]);\n+        let v1 = from_slice(&[3, 0, 1]);\n+        let v2 = from_slice(&[4, 2, 3]);\n+        let v3 = from_slice(&[4, 8, 3]);\n         map.insert(VectorIdx(0), &v1);\n         assert_eq!(map.get(VectorIdx(0)), Some(&v1));\n         map.insert(VectorIdx(5), &v2);\n@@ -641,5 +657,4 @@ mod tests {\n         assert_eq!(map.get(VectorIdx(5)), None);\n         assert_eq!(map.get(VectorIdx(53)), Some(&v3));\n     }\n-    \n }"}]}