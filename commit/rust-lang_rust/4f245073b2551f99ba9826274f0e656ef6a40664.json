{"sha": "4f245073b2551f99ba9826274f0e656ef6a40664", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRmMjQ1MDczYjI1NTFmOTliYTk4MjYyNzRmMGU2NTZlZjZhNDA2NjQ=", "commit": {"author": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2017-08-17T21:45:01Z"}, "committer": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2017-09-10T20:09:18Z"}, "message": "implement unsafe pointer methods", "tree": {"sha": "a6eaa8858dac9fef1b664e9b7a381d225bc34dd6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a6eaa8858dac9fef1b664e9b7a381d225bc34dd6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4f245073b2551f99ba9826274f0e656ef6a40664", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4f245073b2551f99ba9826274f0e656ef6a40664", "html_url": "https://github.com/rust-lang/rust/commit/4f245073b2551f99ba9826274f0e656ef6a40664", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4f245073b2551f99ba9826274f0e656ef6a40664/comments", "author": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b413f34087d913b80cf432a66d05ec5be11f3515", "url": "https://api.github.com/repos/rust-lang/rust/commits/b413f34087d913b80cf432a66d05ec5be11f3515", "html_url": "https://github.com/rust-lang/rust/commit/b413f34087d913b80cf432a66d05ec5be11f3515"}], "stats": {"total": 1186, "additions": 1174, "deletions": 12}, "files": [{"sha": "3c597e68e2e9af41de77b9867dc70e470af13079", "filename": "src/libcore/ptr.rs", "status": "modified", "additions": 1174, "deletions": 12, "changes": 1186, "blob_url": "https://github.com/rust-lang/rust/blob/4f245073b2551f99ba9826274f0e656ef6a40664/src%2Flibcore%2Fptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4f245073b2551f99ba9826274f0e656ef6a40664/src%2Flibcore%2Fptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fptr.rs?ref=4f245073b2551f99ba9826274f0e656ef6a40664", "patch": "@@ -51,7 +51,7 @@ pub use intrinsics::write_bytes;\n ///   as the compiler doesn't need to prove that it's sound to elide the\n ///   copy.\n ///\n-/// # Undefined Behavior\n+/// # Safety\n ///\n /// This has all the same safety problems as `ptr::read` with respect to\n /// invalid pointers, types, and double drops.\n@@ -525,15 +525,41 @@ impl<T: ?Sized> *const T {\n         }\n     }\n \n-    /// Calculates the offset from a pointer. `count` is in units of T; e.g. a\n-    /// `count` of 3 represents a pointer offset of `3 * size_of::<T>()` bytes.\n+    /// Calculates the offset from a pointer.\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n     ///\n     /// # Safety\n     ///\n-    /// Both the starting and resulting pointer must be either in bounds or one\n-    /// byte past the end of an allocated object. If either pointer is out of\n-    /// bounds or arithmetic overflow occurs then\n-    /// any further use of the returned value will result in undefined behavior.\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of an allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow or underflow an\n+    ///   `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum, **in bytes** must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().offset(vec.len() as isize)` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2^63 bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using `wrapping_offset` instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n     ///\n     /// # Examples\n     ///\n@@ -555,6 +581,7 @@ impl<T: ?Sized> *const T {\n     }\n \n     /// Calculates the offset from a pointer using wrapping arithmetic.\n+    ///\n     /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n     /// offset of `3 * size_of::<T>()` bytes.\n     ///\n@@ -630,6 +657,412 @@ impl<T: ?Sized> *const T {\n             Some(diff / size as isize)\n         }\n     }\n+\n+    /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of an allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow or underflow an\n+    ///   `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a `usize`.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2^63 bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using `wrapping_offset` instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let s: &str = \"123\";\n+    /// let ptr: *const u8 = s.as_ptr();\n+    ///\n+    /// unsafe {\n+    ///     println!(\"{}\", *ptr.add(1) as char);\n+    ///     println!(\"{}\", *ptr.add(2) as char);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn add(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer (convenience for\n+    /// `.offset((count as isize).wrapping_neg())`).\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of an allocated object.\n+    ///\n+    /// * The computed offset cannot exceed `isize::MAX` **bytes**.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len()).sub(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2^63 bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using `wrapping_offset` instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let s: &str = \"123\";\n+    ///\n+    /// unsafe {\n+    ///     let end: *const u8 = s.as_ptr().add(3);\n+    ///     println!(\"{}\", *end.sub(1) as char);\n+    ///     println!(\"{}\", *end.sub(2) as char);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn sub(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset(count as isize)`)\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// Always use `.add(count)` instead when possible, because `add`\n+    /// allows the compiler to optimize better.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// // Iterate using a raw pointer in increments of two elements\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let step = 2;\n+    /// let end_rounded_up = ptr.wrapping_add(6);\n+    ///\n+    /// // This loop prints \"1, 3, 5, \"\n+    /// while ptr != end_rounded_up {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_add(step);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub fn wrapping_add(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.wrapping_offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset((count as isize).wrapping_sub())`)\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// Always use `.sub(count)` instead when possible, because `sub`\n+    /// allows the compiler to optimize better.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// // Iterate using a raw pointer in increments of two elements (backwards)\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let start_rounded_down = ptr.wrapping_sub(2);\n+    /// ptr = ptr.wrapping_add(4);\n+    /// let step = 2;\n+    /// // This loop prints \"5, 3, 1, \"\n+    /// while ptr != start_rounded_down {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_sub(step);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub fn wrapping_sub(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.wrapping_offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond accepting a raw pointer, this is unsafe because it semantically\n+    /// moves the value out of `self` without preventing further usage of `self`.\n+    /// If `T` is not `Copy`, then care must be taken to ensure that the value at\n+    /// `self` is not used before the data is overwritten again (e.g. with `write`,\n+    /// `zero_memory`, or `copy_memory`). Note that `*self = foo` counts as a use\n+    /// because it will attempt to drop the value previously at `*self`.\n+    ///\n+    /// The pointer must be aligned; use `read_unaligned` if that is not the case.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let x = 12;\n+    /// let y = &x as *const i32;\n+    ///\n+    /// unsafe {\n+    ///     assert_eq!(y.read(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn read(self) -> T\n+        where T: Sized,\n+    {\n+        read(self)\n+    }\n+\n+    /// Performs a volatile read of the value from `self` without moving it. This\n+    /// leaves the memory in `self` unchanged.\n+    ///\n+    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n+    /// to not be elided or reordered by the compiler across other volatile\n+    /// operations.\n+    ///\n+    /// # Notes\n+    ///\n+    /// Rust does not currently have a rigorously and formally defined memory model,\n+    /// so the precise semantics of what \"volatile\" means here is subject to change\n+    /// over time. That being said, the semantics will almost always end up pretty\n+    /// similar to [C11's definition of volatile][c11].\n+    ///\n+    /// The compiler shouldn't change the relative order or number of volatile\n+    /// memory operations. However, volatile memory operations on zero-sized types\n+    /// (e.g. if a zero-sized type is passed to `read_volatile`) are no-ops\n+    /// and may be ignored.\n+    ///\n+    /// [c11]: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond accepting a raw pointer, this is unsafe because it semantically\n+    /// moves the value out of `self` without preventing further usage of `self`.\n+    /// If `T` is not `Copy`, then care must be taken to ensure that the value at\n+    /// `self` is not used before the data is overwritten again (e.g. with `write`,\n+    /// `zero_memory`, or `copy_memory`). Note that `*self = foo` counts as a use\n+    /// because it will attempt to drop the value previously at `*self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let x = 12;\n+    /// let y = &x as *const i32;\n+    ///\n+    /// unsafe {\n+    ///     assert_eq!(y.read_volatile(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn read_volatile(self) -> T\n+        where T: Sized,\n+    {\n+        read_volatile(self)\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// Unlike `read`, the pointer may be unaligned.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond accepting a raw pointer, this is unsafe because it semantically\n+    /// moves the value out of `self` without preventing further usage of `self`.\n+    /// If `T` is not `Copy`, then care must be taken to ensure that the value at\n+    /// `self` is not used before the data is overwritten again (e.g. with `write`,\n+    /// `zero_memory`, or `copy_memory`). Note that `*self = foo` counts as a use\n+    /// because it will attempt to drop the value previously at `*self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let x = 12;\n+    /// let y = &x as *const i32;\n+    ///\n+    /// unsafe {\n+    ///     assert_eq!(y.read_unaligned(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn read_unaligned(self) -> T\n+        where T: Sized,\n+    {\n+        read_unaligned(self)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as `ptr::copy`.\n+    ///\n+    /// This is semantically equivalent to C's `memmove`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Care must be taken with the ownership of `self` and `dest`.\n+    /// This method semantically moves the values of `self` into `dest`.\n+    /// However it does not drop the contents of `self`, or prevent the contents\n+    /// of `dest` from being dropped or used.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Efficiently create a Rust vector from an unsafe buffer:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// # #[allow(dead_code)]\n+    /// unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n+    ///     let mut dst = Vec::with_capacity(elts);\n+    ///     dst.set_len(elts);\n+    ///     ptr.copy_to(dst.as_mut_ptr(), elts);\n+    ///     dst\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn copy_to(self, dest: *mut T, count: usize)\n+        where T: Sized,\n+    {\n+        copy(self, dest, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may *not* overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as `ptr::copy_nonoverlapping`.\n+    ///\n+    /// `copy_nonoverlapping` is semantically equivalent to C's `memcpy`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond requiring that the program must be allowed to access both regions\n+    /// of memory, it is Undefined Behavior for source and destination to\n+    /// overlap. Care must also be taken with the ownership of `self` and\n+    /// `self`. This method semantically moves the values of `self` into `dest`.\n+    /// However it does not drop the contents of `dest`, or prevent the contents\n+    /// of `self` from being dropped or used.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Efficiently create a Rust vector from an unsafe buffer:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// # #[allow(dead_code)]\n+    /// unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n+    ///     let mut dst = Vec::with_capacity(elts);\n+    ///     dst.set_len(elts);\n+    ///     ptr.copy_to_nonoverlapping(dst.as_mut_ptr(), elts);\n+    ///     dst\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)\n+        where T: Sized,\n+    {\n+        copy_nonoverlapping(self, dest, count)\n+    }\n+\n+\n }\n \n #[lang = \"mut_ptr\"]\n@@ -687,14 +1120,41 @@ impl<T: ?Sized> *mut T {\n         }\n     }\n \n-    /// Calculates the offset from a pointer. `count` is in units of T; e.g. a\n-    /// `count` of 3 represents a pointer offset of `3 * size_of::<T>()` bytes.\n+    /// Calculates the offset from a pointer.\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n     ///\n     /// # Safety\n     ///\n-    /// The offset must be in-bounds of the object, or one-byte-past-the-end.\n-    /// Otherwise `offset` invokes Undefined Behavior, regardless of whether\n-    /// the pointer is used.\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of an allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow or underflow an\n+    ///   `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum, **in bytes** must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().offset(vec.len() as isize)` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2^63 bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using `wrapping_offset` instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n     ///\n     /// # Examples\n     ///\n@@ -821,6 +1281,708 @@ impl<T: ?Sized> *mut T {\n             Some(diff / size as isize)\n         }\n     }\n+\n+\n+    /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of an allocated object.\n+    ///\n+    /// * The computed offset, **in bytes**, cannot overflow or underflow an\n+    ///   `isize`.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a `usize`.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2^63 bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using `wrapping_offset` instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let s: &str = \"123\";\n+    /// let ptr: *const u8 = s.as_ptr();\n+    ///\n+    /// unsafe {\n+    ///     println!(\"{}\", *ptr.add(1) as char);\n+    ///     println!(\"{}\", *ptr.add(2) as char);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn add(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer (convenience for\n+    /// `.offset((count as isize).wrapping_neg())`).\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// If any of the following conditions are violated, the result is Undefined\n+    /// Behavior:\n+    ///\n+    /// * Both the starting and resulting pointer must be either in bounds or one\n+    ///   byte past the end of an allocated object.\n+    ///\n+    /// * The computed offset cannot exceed `isize::MAX` **bytes**.\n+    ///\n+    /// * The offset being in bounds cannot rely on \"wrapping around\" the address\n+    ///   space. That is, the infinite-precision sum must fit in a usize.\n+    ///\n+    /// The compiler and standard library generally tries to ensure allocations\n+    /// never reach a size where an offset is a concern. For instance, `Vec`\n+    /// and `Box` ensure they never allocate more than `isize::MAX` bytes, so\n+    /// `vec.as_ptr().add(vec.len()).sub(vec.len())` is always safe.\n+    ///\n+    /// Most platforms fundamentally can't even construct such an allocation.\n+    /// For instance, no known 64-bit platform can ever serve a request\n+    /// for 2^63 bytes due to page-table limitations or splitting the address space.\n+    /// However, some 32-bit and 16-bit platforms may successfully serve a request for\n+    /// more than `isize::MAX` bytes with things like Physical Address\n+    /// Extension. As such, memory acquired directly from allocators or memory\n+    /// mapped files *may* be too large to handle with this function.\n+    ///\n+    /// Consider using `wrapping_offset` instead if these constraints are\n+    /// difficult to satisfy. The only advantage of this method is that it\n+    /// enables more aggressive compiler optimizations.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let s: &str = \"123\";\n+    ///\n+    /// unsafe {\n+    ///     let end: *const u8 = s.as_ptr().add(3);\n+    ///     println!(\"{}\", *end.sub(1) as char);\n+    ///     println!(\"{}\", *end.sub(2) as char);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn sub(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset(count as isize)`)\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// Always use `.add(count)` instead when possible, because `add`\n+    /// allows the compiler to optimize better.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// // Iterate using a raw pointer in increments of two elements\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let step = 2;\n+    /// let end_rounded_up = ptr.wrapping_add(6);\n+    ///\n+    /// // This loop prints \"1, 3, 5, \"\n+    /// while ptr != end_rounded_up {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_add(step);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub fn wrapping_add(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.wrapping_offset(count as isize)\n+    }\n+\n+    /// Calculates the offset from a pointer using wrapping arithmetic.\n+    /// (convenience for `.wrapping_offset((count as isize).wrapping_sub())`)\n+    ///\n+    /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n+    /// offset of `3 * size_of::<T>()` bytes.\n+    ///\n+    /// # Safety\n+    ///\n+    /// The resulting pointer does not need to be in bounds, but it is\n+    /// potentially hazardous to dereference (which requires `unsafe`).\n+    ///\n+    /// Always use `.sub(count)` instead when possible, because `sub`\n+    /// allows the compiler to optimize better.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// // Iterate using a raw pointer in increments of two elements (backwards)\n+    /// let data = [1u8, 2, 3, 4, 5];\n+    /// let mut ptr: *const u8 = data.as_ptr();\n+    /// let start_rounded_down = ptr.wrapping_sub(2);\n+    /// ptr = ptr.wrapping_add(4);\n+    /// let step = 2;\n+    /// // This loop prints \"5, 3, 1, \"\n+    /// while ptr != start_rounded_down {\n+    ///     unsafe {\n+    ///         print!(\"{}, \", *ptr);\n+    ///     }\n+    ///     ptr = ptr.wrapping_sub(step);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub fn wrapping_sub(self, count: usize) -> Self\n+        where T: Sized,\n+    {\n+        self.wrapping_offset((count as isize).wrapping_neg())\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond accepting a raw pointer, this is unsafe because it semantically\n+    /// moves the value out of `self` without preventing further usage of `self`.\n+    /// If `T` is not `Copy`, then care must be taken to ensure that the value at\n+    /// `self` is not used before the data is overwritten again (e.g. with `write`,\n+    /// `zero_memory`, or `copy_memory`). Note that `*self = foo` counts as a use\n+    /// because it will attempt to drop the value previously at `*self`.\n+    ///\n+    /// The pointer must be aligned; use `read_unaligned` if that is not the case.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let x = 12;\n+    /// let y = &x as *const i32;\n+    ///\n+    /// unsafe {\n+    ///     assert_eq!(y.read(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn read(self) -> T\n+        where T: Sized,\n+    {\n+        read(self)\n+    }\n+\n+    /// Performs a volatile read of the value from `self` without moving it. This\n+    /// leaves the memory in `self` unchanged.\n+    ///\n+    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n+    /// to not be elided or reordered by the compiler across other volatile\n+    /// operations.\n+    ///\n+    /// # Notes\n+    ///\n+    /// Rust does not currently have a rigorously and formally defined memory model,\n+    /// so the precise semantics of what \"volatile\" means here is subject to change\n+    /// over time. That being said, the semantics will almost always end up pretty\n+    /// similar to [C11's definition of volatile][c11].\n+    ///\n+    /// The compiler shouldn't change the relative order or number of volatile\n+    /// memory operations. However, volatile memory operations on zero-sized types\n+    /// (e.g. if a zero-sized type is passed to `read_volatile`) are no-ops\n+    /// and may be ignored.\n+    ///\n+    /// [c11]: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond accepting a raw pointer, this is unsafe because it semantically\n+    /// moves the value out of `self` without preventing further usage of `self`.\n+    /// If `T` is not `Copy`, then care must be taken to ensure that the value at\n+    /// `src` is not used before the data is overwritten again (e.g. with `write`,\n+    /// `zero_memory`, or `copy_memory`). Note that `*self = foo` counts as a use\n+    /// because it will attempt to drop the value previously at `*self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let x = 12;\n+    /// let y = &x as *const i32;\n+    ///\n+    /// unsafe {\n+    ///     assert_eq!(y.read_volatile(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn read_volatile(self) -> T\n+        where T: Sized,\n+    {\n+        read_volatile(self)\n+    }\n+\n+    /// Reads the value from `self` without moving it. This leaves the\n+    /// memory in `self` unchanged.\n+    ///\n+    /// Unlike `read`, the pointer may be unaligned.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond accepting a raw pointer, this is unsafe because it semantically\n+    /// moves the value out of `self` without preventing further usage of `self`.\n+    /// If `T` is not `Copy`, then care must be taken to ensure that the value at\n+    /// `self` is not used before the data is overwritten again (e.g. with `write`,\n+    /// `zero_memory`, or `copy_memory`). Note that `*self = foo` counts as a use\n+    /// because it will attempt to drop the value previously at `*self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let x = 12;\n+    /// let y = &x as *const i32;\n+    ///\n+    /// unsafe {\n+    ///     assert_eq!(y.read_unaligned(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn read_unaligned(self) -> T\n+        where T: Sized,\n+    {\n+        read_unaligned(self)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as `ptr::copy`.\n+    ///\n+    /// This is semantically equivalent to C's `memmove`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Care must be taken with the ownership of `self` and `dest`.\n+    /// This method semantically moves the values of `self` into `dest`.\n+    /// However it does not drop the contents of `self`, or prevent the contents\n+    /// of `dest` from being dropped or used.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Efficiently create a Rust vector from an unsafe buffer:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// # #[allow(dead_code)]\n+    /// unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n+    ///     let mut dst = Vec::with_capacity(elts);\n+    ///     dst.set_len(elts);\n+    ///     ptr.copy_to(dst.as_mut_ptr(), elts);\n+    ///     dst\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn copy_to(self, dest: *mut T, count: usize)\n+        where T: Sized,\n+    {\n+        copy(self, dest, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `self` to `dest`. The source\n+    /// and destination may *not* overlap.\n+    ///\n+    /// NOTE: this has the *same* argument order as `ptr::copy_nonoverlapping`.\n+    ///\n+    /// `copy_nonoverlapping` is semantically equivalent to C's `memcpy`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond requiring that the program must be allowed to access both regions\n+    /// of memory, it is Undefined Behavior for source and destination to\n+    /// overlap. Care must also be taken with the ownership of `self` and\n+    /// `self`. This method semantically moves the values of `self` into `dest`.\n+    /// However it does not drop the contents of `dest`, or prevent the contents\n+    /// of `self` from being dropped or used.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Efficiently create a Rust vector from an unsafe buffer:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// # #[allow(dead_code)]\n+    /// unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n+    ///     let mut dst = Vec::with_capacity(elts);\n+    ///     dst.set_len(elts);\n+    ///     ptr.copy_to_nonoverlapping(dst.as_mut_ptr(), elts);\n+    ///     dst\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)\n+        where T: Sized,\n+    {\n+        copy_nonoverlapping(self, dest, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `src` to `self`. The source\n+    /// and destination may overlap.\n+    ///\n+    /// NOTE: this has the *opposite* argument order of `ptr::copy`.\n+    ///\n+    /// This is semantically equivalent to C's `memmove`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Care must be taken with the ownership of `src` and `self`.\n+    /// This method semantically moves the values of `src` into `self`.\n+    /// However it does not drop the contents of `self`, or prevent the contents\n+    /// of `src` from being dropped or used.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Efficiently create a Rust vector from an unsafe buffer:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// # #[allow(dead_code)]\n+    /// unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n+    ///     let mut dst = Vec::with_capacity(elts);\n+    ///     dst.set_len(elts);\n+    ///     dst.as_mut_ptr().copy_from(ptr, elts);\n+    ///     dst\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn copy_from(self, src: *const T, count: usize)\n+        where T: Sized,\n+    {\n+        copy(src, self, count)\n+    }\n+\n+    /// Copies `count * size_of<T>` bytes from `src` to `self`. The source\n+    /// and destination may *not* overlap.\n+    ///\n+    /// NOTE: this has the *opposite* argument order of `ptr::copy_nonoverlapping`.\n+    ///\n+    /// `copy_nonoverlapping` is semantically equivalent to C's `memcpy`.\n+    ///\n+    /// # Safety\n+    ///\n+    /// Beyond requiring that the program must be allowed to access both regions\n+    /// of memory, it is Undefined Behavior for source and destination to\n+    /// overlap. Care must also be taken with the ownership of `src` and\n+    /// `self`. This method semantically moves the values of `src` into `self`.\n+    /// However it does not drop the contents of `self`, or prevent the contents\n+    /// of `src` from being dropped or used.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Efficiently create a Rust vector from an unsafe buffer:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// # #[allow(dead_code)]\n+    /// unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n+    ///     let mut dst = Vec::with_capacity(elts);\n+    ///     dst.set_len(elts);\n+    ///     dst.as_mut_ptr().copy_from_nonoverlapping(ptr, elts);\n+    ///     dst\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn copy_from_nonoverlapping(self, src: *const T, count: usize)\n+        where T: Sized,\n+    {\n+        copy_nonoverlapping(src, self, count)\n+    }\n+\n+    /// Executes the destructor (if any) of the pointed-to value.\n+    ///\n+    /// This has two use cases:\n+    ///\n+    /// * It is *required* to use `drop_in_place` to drop unsized types like\n+    ///   trait objects, because they can't be read out onto the stack and\n+    ///   dropped normally.\n+    ///\n+    /// * It is friendlier to the optimizer to do this over `ptr::read` when\n+    ///   dropping manually allocated memory (e.g. when writing Box/Rc/Vec),\n+    ///   as the compiler doesn't need to prove that it's sound to elide the\n+    ///   copy.\n+    ///\n+    /// # Safety\n+    ///\n+    /// This has all the same safety problems as `ptr::read` with respect to\n+    /// invalid pointers, types, and double drops.\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn drop_in_place(self) {\n+        drop_in_place(self)\n+    }\n+\n+    /// Overwrites a memory location with the given value without reading or\n+    /// dropping the old value.\n+    ///\n+    /// # Safety\n+    ///\n+    /// This operation is marked unsafe because it writes through a raw pointer.\n+    ///\n+    /// It does not drop the contents of `self`. This is safe, but it could leak\n+    /// allocations or resources, so care must be taken not to overwrite an object\n+    /// that should be dropped.\n+    ///\n+    /// Additionally, it does not drop `val`. Semantically, `val` is moved into the\n+    /// location pointed to by `self`.\n+    ///\n+    /// This is appropriate for initializing uninitialized memory, or overwriting\n+    /// memory that has previously been `read` from.\n+    ///\n+    /// The pointer must be aligned; use `write_unaligned` if that is not the case.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let mut x = 0;\n+    /// let y = &mut x as *mut i32;\n+    /// let z = 12;\n+    ///\n+    /// unsafe {\n+    ///     y.write(z);\n+    ///     assert_eq!(y.read(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn write(self, val: T)\n+        where T: Sized,\n+    {\n+        write(self, val)\n+    }\n+\n+    /// Invokes memset on the specified pointer, setting `count * size_of::<T>()`\n+    /// bytes of memory starting at `self` to `val`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let mut vec = vec![0; 4];\n+    /// unsafe {\n+    ///     let vec_ptr = vec.as_mut_ptr();\n+    ///     vec_ptr.write_bytes(b'a', 2);\n+    /// }\n+    /// assert_eq!(vec, [b'a', b'a', 0, 0]);\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn write_bytes(self, val: u8, count: usize)\n+        where T: Sized,\n+    {\n+        write_bytes(self, val, count)\n+    }\n+\n+    /// Performs a volatile write of a memory location with the given value without\n+    /// reading or dropping the old value.\n+    ///\n+    /// Volatile operations are intended to act on I/O memory, and are guaranteed\n+    /// to not be elided or reordered by the compiler across other volatile\n+    /// operations.\n+    ///\n+    /// # Notes\n+    ///\n+    /// Rust does not currently have a rigorously and formally defined memory model,\n+    /// so the precise semantics of what \"volatile\" means here is subject to change\n+    /// over time. That being said, the semantics will almost always end up pretty\n+    /// similar to [C11's definition of volatile][c11].\n+    ///\n+    /// The compiler shouldn't change the relative order or number of volatile\n+    /// memory operations. However, volatile memory operations on zero-sized types\n+    /// (e.g. if a zero-sized type is passed to `write_volatile`) are no-ops\n+    /// and may be ignored.\n+    ///\n+    /// [c11]: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf\n+    ///\n+    /// # Safety\n+    ///\n+    /// This operation is marked unsafe because it accepts a raw pointer.\n+    ///\n+    /// It does not drop the contents of `self`. This is safe, but it could leak\n+    /// allocations or resources, so care must be taken not to overwrite an object\n+    /// that should be dropped.\n+    ///\n+    /// This is appropriate for initializing uninitialized memory, or overwriting\n+    /// memory that has previously been `read` from.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let mut x = 0;\n+    /// let y = &mut x as *mut i32;\n+    /// let z = 12;\n+    ///\n+    /// unsafe {\n+    ///     y.write_volatile(z);\n+    ///     assert_eq!(y.read_volatile(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn write_volatile(self, val: T)\n+        where T: Sized,\n+    {\n+        write_volatile(self, val)\n+    }\n+\n+    /// Overwrites a memory location with the given value without reading or\n+    /// dropping the old value.\n+    ///\n+    /// Unlike `write`, the pointer may be unaligned.\n+    ///\n+    /// # Safety\n+    ///\n+    /// This operation is marked unsafe because it writes through a raw pointer.\n+    ///\n+    /// It does not drop the contents of `self`. This is safe, but it could leak\n+    /// allocations or resources, so care must be taken not to overwrite an object\n+    /// that should be dropped.\n+    ///\n+    /// Additionally, it does not drop `src`. Semantically, `src` is moved into the\n+    /// location pointed to by `dst`.\n+    ///\n+    /// This is appropriate for initializing uninitialized memory, or overwriting\n+    /// memory that has previously been `read` from.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// #![feature(pointer_methods)]\n+    ///\n+    /// let mut x = 0;\n+    /// let y = &mut x as *mut i32;\n+    /// let z = 12;\n+    ///\n+    /// unsafe {\n+    ///     y.write_unaligned(z);\n+    ///     assert_eq!(y.read_unaligned(), 12);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn write_unaligned(self, val: T)\n+        where T: Sized,\n+    {\n+        write_unaligned(self, val)\n+    }\n+\n+    /// Replaces the value at `self` with `src`, returning the old\n+    /// value, without dropping either.\n+    ///\n+    /// # Safety\n+    ///\n+    /// This is only unsafe because it accepts a raw pointer.\n+    /// Otherwise, this operation is identical to `mem::replace`.\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn replace(self, src: T) -> T\n+        where T: Sized,\n+    {\n+        replace(self, src)\n+    }\n+\n+    /// Swaps the values at two mutable locations of the same type, without\n+    /// deinitializing either. They may overlap, unlike `mem::swap` which is\n+    /// otherwise equivalent.\n+    ///\n+    /// # Safety\n+    ///\n+    /// This function copies the memory through the raw pointers passed to it\n+    /// as arguments.\n+    ///\n+    /// Ensure that these pointers are valid before calling `swap`.\n+    #[unstable(feature = \"pointer_methods\", issue = \"43941\")]\n+    #[inline]\n+    pub unsafe fn swap(self, with: *mut T)\n+        where T: Sized,\n+    {\n+        swap(self, with)\n+    }\n }\n \n // Equality for pointers"}]}