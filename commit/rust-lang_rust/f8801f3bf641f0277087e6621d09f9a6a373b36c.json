{"sha": "f8801f3bf641f0277087e6621d09f9a6a373b36c", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY4ODAxZjNiZjY0MWYwMjc3MDg3ZTY2MjFkMDlmOWE2YTM3M2IzNmM=", "commit": {"author": {"name": "Nicholas Nethercote", "email": "nnethercote@mozilla.com", "date": "2019-02-14T22:10:02Z"}, "committer": {"name": "Nicholas Nethercote", "email": "nnethercote@mozilla.com", "date": "2019-02-17T22:46:33Z"}, "message": "Remove `LazyTokenStream`.\n\nIt's present within `Token::Interpolated` as an optimization, so that if\na nonterminal is converted to a `TokenStream` multiple times, the\nfirst-computed value is saved and reused.\n\nBut in practice it's not needed. `interpolated_to_tokenstream()` is a\ncold function: it's only called a few dozen times while compiling rustc\nitself, and a few hundred times across the entire `rustc-perf` suite.\nFurthermore, when it is called, it is almost always the first\nconversion, so no benefit is gained from it.\n\nSo this commit removes `LazyTokenStream`, along with the now-unnecessary\n`Token::interpolated()`.\n\nAs well as a significant simplification, the removal speeds things up\nslightly, mostly due to not having to `drop` the `LazyTokenStream`\ninstances.", "tree": {"sha": "d58803ac7c531e5911f4f3e17d843f80ac401708", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d58803ac7c531e5911f4f3e17d843f80ac401708"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f8801f3bf641f0277087e6621d09f9a6a373b36c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f8801f3bf641f0277087e6621d09f9a6a373b36c", "html_url": "https://github.com/rust-lang/rust/commit/f8801f3bf641f0277087e6621d09f9a6a373b36c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f8801f3bf641f0277087e6621d09f9a6a373b36c/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d26bf742db0754893567401e49ae8b016c878a92", "url": "https://api.github.com/repos/rust-lang/rust/commits/d26bf742db0754893567401e49ae8b016c878a92", "html_url": "https://github.com/rust-lang/rust/commit/d26bf742db0754893567401e49ae8b016c878a92"}], "stats": {"total": 171, "additions": 58, "deletions": 113}, "files": [{"sha": "72aa9570cc2ffa04f8025ec16e992677a65c5955", "filename": "src/librustc/hir/map/def_collector.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -339,7 +339,7 @@ impl<'a> visit::Visitor<'a> for DefCollector<'a> {\n \n     fn visit_token(&mut self, t: Token) {\n         if let Token::Interpolated(nt) = t {\n-            if let token::NtExpr(ref expr) = nt.0 {\n+            if let token::NtExpr(ref expr) = *nt {\n                 if let ExprKind::Mac(..) = expr.node {\n                     self.visit_macro_invoc(expr.id);\n                 }"}, {"sha": "29de5308a3cdb8055cfbeb6d25e5e34714e86aef", "filename": "src/librustc_resolve/build_reduced_graph.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -1025,7 +1025,7 @@ impl<'a, 'b> Visitor<'a> for BuildReducedGraphVisitor<'a, 'b> {\n \n     fn visit_token(&mut self, t: Token) {\n         if let Token::Interpolated(nt) = t {\n-            if let token::NtExpr(ref expr) = nt.0 {\n+            if let token::NtExpr(ref expr) = *nt {\n                 if let ast::ExprKind::Mac(..) = expr.node {\n                     self.visit_invoc(expr.id);\n                 }"}, {"sha": "b5fc8507314047a3fffb19635bb1e61b8723e49c", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -517,7 +517,7 @@ impl MetaItem {\n                 let span = span.with_hi(segments.last().unwrap().ident.span.hi());\n                 Path { span, segments }\n             }\n-            Some(TokenTree::Token(_, Token::Interpolated(ref nt))) => match nt.0 {\n+            Some(TokenTree::Token(_, Token::Interpolated(nt))) => match *nt {\n                 token::Nonterminal::NtIdent(ident, _) => Path::from_ident(ident),\n                 token::Nonterminal::NtMeta(ref meta) => return Some(meta.clone()),\n                 token::Nonterminal::NtPath(ref path) => path.clone(),\n@@ -682,7 +682,7 @@ impl LitKind {\n         match token {\n             Token::Ident(ident, false) if ident.name == \"true\" => Some(LitKind::Bool(true)),\n             Token::Ident(ident, false) if ident.name == \"false\" => Some(LitKind::Bool(false)),\n-            Token::Interpolated(ref nt) => match nt.0 {\n+            Token::Interpolated(nt) => match *nt {\n                 token::NtExpr(ref v) | token::NtLiteral(ref v) => match v.node {\n                     ExprKind::Lit(ref lit) => Some(lit.node.clone()),\n                     _ => None,"}, {"sha": "452cc2f2c65ccc68cee03502b9710cb35987f1ad", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -266,7 +266,7 @@ impl<F> TTMacroExpander for F\n         impl MutVisitor for AvoidInterpolatedIdents {\n             fn visit_tt(&mut self, tt: &mut tokenstream::TokenTree) {\n                 if let tokenstream::TokenTree::Token(_, token::Interpolated(nt)) = tt {\n-                    if let token::NtIdent(ident, is_raw) = nt.0 {\n+                    if let token::NtIdent(ident, is_raw) = **nt {\n                         *tt = tokenstream::TokenTree::Token(ident.span,\n                                                             token::Ident(ident, is_raw));\n                     }"}, {"sha": "55a6471e3688d76c4126ebfb8ee900d2bcc1c670", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -25,6 +25,7 @@ use syntax_pos::{Span, DUMMY_SP, FileName};\n use syntax_pos::hygiene::ExpnFormat;\n \n use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::sync::Lrc;\n use std::fs;\n use std::io::ErrorKind;\n use std::{iter, mem};\n@@ -586,14 +587,14 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             }\n             AttrProcMacro(ref mac, ..) => {\n                 self.gate_proc_macro_attr_item(attr.span, &item);\n-                let item_tok = TokenTree::Token(DUMMY_SP, Token::interpolated(match item {\n+                let item_tok = TokenTree::Token(DUMMY_SP, Token::Interpolated(Lrc::new(match item {\n                     Annotatable::Item(item) => token::NtItem(item),\n                     Annotatable::TraitItem(item) => token::NtTraitItem(item.into_inner()),\n                     Annotatable::ImplItem(item) => token::NtImplItem(item.into_inner()),\n                     Annotatable::ForeignItem(item) => token::NtForeignItem(item.into_inner()),\n                     Annotatable::Stmt(stmt) => token::NtStmt(stmt.into_inner()),\n                     Annotatable::Expr(expr) => token::NtExpr(expr),\n-                })).into();\n+                }))).into();\n                 let input = self.extract_proc_macro_attr_input(attr.tokens, attr.span);\n                 let tok_result = mac.expand(self.cx, attr.span, input, item_tok);\n                 let res = self.parse_ast_fragment(tok_result, invoc.fragment_kind,"}, {"sha": "c2607ed530cf017501b05658ab5baf179388269d", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -829,7 +829,7 @@ fn may_begin_with(name: &str, token: &Token) -> bool {\n         },\n         \"block\" => match *token {\n             Token::OpenDelim(token::Brace) => true,\n-            Token::Interpolated(ref nt) => match nt.0 {\n+            Token::Interpolated(ref nt) => match **nt {\n                 token::NtItem(_)\n                 | token::NtPat(_)\n                 | token::NtTy(_)\n@@ -843,9 +843,9 @@ fn may_begin_with(name: &str, token: &Token) -> bool {\n         },\n         \"path\" | \"meta\" => match *token {\n             Token::ModSep | Token::Ident(..) => true,\n-            Token::Interpolated(ref nt) => match nt.0 {\n+            Token::Interpolated(ref nt) => match **nt {\n                 token::NtPath(_) | token::NtMeta(_) => true,\n-                _ => may_be_ident(&nt.0),\n+                _ => may_be_ident(&nt),\n             },\n             _ => false,\n         },\n@@ -862,12 +862,12 @@ fn may_begin_with(name: &str, token: &Token) -> bool {\n             Token::ModSep |                     // path\n             Token::Lt |                         // path (UFCS constant)\n             Token::BinOp(token::Shl) => true,   // path (double UFCS)\n-            Token::Interpolated(ref nt) => may_be_ident(&nt.0),\n+            Token::Interpolated(ref nt) => may_be_ident(nt),\n             _ => false,\n         },\n         \"lifetime\" => match *token {\n             Token::Lifetime(_) => true,\n-            Token::Interpolated(ref nt) => match nt.0 {\n+            Token::Interpolated(ref nt) => match **nt {\n                 token::NtLifetime(_) | token::NtTT(_) => true,\n                 _ => false,\n             },"}, {"sha": "5c240e237f63257a8d04712644d2b25ea8f1e90d", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -149,7 +149,8 @@ pub fn transcribe(cx: &ExtCtxt<'_>,\n                             result.push(tt.clone().into());\n                         } else {\n                             sp = sp.apply_mark(cx.current_expansion.mark);\n-                            let token = TokenTree::Token(sp, Token::interpolated((**nt).clone()));\n+                            let token =\n+                                TokenTree::Token(sp, Token::Interpolated(Lrc::new((**nt).clone())));\n                             result.push(token.into());\n                         }\n                     } else {"}, {"sha": "59fae789188b04c3822cf4f5cc4df9d68710a2be", "filename": "src/libsyntax/mut_visit.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -581,9 +581,8 @@ pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n         token::Ident(id, _is_raw) => vis.visit_ident(id),\n         token::Lifetime(id) => vis.visit_ident(id),\n         token::Interpolated(nt) => {\n-            let nt = Lrc::make_mut(nt);\n-            vis.visit_interpolated(&mut nt.0);\n-            nt.1 = token::LazyTokenStream::new();\n+            let mut nt = Lrc::make_mut(nt);\n+            vis.visit_interpolated(&mut nt);\n         }\n         _ => {}\n     }"}, {"sha": "9020c8c6a2dc66fb9c3760e11bab580e4e72b4f0", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -141,7 +141,7 @@ impl<'a> Parser<'a> {\n     /// The delimiters or `=` are still put into the resulting token stream.\n     crate fn parse_meta_item_unrestricted(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n         let meta = match self.token {\n-            token::Interpolated(ref nt) => match nt.0 {\n+            token::Interpolated(ref nt) => match **nt {\n                 Nonterminal::NtMeta(ref meta) => Some(meta.clone()),\n                 _ => None,\n             },\n@@ -227,7 +227,7 @@ impl<'a> Parser<'a> {\n     /// meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n     pub fn parse_meta_item(&mut self) -> PResult<'a, ast::MetaItem> {\n         let nt_meta = match self.token {\n-            token::Interpolated(ref nt) => match nt.0 {\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtMeta(ref e) => Some(e.clone()),\n                 _ => None,\n             },"}, {"sha": "559e992ee0d7a724257043f309b887a8e9a86853", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -119,7 +119,7 @@ enum BlockMode {\n macro_rules! maybe_whole_expr {\n     ($p:expr) => {\n         if let token::Interpolated(nt) = $p.token.clone() {\n-            match nt.0 {\n+            match *nt {\n                 token::NtExpr(ref e) | token::NtLiteral(ref e) => {\n                     $p.bump();\n                     return Ok((*e).clone());\n@@ -146,7 +146,7 @@ macro_rules! maybe_whole_expr {\n macro_rules! maybe_whole {\n     ($p:expr, $constructor:ident, |$x:ident| $e:expr) => {\n         if let token::Interpolated(nt) = $p.token.clone() {\n-            if let token::$constructor($x) = nt.0.clone() {\n+            if let token::$constructor($x) = (*nt).clone() {\n                 $p.bump();\n                 return Ok($e);\n             }\n@@ -1570,7 +1570,7 @@ impl<'a> Parser<'a> {\n                     Some(body)\n                 }\n                 token::Interpolated(ref nt) => {\n-                    match &nt.0 {\n+                    match **nt {\n                         token::NtBlock(..) => {\n                             *at_end = true;\n                             let (inner_attrs, body) = self.parse_inner_attrs_and_block()?;\n@@ -1913,7 +1913,7 @@ impl<'a> Parser<'a> {\n \n     fn is_named_argument(&mut self) -> bool {\n         let offset = match self.token {\n-            token::Interpolated(ref nt) => match nt.0 {\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtPat(..) => return self.look_ahead(1, |t| t == &token::Colon),\n                 _ => 0,\n             }\n@@ -2099,7 +2099,7 @@ impl<'a> Parser<'a> {\n     /// Matches `token_lit = LIT_INTEGER | ...`.\n     fn parse_lit_token(&mut self) -> PResult<'a, LitKind> {\n         let out = match self.token {\n-            token::Interpolated(ref nt) => match nt.0 {\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtExpr(ref v) | token::NtLiteral(ref v) => match v.node {\n                     ExprKind::Lit(ref lit) => { lit.node.clone() }\n                     _ => { return self.unexpected_last(&self.token); }\n@@ -2299,7 +2299,7 @@ impl<'a> Parser<'a> {\n     /// attributes.\n     pub fn parse_path_allowing_meta(&mut self, style: PathStyle) -> PResult<'a, ast::Path> {\n         let meta_ident = match self.token {\n-            token::Interpolated(ref nt) => match nt.0 {\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtMeta(ref meta) => match meta.node {\n                     ast::MetaItemKind::Word => Some(meta.ident.clone()),\n                     _ => None,\n@@ -3271,7 +3271,7 @@ impl<'a> Parser<'a> {\n                 self.meta_var_span = Some(self.span);\n                 // Interpolated identifier and lifetime tokens are replaced with usual identifier\n                 // and lifetime tokens, so the former are never encountered during normal parsing.\n-                match nt.0 {\n+                match **nt {\n                     token::NtIdent(ident, is_raw) => (token::Ident(ident, is_raw), ident.span),\n                     token::NtLifetime(ident) => (token::Lifetime(ident), ident.span),\n                     _ => return,\n@@ -3403,7 +3403,7 @@ impl<'a> Parser<'a> {\n                     // can't continue an expression after an ident\n                     token::Ident(ident, is_raw) => token::ident_can_begin_expr(ident, is_raw),\n                     token::Literal(..) | token::Pound => true,\n-                    token::Interpolated(ref nt) => match nt.0 {\n+                    token::Interpolated(ref nt) => match **nt {\n                         token::NtIdent(..) | token::NtExpr(..) |\n                         token::NtBlock(..) | token::NtPath(..) => true,\n                         _ => false,"}, {"sha": "a1d1a0f51baf0c15e05452ded69f17684f7c4312", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 28, "deletions": 85, "changes": 113, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -13,16 +13,15 @@ use crate::syntax::parse::parse_stream_from_source_str;\n use crate::syntax::parse::parser::emit_unclosed_delims;\n use crate::tokenstream::{self, DelimSpan, TokenStream, TokenTree};\n \n-use serialize::{Decodable, Decoder, Encodable, Encoder};\n use syntax_pos::symbol::{self, Symbol};\n use syntax_pos::{self, Span, FileName};\n use log::info;\n \n-use std::{cmp, fmt};\n+use std::fmt;\n use std::mem;\n #[cfg(target_arch = \"x86_64\")]\n use rustc_data_structures::static_assert;\n-use rustc_data_structures::sync::{Lrc, Lock};\n+use rustc_data_structures::sync::Lrc;\n \n #[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n pub enum BinOpToken {\n@@ -184,9 +183,8 @@ pub enum Token {\n     Ident(ast::Ident, /* is_raw */ bool),\n     Lifetime(ast::Ident),\n \n-    // The `LazyTokenStream` is a pure function of the `Nonterminal`,\n-    // and so the `LazyTokenStream` can be ignored by Eq, Hash, etc.\n-    Interpolated(Lrc<(Nonterminal, LazyTokenStream)>),\n+    Interpolated(Lrc<Nonterminal>),\n+\n     // Can be expanded into several tokens.\n     /// A doc comment.\n     DocComment(ast::Name),\n@@ -209,10 +207,6 @@ pub enum Token {\n static_assert!(MEM_SIZE_OF_STATEMENT: mem::size_of::<Token>() == 16);\n \n impl Token {\n-    pub fn interpolated(nt: Nonterminal) -> Token {\n-        Token::Interpolated(Lrc::new((nt, LazyTokenStream::new())))\n-    }\n-\n     /// Recovers a `Token` from an `ast::Ident`. This creates a raw identifier if necessary.\n     pub fn from_ast_ident(ident: ast::Ident) -> Token {\n         Ident(ident, ident.is_raw_guess())\n@@ -244,7 +238,7 @@ impl Token {\n             ModSep                            | // global path\n             Lifetime(..)                      | // labeled loop\n             Pound                             => true, // expression attributes\n-            Interpolated(ref nt) => match nt.0 {\n+            Interpolated(ref nt) => match **nt {\n                 NtLiteral(..) |\n                 NtIdent(..)   |\n                 NtExpr(..)    |\n@@ -272,7 +266,7 @@ impl Token {\n             Lifetime(..)                | // lifetime bound in trait object\n             Lt | BinOp(Shl)             | // associated path\n             ModSep                      => true, // global path\n-            Interpolated(ref nt) => match nt.0 {\n+            Interpolated(ref nt) => match **nt {\n                 NtIdent(..) | NtTy(..) | NtPath(..) | NtLifetime(..) => true,\n                 _ => false,\n             },\n@@ -284,7 +278,7 @@ impl Token {\n     pub fn can_begin_const_arg(&self) -> bool {\n         match self {\n             OpenDelim(Brace) => true,\n-            Interpolated(ref nt) => match nt.0 {\n+            Interpolated(ref nt) => match **nt {\n                 NtExpr(..) => true,\n                 NtBlock(..) => true,\n                 NtLiteral(..) => true,\n@@ -316,7 +310,7 @@ impl Token {\n             BinOp(Minus) => true,\n             Ident(ident, false) if ident.name == keywords::True.name() => true,\n             Ident(ident, false) if ident.name == keywords::False.name() => true,\n-            Interpolated(ref nt) => match nt.0 {\n+            Interpolated(ref nt) => match **nt {\n                 NtLiteral(..) => true,\n                 _             => false,\n             },\n@@ -328,7 +322,7 @@ impl Token {\n     pub fn ident(&self) -> Option<(ast::Ident, /* is_raw */ bool)> {\n         match *self {\n             Ident(ident, is_raw) => Some((ident, is_raw)),\n-            Interpolated(ref nt) => match nt.0 {\n+            Interpolated(ref nt) => match **nt {\n                 NtIdent(ident, is_raw) => Some((ident, is_raw)),\n                 _ => None,\n             },\n@@ -339,7 +333,7 @@ impl Token {\n     pub fn lifetime(&self) -> Option<ast::Ident> {\n         match *self {\n             Lifetime(ident) => Some(ident),\n-            Interpolated(ref nt) => match nt.0 {\n+            Interpolated(ref nt) => match **nt {\n                 NtLifetime(ident) => Some(ident),\n                 _ => None,\n             },\n@@ -367,7 +361,7 @@ impl Token {\n     /// Returns `true` if the token is an interpolated path.\n     fn is_path(&self) -> bool {\n         if let Interpolated(ref nt) = *self {\n-            if let NtPath(..) = nt.0 {\n+            if let NtPath(..) = **nt {\n                 return true;\n             }\n         }\n@@ -508,8 +502,8 @@ impl Token {\n         }\n     }\n \n-    pub fn interpolated_to_tokenstream(sess: &ParseSess, nt: Lrc<(Nonterminal, LazyTokenStream)>,\n-                                       span: Span) -> TokenStream {\n+    pub fn interpolated_to_tokenstream(sess: &ParseSess, nt: Lrc<Nonterminal>, span: Span)\n+                                       -> TokenStream {\n         // An `Interpolated` token means that we have a `Nonterminal`\n         // which is often a parsed AST item. At this point we now need\n         // to convert the parsed AST to an actual token stream, e.g.\n@@ -524,41 +518,36 @@ impl Token {\n         // stream they came from. Here we attempt to extract these\n         // lossless token streams before we fall back to the\n         // stringification.\n-        let mut tokens = None;\n-\n-        match nt.0 {\n+        let tokens = match *nt {\n             Nonterminal::NtItem(ref item) => {\n-                tokens = prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span);\n+                prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span)\n             }\n             Nonterminal::NtTraitItem(ref item) => {\n-                tokens = prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span);\n+                prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span)\n             }\n             Nonterminal::NtImplItem(ref item) => {\n-                tokens = prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span);\n+                prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span)\n             }\n             Nonterminal::NtIdent(ident, is_raw) => {\n                 let token = Token::Ident(ident, is_raw);\n-                tokens = Some(TokenTree::Token(ident.span, token).into());\n+                Some(TokenTree::Token(ident.span, token).into())\n             }\n             Nonterminal::NtLifetime(ident) => {\n                 let token = Token::Lifetime(ident);\n-                tokens = Some(TokenTree::Token(ident.span, token).into());\n+                Some(TokenTree::Token(ident.span, token).into())\n             }\n             Nonterminal::NtTT(ref tt) => {\n-                tokens = Some(tt.clone().into());\n+                Some(tt.clone().into())\n             }\n-            _ => {}\n-        }\n+            _ => None,\n+        };\n \n-        let tokens_for_real = nt.1.force(|| {\n-            // FIXME(#43081): Avoid this pretty-print + reparse hack\n-            let source = pprust::nonterminal_to_string(&nt.0);\n-            let filename = FileName::macro_expansion_source_code(&source);\n-            let (tokens, errors) = parse_stream_from_source_str(\n-                filename, source, sess, Some(span));\n-            emit_unclosed_delims(&errors, &sess.span_diagnostic);\n-            tokens\n-        });\n+        // FIXME(#43081): Avoid this pretty-print + reparse hack\n+        let source = pprust::nonterminal_to_string(&nt);\n+        let filename = FileName::macro_expansion_source_code(&source);\n+        let (tokens_for_real, errors) =\n+            parse_stream_from_source_str(filename, source, sess, Some(span));\n+        emit_unclosed_delims(&errors, &sess.span_diagnostic);\n \n         // During early phases of the compiler the AST could get modified\n         // directly (e.g., attributes added or removed) and the internal cache\n@@ -734,52 +723,6 @@ crate fn is_op(tok: &Token) -> bool {\n     }\n }\n \n-#[derive(Clone)]\n-pub struct LazyTokenStream(Lock<Option<TokenStream>>);\n-\n-impl cmp::Eq for LazyTokenStream {}\n-impl PartialEq for LazyTokenStream {\n-    fn eq(&self, _other: &LazyTokenStream) -> bool {\n-        true\n-    }\n-}\n-\n-impl fmt::Debug for LazyTokenStream {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        fmt::Debug::fmt(&self.clone().0.into_inner(), f)\n-    }\n-}\n-\n-impl LazyTokenStream {\n-    pub fn new() -> Self {\n-        LazyTokenStream(Lock::new(None))\n-    }\n-\n-    fn force<F: FnOnce() -> TokenStream>(&self, f: F) -> TokenStream {\n-        let mut opt_stream = self.0.lock();\n-        if opt_stream.is_none() {\n-            *opt_stream = Some(f());\n-        }\n-        opt_stream.clone().unwrap()\n-    }\n-}\n-\n-impl Encodable for LazyTokenStream {\n-    fn encode<S: Encoder>(&self, _: &mut S) -> Result<(), S::Error> {\n-        Ok(())\n-    }\n-}\n-\n-impl Decodable for LazyTokenStream {\n-    fn decode<D: Decoder>(_: &mut D) -> Result<LazyTokenStream, D::Error> {\n-        Ok(LazyTokenStream::new())\n-    }\n-}\n-\n-impl ::std::hash::Hash for LazyTokenStream {\n-    fn hash<H: ::std::hash::Hasher>(&self, _hasher: &mut H) {}\n-}\n-\n fn prepend_attrs(sess: &ParseSess,\n                  attrs: &[ast::Attribute],\n                  tokens: Option<&tokenstream::TokenStream>,"}, {"sha": "dcf9815f6d1ba47a4df2facd444514455fb87293", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -257,7 +257,7 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::Comment              => \"/* */\".to_string(),\n         token::Shebang(s)           => format!(\"/* shebang: {}*/\", s),\n \n-        token::Interpolated(ref nt) => nonterminal_to_string(&nt.0),\n+        token::Interpolated(ref nt) => nonterminal_to_string(nt),\n     }\n }\n "}, {"sha": "cfc3c931598a1df73a4372d3689a49813d0a3277", "filename": "src/libsyntax_ext/deriving/custom.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f8801f3bf641f0277087e6621d09f9a6a373b36c/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs?ref=f8801f3bf641f0277087e6621d09f9a6a373b36c", "patch": "@@ -2,6 +2,7 @@ use crate::proc_macro_impl::EXEC_STRATEGY;\n use crate::proc_macro_server;\n \n use errors::FatalError;\n+use rustc_data_structures::sync::Lrc;\n use syntax::ast::{self, ItemKind, Attribute, Mac};\n use syntax::attr::{mark_used, mark_known};\n use syntax::source_map::Span;\n@@ -65,7 +66,7 @@ impl MultiItemModifier for ProcMacroDerive {\n         // Mark attributes as known, and used.\n         MarkAttrs(&self.attrs).visit_item(&item);\n \n-        let token = Token::interpolated(token::NtItem(item));\n+        let token = Token::Interpolated(Lrc::new(token::NtItem(item)));\n         let input = tokenstream::TokenTree::Token(DUMMY_SP, token).into();\n \n         let server = proc_macro_server::Rustc::new(ecx);"}]}