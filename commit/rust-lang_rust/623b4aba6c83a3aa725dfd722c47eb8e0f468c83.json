{"sha": "623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "node_id": "C_kwDOAAsO6NoAKDYyM2I0YWJhNmM4M2EzYWE3MjVkZmQ3MjJjNDdlYjhlMGY0NjhjODM", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-12-01T09:08:06Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-12-01T09:08:06Z"}, "message": "Auto merge of #2699 - RalfJung:schedule-refactor, r=RalfJung\n\nrefactor scheduler\n\nRefactors the scheduler to use something akin to a generator -- a callback that will be invoked when the stack of a thread is empty, which has the chance to push a new stack frame or do other things and then indicates whether this thread is done, or should be scheduled again. (Unfortunately I think we [cannot use actual generators](https://rust-lang.zulipchat.com/#narrow/stream/213817-t-lang/topic/Generators.20that.20borrow.20on.20each.20resume.3F) here.) The interpreter loop is now a proper infinite loop, the only way to leave it is for some kind of interrupt to be triggered (represented as `InterpError`) -- unifying how we handle 'exit when calling `process::exit`' and 'exit when main thread quits'.\n\nThe last commit implements an alternative approach to https://github.com/rust-lang/miri/pull/2660 using this new structure. Fixes https://github.com/rust-lang/miri/issues/2629.", "tree": {"sha": "bc20a5aea5b4ff7b4350b9b26a8025bad5061a7f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bc20a5aea5b4ff7b4350b9b26a8025bad5061a7f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "html_url": "https://github.com/rust-lang/rust/commit/623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5c2592cd4324973b48011a8a93908612bec9cebf", "url": "https://api.github.com/repos/rust-lang/rust/commits/5c2592cd4324973b48011a8a93908612bec9cebf", "html_url": "https://github.com/rust-lang/rust/commit/5c2592cd4324973b48011a8a93908612bec9cebf"}, {"sha": "ef5d5e78958f70be656b29a993e4658783919bcb", "url": "https://api.github.com/repos/rust-lang/rust/commits/ef5d5e78958f70be656b29a993e4658783919bcb", "html_url": "https://github.com/rust-lang/rust/commit/ef5d5e78958f70be656b29a993e4658783919bcb"}], "stats": {"total": 739, "additions": 412, "deletions": 327}, "files": [{"sha": "3ec63ba0f104fefb6663839813a27036af41f044", "filename": "src/tools/miri/cargo-miri/src/setup.rs", "status": "modified", "additions": 9, "deletions": 7, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fcargo-miri%2Fsrc%2Fsetup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fcargo-miri%2Fsrc%2Fsetup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fcargo-miri%2Fsrc%2Fsetup.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -99,12 +99,10 @@ pub fn setup(subcommand: &MiriCommand, target: &str, rustc_version: &VersionMeta\n         // `config.toml`.\n         command.env(\"RUSTC_WRAPPER\", \"\");\n \n-        if only_setup {\n-            if print_sysroot {\n-                // Be extra sure there is no noise on stdout.\n-                command.stdout(process::Stdio::null());\n-            }\n+        if only_setup && !print_sysroot {\n+            // Forward output.\n         } else {\n+            // Supress output.\n             command.stdout(process::Stdio::null());\n             command.stderr(process::Stdio::null());\n         }\n@@ -120,7 +118,9 @@ pub fn setup(subcommand: &MiriCommand, target: &str, rustc_version: &VersionMeta\n     std::env::set_var(\"MIRI_SYSROOT\", &sysroot_dir);\n \n     // Do the build.\n-    if only_setup {\n+    if print_sysroot {\n+        // Be silent.\n+    } else if only_setup {\n         // We want to be explicit.\n         eprintln!(\"Preparing a sysroot for Miri (target: {target})...\");\n     } else {\n@@ -143,7 +143,9 @@ pub fn setup(subcommand: &MiriCommand, target: &str, rustc_version: &VersionMeta\n                 )\n             }\n         });\n-    if only_setup {\n+    if print_sysroot {\n+        // Be silent.\n+    } else if only_setup {\n         eprintln!(\"A sysroot for Miri is now available in `{}`.\", sysroot_dir.display());\n     } else {\n         eprintln!(\"done\");"}, {"sha": "e455b482338f4b7d4cd748b1bfa8f34f799e5ead", "filename": "src/tools/miri/ci.sh", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fci.sh", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fci.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fci.sh?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -40,10 +40,15 @@ function run_tests {\n   ./miri test\n   if [ -z \"${MIRI_TEST_TARGET+exists}\" ]; then\n     # Only for host architecture: tests with optimizations (`-O` is what cargo passes, but crank MIR\n-    # optimizations up all the way).\n-    # Optimizations change diagnostics (mostly backtraces), so we don't check them\n-    #FIXME(#2155): we want to only run the pass and panic tests here, not the fail tests.\n+    # optimizations up all the way, too).\n+    # Optimizations change diagnostics (mostly backtraces), so we don't check\n+    # them. Also error locations change so we don't run the failing tests.\n     MIRIFLAGS=\"${MIRIFLAGS:-} -O -Zmir-opt-level=4\" MIRI_SKIP_UI_CHECKS=1 ./miri test -- tests/{pass,panic}\n+\n+    # Also run some many-seeds tests. 64 seeds means this takes around a minute per test.\n+    for FILE in tests/many-seeds/*.rs; do\n+      MIRI_SEEDS=64 CARGO_EXTRA_FLAGS=\"$CARGO_EXTRA_FLAGS -q\" ./miri many-seeds ./miri run \"$FILE\"\n+    done\n   fi\n \n   ## test-cargo-miri"}, {"sha": "a259576ed42a0edb8f2529f827a46ac216efa629", "filename": "src/tools/miri/miri", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fmiri", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fmiri", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fmiri?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -36,7 +36,8 @@ Mainly meant to be invoked by rust-analyzer.\n ./miri many-seeds <command>:\n Runs <command> over and over again with different seeds for Miri. The MIRIFLAGS\n variable is set to its original value appended with ` -Zmiri-seed=$SEED` for\n-many different seeds.\n+many different seeds. The MIRI_SEEDS variable controls how many seeds are being\n+tried; MIRI_SEED_START controls the first seed to try.\n \n ./miri bench <benches>:\n Runs the benchmarks from bench-cargo-miri in hyperfine. hyperfine needs to be installed.\n@@ -174,7 +175,9 @@ rustc-push)\n     fi\n     ;;\n many-seeds)\n-    for SEED in $(seq 0 255); do\n+    MIRI_SEED_START=${MIRI_SEED_START:-0} # default to 0\n+    MIRI_SEEDS=${MIRI_SEEDS:-256} # default to 256\n+    for SEED in $(seq $MIRI_SEED_START $(( $MIRI_SEED_START + $MIRI_SEEDS - 1 )) ); do\n         echo \"Trying seed: $SEED\"\n         MIRIFLAGS=\"$MIRIFLAGS -Zlayout-seed=$SEED -Zmiri-seed=$SEED\" $@ || { echo \"Failing seed: $SEED\"; break; }\n     done\n@@ -249,6 +252,8 @@ export RUSTFLAGS=\"-C link-args=-Wl,-rpath,$LIBDIR $RUSTFLAGS\"\n # Build a sysroot and set MIRI_SYSROOT to use it. Arguments are passed to `cargo miri setup`.\n build_sysroot() {\n     if ! MIRI_SYSROOT=\"$($CARGO run $CARGO_EXTRA_FLAGS --manifest-path \"$MIRIDIR\"/cargo-miri/Cargo.toml -- miri setup --print-sysroot \"$@\")\"; then\n+        # Run it again so the user can see the error.\n+        $CARGO run $CARGO_EXTRA_FLAGS --manifest-path \"$MIRIDIR\"/cargo-miri/Cargo.toml -- miri setup \"$@\"\n         echo \"'cargo miri setup' failed\"\n         exit 1\n     fi"}, {"sha": "900d24443cc9668b454dc038271ab0b9e2535c26", "filename": "src/tools/miri/src/concurrency/thread.rs", "status": "modified", "additions": 136, "deletions": 133, "changes": 269, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fthread.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -3,6 +3,7 @@\n use std::cell::RefCell;\n use std::collections::hash_map::Entry;\n use std::num::TryFromIntError;\n+use std::task::Poll;\n use std::time::{Duration, SystemTime};\n \n use log::trace;\n@@ -16,18 +17,17 @@ use rustc_target::spec::abi::Abi;\n \n use crate::concurrency::data_race;\n use crate::concurrency::sync::SynchronizationState;\n+use crate::shims::tls;\n use crate::*;\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq)]\n-pub enum SchedulingAction {\n+enum SchedulingAction {\n     /// Execute step on the active thread.\n     ExecuteStep,\n     /// Execute a timeout callback.\n     ExecuteTimeoutCallback,\n-    /// Execute destructors of the active thread.\n-    ExecuteDtors,\n-    /// Stop the program.\n-    Stop,\n+    /// Wait for a bit, until there is a timeout to be called.\n+    Sleep(Duration),\n }\n \n /// Trait for callbacks that can be executed when some event happens, such as after a timeout.\n@@ -41,9 +41,6 @@ type TimeoutCallback<'mir, 'tcx> = Box<dyn MachineCallback<'mir, 'tcx> + 'tcx>;\n #[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n pub struct ThreadId(u32);\n \n-/// The main thread. When it terminates, the whole application terminates.\n-const MAIN_THREAD: ThreadId = ThreadId(0);\n-\n impl ThreadId {\n     pub fn to_u32(self) -> u32 {\n         self.0\n@@ -118,6 +115,12 @@ pub struct Thread<'mir, 'tcx> {\n     /// The virtual call stack.\n     stack: Vec<Frame<'mir, 'tcx, Provenance, FrameData<'tcx>>>,\n \n+    /// The function to call when the stack ran empty, to figure out what to do next.\n+    /// Conceptually, this is the interpreter implementation of the things that happen 'after' the\n+    /// Rust language entry point for this thread returns (usually implemented by the C or OS runtime).\n+    /// (`None` is an error, it means the callback has not been set up yet or is actively running.)\n+    pub(crate) on_stack_empty: Option<StackEmptyCallback<'mir, 'tcx>>,\n+\n     /// The index of the topmost user-relevant frame in `stack`. This field must contain\n     /// the value produced by `get_top_user_relevant_frame`.\n     /// The `None` state here represents\n@@ -137,19 +140,10 @@ pub struct Thread<'mir, 'tcx> {\n     pub(crate) last_error: Option<MPlaceTy<'tcx, Provenance>>,\n }\n \n-impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n-    /// Check if the thread is done executing (no more stack frames). If yes,\n-    /// change the state to terminated and return `true`.\n-    fn check_terminated(&mut self) -> bool {\n-        if self.state == ThreadState::Enabled {\n-            if self.stack.is_empty() {\n-                self.state = ThreadState::Terminated;\n-                return true;\n-            }\n-        }\n-        false\n-    }\n+pub type StackEmptyCallback<'mir, 'tcx> =\n+    Box<dyn FnMut(&mut MiriInterpCx<'mir, 'tcx>) -> InterpResult<'tcx, Poll<()>>>;\n \n+impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n     /// Get the name of the current thread, or `<unnamed>` if it was not set.\n     fn thread_name(&self) -> &[u8] {\n         if let Some(ref thread_name) = self.thread_name { thread_name } else { b\"<unnamed>\" }\n@@ -202,28 +196,21 @@ impl<'mir, 'tcx> std::fmt::Debug for Thread<'mir, 'tcx> {\n     }\n }\n \n-impl<'mir, 'tcx> Default for Thread<'mir, 'tcx> {\n-    fn default() -> Self {\n+impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n+    fn new(name: Option<&str>, on_stack_empty: Option<StackEmptyCallback<'mir, 'tcx>>) -> Self {\n         Self {\n             state: ThreadState::Enabled,\n-            thread_name: None,\n+            thread_name: name.map(|name| Vec::from(name.as_bytes())),\n             stack: Vec::new(),\n             top_user_relevant_frame: None,\n             join_status: ThreadJoinStatus::Joinable,\n             panic_payload: None,\n             last_error: None,\n+            on_stack_empty,\n         }\n     }\n }\n \n-impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n-    fn new(name: &str) -> Self {\n-        let mut thread = Thread::default();\n-        thread.thread_name = Some(Vec::from(name.as_bytes()));\n-        thread\n-    }\n-}\n-\n impl VisitTags for Thread<'_, '_> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n         let Thread {\n@@ -234,6 +221,7 @@ impl VisitTags for Thread<'_, '_> {\n             state: _,\n             thread_name: _,\n             join_status: _,\n+            on_stack_empty: _, // we assume the closure captures no GC-relevant state\n         } = self;\n \n         panic_payload.visit_tags(visit);\n@@ -327,22 +315,6 @@ pub struct ThreadManager<'mir, 'tcx> {\n     timeout_callbacks: FxHashMap<ThreadId, TimeoutCallbackInfo<'mir, 'tcx>>,\n }\n \n-impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n-    fn default() -> Self {\n-        let mut threads = IndexVec::new();\n-        // Create the main thread and add it to the list of threads.\n-        threads.push(Thread::new(\"main\"));\n-        Self {\n-            active_thread: ThreadId::new(0),\n-            threads,\n-            sync: SynchronizationState::default(),\n-            thread_local_alloc_ids: Default::default(),\n-            yield_active_thread: false,\n-            timeout_callbacks: FxHashMap::default(),\n-        }\n-    }\n-}\n-\n impl VisitTags for ThreadManager<'_, '_> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n         let ThreadManager {\n@@ -367,8 +339,28 @@ impl VisitTags for ThreadManager<'_, '_> {\n     }\n }\n \n+impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n+    fn default() -> Self {\n+        let mut threads = IndexVec::new();\n+        // Create the main thread and add it to the list of threads.\n+        threads.push(Thread::new(Some(\"main\"), None));\n+        Self {\n+            active_thread: ThreadId::new(0),\n+            threads,\n+            sync: SynchronizationState::default(),\n+            thread_local_alloc_ids: Default::default(),\n+            yield_active_thread: false,\n+            timeout_callbacks: FxHashMap::default(),\n+        }\n+    }\n+}\n+\n impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n-    pub(crate) fn init(ecx: &mut MiriInterpCx<'mir, 'tcx>) {\n+    pub(crate) fn init(\n+        ecx: &mut MiriInterpCx<'mir, 'tcx>,\n+        on_main_stack_empty: StackEmptyCallback<'mir, 'tcx>,\n+    ) {\n+        ecx.machine.threads.threads[ThreadId::new(0)].on_stack_empty = Some(on_main_stack_empty);\n         if ecx.tcx.sess.target.os.as_ref() != \"windows\" {\n             // The main thread can *not* be joined on except on windows.\n             ecx.machine.threads.threads[ThreadId::new(0)].join_status = ThreadJoinStatus::Detached;\n@@ -411,9 +403,9 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n     }\n \n     /// Create a new thread and returns its id.\n-    fn create_thread(&mut self) -> ThreadId {\n+    fn create_thread(&mut self, on_stack_empty: StackEmptyCallback<'mir, 'tcx>) -> ThreadId {\n         let new_thread_id = ThreadId::new(self.threads.len());\n-        self.threads.push(Default::default());\n+        self.threads.push(Thread::new(None, Some(on_stack_empty)));\n         new_thread_id\n     }\n \n@@ -458,7 +450,7 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n     }\n \n     /// Get a mutable borrow of the currently active thread.\n-    fn active_thread_mut(&mut self) -> &mut Thread<'mir, 'tcx> {\n+    pub fn active_thread_mut(&mut self) -> &mut Thread<'mir, 'tcx> {\n         &mut self.threads[self.active_thread]\n     }\n \n@@ -669,37 +661,25 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n     /// long as we can and switch only when we have to (the active thread was\n     /// blocked, terminated, or has explicitly asked to be preempted).\n     fn schedule(&mut self, clock: &Clock) -> InterpResult<'tcx, SchedulingAction> {\n-        // Check whether the thread has **just** terminated (`check_terminated`\n-        // checks whether the thread has popped all its stack and if yes, sets\n-        // the thread state to terminated).\n-        if self.threads[self.active_thread].check_terminated() {\n-            return Ok(SchedulingAction::ExecuteDtors);\n-        }\n-        // If we get here again and the thread is *still* terminated, there are no more dtors to run.\n-        if self.threads[MAIN_THREAD].state == ThreadState::Terminated {\n-            // The main thread terminated; stop the program.\n-            // We do *not* run TLS dtors of remaining threads, which seems to match rustc behavior.\n-            return Ok(SchedulingAction::Stop);\n-        }\n         // This thread and the program can keep going.\n         if self.threads[self.active_thread].state == ThreadState::Enabled\n             && !self.yield_active_thread\n         {\n             // The currently active thread is still enabled, just continue with it.\n             return Ok(SchedulingAction::ExecuteStep);\n         }\n-        // The active thread yielded. Let's see if there are any timeouts to take care of. We do\n-        // this *before* running any other thread, to ensure that timeouts \"in the past\" fire before\n-        // any other thread can take an action. This ensures that for `pthread_cond_timedwait`, \"an\n-        // error is returned if [...] the absolute time specified by abstime has already been passed\n-        // at the time of the call\".\n+        // The active thread yielded or got terminated. Let's see if there are any timeouts to take\n+        // care of. We do this *before* running any other thread, to ensure that timeouts \"in the\n+        // past\" fire before any other thread can take an action. This ensures that for\n+        // `pthread_cond_timedwait`, \"an error is returned if [...] the absolute time specified by\n+        // abstime has already been passed at the time of the call\".\n         // <https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_cond_timedwait.html>\n         let potential_sleep_time =\n             self.timeout_callbacks.values().map(|info| info.call_time.get_wait_time(clock)).min();\n         if potential_sleep_time == Some(Duration::new(0, 0)) {\n             return Ok(SchedulingAction::ExecuteTimeoutCallback);\n         }\n-        // No callbacks scheduled, pick a regular thread to execute.\n+        // No callbacks immediately scheduled, pick a regular thread to execute.\n         // The active thread blocked or yielded. So we go search for another enabled thread.\n         // Crucially, we start searching at the current active thread ID, rather than at 0, since we\n         // want to avoid always scheduling threads 0 and 1 without ever making progress in thread 2.\n@@ -730,15 +710,58 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n             // All threads are currently blocked, but we have unexecuted\n             // timeout_callbacks, which may unblock some of the threads. Hence,\n             // sleep until the first callback.\n-\n-            clock.sleep(sleep_time);\n-            Ok(SchedulingAction::ExecuteTimeoutCallback)\n+            Ok(SchedulingAction::Sleep(sleep_time))\n         } else {\n             throw_machine_stop!(TerminationInfo::Deadlock);\n         }\n     }\n }\n \n+impl<'mir, 'tcx: 'mir> EvalContextPrivExt<'mir, 'tcx> for MiriInterpCx<'mir, 'tcx> {}\n+trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriInterpCxExt<'mir, 'tcx> {\n+    /// Execute a timeout callback on the callback's thread.\n+    #[inline]\n+    fn run_timeout_callback(&mut self) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        let (thread, callback) = if let Some((thread, callback)) =\n+            this.machine.threads.get_ready_callback(&this.machine.clock)\n+        {\n+            (thread, callback)\n+        } else {\n+            // get_ready_callback can return None if the computer's clock\n+            // was shifted after calling the scheduler and before the call\n+            // to get_ready_callback (see issue\n+            // https://github.com/rust-lang/miri/issues/1763). In this case,\n+            // just do nothing, which effectively just returns to the\n+            // scheduler.\n+            return Ok(());\n+        };\n+        // This back-and-forth with `set_active_thread` is here because of two\n+        // design decisions:\n+        // 1. Make the caller and not the callback responsible for changing\n+        //    thread.\n+        // 2. Make the scheduler the only place that can change the active\n+        //    thread.\n+        let old_thread = this.set_active_thread(thread);\n+        callback.call(this)?;\n+        this.set_active_thread(old_thread);\n+        Ok(())\n+    }\n+\n+    #[inline]\n+    fn run_on_stack_empty(&mut self) -> InterpResult<'tcx, Poll<()>> {\n+        let this = self.eval_context_mut();\n+        let mut callback = this\n+            .active_thread_mut()\n+            .on_stack_empty\n+            .take()\n+            .expect(\"`on_stack_empty` not set up, or already running\");\n+        let res = callback(this)?;\n+        this.active_thread_mut().on_stack_empty = Some(callback);\n+        Ok(res)\n+    }\n+}\n+\n // Public interface to thread management.\n impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriInterpCx<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n@@ -773,18 +796,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         }\n     }\n \n+    /// Start a regular (non-main) thread.\n     #[inline]\n-    fn create_thread(&mut self) -> ThreadId {\n-        let this = self.eval_context_mut();\n-        let id = this.machine.threads.create_thread();\n-        if let Some(data_race) = &mut this.machine.data_race {\n-            data_race.thread_created(&this.machine.threads, id);\n-        }\n-        id\n-    }\n-\n-    #[inline]\n-    fn start_thread(\n+    fn start_regular_thread(\n         &mut self,\n         thread: Option<MPlaceTy<'tcx, Provenance>>,\n         start_routine: Pointer<Option<Provenance>>,\n@@ -795,7 +809,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         let this = self.eval_context_mut();\n \n         // Create the new thread\n-        let new_thread_id = this.create_thread();\n+        let new_thread_id = this.machine.threads.create_thread({\n+            let mut state = tls::TlsDtorsState::default();\n+            Box::new(move |m| state.on_stack_empty(m))\n+        });\n+        if let Some(data_race) = &mut this.machine.data_race {\n+            data_race.thread_created(&this.machine.threads, new_thread_id);\n+        }\n \n         // Write the current thread-id, switch to the next thread later\n         // to treat this write operation as occuring on the current thread.\n@@ -888,12 +908,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         this.machine.threads.get_total_thread_count()\n     }\n \n-    #[inline]\n-    fn has_terminated(&self, thread_id: ThreadId) -> bool {\n-        let this = self.eval_context_ref();\n-        this.machine.threads.has_terminated(thread_id)\n-    }\n-\n     #[inline]\n     fn have_all_terminated(&self) -> bool {\n         let this = self.eval_context_ref();\n@@ -943,26 +957,22 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n     where\n         'mir: 'c,\n     {\n-        let this = self.eval_context_ref();\n-        this.machine.threads.get_thread_name(thread)\n+        self.eval_context_ref().machine.threads.get_thread_name(thread)\n     }\n \n     #[inline]\n     fn block_thread(&mut self, thread: ThreadId) {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.block_thread(thread);\n+        self.eval_context_mut().machine.threads.block_thread(thread);\n     }\n \n     #[inline]\n     fn unblock_thread(&mut self, thread: ThreadId) {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.unblock_thread(thread);\n+        self.eval_context_mut().machine.threads.unblock_thread(thread);\n     }\n \n     #[inline]\n     fn yield_active_thread(&mut self) {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.yield_active_thread();\n+        self.eval_context_mut().machine.threads.yield_active_thread();\n     }\n \n     #[inline]\n@@ -995,49 +1005,42 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         this.machine.threads.unregister_timeout_callback_if_exists(thread);\n     }\n \n-    /// Execute a timeout callback on the callback's thread.\n-    #[inline]\n-    fn run_timeout_callback(&mut self) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-        let (thread, callback) = if let Some((thread, callback)) =\n-            this.machine.threads.get_ready_callback(&this.machine.clock)\n-        {\n-            (thread, callback)\n-        } else {\n-            // get_ready_callback can return None if the computer's clock\n-            // was shifted after calling the scheduler and before the call\n-            // to get_ready_callback (see issue\n-            // https://github.com/rust-lang/miri/issues/1763). In this case,\n-            // just do nothing, which effectively just returns to the\n-            // scheduler.\n-            return Ok(());\n-        };\n-        // This back-and-forth with `set_active_thread` is here because of two\n-        // design decisions:\n-        // 1. Make the caller and not the callback responsible for changing\n-        //    thread.\n-        // 2. Make the scheduler the only place that can change the active\n-        //    thread.\n-        let old_thread = this.set_active_thread(thread);\n-        callback.call(this)?;\n-        this.set_active_thread(old_thread);\n-        Ok(())\n-    }\n-\n-    /// Decide which action to take next and on which thread.\n-    #[inline]\n-    fn schedule(&mut self) -> InterpResult<'tcx, SchedulingAction> {\n+    /// Run the core interpreter loop. Returns only when an interrupt occurs (an error or program\n+    /// termination).\n+    fn run_threads(&mut self) -> InterpResult<'tcx, !> {\n         let this = self.eval_context_mut();\n-        this.machine.threads.schedule(&this.machine.clock)\n+        loop {\n+            match this.machine.threads.schedule(&this.machine.clock)? {\n+                SchedulingAction::ExecuteStep => {\n+                    if !this.step()? {\n+                        // See if this thread can do something else.\n+                        match this.run_on_stack_empty()? {\n+                            Poll::Pending => {} // keep going\n+                            Poll::Ready(()) => this.terminate_active_thread()?,\n+                        }\n+                    }\n+                }\n+                SchedulingAction::ExecuteTimeoutCallback => {\n+                    this.run_timeout_callback()?;\n+                }\n+                SchedulingAction::Sleep(duration) => {\n+                    this.machine.clock.sleep(duration);\n+                }\n+            }\n+        }\n     }\n \n     /// Handles thread termination of the active thread: wakes up threads joining on this one,\n     /// and deallocated thread-local statics.\n     ///\n-    /// This is called from `tls.rs` after handling the TLS dtors.\n+    /// This is called by the eval loop when a thread's on_stack_empty returns `Ready`.\n     #[inline]\n-    fn thread_terminated(&mut self) -> InterpResult<'tcx> {\n+    fn terminate_active_thread(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n+        let thread = this.active_thread_mut();\n+        assert!(thread.stack.is_empty(), \"only threads with an empty stack can be terminated\");\n+        thread.state = ThreadState::Terminated;\n+\n         for ptr in this.machine.threads.thread_terminated(this.machine.data_race.as_mut()) {\n             this.deallocate_ptr(ptr.into(), None, MiriMemoryKind::Tls.into())?;\n         }"}, {"sha": "5cd0a0eeb58c15d191100e85f32366b093173d9b", "filename": "src/tools/miri/src/diagnostics.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fdiagnostics.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -11,7 +11,10 @@ use crate::*;\n \n /// Details of premature program termination.\n pub enum TerminationInfo {\n-    Exit(i64),\n+    Exit {\n+        code: i64,\n+        leak_check: bool,\n+    },\n     Abort(String),\n     UnsupportedInIsolation(String),\n     StackedBorrowsUb {\n@@ -38,7 +41,7 @@ impl fmt::Display for TerminationInfo {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         use TerminationInfo::*;\n         match self {\n-            Exit(code) => write!(f, \"the evaluated program completed with exit code {code}\"),\n+            Exit { code, .. } => write!(f, \"the evaluated program completed with exit code {code}\"),\n             Abort(msg) => write!(f, \"{msg}\"),\n             UnsupportedInIsolation(msg) => write!(f, \"{msg}\"),\n             Int2PtrWithStrictProvenance =>\n@@ -148,11 +151,11 @@ fn prune_stacktrace<'tcx>(\n \n /// Emit a custom diagnostic without going through the miri-engine machinery.\n ///\n-/// Returns `Some` if this was regular program termination with a given exit code, `None` otherwise.\n+/// Returns `Some` if this was regular program termination with a given exit code and a `bool` indicating whether a leak check should happen; `None` otherwise.\n pub fn report_error<'tcx, 'mir>(\n     ecx: &InterpCx<'mir, 'tcx, MiriMachine<'mir, 'tcx>>,\n     e: InterpErrorInfo<'tcx>,\n-) -> Option<i64> {\n+) -> Option<(i64, bool)> {\n     use InterpError::*;\n \n     let mut msg = vec![];\n@@ -161,7 +164,7 @@ pub fn report_error<'tcx, 'mir>(\n         let info = info.downcast_ref::<TerminationInfo>().expect(\"invalid MachineStop payload\");\n         use TerminationInfo::*;\n         let title = match info {\n-            Exit(code) => return Some(*code),\n+            Exit { code, leak_check } => return Some((*code, *leak_check)),\n             Abort(_) => Some(\"abnormal termination\"),\n             UnsupportedInIsolation(_) | Int2PtrWithStrictProvenance =>\n                 Some(\"unsupported operation\"),"}, {"sha": "b8578b1277f53ad94a7103e963556d900d2ba47c", "filename": "src/tools/miri/src/eval.rs", "status": "modified", "additions": 107, "deletions": 56, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Feval.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -4,6 +4,7 @@ use std::ffi::{OsStr, OsString};\n use std::iter;\n use std::panic::{self, AssertUnwindSafe};\n use std::path::PathBuf;\n+use std::task::Poll;\n use std::thread;\n \n use log::info;\n@@ -20,8 +21,14 @@ use rustc_target::spec::abi::Abi;\n \n use rustc_session::config::EntryFnType;\n \n+use crate::shims::tls;\n use crate::*;\n \n+/// When the main thread would exit, we will yield to any other thread that is ready to execute.\n+/// But we must only do that a finite number of times, or a background thread running `loop {}`\n+/// will hang the program.\n+const MAIN_THREAD_YIELDS_AT_SHUTDOWN: u32 = 256;\n+\n #[derive(Copy, Clone, Debug, PartialEq)]\n pub enum AlignmentCheck {\n     /// Do not check alignment.\n@@ -172,17 +179,79 @@ impl Default for MiriConfig {\n     }\n }\n \n-/// Returns a freshly created `InterpCx`, along with an `MPlaceTy` representing\n-/// the location where the return value of the `start` function will be\n-/// written to.\n+/// The state of the main thread. Implementation detail of `on_main_stack_empty`.\n+#[derive(Default, Debug)]\n+enum MainThreadState {\n+    #[default]\n+    Running,\n+    TlsDtors(tls::TlsDtorsState),\n+    Yield {\n+        remaining: u32,\n+    },\n+    Done,\n+}\n+\n+impl MainThreadState {\n+    fn on_main_stack_empty<'tcx>(\n+        &mut self,\n+        this: &mut MiriInterpCx<'_, 'tcx>,\n+    ) -> InterpResult<'tcx, Poll<()>> {\n+        use MainThreadState::*;\n+        match self {\n+            Running => {\n+                *self = TlsDtors(Default::default());\n+            }\n+            TlsDtors(state) =>\n+                match state.on_stack_empty(this)? {\n+                    Poll::Pending => {} // just keep going\n+                    Poll::Ready(()) => {\n+                        // Give background threads a chance to finish by yielding the main thread a\n+                        // couple of times -- but only if we would also preempt threads randomly.\n+                        if this.machine.preemption_rate > 0.0 {\n+                            // There is a non-zero chance they will yield back to us often enough to\n+                            // make Miri terminate eventually.\n+                            *self = Yield { remaining: MAIN_THREAD_YIELDS_AT_SHUTDOWN };\n+                        } else {\n+                            // The other threads did not get preempted, so no need to yield back to\n+                            // them.\n+                            *self = Done;\n+                        }\n+                    }\n+                },\n+            Yield { remaining } =>\n+                match remaining.checked_sub(1) {\n+                    None => *self = Done,\n+                    Some(new_remaining) => {\n+                        *remaining = new_remaining;\n+                        this.yield_active_thread();\n+                    }\n+                },\n+            Done => {\n+                // Figure out exit code.\n+                let ret_place = MPlaceTy::from_aligned_ptr(\n+                    this.machine.main_fn_ret_place.unwrap().ptr,\n+                    this.machine.layouts.isize,\n+                );\n+                let exit_code = this.read_scalar(&ret_place.into())?.to_machine_isize(this)?;\n+                // Need to call this ourselves since we are not going to return to the scheduler\n+                // loop, and we want the main thread TLS to not show up as memory leaks.\n+                this.terminate_active_thread()?;\n+                // Stop interpreter loop.\n+                throw_machine_stop!(TerminationInfo::Exit { code: exit_code, leak_check: true });\n+            }\n+        }\n+        Ok(Poll::Pending)\n+    }\n+}\n+\n+/// Returns a freshly created `InterpCx`.\n /// Public because this is also used by `priroda`.\n pub fn create_ecx<'mir, 'tcx: 'mir>(\n     tcx: TyCtxt<'tcx>,\n     entry_id: DefId,\n     entry_type: EntryFnType,\n     config: &MiriConfig,\n-) -> InterpResult<'tcx, (InterpCx<'mir, 'tcx, MiriMachine<'mir, 'tcx>>, MPlaceTy<'tcx, Provenance>)>\n-{\n+) -> InterpResult<'tcx, InterpCx<'mir, 'tcx, MiriMachine<'mir, 'tcx>>> {\n     let param_env = ty::ParamEnv::reveal_all();\n     let layout_cx = LayoutCx { tcx, param_env };\n     let mut ecx = InterpCx::new(\n@@ -193,7 +262,11 @@ pub fn create_ecx<'mir, 'tcx: 'mir>(\n     );\n \n     // Some parts of initialization require a full `InterpCx`.\n-    MiriMachine::late_init(&mut ecx, config)?;\n+    MiriMachine::late_init(&mut ecx, config, {\n+        let mut state = MainThreadState::default();\n+        // Cannot capture anything GC-relevant here.\n+        Box::new(move |m| state.on_main_stack_empty(m))\n+    })?;\n \n     // Make sure we have MIR. We check MIR for some stable monomorphic function in libcore.\n     let sentinel = ecx.try_resolve_path(&[\"core\", \"ascii\", \"escape_default\"], Namespace::ValueNS);\n@@ -274,6 +347,7 @@ pub fn create_ecx<'mir, 'tcx: 'mir>(\n \n     // Return place (in static memory so that it does not count as leak).\n     let ret_place = ecx.allocate(ecx.machine.layouts.isize, MiriMemoryKind::Machine.into())?;\n+    ecx.machine.main_fn_ret_place = Some(*ret_place);\n     // Call start function.\n \n     match entry_type {\n@@ -321,7 +395,7 @@ pub fn create_ecx<'mir, 'tcx: 'mir>(\n         }\n     }\n \n-    Ok((ecx, ret_place))\n+    Ok(ecx)\n }\n \n /// Evaluates the entry function specified by `entry_id`.\n@@ -337,7 +411,7 @@ pub fn eval_entry<'tcx>(\n     // Copy setting before we move `config`.\n     let ignore_leaks = config.ignore_leaks;\n \n-    let (mut ecx, ret_place) = match create_ecx(tcx, entry_id, entry_type, &config) {\n+    let mut ecx = match create_ecx(tcx, entry_id, entry_type, &config) {\n         Ok(v) => v,\n         Err(err) => {\n             err.print_backtrace();\n@@ -346,34 +420,17 @@ pub fn eval_entry<'tcx>(\n     };\n \n     // Perform the main execution.\n-    let res: thread::Result<InterpResult<'_, i64>> = panic::catch_unwind(AssertUnwindSafe(|| {\n-        // Main loop.\n-        loop {\n-            match ecx.schedule()? {\n-                SchedulingAction::ExecuteStep => {\n-                    assert!(ecx.step()?, \"a terminated thread was scheduled for execution\");\n-                }\n-                SchedulingAction::ExecuteTimeoutCallback => {\n-                    ecx.run_timeout_callback()?;\n-                }\n-                SchedulingAction::ExecuteDtors => {\n-                    // This will either enable the thread again (so we go back\n-                    // to `ExecuteStep`), or determine that this thread is done\n-                    // for good.\n-                    ecx.schedule_next_tls_dtor_for_active_thread()?;\n-                }\n-                SchedulingAction::Stop => {\n-                    break;\n-                }\n-            }\n-        }\n-        let return_code = ecx.read_scalar(&ret_place.into())?.to_machine_isize(&ecx)?;\n-        Ok(return_code)\n-    }));\n+    let res: thread::Result<InterpResult<'_, !>> =\n+        panic::catch_unwind(AssertUnwindSafe(|| ecx.run_threads()));\n     let res = res.unwrap_or_else(|panic_payload| {\n         ecx.handle_ice();\n         panic::resume_unwind(panic_payload)\n     });\n+    let res = match res {\n+        Err(res) => res,\n+        // `Ok` can never happen\n+        Ok(never) => match never {},\n+    };\n \n     // Machine cleanup. Only do this if all threads have terminated; threads that are still running\n     // might cause Stacked Borrows errors (https://github.com/rust-lang/miri/issues/2396).\n@@ -386,32 +443,26 @@ pub fn eval_entry<'tcx>(\n     }\n \n     // Process the result.\n-    match res {\n-        Ok(return_code) => {\n-            if !ignore_leaks {\n-                // Check for thread leaks.\n-                if !ecx.have_all_terminated() {\n-                    tcx.sess.err(\n-                        \"the main thread terminated without waiting for all remaining threads\",\n-                    );\n-                    tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n-                    return None;\n-                }\n-                // Check for memory leaks.\n-                info!(\"Additonal static roots: {:?}\", ecx.machine.static_roots);\n-                let leaks = ecx.leak_report(&ecx.machine.static_roots);\n-                if leaks != 0 {\n-                    tcx.sess.err(\"the evaluated program leaked memory\");\n-                    tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n-                    // Ignore the provided return code - let the reported error\n-                    // determine the return code.\n-                    return None;\n-                }\n-            }\n-            Some(return_code)\n+    let (return_code, leak_check) = report_error(&ecx, res)?;\n+    if leak_check && !ignore_leaks {\n+        // Check for thread leaks.\n+        if !ecx.have_all_terminated() {\n+            tcx.sess.err(\"the main thread terminated without waiting for all remaining threads\");\n+            tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n+            return None;\n+        }\n+        // Check for memory leaks.\n+        info!(\"Additonal static roots: {:?}\", ecx.machine.static_roots);\n+        let leaks = ecx.leak_report(&ecx.machine.static_roots);\n+        if leaks != 0 {\n+            tcx.sess.err(\"the evaluated program leaked memory\");\n+            tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n+            // Ignore the provided return code - let the reported error\n+            // determine the return code.\n+            return None;\n         }\n-        Err(e) => report_error(&ecx, e),\n     }\n+    Some(return_code)\n }\n \n /// Turns an array of arguments into a Windows command line string."}, {"sha": "6f483cf2cc4800d84ef71ef4781de05e65437f66", "filename": "src/tools/miri/src/lib.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Flib.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -81,15 +81,15 @@ pub use crate::shims::intrinsics::EvalContextExt as _;\n pub use crate::shims::os_str::EvalContextExt as _;\n pub use crate::shims::panic::{CatchUnwindData, EvalContextExt as _};\n pub use crate::shims::time::EvalContextExt as _;\n-pub use crate::shims::tls::{EvalContextExt as _, TlsData};\n+pub use crate::shims::tls::TlsData;\n pub use crate::shims::EvalContextExt as _;\n \n pub use crate::clock::{Clock, Instant};\n pub use crate::concurrency::{\n     data_race::{AtomicFenceOrd, AtomicReadOrd, AtomicRwOrd, AtomicWriteOrd, EvalContextExt as _},\n     init_once::{EvalContextExt as _, InitOnceId},\n     sync::{CondvarId, EvalContextExt as _, MutexId, RwLockId, SyncId},\n-    thread::{EvalContextExt as _, SchedulingAction, ThreadId, ThreadManager, ThreadState, Time},\n+    thread::{EvalContextExt as _, StackEmptyCallback, ThreadId, ThreadManager, Time},\n };\n pub use crate::diagnostics::{\n     report_error, EvalContextExt as _, NonHaltingDiagnostic, TerminationInfo,\n@@ -107,7 +107,7 @@ pub use crate::mono_hash_map::MonoHashMap;\n pub use crate::operator::EvalContextExt as _;\n pub use crate::range_map::RangeMap;\n pub use crate::stacked_borrows::{\n-    CallId, EvalContextExt as _, Item, Permission, RetagFields, SbTag, Stack, Stacks,\n+    CallId, EvalContextExt as _, Item, Permission, RetagFields, SbTag,\n };\n pub use crate::tag_gc::{EvalContextExt as _, VisitTags};\n "}, {"sha": "4d3444bc39cdd97a839f0f9fcf6eb727a8dd4352", "filename": "src/tools/miri/src/machine.rs", "status": "modified", "additions": 15, "deletions": 2, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -363,6 +363,9 @@ pub struct MiriMachine<'mir, 'tcx> {\n     /// Miri does not expose env vars from the host to the emulated program.\n     pub(crate) env_vars: EnvVars<'tcx>,\n \n+    /// Return place of the main function.\n+    pub(crate) main_fn_ret_place: Option<MemPlace<Provenance>>,\n+\n     /// Program arguments (`Option` because we can only initialize them after creating the ecx).\n     /// These are *pointers* to argc/argv because macOS.\n     /// We also need the full command line as one string because of Windows.\n@@ -492,6 +495,7 @@ impl<'mir, 'tcx> MiriMachine<'mir, 'tcx> {\n             intptrcast: RefCell::new(intptrcast::GlobalStateInner::new(config)),\n             // `env_vars` depends on a full interpreter so we cannot properly initialize it yet.\n             env_vars: EnvVars::default(),\n+            main_fn_ret_place: None,\n             argc: None,\n             argv: None,\n             cmd_line: None,\n@@ -556,10 +560,11 @@ impl<'mir, 'tcx> MiriMachine<'mir, 'tcx> {\n     pub(crate) fn late_init(\n         this: &mut MiriInterpCx<'mir, 'tcx>,\n         config: &MiriConfig,\n+        on_main_stack_empty: StackEmptyCallback<'mir, 'tcx>,\n     ) -> InterpResult<'tcx> {\n         EnvVars::init(this, config)?;\n         MiriMachine::init_extern_statics(this)?;\n-        ThreadManager::init(this);\n+        ThreadManager::init(this, on_main_stack_empty);\n         Ok(())\n     }\n \n@@ -657,6 +662,7 @@ impl VisitTags for MiriMachine<'_, '_> {\n             threads,\n             tls,\n             env_vars,\n+            main_fn_ret_place,\n             argc,\n             argv,\n             cmd_line,\n@@ -702,6 +708,7 @@ impl VisitTags for MiriMachine<'_, '_> {\n         data_race.visit_tags(visit);\n         stacked_borrows.visit_tags(visit);\n         intptrcast.visit_tags(visit);\n+        main_fn_ret_place.visit_tags(visit);\n         argc.visit_tags(visit);\n         argv.visit_tags(visit);\n         cmd_line.visit_tags(visit);\n@@ -901,7 +908,13 @@ impl<'mir, 'tcx> Machine<'mir, 'tcx> for MiriMachine<'mir, 'tcx> {\n \n         let alloc = alloc.into_owned();\n         let stacks = ecx.machine.stacked_borrows.as_ref().map(|stacked_borrows| {\n-            Stacks::new_allocation(id, alloc.size(), stacked_borrows, kind, &ecx.machine)\n+            stacked_borrows::Stacks::new_allocation(\n+                id,\n+                alloc.size(),\n+                stacked_borrows,\n+                kind,\n+                &ecx.machine,\n+            )\n         });\n         let race_alloc = ecx.machine.data_race.as_ref().map(|data_race| {\n             data_race::AllocExtra::new_allocation("}, {"sha": "f72521f64adaf0b45c4ed3e4daa4562f05fd58d4", "filename": "src/tools/miri/src/shims/foreign_items.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fforeign_items.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fforeign_items.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fforeign_items.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -286,7 +286,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n                         let [code] = this.check_shim(abi, exp_abi, link_name, args)?;\n                         // it's really u32 for ExitProcess, but we have to put it into the `Exit` variant anyway\n                         let code = this.read_scalar(code)?.to_i32()?;\n-                        throw_machine_stop!(TerminationInfo::Exit(code.into()));\n+                        throw_machine_stop!(TerminationInfo::Exit { code: code.into(), leak_check: false });\n                     }\n                     \"abort\" => {\n                         let [] = this.check_shim(abi, Abi::C { unwind: false }, link_name, args)?;"}, {"sha": "fe278ff717f0cc17c2c98c7e424655aed3b66bd0", "filename": "src/tools/miri/src/shims/tls.rs", "status": "modified", "additions": 81, "deletions": 112, "changes": 193, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Ftls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Ftls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Ftls.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -1,12 +1,11 @@\n //! Implement thread-local storage.\n \n use std::collections::btree_map::Entry as BTreeEntry;\n-use std::collections::hash_map::Entry as HashMapEntry;\n use std::collections::BTreeMap;\n+use std::task::Poll;\n \n use log::trace;\n \n-use rustc_data_structures::fx::FxHashMap;\n use rustc_middle::ty;\n use rustc_target::abi::{HasDataLayout, Size};\n use rustc_target::spec::abi::Abi;\n@@ -23,12 +22,12 @@ pub struct TlsEntry<'tcx> {\n     dtor: Option<ty::Instance<'tcx>>,\n }\n \n-#[derive(Clone, Debug)]\n-struct RunningDtorsState {\n+#[derive(Default, Debug)]\n+struct RunningDtorState {\n     /// The last TlsKey used to retrieve a TLS destructor. `None` means that we\n     /// have not tried to retrieve a TLS destructor yet or that we already tried\n     /// all keys.\n-    last_dtor_key: Option<TlsKey>,\n+    last_key: Option<TlsKey>,\n }\n \n #[derive(Debug)]\n@@ -42,11 +41,6 @@ pub struct TlsData<'tcx> {\n     /// A single per thread destructor of the thread local storage (that's how\n     /// things work on macOS) with a data argument.\n     macos_thread_dtors: BTreeMap<ThreadId, (ty::Instance<'tcx>, Scalar<Provenance>)>,\n-\n-    /// State for currently running TLS dtors. If this map contains a key for a\n-    /// specific thread, it means that we are in the \"destruct\" phase, during\n-    /// which some operations are UB.\n-    dtors_running: FxHashMap<ThreadId, RunningDtorsState>,\n }\n \n impl<'tcx> Default for TlsData<'tcx> {\n@@ -55,7 +49,6 @@ impl<'tcx> Default for TlsData<'tcx> {\n             next_key: 1, // start with 1 as we must not use 0 on Windows\n             keys: Default::default(),\n             macos_thread_dtors: Default::default(),\n-            dtors_running: Default::default(),\n         }\n     }\n }\n@@ -143,12 +136,6 @@ impl<'tcx> TlsData<'tcx> {\n         dtor: ty::Instance<'tcx>,\n         data: Scalar<Provenance>,\n     ) -> InterpResult<'tcx> {\n-        if self.dtors_running.contains_key(&thread) {\n-            // UB, according to libstd docs.\n-            throw_ub_format!(\n-                \"setting thread's local storage destructor while destructors are already running\"\n-            );\n-        }\n         if self.macos_thread_dtors.insert(thread, (dtor, data)).is_some() {\n             throw_unsup_format!(\n                 \"setting more than one thread local storage destructor for the same thread is not supported\"\n@@ -211,21 +198,6 @@ impl<'tcx> TlsData<'tcx> {\n         None\n     }\n \n-    /// Set that dtors are running for `thread`. It is guaranteed not to change\n-    /// the existing values stored in `dtors_running` for this thread. Returns\n-    /// `true` if dtors for `thread` are already running.\n-    fn set_dtors_running_for_thread(&mut self, thread: ThreadId) -> bool {\n-        match self.dtors_running.entry(thread) {\n-            HashMapEntry::Occupied(_) => true,\n-            HashMapEntry::Vacant(entry) => {\n-                // We cannot just do `self.dtors_running.insert` because that\n-                // would overwrite `last_dtor_key` with `None`.\n-                entry.insert(RunningDtorsState { last_dtor_key: None });\n-                false\n-            }\n-        }\n-    }\n-\n     /// Delete all TLS entries for the given thread. This function should be\n     /// called after all TLS destructors have already finished.\n     fn delete_all_thread_tls(&mut self, thread_id: ThreadId) {\n@@ -237,7 +209,7 @@ impl<'tcx> TlsData<'tcx> {\n \n impl VisitTags for TlsData<'_> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n-        let TlsData { keys, macos_thread_dtors, next_key: _, dtors_running: _ } = self;\n+        let TlsData { keys, macos_thread_dtors, next_key: _ } = self;\n \n         for scalar in keys.values().flat_map(|v| v.data.values()) {\n             scalar.visit_tags(visit);\n@@ -248,13 +220,77 @@ impl VisitTags for TlsData<'_> {\n     }\n }\n \n+#[derive(Debug, Default)]\n+pub struct TlsDtorsState(TlsDtorsStatePriv);\n+\n+#[derive(Debug, Default)]\n+enum TlsDtorsStatePriv {\n+    #[default]\n+    Init,\n+    PthreadDtors(RunningDtorState),\n+    Done,\n+}\n+\n+impl TlsDtorsState {\n+    pub fn on_stack_empty<'tcx>(\n+        &mut self,\n+        this: &mut MiriInterpCx<'_, 'tcx>,\n+    ) -> InterpResult<'tcx, Poll<()>> {\n+        use TlsDtorsStatePriv::*;\n+        match &mut self.0 {\n+            Init => {\n+                match this.tcx.sess.target.os.as_ref() {\n+                    \"linux\" | \"freebsd\" | \"android\" => {\n+                        // Run the pthread dtors.\n+                        self.0 = PthreadDtors(Default::default());\n+                    }\n+                    \"macos\" => {\n+                        // The macOS thread wide destructor runs \"before any TLS slots get\n+                        // freed\", so do that first.\n+                        this.schedule_macos_tls_dtor()?;\n+                        // When the stack is empty again, go on with the pthread dtors.\n+                        self.0 = PthreadDtors(Default::default());\n+                    }\n+                    \"windows\" => {\n+                        // Run the special magic hook.\n+                        this.schedule_windows_tls_dtors()?;\n+                        // And move to the final state.\n+                        self.0 = Done;\n+                    }\n+                    \"wasi\" | \"none\" => {\n+                        // No OS, no TLS dtors.\n+                        // FIXME: should we do something on wasi?\n+                        self.0 = Done;\n+                    }\n+                    os => {\n+                        throw_unsup_format!(\n+                            \"the TLS machinery does not know how to handle OS `{os}`\"\n+                        );\n+                    }\n+                }\n+            }\n+            PthreadDtors(state) => {\n+                match this.schedule_next_pthread_tls_dtor(state)? {\n+                    Poll::Pending => {} // just keep going\n+                    Poll::Ready(()) => self.0 = Done,\n+                }\n+            }\n+            Done => {\n+                this.machine.tls.delete_all_thread_tls(this.get_active_thread());\n+                return Ok(Poll::Ready(()));\n+            }\n+        }\n+\n+        Ok(Poll::Pending)\n+    }\n+}\n+\n impl<'mir, 'tcx: 'mir> EvalContextPrivExt<'mir, 'tcx> for crate::MiriInterpCx<'mir, 'tcx> {}\n trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n     /// Schedule TLS destructors for Windows.\n     /// On windows, TLS destructors are managed by std.\n     fn schedule_windows_tls_dtors(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        let active_thread = this.get_active_thread();\n \n         // Windows has a special magic linker section that is run on certain events.\n         // Instead of searching for that section and supporting arbitrary hooks in there\n@@ -284,16 +320,12 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n             None,\n             StackPopCleanup::Root { cleanup: true },\n         )?;\n-\n-        this.enable_thread(active_thread);\n         Ok(())\n     }\n \n     /// Schedule the MacOS thread destructor of the thread local storage to be\n-    /// executed. Returns `true` if scheduled.\n-    ///\n-    /// Note: It is safe to call this function also on other Unixes.\n-    fn schedule_macos_tls_dtor(&mut self) -> InterpResult<'tcx, bool> {\n+    /// executed.\n+    fn schedule_macos_tls_dtor(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         let thread_id = this.get_active_thread();\n         if let Some((instance, data)) = this.machine.tls.macos_thread_dtors.remove(&thread_id) {\n@@ -306,35 +338,27 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n                 None,\n                 StackPopCleanup::Root { cleanup: true },\n             )?;\n-\n-            // Enable the thread so that it steps through the destructor which\n-            // we just scheduled. Since we deleted the destructor, it is\n-            // guaranteed that we will schedule it again. The `dtors_running`\n-            // flag will prevent the code from adding the destructor again.\n-            this.enable_thread(thread_id);\n-            Ok(true)\n-        } else {\n-            Ok(false)\n         }\n+        Ok(())\n     }\n \n     /// Schedule a pthread TLS destructor. Returns `true` if found\n     /// a destructor to schedule, and `false` otherwise.\n-    fn schedule_next_pthread_tls_dtor(&mut self) -> InterpResult<'tcx, bool> {\n+    fn schedule_next_pthread_tls_dtor(\n+        &mut self,\n+        state: &mut RunningDtorState,\n+    ) -> InterpResult<'tcx, Poll<()>> {\n         let this = self.eval_context_mut();\n         let active_thread = this.get_active_thread();\n \n-        assert!(this.has_terminated(active_thread), \"running TLS dtors for non-terminated thread\");\n         // Fetch next dtor after `key`.\n-        let last_key = this.machine.tls.dtors_running[&active_thread].last_dtor_key;\n-        let dtor = match this.machine.tls.fetch_tls_dtor(last_key, active_thread) {\n+        let dtor = match this.machine.tls.fetch_tls_dtor(state.last_key, active_thread) {\n             dtor @ Some(_) => dtor,\n             // We ran each dtor once, start over from the beginning.\n             None => this.machine.tls.fetch_tls_dtor(None, active_thread),\n         };\n         if let Some((instance, ptr, key)) = dtor {\n-            this.machine.tls.dtors_running.get_mut(&active_thread).unwrap().last_dtor_key =\n-                Some(key);\n+            state.last_key = Some(key);\n             trace!(\"Running TLS dtor {:?} on {:?} at {:?}\", instance, ptr, active_thread);\n             assert!(\n                 !ptr.to_machine_usize(this).unwrap() != 0,\n@@ -349,64 +373,9 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n                 StackPopCleanup::Root { cleanup: true },\n             )?;\n \n-            this.enable_thread(active_thread);\n-            return Ok(true);\n-        }\n-        this.machine.tls.dtors_running.get_mut(&active_thread).unwrap().last_dtor_key = None;\n-\n-        Ok(false)\n-    }\n-}\n-\n-impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriInterpCx<'mir, 'tcx> {}\n-pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n-    /// Schedule an active thread's TLS destructor to run on the active thread.\n-    /// Note that this function does not run the destructors itself, it just\n-    /// schedules them one by one each time it is called and reenables the\n-    /// thread so that it can be executed normally by the main execution loop.\n-    ///\n-    /// Note: we consistently run TLS destructors for all threads, including the\n-    /// main thread. However, it is not clear that we should run the TLS\n-    /// destructors for the main thread. See issue:\n-    /// <https://github.com/rust-lang/rust/issues/28129>.\n-    fn schedule_next_tls_dtor_for_active_thread(&mut self) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-        let active_thread = this.get_active_thread();\n-        trace!(\"schedule_next_tls_dtor_for_active_thread on thread {:?}\", active_thread);\n-\n-        if !this.machine.tls.set_dtors_running_for_thread(active_thread) {\n-            // This is the first time we got asked to schedule a destructor. The\n-            // Windows schedule destructor function must be called exactly once,\n-            // this is why it is in this block.\n-            if this.tcx.sess.target.os == \"windows\" {\n-                // On Windows, we signal that the thread quit by starting the\n-                // relevant function, reenabling the thread, and going back to\n-                // the scheduler.\n-                this.schedule_windows_tls_dtors()?;\n-                return Ok(());\n-            }\n+            return Ok(Poll::Pending);\n         }\n-        // The remaining dtors make some progress each time around the scheduler loop,\n-        // until they return `false` to indicate that they are done.\n-\n-        // The macOS thread wide destructor runs \"before any TLS slots get\n-        // freed\", so do that first.\n-        if this.schedule_macos_tls_dtor()? {\n-            // We have scheduled a MacOS dtor to run on the thread. Execute it\n-            // to completion and come back here. Scheduling a destructor\n-            // destroys it, so we will not enter this branch again.\n-            return Ok(());\n-        }\n-        if this.schedule_next_pthread_tls_dtor()? {\n-            // We have scheduled a pthread destructor and removed it from the\n-            // destructors list. Run it to completion and come back here.\n-            return Ok(());\n-        }\n-\n-        // All dtors done!\n-        this.machine.tls.delete_all_thread_tls(active_thread);\n-        this.thread_terminated()?;\n \n-        Ok(())\n+        Ok(Poll::Ready(()))\n     }\n }"}, {"sha": "5b9dc90f0f0060c63524e4297e83aec4d8301532", "filename": "src/tools/miri/src/shims/unix/thread.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Funix%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Funix%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Funix%2Fthread.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -19,7 +19,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n \n         let func_arg = this.read_immediate(arg)?;\n \n-        this.start_thread(\n+        this.start_regular_thread(\n             Some(thread_info_place),\n             start_routine,\n             Abi::C { unwind: false },"}, {"sha": "25a5194caa096540d997df4c13dfe33c42ca9464", "filename": "src/tools/miri/src/shims/windows/thread.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fwindows%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fwindows%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fwindows%2Fthread.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -46,7 +46,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n             throw_unsup_format!(\"non-null `lpThreadAttributes` in `CreateThread`\")\n         }\n \n-        this.start_thread(\n+        this.start_regular_thread(\n             thread,\n             start_routine,\n             Abi::System { unwind: false },"}, {"sha": "023f6005419a603310a4fb44327b3d98c4b61903", "filename": "src/tools/miri/src/stacked_borrows/diagnostics.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fstacked_borrows%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Fsrc%2Fstacked_borrows%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fstacked_borrows%2Fdiagnostics.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -5,7 +5,9 @@ use rustc_middle::mir::interpret::{alloc_range, AllocId, AllocRange};\n use rustc_span::{Span, SpanData};\n use rustc_target::abi::Size;\n \n-use crate::stacked_borrows::{err_sb_ub, AccessKind, GlobalStateInner, Permission, ProtectorKind};\n+use crate::stacked_borrows::{\n+    err_sb_ub, AccessKind, GlobalStateInner, Permission, ProtectorKind, Stack,\n+};\n use crate::*;\n \n use rustc_middle::mir::interpret::InterpError;"}, {"sha": "f28e43696f709c850a231daff02d5ea8d9488d99", "filename": "src/tools/miri/tests/many-seeds/scoped-thread-leak.rs", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Ftests%2Fmany-seeds%2Fscoped-thread-leak.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Ftests%2Fmany-seeds%2Fscoped-thread-leak.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Fmany-seeds%2Fscoped-thread-leak.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -0,0 +1,8 @@\n+//! Regression test for https://github.com/rust-lang/miri/issues/2629\n+use std::thread;\n+\n+fn main() {\n+    thread::scope(|s| {\n+        s.spawn(|| {});\n+    });\n+}"}, {"sha": "ce5d17f5f2dc59ec9e0b81e0762cfdd699703b30", "filename": "src/tools/miri/tests/pass/concurrency/scope.rs", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fconcurrency%2Fscope.rs", "raw_url": "https://github.com/rust-lang/rust/raw/623b4aba6c83a3aa725dfd722c47eb8e0f468c83/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fconcurrency%2Fscope.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fconcurrency%2Fscope.rs?ref=623b4aba6c83a3aa725dfd722c47eb8e0f468c83", "patch": "@@ -0,0 +1,24 @@\n+use std::thread;\n+\n+fn main() {\n+    let mut a = vec![1, 2, 3];\n+    let mut x = 0;\n+\n+    thread::scope(|s| {\n+        s.spawn(|| {\n+            // We can borrow `a` here.\n+            let _s = format!(\"hello from the first scoped thread: {a:?}\");\n+        });\n+        s.spawn(|| {\n+            let _s = format!(\"hello from the second scoped thread\");\n+            // We can even mutably borrow `x` here,\n+            // because no other threads are using it.\n+            x += a[0] + a[2];\n+        });\n+        let _s = format!(\"hello from the main thread\");\n+    });\n+\n+    // After the scope, we can modify and access our variables again:\n+    a.push(4);\n+    assert_eq!(x, a.len());\n+}"}]}