{"sha": "bdcd08278a4b442bd156e3704065403d86728eda", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJkY2QwODI3OGE0YjQ0MmJkMTU2ZTM3MDQwNjU0MDNkODY3MjhlZGE=", "commit": {"author": {"name": "Irina Popa", "email": "irinagpopa@gmail.com", "date": "2017-12-18T14:18:36Z"}, "committer": {"name": "Irina Popa", "email": "irinagpopa@gmail.com", "date": "2018-04-26T13:50:20Z"}, "message": "rustc_target: move in type definitions from ty::layout.", "tree": {"sha": "6221961db85187bb0dfd658a282ca203a9549304", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6221961db85187bb0dfd658a282ca203a9549304"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bdcd08278a4b442bd156e3704065403d86728eda", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bdcd08278a4b442bd156e3704065403d86728eda", "html_url": "https://github.com/rust-lang/rust/commit/bdcd08278a4b442bd156e3704065403d86728eda", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bdcd08278a4b442bd156e3704065403d86728eda/comments", "author": {"login": "irinagpopa", "id": 32459019, "node_id": "MDQ6VXNlcjMyNDU5MDE5", "avatar_url": "https://avatars.githubusercontent.com/u/32459019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irinagpopa", "html_url": "https://github.com/irinagpopa", "followers_url": "https://api.github.com/users/irinagpopa/followers", "following_url": "https://api.github.com/users/irinagpopa/following{/other_user}", "gists_url": "https://api.github.com/users/irinagpopa/gists{/gist_id}", "starred_url": "https://api.github.com/users/irinagpopa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irinagpopa/subscriptions", "organizations_url": "https://api.github.com/users/irinagpopa/orgs", "repos_url": "https://api.github.com/users/irinagpopa/repos", "events_url": "https://api.github.com/users/irinagpopa/events{/privacy}", "received_events_url": "https://api.github.com/users/irinagpopa/received_events", "type": "User", "site_admin": false}, "committer": {"login": "irinagpopa", "id": 32459019, "node_id": "MDQ6VXNlcjMyNDU5MDE5", "avatar_url": "https://avatars.githubusercontent.com/u/32459019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irinagpopa", "html_url": "https://github.com/irinagpopa", "followers_url": "https://api.github.com/users/irinagpopa/followers", "following_url": "https://api.github.com/users/irinagpopa/following{/other_user}", "gists_url": "https://api.github.com/users/irinagpopa/gists{/gist_id}", "starred_url": "https://api.github.com/users/irinagpopa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irinagpopa/subscriptions", "organizations_url": "https://api.github.com/users/irinagpopa/orgs", "repos_url": "https://api.github.com/users/irinagpopa/repos", "events_url": "https://api.github.com/users/irinagpopa/events{/privacy}", "received_events_url": "https://api.github.com/users/irinagpopa/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "38e964077b5a163fc7e4c825d23f4c7cf0625d4c", "url": "https://api.github.com/repos/rust-lang/rust/commits/38e964077b5a163fc7e4c825d23f4c7cf0625d4c", "html_url": "https://github.com/rust-lang/rust/commit/38e964077b5a163fc7e4c825d23f4c7cf0625d4c"}], "stats": {"total": 1570, "additions": 808, "deletions": 762}, "files": [{"sha": "a5df068dee2533d770d8fae694cb8d0ba8594752", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -1204,7 +1204,9 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                                   f: F) -> R\n                                   where F: for<'b> FnOnce(TyCtxt<'b, 'tcx, 'tcx>) -> R\n     {\n-        let data_layout = TargetDataLayout::parse(s);\n+        let data_layout = TargetDataLayout::parse(&s.target.target).unwrap_or_else(|err| { \n+            s.fatal(&err);\n+        });\n         let interners = CtxtInterners::new(&arenas.interner);\n         let common_types = CommonTypes::new(&interners);\n         let dep_graph = hir.dep_graph.clone();"}, {"sha": "c7fbd31b2598c1ca5ff3d70983dfa2c7cf4f2138", "filename": "src/librustc/ty/layout.rs", "status": "modified", "additions": 35, "deletions": 757, "changes": 792, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc%2Fty%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc%2Fty%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Flayout.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -8,10 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-pub use self::Integer::*;\n-pub use self::Primitive::*;\n-\n-use session::{self, DataTypeKind, Session};\n+use session::{self, DataTypeKind};\n use ty::{self, Ty, TyCtxt, TypeFoldable, ReprOptions};\n \n use syntax::ast::{self, FloatTy, IntTy, UintTy};\n@@ -21,432 +18,28 @@ use syntax_pos::DUMMY_SP;\n use std::cmp;\n use std::fmt;\n use std::i128;\n-use std::iter;\n use std::mem;\n-use std::ops::{Add, Sub, Mul, AddAssign, Deref, RangeInclusive};\n+use std::ops::{Deref, RangeInclusive};\n \n use ich::StableHashingContext;\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher,\n                                            StableHasherResult};\n \n-/// Parsed [Data layout](http://llvm.org/docs/LangRef.html#data-layout)\n-/// for a target, which contains everything needed to compute layouts.\n-pub struct TargetDataLayout {\n-    pub endian: Endian,\n-    pub i1_align: Align,\n-    pub i8_align: Align,\n-    pub i16_align: Align,\n-    pub i32_align: Align,\n-    pub i64_align: Align,\n-    pub i128_align: Align,\n-    pub f32_align: Align,\n-    pub f64_align: Align,\n-    pub pointer_size: Size,\n-    pub pointer_align: Align,\n-    pub aggregate_align: Align,\n-\n-    /// Alignments for vector types.\n-    pub vector_align: Vec<(Size, Align)>\n-}\n-\n-impl Default for TargetDataLayout {\n-    /// Creates an instance of `TargetDataLayout`.\n-    fn default() -> TargetDataLayout {\n-        TargetDataLayout {\n-            endian: Endian::Big,\n-            i1_align: Align::from_bits(8, 8).unwrap(),\n-            i8_align: Align::from_bits(8, 8).unwrap(),\n-            i16_align: Align::from_bits(16, 16).unwrap(),\n-            i32_align: Align::from_bits(32, 32).unwrap(),\n-            i64_align: Align::from_bits(32, 64).unwrap(),\n-            i128_align: Align::from_bits(32, 64).unwrap(),\n-            f32_align: Align::from_bits(32, 32).unwrap(),\n-            f64_align: Align::from_bits(64, 64).unwrap(),\n-            pointer_size: Size::from_bits(64),\n-            pointer_align: Align::from_bits(64, 64).unwrap(),\n-            aggregate_align: Align::from_bits(0, 64).unwrap(),\n-            vector_align: vec![\n-                (Size::from_bits(64), Align::from_bits(64, 64).unwrap()),\n-                (Size::from_bits(128), Align::from_bits(128, 128).unwrap())\n-            ]\n-        }\n-    }\n-}\n-\n-impl TargetDataLayout {\n-    pub fn parse(sess: &Session) -> TargetDataLayout {\n-        // Parse a bit count from a string.\n-        let parse_bits = |s: &str, kind: &str, cause: &str| {\n-            s.parse::<u64>().unwrap_or_else(|err| {\n-                sess.err(&format!(\"invalid {} `{}` for `{}` in \\\"data-layout\\\": {}\",\n-                                  kind, s, cause, err));\n-                0\n-            })\n-        };\n-\n-        // Parse a size string.\n-        let size = |s: &str, cause: &str| {\n-            Size::from_bits(parse_bits(s, \"size\", cause))\n-        };\n-\n-        // Parse an alignment string.\n-        let align = |s: &[&str], cause: &str| {\n-            if s.is_empty() {\n-                sess.err(&format!(\"missing alignment for `{}` in \\\"data-layout\\\"\", cause));\n-            }\n-            let abi = parse_bits(s[0], \"alignment\", cause);\n-            let pref = s.get(1).map_or(abi, |pref| parse_bits(pref, \"alignment\", cause));\n-            Align::from_bits(abi, pref).unwrap_or_else(|err| {\n-                sess.err(&format!(\"invalid alignment for `{}` in \\\"data-layout\\\": {}\",\n-                                  cause, err));\n-                Align::from_bits(8, 8).unwrap()\n-            })\n-        };\n-\n-        let mut dl = TargetDataLayout::default();\n-        let mut i128_align_src = 64;\n-        for spec in sess.target.target.data_layout.split(\"-\") {\n-            match &spec.split(\":\").collect::<Vec<_>>()[..] {\n-                &[\"e\"] => dl.endian = Endian::Little,\n-                &[\"E\"] => dl.endian = Endian::Big,\n-                &[\"a\", ref a..] => dl.aggregate_align = align(a, \"a\"),\n-                &[\"f32\", ref a..] => dl.f32_align = align(a, \"f32\"),\n-                &[\"f64\", ref a..] => dl.f64_align = align(a, \"f64\"),\n-                &[p @ \"p\", s, ref a..] | &[p @ \"p0\", s, ref a..] => {\n-                    dl.pointer_size = size(s, p);\n-                    dl.pointer_align = align(a, p);\n-                }\n-                &[s, ref a..] if s.starts_with(\"i\") => {\n-                    let bits = match s[1..].parse::<u64>() {\n-                        Ok(bits) => bits,\n-                        Err(_) => {\n-                            size(&s[1..], \"i\"); // For the user error.\n-                            continue;\n-                        }\n-                    };\n-                    let a = align(a, s);\n-                    match bits {\n-                        1 => dl.i1_align = a,\n-                        8 => dl.i8_align = a,\n-                        16 => dl.i16_align = a,\n-                        32 => dl.i32_align = a,\n-                        64 => dl.i64_align = a,\n-                        _ => {}\n-                    }\n-                    if bits >= i128_align_src && bits <= 128 {\n-                        // Default alignment for i128 is decided by taking the alignment of\n-                        // largest-sized i{64...128}.\n-                        i128_align_src = bits;\n-                        dl.i128_align = a;\n-                    }\n-                }\n-                &[s, ref a..] if s.starts_with(\"v\") => {\n-                    let v_size = size(&s[1..], \"v\");\n-                    let a = align(a, s);\n-                    if let Some(v) = dl.vector_align.iter_mut().find(|v| v.0 == v_size) {\n-                        v.1 = a;\n-                        continue;\n-                    }\n-                    // No existing entry, add a new one.\n-                    dl.vector_align.push((v_size, a));\n-                }\n-                _ => {} // Ignore everything else.\n-            }\n-        }\n-\n-        // Perform consistency checks against the Target information.\n-        let endian_str = match dl.endian {\n-            Endian::Little => \"little\",\n-            Endian::Big => \"big\"\n-        };\n-        if endian_str != sess.target.target.target_endian {\n-            sess.err(&format!(\"inconsistent target specification: \\\"data-layout\\\" claims \\\n-                               architecture is {}-endian, while \\\"target-endian\\\" is `{}`\",\n-                              endian_str, sess.target.target.target_endian));\n-        }\n-\n-        if dl.pointer_size.bits().to_string() != sess.target.target.target_pointer_width {\n-            sess.err(&format!(\"inconsistent target specification: \\\"data-layout\\\" claims \\\n-                               pointers are {}-bit, while \\\"target-pointer-width\\\" is `{}`\",\n-                              dl.pointer_size.bits(), sess.target.target.target_pointer_width));\n-        }\n-\n-        dl\n-    }\n-\n-    /// Return exclusive upper bound on object size.\n-    ///\n-    /// The theoretical maximum object size is defined as the maximum positive `isize` value.\n-    /// This ensures that the `offset` semantics remain well-defined by allowing it to correctly\n-    /// index every address within an object along with one byte past the end, along with allowing\n-    /// `isize` to store the difference between any two pointers into an object.\n-    ///\n-    /// The upper bound on 64-bit currently needs to be lower because LLVM uses a 64-bit integer\n-    /// to represent object size in bits. It would need to be 1 << 61 to account for this, but is\n-    /// currently conservatively bounded to 1 << 47 as that is enough to cover the current usable\n-    /// address space on 64-bit ARMv8 and x86_64.\n-    pub fn obj_size_bound(&self) -> u64 {\n-        match self.pointer_size.bits() {\n-            16 => 1 << 15,\n-            32 => 1 << 31,\n-            64 => 1 << 47,\n-            bits => bug!(\"obj_size_bound: unknown pointer bit size {}\", bits)\n-        }\n-    }\n-\n-    pub fn ptr_sized_integer(&self) -> Integer {\n-        match self.pointer_size.bits() {\n-            16 => I16,\n-            32 => I32,\n-            64 => I64,\n-            bits => bug!(\"ptr_sized_integer: unknown pointer bit size {}\", bits)\n-        }\n-    }\n-\n-    pub fn vector_align(&self, vec_size: Size) -> Align {\n-        for &(size, align) in &self.vector_align {\n-            if size == vec_size {\n-                return align;\n-            }\n-        }\n-        // Default to natural alignment, which is what LLVM does.\n-        // That is, use the size, rounded up to a power of 2.\n-        let align = vec_size.bytes().next_power_of_two();\n-        Align::from_bytes(align, align).unwrap()\n-    }\n-}\n-\n-pub trait HasDataLayout: Copy {\n-    fn data_layout(&self) -> &TargetDataLayout;\n-}\n-\n-impl<'a> HasDataLayout for &'a TargetDataLayout {\n-    fn data_layout(&self) -> &TargetDataLayout {\n-        self\n-    }\n-}\n-\n-/// Endianness of the target, which must match cfg(target-endian).\n-#[derive(Copy, Clone)]\n-pub enum Endian {\n-    Little,\n-    Big\n-}\n-\n-/// Size of a type in bytes.\n-#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n-pub struct Size {\n-    raw: u64\n-}\n-\n-impl Size {\n-    pub fn from_bits(bits: u64) -> Size {\n-        // Avoid potential overflow from `bits + 7`.\n-        Size::from_bytes(bits / 8 + ((bits % 8) + 7) / 8)\n-    }\n-\n-    pub fn from_bytes(bytes: u64) -> Size {\n-        if bytes >= (1 << 61) {\n-            bug!(\"Size::from_bytes: {} bytes in bits doesn't fit in u64\", bytes)\n-        }\n-        Size {\n-            raw: bytes\n-        }\n-    }\n-\n-    pub fn bytes(self) -> u64 {\n-        self.raw\n-    }\n-\n-    pub fn bits(self) -> u64 {\n-        self.bytes() * 8\n-    }\n-\n-    pub fn abi_align(self, align: Align) -> Size {\n-        let mask = align.abi() - 1;\n-        Size::from_bytes((self.bytes() + mask) & !mask)\n-    }\n-\n-    pub fn is_abi_aligned(self, align: Align) -> bool {\n-        let mask = align.abi() - 1;\n-        self.bytes() & mask == 0\n-    }\n-\n-    pub fn checked_add<C: HasDataLayout>(self, offset: Size, cx: C) -> Option<Size> {\n-        let dl = cx.data_layout();\n-\n-        // Each Size is less than dl.obj_size_bound(), so the sum is\n-        // also less than 1 << 62 (and therefore can't overflow).\n-        let bytes = self.bytes() + offset.bytes();\n-\n-        if bytes < dl.obj_size_bound() {\n-            Some(Size::from_bytes(bytes))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    pub fn checked_mul<C: HasDataLayout>(self, count: u64, cx: C) -> Option<Size> {\n-        let dl = cx.data_layout();\n-\n-        match self.bytes().checked_mul(count) {\n-            Some(bytes) if bytes < dl.obj_size_bound() => {\n-                Some(Size::from_bytes(bytes))\n-            }\n-            _ => None\n-        }\n-    }\n-}\n-\n-// Panicking addition, subtraction and multiplication for convenience.\n-// Avoid during layout computation, return `LayoutError` instead.\n-\n-impl Add for Size {\n-    type Output = Size;\n-    fn add(self, other: Size) -> Size {\n-        // Each Size is less than 1 << 61, so the sum is\n-        // less than 1 << 62 (and therefore can't overflow).\n-        Size::from_bytes(self.bytes() + other.bytes())\n-    }\n-}\n-\n-impl Sub for Size {\n-    type Output = Size;\n-    fn sub(self, other: Size) -> Size {\n-        // Each Size is less than 1 << 61, so an underflow\n-        // would result in a value larger than 1 << 61,\n-        // which Size::from_bytes will catch for us.\n-        Size::from_bytes(self.bytes() - other.bytes())\n-    }\n-}\n-\n-impl Mul<u64> for Size {\n-    type Output = Size;\n-    fn mul(self, count: u64) -> Size {\n-        match self.bytes().checked_mul(count) {\n-            Some(bytes) => Size::from_bytes(bytes),\n-            None => {\n-                bug!(\"Size::mul: {} * {} doesn't fit in u64\", self.bytes(), count)\n-            }\n-        }\n-    }\n-}\n-\n-impl AddAssign for Size {\n-    fn add_assign(&mut self, other: Size) {\n-        *self = *self + other;\n-    }\n-}\n-\n-/// Alignment of a type in bytes, both ABI-mandated and preferred.\n-/// Each field is a power of two, giving the alignment a maximum\n-/// value of 2<sup>(2<sup>8</sup> - 1)</sup>, which is limited by LLVM to a i32, with\n-/// a maximum capacity of 2<sup>31</sup> - 1 or 2147483647.\n-#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug, RustcEncodable, RustcDecodable)]\n-pub struct Align {\n-    abi_pow2: u8,\n-    pref_pow2: u8,\n-}\n-\n-impl Align {\n-    pub fn from_bits(abi: u64, pref: u64) -> Result<Align, String> {\n-        Align::from_bytes(Size::from_bits(abi).bytes(),\n-                          Size::from_bits(pref).bytes())\n-    }\n-\n-    pub fn from_bytes(abi: u64, pref: u64) -> Result<Align, String> {\n-        let log2 = |align: u64| {\n-            // Treat an alignment of 0 bytes like 1-byte alignment.\n-            if align == 0 {\n-                return Ok(0);\n-            }\n-\n-            let mut bytes = align;\n-            let mut pow: u8 = 0;\n-            while (bytes & 1) == 0 {\n-                pow += 1;\n-                bytes >>= 1;\n-            }\n-            if bytes != 1 {\n-                Err(format!(\"`{}` is not a power of 2\", align))\n-            } else if pow > 30 {\n-                Err(format!(\"`{}` is too large\", align))\n-            } else {\n-                Ok(pow)\n-            }\n-        };\n-\n-        Ok(Align {\n-            abi_pow2: log2(abi)?,\n-            pref_pow2: log2(pref)?,\n-        })\n-    }\n-\n-    pub fn abi(self) -> u64 {\n-        1 << self.abi_pow2\n-    }\n-\n-    pub fn pref(self) -> u64 {\n-        1 << self.pref_pow2\n-    }\n-\n-    pub fn abi_bits(self) -> u64 {\n-        self.abi() * 8\n-    }\n-\n-    pub fn pref_bits(self) -> u64 {\n-        self.pref() * 8\n-    }\n-\n-    pub fn min(self, other: Align) -> Align {\n-        Align {\n-            abi_pow2: cmp::min(self.abi_pow2, other.abi_pow2),\n-            pref_pow2: cmp::min(self.pref_pow2, other.pref_pow2),\n-        }\n-    }\n-\n-    pub fn max(self, other: Align) -> Align {\n-        Align {\n-            abi_pow2: cmp::max(self.abi_pow2, other.abi_pow2),\n-            pref_pow2: cmp::max(self.pref_pow2, other.pref_pow2),\n-        }\n-    }\n-}\n+pub use rustc_target::abi::*;\n \n-/// Integers, also used for enum discriminants.\n-#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n-pub enum Integer {\n-    I8,\n-    I16,\n-    I32,\n-    I64,\n-    I128,\n+pub trait IntegerExt {\n+    fn to_ty<'a, 'tcx>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>, signed: bool) -> Ty<'tcx>;\n+    fn from_attr<C: HasDataLayout>(cx: C, ity: attr::IntType) -> Integer;\n+    fn repr_discr<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                  ty: Ty<'tcx>,\n+                  repr: &ReprOptions,\n+                  min: i128,\n+                  max: i128)\n+                  -> (Integer, bool);\n }\n \n-impl<'a, 'tcx> Integer {\n-    pub fn size(&self) -> Size {\n-        match *self {\n-            I8 => Size::from_bytes(1),\n-            I16 => Size::from_bytes(2),\n-            I32 => Size::from_bytes(4),\n-            I64  => Size::from_bytes(8),\n-            I128  => Size::from_bytes(16),\n-        }\n-    }\n-\n-    pub fn align<C: HasDataLayout>(&self, cx: C) -> Align {\n-        let dl = cx.data_layout();\n-\n-        match *self {\n-            I8 => dl.i8_align,\n-            I16 => dl.i16_align,\n-            I32 => dl.i32_align,\n-            I64 => dl.i64_align,\n-            I128 => dl.i128_align,\n-        }\n-    }\n-\n-    pub fn to_ty(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>, signed: bool) -> Ty<'tcx> {\n+impl IntegerExt for Integer {\n+    fn to_ty<'a, 'tcx>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>, signed: bool) -> Ty<'tcx> {\n         match (*self, signed) {\n             (I8, false) => tcx.types.u8,\n             (I16, false) => tcx.types.u16,\n@@ -461,57 +54,8 @@ impl<'a, 'tcx> Integer {\n         }\n     }\n \n-    /// Find the smallest Integer type which can represent the signed value.\n-    pub fn fit_signed(x: i128) -> Integer {\n-        match x {\n-            -0x0000_0000_0000_0080...0x0000_0000_0000_007f => I8,\n-            -0x0000_0000_0000_8000...0x0000_0000_0000_7fff => I16,\n-            -0x0000_0000_8000_0000...0x0000_0000_7fff_ffff => I32,\n-            -0x8000_0000_0000_0000...0x7fff_ffff_ffff_ffff => I64,\n-            _ => I128\n-        }\n-    }\n-\n-    /// Find the smallest Integer type which can represent the unsigned value.\n-    pub fn fit_unsigned(x: u128) -> Integer {\n-        match x {\n-            0...0x0000_0000_0000_00ff => I8,\n-            0...0x0000_0000_0000_ffff => I16,\n-            0...0x0000_0000_ffff_ffff => I32,\n-            0...0xffff_ffff_ffff_ffff => I64,\n-            _ => I128,\n-        }\n-    }\n-\n-    /// Find the smallest integer with the given alignment.\n-    pub fn for_abi_align<C: HasDataLayout>(cx: C, align: Align) -> Option<Integer> {\n-        let dl = cx.data_layout();\n-\n-        let wanted = align.abi();\n-        for &candidate in &[I8, I16, I32, I64, I128] {\n-            if wanted == candidate.align(dl).abi() && wanted == candidate.size().bytes() {\n-                return Some(candidate);\n-            }\n-        }\n-        None\n-    }\n-\n-    /// Find the largest integer with the given alignment or less.\n-    pub fn approximate_abi_align<C: HasDataLayout>(cx: C, align: Align) -> Integer {\n-        let dl = cx.data_layout();\n-\n-        let wanted = align.abi();\n-        // FIXME(eddyb) maybe include I128 in the future, when it works everywhere.\n-        for &candidate in &[I64, I32, I16] {\n-            if wanted >= candidate.align(dl).abi() && wanted >= candidate.size().bytes() {\n-                return candidate;\n-            }\n-        }\n-        I8\n-    }\n-\n     /// Get the Integer type from an attr::IntType.\n-    pub fn from_attr<C: HasDataLayout>(cx: C, ity: attr::IntType) -> Integer {\n+    fn from_attr<C: HasDataLayout>(cx: C, ity: attr::IntType) -> Integer {\n         let dl = cx.data_layout();\n \n         match ity {\n@@ -530,7 +74,7 @@ impl<'a, 'tcx> Integer {\n     /// signed discriminant range and #[repr] attribute.\n     /// N.B.: u128 values above i128::MAX will be treated as signed, but\n     /// that shouldn't affect anything, other than maybe debuginfo.\n-    fn repr_discr(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+    fn repr_discr<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                   ty: Ty<'tcx>,\n                   repr: &ReprOptions,\n                   min: i128,\n@@ -578,46 +122,12 @@ impl<'a, 'tcx> Integer {\n     }\n }\n \n-/// Fundamental unit of memory access and layout.\n-#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n-pub enum Primitive {\n-    /// The `bool` is the signedness of the `Integer` type.\n-    ///\n-    /// One would think we would not care about such details this low down,\n-    /// but some ABIs are described in terms of C types and ISAs where the\n-    /// integer arithmetic is done on {sign,zero}-extended registers, e.g.\n-    /// a negative integer passed by zero-extension will appear positive in\n-    /// the callee, and most operations on it will produce the wrong values.\n-    Int(Integer, bool),\n-    F32,\n-    F64,\n-    Pointer\n+pub trait PrimitiveExt {\n+    fn to_ty<'a, 'tcx>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Ty<'tcx>;\n }\n \n-impl<'a, 'tcx> Primitive {\n-    pub fn size<C: HasDataLayout>(self, cx: C) -> Size {\n-        let dl = cx.data_layout();\n-\n-        match self {\n-            Int(i, _) => i.size(),\n-            F32 => Size::from_bits(32),\n-            F64 => Size::from_bits(64),\n-            Pointer => dl.pointer_size\n-        }\n-    }\n-\n-    pub fn align<C: HasDataLayout>(self, cx: C) -> Align {\n-        let dl = cx.data_layout();\n-\n-        match self {\n-            Int(i, _) => i.align(dl),\n-            F32 => dl.f32_align,\n-            F64 => dl.f64_align,\n-            Pointer => dl.pointer_align\n-        }\n-    }\n-\n-    pub fn to_ty(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Ty<'tcx> {\n+impl PrimitiveExt for Primitive {\n+    fn to_ty<'a, 'tcx>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Ty<'tcx> {\n         match *self {\n             Int(i, signed) => i.to_ty(tcx, signed),\n             F32 => tcx.types.f32,\n@@ -627,29 +137,6 @@ impl<'a, 'tcx> Primitive {\n     }\n }\n \n-/// Information about one scalar component of a Rust type.\n-#[derive(Clone, PartialEq, Eq, Hash, Debug)]\n-pub struct Scalar {\n-    pub value: Primitive,\n-\n-    /// Inclusive wrap-around range of valid values, that is, if\n-    /// min > max, it represents min..=u128::MAX followed by 0..=max.\n-    // FIXME(eddyb) always use the shortest range, e.g. by finding\n-    // the largest space between two consecutive valid values and\n-    // taking everything else as the (shortest) valid range.\n-    pub valid_range: RangeInclusive<u128>,\n-}\n-\n-impl Scalar {\n-    pub fn is_bool(&self) -> bool {\n-        if let Int(I8, _) = self.value {\n-            self.valid_range == (0..=1)\n-        } else {\n-            false\n-        }\n-    }\n-}\n-\n /// The first half of a fat pointer.\n ///\n /// - For a trait object, this is the address of the box.\n@@ -662,183 +149,6 @@ pub const FAT_PTR_ADDR: usize = 0;\n /// - For a slice, this is the length.\n pub const FAT_PTR_EXTRA: usize = 1;\n \n-/// Describes how the fields of a type are located in memory.\n-#[derive(PartialEq, Eq, Hash, Debug)]\n-pub enum FieldPlacement {\n-    /// All fields start at no offset. The `usize` is the field count.\n-    Union(usize),\n-\n-    /// Array/vector-like placement, with all fields of identical types.\n-    Array {\n-        stride: Size,\n-        count: u64\n-    },\n-\n-    /// Struct-like placement, with precomputed offsets.\n-    ///\n-    /// Fields are guaranteed to not overlap, but note that gaps\n-    /// before, between and after all the fields are NOT always\n-    /// padding, and as such their contents may not be discarded.\n-    /// For example, enum variants leave a gap at the start,\n-    /// where the discriminant field in the enum layout goes.\n-    Arbitrary {\n-        /// Offsets for the first byte of each field,\n-        /// ordered to match the source definition order.\n-        /// This vector does not go in increasing order.\n-        // FIXME(eddyb) use small vector optimization for the common case.\n-        offsets: Vec<Size>,\n-\n-        /// Maps source order field indices to memory order indices,\n-        /// depending how fields were permuted.\n-        // FIXME(camlorn) also consider small vector  optimization here.\n-        memory_index: Vec<u32>\n-    }\n-}\n-\n-impl FieldPlacement {\n-    pub fn count(&self) -> usize {\n-        match *self {\n-            FieldPlacement::Union(count) => count,\n-            FieldPlacement::Array { count, .. } => {\n-                let usize_count = count as usize;\n-                assert_eq!(usize_count as u64, count);\n-                usize_count\n-            }\n-            FieldPlacement::Arbitrary { ref offsets, .. } => offsets.len()\n-        }\n-    }\n-\n-    pub fn offset(&self, i: usize) -> Size {\n-        match *self {\n-            FieldPlacement::Union(_) => Size::from_bytes(0),\n-            FieldPlacement::Array { stride, count } => {\n-                let i = i as u64;\n-                assert!(i < count);\n-                stride * i\n-            }\n-            FieldPlacement::Arbitrary { ref offsets, .. } => offsets[i]\n-        }\n-    }\n-\n-    pub fn memory_index(&self, i: usize) -> usize {\n-        match *self {\n-            FieldPlacement::Union(_) |\n-            FieldPlacement::Array { .. } => i,\n-            FieldPlacement::Arbitrary { ref memory_index, .. } => {\n-                let r = memory_index[i];\n-                assert_eq!(r as usize as u32, r);\n-                r as usize\n-            }\n-        }\n-    }\n-\n-    /// Get source indices of the fields by increasing offsets.\n-    #[inline]\n-    pub fn index_by_increasing_offset<'a>(&'a self) -> impl iter::Iterator<Item=usize>+'a {\n-        let mut inverse_small = [0u8; 64];\n-        let mut inverse_big = vec![];\n-        let use_small = self.count() <= inverse_small.len();\n-\n-        // We have to write this logic twice in order to keep the array small.\n-        if let FieldPlacement::Arbitrary { ref memory_index, .. } = *self {\n-            if use_small {\n-                for i in 0..self.count() {\n-                    inverse_small[memory_index[i] as usize] = i as u8;\n-                }\n-            } else {\n-                inverse_big = vec![0; self.count()];\n-                for i in 0..self.count() {\n-                    inverse_big[memory_index[i] as usize] = i as u32;\n-                }\n-            }\n-        }\n-\n-        (0..self.count()).map(move |i| {\n-            match *self {\n-                FieldPlacement::Union(_) |\n-                FieldPlacement::Array { .. } => i,\n-                FieldPlacement::Arbitrary { .. } => {\n-                    if use_small { inverse_small[i] as usize }\n-                    else { inverse_big[i] as usize }\n-                }\n-            }\n-        })\n-    }\n-}\n-\n-/// Describes how values of the type are passed by target ABIs,\n-/// in terms of categories of C types there are ABI rules for.\n-#[derive(Clone, PartialEq, Eq, Hash, Debug)]\n-pub enum Abi {\n-    Uninhabited,\n-    Scalar(Scalar),\n-    ScalarPair(Scalar, Scalar),\n-    Vector {\n-        element: Scalar,\n-        count: u64\n-    },\n-    Aggregate {\n-        /// If true, the size is exact, otherwise it's only a lower bound.\n-        sized: bool,\n-    }\n-}\n-\n-impl Abi {\n-    /// Returns true if the layout corresponds to an unsized type.\n-    pub fn is_unsized(&self) -> bool {\n-        match *self {\n-            Abi::Uninhabited |\n-            Abi::Scalar(_) |\n-            Abi::ScalarPair(..) |\n-            Abi::Vector { .. } => false,\n-            Abi::Aggregate { sized } => !sized\n-        }\n-    }\n-\n-    /// Returns true if this is a single signed integer scalar\n-    pub fn is_signed(&self) -> bool {\n-        match *self {\n-            Abi::Scalar(ref scal) => match scal.value {\n-                Primitive::Int(_, signed) => signed,\n-                _ => false,\n-            },\n-            _ => false,\n-        }\n-    }\n-}\n-\n-#[derive(PartialEq, Eq, Hash, Debug)]\n-pub enum Variants {\n-    /// Single enum variants, structs/tuples, unions, and all non-ADTs.\n-    Single {\n-        index: usize\n-    },\n-\n-    /// General-case enums: for each case there is a struct, and they all have\n-    /// all space reserved for the discriminant, and their first field starts\n-    /// at a non-0 offset, after where the discriminant would go.\n-    Tagged {\n-        discr: Scalar,\n-        variants: Vec<LayoutDetails>,\n-    },\n-\n-    /// Multiple cases distinguished by a niche (values invalid for a type):\n-    /// the variant `dataful_variant` contains a niche at an arbitrary\n-    /// offset (field 0 of the enum), which for a variant with discriminant\n-    /// `d` is set to `(d - niche_variants.start).wrapping_add(niche_start)`.\n-    ///\n-    /// For example, `Option<(usize, &T)>`  is represented such that\n-    /// `None` has a null pointer for the second tuple field, and\n-    /// `Some` is the identity function (with a non-null reference).\n-    NicheFilling {\n-        dataful_variant: usize,\n-        niche_variants: RangeInclusive<usize>,\n-        niche: Scalar,\n-        niche_start: u128,\n-        variants: Vec<LayoutDetails>,\n-    }\n-}\n-\n #[derive(Copy, Clone, Debug)]\n pub enum LayoutError<'tcx> {\n     Unknown(Ty<'tcx>),\n@@ -858,40 +168,6 @@ impl<'tcx> fmt::Display for LayoutError<'tcx> {\n     }\n }\n \n-#[derive(PartialEq, Eq, Hash, Debug)]\n-pub struct LayoutDetails {\n-    pub variants: Variants,\n-    pub fields: FieldPlacement,\n-    pub abi: Abi,\n-    pub align: Align,\n-    pub size: Size\n-}\n-\n-impl LayoutDetails {\n-    fn scalar<C: HasDataLayout>(cx: C, scalar: Scalar) -> Self {\n-        let size = scalar.value.size(cx);\n-        let align = scalar.value.align(cx);\n-        LayoutDetails {\n-            variants: Variants::Single { index: 0 },\n-            fields: FieldPlacement::Union(0),\n-            abi: Abi::Scalar(scalar),\n-            size,\n-            align,\n-        }\n-    }\n-\n-    fn uninhabited(field_count: usize) -> Self {\n-        let align = Align::from_bytes(1, 1).unwrap();\n-        LayoutDetails {\n-            variants: Variants::Single { index: 0 },\n-            fields: FieldPlacement::Union(field_count),\n-            abi: Abi::Uninhabited,\n-            align,\n-            size: Size::from_bytes(0)\n-        }\n-    }\n-}\n-\n fn layout_raw<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                         query: ty::ParamEnvAnd<'tcx, Ty<'tcx>>)\n                         -> Result<&'tcx LayoutDetails, LayoutError<'tcx>>\n@@ -2095,12 +1371,6 @@ impl<T, E> MaybeResult<T> for Result<T, E> {\n     }\n }\n \n-pub trait LayoutOf<T> {\n-    type TyLayout;\n-\n-    fn layout_of(self, ty: T) -> Self::TyLayout;\n-}\n-\n impl<'a, 'tcx> LayoutOf<Ty<'tcx>> for LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n     type TyLayout = Result<TyLayout<'tcx>, LayoutError<'tcx>>;\n \n@@ -2549,14 +1819,22 @@ impl_stable_hash_for!(enum ::ty::layout::Primitive {\n     Pointer\n });\n \n-impl_stable_hash_for!(struct ::ty::layout::Align {\n-    abi_pow2,\n-    pref_pow2\n-});\n+impl<'gcx> HashStable<StableHashingContext<'gcx>> for Align {\n+    fn hash_stable<W: StableHasherResult>(&self,\n+                                          hcx: &mut StableHashingContext<'gcx>,\n+                                          hasher: &mut StableHasher<W>) {\n+        self.abi().hash_stable(hcx, hasher);\n+        self.pref().hash_stable(hcx, hasher);\n+    }\n+}\n \n-impl_stable_hash_for!(struct ::ty::layout::Size {\n-    raw\n-});\n+impl<'gcx> HashStable<StableHashingContext<'gcx>> for Size {\n+    fn hash_stable<W: StableHasherResult>(&self,\n+                                          hcx: &mut StableHashingContext<'gcx>,\n+                                          hasher: &mut StableHasher<W>) {\n+        self.bytes().hash_stable(hcx, hasher);\n+    }\n+}\n \n impl<'a, 'gcx> HashStable<StableHashingContext<'a>> for LayoutError<'gcx>\n {"}, {"sha": "a10ca13247216a76fa2600ce1b74f136432f5f3c", "filename": "src/librustc/ty/util.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc%2Fty%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc%2Fty%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Futil.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -22,7 +22,7 @@ use ty::fold::TypeVisitor;\n use ty::subst::UnpackedKind;\n use ty::maps::TyCtxtAt;\n use ty::TypeVariants::*;\n-use ty::layout::Integer;\n+use ty::layout::{Integer, IntegerExt};\n use util::common::ErrorReported;\n use middle::lang_items;\n use mir::interpret::{Value, PrimVal};"}, {"sha": "4d2bddd531ece2fe19a86a9f2c6c1d05ec4cb3d9", "filename": "src/librustc_lint/types.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_lint%2Ftypes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_lint%2Ftypes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lint%2Ftypes.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -13,7 +13,7 @@\n use rustc::hir::map as hir_map;\n use rustc::ty::subst::Substs;\n use rustc::ty::{self, AdtKind, ParamEnv, Ty, TyCtxt};\n-use rustc::ty::layout::{self, LayoutOf};\n+use rustc::ty::layout::{self, IntegerExt, LayoutOf};\n use util::nodemap::FxHashSet;\n use lint::{LateContext, LintContext, LintArray};\n use lint::{LintPass, LateLintPass};"}, {"sha": "e6aa2d3abb7e025de7d3f76b01a8a3ef6f1e563c", "filename": "src/librustc_mir/hair/cx/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_mir%2Fhair%2Fcx%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_mir%2Fhair%2Fcx%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fhair%2Fcx%2Fmod.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -22,6 +22,7 @@ use rustc::hir::def_id::{DefId, LOCAL_CRATE};\n use rustc::hir::map::blocks::FnLikeNode;\n use rustc::middle::region;\n use rustc::infer::InferCtxt;\n+use rustc::ty::layout::IntegerExt;\n use rustc::ty::subst::Subst;\n use rustc::ty::{self, Ty, TyCtxt, layout};\n use rustc::ty::subst::Substs;"}, {"sha": "14ee795b3b13f0531ccc83dbf8cd275dd0e15292", "filename": "src/librustc_mir/interpret/eval_context.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -5,7 +5,7 @@ use rustc::hir::def::Def;\n use rustc::hir::map::definitions::DefPathData;\n use rustc::middle::const_val::{ConstVal, ErrKind};\n use rustc::mir;\n-use rustc::ty::layout::{self, Size, Align, HasDataLayout, LayoutOf, TyLayout};\n+use rustc::ty::layout::{self, Size, Align, HasDataLayout, IntegerExt, LayoutOf, TyLayout};\n use rustc::ty::subst::{Subst, Substs};\n use rustc::ty::{self, Ty, TyCtxt};\n use rustc::ty::maps::TyCtxtAt;"}, {"sha": "e2f9737d8789b23338aaf76ae255278ca06f4bc6", "filename": "src/librustc_target/abi/mod.rs", "status": "added", "additions": 762, "deletions": 0, "changes": 762, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_target%2Fabi%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_target%2Fabi%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_target%2Fabi%2Fmod.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -0,0 +1,762 @@\n+// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+pub use self::Integer::*;\n+pub use self::Primitive::*;\n+\n+use spec::Target;\n+\n+use std::cmp;\n+use std::ops::{Add, Sub, Mul, AddAssign, RangeInclusive};\n+\n+/// Parsed [Data layout](http://llvm.org/docs/LangRef.html#data-layout)\n+/// for a target, which contains everything needed to compute layouts.\n+pub struct TargetDataLayout {\n+    pub endian: Endian,\n+    pub i1_align: Align,\n+    pub i8_align: Align,\n+    pub i16_align: Align,\n+    pub i32_align: Align,\n+    pub i64_align: Align,\n+    pub i128_align: Align,\n+    pub f32_align: Align,\n+    pub f64_align: Align,\n+    pub pointer_size: Size,\n+    pub pointer_align: Align,\n+    pub aggregate_align: Align,\n+\n+    /// Alignments for vector types.\n+    pub vector_align: Vec<(Size, Align)>\n+}\n+\n+impl Default for TargetDataLayout {\n+    /// Creates an instance of `TargetDataLayout`.\n+    fn default() -> TargetDataLayout {\n+        TargetDataLayout {\n+            endian: Endian::Big,\n+            i1_align: Align::from_bits(8, 8).unwrap(),\n+            i8_align: Align::from_bits(8, 8).unwrap(),\n+            i16_align: Align::from_bits(16, 16).unwrap(),\n+            i32_align: Align::from_bits(32, 32).unwrap(),\n+            i64_align: Align::from_bits(32, 64).unwrap(),\n+            i128_align: Align::from_bits(32, 64).unwrap(),\n+            f32_align: Align::from_bits(32, 32).unwrap(),\n+            f64_align: Align::from_bits(64, 64).unwrap(),\n+            pointer_size: Size::from_bits(64),\n+            pointer_align: Align::from_bits(64, 64).unwrap(),\n+            aggregate_align: Align::from_bits(0, 64).unwrap(),\n+            vector_align: vec![\n+                (Size::from_bits(64), Align::from_bits(64, 64).unwrap()),\n+                (Size::from_bits(128), Align::from_bits(128, 128).unwrap())\n+            ]\n+        }\n+    }\n+}\n+\n+impl TargetDataLayout {\n+    pub fn parse(target: &Target) -> Result<TargetDataLayout, String> {\n+        // Parse a bit count from a string.\n+        let parse_bits = |s: &str, kind: &str, cause: &str| {\n+            s.parse::<u64>().map_err(|err| {\n+                format!(\"invalid {} `{}` for `{}` in \\\"data-layout\\\": {}\",\n+                        kind, s, cause, err)\n+            })\n+        };\n+\n+        // Parse a size string.\n+        let size = |s: &str, cause: &str| {\n+            parse_bits(s, \"size\", cause).map(Size::from_bits)\n+        };\n+\n+        // Parse an alignment string.\n+        let align = |s: &[&str], cause: &str| {\n+            if s.is_empty() {\n+                return Err(format!(\"missing alignment for `{}` in \\\"data-layout\\\"\", cause));\n+            }\n+            let abi = parse_bits(s[0], \"alignment\", cause)?;\n+            let pref = s.get(1).map_or(Ok(abi), |pref| parse_bits(pref, \"alignment\", cause))?;\n+            Align::from_bits(abi, pref).map_err(|err| {\n+                format!(\"invalid alignment for `{}` in \\\"data-layout\\\": {}\",\n+                        cause, err)\n+            })\n+        };\n+\n+        let mut dl = TargetDataLayout::default();\n+        let mut i128_align_src = 64;\n+        for spec in target.data_layout.split(\"-\") {\n+            match &spec.split(\":\").collect::<Vec<_>>()[..] {\n+                &[\"e\"] => dl.endian = Endian::Little,\n+                &[\"E\"] => dl.endian = Endian::Big,\n+                &[\"a\", ref a..] => dl.aggregate_align = align(a, \"a\")?,\n+                &[\"f32\", ref a..] => dl.f32_align = align(a, \"f32\")?,\n+                &[\"f64\", ref a..] => dl.f64_align = align(a, \"f64\")?,\n+                &[p @ \"p\", s, ref a..] | &[p @ \"p0\", s, ref a..] => {\n+                    dl.pointer_size = size(s, p)?;\n+                    dl.pointer_align = align(a, p)?;\n+                }\n+                &[s, ref a..] if s.starts_with(\"i\") => {\n+                    let bits = match s[1..].parse::<u64>() {\n+                        Ok(bits) => bits,\n+                        Err(_) => {\n+                            size(&s[1..], \"i\")?; // For the user error.\n+                            continue;\n+                        }\n+                    };\n+                    let a = align(a, s)?;\n+                    match bits {\n+                        1 => dl.i1_align = a,\n+                        8 => dl.i8_align = a,\n+                        16 => dl.i16_align = a,\n+                        32 => dl.i32_align = a,\n+                        64 => dl.i64_align = a,\n+                        _ => {}\n+                    }\n+                    if bits >= i128_align_src && bits <= 128 {\n+                        // Default alignment for i128 is decided by taking the alignment of\n+                        // largest-sized i{64...128}.\n+                        i128_align_src = bits;\n+                        dl.i128_align = a;\n+                    }\n+                }\n+                &[s, ref a..] if s.starts_with(\"v\") => {\n+                    let v_size = size(&s[1..], \"v\")?;\n+                    let a = align(a, s)?;\n+                    if let Some(v) = dl.vector_align.iter_mut().find(|v| v.0 == v_size) {\n+                        v.1 = a;\n+                        continue;\n+                    }\n+                    // No existing entry, add a new one.\n+                    dl.vector_align.push((v_size, a));\n+                }\n+                _ => {} // Ignore everything else.\n+            }\n+        }\n+\n+        // Perform consistency checks against the Target information.\n+        let endian_str = match dl.endian {\n+            Endian::Little => \"little\",\n+            Endian::Big => \"big\"\n+        };\n+        if endian_str != target.target_endian {\n+            return Err(format!(\"inconsistent target specification: \\\"data-layout\\\" claims \\\n+                                architecture is {}-endian, while \\\"target-endian\\\" is `{}`\",\n+                               endian_str, target.target_endian));\n+        }\n+\n+        if dl.pointer_size.bits().to_string() != target.target_pointer_width {\n+            return Err(format!(\"inconsistent target specification: \\\"data-layout\\\" claims \\\n+                                pointers are {}-bit, while \\\"target-pointer-width\\\" is `{}`\",\n+                               dl.pointer_size.bits(), target.target_pointer_width));\n+        }\n+\n+        Ok(dl)\n+    }\n+\n+    /// Return exclusive upper bound on object size.\n+    ///\n+    /// The theoretical maximum object size is defined as the maximum positive `isize` value.\n+    /// This ensures that the `offset` semantics remain well-defined by allowing it to correctly\n+    /// index every address within an object along with one byte past the end, along with allowing\n+    /// `isize` to store the difference between any two pointers into an object.\n+    ///\n+    /// The upper bound on 64-bit currently needs to be lower because LLVM uses a 64-bit integer\n+    /// to represent object size in bits. It would need to be 1 << 61 to account for this, but is\n+    /// currently conservatively bounded to 1 << 47 as that is enough to cover the current usable\n+    /// address space on 64-bit ARMv8 and x86_64.\n+    pub fn obj_size_bound(&self) -> u64 {\n+        match self.pointer_size.bits() {\n+            16 => 1 << 15,\n+            32 => 1 << 31,\n+            64 => 1 << 47,\n+            bits => panic!(\"obj_size_bound: unknown pointer bit size {}\", bits)\n+        }\n+    }\n+\n+    pub fn ptr_sized_integer(&self) -> Integer {\n+        match self.pointer_size.bits() {\n+            16 => I16,\n+            32 => I32,\n+            64 => I64,\n+            bits => panic!(\"ptr_sized_integer: unknown pointer bit size {}\", bits)\n+        }\n+    }\n+\n+    pub fn vector_align(&self, vec_size: Size) -> Align {\n+        for &(size, align) in &self.vector_align {\n+            if size == vec_size {\n+                return align;\n+            }\n+        }\n+        // Default to natural alignment, which is what LLVM does.\n+        // That is, use the size, rounded up to a power of 2.\n+        let align = vec_size.bytes().next_power_of_two();\n+        Align::from_bytes(align, align).unwrap()\n+    }\n+}\n+\n+pub trait HasDataLayout: Copy {\n+    fn data_layout(&self) -> &TargetDataLayout;\n+}\n+\n+impl<'a> HasDataLayout for &'a TargetDataLayout {\n+    fn data_layout(&self) -> &TargetDataLayout {\n+        self\n+    }\n+}\n+\n+/// Endianness of the target, which must match cfg(target-endian).\n+#[derive(Copy, Clone)]\n+pub enum Endian {\n+    Little,\n+    Big\n+}\n+\n+/// Size of a type in bytes.\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n+pub struct Size {\n+    raw: u64\n+}\n+\n+impl Size {\n+    pub fn from_bits(bits: u64) -> Size {\n+        // Avoid potential overflow from `bits + 7`.\n+        Size::from_bytes(bits / 8 + ((bits % 8) + 7) / 8)\n+    }\n+\n+    pub fn from_bytes(bytes: u64) -> Size {\n+        if bytes >= (1 << 61) {\n+            panic!(\"Size::from_bytes: {} bytes in bits doesn't fit in u64\", bytes)\n+        }\n+        Size {\n+            raw: bytes\n+        }\n+    }\n+\n+    pub fn bytes(self) -> u64 {\n+        self.raw\n+    }\n+\n+    pub fn bits(self) -> u64 {\n+        self.bytes() * 8\n+    }\n+\n+    pub fn abi_align(self, align: Align) -> Size {\n+        let mask = align.abi() - 1;\n+        Size::from_bytes((self.bytes() + mask) & !mask)\n+    }\n+\n+    pub fn is_abi_aligned(self, align: Align) -> bool {\n+        let mask = align.abi() - 1;\n+        self.bytes() & mask == 0\n+    }\n+\n+    pub fn checked_add<C: HasDataLayout>(self, offset: Size, cx: C) -> Option<Size> {\n+        let dl = cx.data_layout();\n+\n+        // Each Size is less than dl.obj_size_bound(), so the sum is\n+        // also less than 1 << 62 (and therefore can't overflow).\n+        let bytes = self.bytes() + offset.bytes();\n+\n+        if bytes < dl.obj_size_bound() {\n+            Some(Size::from_bytes(bytes))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn checked_mul<C: HasDataLayout>(self, count: u64, cx: C) -> Option<Size> {\n+        let dl = cx.data_layout();\n+\n+        match self.bytes().checked_mul(count) {\n+            Some(bytes) if bytes < dl.obj_size_bound() => {\n+                Some(Size::from_bytes(bytes))\n+            }\n+            _ => None\n+        }\n+    }\n+}\n+\n+// Panicking addition, subtraction and multiplication for convenience.\n+// Avoid during layout computation, return `LayoutError` instead.\n+\n+impl Add for Size {\n+    type Output = Size;\n+    fn add(self, other: Size) -> Size {\n+        // Each Size is less than 1 << 61, so the sum is\n+        // less than 1 << 62 (and therefore can't overflow).\n+        Size::from_bytes(self.bytes() + other.bytes())\n+    }\n+}\n+\n+impl Sub for Size {\n+    type Output = Size;\n+    fn sub(self, other: Size) -> Size {\n+        // Each Size is less than 1 << 61, so an underflow\n+        // would result in a value larger than 1 << 61,\n+        // which Size::from_bytes will catch for us.\n+        Size::from_bytes(self.bytes() - other.bytes())\n+    }\n+}\n+\n+impl Mul<u64> for Size {\n+    type Output = Size;\n+    fn mul(self, count: u64) -> Size {\n+        match self.bytes().checked_mul(count) {\n+            Some(bytes) => Size::from_bytes(bytes),\n+            None => {\n+                panic!(\"Size::mul: {} * {} doesn't fit in u64\", self.bytes(), count)\n+            }\n+        }\n+    }\n+}\n+\n+impl AddAssign for Size {\n+    fn add_assign(&mut self, other: Size) {\n+        *self = *self + other;\n+    }\n+}\n+\n+/// Alignment of a type in bytes, both ABI-mandated and preferred.\n+/// Each field is a power of two, giving the alignment a maximum value of\n+/// 2<sup>(2<sup>8</sup> - 1)</sup>, which is limited by LLVM to a i32,\n+/// with a maximum capacity of 2<sup>31</sup> - 1 or 2147483647.\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug, RustcEncodable, RustcDecodable)]\n+pub struct Align {\n+    abi_pow2: u8,\n+    pref_pow2: u8,\n+}\n+\n+impl Align {\n+    pub fn from_bits(abi: u64, pref: u64) -> Result<Align, String> {\n+        Align::from_bytes(Size::from_bits(abi).bytes(),\n+                          Size::from_bits(pref).bytes())\n+    }\n+\n+    pub fn from_bytes(abi: u64, pref: u64) -> Result<Align, String> {\n+        let log2 = |align: u64| {\n+            // Treat an alignment of 0 bytes like 1-byte alignment.\n+            if align == 0 {\n+                return Ok(0);\n+            }\n+\n+            let mut bytes = align;\n+            let mut pow: u8 = 0;\n+            while (bytes & 1) == 0 {\n+                pow += 1;\n+                bytes >>= 1;\n+            }\n+            if bytes != 1 {\n+                Err(format!(\"`{}` is not a power of 2\", align))\n+            } else if pow > 30 {\n+                Err(format!(\"`{}` is too large\", align))\n+            } else {\n+                Ok(pow)\n+            }\n+        };\n+\n+        Ok(Align {\n+            abi_pow2: log2(abi)?,\n+            pref_pow2: log2(pref)?,\n+        })\n+    }\n+\n+    pub fn abi(self) -> u64 {\n+        1 << self.abi_pow2\n+    }\n+\n+    pub fn pref(self) -> u64 {\n+        1 << self.pref_pow2\n+    }\n+\n+    pub fn abi_bits(self) -> u64 {\n+        self.abi() * 8\n+    }\n+\n+    pub fn pref_bits(self) -> u64 {\n+        self.pref() * 8\n+    }\n+\n+    pub fn min(self, other: Align) -> Align {\n+        Align {\n+            abi_pow2: cmp::min(self.abi_pow2, other.abi_pow2),\n+            pref_pow2: cmp::min(self.pref_pow2, other.pref_pow2),\n+        }\n+    }\n+\n+    pub fn max(self, other: Align) -> Align {\n+        Align {\n+            abi_pow2: cmp::max(self.abi_pow2, other.abi_pow2),\n+            pref_pow2: cmp::max(self.pref_pow2, other.pref_pow2),\n+        }\n+    }\n+}\n+\n+/// Integers, also used for enum discriminants.\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n+pub enum Integer {\n+    I8,\n+    I16,\n+    I32,\n+    I64,\n+    I128,\n+}\n+\n+impl Integer {\n+    pub fn size(&self) -> Size {\n+        match *self {\n+            I8 => Size::from_bytes(1),\n+            I16 => Size::from_bytes(2),\n+            I32 => Size::from_bytes(4),\n+            I64  => Size::from_bytes(8),\n+            I128  => Size::from_bytes(16),\n+        }\n+    }\n+\n+    pub fn align<C: HasDataLayout>(&self, cx: C) -> Align {\n+        let dl = cx.data_layout();\n+\n+        match *self {\n+            I8 => dl.i8_align,\n+            I16 => dl.i16_align,\n+            I32 => dl.i32_align,\n+            I64 => dl.i64_align,\n+            I128 => dl.i128_align,\n+        }\n+    }\n+\n+    /// Find the smallest Integer type which can represent the signed value.\n+    pub fn fit_signed(x: i128) -> Integer {\n+        match x {\n+            -0x0000_0000_0000_0080...0x0000_0000_0000_007f => I8,\n+            -0x0000_0000_0000_8000...0x0000_0000_0000_7fff => I16,\n+            -0x0000_0000_8000_0000...0x0000_0000_7fff_ffff => I32,\n+            -0x8000_0000_0000_0000...0x7fff_ffff_ffff_ffff => I64,\n+            _ => I128\n+        }\n+    }\n+\n+    /// Find the smallest Integer type which can represent the unsigned value.\n+    pub fn fit_unsigned(x: u128) -> Integer {\n+        match x {\n+            0...0x0000_0000_0000_00ff => I8,\n+            0...0x0000_0000_0000_ffff => I16,\n+            0...0x0000_0000_ffff_ffff => I32,\n+            0...0xffff_ffff_ffff_ffff => I64,\n+            _ => I128,\n+        }\n+    }\n+\n+    /// Find the smallest integer with the given alignment.\n+    pub fn for_abi_align<C: HasDataLayout>(cx: C, align: Align) -> Option<Integer> {\n+        let dl = cx.data_layout();\n+\n+        let wanted = align.abi();\n+        for &candidate in &[I8, I16, I32, I64, I128] {\n+            if wanted == candidate.align(dl).abi() && wanted == candidate.size().bytes() {\n+                return Some(candidate);\n+            }\n+        }\n+        None\n+    }\n+\n+    /// Find the largest integer with the given alignment or less.\n+    pub fn approximate_abi_align<C: HasDataLayout>(cx: C, align: Align) -> Integer {\n+        let dl = cx.data_layout();\n+\n+        let wanted = align.abi();\n+        // FIXME(eddyb) maybe include I128 in the future, when it works everywhere.\n+        for &candidate in &[I64, I32, I16] {\n+            if wanted >= candidate.align(dl).abi() && wanted >= candidate.size().bytes() {\n+                return candidate;\n+            }\n+        }\n+        I8\n+    }\n+}\n+\n+/// Fundamental unit of memory access and layout.\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n+pub enum Primitive {\n+    /// The `bool` is the signedness of the `Integer` type.\n+    ///\n+    /// One would think we would not care about such details this low down,\n+    /// but some ABIs are described in terms of C types and ISAs where the\n+    /// integer arithmetic is done on {sign,zero}-extended registers, e.g.\n+    /// a negative integer passed by zero-extension will appear positive in\n+    /// the callee, and most operations on it will produce the wrong values.\n+    Int(Integer, bool),\n+    F32,\n+    F64,\n+    Pointer\n+}\n+\n+impl<'a, 'tcx> Primitive {\n+    pub fn size<C: HasDataLayout>(self, cx: C) -> Size {\n+        let dl = cx.data_layout();\n+\n+        match self {\n+            Int(i, _) => i.size(),\n+            F32 => Size::from_bits(32),\n+            F64 => Size::from_bits(64),\n+            Pointer => dl.pointer_size\n+        }\n+    }\n+\n+    pub fn align<C: HasDataLayout>(self, cx: C) -> Align {\n+        let dl = cx.data_layout();\n+\n+        match self {\n+            Int(i, _) => i.align(dl),\n+            F32 => dl.f32_align,\n+            F64 => dl.f64_align,\n+            Pointer => dl.pointer_align\n+        }\n+    }\n+}\n+\n+/// Information about one scalar component of a Rust type.\n+#[derive(Clone, PartialEq, Eq, Hash, Debug)]\n+pub struct Scalar {\n+    pub value: Primitive,\n+\n+    /// Inclusive wrap-around range of valid values, that is, if\n+    /// min > max, it represents min..=u128::MAX followed by 0..=max.\n+    // FIXME(eddyb) always use the shortest range, e.g. by finding\n+    // the largest space between two consecutive valid values and\n+    // taking everything else as the (shortest) valid range.\n+    pub valid_range: RangeInclusive<u128>,\n+}\n+\n+impl Scalar {\n+    pub fn is_bool(&self) -> bool {\n+        if let Int(I8, _) = self.value {\n+            self.valid_range == (0..=1)\n+        } else {\n+            false\n+        }\n+    }\n+}\n+\n+/// Describes how the fields of a type are located in memory.\n+#[derive(PartialEq, Eq, Hash, Debug)]\n+pub enum FieldPlacement {\n+    /// All fields start at no offset. The `usize` is the field count.\n+    Union(usize),\n+\n+    /// Array/vector-like placement, with all fields of identical types.\n+    Array {\n+        stride: Size,\n+        count: u64\n+    },\n+\n+    /// Struct-like placement, with precomputed offsets.\n+    ///\n+    /// Fields are guaranteed to not overlap, but note that gaps\n+    /// before, between and after all the fields are NOT always\n+    /// padding, and as such their contents may not be discarded.\n+    /// For example, enum variants leave a gap at the start,\n+    /// where the discriminant field in the enum layout goes.\n+    Arbitrary {\n+        /// Offsets for the first byte of each field,\n+        /// ordered to match the source definition order.\n+        /// This vector does not go in increasing order.\n+        // FIXME(eddyb) use small vector optimization for the common case.\n+        offsets: Vec<Size>,\n+\n+        /// Maps source order field indices to memory order indices,\n+        /// depending how fields were permuted.\n+        // FIXME(camlorn) also consider small vector  optimization here.\n+        memory_index: Vec<u32>\n+    }\n+}\n+\n+impl FieldPlacement {\n+    pub fn count(&self) -> usize {\n+        match *self {\n+            FieldPlacement::Union(count) => count,\n+            FieldPlacement::Array { count, .. } => {\n+                let usize_count = count as usize;\n+                assert_eq!(usize_count as u64, count);\n+                usize_count\n+            }\n+            FieldPlacement::Arbitrary { ref offsets, .. } => offsets.len()\n+        }\n+    }\n+\n+    pub fn offset(&self, i: usize) -> Size {\n+        match *self {\n+            FieldPlacement::Union(_) => Size::from_bytes(0),\n+            FieldPlacement::Array { stride, count } => {\n+                let i = i as u64;\n+                assert!(i < count);\n+                stride * i\n+            }\n+            FieldPlacement::Arbitrary { ref offsets, .. } => offsets[i]\n+        }\n+    }\n+\n+    pub fn memory_index(&self, i: usize) -> usize {\n+        match *self {\n+            FieldPlacement::Union(_) |\n+            FieldPlacement::Array { .. } => i,\n+            FieldPlacement::Arbitrary { ref memory_index, .. } => {\n+                let r = memory_index[i];\n+                assert_eq!(r as usize as u32, r);\n+                r as usize\n+            }\n+        }\n+    }\n+\n+    /// Get source indices of the fields by increasing offsets.\n+    #[inline]\n+    pub fn index_by_increasing_offset<'a>(&'a self) -> impl Iterator<Item=usize>+'a {\n+        let mut inverse_small = [0u8; 64];\n+        let mut inverse_big = vec![];\n+        let use_small = self.count() <= inverse_small.len();\n+\n+        // We have to write this logic twice in order to keep the array small.\n+        if let FieldPlacement::Arbitrary { ref memory_index, .. } = *self {\n+            if use_small {\n+                for i in 0..self.count() {\n+                    inverse_small[memory_index[i] as usize] = i as u8;\n+                }\n+            } else {\n+                inverse_big = vec![0; self.count()];\n+                for i in 0..self.count() {\n+                    inverse_big[memory_index[i] as usize] = i as u32;\n+                }\n+            }\n+        }\n+\n+        (0..self.count()).map(move |i| {\n+            match *self {\n+                FieldPlacement::Union(_) |\n+                FieldPlacement::Array { .. } => i,\n+                FieldPlacement::Arbitrary { .. } => {\n+                    if use_small { inverse_small[i] as usize }\n+                    else { inverse_big[i] as usize }\n+                }\n+            }\n+        })\n+    }\n+}\n+\n+/// Describes how values of the type are passed by target ABIs,\n+/// in terms of categories of C types there are ABI rules for.\n+#[derive(Clone, PartialEq, Eq, Hash, Debug)]\n+pub enum Abi {\n+    Uninhabited,\n+    Scalar(Scalar),\n+    ScalarPair(Scalar, Scalar),\n+    Vector {\n+        element: Scalar,\n+        count: u64\n+    },\n+    Aggregate {\n+        /// If true, the size is exact, otherwise it's only a lower bound.\n+        sized: bool,\n+    }\n+}\n+\n+impl Abi {\n+    /// Returns true if the layout corresponds to an unsized type.\n+    pub fn is_unsized(&self) -> bool {\n+        match *self {\n+            Abi::Uninhabited |\n+            Abi::Scalar(_) |\n+            Abi::ScalarPair(..) |\n+            Abi::Vector { .. } => false,\n+            Abi::Aggregate { sized } => !sized\n+        }\n+    }\n+\n+    /// Returns true if this is a single signed integer scalar\n+    pub fn is_signed(&self) -> bool {\n+        match *self {\n+            Abi::Scalar(ref scal) => match scal.value {\n+                Primitive::Int(_, signed) => signed,\n+                _ => false,\n+            },\n+            _ => false,\n+        }\n+    }\n+}\n+\n+#[derive(PartialEq, Eq, Hash, Debug)]\n+pub enum Variants {\n+    /// Single enum variants, structs/tuples, unions, and all non-ADTs.\n+    Single {\n+        index: usize\n+    },\n+\n+    /// General-case enums: for each case there is a struct, and they all have\n+    /// all space reserved for the discriminant, and their first field starts\n+    /// at a non-0 offset, after where the discriminant would go.\n+    Tagged {\n+        discr: Scalar,\n+        variants: Vec<LayoutDetails>,\n+    },\n+\n+    /// Multiple cases distinguished by a niche (values invalid for a type):\n+    /// the variant `dataful_variant` contains a niche at an arbitrary\n+    /// offset (field 0 of the enum), which for a variant with discriminant\n+    /// `d` is set to `(d - niche_variants.start).wrapping_add(niche_start)`.\n+    ///\n+    /// For example, `Option<(usize, &T)>`  is represented such that\n+    /// `None` has a null pointer for the second tuple field, and\n+    /// `Some` is the identity function (with a non-null reference).\n+    NicheFilling {\n+        dataful_variant: usize,\n+        niche_variants: RangeInclusive<usize>,\n+        niche: Scalar,\n+        niche_start: u128,\n+        variants: Vec<LayoutDetails>,\n+    }\n+}\n+\n+#[derive(PartialEq, Eq, Hash, Debug)]\n+pub struct LayoutDetails {\n+    pub variants: Variants,\n+    pub fields: FieldPlacement,\n+    pub abi: Abi,\n+    pub align: Align,\n+    pub size: Size\n+}\n+\n+impl LayoutDetails {\n+    pub fn scalar<C: HasDataLayout>(cx: C, scalar: Scalar) -> Self {\n+        let size = scalar.value.size(cx);\n+        let align = scalar.value.align(cx);\n+        LayoutDetails {\n+            variants: Variants::Single { index: 0 },\n+            fields: FieldPlacement::Union(0),\n+            abi: Abi::Scalar(scalar),\n+            size,\n+            align,\n+        }\n+    }\n+\n+    pub fn uninhabited(field_count: usize) -> Self {\n+        let align = Align::from_bytes(1, 1).unwrap();\n+        LayoutDetails {\n+            variants: Variants::Single { index: 0 },\n+            fields: FieldPlacement::Union(field_count),\n+            abi: Abi::Uninhabited,\n+            align,\n+            size: Size::from_bytes(0)\n+        }\n+    }\n+}\n+\n+pub trait LayoutOf<T> {\n+    type TyLayout;\n+\n+    fn layout_of(self, ty: T) -> Self::TyLayout;\n+}\n\\ No newline at end of file"}, {"sha": "a98685f9274198279bba5ebac9070f3c9022e16f", "filename": "src/librustc_target/lib.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_target%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_target%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_target%2Flib.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -28,6 +28,8 @@\n #![feature(box_syntax)]\n #![feature(const_fn)]\n #![feature(fs_read_write)]\n+#![feature(inclusive_range)]\n+#![feature(slice_patterns)]\n \n extern crate syntax;\n extern crate rand;\n@@ -36,4 +38,5 @@ extern crate serialize;\n \n extern crate serialize as rustc_serialize; // used by deriving\n \n+pub mod abi;\n pub mod spec;"}, {"sha": "5359e0e0405a1d5af2ef41fe2259f6ab402251e2", "filename": "src/librustc_trans/debuginfo/metadata.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_trans%2Fdebuginfo%2Fmetadata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bdcd08278a4b442bd156e3704065403d86728eda/src%2Flibrustc_trans%2Fdebuginfo%2Fmetadata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fdebuginfo%2Fmetadata.rs?ref=bdcd08278a4b442bd156e3704065403d86728eda", "patch": "@@ -32,7 +32,7 @@ use rustc::ich::Fingerprint;\n use rustc::ty::Instance;\n use common::CodegenCx;\n use rustc::ty::{self, AdtKind, ParamEnv, Ty, TyCtxt};\n-use rustc::ty::layout::{self, Align, LayoutOf, Size, TyLayout};\n+use rustc::ty::layout::{self, Align, LayoutOf, PrimitiveExt, Size, TyLayout};\n use rustc::session::config;\n use rustc::util::nodemap::FxHashMap;\n use rustc::util::common::path2cstr;"}]}