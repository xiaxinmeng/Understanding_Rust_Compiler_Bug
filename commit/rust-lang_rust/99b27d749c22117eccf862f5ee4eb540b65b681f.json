{"sha": "99b27d749c22117eccf862f5ee4eb540b65b681f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk5YjI3ZDc0OWMyMjExN2VjY2Y4NjJmNWVlNGViNTQwYjY1YjY4MWY=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-04T14:55:23Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-06T11:03:14Z"}, "message": "syntax: Rename `Token` into `TokenKind`", "tree": {"sha": "e891310a8eb306921f8a054bb40cf653433403fe", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e891310a8eb306921f8a054bb40cf653433403fe"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/99b27d749c22117eccf862f5ee4eb540b65b681f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/99b27d749c22117eccf862f5ee4eb540b65b681f", "html_url": "https://github.com/rust-lang/rust/commit/99b27d749c22117eccf862f5ee4eb540b65b681f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/99b27d749c22117eccf862f5ee4eb540b65b681f/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "eac3846b65b068a5cbdfafc786e258554b875dae", "url": "https://api.github.com/repos/rust-lang/rust/commits/eac3846b65b068a5cbdfafc786e258554b875dae", "html_url": "https://github.com/rust-lang/rust/commit/eac3846b65b068a5cbdfafc786e258554b875dae"}], "stats": {"total": 238, "additions": 119, "deletions": 119}, "files": [{"sha": "919f682fc4f6fced54f58ae31f20cb319172039c", "filename": "src/librustc/hir/lowering.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc%2Fhir%2Flowering.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc%2Fhir%2Flowering.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Flowering.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -67,7 +67,7 @@ use syntax::source_map::CompilerDesugaringKind::IfTemporary;\n use syntax::std_inject;\n use syntax::symbol::{kw, sym, Symbol};\n use syntax::tokenstream::{TokenStream, TokenTree};\n-use syntax::parse::token::{self, Token};\n+use syntax::parse::token::{self, TokenKind};\n use syntax::visit::{self, Visitor};\n use syntax_pos::{DUMMY_SP, edition, Span};\n \n@@ -1337,7 +1337,7 @@ impl<'a> LoweringContext<'a> {\n         }\n     }\n \n-    fn lower_token(&mut self, token: Token, span: Span) -> TokenStream {\n+    fn lower_token(&mut self, token: TokenKind, span: Span) -> TokenStream {\n         match token {\n             token::Interpolated(nt) => {\n                 let tts = nt.to_tokenstream(&self.sess.parse_sess, span);"}, {"sha": "b9a80ebb78f20ef1783b21e45c163615ae07f142", "filename": "src/librustc/hir/map/def_collector.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -6,7 +6,7 @@ use syntax::ast::*;\n use syntax::ext::hygiene::Mark;\n use syntax::visit;\n use syntax::symbol::{kw, sym};\n-use syntax::parse::token::{self, Token};\n+use syntax::parse::token::{self, TokenKind};\n use syntax_pos::Span;\n \n /// Creates `DefId`s for nodes in the AST.\n@@ -325,7 +325,7 @@ impl<'a> visit::Visitor<'a> for DefCollector<'a> {\n         }\n     }\n \n-    fn visit_token(&mut self, t: Token) {\n+    fn visit_token(&mut self, t: TokenKind) {\n         if let token::Interpolated(nt) = t {\n             if let token::NtExpr(ref expr) = *nt {\n                 if let ExprKind::Mac(..) = expr.node {"}, {"sha": "8e2550d3c453747188fc6528b6ea0c0d2afe0fa8", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -307,7 +307,7 @@ impl_stable_hash_for!(struct token::Lit {\n });\n \n fn hash_token<'a, 'gcx, W: StableHasherResult>(\n-    token: &token::Token,\n+    token: &token::TokenKind,\n     hcx: &mut StableHashingContext<'a>,\n     hasher: &mut StableHasher<W>,\n ) {"}, {"sha": "a7a78a69952f4f265ad9da4c8cbc76329cd4049c", "filename": "src/librustc_resolve/build_reduced_graph.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -34,7 +34,7 @@ use syntax::ext::base::Determinacy::Undetermined;\n use syntax::ext::hygiene::Mark;\n use syntax::ext::tt::macro_rules;\n use syntax::feature_gate::is_builtin_attr;\n-use syntax::parse::token::{self, Token};\n+use syntax::parse::token::{self, TokenKind};\n use syntax::span_err;\n use syntax::std_inject::injected_crate_name;\n use syntax::symbol::{kw, sym};\n@@ -1052,7 +1052,7 @@ impl<'a, 'b> Visitor<'a> for BuildReducedGraphVisitor<'a, 'b> {\n         self.resolver.current_module = parent;\n     }\n \n-    fn visit_token(&mut self, t: Token) {\n+    fn visit_token(&mut self, t: TokenKind) {\n         if let token::Interpolated(nt) = t {\n             if let token::NtExpr(ref expr) = *nt {\n                 if let ast::ExprKind::Mac(..) = expr.node {"}, {"sha": "5527fcb923b6fbf87840de746e54b815104b370d", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -5,7 +5,7 @@ use crate::generated_code;\n use std::cell::Cell;\n \n use syntax::parse::lexer::{self, StringReader};\n-use syntax::parse::token::{self, Token};\n+use syntax::parse::token::{self, TokenKind};\n use syntax_pos::*;\n \n #[derive(Clone)]\n@@ -56,7 +56,7 @@ impl<'a> SpanUtils<'a> {\n         lexer::StringReader::retokenize(&self.sess.parse_sess, span)\n     }\n \n-    pub fn sub_span_of_token(&self, span: Span, tok: Token) -> Option<Span> {\n+    pub fn sub_span_of_token(&self, span: Span, tok: TokenKind) -> Option<Span> {\n         let mut toks = self.retokenise_span(span);\n         loop {\n             let next = toks.real_token();"}, {"sha": "ade15f024a60919a760be14d0567f4e38fffceaa", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -20,7 +20,7 @@ use crate::source_map::{BytePos, Spanned, dummy_spanned};\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use crate::parse::parser::Parser;\n use crate::parse::{self, ParseSess, PResult};\n-use crate::parse::token::{self, Token};\n+use crate::parse::token::{self, TokenKind};\n use crate::ptr::P;\n use crate::symbol::{sym, Symbol};\n use crate::ThinVec;\n@@ -468,7 +468,7 @@ impl MetaItem {\n                 idents.push(TokenTree::Token(mod_sep_span, token::ModSep).into());\n             }\n             idents.push(TokenTree::Token(segment.ident.span,\n-                                         Token::from_ast_ident(segment.ident)).into());\n+                                         TokenKind::from_ast_ident(segment.ident)).into());\n             last_pos = segment.ident.span.hi();\n         }\n         self.node.tokens(self.span).append_to_tree_and_joint_vec(&mut idents);"}, {"sha": "c22952ed7504b904ea4cc07e2c8e37a4d65666eb", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -78,7 +78,7 @@ use crate::ast::Ident;\n use crate::ext::tt::quoted::{self, TokenTree};\n use crate::parse::{Directory, ParseSess};\n use crate::parse::parser::{Parser, PathStyle};\n-use crate::parse::token::{self, DocComment, Nonterminal, Token};\n+use crate::parse::token::{self, DocComment, Nonterminal, TokenKind};\n use crate::print::pprust;\n use crate::symbol::{kw, sym, Symbol};\n use crate::tokenstream::{DelimSpan, TokenStream};\n@@ -199,7 +199,7 @@ struct MatcherPos<'root, 'tt: 'root> {\n     seq_op: Option<quoted::KleeneOp>,\n \n     /// The separator if we are in a repetition.\n-    sep: Option<Token>,\n+    sep: Option<TokenKind>,\n \n     /// The \"parent\" matcher position if we are in a repetition. That is, the matcher position just\n     /// before we enter the sequence.\n@@ -273,7 +273,7 @@ pub enum ParseResult<T> {\n     Success(T),\n     /// Arm failed to match. If the second parameter is `token::Eof`, it indicates an unexpected\n     /// end of macro invocation. Otherwise, it indicates that no rules expected the given token.\n-    Failure(syntax_pos::Span, Token, &'static str),\n+    Failure(syntax_pos::Span, TokenKind, &'static str),\n     /// Fatal error (malformed macro?). Abort compilation.\n     Error(syntax_pos::Span, String),\n }\n@@ -417,7 +417,7 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n \n /// Generates an appropriate parsing failure message. For EOF, this is \"unexpected end...\". For\n /// other tokens, this is \"unexpected token...\".\n-pub fn parse_failure_msg(tok: Token) -> String {\n+pub fn parse_failure_msg(tok: TokenKind) -> String {\n     match tok {\n         token::Eof => \"unexpected end of macro invocation\".to_string(),\n         _ => format!(\n@@ -428,7 +428,7 @@ pub fn parse_failure_msg(tok: Token) -> String {\n }\n \n /// Performs a token equality check, ignoring syntax context (that is, an unhygienic comparison)\n-fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n+fn token_name_eq(t1: &TokenKind, t2: &TokenKind) -> bool {\n     if let (Some((id1, is_raw1)), Some((id2, is_raw2))) = (t1.ident(), t2.ident()) {\n         id1.name == id2.name && is_raw1 == is_raw2\n     } else if let (Some(id1), Some(id2)) = (t1.lifetime(), t2.lifetime()) {\n@@ -466,7 +466,7 @@ fn inner_parse_loop<'root, 'tt>(\n     next_items: &mut Vec<MatcherPosHandle<'root, 'tt>>,\n     eof_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n     bb_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    token: &Token,\n+    token: &TokenKind,\n     span: syntax_pos::Span,\n ) -> ParseResult<()> {\n     // Pop items from `cur_items` until it is empty.\n@@ -807,7 +807,7 @@ pub fn parse(\n \n /// The token is an identifier, but not `_`.\n /// We prohibit passing `_` to macros expecting `ident` for now.\n-fn get_macro_ident(token: &Token) -> Option<(Ident, bool)> {\n+fn get_macro_ident(token: &TokenKind) -> Option<(Ident, bool)> {\n     match *token {\n         token::Ident(ident, is_raw) if ident.name != kw::Underscore =>\n             Some((ident, is_raw)),\n@@ -819,7 +819,7 @@ fn get_macro_ident(token: &Token) -> Option<(Ident, bool)> {\n ///\n /// Returning `false` is a *stability guarantee* that such a matcher will *never* begin with that\n /// token. Be conservative (return true) if not sure.\n-fn may_begin_with(name: Symbol, token: &Token) -> bool {\n+fn may_begin_with(name: Symbol, token: &TokenKind) -> bool {\n     /// Checks whether the non-terminal may contain a single (non-keyword) identifier.\n     fn may_be_ident(nt: &token::Nonterminal) -> bool {\n         match *nt {"}, {"sha": "9d3ea4d8645da328f8b577d6ebfa9fc780255399", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -12,7 +12,7 @@ use crate::feature_gate::Features;\n use crate::parse::{Directory, ParseSess};\n use crate::parse::parser::Parser;\n use crate::parse::token::{self, NtTT};\n-use crate::parse::token::Token::*;\n+use crate::parse::token::TokenKind::*;\n use crate::symbol::{Symbol, kw, sym};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree};\n "}, {"sha": "fe0cb56b29e3087db7b9228ef102952f9d40c18f", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -23,12 +23,12 @@ pub struct Delimited {\n \n impl Delimited {\n     /// Returns the opening delimiter (possibly `NoDelim`).\n-    pub fn open_token(&self) -> token::Token {\n+    pub fn open_token(&self) -> token::TokenKind {\n         token::OpenDelim(self.delim)\n     }\n \n     /// Returns the closing delimiter (possibly `NoDelim`).\n-    pub fn close_token(&self) -> token::Token {\n+    pub fn close_token(&self) -> token::TokenKind {\n         token::CloseDelim(self.delim)\n     }\n \n@@ -58,7 +58,7 @@ pub struct SequenceRepetition {\n     /// The sequence of token trees\n     pub tts: Vec<TokenTree>,\n     /// The optional separator\n-    pub separator: Option<token::Token>,\n+    pub separator: Option<token::TokenKind>,\n     /// Whether the sequence can be repeated zero (*), or one or more times (+)\n     pub op: KleeneOp,\n     /// The number of `Match`s that appear in the sequence (and subsequences)\n@@ -81,7 +81,7 @@ pub enum KleeneOp {\n /// are \"first-class\" token trees. Useful for parsing macros.\n #[derive(Debug, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n pub enum TokenTree {\n-    Token(Span, token::Token),\n+    Token(Span, token::TokenKind),\n     Delimited(DelimSpan, Lrc<Delimited>),\n     /// A kleene-style repetition sequence\n     Sequence(DelimSpan, Lrc<SequenceRepetition>),\n@@ -366,7 +366,7 @@ where\n \n /// Takes a token and returns `Some(KleeneOp)` if the token is `+` `*` or `?`. Otherwise, return\n /// `None`.\n-fn kleene_op(token: &token::Token) -> Option<KleeneOp> {\n+fn kleene_op(token: &token::TokenKind) -> Option<KleeneOp> {\n     match *token {\n         token::BinOp(token::Star) => Some(KleeneOp::ZeroOrMore),\n         token::BinOp(token::Plus) => Some(KleeneOp::OneOrMore),\n@@ -383,7 +383,7 @@ fn kleene_op(token: &token::Token) -> Option<KleeneOp> {\n fn parse_kleene_op<I>(\n     input: &mut I,\n     span: Span,\n-) -> Result<Result<(KleeneOp, Span), (token::Token, Span)>, Span>\n+) -> Result<Result<(KleeneOp, Span), (token::TokenKind, Span)>, Span>\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -422,7 +422,7 @@ fn parse_sep_and_kleene_op<I>(\n     attrs: &[ast::Attribute],\n     edition: Edition,\n     macro_node_id: NodeId,\n-) -> (Option<token::Token>, KleeneOp)\n+) -> (Option<token::TokenKind>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -447,7 +447,7 @@ fn parse_sep_and_kleene_op_2015<I>(\n     _features: &Features,\n     _attrs: &[ast::Attribute],\n     macro_node_id: NodeId,\n-) -> (Option<token::Token>, KleeneOp)\n+) -> (Option<token::TokenKind>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -565,7 +565,7 @@ fn parse_sep_and_kleene_op_2018<I>(\n     sess: &ParseSess,\n     _features: &Features,\n     _attrs: &[ast::Attribute],\n-) -> (Option<token::Token>, KleeneOp)\n+) -> (Option<token::TokenKind>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {"}, {"sha": "1b169d7696af3888881ae080e2377051239b2c30", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -4,7 +4,7 @@ use crate::ext::expand::Marker;\n use crate::ext::tt::macro_parser::{MatchedNonterminal, MatchedSeq, NamedMatch};\n use crate::ext::tt::quoted;\n use crate::mut_visit::noop_visit_tt;\n-use crate::parse::token::{self, NtTT, Token};\n+use crate::parse::token::{self, NtTT, TokenKind};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndJoint};\n \n use smallvec::{smallvec, SmallVec};\n@@ -18,7 +18,7 @@ use std::rc::Rc;\n /// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n enum Frame {\n     Delimited { forest: Lrc<quoted::Delimited>, idx: usize, span: DelimSpan },\n-    Sequence { forest: Lrc<quoted::SequenceRepetition>, idx: usize, sep: Option<Token> },\n+    Sequence { forest: Lrc<quoted::SequenceRepetition>, idx: usize, sep: Option<TokenKind> },\n }\n \n impl Frame {\n@@ -242,7 +242,7 @@ pub fn transcribe(\n                         Ident::new(ident.name, ident.span.apply_mark(cx.current_expansion.mark));\n                     sp = sp.apply_mark(cx.current_expansion.mark);\n                     result.push(TokenTree::Token(sp, token::Dollar).into());\n-                    result.push(TokenTree::Token(sp, token::Token::from_ast_ident(ident)).into());\n+                    result.push(TokenTree::Token(sp, token::TokenKind::from_ast_ident(ident)).into());\n                 }\n             }\n "}, {"sha": "289f2c0ce4864f7f00a7337918968c826215ea5a", "filename": "src/libsyntax/mut_visit.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -9,7 +9,7 @@\n \n use crate::ast::*;\n use crate::source_map::{Spanned, respan};\n-use crate::parse::token::{self, Token};\n+use crate::parse::token::{self, TokenKind};\n use crate::ptr::P;\n use crate::ThinVec;\n use crate::tokenstream::*;\n@@ -262,7 +262,7 @@ pub trait MutVisitor: Sized {\n         noop_visit_tts(tts, self);\n     }\n \n-    fn visit_token(&mut self, t: &mut Token) {\n+    fn visit_token(&mut self, t: &mut TokenKind) {\n         noop_visit_token(t, self);\n     }\n \n@@ -596,7 +596,7 @@ pub fn noop_visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &m\n }\n \n // apply ident visitor if it's an ident, apply other visits to interpolated nodes\n-pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n+pub fn noop_visit_token<T: MutVisitor>(t: &mut TokenKind, vis: &mut T) {\n     match t {\n         token::Ident(id, _is_raw) => vis.visit_ident(id),\n         token::Lifetime(id) => vis.visit_ident(id),"}, {"sha": "b391f7ca327e851025a8ff0e28189aceffc02ea7", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -229,8 +229,8 @@ impl<'a> Parser<'a> {\n \n     pub fn expected_one_of_not_found(\n         &mut self,\n-        edible: &[token::Token],\n-        inedible: &[token::Token],\n+        edible: &[token::TokenKind],\n+        inedible: &[token::TokenKind],\n     ) -> PResult<'a, bool /* recovered */> {\n         fn tokens_to_string(tokens: &[TokenType]) -> String {\n             let mut i = tokens.iter();\n@@ -368,7 +368,7 @@ impl<'a> Parser<'a> {\n \n     /// Eats and discards tokens until one of `kets` is encountered. Respects token trees,\n     /// passes through any errors encountered. Used for error recovery.\n-    crate fn eat_to_tokens(&mut self, kets: &[&token::Token]) {\n+    crate fn eat_to_tokens(&mut self, kets: &[&token::TokenKind]) {\n         let handler = self.diagnostic();\n \n         if let Err(ref mut err) = self.parse_seq_to_before_tokens(\n@@ -388,7 +388,7 @@ impl<'a> Parser<'a> {\n     /// let _ = vec![1, 2, 3].into_iter().collect::<Vec<usize>>>>();\n     ///                                                        ^^ help: remove extra angle brackets\n     /// ```\n-    crate fn check_trailing_angle_brackets(&mut self, segment: &PathSegment, end: token::Token) {\n+    crate fn check_trailing_angle_brackets(&mut self, segment: &PathSegment, end: token::TokenKind) {\n         // This function is intended to be invoked after parsing a path segment where there are two\n         // cases:\n         //\n@@ -726,7 +726,7 @@ impl<'a> Parser<'a> {\n     /// closing delimiter.\n     pub fn unexpected_try_recover(\n         &mut self,\n-        t: &token::Token,\n+        t: &token::TokenKind,\n     ) -> PResult<'a, bool /* recovered */> {\n         let token_str = pprust::token_to_string(t);\n         let this_token_str = self.this_token_descr();\n@@ -903,7 +903,7 @@ impl<'a> Parser<'a> {\n \n     crate fn recover_closing_delimiter(\n         &mut self,\n-        tokens: &[token::Token],\n+        tokens: &[token::TokenKind],\n         mut err: DiagnosticBuilder<'a>,\n     ) -> PResult<'a, bool> {\n         let mut pos = None;"}, {"sha": "ca9199975bb7e0e0260ae3abe8c884ddeda14f7a", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -1,6 +1,6 @@\n use crate::ast::{self, Ident};\n use crate::parse::ParseSess;\n-use crate::parse::token::{self, Token};\n+use crate::parse::token::{self, TokenKind};\n use crate::symbol::{sym, Symbol};\n use crate::parse::unescape;\n use crate::parse::unescape_error_reporting::{emit_unescape_error, push_escaped_char};\n@@ -22,7 +22,7 @@ mod unicode_chars;\n \n #[derive(Clone, Debug)]\n pub struct TokenAndSpan {\n-    pub tok: Token,\n+    pub tok: TokenKind,\n     pub sp: Span,\n }\n \n@@ -56,7 +56,7 @@ pub struct StringReader<'a> {\n     /// Stop reading src at this index.\n     crate end_src_index: usize,\n     // cached:\n-    peek_tok: Token,\n+    peek_tok: TokenKind,\n     peek_span: Span,\n     peek_span_src_raw: Span,\n     fatal_errs: Vec<DiagnosticBuilder<'a>>,\n@@ -847,7 +847,7 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    fn binop(&mut self, op: token::BinOpToken) -> Token {\n+    fn binop(&mut self, op: token::BinOpToken) -> TokenKind {\n         self.bump();\n         if self.ch_is('=') {\n             self.bump();\n@@ -859,7 +859,7 @@ impl<'a> StringReader<'a> {\n \n     /// Returns the next token from the string, advances the input past that\n     /// token, and updates the interner\n-    fn next_token_inner(&mut self) -> Result<Token, ()> {\n+    fn next_token_inner(&mut self) -> Result<TokenKind, ()> {\n         let c = self.ch;\n \n         if ident_start(c) {\n@@ -916,7 +916,7 @@ impl<'a> StringReader<'a> {\n             let (kind, symbol) = self.scan_number(c.unwrap());\n             let suffix = self.scan_optional_raw_name();\n             debug!(\"next_token_inner: scanned number {:?}, {:?}, {:?}\", kind, symbol, suffix);\n-            return Ok(Token::lit(kind, symbol, suffix));\n+            return Ok(TokenKind::lit(kind, symbol, suffix));\n         }\n \n         match c.expect(\"next_token_inner called at EOF\") {\n@@ -1077,7 +1077,7 @@ impl<'a> StringReader<'a> {\n                         let symbol = self.name_from(start);\n                         self.bump();\n                         self.validate_char_escape(start_with_quote);\n-                        return Ok(Token::lit(token::Char, symbol, None));\n+                        return Ok(TokenKind::lit(token::Char, symbol, None));\n                     }\n \n                     // Include the leading `'` in the real identifier, for macro\n@@ -1102,7 +1102,7 @@ impl<'a> StringReader<'a> {\n                 let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n                 self.validate_char_escape(start_with_quote);\n                 let suffix = self.scan_optional_raw_name();\n-                Ok(Token::lit(token::Char, symbol, suffix))\n+                Ok(TokenKind::lit(token::Char, symbol, suffix))\n             }\n             'b' => {\n                 self.bump();\n@@ -1127,15 +1127,15 @@ impl<'a> StringReader<'a> {\n                 };\n                 let suffix = self.scan_optional_raw_name();\n \n-                Ok(Token::lit(kind, symbol, suffix))\n+                Ok(TokenKind::lit(kind, symbol, suffix))\n             }\n             '\"' => {\n                 let start_with_quote = self.pos;\n                 let msg = \"unterminated double quote string\";\n                 let symbol = self.scan_double_quoted_string(msg);\n                 self.validate_str_escape(start_with_quote);\n                 let suffix = self.scan_optional_raw_name();\n-                Ok(Token::lit(token::Str, symbol, suffix))\n+                Ok(TokenKind::lit(token::Str, symbol, suffix))\n             }\n             'r' => {\n                 let start_bpos = self.pos;\n@@ -1213,7 +1213,7 @@ impl<'a> StringReader<'a> {\n                 };\n                 let suffix = self.scan_optional_raw_name();\n \n-                Ok(Token::lit(token::StrRaw(hash_count), symbol, suffix))\n+                Ok(TokenKind::lit(token::StrRaw(hash_count), symbol, suffix))\n             }\n             '-' => {\n                 if self.nextch_is('>') {\n@@ -1638,19 +1638,19 @@ mod tests {\n \n     // check that the given reader produces the desired stream\n     // of tokens (stop checking after exhausting the expected vec)\n-    fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<Token>) {\n+    fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<TokenKind>) {\n         for expected_tok in &expected {\n             assert_eq!(&string_reader.next_token().tok, expected_tok);\n         }\n     }\n \n     // make the identifier by looking up the string in the interner\n-    fn mk_ident(id: &str) -> Token {\n-        Token::from_ast_ident(Ident::from_str(id))\n+    fn mk_ident(id: &str) -> TokenKind {\n+        TokenKind::from_ast_ident(Ident::from_str(id))\n     }\n \n-    fn mk_lit(kind: token::LitKind, symbol: &str, suffix: Option<&str>) -> Token {\n-        Token::lit(kind, Symbol::intern(symbol), suffix.map(Symbol::intern))\n+    fn mk_lit(kind: token::LitKind, symbol: &str, suffix: Option<&str>) -> TokenKind {\n+        TokenKind::lit(kind, Symbol::intern(symbol), suffix.map(Symbol::intern))\n     }\n \n     #[test]"}, {"sha": "b8cd32883b88c5299596d068850b67b6fe4efe14", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -23,7 +23,7 @@ impl<'a> StringReader<'a> {\n \n struct TokenTreesReader<'a> {\n     string_reader: StringReader<'a>,\n-    token: token::Token,\n+    token: token::TokenKind,\n     span: Span,\n     /// Stack of open delimiters and their spans. Used for error message.\n     open_braces: Vec<(token::DelimToken, Span)>,"}, {"sha": "945475ff9818bc6e4d882d0b4960beefa38cd5fd", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -3,7 +3,7 @@\n use crate::ast::{self, Ident, Lit, LitKind};\n use crate::parse::parser::Parser;\n use crate::parse::PResult;\n-use crate::parse::token::{self, Token};\n+use crate::parse::token::{self, TokenKind};\n use crate::parse::unescape::{unescape_str, unescape_char, unescape_byte_str, unescape_byte};\n use crate::print::pprust;\n use crate::symbol::{kw, sym, Symbol};\n@@ -228,7 +228,7 @@ impl Lit {\n     }\n \n     /// Converts arbitrary token into an AST literal.\n-    crate fn from_token(token: &Token, span: Span) -> Result<Lit, LitError> {\n+    crate fn from_token(token: &TokenKind, span: Span) -> Result<Lit, LitError> {\n         let lit = match *token {\n             token::Ident(ident, false) if ident.name == kw::True || ident.name == kw::False =>\n                 token::Lit::new(token::Bool, ident.name, None),\n@@ -276,7 +276,7 @@ impl<'a> Parser<'a> {\n                     let next_span = self.look_ahead_span(1);\n                     if self.span.hi() == next_span.lo() {\n                         let s = String::from(\"0.\") + &symbol.as_str();\n-                        let token = Token::lit(token::Float, Symbol::intern(&s), suffix);\n+                        let token = TokenKind::lit(token::Float, Symbol::intern(&s), suffix);\n                         return Some((token, self.span.to(next_span)));\n                     }\n                 }"}, {"sha": "7f8b96508bdd943a2980ef6a2ca3c9d09e732315", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -358,13 +358,13 @@ pub fn stream_to_parser_with_base_dir<'a>(\n /// A sequence separator.\n pub struct SeqSep {\n     /// The seperator token.\n-    pub sep: Option<token::Token>,\n+    pub sep: Option<token::TokenKind>,\n     /// `true` if a trailing separator is allowed.\n     pub trailing_sep_allowed: bool,\n }\n \n impl SeqSep {\n-    pub fn trailing_allowed(t: token::Token) -> SeqSep {\n+    pub fn trailing_allowed(t: token::TokenKind) -> SeqSep {\n         SeqSep {\n             sep: Some(t),\n             trailing_sep_allowed: true,"}, {"sha": "8fc02dd9259e0c310725ec81d77df6476686b31e", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 24, "deletions": 24, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -196,9 +196,9 @@ enum PrevTokenKind {\n #[derive(Clone)]\n pub struct Parser<'a> {\n     pub sess: &'a ParseSess,\n-    /// The current token.\n-    pub token: token::Token,\n-    /// The span of the current token.\n+    /// the current token:\n+    pub token: token::TokenKind,\n+    /// the span of the current token:\n     pub span: Span,\n     meta_var_span: Option<Span>,\n     /// The span of the previous token.\n@@ -355,7 +355,7 @@ impl TokenCursor {\n             [\n                 TokenTree::Token(sp, token::Ident(ast::Ident::with_empty_ctxt(sym::doc), false)),\n                 TokenTree::Token(sp, token::Eq),\n-                TokenTree::Token(sp, token::Token::lit(\n+                TokenTree::Token(sp, token::TokenKind::lit(\n                     token::StrRaw(num_of_hashes), Symbol::intern(&stripped), None\n                 )),\n             ]\n@@ -380,7 +380,7 @@ impl TokenCursor {\n \n #[derive(Clone, PartialEq)]\n crate enum TokenType {\n-    Token(token::Token),\n+    Token(token::TokenKind),\n     Keyword(Symbol),\n     Operator,\n     Lifetime,\n@@ -410,7 +410,7 @@ impl TokenType {\n ///\n /// Types can also be of the form `IDENT(u8, u8) -> u8`, however this assumes\n /// that `IDENT` is not the ident of a fn trait.\n-fn can_continue_type_after_non_fn_ident(t: &token::Token) -> bool {\n+fn can_continue_type_after_non_fn_ident(t: &token::TokenKind) -> bool {\n     t == &token::ModSep || t == &token::Lt ||\n     t == &token::BinOp(token::Shl)\n }\n@@ -559,7 +559,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Expects and consumes the token `t`. Signals an error if the next token is not `t`.\n-    pub fn expect(&mut self, t: &token::Token) -> PResult<'a, bool /* recovered */> {\n+    pub fn expect(&mut self, t: &token::TokenKind) -> PResult<'a, bool /* recovered */> {\n         if self.expected_tokens.is_empty() {\n             if self.token == *t {\n                 self.bump();\n@@ -577,8 +577,8 @@ impl<'a> Parser<'a> {\n     /// anything.  Signal a fatal error if next token is unexpected.\n     pub fn expect_one_of(\n         &mut self,\n-        edible: &[token::Token],\n-        inedible: &[token::Token],\n+        edible: &[token::TokenKind],\n+        inedible: &[token::TokenKind],\n     ) -> PResult<'a, bool /* recovered */> {\n         if edible.contains(&self.token) {\n             self.bump();\n@@ -640,14 +640,14 @@ impl<'a> Parser<'a> {\n     ///\n     /// This method will automatically add `tok` to `expected_tokens` if `tok` is not\n     /// encountered.\n-    crate fn check(&mut self, tok: &token::Token) -> bool {\n+    crate fn check(&mut self, tok: &token::TokenKind) -> bool {\n         let is_present = self.token == *tok;\n         if !is_present { self.expected_tokens.push(TokenType::Token(tok.clone())); }\n         is_present\n     }\n \n     /// Consumes a token 'tok' if it exists. Returns whether the given token was present.\n-    pub fn eat(&mut self, tok: &token::Token) -> bool {\n+    pub fn eat(&mut self, tok: &token::TokenKind) -> bool {\n         let is_present = self.check(tok);\n         if is_present { self.bump() }\n         is_present\n@@ -883,7 +883,7 @@ impl<'a> Parser<'a> {\n     /// `f` must consume tokens until reaching the next separator or\n     /// closing bracket.\n     pub fn parse_seq_to_end<T, F>(&mut self,\n-                                  ket: &token::Token,\n+                                  ket: &token::TokenKind,\n                                   sep: SeqSep,\n                                   f: F)\n                                   -> PResult<'a, Vec<T>> where\n@@ -901,7 +901,7 @@ impl<'a> Parser<'a> {\n     /// closing bracket.\n     pub fn parse_seq_to_before_end<T, F>(\n         &mut self,\n-        ket: &token::Token,\n+        ket: &token::TokenKind,\n         sep: SeqSep,\n         f: F,\n     ) -> PResult<'a, (Vec<T>, bool)>\n@@ -912,7 +912,7 @@ impl<'a> Parser<'a> {\n \n     crate fn parse_seq_to_before_tokens<T, F>(\n         &mut self,\n-        kets: &[&token::Token],\n+        kets: &[&token::TokenKind],\n         sep: SeqSep,\n         expect: TokenExpectType,\n         mut f: F,\n@@ -986,8 +986,8 @@ impl<'a> Parser<'a> {\n     /// closing bracket.\n     fn parse_unspanned_seq<T, F>(\n         &mut self,\n-        bra: &token::Token,\n-        ket: &token::Token,\n+        bra: &token::TokenKind,\n+        ket: &token::TokenKind,\n         sep: SeqSep,\n         f: F,\n     ) -> PResult<'a, Vec<T>> where\n@@ -1032,7 +1032,7 @@ impl<'a> Parser<'a> {\n \n     /// Advance the parser using provided token as a next one. Use this when\n     /// consuming a part of a token. For example a single `<` from `<<`.\n-    fn bump_with(&mut self, next: token::Token, span: Span) {\n+    fn bump_with(&mut self, next: token::TokenKind, span: Span) {\n         self.prev_span = self.span.with_hi(span.lo());\n         // It would be incorrect to record the kind of the current token, but\n         // fortunately for tokens currently using `bump_with`, the\n@@ -1044,7 +1044,7 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn look_ahead<R, F>(&self, dist: usize, f: F) -> R where\n-        F: FnOnce(&token::Token) -> R,\n+        F: FnOnce(&token::TokenKind) -> R,\n     {\n         if dist == 0 {\n             return f(&self.token)\n@@ -1763,7 +1763,7 @@ impl<'a> Parser<'a> {\n     fn parse_path_segment(&mut self, style: PathStyle) -> PResult<'a, PathSegment> {\n         let ident = self.parse_path_segment_ident()?;\n \n-        let is_args_start = |token: &token::Token| match *token {\n+        let is_args_start = |token: &token::TokenKind| match *token {\n             token::Lt | token::BinOp(token::Shl) | token::OpenDelim(token::Paren)\n             | token::LArrow => true,\n             _ => false,\n@@ -1992,7 +1992,7 @@ impl<'a> Parser<'a> {\n \n         let ex: ExprKind;\n \n-        // Note: when adding new syntax here, don't forget to adjust Token::can_begin_expr().\n+        // Note: when adding new syntax here, don't forget to adjust TokenKind::can_begin_expr().\n         match self.token {\n             token::OpenDelim(token::Paren) => {\n                 self.bump();\n@@ -2706,7 +2706,7 @@ impl<'a> Parser<'a> {\n                              -> PResult<'a, P<Expr>> {\n         let attrs = self.parse_or_use_outer_attributes(already_parsed_attrs)?;\n         let lo = self.span;\n-        // Note: when adding new unary operators, don't forget to adjust Token::can_begin_expr()\n+        // Note: when adding new unary operators, don't forget to adjust TokenKind::can_begin_expr()\n         let (hi, ex) = match self.token {\n             token::Not => {\n                 self.bump();\n@@ -2760,7 +2760,7 @@ impl<'a> Parser<'a> {\n                 // `not` is just an ordinary identifier in Rust-the-language,\n                 // but as `rustc`-the-compiler, we can issue clever diagnostics\n                 // for confused users who really want to say `!`\n-                let token_cannot_continue_expr = |t: &token::Token| match *t {\n+                let token_cannot_continue_expr = |t: &token::TokenKind| match *t {\n                     // These tokens can start an expression after `!`, but\n                     // can't continue an expression after an ident\n                     token::Ident(ident, is_raw) => token::ident_can_begin_expr(ident, is_raw),\n@@ -4779,7 +4779,7 @@ impl<'a> Parser<'a> {\n         let mut last_plus_span = None;\n         let mut was_negative = false;\n         loop {\n-            // This needs to be synchronized with `Token::can_begin_bound`.\n+            // This needs to be synchronized with `TokenKind::can_begin_bound`.\n             let is_bound_start = self.check_path() || self.check_lifetime() ||\n                                  self.check(&token::Not) || // used for error reporting only\n                                  self.check(&token::Question) ||\n@@ -6413,7 +6413,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Given a termination token, parses all of the items in a module.\n-    fn parse_mod_items(&mut self, term: &token::Token, inner_lo: Span) -> PResult<'a, Mod> {\n+    fn parse_mod_items(&mut self, term: &token::TokenKind, inner_lo: Span) -> PResult<'a, Mod> {\n         let mut items = vec![];\n         while let Some(item) = self.parse_item()? {\n             items.push(item);"}, {"sha": "aa1e8fd060f783ba8585a88777acaa5b25d313ab", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -2,7 +2,7 @@ pub use BinOpToken::*;\n pub use Nonterminal::*;\n pub use DelimToken::*;\n pub use LitKind::*;\n-pub use Token::*;\n+pub use TokenKind::*;\n \n use crate::ast::{self};\n use crate::parse::ParseSess;\n@@ -118,7 +118,7 @@ impl Lit {\n }\n \n pub(crate) fn ident_can_begin_expr(ident: ast::Ident, is_raw: bool) -> bool {\n-    let ident_token: Token = Ident(ident, is_raw);\n+    let ident_token: TokenKind = Ident(ident, is_raw);\n \n     !ident_token.is_reserved_ident() ||\n     ident_token.is_path_segment_keyword() ||\n@@ -149,7 +149,7 @@ pub(crate) fn ident_can_begin_expr(ident: ast::Ident, is_raw: bool) -> bool {\n }\n \n fn ident_can_begin_type(ident: ast::Ident, is_raw: bool) -> bool {\n-    let ident_token: Token = Ident(ident, is_raw);\n+    let ident_token: TokenKind = Ident(ident, is_raw);\n \n     !ident_token.is_reserved_ident() ||\n     ident_token.is_path_segment_keyword() ||\n@@ -166,7 +166,7 @@ fn ident_can_begin_type(ident: ast::Ident, is_raw: bool) -> bool {\n }\n \n #[derive(Clone, RustcEncodable, RustcDecodable, PartialEq, Debug)]\n-pub enum Token {\n+pub enum TokenKind {\n     /* Expression-operator symbols. */\n     Eq,\n     Lt,\n@@ -231,13 +231,13 @@ pub enum Token {\n     Eof,\n }\n \n-// `Token` is used a lot. Make sure it doesn't unintentionally get bigger.\n+// `TokenKind` is used a lot. Make sure it doesn't unintentionally get bigger.\n #[cfg(target_arch = \"x86_64\")]\n-static_assert_size!(Token, 16);\n+static_assert_size!(TokenKind, 16);\n \n-impl Token {\n-    /// Recovers a `Token` from an `ast::Ident`. This creates a raw identifier if necessary.\n-    pub fn from_ast_ident(ident: ast::Ident) -> Token {\n+impl TokenKind {\n+    /// Recovers a `TokenKind` from an `ast::Ident`. This creates a raw identifier if necessary.\n+    pub fn from_ast_ident(ident: ast::Ident) -> TokenKind {\n         Ident(ident, ident.is_raw_guess())\n     }\n \n@@ -323,7 +323,7 @@ impl Token {\n         self == &Question || self == &OpenDelim(Paren)\n     }\n \n-    pub fn lit(kind: LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Token {\n+    pub fn lit(kind: LitKind, symbol: Symbol, suffix: Option<Symbol>) -> TokenKind {\n         Literal(Lit::new(kind, symbol, suffix))\n     }\n \n@@ -468,7 +468,7 @@ impl Token {\n         }\n     }\n \n-    crate fn glue(self, joint: Token) -> Option<Token> {\n+    crate fn glue(self, joint: TokenKind) -> Option<TokenKind> {\n         Some(match self {\n             Eq => match joint {\n                 Eq => EqEq,\n@@ -534,7 +534,7 @@ impl Token {\n \n     /// Returns tokens that are likely to be typed accidentally instead of the current token.\n     /// Enables better error recovery when the wrong token is found.\n-    crate fn similar_tokens(&self) -> Option<Vec<Token>> {\n+    crate fn similar_tokens(&self) -> Option<Vec<TokenKind>> {\n         match *self {\n             Comma => Some(vec![Dot, Lt, Semi]),\n             Semi => Some(vec![Colon, Comma]),\n@@ -544,7 +544,7 @@ impl Token {\n \n     // See comments in `Nonterminal::to_tokenstream` for why we care about\n     // *probably* equal here rather than actual equality\n-    crate fn probably_equal_for_proc_macro(&self, other: &Token) -> bool {\n+    crate fn probably_equal_for_proc_macro(&self, other: &TokenKind) -> bool {\n         if mem::discriminant(self) != mem::discriminant(other) {\n             return false\n         }\n@@ -743,7 +743,7 @@ impl Nonterminal {\n     }\n }\n \n-crate fn is_op(tok: &Token) -> bool {\n+crate fn is_op(tok: &TokenKind) -> bool {\n     match *tok {\n         OpenDelim(..) | CloseDelim(..) | Literal(..) | DocComment(..) |\n         Ident(..) | Lifetime(..) | Interpolated(..) |"}, {"sha": "cd7106191bee27510c2ebae8b7a7a656e7d937d4", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -6,7 +6,7 @@ use crate::ast::{Attribute, MacDelimiter, GenericArg};\n use crate::util::parser::{self, AssocOp, Fixity};\n use crate::attr;\n use crate::source_map::{self, SourceMap, Spanned};\n-use crate::parse::token::{self, BinOpToken, Nonterminal, Token};\n+use crate::parse::token::{self, BinOpToken, Nonterminal, TokenKind};\n use crate::parse::lexer::comments;\n use crate::parse::{self, ParseSess};\n use crate::print::pp::{self, Breaks};\n@@ -189,7 +189,7 @@ pub fn literal_to_string(lit: token::Lit) -> String {\n     out\n }\n \n-pub fn token_to_string(tok: &Token) -> String {\n+pub fn token_to_string(tok: &TokenKind) -> String {\n     match *tok {\n         token::Eq                   => \"=\".to_string(),\n         token::Lt                   => \"<\".to_string(),"}, {"sha": "0f50f51f5d35c4adbd676c86d123b7cec95faac6", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -16,7 +16,7 @@\n use crate::ext::base;\n use crate::ext::tt::{macro_parser, quoted};\n use crate::parse::Directory;\n-use crate::parse::token::{self, DelimToken, Token};\n+use crate::parse::token::{self, DelimToken, TokenKind};\n use crate::print::pprust;\n \n use syntax_pos::{BytePos, Mark, Span, DUMMY_SP};\n@@ -44,7 +44,7 @@ use std::{fmt, iter, mem};\n #[derive(Debug, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n pub enum TokenTree {\n     /// A single token\n-    Token(Span, token::Token),\n+    Token(Span, token::TokenKind),\n     /// A delimited sequence of token trees\n     Delimited(DelimSpan, DelimToken, TokenStream),\n }\n@@ -54,7 +54,7 @@ pub enum TokenTree {\n fn _dummy()\n where\n     Span: Send + Sync,\n-    token::Token: Send + Sync,\n+    token::TokenKind: Send + Sync,\n     DelimSpan: Send + Sync,\n     DelimToken: Send + Sync,\n     TokenStream: Send + Sync,\n@@ -130,7 +130,7 @@ impl TokenTree {\n     }\n \n     /// Indicates if the stream is a token that is equal to the provided token.\n-    pub fn eq_token(&self, t: Token) -> bool {\n+    pub fn eq_token(&self, t: TokenKind) -> bool {\n         match *self {\n             TokenTree::Token(_, ref tk) => *tk == t,\n             _ => false,\n@@ -241,8 +241,8 @@ impl From<TokenTree> for TreeAndJoint {\n     }\n }\n \n-impl From<Token> for TokenStream {\n-    fn from(token: Token) -> TokenStream {\n+impl From<TokenKind> for TokenStream {\n+    fn from(token: TokenKind) -> TokenStream {\n         TokenTree::Token(DUMMY_SP, token).into()\n     }\n }\n@@ -580,7 +580,7 @@ mod tests {\n     use super::*;\n     use crate::syntax::ast::Ident;\n     use crate::with_default_globals;\n-    use crate::parse::token::Token;\n+    use crate::parse::token::TokenKind;\n     use crate::util::parser_testing::string_to_stream;\n     use syntax_pos::{Span, BytePos, NO_EXPANSION};\n "}, {"sha": "9e26f1bf7d374644586f33e6e4c276044ed0b6df", "filename": "src/libsyntax/util/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Futil%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Futil%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -1,4 +1,4 @@\n-use crate::parse::token::{self, Token, BinOpToken};\n+use crate::parse::token::{self, TokenKind, BinOpToken};\n use crate::symbol::kw;\n use crate::ast::{self, BinOpKind};\n \n@@ -69,7 +69,7 @@ pub enum Fixity {\n \n impl AssocOp {\n     /// Creates a new AssocOP from a token\n-    pub fn from_token(t: &Token) -> Option<AssocOp> {\n+    pub fn from_token(t: &TokenKind) -> Option<AssocOp> {\n         use AssocOp::*;\n         match *t {\n             token::BinOpEq(k) => Some(AssignOp(k)),"}, {"sha": "35f70092be432463e9c312aee31a4176d492d151", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -14,7 +14,7 @@\n //! those that are created by the expansion of a macro.\n \n use crate::ast::*;\n-use crate::parse::token::Token;\n+use crate::parse::token::TokenKind;\n use crate::tokenstream::{TokenTree, TokenStream};\n \n use syntax_pos::Span;\n@@ -151,7 +151,7 @@ pub trait Visitor<'ast>: Sized {\n     fn visit_tts(&mut self, tts: TokenStream) {\n         walk_tts(self, tts)\n     }\n-    fn visit_token(&mut self, _t: Token) {}\n+    fn visit_token(&mut self, _t: TokenKind) {}\n     // FIXME: add `visit_interpolated` and `walk_interpolated`\n     fn visit_vis(&mut self, vis: &'ast Visibility) {\n         walk_vis(self, vis)"}, {"sha": "29dd445e75168ef11a3d0ce7ca31d9da02e1838e", "filename": "src/libsyntax_ext/assert.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax_ext%2Fassert.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax_ext%2Fassert.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fassert.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -4,7 +4,7 @@ use syntax::ast::{self, *};\n use syntax::source_map::Spanned;\n use syntax::ext::base::*;\n use syntax::ext::build::AstBuilder;\n-use syntax::parse::token::{self, Token};\n+use syntax::parse::token::{self, TokenKind};\n use syntax::parse::parser::Parser;\n use syntax::print::pprust;\n use syntax::ptr::P;\n@@ -31,7 +31,7 @@ pub fn expand_assert<'cx>(\n         tts: custom_message.unwrap_or_else(|| {\n             TokenStream::from(TokenTree::Token(\n                 DUMMY_SP,\n-                Token::lit(token::Str, Symbol::intern(&format!(\n+                TokenKind::lit(token::Str, Symbol::intern(&format!(\n                     \"assertion failed: {}\",\n                     pprust::expr_to_string(&cond_expr).escape_debug()\n                 )), None),"}, {"sha": "119b83b7527b491f5f59e80c1c48b4610a9b2906", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99b27d749c22117eccf862f5ee4eb540b65b681f/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=99b27d749c22117eccf862f5ee4eb540b65b681f", "patch": "@@ -161,7 +161,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n                 let stream = vec![\n                     Ident(ast::Ident::new(sym::doc, span), false),\n                     Eq,\n-                    Token::lit(token::Str, Symbol::intern(&escaped), None),\n+                    TokenKind::lit(token::Str, Symbol::intern(&escaped), None),\n                 ]\n                 .into_iter()\n                 .map(|token| tokenstream::TokenTree::Token(span, token))\n@@ -220,7 +220,7 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n             }) if symbol.as_str().starts_with(\"-\") => {\n                 let minus = BinOp(BinOpToken::Minus);\n                 let symbol = Symbol::intern(&symbol.as_str()[1..]);\n-                let integer = Token::lit(token::Integer, symbol, suffix);\n+                let integer = TokenKind::lit(token::Integer, symbol, suffix);\n                 let a = tokenstream::TokenTree::Token(span, minus);\n                 let b = tokenstream::TokenTree::Token(span, integer);\n                 return vec![a, b].into_iter().collect();\n@@ -231,7 +231,7 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n             }) if symbol.as_str().starts_with(\"-\") => {\n                 let minus = BinOp(BinOpToken::Minus);\n                 let symbol = Symbol::intern(&symbol.as_str()[1..]);\n-                let float = Token::lit(token::Float, symbol, suffix);\n+                let float = TokenKind::lit(token::Float, symbol, suffix);\n                 let a = tokenstream::TokenTree::Token(span, minus);\n                 let b = tokenstream::TokenTree::Token(span, float);\n                 return vec![a, b].into_iter().collect();"}]}