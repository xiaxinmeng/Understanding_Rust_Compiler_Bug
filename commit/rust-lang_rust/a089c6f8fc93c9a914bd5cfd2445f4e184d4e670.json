{"sha": "a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "node_id": "MDY6Q29tbWl0NzI0NzEyOmEwODljNmY4ZmM5M2M5YTkxNGJkNWNmZDI0NDVmNGUxODRkNGU2NzA=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-04-18T02:48:59Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-04-18T02:48:59Z"}, "message": "auto merge of #5908 : jbclements/rust/add-hygiene-machinery, r=graydon\n\nThis pull request changes the representation of identifiers by adding an integer to the side of each one.  This integer will eventually be a reference to a side-table of syntax contexts, presumably stored in TLS. This pull request also adds a bunch of utility functions required for hygiene, and associated tests, but doesn't actually deploy those functions.\r\n\r\nFinally, it also has a number of small cleanup items.", "tree": {"sha": "0a47b1968bc518236a699ac007da129d9a468be4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0a47b1968bc518236a699ac007da129d9a468be4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "html_url": "https://github.com/rust-lang/rust/commit/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fdb4ef321ed5eee681c2b723dcb157c280aa72f2", "url": "https://api.github.com/repos/rust-lang/rust/commits/fdb4ef321ed5eee681c2b723dcb157c280aa72f2", "html_url": "https://github.com/rust-lang/rust/commit/fdb4ef321ed5eee681c2b723dcb157c280aa72f2"}, {"sha": "e7aa24de18bb1be6764c90bc08fecb322aeb7154", "url": "https://api.github.com/repos/rust-lang/rust/commits/e7aa24de18bb1be6764c90bc08fecb322aeb7154", "html_url": "https://github.com/rust-lang/rust/commit/e7aa24de18bb1be6764c90bc08fecb322aeb7154"}], "stats": {"total": 655, "additions": 541, "deletions": 114}, "files": [{"sha": "6f4693adb9f4a0e8db560ca627234dc38ef299f1", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 99, "deletions": 33, "changes": 132, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -22,45 +22,53 @@ use core::to_str::ToStr;\n use std::serialize::{Encodable, Decodable, Encoder, Decoder};\n \n \n-/* can't import macros yet, so this is copied from token.rs. See its comment\n- * there. */\n-macro_rules! interner_key (\n-    () => (cast::transmute::<(uint, uint),\n-            &fn(+v: @@::parse::token::ident_interner)>(\n-        (-3 as uint, 0u)))\n-)\n-\n // an identifier contains an index into the interner\n // table and a SyntaxContext to track renaming and\n // macro expansion per Flatt et al., \"Macros\n // That Work Together\"\n #[deriving(Eq)]\n-pub struct ident { repr: Name }\n+pub struct ident { repr: Name, ctxt: SyntaxContext }\n \n // a SyntaxContext represents a chain of macro-expandings\n // and renamings. Each macro expansion corresponds to\n // a fresh uint\n+\n+// I'm representing this syntax context as an index into\n+// a table, in order to work around a compiler bug\n+// that's causing unreleased memory to cause core dumps\n+// and also perhaps to save some work in destructor checks.\n+// the special uint '0' will be used to indicate an empty\n+// syntax context\n+\n+// this uint is a reference to a table stored in thread-local\n+// storage.\n+pub type SyntaxContext = uint;\n+\n+pub type SCTable = ~[SyntaxContext_];\n+pub static empty_ctxt : uint = 0;\n+\n #[deriving(Eq)]\n-pub enum SyntaxContext {\n-    MT,\n-    Mark (Mrk,~SyntaxContext),\n-    Rename (~ident,Name,~SyntaxContext)\n+#[auto_encode]\n+#[auto_decode]\n+pub enum SyntaxContext_ {\n+    EmptyCtxt,\n+    Mark (Mrk,SyntaxContext),\n+    // flattening the name and syntaxcontext into the rename...\n+    // HIDDEN INVARIANTS:\n+    // 1) the first name in a Rename node\n+    // can only be a programmer-supplied name.\n+    // 2) Every Rename node with a given Name in the\n+    // \"to\" slot must have the same name and context\n+    // in the \"from\" slot. In essence, they're all\n+    // pointers to a single \"rename\" event node.\n+    Rename (ident,Name,SyntaxContext)\n }\n \n-/*\n-// ** this is going to have to apply to paths, not to idents.\n-// Returns true if these two identifiers access the same\n-// local binding or top-level binding... that's what it\n-// should do. For now, it just compares the names.\n-pub fn free_ident_eq (a : ident, b: ident) -> bool{\n-    a.repr == b.repr\n-}\n-*/\n-// a name represents a string, interned\n-type Name = uint;\n+// a name represents an identifier\n+pub type Name = uint;\n // a mark represents a unique id associated\n // with a macro expansion\n-type Mrk = uint;\n+pub type Mrk = uint;\n \n impl<S:Encoder> Encodable<S> for ident {\n     fn encode(&self, s: &S) {\n@@ -1310,22 +1318,77 @@ pub enum inlined_item {\n     ii_dtor(struct_dtor, ident, Generics, def_id /* parent id */)\n }\n \n+/* hold off on tests ... they appear in a later merge.\n #[cfg(test)]\n mod test {\n-    //are asts encodable?\n-\n-    // it looks like this *will* be a compiler bug, after\n-    // I get deriving_eq for crates into incoming :)\n-    /*\n+    use core::option::{None, Option, Some};\n+    use core::uint;\n     use std;\n     use codemap::*;\n     use super::*;\n \n+\n+    #[test] fn xorpush_test () {\n+        let mut s = ~[];\n+        xorPush(&mut s,14);\n+        assert_eq!(s,~[14]);\n+        xorPush(&mut s,14);\n+        assert_eq!(s,~[]);\n+        xorPush(&mut s,14);\n+        assert_eq!(s,~[14]);\n+        xorPush(&mut s,15);\n+        assert_eq!(s,~[14,15]);\n+        xorPush (&mut s,16);\n+        assert_eq! (s,~[14,15,16]);\n+        xorPush (&mut s,16);\n+        assert_eq! (s,~[14,15]);\n+        xorPush (&mut s,15);\n+        assert_eq! (s,~[14]);\n+    }\n+\n+    #[test] fn test_marksof () {\n+        let stopname = uints_to_name(&~[12,14,78]);\n+        let name1 = uints_to_name(&~[4,9,7]);\n+        assert_eq!(marksof (MT,stopname),~[]);\n+        assert_eq! (marksof (Mark (4,@Mark(98,@MT)),stopname),~[4,98]);\n+        // does xoring work?\n+        assert_eq! (marksof (Mark (5, @Mark (5, @Mark (16,@MT))),stopname),\n+                     ~[16]);\n+        // does nested xoring work?\n+        assert_eq! (marksof (Mark (5,\n+                                    @Mark (10,\n+                                           @Mark (10,\n+                                                  @Mark (5,\n+                                                         @Mark (16,@MT))))),\n+                              stopname),\n+                     ~[16]);\n+        // stop has no effect on marks\n+        assert_eq! (marksof (Mark (9, @Mark (14, @Mark (12, @MT))),stopname),\n+                     ~[9,14,12]);\n+        // rename where stop doesn't match:\n+        assert_eq! (marksof (Mark (9, @Rename\n+                                    (name1,\n+                                     @Mark (4, @MT),\n+                                     uints_to_name(&~[100,101,102]),\n+                                     @Mark (14, @MT))),\n+                              stopname),\n+                     ~[9,14]);\n+        // rename where stop does match\n+        ;\n+        assert_eq! (marksof (Mark(9, @Rename (name1,\n+                                               @Mark (4, @MT),\n+                                               stopname,\n+                                               @Mark (14, @MT))),\n+                              stopname),\n+                     ~[9]);\n+    }\n+\n+    // are ASTs encodable?\n     #[test] fn check_asts_encodable() {\n         let bogus_span = span {lo:BytePos(10),\n                                hi:BytePos(20),\n                                expn_info:None};\n-        let _e : crate =\n+        let e : crate =\n             spanned{\n             node: crate_{\n                 module: _mod {view_items: ~[], items: ~[]},\n@@ -1334,10 +1397,13 @@ mod test {\n             },\n             span: bogus_span};\n         // doesn't matter which encoder we use....\n-        let _f = (_e as std::serialize::Encodable::<std::json::Encoder>);\n+        let _f = (@e as @std::serialize::Encodable<std::json::Encoder>);\n     }\n-    */\n+\n+\n }\n+\n+*/\n //\n // Local Variables:\n // mode: rust"}, {"sha": "59a640bb571634c88faa529dbf6b779eb97b94ca", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 275, "deletions": 0, "changes": 275, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -24,6 +24,7 @@ use core::str;\n use core::to_bytes;\n use core::vec;\n \n+\n pub fn path_name_i(idents: &[ident], intr: @token::ident_interner) -> ~str {\n     // FIXME: Bad copies (#2543 -- same for everything else that says \"bad\")\n     str::connect(idents.map(|i| copy *intr.get(*i)), ~\"::\")\n@@ -587,6 +588,280 @@ pub enum Privacy {\n     Public\n }\n \n+// HYGIENE FUNCTIONS\n+\n+/// Construct an identifier with the given repr and an empty context:\n+pub fn mk_ident(repr: uint) -> ident { ident {repr: repr, ctxt: 0}}\n+\n+/// Extend a syntax context with a given mark\n+pub fn mk_mark (m:Mrk,ctxt:SyntaxContext,table:&mut SCTable)\n+    -> SyntaxContext {\n+    idx_push(table,Mark(m,ctxt))\n+}\n+\n+/// Extend a syntax context with a given rename\n+pub fn mk_rename (id:ident, to:Name, tail:SyntaxContext, table: &mut SCTable)\n+    -> SyntaxContext {\n+    idx_push(table,Rename(id,to,tail))\n+}\n+\n+/// Make a fresh syntax context table with EmptyCtxt in slot zero\n+pub fn mk_sctable() -> SCTable { ~[EmptyCtxt] }\n+\n+/// Add a value to the end of a vec, return its index\n+fn idx_push<T>(vec: &mut ~[T], +val: T) -> uint {\n+    vec.push(val);\n+    vec.len() - 1\n+}\n+\n+/// Resolve a syntax object to a name, per MTWT.\n+pub fn resolve (id : ident, table : &SCTable) -> Name {\n+    match table[id.ctxt] {\n+        EmptyCtxt => id.repr,\n+        // ignore marks here:\n+        Mark(_,subctxt) => resolve (ident{repr:id.repr, ctxt: subctxt},table),\n+        // do the rename if necessary:\n+        Rename(ident{repr,ctxt},toname,subctxt) => {\n+            // this could be cached or computed eagerly:\n+            let resolvedfrom = resolve(ident{repr:repr,ctxt:ctxt},table);\n+            let resolvedthis = resolve(ident{repr:id.repr,ctxt:subctxt},table);\n+            if ((resolvedthis == resolvedfrom)\n+                && (marksof (ctxt,resolvedthis,table)\n+                    == marksof (subctxt,resolvedthis,table))) {\n+                toname\n+            } else {\n+                resolvedthis\n+            }\n+        }\n+    }\n+}\n+\n+/// Compute the marks associated with a syntax context.\n+// it's not clear to me whether it's better to use a [] mutable\n+// vector or a cons-list for this.\n+pub fn marksof(ctxt: SyntaxContext, stopname: Name, table: &SCTable) -> ~[Mrk] {\n+    let mut result = ~[];\n+    let mut loopvar = ctxt;\n+    loop {\n+        match table[loopvar] {\n+            EmptyCtxt => {return result;},\n+            Mark(mark,tl) => {\n+                xorPush(&mut result,mark);\n+                loopvar = tl;\n+            },\n+            Rename(_,name,tl) => {\n+                // see MTWT for details on the purpose of the stopname.\n+                // short version: it prevents duplication of effort.\n+                if (name == stopname) {\n+                    return result;\n+                } else {\n+                    loopvar = tl;\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Push a name... unless it matches the one on top, in which\n+/// case pop and discard (so two of the same marks cancel)\n+pub fn xorPush(marks: &mut ~[uint], mark: uint) {\n+    if ((marks.len() > 0) && (getLast(marks) == mark)) {\n+        marks.pop();\n+    } else {\n+        marks.push(mark);\n+    }\n+}\n+\n+// get the last element of a mutable array.\n+// FIXME #4903: , must be a separate procedure for now.\n+pub fn getLast(arr: &~[Mrk]) -> uint {\n+    *arr.last()\n+}\n+\n+\n+#[cfg(test)]\n+mod test {\n+    use ast::*;\n+    use super::*;\n+    use core::io;\n+\n+    #[test] fn xorpush_test () {\n+        let mut s = ~[];\n+        xorPush(&mut s,14);\n+        assert_eq!(s,~[14]);\n+        xorPush(&mut s,14);\n+        assert_eq!(s,~[]);\n+        xorPush(&mut s,14);\n+        assert_eq!(s,~[14]);\n+        xorPush(&mut s,15);\n+        assert_eq!(s,~[14,15]);\n+        xorPush (&mut s,16);\n+        assert_eq! (s,~[14,15,16]);\n+        xorPush (&mut s,16);\n+        assert_eq! (s,~[14,15]);\n+        xorPush (&mut s,15);\n+        assert_eq! (s,~[14]);\n+    }\n+\n+    // convert a list of uints to an @~[ident]\n+    // (ignores the interner completely)\n+    fn uints_to_idents (uints: &~[uint]) -> @~[ident] {\n+        @uints.map(|u|{ ident {repr:*u, ctxt: empty_ctxt} })\n+    }\n+\n+    fn id (u : uint, s: SyntaxContext) -> ident {\n+        ident{repr:u, ctxt: s}\n+    }\n+\n+    // because of the SCTable, I now need a tidy way of\n+    // creating syntax objects. Sigh.\n+    #[deriving(Eq)]\n+    enum TestSC {\n+        M(Mrk),\n+        R(ident,Name)\n+    }\n+\n+    // unfold a vector of TestSC values into a SCTable,\n+    // returning the resulting index\n+    fn unfold_test_sc(tscs : ~[TestSC], tail: SyntaxContext, table : &mut SCTable)\n+        -> SyntaxContext {\n+        tscs.foldr(tail, |tsc : &TestSC,tail : SyntaxContext|\n+                  {match *tsc {\n+                      M(mrk) => mk_mark(mrk,tail,table),\n+                      R(ident,name) => mk_rename(ident,name,tail,table)}})\n+    }\n+\n+    // gather a SyntaxContext back into a vector of TestSCs\n+    fn refold_test_sc(mut sc: SyntaxContext, table : &SCTable) -> ~[TestSC] {\n+        let mut result = ~[];\n+        loop {\n+            match table[sc] {\n+                EmptyCtxt => {return result;},\n+                Mark(mrk,tail) => {\n+                    result.push(M(mrk));\n+                    sc = tail;\n+                    loop;\n+                },\n+                Rename(id,name,tail) => {\n+                    result.push(R(id,name));\n+                    sc = tail;\n+                    loop;\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test] fn test_unfold_refold(){\n+        let mut t = mk_sctable();\n+\n+        let test_sc = ~[M(3),R(id(101,0),14),M(9)];\n+        assert_eq!(unfold_test_sc(test_sc,empty_ctxt,&mut t),3);\n+        assert_eq!(t[1],Mark(9,0));\n+        assert_eq!(t[2],Rename(id(101,0),14,1));\n+        assert_eq!(t[3],Mark(3,2));\n+        assert_eq!(refold_test_sc(3,&t),test_sc);\n+    }\n+\n+\n+    // extend a syntax context with a sequence of marks given\n+    // in a vector. v[0] will be the outermost mark.\n+    fn unfold_marks(mrks:~[Mrk],tail:SyntaxContext,table: &mut SCTable) -> SyntaxContext {\n+        mrks.foldr(tail, |mrk:&Mrk,tail:SyntaxContext|\n+                   {mk_mark(*mrk,tail,table)})\n+    }\n+\n+    #[test] fn unfold_marks_test() {\n+        let mut t = ~[EmptyCtxt];\n+\n+        assert_eq!(unfold_marks(~[3,7],empty_ctxt,&mut t),2);\n+        assert_eq!(t[1],Mark(7,0));\n+        assert_eq!(t[2],Mark(3,1));\n+    }\n+\n+    #[test] fn test_marksof () {\n+        let stopname = 242;\n+        let name1 = 243;\n+        let mut t = mk_sctable();\n+        assert_eq!(marksof (empty_ctxt,stopname,&t),~[]);\n+        // FIXME #5074: ANF'd to dodge nested calls\n+        { let ans = unfold_marks(~[4,98],empty_ctxt,&mut t);\n+         assert_eq! (marksof (ans,stopname,&t),~[4,98]);}\n+        // does xoring work?\n+        { let ans = unfold_marks(~[5,5,16],empty_ctxt,&mut t);\n+         assert_eq! (marksof (ans,stopname,&t), ~[16]);}\n+        // does nested xoring work?\n+        { let ans = unfold_marks(~[5,10,10,5,16],empty_ctxt,&mut t);\n+         assert_eq! (marksof (ans, stopname,&t), ~[16]);}\n+        // rename where stop doesn't match:\n+        { let chain = ~[M(9),\n+                        R(id(name1,\n+                             mk_mark (4, empty_ctxt,&mut t)),\n+                          100101102),\n+                        M(14)];\n+         let ans = unfold_test_sc(chain,empty_ctxt,&mut t);\n+         assert_eq! (marksof (ans, stopname, &t), ~[9,14]);}\n+        // rename where stop does match\n+        { let name1sc = mk_mark(4, empty_ctxt, &mut t);\n+         let chain = ~[M(9),\n+                       R(id(name1, name1sc),\n+                         stopname),\n+                       M(14)];\n+         let ans = unfold_test_sc(chain,empty_ctxt,&mut t);\n+         assert_eq! (marksof (ans, stopname, &t), ~[9]); }\n+    }\n+\n+\n+    #[test] fn resolve_tests () {\n+        let a = 40;\n+        let mut t = mk_sctable();\n+        // - ctxt is MT\n+        assert_eq!(resolve(id(a,empty_ctxt),&t),a);\n+        // - simple ignored marks\n+        { let sc = unfold_marks(~[1,2,3],empty_ctxt,&mut t);\n+         assert_eq!(resolve(id(a,sc),&t),a);}\n+        // - orthogonal rename where names don't match\n+        { let sc = unfold_test_sc(~[R(id(50,empty_ctxt),51),M(12)],empty_ctxt,&mut t);\n+         assert_eq!(resolve(id(a,sc),&t),a);}\n+        // - rename where names do match, but marks don't\n+        { let sc1 = mk_mark(1,empty_ctxt,&mut t);\n+         let sc = unfold_test_sc(~[R(id(a,sc1),50),\n+                                   M(1),\n+                                   M(2)],\n+                                 empty_ctxt,&mut t);\n+        assert_eq!(resolve(id(a,sc),&t), a);}\n+        // - rename where names and marks match\n+        { let sc1 = unfold_test_sc(~[M(1),M(2)],empty_ctxt,&mut t);\n+         let sc = unfold_test_sc(~[R(id(a,sc1),50),M(1),M(2)],empty_ctxt,&mut t);\n+         assert_eq!(resolve(id(a,sc),&t), 50); }\n+        // - rename where names and marks match by literal sharing\n+        { let sc1 = unfold_test_sc(~[M(1),M(2)],empty_ctxt,&mut t);\n+         let sc = unfold_test_sc(~[R(id(a,sc1),50)],sc1,&mut t);\n+         assert_eq!(resolve(id(a,sc),&t), 50); }\n+        // - two renames of the same var.. can only happen if you use\n+        // local-expand to prevent the inner binding from being renamed\n+        // during the rename-pass caused by the first:\n+        io::println(\"about to run bad test\");\n+        { let sc = unfold_test_sc(~[R(id(a,empty_ctxt),50),\n+                                    R(id(a,empty_ctxt),51)],\n+                                  empty_ctxt,&mut t);\n+         assert_eq!(resolve(id(a,sc),&t), 51); }\n+        // the simplest double-rename:\n+        { let a_to_a50 = mk_rename(id(a,empty_ctxt),50,empty_ctxt,&mut t);\n+         let a50_to_a51 = mk_rename(id(a,a_to_a50),51,a_to_a50,&mut t);\n+         assert_eq!(resolve(id(a,a50_to_a51),&t),51);\n+         // mark on the outside doesn't stop rename:\n+         let sc = mk_mark(9,a50_to_a51,&mut t);\n+         assert_eq!(resolve(id(a,sc),&t),51);\n+         // but mark on the inside does:\n+         let a50_to_a51_b = unfold_test_sc(~[R(id(a,a_to_a50),51),\n+                                              M(9)],\n+                                           a_to_a50,\n+                                           &mut t);\n+         assert_eq!(resolve(id(a,a50_to_a51_b),&t),50);}\n+    }\n+\n+}\n+\n // Local Variables:\n // mode: rust\n // fill-column: 78;"}, {"sha": "430402a8982fc733b36c2ff7cd49dc0033d7616d", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 47, "deletions": 0, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -547,6 +547,53 @@ pub fn expand_crate(parse_sess: @mut parse::ParseSess,\n     @f.fold_crate(&*c)\n }\n \n+// given a function from paths to paths, produce\n+// an ast_fold that applies that function:\n+fn fun_to_path_folder(f: @fn(&ast::Path)->ast::Path) -> @ast_fold{\n+    let afp = default_ast_fold();\n+    let f_pre = @AstFoldFns{\n+        fold_path : |p, _| f(p),\n+        .. *afp\n+    };\n+    make_fold(f_pre)\n+}\n+/* going to have to figure out whether the table is passed in or\n+extracted from TLS...\n+// update the ctxts in a path to get a rename node\n+fn ctxt_update_rename(from: ast::Name,\n+                       fromctx: ast::SyntaxContext, to: ast::Name) ->\n+    @fn(&ast::Path,@ast_fold)->ast::Path {\n+    return |p:&ast::Path,_|\n+    ast::Path {span: p.span,\n+               global: p.global,\n+               idents: p.idents.map(|id|\n+                                    ast::ident{\n+                                        repr: id.repr,\n+                                        // this needs to be cached....\n+                                        ctxt: Some(@ast::Rename(from,fromctx,\n+                                                           to,id.ctxt))\n+                                    }),\n+               rp: p.rp,\n+               types: p.types};\n+}\n+\n+// update the ctxts in a path to get a mark node\n+fn ctxt_update_mark(mark: uint) ->\n+    @fn(&ast::Path,@ast_fold)->ast::Path {\n+    return |p:&ast::Path,_|\n+    ast::Path {span: p.span,\n+               global: p.global,\n+               idents: p.idents.map(|id|\n+                                    ast::ident{\n+                                        repr: id.repr,\n+                                        // this needs to be cached....\n+                                        ctxt: Some(@ast::Mark(mark,id.ctxt))\n+                                    }),\n+               rp: p.rp,\n+               types: p.types};\n+}\n+*/\n+\n #[cfg(test)]\n mod test {\n     use super::*;"}, {"sha": "f353d94894a43046d9c3df686c38c0fd13a67ffb", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 27, "deletions": 8, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -47,17 +47,29 @@ pub fn seq_sep_none() -> SeqSep {\n     }\n }\n \n+// maps any token back to a string. not necessary if you know it's\n+// an identifier....\n pub fn token_to_str(reader: @reader, token: &token::Token) -> ~str {\n     token::to_str(reader.interner(), token)\n }\n \n pub impl Parser {\n+    // convert a token to a string using self's reader\n+    fn token_to_str(&self, token: &token::Token) -> ~str {\n+        token::to_str(self.reader.interner(), token)\n+    }\n+\n+    // convert the current token to a string using self's reader\n+    fn this_token_to_str(&self) -> ~str {\n+        self.token_to_str(self.token)\n+    }\n+\n     fn unexpected_last(&self, t: &token::Token) -> ! {\n         self.span_fatal(\n             *self.last_span,\n             fmt!(\n                 \"unexpected token: `%s`\",\n-                token_to_str(self.reader, t)\n+                self.token_to_str(t)\n             )\n         );\n     }\n@@ -66,7 +78,7 @@ pub impl Parser {\n         self.fatal(\n             fmt!(\n                 \"unexpected token: `%s`\",\n-                token_to_str(self.reader, &copy *self.token)\n+                self.this_token_to_str()\n             )\n         );\n     }\n@@ -80,8 +92,8 @@ pub impl Parser {\n             self.fatal(\n                 fmt!(\n                     \"expected `%s` but found `%s`\",\n-                    token_to_str(self.reader, t),\n-                    token_to_str(self.reader, &copy *self.token)\n+                    self.token_to_str(t),\n+                    self.this_token_to_str()\n                 )\n             )\n         }\n@@ -104,7 +116,7 @@ pub impl Parser {\n                 self.fatal(\n                     fmt!(\n                         \"expected ident, found `%s`\",\n-                        token_to_str(self.reader, &copy *self.token)\n+                        self.this_token_to_str()\n                     )\n                 );\n             }\n@@ -128,12 +140,15 @@ pub impl Parser {\n     // Storing keywords as interned idents instead of strings would be nifty.\n \n     // A sanity check that the word we are asking for is a known keyword\n+    // NOTE: this could be done statically....\n     fn require_keyword(&self, word: &~str) {\n         if !self.keywords.contains(word) {\n             self.bug(fmt!(\"unknown keyword: %s\", *word));\n         }\n     }\n \n+    // return true when this token represents the given string, and is not\n+    // followed immediately by :: .\n     fn token_is_word(&self, word: &~str, tok: &token::Token) -> bool {\n         match *tok {\n             token::IDENT(sid, false) => { *self.id_to_str(sid) == *word }\n@@ -150,6 +165,10 @@ pub impl Parser {\n         self.token_is_keyword(word, &copy *self.token)\n     }\n \n+    fn id_is_any_keyword(&self, id: ast::ident) -> bool {\n+        self.keywords.contains(self.id_to_str(id))\n+    }\n+\n     fn is_any_keyword(&self, tok: &token::Token) -> bool {\n         match *tok {\n           token::IDENT(sid, false) => {\n@@ -182,7 +201,7 @@ pub impl Parser {\n                 fmt!(\n                     \"expected `%s`, found `%s`\",\n                     *word,\n-                    token_to_str(self.reader, &copy *self.token)\n+                    self.this_token_to_str()\n                 )\n             );\n         }\n@@ -248,9 +267,9 @@ pub impl Parser {\n             );\n         } else {\n             let mut s: ~str = ~\"expected `\";\n-            s += token_to_str(self.reader, &token::GT);\n+            s += self.token_to_str(&token::GT);\n             s += ~\"`, found `\";\n-            s += token_to_str(self.reader, &copy *self.token);\n+            s += self.this_token_to_str();\n             s += ~\"`\";\n             self.fatal(s);\n         }"}, {"sha": "c1f781f8570e01347167be0e87946bf64d9909d3", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 31, "deletions": 19, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -66,7 +66,7 @@ use codemap::{span, BytePos, spanned, mk_sp};\n use codemap;\n use parse::attr::parser_attr;\n use parse::classify;\n-use parse::common::{seq_sep_none, token_to_str};\n+use parse::common::{seq_sep_none};\n use parse::common::{seq_sep_trailing_disallowed, seq_sep_trailing_allowed};\n use parse::lexer::reader;\n use parse::lexer::TokenAndSpan;\n@@ -252,8 +252,11 @@ pub fn Parser(sess: @mut ParseSess,\n pub struct Parser {\n     sess: @mut ParseSess,\n     cfg: crate_cfg,\n+    // the current token:\n     token: @mut token::Token,\n+    // the span of the current token:\n     span: @mut span,\n+    // the span of the prior token:\n     last_span: @mut span,\n     buffer: @mut [TokenAndSpan, ..4],\n     buffer_start: @mut int,\n@@ -499,7 +502,7 @@ pub impl Parser {\n             let hi = p.last_span.hi;\n             debug!(\"parse_trait_methods(): trait method signature ends in \\\n                     `%s`\",\n-                   token_to_str(p.reader, &copy *p.token));\n+                   self.this_token_to_str());\n             match *p.token {\n               token::SEMI => {\n                 p.bump();\n@@ -541,7 +544,7 @@ pub impl Parser {\n                     p.fatal(\n                         fmt!(\n                             \"expected `;` or `}` but found `%s`\",\n-                            token_to_str(p.reader, &copy *p.token)\n+                            self.this_token_to_str()\n                         )\n                     );\n                 }\n@@ -698,7 +701,8 @@ pub impl Parser {\n             let path = self.parse_path_with_tps(false);\n             ty_path(path, self.get_id())\n         } else {\n-            self.fatal(~\"expected type\");\n+            self.fatal(fmt!(\"expected type, found token %?\",\n+                            *self.token));\n         };\n \n         let sp = mk_sp(lo, self.last_span.hi);\n@@ -1455,6 +1459,11 @@ pub impl Parser {\n     fn parse_token_tree(&self) -> token_tree {\n         maybe_whole!(deref self, nt_tt);\n \n+        // this is the fall-through for the 'match' below.\n+        // invariants: the current token is not a left-delimiter,\n+        // not an EOF, and not the desired right-delimiter (if\n+        // it were, parse_seq_to_before_end would have prevented\n+        // reaching this point.\n         fn parse_non_delim_tt_tok(p: &Parser) -> token_tree {\n             maybe_whole!(deref p, nt_tt);\n             match *p.token {\n@@ -1463,7 +1472,7 @@ pub impl Parser {\n                 p.fatal(\n                     fmt!(\n                         \"incorrect close delimiter: `%s`\",\n-                        token_to_str(p.reader, &copy *p.token)\n+                        p.this_token_to_str()\n                     )\n                 );\n               }\n@@ -1505,18 +1514,17 @@ pub impl Parser {\n \n         match *self.token {\n             token::EOF => {\n-                self.fatal(~\"file ended in the middle of a macro invocation\");\n+                self.fatal(~\"file ended with unbalanced delimiters\");\n             }\n             token::LPAREN | token::LBRACE | token::LBRACKET => {\n-                // tjc: ??????\n-                let ket = token::flip_delimiter(&*self.token);\n+                let close_delim = token::flip_delimiter(&*self.token);\n                 tt_delim(\n                     vec::append(\n                         // the open delimiter:\n                         ~[parse_any_tt_tok(self)],\n                         vec::append(\n                             self.parse_seq_to_before_end(\n-                                &ket,\n+                                &close_delim,\n                                 seq_sep_none(),\n                                 |p| p.parse_token_tree()\n                             ),\n@@ -1530,6 +1538,8 @@ pub impl Parser {\n         }\n     }\n \n+    // parse a stream of tokens into a list of token_trees,\n+    // up to EOF.\n     fn parse_all_token_trees(&self) -> ~[token_tree] {\n         let mut tts = ~[];\n         while *self.token != token::EOF {\n@@ -2052,6 +2062,7 @@ pub impl Parser {\n         return e;\n     }\n \n+    // parse the RHS of a local variable declaration (e.g. '= 14;')\n     fn parse_initializer(&self) -> Option<@expr> {\n         match *self.token {\n           token::EQ => {\n@@ -2138,7 +2149,7 @@ pub impl Parser {\n                     self.fatal(\n                         fmt!(\n                             \"expected `}`, found `%s`\",\n-                            token_to_str(self.reader, &copy *self.token)\n+                            self.this_token_to_str()\n                         )\n                     );\n                 }\n@@ -2406,6 +2417,7 @@ pub impl Parser {\n         pat_ident(binding_mode, name, sub)\n     }\n \n+    // parse a local variable declaration\n     fn parse_local(&self, is_mutbl: bool,\n                    allow_init: bool) -> @local {\n         let lo = self.span.lo;\n@@ -2651,7 +2663,7 @@ pub impl Parser {\n                                             fmt!(\n                                                 \"expected `;` or `}` after \\\n                                                 expression but found `%s`\",\n-                                                token_to_str(self.reader, &t)\n+                                                self.token_to_str(&t)\n                                             )\n                                         );\n                                     }\n@@ -2866,7 +2878,7 @@ pub impl Parser {\n             self.fatal(\n                 fmt!(\n                     \"expected `self` but found `%s`\",\n-                    token_to_str(self.reader, &copy *self.token)\n+                    self.this_token_to_str()\n                 )\n             );\n         }\n@@ -2990,7 +3002,7 @@ pub impl Parser {\n                     self.fatal(\n                         fmt!(\n                             \"expected `,` or `)`, found `%s`\",\n-                            token_to_str(self.reader, &copy *self.token)\n+                            self.this_token_to_str()\n                         )\n                     );\n                 }\n@@ -3270,7 +3282,7 @@ pub impl Parser {\n                 fmt!(\n                     \"expected `{`, `(`, or `;` after struct name \\\n                     but found `%s`\",\n-                    token_to_str(self.reader, &copy *self.token)\n+                    self.this_token_to_str()\n                 )\n             );\n         }\n@@ -3320,7 +3332,7 @@ pub impl Parser {\n                     copy *self.span,\n                     fmt!(\n                         \"expected `;`, `,`, or '}' but found `%s`\",\n-                        token_to_str(self.reader, &copy *self.token)\n+                        self.this_token_to_str()\n                     )\n                 );\n             }\n@@ -3422,7 +3434,7 @@ pub impl Parser {\n                 self.fatal(\n                     fmt!(\n                         \"expected item but found `%s`\",\n-                        token_to_str(self.reader, &copy *self.token)\n+                        self.this_token_to_str()\n                     )\n                 );\n               }\n@@ -3682,7 +3694,7 @@ pub impl Parser {\n                 copy *self.span,\n                 fmt!(\n                     \"expected `{` or `mod` but found `%s`\",\n-                    token_to_str(self.reader, &copy *self.token)\n+                    self.this_token_to_str()\n                 )\n             );\n         }\n@@ -3695,7 +3707,7 @@ pub impl Parser {\n                         copy *self.span,\n                         fmt!(\n                             \"expected foreign module name but found `%s`\",\n-                            token_to_str(self.reader, &copy *self.token)\n+                            self.this_token_to_str()\n                         )\n                     );\n                 }\n@@ -4279,7 +4291,7 @@ pub impl Parser {\n                                             rp: None,\n                                             types: ~[] };\n                     return @spanned(lo, self.span.hi,\n-                                 view_path_glob(path, self.get_id()));\n+                                    view_path_glob(path, self.get_id()));\n                   }\n \n                   _ => break"}, {"sha": "cf05a4375a8a5fb0ddc56d8ace08d8002feb65f5", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 40, "deletions": 50, "changes": 90, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -309,50 +309,50 @@ pub fn is_bar(t: &Token) -> bool {\n pub mod special_idents {\n     use ast::ident;\n \n-    pub static underscore : ident = ident { repr: 0u };\n-    pub static anon : ident = ident { repr: 1u };\n-    pub static dtor : ident = ident { repr: 2u }; // 'drop', but that's\n+    pub static underscore : ident = ident { repr: 0u, ctxt: 0};\n+    pub static anon : ident = ident { repr: 1u, ctxt: 0};\n+    pub static dtor : ident = ident { repr: 2u, ctxt: 0}; // 'drop', but that's\n                                                  // reserved\n-    pub static invalid : ident = ident { repr: 3u }; // ''\n-    pub static unary : ident = ident { repr: 4u };\n-    pub static not_fn : ident = ident { repr: 5u };\n-    pub static idx_fn : ident = ident { repr: 6u };\n-    pub static unary_minus_fn : ident = ident { repr: 7u };\n-    pub static clownshoes_extensions : ident = ident { repr: 8u };\n+    pub static invalid : ident = ident { repr: 3u, ctxt: 0}; // ''\n+    pub static unary : ident = ident { repr: 4u, ctxt: 0};\n+    pub static not_fn : ident = ident { repr: 5u, ctxt: 0};\n+    pub static idx_fn : ident = ident { repr: 6u, ctxt: 0};\n+    pub static unary_minus_fn : ident = ident { repr: 7u, ctxt: 0};\n+    pub static clownshoes_extensions : ident = ident { repr: 8u, ctxt: 0};\n \n-    pub static self_ : ident = ident { repr: 9u }; // 'self'\n+    pub static self_ : ident = ident { repr: 9u, ctxt: 0}; // 'self'\n \n     /* for matcher NTs */\n-    pub static item : ident = ident { repr: 10u };\n-    pub static block : ident = ident { repr: 11u };\n-    pub static stmt : ident = ident { repr: 12u };\n-    pub static pat : ident = ident { repr: 13u };\n-    pub static expr : ident = ident { repr: 14u };\n-    pub static ty : ident = ident { repr: 15u };\n-    pub static ident : ident = ident { repr: 16u };\n-    pub static path : ident = ident { repr: 17u };\n-    pub static tt : ident = ident { repr: 18u };\n-    pub static matchers : ident = ident { repr: 19u };\n-\n-    pub static str : ident = ident { repr: 20u }; // for the type\n+    pub static item : ident = ident { repr: 10u, ctxt: 0};\n+    pub static block : ident = ident { repr: 11u, ctxt: 0};\n+    pub static stmt : ident = ident { repr: 12u, ctxt: 0};\n+    pub static pat : ident = ident { repr: 13u, ctxt: 0};\n+    pub static expr : ident = ident { repr: 14u, ctxt: 0};\n+    pub static ty : ident = ident { repr: 15u, ctxt: 0};\n+    pub static ident : ident = ident { repr: 16u, ctxt: 0};\n+    pub static path : ident = ident { repr: 17u, ctxt: 0};\n+    pub static tt : ident = ident { repr: 18u, ctxt: 0};\n+    pub static matchers : ident = ident { repr: 19u, ctxt: 0};\n+\n+    pub static str : ident = ident { repr: 20u, ctxt: 0}; // for the type\n \n     /* outside of libsyntax */\n-    pub static ty_visitor : ident = ident { repr: 21u };\n-    pub static arg : ident = ident { repr: 22u };\n-    pub static descrim : ident = ident { repr: 23u };\n-    pub static clownshoe_abi : ident = ident { repr: 24u };\n-    pub static clownshoe_stack_shim : ident = ident { repr: 25u };\n-    pub static tydesc : ident = ident { repr: 26u };\n-    pub static literally_dtor : ident = ident { repr: 27u };\n-    pub static main : ident = ident { repr: 28u };\n-    pub static opaque : ident = ident { repr: 29u };\n-    pub static blk : ident = ident { repr: 30u };\n-    pub static static : ident = ident { repr: 31u };\n-    pub static intrinsic : ident = ident { repr: 32u };\n-    pub static clownshoes_foreign_mod: ident = ident { repr: 33 };\n-    pub static unnamed_field: ident = ident { repr: 34 };\n-    pub static c_abi: ident = ident { repr: 35 };\n-    pub static type_self: ident = ident { repr: 36 };    // `Self`\n+    pub static ty_visitor : ident = ident { repr: 21u, ctxt: 0};\n+    pub static arg : ident = ident { repr: 22u, ctxt: 0};\n+    pub static descrim : ident = ident { repr: 23u, ctxt: 0};\n+    pub static clownshoe_abi : ident = ident { repr: 24u, ctxt: 0};\n+    pub static clownshoe_stack_shim : ident = ident { repr: 25u, ctxt: 0};\n+    pub static tydesc : ident = ident { repr: 26u, ctxt: 0};\n+    pub static literally_dtor : ident = ident { repr: 27u, ctxt: 0};\n+    pub static main : ident = ident { repr: 28u, ctxt: 0};\n+    pub static opaque : ident = ident { repr: 29u, ctxt: 0};\n+    pub static blk : ident = ident { repr: 30u, ctxt: 0};\n+    pub static static : ident = ident { repr: 31u, ctxt: 0};\n+    pub static intrinsic : ident = ident { repr: 32u, ctxt: 0};\n+    pub static clownshoes_foreign_mod: ident = ident { repr: 33u, ctxt: 0};\n+    pub static unnamed_field: ident = ident { repr: 34u, ctxt: 0};\n+    pub static c_abi: ident = ident { repr: 35u, ctxt: 0};\n+    pub static type_self: ident = ident { repr: 36u, ctxt: 0};    // `Self`\n }\n \n pub struct ident_interner {\n@@ -361,10 +361,10 @@ pub struct ident_interner {\n \n pub impl ident_interner {\n     fn intern(&self, val: @~str) -> ast::ident {\n-        ast::ident { repr: self.interner.intern(val) }\n+        ast::ident { repr: self.interner.intern(val), ctxt: 0}\n     }\n     fn gensym(&self, val: @~str) -> ast::ident {\n-        ast::ident { repr: self.interner.gensym(val) }\n+        ast::ident { repr: self.interner.gensym(val), ctxt: 0}\n     }\n     fn get(&self, idx: ast::ident) -> @~str {\n         self.interner.get(idx.repr)\n@@ -374,16 +374,6 @@ pub impl ident_interner {\n     }\n }\n \n-/* Key for thread-local data for sneaking interner information to the\n- * encoder/decoder. It sounds like a hack because it is one.\n- * Bonus ultra-hack: functions as keys don't work across crates,\n- * so we have to use a unique number. See taskgroup_key! in task.rs\n- * for another case of this. */\n-macro_rules! interner_key (\n-    () => (cast::transmute::<(uint, uint), &fn(+v: @@token::ident_interner)>(\n-        (-3 as uint, 0u)))\n-)\n-\n pub fn mk_ident_interner() -> @ident_interner {\n     unsafe {\n         match task::local_data::local_data_get(interner_key!()) {"}, {"sha": "c1b857a6cdba70a815bf73c25c4612dd1198cb4d", "filename": "src/libsyntax/syntax.rc", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fsyntax.rc", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Fsyntax.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsyntax.rc?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -30,6 +30,13 @@ extern mod std(vers = \"0.7-pre\");\n \n use core::*;\n \n+// allow the interner_key macro\n+// to escape this module:\n+#[macro_escape]\n+pub mod util {\n+    pub mod interner;\n+}\n+\n pub mod syntax {\n     pub use ext;\n     pub use parse;\n@@ -45,9 +52,6 @@ pub mod ast_util;\n pub mod ast_map;\n pub mod visit;\n pub mod fold;\n-pub mod util {\n-    pub mod interner;\n-}\n \n \n #[path = \"parse/mod.rs\"]"}, {"sha": "75bcac1b163062812c98942e8f2fa31f65c19d46", "filename": "src/libsyntax/util/interner.rs", "status": "modified", "additions": 15, "deletions": 1, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Futil%2Finterner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a089c6f8fc93c9a914bd5cfd2445f4e184d4e670/src%2Flibsyntax%2Futil%2Finterner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Finterner.rs?ref=a089c6f8fc93c9a914bd5cfd2445f4e184d4e670", "patch": "@@ -12,6 +12,9 @@\n // allows bidirectional lookup; i.e. given a value, one can easily find the\n // type, and vice versa.\n \n+// allow the interner_key macro to escape this module:\n+#[macro_escape];\n+\n use core::prelude::*;\n use core::hashmap::HashMap;\n \n@@ -66,6 +69,17 @@ pub impl<T:Eq + IterBytes + Hash + Const + Copy> Interner<T> {\n     fn len(&self) -> uint { let vect = &*self.vect; vect.len() }\n }\n \n+/* Key for thread-local data for sneaking interner information to the\n+* encoder/decoder. It sounds like a hack because it is one.\n+* Bonus ultra-hack: functions as keys don't work across crates,\n+* so we have to use a unique number. See taskgroup_key! in task.rs\n+* for another case of this. */\n+macro_rules! interner_key (\n+    () => (cast::transmute::<(uint, uint),\n+           &fn(+v: @@::parse::token::ident_interner)>(\n+        (-3 as uint, 0u)))\n+)\n+\n #[cfg(test)]\n mod tests {\n     use super::*;\n@@ -109,4 +123,4 @@ mod tests {\n         assert_eq!(i.get(2), @~\"Carol\");\n         assert_eq!(i.intern(@~\"Bob\"), 1);\n     }\n-}\n\\ No newline at end of file\n+}"}]}