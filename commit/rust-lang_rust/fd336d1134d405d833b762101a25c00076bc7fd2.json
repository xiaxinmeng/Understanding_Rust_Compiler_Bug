{"sha": "fd336d1134d405d833b762101a25c00076bc7fd2", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZkMzM2ZDExMzRkNDA1ZDgzM2I3NjIxMDFhMjVjMDAwNzZiYzdmZDI=", "commit": {"author": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2018-10-20T20:04:06Z"}, "committer": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2018-10-20T20:04:06Z"}, "message": "Merge #147\n\n147: Cancelation r=matklad a=matklad\n\nThis series of commits switch cancellation strategy from `JobToken` (which are cancellation tokens, explicitly controlled by the called) to salsa built-in auto cancellation. \"Auto\" means that, as soon as we advance the revision, all pending queries are cancelled automatically, and this looks like a semantic we actually want. \r\n\r\n\"client-side\" cancellation is a rare event, and it's ok to just punt on it. Automatic cancellation after the user types something in happens all the time. \n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "040ab6dc1286ab9fe5da0002d29ae4eb7a37850a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/040ab6dc1286ab9fe5da0002d29ae4eb7a37850a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fd336d1134d405d833b762101a25c00076bc7fd2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fd336d1134d405d833b762101a25c00076bc7fd2", "html_url": "https://github.com/rust-lang/rust/commit/fd336d1134d405d833b762101a25c00076bc7fd2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fd336d1134d405d833b762101a25c00076bc7fd2/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "parents": [{"sha": "73dd870da2dcc991b0fdcdde8bee91f05cb9e182", "url": "https://api.github.com/repos/rust-lang/rust/commits/73dd870da2dcc991b0fdcdde8bee91f05cb9e182", "html_url": "https://github.com/rust-lang/rust/commit/73dd870da2dcc991b0fdcdde8bee91f05cb9e182"}, {"sha": "0102a01f76c855da447e25eb81191047a3ca79b8", "url": "https://api.github.com/repos/rust-lang/rust/commits/0102a01f76c855da447e25eb81191047a3ca79b8", "html_url": "https://github.com/rust-lang/rust/commit/0102a01f76c855da447e25eb81191047a3ca79b8"}], "stats": {"total": 474, "additions": 212, "deletions": 262}, "files": [{"sha": "f51914883431ed78748cf3ccf3d91ac2a4d190fd", "filename": "Cargo.lock", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -609,7 +609,6 @@ dependencies = [\n name = \"ra_analysis\"\n version = \"0.1.0\"\n dependencies = [\n- \"crossbeam-channel 0.2.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"fst 0.3.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"im 12.2.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"log 0.4.5 (registry+https://github.com/rust-lang/crates.io-index)\","}, {"sha": "d7ac69fe8db9518deb3163a555b5f599a71b6d08", "filename": "crates/ra_analysis/Cargo.toml", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2FCargo.toml?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -7,7 +7,6 @@ authors = [\"Aleksey Kladov <aleksey.kladov@gmail.com>\"]\n [dependencies]\n relative-path = \"0.3.7\"\n log = \"0.4.2\"\n-crossbeam-channel = \"0.2.4\"\n parking_lot = \"0.6.3\"\n once_cell = \"0.1.5\"\n rayon = \"1.0.2\""}, {"sha": "09d74b9e742f7c7d62758302bfabf99da9ccba23", "filename": "crates/ra_analysis/src/db.rs", "status": "modified", "additions": 23, "deletions": 11, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Fdb.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,17 +1,20 @@\n-use crate::{\n-    module_map::{ModuleDescriptorQuery, ModuleTreeQuery, ModulesDatabase},\n-    symbol_index::SymbolIndex,\n-    FileId, FileResolverImp,\n+use std::{\n+    fmt,\n+    hash::{Hash, Hasher},\n+    sync::Arc,\n };\n+\n use ra_editor::LineIndex;\n use ra_syntax::File;\n use rustc_hash::FxHashSet;\n use salsa;\n \n-use std::{\n-    fmt,\n-    hash::{Hash, Hasher},\n-    sync::Arc,\n+use crate::{\n+    db,\n+    Cancelable, Canceled,\n+    module_map::{ModuleDescriptorQuery, ModuleTreeQuery, ModulesDatabase},\n+    symbol_index::SymbolIndex,\n+    FileId, FileResolverImp,\n };\n \n #[derive(Default)]\n@@ -31,6 +34,14 @@ impl salsa::Database for RootDatabase {\n     }\n }\n \n+pub(crate) fn check_canceled(db: &impl salsa::Database) -> Cancelable<()> {\n+    if db.salsa_runtime().is_current_revision_canceled() {\n+        Err(Canceled)\n+    } else {\n+        Ok(())\n+    }\n+}\n+\n impl salsa::ParallelDatabase for RootDatabase {\n     fn fork(&self) -> Self {\n         RootDatabase {\n@@ -98,7 +109,7 @@ salsa::query_group! {\n         fn file_lines(file_id: FileId) -> Arc<LineIndex> {\n             type FileLinesQuery;\n         }\n-        fn file_symbols(file_id: FileId) -> Arc<SymbolIndex> {\n+        fn file_symbols(file_id: FileId) -> Cancelable<Arc<SymbolIndex>> {\n             type FileSymbolsQuery;\n         }\n     }\n@@ -112,7 +123,8 @@ fn file_lines(db: &impl SyntaxDatabase, file_id: FileId) -> Arc<LineIndex> {\n     let text = db.file_text(file_id);\n     Arc::new(LineIndex::new(&*text))\n }\n-fn file_symbols(db: &impl SyntaxDatabase, file_id: FileId) -> Arc<SymbolIndex> {\n+fn file_symbols(db: &impl SyntaxDatabase, file_id: FileId) -> Cancelable<Arc<SymbolIndex>> {\n+    db::check_canceled(db)?;\n     let syntax = db.file_syntax(file_id);\n-    Arc::new(SymbolIndex::for_file(file_id, syntax))\n+    Ok(Arc::new(SymbolIndex::for_file(file_id, syntax)))\n }"}, {"sha": "310bf15857231b32307f172220edd49ff4a7e3dd", "filename": "crates/ra_analysis/src/descriptors.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fdescriptors.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fdescriptors.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Fdescriptors.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,12 +1,13 @@\n-use crate::{imp::FileResolverImp, FileId};\n+use std::collections::BTreeMap;\n+\n use ra_syntax::{\n     ast::{self, AstNode, NameOwner},\n     text_utils::is_subrange,\n     SmolStr,\n };\n use relative_path::RelativePathBuf;\n \n-use std::collections::BTreeMap;\n+use crate::{imp::FileResolverImp, FileId};\n \n #[derive(Debug, PartialEq, Eq, Hash)]\n pub struct ModuleDescriptor {"}, {"sha": "32e9bb6d7f238b1e5cc1178d3440b5ada20f6a3f", "filename": "crates/ra_analysis/src/imp.rs", "status": "modified", "additions": 42, "deletions": 36, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fimp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fimp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Fimp.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -19,8 +19,8 @@ use rustc_hash::FxHashSet;\n use crate::{\n     descriptors::{FnDescriptor, ModuleTreeDescriptor, Problem},\n     roots::{ReadonlySourceRoot, SourceRoot, WritableSourceRoot},\n-    CrateGraph, CrateId, Diagnostic, FileId, FileResolver, FileSystemEdit, JobToken, Position,\n-    Query, SourceChange, SourceFileEdit,\n+    CrateGraph, CrateId, Diagnostic, FileId, FileResolver, FileSystemEdit, Position,\n+    Query, SourceChange, SourceFileEdit, Cancelable,\n };\n \n #[derive(Clone, Debug)]\n@@ -148,19 +148,21 @@ impl AnalysisImpl {\n     pub fn file_line_index(&self, file_id: FileId) -> Arc<LineIndex> {\n         self.root(file_id).lines(file_id)\n     }\n-    pub fn world_symbols(&self, query: Query, token: &JobToken) -> Vec<(FileId, FileSymbol)> {\n+    pub fn world_symbols(&self, query: Query) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n         let mut buf = Vec::new();\n         if query.libs {\n-            self.data.libs.iter().for_each(|it| it.symbols(&mut buf));\n+            for lib in self.data.libs.iter() {\n+                lib.symbols(&mut buf)?;\n+            }\n         } else {\n-            self.data.root.symbols(&mut buf);\n+            self.data.root.symbols(&mut buf)?;\n         }\n-        query.search(&buf, token)\n+        Ok(query.search(&buf))\n     }\n-    pub fn parent_module(&self, file_id: FileId) -> Vec<(FileId, FileSymbol)> {\n+    pub fn parent_module(&self, file_id: FileId) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n         let root = self.root(file_id);\n-        let module_tree = root.module_tree();\n-        module_tree\n+        let module_tree = root.module_tree()?;\n+        let res = module_tree\n             .parent_modules(file_id)\n             .iter()\n             .map(|link| {\n@@ -174,10 +176,11 @@ impl AnalysisImpl {\n                 };\n                 (file_id, sym)\n             })\n-            .collect()\n+            .collect();\n+        Ok(res)\n     }\n-    pub fn crate_for(&self, file_id: FileId) -> Vec<CrateId> {\n-        let module_tree = self.root(file_id).module_tree();\n+    pub fn crate_for(&self, file_id: FileId) -> Cancelable<Vec<CrateId>> {\n+        let module_tree = self.root(file_id).module_tree()?;\n         let crate_graph = &self.data.crate_graph;\n         let mut res = Vec::new();\n         let mut work = VecDeque::new();\n@@ -195,7 +198,7 @@ impl AnalysisImpl {\n                 .filter(|&id| visited.insert(id));\n             work.extend(parents);\n         }\n-        res\n+        Ok(res)\n     }\n     pub fn crate_root(&self, crate_id: CrateId) -> FileId {\n         self.data.crate_graph.crate_roots[&crate_id]\n@@ -204,15 +207,14 @@ impl AnalysisImpl {\n         &self,\n         file_id: FileId,\n         offset: TextUnit,\n-        token: &JobToken,\n-    ) -> Vec<(FileId, FileSymbol)> {\n+    ) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n         let root = self.root(file_id);\n-        let module_tree = root.module_tree();\n+        let module_tree = root.module_tree()?;\n         let file = root.syntax(file_id);\n         let syntax = file.syntax();\n         if let Some(name_ref) = find_node_at_offset::<ast::NameRef>(syntax, offset) {\n             // First try to resolve the symbol locally\n-            if let Some((name, range)) = resolve_local_name(&file, offset, name_ref) {\n+            return if let Some((name, range)) = resolve_local_name(&file, offset, name_ref) {\n                 let mut vec = vec![];\n                 vec.push((\n                     file_id,\n@@ -222,12 +224,11 @@ impl AnalysisImpl {\n                         kind: NAME,\n                     },\n                 ));\n-\n-                return vec;\n+                Ok(vec)\n             } else {\n                 // If that fails try the index based approach.\n-                return self.index_resolve(name_ref, token);\n-            }\n+                self.index_resolve(name_ref)\n+            };\n         }\n         if let Some(name) = find_node_at_offset::<ast::Name>(syntax, offset) {\n             if let Some(module) = name.syntax().parent().and_then(ast::Module::cast) {\n@@ -250,14 +251,14 @@ impl AnalysisImpl {\n                         })\n                         .collect();\n \n-                    return res;\n+                    return Ok(res);\n                 }\n             }\n         }\n-        vec![]\n+        Ok(vec![])\n     }\n \n-    pub fn find_all_refs(&self, file_id: FileId, offset: TextUnit, _token: &JobToken) -> Vec<(FileId, TextRange)> {\n+    pub fn find_all_refs(&self, file_id: FileId, offset: TextUnit) -> Vec<(FileId, TextRange)> {\n         let root = self.root(file_id);\n         let file = root.syntax(file_id);\n         let syntax = file.syntax();\n@@ -289,9 +290,9 @@ impl AnalysisImpl {\n         ret\n     }\n \n-    pub fn diagnostics(&self, file_id: FileId) -> Vec<Diagnostic> {\n+    pub fn diagnostics(&self, file_id: FileId) -> Cancelable<Vec<Diagnostic>> {\n         let root = self.root(file_id);\n-        let module_tree = root.module_tree();\n+        let module_tree = root.module_tree()?;\n         let syntax = root.syntax(file_id);\n \n         let mut res = ra_editor::diagnostics(&syntax)\n@@ -346,7 +347,7 @@ impl AnalysisImpl {\n             };\n             res.push(diag)\n         }\n-        res\n+        Ok(res)\n     }\n \n     pub fn assists(&self, file_id: FileId, range: TextRange) -> Vec<SourceChange> {\n@@ -379,18 +380,23 @@ impl AnalysisImpl {\n         &self,\n         file_id: FileId,\n         offset: TextUnit,\n-        token: &JobToken,\n-    ) -> Option<(FnDescriptor, Option<usize>)> {\n+    ) -> Cancelable<Option<(FnDescriptor, Option<usize>)>> {\n         let root = self.root(file_id);\n         let file = root.syntax(file_id);\n         let syntax = file.syntax();\n \n         // Find the calling expression and it's NameRef\n-        let calling_node = FnCallNode::with_node(syntax, offset)?;\n-        let name_ref = calling_node.name_ref()?;\n+        let calling_node = match FnCallNode::with_node(syntax, offset) {\n+            Some(node) => node,\n+            None => return Ok(None),\n+        };\n+        let name_ref = match calling_node.name_ref() {\n+            Some(name) => name,\n+            None => return Ok(None),\n+        };\n \n         // Resolve the function's NameRef (NOTE: this isn't entirely accurate).\n-        let file_symbols = self.index_resolve(name_ref, token);\n+        let file_symbols = self.index_resolve(name_ref)?;\n         for (_, fs) in file_symbols {\n             if fs.kind == FN_DEF {\n                 if let Some(fn_def) = find_node_at_offset(syntax, fs.node_range.start()) {\n@@ -432,21 +438,21 @@ impl AnalysisImpl {\n                             }\n                         }\n \n-                        return Some((descriptor, current_parameter));\n+                        return Ok(Some((descriptor, current_parameter)));\n                     }\n                 }\n             }\n         }\n \n-        None\n+        Ok(None)\n     }\n \n-    fn index_resolve(&self, name_ref: ast::NameRef, token: &JobToken) -> Vec<(FileId, FileSymbol)> {\n+    fn index_resolve(&self, name_ref: ast::NameRef) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n         let name = name_ref.text();\n         let mut query = Query::new(name.to_string());\n         query.exact();\n         query.limit(4);\n-        self.world_symbols(query, token)\n+        self.world_symbols(query)\n     }\n \n     fn resolve_module("}, {"sha": "2871f983908306b8bb6881b3af4dedce8f55198d", "filename": "crates/ra_analysis/src/job.rs", "status": "removed", "additions": 0, "deletions": 53, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/73dd870da2dcc991b0fdcdde8bee91f05cb9e182/crates%2Fra_analysis%2Fsrc%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/73dd870da2dcc991b0fdcdde8bee91f05cb9e182/crates%2Fra_analysis%2Fsrc%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Fjob.rs?ref=73dd870da2dcc991b0fdcdde8bee91f05cb9e182", "patch": "@@ -1,53 +0,0 @@\n-use crossbeam_channel::{bounded, Receiver, Sender};\n-\n-pub struct JobHandle {\n-    job_alive: Receiver<Never>,\n-    _job_canceled: Sender<Never>,\n-}\n-\n-pub struct JobToken {\n-    _job_alive: Sender<Never>,\n-    job_canceled: Receiver<Never>,\n-}\n-\n-impl JobHandle {\n-    pub fn new() -> (JobHandle, JobToken) {\n-        let (sender_alive, receiver_alive) = bounded(0);\n-        let (sender_canceled, receiver_canceled) = bounded(0);\n-        let token = JobToken {\n-            _job_alive: sender_alive,\n-            job_canceled: receiver_canceled,\n-        };\n-        let handle = JobHandle {\n-            job_alive: receiver_alive,\n-            _job_canceled: sender_canceled,\n-        };\n-        (handle, token)\n-    }\n-    pub fn has_completed(&self) -> bool {\n-        is_closed(&self.job_alive)\n-    }\n-    pub fn cancel(self) {}\n-}\n-\n-impl JobToken {\n-    pub fn is_canceled(&self) -> bool {\n-        is_closed(&self.job_canceled)\n-    }\n-}\n-\n-// We don't actually send messages through the channels,\n-// and instead just check if the channel is closed,\n-// so we use uninhabited enum as a message type\n-enum Never {}\n-\n-/// Nonblocking\n-fn is_closed(chan: &Receiver<Never>) -> bool {\n-    select! {\n-        recv(chan, msg) => match msg {\n-            None => true,\n-            Some(never) => match never {}\n-        }\n-        default => false,\n-    }\n-}"}, {"sha": "28e0a12b20f7be3e0373cd6e620890979288a11f", "filename": "crates/ra_analysis/src/lib.rs", "status": "modified", "additions": 42, "deletions": 34, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Flib.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -7,36 +7,47 @@ extern crate ra_editor;\n extern crate ra_syntax;\n extern crate rayon;\n extern crate relative_path;\n-#[macro_use]\n-extern crate crossbeam_channel;\n extern crate im;\n extern crate rustc_hash;\n extern crate salsa;\n \n mod db;\n mod descriptors;\n mod imp;\n-mod job;\n mod module_map;\n mod roots;\n mod symbol_index;\n \n use std::{fmt::Debug, sync::Arc};\n \n-use crate::imp::{AnalysisHostImpl, AnalysisImpl, FileResolverImp};\n use ra_syntax::{AtomEdit, File, TextRange, TextUnit};\n use relative_path::{RelativePath, RelativePathBuf};\n use rustc_hash::FxHashMap;\n \n+use crate::imp::{AnalysisHostImpl, AnalysisImpl, FileResolverImp};\n+\n pub use crate::{\n     descriptors::FnDescriptor,\n-    job::{JobHandle, JobToken},\n };\n pub use ra_editor::{\n     CompletionItem, FileSymbol, Fold, FoldKind, HighlightedRange, LineIndex, Runnable,\n     RunnableKind, StructureNode,\n };\n \n+#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]\n+pub struct Canceled;\n+\n+pub type Cancelable<T> = Result<T, Canceled>;\n+\n+impl std::fmt::Display for Canceled {\n+    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        fmt.write_str(\"Canceled\")\n+    }\n+}\n+\n+impl std::error::Error for Canceled {\n+}\n+\n #[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]\n pub struct FileId(pub u32);\n \n@@ -205,60 +216,57 @@ impl Analysis {\n         let file = self.imp.file_syntax(file_id);\n         ra_editor::file_structure(&file)\n     }\n-    pub fn symbol_search(&self, query: Query, token: &JobToken) -> Vec<(FileId, FileSymbol)> {\n-        self.imp.world_symbols(query, token)\n+    pub fn folding_ranges(&self, file_id: FileId) -> Vec<Fold> {\n+        let file = self.imp.file_syntax(file_id);\n+        ra_editor::folding_ranges(&file)\n+    }\n+    pub fn symbol_search(&self, query: Query) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n+        self.imp.world_symbols(query)\n     }\n     pub fn approximately_resolve_symbol(\n         &self,\n         file_id: FileId,\n-        offset: TextUnit,\n-        token: &JobToken,\n-    ) -> Vec<(FileId, FileSymbol)> {\n+        offset: TextUnit\n+    ) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n         self.imp\n-            .approximately_resolve_symbol(file_id, offset, token)\n+            .approximately_resolve_symbol(file_id, offset)\n     }\n-    pub fn find_all_refs(&self, file_id: FileId, offset: TextUnit, token: &JobToken) -> Vec<(FileId, TextRange)> {\n-        self.imp.find_all_refs(file_id, offset, token)\n+    pub fn find_all_refs(&self, file_id: FileId, offset: TextUnit, ) -> Cancelable<Vec<(FileId, TextRange)>> {\n+        Ok(self.imp.find_all_refs(file_id, offset))\n     }\n-    pub fn parent_module(&self, file_id: FileId) -> Vec<(FileId, FileSymbol)> {\n+    pub fn parent_module(&self, file_id: FileId) -> Cancelable<Vec<(FileId, FileSymbol)>> {\n         self.imp.parent_module(file_id)\n     }\n-    pub fn crate_for(&self, file_id: FileId) -> Vec<CrateId> {\n+    pub fn crate_for(&self, file_id: FileId) -> Cancelable<Vec<CrateId>> {\n         self.imp.crate_for(file_id)\n     }\n-    pub fn crate_root(&self, crate_id: CrateId) -> FileId {\n-        self.imp.crate_root(crate_id)\n+    pub fn crate_root(&self, crate_id: CrateId) -> Cancelable<FileId> {\n+        Ok(self.imp.crate_root(crate_id))\n     }\n-    pub fn runnables(&self, file_id: FileId) -> Vec<Runnable> {\n+    pub fn runnables(&self, file_id: FileId) -> Cancelable<Vec<Runnable>> {\n         let file = self.imp.file_syntax(file_id);\n-        ra_editor::runnables(&file)\n+        Ok(ra_editor::runnables(&file))\n     }\n-    pub fn highlight(&self, file_id: FileId) -> Vec<HighlightedRange> {\n+    pub fn highlight(&self, file_id: FileId) -> Cancelable<Vec<HighlightedRange>> {\n         let file = self.imp.file_syntax(file_id);\n-        ra_editor::highlight(&file)\n+        Ok(ra_editor::highlight(&file))\n     }\n-    pub fn completions(&self, file_id: FileId, offset: TextUnit) -> Option<Vec<CompletionItem>> {\n+    pub fn completions(&self, file_id: FileId, offset: TextUnit) -> Cancelable<Option<Vec<CompletionItem>>> {\n         let file = self.imp.file_syntax(file_id);\n-        ra_editor::scope_completion(&file, offset)\n+        Ok(ra_editor::scope_completion(&file, offset))\n     }\n-    pub fn assists(&self, file_id: FileId, range: TextRange) -> Vec<SourceChange> {\n-        self.imp.assists(file_id, range)\n+    pub fn assists(&self, file_id: FileId, range: TextRange) -> Cancelable<Vec<SourceChange>> {\n+        Ok(self.imp.assists(file_id, range))\n     }\n-    pub fn diagnostics(&self, file_id: FileId) -> Vec<Diagnostic> {\n+    pub fn diagnostics(&self, file_id: FileId) -> Cancelable<Vec<Diagnostic>> {\n         self.imp.diagnostics(file_id)\n     }\n-    pub fn folding_ranges(&self, file_id: FileId) -> Vec<Fold> {\n-        let file = self.imp.file_syntax(file_id);\n-        ra_editor::folding_ranges(&file)\n-    }\n-\n     pub fn resolve_callable(\n         &self,\n         file_id: FileId,\n         offset: TextUnit,\n-        token: &JobToken,\n-    ) -> Option<(FnDescriptor, Option<usize>)> {\n-        self.imp.resolve_callable(file_id, offset, token)\n+    ) -> Cancelable<Option<(FnDescriptor, Option<usize>)>> {\n+        self.imp.resolve_callable(file_id, offset)\n     }\n }\n "}, {"sha": "3c800265ad3146075fd3ecb57676c8f999629fba", "filename": "crates/ra_analysis/src/module_map.rs", "status": "modified", "additions": 13, "deletions": 9, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fmodule_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fmodule_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Fmodule_map.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,37 +1,41 @@\n+use std::sync::Arc;\n+\n use crate::{\n+    db,\n+    Cancelable,\n     db::SyntaxDatabase,\n     descriptors::{ModuleDescriptor, ModuleTreeDescriptor},\n     FileId,\n };\n \n-use std::sync::Arc;\n-\n salsa::query_group! {\n     pub(crate) trait ModulesDatabase: SyntaxDatabase {\n-        fn module_tree() -> Arc<ModuleTreeDescriptor> {\n+        fn module_tree() -> Cancelable<Arc<ModuleTreeDescriptor>> {\n             type ModuleTreeQuery;\n         }\n-        fn module_descriptor(file_id: FileId) -> Arc<ModuleDescriptor> {\n+        fn module_descriptor(file_id: FileId) -> Cancelable<Arc<ModuleDescriptor>> {\n             type ModuleDescriptorQuery;\n         }\n     }\n }\n \n-fn module_descriptor(db: &impl ModulesDatabase, file_id: FileId) -> Arc<ModuleDescriptor> {\n+fn module_descriptor(db: &impl ModulesDatabase, file_id: FileId) -> Cancelable<Arc<ModuleDescriptor>> {\n+    db::check_canceled(db)?;\n     let file = db.file_syntax(file_id);\n-    Arc::new(ModuleDescriptor::new(file.ast()))\n+    Ok(Arc::new(ModuleDescriptor::new(file.ast())))\n }\n \n-fn module_tree(db: &impl ModulesDatabase) -> Arc<ModuleTreeDescriptor> {\n+fn module_tree(db: &impl ModulesDatabase) -> Cancelable<Arc<ModuleTreeDescriptor>> {\n+    db::check_canceled(db)?;\n     let file_set = db.file_set();\n     let mut files = Vec::new();\n     for &file_id in file_set.files.iter() {\n-        let module_descr = db.module_descriptor(file_id);\n+        let module_descr = db.module_descriptor(file_id)?;\n         files.push((file_id, module_descr));\n     }\n     let res = ModuleTreeDescriptor::new(\n         files.iter().map(|(file_id, descr)| (*file_id, &**descr)),\n         &file_set.resolver,\n     );\n-    Arc::new(res)\n+    Ok(Arc::new(res))\n }"}, {"sha": "123c4acfa153d556859dbd23e20ac6d719c8e49a", "filename": "crates/ra_analysis/src/roots.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Froots.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Froots.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Froots.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -8,6 +8,7 @@ use rustc_hash::{FxHashMap, FxHashSet};\n use salsa::Database;\n \n use crate::{\n+    Cancelable,\n     db::{self, FilesDatabase, SyntaxDatabase},\n     descriptors::{ModuleDescriptor, ModuleTreeDescriptor},\n     imp::FileResolverImp,\n@@ -18,10 +19,10 @@ use crate::{\n \n pub(crate) trait SourceRoot {\n     fn contains(&self, file_id: FileId) -> bool;\n-    fn module_tree(&self) -> Arc<ModuleTreeDescriptor>;\n+    fn module_tree(&self) -> Cancelable<Arc<ModuleTreeDescriptor>>;\n     fn lines(&self, file_id: FileId) -> Arc<LineIndex>;\n     fn syntax(&self, file_id: FileId) -> File;\n-    fn symbols(&self, acc: &mut Vec<Arc<SymbolIndex>>);\n+    fn symbols(&self, acc: &mut Vec<Arc<SymbolIndex>>) -> Cancelable<()>;\n }\n \n #[derive(Default, Debug, Clone)]\n@@ -64,7 +65,7 @@ impl WritableSourceRoot {\n }\n \n impl SourceRoot for WritableSourceRoot {\n-    fn module_tree(&self) -> Arc<ModuleTreeDescriptor> {\n+    fn module_tree(&self) -> Cancelable<Arc<ModuleTreeDescriptor>> {\n         self.db.module_tree()\n     }\n     fn contains(&self, file_id: FileId) -> bool {\n@@ -76,14 +77,12 @@ impl SourceRoot for WritableSourceRoot {\n     fn syntax(&self, file_id: FileId) -> File {\n         self.db.file_syntax(file_id)\n     }\n-    fn symbols<'a>(&'a self, acc: &mut Vec<Arc<SymbolIndex>>) {\n-        let db = &self.db;\n-        let symbols = db.file_set();\n-        let symbols = symbols\n-            .files\n-            .iter()\n-            .map(|&file_id| db.file_symbols(file_id));\n-        acc.extend(symbols);\n+    fn symbols<'a>(&'a self, acc: &mut Vec<Arc<SymbolIndex>>) -> Cancelable<()> {\n+        for &file_id in self.db.file_set().files.iter() {\n+            let symbols = self.db.file_symbols(file_id)?;\n+            acc.push(symbols)\n+        }\n+        Ok(())\n     }\n }\n \n@@ -167,8 +166,8 @@ impl ReadonlySourceRoot {\n }\n \n impl SourceRoot for ReadonlySourceRoot {\n-    fn module_tree(&self) -> Arc<ModuleTreeDescriptor> {\n-        Arc::clone(&self.module_tree)\n+    fn module_tree(&self) -> Cancelable<Arc<ModuleTreeDescriptor>> {\n+        Ok(Arc::clone(&self.module_tree))\n     }\n     fn contains(&self, file_id: FileId) -> bool {\n         self.file_map.contains_key(&file_id)\n@@ -179,7 +178,8 @@ impl SourceRoot for ReadonlySourceRoot {\n     fn syntax(&self, file_id: FileId) -> File {\n         self.data(file_id).syntax().clone()\n     }\n-    fn symbols(&self, acc: &mut Vec<Arc<SymbolIndex>>) {\n-        acc.push(Arc::clone(&self.symbol_index))\n+    fn symbols(&self, acc: &mut Vec<Arc<SymbolIndex>>) -> Cancelable<()> {\n+        acc.push(Arc::clone(&self.symbol_index));\n+        Ok(())\n     }\n }"}, {"sha": "a0f3c0437466bdeb0d77d315e28fd95174c2874e", "filename": "crates/ra_analysis/src/symbol_index.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fsymbol_index.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Fsrc%2Fsymbol_index.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Fsrc%2Fsymbol_index.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,4 +1,8 @@\n-use crate::{FileId, JobToken, Query};\n+use std::{\n+    hash::{Hash, Hasher},\n+    sync::Arc,\n+};\n+\n use fst::{self, Streamer};\n use ra_editor::{file_symbols, FileSymbol};\n use ra_syntax::{\n@@ -7,10 +11,7 @@ use ra_syntax::{\n };\n use rayon::prelude::*;\n \n-use std::{\n-    hash::{Hash, Hasher},\n-    sync::Arc,\n-};\n+use crate::{FileId, Query};\n \n #[derive(Debug)]\n pub(crate) struct SymbolIndex {\n@@ -59,7 +60,6 @@ impl Query {\n     pub(crate) fn search(\n         self,\n         indices: &[Arc<SymbolIndex>],\n-        token: &JobToken,\n     ) -> Vec<(FileId, FileSymbol)> {\n         let mut op = fst::map::OpBuilder::new();\n         for file_symbols in indices.iter() {\n@@ -69,7 +69,7 @@ impl Query {\n         let mut stream = op.union();\n         let mut res = Vec::new();\n         while let Some((_, indexed_values)) = stream.next() {\n-            if res.len() >= self.limit || token.is_canceled() {\n+            if res.len() >= self.limit {\n                 break;\n             }\n             for indexed_value in indexed_values {"}, {"sha": "7ae3d0eebfc1c8c998959216eae52d195dcaebc6", "filename": "crates/ra_analysis/tests/tests.rs", "status": "modified", "additions": 14, "deletions": 17, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Ftests%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_analysis%2Ftests%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_analysis%2Ftests%2Ftests.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -7,15 +7,15 @@ extern crate test_utils;\n \n use std::sync::Arc;\n \n-use ra_analysis::{\n-    Analysis, AnalysisHost, CrateGraph, CrateId, FileId, FileResolver, FnDescriptor, JobHandle,\n-};\n use ra_syntax::TextRange;\n-\n use relative_path::{RelativePath, RelativePathBuf};\n use rustc_hash::FxHashMap;\n use test_utils::{assert_eq_dbg, extract_offset};\n \n+use ra_analysis::{\n+    Analysis, AnalysisHost, CrateGraph, CrateId, FileId, FileResolver, FnDescriptor,\n+};\n+\n #[derive(Debug)]\n struct FileMap(Vec<(FileId, RelativePathBuf)>);\n \n@@ -64,24 +64,22 @@ fn get_signature(text: &str) -> (FnDescriptor, Option<usize>) {\n     let (offset, code) = extract_offset(text);\n     let code = code.as_str();\n \n-    let (_handle, token) = JobHandle::new();\n     let snap = analysis(&[(\"/lib.rs\", code)]);\n \n-    snap.resolve_callable(FileId(1), offset, &token).unwrap()\n+    snap.resolve_callable(FileId(1), offset).unwrap().unwrap()\n }\n \n #[test]\n fn test_resolve_module() {\n     let snap = analysis(&[(\"/lib.rs\", \"mod foo;\"), (\"/foo.rs\", \"\")]);\n-    let (_handle, token) = JobHandle::new();\n-    let symbols = snap.approximately_resolve_symbol(FileId(1), 4.into(), &token);\n+    let symbols = snap.approximately_resolve_symbol(FileId(1), 4.into()).unwrap();\n     assert_eq_dbg(\n         r#\"[(FileId(2), FileSymbol { name: \"foo\", node_range: [0; 0), kind: MODULE })]\"#,\n         &symbols,\n     );\n \n     let snap = analysis(&[(\"/lib.rs\", \"mod foo;\"), (\"/foo/mod.rs\", \"\")]);\n-    let symbols = snap.approximately_resolve_symbol(FileId(1), 4.into(), &token);\n+    let symbols = snap.approximately_resolve_symbol(FileId(1), 4.into()).unwrap();\n     assert_eq_dbg(\n         r#\"[(FileId(2), FileSymbol { name: \"foo\", node_range: [0; 0), kind: MODULE })]\"#,\n         &symbols,\n@@ -91,7 +89,7 @@ fn test_resolve_module() {\n #[test]\n fn test_unresolved_module_diagnostic() {\n     let snap = analysis(&[(\"/lib.rs\", \"mod foo;\")]);\n-    let diagnostics = snap.diagnostics(FileId(1));\n+    let diagnostics = snap.diagnostics(FileId(1)).unwrap();\n     assert_eq_dbg(\n         r#\"[Diagnostic {\n             message: \"unresolved module\",\n@@ -108,14 +106,14 @@ fn test_unresolved_module_diagnostic() {\n #[test]\n fn test_unresolved_module_diagnostic_no_diag_for_inline_mode() {\n     let snap = analysis(&[(\"/lib.rs\", \"mod foo {}\")]);\n-    let diagnostics = snap.diagnostics(FileId(1));\n+    let diagnostics = snap.diagnostics(FileId(1)).unwrap();\n     assert_eq_dbg(r#\"[]\"#, &diagnostics);\n }\n \n #[test]\n fn test_resolve_parent_module() {\n     let snap = analysis(&[(\"/lib.rs\", \"mod foo;\"), (\"/foo.rs\", \"\")]);\n-    let symbols = snap.parent_module(FileId(2));\n+    let symbols = snap.parent_module(FileId(2)).unwrap();\n     assert_eq_dbg(\n         r#\"[(FileId(1), FileSymbol { name: \"foo\", node_range: [0; 8), kind: MODULE })]\"#,\n         &symbols,\n@@ -126,7 +124,7 @@ fn test_resolve_parent_module() {\n fn test_resolve_crate_root() {\n     let mut host = analysis_host(&[(\"/lib.rs\", \"mod foo;\"), (\"/foo.rs\", \"\")]);\n     let snap = host.analysis();\n-    assert!(snap.crate_for(FileId(2)).is_empty());\n+    assert!(snap.crate_for(FileId(2)).unwrap().is_empty());\n \n     let crate_graph = CrateGraph {\n         crate_roots: {\n@@ -138,7 +136,7 @@ fn test_resolve_crate_root() {\n     host.set_crate_graph(crate_graph);\n     let snap = host.analysis();\n \n-    assert_eq!(snap.crate_for(FileId(2)), vec![CrateId(1)],);\n+    assert_eq!(snap.crate_for(FileId(2)).unwrap(), vec![CrateId(1)],);\n }\n \n #[test]\n@@ -232,10 +230,9 @@ fn get_all_refs(text: &str) -> Vec<(FileId, TextRange)> {\n     let (offset, code) = extract_offset(text);\n     let code = code.as_str();\n \n-    let (_handle, token) = JobHandle::new();\n     let snap = analysis(&[(\"/lib.rs\", code)]);\n \n-    snap.find_all_refs(FileId(1), offset, &token)\n+    snap.find_all_refs(FileId(1), offset).unwrap()\n }\n \n #[test]\n@@ -266,4 +263,4 @@ fn test_find_all_refs_for_param_inside() {\n \n     let refs = get_all_refs(code);\n     assert_eq!(refs.len(), 2);\n-}\n\\ No newline at end of file\n+}"}, {"sha": "f5dff4c80aab67f7508dd5af12db34ede9ec6f92", "filename": "crates/ra_lsp_server/src/main_loop/handlers.rs", "status": "modified", "additions": 29, "deletions": 49, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fmain_loop%2Fhandlers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fmain_loop%2Fhandlers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_lsp_server%2Fsrc%2Fmain_loop%2Fhandlers.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,12 +1,13 @@\n-use rustc_hash::FxHashMap;\n+use std::collections::HashMap;\n \n+use rustc_hash::FxHashMap;\n use languageserver_types::{\n     CodeActionResponse, Command, CompletionItem, CompletionItemKind, Diagnostic,\n     DiagnosticSeverity, DocumentSymbol, FoldingRange, FoldingRangeKind, FoldingRangeParams,\n     InsertTextFormat, Location, Position, SymbolInformation, TextDocumentIdentifier, TextEdit,\n     RenameParams, WorkspaceEdit, PrepareRenameResponse\n };\n-use ra_analysis::{FileId, FoldKind, JobToken, Query, RunnableKind};\n+use ra_analysis::{FileId, FoldKind, Query, RunnableKind};\n use ra_syntax::text_utils::contains_offset_nonstrict;\n use serde_json::to_value;\n \n@@ -18,12 +19,9 @@ use crate::{\n     Result,\n };\n \n-use std::collections::HashMap;\n-\n pub fn handle_syntax_tree(\n     world: ServerWorld,\n     params: req::SyntaxTreeParams,\n-    _token: JobToken,\n ) -> Result<String> {\n     let id = params.text_document.try_conv_with(&world)?;\n     let res = world.analysis().syntax_tree(id);\n@@ -33,7 +31,6 @@ pub fn handle_syntax_tree(\n pub fn handle_extend_selection(\n     world: ServerWorld,\n     params: req::ExtendSelectionParams,\n-    _token: JobToken,\n ) -> Result<req::ExtendSelectionResult> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let file = world.analysis().file_syntax(file_id);\n@@ -51,7 +48,6 @@ pub fn handle_extend_selection(\n pub fn handle_find_matching_brace(\n     world: ServerWorld,\n     params: req::FindMatchingBraceParams,\n-    _token: JobToken,\n ) -> Result<Vec<Position>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let file = world.analysis().file_syntax(file_id);\n@@ -74,7 +70,6 @@ pub fn handle_find_matching_brace(\n pub fn handle_join_lines(\n     world: ServerWorld,\n     params: req::JoinLinesParams,\n-    _token: JobToken,\n ) -> Result<req::SourceChange> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n@@ -88,7 +83,6 @@ pub fn handle_join_lines(\n pub fn handle_on_enter(\n     world: ServerWorld,\n     params: req::TextDocumentPositionParams,\n-    _token: JobToken,\n ) -> Result<Option<req::SourceChange>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n@@ -102,7 +96,6 @@ pub fn handle_on_enter(\n pub fn handle_on_type_formatting(\n     world: ServerWorld,\n     params: req::DocumentOnTypeFormattingParams,\n-    _token: JobToken,\n ) -> Result<Option<Vec<TextEdit>>> {\n     if params.ch != \"=\" {\n         return Ok(None);\n@@ -122,7 +115,6 @@ pub fn handle_on_type_formatting(\n pub fn handle_document_symbol(\n     world: ServerWorld,\n     params: req::DocumentSymbolParams,\n-    _token: JobToken,\n ) -> Result<Option<req::DocumentSymbolResponse>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n@@ -161,7 +153,6 @@ pub fn handle_document_symbol(\n pub fn handle_workspace_symbol(\n     world: ServerWorld,\n     params: req::WorkspaceSymbolParams,\n-    token: JobToken,\n ) -> Result<Option<Vec<SymbolInformation>>> {\n     let all_symbols = params.query.contains(\"#\");\n     let libs = params.query.contains(\"*\");\n@@ -181,22 +172,21 @@ pub fn handle_workspace_symbol(\n         q.limit(128);\n         q\n     };\n-    let mut res = exec_query(&world, query, &token)?;\n+    let mut res = exec_query(&world, query)?;\n     if res.is_empty() && !all_symbols {\n         let mut query = Query::new(params.query);\n         query.limit(128);\n-        res = exec_query(&world, query, &token)?;\n+        res = exec_query(&world, query)?;\n     }\n \n     return Ok(Some(res));\n \n     fn exec_query(\n         world: &ServerWorld,\n         query: Query,\n-        token: &JobToken,\n     ) -> Result<Vec<SymbolInformation>> {\n         let mut res = Vec::new();\n-        for (file_id, symbol) in world.analysis().symbol_search(query, token) {\n+        for (file_id, symbol) in world.analysis().symbol_search(query)? {\n             let line_index = world.analysis().file_line_index(file_id);\n             let info = SymbolInformation {\n                 name: symbol.name.to_string(),\n@@ -214,15 +204,14 @@ pub fn handle_workspace_symbol(\n pub fn handle_goto_definition(\n     world: ServerWorld,\n     params: req::TextDocumentPositionParams,\n-    token: JobToken,\n ) -> Result<Option<req::GotoDefinitionResponse>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n     let offset = params.position.conv_with(&line_index);\n     let mut res = Vec::new();\n     for (file_id, symbol) in world\n         .analysis()\n-        .approximately_resolve_symbol(file_id, offset, &token)\n+        .approximately_resolve_symbol(file_id, offset)?\n     {\n         let line_index = world.analysis().file_line_index(file_id);\n         let location = to_location(file_id, symbol.node_range, &world, &line_index)?;\n@@ -234,11 +223,10 @@ pub fn handle_goto_definition(\n pub fn handle_parent_module(\n     world: ServerWorld,\n     params: TextDocumentIdentifier,\n-    _token: JobToken,\n ) -> Result<Vec<Location>> {\n     let file_id = params.try_conv_with(&world)?;\n     let mut res = Vec::new();\n-    for (file_id, symbol) in world.analysis().parent_module(file_id) {\n+    for (file_id, symbol) in world.analysis().parent_module(file_id)? {\n         let line_index = world.analysis().file_line_index(file_id);\n         let location = to_location(file_id, symbol.node_range, &world, &line_index)?;\n         res.push(location);\n@@ -249,20 +237,19 @@ pub fn handle_parent_module(\n pub fn handle_runnables(\n     world: ServerWorld,\n     params: req::RunnablesParams,\n-    _token: JobToken,\n ) -> Result<Vec<req::Runnable>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n     let offset = params.position.map(|it| it.conv_with(&line_index));\n     let mut res = Vec::new();\n-    for runnable in world.analysis().runnables(file_id) {\n+    for runnable in world.analysis().runnables(file_id)? {\n         if let Some(offset) = offset {\n             if !contains_offset_nonstrict(runnable.range, offset) {\n                 continue;\n             }\n         }\n \n-        let args = runnable_args(&world, file_id, &runnable.kind);\n+        let args = runnable_args(&world, file_id, &runnable.kind)?;\n \n         let r = req::Runnable {\n             range: runnable.range.conv_with(&line_index),\n@@ -282,9 +269,9 @@ pub fn handle_runnables(\n     }\n     return Ok(res);\n \n-    fn runnable_args(world: &ServerWorld, file_id: FileId, kind: &RunnableKind) -> Vec<String> {\n-        let spec = if let Some(&crate_id) = world.analysis().crate_for(file_id).first() {\n-            let file_id = world.analysis().crate_root(crate_id);\n+    fn runnable_args(world: &ServerWorld, file_id: FileId, kind: &RunnableKind) -> Result<Vec<String>> {\n+        let spec = if let Some(&crate_id) = world.analysis().crate_for(file_id)?.first() {\n+            let file_id = world.analysis().crate_root(crate_id)?;\n             let path = world.path_map.get_path(file_id);\n             world\n                 .workspaces\n@@ -319,7 +306,7 @@ pub fn handle_runnables(\n                 }\n             }\n         }\n-        res\n+        Ok(res)\n     }\n \n     fn spec_args(pkg_name: &str, tgt_name: &str, tgt_kind: TargetKind, buf: &mut Vec<String>) {\n@@ -353,21 +340,19 @@ pub fn handle_runnables(\n pub fn handle_decorations(\n     world: ServerWorld,\n     params: TextDocumentIdentifier,\n-    _token: JobToken,\n ) -> Result<Vec<Decoration>> {\n     let file_id = params.try_conv_with(&world)?;\n-    Ok(highlight(&world, file_id))\n+    highlight(&world, file_id)\n }\n \n pub fn handle_completion(\n     world: ServerWorld,\n     params: req::CompletionParams,\n-    _token: JobToken,\n ) -> Result<Option<req::CompletionResponse>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n     let offset = params.position.conv_with(&line_index);\n-    let items = match world.analysis().completions(file_id, offset) {\n+    let items = match world.analysis().completions(file_id, offset)? {\n         None => return Ok(None),\n         Some(items) => items,\n     };\n@@ -394,7 +379,6 @@ pub fn handle_completion(\n pub fn handle_folding_range(\n     world: ServerWorld,\n     params: FoldingRangeParams,\n-    _token: JobToken,\n ) -> Result<Option<Vec<FoldingRange>>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n@@ -427,7 +411,6 @@ pub fn handle_folding_range(\n pub fn handle_signature_help(\n     world: ServerWorld,\n     params: req::TextDocumentPositionParams,\n-    token: JobToken,\n ) -> Result<Option<req::SignatureHelp>> {\n     use languageserver_types::{ParameterInformation, SignatureInformation};\n \n@@ -436,7 +419,7 @@ pub fn handle_signature_help(\n     let offset = params.position.conv_with(&line_index);\n \n     if let Some((descriptor, active_param)) =\n-        world.analysis().resolve_callable(file_id, offset, &token)\n+        world.analysis().resolve_callable(file_id, offset)?\n     {\n         let parameters: Vec<ParameterInformation> = descriptor\n             .params\n@@ -466,15 +449,14 @@ pub fn handle_signature_help(\n pub fn handle_prepare_rename(\n     world: ServerWorld,\n     params: req::TextDocumentPositionParams,\n-    token: JobToken,\n ) -> Result<Option<PrepareRenameResponse>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n     let offset = params.position.conv_with(&line_index);\n \n     // We support renaming references like handle_rename does.\n     // In the future we may want to reject the renaming of things like keywords here too.\n-    let refs = world.analysis().find_all_refs(file_id, offset, &token);\n+    let refs = world.analysis().find_all_refs(file_id, offset)?;\n     if refs.is_empty() {\n         return Ok(None);\n     }\n@@ -488,7 +470,6 @@ pub fn handle_prepare_rename(\n pub fn handle_rename(\n     world: ServerWorld,\n     params: RenameParams,\n-    token: JobToken,\n ) -> Result<Option<WorkspaceEdit>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n@@ -498,7 +479,7 @@ pub fn handle_rename(\n         return Ok(None);\n     }\n \n-    let refs = world.analysis().find_all_refs(file_id, offset, &token);\n+    let refs = world.analysis().find_all_refs(file_id, offset)?;\n     if refs.is_empty() {\n         return Ok(None);\n     }\n@@ -525,13 +506,12 @@ pub fn handle_rename(\n pub fn handle_references(\n     world: ServerWorld,\n     params: req::ReferenceParams,\n-    token: JobToken,\n ) -> Result<Option<Vec<Location>>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n     let offset = params.position.conv_with(&line_index);\n \n-    let refs = world.analysis().find_all_refs(file_id, offset, &token);\n+    let refs = world.analysis().find_all_refs(file_id, offset)?;\n \n     Ok(Some(refs.into_iter()\n         .filter_map(|r| to_location(r.0, r.1, &world, &line_index).ok())\n@@ -541,16 +521,15 @@ pub fn handle_references(\n pub fn handle_code_action(\n     world: ServerWorld,\n     params: req::CodeActionParams,\n-    _token: JobToken,\n ) -> Result<Option<CodeActionResponse>> {\n     let file_id = params.text_document.try_conv_with(&world)?;\n     let line_index = world.analysis().file_line_index(file_id);\n     let range = params.range.conv_with(&line_index);\n \n-    let assists = world.analysis().assists(file_id, range).into_iter();\n+    let assists = world.analysis().assists(file_id, range)?.into_iter();\n     let fixes = world\n         .analysis()\n-        .diagnostics(file_id)\n+        .diagnostics(file_id)?\n         .into_iter()\n         .filter_map(|d| Some((d.range, d.fix?)))\n         .filter(|(range, _fix)| contains_offset_nonstrict(*range, range.start()))\n@@ -579,7 +558,7 @@ pub fn publish_diagnostics(\n     let line_index = world.analysis().file_line_index(file_id);\n     let diagnostics = world\n         .analysis()\n-        .diagnostics(file_id)\n+        .diagnostics(file_id)?\n         .into_iter()\n         .map(|d| Diagnostic {\n             range: d.range.conv_with(&line_index),\n@@ -600,19 +579,20 @@ pub fn publish_decorations(\n     let uri = world.file_id_to_uri(file_id)?;\n     Ok(req::PublishDecorationsParams {\n         uri,\n-        decorations: highlight(&world, file_id),\n+        decorations: highlight(&world, file_id)?,\n     })\n }\n \n-fn highlight(world: &ServerWorld, file_id: FileId) -> Vec<Decoration> {\n+fn highlight(world: &ServerWorld, file_id: FileId) -> Result<Vec<Decoration>> {\n     let line_index = world.analysis().file_line_index(file_id);\n-    world\n+    let res = world\n         .analysis()\n-        .highlight(file_id)\n+        .highlight(file_id)?\n         .into_iter()\n         .map(|h| Decoration {\n             range: h.range.conv_with(&line_index),\n             tag: h.tag,\n         })\n-        .collect()\n+        .collect();\n+    Ok(res)\n }"}, {"sha": "b35ebd38b69a05ef9910eb9cfb136805f617e080", "filename": "crates/ra_lsp_server/src/main_loop/mod.rs", "status": "modified", "additions": 17, "deletions": 21, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fmain_loop%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fmain_loop%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_lsp_server%2Fsrc%2Fmain_loop%2Fmod.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -8,9 +8,9 @@ use gen_lsp_server::{\n     handle_shutdown, ErrorCode, RawMessage, RawNotification, RawRequest, RawResponse,\n };\n use languageserver_types::NumberOrString;\n-use ra_analysis::{FileId, JobHandle, JobToken, LibraryData};\n+use ra_analysis::{FileId, LibraryData};\n use rayon::{self, ThreadPool};\n-use rustc_hash::FxHashMap;\n+use rustc_hash::FxHashSet;\n use serde::{de::DeserializeOwned, Serialize};\n \n use crate::{\n@@ -47,7 +47,7 @@ pub fn main_loop(\n     info!(\"server initialized, serving requests\");\n     let mut state = ServerWorldState::new();\n \n-    let mut pending_requests = FxHashMap::default();\n+    let mut pending_requests = FxHashSet::default();\n     let mut subs = Subscriptions::new();\n     let main_res = main_loop_inner(\n         internal_mode,\n@@ -92,7 +92,7 @@ fn main_loop_inner(\n     fs_worker: Worker<PathBuf, (PathBuf, Vec<FileEvent>)>,\n     ws_worker: Worker<PathBuf, Result<CargoWorkspace>>,\n     state: &mut ServerWorldState,\n-    pending_requests: &mut FxHashMap<u64, JobHandle>,\n+    pending_requests: &mut FxHashSet<u64>,\n     subs: &mut Subscriptions,\n ) -> Result<()> {\n     let (libdata_sender, libdata_receiver) = unbounded();\n@@ -204,22 +204,21 @@ fn main_loop_inner(\n fn on_task(\n     task: Task,\n     msg_sender: &Sender<RawMessage>,\n-    pending_requests: &mut FxHashMap<u64, JobHandle>,\n+    pending_requests: &mut FxHashSet<u64>,\n ) {\n     match task {\n         Task::Respond(response) => {\n-            if let Some(handle) = pending_requests.remove(&response.id) {\n-                assert!(handle.has_completed());\n+            if pending_requests.remove(&response.id) {\n+                msg_sender.send(RawMessage::Response(response))\n             }\n-            msg_sender.send(RawMessage::Response(response))\n         }\n         Task::Notify(n) => msg_sender.send(RawMessage::Notification(n)),\n     }\n }\n \n fn on_request(\n     world: &mut ServerWorldState,\n-    pending_requests: &mut FxHashMap<u64, JobHandle>,\n+    pending_requests: &mut FxHashSet<u64>,\n     pool: &ThreadPool,\n     sender: &Sender<Task>,\n     req: RawRequest,\n@@ -253,8 +252,8 @@ fn on_request(\n         .on::<req::References>(handlers::handle_references)?\n         .finish();\n     match req {\n-        Ok((id, handle)) => {\n-            let inserted = pending_requests.insert(id, handle).is_none();\n+        Ok(id) => {\n+            let inserted = pending_requests.insert(id);\n             assert!(inserted, \"duplicate request: {}\", id);\n             Ok(None)\n         }\n@@ -265,7 +264,7 @@ fn on_request(\n fn on_notification(\n     msg_sender: &Sender<RawMessage>,\n     state: &mut ServerWorldState,\n-    pending_requests: &mut FxHashMap<u64, JobHandle>,\n+    pending_requests: &mut FxHashSet<u64>,\n     subs: &mut Subscriptions,\n     not: RawNotification,\n ) -> Result<()> {\n@@ -277,9 +276,7 @@ fn on_notification(\n                     panic!(\"string id's not supported: {:?}\", id);\n                 }\n             };\n-            if let Some(handle) = pending_requests.remove(&id) {\n-                handle.cancel();\n-            }\n+            pending_requests.remove(&id);\n             return Ok(());\n         }\n         Err(not) => not,\n@@ -336,7 +333,7 @@ fn on_notification(\n \n struct PoolDispatcher<'a> {\n     req: Option<RawRequest>,\n-    res: Option<(u64, JobHandle)>,\n+    res: Option<u64>,\n     pool: &'a ThreadPool,\n     world: &'a ServerWorldState,\n     sender: &'a Sender<Task>,\n@@ -345,7 +342,7 @@ struct PoolDispatcher<'a> {\n impl<'a> PoolDispatcher<'a> {\n     fn on<'b, R>(\n         &'b mut self,\n-        f: fn(ServerWorld, R::Params, JobToken) -> Result<R::Result>,\n+        f: fn(ServerWorld, R::Params) -> Result<R::Result>,\n     ) -> Result<&'b mut Self>\n     where\n         R: req::Request,\n@@ -358,11 +355,10 @@ impl<'a> PoolDispatcher<'a> {\n         };\n         match req.cast::<R>() {\n             Ok((id, params)) => {\n-                let (handle, token) = JobHandle::new();\n                 let world = self.world.snapshot();\n                 let sender = self.sender.clone();\n                 self.pool.spawn(move || {\n-                    let resp = match f(world, params, token) {\n+                    let resp = match f(world, params) {\n                         Ok(resp) => RawResponse::ok::<R>(id, &resp),\n                         Err(e) => {\n                             RawResponse::err(id, ErrorCode::InternalError as i32, e.to_string())\n@@ -371,14 +367,14 @@ impl<'a> PoolDispatcher<'a> {\n                     let task = Task::Respond(resp);\n                     sender.send(task);\n                 });\n-                self.res = Some((id, handle));\n+                self.res = Some(id);\n             }\n             Err(req) => self.req = Some(req),\n         }\n         Ok(self)\n     }\n \n-    fn finish(&mut self) -> ::std::result::Result<(u64, JobHandle), RawRequest> {\n+    fn finish(&mut self) -> ::std::result::Result<u64, RawRequest> {\n         match (self.res.take(), self.req.take()) {\n             (Some(res), None) => Ok(res),\n             (None, Some(req)) => Err(req),"}, {"sha": "d3282938267ba3cf3e3f799a1ba1474d5e5e7bec", "filename": "crates/ra_lsp_server/src/path_map.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fpath_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fpath_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_lsp_server%2Fsrc%2Fpath_map.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,9 +1,9 @@\n+use std::path::{Component, Path, PathBuf};\n+\n use im;\n use ra_analysis::{FileId, FileResolver};\n use relative_path::RelativePath;\n \n-use std::path::{Component, Path, PathBuf};\n-\n #[derive(Debug, Clone, Copy, PartialEq, Eq)]\n pub enum Root {\n     Workspace,"}, {"sha": "04e2ef9c852f95418f185f1922eaf452e1b9f13c", "filename": "crates/ra_lsp_server/src/project_model.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fproject_model.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fproject_model.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_lsp_server%2Fsrc%2Fproject_model.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,9 +1,9 @@\n+use std::path::{Path, PathBuf};\n+\n use cargo_metadata::{metadata_run, CargoOpt};\n use ra_syntax::SmolStr;\n use rustc_hash::{FxHashMap, FxHashSet};\n \n-use std::path::{Path, PathBuf};\n-\n use crate::{\n     thread_watcher::{ThreadWatcher, Worker},\n     Result,"}, {"sha": "51b35fa6679d119a9869115fd06d5afd0661ed99", "filename": "crates/ra_lsp_server/src/thread_watcher.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fthread_watcher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd336d1134d405d833b762101a25c00076bc7fd2/crates%2Fra_lsp_server%2Fsrc%2Fthread_watcher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_lsp_server%2Fsrc%2Fthread_watcher.rs?ref=fd336d1134d405d833b762101a25c00076bc7fd2", "patch": "@@ -1,8 +1,9 @@\n-use crate::Result;\n+use std::thread;\n+\n use crossbeam_channel::{bounded, unbounded, Receiver, Sender};\n use drop_bomb::DropBomb;\n \n-use std::thread;\n+use crate::Result;\n \n pub struct Worker<I, O> {\n     pub inp: Sender<I>,"}]}