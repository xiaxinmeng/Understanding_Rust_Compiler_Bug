{"sha": "95b7e6fe92b925ddde0656d334862d225a2fdb77", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk1YjdlNmZlOTJiOTI1ZGRkZTA2NTZkMzM0ODYyZDIyNWEyZmRiNzc=", "commit": {"author": {"name": "kennytm", "email": "kennytm@gmail.com", "date": "2018-04-14T07:21:19Z"}, "committer": {"name": "kennytm", "email": "kennytm@gmail.com", "date": "2018-04-14T07:21:19Z"}, "message": "Rollup merge of #49852 - alexcrichton:fix-more-proc-macros, r=nrc\n\nproc_macro: Avoid cached TokenStream more often\n\nThis commit adds even more pessimization to use the cached `TokenStream` inside\nof an AST node. As a reminder the `proc_macro` API requires taking an arbitrary\nAST node and transforming it back into a `TokenStream` to hand off to a\nprocedural macro. Such functionality isn't actually implemented in rustc today,\nso the way `proc_macro` works today is that it stringifies an AST node and then\nreparses for a list of tokens.\n\nThis strategy unfortunately loses all span information, so we try to avoid it\nwhenever possible. Implemented in #43230 some AST nodes have a `TokenStream`\ncache representing the tokens they were originally parsed from. This\n`TokenStream` cache, however, has turned out to not always reflect the current\nstate of the item when it's being tokenized. For example `#[cfg]` processing or\nmacro expansion could modify the state of an item. Consequently we've seen a\nnumber of bugs (#48644 and #49846) related to using this stale cache.\n\nThis commit tweaks the usage of the cached `TokenStream` to compare it to our\nlossy stringification of the token stream. If the tokens that make up the cache\nand the stringified token stream are the same then we return the cached version\n(which has correct span information). If they differ, however, then we will\nreturn the stringified version as the cache has been invalidated and we just\nhaven't figured that out.\n\nCloses #48644\nCloses #49846", "tree": {"sha": "6d74a8ca3cbf60269eb9f38d03707caccc03aa7a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6d74a8ca3cbf60269eb9f38d03707caccc03aa7a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/95b7e6fe92b925ddde0656d334862d225a2fdb77", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEZ1R8CLMp8f2GxWoQ/vbIBR0OATwFAlrRq+8ACgkQ/vbIBR0O\nATxnGA/9FtkjVQOzdKz6Bp2o/mIS8HE37oVA0dFUVOtfQUFL9H9iM3S7yjZzki3S\n4U6pT6K3nquhEen6v2EEOTotcnRCQBlkIpAr+jbZKwxAMJcwviDk8fF2pMoDKI3a\n5PRsfdpDK5XkCSmzRc3xSGX86qbjb7LijCP1S0RLnQUUywMhbDwncSWEtrkxJYyn\nunc9n4ujCoe2NOqrOCk2W5j7Uv1g4cMz2mLprr2tGVdSSVgJMnWWkq71phLfcGea\nnb7LKAFf9Ui2R/U7ODRTH0pMrLHMjZRiRbVBFBn14rzSf666loR4oQi0mDH0gA0J\n41qhRtodFzaGuQKenWWqj23kVzzdQhz1KFeWzahNQYHv+0r3TkH3Cah1tf09ZURg\noljMBCRQqSCZIjZAsICSjl/IUssesXFlL/tYqEiFEipgWkAQrQGTQI2kjc17vz5Z\nU8Eq0cVVJu/w+xtUK2tSwxU4P62znAJAxZKYIHxRiucrc8CV90BuA0hHATQIFlYk\nMyMSciKcHpDICtli4lZxhYscc4SsQHd1v5tkHwfJVC/lkhJK3y+PL53GWFgWGPgH\nl4ldsfHS9abmlayuQ2yJHCBf7c45spxKPtR9B0hMvIEAK7ytR0TZxgDCu5fsqYT5\nRAJWwYTmH46Mp5AE+WR/+cI8rdeZlkPlkG4N8SEd8QXfUaiiy5c=\n=6Kfk\n-----END PGP SIGNATURE-----", "payload": "tree 6d74a8ca3cbf60269eb9f38d03707caccc03aa7a\nparent fbbc9907b1609dc5be65e658e74ea6aa77366542\nparent 6d7cfd4f1ac571f1d9b29f5ddf836909fe5f127b\nauthor kennytm <kennytm@gmail.com> 1523690479 +0800\ncommitter kennytm <kennytm@gmail.com> 1523690479 +0800\n\nRollup merge of #49852 - alexcrichton:fix-more-proc-macros, r=nrc\n\nproc_macro: Avoid cached TokenStream more often\n\nThis commit adds even more pessimization to use the cached `TokenStream` inside\nof an AST node. As a reminder the `proc_macro` API requires taking an arbitrary\nAST node and transforming it back into a `TokenStream` to hand off to a\nprocedural macro. Such functionality isn't actually implemented in rustc today,\nso the way `proc_macro` works today is that it stringifies an AST node and then\nreparses for a list of tokens.\n\nThis strategy unfortunately loses all span information, so we try to avoid it\nwhenever possible. Implemented in #43230 some AST nodes have a `TokenStream`\ncache representing the tokens they were originally parsed from. This\n`TokenStream` cache, however, has turned out to not always reflect the current\nstate of the item when it's being tokenized. For example `#[cfg]` processing or\nmacro expansion could modify the state of an item. Consequently we've seen a\nnumber of bugs (#48644 and #49846) related to using this stale cache.\n\nThis commit tweaks the usage of the cached `TokenStream` to compare it to our\nlossy stringification of the token stream. If the tokens that make up the cache\nand the stringified token stream are the same then we return the cached version\n(which has correct span information). If they differ, however, then we will\nreturn the stringified version as the cache has been invalidated and we just\nhaven't figured that out.\n\nCloses #48644\nCloses #49846\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/95b7e6fe92b925ddde0656d334862d225a2fdb77", "html_url": "https://github.com/rust-lang/rust/commit/95b7e6fe92b925ddde0656d334862d225a2fdb77", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/95b7e6fe92b925ddde0656d334862d225a2fdb77/comments", "author": {"login": "kennytm", "id": 103023, "node_id": "MDQ6VXNlcjEwMzAyMw==", "avatar_url": "https://avatars.githubusercontent.com/u/103023?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kennytm", "html_url": "https://github.com/kennytm", "followers_url": "https://api.github.com/users/kennytm/followers", "following_url": "https://api.github.com/users/kennytm/following{/other_user}", "gists_url": "https://api.github.com/users/kennytm/gists{/gist_id}", "starred_url": "https://api.github.com/users/kennytm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kennytm/subscriptions", "organizations_url": "https://api.github.com/users/kennytm/orgs", "repos_url": "https://api.github.com/users/kennytm/repos", "events_url": "https://api.github.com/users/kennytm/events{/privacy}", "received_events_url": "https://api.github.com/users/kennytm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "kennytm", "id": 103023, "node_id": "MDQ6VXNlcjEwMzAyMw==", "avatar_url": "https://avatars.githubusercontent.com/u/103023?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kennytm", "html_url": "https://github.com/kennytm", "followers_url": "https://api.github.com/users/kennytm/followers", "following_url": "https://api.github.com/users/kennytm/following{/other_user}", "gists_url": "https://api.github.com/users/kennytm/gists{/gist_id}", "starred_url": "https://api.github.com/users/kennytm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kennytm/subscriptions", "organizations_url": "https://api.github.com/users/kennytm/orgs", "repos_url": "https://api.github.com/users/kennytm/repos", "events_url": "https://api.github.com/users/kennytm/events{/privacy}", "received_events_url": "https://api.github.com/users/kennytm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fbbc9907b1609dc5be65e658e74ea6aa77366542", "url": "https://api.github.com/repos/rust-lang/rust/commits/fbbc9907b1609dc5be65e658e74ea6aa77366542", "html_url": "https://github.com/rust-lang/rust/commit/fbbc9907b1609dc5be65e658e74ea6aa77366542"}, {"sha": "6d7cfd4f1ac571f1d9b29f5ddf836909fe5f127b", "url": "https://api.github.com/repos/rust-lang/rust/commits/6d7cfd4f1ac571f1d9b29f5ddf836909fe5f127b", "html_url": "https://github.com/rust-lang/rust/commit/6d7cfd4f1ac571f1d9b29f5ddf836909fe5f127b"}], "stats": {"total": 133, "additions": 121, "deletions": 12}, "files": [{"sha": "0913ed8614792b9ecc73c368bb8db6cccb934f77", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 22, "deletions": 9, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=95b7e6fe92b925ddde0656d334862d225a2fdb77", "patch": "@@ -527,8 +527,17 @@ impl Token {\n         // all span information.\n         //\n         // As a result, some AST nodes are annotated with the token\n-        // stream they came from. Attempt to extract these lossless\n-        // token streams before we fall back to the stringification.\n+        // stream they came from. Here we attempt to extract these\n+        // lossless token streams before we fall back to the\n+        // stringification.\n+        //\n+        // During early phases of the compiler, though, the AST could\n+        // get modified directly (e.g. attributes added or removed) and\n+        // the internal cache of tokens my not be invalidated or\n+        // updated. Consequently if the \"lossless\" token stream\n+        // disagrees with our actuall stringification (which has\n+        // historically been much more battle-tested) then we go with\n+        // the lossy stream anyway (losing span information).\n         let mut tokens = None;\n \n         match nt.0 {\n@@ -555,13 +564,17 @@ impl Token {\n             _ => {}\n         }\n \n-        tokens.unwrap_or_else(|| {\n-            nt.1.force(|| {\n-                // FIXME(jseyfried): Avoid this pretty-print + reparse hack\n-                let source = pprust::token_to_string(self);\n-                parse_stream_from_source_str(FileName::MacroExpansion, source, sess, Some(span))\n-            })\n-        })\n+        let tokens_for_real = nt.1.force(|| {\n+            // FIXME(#43081): Avoid this pretty-print + reparse hack\n+            let source = pprust::token_to_string(self);\n+            parse_stream_from_source_str(FileName::MacroExpansion, source, sess, Some(span))\n+        });\n+        if let Some(tokens) = tokens {\n+            if tokens.eq_unspanned(&tokens_for_real) {\n+                return tokens\n+            }\n+        }\n+        return tokens_for_real\n     }\n }\n "}, {"sha": "6ac04b3cdf6c437bd4dcd67b914ef7b91e7298c8", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=95b7e6fe92b925ddde0656d334862d225a2fdb77", "patch": "@@ -118,7 +118,7 @@ impl TokenTree {\n             (&TokenTree::Token(_, ref tk), &TokenTree::Token(_, ref tk2)) => tk == tk2,\n             (&TokenTree::Delimited(_, ref dl), &TokenTree::Delimited(_, ref dl2)) => {\n                 dl.delim == dl2.delim &&\n-                dl.stream().trees().zip(dl2.stream().trees()).all(|(tt, tt2)| tt.eq_unspanned(&tt2))\n+                dl.stream().eq_unspanned(&dl2.stream())\n             }\n             (_, _) => false,\n         }\n@@ -240,12 +240,14 @@ impl TokenStream {\n \n     /// Compares two TokenStreams, checking equality without regarding span information.\n     pub fn eq_unspanned(&self, other: &TokenStream) -> bool {\n-        for (t1, t2) in self.trees().zip(other.trees()) {\n+        let mut t1 = self.trees();\n+        let mut t2 = other.trees();\n+        for (t1, t2) in t1.by_ref().zip(t2.by_ref()) {\n             if !t1.eq_unspanned(&t2) {\n                 return false;\n             }\n         }\n-        true\n+        t1.next().is_none() && t2.next().is_none()\n     }\n \n     /// Precondition: `self` consists of a single token tree."}, {"sha": "6f8c649c6b56cfe22a56ea6baef5434953b4c95b", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/modify-ast.rs", "status": "added", "additions": 57, "deletions": 0, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fmodify-ast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fmodify-ast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fmodify-ast.rs?ref=95b7e6fe92b925ddde0656d334862d225a2fdb77", "patch": "@@ -0,0 +1,57 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// no-prefer-dynamic\n+\n+#![crate_type = \"proc-macro\"]\n+#![feature(proc_macro)]\n+\n+extern crate proc_macro;\n+\n+use proc_macro::*;\n+\n+#[proc_macro_attribute]\n+pub fn assert1(_a: TokenStream, b: TokenStream) -> TokenStream {\n+    assert_eq(b.clone(), \"pub fn foo() {}\".parse().unwrap());\n+    b\n+}\n+\n+#[proc_macro_derive(Foo, attributes(foo))]\n+pub fn assert2(a: TokenStream) -> TokenStream {\n+    assert_eq(a, \"pub struct MyStructc { _a: i32, }\".parse().unwrap());\n+    TokenStream::empty()\n+}\n+\n+fn assert_eq(a: TokenStream, b: TokenStream) {\n+    let mut a = a.into_iter();\n+    let mut b = b.into_iter();\n+    for (a, b) in a.by_ref().zip(&mut b) {\n+        match (a, b) {\n+            (TokenTree::Group(a), TokenTree::Group(b)) => {\n+                assert_eq!(a.delimiter(), b.delimiter());\n+                assert_eq(a.stream(), b.stream());\n+            }\n+            (TokenTree::Op(a), TokenTree::Op(b)) => {\n+                assert_eq!(a.op(), b.op());\n+                assert_eq!(a.spacing(), b.spacing());\n+            }\n+            (TokenTree::Literal(a), TokenTree::Literal(b)) => {\n+                assert_eq!(a.to_string(), b.to_string());\n+            }\n+            (TokenTree::Term(a), TokenTree::Term(b)) => {\n+                assert_eq!(a.to_string(), b.to_string());\n+            }\n+            (a, b) => panic!(\"{:?} != {:?}\", a, b),\n+        }\n+    }\n+\n+    assert!(a.next().is_none());\n+    assert!(b.next().is_none());\n+}"}, {"sha": "13a6dbd2ae576613863e0d0a32f30f8173ab0094", "filename": "src/test/run-pass-fulldeps/proc-macro/modify-ast.rs", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fmodify-ast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/95b7e6fe92b925ddde0656d334862d225a2fdb77/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fmodify-ast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fmodify-ast.rs?ref=95b7e6fe92b925ddde0656d334862d225a2fdb77", "patch": "@@ -0,0 +1,37 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:modify-ast.rs\n+\n+#![feature(proc_macro)]\n+\n+extern crate modify_ast;\n+\n+use modify_ast::*;\n+\n+#[derive(Foo)]\n+pub struct MyStructc {\n+    #[cfg_attr(my_cfg, foo)]\n+    _a: i32,\n+}\n+\n+macro_rules! a {\n+    ($i:item) => ($i)\n+}\n+\n+a! {\n+    #[assert1]\n+    pub fn foo() {}\n+}\n+\n+fn main() {\n+    let _a = MyStructc { _a: 0 };\n+    foo();\n+}"}]}