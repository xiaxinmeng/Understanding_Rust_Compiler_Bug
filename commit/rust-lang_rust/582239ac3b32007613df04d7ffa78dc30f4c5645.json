{"sha": "582239ac3b32007613df04d7ffa78dc30f4c5645", "node_id": "C_kwDOAAsO6NoAKDU4MjIzOWFjM2IzMjAwNzYxM2RmMDRkN2ZmYTc4ZGMzMGY0YzU2NDU", "commit": {"author": {"name": "Jubilee", "email": "46493976+workingjubilee@users.noreply.github.com", "date": "2022-12-04T20:25:09Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-12-04T20:25:09Z"}, "message": "Merge pull request #128 from miguelraz/dotprodexample\n\nadd dot_product example", "tree": {"sha": "acb22bd7c8041f27df3b5a6f775408914f531de2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/acb22bd7c8041f27df3b5a6f775408914f531de2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/582239ac3b32007613df04d7ffa78dc30f4c5645", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJjjQIlCRBK7hj4Ov3rIwAARPQIAKYrZqtnTpOEuXT6vnp/EjbH\nzv4jj2WT+iZri3xpH4tNm5cHCy5T2O2QO9uLZD1rME8maGDJKUcNvhIVb12Bn9V9\ndEjshTt8gJYLCFe1ukSA+DKTk1ftiBWEUEi3UMOvnhO0cVDElY+GofCMP45WNsmO\nSfMdYKEASuZw7h273VthQt06Ukc1vZZHrgs1ffFmPrJoHUBQEZdsyLp7eTlWDZzW\nkylzzUvNu0/kzSLaJ1h2eW2JVh+vV/4vbafMU+ubf5IGGIPHZpGI6m6gLxtjQWpl\n+kQfxqMAHN/6MFM2y2NvE+YQwF1r4YH0IS2oBEmr/ZuqkILOGoWFt85ol/rVMPo=\n=34hR\n-----END PGP SIGNATURE-----\n", "payload": "tree acb22bd7c8041f27df3b5a6f775408914f531de2\nparent 1547dd66f9c3c2ba9e4998f8d4885e4f7bd62c52\nparent da3bd6d3a04f84ebc7fc6314f2e1f8a74e379018\nauthor Jubilee <46493976+workingjubilee@users.noreply.github.com> 1670185509 -0800\ncommitter GitHub <noreply@github.com> 1670185509 -0800\n\nMerge pull request #128 from miguelraz/dotprodexample\n\nadd dot_product example"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/582239ac3b32007613df04d7ffa78dc30f4c5645", "html_url": "https://github.com/rust-lang/rust/commit/582239ac3b32007613df04d7ffa78dc30f4c5645", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/582239ac3b32007613df04d7ffa78dc30f4c5645/comments", "author": {"login": "workingjubilee", "id": 46493976, "node_id": "MDQ6VXNlcjQ2NDkzOTc2", "avatar_url": "https://avatars.githubusercontent.com/u/46493976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/workingjubilee", "html_url": "https://github.com/workingjubilee", "followers_url": "https://api.github.com/users/workingjubilee/followers", "following_url": "https://api.github.com/users/workingjubilee/following{/other_user}", "gists_url": "https://api.github.com/users/workingjubilee/gists{/gist_id}", "starred_url": "https://api.github.com/users/workingjubilee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/workingjubilee/subscriptions", "organizations_url": "https://api.github.com/users/workingjubilee/orgs", "repos_url": "https://api.github.com/users/workingjubilee/repos", "events_url": "https://api.github.com/users/workingjubilee/events{/privacy}", "received_events_url": "https://api.github.com/users/workingjubilee/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1547dd66f9c3c2ba9e4998f8d4885e4f7bd62c52", "url": "https://api.github.com/repos/rust-lang/rust/commits/1547dd66f9c3c2ba9e4998f8d4885e4f7bd62c52", "html_url": "https://github.com/rust-lang/rust/commit/1547dd66f9c3c2ba9e4998f8d4885e4f7bd62c52"}, {"sha": "da3bd6d3a04f84ebc7fc6314f2e1f8a74e379018", "url": "https://api.github.com/repos/rust-lang/rust/commits/da3bd6d3a04f84ebc7fc6314f2e1f8a74e379018", "html_url": "https://github.com/rust-lang/rust/commit/da3bd6d3a04f84ebc7fc6314f2e1f8a74e379018"}], "stats": {"total": 182, "additions": 182, "deletions": 0}, "files": [{"sha": "82747f1b5a6f9c7091f7d3e1ad13d357d9619efb", "filename": "crates/core_simd/examples/README.md", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/582239ac3b32007613df04d7ffa78dc30f4c5645/crates%2Fcore_simd%2Fexamples%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/582239ac3b32007613df04d7ffa78dc30f4c5645/crates%2Fcore_simd%2Fexamples%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fexamples%2FREADME.md?ref=582239ac3b32007613df04d7ffa78dc30f4c5645", "patch": "@@ -0,0 +1,13 @@\n+### `stdsimd` examples\n+\n+This crate is a port of example uses of `stdsimd`, mostly taken from the `packed_simd` crate.\n+\n+The examples contain, as in the case of `dot_product.rs`, multiple ways of solving the problem, in order to show idiomatic uses of SIMD and iteration of performance designs.\n+\n+Run the tests with the command \n+\n+```\n+cargo run --example dot_product\n+```\n+\n+and verify the code for `dot_product.rs` on your machine."}, {"sha": "391f08f55a07a37d54c33414cc7c0ea0449781b3", "filename": "crates/core_simd/examples/dot_product.rs", "status": "added", "additions": 169, "deletions": 0, "changes": 169, "blob_url": "https://github.com/rust-lang/rust/blob/582239ac3b32007613df04d7ffa78dc30f4c5645/crates%2Fcore_simd%2Fexamples%2Fdot_product.rs", "raw_url": "https://github.com/rust-lang/rust/raw/582239ac3b32007613df04d7ffa78dc30f4c5645/crates%2Fcore_simd%2Fexamples%2Fdot_product.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fexamples%2Fdot_product.rs?ref=582239ac3b32007613df04d7ffa78dc30f4c5645", "patch": "@@ -0,0 +1,169 @@\n+// Code taken from the `packed_simd` crate\n+// Run this code with `cargo test --example dot_product`\n+//use std::iter::zip;\n+\n+#![feature(array_chunks)]\n+#![feature(slice_as_chunks)]\n+// Add these imports to use the stdsimd library\n+#![feature(portable_simd)]\n+use core_simd::simd::*;\n+\n+// This is your barebones dot product implementation:\n+// Take 2 vectors, multiply them element wise and *then*\n+// go along the resulting array and add up the result.\n+// In the next example we will see if there\n+//  is any difference to adding and multiplying in tandem.\n+pub fn dot_prod_scalar_0(a: &[f32], b: &[f32]) -> f32 {\n+    assert_eq!(a.len(), b.len());\n+\n+    a.iter().zip(b.iter()).map(|(a, b)| a * b).sum()\n+}\n+\n+// When dealing with SIMD, it is very important to think about the amount\n+// of data movement and when it happens. We're going over simple computation examples here, and yet\n+// it is not trivial to understand what may or may not contribute to performance\n+// changes. Eventually, you will need tools to inspect the generated assembly and confirm your\n+// hypothesis and benchmarks - we will mention them later on.\n+// With the use of `fold`, we're doing a multiplication,\n+// and then adding it to the sum, one element from both vectors at a time.\n+pub fn dot_prod_scalar_1(a: &[f32], b: &[f32]) -> f32 {\n+    assert_eq!(a.len(), b.len());\n+    a.iter()\n+        .zip(b.iter())\n+        .fold(0.0, |a, zipped| a + zipped.0 * zipped.1)\n+}\n+\n+// We now move on to the SIMD implementations: notice the following constructs:\n+// `array_chunks::<4>`: mapping this over the vector will let use construct SIMD vectors\n+// `f32x4::from_array`: construct the SIMD vector from a slice\n+// `(a * b).reduce_sum()`: Multiply both f32x4 vectors together, and then reduce them.\n+// This approach essentially uses SIMD to produce a vector of length N/4 of all the products,\n+// and then add those with `sum()`. This is suboptimal.\n+// TODO: ASCII diagrams\n+pub fn dot_prod_simd_0(a: &[f32], b: &[f32]) -> f32 {\n+    assert_eq!(a.len(), b.len());\n+    // TODO handle remainder when a.len() % 4 != 0\n+    a.array_chunks::<4>()\n+        .map(|&a| f32x4::from_array(a))\n+        .zip(b.array_chunks::<4>().map(|&b| f32x4::from_array(b)))\n+        .map(|(a, b)| (a * b).reduce_sum())\n+        .sum()\n+}\n+\n+// There's some simple ways to improve the previous code:\n+// 1. Make a `zero` `f32x4` SIMD vector that we will be accumulating into\n+// So that there is only one `sum()` reduction when the last `f32x4` has been processed\n+// 2. Exploit Fused Multiply Add so that the multiplication, addition and sinking into the reduciton\n+// happen in the same step.\n+// If the arrays are large, minimizing the data shuffling will lead to great perf.\n+// If the arrays are small, handling the remainder elements when the length isn't a multiple of 4\n+// Can become a problem.\n+pub fn dot_prod_simd_1(a: &[f32], b: &[f32]) -> f32 {\n+    assert_eq!(a.len(), b.len());\n+    // TODO handle remainder when a.len() % 4 != 0\n+    a.array_chunks::<4>()\n+        .map(|&a| f32x4::from_array(a))\n+        .zip(b.array_chunks::<4>().map(|&b| f32x4::from_array(b)))\n+        .fold(f32x4::splat(0.0), |acc, zipped| acc + zipped.0 * zipped.1)\n+        .reduce_sum()\n+}\n+\n+// A lot of knowledgeable use of SIMD comes from knowing specific instructions that are\n+// available - let's try to use the `mul_add` instruction, which is the fused-multiply-add we were looking for.\n+use std_float::StdFloat;\n+pub fn dot_prod_simd_2(a: &[f32], b: &[f32]) -> f32 {\n+    assert_eq!(a.len(), b.len());\n+    // TODO handle remainder when a.len() % 4 != 0\n+    let mut res = f32x4::splat(0.0);\n+    a.array_chunks::<4>()\n+        .map(|&a| f32x4::from_array(a))\n+        .zip(b.array_chunks::<4>().map(|&b| f32x4::from_array(b)))\n+        .for_each(|(a, b)| {\n+            res = a.mul_add(b, res);\n+        });\n+    res.reduce_sum()\n+}\n+\n+// Finally, we will write the same operation but handling the loop remainder.\n+const LANES: usize = 4;\n+pub fn dot_prod_simd_3(a: &[f32], b: &[f32]) -> f32 {\n+    assert_eq!(a.len(), b.len());\n+\n+    let (a_extra, a_chunks) = a.as_rchunks();\n+    let (b_extra, b_chunks) = b.as_rchunks();\n+\n+    // These are always true, but for emphasis:\n+    assert_eq!(a_chunks.len(), b_chunks.len());\n+    assert_eq!(a_extra.len(), b_extra.len());\n+\n+    let mut sums = [0.0; LANES];\n+    for ((x, y), d) in std::iter::zip(a_extra, b_extra).zip(&mut sums) {\n+        *d = x * y;\n+    }\n+\n+    let mut sums = f32x4::from_array(sums);\n+    std::iter::zip(a_chunks, b_chunks).for_each(|(x, y)| {\n+        sums += f32x4::from_array(*x) * f32x4::from_array(*y);\n+    });\n+\n+    sums.reduce_sum()\n+}\n+\n+// Finally, we present an iterator version for handling remainders in a scalar fashion at the end of the loop.\n+// Unfortunately, this is allocating 1 `XMM` register on the order of `~len(a)` - we'll see how we can get around it in the\n+// next example.\n+pub fn dot_prod_simd_4(a: &[f32], b: &[f32]) -> f32 {\n+    let mut sum = a\n+        .array_chunks::<4>()\n+        .map(|&a| f32x4::from_array(a))\n+        .zip(b.array_chunks::<4>().map(|&b| f32x4::from_array(b)))\n+        .map(|(a, b)| a * b)\n+        .fold(f32x4::splat(0.0), std::ops::Add::add)\n+        .reduce_sum();\n+    let remain = a.len() - (a.len() % 4);\n+    sum += a[remain..]\n+        .iter()\n+        .zip(&b[remain..])\n+        .map(|(a, b)| a * b)\n+        .sum::<f32>();\n+    sum\n+}\n+\n+// This version allocates a single `XMM` register for accumulation, and the folds don't allocate on top of that.\n+// Notice the the use of `mul_add`, which can do a multiply and an add operation ber iteration.\n+pub fn dot_prod_simd_5(a: &[f32], b: &[f32]) -> f32 {\n+    a.array_chunks::<4>()\n+        .map(|&a| f32x4::from_array(a))\n+        .zip(b.array_chunks::<4>().map(|&b| f32x4::from_array(b)))\n+        .fold(f32x4::splat(0.), |acc, (a, b)| a.mul_add(b, acc))\n+        .reduce_sum()\n+}\n+\n+fn main() {\n+    // Empty main to make cargo happy\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    #[test]\n+    fn smoke_test() {\n+        use super::*;\n+        let a: Vec<f32> = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];\n+        let b: Vec<f32> = vec![-8.0, -7.0, -6.0, -5.0, 4.0, 3.0, 2.0, 1.0];\n+        let x: Vec<f32> = [0.5; 1003].to_vec();\n+        let y: Vec<f32> = [2.0; 1003].to_vec();\n+\n+        // Basic check\n+        assert_eq!(0.0, dot_prod_scalar_0(&a, &b));\n+        assert_eq!(0.0, dot_prod_scalar_1(&a, &b));\n+        assert_eq!(0.0, dot_prod_simd_0(&a, &b));\n+        assert_eq!(0.0, dot_prod_simd_1(&a, &b));\n+        assert_eq!(0.0, dot_prod_simd_2(&a, &b));\n+        assert_eq!(0.0, dot_prod_simd_3(&a, &b));\n+        assert_eq!(0.0, dot_prod_simd_4(&a, &b));\n+        assert_eq!(0.0, dot_prod_simd_5(&a, &b));\n+\n+        // We can handle vectors that are non-multiples of 4\n+        assert_eq!(1003.0, dot_prod_simd_3(&x, &y));\n+    }\n+}"}]}