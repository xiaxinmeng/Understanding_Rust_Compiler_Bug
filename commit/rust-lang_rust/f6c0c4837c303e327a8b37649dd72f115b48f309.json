{"sha": "f6c0c4837c303e327a8b37649dd72f115b48f309", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY2YzBjNDgzN2MzMDNlMzI3YThiMzc2NDlkZDcyZjExNWI0OGYzMDk=", "commit": {"author": {"name": "Austin Bonander", "email": "austin.bonander@gmail.com", "date": "2017-01-08T05:04:49Z"}, "committer": {"name": "Austin Bonander", "email": "austin.bonander@gmail.com", "date": "2017-01-16T07:11:50Z"}, "message": "Refactor `proc_macro::TokenStream` to use `syntax::tokenstream::TokenStream`; fix tests for changed semantics", "tree": {"sha": "8c42911c88a9a5680aee4810e3913a8e15c39b9a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8c42911c88a9a5680aee4810e3913a8e15c39b9a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f6c0c4837c303e327a8b37649dd72f115b48f309", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f6c0c4837c303e327a8b37649dd72f115b48f309", "html_url": "https://github.com/rust-lang/rust/commit/f6c0c4837c303e327a8b37649dd72f115b48f309", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f6c0c4837c303e327a8b37649dd72f115b48f309/comments", "author": {"login": "abonander", "id": 3198595, "node_id": "MDQ6VXNlcjMxOTg1OTU=", "avatar_url": "https://avatars.githubusercontent.com/u/3198595?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abonander", "html_url": "https://github.com/abonander", "followers_url": "https://api.github.com/users/abonander/followers", "following_url": "https://api.github.com/users/abonander/following{/other_user}", "gists_url": "https://api.github.com/users/abonander/gists{/gist_id}", "starred_url": "https://api.github.com/users/abonander/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abonander/subscriptions", "organizations_url": "https://api.github.com/users/abonander/orgs", "repos_url": "https://api.github.com/users/abonander/repos", "events_url": "https://api.github.com/users/abonander/events{/privacy}", "received_events_url": "https://api.github.com/users/abonander/received_events", "type": "User", "site_admin": false}, "committer": {"login": "abonander", "id": 3198595, "node_id": "MDQ6VXNlcjMxOTg1OTU=", "avatar_url": "https://avatars.githubusercontent.com/u/3198595?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abonander", "html_url": "https://github.com/abonander", "followers_url": "https://api.github.com/users/abonander/followers", "following_url": "https://api.github.com/users/abonander/following{/other_user}", "gists_url": "https://api.github.com/users/abonander/gists{/gist_id}", "starred_url": "https://api.github.com/users/abonander/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abonander/subscriptions", "organizations_url": "https://api.github.com/users/abonander/orgs", "repos_url": "https://api.github.com/users/abonander/repos", "events_url": "https://api.github.com/users/abonander/events{/privacy}", "received_events_url": "https://api.github.com/users/abonander/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ff591b6dc0e0a107c778d0bb4cf103881527e1a5", "url": "https://api.github.com/repos/rust-lang/rust/commits/ff591b6dc0e0a107c778d0bb4cf103881527e1a5", "html_url": "https://github.com/rust-lang/rust/commit/ff591b6dc0e0a107c778d0bb4cf103881527e1a5"}], "stats": {"total": 101, "additions": 67, "deletions": 34}, "files": [{"sha": "ab5962779feebca424f0ad1d3045536cc98ad7d8", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 47, "deletions": 26, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=f6c0c4837c303e327a8b37649dd72f115b48f309", "patch": "@@ -39,9 +39,9 @@ extern crate syntax;\n use std::fmt;\n use std::str::FromStr;\n \n-use syntax::ast;\n+use syntax::errors::DiagnosticBuilder;\n use syntax::parse;\n-use syntax::ptr::P;\n+use syntax::tokenstream::TokenStream as TokenStream_;\n \n /// The main type provided by this crate, representing an abstract stream of\n /// tokens.\n@@ -54,7 +54,7 @@ use syntax::ptr::P;\n /// time!\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n pub struct TokenStream {\n-    inner: Vec<P<ast::Item>>,\n+    inner: TokenStream_,\n }\n \n /// Error returned from `TokenStream::from_str`.\n@@ -77,17 +77,41 @@ pub struct LexError {\n #[doc(hidden)]\n pub mod __internal {\n     use std::cell::Cell;\n+    use std::rc::Rc;\n \n     use syntax::ast;\n     use syntax::ptr::P;\n-    use syntax::parse::ParseSess;\n-    use super::TokenStream;\n+    use syntax::parse::{self, token, ParseSess};\n+    use syntax::tokenstream::TokenStream as TokenStream_;\n+\n+    use super::{TokenStream, LexError};\n \n     pub fn new_token_stream(item: P<ast::Item>) -> TokenStream {\n-        TokenStream { inner: vec![item] }\n+        TokenStream { inner: TokenStream_::from_tokens(vec![\n+            token::Interpolated(Rc::new(token::NtItem(item)))\n+        ])}\n+    }\n+\n+    pub fn token_stream_wrap(inner: TokenStream_) -> TokenStream {\n+        TokenStream {\n+            inner: inner\n+        }\n+    }\n+\n+    pub fn token_stream_parse_items(stream: TokenStream) -> Result<Vec<P<ast::Item>>, LexError> {\n+        with_parse_sess(move |sess| {\n+            let mut parser = parse::new_parser_from_ts(sess, stream.inner);\n+            let mut items = Vec::new();\n+\n+            while let Some(item) = try!(parser.parse_item().map_err(super::parse_to_lex_err)) {\n+                items.push(item)\n+            }\n+\n+            Ok(items)\n+        })\n     }\n \n-    pub fn token_stream_items(stream: TokenStream) -> Vec<P<ast::Item>> {\n+    pub fn token_stream_inner(stream: TokenStream) -> TokenStream_ {\n         stream.inner\n     }\n \n@@ -96,6 +120,10 @@ pub mod __internal {\n                                   trait_name: &str,\n                                   expand: fn(TokenStream) -> TokenStream,\n                                   attributes: &[&'static str]);\n+\n+        fn register_attr_proc_macro(&mut self,\n+                                    name: &str,\n+                                    expand: fn(TokenStream, TokenStream) -> TokenStream);\n     }\n \n     // Emulate scoped_thread_local!() here essentially\n@@ -125,11 +153,17 @@ pub mod __internal {\n         where F: FnOnce(&ParseSess) -> R\n     {\n         let p = CURRENT_SESS.with(|p| p.get());\n-        assert!(!p.is_null());\n+        assert!(!p.is_null(), \"proc_macro::__internal::with_parse_sess() called \\\n+                               before set_parse_sess()!\");\n         f(unsafe { &*p })\n     }\n }\n \n+fn parse_to_lex_err(mut err: DiagnosticBuilder) -> LexError {\n+    err.cancel();\n+    LexError { _inner: () }\n+}\n+\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl FromStr for TokenStream {\n     type Err = LexError;\n@@ -138,30 +172,17 @@ impl FromStr for TokenStream {\n         __internal::with_parse_sess(|sess| {\n             let src = src.to_string();\n             let name = \"<proc-macro source code>\".to_string();\n-            let mut parser = parse::new_parser_from_source_str(sess, name, src);\n-            let mut ret = TokenStream { inner: Vec::new() };\n-            loop {\n-                match parser.parse_item() {\n-                    Ok(Some(item)) => ret.inner.push(item),\n-                    Ok(None) => return Ok(ret),\n-                    Err(mut err) => {\n-                        err.cancel();\n-                        return Err(LexError { _inner: () })\n-                    }\n-                }\n-            }\n+            let tts = try!(parse::parse_tts_from_source_str(name, src, sess)\n+                .map_err(parse_to_lex_err));\n+\n+            Ok(__internal::token_stream_wrap(TokenStream_::from_tts(tts)))\n         })\n     }\n }\n \n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl fmt::Display for TokenStream {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        for item in self.inner.iter() {\n-            let item = syntax::print::pprust::item_to_string(item);\n-            try!(f.write_str(&item));\n-            try!(f.write_str(\"\\n\"));\n-        }\n-        Ok(())\n+        self.inner.fmt(f)\n     }\n }"}, {"sha": "2ce6fc03f7731a5d85f230b4c167d6cacc01fa6a", "filename": "src/libsyntax_ext/deriving/custom.rs", "status": "modified", "additions": 15, "deletions": 2, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs?ref=f6c0c4837c303e327a8b37649dd72f115b48f309", "patch": "@@ -77,8 +77,9 @@ impl MultiItemModifier for CustomDerive {\n             let inner = self.inner;\n             panic::catch_unwind(panic::AssertUnwindSafe(|| inner(input)))\n         });\n-        let new_items = match res {\n-            Ok(stream) => __internal::token_stream_items(stream),\n+\n+        let stream = match res {\n+            Ok(stream) => stream,\n             Err(e) => {\n                 let msg = \"custom derive attribute panicked\";\n                 let mut err = ecx.struct_span_fatal(span, msg);\n@@ -94,6 +95,18 @@ impl MultiItemModifier for CustomDerive {\n             }\n         };\n \n+        let new_items = __internal::set_parse_sess(&ecx.parse_sess, || {\n+            match __internal::token_stream_parse_items(stream) {\n+                Ok(new_items) => new_items,\n+                Err(_) => {\n+                    // FIXME: handle this better\n+                    let msg = \"custom derive produced unparseable tokens\";\n+                    ecx.struct_span_fatal(span, msg).emit();\n+                    panic!(FatalError);\n+                }\n+            }\n+        });\n+\n         let mut res = vec![Annotatable::Item(item)];\n         // Reassign spans of all expanded items to the input `item`\n         // for better errors here."}, {"sha": "a5359946c09c2626557ba7fbb023b39f9c7db5e2", "filename": "src/test/compile-fail-fulldeps/proc-macro/derive-bad.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fderive-bad.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fderive-bad.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fderive-bad.rs?ref=f6c0c4837c303e327a8b37649dd72f115b48f309", "patch": "@@ -16,8 +16,7 @@ extern crate derive_bad;\n #[derive(\n     A\n )]\n-//~^^ ERROR: custom derive attribute panicked\n-//~| HELP: called `Result::unwrap()` on an `Err` value: LexError\n+//~^^ ERROR: custom derive produced unparseable tokens\n struct A;\n \n fn main() {}"}, {"sha": "4624891c1a32d3279ed5b4e4b7bf22c731f0d6c1", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/derive-atob.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-atob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-atob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-atob.rs?ref=f6c0c4837c303e327a8b37649dd72f115b48f309", "patch": "@@ -19,6 +19,6 @@ use proc_macro::TokenStream;\n #[proc_macro_derive(AToB)]\n pub fn derive(input: TokenStream) -> TokenStream {\n     let input = input.to_string();\n-    assert_eq!(input, \"#[derive(Copy, Clone)]\\nstruct A;\\n\");\n+    assert_eq!(input, \"#[derive(Copy, Clone)]\\nstruct A;\");\n     \"struct B;\".parse().unwrap()\n }"}, {"sha": "550ffe9400db88a3707bdfe3b52f3452869c7b4c", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/derive-ctod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-ctod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-ctod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-ctod.rs?ref=f6c0c4837c303e327a8b37649dd72f115b48f309", "patch": "@@ -19,6 +19,6 @@ use proc_macro::TokenStream;\n #[proc_macro_derive(CToD)]\n pub fn derive(input: TokenStream) -> TokenStream {\n     let input = input.to_string();\n-    assert_eq!(input, \"struct C;\\n\");\n+    assert_eq!(input, \"struct C;\");\n     \"struct D;\".parse().unwrap()\n }"}, {"sha": "cf96f52823f0f0fcb3b2bdbd2ff5923468c66069", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/derive-same-struct.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-same-struct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f6c0c4837c303e327a8b37649dd72f115b48f309/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-same-struct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fderive-same-struct.rs?ref=f6c0c4837c303e327a8b37649dd72f115b48f309", "patch": "@@ -18,12 +18,12 @@ use proc_macro::TokenStream;\n #[proc_macro_derive(AToB)]\n pub fn derive1(input: TokenStream) -> TokenStream {\n     println!(\"input1: {:?}\", input.to_string());\n-    assert_eq!(input.to_string(), \"struct A;\\n\");\n+    assert_eq!(input.to_string(), \"struct A;\");\n     \"#[derive(BToC)] struct B;\".parse().unwrap()\n }\n \n #[proc_macro_derive(BToC)]\n pub fn derive2(input: TokenStream) -> TokenStream {\n-    assert_eq!(input.to_string(), \"struct B;\\n\");\n+    assert_eq!(input.to_string(), \"struct B;\");\n     \"struct C;\".parse().unwrap()\n }"}]}