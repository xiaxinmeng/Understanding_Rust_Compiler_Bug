{"sha": "2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "node_id": "C_kwDOAAsO6NoAKDJjZWY5ZTNkMTkwODdhODNmZTE0MzFhYjhmZDkxNWNmZmQ2YTIyZWM", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-11-06T12:00:09Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-11-06T13:17:10Z"}, "message": "interpret: support for per-byte provenance", "tree": {"sha": "2c0d62cb14e977d513c0350ab23b23db34a8a3ef", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2c0d62cb14e977d513c0350ab23b23db34a8a3ef"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "html_url": "https://github.com/rust-lang/rust/commit/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "452cf4f7109f58433ac38be7d3da527408571054", "url": "https://api.github.com/repos/rust-lang/rust/commits/452cf4f7109f58433ac38be7d3da527408571054", "html_url": "https://github.com/rust-lang/rust/commit/452cf4f7109f58433ac38be7d3da527408571054"}], "stats": {"total": 797, "additions": 506, "deletions": 291}, "files": [{"sha": "b58b47df65fa4ee49227e33e902e4e05695b60ce", "filename": "compiler/rustc_codegen_llvm/src/consts.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -26,7 +26,7 @@ use std::ops::Range;\n \n pub fn const_alloc_to_llvm<'ll>(cx: &CodegenCx<'ll, '_>, alloc: ConstAllocation<'_>) -> &'ll Value {\n     let alloc = alloc.inner();\n-    let mut llvals = Vec::with_capacity(alloc.provenance().len() + 1);\n+    let mut llvals = Vec::with_capacity(alloc.provenance().ptrs().len() + 1);\n     let dl = cx.data_layout();\n     let pointer_size = dl.pointer_size.bytes() as usize;\n \n@@ -78,7 +78,7 @@ pub fn const_alloc_to_llvm<'ll>(cx: &CodegenCx<'ll, '_>, alloc: ConstAllocation<\n     }\n \n     let mut next_offset = 0;\n-    for &(offset, alloc_id) in alloc.provenance().iter() {\n+    for &(offset, alloc_id) in alloc.provenance().ptrs().iter() {\n         let offset = offset.bytes();\n         assert_eq!(offset as usize as u64, offset);\n         let offset = offset as usize;\n@@ -489,7 +489,7 @@ impl<'ll> StaticMethods for CodegenCx<'ll, '_> {\n                     // happens to be zero. Instead, we should only check the value of defined bytes\n                     // and set all undefined bytes to zero if this allocation is headed for the\n                     // BSS.\n-                    let all_bytes_are_zero = alloc.provenance().is_empty()\n+                    let all_bytes_are_zero = alloc.provenance().ptrs().is_empty()\n                         && alloc\n                             .inspect_with_uninit_and_ptr_outside_interpreter(0..alloc.len())\n                             .iter()\n@@ -513,7 +513,7 @@ impl<'ll> StaticMethods for CodegenCx<'ll, '_> {\n                         section.as_str().as_ptr().cast(),\n                         section.as_str().len() as c_uint,\n                     );\n-                    assert!(alloc.provenance().is_empty());\n+                    assert!(alloc.provenance().ptrs().is_empty());\n \n                     // The `inspect` method is okay here because we checked for provenance, and\n                     // because we are doing this access to inspect the final interpreter state (not"}, {"sha": "458cc6180d53e47281bf97a9754125159963cb96", "filename": "compiler/rustc_const_eval/src/interpret/intern.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fintern.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fintern.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fintern.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -134,7 +134,7 @@ fn intern_shallow<'rt, 'mir, 'tcx, M: CompileTimeMachine<'mir, 'tcx, const_eval:\n         alloc.mutability = Mutability::Not;\n     };\n     // link the alloc id to the actual allocation\n-    leftover_allocations.extend(alloc.provenance().iter().map(|&(_, alloc_id)| alloc_id));\n+    leftover_allocations.extend(alloc.provenance().ptrs().iter().map(|&(_, alloc_id)| alloc_id));\n     let alloc = tcx.intern_const_alloc(alloc);\n     tcx.set_alloc_id_memory(alloc_id, alloc);\n     None\n@@ -439,7 +439,7 @@ pub fn intern_const_alloc_recursive<\n             }\n             let alloc = tcx.intern_const_alloc(alloc);\n             tcx.set_alloc_id_memory(alloc_id, alloc);\n-            for &(_, alloc_id) in alloc.inner().provenance().iter() {\n+            for &(_, alloc_id) in alloc.inner().provenance().ptrs().iter() {\n                 if leftover_allocations.insert(alloc_id) {\n                     todo.push(alloc_id);\n                 }"}, {"sha": "19e8dd660f0b2235596398e976cd5b7957147f1f", "filename": "compiler/rustc_const_eval/src/interpret/memory.rs", "status": "modified", "additions": 15, "deletions": 20, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmemory.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -302,8 +302,6 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             .into());\n         };\n \n-        debug!(?alloc);\n-\n         if alloc.mutability == Mutability::Not {\n             throw_ub_format!(\"deallocating immutable allocation {alloc_id:?}\");\n         }\n@@ -797,7 +795,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                     // This is a new allocation, add the allocation it points to `todo`.\n                     if let Some((_, alloc)) = self.memory.alloc_map.get(id) {\n                         todo.extend(\n-                            alloc.provenance().values().filter_map(|prov| prov.get_alloc_id()),\n+                            alloc.provenance().provenances().filter_map(|prov| prov.get_alloc_id()),\n                         );\n                     }\n                 }\n@@ -833,7 +831,8 @@ impl<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> std::fmt::Debug for DumpAllocs<'a,\n             allocs_to_print: &mut VecDeque<AllocId>,\n             alloc: &Allocation<Prov, Extra>,\n         ) -> std::fmt::Result {\n-            for alloc_id in alloc.provenance().values().filter_map(|prov| prov.get_alloc_id()) {\n+            for alloc_id in alloc.provenance().provenances().filter_map(|prov| prov.get_alloc_id())\n+            {\n                 allocs_to_print.push_back(alloc_id);\n             }\n             write!(fmt, \"{}\", display_allocation(tcx, alloc))\n@@ -962,7 +961,7 @@ impl<'tcx, 'a, Prov: Provenance, Extra> AllocRef<'a, 'tcx, Prov, Extra> {\n \n     /// Returns whether the allocation has provenance anywhere in the range of the `AllocRef`.\n     pub(crate) fn has_provenance(&self) -> bool {\n-        self.alloc.range_has_provenance(&self.tcx, self.range)\n+        !self.alloc.provenance().range_empty(self.range, &self.tcx)\n     }\n }\n \n@@ -1060,7 +1059,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n \n         // Source alloc preparations and access hooks.\n         let Some((src_alloc_id, src_offset, src_prov)) = src_parts else {\n-            // Zero-sized *source*, that means dst is also zero-sized and we have nothing to do.\n+            // Zero-sized *source*, that means dest is also zero-sized and we have nothing to do.\n             return Ok(());\n         };\n         let src_alloc = self.get_alloc_raw(src_alloc_id)?;\n@@ -1079,22 +1078,18 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             return Ok(());\n         };\n \n-        // Checks provenance edges on the src, which needs to happen before\n-        // `prepare_provenance_copy`.\n-        if src_alloc.range_has_provenance(&tcx, alloc_range(src_range.start, Size::ZERO)) {\n-            throw_unsup!(PartialPointerCopy(Pointer::new(src_alloc_id, src_range.start)));\n-        }\n-        if src_alloc.range_has_provenance(&tcx, alloc_range(src_range.end(), Size::ZERO)) {\n-            throw_unsup!(PartialPointerCopy(Pointer::new(src_alloc_id, src_range.end())));\n-        }\n+        // Prepare getting source provenance.\n         let src_bytes = src_alloc.get_bytes_unchecked(src_range).as_ptr(); // raw ptr, so we can also get a ptr to the destination allocation\n         // first copy the provenance to a temporary buffer, because\n         // `get_bytes_mut` will clear the provenance, which is correct,\n         // since we don't want to keep any provenance at the target.\n-        let provenance =\n-            src_alloc.prepare_provenance_copy(self, src_range, dest_offset, num_copies);\n+        // This will also error if copying partial provenance is not supported.\n+        let provenance = src_alloc\n+            .provenance()\n+            .prepare_copy(src_range, dest_offset, num_copies, self)\n+            .map_err(|e| e.to_interp_error(dest_alloc_id))?;\n         // Prepare a copy of the initialization mask.\n-        let compressed = src_alloc.compress_uninit_range(src_range);\n+        let init = src_alloc.compress_uninit_range(src_range);\n \n         // Destination alloc preparations and access hooks.\n         let (dest_alloc, extra) = self.get_alloc_raw_mut(dest_alloc_id)?;\n@@ -1111,7 +1106,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             .map_err(|e| e.to_interp_error(dest_alloc_id))?\n             .as_mut_ptr();\n \n-        if compressed.no_bytes_init() {\n+        if init.no_bytes_init() {\n             // Fast path: If all bytes are `uninit` then there is nothing to copy. The target range\n             // is marked as uninitialized but we otherwise omit changing the byte representation which may\n             // be arbitrary for uninitialized bytes.\n@@ -1161,12 +1156,12 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n \n         // now fill in all the \"init\" data\n         dest_alloc.mark_compressed_init_range(\n-            &compressed,\n+            &init,\n             alloc_range(dest_offset, size), // just a single copy (i.e., not full `dest_range`)\n             num_copies,\n         );\n         // copy the provenance to the destination\n-        dest_alloc.mark_provenance_range(provenance);\n+        dest_alloc.provenance_apply_copy(provenance);\n \n         Ok(())\n     }"}, {"sha": "2fdfdd77256fcce4ed49226323612f11c168cff7", "filename": "compiler/rustc_hir_analysis/src/check/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_hir_analysis%2Fsrc%2Fcheck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_hir_analysis%2Fsrc%2Fcheck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_hir_analysis%2Fsrc%2Fcheck%2Fmod.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -159,7 +159,7 @@ fn maybe_check_static_with_link_section(tcx: TyCtxt<'_>, id: LocalDefId) {\n     // the consumer's responsibility to ensure all bytes that have been read\n     // have defined values.\n     if let Ok(alloc) = tcx.eval_static_initializer(id.to_def_id())\n-        && alloc.inner().provenance().len() != 0\n+        && alloc.inner().provenance().ptrs().len() != 0\n     {\n         let msg = \"statics with a custom `#[link_section]` must be a \\\n                         simple list of bytes on the wasm target with no \\"}, {"sha": "ba64711ea281487f6b4199dac06cf6daa86ccd8d", "filename": "compiler/rustc_middle/src/mir/interpret/allocation.rs", "status": "modified", "additions": 21, "deletions": 173, "changes": 194, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -1,16 +1,17 @@\n //! The virtual memory representation of the MIR interpreter.\n \n+mod provenance_map;\n+\n use std::borrow::Cow;\n use std::convert::{TryFrom, TryInto};\n use std::fmt;\n use std::hash;\n use std::iter;\n-use std::ops::{Deref, Range};\n+use std::ops::Range;\n use std::ptr;\n \n use rustc_ast::Mutability;\n use rustc_data_structures::intern::Interned;\n-use rustc_data_structures::sorted_map::SortedMap;\n use rustc_span::DUMMY_SP;\n use rustc_target::abi::{Align, HasDataLayout, Size};\n \n@@ -20,6 +21,7 @@ use super::{\n     UnsupportedOpInfo,\n };\n use crate::ty;\n+use provenance_map::*;\n \n /// This type represents an Allocation in the Miri/CTFE core engine.\n ///\n@@ -271,10 +273,10 @@ impl Allocation {\n     ) -> Result<Allocation<Prov, Extra>, Err> {\n         // Compute new pointer provenance, which also adjusts the bytes.\n         let mut bytes = self.bytes;\n-        let mut new_provenance = Vec::with_capacity(self.provenance.0.len());\n+        let mut new_provenance = Vec::with_capacity(self.provenance.ptrs().len());\n         let ptr_size = cx.data_layout().pointer_size.bytes_usize();\n         let endian = cx.data_layout().endian;\n-        for &(offset, alloc_id) in self.provenance.iter() {\n+        for &(offset, alloc_id) in self.provenance.ptrs().iter() {\n             let idx = offset.bytes_usize();\n             let ptr_bytes = &mut bytes[idx..idx + ptr_size];\n             let bits = read_target_uint(endian, ptr_bytes).unwrap();\n@@ -286,7 +288,7 @@ impl Allocation {\n         // Create allocation.\n         Ok(Allocation {\n             bytes,\n-            provenance: ProvenanceMap::from_presorted(new_provenance),\n+            provenance: ProvenanceMap::from_presorted_ptrs(new_provenance),\n             init_mask: self.init_mask,\n             align: self.align,\n             mutability: self.mutability,\n@@ -351,7 +353,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     ) -> AllocResult<&[u8]> {\n         self.check_init(range)?;\n         if !Prov::OFFSET_IS_ADDR {\n-            if self.range_has_provenance(cx, range) {\n+            if !self.provenance.range_empty(range, cx) {\n                 return Err(AllocError::ReadPointerAsBytes);\n             }\n         }\n@@ -370,7 +372,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         range: AllocRange,\n     ) -> AllocResult<&mut [u8]> {\n         self.mark_init(range, true);\n-        self.clear_provenance(cx, range)?;\n+        self.provenance.clear(range, cx)?;\n \n         Ok(&mut self.bytes[range.start.bytes_usize()..range.end().bytes_usize()])\n     }\n@@ -382,7 +384,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n         range: AllocRange,\n     ) -> AllocResult<*mut [u8]> {\n         self.mark_init(range, true);\n-        self.clear_provenance(cx, range)?;\n+        self.provenance.clear(range, cx)?;\n \n         assert!(range.end().bytes_usize() <= self.bytes.len()); // need to do our own bounds-check\n         let begin_ptr = self.bytes.as_mut_ptr().wrapping_add(range.start.bytes_usize());\n@@ -423,18 +425,17 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n \n             // When reading data with provenance, the easy case is finding provenance exactly where we\n             // are reading, then we can put data and provenance back together and return that.\n-            if let Some(&prov) = self.provenance.get(&range.start) {\n+            if let Some(prov) = self.provenance.get_ptr(range.start) {\n                 // Now we can return the bits, with their appropriate provenance.\n                 let ptr = Pointer::new(prov, Size::from_bytes(bits));\n                 return Ok(Scalar::from_pointer(ptr, cx));\n             }\n \n             // If we can work on pointers byte-wise, join the byte-wise provenances.\n             if Prov::OFFSET_IS_ADDR {\n-                let mut prov = self.offset_get_provenance(cx, range.start);\n-                for offset in 1..range.size.bytes() {\n-                    let this_prov =\n-                        self.offset_get_provenance(cx, range.start + Size::from_bytes(offset));\n+                let mut prov = self.provenance.get(range.start, cx);\n+                for offset in Size::from_bytes(1)..range.size {\n+                    let this_prov = self.provenance.get(range.start + offset, cx);\n                     prov = Prov::join(prov, this_prov);\n                 }\n                 // Now use this provenance.\n@@ -452,7 +453,7 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n \n         // Fallback path for when we cannot treat provenance bytewise or ignore it.\n         assert!(!Prov::OFFSET_IS_ADDR);\n-        if self.range_has_provenance(cx, range) {\n+        if !self.provenance.range_empty(range, cx) {\n             return Err(AllocError::ReadPointerAsBytes);\n         }\n         // There is no provenance, we can just return the bits.\n@@ -466,7 +467,6 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n     /// Most likely, you want to call `InterpCx::write_scalar` instead of this method.\n-    #[instrument(skip(self, cx), level = \"debug\")]\n     pub fn write_scalar(\n         &mut self,\n         cx: &impl HasDataLayout,\n@@ -491,7 +491,8 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n \n         // See if we have to also store some provenance.\n         if let Some(provenance) = provenance {\n-            self.provenance.0.insert(range.start, provenance);\n+            assert_eq!(range.size, cx.data_layout().pointer_size);\n+            self.provenance.insert_ptr(range.start, provenance, cx);\n         }\n \n         Ok(())\n@@ -500,171 +501,18 @@ impl<Prov: Provenance, Extra> Allocation<Prov, Extra> {\n     /// Write \"uninit\" to the given memory range.\n     pub fn write_uninit(&mut self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult {\n         self.mark_init(range, false);\n-        self.clear_provenance(cx, range)?;\n+        self.provenance.clear(range, cx)?;\n         return Ok(());\n     }\n-}\n-\n-/// Provenance.\n-impl<Prov: Copy, Extra> Allocation<Prov, Extra> {\n-    /// Returns all provenance overlapping with the given pointer-offset pair.\n-    fn range_get_provenance(&self, cx: &impl HasDataLayout, range: AllocRange) -> &[(Size, Prov)] {\n-        // We have to go back `pointer_size - 1` bytes, as that one would still overlap with\n-        // the beginning of this range.\n-        let start = range.start.bytes().saturating_sub(cx.data_layout().pointer_size.bytes() - 1);\n-        self.provenance.range(Size::from_bytes(start)..range.end())\n-    }\n-\n-    /// Get the provenance of a single byte.\n-    fn offset_get_provenance(&self, cx: &impl HasDataLayout, offset: Size) -> Option<Prov> {\n-        let prov = self.range_get_provenance(cx, alloc_range(offset, Size::from_bytes(1)));\n-        assert!(prov.len() <= 1);\n-        prov.first().map(|(_offset, prov)| *prov)\n-    }\n-\n-    /// Returns whether this allocation has progrnance overlapping with the given range.\n-    ///\n-    /// Note: this function exists to allow `range_get_provenance` to be private, in order to somewhat\n-    /// limit access to provenance outside of the `Allocation` abstraction.\n-    ///\n-    pub fn range_has_provenance(&self, cx: &impl HasDataLayout, range: AllocRange) -> bool {\n-        !self.range_get_provenance(cx, range).is_empty()\n-    }\n-\n-    /// Removes all provenance inside the given range.\n-    /// If there is provenance overlapping with the edges, it\n-    /// are removed as well *and* the bytes they cover are marked as\n-    /// uninitialized. This is a somewhat odd \"spooky action at a distance\",\n-    /// but it allows strictly more code to run than if we would just error\n-    /// immediately in that case.\n-    fn clear_provenance(&mut self, cx: &impl HasDataLayout, range: AllocRange) -> AllocResult\n-    where\n-        Prov: Provenance,\n-    {\n-        // Find the start and end of the given range and its outermost provenance.\n-        let (first, last) = {\n-            // Find all provenance overlapping the given range.\n-            let provenance = self.range_get_provenance(cx, range);\n-            if provenance.is_empty() {\n-                return Ok(());\n-            }\n-\n-            (\n-                provenance.first().unwrap().0,\n-                provenance.last().unwrap().0 + cx.data_layout().pointer_size,\n-            )\n-        };\n-        let start = range.start;\n-        let end = range.end();\n-\n-        // We need to handle clearing the provenance from parts of a pointer.\n-        // FIXME: Miri should preserve partial provenance; see\n-        // https://github.com/rust-lang/miri/issues/2181.\n-        if first < start {\n-            if Prov::ERR_ON_PARTIAL_PTR_OVERWRITE {\n-                return Err(AllocError::PartialPointerOverwrite(first));\n-            }\n-            warn!(\n-                \"Partial pointer overwrite! De-initializing memory at offsets {first:?}..{start:?}.\"\n-            );\n-            self.init_mask.set_range(first, start, false);\n-        }\n-        if last > end {\n-            if Prov::ERR_ON_PARTIAL_PTR_OVERWRITE {\n-                return Err(AllocError::PartialPointerOverwrite(\n-                    last - cx.data_layout().pointer_size,\n-                ));\n-            }\n-            warn!(\n-                \"Partial pointer overwrite! De-initializing memory at offsets {end:?}..{last:?}.\"\n-            );\n-            self.init_mask.set_range(end, last, false);\n-        }\n-\n-        // Forget all the provenance.\n-        // Since provenance do not overlap, we know that removing until `last` (exclusive) is fine,\n-        // i.e., this will not remove any other provenance just after the ones we care about.\n-        self.provenance.0.remove_range(first..last);\n-\n-        Ok(())\n-    }\n-}\n-\n-/// Stores the provenance information of pointers stored in memory.\n-#[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, TyEncodable, TyDecodable)]\n-pub struct ProvenanceMap<Prov = AllocId>(SortedMap<Size, Prov>);\n-\n-impl<Prov> ProvenanceMap<Prov> {\n-    pub fn new() -> Self {\n-        ProvenanceMap(SortedMap::new())\n-    }\n-\n-    // The caller must guarantee that the given provenance list is already sorted\n-    // by address and contain no duplicates.\n-    pub fn from_presorted(r: Vec<(Size, Prov)>) -> Self {\n-        ProvenanceMap(SortedMap::from_presorted_elements(r))\n-    }\n-}\n-\n-impl<Prov> Deref for ProvenanceMap<Prov> {\n-    type Target = SortedMap<Size, Prov>;\n-\n-    fn deref(&self) -> &Self::Target {\n-        &self.0\n-    }\n-}\n-\n-/// A partial, owned list of provenance to transfer into another allocation.\n-///\n-/// Offsets are already adjusted to the destination allocation.\n-pub struct AllocationProvenance<Prov> {\n-    dest_provenance: Vec<(Size, Prov)>,\n-}\n-\n-impl<Prov: Copy, Extra> Allocation<Prov, Extra> {\n-    pub fn prepare_provenance_copy(\n-        &self,\n-        cx: &impl HasDataLayout,\n-        src: AllocRange,\n-        dest: Size,\n-        count: u64,\n-    ) -> AllocationProvenance<Prov> {\n-        let provenance = self.range_get_provenance(cx, src);\n-        if provenance.is_empty() {\n-            return AllocationProvenance { dest_provenance: Vec::new() };\n-        }\n-\n-        let size = src.size;\n-        let mut new_provenance = Vec::with_capacity(provenance.len() * (count as usize));\n-\n-        // If `count` is large, this is rather wasteful -- we are allocating a big array here, which\n-        // is mostly filled with redundant information since it's just N copies of the same `Prov`s\n-        // at slightly adjusted offsets. The reason we do this is so that in `mark_provenance_range`\n-        // we can use `insert_presorted`. That wouldn't work with an `Iterator` that just produces\n-        // the right sequence of provenance for all N copies.\n-        for i in 0..count {\n-            new_provenance.extend(provenance.iter().map(|&(offset, reloc)| {\n-                // compute offset for current repetition\n-                let dest_offset = dest + size * i; // `Size` operations\n-                (\n-                    // shift offsets from source allocation to destination allocation\n-                    (offset + dest_offset) - src.start, // `Size` operations\n-                    reloc,\n-                )\n-            }));\n-        }\n-\n-        AllocationProvenance { dest_provenance: new_provenance }\n-    }\n \n     /// Applies a provenance copy.\n-    /// The affected range, as defined in the parameters to `prepare_provenance_copy` is expected\n+    /// The affected range, as defined in the parameters to `provenance().prepare_copy` is expected\n     /// to be clear of provenance.\n     ///\n     /// This is dangerous to use as it can violate internal `Allocation` invariants!\n     /// It only exists to support an efficient implementation of `mem_copy_repeatedly`.\n-    pub fn mark_provenance_range(&mut self, provenance: AllocationProvenance<Prov>) {\n-        self.provenance.0.insert_presorted(provenance.dest_provenance);\n+    pub fn provenance_apply_copy(&mut self, copy: ProvenanceCopy<Prov>) {\n+        self.provenance.apply_copy(copy)\n     }\n }\n "}, {"sha": "f0f990f4e9d935ffc1a4c316d07a34e32caab54d", "filename": "compiler/rustc_middle/src/mir/interpret/allocation/provenance_map.rs", "status": "added", "additions": 274, "deletions": 0, "changes": 274, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation%2Fprovenance_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation%2Fprovenance_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation%2Fprovenance_map.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -0,0 +1,274 @@\n+//! Store the provenance for each byte in the range, with a more efficient\n+//! representation for the common case where PTR_SIZE consecutive bytes have the same provenance.\n+\n+use std::cmp;\n+\n+use rustc_data_structures::sorted_map::SortedMap;\n+use rustc_target::abi::{HasDataLayout, Size};\n+\n+use super::{alloc_range, AllocError, AllocId, AllocRange, AllocResult, Provenance};\n+\n+/// Stores the provenance information of pointers stored in memory.\n+#[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, TyEncodable, TyDecodable)]\n+#[derive(HashStable)]\n+pub struct ProvenanceMap<Prov = AllocId> {\n+    /// Provenance in this map applies from the given offset for an entire pointer-size worth of\n+    /// bytes. Two entires in this map are always at least a pointer size apart.\n+    ptrs: SortedMap<Size, Prov>,\n+    /// Provenance in this map only applies to the given single byte.\n+    /// This map is disjoint from the previous.\n+    bytes: SortedMap<Size, Prov>,\n+}\n+\n+impl<Prov> ProvenanceMap<Prov> {\n+    pub fn new() -> Self {\n+        ProvenanceMap { ptrs: SortedMap::new(), bytes: SortedMap::new() }\n+    }\n+\n+    /// The caller must guarantee that the given provenance list is already sorted\n+    /// by address and contain no duplicates.\n+    pub fn from_presorted_ptrs(r: Vec<(Size, Prov)>) -> Self {\n+        ProvenanceMap { ptrs: SortedMap::from_presorted_elements(r), bytes: SortedMap::new() }\n+    }\n+}\n+\n+impl ProvenanceMap {\n+    /// Give access to the ptr-sized provenances (which can also be thought of as relocations, and\n+    /// indeed that is how codegen treats them).\n+    ///\n+    /// Only exposed with `AllocId` provenance, since it panics if there is bytewise provenance.\n+    pub fn ptrs(&self) -> &SortedMap<Size, AllocId> {\n+        assert!(self.bytes.is_empty());\n+        &self.ptrs\n+    }\n+}\n+\n+impl<Prov: Provenance> ProvenanceMap<Prov> {\n+    /// Returns all ptr-sized provenance in the given range.\n+    /// If the range has length 0, returns provenance that crosses the edge between `start-1` and\n+    /// `start`.\n+    fn range_get_ptrs(&self, range: AllocRange, cx: &impl HasDataLayout) -> &[(Size, Prov)] {\n+        // We have to go back `pointer_size - 1` bytes, as that one would still overlap with\n+        // the beginning of this range.\n+        let adjusted_start = Size::from_bytes(\n+            range.start.bytes().saturating_sub(cx.data_layout().pointer_size.bytes() - 1),\n+        );\n+        self.ptrs.range(adjusted_start..range.end())\n+    }\n+\n+    /// Returns all byte-wise provenance in the given range.\n+    fn range_get_bytes(&self, range: AllocRange) -> &[(Size, Prov)] {\n+        self.bytes.range(range.start..range.end())\n+    }\n+\n+    /// Get the provenance of a single byte.\n+    pub fn get(&self, offset: Size, cx: &impl HasDataLayout) -> Option<Prov> {\n+        let prov = self.range_get_ptrs(alloc_range(offset, Size::from_bytes(1)), cx);\n+        debug_assert!(prov.len() <= 1);\n+        if let Some(entry) = prov.first() {\n+            // If it overlaps with this byte, it is on this byte.\n+            debug_assert!(self.bytes.get(&offset).is_none());\n+            Some(entry.1)\n+        } else {\n+            // Look up per-byte provenance.\n+            self.bytes.get(&offset).copied()\n+        }\n+    }\n+\n+    /// Check if here is ptr-sized provenance at the given index.\n+    /// Does not mean anything for bytewise provenance! But can be useful as an optimization.\n+    pub fn get_ptr(&self, offset: Size) -> Option<Prov> {\n+        self.ptrs.get(&offset).copied()\n+    }\n+\n+    /// Returns whether this allocation has provenance overlapping with the given range.\n+    ///\n+    /// Note: this function exists to allow `range_get_provenance` to be private, in order to somewhat\n+    /// limit access to provenance outside of the `Allocation` abstraction.\n+    ///\n+    pub fn range_empty(&self, range: AllocRange, cx: &impl HasDataLayout) -> bool {\n+        self.range_get_ptrs(range, cx).is_empty() && self.range_get_bytes(range).is_empty()\n+    }\n+\n+    /// Yields all the provenances stored in this map.\n+    pub fn provenances(&self) -> impl Iterator<Item = Prov> + '_ {\n+        self.ptrs.values().chain(self.bytes.values()).copied()\n+    }\n+\n+    pub fn insert_ptr(&mut self, offset: Size, prov: Prov, cx: &impl HasDataLayout) {\n+        debug_assert!(self.range_empty(alloc_range(offset, cx.data_layout().pointer_size), cx));\n+        self.ptrs.insert(offset, prov);\n+    }\n+\n+    /// Removes all provenance inside the given range.\n+    /// If there is provenance overlapping with the edges, might result in an error.\n+    pub fn clear(&mut self, range: AllocRange, cx: &impl HasDataLayout) -> AllocResult {\n+        let start = range.start;\n+        let end = range.end();\n+        // Clear the bytewise part -- this is easy.\n+        self.bytes.remove_range(start..end);\n+\n+        // For the ptr-sized part, find the first (inclusive) and last (exclusive) byte of\n+        // provenance that overlaps with the given range.\n+        let (first, last) = {\n+            // Find all provenance overlapping the given range.\n+            let provenance = self.range_get_ptrs(range, cx);\n+            if provenance.is_empty() {\n+                // No provenance in this range, we are done.\n+                return Ok(());\n+            }\n+\n+            (\n+                provenance.first().unwrap().0,\n+                provenance.last().unwrap().0 + cx.data_layout().pointer_size,\n+            )\n+        };\n+\n+        // We need to handle clearing the provenance from parts of a pointer.\n+        if first < start {\n+            if !Prov::OFFSET_IS_ADDR {\n+                // We can't split up the provenance into less than a pointer.\n+                return Err(AllocError::PartialPointerOverwrite(first));\n+            }\n+            // Insert the remaining part in the bytewise provenance.\n+            let prov = self.ptrs[&first];\n+            for offset in first..start {\n+                self.bytes.insert(offset, prov);\n+            }\n+        }\n+        if last > end {\n+            let begin_of_last = last - cx.data_layout().pointer_size;\n+            if !Prov::OFFSET_IS_ADDR {\n+                // We can't split up the provenance into less than a pointer.\n+                return Err(AllocError::PartialPointerOverwrite(begin_of_last));\n+            }\n+            // Insert the remaining part in the bytewise provenance.\n+            let prov = self.ptrs[&begin_of_last];\n+            for offset in end..last {\n+                self.bytes.insert(offset, prov);\n+            }\n+        }\n+\n+        // Forget all the provenance.\n+        // Since provenance do not overlap, we know that removing until `last` (exclusive) is fine,\n+        // i.e., this will not remove any other provenance just after the ones we care about.\n+        self.ptrs.remove_range(first..last);\n+\n+        Ok(())\n+    }\n+}\n+\n+/// A partial, owned list of provenance to transfer into another allocation.\n+///\n+/// Offsets are already adjusted to the destination allocation.\n+pub struct ProvenanceCopy<Prov> {\n+    dest_ptrs: Vec<(Size, Prov)>,\n+    dest_bytes: Vec<(Size, Prov)>,\n+}\n+\n+impl<Prov: Provenance> ProvenanceMap<Prov> {\n+    #[instrument(skip(self, cx), level = \"debug\")]\n+    pub fn prepare_copy(\n+        &self,\n+        src: AllocRange,\n+        dest: Size,\n+        count: u64,\n+        cx: &impl HasDataLayout,\n+    ) -> AllocResult<ProvenanceCopy<Prov>> {\n+        let shift_offset = move |idx, offset| {\n+            // compute offset for current repetition\n+            let dest_offset = dest + src.size * idx; // `Size` operations\n+            // shift offsets from source allocation to destination allocation\n+            (offset - src.start) + dest_offset // `Size` operations\n+        };\n+        let ptr_size = cx.data_layout().pointer_size;\n+\n+        // # Pointer-sized provenances\n+        // Get the provenances that are entirely within this range.\n+        // (Different from `range_get_ptrs` which asks if they overlap the range.)\n+        let ptrs = if src.size < ptr_size {\n+            // This isn't even large enough to contain a pointer.\n+            &[]\n+        } else {\n+            let adjusted_end =\n+                Size::from_bytes(src.end().bytes().saturating_sub(ptr_size.bytes() - 1));\n+            self.ptrs.range(src.start..adjusted_end)\n+        };\n+\n+        // Buffer for the new list.\n+        let mut dest_ptrs = Vec::with_capacity(ptrs.len() * (count as usize));\n+        // If `count` is large, this is rather wasteful -- we are allocating a big array here, which\n+        // is mostly filled with redundant information since it's just N copies of the same `Prov`s\n+        // at slightly adjusted offsets. The reason we do this is so that in `mark_provenance_range`\n+        // we can use `insert_presorted`. That wouldn't work with an `Iterator` that just produces\n+        // the right sequence of provenance for all N copies.\n+        // Basically, this large array would have to be created anyway in the target allocation.\n+        for i in 0..count {\n+            dest_ptrs.extend(ptrs.iter().map(|&(offset, reloc)| (shift_offset(i, offset), reloc)));\n+        }\n+\n+        // # Byte-sized provenances\n+        let mut bytes = Vec::new();\n+        // First, if there is a part of a pointer at the start, add that.\n+        if let Some(entry) = self.range_get_ptrs(alloc_range(src.start, Size::ZERO), cx).first() {\n+            if !Prov::OFFSET_IS_ADDR {\n+                // We can't split up the provenance into less than a pointer.\n+                return Err(AllocError::PartialPointerCopy(entry.0));\n+            }\n+            trace!(\"start overlapping entry: {entry:?}\");\n+            // For really small copies, make sure we don't run off the end of the `src` range.\n+            let entry_end = cmp::min(entry.0 + ptr_size, src.end());\n+            for offset in src.start..entry_end {\n+                bytes.push((offset, entry.1));\n+            }\n+        } else {\n+            trace!(\"no start overlapping entry\");\n+        }\n+        // Then the main part, bytewise provenance from `self.bytes`.\n+        bytes.extend(self.bytes.range(src.start..src.end()));\n+        // And finally possibly parts of a pointer at the end.\n+        if let Some(entry) = self.range_get_ptrs(alloc_range(src.end(), Size::ZERO), cx).first() {\n+            if !Prov::OFFSET_IS_ADDR {\n+                // We can't split up the provenance into less than a pointer.\n+                return Err(AllocError::PartialPointerCopy(entry.0));\n+            }\n+            trace!(\"end overlapping entry: {entry:?}\");\n+            // For really small copies, make sure we don't start before `src` does.\n+            let entry_start = cmp::max(entry.0, src.start);\n+            for offset in entry_start..src.end() {\n+                if bytes.last().map_or(true, |bytes_entry| bytes_entry.0 < offset) {\n+                    // The last entry, if it exists, has a lower offset than us.\n+                    bytes.push((offset, entry.1));\n+                } else {\n+                    // There already is an entry for this offset in there! This can happen when the\n+                    // start and end range checks actually end up hitting the same pointer, so we\n+                    // already added this in the \"pointer at the start\" part above.\n+                    assert!(entry.0 <= src.start);\n+                }\n+            }\n+        } else {\n+            trace!(\"no end overlapping entry\");\n+        }\n+        trace!(\"byte provenances: {bytes:?}\");\n+\n+        // And again a buffer for the new list on the target side.\n+        let mut dest_bytes = Vec::with_capacity(bytes.len() * (count as usize));\n+        for i in 0..count {\n+            dest_bytes\n+                .extend(bytes.iter().map(|&(offset, reloc)| (shift_offset(i, offset), reloc)));\n+        }\n+\n+        Ok(ProvenanceCopy { dest_ptrs, dest_bytes })\n+    }\n+\n+    /// Applies a provenance copy.\n+    /// The affected range, as defined in the parameters to `prepare_copy` is expected\n+    /// to be clear of provenance.\n+    ///\n+    /// This is dangerous to use as it can violate internal `Allocation` invariants!\n+    /// It only exists to support an efficient implementation of `mem_copy_repeatedly`.\n+    pub fn apply_copy(&mut self, copy: ProvenanceCopy<Prov>) {\n+        self.ptrs.insert_presorted(copy.dest_ptrs);\n+        self.bytes.insert_presorted(copy.dest_bytes);\n+    }\n+}"}, {"sha": "9c8ab44cfd6122befac84ec11ffdea98c787c6f9", "filename": "compiler/rustc_middle/src/mir/interpret/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -127,8 +127,8 @@ pub use self::error::{\n pub use self::value::{get_slice_bytes, ConstAlloc, ConstValue, Scalar};\n \n pub use self::allocation::{\n-    alloc_range, AllocRange, Allocation, ConstAllocation, InitChunk, InitChunkIter, InitMask,\n-    ProvenanceMap,\n+    alloc_range, AllocError, AllocRange, AllocResult, Allocation, ConstAllocation, InitChunk,\n+    InitChunkIter, InitMask,\n };\n \n pub use self::pointer::{Pointer, PointerArithmetic, Provenance};"}, {"sha": "4e59f1b24821643263b294a83f75b84e0c07144f", "filename": "compiler/rustc_middle/src/mir/interpret/pointer.rs", "status": "modified", "additions": 15, "deletions": 10, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fpointer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fpointer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fpointer.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -103,8 +103,7 @@ impl<T: HasDataLayout> PointerArithmetic for T {}\n /// This trait abstracts over the kind of provenance that is associated with a `Pointer`. It is\n /// mostly opaque; the `Machine` trait extends it with some more operations that also have access to\n /// some global state.\n-/// We don't actually care about this `Debug` bound (we use `Provenance::fmt` to format the entire\n-/// pointer), but `derive` adds some unnecessary bounds.\n+/// The `Debug` rendering is used to distplay bare provenance, and for the default impl of `fmt`.\n pub trait Provenance: Copy + fmt::Debug {\n     /// Says whether the `offset` field of `Pointer`s with this provenance is the actual physical address.\n     /// - If `false`, the offset *must* be relative. This means the bytes representing a pointer are\n@@ -115,14 +114,23 @@ pub trait Provenance: Copy + fmt::Debug {\n     ///   pointer, and implement ptr-to-int transmutation by stripping provenance.\n     const OFFSET_IS_ADDR: bool;\n \n-    /// We also use this trait to control whether to abort execution when a pointer is being partially overwritten\n-    /// (this avoids a separate trait in `allocation.rs` just for this purpose).\n-    const ERR_ON_PARTIAL_PTR_OVERWRITE: bool;\n-\n     /// Determines how a pointer should be printed.\n+    ///\n+    /// Default impl is only good for when `OFFSET_IS_ADDR == true`.\n     fn fmt(ptr: &Pointer<Self>, f: &mut fmt::Formatter<'_>) -> fmt::Result\n     where\n-        Self: Sized;\n+        Self: Sized,\n+    {\n+        assert!(Self::OFFSET_IS_ADDR);\n+        let (prov, addr) = ptr.into_parts(); // address is absolute\n+        write!(f, \"{:#x}\", addr.bytes())?;\n+        if f.alternate() {\n+            write!(f, \"{prov:#?}\")?;\n+        } else {\n+            write!(f, \"{prov:?}\")?;\n+        }\n+        Ok(())\n+    }\n \n     /// If `OFFSET_IS_ADDR == false`, provenance must always be able to\n     /// identify the allocation this ptr points to (i.e., this must return `Some`).\n@@ -139,9 +147,6 @@ impl Provenance for AllocId {\n     // so ptr-to-int casts are not possible (since we do not know the global physical offset).\n     const OFFSET_IS_ADDR: bool = false;\n \n-    // For now, do not allow this, so that we keep our options open.\n-    const ERR_ON_PARTIAL_PTR_OVERWRITE: bool = true;\n-\n     fn fmt(ptr: &Pointer<Self>, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         // Forward `alternate` flag to `alloc_id` printing.\n         if f.alternate() {"}, {"sha": "7965a9499a16cc6de0a1b4deaaee38a0a99c7551", "filename": "compiler/rustc_middle/src/mir/pretty.rs", "status": "modified", "additions": 16, "deletions": 6, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fpretty.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -685,7 +685,7 @@ pub fn write_allocations<'tcx>(\n     fn alloc_ids_from_alloc(\n         alloc: ConstAllocation<'_>,\n     ) -> impl DoubleEndedIterator<Item = AllocId> + '_ {\n-        alloc.inner().provenance().values().map(|id| *id)\n+        alloc.inner().provenance().ptrs().values().map(|id| *id)\n     }\n \n     fn alloc_ids_from_const_val(val: ConstValue<'_>) -> impl Iterator<Item = AllocId> + '_ {\n@@ -882,7 +882,7 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n         if i != line_start {\n             write!(w, \" \")?;\n         }\n-        if let Some(&prov) = alloc.provenance().get(&i) {\n+        if let Some(prov) = alloc.provenance().get_ptr(i) {\n             // Memory with provenance must be defined\n             assert!(alloc.init_mask().is_range_initialized(i, i + ptr_size).is_ok());\n             let j = i.bytes_usize();\n@@ -904,9 +904,9 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n                 let overflow = ptr_size - remainder;\n                 let remainder_width = provenance_width(remainder.bytes_usize()) - 2;\n                 let overflow_width = provenance_width(overflow.bytes_usize() - 1) + 1;\n-                ascii.push('\u257e');\n-                for _ in 0..remainder.bytes() - 1 {\n-                    ascii.push('\u2500');\n+                ascii.push('\u257e'); // HEAVY LEFT AND LIGHT RIGHT\n+                for _ in 1..remainder.bytes() {\n+                    ascii.push('\u2500'); // LIGHT HORIZONTAL\n                 }\n                 if overflow_width > remainder_width && overflow_width >= target.len() {\n                     // The case where the provenance fits into the part in the next line\n@@ -926,7 +926,7 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n                 for _ in 0..overflow.bytes() - 1 {\n                     ascii.push('\u2500');\n                 }\n-                ascii.push('\u257c');\n+                ascii.push('\u257c'); // LIGHT LEFT AND HEAVY RIGHT\n                 i += ptr_size;\n                 continue;\n             } else {\n@@ -941,6 +941,16 @@ fn write_allocation_bytes<'tcx, Prov: Provenance, Extra>(\n                 ascii.push('\u257c');\n                 i += ptr_size;\n             }\n+        } else if let Some(prov) = alloc.provenance().get(i, &tcx) {\n+            // Memory with provenance must be defined\n+            assert!(alloc.init_mask().is_range_initialized(i, i + Size::from_bytes(1)).is_ok());\n+            ascii.push('\u2501'); // HEAVY HORIZONTAL\n+            // We have two characters to display this, which is obviously not enough.\n+            // Format is similar to \"oversized\" above.\n+            let j = i.bytes_usize();\n+            let c = alloc.inspect_with_uninit_and_ptr_outside_interpreter(j..j + 1)[0];\n+            write!(w, \"\u257e{:02x}{:#?} (1 ptr byte)\u257c\", c, prov)?;\n+            i += Size::from_bytes(1);\n         } else if alloc.init_mask().is_range_initialized(i, i + Size::from_bytes(1)).is_ok() {\n             let j = i.bytes_usize();\n "}, {"sha": "3e59c0b967c3d8a6fd00cca0aab858108760467f", "filename": "compiler/rustc_middle/src/ty/impls_ty.rs", "status": "modified", "additions": 0, "deletions": 13, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fty%2Fimpls_ty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_middle%2Fsrc%2Fty%2Fimpls_ty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fimpls_ty.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -112,19 +112,6 @@ impl<'a> HashStable<StableHashingContext<'a>> for mir::interpret::AllocId {\n     }\n }\n \n-// `Relocations` with default type parameters is a sorted map.\n-impl<'a, Prov> HashStable<StableHashingContext<'a>> for mir::interpret::ProvenanceMap<Prov>\n-where\n-    Prov: HashStable<StableHashingContext<'a>>,\n-{\n-    fn hash_stable(&self, hcx: &mut StableHashingContext<'a>, hasher: &mut StableHasher) {\n-        self.len().hash_stable(hcx, hasher);\n-        for reloc in self.iter() {\n-            reloc.hash_stable(hcx, hasher);\n-        }\n-    }\n-}\n-\n impl<'a> ToStableHashKey<StableHashingContext<'a>> for region::Scope {\n     type KeyType = region::Scope;\n "}, {"sha": "e296d4766c18b8e2624e3874156739323f0fe2ce", "filename": "compiler/rustc_monomorphize/src/collector.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_monomorphize%2Fsrc%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/compiler%2Frustc_monomorphize%2Fsrc%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_monomorphize%2Fsrc%2Fcollector.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -456,7 +456,7 @@ fn collect_items_rec<'tcx>(\n             recursion_depth_reset = None;\n \n             if let Ok(alloc) = tcx.eval_static_initializer(def_id) {\n-                for &id in alloc.inner().provenance().values() {\n+                for &id in alloc.inner().provenance().ptrs().values() {\n                     collect_miri(tcx, id, &mut neighbors);\n                 }\n             }\n@@ -1404,7 +1404,7 @@ fn collect_miri<'tcx>(tcx: TyCtxt<'tcx>, alloc_id: AllocId, output: &mut MonoIte\n         }\n         GlobalAlloc::Memory(alloc) => {\n             trace!(\"collecting {:?} with {:#?}\", alloc_id, alloc);\n-            for &inner in alloc.inner().provenance().values() {\n+            for &inner in alloc.inner().provenance().ptrs().values() {\n                 rustc_data_structures::stack::ensure_sufficient_stack(|| {\n                     collect_miri(tcx, inner, output);\n                 });\n@@ -1443,7 +1443,7 @@ fn collect_const_value<'tcx>(\n     match value {\n         ConstValue::Scalar(Scalar::Ptr(ptr, _size)) => collect_miri(tcx, ptr.provenance, output),\n         ConstValue::Slice { data: alloc, start: _, end: _ } | ConstValue::ByRef { alloc, .. } => {\n-            for &id in alloc.inner().provenance().values() {\n+            for &id in alloc.inner().provenance().ptrs().values() {\n                 collect_miri(tcx, id, output);\n             }\n         }"}, {"sha": "5887d26462ba2751135c5a5aa810f9477be64f87", "filename": "src/tools/miri/src/machine.rs", "status": "modified", "additions": 9, "deletions": 14, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -133,7 +133,7 @@ impl fmt::Display for MiriMemoryKind {\n }\n \n /// Pointer provenance.\n-#[derive(Debug, Clone, Copy)]\n+#[derive(Clone, Copy)]\n pub enum Provenance {\n     Concrete {\n         alloc_id: AllocId,\n@@ -176,18 +176,9 @@ static_assert_size!(Pointer<Provenance>, 24);\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n static_assert_size!(Scalar<Provenance>, 32);\n \n-impl interpret::Provenance for Provenance {\n-    /// We use absolute addresses in the `offset` of a `Pointer<Provenance>`.\n-    const OFFSET_IS_ADDR: bool = true;\n-\n-    /// We cannot err on partial overwrites, it happens too often in practice (due to unions).\n-    const ERR_ON_PARTIAL_PTR_OVERWRITE: bool = false;\n-\n-    fn fmt(ptr: &Pointer<Self>, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        let (prov, addr) = ptr.into_parts(); // address is absolute\n-        write!(f, \"{:#x}\", addr.bytes())?;\n-\n-        match prov {\n+impl fmt::Debug for Provenance {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        match self {\n             Provenance::Concrete { alloc_id, sb } => {\n                 // Forward `alternate` flag to `alloc_id` printing.\n                 if f.alternate() {\n@@ -202,9 +193,13 @@ impl interpret::Provenance for Provenance {\n                 write!(f, \"[wildcard]\")?;\n             }\n         }\n-\n         Ok(())\n     }\n+}\n+\n+impl interpret::Provenance for Provenance {\n+    /// We use absolute addresses in the `offset` of a `Pointer<Provenance>`.\n+    const OFFSET_IS_ADDR: bool = true;\n \n     fn get_alloc_id(self) -> Option<AllocId> {\n         match self {"}, {"sha": "73712348f0d5f076cd3d81e662ecc112cafad175", "filename": "src/tools/miri/src/tag_gc.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Fsrc%2Ftag_gc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Fsrc%2Ftag_gc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Ftag_gc.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -127,7 +127,7 @@ impl VisitTags for Operand<Provenance> {\n \n impl VisitTags for Allocation<Provenance, AllocExtra> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n-        for (_size, prov) in self.provenance().iter() {\n+        for prov in self.provenance().provenances() {\n             prov.visit_tags(visit);\n         }\n "}, {"sha": "e1dcdda7fdfe344608cd137199d59a402ce01e23", "filename": "src/tools/miri/tests/fail/copy_half_a_pointer.rs", "status": "removed", "additions": 0, "deletions": 21, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/452cf4f7109f58433ac38be7d3da527408571054/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fcopy_half_a_pointer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/452cf4f7109f58433ac38be7d3da527408571054/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fcopy_half_a_pointer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fcopy_half_a_pointer.rs?ref=452cf4f7109f58433ac38be7d3da527408571054", "patch": "@@ -1,21 +0,0 @@\n-//@normalize-stderr-test: \"\\+0x[48]\" -> \"+HALF_PTR\"\n-#![allow(dead_code)]\n-\n-// We use packed structs to get around alignment restrictions\n-#[repr(packed)]\n-struct Data {\n-    pad: u8,\n-    ptr: &'static i32,\n-}\n-\n-static G: i32 = 0;\n-\n-fn main() {\n-    let mut d = Data { pad: 0, ptr: &G };\n-\n-    // Get a pointer to the beginning of the Data struct (one u8 byte, then the pointer bytes).\n-    let d_alias = &mut d as *mut _ as *mut *const u8;\n-    unsafe {\n-        let _x = d_alias.read_unaligned(); //~ERROR: unable to copy parts of a pointer\n-    }\n-}"}, {"sha": "21797757084eec6bba714e3cf6123aa1eadbe232", "filename": "src/tools/miri/tests/fail/copy_half_a_pointer.stderr", "status": "removed", "additions": 0, "deletions": 14, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/452cf4f7109f58433ac38be7d3da527408571054/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fcopy_half_a_pointer.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/452cf4f7109f58433ac38be7d3da527408571054/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fcopy_half_a_pointer.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fcopy_half_a_pointer.stderr?ref=452cf4f7109f58433ac38be7d3da527408571054", "patch": "@@ -1,14 +0,0 @@\n-error: unsupported operation: unable to copy parts of a pointer from memory at ALLOC+HALF_PTR\n-  --> $DIR/copy_half_a_pointer.rs:LL:CC\n-   |\n-LL |         let _x = d_alias.read_unaligned();\n-   |                  ^^^^^^^^^^^^^^^^^^^^^^^^ unable to copy parts of a pointer from memory at ALLOC+HALF_PTR\n-   |\n-   = help: this is likely not a bug in the program; it indicates that the program performed an operation that the interpreter does not support\n-   = note: BACKTRACE:\n-   = note: inside `main` at $DIR/copy_half_a_pointer.rs:LL:CC\n-\n-note: some details are omitted, run with `MIRIFLAGS=-Zmiri-backtrace=full` for a verbose backtrace\n-\n-error: aborting due to previous error\n-"}, {"sha": "d3a68fbdd018f6aa13bb832c00c13e49a227e676", "filename": "src/tools/miri/tests/fail/provenance/pointer_partial_overwrite.rs", "status": "renamed", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fprovenance%2Fpointer_partial_overwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fprovenance%2Fpointer_partial_overwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fprovenance%2Fpointer_partial_overwrite.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -2,16 +2,13 @@\n //@compile-flags: -Zmiri-disable-alignment-check -Zmiri-disable-stacked-borrows -Zmiri-disable-validation\n \n // Test what happens when we overwrite parts of a pointer.\n-// Also see <https://github.com/rust-lang/miri/issues/2181>.\n \n fn main() {\n     let mut p = &42;\n     unsafe {\n         let ptr: *mut _ = &mut p;\n-        *(ptr as *mut u8) = 123; // if we ever support 8 bit pointers, this is gonna cause\n-        // \"attempted to interpret some raw bytes as a pointer address\" instead of\n-        // \"attempted to read undefined bytes\"\n+        *(ptr as *mut u8) = 123; // this removes provenance from one of the bytes, meaning the entire ptr is considered to have no provenance.\n     }\n-    let x = *p; //~ ERROR: this operation requires initialized memory\n+    let x = *p; //~ ERROR: no provenance\n     panic!(\"this should never print: {}\", x);\n }", "previous_filename": "src/tools/miri/tests/fail/pointer_partial_overwrite.rs"}, {"sha": "06e5ede8c7788447bb204c9df009d115331d1027", "filename": "src/tools/miri/tests/fail/provenance/pointer_partial_overwrite.stderr", "status": "renamed", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fprovenance%2Fpointer_partial_overwrite.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fprovenance%2Fpointer_partial_overwrite.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Ffail%2Fprovenance%2Fpointer_partial_overwrite.stderr?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -1,8 +1,8 @@\n-error: Undefined Behavior: using uninitialized data, but this operation requires initialized memory\n+error: Undefined Behavior: dereferencing pointer failed: $HEX[noalloc] is a dangling pointer (it has no provenance)\n   --> $DIR/pointer_partial_overwrite.rs:LL:CC\n    |\n LL |     let x = *p;\n-   |             ^^ using uninitialized data, but this operation requires initialized memory\n+   |             ^^ dereferencing pointer failed: $HEX[noalloc] is a dangling pointer (it has no provenance)\n    |\n    = help: this indicates a bug in the program: it performed an invalid operation, and caused Undefined Behavior\n    = help: see https://doc.rust-lang.org/nightly/reference/behavior-considered-undefined.html for further information", "previous_filename": "src/tools/miri/tests/fail/pointer_partial_overwrite.stderr"}, {"sha": "b18d903e36cebf07950473644d630600deb8b2bd", "filename": "src/tools/miri/tests/pass/provenance.rs", "status": "added", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fprovenance.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2cef9e3d19087a83fe1431ab8fd915cffd6a22ec/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fprovenance.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Ftests%2Fpass%2Fprovenance.rs?ref=2cef9e3d19087a83fe1431ab8fd915cffd6a22ec", "patch": "@@ -0,0 +1,139 @@\n+#![feature(strict_provenance)]\n+#![feature(pointer_byte_offsets)]\n+use std::{mem, ptr};\n+\n+const PTR_SIZE: usize = mem::size_of::<&i32>();\n+\n+fn main() {\n+    basic();\n+    partial_overwrite_then_restore();\n+    bytewise_ptr_methods();\n+    bytewise_custom_memcpy();\n+    bytewise_custom_memcpy_chunked();\n+}\n+\n+/// Some basic smoke tests for provenance.\n+fn basic() {\n+    let x = &42;\n+    let ptr = x as *const i32;\n+    let addr: usize = unsafe { mem::transmute(ptr) }; // an integer without provenance\n+    // But we can give provenance back via `with_addr`.\n+    let ptr_back = ptr.with_addr(addr);\n+    assert_eq!(unsafe { *ptr_back }, 42);\n+\n+    // It is preserved by MaybeUninit.\n+    let addr_mu: mem::MaybeUninit<usize> = unsafe { mem::transmute(ptr) };\n+    let ptr_back: *const i32 = unsafe { mem::transmute(addr_mu) };\n+    assert_eq!(unsafe { *ptr_back }, 42);\n+}\n+\n+/// Overwrite one byte of a pointer, then restore it.\n+fn partial_overwrite_then_restore() {\n+    unsafe fn ptr_bytes<'x>(ptr: &'x mut *const i32) -> &'x mut [mem::MaybeUninit<u8>; PTR_SIZE] {\n+        mem::transmute(ptr)\n+    }\n+\n+    // Returns a value with the same provenance as `x` but 0 for the integer value.\n+    // `x` must be initialized.\n+    unsafe fn zero_with_provenance(x: mem::MaybeUninit<u8>) -> mem::MaybeUninit<u8> {\n+        let ptr = [x; PTR_SIZE];\n+        let ptr: *const i32 = mem::transmute(ptr);\n+        let mut ptr = ptr.with_addr(0);\n+        ptr_bytes(&mut ptr)[0]\n+    }\n+\n+    unsafe {\n+        let ptr = &42;\n+        let mut ptr = ptr as *const i32;\n+        // Get a bytewise view of the pointer.\n+        let ptr_bytes = ptr_bytes(&mut ptr);\n+\n+        // The highest bytes must be 0 for this to work.\n+        let hi = if cfg!(target_endian = \"little\") { ptr_bytes.len() - 1 } else { 0 };\n+        assert_eq!(*ptr_bytes[hi].as_ptr().cast::<u8>(), 0);\n+        // Overwrite provenance on the last byte.\n+        ptr_bytes[hi] = mem::MaybeUninit::new(0);\n+        // Restore it from the another byte.\n+        ptr_bytes[hi] = zero_with_provenance(ptr_bytes[1]);\n+\n+        // Now ptr should be good again.\n+        assert_eq!(*ptr, 42);\n+    }\n+}\n+\n+fn bytewise_ptr_methods() {\n+    let mut ptr1 = &1;\n+    let mut ptr2 = &2;\n+\n+    // Swap them, bytewise.\n+    unsafe {\n+        ptr::swap_nonoverlapping(\n+            &mut ptr1 as *mut _ as *mut mem::MaybeUninit<u8>,\n+            &mut ptr2 as *mut _ as *mut mem::MaybeUninit<u8>,\n+            mem::size_of::<&i32>(),\n+        );\n+    }\n+\n+    // Make sure they still work.\n+    assert_eq!(*ptr1, 2);\n+    assert_eq!(*ptr2, 1);\n+\n+    // TODO: also test ptr::swap, ptr::copy, ptr::copy_nonoverlapping.\n+}\n+\n+fn bytewise_custom_memcpy() {\n+    unsafe fn memcpy<T>(to: *mut T, from: *const T) {\n+        let to = to.cast::<mem::MaybeUninit<u8>>();\n+        let from = from.cast::<mem::MaybeUninit<u8>>();\n+        for i in 0..mem::size_of::<T>() {\n+            let b = from.add(i).read();\n+            to.add(i).write(b);\n+        }\n+    }\n+\n+    let ptr1 = &1;\n+    let mut ptr2 = &2;\n+\n+    // Copy, bytewise.\n+    unsafe { memcpy(&mut ptr2, &ptr1) };\n+\n+    // Make sure they still work.\n+    assert_eq!(*ptr1, 1);\n+    assert_eq!(*ptr2, 1);\n+}\n+\n+fn bytewise_custom_memcpy_chunked() {\n+    unsafe fn memcpy<T>(to: *mut T, from: *const T) {\n+        assert!(mem::size_of::<T>() % mem::size_of::<usize>() == 0);\n+        let count = mem::size_of::<T>() / mem::size_of::<usize>();\n+        let to = to.cast::<mem::MaybeUninit<usize>>();\n+        let from = from.cast::<mem::MaybeUninit<usize>>();\n+        for i in 0..count {\n+            let b = from.add(i).read();\n+            to.add(i).write(b);\n+        }\n+    }\n+\n+    // Prepare an array where pointers are stored at... interesting... offsets.\n+    let mut data = [0usize; 2 * PTR_SIZE];\n+    let mut offsets = vec![];\n+    for i in 0..mem::size_of::<usize>() {\n+        // We have 2*PTR_SIZE room for each of these pointers.\n+        let base = i * 2 * PTR_SIZE;\n+        // This one is mis-aligned by `i`.\n+        let offset = base + i;\n+        offsets.push(offset);\n+        // Store it there.\n+        unsafe { data.as_mut_ptr().byte_add(offset).cast::<&i32>().write_unaligned(&42) };\n+    }\n+\n+    // Now memcpy that.\n+    let mut data2 = [0usize; 2 * PTR_SIZE];\n+    unsafe { memcpy(&mut data2, &data) };\n+\n+    // And check the result.\n+    for &offset in &offsets {\n+        let ptr = unsafe { data2.as_ptr().byte_add(offset).cast::<&i32>().read_unaligned() };\n+        assert_eq!(*ptr, 42);\n+    }\n+}"}]}