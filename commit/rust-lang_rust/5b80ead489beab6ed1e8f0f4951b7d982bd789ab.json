{"sha": "5b80ead489beab6ed1e8f0f4951b7d982bd789ab", "node_id": "MDY6Q29tbWl0NzI0NzEyOjViODBlYWQ0ODliZWFiNmVkMWU4ZjBmNDk1MWI3ZDk4MmJkNzg5YWI=", "commit": {"author": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2019-09-30T04:21:30Z"}, "committer": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2019-09-30T04:21:30Z"}, "message": "syntax: misc cleanup", "tree": {"sha": "f7a45b0f16afa29a021ed33c60f515a550b0eb53", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f7a45b0f16afa29a021ed33c60f515a550b0eb53"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5b80ead489beab6ed1e8f0f4951b7d982bd789ab", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5b80ead489beab6ed1e8f0f4951b7d982bd789ab", "html_url": "https://github.com/rust-lang/rust/commit/5b80ead489beab6ed1e8f0f4951b7d982bd789ab", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5b80ead489beab6ed1e8f0f4951b7d982bd789ab/comments", "author": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d9d0e5d36bb6b3e23b4869196788bd10b5220f31", "url": "https://api.github.com/repos/rust-lang/rust/commits/d9d0e5d36bb6b3e23b4869196788bd10b5220f31", "html_url": "https://github.com/rust-lang/rust/commit/d9d0e5d36bb6b3e23b4869196788bd10b5220f31"}], "stats": {"total": 74, "additions": 30, "deletions": 44}, "files": [{"sha": "4853da865645fd5517f794929e8e119878dfda00", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 30, "deletions": 44, "changes": 74, "blob_url": "https://github.com/rust-lang/rust/blob/5b80ead489beab6ed1e8f0f4951b7d982bd789ab/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b80ead489beab6ed1e8f0f4951b7d982bd789ab/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=5b80ead489beab6ed1e8f0f4951b7d982bd789ab", "patch": "@@ -547,40 +547,38 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    crate fn check_ident(&mut self) -> bool {\n-        if self.token.is_ident() {\n+    fn check_or_expected(&mut self, ok: bool, mk_type: impl FnOnce() -> TokenType) -> bool {\n+        if ok {\n             true\n         } else {\n-            self.expected_tokens.push(TokenType::Ident);\n+            self.expected_tokens.push(mk_type());\n             false\n         }\n     }\n \n+    crate fn check_ident(&mut self) -> bool {\n+        self.check_or_expected(self.token.is_ident(), || TokenType::Ident)\n+    }\n+\n     fn check_path(&mut self) -> bool {\n-        if self.token.is_path_start() {\n-            true\n-        } else {\n-            self.expected_tokens.push(TokenType::Path);\n-            false\n-        }\n+        self.check_or_expected(self.token.is_path_start(), || TokenType::Path)\n     }\n \n     fn check_type(&mut self) -> bool {\n-        if self.token.can_begin_type() {\n-            true\n-        } else {\n-            self.expected_tokens.push(TokenType::Type);\n-            false\n-        }\n+        self.check_or_expected(self.token.can_begin_type(), || TokenType::Type)\n     }\n \n     fn check_const_arg(&mut self) -> bool {\n-        if self.token.can_begin_const_arg() {\n-            true\n-        } else {\n-            self.expected_tokens.push(TokenType::Const);\n-            false\n-        }\n+        self.check_or_expected(self.token.can_begin_const_arg(), || TokenType::Const)\n+    }\n+\n+    /// Checks to see if the next token is either `+` or `+=`.\n+    /// Otherwise returns `false`.\n+    fn check_plus(&mut self) -> bool {\n+        self.check_or_expected(\n+            self.token.is_like_plus(),\n+            || TokenType::Token(token::BinOp(token::Plus)),\n+        )\n     }\n \n     /// Expects and consumes a `+`. if `+=` is seen, replaces it with a `=`\n@@ -604,18 +602,6 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Checks to see if the next token is either `+` or `+=`.\n-    /// Otherwise returns `false`.\n-    fn check_plus(&mut self) -> bool {\n-        if self.token.is_like_plus() {\n-            true\n-        }\n-        else {\n-            self.expected_tokens.push(TokenType::Token(token::BinOp(token::Plus)));\n-            false\n-        }\n-    }\n-\n     /// Expects and consumes an `&`. If `&&` is seen, replaces it with a single\n     /// `&` and continues. If an `&` is not seen, signals an error.\n     fn expect_and(&mut self) -> PResult<'a, ()> {\n@@ -910,15 +896,13 @@ impl<'a> Parser<'a> {\n         self.expected_tokens.clear();\n     }\n \n-    pub fn look_ahead<R, F>(&self, dist: usize, f: F) -> R where\n-        F: FnOnce(&Token) -> R,\n-    {\n+    pub fn look_ahead<R>(&self, dist: usize, looker: impl FnOnce(&Token) -> R) -> R {\n         if dist == 0 {\n-            return f(&self.token);\n+            return looker(&self.token);\n         }\n \n         let frame = &self.token_cursor.frame;\n-        f(&match frame.tree_cursor.look_ahead(dist - 1) {\n+        looker(&match frame.tree_cursor.look_ahead(dist - 1) {\n             Some(tree) => match tree {\n                 TokenTree::Token(token) => token,\n                 TokenTree::Delimited(dspan, delim, _) =>\n@@ -1008,9 +992,10 @@ impl<'a> Parser<'a> {\n         Ok((delim, tts.into()))\n     }\n \n-    fn parse_or_use_outer_attributes(&mut self,\n-                                     already_parsed_attrs: Option<ThinVec<Attribute>>)\n-                                     -> PResult<'a, ThinVec<Attribute>> {\n+    fn parse_or_use_outer_attributes(\n+        &mut self,\n+        already_parsed_attrs: Option<ThinVec<Attribute>>,\n+    ) -> PResult<'a, ThinVec<Attribute>> {\n         if let Some(attrs) = already_parsed_attrs {\n             Ok(attrs)\n         } else {\n@@ -1539,9 +1524,10 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    fn collect_tokens<F, R>(&mut self, f: F) -> PResult<'a, (R, TokenStream)>\n-        where F: FnOnce(&mut Self) -> PResult<'a, R>\n-    {\n+    fn collect_tokens<R>(\n+        &mut self,\n+        f: impl FnOnce(&mut Self) -> PResult<'a, R>,\n+    ) -> PResult<'a, (R, TokenStream)> {\n         // Record all tokens we parse when parsing this item.\n         let mut tokens = Vec::new();\n         let prev_collecting = match self.token_cursor.frame.last_token {"}]}