{"sha": "f702b20dfd22990a326af9221cb3ed9b389c8307", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY3MDJiMjBkZmQyMjk5MGEzMjZhZjkyMjFjYjNlZDliMzg5YzgzMDc=", "commit": {"author": {"name": "Eduard Burtescu", "email": "edy.burt@gmail.com", "date": "2016-06-10T10:00:21Z"}, "committer": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2017-02-28T06:30:07Z"}, "message": "rustc_save_analysis: don't pollute the codemap with fake files.", "tree": {"sha": "60ee6a9747fc06a246a612f3d01a829fb17d50ec", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/60ee6a9747fc06a246a612f3d01a829fb17d50ec"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f702b20dfd22990a326af9221cb3ed9b389c8307", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f702b20dfd22990a326af9221cb3ed9b389c8307", "html_url": "https://github.com/rust-lang/rust/commit/f702b20dfd22990a326af9221cb3ed9b389c8307", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f702b20dfd22990a326af9221cb3ed9b389c8307/comments", "author": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d9f0a949fd6b74641b12afc0f8a17f00919ebcef", "url": "https://api.github.com/repos/rust-lang/rust/commits/d9f0a949fd6b74641b12afc0f8a17f00919ebcef", "html_url": "https://github.com/rust-lang/rust/commit/d9f0a949fd6b74641b12afc0f8a17f00919ebcef"}], "stats": {"total": 113, "additions": 54, "deletions": 59}, "files": [{"sha": "b5add6404fc9f0e37f953c77fba7583c7fa416d7", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 16, "deletions": 51, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/f702b20dfd22990a326af9221cb3ed9b389c8307/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f702b20dfd22990a326af9221cb3ed9b389c8307/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=f702b20dfd22990a326af9221cb3ed9b389c8307", "patch": "@@ -17,7 +17,6 @@ use std::env;\n use std::path::Path;\n \n use syntax::ast;\n-use syntax::parse::filemap_to_tts;\n use syntax::parse::lexer::{self, StringReader};\n use syntax::parse::token::{self, Token};\n use syntax::symbol::keywords;\n@@ -49,23 +48,6 @@ impl<'a> SpanUtils<'a> {\n         }\n     }\n \n-    // sub_span starts at span.lo, so we need to adjust the positions etc.\n-    // If sub_span is None, we don't need to adjust.\n-    pub fn make_sub_span(&self, span: Span, sub_span: Option<Span>) -> Option<Span> {\n-        match sub_span {\n-            None => None,\n-            Some(sub) => {\n-                let FileMapAndBytePos {fm, pos} = self.sess.codemap().lookup_byte_offset(span.lo);\n-                let base = pos + fm.start_pos;\n-                Some(Span {\n-                    lo: base + self.sess.codemap().lookup_byte_offset(sub.lo).pos,\n-                    hi: base + self.sess.codemap().lookup_byte_offset(sub.hi).pos,\n-                    expn_id: span.expn_id,\n-                })\n-            }\n-        }\n-    }\n-\n     pub fn snippet(&self, span: Span) -> String {\n         match self.sess.codemap().span_to_snippet(span) {\n             Ok(s) => s,\n@@ -74,24 +56,7 @@ impl<'a> SpanUtils<'a> {\n     }\n \n     pub fn retokenise_span(&self, span: Span) -> StringReader<'a> {\n-        // sadness - we don't have spans for sub-expressions nor access to the tokens\n-        // so in order to get extents for the function name itself (which dxr expects)\n-        // we need to re-tokenise the fn definition\n-\n-        // Note: this is a bit awful - it adds the contents of span to the end of\n-        // the codemap as a new filemap. This is mostly OK, but means we should\n-        // not iterate over the codemap. Also, any spans over the new filemap\n-        // are incompatible with spans over other filemaps.\n-        let filemap = self.sess\n-                          .codemap()\n-                          .new_filemap(String::from(\"<anon-dxr>\"), None, self.snippet(span));\n-        lexer::StringReader::new(&self.sess.parse_sess, filemap)\n-    }\n-\n-    fn span_to_tts(&self, span: Span) -> Vec<TokenTree> {\n-        let filename = String::from(\"<anon-dxr>\");\n-        let filemap = self.sess.codemap().new_filemap(filename, None, self.snippet(span));\n-        filemap_to_tts(&self.sess.parse_sess, filemap)\n+        lexer::StringReader::retokenize(&self.sess.parse_sess, span)\n     }\n \n     // Re-parses a path and returns the span for the last identifier in the path\n@@ -103,7 +68,7 @@ impl<'a> SpanUtils<'a> {\n         loop {\n             let ts = toks.real_token();\n             if ts.tok == token::Eof {\n-                return self.make_sub_span(span, result)\n+                return result\n             }\n             if bracket_count == 0 && (ts.tok.is_ident() || ts.tok.is_keyword(keywords::SelfValue)) {\n                 result = Some(ts.sp);\n@@ -128,7 +93,7 @@ impl<'a> SpanUtils<'a> {\n                 return None;\n             }\n             if bracket_count == 0 && (ts.tok.is_ident() || ts.tok.is_keyword(keywords::SelfValue)) {\n-                return self.make_sub_span(span, Some(ts.sp));\n+                return Some(ts.sp);\n             }\n \n             bracket_count += match ts.tok {\n@@ -178,10 +143,7 @@ impl<'a> SpanUtils<'a> {\n             }\n             prev = next;\n         }\n-        if result.is_none() && prev_span.is_some() {\n-            return self.make_sub_span(span, prev_span);\n-        }\n-        return self.make_sub_span(span, result);\n+        result.or(prev_span)\n     }\n \n     // Return the span for the last ident before a `<` and outside any\n@@ -241,9 +203,9 @@ impl<'a> SpanUtils<'a> {\n                       loc.line);\n         }\n         if result.is_none() && prev.tok.is_ident() && angle_count == 0 {\n-            return self.make_sub_span(span, Some(prev.sp));\n+            return Some(prev.sp);\n         }\n-        self.make_sub_span(span, result)\n+        result\n     }\n \n     // Reparse span and return an owned vector of sub spans of the first limit\n@@ -310,7 +272,7 @@ impl<'a> SpanUtils<'a> {\n                 angle_count += 1;\n             }\n             if ts.tok.is_ident() && angle_count == nesting {\n-                result.push(self.make_sub_span(span, Some(ts.sp)).unwrap());\n+                result.push(ts.sp);\n             }\n         }\n     }\n@@ -320,8 +282,11 @@ impl<'a> SpanUtils<'a> {\n     /// end of the 'signature' part, that is up to, but not including an opening\n     /// brace or semicolon.\n     pub fn signature_string_for_span(&self, span: Span) -> String {\n-        let mut toks = self.span_to_tts(span).into_iter();\n+        let mut toks = self.retokenise_span(span);\n+        toks.real_token();\n+        let mut toks = toks.parse_all_token_trees().unwrap().into_iter();\n         let mut prev = toks.next().unwrap();\n+\n         let first_span = prev.get_span();\n         let mut angle_count = 0;\n         for tok in toks {\n@@ -360,7 +325,7 @@ impl<'a> SpanUtils<'a> {\n             }\n             let next = toks.real_token();\n             if next.tok == tok {\n-                return self.make_sub_span(span, Some(prev.sp));\n+                return Some(prev.sp);\n             }\n             prev = next;\n         }\n@@ -374,7 +339,7 @@ impl<'a> SpanUtils<'a> {\n                 return None;\n             }\n             if next.tok == tok {\n-                return self.make_sub_span(span, Some(next.sp));\n+                return Some(next.sp);\n             }\n         }\n     }\n@@ -399,7 +364,7 @@ impl<'a> SpanUtils<'a> {\n                 if ts.tok == token::Eof {\n                     return None\n                 } else {\n-                    return self.make_sub_span(span, Some(ts.sp));\n+                    return Some(ts.sp);\n                 }\n             }\n         }\n@@ -444,7 +409,7 @@ impl<'a> SpanUtils<'a> {\n             if ts.tok == token::Not {\n                 let ts = toks.real_token();\n                 if ts.tok.is_ident() {\n-                    return self.make_sub_span(span, Some(ts.sp));\n+                    return Some(ts.sp);\n                 } else {\n                     return None;\n                 }\n@@ -463,7 +428,7 @@ impl<'a> SpanUtils<'a> {\n             let ts = toks.real_token();\n             if ts.tok == token::Not {\n                 if prev.tok.is_ident() {\n-                    return self.make_sub_span(span, Some(prev.sp));\n+                    return Some(prev.sp);\n                 } else {\n                     return None;\n                 }"}, {"sha": "b7f6e6a2384f71d56435e3f3b0b12711dfd25c15", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 38, "deletions": 8, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/f702b20dfd22990a326af9221cb3ed9b389c8307/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f702b20dfd22990a326af9221cb3ed9b389c8307/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=f702b20dfd22990a326af9221cb3ed9b389c8307", "patch": "@@ -51,10 +51,10 @@ pub struct StringReader<'a> {\n     pub filemap: Rc<syntax_pos::FileMap>,\n     /// If Some, stop reading the source at this position (inclusive).\n     pub terminator: Option<BytePos>,\n-    /// Whether to record new-lines in filemap. This is only necessary the first\n-    /// time a filemap is lexed. If part of a filemap is being re-lexed, this\n-    /// should be set to false.\n-    pub save_new_lines: bool,\n+    /// Whether to record new-lines and multibyte chars in filemap.\n+    /// This is only necessary the first time a filemap is lexed.\n+    /// If part of a filemap is being re-lexed, this should be set to false.\n+    pub save_new_lines_and_multibyte: bool,\n     // cached:\n     pub peek_tok: token::Token,\n     pub peek_span: Span,\n@@ -162,7 +162,7 @@ impl<'a> StringReader<'a> {\n             ch: Some('\\n'),\n             filemap: filemap,\n             terminator: None,\n-            save_new_lines: true,\n+            save_new_lines_and_multibyte: true,\n             // dummy values; not read\n             peek_tok: token::Eof,\n             peek_span: syntax_pos::DUMMY_SP,\n@@ -183,6 +183,31 @@ impl<'a> StringReader<'a> {\n         sr\n     }\n \n+    pub fn retokenize(sess: &'a ParseSess, mut span: Span) -> Self {\n+        let begin = sess.codemap().lookup_byte_offset(span.lo);\n+        let end = sess.codemap().lookup_byte_offset(span.hi);\n+\n+        // Make the range zero-length if the span is invalid.\n+        if span.lo > span.hi || begin.fm.start_pos != end.fm.start_pos {\n+            span.hi = span.lo;\n+        }\n+\n+        let mut sr = StringReader::new_raw_internal(sess, begin.fm);\n+\n+        // Seek the lexer to the right byte range.\n+        sr.save_new_lines_and_multibyte = false;\n+        sr.next_pos = span.lo;\n+        sr.terminator = Some(span.hi);\n+\n+        sr.bump();\n+\n+        if let Err(_) = sr.advance_token() {\n+            sr.emit_fatal_errors();\n+            panic!(FatalError);\n+        }\n+        sr\n+    }\n+\n     pub fn ch_is(&self, c: char) -> bool {\n         self.ch == Some(c)\n     }\n@@ -378,7 +403,10 @@ impl<'a> StringReader<'a> {\n     pub fn bump(&mut self) {\n         let new_pos = self.next_pos;\n         let new_byte_offset = self.byte_offset(new_pos).to_usize();\n-        if new_byte_offset < self.source_text.len() {\n+        let end = self.terminator.map_or(self.source_text.len(), |t| {\n+            self.byte_offset(t).to_usize()\n+        });\n+        if new_byte_offset < end {\n             let old_ch_is_newline = self.ch.unwrap() == '\\n';\n             let new_ch = char_at(&self.source_text, new_byte_offset);\n             let new_ch_len = new_ch.len_utf8();\n@@ -387,15 +415,17 @@ impl<'a> StringReader<'a> {\n             self.pos = new_pos;\n             self.next_pos = new_pos + Pos::from_usize(new_ch_len);\n             if old_ch_is_newline {\n-                if self.save_new_lines {\n+                if self.save_new_lines_and_multibyte {\n                     self.filemap.next_line(self.pos);\n                 }\n                 self.col = CharPos(0);\n             } else {\n                 self.col = self.col + CharPos(1);\n             }\n             if new_ch_len > 1 {\n-                self.filemap.record_multibyte_char(self.pos, new_ch_len);\n+                if self.save_new_lines_and_multibyte {\n+                    self.filemap.record_multibyte_char(self.pos, new_ch_len);\n+                }\n             }\n         } else {\n             self.ch = None;"}]}