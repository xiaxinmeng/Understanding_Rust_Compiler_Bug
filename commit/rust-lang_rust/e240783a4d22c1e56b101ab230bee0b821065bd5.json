{"sha": "e240783a4d22c1e56b101ab230bee0b821065bd5", "node_id": "C_kwDOAAsO6NoAKGUyNDA3ODNhNGQyMmMxZTU2YjEwMWFiMjMwYmVlMGI4MjEwNjViZDU", "commit": {"author": {"name": "Mark Rousskov", "email": "mark.simulacrum@gmail.com", "date": "2022-02-07T16:03:51Z"}, "committer": {"name": "Mark Rousskov", "email": "mark.simulacrum@gmail.com", "date": "2022-02-08T23:49:55Z"}, "message": "Switch QueryJobId to a single global counter\n\nThis replaces the per-shard counters with a single global counter, simplifying\nthe JobId struct down to just a u64 and removing the need to pipe a DepKind\ngeneric through a bunch of code. The performance implications on non-parallel\ncompilers are likely minimal (this switches to `Cell<u64>` as the backing\nstorage over a `u64`, but the latter was already inside a `RefCell` so it's not\nreally a significance divergence). On parallel compilers, the cost of a single\nglobal u64 counter may be more significant: it adds a serialization point in\ntheory. On the other hand, we can imagine changing the counter to have a\nthread-local component if it becomes worrisome or some similar structure.\n\nThe new design is sufficiently simpler that it warrants the potential for slight\nchanges down the line if/when we get parallel compilation to be more of a\ndefault.\n\nA u64 counter, instead of u32 (the old per-shard width), is chosen to avoid\npossibly overflowing it and causing problems; it is effectively impossible that\nwe would overflow a u64 counter in this context.", "tree": {"sha": "c7093199316fffe10e02e03a567a748f93bbdcee", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c7093199316fffe10e02e03a567a748f93bbdcee"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e240783a4d22c1e56b101ab230bee0b821065bd5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e240783a4d22c1e56b101ab230bee0b821065bd5", "html_url": "https://github.com/rust-lang/rust/commit/e240783a4d22c1e56b101ab230bee0b821065bd5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e240783a4d22c1e56b101ab230bee0b821065bd5/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "88fb06a1f331926bccb448acdb52966fd1ec8a92", "url": "https://api.github.com/repos/rust-lang/rust/commits/88fb06a1f331926bccb448acdb52966fd1ec8a92", "html_url": "https://github.com/rust-lang/rust/commit/88fb06a1f331926bccb448acdb52966fd1ec8a92"}], "stats": {"total": 292, "additions": 115, "deletions": 177}, "files": [{"sha": "273d6771907faefa1504df8c783594b12ac38bf4", "filename": "compiler/rustc_middle/src/ty/context.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -1668,7 +1668,7 @@ CloneLiftImpls! { for<'tcx> { Constness, traits::WellFormedLoc, } }\n pub mod tls {\n     use super::{ptr_eq, GlobalCtxt, TyCtxt};\n \n-    use crate::dep_graph::{DepKind, TaskDepsRef};\n+    use crate::dep_graph::TaskDepsRef;\n     use crate::ty::query;\n     use rustc_data_structures::sync::{self, Lock};\n     use rustc_data_structures::thin_vec::ThinVec;\n@@ -1693,7 +1693,7 @@ pub mod tls {\n \n         /// The current query job, if any. This is updated by `JobOwner::start` in\n         /// `ty::query::plumbing` when executing a query.\n-        pub query: Option<query::QueryJobId<DepKind>>,\n+        pub query: Option<query::QueryJobId>,\n \n         /// Where to store diagnostics for the current query job, if any.\n         /// This is updated by `JobOwner::start` in `ty::query::plumbing` when executing a query."}, {"sha": "f6bce7486791c465586291868c8913e4aa234007", "filename": "compiler/rustc_query_impl/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_impl%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_impl%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Flib.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -15,6 +15,7 @@ extern crate rustc_macros;\n extern crate rustc_middle;\n \n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n+use rustc_data_structures::sync::AtomicU64;\n use rustc_middle::arena::Arena;\n use rustc_middle::dep_graph::{self, DepKindStruct, SerializedDepNodeIndex};\n use rustc_middle::ty::query::{query_keys, query_storage, query_stored, query_values};"}, {"sha": "326ba999bc3b589b3a8d9eddd4584a7157354366", "filename": "compiler/rustc_query_impl/src/plumbing.rs", "status": "modified", "additions": 21, "deletions": 12, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -3,7 +3,7 @@\n //! manage the caches, and so forth.\n \n use crate::{on_disk_cache, Queries};\n-use rustc_middle::dep_graph::{DepKind, DepNodeIndex, SerializedDepNodeIndex};\n+use rustc_middle::dep_graph::{DepNodeIndex, SerializedDepNodeIndex};\n use rustc_middle::ty::tls::{self, ImplicitCtxt};\n use rustc_middle::ty::TyCtxt;\n use rustc_query_system::dep_graph::HasDepContext;\n@@ -15,6 +15,7 @@ use rustc_errors::{Diagnostic, Handler};\n use rustc_serialize::opaque;\n \n use std::any::Any;\n+use std::num::NonZeroU64;\n \n #[derive(Copy, Clone)]\n pub struct QueryCtxt<'tcx> {\n@@ -42,11 +43,20 @@ impl<'tcx> HasDepContext for QueryCtxt<'tcx> {\n }\n \n impl QueryContext for QueryCtxt<'_> {\n-    fn current_query_job(&self) -> Option<QueryJobId<Self::DepKind>> {\n+    fn next_job_id(&self) -> QueryJobId {\n+        QueryJobId(\n+            NonZeroU64::new(\n+                self.queries.jobs.fetch_add(1, rustc_data_structures::sync::Ordering::Relaxed),\n+            )\n+            .unwrap(),\n+        )\n+    }\n+\n+    fn current_query_job(&self) -> Option<QueryJobId> {\n         tls::with_related_context(**self, |icx| icx.query)\n     }\n \n-    fn try_collect_active_jobs(&self) -> Option<QueryMap<Self::DepKind>> {\n+    fn try_collect_active_jobs(&self) -> Option<QueryMap> {\n         self.queries.try_collect_active_jobs(**self)\n     }\n \n@@ -81,7 +91,7 @@ impl QueryContext for QueryCtxt<'_> {\n     #[inline(always)]\n     fn start_query<R>(\n         &self,\n-        token: QueryJobId<Self::DepKind>,\n+        token: QueryJobId,\n         diagnostics: Option<&Lock<ThinVec<Diagnostic>>>,\n         compute: impl FnOnce() -> R,\n     ) -> R {\n@@ -152,7 +162,7 @@ impl<'tcx> QueryCtxt<'tcx> {\n \n     pub fn try_print_query_stack(\n         self,\n-        query: Option<QueryJobId<DepKind>>,\n+        query: Option<QueryJobId>,\n         handler: &Handler,\n         num_frames: Option<usize>,\n     ) -> usize {\n@@ -320,7 +330,7 @@ macro_rules! define_queries {\n             type Cache = query_storage::$name<$tcx>;\n \n             #[inline(always)]\n-            fn query_state<'a>(tcx: QueryCtxt<$tcx>) -> &'a QueryState<crate::dep_graph::DepKind, Self::Key>\n+            fn query_state<'a>(tcx: QueryCtxt<$tcx>) -> &'a QueryState<Self::Key>\n                 where QueryCtxt<$tcx>: 'a\n             {\n                 &tcx.queries.$name\n@@ -471,10 +481,9 @@ macro_rules! define_queries_struct {\n \n             pub on_disk_cache: Option<OnDiskCache<$tcx>>,\n \n-            $($(#[$attr])*  $name: QueryState<\n-                crate::dep_graph::DepKind,\n-                query_keys::$name<$tcx>,\n-            >,)*\n+            jobs: AtomicU64,\n+\n+            $($(#[$attr])*  $name: QueryState<query_keys::$name<$tcx>>,)*\n         }\n \n         impl<$tcx> Queries<$tcx> {\n@@ -487,21 +496,21 @@ macro_rules! define_queries_struct {\n                     local_providers: Box::new(local_providers),\n                     extern_providers: Box::new(extern_providers),\n                     on_disk_cache,\n+                    jobs: AtomicU64::new(1),\n                     $($name: Default::default()),*\n                 }\n             }\n \n             pub(crate) fn try_collect_active_jobs(\n                 &$tcx self,\n                 tcx: TyCtxt<$tcx>,\n-            ) -> Option<QueryMap<crate::dep_graph::DepKind>> {\n+            ) -> Option<QueryMap> {\n                 let tcx = QueryCtxt { tcx, queries: self };\n                 let mut jobs = QueryMap::default();\n \n                 $(\n                     self.$name.try_collect_active_jobs(\n                         tcx,\n-                        dep_graph::DepKind::$name,\n                         make_query::$name,\n                         &mut jobs,\n                     )?;"}, {"sha": "b1ff1e15a9db53e0367d0fc895f2056c78c809ac", "filename": "compiler/rustc_query_system/src/query/config.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -59,7 +59,7 @@ pub trait QueryDescription<CTX: QueryContext>: QueryConfig {\n     fn describe(tcx: CTX, key: Self::Key) -> String;\n \n     // Don't use this method to access query results, instead use the methods on TyCtxt\n-    fn query_state<'a>(tcx: CTX) -> &'a QueryState<CTX::DepKind, Self::Key>\n+    fn query_state<'a>(tcx: CTX) -> &'a QueryState<Self::Key>\n     where\n         CTX: 'a;\n "}, {"sha": "adf878a7f04c189a84c025e9737bb09a7ced0fee", "filename": "compiler/rustc_query_system/src/query/job.rs", "status": "modified", "additions": 54, "deletions": 101, "changes": 155, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -7,13 +7,11 @@ use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, Handler, Leve\n use rustc_session::Session;\n use rustc_span::Span;\n \n-use std::convert::TryFrom;\n use std::hash::Hash;\n-use std::num::NonZeroU32;\n+use std::num::NonZeroU64;\n \n #[cfg(parallel_compiler)]\n use {\n-    crate::dep_graph::DepKind,\n     parking_lot::{Condvar, Mutex},\n     rustc_data_structures::fx::FxHashSet,\n     rustc_data_structures::sync::Lock,\n@@ -33,80 +31,57 @@ pub struct QueryInfo {\n     pub query: QueryStackFrame,\n }\n \n-pub type QueryMap<D> = FxHashMap<QueryJobId<D>, QueryJobInfo<D>>;\n-\n-/// A value uniquely identifying an active query job within a shard in the query cache.\n-#[derive(Copy, Clone, Eq, PartialEq, Hash)]\n-pub struct QueryShardJobId(pub NonZeroU32);\n+pub type QueryMap = FxHashMap<QueryJobId, QueryJobInfo>;\n \n /// A value uniquely identifying an active query job.\n #[derive(Copy, Clone, Eq, PartialEq, Hash)]\n-pub struct QueryJobId<D> {\n-    /// Which job within a shard is this\n-    pub job: QueryShardJobId,\n-\n-    /// In which shard is this job\n-    pub shard: u16,\n+pub struct QueryJobId(pub NonZeroU64);\n \n-    /// What kind of query this job is.\n-    pub kind: D,\n-}\n-\n-impl<D> QueryJobId<D>\n-where\n-    D: Copy + Clone + Eq + Hash,\n-{\n-    pub fn new(job: QueryShardJobId, shard: usize, kind: D) -> Self {\n-        QueryJobId { job, shard: u16::try_from(shard).unwrap(), kind }\n-    }\n-\n-    fn query(self, map: &QueryMap<D>) -> QueryStackFrame {\n+impl QueryJobId {\n+    fn query(self, map: &QueryMap) -> QueryStackFrame {\n         map.get(&self).unwrap().query.clone()\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn span(self, map: &QueryMap<D>) -> Span {\n+    fn span(self, map: &QueryMap) -> Span {\n         map.get(&self).unwrap().job.span\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn parent(self, map: &QueryMap<D>) -> Option<QueryJobId<D>> {\n+    fn parent(self, map: &QueryMap) -> Option<QueryJobId> {\n         map.get(&self).unwrap().job.parent\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn latch<'a>(self, map: &'a QueryMap<D>) -> Option<&'a QueryLatch<D>> {\n+    fn latch<'a>(self, map: &'a QueryMap) -> Option<&'a QueryLatch> {\n         map.get(&self).unwrap().job.latch.as_ref()\n     }\n }\n \n-pub struct QueryJobInfo<D> {\n+pub struct QueryJobInfo {\n     pub query: QueryStackFrame,\n-    pub job: QueryJob<D>,\n+    pub job: QueryJob,\n }\n \n /// Represents an active query job.\n #[derive(Clone)]\n-pub struct QueryJob<D> {\n-    pub id: QueryShardJobId,\n+pub struct QueryJob {\n+    pub id: QueryJobId,\n \n     /// The span corresponding to the reason for which this query was required.\n     pub span: Span,\n \n     /// The parent query job which created this job and is implicitly waiting on it.\n-    pub parent: Option<QueryJobId<D>>,\n+    pub parent: Option<QueryJobId>,\n \n     /// The latch that is used to wait on this job.\n     #[cfg(parallel_compiler)]\n-    latch: Option<QueryLatch<D>>,\n+    latch: Option<QueryLatch>,\n }\n \n-impl<D> QueryJob<D>\n-where\n-    D: Copy + Clone + Eq + Hash,\n-{\n+impl QueryJob {\n     /// Creates a new query job.\n-    pub fn new(id: QueryShardJobId, span: Span, parent: Option<QueryJobId<D>>) -> Self {\n+    pub fn new(id: QueryJobId, span: Span, parent: Option<QueryJobId>) -> Self {\n         QueryJob {\n             id,\n             span,\n@@ -117,7 +92,7 @@ where\n     }\n \n     #[cfg(parallel_compiler)]\n-    pub(super) fn latch(&mut self) -> QueryLatch<D> {\n+    pub(super) fn latch(&mut self) -> QueryLatch {\n         if self.latch.is_none() {\n             self.latch = Some(QueryLatch::new());\n         }\n@@ -139,16 +114,13 @@ where\n }\n \n #[cfg(not(parallel_compiler))]\n-impl<D> QueryJobId<D>\n-where\n-    D: Copy + Clone + Eq + Hash,\n-{\n+impl QueryJobId {\n     #[cold]\n     #[inline(never)]\n     pub(super) fn find_cycle_in_stack(\n         &self,\n-        query_map: QueryMap<D>,\n-        current_job: &Option<QueryJobId<D>>,\n+        query_map: QueryMap,\n+        current_job: &Option<QueryJobId>,\n         span: Span,\n     ) -> CycleError {\n         // Find the waitee amongst `current_job` parents\n@@ -184,50 +156,43 @@ where\n }\n \n #[cfg(parallel_compiler)]\n-struct QueryWaiter<D> {\n-    query: Option<QueryJobId<D>>,\n+struct QueryWaiter {\n+    query: Option<QueryJobId>,\n     condvar: Condvar,\n     span: Span,\n     cycle: Lock<Option<CycleError>>,\n }\n \n #[cfg(parallel_compiler)]\n-impl<D> QueryWaiter<D> {\n+impl QueryWaiter {\n     fn notify(&self, registry: &rayon_core::Registry) {\n         rayon_core::mark_unblocked(registry);\n         self.condvar.notify_one();\n     }\n }\n \n #[cfg(parallel_compiler)]\n-struct QueryLatchInfo<D> {\n+struct QueryLatchInfo {\n     complete: bool,\n-    waiters: Vec<Lrc<QueryWaiter<D>>>,\n+    waiters: Vec<Lrc<QueryWaiter>>,\n }\n \n #[cfg(parallel_compiler)]\n #[derive(Clone)]\n-pub(super) struct QueryLatch<D> {\n-    info: Lrc<Mutex<QueryLatchInfo<D>>>,\n+pub(super) struct QueryLatch {\n+    info: Lrc<Mutex<QueryLatchInfo>>,\n }\n \n #[cfg(parallel_compiler)]\n-impl<D: Eq + Hash> QueryLatch<D> {\n+impl QueryLatch {\n     fn new() -> Self {\n         QueryLatch {\n             info: Lrc::new(Mutex::new(QueryLatchInfo { complete: false, waiters: Vec::new() })),\n         }\n     }\n-}\n \n-#[cfg(parallel_compiler)]\n-impl<D> QueryLatch<D> {\n     /// Awaits for the query job to complete.\n-    pub(super) fn wait_on(\n-        &self,\n-        query: Option<QueryJobId<D>>,\n-        span: Span,\n-    ) -> Result<(), CycleError> {\n+    pub(super) fn wait_on(&self, query: Option<QueryJobId>, span: Span) -> Result<(), CycleError> {\n         let waiter =\n             Lrc::new(QueryWaiter { query, span, cycle: Lock::new(None), condvar: Condvar::new() });\n         self.wait_on_inner(&waiter);\n@@ -242,7 +207,7 @@ impl<D> QueryLatch<D> {\n     }\n \n     /// Awaits the caller on this latch by blocking the current thread.\n-    fn wait_on_inner(&self, waiter: &Lrc<QueryWaiter<D>>) {\n+    fn wait_on_inner(&self, waiter: &Lrc<QueryWaiter>) {\n         let mut info = self.info.lock();\n         if !info.complete {\n             // We push the waiter on to the `waiters` list. It can be accessed inside\n@@ -276,7 +241,7 @@ impl<D> QueryLatch<D> {\n \n     /// Removes a single waiter from the list of waiters.\n     /// This is used to break query cycles.\n-    fn extract_waiter(&self, waiter: usize) -> Lrc<QueryWaiter<D>> {\n+    fn extract_waiter(&self, waiter: usize) -> Lrc<QueryWaiter> {\n         let mut info = self.info.lock();\n         debug_assert!(!info.complete);\n         // Remove the waiter from the list of waiters\n@@ -286,7 +251,7 @@ impl<D> QueryLatch<D> {\n \n /// A resumable waiter of a query. The usize is the index into waiters in the query's latch\n #[cfg(parallel_compiler)]\n-type Waiter<D> = (QueryJobId<D>, usize);\n+type Waiter = (QueryJobId, usize);\n \n /// Visits all the non-resumable and resumable waiters of a query.\n /// Only waiters in a query are visited.\n@@ -298,14 +263,9 @@ type Waiter<D> = (QueryJobId<D>, usize);\n /// required information to resume the waiter.\n /// If all `visit` calls returns None, this function also returns None.\n #[cfg(parallel_compiler)]\n-fn visit_waiters<D, F>(\n-    query_map: &QueryMap<D>,\n-    query: QueryJobId<D>,\n-    mut visit: F,\n-) -> Option<Option<Waiter<D>>>\n+fn visit_waiters<F>(query_map: &QueryMap, query: QueryJobId, mut visit: F) -> Option<Option<Waiter>>\n where\n-    D: Copy + Clone + Eq + Hash,\n-    F: FnMut(Span, QueryJobId<D>) -> Option<Option<Waiter<D>>>,\n+    F: FnMut(Span, QueryJobId) -> Option<Option<Waiter>>,\n {\n     // Visit the parent query which is a non-resumable waiter since it's on the same stack\n     if let Some(parent) = query.parent(query_map) {\n@@ -334,16 +294,13 @@ where\n /// If a cycle is detected, this initial value is replaced with the span causing\n /// the cycle.\n #[cfg(parallel_compiler)]\n-fn cycle_check<D>(\n-    query_map: &QueryMap<D>,\n-    query: QueryJobId<D>,\n+fn cycle_check(\n+    query_map: &QueryMap,\n+    query: QueryJobId,\n     span: Span,\n-    stack: &mut Vec<(Span, QueryJobId<D>)>,\n-    visited: &mut FxHashSet<QueryJobId<D>>,\n-) -> Option<Option<Waiter<D>>>\n-where\n-    D: Copy + Clone + Eq + Hash,\n-{\n+    stack: &mut Vec<(Span, QueryJobId)>,\n+    visited: &mut FxHashSet<QueryJobId>,\n+) -> Option<Option<Waiter>> {\n     if !visited.insert(query) {\n         return if let Some(p) = stack.iter().position(|q| q.1 == query) {\n             // We detected a query cycle, fix up the initial span and return Some\n@@ -378,14 +335,11 @@ where\n /// from `query` without going through any of the queries in `visited`.\n /// This is achieved with a depth first search.\n #[cfg(parallel_compiler)]\n-fn connected_to_root<D>(\n-    query_map: &QueryMap<D>,\n-    query: QueryJobId<D>,\n-    visited: &mut FxHashSet<QueryJobId<D>>,\n-) -> bool\n-where\n-    D: Copy + Clone + Eq + Hash,\n-{\n+fn connected_to_root(\n+    query_map: &QueryMap,\n+    query: QueryJobId,\n+    visited: &mut FxHashSet<QueryJobId>,\n+) -> bool {\n     // We already visited this or we're deliberately ignoring it\n     if !visited.insert(query) {\n         return false;\n@@ -404,10 +358,9 @@ where\n \n // Deterministically pick an query from a list\n #[cfg(parallel_compiler)]\n-fn pick_query<'a, D, T, F>(query_map: &QueryMap<D>, queries: &'a [T], f: F) -> &'a T\n+fn pick_query<'a, T, F>(query_map: &QueryMap, queries: &'a [T], f: F) -> &'a T\n where\n-    D: Copy + Clone + Eq + Hash,\n-    F: Fn(&T) -> (Span, QueryJobId<D>),\n+    F: Fn(&T) -> (Span, QueryJobId),\n {\n     // Deterministically pick an entry point\n     // FIXME: Sort this instead\n@@ -431,10 +384,10 @@ where\n /// If a cycle was not found, the starting query is removed from `jobs` and\n /// the function returns false.\n #[cfg(parallel_compiler)]\n-fn remove_cycle<D: DepKind>(\n-    query_map: &QueryMap<D>,\n-    jobs: &mut Vec<QueryJobId<D>>,\n-    wakelist: &mut Vec<Lrc<QueryWaiter<D>>>,\n+fn remove_cycle(\n+    query_map: &QueryMap,\n+    jobs: &mut Vec<QueryJobId>,\n+    wakelist: &mut Vec<Lrc<QueryWaiter>>,\n ) -> bool {\n     let mut visited = FxHashSet::default();\n     let mut stack = Vec::new();\n@@ -489,7 +442,7 @@ fn remove_cycle<D: DepKind>(\n                     }\n                 }\n             })\n-            .collect::<Vec<(Span, QueryJobId<D>, Option<(Span, QueryJobId<D>)>)>>();\n+            .collect::<Vec<(Span, QueryJobId, Option<(Span, QueryJobId)>)>>();\n \n         // Deterministically pick an entry point\n         let (_, entry_point, usage) = pick_query(query_map, &entry_points, |e| (e.0, e.1));\n@@ -544,7 +497,7 @@ pub fn deadlock<CTX: QueryContext>(tcx: CTX, registry: &rayon_core::Registry) {\n \n     let mut wakelist = Vec::new();\n     let query_map = tcx.try_collect_active_jobs().unwrap();\n-    let mut jobs: Vec<QueryJobId<CTX::DepKind>> = query_map.keys().cloned().collect();\n+    let mut jobs: Vec<QueryJobId> = query_map.keys().cloned().collect();\n \n     let mut found_cycle = false;\n \n@@ -630,7 +583,7 @@ pub(crate) fn report_cycle<'a>(\n \n pub fn print_query_stack<CTX: QueryContext>(\n     tcx: CTX,\n-    mut current_query: Option<QueryJobId<CTX::DepKind>>,\n+    mut current_query: Option<QueryJobId>,\n     handler: &Handler,\n     num_frames: Option<usize>,\n ) -> usize {"}, {"sha": "361ae3c43527dcd26eb701df848f4d642ace24c9", "filename": "compiler/rustc_query_system/src/query/mod.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fmod.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -117,10 +117,12 @@ impl QuerySideEffects {\n }\n \n pub trait QueryContext: HasDepContext {\n+    fn next_job_id(&self) -> QueryJobId;\n+\n     /// Get the query information from the TLS context.\n-    fn current_query_job(&self) -> Option<QueryJobId<Self::DepKind>>;\n+    fn current_query_job(&self) -> Option<QueryJobId>;\n \n-    fn try_collect_active_jobs(&self) -> Option<QueryMap<Self::DepKind>>;\n+    fn try_collect_active_jobs(&self) -> Option<QueryMap>;\n \n     /// Load side effects associated to the node in the previous session.\n     fn load_side_effects(&self, prev_dep_node_index: SerializedDepNodeIndex) -> QuerySideEffects;\n@@ -140,7 +142,7 @@ pub trait QueryContext: HasDepContext {\n     /// captured during execution and the actual result.\n     fn start_query<R>(\n         &self,\n-        token: QueryJobId<Self::DepKind>,\n+        token: QueryJobId,\n         diagnostics: Option<&Lock<ThinVec<Diagnostic>>>,\n         compute: impl FnOnce() -> R,\n     ) -> R;"}, {"sha": "77e1fd3f2ccbbda9952dda4d3faa617db717214f", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 31, "deletions": 58, "changes": 89, "blob_url": "https://github.com/rust-lang/rust/blob/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e240783a4d22c1e56b101ab230bee0b821065bd5/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=e240783a4d22c1e56b101ab230bee0b821065bd5", "patch": "@@ -5,9 +5,7 @@\n use crate::dep_graph::{DepContext, DepNode, DepNodeIndex, DepNodeParams};\n use crate::query::caches::QueryCache;\n use crate::query::config::{QueryDescription, QueryVtable};\n-use crate::query::job::{\n-    report_cycle, QueryInfo, QueryJob, QueryJobId, QueryJobInfo, QueryShardJobId,\n-};\n+use crate::query::job::{report_cycle, QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n use crate::query::{QueryContext, QueryMap, QuerySideEffects, QueryStackFrame};\n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n@@ -24,7 +22,6 @@ use std::collections::hash_map::Entry;\n use std::fmt::Debug;\n use std::hash::{Hash, Hasher};\n use std::mem;\n-use std::num::NonZeroU32;\n use std::ptr;\n \n pub struct QueryCacheStore<C: QueryCache> {\n@@ -69,36 +66,32 @@ impl<C: QueryCache> QueryCacheStore<C> {\n     }\n }\n \n-struct QueryStateShard<D, K> {\n-    active: FxHashMap<K, QueryResult<D>>,\n-\n-    /// Used to generate unique ids for active jobs.\n-    jobs: u32,\n+struct QueryStateShard<K> {\n+    active: FxHashMap<K, QueryResult>,\n }\n \n-impl<D, K> Default for QueryStateShard<D, K> {\n-    fn default() -> QueryStateShard<D, K> {\n-        QueryStateShard { active: Default::default(), jobs: 0 }\n+impl<K> Default for QueryStateShard<K> {\n+    fn default() -> QueryStateShard<K> {\n+        QueryStateShard { active: Default::default() }\n     }\n }\n \n-pub struct QueryState<D, K> {\n-    shards: Sharded<QueryStateShard<D, K>>,\n+pub struct QueryState<K> {\n+    shards: Sharded<QueryStateShard<K>>,\n }\n \n /// Indicates the state of a query for a given key in a query map.\n-enum QueryResult<D> {\n+enum QueryResult {\n     /// An already executing query. The query job can be used to await for its completion.\n-    Started(QueryJob<D>),\n+    Started(QueryJob),\n \n     /// The query panicked. Queries trying to wait on this will raise a fatal error which will\n     /// silently panic.\n     Poisoned,\n }\n \n-impl<D, K> QueryState<D, K>\n+impl<K> QueryState<K>\n where\n-    D: Copy + Clone + Eq + Hash,\n     K: Eq + Hash + Clone + Debug,\n {\n     pub fn all_inactive(&self) -> bool {\n@@ -109,19 +102,17 @@ where\n     pub fn try_collect_active_jobs<CTX: Copy>(\n         &self,\n         tcx: CTX,\n-        kind: D,\n         make_query: fn(CTX, K) -> QueryStackFrame,\n-        jobs: &mut QueryMap<D>,\n+        jobs: &mut QueryMap,\n     ) -> Option<()> {\n         // We use try_lock_shards here since we are called from the\n         // deadlock handler, and this shouldn't be locked.\n         let shards = self.shards.try_lock_shards()?;\n-        for (shard_id, shard) in shards.iter().enumerate() {\n+        for shard in shards.iter() {\n             for (k, v) in shard.active.iter() {\n                 if let QueryResult::Started(ref job) = *v {\n-                    let id = QueryJobId::new(job.id, shard_id, kind);\n                     let query = make_query(tcx, k.clone());\n-                    jobs.insert(id, QueryJobInfo { query, job: job.clone() });\n+                    jobs.insert(job.id, QueryJobInfo { query, job: job.clone() });\n                 }\n             }\n         }\n@@ -130,22 +121,21 @@ where\n     }\n }\n \n-impl<D, K> Default for QueryState<D, K> {\n-    fn default() -> QueryState<D, K> {\n+impl<K> Default for QueryState<K> {\n+    fn default() -> QueryState<K> {\n         QueryState { shards: Default::default() }\n     }\n }\n \n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n-struct JobOwner<'tcx, D, K>\n+struct JobOwner<'tcx, K>\n where\n-    D: Copy + Clone + Eq + Hash,\n     K: Eq + Hash + Clone,\n {\n-    state: &'tcx QueryState<D, K>,\n+    state: &'tcx QueryState<K>,\n     key: K,\n-    id: QueryJobId<D>,\n+    id: QueryJobId,\n }\n \n #[cold]\n@@ -166,9 +156,8 @@ where\n     cache.store_nocache(value)\n }\n \n-impl<'tcx, D, K> JobOwner<'tcx, D, K>\n+impl<'tcx, K> JobOwner<'tcx, K>\n where\n-    D: Copy + Clone + Eq + Hash,\n     K: Eq + Hash + Clone,\n {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n@@ -182,12 +171,11 @@ where\n     #[inline(always)]\n     fn try_start<'b, CTX>(\n         tcx: &'b CTX,\n-        state: &'b QueryState<CTX::DepKind, K>,\n+        state: &'b QueryState<K>,\n         span: Span,\n         key: K,\n         lookup: QueryLookup,\n-        dep_kind: CTX::DepKind,\n-    ) -> TryGetJob<'b, CTX::DepKind, K>\n+    ) -> TryGetJob<'b, K>\n     where\n         CTX: QueryContext,\n     {\n@@ -197,27 +185,21 @@ where\n \n         match lock.active.entry(key) {\n             Entry::Vacant(entry) => {\n-                // Generate an id unique within this shard.\n-                let id = lock.jobs.checked_add(1).unwrap();\n-                lock.jobs = id;\n-                let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n-\n+                let id = tcx.next_job_id();\n                 let job = tcx.current_query_job();\n                 let job = QueryJob::new(id, span, job);\n \n                 let key = entry.key().clone();\n                 entry.insert(QueryResult::Started(job));\n \n-                let global_id = QueryJobId::new(id, shard, dep_kind);\n-                let owner = JobOwner { state, id: global_id, key };\n+                let owner = JobOwner { state, id, key };\n                 return TryGetJob::NotYetStarted(owner);\n             }\n             Entry::Occupied(mut entry) => {\n                 match entry.get_mut() {\n                     #[cfg(not(parallel_compiler))]\n                     QueryResult::Started(job) => {\n-                        let id = QueryJobId::new(job.id, shard, dep_kind);\n-\n+                        let id = job.id;\n                         drop(state_lock);\n \n                         // If we are single-threaded we know that we have cycle error,\n@@ -295,9 +277,8 @@ where\n     }\n }\n \n-impl<'tcx, D, K> Drop for JobOwner<'tcx, D, K>\n+impl<'tcx, K> Drop for JobOwner<'tcx, K>\n where\n-    D: Copy + Clone + Eq + Hash,\n     K: Eq + Hash + Clone,\n {\n     #[inline(never)]\n@@ -329,13 +310,12 @@ pub(crate) struct CycleError {\n }\n \n /// The result of `try_start`.\n-enum TryGetJob<'tcx, D, K>\n+enum TryGetJob<'tcx, K>\n where\n-    D: Copy + Clone + Eq + Hash,\n     K: Eq + Hash + Clone,\n {\n     /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'tcx, D, K>),\n+    NotYetStarted(JobOwner<'tcx, K>),\n \n     /// The query was already completed.\n     /// Returns the result of the query and its dep-node index\n@@ -375,7 +355,7 @@ where\n \n fn try_execute_query<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, C::Key>,\n+    state: &QueryState<C::Key>,\n     cache: &QueryCacheStore<C>,\n     span: Span,\n     key: C::Key,\n@@ -388,14 +368,7 @@ where\n     C::Key: Clone + DepNodeParams<CTX::DepContext>,\n     CTX: QueryContext,\n {\n-    match JobOwner::<'_, CTX::DepKind, C::Key>::try_start(\n-        &tcx,\n-        state,\n-        span,\n-        key.clone(),\n-        lookup,\n-        query.dep_kind,\n-    ) {\n+    match JobOwner::<'_, C::Key>::try_start(&tcx, state, span, key.clone(), lookup) {\n         TryGetJob::NotYetStarted(job) => {\n             let (result, dep_node_index) = execute_job(tcx, key, dep_node, query, job.id);\n             let result = job.complete(cache, result, dep_node_index);\n@@ -427,7 +400,7 @@ fn execute_job<CTX, K, V>(\n     key: K,\n     mut dep_node_opt: Option<DepNode<CTX::DepKind>>,\n     query: &QueryVtable<CTX, K, V>,\n-    job_id: QueryJobId<CTX::DepKind>,\n+    job_id: QueryJobId,\n ) -> (V, DepNodeIndex)\n where\n     K: Clone + DepNodeParams<CTX::DepContext>,"}]}