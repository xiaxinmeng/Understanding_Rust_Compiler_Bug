{"sha": "934c938f90662522c4a8a86bd58d7618207f5c2a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjkzNGM5MzhmOTA2NjI1MjJjNGE4YTg2YmQ1OGQ3NjE4MjA3ZjVjMmE=", "commit": {"author": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2013-02-22T02:12:13Z"}, "committer": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2013-02-23T00:09:16Z"}, "message": "libsyntax: De-mut the parser. rs=demuting", "tree": {"sha": "1c8d30efe22d539824b9255442aeb898a25ac7da", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1c8d30efe22d539824b9255442aeb898a25ac7da"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/934c938f90662522c4a8a86bd58d7618207f5c2a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/934c938f90662522c4a8a86bd58d7618207f5c2a", "html_url": "https://github.com/rust-lang/rust/commit/934c938f90662522c4a8a86bd58d7618207f5c2a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/934c938f90662522c4a8a86bd58d7618207f5c2a/comments", "author": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "77dc3ad810d4887d1148d2b0d8e7807ecadaea3e", "url": "https://api.github.com/repos/rust-lang/rust/commits/77dc3ad810d4887d1148d2b0d8e7807ecadaea3e", "html_url": "https://github.com/rust-lang/rust/commit/77dc3ad810d4887d1148d2b0d8e7807ecadaea3e"}], "stats": {"total": 665, "additions": 332, "deletions": 333}, "files": [{"sha": "f3a74302400c9cccbce5b06d4fe8a8fe5337fbbc", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -339,7 +339,7 @@ pub fn get_exprs_from_tts(cx: ext_ctxt, tts: ~[ast::token_tree])\n                                        cx.cfg(),\n                                        tts);\n     let mut es = ~[];\n-    while p.token != token::EOF {\n+    while *p.token != token::EOF {\n         if es.len() != 0 {\n             p.eat(token::COMMA);\n         }"}, {"sha": "66feb7cc753cfb85b51847ef58c4e1b6038a409f", "filename": "src/libsyntax/ext/pipes/parse_proto.rs", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fpipes%2Fparse_proto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fpipes%2Fparse_proto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fparse_proto.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -25,7 +25,7 @@ pub trait proto_parser {\n \n pub impl proto_parser for parser::Parser {\n     fn parse_proto(&self, id: ~str) -> protocol {\n-        let proto = protocol(id, self.span);\n+        let proto = protocol(id, *self.span);\n \n         self.parse_seq_to_before_end(token::EOF, SeqSep {\n                                         sep: None,\n@@ -40,7 +40,7 @@ pub impl proto_parser for parser::Parser {\n         let name = *self.interner.get(id);\n \n         self.expect(token::COLON);\n-        let dir = match copy self.token {\n+        let dir = match *self.token {\n           token::IDENT(n, _) => self.interner.get(n),\n           _ => fail!()\n         };\n@@ -51,10 +51,11 @@ pub impl proto_parser for parser::Parser {\n           _ => fail!()\n         };\n \n-        let typarms = if self.token == token::LT {\n+        let typarms = if *self.token == token::LT {\n             self.parse_ty_params()\n-        }\n-        else { ~[] };\n+        } else {\n+            ~[]\n+        };\n \n         let state = proto.add_state_poly(name, id, dir, typarms);\n \n@@ -69,7 +70,7 @@ pub impl proto_parser for parser::Parser {\n     fn parse_message(&self, state: state) {\n         let mname = *self.interner.get(self.parse_ident());\n \n-        let args = if self.token == token::LPAREN {\n+        let args = if *self.token == token::LPAREN {\n             self.parse_unspanned_seq(token::LPAREN,\n                                      token::RPAREN, SeqSep {\n                                         sep: Some(token::COMMA),\n@@ -80,10 +81,10 @@ pub impl proto_parser for parser::Parser {\n \n         self.expect(token::RARROW);\n \n-        let next = match copy self.token {\n+        let next = match *self.token {\n           token::IDENT(_, _) => {\n             let name = *self.interner.get(self.parse_ident());\n-            let ntys = if self.token == token::LT {\n+            let ntys = if *self.token == token::LT {\n                 self.parse_unspanned_seq(token::LT,\n                                          token::GT, SeqSep {\n                                             sep: Some(token::COMMA),\n@@ -101,7 +102,7 @@ pub impl proto_parser for parser::Parser {\n           _ => self.fatal(~\"invalid next state\")\n         };\n \n-        state.add_message(mname, copy self.span, args, next);\n+        state.add_message(mname, *self.span, args, next);\n \n     }\n }"}, {"sha": "444b09d9ae458c4fe88e6799eb0ba74cba0da878", "filename": "src/libsyntax/ext/pipes/pipec.rs", "status": "modified", "additions": 11, "deletions": 14, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fpipes%2Fpipec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fpipes%2Fpipec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fpipec.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -49,6 +49,9 @@ pub trait gen_init {\n pub impl gen_send for message {\n     fn gen_send(&mut self, cx: ext_ctxt, try: bool) -> @ast::item {\n         debug!(\"pipec: gen_send\");\n+        let name = self.name();\n+        let params = self.get_params();\n+\n         match *self {\n           message(ref _id, span, ref tys, this, Some(ref next_state)) => {\n             debug!(\"pipec: next state exists\");\n@@ -67,7 +70,7 @@ pub impl gen_send for message {\n                 args_ast);\n \n             let mut body = ~\"{\\n\";\n-            body += fmt!(\"use super::%s;\\n\", self.name());\n+            body += fmt!(\"use super::%s;\\n\", name);\n \n             if this.proto.is_bounded() {\n                 let (sp, rp) = match (this.dir, next.dir) {\n@@ -96,7 +99,7 @@ pub impl gen_send for message {\n                 body += fmt!(\"let %s = ::core::pipes::entangle();\\n\", pat);\n             }\n             body += fmt!(\"let message = %s(%s);\\n\",\n-                         self.name(),\n+                         name,\n                          str::connect(vec::append_one(\n                            arg_names.map(|x| cx.str_of(*x)),\n                              ~\"s\"), ~\", \"));\n@@ -121,13 +124,12 @@ pub impl gen_send for message {\n                 rty = cx.ty_option(rty);\n             }\n \n-            let name = cx.ident_of(if try { ~\"try_\" + self.name()\n-                                          } else { self.name() } );\n+            let name = cx.ident_of(if try { ~\"try_\" + name } else { name } );\n \n             cx.item_fn_poly(name,\n                             args_ast,\n                             rty,\n-                            self.get_params(),\n+                            params,\n                             cx.expr_block(body))\n           }\n \n@@ -156,10 +158,8 @@ pub impl gen_send for message {\n                 };\n \n                 let mut body = ~\"{ \";\n-                body += fmt!(\"use super::%s;\\n\", self.name());\n-                body += fmt!(\"let message = %s%s;\\n\",\n-                             self.name(),\n-                             message_args);\n+                body += fmt!(\"use super::%s;\\n\", name);\n+                body += fmt!(\"let message = %s%s;\\n\", name, message_args);\n \n                 if !try {\n                     body += fmt!(\"::core::pipes::send(pipe, message);\\n\");\n@@ -175,10 +175,7 @@ pub impl gen_send for message {\n \n                 let body = cx.parse_expr(body);\n \n-                let name = if try {\n-                    ~\"try_\" + self.name()\n-                }\n-                else { self.name() };\n+                let name = if try { ~\"try_\" + name } else { name };\n \n                 cx.item_fn_poly(cx.ident_of(name),\n                                 args_ast,\n@@ -187,7 +184,7 @@ pub impl gen_send for message {\n                                 } else {\n                                     cx.ty_nil_ast_builder()\n                                 },\n-                                self.get_params(),\n+                                params,\n                                 cx.expr_block(body))\n             }\n           }"}, {"sha": "d529ee0c01b01a1bc5cab9fbb5abe65d99d1ce78", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -515,7 +515,7 @@ fn expand_tts(cx: ext_ctxt,\n     // try removing it when enough of them are gone.\n \n     let p = parse::new_parser_from_tts(cx.parse_sess(), cx.cfg(), tts);\n-    p.quote_depth += 1u;\n+    *p.quote_depth += 1u;\n     let tts = p.parse_all_token_trees();\n     p.abort_if_errors();\n "}, {"sha": "890420edf6d68ce274265b7029a3a3903b1bd3de", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -421,16 +421,16 @@ pub fn parse_nt(p: Parser, name: ~str) -> nonterminal {\n       ~\"expr\" => token::nt_expr(p.parse_expr()),\n       ~\"ty\" => token::nt_ty(p.parse_ty(false /* no need to disambiguate*/)),\n       // this could be handled like a token, since it is one\n-      ~\"ident\" => match copy p.token {\n+      ~\"ident\" => match *p.token {\n         token::IDENT(sn,b) => { p.bump(); token::nt_ident(sn,b) }\n         _ => p.fatal(~\"expected ident, found \"\n-                     + token::to_str(p.reader.interner(), copy p.token))\n+                     + token::to_str(p.reader.interner(), *p.token))\n       },\n       ~\"path\" => token::nt_path(p.parse_path_with_tps(false)),\n       ~\"tt\" => {\n-        p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n+        *p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n         let res = token::nt_tt(@p.parse_token_tree());\n-        p.quote_depth -= 1u;\n+        *p.quote_depth -= 1u;\n         res\n       }\n       ~\"matchers\" => token::nt_matchers(p.parse_matchers()),"}, {"sha": "c0c97a0b9eb5917e0a8e66a19a51bdeb0f5f061d", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -37,7 +37,7 @@ impl parser_attr for Parser {\n     fn parse_outer_attributes() -> ~[ast::attribute] {\n         let mut attrs: ~[ast::attribute] = ~[];\n         loop {\n-            match copy self.token {\n+            match *self.token {\n               token::POUND => {\n                 if self.look_ahead(1u) != token::LBRACKET {\n                     break;\n@@ -90,14 +90,14 @@ impl parser_attr for Parser {\n         let mut inner_attrs: ~[ast::attribute] = ~[];\n         let mut next_outer_attrs: ~[ast::attribute] = ~[];\n         loop {\n-            match copy self.token {\n+            match *self.token {\n               token::POUND => {\n                 if self.look_ahead(1u) != token::LBRACKET {\n                     // This is an extension\n                     break;\n                 }\n                 let attr = self.parse_attribute(ast::attr_inner);\n-                if self.token == token::SEMI {\n+                if *self.token == token::SEMI {\n                     self.bump();\n                     inner_attrs += ~[attr];\n                 } else {\n@@ -131,7 +131,7 @@ impl parser_attr for Parser {\n     fn parse_meta_item() -> @ast::meta_item {\n         let lo = self.span.lo;\n         let name = self.id_to_str(self.parse_ident());\n-        match self.token {\n+        match *self.token {\n             token::EQ => {\n                 self.bump();\n                 let lit = self.parse_lit();\n@@ -157,7 +157,7 @@ impl parser_attr for Parser {\n     }\n \n     fn parse_optional_meta() -> ~[@ast::meta_item] {\n-        match self.token {\n+        match *self.token {\n           token::LPAREN => return self.parse_meta_seq(),\n           _ => return ~[]\n         }"}, {"sha": "57d62d628dc6fa93b455f8e460e77c82494122f2", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 23, "deletions": 23, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -53,38 +53,38 @@ pub fn token_to_str(reader: reader, ++token: token::Token) -> ~str {\n pub impl Parser {\n     fn unexpected_last(t: token::Token) -> ! {\n         self.span_fatal(\n-            copy self.last_span,\n+            *self.last_span,\n             ~\"unexpected token: `\" + token_to_str(self.reader, t) + ~\"`\");\n     }\n \n     fn unexpected() -> ! {\n         self.fatal(~\"unexpected token: `\"\n-                   + token_to_str(self.reader, self.token) + ~\"`\");\n+                   + token_to_str(self.reader, *self.token) + ~\"`\");\n     }\n \n     // expect and consume the token t. Signal an error if\n     // the next token is not t.\n     fn expect(t: token::Token) {\n-        if self.token == t {\n+        if *self.token == t {\n             self.bump();\n         } else {\n             let mut s: ~str = ~\"expected `\";\n             s += token_to_str(self.reader, t);\n             s += ~\"` but found `\";\n-            s += token_to_str(self.reader, self.token);\n+            s += token_to_str(self.reader, *self.token);\n             self.fatal(s + ~\"`\");\n         }\n     }\n \n     fn parse_ident() -> ast::ident {\n         self.check_strict_keywords();\n         self.check_reserved_keywords();\n-        match copy self.token {\n+        match *self.token {\n           token::IDENT(i, _) => { self.bump(); return i; }\n           token::INTERPOLATED(token::nt_ident(*)) => { self.bug(\n               ~\"ident interpolation not converted to real token\"); }\n           _ => { self.fatal(~\"expected ident, found `\"\n-                         + token_to_str(self.reader, self.token)\n+                         + token_to_str(self.reader, *self.token)\n                          + ~\"`\"); }\n         }\n     }\n@@ -104,7 +104,7 @@ pub impl Parser {\n     // consume token 'tok' if it exists. Returns true if the given\n     // token was present, false otherwise.\n     fn eat(tok: token::Token) -> bool {\n-        return if self.token == tok { self.bump(); true } else { false };\n+        return if *self.token == tok { self.bump(); true } else { false };\n     }\n \n     // Storing keywords as interned idents instead of strings would be nifty.\n@@ -129,7 +129,7 @@ pub impl Parser {\n     }\n \n     fn is_keyword(word: ~str) -> bool {\n-        self.token_is_keyword(word, self.token)\n+        self.token_is_keyword(word, *self.token)\n     }\n \n     fn is_any_keyword(tok: token::Token) -> bool {\n@@ -143,7 +143,7 @@ pub impl Parser {\n \n     fn eat_keyword(word: ~str) -> bool {\n         self.require_keyword(word);\n-        let is_kw = match self.token {\n+        let is_kw = match *self.token {\n           token::IDENT(sid, false) => (word == *self.id_to_str(sid)),\n           _ => false\n         };\n@@ -155,7 +155,7 @@ pub impl Parser {\n         self.require_keyword(word);\n         if !self.eat_keyword(word) {\n             self.fatal(~\"expected `\" + word + ~\"`, found `\" +\n-                       token_to_str(self.reader, self.token) +\n+                       token_to_str(self.reader, *self.token) +\n                        ~\"`\");\n         }\n     }\n@@ -165,9 +165,9 @@ pub impl Parser {\n     }\n \n     fn check_strict_keywords() {\n-        match self.token {\n+        match *self.token {\n           token::IDENT(_, false) => {\n-            let w = token_to_str(self.reader, self.token);\n+            let w = token_to_str(self.reader, *self.token);\n             self.check_strict_keywords_(w);\n           }\n           _ => ()\n@@ -185,9 +185,9 @@ pub impl Parser {\n     }\n \n     fn check_reserved_keywords() {\n-        match self.token {\n+        match *self.token {\n           token::IDENT(_, false) => {\n-            let w = token_to_str(self.reader, self.token);\n+            let w = token_to_str(self.reader, *self.token);\n             self.check_reserved_keywords_(w);\n           }\n           _ => ()\n@@ -203,17 +203,17 @@ pub impl Parser {\n     // expect and consume a GT. if a >> is seen, replace it\n     // with a single > and continue.\n     fn expect_gt() {\n-        if self.token == token::GT {\n+        if *self.token == token::GT {\n             self.bump();\n-        } else if self.token == token::BINOP(token::SHR) {\n+        } else if *self.token == token::BINOP(token::SHR) {\n             self.replace_token(token::GT,\n                                self.span.lo + BytePos(1u),\n                                self.span.hi);\n         } else {\n             let mut s: ~str = ~\"expected `\";\n             s += token_to_str(self.reader, token::GT);\n             s += ~\"`, found `\";\n-            s += token_to_str(self.reader, self.token);\n+            s += token_to_str(self.reader, *self.token);\n             s += ~\"`\";\n             self.fatal(s);\n         }\n@@ -225,8 +225,8 @@ pub impl Parser {\n                                        f: fn(Parser) -> T) -> ~[T] {\n         let mut first = true;\n         let mut v = ~[];\n-        while self.token != token::GT\n-            && self.token != token::BINOP(token::SHR) {\n+        while *self.token != token::GT\n+            && *self.token != token::BINOP(token::SHR) {\n             match sep {\n               Some(ref t) => {\n                 if first { first = false; }\n@@ -276,15 +276,15 @@ pub impl Parser {\n                                         f: fn(Parser) -> T) -> ~[T] {\n         let mut first: bool = true;\n         let mut v: ~[T] = ~[];\n-        while self.token != ket {\n+        while *self.token != ket {\n             match sep.sep {\n               Some(ref t) => {\n                 if first { first = false; }\n                 else { self.expect(*t); }\n               }\n               _ => ()\n             }\n-            if sep.trailing_sep_allowed && self.token == ket { break; }\n+            if sep.trailing_sep_allowed && *self.token == ket { break; }\n             v.push(f(self));\n         }\n         return v;\n@@ -293,8 +293,8 @@ pub impl Parser {\n     // parse a sequence, including the closing delimiter. The function\n     // f must consume tokens until reaching the next separator or\n     // closing bracket.\n-    fn parse_unspanned_seq<T:Copy>(bra: token::Token,\n-                                    ket: token::Token,\n+    fn parse_unspanned_seq<T:Copy>(+bra: token::Token,\n+                                   +ket: token::Token,\n                                     sep: SeqSep,\n                                     f: fn(Parser) -> T) -> ~[T] {\n         self.expect(bra);"}, {"sha": "5fa611593850660d6aa28b81492686b0009ca695", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -141,7 +141,7 @@ pub fn parse_tts_from_source_str(name: ~str,\n                                  sess: @mut ParseSess) -> ~[ast::token_tree] {\n     let p = new_parser_from_source_str(sess, cfg, name,\n                                        codemap::FssNone, source);\n-    p.quote_depth += 1u;\n+    *p.quote_depth += 1u;\n     let r = p.parse_all_token_trees();\n     p.abort_if_errors();\n     return r;"}, {"sha": "1ae8786e09bb2c5841241564928135a4f476716a", "filename": "src/libsyntax/parse/obsolete.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fobsolete.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -158,7 +158,7 @@ pub impl Parser {\n     }\n \n     fn is_obsolete_ident(ident: &str) -> bool {\n-        self.token_is_obsolete_ident(ident, copy self.token)\n+        self.token_is_obsolete_ident(ident, *self.token)\n     }\n \n     fn eat_obsolete_ident(ident: &str) -> bool {\n@@ -172,7 +172,7 @@ pub impl Parser {\n \n     fn try_parse_obsolete_struct_ctor() -> bool {\n         if self.eat_obsolete_ident(\"new\") {\n-            self.obsolete(copy self.last_span, ObsoleteStructCtor);\n+            self.obsolete(*self.last_span, ObsoleteStructCtor);\n             self.parse_fn_decl(|p| p.parse_arg());\n             self.parse_block();\n             true\n@@ -182,13 +182,13 @@ pub impl Parser {\n     }\n \n     fn try_parse_obsolete_with() -> bool {\n-        if self.token == token::COMMA\n+        if *self.token == token::COMMA\n             && self.token_is_obsolete_ident(\"with\",\n                                             self.look_ahead(1u)) {\n             self.bump();\n         }\n         if self.eat_obsolete_ident(\"with\") {\n-            self.obsolete(copy self.last_span, ObsoleteWith);\n+            self.obsolete(*self.last_span, ObsoleteWith);\n             self.parse_expr();\n             true\n         } else {\n@@ -198,10 +198,10 @@ pub impl Parser {\n \n     fn try_parse_obsolete_priv_section() -> bool {\n         if self.is_keyword(~\"priv\") && self.look_ahead(1) == token::LBRACE {\n-            self.obsolete(copy self.span, ObsoletePrivSection);\n+            self.obsolete(*self.span, ObsoletePrivSection);\n             self.eat_keyword(~\"priv\");\n             self.bump();\n-            while self.token != token::RBRACE {\n+            while *self.token != token::RBRACE {\n                 self.parse_single_class_item(ast::private);\n             }\n             self.bump();"}, {"sha": "9bac163dab6ef6eca5c4274e284836d88ab3644c", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 270, "deletions": 269, "changes": 539, "blob_url": "https://github.com/rust-lang/rust/blob/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/934c938f90662522c4a8a86bd58d7618207f5c2a/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=934c938f90662522c4a8a86bd58d7618207f5c2a", "patch": "@@ -127,7 +127,7 @@ enum view_item_parse_mode {\n The important thing is to make sure that lookahead doesn't balk\n at INTERPOLATED tokens */\n macro_rules! maybe_whole_expr (\n-    ($p:expr) => ( match copy $p.token {\n+    ($p:expr) => ( match *$p.token {\n       INTERPOLATED(token::nt_expr(e)) => {\n         $p.bump();\n         return e;\n@@ -142,28 +142,28 @@ macro_rules! maybe_whole_expr (\n )\n \n macro_rules! maybe_whole (\n-    ($p:expr, $constructor:ident) => ( match copy $p.token {\n-      INTERPOLATED(token::$constructor(ref x)) => { $p.bump(); return (*x); }\n+    ($p:expr, $constructor:ident) => ( match *$p.token {\n+      INTERPOLATED(token::$constructor(x)) => { $p.bump(); return x; }\n       _ => ()\n     }) ;\n-    (deref $p:expr, $constructor:ident) => ( match copy $p.token {\n+    (deref $p:expr, $constructor:ident) => ( match *$p.token {\n       INTERPOLATED(token::$constructor(x)) => { $p.bump(); return *x; }\n       _ => ()\n     }) ;\n-    (Some $p:expr, $constructor:ident) => ( match copy $p.token {\n+    (Some $p:expr, $constructor:ident) => ( match *$p.token {\n       INTERPOLATED(token::$constructor(x)) => { $p.bump(); return Some(x); }\n       _ => ()\n     }) ;\n-    (iovi $p:expr, $constructor:ident) => ( match copy $p.token {\n+    (iovi $p:expr, $constructor:ident) => ( match *$p.token {\n       INTERPOLATED(token::$constructor(x)) => {\n         $p.bump();\n         return iovi_item(x);\n       }\n       _ => ()\n     }) ;\n-    (pair_empty $p:expr, $constructor:ident) => ( match copy $p.token {\n-      INTERPOLATED(token::$constructor(ref x)) => {\n-        $p.bump(); return (~[], (*x));\n+    (pair_empty $p:expr, $constructor:ident) => ( match *$p.token {\n+      INTERPOLATED(token::$constructor(x)) => {\n+        $p.bump(); return (~[], x);\n       }\n       _ => ()\n     })\n@@ -202,35 +202,35 @@ pub fn Parser(sess: @mut ParseSess,\n         interner: interner,\n         sess: sess,\n         cfg: cfg,\n-        token: tok0.tok,\n-        span: span0,\n-        last_span: span0,\n-        mut buffer: [TokenAndSpan {tok: tok0.tok, sp: span0}, ..4],\n-        buffer_start: 0,\n-        buffer_end: 0,\n-        tokens_consumed: 0u,\n-        restriction: UNRESTRICTED,\n-        quote_depth: 0u,\n+        token: @mut tok0.tok,\n+        span: @mut span0,\n+        last_span: @mut span0,\n+        buffer: @mut [TokenAndSpan {tok: tok0.tok, sp: span0}, ..4],\n+        buffer_start: @mut 0,\n+        buffer_end: @mut 0,\n+        tokens_consumed: @mut 0u,\n+        restriction: @mut UNRESTRICTED,\n+        quote_depth: @mut 0u,\n         keywords: token::keyword_table(),\n         strict_keywords: token::strict_keyword_table(),\n         reserved_keywords: token::reserved_keyword_table(),\n         obsolete_set: HashMap(),\n-        mod_path_stack: ~[],\n+        mod_path_stack: @mut ~[],\n     }\n }\n \n pub struct Parser {\n     sess: @mut ParseSess,\n     cfg: crate_cfg,\n-    mut token: token::Token,\n-    mut span: span,\n-    mut last_span: span,\n-    mut buffer: [TokenAndSpan * 4],\n-    mut buffer_start: int,\n-    mut buffer_end: int,\n-    mut tokens_consumed: uint,\n-    mut restriction: restriction,\n-    mut quote_depth: uint, // not (yet) related to the quasiquoter\n+    token: @mut token::Token,\n+    span: @mut span,\n+    last_span: @mut span,\n+    buffer: @mut [TokenAndSpan * 4],\n+    buffer_start: @mut int,\n+    buffer_end: @mut int,\n+    tokens_consumed: @mut uint,\n+    restriction: @mut restriction,\n+    quote_depth: @mut uint, // not (yet) related to the quasiquoter\n     reader: reader,\n     interner: @token::ident_interner,\n     keywords: HashMap<~str, ()>,\n@@ -240,47 +240,47 @@ pub struct Parser {\n     /// extra detail when the same error is seen twice\n     obsolete_set: HashMap<ObsoleteSyntax, ()>,\n     /// Used to determine the path to externally loaded source files\n-    mut mod_path_stack: ~[~str],\n+    mod_path_stack: @mut ~[~str],\n \n     drop {} /* do not copy the parser; its state is tied to outside state */\n }\n \n pub impl Parser {\n     // advance the parser by one token\n     fn bump() {\n-        self.last_span = self.span;\n-        let next = if self.buffer_start == self.buffer_end {\n+        *self.last_span = *self.span;\n+        let next = if *self.buffer_start == *self.buffer_end {\n             self.reader.next_token()\n         } else {\n-            let next = self.buffer[self.buffer_start];\n-            self.buffer_start = (self.buffer_start + 1) & 3;\n+            let next = self.buffer[*self.buffer_start];\n+            *self.buffer_start = (*self.buffer_start + 1) & 3;\n             next\n         };\n-        self.token = next.tok;\n-        self.span = next.sp;\n-        self.tokens_consumed += 1u;\n+        *self.token = next.tok;\n+        *self.span = next.sp;\n+        *self.tokens_consumed += 1u;\n     }\n     // EFFECT: replace the current token and span with the given one\n     fn replace_token(next: token::Token, +lo: BytePos, +hi: BytePos) {\n-        self.token = next;\n-        self.span = mk_sp(lo, hi);\n+        *self.token = next;\n+        *self.span = mk_sp(lo, hi);\n     }\n     fn buffer_length() -> int {\n-        if self.buffer_start <= self.buffer_end {\n-            return self.buffer_end - self.buffer_start;\n+        if *self.buffer_start <= *self.buffer_end {\n+            return *self.buffer_end - *self.buffer_start;\n         }\n-        return (4 - self.buffer_start) + self.buffer_end;\n+        return (4 - *self.buffer_start) + *self.buffer_end;\n     }\n     fn look_ahead(distance: uint) -> token::Token {\n         let dist = distance as int;\n         while self.buffer_length() < dist {\n-            self.buffer[self.buffer_end] = self.reader.next_token();\n-            self.buffer_end = (self.buffer_end + 1) & 3;\n+            self.buffer[*self.buffer_end] = self.reader.next_token();\n+            *self.buffer_end = (*self.buffer_end + 1) & 3;\n         }\n-        return copy self.buffer[(self.buffer_start + dist - 1) & 3].tok;\n+        return copy self.buffer[(*self.buffer_start + dist - 1) & 3].tok;\n     }\n     fn fatal(m: ~str) -> ! {\n-        self.sess.span_diagnostic.span_fatal(copy self.span, m)\n+        self.sess.span_diagnostic.span_fatal(*copy self.span, m)\n     }\n     fn span_fatal(sp: span, m: ~str) -> ! {\n         self.sess.span_diagnostic.span_fatal(sp, m)\n@@ -289,10 +289,10 @@ pub impl Parser {\n         self.sess.span_diagnostic.span_note(sp, m)\n     }\n     fn bug(m: ~str) -> ! {\n-        self.sess.span_diagnostic.span_bug(copy self.span, m)\n+        self.sess.span_diagnostic.span_bug(*copy self.span, m)\n     }\n     fn warn(m: ~str) {\n-        self.sess.span_diagnostic.span_warn(copy self.span, m)\n+        self.sess.span_diagnostic.span_warn(*copy self.span, m)\n     }\n     fn span_err(sp: span, m: ~str) {\n         self.sess.span_diagnostic.span_err(sp, m)\n@@ -451,8 +451,8 @@ pub impl Parser {\n             let hi = p.last_span.hi;\n             debug!(\"parse_trait_methods(): trait method signature ends in \\\n                     `%s`\",\n-                   token_to_str(p.reader, p.token));\n-            match p.token {\n+                   token_to_str(p.reader, *p.token));\n+            match *p.token {\n               token::SEMI => {\n                 p.bump();\n                 debug!(\"parse_trait_methods(): parsing required method\");\n@@ -490,7 +490,7 @@ pub impl Parser {\n               }\n \n               _ => { p.fatal(~\"expected `;` or `}` but found `\" +\n-                          token_to_str(p.reader, p.token) + ~\"`\");\n+                          token_to_str(p.reader, *p.token) + ~\"`\");\n                 }\n             }\n         }\n@@ -562,7 +562,7 @@ pub impl Parser {\n     fn parse_region() -> @region {\n         self.expect(token::BINOP(token::AND));\n \n-        match copy self.token {\n+        match *self.token {\n           token::IDENT(sid, _) => {\n             self.bump();\n             self.region_from_name(Some(sid))\n@@ -578,9 +578,9 @@ pub impl Parser {\n \n         let lo = self.span.lo;\n \n-        let t = if self.token == token::LPAREN {\n+        let t = if *self.token == token::LPAREN {\n             self.bump();\n-            if self.token == token::RPAREN {\n+            if *self.token == token::RPAREN {\n                 self.bump();\n                 ty_nil\n             } else {\n@@ -589,9 +589,9 @@ pub impl Parser {\n                 // of type t\n                 let mut ts = ~[self.parse_ty(false)];\n                 let mut one_tuple = false;\n-                while self.token == token::COMMA {\n+                while *self.token == token::COMMA {\n                     self.bump();\n-                    if self.token != token::RPAREN {\n+                    if *self.token != token::RPAREN {\n                         ts.push(self.parse_ty(false));\n                     }\n                     else {\n@@ -603,16 +603,16 @@ pub impl Parser {\n                 self.expect(token::RPAREN);\n                 t\n             }\n-        } else if self.token == token::AT {\n+        } else if *self.token == token::AT {\n             self.bump();\n             self.parse_box_or_uniq_pointee(ManagedSigil, ty_box)\n-        } else if self.token == token::TILDE {\n+        } else if *self.token == token::TILDE {\n             self.bump();\n             self.parse_box_or_uniq_pointee(OwnedSigil, ty_uniq)\n-        } else if self.token == token::BINOP(token::STAR) {\n+        } else if *self.token == token::BINOP(token::STAR) {\n             self.bump();\n             ty_ptr(self.parse_mt())\n-        } else if self.token == token::LBRACE {\n+        } else if *self.token == token::LBRACE {\n             let elems = self.parse_unspanned_seq(\n                 token::LBRACE, token::RBRACE,\n                 seq_sep_trailing_allowed(token::COMMA),\n@@ -621,7 +621,7 @@ pub impl Parser {\n                 self.unexpected_last(token::RBRACE);\n             }\n             ty_rec(elems)\n-        } else if self.token == token::LBRACKET {\n+        } else if *self.token == token::LBRACKET {\n             self.expect(token::LBRACKET);\n             let mt = self.parse_mt();\n \n@@ -632,15 +632,15 @@ pub impl Parser {\n             };\n             self.expect(token::RBRACKET);\n             t\n-        } else if self.token == token::BINOP(token::AND) {\n+        } else if *self.token == token::BINOP(token::AND) {\n             self.bump();\n             self.parse_borrowed_pointee()\n         } else if self.eat_keyword(~\"extern\") {\n             self.parse_ty_bare_fn()\n-        } else if self.token_is_closure_keyword(self.token) {\n+        } else if self.token_is_closure_keyword(*self.token) {\n             self.parse_ty_closure(None, None)\n-        } else if self.token == token::MOD_SEP\n-            || is_ident_or_path(self.token) {\n+        } else if *self.token == token::MOD_SEP\n+            || is_ident_or_path(*self.token) {\n             let path = self.parse_path_with_tps(colons_before_params);\n             ty_path(path, self.get_id())\n         } else { self.fatal(~\"expected type\"); };\n@@ -654,19 +654,18 @@ pub impl Parser {\n         ctor: &fn(+v: mt) -> ty_) -> ty_\n     {\n         // @'foo fn() or @foo/fn() or @fn() are parsed directly as fn types:\n-        match copy self.token {\n+        match *self.token {\n             token::LIFETIME(rname) => {\n                 self.bump();\n                 return self.parse_ty_closure(Some(sigil), Some(rname));\n             }\n \n             token::IDENT(rname, _) => {\n                 if self.look_ahead(1u) == token::BINOP(token::SLASH) &&\n-                    self.token_is_closure_keyword(self.look_ahead(2u))\n-                {\n+                        self.token_is_closure_keyword(self.look_ahead(2u)) {\n                     self.bump(); self.bump();\n                     return self.parse_ty_closure(Some(sigil), Some(rname));\n-                } else if self.token_is_closure_keyword(self.token) {\n+                } else if self.token_is_closure_keyword(*self.token) {\n                     return self.parse_ty_closure(Some(sigil), None);\n                 }\n             }\n@@ -683,7 +682,7 @@ pub impl Parser {\n \n     fn parse_borrowed_pointee() -> ty_ {\n         // look for `&'lt` or `&foo/` and interpret `foo` as the region name:\n-        let rname = match self.token {\n+        let rname = match *self.token {\n             token::LIFETIME(sid) => {\n                 self.bump();\n                 Some(sid)\n@@ -701,7 +700,7 @@ pub impl Parser {\n             _ => { None }\n         };\n \n-        if self.token_is_closure_keyword(self.token) {\n+        if self.token_is_closure_keyword(*self.token) {\n             return self.parse_ty_closure(Some(BorrowedSigil), rname);\n         }\n \n@@ -727,21 +726,21 @@ pub impl Parser {\n     }\n \n     fn is_named_argument() -> bool {\n-        let offset = if self.token == token::BINOP(token::AND) {\n+        let offset = if *self.token == token::BINOP(token::AND) {\n             1\n-        } else if self.token == token::BINOP(token::MINUS) {\n+        } else if *self.token == token::BINOP(token::MINUS) {\n             1\n-        } else if self.token == token::ANDAND {\n+        } else if *self.token == token::ANDAND {\n             1\n-        } else if self.token == token::BINOP(token::PLUS) {\n+        } else if *self.token == token::BINOP(token::PLUS) {\n             if self.look_ahead(1) == token::BINOP(token::PLUS) {\n                 2\n             } else {\n                 1\n             }\n         } else { 0 };\n         if offset == 0 {\n-            is_plain_ident(self.token)\n+            is_plain_ident(*self.token)\n                 && self.look_ahead(1) == token::COLON\n         } else {\n             is_plain_ident(self.look_ahead(offset))\n@@ -775,7 +774,7 @@ pub impl Parser {\n         } else {\n             m = infer(self.get_id());\n             ast_util::ident_to_pat(self.get_id(),\n-                                   copy self.last_span,\n+                                   *self.last_span,\n                                    special_idents::invalid)\n         };\n \n@@ -819,7 +818,7 @@ pub impl Parser {\n \n     fn maybe_parse_fixed_vstore_with_star() -> Option<uint> {\n         if self.eat(token::BINOP(token::STAR)) {\n-            match copy self.token {\n+            match *self.token {\n                 token::LIT_INT_UNSUFFIXED(i) if i >= 0i64 => {\n                     self.bump();\n                     Some(i as uint)\n@@ -828,7 +827,7 @@ pub impl Parser {\n                     self.fatal(\n                         fmt!(\"expected integral vector length \\\n                               but found `%s`\",\n-                             token_to_str(self.reader, self.token)));\n+                             token_to_str(self.reader, *self.token)));\n                 }\n             }\n         } else {\n@@ -857,7 +856,8 @@ pub impl Parser {\n         } else if self.eat_keyword(~\"false\") {\n             lit_bool(false)\n         } else {\n-            let tok = self.token;\n+            // XXX: This is a really bad copy!\n+            let tok = *self.token;\n             self.bump();\n             self.lit_from_token(tok)\n         };\n@@ -920,9 +920,8 @@ pub impl Parser {\n             // vstores is... um... the same.  I guess that's my fault.  This\n             // is still not ideal as for &str we end up parsing more than we\n             // ought to and have to sort it out later.\n-            if self.token == token::BINOP(token::SLASH)\n+            if *self.token == token::BINOP(token::SLASH)\n                 && self.look_ahead(1u) == token::BINOP(token::AND) {\n-\n                 self.expect(token::BINOP(token::SLASH));\n                 Some(self.parse_region())\n             } else {\n@@ -958,7 +957,7 @@ pub impl Parser {\n          * Parses 0 or 1 lifetime.\n          */\n \n-        match self.token {\n+        match *self.token {\n             token::LIFETIME(_) => {\n                 Some(self.parse_lifetime())\n             }\n@@ -974,12 +973,12 @@ pub impl Parser {\n          * Parses a single lifetime.\n          */\n \n-        match self.token {\n+        match *self.token {\n             token::LIFETIME(i) => {\n                 self.bump();\n                 return ast::Lifetime {\n                     id: self.get_id(),\n-                    span: self.span,\n+                    span: *self.span,\n                     ident: i\n                 };\n             }\n@@ -1000,7 +999,7 @@ pub impl Parser {\n \n         let mut res = ~[];\n         loop {\n-            match self.token {\n+            match *self.token {\n                 token::LIFETIME(_) => {\n                     res.push(self.parse_lifetime());\n                 }\n@@ -1009,7 +1008,7 @@ pub impl Parser {\n                 }\n             }\n \n-            match self.token {\n+            match *self.token {\n                 token::COMMA => { self.bump();}\n                 token::GT => { return res; }\n                 _ => {\n@@ -1058,14 +1057,16 @@ pub impl Parser {\n \n     fn mk_lit_u32(i: u32) -> @expr {\n         let span = self.span;\n-        let lv_lit = @codemap::spanned { node: lit_uint(i as u64, ty_u32),\n-                                     span: span };\n+        let lv_lit = @codemap::spanned {\n+            node: lit_uint(i as u64, ty_u32),\n+            span: *span\n+        };\n \n         @expr {\n             id: self.get_id(),\n             callee_id: self.get_id(),\n             node: expr_lit(lv_lit),\n-            span: span,\n+            span: *span,\n         }\n     }\n \n@@ -1076,21 +1077,21 @@ pub impl Parser {\n \n         let mut ex: expr_;\n \n-        if self.token == token::LPAREN {\n+        if *self.token == token::LPAREN {\n             self.bump();\n             // (e) is parenthesized e\n             // (e,) is a tuple with only one field, e\n             let mut one_tuple = false;\n-            if self.token == token::RPAREN {\n+            if *self.token == token::RPAREN {\n                 hi = self.span.hi;\n                 self.bump();\n                 let lit = @spanned(lo, hi, lit_nil);\n                 return self.mk_expr(lo, hi, expr_lit(lit));\n             }\n             let mut es = ~[self.parse_expr()];\n-            while self.token == token::COMMA {\n+            while *self.token == token::COMMA {\n                 self.bump();\n-                if self.token != token::RPAREN {\n+                if *self.token != token::RPAREN {\n                     es.push(self.parse_expr());\n                 }\n                 else {\n@@ -1106,7 +1107,7 @@ pub impl Parser {\n             else {\n                 self.mk_expr(lo, hi, expr_tup(es))\n             }\n-        } else if self.token == token::LBRACE {\n+        } else if *self.token == token::LBRACE {\n             if self.looking_at_record_literal() {\n                 ex = self.parse_record_literal();\n                 hi = self.span.hi;\n@@ -1116,7 +1117,7 @@ pub impl Parser {\n                 return self.mk_expr(blk.span.lo, blk.span.hi,\n                                      expr_block(blk));\n             }\n-        } else if token::is_bar(self.token) {\n+        } else if token::is_bar(*self.token) {\n             return self.parse_lambda_expr();\n         } else if self.eat_keyword(~\"if\") {\n             return self.parse_if_expr();\n@@ -1143,25 +1144,25 @@ pub impl Parser {\n             return self.parse_fn_expr(sigil);\n         } else if self.eat_keyword(~\"unsafe\") {\n             return self.parse_block_expr(lo, unsafe_blk);\n-        } else if self.token == token::LBRACKET {\n+        } else if *self.token == token::LBRACKET {\n             self.bump();\n             let mutbl = self.parse_mutability();\n-            if self.token == token::RBRACKET {\n+            if *self.token == token::RBRACKET {\n                 // Empty vector.\n                 self.bump();\n                 ex = expr_vec(~[], mutbl);\n             } else {\n                 // Nonempty vector.\n                 let first_expr = self.parse_expr();\n-                if self.token == token::COMMA &&\n+                if *self.token == token::COMMA &&\n                         self.look_ahead(1) == token::DOTDOT {\n                     // Repeating vector syntax: [ 0, ..512 ]\n                     self.bump();\n                     self.bump();\n                     let count = self.parse_expr();\n                     self.expect(token::RBRACKET);\n                     ex = expr_repeat(first_expr, count, mutbl);\n-                } else if self.token == token::COMMA {\n+                } else if *self.token == token::COMMA {\n                     // Vector with two or more elements.\n                     self.bump();\n                     let remaining_exprs =\n@@ -1189,13 +1190,13 @@ pub impl Parser {\n             ex = expr_assert(e);\n             hi = e.span.hi;\n         } else if self.eat_keyword(~\"return\") {\n-            if can_begin_expr(self.token) {\n+            if can_begin_expr(*self.token) {\n                 let e = self.parse_expr();\n                 hi = e.span.hi;\n                 ex = expr_ret(Some(e));\n             } else { ex = expr_ret(None); }\n         } else if self.eat_keyword(~\"break\") {\n-            if is_ident(self.token) {\n+            if is_ident(*self.token) {\n                 ex = expr_break(Some(self.parse_ident()));\n             } else {\n                 ex = expr_break(None);\n@@ -1205,37 +1206,36 @@ pub impl Parser {\n             let e = self.parse_expr();\n             ex = expr_copy(e);\n             hi = e.span.hi;\n-        } else if self.token == token::MOD_SEP ||\n-            is_ident(self.token) && !self.is_keyword(~\"true\") &&\n-            !self.is_keyword(~\"false\") {\n+        } else if *self.token == token::MOD_SEP ||\n+                is_ident(*self.token) && !self.is_keyword(~\"true\") &&\n+                !self.is_keyword(~\"false\") {\n             let pth = self.parse_path_with_tps(true);\n \n             /* `!`, as an operator, is prefix, so we know this isn't that */\n-            if self.token == token::NOT {\n+            if *self.token == token::NOT {\n                 self.bump();\n-                let tts = match self.token {\n-                  token::LPAREN | token::LBRACE => {\n-                    let ket = token::flip_delimiter(copy self.token);\n-                    self.parse_unspanned_seq(copy self.token, ket,\n-                                             seq_sep_none(),\n-                                             |p| p.parse_token_tree())\n-                  }\n+                match *self.token {\n+                  token::LPAREN | token::LBRACE => {}\n                   _ => self.fatal(~\"expected open delimiter\")\n                 };\n+\n+                let ket = token::flip_delimiter(*self.token);\n+                let tts = self.parse_unspanned_seq(*self.token,\n+                                                   ket,\n+                                                   seq_sep_none(),\n+                                                   |p| p.parse_token_tree());\n                 let hi = self.span.hi;\n \n-                return self.mk_mac_expr(\n-                    lo, hi, mac_invoc_tt(pth, tts));\n-            } else if self.token == token::LBRACE {\n+                return self.mk_mac_expr(lo, hi, mac_invoc_tt(pth, tts));\n+            } else if *self.token == token::LBRACE {\n                 // This might be a struct literal.\n                 if self.looking_at_record_literal() {\n                     // It's a struct literal.\n                     self.bump();\n                     let mut fields = ~[];\n                     let mut base = None;\n                     fields.push(self.parse_field(token::COLON));\n-                    while self.token != token::RBRACE {\n-\n+                    while *self.token != token::RBRACE {\n                         if self.try_parse_obsolete_with() {\n                             break;\n                         }\n@@ -1247,7 +1247,7 @@ pub impl Parser {\n                             break;\n                         }\n \n-                        if self.token == token::RBRACE {\n+                        if *self.token == token::RBRACE {\n                             // Accept an optional trailing comma.\n                             break;\n                         }\n@@ -1284,7 +1284,7 @@ pub impl Parser {\n     }\n \n     fn permits_call() -> bool {\n-        return self.restriction != RESTRICT_NO_CALL_EXPRS;\n+        return *self.restriction != RESTRICT_NO_CALL_EXPRS;\n     }\n \n     fn parse_dot_or_call_expr_with(e0: @expr) -> @expr {\n@@ -1294,7 +1294,7 @@ pub impl Parser {\n         loop {\n             // expr.f\n             if self.eat(token::DOT) {\n-                match copy self.token {\n+                match *self.token {\n                   token::IDENT(i, _) => {\n                     hi = self.span.hi;\n                     self.bump();\n@@ -1307,7 +1307,7 @@ pub impl Parser {\n                     };\n \n                     // expr.f() method call\n-                    match copy self.token {\n+                    match *self.token {\n                         token::LPAREN if self.permits_call() => {\n                             let es = self.parse_unspanned_seq(\n                                 token::LPAREN, token::RPAREN,\n@@ -1328,7 +1328,7 @@ pub impl Parser {\n                 loop;\n             }\n             if self.expr_is_complete(e) { break; }\n-            match copy self.token {\n+            match *self.token {\n               // expr(...)\n               token::LPAREN if self.permits_call() => {\n                 let es = self.parse_unspanned_seq(\n@@ -1359,17 +1359,17 @@ pub impl Parser {\n     // parse an optional separator followed by a kleene-style\n     // repetition token (+ or *).\n     fn parse_sep_and_zerok() -> (Option<token::Token>, bool) {\n-        if self.token == token::BINOP(token::STAR)\n-            || self.token == token::BINOP(token::PLUS) {\n-            let zerok = self.token == token::BINOP(token::STAR);\n+        if *self.token == token::BINOP(token::STAR)\n+            || *self.token == token::BINOP(token::PLUS) {\n+            let zerok = *self.token == token::BINOP(token::STAR);\n             self.bump();\n             return (None, zerok);\n         } else {\n-            let sep = self.token;\n+            let sep = *self.token;\n             self.bump();\n-            if self.token == token::BINOP(token::STAR)\n-                || self.token == token::BINOP(token::PLUS) {\n-                let zerok = self.token == token::BINOP(token::STAR);\n+            if *self.token == token::BINOP(token::STAR)\n+                || *self.token == token::BINOP(token::PLUS) {\n+                let zerok = *self.token == token::BINOP(token::STAR);\n                 self.bump();\n                 return (Some(sep), zerok);\n             } else {\n@@ -1384,18 +1384,18 @@ pub impl Parser {\n \n         fn parse_non_delim_tt_tok(p: Parser) -> token_tree {\n             maybe_whole!(deref p, nt_tt);\n-            match p.token {\n+            match *p.token {\n               token::RPAREN | token::RBRACE | token::RBRACKET\n               => {\n                 p.fatal(~\"incorrect close delimiter: `\"\n-                           + token_to_str(p.reader, p.token) + ~\"`\");\n+                           + token_to_str(p.reader, *p.token) + ~\"`\");\n               }\n               /* we ought to allow different depths of unquotation */\n-              token::DOLLAR if p.quote_depth > 0u => {\n+              token::DOLLAR if *p.quote_depth > 0u => {\n                 p.bump();\n-                let sp = p.span;\n+                let sp = *p.span;\n \n-                if p.token == token::LPAREN {\n+                if *p.token == token::LPAREN {\n                     let seq = p.parse_seq(token::LPAREN, token::RPAREN,\n                                           seq_sep_none(),\n                                           |p| p.parse_token_tree());\n@@ -1413,18 +1413,18 @@ pub impl Parser {\n \n         // turn the next token into a tt_tok:\n         fn parse_any_tt_tok(p: Parser) -> token_tree{\n-            let res = tt_tok(p.span, p.token);\n+            let res = tt_tok(*p.span, *p.token);\n             p.bump();\n             res\n         }\n \n-        match self.token {\n+        match *self.token {\n           token::EOF => {\n                 self.fatal(~\"file ended in the middle of a macro invocation\");\n           }\n           token::LPAREN | token::LBRACE | token::LBRACKET => {\n               // tjc: ??????\n-            let ket = token::flip_delimiter(copy self.token);\n+            let ket = token::flip_delimiter(*self.token);\n             tt_delim(vec::append(\n                 // the open delimiter:\n                 ~[parse_any_tt_tok(self)],\n@@ -1441,7 +1441,7 @@ pub impl Parser {\n \n     fn parse_all_token_trees() -> ~[token_tree] {\n         let mut tts = ~[];\n-        while self.token != token::EOF {\n+        while *self.token != token::EOF {\n             tts.push(self.parse_token_tree());\n         }\n         tts\n@@ -1452,11 +1452,11 @@ pub impl Parser {\n         // the interpolation of matchers\n         maybe_whole!(self, nt_matchers);\n         let name_idx = @mut 0u;\n-        return match self.token {\n+        return match *self.token {\n           token::LBRACE | token::LPAREN | token::LBRACKET => {\n-            self.parse_matcher_subseq(name_idx, copy self.token,\n+            self.parse_matcher_subseq(name_idx, *self.token,\n                                       // tjc: not sure why we need a copy\n-                                      token::flip_delimiter(copy self.token))\n+                                      token::flip_delimiter(*self.token))\n           }\n           _ => self.fatal(~\"expected open delimiter\")\n         }\n@@ -1473,9 +1473,9 @@ pub impl Parser {\n \n         self.expect(bra);\n \n-        while self.token != ket || lparens > 0u {\n-            if self.token == token::LPAREN { lparens += 1u; }\n-            if self.token == token::RPAREN { lparens -= 1u; }\n+        while *self.token != ket || lparens > 0u {\n+            if *self.token == token::LPAREN { lparens += 1u; }\n+            if *self.token == token::RPAREN { lparens -= 1u; }\n             ret_val.push(self.parse_matcher(name_idx));\n         }\n \n@@ -1487,11 +1487,12 @@ pub impl Parser {\n     fn parse_matcher(name_idx: @mut uint) -> matcher {\n         let lo = self.span.lo;\n \n-        let m = if self.token == token::DOLLAR {\n+        let m = if *self.token == token::DOLLAR {\n             self.bump();\n-            if self.token == token::LPAREN {\n+            if *self.token == token::LPAREN {\n                 let name_idx_lo = *name_idx;\n-                let ms = self.parse_matcher_subseq(name_idx, token::LPAREN,\n+                let ms = self.parse_matcher_subseq(name_idx,\n+                                                   token::LPAREN,\n                                                    token::RPAREN);\n                 if ms.len() == 0u {\n                     self.fatal(~\"repetition body must be nonempty\");\n@@ -1507,7 +1508,7 @@ pub impl Parser {\n                 m\n             }\n         } else {\n-            let m = match_tok(self.token);\n+            let m = match_tok(*self.token);\n             self.bump();\n             m\n         };\n@@ -1521,7 +1522,7 @@ pub impl Parser {\n         let mut hi;\n \n         let mut ex;\n-        match copy self.token {\n+        match *self.token {\n           token::NOT => {\n             self.bump();\n             let e = self.parse_prefix_expr();\n@@ -1610,13 +1611,13 @@ pub impl Parser {\n     fn parse_more_binops(lhs: @expr, min_prec: uint) ->\n         @expr {\n         if self.expr_is_complete(lhs) { return lhs; }\n-        let peeked = self.token;\n+        let peeked = *self.token;\n         if peeked == token::BINOP(token::OR) &&\n-            (self.restriction == RESTRICT_NO_BAR_OP ||\n-             self.restriction == RESTRICT_NO_BAR_OR_DOUBLEBAR_OP) {\n+            (*self.restriction == RESTRICT_NO_BAR_OP ||\n+             *self.restriction == RESTRICT_NO_BAR_OR_DOUBLEBAR_OP) {\n             lhs\n         } else if peeked == token::OROR &&\n-            self.restriction == RESTRICT_NO_BAR_OR_DOUBLEBAR_OP {\n+            *self.restriction == RESTRICT_NO_BAR_OR_DOUBLEBAR_OP {\n             lhs\n         } else {\n             let cur_opt = token_to_binop(peeked);\n@@ -1656,7 +1657,7 @@ pub impl Parser {\n     fn parse_assign_expr() -> @expr {\n         let lo = self.span.lo;\n         let lhs = self.parse_binops();\n-        match copy self.token {\n+        match *self.token {\n             token::EQ => {\n                 self.bump();\n                 let rhs = self.parse_expr();\n@@ -1683,7 +1684,7 @@ pub impl Parser {\n                            expr_assign_op(aop, lhs, rhs))\n           }\n           token::LARROW => {\n-              self.obsolete(copy self.span, ObsoleteBinaryMove);\n+              self.obsolete(*self.span, ObsoleteBinaryMove);\n               // Bogus value (but it's an error)\n               self.bump(); // <-\n               self.bump(); // rhs\n@@ -1733,7 +1734,7 @@ pub impl Parser {\n     fn parse_lambda_block_expr() -> @expr {\n         self.parse_lambda_expr_(\n             || {\n-                match self.token {\n+                match *self.token {\n                   token::BINOP(token::OR) | token::OROR => {\n                     self.parse_fn_block_decl()\n                   }\n@@ -1744,7 +1745,7 @@ pub impl Parser {\n                           output: @Ty {\n                               id: self.get_id(),\n                               node: ty_infer,\n-                              span: self.span\n+                              span: *self.span\n                           },\n                           cf: return_val\n                       }\n@@ -1841,8 +1842,8 @@ pub impl Parser {\n                 // but they aren't represented by tests\n                 debug!(\"sugary call on %?\", e.node);\n                 self.span_fatal(\n-                    lo, fmt!(\"`%s` must be followed by a block call\",\n-                             keyword));\n+                    *lo,\n+                    fmt!(\"`%s` must be followed by a block call\", keyword));\n             }\n         }\n     }\n@@ -1858,13 +1859,13 @@ pub impl Parser {\n     fn parse_loop_expr() -> @expr {\n         // loop headers look like 'loop {' or 'loop unsafe {'\n         let is_loop_header =\n-            self.token == token::LBRACE\n-            || (is_ident(copy self.token)\n+            *self.token == token::LBRACE\n+            || (is_ident(*self.token)\n                 && self.look_ahead(1) == token::LBRACE);\n         // labeled loop headers look like 'loop foo: {'\n         let is_labeled_loop_header =\n-            is_ident(self.token)\n-            && !self.is_any_keyword(copy self.token)\n+            is_ident(*self.token)\n+            && !self.is_any_keyword(*self.token)\n             && self.look_ahead(1) == token::COLON;\n \n         if is_loop_header || is_labeled_loop_header {\n@@ -1884,7 +1885,7 @@ pub impl Parser {\n         } else {\n             // This is a 'continue' expression\n             let lo = self.span.lo;\n-            let ex = if is_ident(self.token) {\n+            let ex = if is_ident(*self.token) {\n                 expr_again(Some(self.parse_ident()))\n             } else {\n                 expr_again(None)\n@@ -1897,7 +1898,7 @@ pub impl Parser {\n     // For distingishing between record literals and blocks\n     fn looking_at_record_literal() -> bool {\n         let lookahead = self.look_ahead(1);\n-        self.token == token::LBRACE &&\n+        *self.token == token::LBRACE &&\n             (self.token_is_keyword(~\"mut\", lookahead) ||\n              (is_plain_ident(lookahead) &&\n               self.look_ahead(2) == token::COLON))\n@@ -1907,8 +1908,8 @@ pub impl Parser {\n         self.expect(token::LBRACE);\n         let mut fields = ~[self.parse_field(token::COLON)];\n         let mut base = None;\n-        while self.token != token::RBRACE {\n-            if self.token == token::COMMA\n+        while *self.token != token::RBRACE {\n+            if *self.token == token::COMMA\n                 && self.look_ahead(1) == token::DOTDOT {\n                 self.bump();\n                 self.bump();\n@@ -1920,7 +1921,7 @@ pub impl Parser {\n             }\n \n             self.expect(token::COMMA);\n-            if self.token == token::RBRACE {\n+            if *self.token == token::RBRACE {\n                 // record ends by an optional trailing comma\n                 break;\n             }\n@@ -1936,7 +1937,7 @@ pub impl Parser {\n         let discriminant = self.parse_expr();\n         self.expect(token::LBRACE);\n         let mut arms: ~[arm] = ~[];\n-        while self.token != token::RBRACE {\n+        while *self.token != token::RBRACE {\n             let pats = self.parse_pats();\n             let mut guard = None;\n             if self.eat_keyword(~\"if\") { guard = Some(self.parse_expr()); }\n@@ -1945,7 +1946,7 @@ pub impl Parser {\n \n             let require_comma =\n                 !classify::expr_is_simple_block(expr)\n-                && self.token != token::RBRACE;\n+                && *self.token != token::RBRACE;\n \n             if require_comma {\n                 self.expect(token::COMMA);\n@@ -1978,21 +1979,21 @@ pub impl Parser {\n \n     // parse an expression, subject to the given restriction\n     fn parse_expr_res(r: restriction) -> @expr {\n-        let old = self.restriction;\n-        self.restriction = r;\n+        let old = *self.restriction;\n+        *self.restriction = r;\n         let e = self.parse_assign_expr();\n-        self.restriction = old;\n+        *self.restriction = old;\n         return e;\n     }\n \n     fn parse_initializer() -> Option<@expr> {\n-        match self.token {\n+        match *self.token {\n           token::EQ => {\n             self.bump();\n             return Some(self.parse_expr());\n           }\n           token::LARROW => {\n-              self.obsolete(copy self.span, ObsoleteMoveInit);\n+              self.obsolete(*self.span, ObsoleteMoveInit);\n               self.bump();\n               self.bump();\n               return None;\n@@ -2007,7 +2008,7 @@ pub impl Parser {\n         let mut pats = ~[];\n         loop {\n             pats.push(self.parse_pat(true));\n-            if self.token == token::BINOP(token::OR) { self.bump(); }\n+            if *self.token == token::BINOP(token::OR) { self.bump(); }\n             else { return pats; }\n         };\n     }\n@@ -2017,12 +2018,12 @@ pub impl Parser {\n         let mut tail = None;\n         let mut first = true;\n \n-        while self.token != token::RBRACKET {\n+        while *self.token != token::RBRACKET {\n             if first { first = false; }\n             else { self.expect(token::COMMA); }\n \n             let mut is_tail = false;\n-            if self.token == token::DOTDOT {\n+            if *self.token == token::DOTDOT {\n                 self.bump();\n                 is_tail = true;\n             }\n@@ -2049,15 +2050,15 @@ pub impl Parser {\n         let mut fields = ~[];\n         let mut etc = false;\n         let mut first = true;\n-        while self.token != token::RBRACE {\n+        while *self.token != token::RBRACE {\n             if first { first = false; }\n             else { self.expect(token::COMMA); }\n \n-            if self.token == token::UNDERSCORE {\n+            if *self.token == token::UNDERSCORE {\n                 self.bump();\n-                if self.token != token::RBRACE {\n+                if *self.token != token::RBRACE {\n                     self.fatal(~\"expected `}`, found `\" +\n-                               token_to_str(self.reader, self.token) +\n+                               token_to_str(self.reader, *self.token) +\n                                ~\"`\");\n                 }\n                 etc = true;\n@@ -2074,14 +2075,14 @@ pub impl Parser {\n             let fieldpath = ast_util::ident_to_path(mk_sp(lo1, hi1),\n                                                     fieldname);\n             let mut subpat;\n-            if self.token == token::COLON {\n+            if *self.token == token::COLON {\n                 self.bump();\n                 subpat = self.parse_pat(refutable);\n             } else {\n                 subpat = @ast::pat {\n                     id: self.get_id(),\n                     node: pat_ident(bind_infer, fieldpath, None),\n-                    span: self.last_span\n+                    span: *self.last_span\n                 };\n             }\n             fields.push(ast::field_pat { ident: fieldname, pat: subpat });\n@@ -2095,7 +2096,7 @@ pub impl Parser {\n         let lo = self.span.lo;\n         let mut hi = self.span.hi;\n         let mut pat;\n-        match self.token {\n+        match *self.token {\n           token::UNDERSCORE => { self.bump(); pat = pat_wild; }\n           token::AT => {\n             self.bump();\n@@ -2173,7 +2174,7 @@ pub impl Parser {\n           }\n           token::LPAREN => {\n             self.bump();\n-            if self.token == token::RPAREN {\n+            if *self.token == token::RPAREN {\n                 hi = self.span.hi;\n                 self.bump();\n                 let lit = @codemap::spanned {\n@@ -2184,7 +2185,7 @@ pub impl Parser {\n             } else {\n                 let mut fields = ~[self.parse_pat(refutable)];\n                 if self.look_ahead(1) != token::RPAREN {\n-                    while self.token == token::COMMA {\n+                    while *self.token == token::COMMA {\n                         self.bump();\n                         fields.push(self.parse_pat(refutable));\n                     }\n@@ -2233,7 +2234,7 @@ pub impl Parser {\n                         cannot_be_enum_or_struct = true\n                 }\n \n-                if is_plain_ident(self.token) && cannot_be_enum_or_struct {\n+                if is_plain_ident(*self.token) && cannot_be_enum_or_struct {\n                     let name = self.parse_value_path();\n                     let sub;\n                     if self.eat(token::AT) {\n@@ -2244,7 +2245,7 @@ pub impl Parser {\n                     pat = pat_ident(binding_mode, name, sub);\n                 } else {\n                     let enum_path = self.parse_path_with_tps(true);\n-                    match self.token {\n+                    match *self.token {\n                         token::LBRACE => {\n                             self.bump();\n                             let (fields, etc) =\n@@ -2255,7 +2256,7 @@ pub impl Parser {\n                         _ => {\n                             let mut args: ~[@pat] = ~[];\n                             let mut star_pat = false;\n-                            match self.token {\n+                            match *self.token {\n                               token::LPAREN => match self.look_ahead(1u) {\n                                 token::BINOP(token::STAR) => {\n                                     // This is a \"top constructor only\" pat\n@@ -2299,9 +2300,9 @@ pub impl Parser {\n \n     fn parse_pat_ident(refutable: bool,\n                        binding_mode: ast::binding_mode) -> ast::pat_ {\n-        if !is_plain_ident(self.token) {\n+        if !is_plain_ident(*self.token) {\n             self.span_fatal(\n-                copy self.last_span,\n+                *self.last_span,\n                 ~\"expected identifier, found path\");\n         }\n         let name = self.parse_value_path();\n@@ -2315,9 +2316,9 @@ pub impl Parser {\n         // leads to a parse error.  Note that if there is no explicit\n         // binding mode then we do not end up here, because the lookahead\n         // will direct us over to parse_enum_variant()\n-        if self.token == token::LPAREN {\n+        if *self.token == token::LPAREN {\n             self.span_fatal(\n-                copy self.last_span,\n+                *self.last_span,\n                 ~\"expected identifier, found enum pattern\");\n         }\n \n@@ -2365,7 +2366,7 @@ pub impl Parser {\n         if self.eat_keyword(~\"mut\") {\n             is_mutbl = struct_mutable;\n         }\n-        if !is_plain_ident(self.token) {\n+        if !is_plain_ident(*self.token) {\n             self.fatal(~\"expected ident\");\n         }\n         let name = self.parse_ident();\n@@ -2394,8 +2395,8 @@ pub impl Parser {\n             self.expect_keyword(~\"let\");\n             let decl = self.parse_let();\n             return @spanned(lo, decl.span.hi, stmt_decl(decl, self.get_id()));\n-        } else if is_ident(self.token)\n-            && !self.is_any_keyword(copy self.token)\n+        } else if is_ident(*self.token)\n+            && !self.is_any_keyword(*self.token)\n             && self.look_ahead(1) == token::NOT {\n \n             check_expected_item(self, first_item_attrs);\n@@ -2405,7 +2406,7 @@ pub impl Parser {\n             let pth = self.parse_value_path();\n             self.bump();\n \n-            let id = if self.token == token::LPAREN {\n+            let id = if *self.token == token::LPAREN {\n                 token::special_idents::invalid // no special identifier\n             } else {\n                 self.parse_ident()\n@@ -2460,7 +2461,7 @@ pub impl Parser {\n     }\n \n     fn expr_is_complete(e: @expr) -> bool {\n-        return self.restriction == RESTRICT_STMT_EXPR &&\n+        return *self.restriction == RESTRICT_STMT_EXPR &&\n             !classify::expr_requires_semi_to_be_stmt(e);\n     }\n \n@@ -2486,7 +2487,7 @@ pub impl Parser {\n \n         let lo = self.span.lo;\n         if self.eat_keyword(~\"unsafe\") {\n-            self.obsolete(copy self.span, ObsoleteUnsafeBlock);\n+            self.obsolete(*self.span, ObsoleteUnsafeBlock);\n         }\n         self.expect(token::LBRACE);\n         let (inner, next) =\n@@ -2530,12 +2531,12 @@ pub impl Parser {\n \n         let mut initial_attrs = attrs_remaining;\n \n-        if self.token == token::RBRACE && !vec::is_empty(initial_attrs) {\n+        if *self.token == token::RBRACE && !vec::is_empty(initial_attrs) {\n             self.fatal(~\"expected item\");\n         }\n \n-        while self.token != token::RBRACE {\n-            match self.token {\n+        while *self.token != token::RBRACE {\n+            match *self.token {\n                 token::SEMI => {\n                     self.bump(); // empty\n                 }\n@@ -2545,7 +2546,7 @@ pub impl Parser {\n                     match stmt.node {\n                         stmt_expr(e, stmt_id) => {\n                             // Expression without semicolon\n-                            match self.token {\n+                            match *self.token {\n                                 token::SEMI => {\n                                     self.bump();\n                                     stmts.push(@codemap::spanned {\n@@ -2570,7 +2571,7 @@ pub impl Parser {\n \n                         stmt_mac(ref m, _) => {\n                             // Statement macro; might be an expr\n-                            match self.token {\n+                            match *self.token {\n                                 token::SEMI => {\n                                     self.bump();\n                                     stmts.push(@codemap::spanned {\n@@ -2616,9 +2617,9 @@ pub impl Parser {\n         @Ty {\n             id: self.get_id(),\n             node: ty_path(\n-                ident_to_path(copy self.last_span, i),\n+                ident_to_path(*self.last_span, i),\n                 self.get_id()),\n-            span: self.last_span,\n+            span: *self.last_span,\n         }\n     }\n \n@@ -2644,20 +2645,20 @@ pub impl Parser {\n                     if self.eat_keyword(~\"static\") {\n                         bounds.push(RegionTyParamBound);\n                     } else {\n-                        self.span_err(copy self.span,\n+                        self.span_err(*self.span,\n                                       ~\"`&static` is the only permissible \\\n                                         region bound here\");\n                     }\n-                } else if is_ident(self.token) {\n-                    let maybe_bound = match self.token {\n+                } else if is_ident(*self.token) {\n+                    let maybe_bound = match *self.token {\n                       token::IDENT(copy sid, _) => {\n                         match *self.id_to_str(sid) {\n \n                           ~\"send\"\n                           | ~\"copy\"\n                           | ~\"const\"\n                           | ~\"owned\" => {\n-                            self.obsolete(copy self.span,\n+                            self.obsolete(*self.span,\n                                           ObsoleteLowerCaseKindBounds);\n                             // Bogus value, but doesn't matter, since\n                             // is an error\n@@ -2689,8 +2690,8 @@ pub impl Parser {\n                     loop;\n                 }\n \n-                if is_ident_or_path(self.token) {\n-                    self.obsolete(copy self.span,\n+                if is_ident_or_path(*self.token) {\n+                    self.obsolete(*self.span,\n                                   ObsoleteTraitBoundSeparator);\n                 }\n             }\n@@ -2732,7 +2733,7 @@ pub impl Parser {\n     }\n \n     fn is_self_ident() -> bool {\n-        match self.token {\n+        match *self.token {\n           token::IDENT(id, false) if id == special_idents::self_\n             => true,\n           _ => false\n@@ -2742,7 +2743,7 @@ pub impl Parser {\n     fn expect_self_ident() {\n         if !self.is_self_ident() {\n             self.fatal(fmt!(\"expected `self` but found `%s`\",\n-                            token_to_str(self.reader, self.token)));\n+                            token_to_str(self.reader, *self.token)));\n         }\n         self.bump();\n     }\n@@ -2773,7 +2774,7 @@ pub impl Parser {\n         // A bit of complexity and lookahead is needed here in order to to be\n         // backwards compatible.\n         let lo = self.span.lo;\n-        let self_ty = match copy self.token {\n+        let self_ty = match *self.token {\n           token::BINOP(token::AND) => {\n             maybe_parse_self_ty(sty_region, self)\n           }\n@@ -2795,7 +2796,7 @@ pub impl Parser {\n         // If we parsed a self type, expect a comma before the argument list.\n         let args_or_capture_items;\n         if self_ty != sty_by_ref {\n-            match copy self.token {\n+            match *self.token {\n                 token::COMMA => {\n                     self.bump();\n                     let sep = seq_sep_trailing_disallowed(token::COMMA);\n@@ -2809,7 +2810,8 @@ pub impl Parser {\n                 }\n                 _ => {\n                     self.fatal(~\"expected `,` or `)`, found `\" +\n-                               token_to_str(self.reader, self.token) + ~\"`\");\n+                               token_to_str(self.reader, *self.token) +\n+                               ~\"`\");\n                 }\n             }\n         } else {\n@@ -2850,7 +2852,7 @@ pub impl Parser {\n         let output = if self.eat(token::RARROW) {\n             self.parse_ty(false)\n         } else {\n-            @Ty { id: self.get_id(), node: ty_infer, span: self.span }\n+            @Ty { id: self.get_id(), node: ty_infer, span: *self.span }\n         };\n \n         ast::fn_decl {\n@@ -2929,7 +2931,7 @@ pub impl Parser {\n \n         // Parse traits, if necessary.\n         let traits;\n-        if self.token == token::COLON {\n+        if *self.token == token::COLON {\n             self.bump();\n             traits = self.parse_trait_ref_list(token::LBRACE);\n         } else {\n@@ -2954,7 +2956,7 @@ pub impl Parser {\n \n         // First, parse type parameters if necessary.\n         let mut tps;\n-        if self.token == token::LT {\n+        if *self.token == token::LT {\n             tps = self.parse_ty_params();\n         } else {\n             tps = ~[];\n@@ -2978,15 +2980,15 @@ pub impl Parser {\n                     })\n                 }\n                 _ => {\n-                    self.span_err(copy self.span, ~\"not a trait\");\n+                    self.span_err(*self.span, ~\"not a trait\");\n                     None\n                 }\n             };\n \n             ty = self.parse_ty(false);\n             opt_trait_ref\n         } else if self.eat(token::COLON) {\n-            self.obsolete(copy self.span, ObsoleteImplSyntax);\n+            self.obsolete(*self.span, ObsoleteImplSyntax);\n             Some(self.parse_trait_ref())\n         } else {\n             None\n@@ -3008,7 +3010,7 @@ pub impl Parser {\n     // the return type of the ctor function.\n     fn ident_to_path_tys(i: ident,\n                          typarams: ~[ty_param]) -> @path {\n-        let s = self.last_span;\n+        let s = *self.last_span;\n \n         @ast::path {\n              span: s,\n@@ -3026,7 +3028,7 @@ pub impl Parser {\n     }\n \n     fn ident_to_path(i: ident) -> @path {\n-        @ast::path { span: self.last_span,\n+        @ast::path { span: *self.last_span,\n                      global: false,\n                      idents: ~[i],\n                      rp: None,\n@@ -3051,7 +3053,7 @@ pub impl Parser {\n         self.parse_region_param();\n         let ty_params = self.parse_ty_params();\n         if self.eat(token::COLON) {\n-            self.obsolete(copy self.span, ObsoleteClassTraits);\n+            self.obsolete(*self.span, ObsoleteClassTraits);\n             let _ = self.parse_trait_ref_list(token::LBRACE);\n         }\n \n@@ -3063,7 +3065,7 @@ pub impl Parser {\n             // It's a record-like struct.\n             is_tuple_like = false;\n             fields = ~[];\n-            while self.token != token::RBRACE {\n+            while *self.token != token::RBRACE {\n                 match self.parse_class_item() {\n                   dtor_decl(ref blk, ref attrs, s) => {\n                       match the_dtor {\n@@ -3087,7 +3089,7 @@ pub impl Parser {\n                 }\n             }\n             self.bump();\n-        } else if self.token == token::LPAREN {\n+        } else if *self.token == token::LPAREN {\n             // It's a tuple-like struct.\n             is_tuple_like = true;\n             fields = do self.parse_unspanned_seq(token::LPAREN, token::RPAREN,\n@@ -3109,7 +3111,7 @@ pub impl Parser {\n         } else {\n             self.fatal(fmt!(\"expected `{`, `(`, or `;` after struct name \\\n                              but found `%s`\",\n-                            token_to_str(self.reader, self.token)));\n+                            token_to_str(self.reader, *self.token)));\n         }\n \n         let actual_dtor = do the_dtor.map |dtor| {\n@@ -3139,25 +3141,25 @@ pub impl Parser {\n \n     fn parse_single_class_item(vis: visibility) -> @struct_field {\n         if self.eat_obsolete_ident(\"let\") {\n-            self.obsolete(copy self.last_span, ObsoleteLet);\n+            self.obsolete(*self.last_span, ObsoleteLet);\n         }\n \n         let a_var = self.parse_instance_var(vis);\n-        match self.token {\n+        match *self.token {\n           token::SEMI => {\n-            self.obsolete(copy self.span, ObsoleteFieldTerminator);\n+            self.obsolete(*self.span, ObsoleteFieldTerminator);\n             self.bump();\n           }\n           token::COMMA => {\n             self.bump();\n           }\n           token::RBRACE => {}\n           _ => {\n-            self.span_fatal(copy self.span,\n+            self.span_fatal(*self.span,\n                             fmt!(\"expected `;`, `,`, or '}' but \\\n                                   found `%s`\",\n                                  token_to_str(self.reader,\n-                                              self.token)));\n+                                              *self.token)));\n           }\n         }\n         a_var\n@@ -3226,7 +3228,7 @@ pub impl Parser {\n         // outer attributes can't occur on view items (or macros\n         // invocations?)\n         let mut first = true;\n-        while self.token != term {\n+        while *self.token != term {\n             let mut attrs = self.parse_outer_attributes();\n             if first {\n                 attrs = vec::append(attrs_remaining, attrs);\n@@ -3243,7 +3245,7 @@ pub impl Parser {\n               }\n               _ => {\n                 self.fatal(~\"expected item but found `\" +\n-                           token_to_str(self.reader, self.token) + ~\"`\");\n+                           token_to_str(self.reader, *self.token) + ~\"`\");\n               }\n             }\n             debug!(\"parse_mod_items: attrs=%?\", attrs);\n@@ -3268,9 +3270,9 @@ pub impl Parser {\n     }\n \n     fn parse_item_mod(outer_attrs: ~[ast::attribute]) -> item_info {\n-        let id_span = self.span;\n+        let id_span = *self.span;\n         let id = self.parse_ident();\n-        let info_ = if self.token == token::SEMI {\n+        let info_ = if *self.token == token::SEMI {\n             self.bump();\n             // This mod is in an external file. Let's go get it!\n             let (m, attrs) = self.eval_src_mod(id, outer_attrs, id_span);\n@@ -3292,7 +3294,7 @@ pub impl Parser {\n         match ::attr::first_attr_value_str_by_name(outer_attrs, ~\"merge\") {\n             Some(path) => {\n                 let prefix = Path(\n-                    self.sess.cm.span_to_filename(copy self.span));\n+                    self.sess.cm.span_to_filename(*self.span));\n                 let prefix = prefix.dir_path();\n                 let path = Path(copy *path);\n                 let (new_mod_item, new_attrs) = self.eval_src_mod_from_path(\n@@ -3337,9 +3339,9 @@ pub impl Parser {\n                     outer_attrs: ~[ast::attribute],\n                     id_sp: span) -> (ast::item_, ~[ast::attribute]) {\n \n-        let prefix = Path(self.sess.cm.span_to_filename(copy self.span));\n+        let prefix = Path(self.sess.cm.span_to_filename(*self.span));\n         let prefix = prefix.dir_path();\n-        let mod_path = Path(\".\").push_many(self.mod_path_stack);\n+        let mod_path = Path(\".\").push_many(*self.mod_path_stack);\n         let default_path = self.sess.interner.get(id) + ~\".rs\";\n         let file_path = match ::attr::first_attr_value_str_by_name(\n             outer_attrs, ~\"path\") {\n@@ -3456,7 +3458,7 @@ pub impl Parser {\n \n         let mut items: ~[@foreign_item] = foreign_items;\n         let mut initial_attrs = attrs_remaining;\n-        while self.token != token::RBRACE {\n+        while *self.token != token::RBRACE {\n             let attrs = vec::append(initial_attrs,\n                                     self.parse_outer_attributes());\n             initial_attrs = ~[];\n@@ -3478,7 +3480,7 @@ pub impl Parser {\n \n         // Parse the ABI.\n         let abi_opt;\n-        match self.token {\n+        match *self.token {\n             token::LIT_STR(copy found_abi) => {\n                 self.bump();\n                 abi_opt = Some(found_abi);\n@@ -3492,21 +3494,21 @@ pub impl Parser {\n         if self.is_keyword(~\"mod\") {\n             must_be_named_mod = true;\n             self.expect_keyword(~\"mod\");\n-        } else if self.token != token::LBRACE {\n-            self.span_fatal(copy self.span,\n+        } else if *self.token != token::LBRACE {\n+            self.span_fatal(*self.span,\n                             fmt!(\"expected `{` or `mod` but found %s\",\n-                                 token_to_str(self.reader, self.token)));\n+                                 token_to_str(self.reader, *self.token)));\n         }\n \n-        let (sort, ident) = match self.token {\n+        let (sort, ident) = match *self.token {\n             token::IDENT(*) => (ast::named, self.parse_ident()),\n             _ => {\n                 if must_be_named_mod {\n-                    self.span_fatal(copy self.span,\n+                    self.span_fatal(*self.span,\n                                     fmt!(\"expected foreign module name but \\\n                                           found %s\",\n                                          token_to_str(self.reader,\n-                                                      self.token)));\n+                                                      *self.token)));\n                 }\n \n                 (ast::anonymous,\n@@ -3534,7 +3536,7 @@ pub impl Parser {\n         match abi_opt {\n             None => {}  // OK.\n             Some(_) => {\n-                self.span_err(copy self.span, ~\"an ABI may not be specified \\\n+                self.span_err(*self.span, ~\"an ABI may not be specified \\\n                                                 here\");\n             }\n         }\n@@ -3575,7 +3577,7 @@ pub impl Parser {\n     fn parse_struct_def() -> @struct_def {\n         let mut the_dtor: Option<(blk, ~[attribute], codemap::span)> = None;\n         let mut fields: ~[@struct_field] = ~[];\n-        while self.token != token::RBRACE {\n+        while *self.token != token::RBRACE {\n             match self.parse_class_item() {\n                 dtor_decl(ref blk, ref attrs, s) => {\n                     match the_dtor {\n@@ -3621,7 +3623,7 @@ pub impl Parser {\n         let mut all_nullary = true, have_disr = false;\n         let mut common_fields = None;\n \n-        while self.token != token::RBRACE {\n+        while *self.token != token::RBRACE {\n             let variant_attrs = self.parse_outer_attributes();\n             let vlo = self.span.lo;\n \n@@ -3652,7 +3654,7 @@ pub impl Parser {\n                     // Parse a struct variant.\n                     all_nullary = false;\n                     kind = struct_variant_kind(self.parse_struct_def());\n-                } else if self.token == token::LPAREN {\n+                } else if *self.token == token::LPAREN {\n                     all_nullary = false;\n                     let arg_tys = self.parse_unspanned_seq(\n                         token::LPAREN, token::RPAREN,\n@@ -3701,7 +3703,7 @@ pub impl Parser {\n         self.parse_region_param();\n         let ty_params = self.parse_ty_params();\n         // Newtype syntax\n-        if self.token == token::EQ {\n+        if *self.token == token::EQ {\n             self.bump();\n             let ty = self.parse_ty(false);\n             self.expect(token::SEMI);\n@@ -3733,7 +3735,7 @@ pub impl Parser {\n     }\n \n     fn parse_fn_ty_sigil() -> Option<Sigil> {\n-        match self.token {\n+        match *self.token {\n             token::AT => {\n                 self.bump();\n                 Some(ManagedSigil)\n@@ -3879,7 +3881,7 @@ pub impl Parser {\n                 vis: visibility,\n                 span: mk_sp(lo, self.last_span.hi)\n             });\n-        } else if macros_allowed && !self.is_any_keyword(copy self.token)\n+        } else if macros_allowed && !self.is_any_keyword(*self.token)\n                 && self.look_ahead(1) == token::NOT\n                 && (is_plain_ident(self.look_ahead(2))\n                     || self.look_ahead(2) == token::LPAREN\n@@ -3896,16 +3898,16 @@ pub impl Parser {\n             // a 'special' identifier (like what `macro_rules!` uses)\n             // is optional. We should eventually unify invoc syntax\n             // and remove this.\n-            let id = if is_plain_ident(self.token) {\n+            let id = if is_plain_ident(*self.token) {\n                 self.parse_ident()\n             } else {\n                 token::special_idents::invalid // no special identifier\n             };\n             // eat a matched-delimiter token tree:\n-            let tts = match self.token {\n+            let tts = match *self.token {\n               token::LPAREN | token::LBRACE => {\n-                let ket = token::flip_delimiter(copy self.token);\n-                self.parse_unspanned_seq(copy self.token, ket,\n+                let ket = token::flip_delimiter(*self.token);\n+                self.parse_unspanned_seq(*self.token, ket,\n                                          seq_sep_none(),\n                                          |p| p.parse_token_tree())\n               }\n@@ -3925,7 +3927,7 @@ pub impl Parser {\n                 let mut s = ~\"unmatched visibility `\";\n                 s += if visibility == public { ~\"pub\" } else { ~\"priv\" };\n                 s += ~\"`\";\n-                self.span_fatal(copy self.last_span, s);\n+                self.span_fatal(*self.last_span, s);\n             }\n             return iovi_none;\n         };\n@@ -3961,12 +3963,12 @@ pub impl Parser {\n         let first_ident = self.parse_ident();\n         let mut path = ~[first_ident];\n         debug!(\"parsed view_path: %s\", *self.id_to_str(first_ident));\n-        match self.token {\n+        match *self.token {\n           token::EQ => {\n             // x = foo::bar\n             self.bump();\n             path = ~[self.parse_ident()];\n-            while self.token == token::MOD_SEP {\n+            while *self.token == token::MOD_SEP {\n                 self.bump();\n                 let id = self.parse_ident();\n                 path.push(id);\n@@ -3983,11 +3985,10 @@ pub impl Parser {\n \n           token::MOD_SEP => {\n             // foo::bar or foo::{a,b,c} or foo::*\n-            while self.token == token::MOD_SEP {\n+            while *self.token == token::MOD_SEP {\n                 self.bump();\n \n-                match copy self.token {\n-\n+                match *self.token {\n                   token::IDENT(i, _) => {\n                     self.bump();\n                     path.push(i);\n@@ -4038,7 +4039,7 @@ pub impl Parser {\n \n     fn parse_view_paths() -> ~[@view_path] {\n         let mut vp = ~[self.parse_view_path()];\n-        while self.token == token::COMMA {\n+        while *self.token == token::COMMA {\n             self.bump();\n             vp.push(self.parse_view_path());\n         }\n@@ -4048,7 +4049,7 @@ pub impl Parser {\n     fn is_view_item() -> bool {\n         let tok, next_tok;\n         if !self.is_keyword(~\"pub\") && !self.is_keyword(~\"priv\") {\n-            tok = self.token;\n+            tok = *self.token;\n             next_tok = self.look_ahead(1);\n         } else {\n             tok = self.look_ahead(1);\n@@ -4159,7 +4160,7 @@ pub impl Parser {\n     }\n \n     fn parse_str() -> @~str {\n-        match copy self.token {\n+        match *self.token {\n           token::LIT_STR(s) => { self.bump(); self.id_to_str(s) }\n           _ =>  self.fatal(~\"expected string literal\")\n         }"}]}