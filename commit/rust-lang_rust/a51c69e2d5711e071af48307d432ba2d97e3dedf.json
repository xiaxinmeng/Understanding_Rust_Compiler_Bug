{"sha": "a51c69e2d5711e071af48307d432ba2d97e3dedf", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE1MWM2OWUyZDU3MTFlMDcxYWY0ODMwN2Q0MzJiYTJkOTdlM2RlZGY=", "commit": {"author": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2017-11-05T16:25:45Z"}, "committer": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2017-11-08T23:40:04Z"}, "message": "proc_macro: process proc_macro tokens instead of libsyntax ones in the quasi-quoter.", "tree": {"sha": "4ff3096738c759d0b93cebdff6c6bdf95d61dbc5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4ff3096738c759d0b93cebdff6c6bdf95d61dbc5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a51c69e2d5711e071af48307d432ba2d97e3dedf", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a51c69e2d5711e071af48307d432ba2d97e3dedf", "html_url": "https://github.com/rust-lang/rust/commit/a51c69e2d5711e071af48307d432ba2d97e3dedf", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a51c69e2d5711e071af48307d432ba2d97e3dedf/comments", "author": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "02004ef78383cb174a41df7735a552823fa10b90", "url": "https://api.github.com/repos/rust-lang/rust/commits/02004ef78383cb174a41df7735a552823fa10b90", "html_url": "https://github.com/rust-lang/rust/commit/02004ef78383cb174a41df7735a552823fa10b90"}], "stats": {"total": 320, "additions": 167, "deletions": 153}, "files": [{"sha": "33dd6c9a94170a8ab6743abd64457f1941aeaa5f", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a51c69e2d5711e071af48307d432ba2d97e3dedf/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a51c69e2d5711e071af48307d432ba2d97e3dedf/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=a51c69e2d5711e071af48307d432ba2d97e3dedf", "patch": "@@ -191,7 +191,7 @@ impl Default for Span {\n /// This is needed to implement a custom quoter.\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n pub fn quote_span(span: Span) -> TokenStream {\n-    TokenStream(quote::Quote::quote(&span.0))\n+    quote::Quote::quote(span)\n }\n \n macro_rules! diagnostic_method {"}, {"sha": "49a9d71e83c02e3a93c9667347134864db5dd15e", "filename": "src/libproc_macro/quote.rs", "status": "modified", "additions": 166, "deletions": 152, "changes": 318, "blob_url": "https://github.com/rust-lang/rust/blob/a51c69e2d5711e071af48307d432ba2d97e3dedf/src%2Flibproc_macro%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a51c69e2d5711e071af48307d432ba2d97e3dedf/src%2Flibproc_macro%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fquote.rs?ref=a51c69e2d5711e071af48307d432ba2d97e3dedf", "patch": "@@ -15,13 +15,12 @@\n //! including re-exported API `libsyntax`, to build a `syntax::tokenstream::TokenStream`\n //! and wrap it into a `proc_macro::TokenStream`.\n \n-use syntax::ast::Ident;\n+use {Delimiter, Literal, Spacing, Span, Term, TokenNode, TokenStream, TokenTree};\n+\n+use std::iter;\n use syntax::ext::base::{ExtCtxt, ProcMacro};\n-use syntax::parse::token::{self, Token, Lit};\n-use syntax::symbol::Symbol;\n-use syntax::tokenstream::{Delimited, TokenTree, TokenStream, TokenStreamBuilder};\n-use syntax_pos::{DUMMY_SP, Span};\n-use syntax_pos::hygiene::SyntaxContext;\n+use syntax::parse::token;\n+use syntax::tokenstream;\n \n pub struct Quoter;\n \n@@ -30,216 +29,231 @@ pub mod __rt {\n     pub use syntax::parse::token;\n     pub use syntax::symbol::Symbol;\n     pub use syntax::tokenstream::{TokenStream, TokenStreamBuilder, TokenTree, Delimited};\n-    pub use super::{ctxt, span};\n+\n+    use syntax_pos::Span;\n+    use syntax_pos::hygiene::SyntaxContext;\n \n     pub fn unquote<T: Into<::TokenStream> + Clone>(tokens: &T) -> TokenStream {\n         T::into(tokens.clone()).0\n     }\n-}\n \n-pub fn ctxt() -> SyntaxContext {\n-    ::__internal::with_sess(|(_, mark)| SyntaxContext::empty().apply_mark(mark))\n-}\n+    pub fn ctxt() -> SyntaxContext {\n+        ::__internal::with_sess(|(_, mark)| SyntaxContext::empty().apply_mark(mark))\n+    }\n \n-pub fn span() -> Span {\n-    ::Span::default().0\n+    pub fn span() -> Span {\n+        ::Span::default().0\n+    }\n }\n \n pub trait Quote {\n-    fn quote(&self) -> TokenStream;\n+    fn quote(self) -> TokenStream;\n }\n \n macro_rules! quote_tok {\n-    (,) => { Token::Comma };\n-    (.) => { Token::Dot };\n-    (:) => { Token::Colon };\n-    (::) => { Token::ModSep };\n-    (!) => { Token::Not };\n-    (<) => { Token::Lt };\n-    (>) => { Token::Gt };\n-    (_) => { Token::Underscore };\n-    (0) => { Token::Literal(token::Lit::Integer(Symbol::intern(\"0\")), None) };\n-    (&) => { Token::BinOp(token::And) };\n-    ($i:ident) => { Token::Ident(Ident { name: Symbol::intern(stringify!($i)), ctxt: ctxt() }) };\n+    (,) => { TokenNode::Op(',', Spacing::Alone) };\n+    (.) => { TokenNode::Op('.', Spacing::Alone) };\n+    (:) => { TokenNode::Op(':', Spacing::Alone) };\n+    (::) => {\n+        [\n+            TokenNode::Op(':', Spacing::Joint),\n+            TokenNode::Op(':', Spacing::Alone)\n+        ].iter().cloned().collect::<TokenStream>()\n+    };\n+    (!) => { TokenNode::Op('!', Spacing::Alone) };\n+    (<) => { TokenNode::Op('<', Spacing::Alone) };\n+    (>) => { TokenNode::Op('>', Spacing::Alone) };\n+    (_) => { TokenNode::Op('_', Spacing::Alone) };\n+    (0) => { TokenNode::Literal(::Literal::integer(0)) };\n+    (&) => { TokenNode::Op('&', Spacing::Alone) };\n+    ($i:ident) => { TokenNode::Term(Term::intern(stringify!($i))) };\n }\n \n macro_rules! quote_tree {\n-    ((unquote $($t:tt)*)) => { TokenStream::from($($t)*) };\n+    ((unquote $($t:tt)*)) => { $($t)* };\n     ((quote $($t:tt)*)) => { ($($t)*).quote() };\n-    (($($t:tt)*)) => { delimit(token::Paren, quote!($($t)*)) };\n-    ([$($t:tt)*]) => { delimit(token::Bracket, quote!($($t)*)) };\n-    ({$($t:tt)*}) => { delimit(token::Brace, quote!($($t)*)) };\n+    (($($t:tt)*)) => { TokenNode::Group(Delimiter::Parenthesis, quote!($($t)*)) };\n+    ([$($t:tt)*]) => { TokenNode::Group(Delimiter::Bracket, quote!($($t)*)) };\n+    ({$($t:tt)*}) => { TokenNode::Group(Delimiter::Brace, quote!($($t)*)) };\n     (rt) => { quote!(::__internal::__rt) };\n-    ($t:tt) => { TokenStream::from(TokenTree::Token(span(), quote_tok!($t))) };\n-}\n-\n-fn delimit(delim: token::DelimToken, stream: TokenStream) -> TokenStream {\n-    TokenTree::Delimited(span(), Delimited { delim: delim, tts: stream.into() }).into()\n+    ($t:tt) => { quote_tok!($t) };\n }\n \n macro_rules! quote {\n     () => { TokenStream::empty() };\n-    ($($t:tt)*) => { [ $( quote_tree!($t), )* ].iter().cloned().collect::<TokenStream>() };\n+    ($($t:tt)*) => {\n+        [\n+            $(TokenStream::from(quote_tree!($t)),)*\n+        ].iter().cloned().collect::<TokenStream>()\n+    };\n }\n \n impl ProcMacro for Quoter {\n-    fn expand<'cx>(&self, cx: &'cx mut ExtCtxt, _: Span, stream: TokenStream) -> TokenStream {\n+    fn expand<'cx>(&self, cx: &'cx mut ExtCtxt,\n+                   _: ::syntax_pos::Span,\n+                   stream: tokenstream::TokenStream)\n+                   -> tokenstream::TokenStream {\n         let mut info = cx.current_expansion.mark.expn_info().unwrap();\n         info.callee.allow_internal_unstable = true;\n         cx.current_expansion.mark.set_expn_info(info);\n-        ::__internal::set_sess(cx, || quote!(::TokenStream { 0: (quote stream) }))\n+        ::__internal::set_sess(cx, || quote!(::TokenStream {\n+            0: (quote TokenStream(stream))\n+        }).0)\n     }\n }\n \n impl<T: Quote> Quote for Option<T> {\n-    fn quote(&self) -> TokenStream {\n-        match *self {\n-            Some(ref t) => quote!(Some((quote t))),\n+    fn quote(self) -> TokenStream {\n+        match self {\n+            Some(t) => quote!(Some((quote t))),\n             None => quote!(None),\n         }\n     }\n }\n \n impl Quote for TokenStream {\n-    fn quote(&self) -> TokenStream {\n-        let mut builder = TokenStreamBuilder::new();\n-        builder.push(quote!(rt::TokenStreamBuilder::new()));\n-\n-        let mut trees = self.trees();\n-        loop {\n-            let (mut tree, mut is_joint) = match trees.next_as_stream() {\n-                Some(next) => next.as_tree(),\n-                None => return builder.add(quote!(.build())).build(),\n-            };\n-            if let TokenTree::Token(_, Token::Dollar) = tree {\n-                let (next_tree, next_is_joint) = match trees.next_as_stream() {\n-                    Some(next) => next.as_tree(),\n-                    None => panic!(\"unexpected trailing `$` in `quote!`\"),\n-                };\n-                match next_tree {\n-                    TokenTree::Token(_, Token::Ident(..)) => {\n-                        builder.push(quote!(.add(rt::unquote(&(unquote next_tree)))));\n-                        continue\n+    fn quote(self) -> TokenStream {\n+        let mut after_dollar = false;\n+        let stream = iter::once(quote!(rt::TokenStreamBuilder::new()))\n+            .chain(self.into_iter().filter_map(|tree| {\n+                if after_dollar {\n+                    after_dollar = false;\n+                    match tree.kind {\n+                        TokenNode::Term(_) => {\n+                            return Some(quote!(.add(rt::unquote(&(unquote tree)))));\n+                        }\n+                        TokenNode::Op('$', _) => {}\n+                        _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n                     }\n-                    TokenTree::Token(_, Token::Dollar) => {\n-                        tree = next_tree;\n-                        is_joint = next_is_joint;\n-                    }\n-                    _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n+                } else if let TokenNode::Op('$', _) = tree.kind {\n+                    after_dollar = true;\n+                    return None;\n                 }\n-            }\n \n-            builder.push(match is_joint {\n-                true => quote!(.add((quote tree).joint())),\n-                false => quote!(.add(rt::TokenStream::from((quote tree)))),\n-            });\n+                Some(quote!(.add(rt::TokenStream::from((quote tree)))))\n+            }))\n+            .chain(iter::once(quote!(.build()))).collect();\n+\n+        if after_dollar {\n+            panic!(\"unexpected trailing `$` in `quote!`\");\n         }\n+\n+        stream\n     }\n }\n \n impl Quote for TokenTree {\n-    fn quote(&self) -> TokenStream {\n-        match *self {\n-            TokenTree::Token(span, ref token) => quote! {\n-                rt::TokenTree::Token((quote span), (quote token))\n+    fn quote(self) -> TokenStream {\n+        let (op, kind) = match self.kind {\n+            TokenNode::Op(op, kind) => (op, kind),\n+            TokenNode::Group(delimiter, tokens) => {\n+                return quote! {\n+                    rt::TokenTree::Delimited((quote self.span), rt::Delimited {\n+                        delim: (quote delimiter),\n+                        tts: (quote tokens).into()\n+                    })\n+                };\n+            },\n+            TokenNode::Term(term) => {\n+                let variant = if term.as_str().starts_with(\"'\") {\n+                    quote!(Lifetime)\n+                } else {\n+                    quote!(Ident)\n+                };\n+                return quote! {\n+                    rt::TokenTree::Token((quote self.span),\n+                        rt::token::(unquote variant)(rt::Ident {\n+                            name: (quote term),\n+                            ctxt: rt::ctxt()\n+                        }))\n+                };\n+            }\n+            TokenNode::Literal(lit) => {\n+                return quote! {\n+                    rt::TokenTree::Token((quote self.span), (quote lit))\n+                };\n+            }\n+        };\n+\n+        let token = match op {\n+            '=' => quote!(Eq),\n+            '<' => quote!(Lt),\n+            '>' => quote!(Gt),\n+            '!' => quote!(Not),\n+            '~' => quote!(Tilde),\n+            '+' => quote!(BinOp(rt::token::BinOpToken::Plus)),\n+            '-' => quote!(BinOp(rt::token::BinOpToken::Minus)),\n+            '*' => quote!(BinOp(rt::token::BinOpToken::Star)),\n+            '/' => quote!(BinOp(rt::token::BinOpToken::Slash)),\n+            '%' => quote!(BinOp(rt::token::BinOpToken::Percent)),\n+            '^' => quote!(BinOp(rt::token::BinOpToken::Caret)),\n+            '&' => quote!(BinOp(rt::token::BinOpToken::And)),\n+            '|' => quote!(BinOp(rt::token::BinOpToken::Or)),\n+            '@' => quote!(At),\n+            '.' => quote!(Dot),\n+            ',' => quote!(Comma),\n+            ';' => quote!(Semi),\n+            ':' => quote!(Colon),\n+            '#' => quote!(Pound),\n+            '$' => quote!(Dollar),\n+            '?' => quote!(Question),\n+            '_' => quote!(Underscore),\n+            _ => panic!(\"unsupported character {}\", op),\n+        };\n+\n+        match kind {\n+            Spacing::Alone => quote! {\n+                rt::TokenTree::Token((quote self.span), rt::token::(unquote token))\n             },\n-            TokenTree::Delimited(span, ref delimited) => quote! {\n-                rt::TokenTree::Delimited((quote span), (quote delimited))\n+            Spacing::Joint => quote! {\n+                rt::TokenTree::Token((quote self.span), rt::token::(unquote token)).joint()\n             },\n         }\n     }\n }\n \n-impl Quote for Delimited {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::Delimited { delim: (quote self.delim), tts: (quote self.stream()).into() })\n-    }\n-}\n-\n impl<'a> Quote for &'a str {\n-    fn quote(&self) -> TokenStream {\n-        TokenTree::Token(span(), Token::Literal(token::Lit::Str_(Symbol::intern(self)), None))\n-            .into()\n+    fn quote(self) -> TokenStream {\n+        TokenNode::Literal(Literal::string(self)).into()\n     }\n }\n \n impl Quote for usize {\n-    fn quote(&self) -> TokenStream {\n-        let integer_symbol = Symbol::intern(&self.to_string());\n-        TokenTree::Token(DUMMY_SP, Token::Literal(token::Lit::Integer(integer_symbol), None))\n-            .into()\n-    }\n-}\n-\n-impl Quote for Ident {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::Ident { name: (quote self.name), ctxt: rt::ctxt() })\n+    fn quote(self) -> TokenStream {\n+        TokenNode::Literal(Literal::integer(self as i128)).into()\n     }\n }\n \n-impl Quote for Symbol {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::Symbol::intern((quote &*self.as_str())))\n+impl Quote for Term {\n+    fn quote(self) -> TokenStream {\n+        quote!(rt::Symbol::intern((quote self.as_str())))\n     }\n }\n \n impl Quote for Span {\n-    fn quote(&self) -> TokenStream {\n+    fn quote(self) -> TokenStream {\n         quote!(rt::span())\n     }\n }\n \n-impl Quote for Token {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*; $($t:tt)*) => {\n-                match *self {\n-                    $( Token::$i => quote!(rt::token::$i), )*\n-                    $( $t )*\n-                }\n-            }\n-        }\n-\n-        gen_match! {\n-            Eq, Lt, Le, EqEq, Ne, Ge, Gt, AndAnd, OrOr, Not, Tilde, At, Dot, DotDot, DotDotDot,\n-            DotDotEq, Comma, Semi, Colon, ModSep, RArrow, LArrow, FatArrow, Pound, Dollar,\n-            Question, Underscore;\n-\n-            Token::OpenDelim(delim) => quote!(rt::token::OpenDelim((quote delim))),\n-            Token::CloseDelim(delim) => quote!(rt::token::CloseDelim((quote delim))),\n-            Token::BinOp(tok) => quote!(rt::token::BinOp((quote tok))),\n-            Token::BinOpEq(tok) => quote!(rt::token::BinOpEq((quote tok))),\n-            Token::Ident(ident) => quote!(rt::token::Ident((quote ident))),\n-            Token::Lifetime(ident) => quote!(rt::token::Lifetime((quote ident))),\n-            Token::Literal(lit, sfx) => quote!(rt::token::Literal((quote lit), (quote sfx))),\n-            _ => panic!(\"Unhandled case!\"),\n-        }\n-    }\n-}\n-\n-impl Quote for token::BinOpToken {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*) => {\n-                match *self {\n-                    $( token::BinOpToken::$i => quote!(rt::token::BinOpToken::$i), )*\n-                }\n-            }\n-        }\n-\n-        gen_match!(Plus, Minus, Star, Slash, Percent, Caret, And, Or, Shl, Shr)\n-    }\n-}\n+impl Quote for Literal {\n+    fn quote(self) -> TokenStream {\n+        let (lit, sfx) = match self.0 {\n+            token::Literal(lit, sfx) => (lit, sfx.map(Term)),\n+            _ => panic!(\"unsupported literal {:?}\", self.0),\n+        };\n \n-impl Quote for Lit {\n-    fn quote(&self) -> TokenStream {\n         macro_rules! gen_match {\n             ($($i:ident),*; $($raw:ident),*) => {\n-                match *self {\n-                    $( Lit::$i(lit) => quote!(rt::token::Lit::$i((quote lit))), )*\n-                    $( Lit::$raw(lit, n) => {\n-                        quote!(::syntax::parse::token::Lit::$raw((quote lit), (quote n)))\n-                    })*\n+                match lit {\n+                    $(token::Lit::$i(lit) => quote! {\n+                        rt::token::Literal(rt::token::Lit::$i((quote Term(lit))),\n+                            (quote sfx))\n+                    },)*\n+                    $(token::Lit::$raw(lit, n) => quote! {\n+                        rt::token::Literal(rt::token::Lit::$raw((quote Term(lit)), (quote n)),\n+                            (quote sfx))\n+                    },)*\n                 }\n             }\n         }\n@@ -248,16 +262,16 @@ impl Quote for Lit {\n     }\n }\n \n-impl Quote for token::DelimToken {\n-    fn quote(&self) -> TokenStream {\n+impl Quote for Delimiter {\n+    fn quote(self) -> TokenStream {\n         macro_rules! gen_match {\n-            ($($i:ident),*) => {\n-                match *self {\n-                    $(token::DelimToken::$i => { quote!(rt::token::DelimToken::$i) })*\n+            ($($i:ident => $j:ident),*) => {\n+                match self {\n+                    $(Delimiter::$i => { quote!(rt::token::DelimToken::$j) })*\n                 }\n             }\n         }\n \n-        gen_match!(Paren, Bracket, Brace, NoDelim)\n+        gen_match!(Parenthesis => Paren, Brace => Brace, Bracket => Bracket, None => NoDelim)\n     }\n }"}]}