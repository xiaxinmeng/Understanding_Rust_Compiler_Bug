{"sha": "779676f782565cfc936db79db48e2e7b62adf3a3", "node_id": "MDY6Q29tbWl0NzI0NzEyOjc3OTY3NmY3ODI1NjVjZmM5MzZkYjc5ZGI0OGUyZTdiNjJhZGYzYTM=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-05-02T02:19:12Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-05-02T02:19:12Z"}, "message": "Remove unused code in subtree_source", "tree": {"sha": "487b133512986fb6eb6eac4068e0045e75cfd2ac", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/487b133512986fb6eb6eac4068e0045e75cfd2ac"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/779676f782565cfc936db79db48e2e7b62adf3a3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/779676f782565cfc936db79db48e2e7b62adf3a3", "html_url": "https://github.com/rust-lang/rust/commit/779676f782565cfc936db79db48e2e7b62adf3a3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/779676f782565cfc936db79db48e2e7b62adf3a3/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a7ef9bac4e2ffd8120b4053c8bfc3132e047fa45", "url": "https://api.github.com/repos/rust-lang/rust/commits/a7ef9bac4e2ffd8120b4053c8bfc3132e047fa45", "html_url": "https://github.com/rust-lang/rust/commit/a7ef9bac4e2ffd8120b4053c8bfc3132e047fa45"}], "stats": {"total": 223, "additions": 41, "deletions": 182}, "files": [{"sha": "8176296e6f14fc210600176279df6dece6342bdc", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "modified", "additions": 41, "deletions": 182, "changes": 223, "blob_url": "https://github.com/rust-lang/rust/blob/779676f782565cfc936db79db48e2e7b62adf3a3/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/779676f782565cfc936db79db48e2e7b62adf3a3/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=779676f782565cfc936db79db48e2e7b62adf3a3", "patch": "@@ -45,28 +45,13 @@ impl<'a> TokenSeq<'a> {\n             }\n         }\n     }\n-\n-    fn len(&self) -> usize {\n-        match self {\n-            TokenSeq::Subtree(subtree) => subtree.token_trees.len() + 2,\n-            TokenSeq::Seq(tokens) => tokens.len(),\n-        }\n-    }\n-\n-    fn child_slice(&self, pos: usize) -> &[tt::TokenTree] {\n-        match self {\n-            TokenSeq::Subtree(subtree) => &subtree.token_trees[pos - 1..],\n-            TokenSeq::Seq(tokens) => &tokens[pos..],\n-        }\n-    }\n }\n \n #[derive(Debug, Clone, Eq, PartialEq)]\n struct TtToken {\n     pub kind: SyntaxKind,\n     pub is_joint_to_next: bool,\n     pub text: SmolStr,\n-    pub n_tokens: usize,\n }\n \n #[derive(Debug, Clone, Eq, PartialEq)]\n@@ -80,19 +65,12 @@ struct SubTreeWalker<'a> {\n     pos: usize,\n     stack: Vec<(TokenSeq<'a>, usize)>,\n     cursor: WalkCursor,\n-    last_steps: Vec<usize>,\n     ts: TokenSeq<'a>,\n }\n \n impl<'a> SubTreeWalker<'a> {\n     fn new(ts: TokenSeq<'a>) -> SubTreeWalker {\n-        let mut res = SubTreeWalker {\n-            pos: 0,\n-            stack: vec![],\n-            cursor: WalkCursor::Eof,\n-            last_steps: vec![],\n-            ts,\n-        };\n+        let mut res = SubTreeWalker { pos: 0, stack: vec![], cursor: WalkCursor::Eof, ts };\n \n         res.reset();\n         res\n@@ -105,7 +83,6 @@ impl<'a> SubTreeWalker<'a> {\n     fn reset(&mut self) {\n         self.pos = 0;\n         self.stack = vec![];\n-        self.last_steps = vec![];\n \n         self.cursor = match self.ts.get(0) {\n             DelimToken::Token(token) => match token {\n@@ -114,10 +91,7 @@ impl<'a> SubTreeWalker<'a> {\n                     self.stack.push((ts, 0));\n                     WalkCursor::Token(0, convert_delim(subtree.delimiter, false))\n                 }\n-                tt::TokenTree::Leaf(leaf) => {\n-                    let next_tokens = self.ts.child_slice(0);\n-                    WalkCursor::Token(0, convert_leaf(&next_tokens, leaf))\n-                }\n+                tt::TokenTree::Leaf(leaf) => WalkCursor::Token(0, convert_leaf(leaf)),\n             },\n             DelimToken::Delim(delim, is_end) => {\n                 assert!(!is_end);\n@@ -138,71 +112,39 @@ impl<'a> SubTreeWalker<'a> {\n         self.stack.last().map(|(t, _)| t).unwrap_or(&self.ts)\n     }\n \n-    /// Move cursor backward by 1 step\n-    fn backward(&mut self) {\n-        if self.last_steps.is_empty() {\n-            return;\n-        }\n-\n-        self.pos -= 1;\n-        let last_step = self.last_steps.pop().unwrap();\n-\n-        self.cursor = match self.cursor {\n-            WalkCursor::Token(idx, _) => self.walk_token(idx, last_step, true),\n-            WalkCursor::Eof => {\n-                let len = self.top().len();\n-                self.walk_token(len, last_step, true)\n-            }\n-        }\n-    }\n-\n     /// Move cursor forward by 1 step        \n     fn forward(&mut self) {\n         if self.is_eof() {\n             return;\n         }\n         self.pos += 1;\n \n-        let step = self.current().map(|x| x.n_tokens).unwrap_or(1);\n-        self.last_steps.push(step);\n-\n         if let WalkCursor::Token(u, _) = self.cursor {\n-            self.cursor = self.walk_token(u, step, false)\n+            self.cursor = self.walk_token(u)\n         }\n     }\n \n     /// Traversal child token\n-    fn walk_token(&mut self, pos: usize, offset: usize, backward: bool) -> WalkCursor {\n+    fn walk_token(&mut self, pos: usize) -> WalkCursor {\n         let top = self.stack.last().map(|(t, _)| t).unwrap_or(&self.ts);\n-\n-        if backward && pos < offset {\n-            let (_, last_idx) = self.stack.pop().unwrap();\n-            return self.walk_token(last_idx, offset, backward);\n-        }\n-\n-        let pos = if backward { pos - offset } else { pos + offset };\n+        let pos = pos + 1;\n \n         match top.get(pos) {\n             DelimToken::Token(token) => match token {\n                 tt::TokenTree::Subtree(subtree) => {\n                     let ts = TokenSeq::from(subtree);\n-                    let new_idx = if backward { ts.len() - 1 } else { 0 };\n                     self.stack.push((ts, pos));\n-                    WalkCursor::Token(new_idx, convert_delim(subtree.delimiter, backward))\n-                }\n-                tt::TokenTree::Leaf(leaf) => {\n-                    let next_tokens = top.child_slice(pos);\n-                    WalkCursor::Token(pos, convert_leaf(&next_tokens, leaf))\n+                    WalkCursor::Token(0, convert_delim(subtree.delimiter, false))\n                 }\n+                tt::TokenTree::Leaf(leaf) => WalkCursor::Token(pos, convert_leaf(leaf)),\n             },\n             DelimToken::Delim(delim, is_end) => {\n                 WalkCursor::Token(pos, convert_delim(*delim, is_end))\n             }\n             DelimToken::End => {\n                 // it is the top level\n                 if let Some((_, last_idx)) = self.stack.pop() {\n-                    assert!(!backward);\n-                    self.walk_token(last_idx, offset, backward)\n+                    self.walk_token(last_idx)\n                 } else {\n                     WalkCursor::Eof\n                 }\n@@ -237,25 +179,21 @@ impl<'a> WalkerOwner<'a> {\n         }\n \n         while pos >= cached.len() {\n-            let len = cached.len();\n-            cached.push({\n-                self.set_pos(len);\n-                let walker = self.walker.borrow();\n-                walker.current().cloned()\n-            });\n+            self.set_pos(cached.len());\n+            let walker = self.walker.borrow();\n+            cached.push(walker.current().cloned());\n         }\n \n         return cached[pos].clone();\n     }\n \n     fn set_pos(&self, pos: usize) {\n         let mut walker = self.walker.borrow_mut();\n+        assert!(walker.pos <= pos);\n+\n         while pos > walker.pos && !walker.is_eof() {\n             walker.forward();\n         }\n-        while pos < walker.pos {\n-            walker.backward();\n-        }\n     }\n \n     fn collect_token_trees(&mut self, n: usize) -> Vec<&tt::TokenTree> {\n@@ -264,15 +202,16 @@ impl<'a> WalkerOwner<'a> {\n         walker.reset();\n \n         while walker.pos < n {\n-            if let WalkCursor::Token(u, tt) = &walker.cursor {\n+            if let WalkCursor::Token(u, _) = &walker.cursor {\n                 // We only collect the topmost child\n                 if walker.stack.len() == 0 {\n-                    for i in 0..tt.n_tokens {\n-                        if let DelimToken::Token(token) = walker.ts.get(u + i) {\n-                            res.push(token);\n-                        }\n+                    if let DelimToken::Token(token) = walker.ts.get(*u) {\n+                        res.push(token);\n                     }\n-                } else if walker.stack.len() == 1 {\n+                }\n+                // Check whether the second level is a subtree\n+                // if so, collect its parent which is topmost child\n+                else if walker.stack.len() == 1 {\n                     if let DelimToken::Delim(_, is_end) = walker.top().get(*u) {\n                         if !is_end {\n                             let (_, last_idx) = &walker.stack[0];\n@@ -343,78 +282,6 @@ impl<'a> TokenSource for SubtreeTokenSource<'a> {\n     }\n }\n \n-pub(crate) struct TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    iter: itertools::MultiPeek<I>,\n-}\n-\n-// helper function\n-fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n-    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n-        return Some(pp);\n-    }\n-    None\n-}\n-\n-impl<'a, I> TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    pub fn new(iter: I) -> Self {\n-        TokenPeek { iter: itertools::multipeek(iter) }\n-    }\n-\n-    pub fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n-        if p.spacing != tt::Spacing::Joint {\n-            return None;\n-        }\n-\n-        self.iter.reset_peek();\n-        let p1 = to_punct(self.iter.peek()?)?;\n-        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n-    }\n-\n-    pub fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n-        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n-            if !last_joint {\n-                None\n-            } else {\n-                let p2 = to_punct(*self.iter.peek()?)?;\n-                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n-            }\n-        })\n-    }\n-}\n-\n-// FIXME: Remove this function\n-fn convert_multi_char_punct<'b, I>(\n-    p: &tt::Punct,\n-    iter: &mut TokenPeek<'b, I>,\n-) -> Option<(SyntaxKind, bool, &'static str, usize)>\n-where\n-    I: Iterator<Item = &'b tt::TokenTree>,\n-{\n-    if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n-        if let Some((kind, text)) = match m {\n-            _ => None,\n-        } {\n-            return Some((kind, is_joint_to_next, text, 3));\n-        }\n-    }\n-\n-    if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n-        if let Some((kind, text)) = match m {\n-            _ => None,\n-        } {\n-            return Some((kind, is_joint_to_next, text, 2));\n-        }\n-    }\n-\n-    None\n-}\n-\n fn convert_delim(d: tt::Delimiter, closing: bool) -> TtToken {\n     let (kinds, texts) = match d {\n         tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n@@ -426,7 +293,7 @@ fn convert_delim(d: tt::Delimiter, closing: bool) -> TtToken {\n     let idx = closing as usize;\n     let kind = kinds[idx];\n     let text = if texts.len() > 0 { &texts[idx..texts.len() - (1 - idx)] } else { \"\" };\n-    TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 }\n+    TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text) }\n }\n \n fn convert_literal(l: &tt::Literal) -> TtToken {\n@@ -437,7 +304,7 @@ fn convert_literal(l: &tt::Literal) -> TtToken {\n             _ => panic!(\"Fail to convert given literal {:#?}\", &l),\n         });\n \n-    TtToken { kind, is_joint_to_next: false, text: l.text.clone(), n_tokens: 1 }\n+    TtToken { kind, is_joint_to_next: false, text: l.text.clone() }\n }\n \n fn convert_ident(ident: &tt::Ident) -> TtToken {\n@@ -447,39 +314,31 @@ fn convert_ident(ident: &tt::Ident) -> TtToken {\n         SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT)\n     };\n \n-    TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n+    TtToken { kind, is_joint_to_next: false, text: ident.text.clone() }\n }\n \n-fn convert_punct(p: &tt::Punct, next_tokens: &[tt::TokenTree]) -> TtToken {\n-    let mut iter = next_tokens.iter();\n-    iter.next();\n-    let mut peek = TokenPeek::new(iter);\n-\n-    if let Some((kind, is_joint_to_next, text, size)) = convert_multi_char_punct(p, &mut peek) {\n-        TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n-    } else {\n-        let kind = match p.char {\n-            // lexer may produce combpund tokens for these ones\n-            '.' => DOT,\n-            ':' => COLON,\n-            '=' => EQ,\n-            '!' => EXCL,\n-            '-' => MINUS,\n-            c => SyntaxKind::from_char(c).unwrap(),\n-        };\n-        let text = {\n-            let mut buf = [0u8; 4];\n-            let s: &str = p.char.encode_utf8(&mut buf);\n-            SmolStr::new(s)\n-        };\n-        TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text, n_tokens: 1 }\n-    }\n+fn convert_punct(p: &tt::Punct) -> TtToken {\n+    let kind = match p.char {\n+        // lexer may produce combpund tokens for these ones\n+        '.' => DOT,\n+        ':' => COLON,\n+        '=' => EQ,\n+        '!' => EXCL,\n+        '-' => MINUS,\n+        c => SyntaxKind::from_char(c).unwrap(),\n+    };\n+    let text = {\n+        let mut buf = [0u8; 4];\n+        let s: &str = p.char.encode_utf8(&mut buf);\n+        SmolStr::new(s)\n+    };\n+    TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n }\n \n-fn convert_leaf(tokens: &[tt::TokenTree], leaf: &tt::Leaf) -> TtToken {\n+fn convert_leaf(leaf: &tt::Leaf) -> TtToken {\n     match leaf {\n         tt::Leaf::Literal(l) => convert_literal(l),\n         tt::Leaf::Ident(ident) => convert_ident(ident),\n-        tt::Leaf::Punct(punct) => convert_punct(punct, tokens),\n+        tt::Leaf::Punct(punct) => convert_punct(punct),\n     }\n }"}]}