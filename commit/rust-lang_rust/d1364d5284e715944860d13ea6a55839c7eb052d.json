{"sha": "d1364d5284e715944860d13ea6a55839c7eb052d", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQxMzY0ZDUyODRlNzE1OTQ0ODYwZDEzZWE2YTU1ODM5YzdlYjA1MmQ=", "commit": {"author": {"name": "Esteban K\u00fcber", "email": "esteban@kuber.com.ar", "date": "2019-05-23T19:55:26Z"}, "committer": {"name": "Esteban K\u00fcber", "email": "esteban@kuber.com.ar", "date": "2019-05-25T19:11:41Z"}, "message": "Move some methods to `diagnostics.rs` away from `parser.rs`\n\nMove a bunch of error recovery methods to `diagnostics.rs` away from\n`parser.rs`.", "tree": {"sha": "3d3da33c03cd2ffeee11dfdda19a246a605256d8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3d3da33c03cd2ffeee11dfdda19a246a605256d8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d1364d5284e715944860d13ea6a55839c7eb052d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d1364d5284e715944860d13ea6a55839c7eb052d", "html_url": "https://github.com/rust-lang/rust/commit/d1364d5284e715944860d13ea6a55839c7eb052d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d1364d5284e715944860d13ea6a55839c7eb052d/comments", "author": {"login": "estebank", "id": 1606434, "node_id": "MDQ6VXNlcjE2MDY0MzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1606434?v=4", "gravatar_id": "", "url": "https://api.github.com/users/estebank", "html_url": "https://github.com/estebank", "followers_url": "https://api.github.com/users/estebank/followers", "following_url": "https://api.github.com/users/estebank/following{/other_user}", "gists_url": "https://api.github.com/users/estebank/gists{/gist_id}", "starred_url": "https://api.github.com/users/estebank/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/estebank/subscriptions", "organizations_url": "https://api.github.com/users/estebank/orgs", "repos_url": "https://api.github.com/users/estebank/repos", "events_url": "https://api.github.com/users/estebank/events{/privacy}", "received_events_url": "https://api.github.com/users/estebank/received_events", "type": "User", "site_admin": false}, "committer": {"login": "estebank", "id": 1606434, "node_id": "MDQ6VXNlcjE2MDY0MzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1606434?v=4", "gravatar_id": "", "url": "https://api.github.com/users/estebank", "html_url": "https://github.com/estebank", "followers_url": "https://api.github.com/users/estebank/followers", "following_url": "https://api.github.com/users/estebank/following{/other_user}", "gists_url": "https://api.github.com/users/estebank/gists{/gist_id}", "starred_url": "https://api.github.com/users/estebank/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/estebank/subscriptions", "organizations_url": "https://api.github.com/users/estebank/orgs", "repos_url": "https://api.github.com/users/estebank/repos", "events_url": "https://api.github.com/users/estebank/events{/privacy}", "received_events_url": "https://api.github.com/users/estebank/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "976541884f674127c33e08aaaf15c99b735701f7", "url": "https://api.github.com/repos/rust-lang/rust/commits/976541884f674127c33e08aaaf15c99b735701f7", "html_url": "https://github.com/rust-lang/rust/commit/976541884f674127c33e08aaaf15c99b735701f7"}], "stats": {"total": 875, "additions": 462, "deletions": 413}, "files": [{"sha": "7df9b80c3c521e047b12440dc624014b2a04c45e", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 429, "deletions": 7, "changes": 436, "blob_url": "https://github.com/rust-lang/rust/blob/d1364d5284e715944860d13ea6a55839c7eb052d/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1364d5284e715944860d13ea6a55839c7eb052d/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=d1364d5284e715944860d13ea6a55839c7eb052d", "patch": "@@ -1,19 +1,104 @@\n use crate::ast;\n use crate::ast::{\n-    BlockCheckMode, Expr, ExprKind, Item, ItemKind, Pat, PatKind, QSelf, Ty, TyKind, VariantData,\n+    BlockCheckMode, BinOpKind, Expr, ExprKind, Item, ItemKind, Pat, PatKind, PathSegment, QSelf,\n+    Ty, TyKind, VariantData,\n };\n-use crate::parse::parser::{BlockMode, PathStyle, SemiColonMode, TokenType};\n+use crate::parse::{SeqSep, token, PResult, Parser};\n+use crate::parse::parser::{BlockMode, PathStyle, SemiColonMode, TokenType, TokenExpectType};\n use crate::parse::token;\n-use crate::parse::PResult;\n-use crate::parse::Parser;\n use crate::print::pprust;\n use crate::ptr::P;\n use crate::source_map::Spanned;\n use crate::symbol::kw;\n use crate::ThinVec;\n-use errors::{Applicability, DiagnosticBuilder};\n-use log::debug;\n-use syntax_pos::{Span, DUMMY_SP};\n+use crate::tokenstream::TokenTree;\n+use crate::util::parser::AssocOp;\n+use errors::{Applicability, DiagnosticBuilder, DiagnosticId, FatalError};\n+use syntax_pos::{Span, DUMMY_SP, MultiSpan};\n+use log::{debug, trace};\n+use std::slice;\n+\n+pub enum Error {\n+    FileNotFoundForModule {\n+        mod_name: String,\n+        default_path: String,\n+        secondary_path: String,\n+        dir_path: String,\n+    },\n+    DuplicatePaths {\n+        mod_name: String,\n+        default_path: String,\n+        secondary_path: String,\n+    },\n+    UselessDocComment,\n+    InclusiveRangeWithNoEnd,\n+}\n+\n+impl Error {\n+    fn span_err<S: Into<MultiSpan>>(\n+        self,\n+        sp: S,\n+        handler: &errors::Handler,\n+    ) -> DiagnosticBuilder<'_> {\n+        match self {\n+            Error::FileNotFoundForModule {\n+                ref mod_name,\n+                ref default_path,\n+                ref secondary_path,\n+                ref dir_path,\n+            } => {\n+                let mut err = struct_span_err!(\n+                    handler,\n+                    sp,\n+                    E0583,\n+                    \"file not found for module `{}`\",\n+                    mod_name,\n+                );\n+                err.help(&format!(\n+                    \"name the file either {} or {} inside the directory \\\"{}\\\"\",\n+                    default_path,\n+                    secondary_path,\n+                    dir_path,\n+                ));\n+                err\n+            }\n+            Error::DuplicatePaths { ref mod_name, ref default_path, ref secondary_path } => {\n+                let mut err = struct_span_err!(\n+                    handler,\n+                    sp,\n+                    E0584,\n+                    \"file for module `{}` found at both {} and {}\",\n+                    mod_name,\n+                    default_path,\n+                    secondary_path,\n+                );\n+                err.help(\"delete or rename one of them to remove the ambiguity\");\n+                err\n+            }\n+            Error::UselessDocComment => {\n+                let mut err = struct_span_err!(\n+                    handler,\n+                    sp,\n+                    E0585,\n+                    \"found a documentation comment that doesn't document anything\",\n+                );\n+                err.help(\"doc comments must come before what they document, maybe a comment was \\\n+                          intended with `//`?\");\n+                err\n+            }\n+            Error::InclusiveRangeWithNoEnd => {\n+                let mut err = struct_span_err!(\n+                    handler,\n+                    sp,\n+                    E0586,\n+                    \"inclusive range with no end\",\n+                );\n+                err.help(\"inclusive ranges must be bounded at the end (`..=b` or `a..=b`)\");\n+                err\n+            }\n+        }\n+    }\n+}\n \n pub trait RecoverQPath: Sized + 'static {\n     const PATH_STYLE: PathStyle = PathStyle::Expr;\n@@ -63,6 +148,253 @@ impl RecoverQPath for Expr {\n }\n \n impl<'a> Parser<'a> {\n+    pub fn look_ahead<R, F>(&self, dist: usize, f: F) -> R where\n+        F: FnOnce(&token::Token) -> R,\n+    {\n+        if dist == 0 {\n+            return f(&self.token)\n+        }\n+\n+        f(&match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n+            Some(tree) => match tree {\n+                TokenTree::Token(_, tok) => tok,\n+                TokenTree::Delimited(_, delim, _) => token::OpenDelim(delim),\n+            },\n+            None => token::CloseDelim(self.token_cursor.frame.delim),\n+        })\n+    }\n+\n+    crate fn look_ahead_span(&self, dist: usize) -> Span {\n+        if dist == 0 {\n+            return self.span\n+        }\n+\n+        match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n+            Some(TokenTree::Token(span, _)) => span,\n+            Some(TokenTree::Delimited(span, ..)) => span.entire(),\n+            None => self.look_ahead_span(dist - 1),\n+        }\n+    }\n+\n+    pub fn fatal(&self, m: &str) -> DiagnosticBuilder<'a> {\n+        self.sess.span_diagnostic.struct_span_fatal(self.span, m)\n+    }\n+\n+    pub fn span_fatal<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n+        self.sess.span_diagnostic.struct_span_fatal(sp, m)\n+    }\n+\n+    pub fn span_fatal_err<S: Into<MultiSpan>>(&self, sp: S, err: Error) -> DiagnosticBuilder<'a> {\n+        err.span_err(sp, self.diagnostic())\n+    }\n+\n+    pub fn bug(&self, m: &str) -> ! {\n+        self.sess.span_diagnostic.span_bug(self.span, m)\n+    }\n+\n+    pub fn span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) {\n+        self.sess.span_diagnostic.span_err(sp, m)\n+    }\n+\n+    crate fn struct_span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n+        self.sess.span_diagnostic.struct_span_err(sp, m)\n+    }\n+\n+    crate fn span_bug<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> ! {\n+        self.sess.span_diagnostic.span_bug(sp, m)\n+    }\n+\n+    crate fn cancel(&self, err: &mut DiagnosticBuilder<'_>) {\n+        self.sess.span_diagnostic.cancel(err)\n+    }\n+\n+    crate fn diagnostic(&self) -> &'a errors::Handler {\n+        &self.sess.span_diagnostic\n+    }\n+\n+    crate fn expected_ident_found(&self) -> DiagnosticBuilder<'a> {\n+        let mut err = self.struct_span_err(\n+            self.span,\n+            &format!(\"expected identifier, found {}\", self.this_token_descr()),\n+        );\n+        if let token::Ident(ident, false) = &self.token {\n+            if ident.is_raw_guess() {\n+                err.span_suggestion(\n+                    self.span,\n+                    \"you can escape reserved keywords to use them as identifiers\",\n+                    format!(\"r#{}\", ident),\n+                    Applicability::MaybeIncorrect,\n+                );\n+            }\n+        }\n+        if let Some(token_descr) = self.token_descr() {\n+            err.span_label(self.span, format!(\"expected identifier, found {}\", token_descr));\n+        } else {\n+            err.span_label(self.span, \"expected identifier\");\n+            if self.token == token::Comma && self.look_ahead(1, |t| t.is_ident()) {\n+                err.span_suggestion(\n+                    self.span,\n+                    \"remove this comma\",\n+                    String::new(),\n+                    Applicability::MachineApplicable,\n+                );\n+            }\n+        }\n+        err\n+    }\n+\n+    /// Eats and discards tokens until one of `kets` is encountered. Respects token trees,\n+    /// passes through any errors encountered. Used for error recovery.\n+    crate fn eat_to_tokens(&mut self, kets: &[&token::Token]) {\n+        let handler = self.diagnostic();\n+\n+        if let Err(ref mut err) = self.parse_seq_to_before_tokens(\n+            kets,\n+            SeqSep::none(),\n+            TokenExpectType::Expect,\n+            |p| Ok(p.parse_token_tree()),\n+        ) {\n+            handler.cancel(err);\n+        }\n+    }\n+\n+    /// This function checks if there are trailing angle brackets and produces\n+    /// a diagnostic to suggest removing them.\n+    ///\n+    /// ```ignore (diagnostic)\n+    /// let _ = vec![1, 2, 3].into_iter().collect::<Vec<usize>>>>();\n+    ///                                                        ^^ help: remove extra angle brackets\n+    /// ```\n+    crate fn check_trailing_angle_brackets(&mut self, segment: &PathSegment, end: token::Token) {\n+        // This function is intended to be invoked after parsing a path segment where there are two\n+        // cases:\n+        //\n+        // 1. A specific token is expected after the path segment.\n+        //    eg. `x.foo(`, `x.foo::<u32>(` (parenthesis - method call),\n+        //        `Foo::`, or `Foo::<Bar>::` (mod sep - continued path).\n+        // 2. No specific token is expected after the path segment.\n+        //    eg. `x.foo` (field access)\n+        //\n+        // This function is called after parsing `.foo` and before parsing the token `end` (if\n+        // present). This includes any angle bracket arguments, such as `.foo::<u32>` or\n+        // `Foo::<Bar>`.\n+\n+        // We only care about trailing angle brackets if we previously parsed angle bracket\n+        // arguments. This helps stop us incorrectly suggesting that extra angle brackets be\n+        // removed in this case:\n+        //\n+        // `x.foo >> (3)` (where `x.foo` is a `u32` for example)\n+        //\n+        // This case is particularly tricky as we won't notice it just looking at the tokens -\n+        // it will appear the same (in terms of upcoming tokens) as below (since the `::<u32>` will\n+        // have already been parsed):\n+        //\n+        // `x.foo::<u32>>>(3)`\n+        let parsed_angle_bracket_args = segment.args\n+            .as_ref()\n+            .map(|args| args.is_angle_bracketed())\n+            .unwrap_or(false);\n+\n+        debug!(\n+            \"check_trailing_angle_brackets: parsed_angle_bracket_args={:?}\",\n+            parsed_angle_bracket_args,\n+        );\n+        if !parsed_angle_bracket_args {\n+            return;\n+        }\n+\n+        // Keep the span at the start so we can highlight the sequence of `>` characters to be\n+        // removed.\n+        let lo = self.span;\n+\n+        // We need to look-ahead to see if we have `>` characters without moving the cursor forward\n+        // (since we might have the field access case and the characters we're eating are\n+        // actual operators and not trailing characters - ie `x.foo >> 3`).\n+        let mut position = 0;\n+\n+        // We can encounter `>` or `>>` tokens in any order, so we need to keep track of how\n+        // many of each (so we can correctly pluralize our error messages) and continue to\n+        // advance.\n+        let mut number_of_shr = 0;\n+        let mut number_of_gt = 0;\n+        while self.look_ahead(position, |t| {\n+            trace!(\"check_trailing_angle_brackets: t={:?}\", t);\n+            if *t == token::BinOp(token::BinOpToken::Shr) {\n+                number_of_shr += 1;\n+                true\n+            } else if *t == token::Gt {\n+                number_of_gt += 1;\n+                true\n+            } else {\n+                false\n+            }\n+        }) {\n+            position += 1;\n+        }\n+\n+        // If we didn't find any trailing `>` characters, then we have nothing to error about.\n+        debug!(\n+            \"check_trailing_angle_brackets: number_of_gt={:?} number_of_shr={:?}\",\n+            number_of_gt, number_of_shr,\n+        );\n+        if number_of_gt < 1 && number_of_shr < 1 {\n+            return;\n+        }\n+\n+        // Finally, double check that we have our end token as otherwise this is the\n+        // second case.\n+        if self.look_ahead(position, |t| {\n+            trace!(\"check_trailing_angle_brackets: t={:?}\", t);\n+            *t == end\n+        }) {\n+            // Eat from where we started until the end token so that parsing can continue\n+            // as if we didn't have those extra angle brackets.\n+            self.eat_to_tokens(&[&end]);\n+            let span = lo.until(self.span);\n+\n+            let plural = number_of_gt > 1 || number_of_shr >= 1;\n+            self.diagnostic()\n+                .struct_span_err(\n+                    span,\n+                    &format!(\"unmatched angle bracket{}\", if plural { \"s\" } else { \"\" }),\n+                )\n+                .span_suggestion(\n+                    span,\n+                    &format!(\"remove extra angle bracket{}\", if plural { \"s\" } else { \"\" }),\n+                    String::new(),\n+                    Applicability::MachineApplicable,\n+                )\n+                .emit();\n+        }\n+    }\n+\n+    /// Produce an error if comparison operators are chained (RFC #558).\n+    /// We only need to check lhs, not rhs, because all comparison ops\n+    /// have same precedence and are left-associative\n+    crate fn check_no_chained_comparison(&self, lhs: &Expr, outer_op: &AssocOp) {\n+        debug_assert!(outer_op.is_comparison(),\n+                      \"check_no_chained_comparison: {:?} is not comparison\",\n+                      outer_op);\n+        match lhs.node {\n+            ExprKind::Binary(op, _, _) if op.node.is_comparison() => {\n+                // respan to include both operators\n+                let op_span = op.span.to(self.span);\n+                let mut err = self.diagnostic().struct_span_err(op_span,\n+                    \"chained comparison operators require parentheses\");\n+                if op.node == BinOpKind::Lt &&\n+                    *outer_op == AssocOp::Less ||  // Include `<` to provide this recommendation\n+                    *outer_op == AssocOp::Greater  // even in a case like the following:\n+                {                                  //     Foo<Bar<Baz<Qux, ()>>>\n+                    err.help(\n+                        \"use `::<...>` instead of `<...>` if you meant to specify type arguments\");\n+                    err.help(\"or use `(...)` if you meant to specify fn arguments\");\n+                }\n+                err.emit();\n+            }\n+            _ => {}\n+        }\n+    }\n+\n     crate fn maybe_report_ambiguous_plus(\n         &mut self,\n         allow_plus: bool,\n@@ -594,6 +926,96 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n+    crate fn check_for_for_in_in_typo(&mut self, in_span: Span) {\n+        if self.eat_keyword(kw::In) {\n+            // a common typo: `for _ in in bar {}`\n+            let mut err = self.sess.span_diagnostic.struct_span_err(\n+                self.prev_span,\n+                \"expected iterable, found keyword `in`\",\n+            );\n+            err.span_suggestion_short(\n+                in_span.until(self.prev_span),\n+                \"remove the duplicated `in`\",\n+                String::new(),\n+                Applicability::MachineApplicable,\n+            );\n+            err.note(\"if you meant to use emplacement syntax, it is obsolete (for now, anyway)\");\n+            err.note(\"for more information on the status of emplacement syntax, see <\\\n+                      https://github.com/rust-lang/rust/issues/27779#issuecomment-378416911>\");\n+            err.emit();\n+        }\n+    }\n+\n+    crate fn expected_semi_or_open_brace(&mut self) -> PResult<'a, ast::TraitItem> {\n+        let token_str = self.this_token_descr();\n+        let mut err = self.fatal(&format!(\"expected `;` or `{{`, found {}\", token_str));\n+        err.span_label(self.span, \"expected `;` or `{`\");\n+        Err(err)\n+    }\n+\n+    crate fn eat_incorrect_doc_comment(&mut self, applied_to: &str) {\n+        if let token::DocComment(_) = self.token {\n+            let mut err = self.diagnostic().struct_span_err(\n+                self.span,\n+                &format!(\"documentation comments cannot be applied to {}\", applied_to),\n+            );\n+            err.span_label(self.span, \"doc comments are not allowed here\");\n+            err.emit();\n+            self.bump();\n+        } else if self.token == token::Pound && self.look_ahead(1, |t| {\n+            *t == token::OpenDelim(token::Bracket)\n+        }) {\n+            let lo = self.span;\n+            // Skip every token until next possible arg.\n+            while self.token != token::CloseDelim(token::Bracket) {\n+                self.bump();\n+            }\n+            let sp = lo.to(self.span);\n+            self.bump();\n+            let mut err = self.diagnostic().struct_span_err(\n+                sp,\n+                &format!(\"attributes cannot be applied to {}\", applied_to),\n+            );\n+            err.span_label(sp, \"attributes are not allowed here\");\n+            err.emit();\n+        }\n+    }\n+\n+    crate fn argument_without_type(\n+        &mut self,\n+        err: &mut DiagnosticBuilder<'_>,\n+        pat: P<ast::Pat>,\n+        require_name: bool,\n+        is_trait_item: bool,\n+    ) {\n+        // If we find a pattern followed by an identifier, it could be an (incorrect)\n+        // C-style parameter declaration.\n+        if self.check_ident() && self.look_ahead(1, |t| {\n+            *t == token::Comma || *t == token::CloseDelim(token::Paren)\n+        }) {\n+            let ident = self.parse_ident().unwrap();\n+            let span = pat.span.with_hi(ident.span.hi());\n+\n+            err.span_suggestion(\n+                span,\n+                \"declare the type after the parameter binding\",\n+                String::from(\"<identifier>: <type>\"),\n+                Applicability::HasPlaceholders,\n+            );\n+        } else if require_name && is_trait_item {\n+            if let PatKind::Ident(_, ident, _) = pat.node {\n+                err.span_suggestion(\n+                    pat.span,\n+                    \"explicitly ignore parameter\",\n+                    format!(\"_: {}\", ident),\n+                    Applicability::MachineApplicable,\n+                );\n+            }\n+\n+            err.note(\"anonymous parameters are removed in the 2018 edition (see RFC 1685)\");\n+        }\n+    }\n+\n     crate fn recover_arg_parse(&mut self) -> PResult<'a, (P<ast::Pat>, P<ast::Ty>)> {\n         let pat = self.parse_pat(Some(\"argument name\"))?;\n         self.expect(&token::Colon)?;"}, {"sha": "6d866d7f3d43ffc2085784c5fa6eda871fbed3b3", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 33, "deletions": 406, "changes": 439, "blob_url": "https://github.com/rust-lang/rust/blob/d1364d5284e715944860d13ea6a55839c7eb052d/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1364d5284e715944860d13ea6a55839c7eb052d/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=d1364d5284e715944860d13ea6a55839c7eb052d", "patch": "@@ -47,20 +47,17 @@ use crate::parse::PResult;\n use crate::ThinVec;\n use crate::tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n use crate::symbol::{kw, sym, Symbol};\n+use crate::parse::diagnostics::Error;\n \n-use errors::{Applicability, DiagnosticBuilder, DiagnosticId, FatalError};\n+use errors::{Applicability, DiagnosticBuilder, DiagnosticId};\n use rustc_target::spec::abi::{self, Abi};\n-use syntax_pos::{\n-    BytePos, DUMMY_SP, FileName, MultiSpan, Span,\n-    hygiene::CompilerDesugaringKind,\n-};\n-use log::{debug, trace};\n+use syntax_pos::{Span, BytePos, DUMMY_SP, FileName, hygiene::CompilerDesugaringKind};\n+use log::debug;\n \n use std::borrow::Cow;\n use std::cmp;\n use std::mem;\n use std::path::{self, Path, PathBuf};\n-use std::slice;\n \n #[derive(Debug)]\n /// Whether the type alias or associated type is a concrete type or an existential type\n@@ -217,7 +214,7 @@ pub struct Parser<'a> {\n     /// into modules, and sub-parsers have new values for this name.\n     pub root_module_name: Option<String>,\n     crate expected_tokens: Vec<TokenType>,\n-    token_cursor: TokenCursor,\n+    crate token_cursor: TokenCursor,\n     desugar_doc_comments: bool,\n     /// Whether we should configure out of line modules as we parse.\n     pub cfg_mods: bool,\n@@ -232,7 +229,7 @@ pub struct Parser<'a> {\n     /// it gets removed from here. Every entry left at the end gets emitted as an independent\n     /// error.\n     crate unclosed_delims: Vec<UnmatchedBrace>,\n-    last_unexpected_token_span: Option<Span>,\n+    crate last_unexpected_token_span: Option<Span>,\n     /// If present, this `Parser` is not parsing Rust code but rather a macro call.\n     crate subparser_name: Option<&'static str>,\n }\n@@ -245,19 +242,19 @@ impl<'a> Drop for Parser<'a> {\n }\n \n #[derive(Clone)]\n-struct TokenCursor {\n-    frame: TokenCursorFrame,\n-    stack: Vec<TokenCursorFrame>,\n+crate struct TokenCursor {\n+    crate frame: TokenCursorFrame,\n+    crate stack: Vec<TokenCursorFrame>,\n }\n \n #[derive(Clone)]\n-struct TokenCursorFrame {\n-    delim: token::DelimToken,\n-    span: DelimSpan,\n-    open_delim: bool,\n-    tree_cursor: tokenstream::Cursor,\n-    close_delim: bool,\n-    last_token: LastToken,\n+crate struct TokenCursorFrame {\n+    crate delim: token::DelimToken,\n+    crate span: DelimSpan,\n+    crate open_delim: bool,\n+    crate tree_cursor: tokenstream::Cursor,\n+    crate close_delim: bool,\n+    crate last_token: LastToken,\n }\n \n /// This is used in `TokenCursorFrame` above to track tokens that are consumed\n@@ -278,7 +275,7 @@ struct TokenCursorFrame {\n /// You can find some more example usage of this in the `collect_tokens` method\n /// on the parser.\n #[derive(Clone)]\n-enum LastToken {\n+crate enum LastToken {\n     Collecting(Vec<TreeAndJoint>),\n     Was(Option<TreeAndJoint>),\n }\n@@ -430,65 +427,6 @@ pub struct ModulePathSuccess {\n     warn: bool,\n }\n \n-pub enum Error {\n-    FileNotFoundForModule {\n-        mod_name: String,\n-        default_path: String,\n-        secondary_path: String,\n-        dir_path: String,\n-    },\n-    DuplicatePaths {\n-        mod_name: String,\n-        default_path: String,\n-        secondary_path: String,\n-    },\n-    UselessDocComment,\n-    InclusiveRangeWithNoEnd,\n-}\n-\n-impl Error {\n-    fn span_err<S: Into<MultiSpan>>(self,\n-                                        sp: S,\n-                                        handler: &errors::Handler) -> DiagnosticBuilder<'_> {\n-        match self {\n-            Error::FileNotFoundForModule { ref mod_name,\n-                                           ref default_path,\n-                                           ref secondary_path,\n-                                           ref dir_path } => {\n-                let mut err = struct_span_err!(handler, sp, E0583,\n-                                               \"file not found for module `{}`\", mod_name);\n-                err.help(&format!(\"name the file either {} or {} inside the directory \\\"{}\\\"\",\n-                                  default_path,\n-                                  secondary_path,\n-                                  dir_path));\n-                err\n-            }\n-            Error::DuplicatePaths { ref mod_name, ref default_path, ref secondary_path } => {\n-                let mut err = struct_span_err!(handler, sp, E0584,\n-                                               \"file for module `{}` found at both {} and {}\",\n-                                               mod_name,\n-                                               default_path,\n-                                               secondary_path);\n-                err.help(\"delete or rename one of them to remove the ambiguity\");\n-                err\n-            }\n-            Error::UselessDocComment => {\n-                let mut err = struct_span_err!(handler, sp, E0585,\n-                                  \"found a documentation comment that doesn't document anything\");\n-                err.help(\"doc comments must come before what they document, maybe a comment was \\\n-                          intended with `//`?\");\n-                err\n-            }\n-            Error::InclusiveRangeWithNoEnd => {\n-                let mut err = struct_span_err!(handler, sp, E0586,\n-                                               \"inclusive range with no end\");\n-                err.help(\"inclusive ranges must be bounded at the end (`..=b` or `a..=b`)\");\n-                err\n-            }\n-        }\n-    }\n-}\n-\n #[derive(Debug)]\n enum LhsExpr {\n     NotYetParsed,\n@@ -529,7 +467,7 @@ fn dummy_arg(span: Span) -> Arg {\n }\n \n #[derive(Copy, Clone, Debug)]\n-enum TokenExpectType {\n+crate enum TokenExpectType {\n     Expect,\n     NoExpect,\n }\n@@ -610,7 +548,7 @@ impl<'a> Parser<'a> {\n         pprust::token_to_string(&self.token)\n     }\n \n-    fn token_descr(&self) -> Option<&'static str> {\n+    crate fn token_descr(&self) -> Option<&'static str> {\n         Some(match &self.token {\n             t if t.is_special_ident() => \"reserved identifier\",\n             t if t.is_used_keyword() => \"keyword\",\n@@ -801,9 +739,10 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Returns the span of expr, if it was not interpolated or the span of the interpolated token.\n-    fn interpolated_or_expr_span(&self,\n-                                 expr: PResult<'a, P<Expr>>)\n-                                 -> PResult<'a, (Span, P<Expr>)> {\n+    fn interpolated_or_expr_span(\n+        &self,\n+        expr: PResult<'a, P<Expr>>,\n+    ) -> PResult<'a, (Span, P<Expr>)> {\n         expr.map(|e| {\n             if self.prev_token_kind == PrevTokenKind::Interpolated {\n                 (self.prev_span, e)\n@@ -813,36 +752,6 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    fn expected_ident_found(&self) -> DiagnosticBuilder<'a> {\n-        let mut err = self.struct_span_err(self.span,\n-                                           &format!(\"expected identifier, found {}\",\n-                                                    self.this_token_descr()));\n-        if let token::Ident(ident, false) = &self.token {\n-            if ident.is_raw_guess() {\n-                err.span_suggestion(\n-                    self.span,\n-                    \"you can escape reserved keywords to use them as identifiers\",\n-                    format!(\"r#{}\", ident),\n-                    Applicability::MaybeIncorrect,\n-                );\n-            }\n-        }\n-        if let Some(token_descr) = self.token_descr() {\n-            err.span_label(self.span, format!(\"expected identifier, found {}\", token_descr));\n-        } else {\n-            err.span_label(self.span, \"expected identifier\");\n-            if self.token == token::Comma && self.look_ahead(1, |t| t.is_ident()) {\n-                err.span_suggestion(\n-                    self.span,\n-                    \"remove this comma\",\n-                    String::new(),\n-                    Applicability::MachineApplicable,\n-                );\n-            }\n-        }\n-        err\n-    }\n-\n     pub fn parse_ident(&mut self) -> PResult<'a, ast::Ident> {\n         self.parse_ident_common(true)\n     }\n@@ -925,7 +834,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    fn check_ident(&mut self) -> bool {\n+    crate fn check_ident(&mut self) -> bool {\n         if self.token.is_ident() {\n             true\n         } else {\n@@ -1115,19 +1024,6 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Eats and discards tokens until one of `kets` is encountered. Respects token trees,\n-    /// passes through any errors encountered. Used for error recovery.\n-    fn eat_to_tokens(&mut self, kets: &[&token::Token]) {\n-        let handler = self.diagnostic();\n-\n-        if let Err(ref mut err) = self.parse_seq_to_before_tokens(kets,\n-                                                                  SeqSep::none(),\n-                                                                  TokenExpectType::Expect,\n-                                                                  |p| Ok(p.parse_token_tree())) {\n-            handler.cancel(err);\n-        }\n-    }\n-\n     /// Parses a sequence, including the closing delimiter. The function\n     /// `f` must consume tokens until reaching the next separator or\n     /// closing bracket.\n@@ -1159,7 +1055,7 @@ impl<'a> Parser<'a> {\n         self.parse_seq_to_before_tokens(&[ket], sep, TokenExpectType::Expect, f)\n     }\n \n-    fn parse_seq_to_before_tokens<T, F>(\n+    crate fn parse_seq_to_before_tokens<T, F>(\n         &mut self,\n         kets: &[&token::Token],\n         sep: SeqSep,\n@@ -1292,63 +1188,6 @@ impl<'a> Parser<'a> {\n         self.expected_tokens.clear();\n     }\n \n-    pub fn look_ahead<R, F>(&self, dist: usize, f: F) -> R where\n-        F: FnOnce(&token::Token) -> R,\n-    {\n-        if dist == 0 {\n-            return f(&self.token)\n-        }\n-\n-        f(&match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n-            Some(tree) => match tree {\n-                TokenTree::Token(_, tok) => tok,\n-                TokenTree::Delimited(_, delim, _) => token::OpenDelim(delim),\n-            },\n-            None => token::CloseDelim(self.token_cursor.frame.delim),\n-        })\n-    }\n-\n-    crate fn look_ahead_span(&self, dist: usize) -> Span {\n-        if dist == 0 {\n-            return self.span\n-        }\n-\n-        match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n-            Some(TokenTree::Token(span, _)) => span,\n-            Some(TokenTree::Delimited(span, ..)) => span.entire(),\n-            None => self.look_ahead_span(dist - 1),\n-        }\n-    }\n-    pub fn fatal(&self, m: &str) -> DiagnosticBuilder<'a> {\n-        self.sess.span_diagnostic.struct_span_fatal(self.span, m)\n-    }\n-    pub fn span_fatal<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n-        self.sess.span_diagnostic.struct_span_fatal(sp, m)\n-    }\n-    fn span_fatal_err<S: Into<MultiSpan>>(&self, sp: S, err: Error) -> DiagnosticBuilder<'a> {\n-        err.span_err(sp, self.diagnostic())\n-    }\n-    fn bug(&self, m: &str) -> ! {\n-        self.sess.span_diagnostic.span_bug(self.span, m)\n-    }\n-    fn span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) {\n-        self.sess.span_diagnostic.span_err(sp, m)\n-    }\n-    crate fn struct_span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n-        self.sess.span_diagnostic.struct_span_err(sp, m)\n-    }\n-    crate fn span_bug<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> ! {\n-        self.sess.span_diagnostic.span_bug(sp, m)\n-    }\n-\n-    fn cancel(&self, err: &mut DiagnosticBuilder<'_>) {\n-        self.sess.span_diagnostic.cancel(err)\n-    }\n-\n-    crate fn diagnostic(&self) -> &'a errors::Handler {\n-        &self.sess.span_diagnostic\n-    }\n-\n     /// Is the current token one of the keywords that signals a bare function type?\n     fn token_is_bare_fn_keyword(&mut self) -> bool {\n         self.check_keyword(kw::Fn) ||\n@@ -1507,20 +1346,12 @@ impl<'a> Parser<'a> {\n                             Some(body)\n                         }\n                         _ => {\n-                            let token_str = self.this_token_descr();\n-                            let mut err = self.fatal(&format!(\"expected `;` or `{{`, found {}\",\n-                                                              token_str));\n-                            err.span_label(self.span, \"expected `;` or `{`\");\n-                            return Err(err);\n+                            return self.expected_semi_or_open_brace();\n                         }\n                     }\n                 }\n                 _ => {\n-                    let token_str = self.this_token_descr();\n-                    let mut err = self.fatal(&format!(\"expected `;` or `{{`, found {}\",\n-                                                      token_str));\n-                    err.span_label(self.span, \"expected `;` or `{`\");\n-                    return Err(err);\n+                    return self.expected_semi_or_open_brace();\n                 }\n             };\n             (ident, ast::TraitItemKind::Method(sig, body), generics)\n@@ -1776,34 +1607,6 @@ impl<'a> Parser<'a> {\n \n     /// Skips unexpected attributes and doc comments in this position and emits an appropriate\n     /// error.\n-    fn eat_incorrect_doc_comment(&mut self, applied_to: &str) {\n-        if let token::DocComment(_) = self.token {\n-            let mut err = self.diagnostic().struct_span_err(\n-                self.span,\n-                &format!(\"documentation comments cannot be applied to {}\", applied_to),\n-            );\n-            err.span_label(self.span, \"doc comments are not allowed here\");\n-            err.emit();\n-            self.bump();\n-        } else if self.token == token::Pound && self.look_ahead(1, |t| {\n-            *t == token::OpenDelim(token::Bracket)\n-        }) {\n-            let lo = self.span;\n-            // Skip every token until next possible arg.\n-            while self.token != token::CloseDelim(token::Bracket) {\n-                self.bump();\n-            }\n-            let sp = lo.to(self.span);\n-            self.bump();\n-            let mut err = self.diagnostic().struct_span_err(\n-                sp,\n-                &format!(\"attributes cannot be applied to {}\", applied_to),\n-            );\n-            err.span_label(sp, \"attributes are not allowed here\");\n-            err.emit();\n-        }\n-    }\n-\n     /// This version of parse arg doesn't necessarily require identifier names.\n     fn parse_arg_general(\n         &mut self,\n@@ -1858,42 +1661,14 @@ impl<'a> Parser<'a> {\n                     // Recover from attempting to parse the argument as a type without pattern.\n                     err.cancel();\n                     mem::replace(self, parser_snapshot_before_ty);\n-                    let pat = self.parse_pat(Some(\"argument name\"))?;\n-                    self.expect(&token::Colon)?;\n-                    let ty = self.parse_ty()?;\n-\n-                    let mut err = self.diagnostic().struct_span_err_with_code(\n-                        pat.span,\n-                        \"patterns aren't allowed in methods without bodies\",\n-                        DiagnosticId::Error(\"E0642\".into()),\n-                    );\n-                    err.span_suggestion_short(\n-                        pat.span,\n-                        \"give this argument a name or use an underscore to ignore it\",\n-                        \"_\".to_owned(),\n-                        Applicability::MachineApplicable,\n-                    );\n-                    err.emit();\n-\n-                    // Pretend the pattern is `_`, to avoid duplicate errors from AST validation.\n-                    let pat = P(Pat {\n-                        node: PatKind::Wild,\n-                        span: pat.span,\n-                        id: ast::DUMMY_NODE_ID\n-                    });\n-                    (pat, ty)\n+                    self.recover_arg_parse()?\n                 }\n             }\n         };\n \n         Ok(Arg { ty, pat, id: ast::DUMMY_NODE_ID, source: ast::ArgSource::Normal })\n     }\n \n-    /// Parses a single function argument.\n-    crate fn parse_arg(&mut self) -> PResult<'a, Arg> {\n-        self.parse_arg_general(true, false, false)\n-    }\n-\n     /// Parses an argument in a lambda header (e.g., `|arg, arg|`).\n     fn parse_fn_block_arg(&mut self) -> PResult<'a, Arg> {\n         let pat = self.parse_pat(Some(\"argument name\"))?;\n@@ -2858,116 +2633,6 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// This function checks if there are trailing angle brackets and produces\n-    /// a diagnostic to suggest removing them.\n-    ///\n-    /// ```ignore (diagnostic)\n-    /// let _ = vec![1, 2, 3].into_iter().collect::<Vec<usize>>>>();\n-    ///                                                        ^^ help: remove extra angle brackets\n-    /// ```\n-    fn check_trailing_angle_brackets(&mut self, segment: &PathSegment, end: token::Token) {\n-        // This function is intended to be invoked after parsing a path segment where there are two\n-        // cases:\n-        //\n-        // 1. A specific token is expected after the path segment.\n-        //    eg. `x.foo(`, `x.foo::<u32>(` (parenthesis - method call),\n-        //        `Foo::`, or `Foo::<Bar>::` (mod sep - continued path).\n-        // 2. No specific token is expected after the path segment.\n-        //    eg. `x.foo` (field access)\n-        //\n-        // This function is called after parsing `.foo` and before parsing the token `end` (if\n-        // present). This includes any angle bracket arguments, such as `.foo::<u32>` or\n-        // `Foo::<Bar>`.\n-\n-        // We only care about trailing angle brackets if we previously parsed angle bracket\n-        // arguments. This helps stop us incorrectly suggesting that extra angle brackets be\n-        // removed in this case:\n-        //\n-        // `x.foo >> (3)` (where `x.foo` is a `u32` for example)\n-        //\n-        // This case is particularly tricky as we won't notice it just looking at the tokens -\n-        // it will appear the same (in terms of upcoming tokens) as below (since the `::<u32>` will\n-        // have already been parsed):\n-        //\n-        // `x.foo::<u32>>>(3)`\n-        let parsed_angle_bracket_args = segment.args\n-            .as_ref()\n-            .map(|args| args.is_angle_bracketed())\n-            .unwrap_or(false);\n-\n-        debug!(\n-            \"check_trailing_angle_brackets: parsed_angle_bracket_args={:?}\",\n-            parsed_angle_bracket_args,\n-        );\n-        if !parsed_angle_bracket_args {\n-            return;\n-        }\n-\n-        // Keep the span at the start so we can highlight the sequence of `>` characters to be\n-        // removed.\n-        let lo = self.span;\n-\n-        // We need to look-ahead to see if we have `>` characters without moving the cursor forward\n-        // (since we might have the field access case and the characters we're eating are\n-        // actual operators and not trailing characters - ie `x.foo >> 3`).\n-        let mut position = 0;\n-\n-        // We can encounter `>` or `>>` tokens in any order, so we need to keep track of how\n-        // many of each (so we can correctly pluralize our error messages) and continue to\n-        // advance.\n-        let mut number_of_shr = 0;\n-        let mut number_of_gt = 0;\n-        while self.look_ahead(position, |t| {\n-            trace!(\"check_trailing_angle_brackets: t={:?}\", t);\n-            if *t == token::BinOp(token::BinOpToken::Shr) {\n-                number_of_shr += 1;\n-                true\n-            } else if *t == token::Gt {\n-                number_of_gt += 1;\n-                true\n-            } else {\n-                false\n-            }\n-        }) {\n-            position += 1;\n-        }\n-\n-        // If we didn't find any trailing `>` characters, then we have nothing to error about.\n-        debug!(\n-            \"check_trailing_angle_brackets: number_of_gt={:?} number_of_shr={:?}\",\n-            number_of_gt, number_of_shr,\n-        );\n-        if number_of_gt < 1 && number_of_shr < 1 {\n-            return;\n-        }\n-\n-        // Finally, double check that we have our end token as otherwise this is the\n-        // second case.\n-        if self.look_ahead(position, |t| {\n-            trace!(\"check_trailing_angle_brackets: t={:?}\", t);\n-            *t == end\n-        }) {\n-            // Eat from where we started until the end token so that parsing can continue\n-            // as if we didn't have those extra angle brackets.\n-            self.eat_to_tokens(&[&end]);\n-            let span = lo.until(self.span);\n-\n-            let plural = number_of_gt > 1 || number_of_shr >= 1;\n-            self.diagnostic()\n-                .struct_span_err(\n-                    span,\n-                    &format!(\"unmatched angle bracket{}\", if plural { \"s\" } else { \"\" }),\n-                )\n-                .span_suggestion(\n-                    span,\n-                    &format!(\"remove extra angle bracket{}\", if plural { \"s\" } else { \"\" }),\n-                    String::new(),\n-                    Applicability::MachineApplicable,\n-                )\n-                .emit();\n-        }\n-    }\n-\n     fn parse_dot_or_call_expr_with_(&mut self, e0: P<Expr>, lo: Span) -> PResult<'a, P<Expr>> {\n         let mut e = e0;\n         let mut hi;\n@@ -3529,33 +3194,6 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Produce an error if comparison operators are chained (RFC #558).\n-    /// We only need to check lhs, not rhs, because all comparison ops\n-    /// have same precedence and are left-associative\n-    fn check_no_chained_comparison(&self, lhs: &Expr, outer_op: &AssocOp) {\n-        debug_assert!(outer_op.is_comparison(),\n-                      \"check_no_chained_comparison: {:?} is not comparison\",\n-                      outer_op);\n-        match lhs.node {\n-            ExprKind::Binary(op, _, _) if op.node.is_comparison() => {\n-                // respan to include both operators\n-                let op_span = op.span.to(self.span);\n-                let mut err = self.diagnostic().struct_span_err(op_span,\n-                    \"chained comparison operators require parentheses\");\n-                if op.node == BinOpKind::Lt &&\n-                    *outer_op == AssocOp::Less ||  // Include `<` to provide this recommendation\n-                    *outer_op == AssocOp::Greater  // even in a case like the following:\n-                {                                  //     Foo<Bar<Baz<Qux, ()>>>\n-                    err.help(\n-                        \"use `::<...>` instead of `<...>` if you meant to specify type arguments\");\n-                    err.help(\"or use `(...)` if you meant to specify fn arguments\");\n-                }\n-                err.emit();\n-            }\n-            _ => {}\n-        }\n-    }\n-\n     /// Parse prefix-forms of range notation: `..expr`, `..`, `..=expr`\n     fn parse_prefix_range_expr(&mut self,\n                                already_parsed_attrs: Option<ThinVec<Attribute>>)\n@@ -3582,7 +3220,7 @@ impl<'a> Parser<'a> {\n                     hi = x.span;\n                     x\n                 })?)\n-         } else {\n+        } else {\n             None\n         };\n         let limits = if tok == token::DotDot {\n@@ -3732,20 +3370,7 @@ impl<'a> Parser<'a> {\n             err.emit();\n         }\n         let in_span = self.prev_span;\n-        if self.eat_keyword(kw::In) {\n-            // a common typo: `for _ in in bar {}`\n-            let mut err = self.sess.span_diagnostic.struct_span_err(\n-                self.prev_span,\n-                \"expected iterable, found keyword `in`\",\n-            );\n-            err.span_suggestion_short(\n-                in_span.until(self.prev_span),\n-                \"remove the duplicated `in`\",\n-                String::new(),\n-                Applicability::MachineApplicable,\n-            );\n-            err.emit();\n-        }\n+        self.check_for_for_in_in_typo(in_span);\n         let expr = self.parse_expr_res(Restrictions::NO_STRUCT_LITERAL, None)?;\n         let (iattrs, loop_block) = self.parse_inner_attrs_and_block()?;\n         attrs.extend(iattrs);\n@@ -6327,7 +5952,9 @@ impl<'a> Parser<'a> {\n             let (constness, unsafety, mut asyncness, abi) = self.parse_fn_front_matter()?;\n             let ident = self.parse_ident()?;\n             let mut generics = self.parse_generics()?;\n-            let mut decl = self.parse_fn_decl_with_self(|p| p.parse_arg())?;\n+            let mut decl = self.parse_fn_decl_with_self(|p| {\n+                p.parse_arg_general(true, true, false)\n+            })?;\n             generics.where_clause = self.parse_where_clause()?;\n             self.construct_async_arguments(&mut asyncness, &mut decl);\n             *at_end = true;"}]}