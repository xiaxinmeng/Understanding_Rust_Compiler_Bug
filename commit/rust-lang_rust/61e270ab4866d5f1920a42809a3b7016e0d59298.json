{"sha": "61e270ab4866d5f1920a42809a3b7016e0d59298", "node_id": "MDY6Q29tbWl0NzI0NzEyOjYxZTI3MGFiNDg2NmQ1ZjE5MjBhNDI4MDlhM2I3MDE2ZTBkNTkyOTg=", "commit": {"author": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2019-08-06T06:17:34Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-08-06T06:17:34Z"}, "message": "Rollup merge of #63017 - matklad:no-fatal, r=petrochenkov\n\nRemove special code-path for handing unknown tokens\n\nIn `StringReader`, we have a buffer of fatal errors, which is used only in a single case: when we see something which is not a reasonable token at all, like `\ud83e\udd80`. I think a more straightforward thing to do here is to produce an explicit error token in this case, and let the next layer (the parser), deal with it.\n\nHowever currently this leads to duplicated error messages. What should we do with this? Naively, I would think that emitting (just emitting, not raising) `FatalError` should stop other errors, but looks like this is not the case? We can also probably tweak parser on the case-by-case basis, to avoid emitting \"expected\" errors if the current token is an `Err`. I personally also fine with cascading errors in this case: it's quite unlikely that you actually type a fully invalid token.\n\n@petrochenkov, which approach should we take to fight cascading errors?", "tree": {"sha": "768eac02a16923f52df3f2615bf581a73ca5037a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/768eac02a16923f52df3f2615bf581a73ca5037a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/61e270ab4866d5f1920a42809a3b7016e0d59298", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJdSRt+CRBK7hj4Ov3rIwAAdHIIABZhna87NqnKGnMFYaWsK/G3\n8t2+DgrygheqaLtSFjH6GF90KIEivVTr5ehEjzBy1vbgUNZWMEI5cStDQocjNo8q\ncY/J2L/s15gfZ4mWflCARB6uNvF5x5/1NooG11viW0g+6d2wPavDi4t25zCYu+2Q\nfLc4/vuRoudvkvTMB2+vP9cWo4JcjkV05yLPA5DFUPy9smM2oen/lmUo1ye06nyd\neugn6qx7Mm620IREgJNpHUE2fDl79XM2OlBbLC/9iauDjoEf3Rlk3zEsgRzp8v2n\nZKa2InrhPsS4spntrYvyOxN+UO9ERCHYZcqHQYR1yH/isCfPaGN++gNhMb7chNA=\n=JIgp\n-----END PGP SIGNATURE-----\n", "payload": "tree 768eac02a16923f52df3f2615bf581a73ca5037a\nparent fe998dbfe496d05dc1536820ab9611bd3281a7f2\nparent b3e8c8bbe27e21a2e67039d9fb9ea41cb83b1499\nauthor Mazdak Farrokhzad <twingoow@gmail.com> 1565072254 +0200\ncommitter GitHub <noreply@github.com> 1565072254 +0200\n\nRollup merge of #63017 - matklad:no-fatal, r=petrochenkov\n\nRemove special code-path for handing unknown tokens\n\nIn `StringReader`, we have a buffer of fatal errors, which is used only in a single case: when we see something which is not a reasonable token at all, like `\ud83e\udd80`. I think a more straightforward thing to do here is to produce an explicit error token in this case, and let the next layer (the parser), deal with it.\n\nHowever currently this leads to duplicated error messages. What should we do with this? Naively, I would think that emitting (just emitting, not raising) `FatalError` should stop other errors, but looks like this is not the case? We can also probably tweak parser on the case-by-case basis, to avoid emitting \"expected\" errors if the current token is an `Err`. I personally also fine with cascading errors in this case: it's quite unlikely that you actually type a fully invalid token.\n\n@petrochenkov, which approach should we take to fight cascading errors?\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/61e270ab4866d5f1920a42809a3b7016e0d59298", "html_url": "https://github.com/rust-lang/rust/commit/61e270ab4866d5f1920a42809a3b7016e0d59298", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/61e270ab4866d5f1920a42809a3b7016e0d59298/comments", "author": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fe998dbfe496d05dc1536820ab9611bd3281a7f2", "url": "https://api.github.com/repos/rust-lang/rust/commits/fe998dbfe496d05dc1536820ab9611bd3281a7f2", "html_url": "https://github.com/rust-lang/rust/commit/fe998dbfe496d05dc1536820ab9611bd3281a7f2"}, {"sha": "b3e8c8bbe27e21a2e67039d9fb9ea41cb83b1499", "url": "https://api.github.com/repos/rust-lang/rust/commits/b3e8c8bbe27e21a2e67039d9fb9ea41cb83b1499", "html_url": "https://github.com/rust-lang/rust/commit/b3e8c8bbe27e21a2e67039d9fb9ea41cb83b1499"}], "stats": {"total": 339, "additions": 223, "deletions": 116}, "files": [{"sha": "5cc8324b316065064a413867c538c8abe2ee6d46", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -363,7 +363,8 @@ impl<'a> HashStable<StableHashingContext<'a>> for token::TokenKind {\n             }\n \n             token::DocComment(val) |\n-            token::Shebang(val) => val.hash_stable(hcx, hasher),\n+            token::Shebang(val) |\n+            token::Unknown(val) => val.hash_stable(hcx, hasher),\n         }\n     }\n }"}, {"sha": "5d86ee9721b75711aa73b12290c2493c15f82eac", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 15, "deletions": 14, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -44,7 +44,7 @@ pub fn render_with_highlighting(\n \n         let mut highlighted_source = vec![];\n         if classifier.write_source(&mut highlighted_source).is_err() {\n-            Err(classifier.lexer.buffer_fatal_errors())\n+            Err(())\n         } else {\n             Ok(String::from_utf8_lossy(&highlighted_source).into_owned())\n         }\n@@ -59,14 +59,9 @@ pub fn render_with_highlighting(\n             }\n             write_footer(&mut out).unwrap();\n         }\n-        Err(errors) => {\n-            // If errors are encountered while trying to highlight, cancel the errors and just emit\n-            // the unhighlighted source. The errors will have already been reported in the\n-            // `check-code-block-syntax` pass.\n-            for mut error in errors {\n-                error.cancel();\n-            }\n-\n+        Err(()) => {\n+            // If errors are encountered while trying to highlight, just emit\n+            // the unhighlighted source.\n             write!(out, \"<pre><code>{}</code></pre>\", src).unwrap();\n         }\n     }\n@@ -192,14 +187,20 @@ impl<'a> Classifier<'a> {\n         if let Some(token) = self.peek_token.take() {\n             return Ok(token);\n         }\n-        self.lexer.try_next_token().map_err(|()| HighlightError::LexError)\n+        let token = self.lexer.next_token();\n+        if let token::Unknown(..) = &token.kind {\n+            return Err(HighlightError::LexError);\n+        }\n+        Ok(token)\n     }\n \n     fn peek(&mut self) -> Result<&Token, HighlightError> {\n         if self.peek_token.is_none() {\n-            self.peek_token = Some(\n-                self.lexer.try_next_token().map_err(|()| HighlightError::LexError)?\n-            );\n+            let token = self.lexer.next_token();\n+            if let token::Unknown(..) = &token.kind {\n+                return Err(HighlightError::LexError);\n+            }\n+            self.peek_token = Some(token);\n         }\n         Ok(self.peek_token.as_ref().unwrap())\n     }\n@@ -237,7 +238,7 @@ impl<'a> Classifier<'a> {\n                 return Ok(());\n             },\n \n-            token::Whitespace => Class::None,\n+            token::Whitespace | token::Unknown(..) => Class::None,\n             token::Comment => Class::Comment,\n             token::DocComment(..) => Class::DocComment,\n "}, {"sha": "357e17d2d1bc46c4c97cb79576f1cb668efd6ea8", "filename": "src/librustdoc/passes/check_code_block_syntax.rs", "status": "modified", "additions": 9, "deletions": 23, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibrustdoc%2Fpasses%2Fcheck_code_block_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibrustdoc%2Fpasses%2Fcheck_code_block_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fpasses%2Fcheck_code_block_syntax.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -32,24 +32,20 @@ impl<'a, 'tcx> SyntaxChecker<'a, 'tcx> {\n             dox[code_block.code].to_owned(),\n         );\n \n-        let errors = {\n+        let has_errors = {\n+            let mut has_errors = false;\n             let mut lexer = Lexer::new(&sess, source_file, None);\n-            while let Ok(token::Token { kind, .. }) = lexer.try_next_token() {\n-                if kind == token::Eof {\n-                    break;\n+            loop  {\n+                match lexer.next_token().kind {\n+                    token::Eof => break,\n+                    token::Unknown(..) => has_errors = true,\n+                    _ => (),\n                 }\n             }\n-\n-            let errors = lexer.buffer_fatal_errors();\n-\n-            if !errors.is_empty() {\n-                Err(errors)\n-            } else {\n-                Ok(())\n-            }\n+            has_errors\n         };\n \n-        if let Err(errors) = errors {\n+        if has_errors {\n             let mut diag = if let Some(sp) =\n                 super::source_span_for_markdown_range(self.cx, &dox, &code_block.range, &item.attrs)\n             {\n@@ -58,11 +54,6 @@ impl<'a, 'tcx> SyntaxChecker<'a, 'tcx> {\n                     .sess()\n                     .struct_span_warn(sp, \"could not parse code block as Rust code\");\n \n-                for mut err in errors {\n-                    diag.note(&format!(\"error from rustc: {}\", err.message()));\n-                    err.cancel();\n-                }\n-\n                 if code_block.syntax.is_none() && code_block.is_fenced {\n                     let sp = sp.from_inner(InnerSpan::new(0, 3));\n                     diag.span_suggestion(\n@@ -82,11 +73,6 @@ impl<'a, 'tcx> SyntaxChecker<'a, 'tcx> {\n                     \"doc comment contains an invalid Rust code block\",\n                 );\n \n-                for mut err in errors {\n-                    // Don't bother reporting the error, because we can't show where it happened.\n-                    err.cancel();\n-                }\n-\n                 if code_block.syntax.is_none() && code_block.is_fenced {\n                     diag.help(\"mark blocks that do not contain Rust code as text: ```text\");\n                 }"}, {"sha": "36621ce7775107d77a76790c2a1d28f4099c8b9b", "filename": "src/libsyntax/ext/proc_macro_server.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -184,7 +184,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n             }\n \n             OpenDelim(..) | CloseDelim(..) => unreachable!(),\n-            Whitespace | Comment | Shebang(..) | Eof => unreachable!(),\n+            Whitespace | Comment | Shebang(..) | Unknown(..) | Eof => unreachable!(),\n         }\n     }\n }"}, {"sha": "e86d4c7fde683f39e6ba394e2f70a2deeb43db0b", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 13, "deletions": 60, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -3,7 +3,7 @@ use crate::parse::token::{self, Token, TokenKind};\n use crate::symbol::{sym, Symbol};\n use crate::parse::unescape_error_reporting::{emit_unescape_error, push_escaped_char};\n \n-use errors::{FatalError, Diagnostic, DiagnosticBuilder};\n+use errors::{FatalError, DiagnosticBuilder};\n use syntax_pos::{BytePos, Pos, Span, NO_EXPANSION};\n use rustc_lexer::Base;\n use rustc_lexer::unescape;\n@@ -39,7 +39,6 @@ pub struct StringReader<'a> {\n     pos: BytePos,\n     /// Stop reading src at this index.\n     end_src_index: usize,\n-    fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     /// Source text to tokenize.\n     src: Lrc<String>,\n     override_span: Option<Span>,\n@@ -62,7 +61,6 @@ impl<'a> StringReader<'a> {\n             pos: source_file.start_pos,\n             end_src_index: src.len(),\n             src,\n-            fatal_errs: Vec::new(),\n             override_span,\n         }\n     }\n@@ -89,29 +87,17 @@ impl<'a> StringReader<'a> {\n         self.override_span.unwrap_or_else(|| Span::new(lo, hi, NO_EXPANSION))\n     }\n \n-    fn unwrap_or_abort(&mut self, res: Result<Token, ()>) -> Token {\n-        match res {\n-            Ok(tok) => tok,\n-            Err(_) => {\n-                self.emit_fatal_errors();\n-                FatalError.raise();\n-            }\n-        }\n-    }\n-\n     /// Returns the next token, including trivia like whitespace or comments.\n     ///\n     /// `Err(())` means that some errors were encountered, which can be\n     /// retrieved using `buffer_fatal_errors`.\n-    pub fn try_next_token(&mut self) -> Result<Token, ()> {\n-        assert!(self.fatal_errs.is_empty());\n-\n+    pub fn next_token(&mut self) -> Token {\n         let start_src_index = self.src_index(self.pos);\n         let text: &str = &self.src[start_src_index..self.end_src_index];\n \n         if text.is_empty() {\n             let span = self.mk_sp(self.pos, self.pos);\n-            return Ok(Token::new(token::Eof, span));\n+            return Token::new(token::Eof, span);\n         }\n \n         {\n@@ -125,7 +111,7 @@ impl<'a> StringReader<'a> {\n                     let kind = token::Shebang(sym);\n \n                     let span = self.mk_sp(start, self.pos);\n-                    return Ok(Token::new(kind, span));\n+                    return Token::new(kind, span);\n                 }\n             }\n         }\n@@ -139,39 +125,10 @@ impl<'a> StringReader<'a> {\n \n         // This could use `?`, but that makes code significantly (10-20%) slower.\n         // https://github.com/rust-lang/rust/issues/37939\n-        let kind = match self.cook_lexer_token(token.kind, start) {\n-            Ok(it) => it,\n-            Err(err) => return Err(self.fatal_errs.push(err)),\n-        };\n+        let kind = self.cook_lexer_token(token.kind, start);\n \n         let span = self.mk_sp(start, self.pos);\n-        Ok(Token::new(kind, span))\n-    }\n-\n-    /// Returns the next token, including trivia like whitespace or comments.\n-    ///\n-    /// Aborts in case of an error.\n-    pub fn next_token(&mut self) -> Token {\n-        let res = self.try_next_token();\n-        self.unwrap_or_abort(res)\n-    }\n-\n-    fn emit_fatal_errors(&mut self) {\n-        for err in &mut self.fatal_errs {\n-            err.emit();\n-        }\n-\n-        self.fatal_errs.clear();\n-    }\n-\n-    pub fn buffer_fatal_errors(&mut self) -> Vec<Diagnostic> {\n-        let mut buffer = Vec::new();\n-\n-        for err in self.fatal_errs.drain(..) {\n-            err.buffer(&mut buffer);\n-        }\n-\n-        buffer\n+        Token::new(kind, span)\n     }\n \n     /// Report a fatal lexical error with a given span.\n@@ -218,8 +175,8 @@ impl<'a> StringReader<'a> {\n         &self,\n         token: rustc_lexer::TokenKind,\n         start: BytePos,\n-    ) -> Result<TokenKind, DiagnosticBuilder<'a>> {\n-        let kind = match token {\n+    ) -> TokenKind {\n+        match token {\n             rustc_lexer::TokenKind::LineComment => {\n                 let string = self.str_from(start);\n                 // comments with only more \"/\"s are not doc comments\n@@ -396,16 +353,12 @@ impl<'a> StringReader<'a> {\n                 // this should be inside `rustc_lexer`. However, we should first remove compound\n                 // tokens like `<<` from `rustc_lexer`, and then add fancier error recovery to it,\n                 // as there will be less overall work to do this way.\n-                return match unicode_chars::check_for_substitution(self, start, c, &mut err) {\n-                    Some(token) => {\n-                        err.emit();\n-                        Ok(token)\n-                    }\n-                    None => Err(err),\n-                }\n+                let token = unicode_chars::check_for_substitution(self, start, c, &mut err)\n+                    .unwrap_or_else(|| token::Unknown(self.symbol_from(start)));\n+                err.emit();\n+                token\n             }\n-        };\n-        Ok(kind)\n+        }\n     }\n \n     fn cook_lexer_literal("}, {"sha": "37e67a2729e6d36ac904727bb5ea7f6b4724689e", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -217,7 +217,7 @@ impl<'a> TokenTreesReader<'a> {\n         loop {\n             let token = self.string_reader.next_token();\n             match token.kind {\n-                token::Whitespace | token::Comment | token::Shebang(_) => {\n+                token::Whitespace | token::Comment | token::Shebang(_) | token::Unknown(_) => {\n                     self.joint_to_prev = NonJoint;\n                 }\n                 _ => {"}, {"sha": "be800b4de66aff2153ec99c7fb06ef92473ceaf2", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -255,6 +255,8 @@ pub enum TokenKind {\n     /// A comment.\n     Comment,\n     Shebang(ast::Name),\n+    /// A completely invalid token which should be skipped.\n+    Unknown(ast::Name),\n \n     Eof,\n }\n@@ -603,7 +605,7 @@ impl Token {\n             DotDotEq | Comma | Semi | ModSep | RArrow | LArrow | FatArrow | Pound | Dollar |\n             Question | OpenDelim(..) | CloseDelim(..) |\n             Literal(..) | Ident(..) | Lifetime(..) | Interpolated(..) | DocComment(..) |\n-            Whitespace | Comment | Shebang(..) | Eof => return None,\n+            Whitespace | Comment | Shebang(..) | Unknown(..) | Eof => return None,\n         };\n \n         Some(Token::new(kind, self.span.to(joint.span)))"}, {"sha": "378ba1e4107a49103bc0a93e1cc59dd31114f874", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -288,6 +288,7 @@ fn token_kind_to_string_ext(tok: &TokenKind, convert_dollar_crate: Option<Span>)\n         token::Whitespace           => \" \".to_string(),\n         token::Comment              => \"/* */\".to_string(),\n         token::Shebang(s)           => format!(\"/* shebang: {}*/\", s),\n+        token::Unknown(s)           => s.to_string(),\n \n         token::Interpolated(ref nt) => nonterminal_to_string(nt),\n     }"}, {"sha": "3bebbecb9dfcf5ad196f5a19657d24c8260fb637", "filename": "src/test/rustdoc-ui/invalid-syntax.stderr", "status": "modified", "additions": 154, "deletions": 14, "changes": 168, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Frustdoc-ui%2Finvalid-syntax.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Frustdoc-ui%2Finvalid-syntax.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frustdoc-ui%2Finvalid-syntax.stderr?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -1,3 +1,21 @@\n+error: unknown start of token: \\\n+ --> <doctest>:1:1\n+  |\n+1 | \\__________pkt->size___________/          \\_result->size_/ \\__pkt->size__/\n+  | ^\n+\n+error: unknown start of token: \\\n+ --> <doctest>:1:43\n+  |\n+1 | \\__________pkt->size___________/          \\_result->size_/ \\__pkt->size__/\n+  |                                           ^\n+\n+error: unknown start of token: \\\n+ --> <doctest>:1:60\n+  |\n+1 | \\__________pkt->size___________/          \\_result->size_/ \\__pkt->size__/\n+  |                                                            ^\n+\n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:3:5\n    |\n@@ -6,13 +24,31 @@ LL |   /// ```\n LL | | /// \\__________pkt->size___________/          \\_result->size_/ \\__pkt->size__/\n LL | | /// ```\n    | |_______^\n-   |\n-   = note: error from rustc: unknown start of token: \\\n help: mark blocks that do not contain Rust code as text\n    |\n LL | /// ```text\n    |     ^^^^^^^\n \n+error: unknown start of token: `\n+ --> <doctest>:3:30\n+  |\n+3 |    |     ^^^^^^ did you mean `baz::foobar`?\n+  |                              ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+3 |    |     ^^^^^^ did you mean 'baz::foobar`?\n+  |                              ^\n+\n+error: unknown start of token: `\n+ --> <doctest>:3:42\n+  |\n+3 |    |     ^^^^^^ did you mean `baz::foobar`?\n+  |                                          ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+3 |    |     ^^^^^^ did you mean `baz::foobar'?\n+  |                                          ^\n+\n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:8:5\n    |\n@@ -23,13 +59,17 @@ LL | | /// LL | use foobar::Baz;\n LL | | ///    |     ^^^^^^ did you mean `baz::foobar`?\n LL | | /// ```\n    | |_______^\n-   |\n-   = note: error from rustc: unknown start of token: `\n help: mark blocks that do not contain Rust code as text\n    |\n LL | /// ```text\n    |     ^^^^^^^\n \n+error: unknown start of token: \\\n+ --> <doctest>:1:1\n+  |\n+1 | \\_\n+  | ^\n+\n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:19:5\n    |\n@@ -38,13 +78,17 @@ LL |   /// ```\n LL | | /// \\_\n LL | | /// ```\n    | |_______^\n-   |\n-   = note: error from rustc: unknown start of token: \\\n help: mark blocks that do not contain Rust code as text\n    |\n LL | /// ```text\n    |     ^^^^^^^\n \n+error: unknown start of token: \\\n+ --> <doctest>:1:1\n+  |\n+1 | \\_\n+  | ^\n+\n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:32:5\n    |\n@@ -53,8 +97,12 @@ LL |   /// ```rust\n LL | | /// \\_\n LL | | /// ```\n    | |_______^\n-   |\n-   = note: error from rustc: unknown start of token: \\\n+\n+error: unknown start of token: \\\n+ --> <doctest>:2:5\n+  |\n+2 |     \\_\n+  |     ^\n \n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:41:9\n@@ -63,16 +111,48 @@ LL |   ///     code with bad syntax\n    |  _________^\n LL | | ///     \\_\n    | |__________^\n-   |\n-   = note: error from rustc: unknown start of token: \\\n+\n+error: unknown start of token: `\n+ --> <doctest>:1:1\n+  |\n+1 | ```\n+  | ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+1 | '``\n+  | ^\n+\n+error: unknown start of token: `\n+ --> <doctest>:1:2\n+  |\n+1 | ```\n+  |  ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+1 | `'`\n+  |  ^\n+\n+error: unknown start of token: `\n+ --> <doctest>:1:3\n+  |\n+1 | ```\n+  |   ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+1 | ``'\n+  |   ^\n \n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:55:9\n    |\n LL | ///     ```\n    |         ^^^\n-   |\n-   = note: error from rustc: unknown start of token: `\n+\n+error: unknown start of token: \\\n+ --> <doctest>:1:1\n+  |\n+1 | \\_\n+  | ^\n \n warning: could not parse code block as Rust code\n   --> $DIR/invalid-syntax.rs:58:5\n@@ -82,8 +162,12 @@ LL |   /// ```edition2018\n LL | | /// \\_\n LL | | /// ```\n    | |_______^\n-   |\n-   = note: error from rustc: unknown start of token: \\\n+\n+error: unknown start of token: \\\n+ --> <doctest>:1:1\n+  |\n+1 | \\_\n+  | ^\n \n warning: doc comment contains an invalid Rust code block\n   --> $DIR/invalid-syntax.rs:63:1\n@@ -95,3 +179,59 @@ LL | | #[doc = \"```\"]\n    |\n    = help: mark blocks that do not contain Rust code as text: ```text\n \n+error: unknown start of token: \\\n+ --> <rustdoc-highlighting>:1:1\n+  |\n+1 | \\_\n+  | ^\n+\n+error: unknown start of token: \\\n+ --> <rustdoc-highlighting>:1:1\n+  |\n+1 | \\_\n+  | ^\n+\n+error: unknown start of token: `\n+ --> <rustdoc-highlighting>:1:1\n+  |\n+1 | ```\n+  | ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+1 | '``\n+  | ^\n+\n+error: unknown start of token: \\\n+ --> <rustdoc-highlighting>:2:1\n+  |\n+2 | \\_\n+  | ^\n+\n+error: unknown start of token: \\\n+ --> <rustdoc-highlighting>:1:1\n+  |\n+1 | \\_\n+  | ^\n+\n+error: unknown start of token: \\\n+ --> <rustdoc-highlighting>:1:1\n+  |\n+1 | \\_\n+  | ^\n+\n+error: unknown start of token: `\n+ --> <rustdoc-highlighting>:3:30\n+  |\n+3 |    |     ^^^^^^ did you mean `baz::foobar`?\n+  |                              ^\n+help: Unicode character '`' (Grave Accent) looks like ''' (Single Quote), but it is not\n+  |\n+3 |    |     ^^^^^^ did you mean 'baz::foobar`?\n+  |                              ^\n+\n+error: unknown start of token: \\\n+ --> <rustdoc-highlighting>:1:1\n+  |\n+1 | \\__________pkt->size___________/          \\_result->size_/ \\__pkt->size__/\n+  | ^\n+"}, {"sha": "9e4824611128d1d64fdc4234da5716a7758af2e5", "filename": "src/test/ui/parser/lex-bad-token.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Flex-bad-token.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Flex-bad-token.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-bad-token.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -1 +1,3 @@\n \u25cf //~ ERROR: unknown start of token\n+\n+fn main() {}"}, {"sha": "bb27f44c279f7ccf4c903c8f5e82a29e20b937b5", "filename": "src/test/ui/parser/lex-stray-backslash.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Flex-stray-backslash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Flex-stray-backslash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-stray-backslash.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -1 +1,3 @@\n \\ //~ ERROR: unknown start of token: \\\n+\n+fn main() {}"}, {"sha": "1812dad81afc34b92c0f1a998d8447e86be5ba9c", "filename": "src/test/ui/parser/unicode-quote-chars.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.rs?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -4,4 +4,7 @@ fn main() {\n     println!(\u201chello world\u201d);\n     //~^ ERROR unknown start of token: \\u{201c}\n     //~^^ HELP Unicode characters '\u201c' (Left Double Quotation Mark) and '\u201d' (Right Double Quotation Mark) look like '\"' (Quotation Mark), but are not\n+    //~^^^ ERROR unknown start of token: \\u{201d}\n+    //~^^^^ HELP Unicode character '\u201d' (Right Double Quotation Mark) looks like '\"' (Quotation Mark), but it is not\n+    //~^^^^^ ERROR expected token: `,`\n }"}, {"sha": "84e45ecd873a4852564cf35c13800b5e4299492d", "filename": "src/test/ui/parser/unicode-quote-chars.stderr", "status": "modified", "additions": 17, "deletions": 1, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/61e270ab4866d5f1920a42809a3b7016e0d59298/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.stderr?ref=61e270ab4866d5f1920a42809a3b7016e0d59298", "patch": "@@ -8,5 +8,21 @@ help: Unicode characters '\u201c' (Left Double Quotation Mark) and '\u201d' (Right Dou\n LL |     println!(\"hello world\");\n    |              ^^^^^^^^^^^^^\n \n-error: aborting due to previous error\n+error: unknown start of token: \\u{201d}\n+  --> $DIR/unicode-quote-chars.rs:4:26\n+   |\n+LL |     println!(\u201chello world\u201d);\n+   |                          ^\n+help: Unicode character '\u201d' (Right Double Quotation Mark) looks like '\"' (Quotation Mark), but it is not\n+   |\n+LL |     println!(\u201chello world\");\n+   |                          ^\n+\n+error: expected token: `,`\n+  --> $DIR/unicode-quote-chars.rs:4:21\n+   |\n+LL |     println!(\u201chello world\u201d);\n+   |                     ^^^^^ expected `,`\n+\n+error: aborting due to 3 previous errors\n "}]}