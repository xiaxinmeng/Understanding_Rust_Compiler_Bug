{"sha": "d5638142b32935508626226d0f0cf9059db40789", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ1NjM4MTQyYjMyOTM1NTA4NjI2MjI2ZDBmMGNmOTA1OWRiNDA3ODk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-02-19T22:29:07Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-02-19T22:29:07Z"}, "message": "Auto merge of #68988 - Zoxc:query-caches, r=eddyb\n\nAdd an abstraction for custom query caches\n\nr? @eddyb", "tree": {"sha": "2b839a949559628ae3f7ba8b5c2e4192b11f7773", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2b839a949559628ae3f7ba8b5c2e4192b11f7773"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d5638142b32935508626226d0f0cf9059db40789", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d5638142b32935508626226d0f0cf9059db40789", "html_url": "https://github.com/rust-lang/rust/commit/d5638142b32935508626226d0f0cf9059db40789", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d5638142b32935508626226d0f0cf9059db40789/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7760cd0fbbbf2c59a625e075a5bdfa88b8e30f8a", "url": "https://api.github.com/repos/rust-lang/rust/commits/7760cd0fbbbf2c59a625e075a5bdfa88b8e30f8a", "html_url": "https://github.com/rust-lang/rust/commit/7760cd0fbbbf2c59a625e075a5bdfa88b8e30f8a"}, {"sha": "d924a251f120ba44fd091962fcda733591a07485", "url": "https://api.github.com/repos/rust-lang/rust/commits/d924a251f120ba44fd091962fcda733591a07485", "html_url": "https://github.com/rust-lang/rust/commit/d924a251f120ba44fd091962fcda733591a07485"}], "stats": {"total": 1107, "additions": 691, "deletions": 416}, "files": [{"sha": "eb7e2871bfcd8371b6c1c3414559fe1b2c89c269", "filename": "src/librustc/dep_graph/dep_node.rs", "status": "modified", "additions": 42, "deletions": 97, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -76,10 +76,6 @@ macro_rules! erase {\n     ($x:tt) => {{}};\n }\n \n-macro_rules! replace {\n-    ($x:tt with $($y:tt)*) => ($($y)*)\n-}\n-\n macro_rules! is_anon_attr {\n     (anon) => {\n         true\n@@ -99,19 +95,18 @@ macro_rules! is_eval_always_attr {\n }\n \n macro_rules! contains_anon_attr {\n-    ($($attr:ident),*) => ({$(is_anon_attr!($attr) | )* false});\n+    ($($attr:ident $(($($attr_args:tt)*))* ),*) => ({$(is_anon_attr!($attr) | )* false});\n }\n \n macro_rules! contains_eval_always_attr {\n-    ($($attr:ident),*) => ({$(is_eval_always_attr!($attr) | )* false});\n+    ($($attr:ident $(($($attr_args:tt)*))* ),*) => ({$(is_eval_always_attr!($attr) | )* false});\n }\n \n macro_rules! define_dep_nodes {\n     (<$tcx:tt>\n     $(\n-        [$($attr:ident),* ]\n+        [$($attrs:tt)*]\n         $variant:ident $(( $tuple_arg_ty:ty $(,)? ))*\n-                       $({ $($struct_arg_name:ident : $struct_arg_ty:ty),* })*\n       ,)*\n     ) => (\n         #[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord, Hash,\n@@ -126,7 +121,7 @@ macro_rules! define_dep_nodes {\n                 match *self {\n                     $(\n                         DepKind :: $variant => {\n-                            if contains_anon_attr!($($attr),*) {\n+                            if contains_anon_attr!($($attrs)*) {\n                                 return false;\n                             }\n \n@@ -136,13 +131,6 @@ macro_rules! define_dep_nodes {\n                                     ::CAN_RECONSTRUCT_QUERY_KEY;\n                             })*\n \n-                            // struct args\n-                            $({\n-\n-                                return <( $($struct_arg_ty,)* ) as DepNodeParams>\n-                                    ::CAN_RECONSTRUCT_QUERY_KEY;\n-                            })*\n-\n                             true\n                         }\n                     )*\n@@ -152,15 +140,15 @@ macro_rules! define_dep_nodes {\n             pub fn is_anon(&self) -> bool {\n                 match *self {\n                     $(\n-                        DepKind :: $variant => { contains_anon_attr!($($attr),*) }\n+                        DepKind :: $variant => { contains_anon_attr!($($attrs)*) }\n                     )*\n                 }\n             }\n \n             pub fn is_eval_always(&self) -> bool {\n                 match *self {\n                     $(\n-                        DepKind :: $variant => { contains_eval_always_attr!($($attr), *) }\n+                        DepKind :: $variant => { contains_eval_always_attr!($($attrs)*) }\n                     )*\n                 }\n             }\n@@ -176,24 +164,50 @@ macro_rules! define_dep_nodes {\n                                 return true;\n                             })*\n \n-                            // struct args\n-                            $({\n-                                $(erase!($struct_arg_name);)*\n-                                return true;\n-                            })*\n-\n                             false\n                         }\n                     )*\n                 }\n             }\n         }\n \n-        pub enum DepConstructor<$tcx> {\n+        pub struct DepConstructor;\n+\n+        impl DepConstructor {\n             $(\n-                $variant $(( $tuple_arg_ty ))*\n-                         $({ $($struct_arg_name : $struct_arg_ty),* })*\n-            ),*\n+                #[inline(always)]\n+                #[allow(unreachable_code, non_snake_case)]\n+                pub fn $variant<'tcx>(_tcx: TyCtxt<'tcx>, $(arg: $tuple_arg_ty)*) -> DepNode {\n+                    // tuple args\n+                    $({\n+                        erase!($tuple_arg_ty);\n+                        let hash = DepNodeParams::to_fingerprint(&arg, _tcx);\n+                        let dep_node = DepNode {\n+                            kind: DepKind::$variant,\n+                            hash\n+                        };\n+\n+                        #[cfg(debug_assertions)]\n+                        {\n+                            if !dep_node.kind.can_reconstruct_query_key() &&\n+                            (_tcx.sess.opts.debugging_opts.incremental_info ||\n+                                _tcx.sess.opts.debugging_opts.query_dep_graph)\n+                            {\n+                                _tcx.dep_graph.register_dep_node_debug_str(dep_node, || {\n+                                    arg.to_debug_str(_tcx)\n+                                });\n+                            }\n+                        }\n+\n+                        return dep_node;\n+                    })*\n+\n+                    DepNode {\n+                        kind: DepKind::$variant,\n+                        hash: Fingerprint::ZERO,\n+                    }\n+                }\n+            )*\n         }\n \n         #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash,\n@@ -204,75 +218,6 @@ macro_rules! define_dep_nodes {\n         }\n \n         impl DepNode {\n-            #[allow(unreachable_code, non_snake_case)]\n-            pub fn new<'tcx>(tcx: TyCtxt<'tcx>,\n-                                       dep: DepConstructor<'tcx>)\n-                                       -> DepNode\n-            {\n-                match dep {\n-                    $(\n-                        DepConstructor :: $variant $(( replace!(($tuple_arg_ty) with arg) ))*\n-                                                   $({ $($struct_arg_name),* })*\n-                            =>\n-                        {\n-                            // tuple args\n-                            $({\n-                                erase!($tuple_arg_ty);\n-                                let hash = DepNodeParams::to_fingerprint(&arg, tcx);\n-                                let dep_node = DepNode {\n-                                    kind: DepKind::$variant,\n-                                    hash\n-                                };\n-\n-                                #[cfg(debug_assertions)]\n-                                {\n-                                    if !dep_node.kind.can_reconstruct_query_key() &&\n-                                    (tcx.sess.opts.debugging_opts.incremental_info ||\n-                                        tcx.sess.opts.debugging_opts.query_dep_graph)\n-                                    {\n-                                        tcx.dep_graph.register_dep_node_debug_str(dep_node, || {\n-                                            arg.to_debug_str(tcx)\n-                                        });\n-                                    }\n-                                }\n-\n-                                return dep_node;\n-                            })*\n-\n-                            // struct args\n-                            $({\n-                                let tupled_args = ( $($struct_arg_name,)* );\n-                                let hash = DepNodeParams::to_fingerprint(&tupled_args,\n-                                                                         tcx);\n-                                let dep_node = DepNode {\n-                                    kind: DepKind::$variant,\n-                                    hash\n-                                };\n-\n-                                #[cfg(debug_assertions)]\n-                                {\n-                                    if !dep_node.kind.can_reconstruct_query_key() &&\n-                                    (tcx.sess.opts.debugging_opts.incremental_info ||\n-                                        tcx.sess.opts.debugging_opts.query_dep_graph)\n-                                    {\n-                                        tcx.dep_graph.register_dep_node_debug_str(dep_node, || {\n-                                            tupled_args.to_debug_str(tcx)\n-                                        });\n-                                    }\n-                                }\n-\n-                                return dep_node;\n-                            })*\n-\n-                            DepNode {\n-                                kind: DepKind::$variant,\n-                                hash: Fingerprint::ZERO,\n-                            }\n-                        }\n-                    )*\n-                }\n-            }\n-\n             /// Construct a DepNode from the given DepKind and DefPathHash. This\n             /// method will assert that the given DepKind actually requires a\n             /// single DefId/DefPathHash parameter."}, {"sha": "531a45b120c248dbd0d21091f2d4aebad4265550", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -1122,6 +1122,7 @@ impl CurrentDepGraph {\n }\n \n impl DepGraphData {\n+    #[inline(never)]\n     fn read_index(&self, source: DepNodeIndex) {\n         ty::tls::with_context_opt(|icx| {\n             let icx = if let Some(icx) = icx { icx } else { return };"}, {"sha": "9a3ddfb0e82c9f583cf75c3357eec00379651a1b", "filename": "src/librustc/mir/mono.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fmir%2Fmono.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fmir%2Fmono.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Fmono.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -362,7 +362,7 @@ impl<'tcx> CodegenUnit<'tcx> {\n     }\n \n     pub fn codegen_dep_node(&self, tcx: TyCtxt<'tcx>) -> DepNode {\n-        DepNode::new(tcx, DepConstructor::CompileCodegenUnit(self.name()))\n+        DepConstructor::CompileCodegenUnit(tcx, self.name())\n     }\n }\n "}, {"sha": "e59738d8886081f581e93a2153b157fc3c372b93", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -2,7 +2,7 @@\n \n use crate::arena::Arena;\n use crate::dep_graph::DepGraph;\n-use crate::dep_graph::{self, DepConstructor, DepNode};\n+use crate::dep_graph::{self, DepConstructor};\n use crate::hir::exports::Export;\n use crate::hir::map as hir_map;\n use crate::hir::map::DefPathHash;\n@@ -1347,7 +1347,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         // We cannot use the query versions of crates() and crate_hash(), since\n         // those would need the DepNodes that we are allocating here.\n         for cnum in self.cstore.crates_untracked() {\n-            let dep_node = DepNode::new(self, DepConstructor::CrateMetadata(cnum));\n+            let dep_node = DepConstructor::CrateMetadata(self, cnum);\n             let crate_hash = self.cstore.crate_hash_untracked(cnum);\n             self.dep_graph.with_task(\n                 dep_node,\n@@ -1688,6 +1688,7 @@ pub mod tls {\n \n     /// Gets the pointer to the current `ImplicitCtxt`.\n     #[cfg(not(parallel_compiler))]\n+    #[inline]\n     fn get_tlv() -> usize {\n         TLV.with(|tlv| tlv.get())\n     }"}, {"sha": "efc2804bd4d5985fa45b1fc95a19c05b18dc6501", "filename": "src/librustc/ty/query/caches.rs", "status": "added", "additions": 112, "deletions": 0, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fcaches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fcaches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fcaches.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -0,0 +1,112 @@\n+use crate::dep_graph::DepNodeIndex;\n+use crate::ty::query::config::QueryAccessors;\n+use crate::ty::query::plumbing::{QueryLookup, QueryState, QueryStateShard};\n+use crate::ty::TyCtxt;\n+\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::sharded::Sharded;\n+use std::default::Default;\n+use std::hash::Hash;\n+\n+pub(crate) trait CacheSelector<K, V> {\n+    type Cache: QueryCache<K, V>;\n+}\n+\n+pub(crate) trait QueryCache<K, V>: Default {\n+    type Sharded: Default;\n+\n+    /// Checks if the query is already computed and in the cache.\n+    /// It returns the shard index and a lock guard to the shard,\n+    /// which will be used if the query is not in the cache and we need\n+    /// to compute it.\n+    fn lookup<'tcx, R, GetCache, OnHit, OnMiss, Q>(\n+        &self,\n+        state: &'tcx QueryState<'tcx, Q>,\n+        get_cache: GetCache,\n+        key: K,\n+        // `on_hit` can be called while holding a lock to the query state shard.\n+        on_hit: OnHit,\n+        on_miss: OnMiss,\n+    ) -> R\n+    where\n+        Q: QueryAccessors<'tcx>,\n+        GetCache: for<'a> Fn(&'a mut QueryStateShard<'tcx, Q>) -> &'a mut Self::Sharded,\n+        OnHit: FnOnce(&V, DepNodeIndex) -> R,\n+        OnMiss: FnOnce(K, QueryLookup<'tcx, Q>) -> R;\n+\n+    fn complete(\n+        &self,\n+        tcx: TyCtxt<'tcx>,\n+        lock_sharded_storage: &mut Self::Sharded,\n+        key: K,\n+        value: V,\n+        index: DepNodeIndex,\n+    );\n+\n+    fn iter<R, L>(\n+        &self,\n+        shards: &Sharded<L>,\n+        get_shard: impl Fn(&mut L) -> &mut Self::Sharded,\n+        f: impl for<'a> FnOnce(Box<dyn Iterator<Item = (&'a K, &'a V, DepNodeIndex)> + 'a>) -> R,\n+    ) -> R;\n+}\n+\n+pub struct DefaultCacheSelector;\n+\n+impl<K: Eq + Hash, V: Clone> CacheSelector<K, V> for DefaultCacheSelector {\n+    type Cache = DefaultCache;\n+}\n+\n+#[derive(Default)]\n+pub struct DefaultCache;\n+\n+impl<K: Eq + Hash, V: Clone> QueryCache<K, V> for DefaultCache {\n+    type Sharded = FxHashMap<K, (V, DepNodeIndex)>;\n+\n+    #[inline(always)]\n+    fn lookup<'tcx, R, GetCache, OnHit, OnMiss, Q>(\n+        &self,\n+        state: &'tcx QueryState<'tcx, Q>,\n+        get_cache: GetCache,\n+        key: K,\n+        on_hit: OnHit,\n+        on_miss: OnMiss,\n+    ) -> R\n+    where\n+        Q: QueryAccessors<'tcx>,\n+        GetCache: for<'a> Fn(&'a mut QueryStateShard<'tcx, Q>) -> &'a mut Self::Sharded,\n+        OnHit: FnOnce(&V, DepNodeIndex) -> R,\n+        OnMiss: FnOnce(K, QueryLookup<'tcx, Q>) -> R,\n+    {\n+        let mut lookup = state.get_lookup(&key);\n+        let lock = &mut *lookup.lock;\n+\n+        let result = get_cache(lock).raw_entry().from_key_hashed_nocheck(lookup.key_hash, &key);\n+\n+        if let Some((_, value)) = result { on_hit(&value.0, value.1) } else { on_miss(key, lookup) }\n+    }\n+\n+    #[inline]\n+    fn complete(\n+        &self,\n+        _: TyCtxt<'tcx>,\n+        lock_sharded_storage: &mut Self::Sharded,\n+        key: K,\n+        value: V,\n+        index: DepNodeIndex,\n+    ) {\n+        lock_sharded_storage.insert(key, (value, index));\n+    }\n+\n+    fn iter<R, L>(\n+        &self,\n+        shards: &Sharded<L>,\n+        get_shard: impl Fn(&mut L) -> &mut Self::Sharded,\n+        f: impl for<'a> FnOnce(Box<dyn Iterator<Item = (&'a K, &'a V, DepNodeIndex)> + 'a>) -> R,\n+    ) -> R {\n+        let mut shards = shards.lock_shards();\n+        let mut shards: Vec<_> = shards.iter_mut().map(|shard| get_shard(shard)).collect();\n+        let results = shards.iter_mut().flat_map(|shard| shard.iter()).map(|(k, v)| (k, &v.0, v.1));\n+        f(Box::new(results))\n+    }\n+}"}, {"sha": "e0e1ca374d9aef8deacadeabbbf29974773ecbd6", "filename": "src/librustc/ty/query/config.rs", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -1,15 +1,15 @@\n use crate::dep_graph::SerializedDepNodeIndex;\n use crate::dep_graph::{DepKind, DepNode};\n+use crate::ty::query::caches::QueryCache;\n use crate::ty::query::plumbing::CycleError;\n use crate::ty::query::queries;\n-use crate::ty::query::{Query, QueryCache};\n+use crate::ty::query::{Query, QueryState};\n use crate::ty::TyCtxt;\n use rustc_data_structures::profiling::ProfileCategory;\n use rustc_hir::def_id::{CrateNum, DefId};\n \n use crate::ich::StableHashingContext;\n use rustc_data_structures::fingerprint::Fingerprint;\n-use rustc_data_structures::sharded::Sharded;\n use std::borrow::Cow;\n use std::fmt::Debug;\n use std::hash::Hash;\n@@ -30,10 +30,12 @@ pub(crate) trait QueryAccessors<'tcx>: QueryConfig<'tcx> {\n     const ANON: bool;\n     const EVAL_ALWAYS: bool;\n \n+    type Cache: QueryCache<Self::Key, Self::Value>;\n+\n     fn query(key: Self::Key) -> Query<'tcx>;\n \n     // Don't use this method to access query results, instead use the methods on TyCtxt\n-    fn query_cache<'a>(tcx: TyCtxt<'tcx>) -> &'a Sharded<QueryCache<'tcx, Self>>;\n+    fn query_state<'a>(tcx: TyCtxt<'tcx>) -> &'a QueryState<'tcx, Self>;\n \n     fn to_dep_node(tcx: TyCtxt<'tcx>, key: &Self::Key) -> DepNode;\n \n@@ -61,7 +63,10 @@ pub(crate) trait QueryDescription<'tcx>: QueryAccessors<'tcx> {\n     }\n }\n \n-impl<'tcx, M: QueryAccessors<'tcx, Key = DefId>> QueryDescription<'tcx> for M {\n+impl<'tcx, M: QueryAccessors<'tcx, Key = DefId>> QueryDescription<'tcx> for M\n+where\n+    <M as QueryAccessors<'tcx>>::Cache: QueryCache<DefId, <M as QueryConfig<'tcx>>::Value>,\n+{\n     default fn describe(tcx: TyCtxt<'_>, def_id: DefId) -> Cow<'static, str> {\n         if !tcx.sess.verbose() {\n             format!(\"processing `{}`\", tcx.def_path_str(def_id)).into()"}, {"sha": "09fb307a1ceb416cb6aec8b5030a7a676002bee1", "filename": "src/librustc/ty/query/keys.rs", "status": "modified", "additions": 50, "deletions": 1, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fkeys.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fkeys.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fkeys.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -4,6 +4,7 @@ use crate::infer::canonical::Canonical;\n use crate::mir;\n use crate::traits;\n use crate::ty::fast_reject::SimplifiedType;\n+use crate::ty::query::caches::DefaultCacheSelector;\n use crate::ty::subst::SubstsRef;\n use crate::ty::{self, Ty, TyCtxt};\n use rustc_hir::def_id::{CrateNum, DefId, DefIndex, LOCAL_CRATE};\n@@ -12,7 +13,9 @@ use rustc_span::{Span, DUMMY_SP};\n \n /// The `Key` trait controls what types can legally be used as the key\n /// for a query.\n-pub(super) trait Key {\n+pub trait Key {\n+    type CacheSelector;\n+\n     /// Given an instance of this key, what crate is it referring to?\n     /// This is used to find the provider.\n     fn query_crate(&self) -> CrateNum;\n@@ -23,6 +26,8 @@ pub(super) trait Key {\n }\n \n impl<'tcx> Key for ty::InstanceDef<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -33,6 +38,8 @@ impl<'tcx> Key for ty::InstanceDef<'tcx> {\n }\n \n impl<'tcx> Key for ty::Instance<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -43,6 +50,8 @@ impl<'tcx> Key for ty::Instance<'tcx> {\n }\n \n impl<'tcx> Key for mir::interpret::GlobalId<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.instance.query_crate()\n     }\n@@ -53,6 +62,8 @@ impl<'tcx> Key for mir::interpret::GlobalId<'tcx> {\n }\n \n impl<'tcx> Key for mir::interpret::LitToConstInput<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -63,6 +74,8 @@ impl<'tcx> Key for mir::interpret::LitToConstInput<'tcx> {\n }\n \n impl Key for CrateNum {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         *self\n     }\n@@ -72,6 +85,8 @@ impl Key for CrateNum {\n }\n \n impl Key for DefIndex {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -81,6 +96,8 @@ impl Key for DefIndex {\n }\n \n impl Key for DefId {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.krate\n     }\n@@ -90,6 +107,8 @@ impl Key for DefId {\n }\n \n impl Key for (DefId, DefId) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.0.krate\n     }\n@@ -99,6 +118,8 @@ impl Key for (DefId, DefId) {\n }\n \n impl Key for (CrateNum, DefId) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.0\n     }\n@@ -108,6 +129,8 @@ impl Key for (CrateNum, DefId) {\n }\n \n impl Key for (DefId, SimplifiedType) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.0.krate\n     }\n@@ -117,6 +140,8 @@ impl Key for (DefId, SimplifiedType) {\n }\n \n impl<'tcx> Key for SubstsRef<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -126,6 +151,8 @@ impl<'tcx> Key for SubstsRef<'tcx> {\n }\n \n impl<'tcx> Key for (DefId, SubstsRef<'tcx>) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.0.krate\n     }\n@@ -135,6 +162,8 @@ impl<'tcx> Key for (DefId, SubstsRef<'tcx>) {\n }\n \n impl<'tcx> Key for (ty::ParamEnv<'tcx>, ty::PolyTraitRef<'tcx>) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.1.def_id().krate\n     }\n@@ -144,6 +173,8 @@ impl<'tcx> Key for (ty::ParamEnv<'tcx>, ty::PolyTraitRef<'tcx>) {\n }\n \n impl<'tcx> Key for (&'tcx ty::Const<'tcx>, mir::Field) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -153,6 +184,8 @@ impl<'tcx> Key for (&'tcx ty::Const<'tcx>, mir::Field) {\n }\n \n impl<'tcx> Key for ty::PolyTraitRef<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.def_id().krate\n     }\n@@ -162,6 +195,8 @@ impl<'tcx> Key for ty::PolyTraitRef<'tcx> {\n }\n \n impl<'tcx> Key for &'tcx ty::Const<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -171,6 +206,8 @@ impl<'tcx> Key for &'tcx ty::Const<'tcx> {\n }\n \n impl<'tcx> Key for Ty<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -180,6 +217,8 @@ impl<'tcx> Key for Ty<'tcx> {\n }\n \n impl<'tcx> Key for ty::ParamEnv<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -189,6 +228,8 @@ impl<'tcx> Key for ty::ParamEnv<'tcx> {\n }\n \n impl<'tcx, T: Key> Key for ty::ParamEnvAnd<'tcx, T> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         self.value.query_crate()\n     }\n@@ -198,6 +239,8 @@ impl<'tcx, T: Key> Key for ty::ParamEnvAnd<'tcx, T> {\n }\n \n impl<'tcx> Key for traits::Environment<'tcx> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -207,6 +250,8 @@ impl<'tcx> Key for traits::Environment<'tcx> {\n }\n \n impl Key for Symbol {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -218,6 +263,8 @@ impl Key for Symbol {\n /// Canonical query goals correspond to abstract trait operations that\n /// are not tied to any crate in particular.\n impl<'tcx, T> Key for Canonical<'tcx, T> {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }\n@@ -228,6 +275,8 @@ impl<'tcx, T> Key for Canonical<'tcx, T> {\n }\n \n impl Key for (Symbol, u32, u32) {\n+    type CacheSelector = DefaultCacheSelector;\n+\n     fn query_crate(&self) -> CrateNum {\n         LOCAL_CRATE\n     }"}, {"sha": "381a7b1f03ff73388bdd0cb5b7be41acac3cfdf8", "filename": "src/librustc/ty/query/mod.rs", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -1,4 +1,4 @@\n-use crate::dep_graph::{self, DepNode};\n+use crate::dep_graph::{self, DepConstructor, DepNode};\n use crate::hir::exports::Export;\n use crate::infer::canonical::{self, Canonical};\n use crate::lint::LintLevelMap;\n@@ -52,7 +52,6 @@ use rustc_target::spec::PanicStrategy;\n use rustc_attr as attr;\n use rustc_span::symbol::Symbol;\n use rustc_span::{Span, DUMMY_SP};\n-use std::any::type_name;\n use std::borrow::Cow;\n use std::convert::TryFrom;\n use std::ops::Deref;\n@@ -64,6 +63,9 @@ mod plumbing;\n use self::plumbing::*;\n pub use self::plumbing::{force_from_dep_node, CycleError};\n \n+mod stats;\n+pub use self::stats::print_stats;\n+\n mod job;\n #[cfg(parallel_compiler)]\n pub use self::job::handle_deadlock;\n@@ -76,6 +78,9 @@ use self::keys::Key;\n mod values;\n use self::values::Value;\n \n+mod caches;\n+use self::caches::CacheSelector;\n+\n mod config;\n use self::config::QueryAccessors;\n pub use self::config::QueryConfig;"}, {"sha": "b92081ff7c05f508b3e69073b9c287a6ec93584d", "filename": "src/librustc/ty/query/on_disk_cache.rs", "status": "modified", "additions": 17, "deletions": 15, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -1035,20 +1035,22 @@ where\n         .prof\n         .extra_verbose_generic_activity(\"encode_query_results_for\", ::std::any::type_name::<Q>());\n \n-    let shards = Q::query_cache(tcx).lock_shards();\n-    assert!(shards.iter().all(|shard| shard.active.is_empty()));\n-    for (key, entry) in shards.iter().flat_map(|shard| shard.results.iter()) {\n-        if Q::cache_on_disk(tcx, key.clone(), Some(&entry.value)) {\n-            let dep_node = SerializedDepNodeIndex::new(entry.index.index());\n-\n-            // Record position of the cache entry.\n-            query_result_index.push((dep_node, AbsoluteBytePos::new(encoder.position())));\n-\n-            // Encode the type check tables with the `SerializedDepNodeIndex`\n-            // as tag.\n-            encoder.encode_tagged(dep_node, &entry.value)?;\n-        }\n-    }\n+    let state = Q::query_state(tcx);\n+    assert!(state.all_inactive());\n+\n+    state.iter_results(|results| {\n+        for (key, value, dep_node) in results {\n+            if Q::cache_on_disk(tcx, key.clone(), Some(&value)) {\n+                let dep_node = SerializedDepNodeIndex::new(dep_node.index());\n+\n+                // Record position of the cache entry.\n+                query_result_index.push((dep_node, AbsoluteBytePos::new(encoder.position())));\n \n-    Ok(())\n+                // Encode the type check tables with the `SerializedDepNodeIndex`\n+                // as tag.\n+                encoder.encode_tagged(dep_node, &value)?;\n+            }\n+        }\n+        Ok(())\n+    })\n }"}, {"sha": "a61256b9fcbbc82652c873c20ef15ebd62c17d2e", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 265, "deletions": 258, "changes": 523, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -3,7 +3,8 @@\n //! manage the caches, and so forth.\n \n use crate::dep_graph::{DepKind, DepNode, DepNodeIndex, SerializedDepNodeIndex};\n-use crate::ty::query::config::{QueryConfig, QueryDescription};\n+use crate::ty::query::caches::QueryCache;\n+use crate::ty::query::config::{QueryAccessors, QueryDescription};\n use crate::ty::query::job::{QueryInfo, QueryJob, QueryJobId, QueryShardJobId};\n use crate::ty::query::Query;\n use crate::ty::tls;\n@@ -12,10 +13,8 @@ use crate::ty::{self, TyCtxt};\n #[cfg(not(parallel_compiler))]\n use rustc_data_structures::cold_path;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n-#[cfg(parallel_compiler)]\n-use rustc_data_structures::profiling::TimingGuard;\n use rustc_data_structures::sharded::Sharded;\n-use rustc_data_structures::sync::Lock;\n+use rustc_data_structures::sync::{Lock, LockGuard};\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, FatalError, Handler, Level};\n use rustc_span::source_map::DUMMY_SP;\n@@ -25,26 +24,50 @@ use std::hash::{Hash, Hasher};\n use std::mem;\n use std::num::NonZeroU32;\n use std::ptr;\n+#[cfg(debug_assertions)]\n+use std::sync::atomic::{AtomicUsize, Ordering};\n \n-pub struct QueryCache<'tcx, D: QueryConfig<'tcx> + ?Sized> {\n-    pub(super) results: FxHashMap<D::Key, QueryValue<D::Value>>,\n+pub(crate) struct QueryStateShard<'tcx, D: QueryAccessors<'tcx> + ?Sized> {\n+    pub(super) cache: <<D as QueryAccessors<'tcx>>::Cache as QueryCache<D::Key, D::Value>>::Sharded,\n     pub(super) active: FxHashMap<D::Key, QueryResult<'tcx>>,\n \n     /// Used to generate unique ids for active jobs.\n     pub(super) jobs: u32,\n+}\n \n-    #[cfg(debug_assertions)]\n-    pub(super) cache_hits: usize,\n+impl<'tcx, Q: QueryAccessors<'tcx>> QueryStateShard<'tcx, Q> {\n+    fn get_cache(\n+        &mut self,\n+    ) -> &mut <<Q as QueryAccessors<'tcx>>::Cache as QueryCache<Q::Key, Q::Value>>::Sharded {\n+        &mut self.cache\n+    }\n }\n \n-pub(super) struct QueryValue<T> {\n-    pub(super) value: T,\n-    pub(super) index: DepNodeIndex,\n+impl<'tcx, Q: QueryAccessors<'tcx>> Default for QueryStateShard<'tcx, Q> {\n+    fn default() -> QueryStateShard<'tcx, Q> {\n+        QueryStateShard { cache: Default::default(), active: Default::default(), jobs: 0 }\n+    }\n+}\n+\n+pub(crate) struct QueryState<'tcx, D: QueryAccessors<'tcx> + ?Sized> {\n+    pub(super) cache: D::Cache,\n+    pub(super) shards: Sharded<QueryStateShard<'tcx, D>>,\n+    #[cfg(debug_assertions)]\n+    pub(super) cache_hits: AtomicUsize,\n }\n \n-impl<T> QueryValue<T> {\n-    pub(super) fn new(value: T, dep_node_index: DepNodeIndex) -> QueryValue<T> {\n-        QueryValue { value, index: dep_node_index }\n+impl<'tcx, Q: QueryAccessors<'tcx>> QueryState<'tcx, Q> {\n+    pub(super) fn get_lookup<K: Hash>(&'tcx self, key: &K) -> QueryLookup<'tcx, Q> {\n+        // We compute the key's hash once and then use it for both the\n+        // shard lookup and the hashmap lookup. This relies on the fact\n+        // that both of them use `FxHasher`.\n+        let mut hasher = FxHasher::default();\n+        key.hash(&mut hasher);\n+        let key_hash = hasher.finish();\n+\n+        let shard = self.shards.get_shard_index_by_hash(key_hash);\n+        let lock = self.shards.get_shard_by_index(shard).lock();\n+        QueryLookup { key_hash, shard, lock }\n     }\n }\n \n@@ -58,142 +81,134 @@ pub(super) enum QueryResult<'tcx> {\n     Poisoned,\n }\n \n-impl<'tcx, M: QueryConfig<'tcx>> Default for QueryCache<'tcx, M> {\n-    fn default() -> QueryCache<'tcx, M> {\n-        QueryCache {\n-            results: FxHashMap::default(),\n-            active: FxHashMap::default(),\n-            jobs: 0,\n+impl<'tcx, M: QueryAccessors<'tcx>> QueryState<'tcx, M> {\n+    pub fn iter_results<R>(\n+        &self,\n+        f: impl for<'a> FnOnce(\n+            Box<dyn Iterator<Item = (&'a M::Key, &'a M::Value, DepNodeIndex)> + 'a>,\n+        ) -> R,\n+    ) -> R {\n+        self.cache.iter(&self.shards, |shard| &mut shard.cache, f)\n+    }\n+    pub fn all_inactive(&self) -> bool {\n+        let shards = self.shards.lock_shards();\n+        shards.iter().all(|shard| shard.active.is_empty())\n+    }\n+}\n+\n+impl<'tcx, M: QueryAccessors<'tcx>> Default for QueryState<'tcx, M> {\n+    fn default() -> QueryState<'tcx, M> {\n+        QueryState {\n+            cache: M::Cache::default(),\n+            shards: Default::default(),\n             #[cfg(debug_assertions)]\n-            cache_hits: 0,\n+            cache_hits: AtomicUsize::new(0),\n         }\n     }\n }\n \n+/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n+pub(crate) struct QueryLookup<'tcx, Q: QueryAccessors<'tcx>> {\n+    pub(super) key_hash: u64,\n+    pub(super) shard: usize,\n+    pub(super) lock: LockGuard<'tcx, QueryStateShard<'tcx, Q>>,\n+}\n+\n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n-pub(super) struct JobOwner<'a, 'tcx, Q: QueryDescription<'tcx>> {\n-    cache: &'a Sharded<QueryCache<'tcx, Q>>,\n+pub(super) struct JobOwner<'tcx, Q: QueryDescription<'tcx>> {\n+    tcx: TyCtxt<'tcx>,\n     key: Q::Key,\n     id: QueryJobId,\n }\n \n-impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n+impl<'tcx, Q: QueryDescription<'tcx>> JobOwner<'tcx, Q> {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n     /// start executing the query, or returns with the result of the query.\n-    /// If the query is executing elsewhere, this will wait for it.\n+    /// This function assumes that `try_get_cached` is already called and returned `lookup`.\n+    /// If the query is executing elsewhere, this will wait for it and return the result.\n     /// If the query panicked, this will silently panic.\n     ///\n     /// This function is inlined because that results in a noticeable speed-up\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n-    pub(super) fn try_get(tcx: TyCtxt<'tcx>, span: Span, key: &Q::Key) -> TryGetJob<'a, 'tcx, Q> {\n-        // Handling the `query_blocked_prof_timer` is a bit weird because of the\n-        // control flow in this function: Blocking is implemented by\n-        // awaiting a running job and, once that is done, entering the loop below\n-        // again from the top. In that second iteration we will hit the\n-        // cache which provides us with the information we need for\n-        // finishing the \"query-blocked\" event.\n-        //\n-        // We thus allocate `query_blocked_prof_timer` outside the loop,\n-        // initialize it during the first iteration and finish it during the\n-        // second iteration.\n-        #[cfg(parallel_compiler)]\n-        let mut query_blocked_prof_timer: Option<TimingGuard<'_>> = None;\n-\n-        let cache = Q::query_cache(tcx);\n-        loop {\n-            // We compute the key's hash once and then use it for both the\n-            // shard lookup and the hashmap lookup. This relies on the fact\n-            // that both of them use `FxHasher`.\n-            let mut state = FxHasher::default();\n-            key.hash(&mut state);\n-            let key_hash = state.finish();\n-\n-            let shard = cache.get_shard_index_by_hash(key_hash);\n-            let mut lock_guard = cache.get_shard_by_index(shard).lock();\n-            let lock = &mut *lock_guard;\n-\n-            if let Some((_, value)) =\n-                lock.results.raw_entry().from_key_hashed_nocheck(key_hash, key)\n-            {\n-                if unlikely!(tcx.prof.enabled()) {\n-                    tcx.prof.query_cache_hit(value.index.into());\n+    pub(super) fn try_start(\n+        tcx: TyCtxt<'tcx>,\n+        span: Span,\n+        key: &Q::Key,\n+        mut lookup: QueryLookup<'tcx, Q>,\n+    ) -> TryGetJob<'tcx, Q> {\n+        let lock = &mut *lookup.lock;\n+\n+        let (latch, mut _query_blocked_prof_timer) = match lock.active.entry((*key).clone()) {\n+            Entry::Occupied(mut entry) => {\n+                match entry.get_mut() {\n+                    QueryResult::Started(job) => {\n+                        // For parallel queries, we'll block and wait until the query running\n+                        // in another thread has completed. Record how long we wait in the\n+                        // self-profiler.\n+                        let _query_blocked_prof_timer = if cfg!(parallel_compiler) {\n+                            Some(tcx.prof.query_blocked())\n+                        } else {\n+                            None\n+                        };\n \n-                    #[cfg(parallel_compiler)]\n-                    {\n-                        if let Some(prof_timer) = query_blocked_prof_timer.take() {\n-                            prof_timer.finish_with_query_invocation_id(value.index.into());\n-                        }\n-                    }\n-                }\n+                        // Create the id of the job we're waiting for\n+                        let id = QueryJobId::new(job.id, lookup.shard, Q::dep_kind());\n \n-                let result = (value.value.clone(), value.index);\n-                #[cfg(debug_assertions)]\n-                {\n-                    lock.cache_hits += 1;\n+                        (job.latch(id), _query_blocked_prof_timer)\n+                    }\n+                    QueryResult::Poisoned => FatalError.raise(),\n                 }\n-                return TryGetJob::JobCompleted(result);\n             }\n+            Entry::Vacant(entry) => {\n+                // No job entry for this query. Return a new one to be started later.\n \n-            let latch = match lock.active.entry((*key).clone()) {\n-                Entry::Occupied(mut entry) => {\n-                    match entry.get_mut() {\n-                        QueryResult::Started(job) => {\n-                            // For parallel queries, we'll block and wait until the query running\n-                            // in another thread has completed. Record how long we wait in the\n-                            // self-profiler.\n-                            #[cfg(parallel_compiler)]\n-                            {\n-                                query_blocked_prof_timer = Some(tcx.prof.query_blocked());\n-                            }\n-\n-                            // Create the id of the job we're waiting for\n-                            let id = QueryJobId::new(job.id, shard, Q::dep_kind());\n-\n-                            job.latch(id)\n-                        }\n-                        QueryResult::Poisoned => FatalError.raise(),\n-                    }\n-                }\n-                Entry::Vacant(entry) => {\n-                    // No job entry for this query. Return a new one to be started later.\n+                // Generate an id unique within this shard.\n+                let id = lock.jobs.checked_add(1).unwrap();\n+                lock.jobs = id;\n+                let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n+\n+                let global_id = QueryJobId::new(id, lookup.shard, Q::dep_kind());\n \n-                    // Generate an id unique within this shard.\n-                    let id = lock.jobs.checked_add(1).unwrap();\n-                    lock.jobs = id;\n-                    let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n+                let job = tls::with_related_context(tcx, |icx| QueryJob::new(id, span, icx.query));\n \n-                    let global_id = QueryJobId::new(id, shard, Q::dep_kind());\n+                entry.insert(QueryResult::Started(job));\n \n-                    let job =\n-                        tls::with_related_context(tcx, |icx| QueryJob::new(id, span, icx.query));\n+                let owner = JobOwner { tcx, id: global_id, key: (*key).clone() };\n+                return TryGetJob::NotYetStarted(owner);\n+            }\n+        };\n+        mem::drop(lookup.lock);\n \n-                    entry.insert(QueryResult::Started(job));\n+        // If we are single-threaded we know that we have cycle error,\n+        // so we just return the error.\n+        #[cfg(not(parallel_compiler))]\n+        return TryGetJob::Cycle(cold_path(|| {\n+            Q::handle_cycle_error(tcx, latch.find_cycle_in_stack(tcx, span))\n+        }));\n \n-                    let owner = JobOwner { cache, id: global_id, key: (*key).clone() };\n-                    return TryGetJob::NotYetStarted(owner);\n-                }\n-            };\n-            mem::drop(lock_guard);\n+        // With parallel queries we might just have to wait on some other\n+        // thread.\n+        #[cfg(parallel_compiler)]\n+        {\n+            let result = latch.wait_on(tcx, span);\n \n-            // If we are single-threaded we know that we have cycle error,\n-            // so we just return the error.\n-            #[cfg(not(parallel_compiler))]\n-            return TryGetJob::Cycle(cold_path(|| {\n-                Q::handle_cycle_error(tcx, latch.find_cycle_in_stack(tcx, span))\n-            }));\n+            if let Err(cycle) = result {\n+                return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n+            }\n \n-            // With parallel queries we might just have to wait on some other\n-            // thread.\n-            #[cfg(parallel_compiler)]\n-            {\n-                let result = latch.wait_on(tcx, span);\n+            let cached = tcx.try_get_cached::<Q, _, _, _>(\n+                (*key).clone(),\n+                |value, index| (value.clone(), index),\n+                |_, _| panic!(\"value must be in cache after waiting\"),\n+            );\n \n-                if let Err(cycle) = result {\n-                    return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n-                }\n+            if let Some(prof_timer) = _query_blocked_prof_timer.take() {\n+                prof_timer.finish_with_query_invocation_id(cached.1.into());\n             }\n+\n+            return TryGetJob::JobCompleted(cached);\n         }\n     }\n \n@@ -203,19 +218,20 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n     pub(super) fn complete(self, result: &Q::Value, dep_node_index: DepNodeIndex) {\n         // We can move out of `self` here because we `mem::forget` it below\n         let key = unsafe { ptr::read(&self.key) };\n-        let cache = self.cache;\n+        let tcx = self.tcx;\n \n         // Forget ourself so our destructor won't poison the query\n         mem::forget(self);\n \n-        let value = QueryValue::new(result.clone(), dep_node_index);\n         let job = {\n-            let mut lock = cache.get_shard_by_value(&key).lock();\n+            let state = Q::query_state(tcx);\n+            let result = result.clone();\n+            let mut lock = state.shards.get_shard_by_value(&key).lock();\n             let job = match lock.active.remove(&key).unwrap() {\n                 QueryResult::Started(job) => job,\n                 QueryResult::Poisoned => panic!(),\n             };\n-            lock.results.insert(key, value);\n+            state.cache.complete(tcx, &mut lock.cache, key, result, dep_node_index);\n             job\n         };\n \n@@ -233,12 +249,13 @@ where\n     (result, diagnostics.into_inner())\n }\n \n-impl<'a, 'tcx, Q: QueryDescription<'tcx>> Drop for JobOwner<'a, 'tcx, Q> {\n+impl<'tcx, Q: QueryDescription<'tcx>> Drop for JobOwner<'tcx, Q> {\n     #[inline(never)]\n     #[cold]\n     fn drop(&mut self) {\n         // Poison the query so jobs waiting on it panic.\n-        let shard = self.cache.get_shard_by_value(&self.key);\n+        let state = Q::query_state(self.tcx);\n+        let shard = state.shards.get_shard_by_value(&self.key);\n         let job = {\n             let mut shard = shard.lock();\n             let job = match shard.active.remove(&self.key).unwrap() {\n@@ -261,14 +278,15 @@ pub struct CycleError<'tcx> {\n     pub(super) cycle: Vec<QueryInfo<'tcx>>,\n }\n \n-/// The result of `try_get_lock`.\n-pub(super) enum TryGetJob<'a, 'tcx, D: QueryDescription<'tcx>> {\n+/// The result of `try_start`.\n+pub(super) enum TryGetJob<'tcx, D: QueryDescription<'tcx>> {\n     /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'a, 'tcx, D>),\n+    NotYetStarted(JobOwner<'tcx, D>),\n \n     /// The query was already completed.\n     /// Returns the result of the query and its dep-node index\n     /// if it succeeded or a cycle error if it failed.\n+    #[cfg(parallel_compiler)]\n     JobCompleted((D::Value, DepNodeIndex)),\n \n     /// Trying to execute the query resulted in a cycle.\n@@ -396,13 +414,72 @@ impl<'tcx> TyCtxt<'tcx> {\n         eprintln!(\"end of query stack\");\n     }\n \n+    /// Checks if the query is already computed and in the cache.\n+    /// It returns the shard index and a lock guard to the shard,\n+    /// which will be used if the query is not in the cache and we need\n+    /// to compute it.\n+    #[inline(always)]\n+    fn try_get_cached<Q, R, OnHit, OnMiss>(\n+        self,\n+        key: Q::Key,\n+        // `on_hit` can be called while holding a lock to the query cache\n+        on_hit: OnHit,\n+        on_miss: OnMiss,\n+    ) -> R\n+    where\n+        Q: QueryDescription<'tcx> + 'tcx,\n+        OnHit: FnOnce(&Q::Value, DepNodeIndex) -> R,\n+        OnMiss: FnOnce(Q::Key, QueryLookup<'tcx, Q>) -> R,\n+    {\n+        let state = Q::query_state(self);\n+\n+        state.cache.lookup(\n+            state,\n+            QueryStateShard::<Q>::get_cache,\n+            key,\n+            |value, index| {\n+                if unlikely!(self.prof.enabled()) {\n+                    self.prof.query_cache_hit(index.into());\n+                }\n+                #[cfg(debug_assertions)]\n+                {\n+                    state.cache_hits.fetch_add(1, Ordering::Relaxed);\n+                }\n+                on_hit(value, index)\n+            },\n+            on_miss,\n+        )\n+    }\n+\n     #[inline(never)]\n-    pub(super) fn get_query<Q: QueryDescription<'tcx>>(self, span: Span, key: Q::Key) -> Q::Value {\n+    pub(super) fn get_query<Q: QueryDescription<'tcx> + 'tcx>(\n+        self,\n+        span: Span,\n+        key: Q::Key,\n+    ) -> Q::Value {\n         debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n \n-        let job = match JobOwner::try_get(self, span, &key) {\n+        self.try_get_cached::<Q, _, _, _>(\n+            key,\n+            |value, index| {\n+                self.dep_graph.read_index(index);\n+                value.clone()\n+            },\n+            |key, lookup| self.try_execute_query::<Q>(span, key, lookup),\n+        )\n+    }\n+\n+    #[inline(always)]\n+    pub(super) fn try_execute_query<Q: QueryDescription<'tcx>>(\n+        self,\n+        span: Span,\n+        key: Q::Key,\n+        lookup: QueryLookup<'tcx, Q>,\n+    ) -> Q::Value {\n+        let job = match JobOwner::try_start(self, span, &key, lookup) {\n             TryGetJob::NotYetStarted(job) => job,\n             TryGetJob::Cycle(result) => return result,\n+            #[cfg(parallel_compiler)]\n             TryGetJob::JobCompleted((v, index)) => {\n                 self.dep_graph.read_index(index);\n                 return v;\n@@ -560,7 +637,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     fn force_query_with_job<Q: QueryDescription<'tcx>>(\n         self,\n         key: Q::Key,\n-        job: JobOwner<'_, 'tcx, Q>,\n+        job: JobOwner<'tcx, Q>,\n         dep_node: DepNode,\n     ) -> (Q::Value, DepNodeIndex) {\n         // If the following assertion triggers, it can have two reasons:\n@@ -615,7 +692,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     /// side-effects -- e.g., in order to report errors for erroneous programs.\n     ///\n     /// Note: The optimization is only available during incr. comp.\n-    pub(super) fn ensure_query<Q: QueryDescription<'tcx>>(self, key: Q::Key) -> () {\n+    pub(super) fn ensure_query<Q: QueryDescription<'tcx> + 'tcx>(self, key: Q::Key) -> () {\n         if Q::EVAL_ALWAYS {\n             let _ = self.get_query::<Q>(DUMMY_SP, key);\n             return;\n@@ -643,14 +720,30 @@ impl<'tcx> TyCtxt<'tcx> {\n     }\n \n     #[allow(dead_code)]\n-    fn force_query<Q: QueryDescription<'tcx>>(self, key: Q::Key, span: Span, dep_node: DepNode) {\n+    fn force_query<Q: QueryDescription<'tcx> + 'tcx>(\n+        self,\n+        key: Q::Key,\n+        span: Span,\n+        dep_node: DepNode,\n+    ) {\n         // We may be concurrently trying both execute and force a query.\n         // Ensure that only one of them runs the query.\n-        let job = match JobOwner::try_get(self, span, &key) {\n-            TryGetJob::NotYetStarted(job) => job,\n-            TryGetJob::Cycle(_) | TryGetJob::JobCompleted(_) => return,\n-        };\n-        self.force_query_with_job::<Q>(key, job, dep_node);\n+\n+        self.try_get_cached::<Q, _, _, _>(\n+            key,\n+            |_, _| {\n+                // Cache hit, do nothing\n+            },\n+            |key, lookup| {\n+                let job = match JobOwner::try_start(self, span, &key, lookup) {\n+                    TryGetJob::NotYetStarted(job) => job,\n+                    TryGetJob::Cycle(_) => return,\n+                    #[cfg(parallel_compiler)]\n+                    TryGetJob::JobCompleted(_) => return,\n+                };\n+                self.force_query_with_job::<Q>(key, job, dep_node);\n+            },\n+        );\n     }\n }\n \n@@ -659,53 +752,65 @@ macro_rules! handle_cycle_error {\n         $tcx.report_cycle($error).emit();\n         Value::from_cycle_error($tcx)\n     }};\n-    ([fatal_cycle$(, $modifiers:ident)*][$tcx:expr, $error:expr]) => {{\n+    ([fatal_cycle $($rest:tt)*][$tcx:expr, $error:expr]) => {{\n         $tcx.report_cycle($error).emit();\n         $tcx.sess.abort_if_errors();\n         unreachable!()\n     }};\n-    ([cycle_delay_bug$(, $modifiers:ident)*][$tcx:expr, $error:expr]) => {{\n+    ([cycle_delay_bug $($rest:tt)*][$tcx:expr, $error:expr]) => {{\n         $tcx.report_cycle($error).delay_as_bug();\n         Value::from_cycle_error($tcx)\n     }};\n-    ([$other:ident$(, $modifiers:ident)*][$($args:tt)*]) => {\n-        handle_cycle_error!([$($modifiers),*][$($args)*])\n+    ([$other:ident $(($($other_args:tt)*))* $(, $($modifiers:tt)*)*][$($args:tt)*]) => {\n+        handle_cycle_error!([$($($modifiers)*)*][$($args)*])\n     };\n }\n \n macro_rules! is_anon {\n     ([]) => {{\n         false\n     }};\n-    ([anon$(, $modifiers:ident)*]) => {{\n+    ([anon $($rest:tt)*]) => {{\n         true\n     }};\n-    ([$other:ident$(, $modifiers:ident)*]) => {\n-        is_anon!([$($modifiers),*])\n+    ([$other:ident $(($($other_args:tt)*))* $(, $($modifiers:tt)*)*]) => {\n+        is_anon!([$($($modifiers)*)*])\n     };\n }\n \n macro_rules! is_eval_always {\n     ([]) => {{\n         false\n     }};\n-    ([eval_always$(, $modifiers:ident)*]) => {{\n+    ([eval_always $($rest:tt)*]) => {{\n         true\n     }};\n-    ([$other:ident$(, $modifiers:ident)*]) => {\n-        is_eval_always!([$($modifiers),*])\n+    ([$other:ident $(($($other_args:tt)*))* $(, $($modifiers:tt)*)*]) => {\n+        is_eval_always!([$($($modifiers)*)*])\n+    };\n+}\n+\n+macro_rules! query_storage {\n+    ([][$K:ty, $V:ty]) => {\n+        <<$K as Key>::CacheSelector as CacheSelector<$K, $V>>::Cache\n+    };\n+    ([storage($ty:ty) $($rest:tt)*][$K:ty, $V:ty]) => {\n+        $ty\n+    };\n+    ([$other:ident $(($($other_args:tt)*))* $(, $($modifiers:tt)*)*][$($args:tt)*]) => {\n+        query_storage!([$($($modifiers)*)*][$($args)*])\n     };\n }\n \n macro_rules! hash_result {\n     ([][$hcx:expr, $result:expr]) => {{\n         dep_graph::hash_result($hcx, &$result)\n     }};\n-    ([no_hash$(, $modifiers:ident)*][$hcx:expr, $result:expr]) => {{\n+    ([no_hash $($rest:tt)*][$hcx:expr, $result:expr]) => {{\n         None\n     }};\n-    ([$other:ident$(, $modifiers:ident)*][$($args:tt)*]) => {\n-        hash_result!([$($modifiers),*][$($args)*])\n+    ([$other:ident $(($($other_args:tt)*))* $(, $($modifiers:tt)*)*][$($args:tt)*]) => {\n+        hash_result!([$($($modifiers)*)*][$($args)*])\n     };\n }\n \n@@ -725,7 +830,6 @@ macro_rules! define_queries_inner {\n         [$($modifiers:tt)*] fn $name:ident: $node:ident($K:ty) -> $V:ty,)*) => {\n \n         use std::mem;\n-        use rustc_data_structures::sharded::Sharded;\n         use crate::{\n             rustc_data_structures::stable_hasher::HashStable,\n             rustc_data_structures::stable_hasher::StableHasher,\n@@ -760,11 +864,11 @@ macro_rules! define_queries_inner {\n                 $(\n                     // We use try_lock_shards here since we are called from the\n                     // deadlock handler, and this shouldn't be locked.\n-                    let shards = self.$name.try_lock_shards()?;\n+                    let shards = self.$name.shards.try_lock_shards()?;\n                     let shards = shards.iter().enumerate();\n                     jobs.extend(shards.flat_map(|(shard_id, shard)| {\n                         shard.active.iter().filter_map(move |(k, v)| {\n-                            if let QueryResult::Started(ref job) = *v {\n+                        if let QueryResult::Started(ref job) = *v {\n                                 let id = QueryJobId {\n                                     job: job.id,\n                                     shard:  u16::try_from(shard_id).unwrap(),\n@@ -776,111 +880,15 @@ macro_rules! define_queries_inner {\n                                     query: queries::$name::query(k.clone())\n                                 };\n                                 Some((id, QueryJobInfo { info,  job: job.clone() }))\n-                            } else {\n-                                None\n-                            }\n+                        } else {\n+                            None\n+                        }\n                         })\n                     }));\n                 )*\n \n                 Some(jobs)\n             }\n-\n-            pub fn print_stats(&self) {\n-                let mut queries = Vec::new();\n-\n-                #[derive(Clone)]\n-                struct QueryStats {\n-                    name: &'static str,\n-                    cache_hits: usize,\n-                    key_size: usize,\n-                    key_type: &'static str,\n-                    value_size: usize,\n-                    value_type: &'static str,\n-                    entry_count: usize,\n-                }\n-\n-                fn stats<'tcx, Q: QueryConfig<'tcx>>(\n-                    name: &'static str,\n-                    map: &Sharded<QueryCache<'tcx, Q>>,\n-                ) -> QueryStats {\n-                    let map = map.lock_shards();\n-                    QueryStats {\n-                        name,\n-                        #[cfg(debug_assertions)]\n-                        cache_hits: map.iter().map(|shard| shard.cache_hits).sum(),\n-                        #[cfg(not(debug_assertions))]\n-                        cache_hits: 0,\n-                        key_size: mem::size_of::<Q::Key>(),\n-                        key_type: type_name::<Q::Key>(),\n-                        value_size: mem::size_of::<Q::Value>(),\n-                        value_type: type_name::<Q::Value>(),\n-                        entry_count: map.iter().map(|shard| shard.results.len()).sum(),\n-                    }\n-                }\n-\n-                $(\n-                    queries.push(stats::<queries::$name<'_>>(\n-                        stringify!($name),\n-                        &self.$name,\n-                    ));\n-                )*\n-\n-                if cfg!(debug_assertions) {\n-                    let hits: usize = queries.iter().map(|s| s.cache_hits).sum();\n-                    let results: usize = queries.iter().map(|s| s.entry_count).sum();\n-                    println!(\"\\nQuery cache hit rate: {}\", hits as f64 / (hits + results) as f64);\n-                }\n-\n-                let mut query_key_sizes = queries.clone();\n-                query_key_sizes.sort_by_key(|q| q.key_size);\n-                println!(\"\\nLarge query keys:\");\n-                for q in query_key_sizes.iter().rev()\n-                                        .filter(|q| q.key_size > 8) {\n-                    println!(\n-                        \"   {} - {} x {} - {}\",\n-                        q.name,\n-                        q.key_size,\n-                        q.entry_count,\n-                        q.key_type\n-                    );\n-                }\n-\n-                let mut query_value_sizes = queries.clone();\n-                query_value_sizes.sort_by_key(|q| q.value_size);\n-                println!(\"\\nLarge query values:\");\n-                for q in query_value_sizes.iter().rev()\n-                                          .filter(|q| q.value_size > 8) {\n-                    println!(\n-                        \"   {} - {} x {} - {}\",\n-                        q.name,\n-                        q.value_size,\n-                        q.entry_count,\n-                        q.value_type\n-                    );\n-                }\n-\n-                if cfg!(debug_assertions) {\n-                    let mut query_cache_hits = queries.clone();\n-                    query_cache_hits.sort_by_key(|q| q.cache_hits);\n-                    println!(\"\\nQuery cache hits:\");\n-                    for q in query_cache_hits.iter().rev() {\n-                        println!(\n-                            \"   {} - {} ({}%)\",\n-                            q.name,\n-                            q.cache_hits,\n-                            q.cache_hits as f64 / (q.cache_hits + q.entry_count) as f64\n-                        );\n-                    }\n-                }\n-\n-                let mut query_value_count = queries.clone();\n-                query_value_count.sort_by_key(|q| q.entry_count);\n-                println!(\"\\nQuery value count:\");\n-                for q in query_value_count.iter().rev() {\n-                    println!(\"   {} - {}\", q.name, q.entry_count);\n-                }\n-            }\n         }\n \n         #[allow(nonstandard_style)]\n@@ -956,7 +964,6 @@ macro_rules! define_queries_inner {\n         $(impl<$tcx> QueryConfig<$tcx> for queries::$name<$tcx> {\n             type Key = $K;\n             type Value = $V;\n-\n             const NAME: &'static str = stringify!($name);\n             const CATEGORY: ProfileCategory = $category;\n         }\n@@ -965,22 +972,22 @@ macro_rules! define_queries_inner {\n             const ANON: bool = is_anon!([$($modifiers)*]);\n             const EVAL_ALWAYS: bool = is_eval_always!([$($modifiers)*]);\n \n+            type Cache = query_storage!([$($modifiers)*][$K, $V]);\n+\n             #[inline(always)]\n             fn query(key: Self::Key) -> Query<'tcx> {\n                 Query::$name(key)\n             }\n \n             #[inline(always)]\n-            fn query_cache<'a>(tcx: TyCtxt<$tcx>) -> &'a Sharded<QueryCache<$tcx, Self>> {\n+            fn query_state<'a>(tcx: TyCtxt<$tcx>) -> &'a QueryState<$tcx, Self> {\n                 &tcx.queries.$name\n             }\n \n             #[allow(unused)]\n             #[inline(always)]\n             fn to_dep_node(tcx: TyCtxt<$tcx>, key: &Self::Key) -> DepNode {\n-                use crate::dep_graph::DepConstructor::*;\n-\n-                DepNode::new(tcx, $node(*key))\n+                DepConstructor::$node(tcx, *key)\n             }\n \n             #[inline(always)]\n@@ -1132,7 +1139,7 @@ macro_rules! define_queries_struct {\n             providers: IndexVec<CrateNum, Providers<$tcx>>,\n             fallback_extern_providers: Box<Providers<$tcx>>,\n \n-            $($(#[$attr])*  $name: Sharded<QueryCache<$tcx, queries::$name<$tcx>>>,)*\n+            $($(#[$attr])*  $name: QueryState<$tcx, queries::$name<$tcx>>,)*\n         }\n     };\n }"}, {"sha": "99ada34d59ebed13c5b4829e107e0be83f973c40", "filename": "src/librustc/ty/query/profiling_support.rs", "status": "modified", "additions": 13, "deletions": 30, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -1,11 +1,10 @@\n use crate::hir::map::definitions::DefPathData;\n use crate::ty::context::TyCtxt;\n-use crate::ty::query::config::QueryConfig;\n-use crate::ty::query::plumbing::QueryCache;\n+use crate::ty::query::config::QueryAccessors;\n+use crate::ty::query::plumbing::QueryState;\n use measureme::{StringComponent, StringId};\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::profiling::SelfProfiler;\n-use rustc_data_structures::sharded::Sharded;\n use rustc_hir::def_id::{CrateNum, DefId, DefIndex, CRATE_DEF_INDEX, LOCAL_CRATE};\n use std::fmt::Debug;\n use std::io::Write;\n@@ -161,10 +160,10 @@ where\n pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, Q>(\n     tcx: TyCtxt<'tcx>,\n     query_name: &'static str,\n-    query_cache: &Sharded<QueryCache<'tcx, Q>>,\n+    query_state: &QueryState<'tcx, Q>,\n     string_cache: &mut QueryKeyStringCache,\n ) where\n-    Q: QueryConfig<'tcx>,\n+    Q: QueryAccessors<'tcx>,\n {\n     tcx.prof.with_profiler(|profiler| {\n         let event_id_builder = profiler.event_id_builder();\n@@ -181,20 +180,8 @@ pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, Q>(\n             // need to invoke queries itself, we cannot keep the query caches\n             // locked while doing so. Instead we copy out the\n             // `(query_key, dep_node_index)` pairs and release the lock again.\n-            let query_keys_and_indices = {\n-                let shards = query_cache.lock_shards();\n-                let len = shards.iter().map(|shard| shard.results.len()).sum();\n-\n-                let mut query_keys_and_indices = Vec::with_capacity(len);\n-\n-                for shard in &shards {\n-                    query_keys_and_indices.extend(\n-                        shard.results.iter().map(|(q_key, q_val)| (q_key.clone(), q_val.index)),\n-                    );\n-                }\n-\n-                query_keys_and_indices\n-            };\n+            let query_keys_and_indices: Vec<_> = query_state\n+                .iter_results(|results| results.map(|(k, _, i)| (k.clone(), i)).collect());\n \n             // Now actually allocate the strings. If allocating the strings\n             // generates new entries in the query cache, we'll miss them but\n@@ -218,18 +205,14 @@ pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, Q>(\n             let query_name = profiler.get_or_alloc_cached_string(query_name);\n             let event_id = event_id_builder.from_label(query_name).to_string_id();\n \n-            let shards = query_cache.lock_shards();\n+            query_state.iter_results(|results| {\n+                let query_invocation_ids: Vec<_> = results.map(|v| v.2.into()).collect();\n \n-            for shard in shards.iter() {\n-                let query_invocation_ids = shard\n-                    .results\n-                    .values()\n-                    .map(|v| v.index)\n-                    .map(|dep_node_index| dep_node_index.into());\n-\n-                profiler\n-                    .bulk_map_query_invocation_id_to_single_string(query_invocation_ids, event_id);\n-            }\n+                profiler.bulk_map_query_invocation_id_to_single_string(\n+                    query_invocation_ids.into_iter(),\n+                    event_id,\n+                );\n+            });\n         }\n     });\n }"}, {"sha": "d257320d4eaf652242660491b94603750217d6ed", "filename": "src/librustc/ty/query/stats.rs", "status": "added", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fstats.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc%2Fty%2Fquery%2Fstats.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fstats.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -0,0 +1,139 @@\n+use crate::ty::query::config::QueryAccessors;\n+use crate::ty::query::plumbing::QueryState;\n+use crate::ty::query::queries;\n+use crate::ty::TyCtxt;\n+use rustc_hir::def_id::{DefId, LOCAL_CRATE};\n+\n+use std::any::type_name;\n+use std::mem;\n+#[cfg(debug_assertions)]\n+use std::sync::atomic::Ordering;\n+\n+trait KeyStats {\n+    fn key_stats(&self, stats: &mut QueryStats);\n+}\n+\n+impl<T> KeyStats for T {\n+    default fn key_stats(&self, _: &mut QueryStats) {}\n+}\n+\n+impl KeyStats for DefId {\n+    fn key_stats(&self, stats: &mut QueryStats) {\n+        if self.krate == LOCAL_CRATE {\n+            stats.local_def_id_keys = Some(stats.local_def_id_keys.unwrap_or(0) + 1);\n+        }\n+    }\n+}\n+\n+#[derive(Clone)]\n+struct QueryStats {\n+    name: &'static str,\n+    cache_hits: usize,\n+    key_size: usize,\n+    key_type: &'static str,\n+    value_size: usize,\n+    value_type: &'static str,\n+    entry_count: usize,\n+    local_def_id_keys: Option<usize>,\n+}\n+\n+fn stats<'tcx, Q: QueryAccessors<'tcx>>(\n+    name: &'static str,\n+    map: &QueryState<'tcx, Q>,\n+) -> QueryStats {\n+    let mut stats = QueryStats {\n+        name,\n+        #[cfg(debug_assertions)]\n+        cache_hits: map.cache_hits.load(Ordering::Relaxed),\n+        #[cfg(not(debug_assertions))]\n+        cache_hits: 0,\n+        key_size: mem::size_of::<Q::Key>(),\n+        key_type: type_name::<Q::Key>(),\n+        value_size: mem::size_of::<Q::Value>(),\n+        value_type: type_name::<Q::Value>(),\n+        entry_count: map.iter_results(|results| results.count()),\n+        local_def_id_keys: None,\n+    };\n+    map.iter_results(|results| {\n+        for (key, _, _) in results {\n+            key.key_stats(&mut stats)\n+        }\n+    });\n+    stats\n+}\n+\n+pub fn print_stats(tcx: TyCtxt<'_>) {\n+    let queries = query_stats(tcx);\n+\n+    if cfg!(debug_assertions) {\n+        let hits: usize = queries.iter().map(|s| s.cache_hits).sum();\n+        let results: usize = queries.iter().map(|s| s.entry_count).sum();\n+        println!(\"\\nQuery cache hit rate: {}\", hits as f64 / (hits + results) as f64);\n+    }\n+\n+    let mut query_key_sizes = queries.clone();\n+    query_key_sizes.sort_by_key(|q| q.key_size);\n+    println!(\"\\nLarge query keys:\");\n+    for q in query_key_sizes.iter().rev().filter(|q| q.key_size > 8) {\n+        println!(\"   {} - {} x {} - {}\", q.name, q.key_size, q.entry_count, q.key_type);\n+    }\n+\n+    let mut query_value_sizes = queries.clone();\n+    query_value_sizes.sort_by_key(|q| q.value_size);\n+    println!(\"\\nLarge query values:\");\n+    for q in query_value_sizes.iter().rev().filter(|q| q.value_size > 8) {\n+        println!(\"   {} - {} x {} - {}\", q.name, q.value_size, q.entry_count, q.value_type);\n+    }\n+\n+    if cfg!(debug_assertions) {\n+        let mut query_cache_hits = queries.clone();\n+        query_cache_hits.sort_by_key(|q| q.cache_hits);\n+        println!(\"\\nQuery cache hits:\");\n+        for q in query_cache_hits.iter().rev() {\n+            println!(\n+                \"   {} - {} ({}%)\",\n+                q.name,\n+                q.cache_hits,\n+                q.cache_hits as f64 / (q.cache_hits + q.entry_count) as f64\n+            );\n+        }\n+    }\n+\n+    let mut query_value_count = queries.clone();\n+    query_value_count.sort_by_key(|q| q.entry_count);\n+    println!(\"\\nQuery value count:\");\n+    for q in query_value_count.iter().rev() {\n+        println!(\"   {} - {}\", q.name, q.entry_count);\n+    }\n+\n+    let mut def_id_density: Vec<_> =\n+        queries.iter().filter(|q| q.local_def_id_keys.is_some()).collect();\n+    def_id_density.sort_by_key(|q| q.local_def_id_keys.unwrap());\n+    println!(\"\\nLocal DefId density:\");\n+    let total = tcx.hir().definitions().def_index_count() as f64;\n+    for q in def_id_density.iter().rev() {\n+        let local = q.local_def_id_keys.unwrap();\n+        println!(\"   {} - {} = ({}%)\", q.name, local, (local as f64 * 100.0) / total);\n+    }\n+}\n+\n+macro_rules! print_stats {\n+    (<$tcx:tt> $($category:tt {\n+        $($(#[$attr:meta])* [$($modifiers:tt)*] fn $name:ident: $node:ident($K:ty) -> $V:ty,)*\n+    },)*) => {\n+        fn query_stats(tcx: TyCtxt<'_>) -> Vec<QueryStats> {\n+            let mut queries = Vec::new();\n+\n+            $($(\n+                queries.push(stats::<queries::$name<'_>>(\n+                    stringify!($name),\n+                    &tcx.queries.$name,\n+                ));\n+            )*)*\n+\n+            queries\n+        }\n+    }\n+}\n+\n+rustc_query_append! { [print_stats!][<'tcx>] }"}, {"sha": "f2c80510f226945413530eef779359c3b5e0f577", "filename": "src/librustc_data_structures/profiling.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_data_structures%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_data_structures%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fprofiling.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -81,6 +81,7 @@\n //!\n //! [mm]: https://github.com/rust-lang/measureme/\n \n+use crate::cold_path;\n use crate::fx::FxHashMap;\n \n use std::borrow::Borrow;\n@@ -531,9 +532,11 @@ impl<'a> TimingGuard<'a> {\n     #[inline]\n     pub fn finish_with_query_invocation_id(self, query_invocation_id: QueryInvocationId) {\n         if let Some(guard) = self.0 {\n-            let event_id = StringId::new_virtual(query_invocation_id.0);\n-            let event_id = EventId::from_virtual(event_id);\n-            guard.finish_with_override_event_id(event_id);\n+            cold_path(|| {\n+                let event_id = StringId::new_virtual(query_invocation_id.0);\n+                let event_id = EventId::from_virtual(event_id);\n+                guard.finish_with_override_event_id(event_id);\n+            });\n         }\n     }\n "}, {"sha": "a98e77cebd88aaa2249c170e5084895caf7aa4fd", "filename": "src/librustc_data_structures/stable_hasher.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_data_structures%2Fstable_hasher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_data_structures%2Fstable_hasher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fstable_hasher.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -27,6 +27,7 @@ pub trait StableHasherResult: Sized {\n }\n \n impl StableHasher {\n+    #[inline]\n     pub fn new() -> Self {\n         StableHasher { state: SipHasher128::new_with_keys(0, 0) }\n     }"}, {"sha": "96a2ac08f2c49c7e5a5d553665ec614c4dd97106", "filename": "src/librustc_interface/passes.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_interface%2Fpasses.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_interface%2Fpasses.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Fpasses.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -696,8 +696,8 @@ impl<'tcx> QueryContext<'tcx> {\n         ty::tls::enter_global(self.0, |tcx| f(tcx))\n     }\n \n-    pub fn print_stats(&self) {\n-        self.0.queries.print_stats()\n+    pub fn print_stats(&mut self) {\n+        self.enter(|tcx| ty::query::print_stats(tcx))\n     }\n }\n "}, {"sha": "0c77ab57500a0785bc66eece5de3a82df6210129", "filename": "src/librustc_interface/queries.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_interface%2Fqueries.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_interface%2Fqueries.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Fqueries.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -340,7 +340,7 @@ impl Compiler {\n \n         if self.session().opts.debugging_opts.query_stats {\n             if let Ok(gcx) = queries.global_ctxt() {\n-                gcx.peek().print_stats();\n+                gcx.peek_mut().print_stats();\n             }\n         }\n "}, {"sha": "6362f3c2c49f03929543ff72f9b204768ae75fcf", "filename": "src/librustc_macros/src/query.rs", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_macros%2Fsrc%2Fquery.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_macros%2Fsrc%2Fquery.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_macros%2Fsrc%2Fquery.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -33,6 +33,9 @@ enum QueryModifier {\n     /// The description of the query.\n     Desc(Option<Ident>, Punctuated<Expr, Token![,]>),\n \n+    /// Use this type for the in-memory cache.\n+    Storage(Type),\n+\n     /// Cache the query to disk if the `Expr` returns true.\n     Cache(Option<(IdentOrWild, IdentOrWild)>, Block),\n \n@@ -106,6 +109,9 @@ impl Parse for QueryModifier {\n             let id = args.parse()?;\n             let block = input.parse()?;\n             Ok(QueryModifier::LoadCached(tcx, id, block))\n+        } else if modifier == \"storage\" {\n+            let ty = input.parse()?;\n+            Ok(QueryModifier::Storage(ty))\n         } else if modifier == \"fatal_cycle\" {\n             Ok(QueryModifier::FatalCycle)\n         } else if modifier == \"cycle_delay_bug\" {\n@@ -198,6 +204,9 @@ struct QueryModifiers {\n     /// The description of the query.\n     desc: Option<(Option<Ident>, Punctuated<Expr, Token![,]>)>,\n \n+    /// Use this type for the in-memory cache.\n+    storage: Option<Type>,\n+\n     /// Cache the query to disk if the `Block` returns true.\n     cache: Option<(Option<(IdentOrWild, IdentOrWild)>, Block)>,\n \n@@ -226,6 +235,7 @@ struct QueryModifiers {\n /// Process query modifiers into a struct, erroring on duplicates\n fn process_modifiers(query: &mut Query) -> QueryModifiers {\n     let mut load_cached = None;\n+    let mut storage = None;\n     let mut cache = None;\n     let mut desc = None;\n     let mut fatal_cycle = false;\n@@ -242,6 +252,12 @@ fn process_modifiers(query: &mut Query) -> QueryModifiers {\n                 }\n                 load_cached = Some((tcx, id, block));\n             }\n+            QueryModifier::Storage(ty) => {\n+                if storage.is_some() {\n+                    panic!(\"duplicate modifier `storage` for query `{}`\", query.name);\n+                }\n+                storage = Some(ty);\n+            }\n             QueryModifier::Cache(args, expr) => {\n                 if cache.is_some() {\n                     panic!(\"duplicate modifier `cache` for query `{}`\", query.name);\n@@ -294,6 +310,7 @@ fn process_modifiers(query: &mut Query) -> QueryModifiers {\n     }\n     QueryModifiers {\n         load_cached,\n+        storage,\n         cache,\n         desc,\n         fatal_cycle,\n@@ -451,6 +468,10 @@ pub fn rustc_queries(input: TokenStream) -> TokenStream {\n             if modifiers.fatal_cycle {\n                 attributes.push(quote! { fatal_cycle });\n             };\n+            // Pass on the storage modifier\n+            if let Some(ref ty) = modifiers.storage {\n+                attributes.push(quote! { storage(#ty) });\n+            };\n             // Pass on the cycle_delay_bug modifier\n             if modifiers.cycle_delay_bug {\n                 attributes.push(quote! { cycle_delay_bug });"}, {"sha": "2fb7977dce9eeced5169eeb9f3800563ea82bf45", "filename": "src/librustc_session/session.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_session%2Fsession.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d5638142b32935508626226d0f0cf9059db40789/src%2Flibrustc_session%2Fsession.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_session%2Fsession.rs?ref=d5638142b32935508626226d0f0cf9059db40789", "patch": "@@ -392,6 +392,7 @@ impl Session {\n         );\n     }\n \n+    #[inline]\n     pub fn source_map(&self) -> &source_map::SourceMap {\n         self.parse_sess.source_map()\n     }"}]}