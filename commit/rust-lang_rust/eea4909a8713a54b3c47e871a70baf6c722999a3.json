{"sha": "eea4909a8713a54b3c47e871a70baf6c722999a3", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVlYTQ5MDlhODcxM2E1NGIzYzQ3ZTg3MWE3MGJhZjZjNzIyOTk5YTM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-04-25T06:41:15Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-04-25T06:41:15Z"}, "message": "auto merge of #13700 : BurntSushi/rust/regexp, r=alexcrichton\n\nImplements [RFC 7](https://github.com/rust-lang/rfcs/blob/master/active/0007-regexps.md) and will hopefully resolve #3591. The crate is marked as experimental. It includes a syntax extension for compiling regexps to native Rust code.\r\n\r\nEmbeds and passes the `basic`, `nullsubexpr` and `repetition` tests from [Glenn Fowler's (slightly modified by Russ Cox for leftmost-first semantics) testregex test suite](http://www2.research.att.com/~astopen/testregex/testregex.html). I've also hand written a plethora of other tests that exercise Unicode support, the parser, public API, etc. Also includes a `regex-dna` benchmark for the shootout.\r\n\r\nI know the addition looks huge at first, but consider these things:\r\n\r\n1. More than half the number of lines is dedicated to Unicode character classes.\r\n2. Of the ~4,500 lines remaining, 1,225 of them are comments.\r\n3. Another ~800 are tests.\r\n4. That leaves 2500 lines for the meat. The parser is ~850 of them. The public API, compiler, dynamic VM and code generator (for `regexp!`) make up the rest.", "tree": {"sha": "b01796a9342a4763e0701712c72f8fe22672c789", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b01796a9342a4763e0701712c72f8fe22672c789"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/eea4909a8713a54b3c47e871a70baf6c722999a3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/eea4909a8713a54b3c47e871a70baf6c722999a3", "html_url": "https://github.com/rust-lang/rust/commit/eea4909a8713a54b3c47e871a70baf6c722999a3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/eea4909a8713a54b3c47e871a70baf6c722999a3/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2bb2341a4af75fb54b809a8e1d5aacbca4df56fc", "url": "https://api.github.com/repos/rust-lang/rust/commits/2bb2341a4af75fb54b809a8e1d5aacbca4df56fc", "html_url": "https://github.com/rust-lang/rust/commit/2bb2341a4af75fb54b809a8e1d5aacbca4df56fc"}, {"sha": "7269bc77e1d1f1babfd159db97024cbd535c47a7", "url": "https://api.github.com/repos/rust-lang/rust/commits/7269bc77e1d1f1babfd159db97024cbd535c47a7", "html_url": "https://github.com/rust-lang/rust/commit/7269bc77e1d1f1babfd159db97024cbd535c47a7"}], "stats": {"total": 11114, "additions": 11108, "deletions": 6}, "files": [{"sha": "fc0afa6df62711d8d8ace9828c378d2f9192d729", "filename": "mk/crates.mk", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/mk%2Fcrates.mk", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/mk%2Fcrates.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fcrates.mk?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -51,8 +51,8 @@\n \n TARGET_CRATES := libc std green rustuv native flate arena glob term semver \\\n                  uuid serialize sync getopts collections num test time rand \\\n-\t\t workcache url log\n-HOST_CRATES := syntax rustc rustdoc fourcc hexfloat\n+\t\t workcache url log regex\n+HOST_CRATES := syntax rustc rustdoc fourcc hexfloat regex_macros\n CRATES := $(TARGET_CRATES) $(HOST_CRATES)\n TOOLS := compiletest rustdoc rustc\n \n@@ -84,6 +84,8 @@ DEPS_rand := std\n DEPS_url := std collections\n DEPS_workcache := std serialize collections log\n DEPS_log := std sync\n+DEPS_regex := std collections\n+DEPS_regex_macros = syntax std regex\n \n TOOL_DEPS_compiletest := test green rustuv getopts\n TOOL_DEPS_rustdoc := rustdoc native"}, {"sha": "685dd0b51829bf7124b0de4329c7b610a3346228", "filename": "mk/main.mk", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/mk%2Fmain.mk", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/mk%2Fmain.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fmain.mk?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -311,8 +311,6 @@ HSREQ$(1)_H_$(3) = $$(HBIN$(1)_H_$(3))/rustc$$(X_$(3))\n else\n HSREQ$(1)_H_$(3) = \\\n \t$$(HBIN$(1)_H_$(3))/rustc$$(X_$(3)) \\\n-\t$$(HLIB$(1)_H_$(3))/stamp.rustc \\\n-\t$$(foreach dep,$$(RUST_DEPS_rustc),$$(HLIB$(1)_H_$(3))/stamp.$$(dep)) \\\n \t$$(MKFILE_DEPS)\n endif\n \n@@ -334,8 +332,7 @@ SREQ$(1)_T_$(2)_H_$(3) = \\\n CSREQ$(1)_T_$(2)_H_$(3) = \\\n \t$$(TSREQ$(1)_T_$(2)_H_$(3)) \\\n \t$$(HBIN$(1)_H_$(3))/rustdoc$$(X_$(3)) \\\n-\t$$(foreach dep,$$(CRATES),$$(TLIB$(1)_T_$(2)_H_$(3))/stamp.$$(dep)) \\\n-\t$$(foreach dep,$$(HOST_CRATES),$$(HLIB$(1)_H_$(3))/stamp.$$(dep))\n+\t$$(foreach dep,$$(CRATES),$$(TLIB$(1)_T_$(2)_H_$(3))/stamp.$$(dep))\n \n ifeq ($(1),0)\n # Don't run the stage0 compiler under valgrind - that ship has sailed"}, {"sha": "de9a793bafc9645783d5c4286da27324b7e24ae2", "filename": "src/README.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FREADME.md?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -19,6 +19,7 @@ Source layout:\n | `libfourcc/`        | Data format identifier library                            |\n | `libgetopts/`       | Get command-line-options library                          |\n | `libglob/`          | Unix glob patterns library                                |\n+| `libregex/`         | Regular expressions                                       |\n | `libsemver/`        | Rust's semantic versioning library                        |\n | `libserialize/`     | Encode-Decode types library                               |\n | `libsync/`          | Concurrency mechanisms and primitives                     |"}, {"sha": "0bfc9baaa1688ad6002cf881fd38935053a4389e", "filename": "src/doc/index.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Fdoc%2Findex.md", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Fdoc%2Findex.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Findex.md?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -41,6 +41,7 @@ li {list-style-type: none; }\n * [The `native` 1:1 threading runtime](native/index.html)\n * [The `num` arbitrary precision numerics library](num/index.html)\n * [The `rand` library for random numbers and distributions](rand/index.html)\n+* [The `regex` library for regular expressions](regex/index.html)\n * [The `rustc` compiler](rustc/index.html)\n * [The `rustuv` M:N I/O library](rustuv/index.html)\n * [The `semver` version collation library](semver/index.html)"}, {"sha": "826af961fce06dd7d4162936da1c40b28db82fbc", "filename": "src/etc/regex-match-tests.py", "status": "added", "additions": 109, "deletions": 0, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Fetc%2Fregex-match-tests.py", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Fetc%2Fregex-match-tests.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fregex-match-tests.py?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,109 @@\n+#!/usr/bin/env python2\n+\n+# Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+# file at the top-level directory of this distribution and at\n+# http://rust-lang.org/COPYRIGHT.\n+#\n+# Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+# http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+# <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+# option. This file may not be copied, modified, or distributed\n+# except according to those terms.\n+\n+from __future__ import absolute_import, division, print_function\n+import argparse\n+import datetime\n+import os.path as path\n+\n+\n+def print_tests(tests):\n+    print('\\n'.join([test_tostr(t) for t in tests]))\n+\n+\n+def read_tests(f):\n+    basename, _ = path.splitext(path.basename(f))\n+    tests = []\n+    for lineno, line in enumerate(open(f), 1):\n+        fields = filter(None, map(str.strip, line.split('\\t')))\n+        if not (4 <= len(fields) <= 5) \\\n+           or 'E' not in fields[0] or fields[0][0] == '#':\n+            continue\n+\n+        opts, pat, text, sgroups = fields[0:4]\n+        groups = []  # groups as integer ranges\n+        if sgroups == 'NOMATCH':\n+            groups = [None]\n+        elif ',' in sgroups:\n+            noparen = map(lambda s: s.strip('()'), sgroups.split(')('))\n+            for g in noparen:\n+                s, e = map(str.strip, g.split(','))\n+                if s == '?' and e == '?':\n+                    groups.append(None)\n+                else:\n+                    groups.append((int(s), int(e)))\n+        else:\n+            # This skips tests that should result in an error.\n+            # There aren't many, so I think we can just capture those\n+            # manually. Possibly fix this in future.\n+            continue\n+\n+        if pat == 'SAME':\n+            pat = tests[-1][1]\n+        if '$' in opts:\n+            pat = pat.decode('string_escape')\n+            text = text.decode('string_escape')\n+        if 'i' in opts:\n+            pat = '(?i)%s' % pat\n+\n+        name = '%s_%d' % (basename, lineno)\n+        tests.append((name, pat, text, groups))\n+    return tests\n+\n+\n+def test_tostr(t):\n+    lineno, pat, text, groups = t\n+    options = map(group_tostr, groups)\n+    return 'mat!(match_%s, r\"%s\", r\"%s\", %s)' \\\n+           % (lineno, pat, '' if text == \"NULL\" else text, ', '.join(options))\n+\n+\n+def group_tostr(g):\n+    if g is None:\n+        return 'None'\n+    else:\n+        return 'Some((%d, %d))' % (g[0], g[1])\n+\n+\n+if __name__ == '__main__':\n+    parser = argparse.ArgumentParser(\n+        description='Generate match tests from an AT&T POSIX test file.')\n+    aa = parser.add_argument\n+    aa('files', nargs='+',\n+       help='A list of dat AT&T POSIX test files. See src/libregexp/testdata')\n+    args = parser.parse_args()\n+\n+    tests = []\n+    for f in args.files:\n+        tests += read_tests(f)\n+\n+    tpl = '''// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// ignore-tidy-linelength\n+\n+// DO NOT EDIT. Automatically generated by 'src/etc/regexp-match-tests'\n+// on {date}.\n+'''\n+    print(tpl.format(date=str(datetime.datetime.now())))\n+\n+    for f in args.files:\n+        print('// Tests from %s' % path.basename(f))\n+        print_tests(read_tests(f))\n+        print('')"}, {"sha": "5dc404736a4032452b4d62c5322b0c66b2832839", "filename": "src/etc/regex-unicode-tables.py", "status": "added", "additions": 183, "deletions": 0, "changes": 183, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Fetc%2Fregex-unicode-tables.py", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Fetc%2Fregex-unicode-tables.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fregex-unicode-tables.py?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,183 @@\n+#!/usr/bin/env python2\n+\n+# Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+# file at the top-level directory of this distribution and at\n+# http://rust-lang.org/COPYRIGHT.\n+#\n+# Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+# http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+# <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+# option. This file may not be copied, modified, or distributed\n+# except according to those terms.\n+\n+from __future__ import absolute_import, division, print_function\n+import argparse\n+from collections import defaultdict\n+import csv\n+import datetime\n+import urllib2\n+\n+BASE_URL = 'http://www.unicode.org/Public/6.3.0/ucd/'\n+DATA = 'UnicodeData.txt'\n+SCRIPTS = 'Scripts.txt'\n+\n+# Mapping taken from Table 12 from:\n+# http://www.unicode.org/reports/tr44/#General_Category_Values\n+expanded_categories = {\n+    'Lu': ['LC', 'L'], 'Ll': ['LC', 'L'], 'Lt': ['LC', 'L'],\n+    'Lm': ['L'], 'Lo': ['L'],\n+    'Mn': ['M'], 'Mc': ['M'], 'Me': ['M'],\n+    'Nd': ['N'], 'Nl': ['N'], 'No': ['No'],\n+    'Pc': ['P'], 'Pd': ['P'], 'Ps': ['P'], 'Pe': ['P'],\n+    'Pi': ['P'], 'Pf': ['P'], 'Po': ['P'],\n+    'Sm': ['S'], 'Sc': ['S'], 'Sk': ['S'], 'So': ['S'],\n+    'Zs': ['Z'], 'Zl': ['Z'], 'Zp': ['Z'],\n+    'Cc': ['C'], 'Cf': ['C'], 'Cs': ['C'], 'Co': ['C'], 'Cn': ['C'],\n+}\n+\n+\n+def as_4byte_uni(n):\n+    s = hex(n)[2:]\n+    return '\\\\U%s%s' % ('0' * (8 - len(s)), s)\n+\n+\n+def expand_cat(c):\n+    return expanded_categories.get(c, []) + [c]\n+\n+\n+def is_valid_unicode(n):\n+    return 0 <= n <= 0xD7FF or 0xE000 <= n <= 0x10FFFF\n+\n+\n+def read_cats(f):\n+    assigned = defaultdict(list)\n+    for row in csv.reader(f, delimiter=';'):\n+        (hex, cats) = (int(row[0], 16), expand_cat(row[2]))\n+        if not is_valid_unicode(hex):\n+            continue\n+        for cat in cats:\n+            assigned[cat].append(hex)\n+    return assigned\n+\n+\n+def read_scripts(f):\n+    assigned = defaultdict(list)\n+    for line in f:\n+        line = line.strip()\n+        if not line or line.startswith('#'):\n+            continue\n+        hexes, name = map(str.strip, line.split(';'))[:2]\n+        name = name[:name.index('#')].strip()\n+        if '..' not in hexes:\n+            hex = int(hexes, 16)\n+            if is_valid_unicode(hex):\n+                assigned[name].append(hex)\n+        else:\n+            hex1, hex2 = map(lambda s: int(s, 16), hexes.split('..'))\n+            for hex in xrange(hex1, hex2 + 1):\n+                if is_valid_unicode(hex):\n+                    assigned[name].append(hex)\n+    return assigned\n+\n+\n+def group(letters):\n+    letters = sorted(set(letters))\n+    grouped = []\n+    cur_start = letters.pop(0)\n+    cur_end = cur_start\n+    for letter in letters:\n+        assert letter > cur_end, \\\n+            'cur_end: %s, letter: %s' % (hex(cur_end), hex(letter))\n+\n+        if letter == cur_end + 1:\n+            cur_end = letter\n+        else:\n+            grouped.append((cur_start, cur_end))\n+            cur_start, cur_end = letter, letter\n+    grouped.append((cur_start, cur_end))\n+    return grouped\n+\n+\n+def ranges_to_rust(rs):\n+    rs = (\"('%s', '%s')\" % (as_4byte_uni(s), as_4byte_uni(e)) for s, e in rs)\n+    return ',\\n    '.join(rs)\n+\n+\n+def groups_to_rust(groups):\n+    rust_groups = []\n+    for group_name in sorted(groups):\n+        rust_groups.append('(\"%s\", &[\\n    %s\\n    ]),'\n+                           % (group_name, ranges_to_rust(groups[group_name])))\n+    return '\\n'.join(rust_groups)\n+\n+\n+if __name__ == '__main__':\n+    parser = argparse.ArgumentParser(\n+        description='Generate Unicode character class tables.')\n+    aa = parser.add_argument\n+    aa('--local', action='store_true',\n+       help='When set, Scripts.txt and UnicodeData.txt will be read from '\n+            'the CWD.')\n+    aa('--base-url', type=str, default=BASE_URL,\n+       help='The base URL to use for downloading Unicode data files.')\n+    args = parser.parse_args()\n+\n+    if args.local:\n+        cats = read_cats(open(DATA))\n+        scripts = read_scripts(open(SCRIPTS))\n+    else:\n+        cats = read_cats(urllib2.urlopen(args.base_url + '/' + DATA))\n+        scripts = read_scripts(urllib2.urlopen(args.base_url + '/' + SCRIPTS))\n+\n+    # Get Rust code for all Unicode general categories and scripts.\n+    combined = dict(cats, **scripts)\n+    unigroups = groups_to_rust({k: group(letters)\n+                                for k, letters in combined.items()})\n+\n+    # Now get Perl character classes that are Unicode friendly.\n+    perld = range(ord('0'), ord('9') + 1)\n+    dgroups = ranges_to_rust(group(perld + cats['Nd'][:]))\n+\n+    perls = map(ord, ['\\t', '\\n', '\\x0C', '\\r', ' '])\n+    sgroups = ranges_to_rust(group(perls + cats['Z'][:]))\n+\n+    low, up = (range(ord('a'), ord('z') + 1), range(ord('A'), ord('Z') + 1))\n+    perlw = [ord('_')] + perld + low + up\n+    wgroups = ranges_to_rust(group(perlw + cats['L'][:]))\n+\n+    tpl = '''// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// DO NOT EDIT. Automatically generated by 'src/etc/regexp-unicode-tables'\n+// on {date}.\n+\n+use parse::{{Class, NamedClasses}};\n+\n+pub static UNICODE_CLASSES: NamedClasses = &[\n+\n+{groups}\n+\n+];\n+\n+pub static PERLD: Class = &[\n+    {dgroups}\n+];\n+\n+pub static PERLS: Class = &[\n+    {sgroups}\n+];\n+\n+pub static PERLW: Class = &[\n+    {wgroups}\n+];\n+'''\n+    now = datetime.datetime.now()\n+    print(tpl.format(date=str(now), groups=unigroups,\n+                     dgroups=dgroups, sgroups=sgroups, wgroups=wgroups))"}, {"sha": "3987d755050993cb95f61c299001b7a3fad8dc6c", "filename": "src/libregex/compile.rs", "status": "added", "additions": 274, "deletions": 0, "changes": 274, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fcompile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fcompile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fcompile.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,274 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// Enable this to squash warnings due to exporting pieces of the representation\n+// for use with the regex! macro. See lib.rs for explanation.\n+#![allow(visible_private_types)]\n+\n+use std::cmp;\n+use std::iter;\n+use parse;\n+use parse::{\n+    Flags, FLAG_EMPTY,\n+    Nothing, Literal, Dot, Class, Begin, End, WordBoundary, Capture, Cat, Alt,\n+    Rep,\n+    ZeroOne, ZeroMore, OneMore,\n+};\n+\n+type InstIdx = uint;\n+\n+#[deriving(Show, Clone)]\n+pub enum Inst {\n+    // When a Match instruction is executed, the current thread is successful.\n+    Match,\n+\n+    // The OneChar instruction matches a literal character.\n+    // The flags indicate whether to do a case insensitive match.\n+    OneChar(char, Flags),\n+\n+    // The CharClass instruction tries to match one input character against\n+    // the range of characters given.\n+    // The flags indicate whether to do a case insentivie match and whether\n+    // the character class is negated or not.\n+    CharClass(Vec<(char, char)>, Flags),\n+\n+    // Matches any character except new lines.\n+    // The flags indicate whether to include the '\\n' character.\n+    Any(Flags),\n+\n+    // Matches the beginning of the string, consumes no characters.\n+    // The flags indicate whether it matches if the preceding character\n+    // is a new line.\n+    EmptyBegin(Flags),\n+\n+    // Matches the end of the string, consumes no characters.\n+    // The flags indicate whether it matches if the proceding character\n+    // is a new line.\n+    EmptyEnd(Flags),\n+\n+    // Matches a word boundary (\\w on one side and \\W \\A or \\z on the other),\n+    // and consumes no character.\n+    // The flags indicate whether this matches a word boundary or something\n+    // that isn't a word boundary.\n+    EmptyWordBoundary(Flags),\n+\n+    // Saves the current position in the input string to the Nth save slot.\n+    Save(uint),\n+\n+    // Jumps to the instruction at the index given.\n+    Jump(InstIdx),\n+\n+    // Jumps to the instruction at the first index given. If that leads to\n+    // a failing state, then the instruction at the second index given is\n+    // tried.\n+    Split(InstIdx, InstIdx),\n+}\n+\n+/// Program represents a compiled regular expression. Once an expression is\n+/// compiled, its representation is immutable and will never change.\n+///\n+/// All of the data in a compiled expression is wrapped in \"MaybeStatic\" or\n+/// \"MaybeOwned\" types so that a `Program` can be represented as static data.\n+/// (This makes it convenient and efficient for use with the `regex!` macro.)\n+#[deriving(Clone)]\n+pub struct Program {\n+    /// A sequence of instructions.\n+    pub insts: Vec<Inst>,\n+    /// If the regular expression requires a literal prefix in order to have a\n+    /// match, that prefix is stored here. (It's used in the VM to implement\n+    /// an optimization.)\n+    pub prefix: ~str,\n+}\n+\n+impl Program {\n+    /// Compiles a Regex given its AST.\n+    pub fn new(ast: ~parse::Ast) -> (Program, ~[Option<~str>]) {\n+        let mut c = Compiler {\n+            insts: Vec::with_capacity(100),\n+            names: Vec::with_capacity(10),\n+        };\n+\n+        c.insts.push(Save(0));\n+        c.compile(ast);\n+        c.insts.push(Save(1));\n+        c.insts.push(Match);\n+\n+        // Try to discover a literal string prefix.\n+        // This is a bit hacky since we have to skip over the initial\n+        // 'Save' instruction.\n+        let mut pre = StrBuf::with_capacity(5);\n+        for i in iter::range(1, c.insts.len()) {\n+            match *c.insts.get(i) {\n+                OneChar(c, FLAG_EMPTY) => pre.push_char(c),\n+                _ => break\n+            }\n+        }\n+\n+        let names = c.names.as_slice().into_owned();\n+        let prog = Program {\n+            insts: c.insts,\n+            prefix: pre.into_owned(),\n+        };\n+        (prog, names)\n+    }\n+\n+    /// Returns the total number of capture groups in the regular expression.\n+    /// This includes the zeroth capture.\n+    pub fn num_captures(&self) -> uint {\n+        let mut n = 0;\n+        for inst in self.insts.iter() {\n+            match *inst {\n+                Save(c) => n = cmp::max(n, c+1),\n+                _ => {}\n+            }\n+        }\n+        // There's exactly 2 Save slots for every capture.\n+        n / 2\n+    }\n+}\n+\n+struct Compiler<'r> {\n+    insts: Vec<Inst>,\n+    names: Vec<Option<~str>>,\n+}\n+\n+// The compiler implemented here is extremely simple. Most of the complexity\n+// in this crate is in the parser or the VM.\n+// The only tricky thing here is patching jump/split instructions to point to\n+// the right instruction.\n+impl<'r> Compiler<'r> {\n+    fn compile(&mut self, ast: ~parse::Ast) {\n+        match ast {\n+            ~Nothing => {},\n+            ~Literal(c, flags) => self.push(OneChar(c, flags)),\n+            ~Dot(nl) => self.push(Any(nl)),\n+            ~Class(ranges, flags) =>\n+                self.push(CharClass(ranges, flags)),\n+            ~Begin(flags) => self.push(EmptyBegin(flags)),\n+            ~End(flags) => self.push(EmptyEnd(flags)),\n+            ~WordBoundary(flags) => self.push(EmptyWordBoundary(flags)),\n+            ~Capture(cap, name, x) => {\n+                let len = self.names.len();\n+                if cap >= len {\n+                    self.names.grow(10 + cap - len, &None)\n+                }\n+                *self.names.get_mut(cap) = name;\n+\n+                self.push(Save(2 * cap));\n+                self.compile(x);\n+                self.push(Save(2 * cap + 1));\n+            }\n+            ~Cat(xs) => {\n+                for x in xs.move_iter() {\n+                    self.compile(x)\n+                }\n+            }\n+            ~Alt(x, y) => {\n+                let split = self.empty_split(); // push: split 0, 0\n+                let j1 = self.insts.len();\n+                self.compile(x);                // push: insts for x\n+                let jmp = self.empty_jump();    // push: jmp 0\n+                let j2 = self.insts.len();\n+                self.compile(y);                // push: insts for y\n+                let j3 = self.insts.len();\n+\n+                self.set_split(split, j1, j2);  // split 0, 0 -> split j1, j2\n+                self.set_jump(jmp, j3);         // jmp 0      -> jmp j3\n+            }\n+            ~Rep(x, ZeroOne, g) => {\n+                let split = self.empty_split();\n+                let j1 = self.insts.len();\n+                self.compile(x);\n+                let j2 = self.insts.len();\n+\n+                if g.is_greedy() {\n+                    self.set_split(split, j1, j2);\n+                } else {\n+                    self.set_split(split, j2, j1);\n+                }\n+            }\n+            ~Rep(x, ZeroMore, g) => {\n+                let j1 = self.insts.len();\n+                let split = self.empty_split();\n+                let j2 = self.insts.len();\n+                self.compile(x);\n+                let jmp = self.empty_jump();\n+                let j3 = self.insts.len();\n+\n+                self.set_jump(jmp, j1);\n+                if g.is_greedy() {\n+                    self.set_split(split, j2, j3);\n+                } else {\n+                    self.set_split(split, j3, j2);\n+                }\n+            }\n+            ~Rep(x, OneMore, g) => {\n+                let j1 = self.insts.len();\n+                self.compile(x);\n+                let split = self.empty_split();\n+                let j2 = self.insts.len();\n+\n+                if g.is_greedy() {\n+                    self.set_split(split, j1, j2);\n+                } else {\n+                    self.set_split(split, j2, j1);\n+                }\n+            }\n+        }\n+    }\n+\n+    /// Appends the given instruction to the program.\n+    #[inline]\n+    fn push(&mut self, x: Inst) {\n+        self.insts.push(x)\n+    }\n+\n+    /// Appends an *empty* `Split` instruction to the program and returns\n+    /// the index of that instruction. (The index can then be used to \"patch\"\n+    /// the actual locations of the split in later.)\n+    #[inline]\n+    fn empty_split(&mut self) -> InstIdx {\n+        self.insts.push(Split(0, 0));\n+        self.insts.len() - 1\n+    }\n+\n+    /// Sets the left and right locations of a `Split` instruction at index\n+    /// `i` to `pc1` and `pc2`, respectively.\n+    /// If the instruction at index `i` isn't a `Split` instruction, then\n+    /// `fail!` is called.\n+    #[inline]\n+    fn set_split(&mut self, i: InstIdx, pc1: InstIdx, pc2: InstIdx) {\n+        let split = self.insts.get_mut(i);\n+        match *split {\n+            Split(_, _) => *split = Split(pc1, pc2),\n+            _ => fail!(\"BUG: Invalid split index.\"),\n+        }\n+    }\n+\n+    /// Appends an *empty* `Jump` instruction to the program and returns the\n+    /// index of that instruction.\n+    #[inline]\n+    fn empty_jump(&mut self) -> InstIdx {\n+        self.insts.push(Jump(0));\n+        self.insts.len() - 1\n+    }\n+\n+    /// Sets the location of a `Jump` instruction at index `i` to `pc`.\n+    /// If the instruction at index `i` isn't a `Jump` instruction, then\n+    /// `fail!` is called.\n+    #[inline]\n+    fn set_jump(&mut self, i: InstIdx, pc: InstIdx) {\n+        let jmp = self.insts.get_mut(i);\n+        match *jmp {\n+            Jump(_) => *jmp = Jump(pc),\n+            _ => fail!(\"BUG: Invalid jump index.\"),\n+        }\n+    }\n+}"}, {"sha": "cd5d387bfa0d6f4cd4a1b795e967ebdb25bf39f9", "filename": "src/libregex/lib.rs", "status": "added", "additions": 426, "deletions": 0, "changes": 426, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Flib.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,426 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! This crate provides a native implementation of regular expressions that is\n+//! heavily based on RE2 both in syntax and in implementation. Notably,\n+//! backreferences and arbitrary lookahead/lookbehind assertions are not\n+//! provided. In return, regular expression searching provided by this package\n+//! has excellent worst case performance. The specific syntax supported is\n+//! documented further down.\n+//!\n+//! This crate's documentation provides some simple examples, describes Unicode\n+//! support and exhaustively lists the supported syntax. For more specific\n+//! details on the API, please see the documentation for the `Regex` type.\n+//!\n+//! # First example: find a date\n+//!\n+//! General use of regular expressions in this package involves compiling an\n+//! expression and then using it to search, split or replace text. For example,\n+//! to confirm that some text resembles a date:\n+//!\n+//! ```rust\n+//! use regex::Regex;\n+//! let re = match Regex::new(r\"^\\d{4}-\\d{2}-\\d{2}$\") {\n+//!     Ok(re) => re,\n+//!     Err(err) => fail!(\"{}\", err),\n+//! };\n+//! assert_eq!(re.is_match(\"2014-01-01\"), true);\n+//! ```\n+//!\n+//! Notice the use of the `^` and `$` anchors. In this crate, every expression\n+//! is executed with an implicit `.*?` at the beginning and end, which allows\n+//! it to match anywhere in the text. Anchors can be used to ensure that the\n+//! full text matches an expression.\n+//!\n+//! This example also demonstrates the utility of raw strings in Rust, which\n+//! are just like regular strings except they are prefixed with an `r` and do\n+//! not process any escape sequences. For example, `\"\\\\d\"` is the same\n+//! expression as `r\"\\d\"`.\n+//!\n+//! # The `regex!` macro\n+//!\n+//! Rust's compile time meta-programming facilities provide a way to write a\n+//! `regex!` macro which compiles regular expressions *when your program\n+//! compiles*. Said differently, if you only use `regex!` to build regular\n+//! expressions in your program, then your program cannot compile with an\n+//! invalid regular expression. Moreover, the `regex!` macro compiles the\n+//! given expression to native Rust code, which makes it much faster for\n+//! searching text.\n+//!\n+//! Since `regex!` provides compiled regular expressions that are both safer\n+//! and faster to use, you should use them whenever possible. The only\n+//! requirement for using them is that you have a string literal corresponding\n+//! to your expression. Otherwise, it is indistinguishable from an expression\n+//! compiled at runtime with `Regex::new`.\n+//!\n+//! To use the `regex!` macro, you must enable the `phase` feature and import\n+//! the `regex_macros` crate as a syntax extension:\n+//!\n+//! ```rust\n+//! #![feature(phase)]\n+//! #[phase(syntax)]\n+//! extern crate regex_macros;\n+//! extern crate regex;\n+//!\n+//! fn main() {\n+//!     let re = regex!(r\"^\\d{4}-\\d{2}-\\d{2}$\");\n+//!     assert_eq!(re.is_match(\"2014-01-01\"), true);\n+//! }\n+//! ```\n+//!\n+//! There are a few things worth mentioning about using the `regex!` macro.\n+//! Firstly, the `regex!` macro *only* accepts string *literals*.\n+//! Secondly, the `regex` crate *must* be linked with the name `regex` since\n+//! the generated code depends on finding symbols in the `regex` crate.\n+//!\n+//! The only downside of using the `regex!` macro is that it can increase the\n+//! size of your program's binary since it generates specialized Rust code.\n+//! The extra size probably won't be significant for a small number of\n+//! expressions, but 100+ calls to `regex!` will probably result in a\n+//! noticeably bigger binary.\n+//!\n+//! # Example: iterating over capture groups\n+//!\n+//! This crate provides convenient iterators for matching an expression\n+//! repeatedly against a search string to find successive non-overlapping\n+//! matches. For example, to find all dates in a string and be able to access\n+//! them by their component pieces:\n+//!\n+//! ```rust\n+//! # #![feature(phase)]\n+//! # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+//! # fn main() {\n+//! let re = regex!(r\"(\\d{4})-(\\d{2})-(\\d{2})\");\n+//! let text = \"2012-03-14, 2013-01-01 and 2014-07-05\";\n+//! for cap in re.captures_iter(text) {\n+//!     println!(\"Month: {} Day: {} Year: {}\", cap.at(2), cap.at(3), cap.at(1));\n+//! }\n+//! // Output:\n+//! // Month: 03 Day: 14 Year: 2012\n+//! // Month: 01 Day: 01 Year: 2013\n+//! // Month: 07 Day: 05 Year: 2014\n+//! # }\n+//! ```\n+//!\n+//! Notice that the year is in the capture group indexed at `1`. This is\n+//! because the *entire match* is stored in the capture group at index `0`.\n+//!\n+//! # Example: replacement with named capture groups\n+//!\n+//! Building on the previous example, perhaps we'd like to rearrange the date\n+//! formats. This can be done with text replacement. But to make the code\n+//! clearer, we can *name*  our capture groups and use those names as variables\n+//! in our replacement text:\n+//!\n+//! ```rust\n+//! # #![feature(phase)]\n+//! # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+//! # fn main() {\n+//! let re = regex!(r\"(?P<y>\\d{4})-(?P<m>\\d{2})-(?P<d>\\d{2})\");\n+//! let before = \"2012-03-14, 2013-01-01 and 2014-07-05\";\n+//! let after = re.replace_all(before, \"$m/$d/$y\");\n+//! assert_eq!(after.as_slice(), \"03/14/2012, 01/01/2013 and 07/05/2014\");\n+//! # }\n+//! ```\n+//!\n+//! The `replace` methods are actually polymorphic in the replacement, which\n+//! provides more flexibility than is seen here. (See the documentation for\n+//! `Regex::replace` for more details.)\n+//!\n+//! # Pay for what you use\n+//!\n+//! With respect to searching text with a regular expression, there are three\n+//! questions that can be asked:\n+//!\n+//! 1. Does the text match this expression?\n+//! 2. If so, where does it match?\n+//! 3. Where are the submatches?\n+//!\n+//! Generally speaking, this crate could provide a function to answer only #3,\n+//! which would subsume #1 and #2 automatically. However, it can be\n+//! significantly more expensive to compute the location of submatches, so it's\n+//! best not to do it if you don't need to.\n+//!\n+//! Therefore, only use what you need. For example, don't use `find` if you\n+//! only need to test if an expression matches a string. (Use `is_match`\n+//! instead.)\n+//!\n+//! # Unicode\n+//!\n+//! This implementation executes regular expressions **only** on sequences of\n+//! UTF8 codepoints while exposing match locations as byte indices.\n+//!\n+//! Currently, only naive case folding is supported. Namely, when matching\n+//! case insensitively, the characters are first converted to their uppercase\n+//! forms and then compared.\n+//!\n+//! Regular expressions themselves are also **only** interpreted as a sequence\n+//! of UTF8 codepoints. This means you can embed Unicode characters directly\n+//! into your expression:\n+//!\n+//! ```rust\n+//! # #![feature(phase)]\n+//! # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+//! # fn main() {\n+//! let re = regex!(r\"(?i)\u0394+\");\n+//! assert_eq!(re.find(\"\u0394\u03b4\u0394\"), Some((0, 6)));\n+//! # }\n+//! ```\n+//!\n+//! Finally, Unicode general categories and scripts are available as character\n+//! classes. For example, you can match a sequence of numerals, Greek or\n+//! Cherokee letters:\n+//!\n+//! ```rust\n+//! # #![feature(phase)]\n+//! # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+//! # fn main() {\n+//! let re = regex!(r\"[\\pN\\p{Greek}\\p{Cherokee}]+\");\n+//! assert_eq!(re.find(\"abc\u0394\u13a0\u03b2\u2160\u13f4\u03b3\u03b4\u2161xyz\"), Some((3, 23)));\n+//! # }\n+//! ```\n+//!\n+//! # Syntax\n+//!\n+//! The syntax supported in this crate is almost in an exact correspondence\n+//! with the syntax supported by RE2.\n+//!\n+//! ## Matching one character\n+//!\n+//! <pre class=\"rust\">\n+//! .           any character except new line (includes new line with s flag)\n+//! [xyz]       A character class matching either x, y or z.\n+//! [^xyz]      A character class matching any character except x, y and z.\n+//! [a-z]       A character class matching any character in range a-z.\n+//! \\d          Perl character class ([0-9])\n+//! \\D          Negated Perl character class ([^0-9])\n+//! [:alpha:]   ASCII character class ([A-Za-z])\n+//! [:^alpha:]  Negated ASCII character class ([^A-Za-z])\n+//! \\pN         One letter name Unicode character class\n+//! \\p{Greek}   Unicode character class (general category or script)\n+//! \\PN         Negated one letter name Unicode character class\n+//! \\P{Greek}   negated Unicode character class (general category or script)\n+//! </pre>\n+//!\n+//! Any named character class may appear inside a bracketed `[...]` character\n+//! class. For example, `[\\p{Greek}\\pN]` matches any Greek or numeral\n+//! character.\n+//!\n+//! ## Composites\n+//!\n+//! <pre class=\"rust\">\n+//! xy    concatenation (x followed by y)\n+//! x|y   alternation (x or y, prefer x)\n+//! </pre>\n+//!\n+//! ## Repetitions\n+//!\n+//! <pre class=\"rust\">\n+//! x*        zero or more of x (greedy)\n+//! x+        one or more of x (greedy)\n+//! x?        zero or one of x (greedy)\n+//! x*?       zero or more of x (ungreedy)\n+//! x+?       one or more of x (ungreedy)\n+//! x??       zero or one of x (ungreedy)\n+//! x{n,m}    at least n and at most x (greedy)\n+//! x{n,}     at least n x (greedy)\n+//! x{n}      exactly n x\n+//! x{n,m}?   at least n and at most x (ungreedy)\n+//! x{n,}?    at least n x (ungreedy)\n+//! x{n}?     exactly n x\n+//! </pre>\n+//!\n+//! ## Empty matches\n+//!\n+//! <pre class=\"rust\">\n+//! ^     the beginning of text (or start-of-line with multi-line mode)\n+//! $     the end of text (or end-of-line with multi-line mode)\n+//! \\A    only the beginning of text (even with multi-line mode enabled)\n+//! \\z    only the end of text (even with multi-line mode enabled)\n+//! \\b    a Unicode word boundary (\\w on one side and \\W, \\A, or \\z on other)\n+//! \\B    not a Unicode word boundary\n+//! </pre>\n+//!\n+//! ## Grouping and flags\n+//!\n+//! <pre class=\"rust\">\n+//! (exp)          numbered capture group (indexed by opening parenthesis)\n+//! (?P&lt;name&gt;exp)  named (also numbered) capture group (allowed chars: [_0-9a-zA-Z])\n+//! (?:exp)        non-capturing group\n+//! (?flags)       set flags within current group\n+//! (?flags:exp)   set flags for exp (non-capturing)\n+//! </pre>\n+//!\n+//! Flags are each a single character. For example, `(?x)` sets the flag `x`\n+//! and `(?-x)` clears the flag `x`. Multiple flags can be set or cleared at\n+//! the same time: `(?xy)` sets both the `x` and `y` flags and `(?x-y)` sets\n+//! the `x` flag and clears the `y` flag.\n+//!\n+//! All flags are by default disabled. They are:\n+//!\n+//! <pre class=\"rust\">\n+//! i     case insensitive\n+//! m     multi-line mode: ^ and $ match begin/end of line\n+//! s     allow . to match \\n\n+//! U     swap the meaning of x* and x*?\n+//! </pre>\n+//!\n+//! Here's an example that matches case insensitively for only part of the\n+//! expression:\n+//!\n+//! ```rust\n+//! # #![feature(phase)]\n+//! # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+//! # fn main() {\n+//! let re = regex!(r\"(?i)a+(?-i)b+\");\n+//! let cap = re.captures(\"AaAaAbbBBBb\").unwrap();\n+//! assert_eq!(cap.at(0), \"AaAaAbb\");\n+//! # }\n+//! ```\n+//!\n+//! Notice that the `a+` matches either `a` or `A`, but the `b+` only matches\n+//! `b`.\n+//!\n+//! ## Escape sequences\n+//!\n+//! <pre class=\"rust\">\n+//! \\*         literal *, works for any punctuation character: \\.+*?()|[]{}^$\n+//! \\a         bell (\\x07)\n+//! \\f         form feed (\\x0C)\n+//! \\t         horizontal tab\n+//! \\n         new line\n+//! \\r         carriage return\n+//! \\v         vertical tab (\\x0B)\n+//! \\123       octal character code (up to three digits)\n+//! \\x7F       hex character code (exactly two digits)\n+//! \\x{10FFFF} any hex character code corresponding to a valid UTF8 codepoint\n+//! </pre>\n+//!\n+//! ## Perl character classes (Unicode friendly)\n+//!\n+//! <pre class=\"rust\">\n+//! \\d     digit ([0-9] + \\p{Nd})\n+//! \\D     not digit\n+//! \\s     whitespace ([\\t\\n\\f\\r ] + \\p{Z})\n+//! \\S     not whitespace\n+//! \\w     word character ([0-9A-Za-z_] + \\p{L})\n+//! \\W     not word character\n+//! </pre>\n+//!\n+//! ## ASCII character classes\n+//!\n+//! <pre class=\"rust\">\n+//! [:alnum:]    alphanumeric ([0-9A-Za-z])\n+//! [:alpha:]    alphabetic ([A-Za-z])\n+//! [:ascii:]    ASCII ([\\x00-\\x7F])\n+//! [:blank:]    blank ([\\t ])\n+//! [:cntrl:]    control ([\\x00-\\x1F\\x7F])\n+//! [:digit:]    digits ([0-9])\n+//! [:graph:]    graphical ([!-~])\n+//! [:lower:]    lower case ([a-z])\n+//! [:print:]    printable ([ -~])\n+//! [:punct:]    punctuation ([!-/:-@[-`{-~])\n+//! [:space:]    whitespace ([\\t\\n\\v\\f\\r ])\n+//! [:upper:]    upper case ([A-Z])\n+//! [:word:]     word characters ([0-9A-Za-z_])\n+//! [:xdigit:]   hex digit ([0-9A-Fa-f])\n+//! </pre>\n+//!\n+//! # Untrusted input\n+//!\n+//! There are two factors to consider here: untrusted regular expressions and\n+//! untrusted search text.\n+//!\n+//! Currently, there are no counter-measures in place to prevent a malicious\n+//! user from writing an expression that may use a lot of resources. One such\n+//! example is to repeat counted repetitions: `((a{100}){100}){100}` will try\n+//! to repeat the `a` instruction `100^3` times. Essentially, this means it's\n+//! very easy for an attacker to exhaust your system's memory if they are\n+//! allowed to execute arbitrary regular expressions. A possible solution to\n+//! this is to impose a hard limit on the size of a compiled expression, but it\n+//! does not yet exist.\n+//!\n+//! The story is a bit better with untrusted search text, since this crate's\n+//! implementation provides `O(nm)` search where `n` is the number of\n+//! characters in the search text and `m` is the number of instructions in a\n+//! compiled expression.\n+\n+#![crate_id = \"regex#0.11-pre\"]\n+#![crate_type = \"rlib\"]\n+#![crate_type = \"dylib\"]\n+#![experimental]\n+#![license = \"MIT/ASL2\"]\n+#![doc(html_logo_url = \"http://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n+       html_favicon_url = \"http://www.rust-lang.org/favicon.ico\",\n+       html_root_url = \"http://static.rust-lang.org/doc/master\")]\n+\n+#![feature(macro_rules, phase)]\n+#![deny(missing_doc)]\n+\n+extern crate collections;\n+#[cfg(test)]\n+extern crate stdtest = \"test\";\n+#[cfg(test)]\n+extern crate rand;\n+\n+// During tests, this links with the `regex` crate so that the `regex!` macro\n+// can be tested.\n+#[cfg(test)]\n+extern crate regex;\n+\n+pub use parse::Error;\n+pub use re::{Regex, Captures, SubCaptures, SubCapturesPos};\n+pub use re::{FindCaptures, FindMatches};\n+pub use re::{Replacer, NoExpand, RegexSplits, RegexSplitsN};\n+pub use re::{quote, is_match};\n+\n+mod compile;\n+mod parse;\n+mod re;\n+mod vm;\n+\n+// FIXME(#13725) windows needs fixing.\n+#[cfg(test, not(windows))]\n+mod test;\n+\n+/// The `program` module exists to support the `regex!` macro. Do not use.\n+#[doc(hidden)]\n+pub mod native {\n+    // Exporting this stuff is bad form, but it's necessary for two reasons.\n+    // Firstly, the `regex!` syntax extension is in a different crate and\n+    // requires access to the representation of a regex (particularly the\n+    // instruction set) in order to compile to native Rust. This could be\n+    // mitigated if `regex!` was defined in the same crate, but this has\n+    // undesirable consequences (such as requiring a dependency on\n+    // `libsyntax`).\n+    //\n+    // Secondly, the code generated generated by `regex!` must *also* be able\n+    // to access various functions in this crate to reduce code duplication\n+    // and to provide a value with precisely the same `Regex` type in this\n+    // crate. This, AFAIK, is impossible to mitigate.\n+    //\n+    // On the bright side, `rustdoc` lets us hide this from the public API\n+    // documentation.\n+    pub use compile::{\n+        Program,\n+        OneChar, CharClass, Any, Save, Jump, Split,\n+        Match, EmptyBegin, EmptyEnd, EmptyWordBoundary,\n+    };\n+    pub use parse::{\n+        FLAG_EMPTY, FLAG_NOCASE, FLAG_MULTI, FLAG_DOTNL,\n+        FLAG_SWAP_GREED, FLAG_NEGATED,\n+    };\n+    pub use re::{Dynamic, Native};\n+    pub use vm::{\n+        MatchKind, Exists, Location, Submatches,\n+        StepState, StepMatchEarlyReturn, StepMatch, StepContinue,\n+        CharReader, find_prefix,\n+    };\n+}"}, {"sha": "27510f01bd676a8027934c874d13473c77fd00c6", "filename": "src/libregex/parse.rs", "status": "added", "additions": 1028, "deletions": 0, "changes": 1028, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fparse.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,1028 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use std::char;\n+use std::cmp;\n+use std::fmt;\n+use std::iter;\n+use std::num;\n+use std::str;\n+\n+/// Static data containing Unicode ranges for general categories and scripts.\n+use self::unicode::{UNICODE_CLASSES, PERLD, PERLS, PERLW};\n+#[allow(visible_private_types)]\n+pub mod unicode;\n+\n+/// The maximum number of repetitions allowed with the `{n,m}` syntax.\n+static MAX_REPEAT: uint = 1000;\n+\n+/// Error corresponds to something that can go wrong while parsing\n+/// a regular expression.\n+///\n+/// (Once an expression is compiled, it is not possible to produce an error\n+/// via searching, splitting or replacing.)\n+pub struct Error {\n+    /// The *approximate* character index of where the error occurred.\n+    pub pos: uint,\n+    /// A message describing the error.\n+    pub msg: ~str,\n+}\n+\n+impl fmt::Show for Error {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        write!(f.buf, \"Regex syntax error near position {}: {}\",\n+               self.pos, self.msg)\n+    }\n+}\n+\n+/// Represents the abstract syntax of a regular expression.\n+/// It is showable so that error messages resulting from a bug can provide\n+/// useful information.\n+/// It is cloneable so that expressions can be repeated for the counted\n+/// repetition feature. (No other copying is done.)\n+///\n+/// Note that this representation prevents one from reproducing the regex as\n+/// it was typed. (But it could be used to reproduce an equivalent regex.)\n+#[deriving(Show, Clone)]\n+pub enum Ast {\n+    Nothing,\n+    Literal(char, Flags),\n+    Dot(Flags),\n+    Class(Vec<(char, char)>, Flags),\n+    Begin(Flags),\n+    End(Flags),\n+    WordBoundary(Flags),\n+    Capture(uint, Option<~str>, ~Ast),\n+    // Represent concatenation as a flat vector to avoid blowing the\n+    // stack in the compiler.\n+    Cat(Vec<~Ast>),\n+    Alt(~Ast, ~Ast),\n+    Rep(~Ast, Repeater, Greed),\n+}\n+\n+#[deriving(Show, Eq, Clone)]\n+pub enum Repeater {\n+    ZeroOne,\n+    ZeroMore,\n+    OneMore,\n+}\n+\n+#[deriving(Show, Clone)]\n+pub enum Greed {\n+    Greedy,\n+    Ungreedy,\n+}\n+\n+impl Greed {\n+    pub fn is_greedy(&self) -> bool {\n+        match *self {\n+            Greedy => true,\n+            _ => false,\n+        }\n+    }\n+\n+    fn swap(self, swapped: bool) -> Greed {\n+        if !swapped { return self }\n+        match self {\n+            Greedy => Ungreedy,\n+            Ungreedy => Greedy,\n+        }\n+    }\n+}\n+\n+/// BuildAst is a regrettable type that represents intermediate state for\n+/// constructing an abstract syntax tree. Its central purpose is to facilitate\n+/// parsing groups and alternations while also maintaining a stack of flag\n+/// state.\n+#[deriving(Show)]\n+enum BuildAst {\n+    Ast(~Ast),\n+    Paren(Flags, uint, ~str), // '('\n+    Bar, // '|'\n+}\n+\n+impl BuildAst {\n+    fn paren(&self) -> bool {\n+        match *self {\n+            Paren(_, _, _) => true,\n+            _ => false,\n+        }\n+    }\n+\n+    fn flags(&self) -> Flags {\n+        match *self {\n+            Paren(flags, _, _) => flags,\n+            _ => fail!(\"Cannot get flags from {}\", self),\n+        }\n+    }\n+\n+    fn capture(&self) -> Option<uint> {\n+        match *self {\n+            Paren(_, 0, _) => None,\n+            Paren(_, c, _) => Some(c),\n+            _ => fail!(\"Cannot get capture group from {}\", self),\n+        }\n+    }\n+\n+    fn capture_name(&self) -> Option<~str> {\n+        match *self {\n+            Paren(_, 0, _) => None,\n+            Paren(_, _, ref name) => {\n+                if name.len() == 0 {\n+                    None\n+                } else {\n+                    Some(name.clone())\n+                }\n+            }\n+            _ => fail!(\"Cannot get capture name from {}\", self),\n+        }\n+    }\n+\n+    fn bar(&self) -> bool {\n+        match *self {\n+            Bar => true,\n+            _ => false,\n+        }\n+    }\n+\n+    fn unwrap(self) -> Result<~Ast, Error> {\n+        match self {\n+            Ast(x) => Ok(x),\n+            _ => fail!(\"Tried to unwrap non-AST item: {}\", self),\n+        }\n+    }\n+}\n+\n+/// Flags represents all options that can be twiddled by a user in an\n+/// expression.\n+pub type Flags = u8;\n+\n+pub static FLAG_EMPTY:      u8 = 0;\n+pub static FLAG_NOCASE:     u8 = 1 << 0; // i\n+pub static FLAG_MULTI:      u8 = 1 << 1; // m\n+pub static FLAG_DOTNL:      u8 = 1 << 2; // s\n+pub static FLAG_SWAP_GREED: u8 = 1 << 3; // U\n+pub static FLAG_NEGATED:    u8 = 1 << 4; // char class or not word boundary\n+\n+struct Parser<'a> {\n+    // The input, parsed only as a sequence of UTF8 code points.\n+    chars: Vec<char>,\n+    // The index of the current character in the input.\n+    chari: uint,\n+    // The intermediate state representing the AST.\n+    stack: Vec<BuildAst>,\n+    // The current set of flags.\n+    flags: Flags,\n+    // The total number of capture groups.\n+    // Incremented each time an opening left paren is seen (assuming it is\n+    // opening a capture group).\n+    caps: uint,\n+    // A set of all capture group names used only to detect duplicates.\n+    names: Vec<~str>,\n+}\n+\n+pub fn parse(s: &str) -> Result<~Ast, Error> {\n+    Parser {\n+        chars: s.chars().collect(),\n+        chari: 0,\n+        stack: vec!(),\n+        flags: FLAG_EMPTY,\n+        caps: 0,\n+        names: vec!(),\n+    }.parse()\n+}\n+\n+impl<'a> Parser<'a> {\n+    fn parse(&mut self) -> Result<~Ast, Error> {\n+        loop {\n+            let c = self.cur();\n+            match c {\n+                '?' | '*' | '+' => try!(self.push_repeater(c)),\n+                '\\\\' => {\n+                    let ast = try!(self.parse_escape());\n+                    self.push(ast)\n+                }\n+                '{' => try!(self.parse_counted()),\n+                '[' => match self.try_parse_ascii() {\n+                    None => try!(self.parse_class()),\n+                    Some(class) => self.push(class),\n+                },\n+                '(' => {\n+                    if self.peek_is(1, '?') {\n+                        try!(self.expect('?'))\n+                        try!(self.parse_group_opts())\n+                    } else {\n+                        self.caps += 1;\n+                        self.stack.push(Paren(self.flags, self.caps, ~\"\"))\n+                    }\n+                }\n+                ')' => {\n+                    let catfrom = try!(\n+                        self.pos_last(false, |x| x.paren() || x.bar()));\n+                    try!(self.concat(catfrom));\n+\n+                    let altfrom = try!(self.pos_last(false, |x| x.paren()));\n+                    // Before we smush the alternates together and pop off the\n+                    // left paren, let's grab the old flags and see if we\n+                    // need a capture.\n+                    let (cap, cap_name, oldflags) = {\n+                        let paren = self.stack.get(altfrom-1);\n+                        (paren.capture(), paren.capture_name(), paren.flags())\n+                    };\n+                    try!(self.alternate(altfrom));\n+                    self.flags = oldflags;\n+\n+                    // If this was a capture, pop what we just pushed in\n+                    // alternate and make it a capture.\n+                    if cap.is_some() {\n+                        let ast = try!(self.pop_ast());\n+                        self.push(~Capture(cap.unwrap(), cap_name, ast));\n+                    }\n+                }\n+                '|' => {\n+                    let catfrom = try!(\n+                        self.pos_last(true, |x| x.paren() || x.bar()));\n+                    try!(self.concat(catfrom));\n+\n+                    self.stack.push(Bar);\n+                }\n+                _ => try!(self.push_literal(c)),\n+            }\n+            if !self.next_char() {\n+                break\n+            }\n+        }\n+\n+        // Try to improve error handling. At this point, there should be\n+        // no remaining open parens.\n+        if self.stack.iter().any(|x| x.paren()) {\n+            return self.err(\"Unclosed parenthesis.\")\n+        }\n+        let catfrom = try!(self.pos_last(true, |x| x.bar()));\n+        try!(self.concat(catfrom));\n+        try!(self.alternate(0));\n+\n+        assert!(self.stack.len() == 1);\n+        self.pop_ast()\n+    }\n+\n+    fn noteof(&mut self, expected: &str) -> Result<(), Error> {\n+        match self.next_char() {\n+            true => Ok(()),\n+            false => self.err(format!(\"Expected {} but got EOF.\", expected)),\n+        }\n+    }\n+\n+    fn expect(&mut self, expected: char) -> Result<(), Error> {\n+        match self.next_char() {\n+            true if self.cur() == expected => Ok(()),\n+            true => self.err(format!(\"Expected '{}' but got '{}'.\",\n+                                     expected, self.cur())),\n+            false => self.err(format!(\"Expected '{}' but got EOF.\", expected)),\n+        }\n+    }\n+\n+    fn next_char(&mut self) -> bool {\n+        self.chari += 1;\n+        self.chari < self.chars.len()\n+    }\n+\n+    fn pop_ast(&mut self) -> Result<~Ast, Error> {\n+        match self.stack.pop().unwrap().unwrap() {\n+            Err(e) => Err(e),\n+            Ok(ast) => Ok(ast),\n+        }\n+    }\n+\n+    fn push(&mut self, ast: ~Ast) {\n+        self.stack.push(Ast(ast))\n+    }\n+\n+    fn push_repeater(&mut self, c: char) -> Result<(), Error> {\n+        if self.stack.len() == 0 {\n+            return self.err(\n+                \"A repeat operator must be preceded by a valid expression.\")\n+        }\n+        let rep: Repeater = match c {\n+            '?' => ZeroOne, '*' => ZeroMore, '+' => OneMore,\n+            _ => fail!(\"Not a valid repeater operator.\"),\n+        };\n+\n+        match self.peek(1) {\n+            Some('*') | Some('+') =>\n+                return self.err(\n+                    \"Double repeat operators are not supported.\"),\n+            _ => {},\n+        }\n+        let ast = try!(self.pop_ast());\n+        match ast {\n+            ~Begin(_) | ~End(_) | ~WordBoundary(_) =>\n+                return self.err(\n+                    \"Repeat arguments cannot be empty width assertions.\"),\n+            _ => {}\n+        }\n+        let greed = try!(self.get_next_greedy());\n+        self.push(~Rep(ast, rep, greed));\n+        Ok(())\n+    }\n+\n+    fn push_literal(&mut self, c: char) -> Result<(), Error> {\n+        match c {\n+            '.' => {\n+                self.push(~Dot(self.flags))\n+            }\n+            '^' => {\n+                self.push(~Begin(self.flags))\n+            }\n+            '$' => {\n+                self.push(~End(self.flags))\n+            }\n+            _ => {\n+                self.push(~Literal(c, self.flags))\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    // Parses all forms of character classes.\n+    // Assumes that '[' is the current character.\n+    fn parse_class(&mut self) -> Result<(), Error> {\n+        let negated =\n+            if self.peek_is(1, '^') {\n+                try!(self.expect('^'))\n+                FLAG_NEGATED\n+            } else {\n+                FLAG_EMPTY\n+            };\n+        let mut ranges: Vec<(char, char)> = vec!();\n+        let mut alts: Vec<~Ast> = vec!();\n+\n+        if self.peek_is(1, ']') {\n+            try!(self.expect(']'))\n+            ranges.push((']', ']'))\n+        }\n+        while self.peek_is(1, '-') {\n+            try!(self.expect('-'))\n+            ranges.push(('-', '-'))\n+        }\n+        loop {\n+            try!(self.noteof(\"a closing ']' or a non-empty character class)\"))\n+            let mut c = self.cur();\n+            match c {\n+                '[' =>\n+                    match self.try_parse_ascii() {\n+                        Some(~Class(asciis, flags)) => {\n+                            alts.push(~Class(asciis, flags ^ negated));\n+                            continue\n+                        }\n+                        Some(ast) =>\n+                            fail!(\"Expected Class AST but got '{}'\", ast),\n+                        // Just drop down and try to add as a regular character.\n+                        None => {},\n+                    },\n+                '\\\\' => {\n+                    match try!(self.parse_escape()) {\n+                        ~Class(asciis, flags) => {\n+                            alts.push(~Class(asciis, flags ^ negated));\n+                            continue\n+                        }\n+                        ~Literal(c2, _) => c = c2, // process below\n+                        ~Begin(_) | ~End(_) | ~WordBoundary(_) =>\n+                            return self.err(\n+                                \"\\\\A, \\\\z, \\\\b and \\\\B are not valid escape \\\n+                                 sequences inside a character class.\"),\n+                        ast => fail!(\"Unexpected AST item '{}'\", ast),\n+                    }\n+                }\n+                _ => {},\n+            }\n+            match c {\n+                ']' => {\n+                    if ranges.len() > 0 {\n+                        let flags = negated | (self.flags & FLAG_NOCASE);\n+                        let mut ast = ~Class(combine_ranges(ranges), flags);\n+                        for alt in alts.move_iter() {\n+                            ast = ~Alt(alt, ast)\n+                        }\n+                        self.push(ast);\n+                    } else if alts.len() > 0 {\n+                        let mut ast = alts.pop().unwrap();\n+                        for alt in alts.move_iter() {\n+                            ast = ~Alt(alt, ast)\n+                        }\n+                        self.push(ast);\n+                    }\n+                    return Ok(())\n+                }\n+                c => {\n+                    if self.peek_is(1, '-') && !self.peek_is(2, ']') {\n+                        try!(self.expect('-'))\n+                        try!(self.noteof(\"not a ']'\"))\n+                        let c2 = self.cur();\n+                        if c2 < c {\n+                            return self.err(format!(\n+                                \"Invalid character class range '{}-{}'\", c, c2))\n+                        }\n+                        ranges.push((c, self.cur()))\n+                    } else {\n+                        ranges.push((c, c))\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    // Tries to parse an ASCII character class of the form [:name:].\n+    // If successful, returns an AST character class corresponding to name\n+    // and moves the parser to the final ']' character.\n+    // If unsuccessful, no state is changed and None is returned.\n+    // Assumes that '[' is the current character.\n+    fn try_parse_ascii(&mut self) -> Option<~Ast> {\n+        if !self.peek_is(1, ':') {\n+            return None\n+        }\n+        let closer =\n+            match self.pos(']') {\n+                Some(i) => i,\n+                None => return None,\n+            };\n+        if *self.chars.get(closer-1) != ':' {\n+            return None\n+        }\n+        if closer - self.chari <= 3 {\n+            return None\n+        }\n+        let mut name_start = self.chari + 2;\n+        let negated =\n+            if self.peek_is(2, '^') {\n+                name_start += 1;\n+                FLAG_NEGATED\n+            } else {\n+                FLAG_EMPTY\n+            };\n+        let name = self.slice(name_start, closer - 1);\n+        match find_class(ASCII_CLASSES, name) {\n+            None => None,\n+            Some(ranges) => {\n+                self.chari = closer;\n+                let flags = negated | (self.flags & FLAG_NOCASE);\n+                Some(~Class(combine_ranges(ranges), flags))\n+            }\n+        }\n+    }\n+\n+    // Parses counted repetition. Supports:\n+    // {n}, {n,}, {n,m}, {n}?, {n,}? and {n,m}?\n+    // Assumes that '{' is the current character.\n+    // Returns either an error or moves the parser to the final '}' character.\n+    // (Or the '?' character if not greedy.)\n+    fn parse_counted(&mut self) -> Result<(), Error> {\n+        // Scan until the closing '}' and grab the stuff in {}.\n+        let start = self.chari;\n+        let closer =\n+            match self.pos('}') {\n+                Some(i) => i,\n+                None => return self.err(format!(\n+                    \"No closing brace for counted repetition starting at \\\n+                     position {}.\", start)),\n+            };\n+        self.chari = closer;\n+        let greed = try!(self.get_next_greedy());\n+        let inner = str::from_chars(\n+            self.chars.as_slice().slice(start + 1, closer));\n+\n+        // Parse the min and max values from the regex.\n+        let (mut min, mut max): (uint, Option<uint>);\n+        if !inner.contains(\",\") {\n+            min = try!(self.parse_uint(inner));\n+            max = Some(min);\n+        } else {\n+            let pieces: Vec<&str> = inner.splitn(',', 1).collect();\n+            let (smin, smax) = (*pieces.get(0), *pieces.get(1));\n+            if smin.len() == 0 {\n+                return self.err(\"Max repetitions cannot be specified \\\n+                                    without min repetitions.\")\n+            }\n+            min = try!(self.parse_uint(smin));\n+            max =\n+                if smax.len() == 0 {\n+                    None\n+                } else {\n+                    Some(try!(self.parse_uint(smax)))\n+                };\n+        }\n+\n+        // Do some bounds checking and make sure max >= min.\n+        if min > MAX_REPEAT {\n+            return self.err(format!(\n+                \"{} exceeds maximum allowed repetitions ({})\",\n+                min, MAX_REPEAT));\n+        }\n+        if max.is_some() {\n+            let m = max.unwrap();\n+            if m > MAX_REPEAT {\n+                return self.err(format!(\n+                    \"{} exceeds maximum allowed repetitions ({})\",\n+                    m, MAX_REPEAT));\n+            }\n+            if m < min {\n+                return self.err(format!(\n+                    \"Max repetitions ({}) cannot be smaller than min \\\n+                     repetitions ({}).\", m, min));\n+            }\n+        }\n+\n+        // Now manipulate the AST be repeating elements.\n+        if max.is_none() {\n+            // Require N copies of what's on the stack and then repeat it.\n+            let ast = try!(self.pop_ast());\n+            for _ in iter::range(0, min) {\n+                self.push(ast.clone())\n+            }\n+            self.push(~Rep(ast, ZeroMore, greed));\n+        } else {\n+            // Require N copies of what's on the stack and then repeat it\n+            // up to M times optionally.\n+            let ast = try!(self.pop_ast());\n+            for _ in iter::range(0, min) {\n+                self.push(ast.clone())\n+            }\n+            if max.is_some() {\n+                for _ in iter::range(min, max.unwrap()) {\n+                    self.push(~Rep(ast.clone(), ZeroOne, greed))\n+                }\n+            }\n+            // It's possible that we popped something off the stack but\n+            // never put anything back on it. To keep things simple, add\n+            // a no-op expression.\n+            if min == 0 && (max.is_none() || max == Some(0)) {\n+                self.push(~Nothing)\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    // Parses all escape sequences.\n+    // Assumes that '\\' is the current character.\n+    fn parse_escape(&mut self) -> Result<~Ast, Error> {\n+        try!(self.noteof(\"an escape sequence following a '\\\\'\"))\n+\n+        let c = self.cur();\n+        if is_punct(c) {\n+            return Ok(~Literal(c, FLAG_EMPTY))\n+        }\n+        match c {\n+            'a' => Ok(~Literal('\\x07', FLAG_EMPTY)),\n+            'f' => Ok(~Literal('\\x0C', FLAG_EMPTY)),\n+            't' => Ok(~Literal('\\t', FLAG_EMPTY)),\n+            'n' => Ok(~Literal('\\n', FLAG_EMPTY)),\n+            'r' => Ok(~Literal('\\r', FLAG_EMPTY)),\n+            'v' => Ok(~Literal('\\x0B', FLAG_EMPTY)),\n+            'A' => Ok(~Begin(FLAG_EMPTY)),\n+            'z' => Ok(~End(FLAG_EMPTY)),\n+            'b' => Ok(~WordBoundary(FLAG_EMPTY)),\n+            'B' => Ok(~WordBoundary(FLAG_NEGATED)),\n+            '0'|'1'|'2'|'3'|'4'|'5'|'6'|'7' => Ok(try!(self.parse_octal())),\n+            'x' => Ok(try!(self.parse_hex())),\n+            'p' | 'P' => Ok(try!(self.parse_unicode_name())),\n+            'd' | 'D' | 's' | 'S' | 'w' | 'W' => {\n+                let ranges = perl_unicode_class(c);\n+                let mut flags = self.flags & FLAG_NOCASE;\n+                if c.is_uppercase() { flags |= FLAG_NEGATED }\n+                Ok(~Class(ranges, flags))\n+            }\n+            _ => self.err(format!(\"Invalid escape sequence '\\\\\\\\{}'\", c)),\n+        }\n+    }\n+\n+    // Parses a unicode character class name, either of the form \\pF where\n+    // F is a one letter unicode class name or of the form \\p{name} where\n+    // name is the unicode class name.\n+    // Assumes that \\p or \\P has been read (and 'p' or 'P' is the current\n+    // character).\n+    fn parse_unicode_name(&mut self) -> Result<~Ast, Error> {\n+        let negated = if self.cur() == 'P' { FLAG_NEGATED } else { FLAG_EMPTY };\n+        let mut name: ~str;\n+        if self.peek_is(1, '{') {\n+            try!(self.expect('{'))\n+            let closer =\n+                match self.pos('}') {\n+                    Some(i) => i,\n+                    None => return self.err(format!(\n+                        \"Missing '\\\\}' for unclosed '\\\\{' at position {}\",\n+                        self.chari)),\n+                };\n+            if closer - self.chari + 1 == 0 {\n+                return self.err(\"No Unicode class name found.\")\n+            }\n+            name = self.slice(self.chari + 1, closer);\n+            self.chari = closer;\n+        } else {\n+            if self.chari + 1 >= self.chars.len() {\n+                return self.err(\"No single letter Unicode class name found.\")\n+            }\n+            name = self.slice(self.chari + 1, self.chari + 2);\n+            self.chari += 1;\n+        }\n+        match find_class(UNICODE_CLASSES, name) {\n+            None => return self.err(format!(\n+                \"Could not find Unicode class '{}'\", name)),\n+            Some(ranges) => {\n+                Ok(~Class(ranges, negated | (self.flags & FLAG_NOCASE)))\n+            }\n+        }\n+    }\n+\n+    // Parses an octal number, up to 3 digits.\n+    // Assumes that \\n has been read, where n is the first digit.\n+    fn parse_octal(&mut self) -> Result<~Ast, Error> {\n+        let start = self.chari;\n+        let mut end = start + 1;\n+        let (d2, d3) = (self.peek(1), self.peek(2));\n+        if d2 >= Some('0') && d2 <= Some('7') {\n+            try!(self.noteof(\"expected octal character in [0-7]\"))\n+            end += 1;\n+            if d3 >= Some('0') && d3 <= Some('7') {\n+                try!(self.noteof(\"expected octal character in [0-7]\"))\n+                end += 1;\n+            }\n+        }\n+        let s = self.slice(start, end);\n+        match num::from_str_radix::<u32>(s, 8) {\n+            Some(n) => Ok(~Literal(try!(self.char_from_u32(n)), FLAG_EMPTY)),\n+            None => self.err(format!(\n+                \"Could not parse '{}' as octal number.\", s)),\n+        }\n+    }\n+\n+    // Parse a hex number. Either exactly two digits or anything in {}.\n+    // Assumes that \\x has been read.\n+    fn parse_hex(&mut self) -> Result<~Ast, Error> {\n+        if !self.peek_is(1, '{') {\n+            try!(self.expect('{'))\n+            return self.parse_hex_two()\n+        }\n+        let start = self.chari + 2;\n+        let closer =\n+            match self.pos('}') {\n+                None => return self.err(format!(\n+                    \"Missing '\\\\}' for unclosed '\\\\{' at position {}\", start)),\n+                Some(i) => i,\n+            };\n+        self.chari = closer;\n+        self.parse_hex_digits(self.slice(start, closer))\n+    }\n+\n+    // Parses a two-digit hex number.\n+    // Assumes that \\xn has been read, where n is the first digit and is the\n+    // current character.\n+    // After return, parser will point at the second digit.\n+    fn parse_hex_two(&mut self) -> Result<~Ast, Error> {\n+        let (start, end) = (self.chari, self.chari + 2);\n+        let bad = self.slice(start - 2, self.chars.len());\n+        try!(self.noteof(format!(\"Invalid hex escape sequence '{}'\", bad)))\n+        self.parse_hex_digits(self.slice(start, end))\n+    }\n+\n+    // Parses `s` as a hexadecimal number.\n+    fn parse_hex_digits(&self, s: &str) -> Result<~Ast, Error> {\n+        match num::from_str_radix::<u32>(s, 16) {\n+            Some(n) => Ok(~Literal(try!(self.char_from_u32(n)), FLAG_EMPTY)),\n+            None => self.err(format!(\n+                \"Could not parse '{}' as hex number.\", s)),\n+        }\n+    }\n+\n+    // Parses a named capture.\n+    // Assumes that '(?P<' has been consumed and that the current character\n+    // is '<'.\n+    // When done, parser will be at the closing '>' character.\n+    fn parse_named_capture(&mut self) -> Result<(), Error> {\n+        try!(self.noteof(\"a capture name\"))\n+        let closer =\n+            match self.pos('>') {\n+                Some(i) => i,\n+                None => return self.err(\"Capture name must end with '>'.\"),\n+            };\n+        if closer - self.chari == 0 {\n+            return self.err(\"Capture names must have at least 1 character.\")\n+        }\n+        let name = self.slice(self.chari, closer);\n+        if !name.chars().all(is_valid_cap) {\n+            return self.err(\n+                \"Capture names can only have underscores, letters and digits.\")\n+        }\n+        if self.names.contains(&name) {\n+            return self.err(format!(\"Duplicate capture group name '{}'.\", name))\n+        }\n+        self.names.push(name.clone());\n+        self.chari = closer;\n+        self.caps += 1;\n+        self.stack.push(Paren(self.flags, self.caps, name));\n+        Ok(())\n+    }\n+\n+    // Parses non-capture groups and options.\n+    // Assumes that '(?' has already been consumed and '?' is the current\n+    // character.\n+    fn parse_group_opts(&mut self) -> Result<(), Error> {\n+        if self.peek_is(1, 'P') && self.peek_is(2, '<') {\n+            try!(self.expect('P')) try!(self.expect('<'))\n+            return self.parse_named_capture()\n+        }\n+        let start = self.chari;\n+        let mut flags = self.flags;\n+        let mut sign = 1;\n+        let mut saw_flag = false;\n+        loop {\n+            try!(self.noteof(\"expected non-empty set of flags or closing ')'\"))\n+            match self.cur() {\n+                'i' => { flags = flags | FLAG_NOCASE;     saw_flag = true},\n+                'm' => { flags = flags | FLAG_MULTI;      saw_flag = true},\n+                's' => { flags = flags | FLAG_DOTNL;      saw_flag = true},\n+                'U' => { flags = flags | FLAG_SWAP_GREED; saw_flag = true},\n+                '-' => {\n+                    if sign < 0 {\n+                        return self.err(format!(\n+                            \"Cannot negate flags twice in '{}'.\",\n+                            self.slice(start, self.chari + 1)))\n+                    }\n+                    sign = -1;\n+                    saw_flag = false;\n+                    flags = flags ^ flags;\n+                }\n+                ':' | ')' => {\n+                    if sign < 0 {\n+                        if !saw_flag {\n+                            return self.err(format!(\n+                                \"A valid flag does not follow negation in '{}'\",\n+                                self.slice(start, self.chari + 1)))\n+                        }\n+                        flags = flags ^ flags;\n+                    }\n+                    if self.cur() == ':' {\n+                        // Save the old flags with the opening paren.\n+                        self.stack.push(Paren(self.flags, 0, ~\"\"));\n+                    }\n+                    self.flags = flags;\n+                    return Ok(())\n+                }\n+                _ => return self.err(format!(\n+                    \"Unrecognized flag '{}'.\", self.cur())),\n+            }\n+        }\n+    }\n+\n+    // Peeks at the next character and returns whether it's ungreedy or not.\n+    // If it is, then the next character is consumed.\n+    fn get_next_greedy(&mut self) -> Result<Greed, Error> {\n+        Ok(if self.peek_is(1, '?') {\n+            try!(self.expect('?'))\n+            Ungreedy\n+        } else {\n+            Greedy\n+        }.swap(self.flags & FLAG_SWAP_GREED > 0))\n+    }\n+\n+    // Searches the stack (starting at the top) until it finds an expression\n+    // for which `pred` returns true. The index of that expression in the\n+    // stack is returned.\n+    // If there's no match, then one of two things happens depending on the\n+    // values of `allow_start`. When it's true, then `0` will be returned.\n+    // Otherwise, an error will be returned.\n+    // Generally, `allow_start` is only true when you're *not* expecting an\n+    // opening parenthesis.\n+    fn pos_last(&self, allow_start: bool, pred: |&BuildAst| -> bool)\n+               -> Result<uint, Error> {\n+        let from = match self.stack.iter().rev().position(pred) {\n+            Some(i) => i,\n+            None => {\n+                if allow_start {\n+                    self.stack.len()\n+                } else {\n+                    return self.err(\"No matching opening parenthesis.\")\n+                }\n+            }\n+        };\n+        // Adjust index since 'from' is for the reversed stack.\n+        // Also, don't include the '(' or '|'.\n+        Ok(self.stack.len() - from)\n+    }\n+\n+    // concat starts at `from` in the parser's stack and concatenates all\n+    // expressions up to the top of the stack. The resulting concatenation is\n+    // then pushed on to the stack.\n+    // Usually `from` corresponds to the position of an opening parenthesis,\n+    // a '|' (alternation) or the start of the entire expression.\n+    fn concat(&mut self, from: uint) -> Result<(), Error> {\n+        let ast = try!(self.build_from(from, concat_flatten));\n+        self.push(ast);\n+        Ok(())\n+    }\n+\n+    // concat starts at `from` in the parser's stack and alternates all\n+    // expressions up to the top of the stack. The resulting alternation is\n+    // then pushed on to the stack.\n+    // Usually `from` corresponds to the position of an opening parenthesis\n+    // or the start of the entire expression.\n+    // This will also drop any opening parens or alternation bars found in\n+    // the intermediate AST.\n+    fn alternate(&mut self, mut from: uint) -> Result<(), Error> {\n+        // Unlike in the concatenation case, we want 'build_from' to continue\n+        // all the way to the opening left paren (so it will be popped off and\n+        // thrown away). But be careful with overflow---we can't count on the\n+        // open paren to be there.\n+        if from > 0 { from = from - 1}\n+        let ast = try!(self.build_from(from, Alt));\n+        self.push(ast);\n+        Ok(())\n+    }\n+\n+    // build_from combines all AST elements starting at 'from' in the\n+    // parser's stack using 'mk' to combine them. If any such element is not an\n+    // AST then it is popped off the stack and ignored.\n+    fn build_from(&mut self, from: uint, mk: |~Ast, ~Ast| -> Ast)\n+                 -> Result<~Ast, Error> {\n+        if from >= self.stack.len() {\n+            return self.err(\"Empty group or alternate not allowed.\")\n+        }\n+\n+        let mut combined = try!(self.pop_ast());\n+        let mut i = self.stack.len();\n+        while i > from {\n+            i = i - 1;\n+            match self.stack.pop().unwrap() {\n+                Ast(x) => combined = ~mk(x, combined),\n+                _ => {},\n+            }\n+        }\n+        Ok(combined)\n+    }\n+\n+    fn parse_uint(&self, s: &str) -> Result<uint, Error> {\n+        match from_str::<uint>(s) {\n+            Some(i) => Ok(i),\n+            None => self.err(format!(\n+                \"Expected an unsigned integer but got '{}'.\", s)),\n+        }\n+    }\n+\n+    fn char_from_u32(&self, n: u32) -> Result<char, Error> {\n+        match char::from_u32(n) {\n+            Some(c) => Ok(c),\n+            None => self.err(format!(\n+                \"Could not decode '{}' to unicode character.\", n)),\n+        }\n+    }\n+\n+    fn pos(&self, c: char) -> Option<uint> {\n+        self.chars.iter()\n+            .skip(self.chari).position(|&c2| c2 == c).map(|i| self.chari + i)\n+    }\n+\n+    fn err<T>(&self, msg: &str) -> Result<T, Error> {\n+        Err(Error {\n+            pos: self.chari,\n+            msg: msg.to_owned(),\n+        })\n+    }\n+\n+    fn peek(&self, offset: uint) -> Option<char> {\n+        if self.chari + offset >= self.chars.len() {\n+            return None\n+        }\n+        Some(*self.chars.get(self.chari + offset))\n+    }\n+\n+    fn peek_is(&self, offset: uint, is: char) -> bool {\n+        self.peek(offset) == Some(is)\n+    }\n+\n+    fn cur(&self) -> char {\n+        *self.chars.get(self.chari)\n+    }\n+\n+    fn slice(&self, start: uint, end: uint) -> ~str {\n+        str::from_chars(self.chars.as_slice().slice(start, end))\n+    }\n+}\n+\n+// Given an unordered collection of character ranges, combine_ranges returns\n+// an ordered sequence of character ranges where no two ranges overlap. They\n+// are ordered from least to greatest (using start position).\n+fn combine_ranges(unordered: Vec<(char, char)>) -> Vec<(char, char)> {\n+    // Returns true iff the two character classes overlap or share a boundary.\n+    // e.g., ('a', 'g') and ('h', 'm') would return true.\n+    fn should_merge((a, b): (char, char), (x, y): (char, char)) -> bool {\n+        cmp::max(a, x) as u32 <= cmp::min(b, y) as u32 + 1\n+    }\n+\n+    // This is currently O(n^2), but I think with sufficient cleverness,\n+    // it can be reduced to O(n) **if necessary**.\n+    let mut ordered: Vec<(char, char)> = Vec::with_capacity(unordered.len());\n+    for (us, ue) in unordered.move_iter() {\n+        let (mut us, mut ue) = (us, ue);\n+        assert!(us <= ue);\n+        let mut which: Option<uint> = None;\n+        for (i, &(os, oe)) in ordered.iter().enumerate() {\n+            if should_merge((us, ue), (os, oe)) {\n+                us = cmp::min(us, os);\n+                ue = cmp::max(ue, oe);\n+                which = Some(i);\n+                break\n+            }\n+        }\n+        match which {\n+            None => ordered.push((us, ue)),\n+            Some(i) => *ordered.get_mut(i) = (us, ue),\n+        }\n+    }\n+    ordered.sort();\n+    ordered\n+}\n+\n+// Constructs a Unicode friendly Perl character class from \\d, \\s or \\w\n+// (or any of their negated forms). Note that this does not handle negation.\n+fn perl_unicode_class(which: char) -> Vec<(char, char)> {\n+    match which.to_lowercase() {\n+        'd' => Vec::from_slice(PERLD),\n+        's' => Vec::from_slice(PERLS),\n+        'w' => Vec::from_slice(PERLW),\n+        _ => unreachable!(),\n+    }\n+}\n+\n+// Returns a concatenation of two expressions. This also guarantees that a\n+// `Cat` expression will never be a direct child of another `Cat` expression.\n+fn concat_flatten(x: ~Ast, y: ~Ast) -> Ast {\n+    match (x, y) {\n+        (~Cat(mut xs), ~Cat(ys)) => { xs.push_all_move(ys); Cat(xs) }\n+        (~Cat(mut xs), ast) => { xs.push(ast); Cat(xs) }\n+        (ast, ~Cat(mut xs)) => { xs.unshift(ast); Cat(xs) }\n+        (ast1, ast2) => Cat(vec!(ast1, ast2)),\n+    }\n+}\n+\n+pub fn is_punct(c: char) -> bool {\n+    match c {\n+        '\\\\' | '.' | '+' | '*' | '?' | '(' | ')' | '|' |\n+        '[' | ']' | '{' | '}' | '^' | '$' => true,\n+        _ => false,\n+    }\n+}\n+\n+fn is_valid_cap(c: char) -> bool {\n+    c == '_' || (c >= '0' && c <= '9')\n+    || (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')\n+}\n+\n+fn find_class(classes: NamedClasses, name: &str) -> Option<Vec<(char, char)>> {\n+    match classes.bsearch(|&(s, _)| s.cmp(&name)) {\n+        Some(i) => Some(Vec::from_slice(classes[i].val1())),\n+        None => None,\n+    }\n+}\n+\n+type Class = &'static [(char, char)];\n+type NamedClasses = &'static [(&'static str, Class)];\n+\n+static ASCII_CLASSES: NamedClasses = &[\n+    // Classes must be in alphabetical order so that bsearch works.\n+    // [:alnum:]      alphanumeric (== [0-9A-Za-z])\n+    // [:alpha:]      alphabetic (== [A-Za-z])\n+    // [:ascii:]      ASCII (== [\\x00-\\x7F])\n+    // [:blank:]      blank (== [\\t ])\n+    // [:cntrl:]      control (== [\\x00-\\x1F\\x7F])\n+    // [:digit:]      digits (== [0-9])\n+    // [:graph:]      graphical (== [!-~])\n+    // [:lower:]      lower case (== [a-z])\n+    // [:print:]      printable (== [ -~] == [ [:graph:]])\n+    // [:punct:]      punctuation (== [!-/:-@[-`{-~])\n+    // [:space:]      whitespace (== [\\t\\n\\v\\f\\r ])\n+    // [:upper:]      upper case (== [A-Z])\n+    // [:word:]       word characters (== [0-9A-Za-z_])\n+    // [:xdigit:]     hex digit (== [0-9A-Fa-f])\n+    // Taken from: http://golang.org/pkg/regex/syntax/\n+    (\"alnum\", &[('0', '9'), ('A', 'Z'), ('a', 'z')]),\n+    (\"alpha\", &[('A', 'Z'), ('a', 'z')]),\n+    (\"ascii\", &[('\\x00', '\\x7F')]),\n+    (\"blank\", &[(' ', ' '), ('\\t', '\\t')]),\n+    (\"cntrl\", &[('\\x00', '\\x1F'), ('\\x7F', '\\x7F')]),\n+    (\"digit\", &[('0', '9')]),\n+    (\"graph\", &[('!', '~')]),\n+    (\"lower\", &[('a', 'z')]),\n+    (\"print\", &[(' ', '~')]),\n+    (\"punct\", &[('!', '/'), (':', '@'), ('[', '`'), ('{', '~')]),\n+    (\"space\", &[('\\t', '\\t'), ('\\n', '\\n'), ('\\x0B', '\\x0B'), ('\\x0C', '\\x0C'),\n+                ('\\r', '\\r'), (' ', ' ')]),\n+    (\"upper\", &[('A', 'Z')]),\n+    (\"word\", &[('0', '9'), ('A', 'Z'), ('a', 'z'), ('_', '_')]),\n+    (\"xdigit\", &[('0', '9'), ('A', 'F'), ('a', 'f')]),\n+];"}, {"sha": "da3ebaee6dba1863baf4e8d8ae4ab2ad158de724", "filename": "src/libregex/re.rs", "status": "added", "additions": 870, "deletions": 0, "changes": 870, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fre.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fre.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fre.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,870 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use collections::HashMap;\n+use std::fmt;\n+use std::from_str::from_str;\n+use std::str::{MaybeOwned, Owned, Slice};\n+\n+use compile::Program;\n+use parse;\n+use vm;\n+use vm::{CaptureLocs, MatchKind, Exists, Location, Submatches};\n+\n+/// Escapes all regular expression meta characters in `text` so that it may be\n+/// safely used in a regular expression as a literal string.\n+pub fn quote(text: &str) -> ~str {\n+    let mut quoted = StrBuf::with_capacity(text.len());\n+    for c in text.chars() {\n+        if parse::is_punct(c) {\n+            quoted.push_char('\\\\')\n+        }\n+        quoted.push_char(c);\n+    }\n+    quoted.into_owned()\n+}\n+\n+/// Tests if the given regular expression matches somewhere in the text given.\n+///\n+/// If there was a problem compiling the regular expression, an error is\n+/// returned.\n+///\n+/// To find submatches, split or replace text, you'll need to compile an\n+/// expression first.\n+///\n+/// Note that you should prefer the `regex!` macro when possible. For example,\n+/// `regex!(\"...\").is_match(\"...\")`.\n+pub fn is_match(regex: &str, text: &str) -> Result<bool, parse::Error> {\n+    Regex::new(regex).map(|r| r.is_match(text))\n+}\n+\n+/// Regex is a compiled regular expression, represented as either a sequence\n+/// of bytecode instructions (dynamic) or as a specialized Rust function\n+/// (native). It can be used to search, split\n+/// or replace text. All searching is done with an implicit `.*?` at the\n+/// beginning and end of an expression. To force an expression to match the\n+/// whole string (or a prefix or a suffix), you must use an anchor like `^` or\n+/// `$` (or `\\A` and `\\z`).\n+///\n+/// While this crate will handle Unicode strings (whether in the regular\n+/// expression or in the search text), all positions returned are **byte\n+/// indices**. Every byte index is guaranteed to be at a UTF8 codepoint\n+/// boundary.\n+///\n+/// The lifetimes `'r` and `'t` in this crate correspond to the lifetime of a\n+/// compiled regular expression and text to search, respectively.\n+///\n+/// The only methods that allocate new strings are the string replacement\n+/// methods. All other methods (searching and splitting) return borrowed\n+/// pointers into the string given.\n+///\n+/// # Examples\n+///\n+/// Find the location of a US phone number:\n+///\n+/// ```rust\n+/// # use regex::Regex;\n+/// let re = match Regex::new(\"[0-9]{3}-[0-9]{3}-[0-9]{4}\") {\n+///     Ok(re) => re,\n+///     Err(err) => fail!(\"{}\", err),\n+/// };\n+/// assert_eq!(re.find(\"phone: 111-222-3333\"), Some((7, 19)));\n+/// ```\n+///\n+/// You can also use the `regex!` macro to compile a regular expression when\n+/// you compile your program:\n+///\n+/// ```rust\n+/// #![feature(phase)]\n+/// extern crate regex;\n+/// #[phase(syntax)] extern crate regex_macros;\n+///\n+/// fn main() {\n+///     let re = regex!(r\"\\d+\");\n+///     assert_eq!(re.find(\"123 abc\"), Some((0, 3)));\n+/// }\n+/// ```\n+///\n+/// Given an incorrect regular expression, `regex!` will cause the Rust\n+/// compiler to produce a compile time error.\n+/// Note that `regex!` will compile the expression to native Rust code, which\n+/// makes it much faster when searching text.\n+/// More details about the `regex!` macro can be found in the `regex` crate\n+/// documentation.\n+#[deriving(Clone)]\n+#[allow(visible_private_types)]\n+pub struct Regex {\n+    /// The representation of `Regex` is exported to support the `regex!`\n+    /// syntax extension. Do not rely on it.\n+    ///\n+    /// See the comments for the `program` module in `lib.rs` for a more\n+    /// detailed explanation for what `regex!` requires.\n+    #[doc(hidden)]\n+    pub original: ~str,\n+    #[doc(hidden)]\n+    pub names: ~[Option<~str>],\n+    #[doc(hidden)]\n+    pub p: MaybeNative,\n+}\n+\n+impl fmt::Show for Regex {\n+    /// Shows the original regular expression.\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        write!(f.buf, \"{}\", self.original)\n+    }\n+}\n+\n+pub enum MaybeNative {\n+    Dynamic(Program),\n+    Native(fn(MatchKind, &str, uint, uint) -> Vec<Option<uint>>),\n+}\n+\n+impl Clone for MaybeNative {\n+    fn clone(&self) -> MaybeNative {\n+        match *self {\n+            Dynamic(ref p) => Dynamic(p.clone()),\n+            Native(fp) => Native(fp),\n+        }\n+    }\n+}\n+\n+impl Regex {\n+    /// Compiles a dynamic regular expression. Once compiled, it can be\n+    /// used repeatedly to search, split or replace text in a string.\n+    ///\n+    /// When possible, you should prefer the `regex!` macro since it is\n+    /// safer and always faster.\n+    ///\n+    /// If an invalid expression is given, then an error is returned.\n+    pub fn new(re: &str) -> Result<Regex, parse::Error> {\n+        let ast = try!(parse::parse(re));\n+        let (prog, names) = Program::new(ast);\n+        Ok(Regex { original: re.to_owned(), names: names, p: Dynamic(prog) })\n+    }\n+\n+    /// Returns true if and only if the regex matches the string given.\n+    ///\n+    /// # Example\n+    ///\n+    /// Test if some text contains at least one word with exactly 13\n+    /// characters:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let text = \"I categorically deny having triskaidekaphobia.\";\n+    /// let matched = regex!(r\"\\b\\w{13}\\b\").is_match(text);\n+    /// assert!(matched);\n+    /// # }\n+    /// ```\n+    pub fn is_match(&self, text: &str) -> bool {\n+        has_match(&exec(self, Exists, text))\n+    }\n+\n+    /// Returns the start and end byte range of the leftmost-first match in\n+    /// `text`. If no match exists, then `None` is returned.\n+    ///\n+    /// Note that this should only be used if you want to discover the position\n+    /// of the match. Testing the existence of a match is faster if you use\n+    /// `is_match`.\n+    ///\n+    /// # Example\n+    ///\n+    /// Find the start and end location of every word with exactly 13\n+    /// characters:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let text = \"I categorically deny having triskaidekaphobia.\";\n+    /// let pos = regex!(r\"\\b\\w{13}\\b\").find(text);\n+    /// assert_eq!(pos, Some((2, 15)));\n+    /// # }\n+    /// ```\n+    pub fn find(&self, text: &str) -> Option<(uint, uint)> {\n+        let caps = exec(self, Location, text);\n+        if has_match(&caps) {\n+            Some((caps.get(0).unwrap(), caps.get(1).unwrap()))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    /// Returns an iterator for each successive non-overlapping match in\n+    /// `text`, returning the start and end byte indices with respect to\n+    /// `text`.\n+    ///\n+    /// # Example\n+    ///\n+    /// Find the start and end location of the first word with exactly 13\n+    /// characters:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let text = \"Retroactively relinquishing remunerations is reprehensible.\";\n+    /// for pos in regex!(r\"\\b\\w{13}\\b\").find_iter(text) {\n+    ///     println!(\"{}\", pos);\n+    /// }\n+    /// // Output:\n+    /// // (0, 13)\n+    /// // (14, 27)\n+    /// // (28, 41)\n+    /// // (45, 58)\n+    /// # }\n+    /// ```\n+    pub fn find_iter<'r, 't>(&'r self, text: &'t str) -> FindMatches<'r, 't> {\n+        FindMatches {\n+            re: self,\n+            search: text,\n+            last_end: 0,\n+            last_match: None,\n+        }\n+    }\n+\n+    /// Returns the capture groups corresponding to the leftmost-first\n+    /// match in `text`. Capture group `0` always corresponds to the entire\n+    /// match. If no match is found, then `None` is returned.\n+    ///\n+    /// You should only use `captures` if you need access to submatches.\n+    /// Otherwise, `find` is faster for discovering the location of the overall\n+    /// match.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Say you have some text with movie names and their release years,\n+    /// like \"'Citizen Kane' (1941)\". It'd be nice if we could search for text\n+    /// looking like that, while also extracting the movie name and its release\n+    /// year separately.\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(r\"'([^']+)'\\s+\\((\\d{4})\\)\");\n+    /// let text = \"Not my favorite movie: 'Citizen Kane' (1941).\";\n+    /// let caps = re.captures(text).unwrap();\n+    /// assert_eq!(caps.at(1), \"Citizen Kane\");\n+    /// assert_eq!(caps.at(2), \"1941\");\n+    /// assert_eq!(caps.at(0), \"'Citizen Kane' (1941)\");\n+    /// # }\n+    /// ```\n+    ///\n+    /// Note that the full match is at capture group `0`. Each subsequent\n+    /// capture group is indexed by the order of its opening `(`.\n+    ///\n+    /// We can make this example a bit clearer by using *named* capture groups:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(r\"'(?P<title>[^']+)'\\s+\\((?P<year>\\d{4})\\)\");\n+    /// let text = \"Not my favorite movie: 'Citizen Kane' (1941).\";\n+    /// let caps = re.captures(text).unwrap();\n+    /// assert_eq!(caps.name(\"title\"), \"Citizen Kane\");\n+    /// assert_eq!(caps.name(\"year\"), \"1941\");\n+    /// assert_eq!(caps.at(0), \"'Citizen Kane' (1941)\");\n+    /// # }\n+    /// ```\n+    ///\n+    /// Here we name the capture groups, which we can access with the `name`\n+    /// method. Note that the named capture groups are still accessible with\n+    /// `at`.\n+    ///\n+    /// The `0`th capture group is always unnamed, so it must always be\n+    /// accessed with `at(0)`.\n+    pub fn captures<'t>(&self, text: &'t str) -> Option<Captures<'t>> {\n+        let caps = exec(self, Submatches, text);\n+        Captures::new(self, text, caps)\n+    }\n+\n+    /// Returns an iterator over all the non-overlapping capture groups matched\n+    /// in `text`. This is operationally the same as `find_iter` (except it\n+    /// yields information about submatches).\n+    ///\n+    /// # Example\n+    ///\n+    /// We can use this to find all movie titles and their release years in\n+    /// some text, where the movie is formatted like \"'Title' (xxxx)\":\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(r\"'(?P<title>[^']+)'\\s+\\((?P<year>\\d{4})\\)\");\n+    /// let text = \"'Citizen Kane' (1941), 'The Wizard of Oz' (1939), 'M' (1931).\";\n+    /// for caps in re.captures_iter(text) {\n+    ///     println!(\"Movie: {}, Released: {}\", caps.name(\"title\"), caps.name(\"year\"));\n+    /// }\n+    /// // Output:\n+    /// // Movie: Citizen Kane, Released: 1941\n+    /// // Movie: The Wizard of Oz, Released: 1939\n+    /// // Movie: M, Released: 1931\n+    /// # }\n+    /// ```\n+    pub fn captures_iter<'r, 't>(&'r self, text: &'t str)\n+                                -> FindCaptures<'r, 't> {\n+        FindCaptures {\n+            re: self,\n+            search: text,\n+            last_match: None,\n+            last_end: 0,\n+        }\n+    }\n+\n+    /// Returns an iterator of substrings of `text` delimited by a match\n+    /// of the regular expression.\n+    /// Namely, each element of the iterator corresponds to text that *isn't*\n+    /// matched by the regular expression.\n+    ///\n+    /// This method will *not* copy the text given.\n+    ///\n+    /// # Example\n+    ///\n+    /// To split a string delimited by arbitrary amounts of spaces or tabs:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(r\"[ \\t]+\");\n+    /// let fields: Vec<&str> = re.split(\"a b \\t  c\\td    e\").collect();\n+    /// assert_eq!(fields, vec!(\"a\", \"b\", \"c\", \"d\", \"e\"));\n+    /// # }\n+    /// ```\n+    pub fn split<'r, 't>(&'r self, text: &'t str) -> RegexSplits<'r, 't> {\n+        RegexSplits {\n+            finder: self.find_iter(text),\n+            last: 0,\n+        }\n+    }\n+\n+    /// Returns an iterator of at most `limit` substrings of `text` delimited\n+    /// by a match of the regular expression. (A `limit` of `0` will return no\n+    /// substrings.)\n+    /// Namely, each element of the iterator corresponds to text that *isn't*\n+    /// matched by the regular expression.\n+    /// The remainder of the string that is not split will be the last element\n+    /// in the iterator.\n+    ///\n+    /// This method will *not* copy the text given.\n+    ///\n+    /// # Example\n+    ///\n+    /// Get the first two words in some text:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(r\"\\W+\");\n+    /// let fields: Vec<&str> = re.splitn(\"Hey! How are you?\", 3).collect();\n+    /// assert_eq!(fields, vec!(\"Hey\", \"How\", \"are you?\"));\n+    /// # }\n+    /// ```\n+    pub fn splitn<'r, 't>(&'r self, text: &'t str, limit: uint)\n+                         -> RegexSplitsN<'r, 't> {\n+        RegexSplitsN {\n+            splits: self.split(text),\n+            cur: 0,\n+            limit: limit,\n+        }\n+    }\n+\n+    /// Replaces the leftmost-first match with the replacement provided.\n+    /// The replacement can be a regular string (where `$N` and `$name` are\n+    /// expanded to match capture groups) or a function that takes the matches'\n+    /// `Captures` and returns the replaced string.\n+    ///\n+    /// If no match is found, then a copy of the string is returned unchanged.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Note that this function is polymorphic with respect to the replacement.\n+    /// In typical usage, this can just be a normal string:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(\"[^01]+\");\n+    /// assert_eq!(re.replace(\"1078910\", \"\").as_slice(), \"1010\");\n+    /// # }\n+    /// ```\n+    ///\n+    /// But anything satisfying the `Replacer` trait will work. For example,\n+    /// a closure of type `|&Captures| -> ~str` provides direct access to the\n+    /// captures corresponding to a match. This allows one to access\n+    /// submatches easily:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # use regex::Captures; fn main() {\n+    /// let re = regex!(r\"([^,\\s]+),\\s+(\\S+)\");\n+    /// let result = re.replace(\"Springsteen, Bruce\", |caps: &Captures| {\n+    ///     format!(\"{} {}\", caps.at(2), caps.at(1))\n+    /// });\n+    /// assert_eq!(result.as_slice(), \"Bruce Springsteen\");\n+    /// # }\n+    /// ```\n+    ///\n+    /// But this is a bit cumbersome to use all the time. Instead, a simple\n+    /// syntax is supported that expands `$name` into the corresponding capture\n+    /// group. Here's the last example, but using this expansion technique\n+    /// with named capture groups:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// let re = regex!(r\"(?P<last>[^,\\s]+),\\s+(?P<first>\\S+)\");\n+    /// let result = re.replace(\"Springsteen, Bruce\", \"$first $last\");\n+    /// assert_eq!(result.as_slice(), \"Bruce Springsteen\");\n+    /// # }\n+    /// ```\n+    ///\n+    /// Note that using `$2` instead of `$first` or `$1` instead of `$last`\n+    /// would produce the same result. To write a literal `$` use `$$`.\n+    ///\n+    /// Finally, sometimes you just want to replace a literal string with no\n+    /// submatch expansion. This can be done by wrapping a string with\n+    /// `NoExpand`:\n+    ///\n+    /// ```rust\n+    /// # #![feature(phase)]\n+    /// # extern crate regex; #[phase(syntax)] extern crate regex_macros;\n+    /// # fn main() {\n+    /// use regex::NoExpand;\n+    ///\n+    /// let re = regex!(r\"(?P<last>[^,\\s]+),\\s+(\\S+)\");\n+    /// let result = re.replace(\"Springsteen, Bruce\", NoExpand(\"$2 $last\"));\n+    /// assert_eq!(result.as_slice(), \"$2 $last\");\n+    /// # }\n+    /// ```\n+    pub fn replace<R: Replacer>(&self, text: &str, rep: R) -> StrBuf {\n+        self.replacen(text, 1, rep)\n+    }\n+\n+    /// Replaces all non-overlapping matches in `text` with the\n+    /// replacement provided. This is the same as calling `replacen` with\n+    /// `limit` set to `0`.\n+    ///\n+    /// See the documentation for `replace` for details on how to access\n+    /// submatches in the replacement string.\n+    pub fn replace_all<R: Replacer>(&self, text: &str, rep: R) -> StrBuf {\n+        self.replacen(text, 0, rep)\n+    }\n+\n+    /// Replaces at most `limit` non-overlapping matches in `text` with the\n+    /// replacement provided. If `limit` is 0, then all non-overlapping matches\n+    /// are replaced.\n+    ///\n+    /// See the documentation for `replace` for details on how to access\n+    /// submatches in the replacement string.\n+    pub fn replacen<R: Replacer>\n+                   (&self, text: &str, limit: uint, mut rep: R) -> StrBuf {\n+        let mut new = StrBuf::with_capacity(text.len());\n+        let mut last_match = 0u;\n+        let mut i = 0;\n+        for cap in self.captures_iter(text) {\n+            // It'd be nicer to use the 'take' iterator instead, but it seemed\n+            // awkward given that '0' => no limit.\n+            if limit > 0 && i >= limit {\n+                break\n+            }\n+            i += 1;\n+\n+            let (s, e) = cap.pos(0).unwrap(); // captures only reports matches\n+            new.push_str(text.slice(last_match, s));\n+            new.push_str(rep.reg_replace(&cap).as_slice());\n+            last_match = e;\n+        }\n+        new.append(text.slice(last_match, text.len()))\n+    }\n+}\n+\n+/// NoExpand indicates literal string replacement.\n+///\n+/// It can be used with `replace` and `replace_all` to do a literal\n+/// string replacement without expanding `$name` to their corresponding\n+/// capture groups.\n+///\n+/// `'r` is the lifetime of the literal text.\n+pub struct NoExpand<'t>(pub &'t str);\n+\n+/// Replacer describes types that can be used to replace matches in a string.\n+pub trait Replacer {\n+    /// Returns a possibly owned string that is used to replace the match\n+    /// corresponding the the `caps` capture group.\n+    ///\n+    /// The `'a` lifetime refers to the lifetime of a borrowed string when\n+    /// a new owned string isn't needed (e.g., for `NoExpand`).\n+    fn reg_replace<'a>(&'a mut self, caps: &Captures) -> MaybeOwned<'a>;\n+}\n+\n+impl<'t> Replacer for NoExpand<'t> {\n+    fn reg_replace<'a>(&'a mut self, _: &Captures) -> MaybeOwned<'a> {\n+        let NoExpand(s) = *self;\n+        Slice(s)\n+    }\n+}\n+\n+impl<'t> Replacer for &'t str {\n+    fn reg_replace<'a>(&'a mut self, caps: &Captures) -> MaybeOwned<'a> {\n+        Owned(caps.expand(*self).into_owned())\n+    }\n+}\n+\n+impl<'a> Replacer for |&Captures|: 'a -> ~str {\n+    fn reg_replace<'r>(&'r mut self, caps: &Captures) -> MaybeOwned<'r> {\n+        Owned((*self)(caps).into_owned())\n+    }\n+}\n+\n+/// Yields all substrings delimited by a regular expression match.\n+///\n+/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n+/// of the string being split.\n+pub struct RegexSplits<'r, 't> {\n+    finder: FindMatches<'r, 't>,\n+    last: uint,\n+}\n+\n+impl<'r, 't> Iterator<&'t str> for RegexSplits<'r, 't> {\n+    fn next(&mut self) -> Option<&'t str> {\n+        let text = self.finder.search;\n+        match self.finder.next() {\n+            None => {\n+                if self.last >= text.len() {\n+                    None\n+                } else {\n+                    let s = text.slice(self.last, text.len());\n+                    self.last = text.len();\n+                    Some(s)\n+                }\n+            }\n+            Some((s, e)) => {\n+                let matched = text.slice(self.last, s);\n+                self.last = e;\n+                Some(matched)\n+            }\n+        }\n+    }\n+}\n+\n+/// Yields at most `N` substrings delimited by a regular expression match.\n+///\n+/// The last substring will be whatever remains after splitting.\n+///\n+/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n+/// of the string being split.\n+pub struct RegexSplitsN<'r, 't> {\n+    splits: RegexSplits<'r, 't>,\n+    cur: uint,\n+    limit: uint,\n+}\n+\n+impl<'r, 't> Iterator<&'t str> for RegexSplitsN<'r, 't> {\n+    fn next(&mut self) -> Option<&'t str> {\n+        let text = self.splits.finder.search;\n+        if self.cur >= self.limit {\n+            None\n+        } else {\n+            self.cur += 1;\n+            if self.cur >= self.limit {\n+                Some(text.slice(self.splits.last, text.len()))\n+            } else {\n+                self.splits.next()\n+            }\n+        }\n+    }\n+}\n+\n+/// Captures represents a group of captured strings for a single match.\n+///\n+/// The 0th capture always corresponds to the entire match. Each subsequent\n+/// index corresponds to the next capture group in the regex.\n+/// If a capture group is named, then the matched string is *also* available\n+/// via the `name` method. (Note that the 0th capture is always unnamed and so\n+/// must be accessed with the `at` method.)\n+///\n+/// Positions returned from a capture group are always byte indices.\n+///\n+/// `'t` is the lifetime of the matched text.\n+pub struct Captures<'t> {\n+    text: &'t str,\n+    locs: CaptureLocs,\n+    named: Option<HashMap<~str, uint>>,\n+}\n+\n+impl<'t> Captures<'t> {\n+    fn new(re: &Regex, search: &'t str, locs: CaptureLocs)\n+          -> Option<Captures<'t>> {\n+        if !has_match(&locs) {\n+            return None\n+        }\n+\n+        let named =\n+            if re.names.len() == 0 {\n+                None\n+            } else {\n+                let mut named = HashMap::new();\n+                for (i, name) in re.names.iter().enumerate() {\n+                    match name {\n+                        &None => {},\n+                        &Some(ref name) => {\n+                            named.insert(name.to_owned(), i);\n+                        }\n+                    }\n+                }\n+                Some(named)\n+            };\n+        Some(Captures {\n+            text: search,\n+            locs: locs,\n+            named: named,\n+        })\n+    }\n+\n+    /// Returns the start and end positions of the Nth capture group.\n+    /// Returns `None` if `i` is not a valid capture group or if the capture\n+    /// group did not match anything.\n+    /// The positions returned are *always* byte indices with respect to the\n+    /// original string matched.\n+    pub fn pos(&self, i: uint) -> Option<(uint, uint)> {\n+        let (s, e) = (i * 2, i * 2 + 1);\n+        if e >= self.locs.len() || self.locs.get(s).is_none() {\n+            // VM guarantees that each pair of locations are both Some or None.\n+            return None\n+        }\n+        Some((self.locs.get(s).unwrap(), self.locs.get(e).unwrap()))\n+    }\n+\n+    /// Returns the matched string for the capture group `i`.\n+    /// If `i` isn't a valid capture group or didn't match anything, then the\n+    /// empty string is returned.\n+    pub fn at(&self, i: uint) -> &'t str {\n+        match self.pos(i) {\n+            None => \"\",\n+            Some((s, e)) => {\n+                self.text.slice(s, e)\n+            }\n+        }\n+    }\n+\n+    /// Returns the matched string for the capture group named `name`.\n+    /// If `name` isn't a valid capture group or didn't match anything, then\n+    /// the empty string is returned.\n+    pub fn name(&self, name: &str) -> &'t str {\n+        match self.named {\n+            None => \"\",\n+            Some(ref h) => {\n+                match h.find_equiv(&name) {\n+                    None => \"\",\n+                    Some(i) => self.at(*i),\n+                }\n+            }\n+        }\n+    }\n+\n+    /// Creates an iterator of all the capture groups in order of appearance\n+    /// in the regular expression.\n+    pub fn iter(&'t self) -> SubCaptures<'t> {\n+        SubCaptures { idx: 0, caps: self, }\n+    }\n+\n+    /// Creates an iterator of all the capture group positions in order of\n+    /// appearance in the regular expression. Positions are byte indices\n+    /// in terms of the original string matched.\n+    pub fn iter_pos(&'t self) -> SubCapturesPos<'t> {\n+        SubCapturesPos { idx: 0, caps: self, }\n+    }\n+\n+    /// Expands all instances of `$name` in `text` to the corresponding capture\n+    /// group `name`.\n+    ///\n+    /// `name` may be an integer corresponding to the index of the\n+    /// capture group (counted by order of opening parenthesis where `0` is the\n+    /// entire match) or it can be a name (consisting of letters, digits or\n+    /// underscores) corresponding to a named capture group.\n+    ///\n+    /// If `name` isn't a valid capture group (whether the name doesn't exist or\n+    /// isn't a valid index), then it is replaced with the empty string.\n+    ///\n+    /// To write a literal `$` use `$$`.\n+    pub fn expand(&self, text: &str) -> StrBuf {\n+        // How evil can you get?\n+        // FIXME: Don't use regexes for this. It's completely unnecessary.\n+        let re = Regex::new(r\"(^|[^$]|\\b)\\$(\\w+)\").unwrap();\n+        let text = re.replace_all(text, |refs: &Captures| -> ~str {\n+            let (pre, name) = (refs.at(1), refs.at(2));\n+            pre + match from_str::<uint>(name) {\n+                None => self.name(name).to_owned(),\n+                Some(i) => self.at(i).to_owned(),\n+            }\n+        });\n+        let re = Regex::new(r\"\\$\\$\").unwrap();\n+        re.replace_all(text.as_slice(), NoExpand(\"$\"))\n+    }\n+}\n+\n+impl<'t> Container for Captures<'t> {\n+    /// Returns the number of captured groups.\n+    #[inline]\n+    fn len(&self) -> uint {\n+        self.locs.len() / 2\n+    }\n+}\n+\n+/// An iterator over capture groups for a particular match of a regular\n+/// expression.\n+///\n+/// `'t` is the lifetime of the matched text.\n+pub struct SubCaptures<'t> {\n+    idx: uint,\n+    caps: &'t Captures<'t>,\n+}\n+\n+impl<'t> Iterator<&'t str> for SubCaptures<'t> {\n+    fn next(&mut self) -> Option<&'t str> {\n+        if self.idx < self.caps.len() {\n+            self.idx += 1;\n+            Some(self.caps.at(self.idx - 1))\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+/// An iterator over capture group positions for a particular match of a\n+/// regular expression.\n+///\n+/// Positions are byte indices in terms of the original string matched.\n+///\n+/// `'t` is the lifetime of the matched text.\n+pub struct SubCapturesPos<'t> {\n+    idx: uint,\n+    caps: &'t Captures<'t>,\n+}\n+\n+impl<'t> Iterator<Option<(uint, uint)>> for SubCapturesPos<'t> {\n+    fn next(&mut self) -> Option<Option<(uint, uint)>> {\n+        if self.idx < self.caps.len() {\n+            self.idx += 1;\n+            Some(self.caps.pos(self.idx - 1))\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+/// An iterator that yields all non-overlapping capture groups matching a\n+/// particular regular expression. The iterator stops when no more matches can\n+/// be found.\n+///\n+/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n+/// of the matched string.\n+pub struct FindCaptures<'r, 't> {\n+    re: &'r Regex,\n+    search: &'t str,\n+    last_match: Option<uint>,\n+    last_end: uint,\n+}\n+\n+impl<'r, 't> Iterator<Captures<'t>> for FindCaptures<'r, 't> {\n+    fn next(&mut self) -> Option<Captures<'t>> {\n+        if self.last_end > self.search.len() {\n+            return None\n+        }\n+\n+        let caps = exec_slice(self.re, Submatches, self.search,\n+                              self.last_end, self.search.len());\n+        let (s, e) =\n+            if !has_match(&caps) {\n+                return None\n+            } else {\n+                (caps.get(0).unwrap(), caps.get(1).unwrap())\n+            };\n+\n+        // Don't accept empty matches immediately following a match.\n+        // i.e., no infinite loops please.\n+        if e - s == 0 && Some(self.last_end) == self.last_match {\n+            self.last_end += 1;\n+            return self.next()\n+        }\n+        self.last_end = e;\n+        self.last_match = Some(self.last_end);\n+        Captures::new(self.re, self.search, caps)\n+    }\n+}\n+\n+/// An iterator over all non-overlapping matches for a particular string.\n+///\n+/// The iterator yields a tuple of integers corresponding to the start and end\n+/// of the match. The indices are byte offsets. The iterator stops when no more\n+/// matches can be found.\n+///\n+/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n+/// of the matched string.\n+pub struct FindMatches<'r, 't> {\n+    re: &'r Regex,\n+    search: &'t str,\n+    last_match: Option<uint>,\n+    last_end: uint,\n+}\n+\n+impl<'r, 't> Iterator<(uint, uint)> for FindMatches<'r, 't> {\n+    fn next(&mut self) -> Option<(uint, uint)> {\n+        if self.last_end > self.search.len() {\n+            return None\n+        }\n+\n+        let caps = exec_slice(self.re, Location, self.search,\n+                              self.last_end, self.search.len());\n+        let (s, e) =\n+            if !has_match(&caps) {\n+                return None\n+            } else {\n+                (caps.get(0).unwrap(), caps.get(1).unwrap())\n+            };\n+\n+        // Don't accept empty matches immediately following a match.\n+        // i.e., no infinite loops please.\n+        if e - s == 0 && Some(self.last_end) == self.last_match {\n+            self.last_end += 1;\n+            return self.next()\n+        }\n+        self.last_end = e;\n+        self.last_match = Some(self.last_end);\n+        Some((s, e))\n+    }\n+}\n+\n+fn exec(re: &Regex, which: MatchKind, input: &str) -> CaptureLocs {\n+    exec_slice(re, which, input, 0, input.len())\n+}\n+\n+fn exec_slice(re: &Regex, which: MatchKind,\n+              input: &str, s: uint, e: uint) -> CaptureLocs {\n+    match re.p {\n+        Dynamic(ref prog) => vm::run(which, prog, input, s, e),\n+        Native(exec) => exec(which, input, s, e),\n+    }\n+}\n+\n+#[inline]\n+fn has_match(caps: &CaptureLocs) -> bool {\n+    caps.len() >= 2 && caps.get(0).is_some() && caps.get(1).is_some()\n+}"}, {"sha": "a5667ab088e75675298ca1fc8e1dfa33c59ec580", "filename": "src/libregex/test/bench.rs", "status": "added", "additions": 179, "deletions": 0, "changes": 179, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Fbench.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Fbench.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fbench.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,179 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use rand::{Rng, task_rng};\n+use stdtest::Bencher;\n+use std::str;\n+use regex::{Regex, NoExpand};\n+\n+fn bench_assert_match(b: &mut Bencher, re: Regex, text: &str) {\n+    b.iter(|| if !re.is_match(text) { fail!(\"no match\") });\n+}\n+\n+#[bench]\n+fn no_exponential(b: &mut Bencher) {\n+    let n = 100;\n+    let re = Regex::new(\"a?\".repeat(n) + \"a\".repeat(n)).unwrap();\n+    let text = \"a\".repeat(n);\n+    bench_assert_match(b, re, text);\n+}\n+\n+#[bench]\n+fn literal(b: &mut Bencher) {\n+    let re = regex!(\"y\");\n+    let text = \"x\".repeat(50) + \"y\";\n+    bench_assert_match(b, re, text);\n+}\n+\n+#[bench]\n+fn not_literal(b: &mut Bencher) {\n+    let re = regex!(\".y\");\n+    let text = \"x\".repeat(50) + \"y\";\n+    bench_assert_match(b, re, text);\n+}\n+\n+#[bench]\n+fn match_class(b: &mut Bencher) {\n+    let re = regex!(\"[abcdw]\");\n+    let text = \"xxxx\".repeat(20) + \"w\";\n+    bench_assert_match(b, re, text);\n+}\n+\n+#[bench]\n+fn match_class_in_range(b: &mut Bencher) {\n+    // 'b' is between 'a' and 'c', so the class range checking doesn't help.\n+    let re = regex!(\"[ac]\");\n+    let text = \"bbbb\".repeat(20) + \"c\";\n+    bench_assert_match(b, re, text);\n+}\n+\n+#[bench]\n+fn replace_all(b: &mut Bencher) {\n+    let re = regex!(\"[cjrw]\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\";\n+    // FIXME: This isn't using the $name expand stuff.\n+    // It's possible RE2/Go is using it, but currently, the expand in this\n+    // crate is actually compiling a regex, so it's incredibly slow.\n+    b.iter(|| re.replace_all(text, NoExpand(\"\")));\n+}\n+\n+#[bench]\n+fn anchored_literal_short_non_match(b: &mut Bencher) {\n+    let re = regex!(\"^zbc(d|e)\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn anchored_literal_long_non_match(b: &mut Bencher) {\n+    let re = regex!(\"^zbc(d|e)\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\".repeat(15);\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn anchored_literal_short_match(b: &mut Bencher) {\n+    let re = regex!(\"^.bc(d|e)\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn anchored_literal_long_match(b: &mut Bencher) {\n+    let re = regex!(\"^.bc(d|e)\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\".repeat(15);\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn one_pass_short_a(b: &mut Bencher) {\n+    let re = regex!(\"^.bc(d|e)*$\");\n+    let text = \"abcddddddeeeededd\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn one_pass_short_a_not(b: &mut Bencher) {\n+    let re = regex!(\".bc(d|e)*$\");\n+    let text = \"abcddddddeeeededd\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn one_pass_short_b(b: &mut Bencher) {\n+    let re = regex!(\"^.bc(?:d|e)*$\");\n+    let text = \"abcddddddeeeededd\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn one_pass_short_b_not(b: &mut Bencher) {\n+    let re = regex!(\".bc(?:d|e)*$\");\n+    let text = \"abcddddddeeeededd\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn one_pass_long_prefix(b: &mut Bencher) {\n+    let re = regex!(\"^abcdefghijklmnopqrstuvwxyz.*$\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+#[bench]\n+fn one_pass_long_prefix_not(b: &mut Bencher) {\n+    let re = regex!(\"^.bcdefghijklmnopqrstuvwxyz.*$\");\n+    let text = \"abcdefghijklmnopqrstuvwxyz\";\n+    b.iter(|| re.is_match(text));\n+}\n+\n+macro_rules! throughput(\n+    ($name:ident, $regex:expr, $size:expr) => (\n+        #[bench]\n+        fn $name(b: &mut Bencher) {\n+            let text = gen_text($size);\n+            b.bytes = $size;\n+            b.iter(|| if $regex.is_match(text) { fail!(\"match\") });\n+        }\n+    );\n+)\n+\n+fn easy0() -> Regex { regex!(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ$\") }\n+fn easy1() -> Regex { regex!(\"A[AB]B[BC]C[CD]D[DE]E[EF]F[FG]G[GH]H[HI]I[IJ]J$\") }\n+fn medium() -> Regex { regex!(\"[XYZ]ABCDEFGHIJKLMNOPQRSTUVWXYZ$\") }\n+fn hard() -> Regex { regex!(\"[ -~]*ABCDEFGHIJKLMNOPQRSTUVWXYZ$\") }\n+\n+fn gen_text(n: uint) -> ~str {\n+    let mut rng = task_rng();\n+    let mut bytes = rng.gen_ascii_str(n).into_bytes();\n+    for (i, b) in bytes.mut_iter().enumerate() {\n+        if i % 20 == 0 {\n+            *b = '\\n' as u8\n+        }\n+    }\n+    str::from_utf8(bytes).unwrap().to_owned()\n+}\n+\n+throughput!(easy0_32, easy0(), 32)\n+throughput!(easy0_1K, easy0(), 1<<10)\n+throughput!(easy0_32K, easy0(), 32<<10)\n+\n+throughput!(easy1_32, easy1(), 32)\n+throughput!(easy1_1K, easy1(), 1<<10)\n+throughput!(easy1_32K, easy1(), 32<<10)\n+\n+throughput!(medium_32, medium(), 32)\n+throughput!(medium_1K, medium(), 1<<10)\n+throughput!(medium_32K,medium(), 32<<10)\n+\n+throughput!(hard_32, hard(), 32)\n+throughput!(hard_1K, hard(), 1<<10)\n+throughput!(hard_32K,hard(), 32<<10)\n+"}, {"sha": "fb938513cb10b9fee81553f25093d4113868b77f", "filename": "src/libregex/test/matches.rs", "status": "added", "additions": 373, "deletions": 0, "changes": 373, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Fmatches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Fmatches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fmatches.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,373 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// ignore-tidy-linelength\n+\n+// DO NOT EDIT. Automatically generated by 'src/etc/regex-match-tests'\n+// on 2014-04-23 01:33:36.539280.\n+\n+// Tests from basic.dat\n+mat!(match_basic_3, r\"abracadabra$\", r\"abracadabracadabra\", Some((7, 18)))\n+mat!(match_basic_4, r\"a...b\", r\"abababbb\", Some((2, 7)))\n+mat!(match_basic_5, r\"XXXXXX\", r\"..XXXXXX\", Some((2, 8)))\n+mat!(match_basic_6, r\"\\)\", r\"()\", Some((1, 2)))\n+mat!(match_basic_7, r\"a]\", r\"a]a\", Some((0, 2)))\n+mat!(match_basic_9, r\"\\}\", r\"}\", Some((0, 1)))\n+mat!(match_basic_10, r\"\\]\", r\"]\", Some((0, 1)))\n+mat!(match_basic_12, r\"]\", r\"]\", Some((0, 1)))\n+mat!(match_basic_15, r\"^a\", r\"ax\", Some((0, 1)))\n+mat!(match_basic_16, r\"\\^a\", r\"a^a\", Some((1, 3)))\n+mat!(match_basic_17, r\"a\\^\", r\"a^\", Some((0, 2)))\n+mat!(match_basic_18, r\"a$\", r\"aa\", Some((1, 2)))\n+mat!(match_basic_19, r\"a\\$\", r\"a$\", Some((0, 2)))\n+mat!(match_basic_20, r\"^$\", r\"\", Some((0, 0)))\n+mat!(match_basic_21, r\"$^\", r\"\", Some((0, 0)))\n+mat!(match_basic_22, r\"a($)\", r\"aa\", Some((1, 2)), Some((2, 2)))\n+mat!(match_basic_23, r\"a*(^a)\", r\"aa\", Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_24, r\"(..)*(...)*\", r\"a\", Some((0, 0)))\n+mat!(match_basic_25, r\"(..)*(...)*\", r\"abcd\", Some((0, 4)), Some((2, 4)))\n+mat!(match_basic_26, r\"(ab|a)(bc|c)\", r\"abc\", Some((0, 3)), Some((0, 2)), Some((2, 3)))\n+mat!(match_basic_27, r\"(ab)c|abc\", r\"abc\", Some((0, 3)), Some((0, 2)))\n+mat!(match_basic_28, r\"a{0}b\", r\"ab\", Some((1, 2)))\n+mat!(match_basic_29, r\"(a*)(b?)(b+)b{3}\", r\"aaabbbbbbb\", Some((0, 10)), Some((0, 3)), Some((3, 4)), Some((4, 7)))\n+mat!(match_basic_30, r\"(a*)(b{0,1})(b{1,})b{3}\", r\"aaabbbbbbb\", Some((0, 10)), Some((0, 3)), Some((3, 4)), Some((4, 7)))\n+mat!(match_basic_32, r\"((a|a)|a)\", r\"a\", Some((0, 1)), Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_33, r\"(a*)(a|aa)\", r\"aaaa\", Some((0, 4)), Some((0, 3)), Some((3, 4)))\n+mat!(match_basic_34, r\"a*(a.|aa)\", r\"aaaa\", Some((0, 4)), Some((2, 4)))\n+mat!(match_basic_35, r\"a(b)|c(d)|a(e)f\", r\"aef\", Some((0, 3)), None, None, Some((1, 2)))\n+mat!(match_basic_36, r\"(a|b)?.*\", r\"b\", Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_37, r\"(a|b)c|a(b|c)\", r\"ac\", Some((0, 2)), Some((0, 1)))\n+mat!(match_basic_38, r\"(a|b)c|a(b|c)\", r\"ab\", Some((0, 2)), None, Some((1, 2)))\n+mat!(match_basic_39, r\"(a|b)*c|(a|ab)*c\", r\"abc\", Some((0, 3)), Some((1, 2)))\n+mat!(match_basic_40, r\"(a|b)*c|(a|ab)*c\", r\"xc\", Some((1, 2)))\n+mat!(match_basic_41, r\"(.a|.b).*|.*(.a|.b)\", r\"xa\", Some((0, 2)), Some((0, 2)))\n+mat!(match_basic_42, r\"a?(ab|ba)ab\", r\"abab\", Some((0, 4)), Some((0, 2)))\n+mat!(match_basic_43, r\"a?(ac{0}b|ba)ab\", r\"abab\", Some((0, 4)), Some((0, 2)))\n+mat!(match_basic_44, r\"ab|abab\", r\"abbabab\", Some((0, 2)))\n+mat!(match_basic_45, r\"aba|bab|bba\", r\"baaabbbaba\", Some((5, 8)))\n+mat!(match_basic_46, r\"aba|bab\", r\"baaabbbaba\", Some((6, 9)))\n+mat!(match_basic_47, r\"(aa|aaa)*|(a|aaaaa)\", r\"aa\", Some((0, 2)), Some((0, 2)))\n+mat!(match_basic_48, r\"(a.|.a.)*|(a|.a...)\", r\"aa\", Some((0, 2)), Some((0, 2)))\n+mat!(match_basic_49, r\"ab|a\", r\"xabc\", Some((1, 3)))\n+mat!(match_basic_50, r\"ab|a\", r\"xxabc\", Some((2, 4)))\n+mat!(match_basic_51, r\"(?i)(Ab|cD)*\", r\"aBcD\", Some((0, 4)), Some((2, 4)))\n+mat!(match_basic_52, r\"[^-]\", r\"--a\", Some((2, 3)))\n+mat!(match_basic_53, r\"[a-]*\", r\"--a\", Some((0, 3)))\n+mat!(match_basic_54, r\"[a-m-]*\", r\"--amoma--\", Some((0, 4)))\n+mat!(match_basic_55, r\":::1:::0:|:::1:1:0:\", r\":::0:::1:::1:::0:\", Some((8, 17)))\n+mat!(match_basic_56, r\":::1:::0:|:::1:1:1:\", r\":::0:::1:::1:::0:\", Some((8, 17)))\n+mat!(match_basic_57, r\"[[:upper:]]\", r\"A\", Some((0, 1)))\n+mat!(match_basic_58, r\"[[:lower:]]+\", r\"`az{\", Some((1, 3)))\n+mat!(match_basic_59, r\"[[:upper:]]+\", r\"@AZ[\", Some((1, 3)))\n+mat!(match_basic_65, r\"\n+\", r\"\n+\", Some((0, 1)))\n+mat!(match_basic_66, r\"\n+\", r\"\n+\", Some((0, 1)))\n+mat!(match_basic_67, r\"[^a]\", r\"\n+\", Some((0, 1)))\n+mat!(match_basic_68, r\"\n+a\", r\"\n+a\", Some((0, 2)))\n+mat!(match_basic_69, r\"(a)(b)(c)\", r\"abc\", Some((0, 3)), Some((0, 1)), Some((1, 2)), Some((2, 3)))\n+mat!(match_basic_70, r\"xxx\", r\"xxx\", Some((0, 3)))\n+mat!(match_basic_71, r\"(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\", r\"feb 6,\", Some((0, 6)))\n+mat!(match_basic_72, r\"(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\", r\"2/7\", Some((0, 3)))\n+mat!(match_basic_73, r\"(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\", r\"feb 1,Feb 6\", Some((5, 11)))\n+mat!(match_basic_74, r\"((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))\", r\"x\", Some((0, 1)), Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_75, r\"((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))*\", r\"xx\", Some((0, 2)), Some((1, 2)), Some((1, 2)))\n+mat!(match_basic_76, r\"a?(ab|ba)*\", r\"ababababababababababababababababababababababababababababababababababababababababa\", Some((0, 81)), Some((79, 81)))\n+mat!(match_basic_77, r\"abaa|abbaa|abbbaa|abbbbaa\", r\"ababbabbbabbbabbbbabbbbaa\", Some((18, 25)))\n+mat!(match_basic_78, r\"abaa|abbaa|abbbaa|abbbbaa\", r\"ababbabbbabbbabbbbabaa\", Some((18, 22)))\n+mat!(match_basic_79, r\"aaac|aabc|abac|abbc|baac|babc|bbac|bbbc\", r\"baaabbbabac\", Some((7, 11)))\n+mat!(match_basic_80, r\".*\", r\"\u0001\u007f\", Some((0, 2)))\n+mat!(match_basic_81, r\"aaaa|bbbb|cccc|ddddd|eeeeee|fffffff|gggg|hhhh|iiiii|jjjjj|kkkkk|llll\", r\"XaaaXbbbXcccXdddXeeeXfffXgggXhhhXiiiXjjjXkkkXlllXcbaXaaaa\", Some((53, 57)))\n+mat!(match_basic_83, r\"a*a*a*a*a*b\", r\"aaaaaaaaab\", Some((0, 10)))\n+mat!(match_basic_84, r\"^\", r\"\", Some((0, 0)))\n+mat!(match_basic_85, r\"$\", r\"\", Some((0, 0)))\n+mat!(match_basic_86, r\"^$\", r\"\", Some((0, 0)))\n+mat!(match_basic_87, r\"^a$\", r\"a\", Some((0, 1)))\n+mat!(match_basic_88, r\"abc\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_89, r\"abc\", r\"xabcy\", Some((1, 4)))\n+mat!(match_basic_90, r\"abc\", r\"ababc\", Some((2, 5)))\n+mat!(match_basic_91, r\"ab*c\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_92, r\"ab*bc\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_93, r\"ab*bc\", r\"abbc\", Some((0, 4)))\n+mat!(match_basic_94, r\"ab*bc\", r\"abbbbc\", Some((0, 6)))\n+mat!(match_basic_95, r\"ab+bc\", r\"abbc\", Some((0, 4)))\n+mat!(match_basic_96, r\"ab+bc\", r\"abbbbc\", Some((0, 6)))\n+mat!(match_basic_97, r\"ab?bc\", r\"abbc\", Some((0, 4)))\n+mat!(match_basic_98, r\"ab?bc\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_99, r\"ab?c\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_100, r\"^abc$\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_101, r\"^abc\", r\"abcc\", Some((0, 3)))\n+mat!(match_basic_102, r\"abc$\", r\"aabc\", Some((1, 4)))\n+mat!(match_basic_103, r\"^\", r\"abc\", Some((0, 0)))\n+mat!(match_basic_104, r\"$\", r\"abc\", Some((3, 3)))\n+mat!(match_basic_105, r\"a.c\", r\"abc\", Some((0, 3)))\n+mat!(match_basic_106, r\"a.c\", r\"axc\", Some((0, 3)))\n+mat!(match_basic_107, r\"a.*c\", r\"axyzc\", Some((0, 5)))\n+mat!(match_basic_108, r\"a[bc]d\", r\"abd\", Some((0, 3)))\n+mat!(match_basic_109, r\"a[b-d]e\", r\"ace\", Some((0, 3)))\n+mat!(match_basic_110, r\"a[b-d]\", r\"aac\", Some((1, 3)))\n+mat!(match_basic_111, r\"a[-b]\", r\"a-\", Some((0, 2)))\n+mat!(match_basic_112, r\"a[b-]\", r\"a-\", Some((0, 2)))\n+mat!(match_basic_113, r\"a]\", r\"a]\", Some((0, 2)))\n+mat!(match_basic_114, r\"a[]]b\", r\"a]b\", Some((0, 3)))\n+mat!(match_basic_115, r\"a[^bc]d\", r\"aed\", Some((0, 3)))\n+mat!(match_basic_116, r\"a[^-b]c\", r\"adc\", Some((0, 3)))\n+mat!(match_basic_117, r\"a[^]b]c\", r\"adc\", Some((0, 3)))\n+mat!(match_basic_118, r\"ab|cd\", r\"abc\", Some((0, 2)))\n+mat!(match_basic_119, r\"ab|cd\", r\"abcd\", Some((0, 2)))\n+mat!(match_basic_120, r\"a\\(b\", r\"a(b\", Some((0, 3)))\n+mat!(match_basic_121, r\"a\\(*b\", r\"ab\", Some((0, 2)))\n+mat!(match_basic_122, r\"a\\(*b\", r\"a((b\", Some((0, 4)))\n+mat!(match_basic_123, r\"((a))\", r\"abc\", Some((0, 1)), Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_124, r\"(a)b(c)\", r\"abc\", Some((0, 3)), Some((0, 1)), Some((2, 3)))\n+mat!(match_basic_125, r\"a+b+c\", r\"aabbabc\", Some((4, 7)))\n+mat!(match_basic_126, r\"a*\", r\"aaa\", Some((0, 3)))\n+mat!(match_basic_128, r\"(a*)*\", r\"-\", Some((0, 0)), None)\n+mat!(match_basic_129, r\"(a*)+\", r\"-\", Some((0, 0)), Some((0, 0)))\n+mat!(match_basic_131, r\"(a*|b)*\", r\"-\", Some((0, 0)), None)\n+mat!(match_basic_132, r\"(a+|b)*\", r\"ab\", Some((0, 2)), Some((1, 2)))\n+mat!(match_basic_133, r\"(a+|b)+\", r\"ab\", Some((0, 2)), Some((1, 2)))\n+mat!(match_basic_134, r\"(a+|b)?\", r\"ab\", Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_135, r\"[^ab]*\", r\"cde\", Some((0, 3)))\n+mat!(match_basic_137, r\"(^)*\", r\"-\", Some((0, 0)), None)\n+mat!(match_basic_138, r\"a*\", r\"\", Some((0, 0)))\n+mat!(match_basic_139, r\"([abc])*d\", r\"abbbcd\", Some((0, 6)), Some((4, 5)))\n+mat!(match_basic_140, r\"([abc])*bcd\", r\"abcd\", Some((0, 4)), Some((0, 1)))\n+mat!(match_basic_141, r\"a|b|c|d|e\", r\"e\", Some((0, 1)))\n+mat!(match_basic_142, r\"(a|b|c|d|e)f\", r\"ef\", Some((0, 2)), Some((0, 1)))\n+mat!(match_basic_144, r\"((a*|b))*\", r\"-\", Some((0, 0)), None, None)\n+mat!(match_basic_145, r\"abcd*efg\", r\"abcdefg\", Some((0, 7)))\n+mat!(match_basic_146, r\"ab*\", r\"xabyabbbz\", Some((1, 3)))\n+mat!(match_basic_147, r\"ab*\", r\"xayabbbz\", Some((1, 2)))\n+mat!(match_basic_148, r\"(ab|cd)e\", r\"abcde\", Some((2, 5)), Some((2, 4)))\n+mat!(match_basic_149, r\"[abhgefdc]ij\", r\"hij\", Some((0, 3)))\n+mat!(match_basic_150, r\"(a|b)c*d\", r\"abcd\", Some((1, 4)), Some((1, 2)))\n+mat!(match_basic_151, r\"(ab|ab*)bc\", r\"abc\", Some((0, 3)), Some((0, 1)))\n+mat!(match_basic_152, r\"a([bc]*)c*\", r\"abc\", Some((0, 3)), Some((1, 3)))\n+mat!(match_basic_153, r\"a([bc]*)(c*d)\", r\"abcd\", Some((0, 4)), Some((1, 3)), Some((3, 4)))\n+mat!(match_basic_154, r\"a([bc]+)(c*d)\", r\"abcd\", Some((0, 4)), Some((1, 3)), Some((3, 4)))\n+mat!(match_basic_155, r\"a([bc]*)(c+d)\", r\"abcd\", Some((0, 4)), Some((1, 2)), Some((2, 4)))\n+mat!(match_basic_156, r\"a[bcd]*dcdcde\", r\"adcdcde\", Some((0, 7)))\n+mat!(match_basic_157, r\"(ab|a)b*c\", r\"abc\", Some((0, 3)), Some((0, 2)))\n+mat!(match_basic_158, r\"((a)(b)c)(d)\", r\"abcd\", Some((0, 4)), Some((0, 3)), Some((0, 1)), Some((1, 2)), Some((3, 4)))\n+mat!(match_basic_159, r\"[A-Za-z_][A-Za-z0-9_]*\", r\"alpha\", Some((0, 5)))\n+mat!(match_basic_160, r\"^a(bc+|b[eh])g|.h$\", r\"abh\", Some((1, 3)))\n+mat!(match_basic_161, r\"(bc+d$|ef*g.|h?i(j|k))\", r\"effgz\", Some((0, 5)), Some((0, 5)))\n+mat!(match_basic_162, r\"(bc+d$|ef*g.|h?i(j|k))\", r\"ij\", Some((0, 2)), Some((0, 2)), Some((1, 2)))\n+mat!(match_basic_163, r\"(bc+d$|ef*g.|h?i(j|k))\", r\"reffgz\", Some((1, 6)), Some((1, 6)))\n+mat!(match_basic_164, r\"(((((((((a)))))))))\", r\"a\", Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)))\n+mat!(match_basic_165, r\"multiple words\", r\"multiple words yeah\", Some((0, 14)))\n+mat!(match_basic_166, r\"(.*)c(.*)\", r\"abcde\", Some((0, 5)), Some((0, 2)), Some((3, 5)))\n+mat!(match_basic_167, r\"abcd\", r\"abcd\", Some((0, 4)))\n+mat!(match_basic_168, r\"a(bc)d\", r\"abcd\", Some((0, 4)), Some((1, 3)))\n+mat!(match_basic_169, r\"a[\u0001-\u0003]?c\", r\"a\u0002c\", Some((0, 3)))\n+mat!(match_basic_170, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Qaddafi\", Some((0, 15)), None, Some((10, 12)))\n+mat!(match_basic_171, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Mo'ammar Gadhafi\", Some((0, 16)), None, Some((11, 13)))\n+mat!(match_basic_172, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Kaddafi\", Some((0, 15)), None, Some((10, 12)))\n+mat!(match_basic_173, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Qadhafi\", Some((0, 15)), None, Some((10, 12)))\n+mat!(match_basic_174, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Gadafi\", Some((0, 14)), None, Some((10, 11)))\n+mat!(match_basic_175, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Mu'ammar Qadafi\", Some((0, 15)), None, Some((11, 12)))\n+mat!(match_basic_176, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Moamar Gaddafi\", Some((0, 14)), None, Some((9, 11)))\n+mat!(match_basic_177, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Mu'ammar Qadhdhafi\", Some((0, 18)), None, Some((13, 15)))\n+mat!(match_basic_178, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Khaddafi\", Some((0, 16)), None, Some((11, 13)))\n+mat!(match_basic_179, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Ghaddafy\", Some((0, 16)), None, Some((11, 13)))\n+mat!(match_basic_180, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Ghadafi\", Some((0, 15)), None, Some((11, 12)))\n+mat!(match_basic_181, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Ghaddafi\", Some((0, 16)), None, Some((11, 13)))\n+mat!(match_basic_182, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muamar Kaddafi\", Some((0, 14)), None, Some((9, 11)))\n+mat!(match_basic_183, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Quathafi\", Some((0, 16)), None, Some((11, 13)))\n+mat!(match_basic_184, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Gheddafi\", Some((0, 16)), None, Some((11, 13)))\n+mat!(match_basic_185, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Moammar Khadafy\", Some((0, 15)), None, Some((11, 12)))\n+mat!(match_basic_186, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Moammar Qudhafi\", Some((0, 15)), None, Some((10, 12)))\n+mat!(match_basic_187, r\"a+(b|c)*d+\", r\"aabcdd\", Some((0, 6)), Some((3, 4)))\n+mat!(match_basic_188, r\"^.+$\", r\"vivi\", Some((0, 4)))\n+mat!(match_basic_189, r\"^(.+)$\", r\"vivi\", Some((0, 4)), Some((0, 4)))\n+mat!(match_basic_190, r\"^([^!.]+).att.com!(.+)$\", r\"gryphon.att.com!eby\", Some((0, 19)), Some((0, 7)), Some((16, 19)))\n+mat!(match_basic_191, r\"^([^!]+!)?([^!]+)$\", r\"bas\", Some((0, 3)), None, Some((0, 3)))\n+mat!(match_basic_192, r\"^([^!]+!)?([^!]+)$\", r\"bar!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7)))\n+mat!(match_basic_193, r\"^([^!]+!)?([^!]+)$\", r\"foo!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7)))\n+mat!(match_basic_194, r\"^.+!([^!]+!)([^!]+)$\", r\"foo!bar!bas\", Some((0, 11)), Some((4, 8)), Some((8, 11)))\n+mat!(match_basic_195, r\"((foo)|(bar))!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3)), None, Some((0, 3)))\n+mat!(match_basic_196, r\"((foo)|(bar))!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7)), None, Some((4, 7)))\n+mat!(match_basic_197, r\"((foo)|(bar))!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3)), Some((0, 3)))\n+mat!(match_basic_198, r\"((foo)|bar)!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3)))\n+mat!(match_basic_199, r\"((foo)|bar)!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7)))\n+mat!(match_basic_200, r\"((foo)|bar)!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3)), Some((0, 3)))\n+mat!(match_basic_201, r\"(foo|(bar))!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3)), Some((0, 3)))\n+mat!(match_basic_202, r\"(foo|(bar))!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7)), Some((4, 7)))\n+mat!(match_basic_203, r\"(foo|(bar))!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3)))\n+mat!(match_basic_204, r\"(foo|bar)!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3)))\n+mat!(match_basic_205, r\"(foo|bar)!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7)))\n+mat!(match_basic_206, r\"(foo|bar)!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3)))\n+mat!(match_basic_207, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"foo!bar!bas\", Some((0, 11)), Some((0, 11)), None, None, Some((4, 8)), Some((8, 11)))\n+mat!(match_basic_208, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"bas\", Some((0, 3)), None, Some((0, 3)))\n+mat!(match_basic_209, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"bar!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7)))\n+mat!(match_basic_210, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"foo!bar!bas\", Some((0, 11)), None, None, Some((4, 8)), Some((8, 11)))\n+mat!(match_basic_211, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"foo!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7)))\n+mat!(match_basic_212, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"bas\", Some((0, 3)), Some((0, 3)), None, Some((0, 3)))\n+mat!(match_basic_213, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"bar!bas\", Some((0, 7)), Some((0, 7)), Some((0, 4)), Some((4, 7)))\n+mat!(match_basic_214, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"foo!bar!bas\", Some((0, 11)), Some((0, 11)), None, None, Some((4, 8)), Some((8, 11)))\n+mat!(match_basic_215, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"foo!bas\", Some((0, 7)), Some((0, 7)), Some((0, 4)), Some((4, 7)))\n+mat!(match_basic_216, r\".*(/XXX).*\", r\"/XXX\", Some((0, 4)), Some((0, 4)))\n+mat!(match_basic_217, r\".*(\\\\XXX).*\", r\"\\XXX\", Some((0, 4)), Some((0, 4)))\n+mat!(match_basic_218, r\"\\\\XXX\", r\"\\XXX\", Some((0, 4)))\n+mat!(match_basic_219, r\".*(/000).*\", r\"/000\", Some((0, 4)), Some((0, 4)))\n+mat!(match_basic_220, r\".*(\\\\000).*\", r\"\\000\", Some((0, 4)), Some((0, 4)))\n+mat!(match_basic_221, r\"\\\\000\", r\"\\000\", Some((0, 4)))\n+\n+// Tests from nullsubexpr.dat\n+mat!(match_nullsubexpr_3, r\"(a*)*\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_5, r\"(a*)*\", r\"x\", Some((0, 0)), None)\n+mat!(match_nullsubexpr_6, r\"(a*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_7, r\"(a*)*\", r\"aaaaaax\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_8, r\"(a*)+\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_9, r\"(a*)+\", r\"x\", Some((0, 0)), Some((0, 0)))\n+mat!(match_nullsubexpr_10, r\"(a*)+\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_11, r\"(a*)+\", r\"aaaaaax\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_12, r\"(a+)*\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_13, r\"(a+)*\", r\"x\", Some((0, 0)))\n+mat!(match_nullsubexpr_14, r\"(a+)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_15, r\"(a+)*\", r\"aaaaaax\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_16, r\"(a+)+\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_17, r\"(a+)+\", r\"x\", None)\n+mat!(match_nullsubexpr_18, r\"(a+)+\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_19, r\"(a+)+\", r\"aaaaaax\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_21, r\"([a]*)*\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_23, r\"([a]*)*\", r\"x\", Some((0, 0)), None)\n+mat!(match_nullsubexpr_24, r\"([a]*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_25, r\"([a]*)*\", r\"aaaaaax\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_26, r\"([a]*)+\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_27, r\"([a]*)+\", r\"x\", Some((0, 0)), Some((0, 0)))\n+mat!(match_nullsubexpr_28, r\"([a]*)+\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_29, r\"([a]*)+\", r\"aaaaaax\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_30, r\"([^b]*)*\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_32, r\"([^b]*)*\", r\"b\", Some((0, 0)), None)\n+mat!(match_nullsubexpr_33, r\"([^b]*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_34, r\"([^b]*)*\", r\"aaaaaab\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_35, r\"([ab]*)*\", r\"a\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_36, r\"([ab]*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_37, r\"([ab]*)*\", r\"ababab\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_38, r\"([ab]*)*\", r\"bababa\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_39, r\"([ab]*)*\", r\"b\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_40, r\"([ab]*)*\", r\"bbbbbb\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_41, r\"([ab]*)*\", r\"aaaabcde\", Some((0, 5)), Some((0, 5)))\n+mat!(match_nullsubexpr_42, r\"([^a]*)*\", r\"b\", Some((0, 1)), Some((0, 1)))\n+mat!(match_nullsubexpr_43, r\"([^a]*)*\", r\"bbbbbb\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_45, r\"([^a]*)*\", r\"aaaaaa\", Some((0, 0)), None)\n+mat!(match_nullsubexpr_46, r\"([^ab]*)*\", r\"ccccxx\", Some((0, 6)), Some((0, 6)))\n+mat!(match_nullsubexpr_48, r\"([^ab]*)*\", r\"ababab\", Some((0, 0)), None)\n+mat!(match_nullsubexpr_50, r\"((z)+|a)*\", r\"zabcde\", Some((0, 2)), Some((1, 2)))\n+mat!(match_nullsubexpr_69, r\"(a*)*(x)\", r\"x\", Some((0, 1)), None, Some((0, 1)))\n+mat!(match_nullsubexpr_70, r\"(a*)*(x)\", r\"ax\", Some((0, 2)), Some((0, 1)), Some((1, 2)))\n+mat!(match_nullsubexpr_71, r\"(a*)*(x)\", r\"axa\", Some((0, 2)), Some((0, 1)), Some((1, 2)))\n+mat!(match_nullsubexpr_73, r\"(a*)+(x)\", r\"x\", Some((0, 1)), Some((0, 0)), Some((0, 1)))\n+mat!(match_nullsubexpr_74, r\"(a*)+(x)\", r\"ax\", Some((0, 2)), Some((0, 1)), Some((1, 2)))\n+mat!(match_nullsubexpr_75, r\"(a*)+(x)\", r\"axa\", Some((0, 2)), Some((0, 1)), Some((1, 2)))\n+mat!(match_nullsubexpr_77, r\"(a*){2}(x)\", r\"x\", Some((0, 1)), Some((0, 0)), Some((0, 1)))\n+mat!(match_nullsubexpr_78, r\"(a*){2}(x)\", r\"ax\", Some((0, 2)), Some((1, 1)), Some((1, 2)))\n+mat!(match_nullsubexpr_79, r\"(a*){2}(x)\", r\"axa\", Some((0, 2)), Some((1, 1)), Some((1, 2)))\n+\n+// Tests from repetition.dat\n+mat!(match_repetition_10, r\"((..)|(.))\", r\"\", None)\n+mat!(match_repetition_11, r\"((..)|(.))((..)|(.))\", r\"\", None)\n+mat!(match_repetition_12, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"\", None)\n+mat!(match_repetition_14, r\"((..)|(.)){1}\", r\"\", None)\n+mat!(match_repetition_15, r\"((..)|(.)){2}\", r\"\", None)\n+mat!(match_repetition_16, r\"((..)|(.)){3}\", r\"\", None)\n+mat!(match_repetition_18, r\"((..)|(.))*\", r\"\", Some((0, 0)))\n+mat!(match_repetition_20, r\"((..)|(.))\", r\"a\", Some((0, 1)), Some((0, 1)), None, Some((0, 1)))\n+mat!(match_repetition_21, r\"((..)|(.))((..)|(.))\", r\"a\", None)\n+mat!(match_repetition_22, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"a\", None)\n+mat!(match_repetition_24, r\"((..)|(.)){1}\", r\"a\", Some((0, 1)), Some((0, 1)), None, Some((0, 1)))\n+mat!(match_repetition_25, r\"((..)|(.)){2}\", r\"a\", None)\n+mat!(match_repetition_26, r\"((..)|(.)){3}\", r\"a\", None)\n+mat!(match_repetition_28, r\"((..)|(.))*\", r\"a\", Some((0, 1)), Some((0, 1)), None, Some((0, 1)))\n+mat!(match_repetition_30, r\"((..)|(.))\", r\"aa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_31, r\"((..)|(.))((..)|(.))\", r\"aa\", Some((0, 2)), Some((0, 1)), None, Some((0, 1)), Some((1, 2)), None, Some((1, 2)))\n+mat!(match_repetition_32, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aa\", None)\n+mat!(match_repetition_34, r\"((..)|(.)){1}\", r\"aa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_35, r\"((..)|(.)){2}\", r\"aa\", Some((0, 2)), Some((1, 2)), None, Some((1, 2)))\n+mat!(match_repetition_36, r\"((..)|(.)){3}\", r\"aa\", None)\n+mat!(match_repetition_38, r\"((..)|(.))*\", r\"aa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_40, r\"((..)|(.))\", r\"aaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_41, r\"((..)|(.))((..)|(.))\", r\"aaa\", Some((0, 3)), Some((0, 2)), Some((0, 2)), None, Some((2, 3)), None, Some((2, 3)))\n+mat!(match_repetition_42, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaa\", Some((0, 3)), Some((0, 1)), None, Some((0, 1)), Some((1, 2)), None, Some((1, 2)), Some((2, 3)), None, Some((2, 3)))\n+mat!(match_repetition_44, r\"((..)|(.)){1}\", r\"aaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_46, r\"((..)|(.)){2}\", r\"aaa\", Some((0, 3)), Some((2, 3)), Some((0, 2)), Some((2, 3)))\n+mat!(match_repetition_47, r\"((..)|(.)){3}\", r\"aaa\", Some((0, 3)), Some((2, 3)), None, Some((2, 3)))\n+mat!(match_repetition_50, r\"((..)|(.))*\", r\"aaa\", Some((0, 3)), Some((2, 3)), Some((0, 2)), Some((2, 3)))\n+mat!(match_repetition_52, r\"((..)|(.))\", r\"aaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_53, r\"((..)|(.))((..)|(.))\", r\"aaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_54, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 3)), None, Some((2, 3)), Some((3, 4)), None, Some((3, 4)))\n+mat!(match_repetition_56, r\"((..)|(.)){1}\", r\"aaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_57, r\"((..)|(.)){2}\", r\"aaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_59, r\"((..)|(.)){3}\", r\"aaaa\", Some((0, 4)), Some((3, 4)), Some((0, 2)), Some((3, 4)))\n+mat!(match_repetition_61, r\"((..)|(.))*\", r\"aaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_63, r\"((..)|(.))\", r\"aaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_64, r\"((..)|(.))((..)|(.))\", r\"aaaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_65, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaaaa\", Some((0, 5)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None, Some((4, 5)), None, Some((4, 5)))\n+mat!(match_repetition_67, r\"((..)|(.)){1}\", r\"aaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_68, r\"((..)|(.)){2}\", r\"aaaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_70, r\"((..)|(.)){3}\", r\"aaaaa\", Some((0, 5)), Some((4, 5)), Some((2, 4)), Some((4, 5)))\n+mat!(match_repetition_73, r\"((..)|(.))*\", r\"aaaaa\", Some((0, 5)), Some((4, 5)), Some((2, 4)), Some((4, 5)))\n+mat!(match_repetition_75, r\"((..)|(.))\", r\"aaaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_76, r\"((..)|(.))((..)|(.))\", r\"aaaaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_77, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaaaaa\", Some((0, 6)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None, Some((4, 6)), Some((4, 6)), None)\n+mat!(match_repetition_79, r\"((..)|(.)){1}\", r\"aaaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None)\n+mat!(match_repetition_80, r\"((..)|(.)){2}\", r\"aaaaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None)\n+mat!(match_repetition_81, r\"((..)|(.)){3}\", r\"aaaaaa\", Some((0, 6)), Some((4, 6)), Some((4, 6)), None)\n+mat!(match_repetition_83, r\"((..)|(.))*\", r\"aaaaaa\", Some((0, 6)), Some((4, 6)), Some((4, 6)), None)\n+mat!(match_repetition_90, r\"X(.?){0,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_91, r\"X(.?){1,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_92, r\"X(.?){2,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_93, r\"X(.?){3,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_94, r\"X(.?){4,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_95, r\"X(.?){5,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_96, r\"X(.?){6,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_97, r\"X(.?){7,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8)))\n+mat!(match_repetition_98, r\"X(.?){8,}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_100, r\"X(.?){0,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_102, r\"X(.?){1,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_104, r\"X(.?){2,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_106, r\"X(.?){3,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_108, r\"X(.?){4,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_110, r\"X(.?){5,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_112, r\"X(.?){6,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_114, r\"X(.?){7,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_115, r\"X(.?){8,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8)))\n+mat!(match_repetition_126, r\"(a|ab|c|bcd){0,}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1)))\n+mat!(match_repetition_127, r\"(a|ab|c|bcd){1,}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1)))\n+mat!(match_repetition_128, r\"(a|ab|c|bcd){2,}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6)))\n+mat!(match_repetition_129, r\"(a|ab|c|bcd){3,}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6)))\n+mat!(match_repetition_130, r\"(a|ab|c|bcd){4,}(d*)\", r\"ababcd\", None)\n+mat!(match_repetition_131, r\"(a|ab|c|bcd){0,10}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1)))\n+mat!(match_repetition_132, r\"(a|ab|c|bcd){1,10}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1)))\n+mat!(match_repetition_133, r\"(a|ab|c|bcd){2,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6)))\n+mat!(match_repetition_134, r\"(a|ab|c|bcd){3,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6)))\n+mat!(match_repetition_135, r\"(a|ab|c|bcd){4,10}(d*)\", r\"ababcd\", None)\n+mat!(match_repetition_136, r\"(a|ab|c|bcd)*(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1)))\n+mat!(match_repetition_137, r\"(a|ab|c|bcd)+(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1)))\n+mat!(match_repetition_143, r\"(ab|a|c|bcd){0,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_145, r\"(ab|a|c|bcd){1,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_147, r\"(ab|a|c|bcd){2,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_149, r\"(ab|a|c|bcd){3,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_150, r\"(ab|a|c|bcd){4,}(d*)\", r\"ababcd\", None)\n+mat!(match_repetition_152, r\"(ab|a|c|bcd){0,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_154, r\"(ab|a|c|bcd){1,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_156, r\"(ab|a|c|bcd){2,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_158, r\"(ab|a|c|bcd){3,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_159, r\"(ab|a|c|bcd){4,10}(d*)\", r\"ababcd\", None)\n+mat!(match_repetition_161, r\"(ab|a|c|bcd)*(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+mat!(match_repetition_163, r\"(ab|a|c|bcd)+(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6)))\n+"}, {"sha": "9386e17e92088cd065e10fd73cc3deb587319ead", "filename": "src/libregex/test/mod.rs", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fmod.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,29 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#[cfg(not(stage1))]\n+#[phase(syntax)]\n+extern crate regex_macros;\n+\n+// Dirty hack: During stage1, test dynamic regexs. For stage2, we test\n+// native regexs.\n+#[cfg(stage1)]\n+macro_rules! regex(\n+    ($re:expr) => (\n+        match ::regex::Regex::new($re) {\n+            Ok(re) => re,\n+            Err(err) => fail!(\"{}\", err),\n+        }\n+    );\n+)\n+\n+mod bench;\n+mod tests;\n+"}, {"sha": "ce8996c681d85539870f9cf71327c5d6b99c9e0a", "filename": "src/libregex/test/tests.rs", "status": "added", "additions": 199, "deletions": 0, "changes": 199, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftest%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Ftests.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,199 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// ignore-tidy-linelength\n+\n+use regex::{Regex, NoExpand};\n+\n+#[test]\n+fn splitn() {\n+    let re = regex!(r\"\\d+\");\n+    let text = \"cauchy123plato456tyler789binx\";\n+    let subs: Vec<&str> = re.splitn(text, 2).collect();\n+    assert_eq!(subs, vec!(\"cauchy\", \"plato456tyler789binx\"));\n+}\n+\n+#[test]\n+fn split() {\n+    let re = regex!(r\"\\d+\");\n+    let text = \"cauchy123plato456tyler789binx\";\n+    let subs: Vec<&str> = re.split(text).collect();\n+    assert_eq!(subs, vec!(\"cauchy\", \"plato\", \"tyler\", \"binx\"));\n+}\n+\n+macro_rules! replace(\n+    ($name:ident, $which:ident, $re:expr,\n+     $search:expr, $replace:expr, $result:expr) => (\n+        #[test]\n+        fn $name() {\n+            let re = regex!($re);\n+            assert_eq!(re.$which($search, $replace), StrBuf::from_str($result));\n+        }\n+    );\n+)\n+\n+replace!(rep_first, replace, r\"\\d\", \"age: 26\", \"Z\", \"age: Z6\")\n+replace!(rep_plus, replace, r\"\\d+\", \"age: 26\", \"Z\", \"age: Z\")\n+replace!(rep_all, replace_all, r\"\\d\", \"age: 26\", \"Z\", \"age: ZZ\")\n+replace!(rep_groups, replace, r\"(\\S+)\\s+(\\S+)\", \"w1 w2\", \"$2 $1\", \"w2 w1\")\n+replace!(rep_double_dollar, replace,\n+         r\"(\\S+)\\s+(\\S+)\", \"w1 w2\", \"$2 $$1\", \"w2 $1\")\n+replace!(rep_no_expand, replace,\n+         r\"(\\S+)\\s+(\\S+)\", \"w1 w2\", NoExpand(\"$2 $1\"), \"$2 $1\")\n+replace!(rep_named, replace_all,\n+         r\"(?P<first>\\S+)\\s+(?P<last>\\S+)(?P<space>\\s*)\",\n+         \"w1 w2 w3 w4\", \"$last $first$space\", \"w2 w1 w4 w3\")\n+replace!(rep_trim, replace_all, \"^[ \\t]+|[ \\t]+$\", \" \\t  trim me\\t   \\t\",\n+         \"\", \"trim me\")\n+\n+macro_rules! noparse(\n+    ($name:ident, $re:expr) => (\n+        #[test]\n+        fn $name() {\n+            let re = $re;\n+            match Regex::new(re) {\n+                Err(_) => {},\n+                Ok(_) => fail!(\"Regex '{}' should cause a parse error.\", re),\n+            }\n+        }\n+    );\n+)\n+\n+noparse!(fail_double_repeat, \"a**\")\n+noparse!(fail_no_repeat_arg, \"*\")\n+noparse!(fail_no_repeat_arg_begin, \"^*\")\n+noparse!(fail_incomplete_escape, \"\\\\\")\n+noparse!(fail_class_incomplete, \"[A-\")\n+noparse!(fail_class_not_closed, \"[A\")\n+noparse!(fail_class_no_begin, r\"[\\A]\")\n+noparse!(fail_class_no_end, r\"[\\z]\")\n+noparse!(fail_class_no_boundary, r\"[\\b]\")\n+noparse!(fail_open_paren, \"(\")\n+noparse!(fail_close_paren, \")\")\n+noparse!(fail_invalid_range, \"[a-Z]\")\n+noparse!(fail_empty_capture_name, \"(?P<>a)\")\n+noparse!(fail_empty_capture_exp, \"(?P<name>)\")\n+noparse!(fail_bad_capture_name, \"(?P<na-me>)\")\n+noparse!(fail_bad_flag, \"(?a)a\")\n+noparse!(fail_empty_alt_before, \"|a\")\n+noparse!(fail_empty_alt_after, \"a|\")\n+noparse!(fail_counted_big_exact, \"a{1001}\")\n+noparse!(fail_counted_big_min, \"a{1001,}\")\n+noparse!(fail_counted_no_close, \"a{1001\")\n+noparse!(fail_unfinished_cap, \"(?\")\n+noparse!(fail_unfinished_escape, \"\\\\\")\n+noparse!(fail_octal_digit, r\"\\8\")\n+noparse!(fail_hex_digit, r\"\\xG0\")\n+noparse!(fail_hex_short, r\"\\xF\")\n+noparse!(fail_hex_long_digits, r\"\\x{fffg}\")\n+noparse!(fail_flag_bad, \"(?a)\")\n+noparse!(fail_flag_empty, \"(?)\")\n+noparse!(fail_double_neg, \"(?-i-i)\")\n+noparse!(fail_neg_empty, \"(?i-)\")\n+noparse!(fail_empty_group, \"()\")\n+noparse!(fail_dupe_named, \"(?P<a>.)(?P<a>.)\")\n+\n+macro_rules! mat(\n+    ($name:ident, $re:expr, $text:expr, $($loc:tt)+) => (\n+        #[test]\n+        fn $name() {\n+            let text = $text;\n+            let expected: Vec<Option<(uint, uint)>> = vec!($($loc)+);\n+            let r = regex!($re);\n+            let got = match r.captures(text) {\n+                Some(c) => c.iter_pos().collect::<Vec<Option<(uint, uint)>>>(),\n+                None => vec!(None),\n+            };\n+            // The test set sometimes leave out capture groups, so truncate\n+            // actual capture groups to match test set.\n+            let (sexpect, mut sgot) = (expected.as_slice(), got.as_slice());\n+            if sgot.len() > sexpect.len() {\n+                sgot = sgot.slice(0, sexpect.len())\n+            }\n+            if sexpect != sgot {\n+                fail!(\"For RE '{}' against '{}', expected '{}' but got '{}'\",\n+                      $re, text, sexpect, sgot);\n+            }\n+        }\n+    );\n+)\n+\n+// Some crazy expressions from regular-expressions.info.\n+mat!(match_ranges,\n+     r\"\\b(?:[0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\b\",\n+     \"num: 255\", Some((5, 8)))\n+mat!(match_ranges_not,\n+     r\"\\b(?:[0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\b\",\n+     \"num: 256\", None)\n+mat!(match_float1, r\"[-+]?[0-9]*\\.?[0-9]+\", \"0.1\", Some((0, 3)))\n+mat!(match_float2, r\"[-+]?[0-9]*\\.?[0-9]+\", \"0.1.2\", Some((0, 3)))\n+mat!(match_float3, r\"[-+]?[0-9]*\\.?[0-9]+\", \"a1.2\", Some((1, 4)))\n+mat!(match_float4, r\"^[-+]?[0-9]*\\.?[0-9]+$\", \"1.a\", None)\n+mat!(match_email, r\"(?i)\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\\b\",\n+     \"mine is jam.slam@gmail.com \", Some((8, 26)))\n+mat!(match_email_not, r\"(?i)\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\\b\",\n+     \"mine is jam.slam@gmail \", None)\n+mat!(match_email_big, r\"[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\",\n+     \"mine is jam.slam@gmail.com \", Some((8, 26)))\n+mat!(match_date1,\n+     r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\",\n+     \"1900-01-01\", Some((0, 10)))\n+mat!(match_date2,\n+     r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\",\n+     \"1900-00-01\", None)\n+mat!(match_date3,\n+     r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\",\n+     \"1900-13-01\", None)\n+\n+// Exercise the flags.\n+mat!(match_flag_case, \"(?i)abc\", \"ABC\", Some((0, 3)))\n+mat!(match_flag_weird_case, \"(?i)a(?-i)bc\", \"Abc\", Some((0, 3)))\n+mat!(match_flag_weird_case_not, \"(?i)a(?-i)bc\", \"ABC\", None)\n+mat!(match_flag_case_dotnl, \"(?is)a.\", \"A\\n\", Some((0, 2)))\n+mat!(match_flag_case_dotnl_toggle, \"(?is)a.(?-is)a.\", \"A\\nab\", Some((0, 4)))\n+mat!(match_flag_case_dotnl_toggle_not, \"(?is)a.(?-is)a.\", \"A\\na\\n\", None)\n+mat!(match_flag_case_dotnl_toggle_ok, \"(?is)a.(?-is:a.)?\", \"A\\na\\n\", Some((0, 2)))\n+mat!(match_flag_multi, \"(?m)(?:^\\\\d+$\\n?)+\", \"123\\n456\\n789\", Some((0, 11)))\n+mat!(match_flag_ungreedy, \"(?U)a+\", \"aa\", Some((0, 1)))\n+mat!(match_flag_ungreedy_greedy, \"(?U)a+?\", \"aa\", Some((0, 2)))\n+mat!(match_flag_ungreedy_noop, \"(?U)(?-U)a+\", \"aa\", Some((0, 2)))\n+\n+// Some Unicode tests.\n+mat!(uni_literal, r\"\u2160\", \"\u2160\", Some((0, 3)))\n+mat!(uni_one, r\"\\pN\", \"\u2160\", Some((0, 3)))\n+mat!(uni_mixed, r\"\\pN+\", \"\u21601\u21612\", Some((0, 8)))\n+mat!(uni_not, r\"\\PN+\", \"ab\u2160\", Some((0, 2)))\n+mat!(uni_not_class, r\"[\\PN]+\", \"ab\u2160\", Some((0, 2)))\n+mat!(uni_not_class_neg, r\"[^\\PN]+\", \"ab\u2160\", Some((2, 5)))\n+mat!(uni_case, r\"(?i)\u0394\", \"\u03b4\", Some((0, 2)))\n+mat!(uni_case_not, r\"\u0394\", \"\u03b4\", None)\n+mat!(uni_case_upper, r\"\\p{Lu}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((0, 8)))\n+mat!(uni_case_upper_nocase_flag, r\"(?i)\\p{Lu}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((0, 10)))\n+mat!(uni_case_upper_nocase, r\"\\p{L}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((0, 10)))\n+mat!(uni_case_lower, r\"\\p{Ll}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((8, 10)))\n+\n+// Test the Unicode friendliness of Perl character classes.\n+mat!(uni_perl_w, r\"\\w+\", \"d\u03b4d\", Some((0, 4)))\n+mat!(uni_perl_w_not, r\"\\w+\", \"\u2161\", None)\n+mat!(uni_perl_w_neg, r\"\\W+\", \"\u2161\", Some((0, 3)))\n+mat!(uni_perl_d, r\"\\d+\", \"1\u0968\u09699\", Some((0, 8)))\n+mat!(uni_perl_d_not, r\"\\d+\", \"\u2161\", None)\n+mat!(uni_perl_d_neg, r\"\\D+\", \"\u2161\", Some((0, 3)))\n+mat!(uni_perl_s, r\"\\s+\", \"\u1680\", Some((0, 3)))\n+mat!(uni_perl_s_not, r\"\\s+\", \"\u2603\", None)\n+mat!(uni_perl_s_neg, r\"\\S+\", \"\u2603\", Some((0, 3)))\n+\n+// And do the same for word boundaries.\n+mat!(uni_boundary_none, r\"\\d\\b\", \"6\u03b4\", None)\n+mat!(uni_boundary_ogham, r\"\\d\\b\", \"6\u1680\", Some((0, 1)))\n+\n+// A whole mess of tests from Glenn Fowler's regex test suite.\n+// Generated by the 'src/etc/regex-match-tests' program.\n+mod matches;"}, {"sha": "f47dbf4c449bcc067f3d535cce4b43b4cc52e21d", "filename": "src/libregex/testdata/LICENSE", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2FLICENSE", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2FLICENSE", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2FLICENSE?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,19 @@\n+The following license covers testregex.c and all associated test data.\n+\n+Permission is hereby granted, free of charge, to any person obtaining a\n+copy of THIS SOFTWARE FILE (the \"Software\"), to deal in the Software\n+without restriction, including without limitation the rights to use,\n+copy, modify, merge, publish, distribute, and/or sell copies of the\n+Software, and to permit persons to whom the Software is furnished to do\n+so, subject to the following disclaimer:\n+\n+THIS SOFTWARE IS PROVIDED BY AT&T ``AS IS'' AND ANY EXPRESS OR IMPLIED\n+WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n+IN NO EVENT SHALL AT&T BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."}, {"sha": "33b0ba17ed7f6aed2808a98f8fc00dcaa3dc488e", "filename": "src/libregex/testdata/README", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2FREADME", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2FREADME", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2FREADME?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,17 @@\n+Test data was taken from the Go distribution, which was in turn taken from the \n+testregex test suite:\n+\n+  http://www2.research.att.com/~astopen/testregex/testregex.html\n+\n+The LICENSE in this directory corresponds to the LICENSE that the data was\n+released under.\n+\n+The tests themselves were modified for RE2/Go. A couple were modified further \n+by me (Andrew Gallant) (only in repetition.dat) so that RE2/Go would pass them. \n+(Yes, it seems like RE2/Go includes failing test cases.) This may or may not \n+have been a bad idea, but I think being consistent with an established Regex \n+library is worth something.\n+\n+Note that these files are read by 'src/etc/regexp-match-tests' and turned into \n+Rust tests found in 'src/libregexp/tests/matches.rs'.\n+"}, {"sha": "e55efaeec062428fa08511d579dd6b9d897ff83c", "filename": "src/libregex/testdata/basic.dat", "status": "added", "additions": 221, "deletions": 0, "changes": 221, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2Fbasic.dat", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2Fbasic.dat", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2Fbasic.dat?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,221 @@\n+NOTE\tall standard compliant implementations should pass these : 2002-05-31\n+\n+BE\tabracadabra$\tabracadabracadabra\t(7,18)\n+BE\ta...b\t\tabababbb\t\t(2,7)\n+BE\tXXXXXX\t\t..XXXXXX\t\t(2,8)\n+E\t\\)\t\t()\t(1,2)\n+BE\ta]\t\ta]a\t(0,2)\n+B\t}\t\t}\t(0,1)\n+E\t\\}\t\t}\t(0,1)\n+BE\t\\]\t\t]\t(0,1)\n+B\t]\t\t]\t(0,1)\n+E\t]\t\t]\t(0,1)\n+B\t{\t\t{\t(0,1)\n+B\t}\t\t}\t(0,1)\n+BE\t^a\t\tax\t(0,1)\n+BE\t\\^a\t\ta^a\t(1,3)\n+BE\ta\\^\t\ta^\t(0,2)\n+BE\ta$\t\taa\t(1,2)\n+BE\ta\\$\t\ta$\t(0,2)\n+BE\t^$\t\tNULL\t(0,0)\n+E\t$^\t\tNULL\t(0,0)\n+E\ta($)\t\taa\t(1,2)(2,2)\n+E\ta*(^a)\t\taa\t(0,1)(0,1)\n+E\t(..)*(...)*\t\ta\t(0,0)\n+E\t(..)*(...)*\t\tabcd\t(0,4)(2,4)\n+E\t(ab|a)(bc|c)\t\tabc\t(0,3)(0,2)(2,3)\n+E\t(ab)c|abc\t\tabc\t(0,3)(0,2)\n+E\ta{0}b\t\tab\t\t\t(1,2)\n+E\t(a*)(b?)(b+)b{3}\taaabbbbbbb\t(0,10)(0,3)(3,4)(4,7)\n+E\t(a*)(b{0,1})(b{1,})b{3}\taaabbbbbbb\t(0,10)(0,3)(3,4)(4,7)\n+E\ta{9876543210}\tNULL\tBADBR\n+E\t((a|a)|a)\t\t\ta\t(0,1)(0,1)(0,1)\n+E\t(a*)(a|aa)\t\t\taaaa\t(0,4)(0,3)(3,4)\n+E\ta*(a.|aa)\t\t\taaaa\t(0,4)(2,4)\n+E\ta(b)|c(d)|a(e)f\t\t\taef\t(0,3)(?,?)(?,?)(1,2)\n+E\t(a|b)?.*\t\t\tb\t(0,1)(0,1)\n+E\t(a|b)c|a(b|c)\t\t\tac\t(0,2)(0,1)\n+E\t(a|b)c|a(b|c)\t\t\tab\t(0,2)(?,?)(1,2)\n+E\t(a|b)*c|(a|ab)*c\t\tabc\t(0,3)(1,2)\n+E\t(a|b)*c|(a|ab)*c\t\txc\t(1,2)\n+E\t(.a|.b).*|.*(.a|.b)\t\txa\t(0,2)(0,2)\n+E\ta?(ab|ba)ab\t\t\tabab\t(0,4)(0,2)\n+E\ta?(ac{0}b|ba)ab\t\t\tabab\t(0,4)(0,2)\n+E\tab|abab\t\t\t\tabbabab\t(0,2)\n+E\taba|bab|bba\t\t\tbaaabbbaba\t(5,8)\n+E\taba|bab\t\t\t\tbaaabbbaba\t(6,9)\n+E\t(aa|aaa)*|(a|aaaaa)\t\taa\t(0,2)(0,2)\n+E\t(a.|.a.)*|(a|.a...)\t\taa\t(0,2)(0,2)\n+E\tab|a\t\t\t\txabc\t(1,3)\n+E\tab|a\t\t\t\txxabc\t(2,4)\n+Ei\t(Ab|cD)*\t\t\taBcD\t(0,4)(2,4)\n+BE\t[^-]\t\t\t--a\t\t(2,3)\n+BE\t[a-]*\t\t\t--a\t\t(0,3)\n+BE\t[a-m-]*\t\t\t--amoma--\t(0,4)\n+E\t:::1:::0:|:::1:1:0:\t:::0:::1:::1:::0:\t(8,17)\n+E\t:::1:::0:|:::1:1:1:\t:::0:::1:::1:::0:\t(8,17)\n+{E\t[[:upper:]]\t\tA\t\t(0,1)\t[[<element>]] not supported\n+E\t[[:lower:]]+\t\t`az{\t\t(1,3)\n+E\t[[:upper:]]+\t\t@AZ[\t\t(1,3)\n+# No collation in Go\n+#BE\t[[-]]\t\t\t[[-]]\t\t(2,4)\n+#BE\t[[.NIL.]]\tNULL\tECOLLATE\n+#BE\t[[=aleph=]]\tNULL\tECOLLATE\n+}\n+BE$\t\\n\t\t\\n\t(0,1)\n+BEn$\t\\n\t\t\\n\t(0,1)\n+BE$\t[^a]\t\t\\n\t(0,1)\n+BE$\t\\na\t\t\\na\t(0,2)\n+E\t(a)(b)(c)\tabc\t(0,3)(0,1)(1,2)(2,3)\n+BE\txxx\t\txxx\t(0,3)\n+E1\t(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\tfeb 6,\t(0,6)\n+E1\t(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\t2/7\t(0,3)\n+E1\t(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\tfeb 1,Feb 6\t(5,11)\n+E3\t((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))\tx\t(0,1)(0,1)(0,1)\n+E3\t((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))*\txx\t(0,2)(1,2)(1,2)\n+E\ta?(ab|ba)*\tababababababababababababababababababababababababababababababababababababababababa\t(0,81)(79,81)\n+E\tabaa|abbaa|abbbaa|abbbbaa\tababbabbbabbbabbbbabbbbaa\t(18,25)\n+E\tabaa|abbaa|abbbaa|abbbbaa\tababbabbbabbbabbbbabaa\t(18,22)\n+E\taaac|aabc|abac|abbc|baac|babc|bbac|bbbc\tbaaabbbabac\t(7,11)\n+BE$\t.*\t\t\t\\x01\\x7f\t(0,2)\n+E\taaaa|bbbb|cccc|ddddd|eeeeee|fffffff|gggg|hhhh|iiiii|jjjjj|kkkkk|llll\t\tXaaaXbbbXcccXdddXeeeXfffXgggXhhhXiiiXjjjXkkkXlllXcbaXaaaa\t(53,57)\n+L\taaaa\\nbbbb\\ncccc\\nddddd\\neeeeee\\nfffffff\\ngggg\\nhhhh\\niiiii\\njjjjj\\nkkkkk\\nllll\t\tXaaaXbbbXcccXdddXeeeXfffXgggXhhhXiiiXjjjXkkkXlllXcbaXaaaa\tNOMATCH\n+E\ta*a*a*a*a*b\t\taaaaaaaaab\t(0,10)\n+BE\t^\t\t\tNULL\t\t(0,0)\n+BE\t$\t\t\tNULL\t\t(0,0)\n+BE\t^$\t\t\tNULL\t\t(0,0)\n+BE\t^a$\t\t\ta\t\t(0,1)\n+BE\tabc\t\t\tabc\t\t(0,3)\n+BE\tabc\t\t\txabcy\t\t(1,4)\n+BE\tabc\t\t\tababc\t\t(2,5)\n+BE\tab*c\t\t\tabc\t\t(0,3)\n+BE\tab*bc\t\t\tabc\t\t(0,3)\n+BE\tab*bc\t\t\tabbc\t\t(0,4)\n+BE\tab*bc\t\t\tabbbbc\t\t(0,6)\n+E\tab+bc\t\t\tabbc\t\t(0,4)\n+E\tab+bc\t\t\tabbbbc\t\t(0,6)\n+E\tab?bc\t\t\tabbc\t\t(0,4)\n+E\tab?bc\t\t\tabc\t\t(0,3)\n+E\tab?c\t\t\tabc\t\t(0,3)\n+BE\t^abc$\t\t\tabc\t\t(0,3)\n+BE\t^abc\t\t\tabcc\t\t(0,3)\n+BE\tabc$\t\t\taabc\t\t(1,4)\n+BE\t^\t\t\tabc\t\t(0,0)\n+BE\t$\t\t\tabc\t\t(3,3)\n+BE\ta.c\t\t\tabc\t\t(0,3)\n+BE\ta.c\t\t\taxc\t\t(0,3)\n+BE\ta.*c\t\t\taxyzc\t\t(0,5)\n+BE\ta[bc]d\t\t\tabd\t\t(0,3)\n+BE\ta[b-d]e\t\t\tace\t\t(0,3)\n+BE\ta[b-d]\t\t\taac\t\t(1,3)\n+BE\ta[-b]\t\t\ta-\t\t(0,2)\n+BE\ta[b-]\t\t\ta-\t\t(0,2)\n+BE\ta]\t\t\ta]\t\t(0,2)\n+BE\ta[]]b\t\t\ta]b\t\t(0,3)\n+BE\ta[^bc]d\t\t\taed\t\t(0,3)\n+BE\ta[^-b]c\t\t\tadc\t\t(0,3)\n+BE\ta[^]b]c\t\t\tadc\t\t(0,3)\n+E\tab|cd\t\t\tabc\t\t(0,2)\n+E\tab|cd\t\t\tabcd\t\t(0,2)\n+E\ta\\(b\t\t\ta(b\t\t(0,3)\n+E\ta\\(*b\t\t\tab\t\t(0,2)\n+E\ta\\(*b\t\t\ta((b\t\t(0,4)\n+E\t((a))\t\t\tabc\t\t(0,1)(0,1)(0,1)\n+E\t(a)b(c)\t\t\tabc\t\t(0,3)(0,1)(2,3)\n+E\ta+b+c\t\t\taabbabc\t\t(4,7)\n+E\ta*\t\t\taaa\t\t(0,3)\n+#E\t(a*)*\t\t\t-\t\t(0,0)(0,0)\n+E\t(a*)*\t\t\t-\t\t(0,0)(?,?)\tRE2/Go\n+E\t(a*)+\t\t\t-\t\t(0,0)(0,0)\n+#E\t(a*|b)*\t\t\t-\t\t(0,0)(0,0)\n+E\t(a*|b)*\t\t\t-\t\t(0,0)(?,?)\tRE2/Go\n+E\t(a+|b)*\t\t\tab\t\t(0,2)(1,2)\n+E\t(a+|b)+\t\t\tab\t\t(0,2)(1,2)\n+E\t(a+|b)?\t\t\tab\t\t(0,1)(0,1)\n+BE\t[^ab]*\t\t\tcde\t\t(0,3)\n+#E\t(^)*\t\t\t-\t\t(0,0)(0,0)\n+E\t(^)*\t\t\t-\t\t(0,0)(?,?)\tRE2/Go\n+BE\ta*\t\t\tNULL\t\t(0,0)\n+E\t([abc])*d\t\tabbbcd\t\t(0,6)(4,5)\n+E\t([abc])*bcd\t\tabcd\t\t(0,4)(0,1)\n+E\ta|b|c|d|e\t\te\t\t(0,1)\n+E\t(a|b|c|d|e)f\t\tef\t\t(0,2)(0,1)\n+#E\t((a*|b))*\t\t-\t\t(0,0)(0,0)(0,0)\n+E\t((a*|b))*\t\t-\t\t(0,0)(?,?)(?,?)\tRE2/Go\n+BE\tabcd*efg\t\tabcdefg\t\t(0,7)\n+BE\tab*\t\t\txabyabbbz\t(1,3)\n+BE\tab*\t\t\txayabbbz\t(1,2)\n+E\t(ab|cd)e\t\tabcde\t\t(2,5)(2,4)\n+BE\t[abhgefdc]ij\t\thij\t\t(0,3)\n+E\t(a|b)c*d\t\tabcd\t\t(1,4)(1,2)\n+E\t(ab|ab*)bc\t\tabc\t\t(0,3)(0,1)\n+E\ta([bc]*)c*\t\tabc\t\t(0,3)(1,3)\n+E\ta([bc]*)(c*d)\t\tabcd\t\t(0,4)(1,3)(3,4)\n+E\ta([bc]+)(c*d)\t\tabcd\t\t(0,4)(1,3)(3,4)\n+E\ta([bc]*)(c+d)\t\tabcd\t\t(0,4)(1,2)(2,4)\n+E\ta[bcd]*dcdcde\t\tadcdcde\t\t(0,7)\n+E\t(ab|a)b*c\t\tabc\t\t(0,3)(0,2)\n+E\t((a)(b)c)(d)\t\tabcd\t\t(0,4)(0,3)(0,1)(1,2)(3,4)\n+BE\t[A-Za-z_][A-Za-z0-9_]*\talpha\t\t(0,5)\n+E\t^a(bc+|b[eh])g|.h$\tabh\t\t(1,3)\n+E\t(bc+d$|ef*g.|h?i(j|k))\teffgz\t\t(0,5)(0,5)\n+E\t(bc+d$|ef*g.|h?i(j|k))\tij\t\t(0,2)(0,2)(1,2)\n+E\t(bc+d$|ef*g.|h?i(j|k))\treffgz\t\t(1,6)(1,6)\n+E\t(((((((((a)))))))))\ta\t\t(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)\n+BE\tmultiple words\t\tmultiple words yeah\t(0,14)\n+E\t(.*)c(.*)\t\tabcde\t\t(0,5)(0,2)(3,5)\n+BE\tabcd\t\t\tabcd\t\t(0,4)\n+E\ta(bc)d\t\t\tabcd\t\t(0,4)(1,3)\n+E\ta[\u0001-\u0003]?c\t\ta\u0002c\t\t(0,3)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Qaddafi\t(0,15)(?,?)(10,12)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMo'ammar Gadhafi\t(0,16)(?,?)(11,13)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Kaddafi\t(0,15)(?,?)(10,12)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Qadhafi\t(0,15)(?,?)(10,12)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Gadafi\t(0,14)(?,?)(10,11)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMu'ammar Qadafi\t(0,15)(?,?)(11,12)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMoamar Gaddafi\t(0,14)(?,?)(9,11)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMu'ammar Qadhdhafi\t(0,18)(?,?)(13,15)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Khaddafi\t(0,16)(?,?)(11,13)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Ghaddafy\t(0,16)(?,?)(11,13)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Ghadafi\t(0,15)(?,?)(11,12)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Ghaddafi\t(0,16)(?,?)(11,13)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuamar Kaddafi\t(0,14)(?,?)(9,11)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Quathafi\t(0,16)(?,?)(11,13)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Gheddafi\t(0,16)(?,?)(11,13)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMoammar Khadafy\t(0,15)(?,?)(11,12)\n+E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMoammar Qudhafi\t(0,15)(?,?)(10,12)\n+E\ta+(b|c)*d+\t\taabcdd\t\t\t(0,6)(3,4)\n+E\t^.+$\t\t\tvivi\t\t\t(0,4)\n+E\t^(.+)$\t\t\tvivi\t\t\t(0,4)(0,4)\n+E\t^([^!.]+).att.com!(.+)$\tgryphon.att.com!eby\t(0,19)(0,7)(16,19)\n+E\t^([^!]+!)?([^!]+)$\tbas\t\t\t(0,3)(?,?)(0,3)\n+E\t^([^!]+!)?([^!]+)$\tbar!bas\t\t\t(0,7)(0,4)(4,7)\n+E\t^([^!]+!)?([^!]+)$\tfoo!bas\t\t\t(0,7)(0,4)(4,7)\n+E\t^.+!([^!]+!)([^!]+)$\tfoo!bar!bas\t\t(0,11)(4,8)(8,11)\n+E\t((foo)|(bar))!bas\tbar!bas\t\t\t(0,7)(0,3)(?,?)(0,3)\n+E\t((foo)|(bar))!bas\tfoo!bar!bas\t\t(4,11)(4,7)(?,?)(4,7)\n+E\t((foo)|(bar))!bas\tfoo!bas\t\t\t(0,7)(0,3)(0,3)\n+E\t((foo)|bar)!bas\t\tbar!bas\t\t\t(0,7)(0,3)\n+E\t((foo)|bar)!bas\t\tfoo!bar!bas\t\t(4,11)(4,7)\n+E\t((foo)|bar)!bas\t\tfoo!bas\t\t\t(0,7)(0,3)(0,3)\n+E\t(foo|(bar))!bas\t\tbar!bas\t\t\t(0,7)(0,3)(0,3)\n+E\t(foo|(bar))!bas\t\tfoo!bar!bas\t\t(4,11)(4,7)(4,7)\n+E\t(foo|(bar))!bas\t\tfoo!bas\t\t\t(0,7)(0,3)\n+E\t(foo|bar)!bas\t\tbar!bas\t\t\t(0,7)(0,3)\n+E\t(foo|bar)!bas\t\tfoo!bar!bas\t\t(4,11)(4,7)\n+E\t(foo|bar)!bas\t\tfoo!bas\t\t\t(0,7)(0,3)\n+E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tfoo!bar!bas\t(0,11)(0,11)(?,?)(?,?)(4,8)(8,11)\n+E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tbas\t\t(0,3)(?,?)(0,3)\n+E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tbar!bas\t\t(0,7)(0,4)(4,7)\n+E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tfoo!bar!bas\t(0,11)(?,?)(?,?)(4,8)(8,11)\n+E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tfoo!bas\t\t(0,7)(0,4)(4,7)\n+E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tbas\t\t(0,3)(0,3)(?,?)(0,3)\n+E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tbar!bas\t\t(0,7)(0,7)(0,4)(4,7)\n+E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tfoo!bar!bas\t(0,11)(0,11)(?,?)(?,?)(4,8)(8,11)\n+E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tfoo!bas\t\t(0,7)(0,7)(0,4)(4,7)\n+E\t.*(/XXX).*\t\t\t/XXX\t\t\t(0,4)(0,4)\n+E\t.*(\\\\XXX).*\t\t\t\\XXX\t\t\t(0,4)(0,4)\n+E\t\\\\XXX\t\t\t\t\\XXX\t\t\t(0,4)\n+E\t.*(/000).*\t\t\t/000\t\t\t(0,4)(0,4)\n+E\t.*(\\\\000).*\t\t\t\\000\t\t\t(0,4)(0,4)\n+E\t\\\\000\t\t\t\t\\000\t\t\t(0,4)"}, {"sha": "2e18fbb917070347df82ed24978b62884652a037", "filename": "src/libregex/testdata/nullsubexpr.dat", "status": "added", "additions": 79, "deletions": 0, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2Fnullsubexpr.dat", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2Fnullsubexpr.dat", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2Fnullsubexpr.dat?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,79 @@\n+NOTE\tnull subexpression matches : 2002-06-06\n+\n+E\t(a*)*\t\ta\t\t(0,1)(0,1)\n+#E\tSAME\t\tx\t\t(0,0)(0,0)\n+E\tSAME\t\tx\t\t(0,0)(?,?)\tRE2/Go\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n+E\t(a*)+\t\ta\t\t(0,1)(0,1)\n+E\tSAME\t\tx\t\t(0,0)(0,0)\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n+E\t(a+)*\t\ta\t\t(0,1)(0,1)\n+E\tSAME\t\tx\t\t(0,0)\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n+E\t(a+)+\t\ta\t\t(0,1)(0,1)\n+E\tSAME\t\tx\t\tNOMATCH\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n+\n+E\t([a]*)*\t\ta\t\t(0,1)(0,1)\n+#E\tSAME\t\tx\t\t(0,0)(0,0)\n+E\tSAME\t\tx\t\t(0,0)(?,?)\tRE2/Go\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n+E\t([a]*)+\t\ta\t\t(0,1)(0,1)\n+E\tSAME\t\tx\t\t(0,0)(0,0)\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n+E\t([^b]*)*\ta\t\t(0,1)(0,1)\n+#E\tSAME\t\tb\t\t(0,0)(0,0)\n+E\tSAME\t\tb\t\t(0,0)(?,?)\tRE2/Go\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\taaaaaab\t\t(0,6)(0,6)\n+E\t([ab]*)*\ta\t\t(0,1)(0,1)\n+E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n+E\tSAME\t\tababab\t\t(0,6)(0,6)\n+E\tSAME\t\tbababa\t\t(0,6)(0,6)\n+E\tSAME\t\tb\t\t(0,1)(0,1)\n+E\tSAME\t\tbbbbbb\t\t(0,6)(0,6)\n+E\tSAME\t\taaaabcde\t(0,5)(0,5)\n+E\t([^a]*)*\tb\t\t(0,1)(0,1)\n+E\tSAME\t\tbbbbbb\t\t(0,6)(0,6)\n+#E\tSAME\t\taaaaaa\t\t(0,0)(0,0)\n+E\tSAME\t\taaaaaa\t\t(0,0)(?,?)\tRE2/Go\n+E\t([^ab]*)*\tccccxx\t\t(0,6)(0,6)\n+#E\tSAME\t\tababab\t\t(0,0)(0,0)\n+E\tSAME\t\tababab\t\t(0,0)(?,?)\tRE2/Go\n+\n+E\t((z)+|a)*\tzabcde\t\t(0,2)(1,2)\n+\n+#{E\ta+?\t\taaaaaa\t\t(0,1)\tno *? +? mimimal match ops\n+#E\t(a)\t\taaa\t\t(0,1)(0,1)\n+#E\t(a*?)\t\taaa\t\t(0,0)(0,0)\n+#E\t(a)*?\t\taaa\t\t(0,0)\n+#E\t(a*?)*?\t\taaa\t\t(0,0)\n+#}\n+\n+B\t\\(a*\\)*\\(x\\)\t\tx\t(0,1)(0,0)(0,1)\n+B\t\\(a*\\)*\\(x\\)\t\tax\t(0,2)(0,1)(1,2)\n+B\t\\(a*\\)*\\(x\\)\t\taxa\t(0,2)(0,1)(1,2)\n+B\t\\(a*\\)*\\(x\\)\\(\\1\\)\tx\t(0,1)(0,0)(0,1)(1,1)\n+B\t\\(a*\\)*\\(x\\)\\(\\1\\)\tax\t(0,2)(1,1)(1,2)(2,2)\n+B\t\\(a*\\)*\\(x\\)\\(\\1\\)\taxa\t(0,3)(0,1)(1,2)(2,3)\n+B\t\\(a*\\)*\\(x\\)\\(\\1\\)\\(x\\)\taxax\t(0,4)(0,1)(1,2)(2,3)(3,4)\n+B\t\\(a*\\)*\\(x\\)\\(\\1\\)\\(x\\)\taxxa\t(0,3)(1,1)(1,2)(2,2)(2,3)\n+\n+#E\t(a*)*(x)\t\tx\t(0,1)(0,0)(0,1)\n+E\t(a*)*(x)\t\tx\t(0,1)(?,?)(0,1)\tRE2/Go\n+E\t(a*)*(x)\t\tax\t(0,2)(0,1)(1,2)\n+E\t(a*)*(x)\t\taxa\t(0,2)(0,1)(1,2)\n+\n+E\t(a*)+(x)\t\tx\t(0,1)(0,0)(0,1)\n+E\t(a*)+(x)\t\tax\t(0,2)(0,1)(1,2)\n+E\t(a*)+(x)\t\taxa\t(0,2)(0,1)(1,2)\n+\n+E\t(a*){2}(x)\t\tx\t(0,1)(0,0)(0,1)\n+E\t(a*){2}(x)\t\tax\t(0,2)(1,1)(1,2)\n+E\t(a*){2}(x)\t\taxa\t(0,2)(1,1)(1,2)"}, {"sha": "3bb21211800058cef9beaad6cfdc54aa867926ad", "filename": "src/libregex/testdata/repetition.dat", "status": "added", "additions": 163, "deletions": 0, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2Frepetition.dat", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Ftestdata%2Frepetition.dat", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2Frepetition.dat?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,163 @@\n+NOTE\timplicit vs. explicit repetitions : 2009-02-02\n+\n+# Glenn Fowler <gsf@research.att.com>\n+# conforming matches (column 4) must match one of the following BREs\n+#\tNOMATCH\n+#\t(0,.)\\((\\(.\\),\\(.\\))(?,?)(\\2,\\3)\\)*\n+#\t(0,.)\\((\\(.\\),\\(.\\))(\\2,\\3)(?,?)\\)*\n+# i.e., each 3-tuple has two identical elements and one (?,?)\n+\n+E\t((..)|(.))\t\t\t\tNULL\t\tNOMATCH\n+E\t((..)|(.))((..)|(.))\t\t\tNULL\t\tNOMATCH\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\tNULL\t\tNOMATCH\n+\n+E\t((..)|(.)){1}\t\t\t\tNULL\t\tNOMATCH\n+E\t((..)|(.)){2}\t\t\t\tNULL\t\tNOMATCH\n+E\t((..)|(.)){3}\t\t\t\tNULL\t\tNOMATCH\n+\n+E\t((..)|(.))*\t\t\t\tNULL\t\t(0,0)\n+\n+E\t((..)|(.))\t\t\t\ta\t\t(0,1)(0,1)(?,?)(0,1)\n+E\t((..)|(.))((..)|(.))\t\t\ta\t\tNOMATCH\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\ta\t\tNOMATCH\n+\n+E\t((..)|(.)){1}\t\t\t\ta\t\t(0,1)(0,1)(?,?)(0,1)\n+E\t((..)|(.)){2}\t\t\t\ta\t\tNOMATCH\n+E\t((..)|(.)){3}\t\t\t\ta\t\tNOMATCH\n+\n+E\t((..)|(.))*\t\t\t\ta\t\t(0,1)(0,1)(?,?)(0,1)\n+\n+E\t((..)|(.))\t\t\t\taa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.))((..)|(.))\t\t\taa\t\t(0,2)(0,1)(?,?)(0,1)(1,2)(?,?)(1,2)\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\taa\t\tNOMATCH\n+\n+E\t((..)|(.)){1}\t\t\t\taa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.)){2}\t\t\t\taa\t\t(0,2)(1,2)(?,?)(1,2)\n+E\t((..)|(.)){3}\t\t\t\taa\t\tNOMATCH\n+\n+E\t((..)|(.))*\t\t\t\taa\t\t(0,2)(0,2)(0,2)(?,?)\n+\n+E\t((..)|(.))\t\t\t\taaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.))((..)|(.))\t\t\taaa\t\t(0,3)(0,2)(0,2)(?,?)(2,3)(?,?)(2,3)\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\taaa\t\t(0,3)(0,1)(?,?)(0,1)(1,2)(?,?)(1,2)(2,3)(?,?)(2,3)\n+\n+E\t((..)|(.)){1}\t\t\t\taaa\t\t(0,2)(0,2)(0,2)(?,?)\n+#E\t((..)|(.)){2}\t\t\t\taaa\t\t(0,3)(2,3)(?,?)(2,3)\n+E\t((..)|(.)){2}\t\t\t\taaa\t\t(0,3)(2,3)(0,2)(2,3)\tRE2/Go\n+E\t((..)|(.)){3}\t\t\t\taaa\t\t(0,3)(2,3)(?,?)(2,3)\n+\n+#E\t((..)|(.))*\t\t\t\taaa\t\t(0,3)(2,3)(?,?)(2,3)\n+E\t((..)|(.))*\t\t\t\taaa\t\t(0,3)(2,3)(0,2)(2,3)\tRE2/Go\n+\n+E\t((..)|(.))\t\t\t\taaaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.))((..)|(.))\t\t\taaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\taaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,3)(?,?)(2,3)(3,4)(?,?)(3,4)\n+\n+E\t((..)|(.)){1}\t\t\t\taaaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.)){2}\t\t\t\taaaa\t\t(0,4)(2,4)(2,4)(?,?)\n+#E\t((..)|(.)){3}\t\t\t\taaaa\t\t(0,4)(3,4)(?,?)(3,4)\n+E\t((..)|(.)){3}\t\t\t\taaaa\t\t(0,4)(3,4)(0,2)(3,4)\tRE2/Go\n+\n+E\t((..)|(.))*\t\t\t\taaaa\t\t(0,4)(2,4)(2,4)(?,?)\n+\n+E\t((..)|(.))\t\t\t\taaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.))((..)|(.))\t\t\taaaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\taaaaa\t\t(0,5)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)(4,5)(?,?)(4,5)\n+\n+E\t((..)|(.)){1}\t\t\t\taaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.)){2}\t\t\t\taaaaa\t\t(0,4)(2,4)(2,4)(?,?)\n+#E\t((..)|(.)){3}\t\t\t\taaaaa\t\t(0,5)(4,5)(?,?)(4,5)\n+E\t((..)|(.)){3}\t\t\t\taaaaa\t\t(0,5)(4,5)(2,4)(4,5)\tRE2/Go\n+\n+#E\t((..)|(.))*\t\t\t\taaaaa\t\t(0,5)(4,5)(?,?)(4,5)\n+E\t((..)|(.))*\t\t\t\taaaaa\t\t(0,5)(4,5)(2,4)(4,5)\tRE2/Go\n+\n+E\t((..)|(.))\t\t\t\taaaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.))((..)|(.))\t\t\taaaaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)\n+E\t((..)|(.))((..)|(.))((..)|(.))\t\taaaaaa\t\t(0,6)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)(4,6)(4,6)(?,?)\n+\n+E\t((..)|(.)){1}\t\t\t\taaaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n+E\t((..)|(.)){2}\t\t\t\taaaaaa\t\t(0,4)(2,4)(2,4)(?,?)\n+E\t((..)|(.)){3}\t\t\t\taaaaaa\t\t(0,6)(4,6)(4,6)(?,?)\n+\n+E\t((..)|(.))*\t\t\t\taaaaaa\t\t(0,6)(4,6)(4,6)(?,?)\n+\n+NOTE\tadditional repetition tests graciously provided by Chris Kuklewicz www.haskell.org 2009-02-02\n+\n+# These test a bug in OS X / FreeBSD / NetBSD, and libtree. \n+# Linux/GLIBC gets the {8,} and {8,8} wrong.\n+\n+:HA#100:E\tX(.?){0,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#101:E\tX(.?){1,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#102:E\tX(.?){2,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#103:E\tX(.?){3,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#104:E\tX(.?){4,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#105:E\tX(.?){5,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#106:E\tX(.?){6,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#107:E\tX(.?){7,}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#108:E\tX(.?){8,}Y\tX1234567Y\t(0,9)(8,8)\n+#:HA#110:E\tX(.?){0,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#110:E\tX(.?){0,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#111:E\tX(.?){1,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#111:E\tX(.?){1,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#112:E\tX(.?){2,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#112:E\tX(.?){2,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#113:E\tX(.?){3,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#113:E\tX(.?){3,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#114:E\tX(.?){4,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#114:E\tX(.?){4,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#115:E\tX(.?){5,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#115:E\tX(.?){5,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#116:E\tX(.?){6,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#116:E\tX(.?){6,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+#:HA#117:E\tX(.?){7,8}Y\tX1234567Y\t(0,9)(7,8)\n+:HA#117:E\tX(.?){7,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n+:HA#118:E\tX(.?){8,8}Y\tX1234567Y\t(0,9)(8,8)\n+\n+# These test a fixed bug in my regex-tdfa that did not keep the expanded\n+# form properly grouped, so right association did the wrong thing with\n+# these ambiguous patterns (crafted just to test my code when I became\n+# suspicious of my implementation).  The first subexpression should use\n+# \"ab\" then \"a\" then \"bcd\".\n+\n+# OS X / FreeBSD / NetBSD badly fail many of these, with impossible\n+# results like (0,6)(4,5)(6,6).\n+\n+:HA#260:E\t(a|ab|c|bcd){0,}(d*)\tababcd\t(0,1)(0,1)(1,1)\n+:HA#261:E\t(a|ab|c|bcd){1,}(d*)\tababcd\t(0,1)(0,1)(1,1)\n+:HA#262:E\t(a|ab|c|bcd){2,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#263:E\t(a|ab|c|bcd){3,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#264:E\t(a|ab|c|bcd){4,}(d*)\tababcd\tNOMATCH\n+:HA#265:E\t(a|ab|c|bcd){0,10}(d*)\tababcd\t(0,1)(0,1)(1,1)\n+:HA#266:E\t(a|ab|c|bcd){1,10}(d*)\tababcd\t(0,1)(0,1)(1,1)\n+:HA#267:E\t(a|ab|c|bcd){2,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#268:E\t(a|ab|c|bcd){3,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#269:E\t(a|ab|c|bcd){4,10}(d*)\tababcd\tNOMATCH\n+:HA#270:E\t(a|ab|c|bcd)*(d*)\tababcd\t(0,1)(0,1)(1,1)\n+:HA#271:E\t(a|ab|c|bcd)+(d*)\tababcd\t(0,1)(0,1)(1,1)\n+\n+# The above worked on Linux/GLIBC but the following often fail.\n+# They also trip up OS X / FreeBSD / NetBSD:\n+\n+#:HA#280:E\t(ab|a|c|bcd){0,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#280:E\t(ab|a|c|bcd){0,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#281:E\t(ab|a|c|bcd){1,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#281:E\t(ab|a|c|bcd){1,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#282:E\t(ab|a|c|bcd){2,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#282:E\t(ab|a|c|bcd){2,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#283:E\t(ab|a|c|bcd){3,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#283:E\t(ab|a|c|bcd){3,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+:HA#284:E\t(ab|a|c|bcd){4,}(d*)\tababcd\tNOMATCH\n+#:HA#285:E\t(ab|a|c|bcd){0,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#285:E\t(ab|a|c|bcd){0,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#286:E\t(ab|a|c|bcd){1,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#286:E\t(ab|a|c|bcd){1,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#287:E\t(ab|a|c|bcd){2,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#287:E\t(ab|a|c|bcd){2,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#288:E\t(ab|a|c|bcd){3,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#288:E\t(ab|a|c|bcd){3,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+:HA#289:E\t(ab|a|c|bcd){4,10}(d*)\tababcd\tNOMATCH\n+#:HA#290:E\t(ab|a|c|bcd)*(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#290:E\t(ab|a|c|bcd)*(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n+#:HA#291:E\t(ab|a|c|bcd)+(d*)\tababcd\t(0,6)(3,6)(6,6)\n+:HA#291:E\t(ab|a|c|bcd)+(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go"}, {"sha": "c263827dab847ae305adbeed4e97adef1b9c1eba", "filename": "src/libregex/unicode.rs", "status": "added", "additions": 5537, "deletions": 0, "changes": 5537, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Funicode.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Funicode.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Funicode.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3"}, {"sha": "6058ba6bf9210dd2f166cdc020f1aa33f484ccca", "filename": "src/libregex/vm.rs", "status": "added", "additions": 587, "deletions": 0, "changes": 587, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fvm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex%2Fvm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fvm.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,587 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// FIXME: Currently, the VM simulates an NFA. It would be nice to have another\n+// VM that simulates a DFA.\n+//\n+// According to Russ Cox[1], a DFA performs better than an NFA, principally\n+// because it reuses states previously computed by the machine *and* doesn't\n+// keep track of capture groups. The drawback of a DFA (aside from its\n+// complexity) is that it can't accurately return the locations of submatches.\n+// The NFA *can* do that. (This is my understanding anyway.)\n+//\n+// Cox suggests that a DFA ought to be used to answer \"does this match\" and\n+// \"where does it match\" questions. (In the latter, the starting position of\n+// the match is computed by executing the regex backwards.) Cox also suggests\n+// that a DFA should be run when asking \"where are the submatches\", which can\n+// 1) quickly answer \"no\" is there's no match and 2) discover the substring\n+// that matches, which means running the NFA on smaller input.\n+//\n+// Currently, the NFA simulation implemented below does some dirty tricks to\n+// avoid tracking capture groups when they aren't needed (which only works\n+// for 'is_match', not 'find'). This is a half-measure, but does provide some\n+// perf improvement.\n+//\n+// AFAIK, the DFA/NFA approach is implemented in RE2/C++ but *not* in RE2/Go.\n+//\n+// [1] - http://swtch.com/~rsc/regex/regex3.html\n+\n+use std::cmp;\n+use std::mem;\n+use std::slice::MutableVector;\n+use compile::{\n+    Program,\n+    Match, OneChar, CharClass, Any, EmptyBegin, EmptyEnd, EmptyWordBoundary,\n+    Save, Jump, Split,\n+};\n+use parse::{FLAG_NOCASE, FLAG_MULTI, FLAG_DOTNL, FLAG_NEGATED};\n+use parse::unicode::PERLW;\n+\n+pub type CaptureLocs = Vec<Option<uint>>;\n+\n+/// Indicates the type of match to be performed by the VM.\n+pub enum MatchKind {\n+    /// Only checks if a match exists or not. Does not return location.\n+    Exists,\n+    /// Returns the start and end indices of the entire match in the input\n+    /// given.\n+    Location,\n+    /// Returns the start and end indices of each submatch in the input given.\n+    Submatches,\n+}\n+\n+/// Runs an NFA simulation on the compiled expression given on the search text\n+/// `input`. The search begins at byte index `start` and ends at byte index\n+/// `end`. (The range is specified here so that zero-width assertions will work\n+/// correctly when searching for successive non-overlapping matches.)\n+///\n+/// The `which` parameter indicates what kind of capture information the caller\n+/// wants. There are three choices: match existence only, the location of the\n+/// entire match or the locations of the entire match in addition to the\n+/// locations of each submatch.\n+pub fn run<'r, 't>(which: MatchKind, prog: &'r Program, input: &'t str,\n+                   start: uint, end: uint) -> CaptureLocs {\n+    Nfa {\n+        which: which,\n+        prog: prog,\n+        input: input,\n+        start: start,\n+        end: end,\n+        ic: 0,\n+        chars: CharReader::new(input),\n+    }.run()\n+}\n+\n+struct Nfa<'r, 't> {\n+    which: MatchKind,\n+    prog: &'r Program,\n+    input: &'t str,\n+    start: uint,\n+    end: uint,\n+    ic: uint,\n+    chars: CharReader<'t>,\n+}\n+\n+/// Indicates the next action to take after a single non-empty instruction\n+/// is processed.\n+pub enum StepState {\n+    /// This is returned if and only if a Match instruction is reached and\n+    /// we only care about the existence of a match. It instructs the VM to\n+    /// quit early.\n+    StepMatchEarlyReturn,\n+    /// Indicates that a match was found. Thus, the rest of the states in the\n+    /// *current* queue should be dropped (i.e., leftmost-first semantics).\n+    /// States in the \"next\" queue can still be processed.\n+    StepMatch,\n+    /// No match was found. Continue with the next state in the queue.\n+    StepContinue,\n+}\n+\n+impl<'r, 't> Nfa<'r, 't> {\n+    fn run(&mut self) -> CaptureLocs {\n+        let ncaps = match self.which {\n+            Exists => 0,\n+            Location => 1,\n+            Submatches => self.prog.num_captures(),\n+        };\n+        let mut matched = false;\n+        let ninsts = self.prog.insts.len();\n+        let mut clist = &mut Threads::new(self.which, ninsts, ncaps);\n+        let mut nlist = &mut Threads::new(self.which, ninsts, ncaps);\n+\n+        let mut groups = Vec::from_elem(ncaps * 2, None);\n+\n+        // Determine if the expression starts with a '^' so we can avoid\n+        // simulating .*?\n+        // Make sure multi-line mode isn't enabled for it, otherwise we can't\n+        // drop the initial .*?\n+        let prefix_anchor =\n+            match *self.prog.insts.get(1) {\n+                EmptyBegin(flags) if flags & FLAG_MULTI == 0 => true,\n+                _ => false,\n+            };\n+\n+        self.ic = self.start;\n+        let mut next_ic = self.chars.set(self.start);\n+        while self.ic <= self.end {\n+            if clist.size == 0 {\n+                // We have a match and we're done exploring alternatives.\n+                // Time to quit.\n+                if matched {\n+                    break\n+                }\n+\n+                // If there are no threads to try, then we'll have to start\n+                // over at the beginning of the regex.\n+                // BUT, if there's a literal prefix for the program, try to\n+                // jump ahead quickly. If it can't be found, then we can bail\n+                // out early.\n+                if self.prog.prefix.len() > 0 && clist.size == 0 {\n+                    let needle = self.prog.prefix.as_slice().as_bytes();\n+                    let haystack = self.input.as_bytes().slice_from(self.ic);\n+                    match find_prefix(needle, haystack) {\n+                        None => break,\n+                        Some(i) => {\n+                            self.ic += i;\n+                            next_ic = self.chars.set(self.ic);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // This simulates a preceding '.*?' for every regex by adding\n+            // a state starting at the current position in the input for the\n+            // beginning of the program only if we don't already have a match.\n+            if clist.size == 0 || (!prefix_anchor && !matched) {\n+                self.add(clist, 0, groups.as_mut_slice())\n+            }\n+\n+            // Now we try to read the next character.\n+            // As a result, the 'step' method will look at the previous\n+            // character.\n+            self.ic = next_ic;\n+            next_ic = self.chars.advance();\n+\n+            let mut i = 0;\n+            while i < clist.size {\n+                let pc = clist.pc(i);\n+                let step_state = self.step(groups.as_mut_slice(), nlist,\n+                                           clist.groups(i), pc);\n+                match step_state {\n+                    StepMatchEarlyReturn => return vec![Some(0), Some(0)],\n+                    StepMatch => { matched = true; clist.empty() },\n+                    StepContinue => {},\n+                }\n+                i += 1;\n+            }\n+            mem::swap(&mut clist, &mut nlist);\n+            nlist.empty();\n+        }\n+        match self.which {\n+            Exists if matched     => vec![Some(0), Some(0)],\n+            Exists                => vec![None, None],\n+            Location | Submatches => groups,\n+        }\n+    }\n+\n+    fn step(&self, groups: &mut [Option<uint>], nlist: &mut Threads,\n+            caps: &mut [Option<uint>], pc: uint)\n+           -> StepState {\n+        match *self.prog.insts.get(pc) {\n+            Match => {\n+                match self.which {\n+                    Exists => {\n+                        return StepMatchEarlyReturn\n+                    }\n+                    Location => {\n+                        groups[0] = caps[0];\n+                        groups[1] = caps[1];\n+                        return StepMatch\n+                    }\n+                    Submatches => {\n+                        for (slot, val) in groups.mut_iter().zip(caps.iter()) {\n+                            *slot = *val;\n+                        }\n+                        return StepMatch\n+                    }\n+                }\n+            }\n+            OneChar(c, flags) => {\n+                if self.char_eq(flags & FLAG_NOCASE > 0, self.chars.prev, c) {\n+                    self.add(nlist, pc+1, caps);\n+                }\n+            }\n+            CharClass(ref ranges, flags) => {\n+                if self.chars.prev.is_some() {\n+                    let c = self.chars.prev.unwrap();\n+                    let negate = flags & FLAG_NEGATED > 0;\n+                    let casei = flags & FLAG_NOCASE > 0;\n+                    let found = ranges.as_slice();\n+                    let found = found.bsearch(|&rc| class_cmp(casei, c, rc));\n+                    let found = found.is_some();\n+                    if (found && !negate) || (!found && negate) {\n+                        self.add(nlist, pc+1, caps);\n+                    }\n+                }\n+            }\n+            Any(flags) => {\n+                if flags & FLAG_DOTNL > 0\n+                   || !self.char_eq(false, self.chars.prev, '\\n') {\n+                    self.add(nlist, pc+1, caps)\n+                }\n+            }\n+            EmptyBegin(_) | EmptyEnd(_) | EmptyWordBoundary(_)\n+            | Save(_) | Jump(_) | Split(_, _) => {},\n+        }\n+        StepContinue\n+    }\n+\n+    fn add(&self, nlist: &mut Threads, pc: uint, groups: &mut [Option<uint>]) {\n+        if nlist.contains(pc) {\n+            return\n+        }\n+        // We have to add states to the threads list even if their empty.\n+        // TL;DR - It prevents cycles.\n+        // If we didn't care about cycles, we'd *only* add threads that\n+        // correspond to non-jumping instructions (OneChar, Any, Match, etc.).\n+        // But, it's possible for valid regexs (like '(a*)*') to result in\n+        // a cycle in the instruction list. e.g., We'll keep chasing the Split\n+        // instructions forever.\n+        // So we add these instructions to our thread queue, but in the main\n+        // VM loop, we look for them but simply ignore them.\n+        // Adding them to the queue prevents them from being revisited so we\n+        // can avoid cycles (and the inevitable stack overflow).\n+        //\n+        // We make a minor optimization by indicating that the state is \"empty\"\n+        // so that its capture groups are not filled in.\n+        match *self.prog.insts.get(pc) {\n+            EmptyBegin(flags) => {\n+                let multi = flags & FLAG_MULTI > 0;\n+                nlist.add(pc, groups, true);\n+                if self.chars.is_begin()\n+                   || (multi && self.char_is(self.chars.prev, '\\n')) {\n+                    self.add(nlist, pc + 1, groups)\n+                }\n+            }\n+            EmptyEnd(flags) => {\n+                let multi = flags & FLAG_MULTI > 0;\n+                nlist.add(pc, groups, true);\n+                if self.chars.is_end()\n+                   || (multi && self.char_is(self.chars.cur, '\\n')) {\n+                    self.add(nlist, pc + 1, groups)\n+                }\n+            }\n+            EmptyWordBoundary(flags) => {\n+                nlist.add(pc, groups, true);\n+                if self.chars.is_word_boundary() == !(flags & FLAG_NEGATED > 0) {\n+                    self.add(nlist, pc + 1, groups)\n+                }\n+            }\n+            Save(slot) => {\n+                nlist.add(pc, groups, true);\n+                match self.which {\n+                    Location if slot <= 1 => {\n+                        let old = groups[slot];\n+                        groups[slot] = Some(self.ic);\n+                        self.add(nlist, pc + 1, groups);\n+                        groups[slot] = old;\n+                    }\n+                    Submatches => {\n+                        let old = groups[slot];\n+                        groups[slot] = Some(self.ic);\n+                        self.add(nlist, pc + 1, groups);\n+                        groups[slot] = old;\n+                    }\n+                    Exists | Location => self.add(nlist, pc + 1, groups),\n+                }\n+            }\n+            Jump(to) => {\n+                nlist.add(pc, groups, true);\n+                self.add(nlist, to, groups)\n+            }\n+            Split(x, y) => {\n+                nlist.add(pc, groups, true);\n+                self.add(nlist, x, groups);\n+                self.add(nlist, y, groups);\n+            }\n+            Match | OneChar(_, _) | CharClass(_, _) | Any(_) => {\n+                nlist.add(pc, groups, false);\n+            }\n+        }\n+    }\n+\n+    // FIXME: For case insensitive comparisons, it uses the uppercase\n+    // character and tests for equality. IIUC, this does not generalize to\n+    // all of Unicode. I believe we need to check the entire fold for each\n+    // character. This will be easy to add if and when it gets added to Rust's\n+    // standard library.\n+    #[inline]\n+    fn char_eq(&self, casei: bool, textc: Option<char>, regc: char) -> bool {\n+        match textc {\n+            None => false,\n+            Some(textc) => {\n+                regc == textc\n+                    || (casei && regc.to_uppercase() == textc.to_uppercase())\n+            }\n+        }\n+    }\n+\n+    #[inline]\n+    fn char_is(&self, textc: Option<char>, regc: char) -> bool {\n+        textc == Some(regc)\n+    }\n+}\n+\n+/// CharReader is responsible for maintaining a \"previous\" and a \"current\"\n+/// character. This one-character lookahead is necessary for assertions that\n+/// look one character before or after the current position.\n+pub struct CharReader<'t> {\n+    /// The previous character read. It is None only when processing the first\n+    /// character of the input.\n+    pub prev: Option<char>,\n+    /// The current character.\n+    pub cur: Option<char>,\n+    input: &'t str,\n+    next: uint,\n+}\n+\n+impl<'t> CharReader<'t> {\n+    /// Returns a new CharReader that advances through the input given.\n+    /// Note that a CharReader has no knowledge of the range in which to search\n+    /// the input.\n+    pub fn new(input: &'t str) -> CharReader<'t> {\n+        CharReader {\n+            prev: None,\n+            cur: None,\n+            input: input,\n+            next: 0,\n+       }\n+    }\n+\n+    /// Sets the previous and current character given any arbitrary byte\n+    /// index (at a unicode codepoint boundary).\n+    #[inline]\n+    pub fn set(&mut self, ic: uint) -> uint {\n+        self.prev = None;\n+        self.cur = None;\n+        self.next = 0;\n+\n+        if self.input.len() == 0 {\n+            return 1\n+        }\n+        if ic > 0 {\n+            let i = cmp::min(ic, self.input.len());\n+            let prev = self.input.char_range_at_reverse(i);\n+            self.prev = Some(prev.ch);\n+        }\n+        if ic < self.input.len() {\n+            let cur = self.input.char_range_at(ic);\n+            self.cur = Some(cur.ch);\n+            self.next = cur.next;\n+            self.next\n+        } else {\n+            self.input.len() + 1\n+        }\n+    }\n+\n+    /// Does the same as `set`, except it always advances to the next\n+    /// character in the input (and therefore does half as many UTF8 decodings).\n+    #[inline]\n+    pub fn advance(&mut self) -> uint {\n+        self.prev = self.cur;\n+        if self.next < self.input.len() {\n+            let cur = self.input.char_range_at(self.next);\n+            self.cur = Some(cur.ch);\n+            self.next = cur.next;\n+        } else {\n+            self.cur = None;\n+            self.next = self.input.len() + 1;\n+        }\n+        self.next\n+    }\n+\n+    /// Returns true if and only if this is the beginning of the input\n+    /// (ignoring the range of the input to search).\n+    #[inline]\n+    pub fn is_begin(&self) -> bool { self.prev.is_none() }\n+\n+    /// Returns true if and only if this is the end of the input\n+    /// (ignoring the range of the input to search).\n+    #[inline]\n+    pub fn is_end(&self) -> bool { self.cur.is_none() }\n+\n+    /// Returns true if and only if the current position is a word boundary.\n+    /// (Ignoring the range of the input to search.)\n+    pub fn is_word_boundary(&self) -> bool {\n+        if self.is_begin() {\n+            return is_word(self.cur)\n+        }\n+        if self.is_end() {\n+            return is_word(self.prev)\n+        }\n+        (is_word(self.cur) && !is_word(self.prev))\n+        || (is_word(self.prev) && !is_word(self.cur))\n+    }\n+}\n+\n+struct Thread {\n+    pc: uint,\n+    groups: Vec<Option<uint>>,\n+}\n+\n+struct Threads {\n+    which: MatchKind,\n+    queue: Vec<Thread>,\n+    sparse: Vec<uint>,\n+    size: uint,\n+}\n+\n+impl Threads {\n+    // This is using a wicked neat trick to provide constant time lookup\n+    // for threads in the queue using a sparse set. A queue of threads is\n+    // allocated once with maximal size when the VM initializes and is reused\n+    // throughout execution. That is, there should be zero allocation during\n+    // the execution of a VM.\n+    //\n+    // See http://research.swtch.com/sparse for the deets.\n+    fn new(which: MatchKind, num_insts: uint, ncaps: uint) -> Threads {\n+        Threads {\n+            which: which,\n+            queue: Vec::from_fn(num_insts, |_| {\n+                Thread { pc: 0, groups: Vec::from_elem(ncaps * 2, None) }\n+            }),\n+            sparse: Vec::from_elem(num_insts, 0u),\n+            size: 0,\n+        }\n+    }\n+\n+    fn add(&mut self, pc: uint, groups: &[Option<uint>], empty: bool) {\n+        let t = self.queue.get_mut(self.size);\n+        t.pc = pc;\n+        match (empty, self.which) {\n+            (_, Exists) | (true, _) => {},\n+            (false, Location) => {\n+                *t.groups.get_mut(0) = groups[0];\n+                *t.groups.get_mut(1) = groups[1];\n+            }\n+            (false, Submatches) => {\n+                for (slot, val) in t.groups.mut_iter().zip(groups.iter()) {\n+                    *slot = *val;\n+                }\n+            }\n+        }\n+        *self.sparse.get_mut(pc) = self.size;\n+        self.size += 1;\n+    }\n+\n+    #[inline]\n+    fn contains(&self, pc: uint) -> bool {\n+        let s = *self.sparse.get(pc);\n+        s < self.size && self.queue.get(s).pc == pc\n+    }\n+\n+    #[inline]\n+    fn empty(&mut self) {\n+        self.size = 0;\n+    }\n+\n+    #[inline]\n+    fn pc(&self, i: uint) -> uint {\n+        self.queue.get(i).pc\n+    }\n+\n+    #[inline]\n+    fn groups<'r>(&'r mut self, i: uint) -> &'r mut [Option<uint>] {\n+        self.queue.get_mut(i).groups.as_mut_slice()\n+    }\n+}\n+\n+/// Returns true if the character is a word character, according to the\n+/// (Unicode friendly) Perl character class '\\w'.\n+/// Note that this is only use for testing word boundaries. The actual '\\w'\n+/// is encoded as a CharClass instruction.\n+pub fn is_word(c: Option<char>) -> bool {\n+    let c = match c {\n+        None => return false,\n+        Some(c) => c,\n+    };\n+    // Try the common ASCII case before invoking binary search.\n+    match c {\n+        '_' | '0' .. '9' | 'a' .. 'z' | 'A' .. 'Z' => true,\n+        _ => PERLW.bsearch(|&(start, end)| {\n+            if c >= start && c <= end {\n+                Equal\n+            } else if start > c {\n+                Greater\n+            } else {\n+                Less\n+            }\n+        }).is_some()\n+    }\n+}\n+\n+/// Given a character and a single character class range, return an ordering\n+/// indicating whether the character is less than the start of the range,\n+/// in the range (inclusive) or greater than the end of the range.\n+///\n+/// If `casei` is `true`, then this ordering is computed case insensitively.\n+///\n+/// This function is meant to be used with a binary search.\n+#[inline]\n+fn class_cmp(casei: bool, mut textc: char,\n+             (mut start, mut end): (char, char)) -> Ordering {\n+    if casei {\n+        // FIXME: This is pretty ridiculous. All of this case conversion\n+        // can be moved outside this function:\n+        // 1) textc should be uppercased outside the bsearch.\n+        // 2) the character class itself should be uppercased either in the\n+        //    parser or the compiler.\n+        // FIXME: This is too simplistic for correct Unicode support.\n+        //        See also: char_eq\n+        textc = textc.to_uppercase();\n+        start = start.to_uppercase();\n+        end = end.to_uppercase();\n+    }\n+    if textc >= start && textc <= end {\n+        Equal\n+    } else if start > textc {\n+        Greater\n+    } else {\n+        Less\n+    }\n+}\n+\n+/// Returns the starting location of `needle` in `haystack`.\n+/// If `needle` is not in `haystack`, then `None` is returned.\n+///\n+/// Note that this is using a naive substring algorithm.\n+#[inline]\n+pub fn find_prefix(needle: &[u8], haystack: &[u8]) -> Option<uint> {\n+    let (hlen, nlen) = (haystack.len(), needle.len());\n+    if nlen > hlen || nlen == 0 {\n+        return None\n+    }\n+    let mut hayi = 0u;\n+    'HAYSTACK: loop {\n+        if hayi > hlen - nlen {\n+            break\n+        }\n+        let mut nedi = 0;\n+        while nedi < nlen {\n+            if haystack[hayi+nedi] != needle[nedi] {\n+                hayi += 1;\n+                continue 'HAYSTACK\n+            }\n+            nedi += 1;\n+        }\n+        return Some(hayi)\n+    }\n+    None\n+}"}, {"sha": "72e00deba4d9cc8fa9e0471545ae9af7ef91de96", "filename": "src/libregex_macros/lib.rs", "status": "added", "additions": 684, "deletions": 0, "changes": 684, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex_macros%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Flibregex_macros%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex_macros%2Flib.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,684 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! This crate provides the `regex!` macro. Its use is documented in the\n+//! `regex` crate.\n+\n+#![crate_id = \"regex_macros#0.11-pre\"]\n+#![crate_type = \"dylib\"]\n+#![experimental]\n+#![license = \"MIT/ASL2\"]\n+#![doc(html_logo_url = \"http://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n+       html_favicon_url = \"http://www.rust-lang.org/favicon.ico\",\n+       html_root_url = \"http://static.rust-lang.org/doc/master\")]\n+\n+#![feature(macro_registrar, managed_boxes, quote)]\n+\n+extern crate regex;\n+extern crate syntax;\n+\n+use syntax::ast;\n+use syntax::codemap;\n+use syntax::ext::base::{\n+    SyntaxExtension, ExtCtxt, MacResult, MacExpr, DummyResult,\n+    NormalTT, BasicMacroExpander,\n+};\n+use syntax::parse;\n+use syntax::parse::token;\n+use syntax::print::pprust;\n+\n+use regex::Regex;\n+use regex::native::{\n+    OneChar, CharClass, Any, Save, Jump, Split,\n+    Match, EmptyBegin, EmptyEnd, EmptyWordBoundary,\n+    Program, Dynamic, Native,\n+    FLAG_NOCASE, FLAG_MULTI, FLAG_DOTNL, FLAG_NEGATED,\n+};\n+\n+/// For the `regex!` syntax extension. Do not use.\n+#[macro_registrar]\n+#[doc(hidden)]\n+pub fn macro_registrar(register: |ast::Name, SyntaxExtension|) {\n+    let expander = ~BasicMacroExpander { expander: native, span: None };\n+    register(token::intern(\"regex\"), NormalTT(expander, None))\n+}\n+\n+/// Generates specialized code for the Pike VM for a particular regular\n+/// expression.\n+///\n+/// There are two primary differences between the code generated here and the\n+/// general code in vm.rs.\n+///\n+/// 1. All heap allocation is removed. Sized vector types are used instead.\n+///    Care must be taken to make sure that these vectors are not copied\n+///    gratuitously. (If you're not sure, run the benchmarks. They will yell\n+///    at you if you do.)\n+/// 2. The main `match instruction { ... }` expressions are replaced with more\n+///    direct `match pc { ... }`. The generators can be found in\n+///    `step_insts` and `add_insts`.\n+///\n+/// Other more minor changes include eliding code when possible (although this\n+/// isn't completely thorough at the moment), and translating character class\n+/// matching from using a binary search to a simple `match` expression (see\n+/// `match_class`).\n+///\n+/// It is strongly recommended to read the dynamic implementation in vm.rs\n+/// first before trying to understand the code generator. The implementation\n+/// strategy is identical and vm.rs has comments and will be easier to follow.\n+fn native(cx: &mut ExtCtxt, sp: codemap::Span, tts: &[ast::TokenTree])\n+         -> ~MacResult {\n+    let regex = match parse(cx, tts) {\n+        Some(r) => r,\n+        // error is logged in 'parse' with cx.span_err\n+        None => return DummyResult::any(sp),\n+    };\n+    let re = match Regex::new(regex.to_owned()) {\n+        Ok(re) => re,\n+        Err(err) => {\n+            cx.span_err(sp, err.to_str());\n+            return DummyResult::any(sp)\n+        }\n+    };\n+    let prog = match re.p {\n+        Dynamic(ref prog) => prog.clone(),\n+        Native(_) => unreachable!(),\n+    };\n+\n+    let mut gen = NfaGen {\n+        cx: &*cx, sp: sp, prog: prog,\n+        names: re.names.clone(), original: re.original.clone(),\n+    };\n+    MacExpr::new(gen.code())\n+}\n+\n+struct NfaGen<'a> {\n+    cx: &'a ExtCtxt<'a>,\n+    sp: codemap::Span,\n+    prog: Program,\n+    names: ~[Option<~str>],\n+    original: ~str,\n+}\n+\n+impl<'a> NfaGen<'a> {\n+    fn code(&mut self) -> @ast::Expr {\n+        // Most or all of the following things are used in the quasiquoted\n+        // expression returned.\n+        let num_cap_locs = 2 * self.prog.num_captures();\n+        let num_insts = self.prog.insts.len();\n+        let cap_names = self.vec_expr(self.names,\n+            |cx, name| match name {\n+                &Some(ref name) => {\n+                    let name = name.as_slice();\n+                    quote_expr!(cx, Some(~$name))\n+                }\n+                &None => quote_expr!(cx, None),\n+            }\n+        );\n+        let prefix_anchor =\n+            match self.prog.insts.as_slice()[1] {\n+                EmptyBegin(flags) if flags & FLAG_MULTI == 0 => true,\n+                _ => false,\n+            };\n+        let init_groups = self.vec_from_fn(num_cap_locs,\n+                                           |cx| quote_expr!(cx, None));\n+        let prefix_bytes = self.vec_expr(self.prog.prefix.as_slice().as_bytes(),\n+                                         |cx, b| quote_expr!(cx, $b));\n+        let check_prefix = self.check_prefix();\n+        let step_insts = self.step_insts();\n+        let add_insts = self.add_insts();\n+        let regex = self.original.as_slice();\n+\n+        quote_expr!(self.cx, {\n+fn exec<'t>(which: ::regex::native::MatchKind, input: &'t str,\n+            start: uint, end: uint) -> Vec<Option<uint>> {\n+    #![allow(unused_imports)]\n+    use regex::native::{\n+        MatchKind, Exists, Location, Submatches,\n+        StepState, StepMatchEarlyReturn, StepMatch, StepContinue,\n+        CharReader, find_prefix,\n+    };\n+\n+    return Nfa {\n+        which: which,\n+        input: input,\n+        ic: 0,\n+        chars: CharReader::new(input),\n+    }.run(start, end);\n+\n+    type Captures = [Option<uint>, ..$num_cap_locs];\n+\n+    struct Nfa<'t> {\n+        which: MatchKind,\n+        input: &'t str,\n+        ic: uint,\n+        chars: CharReader<'t>,\n+    }\n+\n+    impl<'t> Nfa<'t> {\n+        #[allow(unused_variable)]\n+        fn run(&mut self, start: uint, end: uint) -> Vec<Option<uint>> {\n+            let mut matched = false;\n+            let prefix_bytes: &[u8] = &$prefix_bytes;\n+            let mut clist = &mut Threads::new(self.which);\n+            let mut nlist = &mut Threads::new(self.which);\n+\n+            let mut groups = $init_groups;\n+\n+            self.ic = start;\n+            let mut next_ic = self.chars.set(start);\n+            while self.ic <= end {\n+                if clist.size == 0 {\n+                    if matched {\n+                        break\n+                    }\n+                    $check_prefix\n+                }\n+                if clist.size == 0 || (!$prefix_anchor && !matched) {\n+                    self.add(clist, 0, &mut groups)\n+                }\n+\n+                self.ic = next_ic;\n+                next_ic = self.chars.advance();\n+\n+                let mut i = 0;\n+                while i < clist.size {\n+                    let pc = clist.pc(i);\n+                    let step_state = self.step(&mut groups, nlist,\n+                                               clist.groups(i), pc);\n+                    match step_state {\n+                        StepMatchEarlyReturn =>\n+                            return vec![Some(0u), Some(0u)],\n+                        StepMatch => { matched = true; clist.empty() },\n+                        StepContinue => {},\n+                    }\n+                    i += 1;\n+                }\n+                ::std::mem::swap(&mut clist, &mut nlist);\n+                nlist.empty();\n+            }\n+            match self.which {\n+                Exists if matched     => vec![Some(0u), Some(0u)],\n+                Exists                => vec![None, None],\n+                Location | Submatches => groups.iter().map(|x| *x).collect(),\n+            }\n+        }\n+\n+        // Sometimes `nlist` is never used (for empty regexes).\n+        #[allow(unused_variable)]\n+        #[inline]\n+        fn step(&self, groups: &mut Captures, nlist: &mut Threads,\n+                caps: &mut Captures, pc: uint) -> StepState {\n+            $step_insts\n+            StepContinue\n+        }\n+\n+        fn add(&self, nlist: &mut Threads, pc: uint,\n+               groups: &mut Captures) {\n+            if nlist.contains(pc) {\n+                return\n+            }\n+            $add_insts\n+        }\n+    }\n+\n+    struct Thread {\n+        pc: uint,\n+        groups: Captures,\n+    }\n+\n+    struct Threads {\n+        which: MatchKind,\n+        queue: [Thread, ..$num_insts],\n+        sparse: [uint, ..$num_insts],\n+        size: uint,\n+    }\n+\n+    impl Threads {\n+        fn new(which: MatchKind) -> Threads {\n+            Threads {\n+                which: which,\n+                // These unsafe blocks are used for performance reasons, as it\n+                // gives us a zero-cost initialization of a sparse set. The\n+                // trick is described in more detail here:\n+                // http://research.swtch.com/sparse\n+                // The idea here is to avoid initializing threads that never\n+                // need to be initialized, particularly for larger regexs with\n+                // a lot of instructions.\n+                queue: unsafe { ::std::mem::uninit() },\n+                sparse: unsafe { ::std::mem::uninit() },\n+                size: 0,\n+            }\n+        }\n+\n+        #[inline]\n+        fn add(&mut self, pc: uint, groups: &Captures) {\n+            let t = &mut self.queue[self.size];\n+            t.pc = pc;\n+            match self.which {\n+                Exists => {},\n+                Location => {\n+                    t.groups[0] = groups[0];\n+                    t.groups[1] = groups[1];\n+                }\n+                Submatches => {\n+                    for (slot, val) in t.groups.mut_iter().zip(groups.iter()) {\n+                        *slot = *val;\n+                    }\n+                }\n+            }\n+            self.sparse[pc] = self.size;\n+            self.size += 1;\n+        }\n+\n+        #[inline]\n+        fn add_empty(&mut self, pc: uint) {\n+            self.queue[self.size].pc = pc;\n+            self.sparse[pc] = self.size;\n+            self.size += 1;\n+        }\n+\n+        #[inline]\n+        fn contains(&self, pc: uint) -> bool {\n+            let s = self.sparse[pc];\n+            s < self.size && self.queue[s].pc == pc\n+        }\n+\n+        #[inline]\n+        fn empty(&mut self) {\n+            self.size = 0;\n+        }\n+\n+        #[inline]\n+        fn pc(&self, i: uint) -> uint {\n+            self.queue[i].pc\n+        }\n+\n+        #[inline]\n+        fn groups<'r>(&'r mut self, i: uint) -> &'r mut Captures {\n+            &'r mut self.queue[i].groups\n+        }\n+    }\n+}\n+\n+::regex::Regex {\n+    original: ~$regex,\n+    names: ~$cap_names,\n+    p: ::regex::native::Native(exec),\n+}\n+        })\n+    }\n+\n+    // Generates code for the `add` method, which is responsible for adding\n+    // zero-width states to the next queue of states to visit.\n+    fn add_insts(&self) -> @ast::Expr {\n+        let arms = self.prog.insts.iter().enumerate().map(|(pc, inst)| {\n+            let nextpc = pc + 1;\n+            let body = match *inst {\n+                EmptyBegin(flags) => {\n+                    let nl = '\\n';\n+                    let cond =\n+                        if flags & FLAG_MULTI > 0 {\n+                            quote_expr!(self.cx,\n+                                self.chars.is_begin()\n+                                || self.chars.prev == Some($nl)\n+                            )\n+                        } else {\n+                            quote_expr!(self.cx, self.chars.is_begin())\n+                        };\n+                    quote_expr!(self.cx, {\n+                        nlist.add_empty($pc);\n+                        if $cond { self.add(nlist, $nextpc, &mut *groups) }\n+                    })\n+                }\n+                EmptyEnd(flags) => {\n+                    let nl = '\\n';\n+                    let cond =\n+                        if flags & FLAG_MULTI > 0 {\n+                            quote_expr!(self.cx,\n+                                self.chars.is_end()\n+                                || self.chars.cur == Some($nl)\n+                            )\n+                        } else {\n+                            quote_expr!(self.cx, self.chars.is_end())\n+                        };\n+                    quote_expr!(self.cx, {\n+                        nlist.add_empty($pc);\n+                        if $cond { self.add(nlist, $nextpc, &mut *groups) }\n+                    })\n+                }\n+                EmptyWordBoundary(flags) => {\n+                    let cond =\n+                        if flags & FLAG_NEGATED > 0 {\n+                            quote_expr!(self.cx, !self.chars.is_word_boundary())\n+                        } else {\n+                            quote_expr!(self.cx, self.chars.is_word_boundary())\n+                        };\n+                    quote_expr!(self.cx, {\n+                        nlist.add_empty($pc);\n+                        if $cond { self.add(nlist, $nextpc, &mut *groups) }\n+                    })\n+                }\n+                Save(slot) => {\n+                    let save = quote_expr!(self.cx, {\n+                        let old = groups[$slot];\n+                        groups[$slot] = Some(self.ic);\n+                        self.add(nlist, $nextpc, &mut *groups);\n+                        groups[$slot] = old;\n+                    });\n+                    let add = quote_expr!(self.cx, {\n+                        self.add(nlist, $nextpc, &mut *groups);\n+                    });\n+                    // If this is saving a submatch location but we request\n+                    // existence or only full match location, then we can skip\n+                    // right over it every time.\n+                    if slot > 1 {\n+                        quote_expr!(self.cx, {\n+                            nlist.add_empty($pc);\n+                            match self.which {\n+                                Submatches => $save,\n+                                Exists | Location => $add,\n+                            }\n+                        })\n+                    } else {\n+                        quote_expr!(self.cx, {\n+                            nlist.add_empty($pc);\n+                            match self.which {\n+                                Submatches | Location => $save,\n+                                Exists => $add,\n+                            }\n+                        })\n+                    }\n+                }\n+                Jump(to) => {\n+                    quote_expr!(self.cx, {\n+                        nlist.add_empty($pc);\n+                        self.add(nlist, $to, &mut *groups);\n+                    })\n+                }\n+                Split(x, y) => {\n+                    quote_expr!(self.cx, {\n+                        nlist.add_empty($pc);\n+                        self.add(nlist, $x, &mut *groups);\n+                        self.add(nlist, $y, &mut *groups);\n+                    })\n+                }\n+                // For Match, OneChar, CharClass, Any\n+                _ => quote_expr!(self.cx, nlist.add($pc, &*groups)),\n+            };\n+            self.arm_inst(pc, body)\n+        }).collect::<Vec<ast::Arm>>();\n+\n+        self.match_insts(arms)\n+    }\n+\n+    // Generates the code for the `step` method, which processes all states\n+    // in the current queue that consume a single character.\n+    fn step_insts(&self) -> @ast::Expr {\n+        let arms = self.prog.insts.iter().enumerate().map(|(pc, inst)| {\n+            let nextpc = pc + 1;\n+            let body = match *inst {\n+                Match => {\n+                    quote_expr!(self.cx, {\n+                        match self.which {\n+                            Exists => {\n+                                return StepMatchEarlyReturn\n+                            }\n+                            Location => {\n+                                groups[0] = caps[0];\n+                                groups[1] = caps[1];\n+                                return StepMatch\n+                            }\n+                            Submatches => {\n+                                for (slot, val) in groups.mut_iter().zip(caps.iter()) {\n+                                    *slot = *val;\n+                                }\n+                                return StepMatch\n+                            }\n+                        }\n+                    })\n+                }\n+                OneChar(c, flags) => {\n+                    if flags & FLAG_NOCASE > 0 {\n+                        let upc = c.to_uppercase();\n+                        quote_expr!(self.cx, {\n+                            let upc = self.chars.prev.map(|c| c.to_uppercase());\n+                            if upc == Some($upc) {\n+                                self.add(nlist, $nextpc, caps);\n+                            }\n+                        })\n+                    } else {\n+                        quote_expr!(self.cx, {\n+                            if self.chars.prev == Some($c) {\n+                                self.add(nlist, $nextpc, caps);\n+                            }\n+                        })\n+                    }\n+                }\n+                CharClass(ref ranges, flags) => {\n+                    let negate = flags & FLAG_NEGATED > 0;\n+                    let casei = flags & FLAG_NOCASE > 0;\n+                    let get_char =\n+                        if casei {\n+                            quote_expr!(self.cx, self.chars.prev.unwrap().to_uppercase())\n+                        } else {\n+                            quote_expr!(self.cx, self.chars.prev.unwrap())\n+                        };\n+                    let negcond =\n+                        if negate {\n+                            quote_expr!(self.cx, !found)\n+                        } else {\n+                            quote_expr!(self.cx, found)\n+                        };\n+                    let mranges = self.match_class(casei, ranges.as_slice());\n+                    quote_expr!(self.cx, {\n+                        if self.chars.prev.is_some() {\n+                            let c = $get_char;\n+                            let found = $mranges;\n+                            if $negcond {\n+                                self.add(nlist, $nextpc, caps);\n+                            }\n+                        }\n+                    })\n+                }\n+                Any(flags) => {\n+                    if flags & FLAG_DOTNL > 0 {\n+                        quote_expr!(self.cx, self.add(nlist, $nextpc, caps))\n+                    } else {\n+                        let nl = '\\n'; // no char lits allowed? wtf?\n+                        quote_expr!(self.cx, {\n+                            if self.chars.prev != Some($nl) {\n+                                self.add(nlist, $nextpc, caps)\n+                            }\n+                        })\n+                    }\n+                }\n+                // EmptyBegin, EmptyEnd, EmptyWordBoundary, Save, Jump, Split\n+                _ => quote_expr!(self.cx, {}),\n+            };\n+            self.arm_inst(pc, body)\n+        }).collect::<Vec<ast::Arm>>();\n+\n+        self.match_insts(arms)\n+    }\n+\n+    // Translates a character class into a match expression.\n+    // This avoids a binary search (and is hopefully replaced by a jump\n+    // table).\n+    fn match_class(&self, casei: bool, ranges: &[(char, char)]) -> @ast::Expr {\n+        let mut arms = ranges.iter().map(|&(mut start, mut end)| {\n+            if casei {\n+                start = start.to_uppercase();\n+                end = end.to_uppercase();\n+            }\n+            ast::Arm {\n+                attrs: vec!(),\n+                pats: vec!(@ast::Pat{\n+                    id: ast::DUMMY_NODE_ID,\n+                    span: self.sp,\n+                    node: ast::PatRange(quote_expr!(self.cx, $start),\n+                                        quote_expr!(self.cx, $end)),\n+                }),\n+                guard: None,\n+                body: quote_expr!(self.cx, true),\n+            }\n+        }).collect::<Vec<ast::Arm>>();\n+\n+        arms.push(self.wild_arm_expr(quote_expr!(self.cx, false)));\n+\n+        let match_on = quote_expr!(self.cx, c);\n+        self.dummy_expr(ast::ExprMatch(match_on, arms))\n+    }\n+\n+    // Generates code for checking a literal prefix of the search string.\n+    // The code is only generated if the regex *has* a literal prefix.\n+    // Otherwise, a no-op is returned.\n+    fn check_prefix(&self) -> @ast::Expr {\n+        if self.prog.prefix.len() == 0 {\n+            quote_expr!(self.cx, {})\n+        } else {\n+            quote_expr!(self.cx,\n+                if clist.size == 0 {\n+                    let haystack = self.input.as_bytes().slice_from(self.ic);\n+                    match find_prefix(prefix_bytes, haystack) {\n+                        None => break,\n+                        Some(i) => {\n+                            self.ic += i;\n+                            next_ic = self.chars.set(self.ic);\n+                        }\n+                    }\n+                }\n+            )\n+        }\n+    }\n+\n+    // Builds a `match pc { ... }` expression from a list of arms, specifically\n+    // for matching the current program counter with an instruction.\n+    // A wild-card arm is automatically added that executes a no-op. It will\n+    // never be used, but is added to satisfy the compiler complaining about\n+    // non-exhaustive patterns.\n+    fn match_insts(&self, mut arms: Vec<ast::Arm>) -> @ast::Expr {\n+        let mat_pc = quote_expr!(self.cx, pc);\n+        arms.push(self.wild_arm_expr(quote_expr!(self.cx, {})));\n+        self.dummy_expr(ast::ExprMatch(mat_pc, arms))\n+    }\n+\n+    // Creates a match arm for the instruction at `pc` with the expression\n+    // `body`.\n+    fn arm_inst(&self, pc: uint, body: @ast::Expr) -> ast::Arm {\n+        ast::Arm {\n+            attrs: vec!(),\n+            pats: vec!(@ast::Pat{\n+                id: ast::DUMMY_NODE_ID,\n+                span: self.sp,\n+                node: ast::PatLit(quote_expr!(self.cx, $pc)),\n+            }),\n+            guard: None,\n+            body: body,\n+        }\n+    }\n+\n+    // Creates a wild-card match arm with the expression `body`.\n+    fn wild_arm_expr(&self, body: @ast::Expr) -> ast::Arm {\n+        ast::Arm {\n+            attrs: vec!(),\n+            pats: vec!(@ast::Pat{\n+                id: ast::DUMMY_NODE_ID,\n+                span: self.sp,\n+                node: ast::PatWild,\n+            }),\n+            guard: None,\n+            body: body,\n+        }\n+    }\n+\n+    // Builds a `[a, b, .., len]` expression where each element is the result\n+    // of executing `to_expr`.\n+    fn vec_from_fn(&self, len: uint, to_expr: |&ExtCtxt| -> @ast::Expr)\n+                  -> @ast::Expr {\n+        self.vec_expr(Vec::from_elem(len, ()).as_slice(),\n+                      |cx, _| to_expr(cx))\n+    }\n+\n+    // Converts `xs` to a `[x1, x2, .., xN]` expression by calling `to_expr`\n+    // on each element in `xs`.\n+    fn vec_expr<T>(&self, xs: &[T], to_expr: |&ExtCtxt, &T| -> @ast::Expr)\n+                  -> @ast::Expr {\n+        let mut exprs = vec!();\n+        for x in xs.iter() {\n+            exprs.push(to_expr(self.cx, x))\n+        }\n+        let vec_exprs = self.dummy_expr(ast::ExprVec(exprs));\n+        quote_expr!(self.cx, $vec_exprs)\n+    }\n+\n+    // Creates an expression with a dummy node ID given an underlying\n+    // `ast::Expr_`.\n+    fn dummy_expr(&self, e: ast::Expr_) -> @ast::Expr {\n+        @ast::Expr {\n+            id: ast::DUMMY_NODE_ID,\n+            node: e,\n+            span: self.sp,\n+        }\n+    }\n+}\n+\n+// This trait is defined in the quote module in the syntax crate, but I\n+// don't think it's exported.\n+// Interestingly, quote_expr! only requires that a 'to_tokens' method be\n+// defined rather than satisfying a particular trait.\n+#[doc(hidden)]\n+trait ToTokens {\n+    fn to_tokens(&self, cx: &ExtCtxt) -> Vec<ast::TokenTree>;\n+}\n+\n+impl ToTokens for char {\n+    fn to_tokens(&self, _: &ExtCtxt) -> Vec<ast::TokenTree> {\n+        vec!(ast::TTTok(codemap::DUMMY_SP, token::LIT_CHAR((*self) as u32)))\n+    }\n+}\n+\n+impl ToTokens for bool {\n+    fn to_tokens(&self, _: &ExtCtxt) -> Vec<ast::TokenTree> {\n+        let ident = token::IDENT(token::str_to_ident(self.to_str()), false);\n+        vec!(ast::TTTok(codemap::DUMMY_SP, ident))\n+    }\n+}\n+\n+/// Looks for a single string literal and returns it.\n+/// Otherwise, logs an error with cx.span_err and returns None.\n+fn parse(cx: &mut ExtCtxt, tts: &[ast::TokenTree]) -> Option<~str> {\n+    let mut parser = parse::new_parser_from_tts(cx.parse_sess(), cx.cfg(),\n+                                                Vec::from_slice(tts));\n+    let entry = cx.expand_expr(parser.parse_expr());\n+    let regex = match entry.node {\n+        ast::ExprLit(lit) => {\n+            match lit.node {\n+                ast::LitStr(ref s, _) => s.to_str(),\n+                _ => {\n+                    cx.span_err(entry.span, format!(\n+                        \"expected string literal but got `{}`\",\n+                        pprust::lit_to_str(lit)));\n+                    return None\n+                }\n+            }\n+        }\n+        _ => {\n+            cx.span_err(entry.span, format!(\n+                \"expected string literal but got `{}`\",\n+                pprust::expr_to_str(entry)));\n+            return None\n+        }\n+    };\n+    if !parser.eat(&token::EOF) {\n+        cx.span_err(parser.span, \"only one string literal allowed\");\n+        return None;\n+    }\n+    Some(regex)\n+}"}, {"sha": "0f86b8043a02d8f1fd10c8149646caca97f66b9a", "filename": "src/test/bench/shootout-regex-dna.rs", "status": "added", "additions": 96, "deletions": 0, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Ftest%2Fbench%2Fshootout-regex-dna.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Ftest%2Fbench%2Fshootout-regex-dna.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-regex-dna.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,96 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// FIXME(#13725) windows needs fixing.\n+// ignore-win32\n+// ignore-stage1\n+// ignore-cross-compile #12102\n+\n+#![feature(macro_rules, phase)]\n+\n+extern crate regex;\n+#[phase(syntax)]extern crate regex_macros;\n+extern crate sync;\n+\n+use std::io;\n+use regex::{NoExpand, Regex};\n+use sync::Arc;\n+\n+fn count_matches(seq: &str, variant: &Regex) -> int {\n+    let mut n = 0;\n+    for _ in variant.find_iter(seq) {\n+        n += 1;\n+    }\n+    n\n+}\n+\n+fn main() {\n+    let mut rdr = if std::os::getenv(\"RUST_BENCH\").is_some() {\n+        let fd = io::File::open(&Path::new(\"shootout-k-nucleotide.data\"));\n+        ~io::BufferedReader::new(fd) as ~io::Reader\n+    } else {\n+        ~io::stdin() as ~io::Reader\n+    };\n+    let mut seq = StrBuf::from_str(rdr.read_to_str().unwrap());\n+    let ilen = seq.len();\n+\n+    seq = regex!(\">[^\\n]*\\n|\\n\").replace_all(seq.as_slice(), NoExpand(\"\"));\n+    let seq_arc = Arc::new(seq.clone()); // copy before it moves\n+    let clen = seq.len();\n+\n+    let mut seqlen = sync::Future::spawn(proc() {\n+        let substs = ~[\n+            (regex!(\"B\"), \"(c|g|t)\"),\n+            (regex!(\"D\"), \"(a|g|t)\"),\n+            (regex!(\"H\"), \"(a|c|t)\"),\n+            (regex!(\"K\"), \"(g|t)\"),\n+            (regex!(\"M\"), \"(a|c)\"),\n+            (regex!(\"N\"), \"(a|c|g|t)\"),\n+            (regex!(\"R\"), \"(a|g)\"),\n+            (regex!(\"S\"), \"(c|g)\"),\n+            (regex!(\"V\"), \"(a|c|g)\"),\n+            (regex!(\"W\"), \"(a|t)\"),\n+            (regex!(\"Y\"), \"(c|t)\"),\n+        ];\n+        let mut seq = seq;\n+        for (re, replacement) in substs.move_iter() {\n+            seq = re.replace_all(seq.as_slice(), NoExpand(replacement));\n+        }\n+        seq.len()\n+    });\n+\n+    let variants = ~[\n+        regex!(\"agggtaaa|tttaccct\"),\n+        regex!(\"[cgt]gggtaaa|tttaccc[acg]\"),\n+        regex!(\"a[act]ggtaaa|tttacc[agt]t\"),\n+        regex!(\"ag[act]gtaaa|tttac[agt]ct\"),\n+        regex!(\"agg[act]taaa|ttta[agt]cct\"),\n+        regex!(\"aggg[acg]aaa|ttt[cgt]ccct\"),\n+        regex!(\"agggt[cgt]aa|tt[acg]accct\"),\n+        regex!(\"agggta[cgt]a|t[acg]taccct\"),\n+        regex!(\"agggtaa[cgt]|[acg]ttaccct\"),\n+    ];\n+    let (mut variant_strs, mut counts) = (vec!(), vec!());\n+    for variant in variants.move_iter() {\n+        let seq_arc_copy = seq_arc.clone();\n+        variant_strs.push(variant.to_str().to_owned());\n+        counts.push(sync::Future::spawn(proc() {\n+            count_matches(seq_arc_copy.as_slice(), &variant)\n+        }));\n+    }\n+\n+    for (i, variant) in variant_strs.iter().enumerate() {\n+        println!(\"{} {}\", variant, counts.get_mut(i).get());\n+    }\n+    println!(\"\");\n+    println!(\"{}\", ilen);\n+    println!(\"{}\", clen);\n+    println!(\"{}\", seqlen.get());\n+}"}, {"sha": "0e072dc1c060b512cebddc1545015027409cdb25", "filename": "src/test/compile-fail/syntax-extension-regex-invalid.rs", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Ftest%2Fcompile-fail%2Fsyntax-extension-regex-invalid.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eea4909a8713a54b3c47e871a70baf6c722999a3/src%2Ftest%2Fcompile-fail%2Fsyntax-extension-regex-invalid.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fsyntax-extension-regex-invalid.rs?ref=eea4909a8713a54b3c47e871a70baf6c722999a3", "patch": "@@ -0,0 +1,28 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// FIXME(#13725) windows needs fixing.\n+// ignore-win32\n+// ignore-stage1\n+\n+#![feature(phase)]\n+\n+extern crate regex;\n+#[phase(syntax)] extern crate regex_macros;\n+\n+// Tests to make sure that `regex!` will produce a compile error when given\n+// an invalid regular expression.\n+// More exhaustive failure tests for the parser are done with the traditional\n+// unit testing infrastructure, since both dynamic and native regexes use the\n+// same parser.\n+\n+fn main() {\n+    let _ = regex!(\"(\"); //~ ERROR Regex syntax error\n+}"}]}