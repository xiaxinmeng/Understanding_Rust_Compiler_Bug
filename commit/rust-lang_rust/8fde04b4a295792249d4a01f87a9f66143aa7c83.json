{"sha": "8fde04b4a295792249d4a01f87a9f66143aa7c83", "node_id": "MDY6Q29tbWl0NzI0NzEyOjhmZGUwNGI0YTI5NTc5MjI0OWQ0YTAxZjg3YTlmNjYxNDNhYTdjODM=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-29T07:17:18Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-30T05:44:56Z"}, "message": "Improve `Path` spans.", "tree": {"sha": "c93bce71155b0f7375a24be25a2fbeb21360d806", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c93bce71155b0f7375a24be25a2fbeb21360d806"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8fde04b4a295792249d4a01f87a9f66143aa7c83", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8fde04b4a295792249d4a01f87a9f66143aa7c83", "html_url": "https://github.com/rust-lang/rust/commit/8fde04b4a295792249d4a01f87a9f66143aa7c83", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8fde04b4a295792249d4a01f87a9f66143aa7c83/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f08d5ad4c59ca5fc1c961a94c53807d70959c375", "url": "https://api.github.com/repos/rust-lang/rust/commits/f08d5ad4c59ca5fc1c961a94c53807d70959c375", "html_url": "https://github.com/rust-lang/rust/commit/f08d5ad4c59ca5fc1c961a94c53807d70959c375"}], "stats": {"total": 162, "additions": 95, "deletions": 67}, "files": [{"sha": "6f5f52ff1e953fa4b5798d90df7be07a434ddca3", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -1015,9 +1015,10 @@ impl MetaItem {\n     {\n         let (mut span, name) = match tokens.next() {\n             Some(TokenTree::Token(span, Token::Ident(ident))) => (span, ident.name),\n-            Some(TokenTree::Token(_, Token::Interpolated(ref nt))) => return match **nt {\n-                token::Nonterminal::NtMeta(ref meta) => Some(meta.clone()),\n-                _ => None,\n+            Some(TokenTree::Token(_, Token::Interpolated(ref nt))) => match **nt {\n+                token::Nonterminal::NtIdent(ident) => (ident.span, ident.node.name),\n+                token::Nonterminal::NtMeta(ref meta) => return Some(meta.clone()),\n+                _ => return None,\n             },\n             _ => return None,\n         };"}, {"sha": "fda026fec64ef3d1ebf3e7da501c5aa98b42bd0f", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 20, "deletions": 1, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -209,7 +209,26 @@ impl<F> TTMacroExpander for F\n {\n     fn expand<'cx>(&self, ecx: &'cx mut ExtCtxt, span: Span, input: TokenStream)\n                    -> Box<MacResult+'cx> {\n-        (*self)(ecx, span, &input.trees().collect::<Vec<_>>())\n+        struct AvoidInterpolatedIdents;\n+\n+        impl Folder for AvoidInterpolatedIdents {\n+            fn fold_tt(&mut self, tt: tokenstream::TokenTree) -> tokenstream::TokenTree {\n+                if let tokenstream::TokenTree::Token(_, token::Interpolated(ref nt)) = tt {\n+                    if let token::NtIdent(ident) = **nt {\n+                        return tokenstream::TokenTree::Token(ident.span, token::Ident(ident.node));\n+                    }\n+                }\n+                fold::noop_fold_tt(tt, self)\n+            }\n+\n+            fn fold_mac(&mut self, mac: ast::Mac) -> ast::Mac {\n+                fold::noop_fold_mac(mac, self)\n+            }\n+        }\n+\n+        let input: Vec<_> =\n+            input.trees().map(|tt| AvoidInterpolatedIdents.fold_tt(tt)).collect();\n+        (*self)(ecx, span, &input)\n     }\n }\n "}, {"sha": "6cd1fea2e75e2ccf8749c0f0afcef19b9c4ab030", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -492,7 +492,7 @@ fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         _ => {}\n     }\n     // check at the beginning and the parser checks after each bump\n-    p.check_unknown_macro_variable();\n+    p.process_potential_macro_variable();\n     match name {\n         \"item\" => match panictry!(p.parse_item()) {\n             Some(i) => token::NtItem(i),"}, {"sha": "93348c8f0837677faddbd7b437e17e63328536a4", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -121,7 +121,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                 p.root_module_name = cx.current_expansion.module.mod_path.last()\n                     .map(|id| id.name.as_str().to_string());\n \n-                p.check_unknown_macro_variable();\n+                p.process_potential_macro_variable();\n                 // Let the context choose how to interpret the result.\n                 // Weird, but useful for X-macros.\n                 return Box::new(ParserAnyMacro {"}, {"sha": "d216effbd450812502d4a1c675cb933474f6ab9c", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -136,11 +136,14 @@ pub fn parse(input: tokenstream::TokenStream, expect_matchers: bool, sess: &Pars\n             TokenTree::Token(start_sp, token::SubstNt(ident)) if expect_matchers => {\n                 let span = match trees.next() {\n                     Some(tokenstream::TokenTree::Token(span, token::Colon)) => match trees.next() {\n-                        Some(tokenstream::TokenTree::Token(end_sp, token::Ident(kind))) => {\n-                            let span = Span { lo: start_sp.lo, ..end_sp };\n-                            result.push(TokenTree::MetaVarDecl(span, ident, kind));\n-                            continue\n-                        }\n+                        Some(tokenstream::TokenTree::Token(end_sp, ref tok)) => match tok.ident() {\n+                            Some(kind) => {\n+                                let span = Span { lo: start_sp.lo, ..end_sp };\n+                                result.push(TokenTree::MetaVarDecl(span, ident, kind));\n+                                continue\n+                            }\n+                            _ => end_sp,\n+                        },\n                         tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n                     },\n                     tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(start_sp),"}, {"sha": "947089b0b9ac4b977686c26603f47b06664545f9", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 1, "deletions": 8, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -12,7 +12,7 @@ use ast::Ident;\n use errors::Handler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use ext::tt::quoted;\n-use parse::token::{self, SubstNt, Token, NtIdent, NtTT};\n+use parse::token::{self, SubstNt, Token, NtTT};\n use syntax_pos::{Span, DUMMY_SP};\n use tokenstream::{TokenStream, TokenTree, Delimited};\n use util::small_vector::SmallVector;\n@@ -154,13 +154,6 @@ pub fn transcribe(sp_diag: &Handler,\n                     None => result.push(TokenTree::Token(sp, SubstNt(ident)).into()),\n                     Some(cur_matched) => if let MatchedNonterminal(ref nt) = *cur_matched {\n                         match **nt {\n-                            // sidestep the interpolation tricks for ident because\n-                            // (a) idents can be in lots of places, so it'd be a pain\n-                            // (b) we actually can, since it's a token.\n-                            NtIdent(ref sn) => {\n-                                let token = TokenTree::Token(sn.span, token::Ident(sn.node));\n-                                result.push(token.into());\n-                            }\n                             NtTT(ref tt) => result.push(tt.clone().into()),\n                             _ => {\n                                 let token = TokenTree::Token(sp, token::Interpolated(nt.clone()));"}, {"sha": "c63a6524f7459e32e5154cbbb8278574f9715bbb", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -218,9 +218,7 @@ pub fn filemap_to_stream(sess: &ParseSess, filemap: Rc<FileMap>) -> TokenStream\n \n /// Given stream and the ParseSess, produce a parser\n pub fn stream_to_parser<'a>(sess: &'a ParseSess, stream: TokenStream) -> Parser<'a> {\n-    let mut p = Parser::new(sess, stream, None, false);\n-    p.check_unknown_macro_variable();\n-    p\n+    Parser::new(sess, stream, None, false)\n }\n \n /// Parse a string representing a character literal into its final form."}, {"sha": "db2878c6b1e729ed4d4f61b911b936cbe51cb8a3", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 35, "deletions": 21, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -160,6 +160,7 @@ pub struct Parser<'a> {\n     /// the span of the current token:\n     pub span: Span,\n     /// the span of the previous token:\n+    pub meta_var_span: Option<Span>,\n     pub prev_span: Span,\n     /// the previous token kind\n     prev_token_kind: PrevTokenKind,\n@@ -417,6 +418,7 @@ impl<'a> Parser<'a> {\n             token: token::Underscore,\n             span: syntax_pos::DUMMY_SP,\n             prev_span: syntax_pos::DUMMY_SP,\n+            meta_var_span: None,\n             prev_token_kind: PrevTokenKind::Other,\n             restrictions: Restrictions::empty(),\n             obsolete_set: HashSet::new(),\n@@ -443,6 +445,7 @@ impl<'a> Parser<'a> {\n             parser.directory.path = PathBuf::from(sess.codemap().span_to_filename(parser.span));\n             parser.directory.path.pop();\n         }\n+        parser.process_potential_macro_variable();\n         parser\n     }\n \n@@ -1012,7 +1015,7 @@ impl<'a> Parser<'a> {\n             self.bug(\"attempted to bump the parser past EOF (may be stuck in a loop)\");\n         }\n \n-        self.prev_span = self.span;\n+        self.prev_span = self.meta_var_span.take().unwrap_or(self.span);\n \n         // Record last token kind for possible error recovery.\n         self.prev_token_kind = match self.token {\n@@ -1028,7 +1031,7 @@ impl<'a> Parser<'a> {\n         self.token = next.tok;\n         self.expected_tokens.clear();\n         // check after each token\n-        self.check_unknown_macro_variable();\n+        self.process_potential_macro_variable();\n     }\n \n     /// Advance the parser using provided token as a next one. Use this when\n@@ -1722,7 +1725,7 @@ impl<'a> Parser<'a> {\n     pub fn parse_path(&mut self, mode: PathStyle) -> PResult<'a, ast::Path> {\n         maybe_whole!(self, NtPath, |x| x);\n \n-        let lo = self.span;\n+        let lo = self.meta_var_span.unwrap_or(self.span);\n         let is_global = self.eat(&token::ModSep);\n \n         // Parse any number of segments and bound sets. A segment is an\n@@ -1744,13 +1747,9 @@ impl<'a> Parser<'a> {\n             segments.insert(0, PathSegment::crate_root());\n         }\n \n-        // Assemble the span.\n-        // FIXME(#39450) This is bogus if part of the path is macro generated.\n-        let span = lo.to(self.prev_span);\n-\n         // Assemble the result.\n         Ok(ast::Path {\n-            span: span,\n+            span: lo.to(self.prev_span),\n             segments: segments,\n         })\n     }\n@@ -1763,8 +1762,8 @@ impl<'a> Parser<'a> {\n         let mut segments = Vec::new();\n         loop {\n             // First, parse an identifier.\n+            let ident_span = self.span;\n             let identifier = self.parse_path_segment_ident()?;\n-            let ident_span = self.prev_span;\n \n             if self.check(&token::ModSep) && self.look_ahead(1, |t| *t == token::Lt) {\n                 self.bump();\n@@ -1831,8 +1830,8 @@ impl<'a> Parser<'a> {\n         let mut segments = Vec::new();\n         loop {\n             // First, parse an identifier.\n+            let ident_span = self.span;\n             let identifier = self.parse_path_segment_ident()?;\n-            let ident_span = self.prev_span;\n \n             // If we do not see a `::`, stop.\n             if !self.eat(&token::ModSep) {\n@@ -1873,10 +1872,11 @@ impl<'a> Parser<'a> {\n         let mut segments = Vec::new();\n         loop {\n             // First, parse an identifier.\n+            let ident_span = self.span;\n             let identifier = self.parse_path_segment_ident()?;\n \n             // Assemble and push the result.\n-            segments.push(PathSegment::from_ident(identifier, self.prev_span));\n+            segments.push(PathSegment::from_ident(identifier, ident_span));\n \n             // If we do not see a `::` or see `::{`/`::*`, stop.\n             if !self.check(&token::ModSep) || self.is_import_coupler() {\n@@ -1896,8 +1896,9 @@ impl<'a> Parser<'a> {\n     fn expect_lifetime(&mut self) -> Lifetime {\n         match self.token {\n             token::Lifetime(ident) => {\n+                let ident_span = self.span;\n                 self.bump();\n-                Lifetime { name: ident.name, span: self.prev_span, id: ast::DUMMY_NODE_ID }\n+                Lifetime { name: ident.name, span: ident_span, id: ast::DUMMY_NODE_ID }\n             }\n             _ => self.span_bug(self.span, \"not a lifetime\")\n         }\n@@ -2568,10 +2569,23 @@ impl<'a> Parser<'a> {\n         return Ok(e);\n     }\n \n-    pub fn check_unknown_macro_variable(&mut self) {\n-        if let token::SubstNt(name) = self.token {\n-            self.fatal(&format!(\"unknown macro variable `{}`\", name)).emit()\n-        }\n+    pub fn process_potential_macro_variable(&mut self) {\n+        let ident = match self.token {\n+            token::SubstNt(name) => {\n+                self.fatal(&format!(\"unknown macro variable `{}`\", name)).emit();\n+                return\n+            }\n+            token::Interpolated(ref nt) => {\n+                self.meta_var_span = Some(self.span);\n+                match **nt {\n+                    token::NtIdent(ident) => ident,\n+                    _ => return,\n+                }\n+            }\n+            _ => return,\n+        };\n+        self.token = token::Ident(ident.node);\n+        self.span = ident.span;\n     }\n \n     /// parse a single token tree from the input.\n@@ -2589,9 +2603,9 @@ impl<'a> Parser<'a> {\n             },\n             token::CloseDelim(_) | token::Eof => unreachable!(),\n             _ => {\n-                let token = mem::replace(&mut self.token, token::Underscore);\n+                let (token, span) = (mem::replace(&mut self.token, token::Underscore), self.span);\n                 self.bump();\n-                TokenTree::Token(self.prev_span, token)\n+                TokenTree::Token(span, token)\n             }\n         }\n     }\n@@ -3489,9 +3503,9 @@ impl<'a> Parser<'a> {\n     fn parse_pat_ident(&mut self,\n                        binding_mode: ast::BindingMode)\n                        -> PResult<'a, PatKind> {\n+        let ident_span = self.span;\n         let ident = self.parse_ident()?;\n-        let prev_span = self.prev_span;\n-        let name = codemap::Spanned{span: prev_span, node: ident};\n+        let name = codemap::Spanned{span: ident_span, node: ident};\n         let sub = if self.eat(&token::At) {\n             Some(self.parse_pat()?)\n         } else {\n@@ -4364,7 +4378,7 @@ impl<'a> Parser<'a> {\n     fn parse_self_arg(&mut self) -> PResult<'a, Option<Arg>> {\n         let expect_ident = |this: &mut Self| match this.token {\n             // Preserve hygienic context.\n-            token::Ident(ident) => { this.bump(); codemap::respan(this.prev_span, ident) }\n+            token::Ident(ident) => { let sp = this.span; this.bump(); codemap::respan(sp, ident) }\n             _ => unreachable!()\n         };\n         let isolated_self = |this: &mut Self, n| {"}, {"sha": "74aa3984a9a42a1f2917c59d5f1e69b7d6260bed", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 24, "deletions": 24, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8fde04b4a295792249d4a01f87a9f66143aa7c83/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=8fde04b4a295792249d4a01f87a9f66143aa7c83", "patch": "@@ -211,9 +211,7 @@ impl Token {\n             ModSep                      => true, // global path\n             Pound                       => true, // expression attributes\n             Interpolated(ref nt) => match **nt {\n-                NtExpr(..) => true,\n-                NtBlock(..) => true,\n-                NtPath(..) => true,\n+                NtIdent(..) | NtExpr(..) | NtBlock(..) | NtPath(..) => true,\n                 _ => false,\n             },\n             _ => false,\n@@ -236,8 +234,7 @@ impl Token {\n             Lt | BinOp(Shl)             => true, // associated path\n             ModSep                      => true, // global path\n             Interpolated(ref nt) => match **nt {\n-                NtTy(..) => true,\n-                NtPath(..) => true,\n+                NtIdent(..) | NtTy(..) | NtPath(..) => true,\n                 _ => false,\n             },\n             _ => false,\n@@ -252,14 +249,22 @@ impl Token {\n         }\n     }\n \n-    /// Returns `true` if the token is an identifier.\n-    pub fn is_ident(&self) -> bool {\n+    pub fn ident(&self) -> Option<ast::Ident> {\n         match *self {\n-            Ident(..)   => true,\n-            _           => false,\n+            Ident(ident) => Some(ident),\n+            Interpolated(ref nt) => match **nt {\n+                NtIdent(ident) => Some(ident.node),\n+                _ => None,\n+            },\n+            _ => None,\n         }\n     }\n \n+    /// Returns `true` if the token is an identifier.\n+    pub fn is_ident(&self) -> bool {\n+        self.ident().is_some()\n+    }\n+\n     /// Returns `true` if the token is a documentation comment.\n     pub fn is_doc_comment(&self) -> bool {\n         match *self {\n@@ -311,18 +316,15 @@ impl Token {\n \n     /// Returns `true` if the token is a given keyword, `kw`.\n     pub fn is_keyword(&self, kw: keywords::Keyword) -> bool {\n-        match *self {\n-            Ident(id) => id.name == kw.name(),\n-            _ => false,\n-        }\n+        self.ident().map(|ident| ident.name == kw.name()).unwrap_or(false)\n     }\n \n     pub fn is_path_segment_keyword(&self) -> bool {\n-        match *self {\n-            Ident(id) => id.name == keywords::Super.name() ||\n-                         id.name == keywords::SelfValue.name() ||\n-                         id.name == keywords::SelfType.name(),\n-            _ => false,\n+        match self.ident() {\n+            Some(id) => id.name == keywords::Super.name() ||\n+                        id.name == keywords::SelfValue.name() ||\n+                        id.name == keywords::SelfType.name(),\n+            None => false,\n         }\n     }\n \n@@ -333,18 +335,16 @@ impl Token {\n \n     /// Returns `true` if the token is a strict keyword.\n     pub fn is_strict_keyword(&self) -> bool {\n-        match *self {\n-            Ident(id) => id.name >= keywords::As.name() &&\n-                         id.name <= keywords::While.name(),\n+        match self.ident() {\n+            Some(id) => id.name >= keywords::As.name() && id.name <= keywords::While.name(),\n             _ => false,\n         }\n     }\n \n     /// Returns `true` if the token is a keyword reserved for possible future use.\n     pub fn is_reserved_keyword(&self) -> bool {\n-        match *self {\n-            Ident(id) => id.name >= keywords::Abstract.name() &&\n-                         id.name <= keywords::Yield.name(),\n+        match self.ident() {\n+            Some(id) => id.name >= keywords::Abstract.name() && id.name <= keywords::Yield.name(),\n             _ => false,\n         }\n     }"}]}