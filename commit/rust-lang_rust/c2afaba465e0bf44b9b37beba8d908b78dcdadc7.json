{"sha": "c2afaba465e0bf44b9b37beba8d908b78dcdadc7", "node_id": "C_kwDOAAsO6NoAKGMyYWZhYmE0NjVlMGJmNDRiOWIzN2JlYmE4ZDkwOGI3OGRjZGFkYzc", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-04-06T16:29:32Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-04-06T16:29:32Z"}, "message": "Auto merge of #95669 - nnethercote:call-compute_locs-once-per-rule, r=petrochenkov\n\nCall `compute_locs` once per rule\n\nThis fixes the small regressions on `wg-grammar` and `hyper-0.14.18` seen in #95555.\n\nr? `@petrochenkov`", "tree": {"sha": "99189e16733cf8d8754ef7bb24e4c7f5fc961cbd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/99189e16733cf8d8754ef7bb24e4c7f5fc961cbd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c2afaba465e0bf44b9b37beba8d908b78dcdadc7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c2afaba465e0bf44b9b37beba8d908b78dcdadc7", "html_url": "https://github.com/rust-lang/rust/commit/c2afaba465e0bf44b9b37beba8d908b78dcdadc7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c2afaba465e0bf44b9b37beba8d908b78dcdadc7/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b6ab1fae73a14db17a59e81c532a2b8f048ac159", "url": "https://api.github.com/repos/rust-lang/rust/commits/b6ab1fae73a14db17a59e81c532a2b8f048ac159", "html_url": "https://github.com/rust-lang/rust/commit/b6ab1fae73a14db17a59e81c532a2b8f048ac159"}, {"sha": "238d9076fc6d868c6268918ead1a59941c6d6556", "url": "https://api.github.com/repos/rust-lang/rust/commits/238d9076fc6d868c6268918ead1a59941c6d6556", "html_url": "https://github.com/rust-lang/rust/commit/238d9076fc6d868c6268918ead1a59941c6d6556"}], "stats": {"total": 318, "additions": 169, "deletions": 149}, "files": [{"sha": "ffe8b10e6877a97c56c9eaf6766e28673158e9f7", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 135, "deletions": 132, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/c2afaba465e0bf44b9b37beba8d908b78dcdadc7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c2afaba465e0bf44b9b37beba8d908b78dcdadc7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=c2afaba465e0bf44b9b37beba8d908b78dcdadc7", "patch": "@@ -106,9 +106,9 @@ rustc_data_structures::static_assert_size!(NamedMatchVec, 48);\n ///\n /// This means a matcher can be represented by `&[MatcherLoc]`, and traversal mostly involves\n /// simply incrementing the current matcher position index by one.\n-enum MatcherLoc<'tt> {\n+pub(super) enum MatcherLoc {\n     Token {\n-        token: &'tt Token,\n+        token: Token,\n     },\n     Delimited,\n     Sequence {\n@@ -123,21 +123,93 @@ enum MatcherLoc<'tt> {\n         idx_first: usize,\n     },\n     SequenceSep {\n-        separator: &'tt Token,\n+        separator: Token,\n     },\n     SequenceKleeneOpAfterSep {\n         idx_first: usize,\n     },\n     MetaVarDecl {\n         span: Span,\n         bind: Ident,\n-        kind: NonterminalKind,\n+        kind: Option<NonterminalKind>,\n         next_metavar: usize,\n         seq_depth: usize,\n     },\n     Eof,\n }\n \n+pub(super) fn compute_locs(sess: &ParseSess, matcher: &[TokenTree]) -> Vec<MatcherLoc> {\n+    fn inner(\n+        sess: &ParseSess,\n+        tts: &[TokenTree],\n+        locs: &mut Vec<MatcherLoc>,\n+        next_metavar: &mut usize,\n+        seq_depth: usize,\n+    ) {\n+        for tt in tts {\n+            match tt {\n+                TokenTree::Token(token) => {\n+                    locs.push(MatcherLoc::Token { token: token.clone() });\n+                }\n+                TokenTree::Delimited(_, delimited) => {\n+                    locs.push(MatcherLoc::Delimited);\n+                    inner(sess, &delimited.all_tts, locs, next_metavar, seq_depth);\n+                }\n+                TokenTree::Sequence(_, seq) => {\n+                    // We can't determine `idx_first_after` and construct the final\n+                    // `MatcherLoc::Sequence` until after `inner()` is called and the sequence end\n+                    // pieces are processed. So we push a dummy value (`Eof` is cheapest to\n+                    // construct) now, and overwrite it with the proper value below.\n+                    let dummy = MatcherLoc::Eof;\n+                    locs.push(dummy);\n+\n+                    let next_metavar_orig = *next_metavar;\n+                    let op = seq.kleene.op;\n+                    let idx_first = locs.len();\n+                    let idx_seq = idx_first - 1;\n+                    inner(sess, &seq.tts, locs, next_metavar, seq_depth + 1);\n+\n+                    if let Some(separator) = &seq.separator {\n+                        locs.push(MatcherLoc::SequenceSep { separator: separator.clone() });\n+                        locs.push(MatcherLoc::SequenceKleeneOpAfterSep { idx_first });\n+                    } else {\n+                        locs.push(MatcherLoc::SequenceKleeneOpNoSep { op, idx_first });\n+                    }\n+\n+                    // Overwrite the dummy value pushed above with the proper value.\n+                    locs[idx_seq] = MatcherLoc::Sequence {\n+                        op,\n+                        num_metavar_decls: seq.num_captures,\n+                        idx_first_after: locs.len(),\n+                        next_metavar: next_metavar_orig,\n+                        seq_depth,\n+                    };\n+                }\n+                &TokenTree::MetaVarDecl(span, bind, kind) => {\n+                    locs.push(MatcherLoc::MetaVarDecl {\n+                        span,\n+                        bind,\n+                        kind,\n+                        next_metavar: *next_metavar,\n+                        seq_depth,\n+                    });\n+                    *next_metavar += 1;\n+                }\n+                TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n+            }\n+        }\n+    }\n+\n+    let mut locs = vec![];\n+    let mut next_metavar = 0;\n+    inner(sess, matcher, &mut locs, &mut next_metavar, /* seq_depth */ 0);\n+\n+    // A final entry is needed for eof.\n+    locs.push(MatcherLoc::Eof);\n+\n+    locs\n+}\n+\n /// A single matcher position, representing the state of matching.\n struct MatcherPos {\n     /// The index into `TtParser::locs`, which represents the \"dot\".\n@@ -298,12 +370,9 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n \n // Note: the vectors could be created and dropped within `parse_tt`, but to avoid excess\n // allocations we have a single vector fo each kind that is cleared and reused repeatedly.\n-pub struct TtParser<'tt> {\n+pub struct TtParser {\n     macro_name: Ident,\n \n-    /// The matcher of the current rule.\n-    locs: Vec<MatcherLoc<'tt>>,\n-\n     /// The set of current mps to be processed. This should be empty by the end of a successful\n     /// execution of `parse_tt_inner`.\n     cur_mps: Vec<MatcherPos>,\n@@ -320,111 +389,17 @@ pub struct TtParser<'tt> {\n     empty_matches: Lrc<NamedMatchVec>,\n }\n \n-impl<'tt> TtParser<'tt> {\n-    pub(super) fn new(macro_name: Ident) -> TtParser<'tt> {\n+impl TtParser {\n+    pub(super) fn new(macro_name: Ident) -> TtParser {\n         TtParser {\n             macro_name,\n-            locs: vec![],\n             cur_mps: vec![],\n             next_mps: vec![],\n             bb_mps: vec![],\n             empty_matches: Lrc::new(smallvec![]),\n         }\n     }\n \n-    /// Convert a `&[TokenTree]` to a `&[MatcherLoc]`. Note: this conversion happens every time the\n-    /// macro is called, which may be many times if there are many call sites or if it is\n-    /// recursive. This conversion is fairly cheap and the representation is sufficiently better\n-    /// for matching than `&[TokenTree]` that it's a clear performance win even with the overhead.\n-    /// But it might be possible to move the conversion outwards so it only occurs once per macro.\n-    fn compute_locs(\n-        &mut self,\n-        sess: &ParseSess,\n-        matcher: &'tt [TokenTree],\n-    ) -> Result<usize, (Span, String)> {\n-        fn inner<'tt>(\n-            sess: &ParseSess,\n-            tts: &'tt [TokenTree],\n-            locs: &mut Vec<MatcherLoc<'tt>>,\n-            next_metavar: &mut usize,\n-            seq_depth: usize,\n-        ) -> Result<(), (Span, String)> {\n-            for tt in tts {\n-                match tt {\n-                    TokenTree::Token(token) => {\n-                        locs.push(MatcherLoc::Token { token });\n-                    }\n-                    TokenTree::Delimited(_, delimited) => {\n-                        locs.push(MatcherLoc::Delimited);\n-                        inner(sess, &delimited.all_tts, locs, next_metavar, seq_depth)?;\n-                    }\n-                    TokenTree::Sequence(_, seq) => {\n-                        // We can't determine `idx_first_after` and construct the final\n-                        // `MatcherLoc::Sequence` until after `inner()` is called and the sequence\n-                        // end pieces are processed. So we push a dummy value (`Eof` is cheapest to\n-                        // construct) now, and overwrite it with the proper value below.\n-                        let dummy = MatcherLoc::Eof;\n-                        locs.push(dummy);\n-\n-                        let next_metavar_orig = *next_metavar;\n-                        let op = seq.kleene.op;\n-                        let idx_first = locs.len();\n-                        let idx_seq = idx_first - 1;\n-                        inner(sess, &seq.tts, locs, next_metavar, seq_depth + 1)?;\n-\n-                        if let Some(separator) = &seq.separator {\n-                            locs.push(MatcherLoc::SequenceSep { separator });\n-                            locs.push(MatcherLoc::SequenceKleeneOpAfterSep { idx_first });\n-                        } else {\n-                            locs.push(MatcherLoc::SequenceKleeneOpNoSep { op, idx_first });\n-                        }\n-\n-                        // Overwrite the dummy value pushed above with the proper value.\n-                        locs[idx_seq] = MatcherLoc::Sequence {\n-                            op,\n-                            num_metavar_decls: seq.num_captures,\n-                            idx_first_after: locs.len(),\n-                            next_metavar: next_metavar_orig,\n-                            seq_depth,\n-                        };\n-                    }\n-                    &TokenTree::MetaVarDecl(span, bind, kind) => {\n-                        if let Some(kind) = kind {\n-                            locs.push(MatcherLoc::MetaVarDecl {\n-                                span,\n-                                bind,\n-                                kind,\n-                                next_metavar: *next_metavar,\n-                                seq_depth,\n-                            });\n-                            *next_metavar += 1;\n-                        } else if sess\n-                            .missing_fragment_specifiers\n-                            .borrow_mut()\n-                            .remove(&span)\n-                            .is_some()\n-                        {\n-                            // E.g. `$e` instead of `$e:expr`.\n-                            return Err((span, \"missing fragment specifier\".to_string()));\n-                        }\n-                    }\n-                    TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n-                }\n-            }\n-            Ok(())\n-        }\n-\n-        self.locs.clear();\n-        let mut next_metavar = 0;\n-        inner(sess, matcher, &mut self.locs, &mut next_metavar, /* seq_depth */ 0)?;\n-\n-        // A final entry is needed for eof.\n-        self.locs.push(MatcherLoc::Eof);\n-\n-        // This is the number of metavar decls.\n-        Ok(next_metavar)\n-    }\n-\n     /// Process the matcher positions of `cur_mps` until it is empty. In the process, this will\n     /// produce more mps in `next_mps` and `bb_mps`.\n     ///\n@@ -434,15 +409,16 @@ impl<'tt> TtParser<'tt> {\n     /// track of through the mps generated.\n     fn parse_tt_inner(\n         &mut self,\n-        num_metavar_decls: usize,\n+        sess: &ParseSess,\n+        matcher: &[MatcherLoc],\n         token: &Token,\n     ) -> Option<NamedParseResult> {\n         // Matcher positions that would be valid if the macro invocation was over now. Only\n         // modified if `token == Eof`.\n         let mut eof_mps = EofMatcherPositions::None;\n \n         while let Some(mut mp) = self.cur_mps.pop() {\n-            match &self.locs[mp.idx] {\n+            match &matcher[mp.idx] {\n                 MatcherLoc::Token { token: t } => {\n                     // If it's a doc comment, we just ignore it and move on to the next tt in the\n                     // matcher. This is a bug, but #95267 showed that existing programs rely on\n@@ -532,17 +508,25 @@ impl<'tt> TtParser<'tt> {\n                     mp.idx = idx_first;\n                     self.cur_mps.push(mp);\n                 }\n-                MatcherLoc::MetaVarDecl { kind, .. } => {\n+                &MatcherLoc::MetaVarDecl { span, kind, .. } => {\n                     // Built-in nonterminals never start with these tokens, so we can eliminate\n                     // them from consideration. We use the span of the metavariable declaration\n                     // to determine any edition-specific matching behavior for non-terminals.\n-                    if Parser::nonterminal_may_begin_with(*kind, token) {\n-                        self.bb_mps.push(mp);\n+                    if let Some(kind) = kind {\n+                        if Parser::nonterminal_may_begin_with(kind, token) {\n+                            self.bb_mps.push(mp);\n+                        }\n+                    } else {\n+                        // Both this check and the one in `nameize` are necessary, surprisingly.\n+                        if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n+                            // E.g. `$e` instead of `$e:expr`.\n+                            return Some(Error(span, \"missing fragment specifier\".to_string()));\n+                        }\n                     }\n                 }\n                 MatcherLoc::Eof => {\n                     // We are past the matcher's end, and not in a sequence. Try to end things.\n-                    debug_assert_eq!(mp.idx, self.locs.len() - 1);\n+                    debug_assert_eq!(mp.idx, matcher.len() - 1);\n                     if *token == token::Eof {\n                         eof_mps = match eof_mps {\n                             EofMatcherPositions::None => EofMatcherPositions::One(mp),\n@@ -560,11 +544,10 @@ impl<'tt> TtParser<'tt> {\n         if *token == token::Eof {\n             Some(match eof_mps {\n                 EofMatcherPositions::One(mut eof_mp) => {\n-                    assert_eq!(eof_mp.matches.len(), num_metavar_decls);\n                     // Need to take ownership of the matches from within the `Lrc`.\n                     Lrc::make_mut(&mut eof_mp.matches);\n                     let matches = Lrc::try_unwrap(eof_mp.matches).unwrap().into_iter();\n-                    self.nameize(matches)\n+                    self.nameize(sess, matcher, matches)\n                 }\n                 EofMatcherPositions::Multiple => {\n                     Error(token.span, \"ambiguity: multiple successful parses\".to_string())\n@@ -586,13 +569,8 @@ impl<'tt> TtParser<'tt> {\n     pub(super) fn parse_tt(\n         &mut self,\n         parser: &mut Cow<'_, Parser<'_>>,\n-        matcher: &'tt [TokenTree],\n+        matcher: &[MatcherLoc],\n     ) -> NamedParseResult {\n-        let num_metavar_decls = match self.compute_locs(parser.sess, matcher) {\n-            Ok(num_metavar_decls) => num_metavar_decls,\n-            Err((span, msg)) => return Error(span, msg),\n-        };\n-\n         // A queue of possible matcher positions. We initialize it with the matcher position in\n         // which the \"dot\" is before the first token of the first token tree in `matcher`.\n         // `parse_tt_inner` then processes all of these possible matcher positions and produces\n@@ -607,7 +585,7 @@ impl<'tt> TtParser<'tt> {\n \n             // Process `cur_mps` until either we have finished the input or we need to get some\n             // parsing from the black-box parser done.\n-            if let Some(res) = self.parse_tt_inner(num_metavar_decls, &parser.token) {\n+            if let Some(res) = self.parse_tt_inner(&parser.sess, matcher, &parser.token) {\n                 return res;\n             }\n \n@@ -635,9 +613,13 @@ impl<'tt> TtParser<'tt> {\n                 (0, 1) => {\n                     // We need to call the black-box parser to get some nonterminal.\n                     let mut mp = self.bb_mps.pop().unwrap();\n-                    let loc = &self.locs[mp.idx];\n+                    let loc = &matcher[mp.idx];\n                     if let &MatcherLoc::MetaVarDecl {\n-                        span, kind, next_metavar, seq_depth, ..\n+                        span,\n+                        kind: Some(kind),\n+                        next_metavar,\n+                        seq_depth,\n+                        ..\n                     } = loc\n                     {\n                         // We use the span of the metavariable declaration to determine any\n@@ -669,20 +651,26 @@ impl<'tt> TtParser<'tt> {\n \n                 (_, _) => {\n                     // Too many possibilities!\n-                    return self.ambiguity_error(parser.token.span);\n+                    return self.ambiguity_error(matcher, parser.token.span);\n                 }\n             }\n \n             assert!(!self.cur_mps.is_empty());\n         }\n     }\n \n-    fn ambiguity_error(&self, token_span: rustc_span::Span) -> NamedParseResult {\n+    fn ambiguity_error(\n+        &self,\n+        matcher: &[MatcherLoc],\n+        token_span: rustc_span::Span,\n+    ) -> NamedParseResult {\n         let nts = self\n             .bb_mps\n             .iter()\n-            .map(|mp| match &self.locs[mp.idx] {\n-                MatcherLoc::MetaVarDecl { bind, kind, .. } => format!(\"{} ('{}')\", kind, bind),\n+            .map(|mp| match &matcher[mp.idx] {\n+                MatcherLoc::MetaVarDecl { bind, kind: Some(kind), .. } => {\n+                    format!(\"{} ('{}')\", kind, bind)\n+                }\n                 _ => unreachable!(),\n             })\n             .collect::<Vec<String>>()\n@@ -702,16 +690,31 @@ impl<'tt> TtParser<'tt> {\n         )\n     }\n \n-    fn nameize<I: Iterator<Item = NamedMatch>>(&self, mut res: I) -> NamedParseResult {\n+    fn nameize<I: Iterator<Item = NamedMatch>>(\n+        &self,\n+        sess: &ParseSess,\n+        matcher: &[MatcherLoc],\n+        mut res: I,\n+    ) -> NamedParseResult {\n         // Make that each metavar has _exactly one_ binding. If so, insert the binding into the\n         // `NamedParseResult`. Otherwise, it's an error.\n         let mut ret_val = FxHashMap::default();\n-        for loc in self.locs.iter() {\n-            if let &MatcherLoc::MetaVarDecl { span, bind, .. } = loc {\n-                match ret_val.entry(MacroRulesNormalizedIdent::new(bind)) {\n-                    Vacant(spot) => spot.insert(res.next().unwrap()),\n-                    Occupied(..) => return Error(span, format!(\"duplicated bind name: {}\", bind)),\n-                };\n+        for loc in matcher {\n+            if let &MatcherLoc::MetaVarDecl { span, bind, kind, .. } = loc {\n+                if kind.is_some() {\n+                    match ret_val.entry(MacroRulesNormalizedIdent::new(bind)) {\n+                        Vacant(spot) => spot.insert(res.next().unwrap()),\n+                        Occupied(..) => {\n+                            return Error(span, format!(\"duplicated bind name: {}\", bind));\n+                        }\n+                    };\n+                } else {\n+                    // Both this check and the one in `parse_tt_inner` are necessary, surprisingly.\n+                    if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n+                        // E.g. `$e` instead of `$e:expr`.\n+                        return Error(span, \"missing fragment specifier\".to_string());\n+                    }\n+                }\n             }\n         }\n         Success(ret_val)"}, {"sha": "5dc086ee9e603b763d54adfa33c20109f0c388b6", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 34, "deletions": 17, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/c2afaba465e0bf44b9b37beba8d908b78dcdadc7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c2afaba465e0bf44b9b37beba8d908b78dcdadc7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=c2afaba465e0bf44b9b37beba8d908b78dcdadc7", "patch": "@@ -4,7 +4,7 @@ use crate::expand::{ensure_complete_parse, parse_ast_fragment, AstFragment, AstF\n use crate::mbe;\n use crate::mbe::macro_check;\n use crate::mbe::macro_parser::{Error, ErrorReported, Failure, Success, TtParser};\n-use crate::mbe::macro_parser::{MatchedSeq, MatchedTokenTree};\n+use crate::mbe::macro_parser::{MatchedSeq, MatchedTokenTree, MatcherLoc};\n use crate::mbe::transcribe::transcribe;\n \n use rustc_ast as ast;\n@@ -160,7 +160,7 @@ struct MacroRulesMacroExpander {\n     name: Ident,\n     span: Span,\n     transparency: Transparency,\n-    lhses: Vec<mbe::TokenTree>,\n+    lhses: Vec<Vec<MatcherLoc>>,\n     rhses: Vec<mbe::TokenTree>,\n     valid: bool,\n     is_local: bool,\n@@ -211,7 +211,7 @@ fn generic_extension<'cx, 'tt>(\n     name: Ident,\n     transparency: Transparency,\n     arg: TokenStream,\n-    lhses: &'tt [mbe::TokenTree],\n+    lhses: &'tt [Vec<MatcherLoc>],\n     rhses: &'tt [mbe::TokenTree],\n     is_local: bool,\n ) -> Box<dyn MacResult + 'cx> {\n@@ -246,14 +246,6 @@ fn generic_extension<'cx, 'tt>(\n     // this situation.)\n     let parser = parser_from_cx(sess, arg.clone());\n \n-    // A matcher is always delimited, but the delimiters are ignored.\n-    let delimited_inner_tts = |tt: &'tt mbe::TokenTree| -> &'tt [mbe::TokenTree] {\n-        match tt {\n-            mbe::TokenTree::Delimited(_, delimited) => delimited.inner_tts(),\n-            _ => cx.span_bug(sp, \"malformed macro lhs\"),\n-        }\n-    };\n-\n     // Try each arm's matchers.\n     let mut tt_parser = TtParser::new(name);\n     for (i, lhs) in lhses.iter().enumerate() {\n@@ -263,13 +255,19 @@ fn generic_extension<'cx, 'tt>(\n         // are not recorded. On the first `Success(..)`ful matcher, the spans are merged.\n         let mut gated_spans_snapshot = mem::take(&mut *sess.gated_spans.spans.borrow_mut());\n \n-        match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), delimited_inner_tts(lhs)) {\n+        match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs) {\n             Success(named_matches) => {\n                 // The matcher was `Success(..)`ful.\n                 // Merge the gated spans from parsing the matcher with the pre-existing ones.\n                 sess.gated_spans.merge(gated_spans_snapshot);\n \n-                let rhs = delimited_inner_tts(&rhses[i]).to_vec().clone();\n+                // Ignore the delimiters on the RHS.\n+                let rhs = match &rhses[i] {\n+                    mbe::TokenTree::Delimited(_, delimited) => {\n+                        delimited.inner_tts().to_vec().clone()\n+                    }\n+                    _ => cx.span_bug(sp, \"malformed macro rhs\"),\n+                };\n                 let arm_span = rhses[i].span();\n \n                 let rhs_spans = rhs.iter().map(|t| t.span()).collect::<Vec<_>>();\n@@ -347,10 +345,8 @@ fn generic_extension<'cx, 'tt>(\n     // Check whether there's a missing comma in this macro call, like `println!(\"{}\" a);`\n     if let Some((arg, comma_span)) = arg.add_comma() {\n         for lhs in lhses {\n-            if let Success(_) = tt_parser.parse_tt(\n-                &mut Cow::Borrowed(&parser_from_cx(sess, arg.clone())),\n-                delimited_inner_tts(lhs),\n-            ) {\n+            let parser = parser_from_cx(sess, arg.clone());\n+            if let Success(_) = tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs) {\n                 if comma_span.is_dummy() {\n                     err.note(\"you might be missing a comma\");\n                 } else {\n@@ -441,6 +437,8 @@ pub fn compile_declarative_macro(\n             }),\n         ),\n     ];\n+    // Convert it into `MatcherLoc` form.\n+    let argument_gram = mbe::macro_parser::compute_locs(&sess.parse_sess, &argument_gram);\n \n     let parser = Parser::new(&sess.parse_sess, body, true, rustc_parse::MACRO_ARGUMENTS);\n     let mut tt_parser = TtParser::new(def.ident);\n@@ -537,6 +535,25 @@ pub fn compile_declarative_macro(\n         None => {}\n     }\n \n+    // Convert the lhses into `MatcherLoc` form, which is better for doing the\n+    // actual matching. Unless the matcher is invalid.\n+    let lhses = if valid {\n+        lhses\n+            .iter()\n+            .map(|lhs| {\n+                // Ignore the delimiters around the matcher.\n+                match lhs {\n+                    mbe::TokenTree::Delimited(_, delimited) => {\n+                        mbe::macro_parser::compute_locs(&sess.parse_sess, delimited.inner_tts())\n+                    }\n+                    _ => sess.parse_sess.span_diagnostic.span_bug(def.span, \"malformed macro lhs\"),\n+                }\n+            })\n+            .collect()\n+    } else {\n+        vec![]\n+    };\n+\n     mk_syn_ext(Box::new(MacroRulesMacroExpander {\n         name: def.ident,\n         span: def.span,"}]}