{"sha": "286dc37d1bd30ecd419e889c7f3888575deac5fc", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI4NmRjMzdkMWJkMzBlY2Q0MTllODg5YzdmMzg4ODU3NWRlYWM1ZmM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-12-10T03:33:17Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-12-10T03:33:17Z"}, "message": "Auto merge of #56369 - nnethercote:rm-Delimited, r=petrochenkov\n\nRemove `tokenstream::Delimited`.\n\nBecause it's an extra type layer that doesn't really help; in a couple\nof places it actively gets in the way, and overall removing it makes the\ncode nicer. It does, however, move `tokenstream::TokenTree` further away\nfrom the `TokenTree` in `quote.rs`.\n\nMore importantly, this change reduces the size of `TokenStream` from 48\nbytes to 40 bytes on x86-64, which is enough to slightly reduce\ninstruction counts on numerous benchmarks, the best by 1.5%.\n\nNote that `open_tt` and `close_tt` have gone from being methods on\n`Delimited` to associated methods of `TokenTree`.", "tree": {"sha": "c74b9aef95c350e3fecba10d7e679d35c64312b7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c74b9aef95c350e3fecba10d7e679d35c64312b7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/286dc37d1bd30ecd419e889c7f3888575deac5fc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/286dc37d1bd30ecd419e889c7f3888575deac5fc", "html_url": "https://github.com/rust-lang/rust/commit/286dc37d1bd30ecd419e889c7f3888575deac5fc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/286dc37d1bd30ecd419e889c7f3888575deac5fc/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e2c329c72c3d764423c3909c7483cf2fd6659626", "url": "https://api.github.com/repos/rust-lang/rust/commits/e2c329c72c3d764423c3909c7483cf2fd6659626", "html_url": "https://github.com/rust-lang/rust/commit/e2c329c72c3d764423c3909c7483cf2fd6659626"}, {"sha": "1fe2c0324006165b0c39ece0ccd7509e19583054", "url": "https://api.github.com/repos/rust-lang/rust/commits/1fe2c0324006165b0c39ece0ccd7509e19583054", "html_url": "https://github.com/rust-lang/rust/commit/1fe2c0324006165b0c39ece0ccd7509e19583054"}], "stats": {"total": 385, "additions": 182, "deletions": 203}, "files": [{"sha": "6958801d865bfe3c8a3ca64299f0ed8c6be9ace4", "filename": "src/librustc/hir/lowering.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibrustc%2Fhir%2Flowering.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibrustc%2Fhir%2Flowering.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Flowering.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -72,7 +72,7 @@ use syntax::ptr::P;\n use syntax::source_map::{self, respan, CompilerDesugaringKind, Spanned};\n use syntax::std_inject;\n use syntax::symbol::{keywords, Symbol};\n-use syntax::tokenstream::{Delimited, TokenStream, TokenTree};\n+use syntax::tokenstream::{TokenStream, TokenTree};\n use syntax::parse::token::Token;\n use syntax::visit::{self, Visitor};\n use syntax_pos::{Span, MultiSpan};\n@@ -1088,12 +1088,10 @@ impl<'a> LoweringContext<'a> {\n     fn lower_token_tree(&mut self, tree: TokenTree) -> TokenStream {\n         match tree {\n             TokenTree::Token(span, token) => self.lower_token(token, span),\n-            TokenTree::Delimited(span, delimited) => TokenTree::Delimited(\n+            TokenTree::Delimited(span, delim, tts) => TokenTree::Delimited(\n                 span,\n-                Delimited {\n-                    delim: delimited.delim,\n-                    tts: self.lower_token_stream(delimited.tts.into()).into(),\n-                },\n+                delim,\n+                self.lower_token_stream(tts.into()).into(),\n             ).into(),\n         }\n     }"}, {"sha": "3211937d3ddc712b1e7f5eac06282ec996a01ccd", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -265,10 +265,10 @@ for tokenstream::TokenTree {\n                 span.hash_stable(hcx, hasher);\n                 hash_token(token, hcx, hasher);\n             }\n-            tokenstream::TokenTree::Delimited(span, ref delimited) => {\n+            tokenstream::TokenTree::Delimited(span, delim, ref tts) => {\n                 span.hash_stable(hcx, hasher);\n-                std_hash::Hash::hash(&delimited.delim, hasher);\n-                for sub_tt in delimited.stream().trees() {\n+                std_hash::Hash::hash(&delim, hasher);\n+                for sub_tt in tts.stream().trees() {\n                     sub_tt.hash_stable(hcx, hasher);\n                 }\n             }"}, {"sha": "7dd5d3c1cbc4c7034729bf2ead881daf40992212", "filename": "src/librustc_lint/builtin.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibrustc_lint%2Fbuiltin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibrustc_lint%2Fbuiltin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lint%2Fbuiltin.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -1540,8 +1540,8 @@ impl KeywordIdents {\n                     }\n                     _ => {},\n                 }\n-                TokenTree::Delimited(_, ref delim) => {\n-                    self.check_tokens(cx, delim.tts.clone().into())\n+                TokenTree::Delimited(_, _, tts) => {\n+                    self.check_tokens(cx, tts.stream())\n                 },\n             }\n         }"}, {"sha": "0792b2dc49c27f0396831b94ebbdfe082db0937e", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -1235,7 +1235,7 @@ pub enum MacDelimiter {\n \n impl Mac_ {\n     pub fn stream(&self) -> TokenStream {\n-        self.tts.clone().into()\n+        self.tts.stream()\n     }\n }\n "}, {"sha": "7723c15a266f197ea3ce411f440bbb3af63091fc", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -34,7 +34,7 @@ use parse::token::{self, Token};\n use ptr::P;\n use symbol::Symbol;\n use ThinVec;\n-use tokenstream::{TokenStream, TokenTree, Delimited, DelimSpan};\n+use tokenstream::{TokenStream, TokenTree, DelimSpan};\n use GLOBALS;\n \n use std::iter;\n@@ -549,10 +549,11 @@ impl MetaItemKind {\n                     }\n                     tokens.push(item.node.tokens());\n                 }\n-                TokenTree::Delimited(DelimSpan::from_single(span), Delimited {\n-                    delim: token::Paren,\n-                    tts: TokenStream::concat(tokens).into(),\n-                }).into()\n+                TokenTree::Delimited(\n+                    DelimSpan::from_single(span),\n+                    token::Paren,\n+                    TokenStream::concat(tokens).into(),\n+                ).into()\n             }\n         }\n     }\n@@ -570,9 +571,9 @@ impl MetaItemKind {\n                     None\n                 };\n             }\n-            Some(TokenTree::Delimited(_, ref delimited)) if delimited.delim == token::Paren => {\n+            Some(TokenTree::Delimited(_, delim, ref tts)) if delim == token::Paren => {\n                 tokens.next();\n-                delimited.stream()\n+                tts.stream()\n             }\n             _ => return Some(MetaItemKind::Word),\n         };"}, {"sha": "f4e9a7e409359aa5000886970332defd81c71f02", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -622,9 +622,9 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n     fn extract_proc_macro_attr_input(&self, tokens: TokenStream, span: Span) -> TokenStream {\n         let mut trees = tokens.trees();\n         match trees.next() {\n-            Some(TokenTree::Delimited(_, delim)) => {\n+            Some(TokenTree::Delimited(_, _, tts)) => {\n                 if trees.next().is_none() {\n-                    return delim.tts.into()\n+                    return tts.into()\n                 }\n             }\n             Some(TokenTree::Token(..)) => {}"}, {"sha": "c3497a17806b1797ed86b02801331852b8ab9633", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 15, "deletions": 17, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -36,7 +36,7 @@ pub mod rt {\n     use symbol::Symbol;\n     use ThinVec;\n \n-    use tokenstream::{self, DelimSpan, TokenTree, TokenStream};\n+    use tokenstream::{DelimSpan, TokenTree, TokenStream};\n \n     pub use parse::new_parser_from_tts;\n     pub use syntax_pos::{BytePos, Span, DUMMY_SP, FileName};\n@@ -246,9 +246,9 @@ pub mod rt {\n             inner.push(self.tokens.clone());\n \n             let delim_span = DelimSpan::from_single(self.span);\n-            r.push(TokenTree::Delimited(delim_span, tokenstream::Delimited {\n-                delim: token::Bracket, tts: TokenStream::concat(inner).into()\n-            }));\n+            r.push(TokenTree::Delimited(\n+                delim_span, token::Bracket, TokenStream::concat(inner).into()\n+            ));\n             r\n         }\n     }\n@@ -262,10 +262,9 @@ pub mod rt {\n \n     impl ToTokens for () {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Delimited(DelimSpan::dummy(), tokenstream::Delimited {\n-                delim: token::Paren,\n-                tts: TokenStream::empty().into(),\n-            })]\n+            vec![\n+                TokenTree::Delimited(DelimSpan::dummy(), token::Paren, TokenStream::empty().into())\n+            ]\n         }\n     }\n \n@@ -382,8 +381,6 @@ pub mod rt {\n \n // Replaces `Token::OpenDelim .. Token::CloseDelim` with `TokenTree::Delimited(..)`.\n pub fn unflatten(tts: Vec<TokenTree>) -> Vec<TokenTree> {\n-    use tokenstream::Delimited;\n-\n     let mut results = Vec::new();\n     let mut result = Vec::new();\n     let mut open_span = DUMMY_SP;\n@@ -395,10 +392,11 @@ pub fn unflatten(tts: Vec<TokenTree>) -> Vec<TokenTree> {\n             }\n             TokenTree::Token(span, token::CloseDelim(delim)) => {\n                 let delim_span = DelimSpan::from_pair(open_span, span);\n-                let tree = TokenTree::Delimited(delim_span, Delimited {\n+                let tree = TokenTree::Delimited(\n+                    delim_span,\n                     delim,\n-                    tts: result.into_iter().map(TokenStream::from).collect::<TokenStream>().into(),\n-                });\n+                    result.into_iter().map(TokenStream::from).collect::<TokenStream>().into(),\n+                );\n                 result = results.pop().unwrap();\n                 result.push(tree);\n             }\n@@ -758,10 +756,10 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, quoted: bool) -> Vec<ast::Stmt\n                                     vec![e_tok]);\n             vec![cx.stmt_expr(e_push)]\n         },\n-        TokenTree::Delimited(span, ref delimed) => {\n-            let mut stmts = statements_mk_tt(cx, &delimed.open_tt(span.open), false);\n-            stmts.extend(statements_mk_tts(cx, delimed.stream()));\n-            stmts.extend(statements_mk_tt(cx, &delimed.close_tt(span.close), false));\n+        TokenTree::Delimited(span, delim, ref tts) => {\n+            let mut stmts = statements_mk_tt(cx, &TokenTree::open_tt(span.open, delim), false);\n+            stmts.extend(statements_mk_tts(cx, tts.stream()));\n+            stmts.extend(statements_mk_tt(cx, &TokenTree::close_tt(span.close, delim), false));\n             stmts\n         }\n     }"}, {"sha": "b142f09cdbc74f61c2e05b25929a12e4733c9321", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -280,17 +280,17 @@ where\n         // `tree` is a `$` token. Look at the next token in `trees`\n         tokenstream::TokenTree::Token(span, token::Dollar) => match trees.next() {\n             // `tree` is followed by a delimited set of token trees. This indicates the beginning\n-            // of a repetition sequence in the macro (e.g., `$(pat)*`).\n-            Some(tokenstream::TokenTree::Delimited(span, delimited)) => {\n+            // of a repetition sequence in the macro (e.g. `$(pat)*`).\n+            Some(tokenstream::TokenTree::Delimited(span, delim, tts)) => {\n                 // Must have `(` not `{` or `[`\n-                if delimited.delim != token::Paren {\n-                    let tok = pprust::token_to_string(&token::OpenDelim(delimited.delim));\n+                if delim != token::Paren {\n+                    let tok = pprust::token_to_string(&token::OpenDelim(delim));\n                     let msg = format!(\"expected `(`, found `{}`\", tok);\n                     sess.span_diagnostic.span_err(span.entire(), &msg);\n                 }\n                 // Parse the contents of the sequence itself\n                 let sequence = parse(\n-                    delimited.tts.into(),\n+                    tts.into(),\n                     expect_matchers,\n                     sess,\n                     features,\n@@ -354,12 +354,12 @@ where\n \n         // `tree` is the beginning of a delimited set of tokens (e.g., `(` or `{`). We need to\n         // descend into the delimited set and further parse it.\n-        tokenstream::TokenTree::Delimited(span, delimited) => TokenTree::Delimited(\n+        tokenstream::TokenTree::Delimited(span, delim, tts) => TokenTree::Delimited(\n             span,\n             Lrc::new(Delimited {\n-                delim: delimited.delim,\n+                delim: delim,\n                 tts: parse(\n-                    delimited.tts.into(),\n+                    tts.into(),\n                     expect_matchers,\n                     sess,\n                     features,"}, {"sha": "a76779ffebdc003dd39f420920527220f0e59705", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -17,7 +17,7 @@ use fold::noop_fold_tt;\n use parse::token::{self, Token, NtTT};\n use smallvec::SmallVec;\n use syntax_pos::DUMMY_SP;\n-use tokenstream::{TokenStream, TokenTree, Delimited, DelimSpan};\n+use tokenstream::{TokenStream, TokenTree, DelimSpan};\n \n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lrc;\n@@ -105,10 +105,11 @@ pub fn transcribe(cx: &ExtCtxt,\n                     if result_stack.is_empty() {\n                         return TokenStream::concat(result);\n                     }\n-                    let tree = TokenTree::Delimited(span, Delimited {\n-                        delim: forest.delim,\n-                        tts: TokenStream::concat(result).into(),\n-                    });\n+                    let tree = TokenTree::Delimited(\n+                        span,\n+                        forest.delim,\n+                        TokenStream::concat(result).into(),\n+                    );\n                     result = result_stack.pop().unwrap();\n                     result.push(tree.into());\n                 }"}, {"sha": "ecb0245263853d62470773dd53de862fcec974fd", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -605,12 +605,10 @@ pub fn noop_fold_tt<T: Folder>(tt: TokenTree, fld: &mut T) -> TokenTree {\n     match tt {\n         TokenTree::Token(span, tok) =>\n             TokenTree::Token(fld.new_span(span), fld.fold_token(tok)),\n-        TokenTree::Delimited(span, delimed) => TokenTree::Delimited(\n+        TokenTree::Delimited(span, delim, tts) => TokenTree::Delimited(\n             DelimSpan::from_pair(fld.new_span(span.open), fld.new_span(span.close)),\n-            Delimited {\n-                tts: fld.fold_tts(delimed.stream()).into(),\n-                delim: delimed.delim,\n-            }\n+            delim,\n+            fld.fold_tts(tts.stream()).into(),\n         ),\n     }\n }"}, {"sha": "86c87cf898d09615eabcf1c990e6f508648aa98f", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -11,7 +11,7 @@\n use print::pprust::token_to_string;\n use parse::lexer::StringReader;\n use parse::{token, PResult};\n-use tokenstream::{Delimited, DelimSpan, TokenStream, TokenTree};\n+use tokenstream::{DelimSpan, TokenStream, TokenTree};\n \n impl<'a> StringReader<'a> {\n     // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n@@ -155,10 +155,11 @@ impl<'a> StringReader<'a> {\n                     _ => {}\n                 }\n \n-                Ok(TokenTree::Delimited(delim_span, Delimited {\n+                Ok(TokenTree::Delimited(\n+                    delim_span,\n                     delim,\n-                    tts: tts.into(),\n-                }).into())\n+                    tts.into(),\n+                ).into())\n             },\n             token::CloseDelim(_) => {\n                 // An unexpected closing delimiter (i.e., there is no"}, {"sha": "eb71003d3d0cfbf27f90dc992e6a1a41d520f7c5", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 29, "deletions": 32, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -764,7 +764,7 @@ mod tests {\n     use attr::first_attr_value_str_by_name;\n     use parse;\n     use print::pprust::item_to_string;\n-    use tokenstream::{self, DelimSpan, TokenTree};\n+    use tokenstream::{DelimSpan, TokenTree};\n     use util::parser_testing::string_to_stream;\n     use util::parser_testing::{string_to_expr, string_to_item};\n     use with_globals;\n@@ -795,42 +795,41 @@ mod tests {\n                     Some(&TokenTree::Token(_, token::Ident(name_macro_rules, false))),\n                     Some(&TokenTree::Token(_, token::Not)),\n                     Some(&TokenTree::Token(_, token::Ident(name_zip, false))),\n-                    Some(&TokenTree::Delimited(_, ref macro_delimed)),\n+                    Some(&TokenTree::Delimited(_, macro_delim, ref macro_tts)),\n                 )\n                 if name_macro_rules.name == \"macro_rules\"\n                 && name_zip.name == \"zip\" => {\n-                    let tts = &macro_delimed.stream().trees().collect::<Vec<_>>();\n+                    let tts = &macro_tts.stream().trees().collect::<Vec<_>>();\n                     match (tts.len(), tts.get(0), tts.get(1), tts.get(2)) {\n                         (\n                             3,\n-                            Some(&TokenTree::Delimited(_, ref first_delimed)),\n+                            Some(&TokenTree::Delimited(_, first_delim, ref first_tts)),\n                             Some(&TokenTree::Token(_, token::FatArrow)),\n-                            Some(&TokenTree::Delimited(_, ref second_delimed)),\n+                            Some(&TokenTree::Delimited(_, second_delim, ref second_tts)),\n                         )\n-                        if macro_delimed.delim == token::Paren => {\n-                            let tts = &first_delimed.stream().trees().collect::<Vec<_>>();\n+                        if macro_delim == token::Paren => {\n+                            let tts = &first_tts.stream().trees().collect::<Vec<_>>();\n                             match (tts.len(), tts.get(0), tts.get(1)) {\n                                 (\n                                     2,\n                                     Some(&TokenTree::Token(_, token::Dollar)),\n                                     Some(&TokenTree::Token(_, token::Ident(ident, false))),\n                                 )\n-                                if first_delimed.delim == token::Paren && ident.name == \"a\" => {},\n-                                _ => panic!(\"value 3: {:?}\", *first_delimed),\n+                                if first_delim == token::Paren && ident.name == \"a\" => {},\n+                                _ => panic!(\"value 3: {:?} {:?}\", first_delim, first_tts),\n                             }\n-                            let tts = &second_delimed.stream().trees().collect::<Vec<_>>();\n+                            let tts = &second_tts.stream().trees().collect::<Vec<_>>();\n                             match (tts.len(), tts.get(0), tts.get(1)) {\n                                 (\n                                     2,\n                                     Some(&TokenTree::Token(_, token::Dollar)),\n                                     Some(&TokenTree::Token(_, token::Ident(ident, false))),\n                                 )\n-                                if second_delimed.delim == token::Paren\n-                                && ident.name == \"a\" => {},\n-                                _ => panic!(\"value 4: {:?}\", *second_delimed),\n+                                if second_delim == token::Paren && ident.name == \"a\" => {},\n+                                _ => panic!(\"value 4: {:?} {:?}\", second_delim, second_tts),\n                             }\n                         },\n-                        _ => panic!(\"value 2: {:?}\", *macro_delimed),\n+                        _ => panic!(\"value 2: {:?} {:?}\", macro_delim, macro_tts),\n                     }\n                 },\n                 _ => panic!(\"value: {:?}\",tts),\n@@ -848,26 +847,24 @@ mod tests {\n                 TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"), false)).into(),\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(5, 6), sp(13, 14)),\n-                    tokenstream::Delimited {\n-                        delim: token::DelimToken::Paren,\n-                        tts: TokenStream::concat(vec![\n-                            TokenTree::Token(sp(6, 7),\n-                                             token::Ident(Ident::from_str(\"b\"), false)).into(),\n-                            TokenTree::Token(sp(8, 9), token::Colon).into(),\n-                            TokenTree::Token(sp(10, 13),\n-                                             token::Ident(Ident::from_str(\"i32\"), false)).into(),\n-                        ]).into(),\n-                    }).into(),\n+                    token::DelimToken::Paren,\n+                    TokenStream::concat(vec![\n+                        TokenTree::Token(sp(6, 7),\n+                                         token::Ident(Ident::from_str(\"b\"), false)).into(),\n+                        TokenTree::Token(sp(8, 9), token::Colon).into(),\n+                        TokenTree::Token(sp(10, 13),\n+                                         token::Ident(Ident::from_str(\"i32\"), false)).into(),\n+                    ]).into(),\n+                ).into(),\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(15, 16), sp(20, 21)),\n-                    tokenstream::Delimited {\n-                        delim: token::DelimToken::Brace,\n-                        tts: TokenStream::concat(vec![\n-                            TokenTree::Token(sp(17, 18),\n-                                             token::Ident(Ident::from_str(\"b\"), false)).into(),\n-                            TokenTree::Token(sp(18, 19), token::Semi).into(),\n-                        ]).into(),\n-                    }).into()\n+                    token::DelimToken::Brace,\n+                    TokenStream::concat(vec![\n+                        TokenTree::Token(sp(17, 18),\n+                                         token::Ident(Ident::from_str(\"b\"), false)).into(),\n+                        TokenTree::Token(sp(18, 19), token::Semi).into(),\n+                    ]).into(),\n+                ).into()\n             ]);\n \n             assert_eq!(tts, expected);"}, {"sha": "ded6da9f3adb8845e00a132e043b1731c613aba7", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 42, "deletions": 38, "changes": 80, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -48,13 +48,14 @@ use errors::{self, Applicability, DiagnosticBuilder, DiagnosticId};\n use parse::{self, SeqSep, classify, token};\n use parse::lexer::TokenAndSpan;\n use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n+use parse::token::DelimToken;\n use parse::{new_sub_parser_from_file, ParseSess, Directory, DirectoryOwnership};\n use util::parser::{AssocOp, Fixity};\n use print::pprust;\n use ptr::P;\n use parse::PResult;\n use ThinVec;\n-use tokenstream::{self, Delimited, DelimSpan, ThinTokenStream, TokenTree, TokenStream};\n+use tokenstream::{self, DelimSpan, ThinTokenStream, TokenTree, TokenStream};\n use symbol::{Symbol, keywords};\n \n use std::borrow::Cow;\n@@ -293,13 +294,13 @@ enum LastToken {\n }\n \n impl TokenCursorFrame {\n-    fn new(sp: DelimSpan, delimited: &Delimited) -> Self {\n+    fn new(sp: DelimSpan, delim: DelimToken, tts: &ThinTokenStream) -> Self {\n         TokenCursorFrame {\n-            delim: delimited.delim,\n+            delim: delim,\n             span: sp,\n-            open_delim: delimited.delim == token::NoDelim,\n-            tree_cursor: delimited.stream().into_trees(),\n-            close_delim: delimited.delim == token::NoDelim,\n+            open_delim: delim == token::NoDelim,\n+            tree_cursor: tts.stream().into_trees(),\n+            close_delim: delim == token::NoDelim,\n             last_token: LastToken::Was(None),\n         }\n     }\n@@ -310,14 +311,12 @@ impl TokenCursor {\n         loop {\n             let tree = if !self.frame.open_delim {\n                 self.frame.open_delim = true;\n-                Delimited { delim: self.frame.delim, tts: TokenStream::empty().into() }\n-                    .open_tt(self.frame.span.open)\n+                TokenTree::open_tt(self.frame.span.open, self.frame.delim)\n             } else if let Some(tree) = self.frame.tree_cursor.next() {\n                 tree\n             } else if !self.frame.close_delim {\n                 self.frame.close_delim = true;\n-                Delimited { delim: self.frame.delim, tts: TokenStream::empty().into() }\n-                    .close_tt(self.frame.span.close)\n+                TokenTree::close_tt(self.frame.span.close, self.frame.delim)\n             } else if let Some(frame) = self.stack.pop() {\n                 self.frame = frame;\n                 continue\n@@ -332,8 +331,8 @@ impl TokenCursor {\n \n             match tree {\n                 TokenTree::Token(sp, tok) => return TokenAndSpan { tok: tok, sp: sp },\n-                TokenTree::Delimited(sp, ref delimited) => {\n-                    let frame = TokenCursorFrame::new(sp, delimited);\n+                TokenTree::Delimited(sp, delim, tts) => {\n+                    let frame = TokenCursorFrame::new(sp, delim, &tts);\n                     self.stack.push(mem::replace(&mut self.frame, frame));\n                 }\n             }\n@@ -362,25 +361,28 @@ impl TokenCursor {\n         }\n \n         let delim_span = DelimSpan::from_single(sp);\n-        let body = TokenTree::Delimited(delim_span, Delimited {\n-            delim: token::Bracket,\n-            tts: [TokenTree::Token(sp, token::Ident(ast::Ident::from_str(\"doc\"), false)),\n-                  TokenTree::Token(sp, token::Eq),\n-                  TokenTree::Token(sp, token::Literal(\n-                      token::StrRaw(Symbol::intern(&stripped), num_of_hashes), None))]\n-                .iter().cloned().collect::<TokenStream>().into(),\n-        });\n+        let body = TokenTree::Delimited(\n+            delim_span,\n+            token::Bracket,\n+            [TokenTree::Token(sp, token::Ident(ast::Ident::from_str(\"doc\"), false)),\n+             TokenTree::Token(sp, token::Eq),\n+             TokenTree::Token(sp, token::Literal(\n+                token::StrRaw(Symbol::intern(&stripped), num_of_hashes), None))\n+            ]\n+            .iter().cloned().collect::<TokenStream>().into(),\n+        );\n \n-        self.stack.push(mem::replace(&mut self.frame, TokenCursorFrame::new(delim_span, &Delimited {\n-            delim: token::NoDelim,\n-            tts: if doc_comment_style(&name.as_str()) == AttrStyle::Inner {\n+        self.stack.push(mem::replace(&mut self.frame, TokenCursorFrame::new(\n+            delim_span,\n+            token::NoDelim,\n+            &if doc_comment_style(&name.as_str()) == AttrStyle::Inner {\n                 [TokenTree::Token(sp, token::Pound), TokenTree::Token(sp, token::Not), body]\n                     .iter().cloned().collect::<TokenStream>().into()\n             } else {\n                 [TokenTree::Token(sp, token::Pound), body]\n                     .iter().cloned().collect::<TokenStream>().into()\n             },\n-        })));\n+        )));\n \n         self.next()\n     }\n@@ -561,10 +563,11 @@ impl<'a> Parser<'a> {\n             root_module_name: None,\n             expected_tokens: Vec::new(),\n             token_cursor: TokenCursor {\n-                frame: TokenCursorFrame::new(DelimSpan::dummy(), &Delimited {\n-                    delim: token::NoDelim,\n-                    tts: tokens.into(),\n-                }),\n+                frame: TokenCursorFrame::new(\n+                    DelimSpan::dummy(),\n+                    token::NoDelim,\n+                    &tokens.into(),\n+                ),\n                 stack: Vec::new(),\n             },\n             desugar_doc_comments,\n@@ -1238,7 +1241,7 @@ impl<'a> Parser<'a> {\n         f(&match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n             Some(tree) => match tree {\n                 TokenTree::Token(_, tok) => tok,\n-                TokenTree::Delimited(_, delimited) => token::OpenDelim(delimited.delim),\n+                TokenTree::Delimited(_, delim, _) => token::OpenDelim(delim),\n             },\n             None => token::CloseDelim(self.token_cursor.frame.delim),\n         })\n@@ -1251,7 +1254,7 @@ impl<'a> Parser<'a> {\n \n         match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n             Some(TokenTree::Token(span, _)) => span,\n-            Some(TokenTree::Delimited(span, _)) => span.entire(),\n+            Some(TokenTree::Delimited(span, ..)) => span.entire(),\n             None => self.look_ahead_span(dist - 1),\n         }\n     }\n@@ -2317,8 +2320,8 @@ impl<'a> Parser<'a> {\n                 return Err(err)\n             }\n         };\n-        let delimited = match self.parse_token_tree() {\n-            TokenTree::Delimited(_, delimited) => delimited,\n+        let tts = match self.parse_token_tree() {\n+            TokenTree::Delimited(_, _, tts) => tts,\n             _ => unreachable!(),\n         };\n         let delim = match delim {\n@@ -2327,7 +2330,7 @@ impl<'a> Parser<'a> {\n             token::Brace => MacDelimiter::Brace,\n             token::NoDelim => self.bug(\"unexpected no delimiter\"),\n         };\n-        Ok((delim, delimited.stream().into()))\n+        Ok((delim, tts.stream().into()))\n     }\n \n     /// At the bottom (top?) of the precedence hierarchy,\n@@ -2892,10 +2895,11 @@ impl<'a> Parser<'a> {\n                                          self.token_cursor.stack.pop().unwrap());\n                 self.span = frame.span.entire();\n                 self.bump();\n-                TokenTree::Delimited(frame.span, Delimited {\n-                    delim: frame.delim,\n-                    tts: frame.tree_cursor.original_stream().into(),\n-                })\n+                TokenTree::Delimited(\n+                    frame.span,\n+                    frame.delim,\n+                    frame.tree_cursor.original_stream().into(),\n+                )\n             },\n             token::CloseDelim(_) | token::Eof => unreachable!(),\n             _ => {\n@@ -4609,7 +4613,7 @@ impl<'a> Parser<'a> {\n                 let ident = self.parse_ident()?;\n                 let tokens = if self.check(&token::OpenDelim(token::Brace)) {\n                     match self.parse_token_tree() {\n-                        TokenTree::Delimited(_, ref delimited) => delimited.stream(),\n+                        TokenTree::Delimited(_, _, tts) => tts.stream(),\n                         _ => unreachable!(),\n                     }\n                 } else if self.check(&token::OpenDelim(token::Paren)) {"}, {"sha": "8e4d3c0166bb271291178b099011cededc676b02", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -818,16 +818,13 @@ fn prepend_attrs(sess: &ParseSess,\n \n         brackets.push(attr.tokens.clone());\n \n-        let tokens = tokenstream::Delimited {\n-            delim: DelimToken::Bracket,\n-            tts: brackets.build().into(),\n-        };\n         // The span we list here for `#` and for `[ ... ]` are both wrong in\n         // that it encompasses more than each token, but it hopefully is \"good\n         // enough\" for now at least.\n         builder.push(tokenstream::TokenTree::Token(attr.span, Pound));\n         let delim_span = DelimSpan::from_single(attr.span);\n-        builder.push(tokenstream::TokenTree::Delimited(delim_span, tokens));\n+        builder.push(tokenstream::TokenTree::Delimited(\n+            delim_span, DelimToken::Bracket, brackets.build().into()));\n     }\n     builder.push(tokens.clone());\n     Some(builder.build())"}, {"sha": "41165c7e36d58414bebd5ee358bec038d6594280", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -815,12 +815,12 @@ pub trait PrintState<'a> {\n                     _ => Ok(())\n                 }\n             }\n-            TokenTree::Delimited(_, ref delimed) => {\n-                self.writer().word(token_to_string(&delimed.open_token()))?;\n+            TokenTree::Delimited(_, delim, tts) => {\n+                self.writer().word(token_to_string(&token::OpenDelim(delim)))?;\n                 self.writer().space()?;\n-                self.print_tts(delimed.stream())?;\n+                self.print_tts(tts.stream())?;\n                 self.writer().space()?;\n-                self.writer().word(token_to_string(&delimed.close_token()))\n+                self.writer().word(token_to_string(&token::CloseDelim(delim)))\n             },\n         }\n     }"}, {"sha": "90191c54126d112f396cb8ceb40f40f24c17bf0f", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 42, "deletions": 56, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -34,52 +34,6 @@ use util::RcVec;\n use std::borrow::Cow;\n use std::{fmt, iter, mem};\n \n-/// A delimited sequence of token trees\n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n-pub struct Delimited {\n-    /// The type of delimiter\n-    pub delim: DelimToken,\n-    /// The delimited sequence of token trees\n-    pub tts: ThinTokenStream,\n-}\n-\n-impl Delimited {\n-    /// Returns the opening delimiter as a token.\n-    pub fn open_token(&self) -> token::Token {\n-        token::OpenDelim(self.delim)\n-    }\n-\n-    /// Returns the closing delimiter as a token.\n-    pub fn close_token(&self) -> token::Token {\n-        token::CloseDelim(self.delim)\n-    }\n-\n-    /// Returns the opening delimiter as a token tree.\n-    pub fn open_tt(&self, span: Span) -> TokenTree {\n-        let open_span = if span.is_dummy() {\n-            span\n-        } else {\n-            span.with_hi(span.lo() + BytePos(self.delim.len() as u32))\n-        };\n-        TokenTree::Token(open_span, self.open_token())\n-    }\n-\n-    /// Returns the closing delimiter as a token tree.\n-    pub fn close_tt(&self, span: Span) -> TokenTree {\n-        let close_span = if span.is_dummy() {\n-            span\n-        } else {\n-            span.with_lo(span.hi() - BytePos(self.delim.len() as u32))\n-        };\n-        TokenTree::Token(close_span, self.close_token())\n-    }\n-\n-    /// Returns the token trees inside the delimiters.\n-    pub fn stream(&self) -> TokenStream {\n-        self.tts.clone().into()\n-    }\n-}\n-\n /// When the main rust parser encounters a syntax-extension invocation, it\n /// parses the arguments to the invocation as a token-tree. This is a very\n /// loose structure, such that all sorts of different AST-fragments can\n@@ -97,7 +51,7 @@ pub enum TokenTree {\n     /// A single token\n     Token(Span, token::Token),\n     /// A delimited sequence of token trees\n-    Delimited(DelimSpan, Delimited),\n+    Delimited(DelimSpan, DelimToken, ThinTokenStream),\n }\n \n impl TokenTree {\n@@ -116,9 +70,10 @@ impl TokenTree {\n     pub fn eq_unspanned(&self, other: &TokenTree) -> bool {\n         match (self, other) {\n             (&TokenTree::Token(_, ref tk), &TokenTree::Token(_, ref tk2)) => tk == tk2,\n-            (&TokenTree::Delimited(_, ref dl), &TokenTree::Delimited(_, ref dl2)) => {\n-                dl.delim == dl2.delim &&\n-                dl.stream().eq_unspanned(&dl2.stream())\n+            (&TokenTree::Delimited(_, delim, ref tts),\n+             &TokenTree::Delimited(_, delim2, ref tts2)) => {\n+                delim == delim2 &&\n+                tts.stream().eq_unspanned(&tts2.stream())\n             }\n             (_, _) => false,\n         }\n@@ -134,9 +89,10 @@ impl TokenTree {\n             (&TokenTree::Token(_, ref tk), &TokenTree::Token(_, ref tk2)) => {\n                 tk.probably_equal_for_proc_macro(tk2)\n             }\n-            (&TokenTree::Delimited(_, ref dl), &TokenTree::Delimited(_, ref dl2)) => {\n-                dl.delim == dl2.delim &&\n-                dl.stream().probably_equal_for_proc_macro(&dl2.stream())\n+            (&TokenTree::Delimited(_, delim, ref tts),\n+             &TokenTree::Delimited(_, delim2, ref tts2)) => {\n+                delim == delim2 &&\n+                tts.stream().probably_equal_for_proc_macro(&tts2.stream())\n             }\n             (_, _) => false,\n         }\n@@ -146,15 +102,15 @@ impl TokenTree {\n     pub fn span(&self) -> Span {\n         match *self {\n             TokenTree::Token(sp, _) => sp,\n-            TokenTree::Delimited(sp, _) => sp.entire(),\n+            TokenTree::Delimited(sp, ..) => sp.entire(),\n         }\n     }\n \n     /// Modify the `TokenTree`'s span in-place.\n     pub fn set_span(&mut self, span: Span) {\n         match *self {\n             TokenTree::Token(ref mut sp, _) => *sp = span,\n-            TokenTree::Delimited(ref mut sp, _) => *sp = DelimSpan::from_single(span),\n+            TokenTree::Delimited(ref mut sp, ..) => *sp = DelimSpan::from_single(span),\n         }\n     }\n \n@@ -169,6 +125,26 @@ impl TokenTree {\n     pub fn joint(self) -> TokenStream {\n         TokenStream { kind: TokenStreamKind::JointTree(self) }\n     }\n+\n+    /// Returns the opening delimiter as a token tree.\n+    pub fn open_tt(span: Span, delim: DelimToken) -> TokenTree {\n+        let open_span = if span.is_dummy() {\n+            span\n+        } else {\n+            span.with_hi(span.lo() + BytePos(delim.len() as u32))\n+        };\n+        TokenTree::Token(open_span, token::OpenDelim(delim))\n+    }\n+\n+    /// Returns the closing delimiter as a token tree.\n+    pub fn close_tt(span: Span, delim: DelimToken) -> TokenTree {\n+        let close_span = if span.is_dummy() {\n+            span\n+        } else {\n+            span.with_lo(span.hi() - BytePos(delim.len() as u32))\n+        };\n+        TokenTree::Token(close_span, token::CloseDelim(delim))\n+    }\n }\n \n /// # Token Streams\n@@ -182,6 +158,10 @@ pub struct TokenStream {\n     kind: TokenStreamKind,\n }\n \n+// `TokenStream` is used a lot. Make sure it doesn't unintentionally get bigger.\n+#[cfg(target_arch = \"x86_64\")]\n+static_assert!(MEM_SIZE_OF_TOKEN_STREAM: mem::size_of::<TokenStream>() == 40);\n+\n impl TokenStream {\n     /// Given a `TokenStream` with a `Stream` of only two arguments, return a new `TokenStream`\n     /// separating the two arguments with a comma for diagnostic suggestions.\n@@ -198,7 +178,7 @@ impl TokenStream {\n                             continue;\n                         }\n                         (TokenStreamKind::Tree(TokenTree::Token(sp, _)), _) => *sp,\n-                        (TokenStreamKind::Tree(TokenTree::Delimited(sp, _)), _) => sp.entire(),\n+                        (TokenStreamKind::Tree(TokenTree::Delimited(sp, ..)), _) => sp.entire(),\n                         _ => continue,\n                     };\n                     let sp = sp.shrink_to_hi();\n@@ -678,6 +658,12 @@ impl Cursor {\n #[derive(Debug, Clone)]\n pub struct ThinTokenStream(Option<RcVec<TokenStream>>);\n \n+impl ThinTokenStream {\n+    pub fn stream(&self) -> TokenStream {\n+        self.clone().into()\n+    }\n+}\n+\n impl From<TokenStream> for ThinTokenStream {\n     fn from(stream: TokenStream) -> ThinTokenStream {\n         ThinTokenStream(match stream.kind {"}, {"sha": "6747598f3753fcc59ab0db7ab776c37c50e0f4fc", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -841,7 +841,7 @@ pub fn walk_attribute<'a, V: Visitor<'a>>(visitor: &mut V, attr: &'a Attribute)\n pub fn walk_tt<'a, V: Visitor<'a>>(visitor: &mut V, tt: TokenTree) {\n     match tt {\n         TokenTree::Token(_, tok) => visitor.visit_token(tok),\n-        TokenTree::Delimited(_, delimed) => visitor.visit_tts(delimed.stream()),\n+        TokenTree::Delimited(_, _, tts) => visitor.visit_tts(tts.stream()),\n     }\n }\n "}, {"sha": "a04d6c92b7817d7f6174c77f467cdb3d53cc025d", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/286dc37d1bd30ecd419e889c7f3888575deac5fc/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=286dc37d1bd30ecd419e889c7f3888575deac5fc", "patch": "@@ -64,11 +64,11 @@ impl FromInternal<(TokenStream, &'_ ParseSess, &'_ mut Vec<Self>)>\n \n         let (tree, joint) = stream.as_tree();\n         let (span, token) = match tree {\n-            tokenstream::TokenTree::Delimited(span, delimed) => {\n-                let delimiter = Delimiter::from_internal(delimed.delim);\n+            tokenstream::TokenTree::Delimited(span, delim, tts) => {\n+                let delimiter = Delimiter::from_internal(delim);\n                 return TokenTree::Group(Group {\n                     delimiter,\n-                    stream: delimed.tts.into(),\n+                    stream: tts.into(),\n                     span,\n                 });\n             }\n@@ -232,10 +232,8 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n             }) => {\n                 return tokenstream::TokenTree::Delimited(\n                     span,\n-                    tokenstream::Delimited {\n-                        delim: delimiter.to_internal(),\n-                        tts: stream.into(),\n-                    },\n+                    delimiter.to_internal(),\n+                    stream.into(),\n                 )\n                 .into();\n             }"}]}