{"sha": "b6d91a2bdac45cd919497a24207fab843124d4ba", "node_id": "MDY6Q29tbWl0NzI0NzEyOmI2ZDkxYTJiZGFjNDVjZDkxOTQ5N2EyNDIwN2ZhYjg0MzEyNGQ0YmE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-02-15T07:53:07Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-02-15T07:53:07Z"}, "message": "Auto merge of #22126 - steveklabnik:gh21281, r=nikomatsakis\n\nThis is super black magic internals at the moment, but having it\r\nsomewhere semi-public seems good. The current versions weren't being\r\nrendered, and they'll be useful for some people.\r\n\r\nFixes #21281\r\n\r\nr? @nikomatsakis @kmcallister", "tree": {"sha": "d826a22591607d47cdbc31f7e72b94698b4d451e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d826a22591607d47cdbc31f7e72b94698b4d451e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b6d91a2bdac45cd919497a24207fab843124d4ba", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b6d91a2bdac45cd919497a24207fab843124d4ba", "html_url": "https://github.com/rust-lang/rust/commit/b6d91a2bdac45cd919497a24207fab843124d4ba", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b6d91a2bdac45cd919497a24207fab843124d4ba/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "url": "https://api.github.com/repos/rust-lang/rust/commits/5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "html_url": "https://github.com/rust-lang/rust/commit/5be210c4188fb2f1a4fabc6baee5397ac6e6741e"}, {"sha": "bdc730e403cc29ae8b29f94320df6fa22ff279f6", "url": "https://api.github.com/repos/rust-lang/rust/commits/bdc730e403cc29ae8b29f94320df6fa22ff279f6", "html_url": "https://github.com/rust-lang/rust/commit/bdc730e403cc29ae8b29f94320df6fa22ff279f6"}], "stats": {"total": 5184, "additions": 2545, "deletions": 2639}, "files": [{"sha": "c835189820e5140aa02ddf5c060d14d4244f2b0c", "filename": "src/librustc/middle/infer/README.md", "status": "added", "additions": 237, "deletions": 0, "changes": 237, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2FREADME.md?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -0,0 +1,237 @@\n+# Type inference engine\n+\n+This is loosely based on standard HM-type inference, but with an\n+extension to try and accommodate subtyping.  There is nothing\n+principled about this extension; it's sound---I hope!---but it's a\n+heuristic, ultimately, and does not guarantee that it finds a valid\n+typing even if one exists (in fact, there are known scenarios where it\n+fails, some of which may eventually become problematic).\n+\n+## Key idea\n+\n+The main change is that each type variable T is associated with a\n+lower-bound L and an upper-bound U.  L and U begin as bottom and top,\n+respectively, but gradually narrow in response to new constraints\n+being introduced.  When a variable is finally resolved to a concrete\n+type, it can (theoretically) select any type that is a supertype of L\n+and a subtype of U.\n+\n+There are several critical invariants which we maintain:\n+\n+- the upper-bound of a variable only becomes lower and the lower-bound\n+  only becomes higher over time;\n+- the lower-bound L is always a subtype of the upper bound U;\n+- the lower-bound L and upper-bound U never refer to other type variables,\n+  but only to types (though those types may contain type variables).\n+\n+> An aside: if the terms upper- and lower-bound confuse you, think of\n+> \"supertype\" and \"subtype\".  The upper-bound is a \"supertype\"\n+> (super=upper in Latin, or something like that anyway) and the lower-bound\n+> is a \"subtype\" (sub=lower in Latin).  I find it helps to visualize\n+> a simple class hierarchy, like Java minus interfaces and\n+> primitive types.  The class Object is at the root (top) and other\n+> types lie in between.  The bottom type is then the Null type.\n+> So the tree looks like:\n+>\n+> ```text\n+>         Object\n+>         /    \\\n+>     String   Other\n+>         \\    /\n+>         (null)\n+> ```\n+>\n+> So the upper bound type is the \"supertype\" and the lower bound is the\n+> \"subtype\" (also, super and sub mean upper and lower in Latin, or something\n+> like that anyway).\n+\n+## Satisfying constraints\n+\n+At a primitive level, there is only one form of constraint that the\n+inference understands: a subtype relation.  So the outside world can\n+say \"make type A a subtype of type B\".  If there are variables\n+involved, the inferencer will adjust their upper- and lower-bounds as\n+needed to ensure that this relation is satisfied. (We also allow \"make\n+type A equal to type B\", but this is translated into \"A <: B\" and \"B\n+<: A\")\n+\n+As stated above, we always maintain the invariant that type bounds\n+never refer to other variables.  This keeps the inference relatively\n+simple, avoiding the scenario of having a kind of graph where we have\n+to pump constraints along and reach a fixed point, but it does impose\n+some heuristics in the case where the user is relating two type\n+variables A <: B.\n+\n+Combining two variables such that variable A will forever be a subtype\n+of variable B is the trickiest part of the algorithm because there is\n+often no right choice---that is, the right choice will depend on\n+future constraints which we do not yet know. The problem comes about\n+because both A and B have bounds that can be adjusted in the future.\n+Let's look at some of the cases that can come up.\n+\n+Imagine, to start, the best case, where both A and B have an upper and\n+lower bound (that is, the bounds are not top nor bot respectively). In\n+that case, if we're lucky, A.ub <: B.lb, and so we know that whatever\n+A and B should become, they will forever have the desired subtyping\n+relation.  We can just leave things as they are.\n+\n+### Option 1: Unify\n+\n+However, suppose that A.ub is *not* a subtype of B.lb.  In\n+that case, we must make a decision.  One option is to unify A\n+and B so that they are one variable whose bounds are:\n+\n+    UB = GLB(A.ub, B.ub)\n+    LB = LUB(A.lb, B.lb)\n+\n+(Note that we will have to verify that LB <: UB; if it does not, the\n+types are not intersecting and there is an error) In that case, A <: B\n+holds trivially because A==B.  However, we have now lost some\n+flexibility, because perhaps the user intended for A and B to end up\n+as different types and not the same type.\n+\n+Pictorally, what this does is to take two distinct variables with\n+(hopefully not completely) distinct type ranges and produce one with\n+the intersection.\n+\n+```text\n+                  B.ub                  B.ub\n+                   /\\                    /\n+           A.ub   /  \\           A.ub   /\n+           /   \\ /    \\              \\ /\n+          /     X      \\              UB\n+         /     / \\      \\            / \\\n+        /     /   /      \\          /   /\n+        \\     \\  /       /          \\  /\n+         \\      X       /             LB\n+          \\    / \\     /             / \\\n+           \\  /   \\   /             /   \\\n+           A.lb    B.lb          A.lb    B.lb\n+```\n+\n+\n+### Option 2: Relate UB/LB\n+\n+Another option is to keep A and B as distinct variables but set their\n+bounds in such a way that, whatever happens, we know that A <: B will hold.\n+This can be achieved by ensuring that A.ub <: B.lb.  In practice there\n+are two ways to do that, depicted pictorially here:\n+\n+```text\n+    Before                Option #1            Option #2\n+\n+             B.ub                B.ub                B.ub\n+              /\\                 /  \\                /  \\\n+      A.ub   /  \\        A.ub   /(B')\\       A.ub   /(B')\\\n+      /   \\ /    \\           \\ /     /           \\ /     /\n+     /     X      \\         __UB____/             UB    /\n+    /     / \\      \\       /  |                   |    /\n+   /     /   /      \\     /   |                   |   /\n+   \\     \\  /       /    /(A')|                   |  /\n+    \\      X       /    /     LB            ______LB/\n+     \\    / \\     /    /     / \\           / (A')/ \\\n+      \\  /   \\   /     \\    /   \\          \\    /   \\\n+      A.lb    B.lb       A.lb    B.lb        A.lb    B.lb\n+```\n+\n+In these diagrams, UB and LB are defined as before.  As you can see,\n+the new ranges `A'` and `B'` are quite different from the range that\n+would be produced by unifying the variables.\n+\n+### What we do now\n+\n+Our current technique is to *try* (transactionally) to relate the\n+existing bounds of A and B, if there are any (i.e., if `UB(A) != top\n+&& LB(B) != bot`).  If that succeeds, we're done.  If it fails, then\n+we merge A and B into same variable.\n+\n+This is not clearly the correct course.  For example, if `UB(A) !=\n+top` but `LB(B) == bot`, we could conceivably set `LB(B)` to `UB(A)`\n+and leave the variables unmerged.  This is sometimes the better\n+course, it depends on the program.\n+\n+The main case which fails today that I would like to support is:\n+\n+```text\n+fn foo<T>(x: T, y: T) { ... }\n+\n+fn bar() {\n+    let x: @mut int = @mut 3;\n+    let y: @int = @3;\n+    foo(x, y);\n+}\n+```\n+\n+In principle, the inferencer ought to find that the parameter `T` to\n+`foo(x, y)` is `@const int`.  Today, however, it does not; this is\n+because the type variable `T` is merged with the type variable for\n+`X`, and thus inherits its UB/LB of `@mut int`.  This leaves no\n+flexibility for `T` to later adjust to accommodate `@int`.\n+\n+### What to do when not all bounds are present\n+\n+In the prior discussion we assumed that A.ub was not top and B.lb was\n+not bot.  Unfortunately this is rarely the case.  Often type variables\n+have \"lopsided\" bounds.  For example, if a variable in the program has\n+been initialized but has not been used, then its corresponding type\n+variable will have a lower bound but no upper bound.  When that\n+variable is then used, we would like to know its upper bound---but we\n+don't have one!  In this case we'll do different things depending on\n+how the variable is being used.\n+\n+## Transactional support\n+\n+Whenever we adjust merge variables or adjust their bounds, we always\n+keep a record of the old value.  This allows the changes to be undone.\n+\n+## Regions\n+\n+I've only talked about type variables here, but region variables\n+follow the same principle.  They have upper- and lower-bounds.  A\n+region A is a subregion of a region B if A being valid implies that B\n+is valid.  This basically corresponds to the block nesting structure:\n+the regions for outer block scopes are superregions of those for inner\n+block scopes.\n+\n+## Integral and floating-point type variables\n+\n+There is a third variety of type variable that we use only for\n+inferring the types of unsuffixed integer literals.  Integral type\n+variables differ from general-purpose type variables in that there's\n+no subtyping relationship among the various integral types, so instead\n+of associating each variable with an upper and lower bound, we just\n+use simple unification.  Each integer variable is associated with at\n+most one integer type.  Floating point types are handled similarly to\n+integral types.\n+\n+## GLB/LUB\n+\n+Computing the greatest-lower-bound and least-upper-bound of two\n+types/regions is generally straightforward except when type variables\n+are involved. In that case, we follow a similar \"try to use the bounds\n+when possible but otherwise merge the variables\" strategy.  In other\n+words, `GLB(A, B)` where `A` and `B` are variables will often result\n+in `A` and `B` being merged and the result being `A`.\n+\n+## Type coercion\n+\n+We have a notion of assignability which differs somewhat from\n+subtyping; in particular it may cause region borrowing to occur.  See\n+the big comment later in this file on Type Coercion for specifics.\n+\n+### In conclusion\n+\n+I showed you three ways to relate `A` and `B`.  There are also more,\n+of course, though I'm not sure if there are any more sensible options.\n+The main point is that there are various options, each of which\n+produce a distinct range of types for `A` and `B`.  Depending on what\n+the correct values for A and B are, one of these options will be the\n+right choice: but of course we don't know the right values for A and B\n+yet, that's what we're trying to find!  In our code, we opt to unify\n+(Option #1).\n+\n+# Implementation details\n+\n+We make use of a trait-like implementation strategy to consolidate\n+duplicated code between subtypes, GLB, and LUB computations.  See the\n+section on \"Type Combining\" below for details."}, {"sha": "814eaa873472a2247f35082294130bc7f54f81b7", "filename": "src/librustc/middle/infer/doc.rs", "status": "removed", "additions": 0, "deletions": 247, "changes": 247, "blob_url": "https://github.com/rust-lang/rust/blob/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc%2Fmiddle%2Finfer%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc%2Fmiddle%2Finfer%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fdoc.rs?ref=5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "patch": "@@ -1,247 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # Type inference engine\n-//!\n-//! This is loosely based on standard HM-type inference, but with an\n-//! extension to try and accommodate subtyping.  There is nothing\n-//! principled about this extension; it's sound---I hope!---but it's a\n-//! heuristic, ultimately, and does not guarantee that it finds a valid\n-//! typing even if one exists (in fact, there are known scenarios where it\n-//! fails, some of which may eventually become problematic).\n-//!\n-//! ## Key idea\n-//!\n-//! The main change is that each type variable T is associated with a\n-//! lower-bound L and an upper-bound U.  L and U begin as bottom and top,\n-//! respectively, but gradually narrow in response to new constraints\n-//! being introduced.  When a variable is finally resolved to a concrete\n-//! type, it can (theoretically) select any type that is a supertype of L\n-//! and a subtype of U.\n-//!\n-//! There are several critical invariants which we maintain:\n-//!\n-//! - the upper-bound of a variable only becomes lower and the lower-bound\n-//!   only becomes higher over time;\n-//! - the lower-bound L is always a subtype of the upper bound U;\n-//! - the lower-bound L and upper-bound U never refer to other type variables,\n-//!   but only to types (though those types may contain type variables).\n-//!\n-//! > An aside: if the terms upper- and lower-bound confuse you, think of\n-//! > \"supertype\" and \"subtype\".  The upper-bound is a \"supertype\"\n-//! > (super=upper in Latin, or something like that anyway) and the lower-bound\n-//! > is a \"subtype\" (sub=lower in Latin).  I find it helps to visualize\n-//! > a simple class hierarchy, like Java minus interfaces and\n-//! > primitive types.  The class Object is at the root (top) and other\n-//! > types lie in between.  The bottom type is then the Null type.\n-//! > So the tree looks like:\n-//! >\n-//! > ```text\n-//! >         Object\n-//! >         /    \\\n-//! >     String   Other\n-//! >         \\    /\n-//! >         (null)\n-//! > ```\n-//! >\n-//! > So the upper bound type is the \"supertype\" and the lower bound is the\n-//! > \"subtype\" (also, super and sub mean upper and lower in Latin, or something\n-//! > like that anyway).\n-//!\n-//! ## Satisfying constraints\n-//!\n-//! At a primitive level, there is only one form of constraint that the\n-//! inference understands: a subtype relation.  So the outside world can\n-//! say \"make type A a subtype of type B\".  If there are variables\n-//! involved, the inferencer will adjust their upper- and lower-bounds as\n-//! needed to ensure that this relation is satisfied. (We also allow \"make\n-//! type A equal to type B\", but this is translated into \"A <: B\" and \"B\n-//! <: A\")\n-//!\n-//! As stated above, we always maintain the invariant that type bounds\n-//! never refer to other variables.  This keeps the inference relatively\n-//! simple, avoiding the scenario of having a kind of graph where we have\n-//! to pump constraints along and reach a fixed point, but it does impose\n-//! some heuristics in the case where the user is relating two type\n-//! variables A <: B.\n-//!\n-//! Combining two variables such that variable A will forever be a subtype\n-//! of variable B is the trickiest part of the algorithm because there is\n-//! often no right choice---that is, the right choice will depend on\n-//! future constraints which we do not yet know. The problem comes about\n-//! because both A and B have bounds that can be adjusted in the future.\n-//! Let's look at some of the cases that can come up.\n-//!\n-//! Imagine, to start, the best case, where both A and B have an upper and\n-//! lower bound (that is, the bounds are not top nor bot respectively). In\n-//! that case, if we're lucky, A.ub <: B.lb, and so we know that whatever\n-//! A and B should become, they will forever have the desired subtyping\n-//! relation.  We can just leave things as they are.\n-//!\n-//! ### Option 1: Unify\n-//!\n-//! However, suppose that A.ub is *not* a subtype of B.lb.  In\n-//! that case, we must make a decision.  One option is to unify A\n-//! and B so that they are one variable whose bounds are:\n-//!\n-//!     UB = GLB(A.ub, B.ub)\n-//!     LB = LUB(A.lb, B.lb)\n-//!\n-//! (Note that we will have to verify that LB <: UB; if it does not, the\n-//! types are not intersecting and there is an error) In that case, A <: B\n-//! holds trivially because A==B.  However, we have now lost some\n-//! flexibility, because perhaps the user intended for A and B to end up\n-//! as different types and not the same type.\n-//!\n-//! Pictorally, what this does is to take two distinct variables with\n-//! (hopefully not completely) distinct type ranges and produce one with\n-//! the intersection.\n-//!\n-//! ```text\n-//!                   B.ub                  B.ub\n-//!                    /\\                    /\n-//!            A.ub   /  \\           A.ub   /\n-//!            /   \\ /    \\              \\ /\n-//!           /     X      \\              UB\n-//!          /     / \\      \\            / \\\n-//!         /     /   /      \\          /   /\n-//!         \\     \\  /       /          \\  /\n-//!          \\      X       /             LB\n-//!           \\    / \\     /             / \\\n-//!            \\  /   \\   /             /   \\\n-//!            A.lb    B.lb          A.lb    B.lb\n-//! ```\n-//!\n-//!\n-//! ### Option 2: Relate UB/LB\n-//!\n-//! Another option is to keep A and B as distinct variables but set their\n-//! bounds in such a way that, whatever happens, we know that A <: B will hold.\n-//! This can be achieved by ensuring that A.ub <: B.lb.  In practice there\n-//! are two ways to do that, depicted pictorially here:\n-//!\n-//! ```text\n-//!     Before                Option #1            Option #2\n-//!\n-//!              B.ub                B.ub                B.ub\n-//!               /\\                 /  \\                /  \\\n-//!       A.ub   /  \\        A.ub   /(B')\\       A.ub   /(B')\\\n-//!       /   \\ /    \\           \\ /     /           \\ /     /\n-//!      /     X      \\         __UB____/             UB    /\n-//!     /     / \\      \\       /  |                   |    /\n-//!    /     /   /      \\     /   |                   |   /\n-//!    \\     \\  /       /    /(A')|                   |  /\n-//!     \\      X       /    /     LB            ______LB/\n-//!      \\    / \\     /    /     / \\           / (A')/ \\\n-//!       \\  /   \\   /     \\    /   \\          \\    /   \\\n-//!       A.lb    B.lb       A.lb    B.lb        A.lb    B.lb\n-//! ```\n-//!\n-//! In these diagrams, UB and LB are defined as before.  As you can see,\n-//! the new ranges `A'` and `B'` are quite different from the range that\n-//! would be produced by unifying the variables.\n-//!\n-//! ### What we do now\n-//!\n-//! Our current technique is to *try* (transactionally) to relate the\n-//! existing bounds of A and B, if there are any (i.e., if `UB(A) != top\n-//! && LB(B) != bot`).  If that succeeds, we're done.  If it fails, then\n-//! we merge A and B into same variable.\n-//!\n-//! This is not clearly the correct course.  For example, if `UB(A) !=\n-//! top` but `LB(B) == bot`, we could conceivably set `LB(B)` to `UB(A)`\n-//! and leave the variables unmerged.  This is sometimes the better\n-//! course, it depends on the program.\n-//!\n-//! The main case which fails today that I would like to support is:\n-//!\n-//! ```text\n-//! fn foo<T>(x: T, y: T) { ... }\n-//!\n-//! fn bar() {\n-//!     let x: @mut int = @mut 3;\n-//!     let y: @int = @3;\n-//!     foo(x, y);\n-//! }\n-//! ```\n-//!\n-//! In principle, the inferencer ought to find that the parameter `T` to\n-//! `foo(x, y)` is `@const int`.  Today, however, it does not; this is\n-//! because the type variable `T` is merged with the type variable for\n-//! `X`, and thus inherits its UB/LB of `@mut int`.  This leaves no\n-//! flexibility for `T` to later adjust to accommodate `@int`.\n-//!\n-//! ### What to do when not all bounds are present\n-//!\n-//! In the prior discussion we assumed that A.ub was not top and B.lb was\n-//! not bot.  Unfortunately this is rarely the case.  Often type variables\n-//! have \"lopsided\" bounds.  For example, if a variable in the program has\n-//! been initialized but has not been used, then its corresponding type\n-//! variable will have a lower bound but no upper bound.  When that\n-//! variable is then used, we would like to know its upper bound---but we\n-//! don't have one!  In this case we'll do different things depending on\n-//! how the variable is being used.\n-//!\n-//! ## Transactional support\n-//!\n-//! Whenever we adjust merge variables or adjust their bounds, we always\n-//! keep a record of the old value.  This allows the changes to be undone.\n-//!\n-//! ## Regions\n-//!\n-//! I've only talked about type variables here, but region variables\n-//! follow the same principle.  They have upper- and lower-bounds.  A\n-//! region A is a subregion of a region B if A being valid implies that B\n-//! is valid.  This basically corresponds to the block nesting structure:\n-//! the regions for outer block scopes are superregions of those for inner\n-//! block scopes.\n-//!\n-//! ## Integral and floating-point type variables\n-//!\n-//! There is a third variety of type variable that we use only for\n-//! inferring the types of unsuffixed integer literals.  Integral type\n-//! variables differ from general-purpose type variables in that there's\n-//! no subtyping relationship among the various integral types, so instead\n-//! of associating each variable with an upper and lower bound, we just\n-//! use simple unification.  Each integer variable is associated with at\n-//! most one integer type.  Floating point types are handled similarly to\n-//! integral types.\n-//!\n-//! ## GLB/LUB\n-//!\n-//! Computing the greatest-lower-bound and least-upper-bound of two\n-//! types/regions is generally straightforward except when type variables\n-//! are involved. In that case, we follow a similar \"try to use the bounds\n-//! when possible but otherwise merge the variables\" strategy.  In other\n-//! words, `GLB(A, B)` where `A` and `B` are variables will often result\n-//! in `A` and `B` being merged and the result being `A`.\n-//!\n-//! ## Type coercion\n-//!\n-//! We have a notion of assignability which differs somewhat from\n-//! subtyping; in particular it may cause region borrowing to occur.  See\n-//! the big comment later in this file on Type Coercion for specifics.\n-//!\n-//! ### In conclusion\n-//!\n-//! I showed you three ways to relate `A` and `B`.  There are also more,\n-//! of course, though I'm not sure if there are any more sensible options.\n-//! The main point is that there are various options, each of which\n-//! produce a distinct range of types for `A` and `B`.  Depending on what\n-//! the correct values for A and B are, one of these options will be the\n-//! right choice: but of course we don't know the right values for A and B\n-//! yet, that's what we're trying to find!  In our code, we opt to unify\n-//! (Option #1).\n-//!\n-//! # Implementation details\n-//!\n-//! We make use of a trait-like implementation strategy to consolidate\n-//! duplicated code between subtypes, GLB, and LUB computations.  See the\n-//! section on \"Type Combining\" below for details."}, {"sha": "3414c7515a374c6ca18272be2817253be7efa771", "filename": "src/librustc/middle/infer/higher_ranked/README.md", "status": "added", "additions": 403, "deletions": 0, "changes": 403, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fhigher_ranked%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fhigher_ranked%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fhigher_ranked%2FREADME.md?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -0,0 +1,403 @@\n+# Skolemization and functions\n+\n+One of the trickiest and most subtle aspects of regions is dealing\n+with higher-ranked things which include bound region variables, such\n+as function types. I strongly suggest that if you want to understand\n+the situation, you read this paper (which is, admittedly, very long,\n+but you don't have to read the whole thing):\n+\n+http://research.microsoft.com/en-us/um/people/simonpj/papers/higher-rank/\n+\n+Although my explanation will never compete with SPJ's (for one thing,\n+his is approximately 100 pages), I will attempt to explain the basic\n+problem and also how we solve it. Note that the paper only discusses\n+subtyping, not the computation of LUB/GLB.\n+\n+The problem we are addressing is that there is a kind of subtyping\n+between functions with bound region parameters. Consider, for\n+example, whether the following relation holds:\n+\n+    for<'a> fn(&'a int) <: for<'b> fn(&'b int)? (Yes, a => b)\n+\n+The answer is that of course it does. These two types are basically\n+the same, except that in one we used the name `a` and one we used\n+the name `b`.\n+\n+In the examples that follow, it becomes very important to know whether\n+a lifetime is bound in a function type (that is, is a lifetime\n+parameter) or appears free (is defined in some outer scope).\n+Therefore, from now on I will always write the bindings explicitly,\n+using the Rust syntax `for<'a> fn(&'a int)` to indicate that `a` is a\n+lifetime parameter.\n+\n+Now let's consider two more function types. Here, we assume that the\n+`'b` lifetime is defined somewhere outside and hence is not a lifetime\n+parameter bound by the function type (it \"appears free\"):\n+\n+    for<'a> fn(&'a int) <: fn(&'b int)? (Yes, a => b)\n+\n+This subtyping relation does in fact hold. To see why, you have to\n+consider what subtyping means. One way to look at `T1 <: T2` is to\n+say that it means that it is always ok to treat an instance of `T1` as\n+if it had the type `T2`. So, with our functions, it is always ok to\n+treat a function that can take pointers with any lifetime as if it\n+were a function that can only take a pointer with the specific\n+lifetime `'b`. After all, `'b` is a lifetime, after all, and\n+the function can take values of any lifetime.\n+\n+You can also look at subtyping as the *is a* relationship. This amounts\n+to the same thing: a function that accepts pointers with any lifetime\n+*is a* function that accepts pointers with some specific lifetime.\n+\n+So, what if we reverse the order of the two function types, like this:\n+\n+    fn(&'b int) <: for<'a> fn(&'a int)? (No)\n+\n+Does the subtyping relationship still hold?  The answer of course is\n+no. In this case, the function accepts *only the lifetime `'b`*,\n+so it is not reasonable to treat it as if it were a function that\n+accepted any lifetime.\n+\n+What about these two examples:\n+\n+    for<'a,'b> fn(&'a int, &'b int) <: for<'a>    fn(&'a int, &'a int)? (Yes)\n+    for<'a>    fn(&'a int, &'a int) <: for<'a,'b> fn(&'a int, &'b int)? (No)\n+\n+Here, it is true that functions which take two pointers with any two\n+lifetimes can be treated as if they only accepted two pointers with\n+the same lifetime, but not the reverse.\n+\n+## The algorithm\n+\n+Here is the algorithm we use to perform the subtyping check:\n+\n+1. Replace all bound regions in the subtype with new variables\n+2. Replace all bound regions in the supertype with skolemized\n+   equivalents. A \"skolemized\" region is just a new fresh region\n+   name.\n+3. Check that the parameter and return types match as normal\n+4. Ensure that no skolemized regions 'leak' into region variables\n+   visible from \"the outside\"\n+\n+Let's walk through some examples and see how this algorithm plays out.\n+\n+#### First example\n+\n+We'll start with the first example, which was:\n+\n+    1. for<'a> fn(&'a T) <: for<'b> fn(&'b T)?        Yes: a -> b\n+\n+After steps 1 and 2 of the algorithm we will have replaced the types\n+like so:\n+\n+    1. fn(&'A T) <: fn(&'x T)?\n+\n+Here the upper case `&A` indicates a *region variable*, that is, a\n+region whose value is being inferred by the system. I also replaced\n+`&b` with `&x`---I'll use letters late in the alphabet (`x`, `y`, `z`)\n+to indicate skolemized region names. We can assume they don't appear\n+elsewhere. Note that neither the sub- nor the supertype bind any\n+region names anymore (as indicated by the absence of `<` and `>`).\n+\n+The next step is to check that the parameter types match. Because\n+parameters are contravariant, this means that we check whether:\n+\n+    &'x T <: &'A T\n+\n+Region pointers are contravariant so this implies that\n+\n+    &A <= &x\n+\n+must hold, where `<=` is the subregion relationship. Processing\n+*this* constrain simply adds a constraint into our graph that `&A <=\n+&x` and is considered successful (it can, for example, be satisfied by\n+choosing the value `&x` for `&A`).\n+\n+So far we have encountered no error, so the subtype check succeeds.\n+\n+#### The third example\n+\n+Now let's look first at the third example, which was:\n+\n+    3. fn(&'a T)    <: for<'b> fn(&'b T)?        No!\n+\n+After steps 1 and 2 of the algorithm we will have replaced the types\n+like so:\n+\n+    3. fn(&'a T) <: fn(&'x T)?\n+\n+This looks pretty much the same as before, except that on the LHS\n+`'a` was not bound, and hence was left as-is and not replaced with\n+a variable. The next step is again to check that the parameter types\n+match. This will ultimately require (as before) that `'a` <= `&x`\n+must hold: but this does not hold. `self` and `x` are both distinct\n+free regions. So the subtype check fails.\n+\n+#### Checking for skolemization leaks\n+\n+You may be wondering about that mysterious last step in the algorithm.\n+So far it has not been relevant. The purpose of that last step is to\n+catch something like *this*:\n+\n+    for<'a> fn() -> fn(&'a T) <: fn() -> for<'b> fn(&'b T)?   No.\n+\n+Here the function types are the same but for where the binding occurs.\n+The subtype returns a function that expects a value in precisely one\n+region. The supertype returns a function that expects a value in any\n+region. If we allow an instance of the subtype to be used where the\n+supertype is expected, then, someone could call the fn and think that\n+the return value has type `fn<b>(&'b T)` when it really has type\n+`fn(&'a T)` (this is case #3, above). Bad.\n+\n+So let's step through what happens when we perform this subtype check.\n+We first replace the bound regions in the subtype (the supertype has\n+no bound regions). This gives us:\n+\n+    fn() -> fn(&'A T) <: fn() -> for<'b> fn(&'b T)?\n+\n+Now we compare the return types, which are covariant, and hence we have:\n+\n+    fn(&'A T) <: for<'b> fn(&'b T)?\n+\n+Here we skolemize the bound region in the supertype to yield:\n+\n+    fn(&'A T) <: fn(&'x T)?\n+\n+And then proceed to compare the argument types:\n+\n+    &'x T <: &'A T\n+    'A <= 'x\n+\n+Finally, this is where it gets interesting!  This is where an error\n+*should* be reported. But in fact this will not happen. The reason why\n+is that `A` is a variable: we will infer that its value is the fresh\n+region `x` and think that everything is happy. In fact, this behavior\n+is *necessary*, it was key to the first example we walked through.\n+\n+The difference between this example and the first one is that the variable\n+`A` already existed at the point where the skolemization occurred. In\n+the first example, you had two functions:\n+\n+    for<'a> fn(&'a T) <: for<'b> fn(&'b T)\n+\n+and hence `&A` and `&x` were created \"together\". In general, the\n+intention of the skolemized names is that they are supposed to be\n+fresh names that could never be equal to anything from the outside.\n+But when inference comes into play, we might not be respecting this\n+rule.\n+\n+So the way we solve this is to add a fourth step that examines the\n+constraints that refer to skolemized names. Basically, consider a\n+non-directed version of the constraint graph. Let `Tainted(x)` be the\n+set of all things reachable from a skolemized variable `x`.\n+`Tainted(x)` should not contain any regions that existed before the\n+step at which the skolemization was performed. So this case here\n+would fail because `&x` was created alone, but is relatable to `&A`.\n+\n+## Computing the LUB and GLB\n+\n+The paper I pointed you at is written for Haskell. It does not\n+therefore considering subtyping and in particular does not consider\n+LUB or GLB computation. We have to consider this. Here is the\n+algorithm I implemented.\n+\n+First though, let's discuss what we are trying to compute in more\n+detail. The LUB is basically the \"common supertype\" and the GLB is\n+\"common subtype\"; one catch is that the LUB should be the\n+*most-specific* common supertype and the GLB should be *most general*\n+common subtype (as opposed to any common supertype or any common\n+subtype).\n+\n+Anyway, to help clarify, here is a table containing some function\n+pairs and their LUB/GLB (for conciseness, in this table, I'm just\n+including the lifetimes here, not the rest of the types, and I'm\n+writing `fn<>` instead of `for<> fn`):\n+\n+```\n+Type 1                Type 2                LUB                    GLB\n+fn<'a>('a)            fn('X)                fn('X)                 fn<'a>('a)\n+fn('a)                fn('X)                --                     fn<'a>('a)\n+fn<'a,'b>('a, 'b)     fn<'x>('x, 'x)        fn<'a>('a, 'a)         fn<'a,'b>('a, 'b)\n+fn<'a,'b>('a, 'b, 'a) fn<'x,'y>('x, 'y, 'y) fn<'a>('a, 'a, 'a)     fn<'a,'b,'c>('a,'b,'c)\n+```\n+\n+### Conventions\n+\n+I use lower-case letters (e.g., `&a`) for bound regions and upper-case\n+letters for free regions (`&A`).  Region variables written with a\n+dollar-sign (e.g., `$a`).  I will try to remember to enumerate the\n+bound-regions on the fn type as well (e.g., `for<'a> fn(&a)`).\n+\n+### High-level summary\n+\n+Both the LUB and the GLB algorithms work in a similar fashion.  They\n+begin by replacing all bound regions (on both sides) with fresh region\n+inference variables.  Therefore, both functions are converted to types\n+that contain only free regions.  We can then compute the LUB/GLB in a\n+straightforward way, as described in `combine.rs`.  This results in an\n+interim type T.  The algorithms then examine the regions that appear\n+in T and try to, in some cases, replace them with bound regions to\n+yield the final result.\n+\n+To decide whether to replace a region `R` that appears in `T` with\n+a bound region, the algorithms make use of two bits of\n+information.  First is a set `V` that contains all region\n+variables created as part of the LUB/GLB computation (roughly; see\n+`region_vars_confined_to_snapshot()` for full details). `V` will\n+contain the region variables created to replace the bound regions\n+in the input types, but it also contains 'intermediate' variables\n+created to represent the LUB/GLB of individual regions.\n+Basically, when asked to compute the LUB/GLB of a region variable\n+with another region, the inferencer cannot oblige immediately\n+since the values of that variables are not known.  Therefore, it\n+creates a new variable that is related to the two regions.  For\n+example, the LUB of two variables `$x` and `$y` is a fresh\n+variable `$z` that is constrained such that `$x <= $z` and `$y <=\n+$z`.  So `V` will contain these intermediate variables as well.\n+\n+The other important factor in deciding how to replace a region in T is\n+the function `Tainted($r)` which, for a region variable, identifies\n+all regions that the region variable is related to in some way\n+(`Tainted()` made an appearance in the subtype computation as well).\n+\n+### LUB\n+\n+The LUB algorithm proceeds in three steps:\n+\n+1. Replace all bound regions (on both sides) with fresh region\n+   inference variables.\n+2. Compute the LUB \"as normal\", meaning compute the GLB of each\n+   pair of argument types and the LUB of the return types and\n+   so forth.  Combine those to a new function type `F`.\n+3. Replace each region `R` that appears in `F` as follows:\n+   - Let `V` be the set of variables created during the LUB\n+     computational steps 1 and 2, as described in the previous section.\n+   - If `R` is not in `V`, replace `R` with itself.\n+   - If `Tainted(R)` contains a region that is not in `V`,\n+     replace `R` with itself.\n+   - Otherwise, select the earliest variable in `Tainted(R)` that originates\n+     from the left-hand side and replace `R` with the bound region that\n+     this variable was a replacement for.\n+\n+So, let's work through the simplest example: `fn(&A)` and `for<'a> fn(&a)`.\n+In this case, `&a` will be replaced with `$a` and the interim LUB type\n+`fn($b)` will be computed, where `$b=GLB(&A,$a)`.  Therefore, `V =\n+{$a, $b}` and `Tainted($b) = { $b, $a, &A }`.  When we go to replace\n+`$b`, we find that since `&A \\in Tainted($b)` is not a member of `V`,\n+we leave `$b` as is.  When region inference happens, `$b` will be\n+resolved to `&A`, as we wanted.\n+\n+Let's look at a more complex one: `fn(&a, &b)` and `fn(&x, &x)`.  In\n+this case, we'll end up with a (pre-replacement) LUB type of `fn(&g,\n+&h)` and a graph that looks like:\n+\n+```\n+     $a        $b     *--$x\n+       \\        \\    /  /\n+        \\        $h-*  /\n+         $g-----------*\n+```\n+\n+Here `$g` and `$h` are fresh variables that are created to represent\n+the LUB/GLB of things requiring inference.  This means that `V` and\n+`Tainted` will look like:\n+\n+```\n+V = {$a, $b, $g, $h, $x}\n+Tainted($g) = Tainted($h) = { $a, $b, $h, $g, $x }\n+```\n+\n+Therefore we replace both `$g` and `$h` with `$a`, and end up\n+with the type `fn(&a, &a)`.\n+\n+### GLB\n+\n+The procedure for computing the GLB is similar.  The difference lies\n+in computing the replacements for the various variables. For each\n+region `R` that appears in the type `F`, we again compute `Tainted(R)`\n+and examine the results:\n+\n+1. If `R` is not in `V`, it is not replaced.\n+2. Else, if `Tainted(R)` contains only variables in `V`, and it\n+   contains exactly one variable from the LHS and one variable from\n+   the RHS, then `R` can be mapped to the bound version of the\n+   variable from the LHS.\n+3. Else, if `Tainted(R)` contains no variable from the LHS and no\n+   variable from the RHS, then `R` can be mapped to itself.\n+4. Else, `R` is mapped to a fresh bound variable.\n+\n+These rules are pretty complex.  Let's look at some examples to see\n+how they play out.\n+\n+Out first example was `fn(&a)` and `fn(&X)`.  In this case, `&a` will\n+be replaced with `$a` and we will ultimately compute a\n+(pre-replacement) GLB type of `fn($g)` where `$g=LUB($a,&X)`.\n+Therefore, `V={$a,$g}` and `Tainted($g)={$g,$a,&X}.  To find the\n+replacement for `$g` we consult the rules above:\n+- Rule (1) does not apply because `$g \\in V`\n+- Rule (2) does not apply because `&X \\in Tainted($g)`\n+- Rule (3) does not apply because `$a \\in Tainted($g)`\n+- Hence, by rule (4), we replace `$g` with a fresh bound variable `&z`.\n+So our final result is `fn(&z)`, which is correct.\n+\n+The next example is `fn(&A)` and `fn(&Z)`. In this case, we will again\n+have a (pre-replacement) GLB of `fn(&g)`, where `$g = LUB(&A,&Z)`.\n+Therefore, `V={$g}` and `Tainted($g) = {$g, &A, &Z}`.  In this case,\n+by rule (3), `$g` is mapped to itself, and hence the result is\n+`fn($g)`.  This result is correct (in this case, at least), but it is\n+indicative of a case that *can* lead us into concluding that there is\n+no GLB when in fact a GLB does exist.  See the section \"Questionable\n+Results\" below for more details.\n+\n+The next example is `fn(&a, &b)` and `fn(&c, &c)`. In this case, as\n+before, we'll end up with `F=fn($g, $h)` where `Tainted($g) =\n+Tainted($h) = {$g, $h, $a, $b, $c}`.  Only rule (4) applies and hence\n+we'll select fresh bound variables `y` and `z` and wind up with\n+`fn(&y, &z)`.\n+\n+For the last example, let's consider what may seem trivial, but is\n+not: `fn(&a, &a)` and `fn(&b, &b)`.  In this case, we'll get `F=fn($g,\n+$h)` where `Tainted($g) = {$g, $a, $x}` and `Tainted($h) = {$h, $a,\n+$x}`.  Both of these sets contain exactly one bound variable from each\n+side, so we'll map them both to `&a`, resulting in `fn(&a, &a)`, which\n+is the desired result.\n+\n+### Shortcomings and correctness\n+\n+You may be wondering whether this algorithm is correct.  The answer is\n+\"sort of\".  There are definitely cases where they fail to compute a\n+result even though a correct result exists.  I believe, though, that\n+if they succeed, then the result is valid, and I will attempt to\n+convince you.  The basic argument is that the \"pre-replacement\" step\n+computes a set of constraints.  The replacements, then, attempt to\n+satisfy those constraints, using bound identifiers where needed.\n+\n+For now I will briefly go over the cases for LUB/GLB and identify\n+their intent:\n+\n+- LUB:\n+  - The region variables that are substituted in place of bound regions\n+    are intended to collect constraints on those bound regions.\n+  - If Tainted(R) contains only values in V, then this region is unconstrained\n+    and can therefore be generalized, otherwise it cannot.\n+- GLB:\n+  - The region variables that are substituted in place of bound regions\n+    are intended to collect constraints on those bound regions.\n+  - If Tainted(R) contains exactly one variable from each side, and\n+    only variables in V, that indicates that those two bound regions\n+    must be equated.\n+  - Otherwise, if Tainted(R) references any variables from left or right\n+    side, then it is trying to combine a bound region with a free one or\n+    multiple bound regions, so we need to select fresh bound regions.\n+\n+Sorry this is more of a shorthand to myself.  I will try to write up something\n+more convincing in the future.\n+\n+#### Where are the algorithms wrong?\n+\n+- The pre-replacement computation can fail even though using a\n+  bound-region would have succeeded.\n+- We will compute GLB(fn(fn($a)), fn(fn($b))) as fn($c) where $c is the\n+  GLB of $a and $b.  But if inference finds that $a and $b must be mapped\n+  to regions without a GLB, then this is effectively a failure to compute\n+  the GLB.  However, the result `fn<$c>(fn($c))` is a valid GLB."}, {"sha": "6b520ab665c22ec89a41e5d58652a28bd38bf28b", "filename": "src/librustc/middle/infer/higher_ranked/doc.rs", "status": "removed", "additions": 0, "deletions": 413, "changes": 413, "blob_url": "https://github.com/rust-lang/rust/blob/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc%2Fmiddle%2Finfer%2Fhigher_ranked%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc%2Fmiddle%2Finfer%2Fhigher_ranked%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fhigher_ranked%2Fdoc.rs?ref=5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "patch": "@@ -1,413 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # Skolemization and functions\n-//!\n-//! One of the trickiest and most subtle aspects of regions is dealing\n-//! with higher-ranked things which include bound region variables, such\n-//! as function types. I strongly suggest that if you want to understand\n-//! the situation, you read this paper (which is, admittedly, very long,\n-//! but you don't have to read the whole thing):\n-//!\n-//! http://research.microsoft.com/en-us/um/people/simonpj/papers/higher-rank/\n-//!\n-//! Although my explanation will never compete with SPJ's (for one thing,\n-//! his is approximately 100 pages), I will attempt to explain the basic\n-//! problem and also how we solve it. Note that the paper only discusses\n-//! subtyping, not the computation of LUB/GLB.\n-//!\n-//! The problem we are addressing is that there is a kind of subtyping\n-//! between functions with bound region parameters. Consider, for\n-//! example, whether the following relation holds:\n-//!\n-//!     for<'a> fn(&'a int) <: for<'b> fn(&'b int)? (Yes, a => b)\n-//!\n-//! The answer is that of course it does. These two types are basically\n-//! the same, except that in one we used the name `a` and one we used\n-//! the name `b`.\n-//!\n-//! In the examples that follow, it becomes very important to know whether\n-//! a lifetime is bound in a function type (that is, is a lifetime\n-//! parameter) or appears free (is defined in some outer scope).\n-//! Therefore, from now on I will always write the bindings explicitly,\n-//! using the Rust syntax `for<'a> fn(&'a int)` to indicate that `a` is a\n-//! lifetime parameter.\n-//!\n-//! Now let's consider two more function types. Here, we assume that the\n-//! `'b` lifetime is defined somewhere outside and hence is not a lifetime\n-//! parameter bound by the function type (it \"appears free\"):\n-//!\n-//!     for<'a> fn(&'a int) <: fn(&'b int)? (Yes, a => b)\n-//!\n-//! This subtyping relation does in fact hold. To see why, you have to\n-//! consider what subtyping means. One way to look at `T1 <: T2` is to\n-//! say that it means that it is always ok to treat an instance of `T1` as\n-//! if it had the type `T2`. So, with our functions, it is always ok to\n-//! treat a function that can take pointers with any lifetime as if it\n-//! were a function that can only take a pointer with the specific\n-//! lifetime `'b`. After all, `'b` is a lifetime, after all, and\n-//! the function can take values of any lifetime.\n-//!\n-//! You can also look at subtyping as the *is a* relationship. This amounts\n-//! to the same thing: a function that accepts pointers with any lifetime\n-//! *is a* function that accepts pointers with some specific lifetime.\n-//!\n-//! So, what if we reverse the order of the two function types, like this:\n-//!\n-//!     fn(&'b int) <: for<'a> fn(&'a int)? (No)\n-//!\n-//! Does the subtyping relationship still hold?  The answer of course is\n-//! no. In this case, the function accepts *only the lifetime `'b`*,\n-//! so it is not reasonable to treat it as if it were a function that\n-//! accepted any lifetime.\n-//!\n-//! What about these two examples:\n-//!\n-//!     for<'a,'b> fn(&'a int, &'b int) <: for<'a>    fn(&'a int, &'a int)? (Yes)\n-//!     for<'a>    fn(&'a int, &'a int) <: for<'a,'b> fn(&'a int, &'b int)? (No)\n-//!\n-//! Here, it is true that functions which take two pointers with any two\n-//! lifetimes can be treated as if they only accepted two pointers with\n-//! the same lifetime, but not the reverse.\n-//!\n-//! ## The algorithm\n-//!\n-//! Here is the algorithm we use to perform the subtyping check:\n-//!\n-//! 1. Replace all bound regions in the subtype with new variables\n-//! 2. Replace all bound regions in the supertype with skolemized\n-//!    equivalents. A \"skolemized\" region is just a new fresh region\n-//!    name.\n-//! 3. Check that the parameter and return types match as normal\n-//! 4. Ensure that no skolemized regions 'leak' into region variables\n-//!    visible from \"the outside\"\n-//!\n-//! Let's walk through some examples and see how this algorithm plays out.\n-//!\n-//! #### First example\n-//!\n-//! We'll start with the first example, which was:\n-//!\n-//!     1. for<'a> fn(&'a T) <: for<'b> fn(&'b T)?        Yes: a -> b\n-//!\n-//! After steps 1 and 2 of the algorithm we will have replaced the types\n-//! like so:\n-//!\n-//!     1. fn(&'A T) <: fn(&'x T)?\n-//!\n-//! Here the upper case `&A` indicates a *region variable*, that is, a\n-//! region whose value is being inferred by the system. I also replaced\n-//! `&b` with `&x`---I'll use letters late in the alphabet (`x`, `y`, `z`)\n-//! to indicate skolemized region names. We can assume they don't appear\n-//! elsewhere. Note that neither the sub- nor the supertype bind any\n-//! region names anymore (as indicated by the absence of `<` and `>`).\n-//!\n-//! The next step is to check that the parameter types match. Because\n-//! parameters are contravariant, this means that we check whether:\n-//!\n-//!     &'x T <: &'A T\n-//!\n-//! Region pointers are contravariant so this implies that\n-//!\n-//!     &A <= &x\n-//!\n-//! must hold, where `<=` is the subregion relationship. Processing\n-//! *this* constrain simply adds a constraint into our graph that `&A <=\n-//! &x` and is considered successful (it can, for example, be satisfied by\n-//! choosing the value `&x` for `&A`).\n-//!\n-//! So far we have encountered no error, so the subtype check succeeds.\n-//!\n-//! #### The third example\n-//!\n-//! Now let's look first at the third example, which was:\n-//!\n-//!     3. fn(&'a T)    <: for<'b> fn(&'b T)?        No!\n-//!\n-//! After steps 1 and 2 of the algorithm we will have replaced the types\n-//! like so:\n-//!\n-//!     3. fn(&'a T) <: fn(&'x T)?\n-//!\n-//! This looks pretty much the same as before, except that on the LHS\n-//! `'a` was not bound, and hence was left as-is and not replaced with\n-//! a variable. The next step is again to check that the parameter types\n-//! match. This will ultimately require (as before) that `'a` <= `&x`\n-//! must hold: but this does not hold. `self` and `x` are both distinct\n-//! free regions. So the subtype check fails.\n-//!\n-//! #### Checking for skolemization leaks\n-//!\n-//! You may be wondering about that mysterious last step in the algorithm.\n-//! So far it has not been relevant. The purpose of that last step is to\n-//! catch something like *this*:\n-//!\n-//!     for<'a> fn() -> fn(&'a T) <: fn() -> for<'b> fn(&'b T)?   No.\n-//!\n-//! Here the function types are the same but for where the binding occurs.\n-//! The subtype returns a function that expects a value in precisely one\n-//! region. The supertype returns a function that expects a value in any\n-//! region. If we allow an instance of the subtype to be used where the\n-//! supertype is expected, then, someone could call the fn and think that\n-//! the return value has type `fn<b>(&'b T)` when it really has type\n-//! `fn(&'a T)` (this is case #3, above). Bad.\n-//!\n-//! So let's step through what happens when we perform this subtype check.\n-//! We first replace the bound regions in the subtype (the supertype has\n-//! no bound regions). This gives us:\n-//!\n-//!     fn() -> fn(&'A T) <: fn() -> for<'b> fn(&'b T)?\n-//!\n-//! Now we compare the return types, which are covariant, and hence we have:\n-//!\n-//!     fn(&'A T) <: for<'b> fn(&'b T)?\n-//!\n-//! Here we skolemize the bound region in the supertype to yield:\n-//!\n-//!     fn(&'A T) <: fn(&'x T)?\n-//!\n-//! And then proceed to compare the argument types:\n-//!\n-//!     &'x T <: &'A T\n-//!     'A <= 'x\n-//!\n-//! Finally, this is where it gets interesting!  This is where an error\n-//! *should* be reported. But in fact this will not happen. The reason why\n-//! is that `A` is a variable: we will infer that its value is the fresh\n-//! region `x` and think that everything is happy. In fact, this behavior\n-//! is *necessary*, it was key to the first example we walked through.\n-//!\n-//! The difference between this example and the first one is that the variable\n-//! `A` already existed at the point where the skolemization occurred. In\n-//! the first example, you had two functions:\n-//!\n-//!     for<'a> fn(&'a T) <: for<'b> fn(&'b T)\n-//!\n-//! and hence `&A` and `&x` were created \"together\". In general, the\n-//! intention of the skolemized names is that they are supposed to be\n-//! fresh names that could never be equal to anything from the outside.\n-//! But when inference comes into play, we might not be respecting this\n-//! rule.\n-//!\n-//! So the way we solve this is to add a fourth step that examines the\n-//! constraints that refer to skolemized names. Basically, consider a\n-//! non-directed version of the constraint graph. Let `Tainted(x)` be the\n-//! set of all things reachable from a skolemized variable `x`.\n-//! `Tainted(x)` should not contain any regions that existed before the\n-//! step at which the skolemization was performed. So this case here\n-//! would fail because `&x` was created alone, but is relatable to `&A`.\n-//!\n-//! ## Computing the LUB and GLB\n-//!\n-//! The paper I pointed you at is written for Haskell. It does not\n-//! therefore considering subtyping and in particular does not consider\n-//! LUB or GLB computation. We have to consider this. Here is the\n-//! algorithm I implemented.\n-//!\n-//! First though, let's discuss what we are trying to compute in more\n-//! detail. The LUB is basically the \"common supertype\" and the GLB is\n-//! \"common subtype\"; one catch is that the LUB should be the\n-//! *most-specific* common supertype and the GLB should be *most general*\n-//! common subtype (as opposed to any common supertype or any common\n-//! subtype).\n-//!\n-//! Anyway, to help clarify, here is a table containing some function\n-//! pairs and their LUB/GLB (for conciseness, in this table, I'm just\n-//! including the lifetimes here, not the rest of the types, and I'm\n-//! writing `fn<>` instead of `for<> fn`):\n-//!\n-//! ```\n-//! Type 1                Type 2                LUB                    GLB\n-//! fn<'a>('a)            fn('X)                fn('X)                 fn<'a>('a)\n-//! fn('a)                fn('X)                --                     fn<'a>('a)\n-//! fn<'a,'b>('a, 'b)     fn<'x>('x, 'x)        fn<'a>('a, 'a)         fn<'a,'b>('a, 'b)\n-//! fn<'a,'b>('a, 'b, 'a) fn<'x,'y>('x, 'y, 'y) fn<'a>('a, 'a, 'a)     fn<'a,'b,'c>('a,'b,'c)\n-//! ```\n-//!\n-//! ### Conventions\n-//!\n-//! I use lower-case letters (e.g., `&a`) for bound regions and upper-case\n-//! letters for free regions (`&A`).  Region variables written with a\n-//! dollar-sign (e.g., `$a`).  I will try to remember to enumerate the\n-//! bound-regions on the fn type as well (e.g., `for<'a> fn(&a)`).\n-//!\n-//! ### High-level summary\n-//!\n-//! Both the LUB and the GLB algorithms work in a similar fashion.  They\n-//! begin by replacing all bound regions (on both sides) with fresh region\n-//! inference variables.  Therefore, both functions are converted to types\n-//! that contain only free regions.  We can then compute the LUB/GLB in a\n-//! straightforward way, as described in `combine.rs`.  This results in an\n-//! interim type T.  The algorithms then examine the regions that appear\n-//! in T and try to, in some cases, replace them with bound regions to\n-//! yield the final result.\n-//!\n-//! To decide whether to replace a region `R` that appears in `T` with\n-//! a bound region, the algorithms make use of two bits of\n-//! information.  First is a set `V` that contains all region\n-//! variables created as part of the LUB/GLB computation (roughly; see\n-//! `region_vars_confined_to_snapshot()` for full details). `V` will\n-//! contain the region variables created to replace the bound regions\n-//! in the input types, but it also contains 'intermediate' variables\n-//! created to represent the LUB/GLB of individual regions.\n-//! Basically, when asked to compute the LUB/GLB of a region variable\n-//! with another region, the inferencer cannot oblige immediately\n-//! since the values of that variables are not known.  Therefore, it\n-//! creates a new variable that is related to the two regions.  For\n-//! example, the LUB of two variables `$x` and `$y` is a fresh\n-//! variable `$z` that is constrained such that `$x <= $z` and `$y <=\n-//! $z`.  So `V` will contain these intermediate variables as well.\n-//!\n-//! The other important factor in deciding how to replace a region in T is\n-//! the function `Tainted($r)` which, for a region variable, identifies\n-//! all regions that the region variable is related to in some way\n-//! (`Tainted()` made an appearance in the subtype computation as well).\n-//!\n-//! ### LUB\n-//!\n-//! The LUB algorithm proceeds in three steps:\n-//!\n-//! 1. Replace all bound regions (on both sides) with fresh region\n-//!    inference variables.\n-//! 2. Compute the LUB \"as normal\", meaning compute the GLB of each\n-//!    pair of argument types and the LUB of the return types and\n-//!    so forth.  Combine those to a new function type `F`.\n-//! 3. Replace each region `R` that appears in `F` as follows:\n-//!    - Let `V` be the set of variables created during the LUB\n-//!      computational steps 1 and 2, as described in the previous section.\n-//!    - If `R` is not in `V`, replace `R` with itself.\n-//!    - If `Tainted(R)` contains a region that is not in `V`,\n-//!      replace `R` with itself.\n-//!    - Otherwise, select the earliest variable in `Tainted(R)` that originates\n-//!      from the left-hand side and replace `R` with the bound region that\n-//!      this variable was a replacement for.\n-//!\n-//! So, let's work through the simplest example: `fn(&A)` and `for<'a> fn(&a)`.\n-//! In this case, `&a` will be replaced with `$a` and the interim LUB type\n-//! `fn($b)` will be computed, where `$b=GLB(&A,$a)`.  Therefore, `V =\n-//! {$a, $b}` and `Tainted($b) = { $b, $a, &A }`.  When we go to replace\n-//! `$b`, we find that since `&A \\in Tainted($b)` is not a member of `V`,\n-//! we leave `$b` as is.  When region inference happens, `$b` will be\n-//! resolved to `&A`, as we wanted.\n-//!\n-//! Let's look at a more complex one: `fn(&a, &b)` and `fn(&x, &x)`.  In\n-//! this case, we'll end up with a (pre-replacement) LUB type of `fn(&g,\n-//! &h)` and a graph that looks like:\n-//!\n-//! ```\n-//!      $a        $b     *--$x\n-//!        \\        \\    /  /\n-//!         \\        $h-*  /\n-//!          $g-----------*\n-//! ```\n-//!\n-//! Here `$g` and `$h` are fresh variables that are created to represent\n-//! the LUB/GLB of things requiring inference.  This means that `V` and\n-//! `Tainted` will look like:\n-//!\n-//! ```\n-//! V = {$a, $b, $g, $h, $x}\n-//! Tainted($g) = Tainted($h) = { $a, $b, $h, $g, $x }\n-//! ```\n-//!\n-//! Therefore we replace both `$g` and `$h` with `$a`, and end up\n-//! with the type `fn(&a, &a)`.\n-//!\n-//! ### GLB\n-//!\n-//! The procedure for computing the GLB is similar.  The difference lies\n-//! in computing the replacements for the various variables. For each\n-//! region `R` that appears in the type `F`, we again compute `Tainted(R)`\n-//! and examine the results:\n-//!\n-//! 1. If `R` is not in `V`, it is not replaced.\n-//! 2. Else, if `Tainted(R)` contains only variables in `V`, and it\n-//!    contains exactly one variable from the LHS and one variable from\n-//!    the RHS, then `R` can be mapped to the bound version of the\n-//!    variable from the LHS.\n-//! 3. Else, if `Tainted(R)` contains no variable from the LHS and no\n-//!    variable from the RHS, then `R` can be mapped to itself.\n-//! 4. Else, `R` is mapped to a fresh bound variable.\n-//!\n-//! These rules are pretty complex.  Let's look at some examples to see\n-//! how they play out.\n-//!\n-//! Out first example was `fn(&a)` and `fn(&X)`.  In this case, `&a` will\n-//! be replaced with `$a` and we will ultimately compute a\n-//! (pre-replacement) GLB type of `fn($g)` where `$g=LUB($a,&X)`.\n-//! Therefore, `V={$a,$g}` and `Tainted($g)={$g,$a,&X}.  To find the\n-//! replacement for `$g` we consult the rules above:\n-//! - Rule (1) does not apply because `$g \\in V`\n-//! - Rule (2) does not apply because `&X \\in Tainted($g)`\n-//! - Rule (3) does not apply because `$a \\in Tainted($g)`\n-//! - Hence, by rule (4), we replace `$g` with a fresh bound variable `&z`.\n-//! So our final result is `fn(&z)`, which is correct.\n-//!\n-//! The next example is `fn(&A)` and `fn(&Z)`. In this case, we will again\n-//! have a (pre-replacement) GLB of `fn(&g)`, where `$g = LUB(&A,&Z)`.\n-//! Therefore, `V={$g}` and `Tainted($g) = {$g, &A, &Z}`.  In this case,\n-//! by rule (3), `$g` is mapped to itself, and hence the result is\n-//! `fn($g)`.  This result is correct (in this case, at least), but it is\n-//! indicative of a case that *can* lead us into concluding that there is\n-//! no GLB when in fact a GLB does exist.  See the section \"Questionable\n-//! Results\" below for more details.\n-//!\n-//! The next example is `fn(&a, &b)` and `fn(&c, &c)`. In this case, as\n-//! before, we'll end up with `F=fn($g, $h)` where `Tainted($g) =\n-//! Tainted($h) = {$g, $h, $a, $b, $c}`.  Only rule (4) applies and hence\n-//! we'll select fresh bound variables `y` and `z` and wind up with\n-//! `fn(&y, &z)`.\n-//!\n-//! For the last example, let's consider what may seem trivial, but is\n-//! not: `fn(&a, &a)` and `fn(&b, &b)`.  In this case, we'll get `F=fn($g,\n-//! $h)` where `Tainted($g) = {$g, $a, $x}` and `Tainted($h) = {$h, $a,\n-//! $x}`.  Both of these sets contain exactly one bound variable from each\n-//! side, so we'll map them both to `&a`, resulting in `fn(&a, &a)`, which\n-//! is the desired result.\n-//!\n-//! ### Shortcomings and correctness\n-//!\n-//! You may be wondering whether this algorithm is correct.  The answer is\n-//! \"sort of\".  There are definitely cases where they fail to compute a\n-//! result even though a correct result exists.  I believe, though, that\n-//! if they succeed, then the result is valid, and I will attempt to\n-//! convince you.  The basic argument is that the \"pre-replacement\" step\n-//! computes a set of constraints.  The replacements, then, attempt to\n-//! satisfy those constraints, using bound identifiers where needed.\n-//!\n-//! For now I will briefly go over the cases for LUB/GLB and identify\n-//! their intent:\n-//!\n-//! - LUB:\n-//!   - The region variables that are substituted in place of bound regions\n-//!     are intended to collect constraints on those bound regions.\n-//!   - If Tainted(R) contains only values in V, then this region is unconstrained\n-//!     and can therefore be generalized, otherwise it cannot.\n-//! - GLB:\n-//!   - The region variables that are substituted in place of bound regions\n-//!     are intended to collect constraints on those bound regions.\n-//!   - If Tainted(R) contains exactly one variable from each side, and\n-//!     only variables in V, that indicates that those two bound regions\n-//!     must be equated.\n-//!   - Otherwise, if Tainted(R) references any variables from left or right\n-//!     side, then it is trying to combine a bound region with a free one or\n-//!     multiple bound regions, so we need to select fresh bound regions.\n-//!\n-//! Sorry this is more of a shorthand to myself.  I will try to write up something\n-//! more convincing in the future.\n-//!\n-//! #### Where are the algorithms wrong?\n-//!\n-//! - The pre-replacement computation can fail even though using a\n-//!   bound-region would have succeeded.\n-//! - We will compute GLB(fn(fn($a)), fn(fn($b))) as fn($c) where $c is the\n-//!   GLB of $a and $b.  But if inference finds that $a and $b must be mapped\n-//!   to regions without a GLB, then this is effectively a failure to compute\n-//!   the GLB.  However, the result `fn<$c>(fn($c))` is a valid GLB."}, {"sha": "6c987bba389925db596f1624165a19a7a980f0cd", "filename": "src/librustc/middle/infer/mod.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fmod.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! See doc.rs for documentation\n+//! See the Book for more information.\n \n #![allow(non_camel_case_types)]\n \n@@ -46,7 +46,6 @@ use self::unify::{UnificationTable, InferCtxtMethodsForSimplyUnifiableTypes};\n use self::error_reporting::ErrorReporting;\n \n pub mod combine;\n-pub mod doc;\n pub mod equate;\n pub mod error_reporting;\n pub mod glb;"}, {"sha": "a009e0a8234b990008f7ca2304cf8400ac84d51c", "filename": "src/librustc/middle/infer/region_inference/README.md", "status": "added", "additions": 364, "deletions": 0, "changes": 364, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2FREADME.md?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -0,0 +1,364 @@\n+Region inference\n+\n+# Terminology\n+\n+Note that we use the terms region and lifetime interchangeably,\n+though the term `lifetime` is preferred.\n+\n+# Introduction\n+\n+Region inference uses a somewhat more involved algorithm than type\n+inference.  It is not the most efficient thing ever written though it\n+seems to work well enough in practice (famous last words).  The reason\n+that we use a different algorithm is because, unlike with types, it is\n+impractical to hand-annotate with regions (in some cases, there aren't\n+even the requisite syntactic forms).  So we have to get it right, and\n+it's worth spending more time on a more involved analysis.  Moreover,\n+regions are a simpler case than types: they don't have aggregate\n+structure, for example.\n+\n+Unlike normal type inference, which is similar in spirit to H-M and thus\n+works progressively, the region type inference works by accumulating\n+constraints over the course of a function.  Finally, at the end of\n+processing a function, we process and solve the constraints all at\n+once.\n+\n+The constraints are always of one of three possible forms:\n+\n+- ConstrainVarSubVar(R_i, R_j) states that region variable R_i\n+  must be a subregion of R_j\n+- ConstrainRegSubVar(R, R_i) states that the concrete region R\n+  (which must not be a variable) must be a subregion of the variable R_i\n+- ConstrainVarSubReg(R_i, R) is the inverse\n+\n+# Building up the constraints\n+\n+Variables and constraints are created using the following methods:\n+\n+- `new_region_var()` creates a new, unconstrained region variable;\n+- `make_subregion(R_i, R_j)` states that R_i is a subregion of R_j\n+- `lub_regions(R_i, R_j) -> R_k` returns a region R_k which is\n+  the smallest region that is greater than both R_i and R_j\n+- `glb_regions(R_i, R_j) -> R_k` returns a region R_k which is\n+  the greatest region that is smaller than both R_i and R_j\n+\n+The actual region resolution algorithm is not entirely\n+obvious, though it is also not overly complex.\n+\n+## Snapshotting\n+\n+It is also permitted to try (and rollback) changes to the graph.  This\n+is done by invoking `start_snapshot()`, which returns a value.  Then\n+later you can call `rollback_to()` which undoes the work.\n+Alternatively, you can call `commit()` which ends all snapshots.\n+Snapshots can be recursive---so you can start a snapshot when another\n+is in progress, but only the root snapshot can \"commit\".\n+\n+# Resolving constraints\n+\n+The constraint resolution algorithm is not super complex but also not\n+entirely obvious.  Here I describe the problem somewhat abstractly,\n+then describe how the current code works.  There may be other, smarter\n+ways of doing this with which I am unfamiliar and can't be bothered to\n+research at the moment. - NDM\n+\n+## The problem\n+\n+Basically our input is a directed graph where nodes can be divided\n+into two categories: region variables and concrete regions.  Each edge\n+`R -> S` in the graph represents a constraint that the region `R` is a\n+subregion of the region `S`.\n+\n+Region variable nodes can have arbitrary degree.  There is one region\n+variable node per region variable.\n+\n+Each concrete region node is associated with some, well, concrete\n+region: e.g., a free lifetime, or the region for a particular scope.\n+Note that there may be more than one concrete region node for a\n+particular region value.  Moreover, because of how the graph is built,\n+we know that all concrete region nodes have either in-degree 1 or\n+out-degree 1.\n+\n+Before resolution begins, we build up the constraints in a hashmap\n+that maps `Constraint` keys to spans.  During resolution, we construct\n+the actual `Graph` structure that we describe here.\n+\n+## Our current algorithm\n+\n+We divide region variables into two groups: Expanding and Contracting.\n+Expanding region variables are those that have a concrete region\n+predecessor (direct or indirect).  Contracting region variables are\n+all others.\n+\n+We first resolve the values of Expanding region variables and then\n+process Contracting ones.  We currently use an iterative, fixed-point\n+procedure (but read on, I believe this could be replaced with a linear\n+walk).  Basically we iterate over the edges in the graph, ensuring\n+that, if the source of the edge has a value, then this value is a\n+subregion of the target value.  If the target does not yet have a\n+value, it takes the value from the source.  If the target already had\n+a value, then the resulting value is Least Upper Bound of the old and\n+new values. When we are done, each Expanding node will have the\n+smallest region that it could possibly have and still satisfy the\n+constraints.\n+\n+We next process the Contracting nodes.  Here we again iterate over the\n+edges, only this time we move values from target to source (if the\n+source is a Contracting node).  For each contracting node, we compute\n+its value as the GLB of all its successors.  Basically contracting\n+nodes ensure that there is overlap between their successors; we will\n+ultimately infer the largest overlap possible.\n+\n+# The Region Hierarchy\n+\n+## Without closures\n+\n+Let's first consider the region hierarchy without thinking about\n+closures, because they add a lot of complications. The region\n+hierarchy *basically* mirrors the lexical structure of the code.\n+There is a region for every piece of 'evaluation' that occurs, meaning\n+every expression, block, and pattern (patterns are considered to\n+\"execute\" by testing the value they are applied to and creating any\n+relevant bindings).  So, for example:\n+\n+    fn foo(x: int, y: int) { // -+\n+    //  +------------+       //  |\n+    //  |      +-----+       //  |\n+    //  |  +-+ +-+ +-+       //  |\n+    //  |  | | | | | |       //  |\n+    //  v  v v v v v v       //  |\n+        let z = x + y;       //  |\n+        ...                  //  |\n+    }                        // -+\n+\n+    fn bar() { ... }\n+\n+In this example, there is a region for the fn body block as a whole,\n+and then a subregion for the declaration of the local variable.\n+Within that, there are sublifetimes for the assignment pattern and\n+also the expression `x + y`. The expression itself has sublifetimes\n+for evaluating `x` and `y`.\n+\n+## Function calls\n+\n+Function calls are a bit tricky. I will describe how we handle them\n+*now* and then a bit about how we can improve them (Issue #6268).\n+\n+Consider a function call like `func(expr1, expr2)`, where `func`,\n+`arg1`, and `arg2` are all arbitrary expressions. Currently,\n+we construct a region hierarchy like:\n+\n+    +----------------+\n+    |                |\n+    +--+ +---+  +---+|\n+    v  v v   v  v   vv\n+    func(expr1, expr2)\n+\n+Here you can see that the call as a whole has a region and the\n+function plus arguments are subregions of that. As a side-effect of\n+this, we get a lot of spurious errors around nested calls, in\n+particular when combined with `&mut` functions. For example, a call\n+like this one\n+\n+    self.foo(self.bar())\n+\n+where both `foo` and `bar` are `&mut self` functions will always yield\n+an error.\n+\n+Here is a more involved example (which is safe) so we can see what's\n+going on:\n+\n+    struct Foo { f: uint, g: uint }\n+    ...\n+    fn add(p: &mut uint, v: uint) {\n+        *p += v;\n+    }\n+    ...\n+    fn inc(p: &mut uint) -> uint {\n+        *p += 1; *p\n+    }\n+    fn weird() {\n+        let mut x: Box<Foo> = box Foo { ... };\n+        'a: add(&mut (*x).f,\n+                'b: inc(&mut (*x).f)) // (..)\n+    }\n+\n+The important part is the line marked `(..)` which contains a call to\n+`add()`. The first argument is a mutable borrow of the field `f`.  The\n+second argument also borrows the field `f`. Now, in the current borrow\n+checker, the first borrow is given the lifetime of the call to\n+`add()`, `'a`.  The second borrow is given the lifetime of `'b` of the\n+call to `inc()`. Because `'b` is considered to be a sublifetime of\n+`'a`, an error is reported since there are two co-existing mutable\n+borrows of the same data.\n+\n+However, if we were to examine the lifetimes a bit more carefully, we\n+can see that this error is unnecessary. Let's examine the lifetimes\n+involved with `'a` in detail. We'll break apart all the steps involved\n+in a call expression:\n+\n+    'a: {\n+        'a_arg1: let a_temp1: ... = add;\n+        'a_arg2: let a_temp2: &'a mut uint = &'a mut (*x).f;\n+        'a_arg3: let a_temp3: uint = {\n+            let b_temp1: ... = inc;\n+            let b_temp2: &'b = &'b mut (*x).f;\n+            'b_call: b_temp1(b_temp2)\n+        };\n+        'a_call: a_temp1(a_temp2, a_temp3) // (**)\n+    }\n+\n+Here we see that the lifetime `'a` includes a number of substatements.\n+In particular, there is this lifetime I've called `'a_call` that\n+corresponds to the *actual execution of the function `add()`*, after\n+all arguments have been evaluated. There is a corresponding lifetime\n+`'b_call` for the execution of `inc()`. If we wanted to be precise\n+about it, the lifetime of the two borrows should be `'a_call` and\n+`'b_call` respectively, since the references that were created\n+will not be dereferenced except during the execution itself.\n+\n+However, this model by itself is not sound. The reason is that\n+while the two references that are created will never be used\n+simultaneously, it is still true that the first reference is\n+*created* before the second argument is evaluated, and so even though\n+it will not be *dereferenced* during the evaluation of the second\n+argument, it can still be *invalidated* by that evaluation. Consider\n+this similar but unsound example:\n+\n+    struct Foo { f: uint, g: uint }\n+    ...\n+    fn add(p: &mut uint, v: uint) {\n+        *p += v;\n+    }\n+    ...\n+    fn consume(x: Box<Foo>) -> uint {\n+        x.f + x.g\n+    }\n+    fn weird() {\n+        let mut x: Box<Foo> = box Foo { ... };\n+        'a: add(&mut (*x).f, consume(x)) // (..)\n+    }\n+\n+In this case, the second argument to `add` actually consumes `x`, thus\n+invalidating the first argument.\n+\n+So, for now, we exclude the `call` lifetimes from our model.\n+Eventually I would like to include them, but we will have to make the\n+borrow checker handle this situation correctly. In particular, if\n+there is a reference created whose lifetime does not enclose\n+the borrow expression, we must issue sufficient restrictions to ensure\n+that the pointee remains valid.\n+\n+## Adding closures\n+\n+The other significant complication to the region hierarchy is\n+closures. I will describe here how closures should work, though some\n+of the work to implement this model is ongoing at the time of this\n+writing.\n+\n+The body of closures are type-checked along with the function that\n+creates them. However, unlike other expressions that appear within the\n+function body, it is not entirely obvious when a closure body executes\n+with respect to the other expressions. This is because the closure\n+body will execute whenever the closure is called; however, we can\n+never know precisely when the closure will be called, especially\n+without some sort of alias analysis.\n+\n+However, we can place some sort of limits on when the closure\n+executes.  In particular, the type of every closure `fn:'r K` includes\n+a region bound `'r`. This bound indicates the maximum lifetime of that\n+closure; once we exit that region, the closure cannot be called\n+anymore. Therefore, we say that the lifetime of the closure body is a\n+sublifetime of the closure bound, but the closure body itself is unordered\n+with respect to other parts of the code.\n+\n+For example, consider the following fragment of code:\n+\n+    'a: {\n+         let closure: fn:'a() = || 'b: {\n+             'c: ...\n+         };\n+         'd: ...\n+    }\n+\n+Here we have four lifetimes, `'a`, `'b`, `'c`, and `'d`. The closure\n+`closure` is bounded by the lifetime `'a`. The lifetime `'b` is the\n+lifetime of the closure body, and `'c` is some statement within the\n+closure body. Finally, `'d` is a statement within the outer block that\n+created the closure.\n+\n+We can say that the closure body `'b` is a sublifetime of `'a` due to\n+the closure bound. By the usual lexical scoping conventions, the\n+statement `'c` is clearly a sublifetime of `'b`, and `'d` is a\n+sublifetime of `'d`. However, there is no ordering between `'c` and\n+`'d` per se (this kind of ordering between statements is actually only\n+an issue for dataflow; passes like the borrow checker must assume that\n+closures could execute at any time from the moment they are created\n+until they go out of scope).\n+\n+### Complications due to closure bound inference\n+\n+There is only one problem with the above model: in general, we do not\n+actually *know* the closure bounds during region inference! In fact,\n+closure bounds are almost always region variables! This is very tricky\n+because the inference system implicitly assumes that we can do things\n+like compute the LUB of two scoped lifetimes without needing to know\n+the values of any variables.\n+\n+Here is an example to illustrate the problem:\n+\n+    fn identify<T>(x: T) -> T { x }\n+\n+    fn foo() { // 'foo is the function body\n+      'a: {\n+           let closure = identity(|| 'b: {\n+               'c: ...\n+           });\n+           'd: closure();\n+      }\n+      'e: ...;\n+    }\n+\n+In this example, the closure bound is not explicit. At compile time,\n+we will create a region variable (let's call it `V0`) to represent the\n+closure bound.\n+\n+The primary difficulty arises during the constraint propagation phase.\n+Imagine there is some variable with incoming edges from `'c` and `'d`.\n+This means that the value of the variable must be `LUB('c,\n+'d)`. However, without knowing what the closure bound `V0` is, we\n+can't compute the LUB of `'c` and `'d`! Any we don't know the closure\n+bound until inference is done.\n+\n+The solution is to rely on the fixed point nature of inference.\n+Basically, when we must compute `LUB('c, 'd)`, we just use the current\n+value for `V0` as the closure's bound. If `V0`'s binding should\n+change, then we will do another round of inference, and the result of\n+`LUB('c, 'd)` will change.\n+\n+One minor implication of this is that the graph does not in fact track\n+the full set of dependencies between edges. We cannot easily know\n+whether the result of a LUB computation will change, since there may\n+be indirect dependencies on other variables that are not reflected on\n+the graph. Therefore, we must *always* iterate over all edges when\n+doing the fixed point calculation, not just those adjacent to nodes\n+whose values have changed.\n+\n+Were it not for this requirement, we could in fact avoid fixed-point\n+iteration altogether. In that universe, we could instead first\n+identify and remove strongly connected components (SCC) in the graph.\n+Note that such components must consist solely of region variables; all\n+of these variables can effectively be unified into a single variable.\n+Once SCCs are removed, we are left with a DAG.  At this point, we\n+could walk the DAG in topological order once to compute the expanding\n+nodes, and again in reverse topological order to compute the\n+contracting nodes. However, as I said, this does not work given the\n+current treatment of closure bounds, but perhaps in the future we can\n+address this problem somehow and make region inference somewhat more\n+efficient. Note that this is solely a matter of performance, not\n+expressiveness.\n+\n+### Skolemization\n+\n+For a discussion on skolemization and higher-ranked subtyping, please\n+see the module `middle::infer::higher_ranked::doc`."}, {"sha": "2dc46af9084b3548efed004a27c09f1a30aa40f2", "filename": "src/librustc/middle/infer/region_inference/doc.rs", "status": "removed", "additions": 0, "deletions": 374, "changes": 374, "blob_url": "https://github.com/rust-lang/rust/blob/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fdoc.rs?ref=5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "patch": "@@ -1,374 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Region inference module.\n-//!\n-//! # Terminology\n-//!\n-//! Note that we use the terms region and lifetime interchangeably,\n-//! though the term `lifetime` is preferred.\n-//!\n-//! # Introduction\n-//!\n-//! Region inference uses a somewhat more involved algorithm than type\n-//! inference.  It is not the most efficient thing ever written though it\n-//! seems to work well enough in practice (famous last words).  The reason\n-//! that we use a different algorithm is because, unlike with types, it is\n-//! impractical to hand-annotate with regions (in some cases, there aren't\n-//! even the requisite syntactic forms).  So we have to get it right, and\n-//! it's worth spending more time on a more involved analysis.  Moreover,\n-//! regions are a simpler case than types: they don't have aggregate\n-//! structure, for example.\n-//!\n-//! Unlike normal type inference, which is similar in spirit to H-M and thus\n-//! works progressively, the region type inference works by accumulating\n-//! constraints over the course of a function.  Finally, at the end of\n-//! processing a function, we process and solve the constraints all at\n-//! once.\n-//!\n-//! The constraints are always of one of three possible forms:\n-//!\n-//! - ConstrainVarSubVar(R_i, R_j) states that region variable R_i\n-//!   must be a subregion of R_j\n-//! - ConstrainRegSubVar(R, R_i) states that the concrete region R\n-//!   (which must not be a variable) must be a subregion of the variable R_i\n-//! - ConstrainVarSubReg(R_i, R) is the inverse\n-//!\n-//! # Building up the constraints\n-//!\n-//! Variables and constraints are created using the following methods:\n-//!\n-//! - `new_region_var()` creates a new, unconstrained region variable;\n-//! - `make_subregion(R_i, R_j)` states that R_i is a subregion of R_j\n-//! - `lub_regions(R_i, R_j) -> R_k` returns a region R_k which is\n-//!   the smallest region that is greater than both R_i and R_j\n-//! - `glb_regions(R_i, R_j) -> R_k` returns a region R_k which is\n-//!   the greatest region that is smaller than both R_i and R_j\n-//!\n-//! The actual region resolution algorithm is not entirely\n-//! obvious, though it is also not overly complex.\n-//!\n-//! ## Snapshotting\n-//!\n-//! It is also permitted to try (and rollback) changes to the graph.  This\n-//! is done by invoking `start_snapshot()`, which returns a value.  Then\n-//! later you can call `rollback_to()` which undoes the work.\n-//! Alternatively, you can call `commit()` which ends all snapshots.\n-//! Snapshots can be recursive---so you can start a snapshot when another\n-//! is in progress, but only the root snapshot can \"commit\".\n-//!\n-//! # Resolving constraints\n-//!\n-//! The constraint resolution algorithm is not super complex but also not\n-//! entirely obvious.  Here I describe the problem somewhat abstractly,\n-//! then describe how the current code works.  There may be other, smarter\n-//! ways of doing this with which I am unfamiliar and can't be bothered to\n-//! research at the moment. - NDM\n-//!\n-//! ## The problem\n-//!\n-//! Basically our input is a directed graph where nodes can be divided\n-//! into two categories: region variables and concrete regions.  Each edge\n-//! `R -> S` in the graph represents a constraint that the region `R` is a\n-//! subregion of the region `S`.\n-//!\n-//! Region variable nodes can have arbitrary degree.  There is one region\n-//! variable node per region variable.\n-//!\n-//! Each concrete region node is associated with some, well, concrete\n-//! region: e.g., a free lifetime, or the region for a particular scope.\n-//! Note that there may be more than one concrete region node for a\n-//! particular region value.  Moreover, because of how the graph is built,\n-//! we know that all concrete region nodes have either in-degree 1 or\n-//! out-degree 1.\n-//!\n-//! Before resolution begins, we build up the constraints in a hashmap\n-//! that maps `Constraint` keys to spans.  During resolution, we construct\n-//! the actual `Graph` structure that we describe here.\n-//!\n-//! ## Our current algorithm\n-//!\n-//! We divide region variables into two groups: Expanding and Contracting.\n-//! Expanding region variables are those that have a concrete region\n-//! predecessor (direct or indirect).  Contracting region variables are\n-//! all others.\n-//!\n-//! We first resolve the values of Expanding region variables and then\n-//! process Contracting ones.  We currently use an iterative, fixed-point\n-//! procedure (but read on, I believe this could be replaced with a linear\n-//! walk).  Basically we iterate over the edges in the graph, ensuring\n-//! that, if the source of the edge has a value, then this value is a\n-//! subregion of the target value.  If the target does not yet have a\n-//! value, it takes the value from the source.  If the target already had\n-//! a value, then the resulting value is Least Upper Bound of the old and\n-//! new values. When we are done, each Expanding node will have the\n-//! smallest region that it could possibly have and still satisfy the\n-//! constraints.\n-//!\n-//! We next process the Contracting nodes.  Here we again iterate over the\n-//! edges, only this time we move values from target to source (if the\n-//! source is a Contracting node).  For each contracting node, we compute\n-//! its value as the GLB of all its successors.  Basically contracting\n-//! nodes ensure that there is overlap between their successors; we will\n-//! ultimately infer the largest overlap possible.\n-//!\n-//! # The Region Hierarchy\n-//!\n-//! ## Without closures\n-//!\n-//! Let's first consider the region hierarchy without thinking about\n-//! closures, because they add a lot of complications. The region\n-//! hierarchy *basically* mirrors the lexical structure of the code.\n-//! There is a region for every piece of 'evaluation' that occurs, meaning\n-//! every expression, block, and pattern (patterns are considered to\n-//! \"execute\" by testing the value they are applied to and creating any\n-//! relevant bindings).  So, for example:\n-//!\n-//!     fn foo(x: int, y: int) { // -+\n-//!     //  +------------+       //  |\n-//!     //  |      +-----+       //  |\n-//!     //  |  +-+ +-+ +-+       //  |\n-//!     //  |  | | | | | |       //  |\n-//!     //  v  v v v v v v       //  |\n-//!         let z = x + y;       //  |\n-//!         ...                  //  |\n-//!     }                        // -+\n-//!\n-//!     fn bar() { ... }\n-//!\n-//! In this example, there is a region for the fn body block as a whole,\n-//! and then a subregion for the declaration of the local variable.\n-//! Within that, there are sublifetimes for the assignment pattern and\n-//! also the expression `x + y`. The expression itself has sublifetimes\n-//! for evaluating `x` and `y`.\n-//!\n-//! ## Function calls\n-//!\n-//! Function calls are a bit tricky. I will describe how we handle them\n-//! *now* and then a bit about how we can improve them (Issue #6268).\n-//!\n-//! Consider a function call like `func(expr1, expr2)`, where `func`,\n-//! `arg1`, and `arg2` are all arbitrary expressions. Currently,\n-//! we construct a region hierarchy like:\n-//!\n-//!     +----------------+\n-//!     |                |\n-//!     +--+ +---+  +---+|\n-//!     v  v v   v  v   vv\n-//!     func(expr1, expr2)\n-//!\n-//! Here you can see that the call as a whole has a region and the\n-//! function plus arguments are subregions of that. As a side-effect of\n-//! this, we get a lot of spurious errors around nested calls, in\n-//! particular when combined with `&mut` functions. For example, a call\n-//! like this one\n-//!\n-//!     self.foo(self.bar())\n-//!\n-//! where both `foo` and `bar` are `&mut self` functions will always yield\n-//! an error.\n-//!\n-//! Here is a more involved example (which is safe) so we can see what's\n-//! going on:\n-//!\n-//!     struct Foo { f: uint, g: uint }\n-//!     ...\n-//!     fn add(p: &mut uint, v: uint) {\n-//!         *p += v;\n-//!     }\n-//!     ...\n-//!     fn inc(p: &mut uint) -> uint {\n-//!         *p += 1; *p\n-//!     }\n-//!     fn weird() {\n-//!         let mut x: Box<Foo> = box Foo { ... };\n-//!         'a: add(&mut (*x).f,\n-//!                 'b: inc(&mut (*x).f)) // (..)\n-//!     }\n-//!\n-//! The important part is the line marked `(..)` which contains a call to\n-//! `add()`. The first argument is a mutable borrow of the field `f`.  The\n-//! second argument also borrows the field `f`. Now, in the current borrow\n-//! checker, the first borrow is given the lifetime of the call to\n-//! `add()`, `'a`.  The second borrow is given the lifetime of `'b` of the\n-//! call to `inc()`. Because `'b` is considered to be a sublifetime of\n-//! `'a`, an error is reported since there are two co-existing mutable\n-//! borrows of the same data.\n-//!\n-//! However, if we were to examine the lifetimes a bit more carefully, we\n-//! can see that this error is unnecessary. Let's examine the lifetimes\n-//! involved with `'a` in detail. We'll break apart all the steps involved\n-//! in a call expression:\n-//!\n-//!     'a: {\n-//!         'a_arg1: let a_temp1: ... = add;\n-//!         'a_arg2: let a_temp2: &'a mut uint = &'a mut (*x).f;\n-//!         'a_arg3: let a_temp3: uint = {\n-//!             let b_temp1: ... = inc;\n-//!             let b_temp2: &'b = &'b mut (*x).f;\n-//!             'b_call: b_temp1(b_temp2)\n-//!         };\n-//!         'a_call: a_temp1(a_temp2, a_temp3) // (**)\n-//!     }\n-//!\n-//! Here we see that the lifetime `'a` includes a number of substatements.\n-//! In particular, there is this lifetime I've called `'a_call` that\n-//! corresponds to the *actual execution of the function `add()`*, after\n-//! all arguments have been evaluated. There is a corresponding lifetime\n-//! `'b_call` for the execution of `inc()`. If we wanted to be precise\n-//! about it, the lifetime of the two borrows should be `'a_call` and\n-//! `'b_call` respectively, since the references that were created\n-//! will not be dereferenced except during the execution itself.\n-//!\n-//! However, this model by itself is not sound. The reason is that\n-//! while the two references that are created will never be used\n-//! simultaneously, it is still true that the first reference is\n-//! *created* before the second argument is evaluated, and so even though\n-//! it will not be *dereferenced* during the evaluation of the second\n-//! argument, it can still be *invalidated* by that evaluation. Consider\n-//! this similar but unsound example:\n-//!\n-//!     struct Foo { f: uint, g: uint }\n-//!     ...\n-//!     fn add(p: &mut uint, v: uint) {\n-//!         *p += v;\n-//!     }\n-//!     ...\n-//!     fn consume(x: Box<Foo>) -> uint {\n-//!         x.f + x.g\n-//!     }\n-//!     fn weird() {\n-//!         let mut x: Box<Foo> = box Foo { ... };\n-//!         'a: add(&mut (*x).f, consume(x)) // (..)\n-//!     }\n-//!\n-//! In this case, the second argument to `add` actually consumes `x`, thus\n-//! invalidating the first argument.\n-//!\n-//! So, for now, we exclude the `call` lifetimes from our model.\n-//! Eventually I would like to include them, but we will have to make the\n-//! borrow checker handle this situation correctly. In particular, if\n-//! there is a reference created whose lifetime does not enclose\n-//! the borrow expression, we must issue sufficient restrictions to ensure\n-//! that the pointee remains valid.\n-//!\n-//! ## Adding closures\n-//!\n-//! The other significant complication to the region hierarchy is\n-//! closures. I will describe here how closures should work, though some\n-//! of the work to implement this model is ongoing at the time of this\n-//! writing.\n-//!\n-//! The body of closures are type-checked along with the function that\n-//! creates them. However, unlike other expressions that appear within the\n-//! function body, it is not entirely obvious when a closure body executes\n-//! with respect to the other expressions. This is because the closure\n-//! body will execute whenever the closure is called; however, we can\n-//! never know precisely when the closure will be called, especially\n-//! without some sort of alias analysis.\n-//!\n-//! However, we can place some sort of limits on when the closure\n-//! executes.  In particular, the type of every closure `fn:'r K` includes\n-//! a region bound `'r`. This bound indicates the maximum lifetime of that\n-//! closure; once we exit that region, the closure cannot be called\n-//! anymore. Therefore, we say that the lifetime of the closure body is a\n-//! sublifetime of the closure bound, but the closure body itself is unordered\n-//! with respect to other parts of the code.\n-//!\n-//! For example, consider the following fragment of code:\n-//!\n-//!     'a: {\n-//!          let closure: fn:'a() = || 'b: {\n-//!              'c: ...\n-//!          };\n-//!          'd: ...\n-//!     }\n-//!\n-//! Here we have four lifetimes, `'a`, `'b`, `'c`, and `'d`. The closure\n-//! `closure` is bounded by the lifetime `'a`. The lifetime `'b` is the\n-//! lifetime of the closure body, and `'c` is some statement within the\n-//! closure body. Finally, `'d` is a statement within the outer block that\n-//! created the closure.\n-//!\n-//! We can say that the closure body `'b` is a sublifetime of `'a` due to\n-//! the closure bound. By the usual lexical scoping conventions, the\n-//! statement `'c` is clearly a sublifetime of `'b`, and `'d` is a\n-//! sublifetime of `'d`. However, there is no ordering between `'c` and\n-//! `'d` per se (this kind of ordering between statements is actually only\n-//! an issue for dataflow; passes like the borrow checker must assume that\n-//! closures could execute at any time from the moment they are created\n-//! until they go out of scope).\n-//!\n-//! ### Complications due to closure bound inference\n-//!\n-//! There is only one problem with the above model: in general, we do not\n-//! actually *know* the closure bounds during region inference! In fact,\n-//! closure bounds are almost always region variables! This is very tricky\n-//! because the inference system implicitly assumes that we can do things\n-//! like compute the LUB of two scoped lifetimes without needing to know\n-//! the values of any variables.\n-//!\n-//! Here is an example to illustrate the problem:\n-//!\n-//!     fn identify<T>(x: T) -> T { x }\n-//!\n-//!     fn foo() { // 'foo is the function body\n-//!       'a: {\n-//!            let closure = identity(|| 'b: {\n-//!                'c: ...\n-//!            });\n-//!            'd: closure();\n-//!       }\n-//!       'e: ...;\n-//!     }\n-//!\n-//! In this example, the closure bound is not explicit. At compile time,\n-//! we will create a region variable (let's call it `V0`) to represent the\n-//! closure bound.\n-//!\n-//! The primary difficulty arises during the constraint propagation phase.\n-//! Imagine there is some variable with incoming edges from `'c` and `'d`.\n-//! This means that the value of the variable must be `LUB('c,\n-//! 'd)`. However, without knowing what the closure bound `V0` is, we\n-//! can't compute the LUB of `'c` and `'d`! Any we don't know the closure\n-//! bound until inference is done.\n-//!\n-//! The solution is to rely on the fixed point nature of inference.\n-//! Basically, when we must compute `LUB('c, 'd)`, we just use the current\n-//! value for `V0` as the closure's bound. If `V0`'s binding should\n-//! change, then we will do another round of inference, and the result of\n-//! `LUB('c, 'd)` will change.\n-//!\n-//! One minor implication of this is that the graph does not in fact track\n-//! the full set of dependencies between edges. We cannot easily know\n-//! whether the result of a LUB computation will change, since there may\n-//! be indirect dependencies on other variables that are not reflected on\n-//! the graph. Therefore, we must *always* iterate over all edges when\n-//! doing the fixed point calculation, not just those adjacent to nodes\n-//! whose values have changed.\n-//!\n-//! Were it not for this requirement, we could in fact avoid fixed-point\n-//! iteration altogether. In that universe, we could instead first\n-//! identify and remove strongly connected components (SCC) in the graph.\n-//! Note that such components must consist solely of region variables; all\n-//! of these variables can effectively be unified into a single variable.\n-//! Once SCCs are removed, we are left with a DAG.  At this point, we\n-//! could walk the DAG in topological order once to compute the expanding\n-//! nodes, and again in reverse topological order to compute the\n-//! contracting nodes. However, as I said, this does not work given the\n-//! current treatment of closure bounds, but perhaps in the future we can\n-//! address this problem somehow and make region inference somewhat more\n-//! efficient. Note that this is solely a matter of performance, not\n-//! expressiveness.\n-//!\n-//! ### Skolemization\n-//!\n-//! For a discussion on skolemization and higher-ranked subtyping, please\n-//! see the module `middle::infer::higher_ranked::doc`."}, {"sha": "5cdfdcc7c9b6ca8224d744503fe5936b502d7213", "filename": "src/librustc/middle/infer/region_inference/mod.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fmod.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -38,7 +38,6 @@ use std::iter::repeat;\n use std::u32;\n use syntax::ast;\n \n-mod doc;\n mod graphviz;\n \n // A constraint that influences the inference process."}, {"sha": "9c47d7f217aac183d663e3bc3b65b86aa740bc22", "filename": "src/librustc/middle/traits/README.md", "status": "renamed", "additions": 0, "deletions": 14, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Ftraits%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Ftraits%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2FREADME.md?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -1,15 +1,3 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-/*!\n-\n # TRAIT RESOLUTION\n \n This document describes the general process and points out some non-obvious\n@@ -440,5 +428,3 @@ We used to try and draw finer-grained distinctions, but that led to a\n serious of annoying and weird bugs like #22019 and #18290. This simple\n rule seems to be pretty clearly safe and also still retains a very\n high hit rate (~95% when compiling rustc).\n-\n-*/", "previous_filename": "src/librustc/middle/traits/doc.rs"}, {"sha": "83090dd72aa94e33447a77e0e2b66472b1514b4c", "filename": "src/librustc/middle/traits/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Ftraits%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc%2Fmiddle%2Ftraits%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Fmod.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! Trait Resolution. See doc.rs.\n+//! Trait Resolution. See the Book for more.\n \n pub use self::SelectionError::*;\n pub use self::FulfillmentErrorCode::*;"}, {"sha": "c5a304289227117c4840801cc637928790e4f769", "filename": "src/librustc_borrowck/borrowck/README.md", "status": "added", "additions": 1212, "deletions": 0, "changes": 1212, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_borrowck%2Fborrowck%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_borrowck%2Fborrowck%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_borrowck%2Fborrowck%2FREADME.md?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -0,0 +1,1212 @@\n+% The Borrow Checker\n+\n+This pass has the job of enforcing memory safety. This is a subtle\n+topic. This docs aim to explain both the practice and the theory\n+behind the borrow checker. They start with a high-level overview of\n+how it works, and then proceed to dive into the theoretical\n+background. Finally, they go into detail on some of the more subtle\n+aspects.\n+\n+# Table of contents\n+\n+These docs are long. Search for the section you are interested in.\n+\n+- Overview\n+- Formal model\n+- Borrowing and loans\n+- Moves and initialization\n+- Drop flags and structural fragments\n+- Future work\n+\n+# Overview\n+\n+The borrow checker checks one function at a time. It operates in two\n+passes. The first pass, called `gather_loans`, walks over the function\n+and identifies all of the places where borrows (e.g., `&` expressions\n+and `ref` bindings) and moves (copies or captures of a linear value)\n+occur. It also tracks initialization sites. For each borrow and move,\n+it checks various basic safety conditions at this time (for example,\n+that the lifetime of the borrow doesn't exceed the lifetime of the\n+value being borrowed, or that there is no move out of an `&T`\n+referent).\n+\n+It then uses the dataflow module to propagate which of those borrows\n+may be in scope at each point in the procedure. A loan is considered\n+to come into scope at the expression that caused it and to go out of\n+scope when the lifetime of the resulting reference expires.\n+\n+Once the in-scope loans are known for each point in the program, the\n+borrow checker walks the IR again in a second pass called\n+`check_loans`. This pass examines each statement and makes sure that\n+it is safe with respect to the in-scope loans.\n+\n+# Formal model\n+\n+Throughout the docs we'll consider a simple subset of Rust in which\n+you can only borrow from lvalues, defined like so:\n+\n+```text\n+LV = x | LV.f | *LV\n+```\n+\n+Here `x` represents some variable, `LV.f` is a field reference,\n+and `*LV` is a pointer dereference. There is no auto-deref or other\n+niceties. This means that if you have a type like:\n+\n+```text\n+struct S { f: uint }\n+```\n+\n+and a variable `a: Box<S>`, then the rust expression `a.f` would correspond\n+to an `LV` of `(*a).f`.\n+\n+Here is the formal grammar for the types we'll consider:\n+\n+```text\n+TY = () | S<'LT...> | Box<TY> | & 'LT MQ TY\n+MQ = mut | imm | const\n+```\n+\n+Most of these types should be pretty self explanatory. Here `S` is a\n+struct name and we assume structs are declared like so:\n+\n+```text\n+SD = struct S<'LT...> { (f: TY)... }\n+```\n+\n+# Borrowing and loans\n+\n+## An intuitive explanation\n+\n+### Issuing loans\n+\n+Now, imagine we had a program like this:\n+\n+```text\n+struct Foo { f: uint, g: uint }\n+...\n+'a: {\n+  let mut x: Box<Foo> = ...;\n+  let y = &mut (*x).f;\n+  x = ...;\n+}\n+```\n+\n+This is of course dangerous because mutating `x` will free the old\n+value and hence invalidate `y`. The borrow checker aims to prevent\n+this sort of thing.\n+\n+#### Loans and restrictions\n+\n+The way the borrow checker works is that it analyzes each borrow\n+expression (in our simple model, that's stuff like `&LV`, though in\n+real life there are a few other cases to consider). For each borrow\n+expression, it computes a `Loan`, which is a data structure that\n+records (1) the value being borrowed, (2) the mutability and scope of\n+the borrow, and (3) a set of restrictions. In the code, `Loan` is a\n+struct defined in `middle::borrowck`. Formally, we define `LOAN` as\n+follows:\n+\n+```text\n+LOAN = (LV, LT, MQ, RESTRICTION*)\n+RESTRICTION = (LV, ACTION*)\n+ACTION = MUTATE | CLAIM | FREEZE\n+```\n+\n+Here the `LOAN` tuple defines the lvalue `LV` being borrowed; the\n+lifetime `LT` of that borrow; the mutability `MQ` of the borrow; and a\n+list of restrictions. The restrictions indicate actions which, if\n+taken, could invalidate the loan and lead to type safety violations.\n+\n+Each `RESTRICTION` is a pair of a restrictive lvalue `LV` (which will\n+either be the path that was borrowed or some prefix of the path that\n+was borrowed) and a set of restricted actions.  There are three kinds\n+of actions that may be restricted for the path `LV`:\n+\n+- `MUTATE` means that `LV` cannot be assigned to;\n+- `CLAIM` means that the `LV` cannot be borrowed mutably;\n+- `FREEZE` means that the `LV` cannot be borrowed immutably;\n+\n+Finally, it is never possible to move from an lvalue that appears in a\n+restriction. This implies that the \"empty restriction\" `(LV, [])`,\n+which contains an empty set of actions, still has a purpose---it\n+prevents moves from `LV`. I chose not to make `MOVE` a fourth kind of\n+action because that would imply that sometimes moves are permitted\n+from restricted values, which is not the case.\n+\n+#### Example\n+\n+To give you a better feeling for what kind of restrictions derived\n+from a loan, let's look at the loan `L` that would be issued as a\n+result of the borrow `&mut (*x).f` in the example above:\n+\n+```text\n+L = ((*x).f, 'a, mut, RS) where\n+    RS = [((*x).f, [MUTATE, CLAIM, FREEZE]),\n+          (*x, [MUTATE, CLAIM, FREEZE]),\n+          (x, [MUTATE, CLAIM, FREEZE])]\n+```\n+\n+The loan states that the expression `(*x).f` has been loaned as\n+mutable for the lifetime `'a`. Because the loan is mutable, that means\n+that the value `(*x).f` may be mutated via the newly created reference\n+(and *only* via that pointer). This is reflected in the\n+restrictions `RS` that accompany the loan.\n+\n+The first restriction `((*x).f, [MUTATE, CLAIM, FREEZE])` states that\n+the lender may not mutate, freeze, nor alias `(*x).f`. Mutation is\n+illegal because `(*x).f` is only supposed to be mutated via the new\n+reference, not by mutating the original path `(*x).f`. Freezing is\n+illegal because the path now has an `&mut` alias; so even if we the\n+lender were to consider `(*x).f` to be immutable, it might be mutated\n+via this alias. They will be enforced for the lifetime `'a` of the\n+loan. After the loan expires, the restrictions no longer apply.\n+\n+The second restriction on `*x` is interesting because it does not\n+apply to the path that was lent (`(*x).f`) but rather to a prefix of\n+the borrowed path. This is due to the rules of inherited mutability:\n+if the user were to assign to (or freeze) `*x`, they would indirectly\n+overwrite (or freeze) `(*x).f`, and thus invalidate the reference\n+that was created. In general it holds that when a path is\n+lent, restrictions are issued for all the owning prefixes of that\n+path. In this case, the path `*x` owns the path `(*x).f` and,\n+because `x` is an owned pointer, the path `x` owns the path `*x`.\n+Therefore, borrowing `(*x).f` yields restrictions on both\n+`*x` and `x`.\n+\n+### Checking for illegal assignments, moves, and reborrows\n+\n+Once we have computed the loans introduced by each borrow, the borrow\n+checker uses a data flow propagation to compute the full set of loans\n+in scope at each expression and then uses that set to decide whether\n+that expression is legal.  Remember that the scope of loan is defined\n+by its lifetime LT.  We sometimes say that a loan which is in-scope at\n+a particular point is an \"outstanding loan\", and the set of\n+restrictions included in those loans as the \"outstanding\n+restrictions\".\n+\n+The kinds of expressions which in-scope loans can render illegal are:\n+- *assignments* (`lv = v`): illegal if there is an in-scope restriction\n+  against mutating `lv`;\n+- *moves*: illegal if there is any in-scope restriction on `lv` at all;\n+- *mutable borrows* (`&mut lv`): illegal there is an in-scope restriction\n+  against claiming `lv`;\n+- *immutable borrows* (`&lv`): illegal there is an in-scope restriction\n+  against freezing `lv`.\n+\n+## Formal rules\n+\n+Now that we hopefully have some kind of intuitive feeling for how the\n+borrow checker works, let's look a bit more closely now at the precise\n+conditions that it uses. For simplicity I will ignore const loans.\n+\n+I will present the rules in a modified form of standard inference\n+rules, which looks as follows:\n+\n+```text\n+PREDICATE(X, Y, Z)                  // Rule-Name\n+  Condition 1\n+  Condition 2\n+  Condition 3\n+```\n+\n+The initial line states the predicate that is to be satisfied.  The\n+indented lines indicate the conditions that must be met for the\n+predicate to be satisfied. The right-justified comment states the name\n+of this rule: there are comments in the borrowck source referencing\n+these names, so that you can cross reference to find the actual code\n+that corresponds to the formal rule.\n+\n+### Invariants\n+\n+I want to collect, at a high-level, the invariants the borrow checker\n+maintains. I will give them names and refer to them throughout the\n+text. Together these invariants are crucial for the overall soundness\n+of the system.\n+\n+**Mutability requires uniqueness.** To mutate a path\n+\n+**Unique mutability.** There is only one *usable* mutable path to any\n+given memory at any given time. This implies that when claiming memory\n+with an expression like `p = &mut x`, the compiler must guarantee that\n+the borrowed value `x` can no longer be mutated so long as `p` is\n+live. (This is done via restrictions, read on.)\n+\n+**.**\n+\n+\n+### The `gather_loans` pass\n+\n+We start with the `gather_loans` pass, which walks the AST looking for\n+borrows.  For each borrow, there are three bits of information: the\n+lvalue `LV` being borrowed and the mutability `MQ` and lifetime `LT`\n+of the resulting pointer. Given those, `gather_loans` applies four\n+validity tests:\n+\n+1. `MUTABILITY(LV, MQ)`: The mutability of the reference is\n+compatible with the mutability of `LV` (i.e., not borrowing immutable\n+data as mutable).\n+\n+2. `ALIASABLE(LV, MQ)`: The aliasability of the reference is\n+compatible with the aliasability of `LV`. The goal is to prevent\n+`&mut` borrows of aliasability data.\n+\n+3. `LIFETIME(LV, LT, MQ)`: The lifetime of the borrow does not exceed\n+the lifetime of the value being borrowed.\n+\n+4. `RESTRICTIONS(LV, LT, ACTIONS) = RS`: This pass checks and computes the\n+restrictions to maintain memory safety. These are the restrictions\n+that will go into the final loan. We'll discuss in more detail below.\n+\n+## Checking mutability\n+\n+Checking mutability is fairly straightforward. We just want to prevent\n+immutable data from being borrowed as mutable. Note that it is ok to\n+borrow mutable data as immutable, since that is simply a\n+freeze. Formally we define a predicate `MUTABLE(LV, MQ)` which, if\n+defined, means that \"borrowing `LV` with mutability `MQ` is ok. The\n+Rust code corresponding to this predicate is the function\n+`check_mutability` in `middle::borrowck::gather_loans`.\n+\n+### Checking mutability of variables\n+\n+*Code pointer:* Function `check_mutability()` in `gather_loans/mod.rs`,\n+but also the code in `mem_categorization`.\n+\n+Let's begin with the rules for variables, which state that if a\n+variable is declared as mutable, it may be borrowed any which way, but\n+otherwise the variable must be borrowed as immutable or const:\n+\n+```text\n+MUTABILITY(X, MQ)                   // M-Var-Mut\n+  DECL(X) = mut\n+\n+MUTABILITY(X, MQ)                   // M-Var-Imm\n+  DECL(X) = imm\n+  MQ = imm | const\n+```\n+\n+### Checking mutability of owned content\n+\n+Fields and owned pointers inherit their mutability from\n+their base expressions, so both of their rules basically\n+delegate the check to the base expression `LV`:\n+\n+```text\n+MUTABILITY(LV.f, MQ)                // M-Field\n+  MUTABILITY(LV, MQ)\n+\n+MUTABILITY(*LV, MQ)                 // M-Deref-Unique\n+  TYPE(LV) = Box<Ty>\n+  MUTABILITY(LV, MQ)\n+```\n+\n+### Checking mutability of immutable pointer types\n+\n+Immutable pointer types like `&T` can only\n+be borrowed if MQ is immutable or const:\n+\n+```text\n+MUTABILITY(*LV, MQ)                // M-Deref-Borrowed-Imm\n+  TYPE(LV) = &Ty\n+  MQ == imm | const\n+```\n+\n+### Checking mutability of mutable pointer types\n+\n+`&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n+\n+```text\n+MUTABILITY(*LV, MQ)                 // M-Deref-Borrowed-Mut\n+  TYPE(LV) = &mut Ty\n+```\n+\n+## Checking aliasability\n+\n+The goal of the aliasability check is to ensure that we never permit\n+`&mut` borrows of aliasable data. Formally we define a predicate\n+`ALIASABLE(LV, MQ)` which if defined means that\n+\"borrowing `LV` with mutability `MQ` is ok\". The\n+Rust code corresponding to this predicate is the function\n+`check_aliasability()` in `middle::borrowck::gather_loans`.\n+\n+### Checking aliasability of variables\n+\n+Local variables are never aliasable as they are accessible only within\n+the stack frame.\n+\n+```text\n+    ALIASABLE(X, MQ)                   // M-Var-Mut\n+```\n+\n+### Checking aliasable of owned content\n+\n+Owned content is aliasable if it is found in an aliasable location:\n+\n+```text\n+ALIASABLE(LV.f, MQ)                // M-Field\n+  ALIASABLE(LV, MQ)\n+\n+ALIASABLE(*LV, MQ)                 // M-Deref-Unique\n+  ALIASABLE(LV, MQ)\n+```\n+\n+### Checking mutability of immutable pointer types\n+\n+Immutable pointer types like `&T` are aliasable, and hence can only be\n+borrowed immutably:\n+\n+```text\n+ALIASABLE(*LV, imm)                // M-Deref-Borrowed-Imm\n+  TYPE(LV) = &Ty\n+```\n+\n+### Checking mutability of mutable pointer types\n+\n+`&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n+\n+```text\n+ALIASABLE(*LV, MQ)                 // M-Deref-Borrowed-Mut\n+  TYPE(LV) = &mut Ty\n+```\n+\n+## Checking lifetime\n+\n+These rules aim to ensure that no data is borrowed for a scope that exceeds\n+its lifetime. These two computations wind up being intimately related.\n+Formally, we define a predicate `LIFETIME(LV, LT, MQ)`, which states that\n+\"the lvalue `LV` can be safely borrowed for the lifetime `LT` with mutability\n+`MQ`\". The Rust code corresponding to this predicate is the module\n+`middle::borrowck::gather_loans::lifetime`.\n+\n+### The Scope function\n+\n+Several of the rules refer to a helper function `SCOPE(LV)=LT`.  The\n+`SCOPE(LV)` yields the lifetime `LT` for which the lvalue `LV` is\n+guaranteed to exist, presuming that no mutations occur.\n+\n+The scope of a local variable is the block where it is declared:\n+\n+```text\n+  SCOPE(X) = block where X is declared\n+```\n+\n+The scope of a field is the scope of the struct:\n+\n+```text\n+  SCOPE(LV.f) = SCOPE(LV)\n+```\n+\n+The scope of a unique referent is the scope of the pointer, since\n+(barring mutation or moves) the pointer will not be freed until\n+the pointer itself `LV` goes out of scope:\n+\n+```text\n+  SCOPE(*LV) = SCOPE(LV) if LV has type Box<T>\n+```\n+\n+The scope of a borrowed referent is the scope associated with the\n+pointer.  This is a conservative approximation, since the data that\n+the pointer points at may actually live longer:\n+\n+```text\n+  SCOPE(*LV) = LT if LV has type &'LT T or &'LT mut T\n+```\n+\n+### Checking lifetime of variables\n+\n+The rule for variables states that a variable can only be borrowed a\n+lifetime `LT` that is a subregion of the variable's scope:\n+\n+```text\n+LIFETIME(X, LT, MQ)                 // L-Local\n+  LT <= SCOPE(X)\n+```\n+\n+### Checking lifetime for owned content\n+\n+The lifetime of a field or owned pointer is the same as the lifetime\n+of its owner:\n+\n+```text\n+LIFETIME(LV.f, LT, MQ)              // L-Field\n+  LIFETIME(LV, LT, MQ)\n+\n+LIFETIME(*LV, LT, MQ)               // L-Deref-Send\n+  TYPE(LV) = Box<Ty>\n+  LIFETIME(LV, LT, MQ)\n+```\n+\n+### Checking lifetime for derefs of references\n+\n+References have a lifetime `LT'` associated with them.  The\n+data they point at has been guaranteed to be valid for at least this\n+lifetime. Therefore, the borrow is valid so long as the lifetime `LT`\n+of the borrow is shorter than the lifetime `LT'` of the pointer\n+itself:\n+\n+```text\n+LIFETIME(*LV, LT, MQ)               // L-Deref-Borrowed\n+  TYPE(LV) = &LT' Ty OR &LT' mut Ty\n+  LT <= LT'\n+```\n+\n+## Computing the restrictions\n+\n+The final rules govern the computation of *restrictions*, meaning that\n+we compute the set of actions that will be illegal for the life of the\n+loan. The predicate is written `RESTRICTIONS(LV, LT, ACTIONS) =\n+RESTRICTION*`, which can be read \"in order to prevent `ACTIONS` from\n+occurring on `LV`, the restrictions `RESTRICTION*` must be respected\n+for the lifetime of the loan\".\n+\n+Note that there is an initial set of restrictions: these restrictions\n+are computed based on the kind of borrow:\n+\n+```text\n+&mut LV =>   RESTRICTIONS(LV, LT, MUTATE|CLAIM|FREEZE)\n+&LV =>       RESTRICTIONS(LV, LT, MUTATE|CLAIM)\n+&const LV => RESTRICTIONS(LV, LT, [])\n+```\n+\n+The reasoning here is that a mutable borrow must be the only writer,\n+therefore it prevents other writes (`MUTATE`), mutable borrows\n+(`CLAIM`), and immutable borrows (`FREEZE`). An immutable borrow\n+permits other immutable borrows but forbids writes and mutable borrows.\n+Finally, a const borrow just wants to be sure that the value is not\n+moved out from under it, so no actions are forbidden.\n+\n+### Restrictions for loans of a local variable\n+\n+The simplest case is a borrow of a local variable `X`:\n+\n+```text\n+RESTRICTIONS(X, LT, ACTIONS) = (X, ACTIONS)            // R-Variable\n+```\n+\n+In such cases we just record the actions that are not permitted.\n+\n+### Restrictions for loans of fields\n+\n+Restricting a field is the same as restricting the owner of that\n+field:\n+\n+```text\n+RESTRICTIONS(LV.f, LT, ACTIONS) = RS, (LV.f, ACTIONS)  // R-Field\n+  RESTRICTIONS(LV, LT, ACTIONS) = RS\n+```\n+\n+The reasoning here is as follows. If the field must not be mutated,\n+then you must not mutate the owner of the field either, since that\n+would indirectly modify the field. Similarly, if the field cannot be\n+frozen or aliased, we cannot allow the owner to be frozen or aliased,\n+since doing so indirectly freezes/aliases the field. This is the\n+origin of inherited mutability.\n+\n+### Restrictions for loans of owned referents\n+\n+Because the mutability of owned referents is inherited, restricting an\n+owned referent is similar to restricting a field, in that it implies\n+restrictions on the pointer. However, owned pointers have an important\n+twist: if the owner `LV` is mutated, that causes the owned referent\n+`*LV` to be freed! So whenever an owned referent `*LV` is borrowed, we\n+must prevent the owned pointer `LV` from being mutated, which means\n+that we always add `MUTATE` and `CLAIM` to the restriction set imposed\n+on `LV`:\n+\n+```text\n+RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Send-Pointer\n+  TYPE(LV) = Box<Ty>\n+  RESTRICTIONS(LV, LT, ACTIONS|MUTATE|CLAIM) = RS\n+```\n+\n+### Restrictions for loans of immutable borrowed referents\n+\n+Immutable borrowed referents are freely aliasable, meaning that\n+the compiler does not prevent you from copying the pointer.  This\n+implies that issuing restrictions is useless. We might prevent the\n+user from acting on `*LV` itself, but there could be another path\n+`*LV1` that refers to the exact same memory, and we would not be\n+restricting that path. Therefore, the rule for `&Ty` pointers\n+always returns an empty set of restrictions, and it only permits\n+restricting `MUTATE` and `CLAIM` actions:\n+\n+```text\n+RESTRICTIONS(*LV, LT, ACTIONS) = []                    // R-Deref-Imm-Borrowed\n+  TYPE(LV) = &LT' Ty\n+  LT <= LT'                                            // (1)\n+  ACTIONS subset of [MUTATE, CLAIM]\n+```\n+\n+The reason that we can restrict `MUTATE` and `CLAIM` actions even\n+without a restrictions list is that it is never legal to mutate nor to\n+borrow mutably the contents of a `&Ty` pointer. In other words,\n+those restrictions are already inherent in the type.\n+\n+Clause (1) in the rule for `&Ty` deserves mention. Here I\n+specify that the lifetime of the loan must be less than the lifetime\n+of the `&Ty` pointer. In simple cases, this clause is redundant, since\n+the `LIFETIME()` function will already enforce the required rule:\n+\n+```\n+fn foo(point: &'a Point) -> &'static f32 {\n+    &point.x // Error\n+}\n+```\n+\n+The above example fails to compile both because of clause (1) above\n+but also by the basic `LIFETIME()` check. However, in more advanced\n+examples involving multiple nested pointers, clause (1) is needed:\n+\n+```\n+fn foo(point: &'a &'b mut Point) -> &'b f32 {\n+    &point.x // Error\n+}\n+```\n+\n+The `LIFETIME` rule here would accept `'b` because, in fact, the\n+*memory is* guaranteed to remain valid (i.e., not be freed) for the\n+lifetime `'b`, since the `&mut` pointer is valid for `'b`. However, we\n+are returning an immutable reference, so we need the memory to be both\n+valid and immutable. Even though `point.x` is referenced by an `&mut`\n+pointer, it can still be considered immutable so long as that `&mut`\n+pointer is found in an aliased location. That means the memory is\n+guaranteed to be *immutable* for the lifetime of the `&` pointer,\n+which is only `'a`, not `'b`. Hence this example yields an error.\n+\n+As a final twist, consider the case of two nested *immutable*\n+pointers, rather than a mutable pointer within an immutable one:\n+\n+```\n+fn foo(point: &'a &'b Point) -> &'b f32 {\n+    &point.x // OK\n+}\n+```\n+\n+This function is legal. The reason for this is that the inner pointer\n+(`*point : &'b Point`) is enough to guarantee the memory is immutable\n+and valid for the lifetime `'b`.  This is reflected in\n+`RESTRICTIONS()` by the fact that we do not recurse (i.e., we impose\n+no restrictions on `LV`, which in this particular case is the pointer\n+`point : &'a &'b Point`).\n+\n+#### Why both `LIFETIME()` and `RESTRICTIONS()`?\n+\n+Given the previous text, it might seem that `LIFETIME` and\n+`RESTRICTIONS` should be folded together into one check, but there is\n+a reason that they are separated. They answer separate concerns.\n+The rules pertaining to `LIFETIME` exist to ensure that we don't\n+create a borrowed pointer that outlives the memory it points at. So\n+`LIFETIME` prevents a function like this:\n+\n+```\n+fn get_1<'a>() -> &'a int {\n+    let x = 1;\n+    &x\n+}\n+```\n+\n+Here we would be returning a pointer into the stack. Clearly bad.\n+\n+However, the `RESTRICTIONS` rules are more concerned with how memory\n+is used. The example above doesn't generate an error according to\n+`RESTRICTIONS` because, for local variables, we don't require that the\n+loan lifetime be a subset of the local variable lifetime. The idea\n+here is that we *can* guarantee that `x` is not (e.g.) mutated for the\n+lifetime `'a`, even though `'a` exceeds the function body and thus\n+involves unknown code in the caller -- after all, `x` ceases to exist\n+after we return and hence the remaining code in `'a` cannot possibly\n+mutate it. This distinction is important for type checking functions\n+like this one:\n+\n+```\n+fn inc_and_get<'a>(p: &'a mut Point) -> &'a int {\n+    p.x += 1;\n+    &p.x\n+}\n+```\n+\n+In this case, we take in a `&mut` and return a frozen borrowed pointer\n+with the same lifetime. So long as the lifetime of the returned value\n+doesn't exceed the lifetime of the `&mut` we receive as input, this is\n+fine, though it may seem surprising at first (it surprised me when I\n+first worked it through). After all, we're guaranteeing that `*p`\n+won't be mutated for the lifetime `'a`, even though we can't \"see\" the\n+entirety of the code during that lifetime, since some of it occurs in\n+our caller. But we *do* know that nobody can mutate `*p` except\n+through `p`. So if we don't mutate `*p` and we don't return `p`, then\n+we know that the right to mutate `*p` has been lost to our caller --\n+in terms of capability, the caller passed in the ability to mutate\n+`*p`, and we never gave it back. (Note that we can't return `p` while\n+`*p` is borrowed since that would be a move of `p`, as `&mut` pointers\n+are affine.)\n+\n+### Restrictions for loans of const aliasable referents\n+\n+Freeze pointers are read-only. There may be `&mut` or `&` aliases, and\n+we can not prevent *anything* but moves in that case. So the\n+`RESTRICTIONS` function is only defined if `ACTIONS` is the empty set.\n+Because moves from a `&const` lvalue are never legal, it is not\n+necessary to add any restrictions at all to the final result.\n+\n+```text\n+    RESTRICTIONS(*LV, LT, []) = []                // R-Deref-Freeze-Borrowed\n+      TYPE(LV) = &const Ty\n+```\n+\n+### Restrictions for loans of mutable borrowed referents\n+\n+Mutable borrowed pointers are guaranteed to be the only way to mutate\n+their referent. This permits us to take greater license with them; for\n+example, the referent can be frozen simply be ensuring that we do not\n+use the original pointer to perform mutate. Similarly, we can allow\n+the referent to be claimed, so long as the original pointer is unused\n+while the new claimant is live.\n+\n+The rule for mutable borrowed pointers is as follows:\n+\n+```text\n+RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Mut-Borrowed\n+  TYPE(LV) = &LT' mut Ty\n+  LT <= LT'                                            // (1)\n+  RESTRICTIONS(LV, LT, ACTIONS) = RS                   // (2)\n+```\n+\n+Let's examine the two numbered clauses:\n+\n+Clause (1) specifies that the lifetime of the loan (`LT`) cannot\n+exceed the lifetime of the `&mut` pointer (`LT'`). The reason for this\n+is that the `&mut` pointer is guaranteed to be the only legal way to\n+mutate its referent -- but only for the lifetime `LT'`.  After that\n+lifetime, the loan on the referent expires and hence the data may be\n+modified by its owner again. This implies that we are only able to\n+guarantee that the referent will not be modified or aliased for a\n+maximum of `LT'`.\n+\n+Here is a concrete example of a bug this rule prevents:\n+\n+```\n+// Test region-reborrow-from-shorter-mut-ref.rs:\n+fn copy_pointer<'a,'b,T>(x: &'a mut &'b mut T) -> &'b mut T {\n+    &mut **p // ERROR due to clause (1)\n+}\n+fn main() {\n+    let mut x = 1;\n+    let mut y = &mut x; // <-'b-----------------------------+\n+    //      +-'a--------------------+                       |\n+    //      v                       v                       |\n+    let z = copy_borrowed_ptr(&mut y); // y is lent         |\n+    *y += 1; // Here y==z, so both should not be usable...  |\n+    *z += 1; // ...and yet they would be, but for clause 1. |\n+} // <------------------------------------------------------+\n+```\n+\n+Clause (2) propagates the restrictions on the referent to the pointer\n+itself. This is the same as with an owned pointer, though the\n+reasoning is mildly different. The basic goal in all cases is to\n+prevent the user from establishing another route to the same data. To\n+see what I mean, let's examine various cases of what can go wrong and\n+show how it is prevented.\n+\n+**Example danger 1: Moving the base pointer.** One of the simplest\n+ways to violate the rules is to move the base pointer to a new name\n+and access it via that new name, thus bypassing the restrictions on\n+the old name. Here is an example:\n+\n+```\n+// src/test/compile-fail/borrowck-move-mut-base-ptr.rs\n+fn foo(t0: &mut int) {\n+    let p: &int = &*t0; // Freezes `*t0`\n+    let t1 = t0;        //~ ERROR cannot move out of `t0`\n+    *t1 = 22;           // OK, not a write through `*t0`\n+}\n+```\n+\n+Remember that `&mut` pointers are linear, and hence `let t1 = t0` is a\n+move of `t0` -- or would be, if it were legal. Instead, we get an\n+error, because clause (2) imposes restrictions on `LV` (`t0`, here),\n+and any restrictions on a path make it impossible to move from that\n+path.\n+\n+**Example danger 2: Claiming the base pointer.** Another possible\n+danger is to mutably borrow the base path. This can lead to two bad\n+scenarios. The most obvious is that the mutable borrow itself becomes\n+another path to access the same data, as shown here:\n+\n+```\n+// src/test/compile-fail/borrowck-mut-borrow-of-mut-base-ptr.rs\n+fn foo<'a>(mut t0: &'a mut int,\n+           mut t1: &'a mut int) {\n+    let p: &int = &*t0;     // Freezes `*t0`\n+    let mut t2 = &mut t0;   //~ ERROR cannot borrow `t0`\n+    **t2 += 1;              // Mutates `*t0`\n+}\n+```\n+\n+In this example, `**t2` is the same memory as `*t0`. Because `t2` is\n+an `&mut` pointer, `**t2` is a unique path and hence it would be\n+possible to mutate `**t2` even though that memory was supposed to be\n+frozen by the creation of `p`. However, an error is reported -- the\n+reason is that the freeze `&*t0` will restrict claims and mutation\n+against `*t0` which, by clause 2, in turn prevents claims and mutation\n+of `t0`. Hence the claim `&mut t0` is illegal.\n+\n+Another danger with an `&mut` pointer is that we could swap the `t0`\n+value away to create a new path:\n+\n+```\n+// src/test/compile-fail/borrowck-swap-mut-base-ptr.rs\n+fn foo<'a>(mut t0: &'a mut int,\n+           mut t1: &'a mut int) {\n+    let p: &int = &*t0;     // Freezes `*t0`\n+    swap(&mut t0, &mut t1); //~ ERROR cannot borrow `t0`\n+    *t1 = 22;\n+}\n+```\n+\n+This is illegal for the same reason as above. Note that if we added\n+back a swap operator -- as we used to have -- we would want to be very\n+careful to ensure this example is still illegal.\n+\n+**Example danger 3: Freeze the base pointer.** In the case where the\n+referent is claimed, even freezing the base pointer can be dangerous,\n+as shown in the following example:\n+\n+```\n+// src/test/compile-fail/borrowck-borrow-of-mut-base-ptr.rs\n+fn foo<'a>(mut t0: &'a mut int,\n+           mut t1: &'a mut int) {\n+    let p: &mut int = &mut *t0; // Claims `*t0`\n+    let mut t2 = &t0;           //~ ERROR cannot borrow `t0`\n+    let q: &int = &*t2;         // Freezes `*t0` but not through `*p`\n+    *p += 1;                    // violates type of `*q`\n+}\n+```\n+\n+Here the problem is that `*t0` is claimed by `p`, and hence `p` wants\n+to be the controlling pointer through which mutation or freezes occur.\n+But `t2` would -- if it were legal -- have the type `& &mut int`, and\n+hence would be a mutable pointer in an aliasable location, which is\n+considered frozen (since no one can write to `**t2` as it is not a\n+unique path). Therefore, we could reasonably create a frozen `&int`\n+pointer pointing at `*t0` that coexists with the mutable pointer `p`,\n+which is clearly unsound.\n+\n+However, it is not always unsafe to freeze the base pointer. In\n+particular, if the referent is frozen, there is no harm in it:\n+\n+```\n+// src/test/run-pass/borrowck-borrow-of-mut-base-ptr-safe.rs\n+fn foo<'a>(mut t0: &'a mut int,\n+           mut t1: &'a mut int) {\n+    let p: &int = &*t0; // Freezes `*t0`\n+    let mut t2 = &t0;\n+    let q: &int = &*t2; // Freezes `*t0`, but that's ok...\n+    let r: &int = &*t0; // ...after all, could do same thing directly.\n+}\n+```\n+\n+In this case, creating the alias `t2` of `t0` is safe because the only\n+thing `t2` can be used for is to further freeze `*t0`, which is\n+already frozen. In particular, we cannot assign to `*t0` through the\n+new alias `t2`, as demonstrated in this test case:\n+\n+```\n+// src/test/run-pass/borrowck-borrow-mut-base-ptr-in-aliasable-loc.rs\n+fn foo(t0: & &mut int) {\n+    let t1 = t0;\n+    let p: &int = &**t0;\n+    **t1 = 22; //~ ERROR cannot assign\n+}\n+```\n+\n+This distinction is reflected in the rules. When doing an `&mut`\n+borrow -- as in the first example -- the set `ACTIONS` will be\n+`CLAIM|MUTATE|FREEZE`, because claiming the referent implies that it\n+cannot be claimed, mutated, or frozen by anyone else. These\n+restrictions are propagated back to the base path and hence the base\n+path is considered unfreezable.\n+\n+In contrast, when the referent is merely frozen -- as in the second\n+example -- the set `ACTIONS` will be `CLAIM|MUTATE`, because freezing\n+the referent implies that it cannot be claimed or mutated but permits\n+others to freeze. Hence when these restrictions are propagated back to\n+the base path, it will still be considered freezable.\n+\n+\n+\n+**FIXME #10520: Restrictions against mutating the base pointer.** When\n+an `&mut` pointer is frozen or claimed, we currently pass along the\n+restriction against MUTATE to the base pointer. I do not believe this\n+restriction is needed. It dates from the days when we had a way to\n+mutate that preserved the value being mutated (i.e., swap). Nowadays\n+the only form of mutation is assignment, which destroys the pointer\n+being mutated -- therefore, a mutation cannot create a new path to the\n+same data. Rather, it removes an existing path. This implies that not\n+only can we permit mutation, we can have mutation kill restrictions in\n+the dataflow sense.\n+\n+**WARNING:** We do not currently have `const` borrows in the\n+language. If they are added back in, we must ensure that they are\n+consistent with all of these examples. The crucial question will be\n+what sorts of actions are permitted with a `&const &mut` pointer. I\n+would suggest that an `&mut` referent found in an `&const` location be\n+prohibited from both freezes and claims. This would avoid the need to\n+prevent `const` borrows of the base pointer when the referent is\n+borrowed.\n+\n+# Moves and initialization\n+\n+The borrow checker is also in charge of ensuring that:\n+\n+- all memory which is accessed is initialized\n+- immutable local variables are assigned at most once.\n+\n+These are two separate dataflow analyses built on the same\n+framework. Let's look at checking that memory is initialized first;\n+the checking of immutable local variable assignments works in a very\n+similar way.\n+\n+To track the initialization of memory, we actually track all the\n+points in the program that *create uninitialized memory*, meaning\n+moves and the declaration of uninitialized variables. For each of\n+these points, we create a bit in the dataflow set. Assignments to a\n+variable `x` or path `a.b.c` kill the move/uninitialization bits for\n+those paths and any subpaths (e.g., `x`, `x.y`, `a.b.c`, `*a.b.c`).\n+Bits are unioned when two control-flow paths join. Thus, the\n+presence of a bit indicates that the move may have occurred without an\n+intervening assignment to the same memory. At each use of a variable,\n+we examine the bits in scope, and check that none of them are\n+moves/uninitializations of the variable that is being used.\n+\n+Let's look at a simple example:\n+\n+```\n+fn foo(a: Box<int>) {\n+    let b: Box<int>;   // Gen bit 0.\n+\n+    if cond {          // Bits: 0\n+        use(&*a);\n+        b = a;         // Gen bit 1, kill bit 0.\n+        use(&*b);\n+    } else {\n+                       // Bits: 0\n+    }\n+                       // Bits: 0,1\n+    use(&*a);          // Error.\n+    use(&*b);          // Error.\n+}\n+\n+fn use(a: &int) { }\n+```\n+\n+In this example, the variable `b` is created uninitialized. In one\n+branch of an `if`, we then move the variable `a` into `b`. Once we\n+exit the `if`, therefore, it is an error to use `a` or `b` since both\n+are only conditionally initialized. I have annotated the dataflow\n+state using comments. There are two dataflow bits, with bit 0\n+corresponding to the creation of `b` without an initializer, and bit 1\n+corresponding to the move of `a`. The assignment `b = a` both\n+generates bit 1, because it is a move of `a`, and kills bit 0, because\n+`b` is now initialized. On the else branch, though, `b` is never\n+initialized, and so bit 0 remains untouched. When the two flows of\n+control join, we union the bits from both sides, resulting in both\n+bits 0 and 1 being set. Thus any attempt to use `a` uncovers the bit 1\n+from the \"then\" branch, showing that `a` may be moved, and any attempt\n+to use `b` uncovers bit 0, from the \"else\" branch, showing that `b`\n+may not be initialized.\n+\n+## Initialization of immutable variables\n+\n+Initialization of immutable variables works in a very similar way,\n+except that:\n+\n+1. we generate bits for each assignment to a variable;\n+2. the bits are never killed except when the variable goes out of scope.\n+\n+Thus the presence of an assignment bit indicates that the assignment\n+may have occurred. Note that assignments are only killed when the\n+variable goes out of scope, as it is not relevant whether or not there\n+has been a move in the meantime. Using these bits, we can declare that\n+an assignment to an immutable variable is legal iff there is no other\n+assignment bit to that same variable in scope.\n+\n+## Why is the design made this way?\n+\n+It may seem surprising that we assign dataflow bits to *each move*\n+rather than *each path being moved*. This is somewhat less efficient,\n+since on each use, we must iterate through all moves and check whether\n+any of them correspond to the path in question. Similar concerns apply\n+to the analysis for double assignments to immutable variables. The\n+main reason to do it this way is that it allows us to print better\n+error messages, because when a use occurs, we can print out the\n+precise move that may be in scope, rather than simply having to say\n+\"the variable may not be initialized\".\n+\n+## Data structures used in the move analysis\n+\n+The move analysis maintains several data structures that enable it to\n+cross-reference moves and assignments to determine when they may be\n+moving/assigning the same memory. These are all collected into the\n+`MoveData` and `FlowedMoveData` structs. The former represents the set\n+of move paths, moves, and assignments, and the latter adds in the\n+results of a dataflow computation.\n+\n+### Move paths\n+\n+The `MovePath` tree tracks every path that is moved or assigned to.\n+These paths have the same form as the `LoanPath` data structure, which\n+in turn is the \"real world version of the lvalues `LV` that we\n+introduced earlier. The difference between a `MovePath` and a `LoanPath`\n+is that move paths are:\n+\n+1. Canonicalized, so that we have exactly one copy of each, and\n+   we can refer to move paths by index;\n+2. Cross-referenced with other paths into a tree, so that given a move\n+   path we can efficiently find all parent move paths and all\n+   extensions (e.g., given the `a.b` move path, we can easily find the\n+   move path `a` and also the move paths `a.b.c`)\n+3. Cross-referenced with moves and assignments, so that we can\n+   easily find all moves and assignments to a given path.\n+\n+The mechanism that we use is to create a `MovePath` record for each\n+move path. These are arranged in an array and are referenced using\n+`MovePathIndex` values, which are newtype'd indices. The `MovePath`\n+structs are arranged into a tree, representing using the standard\n+Knuth representation where each node has a child 'pointer' and a \"next\n+sibling\" 'pointer'. In addition, each `MovePath` has a parent\n+'pointer'.  In this case, the 'pointers' are just `MovePathIndex`\n+values.\n+\n+In this way, if we want to find all base paths of a given move path,\n+we can just iterate up the parent pointers (see `each_base_path()` in\n+the `move_data` module). If we want to find all extensions, we can\n+iterate through the subtree (see `each_extending_path()`).\n+\n+### Moves and assignments\n+\n+There are structs to represent moves (`Move`) and assignments\n+(`Assignment`), and these are also placed into arrays and referenced\n+by index. All moves of a particular path are arranged into a linked\n+lists, beginning with `MovePath.first_move` and continuing through\n+`Move.next_move`.\n+\n+We distinguish between \"var\" assignments, which are assignments to a\n+variable like `x = foo`, and \"path\" assignments (`x.f = foo`).  This\n+is because we need to assign dataflows to the former, but not the\n+latter, so as to check for double initialization of immutable\n+variables.\n+\n+### Gathering and checking moves\n+\n+Like loans, we distinguish two phases. The first, gathering, is where\n+we uncover all the moves and assignments. As with loans, we do some\n+basic sanity checking in this phase, so we'll report errors if you\n+attempt to move out of a borrowed pointer etc. Then we do the dataflow\n+(see `FlowedMoveData::new`). Finally, in the `check_loans.rs` code, we\n+walk back over, identify all uses, assignments, and captures, and\n+check that they are legal given the set of dataflow bits we have\n+computed for that program point.\n+\n+# Drop flags and structural fragments\n+\n+In addition to the job of enforcing memory safety, the borrow checker\n+code is also responsible for identifying the *structural fragments* of\n+data in the function, to support out-of-band dynamic drop flags\n+allocated on the stack. (For background, see [RFC PR #320].)\n+\n+[RFC PR #320]: https://github.com/rust-lang/rfcs/pull/320\n+\n+Semantically, each piece of data that has a destructor may need a\n+boolean flag to indicate whether or not its destructor has been run\n+yet. However, in many cases there is no need to actually maintain such\n+a flag: It can be apparent from the code itself that a given path is\n+always initialized (or always deinitialized) when control reaches the\n+end of its owner's scope, and thus we can unconditionally emit (or\n+not) the destructor invocation for that path.\n+\n+A simple example of this is the following:\n+\n+```rust\n+struct D { p: int }\n+impl D { fn new(x: int) -> D { ... }\n+impl Drop for D { ... }\n+\n+fn foo(a: D, b: D, t: || -> bool) {\n+    let c: D;\n+    let d: D;\n+    if t() { c = b; }\n+}\n+```\n+\n+At the end of the body of `foo`, the compiler knows that `a` is\n+initialized, introducing a drop obligation (deallocating the boxed\n+integer) for the end of `a`'s scope that is run unconditionally.\n+Likewise the compiler knows that `d` is not initialized, and thus it\n+leave out the drop code for `d`.\n+\n+The compiler cannot statically know the drop-state of `b` nor `c` at\n+the end of their scope, since that depends on the value of\n+`t`. Therefore, we need to insert boolean flags to track whether we\n+need to drop `b` and `c`.\n+\n+However, the matter is not as simple as just mapping local variables\n+to their corresponding drop flags when necessary. In particular, in\n+addition to being able to move data out of local variables, Rust\n+allows one to move values in and out of structured data.\n+\n+Consider the following:\n+\n+```rust\n+struct S { x: D, y: D, z: D }\n+\n+fn foo(a: S, mut b: S, t: || -> bool) {\n+    let mut c: S;\n+    let d: S;\n+    let e: S = a.clone();\n+    if t() {\n+        c = b;\n+        b.x = e.y;\n+    }\n+    if t() { c.y = D::new(4); }\n+}\n+```\n+\n+As before, the drop obligations of `a` and `d` can be statically\n+determined, and again the state of `b` and `c` depend on dynamic\n+state. But additionally, the dynamic drop obligations introduced by\n+`b` and `c` are not just per-local boolean flags. For example, if the\n+first call to `t` returns `false` and the second call `true`, then at\n+the end of their scope, `b` will be completely initialized, but only\n+`c.y` in `c` will be initialized.  If both calls to `t` return `true`,\n+then at the end of their scope, `c` will be completely initialized,\n+but only `b.x` will be initialized in `b`, and only `e.x` and `e.z`\n+will be initialized in `e`.\n+\n+Note that we need to cover the `z` field in each case in some way,\n+since it may (or may not) need to be dropped, even though `z` is never\n+directly mentioned in the body of the `foo` function. We call a path\n+like `b.z` a *fragment sibling* of `b.x`, since the field `z` comes\n+from the same structure `S` that declared the field `x` in `b.x`.\n+\n+In general we need to maintain boolean flags that match the\n+`S`-structure of both `b` and `c`.  In addition, we need to consult\n+such a flag when doing an assignment (such as `c.y = D::new(4);`\n+above), in order to know whether or not there is a previous value that\n+needs to be dropped before we do the assignment.\n+\n+So for any given function, we need to determine what flags are needed\n+to track its drop obligations. Our strategy for determining the set of\n+flags is to represent the fragmentation of the structure explicitly:\n+by starting initially from the paths that are explicitly mentioned in\n+moves and assignments (such as `b.x` and `c.y` above), and then\n+traversing the structure of the path's type to identify leftover\n+*unmoved fragments*: assigning into `c.y` means that `c.x` and `c.z`\n+are leftover unmoved fragments. Each fragment represents a drop\n+obligation that may need to be tracked. Paths that are only moved or\n+assigned in their entirety (like `a` and `d`) are treated as a single\n+drop obligation.\n+\n+The fragment construction process works by piggy-backing on the\n+existing `move_data` module. We already have callbacks that visit each\n+direct move and assignment; these form the basis for the sets of\n+moved_leaf_paths and assigned_leaf_paths. From these leaves, we can\n+walk up their parent chain to identify all of their parent paths.\n+We need to identify the parents because of cases like the following:\n+\n+```rust\n+struct Pair<X,Y>{ x: X, y: Y }\n+fn foo(dd_d_d: Pair<Pair<Pair<D, D>, D>, D>) {\n+    other_function(dd_d_d.x.y);\n+}\n+```\n+\n+In this code, the move of the path `dd_d.x.y` leaves behind not only\n+the fragment drop-obligation `dd_d.x.x` but also `dd_d.y` as well.\n+\n+Once we have identified the directly-referenced leaves and their\n+parents, we compute the left-over fragments, in the function\n+`fragments::add_fragment_siblings`. As of this writing this works by\n+looking at each directly-moved or assigned path P, and blindly\n+gathering all sibling fields of P (as well as siblings for the parents\n+of P, etc). After accumulating all such siblings, we filter out the\n+entries added as siblings of P that turned out to be\n+directly-referenced paths (or parents of directly referenced paths)\n+themselves, thus leaving the never-referenced \"left-overs\" as the only\n+thing left from the gathering step.\n+\n+## Array structural fragments\n+\n+A special case of the structural fragments discussed above are\n+the elements of an array that has been passed by value, such as\n+the following:\n+\n+```rust\n+fn foo(a: [D; 10], i: uint) -> D {\n+    a[i]\n+}\n+```\n+\n+The above code moves a single element out of the input array `a`.\n+The remainder of the array still needs to be dropped; i.e., it\n+is a structural fragment. Note that after performing such a move,\n+it is not legal to read from the array `a`. There are a number of\n+ways to deal with this, but the important thing to note is that\n+the semantics needs to distinguish in some manner between a\n+fragment that is the *entire* array versus a fragment that represents\n+all-but-one element of the array.  A place where that distinction\n+would arise is the following:\n+\n+```rust\n+fn foo(a: [D; 10], b: [D; 10], i: uint, t: bool) -> D {\n+    if t {\n+        a[i]\n+    } else {\n+        b[i]\n+    }\n+\n+    // When control exits, we will need either to drop all of `a`\n+    // and all-but-one of `b`, or to drop all of `b` and all-but-one\n+    // of `a`.\n+}\n+```\n+\n+There are a number of ways that the trans backend could choose to\n+compile this (e.g. a `[bool; 10]` array for each such moved array;\n+or an `Option<uint>` for each moved array).  From the viewpoint of the\n+borrow-checker, the important thing is to record what kind of fragment\n+is implied by the relevant moves.\n+\n+# Future work\n+\n+While writing up these docs, I encountered some rules I believe to be\n+stricter than necessary:\n+\n+- I think restricting the `&mut` LV against moves and `ALIAS` is sufficient,\n+  `MUTATE` and `CLAIM` are overkill. `MUTATE` was necessary when swap was\n+  a built-in operator, but as it is not, it is implied by `CLAIM`,\n+  and `CLAIM` is implied by `ALIAS`. The only net effect of this is an\n+  extra error message in some cases, though.\n+- I have not described how closures interact. Current code is unsound.\n+  I am working on describing and implementing the fix.\n+- If we wish, we can easily extend the move checking to allow finer-grained\n+  tracking of what is initialized and what is not, enabling code like\n+  this:\n+\n+      a = x.f.g; // x.f.g is now uninitialized\n+      // here, x and x.f are not usable, but x.f.h *is*\n+      x.f.g = b; // x.f.g is not initialized\n+      // now x, x.f, x.f.g, x.f.h are all usable\n+\n+  What needs to change here, most likely, is that the `moves` module\n+  should record not only what paths are moved, but what expressions\n+  are actual *uses*. For example, the reference to `x` in `x.f.g = b`\n+  is not a true *use* in the sense that it requires `x` to be fully\n+  initialized. This is in fact why the above code produces an error\n+  today: the reference to `x` in `x.f.g = b` is considered illegal\n+  because `x` is not fully initialized.\n+\n+There are also some possible refactorings:\n+\n+- It might be nice to replace all loan paths with the MovePath mechanism,\n+  since they allow lightweight comparison using an integer."}, {"sha": "682a5f2f5ace6d28232772f48d0bca01baac3f2a", "filename": "src/librustc_borrowck/borrowck/doc.rs", "status": "removed", "additions": 0, "deletions": 1222, "changes": 1222, "blob_url": "https://github.com/rust-lang/rust/blob/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc_borrowck%2Fborrowck%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc_borrowck%2Fborrowck%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_borrowck%2Fborrowck%2Fdoc.rs?ref=5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "patch": "@@ -1,1222 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # The Borrow Checker\n-//!\n-//! This pass has the job of enforcing memory safety. This is a subtle\n-//! topic. This docs aim to explain both the practice and the theory\n-//! behind the borrow checker. They start with a high-level overview of\n-//! how it works, and then proceed to dive into the theoretical\n-//! background. Finally, they go into detail on some of the more subtle\n-//! aspects.\n-//!\n-//! # Table of contents\n-//!\n-//! These docs are long. Search for the section you are interested in.\n-//!\n-//! - Overview\n-//! - Formal model\n-//! - Borrowing and loans\n-//! - Moves and initialization\n-//! - Drop flags and structural fragments\n-//! - Future work\n-//!\n-//! # Overview\n-//!\n-//! The borrow checker checks one function at a time. It operates in two\n-//! passes. The first pass, called `gather_loans`, walks over the function\n-//! and identifies all of the places where borrows (e.g., `&` expressions\n-//! and `ref` bindings) and moves (copies or captures of a linear value)\n-//! occur. It also tracks initialization sites. For each borrow and move,\n-//! it checks various basic safety conditions at this time (for example,\n-//! that the lifetime of the borrow doesn't exceed the lifetime of the\n-//! value being borrowed, or that there is no move out of an `&T`\n-//! referent).\n-//!\n-//! It then uses the dataflow module to propagate which of those borrows\n-//! may be in scope at each point in the procedure. A loan is considered\n-//! to come into scope at the expression that caused it and to go out of\n-//! scope when the lifetime of the resulting reference expires.\n-//!\n-//! Once the in-scope loans are known for each point in the program, the\n-//! borrow checker walks the IR again in a second pass called\n-//! `check_loans`. This pass examines each statement and makes sure that\n-//! it is safe with respect to the in-scope loans.\n-//!\n-//! # Formal model\n-//!\n-//! Throughout the docs we'll consider a simple subset of Rust in which\n-//! you can only borrow from lvalues, defined like so:\n-//!\n-//! ```text\n-//! LV = x | LV.f | *LV\n-//! ```\n-//!\n-//! Here `x` represents some variable, `LV.f` is a field reference,\n-//! and `*LV` is a pointer dereference. There is no auto-deref or other\n-//! niceties. This means that if you have a type like:\n-//!\n-//! ```text\n-//! struct S { f: uint }\n-//! ```\n-//!\n-//! and a variable `a: Box<S>`, then the rust expression `a.f` would correspond\n-//! to an `LV` of `(*a).f`.\n-//!\n-//! Here is the formal grammar for the types we'll consider:\n-//!\n-//! ```text\n-//! TY = () | S<'LT...> | Box<TY> | & 'LT MQ TY\n-//! MQ = mut | imm | const\n-//! ```\n-//!\n-//! Most of these types should be pretty self explanatory. Here `S` is a\n-//! struct name and we assume structs are declared like so:\n-//!\n-//! ```text\n-//! SD = struct S<'LT...> { (f: TY)... }\n-//! ```\n-//!\n-//! # Borrowing and loans\n-//!\n-//! ## An intuitive explanation\n-//!\n-//! ### Issuing loans\n-//!\n-//! Now, imagine we had a program like this:\n-//!\n-//! ```text\n-//! struct Foo { f: uint, g: uint }\n-//! ...\n-//! 'a: {\n-//!   let mut x: Box<Foo> = ...;\n-//!   let y = &mut (*x).f;\n-//!   x = ...;\n-//! }\n-//! ```\n-//!\n-//! This is of course dangerous because mutating `x` will free the old\n-//! value and hence invalidate `y`. The borrow checker aims to prevent\n-//! this sort of thing.\n-//!\n-//! #### Loans and restrictions\n-//!\n-//! The way the borrow checker works is that it analyzes each borrow\n-//! expression (in our simple model, that's stuff like `&LV`, though in\n-//! real life there are a few other cases to consider). For each borrow\n-//! expression, it computes a `Loan`, which is a data structure that\n-//! records (1) the value being borrowed, (2) the mutability and scope of\n-//! the borrow, and (3) a set of restrictions. In the code, `Loan` is a\n-//! struct defined in `middle::borrowck`. Formally, we define `LOAN` as\n-//! follows:\n-//!\n-//! ```text\n-//! LOAN = (LV, LT, MQ, RESTRICTION*)\n-//! RESTRICTION = (LV, ACTION*)\n-//! ACTION = MUTATE | CLAIM | FREEZE\n-//! ```\n-//!\n-//! Here the `LOAN` tuple defines the lvalue `LV` being borrowed; the\n-//! lifetime `LT` of that borrow; the mutability `MQ` of the borrow; and a\n-//! list of restrictions. The restrictions indicate actions which, if\n-//! taken, could invalidate the loan and lead to type safety violations.\n-//!\n-//! Each `RESTRICTION` is a pair of a restrictive lvalue `LV` (which will\n-//! either be the path that was borrowed or some prefix of the path that\n-//! was borrowed) and a set of restricted actions.  There are three kinds\n-//! of actions that may be restricted for the path `LV`:\n-//!\n-//! - `MUTATE` means that `LV` cannot be assigned to;\n-//! - `CLAIM` means that the `LV` cannot be borrowed mutably;\n-//! - `FREEZE` means that the `LV` cannot be borrowed immutably;\n-//!\n-//! Finally, it is never possible to move from an lvalue that appears in a\n-//! restriction. This implies that the \"empty restriction\" `(LV, [])`,\n-//! which contains an empty set of actions, still has a purpose---it\n-//! prevents moves from `LV`. I chose not to make `MOVE` a fourth kind of\n-//! action because that would imply that sometimes moves are permitted\n-//! from restricted values, which is not the case.\n-//!\n-//! #### Example\n-//!\n-//! To give you a better feeling for what kind of restrictions derived\n-//! from a loan, let's look at the loan `L` that would be issued as a\n-//! result of the borrow `&mut (*x).f` in the example above:\n-//!\n-//! ```text\n-//! L = ((*x).f, 'a, mut, RS) where\n-//!     RS = [((*x).f, [MUTATE, CLAIM, FREEZE]),\n-//!           (*x, [MUTATE, CLAIM, FREEZE]),\n-//!           (x, [MUTATE, CLAIM, FREEZE])]\n-//! ```\n-//!\n-//! The loan states that the expression `(*x).f` has been loaned as\n-//! mutable for the lifetime `'a`. Because the loan is mutable, that means\n-//! that the value `(*x).f` may be mutated via the newly created reference\n-//! (and *only* via that pointer). This is reflected in the\n-//! restrictions `RS` that accompany the loan.\n-//!\n-//! The first restriction `((*x).f, [MUTATE, CLAIM, FREEZE])` states that\n-//! the lender may not mutate, freeze, nor alias `(*x).f`. Mutation is\n-//! illegal because `(*x).f` is only supposed to be mutated via the new\n-//! reference, not by mutating the original path `(*x).f`. Freezing is\n-//! illegal because the path now has an `&mut` alias; so even if we the\n-//! lender were to consider `(*x).f` to be immutable, it might be mutated\n-//! via this alias. They will be enforced for the lifetime `'a` of the\n-//! loan. After the loan expires, the restrictions no longer apply.\n-//!\n-//! The second restriction on `*x` is interesting because it does not\n-//! apply to the path that was lent (`(*x).f`) but rather to a prefix of\n-//! the borrowed path. This is due to the rules of inherited mutability:\n-//! if the user were to assign to (or freeze) `*x`, they would indirectly\n-//! overwrite (or freeze) `(*x).f`, and thus invalidate the reference\n-//! that was created. In general it holds that when a path is\n-//! lent, restrictions are issued for all the owning prefixes of that\n-//! path. In this case, the path `*x` owns the path `(*x).f` and,\n-//! because `x` is an owned pointer, the path `x` owns the path `*x`.\n-//! Therefore, borrowing `(*x).f` yields restrictions on both\n-//! `*x` and `x`.\n-//!\n-//! ### Checking for illegal assignments, moves, and reborrows\n-//!\n-//! Once we have computed the loans introduced by each borrow, the borrow\n-//! checker uses a data flow propagation to compute the full set of loans\n-//! in scope at each expression and then uses that set to decide whether\n-//! that expression is legal.  Remember that the scope of loan is defined\n-//! by its lifetime LT.  We sometimes say that a loan which is in-scope at\n-//! a particular point is an \"outstanding loan\", and the set of\n-//! restrictions included in those loans as the \"outstanding\n-//! restrictions\".\n-//!\n-//! The kinds of expressions which in-scope loans can render illegal are:\n-//! - *assignments* (`lv = v`): illegal if there is an in-scope restriction\n-//!   against mutating `lv`;\n-//! - *moves*: illegal if there is any in-scope restriction on `lv` at all;\n-//! - *mutable borrows* (`&mut lv`): illegal there is an in-scope restriction\n-//!   against claiming `lv`;\n-//! - *immutable borrows* (`&lv`): illegal there is an in-scope restriction\n-//!   against freezing `lv`.\n-//!\n-//! ## Formal rules\n-//!\n-//! Now that we hopefully have some kind of intuitive feeling for how the\n-//! borrow checker works, let's look a bit more closely now at the precise\n-//! conditions that it uses. For simplicity I will ignore const loans.\n-//!\n-//! I will present the rules in a modified form of standard inference\n-//! rules, which looks as follows:\n-//!\n-//! ```text\n-//! PREDICATE(X, Y, Z)                  // Rule-Name\n-//!   Condition 1\n-//!   Condition 2\n-//!   Condition 3\n-//! ```\n-//!\n-//! The initial line states the predicate that is to be satisfied.  The\n-//! indented lines indicate the conditions that must be met for the\n-//! predicate to be satisfied. The right-justified comment states the name\n-//! of this rule: there are comments in the borrowck source referencing\n-//! these names, so that you can cross reference to find the actual code\n-//! that corresponds to the formal rule.\n-//!\n-//! ### Invariants\n-//!\n-//! I want to collect, at a high-level, the invariants the borrow checker\n-//! maintains. I will give them names and refer to them throughout the\n-//! text. Together these invariants are crucial for the overall soundness\n-//! of the system.\n-//!\n-//! **Mutability requires uniqueness.** To mutate a path\n-//!\n-//! **Unique mutability.** There is only one *usable* mutable path to any\n-//! given memory at any given time. This implies that when claiming memory\n-//! with an expression like `p = &mut x`, the compiler must guarantee that\n-//! the borrowed value `x` can no longer be mutated so long as `p` is\n-//! live. (This is done via restrictions, read on.)\n-//!\n-//! **.**\n-//!\n-//!\n-//! ### The `gather_loans` pass\n-//!\n-//! We start with the `gather_loans` pass, which walks the AST looking for\n-//! borrows.  For each borrow, there are three bits of information: the\n-//! lvalue `LV` being borrowed and the mutability `MQ` and lifetime `LT`\n-//! of the resulting pointer. Given those, `gather_loans` applies four\n-//! validity tests:\n-//!\n-//! 1. `MUTABILITY(LV, MQ)`: The mutability of the reference is\n-//! compatible with the mutability of `LV` (i.e., not borrowing immutable\n-//! data as mutable).\n-//!\n-//! 2. `ALIASABLE(LV, MQ)`: The aliasability of the reference is\n-//! compatible with the aliasability of `LV`. The goal is to prevent\n-//! `&mut` borrows of aliasability data.\n-//!\n-//! 3. `LIFETIME(LV, LT, MQ)`: The lifetime of the borrow does not exceed\n-//! the lifetime of the value being borrowed.\n-//!\n-//! 4. `RESTRICTIONS(LV, LT, ACTIONS) = RS`: This pass checks and computes the\n-//! restrictions to maintain memory safety. These are the restrictions\n-//! that will go into the final loan. We'll discuss in more detail below.\n-//!\n-//! ## Checking mutability\n-//!\n-//! Checking mutability is fairly straightforward. We just want to prevent\n-//! immutable data from being borrowed as mutable. Note that it is ok to\n-//! borrow mutable data as immutable, since that is simply a\n-//! freeze. Formally we define a predicate `MUTABLE(LV, MQ)` which, if\n-//! defined, means that \"borrowing `LV` with mutability `MQ` is ok. The\n-//! Rust code corresponding to this predicate is the function\n-//! `check_mutability` in `middle::borrowck::gather_loans`.\n-//!\n-//! ### Checking mutability of variables\n-//!\n-//! *Code pointer:* Function `check_mutability()` in `gather_loans/mod.rs`,\n-//! but also the code in `mem_categorization`.\n-//!\n-//! Let's begin with the rules for variables, which state that if a\n-//! variable is declared as mutable, it may be borrowed any which way, but\n-//! otherwise the variable must be borrowed as immutable or const:\n-//!\n-//! ```text\n-//! MUTABILITY(X, MQ)                   // M-Var-Mut\n-//!   DECL(X) = mut\n-//!\n-//! MUTABILITY(X, MQ)                   // M-Var-Imm\n-//!   DECL(X) = imm\n-//!   MQ = imm | const\n-//! ```\n-//!\n-//! ### Checking mutability of owned content\n-//!\n-//! Fields and owned pointers inherit their mutability from\n-//! their base expressions, so both of their rules basically\n-//! delegate the check to the base expression `LV`:\n-//!\n-//! ```text\n-//! MUTABILITY(LV.f, MQ)                // M-Field\n-//!   MUTABILITY(LV, MQ)\n-//!\n-//! MUTABILITY(*LV, MQ)                 // M-Deref-Unique\n-//!   TYPE(LV) = Box<Ty>\n-//!   MUTABILITY(LV, MQ)\n-//! ```\n-//!\n-//! ### Checking mutability of immutable pointer types\n-//!\n-//! Immutable pointer types like `&T` can only\n-//! be borrowed if MQ is immutable or const:\n-//!\n-//! ```text\n-//! MUTABILITY(*LV, MQ)                // M-Deref-Borrowed-Imm\n-//!   TYPE(LV) = &Ty\n-//!   MQ == imm | const\n-//! ```\n-//!\n-//! ### Checking mutability of mutable pointer types\n-//!\n-//! `&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n-//!\n-//! ```text\n-//! MUTABILITY(*LV, MQ)                 // M-Deref-Borrowed-Mut\n-//!   TYPE(LV) = &mut Ty\n-//! ```\n-//!\n-//! ## Checking aliasability\n-//!\n-//! The goal of the aliasability check is to ensure that we never permit\n-//! `&mut` borrows of aliasable data. Formally we define a predicate\n-//! `ALIASABLE(LV, MQ)` which if defined means that\n-//! \"borrowing `LV` with mutability `MQ` is ok\". The\n-//! Rust code corresponding to this predicate is the function\n-//! `check_aliasability()` in `middle::borrowck::gather_loans`.\n-//!\n-//! ### Checking aliasability of variables\n-//!\n-//! Local variables are never aliasable as they are accessible only within\n-//! the stack frame.\n-//!\n-//! ```text\n-//!     ALIASABLE(X, MQ)                   // M-Var-Mut\n-//! ```\n-//!\n-//! ### Checking aliasable of owned content\n-//!\n-//! Owned content is aliasable if it is found in an aliasable location:\n-//!\n-//! ```text\n-//! ALIASABLE(LV.f, MQ)                // M-Field\n-//!   ALIASABLE(LV, MQ)\n-//!\n-//! ALIASABLE(*LV, MQ)                 // M-Deref-Unique\n-//!   ALIASABLE(LV, MQ)\n-//! ```\n-//!\n-//! ### Checking mutability of immutable pointer types\n-//!\n-//! Immutable pointer types like `&T` are aliasable, and hence can only be\n-//! borrowed immutably:\n-//!\n-//! ```text\n-//! ALIASABLE(*LV, imm)                // M-Deref-Borrowed-Imm\n-//!   TYPE(LV) = &Ty\n-//! ```\n-//!\n-//! ### Checking mutability of mutable pointer types\n-//!\n-//! `&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n-//!\n-//! ```text\n-//! ALIASABLE(*LV, MQ)                 // M-Deref-Borrowed-Mut\n-//!   TYPE(LV) = &mut Ty\n-//! ```\n-//!\n-//! ## Checking lifetime\n-//!\n-//! These rules aim to ensure that no data is borrowed for a scope that exceeds\n-//! its lifetime. These two computations wind up being intimately related.\n-//! Formally, we define a predicate `LIFETIME(LV, LT, MQ)`, which states that\n-//! \"the lvalue `LV` can be safely borrowed for the lifetime `LT` with mutability\n-//! `MQ`\". The Rust code corresponding to this predicate is the module\n-//! `middle::borrowck::gather_loans::lifetime`.\n-//!\n-//! ### The Scope function\n-//!\n-//! Several of the rules refer to a helper function `SCOPE(LV)=LT`.  The\n-//! `SCOPE(LV)` yields the lifetime `LT` for which the lvalue `LV` is\n-//! guaranteed to exist, presuming that no mutations occur.\n-//!\n-//! The scope of a local variable is the block where it is declared:\n-//!\n-//! ```text\n-//!   SCOPE(X) = block where X is declared\n-//! ```\n-//!\n-//! The scope of a field is the scope of the struct:\n-//!\n-//! ```text\n-//!   SCOPE(LV.f) = SCOPE(LV)\n-//! ```\n-//!\n-//! The scope of a unique referent is the scope of the pointer, since\n-//! (barring mutation or moves) the pointer will not be freed until\n-//! the pointer itself `LV` goes out of scope:\n-//!\n-//! ```text\n-//!   SCOPE(*LV) = SCOPE(LV) if LV has type Box<T>\n-//! ```\n-//!\n-//! The scope of a borrowed referent is the scope associated with the\n-//! pointer.  This is a conservative approximation, since the data that\n-//! the pointer points at may actually live longer:\n-//!\n-//! ```text\n-//!   SCOPE(*LV) = LT if LV has type &'LT T or &'LT mut T\n-//! ```\n-//!\n-//! ### Checking lifetime of variables\n-//!\n-//! The rule for variables states that a variable can only be borrowed a\n-//! lifetime `LT` that is a subregion of the variable's scope:\n-//!\n-//! ```text\n-//! LIFETIME(X, LT, MQ)                 // L-Local\n-//!   LT <= SCOPE(X)\n-//! ```\n-//!\n-//! ### Checking lifetime for owned content\n-//!\n-//! The lifetime of a field or owned pointer is the same as the lifetime\n-//! of its owner:\n-//!\n-//! ```text\n-//! LIFETIME(LV.f, LT, MQ)              // L-Field\n-//!   LIFETIME(LV, LT, MQ)\n-//!\n-//! LIFETIME(*LV, LT, MQ)               // L-Deref-Send\n-//!   TYPE(LV) = Box<Ty>\n-//!   LIFETIME(LV, LT, MQ)\n-//! ```\n-//!\n-//! ### Checking lifetime for derefs of references\n-//!\n-//! References have a lifetime `LT'` associated with them.  The\n-//! data they point at has been guaranteed to be valid for at least this\n-//! lifetime. Therefore, the borrow is valid so long as the lifetime `LT`\n-//! of the borrow is shorter than the lifetime `LT'` of the pointer\n-//! itself:\n-//!\n-//! ```text\n-//! LIFETIME(*LV, LT, MQ)               // L-Deref-Borrowed\n-//!   TYPE(LV) = &LT' Ty OR &LT' mut Ty\n-//!   LT <= LT'\n-//! ```\n-//!\n-//! ## Computing the restrictions\n-//!\n-//! The final rules govern the computation of *restrictions*, meaning that\n-//! we compute the set of actions that will be illegal for the life of the\n-//! loan. The predicate is written `RESTRICTIONS(LV, LT, ACTIONS) =\n-//! RESTRICTION*`, which can be read \"in order to prevent `ACTIONS` from\n-//! occurring on `LV`, the restrictions `RESTRICTION*` must be respected\n-//! for the lifetime of the loan\".\n-//!\n-//! Note that there is an initial set of restrictions: these restrictions\n-//! are computed based on the kind of borrow:\n-//!\n-//! ```text\n-//! &mut LV =>   RESTRICTIONS(LV, LT, MUTATE|CLAIM|FREEZE)\n-//! &LV =>       RESTRICTIONS(LV, LT, MUTATE|CLAIM)\n-//! &const LV => RESTRICTIONS(LV, LT, [])\n-//! ```\n-//!\n-//! The reasoning here is that a mutable borrow must be the only writer,\n-//! therefore it prevents other writes (`MUTATE`), mutable borrows\n-//! (`CLAIM`), and immutable borrows (`FREEZE`). An immutable borrow\n-//! permits other immutable borrows but forbids writes and mutable borrows.\n-//! Finally, a const borrow just wants to be sure that the value is not\n-//! moved out from under it, so no actions are forbidden.\n-//!\n-//! ### Restrictions for loans of a local variable\n-//!\n-//! The simplest case is a borrow of a local variable `X`:\n-//!\n-//! ```text\n-//! RESTRICTIONS(X, LT, ACTIONS) = (X, ACTIONS)            // R-Variable\n-//! ```\n-//!\n-//! In such cases we just record the actions that are not permitted.\n-//!\n-//! ### Restrictions for loans of fields\n-//!\n-//! Restricting a field is the same as restricting the owner of that\n-//! field:\n-//!\n-//! ```text\n-//! RESTRICTIONS(LV.f, LT, ACTIONS) = RS, (LV.f, ACTIONS)  // R-Field\n-//!   RESTRICTIONS(LV, LT, ACTIONS) = RS\n-//! ```\n-//!\n-//! The reasoning here is as follows. If the field must not be mutated,\n-//! then you must not mutate the owner of the field either, since that\n-//! would indirectly modify the field. Similarly, if the field cannot be\n-//! frozen or aliased, we cannot allow the owner to be frozen or aliased,\n-//! since doing so indirectly freezes/aliases the field. This is the\n-//! origin of inherited mutability.\n-//!\n-//! ### Restrictions for loans of owned referents\n-//!\n-//! Because the mutability of owned referents is inherited, restricting an\n-//! owned referent is similar to restricting a field, in that it implies\n-//! restrictions on the pointer. However, owned pointers have an important\n-//! twist: if the owner `LV` is mutated, that causes the owned referent\n-//! `*LV` to be freed! So whenever an owned referent `*LV` is borrowed, we\n-//! must prevent the owned pointer `LV` from being mutated, which means\n-//! that we always add `MUTATE` and `CLAIM` to the restriction set imposed\n-//! on `LV`:\n-//!\n-//! ```text\n-//! RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Send-Pointer\n-//!   TYPE(LV) = Box<Ty>\n-//!   RESTRICTIONS(LV, LT, ACTIONS|MUTATE|CLAIM) = RS\n-//! ```\n-//!\n-//! ### Restrictions for loans of immutable borrowed referents\n-//!\n-//! Immutable borrowed referents are freely aliasable, meaning that\n-//! the compiler does not prevent you from copying the pointer.  This\n-//! implies that issuing restrictions is useless. We might prevent the\n-//! user from acting on `*LV` itself, but there could be another path\n-//! `*LV1` that refers to the exact same memory, and we would not be\n-//! restricting that path. Therefore, the rule for `&Ty` pointers\n-//! always returns an empty set of restrictions, and it only permits\n-//! restricting `MUTATE` and `CLAIM` actions:\n-//!\n-//! ```text\n-//! RESTRICTIONS(*LV, LT, ACTIONS) = []                    // R-Deref-Imm-Borrowed\n-//!   TYPE(LV) = &LT' Ty\n-//!   LT <= LT'                                            // (1)\n-//!   ACTIONS subset of [MUTATE, CLAIM]\n-//! ```\n-//!\n-//! The reason that we can restrict `MUTATE` and `CLAIM` actions even\n-//! without a restrictions list is that it is never legal to mutate nor to\n-//! borrow mutably the contents of a `&Ty` pointer. In other words,\n-//! those restrictions are already inherent in the type.\n-//!\n-//! Clause (1) in the rule for `&Ty` deserves mention. Here I\n-//! specify that the lifetime of the loan must be less than the lifetime\n-//! of the `&Ty` pointer. In simple cases, this clause is redundant, since\n-//! the `LIFETIME()` function will already enforce the required rule:\n-//!\n-//! ```\n-//! fn foo(point: &'a Point) -> &'static f32 {\n-//!     &point.x // Error\n-//! }\n-//! ```\n-//!\n-//! The above example fails to compile both because of clause (1) above\n-//! but also by the basic `LIFETIME()` check. However, in more advanced\n-//! examples involving multiple nested pointers, clause (1) is needed:\n-//!\n-//! ```\n-//! fn foo(point: &'a &'b mut Point) -> &'b f32 {\n-//!     &point.x // Error\n-//! }\n-//! ```\n-//!\n-//! The `LIFETIME` rule here would accept `'b` because, in fact, the\n-//! *memory is* guaranteed to remain valid (i.e., not be freed) for the\n-//! lifetime `'b`, since the `&mut` pointer is valid for `'b`. However, we\n-//! are returning an immutable reference, so we need the memory to be both\n-//! valid and immutable. Even though `point.x` is referenced by an `&mut`\n-//! pointer, it can still be considered immutable so long as that `&mut`\n-//! pointer is found in an aliased location. That means the memory is\n-//! guaranteed to be *immutable* for the lifetime of the `&` pointer,\n-//! which is only `'a`, not `'b`. Hence this example yields an error.\n-//!\n-//! As a final twist, consider the case of two nested *immutable*\n-//! pointers, rather than a mutable pointer within an immutable one:\n-//!\n-//! ```\n-//! fn foo(point: &'a &'b Point) -> &'b f32 {\n-//!     &point.x // OK\n-//! }\n-//! ```\n-//!\n-//! This function is legal. The reason for this is that the inner pointer\n-//! (`*point : &'b Point`) is enough to guarantee the memory is immutable\n-//! and valid for the lifetime `'b`.  This is reflected in\n-//! `RESTRICTIONS()` by the fact that we do not recurse (i.e., we impose\n-//! no restrictions on `LV`, which in this particular case is the pointer\n-//! `point : &'a &'b Point`).\n-//!\n-//! #### Why both `LIFETIME()` and `RESTRICTIONS()`?\n-//!\n-//! Given the previous text, it might seem that `LIFETIME` and\n-//! `RESTRICTIONS` should be folded together into one check, but there is\n-//! a reason that they are separated. They answer separate concerns.\n-//! The rules pertaining to `LIFETIME` exist to ensure that we don't\n-//! create a borrowed pointer that outlives the memory it points at. So\n-//! `LIFETIME` prevents a function like this:\n-//!\n-//! ```\n-//! fn get_1<'a>() -> &'a int {\n-//!     let x = 1;\n-//!     &x\n-//! }\n-//! ```\n-//!\n-//! Here we would be returning a pointer into the stack. Clearly bad.\n-//!\n-//! However, the `RESTRICTIONS` rules are more concerned with how memory\n-//! is used. The example above doesn't generate an error according to\n-//! `RESTRICTIONS` because, for local variables, we don't require that the\n-//! loan lifetime be a subset of the local variable lifetime. The idea\n-//! here is that we *can* guarantee that `x` is not (e.g.) mutated for the\n-//! lifetime `'a`, even though `'a` exceeds the function body and thus\n-//! involves unknown code in the caller -- after all, `x` ceases to exist\n-//! after we return and hence the remaining code in `'a` cannot possibly\n-//! mutate it. This distinction is important for type checking functions\n-//! like this one:\n-//!\n-//! ```\n-//! fn inc_and_get<'a>(p: &'a mut Point) -> &'a int {\n-//!     p.x += 1;\n-//!     &p.x\n-//! }\n-//! ```\n-//!\n-//! In this case, we take in a `&mut` and return a frozen borrowed pointer\n-//! with the same lifetime. So long as the lifetime of the returned value\n-//! doesn't exceed the lifetime of the `&mut` we receive as input, this is\n-//! fine, though it may seem surprising at first (it surprised me when I\n-//! first worked it through). After all, we're guaranteeing that `*p`\n-//! won't be mutated for the lifetime `'a`, even though we can't \"see\" the\n-//! entirety of the code during that lifetime, since some of it occurs in\n-//! our caller. But we *do* know that nobody can mutate `*p` except\n-//! through `p`. So if we don't mutate `*p` and we don't return `p`, then\n-//! we know that the right to mutate `*p` has been lost to our caller --\n-//! in terms of capability, the caller passed in the ability to mutate\n-//! `*p`, and we never gave it back. (Note that we can't return `p` while\n-//! `*p` is borrowed since that would be a move of `p`, as `&mut` pointers\n-//! are affine.)\n-//!\n-//! ### Restrictions for loans of const aliasable referents\n-//!\n-//! Freeze pointers are read-only. There may be `&mut` or `&` aliases, and\n-//! we can not prevent *anything* but moves in that case. So the\n-//! `RESTRICTIONS` function is only defined if `ACTIONS` is the empty set.\n-//! Because moves from a `&const` lvalue are never legal, it is not\n-//! necessary to add any restrictions at all to the final result.\n-//!\n-//! ```text\n-//!     RESTRICTIONS(*LV, LT, []) = []                // R-Deref-Freeze-Borrowed\n-//!       TYPE(LV) = &const Ty\n-//! ```\n-//!\n-//! ### Restrictions for loans of mutable borrowed referents\n-//!\n-//! Mutable borrowed pointers are guaranteed to be the only way to mutate\n-//! their referent. This permits us to take greater license with them; for\n-//! example, the referent can be frozen simply be ensuring that we do not\n-//! use the original pointer to perform mutate. Similarly, we can allow\n-//! the referent to be claimed, so long as the original pointer is unused\n-//! while the new claimant is live.\n-//!\n-//! The rule for mutable borrowed pointers is as follows:\n-//!\n-//! ```text\n-//! RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Mut-Borrowed\n-//!   TYPE(LV) = &LT' mut Ty\n-//!   LT <= LT'                                            // (1)\n-//!   RESTRICTIONS(LV, LT, ACTIONS) = RS                   // (2)\n-//! ```\n-//!\n-//! Let's examine the two numbered clauses:\n-//!\n-//! Clause (1) specifies that the lifetime of the loan (`LT`) cannot\n-//! exceed the lifetime of the `&mut` pointer (`LT'`). The reason for this\n-//! is that the `&mut` pointer is guaranteed to be the only legal way to\n-//! mutate its referent -- but only for the lifetime `LT'`.  After that\n-//! lifetime, the loan on the referent expires and hence the data may be\n-//! modified by its owner again. This implies that we are only able to\n-//! guarantee that the referent will not be modified or aliased for a\n-//! maximum of `LT'`.\n-//!\n-//! Here is a concrete example of a bug this rule prevents:\n-//!\n-//! ```\n-//! // Test region-reborrow-from-shorter-mut-ref.rs:\n-//! fn copy_pointer<'a,'b,T>(x: &'a mut &'b mut T) -> &'b mut T {\n-//!     &mut **p // ERROR due to clause (1)\n-//! }\n-//! fn main() {\n-//!     let mut x = 1;\n-//!     let mut y = &mut x; // <-'b-----------------------------+\n-//!     //      +-'a--------------------+                       |\n-//!     //      v                       v                       |\n-//!     let z = copy_borrowed_ptr(&mut y); // y is lent         |\n-//!     *y += 1; // Here y==z, so both should not be usable...  |\n-//!     *z += 1; // ...and yet they would be, but for clause 1. |\n-//! } // <------------------------------------------------------+\n-//! ```\n-//!\n-//! Clause (2) propagates the restrictions on the referent to the pointer\n-//! itself. This is the same as with an owned pointer, though the\n-//! reasoning is mildly different. The basic goal in all cases is to\n-//! prevent the user from establishing another route to the same data. To\n-//! see what I mean, let's examine various cases of what can go wrong and\n-//! show how it is prevented.\n-//!\n-//! **Example danger 1: Moving the base pointer.** One of the simplest\n-//! ways to violate the rules is to move the base pointer to a new name\n-//! and access it via that new name, thus bypassing the restrictions on\n-//! the old name. Here is an example:\n-//!\n-//! ```\n-//! // src/test/compile-fail/borrowck-move-mut-base-ptr.rs\n-//! fn foo(t0: &mut int) {\n-//!     let p: &int = &*t0; // Freezes `*t0`\n-//!     let t1 = t0;        //~ ERROR cannot move out of `t0`\n-//!     *t1 = 22;           // OK, not a write through `*t0`\n-//! }\n-//! ```\n-//!\n-//! Remember that `&mut` pointers are linear, and hence `let t1 = t0` is a\n-//! move of `t0` -- or would be, if it were legal. Instead, we get an\n-//! error, because clause (2) imposes restrictions on `LV` (`t0`, here),\n-//! and any restrictions on a path make it impossible to move from that\n-//! path.\n-//!\n-//! **Example danger 2: Claiming the base pointer.** Another possible\n-//! danger is to mutably borrow the base path. This can lead to two bad\n-//! scenarios. The most obvious is that the mutable borrow itself becomes\n-//! another path to access the same data, as shown here:\n-//!\n-//! ```\n-//! // src/test/compile-fail/borrowck-mut-borrow-of-mut-base-ptr.rs\n-//! fn foo<'a>(mut t0: &'a mut int,\n-//!            mut t1: &'a mut int) {\n-//!     let p: &int = &*t0;     // Freezes `*t0`\n-//!     let mut t2 = &mut t0;   //~ ERROR cannot borrow `t0`\n-//!     **t2 += 1;              // Mutates `*t0`\n-//! }\n-//! ```\n-//!\n-//! In this example, `**t2` is the same memory as `*t0`. Because `t2` is\n-//! an `&mut` pointer, `**t2` is a unique path and hence it would be\n-//! possible to mutate `**t2` even though that memory was supposed to be\n-//! frozen by the creation of `p`. However, an error is reported -- the\n-//! reason is that the freeze `&*t0` will restrict claims and mutation\n-//! against `*t0` which, by clause 2, in turn prevents claims and mutation\n-//! of `t0`. Hence the claim `&mut t0` is illegal.\n-//!\n-//! Another danger with an `&mut` pointer is that we could swap the `t0`\n-//! value away to create a new path:\n-//!\n-//! ```\n-//! // src/test/compile-fail/borrowck-swap-mut-base-ptr.rs\n-//! fn foo<'a>(mut t0: &'a mut int,\n-//!            mut t1: &'a mut int) {\n-//!     let p: &int = &*t0;     // Freezes `*t0`\n-//!     swap(&mut t0, &mut t1); //~ ERROR cannot borrow `t0`\n-//!     *t1 = 22;\n-//! }\n-//! ```\n-//!\n-//! This is illegal for the same reason as above. Note that if we added\n-//! back a swap operator -- as we used to have -- we would want to be very\n-//! careful to ensure this example is still illegal.\n-//!\n-//! **Example danger 3: Freeze the base pointer.** In the case where the\n-//! referent is claimed, even freezing the base pointer can be dangerous,\n-//! as shown in the following example:\n-//!\n-//! ```\n-//! // src/test/compile-fail/borrowck-borrow-of-mut-base-ptr.rs\n-//! fn foo<'a>(mut t0: &'a mut int,\n-//!            mut t1: &'a mut int) {\n-//!     let p: &mut int = &mut *t0; // Claims `*t0`\n-//!     let mut t2 = &t0;           //~ ERROR cannot borrow `t0`\n-//!     let q: &int = &*t2;         // Freezes `*t0` but not through `*p`\n-//!     *p += 1;                    // violates type of `*q`\n-//! }\n-//! ```\n-//!\n-//! Here the problem is that `*t0` is claimed by `p`, and hence `p` wants\n-//! to be the controlling pointer through which mutation or freezes occur.\n-//! But `t2` would -- if it were legal -- have the type `& &mut int`, and\n-//! hence would be a mutable pointer in an aliasable location, which is\n-//! considered frozen (since no one can write to `**t2` as it is not a\n-//! unique path). Therefore, we could reasonably create a frozen `&int`\n-//! pointer pointing at `*t0` that coexists with the mutable pointer `p`,\n-//! which is clearly unsound.\n-//!\n-//! However, it is not always unsafe to freeze the base pointer. In\n-//! particular, if the referent is frozen, there is no harm in it:\n-//!\n-//! ```\n-//! // src/test/run-pass/borrowck-borrow-of-mut-base-ptr-safe.rs\n-//! fn foo<'a>(mut t0: &'a mut int,\n-//!            mut t1: &'a mut int) {\n-//!     let p: &int = &*t0; // Freezes `*t0`\n-//!     let mut t2 = &t0;\n-//!     let q: &int = &*t2; // Freezes `*t0`, but that's ok...\n-//!     let r: &int = &*t0; // ...after all, could do same thing directly.\n-//! }\n-//! ```\n-//!\n-//! In this case, creating the alias `t2` of `t0` is safe because the only\n-//! thing `t2` can be used for is to further freeze `*t0`, which is\n-//! already frozen. In particular, we cannot assign to `*t0` through the\n-//! new alias `t2`, as demonstrated in this test case:\n-//!\n-//! ```\n-//! // src/test/run-pass/borrowck-borrow-mut-base-ptr-in-aliasable-loc.rs\n-//! fn foo(t0: & &mut int) {\n-//!     let t1 = t0;\n-//!     let p: &int = &**t0;\n-//!     **t1 = 22; //~ ERROR cannot assign\n-//! }\n-//! ```\n-//!\n-//! This distinction is reflected in the rules. When doing an `&mut`\n-//! borrow -- as in the first example -- the set `ACTIONS` will be\n-//! `CLAIM|MUTATE|FREEZE`, because claiming the referent implies that it\n-//! cannot be claimed, mutated, or frozen by anyone else. These\n-//! restrictions are propagated back to the base path and hence the base\n-//! path is considered unfreezable.\n-//!\n-//! In contrast, when the referent is merely frozen -- as in the second\n-//! example -- the set `ACTIONS` will be `CLAIM|MUTATE`, because freezing\n-//! the referent implies that it cannot be claimed or mutated but permits\n-//! others to freeze. Hence when these restrictions are propagated back to\n-//! the base path, it will still be considered freezable.\n-//!\n-//!\n-//!\n-//! **FIXME #10520: Restrictions against mutating the base pointer.** When\n-//! an `&mut` pointer is frozen or claimed, we currently pass along the\n-//! restriction against MUTATE to the base pointer. I do not believe this\n-//! restriction is needed. It dates from the days when we had a way to\n-//! mutate that preserved the value being mutated (i.e., swap). Nowadays\n-//! the only form of mutation is assignment, which destroys the pointer\n-//! being mutated -- therefore, a mutation cannot create a new path to the\n-//! same data. Rather, it removes an existing path. This implies that not\n-//! only can we permit mutation, we can have mutation kill restrictions in\n-//! the dataflow sense.\n-//!\n-//! **WARNING:** We do not currently have `const` borrows in the\n-//! language. If they are added back in, we must ensure that they are\n-//! consistent with all of these examples. The crucial question will be\n-//! what sorts of actions are permitted with a `&const &mut` pointer. I\n-//! would suggest that an `&mut` referent found in an `&const` location be\n-//! prohibited from both freezes and claims. This would avoid the need to\n-//! prevent `const` borrows of the base pointer when the referent is\n-//! borrowed.\n-//!\n-//! # Moves and initialization\n-//!\n-//! The borrow checker is also in charge of ensuring that:\n-//!\n-//! - all memory which is accessed is initialized\n-//! - immutable local variables are assigned at most once.\n-//!\n-//! These are two separate dataflow analyses built on the same\n-//! framework. Let's look at checking that memory is initialized first;\n-//! the checking of immutable local variable assignments works in a very\n-//! similar way.\n-//!\n-//! To track the initialization of memory, we actually track all the\n-//! points in the program that *create uninitialized memory*, meaning\n-//! moves and the declaration of uninitialized variables. For each of\n-//! these points, we create a bit in the dataflow set. Assignments to a\n-//! variable `x` or path `a.b.c` kill the move/uninitialization bits for\n-//! those paths and any subpaths (e.g., `x`, `x.y`, `a.b.c`, `*a.b.c`).\n-//! Bits are unioned when two control-flow paths join. Thus, the\n-//! presence of a bit indicates that the move may have occurred without an\n-//! intervening assignment to the same memory. At each use of a variable,\n-//! we examine the bits in scope, and check that none of them are\n-//! moves/uninitializations of the variable that is being used.\n-//!\n-//! Let's look at a simple example:\n-//!\n-//! ```\n-//! fn foo(a: Box<int>) {\n-//!     let b: Box<int>;   // Gen bit 0.\n-//!\n-//!     if cond {          // Bits: 0\n-//!         use(&*a);\n-//!         b = a;         // Gen bit 1, kill bit 0.\n-//!         use(&*b);\n-//!     } else {\n-//!                        // Bits: 0\n-//!     }\n-//!                        // Bits: 0,1\n-//!     use(&*a);          // Error.\n-//!     use(&*b);          // Error.\n-//! }\n-//!\n-//! fn use(a: &int) { }\n-//! ```\n-//!\n-//! In this example, the variable `b` is created uninitialized. In one\n-//! branch of an `if`, we then move the variable `a` into `b`. Once we\n-//! exit the `if`, therefore, it is an error to use `a` or `b` since both\n-//! are only conditionally initialized. I have annotated the dataflow\n-//! state using comments. There are two dataflow bits, with bit 0\n-//! corresponding to the creation of `b` without an initializer, and bit 1\n-//! corresponding to the move of `a`. The assignment `b = a` both\n-//! generates bit 1, because it is a move of `a`, and kills bit 0, because\n-//! `b` is now initialized. On the else branch, though, `b` is never\n-//! initialized, and so bit 0 remains untouched. When the two flows of\n-//! control join, we union the bits from both sides, resulting in both\n-//! bits 0 and 1 being set. Thus any attempt to use `a` uncovers the bit 1\n-//! from the \"then\" branch, showing that `a` may be moved, and any attempt\n-//! to use `b` uncovers bit 0, from the \"else\" branch, showing that `b`\n-//! may not be initialized.\n-//!\n-//! ## Initialization of immutable variables\n-//!\n-//! Initialization of immutable variables works in a very similar way,\n-//! except that:\n-//!\n-//! 1. we generate bits for each assignment to a variable;\n-//! 2. the bits are never killed except when the variable goes out of scope.\n-//!\n-//! Thus the presence of an assignment bit indicates that the assignment\n-//! may have occurred. Note that assignments are only killed when the\n-//! variable goes out of scope, as it is not relevant whether or not there\n-//! has been a move in the meantime. Using these bits, we can declare that\n-//! an assignment to an immutable variable is legal iff there is no other\n-//! assignment bit to that same variable in scope.\n-//!\n-//! ## Why is the design made this way?\n-//!\n-//! It may seem surprising that we assign dataflow bits to *each move*\n-//! rather than *each path being moved*. This is somewhat less efficient,\n-//! since on each use, we must iterate through all moves and check whether\n-//! any of them correspond to the path in question. Similar concerns apply\n-//! to the analysis for double assignments to immutable variables. The\n-//! main reason to do it this way is that it allows us to print better\n-//! error messages, because when a use occurs, we can print out the\n-//! precise move that may be in scope, rather than simply having to say\n-//! \"the variable may not be initialized\".\n-//!\n-//! ## Data structures used in the move analysis\n-//!\n-//! The move analysis maintains several data structures that enable it to\n-//! cross-reference moves and assignments to determine when they may be\n-//! moving/assigning the same memory. These are all collected into the\n-//! `MoveData` and `FlowedMoveData` structs. The former represents the set\n-//! of move paths, moves, and assignments, and the latter adds in the\n-//! results of a dataflow computation.\n-//!\n-//! ### Move paths\n-//!\n-//! The `MovePath` tree tracks every path that is moved or assigned to.\n-//! These paths have the same form as the `LoanPath` data structure, which\n-//! in turn is the \"real world version of the lvalues `LV` that we\n-//! introduced earlier. The difference between a `MovePath` and a `LoanPath`\n-//! is that move paths are:\n-//!\n-//! 1. Canonicalized, so that we have exactly one copy of each, and\n-//!    we can refer to move paths by index;\n-//! 2. Cross-referenced with other paths into a tree, so that given a move\n-//!    path we can efficiently find all parent move paths and all\n-//!    extensions (e.g., given the `a.b` move path, we can easily find the\n-//!    move path `a` and also the move paths `a.b.c`)\n-//! 3. Cross-referenced with moves and assignments, so that we can\n-//!    easily find all moves and assignments to a given path.\n-//!\n-//! The mechanism that we use is to create a `MovePath` record for each\n-//! move path. These are arranged in an array and are referenced using\n-//! `MovePathIndex` values, which are newtype'd indices. The `MovePath`\n-//! structs are arranged into a tree, representing using the standard\n-//! Knuth representation where each node has a child 'pointer' and a \"next\n-//! sibling\" 'pointer'. In addition, each `MovePath` has a parent\n-//! 'pointer'.  In this case, the 'pointers' are just `MovePathIndex`\n-//! values.\n-//!\n-//! In this way, if we want to find all base paths of a given move path,\n-//! we can just iterate up the parent pointers (see `each_base_path()` in\n-//! the `move_data` module). If we want to find all extensions, we can\n-//! iterate through the subtree (see `each_extending_path()`).\n-//!\n-//! ### Moves and assignments\n-//!\n-//! There are structs to represent moves (`Move`) and assignments\n-//! (`Assignment`), and these are also placed into arrays and referenced\n-//! by index. All moves of a particular path are arranged into a linked\n-//! lists, beginning with `MovePath.first_move` and continuing through\n-//! `Move.next_move`.\n-//!\n-//! We distinguish between \"var\" assignments, which are assignments to a\n-//! variable like `x = foo`, and \"path\" assignments (`x.f = foo`).  This\n-//! is because we need to assign dataflows to the former, but not the\n-//! latter, so as to check for double initialization of immutable\n-//! variables.\n-//!\n-//! ### Gathering and checking moves\n-//!\n-//! Like loans, we distinguish two phases. The first, gathering, is where\n-//! we uncover all the moves and assignments. As with loans, we do some\n-//! basic sanity checking in this phase, so we'll report errors if you\n-//! attempt to move out of a borrowed pointer etc. Then we do the dataflow\n-//! (see `FlowedMoveData::new`). Finally, in the `check_loans.rs` code, we\n-//! walk back over, identify all uses, assignments, and captures, and\n-//! check that they are legal given the set of dataflow bits we have\n-//! computed for that program point.\n-//!\n-//! # Drop flags and structural fragments\n-//!\n-//! In addition to the job of enforcing memory safety, the borrow checker\n-//! code is also responsible for identifying the *structural fragments* of\n-//! data in the function, to support out-of-band dynamic drop flags\n-//! allocated on the stack. (For background, see [RFC PR #320].)\n-//!\n-//! [RFC PR #320]: https://github.com/rust-lang/rfcs/pull/320\n-//!\n-//! Semantically, each piece of data that has a destructor may need a\n-//! boolean flag to indicate whether or not its destructor has been run\n-//! yet. However, in many cases there is no need to actually maintain such\n-//! a flag: It can be apparent from the code itself that a given path is\n-//! always initialized (or always deinitialized) when control reaches the\n-//! end of its owner's scope, and thus we can unconditionally emit (or\n-//! not) the destructor invocation for that path.\n-//!\n-//! A simple example of this is the following:\n-//!\n-//! ```rust\n-//! struct D { p: int }\n-//! impl D { fn new(x: int) -> D { ... }\n-//! impl Drop for D { ... }\n-//!\n-//! fn foo(a: D, b: D, t: || -> bool) {\n-//!     let c: D;\n-//!     let d: D;\n-//!     if t() { c = b; }\n-//! }\n-//! ```\n-//!\n-//! At the end of the body of `foo`, the compiler knows that `a` is\n-//! initialized, introducing a drop obligation (deallocating the boxed\n-//! integer) for the end of `a`'s scope that is run unconditionally.\n-//! Likewise the compiler knows that `d` is not initialized, and thus it\n-//! leave out the drop code for `d`.\n-//!\n-//! The compiler cannot statically know the drop-state of `b` nor `c` at\n-//! the end of their scope, since that depends on the value of\n-//! `t`. Therefore, we need to insert boolean flags to track whether we\n-//! need to drop `b` and `c`.\n-//!\n-//! However, the matter is not as simple as just mapping local variables\n-//! to their corresponding drop flags when necessary. In particular, in\n-//! addition to being able to move data out of local variables, Rust\n-//! allows one to move values in and out of structured data.\n-//!\n-//! Consider the following:\n-//!\n-//! ```rust\n-//! struct S { x: D, y: D, z: D }\n-//!\n-//! fn foo(a: S, mut b: S, t: || -> bool) {\n-//!     let mut c: S;\n-//!     let d: S;\n-//!     let e: S = a.clone();\n-//!     if t() {\n-//!         c = b;\n-//!         b.x = e.y;\n-//!     }\n-//!     if t() { c.y = D::new(4); }\n-//! }\n-//! ```\n-//!\n-//! As before, the drop obligations of `a` and `d` can be statically\n-//! determined, and again the state of `b` and `c` depend on dynamic\n-//! state. But additionally, the dynamic drop obligations introduced by\n-//! `b` and `c` are not just per-local boolean flags. For example, if the\n-//! first call to `t` returns `false` and the second call `true`, then at\n-//! the end of their scope, `b` will be completely initialized, but only\n-//! `c.y` in `c` will be initialized.  If both calls to `t` return `true`,\n-//! then at the end of their scope, `c` will be completely initialized,\n-//! but only `b.x` will be initialized in `b`, and only `e.x` and `e.z`\n-//! will be initialized in `e`.\n-//!\n-//! Note that we need to cover the `z` field in each case in some way,\n-//! since it may (or may not) need to be dropped, even though `z` is never\n-//! directly mentioned in the body of the `foo` function. We call a path\n-//! like `b.z` a *fragment sibling* of `b.x`, since the field `z` comes\n-//! from the same structure `S` that declared the field `x` in `b.x`.\n-//!\n-//! In general we need to maintain boolean flags that match the\n-//! `S`-structure of both `b` and `c`.  In addition, we need to consult\n-//! such a flag when doing an assignment (such as `c.y = D::new(4);`\n-//! above), in order to know whether or not there is a previous value that\n-//! needs to be dropped before we do the assignment.\n-//!\n-//! So for any given function, we need to determine what flags are needed\n-//! to track its drop obligations. Our strategy for determining the set of\n-//! flags is to represent the fragmentation of the structure explicitly:\n-//! by starting initially from the paths that are explicitly mentioned in\n-//! moves and assignments (such as `b.x` and `c.y` above), and then\n-//! traversing the structure of the path's type to identify leftover\n-//! *unmoved fragments*: assigning into `c.y` means that `c.x` and `c.z`\n-//! are leftover unmoved fragments. Each fragment represents a drop\n-//! obligation that may need to be tracked. Paths that are only moved or\n-//! assigned in their entirety (like `a` and `d`) are treated as a single\n-//! drop obligation.\n-//!\n-//! The fragment construction process works by piggy-backing on the\n-//! existing `move_data` module. We already have callbacks that visit each\n-//! direct move and assignment; these form the basis for the sets of\n-//! moved_leaf_paths and assigned_leaf_paths. From these leaves, we can\n-//! walk up their parent chain to identify all of their parent paths.\n-//! We need to identify the parents because of cases like the following:\n-//!\n-//! ```rust\n-//! struct Pair<X,Y>{ x: X, y: Y }\n-//! fn foo(dd_d_d: Pair<Pair<Pair<D, D>, D>, D>) {\n-//!     other_function(dd_d_d.x.y);\n-//! }\n-//! ```\n-//!\n-//! In this code, the move of the path `dd_d.x.y` leaves behind not only\n-//! the fragment drop-obligation `dd_d.x.x` but also `dd_d.y` as well.\n-//!\n-//! Once we have identified the directly-referenced leaves and their\n-//! parents, we compute the left-over fragments, in the function\n-//! `fragments::add_fragment_siblings`. As of this writing this works by\n-//! looking at each directly-moved or assigned path P, and blindly\n-//! gathering all sibling fields of P (as well as siblings for the parents\n-//! of P, etc). After accumulating all such siblings, we filter out the\n-//! entries added as siblings of P that turned out to be\n-//! directly-referenced paths (or parents of directly referenced paths)\n-//! themselves, thus leaving the never-referenced \"left-overs\" as the only\n-//! thing left from the gathering step.\n-//!\n-//! ## Array structural fragments\n-//!\n-//! A special case of the structural fragments discussed above are\n-//! the elements of an array that has been passed by value, such as\n-//! the following:\n-//!\n-//! ```rust\n-//! fn foo(a: [D; 10], i: uint) -> D {\n-//!     a[i]\n-//! }\n-//! ```\n-//!\n-//! The above code moves a single element out of the input array `a`.\n-//! The remainder of the array still needs to be dropped; i.e., it\n-//! is a structural fragment. Note that after performing such a move,\n-//! it is not legal to read from the array `a`. There are a number of\n-//! ways to deal with this, but the important thing to note is that\n-//! the semantics needs to distinguish in some manner between a\n-//! fragment that is the *entire* array versus a fragment that represents\n-//! all-but-one element of the array.  A place where that distinction\n-//! would arise is the following:\n-//!\n-//! ```rust\n-//! fn foo(a: [D; 10], b: [D; 10], i: uint, t: bool) -> D {\n-//!     if t {\n-//!         a[i]\n-//!     } else {\n-//!         b[i]\n-//!     }\n-//!\n-//!     // When control exits, we will need either to drop all of `a`\n-//!     // and all-but-one of `b`, or to drop all of `b` and all-but-one\n-//!     // of `a`.\n-//! }\n-//! ```\n-//!\n-//! There are a number of ways that the trans backend could choose to\n-//! compile this (e.g. a `[bool; 10]` array for each such moved array;\n-//! or an `Option<uint>` for each moved array).  From the viewpoint of the\n-//! borrow-checker, the important thing is to record what kind of fragment\n-//! is implied by the relevant moves.\n-//!\n-//! # Future work\n-//!\n-//! While writing up these docs, I encountered some rules I believe to be\n-//! stricter than necessary:\n-//!\n-//! - I think restricting the `&mut` LV against moves and `ALIAS` is sufficient,\n-//!   `MUTATE` and `CLAIM` are overkill. `MUTATE` was necessary when swap was\n-//!   a built-in operator, but as it is not, it is implied by `CLAIM`,\n-//!   and `CLAIM` is implied by `ALIAS`. The only net effect of this is an\n-//!   extra error message in some cases, though.\n-//! - I have not described how closures interact. Current code is unsound.\n-//!   I am working on describing and implementing the fix.\n-//! - If we wish, we can easily extend the move checking to allow finer-grained\n-//!   tracking of what is initialized and what is not, enabling code like\n-//!   this:\n-//!\n-//!       a = x.f.g; // x.f.g is now uninitialized\n-//!       // here, x and x.f are not usable, but x.f.h *is*\n-//!       x.f.g = b; // x.f.g is not initialized\n-//!       // now x, x.f, x.f.g, x.f.h are all usable\n-//!\n-//!   What needs to change here, most likely, is that the `moves` module\n-//!   should record not only what paths are moved, but what expressions\n-//!   are actual *uses*. For example, the reference to `x` in `x.f.g = b`\n-//!   is not a true *use* in the sense that it requires `x` to be fully\n-//!   initialized. This is in fact why the above code produces an error\n-//!   today: the reference to `x` in `x.f.g = b` is considered illegal\n-//!   because `x` is not fully initialized.\n-//!\n-//! There are also some possible refactorings:\n-//!\n-//! - It might be nice to replace all loan paths with the MovePath mechanism,\n-//!   since they allow lightweight comparison using an integer."}, {"sha": "93d97a054a4b3b720fcc0375b02e76d7c2a32d12", "filename": "src/librustc_borrowck/borrowck/mod.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_borrowck%2Fborrowck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_borrowck%2Fborrowck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_borrowck%2Fborrowck%2Fmod.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! See doc.rs for a thorough explanation of the borrow checker\n+//! See The Book chapter on the borrow checker for more details.\n \n #![allow(non_camel_case_types)]\n \n@@ -41,8 +41,6 @@ use syntax::visit;\n use syntax::visit::{Visitor, FnKind};\n use syntax::ast::{FnDecl, Block, NodeId};\n \n-pub mod doc;\n-\n pub mod check_loans;\n \n pub mod gather_loans;"}, {"sha": "1c831090e3eaf0e04e07780f2200ca8462b4227e", "filename": "src/librustc_trans/trans/cleanup.rs", "status": "modified", "additions": 105, "deletions": 2, "changes": 107, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fcleanup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fcleanup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fcleanup.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -8,8 +8,111 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! Code pertaining to cleanup of temporaries as well as execution of\n-//! drop glue. See discussion in `doc.rs` for a high-level summary.\n+//! ## The Cleanup module\n+//!\n+//! The cleanup module tracks what values need to be cleaned up as scopes\n+//! are exited, either via panic or just normal control flow. The basic\n+//! idea is that the function context maintains a stack of cleanup scopes\n+//! that are pushed/popped as we traverse the AST tree. There is typically\n+//! at least one cleanup scope per AST node; some AST nodes may introduce\n+//! additional temporary scopes.\n+//!\n+//! Cleanup items can be scheduled into any of the scopes on the stack.\n+//! Typically, when a scope is popped, we will also generate the code for\n+//! each of its cleanups at that time. This corresponds to a normal exit\n+//! from a block (for example, an expression completing evaluation\n+//! successfully without panic). However, it is also possible to pop a\n+//! block *without* executing its cleanups; this is typically used to\n+//! guard intermediate values that must be cleaned up on panic, but not\n+//! if everything goes right. See the section on custom scopes below for\n+//! more details.\n+//!\n+//! Cleanup scopes come in three kinds:\n+//!\n+//! - **AST scopes:** each AST node in a function body has a corresponding\n+//!   AST scope. We push the AST scope when we start generate code for an AST\n+//!   node and pop it once the AST node has been fully generated.\n+//! - **Loop scopes:** loops have an additional cleanup scope. Cleanups are\n+//!   never scheduled into loop scopes; instead, they are used to record the\n+//!   basic blocks that we should branch to when a `continue` or `break` statement\n+//!   is encountered.\n+//! - **Custom scopes:** custom scopes are typically used to ensure cleanup\n+//!   of intermediate values.\n+//!\n+//! ### When to schedule cleanup\n+//!\n+//! Although the cleanup system is intended to *feel* fairly declarative,\n+//! it's still important to time calls to `schedule_clean()` correctly.\n+//! Basically, you should not schedule cleanup for memory until it has\n+//! been initialized, because if an unwind should occur before the memory\n+//! is fully initialized, then the cleanup will run and try to free or\n+//! drop uninitialized memory. If the initialization itself produces\n+//! byproducts that need to be freed, then you should use temporary custom\n+//! scopes to ensure that those byproducts will get freed on unwind.  For\n+//! example, an expression like `box foo()` will first allocate a box in the\n+//! heap and then call `foo()` -- if `foo()` should panic, this box needs\n+//! to be *shallowly* freed.\n+//!\n+//! ### Long-distance jumps\n+//!\n+//! In addition to popping a scope, which corresponds to normal control\n+//! flow exiting the scope, we may also *jump out* of a scope into some\n+//! earlier scope on the stack. This can occur in response to a `return`,\n+//! `break`, or `continue` statement, but also in response to panic. In\n+//! any of these cases, we will generate a series of cleanup blocks for\n+//! each of the scopes that is exited. So, if the stack contains scopes A\n+//! ... Z, and we break out of a loop whose corresponding cleanup scope is\n+//! X, we would generate cleanup blocks for the cleanups in X, Y, and Z.\n+//! After cleanup is done we would branch to the exit point for scope X.\n+//! But if panic should occur, we would generate cleanups for all the\n+//! scopes from A to Z and then resume the unwind process afterwards.\n+//!\n+//! To avoid generating tons of code, we cache the cleanup blocks that we\n+//! create for breaks, returns, unwinds, and other jumps. Whenever a new\n+//! cleanup is scheduled, though, we must clear these cached blocks. A\n+//! possible improvement would be to keep the cached blocks but simply\n+//! generate a new block which performs the additional cleanup and then\n+//! branches to the existing cached blocks.\n+//!\n+//! ### AST and loop cleanup scopes\n+//!\n+//! AST cleanup scopes are pushed when we begin and end processing an AST\n+//! node. They are used to house cleanups related to rvalue temporary that\n+//! get referenced (e.g., due to an expression like `&Foo()`). Whenever an\n+//! AST scope is popped, we always trans all the cleanups, adding the cleanup\n+//! code after the postdominator of the AST node.\n+//!\n+//! AST nodes that represent breakable loops also push a loop scope; the\n+//! loop scope never has any actual cleanups, it's just used to point to\n+//! the basic blocks where control should flow after a \"continue\" or\n+//! \"break\" statement. Popping a loop scope never generates code.\n+//!\n+//! ### Custom cleanup scopes\n+//!\n+//! Custom cleanup scopes are used for a variety of purposes. The most\n+//! common though is to handle temporary byproducts, where cleanup only\n+//! needs to occur on panic. The general strategy is to push a custom\n+//! cleanup scope, schedule *shallow* cleanups into the custom scope, and\n+//! then pop the custom scope (without transing the cleanups) when\n+//! execution succeeds normally. This way the cleanups are only trans'd on\n+//! unwind, and only up until the point where execution succeeded, at\n+//! which time the complete value should be stored in an lvalue or some\n+//! other place where normal cleanup applies.\n+//!\n+//! To spell it out, here is an example. Imagine an expression `box expr`.\n+//! We would basically:\n+//!\n+//! 1. Push a custom cleanup scope C.\n+//! 2. Allocate the box.\n+//! 3. Schedule a shallow free in the scope C.\n+//! 4. Trans `expr` into the box.\n+//! 5. Pop the scope C.\n+//! 6. Return the box as an rvalue.\n+//!\n+//! This way, if a panic occurs while transing `expr`, the custom\n+//! cleanup scope C is pushed and hence the box will be freed. The trans\n+//! code for `expr` itself is responsible for freeing any other byproducts\n+//! that may be in play.\n \n pub use self::ScopeId::*;\n pub use self::CleanupScopeKind::*;"}, {"sha": "f4a5ba98b676749f76f42b73fc9d19e2001c8efb", "filename": "src/librustc_trans/trans/datum.rs", "status": "modified", "additions": 91, "deletions": 2, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fdatum.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fdatum.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fdatum.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -8,8 +8,97 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! See the section on datums in `doc.rs` for an overview of what Datums are and how they are\n-//! intended to be used.\n+//! ## The Datum module\n+//!\n+//! A `Datum` encapsulates the result of evaluating a Rust expression.  It\n+//! contains a `ValueRef` indicating the result, a `Ty` describing\n+//! the Rust type, but also a *kind*. The kind indicates whether the datum\n+//! has cleanup scheduled (lvalue) or not (rvalue) and -- in the case of\n+//! rvalues -- whether or not the value is \"by ref\" or \"by value\".\n+//!\n+//! The datum API is designed to try and help you avoid memory errors like\n+//! forgetting to arrange cleanup or duplicating a value. The type of the\n+//! datum incorporates the kind, and thus reflects whether it has cleanup\n+//! scheduled:\n+//!\n+//! - `Datum<Lvalue>` -- by ref, cleanup scheduled\n+//! - `Datum<Rvalue>` -- by value or by ref, no cleanup scheduled\n+//! - `Datum<Expr>` -- either `Datum<Lvalue>` or `Datum<Rvalue>`\n+//!\n+//! Rvalue and expr datums are noncopyable, and most of the methods on\n+//! datums consume the datum itself (with some notable exceptions). This\n+//! reflects the fact that datums may represent affine values which ought\n+//! to be consumed exactly once, and if you were to try to (for example)\n+//! store an affine value multiple times, you would be duplicating it,\n+//! which would certainly be a bug.\n+//!\n+//! Some of the datum methods, however, are designed to work only on\n+//! copyable values such as ints or pointers. Those methods may borrow the\n+//! datum (`&self`) rather than consume it, but they always include\n+//! assertions on the type of the value represented to check that this\n+//! makes sense. An example is `shallow_copy()`, which duplicates\n+//! a datum value.\n+//!\n+//! Translating an expression always yields a `Datum<Expr>` result, but\n+//! the methods `to_[lr]value_datum()` can be used to coerce a\n+//! `Datum<Expr>` into a `Datum<Lvalue>` or `Datum<Rvalue>` as\n+//! needed. Coercing to an lvalue is fairly common, and generally occurs\n+//! whenever it is necessary to inspect a value and pull out its\n+//! subcomponents (for example, a match, or indexing expression). Coercing\n+//! to an rvalue is more unusual; it occurs when moving values from place\n+//! to place, such as in an assignment expression or parameter passing.\n+//!\n+//! ### Lvalues in detail\n+//!\n+//! An lvalue datum is one for which cleanup has been scheduled. Lvalue\n+//! datums are always located in memory, and thus the `ValueRef` for an\n+//! LLVM value is always a pointer to the actual Rust value. This means\n+//! that if the Datum has a Rust type of `int`, then the LLVM type of the\n+//! `ValueRef` will be `int*` (pointer to int).\n+//!\n+//! Because lvalues already have cleanups scheduled, the memory must be\n+//! zeroed to prevent the cleanup from taking place (presuming that the\n+//! Rust type needs drop in the first place, otherwise it doesn't\n+//! matter). The Datum code automatically performs this zeroing when the\n+//! value is stored to a new location, for example.\n+//!\n+//! Lvalues usually result from evaluating lvalue expressions. For\n+//! example, evaluating a local variable `x` yields an lvalue, as does a\n+//! reference to a field like `x.f` or an index `x[i]`.\n+//!\n+//! Lvalue datums can also arise by *converting* an rvalue into an lvalue.\n+//! This is done with the `to_lvalue_datum` method defined on\n+//! `Datum<Expr>`. Basically this method just schedules cleanup if the\n+//! datum is an rvalue, possibly storing the value into a stack slot first\n+//! if needed. Converting rvalues into lvalues occurs in constructs like\n+//! `&foo()` or `match foo() { ref x => ... }`, where the user is\n+//! implicitly requesting a temporary.\n+//!\n+//! Somewhat surprisingly, not all lvalue expressions yield lvalue datums\n+//! when trans'd. Ultimately the reason for this is to micro-optimize\n+//! the resulting LLVM. For example, consider the following code:\n+//!\n+//!     fn foo() -> Box<int> { ... }\n+//!     let x = *foo();\n+//!\n+//! The expression `*foo()` is an lvalue, but if you invoke `expr::trans`,\n+//! it will return an rvalue datum. See `deref_once` in expr.rs for\n+//! more details.\n+//!\n+//! ### Rvalues in detail\n+//!\n+//! Rvalues datums are values with no cleanup scheduled. One must be\n+//! careful with rvalue datums to ensure that cleanup is properly\n+//! arranged, usually by converting to an lvalue datum or by invoking the\n+//! `add_clean` method.\n+//!\n+//! ### Scratch datums\n+//!\n+//! Sometimes you need some temporary scratch space.  The functions\n+//! `[lr]value_scratch_datum()` can be used to get temporary stack\n+//! space. As their name suggests, they yield lvalues and rvalues\n+//! respectively. That is, the slot from `lvalue_scratch_datum` will have\n+//! cleanup arranged, and the slot from `rvalue_scratch_datum` does not.\n \n pub use self::Expr::*;\n pub use self::RvalueMode::*;"}, {"sha": "c3ab8986372ad14b8d35106f599baa95cfd664d3", "filename": "src/librustc_trans/trans/doc.rs", "status": "removed", "additions": 0, "deletions": 233, "changes": 233, "blob_url": "https://github.com/rust-lang/rust/blob/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc_trans%2Ftrans%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc_trans%2Ftrans%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fdoc.rs?ref=5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "patch": "@@ -1,233 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # Documentation for the trans module\n-//!\n-//! This module contains high-level summaries of how the various modules\n-//! in trans work. It is a work in progress. For detailed comments,\n-//! naturally, you can refer to the individual modules themselves.\n-//!\n-//! ## The Expr module\n-//!\n-//! The expr module handles translation of expressions. The most general\n-//! translation routine is `trans()`, which will translate an expression\n-//! into a datum. `trans_into()` is also available, which will translate\n-//! an expression and write the result directly into memory, sometimes\n-//! avoiding the need for a temporary stack slot. Finally,\n-//! `trans_to_lvalue()` is available if you'd like to ensure that the\n-//! result has cleanup scheduled.\n-//!\n-//! Internally, each of these functions dispatches to various other\n-//! expression functions depending on the kind of expression. We divide\n-//! up expressions into:\n-//!\n-//! - **Datum expressions:** Those that most naturally yield values.\n-//!   Examples would be `22`, `box x`, or `a + b` (when not overloaded).\n-//! - **DPS expressions:** Those that most naturally write into a location\n-//!   in memory. Examples would be `foo()` or `Point { x: 3, y: 4 }`.\n-//! - **Statement expressions:** That that do not generate a meaningful\n-//!   result. Examples would be `while { ... }` or `return 44`.\n-//!\n-//! ## The Datum module\n-//!\n-//! A `Datum` encapsulates the result of evaluating a Rust expression.  It\n-//! contains a `ValueRef` indicating the result, a `Ty` describing\n-//! the Rust type, but also a *kind*. The kind indicates whether the datum\n-//! has cleanup scheduled (lvalue) or not (rvalue) and -- in the case of\n-//! rvalues -- whether or not the value is \"by ref\" or \"by value\".\n-//!\n-//! The datum API is designed to try and help you avoid memory errors like\n-//! forgetting to arrange cleanup or duplicating a value. The type of the\n-//! datum incorporates the kind, and thus reflects whether it has cleanup\n-//! scheduled:\n-//!\n-//! - `Datum<Lvalue>` -- by ref, cleanup scheduled\n-//! - `Datum<Rvalue>` -- by value or by ref, no cleanup scheduled\n-//! - `Datum<Expr>` -- either `Datum<Lvalue>` or `Datum<Rvalue>`\n-//!\n-//! Rvalue and expr datums are noncopyable, and most of the methods on\n-//! datums consume the datum itself (with some notable exceptions). This\n-//! reflects the fact that datums may represent affine values which ought\n-//! to be consumed exactly once, and if you were to try to (for example)\n-//! store an affine value multiple times, you would be duplicating it,\n-//! which would certainly be a bug.\n-//!\n-//! Some of the datum methods, however, are designed to work only on\n-//! copyable values such as ints or pointers. Those methods may borrow the\n-//! datum (`&self`) rather than consume it, but they always include\n-//! assertions on the type of the value represented to check that this\n-//! makes sense. An example is `shallow_copy()`, which duplicates\n-//! a datum value.\n-//!\n-//! Translating an expression always yields a `Datum<Expr>` result, but\n-//! the methods `to_[lr]value_datum()` can be used to coerce a\n-//! `Datum<Expr>` into a `Datum<Lvalue>` or `Datum<Rvalue>` as\n-//! needed. Coercing to an lvalue is fairly common, and generally occurs\n-//! whenever it is necessary to inspect a value and pull out its\n-//! subcomponents (for example, a match, or indexing expression). Coercing\n-//! to an rvalue is more unusual; it occurs when moving values from place\n-//! to place, such as in an assignment expression or parameter passing.\n-//!\n-//! ### Lvalues in detail\n-//!\n-//! An lvalue datum is one for which cleanup has been scheduled. Lvalue\n-//! datums are always located in memory, and thus the `ValueRef` for an\n-//! LLVM value is always a pointer to the actual Rust value. This means\n-//! that if the Datum has a Rust type of `int`, then the LLVM type of the\n-//! `ValueRef` will be `int*` (pointer to int).\n-//!\n-//! Because lvalues already have cleanups scheduled, the memory must be\n-//! zeroed to prevent the cleanup from taking place (presuming that the\n-//! Rust type needs drop in the first place, otherwise it doesn't\n-//! matter). The Datum code automatically performs this zeroing when the\n-//! value is stored to a new location, for example.\n-//!\n-//! Lvalues usually result from evaluating lvalue expressions. For\n-//! example, evaluating a local variable `x` yields an lvalue, as does a\n-//! reference to a field like `x.f` or an index `x[i]`.\n-//!\n-//! Lvalue datums can also arise by *converting* an rvalue into an lvalue.\n-//! This is done with the `to_lvalue_datum` method defined on\n-//! `Datum<Expr>`. Basically this method just schedules cleanup if the\n-//! datum is an rvalue, possibly storing the value into a stack slot first\n-//! if needed. Converting rvalues into lvalues occurs in constructs like\n-//! `&foo()` or `match foo() { ref x => ... }`, where the user is\n-//! implicitly requesting a temporary.\n-//!\n-//! Somewhat surprisingly, not all lvalue expressions yield lvalue datums\n-//! when trans'd. Ultimately the reason for this is to micro-optimize\n-//! the resulting LLVM. For example, consider the following code:\n-//!\n-//!     fn foo() -> Box<int> { ... }\n-//!     let x = *foo();\n-//!\n-//! The expression `*foo()` is an lvalue, but if you invoke `expr::trans`,\n-//! it will return an rvalue datum. See `deref_once` in expr.rs for\n-//! more details.\n-//!\n-//! ### Rvalues in detail\n-//!\n-//! Rvalues datums are values with no cleanup scheduled. One must be\n-//! careful with rvalue datums to ensure that cleanup is properly\n-//! arranged, usually by converting to an lvalue datum or by invoking the\n-//! `add_clean` method.\n-//!\n-//! ### Scratch datums\n-//!\n-//! Sometimes you need some temporary scratch space.  The functions\n-//! `[lr]value_scratch_datum()` can be used to get temporary stack\n-//! space. As their name suggests, they yield lvalues and rvalues\n-//! respectively. That is, the slot from `lvalue_scratch_datum` will have\n-//! cleanup arranged, and the slot from `rvalue_scratch_datum` does not.\n-//!\n-//! ## The Cleanup module\n-//!\n-//! The cleanup module tracks what values need to be cleaned up as scopes\n-//! are exited, either via panic or just normal control flow. The basic\n-//! idea is that the function context maintains a stack of cleanup scopes\n-//! that are pushed/popped as we traverse the AST tree. There is typically\n-//! at least one cleanup scope per AST node; some AST nodes may introduce\n-//! additional temporary scopes.\n-//!\n-//! Cleanup items can be scheduled into any of the scopes on the stack.\n-//! Typically, when a scope is popped, we will also generate the code for\n-//! each of its cleanups at that time. This corresponds to a normal exit\n-//! from a block (for example, an expression completing evaluation\n-//! successfully without panic). However, it is also possible to pop a\n-//! block *without* executing its cleanups; this is typically used to\n-//! guard intermediate values that must be cleaned up on panic, but not\n-//! if everything goes right. See the section on custom scopes below for\n-//! more details.\n-//!\n-//! Cleanup scopes come in three kinds:\n-//! - **AST scopes:** each AST node in a function body has a corresponding\n-//!   AST scope. We push the AST scope when we start generate code for an AST\n-//!   node and pop it once the AST node has been fully generated.\n-//! - **Loop scopes:** loops have an additional cleanup scope. Cleanups are\n-//!   never scheduled into loop scopes; instead, they are used to record the\n-//!   basic blocks that we should branch to when a `continue` or `break` statement\n-//!   is encountered.\n-//! - **Custom scopes:** custom scopes are typically used to ensure cleanup\n-//!   of intermediate values.\n-//!\n-//! ### When to schedule cleanup\n-//!\n-//! Although the cleanup system is intended to *feel* fairly declarative,\n-//! it's still important to time calls to `schedule_clean()` correctly.\n-//! Basically, you should not schedule cleanup for memory until it has\n-//! been initialized, because if an unwind should occur before the memory\n-//! is fully initialized, then the cleanup will run and try to free or\n-//! drop uninitialized memory. If the initialization itself produces\n-//! byproducts that need to be freed, then you should use temporary custom\n-//! scopes to ensure that those byproducts will get freed on unwind.  For\n-//! example, an expression like `box foo()` will first allocate a box in the\n-//! heap and then call `foo()` -- if `foo()` should panic, this box needs\n-//! to be *shallowly* freed.\n-//!\n-//! ### Long-distance jumps\n-//!\n-//! In addition to popping a scope, which corresponds to normal control\n-//! flow exiting the scope, we may also *jump out* of a scope into some\n-//! earlier scope on the stack. This can occur in response to a `return`,\n-//! `break`, or `continue` statement, but also in response to panic. In\n-//! any of these cases, we will generate a series of cleanup blocks for\n-//! each of the scopes that is exited. So, if the stack contains scopes A\n-//! ... Z, and we break out of a loop whose corresponding cleanup scope is\n-//! X, we would generate cleanup blocks for the cleanups in X, Y, and Z.\n-//! After cleanup is done we would branch to the exit point for scope X.\n-//! But if panic should occur, we would generate cleanups for all the\n-//! scopes from A to Z and then resume the unwind process afterwards.\n-//!\n-//! To avoid generating tons of code, we cache the cleanup blocks that we\n-//! create for breaks, returns, unwinds, and other jumps. Whenever a new\n-//! cleanup is scheduled, though, we must clear these cached blocks. A\n-//! possible improvement would be to keep the cached blocks but simply\n-//! generate a new block which performs the additional cleanup and then\n-//! branches to the existing cached blocks.\n-//!\n-//! ### AST and loop cleanup scopes\n-//!\n-//! AST cleanup scopes are pushed when we begin and end processing an AST\n-//! node. They are used to house cleanups related to rvalue temporary that\n-//! get referenced (e.g., due to an expression like `&Foo()`). Whenever an\n-//! AST scope is popped, we always trans all the cleanups, adding the cleanup\n-//! code after the postdominator of the AST node.\n-//!\n-//! AST nodes that represent breakable loops also push a loop scope; the\n-//! loop scope never has any actual cleanups, it's just used to point to\n-//! the basic blocks where control should flow after a \"continue\" or\n-//! \"break\" statement. Popping a loop scope never generates code.\n-//!\n-//! ### Custom cleanup scopes\n-//!\n-//! Custom cleanup scopes are used for a variety of purposes. The most\n-//! common though is to handle temporary byproducts, where cleanup only\n-//! needs to occur on panic. The general strategy is to push a custom\n-//! cleanup scope, schedule *shallow* cleanups into the custom scope, and\n-//! then pop the custom scope (without transing the cleanups) when\n-//! execution succeeds normally. This way the cleanups are only trans'd on\n-//! unwind, and only up until the point where execution succeeded, at\n-//! which time the complete value should be stored in an lvalue or some\n-//! other place where normal cleanup applies.\n-//!\n-//! To spell it out, here is an example. Imagine an expression `box expr`.\n-//! We would basically:\n-//!\n-//! 1. Push a custom cleanup scope C.\n-//! 2. Allocate the box.\n-//! 3. Schedule a shallow free in the scope C.\n-//! 4. Trans `expr` into the box.\n-//! 5. Pop the scope C.\n-//! 6. Return the box as an rvalue.\n-//!\n-//! This way, if a panic occurs while transing `expr`, the custom\n-//! cleanup scope C is pushed and hence the box will be freed. The trans\n-//! code for `expr` itself is responsible for freeing any other byproducts\n-//! that may be in play."}, {"sha": "44d8457c316737605146a0819f1c81226cc21a6c", "filename": "src/librustc_trans/trans/expr.rs", "status": "modified", "additions": 19, "deletions": 2, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fexpr.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -10,6 +10,25 @@\n \n //! # Translation of Expressions\n //!\n+//! The expr module handles translation of expressions. The most general\n+//! translation routine is `trans()`, which will translate an expression\n+//! into a datum. `trans_into()` is also available, which will translate\n+//! an expression and write the result directly into memory, sometimes\n+//! avoiding the need for a temporary stack slot. Finally,\n+//! `trans_to_lvalue()` is available if you'd like to ensure that the\n+//! result has cleanup scheduled.\n+//!\n+//! Internally, each of these functions dispatches to various other\n+//! expression functions depending on the kind of expression. We divide\n+//! up expressions into:\n+//!\n+//! - **Datum expressions:** Those that most naturally yield values.\n+//!   Examples would be `22`, `box x`, or `a + b` (when not overloaded).\n+//! - **DPS expressions:** Those that most naturally write into a location\n+//!   in memory. Examples would be `foo()` or `Point { x: 3, y: 4 }`.\n+//! - **Statement expressions:** That that do not generate a meaningful\n+//!   result. Examples would be `while { ... }` or `return 44`.\n+//!\n //! Public entry points:\n //!\n //! - `trans_into(bcx, expr, dest) -> bcx`: evaluates an expression,\n@@ -26,8 +45,6 @@\n //!   creating a temporary stack slot if necessary.\n //!\n //! - `trans_local_var -> Datum`: looks up a local variable or upvar.\n-//!\n-//! See doc.rs for more comments.\n \n #![allow(non_camel_case_types)]\n "}, {"sha": "f7433e6a774093de216abddf42379d9c492081ff", "filename": "src/librustc_trans/trans/mod.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_trans%2Ftrans%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fmod.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -19,7 +19,6 @@ pub use self::common::gensym_name;\n #[macro_use]\n mod macros;\n \n-mod doc;\n mod inline;\n mod monomorphize;\n mod controlflow;"}, {"sha": "367273dc635f47b003fed53abf9a7f001f5bb595", "filename": "src/librustc_typeck/check/method/README.md", "status": "added", "additions": 111, "deletions": 0, "changes": 111, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2FREADME.md?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -0,0 +1,111 @@\n+# Method lookup\n+\n+Method lookup can be rather complex due to the interaction of a number\n+of factors, such as self types, autoderef, trait lookup, etc. This\n+file provides an overview of the process. More detailed notes are in\n+the code itself, naturally.\n+\n+One way to think of method lookup is that we convert an expression of\n+the form:\n+\n+    receiver.method(...)\n+\n+into a more explicit UFCS form:\n+\n+    Trait::method(ADJ(receiver), ...) // for a trait call\n+    ReceiverType::method(ADJ(receiver), ...) // for an inherent method call\n+\n+Here `ADJ` is some kind of adjustment, which is typically a series of\n+autoderefs and then possibly an autoref (e.g., `&**receiver`). However\n+we sometimes do other adjustments and coercions along the way, in\n+particular unsizing (e.g., converting from `[T, ..n]` to `[T]`).\n+\n+## The Two Phases\n+\n+Method lookup is divided into two major phases: probing (`probe.rs`)\n+and confirmation (`confirm.rs`). The probe phase is when we decide\n+what method to call and how to adjust the receiver. The confirmation\n+phase \"applies\" this selection, updating the side-tables, unifying\n+type variables, and otherwise doing side-effectful things.\n+\n+One reason for this division is to be more amenable to caching.  The\n+probe phase produces a \"pick\" (`probe::Pick`), which is designed to be\n+cacheable across method-call sites. Therefore, it does not include\n+inference variables or other information.\n+\n+## Probe phase\n+\n+The probe phase (`probe.rs`) decides what method is being called and\n+how to adjust the receiver.\n+\n+### Steps\n+\n+The first thing that the probe phase does is to create a series of\n+*steps*. This is done by progressively dereferencing the receiver type\n+until it cannot be deref'd anymore, as well as applying an optional\n+\"unsize\" step. So if the receiver has type `Rc<Box<[T; 3]>>`, this\n+might yield:\n+\n+    Rc<Box<[T; 3]>>\n+    Box<[T; 3]>\n+    [T; 3]\n+    [T]\n+\n+### Candidate assembly\n+\n+We then search along those steps to create a list of *candidates*. A\n+`Candidate` is a method item that might plausibly be the method being\n+invoked. For each candidate, we'll derive a \"transformed self type\"\n+that takes into account explicit self.\n+\n+Candidates are grouped into two kinds, inherent and extension.\n+\n+**Inherent candidates** are those that are derived from the\n+type of the receiver itself.  So, if you have a receiver of some\n+nominal type `Foo` (e.g., a struct), any methods defined within an\n+impl like `impl Foo` are inherent methods.  Nothing needs to be\n+imported to use an inherent method, they are associated with the type\n+itself (note that inherent impls can only be defined in the same\n+module as the type itself).\n+\n+FIXME: Inherent candidates are not always derived from impls.  If you\n+have a trait object, such as a value of type `Box<ToString>`, then the\n+trait methods (`to_string()`, in this case) are inherently associated\n+with it. Another case is type parameters, in which case the methods of\n+their bounds are inherent. However, this part of the rules is subject\n+to change: when DST's \"impl Trait for Trait\" is complete, trait object\n+dispatch could be subsumed into trait matching, and the type parameter\n+behavior should be reconsidered in light of where clauses.\n+\n+**Extension candidates** are derived from imported traits.  If I have\n+the trait `ToString` imported, and I call `to_string()` on a value of\n+type `T`, then we will go off to find out whether there is an impl of\n+`ToString` for `T`.  These kinds of method calls are called \"extension\n+methods\".  They can be defined in any module, not only the one that\n+defined `T`.  Furthermore, you must import the trait to call such a\n+method.\n+\n+So, let's continue our example. Imagine that we were calling a method\n+`foo` with the receiver `Rc<Box<[T; 3]>>` and there is a trait `Foo`\n+that defines it with `&self` for the type `Rc<U>` as well as a method\n+on the type `Box` that defines `Foo` but with `&mut self`. Then we\n+might have two candidates:\n+\n+    &Rc<Box<[T; 3]>> from the impl of `Foo` for `Rc<U>` where `U=Box<T; 3]>\n+    &mut Box<[T; 3]>> from the inherent impl on `Box<U>` where `U=[T; 3]`\n+\n+### Candidate search\n+\n+Finally, to actually pick the method, we will search down the steps,\n+trying to match the receiver type against the candidate types. At\n+each step, we also consider an auto-ref and auto-mut-ref to see whether\n+that makes any of the candidates match. We pick the first step where\n+we find a match.\n+\n+In the case of our example, the first step is `Rc<Box<[T; 3]>>`,\n+which does not itself match any candidate. But when we autoref it, we\n+get the type `&Rc<Box<[T; 3]>>` which does match. We would then\n+recursively consider all where-clauses that appear on the impl: if\n+those match (or we cannot rule out that they do), then this is the\n+method we would pick. Otherwise, we would continue down the series of\n+steps."}, {"sha": "d748266ed2ea9907a1aa24d0ca7a9a348f23798e", "filename": "src/librustc_typeck/check/method/doc.rs", "status": "removed", "additions": 0, "deletions": 121, "changes": 121, "blob_url": "https://github.com/rust-lang/rust/blob/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5be210c4188fb2f1a4fabc6baee5397ac6e6741e/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2Fdoc.rs?ref=5be210c4188fb2f1a4fabc6baee5397ac6e6741e", "patch": "@@ -1,121 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # Method lookup\n-//!\n-//! Method lookup can be rather complex due to the interaction of a number\n-//! of factors, such as self types, autoderef, trait lookup, etc. This\n-//! file provides an overview of the process. More detailed notes are in\n-//! the code itself, naturally.\n-//!\n-//! One way to think of method lookup is that we convert an expression of\n-//! the form:\n-//!\n-//!     receiver.method(...)\n-//!\n-//! into a more explicit UFCS form:\n-//!\n-//!     Trait::method(ADJ(receiver), ...) // for a trait call\n-//!     ReceiverType::method(ADJ(receiver), ...) // for an inherent method call\n-//!\n-//! Here `ADJ` is some kind of adjustment, which is typically a series of\n-//! autoderefs and then possibly an autoref (e.g., `&**receiver`). However\n-//! we sometimes do other adjustments and coercions along the way, in\n-//! particular unsizing (e.g., converting from `[T, ..n]` to `[T]`).\n-//!\n-//! ## The Two Phases\n-//!\n-//! Method lookup is divided into two major phases: probing (`probe.rs`)\n-//! and confirmation (`confirm.rs`). The probe phase is when we decide\n-//! what method to call and how to adjust the receiver. The confirmation\n-//! phase \"applies\" this selection, updating the side-tables, unifying\n-//! type variables, and otherwise doing side-effectful things.\n-//!\n-//! One reason for this division is to be more amenable to caching.  The\n-//! probe phase produces a \"pick\" (`probe::Pick`), which is designed to be\n-//! cacheable across method-call sites. Therefore, it does not include\n-//! inference variables or other information.\n-//!\n-//! ## Probe phase\n-//!\n-//! The probe phase (`probe.rs`) decides what method is being called and\n-//! how to adjust the receiver.\n-//!\n-//! ### Steps\n-//!\n-//! The first thing that the probe phase does is to create a series of\n-//! *steps*. This is done by progressively dereferencing the receiver type\n-//! until it cannot be deref'd anymore, as well as applying an optional\n-//! \"unsize\" step. So if the receiver has type `Rc<Box<[T; 3]>>`, this\n-//! might yield:\n-//!\n-//!     Rc<Box<[T; 3]>>\n-//!     Box<[T; 3]>\n-//!     [T; 3]\n-//!     [T]\n-//!\n-//! ### Candidate assembly\n-//!\n-//! We then search along those steps to create a list of *candidates*. A\n-//! `Candidate` is a method item that might plausibly be the method being\n-//! invoked. For each candidate, we'll derive a \"transformed self type\"\n-//! that takes into account explicit self.\n-//!\n-//! Candidates are grouped into two kinds, inherent and extension.\n-//!\n-//! **Inherent candidates** are those that are derived from the\n-//! type of the receiver itself.  So, if you have a receiver of some\n-//! nominal type `Foo` (e.g., a struct), any methods defined within an\n-//! impl like `impl Foo` are inherent methods.  Nothing needs to be\n-//! imported to use an inherent method, they are associated with the type\n-//! itself (note that inherent impls can only be defined in the same\n-//! module as the type itself).\n-//!\n-//! FIXME: Inherent candidates are not always derived from impls.  If you\n-//! have a trait object, such as a value of type `Box<ToString>`, then the\n-//! trait methods (`to_string()`, in this case) are inherently associated\n-//! with it. Another case is type parameters, in which case the methods of\n-//! their bounds are inherent. However, this part of the rules is subject\n-//! to change: when DST's \"impl Trait for Trait\" is complete, trait object\n-//! dispatch could be subsumed into trait matching, and the type parameter\n-//! behavior should be reconsidered in light of where clauses.\n-//!\n-//! **Extension candidates** are derived from imported traits.  If I have\n-//! the trait `ToString` imported, and I call `to_string()` on a value of\n-//! type `T`, then we will go off to find out whether there is an impl of\n-//! `ToString` for `T`.  These kinds of method calls are called \"extension\n-//! methods\".  They can be defined in any module, not only the one that\n-//! defined `T`.  Furthermore, you must import the trait to call such a\n-//! method.\n-//!\n-//! So, let's continue our example. Imagine that we were calling a method\n-//! `foo` with the receiver `Rc<Box<[T; 3]>>` and there is a trait `Foo`\n-//! that defines it with `&self` for the type `Rc<U>` as well as a method\n-//! on the type `Box` that defines `Foo` but with `&mut self`. Then we\n-//! might have two candidates:\n-//!\n-//!     &Rc<Box<[T; 3]>> from the impl of `Foo` for `Rc<U>` where `U=Box<T; 3]>\n-//!     &mut Box<[T; 3]>> from the inherent impl on `Box<U>` where `U=[T; 3]`\n-//!\n-//! ### Candidate search\n-//!\n-//! Finally, to actually pick the method, we will search down the steps,\n-//! trying to match the receiver type against the candidate types. At\n-//! each step, we also consider an auto-ref and auto-mut-ref to see whether\n-//! that makes any of the candidates match. We pick the first step where\n-//! we find a match.\n-//!\n-//! In the case of our example, the first step is `Rc<Box<[T; 3]>>`,\n-//! which does not itself match any candidate. But when we autoref it, we\n-//! get the type `&Rc<Box<[T; 3]>>` which does match. We would then\n-//! recursively consider all where-clauses that appear on the impl: if\n-//! those match (or we cannot rule out that they do), then this is the\n-//! method we would pick. Otherwise, we would continue down the series of\n-//! steps."}, {"sha": "ffbc8ad020ab7819af598d980947e4f59a1c295b", "filename": "src/librustc_typeck/check/method/mod.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d91a2bdac45cd919497a24207fab843124d4ba/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fmethod%2Fmod.rs?ref=b6d91a2bdac45cd919497a24207fab843124d4ba", "patch": "@@ -32,7 +32,6 @@ pub use self::CandidateSource::*;\n pub use self::suggest::{report_error, AllTraitsVec};\n \n mod confirm;\n-mod doc;\n mod probe;\n mod suggest;\n "}]}