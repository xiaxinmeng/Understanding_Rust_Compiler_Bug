{"sha": "ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVjMWE4ZjA4MWY5YjNiNzkyYmRjOTY0ZWNkZDJkMjcyZjhmZTg1OWQ=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2018-03-30T09:55:54Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2018-03-31T21:16:05Z"}, "message": "proc_macro: Tweak doc comments and negative literals\n\nThis commit tweaks the tokenization of a doc comment to use `#[doc = \"...\"]`\nlike `macro_rules!` does (instead of treating it as a `Literal` token).\nAdditionally it fixes treatment of negative literals in the compiler, for\nexapmle `Literal::i32(-1)`. The current fix is a bit of a hack around the\ncurrent compiler implementation, providing a fix at the proc-macro layer rather\nthan the libsyntax layer.", "tree": {"sha": "843eaa20de82e0f12273925ce8ea19d959c23cbe", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/843eaa20de82e0f12273925ce8ea19d959c23cbe"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "html_url": "https://github.com/rust-lang/rust/commit/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "696076144d4d904cc99c02f85cf46bbe52404657", "url": "https://api.github.com/repos/rust-lang/rust/commits/696076144d4d904cc99c02f85cf46bbe52404657", "html_url": "https://github.com/rust-lang/rust/commit/696076144d4d904cc99c02f85cf46bbe52404657"}], "stats": {"total": 218, "additions": 164, "deletions": 54}, "files": [{"sha": "007093981d3e19a6ee1ce62557b53627fc50c432", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 80, "deletions": 51, "changes": 131, "blob_url": "https://github.com/rust-lang/rust/blob/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "patch": "@@ -40,7 +40,6 @@\n #![feature(lang_items)]\n #![feature(optin_builtin_traits)]\n \n-#[macro_use]\n extern crate syntax;\n extern crate syntax_pos;\n extern crate rustc_errors;\n@@ -156,7 +155,7 @@ impl IntoIterator for TokenStream {\n     type IntoIter = TokenTreeIter;\n \n     fn into_iter(self) -> TokenTreeIter {\n-        TokenTreeIter { cursor: self.0.trees(), next: None }\n+        TokenTreeIter { cursor: self.0.trees(), stack: Vec::new() }\n     }\n }\n \n@@ -554,7 +553,7 @@ impl Literal {\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n pub struct TokenTreeIter {\n     cursor: tokenstream::Cursor,\n-    next: Option<tokenstream::TokenStream>,\n+    stack: Vec<TokenTree>,\n }\n \n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n@@ -563,9 +562,10 @@ impl Iterator for TokenTreeIter {\n \n     fn next(&mut self) -> Option<TokenTree> {\n         loop {\n-            let next =\n-                unwrap_or!(self.next.take().or_else(|| self.cursor.next_as_stream()), return None);\n-            let tree = TokenTree::from_internal(next, &mut self.next);\n+            let tree = self.stack.pop().or_else(|| {\n+                let next = self.cursor.next_as_stream()?;\n+                Some(TokenTree::from_internal(next, &mut self.stack))\n+            })?;\n             if tree.span.0 == DUMMY_SP {\n                 if let TokenNode::Group(Delimiter::None, stream) = tree.kind {\n                     self.cursor.insert(stream.0);\n@@ -598,12 +598,12 @@ impl Delimiter {\n }\n \n impl TokenTree {\n-    fn from_internal(stream: tokenstream::TokenStream, next: &mut Option<tokenstream::TokenStream>)\n+    fn from_internal(stream: tokenstream::TokenStream, stack: &mut Vec<TokenTree>)\n                 -> TokenTree {\n         use syntax::parse::token::*;\n \n         let (tree, is_joint) = stream.as_tree();\n-        let (mut span, token) = match tree {\n+        let (span, token) = match tree {\n             tokenstream::TokenTree::Token(span, token) => (span, token),\n             tokenstream::TokenTree::Delimited(span, delimed) => {\n                 let delimiter = Delimiter::from_internal(delimed.delim);\n@@ -615,34 +615,32 @@ impl TokenTree {\n         };\n \n         let op_kind = if is_joint { Spacing::Joint } else { Spacing::Alone };\n-        macro_rules! op {\n-            ($op:expr) => { TokenNode::Op($op, op_kind) }\n-        }\n-\n-        macro_rules! joint {\n-            ($first:expr, $rest:expr) => { joint($first, $rest, is_joint, &mut span, next) }\n+        macro_rules! tt {\n+            ($e:expr) => (TokenTree { span: Span(span), kind: $e })\n         }\n-\n-        fn joint(first: char, rest: Token, is_joint: bool, span: &mut syntax_pos::Span,\n-                 next: &mut Option<tokenstream::TokenStream>)\n-                 -> TokenNode {\n-            let (first_span, rest_span) = (*span, *span);\n-            *span = first_span;\n-            let tree = tokenstream::TokenTree::Token(rest_span, rest);\n-            *next = Some(if is_joint { tree.joint() } else { tree.into() });\n-            TokenNode::Op(first, Spacing::Joint)\n+        macro_rules! op {\n+            ($a:expr) => (TokenNode::Op($a, op_kind));\n+            ($a:expr, $b:expr) => ({\n+                stack.push(tt!(TokenNode::Op($b, op_kind).into()));\n+                TokenNode::Op($a, Spacing::Joint)\n+            });\n+            ($a:expr, $b:expr, $c:expr) => ({\n+                stack.push(tt!(TokenNode::Op($c, op_kind)));\n+                stack.push(tt!(TokenNode::Op($b, Spacing::Joint)));\n+                TokenNode::Op($a, Spacing::Joint)\n+            })\n         }\n \n         let kind = match token {\n             Eq => op!('='),\n             Lt => op!('<'),\n-            Le => joint!('<', Eq),\n-            EqEq => joint!('=', Eq),\n-            Ne => joint!('!', Eq),\n-            Ge => joint!('>', Eq),\n+            Le => op!('<', '='),\n+            EqEq => op!('=', '='),\n+            Ne => op!('!', '='),\n+            Ge => op!('>', '='),\n             Gt => op!('>'),\n-            AndAnd => joint!('&', BinOp(And)),\n-            OrOr => joint!('|', BinOp(Or)),\n+            AndAnd => op!('&', '&'),\n+            OrOr => op!('|', '|'),\n             Not => op!('!'),\n             Tilde => op!('~'),\n             BinOp(Plus) => op!('+'),\n@@ -653,37 +651,46 @@ impl TokenTree {\n             BinOp(Caret) => op!('^'),\n             BinOp(And) => op!('&'),\n             BinOp(Or) => op!('|'),\n-            BinOp(Shl) => joint!('<', Lt),\n-            BinOp(Shr) => joint!('>', Gt),\n-            BinOpEq(Plus) => joint!('+', Eq),\n-            BinOpEq(Minus) => joint!('-', Eq),\n-            BinOpEq(Star) => joint!('*', Eq),\n-            BinOpEq(Slash) => joint!('/', Eq),\n-            BinOpEq(Percent) => joint!('%', Eq),\n-            BinOpEq(Caret) => joint!('^', Eq),\n-            BinOpEq(And) => joint!('&', Eq),\n-            BinOpEq(Or) => joint!('|', Eq),\n-            BinOpEq(Shl) => joint!('<', Le),\n-            BinOpEq(Shr) => joint!('>', Ge),\n+            BinOp(Shl) => op!('<', '<'),\n+            BinOp(Shr) => op!('>', '>'),\n+            BinOpEq(Plus) => op!('+', '='),\n+            BinOpEq(Minus) => op!('-', '='),\n+            BinOpEq(Star) => op!('*', '='),\n+            BinOpEq(Slash) => op!('/', '='),\n+            BinOpEq(Percent) => op!('%', '='),\n+            BinOpEq(Caret) => op!('^', '='),\n+            BinOpEq(And) => op!('&', '='),\n+            BinOpEq(Or) => op!('|', '='),\n+            BinOpEq(Shl) => op!('<', '<', '='),\n+            BinOpEq(Shr) => op!('>', '>', '='),\n             At => op!('@'),\n             Dot => op!('.'),\n-            DotDot => joint!('.', Dot),\n-            DotDotDot => joint!('.', DotDot),\n-            DotDotEq => joint!('.', DotEq),\n+            DotDot => op!('.', '.'),\n+            DotDotDot => op!('.', '.', '.'),\n+            DotDotEq => op!('.', '.', '='),\n             Comma => op!(','),\n             Semi => op!(';'),\n             Colon => op!(':'),\n-            ModSep => joint!(':', Colon),\n-            RArrow => joint!('-', Gt),\n-            LArrow => joint!('<', BinOp(Minus)),\n-            FatArrow => joint!('=', Gt),\n+            ModSep => op!(':', ':'),\n+            RArrow => op!('-', '>'),\n+            LArrow => op!('<', '-'),\n+            FatArrow => op!('=', '>'),\n             Pound => op!('#'),\n             Dollar => op!('$'),\n             Question => op!('?'),\n \n             Ident(ident, false) | Lifetime(ident) => TokenNode::Term(Term(ident.name)),\n             Ident(ident, true) => TokenNode::Term(Term(Symbol::intern(&format!(\"r#{}\", ident)))),\n-            Literal(..) | DocComment(..) => TokenNode::Literal(self::Literal(token)),\n+            Literal(..) => TokenNode::Literal(self::Literal(token)),\n+            DocComment(c) => {\n+                let stream = vec![\n+                    tt!(TokenNode::Term(Term::intern(\"doc\"))),\n+                    tt!(op!('=')),\n+                    tt!(TokenNode::Literal(self::Literal(Literal(Lit::Str_(c), None)))),\n+                ].into_iter().collect();\n+                stack.push(tt!(TokenNode::Group(Delimiter::Bracket, stream)));\n+                op!('#')\n+            }\n \n             Interpolated(_) => {\n                 __internal::with_sess(|(sess, _)| {\n@@ -692,7 +699,7 @@ impl TokenTree {\n                 })\n             }\n \n-            DotEq => joint!('.', Eq),\n+            DotEq => op!('.', '='),\n             OpenDelim(..) | CloseDelim(..) => unreachable!(),\n             Whitespace | Comment | Shebang(..) | Eof => unreachable!(),\n         };\n@@ -724,7 +731,29 @@ impl TokenTree {\n                     } else { Ident(ident, false) };\n                 return TokenTree::Token(self.span.0, token).into();\n             }\n-            TokenNode::Literal(token) => return TokenTree::Token(self.span.0, token.0).into(),\n+            TokenNode::Literal(self::Literal(Literal(Lit::Integer(ref a), b)))\n+                if a.as_str().starts_with(\"-\") =>\n+            {\n+                let minus = BinOp(BinOpToken::Minus);\n+                let integer = Symbol::intern(&a.as_str()[1..]);\n+                let integer = Literal(Lit::Integer(integer), b);\n+                let a = TokenTree::Token(self.span.0, minus);\n+                let b = TokenTree::Token(self.span.0, integer);\n+                return vec![a, b].into_iter().collect()\n+            }\n+            TokenNode::Literal(self::Literal(Literal(Lit::Float(ref a), b)))\n+                if a.as_str().starts_with(\"-\") =>\n+            {\n+                let minus = BinOp(BinOpToken::Minus);\n+                let float = Symbol::intern(&a.as_str()[1..]);\n+                let float = Literal(Lit::Float(float), b);\n+                let a = TokenTree::Token(self.span.0, minus);\n+                let b = TokenTree::Token(self.span.0, float);\n+                return vec![a, b].into_iter().collect()\n+            }\n+            TokenNode::Literal(token) => {\n+                return TokenTree::Token(self.span.0, token.0).into()\n+            }\n         };\n \n         let token = match op {"}, {"sha": "d725adfec7544a6950ea29a1a7b13b71c902fcc1", "filename": "src/test/compile-fail-fulldeps/proc-macro/auxiliary/attributes-included.rs", "status": "modified", "additions": 27, "deletions": 3, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fauxiliary%2Fattributes-included.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fauxiliary%2Fattributes-included.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail-fulldeps%2Fproc-macro%2Fauxiliary%2Fattributes-included.rs?ref=ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "patch": "@@ -16,7 +16,7 @@\n \n extern crate proc_macro;\n \n-use proc_macro::{TokenStream, TokenTree, TokenNode, Delimiter, Literal};\n+use proc_macro::{TokenStream, TokenTree, TokenNode, Delimiter, Literal, Spacing};\n \n #[proc_macro_attribute]\n pub fn foo(attr: TokenStream, input: TokenStream) -> TokenStream {\n@@ -65,10 +65,34 @@ fn assert_inline(slice: &mut &[TokenTree]) {\n \n fn assert_doc(slice: &mut &[TokenTree]) {\n     match slice[0].kind {\n+        TokenNode::Op('#', Spacing::Alone) => {}\n+        _ => panic!(\"expected #\"),\n+    }\n+    let inner = match slice[1].kind {\n+        TokenNode::Group(Delimiter::Bracket, ref s) => s.clone(),\n+        _ => panic!(\"expected brackets\"),\n+    };\n+    let tokens = inner.into_iter().collect::<Vec<_>>();\n+    let tokens = &tokens[..];\n+\n+    if tokens.len() != 3 {\n+        panic!(\"expected three tokens in doc\")\n+    }\n+\n+    match tokens[0].kind {\n+        TokenNode::Term(ref t) => assert_eq!(\"doc\", t.as_str()),\n+        _ => panic!(\"expected `doc`\"),\n+    }\n+    match tokens[1].kind {\n+        TokenNode::Op('=', Spacing::Alone) => {}\n+        _ => panic!(\"expected equals\"),\n+    }\n+    match tokens[2].kind {\n         TokenNode::Literal(_) => {}\n-        _ => panic!(\"expected literal doc comment got other\"),\n+        _ => panic!(\"expected literal\"),\n     }\n-    *slice = &slice[1..];\n+\n+    *slice = &slice[2..];\n }\n \n fn assert_invoc(slice: &mut &[TokenTree]) {"}, {"sha": "e5ebb7c2e41b3fa53f224c6a690a4885cfeb484e", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/negative-token.rs", "status": "added", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnegative-token.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnegative-token.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fnegative-token.rs?ref=ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "patch": "@@ -0,0 +1,34 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// no-prefer-dynamic\n+\n+#![feature(proc_macro)]\n+#![crate_type = \"proc-macro\"]\n+\n+extern crate proc_macro;\n+\n+use proc_macro::*;\n+\n+#[proc_macro]\n+pub fn neg_one(_input: TokenStream) -> TokenStream {\n+    TokenTree {\n+        span: Span::call_site(),\n+        kind: TokenNode::Literal(Literal::i32(-1)),\n+    }.into()\n+}\n+\n+#[proc_macro]\n+pub fn neg_one_float(_input: TokenStream) -> TokenStream {\n+    TokenTree {\n+        span: Span::call_site(),\n+        kind: TokenNode::Literal(Literal::f32(-1.0)),\n+    }.into()\n+}"}, {"sha": "418e692fa24ad18105ea64607509766c3e372f74", "filename": "src/test/run-pass-fulldeps/proc-macro/negative-token.rs", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fnegative-token.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fnegative-token.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fnegative-token.rs?ref=ec1a8f081f9b3b792bdc964ecdd2d272f8fe859d", "patch": "@@ -0,0 +1,23 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:negative-token.rs\n+// ignore-stage1\n+\n+#![feature(proc_macro)]\n+\n+extern crate negative_token;\n+\n+use negative_token::*;\n+\n+fn main() {\n+    assert_eq!(-1, neg_one!());\n+    assert_eq!(-1.0, neg_one_float!());\n+}"}]}