{"sha": "275bf626f615f7f154249606ad369d6c142801a5", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI3NWJmNjI2ZjYxNWY3ZjE1NDI0OTYwNmFkMzY5ZDZjMTQyODAxYTU=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2020-09-26T15:46:19Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2020-09-26T17:27:09Z"}, "message": "pretty-print-reparse hack: Rename some variables for clarity", "tree": {"sha": "bb0b3d4568fac71201dcc5aa88caf7fda003f1c4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bb0b3d4568fac71201dcc5aa88caf7fda003f1c4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/275bf626f615f7f154249606ad369d6c142801a5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/275bf626f615f7f154249606ad369d6c142801a5", "html_url": "https://github.com/rust-lang/rust/commit/275bf626f615f7f154249606ad369d6c142801a5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/275bf626f615f7f154249606ad369d6c142801a5/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6f9a8a7f9b9732c55511d2a2a3914e8feafc7c52", "url": "https://api.github.com/repos/rust-lang/rust/commits/6f9a8a7f9b9732c55511d2a2a3914e8feafc7c52", "html_url": "https://github.com/rust-lang/rust/commit/6f9a8a7f9b9732c55511d2a2a3914e8feafc7c52"}], "stats": {"total": 37, "additions": 21, "deletions": 16}, "files": [{"sha": "a7c8eaa4b15e4b45276558bc5899b63a04c014a5", "filename": "compiler/rustc_parse/src/lib.rs", "status": "modified", "additions": 21, "deletions": 16, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/275bf626f615f7f154249606ad369d6c142801a5/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/275bf626f615f7f154249606ad369d6c142801a5/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flib.rs?ref=275bf626f615f7f154249606ad369d6c142801a5", "patch": "@@ -299,7 +299,7 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     // FIXME(#43081): Avoid this pretty-print + reparse hack\n     let source = pprust::nonterminal_to_string(nt);\n     let filename = FileName::macro_expansion_source_code(&source);\n-    let tokens_for_real = parse_stream_from_source_str(filename, source, sess, Some(span));\n+    let reparsed_tokens = parse_stream_from_source_str(filename, source, sess, Some(span));\n \n     // During early phases of the compiler the AST could get modified\n     // directly (e.g., attributes added or removed) and the internal cache\n@@ -325,17 +325,17 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     // modifications, including adding/removing typically non-semantic\n     // tokens such as extra braces and commas, don't happen.\n     if let Some(tokens) = tokens {\n-        if tokenstream_probably_equal_for_proc_macro(&tokens, &tokens_for_real, sess) {\n+        if tokenstream_probably_equal_for_proc_macro(&tokens, &reparsed_tokens, sess) {\n             return tokens;\n         }\n         info!(\n             \"cached tokens found, but they're not \\\"probably equal\\\", \\\n                 going with stringified version\"\n         );\n         info!(\"cached tokens: {:?}\", tokens);\n-        info!(\"reparsed tokens: {:?}\", tokens_for_real);\n+        info!(\"reparsed tokens: {:?}\", reparsed_tokens);\n     }\n-    tokens_for_real\n+    reparsed_tokens\n }\n \n // See comments in `Nonterminal::to_tokenstream` for why we care about\n@@ -344,8 +344,8 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n // This is otherwise the same as `eq_unspanned`, only recursing with a\n // different method.\n pub fn tokenstream_probably_equal_for_proc_macro(\n-    first: &TokenStream,\n-    other: &TokenStream,\n+    tokens: &TokenStream,\n+    reparsed_tokens: &TokenStream,\n     sess: &ParseSess,\n ) -> bool {\n     // When checking for `probably_eq`, we ignore certain tokens that aren't\n@@ -460,10 +460,11 @@ pub fn tokenstream_probably_equal_for_proc_macro(\n \n     // Break tokens after we expand any nonterminals, so that we break tokens\n     // that are produced as a result of nonterminal expansion.\n-    let t1 = first.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n-    let t2 = other.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n+    let tokens = tokens.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n+    let reparsed_tokens =\n+        reparsed_tokens.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n \n-    t1.eq_by(t2, |t1, t2| tokentree_probably_equal_for_proc_macro(&t1, &t2, sess))\n+    tokens.eq_by(reparsed_tokens, |t, rt| tokentree_probably_equal_for_proc_macro(&t, &rt, sess))\n }\n \n // See comments in `Nonterminal::to_tokenstream` for why we care about\n@@ -472,16 +473,20 @@ pub fn tokenstream_probably_equal_for_proc_macro(\n // This is otherwise the same as `eq_unspanned`, only recursing with a\n // different method.\n pub fn tokentree_probably_equal_for_proc_macro(\n-    first: &TokenTree,\n-    other: &TokenTree,\n+    token: &TokenTree,\n+    reparsed_token: &TokenTree,\n     sess: &ParseSess,\n ) -> bool {\n-    match (first, other) {\n-        (TokenTree::Token(token), TokenTree::Token(token2)) => {\n-            token_probably_equal_for_proc_macro(token, token2)\n+    match (token, reparsed_token) {\n+        (TokenTree::Token(token), TokenTree::Token(reparsed_token)) => {\n+            token_probably_equal_for_proc_macro(token, reparsed_token)\n         }\n-        (TokenTree::Delimited(_, delim, tts), TokenTree::Delimited(_, delim2, tts2)) => {\n-            delim == delim2 && tokenstream_probably_equal_for_proc_macro(&tts, &tts2, sess)\n+        (\n+            TokenTree::Delimited(_, delim, tokens),\n+            TokenTree::Delimited(_, reparsed_delim, reparsed_tokens),\n+        ) => {\n+            delim == reparsed_delim\n+                && tokenstream_probably_equal_for_proc_macro(tokens, reparsed_tokens, sess)\n         }\n         _ => false,\n     }"}]}