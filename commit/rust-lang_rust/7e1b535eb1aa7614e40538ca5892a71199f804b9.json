{"sha": "7e1b535eb1aa7614e40538ca5892a71199f804b9", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdlMWI1MzVlYjFhYTc2MTRlNDA1MzhjYTU4OTJhNzExOTlmODA0Yjk=", "commit": {"author": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2013-12-27T21:40:07Z"}, "committer": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2014-01-03T22:01:57Z"}, "message": "libsyntax: De-`@mut` `StringReader`, `TtReader`, and `reader`", "tree": {"sha": "bebc78cca75d060bb876e662ea9f0f39d1af4e17", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bebc78cca75d060bb876e662ea9f0f39d1af4e17"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7e1b535eb1aa7614e40538ca5892a71199f804b9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7e1b535eb1aa7614e40538ca5892a71199f804b9", "html_url": "https://github.com/rust-lang/rust/commit/7e1b535eb1aa7614e40538ca5892a71199f804b9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7e1b535eb1aa7614e40538ca5892a71199f804b9/comments", "author": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2b83377b2922e54e25fbc2e518efbf4feef70829", "url": "https://api.github.com/repos/rust-lang/rust/commits/2b83377b2922e54e25fbc2e518efbf4feef70829", "html_url": "https://github.com/rust-lang/rust/commit/2b83377b2922e54e25fbc2e518efbf4feef70829"}], "stats": {"total": 164, "additions": 77, "deletions": 87}, "files": [{"sha": "a7d1d8fb3663d581644300c7482453347f5755d7", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -25,7 +25,7 @@ pub fn expand_trace_macros(cx: &mut ExtCtxt,\n     let tt_rdr = new_tt_reader(cx.parse_sess().span_diagnostic,\n                                None,\n                                tt.to_owned());\n-    let rdr = tt_rdr as @mut reader;\n+    let rdr = tt_rdr as @reader;\n     let mut rust_parser = Parser(sess, cfg.clone(), rdr.dup());\n \n     if rust_parser.is_keyword(keywords::True) {"}, {"sha": "8b22e32262b642d1614e9a7e983caca698e6136e", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -221,12 +221,11 @@ pub enum parse_result {\n     error(codemap::Span, ~str)\n }\n \n-pub fn parse_or_else(\n-    sess: @ParseSess,\n-    cfg: ast::CrateConfig,\n-    rdr: @mut reader,\n-    ms: ~[matcher]\n-) -> HashMap<Ident, @named_match> {\n+pub fn parse_or_else(sess: @ParseSess,\n+                     cfg: ast::CrateConfig,\n+                     rdr: @reader,\n+                     ms: ~[matcher])\n+                     -> HashMap<Ident, @named_match> {\n     match parse(sess, cfg, rdr, ms) {\n       success(m) => m,\n       failure(sp, str) => sess.span_diagnostic.span_fatal(sp, str),\n@@ -245,7 +244,7 @@ pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n \n pub fn parse(sess: @ParseSess,\n              cfg: ast::CrateConfig,\n-             rdr: @mut reader,\n+             rdr: @reader,\n              ms: &[matcher])\n              -> parse_result {\n     let mut cur_eis = ~[];"}, {"sha": "32d9ed1238b1dbf5ee5e237813905a8a9f8a0940", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 3, "deletions": 10, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -130,11 +130,7 @@ fn generic_extension(cx: &ExtCtxt,\n         match *lhs {\n           @matched_nonterminal(nt_matchers(ref mtcs)) => {\n             // `none` is because we're not interpolating\n-            let arg_rdr = new_tt_reader(\n-                s_d,\n-                None,\n-                arg.to_owned()\n-            ) as @mut reader;\n+            let arg_rdr = new_tt_reader(s_d, None, arg.to_owned()) as @reader;\n             match parse(cx.parse_sess(), cx.cfg(), arg_rdr, *mtcs) {\n               success(named_matches) => {\n                 let rhs = match rhses[i] {\n@@ -154,10 +150,7 @@ fn generic_extension(cx: &ExtCtxt,\n                 // rhs has holes ( `$id` and `$(...)` that need filled)\n                 let trncbr = new_tt_reader(s_d, Some(named_matches),\n                                            rhs);\n-                let p = Parser(cx.parse_sess(),\n-                               cx.cfg(),\n-                               trncbr as @mut reader);\n-\n+                let p = Parser(cx.parse_sess(), cx.cfg(), trncbr as @reader);\n                 // Let the context choose how to interpret the result.\n                 // Weird, but useful for X-macros.\n                 return MRAny(@ParserAnyMacro {\n@@ -218,7 +211,7 @@ pub fn add_new_extension(cx: &mut ExtCtxt,\n                                    arg.clone());\n     let argument_map = parse_or_else(cx.parse_sess(),\n                                      cx.cfg(),\n-                                     arg_reader as @mut reader,\n+                                     arg_reader as @reader,\n                                      argument_gram);\n \n     // Extract the arguments:"}, {"sha": "f4c7132a1f69d4a025672560492f3ae93fc24c89", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -49,8 +49,8 @@ pub struct TtReader {\n pub fn new_tt_reader(sp_diag: @mut SpanHandler,\n                      interp: Option<HashMap<Ident,@named_match>>,\n                      src: ~[ast::token_tree])\n-                  -> @mut TtReader {\n-    let r = @mut TtReader {\n+                  -> @TtReader {\n+    let r = @TtReader {\n         sp_diag: sp_diag,\n         stack: RefCell::new(@mut TtFrame {\n             forest: @src,\n@@ -86,8 +86,8 @@ fn dup_tt_frame(f: @mut TtFrame) -> @mut TtFrame {\n     }\n }\n \n-pub fn dup_tt_reader(r: @mut TtReader) -> @mut TtReader {\n-    @mut TtReader {\n+pub fn dup_tt_reader(r: @TtReader) -> @TtReader {\n+    @TtReader {\n         sp_diag: r.sp_diag,\n         stack: RefCell::new(dup_tt_frame(r.stack.get())),\n         repeat_idx: r.repeat_idx.clone(),\n@@ -99,9 +99,8 @@ pub fn dup_tt_reader(r: @mut TtReader) -> @mut TtReader {\n }\n \n \n-fn lookup_cur_matched_by_matched(r: &mut TtReader,\n-                                      start: @named_match)\n-                                   -> @named_match {\n+fn lookup_cur_matched_by_matched(r: &TtReader, start: @named_match)\n+                                 -> @named_match {\n     fn red(ad: @named_match, idx: &uint) -> @named_match {\n         match *ad {\n           matched_nonterminal(_) => {\n@@ -115,7 +114,7 @@ fn lookup_cur_matched_by_matched(r: &mut TtReader,\n     repeat_idx.get().iter().fold(start, red)\n }\n \n-fn lookup_cur_matched(r: &mut TtReader, name: Ident) -> @named_match {\n+fn lookup_cur_matched(r: &TtReader, name: Ident) -> @named_match {\n     let matched_opt = {\n         let interpolations = r.interpolations.borrow();\n         interpolations.get().find_copy(&name)\n@@ -137,7 +136,7 @@ enum lis {\n     lis_contradiction(~str),\n }\n \n-fn lockstep_iter_size(t: &token_tree, r: &mut TtReader) -> lis {\n+fn lockstep_iter_size(t: &token_tree, r: &TtReader) -> lis {\n     fn lis_merge(lhs: lis, rhs: lis) -> lis {\n         match lhs {\n           lis_unconstrained => rhs.clone(),\n@@ -173,7 +172,7 @@ fn lockstep_iter_size(t: &token_tree, r: &mut TtReader) -> lis {\n \n // return the next token from the TtReader.\n // EFFECT: advances the reader's token field\n-pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n+pub fn tt_next_token(r: &TtReader) -> TokenAndSpan {\n     // XXX(pcwalton): Bad copy?\n     let ret_val = TokenAndSpan {\n         tok: r.cur_tok.get(),"}, {"sha": "248f5fe3ffb27f617c4b168e67158ea373978dd9", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -135,7 +135,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> ~str {\n     fail!(\"not a doc-comment: {}\", comment);\n }\n \n-fn read_to_eol(rdr: @mut StringReader) -> ~str {\n+fn read_to_eol(rdr: @StringReader) -> ~str {\n     let mut val = ~\"\";\n     while rdr.curr.get() != '\\n' && !is_eof(rdr) {\n         val.push_char(rdr.curr.get());\n@@ -145,21 +145,21 @@ fn read_to_eol(rdr: @mut StringReader) -> ~str {\n     return val;\n }\n \n-fn read_one_line_comment(rdr: @mut StringReader) -> ~str {\n+fn read_one_line_comment(rdr: @StringReader) -> ~str {\n     let val = read_to_eol(rdr);\n     assert!((val[0] == '/' as u8 && val[1] == '/' as u8) ||\n                  (val[0] == '#' as u8 && val[1] == '!' as u8));\n     return val;\n }\n \n-fn consume_non_eol_whitespace(rdr: @mut StringReader) {\n+fn consume_non_eol_whitespace(rdr: @StringReader) {\n     while is_whitespace(rdr.curr.get()) && rdr.curr.get() != '\\n' &&\n             !is_eof(rdr) {\n         bump(rdr);\n     }\n }\n \n-fn push_blank_line_comment(rdr: @mut StringReader, comments: &mut ~[cmnt]) {\n+fn push_blank_line_comment(rdr: @StringReader, comments: &mut ~[cmnt]) {\n     debug!(\">>> blank-line comment\");\n     let v: ~[~str] = ~[];\n     comments.push(cmnt {\n@@ -169,7 +169,7 @@ fn push_blank_line_comment(rdr: @mut StringReader, comments: &mut ~[cmnt]) {\n     });\n }\n \n-fn consume_whitespace_counting_blank_lines(rdr: @mut StringReader,\n+fn consume_whitespace_counting_blank_lines(rdr: @StringReader,\n                                            comments: &mut ~[cmnt]) {\n     while is_whitespace(rdr.curr.get()) && !is_eof(rdr) {\n         if rdr.col.get() == CharPos(0u) && rdr.curr.get() == '\\n' {\n@@ -180,7 +180,7 @@ fn consume_whitespace_counting_blank_lines(rdr: @mut StringReader,\n }\n \n \n-fn read_shebang_comment(rdr: @mut StringReader, code_to_the_left: bool,\n+fn read_shebang_comment(rdr: @StringReader, code_to_the_left: bool,\n                                             comments: &mut ~[cmnt]) {\n     debug!(\">>> shebang comment\");\n     let p = rdr.last_pos.get();\n@@ -192,7 +192,7 @@ fn read_shebang_comment(rdr: @mut StringReader, code_to_the_left: bool,\n     });\n }\n \n-fn read_line_comments(rdr: @mut StringReader, code_to_the_left: bool,\n+fn read_line_comments(rdr: @StringReader, code_to_the_left: bool,\n                                           comments: &mut ~[cmnt]) {\n     debug!(\">>> line comments\");\n     let p = rdr.last_pos.get();\n@@ -249,7 +249,7 @@ fn trim_whitespace_prefix_and_push_line(lines: &mut ~[~str],\n     lines.push(s1);\n }\n \n-fn read_block_comment(rdr: @mut StringReader,\n+fn read_block_comment(rdr: @StringReader,\n                       code_to_the_left: bool,\n                       comments: &mut ~[cmnt]) {\n     debug!(\">>> block comment\");\n@@ -280,7 +280,7 @@ fn read_block_comment(rdr: @mut StringReader,\n         while level > 0 {\n             debug!(\"=== block comment level {}\", level);\n             if is_eof(rdr) {\n-                (rdr as @mut reader).fatal(~\"unterminated block comment\");\n+                (rdr as @reader).fatal(~\"unterminated block comment\");\n             }\n             if rdr.curr.get() == '\\n' {\n                 trim_whitespace_prefix_and_push_line(&mut lines, curr_line,\n@@ -318,13 +318,13 @@ fn read_block_comment(rdr: @mut StringReader,\n     comments.push(cmnt {style: style, lines: lines, pos: p});\n }\n \n-fn peeking_at_comment(rdr: @mut StringReader) -> bool {\n+fn peeking_at_comment(rdr: @StringReader) -> bool {\n     return ((rdr.curr.get() == '/' && nextch(rdr) == '/') ||\n          (rdr.curr.get() == '/' && nextch(rdr) == '*')) ||\n          (rdr.curr.get() == '#' && nextch(rdr) == '!');\n }\n \n-fn consume_comment(rdr: @mut StringReader,\n+fn consume_comment(rdr: @StringReader,\n                    code_to_the_left: bool,\n                    comments: &mut ~[cmnt]) {\n     debug!(\">>> consume comment\");"}, {"sha": "e3b2c5406baf675b68f85b5e799983b954e8e58c", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 43, "deletions": 44, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -26,12 +26,12 @@ use std::util;\n pub use ext::tt::transcribe::{TtReader, new_tt_reader};\n \n pub trait reader {\n-    fn is_eof(@mut self) -> bool;\n-    fn next_token(@mut self) -> TokenAndSpan;\n-    fn fatal(@mut self, ~str) -> !;\n-    fn span_diag(@mut self) -> @mut SpanHandler;\n-    fn peek(@mut self) -> TokenAndSpan;\n-    fn dup(@mut self) -> @mut reader;\n+    fn is_eof(@self) -> bool;\n+    fn next_token(@self) -> TokenAndSpan;\n+    fn fatal(@self, ~str) -> !;\n+    fn span_diag(@self) -> @mut SpanHandler;\n+    fn peek(@self) -> TokenAndSpan;\n+    fn dup(@self) -> @reader;\n }\n \n #[deriving(Clone, Eq)]\n@@ -59,7 +59,7 @@ pub struct StringReader {\n \n pub fn new_string_reader(span_diagnostic: @mut SpanHandler,\n                          filemap: @codemap::FileMap)\n-                      -> @mut StringReader {\n+                      -> @StringReader {\n     let r = new_low_level_string_reader(span_diagnostic, filemap);\n     string_advance_token(r); /* fill in peek_* */\n     return r;\n@@ -68,10 +68,10 @@ pub fn new_string_reader(span_diagnostic: @mut SpanHandler,\n /* For comments.rs, which hackily pokes into 'pos' and 'curr' */\n pub fn new_low_level_string_reader(span_diagnostic: @mut SpanHandler,\n                                    filemap: @codemap::FileMap)\n-                                -> @mut StringReader {\n+                                -> @StringReader {\n     // Force the initial reader bump to start on a fresh line\n     let initial_char = '\\n';\n-    let r = @mut StringReader {\n+    let r = @StringReader {\n         span_diagnostic: span_diagnostic,\n         src: filemap.src,\n         pos: Cell::new(filemap.start_pos),\n@@ -90,8 +90,8 @@ pub fn new_low_level_string_reader(span_diagnostic: @mut SpanHandler,\n // duplicating the string reader is probably a bad idea, in\n // that using them will cause interleaved pushes of line\n // offsets to the underlying filemap...\n-fn dup_string_reader(r: @mut StringReader) -> @mut StringReader {\n-    @mut StringReader {\n+fn dup_string_reader(r: @StringReader) -> @StringReader {\n+    @StringReader {\n         span_diagnostic: r.span_diagnostic,\n         src: r.src,\n         pos: Cell::new(r.pos.get()),\n@@ -105,9 +105,9 @@ fn dup_string_reader(r: @mut StringReader) -> @mut StringReader {\n }\n \n impl reader for StringReader {\n-    fn is_eof(@mut self) -> bool { is_eof(self) }\n+    fn is_eof(@self) -> bool { is_eof(self) }\n     // return the next token. EFFECT: advances the string_reader.\n-    fn next_token(@mut self) -> TokenAndSpan {\n+    fn next_token(@self) -> TokenAndSpan {\n         let ret_val = {\n             let mut peek_tok = self.peek_tok.borrow_mut();\n             TokenAndSpan {\n@@ -118,45 +118,45 @@ impl reader for StringReader {\n         string_advance_token(self);\n         ret_val\n     }\n-    fn fatal(@mut self, m: ~str) -> ! {\n+    fn fatal(@self, m: ~str) -> ! {\n         self.span_diagnostic.span_fatal(self.peek_span.get(), m)\n     }\n-    fn span_diag(@mut self) -> @mut SpanHandler { self.span_diagnostic }\n-    fn peek(@mut self) -> TokenAndSpan {\n+    fn span_diag(@self) -> @mut SpanHandler { self.span_diagnostic }\n+    fn peek(@self) -> TokenAndSpan {\n         // XXX(pcwalton): Bad copy!\n         TokenAndSpan {\n             tok: self.peek_tok.get(),\n             sp: self.peek_span.get(),\n         }\n     }\n-    fn dup(@mut self) -> @mut reader { dup_string_reader(self) as @mut reader }\n+    fn dup(@self) -> @reader { dup_string_reader(self) as @reader }\n }\n \n impl reader for TtReader {\n-    fn is_eof(@mut self) -> bool {\n+    fn is_eof(@self) -> bool {\n         let cur_tok = self.cur_tok.borrow();\n         *cur_tok.get() == token::EOF\n     }\n-    fn next_token(@mut self) -> TokenAndSpan {\n+    fn next_token(@self) -> TokenAndSpan {\n         let r = tt_next_token(self);\n         debug!(\"TtReader: r={:?}\", r);\n         return r;\n     }\n-    fn fatal(@mut self, m: ~str) -> ! {\n+    fn fatal(@self, m: ~str) -> ! {\n         self.sp_diag.span_fatal(self.cur_span.get(), m);\n     }\n-    fn span_diag(@mut self) -> @mut SpanHandler { self.sp_diag }\n-    fn peek(@mut self) -> TokenAndSpan {\n+    fn span_diag(@self) -> @mut SpanHandler { self.sp_diag }\n+    fn peek(@self) -> TokenAndSpan {\n         TokenAndSpan {\n             tok: self.cur_tok.get(),\n             sp: self.cur_span.get(),\n         }\n     }\n-    fn dup(@mut self) -> @mut reader { dup_tt_reader(self) as @mut reader }\n+    fn dup(@self) -> @reader { dup_tt_reader(self) as @reader }\n }\n \n // report a lexical error spanning [`from_pos`, `to_pos`)\n-fn fatal_span(rdr: @mut StringReader,\n+fn fatal_span(rdr: @StringReader,\n               from_pos: BytePos,\n               to_pos: BytePos,\n               m: ~str)\n@@ -167,7 +167,7 @@ fn fatal_span(rdr: @mut StringReader,\n \n // report a lexical error spanning [`from_pos`, `to_pos`), appending an\n // escaped character to the error message\n-fn fatal_span_char(rdr: @mut StringReader,\n+fn fatal_span_char(rdr: @StringReader,\n                    from_pos: BytePos,\n                    to_pos: BytePos,\n                    m: ~str,\n@@ -181,7 +181,7 @@ fn fatal_span_char(rdr: @mut StringReader,\n \n // report a lexical error spanning [`from_pos`, `to_pos`), appending the\n // offending string to the error message\n-fn fatal_span_verbose(rdr: @mut StringReader,\n+fn fatal_span_verbose(rdr: @StringReader,\n                       from_pos: BytePos,\n                       to_pos: BytePos,\n                       m: ~str)\n@@ -197,7 +197,7 @@ fn fatal_span_verbose(rdr: @mut StringReader,\n \n // EFFECT: advance peek_tok and peek_span to refer to the next token.\n // EFFECT: update the interner, maybe.\n-fn string_advance_token(r: @mut StringReader) {\n+fn string_advance_token(r: @StringReader) {\n     match (consume_whitespace_and_comments(r)) {\n         Some(comment) => {\n             r.peek_span.set(comment.sp);\n@@ -224,7 +224,7 @@ fn byte_offset(rdr: &StringReader, pos: BytePos) -> BytePos {\n /// up to but excluding `rdr.last_pos`, meaning the slice does not include\n /// the character `rdr.curr`.\n pub fn with_str_from<T>(\n-                     rdr: @mut StringReader,\n+                     rdr: @StringReader,\n                      start: BytePos,\n                      f: |s: &str| -> T)\n                      -> T {\n@@ -234,7 +234,7 @@ pub fn with_str_from<T>(\n /// Calls `f` with astring slice of the source text spanning from `start`\n /// up to but excluding `end`.\n fn with_str_from_to<T>(\n-                    rdr: @mut StringReader,\n+                    rdr: @StringReader,\n                     start: BytePos,\n                     end: BytePos,\n                     f: |s: &str| -> T)\n@@ -246,7 +246,7 @@ fn with_str_from_to<T>(\n \n // EFFECT: advance the StringReader by one character. If a newline is\n // discovered, add it to the FileMap's list of line start offsets.\n-pub fn bump(rdr: &mut StringReader) {\n+pub fn bump(rdr: &StringReader) {\n     rdr.last_pos.set(rdr.pos.get());\n     let current_byte_offset = byte_offset(rdr, rdr.pos.get()).to_uint();\n     if current_byte_offset < (rdr.src).len() {\n@@ -272,10 +272,10 @@ pub fn bump(rdr: &mut StringReader) {\n         rdr.curr.set(unsafe { transmute(-1u32) }); // FIXME: #8971: unsound\n     }\n }\n-pub fn is_eof(rdr: @mut StringReader) -> bool {\n+pub fn is_eof(rdr: @StringReader) -> bool {\n     rdr.curr.get() == unsafe { transmute(-1u32) } // FIXME: #8971: unsound\n }\n-pub fn nextch(rdr: @mut StringReader) -> char {\n+pub fn nextch(rdr: @StringReader) -> char {\n     let offset = byte_offset(rdr, rdr.pos.get()).to_uint();\n     if offset < (rdr.src).len() {\n         return rdr.src.char_at(offset);\n@@ -306,7 +306,7 @@ fn is_hex_digit(c: char) -> bool {\n \n // EFFECT: eats whitespace and comments.\n // returns a Some(sugared-doc-attr) if one exists, None otherwise.\n-fn consume_whitespace_and_comments(rdr: @mut StringReader)\n+fn consume_whitespace_and_comments(rdr: @StringReader)\n                                 -> Option<TokenAndSpan> {\n     while is_whitespace(rdr.curr.get()) { bump(rdr); }\n     return consume_any_line_comment(rdr);\n@@ -319,7 +319,7 @@ pub fn is_line_non_doc_comment(s: &str) -> bool {\n // PRECONDITION: rdr.curr is not whitespace\n // EFFECT: eats any kind of comment.\n // returns a Some(sugared-doc-attr) if one exists, None otherwise\n-fn consume_any_line_comment(rdr: @mut StringReader)\n+fn consume_any_line_comment(rdr: @StringReader)\n                          -> Option<TokenAndSpan> {\n     if rdr.curr.get() == '/' {\n         match nextch(rdr) {\n@@ -377,8 +377,7 @@ pub fn is_block_non_doc_comment(s: &str) -> bool {\n }\n \n // might return a sugared-doc-attr\n-fn consume_block_comment(rdr: @mut StringReader)\n-                      -> Option<TokenAndSpan> {\n+fn consume_block_comment(rdr: @StringReader) -> Option<TokenAndSpan> {\n     // block comments starting with \"/**\" or \"/*!\" are doc-comments\n     let is_doc_comment = rdr.curr.get() == '*' || rdr.curr.get() == '!';\n     let start_bpos = rdr.pos.get() - BytePos(if is_doc_comment {3} else {2});\n@@ -425,7 +424,7 @@ fn consume_block_comment(rdr: @mut StringReader)\n     if res.is_some() { res } else { consume_whitespace_and_comments(rdr) }\n }\n \n-fn scan_exponent(rdr: @mut StringReader, start_bpos: BytePos) -> Option<~str> {\n+fn scan_exponent(rdr: @StringReader, start_bpos: BytePos) -> Option<~str> {\n     let mut c = rdr.curr.get();\n     let mut rslt = ~\"\";\n     if c == 'e' || c == 'E' {\n@@ -446,7 +445,7 @@ fn scan_exponent(rdr: @mut StringReader, start_bpos: BytePos) -> Option<~str> {\n     } else { return None::<~str>; }\n }\n \n-fn scan_digits(rdr: @mut StringReader, radix: uint) -> ~str {\n+fn scan_digits(rdr: @StringReader, radix: uint) -> ~str {\n     let mut rslt = ~\"\";\n     loop {\n         let c = rdr.curr.get();\n@@ -461,7 +460,7 @@ fn scan_digits(rdr: @mut StringReader, radix: uint) -> ~str {\n     };\n }\n \n-fn scan_number(c: char, rdr: @mut StringReader) -> token::Token {\n+fn scan_number(c: char, rdr: @StringReader) -> token::Token {\n     let mut num_str;\n     let mut base = 10u;\n     let mut c = c;\n@@ -597,7 +596,7 @@ fn scan_number(c: char, rdr: @mut StringReader) -> token::Token {\n     }\n }\n \n-fn scan_numeric_escape(rdr: @mut StringReader, n_hex_digits: uint) -> char {\n+fn scan_numeric_escape(rdr: @StringReader, n_hex_digits: uint) -> char {\n     let mut accum_int = 0;\n     let mut i = n_hex_digits;\n     let start_bpos = rdr.last_pos.get();\n@@ -638,7 +637,7 @@ fn ident_continue(c: char) -> bool {\n // return the next token from the string\n // EFFECT: advances the input past that token\n // EFFECT: updates the interner\n-fn next_token_inner(rdr: @mut StringReader) -> token::Token {\n+fn next_token_inner(rdr: @StringReader) -> token::Token {\n     let c = rdr.curr.get();\n     if ident_start(c) && nextch(rdr) != '\"' && nextch(rdr) != '#' {\n         // Note: r as in r\" or r#\" is part of a raw string literal,\n@@ -663,7 +662,7 @@ fn next_token_inner(rdr: @mut StringReader) -> token::Token {\n     if is_dec_digit(c) {\n         return scan_number(c, rdr);\n     }\n-    fn binop(rdr: @mut StringReader, op: token::binop) -> token::Token {\n+    fn binop(rdr: @StringReader, op: token::binop) -> token::Token {\n         bump(rdr);\n         if rdr.curr.get() == '=' {\n             bump(rdr);\n@@ -951,7 +950,7 @@ fn next_token_inner(rdr: @mut StringReader) -> token::Token {\n     }\n }\n \n-fn consume_whitespace(rdr: @mut StringReader) {\n+fn consume_whitespace(rdr: @StringReader) {\n     while is_whitespace(rdr.curr.get()) && !is_eof(rdr) { bump(rdr); }\n }\n \n@@ -966,7 +965,7 @@ mod test {\n \n     // represents a testing reader (incl. both reader and interner)\n     struct Env {\n-        string_reader: @mut StringReader\n+        string_reader: @StringReader\n     }\n \n     // open a string reader for the given string"}, {"sha": "21fdf1d2327d1212109646e8672ce2de30193604", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -312,7 +312,7 @@ pub fn filemap_to_tts(sess: @ParseSess, filemap: @FileMap)\n     // parsing tt's probably shouldn't require a parser at all.\n     let cfg = ~[];\n     let srdr = lexer::new_string_reader(sess.span_diagnostic, filemap);\n-    let mut p1 = Parser(sess, cfg, srdr as @mut reader);\n+    let mut p1 = Parser(sess, cfg, srdr as @reader);\n     p1.parse_all_token_trees()\n }\n \n@@ -321,7 +321,7 @@ pub fn tts_to_parser(sess: @ParseSess,\n                      tts: ~[ast::token_tree],\n                      cfg: ast::CrateConfig) -> Parser {\n     let trdr = lexer::new_tt_reader(sess.span_diagnostic, None, tts);\n-    Parser(sess, cfg, trdr as @mut reader)\n+    Parser(sess, cfg, trdr as @reader)\n }\n \n // abort if necessary"}, {"sha": "20f202826ec749471c0c7dfb02dc674901f8fd96", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7e1b535eb1aa7614e40538ca5892a71199f804b9/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=7e1b535eb1aa7614e40538ca5892a71199f804b9", "patch": "@@ -286,7 +286,7 @@ struct ParsedItemsAndViewItems {\n \n /* ident is handled by common.rs */\n \n-pub fn Parser(sess: @ParseSess, cfg: ast::CrateConfig, rdr: @mut reader)\n+pub fn Parser(sess: @ParseSess, cfg: ast::CrateConfig, rdr: @reader)\n               -> Parser {\n     let tok0 = rdr.next_token();\n     let interner = get_ident_interner();\n@@ -340,7 +340,7 @@ pub struct Parser {\n     tokens_consumed: uint,\n     restriction: restriction,\n     quote_depth: uint, // not (yet) related to the quasiquoter\n-    reader: @mut reader,\n+    reader: @reader,\n     interner: @token::ident_interner,\n     /// The set of seen errors about obsolete syntax. Used to suppress\n     /// extra detail when the same error is seen twice"}]}