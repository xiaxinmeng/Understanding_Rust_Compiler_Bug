{"sha": "579420fbdd9951ae230a9def03e157d9b9957b2f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU3OTQyMGZiZGQ5OTUxYWUyMzBhOWRlZjAzZTE1N2Q5Yjk5NTdiMmY=", "commit": {"author": {"name": "Nicholas Mazzuca", "email": "npmazzuca@gmail.com", "date": "2015-10-26T03:51:51Z"}, "committer": {"name": "Nicholas Mazzuca", "email": "npmazzuca@gmail.com", "date": "2015-10-31T19:22:15Z"}, "message": "Check unchecked_div|rem's specialisation\n\nSimilarly to the simd intrinsics.", "tree": {"sha": "821762e3ba490a2759a0b67b278b458b9b1d7271", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/821762e3ba490a2759a0b67b278b458b9b1d7271"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/579420fbdd9951ae230a9def03e157d9b9957b2f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/579420fbdd9951ae230a9def03e157d9b9957b2f", "html_url": "https://github.com/rust-lang/rust/commit/579420fbdd9951ae230a9def03e157d9b9957b2f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/579420fbdd9951ae230a9def03e157d9b9957b2f/comments", "author": {"login": "ubsan", "id": 60298436, "node_id": "MDQ6VXNlcjYwMjk4NDM2", "avatar_url": "https://avatars.githubusercontent.com/u/60298436?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ubsan", "html_url": "https://github.com/ubsan", "followers_url": "https://api.github.com/users/ubsan/followers", "following_url": "https://api.github.com/users/ubsan/following{/other_user}", "gists_url": "https://api.github.com/users/ubsan/gists{/gist_id}", "starred_url": "https://api.github.com/users/ubsan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ubsan/subscriptions", "organizations_url": "https://api.github.com/users/ubsan/orgs", "repos_url": "https://api.github.com/users/ubsan/repos", "events_url": "https://api.github.com/users/ubsan/events{/privacy}", "received_events_url": "https://api.github.com/users/ubsan/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ubsan", "id": 60298436, "node_id": "MDQ6VXNlcjYwMjk4NDM2", "avatar_url": "https://avatars.githubusercontent.com/u/60298436?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ubsan", "html_url": "https://github.com/ubsan", "followers_url": "https://api.github.com/users/ubsan/followers", "following_url": "https://api.github.com/users/ubsan/following{/other_user}", "gists_url": "https://api.github.com/users/ubsan/gists{/gist_id}", "starred_url": "https://api.github.com/users/ubsan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ubsan/subscriptions", "organizations_url": "https://api.github.com/users/ubsan/orgs", "repos_url": "https://api.github.com/users/ubsan/repos", "events_url": "https://api.github.com/users/ubsan/events{/privacy}", "received_events_url": "https://api.github.com/users/ubsan/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d2f41bd5be70544411e5ed42bcdb201e6ab25eb2", "url": "https://api.github.com/repos/rust-lang/rust/commits/d2f41bd5be70544411e5ed42bcdb201e6ab25eb2", "html_url": "https://github.com/rust-lang/rust/commit/d2f41bd5be70544411e5ed42bcdb201e6ab25eb2"}], "stats": {"total": 1009, "additions": 605, "deletions": 404}, "files": [{"sha": "2961aff4965e27668ba89284977ea238fa27e617", "filename": "src/libcore/intrinsics.rs", "status": "modified", "additions": 75, "deletions": 17, "changes": 92, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fintrinsics.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -492,114 +492,172 @@ extern \"rust-intrinsic\" {\n     pub fn roundf64(x: f64) -> f64;\n \n     /// Returns the number of bits set in a `u8`.\n+    #[cfg(stage0)]\n     pub fn ctpop8(x: u8) -> u8;\n     /// Returns the number of bits set in a `u16`.\n+    #[cfg(stage0)]\n     pub fn ctpop16(x: u16) -> u16;\n     /// Returns the number of bits set in a `u32`.\n+    #[cfg(stage0)]\n     pub fn ctpop32(x: u32) -> u32;\n     /// Returns the number of bits set in a `u64`.\n+    #[cfg(stage0)]\n     pub fn ctpop64(x: u64) -> u64;\n+    /// Returns the number of bits set in an integer type `T`\n+    #[cfg(not(stage0))]\n+    pub fn ctpop<T>(x: T) -> T;\n \n     /// Returns the number of leading bits unset in a `u8`.\n+    #[cfg(stage0)]\n     pub fn ctlz8(x: u8) -> u8;\n     /// Returns the number of leading bits unset in a `u16`.\n+    #[cfg(stage0)]\n     pub fn ctlz16(x: u16) -> u16;\n     /// Returns the number of leading bits unset in a `u32`.\n+    #[cfg(stage0)]\n     pub fn ctlz32(x: u32) -> u32;\n     /// Returns the number of leading bits unset in a `u64`.\n+    #[cfg(stage0)]\n     pub fn ctlz64(x: u64) -> u64;\n+    /// Returns the number of leading bits unset in an integer type `T`\n+    #[cfg(not(stage0))]\n+    pub fn ctlz<T>(x: T) -> T;\n \n     /// Returns the number of trailing bits unset in a `u8`.\n+    #[cfg(stage0)]\n     pub fn cttz8(x: u8) -> u8;\n     /// Returns the number of trailing bits unset in a `u16`.\n+    #[cfg(stage0)]\n     pub fn cttz16(x: u16) -> u16;\n     /// Returns the number of trailing bits unset in a `u32`.\n+    #[cfg(stage0)]\n     pub fn cttz32(x: u32) -> u32;\n     /// Returns the number of trailing bits unset in a `u64`.\n+    #[cfg(stage0)]\n     pub fn cttz64(x: u64) -> u64;\n+    /// Returns the number of trailing bits unset in an integer type `T`\n+    #[cfg(not(stage0))]\n+    pub fn cttz<T>(x: T) -> T;\n \n     /// Reverses the bytes in a `u16`.\n+    #[cfg(stage0)]\n     pub fn bswap16(x: u16) -> u16;\n     /// Reverses the bytes in a `u32`.\n+    #[cfg(stage0)]\n     pub fn bswap32(x: u32) -> u32;\n     /// Reverses the bytes in a `u64`.\n+    #[cfg(stage0)]\n     pub fn bswap64(x: u64) -> u64;\n+    /// Reverses the bytes in an integer type `T`.\n+    #[cfg(not(stage0))]\n+    pub fn bswap<T>(x: T) -> T;\n \n     /// Performs checked `i8` addition.\n+    #[cfg(stage0)]\n     pub fn i8_add_with_overflow(x: i8, y: i8) -> (i8, bool);\n     /// Performs checked `i16` addition.\n+    #[cfg(stage0)]\n     pub fn i16_add_with_overflow(x: i16, y: i16) -> (i16, bool);\n     /// Performs checked `i32` addition.\n+    #[cfg(stage0)]\n     pub fn i32_add_with_overflow(x: i32, y: i32) -> (i32, bool);\n     /// Performs checked `i64` addition.\n+    #[cfg(stage0)]\n     pub fn i64_add_with_overflow(x: i64, y: i64) -> (i64, bool);\n \n     /// Performs checked `u8` addition.\n+    #[cfg(stage0)]\n     pub fn u8_add_with_overflow(x: u8, y: u8) -> (u8, bool);\n     /// Performs checked `u16` addition.\n+    #[cfg(stage0)]\n     pub fn u16_add_with_overflow(x: u16, y: u16) -> (u16, bool);\n     /// Performs checked `u32` addition.\n+    #[cfg(stage0)]\n     pub fn u32_add_with_overflow(x: u32, y: u32) -> (u32, bool);\n     /// Performs checked `u64` addition.\n+    #[cfg(stage0)]\n     pub fn u64_add_with_overflow(x: u64, y: u64) -> (u64, bool);\n \n+    /// Performs checked integer addition.\n+    #[cfg(not(stage0))]\n+    pub fn add_with_overflow<T>(x: T, y: T) -> (T, bool);\n+\n     /// Performs checked `i8` subtraction.\n+    #[cfg(stage0)]\n     pub fn i8_sub_with_overflow(x: i8, y: i8) -> (i8, bool);\n     /// Performs checked `i16` subtraction.\n+    #[cfg(stage0)]\n     pub fn i16_sub_with_overflow(x: i16, y: i16) -> (i16, bool);\n     /// Performs checked `i32` subtraction.\n+    #[cfg(stage0)]\n     pub fn i32_sub_with_overflow(x: i32, y: i32) -> (i32, bool);\n     /// Performs checked `i64` subtraction.\n+    #[cfg(stage0)]\n     pub fn i64_sub_with_overflow(x: i64, y: i64) -> (i64, bool);\n \n     /// Performs checked `u8` subtraction.\n+    #[cfg(stage0)]\n     pub fn u8_sub_with_overflow(x: u8, y: u8) -> (u8, bool);\n     /// Performs checked `u16` subtraction.\n+    #[cfg(stage0)]\n     pub fn u16_sub_with_overflow(x: u16, y: u16) -> (u16, bool);\n     /// Performs checked `u32` subtraction.\n+    #[cfg(stage0)]\n     pub fn u32_sub_with_overflow(x: u32, y: u32) -> (u32, bool);\n     /// Performs checked `u64` subtraction.\n+    #[cfg(stage0)]\n     pub fn u64_sub_with_overflow(x: u64, y: u64) -> (u64, bool);\n \n+    /// Performs checked integer subtraction\n+    #[cfg(not(stage0))]\n+    pub fn sub_with_overflow<T>(x: T, y: T) -> (T, bool);\n+\n     /// Performs checked `i8` multiplication.\n+    #[cfg(stage0)]\n     pub fn i8_mul_with_overflow(x: i8, y: i8) -> (i8, bool);\n     /// Performs checked `i16` multiplication.\n+    #[cfg(stage0)]\n     pub fn i16_mul_with_overflow(x: i16, y: i16) -> (i16, bool);\n     /// Performs checked `i32` multiplication.\n+    #[cfg(stage0)]\n     pub fn i32_mul_with_overflow(x: i32, y: i32) -> (i32, bool);\n     /// Performs checked `i64` multiplication.\n+    #[cfg(stage0)]\n     pub fn i64_mul_with_overflow(x: i64, y: i64) -> (i64, bool);\n \n     /// Performs checked `u8` multiplication.\n+    #[cfg(stage0)]\n     pub fn u8_mul_with_overflow(x: u8, y: u8) -> (u8, bool);\n     /// Performs checked `u16` multiplication.\n+    #[cfg(stage0)]\n     pub fn u16_mul_with_overflow(x: u16, y: u16) -> (u16, bool);\n     /// Performs checked `u32` multiplication.\n+    #[cfg(stage0)]\n     pub fn u32_mul_with_overflow(x: u32, y: u32) -> (u32, bool);\n     /// Performs checked `u64` multiplication.\n+    #[cfg(stage0)]\n     pub fn u64_mul_with_overflow(x: u64, y: u64) -> (u64, bool);\n \n-    /// Returns (a + b) mod 2^N, where N is the width of N in bits.\n+    /// Performs checked integer multiplication\n+    #[cfg(not(stage0))]\n+    pub fn mul_with_overflow<T>(x: T, y: T) -> (T, bool);\n+\n+    /// Performs an unchecked division, resulting in undefined behavior\n+    /// where y = 0 or x = `T::min_value()` and y = -1\n+    #[cfg(not(stage0))]\n+    pub fn unchecked_div<T>(x: T, y: T) -> T;\n+    /// Returns the remainder of an unchecked division, resulting in\n+    /// undefined behavior where y = 0 or x = `T::min_value()` and y = -1\n+    #[cfg(not(stage0))]\n+    pub fn unchecked_rem<T>(x: T, y: T) -> T;\n+\n+    /// Returns (a + b) mod 2^N, where N is the width of T in bits.\n     pub fn overflowing_add<T>(a: T, b: T) -> T;\n-    /// Returns (a - b) mod 2^N, where N is the width of N in bits.\n+    /// Returns (a - b) mod 2^N, where N is the width of T in bits.\n     pub fn overflowing_sub<T>(a: T, b: T) -> T;\n-    /// Returns (a * b) mod 2^N, where N is the width of N in bits.\n+    /// Returns (a * b) mod 2^N, where N is the width of T in bits.\n     pub fn overflowing_mul<T>(a: T, b: T) -> T;\n \n-    /// Performs an unchecked signed division, which results in undefined behavior,\n-    /// in cases where y == 0, or x == isize::MIN and y == -1\n-    pub fn unchecked_sdiv<T>(x: T, y: T) -> T;\n-    /// Performs an unchecked unsigned division, which results in undefined behavior,\n-    /// in cases where y == 0\n-    pub fn unchecked_udiv<T>(x: T, y: T) -> T;\n-\n-    /// Returns the remainder of an unchecked signed division, which results in\n-    /// undefined behavior, in cases where y == 0, or x == isize::MIN and y == -1\n-    pub fn unchecked_srem<T>(x: T, y: T) -> T;\n-    /// Returns the remainder of an unchecked unsigned division, which results in\n-    /// undefined behavior, in cases where y == 0\n-    pub fn unchecked_urem<T>(x: T, y: T) -> T;\n-\n     /// Returns the value of the discriminant for the variant in 'v',\n     /// cast to a `u64`; if `T` has no discriminant, returns 0.\n     pub fn discriminant_value<T>(v: &T) -> u64;"}, {"sha": "5d15ada4e750988ef30c7e2711bbcfd697823648", "filename": "src/libcore/num/bignum.rs", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fnum%2Fbignum.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fnum%2Fbignum.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fnum%2Fbignum.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -55,13 +55,24 @@ macro_rules! impl_full_ops {\n     ($($ty:ty: add($addfn:path), mul/div($bigty:ident);)*) => (\n         $(\n             impl FullOps for $ty {\n+                #[cfg(stage0)]\n                 fn full_add(self, other: $ty, carry: bool) -> (bool, $ty) {\n                     // this cannot overflow, the output is between 0 and 2*2^nbits - 1\n                     // FIXME will LLVM optimize this into ADC or similar???\n                     let (v, carry1) = unsafe { $addfn(self, other) };\n                     let (v, carry2) = unsafe { $addfn(v, if carry {1} else {0}) };\n                     (carry1 || carry2, v)\n                 }\n+                #[cfg(not(stage0))]\n+                fn full_add(self, other: $ty, carry: bool) -> (bool, $ty) {\n+                    // this cannot overflow, the output is between 0 and 2*2^nbits - 1\n+                    // FIXME will LLVM optimize this into ADC or similar???\n+                    let (v, carry1) = unsafe { intrinsics::add_with_overflow(self, other) };\n+                    let (v, carry2) = unsafe {\n+                        intrinsics::add_with_overflow(v, if carry {1} else {0})\n+                    };\n+                    (carry1 || carry2, v)\n+                }\n \n                 fn full_mul(self, other: $ty, carry: $ty) -> ($ty, $ty) {\n                     // this cannot overflow, the output is between 0 and 2^nbits * (2^nbits - 1)"}, {"sha": "d4cfe051728a336f32500587d1745886f7ee7248", "filename": "src/libcore/num/mod.rs", "status": "modified", "additions": 163, "deletions": 7, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fnum%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fnum%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fnum%2Fmod.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -103,17 +103,18 @@ macro_rules! zero_one_impl_float {\n }\n zero_one_impl_float! { f32 f64 }\n \n+// Just for stage0; a byte swap on a byte is a no-op\n+// Delete this once it becomes unused\n+#[cfg(stage0)]\n+unsafe fn bswap8(x: u8) -> u8 { x }\n+\n macro_rules! checked_op {\n     ($U:ty, $op:path, $x:expr, $y:expr) => {{\n         let (result, overflowed) = unsafe { $op($x as $U, $y as $U) };\n         if overflowed { None } else { Some(result as Self) }\n     }}\n }\n \n-/// Swapping a single byte is a no-op. This is marked as `unsafe` for\n-/// consistency with the other `bswap` intrinsics.\n-unsafe fn bswap8(x: u8) -> u8 { x }\n-\n // `Int` + `SignedInt` implemented for signed integers\n macro_rules! int_impl {\n     ($ActualT:ty, $UnsignedT:ty, $BITS:expr,\n@@ -611,54 +612,110 @@ macro_rules! int_impl {\n }\n \n #[lang = \"i8\"]\n+#[cfg(stage0)]\n impl i8 {\n     int_impl! { i8, u8, 8,\n         intrinsics::i8_add_with_overflow,\n         intrinsics::i8_sub_with_overflow,\n         intrinsics::i8_mul_with_overflow }\n }\n+#[lang = \"i8\"]\n+#[cfg(not(stage0))]\n+impl i8 {\n+    int_impl! { i8, u8, 8,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[lang = \"i16\"]\n+#[cfg(stage0)]\n impl i16 {\n     int_impl! { i16, u16, 16,\n         intrinsics::i16_add_with_overflow,\n         intrinsics::i16_sub_with_overflow,\n         intrinsics::i16_mul_with_overflow }\n }\n+#[lang = \"i16\"]\n+#[cfg(not(stage0))]\n+impl i16 {\n+    int_impl! { i16, u16, 16,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[lang = \"i32\"]\n+#[cfg(stage0)]\n impl i32 {\n     int_impl! { i32, u32, 32,\n         intrinsics::i32_add_with_overflow,\n         intrinsics::i32_sub_with_overflow,\n         intrinsics::i32_mul_with_overflow }\n }\n+#[lang = \"i32\"]\n+#[cfg(not(stage0))]\n+impl i32 {\n+    int_impl! { i32, u32, 32,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[lang = \"i64\"]\n+#[cfg(stage0)]\n impl i64 {\n     int_impl! { i64, u64, 64,\n         intrinsics::i64_add_with_overflow,\n         intrinsics::i64_sub_with_overflow,\n         intrinsics::i64_mul_with_overflow }\n }\n+#[lang = \"i64\"]\n+#[cfg(not(stage0))]\n+impl i64 {\n+    int_impl! { i64, u64, 64,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[cfg(target_pointer_width = \"32\")]\n #[lang = \"isize\"]\n+#[cfg(stage0)]\n impl isize {\n     int_impl! { i32, u32, 32,\n         intrinsics::i32_add_with_overflow,\n         intrinsics::i32_sub_with_overflow,\n         intrinsics::i32_mul_with_overflow }\n }\n+#[cfg(target_pointer_width = \"32\")]\n+#[lang = \"isize\"]\n+#[cfg(not(stage0))]\n+impl isize {\n+    int_impl! { i32, u32, 32,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[cfg(target_pointer_width = \"64\")]\n #[lang = \"isize\"]\n+#[cfg(stage0)]\n impl isize {\n     int_impl! { i64, u64, 64,\n         intrinsics::i64_add_with_overflow,\n         intrinsics::i64_sub_with_overflow,\n         intrinsics::i64_mul_with_overflow }\n }\n+#[cfg(target_pointer_width = \"64\")]\n+#[lang = \"isize\"]\n+#[cfg(not(stage0))]\n+impl isize {\n+    int_impl! { i64, u64, 64,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n // `Int` + `UnsignedInt` implemented for signed integers\n macro_rules! uint_impl {\n@@ -744,6 +801,25 @@ macro_rules! uint_impl {\n             unsafe { $ctlz(self as $ActualT) as u32 }\n         }\n \n+        #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+        #[cfg(stage0)]\n+        #[inline]\n+        pub fn trailing_zeros(self) -> u32 {\n+            // As of LLVM 3.6 the codegen for the zero-safe cttz8 intrinsic\n+            // emits two conditional moves on x86_64. By promoting the value to\n+            // u16 and setting bit 8, we get better code without any conditional\n+            // operations.\n+            // FIXME: There's a LLVM patch (http://reviews.llvm.org/D9284)\n+            // pending, remove this workaround once LLVM generates better code\n+            // for cttz8.\n+            unsafe {\n+                if $BITS == 8 {\n+                    intrinsics::cttz16(self as u16 | 0x100) as u32\n+                } else {\n+                    $cttz(self as $ActualT) as u32\n+                }\n+            }\n+        }\n         /// Returns the number of trailing zeros in the binary representation\n         /// of `self`.\n         ///\n@@ -755,6 +831,7 @@ macro_rules! uint_impl {\n         /// assert_eq!(n.trailing_zeros(), 3);\n         /// ```\n         #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+        #[cfg(not(stage0))]\n         #[inline]\n         pub fn trailing_zeros(self) -> u32 {\n             // As of LLVM 3.6 the codegen for the zero-safe cttz8 intrinsic\n@@ -766,9 +843,9 @@ macro_rules! uint_impl {\n             // for cttz8.\n             unsafe {\n                 if $BITS == 8 {\n-                    intrinsics::cttz16(self as u16 | 0x100) as u32\n+                    intrinsics::cttz(self as u16 | 0x100) as u32\n                 } else {\n-                    $cttz(self as $ActualT) as u32\n+                    intrinsics::cttz(self) as u32\n                 }\n             }\n         }\n@@ -1163,6 +1240,7 @@ macro_rules! uint_impl {\n }\n \n #[lang = \"u8\"]\n+#[cfg(stage0)]\n impl u8 {\n     uint_impl! { u8, 8,\n         intrinsics::ctpop8,\n@@ -1173,8 +1251,21 @@ impl u8 {\n         intrinsics::u8_sub_with_overflow,\n         intrinsics::u8_mul_with_overflow }\n }\n+#[lang = \"u8\"]\n+#[cfg(not(stage0))]\n+impl u8 {\n+    uint_impl! { u8, 8,\n+        intrinsics::ctpop,\n+        intrinsics::ctlz,\n+        intrinsics::cttz,\n+        intrinsics::bswap,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[lang = \"u16\"]\n+#[cfg(stage0)]\n impl u16 {\n     uint_impl! { u16, 16,\n         intrinsics::ctpop16,\n@@ -1185,8 +1276,21 @@ impl u16 {\n         intrinsics::u16_sub_with_overflow,\n         intrinsics::u16_mul_with_overflow }\n }\n+#[lang = \"u16\"]\n+#[cfg(not(stage0))]\n+impl u16 {\n+    uint_impl! { u16, 16,\n+        intrinsics::ctpop,\n+        intrinsics::ctlz,\n+        intrinsics::cttz,\n+        intrinsics::bswap,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[lang = \"u32\"]\n+#[cfg(stage0)]\n impl u32 {\n     uint_impl! { u32, 32,\n         intrinsics::ctpop32,\n@@ -1197,9 +1301,21 @@ impl u32 {\n         intrinsics::u32_sub_with_overflow,\n         intrinsics::u32_mul_with_overflow }\n }\n-\n+#[lang = \"u32\"]\n+#[cfg(not(stage0))]\n+impl u32 {\n+    uint_impl! { u32, 32,\n+        intrinsics::ctpop,\n+        intrinsics::ctlz,\n+        intrinsics::cttz,\n+        intrinsics::bswap,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[lang = \"u64\"]\n+#[cfg(stage0)]\n impl u64 {\n     uint_impl! { u64, 64,\n         intrinsics::ctpop64,\n@@ -1210,9 +1326,22 @@ impl u64 {\n         intrinsics::u64_sub_with_overflow,\n         intrinsics::u64_mul_with_overflow }\n }\n+#[lang = \"u64\"]\n+#[cfg(not(stage0))]\n+impl u64 {\n+    uint_impl! { u64, 64,\n+        intrinsics::ctpop,\n+        intrinsics::ctlz,\n+        intrinsics::cttz,\n+        intrinsics::bswap,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[cfg(target_pointer_width = \"32\")]\n #[lang = \"usize\"]\n+#[cfg(stage0)]\n impl usize {\n     uint_impl! { u32, 32,\n         intrinsics::ctpop32,\n@@ -1223,9 +1352,23 @@ impl usize {\n         intrinsics::u32_sub_with_overflow,\n         intrinsics::u32_mul_with_overflow }\n }\n+#[cfg(target_pointer_width = \"32\")]\n+#[lang = \"usize\"]\n+#[cfg(not(stage0))]\n+impl usize {\n+    uint_impl! { u32, 32,\n+        intrinsics::ctpop,\n+        intrinsics::ctlz,\n+        intrinsics::cttz,\n+        intrinsics::bswap,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n #[cfg(target_pointer_width = \"64\")]\n #[lang = \"usize\"]\n+#[cfg(stage0)]\n impl usize {\n     uint_impl! { u64, 64,\n         intrinsics::ctpop64,\n@@ -1236,6 +1379,19 @@ impl usize {\n         intrinsics::u64_sub_with_overflow,\n         intrinsics::u64_mul_with_overflow }\n }\n+#[cfg(target_pointer_width = \"64\")]\n+#[lang = \"usize\"]\n+#[cfg(not(stage0))]\n+impl usize {\n+    uint_impl! { u64, 64,\n+        intrinsics::ctpop,\n+        intrinsics::ctlz,\n+        intrinsics::cttz,\n+        intrinsics::bswap,\n+        intrinsics::add_with_overflow,\n+        intrinsics::sub_with_overflow,\n+        intrinsics::mul_with_overflow }\n+}\n \n /// Used for representing the classification of floating point numbers\n #[derive(Copy, Clone, PartialEq, Debug)]"}, {"sha": "88f71e63da68245adba2d2cc1c244cf950355fa6", "filename": "src/libcore/num/wrapping.rs", "status": "modified", "additions": 169, "deletions": 13, "changes": 182, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fnum%2Fwrapping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibcore%2Fnum%2Fwrapping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fnum%2Fwrapping.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -12,23 +12,35 @@\n #![unstable(feature = \"wrapping\", reason = \"may be removed or relocated\",\n             issue = \"27755\")]\n \n+#[cfg(stage0)]\n+pub use intrinsics::{\n+    u8_add_with_overflow, i8_add_with_overflow,\n+    u16_add_with_overflow, i16_add_with_overflow,\n+    u32_add_with_overflow, i32_add_with_overflow,\n+    u64_add_with_overflow, i64_add_with_overflow,\n+\n+    u8_sub_with_overflow, i8_sub_with_overflow,\n+    u16_sub_with_overflow, i16_sub_with_overflow,\n+    u32_sub_with_overflow, i32_sub_with_overflow,\n+    u64_sub_with_overflow, i64_sub_with_overflow,\n+\n+    u8_mul_with_overflow, i8_mul_with_overflow,\n+    u16_mul_with_overflow, i16_mul_with_overflow,\n+    u32_mul_with_overflow, i32_mul_with_overflow,\n+    u64_mul_with_overflow, i64_mul_with_overflow,\n+};\n+\n+#[cfg(not(stage0))]\n+pub use intrinsics::{\n+    add_with_overflow,\n+    sub_with_overflow,\n+    mul_with_overflow,\n+};\n+\n use super::Wrapping;\n \n use ops::*;\n \n-use intrinsics::{i8_add_with_overflow, u8_add_with_overflow};\n-use intrinsics::{i16_add_with_overflow, u16_add_with_overflow};\n-use intrinsics::{i32_add_with_overflow, u32_add_with_overflow};\n-use intrinsics::{i64_add_with_overflow, u64_add_with_overflow};\n-use intrinsics::{i8_sub_with_overflow, u8_sub_with_overflow};\n-use intrinsics::{i16_sub_with_overflow, u16_sub_with_overflow};\n-use intrinsics::{i32_sub_with_overflow, u32_sub_with_overflow};\n-use intrinsics::{i64_sub_with_overflow, u64_sub_with_overflow};\n-use intrinsics::{i8_mul_with_overflow, u8_mul_with_overflow};\n-use intrinsics::{i16_mul_with_overflow, u16_mul_with_overflow};\n-use intrinsics::{i32_mul_with_overflow, u32_mul_with_overflow};\n-use intrinsics::{i64_mul_with_overflow, u64_mul_with_overflow};\n-\n use ::{i8,i16,i32,i64};\n \n pub trait OverflowingOps {\n@@ -191,23 +203,47 @@ macro_rules! signed_overflowing_impl {\n     ($($t:ident)*) => ($(\n         impl OverflowingOps for $t {\n             #[inline(always)]\n+            #[cfg(stage0)]\n             fn overflowing_add(self, rhs: $t) -> ($t, bool) {\n                 unsafe {\n                     concat_idents!($t, _add_with_overflow)(self, rhs)\n                 }\n             }\n             #[inline(always)]\n+            #[cfg(not(stage0))]\n+            fn overflowing_add(self, rhs: $t) -> ($t, bool) {\n+                unsafe {\n+                    add_with_overflow(self, rhs)\n+                }\n+            }\n+            #[inline(always)]\n+            #[cfg(stage0)]\n             fn overflowing_sub(self, rhs: $t) -> ($t, bool) {\n                 unsafe {\n                     concat_idents!($t, _sub_with_overflow)(self, rhs)\n                 }\n             }\n             #[inline(always)]\n+            #[cfg(not(stage0))]\n+            fn overflowing_sub(self, rhs: $t) -> ($t, bool) {\n+                unsafe {\n+                    sub_with_overflow(self, rhs)\n+                }\n+            }\n+            #[inline(always)]\n+            #[cfg(stage0)]\n             fn overflowing_mul(self, rhs: $t) -> ($t, bool) {\n                 unsafe {\n                     concat_idents!($t, _mul_with_overflow)(self, rhs)\n                 }\n             }\n+            #[inline(always)]\n+            #[cfg(not(stage0))]\n+            fn overflowing_mul(self, rhs: $t) -> ($t, bool) {\n+                unsafe {\n+                    mul_with_overflow(self, rhs)\n+                }\n+            }\n \n             #[inline(always)]\n             fn overflowing_div(self, rhs: $t) -> ($t, bool) {\n@@ -253,23 +289,47 @@ macro_rules! unsigned_overflowing_impl {\n     ($($t:ident)*) => ($(\n         impl OverflowingOps for $t {\n             #[inline(always)]\n+            #[cfg(stage0)]\n             fn overflowing_add(self, rhs: $t) -> ($t, bool) {\n                 unsafe {\n                     concat_idents!($t, _add_with_overflow)(self, rhs)\n                 }\n             }\n             #[inline(always)]\n+            #[cfg(not(stage0))]\n+            fn overflowing_add(self, rhs: $t) -> ($t, bool) {\n+                unsafe {\n+                    add_with_overflow(self, rhs)\n+                }\n+            }\n+            #[inline(always)]\n+            #[cfg(stage0)]\n             fn overflowing_sub(self, rhs: $t) -> ($t, bool) {\n                 unsafe {\n                     concat_idents!($t, _sub_with_overflow)(self, rhs)\n                 }\n             }\n             #[inline(always)]\n+            #[cfg(not(stage0))]\n+            fn overflowing_sub(self, rhs: $t) -> ($t, bool) {\n+                unsafe {\n+                    sub_with_overflow(self, rhs)\n+                }\n+            }\n+            #[inline(always)]\n+            #[cfg(stage0)]\n             fn overflowing_mul(self, rhs: $t) -> ($t, bool) {\n                 unsafe {\n                     concat_idents!($t, _mul_with_overflow)(self, rhs)\n                 }\n             }\n+            #[inline(always)]\n+            #[cfg(not(stage0))]\n+            fn overflowing_mul(self, rhs: $t) -> ($t, bool) {\n+                unsafe {\n+                    mul_with_overflow(self, rhs)\n+                }\n+            }\n \n             #[inline(always)]\n             fn overflowing_div(self, rhs: $t) -> ($t, bool) {\n@@ -305,27 +365,51 @@ unsigned_overflowing_impl! { u8 u16 u32 u64 }\n #[cfg(target_pointer_width = \"64\")]\n impl OverflowingOps for usize {\n     #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_add(self, rhs: usize) -> (usize, bool) {\n         unsafe {\n             let res = u64_add_with_overflow(self as u64, rhs as u64);\n             (res.0 as usize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_add(self, rhs: usize) -> (usize, bool) {\n+        unsafe {\n+            add_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_sub(self, rhs: usize) -> (usize, bool) {\n         unsafe {\n             let res = u64_sub_with_overflow(self as u64, rhs as u64);\n             (res.0 as usize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_sub(self, rhs: usize) -> (usize, bool) {\n+        unsafe {\n+            sub_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_mul(self, rhs: usize) -> (usize, bool) {\n         unsafe {\n             let res = u64_mul_with_overflow(self as u64, rhs as u64);\n             (res.0 as usize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_mul(self, rhs: usize) -> (usize, bool) {\n+        unsafe {\n+            mul_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n     fn overflowing_div(self, rhs: usize) -> (usize, bool) {\n         let (r, f) = (self as u64).overflowing_div(rhs as u64);\n         (r as usize, f)\n@@ -355,27 +439,51 @@ impl OverflowingOps for usize {\n #[cfg(target_pointer_width = \"32\")]\n impl OverflowingOps for usize {\n     #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_add(self, rhs: usize) -> (usize, bool) {\n         unsafe {\n             let res = u32_add_with_overflow(self as u32, rhs as u32);\n             (res.0 as usize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_add(self, rhs: usize) -> (usize, bool) {\n+        unsafe {\n+            add_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_sub(self, rhs: usize) -> (usize, bool) {\n         unsafe {\n             let res = u32_sub_with_overflow(self as u32, rhs as u32);\n             (res.0 as usize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_sub(self, rhs: usize) -> (usize, bool) {\n+        unsafe {\n+            sub_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_mul(self, rhs: usize) -> (usize, bool) {\n         unsafe {\n             let res = u32_mul_with_overflow(self as u32, rhs as u32);\n             (res.0 as usize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_mul(self, rhs: usize) -> (usize, bool) {\n+        unsafe {\n+            mul_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n     fn overflowing_div(self, rhs: usize) -> (usize, bool) {\n         let (r, f) = (self as u32).overflowing_div(rhs as u32);\n         (r as usize, f)\n@@ -405,27 +513,51 @@ impl OverflowingOps for usize {\n #[cfg(target_pointer_width = \"64\")]\n impl OverflowingOps for isize {\n     #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_add(self, rhs: isize) -> (isize, bool) {\n         unsafe {\n             let res = i64_add_with_overflow(self as i64, rhs as i64);\n             (res.0 as isize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_add(self, rhs: isize) -> (isize, bool) {\n+        unsafe {\n+            add_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_sub(self, rhs: isize) -> (isize, bool) {\n         unsafe {\n             let res = i64_sub_with_overflow(self as i64, rhs as i64);\n             (res.0 as isize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_sub(self, rhs: isize) -> (isize, bool) {\n+        unsafe {\n+            sub_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_mul(self, rhs: isize) -> (isize, bool) {\n         unsafe {\n             let res = i64_mul_with_overflow(self as i64, rhs as i64);\n             (res.0 as isize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_mul(self, rhs: isize) -> (isize, bool) {\n+        unsafe {\n+            mul_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n     fn overflowing_div(self, rhs: isize) -> (isize, bool) {\n         let (r, f) = (self as i64).overflowing_div(rhs as i64);\n         (r as isize, f)\n@@ -455,27 +587,51 @@ impl OverflowingOps for isize {\n #[cfg(target_pointer_width = \"32\")]\n impl OverflowingOps for isize {\n     #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_add(self, rhs: isize) -> (isize, bool) {\n         unsafe {\n             let res = i32_add_with_overflow(self as i32, rhs as i32);\n             (res.0 as isize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_add(self, rhs: isize) -> (isize, bool) {\n+        unsafe {\n+            add_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_sub(self, rhs: isize) -> (isize, bool) {\n         unsafe {\n             let res = i32_sub_with_overflow(self as i32, rhs as i32);\n             (res.0 as isize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_sub(self, rhs: isize) -> (isize, bool) {\n+        unsafe {\n+            sub_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n+    #[cfg(stage0)]\n     fn overflowing_mul(self, rhs: isize) -> (isize, bool) {\n         unsafe {\n             let res = i32_mul_with_overflow(self as i32, rhs as i32);\n             (res.0 as isize, res.1)\n         }\n     }\n     #[inline(always)]\n+    #[cfg(not(stage0))]\n+    fn overflowing_mul(self, rhs: isize) -> (isize, bool) {\n+        unsafe {\n+            mul_with_overflow(self, rhs)\n+        }\n+    }\n+    #[inline(always)]\n     fn overflowing_div(self, rhs: isize) -> (isize, bool) {\n         let (r, f) = (self as i32).overflowing_div(rhs as i32);\n         (r as isize, f)"}, {"sha": "539b9a4171f94b5403013aec3d829639462bc664", "filename": "src/librustc_trans/diagnostics.rs", "status": "modified", "additions": 5, "deletions": 10, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibrustc_trans%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibrustc_trans%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fdiagnostics.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -79,27 +79,23 @@ Transmute with two differently sized types was attempted. Erroneous code\n example:\n \n ```\n-extern \"rust-intrinsic\" {\n-    pub fn ctpop8(x: u8) -> u8;\n-}\n+fn takes_u8(_: u8) {}\n \n fn main() {\n-    unsafe { ctpop8(::std::mem::transmute(0u16)); }\n+    unsafe { takes_u8(::std::mem::transmute(0u16)); }\n     // error: transmute called with differently sized types\n }\n ```\n \n Please use types with same size or use the expected type directly. Example:\n \n ```\n-extern \"rust-intrinsic\" {\n-    pub fn ctpop8(x: u8) -> u8;\n-}\n+fn takes_u8(_: u8) {}\n \n fn main() {\n-    unsafe { ctpop8(::std::mem::transmute(0i8)); } // ok!\n+    unsafe { takes_u8(::std::mem::transmute(0i8)); } // ok!\n     // or:\n-    unsafe { ctpop8(0u8); } // ok!\n+    unsafe { takes_u8(0u8); } // ok!\n }\n ```\n \"##,\n@@ -118,5 +114,4 @@ Example:\n let x = &[0, 1, 2][2]; // ok\n ```\n \"##,\n-\n }"}, {"sha": "72ee53b0c80f8dbd0a8017f77fc5ae8dad29cf22", "filename": "src/librustc_trans/trans/intrinsic.rs", "status": "modified", "additions": 95, "deletions": 220, "changes": 315, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -89,13 +89,6 @@ pub fn get_simple_intrinsic(ccx: &CrateContext, item: &hir::ForeignItem) -> Opti\n         \"nearbyintf64\" => \"llvm.nearbyint.f64\",\n         \"roundf32\" => \"llvm.round.f32\",\n         \"roundf64\" => \"llvm.round.f64\",\n-        \"ctpop8\" => \"llvm.ctpop.i8\",\n-        \"ctpop16\" => \"llvm.ctpop.i16\",\n-        \"ctpop32\" => \"llvm.ctpop.i32\",\n-        \"ctpop64\" => \"llvm.ctpop.i64\",\n-        \"bswap16\" => \"llvm.bswap.i16\",\n-        \"bswap32\" => \"llvm.bswap.i32\",\n-        \"bswap64\" => \"llvm.bswap.i64\",\n         \"assume\" => \"llvm.assume\",\n         _ => return None\n     };\n@@ -589,217 +582,63 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n             C_nil(ccx)\n         },\n \n-        (_, \"ctlz8\") => count_zeros_intrinsic(bcx,\n-                                              \"llvm.ctlz.i8\",\n-                                              llargs[0],\n-                                              call_debug_location),\n-        (_, \"ctlz16\") => count_zeros_intrinsic(bcx,\n-                                               \"llvm.ctlz.i16\",\n-                                               llargs[0],\n-                                               call_debug_location),\n-        (_, \"ctlz32\") => count_zeros_intrinsic(bcx,\n-                                               \"llvm.ctlz.i32\",\n-                                               llargs[0],\n-                                               call_debug_location),\n-        (_, \"ctlz64\") => count_zeros_intrinsic(bcx,\n-                                               \"llvm.ctlz.i64\",\n-                                               llargs[0],\n-                                               call_debug_location),\n-        (_, \"cttz8\") => count_zeros_intrinsic(bcx,\n-                                              \"llvm.cttz.i8\",\n-                                              llargs[0],\n-                                              call_debug_location),\n-        (_, \"cttz16\") => count_zeros_intrinsic(bcx,\n-                                               \"llvm.cttz.i16\",\n-                                               llargs[0],\n-                                               call_debug_location),\n-        (_, \"cttz32\") => count_zeros_intrinsic(bcx,\n-                                               \"llvm.cttz.i32\",\n-                                               llargs[0],\n-                                               call_debug_location),\n-        (_, \"cttz64\") => count_zeros_intrinsic(bcx,\n-                                               \"llvm.cttz.i64\",\n-                                               llargs[0],\n-                                               call_debug_location),\n-\n-        (_, \"i8_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.sadd.with.overflow.i8\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i16_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.sadd.with.overflow.i16\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i32_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.sadd.with.overflow.i32\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i64_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.sadd.with.overflow.i64\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-\n-        (_, \"u8_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.uadd.with.overflow.i8\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u16_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.uadd.with.overflow.i16\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u32_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.uadd.with.overflow.i32\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u64_add_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.uadd.with.overflow.i64\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i8_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.ssub.with.overflow.i8\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i16_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.ssub.with.overflow.i16\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i32_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.ssub.with.overflow.i32\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i64_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.ssub.with.overflow.i64\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u8_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.usub.with.overflow.i8\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u16_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.usub.with.overflow.i16\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u32_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.usub.with.overflow.i32\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u64_sub_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.usub.with.overflow.i64\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i8_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.smul.with.overflow.i8\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i16_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.smul.with.overflow.i16\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i32_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.smul.with.overflow.i32\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"i64_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.smul.with.overflow.i64\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u8_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.umul.with.overflow.i8\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u16_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.umul.with.overflow.i16\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u32_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.umul.with.overflow.i32\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-        (_, \"u64_mul_with_overflow\") =>\n-            with_overflow_intrinsic(bcx,\n-                                    \"llvm.umul.with.overflow.i64\",\n-                                    llargs[0],\n-                                    llargs[1],\n-                                    llresult,\n-                                    call_debug_location),\n-\n-        (_, \"unchecked_udiv\") => UDiv(bcx, llargs[0], llargs[1], call_debug_location),\n-        (_, \"unchecked_sdiv\") => SDiv(bcx, llargs[0], llargs[1], call_debug_location),\n-        (_, \"unchecked_urem\") => URem(bcx, llargs[0], llargs[1], call_debug_location),\n-        (_, \"unchecked_srem\") => SRem(bcx, llargs[0], llargs[1], call_debug_location),\n-\n-        (_, \"overflowing_add\") => Add(bcx, llargs[0], llargs[1], call_debug_location),\n-        (_, \"overflowing_sub\") => Sub(bcx, llargs[0], llargs[1], call_debug_location),\n-        (_, \"overflowing_mul\") => Mul(bcx, llargs[0], llargs[1], call_debug_location),\n+        (_, \"ctlz\") | (_, \"cttz\") | (_, \"ctpop\") | (_, \"bswap\") |\n+        (_, \"add_with_overflow\") | (_, \"sub_with_overflow\") | (_, \"mul_with_overflow\") |\n+        (_, \"overflowing_add\") | (_, \"overflowing_sub\") | (_, \"overflowing_mul\") |\n+        (_, \"unchecked_div\") | (_, \"unchecked_rem\") => {\n+            let sty = &arg_tys[0].sty;\n+            match int_type_width_signed(sty, ccx) {\n+                Some((width, signed)) =>\n+                    match &*name {\n+                        \"ctlz\" => count_zeros_intrinsic(bcx, &format!(\"llvm.ctlz.i{}\", width),\n+                                                        llargs[0], call_debug_location),\n+                        \"cttz\" => count_zeros_intrinsic(bcx, &format!(\"llvm.cttz.i{}\", width),\n+                                                        llargs[0], call_debug_location),\n+                        \"ctpop\" => Call(bcx, ccx.get_intrinsic(&format!(\"llvm.ctpop.i{}\", width)),\n+                                        &llargs, None, call_debug_location),\n+                        \"bswap\" => {\n+                            if width == 8 {\n+                                llargs[0] // byte swap a u8/i8 is just a no-op\n+                            } else {\n+                                Call(bcx, ccx.get_intrinsic(&format!(\"llvm.bswap.i{}\", width)),\n+                                        &llargs, None, call_debug_location)\n+                            }\n+                        }\n+                        \"add_with_overflow\" | \"sub_with_overflow\" | \"mul_with_overflow\" => {\n+                            let intrinsic = format!(\"llvm.{}{}.with.overflow.i{}\",\n+                                                    if signed { 's' } else { 'u' },\n+                                                    &name[..3], width);\n+                            with_overflow_intrinsic(bcx, &intrinsic, llargs[0], llargs[1], llresult,\n+                                                    call_debug_location)\n+                        },\n+                        \"overflowing_add\" => Add(bcx, llargs[0], llargs[1], call_debug_location),\n+                        \"overflowing_sub\" => Sub(bcx, llargs[0], llargs[1], call_debug_location),\n+                        \"overflowing_mul\" => Mul(bcx, llargs[0], llargs[1], call_debug_location),\n+                        \"unchecked_div\" =>\n+                            if signed {\n+                                SDiv(bcx, llargs[0], llargs[1], call_debug_location)\n+                            } else {\n+                                UDiv(bcx, llargs[0], llargs[1], call_debug_location)\n+                            },\n+                        \"unchecked_rem\" =>\n+                            if signed {\n+                                SRem(bcx, llargs[0], llargs[1], call_debug_location)\n+                            } else {\n+                                URem(bcx, llargs[0], llargs[1], call_debug_location)\n+                            },\n+                        _ => unreachable!(),\n+                    },\n+                None => {\n+                    span_invalid_monomorphization_error(\n+                        tcx.sess, call_info.span,\n+                        &format!(\"invalid monomorphization of `{}` intrinsic: \\\n+                                  expected basic integer type, found `{}`\", name, sty));\n+                        C_null(llret_ty)\n+                }\n+            }\n+\n+        },\n+\n \n         (_, \"return_address\") => {\n             if !fcx.caller_expects_out_pointer {\n@@ -1174,7 +1013,7 @@ fn memset_intrinsic<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n }\n \n fn count_zeros_intrinsic(bcx: Block,\n-                         name: &'static str,\n+                         name: &str,\n                          val: ValueRef,\n                          call_debug_location: DebugLoc)\n                          -> ValueRef {\n@@ -1184,7 +1023,7 @@ fn count_zeros_intrinsic(bcx: Block,\n }\n \n fn with_overflow_intrinsic<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n-                                       name: &'static str,\n+                                       name: &str,\n                                        a: ValueRef,\n                                        b: ValueRef,\n                                        out: ValueRef,\n@@ -1716,3 +1555,39 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>\n     }\n     bcx.sess().span_bug(call_info.span, \"unknown SIMD intrinsic\");\n }\n+\n+// Returns the width of an int TypeVariant, and if it's signed or not\n+// Returns None if the type is not an integer\n+fn int_type_width_signed<'tcx>(sty: &ty::TypeVariants<'tcx>, ccx: &CrateContext)\n+        -> Option<(u64, bool)> {\n+    use rustc::middle::ty::{TyInt, TyUint};\n+    match *sty {\n+        TyInt(t) => Some((match t {\n+            ast::TyIs => {\n+                match &ccx.tcx().sess.target.target.target_pointer_width[..] {\n+                    \"32\" => 32,\n+                    \"64\" => 64,\n+                    tws => panic!(\"Unsupported target word size for isize: {}\", tws),\n+                }\n+            },\n+            ast::TyI8 => 8,\n+            ast::TyI16 => 16,\n+            ast::TyI32 => 32,\n+            ast::TyI64 => 64,\n+        }, true)),\n+        TyUint(t) => Some((match t {\n+            ast::TyUs => {\n+                match &ccx.tcx().sess.target.target.target_pointer_width[..] {\n+                    \"32\" => 32,\n+                    \"64\" => 64,\n+                    tws => panic!(\"Unsupported target word size for usize: {}\", tws),\n+                }\n+            },\n+            ast::TyU8 => 8,\n+            ast::TyU16 => 16,\n+            ast::TyU32 => 32,\n+            ast::TyU64 => 64,\n+        }, false)),\n+        _ => None,\n+    }\n+}"}, {"sha": "0ab0f1f9c1de1498f74da3ecf5906ef66aaf25a0", "filename": "src/librustc_typeck/check/intrinsic.rs", "status": "modified", "additions": 5, "deletions": 46, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -254,60 +254,19 @@ pub fn check_intrinsic_type(ccx: &CrateCtxt, it: &hir::ForeignItem) {\n             \"nearbyintf64\" => (0, vec!( tcx.types.f64 ), tcx.types.f64),\n             \"roundf32\"     => (0, vec!( tcx.types.f32 ), tcx.types.f32),\n             \"roundf64\"     => (0, vec!( tcx.types.f64 ), tcx.types.f64),\n-            \"ctpop8\"       => (0, vec!( tcx.types.u8  ), tcx.types.u8),\n-            \"ctpop16\"      => (0, vec!( tcx.types.u16 ), tcx.types.u16),\n-            \"ctpop32\"      => (0, vec!( tcx.types.u32 ), tcx.types.u32),\n-            \"ctpop64\"      => (0, vec!( tcx.types.u64 ), tcx.types.u64),\n-            \"ctlz8\"        => (0, vec!( tcx.types.u8  ), tcx.types.u8),\n-            \"ctlz16\"       => (0, vec!( tcx.types.u16 ), tcx.types.u16),\n-            \"ctlz32\"       => (0, vec!( tcx.types.u32 ), tcx.types.u32),\n-            \"ctlz64\"       => (0, vec!( tcx.types.u64 ), tcx.types.u64),\n-            \"cttz8\"        => (0, vec!( tcx.types.u8  ), tcx.types.u8),\n-            \"cttz16\"       => (0, vec!( tcx.types.u16 ), tcx.types.u16),\n-            \"cttz32\"       => (0, vec!( tcx.types.u32 ), tcx.types.u32),\n-            \"cttz64\"       => (0, vec!( tcx.types.u64 ), tcx.types.u64),\n-            \"bswap16\"      => (0, vec!( tcx.types.u16 ), tcx.types.u16),\n-            \"bswap32\"      => (0, vec!( tcx.types.u32 ), tcx.types.u32),\n-            \"bswap64\"      => (0, vec!( tcx.types.u64 ), tcx.types.u64),\n \n             \"volatile_load\" =>\n                 (1, vec!( tcx.mk_imm_ptr(param(ccx, 0)) ), param(ccx, 0)),\n             \"volatile_store\" =>\n                 (1, vec!( tcx.mk_mut_ptr(param(ccx, 0)), param(ccx, 0) ), tcx.mk_nil()),\n \n-            \"i8_add_with_overflow\" | \"i8_sub_with_overflow\" | \"i8_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.i8, tcx.types.i8),\n-                tcx.mk_tup(vec!(tcx.types.i8, tcx.types.bool))),\n+            \"ctpop\" | \"ctlz\" | \"cttz\" | \"bswap\" => (1, vec!(param(ccx, 0)), param(ccx, 0)),\n \n-            \"i16_add_with_overflow\" | \"i16_sub_with_overflow\" | \"i16_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.i16, tcx.types.i16),\n-                tcx.mk_tup(vec!(tcx.types.i16, tcx.types.bool))),\n+            \"add_with_overflow\" | \"sub_with_overflow\"  | \"mul_with_overflow\" =>\n+                (1, vec!(param(ccx, 0), param(ccx, 0)),\n+                tcx.mk_tup(vec!(param(ccx, 0), tcx.types.bool))),\n \n-            \"i32_add_with_overflow\" | \"i32_sub_with_overflow\" | \"i32_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.i32, tcx.types.i32),\n-                tcx.mk_tup(vec!(tcx.types.i32, tcx.types.bool))),\n-\n-            \"i64_add_with_overflow\" | \"i64_sub_with_overflow\" | \"i64_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.i64, tcx.types.i64),\n-                tcx.mk_tup(vec!(tcx.types.i64, tcx.types.bool))),\n-\n-            \"u8_add_with_overflow\" | \"u8_sub_with_overflow\" | \"u8_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.u8, tcx.types.u8),\n-                tcx.mk_tup(vec!(tcx.types.u8, tcx.types.bool))),\n-\n-            \"u16_add_with_overflow\" | \"u16_sub_with_overflow\" | \"u16_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.u16, tcx.types.u16),\n-                tcx.mk_tup(vec!(tcx.types.u16, tcx.types.bool))),\n-\n-            \"u32_add_with_overflow\" | \"u32_sub_with_overflow\" | \"u32_mul_with_overflow\"=>\n-                (0, vec!(tcx.types.u32, tcx.types.u32),\n-                tcx.mk_tup(vec!(tcx.types.u32, tcx.types.bool))),\n-\n-            \"u64_add_with_overflow\" | \"u64_sub_with_overflow\"  | \"u64_mul_with_overflow\" =>\n-                (0, vec!(tcx.types.u64, tcx.types.u64),\n-                tcx.mk_tup(vec!(tcx.types.u64, tcx.types.bool))),\n-\n-            \"unchecked_udiv\" | \"unchecked_sdiv\" | \"unchecked_urem\" | \"unchecked_srem\" =>\n+            \"unchecked_div\" | \"unchecked_rem\" =>\n                 (1, vec![param(ccx, 0), param(ccx, 0)], param(ccx, 0)),\n \n             \"overflowing_add\" | \"overflowing_sub\" | \"overflowing_mul\" =>"}, {"sha": "170a6c95aa8a8f0dd204c1d34dd7968449751b80", "filename": "src/test/run-pass/intrinsics-integer.rs", "status": "modified", "additions": 82, "deletions": 91, "changes": 173, "blob_url": "https://github.com/rust-lang/rust/blob/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Ftest%2Frun-pass%2Fintrinsics-integer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/579420fbdd9951ae230a9def03e157d9b9957b2f/src%2Ftest%2Frun-pass%2Fintrinsics-integer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fintrinsics-integer.rs?ref=579420fbdd9951ae230a9def03e157d9b9957b2f", "patch": "@@ -14,103 +14,94 @@\n \n mod rusti {\n     extern \"rust-intrinsic\" {\n-        pub fn ctpop8(x: u8) -> u8;\n-        pub fn ctpop16(x: u16) -> u16;\n-        pub fn ctpop32(x: u32) -> u32;\n-        pub fn ctpop64(x: u64) -> u64;\n-\n-        pub fn ctlz8(x: u8) -> u8;\n-        pub fn ctlz16(x: u16) -> u16;\n-        pub fn ctlz32(x: u32) -> u32;\n-        pub fn ctlz64(x: u64) -> u64;\n-\n-        pub fn cttz8(x: u8) -> u8;\n-        pub fn cttz16(x: u16) -> u16;\n-        pub fn cttz32(x: u32) -> u32;\n-        pub fn cttz64(x: u64) -> u64;\n-\n-        pub fn bswap16(x: u16) -> u16;\n-        pub fn bswap32(x: u32) -> u32;\n-        pub fn bswap64(x: u64) -> u64;\n+        pub fn ctpop<T>(x: T) -> T;\n+        pub fn ctlz<T>(x: T) -> T;\n+        pub fn cttz<T>(x: T) -> T;\n+        pub fn bswap<T>(x: T) -> T;\n     }\n }\n \n pub fn main() {\n     unsafe {\n         use rusti::*;\n \n-        assert_eq!(ctpop8(0), 0);\n-        assert_eq!(ctpop16(0), 0);\n-        assert_eq!(ctpop32(0), 0);\n-        assert_eq!(ctpop64(0), 0);\n-\n-        assert_eq!(ctpop8(1), 1);\n-        assert_eq!(ctpop16(1), 1);\n-        assert_eq!(ctpop32(1), 1);\n-        assert_eq!(ctpop64(1), 1);\n-\n-        assert_eq!(ctpop8(10), 2);\n-        assert_eq!(ctpop16(10), 2);\n-        assert_eq!(ctpop32(10), 2);\n-        assert_eq!(ctpop64(10), 2);\n-\n-        assert_eq!(ctpop8(100), 3);\n-        assert_eq!(ctpop16(100), 3);\n-        assert_eq!(ctpop32(100), 3);\n-        assert_eq!(ctpop64(100), 3);\n-\n-        assert_eq!(ctpop8(-1), 8);\n-        assert_eq!(ctpop16(-1), 16);\n-        assert_eq!(ctpop32(-1), 32);\n-        assert_eq!(ctpop64(-1), 64);\n-\n-        assert_eq!(ctlz8(0), 8);\n-        assert_eq!(ctlz16(0), 16);\n-        assert_eq!(ctlz32(0), 32);\n-        assert_eq!(ctlz64(0), 64);\n-\n-        assert_eq!(ctlz8(1), 7);\n-        assert_eq!(ctlz16(1), 15);\n-        assert_eq!(ctlz32(1), 31);\n-        assert_eq!(ctlz64(1), 63);\n-\n-        assert_eq!(ctlz8(10), 4);\n-        assert_eq!(ctlz16(10), 12);\n-        assert_eq!(ctlz32(10), 28);\n-        assert_eq!(ctlz64(10), 60);\n-\n-        assert_eq!(ctlz8(100), 1);\n-        assert_eq!(ctlz16(100), 9);\n-        assert_eq!(ctlz32(100), 25);\n-        assert_eq!(ctlz64(100), 57);\n-\n-        assert_eq!(cttz8(-1), 0);\n-        assert_eq!(cttz16(-1), 0);\n-        assert_eq!(cttz32(-1), 0);\n-        assert_eq!(cttz64(-1), 0);\n-\n-        assert_eq!(cttz8(0), 8);\n-        assert_eq!(cttz16(0), 16);\n-        assert_eq!(cttz32(0), 32);\n-        assert_eq!(cttz64(0), 64);\n-\n-        assert_eq!(cttz8(1), 0);\n-        assert_eq!(cttz16(1), 0);\n-        assert_eq!(cttz32(1), 0);\n-        assert_eq!(cttz64(1), 0);\n-\n-        assert_eq!(cttz8(10), 1);\n-        assert_eq!(cttz16(10), 1);\n-        assert_eq!(cttz32(10), 1);\n-        assert_eq!(cttz64(10), 1);\n-\n-        assert_eq!(cttz8(100), 2);\n-        assert_eq!(cttz16(100), 2);\n-        assert_eq!(cttz32(100), 2);\n-        assert_eq!(cttz64(100), 2);\n-\n-        assert_eq!(bswap16(0x0A0B), 0x0B0A);\n-        assert_eq!(bswap32(0x0ABBCC0D), 0x0DCCBB0A);\n-        assert_eq!(bswap64(0x0122334455667708), 0x0877665544332201);\n+        assert_eq!(ctpop(0u8), 0); assert_eq!(ctpop(0i8), 0);\n+        assert_eq!(ctpop(0u16), 0); assert_eq!(ctpop(0i16), 0);\n+        assert_eq!(ctpop(0u32), 0); assert_eq!(ctpop(0i32), 0);\n+        assert_eq!(ctpop(0u64), 0); assert_eq!(ctpop(0i64), 0);\n+\n+        assert_eq!(ctpop(1u8), 1); assert_eq!(ctpop(1i8), 1);\n+        assert_eq!(ctpop(1u16), 1); assert_eq!(ctpop(1i16), 1);\n+        assert_eq!(ctpop(1u32), 1); assert_eq!(ctpop(1i32), 1);\n+        assert_eq!(ctpop(1u64), 1); assert_eq!(ctpop(1i64), 1);\n+\n+        assert_eq!(ctpop(10u8), 2); assert_eq!(ctpop(10i8), 2);\n+        assert_eq!(ctpop(10u16), 2); assert_eq!(ctpop(10i16), 2);\n+        assert_eq!(ctpop(10u32), 2); assert_eq!(ctpop(10i32), 2);\n+        assert_eq!(ctpop(10u64), 2); assert_eq!(ctpop(10i64), 2);\n+\n+        assert_eq!(ctpop(100u8), 3); assert_eq!(ctpop(100i8), 3);\n+        assert_eq!(ctpop(100u16), 3); assert_eq!(ctpop(100i16), 3);\n+        assert_eq!(ctpop(100u32), 3); assert_eq!(ctpop(100i32), 3);\n+        assert_eq!(ctpop(100u64), 3); assert_eq!(ctpop(100i64), 3);\n+\n+        assert_eq!(ctpop(-1u8), 8); assert_eq!(ctpop(-1i8), 8);\n+        assert_eq!(ctpop(-1u16), 16); assert_eq!(ctpop(-1i16), 16);\n+        assert_eq!(ctpop(-1u32), 32); assert_eq!(ctpop(-1i32), 32);\n+        assert_eq!(ctpop(-1u64), 64); assert_eq!(ctpop(-1i64), 64);\n+\n+        assert_eq!(ctlz(0u8), 8); assert_eq!(ctlz(0i8), 8);\n+        assert_eq!(ctlz(0u16), 16); assert_eq!(ctlz(0i16), 16);\n+        assert_eq!(ctlz(0u32), 32); assert_eq!(ctlz(0i32), 32);\n+        assert_eq!(ctlz(0u64), 64); assert_eq!(ctlz(0i64), 64);\n+\n+        assert_eq!(ctlz(1u8), 7); assert_eq!(ctlz(1i8), 7);\n+        assert_eq!(ctlz(1u16), 15); assert_eq!(ctlz(1i16), 15);\n+        assert_eq!(ctlz(1u32), 31); assert_eq!(ctlz(1i32), 31);\n+        assert_eq!(ctlz(1u64), 63); assert_eq!(ctlz(1i64), 63);\n+\n+        assert_eq!(ctlz(10u8), 4); assert_eq!(ctlz(10i8), 4);\n+        assert_eq!(ctlz(10u16), 12); assert_eq!(ctlz(10i16), 12);\n+        assert_eq!(ctlz(10u32), 28); assert_eq!(ctlz(10i32), 28);\n+        assert_eq!(ctlz(10u64), 60); assert_eq!(ctlz(10i64), 60);\n+\n+        assert_eq!(ctlz(100u8), 1); assert_eq!(ctlz(100i8), 1);\n+        assert_eq!(ctlz(100u16), 9); assert_eq!(ctlz(100i16), 9);\n+        assert_eq!(ctlz(100u32), 25); assert_eq!(ctlz(100i32), 25);\n+        assert_eq!(ctlz(100u64), 57); assert_eq!(ctlz(100i64), 57);\n+\n+        assert_eq!(cttz(-1u8), 0); assert_eq!(cttz(-1i8), 0);\n+        assert_eq!(cttz(-1u16), 0); assert_eq!(cttz(-1i16), 0);\n+        assert_eq!(cttz(-1u32), 0); assert_eq!(cttz(-1i32), 0);\n+        assert_eq!(cttz(-1u64), 0); assert_eq!(cttz(-1i64), 0);\n+\n+        assert_eq!(cttz(0u8), 8); assert_eq!(cttz(0i8), 8);\n+        assert_eq!(cttz(0u16), 16); assert_eq!(cttz(0i16), 16);\n+        assert_eq!(cttz(0u32), 32); assert_eq!(cttz(0i32), 32);\n+        assert_eq!(cttz(0u64), 64); assert_eq!(cttz(0i64), 64);\n+\n+        assert_eq!(cttz(1u8), 0); assert_eq!(cttz(1i8), 0);\n+        assert_eq!(cttz(1u16), 0); assert_eq!(cttz(1i16), 0);\n+        assert_eq!(cttz(1u32), 0); assert_eq!(cttz(1i32), 0);\n+        assert_eq!(cttz(1u64), 0); assert_eq!(cttz(1i64), 0);\n+\n+        assert_eq!(cttz(10u8), 1); assert_eq!(cttz(10i8), 1);\n+        assert_eq!(cttz(10u16), 1); assert_eq!(cttz(10i16), 1);\n+        assert_eq!(cttz(10u32), 1); assert_eq!(cttz(10i32), 1);\n+        assert_eq!(cttz(10u64), 1); assert_eq!(cttz(10i64), 1);\n+\n+        assert_eq!(cttz(100u8), 2); assert_eq!(cttz(100i8), 2);\n+        assert_eq!(cttz(100u16), 2); assert_eq!(cttz(100i16), 2);\n+        assert_eq!(cttz(100u32), 2); assert_eq!(cttz(100i32), 2);\n+        assert_eq!(cttz(100u64), 2); assert_eq!(cttz(100i64), 2);\n+\n+        assert_eq!(bswap(0x0Au8), 0x0A); // no-op\n+        assert_eq!(bswap(0x0Ai8), 0x0A); // no-op\n+        assert_eq!(bswap(0x0A0Bu16), 0x0B0A);\n+        assert_eq!(bswap(0x0A0Bi16), 0x0B0A);\n+        assert_eq!(bswap(0x0ABBCC0Du32), 0x0DCCBB0A);\n+        assert_eq!(bswap(0x0ABBCC0Di32), 0x0DCCBB0A);\n+        assert_eq!(bswap(0x0122334455667708u64), 0x0877665544332201);\n+        assert_eq!(bswap(0x0122334455667708i64), 0x0877665544332201);\n     }\n }"}]}