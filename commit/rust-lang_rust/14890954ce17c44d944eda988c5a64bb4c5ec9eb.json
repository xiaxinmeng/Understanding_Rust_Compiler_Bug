{"sha": "14890954ce17c44d944eda988c5a64bb4c5ec9eb", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE0ODkwOTU0Y2UxN2M0NGQ5NDRlZGE5ODhjNWE2NGJiNGM1ZWM5ZWI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-08-20T07:44:44Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-08-20T07:44:44Z"}, "message": "Auto merge of #63709 - matklad:decomposed-tokens, r=petrochenkov\n\nMove token gluing to token stream parsing\n\nwork towards #63689, this moves token gluing from the lexer to the token tree layer. This is only a minimal step, but I like the negative diff here.\n\nr? @petrochenkov", "tree": {"sha": "31d7eff7318bb0fff0f541c6c8f6f57f9b2576ba", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/31d7eff7318bb0fff0f541c6c8f6f57f9b2576ba"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/14890954ce17c44d944eda988c5a64bb4c5ec9eb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/14890954ce17c44d944eda988c5a64bb4c5ec9eb", "html_url": "https://github.com/rust-lang/rust/commit/14890954ce17c44d944eda988c5a64bb4c5ec9eb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/14890954ce17c44d944eda988c5a64bb4c5ec9eb/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7858dc237d70fc0c5a31eb528dfab1ad0baf6a27", "url": "https://api.github.com/repos/rust-lang/rust/commits/7858dc237d70fc0c5a31eb528dfab1ad0baf6a27", "html_url": "https://github.com/rust-lang/rust/commit/7858dc237d70fc0c5a31eb528dfab1ad0baf6a27"}, {"sha": "914e1f456415eae0ae095dd39dc51c115c1ffb5a", "url": "https://api.github.com/repos/rust-lang/rust/commits/914e1f456415eae0ae095dd39dc51c115c1ffb5a", "html_url": "https://github.com/rust-lang/rust/commit/914e1f456415eae0ae095dd39dc51c115c1ffb5a"}], "stats": {"total": 277, "additions": 68, "deletions": 209}, "files": [{"sha": "41b47befaf1412241a088087a166e6f0036f82f3", "filename": "src/librustc_lexer/src/lib.rs", "status": "modified", "additions": 14, "deletions": 162, "changes": 176, "blob_url": "https://github.com/rust-lang/rust/blob/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Flib.rs?ref=14890954ce17c44d944eda988c5a64bb4c5ec9eb", "patch": "@@ -23,9 +23,6 @@ pub enum TokenKind {\n     Lifetime { starts_with_number: bool },\n     Semi,\n     Comma,\n-    DotDotDot,\n-    DotDotEq,\n-    DotDot,\n     Dot,\n     OpenParen,\n     CloseParen,\n@@ -37,41 +34,19 @@ pub enum TokenKind {\n     Pound,\n     Tilde,\n     Question,\n-    ColonColon,\n     Colon,\n     Dollar,\n-    EqEq,\n     Eq,\n-    FatArrow,\n-    Ne,\n     Not,\n-    Le,\n-    LArrow,\n     Lt,\n-    ShlEq,\n-    Shl,\n-    Ge,\n     Gt,\n-    ShrEq,\n-    Shr,\n-    RArrow,\n     Minus,\n-    MinusEq,\n     And,\n-    AndAnd,\n-    AndEq,\n     Or,\n-    OrOr,\n-    OrEq,\n-    PlusEq,\n     Plus,\n-    StarEq,\n     Star,\n-    SlashEq,\n     Slash,\n-    CaretEq,\n     Caret,\n-    PercentEq,\n     Percent,\n     Unknown,\n }\n@@ -135,13 +110,7 @@ impl Cursor<'_> {\n             '/' => match self.nth_char(0) {\n                 '/' => self.line_comment(),\n                 '*' => self.block_comment(),\n-                _ => {\n-                    if self.eat_assign() {\n-                        SlashEq\n-                    } else {\n-                        Slash\n-                    }\n-                }\n+                _ => Slash,\n             },\n             c if character_properties::is_whitespace(c) => self.whitespace(),\n             'r' => match (self.nth_char(0), self.nth_char(1)) {\n@@ -199,22 +168,7 @@ impl Cursor<'_> {\n             }\n             ';' => Semi,\n             ',' => Comma,\n-            '.' => {\n-                if self.nth_char(0) == '.' {\n-                    self.bump();\n-                    if self.nth_char(0) == '.' {\n-                        self.bump();\n-                        DotDotDot\n-                    } else if self.nth_char(0) == '=' {\n-                        self.bump();\n-                        DotDotEq\n-                    } else {\n-                        DotDot\n-                    }\n-                } else {\n-                    Dot\n-                }\n-            }\n+            '.' => Dot,\n             '(' => OpenParen,\n             ')' => CloseParen,\n             '{' => OpenBrace,\n@@ -225,112 +179,19 @@ impl Cursor<'_> {\n             '#' => Pound,\n             '~' => Tilde,\n             '?' => Question,\n-            ':' => {\n-                if self.nth_char(0) == ':' {\n-                    self.bump();\n-                    ColonColon\n-                } else {\n-                    Colon\n-                }\n-            }\n+            ':' => Colon,\n             '$' => Dollar,\n-            '=' => {\n-                if self.nth_char(0) == '=' {\n-                    self.bump();\n-                    EqEq\n-                } else if self.nth_char(0) == '>' {\n-                    self.bump();\n-                    FatArrow\n-                } else {\n-                    Eq\n-                }\n-            }\n-            '!' => {\n-                if self.nth_char(0) == '=' {\n-                    self.bump();\n-                    Ne\n-                } else {\n-                    Not\n-                }\n-            }\n-            '<' => match self.nth_char(0) {\n-                '=' => {\n-                    self.bump();\n-                    Le\n-                }\n-                '<' => {\n-                    self.bump();\n-                    if self.eat_assign() { ShlEq } else { Shl }\n-                }\n-                '-' => {\n-                    self.bump();\n-                    LArrow\n-                }\n-                _ => Lt,\n-            },\n-            '>' => match self.nth_char(0) {\n-                '=' => {\n-                    self.bump();\n-                    Ge\n-                }\n-                '>' => {\n-                    self.bump();\n-                    if self.eat_assign() { ShrEq } else { Shr }\n-                }\n-                _ => Gt,\n-            },\n-            '-' => {\n-                if self.nth_char(0) == '>' {\n-                    self.bump();\n-                    RArrow\n-                } else {\n-                    if self.eat_assign() { MinusEq } else { Minus }\n-                }\n-            }\n-            '&' => {\n-                if self.nth_char(0) == '&' {\n-                    self.bump();\n-                    AndAnd\n-                } else {\n-                    if self.eat_assign() { AndEq } else { And }\n-                }\n-            }\n-            '|' => {\n-                if self.nth_char(0) == '|' {\n-                    self.bump();\n-                    OrOr\n-                } else {\n-                    if self.eat_assign() { OrEq } else { Or }\n-                }\n-            }\n-            '+' => {\n-                if self.eat_assign() {\n-                    PlusEq\n-                } else {\n-                    Plus\n-                }\n-            }\n-            '*' => {\n-                if self.eat_assign() {\n-                    StarEq\n-                } else {\n-                    Star\n-                }\n-            }\n-            '^' => {\n-                if self.eat_assign() {\n-                    CaretEq\n-                } else {\n-                    Caret\n-                }\n-            }\n-            '%' => {\n-                if self.eat_assign() {\n-                    PercentEq\n-                } else {\n-                    Percent\n-                }\n-            }\n+            '=' => Eq,\n+            '!' => Not,\n+            '<' => Lt,\n+            '>' => Gt,\n+            '-' => Minus,\n+            '&' => And,\n+            '|' => Or,\n+            '+' => Plus,\n+            '*' => Star,\n+            '^' => Caret,\n+            '%' => Percent,\n             '\\'' => self.lifetime_or_char(),\n             '\"' => {\n                 let terminated = self.double_quoted_string();\n@@ -643,15 +504,6 @@ impl Cursor<'_> {\n             self.bump();\n         }\n     }\n-\n-    fn eat_assign(&mut self) -> bool {\n-        if self.nth_char(0) == '=' {\n-            self.bump();\n-            true\n-        } else {\n-            false\n-        }\n-    }\n }\n \n pub mod character_properties {"}, {"sha": "66add869359d800f030ddf5308351f3b794fb87c", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 0, "deletions": 25, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=14890954ce17c44d944eda988c5a64bb4c5ec9eb", "patch": "@@ -273,9 +273,6 @@ impl<'a> StringReader<'a> {\n             }\n             rustc_lexer::TokenKind::Semi => token::Semi,\n             rustc_lexer::TokenKind::Comma => token::Comma,\n-            rustc_lexer::TokenKind::DotDotDot => token::DotDotDot,\n-            rustc_lexer::TokenKind::DotDotEq => token::DotDotEq,\n-            rustc_lexer::TokenKind::DotDot => token::DotDot,\n             rustc_lexer::TokenKind::Dot => token::Dot,\n             rustc_lexer::TokenKind::OpenParen => token::OpenDelim(token::Paren),\n             rustc_lexer::TokenKind::CloseParen => token::CloseDelim(token::Paren),\n@@ -287,42 +284,20 @@ impl<'a> StringReader<'a> {\n             rustc_lexer::TokenKind::Pound => token::Pound,\n             rustc_lexer::TokenKind::Tilde => token::Tilde,\n             rustc_lexer::TokenKind::Question => token::Question,\n-            rustc_lexer::TokenKind::ColonColon => token::ModSep,\n             rustc_lexer::TokenKind::Colon => token::Colon,\n             rustc_lexer::TokenKind::Dollar => token::Dollar,\n-            rustc_lexer::TokenKind::EqEq => token::EqEq,\n             rustc_lexer::TokenKind::Eq => token::Eq,\n-            rustc_lexer::TokenKind::FatArrow => token::FatArrow,\n-            rustc_lexer::TokenKind::Ne => token::Ne,\n             rustc_lexer::TokenKind::Not => token::Not,\n-            rustc_lexer::TokenKind::Le => token::Le,\n-            rustc_lexer::TokenKind::LArrow => token::LArrow,\n             rustc_lexer::TokenKind::Lt => token::Lt,\n-            rustc_lexer::TokenKind::ShlEq => token::BinOpEq(token::Shl),\n-            rustc_lexer::TokenKind::Shl => token::BinOp(token::Shl),\n-            rustc_lexer::TokenKind::Ge => token::Ge,\n             rustc_lexer::TokenKind::Gt => token::Gt,\n-            rustc_lexer::TokenKind::ShrEq => token::BinOpEq(token::Shr),\n-            rustc_lexer::TokenKind::Shr => token::BinOp(token::Shr),\n-            rustc_lexer::TokenKind::RArrow => token::RArrow,\n             rustc_lexer::TokenKind::Minus => token::BinOp(token::Minus),\n-            rustc_lexer::TokenKind::MinusEq => token::BinOpEq(token::Minus),\n             rustc_lexer::TokenKind::And => token::BinOp(token::And),\n-            rustc_lexer::TokenKind::AndEq => token::BinOpEq(token::And),\n-            rustc_lexer::TokenKind::AndAnd => token::AndAnd,\n             rustc_lexer::TokenKind::Or => token::BinOp(token::Or),\n-            rustc_lexer::TokenKind::OrEq => token::BinOpEq(token::Or),\n-            rustc_lexer::TokenKind::OrOr => token::OrOr,\n             rustc_lexer::TokenKind::Plus => token::BinOp(token::Plus),\n-            rustc_lexer::TokenKind::PlusEq => token::BinOpEq(token::Plus),\n             rustc_lexer::TokenKind::Star => token::BinOp(token::Star),\n-            rustc_lexer::TokenKind::StarEq => token::BinOpEq(token::Star),\n             rustc_lexer::TokenKind::Slash => token::BinOp(token::Slash),\n-            rustc_lexer::TokenKind::SlashEq => token::BinOpEq(token::Slash),\n             rustc_lexer::TokenKind::Caret => token::BinOp(token::Caret),\n-            rustc_lexer::TokenKind::CaretEq => token::BinOpEq(token::Caret),\n             rustc_lexer::TokenKind::Percent => token::BinOp(token::Percent),\n-            rustc_lexer::TokenKind::PercentEq => token::BinOpEq(token::Percent),\n \n             rustc_lexer::TokenKind::Unknown => {\n                 let c = self.str_from(start).chars().next().unwrap();"}, {"sha": "a915aa42fd15ab2da80ed65d109b697f50c2e204", "filename": "src/libsyntax/parse/lexer/tests.rs", "status": "modified", "additions": 20, "deletions": 12, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs?ref=14890954ce17c44d944eda988c5a64bb4c5ec9eb", "patch": "@@ -75,42 +75,50 @@ fn mk_lit(kind: token::LitKind, symbol: &str, suffix: Option<&str>) -> TokenKind\n }\n \n #[test]\n-fn doublecolonparsing() {\n+fn doublecolon_parsing() {\n     with_default_globals(|| {\n         let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n         let sh = mk_sess(sm.clone());\n-        check_tokenization(setup(&sm, &sh, \"a b\".to_string()),\n-                        vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")]);\n+        check_tokenization(\n+            setup(&sm, &sh, \"a b\".to_string()),\n+            vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")],\n+        );\n     })\n }\n \n #[test]\n-fn dcparsing_2() {\n+fn doublecolon_parsing_2() {\n     with_default_globals(|| {\n         let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n         let sh = mk_sess(sm.clone());\n-        check_tokenization(setup(&sm, &sh, \"a::b\".to_string()),\n-                        vec![mk_ident(\"a\"), token::ModSep, mk_ident(\"b\")]);\n+        check_tokenization(\n+            setup(&sm, &sh, \"a::b\".to_string()),\n+            vec![mk_ident(\"a\"), token::Colon, token::Colon, mk_ident(\"b\")],\n+        );\n     })\n }\n \n #[test]\n-fn dcparsing_3() {\n+fn doublecolon_parsing_3() {\n     with_default_globals(|| {\n         let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n         let sh = mk_sess(sm.clone());\n-        check_tokenization(setup(&sm, &sh, \"a ::b\".to_string()),\n-                        vec![mk_ident(\"a\"), token::Whitespace, token::ModSep, mk_ident(\"b\")]);\n+        check_tokenization(\n+            setup(&sm, &sh, \"a ::b\".to_string()),\n+            vec![mk_ident(\"a\"), token::Whitespace, token::Colon, token::Colon, mk_ident(\"b\")],\n+        );\n     })\n }\n \n #[test]\n-fn dcparsing_4() {\n+fn doublecolon_parsing_4() {\n     with_default_globals(|| {\n         let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n         let sh = mk_sess(sm.clone());\n-        check_tokenization(setup(&sm, &sh, \"a:: b\".to_string()),\n-                        vec![mk_ident(\"a\"), token::ModSep, token::Whitespace, mk_ident(\"b\")]);\n+        check_tokenization(\n+            setup(&sm, &sh, \"a:: b\".to_string()),\n+            vec![mk_ident(\"a\"), token::Colon, token::Colon, token::Whitespace, mk_ident(\"b\")],\n+        );\n     })\n }\n "}, {"sha": "e5ba7e45309dda964ca6e42699720070e00a49b6", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 32, "deletions": 8, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=14890954ce17c44d944eda988c5a64bb4c5ec9eb", "patch": "@@ -39,29 +39,29 @@ struct TokenTreesReader<'a> {\n impl<'a> TokenTreesReader<'a> {\n     // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n     fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n-        let mut tts = Vec::new();\n+        let mut buf = TokenStreamBuilder::default();\n \n         self.real_token();\n         while self.token != token::Eof {\n-            tts.push(self.parse_token_tree()?);\n+            buf.push(self.parse_token_tree()?);\n         }\n \n-        Ok(TokenStream::new(tts))\n+        Ok(buf.into_token_stream())\n     }\n \n     // Parse a stream of tokens into a list of `TokenTree`s, up to a `CloseDelim`.\n     fn parse_token_trees_until_close_delim(&mut self) -> TokenStream {\n-        let mut tts = vec![];\n+        let mut buf = TokenStreamBuilder::default();\n         loop {\n             if let token::CloseDelim(..) = self.token.kind {\n-                return TokenStream::new(tts);\n+                return buf.into_token_stream();\n             }\n \n             match self.parse_token_tree() {\n-                Ok(tree) => tts.push(tree),\n+                Ok(tree) => buf.push(tree),\n                 Err(mut e) => {\n                     e.emit();\n-                    return TokenStream::new(tts);\n+                    return buf.into_token_stream();\n                 }\n             }\n         }\n@@ -223,8 +223,32 @@ impl<'a> TokenTreesReader<'a> {\n                 _ => {\n                     self.token = token;\n                     return;\n-                },\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+struct TokenStreamBuilder {\n+    buf: Vec<TreeAndJoint>,\n+}\n+\n+impl TokenStreamBuilder {\n+    fn push(&mut self, (tree, joint): TreeAndJoint) {\n+        if let Some((TokenTree::Token(prev_token), Joint)) = self.buf.last() {\n+            if let TokenTree::Token(token) = &tree {\n+                if let Some(glued) = prev_token.glue(token) {\n+                    self.buf.pop();\n+                    self.buf.push((TokenTree::Token(glued), joint));\n+                    return;\n+                }\n             }\n         }\n+        self.buf.push((tree, joint))\n+    }\n+\n+    fn into_token_stream(self) -> TokenStream {\n+        TokenStream::new(self.buf)\n     }\n }"}, {"sha": "1865f925165bdaeb64d916d7793991ec215afe5e", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=14890954ce17c44d944eda988c5a64bb4c5ec9eb", "patch": "@@ -551,7 +551,7 @@ impl Token {\n         }\n     }\n \n-    crate fn glue(self, joint: Token) -> Option<Token> {\n+    crate fn glue(&self, joint: &Token) -> Option<Token> {\n         let kind = match self.kind {\n             Eq => match joint.kind {\n                 Eq => EqEq,"}, {"sha": "09a1b93c7bb195819e188147ba927e476be3c642", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/14890954ce17c44d944eda988c5a64bb4c5ec9eb/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=14890954ce17c44d944eda988c5a64bb4c5ec9eb", "patch": "@@ -414,7 +414,7 @@ impl TokenStreamBuilder {\n         let last_tree_if_joint = self.0.last().and_then(TokenStream::last_tree_if_joint);\n         if let Some(TokenTree::Token(last_token)) = last_tree_if_joint {\n             if let Some((TokenTree::Token(token), is_joint)) = stream.first_tree_and_joint() {\n-                if let Some(glued_tok) = last_token.glue(token) {\n+                if let Some(glued_tok) = last_token.glue(&token) {\n                     let last_stream = self.0.pop().unwrap();\n                     self.push_all_but_last_tree(&last_stream);\n                     let glued_tt = TokenTree::Token(glued_tok);"}]}