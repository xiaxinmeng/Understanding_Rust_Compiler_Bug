{"sha": "d062f63519bfe7e366f0cadfdb15073434558351", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQwNjJmNjM1MTliZmU3ZTM2NmYwY2FkZmRiMTUwNzM0MzQ1NTgzNTE=", "commit": {"author": {"name": "Vytautas Astrauskas", "email": "astrauv@amazon.com", "date": "2020-04-17T02:40:02Z"}, "committer": {"name": "Vytautas Astrauskas", "email": "astrauv@amazon.com", "date": "2020-04-27T21:26:36Z"}, "message": "Fix support for MacOS.", "tree": {"sha": "6fec195a7211333de4b19ed7aec1e14584ee83c2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6fec195a7211333de4b19ed7aec1e14584ee83c2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d062f63519bfe7e366f0cadfdb15073434558351", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d062f63519bfe7e366f0cadfdb15073434558351", "html_url": "https://github.com/rust-lang/rust/commit/d062f63519bfe7e366f0cadfdb15073434558351", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d062f63519bfe7e366f0cadfdb15073434558351/comments", "author": null, "committer": null, "parents": [{"sha": "44e930559917968d4513e5915f5957f2fe1f3e11", "url": "https://api.github.com/repos/rust-lang/rust/commits/44e930559917968d4513e5915f5957f2fe1f3e11", "html_url": "https://github.com/rust-lang/rust/commit/44e930559917968d4513e5915f5957f2fe1f3e11"}], "stats": {"total": 221, "additions": 128, "deletions": 93}, "files": [{"sha": "ab82c39836b2e387deb687aaf80b9184f1cc0bd3", "filename": "src/eval.rs", "status": "modified", "additions": 13, "deletions": 3, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/d062f63519bfe7e366f0cadfdb15073434558351/src%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d062f63519bfe7e366f0cadfdb15073434558351/src%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Feval.rs?ref=d062f63519bfe7e366f0cadfdb15073434558351", "patch": "@@ -205,15 +205,25 @@ pub fn eval_main<'tcx>(tcx: TyCtxt<'tcx>, main_id: DefId, config: MiriConfig) ->\n     // Perform the main execution.\n     let res: InterpResult<'_, i64> = (|| {\n         // Main loop.\n-        while ecx.schedule()? {\n-            assert!(ecx.step()?, \"a terminated thread was scheduled for execution\");\n+        loop {\n+            match ecx.schedule()? {\n+                SchedulingAction::ExecuteStep => {\n+                    assert!(ecx.step()?, \"a terminated thread was scheduled for execution\");\n+                }\n+                SchedulingAction::ExecuteDtors => {\n+                    ecx.run_tls_dtors_for_active_thread()?;\n+                }\n+                SchedulingAction::Stop => {\n+                    break;\n+                }\n+            }\n             ecx.process_diagnostics();\n         }\n         // Read the return code pointer *before* we run TLS destructors, to assert\n         // that it was written to by the time that `start` lang item returned.\n         let return_code = ecx.read_scalar(ret_place.into())?.not_undef()?.to_machine_isize(&ecx)?;\n         // Global destructors.\n-        ecx.run_tls_dtors()?;\n+        ecx.run_windows_tls_dtors()?;\n         Ok(return_code)\n     })();\n "}, {"sha": "beee94b918b56775d63116a0b43fd9aa41913ec0", "filename": "src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d062f63519bfe7e366f0cadfdb15073434558351/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d062f63519bfe7e366f0cadfdb15073434558351/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=d062f63519bfe7e366f0cadfdb15073434558351", "patch": "@@ -64,7 +64,7 @@ pub use crate::stacked_borrows::{\n     EvalContextExt as StackedBorEvalContextExt, Item, Permission, PtrId, Stack, Stacks, Tag,\n };\n pub use crate::thread::{\n-    EvalContextExt as ThreadsEvalContextExt, ThreadId, ThreadManager, ThreadState,\n+    EvalContextExt as ThreadsEvalContextExt, SchedulingAction, ThreadId, ThreadManager, ThreadState,\n };\n \n /// Insert rustc arguments at the beginning of the argument list that Miri wants to be"}, {"sha": "9f65d0f9c47d76552263b773b69ff03d7b5c8642", "filename": "src/shims/foreign_items/posix/macos.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d062f63519bfe7e366f0cadfdb15073434558351/src%2Fshims%2Fforeign_items%2Fposix%2Fmacos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d062f63519bfe7e366f0cadfdb15073434558351/src%2Fshims%2Fforeign_items%2Fposix%2Fmacos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fforeign_items%2Fposix%2Fmacos.rs?ref=d062f63519bfe7e366f0cadfdb15073434558351", "patch": "@@ -82,7 +82,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 let dtor = this.read_scalar(args[0])?.not_undef()?;\n                 let dtor = this.memory.get_fn(dtor)?.as_instance()?;\n                 let data = this.read_scalar(args[1])?.not_undef()?;\n-                this.machine.tls.set_global_dtor(dtor, data)?;\n+                let active_thread = this.get_active_thread()?;\n+                this.machine.tls.set_global_dtor(active_thread, dtor, data)?;\n             }\n \n             // Querying system information"}, {"sha": "6dc3025acd5ae336933b8465e2dfeea7cc8d15f5", "filename": "src/shims/tls.rs", "status": "modified", "additions": 84, "deletions": 67, "changes": 151, "blob_url": "https://github.com/rust-lang/rust/blob/d062f63519bfe7e366f0cadfdb15073434558351/src%2Fshims%2Ftls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d062f63519bfe7e366f0cadfdb15073434558351/src%2Fshims%2Ftls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Ftls.rs?ref=d062f63519bfe7e366f0cadfdb15073434558351", "patch": "@@ -2,15 +2,17 @@\n \n use std::collections::BTreeMap;\n use std::collections::btree_map::Entry;\n+use std::collections::HashSet;\n \n use log::trace;\n \n+use rustc_index::vec::Idx;\n use rustc_middle::ty;\n use rustc_target::abi::{Size, HasDataLayout};\n \n use crate::{\n     HelpersEvalContextExt, InterpResult, MPlaceTy, Scalar, StackPopCleanup, Tag, ThreadId,\n-    ThreadState, ThreadsEvalContextExt,\n+    ThreadsEvalContextExt,\n };\n \n pub type TlsKey = u128;\n@@ -32,20 +34,20 @@ pub struct TlsData<'tcx> {\n     /// pthreads-style thread-local storage.\n     keys: BTreeMap<TlsKey, TlsEntry<'tcx>>,\n \n-    /// A single global dtor (that's how things work on macOS) with a data argument.\n-    global_dtor: Option<(ty::Instance<'tcx>, Scalar<Tag>)>,\n+    /// A single global per thread dtor (that's how things work on macOS) with a data argument.\n+    global_dtors: BTreeMap<ThreadId, (ty::Instance<'tcx>, Scalar<Tag>)>,\n \n     /// Whether we are in the \"destruct\" phase, during which some operations are UB.\n-    dtors_running: bool,\n+    dtors_running: HashSet<ThreadId>,\n }\n \n impl<'tcx> Default for TlsData<'tcx> {\n     fn default() -> Self {\n         TlsData {\n             next_key: 1, // start with 1 as we must not use 0 on Windows\n             keys: Default::default(),\n-            global_dtor: None,\n-            dtors_running: false,\n+            global_dtors: Default::default(),\n+            dtors_running: Default::default(),\n         }\n     }\n }\n@@ -112,16 +114,15 @@ impl<'tcx> TlsData<'tcx> {\n         }\n     }\n \n-    pub fn set_global_dtor(&mut self, dtor: ty::Instance<'tcx>, data: Scalar<Tag>) -> InterpResult<'tcx> {\n-        if self.dtors_running {\n+    /// Set global dtor for the given thread.\n+    pub fn set_global_dtor(&mut self, thread: ThreadId, dtor: ty::Instance<'tcx>, data: Scalar<Tag>) -> InterpResult<'tcx> {\n+        if self.dtors_running.contains(&thread) {\n             // UB, according to libstd docs.\n             throw_ub_format!(\"setting global destructor while destructors are already running\");\n         }\n-        if self.global_dtor.is_some() {\n-            throw_unsup_format!(\"setting more than one global destructor is not supported\");\n+        if self.global_dtors.insert(thread, (dtor, data)).is_some() {\n+            throw_unsup_format!(\"setting more than one global destructor for the same thread is not supported\");\n         }\n-\n-        self.global_dtor = Some((dtor, data));\n         Ok(())\n     }\n \n@@ -148,7 +149,7 @@ impl<'tcx> TlsData<'tcx> {\n         &mut self,\n         key: Option<TlsKey>,\n         thread_id: ThreadId,\n-    ) -> Option<(ty::Instance<'tcx>, ThreadId, Scalar<Tag>, TlsKey)> {\n+    ) -> Option<(ty::Instance<'tcx>, Scalar<Tag>, TlsKey)> {\n         use std::collections::Bound::*;\n \n         let thread_local = &mut self.keys;\n@@ -161,9 +162,9 @@ impl<'tcx> TlsData<'tcx> {\n         {\n             match data.entry(thread_id) {\n                 Entry::Occupied(entry) => {\n-                    let (thread_id, data_scalar) = entry.remove_entry();\n+                    let data_scalar = entry.remove();\n                     if let Some(dtor) = dtor {\n-                        let ret = Some((*dtor, thread_id, data_scalar, key));\n+                        let ret = Some((*dtor, data_scalar, key));\n                         return ret;\n                     }\n                 }\n@@ -176,83 +177,99 @@ impl<'tcx> TlsData<'tcx> {\n \n impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n-    /// Run TLS destructors for all threads.\n-    fn run_tls_dtors(&mut self) -> InterpResult<'tcx> {\n+\n+    /// Run TLS destructors for the main thread on Windows. The implementation\n+    /// assumes that we do not support concurrency on Windows yet.\n+    ///\n+    /// Note: on non-Windows OS this function is a no-op.\n+    fn run_windows_tls_dtors(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        assert!(!this.machine.tls.dtors_running, \"running TLS dtors twice\");\n-        this.machine.tls.dtors_running = true;\n+        if this.tcx.sess.target.target.target_os != \"windows\" {\n+            return Ok(());\n+        }\n+        let active_thread = this.get_active_thread()?;\n+        assert_eq!(active_thread.index(), 0, \"concurrency on Windows not supported\");\n+        assert!(!this.machine.tls.dtors_running.contains(&active_thread), \"running TLS dtors twice\");\n+        this.machine.tls.dtors_running.insert(active_thread);\n+        // Windows has a special magic linker section that is run on certain events.\n+        // Instead of searching for that section and supporting arbitrary hooks in there\n+        // (that would be basically https://github.com/rust-lang/miri/issues/450),\n+        // we specifically look up the static in libstd that we know is placed\n+        // in that section.\n+        let thread_callback = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"thread_local\", \"p_thread_callback\"])?;\n+        let thread_callback = this.memory.get_fn(thread_callback.not_undef()?)?.as_instance()?;\n+\n+        // The signature of this function is `unsafe extern \"system\" fn(h: c::LPVOID, dwReason: c::DWORD, pv: c::LPVOID)`.\n+        let reason = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"c\", \"DLL_PROCESS_DETACH\"])?;\n+        let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n+        this.call_function(\n+            thread_callback,\n+            &[Scalar::null_ptr(this).into(), reason.into(), Scalar::null_ptr(this).into()],\n+            Some(ret_place),\n+            StackPopCleanup::None { cleanup: true },\n+        )?;\n+\n+        // step until out of stackframes\n+        this.run()?;\n+\n+        // Windows doesn't have other destructors.\n+        Ok(())\n+    }\n \n+    /// Run TLS destructors for the active thread.\n+    ///\n+    /// Note: on Windows OS this function is a no-op because we do not support\n+    /// concurrency on Windows yet.\n+    fn run_tls_dtors_for_active_thread(&mut self) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n         if this.tcx.sess.target.target.target_os == \"windows\" {\n-            // Windows has a special magic linker section that is run on certain events.\n-            // Instead of searching for that section and supporting arbitrary hooks in there\n-            // (that would be basically https://github.com/rust-lang/miri/issues/450),\n-            // we specifically look up the static in libstd that we know is placed\n-            // in that section.\n-            let thread_callback = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"thread_local\", \"p_thread_callback\"])?;\n-            let thread_callback = this.memory.get_fn(thread_callback.not_undef()?)?.as_instance()?;\n-\n-            // The signature of this function is `unsafe extern \"system\" fn(h: c::LPVOID, dwReason: c::DWORD, pv: c::LPVOID)`.\n-            let reason = this.eval_path_scalar(&[\"std\", \"sys\", \"windows\", \"c\", \"DLL_PROCESS_DETACH\"])?;\n+            return Ok(());\n+        }\n+        let thread_id = this.get_active_thread()?;\n+        assert!(!this.machine.tls.dtors_running.contains(&thread_id), \"running TLS dtors twice\");\n+        this.machine.tls.dtors_running.insert(thread_id);\n+\n+        // The macOS global dtor runs \"before any TLS slots get freed\", so do that first.\n+        if let Some(&(instance, data)) = this.machine.tls.global_dtors.get(&thread_id) {\n+            trace!(\"Running global dtor {:?} on {:?} at {:?}\", instance, data, thread_id);\n+\n             let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n             this.call_function(\n-                thread_callback,\n-                &[Scalar::null_ptr(this).into(), reason.into(), Scalar::null_ptr(this).into()],\n+                instance,\n+                &[data.into()],\n                 Some(ret_place),\n                 StackPopCleanup::None { cleanup: true },\n             )?;\n \n             // step until out of stackframes\n             this.run()?;\n-\n-            // Windows doesn't have other destructors.\n-            return Ok(());\n         }\n \n-        // The macOS global dtor runs \"before any TLS slots get freed\", so do that first.\n-        if let Some((instance, data)) = this.machine.tls.global_dtor {\n-            trace!(\"Running global dtor {:?} on {:?}\", instance, data);\n+        assert!(this.has_terminated(thread_id)?, \"running TLS dtors for non-terminated thread\");\n+        let mut dtor = this.machine.tls.fetch_tls_dtor(None, thread_id);\n+        while let Some((instance, ptr, key)) = dtor {\n+            trace!(\"Running TLS dtor {:?} on {:?} at {:?}\", instance, ptr, thread_id);\n+            assert!(!this.is_null(ptr).unwrap(), \"Data can't be NULL when dtor is called!\");\n \n             let ret_place = MPlaceTy::dangling(this.machine.layouts.unit, this).into();\n             this.call_function(\n                 instance,\n-                &[data.into()],\n+                &[ptr.into()],\n                 Some(ret_place),\n                 StackPopCleanup::None { cleanup: true },\n             )?;\n \n             // step until out of stackframes\n             this.run()?;\n-        }\n \n-        // Now run the \"keyed\" destructors.\n-        for (thread_id, thread_state) in this.get_all_thread_ids_with_states() {\n-            assert!(thread_state == ThreadState::Terminated,\n-                    \"TLS destructors should be executed after all threads terminated.\");\n-            this.set_active_thread(thread_id)?;\n-            let mut dtor = this.machine.tls.fetch_tls_dtor(None, thread_id);\n-            while let Some((instance, thread_id, ptr, key)) = dtor {\n-                trace!(\"Running TLS dtor {:?} on {:?} at {:?}\", instance, ptr, thread_id);\n-                assert!(!this.is_null(ptr).unwrap(), \"Data can't be NULL when dtor is called!\");\n-\n-                let ret_place = MPlaceTy::dangling(this.layout_of(this.tcx.mk_unit())?, this).into();\n-                this.call_function(\n-                    instance,\n-                    &[ptr.into()],\n-                    Some(ret_place),\n-                    StackPopCleanup::None { cleanup: true },\n-                )?;\n-\n-                // step until out of stackframes\n-                this.run()?;\n-\n-                // Fetch next dtor after `key`.\n-                dtor = match this.machine.tls.fetch_tls_dtor(Some(key), thread_id) {\n-                    dtor @ Some(_) => dtor,\n-                    // We ran each dtor once, start over from the beginning.\n-                    None => this.machine.tls.fetch_tls_dtor(None, thread_id),\n-                };\n-            }\n+            // Fetch next dtor after `key`.\n+            dtor = match this.machine.tls.fetch_tls_dtor(Some(key), thread_id) {\n+                dtor @ Some(_) => dtor,\n+                // We ran each dtor once, start over from the beginning.\n+                None => this.machine.tls.fetch_tls_dtor(None, thread_id),\n+            };\n         }\n+\n         Ok(())\n     }\n }"}, {"sha": "d40b2a176e73f52cfa9a760c1f2e2482528b08b9", "filename": "src/thread.rs", "status": "modified", "additions": 28, "deletions": 21, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/d062f63519bfe7e366f0cadfdb15073434558351/src%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d062f63519bfe7e366f0cadfdb15073434558351/src%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fthread.rs?ref=d062f63519bfe7e366f0cadfdb15073434558351", "patch": "@@ -17,6 +17,16 @@ use rustc_middle::{\n \n use crate::*;\n \n+#[derive(Clone, Copy, Debug, PartialEq, Eq)]\n+pub enum SchedulingAction {\n+    /// Execute step on the active thread.\n+    ExecuteStep,\n+    /// Execute destructors of the active thread.\n+    ExecuteDtors,\n+    /// Stop the program.\n+    Stop,\n+}\n+\n /// A thread identifier.\n #[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n pub struct ThreadId(usize);\n@@ -197,6 +207,11 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n         self.active_thread\n     }\n \n+    /// Has the given thread terminated?\n+    fn has_terminated(&self, thread_id: ThreadId) -> bool {\n+        self.threads[thread_id].state == ThreadState::Terminated\n+    }\n+\n     /// Get the borrow of the currently active thread.\n     fn active_thread_mut(&mut self) -> &mut Thread<'mir, 'tcx> {\n         &mut self.threads[self.active_thread]\n@@ -234,11 +249,6 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n         self.active_thread_mut().thread_name = Some(new_thread_name);\n     }\n \n-    /// Get ids and states of all threads ever allocated.\n-    fn get_all_thread_ids_with_states(&self) -> Vec<(ThreadId, ThreadState)> {\n-        self.threads.iter_enumerated().map(|(id, thread)| (id, thread.state)).collect()\n-    }\n-\n     /// Allocate a new blockset id.\n     fn create_blockset(&mut self) -> BlockSetId {\n         self.blockset_counter = self.blockset_counter.checked_add(1).unwrap();\n@@ -265,10 +275,8 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n         None\n     }\n \n-    /// Decide which thread to run next.\n-    ///\n-    /// Returns `false` if all threads terminated.\n-    fn schedule(&mut self) -> InterpResult<'tcx, bool> {\n+    /// Decide which action to take next and on which thread.\n+    fn schedule(&mut self) -> InterpResult<'tcx, SchedulingAction> {\n         if self.threads[self.active_thread].check_terminated() {\n             // Check if we need to unblock any threads.\n             for (i, thread) in self.threads.iter_enumerated_mut() {\n@@ -277,18 +285,19 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n                     thread.state = ThreadState::Enabled;\n                 }\n             }\n+            return Ok(SchedulingAction::ExecuteDtors);\n         }\n         if self.threads[self.active_thread].state == ThreadState::Enabled {\n-            return Ok(true);\n+            return Ok(SchedulingAction::ExecuteStep);\n         }\n         if let Some(enabled_thread) =\n             self.threads.iter().position(|thread| thread.state == ThreadState::Enabled)\n         {\n             self.active_thread = ThreadId::new(enabled_thread);\n-            return Ok(true);\n+            return Ok(SchedulingAction::ExecuteStep);\n         }\n         if self.threads.iter().all(|thread| thread.state == ThreadState::Terminated) {\n-            Ok(false)\n+            Ok(SchedulingAction::Stop)\n         } else {\n             throw_machine_stop!(TerminationInfo::Deadlock);\n         }\n@@ -409,6 +418,11 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(this.machine.threads.get_active_thread_id())\n     }\n \n+    fn has_terminated(&self, thread_id: ThreadId) -> InterpResult<'tcx, bool> {\n+        let this = self.eval_context_ref();\n+        Ok(this.machine.threads.has_terminated(thread_id))\n+    }\n+\n     fn active_thread_stack(&self) -> &[Frame<'mir, 'tcx, Tag, FrameData<'tcx>>] {\n         let this = self.eval_context_ref();\n         this.machine.threads.active_thread_stack()\n@@ -424,11 +438,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(this.machine.threads.set_thread_name(new_thread_name))\n     }\n \n-    fn get_all_thread_ids_with_states(&mut self) -> Vec<(ThreadId, ThreadState)> {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.get_all_thread_ids_with_states()\n-    }\n-\n     fn create_blockset(&mut self) -> InterpResult<'tcx, BlockSetId> {\n         let this = self.eval_context_mut();\n         Ok(this.machine.threads.create_blockset())\n@@ -444,10 +453,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(this.machine.threads.unblock_random_thread(set))\n     }\n \n-    /// Decide which thread to run next.\n-    ///\n-    /// Returns `false` if all threads terminated.\n-    fn schedule(&mut self) -> InterpResult<'tcx, bool> {\n+    /// Decide which action to take next and on which thread.\n+    fn schedule(&mut self) -> InterpResult<'tcx, SchedulingAction> {\n         let this = self.eval_context_mut();\n         this.machine.threads.schedule()\n     }"}]}