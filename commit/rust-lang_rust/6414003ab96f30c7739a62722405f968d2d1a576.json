{"sha": "6414003ab96f30c7739a62722405f968d2d1a576", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY0MTQwMDNhYjk2ZjMwYzc3MzlhNjI3MjI0MDVmOTY4ZDJkMWE1NzY=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2020-04-12T09:01:59Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2020-04-12T09:01:59Z"}, "message": "organize intrinsics into groups", "tree": {"sha": "9b3835e1164334a051a2ca0fb198229492c9189c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9b3835e1164334a051a2ca0fb198229492c9189c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6414003ab96f30c7739a62722405f968d2d1a576", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6414003ab96f30c7739a62722405f968d2d1a576", "html_url": "https://github.com/rust-lang/rust/commit/6414003ab96f30c7739a62722405f968d2d1a576", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6414003ab96f30c7739a62722405f968d2d1a576/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "314e7238cf5f5fa6030035814193df455d337ad7", "url": "https://api.github.com/repos/rust-lang/rust/commits/314e7238cf5f5fa6030035814193df455d337ad7", "html_url": "https://github.com/rust-lang/rust/commit/314e7238cf5f5fa6030035814193df455d337ad7"}], "stats": {"total": 493, "additions": 249, "deletions": 244}, "files": [{"sha": "de34f1a7b6cefec5d33923dc8a81e300919aa516", "filename": "src/shims/intrinsics.rs", "status": "modified", "additions": 249, "deletions": 244, "changes": 493, "blob_url": "https://github.com/rust-lang/rust/blob/6414003ab96f30c7739a62722405f968d2d1a576/src%2Fshims%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6414003ab96f30c7739a62722405f968d2d1a576/src%2Fshims%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fintrinsics.rs?ref=6414003ab96f30c7739a62722405f968d2d1a576", "patch": "@@ -37,183 +37,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             Some(p) => p,\n         };\n \n+        // Then handle terminating intrinsics.\n         match intrinsic_name {\n-            \"try\" => return this.handle_try(args, dest, ret),\n-\n-            \"arith_offset\" => {\n-                let offset = this.read_scalar(args[1])?.to_machine_isize(this)?;\n-                let ptr = this.read_scalar(args[0])?.not_undef()?;\n-\n-                let pointee_ty = substs.type_at(0);\n-                let pointee_size = i64::try_from(this.layout_of(pointee_ty)?.size.bytes()).unwrap();\n-                let offset = offset.overflowing_mul(pointee_size).0;\n-                let result_ptr = ptr.ptr_wrapping_signed_offset(offset, this);\n-                this.write_scalar(result_ptr, dest)?;\n-            }\n-\n-            \"assume\" => {\n-                let cond = this.read_scalar(args[0])?.to_bool()?;\n-                if !cond {\n-                    throw_ub_format!(\"`assume` intrinsic called with `false`\");\n-                }\n-            }\n-\n-            \"volatile_load\" => {\n-                let place = this.deref_operand(args[0])?;\n-                this.copy_op(place.into(), dest)?;\n-            }\n-\n-            \"volatile_store\" => {\n-                let place = this.deref_operand(args[0])?;\n-                this.copy_op(args[1], place.into())?;\n-            }\n-\n-            #[rustfmt::skip]\n-            | \"atomic_load\"\n-            | \"atomic_load_relaxed\"\n-            | \"atomic_load_acq\"\n-            => {\n-                let place = this.deref_operand(args[0])?;\n-                let val = this.read_scalar(place.into())?; // make sure it fits into a scalar; otherwise it cannot be atomic\n-\n-                // Check alignment requirements. Atomics must always be aligned to their size,\n-                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-                // be 8-aligned).\n-                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n-\n-                this.write_scalar(val, dest)?;\n-            }\n-\n-            #[rustfmt::skip]\n-            | \"atomic_store\"\n-            | \"atomic_store_relaxed\"\n-            | \"atomic_store_rel\"\n-            => {\n-                let place = this.deref_operand(args[0])?;\n-                let val = this.read_scalar(args[1])?; // make sure it fits into a scalar; otherwise it cannot be atomic\n-\n-                // Check alignment requirements. Atomics must always be aligned to their size,\n-                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-                // be 8-aligned).\n-                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n-\n-                this.write_scalar(val, place.into())?;\n-            }\n-\n-            #[rustfmt::skip]\n-            | \"atomic_fence_acq\"\n-            | \"atomic_fence_rel\"\n-            | \"atomic_fence_acqrel\"\n-            | \"atomic_fence\"\n-            | \"atomic_singlethreadfence_acq\"\n-            | \"atomic_singlethreadfence_rel\"\n-            | \"atomic_singlethreadfence_acqrel\"\n-            | \"atomic_singlethreadfence\"\n-            => {\n-                // we are inherently singlethreaded and singlecored, this is a nop\n-            }\n-\n-            _ if intrinsic_name.starts_with(\"atomic_xchg\") => {\n-                let place = this.deref_operand(args[0])?;\n-                let new = this.read_scalar(args[1])?;\n-                let old = this.read_scalar(place.into())?;\n-\n-                // Check alignment requirements. Atomics must always be aligned to their size,\n-                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-                // be 8-aligned).\n-                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n-\n-                this.write_scalar(old, dest)?; // old value is returned\n-                this.write_scalar(new, place.into())?;\n-            }\n-\n-            _ if intrinsic_name.starts_with(\"atomic_cxchg\") => {\n-                let place = this.deref_operand(args[0])?;\n-                let expect_old = this.read_immediate(args[1])?; // read as immediate for the sake of `binary_op()`\n-                let new = this.read_scalar(args[2])?;\n-                let old = this.read_immediate(place.into())?; // read as immediate for the sake of `binary_op()`\n-\n-                // Check alignment requirements. Atomics must always be aligned to their size,\n-                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-                // be 8-aligned).\n-                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n-\n-                // `binary_op` will bail if either of them is not a scalar.\n-                let eq = this.overflowing_binary_op(mir::BinOp::Eq, old, expect_old)?.0;\n-                let res = Immediate::ScalarPair(old.to_scalar_or_undef(), eq.into());\n-                // Return old value.\n-                this.write_immediate(res, dest)?;\n-                // Update ptr depending on comparison.\n-                if eq.to_bool()? {\n-                    this.write_scalar(new, place.into())?;\n-                }\n-            }\n-\n-            #[rustfmt::skip]\n-            | \"atomic_or\"\n-            | \"atomic_or_acq\"\n-            | \"atomic_or_rel\"\n-            | \"atomic_or_acqrel\"\n-            | \"atomic_or_relaxed\"\n-            | \"atomic_xor\"\n-            | \"atomic_xor_acq\"\n-            | \"atomic_xor_rel\"\n-            | \"atomic_xor_acqrel\"\n-            | \"atomic_xor_relaxed\"\n-            | \"atomic_and\"\n-            | \"atomic_and_acq\"\n-            | \"atomic_and_rel\"\n-            | \"atomic_and_acqrel\"\n-            | \"atomic_and_relaxed\"\n-            | \"atomic_nand\"\n-            | \"atomic_nand_acq\"\n-            | \"atomic_nand_rel\"\n-            | \"atomic_nand_acqrel\"\n-            | \"atomic_nand_relaxed\"\n-            | \"atomic_xadd\"\n-            | \"atomic_xadd_acq\"\n-            | \"atomic_xadd_rel\"\n-            | \"atomic_xadd_acqrel\"\n-            | \"atomic_xadd_relaxed\"\n-            | \"atomic_xsub\"\n-            | \"atomic_xsub_acq\"\n-            | \"atomic_xsub_rel\"\n-            | \"atomic_xsub_acqrel\"\n-            | \"atomic_xsub_relaxed\"\n-            => {\n-                let place = this.deref_operand(args[0])?;\n-                if !place.layout.ty.is_integral() {\n-                    bug!(\"Atomic arithmetic operations only work on integer types\");\n-                }\n-                let rhs = this.read_immediate(args[1])?;\n-                let old = this.read_immediate(place.into())?;\n-\n-                // Check alignment requirements. Atomics must always be aligned to their size,\n-                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-                // be 8-aligned).\n-                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n-\n-                this.write_immediate(*old, dest)?; // old value is returned\n-                let (op, neg) = match intrinsic_name.split('_').nth(1).unwrap() {\n-                    \"or\" => (mir::BinOp::BitOr, false),\n-                    \"xor\" => (mir::BinOp::BitXor, false),\n-                    \"and\" => (mir::BinOp::BitAnd, false),\n-                    \"xadd\" => (mir::BinOp::Add, false),\n-                    \"xsub\" => (mir::BinOp::Sub, false),\n-                    \"nand\" => (mir::BinOp::BitAnd, true),\n-                    _ => bug!(),\n-                };\n-                // Atomics wrap around on overflow.\n-                let val = this.binary_op(op, old, rhs)?;\n-                let val = if neg { this.unary_op(mir::UnOp::Not, val)? } else { val };\n-                this.write_immediate(*val, place.into())?;\n-            }\n-\n+            // Raw memory accesses\n             #[rustfmt::skip]\n             | \"copy\"\n             | \"copy_nonoverlapping\"\n@@ -240,6 +66,51 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 }\n             }\n \n+            \"move_val_init\" => {\n+                let place = this.deref_operand(args[0])?;\n+                this.copy_op(args[1], place.into())?;\n+            }\n+\n+            \"volatile_load\" => {\n+                let place = this.deref_operand(args[0])?;\n+                this.copy_op(place.into(), dest)?;\n+            }\n+            \"volatile_store\" => {\n+                let place = this.deref_operand(args[0])?;\n+                this.copy_op(args[1], place.into())?;\n+            }\n+\n+            \"write_bytes\" => {\n+                let ty = substs.type_at(0);\n+                let ty_layout = this.layout_of(ty)?;\n+                let val_byte = this.read_scalar(args[1])?.to_u8()?;\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                let count = this.read_scalar(args[2])?.to_machine_usize(this)?;\n+                let byte_count = ty_layout.size.checked_mul(count, this)\n+                    .ok_or_else(|| err_ub_format!(\"overflow computing total size of `write_bytes`\"))?;\n+                this.memory\n+                    .write_bytes(ptr, iter::repeat(val_byte).take(byte_count.bytes() as usize))?;\n+            }\n+\n+            // Pointer arithmetic\n+            \"arith_offset\" => {\n+                let offset = this.read_scalar(args[1])?.to_machine_isize(this)?;\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+\n+                let pointee_ty = substs.type_at(0);\n+                let pointee_size = i64::try_from(this.layout_of(pointee_ty)?.size.bytes()).unwrap();\n+                let offset = offset.overflowing_mul(pointee_size).0;\n+                let result_ptr = ptr.ptr_wrapping_signed_offset(offset, this);\n+                this.write_scalar(result_ptr, dest)?;\n+            }\n+            \"offset\" => {\n+                let offset = this.read_scalar(args[1])?.to_machine_isize(this)?;\n+                let ptr = this.read_scalar(args[0])?.not_undef()?;\n+                let result_ptr = this.pointer_offset_inbounds(ptr, substs.type_at(0), offset)?;\n+                this.write_scalar(result_ptr, dest)?;\n+            }\n+\n+            // Floating-point operations\n             #[rustfmt::skip]\n             | \"sinf32\"\n             | \"fabsf32\"\n@@ -363,58 +234,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 };\n                 this.write_scalar(Scalar::from_f64(res), dest)?;\n             }\n-\n-            \"exact_div\" =>\n-                this.exact_div(this.read_immediate(args[0])?, this.read_immediate(args[1])?, dest)?,\n-\n-            \"forget\" => {}\n-\n-            #[rustfmt::skip]\n-            | \"likely\"\n-            | \"unlikely\"\n-            => {\n-                // These just return their argument\n-                let b = this.read_immediate(args[0])?;\n-                this.write_immediate(*b, dest)?;\n-            }\n-\n-            \"pref_align_of\" => {\n-                let ty = substs.type_at(0);\n-                let layout = this.layout_of(ty)?;\n-                let align = layout.align.pref.bytes();\n-                let align_val = Scalar::from_machine_usize(align, this);\n-                this.write_scalar(align_val, dest)?;\n-            }\n-\n-            \"move_val_init\" => {\n-                let place = this.deref_operand(args[0])?;\n-                this.copy_op(args[1], place.into())?;\n-            }\n-\n-            \"offset\" => {\n-                let offset = this.read_scalar(args[1])?.to_machine_isize(this)?;\n-                let ptr = this.read_scalar(args[0])?.not_undef()?;\n-                let result_ptr = this.pointer_offset_inbounds(ptr, substs.type_at(0), offset)?;\n-                this.write_scalar(result_ptr, dest)?;\n-            }\n-\n-            \"assert_inhabited\" |\n-            \"assert_zero_valid\" |\n-            \"assert_uninit_valid\" => {\n-                let ty = substs.type_at(0);\n-                let layout = this.layout_of(ty)?;\n-                // Abort here because the caller might not be panic safe.\n-                if layout.abi.is_uninhabited() {\n-                    throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"attempted to instantiate uninhabited type `{}`\", ty))))\n-                }\n-                if intrinsic_name == \"assert_zero_valid\" && !layout.might_permit_raw_init(this, /*zero:*/ true).unwrap() {\n-                    throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"attempted to zero-initialize type `{}`, which is invalid\", ty))))\n-                }\n-                if intrinsic_name == \"assert_uninit_valid\" && !layout.might_permit_raw_init(this, /*zero:*/ false).unwrap() {\n-                    throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"attempted to leave type `{}` uninitialized, which is invalid\", ty))))\n-                }\n-            }\n-\n+            \n             \"powf32\" => {\n                 // FIXME: Using host floats.\n                 let f = f32::from_bits(this.read_scalar(args[0])?.to_u32()?);\n@@ -459,12 +279,177 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 this.write_scalar(Scalar::from_u64(f.powi(i).to_bits()), dest)?;\n             }\n \n-            \"size_of_val\" => {\n-                let mplace = this.deref_operand(args[0])?;\n-                let (size, _) = this\n-                    .size_and_align_of_mplace(mplace)?\n-                    .expect(\"size_of_val called on extern type\");\n-                this.write_scalar(Scalar::from_machine_usize(size.bytes(), this), dest)?;\n+            // Atomic operations\n+            #[rustfmt::skip]\n+            | \"atomic_load\"\n+            | \"atomic_load_relaxed\"\n+            | \"atomic_load_acq\"\n+            => {\n+                let place = this.deref_operand(args[0])?;\n+                let val = this.read_scalar(place.into())?; // make sure it fits into a scalar; otherwise it cannot be atomic\n+\n+                // Check alignment requirements. Atomics must always be aligned to their size,\n+                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+                // be 8-aligned).\n+                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n+\n+                this.write_scalar(val, dest)?;\n+            }\n+\n+            #[rustfmt::skip]\n+            | \"atomic_store\"\n+            | \"atomic_store_relaxed\"\n+            | \"atomic_store_rel\"\n+            => {\n+                let place = this.deref_operand(args[0])?;\n+                let val = this.read_scalar(args[1])?; // make sure it fits into a scalar; otherwise it cannot be atomic\n+\n+                // Check alignment requirements. Atomics must always be aligned to their size,\n+                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+                // be 8-aligned).\n+                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n+\n+                this.write_scalar(val, place.into())?;\n+            }\n+\n+            #[rustfmt::skip]\n+            | \"atomic_fence_acq\"\n+            | \"atomic_fence_rel\"\n+            | \"atomic_fence_acqrel\"\n+            | \"atomic_fence\"\n+            | \"atomic_singlethreadfence_acq\"\n+            | \"atomic_singlethreadfence_rel\"\n+            | \"atomic_singlethreadfence_acqrel\"\n+            | \"atomic_singlethreadfence\"\n+            => {\n+                // we are inherently singlethreaded and singlecored, this is a nop\n+            }\n+\n+            _ if intrinsic_name.starts_with(\"atomic_xchg\") => {\n+                let place = this.deref_operand(args[0])?;\n+                let new = this.read_scalar(args[1])?;\n+                let old = this.read_scalar(place.into())?;\n+\n+                // Check alignment requirements. Atomics must always be aligned to their size,\n+                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+                // be 8-aligned).\n+                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n+\n+                this.write_scalar(old, dest)?; // old value is returned\n+                this.write_scalar(new, place.into())?;\n+            }\n+\n+            _ if intrinsic_name.starts_with(\"atomic_cxchg\") => {\n+                let place = this.deref_operand(args[0])?;\n+                let expect_old = this.read_immediate(args[1])?; // read as immediate for the sake of `binary_op()`\n+                let new = this.read_scalar(args[2])?;\n+                let old = this.read_immediate(place.into())?; // read as immediate for the sake of `binary_op()`\n+\n+                // Check alignment requirements. Atomics must always be aligned to their size,\n+                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+                // be 8-aligned).\n+                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n+\n+                // `binary_op` will bail if either of them is not a scalar.\n+                let eq = this.overflowing_binary_op(mir::BinOp::Eq, old, expect_old)?.0;\n+                let res = Immediate::ScalarPair(old.to_scalar_or_undef(), eq.into());\n+                // Return old value.\n+                this.write_immediate(res, dest)?;\n+                // Update ptr depending on comparison.\n+                if eq.to_bool()? {\n+                    this.write_scalar(new, place.into())?;\n+                }\n+            }\n+\n+            #[rustfmt::skip]\n+            | \"atomic_or\"\n+            | \"atomic_or_acq\"\n+            | \"atomic_or_rel\"\n+            | \"atomic_or_acqrel\"\n+            | \"atomic_or_relaxed\"\n+            | \"atomic_xor\"\n+            | \"atomic_xor_acq\"\n+            | \"atomic_xor_rel\"\n+            | \"atomic_xor_acqrel\"\n+            | \"atomic_xor_relaxed\"\n+            | \"atomic_and\"\n+            | \"atomic_and_acq\"\n+            | \"atomic_and_rel\"\n+            | \"atomic_and_acqrel\"\n+            | \"atomic_and_relaxed\"\n+            | \"atomic_nand\"\n+            | \"atomic_nand_acq\"\n+            | \"atomic_nand_rel\"\n+            | \"atomic_nand_acqrel\"\n+            | \"atomic_nand_relaxed\"\n+            | \"atomic_xadd\"\n+            | \"atomic_xadd_acq\"\n+            | \"atomic_xadd_rel\"\n+            | \"atomic_xadd_acqrel\"\n+            | \"atomic_xadd_relaxed\"\n+            | \"atomic_xsub\"\n+            | \"atomic_xsub_acq\"\n+            | \"atomic_xsub_rel\"\n+            | \"atomic_xsub_acqrel\"\n+            | \"atomic_xsub_relaxed\"\n+            => {\n+                let place = this.deref_operand(args[0])?;\n+                if !place.layout.ty.is_integral() {\n+                    bug!(\"Atomic arithmetic operations only work on integer types\");\n+                }\n+                let rhs = this.read_immediate(args[1])?;\n+                let old = this.read_immediate(place.into())?;\n+\n+                // Check alignment requirements. Atomics must always be aligned to their size,\n+                // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+                // be 8-aligned).\n+                let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+                this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n+\n+                this.write_immediate(*old, dest)?; // old value is returned\n+                let (op, neg) = match intrinsic_name.split('_').nth(1).unwrap() {\n+                    \"or\" => (mir::BinOp::BitOr, false),\n+                    \"xor\" => (mir::BinOp::BitXor, false),\n+                    \"and\" => (mir::BinOp::BitAnd, false),\n+                    \"xadd\" => (mir::BinOp::Add, false),\n+                    \"xsub\" => (mir::BinOp::Sub, false),\n+                    \"nand\" => (mir::BinOp::BitAnd, true),\n+                    _ => bug!(),\n+                };\n+                // Atomics wrap around on overflow.\n+                let val = this.binary_op(op, old, rhs)?;\n+                let val = if neg { this.unary_op(mir::UnOp::Not, val)? } else { val };\n+                this.write_immediate(*val, place.into())?;\n+            }\n+\n+            // Query type information\n+            \"assert_inhabited\" |\n+            \"assert_zero_valid\" |\n+            \"assert_uninit_valid\" => {\n+                let ty = substs.type_at(0);\n+                let layout = this.layout_of(ty)?;\n+                // Abort here because the caller might not be panic safe.\n+                if layout.abi.is_uninhabited() {\n+                    throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"attempted to instantiate uninhabited type `{}`\", ty))))\n+                }\n+                if intrinsic_name == \"assert_zero_valid\" && !layout.might_permit_raw_init(this, /*zero:*/ true).unwrap() {\n+                    throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"attempted to zero-initialize type `{}`, which is invalid\", ty))))\n+                }\n+                if intrinsic_name == \"assert_uninit_valid\" && !layout.might_permit_raw_init(this, /*zero:*/ false).unwrap() {\n+                    throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"attempted to leave type `{}` uninitialized, which is invalid\", ty))))\n+                }\n+            }\n+\n+            \"pref_align_of\" => {\n+                let ty = substs.type_at(0);\n+                let layout = this.layout_of(ty)?;\n+                let align = layout.align.pref.bytes();\n+                let align_val = Scalar::from_machine_usize(align, this);\n+                this.write_scalar(align_val, dest)?;\n             }\n \n             #[rustfmt::skip]\n@@ -478,18 +463,38 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 this.write_scalar(Scalar::from_machine_usize(align.bytes(), this), dest)?;\n             }\n \n-            \"write_bytes\" => {\n-                let ty = substs.type_at(0);\n-                let ty_layout = this.layout_of(ty)?;\n-                let val_byte = this.read_scalar(args[1])?.to_u8()?;\n-                let ptr = this.read_scalar(args[0])?.not_undef()?;\n-                let count = this.read_scalar(args[2])?.to_machine_usize(this)?;\n-                let byte_count = ty_layout.size.checked_mul(count, this)\n-                    .ok_or_else(|| err_ub_format!(\"overflow computing total size of `write_bytes`\"))?;\n-                this.memory\n-                    .write_bytes(ptr, iter::repeat(val_byte).take(byte_count.bytes() as usize))?;\n+            \"size_of_val\" => {\n+                let mplace = this.deref_operand(args[0])?;\n+                let (size, _) = this\n+                    .size_and_align_of_mplace(mplace)?\n+                    .expect(\"size_of_val called on extern type\");\n+                this.write_scalar(Scalar::from_machine_usize(size.bytes(), this), dest)?;\n+            }\n+\n+            // Other\n+            \"assume\" => {\n+                let cond = this.read_scalar(args[0])?.to_bool()?;\n+                if !cond {\n+                    throw_ub_format!(\"`assume` intrinsic called with `false`\");\n+                }\n+            }\n+\n+            \"exact_div\" =>\n+                this.exact_div(this.read_immediate(args[0])?, this.read_immediate(args[1])?, dest)?,\n+\n+            \"forget\" => {}\n+\n+            #[rustfmt::skip]\n+            | \"likely\"\n+            | \"unlikely\"\n+            => {\n+                // These just return their argument\n+                let b = this.read_immediate(args[0])?;\n+                this.write_immediate(*b, dest)?;\n             }\n \n+            \"try\" => return this.handle_try(args, dest, ret),\n+\n             name => throw_unsup_format!(\"unimplemented intrinsic: {}\", name),\n         }\n "}]}