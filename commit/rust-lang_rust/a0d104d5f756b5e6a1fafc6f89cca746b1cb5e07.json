{"sha": "a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "node_id": "C_kwDOAAsO6NoAKGEwZDEwNGQ1Zjc1NmI1ZTZhMWZhZmM2Zjg5Y2NhNzQ2YjFjYjVlMDc", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-11-27T11:18:23Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-11-28T07:53:14Z"}, "message": "refactor scheduling of TLS dtors", "tree": {"sha": "f05104280521313ca4789f05d67054d05fd74d16", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f05104280521313ca4789f05d67054d05fd74d16"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "html_url": "https://github.com/rust-lang/rust/commit/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f8fbc6da3c467b27793c35c6e105053c9d092447", "url": "https://api.github.com/repos/rust-lang/rust/commits/f8fbc6da3c467b27793c35c6e105053c9d092447", "html_url": "https://github.com/rust-lang/rust/commit/f8fbc6da3c467b27793c35c6e105053c9d092447"}], "stats": {"total": 533, "additions": 268, "deletions": 265}, "files": [{"sha": "fde47ed9ff1ec7f8545e39ae27bd7827285ffdd5", "filename": "src/tools/miri/src/concurrency/thread.rs", "status": "modified", "additions": 80, "deletions": 97, "changes": 177, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fconcurrency%2Fthread.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -3,6 +3,7 @@\n use std::cell::RefCell;\n use std::collections::hash_map::Entry;\n use std::num::TryFromIntError;\n+use std::task::Poll;\n use std::time::{Duration, SystemTime};\n \n use log::trace;\n@@ -16,6 +17,7 @@ use rustc_target::spec::abi::Abi;\n \n use crate::concurrency::data_race;\n use crate::concurrency::sync::SynchronizationState;\n+use crate::shims::tls;\n use crate::*;\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq)]\n@@ -24,10 +26,8 @@ pub enum SchedulingAction {\n     ExecuteStep,\n     /// Execute a timeout callback.\n     ExecuteTimeoutCallback,\n-    /// Execute destructors of the active thread.\n-    ExecuteDtors,\n-    /// Stop the program.\n-    Stop,\n+    /// Wait for a bit, until there is a timeout to be called.\n+    Sleep(Duration),\n }\n \n /// Trait for callbacks that can be executed when some event happens, such as after a timeout.\n@@ -41,9 +41,6 @@ type TimeoutCallback<'mir, 'tcx> = Box<dyn MachineCallback<'mir, 'tcx> + 'tcx>;\n #[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n pub struct ThreadId(u32);\n \n-/// The main thread. When it terminates, the whole application terminates.\n-const MAIN_THREAD: ThreadId = ThreadId(0);\n-\n impl ThreadId {\n     pub fn to_u32(self) -> u32 {\n         self.0\n@@ -118,6 +115,12 @@ pub struct Thread<'mir, 'tcx> {\n     /// The virtual call stack.\n     stack: Vec<Frame<'mir, 'tcx, Provenance, FrameData<'tcx>>>,\n \n+    /// The function to call when the stack ran empty, to figure out what to do next.\n+    /// Conceptually, this is the interpreter implementation of the things that happen 'after' the\n+    /// Rust language entry point for this thread returns (usually implemented by the C or OS runtime).\n+    /// (`None` is an error, it means the callback has not been set up yet or is actively running.)\n+    pub(crate) on_stack_empty: Option<StackEmptyCallback<'mir, 'tcx>>,\n+\n     /// The index of the topmost user-relevant frame in `stack`. This field must contain\n     /// the value produced by `get_top_user_relevant_frame`.\n     /// The `None` state here represents\n@@ -137,19 +140,10 @@ pub struct Thread<'mir, 'tcx> {\n     pub(crate) last_error: Option<MPlaceTy<'tcx, Provenance>>,\n }\n \n-impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n-    /// Check if the thread is done executing (no more stack frames). If yes,\n-    /// change the state to terminated and return `true`.\n-    fn check_terminated(&mut self) -> bool {\n-        if self.state == ThreadState::Enabled {\n-            if self.stack.is_empty() {\n-                self.state = ThreadState::Terminated;\n-                return true;\n-            }\n-        }\n-        false\n-    }\n+pub type StackEmptyCallback<'mir, 'tcx> =\n+    Box<dyn FnMut(&mut MiriInterpCx<'mir, 'tcx>) -> InterpResult<'tcx, Poll<()>>>;\n \n+impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n     /// Get the name of the current thread, or `<unnamed>` if it was not set.\n     fn thread_name(&self) -> &[u8] {\n         if let Some(ref thread_name) = self.thread_name { thread_name } else { b\"<unnamed>\" }\n@@ -202,28 +196,21 @@ impl<'mir, 'tcx> std::fmt::Debug for Thread<'mir, 'tcx> {\n     }\n }\n \n-impl<'mir, 'tcx> Default for Thread<'mir, 'tcx> {\n-    fn default() -> Self {\n+impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n+    fn new(name: Option<&str>, on_stack_empty: Option<StackEmptyCallback<'mir, 'tcx>>) -> Self {\n         Self {\n             state: ThreadState::Enabled,\n-            thread_name: None,\n+            thread_name: name.map(|name| Vec::from(name.as_bytes())),\n             stack: Vec::new(),\n             top_user_relevant_frame: None,\n             join_status: ThreadJoinStatus::Joinable,\n             panic_payload: None,\n             last_error: None,\n+            on_stack_empty,\n         }\n     }\n }\n \n-impl<'mir, 'tcx> Thread<'mir, 'tcx> {\n-    fn new(name: &str) -> Self {\n-        let mut thread = Thread::default();\n-        thread.thread_name = Some(Vec::from(name.as_bytes()));\n-        thread\n-    }\n-}\n-\n impl VisitTags for Thread<'_, '_> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n         let Thread {\n@@ -234,6 +221,7 @@ impl VisitTags for Thread<'_, '_> {\n             state: _,\n             thread_name: _,\n             join_status: _,\n+            on_stack_empty: _, // we assume the closure captures no GC-relevant state\n         } = self;\n \n         panic_payload.visit_tags(visit);\n@@ -327,22 +315,6 @@ pub struct ThreadManager<'mir, 'tcx> {\n     timeout_callbacks: FxHashMap<ThreadId, TimeoutCallbackInfo<'mir, 'tcx>>,\n }\n \n-impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n-    fn default() -> Self {\n-        let mut threads = IndexVec::new();\n-        // Create the main thread and add it to the list of threads.\n-        threads.push(Thread::new(\"main\"));\n-        Self {\n-            active_thread: ThreadId::new(0),\n-            threads,\n-            sync: SynchronizationState::default(),\n-            thread_local_alloc_ids: Default::default(),\n-            yield_active_thread: false,\n-            timeout_callbacks: FxHashMap::default(),\n-        }\n-    }\n-}\n-\n impl VisitTags for ThreadManager<'_, '_> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n         let ThreadManager {\n@@ -367,8 +339,28 @@ impl VisitTags for ThreadManager<'_, '_> {\n     }\n }\n \n+impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n+    fn default() -> Self {\n+        let mut threads = IndexVec::new();\n+        // Create the main thread and add it to the list of threads.\n+        threads.push(Thread::new(Some(\"main\"), None));\n+        Self {\n+            active_thread: ThreadId::new(0),\n+            threads,\n+            sync: SynchronizationState::default(),\n+            thread_local_alloc_ids: Default::default(),\n+            yield_active_thread: false,\n+            timeout_callbacks: FxHashMap::default(),\n+        }\n+    }\n+}\n+\n impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n-    pub(crate) fn init(ecx: &mut MiriInterpCx<'mir, 'tcx>) {\n+    pub(crate) fn init(\n+        ecx: &mut MiriInterpCx<'mir, 'tcx>,\n+        on_main_stack_empty: StackEmptyCallback<'mir, 'tcx>,\n+    ) {\n+        ecx.machine.threads.threads[ThreadId::new(0)].on_stack_empty = Some(on_main_stack_empty);\n         if ecx.tcx.sess.target.os.as_ref() != \"windows\" {\n             // The main thread can *not* be joined on except on windows.\n             ecx.machine.threads.threads[ThreadId::new(0)].join_status = ThreadJoinStatus::Detached;\n@@ -411,9 +403,9 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n     }\n \n     /// Create a new thread and returns its id.\n-    fn create_thread(&mut self) -> ThreadId {\n+    fn create_thread(&mut self, on_stack_empty: StackEmptyCallback<'mir, 'tcx>) -> ThreadId {\n         let new_thread_id = ThreadId::new(self.threads.len());\n-        self.threads.push(Default::default());\n+        self.threads.push(Thread::new(None, Some(on_stack_empty)));\n         new_thread_id\n     }\n \n@@ -458,6 +450,7 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n     }\n \n     /// Get a mutable borrow of the currently active thread.\n+    /// (Private for a bit of protection.)\n     fn active_thread_mut(&mut self) -> &mut Thread<'mir, 'tcx> {\n         &mut self.threads[self.active_thread]\n     }\n@@ -669,37 +662,25 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n     /// long as we can and switch only when we have to (the active thread was\n     /// blocked, terminated, or has explicitly asked to be preempted).\n     fn schedule(&mut self, clock: &Clock) -> InterpResult<'tcx, SchedulingAction> {\n-        // Check whether the thread has **just** terminated (`check_terminated`\n-        // checks whether the thread has popped all its stack and if yes, sets\n-        // the thread state to terminated).\n-        if self.threads[self.active_thread].check_terminated() {\n-            return Ok(SchedulingAction::ExecuteDtors);\n-        }\n-        // If we get here again and the thread is *still* terminated, there are no more dtors to run.\n-        if self.threads[MAIN_THREAD].state == ThreadState::Terminated {\n-            // The main thread terminated; stop the program.\n-            // We do *not* run TLS dtors of remaining threads, which seems to match rustc behavior.\n-            return Ok(SchedulingAction::Stop);\n-        }\n         // This thread and the program can keep going.\n         if self.threads[self.active_thread].state == ThreadState::Enabled\n             && !self.yield_active_thread\n         {\n             // The currently active thread is still enabled, just continue with it.\n             return Ok(SchedulingAction::ExecuteStep);\n         }\n-        // The active thread yielded. Let's see if there are any timeouts to take care of. We do\n-        // this *before* running any other thread, to ensure that timeouts \"in the past\" fire before\n-        // any other thread can take an action. This ensures that for `pthread_cond_timedwait`, \"an\n-        // error is returned if [...] the absolute time specified by abstime has already been passed\n-        // at the time of the call\".\n+        // The active thread yielded or got terminated. Let's see if there are any timeouts to take\n+        // care of. We do this *before* running any other thread, to ensure that timeouts \"in the\n+        // past\" fire before any other thread can take an action. This ensures that for\n+        // `pthread_cond_timedwait`, \"an error is returned if [...] the absolute time specified by\n+        // abstime has already been passed at the time of the call\".\n         // <https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_cond_timedwait.html>\n         let potential_sleep_time =\n             self.timeout_callbacks.values().map(|info| info.call_time.get_wait_time(clock)).min();\n         if potential_sleep_time == Some(Duration::new(0, 0)) {\n             return Ok(SchedulingAction::ExecuteTimeoutCallback);\n         }\n-        // No callbacks scheduled, pick a regular thread to execute.\n+        // No callbacks immediately scheduled, pick a regular thread to execute.\n         // The active thread blocked or yielded. So we go search for another enabled thread.\n         // Crucially, we start searching at the current active thread ID, rather than at 0, since we\n         // want to avoid always scheduling threads 0 and 1 without ever making progress in thread 2.\n@@ -730,9 +711,7 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n             // All threads are currently blocked, but we have unexecuted\n             // timeout_callbacks, which may unblock some of the threads. Hence,\n             // sleep until the first callback.\n-\n-            clock.sleep(sleep_time);\n-            Ok(SchedulingAction::ExecuteTimeoutCallback)\n+            Ok(SchedulingAction::Sleep(sleep_time))\n         } else {\n             throw_machine_stop!(TerminationInfo::Deadlock);\n         }\n@@ -773,18 +752,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         }\n     }\n \n+    /// Start a regular (non-main) thread.\n     #[inline]\n-    fn create_thread(&mut self) -> ThreadId {\n-        let this = self.eval_context_mut();\n-        let id = this.machine.threads.create_thread();\n-        if let Some(data_race) = &mut this.machine.data_race {\n-            data_race.thread_created(&this.machine.threads, id);\n-        }\n-        id\n-    }\n-\n-    #[inline]\n-    fn start_thread(\n+    fn start_regular_thread(\n         &mut self,\n         thread: Option<MPlaceTy<'tcx, Provenance>>,\n         start_routine: Pointer<Option<Provenance>>,\n@@ -795,7 +765,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         let this = self.eval_context_mut();\n \n         // Create the new thread\n-        let new_thread_id = this.create_thread();\n+        let new_thread_id = this.machine.threads.create_thread({\n+            let mut state = tls::TlsDtorsState::default();\n+            Box::new(move |m| state.on_stack_empty(m))\n+        });\n+        if let Some(data_race) = &mut this.machine.data_race {\n+            data_race.thread_created(&this.machine.threads, new_thread_id);\n+        }\n \n         // Write the current thread-id, switch to the next thread later\n         // to treat this write operation as occuring on the current thread.\n@@ -888,12 +864,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         this.machine.threads.get_total_thread_count()\n     }\n \n-    #[inline]\n-    fn has_terminated(&self, thread_id: ThreadId) -> bool {\n-        let this = self.eval_context_ref();\n-        this.machine.threads.has_terminated(thread_id)\n-    }\n-\n     #[inline]\n     fn have_all_terminated(&self) -> bool {\n         let this = self.eval_context_ref();\n@@ -943,26 +913,22 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n     where\n         'mir: 'c,\n     {\n-        let this = self.eval_context_ref();\n-        this.machine.threads.get_thread_name(thread)\n+        self.eval_context_ref().machine.threads.get_thread_name(thread)\n     }\n \n     #[inline]\n     fn block_thread(&mut self, thread: ThreadId) {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.block_thread(thread);\n+        self.eval_context_mut().machine.threads.block_thread(thread);\n     }\n \n     #[inline]\n     fn unblock_thread(&mut self, thread: ThreadId) {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.unblock_thread(thread);\n+        self.eval_context_mut().machine.threads.unblock_thread(thread);\n     }\n \n     #[inline]\n     fn yield_active_thread(&mut self) {\n-        let this = self.eval_context_mut();\n-        this.machine.threads.yield_active_thread();\n+        self.eval_context_mut().machine.threads.yield_active_thread();\n     }\n \n     #[inline]\n@@ -1024,6 +990,19 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n         Ok(())\n     }\n \n+    #[inline]\n+    fn run_on_stack_empty(&mut self) -> InterpResult<'tcx, Poll<()>> {\n+        let this = self.eval_context_mut();\n+        let mut callback = this\n+            .active_thread_mut()\n+            .on_stack_empty\n+            .take()\n+            .expect(\"`on_stack_empty` not set up, or already running\");\n+        let res = callback(this)?;\n+        this.active_thread_mut().on_stack_empty = Some(callback);\n+        Ok(res)\n+    }\n+\n     /// Decide which action to take next and on which thread.\n     #[inline]\n     fn schedule(&mut self) -> InterpResult<'tcx, SchedulingAction> {\n@@ -1034,10 +1013,14 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n     /// Handles thread termination of the active thread: wakes up threads joining on this one,\n     /// and deallocated thread-local statics.\n     ///\n-    /// This is called from `tls.rs` after handling the TLS dtors.\n+    /// This is called by the eval loop when a thread's on_stack_empty returns `Ready`.\n     #[inline]\n     fn thread_terminated(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n+        let thread = this.active_thread_mut();\n+        assert!(thread.stack.is_empty(), \"only threads with an empty stack can be terminated\");\n+        thread.state = ThreadState::Terminated;\n+\n         for ptr in this.machine.threads.thread_terminated(this.machine.data_race.as_mut()) {\n             this.deallocate_ptr(ptr.into(), None, MiriMemoryKind::Tls.into())?;\n         }"}, {"sha": "5cd0a0eeb58c15d191100e85f32366b093173d9b", "filename": "src/tools/miri/src/diagnostics.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fdiagnostics.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -11,7 +11,10 @@ use crate::*;\n \n /// Details of premature program termination.\n pub enum TerminationInfo {\n-    Exit(i64),\n+    Exit {\n+        code: i64,\n+        leak_check: bool,\n+    },\n     Abort(String),\n     UnsupportedInIsolation(String),\n     StackedBorrowsUb {\n@@ -38,7 +41,7 @@ impl fmt::Display for TerminationInfo {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         use TerminationInfo::*;\n         match self {\n-            Exit(code) => write!(f, \"the evaluated program completed with exit code {code}\"),\n+            Exit { code, .. } => write!(f, \"the evaluated program completed with exit code {code}\"),\n             Abort(msg) => write!(f, \"{msg}\"),\n             UnsupportedInIsolation(msg) => write!(f, \"{msg}\"),\n             Int2PtrWithStrictProvenance =>\n@@ -148,11 +151,11 @@ fn prune_stacktrace<'tcx>(\n \n /// Emit a custom diagnostic without going through the miri-engine machinery.\n ///\n-/// Returns `Some` if this was regular program termination with a given exit code, `None` otherwise.\n+/// Returns `Some` if this was regular program termination with a given exit code and a `bool` indicating whether a leak check should happen; `None` otherwise.\n pub fn report_error<'tcx, 'mir>(\n     ecx: &InterpCx<'mir, 'tcx, MiriMachine<'mir, 'tcx>>,\n     e: InterpErrorInfo<'tcx>,\n-) -> Option<i64> {\n+) -> Option<(i64, bool)> {\n     use InterpError::*;\n \n     let mut msg = vec![];\n@@ -161,7 +164,7 @@ pub fn report_error<'tcx, 'mir>(\n         let info = info.downcast_ref::<TerminationInfo>().expect(\"invalid MachineStop payload\");\n         use TerminationInfo::*;\n         let title = match info {\n-            Exit(code) => return Some(*code),\n+            Exit { code, leak_check } => return Some((*code, *leak_check)),\n             Abort(_) => Some(\"abnormal termination\"),\n             UnsupportedInIsolation(_) | Int2PtrWithStrictProvenance =>\n                 Some(\"unsupported operation\"),"}, {"sha": "b5d4282094110c096e64cb2d35533de8726af5d8", "filename": "src/tools/miri/src/eval.rs", "status": "modified", "additions": 89, "deletions": 45, "changes": 134, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Feval.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -4,6 +4,7 @@ use std::ffi::{OsStr, OsString};\n use std::iter;\n use std::panic::{self, AssertUnwindSafe};\n use std::path::PathBuf;\n+use std::task::Poll;\n use std::thread;\n \n use log::info;\n@@ -20,6 +21,7 @@ use rustc_target::spec::abi::Abi;\n \n use rustc_session::config::EntryFnType;\n \n+use crate::shims::tls;\n use crate::*;\n \n #[derive(Copy, Clone, Debug, PartialEq)]\n@@ -172,17 +174,57 @@ impl Default for MiriConfig {\n     }\n }\n \n-/// Returns a freshly created `InterpCx`, along with an `MPlaceTy` representing\n-/// the location where the return value of the `start` function will be\n-/// written to.\n+/// The state of the main thread. Implementation detail of `on_main_stack_empty`.\n+#[derive(Default, Debug)]\n+enum MainThreadState {\n+    #[default]\n+    Running,\n+    TlsDtors(tls::TlsDtorsState),\n+}\n+\n+impl MainThreadState {\n+    fn on_main_stack_empty<'tcx>(\n+        &mut self,\n+        this: &mut MiriInterpCx<'_, 'tcx>,\n+    ) -> InterpResult<'tcx, Poll<()>> {\n+        use MainThreadState::*;\n+        match self {\n+            Running => {\n+                *self = TlsDtors(Default::default());\n+            }\n+            TlsDtors(state) =>\n+                match state.on_stack_empty(this)? {\n+                    Poll::Pending => {} // just keep going\n+                    Poll::Ready(()) => {\n+                        // Need to call `thread_terminated` ourselves since we are not going to\n+                        // return to the scheduler loop.\n+                        this.thread_terminated()?;\n+                        // Raise exception to stop program execution.\n+                        let ret_place = MPlaceTy::from_aligned_ptr(\n+                            this.machine.main_fn_ret_place.unwrap().ptr,\n+                            this.machine.layouts.isize,\n+                        );\n+                        let exit_code =\n+                            this.read_scalar(&ret_place.into())?.to_machine_isize(this)?;\n+                        throw_machine_stop!(TerminationInfo::Exit {\n+                            code: exit_code,\n+                            leak_check: true\n+                        });\n+                    }\n+                },\n+        }\n+        Ok(Poll::Pending)\n+    }\n+}\n+\n+/// Returns a freshly created `InterpCx`.\n /// Public because this is also used by `priroda`.\n pub fn create_ecx<'mir, 'tcx: 'mir>(\n     tcx: TyCtxt<'tcx>,\n     entry_id: DefId,\n     entry_type: EntryFnType,\n     config: &MiriConfig,\n-) -> InterpResult<'tcx, (InterpCx<'mir, 'tcx, MiriMachine<'mir, 'tcx>>, MPlaceTy<'tcx, Provenance>)>\n-{\n+) -> InterpResult<'tcx, InterpCx<'mir, 'tcx, MiriMachine<'mir, 'tcx>>> {\n     let param_env = ty::ParamEnv::reveal_all();\n     let layout_cx = LayoutCx { tcx, param_env };\n     let mut ecx = InterpCx::new(\n@@ -193,7 +235,11 @@ pub fn create_ecx<'mir, 'tcx: 'mir>(\n     );\n \n     // Some parts of initialization require a full `InterpCx`.\n-    MiriMachine::late_init(&mut ecx, config)?;\n+    MiriMachine::late_init(&mut ecx, config, {\n+        let mut state = MainThreadState::default();\n+        // Cannot capture anything GC-relevant here.\n+        Box::new(move |m| state.on_main_stack_empty(m))\n+    })?;\n \n     // Make sure we have MIR. We check MIR for some stable monomorphic function in libcore.\n     let sentinel = ecx.try_resolve_path(&[\"core\", \"ascii\", \"escape_default\"], Namespace::ValueNS);\n@@ -274,6 +320,7 @@ pub fn create_ecx<'mir, 'tcx: 'mir>(\n \n     // Return place (in static memory so that it does not count as leak).\n     let ret_place = ecx.allocate(ecx.machine.layouts.isize, MiriMemoryKind::Machine.into())?;\n+    ecx.machine.main_fn_ret_place = Some(*ret_place);\n     // Call start function.\n \n     match entry_type {\n@@ -321,7 +368,7 @@ pub fn create_ecx<'mir, 'tcx: 'mir>(\n         }\n     }\n \n-    Ok((ecx, ret_place))\n+    Ok(ecx)\n }\n \n /// Evaluates the entry function specified by `entry_id`.\n@@ -337,7 +384,7 @@ pub fn eval_entry<'tcx>(\n     // Copy setting before we move `config`.\n     let ignore_leaks = config.ignore_leaks;\n \n-    let (mut ecx, ret_place) = match create_ecx(tcx, entry_id, entry_type, &config) {\n+    let mut ecx = match create_ecx(tcx, entry_id, entry_type, &config) {\n         Ok(v) => v,\n         Err(err) => {\n             err.print_backtrace();\n@@ -346,34 +393,37 @@ pub fn eval_entry<'tcx>(\n     };\n \n     // Perform the main execution.\n-    let res: thread::Result<InterpResult<'_, i64>> = panic::catch_unwind(AssertUnwindSafe(|| {\n-        // Main loop.\n+    let res: thread::Result<InterpResult<'_, !>> = panic::catch_unwind(AssertUnwindSafe(|| {\n+        // Main loop. Goes on forever until an interrupt is triggered (represented as `InterpError`).\n         loop {\n             match ecx.schedule()? {\n                 SchedulingAction::ExecuteStep => {\n-                    assert!(ecx.step()?, \"a terminated thread was scheduled for execution\");\n+                    if !ecx.step()? {\n+                        // See if this thread can do something else.\n+                        match ecx.run_on_stack_empty()? {\n+                            Poll::Pending => {} // keep going\n+                            Poll::Ready(()) => ecx.thread_terminated()?,\n+                        }\n+                    }\n                 }\n                 SchedulingAction::ExecuteTimeoutCallback => {\n                     ecx.run_timeout_callback()?;\n                 }\n-                SchedulingAction::ExecuteDtors => {\n-                    // This will either enable the thread again (so we go back\n-                    // to `ExecuteStep`), or determine that this thread is done\n-                    // for good.\n-                    ecx.schedule_next_tls_dtor_for_active_thread()?;\n-                }\n-                SchedulingAction::Stop => {\n-                    break;\n+                SchedulingAction::Sleep(duration) => {\n+                    ecx.machine.clock.sleep(duration);\n                 }\n             }\n         }\n-        let return_code = ecx.read_scalar(&ret_place.into())?.to_machine_isize(&ecx)?;\n-        Ok(return_code)\n     }));\n     let res = res.unwrap_or_else(|panic_payload| {\n         ecx.handle_ice();\n         panic::resume_unwind(panic_payload)\n     });\n+    let res = match res {\n+        Err(res) => res,\n+        // `Ok` can never happen\n+        Ok(never) => match never {},\n+    };\n \n     // Machine cleanup. Only do this if all threads have terminated; threads that are still running\n     // might cause Stacked Borrows errors (https://github.com/rust-lang/miri/issues/2396).\n@@ -386,32 +436,26 @@ pub fn eval_entry<'tcx>(\n     }\n \n     // Process the result.\n-    match res {\n-        Ok(return_code) => {\n-            if !ignore_leaks {\n-                // Check for thread leaks.\n-                if !ecx.have_all_terminated() {\n-                    tcx.sess.err(\n-                        \"the main thread terminated without waiting for all remaining threads\",\n-                    );\n-                    tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n-                    return None;\n-                }\n-                // Check for memory leaks.\n-                info!(\"Additonal static roots: {:?}\", ecx.machine.static_roots);\n-                let leaks = ecx.leak_report(&ecx.machine.static_roots);\n-                if leaks != 0 {\n-                    tcx.sess.err(\"the evaluated program leaked memory\");\n-                    tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n-                    // Ignore the provided return code - let the reported error\n-                    // determine the return code.\n-                    return None;\n-                }\n-            }\n-            Some(return_code)\n+    let (return_code, leak_check) = report_error(&ecx, res)?;\n+    if leak_check && !ignore_leaks {\n+        // Check for thread leaks.\n+        if !ecx.have_all_terminated() {\n+            tcx.sess.err(\"the main thread terminated without waiting for all remaining threads\");\n+            tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n+            return None;\n+        }\n+        // Check for memory leaks.\n+        info!(\"Additonal static roots: {:?}\", ecx.machine.static_roots);\n+        let leaks = ecx.leak_report(&ecx.machine.static_roots);\n+        if leaks != 0 {\n+            tcx.sess.err(\"the evaluated program leaked memory\");\n+            tcx.sess.note_without_error(\"pass `-Zmiri-ignore-leaks` to disable this check\");\n+            // Ignore the provided return code - let the reported error\n+            // determine the return code.\n+            return None;\n         }\n-        Err(e) => report_error(&ecx, e),\n     }\n+    Some(return_code)\n }\n \n /// Turns an array of arguments into a Windows command line string."}, {"sha": "13a8874272a0df42a5b04dded3caa922d3c40c4e", "filename": "src/tools/miri/src/lib.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Flib.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -81,15 +81,18 @@ pub use crate::shims::intrinsics::EvalContextExt as _;\n pub use crate::shims::os_str::EvalContextExt as _;\n pub use crate::shims::panic::{CatchUnwindData, EvalContextExt as _};\n pub use crate::shims::time::EvalContextExt as _;\n-pub use crate::shims::tls::{EvalContextExt as _, TlsData};\n+pub use crate::shims::tls::TlsData;\n pub use crate::shims::EvalContextExt as _;\n \n pub use crate::clock::{Clock, Instant};\n pub use crate::concurrency::{\n     data_race::{AtomicFenceOrd, AtomicReadOrd, AtomicRwOrd, AtomicWriteOrd, EvalContextExt as _},\n     init_once::{EvalContextExt as _, InitOnceId},\n     sync::{CondvarId, EvalContextExt as _, MutexId, RwLockId, SyncId},\n-    thread::{EvalContextExt as _, SchedulingAction, ThreadId, ThreadManager, ThreadState, Time},\n+    thread::{\n+        EvalContextExt as _, SchedulingAction, StackEmptyCallback, ThreadId, ThreadManager,\n+        ThreadState, Time,\n+    },\n };\n pub use crate::diagnostics::{\n     report_error, EvalContextExt as _, NonHaltingDiagnostic, TerminationInfo,"}, {"sha": "df1b5064a9cf5093f6ed690241fa9799817a8d38", "filename": "src/tools/miri/src/machine.rs", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fmachine.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -363,6 +363,9 @@ pub struct MiriMachine<'mir, 'tcx> {\n     /// Miri does not expose env vars from the host to the emulated program.\n     pub(crate) env_vars: EnvVars<'tcx>,\n \n+    /// Return place of the main function.\n+    pub(crate) main_fn_ret_place: Option<MemPlace<Provenance>>,\n+\n     /// Program arguments (`Option` because we can only initialize them after creating the ecx).\n     /// These are *pointers* to argc/argv because macOS.\n     /// We also need the full command line as one string because of Windows.\n@@ -492,6 +495,7 @@ impl<'mir, 'tcx> MiriMachine<'mir, 'tcx> {\n             intptrcast: RefCell::new(intptrcast::GlobalStateInner::new(config)),\n             // `env_vars` depends on a full interpreter so we cannot properly initialize it yet.\n             env_vars: EnvVars::default(),\n+            main_fn_ret_place: None,\n             argc: None,\n             argv: None,\n             cmd_line: None,\n@@ -556,10 +560,11 @@ impl<'mir, 'tcx> MiriMachine<'mir, 'tcx> {\n     pub(crate) fn late_init(\n         this: &mut MiriInterpCx<'mir, 'tcx>,\n         config: &MiriConfig,\n+        on_main_stack_empty: StackEmptyCallback<'mir, 'tcx>,\n     ) -> InterpResult<'tcx> {\n         EnvVars::init(this, config)?;\n         MiriMachine::init_extern_statics(this)?;\n-        ThreadManager::init(this);\n+        ThreadManager::init(this, on_main_stack_empty);\n         Ok(())\n     }\n \n@@ -657,6 +662,7 @@ impl VisitTags for MiriMachine<'_, '_> {\n             threads,\n             tls,\n             env_vars,\n+            main_fn_ret_place,\n             argc,\n             argv,\n             cmd_line,\n@@ -702,6 +708,7 @@ impl VisitTags for MiriMachine<'_, '_> {\n         data_race.visit_tags(visit);\n         stacked_borrows.visit_tags(visit);\n         intptrcast.visit_tags(visit);\n+        main_fn_ret_place.visit_tags(visit);\n         argc.visit_tags(visit);\n         argv.visit_tags(visit);\n         cmd_line.visit_tags(visit);"}, {"sha": "f72521f64adaf0b45c4ed3e4daa4562f05fd58d4", "filename": "src/tools/miri/src/shims/foreign_items.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fforeign_items.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fforeign_items.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fforeign_items.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -286,7 +286,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n                         let [code] = this.check_shim(abi, exp_abi, link_name, args)?;\n                         // it's really u32 for ExitProcess, but we have to put it into the `Exit` variant anyway\n                         let code = this.read_scalar(code)?.to_i32()?;\n-                        throw_machine_stop!(TerminationInfo::Exit(code.into()));\n+                        throw_machine_stop!(TerminationInfo::Exit { code: code.into(), leak_check: false });\n                     }\n                     \"abort\" => {\n                         let [] = this.check_shim(abi, Abi::C { unwind: false }, link_name, args)?;"}, {"sha": "65978c9774f516493f97ef17ab19410720c8ca0c", "filename": "src/tools/miri/src/shims/tls.rs", "status": "modified", "additions": 75, "deletions": 112, "changes": 187, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Ftls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Ftls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Ftls.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -1,12 +1,11 @@\n //! Implement thread-local storage.\n \n use std::collections::btree_map::Entry as BTreeEntry;\n-use std::collections::hash_map::Entry as HashMapEntry;\n use std::collections::BTreeMap;\n+use std::task::Poll;\n \n use log::trace;\n \n-use rustc_data_structures::fx::FxHashMap;\n use rustc_middle::ty;\n use rustc_target::abi::{HasDataLayout, Size};\n use rustc_target::spec::abi::Abi;\n@@ -23,12 +22,12 @@ pub struct TlsEntry<'tcx> {\n     dtor: Option<ty::Instance<'tcx>>,\n }\n \n-#[derive(Clone, Debug)]\n-struct RunningDtorsState {\n+#[derive(Default, Debug)]\n+struct RunningDtorState {\n     /// The last TlsKey used to retrieve a TLS destructor. `None` means that we\n     /// have not tried to retrieve a TLS destructor yet or that we already tried\n     /// all keys.\n-    last_dtor_key: Option<TlsKey>,\n+    last_key: Option<TlsKey>,\n }\n \n #[derive(Debug)]\n@@ -42,11 +41,6 @@ pub struct TlsData<'tcx> {\n     /// A single per thread destructor of the thread local storage (that's how\n     /// things work on macOS) with a data argument.\n     macos_thread_dtors: BTreeMap<ThreadId, (ty::Instance<'tcx>, Scalar<Provenance>)>,\n-\n-    /// State for currently running TLS dtors. If this map contains a key for a\n-    /// specific thread, it means that we are in the \"destruct\" phase, during\n-    /// which some operations are UB.\n-    dtors_running: FxHashMap<ThreadId, RunningDtorsState>,\n }\n \n impl<'tcx> Default for TlsData<'tcx> {\n@@ -55,7 +49,6 @@ impl<'tcx> Default for TlsData<'tcx> {\n             next_key: 1, // start with 1 as we must not use 0 on Windows\n             keys: Default::default(),\n             macos_thread_dtors: Default::default(),\n-            dtors_running: Default::default(),\n         }\n     }\n }\n@@ -143,12 +136,6 @@ impl<'tcx> TlsData<'tcx> {\n         dtor: ty::Instance<'tcx>,\n         data: Scalar<Provenance>,\n     ) -> InterpResult<'tcx> {\n-        if self.dtors_running.contains_key(&thread) {\n-            // UB, according to libstd docs.\n-            throw_ub_format!(\n-                \"setting thread's local storage destructor while destructors are already running\"\n-            );\n-        }\n         if self.macos_thread_dtors.insert(thread, (dtor, data)).is_some() {\n             throw_unsup_format!(\n                 \"setting more than one thread local storage destructor for the same thread is not supported\"\n@@ -211,21 +198,6 @@ impl<'tcx> TlsData<'tcx> {\n         None\n     }\n \n-    /// Set that dtors are running for `thread`. It is guaranteed not to change\n-    /// the existing values stored in `dtors_running` for this thread. Returns\n-    /// `true` if dtors for `thread` are already running.\n-    fn set_dtors_running_for_thread(&mut self, thread: ThreadId) -> bool {\n-        match self.dtors_running.entry(thread) {\n-            HashMapEntry::Occupied(_) => true,\n-            HashMapEntry::Vacant(entry) => {\n-                // We cannot just do `self.dtors_running.insert` because that\n-                // would overwrite `last_dtor_key` with `None`.\n-                entry.insert(RunningDtorsState { last_dtor_key: None });\n-                false\n-            }\n-        }\n-    }\n-\n     /// Delete all TLS entries for the given thread. This function should be\n     /// called after all TLS destructors have already finished.\n     fn delete_all_thread_tls(&mut self, thread_id: ThreadId) {\n@@ -237,7 +209,7 @@ impl<'tcx> TlsData<'tcx> {\n \n impl VisitTags for TlsData<'_> {\n     fn visit_tags(&self, visit: &mut dyn FnMut(SbTag)) {\n-        let TlsData { keys, macos_thread_dtors, next_key: _, dtors_running: _ } = self;\n+        let TlsData { keys, macos_thread_dtors, next_key: _ } = self;\n \n         for scalar in keys.values().flat_map(|v| v.data.values()) {\n             scalar.visit_tags(visit);\n@@ -248,13 +220,71 @@ impl VisitTags for TlsData<'_> {\n     }\n }\n \n+#[derive(Debug, Default)]\n+pub struct TlsDtorsState(TlsDtorsStatePriv);\n+\n+#[derive(Debug, Default)]\n+enum TlsDtorsStatePriv {\n+    #[default]\n+    Init,\n+    PthreadDtors(RunningDtorState),\n+    Done,\n+}\n+\n+impl TlsDtorsState {\n+    pub fn on_stack_empty<'tcx>(\n+        &mut self,\n+        this: &mut MiriInterpCx<'_, 'tcx>,\n+    ) -> InterpResult<'tcx, Poll<()>> {\n+        use TlsDtorsStatePriv::*;\n+        match &mut self.0 {\n+            Init => {\n+                match this.tcx.sess.target.os.as_ref() {\n+                    \"linux\" => {\n+                        // Run the pthread dtors.\n+                        self.0 = PthreadDtors(Default::default());\n+                    }\n+                    \"macos\" => {\n+                        // The macOS thread wide destructor runs \"before any TLS slots get\n+                        // freed\", so do that first.\n+                        this.schedule_macos_tls_dtor()?;\n+                        // When the stack is empty again, go on with the pthread dtors.\n+                        self.0 = PthreadDtors(Default::default());\n+                    }\n+                    \"windows\" => {\n+                        // Run the special magic hook.\n+                        this.schedule_windows_tls_dtors()?;\n+                        // And move to the final state.\n+                        self.0 = Done;\n+                    }\n+                    _ => {\n+                        // No TLS support for this platform, directly move to final state.\n+                        self.0 = Done;\n+                    }\n+                }\n+            }\n+            PthreadDtors(state) => {\n+                match this.schedule_next_pthread_tls_dtor(state)? {\n+                    Poll::Pending => {} // just keep going\n+                    Poll::Ready(()) => self.0 = Done,\n+                }\n+            }\n+            Done => {\n+                this.machine.tls.delete_all_thread_tls(this.get_active_thread());\n+                return Ok(Poll::Ready(()));\n+            }\n+        }\n+\n+        Ok(Poll::Pending)\n+    }\n+}\n+\n impl<'mir, 'tcx: 'mir> EvalContextPrivExt<'mir, 'tcx> for crate::MiriInterpCx<'mir, 'tcx> {}\n trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n     /// Schedule TLS destructors for Windows.\n     /// On windows, TLS destructors are managed by std.\n     fn schedule_windows_tls_dtors(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        let active_thread = this.get_active_thread();\n \n         // Windows has a special magic linker section that is run on certain events.\n         // Instead of searching for that section and supporting arbitrary hooks in there\n@@ -284,16 +314,12 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n             None,\n             StackPopCleanup::Root { cleanup: true },\n         )?;\n-\n-        this.enable_thread(active_thread);\n         Ok(())\n     }\n \n     /// Schedule the MacOS thread destructor of the thread local storage to be\n-    /// executed. Returns `true` if scheduled.\n-    ///\n-    /// Note: It is safe to call this function also on other Unixes.\n-    fn schedule_macos_tls_dtor(&mut self) -> InterpResult<'tcx, bool> {\n+    /// executed.\n+    fn schedule_macos_tls_dtor(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         let thread_id = this.get_active_thread();\n         if let Some((instance, data)) = this.machine.tls.macos_thread_dtors.remove(&thread_id) {\n@@ -306,35 +332,27 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n                 None,\n                 StackPopCleanup::Root { cleanup: true },\n             )?;\n-\n-            // Enable the thread so that it steps through the destructor which\n-            // we just scheduled. Since we deleted the destructor, it is\n-            // guaranteed that we will schedule it again. The `dtors_running`\n-            // flag will prevent the code from adding the destructor again.\n-            this.enable_thread(thread_id);\n-            Ok(true)\n-        } else {\n-            Ok(false)\n         }\n+        Ok(())\n     }\n \n     /// Schedule a pthread TLS destructor. Returns `true` if found\n     /// a destructor to schedule, and `false` otherwise.\n-    fn schedule_next_pthread_tls_dtor(&mut self) -> InterpResult<'tcx, bool> {\n+    fn schedule_next_pthread_tls_dtor(\n+        &mut self,\n+        state: &mut RunningDtorState,\n+    ) -> InterpResult<'tcx, Poll<()>> {\n         let this = self.eval_context_mut();\n         let active_thread = this.get_active_thread();\n \n-        assert!(this.has_terminated(active_thread), \"running TLS dtors for non-terminated thread\");\n         // Fetch next dtor after `key`.\n-        let last_key = this.machine.tls.dtors_running[&active_thread].last_dtor_key;\n-        let dtor = match this.machine.tls.fetch_tls_dtor(last_key, active_thread) {\n+        let dtor = match this.machine.tls.fetch_tls_dtor(state.last_key, active_thread) {\n             dtor @ Some(_) => dtor,\n             // We ran each dtor once, start over from the beginning.\n             None => this.machine.tls.fetch_tls_dtor(None, active_thread),\n         };\n         if let Some((instance, ptr, key)) = dtor {\n-            this.machine.tls.dtors_running.get_mut(&active_thread).unwrap().last_dtor_key =\n-                Some(key);\n+            state.last_key = Some(key);\n             trace!(\"Running TLS dtor {:?} on {:?} at {:?}\", instance, ptr, active_thread);\n             assert!(\n                 !ptr.to_machine_usize(this).unwrap() != 0,\n@@ -349,64 +367,9 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n                 StackPopCleanup::Root { cleanup: true },\n             )?;\n \n-            this.enable_thread(active_thread);\n-            return Ok(true);\n+            return Ok(Poll::Pending);\n         }\n-        this.machine.tls.dtors_running.get_mut(&active_thread).unwrap().last_dtor_key = None;\n-\n-        Ok(false)\n-    }\n-}\n \n-impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriInterpCx<'mir, 'tcx> {}\n-pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n-    /// Schedule an active thread's TLS destructor to run on the active thread.\n-    /// Note that this function does not run the destructors itself, it just\n-    /// schedules them one by one each time it is called and reenables the\n-    /// thread so that it can be executed normally by the main execution loop.\n-    ///\n-    /// Note: we consistently run TLS destructors for all threads, including the\n-    /// main thread. However, it is not clear that we should run the TLS\n-    /// destructors for the main thread. See issue:\n-    /// <https://github.com/rust-lang/rust/issues/28129>.\n-    fn schedule_next_tls_dtor_for_active_thread(&mut self) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-        let active_thread = this.get_active_thread();\n-        trace!(\"schedule_next_tls_dtor_for_active_thread on thread {:?}\", active_thread);\n-\n-        if !this.machine.tls.set_dtors_running_for_thread(active_thread) {\n-            // This is the first time we got asked to schedule a destructor. The\n-            // Windows schedule destructor function must be called exactly once,\n-            // this is why it is in this block.\n-            if this.tcx.sess.target.os == \"windows\" {\n-                // On Windows, we signal that the thread quit by starting the\n-                // relevant function, reenabling the thread, and going back to\n-                // the scheduler.\n-                this.schedule_windows_tls_dtors()?;\n-                return Ok(());\n-            }\n-        }\n-        // The remaining dtors make some progress each time around the scheduler loop,\n-        // until they return `false` to indicate that they are done.\n-\n-        // The macOS thread wide destructor runs \"before any TLS slots get\n-        // freed\", so do that first.\n-        if this.schedule_macos_tls_dtor()? {\n-            // We have scheduled a MacOS dtor to run on the thread. Execute it\n-            // to completion and come back here. Scheduling a destructor\n-            // destroys it, so we will not enter this branch again.\n-            return Ok(());\n-        }\n-        if this.schedule_next_pthread_tls_dtor()? {\n-            // We have scheduled a pthread destructor and removed it from the\n-            // destructors list. Run it to completion and come back here.\n-            return Ok(());\n-        }\n-\n-        // All dtors done!\n-        this.machine.tls.delete_all_thread_tls(active_thread);\n-        this.thread_terminated()?;\n-\n-        Ok(())\n+        Ok(Poll::Ready(()))\n     }\n }"}, {"sha": "5b9dc90f0f0060c63524e4297e83aec4d8301532", "filename": "src/tools/miri/src/shims/unix/thread.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Funix%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Funix%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Funix%2Fthread.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -19,7 +19,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n \n         let func_arg = this.read_immediate(arg)?;\n \n-        this.start_thread(\n+        this.start_regular_thread(\n             Some(thread_info_place),\n             start_routine,\n             Abi::C { unwind: false },"}, {"sha": "25a5194caa096540d997df4c13dfe33c42ca9464", "filename": "src/tools/miri/src/shims/windows/thread.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fwindows%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fwindows%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri%2Fsrc%2Fshims%2Fwindows%2Fthread.rs?ref=a0d104d5f756b5e6a1fafc6f89cca746b1cb5e07", "patch": "@@ -46,7 +46,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriInterpCxExt<'mir, 'tcx> {\n             throw_unsup_format!(\"non-null `lpThreadAttributes` in `CreateThread`\")\n         }\n \n-        this.start_thread(\n+        this.start_regular_thread(\n             thread,\n             start_routine,\n             Abi::System { unwind: false },"}]}