{"sha": "0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjODFiOWRlZWVkODFiZmIyY2Y4MTQyYWY5ZDc0ODMxN2Q1ZDcxYTE=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-02-20T18:50:07Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-02-20T18:50:07Z"}, "message": "route parsing via TokenSource trait", "tree": {"sha": "e9c0a1affabfa444611b762dc721d426e3a5bb56", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e9c0a1affabfa444611b762dc721d426e3a5bb56"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "html_url": "https://github.com/rust-lang/rust/commit/0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3517c175ac537b47dd3e36cc7fb1edd60b02c039", "url": "https://api.github.com/repos/rust-lang/rust/commits/3517c175ac537b47dd3e36cc7fb1edd60b02c039", "html_url": "https://github.com/rust-lang/rust/commit/3517c175ac537b47dd3e36cc7fb1edd60b02c039"}], "stats": {"total": 123, "additions": 59, "deletions": 64}, "files": [{"sha": "813ae494c52d8145f429231ef9dbfd47a32f892c", "filename": "crates/ra_syntax/src/parsing/parser_api.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_api.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_api.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_api.rs?ref=0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "patch": "@@ -17,7 +17,9 @@ use crate::{\n /// tree, but rather a flat stream of events of the form\n /// \"start expression, consume number literal,\n /// finish expression\". See `Event` docs for more.\n-pub(crate) struct Parser<'t>(pub(super) ParserImpl<'t>);\n+pub(crate) struct Parser<'t>(\n+    pub(super) ParserImpl<crate::parsing::parser_impl::input::ParserInput<'t>>,\n+);\n \n impl<'t> Parser<'t> {\n     /// Returns the kind of the current token."}, {"sha": "c0d2b6ec12c8daa015b63e8407e8b2929844e2dc", "filename": "crates/ra_syntax/src/parsing/parser_impl.rs", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl.rs?ref=0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "patch": "@@ -1,5 +1,5 @@\n mod event;\n-mod input;\n+pub(crate) mod input;\n \n use std::cell::Cell;\n \n@@ -11,7 +11,7 @@ use crate::{\n         parser_api::Parser,\n         parser_impl::{\n             event::{Event, EventProcessor},\n-            input::{InputPosition, ParserInput},\n+            input::InputPosition,\n         },\n     },\n };\n@@ -39,6 +39,12 @@ pub(super) trait TreeSink {\n     fn finish(self) -> Self::Tree;\n }\n \n+pub(super) trait TokenSource {\n+    fn token_kind(&self, pos: InputPosition) -> SyntaxKind;\n+    fn is_token_joint_to_next(&self, pos: InputPosition) -> bool;\n+    fn is_keyword(&self, pos: InputPosition, kw: &str) -> bool;\n+}\n+\n /// Parse a sequence of tokens into the representative node tree\n pub(super) fn parse_with<S: TreeSink>(\n     sink: S,\n@@ -48,7 +54,7 @@ pub(super) fn parse_with<S: TreeSink>(\n ) -> S::Tree {\n     let mut events = {\n         let input = input::ParserInput::new(text, tokens);\n-        let parser_impl = ParserImpl::new(&input);\n+        let parser_impl = ParserImpl::new(input);\n         let mut parser_api = Parser(parser_impl);\n         parser(&mut parser_api);\n         parser_api.0.into_events()\n@@ -59,17 +65,17 @@ pub(super) fn parse_with<S: TreeSink>(\n /// Implementation details of `Parser`, extracted\n /// to a separate struct in order not to pollute\n /// the public API of the `Parser`.\n-pub(super) struct ParserImpl<'t> {\n-    parser_input: &'t ParserInput<'t>,\n+pub(super) struct ParserImpl<S> {\n+    token_source: S,\n     pos: InputPosition,\n     events: Vec<Event>,\n     steps: Cell<u32>,\n }\n \n-impl<'t> ParserImpl<'t> {\n-    fn new(inp: &'t ParserInput<'t>) -> ParserImpl<'t> {\n+impl<S: TokenSource> ParserImpl<S> {\n+    fn new(token_source: S) -> ParserImpl<S> {\n         ParserImpl {\n-            parser_input: inp,\n+            token_source,\n             pos: InputPosition::new(),\n             events: Vec::new(),\n             steps: Cell::new(0),\n@@ -82,26 +88,21 @@ impl<'t> ParserImpl<'t> {\n     }\n \n     pub(super) fn current2(&self) -> Option<(SyntaxKind, SyntaxKind)> {\n-        let c1 = self.parser_input.kind(self.pos);\n-        let c2 = self.parser_input.kind(self.pos + 1);\n-        if self.parser_input.token_start_at(self.pos + 1)\n-            == self.parser_input.token_start_at(self.pos) + self.parser_input.token_len(self.pos)\n-        {\n+        let c1 = self.token_source.token_kind(self.pos);\n+        let c2 = self.token_source.token_kind(self.pos + 1);\n+        if self.token_source.is_token_joint_to_next(self.pos) {\n             Some((c1, c2))\n         } else {\n             None\n         }\n     }\n \n     pub(super) fn current3(&self) -> Option<(SyntaxKind, SyntaxKind, SyntaxKind)> {\n-        let c1 = self.parser_input.kind(self.pos);\n-        let c2 = self.parser_input.kind(self.pos + 1);\n-        let c3 = self.parser_input.kind(self.pos + 2);\n-        if self.parser_input.token_start_at(self.pos + 1)\n-            == self.parser_input.token_start_at(self.pos) + self.parser_input.token_len(self.pos)\n-            && self.parser_input.token_start_at(self.pos + 2)\n-                == self.parser_input.token_start_at(self.pos + 1)\n-                    + self.parser_input.token_len(self.pos + 1)\n+        let c1 = self.token_source.token_kind(self.pos);\n+        let c2 = self.token_source.token_kind(self.pos + 1);\n+        let c3 = self.token_source.token_kind(self.pos + 2);\n+        if self.token_source.is_token_joint_to_next(self.pos)\n+            && self.token_source.is_token_joint_to_next(self.pos + 1)\n         {\n             Some((c1, c2, c3))\n         } else {\n@@ -114,12 +115,11 @@ impl<'t> ParserImpl<'t> {\n         let steps = self.steps.get();\n         assert!(steps <= 10_000_000, \"the parser seems stuck\");\n         self.steps.set(steps + 1);\n-\n-        self.parser_input.kind(self.pos + n)\n+        self.token_source.token_kind(self.pos + n)\n     }\n \n-    pub(super) fn at_kw(&self, t: &str) -> bool {\n-        self.parser_input.token_text(self.pos) == t\n+    pub(super) fn at_kw(&self, kw: &str) -> bool {\n+        self.token_source.is_keyword(self.pos, kw)\n     }\n \n     /// Start parsing right behind the last event."}, {"sha": "8ebbd38259f9fbe2f9db90958ae123c2e360c907", "filename": "crates/ra_syntax/src/parsing/parser_impl/input.rs", "status": "modified", "additions": 31, "deletions": 38, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl%2Finput.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c81b9deeed81bfb2cf8142af9d748317d5d71a1/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl%2Finput.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl%2Finput.rs?ref=0c81b9deeed81bfb2cf8142af9d748317d5d71a1", "patch": "@@ -1,10 +1,40 @@\n use crate::{\n     SyntaxKind, SyntaxKind::EOF, TextRange, TextUnit,\n-    parsing::lexer::Token,\n+    parsing::{\n+        parser_impl::TokenSource,\n+        lexer::Token,\n+    },\n };\n \n use std::ops::{Add, AddAssign};\n \n+impl<'t> TokenSource for ParserInput<'t> {\n+    fn token_kind(&self, pos: InputPosition) -> SyntaxKind {\n+        let idx = pos.0 as usize;\n+        if !(idx < self.tokens.len()) {\n+            return EOF;\n+        }\n+        self.tokens[idx].kind\n+    }\n+    fn is_token_joint_to_next(&self, pos: InputPosition) -> bool {\n+        let idx_curr = pos.0 as usize;\n+        let idx_next = pos.0 as usize;\n+        if !(idx_next < self.tokens.len()) {\n+            return true;\n+        }\n+        self.start_offsets[idx_curr] + self.tokens[idx_curr].len == self.start_offsets[idx_next]\n+    }\n+    fn is_keyword(&self, pos: InputPosition, kw: &str) -> bool {\n+        let idx = pos.0 as usize;\n+        if !(idx < self.tokens.len()) {\n+            return false;\n+        }\n+        let range = TextRange::offset_len(self.start_offsets[idx], self.tokens[idx].len);\n+\n+        self.text[range] == *kw\n+    }\n+}\n+\n pub(crate) struct ParserInput<'t> {\n     text: &'t str,\n     /// start position of each token(expect whitespace and comment)\n@@ -41,43 +71,6 @@ impl<'t> ParserInput<'t> {\n \n         ParserInput { text, start_offsets, tokens }\n     }\n-\n-    /// Get the syntax kind of token at given input position.\n-    pub fn kind(&self, pos: InputPosition) -> SyntaxKind {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return EOF;\n-        }\n-        self.tokens[idx].kind\n-    }\n-\n-    /// Get the length of a token at given input position.\n-    pub fn token_len(&self, pos: InputPosition) -> TextUnit {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return 0.into();\n-        }\n-        self.tokens[idx].len\n-    }\n-\n-    /// Get the start position of a taken at given input position.\n-    pub fn token_start_at(&self, pos: InputPosition) -> TextUnit {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return 0.into();\n-        }\n-        self.start_offsets[idx]\n-    }\n-\n-    /// Get the raw text of a token at given input position.\n-    pub fn token_text(&self, pos: InputPosition) -> &'t str {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return \"\";\n-        }\n-        let range = TextRange::offset_len(self.start_offsets[idx], self.tokens[idx].len);\n-        &self.text[range]\n-    }\n }\n \n #[derive(Copy, Clone, Ord, PartialOrd, Eq, PartialEq)]"}]}