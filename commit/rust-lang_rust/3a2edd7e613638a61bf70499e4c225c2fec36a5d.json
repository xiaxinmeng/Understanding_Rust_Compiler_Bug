{"sha": "3a2edd7e613638a61bf70499e4c225c2fec36a5d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjNhMmVkZDdlNjEzNjM4YTYxYmY3MDQ5OWU0YzIyNWMyZmVjMzZhNWQ=", "commit": {"author": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2016-05-06T19:09:31Z"}, "committer": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2016-05-18T14:11:36Z"}, "message": "load/save hashes of metadata\n\nThis commit reorganizes how the persist code treats hashing. The idea is\nthat each crate saves a file containing hashes representing the metadata\nfor each item X. When we see a read from `MetaData(X)`, we can load this\nhash up (if we don't find a file for that crate, we just use the SVH for\nthe entire crate).\n\nTo compute the hash for `MetaData(Y)`, where Y is some local item, we\nexamine all the predecessors of the `MetaData(Y)` node and hash their\nhashes together.", "tree": {"sha": "c90f8d2a327fe22588152103f18ddcb28dd588d7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c90f8d2a327fe22588152103f18ddcb28dd588d7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3a2edd7e613638a61bf70499e4c225c2fec36a5d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3a2edd7e613638a61bf70499e4c225c2fec36a5d", "html_url": "https://github.com/rust-lang/rust/commit/3a2edd7e613638a61bf70499e4c225c2fec36a5d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3a2edd7e613638a61bf70499e4c225c2fec36a5d/comments", "author": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b01919a1443615f2ee78f91515e8f01dc2591177", "url": "https://api.github.com/repos/rust-lang/rust/commits/b01919a1443615f2ee78f91515e8f01dc2591177", "html_url": "https://github.com/rust-lang/rust/commit/b01919a1443615f2ee78f91515e8f01dc2591177"}], "stats": {"total": 341, "additions": 249, "deletions": 92}, "files": [{"sha": "f57ab19a5256e397b1c4baca8e3a7661c0d26d5e", "filename": "src/librustc_incremental/persist/data.rs", "status": "modified", "additions": 35, "deletions": 8, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -11,6 +11,7 @@\n //! The data that we will serialize and deserialize.\n \n use rustc::dep_graph::DepNode;\n+use rustc::hir::def_id::DefIndex;\n \n use super::directory::DefPathIndex;\n \n@@ -34,30 +35,56 @@ pub struct SerializedDepGraph {\n     /// compare them against the hashes we see at that time, which\n     /// will tell us what has changed, either in this crate or in some\n     /// crate that we depend on.\n+    ///\n+    /// Because they will be reloaded, we don't store the DefId (which\n+    /// will be different when we next compile) related to each node,\n+    /// but rather the `DefPathIndex`. This can then be retraced\n+    /// to find the current def-id.\n     pub hashes: Vec<SerializedHash>,\n }\n \n+pub type SerializedEdge = (DepNode<DefPathIndex>, DepNode<DefPathIndex>);\n+\n+#[derive(Debug, RustcEncodable, RustcDecodable)]\n+pub struct SerializedHash {\n+    /// node being hashed; either a Hir or MetaData variant, in\n+    /// practice\n+    pub node: DepNode<DefPathIndex>,\n+\n+    /// the hash itself, computed by `calculate_item_hash`\n+    pub hash: u64,\n+}\n+\n /// Data for use when downstream crates get recompiled.\n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedMetadataHashes {\n     /// For each def-id defined in this crate that appears in the\n     /// metadata, we hash all the inputs that were used when producing\n-    /// the metadata. We save this after compilation is done.  Then,\n+    /// the metadata. We save this after compilation is done. Then,\n     /// when some downstream crate is being recompiled, it can compare\n     /// the hashes we saved against the hashes that it saw from\n     /// before; this will tell it which of the items in this crate\n     /// changed, which in turn implies what items in the downstream\n     /// crate need to be recompiled.\n-    pub hashes: Vec<SerializedHash>,\n+    ///\n+    /// Note that we store the def-ids here. This is because we don't\n+    /// reload this file when we recompile this crate, we will just\n+    /// regenerate it completely with the current hashes and new def-ids.\n+    ///\n+    /// Then downstream creates will load up their\n+    /// `SerializedDepGraph`, which may contain `MetaData(X)` nodes\n+    /// where `X` refers to some item in this crate. That `X` will be\n+    /// a `DefPathIndex` that gets retracted to the current `DefId`\n+    /// (matching the one found in this structure).\n+    pub hashes: Vec<SerializedMetadataHash>,\n }\n \n-pub type SerializedEdge = (DepNode<DefPathIndex>, DepNode<DefPathIndex>);\n-\n+/// The hash for some metadata that (when saving) will be exported\n+/// from this crate, or which (when importing) was exported by an\n+/// upstream crate.\n #[derive(Debug, RustcEncodable, RustcDecodable)]\n-pub struct SerializedHash {\n-    /// node being hashed; either a Hir or MetaData variant, in\n-    /// practice\n-    pub node: DepNode<DefPathIndex>,\n+pub struct SerializedMetadataHash {\n+    pub def_index: DefIndex,\n \n     /// the hash itself, computed by `calculate_item_hash`\n     pub hash: u64,"}, {"sha": "f9e90f393219dcc7d6462d16628a55d576e46004", "filename": "src/librustc_incremental/persist/directory.rs", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fdirectory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fdirectory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdirectory.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -64,7 +64,7 @@ impl RetracedDefIdDirectory {\n \n pub struct DefIdDirectoryBuilder<'a,'tcx:'a> {\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    hash: DefIdMap<Option<DefPathIndex>>,\n+    hash: DefIdMap<DefPathIndex>,\n     directory: DefIdDirectory,\n }\n \n@@ -77,29 +77,22 @@ impl<'a,'tcx> DefIdDirectoryBuilder<'a,'tcx> {\n         }\n     }\n \n-    pub fn add(&mut self, def_id: DefId) -> Option<DefPathIndex> {\n-        if !def_id.is_local() {\n-            // FIXME(#32015) clarify story about cross-crate dep tracking\n-            return None;\n-        }\n-\n+    pub fn add(&mut self, def_id: DefId) -> DefPathIndex {\n+        debug!(\"DefIdDirectoryBuilder: def_id={:?}\", def_id);\n         let tcx = self.tcx;\n         let paths = &mut self.directory.paths;\n         self.hash.entry(def_id)\n                  .or_insert_with(|| {\n                      let def_path = tcx.def_path(def_id);\n-                     if !def_path.is_local() {\n-                         return None;\n-                     }\n                      let index = paths.len() as u32;\n                      paths.push(def_path);\n-                     Some(DefPathIndex { index: index })\n+                     DefPathIndex { index: index }\n                  })\n                  .clone()\n     }\n \n-    pub fn map(&mut self, node: DepNode<DefId>) -> Option<DepNode<DefPathIndex>> {\n-        node.map_def(|&def_id| self.add(def_id))\n+    pub fn map(&mut self, node: DepNode<DefId>) -> DepNode<DefPathIndex> {\n+        node.map_def(|&def_id| Some(self.add(def_id))).unwrap()\n     }\n \n     pub fn into_directory(self) -> DefIdDirectory {"}, {"sha": "c36b9ed0d26a3246eb6f596c0be85408fdc1fa19", "filename": "src/librustc_incremental/persist/hash.rs", "status": "added", "additions": 158, "deletions": 0, "changes": 158, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fhash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fhash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fhash.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -0,0 +1,158 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use calculate_svh::SvhCalculate;\n+use rbml::Error;\n+use rbml::opaque::Decoder;\n+use rustc::dep_graph::DepNode;\n+use rustc::hir::def_id::DefId;\n+use rustc::hir::svh::Svh;\n+use rustc::ty::TyCtxt;\n+use rustc_data_structures::fnv::FnvHashMap;\n+use rustc_serialize::Decodable;\n+use std::io::{ErrorKind, Read};\n+use std::fs::File;\n+use syntax::ast;\n+\n+use super::data::*;\n+use super::util::*;\n+\n+pub struct HashContext<'a, 'tcx: 'a> {\n+    pub tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+    item_metadata_hashes: FnvHashMap<DefId, u64>,\n+    crate_hashes: FnvHashMap<ast::CrateNum, Svh>,\n+}\n+\n+impl<'a, 'tcx> HashContext<'a, 'tcx> {\n+    pub fn new(tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Self {\n+        HashContext {\n+            tcx: tcx,\n+            item_metadata_hashes: FnvHashMap(),\n+            crate_hashes: FnvHashMap(),\n+        }\n+    }\n+\n+    pub fn hash(&mut self, dep_node: DepNode<DefId>) -> Option<u64> {\n+        match dep_node {\n+            // HIR nodes (which always come from our crate) are an input:\n+            DepNode::Hir(def_id) => {\n+                assert!(def_id.is_local());\n+                Some(self.hir_hash(def_id))\n+            }\n+\n+            // MetaData from other crates is an *input* to us.\n+            // MetaData nodes from *our* crates are an *output*; we\n+            // don't hash them, but we do compute a hash for them and\n+            // save it for others to use.\n+            DepNode::MetaData(def_id) if !def_id.is_local() => {\n+                Some(self.metadata_hash(def_id))\n+            }\n+\n+            _ => {\n+                // Other kinds of nodes represent computed by-products\n+                // that we don't hash directly; instead, they should\n+                // have some transitive dependency on a Hir or\n+                // MetaData node, so we'll just hash that\n+                None\n+            }\n+        }\n+    }\n+\n+    fn hir_hash(&mut self, def_id: DefId) -> u64 {\n+        assert!(def_id.is_local());\n+        // FIXME(#32753) -- should we use a distinct hash here\n+        self.tcx.calculate_item_hash(def_id)\n+    }\n+\n+    fn metadata_hash(&mut self, def_id: DefId) -> u64 {\n+        debug!(\"metadata_hash(def_id={:?})\", def_id);\n+\n+        assert!(!def_id.is_local());\n+        loop {\n+            // check whether we have a result cached for this def-id\n+            if let Some(&hash) = self.item_metadata_hashes.get(&def_id) {\n+                debug!(\"metadata_hash: def_id={:?} hash={:?}\", def_id, hash);\n+                return hash;\n+            }\n+\n+            // check whether we did not find detailed metadata for this\n+            // krate; in that case, we just use the krate's overall hash\n+            if let Some(&hash) = self.crate_hashes.get(&def_id.krate) {\n+                debug!(\"metadata_hash: def_id={:?} crate_hash={:?}\", def_id, hash);\n+                return hash.as_u64();\n+            }\n+\n+            // otherwise, load the data and repeat.\n+            self.load_data(def_id.krate);\n+            assert!(self.crate_hashes.contains_key(&def_id.krate));\n+        }\n+    }\n+\n+    fn load_data(&mut self, cnum: ast::CrateNum) {\n+        debug!(\"load_data(cnum={})\", cnum);\n+\n+        let svh = self.tcx.sess.cstore.crate_hash(cnum);\n+        let old = self.crate_hashes.insert(cnum, svh);\n+        debug!(\"load_data: svh={}\", svh);\n+        assert!(old.is_none(), \"loaded data for crate {:?} twice\", cnum);\n+\n+        if let Some(path) = metadata_hash_path(self.tcx, cnum) {\n+            debug!(\"load_data: path={:?}\", path);\n+            let mut data = vec![];\n+            match\n+                File::open(&path)\n+                .and_then(|mut file| file.read_to_end(&mut data))\n+            {\n+                Ok(_) => {\n+                    match self.load_from_data(cnum, &data) {\n+                        Ok(()) => { }\n+                        Err(err) => {\n+                            bug!(\"decoding error in dep-graph from `{}`: {}\",\n+                                 path.display(), err);\n+                        }\n+                    }\n+                }\n+                Err(err) => {\n+                    match err.kind() {\n+                        ErrorKind::NotFound => {\n+                            // If the file is not found, that's ok.\n+                        }\n+                        _ => {\n+                            self.tcx.sess.err(\n+                                &format!(\"could not load dep information from `{}`: {}\",\n+                                         path.display(), err));\n+                            return;\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    fn load_from_data(&mut self, cnum: ast::CrateNum, data: &[u8]) -> Result<(), Error> {\n+        debug!(\"load_from_data(cnum={})\", cnum);\n+\n+        // Load up the hashes for the def-ids from this crate.\n+        let mut decoder = Decoder::new(data, 0);\n+        let serialized_hashes = try!(SerializedMetadataHashes::decode(&mut decoder));\n+        for serialized_hash in serialized_hashes.hashes {\n+            // the hashes are stored with just a def-index, which is\n+            // always relative to the old crate; convert that to use\n+            // our internal crate number\n+            let def_id = DefId { krate: cnum, index: serialized_hash.def_index };\n+\n+            // record the hash for this dep-node\n+            let old = self.item_metadata_hashes.insert(def_id, serialized_hash.hash);\n+            debug!(\"load_from_data: def_id={:?} hash={}\", def_id, serialized_hash.hash);\n+            assert!(old.is_none(), \"already have hash for {:?}\", def_id);\n+        }\n+        Ok(())\n+    }\n+}"}, {"sha": "e3fd290443c11bf38ceb002c0bb23d2400b0f748", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -24,6 +24,7 @@ use std::path::Path;\n use super::data::*;\n use super::directory::*;\n use super::dirty_clean;\n+use super::hash::*;\n use super::util::*;\n \n type DirtyNodes = FnvHashSet<DepNode<DefId>>;\n@@ -133,13 +134,13 @@ fn initial_dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                  hashes: &[SerializedHash],\n                                  retraced: &RetracedDefIdDirectory)\n                                  -> DirtyNodes {\n+    let mut hcx = HashContext::new(tcx);\n     let mut items_removed = false;\n     let mut dirty_nodes = FnvHashSet();\n     for hash in hashes {\n         match hash.node.map_def(|&i| retraced.def_id(i)) {\n             Some(dep_node) => {\n-                // FIXME(#32753) -- should we use a distinct hash here\n-                let current_hash = dep_node.hash(tcx).unwrap();\n+                let current_hash = hcx.hash(dep_node).unwrap();\n                 debug!(\"initial_dirty_nodes: hash of {:?} is {:?}, was {:?}\",\n                        dep_node, current_hash, hash.hash);\n                 if current_hash != hash.hash {"}, {"sha": "72ccc29c97b63f6214069fad9accf984dca803d0", "filename": "src/librustc_incremental/persist/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -15,6 +15,7 @@\n mod data;\n mod directory;\n mod dirty_clean;\n+mod hash;\n mod load;\n mod save;\n mod util;"}, {"sha": "7deb1ca36dbded0451760ab5e15ac870434bbcc7", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 46, "deletions": 48, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -20,18 +20,23 @@ use std::path::PathBuf;\n \n use super::data::*;\n use super::directory::*;\n+use super::hash::*;\n use super::util::*;\n \n pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n     let _ignore = tcx.dep_graph.in_ignore();\n-\n-    save_in(tcx, dep_graph_path(tcx), encode_dep_graph);\n-    save_in(tcx, metadata_hash_path(tcx, LOCAL_CRATE), encode_metadata_hashes);\n+    let mut hcx = HashContext::new(tcx);\n+    save_in(&mut hcx, dep_graph_path(tcx), encode_dep_graph);\n+    save_in(&mut hcx, metadata_hash_path(tcx, LOCAL_CRATE), encode_metadata_hashes);\n }\n \n-fn save_in<'a,'tcx,F>(tcx: TyCtxt<'a, 'tcx, 'tcx>, opt_path_buf: Option<PathBuf>, encode: F)\n-    where F: FnOnce(TyCtxt<'a, 'tcx, 'tcx>, &mut Encoder) -> io::Result<()>\n+fn save_in<'a, 'tcx, F>(hcx: &mut HashContext<'a, 'tcx>,\n+                        opt_path_buf: Option<PathBuf>,\n+                        encode: F)\n+    where F: FnOnce(&mut HashContext<'a, 'tcx>, &mut Encoder) -> io::Result<()>\n {\n+    let tcx = hcx.tcx;\n+\n     let path_buf = match opt_path_buf {\n         Some(p) => p,\n         None => return\n@@ -54,7 +59,7 @@ fn save_in<'a,'tcx,F>(tcx: TyCtxt<'a, 'tcx, 'tcx>, opt_path_buf: Option<PathBuf>\n \n     // generate the data in a memory buffer\n     let mut wr = Cursor::new(Vec::new());\n-    match encode(tcx, &mut Encoder::new(&mut wr)) {\n+    match encode(hcx, &mut Encoder::new(&mut wr)) {\n         Ok(()) => { }\n         Err(err) => {\n             tcx.sess.err(\n@@ -80,9 +85,11 @@ fn save_in<'a,'tcx,F>(tcx: TyCtxt<'a, 'tcx, 'tcx>, opt_path_buf: Option<PathBuf>\n     }\n }\n \n-pub fn encode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+pub fn encode_dep_graph<'a, 'tcx>(hcx: &mut HashContext<'a, 'tcx>,\n                                   encoder: &mut Encoder)\n-                                  -> io::Result<()> {\n+                                  -> io::Result<()>\n+{\n+    let tcx = hcx.tcx;\n     let query = tcx.dep_graph.query();\n \n     let mut builder = DefIdDirectoryBuilder::new(tcx);\n@@ -92,29 +99,24 @@ pub fn encode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         query.nodes()\n              .into_iter()\n              .filter_map(|dep_node| {\n-                 dep_node.hash(tcx)\n-                         .map(|hash| {\n-                             let node = builder.map(dep_node).unwrap();\n-                             SerializedHash { node: node, hash: hash }\n-                         })\n+                 hcx.hash(dep_node)\n+                    .map(|hash| {\n+                        let node = builder.map(dep_node);\n+                        SerializedHash { node: node, hash: hash }\n+                    })\n              })\n              .collect();\n \n-    // Create the serialized dep-graph, dropping nodes that are\n-    // from other crates or from inlined items.\n-    //\n-    // FIXME(#32015) fix handling of other crates\n+    // Create the serialized dep-graph.\n     let graph = SerializedDepGraph {\n         nodes: query.nodes().into_iter()\n-                            .flat_map(|node| builder.map(node))\n+                            .map(|node| builder.map(node))\n                             .collect(),\n         edges: query.edges().into_iter()\n-                            .flat_map(|(source_node, target_node)| {\n-                                builder.map(source_node)\n-                                       .and_then(|source| {\n-                                           builder.map(target_node)\n-                                                  .map(|target| (source, target))\n-                                       })\n+                            .map(|(source_node, target_node)| {\n+                                let source = builder.map(source_node);\n+                                let target = builder.map(target_node);\n+                                (source, target)\n                             })\n                             .collect(),\n         hashes: hashes,\n@@ -130,14 +132,13 @@ pub fn encode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     Ok(())\n }\n \n-pub fn encode_metadata_hashes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+pub fn encode_metadata_hashes<'a, 'tcx>(hcx: &mut HashContext<'a, 'tcx>,\n                                         encoder: &mut Encoder)\n                                         -> io::Result<()>\n {\n+    let tcx = hcx.tcx;\n     let query = tcx.dep_graph.query();\n \n-    let mut builder = DefIdDirectoryBuilder::new(tcx);\n-\n     let serialized_hashes = {\n         // Identify the `MetaData(X)` nodes where `X` is local. These are\n         // the metadata items we export. Downstream crates will want to\n@@ -152,32 +153,31 @@ pub fn encode_metadata_hashes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                  });\n \n         // To create the hash for each item `X`, we don't hash the raw\n-        // bytes of the metadata (though in principle we could). Instead,\n-        // we walk the predecessors of `MetaData(X)` from the\n-        // dep-graph. This corresponds to all the inputs that were read to\n-        // construct the metadata. To create the hash for the metadata, we\n-        // hash (the hash of) all of those inputs.\n+        // bytes of the metadata (though in principle we\n+        // could). Instead, we walk the predecessors of `MetaData(X)`\n+        // from the dep-graph. This corresponds to all the inputs that\n+        // were read to construct the metadata. To create the hash for\n+        // the metadata, we hash (the hash of) all of those inputs.\n         let hashes =\n             meta_data_def_ids\n             .map(|def_id| {\n+                assert!(def_id.is_local());\n+                let dep_node = DepNode::MetaData(def_id);\n                 let mut state = SipHasher::new();\n-                for node in query.transitive_predecessors(DepNode::MetaData(def_id)) {\n-                    if let Some(hash) = node.hash(tcx) {\n+                debug!(\"save: computing metadata hash for {:?}\", dep_node);\n+                for node in query.transitive_predecessors(dep_node) {\n+                    if let Some(hash) = hcx.hash(node) {\n+                        debug!(\"save: predecessor {:?} has hash {}\", node, hash);\n                         state.write_u64(hash.to_le());\n+                    } else {\n+                        debug!(\"save: predecessor {:?} cannot be hashed\", node);\n                     }\n                 }\n-                (def_id, state.finish())\n-            });\n-\n-        // Now create the `SerializedHash` data structures that others\n-        // will load later.\n-        let hashes =\n-            hashes\n-            .map(|(def_id, hash)| {\n-                let index = builder.add(def_id).unwrap();\n-                SerializedHash {\n-                    node: DepNode::MetaData(index),\n-                    hash: hash\n+                let hash = state.finish();\n+                debug!(\"save: metadata hash for {:?} is {}\", dep_node, hash);\n+                SerializedMetadataHash {\n+                    def_index: def_id.index,\n+                    hash: hash,\n                 }\n             });\n \n@@ -188,8 +188,6 @@ pub fn encode_metadata_hashes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     };\n \n     // Encode everything.\n-    let directory = builder.into_directory();\n-    try!(directory.encode(encoder));\n     try!(serialized_hashes.encode(encoder));\n \n     Ok(())"}, {"sha": "a77a9607e7734decf10dcc375c989867234b3ab5", "filename": "src/librustc_incremental/persist/util.rs", "status": "modified", "additions": 0, "deletions": 21, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3a2edd7e613638a61bf70499e4c225c2fec36a5d/src%2Flibrustc_incremental%2Fpersist%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Futil.rs?ref=3a2edd7e613638a61bf70499e4c225c2fec36a5d", "patch": "@@ -8,9 +8,6 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use calculate_svh::SvhCalculate;\n-use rustc::dep_graph::DepNode;\n-use rustc::hir::def_id::DefId;\n use rustc::middle::cstore::LOCAL_CRATE;\n use rustc::ty::TyCtxt;\n \n@@ -72,21 +69,3 @@ fn create_dir_racy(path: &Path) -> io::Result<()> {\n     }\n }\n \n-pub trait DepNodeHash {\n-    /// Hash this dep-node, if it is of the kind that we know how to\n-    /// hash.\n-    fn hash<'a, 'tcx>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Option<u64>;\n-}\n-\n-impl DepNodeHash for DepNode<DefId> {\n-    fn hash<'a, 'tcx>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Option<u64> {\n-        match *self {\n-            DepNode::Hir(def_id) => {\n-                // FIXME(#32753) -- should we use a distinct hash here\n-                assert!(def_id.is_local());\n-                Some(tcx.calculate_item_hash(def_id))\n-            }\n-            _ => None\n-        }\n-    }\n-}"}]}