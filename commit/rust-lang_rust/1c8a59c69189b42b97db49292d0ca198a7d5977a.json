{"sha": "1c8a59c69189b42b97db49292d0ca198a7d5977a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFjOGE1OWM2OTE4OWI0MmI5N2RiNDkyOTJkMGNhMTk4YTdkNTk3N2E=", "commit": {"author": {"name": "Vytautas Astrauskas", "email": "astrauv@amazon.com", "date": "2020-04-08T03:20:41Z"}, "committer": {"name": "Vytautas Astrauskas", "email": "astrauv@amazon.com", "date": "2020-04-27T21:23:32Z"}, "message": "Rebase on PR 1157.", "tree": {"sha": "786b05a544346992a3bcdddb306ab401d2b4a881", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/786b05a544346992a3bcdddb306ab401d2b4a881"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1c8a59c69189b42b97db49292d0ca198a7d5977a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1c8a59c69189b42b97db49292d0ca198a7d5977a", "html_url": "https://github.com/rust-lang/rust/commit/1c8a59c69189b42b97db49292d0ca198a7d5977a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1c8a59c69189b42b97db49292d0ca198a7d5977a/comments", "author": null, "committer": null, "parents": [{"sha": "2202278f6af676266034e756bd3848efe4e10ab8", "url": "https://api.github.com/repos/rust-lang/rust/commits/2202278f6af676266034e756bd3848efe4e10ab8", "html_url": "https://github.com/rust-lang/rust/commit/2202278f6af676266034e756bd3848efe4e10ab8"}], "stats": {"total": 495, "additions": 415, "deletions": 80}, "files": [{"sha": "eb543581143484f7c0ef04ff1cd4303f9b288556", "filename": "src/shims/sync.rs", "status": "modified", "additions": 309, "deletions": 73, "changes": 382, "blob_url": "https://github.com/rust-lang/rust/blob/1c8a59c69189b42b97db49292d0ca198a7d5977a/src%2Fshims%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1c8a59c69189b42b97db49292d0ca198a7d5977a/src%2Fshims%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fsync.rs?ref=1c8a59c69189b42b97db49292d0ca198a7d5977a", "patch": "@@ -2,6 +2,7 @@ use rustc_middle::ty::{TyKind, TypeAndMut};\n use rustc_target::abi::{LayoutOf, Size};\n \n use crate::stacked_borrows::Tag;\n+use crate::threads::{BlockSetId, ThreadId};\n use crate::*;\n \n fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n@@ -55,15 +56,17 @@ fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n // bytes 0-3: reserved for signature on macOS\n // (need to avoid this because it is set by static initializer macros)\n // bytes 4-7: count of how many times this mutex has been locked, as a u32\n+// bytes 8-11: when count > 0, id of the owner thread as a u32\n // bytes 12-15 or 16-19 (depending on platform): mutex kind, as an i32\n // (the kind has to be at its offset for compatibility with static initializer macros)\n+// bytes 20-23: when count > 0, id of the blockset in which the blocked threads are waiting.\n \n fn mutex_get_locked_count<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n     // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n     let mutex_place = ecx.deref_operand(mutex_op)?;\n     let locked_count_place = mutex_place.offset(\n         Size::from_bytes(4),\n@@ -80,7 +83,7 @@ fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n     locked_count: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n     // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n     let mutex_place = ecx.deref_operand(mutex_op)?;\n     let locked_count_place = mutex_place.offset(\n         Size::from_bytes(4),\n@@ -91,12 +94,45 @@ fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n     ecx.write_scalar(locked_count.into(), locked_count_place.into())\n }\n \n+fn mutex_get_owner<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let mutex_id_place = mutex_place.offset(\n+        Size::from_bytes(8),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.read_scalar(mutex_id_place.into())\n+}\n+\n+fn mutex_set_owner<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+    mutex_id: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let mutex_id_place = mutex_place.offset(\n+        Size::from_bytes(8),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.write_scalar(mutex_id.into(), mutex_id_place.into())\n+}\n+\n fn mutex_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n     // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n     let mutex_place = ecx.deref_operand(mutex_op)?;\n     let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n     let kind_place = mutex_place.offset(\n@@ -114,7 +150,7 @@ fn mutex_set_kind<'mir, 'tcx: 'mir>(\n     kind: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n     // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n     let mutex_place = ecx.deref_operand(mutex_op)?;\n     let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n     let kind_place = mutex_place.offset(\n@@ -126,20 +162,73 @@ fn mutex_set_kind<'mir, 'tcx: 'mir>(\n     ecx.write_scalar(kind.into(), kind_place.into())\n }\n \n+fn mutex_get_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let mutex_id_place = mutex_place.offset(\n+        Size::from_bytes(20),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.read_scalar(mutex_id_place.into())\n+}\n+\n+fn mutex_set_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+    mutex_id: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let mutex_id_place = mutex_place.offset(\n+        Size::from_bytes(20),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.write_scalar(mutex_id.into(), mutex_id_place.into())\n+}\n+\n+fn mutex_get_or_create_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, BlockSetId> {\n+    let blockset = mutex_get_blockset(ecx, mutex_op)?.to_u32()?;\n+    if blockset == 0 {\n+        // 0 is a default value and also not a valid blockset id. Need to\n+        // allocate a new blockset.\n+        let blockset = ecx.create_blockset()?;\n+        mutex_set_blockset(ecx, mutex_op, blockset.to_u32_scalar())?;\n+        Ok(blockset)\n+    } else {\n+        Ok(blockset.into())\n+    }\n+}\n+\n // pthread_rwlock_t is between 32 and 56 bytes, depending on the platform.\n \n // Our chosen memory layout for the emulated rwlock (does not have to match the platform layout!):\n // bytes 0-3: reserved for signature on macOS\n // (need to avoid this because it is set by static initializer macros)\n // bytes 4-7: reader count, as a u32\n // bytes 8-11: writer count, as a u32\n+// bytes 12-15: when writer or reader count > 0, id of the blockset in which the\n+// blocked writers are waiting.\n+// bytes 16-20: when writer count > 0, id of the blockset in which the blocked\n+// readers are waiting.\n \n fn rwlock_get_readers<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n     // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n     let rwlock_place = ecx.deref_operand(rwlock_op)?;\n     let readers_place = rwlock_place.offset(\n         Size::from_bytes(4),\n@@ -156,7 +245,7 @@ fn rwlock_set_readers<'mir, 'tcx: 'mir>(\n     readers: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n     // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n     let rwlock_place = ecx.deref_operand(rwlock_op)?;\n     let readers_place = rwlock_place.offset(\n         Size::from_bytes(4),\n@@ -172,7 +261,7 @@ fn rwlock_get_writers<'mir, 'tcx: 'mir>(\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n     // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n     let rwlock_place = ecx.deref_operand(rwlock_op)?;\n     let writers_place = rwlock_place.offset(\n         Size::from_bytes(8),\n@@ -189,7 +278,7 @@ fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n     writers: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n     // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n     let rwlock_place = ecx.deref_operand(rwlock_op)?;\n     let writers_place = rwlock_place.offset(\n         Size::from_bytes(8),\n@@ -200,6 +289,104 @@ fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n     ecx.write_scalar(writers.into(), writers_place.into())\n }\n \n+fn rwlock_get_writer_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let blockset_place = rwlock_place.offset(\n+        Size::from_bytes(12),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.read_scalar(blockset_place.into())\n+}\n+\n+fn rwlock_set_writer_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+    blockset: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let blockset_place = rwlock_place.offset(\n+        Size::from_bytes(12),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.write_scalar(blockset.into(), blockset_place.into())\n+}\n+\n+fn rwlock_get_or_create_writer_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, BlockSetId> {\n+    let blockset = rwlock_get_writer_blockset(ecx, rwlock_op)?.to_u32()?;\n+    if blockset == 0 {\n+        // 0 is a default value and also not a valid blockset id. Need to\n+        // allocate a new blockset.\n+        let blockset = ecx.create_blockset()?;\n+        rwlock_set_writer_blockset(ecx, rwlock_op, blockset.to_u32_scalar())?;\n+        Ok(blockset)\n+    } else {\n+        Ok(blockset.into())\n+    }\n+}\n+\n+fn rwlock_get_reader_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let blockset_place = rwlock_place.offset(\n+        Size::from_bytes(16),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.read_scalar(blockset_place.into())\n+}\n+\n+fn rwlock_set_reader_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+    blockset: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let blockset_place = rwlock_place.offset(\n+        Size::from_bytes(16),\n+        MemPlaceMeta::None,\n+        ecx.machine.layouts.u32,\n+        ecx,\n+    )?;\n+    ecx.write_scalar(blockset.into(), blockset_place.into())\n+}\n+\n+fn rwlock_get_or_create_reader_blockset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, BlockSetId> {\n+    let blockset = rwlock_get_reader_blockset(ecx, rwlock_op)?.to_u32()?;\n+    if blockset == 0 {\n+        // 0 is a default value and also not a valid blockset id. Need to\n+        // allocate a new blockset.\n+        let blockset = ecx.create_blockset()?;\n+        rwlock_set_reader_blockset(ecx, rwlock_op, blockset.to_u32_scalar())?;\n+        Ok(blockset)\n+    } else {\n+        Ok(blockset.into())\n+    }\n+}\n+\n impl<'mir, 'tcx> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n     fn pthread_mutexattr_init(&mut self, attr_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n@@ -265,31 +452,40 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n         let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n+        let active_thread = this.get_active_thread()?;\n \n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n-            if locked_count == 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n-                Ok(0)\n-            } else {\n-                throw_machine_stop!(TerminationInfo::Deadlock);\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n-            if locked_count == 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n+        if locked_count == 0 {\n+            // The mutex is unlocked. Let's lock it.\n+            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n+            mutex_set_owner(this, mutex_op, active_thread.to_u32_scalar())?;\n+            Ok(0)\n+        } else {\n+            // The mutex is locked. Let's check by whom.\n+            let owner_thread: ThreadId =\n+                mutex_get_owner(this, mutex_op)?.not_undef()?.to_u32()?.into();\n+            if owner_thread != active_thread {\n+                // Block the active thread.\n+                let blockset = mutex_get_or_create_blockset(this, mutex_op)?;\n+                this.block_active_thread(blockset)?;\n                 Ok(0)\n             } else {\n-                this.eval_libc_i32(\"EDEADLK\")\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-            match locked_count.checked_add(1) {\n-                Some(new_count) => {\n-                    mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                    Ok(0)\n+                // Trying to acquire the same mutex again.\n+                if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n+                    throw_machine_stop!(TerminationInfo::Deadlock);\n+                } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n+                    this.eval_libc_i32(\"EDEADLK\")\n+                } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n+                    match locked_count.checked_add(1) {\n+                        Some(new_count) => {\n+                            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n+                            Ok(0)\n+                        }\n+                        None => this.eval_libc_i32(\"EAGAIN\"),\n+                    }\n+                } else {\n+                    throw_ub_format!(\"called pthread_mutex_lock on an unsupported type of mutex\");\n                 }\n-                None => this.eval_libc_i32(\"EAGAIN\"),\n             }\n-        } else {\n-            throw_ub_format!(\"called pthread_mutex_lock on an unsupported type of mutex\");\n         }\n     }\n \n@@ -298,26 +494,36 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n         let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n+        let active_thread = this.get_active_thread()?;\n \n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?\n-            || kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?\n-        {\n-            if locked_count == 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n-                Ok(0)\n-            } else {\n+        if locked_count == 0 {\n+            // The mutex is unlocked. Let's lock it.\n+            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n+            mutex_set_owner(this, mutex_op, active_thread.to_u32_scalar())?;\n+            Ok(0)\n+        } else {\n+            let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+            if owner_thread != active_thread {\n                 this.eval_libc_i32(\"EBUSY\")\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-            match locked_count.checked_add(1) {\n-                Some(new_count) => {\n-                    mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                    Ok(0)\n+            } else {\n+                if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?\n+                    || kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?\n+                {\n+                    this.eval_libc_i32(\"EBUSY\")\n+                } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n+                    match locked_count.checked_add(1) {\n+                        Some(new_count) => {\n+                            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n+                            Ok(0)\n+                        }\n+                        None => this.eval_libc_i32(\"EAGAIN\"),\n+                    }\n+                } else {\n+                    throw_ub_format!(\n+                        \"called pthread_mutex_trylock on an unsupported type of mutex\"\n+                    );\n                 }\n-                None => this.eval_libc_i32(\"EAGAIN\"),\n             }\n-        } else {\n-            throw_ub_format!(\"called pthread_mutex_trylock on an unsupported type of mutex\");\n         }\n     }\n \n@@ -326,34 +532,40 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n         let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n-\n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n-            if locked_count != 0 {\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(0))?;\n-                Ok(0)\n+        let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+\n+        if owner_thread != this.get_active_thread()? {\n+            throw_ub_format!(\"called pthread_mutex_unlock on a mutex owned by another thread\");\n+        } else if locked_count == 1 {\n+            let blockset = mutex_get_or_create_blockset(this, mutex_op)?;\n+            if let Some(new_owner) = this.unblock_random_thread(blockset)? {\n+                // We have at least one thread waiting on this mutex. Transfer\n+                // ownership to it.\n+                mutex_set_owner(this, mutex_op, new_owner.to_u32_scalar())?;\n             } else {\n-                throw_ub_format!(\"unlocked a PTHREAD_MUTEX_NORMAL mutex that was not locked\");\n-            }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n-            if locked_count != 0 {\n+                // No thread is waiting on this mutex.\n                 mutex_set_locked_count(this, mutex_op, Scalar::from_u32(0))?;\n-                Ok(0)\n-            } else {\n-                this.eval_libc_i32(\"EPERM\")\n             }\n-        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-            match locked_count.checked_sub(1) {\n-                Some(new_count) => {\n-                    mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                    Ok(0)\n-                }\n-                None => {\n-                    // locked_count was already zero\n-                    this.eval_libc_i32(\"EPERM\")\n+            Ok(0)\n+        } else {\n+            if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n+                throw_ub_format!(\"unlocked a PTHREAD_MUTEX_NORMAL mutex that was not locked\");\n+            } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n+                this.eval_libc_i32(\"EPERM\")\n+            } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n+                match locked_count.checked_sub(1) {\n+                    Some(new_count) => {\n+                        mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n+                        Ok(0)\n+                    }\n+                    None => {\n+                        // locked_count was already zero\n+                        this.eval_libc_i32(\"EPERM\")\n+                    }\n                 }\n+            } else {\n+                throw_ub_format!(\"called pthread_mutex_unlock on an unsupported type of mutex\");\n             }\n-        } else {\n-            throw_ub_format!(\"called pthread_mutex_unlock on an unsupported type of mutex\");\n         }\n     }\n \n@@ -366,6 +578,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         mutex_set_kind(this, mutex_op, ScalarMaybeUndef::Undef)?;\n         mutex_set_locked_count(this, mutex_op, ScalarMaybeUndef::Undef)?;\n+        mutex_set_blockset(this, mutex_op, ScalarMaybeUndef::Undef)?;\n \n         Ok(0)\n     }\n@@ -375,8 +588,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n         let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n+\n         if writers != 0 {\n-            throw_machine_stop!(TerminationInfo::Deadlock);\n+            // The lock is locked by a writer.\n+            assert_eq!(writers, 1);\n+            let reader_blockset = rwlock_get_or_create_reader_blockset(this, rwlock_op)?;\n+            this.block_active_thread(reader_blockset)?;\n+            Ok(0)\n         } else {\n             match readers.checked_add(1) {\n                 Some(new_readers) => {\n@@ -411,14 +629,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n         let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n-        if readers != 0 {\n-            throw_machine_stop!(TerminationInfo::Deadlock);\n-        } else if writers != 0 {\n-            throw_machine_stop!(TerminationInfo::Deadlock);\n+        let writer_blockset = rwlock_get_or_create_writer_blockset(this, rwlock_op)?;\n+        if readers != 0 || writers != 0 {\n+            this.block_active_thread(writer_blockset)?;\n         } else {\n             rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n-            Ok(0)\n         }\n+        Ok(0)\n     }\n \n     fn pthread_rwlock_trywrlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n@@ -439,11 +656,28 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n         let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n+        let writer_blockset = rwlock_get_or_create_writer_blockset(this, rwlock_op)?;\n         if let Some(new_readers) = readers.checked_sub(1) {\n+            assert_eq!(writers, 0);\n             rwlock_set_readers(this, rwlock_op, Scalar::from_u32(new_readers))?;\n+            if new_readers == 0 {\n+                if let Some(_writer) = this.unblock_random_thread(writer_blockset)? {\n+                    rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n+                }\n+            }\n             Ok(0)\n         } else if writers != 0 {\n+            let reader_blockset = rwlock_get_or_create_reader_blockset(this, rwlock_op)?;\n             rwlock_set_writers(this, rwlock_op, Scalar::from_u32(0))?;\n+            if let Some(_writer) = this.unblock_random_thread(writer_blockset)? {\n+                rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n+            } else {\n+                let mut readers = 0;\n+                while let Some(_reader) = this.unblock_random_thread(reader_blockset)? {\n+                    readers += 1;\n+                }\n+                rwlock_set_readers(this, rwlock_op, Scalar::from_u32(readers))?\n+            }\n             Ok(0)\n         } else {\n             throw_ub_format!(\"unlocked an rwlock that was not locked\");\n@@ -461,6 +695,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         rwlock_set_readers(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n         rwlock_set_writers(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n+        rwlock_set_reader_blockset(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n+        rwlock_set_writer_blockset(this, rwlock_op, ScalarMaybeUndef::Undef)?;\n \n         Ok(0)\n     }"}, {"sha": "5991ba4ed1f639422a9bed46cc2ea778ca41c985", "filename": "src/threads.rs", "status": "modified", "additions": 74, "deletions": 7, "changes": 81, "blob_url": "https://github.com/rust-lang/rust/blob/1c8a59c69189b42b97db49292d0ca198a7d5977a/src%2Fthreads.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1c8a59c69189b42b97db49292d0ca198a7d5977a/src%2Fthreads.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fthreads.rs?ref=1c8a59c69189b42b97db49292d0ca198a7d5977a", "patch": "@@ -2,6 +2,7 @@\n \n use std::cell::RefCell;\n use std::collections::hash_map::Entry;\n+use std::convert::TryFrom;\n \n use log::trace;\n \n@@ -31,14 +32,47 @@ impl From<u64> for ThreadId {\n     }\n }\n \n+impl From<u32> for ThreadId {\n+    fn from(id: u32) -> Self {\n+        Self(id as usize)\n+    }\n+}\n+\n+impl ThreadId {\n+    pub fn to_u32_scalar<'tcx>(&self) -> Scalar<Tag> {\n+        Scalar::from_u32(u32::try_from(self.0).unwrap())\n+    }\n+}\n+\n+/// An identifier of a set of blocked threads.\n+///\n+/// Note: 0 is not a valid identifier.\n+#[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n+pub struct BlockSetId(u32);\n+\n+impl From<u32> for BlockSetId {\n+    fn from(id: u32) -> Self {\n+        assert_ne!(id, 0, \"0 is not a valid blockset id\");\n+        Self(id)\n+    }\n+}\n+\n+impl BlockSetId {\n+    pub fn to_u32_scalar<'tcx>(&self) -> Scalar<Tag> {\n+        Scalar::from_u32(self.0)\n+    }\n+}\n+\n /// The state of a thread.\n #[derive(Debug, Copy, Clone, PartialEq, Eq)]\n pub enum ThreadState {\n     /// The thread is enabled and can be executed.\n     Enabled,\n     /// The thread tried to join the specified thread and is blocked until that\n     /// thread terminates.\n-    Blocked(ThreadId),\n+    BlockedOnJoin(ThreadId),\n+    /// The thread is blocked and belongs to the given blockset..\n+    Blocked(BlockSetId),\n     /// The thread has terminated its execution (we do not delete terminated\n     /// threads.)\n     Terminated,\n@@ -93,13 +127,15 @@ pub struct ThreadSet<'mir, 'tcx> {\n     ///\n     /// Note that this vector also contains terminated threads.\n     threads: IndexVec<ThreadId, Thread<'mir, 'tcx>>,\n+    /// A counter used to generate unique identifiers for blocksets.\n+    blockset_counter: u32,\n }\n \n impl<'mir, 'tcx> Default for ThreadSet<'mir, 'tcx> {\n     fn default() -> Self {\n         let mut threads = IndexVec::new();\n         threads.push(Default::default());\n-        Self { active_thread: ThreadId::new(0), threads: threads }\n+        Self { active_thread: ThreadId::new(0), threads: threads, blockset_counter: 0 }\n     }\n }\n \n@@ -145,12 +181,12 @@ impl<'mir, 'tcx: 'mir> ThreadSet<'mir, 'tcx> {\n         assert!(\n             self.threads\n                 .iter()\n-                .all(|thread| thread.state != ThreadState::Blocked(joined_thread_id)),\n+                .all(|thread| thread.state != ThreadState::BlockedOnJoin(joined_thread_id)),\n             \"Bug: multiple threads try to join the same thread.\"\n         );\n         if self.threads[joined_thread_id].state != ThreadState::Terminated {\n             // The joined thread is still running, we need to wait for it.\n-            self.threads[self.active_thread].state = ThreadState::Blocked(joined_thread_id);\n+            self.active_thread_mut().state = ThreadState::BlockedOnJoin(joined_thread_id);\n             trace!(\n                 \"{:?} blocked on {:?} when trying to join\",\n                 self.active_thread,\n@@ -162,18 +198,37 @@ impl<'mir, 'tcx: 'mir> ThreadSet<'mir, 'tcx> {\n     fn set_thread_name(&mut self, new_thread_name: Vec<u8>) {\n         self.active_thread_mut().thread_name = Some(new_thread_name);\n     }\n-    /// Get ids of all threads ever allocated.\n+    /// Get ids and states of all threads ever allocated.\n     fn get_all_thread_ids_with_states(&self) -> Vec<(ThreadId, ThreadState)> {\n         self.threads.iter_enumerated().map(|(id, thread)| (id, thread.state)).collect()\n     }\n+    fn create_blockset(&mut self) -> BlockSetId {\n+        self.blockset_counter = self.blockset_counter.checked_add(1).unwrap();\n+        self.blockset_counter.into()\n+    }\n+    fn block_active_thread(&mut self, set: BlockSetId) {\n+        let state = &mut self.active_thread_mut().state;\n+        assert_eq!(*state, ThreadState::Enabled);\n+        *state = ThreadState::Blocked(set);\n+    }\n+    fn unblock_random_thread(&mut self, set: BlockSetId) -> Option<ThreadId> {\n+        for (id, thread) in self.threads.iter_enumerated_mut() {\n+            if thread.state == ThreadState::Blocked(set) {\n+                trace!(\"unblocking {:?} in blockset {:?}\", id, set);\n+                thread.state = ThreadState::Enabled;\n+                return Some(id);\n+            }\n+        }\n+        None\n+    }\n     /// Decide which thread to run next.\n     ///\n     /// Returns `false` if all threads terminated.\n     fn schedule(&mut self) -> InterpResult<'tcx, bool> {\n         if self.threads[self.active_thread].check_terminated() {\n             // Check if we need to unblock any threads.\n             for (i, thread) in self.threads.iter_enumerated_mut() {\n-                if thread.state == ThreadState::Blocked(self.active_thread) {\n+                if thread.state == ThreadState::BlockedOnJoin(self.active_thread) {\n                     trace!(\"unblocking {:?} because {:?} terminated\", i, self.active_thread);\n                     thread.state = ThreadState::Enabled;\n                 }\n@@ -191,7 +246,7 @@ impl<'mir, 'tcx: 'mir> ThreadSet<'mir, 'tcx> {\n         if self.threads.iter().all(|thread| thread.state == ThreadState::Terminated) {\n             Ok(false)\n         } else {\n-            throw_machine_stop!(TerminationInfo::Abort(Some(format!(\"execution deadlocked\"))))\n+            throw_machine_stop!(TerminationInfo::Deadlock);\n         }\n     }\n }\n@@ -298,6 +353,18 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let this = self.eval_context_mut();\n         this.machine.threads.get_all_thread_ids_with_states()\n     }\n+    fn create_blockset(&mut self) -> InterpResult<'tcx, BlockSetId> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.create_blockset())\n+    }\n+    fn block_active_thread(&mut self, set: BlockSetId) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.block_active_thread(set))\n+    }\n+    fn unblock_random_thread(&mut self, set: BlockSetId) -> InterpResult<'tcx, Option<ThreadId>> {\n+        let this = self.eval_context_mut();\n+        Ok(this.machine.threads.unblock_random_thread(set))\n+    }\n     /// Decide which thread to run next.\n     ///\n     /// Returns `false` if all threads terminated."}, {"sha": "575aeadd7fedfa8c3d675004d158efd08a1279b8", "filename": "tests/run-pass/concurrency/locks.rs", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/1c8a59c69189b42b97db49292d0ca198a7d5977a/tests%2Frun-pass%2Fconcurrency%2Flocks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1c8a59c69189b42b97db49292d0ca198a7d5977a/tests%2Frun-pass%2Fconcurrency%2Flocks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Flocks.rs?ref=1c8a59c69189b42b97db49292d0ca198a7d5977a", "patch": "@@ -0,0 +1,29 @@\n+//! This test just calls the relevant APIs to check if Miri crashes.\n+\n+use std::sync::{Arc, Mutex};\n+use std::thread;\n+\n+fn main() {\n+\n+    let data = Arc::new(Mutex::new(0));\n+    let mut threads = Vec::new();\n+\n+    for _ in 0..3 {\n+        let data = Arc::clone(&data);\n+        let thread = thread::spawn(move || {\n+            let mut data = data.lock().unwrap();\n+            *data += 1;\n+        });\n+        threads.push(thread);\n+    }\n+\n+    for thread in threads {\n+        thread.join().unwrap();\n+    }\n+\n+    assert!(data.try_lock().is_ok());\n+\n+    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n+    assert_eq!(data, 3);\n+\n+}\n\\ No newline at end of file"}, {"sha": "2486b320db18f0f36113c5daf939c11d21a60468", "filename": "tests/run-pass/concurrency/locks.stdout", "status": "added", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/1c8a59c69189b42b97db49292d0ca198a7d5977a/tests%2Frun-pass%2Fconcurrency%2Flocks.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/1c8a59c69189b42b97db49292d0ca198a7d5977a/tests%2Frun-pass%2Fconcurrency%2Flocks.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Flocks.stdout?ref=1c8a59c69189b42b97db49292d0ca198a7d5977a", "patch": "@@ -0,0 +1,3 @@\n+WARNING: The thread support is experimental. For example, Miri does not detect data races yet.\n+WARNING: The thread support is experimental. For example, Miri does not detect data races yet.\n+WARNING: The thread support is experimental. For example, Miri does not detect data races yet."}]}