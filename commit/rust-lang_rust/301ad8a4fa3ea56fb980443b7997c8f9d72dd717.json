{"sha": "301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMwMWFkOGE0ZmEzZWE1NmZiOTgwNDQzYjc5OTdjOGY5ZDcyZGQ3MTc=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-02-24T03:29:00Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-02-24T03:29:00Z"}, "message": "Auto merge of #80891 - cjgillot:noq, r=Mark-Simulacrum\n\nMake the `Query` enum a simple struct.\n\nA lot of code in `rustc_query_system` is generic over it, only to encode an exceptional error case: query cycles.\nThe delayed computations are now done at cycle detection.", "tree": {"sha": "4dad474ef93d223486d5f0654fce2bc177e3fb5d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4dad474ef93d223486d5f0654fce2bc177e3fb5d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "html_url": "https://github.com/rust-lang/rust/commit/301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fe1bf8e05c39bdcc73fc09e246b7209444e389bc", "url": "https://api.github.com/repos/rust-lang/rust/commits/fe1bf8e05c39bdcc73fc09e246b7209444e389bc", "html_url": "https://github.com/rust-lang/rust/commit/fe1bf8e05c39bdcc73fc09e246b7209444e389bc"}, {"sha": "903f65f215812ca4d40e1efc6a5f234e0ab5728c", "url": "https://api.github.com/repos/rust-lang/rust/commits/903f65f215812ca4d40e1efc6a5f234e0ab5728c", "html_url": "https://github.com/rust-lang/rust/commit/903f65f215812ca4d40e1efc6a5f234e0ab5728c"}], "stats": {"total": 611, "additions": 297, "deletions": 314}, "files": [{"sha": "c717a8f1a9d5ba7601d51d7f310b9dd3f67b0422", "filename": "Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -4202,6 +4202,7 @@ dependencies = [\n  \"rustc_index\",\n  \"rustc_macros\",\n  \"rustc_serialize\",\n+ \"rustc_session\",\n  \"rustc_span\",\n  \"smallvec 1.6.1\",\n  \"tracing\","}, {"sha": "c688b23be1d02c74a8132e6e40b55503123692e2", "filename": "compiler/rustc_middle/src/dep_graph/mod.rs", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_middle%2Fsrc%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_middle%2Fsrc%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fdep_graph%2Fmod.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -2,6 +2,7 @@ use crate::ich::StableHashingContext;\n use crate::ty::{self, TyCtxt};\n use rustc_data_structures::profiling::SelfProfilerRef;\n use rustc_data_structures::sync::Lock;\n+use rustc_session::Session;\n \n #[macro_use]\n mod dep_node;\n@@ -101,20 +102,18 @@ impl<'tcx> DepContext for TyCtxt<'tcx> {\n         TyCtxt::create_stable_hashing_context(*self)\n     }\n \n-    fn debug_dep_tasks(&self) -> bool {\n-        self.sess.opts.debugging_opts.dep_tasks\n-    }\n-    fn debug_dep_node(&self) -> bool {\n-        self.sess.opts.debugging_opts.incremental_info\n-            || self.sess.opts.debugging_opts.query_dep_graph\n-    }\n-\n     #[inline]\n     fn dep_graph(&self) -> &DepGraph {\n         &self.dep_graph\n     }\n \n+    #[inline(always)]\n     fn profiler(&self) -> &SelfProfilerRef {\n         &self.prof\n     }\n+\n+    #[inline(always)]\n+    fn sess(&self) -> &Session {\n+        self.sess\n+    }\n }"}, {"sha": "e9314797fbdc538a5cc8337a12242ff7328c981f", "filename": "compiler/rustc_query_impl/src/lib.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_impl%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_impl%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Flib.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -17,19 +17,17 @@ extern crate rustc_middle;\n extern crate tracing;\n \n use rustc_data_structures::fingerprint::Fingerprint;\n-use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n-use rustc_errors::{Diagnostic, Handler, Level};\n+use rustc_errors::{DiagnosticBuilder, Handler};\n use rustc_hir::def_id::CrateNum;\n use rustc_index::vec::IndexVec;\n use rustc_middle::dep_graph;\n use rustc_middle::ich::StableHashingContext;\n use rustc_middle::ty::query::{query_keys, query_storage, query_stored, query_values};\n use rustc_middle::ty::query::{Providers, QueryEngine};\n-use rustc_middle::ty::TyCtxt;\n+use rustc_middle::ty::{self, TyCtxt};\n use rustc_serialize::opaque;\n use rustc_span::{Span, DUMMY_SP};\n-use std::mem;\n \n #[macro_use]\n mod plumbing;"}, {"sha": "37a176de9419684ec4822ed39bae66a88364dbfd", "filename": "compiler/rustc_query_impl/src/plumbing.rs", "status": "modified", "additions": 52, "deletions": 164, "changes": 216, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -2,22 +2,19 @@\n //! generate the actual methods on tcx which find and execute the provider,\n //! manage the caches, and so forth.\n \n-use super::{queries, Query};\n+use super::queries;\n use rustc_middle::dep_graph::{DepKind, DepNode, DepNodeExt, DepNodeIndex, SerializedDepNodeIndex};\n use rustc_middle::ty::query::on_disk_cache;\n use rustc_middle::ty::tls::{self, ImplicitCtxt};\n use rustc_middle::ty::{self, TyCtxt};\n use rustc_query_system::dep_graph::HasDepContext;\n-use rustc_query_system::query::{CycleError, QueryJobId, QueryJobInfo};\n-use rustc_query_system::query::{QueryContext, QueryDescription};\n+use rustc_query_system::query::{QueryContext, QueryDescription, QueryJobId, QueryMap};\n \n-use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lock;\n use rustc_data_structures::thin_vec::ThinVec;\n-use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder};\n+use rustc_errors::Diagnostic;\n use rustc_serialize::opaque;\n use rustc_span::def_id::{DefId, LocalDefId};\n-use rustc_span::Span;\n \n #[derive(Copy, Clone)]\n pub struct QueryCtxt<'tcx> {\n@@ -45,15 +42,6 @@ impl HasDepContext for QueryCtxt<'tcx> {\n }\n \n impl QueryContext for QueryCtxt<'tcx> {\n-    type Query = Query<'tcx>;\n-\n-    fn incremental_verify_ich(&self) -> bool {\n-        self.sess.opts.debugging_opts.incremental_verify_ich\n-    }\n-    fn verbose(&self) -> bool {\n-        self.sess.verbose()\n-    }\n-\n     fn def_path_str(&self, def_id: DefId) -> String {\n         self.tcx.def_path_str(def_id)\n     }\n@@ -62,11 +50,8 @@ impl QueryContext for QueryCtxt<'tcx> {\n         tls::with_related_context(**self, |icx| icx.query)\n     }\n \n-    fn try_collect_active_jobs(\n-        &self,\n-    ) -> Option<FxHashMap<QueryJobId<Self::DepKind>, QueryJobInfo<Self::DepKind, Self::Query>>>\n-    {\n-        self.queries.try_collect_active_jobs()\n+    fn try_collect_active_jobs(&self) -> Option<QueryMap<Self::DepKind>> {\n+        self.queries.try_collect_active_jobs(**self)\n     }\n \n     fn try_load_from_on_disk_cache(&self, dep_node: &DepNode) {\n@@ -132,14 +117,6 @@ impl QueryContext for QueryCtxt<'tcx> {\n         (cb.force_from_dep_node)(*self, dep_node)\n     }\n \n-    fn has_errors_or_delayed_span_bugs(&self) -> bool {\n-        self.sess.has_errors_or_delayed_span_bugs()\n-    }\n-\n-    fn diagnostic(&self) -> &rustc_errors::Handler {\n-        self.sess.diagnostic()\n-    }\n-\n     // Interactions with on_disk_cache\n     fn load_diagnostics(&self, prev_dep_node_index: SerializedDepNodeIndex) -> Vec<Diagnostic> {\n         self.on_disk_cache\n@@ -196,54 +173,6 @@ impl QueryContext for QueryCtxt<'tcx> {\n }\n \n impl<'tcx> QueryCtxt<'tcx> {\n-    #[inline(never)]\n-    #[cold]\n-    pub(super) fn report_cycle(\n-        self,\n-        CycleError { usage, cycle: stack }: CycleError<Query<'tcx>>,\n-    ) -> DiagnosticBuilder<'tcx> {\n-        assert!(!stack.is_empty());\n-\n-        let fix_span = |span: Span, query: &Query<'tcx>| {\n-            self.sess.source_map().guess_head_span(query.default_span(*self, span))\n-        };\n-\n-        // Disable naming impls with types in this path, since that\n-        // sometimes cycles itself, leading to extra cycle errors.\n-        // (And cycle errors around impls tend to occur during the\n-        // collect/coherence phases anyhow.)\n-        ty::print::with_forced_impl_filename_line(|| {\n-            let span = fix_span(stack[1 % stack.len()].span, &stack[0].query);\n-            let mut err = struct_span_err!(\n-                self.sess,\n-                span,\n-                E0391,\n-                \"cycle detected when {}\",\n-                stack[0].query.describe(self)\n-            );\n-\n-            for i in 1..stack.len() {\n-                let query = &stack[i].query;\n-                let span = fix_span(stack[(i + 1) % stack.len()].span, query);\n-                err.span_note(span, &format!(\"...which requires {}...\", query.describe(self)));\n-            }\n-\n-            err.note(&format!(\n-                \"...which again requires {}, completing the cycle\",\n-                stack[0].query.describe(self)\n-            ));\n-\n-            if let Some((span, query)) = usage {\n-                err.span_note(\n-                    fix_span(span, &query),\n-                    &format!(\"cycle used when {}\", query.describe(self)),\n-                );\n-            }\n-\n-            err\n-        })\n-    }\n-\n     pub(super) fn encode_query_results(\n         self,\n         encoder: &mut on_disk_cache::CacheEncoder<'a, 'tcx, opaque::FileEncoder>,\n@@ -323,16 +252,16 @@ pub struct QueryStruct {\n \n macro_rules! handle_cycle_error {\n     ([][$tcx: expr, $error:expr]) => {{\n-        $tcx.report_cycle($error).emit();\n+        $error.emit();\n         Value::from_cycle_error($tcx)\n     }};\n     ([fatal_cycle $($rest:tt)*][$tcx:expr, $error:expr]) => {{\n-        $tcx.report_cycle($error).emit();\n+        $error.emit();\n         $tcx.sess.abort_if_errors();\n         unreachable!()\n     }};\n     ([cycle_delay_bug $($rest:tt)*][$tcx:expr, $error:expr]) => {{\n-        $tcx.report_cycle($error).delay_as_bug();\n+        $error.delay_as_bug();\n         Value::from_cycle_error($tcx)\n     }};\n     ([$other:ident $(($($other_args:tt)*))* $(, $($modifiers:tt)*)*][$($args:tt)*]) => {\n@@ -386,55 +315,40 @@ macro_rules! define_queries {\n             input: ($(([$($modifiers)*] [$($attr)*] [$name]))*)\n         }\n \n-        #[allow(nonstandard_style)]\n-        #[derive(Clone, Debug)]\n-        pub enum Query<$tcx> {\n-            $($(#[$attr])* $name(query_keys::$name<$tcx>)),*\n-        }\n-\n-        impl<$tcx> Query<$tcx> {\n-            pub fn name(&self) -> &'static str {\n-                match *self {\n-                    $(Query::$name(_) => stringify!($name),)*\n-                }\n-            }\n+        mod make_query {\n+            use super::*;\n \n-            pub(crate) fn describe(&self, tcx: QueryCtxt<$tcx>) -> String {\n-                let (r, name) = match *self {\n-                    $(Query::$name(key) => {\n-                        (queries::$name::describe(tcx, key), stringify!($name))\n-                    })*\n+            // Create an eponymous constructor for each query.\n+            $(#[allow(nonstandard_style)] $(#[$attr])*\n+            pub fn $name<$tcx>(tcx: QueryCtxt<$tcx>, key: query_keys::$name<$tcx>) -> QueryStackFrame {\n+                let kind = dep_graph::DepKind::$name;\n+                let name = stringify!($name);\n+                let description = ty::print::with_forced_impl_filename_line(\n+                    // Force filename-line mode to avoid invoking `type_of` query.\n+                    || queries::$name::describe(tcx, key)\n+                );\n+                let description = if tcx.sess.verbose() {\n+                    format!(\"{} [{}]\", description, name)\n+                } else {\n+                    description\n                 };\n-                if tcx.sess.verbose() {\n-                    format!(\"{} [{}]\", r, name)\n+                let span = if kind == dep_graph::DepKind::def_span {\n+                    // The `def_span` query is used to calculate `default_span`,\n+                    // so exit to avoid infinite recursion.\n+                    None\n                 } else {\n-                    r\n-                }\n-            }\n-\n-            // FIXME(eddyb) Get more valid `Span`s on queries.\n-            pub fn default_span(&self, tcx: TyCtxt<$tcx>, span: Span) -> Span {\n-                if !span.is_dummy() {\n-                    return span;\n-                }\n-                // The `def_span` query is used to calculate `default_span`,\n-                // so exit to avoid infinite recursion.\n-                if let Query::def_span(..) = *self {\n-                    return span\n-                }\n-                match *self {\n-                    $(Query::$name(key) => key.default_span(tcx),)*\n-                }\n-            }\n-        }\n+                    Some(key.default_span(*tcx))\n+                };\n+                let hash = || {\n+                    let mut hcx = tcx.create_stable_hashing_context();\n+                    let mut hasher = StableHasher::new();\n+                    std::mem::discriminant(&kind).hash_stable(&mut hcx, &mut hasher);\n+                    key.hash_stable(&mut hcx, &mut hasher);\n+                    hasher.finish::<u64>()\n+                };\n \n-        impl<'a, $tcx> HashStable<StableHashingContext<'a>> for Query<$tcx> {\n-            fn hash_stable(&self, hcx: &mut StableHashingContext<'a>, hasher: &mut StableHasher) {\n-                mem::discriminant(self).hash_stable(hcx, hasher);\n-                match *self {\n-                    $(Query::$name(key) => key.hash_stable(hcx, hasher),)*\n-                }\n-            }\n+                QueryStackFrame::new(name, description, span, hash)\n+            })*\n         }\n \n         #[allow(nonstandard_style)]\n@@ -461,7 +375,9 @@ macro_rules! define_queries {\n             type Cache = query_storage::$name<$tcx>;\n \n             #[inline(always)]\n-            fn query_state<'a>(tcx: QueryCtxt<$tcx>) -> &'a QueryState<crate::dep_graph::DepKind, Query<$tcx>, Self::Key> {\n+            fn query_state<'a>(tcx: QueryCtxt<$tcx>) -> &'a QueryState<crate::dep_graph::DepKind, Self::Key>\n+                where QueryCtxt<$tcx>: 'a\n+            {\n                 &tcx.queries.$name\n             }\n \n@@ -493,7 +409,7 @@ macro_rules! define_queries {\n \n             fn handle_cycle_error(\n                 tcx: QueryCtxt<'tcx>,\n-                error: CycleError<Query<'tcx>>\n+                mut error: DiagnosticBuilder<'_>,\n             ) -> Self::Value {\n                 handle_cycle_error!([$($modifiers)*][tcx, error])\n             }\n@@ -596,7 +512,6 @@ macro_rules! define_queries_struct {\n \n             $($(#[$attr])*  $name: QueryState<\n                 crate::dep_graph::DepKind,\n-                Query<$tcx>,\n                 query_keys::$name<$tcx>,\n             >,)*\n         }\n@@ -614,14 +529,17 @@ macro_rules! define_queries_struct {\n             }\n \n             pub(crate) fn try_collect_active_jobs(\n-                &self\n-            ) -> Option<FxHashMap<QueryJobId<crate::dep_graph::DepKind>, QueryJobInfo<crate::dep_graph::DepKind, Query<$tcx>>>> {\n-                let mut jobs = FxHashMap::default();\n+                &$tcx self,\n+                tcx: TyCtxt<$tcx>,\n+            ) -> Option<QueryMap<crate::dep_graph::DepKind>> {\n+                let tcx = QueryCtxt { tcx, queries: self };\n+                let mut jobs = QueryMap::default();\n \n                 $(\n                     self.$name.try_collect_active_jobs(\n-                        <queries::$name<'tcx> as QueryAccessors<QueryCtxt<'tcx>>>::DEP_KIND,\n-                        Query::$name,\n+                        tcx,\n+                        dep_graph::DepKind::$name,\n+                        make_query::$name,\n                         &mut jobs,\n                     )?;\n                 )*\n@@ -666,38 +584,8 @@ macro_rules! define_queries_struct {\n                 handler: &Handler,\n                 num_frames: Option<usize>,\n             ) -> usize {\n-                let query_map = self.try_collect_active_jobs();\n-\n-                let mut current_query = query;\n-                let mut i = 0;\n-\n-                while let Some(query) = current_query {\n-                    if Some(i) == num_frames {\n-                        break;\n-                    }\n-                    let query_info = if let Some(info) = query_map.as_ref().and_then(|map| map.get(&query))\n-                    {\n-                        info\n-                    } else {\n-                        break;\n-                    };\n-                    let mut diag = Diagnostic::new(\n-                        Level::FailureNote,\n-                        &format!(\n-                            \"#{} [{}] {}\",\n-                            i,\n-                            query_info.info.query.name(),\n-                            query_info.info.query.describe(QueryCtxt { tcx, queries: self })\n-                        ),\n-                    );\n-                    diag.span = tcx.sess.source_map().guess_head_span(query_info.info.span).into();\n-                    handler.force_print_diagnostic(diag);\n-\n-                    current_query = query_info.job.parent;\n-                    i += 1;\n-                }\n-\n-                i\n+                let qcx = QueryCtxt { tcx, queries: self };\n+                rustc_query_system::query::print_query_stack(qcx, query, handler, num_frames)\n             }\n \n             $($(#[$attr])*"}, {"sha": "7d3357f8fa2eff274b375bdbe3d426a0dc94bb33", "filename": "compiler/rustc_query_system/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2FCargo.toml?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -16,6 +16,7 @@ rustc_errors = { path = \"../rustc_errors\" }\n rustc_macros = { path = \"../rustc_macros\" }\n rustc_index = { path = \"../rustc_index\" }\n rustc_serialize = { path = \"../rustc_serialize\" }\n+rustc_session = { path = \"../rustc_session\" }\n rustc_span = { path = \"../rustc_span\" }\n parking_lot = \"0.11\"\n smallvec = { version = \"1.6.1\", features = [\"union\", \"may_dangle\"] }"}, {"sha": "f55e2f777a26a7be9c7b7a6abd04d2792f1898db", "filename": "compiler/rustc_query_system/src/dep_graph/dep_node.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fdep_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fdep_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fdep_node.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -87,7 +87,10 @@ impl<K: DepKind> DepNode<K> {\n \n         #[cfg(debug_assertions)]\n         {\n-            if !kind.can_reconstruct_query_key() && tcx.debug_dep_node() {\n+            if !kind.can_reconstruct_query_key()\n+                && (tcx.sess().opts.debugging_opts.incremental_info\n+                    || tcx.sess().opts.debugging_opts.query_dep_graph)\n+            {\n                 tcx.dep_graph().register_dep_node_debug_str(dep_node, || arg.to_debug_str(tcx));\n             }\n         }"}, {"sha": "0f25572170f53dae1d539a43fcb26662d17862fa", "filename": "compiler/rustc_query_system/src/dep_graph/graph.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -280,7 +280,7 @@ impl<K: DepKind> DepGraph<K> {\n             let mut hcx = dcx.create_stable_hashing_context();\n             let current_fingerprint = hash_result(&mut hcx, &result);\n \n-            let print_status = cfg!(debug_assertions) && dcx.debug_dep_tasks();\n+            let print_status = cfg!(debug_assertions) && dcx.sess().opts.debugging_opts.dep_tasks;\n \n             // Intern the new `DepNode`.\n             let dep_node_index = if let Some(prev_index) = data.previous.node_to_index_opt(&key) {\n@@ -731,7 +731,7 @@ impl<K: DepKind> DepGraph<K> {\n                                 return None;\n                             }\n                             None => {\n-                                if !tcx.has_errors_or_delayed_span_bugs() {\n+                                if !tcx.dep_context().sess().has_errors_or_delayed_span_bugs() {\n                                     panic!(\n                                         \"try_mark_previous_green() - Forcing the DepNode \\\n                                           should have set its color\"\n@@ -835,7 +835,7 @@ impl<K: DepKind> DepGraph<K> {\n             // Promote the previous diagnostics to the current session.\n             tcx.store_diagnostics(dep_node_index, diagnostics.clone().into());\n \n-            let handle = tcx.diagnostic();\n+            let handle = tcx.dep_context().sess().diagnostic();\n \n             for diagnostic in diagnostics {\n                 handle.emit_diagnostic(&diagnostic);"}, {"sha": "e8fb71be3e08ffcb25c72829c7180b5f840fbadd", "filename": "compiler/rustc_query_system/src/dep_graph/mod.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fmod.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -13,6 +13,7 @@ pub use serialized::{SerializedDepGraph, SerializedDepNodeIndex};\n \n use rustc_data_structures::profiling::SelfProfilerRef;\n use rustc_data_structures::sync::Lock;\n+use rustc_session::Session;\n \n use std::fmt;\n use std::hash::Hash;\n@@ -24,16 +25,16 @@ pub trait DepContext: Copy {\n     /// Create a hashing context for hashing new results.\n     fn create_stable_hashing_context(&self) -> Self::StableHashingContext;\n \n-    fn debug_dep_tasks(&self) -> bool;\n-    fn debug_dep_node(&self) -> bool;\n-\n     /// Access the DepGraph.\n     fn dep_graph(&self) -> &DepGraph<Self::DepKind>;\n \n     fn register_reused_dep_node(&self, dep_node: &DepNode<Self::DepKind>);\n \n     /// Access the profiler.\n     fn profiler(&self) -> &SelfProfilerRef;\n+\n+    /// Access the compiler session.\n+    fn sess(&self) -> &Session;\n }\n \n pub trait HasDepContext: Copy {"}, {"sha": "4e2515c3ac3fa209b3768815713ceb18a795e0b7", "filename": "compiler/rustc_query_system/src/query/config.rs", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -3,10 +3,10 @@\n use crate::dep_graph::DepNode;\n use crate::dep_graph::SerializedDepNodeIndex;\n use crate::query::caches::QueryCache;\n-use crate::query::plumbing::CycleError;\n use crate::query::{QueryCacheStore, QueryContext, QueryState};\n \n use rustc_data_structures::fingerprint::Fingerprint;\n+use rustc_errors::DiagnosticBuilder;\n use std::fmt::Debug;\n use std::hash::Hash;\n \n@@ -27,7 +27,7 @@ pub(crate) struct QueryVtable<CTX: QueryContext, K, V> {\n     pub compute: fn(CTX, K) -> V,\n \n     pub hash_result: fn(&mut CTX::StableHashingContext, &V) -> Option<Fingerprint>,\n-    pub handle_cycle_error: fn(CTX, CycleError<CTX::Query>) -> V,\n+    pub handle_cycle_error: fn(CTX, DiagnosticBuilder<'_>) -> V,\n     pub cache_on_disk: fn(CTX, &K, Option<&V>) -> bool,\n     pub try_load_from_disk: fn(CTX, SerializedDepNodeIndex) -> Option<V>,\n }\n@@ -52,8 +52,8 @@ impl<CTX: QueryContext, K, V> QueryVtable<CTX, K, V> {\n         (self.hash_result)(hcx, value)\n     }\n \n-    pub(crate) fn handle_cycle_error(&self, tcx: CTX, error: CycleError<CTX::Query>) -> V {\n-        (self.handle_cycle_error)(tcx, error)\n+    pub(crate) fn handle_cycle_error(&self, tcx: CTX, diag: DiagnosticBuilder<'_>) -> V {\n+        (self.handle_cycle_error)(tcx, diag)\n     }\n \n     pub(crate) fn cache_on_disk(&self, tcx: CTX, key: &K, value: Option<&V>) -> bool {\n@@ -73,7 +73,9 @@ pub trait QueryAccessors<CTX: QueryContext>: QueryConfig {\n     type Cache: QueryCache<Key = Self::Key, Stored = Self::Stored, Value = Self::Value>;\n \n     // Don't use this method to access query results, instead use the methods on TyCtxt\n-    fn query_state<'a>(tcx: CTX) -> &'a QueryState<CTX::DepKind, CTX::Query, Self::Key>;\n+    fn query_state<'a>(tcx: CTX) -> &'a QueryState<CTX::DepKind, Self::Key>\n+    where\n+        CTX: 'a;\n \n     // Don't use this method to access query results, instead use the methods on TyCtxt\n     fn query_cache<'a>(tcx: CTX) -> &'a QueryCacheStore<Self::Cache>\n@@ -88,7 +90,7 @@ pub trait QueryAccessors<CTX: QueryContext>: QueryConfig {\n         result: &Self::Value,\n     ) -> Option<Fingerprint>;\n \n-    fn handle_cycle_error(tcx: CTX, error: CycleError<CTX::Query>) -> Self::Value;\n+    fn handle_cycle_error(tcx: CTX, diag: DiagnosticBuilder<'_>) -> Self::Value;\n }\n \n pub trait QueryDescription<CTX: QueryContext>: QueryAccessors<CTX> {"}, {"sha": "35a2ac865f2595ab1f2b20eff93a0863ccdf0da9", "filename": "compiler/rustc_query_system/src/query/job.rs", "status": "modified", "additions": 130, "deletions": 69, "changes": 199, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -1,6 +1,10 @@\n+use crate::dep_graph::DepContext;\n use crate::query::plumbing::CycleError;\n+use crate::query::{QueryContext, QueryStackFrame};\n \n use rustc_data_structures::fx::FxHashMap;\n+use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, Handler, Level};\n+use rustc_session::Session;\n use rustc_span::Span;\n \n use std::convert::TryFrom;\n@@ -10,11 +14,9 @@ use std::num::NonZeroU32;\n \n #[cfg(parallel_compiler)]\n use {\n-    crate::dep_graph::DepContext,\n-    crate::query::QueryContext,\n+    crate::dep_graph::DepKind,\n     parking_lot::{Condvar, Mutex},\n     rustc_data_structures::fx::FxHashSet,\n-    rustc_data_structures::stable_hasher::{HashStable, StableHasher},\n     rustc_data_structures::sync::Lock,\n     rustc_data_structures::sync::Lrc,\n     rustc_data_structures::{jobserver, OnDrop},\n@@ -26,13 +28,13 @@ use {\n \n /// Represents a span and a query key.\n #[derive(Clone, Debug)]\n-pub struct QueryInfo<Q> {\n+pub struct QueryInfo {\n     /// The span corresponding to the reason for which this query was required.\n     pub span: Span,\n-    pub query: Q,\n+    pub query: QueryStackFrame,\n }\n \n-pub(crate) type QueryMap<D, Q> = FxHashMap<QueryJobId<D>, QueryJobInfo<D, Q>>;\n+pub type QueryMap<D> = FxHashMap<QueryJobId<D>, QueryJobInfo<D>>;\n \n /// A value uniquely identifying an active query job within a shard in the query cache.\n #[derive(Copy, Clone, Eq, PartialEq, Hash)]\n@@ -59,34 +61,34 @@ where\n         QueryJobId { job, shard: u16::try_from(shard).unwrap(), kind }\n     }\n \n-    fn query<Q: Clone>(self, map: &QueryMap<D, Q>) -> Q {\n+    fn query(self, map: &QueryMap<D>) -> QueryStackFrame {\n         map.get(&self).unwrap().info.query.clone()\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn span<Q: Clone>(self, map: &QueryMap<D, Q>) -> Span {\n+    fn span(self, map: &QueryMap<D>) -> Span {\n         map.get(&self).unwrap().job.span\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn parent<Q: Clone>(self, map: &QueryMap<D, Q>) -> Option<QueryJobId<D>> {\n+    fn parent(self, map: &QueryMap<D>) -> Option<QueryJobId<D>> {\n         map.get(&self).unwrap().job.parent\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn latch<'a, Q: Clone>(self, map: &'a QueryMap<D, Q>) -> Option<&'a QueryLatch<D, Q>> {\n+    fn latch<'a>(self, map: &'a QueryMap<D>) -> Option<&'a QueryLatch<D>> {\n         map.get(&self).unwrap().job.latch.as_ref()\n     }\n }\n \n-pub struct QueryJobInfo<D, Q> {\n-    pub info: QueryInfo<Q>,\n-    pub job: QueryJob<D, Q>,\n+pub struct QueryJobInfo<D> {\n+    pub info: QueryInfo,\n+    pub job: QueryJob<D>,\n }\n \n /// Represents an active query job.\n #[derive(Clone)]\n-pub struct QueryJob<D, Q> {\n+pub struct QueryJob<D> {\n     pub id: QueryShardJobId,\n \n     /// The span corresponding to the reason for which this query was required.\n@@ -97,15 +99,14 @@ pub struct QueryJob<D, Q> {\n \n     /// The latch that is used to wait on this job.\n     #[cfg(parallel_compiler)]\n-    latch: Option<QueryLatch<D, Q>>,\n+    latch: Option<QueryLatch<D>>,\n \n-    dummy: PhantomData<QueryLatch<D, Q>>,\n+    dummy: PhantomData<QueryLatch<D>>,\n }\n \n-impl<D, Q> QueryJob<D, Q>\n+impl<D> QueryJob<D>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n {\n     /// Creates a new query job.\n     pub fn new(id: QueryShardJobId, span: Span, parent: Option<QueryJobId<D>>) -> Self {\n@@ -120,16 +121,16 @@ where\n     }\n \n     #[cfg(parallel_compiler)]\n-    pub(super) fn latch(&mut self, _id: QueryJobId<D>) -> QueryLatch<D, Q> {\n+    pub(super) fn latch(&mut self, _id: QueryJobId<D>) -> QueryLatch<D> {\n         if self.latch.is_none() {\n             self.latch = Some(QueryLatch::new());\n         }\n         self.latch.as_ref().unwrap().clone()\n     }\n \n     #[cfg(not(parallel_compiler))]\n-    pub(super) fn latch(&mut self, id: QueryJobId<D>) -> QueryLatch<D, Q> {\n-        QueryLatch { id, dummy: PhantomData }\n+    pub(super) fn latch(&mut self, id: QueryJobId<D>) -> QueryLatch<D> {\n+        QueryLatch { id }\n     }\n \n     /// Signals to waiters that the query is complete.\n@@ -148,23 +149,21 @@ where\n \n #[cfg(not(parallel_compiler))]\n #[derive(Clone)]\n-pub(super) struct QueryLatch<D, Q> {\n+pub(super) struct QueryLatch<D> {\n     id: QueryJobId<D>,\n-    dummy: PhantomData<Q>,\n }\n \n #[cfg(not(parallel_compiler))]\n-impl<D, Q> QueryLatch<D, Q>\n+impl<D> QueryLatch<D>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n {\n     pub(super) fn find_cycle_in_stack(\n         &self,\n-        query_map: QueryMap<D, Q>,\n+        query_map: QueryMap<D>,\n         current_job: &Option<QueryJobId<D>>,\n         span: Span,\n-    ) -> CycleError<Q> {\n+    ) -> CycleError {\n         // Find the waitee amongst `current_job` parents\n         let mut cycle = Vec::new();\n         let mut current_job = Option::clone(current_job);\n@@ -198,35 +197,35 @@ where\n }\n \n #[cfg(parallel_compiler)]\n-struct QueryWaiter<D, Q> {\n+struct QueryWaiter<D> {\n     query: Option<QueryJobId<D>>,\n     condvar: Condvar,\n     span: Span,\n-    cycle: Lock<Option<CycleError<Q>>>,\n+    cycle: Lock<Option<CycleError>>,\n }\n \n #[cfg(parallel_compiler)]\n-impl<D, Q> QueryWaiter<D, Q> {\n+impl<D> QueryWaiter<D> {\n     fn notify(&self, registry: &rayon_core::Registry) {\n         rayon_core::mark_unblocked(registry);\n         self.condvar.notify_one();\n     }\n }\n \n #[cfg(parallel_compiler)]\n-struct QueryLatchInfo<D, Q> {\n+struct QueryLatchInfo<D> {\n     complete: bool,\n-    waiters: Vec<Lrc<QueryWaiter<D, Q>>>,\n+    waiters: Vec<Lrc<QueryWaiter<D>>>,\n }\n \n #[cfg(parallel_compiler)]\n #[derive(Clone)]\n-pub(super) struct QueryLatch<D, Q> {\n-    info: Lrc<Mutex<QueryLatchInfo<D, Q>>>,\n+pub(super) struct QueryLatch<D> {\n+    info: Lrc<Mutex<QueryLatchInfo<D>>>,\n }\n \n #[cfg(parallel_compiler)]\n-impl<D: Eq + Hash, Q: Clone> QueryLatch<D, Q> {\n+impl<D: Eq + Hash> QueryLatch<D> {\n     fn new() -> Self {\n         QueryLatch {\n             info: Lrc::new(Mutex::new(QueryLatchInfo { complete: false, waiters: Vec::new() })),\n@@ -235,13 +234,13 @@ impl<D: Eq + Hash, Q: Clone> QueryLatch<D, Q> {\n }\n \n #[cfg(parallel_compiler)]\n-impl<D, Q> QueryLatch<D, Q> {\n+impl<D> QueryLatch<D> {\n     /// Awaits for the query job to complete.\n     pub(super) fn wait_on(\n         &self,\n         query: Option<QueryJobId<D>>,\n         span: Span,\n-    ) -> Result<(), CycleError<Q>> {\n+    ) -> Result<(), CycleError> {\n         let waiter =\n             Lrc::new(QueryWaiter { query, span, cycle: Lock::new(None), condvar: Condvar::new() });\n         self.wait_on_inner(&waiter);\n@@ -256,7 +255,7 @@ impl<D, Q> QueryLatch<D, Q> {\n     }\n \n     /// Awaits the caller on this latch by blocking the current thread.\n-    fn wait_on_inner(&self, waiter: &Lrc<QueryWaiter<D, Q>>) {\n+    fn wait_on_inner(&self, waiter: &Lrc<QueryWaiter<D>>) {\n         let mut info = self.info.lock();\n         if !info.complete {\n             // We push the waiter on to the `waiters` list. It can be accessed inside\n@@ -290,7 +289,7 @@ impl<D, Q> QueryLatch<D, Q> {\n \n     /// Removes a single waiter from the list of waiters.\n     /// This is used to break query cycles.\n-    fn extract_waiter(&self, waiter: usize) -> Lrc<QueryWaiter<D, Q>> {\n+    fn extract_waiter(&self, waiter: usize) -> Lrc<QueryWaiter<D>> {\n         let mut info = self.info.lock();\n         debug_assert!(!info.complete);\n         // Remove the waiter from the list of waiters\n@@ -312,14 +311,13 @@ type Waiter<D> = (QueryJobId<D>, usize);\n /// required information to resume the waiter.\n /// If all `visit` calls returns None, this function also returns None.\n #[cfg(parallel_compiler)]\n-fn visit_waiters<D, Q, F>(\n-    query_map: &QueryMap<D, Q>,\n+fn visit_waiters<D, F>(\n+    query_map: &QueryMap<D>,\n     query: QueryJobId<D>,\n     mut visit: F,\n ) -> Option<Option<Waiter<D>>>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     F: FnMut(Span, QueryJobId<D>) -> Option<Option<Waiter<D>>>,\n {\n     // Visit the parent query which is a non-resumable waiter since it's on the same stack\n@@ -349,16 +347,15 @@ where\n /// If a cycle is detected, this initial value is replaced with the span causing\n /// the cycle.\n #[cfg(parallel_compiler)]\n-fn cycle_check<D, Q>(\n-    query_map: &QueryMap<D, Q>,\n+fn cycle_check<D>(\n+    query_map: &QueryMap<D>,\n     query: QueryJobId<D>,\n     span: Span,\n     stack: &mut Vec<(Span, QueryJobId<D>)>,\n     visited: &mut FxHashSet<QueryJobId<D>>,\n ) -> Option<Option<Waiter<D>>>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n {\n     if !visited.insert(query) {\n         return if let Some(p) = stack.iter().position(|q| q.1 == query) {\n@@ -394,14 +391,13 @@ where\n /// from `query` without going through any of the queries in `visited`.\n /// This is achieved with a depth first search.\n #[cfg(parallel_compiler)]\n-fn connected_to_root<D, Q>(\n-    query_map: &QueryMap<D, Q>,\n+fn connected_to_root<D>(\n+    query_map: &QueryMap<D>,\n     query: QueryJobId<D>,\n     visited: &mut FxHashSet<QueryJobId<D>>,\n ) -> bool\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n {\n     // We already visited this or we're deliberately ignoring it\n     if !visited.insert(query) {\n@@ -421,30 +417,23 @@ where\n \n // Deterministically pick an query from a list\n #[cfg(parallel_compiler)]\n-fn pick_query<'a, CTX, T, F>(\n-    query_map: &QueryMap<CTX::DepKind, CTX::Query>,\n-    tcx: CTX,\n-    queries: &'a [T],\n-    f: F,\n-) -> &'a T\n+fn pick_query<'a, D, T, F>(query_map: &QueryMap<D>, queries: &'a [T], f: F) -> &'a T\n where\n-    CTX: QueryContext,\n-    F: Fn(&T) -> (Span, QueryJobId<CTX::DepKind>),\n+    D: Copy + Clone + Eq + Hash,\n+    F: Fn(&T) -> (Span, QueryJobId<D>),\n {\n     // Deterministically pick an entry point\n     // FIXME: Sort this instead\n-    let mut hcx = tcx.dep_context().create_stable_hashing_context();\n     queries\n         .iter()\n         .min_by_key(|v| {\n             let (span, query) = f(v);\n-            let mut stable_hasher = StableHasher::new();\n-            query.query(query_map).hash_stable(&mut hcx, &mut stable_hasher);\n+            let hash = query.query(query_map).hash;\n             // Prefer entry points which have valid spans for nicer error messages\n             // We add an integer to the tuple ensuring that entry points\n             // with valid spans are picked first\n             let span_cmp = if span == DUMMY_SP { 1 } else { 0 };\n-            (span_cmp, stable_hasher.finish::<u64>())\n+            (span_cmp, hash)\n         })\n         .unwrap()\n }\n@@ -455,11 +444,10 @@ where\n /// If a cycle was not found, the starting query is removed from `jobs` and\n /// the function returns false.\n #[cfg(parallel_compiler)]\n-fn remove_cycle<CTX: QueryContext>(\n-    query_map: &QueryMap<CTX::DepKind, CTX::Query>,\n-    jobs: &mut Vec<QueryJobId<CTX::DepKind>>,\n-    wakelist: &mut Vec<Lrc<QueryWaiter<CTX::DepKind, CTX::Query>>>,\n-    tcx: CTX,\n+fn remove_cycle<D: DepKind>(\n+    query_map: &QueryMap<D>,\n+    jobs: &mut Vec<QueryJobId<D>>,\n+    wakelist: &mut Vec<Lrc<QueryWaiter<D>>>,\n ) -> bool {\n     let mut visited = FxHashSet::default();\n     let mut stack = Vec::new();\n@@ -509,15 +497,15 @@ fn remove_cycle<CTX: QueryContext>(\n                         None\n                     } else {\n                         // Deterministically pick one of the waiters to show to the user\n-                        let waiter = *pick_query(query_map, tcx, &waiters, |s| *s);\n+                        let waiter = *pick_query(query_map, &waiters, |s| *s);\n                         Some((span, query, Some(waiter)))\n                     }\n                 }\n             })\n-            .collect::<Vec<(Span, QueryJobId<CTX::DepKind>, Option<(Span, QueryJobId<CTX::DepKind>)>)>>();\n+            .collect::<Vec<(Span, QueryJobId<D>, Option<(Span, QueryJobId<D>)>)>>();\n \n         // Deterministically pick an entry point\n-        let (_, entry_point, usage) = pick_query(query_map, tcx, &entry_points, |e| (e.0, e.1));\n+        let (_, entry_point, usage) = pick_query(query_map, &entry_points, |e| (e.0, e.1));\n \n         // Shift the stack so that our entry point is first\n         let entry_point_pos = stack.iter().position(|(_, query)| query == entry_point);\n@@ -574,7 +562,7 @@ pub fn deadlock<CTX: QueryContext>(tcx: CTX, registry: &rayon_core::Registry) {\n     let mut found_cycle = false;\n \n     while jobs.len() > 0 {\n-        if remove_cycle(&query_map, &mut jobs, &mut wakelist, tcx) {\n+        if remove_cycle(&query_map, &mut jobs, &mut wakelist) {\n             found_cycle = true;\n         }\n     }\n@@ -595,3 +583,76 @@ pub fn deadlock<CTX: QueryContext>(tcx: CTX, registry: &rayon_core::Registry) {\n \n     on_panic.disable();\n }\n+\n+#[inline(never)]\n+#[cold]\n+pub(crate) fn report_cycle<'a>(\n+    sess: &'a Session,\n+    CycleError { usage, cycle: stack }: CycleError,\n+) -> DiagnosticBuilder<'a> {\n+    assert!(!stack.is_empty());\n+\n+    let fix_span = |span: Span, query: &QueryStackFrame| {\n+        sess.source_map().guess_head_span(query.default_span(span))\n+    };\n+\n+    let span = fix_span(stack[1 % stack.len()].span, &stack[0].query);\n+    let mut err =\n+        struct_span_err!(sess, span, E0391, \"cycle detected when {}\", stack[0].query.description);\n+\n+    for i in 1..stack.len() {\n+        let query = &stack[i].query;\n+        let span = fix_span(stack[(i + 1) % stack.len()].span, query);\n+        err.span_note(span, &format!(\"...which requires {}...\", query.description));\n+    }\n+\n+    err.note(&format!(\n+        \"...which again requires {}, completing the cycle\",\n+        stack[0].query.description\n+    ));\n+\n+    if let Some((span, query)) = usage {\n+        err.span_note(fix_span(span, &query), &format!(\"cycle used when {}\", query.description));\n+    }\n+\n+    err\n+}\n+\n+pub fn print_query_stack<CTX: QueryContext>(\n+    tcx: CTX,\n+    mut current_query: Option<QueryJobId<CTX::DepKind>>,\n+    handler: &Handler,\n+    num_frames: Option<usize>,\n+) -> usize {\n+    // Be careful relying on global state here: this code is called from\n+    // a panic hook, which means that the global `Handler` may be in a weird\n+    // state if it was responsible for triggering the panic.\n+    let mut i = 0;\n+    let query_map = tcx.try_collect_active_jobs();\n+\n+    while let Some(query) = current_query {\n+        if Some(i) == num_frames {\n+            break;\n+        }\n+        let query_info = if let Some(info) = query_map.as_ref().and_then(|map| map.get(&query)) {\n+            info\n+        } else {\n+            break;\n+        };\n+        let mut diag = Diagnostic::new(\n+            Level::FailureNote,\n+            &format!(\n+                \"#{} [{}] {}\",\n+                i, query_info.info.query.name, query_info.info.query.description\n+            ),\n+        );\n+        diag.span =\n+            tcx.dep_context().sess().source_map().guess_head_span(query_info.info.span).into();\n+        handler.force_print_diagnostic(diag);\n+\n+        current_query = query_info.job.parent;\n+        i += 1;\n+    }\n+\n+    i\n+}"}, {"sha": "aef8a13ccef3297f80006f255eb6fcb353dc637b", "filename": "compiler/rustc_query_system/src/query/mod.rs", "status": "modified", "additions": 44, "deletions": 15, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fmod.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -4,7 +4,7 @@ pub use self::plumbing::*;\n mod job;\n #[cfg(parallel_compiler)]\n pub use self::job::deadlock;\n-pub use self::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n+pub use self::job::{print_query_stack, QueryInfo, QueryJob, QueryJobId, QueryJobInfo, QueryMap};\n \n mod caches;\n pub use self::caches::{\n@@ -15,40 +15,69 @@ mod config;\n pub use self::config::{QueryAccessors, QueryConfig, QueryDescription};\n \n use crate::dep_graph::{DepNode, DepNodeIndex, HasDepContext, SerializedDepNodeIndex};\n-use crate::query::job::QueryMap;\n \n-use rustc_data_structures::stable_hasher::HashStable;\n use rustc_data_structures::sync::Lock;\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::Diagnostic;\n use rustc_span::def_id::DefId;\n+use rustc_span::Span;\n+\n+/// Description of a frame in the query stack.\n+///\n+/// This is mostly used in case of cycles for error reporting.\n+#[derive(Clone, Debug)]\n+pub struct QueryStackFrame {\n+    pub name: &'static str,\n+    pub description: String,\n+    span: Option<Span>,\n+    /// This hash is used to deterministically pick\n+    /// a query to remove cycles in the parallel compiler.\n+    #[cfg(parallel_compiler)]\n+    hash: u64,\n+}\n \n-pub trait QueryContext: HasDepContext {\n-    type Query: Clone + HashStable<Self::StableHashingContext>;\n-\n-    fn incremental_verify_ich(&self) -> bool;\n-    fn verbose(&self) -> bool;\n+impl QueryStackFrame {\n+    #[inline]\n+    pub fn new(\n+        name: &'static str,\n+        description: String,\n+        span: Option<Span>,\n+        _hash: impl FnOnce() -> u64,\n+    ) -> Self {\n+        Self {\n+            name,\n+            description,\n+            span,\n+            #[cfg(parallel_compiler)]\n+            hash: _hash(),\n+        }\n+    }\n+\n+    // FIXME(eddyb) Get more valid `Span`s on queries.\n+    #[inline]\n+    pub fn default_span(&self, span: Span) -> Span {\n+        if !span.is_dummy() {\n+            return span;\n+        }\n+        self.span.unwrap_or(span)\n+    }\n+}\n \n+pub trait QueryContext: HasDepContext {\n     /// Get string representation from DefPath.\n     fn def_path_str(&self, def_id: DefId) -> String;\n \n     /// Get the query information from the TLS context.\n     fn current_query_job(&self) -> Option<QueryJobId<Self::DepKind>>;\n \n-    fn try_collect_active_jobs(&self) -> Option<QueryMap<Self::DepKind, Self::Query>>;\n+    fn try_collect_active_jobs(&self) -> Option<QueryMap<Self::DepKind>>;\n \n     /// Load data from the on-disk cache.\n     fn try_load_from_on_disk_cache(&self, dep_node: &DepNode<Self::DepKind>);\n \n     /// Try to force a dep node to execute and see if it's green.\n     fn try_force_from_dep_node(&self, dep_node: &DepNode<Self::DepKind>) -> bool;\n \n-    /// Return whether the current session is tainted by errors.\n-    fn has_errors_or_delayed_span_bugs(&self) -> bool;\n-\n-    /// Return the diagnostic handler.\n-    fn diagnostic(&self) -> &rustc_errors::Handler;\n-\n     /// Load diagnostics associated to the node in the previous session.\n     fn load_diagnostics(&self, prev_dep_node_index: SerializedDepNodeIndex) -> Vec<Diagnostic>;\n "}, {"sha": "0050670b338ea572b2dad1d2a6f9e83cac1f4fcd", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 41, "deletions": 41, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad8a4fa3ea56fb980443b7997c8f9d72dd717/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=301ad8a4fa3ea56fb980443b7997c8f9d72dd717", "patch": "@@ -6,8 +6,10 @@ use crate::dep_graph::{DepContext, DepKind, DepNode};\n use crate::dep_graph::{DepNodeIndex, SerializedDepNodeIndex};\n use crate::query::caches::QueryCache;\n use crate::query::config::{QueryDescription, QueryVtable, QueryVtableExt};\n-use crate::query::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo, QueryShardJobId};\n-use crate::query::{QueryContext, QueryMap};\n+use crate::query::job::{\n+    report_cycle, QueryInfo, QueryJob, QueryJobId, QueryJobInfo, QueryShardJobId,\n+};\n+use crate::query::{QueryContext, QueryMap, QueryStackFrame};\n \n #[cfg(not(parallel_compiler))]\n use rustc_data_structures::cold_path;\n@@ -81,49 +83,49 @@ impl<C: QueryCache> QueryCacheStore<C> {\n     }\n }\n \n-struct QueryStateShard<D, Q, K> {\n-    active: FxHashMap<K, QueryResult<D, Q>>,\n+struct QueryStateShard<D, K> {\n+    active: FxHashMap<K, QueryResult<D>>,\n \n     /// Used to generate unique ids for active jobs.\n     jobs: u32,\n }\n \n-impl<D, Q, K> Default for QueryStateShard<D, Q, K> {\n-    fn default() -> QueryStateShard<D, Q, K> {\n+impl<D, K> Default for QueryStateShard<D, K> {\n+    fn default() -> QueryStateShard<D, K> {\n         QueryStateShard { active: Default::default(), jobs: 0 }\n     }\n }\n \n-pub struct QueryState<D, Q, K> {\n-    shards: Sharded<QueryStateShard<D, Q, K>>,\n+pub struct QueryState<D, K> {\n+    shards: Sharded<QueryStateShard<D, K>>,\n }\n \n /// Indicates the state of a query for a given key in a query map.\n-enum QueryResult<D, Q> {\n+enum QueryResult<D> {\n     /// An already executing query. The query job can be used to await for its completion.\n-    Started(QueryJob<D, Q>),\n+    Started(QueryJob<D>),\n \n     /// The query panicked. Queries trying to wait on this will raise a fatal error which will\n     /// silently panic.\n     Poisoned,\n }\n \n-impl<D, Q, K> QueryState<D, Q, K>\n+impl<D, K> QueryState<D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     K: Eq + Hash + Clone + Debug,\n {\n     pub fn all_inactive(&self) -> bool {\n         let shards = self.shards.lock_shards();\n         shards.iter().all(|shard| shard.active.is_empty())\n     }\n \n-    pub fn try_collect_active_jobs(\n+    pub fn try_collect_active_jobs<CTX: Copy>(\n         &self,\n+        tcx: CTX,\n         kind: D,\n-        make_query: fn(K) -> Q,\n-        jobs: &mut QueryMap<D, Q>,\n+        make_query: fn(CTX, K) -> QueryStackFrame,\n+        jobs: &mut QueryMap<D>,\n     ) -> Option<()> {\n         // We use try_lock_shards here since we are called from the\n         // deadlock handler, and this shouldn't be locked.\n@@ -133,7 +135,7 @@ where\n             shard.active.iter().filter_map(move |(k, v)| {\n                 if let QueryResult::Started(ref job) = *v {\n                     let id = QueryJobId::new(job.id, shard_id, kind);\n-                    let info = QueryInfo { span: job.span, query: make_query(k.clone()) };\n+                    let info = QueryInfo { span: job.span, query: make_query(tcx, k.clone()) };\n                     Some((id, QueryJobInfo { info, job: job.clone() }))\n                 } else {\n                     None\n@@ -145,30 +147,28 @@ where\n     }\n }\n \n-impl<D, Q, K> Default for QueryState<D, Q, K> {\n-    fn default() -> QueryState<D, Q, K> {\n+impl<D, K> Default for QueryState<D, K> {\n+    fn default() -> QueryState<D, K> {\n         QueryState { shards: Default::default() }\n     }\n }\n \n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n-struct JobOwner<'tcx, D, Q, C>\n+struct JobOwner<'tcx, D, C>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     C: QueryCache,\n {\n-    state: &'tcx QueryState<D, Q, C::Key>,\n+    state: &'tcx QueryState<D, C::Key>,\n     cache: &'tcx QueryCacheStore<C>,\n     key: C::Key,\n     id: QueryJobId<D>,\n }\n \n-impl<'tcx, D, Q, C> JobOwner<'tcx, D, Q, C>\n+impl<'tcx, D, C> JobOwner<'tcx, D, C>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     C: QueryCache,\n {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n@@ -182,13 +182,13 @@ where\n     #[inline(always)]\n     fn try_start<'b, CTX>(\n         tcx: CTX,\n-        state: &'b QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+        state: &'b QueryState<CTX::DepKind, C::Key>,\n         cache: &'b QueryCacheStore<C>,\n         span: Span,\n         key: &C::Key,\n         lookup: QueryLookup,\n         query: &QueryVtable<CTX, C::Key, C::Value>,\n-    ) -> TryGetJob<'b, CTX::DepKind, CTX::Query, C>\n+    ) -> TryGetJob<'b, CTX::DepKind, C>\n     where\n         CTX: QueryContext,\n     {\n@@ -242,11 +242,12 @@ where\n         // so we just return the error.\n         #[cfg(not(parallel_compiler))]\n         return TryGetJob::Cycle(cold_path(|| {\n-            let error: CycleError<CTX::Query> = latch.find_cycle_in_stack(\n+            let error: CycleError = latch.find_cycle_in_stack(\n                 tcx.try_collect_active_jobs().unwrap(),\n                 &tcx.current_query_job(),\n                 span,\n             );\n+            let error = report_cycle(tcx.dep_context().sess(), error);\n             let value = query.handle_cycle_error(tcx, error);\n             cache.cache.store_nocache(value)\n         }));\n@@ -258,6 +259,7 @@ where\n             let result = latch.wait_on(tcx.current_query_job(), span);\n \n             if let Err(cycle) = result {\n+                let cycle = report_cycle(tcx.dep_context().sess(), cycle);\n                 let value = query.handle_cycle_error(tcx, cycle);\n                 let value = cache.cache.store_nocache(value);\n                 return TryGetJob::Cycle(value);\n@@ -327,10 +329,9 @@ where\n     (result, diagnostics.into_inner())\n }\n \n-impl<'tcx, D, Q, C> Drop for JobOwner<'tcx, D, Q, C>\n+impl<'tcx, D, C> Drop for JobOwner<'tcx, D, C>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     C: QueryCache,\n {\n     #[inline(never)]\n@@ -355,21 +356,20 @@ where\n }\n \n #[derive(Clone)]\n-pub struct CycleError<Q> {\n+pub(crate) struct CycleError {\n     /// The query and related span that uses the cycle.\n-    pub usage: Option<(Span, Q)>,\n-    pub cycle: Vec<QueryInfo<Q>>,\n+    pub usage: Option<(Span, QueryStackFrame)>,\n+    pub cycle: Vec<QueryInfo>,\n }\n \n /// The result of `try_start`.\n-enum TryGetJob<'tcx, D, Q, C>\n+enum TryGetJob<'tcx, D, C>\n where\n     D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     C: QueryCache,\n {\n     /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'tcx, D, Q, C>),\n+    NotYetStarted(JobOwner<'tcx, D, C>),\n \n     /// The query was already completed.\n     /// Returns the result of the query and its dep-node index\n@@ -413,7 +413,7 @@ where\n \n fn try_execute_query<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+    state: &QueryState<CTX::DepKind, C::Key>,\n     cache: &QueryCacheStore<C>,\n     span: Span,\n     key: C::Key,\n@@ -425,7 +425,7 @@ where\n     C::Key: crate::dep_graph::DepNodeParams<CTX::DepContext>,\n     CTX: QueryContext,\n {\n-    let job = match JobOwner::<'_, CTX::DepKind, CTX::Query, C>::try_start(\n+    let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n         tcx, state, cache, span, &key, lookup, query,\n     ) {\n         TryGetJob::NotYetStarted(job) => job,\n@@ -550,7 +550,7 @@ where\n \n     // If `-Zincremental-verify-ich` is specified, re-hash results from\n     // the cache and make sure that they have the expected fingerprint.\n-    if unlikely!(tcx.incremental_verify_ich()) {\n+    if unlikely!(tcx.dep_context().sess().opts.debugging_opts.incremental_verify_ich) {\n         incremental_verify_ich(*tcx.dep_context(), &result, dep_node, dep_node_index, query);\n     }\n \n@@ -589,7 +589,7 @@ fn incremental_verify_ich<CTX, K, V: Debug>(\n fn force_query_with_job<C, CTX>(\n     tcx: CTX,\n     key: C::Key,\n-    job: JobOwner<'_, CTX::DepKind, CTX::Query, C>,\n+    job: JobOwner<'_, CTX::DepKind, C>,\n     dep_node: DepNode<CTX::DepKind>,\n     query: &QueryVtable<CTX, C::Key, C::Value>,\n ) -> (C::Stored, DepNodeIndex)\n@@ -649,7 +649,7 @@ where\n #[inline(never)]\n fn get_query_impl<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+    state: &QueryState<CTX::DepKind, C::Key>,\n     cache: &QueryCacheStore<C>,\n     span: Span,\n     key: C::Key,\n@@ -707,7 +707,7 @@ where\n #[inline(never)]\n fn force_query_impl<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+    state: &QueryState<CTX::DepKind, C::Key>,\n     cache: &QueryCacheStore<C>,\n     key: C::Key,\n     span: Span,\n@@ -735,7 +735,7 @@ fn force_query_impl<CTX, C>(\n         Err(lookup) => lookup,\n     };\n \n-    let job = match JobOwner::<'_, CTX::DepKind, CTX::Query, C>::try_start(\n+    let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n         tcx, state, cache, span, &key, lookup, query,\n     ) {\n         TryGetJob::NotYetStarted(job) => job,"}]}