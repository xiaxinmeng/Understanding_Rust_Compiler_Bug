{"sha": "0cc7053efa243c117b0d9278a5a62eb62ecee227", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjYzcwNTNlZmEyNDNjMTE3YjBkOTI3OGE1YTYyZWI2MmVjZWUyMjc=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-30T23:48:14Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-02-28T22:15:09Z"}, "message": "Remove `Token::MatchNt`.", "tree": {"sha": "8e70a6cf999df43abf0d30f0dfaa5c036e1d23fa", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8e70a6cf999df43abf0d30f0dfaa5c036e1d23fa"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0cc7053efa243c117b0d9278a5a62eb62ecee227", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0cc7053efa243c117b0d9278a5a62eb62ecee227", "html_url": "https://github.com/rust-lang/rust/commit/0cc7053efa243c117b0d9278a5a62eb62ecee227", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0cc7053efa243c117b0d9278a5a62eb62ecee227/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d8b34e9a74a4e91c4283ba4002a050ac0150cec6", "url": "https://api.github.com/repos/rust-lang/rust/commits/d8b34e9a74a4e91c4283ba4002a050ac0150cec6", "html_url": "https://github.com/rust-lang/rust/commit/d8b34e9a74a4e91c4283ba4002a050ac0150cec6"}], "stats": {"total": 157, "additions": 79, "deletions": 78}, "files": [{"sha": "b075fa599924996650b2571afa356f312f2484c7", "filename": "src/librustc_incremental/calculate_svh/svh_visitor.rs", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibrustc_incremental%2Fcalculate_svh%2Fsvh_visitor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibrustc_incremental%2Fcalculate_svh%2Fsvh_visitor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fcalculate_svh%2Fsvh_visitor.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -1109,10 +1109,6 @@ impl<'a, 'hash, 'tcx> StrictVersionHashVisitor<'a, 'hash, 'tcx> {\n             token::Token::Ident(ident) |\n             token::Token::Lifetime(ident) |\n             token::Token::SubstNt(ident) => ident.name.as_str().hash(self.st),\n-            token::Token::MatchNt(ident1, ident2) => {\n-                ident1.name.as_str().hash(self.st);\n-                ident2.name.as_str().hash(self.st);\n-            }\n \n             token::Token::Interpolated(ref non_terminal) => {\n                 // FIXME(mw): This could be implemented properly. It's just a"}, {"sha": "2c15dd923237fe840362c352c72bac70d3756eca", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -315,7 +315,7 @@ impl<'a> Classifier<'a> {\n             token::Lifetime(..) => Class::Lifetime,\n \n             token::Underscore | token::Eof | token::Interpolated(..) |\n-            token::MatchNt(..) | token::SubstNt(..) | token::Tilde | token::At => Class::None,\n+            token::SubstNt(..) | token::Tilde | token::At => Class::None,\n         };\n \n         // Anything that didn't return above is the simple case where we the"}, {"sha": "a466fd2c6dbe5c96b25f6deca1c1c7bfbe879689", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 6, "deletions": 8, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -85,9 +85,7 @@ use errors::FatalError;\n use ext::tt::quoted;\n use parse::{Directory, ParseSess};\n use parse::parser::{PathStyle, Parser};\n-use parse::token::{DocComment, MatchNt};\n-use parse::token::{Token, Nonterminal};\n-use parse::token;\n+use parse::token::{self, DocComment, Token, Nonterminal};\n use print::pprust;\n use tokenstream::TokenTree;\n use util::small_vector::SmallVector;\n@@ -156,7 +154,7 @@ pub fn count_names(ms: &[quoted::TokenTree]) -> usize {\n             TokenTree::Delimited(_, ref delim) => {\n                 count_names(&delim.tts)\n             }\n-            TokenTree::Token(_, MatchNt(..)) => {\n+            TokenTree::MetaVarDecl(..) => {\n                 1\n             }\n             TokenTree::Token(..) => 0,\n@@ -221,7 +219,7 @@ fn nameize<I: Iterator<Item=Rc<NamedMatch>>>(ms: &[quoted::TokenTree], mut res:\n                     n_rec(next_m, res.by_ref(), ret_val)?;\n                 }\n             }\n-            TokenTree::Token(sp, MatchNt(bind_name, _)) => {\n+            TokenTree::MetaVarDecl(sp, bind_name, _) => {\n                 match ret_val.entry(bind_name) {\n                     Vacant(spot) => {\n                         spot.insert(res.next().unwrap());\n@@ -377,7 +375,7 @@ fn inner_parse_loop(cur_eis: &mut SmallVector<Box<MatcherPos>>,\n                         top_elts: Tt(TokenTree::Sequence(sp, seq)),\n                     }));\n                 }\n-                TokenTree::Token(_, MatchNt(..)) => {\n+                TokenTree::MetaVarDecl(..) => {\n                     // Built-in nonterminals never start with these tokens,\n                     // so we can eliminate them from consideration.\n                     match *token {\n@@ -445,7 +443,7 @@ pub fn parse(sess: &ParseSess,\n             }\n         } else if (!bb_eis.is_empty() && !next_eis.is_empty()) || bb_eis.len() > 1 {\n             let nts = bb_eis.iter().map(|ei| match ei.top_elts.get_tt(ei.idx) {\n-                TokenTree::Token(_, MatchNt(bind, name)) => {\n+                TokenTree::MetaVarDecl(_, bind, name) => {\n                     format!(\"{} ('{}')\", name, bind)\n                 }\n                 _ => panic!()\n@@ -467,7 +465,7 @@ pub fn parse(sess: &ParseSess,\n             parser.bump();\n         } else /* bb_eis.len() == 1 */ {\n             let mut ei = bb_eis.pop().unwrap();\n-            if let TokenTree::Token(span, MatchNt(_, ident)) = ei.top_elts.get_tt(ei.idx) {\n+            if let TokenTree::MetaVarDecl(span, _, ident) = ei.top_elts.get_tt(ei.idx) {\n                 let match_cur = ei.match_cur;\n                 ei.matches[match_cur].push(Rc::new(MatchedNonterminal(\n                             Rc::new(parse_nt(&mut parser, span, &ident.name.as_str())))));"}, {"sha": "c775b2325cd41b3b9f33a012baacdd43325c533a", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 62, "deletions": 54, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -20,7 +20,7 @@ use ext::tt::quoted;\n use ext::tt::transcribe::transcribe;\n use parse::{Directory, ParseSess};\n use parse::parser::Parser;\n-use parse::token::{self, NtTT, Token};\n+use parse::token::{self, NtTT};\n use parse::token::Token::*;\n use print;\n use symbol::Symbol;\n@@ -165,14 +165,12 @@ pub fn compile(sess: &ParseSess, def: &ast::MacroDef) -> SyntaxExtension {\n     // $( $lhs:tt => $rhs:tt );+\n     // ...quasiquoting this would be nice.\n     // These spans won't matter, anyways\n-    let match_lhs_tok = MatchNt(lhs_nm, ast::Ident::from_str(\"tt\"));\n-    let match_rhs_tok = MatchNt(rhs_nm, ast::Ident::from_str(\"tt\"));\n     let argument_gram = vec![\n         quoted::TokenTree::Sequence(DUMMY_SP, Rc::new(quoted::SequenceRepetition {\n             tts: vec![\n-                quoted::TokenTree::Token(DUMMY_SP, match_lhs_tok),\n+                quoted::TokenTree::MetaVarDecl(DUMMY_SP, lhs_nm, ast::Ident::from_str(\"tt\")),\n                 quoted::TokenTree::Token(DUMMY_SP, token::FatArrow),\n-                quoted::TokenTree::Token(DUMMY_SP, match_rhs_tok),\n+                quoted::TokenTree::MetaVarDecl(DUMMY_SP, rhs_nm, ast::Ident::from_str(\"tt\")),\n             ],\n             separator: Some(token::Semi),\n             op: quoted::KleeneOp::OneOrMore,\n@@ -272,7 +270,7 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n     use self::quoted::TokenTree;\n     for tt in tts {\n         match *tt {\n-            TokenTree::Token(_, _) => (),\n+            TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => (),\n             TokenTree::Delimited(_, ref del) => if !check_lhs_no_empty_seq(sess, &del.tts) {\n                 return false;\n             },\n@@ -352,13 +350,12 @@ impl FirstSets {\n             let mut first = TokenSet::empty();\n             for tt in tts.iter().rev() {\n                 match *tt {\n-                    TokenTree::Token(sp, ref tok) => {\n-                        first.replace_with((sp, tok.clone()));\n+                    TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => {\n+                        first.replace_with(tt.clone());\n                     }\n                     TokenTree::Delimited(span, ref delimited) => {\n                         build_recur(sets, &delimited.tts[..]);\n-                        first.replace_with((delimited.open_tt(span).span(),\n-                                            Token::OpenDelim(delimited.delim)));\n+                        first.replace_with(delimited.open_tt(span));\n                     }\n                     TokenTree::Sequence(sp, ref seq_rep) => {\n                         let subfirst = build_recur(sets, &seq_rep.tts[..]);\n@@ -383,7 +380,7 @@ impl FirstSets {\n \n                         if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n                                                         subfirst.maybe_empty) {\n-                            first.add_one_maybe((sp, sep.clone()));\n+                            first.add_one_maybe(TokenTree::Token(sp, sep.clone()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n@@ -413,13 +410,12 @@ impl FirstSets {\n         for tt in tts.iter() {\n             assert!(first.maybe_empty);\n             match *tt {\n-                TokenTree::Token(sp, ref tok) => {\n-                    first.add_one((sp, tok.clone()));\n+                TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => {\n+                    first.add_one(tt.clone());\n                     return first;\n                 }\n                 TokenTree::Delimited(span, ref delimited) => {\n-                    first.add_one((delimited.open_tt(span).span(),\n-                                   Token::OpenDelim(delimited.delim)));\n+                    first.add_one(delimited.open_tt(span));\n                     return first;\n                 }\n                 TokenTree::Sequence(sp, ref seq_rep) => {\n@@ -431,7 +427,7 @@ impl FirstSets {\n \n                             if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n                                                             subfirst.maybe_empty) {\n-                                first.add_one_maybe((sp, sep.clone()));\n+                                first.add_one_maybe(TokenTree::Token(sp, sep.clone()));\n                             }\n \n                             assert!(first.maybe_empty);\n@@ -467,8 +463,8 @@ impl FirstSets {\n     }\n }\n \n-// A set of Tokens, which may include MatchNt tokens (for\n-// macro-by-example syntactic variables). It also carries the\n+// A set of `quoted::TokenTree`s, which may include `TokenTree::Match`s\n+// (for macro-by-example syntactic variables). It also carries the\n // `maybe_empty` flag; that is true if and only if the matcher can\n // match an empty token sequence.\n //\n@@ -479,7 +475,7 @@ impl FirstSets {\n // (Notably, we must allow for *-op to occur zero times.)\n #[derive(Clone, Debug)]\n struct TokenSet {\n-    tokens: Vec<(Span, Token)>,\n+    tokens: Vec<quoted::TokenTree>,\n     maybe_empty: bool,\n }\n \n@@ -489,13 +485,13 @@ impl TokenSet {\n \n     // Returns the set `{ tok }` for the single-token (and thus\n     // non-empty) sequence [tok].\n-    fn singleton(tok: (Span, Token)) -> Self {\n+    fn singleton(tok: quoted::TokenTree) -> Self {\n         TokenSet { tokens: vec![tok], maybe_empty: false }\n     }\n \n     // Changes self to be the set `{ tok }`.\n     // Since `tok` is always present, marks self as non-empty.\n-    fn replace_with(&mut self, tok: (Span, Token)) {\n+    fn replace_with(&mut self, tok: quoted::TokenTree) {\n         self.tokens.clear();\n         self.tokens.push(tok);\n         self.maybe_empty = false;\n@@ -510,15 +506,15 @@ impl TokenSet {\n     }\n \n     // Adds `tok` to the set for `self`, marking sequence as non-empy.\n-    fn add_one(&mut self, tok: (Span, Token)) {\n+    fn add_one(&mut self, tok: quoted::TokenTree) {\n         if !self.tokens.contains(&tok) {\n             self.tokens.push(tok);\n         }\n         self.maybe_empty = false;\n     }\n \n     // Adds `tok` to the set for `self`. (Leaves `maybe_empty` flag alone.)\n-    fn add_one_maybe(&mut self, tok: (Span, Token)) {\n+    fn add_one_maybe(&mut self, tok: quoted::TokenTree) {\n         if !self.tokens.contains(&tok) {\n             self.tokens.push(tok);\n         }\n@@ -558,7 +554,6 @@ fn check_matcher_core(sess: &ParseSess,\n                       first_sets: &FirstSets,\n                       matcher: &[quoted::TokenTree],\n                       follow: &TokenSet) -> TokenSet {\n-    use print::pprust::token_to_string;\n     use self::quoted::TokenTree;\n \n     let mut last = TokenSet::empty();\n@@ -584,11 +579,11 @@ fn check_matcher_core(sess: &ParseSess,\n         // First, update `last` so that it corresponds to the set\n         // of NT tokens that might end the sequence `... token`.\n         match *token {\n-            TokenTree::Token(sp, ref tok) => {\n+            TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => {\n                 let can_be_followed_by_any;\n-                if let Err(bad_frag) = has_legal_fragment_specifier(tok) {\n+                if let Err(bad_frag) = has_legal_fragment_specifier(token) {\n                     let msg = format!(\"invalid fragment specifier `{}`\", bad_frag);\n-                    sess.span_diagnostic.struct_span_err(sp, &msg)\n+                    sess.span_diagnostic.struct_span_err(token.span(), &msg)\n                         .help(\"valid fragment specifiers are `ident`, `block`, \\\n                                `stmt`, `expr`, `pat`, `ty`, `path`, `meta`, `tt` \\\n                                and `item`\")\n@@ -597,7 +592,7 @@ fn check_matcher_core(sess: &ParseSess,\n                     // from error messages.)\n                     can_be_followed_by_any = true;\n                 } else {\n-                    can_be_followed_by_any = token_can_be_followed_by_any(tok);\n+                    can_be_followed_by_any = token_can_be_followed_by_any(token);\n                 }\n \n                 if can_be_followed_by_any {\n@@ -607,13 +602,12 @@ fn check_matcher_core(sess: &ParseSess,\n                     // followed by anything against SUFFIX.\n                     continue 'each_token;\n                 } else {\n-                    last.replace_with((sp, tok.clone()));\n+                    last.replace_with(token.clone());\n                     suffix_first = build_suffix_first();\n                 }\n             }\n             TokenTree::Delimited(span, ref d) => {\n-                let my_suffix = TokenSet::singleton((d.close_tt(span).span(),\n-                                                     Token::CloseDelim(d.delim)));\n+                let my_suffix = TokenSet::singleton(d.close_tt(span));\n                 check_matcher_core(sess, first_sets, &d.tts, &my_suffix);\n                 // don't track non NT tokens\n                 last.replace_with_irrelevant();\n@@ -637,7 +631,7 @@ fn check_matcher_core(sess: &ParseSess,\n                 let mut new;\n                 let my_suffix = if let Some(ref u) = seq_rep.separator {\n                     new = suffix_first.clone();\n-                    new.add_one_maybe((sp, u.clone()));\n+                    new.add_one_maybe(TokenTree::Token(sp, u.clone()));\n                     &new\n                 } else {\n                     &suffix_first\n@@ -663,12 +657,13 @@ fn check_matcher_core(sess: &ParseSess,\n \n         // Now `last` holds the complete set of NT tokens that could\n         // end the sequence before SUFFIX. Check that every one works with `suffix`.\n-        'each_last: for &(_sp, ref t) in &last.tokens {\n-            if let MatchNt(ref name, ref frag_spec) = *t {\n-                for &(sp, ref next_token) in &suffix_first.tokens {\n+        'each_last: for token in &last.tokens {\n+            if let TokenTree::MetaVarDecl(_, ref name, ref frag_spec) = *token {\n+                for next_token in &suffix_first.tokens {\n                     match is_in_follow(next_token, &frag_spec.name.as_str()) {\n                         Err((msg, help)) => {\n-                            sess.span_diagnostic.struct_span_err(sp, &msg).help(help).emit();\n+                            sess.span_diagnostic.struct_span_err(next_token.span(), &msg)\n+                                .help(help).emit();\n                             // don't bother reporting every source of\n                             // conflict for a particular element of `last`.\n                             continue 'each_last;\n@@ -684,12 +679,12 @@ fn check_matcher_core(sess: &ParseSess,\n                             };\n \n                             sess.span_diagnostic.span_err(\n-                                sp,\n+                                next_token.span(),\n                                 &format!(\"`${name}:{frag}` {may_be} followed by `{next}`, which \\\n                                           is not allowed for `{frag}` fragments\",\n                                          name=name,\n                                          frag=frag_spec,\n-                                         next=token_to_string(next_token),\n+                                         next=quoted_tt_to_string(next_token),\n                                          may_be=may_be)\n                             );\n                         }\n@@ -701,8 +696,8 @@ fn check_matcher_core(sess: &ParseSess,\n     last\n }\n \n-fn token_can_be_followed_by_any(tok: &Token) -> bool {\n-    if let &MatchNt(_, ref frag_spec) = tok {\n+fn token_can_be_followed_by_any(tok: &quoted::TokenTree) -> bool {\n+    if let quoted::TokenTree::MetaVarDecl(_, _, frag_spec) = *tok {\n         frag_can_be_followed_by_any(&frag_spec.name.as_str())\n     } else {\n         // (Non NT's can always be followed by anthing in matchers.)\n@@ -740,8 +735,10 @@ fn frag_can_be_followed_by_any(frag: &str) -> bool {\n /// break macros that were relying on that binary operator as a\n /// separator.\n // when changing this do not forget to update doc/book/macros.md!\n-fn is_in_follow(tok: &Token, frag: &str) -> Result<bool, (String, &'static str)> {\n-    if let &CloseDelim(_) = tok {\n+fn is_in_follow(tok: &quoted::TokenTree, frag: &str) -> Result<bool, (String, &'static str)> {\n+    use self::quoted::TokenTree;\n+\n+    if let TokenTree::Token(_, token::CloseDelim(_)) = *tok {\n         // closing a token tree can never be matched by any fragment;\n         // iow, we always require that `(` and `)` match, etc.\n         Ok(true)\n@@ -757,27 +754,30 @@ fn is_in_follow(tok: &Token, frag: &str) -> Result<bool, (String, &'static str)>\n                 // maintain\n                 Ok(true)\n             },\n-            \"stmt\" | \"expr\"  => {\n-                match *tok {\n+            \"stmt\" | \"expr\"  => match *tok {\n+                TokenTree::Token(_, ref tok) => match *tok {\n                     FatArrow | Comma | Semi => Ok(true),\n                     _ => Ok(false)\n-                }\n+                },\n+                _ => Ok(false),\n             },\n-            \"pat\" => {\n-                match *tok {\n+            \"pat\" => match *tok {\n+                TokenTree::Token(_, ref tok) => match *tok {\n                     FatArrow | Comma | Eq | BinOp(token::Or) => Ok(true),\n                     Ident(i) if i.name == \"if\" || i.name == \"in\" => Ok(true),\n                     _ => Ok(false)\n-                }\n+                },\n+                _ => Ok(false),\n             },\n-            \"path\" | \"ty\" => {\n-                match *tok {\n+            \"path\" | \"ty\" => match *tok {\n+                TokenTree::Token(_, ref tok) => match *tok {\n                     OpenDelim(token::DelimToken::Brace) | OpenDelim(token::DelimToken::Bracket) |\n                     Comma | FatArrow | Colon | Eq | Gt | Semi | BinOp(token::Or) => Ok(true),\n-                    MatchNt(_, ref frag) if frag.name == \"block\" => Ok(true),\n                     Ident(i) if i.name == \"as\" || i.name == \"where\" => Ok(true),\n                     _ => Ok(false)\n-                }\n+                },\n+                TokenTree::MetaVarDecl(_, _, frag) if frag.name == \"block\" => Ok(true),\n+                _ => Ok(false),\n             },\n             \"ident\" => {\n                 // being a single token, idents are harmless\n@@ -796,9 +796,9 @@ fn is_in_follow(tok: &Token, frag: &str) -> Result<bool, (String, &'static str)>\n     }\n }\n \n-fn has_legal_fragment_specifier(tok: &Token) -> Result<(), String> {\n+fn has_legal_fragment_specifier(tok: &quoted::TokenTree) -> Result<(), String> {\n     debug!(\"has_legal_fragment_specifier({:?})\", tok);\n-    if let &MatchNt(_, ref frag_spec) = tok {\n+    if let quoted::TokenTree::MetaVarDecl(_, _, frag_spec) = *tok {\n         let s = &frag_spec.name.as_str();\n         if !is_legal_fragment_specifier(s) {\n             return Err(s.to_string());\n@@ -814,3 +814,11 @@ fn is_legal_fragment_specifier(frag: &str) -> bool {\n         _ => false,\n     }\n }\n+\n+fn quoted_tt_to_string(tt: &quoted::TokenTree) -> String {\n+    match *tt {\n+        quoted::TokenTree::Token(_, ref tok) => ::print::pprust::token_to_string(tok),\n+        quoted::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n+        _ => panic!(\"unexpected quoted::TokenTree::{Sequence or Delimited} in follow set checker\"),\n+    }\n+}"}, {"sha": "4fc20d7fefaf7ebbc5d956831f6f14ab88df9432", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -58,7 +58,7 @@ pub struct SequenceRepetition {\n     pub separator: Option<token::Token>,\n     /// Whether the sequence can be repeated zero (*), or one or more times (+)\n     pub op: KleeneOp,\n-    /// The number of `MatchNt`s that appear in the sequence (and subsequences)\n+    /// The number of `Match`s that appear in the sequence (and subsequences)\n     pub num_captures: usize,\n }\n \n@@ -78,6 +78,8 @@ pub enum TokenTree {\n     Delimited(Span, Rc<Delimited>),\n     /// A kleene-style repetition sequence with a span\n     Sequence(Span, Rc<SequenceRepetition>),\n+    /// Matches a nonterminal. This is only used in the left hand side of MBE macros.\n+    MetaVarDecl(Span, ast::Ident /* name to bind */, ast::Ident /* kind of nonterminal */),\n }\n \n impl TokenTree {\n@@ -88,7 +90,7 @@ impl TokenTree {\n                 _ => delimed.tts.len() + 2,\n             },\n             TokenTree::Sequence(_, ref seq) => seq.tts.len(),\n-            TokenTree::Token(..) => 0,\n+            _ => 0,\n         }\n     }\n \n@@ -115,6 +117,7 @@ impl TokenTree {\n     pub fn span(&self) -> Span {\n         match *self {\n             TokenTree::Token(sp, _) |\n+            TokenTree::MetaVarDecl(sp, _, _) |\n             TokenTree::Delimited(sp, _) |\n             TokenTree::Sequence(sp, _) => sp,\n         }\n@@ -133,7 +136,7 @@ pub fn parse(input: &[tokenstream::TokenTree], expect_matchers: bool, sess: &Par\n                     Some(tokenstream::TokenTree::Token(span, token::Colon)) => match trees.next() {\n                         Some(tokenstream::TokenTree::Token(end_sp, token::Ident(kind))) => {\n                             let span = Span { lo: start_sp.lo, ..end_sp };\n-                            result.push(TokenTree::Token(span, token::MatchNt(ident, kind)));\n+                            result.push(TokenTree::MetaVarDecl(span, ident, kind));\n                             continue\n                         }\n                         tree @ _ => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),"}, {"sha": "4ff59ebebbf4515ca5b126eb574ed61dce25fcd8", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -12,7 +12,7 @@ use ast::Ident;\n use errors::Handler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use ext::tt::quoted;\n-use parse::token::{self, MatchNt, SubstNt, Token, NtIdent, NtTT};\n+use parse::token::{self, SubstNt, Token, NtIdent, NtTT};\n use syntax_pos::{Span, DUMMY_SP};\n use tokenstream::{TokenTree, Delimited};\n use util::small_vector::SmallVector;\n@@ -61,7 +61,7 @@ impl Iterator for Frame {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TokenTree::Sequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n+/// `src` contains no `TokenTree::{Sequence, Match}`s, or `SubstNt`s, `interp` can\n /// (and should) be None.\n pub fn transcribe(sp_diag: &Handler,\n                   interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n@@ -177,6 +177,7 @@ pub fn transcribe(sp_diag: &Handler,\n                 result_stack.push(mem::replace(&mut result, Vec::new()));\n             }\n             quoted::TokenTree::Token(span, tok) => result.push(TokenTree::Token(span, tok)),\n+            quoted::TokenTree::MetaVarDecl(..) => panic!(\"unexpected `TokenTree::MetaVarDecl\"),\n         }\n     }\n }\n@@ -243,7 +244,7 @@ fn lockstep_iter_size(tree: &quoted::TokenTree,\n                 size + lockstep_iter_size(tt, interpolations, repeat_idx)\n             })\n         },\n-        TokenTree::Token(_, SubstNt(name)) | TokenTree::Token(_, MatchNt(name, _)) =>\n+        TokenTree::Token(_, SubstNt(name)) | TokenTree::MetaVarDecl(_, name, _) =>\n             match lookup_cur_matched(name, interpolations, repeat_idx) {\n                 Some(matched) => match *matched {\n                     MatchedNonterminal(_) => LockstepIterSize::Unconstrained,"}, {"sha": "257b7efba5c8e8d2f49cf96eef59d93a56a125f1", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -571,7 +571,6 @@ pub fn noop_fold_token<T: Folder>(t: token::Token, fld: &mut T) -> token::Token\n             token::Interpolated(Rc::new(fld.fold_interpolated(nt)))\n         }\n         token::SubstNt(ident) => token::SubstNt(fld.fold_ident(ident)),\n-        token::MatchNt(name, kind) => token::MatchNt(fld.fold_ident(name), fld.fold_ident(kind)),\n         _ => t\n     }\n }"}, {"sha": "5b65aac92b81c2d28ad6efe19d6ba38e1d0c59bc", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -152,9 +152,6 @@ pub enum Token {\n     // Can be expanded into several tokens.\n     /// Doc comment\n     DocComment(ast::Name),\n-    // In left-hand-sides of MBE macros:\n-    /// Parse a nonterminal (name to bind, name of NT)\n-    MatchNt(ast::Ident, ast::Ident),\n     // In right-hand-sides of MBE macros:\n     /// A syntactic variable that will be filled in by macro expansion.\n     SubstNt(ast::Ident),"}, {"sha": "ec962d03458d1753c905e7cffd90269efb092f7d", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cc7053efa243c117b0d9278a5a62eb62ecee227/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=0cc7053efa243c117b0d9278a5a62eb62ecee227", "patch": "@@ -271,7 +271,6 @@ pub fn token_to_string(tok: &Token) -> String {\n         /* Other */\n         token::DocComment(s)        => s.to_string(),\n         token::SubstNt(s)           => format!(\"${}\", s),\n-        token::MatchNt(s, t)        => format!(\"${}:{}\", s, t),\n         token::Eof                  => \"<eof>\".to_string(),\n         token::Whitespace           => \" \".to_string(),\n         token::Comment              => \"/* */\".to_string(),"}]}