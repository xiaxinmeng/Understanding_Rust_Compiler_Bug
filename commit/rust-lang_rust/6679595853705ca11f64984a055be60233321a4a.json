{"sha": "6679595853705ca11f64984a055be60233321a4a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY2Nzk1OTU4NTM3MDVjYTExZjY0OTg0YTA1NWJlNjAyMzMzMjFhNGE=", "commit": {"author": {"name": "Huon Wilson", "email": "dbau.pp+github@gmail.com", "date": "2014-11-19T04:48:38Z"}, "committer": {"name": "Huon Wilson", "email": "dbau.pp+github@gmail.com", "date": "2014-11-19T13:02:42Z"}, "message": "Parse and store suffixes on literals.\n\nThis adds an optional suffix at the end of a literal token:\n`\"foo\"bar`. An actual use of a suffix in a expression (or other literal\nthat the compiler reads) is rejected in the parser.\n\nThis doesn't switch the handling of numbers to this system, and doesn't\noutlaw illegal suffixes for them yet.", "tree": {"sha": "5821ae6fb5779244f5aebfd3527b2ab3eca69219", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5821ae6fb5779244f5aebfd3527b2ab3eca69219"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6679595853705ca11f64984a055be60233321a4a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6679595853705ca11f64984a055be60233321a4a", "html_url": "https://github.com/rust-lang/rust/commit/6679595853705ca11f64984a055be60233321a4a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6679595853705ca11f64984a055be60233321a4a/comments", "author": {"login": "huonw", "id": 1203825, "node_id": "MDQ6VXNlcjEyMDM4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1203825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huonw", "html_url": "https://github.com/huonw", "followers_url": "https://api.github.com/users/huonw/followers", "following_url": "https://api.github.com/users/huonw/following{/other_user}", "gists_url": "https://api.github.com/users/huonw/gists{/gist_id}", "starred_url": "https://api.github.com/users/huonw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huonw/subscriptions", "organizations_url": "https://api.github.com/users/huonw/orgs", "repos_url": "https://api.github.com/users/huonw/repos", "events_url": "https://api.github.com/users/huonw/events{/privacy}", "received_events_url": "https://api.github.com/users/huonw/received_events", "type": "User", "site_admin": false}, "committer": {"login": "huonw", "id": 1203825, "node_id": "MDQ6VXNlcjEyMDM4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1203825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huonw", "html_url": "https://github.com/huonw", "followers_url": "https://api.github.com/users/huonw/followers", "following_url": "https://api.github.com/users/huonw/following{/other_user}", "gists_url": "https://api.github.com/users/huonw/gists{/gist_id}", "starred_url": "https://api.github.com/users/huonw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huonw/subscriptions", "organizations_url": "https://api.github.com/users/huonw/orgs", "repos_url": "https://api.github.com/users/huonw/repos", "events_url": "https://api.github.com/users/huonw/events{/privacy}", "received_events_url": "https://api.github.com/users/huonw/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ff0278bc152c5e3072434615cf9861e98a160e71", "url": "https://api.github.com/repos/rust-lang/rust/commits/ff0278bc152c5e3072434615cf9861e98a160e71", "html_url": "https://github.com/rust-lang/rust/commit/ff0278bc152c5e3072434615cf9861e98a160e71"}], "stats": {"total": 365, "additions": 268, "deletions": 97}, "files": [{"sha": "111650f565cf6bb5643ab7117b5452655d206ee7", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 11, "deletions": 7, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -128,13 +128,17 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n                 }\n             }\n \n-            // text literals\n-            token::Literal(token::Byte(..)) | token::Literal(token::Char(..)) |\n-                token::Literal(token::Binary(..)) | token::Literal(token::BinaryRaw(..)) |\n-                token::Literal(token::Str_(..)) | token::Literal(token::StrRaw(..)) => \"string\",\n-\n-            // number literals\n-            token::Literal(token::Integer(..)) | token::Literal(token::Float(..)) => \"number\",\n+            token::Literal(lit, _suf) => {\n+                match lit {\n+                    // text literals\n+                    token::Byte(..) | token::Char(..) |\n+                        token::Binary(..) | token::BinaryRaw(..) |\n+                        token::Str_(..) | token::StrRaw(..) => \"string\",\n+\n+                    // number literals\n+                    token::Integer(..) | token::Float(..) => \"number\",\n+                }\n+            }\n \n             // keywords are also included in the identifier set\n             token::Ident(ident, _is_mod_sep) => {"}, {"sha": "7b16c08785926200e5654fed2aad4837893169e1", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -838,7 +838,7 @@ impl TokenTree {\n                     tts: vec![TtToken(sp, token::Ident(token::str_to_ident(\"doc\"),\n                                                        token::Plain)),\n                               TtToken(sp, token::Eq),\n-                              TtToken(sp, token::Literal(token::Str_(name)))],\n+                              TtToken(sp, token::Literal(token::Str_(name), None))],\n                     close_span: sp,\n                 }))\n             }"}, {"sha": "281bde3129aba4e642a2479e827bd57f1328f952", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -87,7 +87,7 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n         },\n         [ast::TtToken(_, token::Ident(ref code, _)),\n          ast::TtToken(_, token::Comma),\n-         ast::TtToken(_, token::Literal(token::StrRaw(description, _)))] => {\n+         ast::TtToken(_, token::Literal(token::StrRaw(description, _), None))] => {\n             (code, Some(description))\n         }\n         _ => unreachable!()"}, {"sha": "eaa3632cf499e558b77984b43c8242d9ffa7d447", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 18, "deletions": 15, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -543,10 +543,13 @@ fn mk_delim(cx: &ExtCtxt, sp: Span, delim: token::DelimToken) -> P<ast::Expr> {\n #[allow(non_upper_case_globals)]\n fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n     macro_rules! mk_lit {\n-        ($name: expr, $($args: expr),*) => {{\n+        ($name: expr, $suffix: expr, $($args: expr),*) => {{\n             let inner = cx.expr_call(sp, mk_token_path(cx, sp, $name), vec![$($args),*]);\n-\n-            cx.expr_call(sp, mk_token_path(cx, sp, \"Literal\"), vec![inner])\n+            let suffix = match $suffix {\n+                Some(name) => cx.expr_some(sp, mk_name(cx, sp, ast::Ident::new(name))),\n+                None => cx.expr_none(sp)\n+            };\n+            cx.expr_call(sp, mk_token_path(cx, sp, \"Literal\"), vec![inner, suffix])\n         }}\n     }\n     match *tok {\n@@ -567,32 +570,32 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                                 vec![mk_delim(cx, sp, delim)]);\n         }\n \n-        token::Literal(token::Byte(i)) => {\n+        token::Literal(token::Byte(i), suf) => {\n             let e_byte = mk_name(cx, sp, i.ident());\n-            return mk_lit!(\"Byte\", e_byte);\n+            return mk_lit!(\"Byte\", suf, e_byte);\n         }\n \n-        token::Literal(token::Char(i)) => {\n+        token::Literal(token::Char(i), suf) => {\n             let e_char = mk_name(cx, sp, i.ident());\n-            return mk_lit!(\"Char\", e_char);\n+            return mk_lit!(\"Char\", suf, e_char);\n         }\n \n-        token::Literal(token::Integer(i)) => {\n+        token::Literal(token::Integer(i), suf) => {\n             let e_int = mk_name(cx, sp, i.ident());\n-            return mk_lit!(\"Integer\", e_int);\n+            return mk_lit!(\"Integer\", suf, e_int);\n         }\n \n-        token::Literal(token::Float(fident)) => {\n+        token::Literal(token::Float(fident), suf) => {\n             let e_fident = mk_name(cx, sp, fident.ident());\n-            return mk_lit!(\"Float\", e_fident);\n+            return mk_lit!(\"Float\", suf, e_fident);\n         }\n \n-        token::Literal(token::Str_(ident)) => {\n-            return mk_lit!(\"Str_\", mk_name(cx, sp, ident.ident()))\n+        token::Literal(token::Str_(ident), suf) => {\n+            return mk_lit!(\"Str_\", suf, mk_name(cx, sp, ident.ident()))\n         }\n \n-        token::Literal(token::StrRaw(ident, n)) => {\n-            return mk_lit!(\"StrRaw\", mk_name(cx, sp, ident.ident()), cx.expr_uint(sp, n))\n+        token::Literal(token::StrRaw(ident, n), suf) => {\n+            return mk_lit!(\"StrRaw\", suf, mk_name(cx, sp, ident.ident()), cx.expr_uint(sp, n))\n         }\n \n         token::Ident(ident, style) => {"}, {"sha": "55c4335941dbc303b412e6698f4822ca726cb560", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 84, "deletions": 28, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -369,6 +369,25 @@ impl<'a> StringReader<'a> {\n         self.nextnextch() == Some(c)\n     }\n \n+    /// Eats <XID_start><XID_continue>*, if possible.\n+    fn scan_optional_raw_name(&mut self) -> Option<ast::Name> {\n+        if !ident_start(self.curr) {\n+            return None\n+        }\n+        let start = self.last_pos;\n+        while ident_continue(self.curr) {\n+            self.bump();\n+        }\n+\n+        self.with_str_from(start, |string| {\n+            if string == \"_\" {\n+                None\n+            } else {\n+                Some(token::intern(string))\n+            }\n+        })\n+    }\n+\n     /// PRECONDITION: self.curr is not whitespace\n     /// Eats any kind of comment.\n     fn scan_comment(&mut self) -> Option<TokenAndSpan> {\n@@ -638,7 +657,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     /// Lex a LIT_INTEGER or a LIT_FLOAT\n-    fn scan_number(&mut self, c: char) -> token::Token {\n+    fn scan_number(&mut self, c: char) -> token::Lit {\n         let mut num_digits;\n         let mut base = 10;\n         let start_bpos = self.last_pos;\n@@ -655,17 +674,17 @@ impl<'a> StringReader<'a> {\n                 }\n                 'u' | 'i' => {\n                     self.scan_int_suffix();\n-                    return token::Literal(token::Integer(self.name_from(start_bpos)));\n+                    return token::Integer(self.name_from(start_bpos));\n                 },\n                 'f' => {\n                     let last_pos = self.last_pos;\n                     self.scan_float_suffix();\n                     self.check_float_base(start_bpos, last_pos, base);\n-                    return token::Literal(token::Float(self.name_from(start_bpos)));\n+                    return token::Float(self.name_from(start_bpos));\n                 }\n                 _ => {\n                     // just a 0\n-                    return token::Literal(token::Integer(self.name_from(start_bpos)));\n+                    return token::Integer(self.name_from(start_bpos));\n                 }\n             }\n         } else if c.is_digit_radix(10) {\n@@ -678,7 +697,7 @@ impl<'a> StringReader<'a> {\n             self.err_span_(start_bpos, self.last_pos, \"no valid digits found for number\");\n             // eat any suffix\n             self.scan_int_suffix();\n-            return token::Literal(token::Integer(token::intern(\"0\")));\n+            return token::Integer(token::intern(\"0\"));\n         }\n \n         // might be a float, but don't be greedy if this is actually an\n@@ -696,25 +715,25 @@ impl<'a> StringReader<'a> {\n             }\n             let last_pos = self.last_pos;\n             self.check_float_base(start_bpos, last_pos, base);\n-            return token::Literal(token::Float(self.name_from(start_bpos)));\n+            return token::Float(self.name_from(start_bpos));\n         } else if self.curr_is('f') {\n             // or it might be an integer literal suffixed as a float\n             self.scan_float_suffix();\n             let last_pos = self.last_pos;\n             self.check_float_base(start_bpos, last_pos, base);\n-            return token::Literal(token::Float(self.name_from(start_bpos)));\n+            return token::Float(self.name_from(start_bpos));\n         } else {\n             // it might be a float if it has an exponent\n             if self.curr_is('e') || self.curr_is('E') {\n                 self.scan_float_exponent();\n                 self.scan_float_suffix();\n                 let last_pos = self.last_pos;\n                 self.check_float_base(start_bpos, last_pos, base);\n-                return token::Literal(token::Float(self.name_from(start_bpos)));\n+                return token::Float(self.name_from(start_bpos));\n             }\n             // but we certainly have an integer!\n             self.scan_int_suffix();\n-            return token::Literal(token::Integer(self.name_from(start_bpos)));\n+            return token::Integer(self.name_from(start_bpos));\n         }\n     }\n \n@@ -967,7 +986,9 @@ impl<'a> StringReader<'a> {\n         }\n \n         if is_dec_digit(c) {\n-            return self.scan_number(c.unwrap());\n+            let num = self.scan_number(c.unwrap());\n+            let suffix = self.scan_optional_raw_name();\n+            return token::Literal(num, suffix)\n         }\n \n         if self.read_embedded_ident {\n@@ -1126,17 +1147,19 @@ impl<'a> StringReader<'a> {\n             }\n             let id = if valid { self.name_from(start) } else { token::intern(\"0\") };\n             self.bump(); // advance curr past token\n-            return token::Literal(token::Char(id));\n+            let suffix = self.scan_optional_raw_name();\n+            return token::Literal(token::Char(id), suffix);\n           }\n           'b' => {\n             self.bump();\n-            return match self.curr {\n+            let lit = match self.curr {\n                 Some('\\'') => self.scan_byte(),\n                 Some('\"') => self.scan_byte_string(),\n                 Some('r') => self.scan_raw_byte_string(),\n                 _ => unreachable!()  // Should have been a token::Ident above.\n             };\n-\n+            let suffix = self.scan_optional_raw_name();\n+            return token::Literal(lit, suffix);\n           }\n           '\"' => {\n             let start_bpos = self.last_pos;\n@@ -1157,7 +1180,8 @@ impl<'a> StringReader<'a> {\n             let id = if valid { self.name_from(start_bpos + BytePos(1)) }\n                      else { token::intern(\"??\") };\n             self.bump();\n-            return token::Literal(token::Str_(id));\n+            let suffix = self.scan_optional_raw_name();\n+            return token::Literal(token::Str_(id), suffix);\n           }\n           'r' => {\n             let start_bpos = self.last_pos;\n@@ -1224,7 +1248,8 @@ impl<'a> StringReader<'a> {\n             } else {\n                 token::intern(\"??\")\n             };\n-            return token::Literal(token::StrRaw(id, hash_count));\n+            let suffix = self.scan_optional_raw_name();\n+            return token::Literal(token::StrRaw(id, hash_count), suffix);\n           }\n           '-' => {\n             if self.nextch_is('>') {\n@@ -1293,7 +1318,7 @@ impl<'a> StringReader<'a> {\n      || (self.curr_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n     }\n \n-    fn scan_byte(&mut self) -> token::Token {\n+    fn scan_byte(&mut self) -> token::Lit {\n         self.bump();\n         let start = self.last_pos;\n \n@@ -1314,10 +1339,10 @@ impl<'a> StringReader<'a> {\n \n         let id = if valid { self.name_from(start) } else { token::intern(\"??\") };\n         self.bump(); // advance curr past token\n-        return token::Literal(token::Byte(id));\n+        return token::Byte(id);\n     }\n \n-    fn scan_byte_string(&mut self) -> token::Token {\n+    fn scan_byte_string(&mut self) -> token::Lit {\n         self.bump();\n         let start = self.last_pos;\n         let mut valid = true;\n@@ -1336,10 +1361,10 @@ impl<'a> StringReader<'a> {\n         }\n         let id = if valid { self.name_from(start) } else { token::intern(\"??\") };\n         self.bump();\n-        return token::Literal(token::Binary(id));\n+        return token::Binary(id);\n     }\n \n-    fn scan_raw_byte_string(&mut self) -> token::Token {\n+    fn scan_raw_byte_string(&mut self) -> token::Lit {\n         let start_bpos = self.last_pos;\n         self.bump();\n         let mut hash_count = 0u;\n@@ -1387,9 +1412,9 @@ impl<'a> StringReader<'a> {\n             self.bump();\n         }\n         self.bump();\n-        return token::Literal(token::BinaryRaw(self.name_from_to(content_start_bpos,\n-                                                                 content_end_bpos),\n-                                               hash_count));\n+        return token::BinaryRaw(self.name_from_to(content_start_bpos,\n+                                                  content_end_bpos),\n+                                hash_count);\n     }\n }\n \n@@ -1536,17 +1561,17 @@ mod test {\n \n     #[test] fn character_a() {\n         assert_eq!(setup(&mk_sh(), \"'a'\".to_string()).next_token().tok,\n-                   token::Literal(token::Char(token::intern(\"a\"))));\n+                   token::Literal(token::Char(token::intern(\"a\")), None));\n     }\n \n     #[test] fn character_space() {\n         assert_eq!(setup(&mk_sh(), \"' '\".to_string()).next_token().tok,\n-                   token::Literal(token::Char(token::intern(\" \"))));\n+                   token::Literal(token::Char(token::intern(\" \")), None));\n     }\n \n     #[test] fn character_escaped() {\n         assert_eq!(setup(&mk_sh(), \"'\\\\n'\".to_string()).next_token().tok,\n-                   token::Literal(token::Char(token::intern(\"\\\\n\"))));\n+                   token::Literal(token::Char(token::intern(\"\\\\n\")), None));\n     }\n \n     #[test] fn lifetime_name() {\n@@ -1558,7 +1583,38 @@ mod test {\n         assert_eq!(setup(&mk_sh(),\n                          \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token()\n                                                                  .tok,\n-                   token::Literal(token::StrRaw(token::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3)));\n+                   token::Literal(token::StrRaw(token::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n+    }\n+\n+    #[test] fn literal_suffixes() {\n+        macro_rules! test {\n+            ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n+                assert_eq!(setup(&mk_sh(), format!(\"{}suffix\", $input)).next_token().tok,\n+                           token::Literal(token::$tok_type(token::intern($tok_contents)),\n+                                          Some(token::intern(\"suffix\"))));\n+                // with a whitespace separator:\n+                assert_eq!(setup(&mk_sh(), format!(\"{} suffix\", $input)).next_token().tok,\n+                           token::Literal(token::$tok_type(token::intern($tok_contents)),\n+                                          None));\n+            }}\n+        }\n+\n+        test!(\"'a'\", Char, \"a\");\n+        test!(\"b'a'\", Byte, \"a\");\n+        test!(\"\\\"a\\\"\", Str_, \"a\");\n+        test!(\"b\\\"a\\\"\", Binary, \"a\");\n+        test!(\"1234\", Integer, \"1234\");\n+        test!(\"0b101\", Integer, \"0b101\");\n+        test!(\"0xABC\", Integer, \"0xABC\");\n+        test!(\"1.0\", Float, \"1.0\");\n+        test!(\"1.0e10\", Float, \"1.0e10\");\n+\n+        assert_eq!(setup(&mk_sh(), \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n+                   token::Literal(token::StrRaw(token::intern(\"raw\"), 3),\n+                                  Some(token::intern(\"suffix\"))));\n+        assert_eq!(setup(&mk_sh(), \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n+                   token::Literal(token::BinaryRaw(token::intern(\"raw\"), 3),\n+                                  Some(token::intern(\"suffix\"))));\n     }\n \n     #[test] fn line_doc_comments() {\n@@ -1574,7 +1630,7 @@ mod test {\n             token::Comment => { },\n             _ => panic!(\"expected a comment!\")\n         }\n-        assert_eq!(lexer.next_token().tok, token::Literal(token::Char(token::intern(\"a\"))));\n+        assert_eq!(lexer.next_token().tok, token::Literal(token::Char(token::intern(\"a\")), None));\n     }\n \n }"}, {"sha": "b9e1fe07e712a7c39105bd794a784b75e0d4a3b5", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 79, "deletions": 30, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -646,6 +646,20 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n+    pub fn expect_no_suffix(&mut self, sp: Span, kind: &str, suffix: Option<ast::Name>) {\n+        match suffix {\n+            None => {/* everything ok */}\n+            Some(suf) => {\n+                let text = suf.as_str();\n+                if text.is_empty() {\n+                    self.span_bug(sp, \"found empty non-None literal suffix\")\n+                }\n+                self.span_err(sp, &*format!(\"a {} with a suffix is illegal\", kind));\n+            }\n+        }\n+    }\n+\n+\n     /// Attempt to consume a `<`. If `<<` is seen, replace it with a single\n     /// `<` and continue. If a `<` is not seen, return false.\n     ///\n@@ -968,6 +982,9 @@ impl<'a> Parser<'a> {\n     pub fn span_err(&mut self, sp: Span, m: &str) {\n         self.sess.span_diagnostic.span_err(sp, m)\n     }\n+    pub fn span_bug(&mut self, sp: Span, m: &str) -> ! {\n+        self.sess.span_diagnostic.span_bug(sp, m)\n+    }\n     pub fn abort_if_errors(&mut self) {\n         self.sess.span_diagnostic.handler().abort_if_errors();\n     }\n@@ -1640,24 +1657,40 @@ impl<'a> Parser<'a> {\n     /// Matches token_lit = LIT_INTEGER | ...\n     pub fn lit_from_token(&mut self, tok: &token::Token) -> Lit_ {\n         match *tok {\n-            token::Literal(token::Byte(i)) => LitByte(parse::byte_lit(i.as_str()).val0()),\n-            token::Literal(token::Char(i)) => LitChar(parse::char_lit(i.as_str()).val0()),\n-            token::Literal(token::Integer(s)) => parse::integer_lit(s.as_str(),\n-                                                        &self.sess.span_diagnostic,\n-                                                       self.last_span),\n-            token::Literal(token::Float(s)) => parse::float_lit(s.as_str()),\n-            token::Literal(token::Str_(s)) => {\n-                LitStr(token::intern_and_get_ident(parse::str_lit(s.as_str()).as_slice()),\n-                       ast::CookedStr)\n-            }\n-            token::Literal(token::StrRaw(s, n)) => {\n-                LitStr(token::intern_and_get_ident(parse::raw_str_lit(s.as_str()).as_slice()),\n-                       ast::RawStr(n))\n+            token::Literal(lit, suf) => {\n+                let (suffix_illegal, out) = match lit {\n+                    token::Byte(i) => (true, LitByte(parse::byte_lit(i.as_str()).val0())),\n+                    token::Char(i) => (true, LitChar(parse::char_lit(i.as_str()).val0())),\n+                    token::Integer(s) => (false, parse::integer_lit(s.as_str(),\n+                                                            &self.sess.span_diagnostic,\n+                                                            self.last_span)),\n+                    token::Float(s) => (false, parse::float_lit(s.as_str())),\n+                    token::Str_(s) => {\n+                        (true,\n+                         LitStr(token::intern_and_get_ident(parse::str_lit(s.as_str()).as_slice()),\n+                                ast::CookedStr))\n+                    }\n+                    token::StrRaw(s, n) => {\n+                        (true,\n+                         LitStr(\n+                            token::intern_and_get_ident(\n+                                parse::raw_str_lit(s.as_str()).as_slice()),\n+                            ast::RawStr(n)))\n+                    }\n+                    token::Binary(i) =>\n+                        (true, LitBinary(parse::binary_lit(i.as_str()))),\n+                    token::BinaryRaw(i, _) =>\n+                        (true,\n+                         LitBinary(Rc::new(i.as_str().as_bytes().iter().map(|&x| x).collect()))),\n+                };\n+\n+                if suffix_illegal {\n+                    let sp = self.last_span;\n+                    self.expect_no_suffix(sp, &*format!(\"{} literal\", lit.short_name()), suf)\n+                }\n+\n+                out\n             }\n-            token::Literal(token::Binary(i)) =>\n-                LitBinary(parse::binary_lit(i.as_str())),\n-            token::Literal(token::BinaryRaw(i, _)) =>\n-                LitBinary(Rc::new(i.as_str().as_bytes().iter().map(|&x| x).collect())),\n             _ => { self.unexpected_last(tok); }\n         }\n     }\n@@ -2424,7 +2457,10 @@ impl<'a> Parser<'a> {\n                         }\n                     }\n                   }\n-                  token::Literal(token::Integer(n)) => {\n+                  token::Literal(token::Integer(n), suf) => {\n+                    let sp = self.span;\n+                    self.expect_no_suffix(sp, \"tuple index\", suf);\n+\n                     let index = n.as_str();\n                     let dot = self.last_span.hi;\n                     hi = self.span.hi;\n@@ -2449,7 +2485,7 @@ impl<'a> Parser<'a> {\n                         }\n                     }\n                   }\n-                  token::Literal(token::Float(n)) => {\n+                  token::Literal(token::Float(n), _suf) => {\n                     self.bump();\n                     let last_span = self.last_span;\n                     let fstr = n.as_str();\n@@ -5085,12 +5121,17 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Semi);\n                 (path, the_ident)\n             },\n-            token::Literal(token::Str_(..)) | token::Literal(token::StrRaw(..)) => {\n-                let path = self.parse_str();\n+            token::Literal(token::Str_(..), suf) | token::Literal(token::StrRaw(..), suf) => {\n+                let sp = self.span;\n+                self.expect_no_suffix(sp, \"extern crate name\", suf);\n+                // forgo the internal suffix check of `parse_str` to\n+                // avoid repeats (this unwrap will always succeed due\n+                // to the restriction of the `match`)\n+                let (s, style, _) = self.parse_optional_str().unwrap();\n                 self.expect_keyword(keywords::As);\n                 let the_ident = self.parse_ident();\n                 self.expect(&token::Semi);\n-                (Some(path), the_ident)\n+                (Some((s, style)), the_ident)\n             },\n             _ => {\n                 let span = self.span;\n@@ -5267,7 +5308,9 @@ impl<'a> Parser<'a> {\n     /// the `extern` keyword, if one is found.\n     fn parse_opt_abi(&mut self) -> Option<abi::Abi> {\n         match self.token {\n-            token::Literal(token::Str_(s)) | token::Literal(token::StrRaw(s, _)) => {\n+            token::Literal(token::Str_(s), suf) | token::Literal(token::StrRaw(s, _), suf) => {\n+                let sp = self.span;\n+                self.expect_no_suffix(sp, \"ABI spec\", suf);\n                 self.bump();\n                 let the_string = s.as_str();\n                 match abi::lookup(the_string) {\n@@ -5902,21 +5945,27 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_optional_str(&mut self)\n-                              -> Option<(InternedString, ast::StrStyle)> {\n-        let (s, style) = match self.token {\n-            token::Literal(token::Str_(s)) => (self.id_to_interned_str(s.ident()), ast::CookedStr),\n-            token::Literal(token::StrRaw(s, n)) => {\n-                (self.id_to_interned_str(s.ident()), ast::RawStr(n))\n+                              -> Option<(InternedString, ast::StrStyle, Option<ast::Name>)> {\n+        let ret = match self.token {\n+            token::Literal(token::Str_(s), suf) => {\n+                (self.id_to_interned_str(s.ident()), ast::CookedStr, suf)\n+            }\n+            token::Literal(token::StrRaw(s, n), suf) => {\n+                (self.id_to_interned_str(s.ident()), ast::RawStr(n), suf)\n             }\n             _ => return None\n         };\n         self.bump();\n-        Some((s, style))\n+        Some(ret)\n     }\n \n     pub fn parse_str(&mut self) -> (InternedString, StrStyle) {\n         match self.parse_optional_str() {\n-            Some(s) => { s }\n+            Some((s, style, suf)) => {\n+                let sp = self.last_span;\n+                self.expect_no_suffix(sp, \"str literal\", suf);\n+                (s, style)\n+            }\n             _ =>  self.fatal(\"expected string literal\")\n         }\n     }"}, {"sha": "4272b57a4dc5145f309f819802d4cf95929855ab", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 16, "deletions": 3, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -72,6 +72,19 @@ pub enum Lit {\n     BinaryRaw(ast::Name, uint), /* raw binary str delimited by n hash symbols */\n }\n \n+impl Lit {\n+    pub fn short_name(&self) -> &'static str {\n+        match *self {\n+            Byte(_) => \"byte\",\n+            Char(_) => \"char\",\n+            Integer(_) => \"integer\",\n+            Float(_) => \"float\",\n+            Str_(_) | StrRaw(..) => \"str\",\n+            Binary(_) | BinaryRaw(..) => \"binary str\"\n+        }\n+    }\n+}\n+\n #[allow(non_camel_case_types)]\n #[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n pub enum Token {\n@@ -111,7 +124,7 @@ pub enum Token {\n     CloseDelim(DelimToken),\n \n     /* Literals */\n-    Literal(Lit),\n+    Literal(Lit, Option<ast::Name>),\n \n     /* Name components */\n     Ident(ast::Ident, IdentStyle),\n@@ -151,7 +164,7 @@ impl Token {\n             Ident(_, _)                 => true,\n             Underscore                  => true,\n             Tilde                       => true,\n-            Literal(_)                  => true,\n+            Literal(_, _)               => true,\n             Pound                       => true,\n             At                          => true,\n             Not                         => true,\n@@ -172,7 +185,7 @@ impl Token {\n     /// Returns `true` if the token is any literal\n     pub fn is_lit(&self) -> bool {\n         match *self {\n-            Literal(_) => true,\n+            Literal(_, _) => true,\n             _          => false,\n         }\n     }"}, {"sha": "642ffa3745d9f366265dce096467212d1ce8a60b", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 22, "deletions": 12, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -236,18 +236,28 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::Question             => \"?\".into_string(),\n \n         /* Literals */\n-        token::Literal(token::Byte(b))           => format!(\"b'{}'\", b.as_str()),\n-        token::Literal(token::Char(c))           => format!(\"'{}'\", c.as_str()),\n-        token::Literal(token::Float(c))          => c.as_str().into_string(),\n-        token::Literal(token::Integer(c))        => c.as_str().into_string(),\n-        token::Literal(token::Str_(s))           => format!(\"\\\"{}\\\"\", s.as_str()),\n-        token::Literal(token::StrRaw(s, n))      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n-                                                            delim=\"#\".repeat(n),\n-                                                            string=s.as_str()),\n-        token::Literal(token::Binary(v))         => format!(\"b\\\"{}\\\"\", v.as_str()),\n-        token::Literal(token::BinaryRaw(s, n))   => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n-                                                            delim=\"#\".repeat(n),\n-                                                            string=s.as_str()),\n+        token::Literal(lit, suf) => {\n+            let mut out = match lit {\n+                token::Byte(b)           => format!(\"b'{}'\", b.as_str()),\n+                token::Char(c)           => format!(\"'{}'\", c.as_str()),\n+                token::Float(c)          => c.as_str().into_string(),\n+                token::Integer(c)        => c.as_str().into_string(),\n+                token::Str_(s)           => format!(\"\\\"{}\\\"\", s.as_str()),\n+                token::StrRaw(s, n)      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n+                                                    delim=\"#\".repeat(n),\n+                                                    string=s.as_str()),\n+                token::Binary(v)         => format!(\"b\\\"{}\\\"\", v.as_str()),\n+                token::BinaryRaw(s, n)   => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n+                                                    delim=\"#\".repeat(n),\n+                                                    string=s.as_str()),\n+            };\n+\n+            if let Some(s) = suf {\n+                out.push_str(s.as_str())\n+            }\n+\n+            out\n+        }\n \n         /* Name components */\n         token::Ident(s, _)          => token::get_ident(s).get().into_string(),"}, {"sha": "e48bb807488a0db85455751498814ac22415bcb9", "filename": "src/test/compile-fail/bad-lit-suffixes.rs", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/6679595853705ca11f64984a055be60233321a4a/src%2Ftest%2Fcompile-fail%2Fbad-lit-suffixes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6679595853705ca11f64984a055be60233321a4a/src%2Ftest%2Fcompile-fail%2Fbad-lit-suffixes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fbad-lit-suffixes.rs?ref=6679595853705ca11f64984a055be60233321a4a", "patch": "@@ -0,0 +1,36 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+\n+extern crate\n+    \"foo\"suffix //~ ERROR extern crate name with a suffix is illegal\n+     as foo;\n+\n+extern\n+    \"C\"suffix //~ ERROR ABI spec with a suffix is illegal\n+    fn foo() {}\n+\n+extern\n+    \"C\"suffix //~ ERROR ABI spec with a suffix is illegal\n+{}\n+\n+fn main() {\n+    \"\"suffix; //~ ERROR str literal with a suffix is illegal\n+    b\"\"suffix; //~ ERROR binary str literal with a suffix is illegal\n+    r#\"\"#suffix; //~ ERROR str literal with a suffix is illegal\n+    br#\"\"#suffix; //~ ERROR binary str literal with a suffix is illegal\n+    'a'suffix; //~ ERROR char literal with a suffix is illegal\n+    b'a'suffix; //~ ERROR byte literal with a suffix is illegal\n+\n+    1234suffix;\n+    0b101suffix;\n+    1.0suffix;\n+    1.0e10suffix;\n+}"}]}