{"sha": "5633a5363b6c650500b8b6496ddd49ea8c698f92", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU2MzNhNTM2M2I2YzY1MDUwMGI4YjY0OTZkZGQ0OWVhOGM2OThmOTI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-07-31T01:58:17Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-07-31T01:58:17Z"}, "message": "auto merge of #8008 : bblum/rust/select, r=brson\n\nMain logic in ```Implement select() for new runtime pipes.```. The guts of the ```PortOne::try_recv()``` implementation are now split up across several functions, ```optimistic_check```, ```block_on```, and ```recv_ready```.\r\n\r\nThere is one weird FIXME I left open here, in the \"implement select\" commit -- an assertion I couldn't get to work in the receive path, on an invariant that for some reason doesn't hold with ```SharedPort```. Still investigating this.", "tree": {"sha": "e0a6b69c6eb47b0bba56a452738de000ba5cab2e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e0a6b69c6eb47b0bba56a452738de000ba5cab2e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5633a5363b6c650500b8b6496ddd49ea8c698f92", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5633a5363b6c650500b8b6496ddd49ea8c698f92", "html_url": "https://github.com/rust-lang/rust/commit/5633a5363b6c650500b8b6496ddd49ea8c698f92", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5633a5363b6c650500b8b6496ddd49ea8c698f92/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6534b4d4ce87940954b017bd27dc4e5fa7e59703", "url": "https://api.github.com/repos/rust-lang/rust/commits/6534b4d4ce87940954b017bd27dc4e5fa7e59703", "html_url": "https://github.com/rust-lang/rust/commit/6534b4d4ce87940954b017bd27dc4e5fa7e59703"}, {"sha": "6b75e92afe174696bd00eaa8283ad9e3b1d01582", "url": "https://api.github.com/repos/rust-lang/rust/commits/6b75e92afe174696bd00eaa8283ad9e3b1d01582", "html_url": "https://github.com/rust-lang/rust/commit/6b75e92afe174696bd00eaa8283ad9e3b1d01582"}], "stats": {"total": 1075, "additions": 792, "deletions": 283}, "files": [{"sha": "d4bf1d480ed79219b4f8fb1479316638ad1befb6", "filename": "src/libextra/arc.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibextra%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibextra%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Farc.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -136,7 +136,7 @@ impl<T:Freeze+Send> Arc<T> {\n      */\n     pub fn unwrap(self) -> T {\n         let Arc { x: x } = self;\n-        unsafe { x.unwrap() }\n+        x.unwrap()\n     }\n }\n \n@@ -250,7 +250,7 @@ impl<T:Send> MutexArc<T> {\n      */\n     pub fn unwrap(self) -> T {\n         let MutexArc { x: x } = self;\n-        let inner = unsafe { x.unwrap() };\n+        let inner = x.unwrap();\n         let MutexArcInner { failed: failed, data: data, _ } = inner;\n         if failed {\n             fail!(~\"Can't unwrap poisoned MutexArc - another task failed inside!\");\n@@ -469,7 +469,7 @@ impl<T:Freeze + Send> RWArc<T> {\n      */\n     pub fn unwrap(self) -> T {\n         let RWArc { x: x, _ } = self;\n-        let inner = unsafe { x.unwrap() };\n+        let inner = x.unwrap();\n         let RWArcInner { failed: failed, data: data, _ } = inner;\n         if failed {\n             fail!(~\"Can't unwrap poisoned RWArc - another task failed inside!\")"}, {"sha": "47fd4cccb9f98552cb3c23e3253530823d828409", "filename": "src/libextra/sync.rs", "status": "modified", "additions": 20, "deletions": 28, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibextra%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibextra%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fsync.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -130,11 +130,9 @@ impl<Q:Send> Sem<Q> {\n impl Sem<()> {\n     pub fn access<U>(&self, blk: &fn() -> U) -> U {\n         let mut release = None;\n-        unsafe {\n-            do task::unkillable {\n-                self.acquire();\n-                release = Some(SemRelease(self));\n-            }\n+        do task::unkillable {\n+            self.acquire();\n+            release = Some(SemRelease(self));\n         }\n         blk()\n     }\n@@ -153,11 +151,9 @@ impl Sem<~[WaitQueue]> {\n \n     pub fn access_waitqueue<U>(&self, blk: &fn() -> U) -> U {\n         let mut release = None;\n-        unsafe {\n-            do task::unkillable {\n-                self.acquire();\n-                release = Some(SemAndSignalRelease(self));\n-            }\n+        do task::unkillable {\n+            self.acquire();\n+            release = Some(SemAndSignalRelease(self));\n         }\n         blk()\n     }\n@@ -294,17 +290,15 @@ impl<'self> Condvar<'self> {\n         #[unsafe_destructor]\n         impl<'self> Drop for CondvarReacquire<'self> {\n             fn drop(&self) {\n-                unsafe {\n-                    // Needs to succeed, instead of itself dying.\n-                    do task::unkillable {\n-                        match self.order {\n-                            Just(lock) => do lock.access {\n-                                self.sem.acquire();\n-                            },\n-                            Nothing => {\n-                                self.sem.acquire();\n-                            },\n-                        }\n+                // Needs to succeed, instead of itself dying.\n+                do task::unkillable {\n+                    match self.order {\n+                        Just(lock) => do lock.access {\n+                            self.sem.acquire();\n+                        },\n+                        Nothing => {\n+                            self.sem.acquire();\n+                        },\n                     }\n                 }\n             }\n@@ -644,14 +638,12 @@ impl RWLock {\n         // Implementation slightly different from the slicker 'write's above.\n         // The exit path is conditional on whether the caller downgrades.\n         let mut _release = None;\n-        unsafe {\n-            do task::unkillable {\n-                (&self.order_lock).acquire();\n-                (&self.access_lock).acquire();\n-                (&self.order_lock).release();\n-            }\n-            _release = Some(RWLockReleaseDowngrade(self));\n+        do task::unkillable {\n+            (&self.order_lock).acquire();\n+            (&self.access_lock).acquire();\n+            (&self.order_lock).release();\n         }\n+        _release = Some(RWLockReleaseDowngrade(self));\n         blk(RWLockWriteMode { lock: self })\n     }\n "}, {"sha": "6528835c52c0a089b3c45c7525d972555aab0e44", "filename": "src/libstd/rt/comm.rs", "status": "modified", "additions": 186, "deletions": 87, "changes": 273, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fcomm.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -12,13 +12,13 @@\n \n use option::*;\n use cast;\n-use util;\n use ops::Drop;\n use rt::kill::BlockedTask;\n use kinds::Send;\n use rt::sched::Scheduler;\n use rt::local::Local;\n-use unstable::atomics::{AtomicUint, AtomicOption, SeqCst};\n+use rt::select::{Select, SelectPort};\n+use unstable::atomics::{AtomicUint, AtomicOption, Acquire, Release, SeqCst};\n use unstable::sync::UnsafeAtomicRcBox;\n use util::Void;\n use comm::{GenericChan, GenericSmartChan, GenericPort, Peekable};\n@@ -45,23 +45,12 @@ struct Packet<T> {\n \n /// A one-shot channel.\n pub struct ChanOne<T> {\n-    // XXX: Hack extra allocation to make by-val self work\n-    inner: ~ChanOneHack<T>\n-}\n-\n-\n-/// A one-shot port.\n-pub struct PortOne<T> {\n-    // XXX: Hack extra allocation to make by-val self work\n-    inner: ~PortOneHack<T>\n-}\n-\n-pub struct ChanOneHack<T> {\n     void_packet: *mut Void,\n     suppress_finalize: bool\n }\n \n-pub struct PortOneHack<T> {\n+/// A one-shot port.\n+pub struct PortOne<T> {\n     void_packet: *mut Void,\n     suppress_finalize: bool\n }\n@@ -75,22 +64,26 @@ pub fn oneshot<T: Send>() -> (PortOne<T>, ChanOne<T>) {\n     unsafe {\n         let packet: *mut Void = cast::transmute(packet);\n         let port = PortOne {\n-            inner: ~PortOneHack {\n-                void_packet: packet,\n-                suppress_finalize: false\n-            }\n+            void_packet: packet,\n+            suppress_finalize: false\n         };\n         let chan = ChanOne {\n-            inner: ~ChanOneHack {\n-                void_packet: packet,\n-                suppress_finalize: false\n-            }\n+            void_packet: packet,\n+            suppress_finalize: false\n         };\n         return (port, chan);\n     }\n }\n \n impl<T> ChanOne<T> {\n+    #[inline]\n+    fn packet(&self) -> *mut Packet<T> {\n+        unsafe {\n+            let p: *mut ~Packet<T> = cast::transmute(&self.void_packet);\n+            let p: *mut Packet<T> = &mut **p;\n+            return p;\n+        }\n+    }\n \n     pub fn send(self, val: T) {\n         self.try_send(val);\n@@ -99,7 +92,7 @@ impl<T> ChanOne<T> {\n     pub fn try_send(self, val: T) -> bool {\n         let mut this = self;\n         let mut recvr_active = true;\n-        let packet = this.inner.packet();\n+        let packet = this.packet();\n \n         unsafe {\n \n@@ -127,7 +120,7 @@ impl<T> ChanOne<T> {\n                         sched.metrics.rendezvous_sends += 1;\n                     }\n                     // Port has closed. Need to clean up.\n-                    let _packet: ~Packet<T> = cast::transmute(this.inner.void_packet);\n+                    let _packet: ~Packet<T> = cast::transmute(this.void_packet);\n                     recvr_active = false;\n                 }\n                 task_as_state => {\n@@ -144,13 +137,20 @@ impl<T> ChanOne<T> {\n         }\n \n         // Suppress the synchronizing actions in the finalizer. We're done with the packet.\n-        this.inner.suppress_finalize = true;\n+        this.suppress_finalize = true;\n         return recvr_active;\n     }\n }\n \n-\n impl<T> PortOne<T> {\n+    fn packet(&self) -> *mut Packet<T> {\n+        unsafe {\n+            let p: *mut ~Packet<T> = cast::transmute(&self.void_packet);\n+            let p: *mut Packet<T> = &mut **p;\n+            return p;\n+        }\n+    }\n+\n     pub fn recv(self) -> T {\n         match self.try_recv() {\n             Some(val) => val,\n@@ -162,43 +162,129 @@ impl<T> PortOne<T> {\n \n     pub fn try_recv(self) -> Option<T> {\n         let mut this = self;\n-        let packet = this.inner.packet();\n-\n-        // XXX: Optimize this to not require the two context switches when data is available\n-\n-        // Switch to the scheduler to put the ~Task into the Packet state.\n-        let sched = Local::take::<Scheduler>();\n-        do sched.deschedule_running_task_and_then |sched, task| {\n-            unsafe {\n-                // Atomically swap the task pointer into the Packet state, issuing\n-                // an acquire barrier to prevent reordering of the subsequent read\n-                // of the payload. Also issues a release barrier to prevent reordering\n-                // of any previous writes to the task structure.\n-                let task_as_state = task.cast_to_uint();\n-                let oldstate = (*packet).state.swap(task_as_state, SeqCst);\n-                match oldstate {\n-                    STATE_BOTH => {\n-                        // Data has not been sent. Now we're blocked.\n-                        rtdebug!(\"non-rendezvous recv\");\n-                        sched.metrics.non_rendezvous_recvs += 1;\n-                    }\n-                    STATE_ONE => {\n-                        rtdebug!(\"rendezvous recv\");\n-                        sched.metrics.rendezvous_recvs += 1;\n-\n-                        // Channel is closed. Switch back and check the data.\n-                        // NB: We have to drop back into the scheduler event loop here\n-                        // instead of switching immediately back or we could end up\n-                        // triggering infinite recursion on the scheduler's stack.\n-                        let recvr = BlockedTask::cast_from_uint(task_as_state);\n-                        sched.enqueue_blocked_task(recvr);\n+\n+        // Optimistic check. If data was sent already, we don't even need to block.\n+        // No release barrier needed here; we're not handing off our task pointer yet.\n+        if !this.optimistic_check() {\n+            // No data available yet.\n+            // Switch to the scheduler to put the ~Task into the Packet state.\n+            let sched = Local::take::<Scheduler>();\n+            do sched.deschedule_running_task_and_then |sched, task| {\n+                this.block_on(sched, task);\n+            }\n+        }\n+\n+        // Task resumes.\n+        this.recv_ready()\n+    }\n+}\n+\n+impl<T> Select for PortOne<T> {\n+    #[inline] #[cfg(not(test))]\n+    fn optimistic_check(&mut self) -> bool {\n+        unsafe { (*self.packet()).state.load(Acquire) == STATE_ONE }\n+    }\n+\n+    #[inline] #[cfg(test)]\n+    fn optimistic_check(&mut self) -> bool {\n+        // The optimistic check is never necessary for correctness. For testing\n+        // purposes, making it randomly return false simulates a racing sender.\n+        use rand::{Rand, rng};\n+        let mut rng = rng();\n+        let actually_check = Rand::rand(&mut rng);\n+        if actually_check {\n+            unsafe { (*self.packet()).state.load(Acquire) == STATE_ONE }\n+        } else {\n+            false\n+        }\n+    }\n+\n+    fn block_on(&mut self, sched: &mut Scheduler, task: BlockedTask) -> bool {\n+        unsafe {\n+            // Atomically swap the task pointer into the Packet state, issuing\n+            // an acquire barrier to prevent reordering of the subsequent read\n+            // of the payload. Also issues a release barrier to prevent\n+            // reordering of any previous writes to the task structure.\n+            let task_as_state = task.cast_to_uint();\n+            let oldstate = (*self.packet()).state.swap(task_as_state, SeqCst);\n+            match oldstate {\n+                STATE_BOTH => {\n+                    // Data has not been sent. Now we're blocked.\n+                    rtdebug!(\"non-rendezvous recv\");\n+                    sched.metrics.non_rendezvous_recvs += 1;\n+                    false\n+                }\n+                STATE_ONE => {\n+                    // Re-record that we are the only owner of the packet.\n+                    // Release barrier needed in case the task gets reawoken\n+                    // on a different core (this is analogous to writing a\n+                    // payload; a barrier in enqueueing the task protects it).\n+                    // NB(#8132). This *must* occur before the enqueue below.\n+                    // FIXME(#6842, #8130) This is usually only needed for the\n+                    // assertion in recv_ready, except in the case of select().\n+                    // This won't actually ever have cacheline contention, but\n+                    // maybe should be optimized out with a cfg(test) anyway?\n+                    (*self.packet()).state.store(STATE_ONE, Release);\n+\n+                    rtdebug!(\"rendezvous recv\");\n+                    sched.metrics.rendezvous_recvs += 1;\n+\n+                    // Channel is closed. Switch back and check the data.\n+                    // NB: We have to drop back into the scheduler event loop here\n+                    // instead of switching immediately back or we could end up\n+                    // triggering infinite recursion on the scheduler's stack.\n+                    let recvr = BlockedTask::cast_from_uint(task_as_state);\n+                    sched.enqueue_blocked_task(recvr);\n+                    true\n+                }\n+                _ => rtabort!(\"can't block_on; a task is already blocked\")\n+            }\n+        }\n+    }\n+\n+    // This is the only select trait function that's not also used in recv.\n+    fn unblock_from(&mut self) -> bool {\n+        let packet = self.packet();\n+        unsafe {\n+            // In case the data is available, the acquire barrier here matches\n+            // the release barrier the sender used to release the payload.\n+            match (*packet).state.load(Acquire) {\n+                // Impossible. We removed STATE_BOTH when blocking on it, and\n+                // no self-respecting sender would put it back.\n+                STATE_BOTH    => rtabort!(\"refcount already 2 in unblock_from\"),\n+                // Here, a sender already tried to wake us up. Perhaps they\n+                // even succeeded! Data is available.\n+                STATE_ONE     => true,\n+                // Still registered as blocked. Need to \"unblock\" the pointer.\n+                task_as_state => {\n+                    // In the window between the load and the CAS, a sender\n+                    // might take the pointer and set the refcount to ONE. If\n+                    // that happens, we shouldn't clobber that with BOTH!\n+                    // Acquire barrier again for the same reason as above.\n+                    match (*packet).state.compare_and_swap(task_as_state, STATE_BOTH,\n+                                                           Acquire) {\n+                        STATE_BOTH => rtabort!(\"refcount became 2 in unblock_from\"),\n+                        STATE_ONE  => true, // Lost the race. Data available.\n+                        same_ptr   => {\n+                            // We successfully unblocked our task pointer.\n+                            assert!(task_as_state == same_ptr);\n+                            let handle = BlockedTask::cast_from_uint(task_as_state);\n+                            // Because we are already awake, the handle we\n+                            // gave to this port shall already be empty.\n+                            handle.assert_already_awake();\n+                            false\n+                        }\n                     }\n-                    _ => util::unreachable()\n                 }\n             }\n         }\n+    }\n+}\n \n-        // Task resumes.\n+impl<T> SelectPort<T> for PortOne<T> {\n+    fn recv_ready(self) -> Option<T> {\n+        let mut this = self;\n+        let packet = this.packet();\n \n         // No further memory barrier is needed here to access the\n         // payload. Some scenarios:\n@@ -210,14 +296,17 @@ impl<T> PortOne<T> {\n         // 3) We encountered STATE_BOTH above and blocked, but the receiving task (this task)\n         //    is pinned to some other scheduler, so the sending task had to give us to\n         //    a different scheduler for resuming. That send synchronized memory.\n-\n         unsafe {\n-            let payload = util::replace(&mut (*packet).payload, None);\n+            // See corresponding store() above in block_on for rationale.\n+            // FIXME(#8130) This can happen only in test builds.\n+            assert!((*packet).state.load(Acquire) == STATE_ONE);\n+\n+            let payload = (*packet).payload.take();\n \n             // The sender has closed up shop. Drop the packet.\n-            let _packet: ~Packet<T> = cast::transmute(this.inner.void_packet);\n+            let _packet: ~Packet<T> = cast::transmute(this.void_packet);\n             // Suppress the synchronizing actions in the finalizer. We're done with the packet.\n-            this.inner.suppress_finalize = true;\n+            this.suppress_finalize = true;\n             return payload;\n         }\n     }\n@@ -226,19 +315,19 @@ impl<T> PortOne<T> {\n impl<T> Peekable<T> for PortOne<T> {\n     fn peek(&self) -> bool {\n         unsafe {\n-            let packet: *mut Packet<T> = self.inner.packet();\n+            let packet: *mut Packet<T> = self.packet();\n             let oldstate = (*packet).state.load(SeqCst);\n             match oldstate {\n                 STATE_BOTH => false,\n                 STATE_ONE => (*packet).payload.is_some(),\n-                _ => util::unreachable()\n+                _ => rtabort!(\"peeked on a blocked task\")\n             }\n         }\n     }\n }\n \n #[unsafe_destructor]\n-impl<T> Drop for ChanOneHack<T> {\n+impl<T> Drop for ChanOne<T> {\n     fn drop(&self) {\n         if self.suppress_finalize { return }\n \n@@ -267,7 +356,7 @@ impl<T> Drop for ChanOneHack<T> {\n }\n \n #[unsafe_destructor]\n-impl<T> Drop for PortOneHack<T> {\n+impl<T> Drop for PortOne<T> {\n     fn drop(&self) {\n         if self.suppress_finalize { return }\n \n@@ -295,26 +384,6 @@ impl<T> Drop for PortOneHack<T> {\n     }\n }\n \n-impl<T> ChanOneHack<T> {\n-    fn packet(&self) -> *mut Packet<T> {\n-        unsafe {\n-            let p: *mut ~Packet<T> = cast::transmute(&self.void_packet);\n-            let p: *mut Packet<T> = &mut **p;\n-            return p;\n-        }\n-    }\n-}\n-\n-impl<T> PortOneHack<T> {\n-    fn packet(&self) -> *mut Packet<T> {\n-        unsafe {\n-            let p: *mut ~Packet<T> = cast::transmute(&self.void_packet);\n-            let p: *mut Packet<T> = &mut **p;\n-            return p;\n-        }\n-    }\n-}\n-\n struct StreamPayload<T> {\n     val: T,\n     next: PortOne<StreamPayload<T>>\n@@ -385,6 +454,36 @@ impl<T> Peekable<T> for Port<T> {\n     }\n }\n \n+impl<T> Select for Port<T> {\n+    #[inline]\n+    fn optimistic_check(&mut self) -> bool {\n+        do self.next.with_mut_ref |pone| { pone.optimistic_check() }\n+    }\n+\n+    #[inline]\n+    fn block_on(&mut self, sched: &mut Scheduler, task: BlockedTask) -> bool {\n+        let task = Cell::new(task);\n+        do self.next.with_mut_ref |pone| { pone.block_on(sched, task.take()) }\n+    }\n+\n+    #[inline]\n+    fn unblock_from(&mut self) -> bool {\n+        do self.next.with_mut_ref |pone| { pone.unblock_from() }\n+    }\n+}\n+\n+impl<T> SelectPort<(T, Port<T>)> for Port<T> {\n+    fn recv_ready(self) -> Option<(T, Port<T>)> {\n+        match self.next.take().recv_ready() {\n+            Some(StreamPayload { val, next }) => {\n+                self.next.put_back(next);\n+                Some((val, self))\n+            }\n+            None => None\n+        }\n+    }\n+}\n+\n pub struct SharedChan<T> {\n     // Just like Chan, but a shared AtomicOption instead of Cell\n     priv next: UnsafeAtomicRcBox<AtomicOption<StreamChanOne<T>>>"}, {"sha": "e691bf51ea50e1d6e2c4206993b6ac362831601f", "filename": "src/libstd/rt/kill.rs", "status": "modified", "additions": 40, "deletions": 13, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fkill.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fkill.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fkill.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -106,8 +106,14 @@ impl Drop for KillFlag {\n // blocked task handle. So unblocking a task must restore that spare.\n unsafe fn revive_task_ptr(task_ptr: uint, spare_flag: Option<KillFlagHandle>) -> ~Task {\n     let mut task: ~Task = cast::transmute(task_ptr);\n-    rtassert!(task.death.spare_kill_flag.is_none());\n-    task.death.spare_kill_flag = spare_flag;\n+    if task.death.spare_kill_flag.is_none() {\n+        task.death.spare_kill_flag = spare_flag;\n+    } else {\n+        // A task's spare kill flag is not used for blocking in one case:\n+        // when an unkillable task blocks on select. In this case, a separate\n+        // one was created, which we now discard.\n+        rtassert!(task.death.unkillable > 0);\n+    }\n     task\n }\n \n@@ -119,7 +125,7 @@ impl BlockedTask {\n             Killable(flag_arc) => {\n                 let flag = unsafe { &mut **flag_arc.get() };\n                 match flag.swap(KILL_RUNNING, SeqCst) {\n-                    KILL_RUNNING => rtabort!(\"tried to wake an already-running task\"),\n+                    KILL_RUNNING => None, // woken from select(), perhaps\n                     KILL_KILLED  => None, // a killer stole it already\n                     task_ptr     =>\n                         Some(unsafe { revive_task_ptr(task_ptr, Some(flag_arc)) })\n@@ -162,6 +168,27 @@ impl BlockedTask {\n         }\n     }\n \n+    /// Converts one blocked task handle to a list of many handles to the same.\n+    pub fn make_selectable(self, num_handles: uint) -> ~[BlockedTask] {\n+        let handles = match self {\n+            Unkillable(task) => {\n+                let flag = unsafe { KillFlag(AtomicUint::new(cast::transmute(task))) };\n+                UnsafeAtomicRcBox::newN(flag, num_handles)\n+            }\n+            Killable(flag_arc) => flag_arc.cloneN(num_handles),\n+        };\n+        // Even if the task was unkillable before, we use 'Killable' because\n+        // multiple pipes will have handles. It does not really mean killable.\n+        handles.consume_iter().transform(|x| Killable(x)).collect()\n+    }\n+\n+    // This assertion has two flavours because the wake involves an atomic op.\n+    // In the faster version, destructors will fail dramatically instead.\n+    #[inline] #[cfg(not(test))]\n+    pub fn assert_already_awake(self) { }\n+    #[inline] #[cfg(test)]\n+    pub fn assert_already_awake(self) { assert!(self.wake().is_none()); }\n+\n     /// Convert to an unsafe uint value. Useful for storing in a pipe's state flag.\n     #[inline]\n     pub unsafe fn cast_to_uint(self) -> uint {\n@@ -301,7 +328,7 @@ impl KillHandle {\n         }\n \n         // Try to see if all our children are gone already.\n-        match unsafe { self.try_unwrap() } {\n+        match self.try_unwrap() {\n             // Couldn't unwrap; children still alive. Reparent entire handle as\n             // our own tombstone, to be unwrapped later.\n             Left(this) => {\n@@ -313,7 +340,7 @@ impl KillHandle {\n                         // Prefer to check tombstones that were there first,\n                         // being \"more fair\" at the expense of tail-recursion.\n                         others.take().map_consume_default(true, |f| f()) && {\n-                            let mut inner = unsafe { this.take().unwrap() };\n+                            let mut inner = this.take().unwrap();\n                             (!inner.any_child_failed) &&\n                                 inner.child_tombstones.take_map_default(true, |f| f())\n                         }\n@@ -402,7 +429,7 @@ impl Death {\n         do self.on_exit.take_map |on_exit| {\n             if success {\n                 // We succeeded, but our children might not. Need to wait for them.\n-                let mut inner = unsafe { self.kill_handle.take_unwrap().unwrap() };\n+                let mut inner = self.kill_handle.take_unwrap().unwrap();\n                 if inner.any_child_failed {\n                     success = false;\n                 } else {\n@@ -528,7 +555,7 @@ mod test {\n \n             // Without another handle to child, the try unwrap should succeed.\n             child.reparent_children_to(&mut parent);\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             assert!(parent_inner.child_tombstones.is_none());\n             assert!(parent_inner.any_child_failed == false);\n         }\n@@ -543,7 +570,7 @@ mod test {\n             child.notify_immediate_failure();\n             // Without another handle to child, the try unwrap should succeed.\n             child.reparent_children_to(&mut parent);\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             assert!(parent_inner.child_tombstones.is_none());\n             // Immediate failure should have been propagated.\n             assert!(parent_inner.any_child_failed);\n@@ -565,7 +592,7 @@ mod test {\n             // Otherwise, due to 'link', it would try to tombstone.\n             child2.reparent_children_to(&mut parent);\n             // Should successfully unwrap even though 'link' is still alive.\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             assert!(parent_inner.child_tombstones.is_none());\n             // Immediate failure should have been propagated by first child.\n             assert!(parent_inner.any_child_failed);\n@@ -584,7 +611,7 @@ mod test {\n             // Let parent collect tombstones.\n             util::ignore(link);\n             // Must have created a tombstone\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             assert!(parent_inner.child_tombstones.take_unwrap()());\n             assert!(parent_inner.any_child_failed == false);\n         }\n@@ -603,7 +630,7 @@ mod test {\n             // Let parent collect tombstones.\n             util::ignore(link);\n             // Must have created a tombstone\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             // Failure must be seen in the tombstone.\n             assert!(parent_inner.child_tombstones.take_unwrap()() == false);\n             assert!(parent_inner.any_child_failed == false);\n@@ -623,7 +650,7 @@ mod test {\n             // Let parent collect tombstones.\n             util::ignore(link);\n             // Must have created a tombstone\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             assert!(parent_inner.child_tombstones.take_unwrap()());\n             assert!(parent_inner.any_child_failed == false);\n         }\n@@ -644,7 +671,7 @@ mod test {\n             // Let parent collect tombstones.\n             util::ignore(link);\n             // Must have created a tombstone\n-            let mut parent_inner = unsafe { parent.unwrap() };\n+            let mut parent_inner = parent.unwrap();\n             // Failure must be seen in the tombstone.\n             assert!(parent_inner.child_tombstones.take_unwrap()() == false);\n             assert!(parent_inner.any_child_failed == false);"}, {"sha": "2ca7d01da49a21522665291d626a10bc87d5b733", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -142,6 +142,9 @@ pub mod tube;\n /// Simple reimplementation of core::comm\n pub mod comm;\n \n+/// Routines for select()ing on pipes.\n+pub mod select;\n+\n // FIXME #5248 shouldn't be pub\n /// The runtime needs to be able to put a pointer into thread-local storage.\n pub mod local_ptr;"}, {"sha": "bc9e265c8d99825ca219e099184316324a3799c0", "filename": "src/libstd/rt/select.rs", "status": "added", "additions": 328, "deletions": 0, "changes": 328, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fselect.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Frt%2Fselect.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fselect.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -0,0 +1,328 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use option::*;\n+// use either::{Either, Left, Right};\n+use rt::kill::BlockedTask;\n+use rt::sched::Scheduler;\n+use rt::local::Local;\n+\n+/// Trait for message-passing primitives that can be select()ed on.\n+pub trait Select {\n+    // Returns true if data was available.\n+    fn optimistic_check(&mut self) -> bool;\n+    // Returns true if data was available. If so, shall also wake() the task.\n+    fn block_on(&mut self, &mut Scheduler, BlockedTask) -> bool;\n+    // Returns true if data was available.\n+    fn unblock_from(&mut self) -> bool;\n+}\n+\n+/// Trait for message-passing primitives that can use the select2() convenience wrapper.\n+// (This is separate from the above trait to enable heterogeneous lists of ports\n+// that implement Select on different types to use select().)\n+pub trait SelectPort<T> : Select {\n+    fn recv_ready(self) -> Option<T>;\n+}\n+\n+/// Receive a message from any one of many ports at once.\n+pub fn select<A: Select>(ports: &mut [A]) -> uint {\n+    if ports.is_empty() {\n+        fail!(\"can't select on an empty list\");\n+    }\n+\n+    for ports.mut_iter().enumerate().advance |(index, port)| {\n+        if port.optimistic_check() {\n+            return index;\n+        }\n+    }\n+\n+    // If one of the ports already contains data when we go to block on it, we\n+    // don't bother enqueueing on the rest of them, so we shouldn't bother\n+    // unblocking from it either. This is just for efficiency, not correctness.\n+    // (If not, we need to unblock from all of them. Length is a placeholder.)\n+    let mut ready_index = ports.len();\n+\n+    let sched = Local::take::<Scheduler>();\n+    do sched.deschedule_running_task_and_then |sched, task| {\n+        let task_handles = task.make_selectable(ports.len());\n+\n+        for ports.mut_iter().zip(task_handles.consume_iter()).enumerate().advance\n+                |(index, (port, task_handle))| {\n+            // If one of the ports has data by now, it will wake the handle.\n+            if port.block_on(sched, task_handle) {\n+                ready_index = index;\n+                break;\n+            }\n+        }\n+    }\n+\n+    // Task resumes. Now unblock ourselves from all the ports we blocked on.\n+    // If the success index wasn't reset, 'take' will just take all of them.\n+    // Iterate in reverse so the 'earliest' index that's ready gets returned.\n+    for ports.mut_slice(0, ready_index).mut_rev_iter().enumerate().advance |(index, port)| {\n+        if port.unblock_from() {\n+            ready_index = index;\n+        }\n+    }\n+\n+    assert!(ready_index < ports.len());\n+    return ready_index;\n+}\n+\n+/* FIXME(#5121, #7914) This all should be legal, but rust is not clever enough yet.\n+\n+impl <'self> Select for &'self mut Select {\n+    fn optimistic_check(&mut self) -> bool { self.optimistic_check() }\n+    fn block_on(&mut self, sched: &mut Scheduler, task: BlockedTask) -> bool {\n+        self.block_on(sched, task)\n+    }\n+    fn unblock_from(&mut self) -> bool { self.unblock_from() }\n+}\n+\n+pub fn select2<TA, A: SelectPort<TA>, TB, B: SelectPort<TB>>(mut a: A, mut b: B)\n+        -> Either<(Option<TA>, B), (A, Option<TB>)> {\n+    let result = {\n+        let mut ports = [&mut a as &mut Select, &mut b as &mut Select];\n+        select(ports)\n+    };\n+    match result {\n+        0 => Left ((a.recv_ready(), b)),\n+        1 => Right((a, b.recv_ready())),\n+        x => fail!(\"impossible case in select2: %?\", x)\n+    }\n+}\n+\n+*/\n+\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+    use option::*;\n+    use rt::comm::*;\n+    use rt::test::*;\n+    use vec::*;\n+    use comm::GenericChan;\n+    use task;\n+    use cell::Cell;\n+\n+    #[test] #[ignore(cfg(windows))] #[should_fail]\n+    fn select_doesnt_get_trolled() {\n+        select::<PortOne<()>>([]);\n+    }\n+\n+    /* non-blocking select tests */\n+\n+    #[cfg(test)]\n+    fn select_helper(num_ports: uint, send_on_chans: &[uint]) {\n+        // Unfortunately this does not actually test the block_on early-break\n+        // codepath in select -- racing between the sender and the receiver in\n+        // separate tasks is necessary to get around the optimistic check.\n+        let (ports, chans) = unzip(from_fn(num_ports, |_| oneshot::<()>()));\n+        let mut dead_chans = ~[];\n+        let mut ports = ports;\n+        for chans.consume_iter().enumerate().advance |(i, chan)| {\n+            if send_on_chans.contains(&i) {\n+                chan.send(());\n+            } else {\n+                dead_chans.push(chan);\n+            }\n+        }\n+        let ready_index = select(ports);\n+        assert!(send_on_chans.contains(&ready_index));\n+        assert!(ports.swap_remove(ready_index).recv_ready().is_some());\n+        let _ = dead_chans;\n+\n+        // Same thing with streams instead.\n+        // FIXME(#7971): This should be in a macro but borrowck isn't smart enough.\n+        let (ports, chans) = unzip(from_fn(num_ports, |_| stream::<()>()));\n+        let mut dead_chans = ~[];\n+        let mut ports = ports;\n+        for chans.consume_iter().enumerate().advance |(i, chan)| {\n+            if send_on_chans.contains(&i) {\n+                chan.send(());\n+            } else {\n+                dead_chans.push(chan);\n+            }\n+        }\n+        let ready_index = select(ports);\n+        assert!(send_on_chans.contains(&ready_index));\n+        assert!(ports.swap_remove(ready_index).recv_ready().is_some());\n+        let _ = dead_chans;\n+    }\n+\n+    #[test]\n+    fn select_one() {\n+        do run_in_newsched_task { select_helper(1, [0]) }\n+    }\n+\n+    #[test]\n+    fn select_two() {\n+        // NB. I would like to have a test that tests the first one that is\n+        // ready is the one that's returned, but that can't be reliably tested\n+        // with the randomized behaviour of optimistic_check.\n+        do run_in_newsched_task { select_helper(2, [1]) }\n+        do run_in_newsched_task { select_helper(2, [0]) }\n+        do run_in_newsched_task { select_helper(2, [1,0]) }\n+    }\n+\n+    #[test]\n+    fn select_a_lot() {\n+        do run_in_newsched_task { select_helper(12, [7,8,9]) }\n+    }\n+\n+    #[test]\n+    fn select_stream() {\n+        use util;\n+        use comm::GenericChan;\n+\n+        // Sends 10 buffered packets, and uses select to retrieve them all.\n+        // Puts the port in a different spot in the vector each time.\n+        do run_in_newsched_task {\n+            let (ports, _) = unzip(from_fn(10, |_| stream()));\n+            let (port, chan) = stream();\n+            for 10.times { chan.send(31337); }\n+            let mut ports = ports;\n+            let mut port = Some(port);\n+            let order = [5u,0,4,3,2,6,9,8,7,1];\n+            for order.iter().advance |&index| {\n+                // put the port in the vector at any index\n+                util::swap(port.get_mut_ref(), &mut ports[index]);\n+                assert!(select(ports) == index);\n+                // get it back out\n+                util::swap(port.get_mut_ref(), &mut ports[index]);\n+                // NB. Not recv(), because optimistic_check randomly fails.\n+                let (data, new_port) = port.take_unwrap().recv_ready().unwrap();\n+                assert!(data == 31337);\n+                port = Some(new_port);\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn select_unkillable() {\n+        do run_in_newsched_task {\n+            do task::unkillable { select_helper(2, [1]) }\n+        }\n+    }\n+\n+    /* blocking select tests */\n+\n+    #[test]\n+    fn select_blocking() {\n+        select_blocking_helper(true);\n+        select_blocking_helper(false);\n+\n+        fn select_blocking_helper(killable: bool) {\n+            do run_in_newsched_task {\n+                let (p1,_c) = oneshot();\n+                let (p2,c2) = oneshot();\n+                let mut ports = [p1,p2];\n+\n+                let (p3,c3) = oneshot();\n+                let (p4,c4) = oneshot();\n+\n+                let x = Cell::new((c2, p3, c4));\n+                do task::spawn {\n+                    let (c2, p3, c4) = x.take();\n+                    p3.recv();   // handshake parent\n+                    c4.send(()); // normal receive\n+                    task::yield();\n+                    c2.send(()); // select receive\n+                }\n+\n+                // Try to block before child sends on c2.\n+                c3.send(());\n+                p4.recv();\n+                if killable {\n+                    assert!(select(ports) == 1);\n+                } else {\n+                    do task::unkillable { assert!(select(ports) == 1); }\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn select_racing_senders() {\n+        static NUM_CHANS: uint = 10;\n+\n+        select_racing_senders_helper(true,  ~[0,1,2,3,4,5,6,7,8,9]);\n+        select_racing_senders_helper(false, ~[0,1,2,3,4,5,6,7,8,9]);\n+        select_racing_senders_helper(true,  ~[0,1,2]);\n+        select_racing_senders_helper(false, ~[0,1,2]);\n+        select_racing_senders_helper(true,  ~[3,4,5,6]);\n+        select_racing_senders_helper(false, ~[3,4,5,6]);\n+        select_racing_senders_helper(true,  ~[7,8,9]);\n+        select_racing_senders_helper(false, ~[7,8,9]);\n+\n+        fn select_racing_senders_helper(killable: bool, send_on_chans: ~[uint]) {\n+            use uint;\n+            use rt::test::spawntask_random;\n+\n+            do run_in_newsched_task {\n+                // A bit of stress, since ordinarily this is just smoke and mirrors.\n+                for 4.times {\n+                    let send_on_chans = send_on_chans.clone();\n+                    do task::spawn {\n+                        let mut ports = ~[];\n+                        for uint::range(0, NUM_CHANS) |i| {\n+                            let (p,c) = oneshot();\n+                            ports.push(p);\n+                            if send_on_chans.contains(&i) {\n+                                let c = Cell::new(c);\n+                                do spawntask_random {\n+                                    task::yield();\n+                                    c.take().send(());\n+                                }\n+                            }\n+                        }\n+                        // nondeterministic result, but should succeed\n+                        if killable {\n+                            select(ports);\n+                        } else {\n+                            do task::unkillable { select(ports); }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test] #[ignore(cfg(windows))]\n+    fn select_killed() {\n+        do run_in_newsched_task {\n+            let (success_p, success_c) = oneshot::<bool>();\n+            let success_c = Cell::new(success_c);\n+            do task::try {\n+                let success_c = Cell::new(success_c.take());\n+                do task::unkillable {\n+                    let (p,c) = oneshot();\n+                    let c = Cell::new(c);\n+                    do task::spawn {\n+                        let (dead_ps, dead_cs) = unzip(from_fn(5, |_| oneshot::<()>()));\n+                        let mut ports = dead_ps;\n+                        select(ports); // should get killed; nothing should leak\n+                        c.take().send(()); // must not happen\n+                        // Make sure dead_cs doesn't get closed until after select.\n+                        let _ = dead_cs;\n+                    }\n+                    do task::spawn {\n+                        fail!(); // should kill sibling awake\n+                    }\n+\n+                    // wait for killed selector to close (NOT send on) its c.\n+                    // hope to send 'true'.\n+                    success_c.take().send(p.try_recv().is_none());\n+                }\n+            };\n+            assert!(success_p.recv());\n+        }\n+    }\n+}"}, {"sha": "c26349b220d9438a219bbecf07b47c8664e219a7", "filename": "src/libstd/task/mod.rs", "status": "modified", "additions": 23, "deletions": 21, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Ftask%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Ftask%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fmod.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -618,32 +618,34 @@ pub fn get_scheduler() -> Scheduler {\n  * }\n  * ~~~\n  */\n-pub unsafe fn unkillable<U>(f: &fn() -> U) -> U {\n+pub fn unkillable<U>(f: &fn() -> U) -> U {\n     use rt::task::Task;\n \n-    match context() {\n-        OldTaskContext => {\n-            let t = rt::rust_get_task();\n-            do (|| {\n-                rt::rust_task_inhibit_kill(t);\n-                f()\n-            }).finally {\n-                rt::rust_task_allow_kill(t);\n+    unsafe {\n+        match context() {\n+            OldTaskContext => {\n+                let t = rt::rust_get_task();\n+                do (|| {\n+                    rt::rust_task_inhibit_kill(t);\n+                    f()\n+                }).finally {\n+                    rt::rust_task_allow_kill(t);\n+                }\n             }\n-        }\n-        TaskContext => {\n-            // The inhibits/allows might fail and need to borrow the task.\n-            let t = Local::unsafe_borrow::<Task>();\n-            do (|| {\n-                (*t).death.inhibit_kill((*t).unwinder.unwinding);\n-                f()\n-            }).finally {\n-                (*t).death.allow_kill((*t).unwinder.unwinding);\n+            TaskContext => {\n+                // The inhibits/allows might fail and need to borrow the task.\n+                let t = Local::unsafe_borrow::<Task>();\n+                do (|| {\n+                    (*t).death.inhibit_kill((*t).unwinder.unwinding);\n+                    f()\n+                }).finally {\n+                    (*t).death.allow_kill((*t).unwinder.unwinding);\n+                }\n             }\n+            // FIXME(#3095): This should be an rtabort as soon as the scheduler\n+            // no longer uses a workqueue implemented with an Exclusive.\n+            _ => f()\n         }\n-        // FIXME(#3095): This should be an rtabort as soon as the scheduler\n-        // no longer uses a workqueue implemented with an Exclusive.\n-        _ => f()\n     }\n }\n "}, {"sha": "749db307012312a6ecad0b1630d1d995babf487d", "filename": "src/libstd/task/spawn.rs", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fspawn.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -512,7 +512,9 @@ impl RuntimeGlue {\n     unsafe fn kill_all_tasks(task: &TaskHandle) {\n         match *task {\n             OldTask(ptr) => rt::rust_task_kill_all(ptr),\n-            NewTask(ref _handle) => rtabort!(\"unimplemented\"), // FIXME(#7544)\n+            // FIXME(#7544): Remove the kill_all feature entirely once the\n+            // oldsched goes away.\n+            NewTask(ref _handle) => rtabort!(\"can't kill_all in newsched\"),\n         }\n     }\n \n@@ -573,7 +575,10 @@ impl RuntimeGlue {\n                             members: members,\n                             descendants: TaskSet::new(),\n                         }));\n-                        let group = Taskgroup(tasks, AncestorList(None), true, None);\n+                        // FIXME(#7544): Remove the is_main flag entirely once\n+                        // the newsched goes away. The main taskgroup has no special\n+                        // behaviour.\n+                        let group = Taskgroup(tasks, AncestorList(None), false, None);\n                         (*me).taskgroup = Some(group);\n                         (*me).taskgroup.get_ref()\n                     }\n@@ -689,7 +694,7 @@ fn spawn_raw_newsched(mut opts: TaskOpts, f: ~fn()) {\n         // Should be run after the local-borrowed task is returned.\n         if enlist_success {\n             if indestructible {\n-                unsafe { do unkillable { f() } }\n+                do unkillable { f() }\n             } else {\n                 f()\n             }"}, {"sha": "4c52d897a7212557624ccca77367fdd6f8d22e7b", "filename": "src/libstd/unstable/sync.rs", "status": "modified", "additions": 181, "deletions": 128, "changes": 309, "blob_url": "https://github.com/rust-lang/rust/blob/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Funstable%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5633a5363b6c650500b8b6496ddd49ea8c698f92/src%2Flibstd%2Funstable%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fsync.rs?ref=5633a5363b6c650500b8b6496ddd49ea8c698f92", "patch": "@@ -22,6 +22,7 @@ use unstable::finally::Finally;\n use ops::Drop;\n use clone::Clone;\n use kinds::Send;\n+use vec;\n \n /// An atomically reference counted pointer.\n ///\n@@ -41,138 +42,172 @@ struct AtomicRcBoxData<T> {\n     data: Option<T>,\n }\n \n+unsafe fn new_inner<T: Send>(data: T, refcount: uint) -> *mut libc::c_void {\n+    let data = ~AtomicRcBoxData { count: AtomicUint::new(refcount),\n+                                  unwrapper: AtomicOption::empty(),\n+                                  data: Some(data) };\n+    cast::transmute(data)\n+}\n+\n impl<T: Send> UnsafeAtomicRcBox<T> {\n     pub fn new(data: T) -> UnsafeAtomicRcBox<T> {\n-        unsafe {\n-            let data = ~AtomicRcBoxData { count: AtomicUint::new(1),\n-                                          unwrapper: AtomicOption::empty(),\n-                                          data: Some(data) };\n-            let ptr = cast::transmute(data);\n-            return UnsafeAtomicRcBox { data: ptr };\n-        }\n+        unsafe { UnsafeAtomicRcBox { data: new_inner(data, 1) } }\n     }\n \n     /// As new(), but returns an extra pre-cloned handle.\n     pub fn new2(data: T) -> (UnsafeAtomicRcBox<T>, UnsafeAtomicRcBox<T>) {\n         unsafe {\n-            let data = ~AtomicRcBoxData { count: AtomicUint::new(2),\n-                                          unwrapper: AtomicOption::empty(),\n-                                          data: Some(data) };\n-            let ptr = cast::transmute(data);\n-            return (UnsafeAtomicRcBox { data: ptr },\n-                    UnsafeAtomicRcBox { data: ptr });\n+            let ptr = new_inner(data, 2);\n+            (UnsafeAtomicRcBox { data: ptr }, UnsafeAtomicRcBox { data: ptr })\n+        }\n+    }\n+\n+    /// As new(), but returns a vector of as many pre-cloned handles as requested.\n+    pub fn newN(data: T, num_handles: uint) -> ~[UnsafeAtomicRcBox<T>] {\n+        unsafe {\n+            if num_handles == 0 {\n+                ~[] // need to free data here\n+            } else {\n+                let ptr = new_inner(data, num_handles);\n+                vec::from_fn(num_handles, |_| UnsafeAtomicRcBox { data: ptr })\n+            }\n+        }\n+    }\n+\n+    /// As newN(), but from an already-existing handle. Uses one xadd.\n+    pub fn cloneN(self, num_handles: uint) -> ~[UnsafeAtomicRcBox<T>] {\n+        if num_handles == 0 {\n+            ~[] // The \"num_handles - 1\" trick (below) fails in the 0 case.\n+        } else {\n+            unsafe {\n+                let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n+                // Minus one because we are recycling the given handle's refcount.\n+                let old_count = data.count.fetch_add(num_handles - 1, Acquire);\n+                // let old_count = data.count.fetch_add(num_handles, Acquire);\n+                assert!(old_count >= 1);\n+                let ptr = cast::transmute(data);\n+                cast::forget(self); // Don't run the destructor on this handle.\n+                vec::from_fn(num_handles, |_| UnsafeAtomicRcBox { data: ptr })\n+            }\n         }\n     }\n \n     #[inline]\n-    pub unsafe fn get(&self) -> *mut T\n-    {\n-        let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n-        assert!(data.count.load(Acquire) > 0); // no barrier is really needed\n-        let r: *mut T = data.data.get_mut_ref();\n-        cast::forget(data);\n-        return r;\n+    pub fn get(&self) -> *mut T {\n+        unsafe {\n+            let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n+            // FIXME(#6598) Change Acquire to Relaxed.\n+            assert!(data.count.load(Acquire) > 0);\n+            let r: *mut T = data.data.get_mut_ref();\n+            cast::forget(data);\n+            return r;\n+        }\n     }\n \n     #[inline]\n-    pub unsafe fn get_immut(&self) -> *T\n-    {\n-        let data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n-        assert!(data.count.load(Acquire) > 0); // no barrier is really needed\n-        let r: *T = data.data.get_ref();\n-        cast::forget(data);\n-        return r;\n+    pub fn get_immut(&self) -> *T {\n+        unsafe {\n+            let data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n+            assert!(data.count.load(Acquire) > 0); // no barrier is really needed\n+            let r: *T = data.data.get_ref();\n+            cast::forget(data);\n+            return r;\n+        }\n     }\n \n     /// Wait until all other handles are dropped, then retrieve the enclosed\n     /// data. See extra::arc::Arc for specific semantics documentation.\n     /// If called when the task is already unkillable, unwrap will unkillably\n     /// block; otherwise, an unwrapping task can be killed by linked failure.\n-    pub unsafe fn unwrap(self) -> T {\n+    pub fn unwrap(self) -> T {\n         let this = Cell::new(self); // argh\n         do task::unkillable {\n-            let mut this = this.take();\n-            let mut data: ~AtomicRcBoxData<T> = cast::transmute(this.data);\n-            // Set up the unwrap protocol.\n-            let (p1,c1) = comm::oneshot(); // ()\n-            let (p2,c2) = comm::oneshot(); // bool\n-            // Try to put our server end in the unwrapper slot.\n-            // This needs no barrier -- it's protected by the release barrier on\n-            // the xadd, and the acquire+release barrier in the destructor's xadd.\n-            // FIXME(#6598) Change Acquire to Relaxed.\n-            if data.unwrapper.fill(~(c1,p2), Acquire).is_none() {\n-                // Got in. Tell this handle's destructor not to run (we are now it).\n-                this.data = ptr::mut_null();\n-                // Drop our own reference.\n-                let old_count = data.count.fetch_sub(1, Release);\n-                assert!(old_count >= 1);\n-                if old_count == 1 {\n-                    // We were the last owner. Can unwrap immediately.\n-                    // AtomicOption's destructor will free the server endpoint.\n-                    // FIXME(#3224): it should be like this\n-                    // let ~AtomicRcBoxData { data: user_data, _ } = data;\n-                    // user_data\n-                    data.data.take_unwrap()\n-                } else {\n-                    // The *next* person who sees the refcount hit 0 will wake us.\n-                    let p1 = Cell::new(p1); // argh\n-                    // Unlike the above one, this cell is necessary. It will get\n-                    // taken either in the do block or in the finally block.\n-                    let c2_and_data = Cell::new((c2,data));\n-                    do (|| {\n-                        do task::rekillable { p1.take().recv(); }\n-                        // Got here. Back in the 'unkillable' without getting killed.\n-                        let (c2, data) = c2_and_data.take();\n-                        c2.send(true);\n+            unsafe {\n+                let mut this = this.take();\n+                let mut data: ~AtomicRcBoxData<T> = cast::transmute(this.data);\n+                // Set up the unwrap protocol.\n+                let (p1,c1) = comm::oneshot(); // ()\n+                let (p2,c2) = comm::oneshot(); // bool\n+                // Try to put our server end in the unwrapper slot.\n+                // This needs no barrier -- it's protected by the release barrier on\n+                // the xadd, and the acquire+release barrier in the destructor's xadd.\n+                // FIXME(#6598) Change Acquire to Relaxed.\n+                if data.unwrapper.fill(~(c1,p2), Acquire).is_none() {\n+                    // Got in. Tell this handle's destructor not to run (we are now it).\n+                    this.data = ptr::mut_null();\n+                    // Drop our own reference.\n+                    let old_count = data.count.fetch_sub(1, Release);\n+                    assert!(old_count >= 1);\n+                    if old_count == 1 {\n+                        // We were the last owner. Can unwrap immediately.\n+                        // AtomicOption's destructor will free the server endpoint.\n                         // FIXME(#3224): it should be like this\n                         // let ~AtomicRcBoxData { data: user_data, _ } = data;\n                         // user_data\n-                        let mut data = data;\n                         data.data.take_unwrap()\n-                    }).finally {\n-                        if task::failing() {\n-                            // Killed during wait. Because this might happen while\n-                            // someone else still holds a reference, we can't free\n-                            // the data now; the \"other\" last refcount will free it.\n+                    } else {\n+                        // The *next* person who sees the refcount hit 0 will wake us.\n+                        let p1 = Cell::new(p1); // argh\n+                        // Unlike the above one, this cell is necessary. It will get\n+                        // taken either in the do block or in the finally block.\n+                        let c2_and_data = Cell::new((c2,data));\n+                        do (|| {\n+                            do task::rekillable { p1.take().recv(); }\n+                            // Got here. Back in the 'unkillable' without getting killed.\n                             let (c2, data) = c2_and_data.take();\n-                            c2.send(false);\n-                            cast::forget(data);\n-                        } else {\n-                            assert!(c2_and_data.is_empty());\n+                            c2.send(true);\n+                            // FIXME(#3224): it should be like this\n+                            // let ~AtomicRcBoxData { data: user_data, _ } = data;\n+                            // user_data\n+                            let mut data = data;\n+                            data.data.take_unwrap()\n+                        }).finally {\n+                            if task::failing() {\n+                                // Killed during wait. Because this might happen while\n+                                // someone else still holds a reference, we can't free\n+                                // the data now; the \"other\" last refcount will free it.\n+                                let (c2, data) = c2_and_data.take();\n+                                c2.send(false);\n+                                cast::forget(data);\n+                            } else {\n+                                assert!(c2_and_data.is_empty());\n+                            }\n                         }\n                     }\n+                } else {\n+                    // If 'put' returns the server end back to us, we were rejected;\n+                    // someone else was trying to unwrap. Avoid guaranteed deadlock.\n+                    cast::forget(data);\n+                    fail!(\"Another task is already unwrapping this Arc!\");\n                 }\n-            } else {\n-                // If 'put' returns the server end back to us, we were rejected;\n-                // someone else was trying to unwrap. Avoid guaranteed deadlock.\n-                cast::forget(data);\n-                fail!(\"Another task is already unwrapping this Arc!\");\n             }\n         }\n     }\n \n     /// As unwrap above, but without blocking. Returns 'Left(self)' if this is\n     /// not the last reference; 'Right(unwrapped_data)' if so.\n-    pub unsafe fn try_unwrap(self) -> Either<UnsafeAtomicRcBox<T>, T> {\n-        let mut this = self; // FIXME(#4330) mutable self\n-        let mut data: ~AtomicRcBoxData<T> = cast::transmute(this.data);\n-        // This can of course race with anybody else who has a handle, but in\n-        // such a case, the returned count will always be at least 2. If we\n-        // see 1, no race was possible. All that matters is 1 or not-1.\n-        let count = data.count.load(Acquire);\n-        assert!(count >= 1);\n-        // The more interesting race is one with an unwrapper. They may have\n-        // already dropped their count -- but if so, the unwrapper pointer\n-        // will have been set first, which the barriers ensure we will see.\n-        // (Note: using is_empty(), not take(), to not free the unwrapper.)\n-        if count == 1 && data.unwrapper.is_empty(Acquire) {\n-            // Tell this handle's destructor not to run (we are now it).\n-            this.data = ptr::mut_null();\n-            // FIXME(#3224) as above\n-            Right(data.data.take_unwrap())\n-        } else {\n-            cast::forget(data);\n-            Left(this)\n+    pub fn try_unwrap(self) -> Either<UnsafeAtomicRcBox<T>, T> {\n+        unsafe {\n+            let mut this = self; // FIXME(#4330) mutable self\n+            let mut data: ~AtomicRcBoxData<T> = cast::transmute(this.data);\n+            // This can of course race with anybody else who has a handle, but in\n+            // such a case, the returned count will always be at least 2. If we\n+            // see 1, no race was possible. All that matters is 1 or not-1.\n+            let count = data.count.load(Acquire);\n+            assert!(count >= 1);\n+            // The more interesting race is one with an unwrapper. They may have\n+            // already dropped their count -- but if so, the unwrapper pointer\n+            // will have been set first, which the barriers ensure we will see.\n+            // (Note: using is_empty(), not take(), to not free the unwrapper.)\n+            if count == 1 && data.unwrapper.is_empty(Acquire) {\n+                // Tell this handle's destructor not to run (we are now it).\n+                this.data = ptr::mut_null();\n+                // FIXME(#3224) as above\n+                Right(data.data.take_unwrap())\n+            } else {\n+                cast::forget(data);\n+                Left(this)\n+            }\n         }\n     }\n }\n@@ -342,7 +377,7 @@ impl<T:Send> Exclusive<T> {\n     pub fn unwrap(self) -> T {\n         let Exclusive { x: x } = self;\n         // Someday we might need to unkillably unwrap an Exclusive, but not today.\n-        let inner = unsafe { x.unwrap() };\n+        let inner = x.unwrap();\n         let ExData { data: user_data, _ } = inner; // will destroy the LittleLock\n         user_data\n     }\n@@ -416,53 +451,71 @@ mod tests {\n         }\n     }\n \n+    #[test]\n+    fn arclike_newN() {\n+        // Tests that the many-refcounts-at-once constructors don't leak.\n+        let _ = UnsafeAtomicRcBox::new2(~~\"hello\");\n+        let x = UnsafeAtomicRcBox::newN(~~\"hello\", 0);\n+        assert_eq!(x.len(), 0)\n+        let x = UnsafeAtomicRcBox::newN(~~\"hello\", 1);\n+        assert_eq!(x.len(), 1)\n+        let x = UnsafeAtomicRcBox::newN(~~\"hello\", 10);\n+        assert_eq!(x.len(), 10)\n+    }\n+\n+    #[test]\n+    fn arclike_cloneN() {\n+        // Tests that the many-refcounts-at-once special-clone doesn't leak.\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        let x = x.cloneN(0);\n+        assert_eq!(x.len(), 0);\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        let x = x.cloneN(1);\n+        assert_eq!(x.len(), 1);\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        let x = x.cloneN(10);\n+        assert_eq!(x.len(), 10);\n+    }\n+\n     #[test]\n     fn arclike_unwrap_basic() {\n-        unsafe {\n-            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n-            assert!(x.unwrap() == ~~\"hello\");\n-        }\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        assert!(x.unwrap() == ~~\"hello\");\n     }\n \n     #[test]\n     fn arclike_try_unwrap() {\n-        unsafe {\n-            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n-            assert!(x.try_unwrap().expect_right(\"try_unwrap failed\") == ~~\"hello\");\n-        }\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        assert!(x.try_unwrap().expect_right(\"try_unwrap failed\") == ~~\"hello\");\n     }\n \n     #[test]\n     fn arclike_try_unwrap_fail() {\n-        unsafe {\n-            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n-            let x2 = x.clone();\n-            let left_x = x.try_unwrap();\n-            assert!(left_x.is_left());\n-            util::ignore(left_x);\n-            assert!(x2.try_unwrap().expect_right(\"try_unwrap none\") == ~~\"hello\");\n-        }\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        let x2 = x.clone();\n+        let left_x = x.try_unwrap();\n+        assert!(left_x.is_left());\n+        util::ignore(left_x);\n+        assert!(x2.try_unwrap().expect_right(\"try_unwrap none\") == ~~\"hello\");\n     }\n \n     #[test]\n     fn arclike_try_unwrap_unwrap_race() {\n         // When an unwrap and a try_unwrap race, the unwrapper should always win.\n-        unsafe {\n-            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n-            let x2 = Cell::new(x.clone());\n-            let (p,c) = comm::stream();\n-            do task::spawn {\n-                c.send(());\n-                assert!(x2.take().unwrap() == ~~\"hello\");\n-                c.send(());\n-            }\n-            p.recv();\n-            task::yield(); // Try to make the unwrapper get blocked first.\n-            let left_x = x.try_unwrap();\n-            assert!(left_x.is_left());\n-            util::ignore(left_x);\n-            p.recv();\n+        let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+        let x2 = Cell::new(x.clone());\n+        let (p,c) = comm::stream();\n+        do task::spawn {\n+            c.send(());\n+            assert!(x2.take().unwrap() == ~~\"hello\");\n+            c.send(());\n         }\n+        p.recv();\n+        task::yield(); // Try to make the unwrapper get blocked first.\n+        let left_x = x.try_unwrap();\n+        assert!(left_x.is_left());\n+        util::ignore(left_x);\n+        p.recv();\n     }\n \n     #[test]"}]}