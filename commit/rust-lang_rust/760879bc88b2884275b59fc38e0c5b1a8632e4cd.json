{"sha": "760879bc88b2884275b59fc38e0c5b1a8632e4cd", "node_id": "MDY6Q29tbWl0NzI0NzEyOjc2MDg3OWJjODhiMjg4NDI3NWI1OWZjMzhlMGM1YjFhODYzMmU0Y2Q=", "commit": {"author": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-19T00:41:09Z"}, "committer": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-30T18:30:41Z"}, "message": "Allow `?` as a KleeneOp in the macro parser", "tree": {"sha": "e30d6d78427e636be17b7dc6ee08873f27c0215e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e30d6d78427e636be17b7dc6ee08873f27c0215e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/760879bc88b2884275b59fc38e0c5b1a8632e4cd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/760879bc88b2884275b59fc38e0c5b1a8632e4cd", "html_url": "https://github.com/rust-lang/rust/commit/760879bc88b2884275b59fc38e0c5b1a8632e4cd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/760879bc88b2884275b59fc38e0c5b1a8632e4cd/comments", "author": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "def3269a71be2e737cad27418a3dad9f5bd6cd32", "url": "https://api.github.com/repos/rust-lang/rust/commits/def3269a71be2e737cad27418a3dad9f5bd6cd32", "html_url": "https://github.com/rust-lang/rust/commit/def3269a71be2e737cad27418a3dad9f5bd6cd32"}], "stats": {"total": 130, "additions": 84, "deletions": 46}, "files": [{"sha": "f8ae8726bc1e6309da5eb0ddc7211ff945535f77", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 84, "deletions": 46, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/760879bc88b2884275b59fc38e0c5b1a8632e4cd/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/760879bc88b2884275b59fc38e0c5b1a8632e4cd/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=760879bc88b2884275b59fc38e0c5b1a8632e4cd", "patch": "@@ -16,6 +16,7 @@ use symbol::keywords;\n use syntax_pos::{BytePos, Span, DUMMY_SP};\n use tokenstream;\n \n+use std::iter::Peekable;\n use std::rc::Rc;\n \n /// Contains the sub-token-trees of a \"delimited\" token tree, such as the contents of `(`. Note\n@@ -78,6 +79,7 @@ pub enum KleeneOp {\n     ZeroOrMore,\n     /// Kleene plus (`+`) for one or more repetitions\n     OneOrMore,\n+    ZeroOrOne,\n }\n \n /// Similar to `tokenstream::TokenTree`, except that `$i`, `$i:ident`, and `$(...)`\n@@ -183,7 +185,7 @@ pub fn parse(\n \n     // For each token tree in `input`, parse the token into a `self::TokenTree`, consuming\n     // additional trees if need be.\n-    let mut trees = input.trees();\n+    let mut trees = input.trees().peekable();\n     while let Some(tree) = trees.next() {\n         let tree = parse_tree(tree, &mut trees, expect_matchers, sess);\n \n@@ -321,6 +323,34 @@ where\n     }\n }\n \n+/// Takes a token and returns `Some(KleeneOp)` if the token is `+` `*` or `?`. Otherwise, return\n+/// `None`.\n+fn kleene_op(token: &token::Token) -> Option<KleeneOp> {\n+    match *token {\n+        token::BinOp(token::Star) => Some(KleeneOp::ZeroOrMore),\n+        token::BinOp(token::Plus) => Some(KleeneOp::OneOrMore),\n+        token::Question => Some(KleeneOp::ZeroOrOne),\n+        _ => None,\n+    }\n+}\n+\n+/// Parse the next token tree of the input looking for a KleeneOp. Returns\n+///\n+/// - Ok(Ok(op)) if the next token tree is a KleeneOp\n+/// - Ok(Err(tok, span)) if the next token tree is a token but not a KleeneOp\n+/// - Err(span) if the next token tree is not a token\n+fn parse_kleene_op<I>(input: &mut I, span: Span) -> Result<Result<KleeneOp, (token::Token, Span)>, Span>\n+    where I: Iterator<Item = tokenstream::TokenTree>,\n+{\n+    match input.next() {\n+        Some(tokenstream::TokenTree::Token(span, tok)) => match kleene_op(&tok) {\n+            Some(op) => Ok(Ok(op)),\n+            None => Ok(Err((tok, span))),\n+        }\n+        tree => Err(tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span)),\n+    }\n+}\n+\n /// Attempt to parse a single Kleene star, possibly with a separator.\n ///\n /// For example, in a pattern such as `$(a),*`, `a` is the pattern to be repeated, `,` is the\n@@ -333,56 +363,64 @@ where\n /// session `sess`. If the next one (or possibly two) tokens in `input` correspond to a Kleene\n /// operator and separator, then a tuple with `(separator, KleeneOp)` is returned. Otherwise, an\n /// error with the appropriate span is emitted to `sess` and a dummy value is returned.\n-fn parse_sep_and_kleene_op<I>(\n-    input: &mut I,\n-    span: Span,\n-    sess: &ParseSess,\n-) -> (Option<token::Token>, KleeneOp)\n-where\n-    I: Iterator<Item = tokenstream::TokenTree>,\n+fn parse_sep_and_kleene_op<I>(input: &mut Peekable<I>, span: Span, sess: &ParseSess)\n+                              -> (Option<token::Token>, KleeneOp)\n+    where I: Iterator<Item = tokenstream::TokenTree>,\n {\n-    fn kleene_op(token: &token::Token) -> Option<KleeneOp> {\n-        match *token {\n-            token::BinOp(token::Star) => Some(KleeneOp::ZeroOrMore),\n-            token::BinOp(token::Plus) => Some(KleeneOp::OneOrMore),\n-            _ => None,\n+    // We basically look at two token trees here, denoted as #1 and #2 below\n+    let span = match parse_kleene_op(input, span) {\n+        // #1 is a `+` or `*` KleeneOp\n+        //\n+        // `?` is ambiguous: it could be a separator or a Kleene::ZeroOrOne, so we need to look\n+        // ahead one more token to be sure.\n+        Ok(Ok(op)) if op != KleeneOp::ZeroOrOne => return (None, op),\n+\n+        // #1 is `?` token, but it could be a Kleene::ZeroOrOne without a separator or it could\n+        // be a `?` separator followed by any Kleene operator. We need to look ahead 1 token to\n+        // find out which.\n+        Ok(Ok(op)) => {\n+            // Lookahead at #2. If it is a KleenOp, then #1 is a separator.\n+            let is_1_sep = if let Some(&tokenstream::TokenTree::Token(_, ref tok2)) = input.peek() {\n+                kleene_op(tok2).is_some()\n+            } else {\n+                false\n+            };\n+\n+            if is_1_sep {\n+                // #1 is a separator and #2 should be a KleepeOp::*\n+                // (N.B. We need to advance the input iterator.)\n+                match parse_kleene_op(input, span) {\n+                    // #2 is a KleeneOp (this is the only valid option) :)\n+                    Ok(Ok(op)) => return (Some(token::Question), op),\n+\n+                    // #2 is a random token (this is an error) :(\n+                    Ok(Err((_, span))) => span,\n+\n+                    // #2 is not even a token at all :(\n+                    Err(span) => span,\n+                }\n+            } else {\n+                // #2 is a random tree and #1 is KleeneOp::ZeroOrOne\n+                return (None, op);\n+            }\n         }\n-    }\n \n-    // We attempt to look at the next two token trees in `input`. I will call the first #1 and the\n-    // second #2. If #1 and #2 don't match a valid KleeneOp with/without separator, that is an\n-    // error, and we should emit an error on the most specific span possible.\n-    let span = match input.next() {\n-        // #1 is a token\n-        Some(tokenstream::TokenTree::Token(span, tok)) => match kleene_op(&tok) {\n-            // #1 is a KleeneOp with no separator\n-            Some(op) => return (None, op),\n-\n-            // #1 is not a KleeneOp, but may be a separator... need to look at #2\n-            None => match input.next() {\n-                // #2 is a token\n-                Some(tokenstream::TokenTree::Token(span, tok2)) => match kleene_op(&tok2) {\n-                    // #2 is a KleeneOp, so #1 must be a separator\n-                    Some(op) => return (Some(tok), op),\n-\n-                    // #2 is not a KleeneOp... error\n-                    None => span,\n-                },\n-\n-                // #2 is not a token at all... error\n-                tree => tree.as_ref()\n-                    .map(tokenstream::TokenTree::span)\n-                    .unwrap_or(span),\n-            },\n-        },\n+        // #1 is a separator followed by #2, a KleeneOp\n+        Ok(Err((tok, span))) => match parse_kleene_op(input, span) {\n+            // #2 is a KleeneOp :D\n+            Ok(Ok(op)) => return (Some(tok), op),\n+\n+            // #2 is a random token :(\n+            Ok(Err((_, span))) => span,\n+\n+            // #2 is not a token at all :(\n+            Err(span) => span,\n+        }\n \n-        // #1 is not a token at all... error\n-        tree => tree.as_ref()\n-            .map(tokenstream::TokenTree::span)\n-            .unwrap_or(span),\n+        // #1 is not a token\n+        Err(span) => span,\n     };\n \n-    // Error...\n-    sess.span_diagnostic.span_err(span, \"expected `*` or `+`\");\n+    sess.span_diagnostic.span_err(span, \"expected one of: `*`,  `+`, or `?`\");\n     (None, KleeneOp::ZeroOrMore)\n }"}]}