{"sha": "b6d0eec3de0ac75ce81784251b4648a1cef7f628", "node_id": "C_kwDOAAsO6NoAKGI2ZDBlZWMzZGUwYWM3NWNlODE3ODQyNTFiNDY0OGExY2VmN2Y2Mjg", "commit": {"author": {"name": "Jubilee Young", "email": "workingjubilee@gmail.com", "date": "2021-12-09T00:44:21Z"}, "committer": {"name": "Jubilee Young", "email": "workingjubilee@gmail.com", "date": "2021-12-09T02:08:18Z"}, "message": "Wrap bitshifts in ops.rs\n\nFor all other operators, we use wrapping logic where applicable.\nThis is another case it applies. Per rust-lang/rust#91237, we may\nwish to specify this as the natural behavior of `simd_{shl,shr}`.", "tree": {"sha": "4bcdbefa62796374ee27ad091562e51950cef4b4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4bcdbefa62796374ee27ad091562e51950cef4b4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b6d0eec3de0ac75ce81784251b4648a1cef7f628", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b6d0eec3de0ac75ce81784251b4648a1cef7f628", "html_url": "https://github.com/rust-lang/rust/commit/b6d0eec3de0ac75ce81784251b4648a1cef7f628", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b6d0eec3de0ac75ce81784251b4648a1cef7f628/comments", "author": {"login": "workingjubilee", "id": 46493976, "node_id": "MDQ6VXNlcjQ2NDkzOTc2", "avatar_url": "https://avatars.githubusercontent.com/u/46493976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/workingjubilee", "html_url": "https://github.com/workingjubilee", "followers_url": "https://api.github.com/users/workingjubilee/followers", "following_url": "https://api.github.com/users/workingjubilee/following{/other_user}", "gists_url": "https://api.github.com/users/workingjubilee/gists{/gist_id}", "starred_url": "https://api.github.com/users/workingjubilee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/workingjubilee/subscriptions", "organizations_url": "https://api.github.com/users/workingjubilee/orgs", "repos_url": "https://api.github.com/users/workingjubilee/repos", "events_url": "https://api.github.com/users/workingjubilee/events{/privacy}", "received_events_url": "https://api.github.com/users/workingjubilee/received_events", "type": "User", "site_admin": false}, "committer": {"login": "workingjubilee", "id": 46493976, "node_id": "MDQ6VXNlcjQ2NDkzOTc2", "avatar_url": "https://avatars.githubusercontent.com/u/46493976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/workingjubilee", "html_url": "https://github.com/workingjubilee", "followers_url": "https://api.github.com/users/workingjubilee/followers", "following_url": "https://api.github.com/users/workingjubilee/following{/other_user}", "gists_url": "https://api.github.com/users/workingjubilee/gists{/gist_id}", "starred_url": "https://api.github.com/users/workingjubilee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/workingjubilee/subscriptions", "organizations_url": "https://api.github.com/users/workingjubilee/orgs", "repos_url": "https://api.github.com/users/workingjubilee/repos", "events_url": "https://api.github.com/users/workingjubilee/events{/privacy}", "received_events_url": "https://api.github.com/users/workingjubilee/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "81484a399c96c69adeef352be0e7823b39ce6e7e", "url": "https://api.github.com/repos/rust-lang/rust/commits/81484a399c96c69adeef352be0e7823b39ce6e7e", "html_url": "https://github.com/rust-lang/rust/commit/81484a399c96c69adeef352be0e7823b39ce6e7e"}], "stats": {"total": 168, "additions": 109, "deletions": 59}, "files": [{"sha": "2ebcef3d829764a988c44fcbc250d4874c3fe9ae", "filename": "crates/core_simd/src/ops.rs", "status": "modified", "additions": 109, "deletions": 59, "changes": 168, "blob_url": "https://github.com/rust-lang/rust/blob/b6d0eec3de0ac75ce81784251b4648a1cef7f628/crates%2Fcore_simd%2Fsrc%2Fops.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b6d0eec3de0ac75ce81784251b4648a1cef7f628/crates%2Fcore_simd%2Fsrc%2Fops.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Fops.rs?ref=b6d0eec3de0ac75ce81784251b4648a1cef7f628", "patch": "@@ -32,14 +32,115 @@ where\n     }\n }\n \n-/// Checks if the right-hand side argument of a left- or right-shift would cause overflow.\n-fn invalid_shift_rhs<T>(rhs: T) -> bool\n-where\n-    T: Default + PartialOrd + core::convert::TryFrom<usize>,\n-    <T as core::convert::TryFrom<usize>>::Error: core::fmt::Debug,\n-{\n-    let bits_in_type = T::try_from(8 * core::mem::size_of::<T>()).unwrap();\n-    rhs < T::default() || rhs >= bits_in_type\n+/// SAFETY: This macro should not be used for anything except Shl or Shr, and passed the appropriate shift intrinsic.\n+/// It handles performing a bitand in addition to calling the shift operator, so that the result\n+/// is well-defined: LLVM can return a poison value if you shl, lshr, or ashr if rhs >= <Int>::BITS\n+/// At worst, this will maybe add another instruction and cycle,\n+/// at best, it may open up more optimization opportunities,\n+/// or simply be elided entirely, especially for SIMD ISAs which default to this.\n+///\n+// FIXME: Consider implementing this in cg_llvm instead?\n+// cg_clif defaults to this, and scalar MIR shifts also default to wrapping\n+macro_rules! wrap_bitshift_inner {\n+    (impl<const LANES: usize> $op:ident for Simd<$int:ty, LANES> {\n+        fn $call:ident(self, rhs: Self) -> Self::Output {\n+            unsafe { $simd_call:ident }\n+        }\n+    }) => {\n+        impl<const LANES: usize> $op for Simd<$int, LANES>\n+        where\n+            $int: SimdElement,\n+            LaneCount<LANES>: SupportedLaneCount,\n+        {\n+            type Output = Self;\n+\n+            #[inline]\n+            #[must_use = \"operator returns a new vector without mutating the inputs\"]\n+            fn $call(self, rhs: Self) -> Self::Output {\n+                unsafe {\n+                    $crate::intrinsics::$simd_call(self, rhs.bitand(Simd::splat(<$int>::BITS as $int - 1)))\n+                }\n+            }\n+        }\n+    };\n+}\n+\n+macro_rules! wrap_bitshifts {\n+    ($(impl<const LANES: usize> ShiftOps for Simd<$int:ty, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+     })*) => {\n+        $(\n+            wrap_bitshift_inner! {\n+                impl<const LANES: usize> Shl for Simd<$int, LANES> {\n+                    fn shl(self, rhs: Self) -> Self::Output {\n+                        unsafe { simd_shl }\n+                    }\n+                }\n+            }\n+            wrap_bitshift_inner! {\n+                impl<const LANES: usize> Shr for Simd<$int, LANES> {\n+                    fn shr(self, rhs: Self) -> Self::Output {\n+                        // This automatically monomorphizes to lshr or ashr, depending,\n+                        // so it's fine to use it for both UInts and SInts.\n+                        unsafe { simd_shr }\n+                    }\n+                }\n+            }\n+        )*\n+    };\n+}\n+\n+wrap_bitshifts! {\n+    impl<const LANES: usize> ShiftOps for Simd<i8, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<i16, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<i32, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<i64, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<isize, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<u8, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<u16, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<u32, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<u64, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n+\n+    impl<const LANES: usize> ShiftOps for Simd<usize, LANES> {\n+        fn shl(self, rhs: Self) -> Self::Output;\n+        fn shr(self, rhs: Self) -> Self::Output;\n+    }\n }\n \n /// Automatically implements operators over references in addition to the provided operator.\n@@ -85,12 +186,6 @@ macro_rules! impl_op {\n     { impl Rem for $scalar:ty } => {\n         impl_op! { @binary $scalar, Rem::rem, simd_rem }\n     };\n-    { impl Shl for $scalar:ty } => {\n-        impl_op! { @binary $scalar, Shl::shl, simd_shl }\n-    };\n-    { impl Shr for $scalar:ty } => {\n-        impl_op! { @binary $scalar, Shr::shr, simd_shr }\n-    };\n     { impl BitAnd for $scalar:ty } => {\n         impl_op! { @binary $scalar, BitAnd::bitand, simd_and }\n     };\n@@ -202,51 +297,6 @@ macro_rules! impl_unsigned_int_ops {\n                     }\n                 }\n             }\n-\n-            // shifts panic on overflow\n-            impl_ref_ops! {\n-                impl<const LANES: usize> core::ops::Shl<Self> for Simd<$scalar, LANES>\n-                where\n-                    LaneCount<LANES>: SupportedLaneCount,\n-                {\n-                    type Output = Self;\n-\n-                    #[inline]\n-                    fn shl(self, rhs: Self) -> Self::Output {\n-                        // TODO there is probably a better way of doing this\n-                        if rhs.as_array()\n-                            .iter()\n-                            .copied()\n-                            .any(invalid_shift_rhs)\n-                        {\n-                            panic!(\"attempt to shift left with overflow\");\n-                        }\n-                        unsafe { intrinsics::simd_shl(self, rhs) }\n-                    }\n-                }\n-            }\n-\n-            impl_ref_ops! {\n-                impl<const LANES: usize> core::ops::Shr<Self> for Simd<$scalar, LANES>\n-                where\n-                    LaneCount<LANES>: SupportedLaneCount,\n-                {\n-                    type Output = Self;\n-\n-                    #[inline]\n-                    fn shr(self, rhs: Self) -> Self::Output {\n-                        // TODO there is probably a better way of doing this\n-                        if rhs.as_array()\n-                            .iter()\n-                            .copied()\n-                            .any(invalid_shift_rhs)\n-                        {\n-                            panic!(\"attempt to shift with overflow\");\n-                        }\n-                        unsafe { intrinsics::simd_shr(self, rhs) }\n-                    }\n-                }\n-            }\n         )*\n     };\n }"}]}