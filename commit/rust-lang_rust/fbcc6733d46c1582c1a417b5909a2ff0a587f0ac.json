{"sha": "fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZiY2M2NzMzZDQ2YzE1ODJjMWE0MTdiNTkwOWEyZmYwYTU4N2YwYWM=", "commit": {"author": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2017-11-05T18:21:05Z"}, "committer": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2017-11-08T23:40:04Z"}, "message": "proc_macro: use the proc_macro API at runtime to construct quasi-quoted TokenStream's.", "tree": {"sha": "5eedac96ac7d1504ed88fb7c3244f7ae6f6e3da3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5eedac96ac7d1504ed88fb7c3244f7ae6f6e3da3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "html_url": "https://github.com/rust-lang/rust/commit/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac/comments", "author": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a51c69e2d5711e071af48307d432ba2d97e3dedf", "url": "https://api.github.com/repos/rust-lang/rust/commits/a51c69e2d5711e071af48307d432ba2d97e3dedf", "html_url": "https://github.com/rust-lang/rust/commit/a51c69e2d5711e071af48307d432ba2d97e3dedf"}], "stats": {"total": 248, "additions": 118, "deletions": 130}, "files": [{"sha": "8a400f3e6360e39573e313dc60e751e23868c634", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "patch": "@@ -728,7 +728,7 @@ impl TokenTree {\n #[unstable(feature = \"proc_macro_internals\", issue = \"27812\")]\n #[doc(hidden)]\n pub mod __internal {\n-    pub use quote::{Quoter, __rt};\n+    pub use quote::{LiteralKind, Quoter, unquote};\n \n     use std::cell::Cell;\n "}, {"sha": "26f88ad6bf64937d8819cb0350fa3c8096d76329", "filename": "src/libproc_macro/quote.rs", "status": "modified", "additions": 117, "deletions": 129, "changes": 246, "blob_url": "https://github.com/rust-lang/rust/blob/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac/src%2Flibproc_macro%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac/src%2Flibproc_macro%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fquote.rs?ref=fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "patch": "@@ -11,39 +11,19 @@\n //! # Quasiquoter\n //! This file contains the implementation internals of the quasiquoter provided by `quote!`.\n \n-//! This quasiquoter uses macros 2.0 hygiene to reliably use items from `__rt`,\n-//! including re-exported API `libsyntax`, to build a `syntax::tokenstream::TokenStream`\n-//! and wrap it into a `proc_macro::TokenStream`.\n+//! This quasiquoter uses macros 2.0 hygiene to reliably access\n+//! items from `proc_macro`, to build a `proc_macro::TokenStream`.\n \n use {Delimiter, Literal, Spacing, Span, Term, TokenNode, TokenStream, TokenTree};\n \n-use std::iter;\n use syntax::ext::base::{ExtCtxt, ProcMacro};\n use syntax::parse::token;\n use syntax::tokenstream;\n \n pub struct Quoter;\n \n-pub mod __rt {\n-    pub use syntax::ast::Ident;\n-    pub use syntax::parse::token;\n-    pub use syntax::symbol::Symbol;\n-    pub use syntax::tokenstream::{TokenStream, TokenStreamBuilder, TokenTree, Delimited};\n-\n-    use syntax_pos::Span;\n-    use syntax_pos::hygiene::SyntaxContext;\n-\n-    pub fn unquote<T: Into<::TokenStream> + Clone>(tokens: &T) -> TokenStream {\n-        T::into(tokens.clone()).0\n-    }\n-\n-    pub fn ctxt() -> SyntaxContext {\n-        ::__internal::with_sess(|(_, mark)| SyntaxContext::empty().apply_mark(mark))\n-    }\n-\n-    pub fn span() -> Span {\n-        ::Span::default().0\n-    }\n+pub fn unquote<T: Into<TokenStream> + Clone>(tokens: &T) -> TokenStream {\n+    T::into(tokens.clone())\n }\n \n pub trait Quote {\n@@ -75,7 +55,6 @@ macro_rules! quote_tree {\n     (($($t:tt)*)) => { TokenNode::Group(Delimiter::Parenthesis, quote!($($t)*)) };\n     ([$($t:tt)*]) => { TokenNode::Group(Delimiter::Bracket, quote!($($t)*)) };\n     ({$($t:tt)*}) => { TokenNode::Group(Delimiter::Brace, quote!($($t)*)) };\n-    (rt) => { quote!(::__internal::__rt) };\n     ($t:tt) => { quote_tok!($t) };\n }\n \n@@ -96,9 +75,7 @@ impl ProcMacro for Quoter {\n         let mut info = cx.current_expansion.mark.expn_info().unwrap();\n         info.callee.allow_internal_unstable = true;\n         cx.current_expansion.mark.set_expn_info(info);\n-        ::__internal::set_sess(cx, || quote!(::TokenStream {\n-            0: (quote TokenStream(stream))\n-        }).0)\n+        ::__internal::set_sess(cx, || TokenStream(stream).quote().0)\n     }\n }\n \n@@ -113,102 +90,61 @@ impl<T: Quote> Quote for Option<T> {\n \n impl Quote for TokenStream {\n     fn quote(self) -> TokenStream {\n+        if self.is_empty() {\n+            return quote!(::TokenStream::empty());\n+        }\n         let mut after_dollar = false;\n-        let stream = iter::once(quote!(rt::TokenStreamBuilder::new()))\n-            .chain(self.into_iter().filter_map(|tree| {\n-                if after_dollar {\n-                    after_dollar = false;\n-                    match tree.kind {\n-                        TokenNode::Term(_) => {\n-                            return Some(quote!(.add(rt::unquote(&(unquote tree)))));\n-                        }\n-                        TokenNode::Op('$', _) => {}\n-                        _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n+        let tokens = self.into_iter().filter_map(|tree| {\n+            if after_dollar {\n+                after_dollar = false;\n+                match tree.kind {\n+                    TokenNode::Term(_) => {\n+                        return Some(quote!(::__internal::unquote(&(unquote tree)),));\n                     }\n-                } else if let TokenNode::Op('$', _) = tree.kind {\n-                    after_dollar = true;\n-                    return None;\n+                    TokenNode::Op('$', _) => {}\n+                    _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n                 }\n+            } else if let TokenNode::Op('$', _) = tree.kind {\n+                after_dollar = true;\n+                return None;\n+            }\n \n-                Some(quote!(.add(rt::TokenStream::from((quote tree)))))\n-            }))\n-            .chain(iter::once(quote!(.build()))).collect();\n+            Some(quote!(::TokenStream::from((quote tree)),))\n+        }).collect::<TokenStream>();\n \n         if after_dollar {\n             panic!(\"unexpected trailing `$` in `quote!`\");\n         }\n \n-        stream\n+        quote!([(unquote tokens)].iter().cloned().collect::<::TokenStream>())\n     }\n }\n \n impl Quote for TokenTree {\n     fn quote(self) -> TokenStream {\n-        let (op, kind) = match self.kind {\n-            TokenNode::Op(op, kind) => (op, kind),\n-            TokenNode::Group(delimiter, tokens) => {\n-                return quote! {\n-                    rt::TokenTree::Delimited((quote self.span), rt::Delimited {\n-                        delim: (quote delimiter),\n-                        tts: (quote tokens).into()\n-                    })\n-                };\n-            },\n-            TokenNode::Term(term) => {\n-                let variant = if term.as_str().starts_with(\"'\") {\n-                    quote!(Lifetime)\n-                } else {\n-                    quote!(Ident)\n-                };\n-                return quote! {\n-                    rt::TokenTree::Token((quote self.span),\n-                        rt::token::(unquote variant)(rt::Ident {\n-                            name: (quote term),\n-                            ctxt: rt::ctxt()\n-                        }))\n-                };\n-            }\n-            TokenNode::Literal(lit) => {\n-                return quote! {\n-                    rt::TokenTree::Token((quote self.span), (quote lit))\n-                };\n+        quote!(::TokenTree { span: (quote self.span), kind: (quote self.kind) })\n+    }\n+}\n+\n+impl Quote for TokenNode {\n+    fn quote(self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident($($arg:ident),+)),*) => {\n+                match self {\n+                    $(TokenNode::$i($($arg),+) => quote! {\n+                        ::TokenNode::$i($((quote $arg)),+)\n+                    },)*\n+                }\n             }\n-        };\n-\n-        let token = match op {\n-            '=' => quote!(Eq),\n-            '<' => quote!(Lt),\n-            '>' => quote!(Gt),\n-            '!' => quote!(Not),\n-            '~' => quote!(Tilde),\n-            '+' => quote!(BinOp(rt::token::BinOpToken::Plus)),\n-            '-' => quote!(BinOp(rt::token::BinOpToken::Minus)),\n-            '*' => quote!(BinOp(rt::token::BinOpToken::Star)),\n-            '/' => quote!(BinOp(rt::token::BinOpToken::Slash)),\n-            '%' => quote!(BinOp(rt::token::BinOpToken::Percent)),\n-            '^' => quote!(BinOp(rt::token::BinOpToken::Caret)),\n-            '&' => quote!(BinOp(rt::token::BinOpToken::And)),\n-            '|' => quote!(BinOp(rt::token::BinOpToken::Or)),\n-            '@' => quote!(At),\n-            '.' => quote!(Dot),\n-            ',' => quote!(Comma),\n-            ';' => quote!(Semi),\n-            ':' => quote!(Colon),\n-            '#' => quote!(Pound),\n-            '$' => quote!(Dollar),\n-            '?' => quote!(Question),\n-            '_' => quote!(Underscore),\n-            _ => panic!(\"unsupported character {}\", op),\n-        };\n-\n-        match kind {\n-            Spacing::Alone => quote! {\n-                rt::TokenTree::Token((quote self.span), rt::token::(unquote token))\n-            },\n-            Spacing::Joint => quote! {\n-                rt::TokenTree::Token((quote self.span), rt::token::(unquote token)).joint()\n-            },\n         }\n+\n+        gen_match! { Op(op, kind), Group(delim, tokens), Term(term), Literal(lit) }\n+    }\n+}\n+\n+impl Quote for char {\n+    fn quote(self) -> TokenStream {\n+        TokenNode::Literal(Literal::character(self)).into()\n     }\n }\n \n@@ -226,52 +162,104 @@ impl Quote for usize {\n \n impl Quote for Term {\n     fn quote(self) -> TokenStream {\n-        quote!(rt::Symbol::intern((quote self.as_str())))\n+        quote!(::Term::intern((quote self.as_str())))\n     }\n }\n \n impl Quote for Span {\n     fn quote(self) -> TokenStream {\n-        quote!(rt::span())\n+        quote!(::Span::default())\n     }\n }\n \n-impl Quote for Literal {\n-    fn quote(self) -> TokenStream {\n-        let (lit, sfx) = match self.0 {\n-            token::Literal(lit, sfx) => (lit, sfx.map(Term)),\n-            _ => panic!(\"unsupported literal {:?}\", self.0),\n-        };\n+macro_rules! literals {\n+    ($($i:ident),*; $($raw:ident),*) => {\n+        pub enum LiteralKind {\n+            $($i,)*\n+            $($raw(usize),)*\n+        }\n \n-        macro_rules! gen_match {\n-            ($($i:ident),*; $($raw:ident),*) => {\n-                match lit {\n-                    $(token::Lit::$i(lit) => quote! {\n-                        rt::token::Literal(rt::token::Lit::$i((quote Term(lit))),\n-                            (quote sfx))\n+        impl LiteralKind {\n+            pub fn with_contents_and_suffix(self, contents: Term, suffix: Option<Term>)\n+                                            -> Literal {\n+                let contents = contents.0;\n+                let suffix = suffix.map(|t| t.0);\n+                match self {\n+                    $(LiteralKind::$i => {\n+                        Literal(token::Literal(token::Lit::$i(contents), suffix))\n+                    })*\n+                    $(LiteralKind::$raw(n) => {\n+                        Literal(token::Literal(token::Lit::$raw(contents, n), suffix))\n+                    })*\n+                }\n+            }\n+        }\n+\n+        impl Literal {\n+            fn kind_contents_and_suffix(self) -> (LiteralKind, Term, Option<Term>) {\n+                let (lit, suffix) = match self.0 {\n+                    token::Literal(lit, suffix) => (lit, suffix),\n+                    _ => panic!(\"unsupported literal {:?}\", self.0),\n+                };\n+\n+                let (kind, contents) = match lit {\n+                    $(token::Lit::$i(contents) => (LiteralKind::$i, contents),)*\n+                    $(token::Lit::$raw(contents, n) => (LiteralKind::$raw(n), contents),)*\n+                };\n+                (kind, Term(contents), suffix.map(Term))\n+            }\n+        }\n+\n+        impl Quote for LiteralKind {\n+            fn quote(self) -> TokenStream {\n+                match self {\n+                    $(LiteralKind::$i => quote! {\n+                        ::__internal::LiteralKind::$i\n                     },)*\n-                    $(token::Lit::$raw(lit, n) => quote! {\n-                        rt::token::Literal(rt::token::Lit::$raw((quote Term(lit)), (quote n)),\n-                            (quote sfx))\n+                    $(LiteralKind::$raw(n) => quote! {\n+                        ::__internal::LiteralKind::$raw((quote n))\n                     },)*\n                 }\n             }\n         }\n \n-        gen_match!(Byte, Char, Float, Str_, Integer, ByteStr; StrRaw, ByteStrRaw)\n+        impl Quote for Literal {\n+            fn quote(self) -> TokenStream {\n+                let (kind, contents, suffix) = self.kind_contents_and_suffix();\n+                quote! {\n+                    (quote kind).with_contents_and_suffix((quote contents), (quote suffix))\n+                }\n+            }\n+        }\n     }\n }\n \n+literals!(Byte, Char, Float, Str_, Integer, ByteStr; StrRaw, ByteStrRaw);\n+\n impl Quote for Delimiter {\n     fn quote(self) -> TokenStream {\n         macro_rules! gen_match {\n-            ($($i:ident => $j:ident),*) => {\n+            ($($i:ident),*) => {\n+                match self {\n+                    $(Delimiter::$i => { quote!(::Delimiter::$i) })*\n+                }\n+            }\n+        }\n+\n+        gen_match!(Parenthesis, Brace, Bracket, None)\n+    }\n+}\n+\n+impl Quote for Spacing {\n+    fn quote(self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident),*) => {\n                 match self {\n-                    $(Delimiter::$i => { quote!(rt::token::DelimToken::$j) })*\n+                    $(Spacing::$i => { quote!(::Spacing::$i) })*\n                 }\n             }\n         }\n \n-        gen_match!(Parenthesis => Paren, Brace => Brace, Bracket => Bracket, None => NoDelim)\n+        gen_match!(Alone, Joint)\n     }\n }"}]}