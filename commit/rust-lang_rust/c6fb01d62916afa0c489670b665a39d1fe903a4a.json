{"sha": "c6fb01d62916afa0c489670b665a39d1fe903a4a", "node_id": "MDY6Q29tbWl0NzI0NzEyOmM2ZmIwMWQ2MjkxNmFmYTBjNDg5NjcwYjY2NWEzOWQxZmU5MDNhNGE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-12-17T01:48:23Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-12-17T01:48:23Z"}, "message": "Auto merge of #56737 - nnethercote:TokenStream-improvements, r=petrochenkov\n\n`TokenStream` improvements\n\nSome `TokenStream` improvements: shrinking `TokenStream` and some other types, and some other code clean-ups.", "tree": {"sha": "9a07eccfffaf39ea2561aac81d64f26f6f8df6d6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9a07eccfffaf39ea2561aac81d64f26f6f8df6d6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c6fb01d62916afa0c489670b665a39d1fe903a4a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c6fb01d62916afa0c489670b665a39d1fe903a4a", "html_url": "https://github.com/rust-lang/rust/commit/c6fb01d62916afa0c489670b665a39d1fe903a4a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c6fb01d62916afa0c489670b665a39d1fe903a4a/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0", "url": "https://api.github.com/repos/rust-lang/rust/commits/a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0", "html_url": "https://github.com/rust-lang/rust/commit/a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0"}, {"sha": "e80c7ddb05ee584c12131a4713173a3eafc49f4a", "url": "https://api.github.com/repos/rust-lang/rust/commits/e80c7ddb05ee584c12131a4713173a3eafc49f4a", "html_url": "https://github.com/rust-lang/rust/commit/e80c7ddb05ee584c12131a4713173a3eafc49f4a"}], "stats": {"total": 392, "additions": 107, "deletions": 285}, "files": [{"sha": "73cbe49f43b049ee955b140d0e3e547e3ed1eb2f", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -483,7 +483,7 @@ impl MetaItem {\n             last_pos = segment.ident.span.hi();\n         }\n         idents.push(self.node.tokens(self.span));\n-        TokenStream::concat(idents)\n+        TokenStream::new(idents)\n     }\n \n     fn from_tokens<I>(tokens: &mut iter::Peekable<I>) -> Option<MetaItem>\n@@ -539,7 +539,7 @@ impl MetaItemKind {\n         match *self {\n             MetaItemKind::Word => TokenStream::empty(),\n             MetaItemKind::NameValue(ref lit) => {\n-                TokenStream::concat(vec![TokenTree::Token(span, Token::Eq).into(), lit.tokens()])\n+                TokenStream::new(vec![TokenTree::Token(span, Token::Eq).into(), lit.tokens()])\n             }\n             MetaItemKind::List(ref list) => {\n                 let mut tokens = Vec::new();\n@@ -552,7 +552,7 @@ impl MetaItemKind {\n                 TokenTree::Delimited(\n                     DelimSpan::from_single(span),\n                     token::Paren,\n-                    TokenStream::concat(tokens).into(),\n+                    TokenStream::new(tokens).into(),\n                 ).into()\n             }\n         }"}, {"sha": "5820b49ab621636bb19735b3e4ae045121ad6198", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -247,7 +247,7 @@ pub mod rt {\n \n             let delim_span = DelimSpan::from_single(self.span);\n             r.push(TokenTree::Delimited(\n-                delim_span, token::Bracket, TokenStream::concat(inner).into()\n+                delim_span, token::Bracket, TokenStream::new(inner).into()\n             ));\n             r\n         }"}, {"sha": "a63abd40495136e457d055dca0fb088837973488", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -103,12 +103,12 @@ pub fn transcribe(cx: &ExtCtxt,\n                 }\n                 Frame::Delimited { forest, span, .. } => {\n                     if result_stack.is_empty() {\n-                        return TokenStream::concat(result);\n+                        return TokenStream::new(result);\n                     }\n                     let tree = TokenTree::Delimited(\n                         span,\n                         forest.delim,\n-                        TokenStream::concat(result).into(),\n+                        TokenStream::new(result).into(),\n                     );\n                     result = result_stack.pop().unwrap();\n                     result.push(tree.into());"}, {"sha": "1fa11a4d6c856a3467bc3867bc1a91472e8db51f", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -145,12 +145,6 @@ pub mod util {\n     #[cfg(test)]\n     pub mod parser_testing;\n     pub mod move_map;\n-\n-    mod rc_slice;\n-    pub use self::rc_slice::RcSlice;\n-\n-    mod rc_vec;\n-    pub use self::rc_vec::RcVec;\n }\n \n pub mod json;"}, {"sha": "1bd0656846bcea90ebddb47a26b56e74e9ff06d5", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -170,7 +170,7 @@ impl<'a> Parser<'a> {\n                     token::CloseDelim(_) | token::Eof => self.unexpected()?,\n                     _ => self.parse_token_tree(),\n                 };\n-                TokenStream::concat(vec![eq.into(), tree.into()])\n+                TokenStream::new(vec![eq.into(), tree.into()])\n             } else {\n                 TokenStream::empty()\n             };"}, {"sha": "0906c25cab36103e9d38ec30541d6eaabba1ad3b", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -22,22 +22,22 @@ impl<'a> StringReader<'a> {\n             tts.push(self.parse_token_tree()?);\n         }\n \n-        Ok(TokenStream::concat(tts))\n+        Ok(TokenStream::new(tts))\n     }\n \n     // Parse a stream of tokens into a list of `TokenTree`s, up to a `CloseDelim`.\n     fn parse_token_trees_until_close_delim(&mut self) -> TokenStream {\n         let mut tts = vec![];\n         loop {\n             if let token::CloseDelim(..) = self.token {\n-                return TokenStream::concat(tts);\n+                return TokenStream::new(tts);\n             }\n \n             match self.parse_token_tree() {\n                 Ok(tree) => tts.push(tree),\n                 Err(mut e) => {\n                     e.emit();\n-                    return TokenStream::concat(tts);\n+                    return TokenStream::new(tts);\n                 }\n             }\n         }"}, {"sha": "e3cccacb3c3db9343d138227091df9cc2278d163", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -863,13 +863,13 @@ mod tests {\n         with_globals(|| {\n             let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n \n-            let expected = TokenStream::concat(vec![\n+            let expected = TokenStream::new(vec![\n                 TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"), false)).into(),\n                 TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"), false)).into(),\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(5, 6), sp(13, 14)),\n                     token::DelimToken::Paren,\n-                    TokenStream::concat(vec![\n+                    TokenStream::new(vec![\n                         TokenTree::Token(sp(6, 7),\n                                          token::Ident(Ident::from_str(\"b\"), false)).into(),\n                         TokenTree::Token(sp(8, 9), token::Colon).into(),\n@@ -880,7 +880,7 @@ mod tests {\n                 TokenTree::Delimited(\n                     DelimSpan::from_pair(sp(15, 16), sp(20, 21)),\n                     token::DelimToken::Brace,\n-                    TokenStream::concat(vec![\n+                    TokenStream::new(vec![\n                         TokenTree::Token(sp(17, 18),\n                                          token::Ident(Ident::from_str(\"b\"), false)).into(),\n                         TokenTree::Token(sp(18, 19), token::Semi).into(),"}, {"sha": "a672a08a15a85cac21c4b5b9acbab13a7673359b", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -2939,7 +2939,7 @@ impl<'a> Parser<'a> {\n                 _ => result.push(self.parse_token_tree().into()),\n             }\n         }\n-        TokenStream::concat(result)\n+        TokenStream::new(result)\n     }\n \n     /// Parse a prefix-unary-operator expr\n@@ -4635,7 +4635,7 @@ impl<'a> Parser<'a> {\n                         self.unexpected()?;\n                         unreachable!()\n                     };\n-                    TokenStream::concat(vec![\n+                    TokenStream::new(vec![\n                         args.into(),\n                         TokenTree::Token(token_lo.to(self.prev_span), token::FatArrow).into(),\n                         body.into(),"}, {"sha": "c11ef33f931d8ab94a82ba8ceca62795333595f1", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 92, "deletions": 109, "changes": 201, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -28,8 +28,8 @@ use ext::tt::{macro_parser, quoted};\n use parse::Directory;\n use parse::token::{self, DelimToken, Token};\n use print::pprust;\n+use rustc_data_structures::sync::Lrc;\n use serialize::{Decoder, Decodable, Encoder, Encodable};\n-use util::RcVec;\n \n use std::borrow::Cow;\n use std::{fmt, iter, mem};\n@@ -123,7 +123,7 @@ impl TokenTree {\n     }\n \n     pub fn joint(self) -> TokenStream {\n-        TokenStream { kind: TokenStreamKind::JointTree(self) }\n+        TokenStream::JointTree(self)\n     }\n \n     /// Returns the opening delimiter as a token tree.\n@@ -154,65 +154,57 @@ impl TokenTree {\n /// instead of a representation of the abstract syntax tree.\n /// Today's `TokenTree`s can still contain AST via `Token::Interpolated` for back-compat.\n #[derive(Clone, Debug)]\n-pub struct TokenStream {\n-    kind: TokenStreamKind,\n+pub enum TokenStream {\n+    Empty,\n+    Tree(TokenTree),\n+    JointTree(TokenTree),\n+    Stream(Lrc<Vec<TokenStream>>),\n }\n \n // `TokenStream` is used a lot. Make sure it doesn't unintentionally get bigger.\n #[cfg(target_arch = \"x86_64\")]\n-static_assert!(MEM_SIZE_OF_TOKEN_STREAM: mem::size_of::<TokenStream>() == 40);\n+static_assert!(MEM_SIZE_OF_TOKEN_STREAM: mem::size_of::<TokenStream>() == 32);\n \n impl TokenStream {\n     /// Given a `TokenStream` with a `Stream` of only two arguments, return a new `TokenStream`\n     /// separating the two arguments with a comma for diagnostic suggestions.\n     pub(crate) fn add_comma(&self) -> Option<(TokenStream, Span)> {\n         // Used to suggest if a user writes `foo!(a b);`\n-        if let TokenStreamKind::Stream(ref slice) = self.kind {\n+        if let TokenStream::Stream(ref stream) = self {\n             let mut suggestion = None;\n-            let mut iter = slice.iter().enumerate().peekable();\n+            let mut iter = stream.iter().enumerate().peekable();\n             while let Some((pos, ts)) = iter.next() {\n                 if let Some((_, next)) = iter.peek() {\n-                    let sp = match (&ts.kind, &next.kind) {\n-                        (TokenStreamKind::Tree(TokenTree::Token(_, token::Token::Comma)), _) |\n-                        (_, TokenStreamKind::Tree(TokenTree::Token(_, token::Token::Comma))) => {\n+                    let sp = match (&ts, &next) {\n+                        (TokenStream::Tree(TokenTree::Token(_, token::Token::Comma)), _) |\n+                        (_, TokenStream::Tree(TokenTree::Token(_, token::Token::Comma))) => {\n                             continue;\n                         }\n-                        (TokenStreamKind::Tree(TokenTree::Token(sp, _)), _) => *sp,\n-                        (TokenStreamKind::Tree(TokenTree::Delimited(sp, ..)), _) => sp.entire(),\n+                        (TokenStream::Tree(TokenTree::Token(sp, _)), _) => *sp,\n+                        (TokenStream::Tree(TokenTree::Delimited(sp, ..)), _) => sp.entire(),\n                         _ => continue,\n                     };\n                     let sp = sp.shrink_to_hi();\n-                    let comma = TokenStream {\n-                        kind: TokenStreamKind::Tree(TokenTree::Token(sp, token::Comma)),\n-                    };\n+                    let comma = TokenStream::Tree(TokenTree::Token(sp, token::Comma));\n                     suggestion = Some((pos, comma, sp));\n                 }\n             }\n             if let Some((pos, comma, sp)) = suggestion {\n-                let mut new_slice = vec![];\n-                let parts = slice.split_at(pos + 1);\n-                new_slice.extend_from_slice(parts.0);\n-                new_slice.push(comma);\n-                new_slice.extend_from_slice(parts.1);\n-                let slice = RcVec::new(new_slice);\n-                return Some((TokenStream { kind: TokenStreamKind::Stream(slice) }, sp));\n+                let mut new_stream = vec![];\n+                let parts = stream.split_at(pos + 1);\n+                new_stream.extend_from_slice(parts.0);\n+                new_stream.push(comma);\n+                new_stream.extend_from_slice(parts.1);\n+                return Some((TokenStream::new(new_stream), sp));\n             }\n         }\n         None\n     }\n }\n \n-#[derive(Clone, Debug)]\n-enum TokenStreamKind {\n-    Empty,\n-    Tree(TokenTree),\n-    JointTree(TokenTree),\n-    Stream(RcVec<TokenStream>),\n-}\n-\n impl From<TokenTree> for TokenStream {\n     fn from(tt: TokenTree) -> TokenStream {\n-        TokenStream { kind: TokenStreamKind::Tree(tt) }\n+        TokenStream::Tree(tt)\n     }\n }\n \n@@ -224,29 +216,29 @@ impl From<Token> for TokenStream {\n \n impl<T: Into<TokenStream>> iter::FromIterator<T> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n-        TokenStream::concat(iter.into_iter().map(Into::into).collect::<Vec<_>>())\n+        TokenStream::new(iter.into_iter().map(Into::into).collect::<Vec<_>>())\n     }\n }\n \n impl Extend<TokenStream> for TokenStream {\n     fn extend<I: IntoIterator<Item = TokenStream>>(&mut self, iter: I) {\n         let iter = iter.into_iter();\n-        let kind = mem::replace(&mut self.kind, TokenStreamKind::Empty);\n+        let this = mem::replace(self, TokenStream::Empty);\n \n         // Vector of token streams originally in self.\n-        let tts: Vec<TokenStream> = match kind {\n-            TokenStreamKind::Empty => {\n+        let tts: Vec<TokenStream> = match this {\n+            TokenStream::Empty => {\n                 let mut vec = Vec::new();\n                 vec.reserve(iter.size_hint().0);\n                 vec\n             }\n-            TokenStreamKind::Tree(_) | TokenStreamKind::JointTree(_) => {\n+            TokenStream::Tree(_) | TokenStream::JointTree(_) => {\n                 let mut vec = Vec::new();\n                 vec.reserve(1 + iter.size_hint().0);\n-                vec.push(TokenStream { kind });\n+                vec.push(this);\n                 vec\n             }\n-            TokenStreamKind::Stream(rc_vec) => match RcVec::try_unwrap(rc_vec) {\n+            TokenStream::Stream(rc_vec) => match Lrc::try_unwrap(rc_vec) {\n                 Ok(mut vec) => {\n                     // Extend in place using the existing capacity if possible.\n                     // This is the fast path for libraries like `quote` that\n@@ -273,12 +265,7 @@ impl Extend<TokenStream> for TokenStream {\n         // Build the resulting token stream. If it contains more than one token,\n         // preserve capacity in the vector in anticipation of the caller\n         // performing additional calls to extend.\n-        let mut tts = builder.0;\n-        *self = match tts.len() {\n-            0 => TokenStream::empty(),\n-            1 => tts.pop().unwrap(),\n-            _ => TokenStream::concat_rc_vec(RcVec::new_preserving_capacity(tts)),\n-        };\n+        *self = TokenStream::new(builder.0);\n     }\n }\n \n@@ -292,36 +279,32 @@ impl PartialEq<TokenStream> for TokenStream {\n \n impl TokenStream {\n     pub fn len(&self) -> usize {\n-        if let TokenStreamKind::Stream(ref slice) = self.kind {\n+        if let TokenStream::Stream(ref slice) = self {\n             slice.len()\n         } else {\n             0\n         }\n     }\n \n     pub fn empty() -> TokenStream {\n-        TokenStream { kind: TokenStreamKind::Empty }\n+        TokenStream::Empty\n     }\n \n     pub fn is_empty(&self) -> bool {\n-        match self.kind {\n-            TokenStreamKind::Empty => true,\n+        match self {\n+            TokenStream::Empty => true,\n             _ => false,\n         }\n     }\n \n-    pub fn concat(mut streams: Vec<TokenStream>) -> TokenStream {\n+    pub fn new(mut streams: Vec<TokenStream>) -> TokenStream {\n         match streams.len() {\n             0 => TokenStream::empty(),\n             1 => streams.pop().unwrap(),\n-            _ => TokenStream::concat_rc_vec(RcVec::new(streams)),\n+            _ => TokenStream::Stream(Lrc::new(streams)),\n         }\n     }\n \n-    fn concat_rc_vec(streams: RcVec<TokenStream>) -> TokenStream {\n-        TokenStream { kind: TokenStreamKind::Stream(streams) }\n-    }\n-\n     pub fn trees(&self) -> Cursor {\n         self.clone().into_trees()\n     }\n@@ -383,9 +366,9 @@ impl TokenStream {\n     /// Precondition: `self` consists of a single token tree.\n     /// Returns true if the token tree is a joint operation w.r.t. `proc_macro::TokenNode`.\n     pub fn as_tree(self) -> (TokenTree, bool /* joint? */) {\n-        match self.kind {\n-            TokenStreamKind::Tree(tree) => (tree, false),\n-            TokenStreamKind::JointTree(tree) => (tree, true),\n+        match self {\n+            TokenStream::Tree(tree) => (tree, false),\n+            TokenStream::JointTree(tree) => (tree, true),\n             _ => unreachable!(),\n         }\n     }\n@@ -395,43 +378,43 @@ impl TokenStream {\n         let mut result = Vec::new();\n         let mut i = 0;\n         while let Some(stream) = trees.next_as_stream() {\n-            result.push(match stream.kind {\n-                TokenStreamKind::Tree(tree) => f(i, tree).into(),\n-                TokenStreamKind::JointTree(tree) => f(i, tree).joint(),\n+            result.push(match stream {\n+                TokenStream::Tree(tree) => f(i, tree).into(),\n+                TokenStream::JointTree(tree) => f(i, tree).joint(),\n                 _ => unreachable!()\n             });\n             i += 1;\n         }\n-        TokenStream::concat(result)\n+        TokenStream::new(result)\n     }\n \n     pub fn map<F: FnMut(TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n         let mut trees = self.into_trees();\n         let mut result = Vec::new();\n         while let Some(stream) = trees.next_as_stream() {\n-            result.push(match stream.kind {\n-                TokenStreamKind::Tree(tree) => f(tree).into(),\n-                TokenStreamKind::JointTree(tree) => f(tree).joint(),\n+            result.push(match stream {\n+                TokenStream::Tree(tree) => f(tree).into(),\n+                TokenStream::JointTree(tree) => f(tree).joint(),\n                 _ => unreachable!()\n             });\n         }\n-        TokenStream::concat(result)\n+        TokenStream::new(result)\n     }\n \n     fn first_tree_and_joint(&self) -> Option<(TokenTree, bool)> {\n-        match self.kind {\n-            TokenStreamKind::Empty => None,\n-            TokenStreamKind::Tree(ref tree) => Some((tree.clone(), false)),\n-            TokenStreamKind::JointTree(ref tree) => Some((tree.clone(), true)),\n-            TokenStreamKind::Stream(ref stream) => stream.first().unwrap().first_tree_and_joint(),\n+        match self {\n+            TokenStream::Empty => None,\n+            TokenStream::Tree(ref tree) => Some((tree.clone(), false)),\n+            TokenStream::JointTree(ref tree) => Some((tree.clone(), true)),\n+            TokenStream::Stream(ref stream) => stream.first().unwrap().first_tree_and_joint(),\n         }\n     }\n \n     fn last_tree_if_joint(&self) -> Option<TokenTree> {\n-        match self.kind {\n-            TokenStreamKind::Empty | TokenStreamKind::Tree(..) => None,\n-            TokenStreamKind::JointTree(ref tree) => Some(tree.clone()),\n-            TokenStreamKind::Stream(ref stream) => stream.last().unwrap().last_tree_if_joint(),\n+        match self {\n+            TokenStream::Empty | TokenStream::Tree(..) => None,\n+            TokenStream::JointTree(ref tree) => Some(tree.clone()),\n+            TokenStream::Stream(ref stream) => stream.last().unwrap().last_tree_if_joint(),\n         }\n     }\n }\n@@ -474,28 +457,28 @@ impl TokenStreamBuilder {\n     }\n \n     pub fn build(self) -> TokenStream {\n-        TokenStream::concat(self.0)\n+        TokenStream::new(self.0)\n     }\n \n     fn push_all_but_last_tree(&mut self, stream: &TokenStream) {\n-        if let TokenStreamKind::Stream(ref streams) = stream.kind {\n+        if let TokenStream::Stream(ref streams) = stream {\n             let len = streams.len();\n             match len {\n                 1 => {}\n                 2 => self.0.push(streams[0].clone().into()),\n-                _ => self.0.push(TokenStream::concat_rc_vec(streams.sub_slice(0 .. len - 1))),\n+                _ => self.0.push(TokenStream::new(streams[0 .. len - 1].to_vec())),\n             }\n             self.push_all_but_last_tree(&streams[len - 1])\n         }\n     }\n \n     fn push_all_but_first_tree(&mut self, stream: &TokenStream) {\n-        if let TokenStreamKind::Stream(ref streams) = stream.kind {\n+        if let TokenStream::Stream(ref streams) = stream {\n             let len = streams.len();\n             match len {\n                 1 => {}\n                 2 => self.0.push(streams[1].clone().into()),\n-                _ => self.0.push(TokenStream::concat_rc_vec(streams.sub_slice(1 .. len))),\n+                _ => self.0.push(TokenStream::new(streams[1 .. len].to_vec())),\n             }\n             self.push_all_but_first_tree(&streams[0])\n         }\n@@ -515,13 +498,13 @@ enum CursorKind {\n \n #[derive(Clone)]\n struct StreamCursor {\n-    stream: RcVec<TokenStream>,\n+    stream: Lrc<Vec<TokenStream>>,\n     index: usize,\n-    stack: Vec<(RcVec<TokenStream>, usize)>,\n+    stack: Vec<(Lrc<Vec<TokenStream>>, usize)>,\n }\n \n impl StreamCursor {\n-    fn new(stream: RcVec<TokenStream>) -> Self {\n+    fn new(stream: Lrc<Vec<TokenStream>>) -> Self {\n         StreamCursor { stream: stream, index: 0, stack: Vec::new() }\n     }\n \n@@ -530,10 +513,10 @@ impl StreamCursor {\n             if self.index < self.stream.len() {\n                 self.index += 1;\n                 let next = self.stream[self.index - 1].clone();\n-                match next.kind {\n-                    TokenStreamKind::Tree(..) | TokenStreamKind::JointTree(..) => return Some(next),\n-                    TokenStreamKind::Stream(stream) => self.insert(stream),\n-                    TokenStreamKind::Empty => {}\n+                match next {\n+                    TokenStream::Tree(..) | TokenStream::JointTree(..) => return Some(next),\n+                    TokenStream::Stream(stream) => self.insert(stream),\n+                    TokenStream::Empty => {}\n                 }\n             } else if let Some((stream, index)) = self.stack.pop() {\n                 self.stream = stream;\n@@ -544,7 +527,7 @@ impl StreamCursor {\n         }\n     }\n \n-    fn insert(&mut self, stream: RcVec<TokenStream>) {\n+    fn insert(&mut self, stream: Lrc<Vec<TokenStream>>) {\n         self.stack.push((mem::replace(&mut self.stream, stream),\n                          mem::replace(&mut self.index, 0)));\n     }\n@@ -554,20 +537,20 @@ impl Iterator for Cursor {\n     type Item = TokenTree;\n \n     fn next(&mut self) -> Option<TokenTree> {\n-        self.next_as_stream().map(|stream| match stream.kind {\n-            TokenStreamKind::Tree(tree) | TokenStreamKind::JointTree(tree) => tree,\n+        self.next_as_stream().map(|stream| match stream {\n+            TokenStream::Tree(tree) | TokenStream::JointTree(tree) => tree,\n             _ => unreachable!()\n         })\n     }\n }\n \n impl Cursor {\n     fn new(stream: TokenStream) -> Self {\n-        Cursor(match stream.kind {\n-            TokenStreamKind::Empty => CursorKind::Empty,\n-            TokenStreamKind::Tree(tree) => CursorKind::Tree(tree, false),\n-            TokenStreamKind::JointTree(tree) => CursorKind::JointTree(tree, false),\n-            TokenStreamKind::Stream(stream) => CursorKind::Stream(StreamCursor::new(stream)),\n+        Cursor(match stream {\n+            TokenStream::Empty => CursorKind::Empty,\n+            TokenStream::Tree(tree) => CursorKind::Tree(tree, false),\n+            TokenStream::JointTree(tree) => CursorKind::JointTree(tree, false),\n+            TokenStream::Stream(stream) => CursorKind::Stream(StreamCursor::new(stream)),\n         })\n     }\n \n@@ -590,7 +573,7 @@ impl Cursor {\n             _ if stream.is_empty() => return,\n             CursorKind::Empty => *self = stream.trees(),\n             CursorKind::Tree(_, consumed) | CursorKind::JointTree(_, consumed) => {\n-                *self = TokenStream::concat(vec![self.original_stream(), stream]).trees();\n+                *self = TokenStream::new(vec![self.original_stream(), stream]).trees();\n                 if consumed {\n                     self.next();\n                 }\n@@ -606,21 +589,21 @@ impl Cursor {\n             CursorKind::Empty => TokenStream::empty(),\n             CursorKind::Tree(ref tree, _) => tree.clone().into(),\n             CursorKind::JointTree(ref tree, _) => tree.clone().joint(),\n-            CursorKind::Stream(ref cursor) => TokenStream::concat_rc_vec({\n+            CursorKind::Stream(ref cursor) => TokenStream::Stream(\n                 cursor.stack.get(0).cloned().map(|(stream, _)| stream)\n                     .unwrap_or_else(|| cursor.stream.clone())\n-            }),\n+            ),\n         }\n     }\n \n     pub fn look_ahead(&self, n: usize) -> Option<TokenTree> {\n         fn look_ahead(streams: &[TokenStream], mut n: usize) -> Result<TokenTree, usize> {\n             for stream in streams {\n-                n = match stream.kind {\n-                    TokenStreamKind::Tree(ref tree) | TokenStreamKind::JointTree(ref tree)\n+                n = match stream {\n+                    TokenStream::Tree(ref tree) | TokenStream::JointTree(ref tree)\n                         if n == 0 => return Ok(tree.clone()),\n-                    TokenStreamKind::Tree(..) | TokenStreamKind::JointTree(..) => n - 1,\n-                    TokenStreamKind::Stream(ref stream) => match look_ahead(stream, n) {\n+                    TokenStream::Tree(..) | TokenStream::JointTree(..) => n - 1,\n+                    TokenStream::Stream(ref stream) => match look_ahead(stream, n) {\n                         Ok(tree) => return Ok(tree),\n                         Err(n) => n,\n                     },\n@@ -656,7 +639,7 @@ impl Cursor {\n /// `ThinTokenStream` is smaller, but needs to allocate to represent a single `TokenTree`.\n /// We must use `ThinTokenStream` in `TokenTree::Delimited` to avoid infinite size due to recursion.\n #[derive(Debug, Clone)]\n-pub struct ThinTokenStream(Option<RcVec<TokenStream>>);\n+pub struct ThinTokenStream(Option<Lrc<Vec<TokenStream>>>);\n \n impl ThinTokenStream {\n     pub fn stream(&self) -> TokenStream {\n@@ -666,18 +649,18 @@ impl ThinTokenStream {\n \n impl From<TokenStream> for ThinTokenStream {\n     fn from(stream: TokenStream) -> ThinTokenStream {\n-        ThinTokenStream(match stream.kind {\n-            TokenStreamKind::Empty => None,\n-            TokenStreamKind::Tree(tree) => Some(RcVec::new(vec![tree.into()])),\n-            TokenStreamKind::JointTree(tree) => Some(RcVec::new(vec![tree.joint()])),\n-            TokenStreamKind::Stream(stream) => Some(stream),\n+        ThinTokenStream(match stream {\n+            TokenStream::Empty => None,\n+            TokenStream::Tree(tree) => Some(Lrc::new(vec![tree.into()])),\n+            TokenStream::JointTree(tree) => Some(Lrc::new(vec![tree.joint()])),\n+            TokenStream::Stream(stream) => Some(stream),\n         })\n     }\n }\n \n impl From<ThinTokenStream> for TokenStream {\n     fn from(stream: ThinTokenStream) -> TokenStream {\n-        stream.0.map(TokenStream::concat_rc_vec).unwrap_or_else(TokenStream::empty)\n+        stream.0.map(TokenStream::Stream).unwrap_or_else(TokenStream::empty)\n     }\n }\n \n@@ -776,7 +759,7 @@ mod tests {\n             let test_res = string_to_ts(\"foo::bar::baz\");\n             let test_fst = string_to_ts(\"foo::bar\");\n             let test_snd = string_to_ts(\"::baz\");\n-            let eq_res = TokenStream::concat(vec![test_fst, test_snd]);\n+            let eq_res = TokenStream::new(vec![test_fst, test_snd]);\n             assert_eq!(test_res.trees().count(), 5);\n             assert_eq!(eq_res.trees().count(), 5);\n             assert_eq!(test_res.eq_unspanned(&eq_res), true);"}, {"sha": "520b7a48e3025a205128dd86f37e21ef5309129d", "filename": "src/libsyntax/util/rc_slice.rs", "status": "removed", "additions": 0, "deletions": 64, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0/src%2Flibsyntax%2Futil%2Frc_slice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0/src%2Flibsyntax%2Futil%2Frc_slice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Frc_slice.rs?ref=a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0", "patch": "@@ -1,64 +0,0 @@\n-// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use std::fmt;\n-use std::ops::{Deref, Range};\n-use rustc_data_structures::sync::Lrc;\n-\n-use rustc_data_structures::stable_hasher::{StableHasher, StableHasherResult,\n-                                           HashStable};\n-\n-#[derive(Clone)]\n-pub struct RcSlice<T> {\n-    data: Lrc<Box<[T]>>,\n-    offset: u32,\n-    len: u32,\n-}\n-\n-impl<T> RcSlice<T> {\n-    pub fn new(vec: Vec<T>) -> Self {\n-        RcSlice {\n-            offset: 0,\n-            len: vec.len() as u32,\n-            data: Lrc::new(vec.into_boxed_slice()),\n-        }\n-    }\n-\n-    pub fn sub_slice(&self, range: Range<usize>) -> Self {\n-        RcSlice {\n-            data: self.data.clone(),\n-            offset: self.offset + range.start as u32,\n-            len: (range.end - range.start) as u32,\n-        }\n-    }\n-}\n-\n-impl<T> Deref for RcSlice<T> {\n-    type Target = [T];\n-    fn deref(&self) -> &[T] {\n-        &self.data[self.offset as usize .. (self.offset + self.len) as usize]\n-    }\n-}\n-\n-impl<T: fmt::Debug> fmt::Debug for RcSlice<T> {\n-    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        fmt::Debug::fmt(self.deref(), f)\n-    }\n-}\n-\n-impl<CTX, T> HashStable<CTX> for RcSlice<T>\n-    where T: HashStable<CTX>\n-{\n-    fn hash_stable<W: StableHasherResult>(&self,\n-                                          hcx: &mut CTX,\n-                                          hasher: &mut StableHasher<W>) {\n-        (**self).hash_stable(hcx, hasher);\n-    }\n-}"}, {"sha": "99fbce1ad91e1e27106e3a0590d7d9fee7b8d1b7", "filename": "src/libsyntax/util/rc_vec.rs", "status": "removed", "additions": 0, "deletions": 90, "changes": 90, "blob_url": "https://github.com/rust-lang/rust/blob/a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0/src%2Flibsyntax%2Futil%2Frc_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0/src%2Flibsyntax%2Futil%2Frc_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Frc_vec.rs?ref=a8a2a887d0a65fff6c777f9bcd7b1c0bdfbbddc0", "patch": "@@ -1,90 +0,0 @@\n-// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use std::fmt;\n-use std::ops::{Deref, Range};\n-\n-use rustc_data_structures::stable_hasher::{HashStable, StableHasher, StableHasherResult};\n-use rustc_data_structures::sync::Lrc;\n-\n-#[derive(Clone)]\n-pub struct RcVec<T> {\n-    data: Lrc<Vec<T>>,\n-    offset: u32,\n-    len: u32,\n-}\n-\n-impl<T> RcVec<T> {\n-    pub fn new(mut vec: Vec<T>) -> Self {\n-        // By default, constructing RcVec from Vec gives it just enough capacity\n-        // to hold the initial elements. Callers that anticipate needing to\n-        // extend the vector may prefer RcVec::new_preserving_capacity.\n-        vec.shrink_to_fit();\n-        Self::new_preserving_capacity(vec)\n-    }\n-\n-    pub fn new_preserving_capacity(vec: Vec<T>) -> Self {\n-        RcVec {\n-            offset: 0,\n-            len: vec.len() as u32,\n-            data: Lrc::new(vec),\n-        }\n-    }\n-\n-    pub fn sub_slice(&self, range: Range<usize>) -> Self {\n-        RcVec {\n-            data: self.data.clone(),\n-            offset: self.offset + range.start as u32,\n-            len: (range.end - range.start) as u32,\n-        }\n-    }\n-\n-    /// If this RcVec has exactly one strong reference, returns ownership of the\n-    /// underlying vector. Otherwise returns self unmodified.\n-    pub fn try_unwrap(self) -> Result<Vec<T>, Self> {\n-        match Lrc::try_unwrap(self.data) {\n-            // If no other RcVec shares ownership of this data.\n-            Ok(mut vec) => {\n-                // Drop any elements after our view of the data.\n-                vec.truncate(self.offset as usize + self.len as usize);\n-                // Drop any elements before our view of the data. Do this after\n-                // the `truncate` so that elements past the end of our view do\n-                // not need to be copied around.\n-                vec.drain(..self.offset as usize);\n-                Ok(vec)\n-            }\n-\n-            // If the data is shared.\n-            Err(data) => Err(RcVec { data, ..self }),\n-        }\n-    }\n-}\n-\n-impl<T> Deref for RcVec<T> {\n-    type Target = [T];\n-    fn deref(&self) -> &[T] {\n-        &self.data[self.offset as usize..(self.offset + self.len) as usize]\n-    }\n-}\n-\n-impl<T: fmt::Debug> fmt::Debug for RcVec<T> {\n-    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        fmt::Debug::fmt(self.deref(), f)\n-    }\n-}\n-\n-impl<CTX, T> HashStable<CTX> for RcVec<T>\n-where\n-    T: HashStable<CTX>,\n-{\n-    fn hash_stable<W: StableHasherResult>(&self, hcx: &mut CTX, hasher: &mut StableHasher<W>) {\n-        (**self).hash_stable(hcx, hasher);\n-    }\n-}"}, {"sha": "1aa647a6a1b7822e4186786a287bdd3d7fbe7ad5", "filename": "src/tools/linkchecker/main.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Ftools%2Flinkchecker%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c6fb01d62916afa0c489670b665a39d1fe903a4a/src%2Ftools%2Flinkchecker%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Flinkchecker%2Fmain.rs?ref=c6fb01d62916afa0c489670b665a39d1fe903a4a", "patch": "@@ -137,7 +137,6 @@ fn check(cache: &mut Cache,\n        file.ends_with(\"symbol/struct.InternedString.html\") ||\n        file.ends_with(\"ast/struct.ThinVec.html\") ||\n        file.ends_with(\"util/struct.ThinVec.html\") ||\n-       file.ends_with(\"util/struct.RcSlice.html\") ||\n        file.ends_with(\"layout/struct.TyLayout.html\") ||\n        file.ends_with(\"humantime/struct.Timestamp.html\") ||\n        file.ends_with(\"log/index.html\") ||"}]}