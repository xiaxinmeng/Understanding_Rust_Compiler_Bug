{"sha": "3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "node_id": "C_kwDOAAsO6NoAKDNiMWZlN2U3Yzk1ZTE0ZGQ4YTQyMGVkZjJmOGExNjBjNzAyMTFlMDQ", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-02-27T14:04:07Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-02-27T14:04:07Z"}, "message": "Auto merge of #94084 - Mark-Simulacrum:drop-sharded, r=cjgillot\n\nAvoid query cache sharding code in single-threaded mode\n\nIn non-parallel compilers, this is just adding needless overhead at compilation time (since there is only one shard statically anyway). This amounts to roughly ~10 seconds reduction in bootstrap time, with overall neutral (some wins, some losses) performance results.\n\nParallel compiler performance should be largely unaffected by this PR; sharding is kept there.", "tree": {"sha": "1104075d21653e369db1b908d13c1c0dc8343e2f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1104075d21653e369db1b908d13c1c0dc8343e2f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "html_url": "https://github.com/rust-lang/rust/commit/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bab4c13f64b4197abc1a361796be9940ed5b3904", "url": "https://api.github.com/repos/rust-lang/rust/commits/bab4c13f64b4197abc1a361796be9940ed5b3904", "html_url": "https://github.com/rust-lang/rust/commit/bab4c13f64b4197abc1a361796be9940ed5b3904"}, {"sha": "594ea74bf0f735c7cd81a54409ab4d9005e07110", "url": "https://api.github.com/repos/rust-lang/rust/commits/594ea74bf0f735c7cd81a54409ab4d9005e07110", "html_url": "https://github.com/rust-lang/rust/commit/594ea74bf0f735c7cd81a54409ab4d9005e07110"}], "stats": {"total": 371, "additions": 167, "deletions": 204}, "files": [{"sha": "01d292dde8d13a262f89699ee50fc1c74d3cd6c9", "filename": "compiler/rustc_data_structures/src/sharded.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_data_structures%2Fsrc%2Fsharded.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_data_structures%2Fsrc%2Fsharded.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fsharded.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -129,7 +129,7 @@ impl<K: Eq + Hash + Copy + IntoPointer> ShardedHashMap<K, ()> {\n }\n \n #[inline]\n-fn make_hash<K: Hash + ?Sized>(val: &K) -> u64 {\n+pub fn make_hash<K: Hash + ?Sized>(val: &K) -> u64 {\n     let mut state = FxHasher::default();\n     val.hash(&mut state);\n     state.finish()"}, {"sha": "f2e1d129e9ba791ac765b65b1135fad46a6ee6f4", "filename": "compiler/rustc_middle/src/ty/query.rs", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -210,7 +210,7 @@ macro_rules! define_callbacks {\n \n         #[derive(Default)]\n         pub struct QueryCaches<$tcx> {\n-            $($(#[$attr])* pub $name: QueryCacheStore<query_storage::$name<$tcx>>,)*\n+            $($(#[$attr])* pub $name: query_storage::$name<$tcx>,)*\n         }\n \n         impl<$tcx> TyCtxtEnsure<$tcx> {\n@@ -222,12 +222,12 @@ macro_rules! define_callbacks {\n \n                 let cached = try_get_cached(self.tcx, &self.tcx.query_caches.$name, &key, noop);\n \n-                let lookup = match cached {\n+                match cached {\n                     Ok(()) => return,\n-                    Err(lookup) => lookup,\n-                };\n+                    Err(()) => (),\n+                }\n \n-                self.tcx.queries.$name(self.tcx, DUMMY_SP, key, lookup, QueryMode::Ensure);\n+                self.tcx.queries.$name(self.tcx, DUMMY_SP, key, QueryMode::Ensure);\n             })*\n         }\n \n@@ -251,12 +251,12 @@ macro_rules! define_callbacks {\n \n                 let cached = try_get_cached(self.tcx, &self.tcx.query_caches.$name, &key, copy);\n \n-                let lookup = match cached {\n+                match cached {\n                     Ok(value) => return value,\n-                    Err(lookup) => lookup,\n-                };\n+                    Err(()) => (),\n+                }\n \n-                self.tcx.queries.$name(self.tcx, self.span, key, lookup, QueryMode::Get).unwrap()\n+                self.tcx.queries.$name(self.tcx, self.span, key, QueryMode::Get).unwrap()\n             })*\n         }\n \n@@ -314,7 +314,6 @@ macro_rules! define_callbacks {\n                 tcx: TyCtxt<$tcx>,\n                 span: Span,\n                 key: query_keys::$name<$tcx>,\n-                lookup: QueryLookup,\n                 mode: QueryMode,\n             ) -> Option<query_stored::$name<$tcx>>;)*\n         }"}, {"sha": "f2f895367ff826102c45f58e99d61b2beae19cb0", "filename": "compiler/rustc_query_impl/src/on_disk_cache.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_impl%2Fsrc%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_impl%2Fsrc%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Fon_disk_cache.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -13,7 +13,7 @@ use rustc_middle::thir;\n use rustc_middle::ty::codec::{RefDecodable, TyDecoder, TyEncoder};\n use rustc_middle::ty::{self, Ty, TyCtxt};\n use rustc_query_system::dep_graph::DepContext;\n-use rustc_query_system::query::{QueryContext, QuerySideEffects};\n+use rustc_query_system::query::{QueryCache, QueryContext, QuerySideEffects};\n use rustc_serialize::{\n     opaque::{self, FileEncodeResult, FileEncoder, IntEncodedWithFixedSize},\n     Decodable, Decoder, Encodable, Encoder,\n@@ -1034,7 +1034,7 @@ where\n     assert!(Q::query_state(tcx).all_inactive());\n     let cache = Q::query_cache(tcx);\n     let mut res = Ok(());\n-    cache.iter_results(&mut |key, value, dep_node| {\n+    cache.iter(&mut |key, value, dep_node| {\n         if res.is_err() {\n             return;\n         }"}, {"sha": "bc82b0053b9efb790ca5a6caaaf86b4c343844cc", "filename": "compiler/rustc_query_impl/src/plumbing.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Fplumbing.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -336,7 +336,7 @@ macro_rules! define_queries {\n             }\n \n             #[inline(always)]\n-            fn query_cache<'a>(tcx: QueryCtxt<$tcx>) -> &'a QueryCacheStore<Self::Cache>\n+            fn query_cache<'a>(tcx: QueryCtxt<$tcx>) -> &'a Self::Cache\n                 where 'tcx:'a\n             {\n                 &tcx.query_caches.$name\n@@ -537,12 +537,11 @@ macro_rules! define_queries_struct {\n                 tcx: TyCtxt<$tcx>,\n                 span: Span,\n                 key: query_keys::$name<$tcx>,\n-                lookup: QueryLookup,\n                 mode: QueryMode,\n             ) -> Option<query_stored::$name<$tcx>> {\n                 opt_remap_env_constness!([$($modifiers)*][key]);\n                 let qcx = QueryCtxt { tcx, queries: self };\n-                get_query::<queries::$name<$tcx>, _>(qcx, span, key, lookup, mode)\n+                get_query::<queries::$name<$tcx>, _>(qcx, span, key, mode)\n             })*\n         }\n     };"}, {"sha": "acccf43f06285f59b8421227b0373d47bbbfac26", "filename": "compiler/rustc_query_impl/src/profiling_support.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_impl%2Fsrc%2Fprofiling_support.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_impl%2Fsrc%2Fprofiling_support.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_impl%2Fsrc%2Fprofiling_support.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -4,7 +4,7 @@ use rustc_data_structures::profiling::SelfProfiler;\n use rustc_hir::def_id::{CrateNum, DefId, DefIndex, LocalDefId, CRATE_DEF_INDEX, LOCAL_CRATE};\n use rustc_hir::definitions::DefPathData;\n use rustc_middle::ty::{TyCtxt, WithOptConstParam};\n-use rustc_query_system::query::{QueryCache, QueryCacheStore};\n+use rustc_query_system::query::QueryCache;\n use std::fmt::Debug;\n use std::io::Write;\n \n@@ -229,7 +229,7 @@ where\n fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n     tcx: TyCtxt<'tcx>,\n     query_name: &'static str,\n-    query_cache: &QueryCacheStore<C>,\n+    query_cache: &C,\n     string_cache: &mut QueryKeyStringCache,\n ) where\n     C: QueryCache,\n@@ -251,7 +251,7 @@ fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n             // locked while doing so. Instead we copy out the\n             // `(query_key, dep_node_index)` pairs and release the lock again.\n             let mut query_keys_and_indices = Vec::new();\n-            query_cache.iter_results(&mut |k, _, i| query_keys_and_indices.push((k.clone(), i)));\n+            query_cache.iter(&mut |k, _, i| query_keys_and_indices.push((k.clone(), i)));\n \n             // Now actually allocate the strings. If allocating the strings\n             // generates new entries in the query cache, we'll miss them but\n@@ -276,7 +276,7 @@ fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n             let event_id = event_id_builder.from_label(query_name).to_string_id();\n \n             let mut query_invocation_ids = Vec::new();\n-            query_cache.iter_results(&mut |_, _, i| {\n+            query_cache.iter(&mut |_, _, i| {\n                 query_invocation_ids.push(i.into());\n             });\n "}, {"sha": "85c5af72ef5353fad56cfc1735f3e4b2886478be", "filename": "compiler/rustc_query_system/src/query/caches.rs", "status": "modified", "additions": 76, "deletions": 73, "changes": 149, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -1,9 +1,12 @@\n use crate::dep_graph::DepNodeIndex;\n-use crate::query::plumbing::{QueryCacheStore, QueryLookup};\n \n use rustc_arena::TypedArena;\n use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::sharded;\n+#[cfg(parallel_compiler)]\n use rustc_data_structures::sharded::Sharded;\n+#[cfg(not(parallel_compiler))]\n+use rustc_data_structures::sync::Lock;\n use rustc_data_structures::sync::WorkerLocal;\n use std::default::Default;\n use std::fmt::Debug;\n@@ -25,35 +28,23 @@ pub trait QueryStorage {\n \n pub trait QueryCache: QueryStorage + Sized {\n     type Key: Hash + Eq + Clone + Debug;\n-    type Sharded: Default;\n \n     /// Checks if the query is already computed and in the cache.\n     /// It returns the shard index and a lock guard to the shard,\n     /// which will be used if the query is not in the cache and we need\n     /// to compute it.\n-    fn lookup<'s, R, OnHit>(\n+    fn lookup<R, OnHit>(\n         &self,\n-        state: &'s QueryCacheStore<Self>,\n         key: &Self::Key,\n         // `on_hit` can be called while holding a lock to the query state shard.\n         on_hit: OnHit,\n-    ) -> Result<R, QueryLookup>\n+    ) -> Result<R, ()>\n     where\n         OnHit: FnOnce(&Self::Stored, DepNodeIndex) -> R;\n \n-    fn complete(\n-        &self,\n-        lock_sharded_storage: &mut Self::Sharded,\n-        key: Self::Key,\n-        value: Self::Value,\n-        index: DepNodeIndex,\n-    ) -> Self::Stored;\n+    fn complete(&self, key: Self::Key, value: Self::Value, index: DepNodeIndex) -> Self::Stored;\n \n-    fn iter(\n-        &self,\n-        shards: &Sharded<Self::Sharded>,\n-        f: &mut dyn FnMut(&Self::Key, &Self::Value, DepNodeIndex),\n-    );\n+    fn iter(&self, f: &mut dyn FnMut(&Self::Key, &Self::Value, DepNodeIndex));\n }\n \n pub struct DefaultCacheSelector;\n@@ -62,11 +53,16 @@ impl<K: Eq + Hash, V: Clone> CacheSelector<K, V> for DefaultCacheSelector {\n     type Cache = DefaultCache<K, V>;\n }\n \n-pub struct DefaultCache<K, V>(PhantomData<(K, V)>);\n+pub struct DefaultCache<K, V> {\n+    #[cfg(parallel_compiler)]\n+    cache: Sharded<FxHashMap<K, (V, DepNodeIndex)>>,\n+    #[cfg(not(parallel_compiler))]\n+    cache: Lock<FxHashMap<K, (V, DepNodeIndex)>>,\n+}\n \n impl<K, V> Default for DefaultCache<K, V> {\n     fn default() -> Self {\n-        DefaultCache(PhantomData)\n+        DefaultCache { cache: Default::default() }\n     }\n }\n \n@@ -87,49 +83,51 @@ where\n     V: Clone + Debug,\n {\n     type Key = K;\n-    type Sharded = FxHashMap<K, (V, DepNodeIndex)>;\n \n     #[inline(always)]\n-    fn lookup<'s, R, OnHit>(\n-        &self,\n-        state: &'s QueryCacheStore<Self>,\n-        key: &K,\n-        on_hit: OnHit,\n-    ) -> Result<R, QueryLookup>\n+    fn lookup<R, OnHit>(&self, key: &K, on_hit: OnHit) -> Result<R, ()>\n     where\n         OnHit: FnOnce(&V, DepNodeIndex) -> R,\n     {\n-        let (lookup, lock) = state.get_lookup(key);\n-        let result = lock.raw_entry().from_key_hashed_nocheck(lookup.key_hash, key);\n+        let key_hash = sharded::make_hash(key);\n+        #[cfg(parallel_compiler)]\n+        let lock = self.cache.get_shard_by_hash(key_hash).lock();\n+        #[cfg(not(parallel_compiler))]\n+        let lock = self.cache.lock();\n+        let result = lock.raw_entry().from_key_hashed_nocheck(key_hash, key);\n \n         if let Some((_, value)) = result {\n             let hit_result = on_hit(&value.0, value.1);\n             Ok(hit_result)\n         } else {\n-            Err(lookup)\n+            Err(())\n         }\n     }\n \n     #[inline]\n-    fn complete(\n-        &self,\n-        lock_sharded_storage: &mut Self::Sharded,\n-        key: K,\n-        value: V,\n-        index: DepNodeIndex,\n-    ) -> Self::Stored {\n-        lock_sharded_storage.insert(key, (value.clone(), index));\n+    fn complete(&self, key: K, value: V, index: DepNodeIndex) -> Self::Stored {\n+        #[cfg(parallel_compiler)]\n+        let mut lock = self.cache.get_shard_by_value(&key).lock();\n+        #[cfg(not(parallel_compiler))]\n+        let mut lock = self.cache.lock();\n+        lock.insert(key, (value.clone(), index));\n         value\n     }\n \n-    fn iter(\n-        &self,\n-        shards: &Sharded<Self::Sharded>,\n-        f: &mut dyn FnMut(&Self::Key, &Self::Value, DepNodeIndex),\n-    ) {\n-        let shards = shards.lock_shards();\n-        for shard in shards.iter() {\n-            for (k, v) in shard.iter() {\n+    fn iter(&self, f: &mut dyn FnMut(&Self::Key, &Self::Value, DepNodeIndex)) {\n+        #[cfg(parallel_compiler)]\n+        {\n+            let shards = self.cache.lock_shards();\n+            for shard in shards.iter() {\n+                for (k, v) in shard.iter() {\n+                    f(k, &v.0, v.1);\n+                }\n+            }\n+        }\n+        #[cfg(not(parallel_compiler))]\n+        {\n+            let map = self.cache.lock();\n+            for (k, v) in map.iter() {\n                 f(k, &v.0, v.1);\n             }\n         }\n@@ -144,12 +142,15 @@ impl<'tcx, K: Eq + Hash, V: 'tcx> CacheSelector<K, V> for ArenaCacheSelector<'tc\n \n pub struct ArenaCache<'tcx, K, V> {\n     arena: WorkerLocal<TypedArena<(V, DepNodeIndex)>>,\n-    phantom: PhantomData<(K, &'tcx V)>,\n+    #[cfg(parallel_compiler)]\n+    cache: Sharded<FxHashMap<K, &'tcx (V, DepNodeIndex)>>,\n+    #[cfg(not(parallel_compiler))]\n+    cache: Lock<FxHashMap<K, &'tcx (V, DepNodeIndex)>>,\n }\n \n impl<'tcx, K, V> Default for ArenaCache<'tcx, K, V> {\n     fn default() -> Self {\n-        ArenaCache { arena: WorkerLocal::new(|_| TypedArena::default()), phantom: PhantomData }\n+        ArenaCache { arena: WorkerLocal::new(|_| TypedArena::default()), cache: Default::default() }\n     }\n }\n \n@@ -171,51 +172,53 @@ where\n     V: Debug,\n {\n     type Key = K;\n-    type Sharded = FxHashMap<K, &'tcx (V, DepNodeIndex)>;\n \n     #[inline(always)]\n-    fn lookup<'s, R, OnHit>(\n-        &self,\n-        state: &'s QueryCacheStore<Self>,\n-        key: &K,\n-        on_hit: OnHit,\n-    ) -> Result<R, QueryLookup>\n+    fn lookup<R, OnHit>(&self, key: &K, on_hit: OnHit) -> Result<R, ()>\n     where\n         OnHit: FnOnce(&&'tcx V, DepNodeIndex) -> R,\n     {\n-        let (lookup, lock) = state.get_lookup(key);\n-        let result = lock.raw_entry().from_key_hashed_nocheck(lookup.key_hash, key);\n+        let key_hash = sharded::make_hash(key);\n+        #[cfg(parallel_compiler)]\n+        let lock = self.cache.get_shard_by_hash(key_hash).lock();\n+        #[cfg(not(parallel_compiler))]\n+        let lock = self.cache.lock();\n+        let result = lock.raw_entry().from_key_hashed_nocheck(key_hash, key);\n \n         if let Some((_, value)) = result {\n             let hit_result = on_hit(&&value.0, value.1);\n             Ok(hit_result)\n         } else {\n-            Err(lookup)\n+            Err(())\n         }\n     }\n \n     #[inline]\n-    fn complete(\n-        &self,\n-        lock_sharded_storage: &mut Self::Sharded,\n-        key: K,\n-        value: V,\n-        index: DepNodeIndex,\n-    ) -> Self::Stored {\n+    fn complete(&self, key: K, value: V, index: DepNodeIndex) -> Self::Stored {\n         let value = self.arena.alloc((value, index));\n         let value = unsafe { &*(value as *const _) };\n-        lock_sharded_storage.insert(key, value);\n+        #[cfg(parallel_compiler)]\n+        let mut lock = self.cache.get_shard_by_value(&key).lock();\n+        #[cfg(not(parallel_compiler))]\n+        let mut lock = self.cache.lock();\n+        lock.insert(key, value);\n         &value.0\n     }\n \n-    fn iter(\n-        &self,\n-        shards: &Sharded<Self::Sharded>,\n-        f: &mut dyn FnMut(&Self::Key, &Self::Value, DepNodeIndex),\n-    ) {\n-        let shards = shards.lock_shards();\n-        for shard in shards.iter() {\n-            for (k, v) in shard.iter() {\n+    fn iter(&self, f: &mut dyn FnMut(&Self::Key, &Self::Value, DepNodeIndex)) {\n+        #[cfg(parallel_compiler)]\n+        {\n+            let shards = self.cache.lock_shards();\n+            for shard in shards.iter() {\n+                for (k, v) in shard.iter() {\n+                    f(k, &v.0, v.1);\n+                }\n+            }\n+        }\n+        #[cfg(not(parallel_compiler))]\n+        {\n+            let map = self.cache.lock();\n+            for (k, v) in map.iter() {\n                 f(k, &v.0, v.1);\n             }\n         }"}, {"sha": "9e30d0c6440097398fead78c6c3eb515546b202f", "filename": "compiler/rustc_query_system/src/query/config.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -4,7 +4,7 @@ use crate::dep_graph::DepNode;\n use crate::dep_graph::SerializedDepNodeIndex;\n use crate::ich::StableHashingContext;\n use crate::query::caches::QueryCache;\n-use crate::query::{QueryCacheStore, QueryContext, QueryState};\n+use crate::query::{QueryContext, QueryState};\n \n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_errors::{DiagnosticBuilder, ErrorReported};\n@@ -64,7 +64,7 @@ pub trait QueryDescription<CTX: QueryContext>: QueryConfig {\n         CTX: 'a;\n \n     // Don't use this method to access query results, instead use the methods on TyCtxt\n-    fn query_cache<'a>(tcx: CTX) -> &'a QueryCacheStore<Self::Cache>\n+    fn query_cache<'a>(tcx: CTX) -> &'a Self::Cache\n     where\n         CTX: 'a;\n "}, {"sha": "8781912fe59783a781be8782e1cce0a48848067e", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 71, "deletions": 109, "changes": 180, "blob_url": "https://github.com/rust-lang/rust/blob/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3b1fe7e7c95e14dd8a420edf2f8a160c70211e04/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=3b1fe7e7c95e14dd8a420edf2f8a160c70211e04", "patch": "@@ -8,76 +8,28 @@ use crate::query::config::{QueryDescription, QueryVtable};\n use crate::query::job::{report_cycle, QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n use crate::query::{QueryContext, QueryMap, QuerySideEffects, QueryStackFrame};\n use rustc_data_structures::fingerprint::Fingerprint;\n-use rustc_data_structures::fx::{FxHashMap, FxHasher};\n+use rustc_data_structures::fx::FxHashMap;\n #[cfg(parallel_compiler)]\n use rustc_data_structures::profiling::TimingGuard;\n-use rustc_data_structures::sharded::{get_shard_index_by_hash, Sharded};\n-use rustc_data_structures::sync::{Lock, LockGuard};\n+#[cfg(parallel_compiler)]\n+use rustc_data_structures::sharded::Sharded;\n+use rustc_data_structures::sync::Lock;\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::{DiagnosticBuilder, ErrorReported, FatalError};\n use rustc_session::Session;\n use rustc_span::{Span, DUMMY_SP};\n use std::cell::Cell;\n use std::collections::hash_map::Entry;\n use std::fmt::Debug;\n-use std::hash::{Hash, Hasher};\n+use std::hash::Hash;\n use std::mem;\n use std::ptr;\n \n-pub struct QueryCacheStore<C: QueryCache> {\n-    cache: C,\n-    shards: Sharded<C::Sharded>,\n-}\n-\n-impl<C: QueryCache + Default> Default for QueryCacheStore<C> {\n-    fn default() -> Self {\n-        Self { cache: C::default(), shards: Default::default() }\n-    }\n-}\n-\n-/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n-pub struct QueryLookup {\n-    pub(super) key_hash: u64,\n-    shard: usize,\n-}\n-\n-// We compute the key's hash once and then use it for both the\n-// shard lookup and the hashmap lookup. This relies on the fact\n-// that both of them use `FxHasher`.\n-fn hash_for_shard<K: Hash>(key: &K) -> u64 {\n-    let mut hasher = FxHasher::default();\n-    key.hash(&mut hasher);\n-    hasher.finish()\n-}\n-\n-impl<C: QueryCache> QueryCacheStore<C> {\n-    pub(super) fn get_lookup<'tcx>(\n-        &'tcx self,\n-        key: &C::Key,\n-    ) -> (QueryLookup, LockGuard<'tcx, C::Sharded>) {\n-        let key_hash = hash_for_shard(key);\n-        let shard = get_shard_index_by_hash(key_hash);\n-        let lock = self.shards.get_shard_by_index(shard).lock();\n-        (QueryLookup { key_hash, shard }, lock)\n-    }\n-\n-    pub fn iter_results(&self, f: &mut dyn FnMut(&C::Key, &C::Value, DepNodeIndex)) {\n-        self.cache.iter(&self.shards, f)\n-    }\n-}\n-\n-struct QueryStateShard<K> {\n-    active: FxHashMap<K, QueryResult>,\n-}\n-\n-impl<K> Default for QueryStateShard<K> {\n-    fn default() -> QueryStateShard<K> {\n-        QueryStateShard { active: Default::default() }\n-    }\n-}\n-\n pub struct QueryState<K> {\n-    shards: Sharded<QueryStateShard<K>>,\n+    #[cfg(parallel_compiler)]\n+    active: Sharded<FxHashMap<K, QueryResult>>,\n+    #[cfg(not(parallel_compiler))]\n+    active: Lock<FxHashMap<K, QueryResult>>,\n }\n \n /// Indicates the state of a query for a given key in a query map.\n@@ -95,8 +47,15 @@ where\n     K: Eq + Hash + Clone + Debug,\n {\n     pub fn all_inactive(&self) -> bool {\n-        let shards = self.shards.lock_shards();\n-        shards.iter().all(|shard| shard.active.is_empty())\n+        #[cfg(parallel_compiler)]\n+        {\n+            let shards = self.active.lock_shards();\n+            shards.iter().all(|shard| shard.is_empty())\n+        }\n+        #[cfg(not(parallel_compiler))]\n+        {\n+            self.active.lock().is_empty()\n+        }\n     }\n \n     pub fn try_collect_active_jobs<CTX: Copy>(\n@@ -105,11 +64,27 @@ where\n         make_query: fn(CTX, K) -> QueryStackFrame,\n         jobs: &mut QueryMap,\n     ) -> Option<()> {\n-        // We use try_lock_shards here since we are called from the\n-        // deadlock handler, and this shouldn't be locked.\n-        let shards = self.shards.try_lock_shards()?;\n-        for shard in shards.iter() {\n-            for (k, v) in shard.active.iter() {\n+        #[cfg(parallel_compiler)]\n+        {\n+            // We use try_lock_shards here since we are called from the\n+            // deadlock handler, and this shouldn't be locked.\n+            let shards = self.active.try_lock_shards()?;\n+            for shard in shards.iter() {\n+                for (k, v) in shard.iter() {\n+                    if let QueryResult::Started(ref job) = *v {\n+                        let query = make_query(tcx, k.clone());\n+                        jobs.insert(job.id, QueryJobInfo { query, job: job.clone() });\n+                    }\n+                }\n+            }\n+        }\n+        #[cfg(not(parallel_compiler))]\n+        {\n+            // We use try_lock here since we are called from the\n+            // deadlock handler, and this shouldn't be locked.\n+            // (FIXME: Is this relevant for non-parallel compilers? It doesn't\n+            // really hurt much.)\n+            for (k, v) in self.active.try_lock()?.iter() {\n                 if let QueryResult::Started(ref job) = *v {\n                     let query = make_query(tcx, k.clone());\n                     jobs.insert(job.id, QueryJobInfo { query, job: job.clone() });\n@@ -123,7 +98,7 @@ where\n \n impl<K> Default for QueryState<K> {\n     fn default() -> QueryState<K> {\n-        QueryState { shards: Default::default() }\n+        QueryState { active: Default::default() }\n     }\n }\n \n@@ -174,16 +149,17 @@ where\n         state: &'b QueryState<K>,\n         span: Span,\n         key: K,\n-        lookup: QueryLookup,\n     ) -> TryGetJob<'b, K>\n     where\n         CTX: QueryContext,\n     {\n-        let shard = lookup.shard;\n-        let mut state_lock = state.shards.get_shard_by_index(shard).lock();\n+        #[cfg(parallel_compiler)]\n+        let mut state_lock = state.active.get_shard_by_value(&key).lock();\n+        #[cfg(not(parallel_compiler))]\n+        let mut state_lock = state.active.lock();\n         let lock = &mut *state_lock;\n \n-        match lock.active.entry(key) {\n+        match lock.entry(key) {\n             Entry::Vacant(entry) => {\n                 let id = tcx.next_job_id();\n                 let job = tcx.current_query_job();\n@@ -239,12 +215,7 @@ where\n \n     /// Completes the query by updating the query cache with the `result`,\n     /// signals the waiter and forgets the JobOwner, so it won't poison the query\n-    fn complete<C>(\n-        self,\n-        cache: &QueryCacheStore<C>,\n-        result: C::Value,\n-        dep_node_index: DepNodeIndex,\n-    ) -> C::Stored\n+    fn complete<C>(self, cache: &C, result: C::Value, dep_node_index: DepNodeIndex) -> C::Stored\n     where\n         C: QueryCache<Key = K>,\n     {\n@@ -256,19 +227,17 @@ where\n         mem::forget(self);\n \n         let (job, result) = {\n-            let key_hash = hash_for_shard(&key);\n-            let shard = get_shard_index_by_hash(key_hash);\n             let job = {\n-                let mut lock = state.shards.get_shard_by_index(shard).lock();\n-                match lock.active.remove(&key).unwrap() {\n+                #[cfg(parallel_compiler)]\n+                let mut lock = state.active.get_shard_by_value(&key).lock();\n+                #[cfg(not(parallel_compiler))]\n+                let mut lock = state.active.lock();\n+                match lock.remove(&key).unwrap() {\n                     QueryResult::Started(job) => job,\n                     QueryResult::Poisoned => panic!(),\n                 }\n             };\n-            let result = {\n-                let mut lock = cache.shards.get_shard_by_index(shard).lock();\n-                cache.cache.complete(&mut lock, key, result, dep_node_index)\n-            };\n+            let result = cache.complete(key, result, dep_node_index);\n             (job, result)\n         };\n \n@@ -286,14 +255,16 @@ where\n     fn drop(&mut self) {\n         // Poison the query so jobs waiting on it panic.\n         let state = self.state;\n-        let shard = state.shards.get_shard_by_value(&self.key);\n         let job = {\n-            let mut shard = shard.lock();\n-            let job = match shard.active.remove(&self.key).unwrap() {\n+            #[cfg(parallel_compiler)]\n+            let mut shard = state.active.get_shard_by_value(&self.key).lock();\n+            #[cfg(not(parallel_compiler))]\n+            let mut shard = state.active.lock();\n+            let job = match shard.remove(&self.key).unwrap() {\n                 QueryResult::Started(job) => job,\n                 QueryResult::Poisoned => panic!(),\n             };\n-            shard.active.insert(self.key.clone(), QueryResult::Poisoned);\n+            shard.insert(self.key.clone(), QueryResult::Poisoned);\n             job\n         };\n         // Also signal the completion of the job, so waiters\n@@ -334,17 +305,17 @@ where\n #[inline]\n pub fn try_get_cached<'a, CTX, C, R, OnHit>(\n     tcx: CTX,\n-    cache: &'a QueryCacheStore<C>,\n+    cache: &'a C,\n     key: &C::Key,\n     // `on_hit` can be called while holding a lock to the query cache\n     on_hit: OnHit,\n-) -> Result<R, QueryLookup>\n+) -> Result<R, ()>\n where\n     C: QueryCache,\n     CTX: DepContext,\n     OnHit: FnOnce(&C::Stored) -> R,\n {\n-    cache.cache.lookup(cache, &key, |value, index| {\n+    cache.lookup(&key, |value, index| {\n         if unlikely!(tcx.profiler().enabled()) {\n             tcx.profiler().query_cache_hit(index.into());\n         }\n@@ -356,10 +327,9 @@ where\n fn try_execute_query<CTX, C>(\n     tcx: CTX,\n     state: &QueryState<C::Key>,\n-    cache: &QueryCacheStore<C>,\n+    cache: &C,\n     span: Span,\n     key: C::Key,\n-    lookup: QueryLookup,\n     dep_node: Option<DepNode<CTX::DepKind>>,\n     query: &QueryVtable<CTX, C::Key, C::Value>,\n ) -> (C::Stored, Option<DepNodeIndex>)\n@@ -368,21 +338,20 @@ where\n     C::Key: Clone + DepNodeParams<CTX::DepContext>,\n     CTX: QueryContext,\n {\n-    match JobOwner::<'_, C::Key>::try_start(&tcx, state, span, key.clone(), lookup) {\n+    match JobOwner::<'_, C::Key>::try_start(&tcx, state, span, key.clone()) {\n         TryGetJob::NotYetStarted(job) => {\n             let (result, dep_node_index) = execute_job(tcx, key, dep_node, query, job.id);\n             let result = job.complete(cache, result, dep_node_index);\n             (result, Some(dep_node_index))\n         }\n         TryGetJob::Cycle(error) => {\n-            let result = mk_cycle(tcx, error, query.handle_cycle_error, &cache.cache);\n+            let result = mk_cycle(tcx, error, query.handle_cycle_error, cache);\n             (result, None)\n         }\n         #[cfg(parallel_compiler)]\n         TryGetJob::JobCompleted(query_blocked_prof_timer) => {\n             let (v, index) = cache\n-                .cache\n-                .lookup(cache, &key, |value, index| (value.clone(), index))\n+                .lookup(&key, |value, index| (value.clone(), index))\n                 .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n \n             if unlikely!(tcx.dep_context().profiler().enabled()) {\n@@ -711,13 +680,7 @@ pub enum QueryMode {\n     Ensure,\n }\n \n-pub fn get_query<Q, CTX>(\n-    tcx: CTX,\n-    span: Span,\n-    key: Q::Key,\n-    lookup: QueryLookup,\n-    mode: QueryMode,\n-) -> Option<Q::Stored>\n+pub fn get_query<Q, CTX>(tcx: CTX, span: Span, key: Q::Key, mode: QueryMode) -> Option<Q::Stored>\n where\n     Q: QueryDescription<CTX>,\n     Q::Key: DepNodeParams<CTX::DepContext>,\n@@ -741,7 +704,6 @@ where\n         Q::query_cache(tcx),\n         span,\n         key,\n-        lookup,\n         dep_node,\n         &query,\n     );\n@@ -760,20 +722,20 @@ where\n     // We may be concurrently trying both execute and force a query.\n     // Ensure that only one of them runs the query.\n     let cache = Q::query_cache(tcx);\n-    let cached = cache.cache.lookup(cache, &key, |_, index| {\n+    let cached = cache.lookup(&key, |_, index| {\n         if unlikely!(tcx.dep_context().profiler().enabled()) {\n             tcx.dep_context().profiler().query_cache_hit(index.into());\n         }\n     });\n \n-    let lookup = match cached {\n+    match cached {\n         Ok(()) => return,\n-        Err(lookup) => lookup,\n-    };\n+        Err(()) => {}\n+    }\n \n     let query = Q::make_vtable(tcx, &key);\n     let state = Q::query_state(tcx);\n     debug_assert!(!query.anon);\n \n-    try_execute_query(tcx, state, cache, DUMMY_SP, key, lookup, Some(dep_node), &query);\n+    try_execute_query(tcx, state, cache, DUMMY_SP, key, Some(dep_node), &query);\n }"}]}