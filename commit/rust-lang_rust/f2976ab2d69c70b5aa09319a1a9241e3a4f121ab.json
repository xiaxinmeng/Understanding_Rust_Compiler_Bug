{"sha": "f2976ab2d69c70b5aa09319a1a9241e3a4f121ab", "node_id": "MDY6Q29tbWl0NzI0NzEyOmYyOTc2YWIyZDY5YzcwYjVhYTA5MzE5YTFhOTI0MWUzYTRmMTIxYWI=", "commit": {"author": {"name": "Lzu Tao", "email": "taolzu@gmail.com", "date": "2020-09-04T01:45:11Z"}, "committer": {"name": "Lzu Tao", "email": "taolzu@gmail.com", "date": "2020-09-14T09:35:54Z"}, "message": "Move ascii to new module", "tree": {"sha": "b9a0c83aee68de1fbcc3edffaa5ab9d38bc31180", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b9a0c83aee68de1fbcc3edffaa5ab9d38bc31180"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab", "html_url": "https://github.com/rust-lang/rust/commit/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab/comments", "author": {"login": "tesuji", "id": 15225902, "node_id": "MDQ6VXNlcjE1MjI1OTAy", "avatar_url": "https://avatars.githubusercontent.com/u/15225902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tesuji", "html_url": "https://github.com/tesuji", "followers_url": "https://api.github.com/users/tesuji/followers", "following_url": "https://api.github.com/users/tesuji/following{/other_user}", "gists_url": "https://api.github.com/users/tesuji/gists{/gist_id}", "starred_url": "https://api.github.com/users/tesuji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tesuji/subscriptions", "organizations_url": "https://api.github.com/users/tesuji/orgs", "repos_url": "https://api.github.com/users/tesuji/repos", "events_url": "https://api.github.com/users/tesuji/events{/privacy}", "received_events_url": "https://api.github.com/users/tesuji/received_events", "type": "User", "site_admin": false}, "committer": {"login": "tesuji", "id": 15225902, "node_id": "MDQ6VXNlcjE1MjI1OTAy", "avatar_url": "https://avatars.githubusercontent.com/u/15225902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tesuji", "html_url": "https://github.com/tesuji", "followers_url": "https://api.github.com/users/tesuji/followers", "following_url": "https://api.github.com/users/tesuji/following{/other_user}", "gists_url": "https://api.github.com/users/tesuji/gists{/gist_id}", "starred_url": "https://api.github.com/users/tesuji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tesuji/subscriptions", "organizations_url": "https://api.github.com/users/tesuji/orgs", "repos_url": "https://api.github.com/users/tesuji/repos", "events_url": "https://api.github.com/users/tesuji/events{/privacy}", "received_events_url": "https://api.github.com/users/tesuji/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fbad684e2ff11f58dc94d9c19bf31c5787afd98e", "url": "https://api.github.com/repos/rust-lang/rust/commits/fbad684e2ff11f58dc94d9c19bf31c5787afd98e", "html_url": "https://github.com/rust-lang/rust/commit/fbad684e2ff11f58dc94d9c19bf31c5787afd98e"}], "stats": {"total": 314, "additions": 157, "deletions": 157}, "files": [{"sha": "42032bc9035bcfb1f5f7faa91639dc6390820fbc", "filename": "library/core/src/slice/ascii.rs", "status": "added", "additions": 156, "deletions": 0, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab/library%2Fcore%2Fsrc%2Fslice%2Fascii.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab/library%2Fcore%2Fsrc%2Fslice%2Fascii.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fcore%2Fsrc%2Fslice%2Fascii.rs?ref=f2976ab2d69c70b5aa09319a1a9241e3a4f121ab", "patch": "@@ -0,0 +1,156 @@\n+//! Operations on ASCII `[u8]`.\n+\n+use crate::mem;\n+\n+#[lang = \"slice_u8\"]\n+#[cfg(not(test))]\n+impl [u8] {\n+    /// Checks if all bytes in this slice are within the ASCII range.\n+    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n+    #[inline]\n+    pub fn is_ascii(&self) -> bool {\n+        is_ascii(self)\n+    }\n+\n+    /// Checks that two slices are an ASCII case-insensitive match.\n+    ///\n+    /// Same as `to_ascii_lowercase(a) == to_ascii_lowercase(b)`,\n+    /// but without allocating and copying temporaries.\n+    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n+    #[inline]\n+    pub fn eq_ignore_ascii_case(&self, other: &[u8]) -> bool {\n+        self.len() == other.len() && self.iter().zip(other).all(|(a, b)| a.eq_ignore_ascii_case(b))\n+    }\n+\n+    /// Converts this slice to its ASCII upper case equivalent in-place.\n+    ///\n+    /// ASCII letters 'a' to 'z' are mapped to 'A' to 'Z',\n+    /// but non-ASCII letters are unchanged.\n+    ///\n+    /// To return a new uppercased value without modifying the existing one, use\n+    /// [`to_ascii_uppercase`].\n+    ///\n+    /// [`to_ascii_uppercase`]: #method.to_ascii_uppercase\n+    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n+    #[inline]\n+    pub fn make_ascii_uppercase(&mut self) {\n+        for byte in self {\n+            byte.make_ascii_uppercase();\n+        }\n+    }\n+\n+    /// Converts this slice to its ASCII lower case equivalent in-place.\n+    ///\n+    /// ASCII letters 'A' to 'Z' are mapped to 'a' to 'z',\n+    /// but non-ASCII letters are unchanged.\n+    ///\n+    /// To return a new lowercased value without modifying the existing one, use\n+    /// [`to_ascii_lowercase`].\n+    ///\n+    /// [`to_ascii_lowercase`]: #method.to_ascii_lowercase\n+    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n+    #[inline]\n+    pub fn make_ascii_lowercase(&mut self) {\n+        for byte in self {\n+            byte.make_ascii_lowercase();\n+        }\n+    }\n+}\n+\n+/// Returns `true` if any byte in the word `v` is nonascii (>= 128). Snarfed\n+/// from `../str/mod.rs`, which does something similar for utf8 validation.\n+#[inline]\n+fn contains_nonascii(v: usize) -> bool {\n+    const NONASCII_MASK: usize = 0x80808080_80808080u64 as usize;\n+    (NONASCII_MASK & v) != 0\n+}\n+\n+/// Optimized ASCII test that will use usize-at-a-time operations instead of\n+/// byte-at-a-time operations (when possible).\n+///\n+/// The algorithm we use here is pretty simple. If `s` is too short, we just\n+/// check each byte and be done with it. Otherwise:\n+///\n+/// - Read the first word with an unaligned load.\n+/// - Align the pointer, read subsequent words until end with aligned loads.\n+/// - Read the last `usize` from `s` with an unaligned load.\n+///\n+/// If any of these loads produces something for which `contains_nonascii`\n+/// (above) returns true, then we know the answer is false.\n+#[inline]\n+fn is_ascii(s: &[u8]) -> bool {\n+    const USIZE_SIZE: usize = mem::size_of::<usize>();\n+\n+    let len = s.len();\n+    let align_offset = s.as_ptr().align_offset(USIZE_SIZE);\n+\n+    // If we wouldn't gain anything from the word-at-a-time implementation, fall\n+    // back to a scalar loop.\n+    //\n+    // We also do this for architectures where `size_of::<usize>()` isn't\n+    // sufficient alignment for `usize`, because it's a weird edge case.\n+    if len < USIZE_SIZE || len < align_offset || USIZE_SIZE < mem::align_of::<usize>() {\n+        return s.iter().all(|b| b.is_ascii());\n+    }\n+\n+    // We always read the first word unaligned, which means `align_offset` is\n+    // 0, we'd read the same value again for the aligned read.\n+    let offset_to_aligned = if align_offset == 0 { USIZE_SIZE } else { align_offset };\n+\n+    let start = s.as_ptr();\n+    // SAFETY: We verify `len < USIZE_SIZE` above.\n+    let first_word = unsafe { (start as *const usize).read_unaligned() };\n+\n+    if contains_nonascii(first_word) {\n+        return false;\n+    }\n+    // We checked this above, somewhat implicitly. Note that `offset_to_aligned`\n+    // is either `align_offset` or `USIZE_SIZE`, both of are explicitly checked\n+    // above.\n+    debug_assert!(offset_to_aligned <= len);\n+\n+    // SAFETY: word_ptr is the (properly aligned) usize ptr we use to read the\n+    // middle chunk of the slice.\n+    let mut word_ptr = unsafe { start.add(offset_to_aligned) as *const usize };\n+\n+    // `byte_pos` is the byte index of `word_ptr`, used for loop end checks.\n+    let mut byte_pos = offset_to_aligned;\n+\n+    // Paranoia check about alignment, since we're about to do a bunch of\n+    // unaligned loads. In practice this should be impossible barring a bug in\n+    // `align_offset` though.\n+    debug_assert_eq!((word_ptr as usize) % mem::align_of::<usize>(), 0);\n+\n+    // Read subsequent words until the last aligned word, excluding the last\n+    // aligned word by itself to be done in tail check later, to ensure that\n+    // tail is always one `usize` at most to extra branch `byte_pos == len`.\n+    while byte_pos < len - USIZE_SIZE {\n+        debug_assert!(\n+            // Sanity check that the read is in bounds\n+            (word_ptr as usize + USIZE_SIZE) <= (start.wrapping_add(len) as usize) &&\n+            // And that our assumptions about `byte_pos` hold.\n+            (word_ptr as usize) - (start as usize) == byte_pos\n+        );\n+\n+        // SAFETY: We know `word_ptr` is properly aligned (because of\n+        // `align_offset`), and we know that we have enough bytes between `word_ptr` and the end\n+        let word = unsafe { word_ptr.read() };\n+        if contains_nonascii(word) {\n+            return false;\n+        }\n+\n+        byte_pos += USIZE_SIZE;\n+        // SAFETY: We know that `byte_pos <= len - USIZE_SIZE`, which means that\n+        // after this `add`, `word_ptr` will be at most one-past-the-end.\n+        word_ptr = unsafe { word_ptr.add(1) };\n+    }\n+\n+    // Sanity check to ensure there really is only one `usize` left. This should\n+    // be guaranteed by our loop condition.\n+    debug_assert!(byte_pos <= len && len - byte_pos <= USIZE_SIZE);\n+\n+    // SAFETY: This relies on `len >= USIZE_SIZE`, which we check at the start.\n+    let last_word = unsafe { (start.add(len - USIZE_SIZE) as *const usize).read_unaligned() };\n+\n+    !contains_nonascii(last_word)\n+}"}, {"sha": "e01374a3f5933be2e6ec51e097f7f44d7dbc5d2c", "filename": "library/core/src/slice/mod.rs", "status": "modified", "additions": 1, "deletions": 157, "changes": 158, "blob_url": "https://github.com/rust-lang/rust/blob/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab/library%2Fcore%2Fsrc%2Fslice%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2976ab2d69c70b5aa09319a1a9241e3a4f121ab/library%2Fcore%2Fsrc%2Fslice%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fcore%2Fsrc%2Fslice%2Fmod.rs?ref=f2976ab2d69c70b5aa09319a1a9241e3a4f121ab", "patch": "@@ -39,6 +39,7 @@ use crate::result::Result::{Err, Ok};\n /// Pure rust memchr implementation, taken from rust-memchr\n pub mod memchr;\n \n+mod ascii;\n mod cmp;\n mod index;\n mod iter;\n@@ -3197,163 +3198,6 @@ impl<T> [T] {\n     }\n }\n \n-#[lang = \"slice_u8\"]\n-#[cfg(not(test))]\n-impl [u8] {\n-    /// Checks if all bytes in this slice are within the ASCII range.\n-    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n-    #[inline]\n-    pub fn is_ascii(&self) -> bool {\n-        is_ascii(self)\n-    }\n-\n-    /// Checks that two slices are an ASCII case-insensitive match.\n-    ///\n-    /// Same as `to_ascii_lowercase(a) == to_ascii_lowercase(b)`,\n-    /// but without allocating and copying temporaries.\n-    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n-    #[inline]\n-    pub fn eq_ignore_ascii_case(&self, other: &[u8]) -> bool {\n-        self.len() == other.len() && self.iter().zip(other).all(|(a, b)| a.eq_ignore_ascii_case(b))\n-    }\n-\n-    /// Converts this slice to its ASCII upper case equivalent in-place.\n-    ///\n-    /// ASCII letters 'a' to 'z' are mapped to 'A' to 'Z',\n-    /// but non-ASCII letters are unchanged.\n-    ///\n-    /// To return a new uppercased value without modifying the existing one, use\n-    /// [`to_ascii_uppercase`].\n-    ///\n-    /// [`to_ascii_uppercase`]: #method.to_ascii_uppercase\n-    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n-    #[inline]\n-    pub fn make_ascii_uppercase(&mut self) {\n-        for byte in self {\n-            byte.make_ascii_uppercase();\n-        }\n-    }\n-\n-    /// Converts this slice to its ASCII lower case equivalent in-place.\n-    ///\n-    /// ASCII letters 'A' to 'Z' are mapped to 'a' to 'z',\n-    /// but non-ASCII letters are unchanged.\n-    ///\n-    /// To return a new lowercased value without modifying the existing one, use\n-    /// [`to_ascii_lowercase`].\n-    ///\n-    /// [`to_ascii_lowercase`]: #method.to_ascii_lowercase\n-    #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n-    #[inline]\n-    pub fn make_ascii_lowercase(&mut self) {\n-        for byte in self {\n-            byte.make_ascii_lowercase();\n-        }\n-    }\n-}\n-\n-/// Returns `true` if any byte in the word `v` is nonascii (>= 128). Snarfed\n-/// from `../str/mod.rs`, which does something similar for utf8 validation.\n-#[inline]\n-fn contains_nonascii(v: usize) -> bool {\n-    const NONASCII_MASK: usize = 0x80808080_80808080u64 as usize;\n-    (NONASCII_MASK & v) != 0\n-}\n-\n-/// Optimized ASCII test that will use usize-at-a-time operations instead of\n-/// byte-at-a-time operations (when possible).\n-///\n-/// The algorithm we use here is pretty simple. If `s` is too short, we just\n-/// check each byte and be done with it. Otherwise:\n-///\n-/// - Read the first word with an unaligned load.\n-/// - Align the pointer, read subsequent words until end with aligned loads.\n-/// - Read the last `usize` from `s` with an unaligned load.\n-///\n-/// If any of these loads produces something for which `contains_nonascii`\n-/// (above) returns true, then we know the answer is false.\n-#[inline]\n-fn is_ascii(s: &[u8]) -> bool {\n-    const USIZE_SIZE: usize = mem::size_of::<usize>();\n-\n-    let len = s.len();\n-    let align_offset = s.as_ptr().align_offset(USIZE_SIZE);\n-\n-    // If we wouldn't gain anything from the word-at-a-time implementation, fall\n-    // back to a scalar loop.\n-    //\n-    // We also do this for architectures where `size_of::<usize>()` isn't\n-    // sufficient alignment for `usize`, because it's a weird edge case.\n-    if len < USIZE_SIZE || len < align_offset || USIZE_SIZE < mem::align_of::<usize>() {\n-        return s.iter().all(|b| b.is_ascii());\n-    }\n-\n-    // We always read the first word unaligned, which means `align_offset` is\n-    // 0, we'd read the same value again for the aligned read.\n-    let offset_to_aligned = if align_offset == 0 { USIZE_SIZE } else { align_offset };\n-\n-    let start = s.as_ptr();\n-    // SAFETY: We verify `len < USIZE_SIZE` above.\n-    let first_word = unsafe { (start as *const usize).read_unaligned() };\n-\n-    if contains_nonascii(first_word) {\n-        return false;\n-    }\n-    // We checked this above, somewhat implicitly. Note that `offset_to_aligned`\n-    // is either `align_offset` or `USIZE_SIZE`, both of are explicitly checked\n-    // above.\n-    debug_assert!(offset_to_aligned <= len);\n-\n-    // SAFETY: word_ptr is the (properly aligned) usize ptr we use to read the\n-    // middle chunk of the slice.\n-    let mut word_ptr = unsafe { start.add(offset_to_aligned) as *const usize };\n-\n-    // `byte_pos` is the byte index of `word_ptr`, used for loop end checks.\n-    let mut byte_pos = offset_to_aligned;\n-\n-    // Paranoia check about alignment, since we're about to do a bunch of\n-    // unaligned loads. In practice this should be impossible barring a bug in\n-    // `align_offset` though.\n-    debug_assert_eq!((word_ptr as usize) % mem::align_of::<usize>(), 0);\n-\n-    // Read subsequent words until the last aligned word, excluding the last\n-    // aligned word by itself to be done in tail check later, to ensure that\n-    // tail is always one `usize` at most to extra branch `byte_pos == len`.\n-    while byte_pos < len - USIZE_SIZE {\n-        debug_assert!(\n-            // Sanity check that the read is in bounds\n-            (word_ptr as usize + USIZE_SIZE) <= (start.wrapping_add(len) as usize) &&\n-            // And that our assumptions about `byte_pos` hold.\n-            (word_ptr as usize) - (start as usize) == byte_pos\n-        );\n-\n-        // SAFETY: We know `word_ptr` is properly aligned (because of\n-        // `align_offset`), and we know that we have enough bytes between `word_ptr` and the end\n-        let word = unsafe { word_ptr.read() };\n-        if contains_nonascii(word) {\n-            return false;\n-        }\n-\n-        byte_pos += USIZE_SIZE;\n-        // SAFETY: We know that `byte_pos <= len - USIZE_SIZE`, which means that\n-        // after this `add`, `word_ptr` will be at most one-past-the-end.\n-        word_ptr = unsafe { word_ptr.add(1) };\n-    }\n-\n-    // Sanity check to ensure there really is only one `usize` left. This should\n-    // be guaranteed by our loop condition.\n-    debug_assert!(byte_pos <= len && len - byte_pos <= USIZE_SIZE);\n-\n-    // SAFETY: This relies on `len >= USIZE_SIZE`, which we check at the start.\n-    let last_word = unsafe { (start.add(len - USIZE_SIZE) as *const usize).read_unaligned() };\n-\n-    !contains_nonascii(last_word)\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Common traits\n-////////////////////////////////////////////////////////////////////////////////\n-\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T> Default for &[T] {\n     /// Creates an empty slice."}]}