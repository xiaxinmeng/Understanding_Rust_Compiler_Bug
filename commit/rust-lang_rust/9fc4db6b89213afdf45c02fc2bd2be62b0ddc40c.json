{"sha": "9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjlmYzRkYjZiODkyMTNhZmRmNDVjMDJmYzJiZDJiZTYyYjBkZGM0MGM=", "commit": {"author": {"name": "Brian Anderson", "email": "andersrb@gmail.com", "date": "2011-03-08T02:21:01Z"}, "committer": {"name": "Brian Anderson", "email": "andersrb@gmail.com", "date": "2011-03-08T02:21:01Z"}, "message": "Merge branch 'master' into recursive-elseif\n\nConflicts:\n\n\tsrc/Makefile\n\tsrc/comp/front/ast.rs\n\tsrc/comp/front/parser.rs\n\tsrc/comp/middle/fold.rs\n\tsrc/comp/middle/trans.rs", "tree": {"sha": "6c84574116273f91cbe89abd256b9f809adf97de", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6c84574116273f91cbe89abd256b9f809adf97de"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "html_url": "https://github.com/rust-lang/rust/commit/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3fedb18c0af0bd9fa5e4973936003c0b57e4d3e8", "url": "https://api.github.com/repos/rust-lang/rust/commits/3fedb18c0af0bd9fa5e4973936003c0b57e4d3e8", "html_url": "https://github.com/rust-lang/rust/commit/3fedb18c0af0bd9fa5e4973936003c0b57e4d3e8"}, {"sha": "6ed226c6b3a28f3c10d2176d7dba7e339bf0ab99", "url": "https://api.github.com/repos/rust-lang/rust/commits/6ed226c6b3a28f3c10d2176d7dba7e339bf0ab99", "html_url": "https://github.com/rust-lang/rust/commit/6ed226c6b3a28f3c10d2176d7dba7e339bf0ab99"}], "stats": {"total": 10571, "additions": 8203, "deletions": 2368}, "files": [{"sha": "a6e9935d9fdbac6404af03b138a2e8d1bd999add", "filename": "AUTHORS.txt", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/AUTHORS.txt", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/AUTHORS.txt", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/AUTHORS.txt?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -15,6 +15,7 @@ Jason Orendorff <jorendorff@mozilla.com>\n Jeff Balogh <jbalogh@mozilla.com>\n Jeff Mulzelaar <jmuizelaar@mozilla.com>\n Jeffrey Yasskin <jyasskin@gmail.com>\n+Marijn Haverbeke <marijnh@gmail.com>\n Matt Brubeck <mbrubeck@limpet.net>\n Michael Bebenita <mbebenita@mozilla.com>\n Or Brostovski <tohava@gmail.com>"}, {"sha": "48a639ddcd17f1d562a06a2411507a85dcd38136", "filename": "doc/rust.texi", "status": "modified", "additions": 27, "deletions": 21, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/doc%2Frust.texi", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/doc%2Frust.texi", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/doc%2Frust.texi?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -592,10 +592,12 @@ or interrupted by ignored characters.\n \n Most tokens in Rust follow rules similar to the C family.\n \n-Most tokens (including identifiers, whitespace, keywords, operators and\n-structural symbols) are drawn from the ASCII-compatible range of\n-Unicode. String and character literals, however, may include the full range of\n-Unicode characters.\n+Most tokens (including whitespace, keywords, operators and structural symbols)\n+are drawn from the ASCII-compatible range of Unicode. Identifiers are drawn\n+from Unicode characters specified by the @code{XID_start} and\n+@code{XID_continue} rules given by UAX #31@footnote{Unicode Standard Annex\n+#31: Unicode Identifier and Pattern Syntax}. String and character literals may\n+include the full range of Unicode characters.\n \n @emph{TODO: formalize this section much more}.\n \n@@ -638,18 +640,22 @@ token or a syntactic extension token.  Multi-line comments may be nested.\n @c * Ref.Lex.Ident::             Identifier tokens.\n @cindex Identifier token\n \n-Identifiers follow the pattern of C identifiers: they begin with a\n-@emph{letter} or @emph{underscore}, and continue with any combination of\n-@emph{letters}, @emph{decimal digits} and underscores, and must not be equal\n-to any keyword or reserved token. @xref{Ref.Lex.Key}. @xref{Ref.Lex.Res}.\n+Identifiers follow the rules given by Unicode Standard Annex #31, in the form\n+closed under NFKC normalization, @emph{excluding} those tokens that are\n+otherwise defined as keywords or reserved\n+tokens. @xref{Ref.Lex.Key}. @xref{Ref.Lex.Res}.\n \n-A @emph{letter} is a Unicode character in the ranges U+0061-U+007A and\n-U+0041-U+005A (@code{'a'}-@code{'z'} and @code{'A'}-@code{'Z'}).\n+That is: an identifier starts with any character having derived property\n+@code{XID_Start} and continues with zero or more characters having derived\n+property @code{XID_Continue}; and such an identifier is NFKC-normalized during\n+lexing, such that all subsequent comparison of identifiers is performed on the\n+NFKC-normalized forms.\n \n-An @dfn{underscore} is the character U+005F ('_').\n+@emph{TODO: define relationship between Unicode and Rust versions}.\n \n-A @dfn{decimal digit} is a character in the range U+0030-U+0039\n-(@code{'0'}-@code{'9'}).\n+@footnote{This identifier syntax is a superset of the identifier syntaxes of C\n+and Java, and is modeled on Python PEP #3131, which formed the definition of\n+identifiers in Python 3.0 and later.}\n \n @node       Ref.Lex.Key\n @subsection Ref.Lex.Key\n@@ -1984,22 +1990,22 @@ module system).\n An example of a @code{tag} item and its use:\n @example\n tag animal @{\n-  dog();\n-  cat();\n+  dog;\n+  cat;\n @}\n \n-let animal a = dog();\n-a = cat();\n+let animal a = dog;\n+a = cat;\n @end example\n \n An example of a @emph{recursive} @code{tag} item and its use:\n @example\n tag list[T] @{\n-  nil();\n+  nil;\n   cons(T, @@list[T]);\n @}\n \n-let list[int] a = cons(7, cons(13, nil()));\n+let list[int] a = cons(7, cons(13, nil));\n @end example\n \n \n@@ -3395,9 +3401,9 @@ control enters the block.\n An example of a pattern @code{alt} statement:\n \n @example\n-type list[X] = tag(nil(), cons(X, @@list[X]));\n+type list[X] = tag(nil, cons(X, @@list[X]));\n \n-let list[int] x = cons(10, cons(11, nil()));\n+let list[int] x = cons(10, cons(11, nil));\n \n alt (x) @{\n     case (cons(a, cons(b, _))) @{"}, {"sha": "8855a2d10bae99fb2a2acba9105a8538b8bfbb8c", "filename": "src/Makefile", "status": "modified", "additions": 128, "deletions": 101, "changes": 229, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2FMakefile", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2FMakefile", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FMakefile?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -32,6 +32,19 @@ CFG_RUSTC_FLAGS := -nowarn\n # embedded into the executable, so use a no-op command.\n DSYMUTIL := true\n \n+ifeq ($(CFG_OSTYPE), FreeBSD)\n+  CFG_RUNTIME := librustrt.so\n+  CFG_STDLIB := libstd.so\n+  CFG_GCC_CFLAGS += -fPIC -march=i686 -I/usr/local/include\n+  CFG_GCC_LINK_FLAGS += -shared -fPIC -lpthread -lrt\n+  ifeq ($(CFG_CPUTYPE), x86_64)\n+    CFG_GCC_CFLAGS += -m32\n+    CFG_GCC_LINK_FLAGS += -m32\n+  endif\n+  CFG_NATIVE := 1\n+  CFG_UNIXY := 1\n+endif\n+\n ifeq ($(CFG_OSTYPE), Linux)\n   CFG_RUNTIME := librustrt.so\n   CFG_STDLIB := libstd.so\n@@ -43,13 +56,6 @@ ifeq ($(CFG_OSTYPE), Linux)\n   endif\n   CFG_NATIVE := 1\n   CFG_UNIXY := 1\n-  CFG_VALGRIND := $(shell which valgrind)\n-  ifdef CFG_VALGRIND\n-    CFG_VALGRIND += --leak-check=full \\\n-                    --error-exitcode=1 \\\n-                    --quiet --vex-iropt-level=0 \\\n-                    --suppressions=etc/x86.supp\n-  endif\n endif\n \n ifeq ($(CFG_OSTYPE), Darwin)\n@@ -117,6 +123,13 @@ ifdef CFG_UNIXY\n       CFG_GCC_LINK_FLAGS += -m32\n     endif\n   endif\n+  CFG_VALGRIND := $(shell which valgrind)\n+  ifdef CFG_VALGRIND\n+    CFG_VALGRIND += --leak-check=full \\\n+                    --error-exitcode=1 \\\n+                    --quiet --vex-iropt-level=0 \\\n+                    --suppressions=etc/x86.supp\n+  endif\n endif\n \n ifdef CFG_GCC\n@@ -388,14 +401,15 @@ TASK_XFAILS := test/run-pass/task-comm-8.rs \\\n TEST_XFAILS_BOOT :=  $(TASK_XFAILS) \\\n                     $(NOMINAL_TAG_XFAILS) \\\n                     $(CONST_TAG_XFAILS) \\\n+                    test/run-pass/arith-unsigned.rs \\\n                     test/run-pass/child-outlives-parent.rs \\\n                     test/run-pass/clone-with-exterior.rs \\\n                     test/run-pass/constrained-type.rs \\\n                     test/run-pass/destructor-ordering.rs \\\n                     test/run-pass/obj-as.rs \\\n                     test/run-pass/vec-slice.rs \\\n                     test/run-pass/fn-lval.rs \\\n-                    test/run-pass/generic-recursive-tag.rs \\\n+                    test/run-pass/generic-fn-box.rs \\\n                     test/run-pass/generic-tup.rs \\\n                     test/run-pass/iter-ret.rs \\\n                     test/run-pass/lib-io.rs \\\n@@ -414,101 +428,104 @@ TEST_XFAILS_BOOT :=  $(TASK_XFAILS) \\\n                     test/compile-fail/bad-recv.rs \\\n                     test/compile-fail/bad-send.rs \\\n                     test/compile-fail/infinite-vec-type-recursion.rs \\\n+                    test/compile-fail/tail-non-call.rs \\\n                     test/compile-fail/writing-through-read-alias.rs\n \n-# Same strategy here for the time being: just list the ones that\n-# work and assume the others don't. Invert this when we're closer\n-# to actually bootstrapping.\n-\n-TEST_XFAILS_RUSTC := $(filter-out \\\n-                      $(addprefix test/run-pass/, \\\n-                        alt-path.rs \\\n-                        alt-pattern-simple.rs \\\n-                        alt-tag.rs \\\n-                        arith-0.rs \\\n-                        arith-1.rs \\\n-                        arith-2.rs \\\n-                        autoderef-full-lval.rs \\\n-                        bind-exterior.rs \\\n-                        bind-interior.rs \\\n-                        bind-thunk.rs \\\n-                        bind-trivial.rs \\\n-                        bitwise.rs \\\n-                        bool-not.rs \\\n-                        box.rs \\\n-                        box-in-tup.rs \\\n-                        cast.rs \\\n-                        char.rs \\\n-                        complex.rs \\\n-                        const.rs \\\n-                        dead-code-one-arm-if.rs \\\n-                        deep.rs \\\n-                        deref.rs \\\n-                        div-mod.rs \\\n-                        drop-bind-thunk-args.rs \\\n-                        drop-on-ret.rs \\\n-                        else-if.rs \\\n-                        fact.rs \\\n-                        fn-lval.rs \\\n-                        fun-call-variants.rs \\\n-                        fun-indirect-call.rs \\\n-                        generic-fn.rs \\\n-                        generic-fn-infer.rs \\\n-                        generic-drop-glue.rs \\\n-                        generic-tup.rs \\\n-                        generic-type.rs \\\n-                        hello.rs \\\n-                        int.rs \\\n-                        i32-sub.rs \\\n-                        i8-incr.rs \\\n-                        import2.rs \\\n-                        import3.rs \\\n-                        import4.rs \\\n-                        import5.rs \\\n-                        import6.rs \\\n-                        import7.rs \\\n-                        import8.rs \\\n-                        item-name-overload.rs \\\n-                        large-records.rs \\\n-                        lazy-init.rs \\\n-                        lazy-and-or.rs \\\n-                        leak-box-as-tydesc.rs \\\n-                        linear-for-loop.rs \\\n-                        multiline-comment.rs \\\n-                        mutual-recursion-group.rs \\\n-                        obj-drop.rs \\\n-                        obj-recursion.rs \\\n-                        obj-with-vec.rs \\\n-                        operator-associativity.rs \\\n-                        opeq.rs \\\n-                        output-slot-variants.rs \\\n-                        over-constrained-vregs.rs \\\n-                        readalias.rs \\\n-                        rec.rs \\\n-                        rec-auto.rs \\\n-                        rec-tup.rs \\\n-                        return-nil.rs \\\n-                        simple-obj.rs \\\n-                        stateful-obj.rs \\\n-                        str-idx.rs \\\n-                        type-in-nested-module.rs \\\n-                        type-param.rs \\\n-                        tup.rs \\\n-                        u32-decr.rs \\\n-                        u8-incr.rs \\\n-                        u8-incr-decr.rs \\\n-                        uint.rs \\\n-                        unit.rs \\\n-                        use.rs \\\n-                        tag.rs \\\n-                        vec.rs \\\n-                        vec-drop.rs \\\n-                        vec-in-tup.rs \\\n-                        vec-late-init.rs \\\n-                        while-and-do-while.rs \\\n-                        while-flow-graph.rs \\\n-                        writealias.rs \\\n+TEST_XFAILS_RUSTC := $(addprefix test/run-pass/, \\\n+                        acyclic-unwind.rs \\\n+                        alt-pattern-drop.rs \\\n+                        alt-type-simple.rs \\\n+                        append-units.rs \\\n+                        basic-1.rs \\\n+                        basic-2.rs \\\n+                        basic.rs \\\n+                        bind-obj-ctor.rs \\\n+                        child-outlives-parent.rs \\\n+                        clone-with-exterior.rs \\\n+                        comm.rs \\\n+                        constrained-type.rs \\\n+                        destructor-ordering.rs \\\n+                        drop-parametric-closure-with-bound-box.rs \\\n+                        export-non-interference.rs \\\n+                        foreach-nested-2.rs \\\n+                        foreach-nested.rs \\\n+                        foreach-put-structured.rs \\\n+                        foreach-simple-outer-slot.rs \\\n+                        generic-fn-twice.rs \\\n+                        generic-iter-frame.rs \\\n+                        generic-recursive-tag.rs \\\n+                        generic-tag-alt.rs \\\n+                        generic-tag-values.rs \\\n+                        iter-range.rs \\\n+                        iter-ret.rs \\\n+                        lazychan.rs \\\n+                        lib-bitv.rs \\\n+                        lib-deque.rs \\\n+                        lib-int.rs \\\n+                        lib-io.rs \\\n+                        lib-map.rs \\\n+                        lib-rand.rs \\\n+                        lib-sha1.rs \\\n+                        lib-sort.rs \\\n+                        lib-str.rs \\\n+                        lib-task.rs \\\n+                        lib-uint.rs \\\n+                        lib-vec-str-conversions.rs \\\n+                        lib-vec.rs \\\n+                        many.rs \\\n+                        mlist-cycle.rs \\\n+                        mlist.rs \\\n+                        mutable-alias-vec.rs \\\n+                        obj-as.rs \\\n+                        obj-dtor.rs \\\n+                        obj-return-polytypes.rs \\\n+                        pred.rs \\\n+                        preempt.rs \\\n+                        rt-circular-buffer.rs \\\n+                        size-and-align.rs \\\n+                        spawn-fn.rs \\\n+                        spawn-module-qualified.rs \\\n+                        spawn.rs \\\n+                        str-append.rs \\\n+                        syntax-extension-fmt.rs \\\n+                        syntax-extension-shell.rs \\\n+                        task-comm-0.rs \\\n+                        task-comm-1.rs \\\n+                        task-comm-10.rs \\\n+                        task-comm-11.rs \\\n+                        task-comm-12.rs \\\n+                        task-comm-13-thread.rs \\\n+                        task-comm-13.rs \\\n+                        task-comm-15.rs \\\n+                        task-comm-2.rs \\\n+                        task-comm-3.rs \\\n+                        task-comm-4.rs \\\n+                        task-comm-5.rs \\\n+                        task-comm-6.rs \\\n+                        task-comm-7.rs \\\n+                        task-comm-8.rs \\\n+                        task-comm-9.rs \\\n+                        task-comm.rs \\\n+                        task-killjoin.rs \\\n+                        task-life-0.rs \\\n+                        threads.rs \\\n+                        type-sizes.rs \\\n+                        typestate-cfg-nesting.rs \\\n+                        use-import-export.rs \\\n+                        user.rs \\\n+                        utf8.rs \\\n+                        vec-alloc-append.rs \\\n+                        vec-append.rs \\\n+                        vec-slice.rs \\\n+                        while-prelude-drop.rs \\\n+                        while-with-break.rs \\\n+                        yield.rs \\\n+                        yield2.rs \\\n+                        multi.rc \\\n+                        native-mod.rc \\\n+                        native.rc \\\n                         ) \\\n+                     $(filter-out \\\n                       $(addprefix test/compile-fail/, \\\n                         alt-tag-nullary.rs \\\n                         alt-tag-unary.rs \\\n@@ -517,6 +534,7 @@ TEST_XFAILS_RUSTC := $(filter-out \\\n                         bad-expr-path.rs \\\n                         bad-expr-path2.rs \\\n                         bogus-tag.rs \\\n+                        fru-extra-field.rs \\\n                         import.rs \\\n                         import2.rs \\\n                         import3.rs \\\n@@ -526,11 +544,20 @@ TEST_XFAILS_RUSTC := $(filter-out \\\n                         multiline-comment-line-tracking.rs \\\n                         output-type-mismatch.rs \\\n                         rec-missing-fields.rs \\\n+                        reserved-dec.rs \\\n+                        reserved-f128.rs \\\n+                        reserved-f16.rs \\\n+                        reserved-f80.rs \\\n+                        reserved-m128.rs \\\n+                        reserved-m32.rs \\\n+                        reserved-m64.rs \\\n+                        tail-non-call.rs \\\n+                        tail-typeck.rs \\\n                         type-shadow.rs \\\n                         while-type-error.rs \\\n                         wrong-ret-type.rs \\\n                         ), \\\n-                      $(wildcard test/*/*.rs test/*/*.rc))\n+                      $(wildcard test/*fail/*.rs test/*fail/*.rc))\n \n \n ifdef MINGW_CROSS"}, {"sha": "05d701bd380f693e50b8d66ed171b911dbfa3071", "filename": "src/README", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2FREADME", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2FREADME", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FREADME?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -8,7 +8,6 @@ boot/fe            - Front end (lexer, parser, AST)\n boot/me            - Middle end (resolve, check, layout, trans)\n boot/be            - Back end (IL, RA, insns, asm, objfiles)\n boot/util          - Ubiquitous helpers\n-boot/llvm          - LLVM-based alternative back end\n boot/driver        - Compiler driver\n \n comp/              The self-hosted compiler (\"rustc\": incomplete)"}, {"sha": "89e308bfab971c2d4360814a25ebe2ff06cf9727", "filename": "src/boot/be/abi.ml", "status": "modified", "additions": 22, "deletions": 12, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fbe%2Fabi.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fbe%2Fabi.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fbe%2Fabi.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -110,23 +110,33 @@ let indirect_args_elt_closure = 0;;\n (* Current worst case is by vec grow glue *)\n let worst_case_glue_call_args = 8;;\n \n+(* \n+ * ABI tags used to inform the runtime which sort of frame to set up for new\n+ * spawned functions. FIXME: There is almost certainly a better abstraction to\n+ * use.\n+ *)\n+let abi_x86_rustboot_cdecl = 1;;\n+let abi_x86_rustc_fastcall = 2;;\n+\n type abi =\n-  {\n-    abi_word_sz: int64;\n-    abi_word_bits: Il.bits;\n-    abi_word_ty: Common.ty_mach;\n+    {\n+      abi_word_sz: int64;\n+      abi_word_bits: Il.bits;\n+      abi_word_ty: Common.ty_mach;\n+\n+      abi_tag: int;\n \n-    abi_has_pcrel_data: bool;\n-    abi_has_pcrel_code: bool;\n+      abi_has_pcrel_data: bool;\n+      abi_has_pcrel_code: bool;\n \n-    abi_n_hardregs: int;\n-    abi_str_of_hardreg: (int -> string);\n+      abi_n_hardregs: int;\n+      abi_str_of_hardreg: (int -> string);\n \n-    abi_emit_target_specific: (Il.emitter -> Il.quad -> unit);\n-    abi_constrain_vregs: (Il.quad -> (Il.vreg,Bits.t) Hashtbl.t -> unit);\n+      abi_emit_target_specific: (Il.emitter -> Il.quad -> unit);\n+      abi_constrain_vregs: (Il.quad -> (Il.vreg,Bits.t) Hashtbl.t -> unit);\n \n-    abi_emit_fn_prologue: (Il.emitter\n-                           -> Common.size        (* framesz *)\n+      abi_emit_fn_prologue: (Il.emitter\n+                             -> Common.size        (* framesz *)\n                              -> Common.size      (* callsz  *)\n                                -> Common.nabi\n                                  -> Common.fixup (* grow_task *)"}, {"sha": "99b680427d368fa6c039db20af8112e8e642aefd", "filename": "src/boot/be/elf.ml", "status": "modified", "additions": 81, "deletions": 19, "changes": 100, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fbe%2Felf.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fbe%2Felf.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fbe%2Felf.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -44,7 +44,7 @@ type ei_data =\n ;;\n \n \n-let elf_identification ei_class ei_data =\n+let elf_identification sess ei_class ei_data =\n   SEQ\n     [|\n       STRING \"\\x7fELF\";\n@@ -58,9 +58,16 @@ let elf_identification ei_class ei_data =\n                ELFDATANONE -> 0\n              | ELFDATA2LSB -> 1\n              | ELFDATA2MSB -> 2);\n+\n           1;                    (* EI_VERSION = EV_CURRENT *)\n-          0;                    (* EI_PAD #7 *)\n-          0;                    (* EI_PAD #8 *)\n+\n+                                (* EI_OSABI *)\n+          (match sess.Session.sess_targ with\n+               FreeBSD_x86_elf -> 9\n+             | _ -> 0);\n+\n+          0;                    (* EI_ABIVERSION *)\n+\n           0;                    (* EI_PAD #9 *)\n           0;                    (* EI_PAD #A *)\n           0;                    (* EI_PAD #B *)\n@@ -117,7 +124,7 @@ let elf32_header\n   in\n     DEF\n       (elf_header_fixup,\n-       SEQ [| elf_identification ELFCLASS32 ei_data;\n+       SEQ [| elf_identification sess ELFCLASS32 ei_data;\n               WORD (TY_u16, (IMM (match e_type with\n                                       ET_NONE -> 0L\n                                     | ET_REL -> 1L\n@@ -480,6 +487,7 @@ let elf32_linux_x86_file\n     ~(entry_name:string)\n     ~(text_frags:(string option, frag) Hashtbl.t)\n     ~(data_frags:(string option, frag) Hashtbl.t)\n+    ~(bss_frags:(string option, frag) Hashtbl.t)\n     ~(rodata_frags:(string option, frag) Hashtbl.t)\n     ~(required_fixups:(string, fixup) Hashtbl.t)\n     ~(dwarf:Dwarf.debug_records)\n@@ -644,7 +652,7 @@ let elf32_linux_x86_file\n   (* let gotpltndx      = 8L in *)  (* Section index of .got.plt *)\n   (* let relapltndx     = 9L in *)  (* Section index of .rela.plt *)\n   let datandx        = 10L in  (* Section index of .data *)\n-  (* let bssndx         = 11L in *) (* Section index of .bss *)\n+  let bssndx         = 11L in  (* Section index of .bss *)\n   (* let dynamicndx     = 12L in *) (* Section index of .dynamic *)\n   let shstrtabndx    = 13L in (* Section index of .shstrtab *)\n \n@@ -991,6 +999,22 @@ let elf32_linux_x86_file\n       (strtab_entry, symtab_entry)\n   in\n \n+  let bss_sym name st_bind fixup =\n+    let name_fixup = new_fixup (\"bss symbol name fixup: '\" ^ name ^ \"'\") in\n+    let strtab_entry = DEF (name_fixup, ZSTRING name) in\n+    let symtab_entry =\n+      symbol\n+        ~string_table_fixup: dynstr_section_fixup\n+        ~name_string_fixup: name_fixup\n+        ~sym_target_fixup: (Some fixup)\n+        ~st_bind\n+        ~st_type: STT_OBJECT\n+        ~st_shndx: bssndx\n+    in\n+      incr n_syms;\n+      (strtab_entry, symtab_entry)\n+  in\n+\n   let rodata_sym name st_bind fixup =\n     let name_fixup = new_fixup (\"rodata symbol name fixup: '\" ^ name ^ \"'\") in\n     let strtab_entry = DEF (name_fixup, ZSTRING name) in\n@@ -1212,6 +1236,12 @@ let elf32_linux_x86_file\n     Hashtbl.fold (frags_of_symbol data_sym STB_GLOBAL) data_frags ([],[],[])\n   in\n \n+  let (bss_strtab_frags,\n+       bss_symtab_frags,\n+       bss_body_frags) =\n+    Hashtbl.fold (frags_of_symbol bss_sym STB_GLOBAL) bss_frags ([],[],[])\n+  in\n+\n   let (_,\n        require_strtab_frags,\n        require_symtab_frags,\n@@ -1277,7 +1307,8 @@ let elf32_linux_x86_file\n                            global_text_symtab_frags @\n                            local_text_symtab_frags @\n                            rodata_symtab_frags @\n-                           data_symtab_frags))\n+                           data_symtab_frags @\n+                           bss_symtab_frags))\n   in\n \n   let dynstr_frags = (null_strtab_frag ::\n@@ -1286,11 +1317,16 @@ let elf32_linux_x86_file\n                            local_text_strtab_frags @\n                            rodata_strtab_frags @\n                            data_strtab_frags @\n+                           bss_strtab_frags @\n                            (Array.to_list dynamic_needed_strtab_frags)))\n   in\n \n   let interp_section =\n-    DEF (interp_section_fixup, ZSTRING \"/lib/ld-linux.so.2\")\n+\n+    DEF (interp_section_fixup, ZSTRING\n+           (if sess.Session.sess_targ = FreeBSD_x86_elf\n+            then \"/libexec/ld-elf.so.1\"\n+            else \"/lib/ld-linux.so.2\"))\n   in\n \n   let text_section =\n@@ -1307,7 +1343,7 @@ let elf32_linux_x86_file\n   in\n   let bss_section =\n     DEF (bss_section_fixup,\n-         SEQ [| |])\n+         SEQ (Array.of_list bss_body_frags))\n   in\n   let dynsym_section =\n     DEF (dynsym_section_fixup,\n@@ -1486,6 +1522,7 @@ let emit_file\n   let text_frags = Hashtbl.create 4 in\n   let rodata_frags = Hashtbl.create 4 in\n   let data_frags = Hashtbl.create 4 in\n+  let bss_frags = Hashtbl.create 4 in\n   let required_fixups = Hashtbl.create 4 in\n \n   (*\n@@ -1584,7 +1621,9 @@ let emit_file\n \n   let needed_libs =\n     [|\n-      \"libc.so.6\";\n+      if sess.Session.sess_targ = FreeBSD_x86_elf\n+      then \"libc.so.7\"\n+      else \"libc.so.6\";\n       \"librustrt.so\"\n     |]\n   in\n@@ -1604,6 +1643,27 @@ let emit_file\n     htab_put text_frags None code;\n     htab_put rodata_frags None data;\n \n+    if sess.Session.sess_targ = FreeBSD_x86_elf\n+    then\n+      (* \n+       * FreeBSD wants some extra symbols in .bss so its libc can fill\n+       * them in, I think.\n+       *)\n+      List.iter\n+        (fun x -> htab_put bss_frags (Some x) (WORD (TY_u32, (IMM 0L))))\n+        [\n+          \"environ\";\n+          \"optind\";\n+          \"optarg\";\n+          \"_CurrentRuneLocale\";\n+          \"__stack_chk_guard\";\n+          \"__mb_sb_limit\";\n+          \"__isthreaded\";\n+          \"__stdinp\";\n+          \"__stderrp\";\n+          \"__stdoutp\";\n+        ];\n+\n     Hashtbl.iter\n       begin\n         fun _ tab ->\n@@ -1616,13 +1676,15 @@ let emit_file\n       end\n       sem.Semant.ctxt_native_required\n   in\n+\n   let all_frags =\n     elf32_linux_x86_file\n       ~sess\n       ~crate\n       ~entry_name: \"_start\"\n       ~text_frags\n       ~data_frags\n+      ~bss_frags\n       ~dwarf\n       ~sem\n       ~rodata_frags\n@@ -1640,16 +1702,16 @@ let sniff\n     : asm_reader option =\n   try\n     let stat = Unix.stat filename in\n-    if (stat.Unix.st_kind = Unix.S_REG) &&\n-      (stat.Unix.st_size > 4)\n-    then\n-      let ar = new_asm_reader sess filename in\n-      let _ = log sess \"sniffing ELF file\" in\n-        if (ar.asm_get_zstr_padded 4) = elf_magic\n-        then (ar.asm_seek 0; Some ar)\n-        else None\n-    else\n-      None\n+      if (stat.Unix.st_kind = Unix.S_REG) &&\n+        (stat.Unix.st_size > 4)\n+      then\n+        let ar = new_asm_reader sess filename in\n+        let _ = log sess \"sniffing ELF file\" in\n+          if (ar.asm_get_zstr_padded 4) = elf_magic\n+          then (ar.asm_seek 0; Some ar)\n+          else None\n+      else\n+        None\n   with\n       _ -> None\n ;;"}, {"sha": "49b660be5aef718d0a9ba0ef9e79211fa430cae5", "filename": "src/boot/be/x86.ml", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fbe%2Fx86.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fbe%2Fx86.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fbe%2Fx86.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1851,6 +1851,8 @@ let (abi:Abi.abi) =\n     Abi.abi_word_bits = word_bits;\n     Abi.abi_word_ty = word_ty;\n \n+    Abi.abi_tag = Abi.abi_x86_rustboot_cdecl;\n+\n     Abi.abi_has_pcrel_data = false;\n     Abi.abi_has_pcrel_code = true;\n "}, {"sha": "00b1b8341f517af5bc8495701dc71eb0b03b7874", "filename": "src/boot/driver/lib.ml", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fdriver%2Flib.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fdriver%2Flib.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fdriver%2Flib.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -249,6 +249,7 @@ let get_ar\n               Win32_x86_pe -> Pe.sniff\n             | MacOS_x86_macho -> Macho.sniff\n             | Linux_x86_elf -> Elf.sniff\n+            | FreeBSD_x86_elf -> Elf.sniff\n         in\n           sniff sess filename\n     end\n@@ -270,6 +271,7 @@ let get_sects\n                     Win32_x86_pe -> Pe.get_sections\n                   | MacOS_x86_macho -> Macho.get_sections\n                   | Linux_x86_elf -> Elf.get_sections\n+                  | FreeBSD_x86_elf -> Elf.get_sections\n               in\n                 Some (ar, (get_sections sess ar))\n     end\n@@ -350,6 +352,7 @@ let get_mod\n         Win32_x86_pe -> \".dll\"\n       | MacOS_x86_macho -> \".dylib\"\n       | Linux_x86_elf -> \".so\"\n+      | FreeBSD_x86_elf -> \".so\"\n   in\n   let rec meta_matches i f_meta =\n     if i >= (Array.length meta)\n@@ -447,6 +450,7 @@ let infer_lib_name\n       Win32_x86_pe -> ident ^ \".dll\"\n     | MacOS_x86_macho -> \"lib\" ^ ident ^ \".dylib\"\n     | Linux_x86_elf -> \"lib\" ^ ident ^ \".so\"\n+    | FreeBSD_x86_elf -> \"lib\" ^ ident ^ \".so\"\n ;;\n \n "}, {"sha": "9705f1ee7b11076baefc4cb5500b43272f4fd386", "filename": "src/boot/driver/main.ml", "status": "modified", "additions": 23, "deletions": 6, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fdriver%2Fmain.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fdriver%2Fmain.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fdriver%2Fmain.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -8,12 +8,21 @@ let _ =\n \n let (targ:Common.target) =\n   match Sys.os_type with\n-      \"Unix\" when Unix.system \"test `uname -s` = 'Darwin'\" = Unix.WEXITED 0 ->\n-        MacOS_x86_macho\n-    | \"Unix\" -> Linux_x86_elf\n-    | \"Win32\" -> Win32_x86_pe\n+\n+    | \"Win32\"\n     | \"Cygwin\" -> Win32_x86_pe\n-    | _ -> Linux_x86_elf\n+\n+    | \"Unix\"\n+        when Unix.system \"test `uname -s` = 'Linux'\" = Unix.WEXITED 0 ->\n+        Linux_x86_elf\n+    | \"Unix\"\n+        when Unix.system \"test `uname -s` = 'Darwin'\" = Unix.WEXITED 0 ->\n+        MacOS_x86_macho\n+    | \"Unix\"\n+        when Unix.system \"test `uname -s` = 'FreeBSD'\" = Unix.WEXITED 0 ->\n+        FreeBSD_x86_elf\n+    | _ ->\n+        Linux_x86_elf\n ;;\n \n let (abi:Abi.abi) = X86.abi;;\n@@ -96,6 +105,7 @@ let default_output_filename (sess:Session.sess) : filename option =\n           else\n             base ^ (match sess.Session.sess_targ with\n                         Linux_x86_elf -> \"\"\n+                      | FreeBSD_x86_elf -> \"\"\n                       | MacOS_x86_macho -> \"\"\n                       | Win32_x86_pe -> \".exe\")\n         in\n@@ -144,16 +154,21 @@ let flag f opt desc =\n \n let argspecs =\n   [\n-    (\"-t\", Arg.Symbol ([\"linux-x86-elf\"; \"win32-x86-pe\"; \"macos-x86-macho\"],\n+    (\"-t\", Arg.Symbol ([\"linux-x86-elf\";\n+                        \"win32-x86-pe\";\n+                        \"macos-x86-macho\";\n+                        \"freebsd-x86-elf\"],\n                        fun s -> (sess.Session.sess_targ <-\n                                    (match s with\n                                         \"win32-x86-pe\" -> Win32_x86_pe\n                                       | \"macos-x86-macho\" -> MacOS_x86_macho\n+                                      | \"freebsd-x86-elf\" -> FreeBSD_x86_elf\n                                       | _ -> Linux_x86_elf))),\n      (\" target (default: \" ^ (match sess.Session.sess_targ with\n                                   Win32_x86_pe -> \"win32-x86-pe\"\n                                 | Linux_x86_elf -> \"linux-x86-elf\"\n                                 | MacOS_x86_macho -> \"macos-x86-macho\"\n+                                | FreeBSD_x86_elf -> \"freebsd-x86-elf\"\n                              ) ^ \")\"));\n     (\"-o\", Arg.String (fun s -> sess.Session.sess_out <- Some s),\n      \"file to output (default: \"\n@@ -320,6 +335,7 @@ let parse_input_crate\n             let depfile =\n               match sess.Session.sess_targ with\n                   Linux_x86_elf\n+                | FreeBSD_x86_elf\n                 | MacOS_x86_macho -> outfile ^ \".d\"\n                 | Win32_x86_pe -> (Filename.chop_extension outfile) ^ \".d\"\n             in\n@@ -473,6 +489,7 @@ let main_pipeline _ =\n               Win32_x86_pe -> Pe.emit_file\n             | MacOS_x86_macho -> Macho.emit_file\n             | Linux_x86_elf -> Elf.emit_file\n+            | FreeBSD_x86_elf -> Elf.emit_file\n         in\n           Session.time_inner \"emit\" sess\n             (fun _ -> emitter sess crate code data sem_cx dwarf);"}, {"sha": "0f216fc2993704a224ca41377a095dde814433d4", "filename": "src/boot/fe/cexp.ml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Ffe%2Fcexp.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Ffe%2Fcexp.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Ffe%2Fcexp.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -628,6 +628,7 @@ let parse_crate_file\n     let (os, arch, libc) =\n       match sess.Session.sess_targ with\n           Linux_x86_elf -> (\"linux\", \"x86\", \"libc.so.6\")\n+        | FreeBSD_x86_elf -> (\"freebsd\", \"x86\", \"libc.so.7\")\n         | Win32_x86_pe -> (\"win32\", \"x86\", \"msvcrt.dll\")\n         | MacOS_x86_macho -> (\"macos\", \"x86\", \"libc.dylib\")\n     in"}, {"sha": "bbf49e83b3d9bd116fe6f3d672fc65035f503c71", "filename": "src/boot/me/trans.ml", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fme%2Ftrans.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fme%2Ftrans.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fme%2Ftrans.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -2727,6 +2727,7 @@ let trans_visitor\n                   [|\n                     Il.Cell new_task;\n                     exit_task_glue_fptr;\n+                     (imm (Int64.of_int abi.Abi.abi_tag));\n                     fptr_operand;\n                     callsz\n                   |];\n@@ -2739,6 +2740,7 @@ let trans_visitor\n                    [|\n                      Il.Cell new_task;\n                      exit_task_glue_fptr;\n+                     (imm (Int64.of_int abi.Abi.abi_tag));\n                      fptr_operand;\n                      callsz\n                    |];\n@@ -6183,6 +6185,8 @@ let trans_visitor\n             tab_sz cx.ctxt_required_rust_sym_num;\n             tab_sz cx.ctxt_required_c_sym_num;\n             tab_sz cx.ctxt_required_lib_num;\n+\n+            Asm.WORD (word_ty_mach, Asm.IMM (Int64.of_int abi.Abi.abi_tag));\n           |]))\n     in\n "}, {"sha": "8b7840a2837d9ef06d5c27bf1d2f054c5294afd7", "filename": "src/boot/me/typestate.ml", "status": "modified", "additions": 109, "deletions": 248, "changes": 357, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fme%2Ftypestate.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Fme%2Ftypestate.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Fme%2Ftypestate.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -24,7 +24,6 @@ type typestate_tables =\n       ts_prestates: (node_id,Bits.t) Hashtbl.t;\n       ts_poststates: (node_id,Bits.t) Hashtbl.t;\n       ts_graph: node_graph;\n-      ts_siblings: sibling_map;\n       ts_stmts: Ast.stmt Stack.t;\n       ts_maxid: int ref;\n     }\n@@ -38,7 +37,6 @@ let new_tables _ =\n     ts_poststates = Hashtbl.create 0;\n     ts_prestates = Hashtbl.create 0;\n     ts_graph = Hashtbl.create 0;\n-    ts_siblings = Hashtbl.create 0;\n     ts_stmts = Stack.create ();\n     ts_maxid = ref 0 }\n ;;\n@@ -790,279 +788,148 @@ let show_node cx graph s i =\n          s (int_of_node i) (lset_fmt (Hashtbl.find graph i)))\n ;;\n \n-let graph_sequence_building_visitor\n-    (cx:ctxt)\n-    (tables_stack:typestate_tables Stack.t)\n-    (inner:Walk.visitor)\n-    : Walk.visitor =\n+let add_flow_edges (graph:node_graph) (n:node_id) (dsts:node_id list) : unit =\n+  if Hashtbl.mem graph n\n+  then\n+    let existing = Hashtbl.find graph n in\n+      Hashtbl.replace graph n (lset_union existing dsts)\n+  else\n+    Hashtbl.add graph n dsts\n+;;\n \n-  let tables _ = Stack.top tables_stack in\n+let rec build_flow_graph_for_stmt\n+    (graph:node_graph)\n+    (predecessors:node_id list)\n+    (s:Ast.stmt)\n+    : node_id list =\n \n-  (* Flow each stmt to its sequence-successor. *)\n-  let visit_stmts stmts =\n-    let ts = tables () in\n-    let graph = ts.ts_graph in\n-    let sibs = ts.ts_siblings in\n-    let len = Array.length stmts in\n-      for i = 0 to len - 2\n-      do\n-        let stmt = stmts.(i) in\n-        let next = stmts.(i+1) in\n-          log cx \"sequential stmt edge %d -> %d\"\n-            (int_of_node stmt.id) (int_of_node next.id);\n-          htab_put graph stmt.id [next.id];\n-          htab_put sibs stmt.id next.id;\n-      done;\n-      (* Flow last node to nowhere. *)\n-      if len > 0\n-      then htab_put graph stmts.(len-1).id []\n+  let connect ps qs =\n+    List.iter\n+      (fun pred -> add_flow_edges graph pred qs)\n+      ps\n   in\n \n-  let visit_stmt_pre s =\n-    (* Sequence the prelude nodes on special stmts. *)\n-    begin\n-      match s.node with\n-          Ast.STMT_while sw ->\n-            let (stmts, _) = sw.Ast.while_lval in\n-              visit_stmts stmts\n-        | _ -> ()\n-    end;\n-    inner.Walk.visit_stmt_pre s\n+  let seq ps (ss:Ast.stmt array) =\n+    build_flow_graph_for_stmts graph ps ss\n   in\n \n-  let visit_block_pre b =\n-    visit_stmts b.node;\n-    inner.Walk.visit_block_pre b\n+  let blk ps b =\n+    connect ps [b.id];\n+    seq [b.id] b.node\n   in\n \n-    { inner with\n-        Walk.visit_stmt_pre = visit_stmt_pre;\n-        Walk.visit_block_pre = visit_block_pre }\n-;;\n-\n-let add_flow_edges (graph:node_graph) (n:node_id) (dsts:node_id list) : unit =\n-  let existing = Hashtbl.find graph n in\n-    Hashtbl.replace graph n (lset_union existing dsts)\n-;;\n+  let first ss =\n+    if Array.length ss = 0\n+    then []\n+    else [ss.(0).id]\n+  in\n \n-let remove_flow_edges\n-    (graph:node_graph)\n-    (n:node_id)\n-    (dsts:node_id list)\n-    : unit =\n-  let existing = Hashtbl.find graph n in\n-    Hashtbl.replace graph n (lset_diff existing dsts)\n-;;\n+    connect [s.id] [];\n+    let outs =\n+      match s.node with\n \n+        | Ast.STMT_while sw ->\n+            let (pre_loop_stmts, _) = sw.Ast.while_lval in\n+            let body = sw.Ast.while_body in\n+            let preloop_end = seq [s.id] pre_loop_stmts in\n+              connect predecessors [s.id];\n+              connect (blk preloop_end body) (first pre_loop_stmts);\n+              preloop_end\n+\n+        | Ast.STMT_for sf ->\n+            let body_end = blk [s.id] sf.Ast.for_body in\n+              connect predecessors [s.id];\n+              connect body_end (first sf.Ast.for_body.node);\n+              body_end\n+\n+        | Ast.STMT_for_each sfe ->\n+            let head_end = blk [s.id] sfe.Ast.for_each_head in\n+            let body_end = blk head_end sfe.Ast.for_each_body in\n+              connect predecessors [s.id];\n+              connect body_end (first sfe.Ast.for_each_head.node);\n+              body_end\n+\n+        | Ast.STMT_if sif ->\n+            connect predecessors [s.id];\n+            (blk [s.id] sif.Ast.if_then) @\n+              (match sif.Ast.if_else with\n+                   None -> [s.id]\n+                 | Some els -> blk [s.id] els)\n+\n+        | Ast.STMT_alt_tag sat ->\n+            connect predecessors [s.id];\n+            Array.fold_left\n+              (fun ends {node=(_, b); id=_} -> (blk [s.id] b) @ ends)\n+              [] sat.Ast.alt_tag_arms\n+\n+        | Ast.STMT_block b ->\n+            blk predecessors b\n+\n+        | Ast.STMT_fail\n+        | Ast.STMT_ret _ ->\n+            connect predecessors [s.id];\n+            []\n+\n+        | _ ->\n+            connect predecessors [s.id];\n+            [s.id]\n+    in\n+      connect outs [];\n+      outs\n \n-let last_id (nodes:('a identified) array) : node_id =\n-  let len = Array.length nodes in\n-    nodes.(len-1).id\n+and build_flow_graph_for_stmts\n+    (graph:node_graph)\n+    (predecessors:node_id list)\n+    (ss:Ast.stmt array)\n+    : node_id list =\n+  Array.fold_left (build_flow_graph_for_stmt graph) predecessors ss\n ;;\n \n-let last_id_or_block_id (block:Ast.block) : node_id =\n-  let len = Array.length block.node in\n-    if len = 0\n-    then block.id\n-    else last_id block.node\n-;;\n \n-let graph_general_block_structure_building_visitor\n+let graph_building_visitor\n     (cx:ctxt)\n     (tables_stack:typestate_tables Stack.t)\n     (inner:Walk.visitor)\n     : Walk.visitor =\n \n   let tables _ = Stack.top tables_stack in\n+  let graph _ = (tables()).ts_graph in\n+  let blk b =\n+    add_flow_edges (graph()) b.id [];\n+    ignore (build_flow_graph_for_stmts (graph()) [b.id] b.node)\n+  in\n \n-  let visit_stmt_pre s =\n-    let ts = tables () in\n-    let stmts = ts.ts_stmts in\n-      Stack.push s stmts;\n-      inner.Walk.visit_stmt_pre s\n+  let visit_mod_item_pre n p i =\n+    begin\n+      match i.node.Ast.decl_item with\n+          Ast.MOD_ITEM_fn fn -> blk fn.Ast.fn_body\n+        | _ -> ()\n+    end;\n+    inner.Walk.visit_mod_item_pre n p i\n   in\n \n-  let visit_stmt_post s =\n-    let ts = tables () in\n-    let stmts = ts.ts_stmts in\n-      inner.Walk.visit_stmt_post s;\n-      ignore (Stack.pop stmts)\n+  let visit_obj_fn_pre obj ident fn =\n+    blk fn.node.Ast.fn_body;\n+    inner.Walk.visit_obj_fn_pre obj ident fn\n   in\n \n-  let show_node =\n-    fun n id -> show_node cx (tables()).ts_graph n id\n+  let visit_obj_drop_pre obj b =\n+    blk b;\n+    inner.Walk.visit_obj_drop_pre obj b\n   in\n \n   let visit_block_pre b =\n-    begin\n-      let ts = tables () in\n-      let graph = ts.ts_graph in\n-      let sibs = ts.ts_siblings in\n-      let stmts = ts.ts_stmts in\n-      let len = Array.length b.node in\n-      let _ = htab_put graph b.id\n-        (if len > 0 then [b.node.(0).id] else [])\n-      in\n-\n-      (*\n-       * If block has len, \n-       * then flow block to block.node.(0) and block.node.(len-1) to dsts\n-       * else flow block to dsts\n-       * \n-       * so AST:\n-       * \n-       *   block#n{ stmt#0 ... stmt#k };\n-       *   stmt#j;\n-       * \n-       * turns into graph:\n-       * \n-       *   block#n -> stmt#0 -> ... -> stmt#k -> stmt#j\n-       * \n-       *)\n-        if Stack.is_empty stmts\n-        then ()\n-        else\n-          let s = Stack.top stmts in\n-            add_flow_edges graph s.id [b.id];\n-            match htab_search sibs s.id with\n-                None -> ()\n-              | Some sib_id ->\n-                  if len > 0\n-                  then\n-                    add_flow_edges graph (last_id b.node) [sib_id]\n-                  else\n-                    add_flow_edges graph b.id [sib_id]\n-    end;\n-    show_node \"block\" b.id;\n+    if Hashtbl.mem cx.ctxt_block_is_loop_body b.id\n+    then blk b;\n     inner.Walk.visit_block_pre b\n   in\n \n     { inner with\n-        Walk.visit_stmt_pre = visit_stmt_pre;\n-        Walk.visit_stmt_post = visit_stmt_post;\n+        Walk.visit_mod_item_pre = visit_mod_item_pre;\n+        Walk.visit_obj_fn_pre = visit_obj_fn_pre;\n+        Walk.visit_obj_drop_pre = visit_obj_drop_pre;\n         Walk.visit_block_pre = visit_block_pre }\n-;;\n-\n-\n-let graph_special_block_structure_building_visitor\n-    (cx:ctxt)\n-    (tables_stack:typestate_tables Stack.t)\n-    (inner:Walk.visitor)\n-    : Walk.visitor =\n \n-  let tables _ = Stack.top tables_stack in\n-\n-  let visit_stmt_pre s =\n-    begin\n-      match s.node with\n-\n-          Ast.STMT_if sif ->\n-            let ts = tables () in\n-            let graph = ts.ts_graph in\n-            let cond_id = s.id in\n-            let succ = Hashtbl.find graph cond_id in\n-            let then_id = sif.Ast.if_then.id in\n-            let then_end_id = last_id_or_block_id sif.Ast.if_then in\n-            let show_node = show_node cx graph in\n-            let succ = List.filter (fun x -> not (x = then_id)) succ in\n-              show_node \"initial cond\" cond_id;\n-              show_node \"initial then\" then_id;\n-              show_node \"initial then_end\" then_end_id;\n-              begin\n-                match sif.Ast.if_else with\n-                    None ->\n-                        Hashtbl.replace graph cond_id (then_id :: succ);\n-                        (* Kill residual messed-up block wiring.*)\n-                        remove_flow_edges graph then_end_id [then_id];\n-                        show_node \"cond\" cond_id;\n-                        show_node \"then\" then_id;\n-                        show_node \"then_end\" then_end_id;\n-\n-                  | Some e ->\n-                      let else_id = e.id in\n-                      let succ =\n-                        List.filter (fun x -> not (x = else_id)) succ\n-                      in\n-                      let else_end_id = last_id_or_block_id e in\n-                        show_node \"initial else\" else_id;\n-                        show_node \"initial else_end\" else_end_id;\n-                        Hashtbl.replace graph cond_id [then_id; else_id];\n-                        Hashtbl.replace graph then_end_id succ;\n-                        Hashtbl.replace graph else_end_id succ;\n-\n-                        (* Kill residual messed-up block wiring.*)\n-                        remove_flow_edges graph then_end_id [then_id];\n-                        remove_flow_edges graph else_id [then_id];\n-                        remove_flow_edges graph else_end_id [then_id];\n-                        show_node \"cond\" cond_id;\n-                        show_node \"then\" then_id;\n-                        show_node \"then_end\" then_end_id;\n-                        show_node \"else\" else_id;\n-                        show_node \"else_end\" else_end_id;\n-              end;\n-\n-        | Ast.STMT_while sw ->\n-            (* There are a bunch of rewirings to do on 'while' nodes. *)\n-\n-            begin\n-              let ts = tables () in\n-              let graph = ts.ts_graph in\n-              let dsts = Hashtbl.find graph s.id in\n-              let body = sw.Ast.while_body in\n-              let succ_stmts =\n-                List.filter (fun x -> not (x = body.id)) dsts\n-              in\n-\n-              let (pre_loop_stmts, _) = sw.Ast.while_lval in\n-              let loop_head_id =\n-                (* Splice loop prelude into flow graph, save loop-head\n-                 * node.\n-                 *)\n-                let slen = Array.length pre_loop_stmts in\n-                  if slen > 0\n-                  then\n-                    begin\n-                      let pre_loop_begin = pre_loop_stmts.(0).id in\n-                      let pre_loop_end = last_id pre_loop_stmts in\n-                        remove_flow_edges graph s.id [body.id];\n-                        add_flow_edges graph s.id [pre_loop_begin];\n-                        add_flow_edges graph pre_loop_end [body.id];\n-                        pre_loop_end\n-                    end\n-                  else\n-                    body.id\n-              in\n-\n-                (* Always flow s into the loop prelude; prelude may end\n-                 * loop.\n-                 *)\n-                remove_flow_edges graph s.id succ_stmts;\n-                add_flow_edges graph loop_head_id succ_stmts;\n-\n-                (* Flow loop-end to loop-head. *)\n-                let loop_end = last_id_or_block_id body in\n-                  add_flow_edges graph loop_end [loop_head_id]\n-            end\n-\n-        | Ast.STMT_alt_tag at ->\n-            let ts = tables () in\n-            let graph = ts.ts_graph in\n-            let dsts = Hashtbl.find graph s.id in\n-            let arm_blocks =\n-              let arm_block_id { node = (_, block); id = _ } = block.id in\n-              Array.to_list (Array.map arm_block_id at.Ast.alt_tag_arms)\n-            in\n-            let succ_stmts =\n-              List.filter (fun x -> not (List.mem x arm_blocks)) dsts\n-            in\n-              remove_flow_edges graph s.id succ_stmts\n-\n-        | _ -> ()\n-    end;\n-    inner.Walk.visit_stmt_post s\n-  in\n-    { inner with\n-        Walk.visit_stmt_pre = visit_stmt_pre }\n ;;\n \n let find_roots\n@@ -1631,13 +1498,7 @@ let process_crate\n             (condition_assigning_visitor cx tables_stack scopes\n                Walk.empty_visitor)));\n       (table_managed\n-         (graph_sequence_building_visitor cx tables_stack\n-            Walk.empty_visitor));\n-      (table_managed\n-         (graph_general_block_structure_building_visitor cx tables_stack\n-            Walk.empty_visitor));\n-      (table_managed\n-         (graph_special_block_structure_building_visitor cx tables_stack\n+         (graph_building_visitor cx tables_stack\n             Walk.empty_visitor));\n     |]\n   in"}, {"sha": "c76da0de552b020ce8f7da97d725c87794ff721f", "filename": "src/boot/util/common.ml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Futil%2Fcommon.ml", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fboot%2Futil%2Fcommon.ml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fboot%2Futil%2Fcommon.ml?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -56,6 +56,7 @@ type target =\n     Linux_x86_elf\n   | Win32_x86_pe\n   | MacOS_x86_macho\n+  | FreeBSD_x86_elf\n ;;\n \n type ty_mach ="}, {"sha": "dd058590ae25522fe6c8b3695b14f6b043342398", "filename": "src/comp/back/abi.rs", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fback%2Fabi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fback%2Fabi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fback%2Fabi.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -44,7 +44,8 @@ const int obj_field_vtbl = 0;\n const int obj_field_box = 1;\n \n const int obj_body_elt_tydesc = 0;\n-const int obj_body_elt_fields = 1;\n+const int obj_body_elt_typarams = 1;\n+const int obj_body_elt_fields = 2;\n \n const int fn_field_code = 0;\n const int fn_field_box = 1;\n@@ -59,6 +60,9 @@ const int worst_case_glue_call_args = 7;\n \n const int n_upcall_glues = 7;\n \n+const int abi_x86_rustboot_cdecl = 1;\n+const int abi_x86_rustc_fastcall = 2;\n+\n fn memcpy_glue_name() -> str {\n     ret \"rust_memcpy_glue\";\n }\n@@ -67,6 +71,10 @@ fn bzero_glue_name() -> str {\n     ret \"rust_bzero_glue\";\n }\n \n+fn vec_append_glue_name() -> str {\n+    ret \"rust_vec_append_glue\";\n+}\n+\n fn upcall_glue_name(int n) -> str {\n     ret \"rust_upcall_\" + util.common.istr(n);\n }"}, {"sha": "10227df7ca562adc6c63fd35a8f478b2101b1bd6", "filename": "src/comp/back/x86.rs", "status": "modified", "additions": 99, "deletions": 2, "changes": 101, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fback%2Fx86.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fback%2Fx86.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fback%2Fx86.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -41,20 +41,117 @@ fn store_esp_to_runtime_sp() -> vec[str] {\n     ret vec(\"movl  %esp, \" + wstr(abi.task_field_runtime_sp) + \"(%ecx)\");\n }\n \n+/*\n+ * This is a bit of glue-code. It should be emitted once per\n+ * compilation unit.\n+ *\n+ *   - save regs on C stack\n+ *   - align sp on a 16-byte boundary\n+ *   - save sp to task.runtime_sp (runtime_sp is thus always aligned)\n+ *   - load saved task sp (switch stack)\n+ *   - restore saved task regs\n+ *   - return to saved task pc\n+ *\n+ * Our incoming stack looks like this:\n+ *\n+ *   *esp+4        = [arg1   ] = task ptr\n+ *   *esp          = [retpc  ]\n+ */\n+\n fn rust_activate_glue() -> vec[str] {\n     ret vec(\"movl  4(%esp), %ecx    # ecx = rust_task\")\n         + save_callee_saves()\n         + store_esp_to_runtime_sp()\n         + load_esp_from_rust_sp()\n \n-        // This 'add' instruction is a bit surprising.\n-        // See lengthy comment in boot/be/x86.ml activate_glue.\n+        /*\n+         * There are two paths we can arrive at this code from:\n+         *\n+         *\n+         *   1. We are activating a task for the first time. When we switch\n+         *      into the task stack and 'ret' to its first instruction, we'll\n+         *      start doing whatever the first instruction says. Probably\n+         *      saving registers and starting to establish a frame. Harmless\n+         *      stuff, doesn't look at task->rust_sp again except when it\n+         *      clobbers it during a later upcall.\n+         *\n+         *\n+         *   2. We are resuming a task that was descheduled by the yield glue\n+         *      below.  When we switch into the task stack and 'ret', we'll be\n+         *      ret'ing to a very particular instruction:\n+         *\n+         *              \"esp <- task->rust_sp\"\n+         *\n+         *      this is the first instruction we 'ret' to after this glue,\n+         *      because it is the first instruction following *any* upcall,\n+         *      and the task we are activating was descheduled mid-upcall.\n+         *\n+         *      Unfortunately for us, we have already restored esp from\n+         *      task->rust_sp and are about to eat the 5 words off the top of\n+         *      it.\n+         *\n+         *\n+         *      | ...    | <-- where esp will be once we restore + ret, below,\n+         *      | retpc  |     and where we'd *like* task->rust_sp to wind up.\n+         *      | ebp    |\n+         *      | edi    |\n+         *      | esi    |\n+         *      | ebx    | <-- current task->rust_sp == current esp\n+         *\n+         *\n+         *      This is a problem. If we return to \"esp <- task->rust_sp\" it\n+         *      will push esp back down by 5 words. This manifests as a rust\n+         *      stack that grows by 5 words on each yield/reactivate. Not\n+         *      good.\n+         *\n+         *      So what we do here is just adjust task->rust_sp up 5 words as\n+         *      well, to mirror the movement in esp we're about to\n+         *      perform. That way the \"esp <- task->rust_sp\" we 'ret' to below\n+         *      will be a no-op. Esp won't move, and the task's stack won't\n+         *      grow.\n+         */\n         + vec(\"addl  $20, \" + wstr(abi.task_field_rust_sp) + \"(%ecx)\")\n \n+\n+        /*\n+         * In most cases, the function we're returning to (activating)\n+         * will have saved any caller-saves before it yielded via upcalling,\n+         * so no work to do here. With one exception: when we're initially\n+         * activating, the task needs to be in the fastcall 2nd parameter\n+         * expected by the rust main function. That's edx.\n+         */\n+        + vec(\"mov  %ecx, %edx\")\n+\n         + restore_callee_saves()\n         + vec(\"ret\");\n }\n \n+/* More glue code, this time the 'bottom half' of yielding.\n+ *\n+ * We arrived here because an upcall decided to deschedule the\n+ * running task. So the upcall's return address got patched to the\n+ * first instruction of this glue code.\n+ *\n+ * When the upcall does 'ret' it will come here, and its esp will be\n+ * pointing to the last argument pushed on the C stack before making\n+ * the upcall: the 0th argument to the upcall, which is always the\n+ * task ptr performing the upcall. That's where we take over.\n+ *\n+ * Our goal is to complete the descheduling\n+ *\n+ *   - Switch over to the task stack temporarily.\n+ *\n+ *   - Save the task's callee-saves onto the task stack.\n+ *     (the task is now 'descheduled', safe to set aside)\n+ *\n+ *   - Switch *back* to the C stack.\n+ *\n+ *   - Restore the C-stack callee-saves.\n+ *\n+ *   - Return to the caller on the C stack that activated the task.\n+ *\n+ */\n+\n fn rust_yield_glue() -> vec[str] {\n     ret vec(\"movl  0(%esp), %ecx    # ecx = rust_task\")\n         + load_esp_from_rust_sp()"}, {"sha": "7ad0cdc74fde9d6b2b59f303b49dd230d0da3ea7", "filename": "src/comp/driver/rustc.rs", "status": "modified", "additions": 70, "deletions": 32, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fdriver%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fdriver%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fdriver%2Frustc.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -2,6 +2,7 @@\n \n import front.parser;\n import front.token;\n+import front.eval;\n import middle.trans;\n import middle.resolve;\n import middle.typeck;\n@@ -13,6 +14,30 @@ import std.option.none;\n import std._str;\n import std._vec;\n \n+fn default_environment(session.session sess,\n+                       str argv0,\n+                       str input) -> eval.env {\n+\n+    auto libc = \"libc.so\";\n+    alt (sess.get_targ_cfg().os) {\n+        case (session.os_win32) { libc = \"msvcrt.dll\"; }\n+        case (session.os_macos) { libc = \"libc.dylib\"; }\n+        case (session.os_linux) { libc = \"libc.so.6\"; }\n+    }\n+\n+    ret\n+        vec(\n+            // Target bindings.\n+            tup(\"target_os\", eval.val_str(std.os.target_os())),\n+            tup(\"target_arch\", eval.val_str(\"x86\")),\n+            tup(\"target_libc\", eval.val_str(libc)),\n+\n+            // Build bindings.\n+            tup(\"build_compiler\", eval.val_str(argv0)),\n+            tup(\"build_input\", eval.val_str(input))\n+            );\n+}\n+\n impure fn parse_input(session.session sess,\n                       parser.parser p,\n                       str input) -> @front.ast.crate {\n@@ -25,20 +50,30 @@ impure fn parse_input(session.session sess,\n     fail;\n }\n \n-impure fn compile_input(session.session sess, str input, str output,\n+impure fn compile_input(session.session sess,\n+                        eval.env env,\n+                        str input, str output,\n                         bool shared) {\n-    auto p = parser.new_parser(sess, 0, input);\n+    auto p = parser.new_parser(sess, env, 0, input);\n     auto crate = parse_input(sess, p, input);\n     crate = resolve.resolve_crate(sess, crate);\n     crate = typeck.check_crate(sess, crate);\n     trans.trans_crate(sess, crate, output, shared);\n }\n \n+impure fn pretty_print_input(session.session sess,\n+                             eval.env env,\n+                             str input) {\n+    auto p = front.parser.new_parser(sess, env, 0, input);\n+    auto crate = front.parser.parse_crate_from_source_file(p);\n+    pretty.pprust.print_ast(crate.node.module);\n+}\n+\n fn warn_wrong_compiler() {\n     log \"This is the rust 'self-hosted' compiler.\";\n     log \"The one written in rust.\";\n     log \"It is currently incomplete.\";\n-    log \"You may want rustboot insteaad, the compiler next door.\";\n+    log \"You may want rustboot instead, the compiler next door.\";\n }\n \n fn usage(session.session sess, str argv0) {\n@@ -48,6 +83,7 @@ fn usage(session.session sess, str argv0) {\n     log \"    -o <filename>      write output to <filename>\";\n     log \"    -nowarn            suppress wrong-compiler warning\";\n     log \"    -shared            compile a shared-library crate\";\n+    log \"    -pp                pretty-print the input instead of compiling\";\n     log \"    -h                 display this message\";\n     log \"\";\n     log \"\";\n@@ -74,6 +110,7 @@ impure fn main(vec[str] args) {\n     let option.t[str] output_file = none[str];\n     let bool do_warn = true;\n     let bool shared = false;\n+    let bool pretty = false;\n \n     auto i = 1u;\n     auto len = _vec.len[str](args);\n@@ -86,24 +123,21 @@ impure fn main(vec[str] args) {\n                 do_warn = false;\n             } else if (_str.eq(arg, \"-shared\")) {\n                 shared = true;\n-            } else {\n-                // FIXME: rust could use an elif construct.\n-                if (_str.eq(arg, \"-o\")) {\n-                    if (i+1u < len) {\n-                        output_file = some(args.(i+1u));\n-                        i += 1u;\n-                    } else {\n-                        usage(sess, args.(0));\n-                        sess.err(\"-o requires an argument\");\n-                    }\n+            } else if (_str.eq(arg, \"-pp\")) {\n+                pretty = true;\n+            } else if (_str.eq(arg, \"-o\")) {\n+                if (i+1u < len) {\n+                    output_file = some(args.(i+1u));\n+                    i += 1u;\n                 } else {\n-                    if (_str.eq(arg, \"-h\")) {\n-                        usage(sess, args.(0));\n-                    } else {\n-                        usage(sess, args.(0));\n-                        sess.err(\"unrecognized option: \" + arg);\n-                    }\n+                    usage(sess, args.(0));\n+                    sess.err(\"-o requires an argument\");\n                 }\n+            } else if (_str.eq(arg, \"-h\")) {\n+                usage(sess, args.(0));\n+            } else {\n+                usage(sess, args.(0));\n+                sess.err(\"unrecognized option: \" + arg);\n             }\n         } else {\n             alt (input_file) {\n@@ -115,8 +149,6 @@ impure fn main(vec[str] args) {\n                     input_file = some[str](arg);\n                 }\n             }\n-            // FIXME: dummy node to work around typestate mis-wiring bug.\n-            i = i;\n         }\n         i += 1u;\n     }\n@@ -131,23 +163,29 @@ impure fn main(vec[str] args) {\n             sess.err(\"no input filename\");\n         }\n         case (some[str](?ifile)) {\n-            alt (output_file) {\n-                case (none[str]) {\n-                    let vec[str] parts = _str.split(ifile, '.' as u8);\n-                    parts = _vec.pop[str](parts);\n-                    parts += \".bc\";\n-                    auto ofile = _str.concat(parts);\n-                    compile_input(sess, ifile, ofile, shared);\n-                }\n-                case (some[str](?ofile)) {\n-                    compile_input(sess, ifile, ofile, shared);\n+\n+            auto env = default_environment(sess, args.(0), ifile);\n+            if (pretty) {\n+                pretty_print_input(sess, env, ifile);\n+            }\n+            else {\n+                alt (output_file) {\n+                    case (none[str]) {\n+                        let vec[str] parts = _str.split(ifile, '.' as u8);\n+                        parts = _vec.pop[str](parts);\n+                        parts += \".bc\";\n+                        auto ofile = _str.concat(parts);\n+                        compile_input(sess, env, ifile, ofile, shared);\n+                    }\n+                    case (some[str](?ofile)) {\n+                        compile_input(sess, env, ifile, ofile, shared);\n+                    }\n                 }\n             }\n         }\n     }\n }\n \n-\n // Local Variables:\n // mode: rust\n // fill-column: 78;"}, {"sha": "f9d609d1842ce652beb5deae54cbda35a8607b6b", "filename": "src/comp/front/ast.rs", "status": "modified", "additions": 166, "deletions": 13, "changes": 179, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fast.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -5,6 +5,7 @@ import std._vec;\n import util.common.span;\n import util.common.spanned;\n import util.common.ty_mach;\n+import util.common.filename;\n \n type ident = str;\n \n@@ -36,11 +37,29 @@ tag def {\n     def_ty_arg(def_id);\n     def_binding(def_id);\n     def_use(def_id);\n+    def_native_ty(def_id);\n+    def_native_fn(def_id);\n }\n \n type crate = spanned[crate_];\n type crate_ = rec(_mod module);\n \n+tag crate_directive_ {\n+    cdir_expr(@expr);\n+    // FIXME: cdir_let should be eliminated\n+    // and redirected to the use of const stmt_decls inside\n+    // crate directive blocks.\n+    cdir_let(ident, @expr, vec[@crate_directive]);\n+    cdir_src_mod(ident, option.t[filename]);\n+    cdir_dir_mod(ident, option.t[filename], vec[@crate_directive]);\n+    cdir_view_item(@view_item);\n+    cdir_meta(vec[@meta_item]);\n+    cdir_syntax(path);\n+    cdir_auth(path, effect);\n+}\n+type crate_directive = spanned[crate_directive_];\n+\n+\n type meta_item = spanned[meta_item_];\n type meta_item_ = rec(ident name, str value);\n \n@@ -55,6 +74,7 @@ type pat = spanned[pat_];\n tag pat_ {\n     pat_wild(ann);\n     pat_bind(ident, def_id, ann);\n+    pat_lit(@lit, ann);\n     pat_tag(path, vec[@pat], option.t[variant_def], ann);\n }\n \n@@ -63,6 +83,11 @@ tag mutability {\n     imm;\n }\n \n+tag opacity {\n+    op_abstract;\n+    op_transparent;\n+}\n+\n tag layer {\n     layer_value;\n     layer_state;\n@@ -75,6 +100,11 @@ tag effect {\n     eff_unsafe;\n }\n \n+tag proto {\n+    proto_iter;\n+    proto_fn;\n+}\n+\n tag binop {\n     add;\n     sub;\n@@ -97,12 +127,49 @@ tag binop {\n     gt;\n }\n \n+fn binop_to_str(binop op) -> str {\n+    alt (op) {\n+        case (add) {ret \"+\";}\n+        case (sub) {ret \"-\";}\n+        case (mul) {ret \"*\";}\n+        case (div) {ret \"/\";}\n+        case (rem) {ret \"%\";}\n+        case (and) {ret \"&&\";}\n+        case (or) {ret \"||\";}\n+        case (bitxor) {ret \"^\";}\n+        case (bitand) {ret \"&\";}\n+        case (bitor) {ret \"|\";}\n+        case (lsl) {ret \"<<\";}\n+        case (lsr) {ret \">>\";}\n+        case (asr) {ret \">>>\";}\n+        case (eq) {ret \"==\";}\n+        case (lt) {ret \"<\";}\n+        case (le) {ret \"<=\";}\n+        case (ne) {ret \"!=\";}\n+        case (ge) {ret \">=\";}\n+        case (gt) {ret \">\";}\n+    }\n+}\n+\n+\n tag unop {\n     box;\n     deref;\n     bitnot;\n     not;\n     neg;\n+    _mutable;\n+}\n+\n+fn unop_to_str(unop op) -> str {\n+    alt (op) {\n+        case (box) {ret \"@\";}\n+        case (deref) {ret \"*\";}\n+        case (bitnot) {ret \"~\";}\n+        case (not) {ret \"!\";}\n+        case (neg) {ret \"-\";}\n+        case (_mutable) {ret \"mutable\";}\n+    }\n }\n \n tag mode {\n@@ -113,11 +180,9 @@ tag mode {\n type stmt = spanned[stmt_];\n tag stmt_ {\n     stmt_decl(@decl);\n-    stmt_ret(option.t[@expr]);\n-    stmt_log(@expr);\n-    stmt_check_expr(@expr);\n-    stmt_fail;\n     stmt_expr(@expr);\n+    // These only exist in crate-level blocks.\n+    stmt_crate_directive(@crate_directive);\n }\n \n type local = rec(option.t[@ty] ty,\n@@ -142,7 +207,7 @@ type expr = spanned[expr_];\n tag expr_ {\n     expr_vec(vec[@expr], ann);\n     expr_tup(vec[elt], ann);\n-    expr_rec(vec[field], ann);\n+    expr_rec(vec[field], option.t[@expr], ann);\n     expr_call(@expr, vec[@expr], ann);\n     expr_bind(@expr, vec[option.t[@expr]], ann);\n     expr_binary(binop, @expr, @expr, ann);\n@@ -152,6 +217,7 @@ tag expr_ {\n     expr_if(@expr, block, option.t[@expr], ann);\n     expr_while(@expr, block, ann);\n     expr_for(@decl, @expr, block, ann);\n+    expr_for_each(@decl, @expr, block, ann);\n     expr_do_while(block, @expr, ann);\n     expr_alt(@expr, vec[arm], ann);\n     expr_block(block, ann);\n@@ -160,6 +226,13 @@ tag expr_ {\n     expr_field(@expr, ident, ann);\n     expr_index(@expr, @expr, ann);\n     expr_path(path, option.t[def], ann);\n+    expr_ext(path, vec[@expr], option.t[@expr], @expr, ann);\n+    expr_fail;\n+    expr_ret(option.t[@expr]);\n+    expr_put(option.t[@expr]);\n+    expr_be(@expr);\n+    expr_log(@expr);\n+    expr_check_expr(@expr);\n }\n \n type lit = spanned[lit_];\n@@ -179,7 +252,8 @@ tag lit_ {\n type ty_field = rec(ident ident, @ty ty);\n type ty_arg = rec(mode mode, @ty ty);\n // TODO: effect\n-type ty_method = rec(ident ident, vec[ty_arg] inputs, @ty output);\n+type ty_method = rec(proto proto, ident ident,\n+                     vec[ty_arg] inputs, @ty output);\n type ty = spanned[ty_];\n tag ty_ {\n     ty_nil;\n@@ -193,17 +267,28 @@ tag ty_ {\n     ty_vec(@ty);\n     ty_tup(vec[@ty]);\n     ty_rec(vec[ty_field]);\n-    ty_fn(vec[ty_arg], @ty);        // TODO: effect\n+    ty_fn(proto, vec[ty_arg], @ty);        // TODO: effect\n     ty_obj(vec[ty_method]);\n     ty_path(path, option.t[def]);\n     ty_mutable(@ty);\n+    ty_type;\n+    ty_constr(@ty, vec[@constr]);\n+}\n+\n+tag constr_arg_ {\n+    carg_base;\n+    carg_ident(ident);\n }\n+type constr_arg = spanned[constr_arg_];\n+type constr_ = rec(path path, vec[@constr_arg] args);\n+type constr = spanned[constr_];\n \n type arg = rec(mode mode, @ty ty, ident ident, def_id id);\n-type _fn = rec(effect effect,\n-               bool is_iter,\n-               vec[arg] inputs,\n-               @ty output,\n+type fn_decl = rec(effect effect,\n+                   vec[arg] inputs,\n+                   @ty output);\n+type _fn = rec(fn_decl decl,\n+               proto proto,\n                block body);\n \n \n@@ -212,39 +297,64 @@ type method = spanned[method_];\n \n type obj_field = rec(@ty ty, ident ident, def_id id, ann ann);\n type _obj = rec(vec[obj_field] fields,\n-                vec[@method] methods);\n-\n+                vec[@method] methods,\n+                option.t[block] dtor);\n \n tag mod_index_entry {\n     mie_view_item(@view_item);\n     mie_item(@item);\n     mie_tag_variant(@item /* tag item */, uint /* variant index */);\n }\n \n+tag native_mod_index_entry {\n+    nmie_view_item(@view_item);\n+    nmie_item(@native_item);\n+}\n+\n type mod_index = hashmap[ident,mod_index_entry];\n type _mod = rec(vec[@view_item] view_items,\n                 vec[@item] items,\n                 mod_index index);\n \n+tag native_abi {\n+    native_abi_rust;\n+    native_abi_cdecl;\n+}\n+\n+type native_mod = rec(str native_name,\n+                      native_abi abi,\n+                      vec[@view_item] view_items,\n+                      vec[@native_item] items,\n+                      native_mod_index index);\n+type native_mod_index = hashmap[ident,native_mod_index_entry];\n+\n type variant_arg = rec(@ty ty, def_id id);\n type variant = rec(str name, vec[variant_arg] args, def_id id, ann ann);\n \n type view_item = spanned[view_item_];\n tag view_item_ {\n     view_item_use(ident, vec[@meta_item], def_id);\n     view_item_import(ident, vec[ident], def_id, option.t[def]);\n+    view_item_export(ident);\n }\n \n type item = spanned[item_];\n tag item_ {\n     item_const(ident, @ty, @expr, def_id, ann);\n     item_fn(ident, _fn, vec[ty_param], def_id, ann);\n     item_mod(ident, _mod, def_id);\n+    item_native_mod(ident, native_mod, def_id);\n     item_ty(ident, @ty, vec[ty_param], def_id, ann);\n     item_tag(ident, vec[variant], vec[ty_param], def_id);\n     item_obj(ident, _obj, vec[ty_param], def_id, ann);\n }\n \n+type native_item = spanned[native_item_];\n+tag native_item_ {\n+    native_item_ty(ident, def_id);\n+    native_item_fn(ident, fn_decl, vec[ty_param], def_id, ann);\n+}\n+\n fn index_view_item(mod_index index, @view_item it) {\n     alt (it.node) {\n         case(ast.view_item_use(?id, _, _)) {\n@@ -253,6 +363,11 @@ fn index_view_item(mod_index index, @view_item it) {\n         case(ast.view_item_import(?def_ident,_,_,_)) {\n             index.insert(def_ident, ast.mie_view_item(it));\n         }\n+        case(ast.view_item_export(_)) {\n+            // NB: don't index these, they might collide with\n+            // the import or use that they're exporting. Have\n+            // to do linear search for exports.\n+        }\n     }\n }\n \n@@ -267,6 +382,9 @@ fn index_item(mod_index index, @item it) {\n         case (ast.item_mod(?id, _, _)) {\n             index.insert(id, ast.mie_item(it));\n         }\n+        case (ast.item_native_mod(?id, _, _)) {\n+            index.insert(id, ast.mie_item(it));\n+        }\n         case (ast.item_ty(?id, _, _, _, _)) {\n             index.insert(id, ast.mie_item(it));\n         }\n@@ -285,6 +403,41 @@ fn index_item(mod_index index, @item it) {\n     }\n }\n \n+fn index_native_item(native_mod_index index, @native_item it) {\n+    alt (it.node) {\n+        case (ast.native_item_ty(?id, _)) {\n+            index.insert(id, ast.nmie_item(it));\n+        }\n+        case (ast.native_item_fn(?id, _, _, _, _)) {\n+            index.insert(id, ast.nmie_item(it));\n+        }\n+    }\n+}\n+\n+fn index_native_view_item(native_mod_index index, @view_item it) {\n+    alt (it.node) {\n+        case(ast.view_item_import(?def_ident,_,_,_)) {\n+            index.insert(def_ident, ast.nmie_view_item(it));\n+        }\n+        case(ast.view_item_export(_)) {\n+            // NB: don't index these, they might collide with\n+            // the import or use that they're exporting. Have\n+            // to do linear search for exports.\n+        }\n+    }\n+}\n+\n+fn is_call_expr(@expr e) -> bool {\n+    alt (e.node) {\n+        case (expr_call(_, _, _)) {\n+            ret true;\n+        }\n+        case (_) {\n+            ret false;\n+        }\n+    }\n+}\n+\n //\n // Local Variables:\n // mode: rust"}, {"sha": "881797c90646222400067265ec5a9f86a503e53a", "filename": "src/comp/front/eval.rs", "status": "added", "additions": 436, "deletions": 0, "changes": 436, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Feval.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,436 @@\n+import std._vec;\n+import std._str;\n+import std.option;\n+import std.option.some;\n+import std.option.none;\n+import std.map.hashmap;\n+\n+import driver.session;\n+import ast.ident;\n+import front.parser.parser;\n+import front.parser.spanned;\n+import front.parser.new_parser;\n+import front.parser.parse_mod_items;\n+import util.common;\n+import util.common.filename;\n+import util.common.append;\n+import util.common.span;\n+import util.common.new_str_hash;\n+\n+\n+// Simple dynamic-typed value type for eval_expr.\n+tag val {\n+    val_bool(bool);\n+    val_int(int);\n+    val_str(str);\n+}\n+\n+type env = vec[tup(ident, val)];\n+\n+fn mk_env() -> env {\n+    let env e = vec();\n+    ret e;\n+}\n+\n+fn val_is_bool(val v) -> bool {\n+    alt (v) {\n+        case (val_bool(_)) { ret true; }\n+        case (_) { }\n+    }\n+    ret false;\n+}\n+\n+fn val_is_int(val v) -> bool {\n+    alt (v) {\n+        case (val_bool(_)) { ret true; }\n+        case (_) { }\n+    }\n+    ret false;\n+}\n+\n+fn val_is_str(val v) -> bool {\n+    alt (v) {\n+        case (val_str(_)) { ret true; }\n+        case (_) { }\n+    }\n+    ret false;\n+}\n+\n+fn val_as_bool(val v) -> bool {\n+    alt (v) {\n+        case (val_bool(?b)) { ret b; }\n+        case (_) { }\n+    }\n+    fail;\n+}\n+\n+fn val_as_int(val v) -> int {\n+    alt (v) {\n+        case (val_int(?i)) { ret i; }\n+        case (_) { }\n+    }\n+    fail;\n+}\n+\n+fn val_as_str(val v) -> str {\n+    alt (v) {\n+        case (val_str(?s)) { ret s; }\n+        case (_) { }\n+    }\n+    fail;\n+}\n+\n+fn lookup(session.session sess, env e, span sp, ident i) -> val {\n+    for (tup(ident, val) pair in e) {\n+        if (_str.eq(i, pair._0)) {\n+            ret pair._1;\n+        }\n+    }\n+    sess.span_err(sp, \"unknown variable: \" + i);\n+    fail;\n+}\n+\n+fn eval_lit(session.session sess, env e, span sp, @ast.lit lit) -> val {\n+    alt (lit.node) {\n+        case (ast.lit_bool(?b)) { ret val_bool(b); }\n+        case (ast.lit_int(?i)) { ret val_int(i); }\n+        case (ast.lit_str(?s)) { ret val_str(s); }\n+        case (_) {\n+            sess.span_err(sp, \"evaluating unsupported literal\");\n+        }\n+    }\n+    fail;\n+}\n+\n+fn eval_expr(session.session sess, env e, @ast.expr x) -> val {\n+    alt (x.node) {\n+        case (ast.expr_path(?pth, _, _)) {\n+            if (_vec.len[ident](pth.node.idents) == 1u &&\n+                _vec.len[@ast.ty](pth.node.types) == 0u) {\n+                ret lookup(sess, e, x.span, pth.node.idents.(0));\n+            }\n+            sess.span_err(x.span, \"evaluating structured path-name\");\n+        }\n+\n+        case (ast.expr_lit(?lit, _)) {\n+            ret eval_lit(sess, e, x.span, lit);\n+        }\n+\n+        case (ast.expr_unary(?op, ?a, _)) {\n+            auto av = eval_expr(sess, e, a);\n+            alt (op) {\n+                case (ast.not) {\n+                    if (val_is_bool(av)) {\n+                        ret val_bool(!val_as_bool(av));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '!' expression\");\n+                }\n+                case (_) {\n+                    sess.span_err(x.span, \"evaluating unsupported unop\");\n+                }\n+            }\n+        }\n+\n+        case (ast.expr_binary(?op, ?a, ?b, _)) {\n+            auto av = eval_expr(sess, e, a);\n+            auto bv = eval_expr(sess, e, b);\n+            alt (op) {\n+                case (ast.add) {\n+                    if (val_is_int(av) && val_is_int(bv)) {\n+                        ret val_int(val_as_int(av) + val_as_int(bv));\n+                    }\n+                    if (val_is_str(av) && val_is_str(bv)) {\n+                        ret val_str(val_as_str(av) + val_as_str(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '+' expression\");\n+                }\n+\n+                case (ast.sub) {\n+                    if (val_is_int(av) && val_is_int(bv)) {\n+                        ret val_int(val_as_int(av) - val_as_int(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '-' expression\");\n+                }\n+\n+                case (ast.mul) {\n+                    if (val_is_int(av) && val_is_int(bv)) {\n+                        ret val_int(val_as_int(av) * val_as_int(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '*' expression\");\n+                }\n+\n+                case (ast.div) {\n+                    if (val_is_int(av) && val_is_int(bv)) {\n+                        ret val_int(val_as_int(av) / val_as_int(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '/' expression\");\n+                }\n+\n+                case (ast.rem) {\n+                    if (val_is_int(av) && val_is_int(bv)) {\n+                        ret val_int(val_as_int(av) % val_as_int(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '%' expression\");\n+                }\n+\n+                case (ast.and) {\n+                    if (val_is_bool(av) && val_is_bool(bv)) {\n+                        ret val_bool(val_as_bool(av) && val_as_bool(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '&&' expression\");\n+                }\n+\n+                case (ast.or) {\n+                    if (val_is_bool(av) && val_is_bool(bv)) {\n+                        ret val_bool(val_as_bool(av) || val_as_bool(bv));\n+                    }\n+                    sess.span_err(x.span, \"bad types in '||' expression\");\n+                }\n+\n+                case (ast.eq) {\n+                    ret val_bool(val_eq(sess, x.span, av, bv));\n+                }\n+\n+                case (ast.ne) {\n+                    ret val_bool(! val_eq(sess, x.span, av, bv));\n+                }\n+\n+                case (_) {\n+                    sess.span_err(x.span, \"evaluating unsupported binop\");\n+                }\n+            }\n+        }\n+        case (_) {\n+            sess.span_err(x.span, \"evaluating unsupported expression\");\n+        }\n+    }\n+    fail;\n+}\n+\n+fn val_eq(session.session sess, span sp, val av, val bv) -> bool {\n+    if (val_is_bool(av) && val_is_bool(bv)) {\n+        ret val_as_bool(av) == val_as_bool(bv);\n+    }\n+    if (val_is_int(av) && val_is_int(bv)) {\n+        ret val_as_int(av) == val_as_int(bv);\n+    }\n+    if (val_is_str(av) && val_is_str(bv)) {\n+        ret _str.eq(val_as_str(av),\n+                    val_as_str(bv));\n+    }\n+    sess.span_err(sp, \"bad types in comparison\");\n+    fail;\n+}\n+\n+impure fn eval_crate_directives(parser p,\n+                                env e,\n+                                vec[@ast.crate_directive] cdirs,\n+                                str prefix,\n+                                &mutable vec[@ast.view_item] view_items,\n+                                &mutable vec[@ast.item] items,\n+                                hashmap[ast.ident,\n+                                        ast.mod_index_entry] index) {\n+\n+    for (@ast.crate_directive sub_cdir in cdirs) {\n+        eval_crate_directive(p, e, sub_cdir, prefix,\n+                             view_items, items, index);\n+    }\n+}\n+\n+\n+impure fn eval_crate_directives_to_mod(parser p,\n+                                       env e,\n+                                       vec[@ast.crate_directive] cdirs,\n+                                       str prefix) -> ast._mod {\n+    let vec[@ast.view_item] view_items = vec();\n+    let vec[@ast.item] items = vec();\n+    auto index = new_str_hash[ast.mod_index_entry]();\n+\n+    eval_crate_directives(p, e, cdirs, prefix,\n+                          view_items, items, index);\n+\n+    ret rec(view_items=view_items, items=items, index=index);\n+}\n+\n+\n+impure fn eval_crate_directive_block(parser p,\n+                                     env e,\n+                                     &ast.block blk,\n+                                     str prefix,\n+                                     &mutable vec[@ast.view_item] view_items,\n+                                     &mutable vec[@ast.item] items,\n+                                     hashmap[ast.ident,\n+                                             ast.mod_index_entry] index) {\n+\n+    for (@ast.stmt s in blk.node.stmts) {\n+        alt (s.node) {\n+            case (ast.stmt_crate_directive(?cdir)) {\n+                eval_crate_directive(p, e, cdir, prefix,\n+                                     view_items, items, index);\n+            }\n+            case (_) {\n+                auto sess = p.get_session();\n+                sess.span_err(s.span,\n+                              \"unsupported stmt in crate-directive block\");\n+            }\n+        }\n+    }\n+}\n+\n+impure fn eval_crate_directive_expr(parser p,\n+                                    env e,\n+                                    @ast.expr x,\n+                                    str prefix,\n+                                    &mutable vec[@ast.view_item] view_items,\n+                                    &mutable vec[@ast.item] items,\n+                                    hashmap[ast.ident,\n+                                            ast.mod_index_entry] index) {\n+    auto sess = p.get_session();\n+\n+    alt (x.node) {\n+\n+        case (ast.expr_if(?cond, ?thn, ?elopt, _)) {\n+            auto cv = eval_expr(sess, e, cond);\n+            if (!val_is_bool(cv)) {\n+                sess.span_err(x.span, \"bad cond type in 'if'\");\n+            }\n+\n+            if (val_as_bool(cv)) {\n+                ret eval_crate_directive_block(p, e, thn, prefix,\n+                                               view_items, items,\n+                                               index);\n+            }\n+\n+            alt (elopt) {\n+                case (some[@ast.expr](?els)) {\n+                    ret eval_crate_directive_expr(p, e, els, prefix,\n+                                                  view_items, items,\n+                                                  index);\n+                }\n+                case (_) {\n+                    // Absent-else is ok.\n+                }\n+            }\n+        }\n+\n+        case (ast.expr_alt(?v, ?arms, _)) {\n+            auto vv = eval_expr(sess, e, v);\n+            for (ast.arm arm in arms) {\n+                alt (arm.pat.node) {\n+                    case (ast.pat_lit(?lit, _)) {\n+                        auto pv = eval_lit(sess, e,\n+                                           arm.pat.span, lit);\n+                        if (val_eq(sess, arm.pat.span, vv, pv)) {\n+                            ret eval_crate_directive_block\n+                                (p, e, arm.block, prefix,\n+                                 view_items, items, index);\n+                        }\n+                    }\n+                    case (ast.pat_wild(_)) {\n+                        ret eval_crate_directive_block\n+                            (p, e, arm.block, prefix,\n+                             view_items, items, index);\n+                    }\n+                    case (_) {\n+                        sess.span_err(arm.pat.span,\n+                                      \"bad pattern type in 'alt'\");\n+                    }\n+                }\n+            }\n+            sess.span_err(x.span, \"no cases matched in 'alt'\");\n+        }\n+\n+        case (ast.expr_block(?block, _)) {\n+            ret eval_crate_directive_block(p, e, block, prefix,\n+                                           view_items, items,\n+                                           index);\n+        }\n+\n+        case (_) {\n+            sess.span_err(x.span, \"unsupported expr type\");\n+        }\n+    }\n+}\n+\n+impure fn eval_crate_directive(parser p,\n+                               env e,\n+                               @ast.crate_directive cdir,\n+                               str prefix,\n+                               &mutable vec[@ast.view_item] view_items,\n+                               &mutable vec[@ast.item] items,\n+                               hashmap[ast.ident,\n+                                       ast.mod_index_entry] index) {\n+    alt (cdir.node) {\n+\n+        case (ast.cdir_let(?id, ?x, ?cdirs)) {\n+            auto v = eval_expr(p.get_session(), e, x);\n+            auto e0 = vec(tup(id, v)) + e;\n+            eval_crate_directives(p, e0, cdirs, prefix,\n+                                  view_items, items, index);\n+        }\n+\n+        case (ast.cdir_expr(?x)) {\n+            eval_crate_directive_expr(p, e, x, prefix,\n+                                      view_items, items, index);\n+        }\n+\n+        case (ast.cdir_src_mod(?id, ?file_opt)) {\n+\n+            auto file_path = id + \".rs\";\n+            alt (file_opt) {\n+                case (some[filename](?f)) {\n+                    file_path = f;\n+                }\n+                case (none[filename]) {}\n+            }\n+\n+            auto full_path = prefix + std.os.path_sep() + file_path;\n+\n+            auto p0 = new_parser(p.get_session(), e, 0, full_path);\n+            auto m0 = parse_mod_items(p0, token.EOF);\n+            auto im = ast.item_mod(id, m0, p.next_def_id());\n+            auto i = @spanned(cdir.span, cdir.span, im);\n+            ast.index_item(index, i);\n+            append[@ast.item](items, i);\n+        }\n+\n+        case (ast.cdir_dir_mod(?id, ?dir_opt, ?cdirs)) {\n+\n+            auto path = id;\n+            alt (dir_opt) {\n+                case (some[filename](?d)) {\n+                    path = d;\n+                }\n+                case (none[filename]) {}\n+            }\n+\n+            auto full_path = prefix + std.os.path_sep() + path;\n+            auto m0 = eval_crate_directives_to_mod(p, e, cdirs, full_path);\n+            auto im = ast.item_mod(id, m0, p.next_def_id());\n+            auto i = @spanned(cdir.span, cdir.span, im);\n+            ast.index_item(index, i);\n+            append[@ast.item](items, i);\n+        }\n+\n+        case (ast.cdir_view_item(?vi)) {\n+            append[@ast.view_item](view_items, vi);\n+            ast.index_view_item(index, vi);\n+        }\n+\n+        case (ast.cdir_meta(?mi)) {}\n+        case (ast.cdir_syntax(?pth)) {}\n+        case (ast.cdir_auth(?pth, ?eff)) {}\n+    }\n+}\n+\n+\n+//\n+// Local Variables:\n+// mode: rust\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// compile-command: \"make -k -C ../.. 2>&1 | sed -e 's/\\\\/x\\\\//x:\\\\//g'\";\n+// End:\n+//"}, {"sha": "255614d0f077837016d694a8f2f6e8a42da538f4", "filename": "src/comp/front/extfmt.rs", "status": "added", "additions": 553, "deletions": 0, "changes": 553, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fextfmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fextfmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fextfmt.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,553 @@\n+/* The 'fmt' extension is modeled on the posix printf system.\n+ *\n+ * A posix conversion ostensibly looks like this:\n+ *\n+ * %[parameter][flags][width][.precision][length]type\n+ *\n+ * Given the different numeric type bestiary we have, we omit the 'length'\n+ * parameter and support slightly different conversions for 'type':\n+ *\n+ * %[parameter][flags][width][.precision]type\n+ *\n+ * we also only support translating-to-rust a tiny subset of the possible\n+ * combinations at the moment.\n+ */\n+\n+import util.common;\n+\n+import std._str;\n+import std._vec;\n+import std.option;\n+import std.option.none;\n+import std.option.some;\n+\n+export expand_syntax_ext;\n+\n+tag signedness {\n+    signed;\n+    unsigned;\n+}\n+\n+tag caseness {\n+    case_upper;\n+    case_lower;\n+}\n+\n+tag ty {\n+    ty_bool;\n+    ty_str;\n+    ty_char;\n+    ty_int(signedness);\n+    ty_bits;\n+    ty_hex(caseness);\n+    // FIXME: More types\n+}\n+\n+tag flag {\n+    flag_left_justify;\n+    flag_left_zero_pad;\n+    flag_left_space_pad;\n+    flag_plus_if_positive;\n+    flag_alternate;\n+}\n+\n+tag count {\n+    count_is(int);\n+    count_is_param(int);\n+    count_is_next_param;\n+    count_implied;\n+}\n+\n+// A formatted conversion from an expression to a string\n+type conv = rec(option.t[int] param,\n+                vec[flag] flags,\n+                count width,\n+                count precision,\n+                ty ty);\n+\n+// A fragment of the output sequence\n+tag piece {\n+    piece_string(str);\n+    piece_conv(conv);\n+}\n+\n+// TODO: Need to thread parser through here to handle errors correctly\n+fn expand_syntax_ext(vec[@ast.expr] args,\n+                     option.t[@ast.expr] body) -> @ast.expr {\n+\n+    if (_vec.len[@ast.expr](args) == 0u) {\n+        log \"malformed #fmt call\";\n+        fail;\n+    }\n+\n+    auto fmt = expr_to_str(args.(0));\n+\n+    // log \"Format string:\";\n+    // log fmt;\n+\n+    auto pieces = parse_fmt_string(fmt);\n+    auto args_len = _vec.len[@ast.expr](args);\n+    auto fmt_args = _vec.slice[@ast.expr](args, 1u, args_len - 1u);\n+    ret pieces_to_expr(pieces, args);\n+}\n+\n+fn expr_to_str(@ast.expr expr) -> str {\n+    alt (expr.node) {\n+        case (ast.expr_lit(?l, _)) {\n+            alt (l.node) {\n+                case (ast.lit_str(?s)) {\n+                    ret s;\n+                }\n+            }\n+        }\n+    }\n+    log \"malformed #fmt call\";\n+    fail;\n+}\n+\n+fn parse_fmt_string(str s) -> vec[piece] {\n+    let vec[piece] pieces = vec();\n+    auto lim = _str.byte_len(s);\n+    auto buf = \"\";\n+\n+    fn flush_buf(str buf, &vec[piece] pieces) -> str {\n+        if (_str.byte_len(buf) > 0u) {\n+            auto piece = piece_string(buf);\n+            pieces += piece;\n+        }\n+        ret \"\";\n+    }\n+\n+    auto i = 0u;\n+    while (i < lim) {\n+        auto curr = _str.substr(s, i, 1u);\n+        if (_str.eq(curr, \"%\")) {\n+            i += 1u;\n+            if (i >= lim) {\n+                log \"unterminated conversion at end of string\";\n+                fail;\n+            }\n+            auto curr2 = _str.substr(s, i, 1u);\n+            if (_str.eq(curr2, \"%\")) {\n+                i += 1u;\n+            } else {\n+                buf = flush_buf(buf, pieces);\n+                auto res = parse_conversion(s, i, lim);\n+                pieces += res._0;\n+                i = res._1;\n+            }\n+        } else {\n+            buf += curr;\n+            i += 1u;\n+        }\n+    }\n+    buf = flush_buf(buf, pieces);\n+    ret pieces;\n+}\n+\n+fn peek_num(str s, uint i, uint lim) -> option.t[tup(uint, uint)] {\n+    if (i >= lim) {\n+        ret none[tup(uint, uint)];\n+    }\n+\n+    auto c = s.(i);\n+    if (!('0' as u8 <= c && c <= '9' as u8)) {\n+        ret option.none[tup(uint, uint)];\n+    }\n+\n+    auto n = (c - ('0' as u8)) as uint;\n+    alt (peek_num(s, i + 1u, lim)) {\n+        case (none[tup(uint, uint)]) {\n+            ret some[tup(uint, uint)](tup(n, i + 1u));\n+        }\n+        case (some[tup(uint, uint)](?next)) {\n+            auto m = next._0;\n+            auto j = next._1;\n+            ret some[tup(uint, uint)](tup(n * 10u + m, j));\n+        }\n+    }\n+\n+}\n+\n+fn parse_conversion(str s, uint i, uint lim) -> tup(piece, uint) {\n+    auto parm = parse_parameter(s, i, lim);\n+    auto flags = parse_flags(s, parm._1, lim);\n+    auto width = parse_count(s, flags._1, lim);\n+    auto prec = parse_precision(s, width._1, lim);\n+    auto ty = parse_type(s, prec._1, lim);\n+    ret tup(piece_conv(rec(param = parm._0,\n+                           flags = flags._0,\n+                           width = width._0,\n+                           precision = prec._0,\n+                           ty = ty._0)),\n+            ty._1);\n+}\n+\n+fn parse_parameter(str s, uint i, uint lim) -> tup(option.t[int], uint) {\n+    if (i >= lim) {\n+        ret tup(none[int], i);\n+    }\n+\n+    auto num = peek_num(s, i, lim);\n+    alt (num) {\n+        case (none[tup(uint, uint)]) {\n+            ret tup(none[int], i);\n+        }\n+        case (some[tup(uint, uint)](?t)) {\n+            auto n = t._0;\n+            auto j = t._1;\n+            if (j < lim && s.(j) == '$' as u8) {\n+                ret tup(some[int](n as int), j + 1u);\n+            }\n+            else {\n+                ret tup(none[int], i);\n+            }\n+        }\n+    }\n+}\n+\n+fn parse_flags(str s, uint i, uint lim) -> tup(vec[flag], uint) {\n+    let vec[flag] noflags = vec();\n+\n+    if (i >= lim) {\n+        ret tup(noflags, i);\n+    }\n+\n+    fn more_(flag f, str s, uint i, uint lim) -> tup(vec[flag], uint) {\n+        auto next = parse_flags(s, i + 1u, lim);\n+        auto rest = next._0;\n+        auto j = next._1;\n+        let vec[flag] curr = vec(f);\n+        ret tup(curr + rest, j);\n+    }\n+\n+    auto more = bind more_(_, s, i, lim);\n+\n+    auto f = s.(i);\n+    if (f == ('-' as u8)) {\n+        ret more(flag_left_justify);\n+    } else if (f == ('0' as u8)) {\n+        ret more(flag_left_zero_pad);\n+    } else if (f == (' ' as u8)) {\n+        ret more(flag_left_space_pad);\n+    } else if (f == ('+' as u8)) {\n+        ret more(flag_plus_if_positive);\n+    } else if (f == ('#' as u8)) {\n+        ret more(flag_alternate);\n+    } else {\n+        ret tup(noflags, i);\n+    }\n+}\n+\n+fn parse_count(str s, uint i, uint lim) -> tup(count, uint) {\n+    if (i >= lim) {\n+        ret tup(count_implied, i);\n+    }\n+\n+    if (s.(i) == ('*' as u8)) {\n+        auto param = parse_parameter(s, i + 1u, lim);\n+        auto j = param._1;\n+        alt (param._0) {\n+            case (none[int]) {\n+                ret tup(count_is_next_param, j);\n+            }\n+            case (some[int](?n)) {\n+                ret tup(count_is_param(n), j);\n+            }\n+        }\n+    } else {\n+        auto num = peek_num(s, i, lim);\n+        alt (num) {\n+            case (none[tup(uint, uint)]) {\n+                ret tup(count_implied, i);\n+            }\n+            case (some[tup(uint, uint)](?num)) {\n+                ret tup(count_is(num._0 as int), num._1);\n+            }\n+        }\n+    }\n+}\n+\n+fn parse_precision(str s, uint i, uint lim) -> tup(count, uint) {\n+    if (i >= lim) {\n+        ret tup(count_implied, i);\n+    }\n+\n+    if (s.(i) == '.' as u8) {\n+        ret parse_count(s, i + 1u, lim);\n+    } else {\n+        ret tup(count_implied, i);\n+    }\n+}\n+\n+fn parse_type(str s, uint i, uint lim) -> tup(ty, uint) {\n+    if (i >= lim) {\n+        log \"missing type in conversion\";\n+        fail;\n+    }\n+\n+    auto t;\n+    auto tstr = _str.substr(s, i, 1u);\n+    if (_str.eq(tstr, \"b\")) {\n+        t = ty_bool;\n+    } else if (_str.eq(tstr, \"s\")) {\n+        t = ty_str;\n+    } else if (_str.eq(tstr, \"c\")) {\n+        t = ty_char;\n+    } else if (_str.eq(tstr, \"d\")\n+               || _str.eq(tstr, \"i\")) {\n+        // TODO: Do we really want two signed types here?\n+        // How important is it to be printf compatible?\n+        t = ty_int(signed);\n+    } else if (_str.eq(tstr, \"u\")) {\n+        t = ty_int(unsigned);\n+    } else if (_str.eq(tstr, \"x\")) {\n+        t = ty_hex(case_lower);\n+    } else if (_str.eq(tstr, \"X\")) {\n+        t = ty_hex(case_upper);\n+    } else if (_str.eq(tstr, \"t\")) {\n+        t = ty_bits;\n+    } else {\n+        log \"unknown type in conversion\";\n+        fail;\n+    }\n+\n+    ret tup(t, i + 1u);\n+}\n+\n+fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n+\n+    fn make_new_lit(common.span sp, ast.lit_ lit) -> @ast.expr {\n+        auto sp_lit = @parser.spanned[ast.lit_](sp, sp, lit);\n+        auto expr = ast.expr_lit(sp_lit, ast.ann_none);\n+        ret @parser.spanned[ast.expr_](sp, sp, expr);\n+    }\n+\n+    fn make_new_str(common.span sp, str s) -> @ast.expr {\n+        auto lit = ast.lit_str(s);\n+        ret make_new_lit(sp, lit);\n+    }\n+\n+    fn make_new_uint(common.span sp, uint u) -> @ast.expr {\n+        auto lit = ast.lit_uint(u);\n+        ret make_new_lit(sp, lit);\n+    }\n+\n+    fn make_add_expr(common.span sp,\n+                     @ast.expr lhs, @ast.expr rhs) -> @ast.expr {\n+        auto binexpr = ast.expr_binary(ast.add, lhs, rhs, ast.ann_none);\n+        ret @parser.spanned[ast.expr_](sp, sp, binexpr);\n+    }\n+\n+    fn make_call(common.span sp, vec[ast.ident] fn_path,\n+                 vec[@ast.expr] args) -> @ast.expr {\n+        let vec[ast.ident] path_idents = fn_path;\n+        let vec[@ast.ty] path_types = vec();\n+        auto path = rec(idents = path_idents, types = path_types);\n+        auto sp_path = parser.spanned[ast.path_](sp, sp, path);\n+        auto pathexpr = ast.expr_path(sp_path, none[ast.def], ast.ann_none);\n+        auto sp_pathexpr = @parser.spanned[ast.expr_](sp, sp, pathexpr);\n+        auto callexpr = ast.expr_call(sp_pathexpr, args, ast.ann_none);\n+        auto sp_callexpr = @parser.spanned[ast.expr_](sp, sp, callexpr);\n+        ret sp_callexpr;\n+    }\n+\n+    fn make_new_conv(conv cnv, @ast.expr arg) -> @ast.expr {\n+\n+        auto unsupported = \"conversion not supported in #fmt string\";\n+\n+        alt (cnv.param) {\n+            case (option.none[int]) {\n+            }\n+            case (_) {\n+                log unsupported;\n+                fail;\n+            }\n+        }\n+\n+        if (_vec.len[flag](cnv.flags) != 0u) {\n+            log unsupported;\n+            fail;\n+        }\n+\n+        alt (cnv.width) {\n+            case (count_implied) {\n+            }\n+            case (_) {\n+                log unsupported;\n+                fail;\n+            }\n+        }\n+\n+        alt (cnv.precision) {\n+            case (count_implied) {\n+            }\n+            case (_) {\n+                log unsupported;\n+                fail;\n+            }\n+        }\n+\n+        alt (cnv.ty) {\n+            case (ty_str) {\n+                ret arg;\n+            }\n+            case (ty_int(?sign)) {\n+                alt (sign) {\n+                    case (signed) {\n+                        let vec[str] path = vec(\"std\", \"_int\", \"to_str\");\n+                        auto radix_expr = make_new_uint(arg.span, 10u);\n+                        let vec[@ast.expr] args = vec(arg, radix_expr);\n+                        ret make_call(arg.span, path, args);\n+                    }\n+                    case (unsigned) {\n+                        let vec[str] path = vec(\"std\", \"_uint\", \"to_str\");\n+                        auto radix_expr = make_new_uint(arg.span, 10u);\n+                        let vec[@ast.expr] args = vec(arg, radix_expr);\n+                        ret make_call(arg.span, path, args);\n+                    }\n+                }\n+            }\n+            case (_) {\n+                log unsupported;\n+                fail;\n+            }\n+        }\n+    }\n+\n+    fn log_conv(conv c) {\n+        alt (c.param) {\n+            case (some[int](?p)) {\n+                log \"param: \" + std._int.to_str(p, 10u);\n+            }\n+            case (_) {\n+                log \"param: none\";\n+            }\n+        }\n+        for (flag f in c.flags) {\n+            alt (f) {\n+                case (flag_left_justify) {\n+                    log \"flag: left justify\";\n+                }\n+                case (flag_left_zero_pad) {\n+                    log \"flag: left zero pad\";\n+                }\n+                case (flag_left_space_pad) {\n+                    log \"flag: left space pad\";\n+                }\n+                case (flag_plus_if_positive) {\n+                    log \"flag: plus if positive\";\n+                }\n+                case (flag_alternate) {\n+                    log \"flag: alternate\";\n+                }\n+            }\n+        }\n+        alt (c.width) {\n+            case (count_is(?i)) {\n+                log \"width: count is \" + std._int.to_str(i, 10u);\n+            }\n+            case (count_is_param(?i)) {\n+                log \"width: count is param \" + std._int.to_str(i, 10u);\n+            }\n+            case (count_is_next_param) {\n+                log \"width: count is next param\";\n+            }\n+            case (count_implied) {\n+                log \"width: count is implied\";\n+            }\n+        }\n+        alt (c.precision) {\n+            case (count_is(?i)) {\n+                log \"prec: count is \" + std._int.to_str(i, 10u);\n+            }\n+            case (count_is_param(?i)) {\n+                log \"prec: count is param \" + std._int.to_str(i, 10u);\n+            }\n+            case (count_is_next_param) {\n+                log \"prec: count is next param\";\n+            }\n+            case (count_implied) {\n+                log \"prec: count is implied\";\n+            }\n+        }\n+        alt (c.ty) {\n+            case (ty_bool) {\n+                log \"type: bool\";\n+            }\n+            case (ty_str) {\n+                log \"type: str\";\n+            }\n+            case (ty_char) {\n+                log \"type: char\";\n+            }\n+            case (ty_int(?s)) {\n+                alt (s) {\n+                    case (signed) {\n+                        log \"type: signed\";\n+                    }\n+                    case (unsigned) {\n+                        log \"type: unsigned\";\n+                    }\n+                }\n+            }\n+            case (ty_bits) {\n+                log \"type: bits\";\n+            }\n+            case (ty_hex(?cs)) {\n+                alt (cs) {\n+                    case (case_upper) {\n+                        log \"type: uhex\";\n+                    }\n+                    case (case_lower) {\n+                        log \"type: lhex\";\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    auto sp = args.(0).span;\n+    auto n = 0u;\n+    auto tmp_expr = make_new_str(sp, \"\");\n+\n+    for (piece p in pieces) {\n+        alt (p) {\n+            case (piece_string(?s)) {\n+                auto s_expr = make_new_str(sp, s);\n+                tmp_expr = make_add_expr(sp, tmp_expr, s_expr);\n+            }\n+            case (piece_conv(?conv)) {\n+                if (n >= _vec.len[@ast.expr](args)) {\n+                    log \"too many conversions in #fmt string\";\n+                    fail;\n+                }\n+\n+                // TODO: Remove debug logging\n+                // log \"Building conversion:\";\n+                // log_conv(conv);\n+\n+                n += 1u;\n+                auto arg_expr = args.(n);\n+                auto c_expr = make_new_conv(conv, arg_expr);\n+                tmp_expr = make_add_expr(sp, tmp_expr, c_expr);\n+            }\n+        }\n+    }\n+\n+    // TODO: Remove this debug logging\n+    // log \"dumping expanded ast:\";\n+    // log pretty.print_expr(tmp_expr);\n+    ret tmp_expr;\n+}\n+\n+//\n+// Local Variables:\n+// mode: rust\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// compile-command: \"make -k -C ../.. 2>&1 | sed -e 's/\\\\/x\\\\//x:\\\\//g'\";\n+// End:\n+//"}, {"sha": "0e15e3d8c35bf526642a6ac13613d77c381bc5cf", "filename": "src/comp/front/lexer.rs", "status": "modified", "additions": 18, "deletions": 6, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Flexer.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,4 +1,4 @@\n-import std._io.stdio_reader;\n+import std.io.stdio_reader;\n import std._str;\n import std.map;\n import std.map.hashmap;\n@@ -90,7 +90,6 @@ fn new_reader(stdio_reader rdr, str filename) -> reader\n         }\n \n     auto keywords = new_str_hash[token.token]();\n-    auto reserved = new_str_hash[()]();\n \n     keywords.insert(\"mod\", token.MOD);\n     keywords.insert(\"use\", token.USE);\n@@ -191,6 +190,16 @@ fn new_reader(stdio_reader rdr, str filename) -> reader\n     keywords.insert(\"f32\", token.MACH(common.ty_f32));\n     keywords.insert(\"f64\", token.MACH(common.ty_f64));\n \n+    auto reserved = new_str_hash[()]();\n+\n+    reserved.insert(\"f16\", ());  // IEEE 754-2008 'binary16' interchange fmt\n+    reserved.insert(\"f80\", ());  // IEEE 754-1985 'extended'\n+    reserved.insert(\"f128\", ()); // IEEE 754-2008 'binary128'\n+    reserved.insert(\"m32\", ());  // IEEE 754-2008 'decimal32'\n+    reserved.insert(\"m64\", ());  // IEEE 754-2008 'decimal64'\n+    reserved.insert(\"m128\", ()); // IEEE 754-2008 'decimal128'\n+    reserved.insert(\"dec\", ());  // One of m32, m64, m128\n+\n     ret reader(rdr, filename, rdr.getc() as char, rdr.getc() as char,\n                1u, 0u, 1u, 0u, keywords, reserved);\n }\n@@ -425,6 +434,12 @@ impure fn next_token(reader rdr) -> token.token {\n             ret kwds.get(accum_str);\n         }\n \n+        auto rsvd = rdr.get_reserved();\n+        if (rsvd.contains_key(accum_str)) {\n+            log \"reserved keyword\";\n+            fail;\n+        }\n+\n         ret token.IDENT(accum_str);\n     }\n \n@@ -650,12 +665,9 @@ impure fn next_token(reader rdr) -> token.token {\n         case ('%') {\n             ret binop(rdr, token.PERCENT);\n         }\n-\n     }\n \n-    log \"lexer stopping at \";\n-    log c;\n-    ret token.EOF;\n+    fail;\n }\n \n "}, {"sha": "bb7b8558237af40a5f8e48092186c3c187365c0f", "filename": "src/comp/front/parser.rs", "status": "modified", "additions": 738, "deletions": 314, "changes": 1052, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fparser.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,4 +1,4 @@\n-import std._io;\n+import std.io;\n import std._vec;\n import std._str;\n import std.option;\n@@ -8,6 +8,7 @@ import std.map.hashmap;\n \n import driver.session;\n import util.common;\n+import util.common.filename;\n import util.common.append;\n import util.common.span;\n import util.common.new_str_hash;\n@@ -17,35 +18,49 @@ tag restriction {\n     RESTRICT_NO_CALL_EXPRS;\n }\n \n+tag file_type {\n+    CRATE_FILE;\n+    SOURCE_FILE;\n+}\n+\n state type parser =\n     state obj {\n           fn peek() -> token.token;\n           impure fn bump();\n           impure fn err(str s);\n           impure fn restrict(restriction r);\n           fn get_restriction() -> restriction;\n+          fn get_file_type() -> file_type;\n+          fn get_env() -> eval.env;\n           fn get_session() -> session.session;\n           fn get_span() -> common.span;\n           fn next_def_id() -> ast.def_id;\n+          fn get_prec_table() -> vec[op_spec];\n     };\n \n impure fn new_parser(session.session sess,\n-                 ast.crate_num crate, str path) -> parser {\n+                     eval.env env,\n+                     ast.crate_num crate,\n+                     str path) -> parser {\n     state obj stdio_parser(session.session sess,\n+                           eval.env env,\n+                           file_type ftype,\n                            mutable token.token tok,\n                            mutable common.pos lo,\n                            mutable common.pos hi,\n                            mutable ast.def_num def,\n                            mutable restriction res,\n                            ast.crate_num crate,\n-                           lexer.reader rdr)\n+                           lexer.reader rdr,\n+                           vec[op_spec] precs)\n         {\n             fn peek() -> token.token {\n-                // log token.to_str(tok);\n                 ret tok;\n             }\n \n             impure fn bump() {\n+                // log rdr.get_filename()\n+                //   + \":\" + common.istr(lo.line as int);\n                 tok = lexer.next_token(rdr);\n                 lo = rdr.get_mark_pos();\n                 hi = rdr.get_curr_pos();\n@@ -78,12 +93,29 @@ impure fn new_parser(session.session sess,\n                 def += 1;\n                 ret tup(crate, def);\n             }\n+\n+            fn get_file_type() -> file_type {\n+                ret ftype;\n+            }\n+\n+            fn get_env() -> eval.env {\n+                ret env;\n+            }\n+\n+            fn get_prec_table() -> vec[op_spec] {\n+                ret precs;\n+            }\n         }\n-    auto srdr = _io.new_stdio_reader(path);\n+    auto ftype = SOURCE_FILE;\n+    if (_str.ends_with(path, \".rc\")) {\n+        ftype = CRATE_FILE;\n+    }\n+    auto srdr = io.new_stdio_reader(path);\n     auto rdr = lexer.new_reader(srdr, path);\n     auto npos = rdr.get_curr_pos();\n-    ret stdio_parser(sess, lexer.next_token(rdr),\n-                     npos, npos, 0, UNRESTRICTED, crate, rdr);\n+    ret stdio_parser(sess, env, ftype, lexer.next_token(rdr),\n+                     npos, npos, 0, UNRESTRICTED, crate, rdr,\n+                     prec_table());\n }\n \n impure fn unexpected(parser p, token.token t) {\n@@ -121,9 +153,23 @@ impure fn parse_ident(parser p) -> ast.ident {\n }\n \n \n-impure fn parse_str_lit(parser p) -> ast.ident {\n+/* FIXME: gross hack copied from rustboot to make certain configuration-based\n+ * decisions work at build-time.  We should probably change it to use a\n+ * lexical sytnax-extension or something similar. For now we just imitate\n+ * rustboot.\n+ */\n+impure fn parse_str_lit_or_env_ident(parser p) -> ast.ident {\n     alt (p.peek()) {\n         case (token.LIT_STR(?s)) { p.bump(); ret s; }\n+        case (token.IDENT(?i)) {\n+            auto v = eval.lookup(p.get_session(), p.get_env(),\n+                                 p.get_span(), i);\n+            if (!eval.val_is_str(v)) {\n+                p.err(\"expecting string-valued variable\");\n+            }\n+            p.bump();\n+            ret eval.val_as_str(v);\n+        }\n         case (_) {\n             p.err(\"expecting string literal\");\n             fail;\n@@ -132,7 +178,8 @@ impure fn parse_str_lit(parser p) -> ast.ident {\n }\n \n \n-impure fn parse_ty_fn(parser p, ast.span lo) -> ast.ty_ {\n+impure fn parse_ty_fn(ast.proto proto, parser p,\n+                      ast.span lo) -> ast.ty_ {\n     impure fn parse_fn_input_ty(parser p) -> rec(ast.mode mode, @ast.ty ty) {\n         auto mode;\n         if (p.peek() == token.BINOP(token.AND)) {\n@@ -158,6 +205,10 @@ impure fn parse_ty_fn(parser p, ast.span lo) -> ast.ty_ {\n     auto inputs = parse_seq[rec(ast.mode mode, @ast.ty ty)](token.LPAREN,\n         token.RPAREN, some(token.COMMA), f, p);\n \n+    // FIXME: dropping constrs on the floor at the moment.\n+    // pick them up when they're used by typestate pass.\n+    parse_constrs(p);\n+\n     let @ast.ty output;\n     if (p.peek() == token.RARROW) {\n         p.bump();\n@@ -166,20 +217,33 @@ impure fn parse_ty_fn(parser p, ast.span lo) -> ast.ty_ {\n         output = @spanned(lo, inputs.span, ast.ty_nil);\n     }\n \n-    ret ast.ty_fn(inputs.node, output);\n+    ret ast.ty_fn(proto, inputs.node, output);\n+}\n+\n+impure fn parse_proto(parser p) -> ast.proto {\n+    alt (p.peek()) {\n+        case (token.ITER) { p.bump(); ret ast.proto_iter; }\n+        case (token.FN) { p.bump(); ret ast.proto_fn; }\n+        case (?t) { unexpected(p, t); }\n+    }\n+    fail;\n }\n \n impure fn parse_ty_obj(parser p, &mutable ast.span hi) -> ast.ty_ {\n     expect(p, token.OBJ);\n     impure fn parse_method_sig(parser p) -> ast.ty_method {\n         auto flo = p.get_span();\n-        expect(p, token.FN);\n+\n+        // FIXME: do something with this, currently it's dropped on the floor.\n+        let ast.effect eff = parse_effect(p);\n+        let ast.proto proto = parse_proto(p);\n         auto ident = parse_ident(p);\n-        auto f = parse_ty_fn(p, flo);\n+        auto f = parse_ty_fn(proto, p, flo);\n         expect(p, token.SEMI);\n         alt (f) {\n-            case (ast.ty_fn(?inputs, ?output)) {\n-                ret rec(ident=ident, inputs=inputs, output=output);\n+            case (ast.ty_fn(?proto, ?inputs, ?output)) {\n+                ret rec(proto=proto, ident=ident,\n+                        inputs=inputs, output=output);\n             }\n         }\n         fail;\n@@ -200,10 +264,72 @@ impure fn parse_ty_field(parser p) -> ast.ty_field {\n     ret rec(ident=id, ty=ty);\n }\n \n+impure fn parse_constr_arg(parser p) -> @ast.constr_arg {\n+    auto lo = p.get_span();\n+    auto carg = ast.carg_base;\n+    if (p.peek() == token.BINOP(token.STAR)) {\n+        p.bump();\n+    } else {\n+        carg = ast.carg_ident(parse_ident(p));\n+    }\n+    ret @spanned(lo, lo, carg);\n+}\n+\n+impure fn parse_ty_constr(parser p) -> @ast.constr {\n+    auto lo = p.get_span();\n+    auto path = parse_path(p, GREEDY);\n+    auto pf = parse_constr_arg;\n+    auto args = parse_seq[@ast.constr_arg](token.LPAREN,\n+                                         token.RPAREN,\n+                                         some(token.COMMA), pf, p);\n+    auto hi = args.span;\n+    ret @spanned(lo, hi, rec(path=path, args=args.node));\n+}\n+\n+impure fn parse_constrs(parser p) -> common.spanned[vec[@ast.constr]] {\n+    auto lo = p.get_span();\n+    auto hi = lo;\n+    let vec[@ast.constr] constrs = vec();\n+    if (p.peek() == token.COLON) {\n+        p.bump();\n+        let bool more = true;\n+        while (more) {\n+            alt (p.peek()) {\n+                case (token.IDENT(_)) {\n+                    auto constr = parse_ty_constr(p);\n+                    hi = constr.span;\n+                    append[@ast.constr](constrs, constr);\n+                    if (p.peek() == token.COMMA) {\n+                        p.bump();\n+                        more = false;\n+                    }\n+                }\n+                case (_) { more = false; }\n+            }\n+        }\n+    }\n+   ret spanned(lo, hi, constrs);\n+}\n+\n+impure fn parse_ty_constrs(@ast.ty t, parser p) -> @ast.ty {\n+   if (p.peek() == token.COLON) {\n+       auto constrs = parse_constrs(p);\n+       ret @spanned(t.span, constrs.span,\n+                    ast.ty_constr(t, constrs.node));\n+   }\n+   ret t;\n+}\n+\n impure fn parse_ty(parser p) -> @ast.ty {\n     auto lo = p.get_span();\n     auto hi = lo;\n     let ast.ty_ t;\n+\n+    // FIXME: do something with these; currently they're\n+    // dropped on the floor.\n+    let ast.effect eff = parse_effect(p);\n+    let ast.layer lyr = parse_layer(p);\n+\n     alt (p.peek()) {\n         case (token.BOOL) { p.bump(); t = ast.ty_bool; }\n         case (token.INT) { p.bump(); t = ast.ty_int; }\n@@ -275,9 +401,20 @@ impure fn parse_ty(parser p) -> @ast.ty {\n         case (token.FN) {\n             auto flo = p.get_span();\n             p.bump();\n-            t = parse_ty_fn(p, flo);\n+            t = parse_ty_fn(ast.proto_fn, p, flo);\n+            alt (t) {\n+                case (ast.ty_fn(_, _, ?out)) {\n+                    hi = out.span;\n+                }\n+            }\n+        }\n+\n+        case (token.ITER) {\n+            auto flo = p.get_span();\n+            p.bump();\n+            t = parse_ty_fn(ast.proto_iter, p, flo);\n             alt (t) {\n-                case (ast.ty_fn(_, ?out)) {\n+                case (ast.ty_fn(_, _, ?out)) {\n                     hi = out.span;\n                 }\n             }\n@@ -297,7 +434,8 @@ impure fn parse_ty(parser p) -> @ast.ty {\n             fail;\n         }\n     }\n-    ret @spanned(lo, hi, t);\n+\n+    ret parse_ty_constrs(@spanned(lo, hi, t), p);\n }\n \n impure fn parse_arg(parser p) -> ast.arg {\n@@ -341,9 +479,9 @@ impure fn parse_seq[T](token.token bra,\n     ret spanned(lo, hi, v);\n }\n \n-impure fn parse_lit(parser p) -> option.t[ast.lit] {\n+impure fn parse_lit(parser p) -> ast.lit {\n     auto lo = p.get_span();\n-    let ast.lit_ lit;\n+    let ast.lit_ lit = ast.lit_nil;\n     alt (p.peek()) {\n         case (token.LIT_INT(?i)) {\n             p.bump();\n@@ -369,12 +507,11 @@ impure fn parse_lit(parser p) -> option.t[ast.lit] {\n             p.bump();\n             lit = ast.lit_str(s);\n         }\n-        case (_) {\n-            lit = ast.lit_nil;  // FIXME: typestate bug requires this\n-            ret none[ast.lit];\n+        case (?t) {\n+            unexpected(p, t);\n         }\n     }\n-    ret some(spanned(lo, lo, lit));\n+    ret spanned(lo, lo, lit);\n }\n \n fn is_ident(token.token t) -> bool {\n@@ -520,14 +657,37 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n \n         case (token.REC) {\n             p.bump();\n-            auto pf = parse_field;\n-            auto fs =\n-                parse_seq[ast.field](token.LPAREN,\n-                                     token.RPAREN,\n-                                     some(token.COMMA),\n-                                     pf, p);\n-            hi = fs.span;\n-            ex = ast.expr_rec(fs.node, ast.ann_none);\n+            expect(p, token.LPAREN);\n+            auto fields = vec(parse_field(p));\n+\n+            auto more = true;\n+            auto base = none[@ast.expr];\n+            while (more) {\n+                alt (p.peek()) {\n+                    case (token.RPAREN) {\n+                        hi = p.get_span();\n+                        p.bump();\n+                        more = false;\n+                    }\n+                    case (token.WITH) {\n+                        p.bump();\n+                        base = some[@ast.expr](parse_expr(p));\n+                        hi = p.get_span();\n+                        expect(p, token.RPAREN);\n+                        more = false;\n+                    }\n+                    case (token.COMMA) {\n+                        p.bump();\n+                        fields += parse_field(p);\n+                    }\n+                    case (?t) {\n+                        unexpected(p, t);\n+                    }\n+                }\n+\n+            }\n+\n+            ex = ast.expr_rec(fields, base, ast.ann_none);\n         }\n \n         case (token.BIND) {\n@@ -554,22 +714,124 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n             ex = ast.expr_bind(e, es.node, ast.ann_none);\n         }\n \n-        case (_) {\n-            alt (parse_lit(p)) {\n-                case (some[ast.lit](?lit)) {\n-                    hi = lit.span;\n-                    ex = ast.expr_lit(@lit, ast.ann_none);\n+        case (token.POUND) {\n+            p.bump();\n+            auto pth = parse_path(p, GREEDY);\n+            auto pf = parse_expr;\n+            auto es = parse_seq[@ast.expr](token.LPAREN,\n+                                           token.RPAREN,\n+                                           some(token.COMMA),\n+                                           pf, p);\n+            hi = es.span;\n+            ex = expand_syntax_ext(p, es.span, pth, es.node,\n+                                   none[@ast.expr]);\n+        }\n+\n+        case (token.FAIL) {\n+            p.bump();\n+            ex = ast.expr_fail;\n+        }\n+\n+        case (token.LOG) {\n+            p.bump();\n+            auto e = parse_expr(p);\n+            auto hi = e.span;\n+            ex = ast.expr_log(e);\n+        }\n+\n+        case (token.CHECK) {\n+            p.bump();\n+            alt (p.peek()) {\n+                case (token.LPAREN) {\n+                    auto e = parse_expr(p);\n+                    auto hi = e.span;\n+                    ex = ast.expr_check_expr(e);\n                 }\n-                case (none[ast.lit]) {\n-                    p.err(\"expecting expression\");\n+                case (_) {\n+                    p.get_session().unimpl(\"constraint-check stmt\");\n                 }\n             }\n         }\n+\n+        case (token.RET) {\n+            p.bump();\n+            alt (p.peek()) {\n+                case (token.SEMI) {\n+                    ex = ast.expr_ret(none[@ast.expr]);\n+                }\n+                case (_) {\n+                    auto e = parse_expr(p);\n+                    hi = e.span;\n+                    ex = ast.expr_ret(some[@ast.expr](e));\n+                }\n+            }\n+        }\n+\n+        case (token.PUT) {\n+            p.bump();\n+            alt (p.peek()) {\n+                case (token.SEMI) {\n+                    ex = ast.expr_put(none[@ast.expr]);\n+                }\n+                case (_) {\n+                    auto e = parse_expr(p);\n+                    hi = e.span;\n+                    ex = ast.expr_put(some[@ast.expr](e));\n+                }\n+            }\n+        }\n+\n+        case (token.BE) {\n+            p.bump();\n+            auto e = parse_expr(p);\n+            // FIXME: Is this the right place for this check?\n+            if /*check*/ (ast.is_call_expr(e)) {\n+                    hi = e.span;\n+                    ex = ast.expr_be(e);\n+            }\n+            else {\n+                p.err(\"Non-call expression in tail call\");\n+            }\n+        }\n+\n+        case (_) {\n+            auto lit = parse_lit(p);\n+            hi = lit.span;\n+            ex = ast.expr_lit(@lit, ast.ann_none);\n+        }\n     }\n \n     ret @spanned(lo, hi, ex);\n }\n \n+/*\n+ * FIXME: This is a crude approximation of the syntax-extension system,\n+ * for purposes of prototyping and/or hard-wiring any extensions we\n+ * wish to use while bootstrapping. The eventual aim is to permit\n+ * loading rust crates to process extensions, but this will likely\n+ * require a rust-based frontend, or an ocaml-FFI-based connection to\n+ * rust crates. At the moment we have neither.\n+ */\n+\n+impure fn expand_syntax_ext(parser p, ast.span sp,\n+                     &ast.path path, vec[@ast.expr] args,\n+                     option.t[@ast.expr] body) -> ast.expr_ {\n+\n+    check (_vec.len[ast.ident](path.node.idents) > 0u);\n+    auto extname = path.node.idents.(0);\n+    if (_str.eq(extname, \"fmt\")) {\n+        auto expanded = extfmt.expand_syntax_ext(args, body);\n+        auto newexpr = ast.expr_ext(path, args, body,\n+                                    expanded,\n+                                    ast.ann_none);\n+\n+        ret newexpr;\n+    } else {\n+        p.err(\"unknown syntax extension\");\n+        fail;\n+    }\n+}\n+\n impure fn extend_expr_by_ident(parser p, span lo, span hi,\n                                @ast.expr e, ast.ident i) -> @ast.expr {\n     auto e_ = e.node;\n@@ -705,151 +967,87 @@ impure fn parse_prefix_expr(parser p) -> @ast.expr {\n             ex = ast.expr_unary(ast.box, e, ast.ann_none);\n         }\n \n+        case (token.MUTABLE) {\n+            p.bump();\n+            auto e = parse_prefix_expr(p);\n+            hi = e.span;\n+            ex = ast.expr_unary(ast._mutable, e, ast.ann_none);\n+        }\n+\n         case (_) {\n             ret parse_dot_or_call_expr(p);\n         }\n     }\n     ret @spanned(lo, hi, ex);\n }\n \n-impure fn parse_binops(parser p,\n-                   (impure fn(parser) -> @ast.expr) sub,\n-                   vec[tup(token.binop, ast.binop)] ops)\n+type op_spec = rec(token.token tok, ast.binop op, int prec);\n+\n+// FIXME make this a const, don't store it in parser state\n+fn prec_table() -> vec[op_spec] {\n+    ret vec(rec(tok=token.BINOP(token.STAR), op=ast.mul, prec=11),\n+            rec(tok=token.BINOP(token.SLASH), op=ast.div, prec=11),\n+            rec(tok=token.BINOP(token.PERCENT), op=ast.rem, prec=11),\n+            rec(tok=token.BINOP(token.PLUS), op=ast.add, prec=10),\n+            rec(tok=token.BINOP(token.MINUS), op=ast.sub, prec=10),\n+            rec(tok=token.BINOP(token.LSL), op=ast.lsl, prec=9),\n+            rec(tok=token.BINOP(token.LSR), op=ast.lsr, prec=9),\n+            rec(tok=token.BINOP(token.ASR), op=ast.asr, prec=9),\n+            rec(tok=token.BINOP(token.AND), op=ast.bitand, prec=8),\n+            rec(tok=token.BINOP(token.CARET), op=ast.bitxor, prec=6),\n+            rec(tok=token.BINOP(token.OR), op=ast.bitor, prec=6),\n+            // ast.mul is a bogus placeholder here, AS is special\n+            // cased in parse_more_binops\n+            rec(tok=token.AS, op=ast.mul, prec=5),\n+            rec(tok=token.LT, op=ast.lt, prec=4),\n+            rec(tok=token.LE, op=ast.le, prec=4),\n+            rec(tok=token.GE, op=ast.ge, prec=4),\n+            rec(tok=token.GT, op=ast.gt, prec=4),\n+            rec(tok=token.EQEQ, op=ast.eq, prec=3),\n+            rec(tok=token.NE, op=ast.ne, prec=3),\n+            rec(tok=token.ANDAND, op=ast.and, prec=2),\n+            rec(tok=token.OROR, op=ast.or, prec=1));\n+}\n+\n+impure fn parse_binops(parser p) -> @ast.expr {\n+    ret parse_more_binops(p, parse_prefix_expr(p), 0);\n+}\n+\n+impure fn parse_more_binops(parser p, @ast.expr lhs, int min_prec)\n     -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n-    auto e = sub(p);\n-    auto more = true;\n-    while (more) {\n-        more = false;\n-        for (tup(token.binop, ast.binop) pair in ops) {\n-            alt (p.peek()) {\n-                case (token.BINOP(?op)) {\n-                    if (pair._0 == op) {\n-                        p.bump();\n-                        auto rhs = sub(p);\n-                        hi = rhs.span;\n-                        auto exp = ast.expr_binary(pair._1, e, rhs,\n-                                                   ast.ann_none);\n-                        e = @spanned(lo, hi, exp);\n-                        more = true;\n-                    }\n-                }\n-                case (_) { /* fall through */ }\n-            }\n-        }\n+    // Magic nonsense to work around rustboot bug\n+    fn op_eq(token.token a, token.token b) -> bool {\n+        if (a == b) {ret true;}\n+        else {ret false;}\n     }\n-    ret e;\n-}\n-\n-impure fn parse_binary_exprs(parser p,\n-                            (impure fn(parser) -> @ast.expr) sub,\n-                            vec[tup(token.token, ast.binop)] ops)\n-    -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n-    auto e = sub(p);\n-    auto more = true;\n-    while (more) {\n-        more = false;\n-        for (tup(token.token, ast.binop) pair in ops) {\n-            if (pair._0 == p.peek()) {\n-                p.bump();\n-                auto rhs = sub(p);\n-                hi = rhs.span;\n-                auto exp = ast.expr_binary(pair._1, e, rhs, ast.ann_none);\n-                e = @spanned(lo, hi, exp);\n-                more = true;\n-            }\n-        }\n-    }\n-    ret e;\n-}\n-\n-impure fn parse_factor_expr(parser p) -> @ast.expr {\n-    auto sub = parse_prefix_expr;\n-    ret parse_binops(p, sub, vec(tup(token.STAR, ast.mul),\n-                                 tup(token.SLASH, ast.div),\n-                                 tup(token.PERCENT, ast.rem)));\n-}\n-\n-impure fn parse_term_expr(parser p) -> @ast.expr {\n-    auto sub = parse_factor_expr;\n-    ret parse_binops(p, sub, vec(tup(token.PLUS, ast.add),\n-                                 tup(token.MINUS, ast.sub)));\n-}\n-\n-impure fn parse_shift_expr(parser p) -> @ast.expr {\n-    auto sub = parse_term_expr;\n-    ret parse_binops(p, sub, vec(tup(token.LSL, ast.lsl),\n-                                 tup(token.LSR, ast.lsr),\n-                                 tup(token.ASR, ast.asr)));\n-}\n-\n-impure fn parse_bitand_expr(parser p) -> @ast.expr {\n-    auto sub = parse_shift_expr;\n-    ret parse_binops(p, sub, vec(tup(token.AND, ast.bitand)));\n-}\n-\n-impure fn parse_bitxor_expr(parser p) -> @ast.expr {\n-    auto sub = parse_bitand_expr;\n-    ret parse_binops(p, sub, vec(tup(token.CARET, ast.bitxor)));\n-}\n-\n-impure fn parse_bitor_expr(parser p) -> @ast.expr {\n-    auto sub = parse_bitxor_expr;\n-    ret parse_binops(p, sub, vec(tup(token.OR, ast.bitor)));\n-}\n-\n-impure fn parse_cast_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto e = parse_bitor_expr(p);\n-    auto hi = e.span;\n-    while (true) {\n-        alt (p.peek()) {\n-            case (token.AS) {\n-                p.bump();\n-                auto t = parse_ty(p);\n-                hi = t.span;\n-                e = @spanned(lo, hi, ast.expr_cast(e, t, ast.ann_none));\n-            }\n-\n-            case (_) {\n-                ret e;\n+    auto peeked = p.peek();\n+    for (op_spec cur in p.get_prec_table()) {\n+        if (cur.prec > min_prec && op_eq(cur.tok, peeked)) {\n+            p.bump();\n+            alt (cur.tok) {\n+                case (token.AS) {\n+                    auto rhs = parse_ty(p);\n+                    auto _as = ast.expr_cast(lhs, rhs, ast.ann_none);\n+                    auto span = @spanned(lhs.span, rhs.span, _as);\n+                    ret parse_more_binops(p, span, min_prec);\n+                }\n+                case (_) {\n+                    auto rhs = parse_more_binops(p, parse_prefix_expr(p),\n+                                                 cur.prec);\n+                    auto bin = ast.expr_binary(cur.op, lhs, rhs,\n+                                               ast.ann_none);\n+                    auto span = @spanned(lhs.span, rhs.span, bin);\n+                    ret parse_more_binops(p, span, min_prec);\n+                }\n             }\n         }\n     }\n-    ret e;\n-}\n-\n-impure fn parse_relational_expr(parser p) -> @ast.expr {\n-    auto sub = parse_cast_expr;\n-    ret parse_binary_exprs(p, sub, vec(tup(token.LT, ast.lt),\n-                                       tup(token.LE, ast.le),\n-                                       tup(token.GE, ast.ge),\n-                                       tup(token.GT, ast.gt)));\n-}\n-\n-\n-impure fn parse_equality_expr(parser p) -> @ast.expr {\n-    auto sub = parse_relational_expr;\n-    ret parse_binary_exprs(p, sub, vec(tup(token.EQEQ, ast.eq),\n-                                       tup(token.NE, ast.ne)));\n-}\n-\n-impure fn parse_and_expr(parser p) -> @ast.expr {\n-    auto sub = parse_equality_expr;\n-    ret parse_binary_exprs(p, sub, vec(tup(token.ANDAND, ast.and)));\n-}\n-\n-impure fn parse_or_expr(parser p) -> @ast.expr {\n-    auto sub = parse_and_expr;\n-    ret parse_binary_exprs(p, sub, vec(tup(token.OROR, ast.or)));\n+    ret lhs;\n }\n \n impure fn parse_assign_expr(parser p) -> @ast.expr {\n     auto lo = p.get_span();\n-    auto lhs = parse_or_expr(p);\n+    auto lhs = parse_binops(p);\n     alt (p.peek()) {\n         case (token.EQ) {\n             p.bump();\n@@ -901,6 +1099,7 @@ impure fn parse_if_expr(parser p) -> @ast.expr {\n         }\n         case (_) { /* fall through */ }\n     }\n+\n     ret @spanned(lo, hi, ast.expr_if(cond, thn, els, ast.ann_none));\n }\n \n@@ -935,8 +1134,14 @@ impure fn parse_head_local(parser p) -> @ast.decl {\n impure fn parse_for_expr(parser p) -> @ast.expr {\n     auto lo = p.get_span();\n     auto hi = lo;\n+    auto is_each = false;\n \n     expect(p, token.FOR);\n+    if (p.peek() == token.EACH) {\n+        is_each = true;\n+        p.bump();\n+    }\n+\n     expect (p, token.LPAREN);\n \n     auto decl = parse_head_local(p);\n@@ -946,9 +1151,16 @@ impure fn parse_for_expr(parser p) -> @ast.expr {\n     expect(p, token.RPAREN);\n     auto body = parse_block(p);\n     hi = body.span;\n-    ret @spanned(lo, hi, ast.expr_for(decl, seq, body, ast.ann_none));\n+    if (is_each) {\n+        ret @spanned(lo, hi, ast.expr_for_each(decl, seq, body,\n+                                               ast.ann_none));\n+    } else {\n+        ret @spanned(lo, hi, ast.expr_for(decl, seq, body,\n+                                          ast.ann_none));\n+    }\n }\n \n+\n impure fn parse_while_expr(parser p) -> @ast.expr {\n     auto lo = p.get_span();\n     auto hi = lo;\n@@ -996,6 +1208,23 @@ impure fn parse_alt_expr(parser p) -> @ast.expr {\n                 auto block = parse_block(p);\n                 arms += vec(rec(pat=pat, block=block, index=index));\n             }\n+\n+            // FIXME: this is a vestigial form left over from\n+            // rustboot, we're keeping it here for source-compat\n+            // for the time being but it should be flushed out\n+            // once we've bootstrapped. When we see 'else {' here,\n+            // we pretend we saw 'case (_) {'. It has the same\n+            // meaning, and only exists due to the cexp/pexp split\n+            // in rustboot, which we're not maintaining.\n+\n+            case (token.ELSE) {\n+                p.bump();\n+                auto hi = p.get_span();\n+                auto pat = @spanned(lo, hi, ast.pat_wild(ast.ann_none));\n+                auto index = index_arm(pat);\n+                auto block = parse_block(p);\n+                arms += vec(rec(pat=pat, block=block, index=index));\n+            }\n             case (token.RBRACE) { /* empty */ }\n             case (?tok) {\n                 p.err(\"expected 'case' or '}' when parsing 'alt' statement \" +\n@@ -1062,17 +1291,20 @@ impure fn parse_initializer(parser p) -> option.t[@ast.expr] {\n \n impure fn parse_pat(parser p) -> @ast.pat {\n     auto lo = p.get_span();\n+    auto hi = lo;\n+    auto pat;\n \n-    auto pat = ast.pat_wild(ast.ann_none);  // FIXME: typestate bug\n     alt (p.peek()) {\n         case (token.UNDERSCORE) {\n+            hi = p.get_span();\n             p.bump();\n             pat = ast.pat_wild(ast.ann_none);\n         }\n         case (token.QUES) {\n             p.bump();\n             alt (p.peek()) {\n                 case (token.IDENT(?id)) {\n+                    hi = p.get_span();\n                     p.bump();\n                     pat = ast.pat_bind(id, p.next_def_id(), ast.ann_none);\n                 }\n@@ -1085,27 +1317,30 @@ impure fn parse_pat(parser p) -> @ast.pat {\n         }\n         case (token.IDENT(?id)) {\n             auto tag_path = parse_path(p, GREEDY);\n+            hi = tag_path.span;\n \n             let vec[@ast.pat] args;\n             alt (p.peek()) {\n                 case (token.LPAREN) {\n                     auto f = parse_pat;\n-                    args = parse_seq[@ast.pat](token.LPAREN, token.RPAREN,\n-                                               some(token.COMMA), f, p).node;\n+                    auto a = parse_seq[@ast.pat](token.LPAREN, token.RPAREN,\n+                                                 some(token.COMMA), f, p);\n+                    args = a.node;\n+                    hi = a.span;\n                 }\n                 case (_) { args = vec(); }\n             }\n \n             pat = ast.pat_tag(tag_path, args, none[ast.variant_def],\n                               ast.ann_none);\n         }\n-        case (?tok) {\n-            p.err(\"expected pattern but found \" + token.to_str(tok));\n-            fail;\n+        case (_) {\n+            auto lit = parse_lit(p);\n+            hi = lit.span;\n+            pat = ast.pat_lit(@lit, ast.ann_none);\n         }\n     }\n \n-    auto hi = p.get_span();\n     ret @spanned(lo, hi, pat);\n }\n \n@@ -1147,49 +1382,22 @@ impure fn parse_auto(parser p) -> @ast.decl {\n }\n \n impure fn parse_stmt(parser p) -> @ast.stmt {\n-    auto lo = p.get_span();\n-    alt (p.peek()) {\n-\n-        case (token.LOG) {\n-            p.bump();\n-            auto e = parse_expr(p);\n-            auto hi = p.get_span();\n-            ret @spanned(lo, hi, ast.stmt_log(e));\n-        }\n-\n-        case (token.CHECK) {\n-            p.bump();\n-            alt (p.peek()) {\n-                case (token.LPAREN) {\n-                    auto e = parse_expr(p);\n-                    auto hi = p.get_span();\n-                    ret @spanned(lo, hi, ast.stmt_check_expr(e));\n-                }\n-                case (_) {\n-                    p.get_session().unimpl(\"constraint-check stmt\");\n-                }\n-            }\n-        }\n+    if (p.get_file_type() == SOURCE_FILE) {\n+        ret parse_source_stmt(p);\n+    } else {\n+        ret parse_crate_stmt(p);\n+    }\n+}\n \n-        case (token.FAIL) {\n-            p.bump();\n-            ret @spanned(lo, p.get_span(), ast.stmt_fail);\n-        }\n+impure fn parse_crate_stmt(parser p) -> @ast.stmt {\n+    auto cdir = parse_crate_directive(p);\n+    ret @spanned(cdir.span, cdir.span,\n+                 ast.stmt_crate_directive(@cdir));\n+}\n \n-        case (token.RET) {\n-            p.bump();\n-            alt (p.peek()) {\n-                case (token.SEMI) {\n-                    ret @spanned(lo, p.get_span(),\n-                                 ast.stmt_ret(none[@ast.expr]));\n-                }\n-                case (_) {\n-                    auto e = parse_expr(p);\n-                    ret @spanned(lo, e.span,\n-                                 ast.stmt_ret(some[@ast.expr](e)));\n-                }\n-            }\n-        }\n+impure fn parse_source_stmt(parser p) -> @ast.stmt {\n+    auto lo = p.get_span();\n+    alt (p.peek()) {\n \n         case (token.LET) {\n             auto decl = parse_let(p);\n@@ -1260,38 +1468,36 @@ fn index_block(vec[@ast.stmt] stmts, option.t[@ast.expr] expr) -> ast.block_ {\n     auto index = new_str_hash[uint]();\n     auto u = 0u;\n     for (@ast.stmt s in stmts) {\n-        // FIXME: typestate bug requires we do this up top, not\n-        // down below loop. Sigh.\n-        u += 1u;\n         alt (s.node) {\n             case (ast.stmt_decl(?d)) {\n                 alt (d.node) {\n                     case (ast.decl_local(?loc)) {\n-                        index.insert(loc.ident, u-1u);\n+                        index.insert(loc.ident, u);\n                     }\n                     case (ast.decl_item(?it)) {\n                         alt (it.node) {\n                             case (ast.item_fn(?i, _, _, _, _)) {\n-                                index.insert(i, u-1u);\n+                                index.insert(i, u);\n                             }\n                             case (ast.item_mod(?i, _, _)) {\n-                                index.insert(i, u-1u);\n+                                index.insert(i, u);\n                             }\n                             case (ast.item_ty(?i, _, _, _, _)) {\n-                                index.insert(i, u-1u);\n+                                index.insert(i, u);\n                             }\n                             case (ast.item_tag(?i, _, _, _)) {\n-                                index.insert(i, u-1u);\n+                                index.insert(i, u);\n                             }\n                             case (ast.item_obj(?i, _, _, _, _)) {\n-                                index.insert(i, u-1u);\n+                                index.insert(i, u);\n                             }\n                         }\n                     }\n                 }\n             }\n             case (_) { /* fall through */ }\n         }\n+        u += 1u;\n     }\n     ret rec(stmts=stmts, expr=expr, index=index);\n }\n@@ -1301,6 +1507,7 @@ fn index_arm(@ast.pat pat) -> hashmap[ast.ident,ast.def_id] {\n         alt (pat.node) {\n             case (ast.pat_bind(?i, ?def_id, _)) { index.insert(i, def_id); }\n             case (ast.pat_wild(_)) { /* empty */ }\n+            case (ast.pat_lit(_, _)) { /* empty */ }\n             case (ast.pat_tag(_, ?pats, _, _)) {\n                 for (@ast.pat p in pats) {\n                     do_index_arm(index, p);\n@@ -1330,34 +1537,40 @@ fn stmt_ends_with_semi(@ast.stmt stmt) -> bool {\n                 case (ast.decl_item(_)) { ret false; }\n             }\n         }\n-        case (ast.stmt_ret(_))                  { ret true; }\n-        case (ast.stmt_log(_))                  { ret true; }\n-        case (ast.stmt_check_expr(_))           { ret true; }\n-        case (ast.stmt_fail)                    { ret true; }\n         case (ast.stmt_expr(?e)) {\n             alt (e.node) {\n                 case (ast.expr_vec(_,_))        { ret true; }\n                 case (ast.expr_tup(_,_))        { ret true; }\n-                case (ast.expr_rec(_,_))        { ret true; }\n+                case (ast.expr_rec(_,_,_))      { ret true; }\n                 case (ast.expr_call(_,_,_))     { ret true; }\n                 case (ast.expr_binary(_,_,_,_)) { ret true; }\n                 case (ast.expr_unary(_,_,_))    { ret true; }\n                 case (ast.expr_lit(_,_))        { ret true; }\n                 case (ast.expr_cast(_,_,_))     { ret true; }\n                 case (ast.expr_if(_,_,_,_))     { ret false; }\n                 case (ast.expr_for(_,_,_,_))    { ret false; }\n+                case (ast.expr_for_each(_,_,_,_))\n+                    { ret false; }\n                 case (ast.expr_while(_,_,_))    { ret false; }\n                 case (ast.expr_do_while(_,_,_)) { ret false; }\n                 case (ast.expr_alt(_,_,_))      { ret false; }\n                 case (ast.expr_block(_,_))      { ret false; }\n                 case (ast.expr_assign(_,_,_))   { ret true; }\n                 case (ast.expr_assign_op(_,_,_,_))\n-                                                { ret true; }\n+                    { ret true; }\n                 case (ast.expr_field(_,_,_))    { ret true; }\n                 case (ast.expr_index(_,_,_))    { ret true; }\n                 case (ast.expr_path(_,_,_))     { ret true; }\n+                case (ast.expr_fail)            { ret true; }\n+                case (ast.expr_ret(_))          { ret true; }\n+                case (ast.expr_put(_))          { ret true; }\n+                case (ast.expr_be(_))           { ret true; }\n+                case (ast.expr_log(_))          { ret true; }\n+                case (ast.expr_check_expr(_))   { ret true; }\n             }\n         }\n+        // We should not be calling this on a cdir.\n+        case (ast.stmt_crate_directive(?cdir))  { fail; }\n     }\n }\n \n@@ -1401,8 +1614,13 @@ impure fn parse_block(parser p) -> ast.block {\n                     case (none[@ast.expr]) {\n                         // Not an expression statement.\n                         stmts += vec(stmt);\n-                        if (stmt_ends_with_semi(stmt)) {\n-                            expect(p, token.SEMI);\n+                        // FIXME: crazy differentiation between conditions\n+                        // used in branches and binary expressions in rustboot\n+                        // means we cannot use && here. I know, right?\n+                        if (p.get_file_type() == SOURCE_FILE) {\n+                            if (stmt_ends_with_semi(stmt)) {\n+                                expect(p, token.SEMI);\n+                            }\n                         }\n                     }\n                 }\n@@ -1432,7 +1650,7 @@ impure fn parse_ty_params(parser p) -> vec[ast.ty_param] {\n     ret ty_params;\n }\n \n-impure fn parse_fn(parser p, ast.effect eff, bool is_iter) -> ast._fn {\n+impure fn parse_fn_decl(parser p, ast.effect eff) -> ast.fn_decl {\n     auto pf = parse_arg;\n     let util.common.spanned[vec[ast.arg]] inputs =\n         // FIXME: passing parse_arg as an lval doesn't work at the\n@@ -1444,34 +1662,41 @@ impure fn parse_fn(parser p, ast.effect eff, bool is_iter) -> ast._fn {\n          pf, p);\n \n     let @ast.ty output;\n+\n+    // FIXME: dropping constrs on the floor at the moment.\n+    // pick them up when they're used by typestate pass.\n+    parse_constrs(p);\n+\n     if (p.peek() == token.RARROW) {\n         p.bump();\n         output = parse_ty(p);\n     } else {\n         output = @spanned(inputs.span, inputs.span, ast.ty_nil);\n     }\n+    ret rec(effect=eff, inputs=inputs.node, output=output);\n+}\n \n+impure fn parse_fn(parser p, ast.effect eff, ast.proto proto) -> ast._fn {\n+    auto decl = parse_fn_decl(p, eff);\n     auto body = parse_block(p);\n-\n-    ret rec(effect = eff,\n-            is_iter = is_iter,\n-            inputs = inputs.node,\n-            output = output,\n+    ret rec(decl = decl,\n+            proto = proto,\n             body = body);\n }\n \n-impure fn parse_item_fn_or_iter(parser p, ast.effect eff,\n-                                bool is_iter) -> @ast.item {\n-    auto lo = p.get_span();\n-    if (is_iter) {\n-        expect(p, token.ITER);\n-    } else {\n-        expect(p, token.FN);\n-    }\n+impure fn parse_fn_header(parser p)\n+    -> tup(ast.ident, vec[ast.ty_param]) {\n     auto id = parse_ident(p);\n     auto ty_params = parse_ty_params(p);\n-    auto f = parse_fn(p, eff, is_iter);\n-    auto item = ast.item_fn(id, f, ty_params,\n+    ret tup(id, ty_params);\n+}\n+\n+impure fn parse_item_fn_or_iter(parser p, ast.effect eff) -> @ast.item {\n+    auto lo = p.get_span();\n+    auto proto = parse_proto(p);\n+    auto t = parse_fn_header(p);\n+    auto f = parse_fn(p, eff, proto);\n+    auto item = ast.item_fn(t._0, f, t._1,\n                             p.next_def_id(), ast.ann_none);\n     ret @spanned(lo, f.body.span, item);\n }\n@@ -1486,14 +1711,9 @@ impure fn parse_obj_field(parser p) -> ast.obj_field {\n impure fn parse_method(parser p) -> @ast.method {\n     auto lo = p.get_span();\n     auto eff = parse_effect(p);\n-    auto is_iter = false;\n-    alt (p.peek()) {\n-        case (token.FN) { p.bump(); }\n-        case (token.ITER) { p.bump(); is_iter = true; }\n-        case (?t) { unexpected(p, t); }\n-    }\n+    auto proto = parse_proto(p);\n     auto ident = parse_ident(p);\n-    auto f = parse_fn(p, eff, is_iter);\n+    auto f = parse_fn(p, eff, proto);\n     auto meth = rec(ident=ident, meth=f,\n                     id=p.next_def_id(), ann=ast.ann_none);\n     ret @spanned(lo, f.body.span, meth);\n@@ -1512,21 +1732,33 @@ impure fn parse_item_obj(parser p, ast.layer lyr) -> @ast.item {\n          some(token.COMMA),\n          pf, p);\n \n-    auto pm = parse_method;\n-    let util.common.spanned[vec[@ast.method]] meths =\n-        parse_seq[@ast.method]\n-        (token.LBRACE,\n-         token.RBRACE,\n-         none[token.token],\n-         pm, p);\n+    let vec[@ast.method] meths = vec();\n+    let option.t[ast.block] dtor = none[ast.block];\n+\n+    expect(p, token.LBRACE);\n+    while (p.peek() != token.RBRACE) {\n+        alt (p.peek()) {\n+            case (token.DROP) {\n+                p.bump();\n+                dtor = some[ast.block](parse_block(p));\n+            }\n+            case (_) {\n+                append[@ast.method](meths,\n+                                    parse_method(p));\n+            }\n+        }\n+    }\n+    auto hi = p.get_span();\n+    expect(p, token.RBRACE);\n \n     let ast._obj ob = rec(fields=fields.node,\n-                          methods=meths.node);\n+                          methods=meths,\n+                          dtor=dtor);\n \n     auto item = ast.item_obj(ident, ob, ty_params,\n                              p.next_def_id(), ast.ann_none);\n \n-    ret @spanned(lo, meths.span, item);\n+    ret @spanned(lo, hi, item);\n }\n \n impure fn parse_mod_items(parser p, token.token term) -> ast._mod {\n@@ -1568,18 +1800,127 @@ impure fn parse_item_mod(parser p) -> @ast.item {\n     ret @spanned(lo, hi, item);\n }\n \n-impure fn parse_item_type(parser p) -> @ast.item {\n+impure fn parse_item_native_type(parser p) -> @ast.native_item {\n+    auto t = parse_type_decl(p);\n+    auto hi = p.get_span();\n+    expect(p, token.SEMI);\n+    auto item = ast.native_item_ty(t._1, p.next_def_id());\n+    ret @spanned(t._0, hi, item);\n+}\n+\n+impure fn parse_item_native_fn(parser p, ast.effect eff) -> @ast.native_item {\n+    auto lo = p.get_span();\n+    expect(p, token.FN);\n+    auto t = parse_fn_header(p);\n+    auto decl = parse_fn_decl(p, eff);\n+    auto hi = p.get_span();\n+    expect(p, token.SEMI);\n+    auto item = ast.native_item_fn(t._0, decl, t._1, p.next_def_id(),\n+                                   ast.ann_none);\n+    ret @spanned(lo, hi, item);\n+}\n+\n+impure fn parse_native_item(parser p) -> @ast.native_item {\n+    let ast.effect eff = parse_effect(p);\n+    let ast.opacity opa = parse_opacity(p);\n+    let ast.layer lyr = parse_layer(p);\n+    alt (p.peek()) {\n+        case (token.TYPE) {\n+            ret parse_item_native_type(p);\n+        }\n+        case (token.FN) {\n+            ret parse_item_native_fn(p, eff);\n+        }\n+        case (?t) {\n+            unexpected(p, t);\n+            fail;\n+        }\n+    }\n+}\n+\n+impure fn parse_native_mod_items(parser p,\n+                                 str native_name,\n+                                 ast.native_abi abi) -> ast.native_mod {\n+    auto index = new_str_hash[ast.native_mod_index_entry]();\n+    let vec[@ast.native_item] items = vec();\n+\n+    auto view_items = parse_native_view(p, index);\n+\n+    while (p.peek() != token.RBRACE) {\n+        auto item = parse_native_item(p);\n+        items += vec(item);\n+\n+        // Index the item.\n+        ast.index_native_item(index, item);\n+    }\n+    ret rec(native_name=native_name, abi=abi,\n+            view_items=view_items,\n+            items=items,\n+            index=index);\n+}\n+\n+fn default_native_name(session.session sess, str id) -> str {\n+    alt (sess.get_targ_cfg().os) {\n+        case (session.os_win32) {\n+            ret id + \".dll\";\n+        }\n+        case (session.os_macos) {\n+            ret \"lib\" + id + \".dylib\";\n+        }\n+        case (session.os_linux) {\n+            ret \"lib\" + id + \".so\";\n+        }\n+    }\n+}\n+\n+impure fn parse_item_native_mod(parser p) -> @ast.item {\n+    auto lo = p.get_span();\n+    expect(p, token.NATIVE);\n+    auto abi = ast.native_abi_cdecl;\n+    if (p.peek() != token.MOD) {\n+        auto t = parse_str_lit_or_env_ident(p);\n+        if (_str.eq(t, \"cdecl\")) {\n+        } else if (_str.eq(t, \"rust\")) {\n+            abi = ast.native_abi_rust;\n+        } else {\n+            p.err(\"unsupported abi: \" + t);\n+            fail;\n+        }\n+    }\n+    expect(p, token.MOD);\n+    auto id = parse_ident(p);\n+    auto native_name;\n+    if (p.peek() == token.EQ) {\n+        expect(p, token.EQ);\n+        native_name = parse_str_lit_or_env_ident(p);\n+    } else {\n+        native_name = default_native_name(p.get_session(), id);\n+    }\n+    expect(p, token.LBRACE);\n+    auto m = parse_native_mod_items(p, native_name, abi);\n+    auto hi = p.get_span();\n+    expect(p, token.RBRACE);\n+    auto item = ast.item_native_mod(id, m, p.next_def_id());\n+    ret @spanned(lo, hi, item);\n+}\n+\n+impure fn parse_type_decl(parser p) -> tup(span, ast.ident) {\n     auto lo = p.get_span();\n     expect(p, token.TYPE);\n     auto id = parse_ident(p);\n+    ret tup(lo, id);\n+}\n+\n+impure fn parse_item_type(parser p) -> @ast.item {\n+    auto t = parse_type_decl(p);\n     auto tps = parse_ty_params(p);\n \n     expect(p, token.EQ);\n     auto ty = parse_ty(p);\n     auto hi = p.get_span();\n     expect(p, token.SEMI);\n-    auto item = ast.item_ty(id, ty, tps, p.next_def_id(), ast.ann_none);\n-    ret @spanned(lo, hi, item);\n+    auto item = ast.item_ty(t._1, ty, tps, p.next_def_id(), ast.ann_none);\n+    ret @spanned(t._0, hi, item);\n }\n \n impure fn parse_item_tag(parser p) -> @ast.item {\n@@ -1631,6 +1972,19 @@ impure fn parse_item_tag(parser p) -> @ast.item {\n     ret @spanned(lo, hi, item);\n }\n \n+impure fn parse_opacity(parser p) -> ast.opacity {\n+    alt (p.peek()) {\n+        case (token.ABS) {\n+            p.bump();\n+            ret ast.op_abstract;\n+        }\n+        case (_) {\n+            ret ast.op_transparent;\n+        }\n+    }\n+    fail;\n+}\n+\n impure fn parse_layer(parser p) -> ast.layer {\n     alt (p.peek()) {\n         case (token.STATE) {\n@@ -1686,6 +2040,7 @@ fn peeking_at_item(parser p) -> bool {\n \n impure fn parse_item(parser p) -> @ast.item {\n     let ast.effect eff = parse_effect(p);\n+    let ast.opacity opa = parse_opacity(p);\n     let ast.layer lyr = parse_layer(p);\n \n     alt (p.peek()) {\n@@ -1697,17 +2052,22 @@ impure fn parse_item(parser p) -> @ast.item {\n \n         case (token.FN) {\n             check (lyr == ast.layer_value);\n-            ret parse_item_fn_or_iter(p, eff, false);\n+            ret parse_item_fn_or_iter(p, eff);\n         }\n         case (token.ITER) {\n             check (lyr == ast.layer_value);\n-            ret parse_item_fn_or_iter(p, eff, true);\n+            ret parse_item_fn_or_iter(p, eff);\n         }\n         case (token.MOD) {\n             check (eff == ast.eff_pure);\n             check (lyr == ast.layer_value);\n             ret parse_item_mod(p);\n         }\n+        case (token.NATIVE) {\n+            check (eff == ast.eff_pure);\n+            check (lyr == ast.layer_value);\n+            ret parse_item_native_mod(p);\n+        }\n         case (token.TYPE) {\n             check (eff == ast.eff_pure);\n             ret parse_item_type(p);\n@@ -1840,38 +2200,63 @@ impure fn parse_import(parser p) -> @ast.view_item {\n     fail;\n }\n \n-impure fn parse_use_or_import(parser p) -> @ast.view_item {\n+impure fn parse_export(parser p) -> @ast.view_item {\n+    auto lo = p.get_span();\n+    expect(p, token.EXPORT);\n+    auto id = parse_ident(p);\n+    auto hi = p.get_span();\n+    expect(p, token.SEMI);\n+    ret @spanned(lo, hi, ast.view_item_export(id));\n+}\n+\n+impure fn parse_view_item(parser p) -> @ast.view_item {\n     alt (p.peek()) {\n         case (token.USE) {\n             ret parse_use(p);\n         }\n         case (token.IMPORT) {\n             ret parse_import(p);\n         }\n+        case (token.EXPORT) {\n+            ret parse_export(p);\n+        }\n     }\n }\n \n-fn is_use_or_import(token.token t) -> bool {\n-    if (t == token.USE) {\n-        ret true;\n-    }\n-    if (t == token.IMPORT) {\n-        ret true;\n+fn is_view_item(token.token t) -> bool {\n+    alt (t) {\n+        case (token.USE) { ret true; }\n+        case (token.IMPORT) { ret true; }\n+        case (token.EXPORT) { ret true; }\n+        case (_) {}\n     }\n     ret false;\n }\n \n impure fn parse_view(parser p, ast.mod_index index) -> vec[@ast.view_item] {\n     let vec[@ast.view_item] items = vec();\n-    while (is_use_or_import(p.peek())) {\n-        auto item = parse_use_or_import(p);\n+    while (is_view_item(p.peek())) {\n+        auto item = parse_view_item(p);\n         items += vec(item);\n \n         ast.index_view_item(index, item);\n     }\n     ret items;\n }\n \n+impure fn parse_native_view(parser p, ast.native_mod_index index)\n+    -> vec[@ast.view_item] {\n+    let vec[@ast.view_item] items = vec();\n+    while (is_view_item(p.peek())) {\n+        auto item = parse_view_item(p);\n+        items += vec(item);\n+\n+        ast.index_native_view_item(index, item);\n+    }\n+    ret items;\n+}\n+\n+\n impure fn parse_crate_from_source_file(parser p) -> @ast.crate {\n     auto lo = p.get_span();\n     auto hi = lo;\n@@ -1885,33 +2270,46 @@ impure fn parse_crate_from_source_file(parser p) -> @ast.crate {\n //\n // Each directive imperatively extends its environment with 0 or more items.\n \n-impure fn parse_crate_directive(str prefix, parser p,\n-                                &mutable vec[@ast.item] items,\n-                                hashmap[ast.ident,ast.mod_index_entry] index)\n+impure fn parse_crate_directive(parser p) -> ast.crate_directive\n {\n     auto lo = p.get_span();\n     auto hi = lo;\n     alt (p.peek()) {\n-        case (token.CONST) {\n-            auto c = parse_item_const(p);\n-            ast.index_item(index, c);\n-            append[@ast.item](items, c);\n-         }\n+        case (token.AUTH) {\n+            // FIXME: currently dropping auth clauses on the floor,\n+            // as there is no effect-checking pass.\n+            p.bump();\n+            auto n = parse_path(p, GREEDY);\n+            expect(p, token.EQ);\n+            auto e = parse_effect(p);\n+            hi = p.get_span();\n+            expect(p, token.SEMI);\n+            ret spanned(lo, hi, ast.cdir_auth(n, e));\n+        }\n+\n+        case (token.META) {\n+            // FIXME: currently dropping meta clauses on the floor,\n+            // as there is no crate metadata system\n+            p.bump();\n+            auto mis = parse_meta(p);\n+            hi = p.get_span();\n+            expect(p, token.SEMI);\n+            ret spanned(lo, hi, ast.cdir_meta(mis));\n+        }\n+\n         case (token.MOD) {\n             p.bump();\n             auto id = parse_ident(p);\n-            auto file_path = id;\n+            auto file_opt = none[filename];\n             alt (p.peek()) {\n                 case (token.EQ) {\n                     p.bump();\n                     // FIXME: turn this into parse+eval expr\n-                    file_path = parse_str_lit(p);\n+                    file_opt = some[filename](parse_str_lit_or_env_ident(p));\n                 }\n                 case (_) {}\n             }\n \n-            // dir-qualify file path.\n-            auto full_path = prefix + std.os.path_sep() + file_path;\n \n             alt (p.peek()) {\n \n@@ -1920,58 +2318,84 @@ impure fn parse_crate_directive(str prefix, parser p,\n                 case (token.SEMI) {\n                     hi = p.get_span();\n                     p.bump();\n-                    if (!_str.ends_with(full_path, \".rs\")) {\n-                        full_path += \".rs\";\n-                    }\n-                    auto p0 = new_parser(p.get_session(), 0, full_path);\n-                    auto m0 = parse_mod_items(p0, token.EOF);\n-                    auto im = ast.item_mod(id, m0, p.next_def_id());\n-                    auto i = @spanned(lo, hi, im);\n-                    ast.index_item(index, i);\n-                    append[@ast.item](items, i);\n+                    ret spanned(lo, hi, ast.cdir_src_mod(id, file_opt));\n                 }\n \n                 // mod x = \"foo_dir\" { ...directives... }\n \n                 case (token.LBRACE) {\n                     p.bump();\n-                    auto m0 = parse_crate_directives(full_path, p,\n-                                                     token.RBRACE);\n+                    auto cdirs = parse_crate_directives(p, token.RBRACE);\n                     hi = p.get_span();\n                     expect(p, token.RBRACE);\n-                    auto im = ast.item_mod(id, m0, p.next_def_id());\n-                    auto i = @spanned(lo, hi, im);\n-                    ast.index_item(index, i);\n-                    append[@ast.item](items, i);\n+                    ret spanned(lo, hi,\n+                                ast.cdir_dir_mod(id, file_opt, cdirs));\n                 }\n \n                 case (?t) {\n                     unexpected(p, t);\n                 }\n             }\n         }\n+\n+        case (token.LET) {\n+            p.bump();\n+            expect(p, token.LPAREN);\n+            auto id = parse_ident(p);\n+            expect(p, token.EQ);\n+            auto x = parse_expr(p);\n+            expect(p, token.RPAREN);\n+            expect(p, token.LBRACE);\n+            auto v = parse_crate_directives(p, token.RBRACE);\n+            hi = p.get_span();\n+            expect(p, token.RBRACE);\n+            ret spanned(lo, hi, ast.cdir_let(id, x, v));\n+        }\n+\n+        case (token.USE) {\n+            auto vi = parse_view_item(p);\n+            ret spanned(lo, vi.span, ast.cdir_view_item(vi));\n+        }\n+\n+        case (token.IMPORT) {\n+            auto vi = parse_view_item(p);\n+            ret spanned(lo, vi.span, ast.cdir_view_item(vi));\n+        }\n+\n+        case (token.EXPORT) {\n+            auto vi = parse_view_item(p);\n+            ret spanned(lo, vi.span, ast.cdir_view_item(vi));\n+        }\n+\n+        case (_) {\n+            auto x = parse_expr(p);\n+            ret spanned(lo, x.span, ast.cdir_expr(x));\n+        }\n     }\n+    fail;\n }\n \n-impure fn parse_crate_directives(str prefix, parser p,\n-                                 token.token term) -> ast._mod {\n-    auto index = new_str_hash[ast.mod_index_entry]();\n-    auto view_items = parse_view(p, index);\n \n-    let vec[@ast.item] items = vec();\n+impure fn parse_crate_directives(parser p, token.token term)\n+    -> vec[@ast.crate_directive] {\n+\n+    let vec[@ast.crate_directive] cdirs = vec();\n \n     while (p.peek() != term) {\n-        parse_crate_directive(prefix, p, items, index);\n+        auto cdir = @parse_crate_directive(p);\n+        append[@ast.crate_directive](cdirs, cdir);\n     }\n \n-    ret rec(view_items=view_items, items=items, index=index);\n+    ret cdirs;\n }\n \n impure fn parse_crate_from_crate_file(parser p) -> @ast.crate {\n     auto lo = p.get_span();\n     auto hi = lo;\n     auto prefix = std.path.dirname(lo.filename);\n-    auto m = parse_crate_directives(prefix, p, token.EOF);\n+    auto cdirs = parse_crate_directives(p, token.EOF);\n+    auto m = eval.eval_crate_directives_to_mod(p, p.get_env(),\n+                                               cdirs, prefix);\n     hi = p.get_span();\n     expect(p, token.EOF);\n     ret @spanned(lo, hi, rec(module=m));"}, {"sha": "2fd58126cee9f12abe24dafdd5f3904b9465a28c", "filename": "src/comp/front/pretty.rs", "status": "added", "additions": 87, "deletions": 0, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Ffront%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fpretty.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,87 @@\n+import std._int;\n+import std._str;\n+import std._uint;\n+import std._vec;\n+\n+export print_expr;\n+\n+// FIXME this is superseded by ../pretty/pprust.rs. can it be dropped?\n+\n+fn unknown() -> str {\n+    ret \"<unknown ast node>\";\n+}\n+\n+fn print_expr(@ast.expr expr) -> str {\n+    alt (expr.node) {\n+        case (ast.expr_lit(?lit, _)) {\n+            ret print_lit(lit);\n+        }\n+        case (ast.expr_binary(?op, ?lhs, ?rhs, _)) {\n+            ret print_expr_binary(op, lhs, rhs);\n+        }\n+        case (ast.expr_call(?path, ?args, _)) {\n+            ret print_expr_call(path, args);\n+        }\n+        case (ast.expr_path(?path, _, _)) {\n+            ret print_path(path);\n+        }\n+        case (_) {\n+            ret unknown();\n+        }\n+    }\n+}\n+\n+fn print_lit(@ast.lit lit) -> str {\n+    alt (lit.node) {\n+        case (ast.lit_str(?s)) {\n+            ret \"\\\"\" + s + \"\\\"\";\n+        }\n+        case (ast.lit_int(?i)) {\n+            ret _int.to_str(i, 10u);\n+        }\n+        case (ast.lit_uint(?u)) {\n+            ret _uint.to_str(u, 10u);\n+        }\n+        case (_) {\n+            ret unknown();\n+        }\n+    }\n+}\n+\n+fn print_expr_binary(ast.binop op, @ast.expr lhs, @ast.expr rhs) -> str {\n+    alt (op) {\n+        case (ast.add) {\n+            auto l = print_expr(lhs);\n+            auto r = print_expr(rhs);\n+            ret l + \" + \" + r;\n+        }\n+    }\n+}\n+\n+fn print_expr_call(@ast.expr path_expr, vec[@ast.expr] args) -> str {\n+    auto s = print_expr(path_expr);\n+\n+    s += \"(\";\n+    fn print_expr_ref(&@ast.expr e) -> str { ret print_expr(e); }\n+    auto mapfn = print_expr_ref;\n+    auto argstrs = _vec.map[@ast.expr, str](mapfn, args);\n+    s += _str.connect(argstrs, \", \");\n+    s += \")\";\n+\n+    ret s;\n+}\n+\n+fn print_path(ast.path path) -> str {\n+    ret _str.connect(path.node.idents, \".\");\n+}\n+\n+//\n+// Local Variables:\n+// mode: rust\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// compile-command: \"make -k -C ../.. 2>&1 | sed -e 's/\\\\/x\\\\//x:\\\\//g'\";\n+// End:\n+//"}, {"sha": "f75bdbe1ce8bef333069d6cd2a24ff4154de3610", "filename": "src/comp/lib/llvm.rs", "status": "modified", "additions": 83, "deletions": 11, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Flib%2Fllvm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Flib%2Fllvm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Flib%2Fllvm.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -76,6 +76,25 @@ const uint LLVMIntSLT = 40u;\n const uint LLVMIntSLE = 41u;\n \n \n+// Consts for the LLVM RealPredicate type, pre-case to uint.\n+// FIXME: as above.\n+\n+const uint LLVMRealOEQ = 1u;\n+const uint LLVMRealOGT = 2u;\n+const uint LLVMRealOGE = 3u;\n+const uint LLVMRealOLT = 4u;\n+const uint LLVMRealOLE = 5u;\n+const uint LLVMRealONE = 6u;\n+\n+const uint LLVMRealORD = 7u;\n+const uint LLVMRealUNO = 8u;\n+const uint LLVMRealUEQ = 9u;\n+const uint LLVMRealUGT = 10u;\n+const uint LLVMRealUGE = 11u;\n+const uint LLVMRealULT = 12u;\n+const uint LLVMRealULE = 13u;\n+const uint LLVMRealUNE = 14u;\n+\n native mod llvm = llvm_lib {\n \n     type ModuleRef;\n@@ -657,7 +676,7 @@ native mod llvm = llvm_lib {\n     fn LLVMBuildICmp(BuilderRef B, uint Op,\n                      ValueRef LHS, ValueRef RHS,\n                      sbuf Name) -> ValueRef;\n-    fn LLVMBuildFCmp(BuilderRef B, RealPredicate Op,\n+    fn LLVMBuildFCmp(BuilderRef B, uint Op,\n                      ValueRef LHS, ValueRef RHS,\n                      sbuf Name) -> ValueRef;\n \n@@ -1034,7 +1053,7 @@ obj builder(BuilderRef B) {\n         ret llvm.LLVMBuildICmp(B, Op, LHS, RHS, _str.buf(\"\"));\n     }\n \n-    fn FCmp(RealPredicate Op, ValueRef LHS, ValueRef RHS) -> ValueRef {\n+    fn FCmp(uint Op, ValueRef LHS, ValueRef RHS) -> ValueRef {\n         ret llvm.LLVMBuildFCmp(B, Op, LHS, RHS, _str.buf(\"\"));\n     }\n \n@@ -1151,18 +1170,70 @@ fn mk_type_handle() -> type_handle {\n     ret rec(llth=th, dtor=type_handle_dtor(th));\n }\n \n-fn type_to_str(TypeRef ty) -> str {\n+\n+state obj type_names(std.map.hashmap[TypeRef, str] type_names,\n+                    std.map.hashmap[str, TypeRef] named_types) {\n+\n+    fn associate(str s, TypeRef t) {\n+        check (!named_types.contains_key(s));\n+        check (!type_names.contains_key(t));\n+        type_names.insert(t, s);\n+        named_types.insert(s, t);\n+    }\n+\n+    fn type_has_name(TypeRef t) -> bool {\n+        ret type_names.contains_key(t);\n+    }\n+\n+    fn get_name(TypeRef t) -> str {\n+        ret type_names.get(t);\n+    }\n+\n+    fn name_has_type(str s) -> bool {\n+        ret named_types.contains_key(s);\n+    }\n+\n+    fn get_type(str s) -> TypeRef {\n+        ret named_types.get(s);\n+    }\n+}\n+\n+fn mk_type_names() -> type_names {\n+    auto nt = util.common.new_str_hash[TypeRef]();\n+\n+    fn hash(&TypeRef t) -> uint {\n+        ret t as uint;\n+    }\n+\n+    fn eq(&TypeRef a, &TypeRef b) -> bool {\n+        ret (a as uint) == (b as uint);\n+    }\n+\n+    let std.map.hashfn[TypeRef] hasher = hash;\n+    let std.map.eqfn[TypeRef] eqer = eq;\n+    auto tn = std.map.mk_hashmap[TypeRef,str](hasher, eqer);\n+\n+    ret type_names(tn, nt);\n+}\n+\n+fn type_to_str(type_names names, TypeRef ty) -> str {\n     let vec[TypeRef] v = vec();\n-    ret type_to_str_inner(v, ty);\n+    ret type_to_str_inner(names, v, ty);\n }\n \n-fn type_to_str_inner(vec[TypeRef] outer0, TypeRef ty) -> str {\n+fn type_to_str_inner(type_names names,\n+                     vec[TypeRef] outer0, TypeRef ty) -> str {\n+\n+    if (names.type_has_name(ty)) {\n+        ret names.get_name(ty);\n+    }\n \n     auto outer = outer0 + vec(ty);\n \n     let int kind = llvm.LLVMGetTypeKind(ty);\n \n-    fn tys_str(vec[TypeRef] outer, vec[TypeRef] tys) -> str {\n+    fn tys_str(type_names names,\n+               vec[TypeRef] outer, vec[TypeRef] tys) -> str {\n         let str s = \"\";\n         let bool first = true;\n         for (TypeRef t in tys) {\n@@ -1171,7 +1242,7 @@ fn type_to_str_inner(vec[TypeRef] outer0, TypeRef ty) -> str {\n             } else {\n                 s += \", \";\n             }\n-            s += type_to_str_inner(outer, t);\n+            s += type_to_str_inner(names, outer, t);\n         }\n         ret s;\n     }\n@@ -1200,9 +1271,9 @@ fn type_to_str_inner(vec[TypeRef] outer0, TypeRef ty) -> str {\n             let vec[TypeRef] args =\n                 _vec.init_elt[TypeRef](0 as TypeRef, n_args);\n             llvm.LLVMGetParamTypes(ty, _vec.buf[TypeRef](args));\n-            s += tys_str(outer, args);\n+            s += tys_str(names, outer, args);\n             s += \") -> \";\n-            s += type_to_str_inner(outer, out_ty);\n+            s += type_to_str_inner(names, outer, out_ty);\n             ret s;\n         }\n \n@@ -1212,7 +1283,7 @@ fn type_to_str_inner(vec[TypeRef] outer0, TypeRef ty) -> str {\n             let vec[TypeRef] elts =\n                 _vec.init_elt[TypeRef](0 as TypeRef, n_elts);\n             llvm.LLVMGetStructElementTypes(ty, _vec.buf[TypeRef](elts));\n-            s += tys_str(outer, elts);\n+            s += tys_str(names, outer, elts);\n             s += \"}\";\n             ret s;\n         }\n@@ -1228,7 +1299,8 @@ fn type_to_str_inner(vec[TypeRef] outer0, TypeRef ty) -> str {\n                     ret \"*\\\\\" + util.common.istr(n as int);\n                 }\n             }\n-            ret \"*\" + type_to_str_inner(outer, llvm.LLVMGetElementType(ty));\n+            ret \"*\" + type_to_str_inner(names, outer,\n+                                        llvm.LLVMGetElementType(ty));\n         }\n \n         case (12) { ret \"Opaque\"; }"}, {"sha": "d7660460e04af2f5807fa1419563e153140fe1f8", "filename": "src/comp/middle/fold.rs", "status": "modified", "additions": 318, "deletions": 89, "changes": 407, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ffold.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -10,6 +10,7 @@ import util.common.ty_mach;\n import util.common.append;\n \n import front.ast;\n+import front.ast.fn_decl;\n import front.ast.ident;\n import front.ast.path;\n import front.ast.mutability;\n@@ -20,6 +21,7 @@ import front.ast.block;\n import front.ast.item;\n import front.ast.view_item;\n import front.ast.meta_item;\n+import front.ast.native_item;\n import front.ast.arg;\n import front.ast.pat;\n import front.ast.decl;\n@@ -28,6 +30,7 @@ import front.ast.def;\n import front.ast.def_id;\n import front.ast.ann;\n \n+import std._uint;\n import std._vec;\n \n type ast_fold[ENV] =\n@@ -56,6 +59,7 @@ type ast_fold[ENV] =\n          vec[ast.ty_method] meths) -> @ty)        fold_ty_obj,\n \n      (fn(&ENV e, &span sp,\n+         ast.proto proto,\n          vec[rec(ast.mode mode, @ty ty)] inputs,\n          @ty output) -> @ty)                      fold_ty_fn,\n \n@@ -72,7 +76,8 @@ type ast_fold[ENV] =\n          vec[ast.elt] es, ann a) -> @expr)        fold_expr_tup,\n \n      (fn(&ENV e, &span sp,\n-         vec[ast.field] fields, ann a) -> @expr)  fold_expr_rec,\n+         vec[ast.field] fields,\n+         option.t[@expr] base, ann a) -> @expr)   fold_expr_rec,\n \n      (fn(&ENV e, &span sp,\n          @expr f, vec[@expr] args,\n@@ -107,6 +112,10 @@ type ast_fold[ENV] =\n          @decl decl, @expr seq, &block body,\n          ann a) -> @expr)                         fold_expr_for,\n \n+     (fn(&ENV e, &span sp,\n+         @decl decl, @expr seq, &block body,\n+         ann a) -> @expr)                         fold_expr_for_each,\n+\n      (fn(&ENV e, &span sp,\n          @expr cond, &block body,\n          ann a) -> @expr)                         fold_expr_while,\n@@ -144,6 +153,29 @@ type ast_fold[ENV] =\n          &option.t[def] d,\n          ann a) -> @expr)                         fold_expr_path,\n \n+     (fn(&ENV e, &span sp,\n+         &path p, vec[@expr] args,\n+         option.t[@expr] body,\n+         @expr expanded,\n+         ann a) -> @expr)                         fold_expr_ext,\n+\n+     (fn(&ENV e, &span sp) -> @expr)              fold_expr_fail,\n+\n+     (fn(&ENV e, &span sp,\n+         &option.t[@expr] rv) -> @expr)           fold_expr_ret,\n+\n+     (fn(&ENV e, &span sp,\n+         &option.t[@expr] rv) -> @expr)           fold_expr_put,\n+\n+     (fn(&ENV e, &span sp,\n+         @expr e) -> @expr)                       fold_expr_be,\n+\n+     (fn(&ENV e, &span sp,\n+         @expr e) -> @expr)                       fold_expr_log,\n+\n+     (fn(&ENV e, &span sp,\n+         @expr e) -> @expr)                       fold_expr_check_expr,\n+\n      // Decl folds.\n      (fn(&ENV e, &span sp,\n          @ast.local local) -> @decl)              fold_decl_local,\n@@ -156,6 +188,9 @@ type ast_fold[ENV] =\n      (fn(&ENV e, &span sp,\n          ann a) -> @pat)                          fold_pat_wild,\n \n+     (fn(&ENV e, &span sp,\n+         @ast.lit lit, ann a) -> @pat)            fold_pat_lit,\n+\n      (fn(&ENV e, &span sp,\n          ident i, def_id did, ann a) -> @pat)     fold_pat_bind,\n \n@@ -169,15 +204,6 @@ type ast_fold[ENV] =\n      (fn(&ENV e, &span sp,\n          @decl decl) -> @stmt)                    fold_stmt_decl,\n \n-     (fn(&ENV e, &span sp,\n-         &option.t[@expr] rv) -> @stmt)           fold_stmt_ret,\n-\n-     (fn(&ENV e, &span sp,\n-         @expr e) -> @stmt)                       fold_stmt_log,\n-\n-     (fn(&ENV e, &span sp,\n-         @expr e) -> @stmt)                       fold_stmt_check_expr,\n-\n      (fn(&ENV e, &span sp,\n          @expr e) -> @stmt)                       fold_stmt_expr,\n \n@@ -191,13 +217,24 @@ type ast_fold[ENV] =\n          vec[ast.ty_param] ty_params,\n          def_id id, ann a) -> @item)              fold_item_fn,\n \n+     (fn(&ENV e, &span sp, ident ident,\n+         &ast.fn_decl decl,\n+         vec[ast.ty_param] ty_params,\n+         def_id id, ann a) -> @native_item)       fold_native_item_fn,\n+\n      (fn(&ENV e, &span sp, ident ident,\n          &ast._mod m, def_id id) -> @item)        fold_item_mod,\n \n+     (fn(&ENV e, &span sp, ident ident,\n+         &ast.native_mod m, def_id id) -> @item)  fold_item_native_mod,\n+\n      (fn(&ENV e, &span sp, ident ident,\n          @ty t, vec[ast.ty_param] ty_params,\n          def_id id, ann a) -> @item)              fold_item_ty,\n \n+     (fn(&ENV e, &span sp, ident ident,\n+         def_id id) -> @native_item)              fold_native_item_ty,\n+\n      (fn(&ENV e, &span sp, ident ident,\n          vec[ast.variant] variants,\n          vec[ast.ty_param] ty_params,\n@@ -220,23 +257,30 @@ type ast_fold[ENV] =\n      (fn(&ENV e, &span sp,\n          &ast.block_) -> block)                   fold_block,\n \n+     (fn(&ENV e, &fn_decl decl,\n+         ast.proto proto,\n+         &block body) -> ast._fn)                 fold_fn,\n+\n      (fn(&ENV e, ast.effect effect,\n-         bool is_iter,\n          vec[arg] inputs,\n-         @ty output, &block body) -> ast._fn)     fold_fn,\n+         @ty output) -> ast.fn_decl)              fold_fn_decl,\n \n      (fn(&ENV e, &ast._mod m) -> ast._mod)        fold_mod,\n \n+     (fn(&ENV e, &ast.native_mod m) -> ast.native_mod) fold_native_mod,\n+\n      (fn(&ENV e, &span sp,\n          &ast._mod m) -> @ast.crate)              fold_crate,\n \n      (fn(&ENV e,\n          vec[ast.obj_field] fields,\n-         vec[@ast.method] methods) -> ast._obj)   fold_obj,\n+         vec[@ast.method] methods,\n+         option.t[block] dtor) -> ast._obj)       fold_obj,\n \n      // Env updates.\n      (fn(&ENV e, @ast.crate c) -> ENV) update_env_for_crate,\n      (fn(&ENV e, @item i) -> ENV) update_env_for_item,\n+     (fn(&ENV e, @native_item i) -> ENV) update_env_for_native_item,\n      (fn(&ENV e, @view_item i) -> ENV) update_env_for_view_item,\n      (fn(&ENV e, &block b) -> ENV) update_env_for_block,\n      (fn(&ENV e, @stmt s) -> ENV) update_env_for_stmt,\n@@ -312,11 +356,13 @@ fn fold_ty[ENV](&ENV env, ast_fold[ENV] fld, @ty t) -> @ty {\n         case (ast.ty_obj(?meths)) {\n             let vec[ast.ty_method] meths_ = vec();\n             for (ast.ty_method m in meths) {\n-                auto tfn = fold_ty_fn(env_, fld, t.span, m.inputs, m.output);\n+                auto tfn = fold_ty_fn(env_, fld, t.span, m.proto,\n+                                      m.inputs, m.output);\n                 alt (tfn.node) {\n-                    case (ast.ty_fn(?ins, ?out)) {\n+                    case (ast.ty_fn(?p, ?ins, ?out)) {\n                         append[ast.ty_method]\n-                            (meths_, rec(inputs=ins, output=out with m));\n+                            (meths_, rec(proto=p, inputs=ins, output=out\n+                                         with m));\n                     }\n                 }\n             }\n@@ -333,13 +379,14 @@ fn fold_ty[ENV](&ENV env, ast_fold[ENV] fld, @ty t) -> @ty {\n             ret fld.fold_ty_mutable(env_, t.span, ty_);\n         }\n \n-        case (ast.ty_fn(?inputs, ?output)) {\n-            ret fold_ty_fn(env_, fld, t.span, inputs, output);\n+        case (ast.ty_fn(?proto, ?inputs, ?output)) {\n+            ret fold_ty_fn(env_, fld, t.span, proto, inputs, output);\n         }\n     }\n }\n \n fn fold_ty_fn[ENV](&ENV env, ast_fold[ENV] fld, &span sp,\n+                   ast.proto proto,\n                    vec[rec(ast.mode mode, @ty ty)] inputs,\n                    @ty output) -> @ty {\n     auto output_ = fold_ty(env, fld, output);\n@@ -349,7 +396,7 @@ fn fold_ty_fn[ENV](&ENV env, ast_fold[ENV] fld, &span sp,\n         auto input_ = rec(ty=ty_ with input);\n         inputs_ += vec(input_);\n     }\n-    ret fld.fold_ty_fn(env, sp, inputs_, output_);\n+    ret fld.fold_ty_fn(env, sp, proto, inputs_, output_);\n }\n \n fn fold_decl[ENV](&ENV env, ast_fold[ENV] fld, @decl d) -> @decl {\n@@ -397,6 +444,9 @@ fn fold_pat[ENV](&ENV env, ast_fold[ENV] fld, @ast.pat p) -> @ast.pat {\n \n     alt (p.node) {\n         case (ast.pat_wild(?t)) { ret fld.fold_pat_wild(env_, p.span, t); }\n+        case (ast.pat_lit(?lt, ?t)) {\n+            ret fld.fold_pat_lit(env_, p.span, lt, t);\n+        }\n         case (ast.pat_bind(?id, ?did, ?t)) {\n             ret fld.fold_pat_bind(env_, p.span, id, did, t);\n         }\n@@ -449,12 +499,19 @@ fn fold_expr[ENV](&ENV env, ast_fold[ENV] fld, &@expr e) -> @expr {\n             ret fld.fold_expr_tup(env_, e.span, elts, t);\n         }\n \n-        case (ast.expr_rec(?fs, ?t)) {\n+        case (ast.expr_rec(?fs, ?base, ?t)) {\n             let vec[ast.field] fields = vec();\n+            let option.t[@expr] b = none[@expr];\n             for (ast.field f in fs) {\n                 fields += fold_rec_field(env, fld, f);\n             }\n-            ret fld.fold_expr_rec(env_, e.span, fields, t);\n+            alt (base) {\n+                case (none[@ast.expr]) { }\n+                case (some[@ast.expr](?eb)) {\n+                    b = some[@expr](fold_expr(env_, fld, eb));\n+                }\n+            }\n+            ret fld.fold_expr_rec(env_, e.span, fields, b, t);\n         }\n \n         case (ast.expr_call(?f, ?args, ?t)) {\n@@ -521,6 +578,13 @@ fn fold_expr[ENV](&ENV env, ast_fold[ENV] fld, &@expr e) -> @expr {\n             ret fld.fold_expr_for(env_, e.span, ddecl, sseq, bbody, t);\n         }\n \n+        case (ast.expr_for_each(?decl, ?seq, ?body, ?t)) {\n+            auto ddecl = fold_decl(env_, fld, decl);\n+            auto sseq = fold_expr(env_, fld, seq);\n+            auto bbody = fold_block(env_, fld, body);\n+            ret fld.fold_expr_for_each(env_, e.span, ddecl, sseq, bbody, t);\n+        }\n+\n         case (ast.expr_while(?cnd, ?body, ?t)) {\n             auto ccnd = fold_expr(env_, fld, cnd);\n             auto bbody = fold_block(env_, fld, body);\n@@ -574,9 +638,59 @@ fn fold_expr[ENV](&ENV env, ast_fold[ENV] fld, &@expr e) -> @expr {\n             auto p_ = fold_path(env_, fld, p);\n             ret fld.fold_expr_path(env_, e.span, p_, r, t);\n         }\n+\n+        case (ast.expr_ext(?p, ?args, ?body, ?expanded, ?t)) {\n+            // Only fold the expanded expression, not the\n+            // expressions involved in syntax extension\n+            auto exp = fold_expr(env_, fld, expanded);\n+            ret fld.fold_expr_ext(env_, e.span, p, args, body,\n+                                  exp, t);\n+        }\n+\n+        case (ast.expr_fail) {\n+            ret fld.fold_expr_fail(env_, e.span);\n+        }\n+\n+        case (ast.expr_ret(?oe)) {\n+            auto oee = none[@expr];\n+            alt (oe) {\n+                case (some[@expr](?x)) {\n+                    oee = some(fold_expr(env_, fld, x));\n+                }\n+                case (_) { /* fall through */  }\n+            }\n+            ret fld.fold_expr_ret(env_, e.span, oee);\n+        }\n+\n+        case (ast.expr_put(?oe)) {\n+            auto oee = none[@expr];\n+            alt (oe) {\n+                case (some[@expr](?x)) {\n+                    oee = some(fold_expr(env_, fld, x));\n+                }\n+                case (_) { /* fall through */  }\n+            }\n+            ret fld.fold_expr_put(env_, e.span, oee);\n+        }\n+\n+        case (ast.expr_be(?x)) {\n+            auto ee = fold_expr(env_, fld, x);\n+            ret fld.fold_expr_be(env_, e.span, ee);\n+        }\n+\n+        case (ast.expr_log(?x)) {\n+            auto ee = fold_expr(env_, fld, x);\n+            ret fld.fold_expr_log(env_, e.span, ee);\n+        }\n+\n+        case (ast.expr_check_expr(?x)) {\n+            auto ee = fold_expr(env_, fld, x);\n+            ret fld.fold_expr_check_expr(env_, e.span, ee);\n+        }\n+\n     }\n \n-    ret e;\n+    fail;\n }\n \n \n@@ -594,37 +708,12 @@ fn fold_stmt[ENV](&ENV env, ast_fold[ENV] fld, &@stmt s) -> @stmt {\n             ret fld.fold_stmt_decl(env_, s.span, dd);\n         }\n \n-        case (ast.stmt_ret(?oe)) {\n-            auto oee = none[@expr];\n-            alt (oe) {\n-                case (some[@expr](?e)) {\n-                    oee = some(fold_expr(env_, fld, e));\n-                }\n-                case (_) { /* fall through */  }\n-            }\n-            ret fld.fold_stmt_ret(env_, s.span, oee);\n-        }\n-\n-        case (ast.stmt_log(?e)) {\n-            auto ee = fold_expr(env_, fld, e);\n-            ret fld.fold_stmt_log(env_, s.span, ee);\n-        }\n-\n-        case (ast.stmt_check_expr(?e)) {\n-            auto ee = fold_expr(env_, fld, e);\n-            ret fld.fold_stmt_check_expr(env_, s.span, ee);\n-        }\n-\n-        case (ast.stmt_fail) {\n-            ret s;\n-        }\n-\n         case (ast.stmt_expr(?e)) {\n             auto ee = fold_expr(env_, fld, e);\n             ret fld.fold_stmt_expr(env_, s.span, ee);\n         }\n     }\n-    ret s;\n+    fail;\n }\n \n fn fold_block[ENV](&ENV env, ast_fold[ENV] fld, &block blk) -> block {\n@@ -666,17 +755,22 @@ fn fold_arg[ENV](&ENV env, ast_fold[ENV] fld, &arg a) -> arg {\n     ret rec(ty=ty with a);\n }\n \n-\n-fn fold_fn[ENV](&ENV env, ast_fold[ENV] fld, &ast._fn f) -> ast._fn {\n-\n+fn fold_fn_decl[ENV](&ENV env, ast_fold[ENV] fld,\n+                     &ast.fn_decl decl) -> ast.fn_decl {\n     let vec[ast.arg] inputs = vec();\n-    for (ast.arg a in f.inputs) {\n+    for (ast.arg a in decl.inputs) {\n         inputs += fold_arg(env, fld, a);\n     }\n-    auto output = fold_ty[ENV](env, fld, f.output);\n+    auto output = fold_ty[ENV](env, fld, decl.output);\n+    ret fld.fold_fn_decl(env, decl.effect, inputs, output);\n+}\n+\n+fn fold_fn[ENV](&ENV env, ast_fold[ENV] fld, &ast._fn f) -> ast._fn {\n+    auto decl = fold_fn_decl(env, fld, f.decl);\n+\n     auto body = fold_block[ENV](env, fld, f.body);\n \n-    ret fld.fold_fn(env, f.effect, f.is_iter, inputs, output, body);\n+    ret fld.fold_fn(env, decl, f.proto, body);\n }\n \n \n@@ -701,6 +795,13 @@ fn fold_obj[ENV](&ENV env, ast_fold[ENV] fld, &ast._obj ob) -> ast._obj {\n     for (ast.obj_field f in ob.fields) {\n         fields += fold_obj_field(env, fld, f);\n     }\n+    let option.t[block] dtor = none[block];\n+    alt (ob.dtor) {\n+        case (none[block]) { }\n+        case (some[block](?b)) {\n+            dtor = some[block](fold_block[ENV](env, fld, b));\n+        }\n+    }\n     let vec[ast.ty_param] tp = vec();\n     for (@ast.method m in ob.methods) {\n         // Fake-up an ast.item for this method.\n@@ -715,7 +816,7 @@ fn fold_obj[ENV](&ENV env, ast_fold[ENV] fld, &ast._obj ob) -> ast._obj {\n         let ENV _env = fld.update_env_for_item(env, i);\n         append[@ast.method](meths, fold_method(_env, fld, m));\n     }\n-    ret fld.fold_obj(env, fields, meths);\n+    ret fld.fold_obj(env, fields, meths, dtor);\n }\n \n fn fold_view_item[ENV](&ENV env, ast_fold[ENV] fld, @view_item vi)\n@@ -768,6 +869,11 @@ fn fold_item[ENV](&ENV env, ast_fold[ENV] fld, @item i) -> @item {\n             ret fld.fold_item_mod(env_, i.span, ident, mm_, id);\n         }\n \n+        case (ast.item_native_mod(?ident, ?mm, ?id)) {\n+            let ast.native_mod mm_ = fold_native_mod[ENV](env_, fld, mm);\n+            ret fld.fold_item_native_mod(env_, i.span, ident, mm_, id);\n+        }\n+\n         case (ast.item_ty(?ident, ?ty, ?params, ?id, ?ann)) {\n             let @ast.ty ty_ = fold_ty[ENV](env_, fld, ty);\n             ret fld.fold_item_ty(env_, i.span, ident, ty_, params, id, ann);\n@@ -798,7 +904,6 @@ fn fold_item[ENV](&ENV env, ast_fold[ENV] fld, @item i) -> @item {\n     fail;\n }\n \n-\n fn fold_mod[ENV](&ENV e, ast_fold[ENV] fld, &ast._mod m) -> ast._mod {\n \n     let vec[@view_item] view_items = vec();\n@@ -818,7 +923,50 @@ fn fold_mod[ENV](&ENV e, ast_fold[ENV] fld, &ast._mod m) -> ast._mod {\n     }\n \n     ret fld.fold_mod(e, rec(view_items=view_items, items=items, index=index));\n- }\n+}\n+\n+fn fold_native_item[ENV](&ENV env, ast_fold[ENV] fld,\n+                         @native_item i) -> @native_item {\n+    let ENV env_ = fld.update_env_for_native_item(env, i);\n+\n+    if (!fld.keep_going(env_)) {\n+        ret i;\n+    }\n+    alt (i.node) {\n+        case (ast.native_item_ty(?ident, ?id)) {\n+            ret fld.fold_native_item_ty(env_, i.span, ident, id);\n+        }\n+        case (ast.native_item_fn(?ident, ?fn_decl, ?ty_params, ?id, ?ann)) {\n+            auto d = fold_fn_decl[ENV](env_, fld, fn_decl);\n+            ret fld.fold_native_item_fn(env_, i.span, ident, d,\n+                                        ty_params, id, ann);\n+        }\n+    }\n+}\n+\n+fn fold_native_mod[ENV](&ENV e, ast_fold[ENV] fld,\n+                        &ast.native_mod m) -> ast.native_mod {\n+    let vec[@view_item] view_items = vec();\n+    let vec[@native_item] items = vec();\n+    auto index = new_str_hash[ast.native_mod_index_entry]();\n+\n+    for (@view_item vi in m.view_items) {\n+        auto new_vi = fold_view_item[ENV](e, fld, vi);\n+        append[@view_item](view_items, new_vi);\n+    }\n+\n+    for (@native_item i in m.items) {\n+        auto new_item = fold_native_item[ENV](e, fld, i);\n+        append[@native_item](items, new_item);\n+        ast.index_native_item(index, new_item);\n+    }\n+\n+    ret fld.fold_native_mod(e, rec(native_name=m.native_name,\n+                                   abi=m.abi,\n+                                   view_items=view_items,\n+                                   items=items,\n+                                   index=index));\n+}\n \n fn fold_crate[ENV](&ENV env, ast_fold[ENV] fld, @ast.crate c) -> @ast.crate {\n     let ENV env_ = fld.update_env_for_crate(env, c);\n@@ -894,9 +1042,10 @@ fn identity_fold_ty_obj[ENV](&ENV env, &span sp,\n }\n \n fn identity_fold_ty_fn[ENV](&ENV env, &span sp,\n+                            ast.proto proto,\n                             vec[rec(ast.mode mode, @ty ty)] inputs,\n                             @ty output) -> @ty {\n-    ret @respan(sp, ast.ty_fn(inputs, output));\n+    ret @respan(sp, ast.ty_fn(proto, inputs, output));\n }\n \n fn identity_fold_ty_path[ENV](&ENV env, &span sp, ast.path p,\n@@ -922,8 +1071,9 @@ fn identity_fold_expr_tup[ENV](&ENV env, &span sp,\n }\n \n fn identity_fold_expr_rec[ENV](&ENV env, &span sp,\n-                               vec[ast.field] fields, ann a) -> @expr {\n-    ret @respan(sp, ast.expr_rec(fields, a));\n+                               vec[ast.field] fields,\n+                               option.t[@expr] base, ann a) -> @expr {\n+    ret @respan(sp, ast.expr_rec(fields, base, a));\n }\n \n fn identity_fold_expr_call[ENV](&ENV env, &span sp, @expr f,\n@@ -971,6 +1121,12 @@ fn identity_fold_expr_for[ENV](&ENV env, &span sp,\n     ret @respan(sp, ast.expr_for(d, seq, body, a));\n }\n \n+fn identity_fold_expr_for_each[ENV](&ENV env, &span sp,\n+                                    @decl d, @expr seq,\n+                                    &block body, ann a) -> @expr {\n+    ret @respan(sp, ast.expr_for_each(d, seq, body, a));\n+}\n+\n fn identity_fold_expr_while[ENV](&ENV env, &span sp,\n                                  @expr cond, &block body, ann a) -> @expr {\n     ret @respan(sp, ast.expr_while(cond, body, a));\n@@ -1019,6 +1175,40 @@ fn identity_fold_expr_path[ENV](&ENV env, &span sp,\n     ret @respan(sp, ast.expr_path(p, d, a));\n }\n \n+fn identity_fold_expr_ext[ENV](&ENV env, &span sp,\n+                               &path p, vec[@expr] args,\n+                               option.t[@expr] body,\n+                               @expr expanded,\n+                               ann a) -> @expr {\n+    ret @respan(sp, ast.expr_ext(p, args, body, expanded, a));\n+}\n+\n+fn identity_fold_expr_fail[ENV](&ENV env, &span sp) -> @expr {\n+    ret @respan(sp, ast.expr_fail);\n+}\n+\n+fn identity_fold_expr_ret[ENV](&ENV env, &span sp,\n+                               &option.t[@expr] rv) -> @expr {\n+    ret @respan(sp, ast.expr_ret(rv));\n+}\n+\n+fn identity_fold_expr_put[ENV](&ENV env, &span sp,\n+                               &option.t[@expr] rv) -> @expr {\n+    ret @respan(sp, ast.expr_put(rv));\n+}\n+\n+fn identity_fold_expr_be[ENV](&ENV env, &span sp, @expr x) -> @expr {\n+    ret @respan(sp, ast.expr_be(x));\n+}\n+\n+fn identity_fold_expr_log[ENV](&ENV e, &span sp, @expr x) -> @expr {\n+    ret @respan(sp, ast.expr_log(x));\n+}\n+\n+fn identity_fold_expr_check_expr[ENV](&ENV e, &span sp, @expr x) -> @expr {\n+    ret @respan(sp, ast.expr_check_expr(x));\n+}\n+\n \n // Decl identities.\n \n@@ -1038,6 +1228,10 @@ fn identity_fold_pat_wild[ENV](&ENV e, &span sp, ann a) -> @pat {\n     ret @respan(sp, ast.pat_wild(a));\n }\n \n+fn identity_fold_pat_lit[ENV](&ENV e, &span sp, @ast.lit lit, ann a) -> @pat {\n+    ret @respan(sp, ast.pat_lit(lit, a));\n+}\n+\n fn identity_fold_pat_bind[ENV](&ENV e, &span sp, ident i, def_id did, ann a)\n         -> @pat {\n     ret @respan(sp, ast.pat_bind(i, did, a));\n@@ -1055,19 +1249,6 @@ fn identity_fold_stmt_decl[ENV](&ENV env, &span sp, @decl d) -> @stmt {\n     ret @respan(sp, ast.stmt_decl(d));\n }\n \n-fn identity_fold_stmt_ret[ENV](&ENV env, &span sp,\n-                               &option.t[@expr] rv) -> @stmt {\n-    ret @respan(sp, ast.stmt_ret(rv));\n-}\n-\n-fn identity_fold_stmt_log[ENV](&ENV e, &span sp, @expr x) -> @stmt {\n-    ret @respan(sp, ast.stmt_log(x));\n-}\n-\n-fn identity_fold_stmt_check_expr[ENV](&ENV e, &span sp, @expr x) -> @stmt {\n-    ret @respan(sp, ast.stmt_check_expr(x));\n-}\n-\n fn identity_fold_stmt_expr[ENV](&ENV e, &span sp, @expr x) -> @stmt {\n     ret @respan(sp, ast.stmt_expr(x));\n }\n@@ -1087,17 +1268,34 @@ fn identity_fold_item_fn[ENV](&ENV e, &span sp, ident i,\n     ret @respan(sp, ast.item_fn(i, f, ty_params, id, a));\n }\n \n+fn identity_fold_native_item_fn[ENV](&ENV e, &span sp, ident i,\n+                                     &ast.fn_decl decl,\n+                                     vec[ast.ty_param] ty_params,\n+                                     def_id id, ann a) -> @native_item {\n+    ret @respan(sp, ast.native_item_fn(i, decl, ty_params, id, a));\n+}\n+\n fn identity_fold_item_mod[ENV](&ENV e, &span sp, ident i,\n                                &ast._mod m, def_id id) -> @item {\n     ret @respan(sp, ast.item_mod(i, m, id));\n }\n \n+fn identity_fold_item_native_mod[ENV](&ENV e, &span sp, ident i,\n+                                      &ast.native_mod m, def_id id) -> @item {\n+    ret @respan(sp, ast.item_native_mod(i, m, id));\n+}\n+\n fn identity_fold_item_ty[ENV](&ENV e, &span sp, ident i,\n                               @ty t, vec[ast.ty_param] ty_params,\n                               def_id id, ann a) -> @item {\n     ret @respan(sp, ast.item_ty(i, t, ty_params, id, a));\n }\n \n+fn identity_fold_native_item_ty[ENV](&ENV e, &span sp, ident i,\n+                                     def_id id) -> @native_item {\n+    ret @respan(sp, ast.native_item_ty(i, id));\n+}\n+\n fn identity_fold_item_tag[ENV](&ENV e, &span sp, ident i,\n                                vec[ast.variant] variants,\n                                vec[ast.ty_param] ty_params,\n@@ -1132,28 +1330,38 @@ fn identity_fold_block[ENV](&ENV e, &span sp, &ast.block_ blk) -> block {\n     ret respan(sp, blk);\n }\n \n+fn identity_fold_fn_decl[ENV](&ENV e,\n+                              ast.effect effect,\n+                              vec[arg] inputs,\n+                              @ty output) -> ast.fn_decl {\n+    ret rec(effect=effect, inputs=inputs, output=output);\n+}\n+\n fn identity_fold_fn[ENV](&ENV e,\n-                         ast.effect effect,\n-                         bool is_iter,\n-                         vec[arg] inputs,\n-                         @ast.ty output,\n+                         &fn_decl decl,\n+                         ast.proto proto,\n                          &block body) -> ast._fn {\n-    ret rec(effect=effect, is_iter=is_iter, inputs=inputs,\n-            output=output, body=body);\n+    ret rec(decl=decl, proto=proto, body=body);\n }\n \n fn identity_fold_mod[ENV](&ENV e, &ast._mod m) -> ast._mod {\n     ret m;\n }\n \n+fn identity_fold_native_mod[ENV](&ENV e,\n+                                 &ast.native_mod m) -> ast.native_mod {\n+    ret m;\n+}\n+\n fn identity_fold_crate[ENV](&ENV e, &span sp, &ast._mod m) -> @ast.crate {\n     ret @respan(sp, rec(module=m));\n }\n \n fn identity_fold_obj[ENV](&ENV e,\n                           vec[ast.obj_field] fields,\n-                          vec[@ast.method] methods) -> ast._obj {\n-    ret rec(fields=fields, methods=methods);\n+                          vec[@ast.method] methods,\n+                          option.t[block] dtor) -> ast._obj {\n+    ret rec(fields=fields, methods=methods, dtor=dtor);\n }\n \n \n@@ -1167,6 +1375,10 @@ fn identity_update_env_for_item[ENV](&ENV e, @item i) -> ENV {\n     ret e;\n }\n \n+fn identity_update_env_for_native_item[ENV](&ENV e, @native_item i) -> ENV {\n+    ret e;\n+}\n+\n fn identity_update_env_for_view_item[ENV](&ENV e, @view_item i) -> ENV {\n     ret e;\n }\n@@ -1224,13 +1436,13 @@ fn new_identity_fold[ENV]() -> ast_fold[ENV] {\n          fold_ty_tup     = bind identity_fold_ty_tup[ENV](_,_,_),\n          fold_ty_rec     = bind identity_fold_ty_rec[ENV](_,_,_),\n          fold_ty_obj     = bind identity_fold_ty_obj[ENV](_,_,_),\n-         fold_ty_fn      = bind identity_fold_ty_fn[ENV](_,_,_,_),\n+         fold_ty_fn      = bind identity_fold_ty_fn[ENV](_,_,_,_,_),\n          fold_ty_path    = bind identity_fold_ty_path[ENV](_,_,_,_),\n          fold_ty_mutable = bind identity_fold_ty_mutable[ENV](_,_,_),\n \n          fold_expr_vec    = bind identity_fold_expr_vec[ENV](_,_,_,_),\n          fold_expr_tup    = bind identity_fold_expr_tup[ENV](_,_,_,_),\n-         fold_expr_rec    = bind identity_fold_expr_rec[ENV](_,_,_,_),\n+         fold_expr_rec    = bind identity_fold_expr_rec[ENV](_,_,_,_,_),\n          fold_expr_call   = bind identity_fold_expr_call[ENV](_,_,_,_,_),\n          fold_expr_bind   = bind identity_fold_expr_bind[ENV](_,_,_,_,_),\n          fold_expr_binary = bind identity_fold_expr_binary[ENV](_,_,_,_,_,_),\n@@ -1239,6 +1451,8 @@ fn new_identity_fold[ENV]() -> ast_fold[ENV] {\n          fold_expr_cast   = bind identity_fold_expr_cast[ENV](_,_,_,_,_),\n          fold_expr_if     = bind identity_fold_expr_if[ENV](_,_,_,_,_,_),\n          fold_expr_for    = bind identity_fold_expr_for[ENV](_,_,_,_,_,_),\n+         fold_expr_for_each\n+             = bind identity_fold_expr_for_each[ENV](_,_,_,_,_,_),\n          fold_expr_while  = bind identity_fold_expr_while[ENV](_,_,_,_,_),\n          fold_expr_do_while\n                           = bind identity_fold_expr_do_while[ENV](_,_,_,_,_),\n@@ -1250,25 +1464,36 @@ fn new_identity_fold[ENV]() -> ast_fold[ENV] {\n          fold_expr_field  = bind identity_fold_expr_field[ENV](_,_,_,_,_),\n          fold_expr_index  = bind identity_fold_expr_index[ENV](_,_,_,_,_),\n          fold_expr_path   = bind identity_fold_expr_path[ENV](_,_,_,_,_),\n+         fold_expr_ext    = bind identity_fold_expr_ext[ENV](_,_,_,_,_,_,_),\n+         fold_expr_fail   = bind identity_fold_expr_fail[ENV](_,_),\n+         fold_expr_ret    = bind identity_fold_expr_ret[ENV](_,_,_),\n+         fold_expr_put    = bind identity_fold_expr_put[ENV](_,_,_),\n+         fold_expr_be     = bind identity_fold_expr_be[ENV](_,_,_),\n+         fold_expr_log    = bind identity_fold_expr_log[ENV](_,_,_),\n+         fold_expr_check_expr\n+                          = bind identity_fold_expr_check_expr[ENV](_,_,_),\n \n          fold_decl_local  = bind identity_fold_decl_local[ENV](_,_,_),\n          fold_decl_item   = bind identity_fold_decl_item[ENV](_,_,_),\n \n          fold_pat_wild    = bind identity_fold_pat_wild[ENV](_,_,_),\n+         fold_pat_lit     = bind identity_fold_pat_lit[ENV](_,_,_,_),\n          fold_pat_bind    = bind identity_fold_pat_bind[ENV](_,_,_,_,_),\n          fold_pat_tag     = bind identity_fold_pat_tag[ENV](_,_,_,_,_,_),\n \n          fold_stmt_decl   = bind identity_fold_stmt_decl[ENV](_,_,_),\n-         fold_stmt_ret    = bind identity_fold_stmt_ret[ENV](_,_,_),\n-         fold_stmt_log    = bind identity_fold_stmt_log[ENV](_,_,_),\n-         fold_stmt_check_expr\n-                          = bind identity_fold_stmt_check_expr[ENV](_,_,_),\n          fold_stmt_expr   = bind identity_fold_stmt_expr[ENV](_,_,_),\n \n          fold_item_const= bind identity_fold_item_const[ENV](_,_,_,_,_,_,_),\n          fold_item_fn   = bind identity_fold_item_fn[ENV](_,_,_,_,_,_,_),\n+         fold_native_item_fn =\n+             bind identity_fold_native_item_fn[ENV](_,_,_,_,_,_,_),\n          fold_item_mod  = bind identity_fold_item_mod[ENV](_,_,_,_,_),\n+         fold_item_native_mod =\n+             bind identity_fold_item_native_mod[ENV](_,_,_,_,_),\n          fold_item_ty   = bind identity_fold_item_ty[ENV](_,_,_,_,_,_,_),\n+         fold_native_item_ty =\n+             bind identity_fold_native_item_ty[ENV](_,_,_,_),\n          fold_item_tag  = bind identity_fold_item_tag[ENV](_,_,_,_,_,_),\n          fold_item_obj  = bind identity_fold_item_obj[ENV](_,_,_,_,_,_,_),\n \n@@ -1278,13 +1503,17 @@ fn new_identity_fold[ENV]() -> ast_fold[ENV] {\n              bind identity_fold_view_item_import[ENV](_,_,_,_,_,_),\n \n          fold_block = bind identity_fold_block[ENV](_,_,_),\n-         fold_fn = bind identity_fold_fn[ENV](_,_,_,_,_,_),\n+         fold_fn = bind identity_fold_fn[ENV](_,_,_,_),\n+         fold_fn_decl = bind identity_fold_fn_decl[ENV](_,_,_,_),\n          fold_mod = bind identity_fold_mod[ENV](_,_),\n+         fold_native_mod = bind identity_fold_native_mod[ENV](_,_),\n          fold_crate = bind identity_fold_crate[ENV](_,_,_),\n-         fold_obj = bind identity_fold_obj[ENV](_,_,_),\n+         fold_obj = bind identity_fold_obj[ENV](_,_,_,_),\n \n          update_env_for_crate = bind identity_update_env_for_crate[ENV](_,_),\n          update_env_for_item = bind identity_update_env_for_item[ENV](_,_),\n+         update_env_for_native_item =\n+             bind identity_update_env_for_native_item[ENV](_,_),\n          update_env_for_view_item =\n              bind identity_update_env_for_view_item[ENV](_,_),\n          update_env_for_block = bind identity_update_env_for_block[ENV](_,_),"}, {"sha": "5b6db63166579ce8b98fcd2faf9f667fa2528ac8", "filename": "src/comp/middle/resolve.rs", "status": "modified", "additions": 111, "deletions": 31, "changes": 142, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Fresolve.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Fresolve.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Fresolve.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -18,6 +18,7 @@ import std._vec;\n tag scope {\n     scope_crate(@ast.crate);\n     scope_item(@ast.item);\n+    scope_native_item(@ast.native_item);\n     scope_loop(@ast.decl); // there's only 1 decl per loop.\n     scope_block(ast.block);\n     scope_arm(ast.arm);\n@@ -34,6 +35,7 @@ tag def_wrap {\n     def_wrap_use(@ast.view_item);\n     def_wrap_import(@ast.view_item);\n     def_wrap_mod(@ast.item);\n+    def_wrap_native_mod(@ast.item);\n     def_wrap_other(def);\n     def_wrap_expr_field(uint, def);\n     def_wrap_resolving;\n@@ -103,6 +105,29 @@ fn find_final_def(&env e, import_map index,\n     // should return what a.b.c.d points to in the end.\n     fn found_something(&env e, import_map index,\n                        &span sp, vec[ident] idents, def_wrap d) -> def_wrap {\n+\n+        fn found_mod(&env e, &import_map index, &span sp,\n+                     vec[ident] idents, @ast.item i) -> def_wrap {\n+            auto len = _vec.len[ident](idents);\n+            auto rest_idents = _vec.slice[ident](idents, 1u, len);\n+            auto empty_e = rec(scopes = nil[scope],\n+                               sess = e.sess);\n+            auto tmp_e = update_env_for_item(empty_e, i);\n+            auto next_i = rest_idents.(0);\n+            auto next_ = lookup_name_wrapped(tmp_e, next_i);\n+            alt (next_) {\n+                case (none[tup(@env, def_wrap)]) {\n+                    e.sess.span_err(sp, \"unresolved name: \" + next_i);\n+                    fail;\n+                }\n+                case (some[tup(@env, def_wrap)](?next)) {\n+                    auto combined_e = update_env_for_item(e, i);\n+                    ret found_something(combined_e, index, sp,\n+                                        rest_idents, next._1);\n+                }\n+            }\n+        }\n+\n         alt (d) {\n             case (def_wrap_import(?imp)) {\n                 alt (imp.node) {\n@@ -122,23 +147,10 @@ fn find_final_def(&env e, import_map index,\n         }\n         alt (d) {\n             case (def_wrap_mod(?i)) {\n-                auto rest_idents = _vec.slice[ident](idents, 1u, len);\n-                auto empty_e = rec(scopes = nil[scope],\n-                                   sess = e.sess);\n-                auto tmp_e = update_env_for_item(empty_e, i);\n-                auto next_i = rest_idents.(0);\n-                auto next_ = lookup_name_wrapped(tmp_e, next_i);\n-                alt (next_) {\n-                    case (none[tup(@env, def_wrap)]) {\n-                        e.sess.span_err(sp, \"unresolved name: \" + next_i);\n-                        fail;\n-                    }\n-                    case (some[tup(@env, def_wrap)](?next)) {\n-                        auto combined_e = update_env_for_item(e, i);\n-                        ret found_something(combined_e, index, sp,\n-                                            rest_idents, next._1);\n-                    }\n-                }\n+                ret found_mod(e, index, sp, idents, i);\n+            }\n+            case (def_wrap_native_mod(?i)) {\n+                ret found_mod(e, index, sp, idents, i);\n             }\n             case (def_wrap_use(?c)) {\n                 e.sess.span_err(sp, \"Crate access is not implemented\");\n@@ -201,6 +213,9 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n             case (ast.item_mod(_, _, ?id)) {\n                 ret def_wrap_mod(i);\n             }\n+            case (ast.item_native_mod(_, _, ?id)) {\n+                ret def_wrap_native_mod(i);\n+            }\n             case (ast.item_ty(_, _, _, ?id, _)) {\n                 ret def_wrap_other(ast.def_ty(id));\n             }\n@@ -213,6 +228,17 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n         }\n     }\n \n+    fn found_def_native_item(@ast.native_item i) -> def_wrap {\n+        alt (i.node) {\n+            case (ast.native_item_ty(_, ?id)) {\n+                ret def_wrap_other(ast.def_native_ty(id));\n+            }\n+            case (ast.native_item_fn(_, _, _, ?id, _)) {\n+                ret def_wrap_other(ast.def_native_fn(id));\n+            }\n+        }\n+    }\n+\n     fn found_decl_stmt(@ast.stmt s) -> def_wrap {\n         alt (s.node) {\n             case (ast.stmt_decl(?d)) {\n@@ -267,11 +293,47 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n                     }\n                 }\n             }\n-            case (none[ast.mod_index_entry]) { /* fall through */ }\n+            case (none[ast.mod_index_entry]) {\n+                ret none[def_wrap];\n+            }\n+        }\n+    }\n+\n+    fn check_native_mod(ast.ident i, ast.native_mod m) -> option.t[def_wrap] {\n+\n+        alt (m.index.find(i)) {\n+            case (some[ast.native_mod_index_entry](?ent)) {\n+                alt (ent) {\n+                    case (ast.nmie_view_item(?view_item)) {\n+                        ret some(found_def_view(view_item));\n+                    }\n+                    case (ast.nmie_item(?item)) {\n+                        ret some(found_def_native_item(item));\n+                    }\n+                }\n+            }\n+            case (none[ast.native_mod_index_entry]) {\n+                ret none[def_wrap];\n+            }\n         }\n-        ret none[def_wrap];\n     }\n \n+    fn handle_fn_decl(ast.ident i, &ast.fn_decl decl,\n+                      &vec[ast.ty_param] ty_params) -> option.t[def_wrap] {\n+        for (ast.arg a in decl.inputs) {\n+            if (_str.eq(a.ident, i)) {\n+                auto t = ast.def_arg(a.id);\n+                ret some(def_wrap_other(t));\n+            }\n+        }\n+        for (ast.ty_param tp in ty_params) {\n+            if (_str.eq(tp.ident, i)) {\n+                auto t = ast.def_ty_arg(tp.id);\n+                ret some(def_wrap_other(t));\n+            }\n+        }\n+        ret none[def_wrap];\n+    }\n \n     fn in_scope(ast.ident i, &scope s) -> option.t[def_wrap] {\n         alt (s) {\n@@ -283,9 +345,12 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n             case (scope_item(?it)) {\n                 alt (it.node) {\n                     case (ast.item_fn(_, ?f, ?ty_params, _, _)) {\n-                        for (ast.arg a in f.inputs) {\n-                            if (_str.eq(a.ident, i)) {\n-                                auto t = ast.def_arg(a.id);\n+                        ret handle_fn_decl(i, f.decl, ty_params);\n+                    }\n+                    case (ast.item_obj(_, ?ob, ?ty_params, _, _)) {\n+                        for (ast.obj_field f in ob.fields) {\n+                            if (_str.eq(f.ident, i)) {\n+                                auto t = ast.def_obj_field(f.id);\n                                 ret some(def_wrap_other(t));\n                             }\n                         }\n@@ -296,13 +361,7 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n                             }\n                         }\n                     }\n-                    case (ast.item_obj(_, ?ob, ?ty_params, _, _)) {\n-                        for (ast.obj_field f in ob.fields) {\n-                            if (_str.eq(f.ident, i)) {\n-                                auto t = ast.def_obj_field(f.id);\n-                                ret some(def_wrap_other(t));\n-                            }\n-                        }\n+                    case (ast.item_tag(_, _, ?ty_params, _)) {\n                         for (ast.ty_param tp in ty_params) {\n                             if (_str.eq(tp.ident, i)) {\n                                 auto t = ast.def_ty_arg(tp.id);\n@@ -313,6 +372,9 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n                     case (ast.item_mod(_, ?m, _)) {\n                         ret check_mod(i, m);\n                     }\n+                    case (ast.item_native_mod(_, ?m, _)) {\n+                        ret check_native_mod(i, m);\n+                    }\n                     case (ast.item_ty(_, _, ?ty_params, _, _)) {\n                         for (ast.ty_param tp in ty_params) {\n                             if (_str.eq(tp.ident, i)) {\n@@ -325,6 +387,14 @@ fn lookup_name_wrapped(&env e, ast.ident i) -> option.t[tup(@env, def_wrap)] {\n                 }\n             }\n \n+            case (scope_native_item(?it)) {\n+                alt (it.node) {\n+                    case (ast.native_item_fn(_, ?decl, ?ty_params, _, _)) {\n+                        ret handle_fn_decl(i, decl, ty_params);\n+                    }\n+                }\n+            }\n+\n             case (scope_loop(?d)) {\n                 alt (d.node) {\n                     case (ast.decl_local(?local)) {\n@@ -432,8 +502,7 @@ fn fold_expr_path(&env e, &span sp, &ast.path p, &option.t[def] d,\n             path_len = n_idents - remaining + 1u;\n         }\n         case (def_wrap_other(_)) {\n-            check (n_idents == 1u);\n-            path_len = 1u;\n+            path_len = n_idents;\n         }\n         case (def_wrap_mod(?m)) {\n             e.sess.span_err(sp,\n@@ -491,6 +560,10 @@ fn update_env_for_item(&env e, @ast.item i) -> env {\n     ret rec(scopes = cons[scope](scope_item(i), @e.scopes) with e);\n }\n \n+fn update_env_for_native_item(&env e, @ast.native_item i) -> env {\n+    ret rec(scopes = cons[scope](scope_native_item(i), @e.scopes) with e);\n+}\n+\n fn update_env_for_block(&env e, &ast.block b) -> env {\n     ret rec(scopes = cons[scope](scope_block(b), @e.scopes) with e);\n }\n@@ -500,6 +573,9 @@ fn update_env_for_expr(&env e, @ast.expr x) -> env {\n         case (ast.expr_for(?d, _, _, _)) {\n             ret rec(scopes = cons[scope](scope_loop(d), @e.scopes) with e);\n         }\n+        case (ast.expr_for_each(?d, _, _, _)) {\n+            ret rec(scopes = cons[scope](scope_loop(d), @e.scopes) with e);\n+        }\n         case (_) { }\n     }\n     ret e;\n@@ -517,6 +593,8 @@ fn resolve_imports(session.session sess, @ast.crate crate) -> @ast.crate {\n                     = bind fold_view_item_import(_,_,import_index,_,_,_,_),\n                 update_env_for_crate = bind update_env_for_crate(_,_),\n                 update_env_for_item = bind update_env_for_item(_,_),\n+                update_env_for_native_item =\n+                    bind update_env_for_native_item(_,_),\n                 update_env_for_block = bind update_env_for_block(_,_),\n                 update_env_for_arm = bind update_env_for_arm(_,_),\n                 update_env_for_expr = bind update_env_for_expr(_,_)\n@@ -539,6 +617,8 @@ fn resolve_crate(session.session sess, @ast.crate crate) -> @ast.crate {\n                 fold_ty_path = bind fold_ty_path(_,_,_,_),\n                 update_env_for_crate = bind update_env_for_crate(_,_),\n                 update_env_for_item = bind update_env_for_item(_,_),\n+                update_env_for_native_item =\n+                    bind update_env_for_native_item(_,_),\n                 update_env_for_block = bind update_env_for_block(_,_),\n                 update_env_for_arm = bind update_env_for_arm(_,_),\n                 update_env_for_expr = bind update_env_for_expr(_,_)"}, {"sha": "728f20dd0eb81fd524a6ee17320b9d39e47c470d", "filename": "src/comp/middle/trans.rs", "status": "modified", "additions": 2379, "deletions": 962, "changes": 3341, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Ftrans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Ftrans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftrans.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c"}, {"sha": "5a595db6ea5bf51a077588826503975869dbadcb", "filename": "src/comp/middle/ty.rs", "status": "modified", "additions": 489, "deletions": 190, "changes": 679, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Fty.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -19,7 +19,10 @@ import util.common.span;\n \n type arg = rec(ast.mode mode, @t ty);\n type field = rec(ast.ident ident, @t ty);\n-type method = rec(ast.ident ident, vec[arg] inputs, @t output);\n+type method = rec(ast.proto proto,\n+                  ast.ident ident,\n+                  vec[arg] inputs,\n+                  @t output);\n \n // NB: If you change this, you'll probably want to change the corresponding\n // AST structure in front/ast.rs as well.\n@@ -32,16 +35,19 @@ tag sty {\n     ty_machine(util.common.ty_mach);\n     ty_char;\n     ty_str;\n-    ty_tag(ast.def_id);\n+    ty_tag(ast.def_id, vec[@t]);\n     ty_box(@t);\n     ty_vec(@t);\n     ty_tup(vec[@t]);\n     ty_rec(vec[field]);\n-    ty_fn(vec[arg], @t);                            // TODO: effect\n+    ty_fn(ast.proto, vec[arg], @t);                 // TODO: effect\n+    ty_native_fn(ast.native_abi, vec[arg], @t);     // TODO: effect\n     ty_obj(vec[method]);\n     ty_var(int);                                    // ephemeral type var\n     ty_local(ast.def_id);                           // type of a local var\n-    ty_param(ast.def_id);                           // fn type param\n+    ty_param(ast.def_id);                           // fn/tag type param\n+    ty_type;\n+    ty_native;\n     // TODO: ty_fn_arg(@t), for a possibly-aliased function argument\n }\n \n@@ -103,6 +109,7 @@ fn ast_ty_to_str(&@ast.ty ty) -> str {\n         case (ast.ty_str)          { s = \"str\";                           }\n         case (ast.ty_box(?t))      { s = \"@\" + ast_ty_to_str(t);          }\n         case (ast.ty_vec(?t))      { s = \"vec[\" + ast_ty_to_str(t) + \"]\"; }\n+        case (ast.ty_type)         { s = \"type\";                          }\n \n         case (ast.ty_tup(?elts)) {\n             auto f = ast_ty_to_str;\n@@ -118,9 +125,13 @@ fn ast_ty_to_str(&@ast.ty ty) -> str {\n             s += \")\";\n         }\n \n-        case (ast.ty_fn(?inputs, ?output)) {\n+        case (ast.ty_fn(?proto, ?inputs, ?output)) {\n             auto f = ast_fn_input_to_str;\n-            s = \"fn(\";\n+            if (proto == ast.proto_fn) {\n+                s = \"fn(\";\n+            } else {\n+                s = \"iter(\";\n+            }\n             auto is = _vec.map[rec(ast.mode mode, @ast.ty ty),str](f, inputs);\n             s += _str.connect(is, \", \");\n             s += \")\";\n@@ -138,6 +149,7 @@ fn ast_ty_to_str(&@ast.ty ty) -> str {\n             s = \"mutable \" + ast_ty_to_str(t);\n         }\n \n+\n         case (_) {\n             fail;   // FIXME: typestate bug\n         }\n@@ -157,6 +169,8 @@ fn path_to_str(&ast.path pth) -> str {\n     ret result;\n }\n \n+// FIXME use the pretty-printer for this once it has a concept of an\n+// abstract stream\n fn ty_to_str(&@t typ) -> str {\n \n     fn fn_input_to_str(&rec(ast.mode mode, @t ty) input) -> str {\n@@ -170,10 +184,14 @@ fn ty_to_str(&@t typ) -> str {\n         ret s + ty_to_str(input.ty);\n     }\n \n-    fn fn_to_str(option.t[ast.ident] ident,\n+    fn fn_to_str(ast.proto proto,\n+                 option.t[ast.ident] ident,\n                  vec[arg] inputs, @t output) -> str {\n             auto f = fn_input_to_str;\n             auto s = \"fn\";\n+            if (proto == ast.proto_iter) {\n+                s = \"iter\";\n+            }\n             alt (ident) {\n                 case (some[ast.ident](?i)) {\n                     s += \" \";\n@@ -193,7 +211,8 @@ fn ty_to_str(&@t typ) -> str {\n     }\n \n     fn method_to_str(&method m) -> str {\n-        ret fn_to_str(some[ast.ident](m.ident), m.inputs, m.output) + \";\";\n+        ret fn_to_str(m.proto, some[ast.ident](m.ident),\n+                      m.inputs, m.output) + \";\";\n     }\n \n     fn field_to_str(&field f) -> str {\n@@ -206,6 +225,7 @@ fn ty_to_str(&@t typ) -> str {\n     }\n \n     alt (typ.struct) {\n+        case (ty_native)       { s = \"native\";                    }\n         case (ty_nil)          { s = \"()\";                        }\n         case (ty_bool)         { s = \"bool\";                      }\n         case (ty_int)          { s = \"int\";                       }\n@@ -215,6 +235,7 @@ fn ty_to_str(&@t typ) -> str {\n         case (ty_str)          { s = \"str\";                       }\n         case (ty_box(?t))      { s = \"@\" + ty_to_str(t);          }\n         case (ty_vec(?t))      { s = \"vec[\" + ty_to_str(t) + \"]\"; }\n+        case (ty_type)         { s = \"type\";                      }\n \n         case (ty_tup(?elems)) {\n             auto f = ty_to_str;\n@@ -228,13 +249,23 @@ fn ty_to_str(&@t typ) -> str {\n             s = \"rec(\" + _str.connect(strs, \",\") + \")\";\n         }\n \n-        case (ty_tag(_)) {\n+        case (ty_tag(?id, ?tps)) {\n             // The user should never see this if the cname is set properly!\n-            s = \"<tag>\";\n+            s = \"<tag#\" + util.common.istr(id._0) + \":\" +\n+                util.common.istr(id._1) + \">\";\n+            if (_vec.len[@t](tps) > 0u) {\n+                auto f = ty_to_str;\n+                auto strs = _vec.map[@t,str](f, tps);\n+                s += \"[\" + _str.connect(strs, \",\") + \"]\";\n+            }\n+        }\n+\n+        case (ty_fn(?proto, ?inputs, ?output)) {\n+            s = fn_to_str(proto, none[ast.ident], inputs, output);\n         }\n \n-        case (ty_fn(?inputs, ?output)) {\n-            s = fn_to_str(none[ast.ident], inputs, output);\n+        case (ty_native_fn(_, ?inputs, ?output)) {\n+            s = fn_to_str(ast.proto_fn, none[ast.ident], inputs, output);\n         }\n \n         case (ty_obj(?meths)) {\n@@ -280,13 +311,21 @@ fn fold_ty(ty_fold fld, @t ty) -> @t {\n         case (ty_machine(_))    { ret fld.fold_simple_ty(ty); }\n         case (ty_char)          { ret fld.fold_simple_ty(ty); }\n         case (ty_str)           { ret fld.fold_simple_ty(ty); }\n-        case (ty_tag(_))        { ret fld.fold_simple_ty(ty); }\n+        case (ty_type)          { ret fld.fold_simple_ty(ty); }\n+        case (ty_native)        { ret fld.fold_simple_ty(ty); }\n         case (ty_box(?subty)) {\n             ret rewrap(ty, ty_box(fold_ty(fld, subty)));\n         }\n         case (ty_vec(?subty)) {\n             ret rewrap(ty, ty_vec(fold_ty(fld, subty)));\n         }\n+        case (ty_tag(?tid, ?subtys)) {\n+            let vec[@t] new_subtys = vec();\n+            for (@t subty in subtys) {\n+                new_subtys += vec(fold_ty(fld, subty));\n+            }\n+            ret rewrap(ty, ty_tag(tid, new_subtys));\n+        }\n         case (ty_tup(?subtys)) {\n             let vec[@t] new_subtys = vec();\n             for (@t subty in subtys) {\n@@ -302,13 +341,21 @@ fn fold_ty(ty_fold fld, @t ty) -> @t {\n             }\n             ret rewrap(ty, ty_rec(new_fields));\n         }\n-        case (ty_fn(?args, ?ret_ty)) {\n+        case (ty_fn(?proto, ?args, ?ret_ty)) {\n             let vec[arg] new_args = vec();\n             for (arg a in args) {\n                 auto new_ty = fold_ty(fld, a.ty);\n                 new_args += vec(rec(mode=a.mode, ty=new_ty));\n             }\n-            ret rewrap(ty, ty_fn(new_args, fold_ty(fld, ret_ty)));\n+            ret rewrap(ty, ty_fn(proto, new_args, fold_ty(fld, ret_ty)));\n+        }\n+        case (ty_native_fn(?abi, ?args, ?ret_ty)) {\n+            let vec[arg] new_args = vec();\n+            for (arg a in args) {\n+                auto new_ty = fold_ty(fld, a.ty);\n+                new_args += vec(rec(mode=a.mode, ty=new_ty));\n+            }\n+            ret rewrap(ty, ty_native_fn(abi, new_args, fold_ty(fld, ret_ty)));\n         }\n         case (ty_obj(?methods)) {\n             let vec[method] new_methods = vec();\n@@ -317,7 +364,8 @@ fn fold_ty(ty_fold fld, @t ty) -> @t {\n                 for (arg a in m.inputs) {\n                     new_args += vec(rec(mode=a.mode, ty=fold_ty(fld, a.ty)));\n                 }\n-                new_methods += vec(rec(ident=m.ident, inputs=new_args,\n+                new_methods += vec(rec(proto=m.proto, ident=m.ident,\n+                                       inputs=new_args,\n                                        output=fold_ty(fld, m.output)));\n             }\n             ret rewrap(ty, ty_obj(new_methods));\n@@ -327,7 +375,7 @@ fn fold_ty(ty_fold fld, @t ty) -> @t {\n         case (ty_param(_))      { ret fld.fold_simple_ty(ty); }\n     }\n \n-    ret ty;\n+    fail;\n }\n \n // Type utilities\n@@ -349,24 +397,44 @@ fn type_is_nil(@t ty) -> bool {\n     fail;\n }\n \n+\n fn type_is_structural(@t ty) -> bool {\n     alt (ty.struct) {\n-        case (ty_tup(_)) { ret true; }\n-        case (ty_rec(_)) { ret true; }\n-        case (ty_tag(_)) { ret true; }\n-        case (ty_fn(_,_)) { ret true; }\n-        case (ty_obj(_)) { ret true; }\n-        case (_) { ret false; }\n+        case (ty_tup(_))    { ret true; }\n+        case (ty_rec(_))    { ret true; }\n+        case (ty_tag(_,_))  { ret true; }\n+        case (ty_fn(_,_,_)) { ret true; }\n+        case (ty_obj(_))    { ret true; }\n+        case (_)            { ret false; }\n+    }\n+    fail;\n+}\n+\n+fn type_is_sequence(@t ty) -> bool {\n+    alt (ty.struct) {\n+        case (ty_str)    { ret true; }\n+        case (ty_vec(_))    { ret true; }\n+        case (_)            { ret false; }\n+    }\n+    fail;\n+}\n+\n+fn sequence_element_type(@t ty) -> @t {\n+    alt (ty.struct) {\n+        case (ty_str)     { ret plain_ty(ty_machine(common.ty_u8)); }\n+        case (ty_vec(?e)) { ret e; }\n     }\n     fail;\n }\n \n+\n fn type_is_tup_like(@t ty) -> bool {\n     alt (ty.struct) {\n-        case (ty_tup(_)) { ret true; }\n-        case (ty_rec(_)) { ret true; }\n-        case (ty_tag(_)) { ret true; }\n-        case (_) { ret false; }\n+        case (ty_box(_))    { ret true; }\n+        case (ty_tup(_))    { ret true; }\n+        case (ty_rec(_))    { ret true; }\n+        case (ty_tag(_,_))  { ret true; }\n+        case (_)            { ret false; }\n     }\n     fail;\n }\n@@ -402,6 +470,17 @@ fn type_is_scalar(@t ty) -> bool {\n         case (ty_uint) { ret true; }\n         case (ty_machine(_)) { ret true; }\n         case (ty_char) { ret true; }\n+        case (ty_type) { ret true; }\n+        case (_) { ret false; }\n+    }\n+    fail;\n+}\n+\n+// FIXME: should we just return true for native types in\n+// type_is_scalar?\n+fn type_is_native(@t ty) -> bool {\n+    alt (ty.struct) {\n+        case (ty_native) { ret true; }\n         case (_) { ret false; }\n     }\n     fail;\n@@ -423,6 +502,13 @@ fn type_has_dynamic_size(@t ty) -> bool {\n                 i += 1u;\n             }\n         }\n+        case (ty_tag(_, ?subtys)) {\n+            auto i = 0u;\n+            while (i < _vec.len[@t](subtys)) {\n+                if (type_has_dynamic_size(subtys.(i))) { ret true; }\n+                i += 1u;\n+            }\n+        }\n         case (ty_param(_)) { ret true; }\n         case (_) { /* fall through */ }\n     }\n@@ -547,31 +633,67 @@ fn count_ty_params(@t ty) -> uint {\n // Type accessors for substructures of types\n \n fn ty_fn_args(@t fty) -> vec[arg] {\n-  alt (fty.struct) {\n-    case (ty.ty_fn(?a, _)) { ret a; }\n-  }\n+    alt (fty.struct) {\n+        case (ty.ty_fn(_, ?a, _)) { ret a; }\n+        case (ty.ty_native_fn(_, ?a, _)) { ret a; }\n+    }\n+    fail;\n+}\n+\n+fn ty_fn_proto(@t fty) -> ast.proto {\n+    alt (fty.struct) {\n+        case (ty.ty_fn(?p, _, _)) { ret p; }\n+    }\n+    fail;\n+}\n+\n+fn ty_fn_abi(@t fty) -> ast.native_abi {\n+    alt (fty.struct) {\n+        case (ty.ty_native_fn(?a, _, _)) { ret a; }\n+    }\n+    fail;\n }\n \n fn ty_fn_ret(@t fty) -> @t {\n-  alt (fty.struct) {\n-    case (ty.ty_fn(_, ?r)) { ret r; }\n-  }\n+    alt (fty.struct) {\n+        case (ty.ty_fn(_, _, ?r)) { ret r; }\n+        case (ty.ty_native_fn(_, _, ?r)) { ret r; }\n+    }\n+    fail;\n }\n \n fn is_fn_ty(@t fty) -> bool {\n-  alt (fty.struct) {\n-    case (ty.ty_fn(_, _)) { ret true; }\n-    case (_) { ret false; }\n-  }\n-  ret false;\n+    alt (fty.struct) {\n+        case (ty.ty_fn(_, _, _)) { ret true; }\n+        case (ty.ty_native_fn(_, _, _)) { ret true; }\n+        case (_) { ret false; }\n+    }\n+    ret false;\n }\n \n \n // Type accessors for AST nodes\n \n // Given an item, returns the associated type as well as a list of the IDs of\n // its type parameters.\n-fn item_ty(@ast.item it) -> tup(vec[ast.def_id], @t) {\n+type ty_params_and_ty = tup(vec[ast.def_id], @t);\n+fn native_item_ty(@ast.native_item it) -> ty_params_and_ty {\n+    auto ty_params;\n+    auto result_ty;\n+    alt (it.node) {\n+        case (ast.native_item_fn(_, _, ?tps, _, ?ann)) {\n+            ty_params = tps;\n+            result_ty = ann_to_type(ann);\n+        }\n+    }\n+    let vec[ast.def_id] ty_param_ids = vec();\n+    for (ast.ty_param tp in ty_params) {\n+        ty_param_ids += vec(tp.id);\n+    }\n+    ret tup(ty_param_ids, result_ty);\n+}\n+\n+fn item_ty(@ast.item it) -> ty_params_and_ty {\n     let vec[ast.ty_param] ty_params;\n     auto result_ty;\n     alt (it.node) {\n@@ -591,8 +713,13 @@ fn item_ty(@ast.item it) -> tup(vec[ast.def_id], @t) {\n             result_ty = ann_to_type(ann);\n         }\n         case (ast.item_tag(_, _, ?tps, ?did)) {\n+            // Create a new generic polytype.\n             ty_params = tps;\n-            result_ty = plain_ty(ty_tag(did));\n+            let vec[@t] subtys = vec();\n+            for (ast.ty_param tp in tps) {\n+                subtys += vec(plain_ty(ty_param(tp.id)));\n+            }\n+            result_ty = plain_ty(ty_tag(did, subtys));\n         }\n         case (ast.item_obj(_, _, ?tps, _, ?ann)) {\n             ty_params = tps;\n@@ -628,6 +755,7 @@ fn block_ty(&ast.block b) -> @t {\n fn pat_ty(@ast.pat pat) -> @t {\n     alt (pat.node) {\n         case (ast.pat_wild(?ann))           { ret ann_to_type(ann); }\n+        case (ast.pat_lit(_, ?ann))         { ret ann_to_type(ann); }\n         case (ast.pat_bind(_, _, ?ann))     { ret ann_to_type(ann); }\n         case (ast.pat_tag(_, _, _, ?ann))   { ret ann_to_type(ann); }\n     }\n@@ -638,7 +766,7 @@ fn expr_ty(@ast.expr expr) -> @t {\n     alt (expr.node) {\n         case (ast.expr_vec(_, ?ann))          { ret ann_to_type(ann); }\n         case (ast.expr_tup(_, ?ann))          { ret ann_to_type(ann); }\n-        case (ast.expr_rec(_, ?ann))          { ret ann_to_type(ann); }\n+        case (ast.expr_rec(_, _, ?ann))       { ret ann_to_type(ann); }\n         case (ast.expr_bind(_, _, ?ann))      { ret ann_to_type(ann); }\n         case (ast.expr_call(_, _, ?ann))      { ret ann_to_type(ann); }\n         case (ast.expr_binary(_, _, _, ?ann)) { ret ann_to_type(ann); }\n@@ -647,6 +775,8 @@ fn expr_ty(@ast.expr expr) -> @t {\n         case (ast.expr_cast(_, _, ?ann))      { ret ann_to_type(ann); }\n         case (ast.expr_if(_, _, _, ?ann))     { ret ann_to_type(ann); }\n         case (ast.expr_for(_, _, _, ?ann))    { ret ann_to_type(ann); }\n+        case (ast.expr_for_each(_, _, _, ?ann))\n+                                              { ret ann_to_type(ann); }\n         case (ast.expr_while(_, _, ?ann))     { ret ann_to_type(ann); }\n         case (ast.expr_do_while(_, _, ?ann))  { ret ann_to_type(ann); }\n         case (ast.expr_alt(_, _, ?ann))       { ret ann_to_type(ann); }\n@@ -657,6 +787,14 @@ fn expr_ty(@ast.expr expr) -> @t {\n         case (ast.expr_field(_, _, ?ann))     { ret ann_to_type(ann); }\n         case (ast.expr_index(_, _, ?ann))     { ret ann_to_type(ann); }\n         case (ast.expr_path(_, _, ?ann))      { ret ann_to_type(ann); }\n+        case (ast.expr_ext(_, _, _, _, ?ann)) { ret ann_to_type(ann); }\n+\n+        case (ast.expr_fail)                  { ret plain_ty(ty_nil); }\n+        case (ast.expr_log(_))                { ret plain_ty(ty_nil); }\n+        case (ast.expr_check_expr(_))         { ret plain_ty(ty_nil); }\n+        case (ast.expr_ret(_))                { ret plain_ty(ty_nil); }\n+        case (ast.expr_put(_))                { ret plain_ty(ty_nil); }\n+        case (ast.expr_be(_))                 { ret plain_ty(ty_nil); }\n     }\n     fail;\n }\n@@ -726,7 +864,10 @@ fn is_lval(@ast.expr expr) -> bool {\n     }\n }\n \n-// Type unification\n+// Type unification via Robinson's algorithm (Robinson 1965). Implemented as\n+// described in Hoder and Voronkov:\n+//\n+//     http://www.cs.man.ac.uk/~hoderk/ubench/unification_full.pdf\n \n fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n         -> unify_result {\n@@ -746,81 +887,137 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n         ret ures_err(terr_mismatch, expected, actual);\n     }\n \n-    fn unify_fn(&hashmap[int,@ty.t] bindings,\n-                @ty.t expected,\n-                @ty.t actual,\n-                &unify_handler handler,\n-                vec[arg] expected_inputs, @t expected_output,\n-                vec[arg] actual_inputs, @t actual_output)\n-      -> unify_result {\n-      auto expected_len = _vec.len[arg](expected_inputs);\n-      auto actual_len = _vec.len[arg](actual_inputs);\n-      if (expected_len != actual_len) {\n-        ret ures_err(terr_arg_count, expected, actual);\n-      }\n+    tag fn_common_res {\n+        fn_common_res_err(unify_result);\n+        fn_common_res_ok(vec[arg], @t);\n+    }\n \n-      // TODO: as above, we should have an iter2 iterator.\n-      let vec[arg] result_ins = vec();\n-      auto i = 0u;\n-      while (i < expected_len) {\n-        auto expected_input = expected_inputs.(i);\n-        auto actual_input = actual_inputs.(i);\n-\n-        // This should be safe, I think?\n-        auto result_mode;\n-        if (mode_is_alias(expected_input.mode) ||\n-            mode_is_alias(actual_input.mode)) {\n-          result_mode = ast.alias;\n-        } else {\n-          result_mode = ast.val;\n+    fn unify_fn_common(@hashmap[int,@ty.t] bindings,\n+                       @ty.t expected,\n+                       @ty.t actual,\n+                       &unify_handler handler,\n+                       vec[arg] expected_inputs, @t expected_output,\n+                       vec[arg] actual_inputs, @t actual_output)\n+        -> fn_common_res {\n+        auto expected_len = _vec.len[arg](expected_inputs);\n+        auto actual_len = _vec.len[arg](actual_inputs);\n+        if (expected_len != actual_len) {\n+            ret fn_common_res_err(ures_err(terr_arg_count,\n+                                           expected, actual));\n+        }\n+\n+        // TODO: as above, we should have an iter2 iterator.\n+        let vec[arg] result_ins = vec();\n+        auto i = 0u;\n+        while (i < expected_len) {\n+            auto expected_input = expected_inputs.(i);\n+            auto actual_input = actual_inputs.(i);\n+\n+            // This should be safe, I think?\n+            auto result_mode;\n+            if (mode_is_alias(expected_input.mode) ||\n+                mode_is_alias(actual_input.mode)) {\n+                result_mode = ast.alias;\n+            } else {\n+                result_mode = ast.val;\n+            }\n+\n+            auto result = unify_step(bindings,\n+                                     actual_input.ty,\n+                                     expected_input.ty,\n+                                     handler);\n+\n+            alt (result) {\n+                case (ures_ok(?rty)) {\n+                    result_ins += vec(rec(mode=result_mode,\n+                                          ty=rty));\n+                }\n+\n+                case (_) {\n+                    ret fn_common_res_err(result);\n+                }\n+            }\n+\n+            i += 1u;\n         }\n \n+        // Check the output.\n         auto result = unify_step(bindings,\n-                                 actual_input.ty,\n-                                 expected_input.ty,\n+                                 expected_output,\n+                                 actual_output,\n                                  handler);\n-\n         alt (result) {\n-          case (ures_ok(?rty)) {\n-            result_ins += vec(rec(mode=result_mode,\n-                                  ty=rty));\n-          }\n+            case (ures_ok(?rty)) {\n+                ret fn_common_res_ok(result_ins, rty);\n+            }\n \n-          case (_) {\n-            ret result;\n-          }\n+            case (_) {\n+                ret fn_common_res_err(result);\n+            }\n         }\n+    }\n \n-        i += 1u;\n-      }\n+    fn unify_fn(@hashmap[int,@ty.t] bindings,\n+                ast.proto e_proto,\n+                ast.proto a_proto,\n+                @ty.t expected,\n+                @ty.t actual,\n+                &unify_handler handler,\n+                vec[arg] expected_inputs, @t expected_output,\n+                vec[arg] actual_inputs, @t actual_output)\n+        -> unify_result {\n \n-      // Check the output.\n-      auto result_out;\n-      auto result = unify_step(bindings,\n-                               expected_output,\n-                               actual_output,\n-                               handler);\n-      alt (result) {\n-        case (ures_ok(?rty)) {\n-          result_out = rty;\n+        if (e_proto != a_proto) {\n+            ret ures_err(terr_mismatch, expected, actual);\n         }\n-\n-        case (_) {\n-          ret result;\n+        auto t = unify_fn_common(bindings, expected, actual,\n+                                 handler, expected_inputs, expected_output,\n+                                 actual_inputs, actual_output);\n+        alt (t) {\n+            case (fn_common_res_err(?r)) {\n+                ret r;\n+            }\n+            case (fn_common_res_ok(?result_ins, ?result_out)) {\n+                auto t2 = plain_ty(ty.ty_fn(e_proto, result_ins, result_out));\n+                ret ures_ok(t2);\n+            }\n         }\n-      }\n+    }\n \n-      auto t = plain_ty(ty.ty_fn(result_ins, result_out));\n-      ret ures_ok(t);\n+    fn unify_native_fn(@hashmap[int,@ty.t] bindings,\n+                       ast.native_abi e_abi,\n+                       ast.native_abi a_abi,\n+                       @ty.t expected,\n+                       @ty.t actual,\n+                       &unify_handler handler,\n+                       vec[arg] expected_inputs, @t expected_output,\n+                       vec[arg] actual_inputs, @t actual_output)\n+        -> unify_result {\n+        if (e_abi != a_abi) {\n+            ret ures_err(terr_mismatch, expected, actual);\n+        }\n \n+        auto t = unify_fn_common(bindings, expected, actual,\n+                                 handler, expected_inputs, expected_output,\n+                                 actual_inputs, actual_output);\n+        alt (t) {\n+            case (fn_common_res_err(?r)) {\n+                ret r;\n+            }\n+            case (fn_common_res_ok(?result_ins, ?result_out)) {\n+                auto t2 = plain_ty(ty.ty_native_fn(e_abi, result_ins,\n+                                                   result_out));\n+                ret ures_ok(t2);\n+            }\n+        }\n     }\n \n-    fn unify_obj(&hashmap[int,@ty.t] bindings,\n-                @ty.t expected,\n-                @ty.t actual,\n-                &unify_handler handler,\n-                vec[method] expected_meths,\n-                vec[method] actual_meths) -> unify_result {\n+    fn unify_obj(@hashmap[int,@ty.t] bindings,\n+                 @ty.t expected,\n+                 @ty.t actual,\n+                 &unify_handler handler,\n+                 vec[method] expected_meths,\n+                 vec[method] actual_meths) -> unify_result {\n       let vec[method] result_meths = vec();\n       let uint i = 0u;\n       let uint expected_len = _vec.len[method](expected_meths);\n@@ -830,73 +1027,76 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n         ret ures_err(terr_meth_count, expected, actual);\n       }\n \n-      // FIXME: work around buggy typestate logic for 'alt', sigh.\n-      fn is_ok(&unify_result r) -> bool {\n-        alt (r) {\n-          case (ures_ok(?tfn)) {\n-            ret true;\n-          }\n-          case (_) {}\n-        }\n-        ret false;\n-      }\n-\n-      fn append_if_ok(&method e_meth,\n-                      &unify_result r, &mutable vec[method] result_meths) {\n-        alt (r) {\n-          case (ures_ok(?tfn)) {\n-            alt (tfn.struct) {\n-              case (ty_fn(?ins, ?out)) {\n-                result_meths += vec(rec(inputs = ins,\n-                                        output = out\n-                                        with e_meth));\n-              }\n-            }\n-          }\n-        }\n-      }\n-\n       while (i < expected_len) {\n         auto e_meth = expected_meths.(i);\n         auto a_meth = actual_meths.(i);\n         if (! _str.eq(e_meth.ident, a_meth.ident)) {\n           ret ures_err(terr_obj_meths(e_meth.ident, a_meth.ident),\n                        expected, actual);\n         }\n-        auto r = unify_fn(bindings, expected, actual, handler,\n+        auto r = unify_fn(bindings,\n+                          e_meth.proto, a_meth.proto,\n+                          expected, actual, handler,\n                           e_meth.inputs, e_meth.output,\n                           a_meth.inputs, a_meth.output);\n-        if (!is_ok(r)) {\n-          ret r;\n+        alt (r) {\n+            case (ures_ok(?tfn)) {\n+                alt (tfn.struct) {\n+                    case (ty_fn(?proto, ?ins, ?out)) {\n+                        result_meths += vec(rec(inputs = ins,\n+                                                output = out\n+                                                with e_meth));\n+                    }\n+                }\n+            }\n+            case (_) {\n+                ret r;\n+            }\n         }\n-        append_if_ok(e_meth, r, result_meths);\n         i += 1u;\n       }\n       auto t = plain_ty(ty_obj(result_meths));\n       ret ures_ok(t);\n     }\n \n-    fn unify_step(&hashmap[int,@ty.t] bindings, @ty.t expected, @ty.t actual,\n-                  &unify_handler handler) -> unify_result {\n+    fn resolve(@hashmap[int,@t] bindings, @t typ) -> @t {\n+        alt (typ.struct) {\n+            case (ty_var(?id)) {\n+                alt (bindings.find(id)) {\n+                    case (some[@t](?typ2)) {\n+                        ret resolve(bindings, typ2);\n+                    }\n+                    case (none[@t]) {\n+                        // fall through\n+                    }\n+                }\n+            }\n+            case (_) {\n+                // fall through\n+            }\n+        }\n+        ret typ;\n+    }\n+\n+    fn unify_step(@hashmap[int,@ty.t] bindings, @ty.t in_expected,\n+                  @ty.t in_actual, &unify_handler handler) -> unify_result {\n+\n+        // Resolve any bindings.\n+        auto expected = resolve(bindings, in_expected);\n+        auto actual = resolve(bindings, in_actual);\n+\n         // TODO: rewrite this using tuple pattern matching when available, to\n         // avoid all this rightward drift and spikiness.\n \n+        // TODO: occurs check, to make sure we don't loop forever when\n+        // unifying e.g. 'a and option['a]\n+\n         alt (actual.struct) {\n             // If the RHS is a variable type, then just do the appropriate\n             // binding.\n             case (ty.ty_var(?actual_id)) {\n-                alt (bindings.find(actual_id)) {\n-                    case (some[@ty.t](?actual_ty)) {\n-                        // FIXME: change the binding here?\n-                        // FIXME: \"be\"\n-                        ret unify_step(bindings, expected, actual_ty,\n-                                       handler);\n-                    }\n-                    case (none[@ty.t]) {\n-                        bindings.insert(actual_id, expected);\n-                        ret ures_ok(expected);\n-                    }\n-                }\n+                bindings.insert(actual_id, expected);\n+                ret ures_ok(expected);\n             }\n             case (ty.ty_local(?actual_id)) {\n                 auto actual_ty = handler.resolve_local(actual_id);\n@@ -938,14 +1138,45 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n             case (ty.ty_machine(_)) { ret struct_cmp(expected, actual); }\n             case (ty.ty_char)       { ret struct_cmp(expected, actual); }\n             case (ty.ty_str)        { ret struct_cmp(expected, actual); }\n+            case (ty.ty_type)       { ret struct_cmp(expected, actual); }\n+            case (ty.ty_native)     { ret struct_cmp(expected, actual); }\n \n-            case (ty.ty_tag(?expected_id)) {\n+            case (ty.ty_tag(?expected_id, ?expected_tps)) {\n                 alt (actual.struct) {\n-                    case (ty.ty_tag(?actual_id)) {\n-                        if (expected_id._0 == actual_id._0 &&\n-                                expected_id._1 == actual_id._1) {\n-                            ret ures_ok(expected);\n+                    case (ty.ty_tag(?actual_id, ?actual_tps)) {\n+                        if (expected_id._0 != actual_id._0 ||\n+                                expected_id._1 != actual_id._1) {\n+                            ret ures_err(terr_mismatch, expected, actual);\n                         }\n+\n+                        // TODO: factor this cruft out, see the TODO in the\n+                        // ty.ty_tup case\n+                        let vec[@ty.t] result_tps = vec();\n+                        auto i = 0u;\n+                        auto expected_len = _vec.len[@ty.t](expected_tps);\n+                        while (i < expected_len) {\n+                            auto expected_tp = expected_tps.(i);\n+                            auto actual_tp = actual_tps.(i);\n+\n+                            auto result = unify_step(bindings,\n+                                                     expected_tp,\n+                                                     actual_tp,\n+                                                     handler);\n+\n+                            alt (result) {\n+                                case (ures_ok(?rty)) {\n+                                    append[@ty.t](result_tps, rty);\n+                                }\n+                                case (_) {\n+                                    ret result;\n+                                }\n+                            }\n+\n+                            i += 1u;\n+                        }\n+\n+                        ret ures_ok(plain_ty(ty.ty_tag(expected_id,\n+                                                       result_tps)));\n                     }\n                     case (_) { /* fall through */ }\n                 }\n@@ -970,8 +1201,6 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n                         }\n                     }\n \n-                    // TODO: ty_var\n-\n                     case (_) {\n                         ret ures_err(terr_mismatch, expected, actual);\n                     }\n@@ -995,8 +1224,6 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n                         }\n                     }\n \n-                    // TODO: ty_var\n-\n                     case (_) {\n                         ret ures_err(terr_mismatch, expected, actual);\n                    }\n@@ -1045,8 +1272,6 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n                         ret ures_ok(plain_ty(ty.ty_tup(result_elems)));\n                     }\n \n-                    // TODO: ty_var\n-\n                     case (_) {\n                         ret ures_err(terr_mismatch, expected, actual);\n                     }\n@@ -1106,20 +1331,19 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n                         ret ures_ok(plain_ty(ty.ty_rec(result_fields)));\n                     }\n \n-                    // TODO: ty_var\n-\n                     case (_) {\n                         ret ures_err(terr_mismatch, expected, actual);\n                     }\n                 }\n             }\n \n-            case (ty.ty_fn(?expected_inputs, ?expected_output)) {\n+            case (ty.ty_fn(?ep, ?expected_inputs, ?expected_output)) {\n                 alt (actual.struct) {\n-                    case (ty.ty_fn(?actual_inputs, ?actual_output)) {\n-                      ret unify_fn(bindings, expected, actual, handler,\n-                                   expected_inputs, expected_output,\n-                                   actual_inputs, actual_output);\n+                    case (ty.ty_fn(?ap, ?actual_inputs, ?actual_output)) {\n+                        ret unify_fn(bindings, ep, ap,\n+                                     expected, actual, handler,\n+                                     expected_inputs, expected_output,\n+                                     actual_inputs, actual_output);\n                     }\n \n                     case (_) {\n@@ -1128,35 +1352,40 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n                 }\n             }\n \n-            case (ty.ty_obj(?expected_meths)) {\n-              alt (actual.struct) {\n-                case (ty.ty_obj(?actual_meths)) {\n-                  ret unify_obj(bindings, expected, actual, handler,\n-                                expected_meths, actual_meths);\n-                }\n-                case (_) {\n-                  ret ures_err(terr_mismatch, expected, actual);\n+            case (ty.ty_native_fn(?e_abi, ?expected_inputs,\n+                                  ?expected_output)) {\n+                alt (actual.struct) {\n+                    case (ty.ty_native_fn(?a_abi, ?actual_inputs,\n+                                          ?actual_output)) {\n+                        ret unify_native_fn(bindings, e_abi, a_abi,\n+                                            expected, actual, handler,\n+                                            expected_inputs, expected_output,\n+                                            actual_inputs, actual_output);\n+                    }\n+                    case (_) {\n+                        ret ures_err(terr_mismatch, expected, actual);\n+                    }\n                 }\n-              }\n             }\n \n-            case (ty.ty_var(?expected_id)) {\n-                alt (bindings.find(expected_id)) {\n-                    case (some[@ty.t](?expected_ty)) {\n-                        // FIXME: change the binding here?\n-                        // FIXME: \"be\"\n-                        ret unify_step(bindings,\n-                                       expected_ty,\n-                                       actual,\n-                                       handler);\n+            case (ty.ty_obj(?expected_meths)) {\n+                alt (actual.struct) {\n+                    case (ty.ty_obj(?actual_meths)) {\n+                        ret unify_obj(bindings, expected, actual, handler,\n+                                      expected_meths, actual_meths);\n                     }\n-                    case (none[@ty.t]) {\n-                        bindings.insert(expected_id, actual);\n-                        ret ures_ok(actual);\n+                    case (_) {\n+                        ret ures_err(terr_mismatch, expected, actual);\n                     }\n                 }\n             }\n \n+            case (ty.ty_var(?expected_id)) {\n+                // Add a binding.\n+                bindings.insert(expected_id, actual);\n+                ret ures_ok(actual);\n+            }\n+\n             case (ty.ty_local(?expected_id)) {\n                 auto expected_ty = handler.resolve_local(expected_id);\n                 auto result = unify_step(bindings,\n@@ -1182,13 +1411,43 @@ fn unify(@ty.t expected, @ty.t actual, &unify_handler handler)\n         fail;\n     }\n \n+    // Performs type binding substitution.\n+    fn substitute(@hashmap[int,@t] bindings, @t typ) -> @t {\n+        state obj folder(@hashmap[int,@t] bindings) {\n+            fn fold_simple_ty(@t typ) -> @t {\n+                alt (typ.struct) {\n+                    case (ty_var(?id)) {\n+                        alt (bindings.find(id)) {\n+                            case (some[@t](?typ2)) {\n+                                ret substitute(bindings, typ2);\n+                            }\n+                            case (none[@t]) {\n+                                ret typ;\n+                            }\n+                        }\n+                    }\n+                    case (_) {\n+                        ret typ;\n+                    }\n+                }\n+            }\n+        }\n+\n+        ret ty.fold_ty(folder(bindings), typ);\n+    }\n+\n     fn hash_int(&int x) -> uint { ret x as uint; }\n     fn eq_int(&int a, &int b) -> bool { ret a == b; }\n     auto hasher = hash_int;\n     auto eqer = eq_int;\n-    auto bindings = map.mk_hashmap[int,@ty.t](hasher, eqer);\n+    auto bindings = @map.mk_hashmap[int,@ty.t](hasher, eqer);\n \n-    ret unify_step(bindings, expected, actual, handler);\n+    auto ures = unify_step(bindings, expected, actual, handler);\n+    alt (ures) {\n+        case (ures_ok(?t))  { ret ures_ok(substitute(bindings, t)); }\n+        case (_)            { ret ures;                             }\n+    }\n+    fail;   // not reached\n }\n \n fn type_err_to_str(&ty.type_err err) -> str {\n@@ -1231,9 +1490,10 @@ fn type_err_to_str(&ty.type_err err) -> str {\n     }\n }\n \n-// Type parameter resolution, used in translation\n+// Type parameter resolution, used in translation and typechecking\n \n-fn resolve_ty_params(@ast.item item, @t monoty) -> vec[@t] {\n+fn resolve_ty_params(ty_params_and_ty ty_params_and_polyty,\n+                     @t monoty) -> vec[@t] {\n     obj resolve_ty_params_handler(@hashmap[ast.def_id,@t] bindings) {\n         fn resolve_local(ast.def_id id) -> @t { log \"resolve local\"; fail; }\n         fn record_local(ast.def_id id, @t ty) { log \"record local\"; fail; }\n@@ -1249,8 +1509,6 @@ fn resolve_ty_params(@ast.item item, @t monoty) -> vec[@t] {\n         }\n     }\n \n-    auto ty_params_and_polyty = item_ty(item);\n-\n     auto bindings = @new_def_hash[@t]();\n     auto handler = resolve_ty_params_handler(bindings);\n \n@@ -1274,6 +1532,47 @@ fn resolve_ty_params(@ast.item item, @t monoty) -> vec[@t] {\n     ret result_tys;\n }\n \n+// Performs type parameter replacement using the supplied mapping from\n+// parameter IDs to types.\n+fn replace_type_params(@t typ, hashmap[ast.def_id,@t] param_map) -> @t {\n+    state obj param_replacer(hashmap[ast.def_id,@t] param_map) {\n+        fn fold_simple_ty(@t typ) -> @t {\n+            alt (typ.struct) {\n+                case (ty_param(?param_def)) {\n+                    if (param_map.contains_key(param_def)) {\n+                        ret param_map.get(param_def);\n+                    } else {\n+                        ret typ;\n+                    }\n+                }\n+                case (_) {\n+                    ret typ;\n+                }\n+            }\n+        }\n+    }\n+    auto replacer = param_replacer(param_map);\n+    ret fold_ty(replacer, typ);\n+}\n+\n+// Substitutes the type parameters specified by @ty_params with the\n+// corresponding types in @bound in the given type. The two vectors must have\n+// the same length.\n+fn substitute_ty_params(vec[ast.ty_param] ty_params, vec[@t] bound, @t ty)\n+        -> @t {\n+    auto ty_param_len = _vec.len[ast.ty_param](ty_params);\n+    check (ty_param_len == _vec.len[@t](bound));\n+\n+    auto bindings = common.new_def_hash[@t]();\n+    auto i = 0u;\n+    while (i < ty_param_len) {\n+        bindings.insert(ty_params.(i).id, bound.(i));\n+        i += 1u;\n+    }\n+\n+    ret replace_type_params(ty, bindings);\n+}\n+\n // Local Variables:\n // mode: rust\n // fill-column: 78;"}, {"sha": "5c7f963cb78604a56d2facf2fa64af98b6dd7703", "filename": "src/comp/middle/typeck.rs", "status": "modified", "additions": 628, "deletions": 216, "changes": 844, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Ftypeck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fmiddle%2Ftypeck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftypeck.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -25,13 +25,20 @@ import middle.ty.type_is_scalar;\n import std._str;\n import std._uint;\n import std._vec;\n+import std.map;\n import std.map.hashmap;\n import std.option;\n import std.option.none;\n import std.option.some;\n \n type ty_table = hashmap[ast.def_id, @ty.t];\n-type ty_item_table = hashmap[ast.def_id,@ast.item];\n+\n+tag any_item {\n+    any_item_rust(@ast.item);\n+    any_item_native(@ast.native_item, ast.native_abi);\n+}\n+\n+type ty_item_table = hashmap[ast.def_id,any_item];\n \n type crate_ctxt = rec(session.session sess,\n                       @ty_table item_types,\n@@ -72,6 +79,65 @@ fn generalize_ty(@crate_ctxt cx, @ty.t t) -> @ty.t {\n     ret ty.fold_ty(generalizer, t);\n }\n \n+// Substitutes the user's explicit types for the parameters in a path\n+// expression.\n+fn substitute_ty_params(&@crate_ctxt ccx,\n+                        @ty.t typ,\n+                        vec[@ast.ty] supplied,\n+                        &span sp) -> @ty.t {\n+    state obj ty_substituter(@crate_ctxt ccx,\n+                             @mutable uint i,\n+                             vec[@ast.ty] supplied,\n+                             @hashmap[int,@ty.t] substs) {\n+        fn fold_simple_ty(@ty.t typ) -> @ty.t {\n+            alt (typ.struct) {\n+                case (ty.ty_var(?vid)) {\n+                    alt (substs.find(vid)) {\n+                        case (some[@ty.t](?resolved_ty)) {\n+                            ret resolved_ty;\n+                        }\n+                        case (none[@ty.t]) {\n+                            if (i >= _vec.len[@ast.ty](supplied)) {\n+                                // Just leave it as an unresolved parameter\n+                                // for now. (We will error out later.)\n+                                ret typ;\n+                            }\n+\n+                            auto result = ast_ty_to_ty_crate(ccx,\n+                                                             supplied.(*i));\n+                            *i += 1u;\n+                            substs.insert(vid, result);\n+                            ret result;\n+                        }\n+                    }\n+                }\n+                case (_) { ret typ; }\n+            }\n+        }\n+    }\n+\n+    fn hash_int(&int x) -> uint { ret x as uint; }\n+    fn eq_int(&int a, &int b) -> bool { ret a == b; }\n+    auto hasher = hash_int;\n+    auto eqer = eq_int;\n+    auto substs = @map.mk_hashmap[int,@ty.t](hasher, eqer);\n+\n+    auto subst_count = @mutable 0u;\n+    auto substituter = ty_substituter(ccx, subst_count, supplied, substs);\n+\n+    auto result = ty.fold_ty(substituter, typ);\n+\n+    auto supplied_len = _vec.len[@ast.ty](supplied);\n+    if ((*subst_count) != supplied_len) {\n+        ccx.sess.span_err(sp, \"expected \" + _uint.to_str(*subst_count, 10u) +\n+                          \" type parameter(s) but found \" +\n+                          _uint.to_str(supplied_len, 10u) + \" parameter(s)\");\n+        fail;\n+    }\n+\n+    ret result;\n+}\n+\n // Parses the programmer's textual representation of a type into our internal\n // notion of a type. `getter` is a function that returns the type\n // corresponding to a definition ID.\n@@ -81,23 +147,6 @@ fn ast_ty_to_ty(ty_getter getter, &@ast.ty ast_ty) -> @ty.t {\n         ret rec(mode=arg.mode, ty=ast_ty_to_ty(getter, arg.ty));\n     }\n \n-    fn replace_type_params(@ty.t t, ty_table param_map) -> @ty.t {\n-        state obj param_replacer(ty_table param_map) {\n-            fn fold_simple_ty(@ty.t t) -> @ty.t {\n-                alt (t.struct) {\n-                    case (ty.ty_param(?param_def)) {\n-                        ret param_map.get(param_def);\n-                    }\n-                    case (_) {\n-                        ret t;\n-                    }\n-                }\n-            }\n-        }\n-        auto replacer = param_replacer(param_map);\n-        ret ty.fold_ty(replacer, t);\n-    }\n-\n     fn instantiate(ty_getter getter, ast.def_id id,\n                    vec[@ast.ty] args) -> @ty.t {\n         // TODO: maybe record cname chains so we can do\n@@ -113,7 +162,7 @@ fn ast_ty_to_ty(ty_getter getter, &@ast.ty ast_ty) -> @ty.t {\n             auto param = params.(i);\n             param_map.insert(param.id, ast_ty_to_ty(getter, arg));\n         }\n-        ret replace_type_params(ty_and_params.ty, param_map);\n+        ret ty.replace_type_params(ty_and_params.ty, param_map);\n     }\n \n     auto mut = ast.imm;\n@@ -145,10 +194,10 @@ fn ast_ty_to_ty(ty_getter getter, &@ast.ty ast_ty) -> @ty.t {\n             sty = ty.ty_rec(flds);\n         }\n \n-        case (ast.ty_fn(?inputs, ?output)) {\n+        case (ast.ty_fn(?proto, ?inputs, ?output)) {\n             auto f = bind ast_arg_to_arg(getter, _);\n             auto i = _vec.map[ast.ty_arg, arg](f, inputs);\n-            sty = ty.ty_fn(i, ast_ty_to_ty(getter, output));\n+            sty = ty.ty_fn(proto, i, ast_ty_to_ty(getter, output));\n         }\n \n         case (ast.ty_path(?path, ?def)) {\n@@ -157,6 +206,9 @@ fn ast_ty_to_ty(ty_getter getter, &@ast.ty ast_ty) -> @ty.t {\n                 case (ast.def_ty(?id)) {\n                     sty = instantiate(getter, id, path.node.types).struct;\n                 }\n+                case (ast.def_native_ty(?id)) {\n+                    sty = instantiate(getter, id, path.node.types).struct;\n+                }\n                 case (ast.def_obj(?id))     {\n                     sty = instantiate(getter, id, path.node.types).struct;\n                 }\n@@ -181,7 +233,8 @@ fn ast_ty_to_ty(ty_getter getter, &@ast.ty ast_ty) -> @ty.t {\n                 auto ins = _vec.map[ast.ty_arg, arg](f, m.inputs);\n                 auto out = ast_ty_to_ty(getter, m.output);\n                 append[ty.method](tmeths,\n-                                  rec(ident=m.ident,\n+                                  rec(proto=m.proto,\n+                                      ident=m.ident,\n                                       inputs=ins,\n                                       output=out));\n             }\n@@ -192,23 +245,36 @@ fn ast_ty_to_ty(ty_getter getter, &@ast.ty ast_ty) -> @ty.t {\n     ret @rec(struct=sty, mut=mut, cname=cname);\n }\n \n+fn actual_type(@ty.t t, @ast.item item) -> @ty.t {\n+    alt (item.node) {\n+        case (ast.item_obj(_,_,_,_,_)) {\n+            // An obj used as a type name refers to the output type of the\n+            // item (constructor).\n+            ret middle.ty.ty_fn_ret(t);\n+        }\n+        case (_) { }\n+    }\n+\n+    ret t;\n+}\n+\n // A convenience function to use a crate_ctxt to resolve names for\n // ast_ty_to_ty.\n fn ast_ty_to_ty_crate(@crate_ctxt ccx, &@ast.ty ast_ty) -> @ty.t {\n     fn getter(@crate_ctxt ccx, ast.def_id id) -> ty_and_params {\n         check (ccx.item_items.contains_key(id));\n         check (ccx.item_types.contains_key(id));\n-        auto item = ccx.item_items.get(id);\n+        auto it = ccx.item_items.get(id);\n         auto ty = ccx.item_types.get(id);\n-        auto params = ty_params_of_item(item);\n-\n-        alt (item.node) {\n-            case (ast.item_obj(_,_,_,_,_)) {\n-                // An obj used as a type name refers to the output type of the\n-                // item (constructor).\n-                ty = middle.ty.ty_fn_ret(ty);\n+        auto params;\n+        alt (it) {\n+            case (any_item_rust(?item)) {\n+                ty = actual_type(ty, item);\n+                params = ty_params_of_item(item);\n             }\n-            case (_) { }\n+            case (any_item_native(?native_item, _)) {\n+                params = ty_params_of_native_item(native_item);\n+           }\n         }\n \n         ret rec(params = params, ty = ty);\n@@ -238,6 +304,18 @@ fn ty_params_of_item(@ast.item item) -> vec[ast.ty_param] {\n     }\n }\n \n+fn ty_params_of_native_item(@ast.native_item item) -> vec[ast.ty_param] {\n+    alt (item.node) {\n+        case (ast.native_item_fn(_, _, ?p, _, _)) {\n+            ret p;\n+        }\n+        case (_) {\n+            let vec[ast.ty_param] r = vec();\n+            ret r;\n+        }\n+    }\n+}\n+\n // Item collection - a pair of bootstrap passes:\n //\n // 1. Collect the IDs of all type items (typedefs) and store them in a table.\n@@ -249,24 +327,55 @@ fn ty_params_of_item(@ast.item item) -> vec[ast.ty_param] {\n // We then annotate the AST with the resulting types and return the annotated\n // AST, along with a table mapping item IDs to their types.\n \n+fn ty_of_fn_decl(@ty_item_table id_to_ty_item,\n+                 @ty_table item_to_ty,\n+                 fn(&@ast.ty ast_ty) -> @ty.t convert,\n+                 fn(&ast.arg a) -> arg ty_of_arg,\n+                 &ast.fn_decl decl,\n+                 ast.proto proto,\n+                 ast.def_id def_id) -> @ty.t {\n+    auto input_tys = _vec.map[ast.arg,arg](ty_of_arg, decl.inputs);\n+    auto output_ty = convert(decl.output);\n+    auto t_fn = plain_ty(ty.ty_fn(proto, input_tys, output_ty));\n+    item_to_ty.insert(def_id, t_fn);\n+    ret t_fn;\n+}\n+\n+fn ty_of_native_fn_decl(@ty_item_table id_to_ty_item,\n+                 @ty_table item_to_ty,\n+                 fn(&@ast.ty ast_ty) -> @ty.t convert,\n+                 fn(&ast.arg a) -> arg ty_of_arg,\n+                 &ast.fn_decl decl,\n+                 ast.native_abi abi,\n+                 ast.def_id def_id) -> @ty.t {\n+    auto input_tys = _vec.map[ast.arg,arg](ty_of_arg, decl.inputs);\n+    auto output_ty = convert(decl.output);\n+    auto t_fn = plain_ty(ty.ty_native_fn(abi, input_tys, output_ty));\n+    item_to_ty.insert(def_id, t_fn);\n+    ret t_fn;\n+}\n+\n fn collect_item_types(session.session sess, @ast.crate crate)\n     -> tup(@ast.crate, @ty_table, @ty_item_table) {\n \n     fn getter(@ty_item_table id_to_ty_item,\n               @ty_table item_to_ty,\n               ast.def_id id) -> ty_and_params {\n         check (id_to_ty_item.contains_key(id));\n-        auto item = id_to_ty_item.get(id);\n-        auto ty = ty_of_item(id_to_ty_item, item_to_ty, item);\n-        auto params = ty_params_of_item(item);\n-\n-        alt (item.node) {\n-            case (ast.item_obj(_,_,_,_,_)) {\n-                // An obj used as a type name refers to the output type of the\n-                // item (constructor).\n-                ty = middle.ty.ty_fn_ret(ty);\n+        auto it = id_to_ty_item.get(id);\n+        auto ty;\n+        auto params;\n+        alt (it) {\n+            case (any_item_rust(?item)) {\n+                ty = ty_of_item(id_to_ty_item, item_to_ty, item);\n+                ty = actual_type(ty, item);\n+                params = ty_params_of_item(item);\n+            }\n+            case (any_item_native(?native_item, ?abi)) {\n+                ty = ty_of_native_item(id_to_ty_item, item_to_ty,\n+                                       native_item, abi);\n+                params = ty_params_of_native_item(native_item);\n             }\n-            case (_) { }\n         }\n \n         ret rec(params = params, ty = ty);\n@@ -285,9 +394,10 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n         auto get = bind getter(id_to_ty_item, item_to_ty, _);\n         auto convert = bind ast_ty_to_ty(get, _);\n         auto f = bind ty_of_arg(id_to_ty_item, item_to_ty, _);\n-        auto inputs = _vec.map[ast.arg,arg](f, m.node.meth.inputs);\n-        auto output = convert(m.node.meth.output);\n-        ret rec(ident=m.node.ident, inputs=inputs, output=output);\n+        auto inputs = _vec.map[ast.arg,arg](f, m.node.meth.decl.inputs);\n+        auto output = convert(m.node.meth.decl.output);\n+        ret rec(proto=m.node.meth.proto, ident=m.node.ident,\n+                inputs=inputs, output=output);\n     }\n \n     fn ty_of_obj(@ty_item_table id_to_ty_item,\n@@ -318,7 +428,7 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n             auto t_field = ast_ty_to_ty(g, f.ty);\n             append[arg](t_inputs, rec(mode=ast.alias, ty=t_field));\n         }\n-        auto t_fn = plain_ty(ty.ty_fn(t_inputs, t_obj));\n+        auto t_fn = plain_ty(ty.ty_fn(ast.proto_fn, t_inputs, t_obj));\n         ret t_fn;\n     }\n \n@@ -336,15 +446,9 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n             }\n \n             case (ast.item_fn(?ident, ?fn_info, _, ?def_id, _)) {\n-                // TODO: handle ty-params\n-\n                 auto f = bind ty_of_arg(id_to_ty_item, item_to_ty, _);\n-                auto input_tys = _vec.map[ast.arg,arg](f, fn_info.inputs);\n-                auto output_ty = convert(fn_info.output);\n-\n-                auto t_fn = plain_ty(ty.ty_fn(input_tys, output_ty));\n-                item_to_ty.insert(def_id, t_fn);\n-                ret t_fn;\n+                ret ty_of_fn_decl(id_to_ty_item, item_to_ty, convert, f,\n+                                  fn_info.decl, fn_info.proto, def_id);\n             }\n \n             case (ast.item_obj(?ident, ?obj_info, _, ?def_id, _)) {\n@@ -369,28 +473,67 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n                 ret ty_;\n             }\n \n-            case (ast.item_tag(_, _, _, ?def_id)) {\n-                auto t = plain_ty(ty.ty_tag(def_id));\n+            case (ast.item_tag(_, _, ?tps, ?def_id)) {\n+                // Create a new generic polytype.\n+                let vec[@ty.t] subtys = vec();\n+                for (ast.ty_param tp in tps) {\n+                    subtys += vec(plain_ty(ty.ty_param(tp.id)));\n+                }\n+                auto t = plain_ty(ty.ty_tag(def_id, subtys));\n                 item_to_ty.insert(def_id, t);\n                 ret t;\n             }\n \n             case (ast.item_mod(_, _, _)) { fail; }\n+            case (ast.item_native_mod(_, _, _)) { fail; }\n+        }\n+    }\n+\n+    fn ty_of_native_item(@ty_item_table id_to_ty_item,\n+                         @ty_table item_to_ty,\n+                         @ast.native_item it,\n+                         ast.native_abi abi) -> @ty.t {\n+        alt (it.node) {\n+            case (ast.native_item_fn(?ident, ?fn_decl, ?params, ?def_id, _)) {\n+                auto get = bind getter(id_to_ty_item, item_to_ty, _);\n+                auto convert = bind ast_ty_to_ty(get, _);\n+                auto f = bind ty_of_arg(id_to_ty_item, item_to_ty, _);\n+                ret ty_of_native_fn_decl(id_to_ty_item, item_to_ty, convert,\n+                                         f, fn_decl, abi, def_id);\n+            }\n+            case (ast.native_item_ty(_, ?def_id)) {\n+                if (item_to_ty.contains_key(def_id)) {\n+                    // Avoid repeating work.\n+                    ret item_to_ty.get(def_id);\n+                }\n+                auto x =\n+                    @rec(struct=ty.ty_native, mut=ast.imm, cname=none[str]);\n+                item_to_ty.insert(def_id, x);\n+                ret x;\n+            }\n         }\n     }\n \n     fn get_tag_variant_types(@ty_item_table id_to_ty_item,\n                              @ty_table item_to_ty,\n                              &ast.def_id tag_id,\n-                             &vec[ast.variant] variants) -> vec[ast.variant] {\n+                             &vec[ast.variant] variants,\n+                             &vec[ast.ty_param] ty_params)\n+            -> vec[ast.variant] {\n         let vec[ast.variant] result = vec();\n \n+        // Create a set of parameter types shared among all the variants.\n+        let vec[@ty.t] ty_param_tys = vec();\n+        for (ast.ty_param tp in ty_params) {\n+            ty_param_tys += vec(plain_ty(ty.ty_param(tp.id)));\n+        }\n+\n         for (ast.variant variant in variants) {\n-            // Nullary tag constructors get truned into constants; n-ary tag\n+            // Nullary tag constructors get turned into constants; n-ary tag\n             // constructors get turned into functions.\n             auto result_ty;\n             if (_vec.len[ast.variant_arg](variant.args) == 0u) {\n-                result_ty = plain_ty(ty.ty_tag(tag_id));\n+                result_ty = plain_ty(ty.ty_tag(tag_id, ty_param_tys));\n             } else {\n                 // As above, tell ast_ty_to_ty() that trans_ty_item_to_ty()\n                 // should be called to resolve named types.\n@@ -401,8 +544,8 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n                     auto arg_ty = ast_ty_to_ty(f, va.ty);\n                     args += vec(rec(mode=ast.alias, ty=arg_ty));\n                 }\n-                auto tag_t = plain_ty(ty.ty_tag(tag_id));\n-                result_ty = plain_ty(ty.ty_fn(args, tag_t));\n+                auto tag_t = plain_ty(ty.ty_tag(tag_id, ty_param_tys));\n+                result_ty = plain_ty(ty.ty_fn(ast.proto_fn, args, tag_t));\n             }\n \n             item_to_ty.insert(variant.id, result_ty);\n@@ -416,25 +559,40 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n \n     // First pass: collect all type item IDs.\n     auto module = crate.node.module;\n-    auto id_to_ty_item = @common.new_def_hash[@ast.item]();\n+    auto id_to_ty_item = @common.new_def_hash[any_item]();\n     fn collect(&@ty_item_table id_to_ty_item, @ast.item i)\n         -> @ty_item_table {\n         alt (i.node) {\n             case (ast.item_ty(_, _, _, ?def_id, _)) {\n-                id_to_ty_item.insert(def_id, i);\n+                id_to_ty_item.insert(def_id, any_item_rust(i));\n             }\n             case (ast.item_tag(_, _, _, ?def_id)) {\n-                id_to_ty_item.insert(def_id, i);\n+                id_to_ty_item.insert(def_id, any_item_rust(i));\n             }\n             case (ast.item_obj(_, _, _, ?def_id, _)) {\n-                id_to_ty_item.insert(def_id, i);\n+                id_to_ty_item.insert(def_id, any_item_rust(i));\n             }\n             case (_) { /* empty */ }\n         }\n         ret id_to_ty_item;\n     }\n+    fn collect_native(&@ty_item_table id_to_ty_item, @ast.native_item i)\n+        -> @ty_item_table {\n+        alt (i.node) {\n+            case (ast.native_item_ty(_, ?def_id)) {\n+                // The abi of types is not used.\n+                id_to_ty_item.insert(def_id,\n+                                     any_item_native(i,\n+                                                     ast.native_abi_cdecl));\n+            }\n+            case (_) {\n+            }\n+        }\n+        ret id_to_ty_item;\n+    }\n     auto fld_1 = fold.new_identity_fold[@ty_item_table]();\n-    fld_1 = @rec(update_env_for_item = bind collect(_, _)\n+    fld_1 = @rec(update_env_for_item = bind collect(_, _),\n+                 update_env_for_native_item = bind collect_native(_, _)\n                  with *fld_1);\n     fold.fold_crate[@ty_item_table](id_to_ty_item, fld_1, crate);\n \n@@ -445,22 +603,34 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n \n     type env = rec(session.session sess,\n                    @ty_item_table id_to_ty_item,\n-                   @ty_table item_to_ty);\n+                   @ty_table item_to_ty,\n+                   ast.native_abi abi);\n     let @env e = @rec(sess=sess,\n                       id_to_ty_item=id_to_ty_item,\n-                      item_to_ty=item_to_ty);\n+                      item_to_ty=item_to_ty,\n+                      abi=ast.native_abi_cdecl);\n \n     fn convert(&@env e, @ast.item i) -> @env {\n+        auto abi = e.abi;\n         alt (i.node) {\n             case (ast.item_mod(_, _, _)) {\n                 // ignore item_mod, it has no type.\n             }\n+            case (ast.item_native_mod(_, ?native_mod, _)) {\n+                // ignore item_native_mod, it has no type.\n+                abi = native_mod.abi;\n+            }\n             case (_) {\n                 // This call populates the ty_table with the converted type of\n                 // the item in passing; we don't need to do anything else.\n                 ty_of_item(e.id_to_ty_item, e.item_to_ty, i);\n             }\n         }\n+        ret @rec(abi=abi with *e);\n+    }\n+\n+    fn convert_native(&@env e, @ast.native_item i) -> @env {\n+        ty_of_native_item(e.id_to_ty_item, e.item_to_ty, i, e.abi);\n         ret e;\n     }\n \n@@ -484,9 +654,19 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n         ret @fold.respan[ast.item_](sp, item);\n     }\n \n+    fn fold_native_item_fn(&@env e, &span sp, ast.ident i,\n+                           &ast.fn_decl d, vec[ast.ty_param] ty_params,\n+                           ast.def_id id, ast.ann a) -> @ast.native_item {\n+        check (e.item_to_ty.contains_key(id));\n+        auto ty = e.item_to_ty.get(id);\n+        auto item = ast.native_item_fn(i, d, ty_params, id,\n+                                       ast.ann_type(ty));\n+        ret @fold.respan[ast.native_item_](sp, item);\n+    }\n+\n     fn get_ctor_obj_methods(@ty.t t) -> vec[method] {\n         alt (t.struct) {\n-            case (ty.ty_fn(_,?tobj)) {\n+            case (ty.ty_fn(_,_,?tobj)) {\n                 alt (tobj.struct) {\n                     case (ty.ty_obj(?tm)) {\n                         ret tm;\n@@ -521,7 +701,8 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n             let method meth_ty = meth_tys.(ix);\n             let ast.method_ m_;\n             let @ast.method m;\n-            auto meth_tfn = plain_ty(ty.ty_fn(meth_ty.inputs,\n+            auto meth_tfn = plain_ty(ty.ty_fn(meth_ty.proto,\n+                                              meth_ty.inputs,\n                                               meth_ty.output));\n             m_ = rec(ann=ast.ann_type(meth_tfn) with meth.node);\n             m = @rec(node=m_ with *meth);\n@@ -558,16 +739,20 @@ fn collect_item_types(session.session sess, @ast.crate crate)\n                      ast.def_id id) -> @ast.item {\n         auto variants_t = get_tag_variant_types(e.id_to_ty_item,\n                                                 e.item_to_ty,\n-                                                id, variants);\n+                                                id,\n+                                                variants,\n+                                                ty_params);\n         auto item = ast.item_tag(i, variants_t, ty_params, id);\n         ret @fold.respan[ast.item_](sp, item);\n     }\n \n     auto fld_2 = fold.new_identity_fold[@env]();\n     fld_2 =\n         @rec(update_env_for_item = bind convert(_,_),\n+             update_env_for_native_item = bind convert_native(_,_),\n              fold_item_const = bind fold_item_const(_,_,_,_,_,_,_),\n              fold_item_fn    = bind fold_item_fn(_,_,_,_,_,_,_),\n+             fold_native_item_fn = bind fold_native_item_fn(_,_,_,_,_,_,_),\n              fold_item_obj   = bind fold_item_obj(_,_,_,_,_,_,_),\n              fold_item_ty    = bind fold_item_ty(_,_,_,_,_,_,_),\n              fold_item_tag   = bind fold_item_tag(_,_,_,_,_,_)\n@@ -705,13 +890,17 @@ fn are_compatible(&@fn_ctxt fcx, @ty.t expected, @ty.t actual) -> bool {\n // TODO: enforce this via a predicate.\n \n fn demand_pat(&@fn_ctxt fcx, @ty.t expected, @ast.pat pat) -> @ast.pat {\n-    auto p_1 = ast.pat_wild(ast.ann_none);  // FIXME: typestate botch\n+    auto p_1;\n \n     alt (pat.node) {\n         case (ast.pat_wild(?ann)) {\n             auto t = demand(fcx, pat.span, expected, ann_to_type(ann));\n             p_1 = ast.pat_wild(ast.ann_type(t));\n         }\n+        case (ast.pat_lit(?lit, ?ann)) {\n+            auto t = demand(fcx, pat.span, expected, ann_to_type(ann));\n+            p_1 = ast.pat_lit(lit, ast.ann_type(t));\n+        }\n         case (ast.pat_bind(?id, ?did, ?ann)) {\n             auto t = demand(fcx, pat.span, expected, ann_to_type(ann));\n             fcx.locals.insert(did, t);\n@@ -735,12 +924,12 @@ fn demand_pat(&@fn_ctxt fcx, @ty.t expected, @ast.pat pat) -> @ast.pat {\n \n             auto subpats_len = _vec.len[@ast.pat](subpats);\n             alt (variant_ty.struct) {\n-                case (ty.ty_tag(_)) {\n+                case (ty.ty_tag(_, _)) {\n                     // Nullary tag variant.\n                     check (subpats_len == 0u);\n                     p_1 = ast.pat_tag(id, subpats, vdef_opt, ast.ann_type(t));\n                 }\n-                case (ty.ty_fn(?args, ?tag_ty)) {\n+                case (ty.ty_fn(_, ?args, ?tag_ty)) {\n                     let vec[@ast.pat] new_subpats = vec();\n                     auto i = 0u;\n                     for (arg a in args) {\n@@ -771,9 +960,7 @@ fn demand_expr(&@fn_ctxt fcx, @ty.t expected, @ast.expr e) -> @ast.expr {\n \n fn demand_expr_full(&@fn_ctxt fcx, @ty.t expected, @ast.expr e,\n                     autoderef_kind adk) -> @ast.expr {\n-    // FIXME: botch to work around typestate bug in rustboot\n-    let vec[@ast.expr] v = vec();\n-    auto e_1 = ast.expr_vec(v, ast.ann_none);\n+    auto e_1;\n \n     alt (e.node) {\n         case (ast.expr_vec(?es_0, ?ann)) {\n@@ -811,28 +998,58 @@ fn demand_expr_full(&@fn_ctxt fcx, @ty.t expected, @ast.expr e,\n             }\n             e_1 = ast.expr_tup(elts_1, ast.ann_type(t));\n         }\n-        case (ast.expr_rec(?fields_0, ?ann)) {\n+        case (ast.expr_rec(?fields_0, ?base_0, ?ann)) {\n+\n+            auto base_1 = base_0;\n+\n             auto t = demand(fcx, e.span, expected, ann_to_type(ann));\n             let vec[ast.field] fields_1 = vec();\n             alt (t.struct) {\n                 case (ty.ty_rec(?field_tys)) {\n-                    auto i = 0u;\n-                    for (ast.field field_0 in fields_0) {\n-                        check (_str.eq(field_0.ident, field_tys.(i).ident));\n-                        auto e_1 = demand_expr(fcx, field_tys.(i).ty,\n-                                               field_0.expr);\n-                        fields_1 += vec(rec(mut=field_0.mut,\n-                                            ident=field_0.ident,\n-                                            expr=e_1));\n-                        i += 1u;\n+                    alt (base_0) {\n+                        case (none[@ast.expr]) {\n+                            auto i = 0u;\n+                            for (ast.field field_0 in fields_0) {\n+                                check (_str.eq(field_0.ident,\n+                                               field_tys.(i).ident));\n+                                auto e_1 = demand_expr(fcx,\n+                                                       field_tys.(i).ty,\n+                                                       field_0.expr);\n+                                fields_1 += vec(rec(mut=field_0.mut,\n+                                                    ident=field_0.ident,\n+                                                    expr=e_1));\n+                                i += 1u;\n+                            }\n+                        }\n+                        case (some[@ast.expr](?bx)) {\n+\n+                            base_1 =\n+                                some[@ast.expr](demand_expr(fcx, t, bx));\n+\n+                            let vec[field] base_fields = vec();\n+\n+                            for (ast.field field_0 in fields_0) {\n+\n+                                for (ty.field ft in field_tys) {\n+                                    if (_str.eq(field_0.ident, ft.ident)) {\n+                                        auto e_1 = demand_expr(fcx, ft.ty,\n+                                                               field_0.expr);\n+                                        fields_1 +=\n+                                            vec(rec(mut=field_0.mut,\n+                                                    ident=field_0.ident,\n+                                                    expr=e_1));\n+                                    }\n+                                }\n+                            }\n+                        }\n                     }\n                 }\n                 case (_) {\n                     log \"rec expr doesn't have a rec type!\";\n                     fail;\n                 }\n             }\n-            e_1 = ast.expr_rec(fields_1, ast.ann_type(t));\n+            e_1 = ast.expr_rec(fields_1, base_1, ast.ann_type(t));\n         }\n         case (ast.expr_bind(?sube, ?es, ?ann)) {\n             auto t = demand(fcx, e.span, expected, ann_to_type(ann));\n@@ -868,6 +1085,7 @@ fn demand_expr_full(&@fn_ctxt fcx, @ty.t expected, @ast.expr e,\n             auto t = demand_full(fcx, e.span, expected,\n                                  ann_to_type(ann), adk);\n             auto then_1 = demand_block(fcx, expected, then_0);\n+\n             auto else_1;\n             alt (else_0) {\n                 case (none[@ast.expr]) { else_1 = none[@ast.expr]; }\n@@ -882,6 +1100,10 @@ fn demand_expr_full(&@fn_ctxt fcx, @ty.t expected, @ast.expr e,\n             auto t = demand(fcx, e.span, expected, ann_to_type(ann));\n             e_1 = ast.expr_for(decl, seq, bloc, ast.ann_type(t));\n         }\n+        case (ast.expr_for_each(?decl, ?seq, ?bloc, ?ann)) {\n+            auto t = demand(fcx, e.span, expected, ann_to_type(ann));\n+            e_1 = ast.expr_for_each(decl, seq, bloc, ast.ann_type(t));\n+        }\n         case (ast.expr_while(?cond, ?bloc, ?ann)) {\n             auto t = demand(fcx, e.span, expected, ann_to_type(ann));\n             e_1 = ast.expr_while(cond, bloc, ast.ann_type(t));\n@@ -924,6 +1146,21 @@ fn demand_expr_full(&@fn_ctxt fcx, @ty.t expected, @ast.expr e,\n                                  ann_to_type(ann), adk);\n             e_1 = ast.expr_path(pth, d, ast.ann_type(t));\n         }\n+        case (ast.expr_ext(?p, ?args, ?body, ?expanded, ?ann)) {\n+            auto t = demand_full(fcx, e.span, expected,\n+                                 ann_to_type(ann), adk);\n+            e_1 = ast.expr_ext(p, args, body, expanded, ast.ann_type(t));\n+        }\n+        case (ast.expr_fail) { e_1 = e.node; }\n+        case (ast.expr_log(_)) { e_1 = e.node; }\n+        case (ast.expr_ret(_)) { e_1 = e.node; }\n+        case (ast.expr_put(_)) { e_1 = e.node; }\n+        case (ast.expr_be(_)) { e_1 = e.node; }\n+        case (ast.expr_check_expr(_)) { e_1 = e.node; }\n+        case (_) {\n+            fcx.ccx.sess.unimpl(\"type unification for expression variant\");\n+            fail;\n+        }\n     }\n \n     ret @fold.respan[ast.expr_](e.span, e_1);\n@@ -989,6 +1226,9 @@ fn check_pat(&@fn_ctxt fcx, @ast.pat pat) -> @ast.pat {\n         case (ast.pat_wild(_)) {\n             new_pat = ast.pat_wild(ast.ann_type(next_ty_var(fcx.ccx)));\n         }\n+        case (ast.pat_lit(?lt, _)) {\n+            new_pat = ast.pat_lit(lt, ast.ann_type(check_lit(lt)));\n+        }\n         case (ast.pat_bind(?id, ?def_id, _)) {\n             auto ann = ast.ann_type(next_ty_var(fcx.ccx));\n             new_pat = ast.pat_bind(id, def_id, ann);\n@@ -1000,7 +1240,7 @@ fn check_pat(&@fn_ctxt fcx, @ast.pat pat) -> @ast.pat {\n             auto last_id = p.node.idents.(len - 1u);\n             alt (t.struct) {\n                 // N-ary variants have function types.\n-                case (ty.ty_fn(?args, ?tag_ty)) {\n+                case (ty.ty_fn(_, ?args, ?tag_ty)) {\n                     auto arg_len = _vec.len[arg](args);\n                     auto subpats_len = _vec.len[@ast.pat](subpats);\n                     if (arg_len != subpats_len) {\n@@ -1024,7 +1264,9 @@ fn check_pat(&@fn_ctxt fcx, @ast.pat pat) -> @ast.pat {\n                 }\n \n                 // Nullary variants have tag types.\n-                case (ty.ty_tag(?tid)) {\n+                case (ty.ty_tag(?tid, _)) {\n+                    // TODO: ty params\n+\n                     auto subpats_len = _vec.len[@ast.pat](subpats);\n                     if (subpats_len > 0u) {\n                         // TODO: pluralize properly\n@@ -1038,7 +1280,8 @@ fn check_pat(&@fn_ctxt fcx, @ast.pat pat) -> @ast.pat {\n                         fail;   // TODO: recover\n                     }\n \n-                    auto ann = ast.ann_type(plain_ty(ty.ty_tag(tid)));\n+                    let vec[@ty.t] tys = vec(); // FIXME\n+                    auto ann = ast.ann_type(plain_ty(ty.ty_tag(tid, tys)));\n                     new_pat = ast.pat_tag(p, subpats, vdef_opt, ann);\n                 }\n             }\n@@ -1049,6 +1292,90 @@ fn check_pat(&@fn_ctxt fcx, @ast.pat pat) -> @ast.pat {\n }\n \n fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n+    // A generic function to factor out common logic from call and bind\n+    // expressions.\n+    fn check_call_or_bind(&@fn_ctxt fcx, &@ast.expr f,\n+                          &vec[option.t[@ast.expr]] args)\n+            -> tup(@ast.expr, vec[option.t[@ast.expr]]) {\n+\n+        // Check the function.\n+        auto f_0 = check_expr(fcx, f);\n+\n+        // Check the arguments and generate the argument signature.\n+        let vec[option.t[@ast.expr]] args_0 = vec();\n+        let vec[arg] arg_tys_0 = vec();\n+        for (option.t[@ast.expr] a_opt in args) {\n+            alt (a_opt) {\n+                case (some[@ast.expr](?a)) {\n+                    auto a_0 = check_expr(fcx, a);\n+                    args_0 += vec(some[@ast.expr](a_0));\n+\n+                    // FIXME: this breaks aliases. We need a ty_fn_arg.\n+                    auto arg_ty = rec(mode=ast.val, ty=expr_ty(a_0));\n+                    append[arg](arg_tys_0, arg_ty);\n+                }\n+                case (none[@ast.expr]) {\n+                    args_0 += vec(none[@ast.expr]);\n+\n+                    // FIXME: breaks aliases too?\n+                    auto typ = next_ty_var(fcx.ccx);\n+                    append[arg](arg_tys_0, rec(mode=ast.val, ty=typ));\n+                }\n+            }\n+        }\n+\n+        auto rt_0 = next_ty_var(fcx.ccx);\n+        auto t_0;\n+        alt (expr_ty(f_0).struct) {\n+            case (ty.ty_fn(?proto, _, _))   {\n+                t_0 = plain_ty(ty.ty_fn(proto, arg_tys_0, rt_0));\n+            }\n+            case (ty.ty_native_fn(?abi, _, _))   {\n+                t_0 = plain_ty(ty.ty_native_fn(abi, arg_tys_0, rt_0));\n+            }\n+            case (_) {\n+                log \"check_call_or_bind(): fn expr doesn't have fn type\";\n+                fail;\n+            }\n+        }\n+\n+        // Unify and write back to the function.\n+        auto f_1 = demand_expr(fcx, t_0, f_0);\n+\n+        // Take the argument types out of the resulting function type.\n+        auto t_1 = expr_ty(f_1);\n+\n+        if (!ty.is_fn_ty(t_1)) {\n+            fcx.ccx.sess.span_err(f_1.span,\n+                                  \"mismatched types: callee has \" +\n+                                  \"non-function type: \" +\n+                                  ty_to_str(t_1));\n+        }\n+\n+        let vec[arg] arg_tys_1 = ty.ty_fn_args(t_1);\n+        let @ty.t rt_1 = ty.ty_fn_ret(t_1);\n+\n+        // Unify and write back to the arguments.\n+        auto i = 0u;\n+        let vec[option.t[@ast.expr]] args_1 = vec();\n+        while (i < _vec.len[option.t[@ast.expr]](args_0)) {\n+            alt (args_0.(i)) {\n+                case (some[@ast.expr](?e_0)) {\n+                    auto arg_ty_1 = arg_tys_1.(i);\n+                    auto e_1 = demand_expr(fcx, arg_ty_1.ty, e_0);\n+                    append[option.t[@ast.expr]](args_1, some[@ast.expr](e_1));\n+                }\n+                case (none[@ast.expr]) {\n+                    append[option.t[@ast.expr]](args_1, none[@ast.expr]);\n+                }\n+            }\n+\n+            i += 1u;\n+        }\n+\n+        ret tup(f_1, args_1);\n+    }\n+\n     alt (expr.node) {\n         case (ast.expr_lit(?lit, _)) {\n             auto ty = check_lit(lit);\n@@ -1103,6 +1430,9 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                         }\n                     }\n                 }\n+                case (ast._mutable) {\n+                    oper_t = @rec(mut=ast.mut with *oper_t);\n+                }\n                 case (_) { oper_t = strip_boxes(oper_t); }\n             }\n             ret @fold.respan[ast.expr_](expr.span,\n@@ -1132,13 +1462,18 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                     check (fcx.ccx.item_types.contains_key(id));\n                     t = generalize_ty(fcx.ccx, fcx.ccx.item_types.get(id));\n                 }\n+                case (ast.def_native_fn(?id)) {\n+                    check (fcx.ccx.item_types.contains_key(id));\n+                    t = generalize_ty(fcx.ccx, fcx.ccx.item_types.get(id));\n+                }\n                 case (ast.def_const(?id)) {\n                     check (fcx.ccx.item_types.contains_key(id));\n                     t = fcx.ccx.item_types.get(id);\n                 }\n                 case (ast.def_variant(_, ?variant_id)) {\n                     check (fcx.ccx.item_types.contains_key(variant_id));\n-                    t = fcx.ccx.item_types.get(variant_id);\n+                    t = generalize_ty(fcx.ccx,\n+                                      fcx.ccx.item_types.get(variant_id));\n                 }\n                 case (ast.def_binding(?id)) {\n                     check (fcx.locals.contains_key(id));\n@@ -1161,11 +1496,92 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                 }\n             }\n \n+            // Substitute type parameters if the user provided some.\n+            if (_vec.len[@ast.ty](pth.node.types) > 0u) {\n+                t = substitute_ty_params(fcx.ccx, t, pth.node.types,\n+                                         expr.span);\n+            }\n+\n             ret @fold.respan[ast.expr_](expr.span,\n                                         ast.expr_path(pth, defopt,\n                                                       ast.ann_type(t)));\n         }\n \n+        case (ast.expr_ext(?p, ?args, ?body, ?expanded, _)) {\n+            auto exp_ = check_expr(fcx, expanded);\n+            auto t = expr_ty(exp_);\n+            ret @fold.respan[ast.expr_](expr.span,\n+                                        ast.expr_ext(p, args, body, exp_,\n+                                                     ast.ann_type(t)));\n+        }\n+\n+        case (ast.expr_fail) {\n+            ret expr;\n+        }\n+\n+        case (ast.expr_ret(?expr_opt)) {\n+            alt (expr_opt) {\n+                case (none[@ast.expr]) {\n+                    auto nil = plain_ty(ty.ty_nil);\n+                    if (!are_compatible(fcx, fcx.ret_ty, nil)) {\n+                        fcx.ccx.sess.err(\"ret; in function \"\n+                                         + \"returning non-nil\");\n+                    }\n+\n+                    ret expr;\n+                }\n+\n+                case (some[@ast.expr](?e)) {\n+                    auto expr_0 = check_expr(fcx, e);\n+                    auto expr_1 = demand_expr(fcx, fcx.ret_ty, expr_0);\n+                    ret @fold.respan[ast.expr_](expr.span,\n+                                                ast.expr_ret(some(expr_1)));\n+                }\n+            }\n+        }\n+\n+        case (ast.expr_put(?expr_opt)) {\n+            alt (expr_opt) {\n+                case (none[@ast.expr]) {\n+                    auto nil = plain_ty(ty.ty_nil);\n+                    if (!are_compatible(fcx, fcx.ret_ty, nil)) {\n+                        fcx.ccx.sess.err(\"put; in function \"\n+                                         + \"putting non-nil\");\n+                    }\n+\n+                    ret expr;\n+                }\n+\n+                case (some[@ast.expr](?e)) {\n+                    auto expr_0 = check_expr(fcx, e);\n+                    auto expr_1 = demand_expr(fcx, fcx.ret_ty, expr_0);\n+                    ret @fold.respan[ast.expr_](expr.span,\n+                                                ast.expr_put(some(expr_1)));\n+                }\n+            }\n+        }\n+\n+        case (ast.expr_be(?e)) {\n+            /* FIXME: prove instead of check */\n+            check (ast.is_call_expr(e));\n+            auto expr_0 = check_expr(fcx, e);\n+            auto expr_1 = demand_expr(fcx, fcx.ret_ty, expr_0);\n+            ret @fold.respan[ast.expr_](expr.span,\n+                                        ast.expr_be(expr_1));\n+        }\n+\n+        case (ast.expr_log(?e)) {\n+            auto expr_t = check_expr(fcx, e);\n+            ret @fold.respan[ast.expr_](expr.span, ast.expr_log(expr_t));\n+        }\n+\n+        case (ast.expr_check_expr(?e)) {\n+            auto expr_t = check_expr(fcx, e);\n+            demand(fcx, expr.span, plain_ty(ty.ty_bool), expr_ty(expr_t));\n+            ret @fold.respan[ast.expr_](expr.span,\n+                                        ast.expr_check_expr(expr_t));\n+        }\n+\n         case (ast.expr_assign(?lhs, ?rhs, _)) {\n             auto lhs_0 = check_expr(fcx, lhs);\n             auto rhs_0 = check_expr(fcx, rhs);\n@@ -1238,6 +1654,17 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                                                      body_1, ann));\n         }\n \n+        case (ast.expr_for_each(?decl, ?seq, ?body, _)) {\n+            auto decl_1 = check_decl_local(fcx, decl);\n+            auto seq_1 = check_expr(fcx, seq);\n+            auto body_1 = check_block(fcx, body);\n+\n+            auto ann = ast.ann_type(plain_ty(ty.ty_nil));\n+            ret @fold.respan[ast.expr_](expr.span,\n+                                        ast.expr_for_each(decl_1, seq_1,\n+                                                          body_1, ann));\n+        }\n+\n         case (ast.expr_while(?cond, ?body, _)) {\n             auto cond_0 = check_expr(fcx, cond);\n             auto cond_1 = demand_expr(fcx, plain_ty(ty.ty_bool), cond_0);\n@@ -1324,96 +1751,71 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n         }\n \n         case (ast.expr_bind(?f, ?args, _)) {\n-            auto f_0 = check_expr(fcx, f);\n-            auto t_0 = expr_ty(f_0);\n-\n-            if (!ty.is_fn_ty(t_0)) {\n-                fcx.ccx.sess.span_err(f_0.span,\n-                                      \"mismatched types: bind callee has \" +\n-                                      \"non-function type: \" +\n-                                      ty_to_str(t_0));\n-            }\n-\n-            let vec[arg] arg_tys_0 = ty.ty_fn_args(t_0);\n-            let @ty.t rt_0 = ty.ty_fn_ret(t_0);\n-            let vec[option.t[@ast.expr]] args_1 = vec();\n-\n-            let uint i = 0u;\n-\n-            let vec[arg] residual_args = vec();\n-            for (option.t[@ast.expr] a in args) {\n-                alt (a) {\n-                    case (none[@ast.expr]) {\n-                        append[arg](residual_args,\n-                                    arg_tys_0.(i));\n-                        append[option.t[@ast.expr]](args_1,\n-                                                    none[@ast.expr]);\n-                    }\n-                    case (some[@ast.expr](?sa)) {\n-                        auto arg_1 = check_expr(fcx, sa);\n-                        auto arg_t = expr_ty(arg_1);\n-                        demand_expr(fcx, arg_tys_0.(i).ty, arg_1);\n-                        append[option.t[@ast.expr]](args_1,\n-                                                    some[@ast.expr](arg_1));\n+            // Call the generic checker.\n+            auto result = check_call_or_bind(fcx, f, args);\n+\n+            // Pull the argument and return types out.\n+            auto proto_1;\n+            let vec[ty.arg] arg_tys_1 = vec();\n+            auto rt_1;\n+            alt (expr_ty(result._0).struct) {\n+                case (ty.ty_fn(?proto, ?arg_tys, ?rt)) {\n+                    proto_1 = proto;\n+                    rt_1 = rt;\n+\n+                    // For each blank argument, add the type of that argument\n+                    // to the resulting function type.\n+                    auto i = 0u;\n+                    while (i < _vec.len[option.t[@ast.expr]](args)) {\n+                        alt (args.(i)) {\n+                            case (some[@ast.expr](_)) { /* no-op */ }\n+                            case (none[@ast.expr]) {\n+                                arg_tys_1 += vec(arg_tys.(i));\n+                            }\n+                        }\n+                        i += 1u;\n                     }\n                 }\n-                i += 1u;\n+                case (_) {\n+                    log \"LHS of bind expr didn't have a function type?!\";\n+                    fail;\n+                }\n             }\n \n-            let @ty.t t_1 = plain_ty(ty.ty_fn(residual_args, rt_0));\n+            auto t_1 = plain_ty(ty.ty_fn(proto_1, arg_tys_1, rt_1));\n             ret @fold.respan[ast.expr_](expr.span,\n-                                        ast.expr_bind(f_0, args_1,\n+                                        ast.expr_bind(result._0, result._1,\n                                                       ast.ann_type(t_1)));\n-\n         }\n \n         case (ast.expr_call(?f, ?args, _)) {\n-\n-            // Check the function.\n-            auto f_0 = check_expr(fcx, f);\n-\n-            // Check the arguments and generate the argument signature.\n-            let vec[@ast.expr] args_0 = vec();\n-            let vec[arg] arg_tys_0 = vec();\n-            for (@ast.expr a in args) {\n-                auto a_0 = check_expr(fcx, a);\n-                append[@ast.expr](args_0, a_0);\n-\n-                // FIXME: this breaks aliases. We need a ty_fn_arg.\n-                append[arg](arg_tys_0, rec(mode=ast.val, ty=expr_ty(a_0)));\n+            let vec[option.t[@ast.expr]] args_opt_0 = vec();\n+            for (@ast.expr arg in args) {\n+                args_opt_0 += vec(some[@ast.expr](arg));\n             }\n-            auto rt_0 = next_ty_var(fcx.ccx);\n-            auto t_0 = plain_ty(ty.ty_fn(arg_tys_0, rt_0));\n-\n-            // Unify and write back to the function.\n-            auto f_1 = demand_expr(fcx, t_0, f_0);\n \n-            // Take the argument types out of the resulting function type.\n-            auto t_1 = expr_ty(f_1);\n+            // Call the generic checker.\n+            auto result = check_call_or_bind(fcx, f, args_opt_0);\n \n-            if (!ty.is_fn_ty(t_1)) {\n-                fcx.ccx.sess.span_err(f_1.span,\n-                                      \"mismatched types: callee has \" +\n-                                      \"non-function type: \" +\n-                                      ty_to_str(t_1));\n-            }\n-\n-            let vec[arg] arg_tys_1 = ty.ty_fn_args(t_1);\n-            let @ty.t rt_1 = ty.ty_fn_ret(t_1);\n-\n-            // Unify and write back to the arguments.\n-            auto i = 0u;\n+            // Pull out the arguments.\n             let vec[@ast.expr] args_1 = vec();\n-            while (i < _vec.len[@ast.expr](args_0)) {\n-                auto arg_ty_1 = arg_tys_1.(i);\n-                auto e = demand_expr(fcx, arg_ty_1.ty, args_0.(i));\n-                append[@ast.expr](args_1, e);\n+            for (option.t[@ast.expr] arg in result._1) {\n+                args_1 += vec(option.get[@ast.expr](arg));\n+            }\n \n-                i += 1u;\n+            // Pull the return type out of the type of the function.\n+            auto rt_1 = plain_ty(ty.ty_nil);    // FIXME: typestate botch\n+            alt (expr_ty(result._0).struct) {\n+                case (ty.ty_fn(_,_,?rt))    { rt_1 = rt; }\n+                case (ty.ty_native_fn(_, _, ?rt))    { rt_1 = rt; }\n+                case (_) {\n+                    log \"LHS of call expr didn't have a function type?!\";\n+                    fail;\n+                }\n             }\n \n             ret @fold.respan[ast.expr_](expr.span,\n-                                        ast.expr_call(f_1, args_1,\n+                                        ast.expr_call(result._0, args_1,\n                                                       ast.ann_type(rt_1)));\n         }\n \n@@ -1478,7 +1880,10 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                                         ast.expr_tup(elts_1, ann));\n         }\n \n-        case (ast.expr_rec(?fields, _)) {\n+        case (ast.expr_rec(?fields, ?base, _)) {\n+\n+            auto base_1 = base;\n+\n             let vec[ast.field] fields_1 = vec();\n             let vec[field] fields_t = vec();\n \n@@ -1492,9 +1897,52 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                 append[field](fields_t, rec(ident=f.ident, ty=expr_t));\n             }\n \n-            auto ann = ast.ann_type(plain_ty(ty.ty_rec(fields_t)));\n+            auto ann = ast.ann_none;\n+\n+            alt (base) {\n+                case (none[@ast.expr]) {\n+                    ann = ast.ann_type(plain_ty(ty.ty_rec(fields_t)));\n+                }\n+\n+                case (some[@ast.expr](?bexpr)) {\n+                    auto bexpr_1 = check_expr(fcx, bexpr);\n+                    auto bexpr_t = expr_ty(bexpr_1);\n+\n+                    let vec[field] base_fields = vec();\n+\n+                    alt (bexpr_t.struct) {\n+                        case (ty.ty_rec(?flds)) {\n+                            base_fields = flds;\n+                        }\n+                        case (_) {\n+                            fcx.ccx.sess.span_err\n+                                (expr.span,\n+                                 \"record update non-record base\");\n+                        }\n+                    }\n+\n+                    ann = ast.ann_type(bexpr_t);\n+\n+                    for (ty.field f in fields_t) {\n+                        auto found = false;\n+                        for (ty.field bf in base_fields) {\n+                            if (_str.eq(f.ident, bf.ident)) {\n+                                demand(fcx, expr.span, f.ty, bf.ty);\n+                                found = true;\n+                            }\n+                        }\n+                        if (!found) {\n+                            fcx.ccx.sess.span_err\n+                                (expr.span,\n+                                 \"unknown field in record update: \"\n+                                 + f.ident);\n+                        }\n+                    }\n+                }\n+            }\n+\n             ret @fold.respan[ast.expr_](expr.span,\n-                                        ast.expr_rec(fields_1, ann));\n+                                        ast.expr_rec(fields_1, base_1, ann));\n         }\n \n         case (ast.expr_field(?base, ?field, _)) {\n@@ -1537,7 +1985,8 @@ fn check_expr(&@fn_ctxt fcx, @ast.expr expr) -> @ast.expr {\n                                               \"bad index on obj\");\n                     }\n                     auto meth = methods.(ix);\n-                    auto t = plain_ty(ty.ty_fn(meth.inputs, meth.output));\n+                    auto t = plain_ty(ty.ty_fn(meth.proto,\n+                                               meth.inputs, meth.output));\n                     auto ann = ast.ann_type(t);\n                     ret @fold.respan[ast.expr_](expr.span,\n                                                 ast.expr_field(base_1,\n@@ -1664,43 +2113,6 @@ fn check_stmt(&@fn_ctxt fcx, &@ast.stmt stmt) -> @ast.stmt {\n             ret stmt;\n         }\n \n-        case (ast.stmt_ret(?expr_opt)) {\n-            alt (expr_opt) {\n-                case (none[@ast.expr]) {\n-                    auto nil = plain_ty(ty.ty_nil);\n-                    if (!are_compatible(fcx, fcx.ret_ty, nil)) {\n-                        fcx.ccx.sess.err(\"ret; in function \"\n-                                         + \"returning non-nil\");\n-                    }\n-\n-                    ret stmt;\n-                }\n-\n-                case (some[@ast.expr](?expr)) {\n-                    auto expr_0 = check_expr(fcx, expr);\n-                    auto expr_1 = demand_expr(fcx, fcx.ret_ty, expr_0);\n-                    ret @fold.respan[ast.stmt_](stmt.span,\n-                                                ast.stmt_ret(some(expr_1)));\n-                }\n-            }\n-        }\n-\n-        case (ast.stmt_log(?expr)) {\n-            auto expr_t = check_expr(fcx, expr);\n-            ret @fold.respan[ast.stmt_](stmt.span, ast.stmt_log(expr_t));\n-        }\n-\n-        case (ast.stmt_check_expr(?expr)) {\n-            auto expr_t = check_expr(fcx, expr);\n-            demand(fcx, expr.span, plain_ty(ty.ty_bool), expr_ty(expr_t));\n-            ret @fold.respan[ast.stmt_](stmt.span,\n-                                        ast.stmt_check_expr(expr_t));\n-        }\n-\n-        case (ast.stmt_fail) {\n-            ret stmt;\n-        }\n-\n         case (ast.stmt_expr(?expr)) {\n             auto expr_t = check_expr(fcx, expr);\n             ret @fold.respan[ast.stmt_](stmt.span, ast.stmt_expr(expr_t));\n@@ -1744,9 +2156,8 @@ fn check_const(&@crate_ctxt ccx, &span sp, ast.ident ident, @ast.ty t,\n     ret @fold.respan[ast.item_](sp, item);\n }\n \n-fn check_fn(&@crate_ctxt ccx, ast.effect effect,\n-            bool is_iter, vec[ast.arg] inputs,\n-            @ast.ty output, &ast.block body) -> ast._fn {\n+fn check_fn(&@crate_ctxt ccx, &ast.fn_decl decl, ast.proto proto,\n+            &ast.block body) -> ast._fn {\n     auto local_ty_table = @common.new_def_hash[@ty.t]();\n \n     // FIXME: duplicate work: the item annotation already has the arg types\n@@ -1760,21 +2171,22 @@ fn check_fn(&@crate_ctxt ccx, ast.effect effect,\n     }\n \n     // Store the type of each argument in the table.\n-    for (ast.arg arg in inputs) {\n+    for (ast.arg arg in decl.inputs) {\n         auto input_ty = ast_ty_to_ty_crate(ccx, arg.ty);\n         local_ty_table.insert(arg.id, input_ty);\n     }\n \n-    let @fn_ctxt fcx = @rec(ret_ty = ast_ty_to_ty_crate(ccx, output),\n+    let @fn_ctxt fcx = @rec(ret_ty = ast_ty_to_ty_crate(ccx, decl.output),\n                             locals = local_ty_table,\n                             ccx = ccx);\n \n     // TODO: Make sure the type of the block agrees with the function type.\n     auto block_t = check_block(fcx, body);\n     auto block_wb = writeback(fcx, block_t);\n \n-    auto fn_t = rec(effect=effect, is_iter=is_iter,\n-                    inputs=inputs, output=output, body=block_wb);\n+    auto fn_t = rec(decl=decl,\n+                    proto=proto,\n+                    body=block_wb);\n     ret fn_t;\n }\n \n@@ -1787,13 +2199,13 @@ fn check_item_fn(&@crate_ctxt ccx, &span sp, ast.ident ident, &ast._fn f,\n     // again here, we can extract them.\n \n     let vec[arg] inputs = vec();\n-    for (ast.arg arg in f.inputs) {\n+    for (ast.arg arg in f.decl.inputs) {\n         auto input_ty = ast_ty_to_ty_crate(ccx, arg.ty);\n         inputs += vec(rec(mode=arg.mode, ty=input_ty));\n     }\n \n-    auto output_ty = ast_ty_to_ty_crate(ccx, f.output);\n-    auto fn_sty = ty.ty_fn(inputs, output_ty);\n+    auto output_ty = ast_ty_to_ty_crate(ccx, f.decl.output);\n+    auto fn_sty = ty.ty_fn(f.proto, inputs, output_ty);\n     auto fn_ann = ast.ann_type(plain_ty(fn_sty));\n \n     auto item = ast.item_fn(ident, f, ty_params, id, fn_ann);\n@@ -1825,7 +2237,7 @@ fn check_crate(session.session sess, @ast.crate crate) -> @ast.crate {\n     auto fld = fold.new_identity_fold[@crate_ctxt]();\n \n     fld = @rec(update_env_for_item = bind update_obj_fields(_, _),\n-               fold_fn      = bind check_fn(_,_,_,_,_,_),\n+               fold_fn      = bind check_fn(_,_,_,_),\n                fold_item_fn = bind check_item_fn(_,_,_,_,_,_,_)\n                with *fld);\n     ret fold.fold_crate[@crate_ctxt](ccx, fld, result._0);"}, {"sha": "43a9220f4e508f5855684fcb314a6ee919eab619", "filename": "src/comp/pretty/pp.rs", "status": "added", "additions": 207, "deletions": 0, "changes": 207, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fpretty%2Fpp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fpretty%2Fpp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fpretty%2Fpp.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,207 @@\n+import std.io;\n+import std._vec;\n+import std._str;\n+\n+tag boxtype {box_h; box_v; box_hv; box_align;}\n+tag contexttype {cx_h; cx_v;}\n+\n+tag token {\n+  brk(uint);\n+  word(str);\n+  cword(str); // closing token\n+  open(boxtype, uint);\n+  close;\n+}\n+\n+type context = rec(contexttype tp, uint indent);\n+\n+type ps = @rec(mutable vec[context] context,\n+               uint width,\n+               mutable vec[token] buffered,\n+               mutable uint scandepth,\n+               mutable uint bufferedcol,\n+               mutable uint col,\n+               mutable bool start_of_line);\n+\n+fn mkstate(uint width) -> ps {\n+  let vec[context] stack = vec(rec(tp=cx_v, indent=0u));\n+  let vec[token] buff = vec();\n+  ret @rec(mutable context=stack,\n+           width=width,\n+           mutable buffered=buff,\n+           mutable scandepth=0u,\n+           mutable bufferedcol=0u,\n+           mutable col=0u,\n+           mutable start_of_line=true);\n+}\n+\n+impure fn push_context(ps p, contexttype tp, uint indent) {\n+  before_print(p, false);\n+  p.context = _vec.push[context](p.context, rec(tp=tp, indent=base_indent(p)\n+                                                + indent));\n+}\n+\n+impure fn pop_context(ps p) {\n+  p.context = _vec.pop[context](p.context);\n+}\n+\n+impure fn add_token(ps p, token tok) {\n+  if (p.scandepth == 0u) {do_token(p, tok);}\n+  else {buffer_token(p, tok);}\n+}\n+\n+impure fn buffer_token(ps p, token tok) {\n+  p.buffered += vec(tok);\n+  p.bufferedcol += token_size(tok);\n+  alt (p.buffered.(0)) {\n+    case (brk(_)) {\n+      alt (tok) {\n+        case (brk(_)) {\n+          if (p.scandepth == 1u) {finish_break_scan(p);}\n+        }\n+        case (open(box_h,_)) {p.scandepth += 1u;}\n+        case (open(_,_)) {finish_break_scan(p);}\n+        case (close) {\n+          p.scandepth -= 1u;\n+          if (p.scandepth == 0u) {finish_break_scan(p);}\n+        }\n+        case (_) {}\n+      }\n+    }\n+    case (open(_,_)) {\n+      if (p.bufferedcol > p.width) {finish_block_scan(p, cx_v);}\n+      else {\n+        alt (tok) {\n+          case (open(_,_)) {p.scandepth += 1u;}\n+          case (close) {\n+            p.scandepth -= 1u;\n+            if (p.scandepth == 0u) {finish_block_scan(p, cx_h);}\n+          }\n+          case (_) {}\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+impure fn finish_block_scan(ps p, contexttype tp) {\n+  auto indent;\n+  alt (p.buffered.(0)){\n+    case (open(box_hv,?ind)) {\n+      indent = ind;\n+    }\n+    case (open(box_align, _)) {\n+      indent = p.col - base_indent(p);\n+    }\n+  }\n+  p.scandepth = 0u;\n+  push_context(p, tp, indent);\n+  for (token t in _vec.shift[token](p.buffered)) {add_token(p, t);}\n+}\n+\n+impure fn finish_break_scan(ps p) {\n+  if (p.bufferedcol > p.width) {\n+    write_str(\"\\n\");\n+    p.col = 0u;\n+  }\n+  else {\n+    auto width;\n+    alt (p.buffered.(0)) {case(brk(?w)) {width = w;}}\n+    auto i = 0u;\n+    while (i < width) {write_str(\" \"); i+=1u;}\n+    p.col += width;\n+  }\n+  p.scandepth = 0u;\n+  for (token t in _vec.shift[token](p.buffered)) {add_token(p, t);}\n+}\n+\n+impure fn start_scan(ps p, token tok) {\n+  p.buffered = vec(tok);\n+  p.scandepth = 1u;\n+  p.bufferedcol = p.col;\n+}\n+\n+fn cur_context(ps p) -> context {\n+  ret p.context.(_vec.len[context](p.context)-1u);\n+}\n+fn base_indent(ps p) -> uint {\n+  auto i = _vec.len[context](p.context);\n+  while (i > 0u) {\n+    i -= 1u;\n+    auto cx = p.context.(i);\n+    if (cx.tp == cx_v) {ret cx.indent;}\n+  }\n+}\n+\n+impure fn do_token(ps p, token tok) {\n+  alt (tok) {\n+    case (brk(?sz)) {\n+      alt (cur_context(p).tp) {\n+        case (cx_h) {\n+          before_print(p, false);\n+          start_scan(p, tok);\n+        }\n+        case (cx_v) {\n+          write_str(\"\\n\");\n+          p.col = 0u;\n+          p.start_of_line = true;\n+        }\n+      }\n+    }\n+    case (word(?w)) {\n+      before_print(p, false);\n+      write_str(w);\n+      p.col += _str.byte_len(w); // TODO char_len\n+    }\n+    case (cword(?w)) {\n+      before_print(p, true);\n+      write_str(w);\n+      p.col += _str.byte_len(w); // TODO char_len\n+    }\n+    case (open(?tp, ?indent)) {\n+      alt (tp) {\n+        case (box_hv) {start_scan(p, tok);}\n+        case (box_align) {start_scan(p, tok);}\n+        case (box_h) {push_context(p, cx_h, indent);}\n+        case (box_v) {push_context(p, cx_v, indent);}\n+      }\n+    }\n+    case (close) {pop_context(p);}\n+  }\n+}\n+\n+impure fn before_print(ps p, bool closing) {\n+  if (p.start_of_line) {\n+    p.start_of_line = false;\n+    auto ind;\n+    if (closing) {ind = base_indent(p);}\n+    else {ind = cur_context(p).indent;}\n+    p.col = ind;\n+    while (ind > 0u) {write_str(\" \"); ind -= 1u;}\n+  }\n+}\n+\n+fn write_str(str s) {\n+  io.writefd(1, _str.bytes(s));\n+}\n+\n+fn token_size(token tok) -> uint {\n+  alt (tok) {\n+    case (brk(?sz)) {ret sz;}\n+    case (word(?w)) {ret _str.byte_len(w);}\n+    case (cword(?w)) {ret _str.byte_len(w);}\n+    case (open(_, _)) {ret 0u;} // TODO exception for V blocks?\n+    case (close) {ret 0u;}\n+  }\n+}\n+\n+impure fn box(ps p, uint indent) {add_token(p, open(box_hv, indent));}\n+impure fn abox(ps p) {add_token(p, open(box_align, 0u));}\n+impure fn vbox(ps p, uint indent) {add_token(p, open(box_v, indent));}\n+impure fn hbox(ps p, uint indent) {add_token(p, open(box_h, indent));}\n+impure fn end(ps p) {add_token(p, close);}\n+impure fn wrd(ps p, str wrd) {add_token(p, word(wrd));}\n+impure fn cwrd(ps p, str wrd) {add_token(p, cword(wrd));}\n+impure fn space(ps p) {add_token(p, brk(1u));}\n+impure fn spaces(ps p, uint n) {add_token(p, brk(n));}\n+impure fn line(ps p) {add_token(p, brk(0u));}"}, {"sha": "cab778f1732216d8e67e5349054f8dd1098eb4ee", "filename": "src/comp/pretty/pprust.rs", "status": "added", "additions": 708, "deletions": 0, "changes": 708, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fpretty%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Fpretty%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fpretty%2Fpprust.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,708 @@\n+import std._vec;\n+import std._str;\n+import std.option;\n+import front.ast;\n+import pp.box; import pp.abox; import pp.vbox;\n+import pp.end; import pp.wrd; import pp.space; import pp.line;\n+import pp.ps;\n+\n+import foo = std.io;\n+\n+const uint indent_unit = 2u;\n+const int as_prec = 5;\n+\n+impure fn print_ast(ast._mod _mod) {\n+  auto s = pp.mkstate(80u);\n+  for (@ast.view_item vitem in _mod.view_items) {print_view_item(s, vitem);}\n+  line(s);\n+  for (@ast.item item in _mod.items) {print_item(s, item);}\n+}\n+\n+impure fn hbox(ps s) {\n+  pp.hbox(s, indent_unit);\n+}\n+impure fn wrd1(ps s, str word) {\n+  wrd(s, word);\n+  space(s);\n+}\n+impure fn popen(ps s) {\n+  wrd(s, \"(\");\n+  abox(s);\n+}\n+impure fn pclose(ps s) {\n+  end(s);\n+  wrd(s, \")\");\n+}\n+impure fn bopen(ps s) {\n+  wrd1(s, \"{\");\n+  vbox(s, indent_unit);\n+  line(s);\n+}\n+impure fn bclose(ps s) {\n+  end(s);\n+  pp.cwrd(s, \"}\");\n+}\n+impure fn commasep[IN](ps s, vec[IN] elts, impure fn (ps, IN) op) {\n+  auto first = true;\n+  for (IN elt in elts) {\n+    if (first) {first = false;}\n+    else {wrd1(s, \",\");}\n+    op(s, elt);\n+  }\n+}\n+\n+impure fn print_type(ps s, @ast.ty ty) {\n+  hbox(s);\n+  alt (ty.node) {\n+    case (ast.ty_nil) {wrd(s, \"()\");}\n+    case (ast.ty_bool) {wrd(s, \"bool\");}\n+    case (ast.ty_int) {wrd(s, \"int\");}\n+    case (ast.ty_uint) {wrd(s, \"uint\");}\n+    case (ast.ty_machine(?tm)) {wrd(s, util.common.ty_mach_to_str(tm));}\n+    case (ast.ty_char) {wrd(s, \"char\");}\n+    case (ast.ty_str) {wrd(s, \"str\");}\n+    case (ast.ty_box(?t)) {wrd(s, \"@\"); print_type(s, t);}\n+    case (ast.ty_vec(?t)) {wrd(s, \"vec[\"); print_type(s, t); wrd(s, \"]\");}\n+    case (ast.ty_type) {wrd(s, \"type\");}\n+    case (ast.ty_tup(?elts)) {\n+      wrd(s, \"tup\");\n+      popen(s);\n+      auto f = print_type;\n+      commasep[@ast.ty](s, elts, f);\n+      pclose(s);\n+    }\n+    case (ast.ty_rec(?fields)) {\n+      wrd(s, \"rec\");\n+      popen(s);\n+      impure fn print_field(ps s, ast.ty_field f) {\n+        hbox(s);\n+        print_type(s, f.ty);\n+        space(s);\n+        wrd(s, f.ident);\n+        end(s);\n+      }\n+      auto f = print_field;\n+      commasep[ast.ty_field](s, fields, f);\n+      pclose(s);\n+    }\n+    case (ast.ty_fn(?proto,?inputs,?output)) {\n+      if (proto == ast.proto_fn) {wrd(s, \"fn\");}\n+      else {wrd(s, \"iter\");}\n+      popen(s);\n+      impure fn print_arg(ps s, ast.ty_arg input) {\n+        if (middle.ty.mode_is_alias(input.mode)) {wrd(s, \"&\");}\n+        print_type(s, input.ty);\n+      }\n+      auto f = print_arg;\n+      commasep[ast.ty_arg](s, inputs, f);\n+      pclose(s);\n+      if (output.node != ast.ty_nil) {\n+        space(s);\n+        hbox(s);\n+        wrd1(s, \"->\");\n+        print_type(s, output);\n+        end(s);\n+      }\n+    }\n+    case (ast.ty_path(?path,_)) {\n+      print_path(s, path);\n+    }\n+    case (ast.ty_mutable(?t)) {\n+      wrd1(s, \"mutable\");\n+      print_type(s, t);\n+    }\n+  }\n+  end(s);\n+}\n+\n+impure fn print_item(ps s, @ast.item item) {\n+  hbox(s);\n+  alt (item.node) {\n+    case (ast.item_const(?id, ?ty, ?expr, _, _)) {\n+      wrd1(s, \"const\");\n+      print_type(s, ty);\n+      space(s);\n+      wrd1(s, id);\n+      wrd1(s, \"=\");\n+      print_expr(s, expr);\n+      wrd(s, \";\");\n+    }\n+    case (ast.item_fn(?name,?_fn,?typarams,_,_)) {\n+      print_fn(s, _fn.decl, name, typarams);\n+      space(s);\n+      print_block(s, _fn.body);\n+    }\n+    case (ast.item_mod(?id,?_mod,_)) {\n+      wrd1(s, \"mod\");\n+      wrd1(s, id);\n+      bopen(s);\n+      for (@ast.item itm in _mod.items) {print_item(s, itm);}\n+      bclose(s);\n+    }\n+    case (ast.item_native_mod(?id,?nmod,_)) {\n+      wrd1(s, \"native\");\n+      alt (nmod.abi) {\n+        case (ast.native_abi_rust) {wrd1(s, \"\\\"rust\\\"\");}\n+        case (ast.native_abi_cdecl) {wrd1(s, \"\\\"cdecl\\\"\");}\n+      }\n+      wrd1(s, \"mod\");\n+      wrd1(s, id);\n+      bopen(s);\n+      for (@ast.native_item item in nmod.items) {\n+        hbox(s);\n+        alt (item.node) {\n+          case (ast.native_item_ty(?id,_)) {\n+            wrd1(s, \"type\");\n+            wrd(s, id);\n+          }\n+          case (ast.native_item_fn(?id,?decl,?typarams,_,_)) {\n+            print_fn(s, decl, id, typarams);\n+          }\n+        }\n+        wrd(s, \";\");\n+        end(s);\n+      }\n+      bclose(s);\n+    }\n+    case (ast.item_ty(?id,?ty,?params,_,_)) {\n+      wrd1(s, \"type\");\n+      wrd(s, id);\n+      print_type_params(s, params);\n+      space(s);\n+      wrd1(s, \"=\");\n+      print_type(s, ty);\n+      wrd(s, \";\");\n+    }\n+    case (ast.item_tag(?id,?variants,?params,_)) {\n+      wrd1(s, \"tag\");\n+      wrd(s, id);\n+      print_type_params(s, params);\n+      space(s);\n+      bopen(s);\n+      for (ast.variant v in variants) {\n+        wrd(s, v.name);\n+        if (_vec.len[ast.variant_arg](v.args) > 0u) {\n+          popen(s);\n+          impure fn print_variant_arg(ps s, ast.variant_arg arg) {\n+            print_type(s, arg.ty);\n+          }\n+          auto f = print_variant_arg;\n+          commasep[ast.variant_arg](s, v.args, f);\n+          pclose(s);\n+        }\n+        wrd(s, \";\");\n+        line(s);\n+      }\n+      bclose(s);\n+    }\n+    case (ast.item_obj(?id,?_obj,?params,_,_)) {\n+      wrd1(s, \"obj\");\n+      wrd(s, id);\n+      print_type_params(s, params);\n+      popen(s);\n+      impure fn print_field(ps s, ast.obj_field field) {\n+        hbox(s);\n+        print_type(s, field.ty);\n+        space(s);\n+        wrd(s, field.ident);\n+        end(s);\n+      }\n+      auto f = print_field;\n+      commasep[ast.obj_field](s, _obj.fields, f);\n+      pclose(s);\n+      space(s);\n+      bopen(s);\n+      for (@ast.method meth in _obj.methods) {\n+        hbox(s);\n+        let vec[ast.ty_param] typarams = vec();\n+        print_fn(s, meth.node.meth.decl, meth.node.ident, typarams);\n+        space(s);\n+        print_block(s, meth.node.meth.body);\n+        end(s);\n+        line(s);\n+      }\n+      alt (_obj.dtor) {\n+        case (option.some[ast.block](?dtor)) {\n+          hbox(s);\n+          wrd1(s, \"close\");\n+          print_block(s, dtor);\n+          end(s);\n+          line(s);\n+        }\n+        case (_) {}\n+      }\n+      bclose(s);\n+    }\n+  }\n+  end(s);\n+  line(s);\n+  line(s);\n+}\n+\n+impure fn print_block(ps s, ast.block blk) {\n+  bopen(s);\n+  for (@ast.stmt st in blk.node.stmts) {\n+    alt (st.node) {\n+      case (ast.stmt_decl(?decl)) {print_decl(s, decl);}\n+      case (ast.stmt_expr(?expr)) {print_expr(s, expr);}\n+    }\n+    if (front.parser.stmt_ends_with_semi(st)) {wrd(s, \";\");}\n+    line(s);\n+  }\n+  alt (blk.node.expr) {\n+    case (option.some[@ast.expr](?expr)) {\n+      print_expr(s, expr);\n+      line(s);\n+    }\n+    case (_) {}\n+  }\n+  bclose(s);\n+}\n+\n+impure fn print_literal(ps s, @ast.lit lit) {\n+  alt (lit.node) {\n+    case (ast.lit_str(?st)) {print_string(s, st);}\n+    case (ast.lit_char(?ch)) {\n+      wrd(s, \"'\" + escape_str(_str.from_bytes(vec(ch as u8)), '\\'') + \"'\");\n+    }\n+    case (ast.lit_int(?val)) {\n+      wrd(s, util.common.istr(val));\n+    }\n+    case (ast.lit_uint(?val)) { // TODO clipping? uistr?\n+      wrd(s, util.common.istr(val as int) + \"u\");\n+    }\n+    case (ast.lit_mach_int(?mach,?val)) {\n+      wrd(s, util.common.istr(val as int));\n+      wrd(s, util.common.ty_mach_to_str(mach));\n+    }\n+    case (ast.lit_nil) {wrd(s, \"()\");}\n+    case (ast.lit_bool(?val)) {\n+      if (val) {wrd(s, \"true\");} else {wrd(s, \"false\");}\n+    }\n+  }\n+}\n+\n+impure fn print_expr(ps s, @ast.expr expr) {\n+  auto pe = print_expr;\n+  hbox(s);\n+  alt (expr.node) {\n+    case (ast.expr_vec(?exprs,_)) {\n+      wrd(s, \"vec\");\n+      popen(s);\n+      commasep[@ast.expr](s, exprs, pe);\n+      pclose(s);\n+    }\n+    case (ast.expr_tup(?exprs,_)) {\n+      impure fn printElt(ps s, ast.elt elt) {\n+        hbox(s);\n+        if (elt.mut == ast.mut) {wrd1(s, \"mutable\");}\n+        print_expr(s, elt.expr);\n+        end(s);\n+      }\n+      wrd(s, \"tup\");\n+      popen(s);\n+      auto f = printElt;\n+      commasep[ast.elt](s, exprs, f);\n+      pclose(s);\n+    }\n+    case (ast.expr_rec(?fields,_,_)) {\n+      impure fn print_field(ps s, ast.field field) {\n+        hbox(s);\n+        if (field.mut == ast.mut) {wrd1(s, \"mutable\");}\n+        wrd(s, field.ident);\n+        wrd(s, \"=\");\n+        print_expr(s, field.expr);\n+        end(s);\n+      }\n+      wrd(s, \"rec\");\n+      popen(s);\n+      auto f = print_field;\n+      commasep[ast.field](s, fields, f);\n+      pclose(s);\n+    }\n+    case (ast.expr_call(?func,?args,_)) {\n+      print_expr(s, func);\n+      popen(s);\n+      commasep[@ast.expr](s, args, pe);\n+      pclose(s);\n+    }\n+    case (ast.expr_bind(?func,?args,_)) {\n+      impure fn print_opt(ps s, option.t[@ast.expr] expr) {\n+        alt (expr) {\n+          case (option.some[@ast.expr](?expr)) {\n+            print_expr(s, expr);\n+          }\n+          case (_) {wrd(s, \"_\");}\n+        }\n+      }\n+      wrd1(s, \"bind\");\n+      print_expr(s, func);\n+      popen(s);\n+      auto f = print_opt;\n+      commasep[option.t[@ast.expr]](s, args, f);\n+      pclose(s);\n+    }\n+    case (ast.expr_binary(?op,?lhs,?rhs,_)) {\n+      auto prec = operator_prec(op);\n+      print_maybe_parens(s, lhs, prec);\n+      space(s);\n+      wrd1(s, ast.binop_to_str(op));\n+      print_maybe_parens(s, rhs, prec + 1);\n+    }\n+    case (ast.expr_unary(?op,?expr,_)) {\n+      wrd(s, ast.unop_to_str(op));\n+      if (op == ast._mutable) {space(s);}\n+      print_expr(s, expr);\n+    }\n+    case (ast.expr_lit(?lit,_)) {\n+      print_literal(s, lit);\n+    }\n+    case (ast.expr_cast(?expr,?ty,_)) {\n+      print_maybe_parens(s, expr, as_prec);\n+      space(s);\n+      wrd1(s, \"as\");\n+      print_type(s, ty);\n+    }\n+    case (ast.expr_if(?test,?block,?elseopt,_)) {\n+      wrd1(s, \"if\");\n+      popen(s);\n+      print_expr(s, test);\n+      pclose(s);\n+      space(s);\n+      print_block(s, block);\n+      alt (elseopt) {\n+        case (option.some[@ast.expr](?_else)) {\n+          space(s);\n+          wrd1(s, \"else\");\n+          print_expr(s, _else);\n+        }\n+      }\n+    }\n+    case (ast.expr_while(?test,?block,_)) {\n+      wrd1(s, \"while\");\n+      popen(s);\n+      print_expr(s, test);\n+      pclose(s);\n+      space(s);\n+      print_block(s, block);\n+    }\n+    case (ast.expr_for(?decl,?expr,?block,_)) {\n+      wrd1(s, \"for\");\n+      popen(s);\n+      print_decl(s, decl);\n+      space(s);\n+      wrd1(s, \"in\");\n+      print_expr(s, expr);\n+      pclose(s);\n+      space(s);\n+      print_block(s, block);\n+    }\n+    case (ast.expr_for_each(?decl,?expr,?block,_)) {\n+      wrd1(s, \"for each\");\n+      popen(s);\n+      print_decl(s, decl);\n+      space(s);\n+      wrd1(s, \"in\");\n+      print_expr(s, expr);\n+      space(s);\n+      print_block(s, block);\n+    }\n+    case (ast.expr_do_while(?block,?expr,_)) {\n+      wrd1(s, \"do\");\n+      space(s);\n+      print_block(s, block);\n+      space(s);\n+      wrd1(s, \"while\");\n+      popen(s);\n+      print_expr(s, expr);\n+      pclose(s);\n+    }\n+    case (ast.expr_alt(?expr,?arms,_)) {\n+      wrd1(s, \"alt\");\n+      popen(s);\n+      print_expr(s, expr);\n+      pclose(s);\n+      space(s);\n+      bopen(s);\n+      for (ast.arm arm in arms) {\n+        hbox(s);\n+        wrd1(s, \"case\");\n+        popen(s);\n+        print_pat(s, arm.pat);\n+        pclose(s);\n+        space(s);\n+        print_block(s, arm.block);\n+        end(s);\n+        line(s);\n+      }\n+      bclose(s);\n+    }\n+    case (ast.expr_block(?block,_)) {\n+      print_block(s, block);\n+    }\n+    case (ast.expr_assign(?lhs,?rhs,_)) {\n+      print_expr(s, lhs);\n+      space(s);\n+      wrd1(s, \"=\");\n+      print_expr(s, rhs);\n+    }\n+    case (ast.expr_assign_op(?op,?lhs,?rhs,_)) {\n+      print_expr(s, lhs);\n+      space(s);\n+      wrd(s, ast.binop_to_str(op));\n+      wrd1(s, \"=\");\n+      print_expr(s, rhs);\n+    }\n+    case (ast.expr_field(?expr,?id,_)) {\n+      print_expr(s, expr);\n+      wrd(s, \".\");\n+      wrd(s, id);\n+    }\n+    case (ast.expr_index(?expr,?index,_)) {\n+      print_expr(s, expr);\n+      wrd(s, \".\");\n+      popen(s);\n+      print_expr(s, index);\n+      pclose(s);\n+    }\n+    case (ast.expr_path(?path,_,_)) {\n+      print_path(s, path);\n+    }\n+    case (ast.expr_fail) {\n+      wrd(s, \"fail\");\n+    }\n+    case (ast.expr_ret(?result)) {\n+      wrd(s, \"ret\");\n+      alt (result) {\n+        case (option.some[@ast.expr](?expr)) {\n+          space(s);\n+          print_expr(s, expr);\n+        }\n+        case (_) {}\n+      }\n+    }\n+    case (ast.expr_put(?result)) {\n+      wrd(s, \"put\");\n+      alt (result) {\n+        case (option.some[@ast.expr](?expr)) {\n+          space(s);\n+          print_expr(s, expr);\n+        }\n+        case (_) {}\n+      }\n+    }\n+    case (ast.expr_be(?result)) {\n+      wrd1(s, \"be\");\n+      print_expr(s, result);\n+    }\n+    case (ast.expr_log(?expr)) {\n+      wrd1(s, \"log\");\n+      print_expr(s, expr);\n+    }\n+    case (ast.expr_check_expr(?expr)) {\n+      wrd1(s, \"check\");\n+      print_expr(s, expr);\n+    }\n+    case (_) {wrd(s, \"X\");}\n+    // TODO expr_ext(path, vec[@expr], option.t[@expr], @expr, ann);\n+  }\n+  end(s);\n+}\n+\n+impure fn print_decl(ps s, @ast.decl decl) {\n+  hbox(s);\n+  alt (decl.node) {\n+    case (ast.decl_local(?loc)) {\n+      alt (loc.ty) {\n+        case (option.some[@ast.ty](?ty)) {\n+          wrd1(s, \"let\");\n+          print_type(s, ty);\n+          space(s);\n+        }\n+        case (_) {\n+          wrd1(s, \"auto\");\n+        }\n+      }\n+      wrd(s, loc.ident);\n+      alt (loc.init) {\n+        case (option.some[@ast.expr](?init)) {\n+          space(s);\n+          wrd1(s, \"=\");\n+          print_expr(s, init);\n+        }\n+        case (_) {}\n+      }\n+    }\n+    case (ast.decl_item(?item)) {\n+      print_item(s, item);\n+    }\n+  }\n+  end(s);\n+}\n+\n+impure fn print_path(ps s, ast.path path) {\n+  auto first = true;\n+  for (str id in path.node.idents) {\n+    if (first) {first = false;}\n+    else {wrd(s, \".\");}\n+    wrd(s, id);\n+  }\n+  if (_vec.len[@ast.ty](path.node.types) > 0u) {\n+    wrd(s, \"[\");\n+    auto f = print_type;\n+    commasep[@ast.ty](s, path.node.types, f);\n+    wrd(s, \"]\");\n+  }\n+}\n+\n+impure fn print_pat(ps s, @ast.pat pat) {\n+  alt (pat.node) {\n+    case (ast.pat_wild(_)) {wrd(s, \"_\");}\n+    case (ast.pat_bind(?id,_,_)) {wrd(s, \"?\" + id);}\n+    case (ast.pat_lit(?lit,_)) {print_literal(s, lit);}\n+    case (ast.pat_tag(?path,?args,_,_)) {\n+      print_path(s, path);\n+      if (_vec.len[@ast.pat](args) > 0u) {\n+        popen(s);\n+        auto f = print_pat;\n+        commasep[@ast.pat](s, args, f);\n+        pclose(s);\n+      }\n+    }\n+  }\n+}\n+\n+impure fn print_fn(ps s, ast.fn_decl decl, str name,\n+                   vec[ast.ty_param] typarams) {\n+  alt (decl.effect) {\n+    case (ast.eff_impure) {wrd1(s, \"impure\");}\n+    case (ast.eff_unsafe) {wrd1(s, \"unsafe\");}\n+    case (_) {}\n+  }\n+  wrd1(s, \"fn\");\n+  wrd(s, name);\n+  print_type_params(s, typarams);\n+  popen(s);\n+  impure fn print_arg(ps s, ast.arg x) {\n+    hbox(s);\n+    print_type(s, x.ty);\n+    space(s);\n+    wrd(s, x.ident);\n+    end(s);\n+  }\n+  auto f = print_arg;\n+  commasep[ast.arg](s, decl.inputs, f);\n+  pclose(s);\n+  if (decl.output.node != ast.ty_nil) {\n+    space(s);\n+    hbox(s);\n+    wrd1(s, \"->\");\n+    print_type(s, decl.output);\n+    end(s);\n+  }\n+}\n+\n+impure fn print_type_params(ps s, vec[ast.ty_param] params) {\n+  if (_vec.len[ast.ty_param](params) > 0u) {\n+    wrd(s, \"[\");\n+    impure fn printParam(ps s, ast.ty_param param) {wrd(s, param.ident);}\n+    auto f = printParam;\n+    commasep[ast.ty_param](s, params, f);\n+    wrd(s, \"]\");\n+  }\n+}\n+\n+impure fn print_view_item(ps s, @ast.view_item item) {\n+  hbox(s);\n+  alt (item.node) {\n+    case (ast.view_item_use(?id,?mta,_)) {\n+      wrd1(s, \"use\");\n+      wrd(s, id);\n+      if (_vec.len[@ast.meta_item](mta) > 0u) {\n+        popen(s);\n+        impure fn print_meta(ps s, @ast.meta_item item) {\n+          hbox(s);\n+          wrd1(s, item.node.name);\n+          wrd1(s, \"=\");\n+          print_string(s, item.node.value);\n+          end(s);\n+        }\n+        auto f = print_meta;\n+        commasep[@ast.meta_item](s, mta, f);\n+        pclose(s);\n+      }\n+    }\n+    case (ast.view_item_import(?id,?ids,_,_)) {\n+      wrd1(s, \"import\");\n+      if (!_str.eq(id, ids.(_vec.len[str](ids)-1u))) {\n+        wrd1(s, id);\n+        wrd1(s, \"=\");\n+      }\n+      auto first = true;\n+      for (str elt in ids) {\n+        if (first) {first = false;}\n+        else {wrd(s, \".\");}\n+        wrd(s, elt);\n+      }\n+    }\n+    case (ast.view_item_export(?id)) {\n+      wrd1(s, \"export\");\n+      wrd(s, id);\n+    }\n+  }\n+  end(s);\n+  wrd(s, \";\");\n+  line(s);\n+}\n+\n+// FIXME: The fact that this builds up the table anew for every call is\n+// not good. Eventually, table should be a const.\n+fn operator_prec(ast.binop op) -> int {\n+  for (front.parser.op_spec spec in front.parser.prec_table()) {\n+    if (spec.op == op) {ret spec.prec;}\n+  }\n+  fail;\n+}\n+\n+impure fn print_maybe_parens(ps s, @ast.expr expr, int outer_prec) {\n+  auto add_them;\n+  alt (expr.node) {\n+    case (ast.expr_binary(?op,_,_,_)) {\n+      add_them = operator_prec(op) < outer_prec;\n+    }\n+    case (ast.expr_cast(_,_,_)) {\n+      add_them = as_prec < outer_prec;\n+    }\n+    case (_) {\n+      add_them = false;\n+    }\n+  }\n+  if (add_them) {popen(s);}\n+  print_expr(s, expr);\n+  if (add_them) {pclose(s);}\n+}\n+\n+// TODO non-ascii\n+fn escape_str(str st, char to_escape) -> str {\n+  let str out = \"\";\n+  auto len = _str.byte_len(st);\n+  auto i = 0u;\n+  while (i < len) {\n+    alt (st.(i) as char) {\n+      case ('\\n') {out += \"\\\\n\";}\n+      case ('\\t') {out += \"\\\\t\";}\n+      case ('\\r') {out += \"\\\\r\";}\n+      case ('\\\\') {out += \"\\\\\\\\\";}\n+      case (?cur) {\n+        if (cur == to_escape) {out += \"\\\\\";}\n+        out += cur as u8;\n+      }\n+    }\n+    i += 1u;\n+  }\n+  ret out;\n+}\n+\n+impure fn print_string(ps s, str st) {\n+  wrd(s, \"\\\"\"); wrd(s, escape_str(st, '\"')); wrd(s, \"\\\"\");\n+}"}, {"sha": "e483340949ee4fa9b21ea654511321959822f441", "filename": "src/comp/rustc.rc", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Frustc.rc", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Frustc.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Frustc.rc?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -5,9 +5,12 @@ use std;\n \n mod front {\n     mod ast;\n+    mod extfmt;\n     mod lexer;\n     mod parser;\n+    mod pretty;\n     mod token;\n+    mod eval;\n }\n \n mod middle {\n@@ -28,6 +31,11 @@ mod driver {\n     mod session;\n }\n \n+mod pretty {\n+    mod pp;\n+    mod pprust;\n+}\n+\n mod util {\n     mod common;\n }\n@@ -38,7 +46,6 @@ auth middle.trans.copy_args_to_allocas = impure;\n auth middle.trans.trans_block = impure;\n auth lib.llvm = unsafe;\n \n-\n mod lib {\n     alt (target_os) {\n         case (\"win32\") {"}, {"sha": "071acea2ee235ec6e8f95e49d6cd5c2f8ff44652", "filename": "src/comp/util/common.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Futil%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Fcomp%2Futil%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Futil%2Fcommon.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -2,8 +2,10 @@ import std._uint;\n import std._int;\n import front.ast;\n \n+\n+type filename = str;\n type pos = rec(uint line, uint col);\n-type span = rec(str filename, pos lo, pos hi);\n+type span = rec(filename filename, pos lo, pos hi);\n type spanned[T] = rec(T node, span span);\n \n tag ty_mach {"}, {"sha": "0e0e7650943bf0b1723269349cff834eb5d7cb2f", "filename": "src/lib/_str.rs", "status": "modified", "additions": 3, "deletions": 18, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2F_str.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2F_str.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib%2F_str.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -96,25 +96,10 @@ fn buf(str s) -> sbuf {\n }\n \n fn bytes(str s) -> vec[u8] {\n-    /* FIXME (issue #58):\n-     * Should be...\n-     *\n-     *  fn ith(str s, uint i) -> u8 {\n-     *      ret s.(i);\n-     *  }\n-     *  ret _vec.init_fn[u8](bind ith(s, _), byte_len(s));\n-     *\n-     * but we do not correctly decrement refcount of s when\n-     * the binding dies, so we have to do this manually.\n-     */\n-    let uint n = _str.byte_len(s);\n-    let vec[u8] v = _vec.alloc[u8](n);\n-    let uint i = 0u;\n-    while (i < n) {\n-        v += vec(s.(i));\n-        i += 1u;\n+    fn ith(str s, uint i) -> u8 {\n+        ret s.(i);\n     }\n-    ret v;\n+    ret _vec.init_fn[u8](bind ith(s, _), byte_len(s));\n }\n \n fn from_bytes(vec[u8] v) : is_utf8(v) -> str {"}, {"sha": "0c4eb39e1aa00f4f3c760defe529d193c96c9089", "filename": "src/lib/io.rs", "status": "renamed", "additions": 25, "deletions": 32, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2Fio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2Fio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib%2Fio.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -85,37 +85,34 @@ fn new_buf_reader(str path) -> buf_reader {\n     ret fd_buf_reader(fd, new_buf());\n }\n \n-/**\n- * FIXME (issue #150):  This should be\n- *\n- *   type fileflag = tag(append(), create(), truncate());\n- *\n- * but then the tag value ctors are not found from crate-importers of std, so\n- * we manually simulate the enum below.\n- */\n-type fileflag = uint;\n-fn append() -> uint { ret 0u; }\n-fn create() -> uint { ret 1u; }\n-fn truncate() -> uint { ret 2u; }\n+tag fileflag {\n+    append;\n+    create;\n+    truncate;\n+}\n+\n+fn writefd(int fd, vec[u8] v) {\n+    auto len = _vec.len[u8](v);\n+    auto count = 0u;\n+    auto vbuf;\n+    while (count < len) {\n+        vbuf = _vec.buf_off[u8](v, count);\n+        auto nout = os.libc.write(fd, vbuf, len);\n+        if (nout < 0) {\n+            log \"error dumping buffer\";\n+            log sys.rustrt.last_os_error();\n+            fail;\n+        }\n+        count += nout as uint;\n+    }\n+}\n \n fn new_buf_writer(str path, vec[fileflag] flags) -> buf_writer {\n \n     state obj fd_buf_writer(int fd) {\n \n         fn write(vec[u8] v) {\n-            auto len = _vec.len[u8](v);\n-            auto count = 0u;\n-            auto vbuf;\n-            while (count < len) {\n-                vbuf = _vec.buf_off[u8](v, count);\n-                auto nout = os.libc.write(fd, vbuf, len);\n-                if (nout < 0) {\n-                    log \"error dumping buffer\";\n-                    log sys.rustrt.last_os_error();\n-                    fail;\n-                }\n-                count += nout as uint;\n-            }\n+            writefd(fd, v);\n         }\n \n         drop {\n@@ -129,13 +126,9 @@ fn new_buf_writer(str path, vec[fileflag] flags) -> buf_writer {\n \n     for (fileflag f in flags) {\n         alt (f) {\n-            // FIXME (issue #150): cf comment above defn of fileflag type\n-            //case (append())   { fflags |= os.libc_constants.O_APPEND(); }\n-            //case (create())   { fflags |= os.libc_constants.O_CREAT(); }\n-            //case (truncate()) { fflags |= os.libc_constants.O_TRUNC(); }\n-            case (0u)   { fflags |= os.libc_constants.O_APPEND(); }\n-            case (1u)   { fflags |= os.libc_constants.O_CREAT(); }\n-            case (2u) { fflags |= os.libc_constants.O_TRUNC(); }\n+            case (append)   { fflags |= os.libc_constants.O_APPEND(); }\n+            case (create)   { fflags |= os.libc_constants.O_CREAT(); }\n+            case (truncate) { fflags |= os.libc_constants.O_TRUNC(); }\n         }\n     }\n ", "previous_filename": "src/lib/_io.rs"}, {"sha": "2a6b74d4ff326a0ac2259a7b2513b6c86ebc0820", "filename": "src/lib/sha1.rs", "status": "added", "additions": 284, "deletions": 0, "changes": 284, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2Fsha1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2Fsha1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib%2Fsha1.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,284 @@\n+/*\n+ * A SHA-1 implementation derived from Paul E. Jones's reference\n+ * implementation, which is written for clarity, not speed. At some\n+ * point this will want to be rewritten.\n+ */\n+\n+import std._vec;\n+import std._str;\n+\n+export sha1;\n+export mk_sha1;\n+\n+state type sha1 = state obj {\n+                        // Provide message input as bytes\n+                        fn input(&vec[u8]);\n+\n+                        // Provide message input as string\n+                        fn input_str(&str);\n+\n+                        // Read the digest as a vector of 20 bytes. After\n+                        // calling this no further input may provided\n+                        // until reset is called\n+                        fn result() -> vec[u8];\n+\n+                        // Reset the sha1 state for reuse. This is called\n+                        // automatically during construction\n+                        fn reset();\n+};\n+\n+// Some unexported constants\n+const uint digest_buf_len = 5;\n+const uint msg_block_len = 64;\n+\n+// Builds a sha1 object\n+fn mk_sha1() -> sha1 {\n+\n+    state type sha1state = rec(vec[mutable u32] h,\n+                               mutable u32 len_low,\n+                               mutable u32 len_high,\n+                               vec[mutable u8] msg_block,\n+                               mutable uint msg_block_idx,\n+                               mutable bool computed);\n+\n+    impure fn add_input(&sha1state st, &vec[u8] msg) {\n+        // FIXME: Should be typestate precondition\n+        check (!st.computed);\n+\n+        for (u8 element in msg) {\n+            st.msg_block.(st.msg_block_idx) = element;\n+            st.msg_block_idx += 1u;\n+\n+            st.len_low += 8u32;\n+            if (st.len_low == 0u32) {\n+                st.len_high += 1u32;\n+                if (st.len_high == 0u32) {\n+                    // FIXME: Need better failure mode\n+                    fail;\n+                }\n+            }\n+\n+            if (st.msg_block_idx == msg_block_len) {\n+                process_msg_block(st);\n+            }\n+        }\n+    }\n+\n+    impure fn process_msg_block(&sha1state st) {\n+\n+        // FIXME: Make precondition\n+        check (_vec.len[mutable u32](st.h) == digest_buf_len);\n+\n+        // Constants\n+        auto k = vec(0x5A827999u32,\n+                     0x6ED9EBA1u32,\n+                     0x8F1BBCDCu32,\n+                     0xCA62C1D6u32);\n+\n+        let int t; // Loop counter\n+        let vec[mutable u32] w = _vec.init_elt[mutable u32](0u32, 80u);\n+\n+        // Initialize the first 16 words of the vector w\n+        t = 0;\n+        while (t < 16) {\n+            w.(t) = (st.msg_block.(t * 4) as u32) << 24u32;\n+            w.(t) = w.(t) | ((st.msg_block.(t * 4 + 1) as u32) << 16u32);\n+            w.(t) = w.(t) | ((st.msg_block.(t * 4 + 2) as u32) << 8u32);\n+            w.(t) = w.(t) | (st.msg_block.(t * 4 + 3) as u32);\n+            t += 1;\n+        }\n+\n+        // Initialize the rest of vector w\n+        while (t < 80) {\n+            auto val = w.(t-3) ^ w.(t-8) ^ w.(t-14) ^ w.(t-16);\n+            w.(t) = circular_shift(1u32, val);\n+            t += 1;\n+        }\n+\n+        auto a = st.h.(0);\n+        auto b = st.h.(1);\n+        auto c = st.h.(2);\n+        auto d = st.h.(3);\n+        auto e = st.h.(4);\n+\n+        let u32 temp;\n+\n+        t = 0;\n+        while (t < 20) {\n+            temp = circular_shift(5u32, a)\n+                + ((b & c) | ((~b) & d)) + e + w.(t) + k.(0);\n+            e = d;\n+            d = c;\n+            c = circular_shift(30u32, b);\n+            b = a;\n+            a = temp;\n+            t += 1;\n+        }\n+\n+        while (t < 40) {\n+            temp = circular_shift(5u32, a)\n+                + (b ^ c ^ d) + e + w.(t) + k.(1);\n+            e = d;\n+            d = c;\n+            c = circular_shift(30u32, b);\n+            b = a;\n+            a = temp;\n+            t += 1;\n+        }\n+\n+        while (t < 60) {\n+            temp = circular_shift(5u32, a)\n+                + ((b & c) | (b & d) | (c & d)) + e + w.(t) + k.(2);\n+            e = d;\n+            d = c;\n+            c = circular_shift(30u32, b);\n+            b = a;\n+            a = temp;\n+            t += 1;\n+        }\n+\n+        while (t < 80) {\n+            temp = circular_shift(5u32, a)\n+                + (b ^ c ^ d) + e + w.(t) + k.(3);\n+            e = d;\n+            d = c;\n+            c = circular_shift(30u32, b);\n+            b = a;\n+            a = temp;\n+            t += 1;\n+        }\n+\n+        st.h.(0) = st.h.(0) + a;\n+        st.h.(1) = st.h.(1) + b;\n+        st.h.(2) = st.h.(2) + c;\n+        st.h.(3) = st.h.(3) + d;\n+        st.h.(4) = st.h.(4) + e;\n+\n+        st.msg_block_idx = 0u;\n+    }\n+\n+    fn circular_shift(u32 bits, u32 word) -> u32 {\n+        // FIXME: This is a workaround for a rustboot\n+        // \"unrecognized quads\" codegen bug\n+        auto bits_hack = bits;\n+        ret (word << bits_hack) | (word >> (32u32 - bits));\n+    }\n+\n+    impure fn mk_result(&sha1state st) -> vec[u8] {\n+        if (!st.computed) {\n+            pad_msg(st);\n+            st.computed = true;\n+        }\n+\n+        let vec[u8] res = vec();\n+        for (u32 hpart in st.h) {\n+            res += (hpart >> 24u32) & 0xFFu32 as u8;\n+            res += (hpart >> 16u32) & 0xFFu32 as u8;\n+            res += (hpart >> 8u32) & 0xFFu32 as u8;\n+            res += hpart & 0xFFu32 as u8;\n+        }\n+        ret res;\n+    }\n+\n+    /*\n+     * According to the standard, the message must be padded to an even\n+     * 512 bits.  The first padding bit must be a '1'.  The last 64 bits\n+     * represent the length of the original message.  All bits in between\n+     * should be 0.  This function will pad the message according to those\n+     * rules by filling the msg_block vector accordingly.  It will also\n+     * call process_msg_block() appropriately.  When it returns, it\n+     * can be assumed that the message digest has been computed.\n+     */\n+    impure fn pad_msg(&sha1state st) {\n+        // FIXME: Should be a precondition\n+        check (_vec.len[mutable u8](st.msg_block) == msg_block_len);\n+\n+        /*\n+         * Check to see if the current message block is too small to hold\n+         * the initial padding bits and length.  If so, we will pad the\n+         * block, process it, and then continue padding into a second block.\n+         */\n+        if (st.msg_block_idx > 55u) {\n+            st.msg_block.(st.msg_block_idx) = 0x80u8;\n+            st.msg_block_idx += 1u;\n+\n+            while (st.msg_block_idx < msg_block_len) {\n+                st.msg_block.(st.msg_block_idx) = 0u8;\n+                st.msg_block_idx += 1u;\n+            }\n+\n+            process_msg_block(st);\n+        } else {\n+            st.msg_block.(st.msg_block_idx) = 0x80u8;\n+            st.msg_block_idx += 1u;\n+        }\n+\n+        while (st.msg_block_idx < 56u) {\n+            st.msg_block.(st.msg_block_idx) = 0u8;\n+            st.msg_block_idx += 1u;\n+        }\n+\n+        // Store the message length as the last 8 octets\n+        st.msg_block.(56) = (st.len_high >> 24u32) & 0xFFu32 as u8;\n+        st.msg_block.(57) = (st.len_high >> 16u32) & 0xFFu32 as u8;\n+        st.msg_block.(58) = (st.len_high >> 8u32) & 0xFFu32 as u8;\n+        st.msg_block.(59) = st.len_high & 0xFFu32 as u8;\n+        st.msg_block.(60) = (st.len_low >> 24u32) & 0xFFu32 as u8;\n+        st.msg_block.(61) = (st.len_low >> 16u32) & 0xFFu32 as u8;\n+        st.msg_block.(62) = (st.len_low >> 8u32) & 0xFFu32 as u8;\n+        st.msg_block.(63) = st.len_low & 0xFFu32 as u8;\n+\n+        process_msg_block(st);\n+    }\n+\n+    state obj sha1(sha1state st) {\n+\n+        fn reset() {\n+            // FIXME: Should be typestate precondition\n+            check (_vec.len[mutable u32](st.h) == digest_buf_len);\n+\n+            st.len_low = 0u32;\n+            st.len_high = 0u32;\n+            st.msg_block_idx = 0u;\n+\n+            st.h.(0) = 0x67452301u32;\n+            st.h.(1) = 0xEFCDAB89u32;\n+            st.h.(2) = 0x98BADCFEu32;\n+            st.h.(3) = 0x10325476u32;\n+            st.h.(4) = 0xC3D2E1F0u32;\n+\n+            st.computed = false;\n+        }\n+\n+        fn input(&vec[u8] msg) {\n+            add_input(st, msg);\n+        }\n+\n+        fn input_str(&str msg) {\n+            add_input(st, _str.bytes(msg));\n+        }\n+\n+        fn result() -> vec[u8] {\n+            ret mk_result(st);\n+        }\n+    }\n+\n+    auto st = rec(h = _vec.init_elt[mutable u32](0u32, digest_buf_len),\n+                  mutable len_low = 0u32,\n+                  mutable len_high = 0u32,\n+                  msg_block = _vec.init_elt[mutable u8](0u8, msg_block_len),\n+                  mutable msg_block_idx = 0u,\n+                  mutable computed = false);\n+    auto sh = sha1(st);\n+    sh.reset();\n+    ret sh;\n+}\n+\n+// Local Variables:\n+// mode: rust;\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// compile-command: \"make -k -C .. 2>&1 | sed -e 's/\\\\/x\\\\//x:\\\\//g'\";\n+// End:"}, {"sha": "4ad422a3363741df9730b462cfad443dad76c293", "filename": "src/lib/std.rc", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2Fstd.rc", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Flib%2Fstd.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib%2Fstd.rc?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -14,7 +14,7 @@ mod _str;\n \n // General IO and system-services modules.\n \n-mod _io;\n+mod io;\n mod sys;\n mod _task;\n \n@@ -25,7 +25,7 @@ mod util;\n \n // Authorize various rule-bendings.\n \n-auth _io = unsafe;\n+auth io = unsafe;\n auth _str = unsafe;\n auth _vec = unsafe;\n auth _task = unsafe;\n@@ -57,6 +57,7 @@ mod dbg;\n mod bitv;\n mod sort;\n mod path;\n+mod sha1;\n \n // Local Variables:\n // mode: rust;"}, {"sha": "48220290270145d14a976eb1f3bf044cb3abd33d", "filename": "src/rt/memory_region.cpp", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Fmemory_region.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Fmemory_region.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Fmemory_region.cpp?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,7 +1,10 @@\n #include \"rust_internal.h\"\n #include \"memory_region.h\"\n \n-#define TRACK_ALLOCATIONS\n+// NB: please do not commit code with this uncommented. It's\n+// hugely expensive and should only be used as a last resort.\n+//\n+// #define TRACK_ALLOCATIONS\n \n memory_region::memory_region(rust_srv *srv, bool synchronized) :\n     _srv(srv), _parent(NULL), _live_allocations(0),"}, {"sha": "46fcb22ea0b10c61a7fb7dca24e7879650cfa8ec", "filename": "src/rt/rust.cpp", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust.cpp?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -78,7 +78,7 @@ command_line_args : public dom_owned<command_line_args>\n \n extern \"C\" CDECL int\n rust_start(uintptr_t main_fn, rust_crate const *crate, int argc,\n-    char **argv) {\n+           char **argv) {\n \n     rust_srv *srv = new rust_srv();\n     rust_kernel *kernel = new rust_kernel(srv);\n@@ -87,7 +87,8 @@ rust_start(uintptr_t main_fn, rust_crate const *crate, int argc,\n     rust_dom *dom = handle->referent();\n     command_line_args *args = new (dom) command_line_args(dom, argc, argv);\n \n-    dom->log(rust_log::DOM, \"startup: %d args\", args->argc);\n+    dom->log(rust_log::DOM, \"startup: %d args in 0x%\" PRIxPTR,\n+             args->argc, (uintptr_t)args->args);\n     for (int i = 0; i < args->argc; i++) {\n         dom->log(rust_log::DOM,\n             \"startup: arg[%d] = '%s'\", i, args->argv[i]);\n@@ -99,7 +100,8 @@ rust_start(uintptr_t main_fn, rust_crate const *crate, int argc,\n \n     uintptr_t main_args[4] = {0, 0, 0, (uintptr_t)args->args};\n     dom->root_task->start(crate->get_exit_task_glue(),\n-        main_fn, (uintptr_t)&main_args, sizeof(main_args));\n+                          crate->abi_tag, main_fn,\n+                          (uintptr_t)&main_args, sizeof(main_args));\n     int ret = dom->start_main_loop();\n     delete args;\n     kernel->destroy_domain(dom);"}, {"sha": "62fd7c01a9c31ed7c1e63aacb9dac95ffd9fcafc", "filename": "src/rt/rust_crate_cache.cpp", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_crate_cache.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_crate_cache.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_crate_cache.cpp?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -49,7 +49,8 @@ rust_crate_cache::c_sym::c_sym(rust_dom *dom, lib *library, char const *name)\n         dom->log(rust_log::CACHE, \"resolved symbol '%s' to 0x%\"  PRIxPTR,\n                  name, val);\n     } else {\n-        dom->log(rust_log::CACHE, \"unresolved symbol '%s', null lib handle\",\n+        dom->log(rust_log::CACHE | rust_log::ERR,\n+                 \"unresolved symbol '%s', null lib handle\",\n                  name);\n     }\n }\n@@ -79,7 +80,7 @@ rust_crate_cache::rust_sym::rust_sym(rust_dom *dom,\n     typedef rust_crate_reader::die die;\n     rust_crate const *crate = (rust_crate*)crate_sym->get_val();\n     if (!crate) {\n-        dom->log(rust_log::CACHE,\n+        dom->log(rust_log::CACHE | rust_log::ERR,\n                  \"failed to resolve symbol, null crate symbol\");\n         return;\n     }"}, {"sha": "42b61801f53f7b6ade8e4a96c24b9235333e3f65", "filename": "src/rt/rust_internal.h", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_internal.h", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_internal.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_internal.h?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -88,6 +88,10 @@ static size_t const TIME_SLICE_IN_MS = 10;\n \n static intptr_t const CONST_REFCOUNT = 0x7badface;\n \n+// ABI tags for rust_start, rust_task::start and friends.\n+static uintptr_t const ABI_X86_RUSTBOOT_CDECL = 1;\n+static uintptr_t const ABI_X86_RUSTC_FASTCALL = 2;\n+\n // This accounts for logging buffers.\n \n static size_t const BUF_BYTES = 2048;\n@@ -241,6 +245,8 @@ class rust_crate {\n     size_t n_c_syms;\n     size_t n_libs;\n \n+    uintptr_t abi_tag;\n+\n     // Crates are immutable, constructed by the compiler.\n \n     uintptr_t get_image_base() const;"}, {"sha": "1afbfdd6b3b8140c5e69573d1f178187eaa26c42", "filename": "src/rt/rust_task.cpp", "status": "modified", "additions": 36, "deletions": 20, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_task.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_task.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_task.cpp?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -123,6 +123,7 @@ rust_task::~rust_task()\n \n void\n rust_task::start(uintptr_t exit_task_glue,\n+                 uintptr_t spawnee_abi,\n                  uintptr_t spawnee_fn,\n                  uintptr_t args,\n                  size_t callsz)\n@@ -147,39 +148,46 @@ rust_task::start(uintptr_t exit_task_glue,\n     // The exit_task_glue frame we synthesize above the frame we activate:\n     *spp-- = (uintptr_t) 0;          // closure-or-obj\n     *spp-- = (uintptr_t) this;       // task\n-    *spp-- = (uintptr_t) 0;          // output\n-    *spp-- = (uintptr_t) 0;          // retpc\n+    *spp-- = (uintptr_t) 0x0;        // output\n+    *spp-- = (uintptr_t) 0x0;        // retpc\n \n     uintptr_t exit_task_frame_base;\n \n-    for (size_t j = 0; j < n_callee_saves; ++j) {\n+    if (spawnee_abi == ABI_X86_RUSTBOOT_CDECL) {\n+        for (size_t j = 0; j < n_callee_saves; ++j) {\n \n-        // We want 'frame_base' to point to the old fp in this (exit-task)\n-        // frame, because we're going to inject this frame-pointer into the\n-        // callee-save frame pointer value in the *next* (spawnee) frame. A\n-        // cheap trick, but this means the spawnee frame will restore the\n-        // proper frame pointer of the glue frame as it runs its epilogue.\n-        if (j == callee_save_fp)\n-            exit_task_frame_base = (uintptr_t)spp;\n+            // We want 'frame_base' to point to the old fp in this (exit-task)\n+            // frame, because we're going to inject this frame-pointer into\n+            // the callee-save frame pointer value in the *next* (spawnee)\n+            // frame. A cheap trick, but this means the spawnee frame will\n+            // restore the proper frame pointer of the glue frame as it runs\n+            // its epilogue.\n+            if (j == callee_save_fp)\n+                exit_task_frame_base = (uintptr_t)spp;\n \n-        *spp-- = 0;\n-    }\n+            *spp-- = 0;\n+        }\n \n-    *spp-- = (uintptr_t) dom->root_crate;  // crate ptr\n-    *spp-- = (uintptr_t) 0;                // frame_glue_fns\n+        *spp-- = (uintptr_t) dom->root_crate;  // crate ptr\n+        *spp-- = (uintptr_t) 0;                // frame_glue_fns\n+    }\n \n     // Copy args from spawner to spawnee.\n     if (args)  {\n         uintptr_t *src = (uintptr_t *)args;\n         src += 1;                  // spawn-call output slot\n         src += 1;                  // spawn-call task slot\n         src += 1;                  // spawn-call closure-or-obj slot\n-        // Memcpy all but the task and output pointers\n-        callsz -= (2 * sizeof(uintptr_t));\n+\n+        // Undo previous sp-- so we're pointing at the last word pushed.\n+        ++spp;\n+\n+        // Memcpy all but the task, output and env pointers\n+        callsz -= (3 * sizeof(uintptr_t));\n         spp = (uintptr_t*) (((uintptr_t)spp) - callsz);\n         memcpy(spp, src, callsz);\n \n-        // Move sp down to point to task cell.\n+        // Move sp down to point to last implicit-arg cell (env).\n         spp--;\n     } else {\n         // We're at root, starting up.\n@@ -188,10 +196,18 @@ rust_task::start(uintptr_t exit_task_glue,\n \n     // The *implicit* incoming args to the spawnee frame we're\n     // activating:\n+    *spp-- = (uintptr_t) 0x0;               // closure-or-obj\n+\n+    if (spawnee_abi == ABI_X86_RUSTBOOT_CDECL) {\n+        // in CDECL mode we write the task + outptr to the spawnee stack.\n+        *spp-- = (uintptr_t) this;            // task\n+        *spp-- = (uintptr_t) 0;               // output addr\n+    } else {\n+        // in FASTCALL mode we don't, the outptr will be in ecx and the task\n+        // in edx, and the activate_glue will make sure to set that up.\n+        I(dom, spawnee_abi == ABI_X86_RUSTC_FASTCALL);\n+    }\n \n-    *spp-- = (uintptr_t) 0;               // closure-or-obj\n-    *spp-- = (uintptr_t) this;            // task\n-    *spp-- = (uintptr_t) 0;               // output addr\n     *spp-- = (uintptr_t) exit_task_glue;  // retpc\n \n     // The context the activate_glue needs to switch stack."}, {"sha": "5318ab71edfe31cdb6a1fac702958393d4ba0a60", "filename": "src/rt/rust_task.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_task.h", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_task.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_task.h?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -56,6 +56,7 @@ rust_task : public maybe_proxy<rust_task>,\n     ~rust_task();\n \n     void start(uintptr_t exit_task_glue,\n+               uintptr_t spawnee_abi,\n                uintptr_t spawnee_fn,\n                uintptr_t args,\n                size_t callsz);"}, {"sha": "1dba11024f417fa924596c29a070fced39fb7be4", "filename": "src/rt/rust_upcall.cpp", "status": "modified", "additions": 12, "deletions": 3, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_upcall.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Frust_upcall.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_upcall.cpp?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -253,6 +253,10 @@ upcall_fail(rust_task *task,\n     task->log(rust_log::UPCALL | rust_log::ERR,\n               \"upcall fail '%s', %s:%\" PRIdPTR, expr, file, line);\n     task->fail(4);\n+    if (getenv(\"RUST_TRAP_FAILURE\")) {\n+        // FIXME: x86-ism.\n+        __asm__(\"int3\");\n+    }\n }\n \n /**\n@@ -555,6 +559,7 @@ extern \"C\" CDECL rust_task *\n upcall_start_task(rust_task *spawner,\n                   rust_task *task,\n                   uintptr_t exit_task_glue,\n+                  uintptr_t spawnee_abi,\n                   uintptr_t spawnee_fn,\n                   size_t callsz) {\n     LOG_UPCALL_ENTRY(spawner);\n@@ -566,7 +571,8 @@ upcall_start_task(rust_task *spawner,\n              \", spawnee 0x%\" PRIxPTR\n              \", callsz %\" PRIdPTR \")\", task->name, task, exit_task_glue,\n              spawnee_fn, callsz);\n-    task->start(exit_task_glue, spawnee_fn, spawner->rust_sp, callsz);\n+    task->start(exit_task_glue, spawnee_abi, spawnee_fn,\n+                spawner->rust_sp, callsz);\n     return task;\n }\n \n@@ -619,16 +625,19 @@ extern \"C\" CDECL maybe_proxy<rust_task> *\n upcall_start_thread(rust_task *task,\n                     rust_proxy<rust_task> *child_task_proxy,\n                     uintptr_t exit_task_glue,\n+                    uintptr_t spawnee_abi,\n                     uintptr_t spawnee_fn,\n                     size_t callsz) {\n     LOG_UPCALL_ENTRY(task);\n     rust_dom *parenet_dom = task->dom;\n     rust_handle<rust_task> *child_task_handle = child_task_proxy->handle();\n     task->log(rust_log::UPCALL | rust_log::MEM | rust_log::TASK,\n               \"exit_task_glue: \" PTR \", spawnee_fn \" PTR\n-              \", callsz %\" PRIdPTR \")\", exit_task_glue, spawnee_fn, callsz);\n+              \", callsz %\" PRIdPTR \")\",\n+              exit_task_glue, spawnee_fn, callsz);\n     rust_task *child_task = child_task_handle->referent();\n-    child_task->start(exit_task_glue, spawnee_fn, task->rust_sp, callsz);\n+    child_task->start(exit_task_glue, spawnee_abi, spawnee_fn,\n+                      task->rust_sp, callsz);\n #if defined(__WIN32__)\n     HANDLE thread;\n     thread = CreateThread(NULL, 0, rust_thread_start, child_task->dom, 0,"}, {"sha": "e0e24156e6f1708638adf44d4daede575622cf37", "filename": "src/rt/test/rust_test_runtime.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Ftest%2Frust_test_runtime.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Frt%2Ftest%2Frust_test_runtime.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Ftest%2Frust_test_runtime.cpp?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -54,6 +54,7 @@ rust_task_test::worker::run() {\n         kernel->create_domain(crate, \"test\");\n     rust_dom *domain = handle->referent();\n     domain->root_task->start(crate->get_exit_task_glue(),\n+                             ABI_X86_RUSTBOOT_CDECL,\n                              (uintptr_t)&task_entry, (uintptr_t)NULL, 0);\n     domain->start_main_loop();\n     kernel->destroy_domain(domain);"}, {"sha": "d8c204d9fb32b24c7a50918f571f2b17e5b01f54", "filename": "src/test/compile-fail/reserved-dec.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-dec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-dec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-dec.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int dec = 0;\n+}"}, {"sha": "63d00f705bf93c3729dbf62641bb0881474bd70b", "filename": "src/test/compile-fail/reserved-f128.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-f128.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-f128.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-f128.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int f128 = 0;\n+}"}, {"sha": "bfb14cd8fee38ff83f2378400806674a42eba666", "filename": "src/test/compile-fail/reserved-f16.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-f16.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-f16.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-f16.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int f16 = 0;\n+}"}, {"sha": "33e8bd5e5b3626970c0481b9ebe4b635ead378e6", "filename": "src/test/compile-fail/reserved-f80.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-f80.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-f80.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-f80.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int f80 = 0;\n+}"}, {"sha": "c4d36bf76e013f4c723febfeaf24b346c6b79d1d", "filename": "src/test/compile-fail/reserved-m128.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-m128.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-m128.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-m128.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int m128 = 0;\n+}"}, {"sha": "bdb3a427c7e3d32d453fb1f084a79be48b9799db", "filename": "src/test/compile-fail/reserved-m32.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-m32.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-m32.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-m32.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int m32 = 0;\n+}"}, {"sha": "034884a6fddd306744ae696a3339c16886a00e7b", "filename": "src/test/compile-fail/reserved-m64.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-m64.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Freserved-m64.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Freserved-m64.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,5 @@\n+// error-pattern:reserved keyword\n+\n+fn main() {\n+  let int m64 = 0;\n+}"}, {"sha": "00a451f647aabc76e5405edafb7cecbe4f83d1b1", "filename": "src/test/compile-fail/tail-non-call.rs", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Ftail-non-call.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Ftail-non-call.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Ftail-non-call.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,10 @@\n+// error-pattern: Non-call expression in tail call\n+\n+fn f() -> int {\n+  auto x = 1;\n+  be x;\n+}\n+\n+fn main() {\n+  auto y = f();\n+}"}, {"sha": "64beedb9a99bb45b4428967470383dc1cf2a6804", "filename": "src/test/compile-fail/tail-typeck.rs", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Ftail-typeck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Fcompile-fail%2Ftail-typeck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Ftail-typeck.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,13 @@\n+// error-pattern: mismatched types\n+\n+fn f() -> int {\n+  be g();\n+}\n+\n+fn g() -> uint {\n+  ret 0u;\n+}\n+\n+fn main() {\n+  auto y = f();\n+}"}, {"sha": "91190260bb10f53bd54bd62a194250ded909879d", "filename": "src/test/run-pass/alt-pattern-lit.rs", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Falt-pattern-lit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Falt-pattern-lit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Falt-pattern-lit.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,17 @@\n+fn altlit(int f) -> int {\n+  alt (f) {\n+    case (10) {\n+      log \"case 10\";\n+      ret 20;\n+    }\n+    case (11) {\n+      log \"case 11\";\n+      ret 22;\n+    }\n+  }\n+}\n+\n+fn main() {\n+  check (altlit(10) == 20);\n+  check (altlit(11) == 22);\n+}"}, {"sha": "3fac37142f80a95fbac221de2686b67af2568d3d", "filename": "src/test/run-pass/arith-unsigned.rs", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Farith-unsigned.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Farith-unsigned.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Farith-unsigned.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,24 @@\n+// Unsigned integer operations\n+\n+fn main() {\n+  check (0u8 < 255u8);\n+  check (0u8 <= 255u8);\n+  check (255u8 > 0u8);\n+  check (255u8 >= 0u8);\n+  check (250u8 / 10u8 == 25u8);\n+  check (255u8 % 10u8 == 5u8);\n+  check (0u16 < 60000u16);\n+  check (0u16 <= 60000u16);\n+  check (60000u16 > 0u16);\n+  check (60000u16 >= 0u16);\n+  check (60000u16 / 10u16 == 6000u16);\n+  check (60005u16 % 10u16 == 5u16);\n+  check (0u32 < 4000000000u32);\n+  check (0u32 <= 4000000000u32);\n+  check (4000000000u32 > 0u32);\n+  check (4000000000u32 >= 0u32);\n+  check (4000000000u32 / 10u32 == 400000000u32);\n+  check (4000000005u32 % 10u32 == 5u32);\n+\n+  // 64-bit numbers have some flakiness yet. Not tested\n+}"}, {"sha": "856f3aff8e6e069ed4bc4e37d89ef307042fceb3", "filename": "src/test/run-pass/generic-box.rs", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-box.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-box.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fgeneric-box.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,8 @@\n+fn box[T](&tup(T,T,T) x) -> @tup(T,T,T) {\n+  ret @x;\n+}\n+\n+fn main() {\n+  let @tup(int,int,int) x = box[int](tup(1,2,3));\n+  check (x._1 == 2);\n+}\n\\ No newline at end of file"}, {"sha": "e821a784598d2275a23e67bcf20dd110a02103df", "filename": "src/test/run-pass/generic-fn-box.rs", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-fn-box.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-fn-box.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fgeneric-fn-box.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,9 @@\n+fn f[T](@T x) -> @T {\n+    ret x;\n+}\n+\n+fn main() {\n+    auto x = f(@3);\n+    log *x;\n+}\n+"}, {"sha": "b9596b0da9cdc1bd167a670165029b31197d380c", "filename": "src/test/run-pass/generic-recursive-tag.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-recursive-tag.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-recursive-tag.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fgeneric-recursive-tag.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,8 +1,9 @@\n tag list[T] {\n   cons(@T, @list[T]);\n-  nil();\n+  nil;\n }\n \n fn main() {\n-  let list[int] a = cons[int](10, cons[int](12, cons[int](13, nil[int]())));\n-}\n\\ No newline at end of file\n+  let list[int] a = cons[int](@10, @cons[int](@12, @cons[int](@13,\n+                                                              @nil[int])));\n+}"}, {"sha": "68d7c18f8d2b99ff53d44e9f89bc336926cef957", "filename": "src/test/run-pass/generic-tag.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-tag.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-tag.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fgeneric-tag.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -6,4 +6,4 @@ tag option[T] {\n fn main() {\n   let option[int] a = some[int](@10);\n   a = none[int];\n-}\n\\ No newline at end of file\n+}"}, {"sha": "c3d2a9d590381eb52428ada3264dc87a48df74a8", "filename": "src/test/run-pass/generic-type-synonym.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-type-synonym.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fgeneric-type-synonym.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fgeneric-type-synonym.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,4 +1,4 @@\n type foo[T] = tup(T);\n type bar[T] = foo[T];\n-fn takebar[T](bar[T] b) {}\n+fn takebar[T](&bar[T] b) {}\n fn main() {}\n\\ No newline at end of file"}, {"sha": "0c0bcdcd041ceb20a638d290818da2f041cf6cb5", "filename": "src/test/run-pass/lib-io.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Flib-io.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Flib-io.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Flib-io.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,7 +1,7 @@\n // -*- rust -*-\n \n use std;\n-import std._io;\n+import std.io;\n import std._str;\n \n fn test_simple(str tmpfilebase) {\n@@ -11,11 +11,11 @@ fn test_simple(str tmpfilebase) {\n   log frood;\n \n   {\n-    let _io.buf_writer out = _io.new_buf_writer(tmpfile, vec(_io.create()));\n+    let io.buf_writer out = io.new_buf_writer(tmpfile, vec(io.create));\n     out.write(_str.bytes(frood));\n   }\n \n-  let _io.buf_reader inp = _io.new_buf_reader(tmpfile);\n+  let io.buf_reader inp = io.new_buf_reader(tmpfile);\n   let str frood2 = _str.from_bytes(inp.read());\n   log frood2;\n   check (_str.eq(frood, frood2));"}, {"sha": "57e3cdc856b6d95b9e1d80d0522495044c7af5e4", "filename": "src/test/run-pass/lib-sha1.rs", "status": "added", "additions": 115, "deletions": 0, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Flib-sha1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Flib-sha1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Flib-sha1.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,115 @@\n+// -*- rust -*-\n+\n+use std;\n+\n+import std.sha1;\n+import std._vec;\n+import std._str;\n+\n+fn main() {\n+\n+    type test = rec(str input, vec[u8] output);\n+\n+    fn a_million_letter_a() -> str {\n+        auto i = 0;\n+        auto res = \"\";\n+        while (i < 100000) {\n+            res += \"aaaaaaaaaa\";\n+            i += 1;\n+        }\n+        ret res;\n+    }\n+\n+    // Test messages from FIPS 180-1\n+    let vec[test] fips_180_1_tests =\n+        vec(\n+            rec(input = \"abc\",\n+                output = vec(0xA9u8, 0x99u8, 0x3Eu8, 0x36u8, 0x47u8,\n+                             0x06u8, 0x81u8, 0x6Au8, 0xBAu8, 0x3Eu8,\n+                             0x25u8, 0x71u8, 0x78u8, 0x50u8, 0xC2u8,\n+                             0x6Cu8, 0x9Cu8, 0xD0u8, 0xD8u8, 0x9Du8)\n+                ),\n+            rec(input = \"abcdbcdecdefdefgefghfghighij\"\n+                      + \"hijkijkljklmklmnlmnomnopnopq\",\n+                output = vec(0x84u8, 0x98u8, 0x3Eu8, 0x44u8, 0x1Cu8,\n+                             0x3Bu8, 0xD2u8, 0x6Eu8, 0xBAu8, 0xAEu8,\n+                             0x4Au8, 0xA1u8, 0xF9u8, 0x51u8, 0x29u8,\n+                             0xE5u8, 0xE5u8, 0x46u8, 0x70u8, 0xF1u8)\n+                )\n+            // FIXME: This test is disabled because it takes some\n+            // minutes to run under rustboot+valgrind. It may be\n+            // possible to reenable once things are more optimized.\n+            /*,\n+            rec(input = a_million_letter_a(),\n+                output = vec(0x34u8, 0xAAu8, 0x97u8, 0x3Cu8, 0xD4u8,\n+                             0xC4u8, 0xDAu8, 0xA4u8, 0xF6u8, 0x1Eu8,\n+                             0xEBu8, 0x2Bu8, 0xDBu8, 0xADu8, 0x27u8,\n+                             0x31u8, 0x65u8, 0x34u8, 0x01u8, 0x6Fu8)\n+                )\n+            */\n+            );\n+\n+    // Examples from wikipedia\n+    let vec[test] wikipedia_tests =\n+        vec(\n+            rec(input = \"The quick brown fox jumps over the lazy dog\",\n+                output = vec(0x2fu8, 0xd4u8, 0xe1u8, 0xc6u8, 0x7au8,\n+                             0x2du8, 0x28u8, 0xfcu8, 0xedu8, 0x84u8,\n+                             0x9eu8, 0xe1u8, 0xbbu8, 0x76u8, 0xe7u8,\n+                             0x39u8, 0x1bu8, 0x93u8, 0xebu8, 0x12u8)\n+                ),\n+            rec(input = \"The quick brown fox jumps over the lazy cog\",\n+                output = vec(0xdeu8, 0x9fu8, 0x2cu8, 0x7fu8, 0xd2u8,\n+                             0x5eu8, 0x1bu8, 0x3au8, 0xfau8, 0xd3u8,\n+                             0xe8u8, 0x5au8, 0x0bu8, 0xd1u8, 0x7du8,\n+                             0x9bu8, 0x10u8, 0x0du8, 0xb4u8, 0xb3u8)\n+                )\n+            );\n+\n+    auto tests = fips_180_1_tests + wikipedia_tests;\n+\n+    fn check_vec_eq(vec[u8] v0, vec[u8] v1) {\n+        check (_vec.len[u8](v0) == _vec.len[u8](v1));\n+        auto len = _vec.len[u8](v0);\n+        auto i = 0u;\n+        while (i < len) {\n+            auto a = v0.(i);\n+            auto b = v1.(i);\n+            check (a == b);\n+            i += 1u;\n+        }\n+    }\n+\n+    // Test that it works when accepting the message all at once\n+    auto sh = sha1.mk_sha1();\n+    for (test t in tests) {\n+        sh.input_str(t.input);\n+        auto out = sh.result();\n+        check_vec_eq(t.output, out);\n+        sh.reset();\n+    }\n+\n+    // Test that it works when accepting the message in pieces\n+    for (test t in tests) {\n+        auto len = _str.byte_len(t.input);\n+        auto left = len;\n+        while (left > 0u) {\n+            auto take = (left + 1u) / 2u;\n+            sh.input_str(_str.substr(t.input, len - left, take));\n+            left = left - take;\n+        }\n+        auto out = sh.result();\n+        check_vec_eq(t.output, out);\n+        sh.reset();\n+    }\n+}\n+\n+\n+// Local Variables:\n+// mode: rust;\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// compile-command: \"make -k -C .. 2>&1 | sed -e 's/\\\\/x\\\\//x:\\\\//g'\";\n+// End:"}, {"sha": "4815345add651c807e6208c5beaac417534aa8e1", "filename": "src/test/run-pass/native2.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fnative2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fnative2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fnative2.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,20 @@\n+native \"rust\" mod rustrt {\n+    type vbuf;\n+    fn vec_buf[T](vec[T] v, uint offset) -> vbuf;\n+}\n+\n+native \"rust\" mod bar = \"foo\" {\n+}\n+\n+native mod zed {\n+}\n+\n+native mod libc = \"libc.dylib\" {\n+    fn write(int fd, rustrt.vbuf buf, uint count) -> int;\n+}\n+\n+native \"cdecl\" mod baz {\n+}\n+\n+fn main(vec[str] args) {\n+}"}, {"sha": "e94d32ebfa839503d6a5c4fbce1cc99da0458439", "filename": "src/test/run-pass/path.rs", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fpath.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fpath.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fpath.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,8 @@\n+mod foo {\n+   fn bar(uint offset) {\n+   }\n+}\n+\n+fn main(vec[str] args) {\n+  foo.bar(0u);\n+}"}, {"sha": "ebb09f96ba2c90930f62bf69b7750bed08e00478", "filename": "src/test/run-pass/syntax-extension-fmt.rs", "status": "modified", "additions": 13, "deletions": 2, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fsyntax-extension-fmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Fsyntax-extension-fmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fsyntax-extension-fmt.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -1,5 +1,16 @@\n use std;\n+import std._str;\n+\n+fn test(str actual, str expected) {\n+  log actual;\n+  log expected;\n+  check (_str.eq(actual, expected));\n+}\n+\n fn main() {\n-  auto s = #fmt(\"hello %d friends and %s things\", 10, \"formatted\");\n-  log s;\n+  test(#fmt(\"hello %d friends and %s things\", 10, \"formatted\"),\n+    \"hello 10 friends and formatted things\");\n+  test(#fmt(\"d: %d\", 1), \"d: 1\");\n+  test(#fmt(\"i: %i\", 2), \"i: 2\");\n+  test(#fmt(\"s: %s\", \"test\"), \"s: test\");\n }"}, {"sha": "8f0506469b1e5cf0f43f9e14efdb39fec58ead20", "filename": "src/test/run-pass/typestate-cfg-nesting.rs", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Ftypestate-cfg-nesting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c/src%2Ftest%2Frun-pass%2Ftypestate-cfg-nesting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Ftypestate-cfg-nesting.rs?ref=9fc4db6b89213afdf45c02fc2bd2be62b0ddc40c", "patch": "@@ -0,0 +1,26 @@\n+\n+fn f() {\n+\n+  auto x = 10;\n+  auto y = 11;\n+  if (true) {\n+    alt (x) {\n+      case (_) {\n+        y = x;\n+      }\n+    }\n+  } else {\n+  }\n+}\n+\n+fn main() {\n+\n+  auto x = 10;\n+  auto y = 11;\n+  if (true) {\n+    while (false) {\n+        y = x;\n+    }\n+  } else {\n+  }\n+}"}]}