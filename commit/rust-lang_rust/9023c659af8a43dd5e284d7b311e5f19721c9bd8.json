{"sha": "9023c659af8a43dd5e284d7b311e5f19721c9bd8", "node_id": "MDY6Q29tbWl0NzI0NzEyOjkwMjNjNjU5YWY4YTQzZGQ1ZTI4NGQ3YjMxMWU1ZjE5NzIxYzliZDg=", "commit": {"author": {"name": "Nick Cameron", "email": "ncameron@mozilla.com", "date": "2015-12-30T23:11:53Z"}, "committer": {"name": "Nick Cameron", "email": "ncameron@mozilla.com", "date": "2015-12-31T01:29:02Z"}, "message": "Cut out a bunch of Result and panictry! boilerplate from libsyntax.\n\n[breaking-change] if you use any of the changed functions, you'll need to remove a try! or panictry!", "tree": {"sha": "2f119e231c3f141514dcf59cf3c5d3b91d952a33", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2f119e231c3f141514dcf59cf3c5d3b91d952a33"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/9023c659af8a43dd5e284d7b311e5f19721c9bd8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/9023c659af8a43dd5e284d7b311e5f19721c9bd8", "html_url": "https://github.com/rust-lang/rust/commit/9023c659af8a43dd5e284d7b311e5f19721c9bd8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/9023c659af8a43dd5e284d7b311e5f19721c9bd8/comments", "author": {"login": "nrc", "id": 762626, "node_id": "MDQ6VXNlcjc2MjYyNg==", "avatar_url": "https://avatars.githubusercontent.com/u/762626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nrc", "html_url": "https://github.com/nrc", "followers_url": "https://api.github.com/users/nrc/followers", "following_url": "https://api.github.com/users/nrc/following{/other_user}", "gists_url": "https://api.github.com/users/nrc/gists{/gist_id}", "starred_url": "https://api.github.com/users/nrc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nrc/subscriptions", "organizations_url": "https://api.github.com/users/nrc/orgs", "repos_url": "https://api.github.com/users/nrc/repos", "events_url": "https://api.github.com/users/nrc/events{/privacy}", "received_events_url": "https://api.github.com/users/nrc/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nrc", "id": 762626, "node_id": "MDQ6VXNlcjc2MjYyNg==", "avatar_url": "https://avatars.githubusercontent.com/u/762626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nrc", "html_url": "https://github.com/nrc", "followers_url": "https://api.github.com/users/nrc/followers", "following_url": "https://api.github.com/users/nrc/following{/other_user}", "gists_url": "https://api.github.com/users/nrc/gists{/gist_id}", "starred_url": "https://api.github.com/users/nrc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nrc/subscriptions", "organizations_url": "https://api.github.com/users/nrc/orgs", "repos_url": "https://api.github.com/users/nrc/repos", "events_url": "https://api.github.com/users/nrc/events{/privacy}", "received_events_url": "https://api.github.com/users/nrc/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "efb5a9a9f03016b8d3d3c13f940bbbfeac2cdfa6", "url": "https://api.github.com/repos/rust-lang/rust/commits/efb5a9a9f03016b8d3d3c13f940bbbfeac2cdfa6", "html_url": "https://github.com/rust-lang/rust/commit/efb5a9a9f03016b8d3d3c13f940bbbfeac2cdfa6"}], "stats": {"total": 631, "additions": 318, "deletions": 313}, "files": [{"sha": "107626c54cc9da82749d5d4b18c28478c14e511f", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -826,7 +826,7 @@ pub fn get_exprs_from_tts(cx: &mut ExtCtxt,\n     let mut es = Vec::new();\n     while p.token != token::Eof {\n         es.push(cx.expander().fold_expr(panictry!(p.parse_expr())));\n-        if panictry!(p.eat(&token::Comma)){\n+        if p.eat(&token::Comma) {\n             continue;\n         }\n         if p.token != token::Eof {"}, {"sha": "bc7dc67e1bae5d68e7d2eb56143f664ddb3998eb", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -801,7 +801,7 @@ fn parse_arguments_to_quote(cx: &ExtCtxt, tts: &[TokenTree])\n     p.quote_depth += 1;\n \n     let cx_expr = panictry!(p.parse_expr());\n-    if !panictry!(p.eat(&token::Comma)) {\n+    if !p.eat(&token::Comma) {\n         let _ = p.diagnostic().fatal(\"expected token `,`\");\n     }\n "}, {"sha": "ae8ab0541050c0be5b251f4a1fda0e77de690876", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -512,7 +512,7 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         _ => {}\n     }\n     // check at the beginning and the parser checks after each bump\n-    panictry!(p.check_unknown_macro_variable());\n+    p.check_unknown_macro_variable();\n     match name {\n         \"item\" => match panictry!(p.parse_item()) {\n             Some(i) => token::NtItem(i),\n@@ -535,7 +535,7 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         // this could be handled like a token, since it is one\n         \"ident\" => match p.token {\n             token::Ident(sn,b) => {\n-                panictry!(p.bump());\n+                p.bump();\n                 token::NtIdent(Box::new(Spanned::<Ident>{node: sn, span: p.span}),b)\n             }\n             _ => {"}, {"sha": "4f21b3f44365134309cb829b657c496f86bad75c", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -47,7 +47,7 @@ impl<'a> ParserAnyMacro<'a> {\n     fn ensure_complete_parse(&self, allow_semi: bool, context: &str) {\n         let mut parser = self.parser.borrow_mut();\n         if allow_semi && parser.token == token::Semi {\n-            panictry!(parser.bump())\n+            parser.bump();\n         }\n         if parser.token != token::Eof {\n             let token_str = parser.this_token_to_string();\n@@ -194,7 +194,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                                            imported_from,\n                                            rhs);\n                 let mut p = Parser::new(cx.parse_sess(), cx.cfg(), Box::new(trncbr));\n-                panictry!(p.check_unknown_macro_variable());\n+                p.check_unknown_macro_variable();\n                 // Let the context choose how to interpret the result.\n                 // Weird, but useful for X-macros.\n                 return Box::new(ParserAnyMacro {"}, {"sha": "cad9b45694b28b5bc4d144682fa1e8fd35a63b3f", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -39,7 +39,7 @@ impl<'a> Parser<'a> {\n                   return Err(self.fatal(\"expected outer comment\"));\n                 }\n                 attrs.push(attr);\n-                try!(self.bump());\n+                self.bump();\n               }\n               _ => break\n             }\n@@ -57,11 +57,11 @@ impl<'a> Parser<'a> {\n         let (span, value, mut style) = match self.token {\n             token::Pound => {\n                 let lo = self.span.lo;\n-                try!(self.bump());\n+                self.bump();\n \n                 if permit_inner { self.expected_tokens.push(TokenType::Token(token::Not)); }\n                 let style = if self.token == token::Not {\n-                    try!(self.bump());\n+                    self.bump();\n                     if !permit_inner {\n                         let span = self.span;\n                         self.diagnostic().struct_span_err(span,\n@@ -91,7 +91,7 @@ impl<'a> Parser<'a> {\n         };\n \n         if permit_inner && self.token == token::Semi {\n-            try!(self.bump());\n+            self.bump();\n             self.span_warn(span, \"this inner attribute syntax is deprecated. \\\n                            The new syntax is `#![foo]`, with a bang and no semicolon\");\n             style = ast::AttrStyle::Inner;\n@@ -134,7 +134,7 @@ impl<'a> Parser<'a> {\n                     let attr = attr::mk_sugared_doc_attr(attr::mk_attr_id(), str, lo, hi);\n                     if attr.node.style == ast::AttrStyle::Inner {\n                         attrs.push(attr);\n-                        try!(self.bump());\n+                        self.bump();\n                     } else {\n                         break;\n                     }\n@@ -158,7 +158,7 @@ impl<'a> Parser<'a> {\n \n         match nt_meta {\n             Some(meta) => {\n-                try!(self.bump());\n+                self.bump();\n                 return Ok(meta);\n             }\n             None => {}\n@@ -169,7 +169,7 @@ impl<'a> Parser<'a> {\n         let name = self.id_to_interned_str(ident);\n         match self.token {\n             token::Eq => {\n-                try!(self.bump());\n+                self.bump();\n                 let lit = try!(self.parse_lit());\n                 // FIXME #623 Non-string meta items are not serialized correctly;\n                 // just forbid them for now"}, {"sha": "a122456550116c3135c13b5f35a900eee837fd7c", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -261,7 +261,7 @@ pub fn tts_to_parser<'a>(sess: &'a ParseSess,\n                          cfg: ast::CrateConfig) -> Parser<'a> {\n     let trdr = lexer::new_tt_reader(&sess.span_diagnostic, None, None, tts);\n     let mut p = Parser::new(sess, cfg, Box::new(trdr));\n-    panictry!(p.check_unknown_macro_variable());\n+    p.check_unknown_macro_variable();\n     p\n }\n "}, {"sha": "3d6f232411aa74ee5d54534e8a7298a5e150ceda", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 292, "deletions": 287, "changes": 579, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -155,7 +155,7 @@ macro_rules! maybe_whole_expr {\n             };\n             match found {\n                 Some(e) => {\n-                    try!($p.bump());\n+                    $p.bump();\n                     return Ok(e);\n                 }\n                 None => ()\n@@ -170,7 +170,7 @@ macro_rules! maybe_whole {\n         {\n             let found = match ($p).token {\n                 token::Interpolated(token::$constructor(_)) => {\n-                    Some(try!(($p).bump_and_get()))\n+                    Some(($p).bump_and_get())\n                 }\n                 _ => None\n             };\n@@ -183,7 +183,7 @@ macro_rules! maybe_whole {\n         {\n             let found = match ($p).token {\n                 token::Interpolated(token::$constructor(_)) => {\n-                    Some(try!(($p).bump_and_get()))\n+                    Some(($p).bump_and_get())\n                 }\n                 _ => None\n             };\n@@ -196,7 +196,7 @@ macro_rules! maybe_whole {\n         {\n             let found = match ($p).token {\n                 token::Interpolated(token::$constructor(_)) => {\n-                    Some(try!(($p).bump_and_get()))\n+                    Some(($p).bump_and_get())\n                 }\n                 _ => None\n             };\n@@ -209,7 +209,7 @@ macro_rules! maybe_whole {\n         {\n             let found = match ($p).token {\n                 token::Interpolated(token::$constructor(_)) => {\n-                    Some(try!(($p).bump_and_get()))\n+                    Some(($p).bump_and_get())\n                 }\n                 _ => None\n             };\n@@ -222,7 +222,7 @@ macro_rules! maybe_whole {\n         {\n             let found = match ($p).token {\n                 token::Interpolated(token::$constructor(_)) => {\n-                    Some(try!(($p).bump_and_get()))\n+                    Some(($p).bump_and_get())\n                 }\n                 _ => None\n             };\n@@ -392,17 +392,16 @@ impl<'a> Parser<'a> {\n         Parser::token_to_string(&self.token)\n     }\n \n-    pub fn unexpected_last(&self, t: &token::Token) -> DiagnosticBuilder<'a> {\n+    pub fn unexpected_last<T>(&self, t: &token::Token) -> PResult<'a, T> {\n         let token_str = Parser::token_to_string(t);\n         let last_span = self.last_span;\n-        self.span_fatal(last_span, &format!(\"unexpected token: `{}`\",\n-                                                token_str))\n+        Err(self.span_fatal(last_span, &format!(\"unexpected token: `{}`\", token_str)))\n     }\n \n-    pub fn unexpected(&mut self) -> DiagnosticBuilder<'a> {\n+    pub fn unexpected<T>(&mut self) -> PResult<'a, T> {\n         match self.expect_one_of(&[], &[]) {\n-            Err(e) => e,\n-            Ok(_) => unreachable!()\n+            Err(e) => Err(e),\n+            Ok(_) => unreachable!(),\n         }\n     }\n \n@@ -411,7 +410,8 @@ impl<'a> Parser<'a> {\n     pub fn expect(&mut self, t: &token::Token) -> PResult<'a,  ()> {\n         if self.expected_tokens.is_empty() {\n             if self.token == *t {\n-                self.bump()\n+                self.bump();\n+                Ok(())\n             } else {\n                 let token_str = Parser::token_to_string(t);\n                 let this_token_str = self.this_token_to_string();\n@@ -448,7 +448,8 @@ impl<'a> Parser<'a> {\n             })\n         }\n         if edible.contains(&self.token) {\n-            self.bump()\n+            self.bump();\n+            Ok(())\n         } else if inedible.contains(&self.token) {\n             // leave it in the input\n             Ok(())\n@@ -484,19 +485,18 @@ impl<'a> Parser<'a> {\n     /// true if and only if input was consumed for recovery.\n     pub fn check_for_erroneous_unit_struct_expecting(&mut self,\n                                                      expected: &[token::Token])\n-                                                     -> PResult<'a, bool> {\n+                                                     -> bool {\n         if self.token == token::OpenDelim(token::Brace)\n             && expected.iter().all(|t| *t != token::OpenDelim(token::Brace))\n             && self.look_ahead(1, |t| *t == token::CloseDelim(token::Brace)) {\n             // matched; signal non-fatal error and recover.\n             let span = self.span;\n-            self.span_err(span,\n-                          \"unit-like struct construction is written with no trailing `{ }`\");\n-            try!(self.eat(&token::OpenDelim(token::Brace)));\n-            try!(self.eat(&token::CloseDelim(token::Brace)));\n-            Ok(true)\n+            self.span_err(span, \"unit-like struct construction is written with no trailing `{ }`\");\n+            self.eat(&token::OpenDelim(token::Brace));\n+            self.eat(&token::CloseDelim(token::Brace));\n+            true\n         } else {\n-            Ok(false)\n+            false\n         }\n     }\n \n@@ -512,7 +512,7 @@ impl<'a> Parser<'a> {\n                 .cloned()\n                 .chain(inedible.iter().cloned())\n                 .collect::<Vec<_>>();\n-            try!(self.check_for_erroneous_unit_struct_expecting(&expected[..]));\n+            self.check_for_erroneous_unit_struct_expecting(&expected[..]);\n         }\n         self.expect_one_of(edible, inedible)\n     }\n@@ -533,7 +533,7 @@ impl<'a> Parser<'a> {\n                 .cloned()\n                 .chain(inedible.iter().cloned())\n                 .collect::<Vec<_>>();\n-            try!(self.check_for_erroneous_unit_struct_expecting(&expected));\n+            self.check_for_erroneous_unit_struct_expecting(&expected);\n         }\n         self.expect_one_of(edible, inedible)\n     }\n@@ -544,10 +544,10 @@ impl<'a> Parser<'a> {\n \n     pub fn parse_ident(&mut self) -> PResult<'a, ast::Ident> {\n         self.check_strict_keywords();\n-        try!(self.check_reserved_keywords());\n+        self.check_reserved_keywords();\n         match self.token {\n             token::Ident(i, _) => {\n-                try!(self.bump());\n+                self.bump();\n                 Ok(i)\n             }\n             token::Interpolated(token::NtIdent(..)) => {\n@@ -571,7 +571,7 @@ impl<'a> Parser<'a> {\n \n     pub fn parse_path_list_item(&mut self) -> PResult<'a, ast::PathListItem> {\n         let lo = self.span.lo;\n-        let node = if try!(self.eat_keyword(keywords::SelfValue)) {\n+        let node = if self.eat_keyword(keywords::SelfValue) {\n             let rename = try!(self.parse_rename());\n             ast::PathListMod { id: ast::DUMMY_NODE_ID, rename: rename }\n         } else {\n@@ -595,10 +595,10 @@ impl<'a> Parser<'a> {\n \n     /// Consume token 'tok' if it exists. Returns true if the given\n     /// token was present, false otherwise.\n-    pub fn eat(&mut self, tok: &token::Token) -> PResult<'a, bool> {\n+    pub fn eat(&mut self, tok: &token::Token) -> bool {\n         let is_present = self.check(tok);\n-        if is_present { try!(self.bump())}\n-        Ok(is_present)\n+        if is_present { self.bump() }\n+        is_present\n     }\n \n     pub fn check_keyword(&mut self, kw: keywords::Keyword) -> bool {\n@@ -608,30 +608,30 @@ impl<'a> Parser<'a> {\n \n     /// If the next token is the given keyword, eat it and return\n     /// true. Otherwise, return false.\n-    pub fn eat_keyword(&mut self, kw: keywords::Keyword) -> PResult<'a, bool> {\n+    pub fn eat_keyword(&mut self, kw: keywords::Keyword) -> bool {\n         if self.check_keyword(kw) {\n-            try!(self.bump());\n-            Ok(true)\n+            self.bump();\n+            true\n         } else {\n-            Ok(false)\n+            false\n         }\n     }\n \n-    pub fn eat_keyword_noexpect(&mut self, kw: keywords::Keyword) -> PResult<'a, bool> {\n+    pub fn eat_keyword_noexpect(&mut self, kw: keywords::Keyword) -> bool {\n         if self.token.is_keyword(kw) {\n-            try!(self.bump());\n-            Ok(true)\n+            self.bump();\n+            true\n         } else {\n-            Ok(false)\n+            false\n         }\n     }\n \n     /// If the given word is not a keyword, signal an error.\n     /// If the next token is not the given word, signal an error.\n     /// Otherwise, eat it.\n     pub fn expect_keyword(&mut self, kw: keywords::Keyword) -> PResult<'a, ()> {\n-        if !try!(self.eat_keyword(kw) ){\n-            self.expect_one_of(&[], &[])\n+        if !self.eat_keyword(kw) {\n+            self.unexpected()\n         } else {\n             Ok(())\n         }\n@@ -649,12 +649,10 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Signal an error if the current token is a reserved keyword\n-    pub fn check_reserved_keywords(&mut self) -> PResult<'a, ()>{\n+    pub fn check_reserved_keywords(&mut self) {\n         if self.token.is_reserved_keyword() {\n             let token_str = self.this_token_to_string();\n-            Err(self.fatal(&format!(\"`{}` is a reserved keyword\", token_str)))\n-        } else {\n-            Ok(())\n+            self.fatal(&format!(\"`{}` is a reserved keyword\", token_str)).emit()\n         }\n     }\n \n@@ -663,13 +661,16 @@ impl<'a> Parser<'a> {\n     fn expect_and(&mut self) -> PResult<'a, ()> {\n         self.expected_tokens.push(TokenType::Token(token::BinOp(token::And)));\n         match self.token {\n-            token::BinOp(token::And) => self.bump(),\n+            token::BinOp(token::And) => {\n+                self.bump();\n+                Ok(())\n+            }\n             token::AndAnd => {\n                 let span = self.span;\n                 let lo = span.lo + BytePos(1);\n                 Ok(self.replace_token(token::BinOp(token::And), lo, span.hi))\n             }\n-            _ => self.expect_one_of(&[], &[])\n+            _ => self.unexpected()\n         }\n     }\n \n@@ -692,23 +693,26 @@ impl<'a> Parser<'a> {\n     ///\n     /// This is meant to be used when parsing generics on a path to get the\n     /// starting token.\n-    fn eat_lt(&mut self) -> PResult<'a, bool> {\n+    fn eat_lt(&mut self) -> bool {\n         self.expected_tokens.push(TokenType::Token(token::Lt));\n         match self.token {\n-            token::Lt => { try!(self.bump()); Ok(true)}\n+            token::Lt => {\n+                self.bump();\n+                true\n+            }\n             token::BinOp(token::Shl) => {\n                 let span = self.span;\n                 let lo = span.lo + BytePos(1);\n                 self.replace_token(token::Lt, lo, span.hi);\n-                Ok(true)\n+                true\n             }\n-            _ => Ok(false),\n+            _ => false,\n         }\n     }\n \n     fn expect_lt(&mut self) -> PResult<'a, ()> {\n-        if !try!(self.eat_lt()) {\n-            self.expect_one_of(&[], &[])\n+        if !self.eat_lt() {\n+            self.unexpected()\n         } else {\n             Ok(())\n         }\n@@ -720,7 +724,10 @@ impl<'a> Parser<'a> {\n     pub fn expect_gt(&mut self) -> PResult<'a, ()> {\n         self.expected_tokens.push(TokenType::Token(token::Gt));\n         match self.token {\n-            token::Gt => self.bump(),\n+            token::Gt => {\n+                self.bump();\n+                Ok(())\n+            }\n             token::BinOp(token::Shr) => {\n                 let span = self.span;\n                 let lo = span.lo + BytePos(1);\n@@ -831,7 +838,7 @@ impl<'a> Parser<'a> {\n         F: FnMut(&mut Parser<'a>) -> PResult<'a,  T>,\n     {\n         let val = try!(self.parse_seq_to_before_end(ket, sep, f));\n-        try!(self.bump());\n+        self.bump();\n         Ok(val)\n     }\n \n@@ -874,7 +881,7 @@ impl<'a> Parser<'a> {\n     {\n         try!(self.expect(bra));\n         let result = try!(self.parse_seq_to_before_end(ket, sep, f));\n-        try!(self.bump());\n+        self.bump();\n         Ok(result)\n     }\n \n@@ -911,12 +918,12 @@ impl<'a> Parser<'a> {\n         try!(self.expect(bra));\n         let result = try!(self.parse_seq_to_before_end(ket, sep, f));\n         let hi = self.span.hi;\n-        try!(self.bump());\n+        self.bump();\n         Ok(spanned(lo, hi, result))\n     }\n \n     /// Advance the parser by one token\n-    pub fn bump(&mut self) -> PResult<'a,  ()> {\n+    pub fn bump(&mut self) {\n         self.last_span = self.span;\n         // Stash token for error recovery (sometimes; clone is not necessarily cheap).\n         self.last_token = if self.token.is_ident() ||\n@@ -945,14 +952,14 @@ impl<'a> Parser<'a> {\n         self.tokens_consumed += 1;\n         self.expected_tokens.clear();\n         // check after each token\n-        self.check_unknown_macro_variable()\n+        self.check_unknown_macro_variable();\n     }\n \n     /// Advance the parser by one token and return the bumped token.\n-    pub fn bump_and_get(&mut self) -> PResult<'a, token::Token> {\n+    pub fn bump_and_get(&mut self) -> token::Token {\n         let old_token = mem::replace(&mut self.token, token::Underscore);\n-        try!(self.bump());\n-        Ok(old_token)\n+        self.bump();\n+        old_token\n     }\n \n     /// EFFECT: replace the current token and span with the given one\n@@ -1063,7 +1070,7 @@ impl<'a> Parser<'a> {\n             let poly_trait_ref = ast::PolyTraitRef { bound_lifetimes: lifetime_defs,\n                                                      trait_ref: trait_ref,\n                                                      span: mk_sp(lo, hi)};\n-            let other_bounds = if try!(self.eat(&token::BinOp(token::Plus)) ){\n+            let other_bounds = if self.eat(&token::BinOp(token::Plus)) {\n                 try!(self.parse_ty_param_bounds(BoundParsingMode::Bare))\n             } else {\n                 P::empty()\n@@ -1095,7 +1102,7 @@ impl<'a> Parser<'a> {\n         */\n \n         let unsafety = try!(self.parse_unsafety());\n-        let abi = if try!(self.eat_keyword(keywords::Extern) ){\n+        let abi = if self.eat_keyword(keywords::Extern) {\n             try!(self.parse_opt_abi()).unwrap_or(abi::C)\n         } else {\n             abi::Rust\n@@ -1125,17 +1132,17 @@ impl<'a> Parser<'a> {\n             self.look_ahead(1, |t| t.is_keyword(keywords::Mut)) &&\n             self.look_ahead(2, |t| *t == token::Colon)\n         {\n-            try!(self.bump());\n-            try!(self.bump());\n-            try!(self.bump());\n+            self.bump();\n+            self.bump();\n+            self.bump();\n         } else if\n             self.token == token::BinOp(token::And) &&\n             self.look_ahead(1, |t| *t == token::Colon)\n         {\n-            try!(self.bump());\n-            try!(self.bump());\n+            self.bump();\n+            self.bump();\n         } else if\n-            try!(self.eat(&token::Colon))\n+            self.eat(&token::Colon)\n         {\n             /* nothing */\n         } else {\n@@ -1148,7 +1155,7 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_unsafety(&mut self) -> PResult<'a, Unsafety> {\n-        if try!(self.eat_keyword(keywords::Unsafe)) {\n+        if self.eat_keyword(keywords::Unsafe) {\n             return Ok(Unsafety::Unsafe);\n         } else {\n             return Ok(Unsafety::Normal);\n@@ -1166,7 +1173,7 @@ impl<'a> Parser<'a> {\n             let mut attrs = try!(p.parse_outer_attributes());\n             let lo = p.span.lo;\n \n-            let (name, node) = if try!(p.eat_keyword(keywords::Type)) {\n+            let (name, node) = if p.eat_keyword(keywords::Type) {\n                 let TyParam {ident, bounds, default, ..} = try!(p.parse_ty_param());\n                 try!(p.expect(&token::Semi));\n                 (ident, TypeTraitItem(bounds, default))\n@@ -1176,7 +1183,7 @@ impl<'a> Parser<'a> {\n                 try!(p.expect(&token::Colon));\n                 let ty = try!(p.parse_ty_sum());\n                 let default = if p.check(&token::Eq) {\n-                    try!(p.bump());\n+                    p.bump();\n                     let expr = try!(p.parse_expr());\n                     try!(p.commit_expr_expecting(&expr, token::Semi));\n                     Some(expr)\n@@ -1210,7 +1217,7 @@ impl<'a> Parser<'a> {\n \n                 let body = match p.token {\n                   token::Semi => {\n-                    try!(p.bump());\n+                    p.bump();\n                     debug!(\"parse_trait_methods(): parsing required method\");\n                     None\n                   }\n@@ -1250,8 +1257,8 @@ impl<'a> Parser<'a> {\n \n     /// Parse optional return type [ -> TY ] in function decl\n     pub fn parse_ret_ty(&mut self) -> PResult<'a, FunctionRetTy> {\n-        if try!(self.eat(&token::RArrow) ){\n-            if try!(self.eat(&token::Not) ){\n+        if self.eat(&token::RArrow) {\n+            if self.eat(&token::Not) {\n                 Ok(NoReturn(self.last_span))\n             } else {\n                 Ok(Return(try!(self.parse_ty())))\n@@ -1267,7 +1274,7 @@ impl<'a> Parser<'a> {\n         let lo = self.span.lo;\n         let lhs = try!(self.parse_ty());\n \n-        if !try!(self.eat(&token::BinOp(token::Plus)) ){\n+        if !self.eat(&token::BinOp(token::Plus)) {\n             return Ok(lhs);\n         }\n \n@@ -1294,7 +1301,7 @@ impl<'a> Parser<'a> {\n         let lo = self.span.lo;\n \n         let t = if self.check(&token::OpenDelim(token::Paren)) {\n-            try!(self.bump());\n+            self.bump();\n \n             // (t) is a parenthesized ty\n             // (t,) is the type of a tuple with only one field,\n@@ -1305,7 +1312,7 @@ impl<'a> Parser<'a> {\n                 ts.push(try!(self.parse_ty_sum()));\n                 if self.check(&token::Comma) {\n                     last_comma = true;\n-                    try!(self.bump());\n+                    self.bump();\n                 } else {\n                     last_comma = false;\n                     break;\n@@ -1320,7 +1327,7 @@ impl<'a> Parser<'a> {\n             }\n         } else if self.check(&token::BinOp(token::Star)) {\n             // STAR POINTER (bare pointer?)\n-            try!(self.bump());\n+            self.bump();\n             TyPtr(try!(self.parse_ptr()))\n         } else if self.check(&token::OpenDelim(token::Bracket)) {\n             // VECTOR\n@@ -1345,14 +1352,14 @@ impl<'a> Parser<'a> {\n         } else if self.token_is_bare_fn_keyword() {\n             // BARE FUNCTION\n             try!(self.parse_ty_bare_fn(Vec::new()))\n-        } else if try!(self.eat_keyword_noexpect(keywords::Typeof)) {\n+        } else if self.eat_keyword_noexpect(keywords::Typeof) {\n             // TYPEOF\n             // In order to not be ambiguous, the type must be surrounded by parens.\n             try!(self.expect(&token::OpenDelim(token::Paren)));\n             let e = try!(self.parse_expr());\n             try!(self.expect(&token::CloseDelim(token::Paren)));\n             TyTypeof(e)\n-        } else if try!(self.eat_lt()) {\n+        } else if self.eat_lt() {\n \n             let (qself, path) =\n                  try!(self.parse_qualified_path(NoTypesAllowed));\n@@ -1364,7 +1371,7 @@ impl<'a> Parser<'a> {\n             let path = try!(self.parse_path(LifetimeAndTypesWithoutColons));\n             if self.check(&token::Not) {\n                 // MACRO INVOCATION\n-                try!(self.bump());\n+                self.bump();\n                 let delim = try!(self.expect_open_delim());\n                 let tts = try!(self.parse_seq_to_end(&token::CloseDelim(delim),\n                                                      seq_sep_none(),\n@@ -1375,7 +1382,7 @@ impl<'a> Parser<'a> {\n                 // NAMED TYPE\n                 TyPath(None, path)\n             }\n-        } else if try!(self.eat(&token::Underscore) ){\n+        } else if self.eat(&token::Underscore) {\n             // TYPE TO BE INFERRED\n             TyInfer\n         } else {\n@@ -1397,9 +1404,9 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_ptr(&mut self) -> PResult<'a, MutTy> {\n-        let mutbl = if try!(self.eat_keyword(keywords::Mut) ){\n+        let mutbl = if self.eat_keyword(keywords::Mut) {\n             MutMutable\n-        } else if try!(self.eat_keyword(keywords::Const) ){\n+        } else if self.eat_keyword(keywords::Const) {\n             MutImmutable\n         } else {\n             let span = self.last_span;\n@@ -1468,7 +1475,7 @@ impl<'a> Parser<'a> {\n     /// Parse an argument in a lambda header e.g. |arg, arg|\n     pub fn parse_fn_block_arg(&mut self) -> PResult<'a, Arg> {\n         let pat = try!(self.parse_pat());\n-        let t = if try!(self.eat(&token::Colon) ){\n+        let t = if self.eat(&token::Colon) {\n             try!(self.parse_ty_sum())\n         } else {\n             P(Ty {\n@@ -1486,7 +1493,7 @@ impl<'a> Parser<'a> {\n \n     pub fn maybe_parse_fixed_length_of_vec(&mut self) -> PResult<'a, Option<P<ast::Expr>>> {\n         if self.check(&token::Semi) {\n-            try!(self.bump());\n+            self.bump();\n             Ok(Some(try!(self.parse_expr())))\n         } else {\n             Ok(None)\n@@ -1499,7 +1506,7 @@ impl<'a> Parser<'a> {\n             token::Interpolated(token::NtExpr(ref v)) => {\n                 match v.node {\n                     ExprLit(ref lit) => { Ok(lit.node.clone()) }\n-                    _ => { return Err(self.unexpected_last(tok)); }\n+                    _ => { return self.unexpected_last(tok); }\n                 }\n             }\n             token::Literal(lit, suf) => {\n@@ -1548,19 +1555,19 @@ impl<'a> Parser<'a> {\n \n                 Ok(out)\n             }\n-            _ => { return Err(self.unexpected_last(tok)); }\n+            _ => { return self.unexpected_last(tok); }\n         }\n     }\n \n     /// Matches lit = true | false | token_lit\n     pub fn parse_lit(&mut self) -> PResult<'a, Lit> {\n         let lo = self.span.lo;\n-        let lit = if try!(self.eat_keyword(keywords::True) ){\n+        let lit = if self.eat_keyword(keywords::True) {\n             LitBool(true)\n-        } else if try!(self.eat_keyword(keywords::False) ){\n+        } else if self.eat_keyword(keywords::False) {\n             LitBool(false)\n         } else {\n-            let token = try!(self.bump_and_get());\n+            let token = self.bump_and_get();\n             let lit = try!(self.lit_from_token(&token));\n             lit\n         };\n@@ -1570,7 +1577,7 @@ impl<'a> Parser<'a> {\n     /// matches '-' lit | lit\n     pub fn parse_pat_literal_maybe_minus(&mut self) -> PResult<'a, P<Expr>> {\n         let minus_lo = self.span.lo;\n-        let minus_present = try!(self.eat(&token::BinOp(token::Minus)));\n+        let minus_present = self.eat(&token::BinOp(token::Minus));\n         let lo = self.span.lo;\n         let literal = P(try!(self.parse_lit()));\n         let hi = self.last_span.hi;\n@@ -1604,7 +1611,7 @@ impl<'a> Parser<'a> {\n                                 -> PResult<'a, (QSelf, ast::Path)> {\n         let span = self.last_span;\n         let self_type = try!(self.parse_ty_sum());\n-        let mut path = if try!(self.eat_keyword(keywords::As)) {\n+        let mut path = if self.eat_keyword(keywords::As) {\n             try!(self.parse_path(LifetimeAndTypesWithoutColons))\n         } else {\n             ast::Path {\n@@ -1647,15 +1654,15 @@ impl<'a> Parser<'a> {\n     pub fn parse_path(&mut self, mode: PathParsingMode) -> PResult<'a, ast::Path> {\n         // Check for a whole path...\n         let found = match self.token {\n-            token::Interpolated(token::NtPath(_)) => Some(try!(self.bump_and_get())),\n+            token::Interpolated(token::NtPath(_)) => Some(self.bump_and_get()),\n             _ => None,\n         };\n         if let Some(token::Interpolated(token::NtPath(path))) = found {\n             return Ok(*path);\n         }\n \n         let lo = self.span.lo;\n-        let is_global = try!(self.eat(&token::ModSep));\n+        let is_global = self.eat(&token::ModSep);\n \n         // Parse any number of segments and bound sets. A segment is an\n         // identifier followed by an optional lifetime and a set of types.\n@@ -1694,23 +1701,23 @@ impl<'a> Parser<'a> {\n             let identifier = try!(self.parse_ident_or_self_type());\n \n             // Parse types, optionally.\n-            let parameters = if try!(self.eat_lt() ){\n+            let parameters = if self.eat_lt() {\n                 let (lifetimes, types, bindings) = try!(self.parse_generic_values_after_lt());\n \n                 ast::PathParameters::AngleBracketed(ast::AngleBracketedParameterData {\n                     lifetimes: lifetimes,\n                     types: P::from_vec(types),\n                     bindings: P::from_vec(bindings),\n                 })\n-            } else if try!(self.eat(&token::OpenDelim(token::Paren)) ){\n+            } else if self.eat(&token::OpenDelim(token::Paren)) {\n                 let lo = self.last_span.lo;\n \n                 let inputs = try!(self.parse_seq_to_end(\n                     &token::CloseDelim(token::Paren),\n                     seq_sep_trailing_allowed(token::Comma),\n                     |p| p.parse_ty_sum()));\n \n-                let output_ty = if try!(self.eat(&token::RArrow) ){\n+                let output_ty = if self.eat(&token::RArrow) {\n                     Some(try!(self.parse_ty()))\n                 } else {\n                     None\n@@ -1732,7 +1739,7 @@ impl<'a> Parser<'a> {\n                                              parameters: parameters });\n \n             // Continue only if we see a `::`\n-            if !try!(self.eat(&token::ModSep) ){\n+            if !self.eat(&token::ModSep) {\n                 return Ok(segments);\n             }\n         }\n@@ -1747,7 +1754,7 @@ impl<'a> Parser<'a> {\n             let identifier = try!(self.parse_ident_or_self_type());\n \n             // If we do not see a `::`, stop.\n-            if !try!(self.eat(&token::ModSep) ){\n+            if !self.eat(&token::ModSep) {\n                 segments.push(ast::PathSegment {\n                     identifier: identifier,\n                     parameters: ast::PathParameters::none()\n@@ -1756,7 +1763,7 @@ impl<'a> Parser<'a> {\n             }\n \n             // Check for a type segment.\n-            if try!(self.eat_lt() ){\n+            if self.eat_lt() {\n                 // Consumed `a::b::<`, go look for types\n                 let (lifetimes, types, bindings) = try!(self.parse_generic_values_after_lt());\n                 let parameters = ast::AngleBracketedParameterData {\n@@ -1770,7 +1777,7 @@ impl<'a> Parser<'a> {\n                 });\n \n                 // Consumed `a::b::<T,U>`, check for `::` before proceeding\n-                if !try!(self.eat(&token::ModSep) ){\n+                if !self.eat(&token::ModSep) {\n                     return Ok(segments);\n                 }\n             } else {\n@@ -1799,7 +1806,7 @@ impl<'a> Parser<'a> {\n             });\n \n             // If we do not see a `::`, stop.\n-            if !try!(self.eat(&token::ModSep) ){\n+            if !self.eat(&token::ModSep) {\n                 return Ok(segments);\n             }\n         }\n@@ -1823,7 +1830,7 @@ impl<'a> Parser<'a> {\n         match self.token {\n             token::Lifetime(i) => {\n                 let span = self.span;\n-                try!(self.bump());\n+                self.bump();\n                 return Ok(ast::Lifetime {\n                     id: ast::DUMMY_NODE_ID,\n                     span: span,\n@@ -1846,7 +1853,7 @@ impl<'a> Parser<'a> {\n                 token::Lifetime(_) => {\n                     let lifetime = try!(self.parse_lifetime());\n                     let bounds =\n-                        if try!(self.eat(&token::Colon) ){\n+                        if self.eat(&token::Colon) {\n                             try!(self.parse_lifetimes(token::BinOp(token::Plus)))\n                         } else {\n                             Vec::new()\n@@ -1861,7 +1868,7 @@ impl<'a> Parser<'a> {\n             }\n \n             match self.token {\n-                token::Comma => { try!(self.bump());}\n+                token::Comma => { self.bump();}\n                 token::Gt => { return Ok(res); }\n                 token::BinOp(token::Shr) => { return Ok(res); }\n                 _ => {\n@@ -1898,13 +1905,13 @@ impl<'a> Parser<'a> {\n                 return Ok(res);\n             }\n \n-            try!(self.bump());\n+            self.bump();\n         }\n     }\n \n     /// Parse mutability declaration (mut/const/imm)\n     pub fn parse_mutability(&mut self) -> PResult<'a, Mutability> {\n-        if try!(self.eat_keyword(keywords::Mut) ){\n+        if self.eat_keyword(keywords::Mut) {\n             Ok(MutMutable)\n         } else {\n             Ok(MutImmutable)\n@@ -2008,7 +2015,7 @@ impl<'a> Parser<'a> {\n         self.expected_tokens.push(TokenType::Token(token::Gt));\n         match self.token {\n             token::OpenDelim(delim) => {\n-                try!(self.bump());\n+                self.bump();\n                 Ok(delim)\n             },\n             _ => Err(self.fatal(\"expected open delimiter\")),\n@@ -2040,7 +2047,7 @@ impl<'a> Parser<'a> {\n         // Note: when adding new syntax here, don't forget to adjust Token::can_begin_expr().\n         match self.token {\n             token::OpenDelim(token::Paren) => {\n-                try!(self.bump());\n+                self.bump();\n \n                 let attrs = try!(self.parse_inner_attributes())\n                     .into_thin_attrs()\n@@ -2057,13 +2064,13 @@ impl<'a> Parser<'a> {\n                     if self.check(&token::Comma) {\n                         trailing_comma = true;\n \n-                        try!(self.bump());\n+                        self.bump();\n                     } else {\n                         trailing_comma = false;\n                         break;\n                     }\n                 }\n-                try!(self.bump());\n+                self.bump();\n \n                 hi = self.last_span.hi;\n                 return if es.len() == 1 && !trailing_comma {\n@@ -2083,34 +2090,34 @@ impl<'a> Parser<'a> {\n                             name: token::SELF_KEYWORD_NAME,\n                             ctxt: _\n                          }, token::Plain) => {\n-                try!(self.bump());\n+                self.bump();\n                 let path = ast_util::ident_to_path(mk_sp(lo, hi), id);\n                 ex = ExprPath(None, path);\n                 hi = self.last_span.hi;\n             }\n             token::OpenDelim(token::Bracket) => {\n-                try!(self.bump());\n+                self.bump();\n \n                 let inner_attrs = try!(self.parse_inner_attributes())\n                     .into_thin_attrs();\n                 attrs.update(|attrs| attrs.append(inner_attrs));\n \n                 if self.check(&token::CloseDelim(token::Bracket)) {\n                     // Empty vector.\n-                    try!(self.bump());\n+                    self.bump();\n                     ex = ExprVec(Vec::new());\n                 } else {\n                     // Nonempty vector.\n                     let first_expr = try!(self.parse_expr());\n                     if self.check(&token::Semi) {\n                         // Repeating array syntax: [ 0; 512 ]\n-                        try!(self.bump());\n+                        self.bump();\n                         let count = try!(self.parse_expr());\n                         try!(self.expect(&token::CloseDelim(token::Bracket)));\n                         ex = ExprRepeat(first_expr, count);\n                     } else if self.check(&token::Comma) {\n                         // Vector with two or more elements.\n-                        try!(self.bump());\n+                        self.bump();\n                         let remaining_exprs = try!(self.parse_seq_to_end(\n                             &token::CloseDelim(token::Bracket),\n                             seq_sep_trailing_allowed(token::Comma),\n@@ -2128,85 +2135,85 @@ impl<'a> Parser<'a> {\n                 hi = self.last_span.hi;\n             }\n             _ => {\n-                if try!(self.eat_lt()){\n+                if self.eat_lt() {\n                     let (qself, path) =\n                         try!(self.parse_qualified_path(LifetimeAndTypesWithColons));\n                     hi = path.span.hi;\n                     return Ok(self.mk_expr(lo, hi, ExprPath(Some(qself), path), attrs));\n                 }\n-                if try!(self.eat_keyword(keywords::Move) ){\n+                if self.eat_keyword(keywords::Move) {\n                     let lo = self.last_span.lo;\n                     return self.parse_lambda_expr(lo, CaptureByValue, attrs);\n                 }\n-                if try!(self.eat_keyword(keywords::If)) {\n+                if self.eat_keyword(keywords::If) {\n                     return self.parse_if_expr(attrs);\n                 }\n-                if try!(self.eat_keyword(keywords::For) ){\n+                if self.eat_keyword(keywords::For) {\n                     let lo = self.last_span.lo;\n                     return self.parse_for_expr(None, lo, attrs);\n                 }\n-                if try!(self.eat_keyword(keywords::While) ){\n+                if self.eat_keyword(keywords::While) {\n                     let lo = self.last_span.lo;\n                     return self.parse_while_expr(None, lo, attrs);\n                 }\n                 if self.token.is_lifetime() {\n                     let lifetime = self.get_lifetime();\n                     let lo = self.span.lo;\n-                    try!(self.bump());\n+                    self.bump();\n                     try!(self.expect(&token::Colon));\n-                    if try!(self.eat_keyword(keywords::While) ){\n+                    if self.eat_keyword(keywords::While) {\n                         return self.parse_while_expr(Some(lifetime), lo, attrs)\n                     }\n-                    if try!(self.eat_keyword(keywords::For) ){\n+                    if self.eat_keyword(keywords::For) {\n                         return self.parse_for_expr(Some(lifetime), lo, attrs)\n                     }\n-                    if try!(self.eat_keyword(keywords::Loop) ){\n+                    if self.eat_keyword(keywords::Loop) {\n                         return self.parse_loop_expr(Some(lifetime), lo, attrs)\n                     }\n                     return Err(self.fatal(\"expected `while`, `for`, or `loop` after a label\"))\n                 }\n-                if try!(self.eat_keyword(keywords::Loop) ){\n+                if self.eat_keyword(keywords::Loop) {\n                     let lo = self.last_span.lo;\n                     return self.parse_loop_expr(None, lo, attrs);\n                 }\n-                if try!(self.eat_keyword(keywords::Continue) ){\n+                if self.eat_keyword(keywords::Continue) {\n                     let ex = if self.token.is_lifetime() {\n                         let ex = ExprAgain(Some(Spanned{\n                             node: self.get_lifetime(),\n                             span: self.span\n                         }));\n-                        try!(self.bump());\n+                        self.bump();\n                         ex\n                     } else {\n                         ExprAgain(None)\n                     };\n                     let hi = self.last_span.hi;\n                     return Ok(self.mk_expr(lo, hi, ex, attrs));\n                 }\n-                if try!(self.eat_keyword(keywords::Match) ){\n+                if self.eat_keyword(keywords::Match) {\n                     return self.parse_match_expr(attrs);\n                 }\n-                if try!(self.eat_keyword(keywords::Unsafe) ){\n+                if self.eat_keyword(keywords::Unsafe) {\n                     return self.parse_block_expr(\n                         lo,\n                         UnsafeBlock(ast::UserProvided),\n                         attrs);\n                 }\n-                if try!(self.eat_keyword(keywords::Return) ){\n+                if self.eat_keyword(keywords::Return) {\n                     if self.token.can_begin_expr() {\n                         let e = try!(self.parse_expr());\n                         hi = e.span.hi;\n                         ex = ExprRet(Some(e));\n                     } else {\n                         ex = ExprRet(None);\n                     }\n-                } else if try!(self.eat_keyword(keywords::Break) ){\n+                } else if self.eat_keyword(keywords::Break) {\n                     if self.token.is_lifetime() {\n                         ex = ExprBreak(Some(Spanned {\n                             node: self.get_lifetime(),\n                             span: self.span\n                         }));\n-                        try!(self.bump());\n+                        self.bump();\n                     } else {\n                         ex = ExprBreak(None);\n                     }\n@@ -2221,7 +2228,7 @@ impl<'a> Parser<'a> {\n                     // `!`, as an operator, is prefix, so we know this isn't that\n                     if self.check(&token::Not) {\n                         // MACRO INVOCATION expression\n-                        try!(self.bump());\n+                        self.bump();\n \n                         let delim = try!(self.expect_open_delim());\n                         let tts = try!(self.parse_seq_to_end(\n@@ -2243,7 +2250,7 @@ impl<'a> Parser<'a> {\n                         );\n                         if !prohibited {\n                             // It's a struct literal.\n-                            try!(self.bump());\n+                            self.bump();\n                             let mut fields = Vec::new();\n                             let mut base = None;\n \n@@ -2252,7 +2259,7 @@ impl<'a> Parser<'a> {\n                                     .into_thin_attrs());\n \n                             while self.token != token::CloseDelim(token::Brace) {\n-                                if try!(self.eat(&token::DotDot) ){\n+                                if self.eat(&token::DotDot) {\n                                     base = Some(try!(self.parse_expr()));\n                                     break;\n                                 }\n@@ -2354,13 +2361,13 @@ impl<'a> Parser<'a> {\n         let mut hi;\n         loop {\n             // expr.f\n-            if try!(self.eat(&token::Dot) ){\n+            if self.eat(&token::Dot) {\n                 match self.token {\n                   token::Ident(i, _) => {\n                     let dot = self.last_span.hi;\n                     hi = self.span.hi;\n-                    try!(self.bump());\n-                    let (_, tys, bindings) = if try!(self.eat(&token::ModSep) ){\n+                    self.bump();\n+                    let (_, tys, bindings) = if self.eat(&token::ModSep) {\n                         try!(self.expect_lt());\n                         try!(self.parse_generic_values_after_lt())\n                     } else {\n@@ -2410,7 +2417,7 @@ impl<'a> Parser<'a> {\n \n                     let dot = self.last_span.hi;\n                     hi = self.span.hi;\n-                    try!(self.bump());\n+                    self.bump();\n \n                     let index = n.as_str().parse::<usize>().ok();\n                     match index {\n@@ -2426,7 +2433,7 @@ impl<'a> Parser<'a> {\n                     }\n                   }\n                   token::Literal(token::Float(n), _suf) => {\n-                    try!(self.bump());\n+                    self.bump();\n                     let last_span = self.last_span;\n                     let fstr = n.as_str();\n                     let mut err = self.diagnostic().struct_span_err(last_span,\n@@ -2445,7 +2452,7 @@ impl<'a> Parser<'a> {\n                     self.abort_if_errors();\n \n                   }\n-                  _ => return Err(self.unexpected())\n+                  _ => return self.unexpected()\n                 }\n                 continue;\n             }\n@@ -2468,7 +2475,7 @@ impl<'a> Parser<'a> {\n               // expr[...]\n               // Could be either an index expression or a slicing expression.\n               token::OpenDelim(token::Bracket) => {\n-                try!(self.bump());\n+                self.bump();\n                 let ix = try!(self.parse_expr());\n                 hi = self.span.hi;\n                 try!(self.commit_expr_expecting(&*ix, token::CloseDelim(token::Bracket)));\n@@ -2486,7 +2493,7 @@ impl<'a> Parser<'a> {\n         let mut sp = self.span;\n         let (name, namep) = match self.token {\n             token::Dollar => {\n-                try!(self.bump());\n+                self.bump();\n \n                 if self.token == token::OpenDelim(token::Paren) {\n                     let Spanned { node: seq, span: seq_span } = try!(self.parse_seq(\n@@ -2505,7 +2512,7 @@ impl<'a> Parser<'a> {\n                                           num_captures: name_num\n                                       })));\n                 } else if self.token.is_keyword_allow_following_colon(keywords::Crate) {\n-                    try!(self.bump());\n+                    self.bump();\n                     return Ok(TokenTree::Token(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar)));\n                 } else {\n                     sp = mk_sp(sp.lo, self.span.hi);\n@@ -2515,7 +2522,7 @@ impl<'a> Parser<'a> {\n                 }\n             }\n             token::SubstNt(name, namep) => {\n-                try!(self.bump());\n+                self.bump();\n                 (name, namep)\n             }\n             _ => unreachable!()\n@@ -2524,7 +2531,7 @@ impl<'a> Parser<'a> {\n         if self.token == token::Colon && self.look_ahead(1, |t| t.is_ident() &&\n                                                                 !t.is_strict_keyword() &&\n                                                                 !t.is_reserved_keyword()) {\n-            try!(self.bump());\n+            self.bump();\n             sp = mk_sp(sp.lo, self.span.hi);\n             let kindp = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n             let nt_kind = try!(self.parse_ident());\n@@ -2534,16 +2541,14 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn check_unknown_macro_variable(&mut self) -> PResult<'a, ()> {\n+    pub fn check_unknown_macro_variable(&mut self) {\n         if self.quote_depth == 0 {\n             match self.token {\n                 token::SubstNt(name, _) =>\n-                    return Err(self.fatal(&format!(\"unknown macro variable `{}`\",\n-                                       name))),\n+                    self.fatal(&format!(\"unknown macro variable `{}`\", name)).emit(),\n                 _ => {}\n             }\n         }\n-        Ok(())\n     }\n \n     /// Parse an optional separator followed by a Kleene-style\n@@ -2553,11 +2558,11 @@ impl<'a> Parser<'a> {\n         fn parse_kleene_op<'a>(parser: &mut Parser<'a>) -> PResult<'a,  Option<ast::KleeneOp>> {\n             match parser.token {\n                 token::BinOp(token::Star) => {\n-                    try!(parser.bump());\n+                    parser.bump();\n                     Ok(Some(ast::ZeroOrMore))\n                 },\n                 token::BinOp(token::Plus) => {\n-                    try!(parser.bump());\n+                    parser.bump();\n                     Ok(Some(ast::OneOrMore))\n                 },\n                 _ => Ok(None)\n@@ -2569,7 +2574,7 @@ impl<'a> Parser<'a> {\n             None => {}\n         }\n \n-        let separator = try!(self.bump_and_get());\n+        let separator = self.bump_and_get();\n         match try!(parse_kleene_op(self)) {\n             Some(zerok) => Ok((Some(separator), zerok)),\n             None => return Err(self.fatal(\"expected `*` or `+`\"))\n@@ -2610,7 +2615,7 @@ impl<'a> Parser<'a> {\n                     p.parse_unquoted()\n                 }\n                 _ => {\n-                    Ok(TokenTree::Token(p.span, try!(p.bump_and_get())))\n+                    Ok(TokenTree::Token(p.span, p.bump_and_get()))\n                 }\n             }\n         }\n@@ -2632,7 +2637,7 @@ impl<'a> Parser<'a> {\n                 // Parse the open delimiter.\n                 self.open_braces.push(self.span);\n                 let open_span = self.span;\n-                try!(self.bump());\n+                self.bump();\n \n                 // Parse the token trees within the delimiters\n                 let tts = try!(self.parse_seq_to_before_end(\n@@ -2643,7 +2648,7 @@ impl<'a> Parser<'a> {\n \n                 // Parse the close delimiter.\n                 let close_span = self.span;\n-                try!(self.bump());\n+                self.bump();\n                 self.open_braces.pop().unwrap();\n \n                 // Expand to cover the entire delimited token tree\n@@ -2680,19 +2685,19 @@ impl<'a> Parser<'a> {\n         // Note: when adding new unary operators, don't forget to adjust Token::can_begin_expr()\n         let ex = match self.token {\n             token::Not => {\n-                try!(self.bump());\n+                self.bump();\n                 let e = try!(self.parse_prefix_expr(None));\n                 hi = e.span.hi;\n                 self.mk_unary(UnNot, e)\n             }\n             token::BinOp(token::Minus) => {\n-                try!(self.bump());\n+                self.bump();\n                 let e = try!(self.parse_prefix_expr(None));\n                 hi = e.span.hi;\n                 self.mk_unary(UnNeg, e)\n             }\n             token::BinOp(token::Star) => {\n-                try!(self.bump());\n+                self.bump();\n                 let e = try!(self.parse_prefix_expr(None));\n                 hi = e.span.hi;\n                 self.mk_unary(UnDeref, e)\n@@ -2705,7 +2710,7 @@ impl<'a> Parser<'a> {\n                 ExprAddrOf(m, e)\n             }\n             token::Ident(..) if self.token.is_keyword(keywords::In) => {\n-                try!(self.bump());\n+                self.bump();\n                 let place = try!(self.parse_expr_res(\n                     Restrictions::RESTRICTION_NO_STRUCT_LITERAL,\n                     None,\n@@ -2718,7 +2723,7 @@ impl<'a> Parser<'a> {\n                 ExprInPlace(place, blk_expr)\n             }\n             token::Ident(..) if self.token.is_keyword(keywords::Box) => {\n-                try!(self.bump());\n+                self.bump();\n                 let subexpression = try!(self.parse_prefix_expr(None));\n                 hi = subexpression.span.hi;\n                 ExprBox(subexpression)\n@@ -2771,7 +2776,7 @@ impl<'a> Parser<'a> {\n             if op.precedence() < min_prec {\n                 break;\n             }\n-            try!(self.bump());\n+            self.bump();\n             if op.is_comparison() {\n                 self.check_no_chained_comparison(&*lhs, &op);\n             }\n@@ -2893,7 +2898,7 @@ impl<'a> Parser<'a> {\n         let attrs = try!(self.parse_or_use_outer_attributes(already_parsed_attrs));\n         let lo = self.span.lo;\n         let mut hi = self.span.hi;\n-        try!(self.bump());\n+        self.bump();\n         let opt_end = if self.is_at_start_of_range_notation_rhs() {\n             // RHS must be parsed with more associativity than DotDot.\n             let next_prec = AssocOp::from_token(&token::DotDot).unwrap().precedence() + 1;\n@@ -2932,7 +2937,7 @@ impl<'a> Parser<'a> {\n         let thn = try!(self.parse_block());\n         let mut els: Option<P<Expr>> = None;\n         let mut hi = thn.span.hi;\n-        if try!(self.eat_keyword(keywords::Else) ){\n+        if self.eat_keyword(keywords::Else) {\n             let elexpr = try!(self.parse_else_expr());\n             hi = elexpr.span.hi;\n             els = Some(elexpr);\n@@ -2949,7 +2954,7 @@ impl<'a> Parser<'a> {\n         try!(self.expect(&token::Eq));\n         let expr = try!(self.parse_expr_res(Restrictions::RESTRICTION_NO_STRUCT_LITERAL, None));\n         let thn = try!(self.parse_block());\n-        let (hi, els) = if try!(self.eat_keyword(keywords::Else) ){\n+        let (hi, els) = if self.eat_keyword(keywords::Else) {\n             let expr = try!(self.parse_else_expr());\n             (expr.span.hi, Some(expr))\n         } else {\n@@ -2993,7 +2998,7 @@ impl<'a> Parser<'a> {\n \n     // `else` token already eaten\n     pub fn parse_else_expr(&mut self) -> PResult<'a, P<Expr>> {\n-        if try!(self.eat_keyword(keywords::If) ){\n+        if self.eat_keyword(keywords::If) {\n             return self.parse_if_expr(None);\n         } else {\n             let blk = try!(self.parse_block());\n@@ -3079,7 +3084,7 @@ impl<'a> Parser<'a> {\n             arms.push(try!(self.parse_arm()));\n         }\n         let hi = self.span.hi;\n-        try!(self.bump());\n+        self.bump();\n         return Ok(self.mk_expr(lo, hi, ExprMatch(discriminant, arms), attrs));\n     }\n \n@@ -3089,7 +3094,7 @@ impl<'a> Parser<'a> {\n         let attrs = try!(self.parse_outer_attributes());\n         let pats = try!(self.parse_pats());\n         let mut guard = None;\n-        if try!(self.eat_keyword(keywords::If) ){\n+        if self.eat_keyword(keywords::If) {\n             guard = Some(try!(self.parse_expr()));\n         }\n         try!(self.expect(&token::FatArrow));\n@@ -3102,7 +3107,7 @@ impl<'a> Parser<'a> {\n         if require_comma {\n             try!(self.commit_expr(&*expr, &[token::Comma], &[token::CloseDelim(token::Brace)]));\n         } else {\n-            try!(self.eat(&token::Comma));\n+            self.eat(&token::Comma);\n         }\n \n         Ok(ast::Arm {\n@@ -3142,7 +3147,7 @@ impl<'a> Parser<'a> {\n     /// Parse the RHS of a local variable declaration (e.g. '= 14;')\n     fn parse_initializer(&mut self) -> PResult<'a, Option<P<Expr>>> {\n         if self.check(&token::Eq) {\n-            try!(self.bump());\n+            self.bump();\n             Ok(Some(try!(self.parse_expr())))\n         } else {\n             Ok(None)\n@@ -3154,7 +3159,7 @@ impl<'a> Parser<'a> {\n         let mut pats = Vec::new();\n         loop {\n             pats.push(try!(self.parse_pat()));\n-            if self.check(&token::BinOp(token::Or)) { try!(self.bump());}\n+            if self.check(&token::BinOp(token::Or)) { self.bump();}\n             else { return Ok(pats); }\n         };\n     }\n@@ -3164,7 +3169,7 @@ impl<'a> Parser<'a> {\n         if !self.check(&token::CloseDelim(token::Paren)) {\n             fields.push(try!(self.parse_pat()));\n             if self.look_ahead(1, |t| *t != token::CloseDelim(token::Paren)) {\n-                while try!(self.eat(&token::Comma)) &&\n+                while self.eat(&token::Comma) &&\n                       !self.check(&token::CloseDelim(token::Paren)) {\n                     fields.push(try!(self.parse_pat()));\n                 }\n@@ -3199,7 +3204,7 @@ impl<'a> Parser<'a> {\n \n             if before_slice {\n                 if self.check(&token::DotDot) {\n-                    try!(self.bump());\n+                    self.bump();\n \n                     if self.check(&token::Comma) ||\n                             self.check(&token::CloseDelim(token::Bracket)) {\n@@ -3216,7 +3221,7 @@ impl<'a> Parser<'a> {\n \n             let subpat = try!(self.parse_pat());\n             if before_slice && self.check(&token::DotDot) {\n-                try!(self.bump());\n+                self.bump();\n                 slice = Some(subpat);\n                 before_slice = false;\n             } else if before_slice {\n@@ -3247,7 +3252,7 @@ impl<'a> Parser<'a> {\n             let hi;\n \n             if self.check(&token::DotDot) {\n-                try!(self.bump());\n+                self.bump();\n                 if self.token != token::CloseDelim(token::Brace) {\n                     let token_str = self.this_token_to_string();\n                     return Err(self.fatal(&format!(\"expected `{}`, found `{}`\", \"}\",\n@@ -3261,16 +3266,16 @@ impl<'a> Parser<'a> {\n             let (subpat, fieldname, is_shorthand) = if self.look_ahead(1, |t| t == &token::Colon) {\n                 // Parsing a pattern of the form \"fieldname: pat\"\n                 let fieldname = try!(self.parse_ident());\n-                try!(self.bump());\n+                self.bump();\n                 let pat = try!(self.parse_pat());\n                 hi = pat.span.hi;\n                 (pat, fieldname, false)\n             } else {\n                 // Parsing a pattern of the form \"(box) (ref) (mut) fieldname\"\n-                let is_box = try!(self.eat_keyword(keywords::Box));\n+                let is_box = self.eat_keyword(keywords::Box);\n                 let boxed_span_lo = self.span.lo;\n-                let is_ref = try!(self.eat_keyword(keywords::Ref));\n-                let is_mut = try!(self.eat_keyword(keywords::Mut));\n+                let is_ref = self.eat_keyword(keywords::Ref);\n+                let is_mut = self.eat_keyword(keywords::Mut);\n                 let fieldname = try!(self.parse_ident());\n                 hi = self.last_span.hi;\n \n@@ -3310,7 +3315,7 @@ impl<'a> Parser<'a> {\n     fn parse_pat_range_end(&mut self) -> PResult<'a, P<Expr>> {\n         if self.is_path_start() {\n             let lo = self.span.lo;\n-            let (qself, path) = if try!(self.eat_lt()) {\n+            let (qself, path) = if self.eat_lt() {\n                 // Parse a qualified path\n                 let (qself, path) =\n                     try!(self.parse_qualified_path(NoTypesAllowed));\n@@ -3341,7 +3346,7 @@ impl<'a> Parser<'a> {\n         match self.token {\n           token::Underscore => {\n             // Parse _\n-            try!(self.bump());\n+            self.bump();\n             pat = PatWild;\n           }\n           token::BinOp(token::And) | token::AndAnd => {\n@@ -3357,28 +3362,28 @@ impl<'a> Parser<'a> {\n           }\n           token::OpenDelim(token::Paren) => {\n             // Parse (pat,pat,pat,...) as tuple pattern\n-            try!(self.bump());\n+            self.bump();\n             let fields = try!(self.parse_pat_tuple_elements());\n             try!(self.expect(&token::CloseDelim(token::Paren)));\n             pat = PatTup(fields);\n           }\n           token::OpenDelim(token::Bracket) => {\n             // Parse [pat,pat,...] as slice pattern\n-            try!(self.bump());\n+            self.bump();\n             let (before, slice, after) = try!(self.parse_pat_vec_elements());\n             try!(self.expect(&token::CloseDelim(token::Bracket)));\n             pat = PatVec(before, slice, after);\n           }\n           _ => {\n             // At this point, token != _, &, &&, (, [\n-            if try!(self.eat_keyword(keywords::Mut)) {\n+            if self.eat_keyword(keywords::Mut) {\n                 // Parse mut ident @ pat\n                 pat = try!(self.parse_pat_ident(BindingMode::ByValue(MutMutable)));\n-            } else if try!(self.eat_keyword(keywords::Ref)) {\n+            } else if self.eat_keyword(keywords::Ref) {\n                 // Parse ref ident @ pat / ref mut ident @ pat\n                 let mutbl = try!(self.parse_mutability());\n                 pat = try!(self.parse_pat_ident(BindingMode::ByRef(mutbl)));\n-            } else if try!(self.eat_keyword(keywords::Box)) {\n+            } else if self.eat_keyword(keywords::Box) {\n                 // Parse box pat\n                 let subpat = try!(self.parse_pat());\n                 pat = PatBox(subpat);\n@@ -3395,7 +3400,7 @@ impl<'a> Parser<'a> {\n                         let ident = try!(self.parse_ident());\n                         let ident_span = self.last_span;\n                         let path = ident_to_path(ident_span, ident);\n-                        try!(self.bump());\n+                        self.bump();\n                         let delim = try!(self.expect_open_delim());\n                         let tts = try!(self.parse_seq_to_end(&token::CloseDelim(delim),\n                                 seq_sep_none(), |p| p.parse_token_tree()));\n@@ -3409,7 +3414,7 @@ impl<'a> Parser<'a> {\n                         pat = try!(self.parse_pat_ident(BindingMode::ByValue(MutImmutable)));\n                     }\n                 } else {\n-                    let (qself, path) = if try!(self.eat_lt()) {\n+                    let (qself, path) = if self.eat_lt() {\n                         // Parse a qualified path\n                         let (qself, path) =\n                             try!(self.parse_qualified_path(NoTypesAllowed));\n@@ -3423,7 +3428,7 @@ impl<'a> Parser<'a> {\n                         // Parse range\n                         let hi = self.last_span.hi;\n                         let begin = self.mk_expr(lo, hi, ExprPath(qself, path), None);\n-                        try!(self.bump());\n+                        self.bump();\n                         let end = try!(self.parse_pat_range_end());\n                         pat = PatRange(begin, end);\n                       }\n@@ -3432,9 +3437,9 @@ impl<'a> Parser<'a> {\n                             return Err(self.fatal(\"unexpected `{` after qualified path\"));\n                         }\n                         // Parse struct pattern\n-                        try!(self.bump());\n+                        self.bump();\n                         let (fields, etc) = try!(self.parse_pat_fields());\n-                        try!(self.bump());\n+                        self.bump();\n                         pat = PatStruct(path, fields, etc);\n                       }\n                       token::OpenDelim(token::Paren) => {\n@@ -3444,8 +3449,8 @@ impl<'a> Parser<'a> {\n                         // Parse tuple struct or enum pattern\n                         if self.look_ahead(1, |t| *t == token::DotDot) {\n                             // This is a \"top constructor only\" pat\n-                            try!(self.bump());\n-                            try!(self.bump());\n+                            self.bump();\n+                            self.bump();\n                             try!(self.expect(&token::CloseDelim(token::Paren)));\n                             pat = PatEnum(path, None);\n                         } else {\n@@ -3470,7 +3475,7 @@ impl<'a> Parser<'a> {\n             } else {\n                 // Try to parse everything else as literal with optional minus\n                 let begin = try!(self.parse_pat_literal_maybe_minus());\n-                if try!(self.eat(&token::DotDotDot)) {\n+                if self.eat(&token::DotDotDot) {\n                     let end = try!(self.parse_pat_range_end());\n                     pat = PatRange(begin, end);\n                 } else {\n@@ -3503,7 +3508,7 @@ impl<'a> Parser<'a> {\n         let ident = try!(self.parse_ident());\n         let last_span = self.last_span;\n         let name = codemap::Spanned{span: last_span, node: ident};\n-        let sub = if try!(self.eat(&token::At) ){\n+        let sub = if self.eat(&token::At) {\n             Some(try!(self.parse_pat()))\n         } else {\n             None\n@@ -3531,7 +3536,7 @@ impl<'a> Parser<'a> {\n         let pat = try!(self.parse_pat());\n \n         let mut ty = None;\n-        if try!(self.eat(&token::Colon) ){\n+        if self.eat(&token::Colon) {\n             ty = Some(try!(self.parse_ty_sum()));\n         }\n         let init = try!(self.parse_initializer());\n@@ -3610,7 +3615,7 @@ impl<'a> Parser<'a> {\n             // Potential trouble: if we allow macros with paths instead of\n             // idents, we'd need to look ahead past the whole path here...\n             let pth = try!(self.parse_path(NoTypesAllowed));\n-            try!(self.bump());\n+            self.bump();\n \n             let id = match self.token {\n                 token::OpenDelim(_) => token::special_idents::invalid, // no special identifier\n@@ -3663,7 +3668,7 @@ impl<'a> Parser<'a> {\n                 //\n                 // Require a semicolon or braces.\n                 if style != MacStmtWithBraces {\n-                    if !try!(self.eat(&token::Semi) ){\n+                    if !self.eat(&token::Semi) {\n                         let last_span = self.last_span;\n                         self.span_err(last_span,\n                                       \"macros that expand to items must \\\n@@ -3699,7 +3704,7 @@ impl<'a> Parser<'a> {\n                     // Do not attempt to parse an expression if we're done here.\n                     if self.token == token::Semi {\n                         unused_attrs(&attrs, self);\n-                        try!(self.bump());\n+                        self.bump();\n                         return Ok(None);\n                     }\n \n@@ -3731,7 +3736,7 @@ impl<'a> Parser<'a> {\n \n         let lo = self.span.lo;\n \n-        if !try!(self.eat(&token::OpenDelim(token::Brace)) ){\n+        if !self.eat(&token::OpenDelim(token::Brace)) {\n             let sp = self.span;\n             let tok = self.this_token_to_string();\n             return Err(self.span_fatal_help(sp,\n@@ -3758,7 +3763,7 @@ impl<'a> Parser<'a> {\n         let mut stmts = vec![];\n         let mut expr = None;\n \n-        while !try!(self.eat(&token::CloseDelim(token::Brace))) {\n+        while !self.eat(&token::CloseDelim(token::Brace)) {\n             let Spanned {node, span} = if let Some(s) = try!(self.parse_stmt_()) {\n                 s\n             } else {\n@@ -3778,7 +3783,7 @@ impl<'a> Parser<'a> {\n                                 node: StmtMac(mac, MacStmtWithSemicolon, attrs),\n                                 span: mk_sp(span.lo, self.span.hi),\n                             }));\n-                            try!(self.bump());\n+                            self.bump();\n                         }\n                         _ => {\n                             let e = self.mk_mac_expr(span.lo, span.hi,\n@@ -3802,7 +3807,7 @@ impl<'a> Parser<'a> {\n                                 node: StmtMac(m, MacStmtWithSemicolon, attrs),\n                                 span: mk_sp(span.lo, self.span.hi),\n                             }));\n-                            try!(self.bump());\n+                            self.bump();\n                         }\n                         token::CloseDelim(token::Brace) => {\n                             // if a block ends in `m!(arg)` without\n@@ -3858,7 +3863,7 @@ impl<'a> Parser<'a> {\n \n         match self.token {\n             token::Semi => {\n-                try!(self.bump());\n+                self.bump();\n                 let span_with_semi = Span {\n                     lo: span.lo,\n                     hi: self.last_span.hi,\n@@ -3886,7 +3891,7 @@ impl<'a> Parser<'a> {\n                                         mode: BoundParsingMode)\n                                         -> PResult<'a, TyParamBounds>\n     {\n-        if !try!(self.eat(&token::Colon) ){\n+        if !self.eat(&token::Colon) {\n             Ok(P::empty())\n         } else {\n             self.parse_ty_param_bounds(mode)\n@@ -3904,7 +3909,7 @@ impl<'a> Parser<'a> {\n         let mut result = vec!();\n         loop {\n             let question_span = self.span;\n-            let ate_question = try!(self.eat(&token::Question));\n+            let ate_question = self.eat(&token::Question);\n             match self.token {\n                 token::Lifetime(lifetime) => {\n                     if ate_question {\n@@ -3916,7 +3921,7 @@ impl<'a> Parser<'a> {\n                         span: self.span,\n                         name: lifetime.name\n                     }));\n-                    try!(self.bump());\n+                    self.bump();\n                 }\n                 token::ModSep | token::Ident(..) => {\n                     let poly_trait_ref = try!(self.parse_poly_trait_ref());\n@@ -3936,7 +3941,7 @@ impl<'a> Parser<'a> {\n                 _ => break,\n             }\n \n-            if !try!(self.eat(&token::BinOp(token::Plus)) ){\n+            if !self.eat(&token::BinOp(token::Plus)) {\n                 break;\n             }\n         }\n@@ -3952,7 +3957,7 @@ impl<'a> Parser<'a> {\n         let bounds = try!(self.parse_colon_then_ty_param_bounds(BoundParsingMode::Modified));\n \n         let default = if self.check(&token::Eq) {\n-            try!(self.bump());\n+            self.bump();\n             Some(try!(self.parse_ty_sum()))\n         } else {\n             None\n@@ -3977,7 +3982,7 @@ impl<'a> Parser<'a> {\n     pub fn parse_generics(&mut self) -> PResult<'a, ast::Generics> {\n         maybe_whole!(self, NtGenerics);\n \n-        if try!(self.eat(&token::Lt) ){\n+        if self.eat(&token::Lt) {\n             let lifetime_defs = try!(self.parse_lifetime_defs());\n             let mut seen_default = false;\n             let ty_params = try!(self.parse_seq_to_gt(Some(token::Comma), |p| {\n@@ -4065,7 +4070,7 @@ impl<'a> Parser<'a> {\n                 try!(p.forbid_lifetime());\n                 let lo = p.span.lo;\n                 let ident = try!(p.parse_ident());\n-                let found_eq = try!(p.eat(&token::Eq));\n+                let found_eq = p.eat(&token::Eq);\n                 if !found_eq {\n                     let span = p.span;\n                     p.span_warn(span, \"whoops, no =?\");\n@@ -4105,7 +4110,7 @@ impl<'a> Parser<'a> {\n             predicates: Vec::new(),\n         };\n \n-        if !try!(self.eat_keyword(keywords::Where)) {\n+        if !self.eat_keyword(keywords::Where) {\n             return Ok(where_clause);\n         }\n \n@@ -4121,7 +4126,7 @@ impl<'a> Parser<'a> {\n                     let bounded_lifetime =\n                         try!(self.parse_lifetime());\n \n-                    try!(self.eat(&token::Colon));\n+                    self.eat(&token::Colon);\n \n                     let bounds =\n                         try!(self.parse_lifetimes(token::BinOp(token::Plus)));\n@@ -4141,7 +4146,7 @@ impl<'a> Parser<'a> {\n                 }\n \n                 _ => {\n-                    let bound_lifetimes = if try!(self.eat_keyword(keywords::For) ){\n+                    let bound_lifetimes = if self.eat_keyword(keywords::For) {\n                         // Higher ranked constraint.\n                         try!(self.expect(&token::Lt));\n                         let lifetime_defs = try!(self.parse_lifetime_defs());\n@@ -4153,7 +4158,7 @@ impl<'a> Parser<'a> {\n \n                     let bounded_ty = try!(self.parse_ty());\n \n-                    if try!(self.eat(&token::Colon) ){\n+                    if self.eat(&token::Colon) {\n                         let bounds = try!(self.parse_ty_param_bounds(BoundParsingMode::Bare));\n                         let hi = self.last_span.hi;\n                         let span = mk_sp(lo, hi);\n@@ -4173,7 +4178,7 @@ impl<'a> Parser<'a> {\n                         }));\n \n                         parsed_something = true;\n-                    } else if try!(self.eat(&token::Eq) ){\n+                    } else if self.eat(&token::Eq) {\n                         // let ty = try!(self.parse_ty());\n                         let hi = self.last_span.hi;\n                         let span = mk_sp(lo, hi);\n@@ -4197,7 +4202,7 @@ impl<'a> Parser<'a> {\n                 }\n             };\n \n-            if !try!(self.eat(&token::Comma) ){\n+            if !self.eat(&token::Comma) {\n                 break\n             }\n         }\n@@ -4222,7 +4227,7 @@ impl<'a> Parser<'a> {\n                 seq_sep_trailing_allowed(token::Comma),\n                 |p| {\n                     if p.token == token::DotDotDot {\n-                        try!(p.bump());\n+                        p.bump();\n                         if allow_variadic {\n                             if p.token != token::CloseDelim(token::Paren) {\n                                 let span = p.span;\n@@ -4284,7 +4289,7 @@ impl<'a> Parser<'a> {\n     fn expect_self_ident(&mut self) -> PResult<'a, ast::Ident> {\n         match self.token {\n             token::Ident(id, token::Plain) if id.name == special_idents::self_.name => {\n-                try!(self.bump());\n+                self.bump();\n                 Ok(id)\n             },\n             _ => {\n@@ -4305,7 +4310,7 @@ impl<'a> Parser<'a> {\n     fn expect_self_type_ident(&mut self) -> PResult<'a, ast::Ident> {\n         match self.token {\n             token::Ident(id, token::Plain) if id.name == special_idents::type_self.name => {\n-                try!(self.bump());\n+                self.bump();\n                 Ok(id)\n             },\n             _ => {\n@@ -4334,22 +4339,22 @@ impl<'a> Parser<'a> {\n             // We already know that the current token is `&`.\n \n             if this.look_ahead(1, |t| t.is_keyword(keywords::SelfValue)) {\n-                try!(this.bump());\n+                this.bump();\n                 Ok(SelfRegion(None, MutImmutable, try!(this.expect_self_ident())))\n             } else if this.look_ahead(1, |t| t.is_mutability()) &&\n                       this.look_ahead(2, |t| t.is_keyword(keywords::SelfValue)) {\n-                try!(this.bump());\n+                this.bump();\n                 let mutability = try!(this.parse_mutability());\n                 Ok(SelfRegion(None, mutability, try!(this.expect_self_ident())))\n             } else if this.look_ahead(1, |t| t.is_lifetime()) &&\n                       this.look_ahead(2, |t| t.is_keyword(keywords::SelfValue)) {\n-                try!(this.bump());\n+                this.bump();\n                 let lifetime = try!(this.parse_lifetime());\n                 Ok(SelfRegion(Some(lifetime), MutImmutable, try!(this.expect_self_ident())))\n             } else if this.look_ahead(1, |t| t.is_lifetime()) &&\n                       this.look_ahead(2, |t| t.is_mutability()) &&\n                       this.look_ahead(3, |t| t.is_keyword(keywords::SelfValue)) {\n-                try!(this.bump());\n+                this.bump();\n                 let lifetime = try!(this.parse_lifetime());\n                 let mutability = try!(this.parse_mutability());\n                 Ok(SelfRegion(Some(lifetime), mutability, try!(this.expect_self_ident())))\n@@ -4377,7 +4382,7 @@ impl<'a> Parser<'a> {\n             token::BinOp(token::Star) => {\n                 // Possibly \"*self\" or \"*mut self\" -- not supported. Try to avoid\n                 // emitting cryptic \"unexpected token\" errors.\n-                try!(self.bump());\n+                self.bump();\n                 let _mutability = if self.token.is_mutability() {\n                     try!(self.parse_mutability())\n                 } else {\n@@ -4386,7 +4391,7 @@ impl<'a> Parser<'a> {\n                 if self.is_self_ident() {\n                     let span = self.span;\n                     self.span_err(span, \"cannot pass self by raw pointer\");\n-                    try!(self.bump());\n+                    self.bump();\n                 }\n                 // error case, making bogus self ident:\n                 SelfValue(special_idents::self_)\n@@ -4397,7 +4402,7 @@ impl<'a> Parser<'a> {\n \n                     // Determine whether this is the fully explicit form, `self:\n                     // TYPE`.\n-                    if try!(self.eat(&token::Colon) ){\n+                    if self.eat(&token::Colon) {\n                         SelfExplicit(try!(self.parse_ty_sum()), self_ident)\n                     } else {\n                         SelfValue(self_ident)\n@@ -4409,7 +4414,7 @@ impl<'a> Parser<'a> {\n \n                     // Determine whether this is the fully explicit form,\n                     // `self: TYPE`.\n-                    if try!(self.eat(&token::Colon) ){\n+                    if self.eat(&token::Colon) {\n                         SelfExplicit(try!(self.parse_ty_sum()), self_ident)\n                     } else {\n                         SelfValue(self_ident)\n@@ -4431,7 +4436,7 @@ impl<'a> Parser<'a> {\n             // If we parsed a self type, expect a comma before the argument list.\n             match self.token {\n                 token::Comma => {\n-                    try!(self.bump());\n+                    self.bump();\n                     let sep = seq_sep_trailing_allowed(token::Comma);\n                     let mut fn_inputs = try!(self.parse_seq_to_before_end(\n                         &token::CloseDelim(token::Paren),\n@@ -4483,7 +4488,7 @@ impl<'a> Parser<'a> {\n     // parse the |arg, arg| header on a lambda\n     fn parse_fn_block_decl(&mut self) -> PResult<'a, P<FnDecl>> {\n         let inputs_captures = {\n-            if try!(self.eat(&token::OrOr) ){\n+            if self.eat(&token::OrOr) {\n                 Vec::new()\n             } else {\n                 try!(self.expect(&token::BinOp(token::Or)));\n@@ -4493,7 +4498,7 @@ impl<'a> Parser<'a> {\n                     seq_sep_trailing_allowed(token::Comma),\n                     |p| p.parse_fn_block_arg()\n                 ));\n-                try!(self.bump());\n+                self.bump();\n                 args\n             }\n         };\n@@ -4556,12 +4561,12 @@ impl<'a> Parser<'a> {\n     /// - etc\n     pub fn parse_fn_front_matter(&mut self)\n                                  -> PResult<'a, (ast::Constness, ast::Unsafety, abi::Abi)> {\n-        let is_const_fn = try!(self.eat_keyword(keywords::Const));\n+        let is_const_fn = self.eat_keyword(keywords::Const);\n         let unsafety = try!(self.parse_unsafety());\n         let (constness, unsafety, abi) = if is_const_fn {\n             (Constness::Const, unsafety, abi::Rust)\n         } else {\n-            let abi = if try!(self.eat_keyword(keywords::Extern)) {\n+            let abi = if self.eat_keyword(keywords::Extern) {\n                 try!(self.parse_opt_abi()).unwrap_or(abi::C)\n             } else {\n                 abi::Rust\n@@ -4579,7 +4584,7 @@ impl<'a> Parser<'a> {\n         let mut attrs = try!(self.parse_outer_attributes());\n         let lo = self.span.lo;\n         let vis = try!(self.parse_visibility());\n-        let (name, node) = if try!(self.eat_keyword(keywords::Type)) {\n+        let (name, node) = if self.eat_keyword(keywords::Type) {\n             let name = try!(self.parse_ident());\n             try!(self.expect(&token::Eq));\n             let typ = try!(self.parse_ty_sum());\n@@ -4702,7 +4707,7 @@ impl<'a> Parser<'a> {\n         let could_be_trait = self.token != token::OpenDelim(token::Paren);\n \n         let neg_span = self.span;\n-        let polarity = if try!(self.eat(&token::Not) ){\n+        let polarity = if self.eat(&token::Not) {\n             ast::ImplPolarity::Negative\n         } else {\n             ast::ImplPolarity::Positive\n@@ -4712,7 +4717,7 @@ impl<'a> Parser<'a> {\n         let mut ty = try!(self.parse_ty_sum());\n \n         // Parse traits, if necessary.\n-        let opt_trait = if could_be_trait && try!(self.eat_keyword(keywords::For) ){\n+        let opt_trait = if could_be_trait && self.eat_keyword(keywords::For) {\n             // New-style trait. Reinterpret the type as a trait.\n             match ty.node {\n                 TyPath(None, ref path) => {\n@@ -4738,7 +4743,7 @@ impl<'a> Parser<'a> {\n             None\n         };\n \n-        if opt_trait.is_some() && try!(self.eat(&token::DotDot) ){\n+        if opt_trait.is_some() && self.eat(&token::DotDot) {\n             if generics.is_parameterized() {\n                 self.span_err(impl_span, \"default trait implementations are not \\\n                                           allowed to have generics\");\n@@ -4758,7 +4763,7 @@ impl<'a> Parser<'a> {\n             let attrs = try!(self.parse_inner_attributes());\n \n             let mut impl_items = vec![];\n-            while !try!(self.eat(&token::CloseDelim(token::Brace))) {\n+            while !self.eat(&token::CloseDelim(token::Brace)) {\n                 impl_items.push(try!(self.parse_impl_item()));\n             }\n \n@@ -4777,7 +4782,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_late_bound_lifetime_defs(&mut self) -> PResult<'a, Vec<ast::LifetimeDef>> {\n-        if try!(self.eat_keyword(keywords::For) ){\n+        if self.eat_keyword(keywords::For) {\n             try!(self.expect(&token::Lt));\n             let lifetime_defs = try!(self.parse_lifetime_defs());\n             try!(self.expect_gt());\n@@ -4820,7 +4825,7 @@ impl<'a> Parser<'a> {\n \n         let vdata = if self.token.is_keyword(keywords::Where) {\n             generics.where_clause = try!(self.parse_where_clause());\n-            if try!(self.eat(&token::Semi)) {\n+            if self.eat(&token::Semi) {\n                 // If we see a: `struct Foo<T> where T: Copy;` style decl.\n                 VariantData::Unit(ast::DUMMY_NODE_ID)\n             } else {\n@@ -4829,7 +4834,7 @@ impl<'a> Parser<'a> {\n                                     ast::DUMMY_NODE_ID)\n             }\n         // No `where` so: `struct Foo<T>;`\n-        } else if try!(self.eat(&token::Semi) ){\n+        } else if self.eat(&token::Semi) {\n             VariantData::Unit(ast::DUMMY_NODE_ID)\n         // Record-style struct definition\n         } else if self.token == token::OpenDelim(token::Brace) {\n@@ -4855,12 +4860,12 @@ impl<'a> Parser<'a> {\n                                     parse_pub: ParsePub)\n                                     -> PResult<'a, Vec<StructField>> {\n         let mut fields = Vec::new();\n-        if try!(self.eat(&token::OpenDelim(token::Brace)) ){\n+        if self.eat(&token::OpenDelim(token::Brace)) {\n             while self.token != token::CloseDelim(token::Brace) {\n                 fields.push(try!(self.parse_struct_decl_field(parse_pub)));\n             }\n \n-            try!(self.bump());\n+            self.bump();\n         } else {\n             let token_str = self.this_token_to_string();\n             return Err(self.fatal(&format!(\"expected `where`, or `{{` after struct \\\n@@ -4909,7 +4914,7 @@ impl<'a> Parser<'a> {\n         let a_var = try!(self.parse_name_and_ty(vis, attrs));\n         match self.token {\n             token::Comma => {\n-                try!(self.bump());\n+                self.bump();\n             }\n             token::CloseDelim(token::Brace) => {}\n             _ => {\n@@ -4929,7 +4934,7 @@ impl<'a> Parser<'a> {\n \n         let attrs = try!(self.parse_outer_attributes());\n \n-        if try!(self.eat_keyword(keywords::Pub) ){\n+        if self.eat_keyword(keywords::Pub) {\n             if parse_pub == ParsePub::No {\n                 let span = self.last_span;\n                 self.span_err(span, \"`pub` is not allowed here\");\n@@ -4942,7 +4947,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse visibility: PUB or nothing\n     fn parse_visibility(&mut self) -> PResult<'a, Visibility> {\n-        if try!(self.eat_keyword(keywords::Pub)) { Ok(Public) }\n+        if self.eat_keyword(keywords::Pub) { Ok(Public) }\n         else { Ok(Inherited) }\n     }\n \n@@ -4953,7 +4958,7 @@ impl<'a> Parser<'a> {\n             items.push(item);\n         }\n \n-        if !try!(self.eat(term)) {\n+        if !self.eat(term) {\n             let token_str = self.this_token_to_string();\n             return Err(self.fatal(&format!(\"expected item, found `{}`\", token_str)));\n         }\n@@ -4989,7 +4994,7 @@ impl<'a> Parser<'a> {\n         let id_span = self.span;\n         let id = try!(self.parse_ident());\n         if self.check(&token::Semi) {\n-            try!(self.bump());\n+            self.bump();\n             // This mod is in an external file. Let's go get it!\n             let (m, attrs) = try!(self.eval_src_mod(id, outer_attrs, id_span));\n             Ok((id, m, Some(attrs)))\n@@ -5180,7 +5185,7 @@ impl<'a> Parser<'a> {\n     fn parse_item_foreign_static(&mut self, vis: ast::Visibility, lo: BytePos,\n                                  attrs: Vec<Attribute>) -> PResult<'a, P<ForeignItem>> {\n         try!(self.expect_keyword(keywords::Static));\n-        let mutbl = try!(self.eat_keyword(keywords::Mut));\n+        let mutbl = self.eat_keyword(keywords::Mut);\n \n         let ident = try!(self.parse_ident());\n         try!(self.expect(&token::Colon));\n@@ -5306,7 +5311,7 @@ impl<'a> Parser<'a> {\n                 all_nullary = false;\n                 struct_def = VariantData::Tuple(try!(self.parse_tuple_struct_body(ParsePub::No)),\n                                                 ast::DUMMY_NODE_ID);\n-            } else if try!(self.eat(&token::Eq) ){\n+            } else if self.eat(&token::Eq) {\n                 disr_expr = Some(try!(self.parse_expr()));\n                 any_disr = disr_expr.as_ref().map(|expr| expr.span);\n                 struct_def = VariantData::Unit(ast::DUMMY_NODE_ID);\n@@ -5322,7 +5327,7 @@ impl<'a> Parser<'a> {\n             };\n             variants.push(P(spanned(vlo, self.last_span.hi, vr)));\n \n-            if !try!(self.eat(&token::Comma)) { break; }\n+            if !self.eat(&token::Comma) { break; }\n         }\n         try!(self.expect(&token::CloseDelim(token::Brace)));\n         match any_disr {\n@@ -5353,7 +5358,7 @@ impl<'a> Parser<'a> {\n             token::Literal(token::Str_(s), suf) | token::Literal(token::StrRaw(s, _), suf) => {\n                 let sp = self.span;\n                 self.expect_no_suffix(sp, \"ABI spec\", suf);\n-                try!(self.bump());\n+                self.bump();\n                 match abi::lookup(&s.as_str()) {\n                     Some(abi) => Ok(Some(abi)),\n                     None => {\n@@ -5386,7 +5391,7 @@ impl<'a> Parser<'a> {\n         };\n         match nt_item {\n             Some(mut item) => {\n-                try!(self.bump());\n+                self.bump();\n                 let mut attrs = attrs;\n                 mem::swap(&mut item.attrs, &mut attrs);\n                 item.attrs.extend(attrs);\n@@ -5399,7 +5404,7 @@ impl<'a> Parser<'a> {\n \n         let visibility = try!(self.parse_visibility());\n \n-        if try!(self.eat_keyword(keywords::Use) ){\n+        if self.eat_keyword(keywords::Use) {\n             // USE ITEM\n             let item_ = ItemUse(try!(self.parse_view_path()));\n             try!(self.expect(&token::Semi));\n@@ -5414,14 +5419,14 @@ impl<'a> Parser<'a> {\n             return Ok(Some(item));\n         }\n \n-        if try!(self.eat_keyword(keywords::Extern)) {\n-            if try!(self.eat_keyword(keywords::Crate)) {\n+        if self.eat_keyword(keywords::Extern) {\n+            if self.eat_keyword(keywords::Crate) {\n                 return Ok(Some(try!(self.parse_item_extern_crate(lo, visibility, attrs))));\n             }\n \n             let opt_abi = try!(self.parse_opt_abi());\n \n-            if try!(self.eat_keyword(keywords::Fn) ){\n+            if self.eat_keyword(keywords::Fn) {\n                 // EXTERN FUNCTION ITEM\n                 let abi = opt_abi.unwrap_or(abi::C);\n                 let (ident, item_, extra_attrs) =\n@@ -5438,12 +5443,12 @@ impl<'a> Parser<'a> {\n                 return Ok(Some(try!(self.parse_item_foreign_mod(lo, opt_abi, visibility, attrs))));\n             }\n \n-            try!(self.expect_one_of(&[], &[]));\n+            try!(self.unexpected());\n         }\n \n-        if try!(self.eat_keyword(keywords::Static) ){\n+        if self.eat_keyword(keywords::Static) {\n             // STATIC ITEM\n-            let m = if try!(self.eat_keyword(keywords::Mut)) {MutMutable} else {MutImmutable};\n+            let m = if self.eat_keyword(keywords::Mut) {MutMutable} else {MutImmutable};\n             let (ident, item_, extra_attrs) = try!(self.parse_item_const(Some(m)));\n             let last_span = self.last_span;\n             let item = self.mk_item(lo,\n@@ -5454,17 +5459,17 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Const) ){\n+        if self.eat_keyword(keywords::Const) {\n             if self.check_keyword(keywords::Fn)\n                 || (self.check_keyword(keywords::Unsafe)\n                     && self.look_ahead(1, |t| t.is_keyword(keywords::Fn))) {\n                 // CONST FUNCTION ITEM\n-                let unsafety = if try!(self.eat_keyword(keywords::Unsafe) ){\n+                let unsafety = if self.eat_keyword(keywords::Unsafe) {\n                     Unsafety::Unsafe\n                 } else {\n                     Unsafety::Normal\n                 };\n-                try!(self.bump());\n+                self.bump();\n                 let (ident, item_, extra_attrs) =\n                     try!(self.parse_item_fn(unsafety, Constness::Const, abi::Rust));\n                 let last_span = self.last_span;\n@@ -5478,7 +5483,7 @@ impl<'a> Parser<'a> {\n             }\n \n             // CONST ITEM\n-            if try!(self.eat_keyword(keywords::Mut) ){\n+            if self.eat_keyword(keywords::Mut) {\n                 let last_span = self.last_span;\n                 self.diagnostic().struct_span_err(last_span, \"const globals cannot be mutable\")\n                                  .fileline_help(last_span, \"did you mean to declare a static?\")\n@@ -5529,7 +5534,7 @@ impl<'a> Parser<'a> {\n         }\n         if self.check_keyword(keywords::Fn) {\n             // FUNCTION ITEM\n-            try!(self.bump());\n+            self.bump();\n             let (ident, item_, extra_attrs) =\n                 try!(self.parse_item_fn(Unsafety::Normal, Constness::NotConst, abi::Rust));\n             let last_span = self.last_span;\n@@ -5544,8 +5549,8 @@ impl<'a> Parser<'a> {\n         if self.check_keyword(keywords::Unsafe)\n             && self.look_ahead(1, |t| *t != token::OpenDelim(token::Brace)) {\n             // UNSAFE FUNCTION ITEM\n-            try!(self.bump());\n-            let abi = if try!(self.eat_keyword(keywords::Extern) ){\n+            self.bump();\n+            let abi = if self.eat_keyword(keywords::Extern) {\n                 try!(self.parse_opt_abi()).unwrap_or(abi::C)\n             } else {\n                 abi::Rust\n@@ -5562,7 +5567,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Mod) ){\n+        if self.eat_keyword(keywords::Mod) {\n             // MODULE ITEM\n             let (ident, item_, extra_attrs) =\n                 try!(self.parse_item_mod(&attrs[..]));\n@@ -5575,7 +5580,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Type) ){\n+        if self.eat_keyword(keywords::Type) {\n             // TYPE ITEM\n             let (ident, item_, extra_attrs) = try!(self.parse_item_type());\n             let last_span = self.last_span;\n@@ -5587,7 +5592,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Enum) ){\n+        if self.eat_keyword(keywords::Enum) {\n             // ENUM ITEM\n             let (ident, item_, extra_attrs) = try!(self.parse_item_enum());\n             let last_span = self.last_span;\n@@ -5599,7 +5604,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Trait) ){\n+        if self.eat_keyword(keywords::Trait) {\n             // TRAIT ITEM\n             let (ident, item_, extra_attrs) =\n                 try!(self.parse_item_trait(ast::Unsafety::Normal));\n@@ -5612,7 +5617,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Impl) ){\n+        if self.eat_keyword(keywords::Impl) {\n             // IMPL ITEM\n             let (ident, item_, extra_attrs) = try!(self.parse_item_impl(ast::Unsafety::Normal));\n             let last_span = self.last_span;\n@@ -5624,7 +5629,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return Ok(Some(item));\n         }\n-        if try!(self.eat_keyword(keywords::Struct) ){\n+        if self.eat_keyword(keywords::Struct) {\n             // STRUCT ITEM\n             let (ident, item_, extra_attrs) = try!(self.parse_item_struct());\n             let last_span = self.last_span;\n@@ -5708,7 +5713,7 @@ impl<'a> Parser<'a> {\n                                                          self.last_span.hi) };\n \n             if delim != token::Brace {\n-                if !try!(self.eat(&token::Semi) ){\n+                if !self.eat(&token::Semi) {\n                     let last_span = self.last_span;\n                     self.span_err(last_span,\n                                   \"macros that expand to items must either \\\n@@ -5759,7 +5764,7 @@ impl<'a> Parser<'a> {\n \n         // Allow a leading :: because the paths are absolute either way.\n         // This occurs with \"use $crate::...\" in macros.\n-        try!(self.eat(&token::ModSep));\n+        self.eat(&token::ModSep);\n \n         if self.check(&token::OpenDelim(token::Brace)) {\n             // use {foo,bar}\n@@ -5781,7 +5786,7 @@ impl<'a> Parser<'a> {\n         if let token::ModSep = self.token {\n             // foo::bar or foo::{a,b,c} or foo::*\n             while self.check(&token::ModSep) {\n-                try!(self.bump());\n+                self.bump();\n \n                 match self.token {\n                   token::Ident(..) => {\n@@ -5812,7 +5817,7 @@ impl<'a> Parser<'a> {\n \n                   // foo::bar::*\n                   token::BinOp(token::Star) => {\n-                    try!(self.bump());\n+                    self.bump();\n                     let path = ast::Path {\n                         span: mk_sp(lo, self.span.hi),\n                         global: false,\n@@ -5851,7 +5856,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_rename(&mut self) -> PResult<'a, Option<Ident>> {\n-        if try!(self.eat_keyword(keywords::As)) {\n+        if self.eat_keyword(keywords::As) {\n             self.parse_ident().map(Some)\n         } else {\n             Ok(None)\n@@ -5872,24 +5877,24 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_optional_str(&mut self)\n-                              -> PResult<'a, Option<(InternedString,\n-                                                 ast::StrStyle,\n-                                                 Option<ast::Name>)>> {\n+                              -> Option<(InternedString,\n+                                         ast::StrStyle,\n+                                         Option<ast::Name>)> {\n         let ret = match self.token {\n             token::Literal(token::Str_(s), suf) => {\n                 (self.id_to_interned_str(ast::Ident::with_empty_ctxt(s)), ast::CookedStr, suf)\n             }\n             token::Literal(token::StrRaw(s, n), suf) => {\n                 (self.id_to_interned_str(ast::Ident::with_empty_ctxt(s)), ast::RawStr(n), suf)\n             }\n-            _ => return Ok(None)\n+            _ => return None\n         };\n-        try!(self.bump());\n-        Ok(Some(ret))\n+        self.bump();\n+        Some(ret)\n     }\n \n     pub fn parse_str(&mut self) -> PResult<'a, (InternedString, StrStyle)> {\n-        match try!(self.parse_optional_str()) {\n+        match self.parse_optional_str() {\n             Some((s, style, suf)) => {\n                 let sp = self.last_span;\n                 self.expect_no_suffix(sp, \"string literal\", suf);"}, {"sha": "2f50f610d2be498674637174c6763de6d4b758b2", "filename": "src/libsyntax_ext/asm.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax_ext%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax_ext%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fasm.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -113,7 +113,7 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                       p.token != token::ModSep {\n \n                     if !outputs.is_empty() {\n-                        panictry!(p.eat(&token::Comma));\n+                        p.eat(&token::Comma);\n                     }\n \n                     let (constraint, _str_style) = panictry!(p.parse_str());\n@@ -159,7 +159,7 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                       p.token != token::ModSep {\n \n                     if !inputs.is_empty() {\n-                        panictry!(p.eat(&token::Comma));\n+                        p.eat(&token::Comma);\n                     }\n \n                     let (constraint, _str_style) = panictry!(p.parse_str());\n@@ -183,7 +183,7 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                       p.token != token::ModSep {\n \n                     if !clobs.is_empty() {\n-                        panictry!(p.eat(&token::Comma));\n+                        p.eat(&token::Comma);\n                     }\n \n                     let (s, _str_style) = panictry!(p.parse_str());\n@@ -210,7 +210,7 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                 }\n \n                 if p.token == token::Comma {\n-                    panictry!(p.eat(&token::Comma));\n+                    p.eat(&token::Comma);\n                 }\n             }\n             StateNone => ()\n@@ -222,12 +222,12 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n             match (&p.token, state.next(), state.next().next()) {\n                 (&token::Colon, StateNone, _)   |\n                 (&token::ModSep, _, StateNone) => {\n-                    panictry!(p.bump());\n+                    p.bump();\n                     break 'statement;\n                 }\n                 (&token::Colon, st, _)   |\n                 (&token::ModSep, _, st) => {\n-                    panictry!(p.bump());\n+                    p.bump();\n                     state = st;\n                 }\n                 (&token::Eof, _, _) => break 'statement,"}, {"sha": "bae0462b8d33044f3141bffa53e22468a891c75e", "filename": "src/libsyntax_ext/cfg.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax_ext%2Fcfg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax_ext%2Fcfg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fcfg.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -28,7 +28,7 @@ pub fn expand_cfg<'cx>(cx: &mut ExtCtxt,\n     let mut p = cx.new_parser_from_tts(tts);\n     let cfg = panictry!(p.parse_meta_item());\n \n-    if !panictry!(p.eat(&token::Eof)){\n+    if !p.eat(&token::Eof) {\n         cx.span_err(sp, \"expected 1 cfg-pattern\");\n         return DummyResult::expr(sp);\n     }"}, {"sha": "1fb2b55215deda3893057d63276399cf2d6f0161", "filename": "src/libsyntax_ext/format.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax_ext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Flibsyntax_ext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fformat.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -98,7 +98,7 @@ fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     let fmtstr = panictry!(p.parse_expr());\n     let mut named = false;\n     while p.token != token::Eof {\n-        if !panictry!(p.eat(&token::Comma)) {\n+        if !p.eat(&token::Comma) {\n             ecx.span_err(sp, \"expected token: `,`\");\n             return None;\n         }\n@@ -107,7 +107,7 @@ fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n             named = true;\n             let ident = match p.token {\n                 token::Ident(i, _) => {\n-                    panictry!(p.bump());\n+                    p.bump();\n                     i\n                 }\n                 _ if named => {"}, {"sha": "8fa5e0a70890ed2abf328ea6559dcdd5ec152fe2", "filename": "src/test/compile-fail/macro-context.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Ftest%2Fcompile-fail%2Fmacro-context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Ftest%2Fcompile-fail%2Fmacro-context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fmacro-context.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -13,7 +13,6 @@\n // (typeof used because it's surprisingly hard to find an unparsed token after a stmt)\n macro_rules! m {\n     () => ( i ; typeof );   //~ ERROR `typeof` is a reserved keyword\n-                            //~| ERROR macro expansion ignores token `typeof`\n                             //~| ERROR macro expansion ignores token `typeof`\n                             //~| ERROR macro expansion ignores token `;`\n                             //~| ERROR macro expansion ignores token `;`\n@@ -29,5 +28,5 @@ fn main() {\n         m!() => {}  //~ NOTE the usage of `m!` is likely invalid in pattern context\n     }\n \n-    m!();           //~ NOTE the usage of `m!` is likely invalid in statement context\n+    m!();\n }"}, {"sha": "1ef8cd2714d7f4124d134384e44904bd9dc21c08", "filename": "src/test/parse-fail/obsolete-proc.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Ftest%2Fparse-fail%2Fobsolete-proc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9023c659af8a43dd5e284d7b311e5f19721c9bd8/src%2Ftest%2Fparse-fail%2Fobsolete-proc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fparse-fail%2Fobsolete-proc.rs?ref=9023c659af8a43dd5e284d7b311e5f19721c9bd8", "patch": "@@ -14,6 +14,7 @@\n \n fn foo(p: proc()) { } //~ ERROR `proc` is a reserved keyword\n \n-fn bar() { proc() 1; }\n+fn bar() { proc() 1; } //~ ERROR `proc` is a reserved keyword\n+                       //~^ ERROR expected\n \n fn main() { }"}]}