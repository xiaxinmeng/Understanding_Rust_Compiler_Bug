{"sha": "7b5715289f813460ac95189fb7d3479e8edd23eb", "node_id": "C_kwDOAAsO6NoAKDdiNTcxNTI4OWY4MTM0NjBhYzk1MTg5ZmI3ZDM0NzllOGVkZDIzZWI", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-13T02:43:25Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-07-13T02:43:25Z"}, "message": "Auto merge of #99101 - RalfJung:interpret-projections, r=oli-obk\n\ninterpret: refactor projection handling code\n\nMoves our projection handling code into a common file, and avoids the use of a\ngeneral mplace-based fallback function by have more specialized implementations.\n\nmplace_index (and the other slice-related functions) could be more efficient by\ncopy-pasting the body of operand_index. Or we could do some trait magic to share\nthe code between them. But for now this is probably fine.\n\nThis is the common part of https://github.com/rust-lang/rust/pull/99013 and https://github.com/rust-lang/rust/pull/99097. I am seeing some strange perf results so this probably should be its own change so we know which diff caused which perf changes...\n\nr? `@oli-obk`", "tree": {"sha": "8b1150568dd638cb9b2a47c58294f4035db80c53", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8b1150568dd638cb9b2a47c58294f4035db80c53"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7b5715289f813460ac95189fb7d3479e8edd23eb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7b5715289f813460ac95189fb7d3479e8edd23eb", "html_url": "https://github.com/rust-lang/rust/commit/7b5715289f813460ac95189fb7d3479e8edd23eb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7b5715289f813460ac95189fb7d3479e8edd23eb/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1c7b36d4db582cb47513a6c7176baaec1c3346ab", "url": "https://api.github.com/repos/rust-lang/rust/commits/1c7b36d4db582cb47513a6c7176baaec1c3346ab", "html_url": "https://github.com/rust-lang/rust/commit/1c7b36d4db582cb47513a6c7176baaec1c3346ab"}, {"sha": "04b3cd9f7c8366490590d839ab814d03406eed4a", "url": "https://api.github.com/repos/rust-lang/rust/commits/04b3cd9f7c8366490590d839ab814d03406eed4a", "html_url": "https://github.com/rust-lang/rust/commit/04b3cd9f7c8366490590d839ab814d03406eed4a"}], "stats": {"total": 972, "additions": 540, "deletions": 432}, "files": [{"sha": "2e356f67bf36f70c273bad3fd8278cb99208bfc9", "filename": "compiler/rustc_const_eval/src/interpret/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fmod.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -9,6 +9,7 @@ mod memory;\n mod operand;\n mod operator;\n mod place;\n+mod projection;\n mod step;\n mod terminator;\n mod traits;"}, {"sha": "1465b986293452efa3c8201ebe4e0ae9609dc85b", "filename": "compiler/rustc_const_eval/src/interpret/operand.rs", "status": "modified", "additions": 79, "deletions": 133, "changes": 212, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Foperand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Foperand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Foperand.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -1,7 +1,6 @@\n //! Functions concerning immediate values and operands, and reading from operands.\n //! All high-level functions to read from memory work on operands as sources.\n \n-use std::convert::TryFrom;\n use std::fmt::Write;\n \n use rustc_hir::def::Namespace;\n@@ -15,7 +14,7 @@ use rustc_target::abi::{VariantIdx, Variants};\n \n use super::{\n     alloc_range, from_known_layout, mir_assign_valid_types, AllocId, ConstValue, Frame, GlobalId,\n-    InterpCx, InterpResult, MPlaceTy, Machine, MemPlace, Place, PlaceTy, Pointer,\n+    InterpCx, InterpResult, MPlaceTy, Machine, MemPlace, MemPlaceMeta, Place, PlaceTy, Pointer,\n     PointerArithmetic, Provenance, Scalar, ScalarMaybeUninit,\n };\n \n@@ -253,6 +252,11 @@ impl<'tcx, Tag: Provenance> ImmTy<'tcx, Tag> {\n         ImmTy { imm, layout }\n     }\n \n+    #[inline]\n+    pub fn uninit(layout: TyAndLayout<'tcx>) -> Self {\n+        ImmTy { imm: Immediate::Uninit, layout }\n+    }\n+\n     #[inline]\n     pub fn try_from_uint(i: impl Into<u128>, layout: TyAndLayout<'tcx>) -> Option<Self> {\n         Some(Self::from_scalar(Scalar::try_from_uint(i, layout.size)?, layout))\n@@ -280,6 +284,41 @@ impl<'tcx, Tag: Provenance> ImmTy<'tcx, Tag> {\n     }\n }\n \n+impl<'tcx, Tag: Provenance> OpTy<'tcx, Tag> {\n+    pub fn len(&self, cx: &impl HasDataLayout) -> InterpResult<'tcx, u64> {\n+        if self.layout.is_unsized() {\n+            // There are no unsized immediates.\n+            self.assert_mem_place().len(cx)\n+        } else {\n+            match self.layout.fields {\n+                abi::FieldsShape::Array { count, .. } => Ok(count),\n+                _ => bug!(\"len not supported on sized type {:?}\", self.layout.ty),\n+            }\n+        }\n+    }\n+\n+    pub fn offset(\n+        &self,\n+        offset: Size,\n+        meta: MemPlaceMeta<Tag>,\n+        layout: TyAndLayout<'tcx>,\n+        cx: &impl HasDataLayout,\n+    ) -> InterpResult<'tcx, Self> {\n+        match self.try_as_mplace() {\n+            Ok(mplace) => Ok(mplace.offset(offset, meta, layout, cx)?.into()),\n+            Err(imm) => {\n+                assert!(\n+                    matches!(*imm, Immediate::Uninit),\n+                    \"Scalar/ScalarPair cannot be offset into\"\n+                );\n+                assert!(!meta.has_meta()); // no place to store metadata here\n+                // Every part of an uninit is uninit.\n+                Ok(ImmTy::uninit(layout).into())\n+            }\n+        }\n+    }\n+}\n+\n impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n     /// Try reading an immediate in memory; this is interesting particularly for `ScalarPair`.\n     /// Returns `None` if the layout does not permit loading this as a value.\n@@ -296,11 +335,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         }\n \n         let Some(alloc) = self.get_place_alloc(mplace)? else {\n-            return Ok(Some(ImmTy {\n-                // zero-sized type can be left uninit\n-                imm: Immediate::Uninit,\n-                layout: mplace.layout,\n-            }));\n+            // zero-sized type can be left uninit\n+            return Ok(Some(ImmTy::uninit(mplace.layout)));\n         };\n \n         // It may seem like all types with `Scalar` or `ScalarPair` ABI are fair game at this point.\n@@ -367,6 +403,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n     /// This flag exists only for validity checking.\n     ///\n     /// This is an internal function that should not usually be used; call `read_immediate` instead.\n+    /// ConstProp needs it, though.\n     pub fn read_immediate_raw(\n         &self,\n         src: &OpTy<'tcx, M::PointerTag>,\n@@ -421,123 +458,28 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         Ok(str)\n     }\n \n-    /// Projection functions\n-    pub fn operand_field(\n-        &self,\n-        op: &OpTy<'tcx, M::PointerTag>,\n-        field: usize,\n-    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n-        let base = match op.try_as_mplace() {\n-            Ok(ref mplace) => {\n-                // We can reuse the mplace field computation logic for indirect operands.\n-                let field = self.mplace_field(mplace, field)?;\n-                return Ok(field.into());\n-            }\n-            Err(value) => value,\n-        };\n-\n-        let field_layout = base.layout.field(self, field);\n-        let offset = base.layout.fields.offset(field);\n-        // This makes several assumptions about what layouts we will encounter; we match what\n-        // codegen does as good as we can (see `extract_field` in `rustc_codegen_ssa/src/mir/operand.rs`).\n-        let field_val: Immediate<_> = match (*base, base.layout.abi) {\n-            // the field contains no information, can be left uninit\n-            _ if field_layout.is_zst() => Immediate::Uninit,\n-            // the field covers the entire type\n-            _ if field_layout.size == base.layout.size => {\n-                assert!(match (base.layout.abi, field_layout.abi) {\n-                    (Abi::Scalar(..), Abi::Scalar(..)) => true,\n-                    (Abi::ScalarPair(..), Abi::ScalarPair(..)) => true,\n-                    _ => false,\n-                });\n-                assert!(offset.bytes() == 0);\n-                *base\n-            }\n-            // extract fields from types with `ScalarPair` ABI\n-            (Immediate::ScalarPair(a_val, b_val), Abi::ScalarPair(a, b)) => {\n-                assert!(matches!(field_layout.abi, Abi::Scalar(..)));\n-                Immediate::from(if offset.bytes() == 0 {\n-                    debug_assert_eq!(field_layout.size, a.size(self));\n-                    a_val\n-                } else {\n-                    debug_assert_eq!(offset, a.size(self).align_to(b.align(self).abi));\n-                    debug_assert_eq!(field_layout.size, b.size(self));\n-                    b_val\n-                })\n-            }\n-            _ => span_bug!(\n-                self.cur_span(),\n-                \"invalid field access on immediate {}, layout {:#?}\",\n-                base,\n-                base.layout\n-            ),\n-        };\n-\n-        Ok(OpTy { op: Operand::Immediate(field_val), layout: field_layout, align: None })\n-    }\n-\n-    pub fn operand_index(\n-        &self,\n-        op: &OpTy<'tcx, M::PointerTag>,\n-        index: u64,\n-    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n-        if let Ok(index) = usize::try_from(index) {\n-            // We can just treat this as a field.\n-            self.operand_field(op, index)\n-        } else {\n-            // Indexing into a big array. This must be an mplace.\n-            let mplace = op.assert_mem_place();\n-            Ok(self.mplace_index(&mplace, index)?.into())\n-        }\n-    }\n-\n-    pub fn operand_downcast(\n-        &self,\n-        op: &OpTy<'tcx, M::PointerTag>,\n-        variant: VariantIdx,\n-    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n-        Ok(match op.try_as_mplace() {\n-            Ok(ref mplace) => self.mplace_downcast(mplace, variant)?.into(),\n-            Err(..) => {\n-                // Downcasts only change the layout.\n-                // (In particular, no check about whether this is even the active variant -- that's by design,\n-                // see https://github.com/rust-lang/rust/issues/93688#issuecomment-1032929496.)\n-                let layout = op.layout.for_variant(self, variant);\n-                OpTy { layout, ..*op }\n-            }\n-        })\n-    }\n-\n-    #[instrument(skip(self), level = \"debug\")]\n-    pub fn operand_projection(\n-        &self,\n-        base: &OpTy<'tcx, M::PointerTag>,\n-        proj_elem: mir::PlaceElem<'tcx>,\n-    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n-        use rustc_middle::mir::ProjectionElem::*;\n-        Ok(match proj_elem {\n-            Field(field, _) => self.operand_field(base, field.index())?,\n-            Downcast(_, variant) => self.operand_downcast(base, variant)?,\n-            Deref => self.deref_operand(base)?.into(),\n-            Subslice { .. } | ConstantIndex { .. } | Index(_) => {\n-                // The rest should only occur as mplace, we do not use Immediates for types\n-                // allowing such operations.  This matches place_projection forcing an allocation.\n-                let mplace = base.assert_mem_place();\n-                self.mplace_projection(&mplace, proj_elem)?.into()\n-            }\n-        })\n-    }\n-\n     /// Converts a repr(simd) operand into an operand where `place_index` accesses the SIMD elements.\n     /// Also returns the number of elements.\n+    ///\n+    /// Can (but does not always) trigger UB if `op` is uninitialized.\n     pub fn operand_to_simd(\n         &self,\n-        base: &OpTy<'tcx, M::PointerTag>,\n+        op: &OpTy<'tcx, M::PointerTag>,\n     ) -> InterpResult<'tcx, (MPlaceTy<'tcx, M::PointerTag>, u64)> {\n         // Basically we just transmute this place into an array following simd_size_and_type.\n         // This only works in memory, but repr(simd) types should never be immediates anyway.\n-        assert!(base.layout.ty.is_simd());\n-        self.mplace_to_simd(&base.assert_mem_place())\n+        assert!(op.layout.ty.is_simd());\n+        match op.try_as_mplace() {\n+            Ok(mplace) => self.mplace_to_simd(&mplace),\n+            Err(imm) => match *imm {\n+                Immediate::Uninit => {\n+                    throw_ub!(InvalidUninitBytes(None))\n+                }\n+                Immediate::Scalar(..) | Immediate::ScalarPair(..) => {\n+                    bug!(\"arrays/slices can never have Scalar/ScalarPair layout\")\n+                }\n+            },\n+        }\n     }\n \n     /// Read from a local. Will not actually access the local if reading from a ZST.\n@@ -582,30 +524,34 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n     /// avoid allocations.\n     pub fn eval_place_to_op(\n         &self,\n-        place: mir::Place<'tcx>,\n+        mir_place: mir::Place<'tcx>,\n         layout: Option<TyAndLayout<'tcx>>,\n     ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n         // Do not use the layout passed in as argument if the base we are looking at\n         // here is not the entire place.\n-        let layout = if place.projection.is_empty() { layout } else { None };\n+        let layout = if mir_place.projection.is_empty() { layout } else { None };\n \n-        let base_op = self.local_to_op(self.frame(), place.local, layout)?;\n-\n-        let op = place\n-            .projection\n-            .iter()\n-            .try_fold(base_op, |op, elem| self.operand_projection(&op, elem))?;\n+        let mut op = self.local_to_op(self.frame(), mir_place.local, layout)?;\n+        // Using `try_fold` turned out to be bad for performance, hence the loop.\n+        for elem in mir_place.projection.iter() {\n+            op = self.operand_projection(&op, elem)?\n+        }\n \n         trace!(\"eval_place_to_op: got {:?}\", *op);\n         // Sanity-check the type we ended up with.\n-        debug_assert!(mir_assign_valid_types(\n-            *self.tcx,\n-            self.param_env,\n-            self.layout_of(self.subst_from_current_frame_and_normalize_erasing_regions(\n-                place.ty(&self.frame().body.local_decls, *self.tcx).ty\n-            )?)?,\n-            op.layout,\n-        ));\n+        debug_assert!(\n+            mir_assign_valid_types(\n+                *self.tcx,\n+                self.param_env,\n+                self.layout_of(self.subst_from_current_frame_and_normalize_erasing_regions(\n+                    mir_place.ty(&self.frame().body.local_decls, *self.tcx).ty\n+                )?)?,\n+                op.layout,\n+            ),\n+            \"eval_place of a MIR place with type {:?} produced an interpreter operand with type {:?}\",\n+            mir_place.ty(&self.frame().body.local_decls, *self.tcx).ty,\n+            op.layout.ty,\n+        );\n         Ok(op)\n     }\n "}, {"sha": "2001359d199cf7f6c8bd4f535e35059747e8da46", "filename": "compiler/rustc_const_eval/src/interpret/place.rs", "status": "modified", "additions": 31, "deletions": 279, "changes": 310, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fplace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fplace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fplace.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -2,17 +2,14 @@\n //! into a place.\n //! All high-level functions to write to memory work on places as destinations.\n \n-use std::convert::TryFrom;\n use std::hash::Hash;\n \n use rustc_ast::Mutability;\n use rustc_macros::HashStable;\n use rustc_middle::mir;\n+use rustc_middle::ty;\n use rustc_middle::ty::layout::{LayoutOf, PrimitiveExt, TyAndLayout};\n-use rustc_middle::ty::{self, Ty};\n-use rustc_target::abi::{\n-    Abi, Align, FieldsShape, HasDataLayout, Size, TagEncoding, VariantIdx, Variants,\n-};\n+use rustc_target::abi::{self, Abi, Align, HasDataLayout, Size, TagEncoding, VariantIdx};\n \n use super::{\n     alloc_range, mir_assign_valid_types, AllocId, AllocRef, AllocRefMut, CheckInAllocMsg,\n@@ -46,7 +43,7 @@ impl<Tag: Provenance> MemPlaceMeta<Tag> {\n             }\n         }\n     }\n-    fn has_meta(self) -> bool {\n+    pub fn has_meta(self) -> bool {\n         match self {\n             Self::Meta(_) => true,\n             Self::None | Self::Poison => false,\n@@ -188,6 +185,7 @@ impl<Tag: Provenance> Place<Tag> {\n     /// Asserts that this points to some local variable.\n     /// Returns the frame idx and the variable idx.\n     #[inline]\n+    #[cfg_attr(debug_assertions, track_caller)] // only in debug builds due to perf (see #98980)\n     pub fn assert_local(&self) -> (usize, mir::Local) {\n         match self {\n             Place::Local { frame, local } => (*frame, *local),\n@@ -250,7 +248,7 @@ impl<'tcx, Tag: Provenance> MPlaceTy<'tcx, Tag> {\n             // Go through the layout.  There are lots of types that support a length,\n             // e.g., SIMD types. (But not all repr(simd) types even have FieldsShape::Array!)\n             match self.layout.fields {\n-                FieldsShape::Array { count, .. } => Ok(count),\n+                abi::FieldsShape::Array { count, .. } => Ok(count),\n                 _ => bug!(\"len not supported on sized type {:?}\", self.layout.ty),\n             }\n         }\n@@ -281,6 +279,7 @@ impl<'tcx, Tag: Provenance> OpTy<'tcx, Tag> {\n     }\n \n     #[inline(always)]\n+    #[cfg_attr(debug_assertions, track_caller)] // only in debug builds due to perf (see #98980)\n     /// Note: do not call `as_ref` on the resulting place. This function should only be used to\n     /// read from the resulting mplace, not to get its address back.\n     pub fn assert_mem_place(&self) -> MPlaceTy<'tcx, Tag> {\n@@ -298,16 +297,16 @@ impl<'tcx, Tag: Provenance> PlaceTy<'tcx, Tag> {\n         }\n     }\n \n-    #[inline]\n-    pub fn assert_mem_place(&self) -> MPlaceTy<'tcx, Tag> {\n+    #[inline(always)]\n+    #[cfg_attr(debug_assertions, track_caller)] // only in debug builds due to perf (see #98980)\n+    pub fn assert_mem_place(self) -> MPlaceTy<'tcx, Tag> {\n         self.try_as_mplace().unwrap()\n     }\n }\n \n-// separating the pointer tag for `impl Trait`, see https://github.com/rust-lang/rust/issues/54385\n+// FIXME: Working around https://github.com/rust-lang/rust/issues/54385\n impl<'mir, 'tcx: 'mir, Tag, M> InterpCx<'mir, 'tcx, M>\n where\n-    // FIXME: Working around https://github.com/rust-lang/rust/issues/54385\n     Tag: Provenance + Eq + Hash + 'static,\n     M: Machine<'mir, 'tcx, PointerTag = Tag>,\n {\n@@ -392,276 +391,29 @@ where\n         Ok(())\n     }\n \n-    /// Offset a pointer to project to a field of a struct/union. Unlike `place_field`, this is\n-    /// always possible without allocating, so it can take `&self`. Also return the field's layout.\n-    /// This supports both struct and array fields.\n-    ///\n-    /// This also works for arrays, but then the `usize` index type is restricting.\n-    /// For indexing into arrays, use `mplace_index`.\n-    #[inline(always)]\n-    pub fn mplace_field(\n-        &self,\n-        base: &MPlaceTy<'tcx, M::PointerTag>,\n-        field: usize,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n-        let offset = base.layout.fields.offset(field);\n-        let field_layout = base.layout.field(self, field);\n-\n-        // Offset may need adjustment for unsized fields.\n-        let (meta, offset) = if field_layout.is_unsized() {\n-            // Re-use parent metadata to determine dynamic field layout.\n-            // With custom DSTS, this *will* execute user-defined code, but the same\n-            // happens at run-time so that's okay.\n-            match self.size_and_align_of(&base.meta, &field_layout)? {\n-                Some((_, align)) => (base.meta, offset.align_to(align)),\n-                None => {\n-                    // For unsized types with an extern type tail we perform no adjustments.\n-                    // NOTE: keep this in sync with `PlaceRef::project_field` in the codegen backend.\n-                    assert!(matches!(base.meta, MemPlaceMeta::None));\n-                    (base.meta, offset)\n-                }\n-            }\n-        } else {\n-            // base.meta could be present; we might be accessing a sized field of an unsized\n-            // struct.\n-            (MemPlaceMeta::None, offset)\n-        };\n-\n-        // We do not look at `base.layout.align` nor `field_layout.align`, unlike\n-        // codegen -- mostly to see if we can get away with that\n-        base.offset(offset, meta, field_layout, self)\n-    }\n-\n-    /// Index into an array.\n-    #[inline(always)]\n-    pub fn mplace_index(\n-        &self,\n-        base: &MPlaceTy<'tcx, M::PointerTag>,\n-        index: u64,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n-        // Not using the layout method because we want to compute on u64\n-        match base.layout.fields {\n-            FieldsShape::Array { stride, .. } => {\n-                let len = base.len(self)?;\n-                if index >= len {\n-                    // This can only be reached in ConstProp and non-rustc-MIR.\n-                    throw_ub!(BoundsCheckFailed { len, index });\n-                }\n-                let offset = stride * index; // `Size` multiplication\n-                // All fields have the same layout.\n-                let field_layout = base.layout.field(self, 0);\n-\n-                assert!(!field_layout.is_unsized());\n-                base.offset(offset, MemPlaceMeta::None, field_layout, self)\n-            }\n-            _ => span_bug!(\n-                self.cur_span(),\n-                \"`mplace_index` called on non-array type {:?}\",\n-                base.layout.ty\n-            ),\n-        }\n-    }\n-\n-    // Iterates over all fields of an array. Much more efficient than doing the\n-    // same by repeatedly calling `mplace_array`.\n-    pub(super) fn mplace_array_fields<'a>(\n-        &self,\n-        base: &'a MPlaceTy<'tcx, Tag>,\n-    ) -> InterpResult<'tcx, impl Iterator<Item = InterpResult<'tcx, MPlaceTy<'tcx, Tag>>> + 'a>\n-    {\n-        let len = base.len(self)?; // also asserts that we have a type where this makes sense\n-        let FieldsShape::Array { stride, .. } = base.layout.fields else {\n-            span_bug!(self.cur_span(), \"mplace_array_fields: expected an array layout\");\n-        };\n-        let layout = base.layout.field(self, 0);\n-        let dl = &self.tcx.data_layout;\n-        // `Size` multiplication\n-        Ok((0..len).map(move |i| base.offset(stride * i, MemPlaceMeta::None, layout, dl)))\n-    }\n-\n-    fn mplace_subslice(\n-        &self,\n-        base: &MPlaceTy<'tcx, M::PointerTag>,\n-        from: u64,\n-        to: u64,\n-        from_end: bool,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n-        let len = base.len(self)?; // also asserts that we have a type where this makes sense\n-        let actual_to = if from_end {\n-            if from.checked_add(to).map_or(true, |to| to > len) {\n-                // This can only be reached in ConstProp and non-rustc-MIR.\n-                throw_ub!(BoundsCheckFailed { len: len, index: from.saturating_add(to) });\n-            }\n-            len.checked_sub(to).unwrap()\n-        } else {\n-            to\n-        };\n-\n-        // Not using layout method because that works with usize, and does not work with slices\n-        // (that have count 0 in their layout).\n-        let from_offset = match base.layout.fields {\n-            FieldsShape::Array { stride, .. } => stride * from, // `Size` multiplication is checked\n-            _ => {\n-                span_bug!(self.cur_span(), \"unexpected layout of index access: {:#?}\", base.layout)\n-            }\n-        };\n-\n-        // Compute meta and new layout\n-        let inner_len = actual_to.checked_sub(from).unwrap();\n-        let (meta, ty) = match base.layout.ty.kind() {\n-            // It is not nice to match on the type, but that seems to be the only way to\n-            // implement this.\n-            ty::Array(inner, _) => (MemPlaceMeta::None, self.tcx.mk_array(*inner, inner_len)),\n-            ty::Slice(..) => {\n-                let len = Scalar::from_machine_usize(inner_len, self);\n-                (MemPlaceMeta::Meta(len), base.layout.ty)\n-            }\n-            _ => {\n-                span_bug!(self.cur_span(), \"cannot subslice non-array type: `{:?}`\", base.layout.ty)\n-            }\n-        };\n-        let layout = self.layout_of(ty)?;\n-        base.offset(from_offset, meta, layout, self)\n-    }\n-\n-    pub(crate) fn mplace_downcast(\n-        &self,\n-        base: &MPlaceTy<'tcx, M::PointerTag>,\n-        variant: VariantIdx,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n-        // Downcasts only change the layout.\n-        // (In particular, no check about whether this is even the active variant -- that's by design,\n-        // see https://github.com/rust-lang/rust/issues/93688#issuecomment-1032929496.)\n-        assert!(!base.meta.has_meta());\n-        Ok(MPlaceTy { layout: base.layout.for_variant(self, variant), ..*base })\n-    }\n-\n-    /// Project into an mplace\n-    #[instrument(skip(self), level = \"debug\")]\n-    pub(super) fn mplace_projection(\n-        &self,\n-        base: &MPlaceTy<'tcx, M::PointerTag>,\n-        proj_elem: mir::PlaceElem<'tcx>,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n-        use rustc_middle::mir::ProjectionElem::*;\n-        Ok(match proj_elem {\n-            Field(field, _) => self.mplace_field(base, field.index())?,\n-            Downcast(_, variant) => self.mplace_downcast(base, variant)?,\n-            Deref => self.deref_operand(&base.into())?,\n-\n-            Index(local) => {\n-                let layout = self.layout_of(self.tcx.types.usize)?;\n-                let n = self.local_to_op(self.frame(), local, Some(layout))?;\n-                let n = self.read_scalar(&n)?;\n-                let n = n.to_machine_usize(self)?;\n-                self.mplace_index(base, n)?\n-            }\n-\n-            ConstantIndex { offset, min_length, from_end } => {\n-                let n = base.len(self)?;\n-                if n < min_length {\n-                    // This can only be reached in ConstProp and non-rustc-MIR.\n-                    throw_ub!(BoundsCheckFailed { len: min_length, index: n });\n-                }\n-\n-                let index = if from_end {\n-                    assert!(0 < offset && offset <= min_length);\n-                    n.checked_sub(offset).unwrap()\n-                } else {\n-                    assert!(offset < min_length);\n-                    offset\n-                };\n-\n-                self.mplace_index(base, index)?\n-            }\n-\n-            Subslice { from, to, from_end } => self.mplace_subslice(base, from, to, from_end)?,\n-        })\n-    }\n-\n     /// Converts a repr(simd) place into a place where `place_index` accesses the SIMD elements.\n     /// Also returns the number of elements.\n     pub fn mplace_to_simd(\n         &self,\n-        base: &MPlaceTy<'tcx, M::PointerTag>,\n+        mplace: &MPlaceTy<'tcx, M::PointerTag>,\n     ) -> InterpResult<'tcx, (MPlaceTy<'tcx, M::PointerTag>, u64)> {\n         // Basically we just transmute this place into an array following simd_size_and_type.\n         // (Transmuting is okay since this is an in-memory place. We also double-check the size\n         // stays the same.)\n-        let (len, e_ty) = base.layout.ty.simd_size_and_type(*self.tcx);\n+        let (len, e_ty) = mplace.layout.ty.simd_size_and_type(*self.tcx);\n         let array = self.tcx.mk_array(e_ty, len);\n         let layout = self.layout_of(array)?;\n-        assert_eq!(layout.size, base.layout.size);\n-        Ok((MPlaceTy { layout, ..*base }, len))\n-    }\n-\n-    /// Gets the place of a field inside the place, and also the field's type.\n-    /// Just a convenience function, but used quite a bit.\n-    /// This is the only projection that might have a side-effect: We cannot project\n-    /// into the field of a local `ScalarPair`, we have to first allocate it.\n-    #[instrument(skip(self), level = \"debug\")]\n-    pub fn place_field(\n-        &mut self,\n-        base: &PlaceTy<'tcx, M::PointerTag>,\n-        field: usize,\n-    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n-        // FIXME: We could try to be smarter and avoid allocation for fields that span the\n-        // entire place.\n-        let mplace = self.force_allocation(base)?;\n-        Ok(self.mplace_field(&mplace, field)?.into())\n-    }\n-\n-    pub fn place_index(\n-        &mut self,\n-        base: &PlaceTy<'tcx, M::PointerTag>,\n-        index: u64,\n-    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n-        let mplace = self.force_allocation(base)?;\n-        Ok(self.mplace_index(&mplace, index)?.into())\n-    }\n-\n-    pub fn place_downcast(\n-        &self,\n-        base: &PlaceTy<'tcx, M::PointerTag>,\n-        variant: VariantIdx,\n-    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n-        // Downcast just changes the layout\n-        Ok(match base.try_as_mplace() {\n-            Ok(mplace) => self.mplace_downcast(&mplace, variant)?.into(),\n-            Err(..) => {\n-                let layout = base.layout.for_variant(self, variant);\n-                PlaceTy { layout, ..*base }\n-            }\n-        })\n-    }\n-\n-    /// Projects into a place.\n-    pub fn place_projection(\n-        &mut self,\n-        base: &PlaceTy<'tcx, M::PointerTag>,\n-        &proj_elem: &mir::ProjectionElem<mir::Local, Ty<'tcx>>,\n-    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n-        use rustc_middle::mir::ProjectionElem::*;\n-        Ok(match proj_elem {\n-            Field(field, _) => self.place_field(base, field.index())?,\n-            Downcast(_, variant) => self.place_downcast(base, variant)?,\n-            Deref => self.deref_operand(&self.place_to_op(base)?)?.into(),\n-            // For the other variants, we have to force an allocation.\n-            // This matches `operand_projection`.\n-            Subslice { .. } | ConstantIndex { .. } | Index(_) => {\n-                let mplace = self.force_allocation(base)?;\n-                self.mplace_projection(&mplace, proj_elem)?.into()\n-            }\n-        })\n+        assert_eq!(layout.size, mplace.layout.size);\n+        Ok((MPlaceTy { layout, ..*mplace }, len))\n     }\n \n     /// Converts a repr(simd) place into a place where `place_index` accesses the SIMD elements.\n     /// Also returns the number of elements.\n     pub fn place_to_simd(\n         &mut self,\n-        base: &PlaceTy<'tcx, M::PointerTag>,\n+        place: &PlaceTy<'tcx, M::PointerTag>,\n     ) -> InterpResult<'tcx, (MPlaceTy<'tcx, M::PointerTag>, u64)> {\n-        let mplace = self.force_allocation(base)?;\n+        let mplace = self.force_allocation(place)?;\n         self.mplace_to_simd(&mplace)\n     }\n \n@@ -680,30 +432,30 @@ where\n     #[instrument(skip(self), level = \"debug\")]\n     pub fn eval_place(\n         &mut self,\n-        place: mir::Place<'tcx>,\n+        mir_place: mir::Place<'tcx>,\n     ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n-        let mut place_ty = self.local_to_place(self.frame_idx(), place.local)?;\n-\n-        for elem in place.projection.iter() {\n-            place_ty = self.place_projection(&place_ty, &elem)?\n+        let mut place = self.local_to_place(self.frame_idx(), mir_place.local)?;\n+        // Using `try_fold` turned out to be bad for performance, hence the loop.\n+        for elem in mir_place.projection.iter() {\n+            place = self.place_projection(&place, elem)?\n         }\n \n-        trace!(\"{:?}\", self.dump_place(place_ty.place));\n+        trace!(\"{:?}\", self.dump_place(place.place));\n         // Sanity-check the type we ended up with.\n         debug_assert!(\n             mir_assign_valid_types(\n                 *self.tcx,\n                 self.param_env,\n                 self.layout_of(self.subst_from_current_frame_and_normalize_erasing_regions(\n-                    place.ty(&self.frame().body.local_decls, *self.tcx).ty\n+                    mir_place.ty(&self.frame().body.local_decls, *self.tcx).ty\n                 )?)?,\n-                place_ty.layout,\n+                place.layout,\n             ),\n-            \"eval_place of a MIR place with type {:?} produced an interpret place with type {:?}\",\n-            place.ty(&self.frame().body.local_decls, *self.tcx).ty,\n-            place_ty.layout.ty,\n+            \"eval_place of a MIR place with type {:?} produced an interpreter place with type {:?}\",\n+            mir_place.ty(&self.frame().body.local_decls, *self.tcx).ty,\n+            place.layout.ty,\n         );\n-        Ok(place_ty)\n+        Ok(place)\n     }\n \n     /// Write an immediate to a place\n@@ -1058,10 +810,10 @@ where\n         }\n \n         match dest.layout.variants {\n-            Variants::Single { index } => {\n+            abi::Variants::Single { index } => {\n                 assert_eq!(index, variant_index);\n             }\n-            Variants::Multiple {\n+            abi::Variants::Multiple {\n                 tag_encoding: TagEncoding::Direct,\n                 tag: tag_layout,\n                 tag_field,\n@@ -1082,7 +834,7 @@ where\n                 let tag_dest = self.place_field(dest, tag_field)?;\n                 self.write_scalar(Scalar::from_uint(tag_val, size), &tag_dest)?;\n             }\n-            Variants::Multiple {\n+            abi::Variants::Multiple {\n                 tag_encoding:\n                     TagEncoding::Niche { dataful_variant, ref niche_variants, niche_start },\n                 tag: tag_layout,"}, {"sha": "31fb6a8944df6af11007b946e094f37a0c4ddd45", "filename": "compiler/rustc_const_eval/src/interpret/projection.rs", "status": "added", "additions": 393, "deletions": 0, "changes": 393, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fprojection.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fprojection.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fprojection.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -0,0 +1,393 @@\n+//! This file implements \"place projections\"; basically a symmetric API for 3 types: MPlaceTy, OpTy, PlaceTy.\n+//!\n+//! OpTy and PlaceTy genrally work by \"let's see if we are actually an MPlaceTy, and do something custom if not\".\n+//! For PlaceTy, the custom thing is basically always to call `force_allocation` and then use the MPlaceTy logic anyway.\n+//! For OpTy, the custom thing on field pojections has to be pretty clever (since `Operand::Immediate` can have fields),\n+//! but for array/slice operations it only has to worry about `Operand::Uninit`. That makes the value part trivial,\n+//! but we still need to do bounds checking and adjust the layout. To not duplicate that with MPlaceTy, we actually\n+//! implement the logic on OpTy, and MPlaceTy calls that.\n+\n+use std::hash::Hash;\n+\n+use rustc_middle::mir;\n+use rustc_middle::ty;\n+use rustc_middle::ty::layout::LayoutOf;\n+use rustc_target::abi::{self, Abi, VariantIdx};\n+\n+use super::{\n+    ImmTy, Immediate, InterpCx, InterpResult, MPlaceTy, Machine, MemPlaceMeta, OpTy, PlaceTy,\n+    Provenance, Scalar,\n+};\n+\n+// FIXME: Working around https://github.com/rust-lang/rust/issues/54385\n+impl<'mir, 'tcx: 'mir, Tag, M> InterpCx<'mir, 'tcx, M>\n+where\n+    Tag: Provenance + Eq + Hash + 'static,\n+    M: Machine<'mir, 'tcx, PointerTag = Tag>,\n+{\n+    //# Field access\n+\n+    /// Offset a pointer to project to a field of a struct/union. Unlike `place_field`, this is\n+    /// always possible without allocating, so it can take `&self`. Also return the field's layout.\n+    /// This supports both struct and array fields.\n+    ///\n+    /// This also works for arrays, but then the `usize` index type is restricting.\n+    /// For indexing into arrays, use `mplace_index`.\n+    pub fn mplace_field(\n+        &self,\n+        base: &MPlaceTy<'tcx, M::PointerTag>,\n+        field: usize,\n+    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n+        let offset = base.layout.fields.offset(field);\n+        let field_layout = base.layout.field(self, field);\n+\n+        // Offset may need adjustment for unsized fields.\n+        let (meta, offset) = if field_layout.is_unsized() {\n+            // Re-use parent metadata to determine dynamic field layout.\n+            // With custom DSTS, this *will* execute user-defined code, but the same\n+            // happens at run-time so that's okay.\n+            match self.size_and_align_of(&base.meta, &field_layout)? {\n+                Some((_, align)) => (base.meta, offset.align_to(align)),\n+                None => {\n+                    // For unsized types with an extern type tail we perform no adjustments.\n+                    // NOTE: keep this in sync with `PlaceRef::project_field` in the codegen backend.\n+                    assert!(matches!(base.meta, MemPlaceMeta::None));\n+                    (base.meta, offset)\n+                }\n+            }\n+        } else {\n+            // base.meta could be present; we might be accessing a sized field of an unsized\n+            // struct.\n+            (MemPlaceMeta::None, offset)\n+        };\n+\n+        // We do not look at `base.layout.align` nor `field_layout.align`, unlike\n+        // codegen -- mostly to see if we can get away with that\n+        base.offset(offset, meta, field_layout, self)\n+    }\n+\n+    /// Gets the place of a field inside the place, and also the field's type.\n+    /// Just a convenience function, but used quite a bit.\n+    /// This is the only projection that might have a side-effect: We cannot project\n+    /// into the field of a local `ScalarPair`, we have to first allocate it.\n+    pub fn place_field(\n+        &mut self,\n+        base: &PlaceTy<'tcx, M::PointerTag>,\n+        field: usize,\n+    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n+        // FIXME: We could try to be smarter and avoid allocation for fields that span the\n+        // entire place.\n+        let base = self.force_allocation(base)?;\n+        Ok(self.mplace_field(&base, field)?.into())\n+    }\n+\n+    pub fn operand_field(\n+        &self,\n+        base: &OpTy<'tcx, M::PointerTag>,\n+        field: usize,\n+    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n+        let base = match base.try_as_mplace() {\n+            Ok(ref mplace) => {\n+                // We can reuse the mplace field computation logic for indirect operands.\n+                let field = self.mplace_field(mplace, field)?;\n+                return Ok(field.into());\n+            }\n+            Err(value) => value,\n+        };\n+\n+        let field_layout = base.layout.field(self, field);\n+        let offset = base.layout.fields.offset(field);\n+        // This makes several assumptions about what layouts we will encounter; we match what\n+        // codegen does as good as we can (see `extract_field` in `rustc_codegen_ssa/src/mir/operand.rs`).\n+        let field_val: Immediate<_> = match (*base, base.layout.abi) {\n+            // the field contains no information, can be left uninit\n+            _ if field_layout.is_zst() => Immediate::Uninit,\n+            // the field covers the entire type\n+            _ if field_layout.size == base.layout.size => {\n+                assert!(match (base.layout.abi, field_layout.abi) {\n+                    (Abi::Scalar(..), Abi::Scalar(..)) => true,\n+                    (Abi::ScalarPair(..), Abi::ScalarPair(..)) => true,\n+                    _ => false,\n+                });\n+                assert!(offset.bytes() == 0);\n+                *base\n+            }\n+            // extract fields from types with `ScalarPair` ABI\n+            (Immediate::ScalarPair(a_val, b_val), Abi::ScalarPair(a, b)) => {\n+                assert!(matches!(field_layout.abi, Abi::Scalar(..)));\n+                Immediate::from(if offset.bytes() == 0 {\n+                    debug_assert_eq!(field_layout.size, a.size(self));\n+                    a_val\n+                } else {\n+                    debug_assert_eq!(offset, a.size(self).align_to(b.align(self).abi));\n+                    debug_assert_eq!(field_layout.size, b.size(self));\n+                    b_val\n+                })\n+            }\n+            _ => span_bug!(\n+                self.cur_span(),\n+                \"invalid field access on immediate {}, layout {:#?}\",\n+                base,\n+                base.layout\n+            ),\n+        };\n+\n+        Ok(ImmTy::from_immediate(field_val, field_layout).into())\n+    }\n+\n+    //# Downcasting\n+\n+    pub fn mplace_downcast(\n+        &self,\n+        base: &MPlaceTy<'tcx, M::PointerTag>,\n+        variant: VariantIdx,\n+    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n+        // Downcasts only change the layout.\n+        // (In particular, no check about whether this is even the active variant -- that's by design,\n+        // see https://github.com/rust-lang/rust/issues/93688#issuecomment-1032929496.)\n+        assert!(!base.meta.has_meta());\n+        let mut base = *base;\n+        base.layout = base.layout.for_variant(self, variant);\n+        Ok(base)\n+    }\n+\n+    pub fn place_downcast(\n+        &self,\n+        base: &PlaceTy<'tcx, M::PointerTag>,\n+        variant: VariantIdx,\n+    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n+        // Downcast just changes the layout\n+        let mut base = *base;\n+        base.layout = base.layout.for_variant(self, variant);\n+        Ok(base)\n+    }\n+\n+    pub fn operand_downcast(\n+        &self,\n+        base: &OpTy<'tcx, M::PointerTag>,\n+        variant: VariantIdx,\n+    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n+        // Downcast just changes the layout\n+        let mut base = *base;\n+        base.layout = base.layout.for_variant(self, variant);\n+        Ok(base)\n+    }\n+\n+    //# Slice indexing\n+\n+    #[inline(always)]\n+    pub fn operand_index(\n+        &self,\n+        base: &OpTy<'tcx, M::PointerTag>,\n+        index: u64,\n+    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n+        // Not using the layout method because we want to compute on u64\n+        match base.layout.fields {\n+            abi::FieldsShape::Array { stride, count: _ } => {\n+                // `count` is nonsense for slices, use the dynamic length instead.\n+                let len = base.len(self)?;\n+                if index >= len {\n+                    // This can only be reached in ConstProp and non-rustc-MIR.\n+                    throw_ub!(BoundsCheckFailed { len, index });\n+                }\n+                let offset = stride * index; // `Size` multiplication\n+                // All fields have the same layout.\n+                let field_layout = base.layout.field(self, 0);\n+                assert!(!field_layout.is_unsized());\n+\n+                base.offset(offset, MemPlaceMeta::None, field_layout, self)\n+            }\n+            _ => span_bug!(\n+                self.cur_span(),\n+                \"`mplace_index` called on non-array type {:?}\",\n+                base.layout.ty\n+            ),\n+        }\n+    }\n+\n+    // Iterates over all fields of an array. Much more efficient than doing the\n+    // same by repeatedly calling `operand_index`.\n+    pub fn operand_array_fields<'a>(\n+        &self,\n+        base: &'a OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, impl Iterator<Item = InterpResult<'tcx, OpTy<'tcx, Tag>>> + 'a> {\n+        let len = base.len(self)?; // also asserts that we have a type where this makes sense\n+        let abi::FieldsShape::Array { stride, .. } = base.layout.fields else {\n+            span_bug!(self.cur_span(), \"operand_array_fields: expected an array layout\");\n+        };\n+        let layout = base.layout.field(self, 0);\n+        let dl = &self.tcx.data_layout;\n+        // `Size` multiplication\n+        Ok((0..len).map(move |i| base.offset(stride * i, MemPlaceMeta::None, layout, dl)))\n+    }\n+\n+    /// Index into an array.\n+    pub fn mplace_index(\n+        &self,\n+        base: &MPlaceTy<'tcx, M::PointerTag>,\n+        index: u64,\n+    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n+        Ok(self.operand_index(&base.into(), index)?.assert_mem_place())\n+    }\n+\n+    pub fn place_index(\n+        &mut self,\n+        base: &PlaceTy<'tcx, M::PointerTag>,\n+        index: u64,\n+    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n+        // There's not a lot we can do here, since we cannot have a place to a part of a local. If\n+        // we are accessing the only element of a 1-element array, it's still the entire local...\n+        // that doesn't seem worth it.\n+        let base = self.force_allocation(base)?;\n+        Ok(self.mplace_index(&base, index)?.into())\n+    }\n+\n+    //# ConstantIndex support\n+\n+    fn operand_constant_index(\n+        &self,\n+        base: &OpTy<'tcx, M::PointerTag>,\n+        offset: u64,\n+        min_length: u64,\n+        from_end: bool,\n+    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n+        let n = base.len(self)?;\n+        if n < min_length {\n+            // This can only be reached in ConstProp and non-rustc-MIR.\n+            throw_ub!(BoundsCheckFailed { len: min_length, index: n });\n+        }\n+\n+        let index = if from_end {\n+            assert!(0 < offset && offset <= min_length);\n+            n.checked_sub(offset).unwrap()\n+        } else {\n+            assert!(offset < min_length);\n+            offset\n+        };\n+\n+        self.operand_index(base, index)\n+    }\n+\n+    fn place_constant_index(\n+        &mut self,\n+        base: &PlaceTy<'tcx, M::PointerTag>,\n+        offset: u64,\n+        min_length: u64,\n+        from_end: bool,\n+    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n+        let base = self.force_allocation(base)?;\n+        Ok(self\n+            .operand_constant_index(&base.into(), offset, min_length, from_end)?\n+            .assert_mem_place()\n+            .into())\n+    }\n+\n+    //# Subslicing\n+\n+    fn operand_subslice(\n+        &self,\n+        base: &OpTy<'tcx, M::PointerTag>,\n+        from: u64,\n+        to: u64,\n+        from_end: bool,\n+    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n+        let len = base.len(self)?; // also asserts that we have a type where this makes sense\n+        let actual_to = if from_end {\n+            if from.checked_add(to).map_or(true, |to| to > len) {\n+                // This can only be reached in ConstProp and non-rustc-MIR.\n+                throw_ub!(BoundsCheckFailed { len: len, index: from.saturating_add(to) });\n+            }\n+            len.checked_sub(to).unwrap()\n+        } else {\n+            to\n+        };\n+\n+        // Not using layout method because that works with usize, and does not work with slices\n+        // (that have count 0 in their layout).\n+        let from_offset = match base.layout.fields {\n+            abi::FieldsShape::Array { stride, .. } => stride * from, // `Size` multiplication is checked\n+            _ => {\n+                span_bug!(self.cur_span(), \"unexpected layout of index access: {:#?}\", base.layout)\n+            }\n+        };\n+\n+        // Compute meta and new layout\n+        let inner_len = actual_to.checked_sub(from).unwrap();\n+        let (meta, ty) = match base.layout.ty.kind() {\n+            // It is not nice to match on the type, but that seems to be the only way to\n+            // implement this.\n+            ty::Array(inner, _) => (MemPlaceMeta::None, self.tcx.mk_array(*inner, inner_len)),\n+            ty::Slice(..) => {\n+                let len = Scalar::from_machine_usize(inner_len, self);\n+                (MemPlaceMeta::Meta(len), base.layout.ty)\n+            }\n+            _ => {\n+                span_bug!(self.cur_span(), \"cannot subslice non-array type: `{:?}`\", base.layout.ty)\n+            }\n+        };\n+        let layout = self.layout_of(ty)?;\n+        base.offset(from_offset, meta, layout, self)\n+    }\n+\n+    pub fn place_subslice(\n+        &mut self,\n+        base: &PlaceTy<'tcx, M::PointerTag>,\n+        from: u64,\n+        to: u64,\n+        from_end: bool,\n+    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n+        let base = self.force_allocation(base)?;\n+        Ok(self.operand_subslice(&base.into(), from, to, from_end)?.assert_mem_place().into())\n+    }\n+\n+    //# Applying a general projection\n+\n+    /// Projects into a place.\n+    #[instrument(skip(self), level = \"trace\")]\n+    pub fn place_projection(\n+        &mut self,\n+        base: &PlaceTy<'tcx, M::PointerTag>,\n+        proj_elem: mir::PlaceElem<'tcx>,\n+    ) -> InterpResult<'tcx, PlaceTy<'tcx, M::PointerTag>> {\n+        use rustc_middle::mir::ProjectionElem::*;\n+        Ok(match proj_elem {\n+            Field(field, _) => self.place_field(base, field.index())?,\n+            Downcast(_, variant) => self.place_downcast(base, variant)?,\n+            Deref => self.deref_operand(&self.place_to_op(base)?)?.into(),\n+            Index(local) => {\n+                let layout = self.layout_of(self.tcx.types.usize)?;\n+                let n = self.local_to_op(self.frame(), local, Some(layout))?;\n+                let n = self.read_scalar(&n)?.to_machine_usize(self)?;\n+                self.place_index(base, n)?\n+            }\n+            ConstantIndex { offset, min_length, from_end } => {\n+                self.place_constant_index(base, offset, min_length, from_end)?\n+            }\n+            Subslice { from, to, from_end } => self.place_subslice(base, from, to, from_end)?,\n+        })\n+    }\n+\n+    #[instrument(skip(self), level = \"trace\")]\n+    pub fn operand_projection(\n+        &self,\n+        base: &OpTy<'tcx, M::PointerTag>,\n+        proj_elem: mir::PlaceElem<'tcx>,\n+    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n+        use rustc_middle::mir::ProjectionElem::*;\n+        Ok(match proj_elem {\n+            Field(field, _) => self.operand_field(base, field.index())?,\n+            Downcast(_, variant) => self.operand_downcast(base, variant)?,\n+            Deref => self.deref_operand(base)?.into(),\n+            Index(local) => {\n+                let layout = self.layout_of(self.tcx.types.usize)?;\n+                let n = self.local_to_op(self.frame(), local, Some(layout))?;\n+                let n = self.read_scalar(&n)?.to_machine_usize(self)?;\n+                self.operand_index(base, n)?\n+            }\n+            ConstantIndex { offset, min_length, from_end } => {\n+                self.operand_constant_index(base, offset, min_length, from_end)?\n+            }\n+            Subslice { from, to, from_end } => self.operand_subslice(base, from, to, from_end)?,\n+        })\n+    }\n+}"}, {"sha": "9e74b99ecd73bbef66f8070c00cc650647f74640", "filename": "compiler/rustc_const_eval/src/interpret/terminator.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fterminator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fterminator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fterminator.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -529,7 +529,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 let receiver_place = loop {\n                     match receiver.layout.ty.kind() {\n                         ty::Ref(..) | ty::RawPtr(..) => break self.deref_operand(&receiver)?,\n-                        ty::Dynamic(..) => break receiver.assert_mem_place(),\n+                        ty::Dynamic(..) => break receiver.assert_mem_place(), // no immediate unsized values\n                         _ => {\n                             // Not there yet, search for the only non-ZST field.\n                             let mut non_zst_field = None;"}, {"sha": "5114ce5d452b3930bdd278e18857329885fb896e", "filename": "compiler/rustc_const_eval/src/interpret/validity.rs", "status": "modified", "additions": 22, "deletions": 8, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fvalidity.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fvalidity.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fvalidity.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -847,6 +847,8 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n                 );\n             }\n             Abi::Scalar(scalar_layout) => {\n+                // We use a 'forced' read because we always need a `Immediate` here\n+                // and treating \"partially uninit\" as \"fully uninit\" is fine for us.\n                 let scalar = self.read_immediate_forced(op)?.to_scalar_or_uninit();\n                 self.visit_scalar(scalar, scalar_layout)?;\n             }\n@@ -856,6 +858,8 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n                 // is subtle due to enums having ScalarPair layout, where one field\n                 // is the discriminant.\n                 if cfg!(debug_assertions) {\n+                    // We use a 'forced' read because we always need a `Immediate` here\n+                    // and treating \"partially uninit\" as \"fully uninit\" is fine for us.\n                     let (a, b) = self.read_immediate_forced(op)?.to_scalar_or_uninit_pair();\n                     self.visit_scalar(a, a_layout)?;\n                     self.visit_scalar(b, b_layout)?;\n@@ -880,7 +884,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n     ) -> InterpResult<'tcx> {\n         match op.layout.ty.kind() {\n             ty::Str => {\n-                let mplace = op.assert_mem_place(); // strings are never immediate\n+                let mplace = op.assert_mem_place(); // strings are unsized and hence never immediate\n                 let len = mplace.len(self.ecx)?;\n                 try_validation!(\n                     self.ecx.read_bytes_ptr(mplace.ptr, Size::from_bytes(len)),\n@@ -900,14 +904,27 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n             {\n                 // Optimized handling for arrays of integer/float type.\n \n-                // Arrays cannot be immediate, slices are never immediate.\n-                let mplace = op.assert_mem_place();\n                 // This is the length of the array/slice.\n-                let len = mplace.len(self.ecx)?;\n+                let len = op.len(self.ecx)?;\n                 // This is the element type size.\n                 let layout = self.ecx.layout_of(*tys)?;\n                 // This is the size in bytes of the whole array. (This checks for overflow.)\n                 let size = layout.size * len;\n+                // If the size is 0, there is nothing to check.\n+                // (`size` can only be 0 of `len` is 0, and empty arrays are always valid.)\n+                if size == Size::ZERO {\n+                    return Ok(());\n+                }\n+                // Now that we definitely have a non-ZST array, we know it lives in memory.\n+                let mplace = match op.try_as_mplace() {\n+                    Ok(mplace) => mplace,\n+                    Err(imm) => match *imm {\n+                        Immediate::Uninit =>\n+                            throw_validation_failure!(self.path, { \"uninitialized bytes\" }),\n+                        Immediate::Scalar(..) | Immediate::ScalarPair(..) =>\n+                            bug!(\"arrays/slices can never have Scalar/ScalarPair layout\"),\n+                    }\n+                };\n \n                 // Optimization: we just check the entire range at once.\n                 // NOTE: Keep this in sync with the handling of integer and float\n@@ -919,10 +936,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n                 // to reject those pointers, we just do not have the machinery to\n                 // talk about parts of a pointer.\n                 // We also accept uninit, for consistency with the slow path.\n-                let Some(alloc) = self.ecx.get_ptr_alloc(mplace.ptr, size, mplace.align)? else {\n-                    // Size 0, nothing more to check.\n-                    return Ok(());\n-                };\n+                let alloc = self.ecx.get_ptr_alloc(mplace.ptr, size, mplace.align)?.expect(\"we already excluded size 0\");\n \n                 match alloc.check_bytes(\n                     alloc_range(Size::ZERO, size),"}, {"sha": "c262bca9bb4eeb1b192e18f4f9e5486e36695302", "filename": "compiler/rustc_const_eval/src/interpret/visitor.rs", "status": "modified", "additions": 13, "deletions": 11, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fvisitor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7b5715289f813460ac95189fb7d3479e8edd23eb/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fvisitor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Finterpret%2Fvisitor.rs?ref=7b5715289f813460ac95189fb7d3479e8edd23eb", "patch": "@@ -21,8 +21,10 @@ pub trait Value<'mir, 'tcx, M: Machine<'mir, 'tcx>>: Copy {\n     fn to_op(&self, ecx: &InterpCx<'mir, 'tcx, M>)\n     -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>>;\n \n-    /// Creates this from an `MPlaceTy`.\n-    fn from_mem_place(mplace: MPlaceTy<'tcx, M::PointerTag>) -> Self;\n+    /// Creates this from an `OpTy`.\n+    ///\n+    /// If `to_op` only ever produces `Indirect` operands, then this one is definitely `Indirect`.\n+    fn from_op(mplace: OpTy<'tcx, M::PointerTag>) -> Self;\n \n     /// Projects to the given enum variant.\n     fn project_downcast(\n@@ -56,8 +58,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> Value<'mir, 'tcx, M> for OpTy<'tc\n     }\n \n     #[inline(always)]\n-    fn from_mem_place(mplace: MPlaceTy<'tcx, M::PointerTag>) -> Self {\n-        mplace.into()\n+    fn from_op(op: OpTy<'tcx, M::PointerTag>) -> Self {\n+        op\n     }\n \n     #[inline(always)]\n@@ -96,8 +98,9 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> Value<'mir, 'tcx, M>\n     }\n \n     #[inline(always)]\n-    fn from_mem_place(mplace: MPlaceTy<'tcx, M::PointerTag>) -> Self {\n-        mplace\n+    fn from_op(op: OpTy<'tcx, M::PointerTag>) -> Self {\n+        // assert is justified because our `to_op` only ever produces `Indirect` operands.\n+        op.assert_mem_place()\n     }\n \n     #[inline(always)]\n@@ -218,13 +221,13 @@ macro_rules! make_value_visitor {\n                 match *v.layout().ty.kind() {\n                     // If it is a trait object, switch to the real type that was used to create it.\n                     ty::Dynamic(..) => {\n-                        // immediate trait objects are not a thing\n+                        // unsized values are never immediate, so we can assert_mem_place\n                         let op = v.to_op(self.ecx())?;\n                         let dest = op.assert_mem_place();\n                         let inner = self.ecx().unpack_dyn_trait(&dest)?.1;\n                         trace!(\"walk_value: dyn object layout: {:#?}\", inner.layout);\n                         // recurse with the inner type\n-                        return self.visit_field(&v, 0, &Value::from_mem_place(inner));\n+                        return self.visit_field(&v, 0, &Value::from_op(inner.into()));\n                     },\n                     // Slices do not need special handling here: they have `Array` field\n                     // placement with length 0, so we enter the `Array` case below which\n@@ -292,13 +295,12 @@ macro_rules! make_value_visitor {\n                     FieldsShape::Array { .. } => {\n                         // Let's get an mplace first.\n                         let op = v.to_op(self.ecx())?;\n-                        let mplace = op.assert_mem_place();\n                         // Now we can go over all the fields.\n                         // This uses the *run-time length*, i.e., if we are a slice,\n                         // the dynamic info from the metadata is used.\n-                        let iter = self.ecx().mplace_array_fields(&mplace)?\n+                        let iter = self.ecx().operand_array_fields(&op)?\n                             .map(|f| f.and_then(|f| {\n-                                Ok(Value::from_mem_place(f))\n+                                Ok(Value::from_op(f))\n                             }));\n                         self.visit_aggregate(v, iter)?;\n                     }"}]}