{"sha": "96a774261f4308532f813149d2e5677310555520", "node_id": "C_kwDOAAsO6NoAKDk2YTc3NDI2MWY0MzA4NTMyZjgxMzE0OWQyZTU2NzczMTA1NTU1MjA", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2023-04-16T17:20:42Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2023-04-16T17:20:42Z"}, "message": "Option begone part 1", "tree": {"sha": "3aad2364ce5a12f5e4a5d7dfe7ab84b04e4e2e8d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3aad2364ce5a12f5e4a5d7dfe7ab84b04e4e2e8d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/96a774261f4308532f813149d2e5677310555520", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/96a774261f4308532f813149d2e5677310555520", "html_url": "https://github.com/rust-lang/rust/commit/96a774261f4308532f813149d2e5677310555520", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/96a774261f4308532f813149d2e5677310555520/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0f4ffaa5afac3d5df27905cbab4630de4d8556ed", "url": "https://api.github.com/repos/rust-lang/rust/commits/0f4ffaa5afac3d5df27905cbab4630de4d8556ed", "html_url": "https://github.com/rust-lang/rust/commit/0f4ffaa5afac3d5df27905cbab4630de4d8556ed"}], "stats": {"total": 199, "additions": 94, "deletions": 105}, "files": [{"sha": "6286295c52639ea6222ac83e63b739645f83312f", "filename": "crates/hir-def/src/macro_expansion_tests/mod.rs", "status": "modified", "additions": 31, "deletions": 33, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-def%2Fsrc%2Fmacro_expansion_tests%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-def%2Fsrc%2Fmacro_expansion_tests%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Fmacro_expansion_tests%2Fmod.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -151,47 +151,45 @@ pub fn identity_when_valid(_attr: TokenStream, item: TokenStream) -> TokenStream\n         if let Some(err) = exp.err {\n             format_to!(expn_text, \"/* error: {} */\", err);\n         }\n-        if let Some((parse, token_map)) = exp.value {\n-            if expect_errors {\n-                assert!(!parse.errors().is_empty(), \"no parse errors in expansion\");\n-                for e in parse.errors() {\n-                    format_to!(expn_text, \"/* parse error: {} */\\n\", e);\n-                }\n-            } else {\n-                assert!(\n-                    parse.errors().is_empty(),\n-                    \"parse errors in expansion: \\n{:#?}\",\n-                    parse.errors()\n-                );\n+        let (parse, token_map) = exp.value;\n+        if expect_errors {\n+            assert!(!parse.errors().is_empty(), \"no parse errors in expansion\");\n+            for e in parse.errors() {\n+                format_to!(expn_text, \"/* parse error: {} */\\n\", e);\n             }\n-            let pp = pretty_print_macro_expansion(\n-                parse.syntax_node(),\n-                show_token_ids.then_some(&*token_map),\n+        } else {\n+            assert!(\n+                parse.errors().is_empty(),\n+                \"parse errors in expansion: \\n{:#?}\",\n+                parse.errors()\n             );\n-            let indent = IndentLevel::from_node(call.syntax());\n-            let pp = reindent(indent, pp);\n-            format_to!(expn_text, \"{}\", pp);\n+        }\n+        let pp = pretty_print_macro_expansion(\n+            parse.syntax_node(),\n+            show_token_ids.then_some(&*token_map),\n+        );\n+        let indent = IndentLevel::from_node(call.syntax());\n+        let pp = reindent(indent, pp);\n+        format_to!(expn_text, \"{}\", pp);\n \n-            if tree {\n-                let tree = format!(\"{:#?}\", parse.syntax_node())\n-                    .split_inclusive('\\n')\n-                    .map(|line| format!(\"// {line}\"))\n-                    .collect::<String>();\n-                format_to!(expn_text, \"\\n{}\", tree)\n-            }\n+        if tree {\n+            let tree = format!(\"{:#?}\", parse.syntax_node())\n+                .split_inclusive('\\n')\n+                .map(|line| format!(\"// {line}\"))\n+                .collect::<String>();\n+            format_to!(expn_text, \"\\n{}\", tree)\n         }\n         let range = call.syntax().text_range();\n         let range: Range<usize> = range.into();\n \n         if show_token_ids {\n-            if let Some((tree, map, _)) = arg.as_deref() {\n-                let tt_range = call.token_tree().unwrap().syntax().text_range();\n-                let mut ranges = Vec::new();\n-                extract_id_ranges(&mut ranges, map, tree);\n-                for (range, id) in ranges {\n-                    let idx = (tt_range.start() + range.end()).into();\n-                    text_edits.push((idx..idx, format!(\"#{}\", id.0)));\n-                }\n+            let (tree, map, _) = &*arg;\n+            let tt_range = call.token_tree().unwrap().syntax().text_range();\n+            let mut ranges = Vec::new();\n+            extract_id_ranges(&mut ranges, map, tree);\n+            for (range, id) in ranges {\n+                let idx = (tt_range.start() + range.end()).into();\n+                text_edits.push((idx..idx, format!(\"#{}\", id.0)));\n             }\n             text_edits.push((range.start..range.start, \"// \".into()));\n             call.to_string().match_indices('\\n').for_each(|(offset, _)| {"}, {"sha": "461b498fa01e108223a4e973bff6c1d376a424b3", "filename": "crates/hir-def/src/nameres/collector.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-def%2Fsrc%2Fnameres%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-def%2Fsrc%2Fnameres%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Fnameres%2Fcollector.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -1371,7 +1371,7 @@ impl DefCollector<'_> {\n \n             self.def_map.diagnostics.push(diag);\n         }\n-        if let Some(errors) = value {\n+        if let errors @ [_, ..] = &*value {\n             let loc: MacroCallLoc = self.db.lookup_intern_macro_call(macro_call_id);\n             let diag = DefDiagnostic::macro_expansion_parse_error(module_id, loc.kind, &errors);\n             self.def_map.diagnostics.push(diag);"}, {"sha": "4794ccc2aae2ccc192ee54dcabe1c48a1d859638", "filename": "crates/hir-expand/src/db.rs", "status": "modified", "additions": 52, "deletions": 60, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Fdb.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -108,7 +108,7 @@ pub trait ExpandDatabase: SourceDatabase {\n     fn parse_macro_expansion(\n         &self,\n         macro_file: MacroFile,\n-    ) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>>;\n+    ) -> ExpandResult<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>;\n \n     /// Macro ids. That's probably the tricksiest bit in rust-analyzer, and the\n     /// reason why we use salsa at all.\n@@ -123,7 +123,7 @@ pub trait ExpandDatabase: SourceDatabase {\n     fn macro_arg(\n         &self,\n         id: MacroCallId,\n-    ) -> Option<Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>>;\n+    ) -> Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>;\n     /// Extracts syntax node, corresponding to a macro call. That's a firewall\n     /// query, only typing in the macro call itself changes the returned\n     /// subtree.\n@@ -133,7 +133,7 @@ pub trait ExpandDatabase: SourceDatabase {\n     fn macro_def(&self, id: MacroDefId) -> Result<Arc<TokenExpander>, mbe::ParseError>;\n \n     /// Expand macro call to a token tree.\n-    fn macro_expand(&self, macro_call: MacroCallId) -> ExpandResult<Option<Arc<tt::Subtree>>>;\n+    fn macro_expand(&self, macro_call: MacroCallId) -> ExpandResult<Arc<tt::Subtree>>;\n     /// Special case of the previous query for procedural macros. We can't LRU\n     /// proc macros, since they are not deterministic in general, and\n     /// non-determinism breaks salsa in a very, very, very bad way. @edwin0cheng\n@@ -143,7 +143,7 @@ pub trait ExpandDatabase: SourceDatabase {\n     fn parse_macro_expansion_error(\n         &self,\n         macro_call: MacroCallId,\n-    ) -> ExpandResult<Option<Box<[SyntaxError]>>>;\n+    ) -> ExpandResult<Box<[SyntaxError]>>;\n \n     fn hygiene_frame(&self, file_id: HirFileId) -> Arc<HygieneFrame>;\n }\n@@ -257,12 +257,12 @@ fn ast_id_map(db: &dyn ExpandDatabase, file_id: HirFileId) -> Arc<AstIdMap> {\n }\n \n fn parse_or_expand(db: &dyn ExpandDatabase, file_id: HirFileId) -> Option<SyntaxNode> {\n-    match file_id.repr() {\n-        HirFileIdRepr::FileId(file_id) => Some(db.parse(file_id).tree().syntax().clone()),\n+    Some(match file_id.repr() {\n+        HirFileIdRepr::FileId(file_id) => db.parse(file_id).tree().syntax().clone(),\n         HirFileIdRepr::MacroFile(macro_file) => {\n-            db.parse_macro_expansion(macro_file).value.map(|(it, _)| it.syntax_node())\n+            db.parse_macro_expansion(macro_file).value.0.syntax_node()\n         }\n-    }\n+    })\n }\n \n fn parse_or_expand_with_err(\n@@ -272,17 +272,17 @@ fn parse_or_expand_with_err(\n     match file_id.repr() {\n         HirFileIdRepr::FileId(file_id) => ExpandResult::ok(Some(db.parse(file_id).to_syntax())),\n         HirFileIdRepr::MacroFile(macro_file) => {\n-            db.parse_macro_expansion(macro_file).map(|it| it.map(|(parse, _)| parse))\n+            db.parse_macro_expansion(macro_file).map(|it| Some(it.0))\n         }\n     }\n }\n \n fn parse_macro_expansion(\n     db: &dyn ExpandDatabase,\n     macro_file: MacroFile,\n-) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>> {\n+) -> ExpandResult<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)> {\n     let _p = profile::span(\"parse_macro_expansion\");\n-    let mbe::ValueResult { value, err } = db.macro_expand(macro_file.macro_call_id);\n+    let mbe::ValueResult { value: tt, err } = db.macro_expand(macro_file.macro_call_id);\n \n     if let Some(err) = &err {\n         if tracing::enabled!(tracing::Level::DEBUG) {\n@@ -308,10 +308,6 @@ fn parse_macro_expansion(\n             );\n         }\n     }\n-    let tt = match value {\n-        Some(tt) => tt,\n-        None => return ExpandResult { value: None, err },\n-    };\n \n     let expand_to = macro_expand_to(db, macro_file.macro_call_id);\n \n@@ -320,14 +316,23 @@ fn parse_macro_expansion(\n \n     let (parse, rev_token_map) = token_tree_to_syntax_node(&tt, expand_to);\n \n-    ExpandResult { value: Some((parse, Arc::new(rev_token_map))), err }\n+    ExpandResult { value: (parse, Arc::new(rev_token_map)), err }\n }\n \n fn macro_arg(\n     db: &dyn ExpandDatabase,\n     id: MacroCallId,\n-) -> Option<Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>> {\n-    let arg = db.macro_arg_text(id)?;\n+) -> Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)> {\n+    let Some(arg) = db.macro_arg_text(id) else {\n+        return Arc::new((\n+            tt::Subtree {\n+                delimiter: tt::Delimiter::UNSPECIFIED,\n+                token_trees: Vec::new(),\n+            },\n+            Default::default(),\n+            Default::default())\n+        );\n+    };\n     let loc = db.lookup_intern_macro_call(id);\n \n     let node = SyntaxNode::new_root(arg);\n@@ -346,7 +351,7 @@ fn macro_arg(\n         // proc macros expect their inputs without parentheses, MBEs expect it with them included\n         tt.delimiter = tt::Delimiter::unspecified();\n     }\n-    Some(Arc::new((tt, tmap, fixups.undo_info)))\n+    Arc::new((tt, tmap, fixups.undo_info))\n }\n \n fn censor_for_macro_input(loc: &MacroCallLoc, node: &SyntaxNode) -> FxHashSet<SyntaxNode> {\n@@ -448,79 +453,66 @@ fn macro_def(\n     }\n }\n \n-fn macro_expand(\n-    db: &dyn ExpandDatabase,\n-    id: MacroCallId,\n-    // FIXME: Remove the OPtion if possible\n-) -> ExpandResult<Option<Arc<tt::Subtree>>> {\n+fn macro_expand(db: &dyn ExpandDatabase, id: MacroCallId) -> ExpandResult<Arc<tt::Subtree>> {\n     let _p = profile::span(\"macro_expand\");\n     let loc: MacroCallLoc = db.lookup_intern_macro_call(id);\n     if let Some(eager) = &loc.eager {\n-        return ExpandResult {\n-            value: Some(eager.arg_or_expansion.clone()),\n-            err: eager.error.clone(),\n-        };\n+        return ExpandResult { value: eager.arg_or_expansion.clone(), err: eager.error.clone() };\n     }\n \n-    let macro_arg = match db.macro_arg(id) {\n-        Some(it) => it,\n-        None => {\n-            return ExpandResult::only_err(ExpandError::Other(\n-                \"Failed to lower macro args to token tree\".into(),\n-            ))\n-        }\n-    };\n-\n     let expander = match db.macro_def(loc.def) {\n         Ok(it) => it,\n         // FIXME: This is weird -- we effectively report macro *definition*\n         // errors lazily, when we try to expand the macro. Instead, they should\n         // be reported at the definition site when we construct a def map.\n         // (Note we do report them also at the definition site in the late diagnostic pass)\n         Err(err) => {\n-            return ExpandResult::only_err(ExpandError::Other(\n-                format!(\"invalid macro definition: {err}\").into(),\n-            ))\n+            return ExpandResult {\n+                value: Arc::new(tt::Subtree {\n+                    delimiter: tt::Delimiter::UNSPECIFIED,\n+                    token_trees: vec![],\n+                }),\n+                err: Some(ExpandError::Other(format!(\"invalid macro definition: {err}\").into())),\n+            }\n         }\n     };\n+    let macro_arg = db.macro_arg(id);\n     let ExpandResult { value: mut tt, err } = expander.expand(db, id, &macro_arg.0);\n     // Set a hard limit for the expanded tt\n     let count = tt.count();\n     if TOKEN_LIMIT.check(count).is_err() {\n-        return ExpandResult::only_err(ExpandError::Other(\n-            format!(\n-                \"macro invocation exceeds token limit: produced {} tokens, limit is {}\",\n-                count,\n-                TOKEN_LIMIT.inner(),\n-            )\n-            .into(),\n-        ));\n+        return ExpandResult {\n+            value: Arc::new(tt::Subtree {\n+                delimiter: tt::Delimiter::UNSPECIFIED,\n+                token_trees: vec![],\n+            }),\n+            err: Some(ExpandError::Other(\n+                format!(\n+                    \"macro invocation exceeds token limit: produced {} tokens, limit is {}\",\n+                    count,\n+                    TOKEN_LIMIT.inner(),\n+                )\n+                .into(),\n+            )),\n+        };\n     }\n \n     fixup::reverse_fixups(&mut tt, &macro_arg.1, &macro_arg.2);\n \n-    ExpandResult { value: Some(Arc::new(tt)), err }\n+    ExpandResult { value: Arc::new(tt), err }\n }\n \n fn parse_macro_expansion_error(\n     db: &dyn ExpandDatabase,\n     macro_call_id: MacroCallId,\n-) -> ExpandResult<Option<Box<[SyntaxError]>>> {\n+) -> ExpandResult<Box<[SyntaxError]>> {\n     db.parse_macro_expansion(MacroFile { macro_call_id })\n-        .map(|it| it.map(|(it, _)| it.errors().to_vec().into_boxed_slice()))\n+        .map(|it| it.0.errors().to_vec().into_boxed_slice())\n }\n \n fn expand_proc_macro(db: &dyn ExpandDatabase, id: MacroCallId) -> ExpandResult<tt::Subtree> {\n     let loc: MacroCallLoc = db.lookup_intern_macro_call(id);\n-    let macro_arg = match db.macro_arg(id) {\n-        Some(it) => it,\n-        None => {\n-            return ExpandResult::with_err(\n-                tt::Subtree::empty(),\n-                ExpandError::Other(\"No arguments for proc-macro\".into()),\n-            )\n-        }\n-    };\n+    let macro_arg = db.macro_arg(id);\n \n     let expander = match loc.def.kind {\n         MacroDefKind::ProcMacro(expander, ..) => expander,"}, {"sha": "00796e7c0dbb02351967826256098143606a0a8a", "filename": "crates/hir-expand/src/fixup.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Ffixup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Ffixup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Ffixup.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -14,7 +14,7 @@ use tt::token_id::Subtree;\n /// The result of calculating fixes for a syntax node -- a bunch of changes\n /// (appending to and replacing nodes), the information that is needed to\n /// reverse those changes afterwards, and a token map.\n-#[derive(Debug)]\n+#[derive(Debug, Default)]\n pub(crate) struct SyntaxFixups {\n     pub(crate) append: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n     pub(crate) replace: FxHashMap<SyntaxElement, Vec<SyntheticToken>>,\n@@ -24,7 +24,7 @@ pub(crate) struct SyntaxFixups {\n }\n \n /// This is the information needed to reverse the fixups.\n-#[derive(Debug, PartialEq, Eq)]\n+#[derive(Debug, Default, PartialEq, Eq)]\n pub struct SyntaxFixupUndoInfo {\n     original: Vec<Subtree>,\n }"}, {"sha": "addffb8877205e3b18fbc1329c3f3bf48fc56bc4", "filename": "crates/hir-expand/src/hygiene.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Fhygiene.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -200,8 +200,8 @@ fn make_hygiene_info(\n     });\n \n     let macro_def = db.macro_def(loc.def).ok()?;\n-    let (_, exp_map) = db.parse_macro_expansion(macro_file).value?;\n-    let macro_arg = db.macro_arg(macro_file.macro_call_id)?;\n+    let (_, exp_map) = db.parse_macro_expansion(macro_file).value;\n+    let macro_arg = db.macro_arg(macro_file.macro_call_id);\n \n     Some(HygieneInfo {\n         file: macro_file,"}, {"sha": "f4d858e8e261a6cc47b7bb6787a20b9ac12348bc", "filename": "crates/hir-expand/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fhir-expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Flib.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -257,8 +257,8 @@ impl HirFileId {\n         let arg_tt = loc.kind.arg(db)?;\n \n         let macro_def = db.macro_def(loc.def).ok()?;\n-        let (parse, exp_map) = db.parse_macro_expansion(macro_file).value?;\n-        let macro_arg = db.macro_arg(macro_file.macro_call_id)?;\n+        let (parse, exp_map) = db.parse_macro_expansion(macro_file).value;\n+        let macro_arg = db.macro_arg(macro_file.macro_call_id);\n \n         let def = loc.def.ast_id().left().and_then(|id| {\n             let def_tt = match id.to_node(db) {"}, {"sha": "71fc91cf3177cce9acce20bc59fa383f098b958f", "filename": "crates/ide/src/status.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Fide%2Fsrc%2Fstatus.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Fide%2Fsrc%2Fstatus.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fstatus.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -120,12 +120,12 @@ impl FromIterator<TableEntry<FileId, Parse<ast::SourceFile>>> for SyntaxTreeStat\n     }\n }\n \n-impl<M> FromIterator<TableEntry<MacroFile, ExpandResult<Option<(Parse<SyntaxNode>, M)>>>>\n+impl<M> FromIterator<TableEntry<MacroFile, ExpandResult<(Parse<SyntaxNode>, M)>>>\n     for SyntaxTreeStats\n {\n     fn from_iter<T>(iter: T) -> SyntaxTreeStats\n     where\n-        T: IntoIterator<Item = TableEntry<MacroFile, ExpandResult<Option<(Parse<SyntaxNode>, M)>>>>,\n+        T: IntoIterator<Item = TableEntry<MacroFile, ExpandResult<(Parse<SyntaxNode>, M)>>>,\n     {\n         let mut res = SyntaxTreeStats::default();\n         for entry in iter {"}, {"sha": "8aeb1df8d048213f42303652b18110a072c1be04", "filename": "crates/rust-analyzer/src/cli/analysis_stats.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/96a774261f4308532f813149d2e5677310555520/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_stats.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96a774261f4308532f813149d2e5677310555520/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_stats.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_stats.rs?ref=96a774261f4308532f813149d2e5677310555520", "patch": "@@ -180,9 +180,8 @@ impl flags::AnalysisStats {\n \n             let mut total_macro_file_size = Bytes::default();\n             for e in hir::db::ParseMacroExpansionQuery.in_db(db).entries::<Vec<_>>() {\n-                if let Some((val, _)) = db.parse_macro_expansion(e.key).value {\n-                    total_macro_file_size += syntax_len(val.syntax_node())\n-                }\n+                let val = db.parse_macro_expansion(e.key).value.0;\n+                total_macro_file_size += syntax_len(val.syntax_node())\n             }\n             eprintln!(\"source files: {total_file_size}, macro files: {total_macro_file_size}\");\n         }"}]}