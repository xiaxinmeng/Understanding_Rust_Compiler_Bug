{"sha": "5d872727e02d9cc67813fa7f00763e355d39ae06", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVkODcyNzI3ZTAyZDljYzY3ODEzZmE3ZjAwNzYzZTM1NWQzOWFlMDY=", "commit": {"author": {"name": "mark", "email": "markm@cs.wisc.edu", "date": "2018-07-03T00:44:01Z"}, "committer": {"name": "mark", "email": "markm@cs.wisc.edu", "date": "2018-07-24T02:54:43Z"}, "message": "Fix test and errors", "tree": {"sha": "386e437a1eed0b3e95c16ed3f45a9885e07414e1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/386e437a1eed0b3e95c16ed3f45a9885e07414e1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5d872727e02d9cc67813fa7f00763e355d39ae06", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5d872727e02d9cc67813fa7f00763e355d39ae06", "html_url": "https://github.com/rust-lang/rust/commit/5d872727e02d9cc67813fa7f00763e355d39ae06", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5d872727e02d9cc67813fa7f00763e355d39ae06/comments", "author": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "63c2d06a0d777f78048963cc55630631505de83b", "url": "https://api.github.com/repos/rust-lang/rust/commits/63c2d06a0d777f78048963cc55630631505de83b", "html_url": "https://github.com/rust-lang/rust/commit/63c2d06a0d777f78048963cc55630631505de83b"}], "stats": {"total": 465, "additions": 193, "deletions": 272}, "files": [{"sha": "0bf1f4decc43040c4184d1fd31924ba01434d672", "filename": "src/librustc/macros.rs", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/5d872727e02d9cc67813fa7f00763e355d39ae06/src%2Flibrustc%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5d872727e02d9cc67813fa7f00763e355d39ae06/src%2Flibrustc%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmacros.rs?ref=5d872727e02d9cc67813fa7f00763e355d39ae06", "patch": "@@ -71,7 +71,9 @@ macro_rules! __impl_stable_hash_field {\n \n #[macro_export]\n macro_rules! impl_stable_hash_for {\n-    (enum $enum_name:path { $( $variant:ident $( ( $($field:ident $(-> $delegate:tt)?),* ) )* ),* $(,)? }) => {\n+    // FIXME(mark-i-m): Some of these should be `?` rather than `*`. See the git blame and change\n+    // them back when `?` is supported again.\n+    (enum $enum_name:path { $( $variant:ident $( ( $($field:ident $(-> $delegate:tt)*),* ) )* ),* $(,)* }) => {\n         impl<'a, 'tcx> ::rustc_data_structures::stable_hasher::HashStable<$crate::ich::StableHashingContext<'a>> for $enum_name {\n             #[inline]\n             fn hash_stable<W: ::rustc_data_structures::stable_hasher::StableHasherResult>(&self,\n@@ -83,14 +85,15 @@ macro_rules! impl_stable_hash_for {\n                 match *self {\n                     $(\n                         $variant $( ( $(ref $field),* ) )* => {\n-                            $($( __impl_stable_hash_field!($field, __ctx, __hasher $(, $delegate)?) );*)*\n+                            $($( __impl_stable_hash_field!($field, __ctx, __hasher $(, $delegate)*) );*)*\n                         }\n                     )*\n                 }\n             }\n         }\n     };\n-    (struct $struct_name:path { $($field:ident $(-> $delegate:tt)?),*  $(,)? }) => {\n+    // FIXME(mark-i-m): same here.\n+    (struct $struct_name:path { $($field:ident $(-> $delegate:tt)*),*  $(,)* }) => {\n         impl<'a, 'tcx> ::rustc_data_structures::stable_hasher::HashStable<$crate::ich::StableHashingContext<'a>> for $struct_name {\n             #[inline]\n             fn hash_stable<W: ::rustc_data_structures::stable_hasher::StableHasherResult>(&self,\n@@ -100,11 +103,12 @@ macro_rules! impl_stable_hash_for {\n                     $(ref $field),*\n                 } = *self;\n \n-                $( __impl_stable_hash_field!($field, __ctx, __hasher $(, $delegate)?) );*\n+                $( __impl_stable_hash_field!($field, __ctx, __hasher $(, $delegate)*) );*\n             }\n         }\n     };\n-    (tuple_struct $struct_name:path { $($field:ident $(-> $delegate:tt)?),*  $(,)? }) => {\n+    // FIXME(mark-i-m): same here.\n+    (tuple_struct $struct_name:path { $($field:ident $(-> $delegate:tt)*),*  $(,)* }) => {\n         impl<'a, 'tcx> ::rustc_data_structures::stable_hasher::HashStable<$crate::ich::StableHashingContext<'a>> for $struct_name {\n             #[inline]\n             fn hash_stable<W: ::rustc_data_structures::stable_hasher::StableHasherResult>(&self,\n@@ -114,7 +118,7 @@ macro_rules! impl_stable_hash_for {\n                     $(ref $field),*\n                 ) = *self;\n \n-                $( __impl_stable_hash_field!($field, __ctx, __hasher $(, $delegate)?) );*\n+                $( __impl_stable_hash_field!($field, __ctx, __hasher $(, $delegate)*) );*\n             }\n         }\n     };"}, {"sha": "8912be5f69d115ce9a922a8efa4f3ef4215a1b79", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 182, "deletions": 265, "changes": 447, "blob_url": "https://github.com/rust-lang/rust/blob/5d872727e02d9cc67813fa7f00763e355d39ae06/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5d872727e02d9cc67813fa7f00763e355d39ae06/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=5d872727e02d9cc67813fa7f00763e355d39ae06", "patch": "@@ -8,33 +8,28 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use {ast, attr};\n+use syntax_pos::{Span, DUMMY_SP};\n use edition::Edition;\n-use ext::{\n-    base::{DummyResult, ExtCtxt, MacResult, NormalTT, SyntaxExtension, TTMacroExpander},\n-    expand::{AstFragment, AstFragmentKind},\n-    tt::{\n-        macro_parser::{\n-            parse, parse_failure_msg, Error, Failure, MatchedNonterminal, MatchedSeq, Success,\n-        },\n-        quoted,\n-        transcribe::transcribe,\n-    },\n-};\n+use ext::base::{DummyResult, ExtCtxt, MacResult, SyntaxExtension};\n+use ext::base::{NormalTT, TTMacroExpander};\n+use ext::expand::{AstFragment, AstFragmentKind};\n+use ext::tt::macro_parser::{Success, Error, Failure};\n+use ext::tt::macro_parser::{MatchedSeq, MatchedNonterminal};\n+use ext::tt::macro_parser::{parse, parse_failure_msg};\n+use ext::tt::quoted;\n+use ext::tt::transcribe::transcribe;\n use feature_gate::{self, emit_feature_err, Features, GateIssue};\n-use parse::{\n-    parser::Parser,\n-    token::{self, NtTT, Token::*},\n-    Directory, ParseSess,\n-};\n+use parse::{Directory, ParseSess};\n+use parse::parser::Parser;\n+use parse::token::{self, NtTT};\n+use parse::token::Token::*;\n use symbol::Symbol;\n-use syntax_pos::{Span, DUMMY_SP};\n use tokenstream::{TokenStream, TokenTree};\n-use {ast, attr};\n \n-use std::{\n-    borrow::Cow,\n-    collections::{hash_map::Entry, HashMap},\n-};\n+use std::borrow::Cow;\n+use std::collections::HashMap;\n+use std::collections::hash_map::Entry;\n \n use rustc_data_structures::sync::Lrc;\n \n@@ -44,16 +39,12 @@ pub struct ParserAnyMacro<'a> {\n     /// Span of the expansion site of the macro this parser is for\n     site_span: Span,\n     /// The ident of the macro we're parsing\n-    macro_ident: ast::Ident,\n+    macro_ident: ast::Ident\n }\n \n impl<'a> ParserAnyMacro<'a> {\n     pub fn make(mut self: Box<ParserAnyMacro<'a>>, kind: AstFragmentKind) -> AstFragment {\n-        let ParserAnyMacro {\n-            site_span,\n-            macro_ident,\n-            ref mut parser,\n-        } = *self;\n+        let ParserAnyMacro { site_span, macro_ident, ref mut parser } = *self;\n         let fragment = panictry!(parser.parse_ast_fragment(kind, true));\n \n         // We allow semicolons at the end of expressions -- e.g. the semicolon in\n@@ -86,16 +77,17 @@ impl TTMacroExpander for MacroRulesMacroExpander {\n         if !self.valid {\n             return DummyResult::any(sp);\n         }\n-        generic_extension(cx, sp, self.name, input, &self.lhses, &self.rhses)\n+        generic_extension(cx,\n+                          sp,\n+                          self.name,\n+                          input,\n+                          &self.lhses,\n+                          &self.rhses)\n     }\n }\n \n fn trace_macros_note(cx: &mut ExtCtxt, sp: Span, message: String) {\n-    let sp = sp\n-        .macro_backtrace()\n-        .last()\n-        .map(|trace| trace.call_site)\n-        .unwrap_or(sp);\n+    let sp = sp.macro_backtrace().last().map(|trace| trace.call_site).unwrap_or(sp);\n     let values: &mut Vec<String> = cx.expansions.entry(sp).or_insert_with(Vec::new);\n     values.push(message);\n }\n@@ -116,11 +108,10 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n     let mut best_fail_spot = DUMMY_SP;\n     let mut best_fail_tok = None;\n \n-    for (i, lhs) in lhses.iter().enumerate() {\n-        // try each arm's matchers\n+    for (i, lhs) in lhses.iter().enumerate() { // try each arm's matchers\n         let lhs_tt = match *lhs {\n             quoted::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n-            _ => cx.span_bug(sp, \"malformed macro lhs\"),\n+            _ => cx.span_bug(sp, \"malformed macro lhs\")\n         };\n \n         match TokenTree::parse(cx, lhs_tt, arg.clone()) {\n@@ -156,11 +147,7 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n                     ownership: cx.current_expansion.directory_ownership,\n                 };\n                 let mut p = Parser::new(cx.parse_sess(), tts, Some(directory), true, false);\n-                p.root_module_name = cx\n-                    .current_expansion\n-                    .module\n-                    .mod_path\n-                    .last()\n+                p.root_module_name = cx.current_expansion.module.mod_path.last()\n                     .map(|id| id.as_str().to_string());\n \n                 p.process_potential_macro_variable();\n@@ -173,14 +160,16 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n                     // so we can print a useful error message if the parse of the expanded\n                     // macro leaves unparsed tokens.\n                     site_span: sp,\n-                    macro_ident: name,\n-                });\n+                    macro_ident: name\n+                })\n             }\n             Failure(sp, tok) => if sp.lo() >= best_fail_spot.lo() {\n                 best_fail_spot = sp;\n                 best_fail_tok = Some(tok);\n             },\n-            Error(err_sp, ref msg) => cx.span_fatal(err_sp.substitute_dummy(sp), &msg[..]),\n+            Error(err_sp, ref msg) => {\n+                cx.span_fatal(err_sp.substitute_dummy(sp), &msg[..])\n+            }\n         }\n     }\n \n@@ -196,12 +185,8 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n // Holy self-referential!\n \n /// Converts a `macro_rules!` invocation into a syntax extension.\n-pub fn compile(\n-    sess: &ParseSess,\n-    features: &Features,\n-    def: &ast::Item,\n-    edition: Edition,\n-) -> SyntaxExtension {\n+pub fn compile(sess: &ParseSess, features: &Features, def: &ast::Item, edition: Edition)\n+               -> SyntaxExtension {\n     let lhs_nm = ast::Ident::with_empty_ctxt(Symbol::gensym(\"lhs\"));\n     let rhs_nm = ast::Ident::with_empty_ctxt(Symbol::gensym(\"rhs\"));\n \n@@ -217,57 +202,42 @@ pub fn compile(\n     // ...quasiquoting this would be nice.\n     // These spans won't matter, anyways\n     let argument_gram = vec![\n-        quoted::TokenTree::Sequence(\n-            DUMMY_SP,\n-            Lrc::new(quoted::SequenceRepetition {\n-                tts: vec![\n-                    quoted::TokenTree::MetaVarDecl(DUMMY_SP, lhs_nm, ast::Ident::from_str(\"tt\")),\n-                    quoted::TokenTree::Token(DUMMY_SP, token::FatArrow),\n-                    quoted::TokenTree::MetaVarDecl(DUMMY_SP, rhs_nm, ast::Ident::from_str(\"tt\")),\n-                ],\n-                separator: Some(if body.legacy {\n-                    token::Semi\n-                } else {\n-                    token::Comma\n-                }),\n-                op: quoted::KleeneOp::OneOrMore,\n-                num_captures: 2,\n-            }),\n-        ),\n+        quoted::TokenTree::Sequence(DUMMY_SP, Lrc::new(quoted::SequenceRepetition {\n+            tts: vec![\n+                quoted::TokenTree::MetaVarDecl(DUMMY_SP, lhs_nm, ast::Ident::from_str(\"tt\")),\n+                quoted::TokenTree::Token(DUMMY_SP, token::FatArrow),\n+                quoted::TokenTree::MetaVarDecl(DUMMY_SP, rhs_nm, ast::Ident::from_str(\"tt\")),\n+            ],\n+            separator: Some(if body.legacy { token::Semi } else { token::Comma }),\n+            op: quoted::KleeneOp::OneOrMore,\n+            num_captures: 2,\n+        })),\n         // to phase into semicolon-termination instead of semicolon-separation\n-        quoted::TokenTree::Sequence(\n-            DUMMY_SP,\n-            Lrc::new(quoted::SequenceRepetition {\n-                tts: vec![quoted::TokenTree::Token(DUMMY_SP, token::Semi)],\n-                separator: None,\n-                op: quoted::KleeneOp::ZeroOrMore,\n-                num_captures: 0,\n-            }),\n-        ),\n+        quoted::TokenTree::Sequence(DUMMY_SP, Lrc::new(quoted::SequenceRepetition {\n+            tts: vec![quoted::TokenTree::Token(DUMMY_SP, token::Semi)],\n+            separator: None,\n+            op: quoted::KleeneOp::ZeroOrMore,\n+            num_captures: 0\n+        })),\n     ];\n \n     let argument_map = match parse(sess, body.stream(), &argument_gram, None, true) {\n         Success(m) => m,\n         Failure(sp, tok) => {\n             let s = parse_failure_msg(tok);\n-            sess.span_diagnostic\n-                .span_fatal(sp.substitute_dummy(def.span), &s)\n-                .raise();\n+            sess.span_diagnostic.span_fatal(sp.substitute_dummy(def.span), &s).raise();\n         }\n         Error(sp, s) => {\n-            sess.span_diagnostic\n-                .span_fatal(sp.substitute_dummy(def.span), &s)\n-                .raise();\n+            sess.span_diagnostic.span_fatal(sp.substitute_dummy(def.span), &s).raise();\n         }\n     };\n \n     let mut valid = true;\n \n     // Extract the arguments:\n     let lhses = match *argument_map[&lhs_nm] {\n-        MatchedSeq(ref s, _) => s\n-            .iter()\n-            .map(|m| {\n+        MatchedSeq(ref s, _) => {\n+            s.iter().map(|m| {\n                 if let MatchedNonterminal(ref nt) = *m {\n                     if let NtTT(ref tt) = **nt {\n                         let tt = quoted::parse(\n@@ -277,25 +247,22 @@ pub fn compile(\n                             features,\n                             &def.attrs,\n                             edition,\n-                        ).pop()\n-                            .unwrap();\n+                        )\n+                        .pop()\n+                        .unwrap();\n                         valid &= check_lhs_nt_follows(sess, features, &def.attrs, &tt);\n                         return tt;\n                     }\n                 }\n-                sess.span_diagnostic\n-                    .span_bug(def.span, \"wrong-structured lhs\")\n-            })\n-            .collect::<Vec<quoted::TokenTree>>(),\n-        _ => sess\n-            .span_diagnostic\n-            .span_bug(def.span, \"wrong-structured lhs\"),\n+                sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n+            }).collect::<Vec<quoted::TokenTree>>()\n+        }\n+        _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n     };\n \n     let rhses = match *argument_map[&rhs_nm] {\n-        MatchedSeq(ref s, _) => s\n-            .iter()\n-            .map(|m| {\n+        MatchedSeq(ref s, _) => {\n+            s.iter().map(|m| {\n                 if let MatchedNonterminal(ref nt) = *m {\n                     if let NtTT(ref tt) = **nt {\n                         return quoted::parse(\n@@ -306,16 +273,13 @@ pub fn compile(\n                             &def.attrs,\n                             edition,\n                         ).pop()\n-                            .unwrap();\n+                         .unwrap();\n                     }\n                 }\n-                sess.span_diagnostic\n-                    .span_bug(def.span, \"wrong-structured lhs\")\n-            })\n-            .collect::<Vec<quoted::TokenTree>>(),\n-        _ => sess\n-            .span_diagnostic\n-            .span_bug(def.span, \"wrong-structured rhs\"),\n+                sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n+            }).collect::<Vec<quoted::TokenTree>>()\n+        }\n+        _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured rhs\")\n     };\n \n     for rhs in &rhses {\n@@ -344,14 +308,14 @@ pub fn compile(\n             }\n         }\n \n-        let unstable_feature = attr::find_stability(&sess.span_diagnostic, &def.attrs, def.span)\n-            .and_then(|stability| {\n-                if let attr::StabilityLevel::Unstable { issue, .. } = stability.level {\n-                    Some((stability.feature, issue))\n-                } else {\n-                    None\n-                }\n-            });\n+        let unstable_feature = attr::find_stability(&sess.span_diagnostic,\n+                                                    &def.attrs, def.span).and_then(|stability| {\n+            if let attr::StabilityLevel::Unstable { issue, .. } = stability.level {\n+                Some((stability.feature, issue))\n+            } else {\n+                None\n+            }\n+        });\n \n         NormalTT {\n             expander,\n@@ -374,12 +338,10 @@ pub fn compile(\n     }\n }\n \n-fn check_lhs_nt_follows(\n-    sess: &ParseSess,\n-    features: &Features,\n-    attrs: &[ast::Attribute],\n-    lhs: &quoted::TokenTree,\n-) -> bool {\n+fn check_lhs_nt_follows(sess: &ParseSess,\n+                        features: &Features,\n+                        attrs: &[ast::Attribute],\n+                        lhs: &quoted::TokenTree) -> bool {\n     // lhs is going to be like TokenTree::Delimited(...), where the\n     // entire lhs is those tts. Or, it can be a \"bare sequence\", not wrapped in parens.\n     if let quoted::TokenTree::Delimited(_, ref tts) = *lhs {\n@@ -404,15 +366,15 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n                 return false;\n             },\n             TokenTree::Sequence(span, ref seq) => {\n-                if seq.separator.is_none() && seq.tts.iter().all(|seq_tt| match *seq_tt {\n-                    TokenTree::MetaVarDecl(_, _, id) => id.name == \"vis\",\n-                    TokenTree::Sequence(_, ref sub_seq) => {\n-                        sub_seq.op == quoted::KleeneOp::ZeroOrMore\n+                if seq.separator.is_none() && seq.tts.iter().all(|seq_tt| {\n+                    match *seq_tt {\n+                        TokenTree::MetaVarDecl(_, _, id) => id.name == \"vis\",\n+                        TokenTree::Sequence(_, ref sub_seq) =>\n+                            sub_seq.op == quoted::KleeneOp::ZeroOrMore,\n+                        _ => false,\n                     }\n-                    _ => false,\n                 }) {\n-                    sess.span_diagnostic\n-                        .span_err(span, \"repetition matches empty token tree\");\n+                    sess.span_diagnostic.span_err(span, \"repetition matches empty token tree\");\n                     return false;\n                 }\n                 if !check_lhs_no_empty_seq(sess, &seq.tts) {\n@@ -428,19 +390,15 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n fn check_rhs(sess: &ParseSess, rhs: &quoted::TokenTree) -> bool {\n     match *rhs {\n         quoted::TokenTree::Delimited(..) => return true,\n-        _ => sess\n-            .span_diagnostic\n-            .span_err(rhs.span(), \"macro rhs must be delimited\"),\n+        _ => sess.span_diagnostic.span_err(rhs.span(), \"macro rhs must be delimited\")\n     }\n     false\n }\n \n-fn check_matcher(\n-    sess: &ParseSess,\n-    features: &Features,\n-    attrs: &[ast::Attribute],\n-    matcher: &[quoted::TokenTree],\n-) -> bool {\n+fn check_matcher(sess: &ParseSess,\n+                 features: &Features,\n+                 attrs: &[ast::Attribute],\n+                 matcher: &[quoted::TokenTree]) -> bool {\n     let first_sets = FirstSets::new(matcher);\n     let empty_suffix = TokenSet::empty();\n     let err = sess.span_diagnostic.err_count();\n@@ -474,9 +432,7 @@ impl FirstSets {\n     fn new(tts: &[quoted::TokenTree]) -> FirstSets {\n         use self::quoted::TokenTree;\n \n-        let mut sets = FirstSets {\n-            first: HashMap::new(),\n-        };\n+        let mut sets = FirstSets { first: HashMap::new() };\n         build_recur(&mut sets, tts);\n         return sets;\n \n@@ -515,20 +471,16 @@ impl FirstSets {\n                         // If the sequence contents can be empty, then the first\n                         // token could be the separator token itself.\n \n-                        if let (Some(ref sep), true) =\n-                            (seq_rep.separator.clone(), subfirst.maybe_empty)\n-                        {\n+                        if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n+                                                        subfirst.maybe_empty) {\n                             first.add_one_maybe(TokenTree::Token(sp, sep.clone()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n                         if subfirst.maybe_empty || seq_rep.op == quoted::KleeneOp::ZeroOrMore {\n                             // If sequence is potentially empty, then\n                             // union them (preserving first emptiness).\n-                            first.add_all(&TokenSet {\n-                                maybe_empty: true,\n-                                ..subfirst\n-                            });\n+                            first.add_all(&TokenSet { maybe_empty: true, ..subfirst });\n                         } else {\n                             // Otherwise, sequence guaranteed\n                             // non-empty; replace first.\n@@ -562,18 +514,19 @@ impl FirstSets {\n                 TokenTree::Sequence(sp, ref seq_rep) => {\n                     match self.first.get(&sp) {\n                         Some(&Some(ref subfirst)) => {\n+\n                             // If the sequence contents can be empty, then the first\n                             // token could be the separator token itself.\n \n-                            if let (Some(ref sep), true) =\n-                                (seq_rep.separator.clone(), subfirst.maybe_empty)\n-                            {\n+                            if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n+                                                            subfirst.maybe_empty) {\n                                 first.add_one_maybe(TokenTree::Token(sp, sep.clone()));\n                             }\n \n                             assert!(first.maybe_empty);\n                             first.add_all(subfirst);\n-                            if subfirst.maybe_empty || seq_rep.op == quoted::KleeneOp::ZeroOrMore {\n+                            if subfirst.maybe_empty ||\n+                               seq_rep.op == quoted::KleeneOp::ZeroOrMore {\n                                 // continue scanning for more first\n                                 // tokens, but also make sure we\n                                 // restore empty-tracking state\n@@ -621,20 +574,12 @@ struct TokenSet {\n \n impl TokenSet {\n     // Returns a set for the empty sequence.\n-    fn empty() -> Self {\n-        TokenSet {\n-            tokens: Vec::new(),\n-            maybe_empty: true,\n-        }\n-    }\n+    fn empty() -> Self { TokenSet { tokens: Vec::new(), maybe_empty: true } }\n \n     // Returns the set `{ tok }` for the single-token (and thus\n     // non-empty) sequence [tok].\n     fn singleton(tok: quoted::TokenTree) -> Self {\n-        TokenSet {\n-            tokens: vec![tok],\n-            maybe_empty: false,\n-        }\n+        TokenSet { tokens: vec![tok], maybe_empty: false }\n     }\n \n     // Changes self to be the set `{ tok }`.\n@@ -698,14 +643,12 @@ impl TokenSet {\n //\n // Requires that `first_sets` is pre-computed for `matcher`;\n // see `FirstSets::new`.\n-fn check_matcher_core(\n-    sess: &ParseSess,\n-    features: &Features,\n-    attrs: &[ast::Attribute],\n-    first_sets: &FirstSets,\n-    matcher: &[quoted::TokenTree],\n-    follow: &TokenSet,\n-) -> TokenSet {\n+fn check_matcher_core(sess: &ParseSess,\n+                      features: &Features,\n+                      attrs: &[ast::Attribute],\n+                      first_sets: &FirstSets,\n+                      matcher: &[quoted::TokenTree],\n+                      follow: &TokenSet) -> TokenSet {\n     use self::quoted::TokenTree;\n \n     let mut last = TokenSet::empty();\n@@ -715,13 +658,11 @@ fn check_matcher_core(\n     // then ensure T can also be followed by any element of FOLLOW.\n     'each_token: for i in 0..matcher.len() {\n         let token = &matcher[i];\n-        let suffix = &matcher[i + 1..];\n+        let suffix = &matcher[i+1..];\n \n         let build_suffix_first = || {\n             let mut s = first_sets.first(suffix);\n-            if s.maybe_empty {\n-                s.add_all(follow);\n-            }\n+            if s.maybe_empty { s.add_all(follow); }\n             s\n         };\n \n@@ -737,12 +678,9 @@ fn check_matcher_core(\n                 let can_be_followed_by_any;\n                 if let Err(bad_frag) = has_legal_fragment_specifier(sess, features, attrs, token) {\n                     let msg = format!(\"invalid fragment specifier `{}`\", bad_frag);\n-                    sess.span_diagnostic\n-                        .struct_span_err(token.span(), &msg)\n-                        .help(\n-                            \"valid fragment specifiers are `ident`, `block`, `stmt`, `expr`, \\\n-                             `pat`, `ty`, `literal`, `path`, `meta`, `tt`, `item` and `vis`\",\n-                        )\n+                    sess.span_diagnostic.struct_span_err(token.span(), &msg)\n+                        .help(\"valid fragment specifiers are `ident`, `block`, `stmt`, `expr`, \\\n+                              `pat`, `ty`, `literal`, `path`, `meta`, `tt`, `item` and `vis`\")\n                         .emit();\n                     // (This eliminates false positives and duplicates\n                     // from error messages.)\n@@ -796,8 +734,12 @@ fn check_matcher_core(\n                 // At this point, `suffix_first` is built, and\n                 // `my_suffix` is some TokenSet that we can use\n                 // for checking the interior of `seq_rep`.\n-                let next =\n-                    check_matcher_core(sess, features, attrs, first_sets, &seq_rep.tts, my_suffix);\n+                let next = check_matcher_core(sess,\n+                                              features,\n+                                              attrs,\n+                                              first_sets,\n+                                              &seq_rep.tts,\n+                                              my_suffix);\n                 if next.maybe_empty {\n                     last.add_all(&next);\n                 } else {\n@@ -819,17 +761,16 @@ fn check_matcher_core(\n                 for next_token in &suffix_first.tokens {\n                     match is_in_follow(next_token, &frag_spec.as_str()) {\n                         Err((msg, help)) => {\n-                            sess.span_diagnostic\n-                                .struct_span_err(next_token.span(), &msg)\n-                                .help(help)\n-                                .emit();\n+                            sess.span_diagnostic.struct_span_err(next_token.span(), &msg)\n+                                .help(help).emit();\n                             // don't bother reporting every source of\n                             // conflict for a particular element of `last`.\n                             continue 'each_last;\n                         }\n                         Ok(true) => {}\n                         Ok(false) => {\n-                            let may_be = if last.tokens.len() == 1 && suffix_first.tokens.len() == 1\n+                            let may_be = if last.tokens.len() == 1 &&\n+                                suffix_first.tokens.len() == 1\n                             {\n                                 \"is\"\n                             } else {\n@@ -838,14 +779,12 @@ fn check_matcher_core(\n \n                             sess.span_diagnostic.span_err(\n                                 next_token.span(),\n-                                &format!(\n-                                    \"`${name}:{frag}` {may_be} followed by `{next}`, which \\\n-                                     is not allowed for `{frag}` fragments\",\n-                                    name = name,\n-                                    frag = frag_spec,\n-                                    next = quoted_tt_to_string(next_token),\n-                                    may_be = may_be\n-                                ),\n+                                &format!(\"`${name}:{frag}` {may_be} followed by `{next}`, which \\\n+                                          is not allowed for `{frag}` fragments\",\n+                                         name=name,\n+                                         frag=frag_spec,\n+                                         next=quoted_tt_to_string(next_token),\n+                                         may_be=may_be)\n                             );\n                         }\n                     }\n@@ -910,90 +849,77 @@ fn is_in_follow(tok: &quoted::TokenTree, frag: &str) -> Result<bool, (String, &'\n                 // since items *must* be followed by either a `;` or a `}`, we can\n                 // accept anything after them\n                 Ok(true)\n-            }\n+            },\n             \"block\" => {\n                 // anything can follow block, the braces provide an easy boundary to\n                 // maintain\n                 Ok(true)\n-            }\n-            \"stmt\" | \"expr\" => match *tok {\n+            },\n+            \"stmt\" | \"expr\"  => match *tok {\n                 TokenTree::Token(_, ref tok) => match *tok {\n                     FatArrow | Comma | Semi => Ok(true),\n-                    _ => Ok(false),\n+                    _ => Ok(false)\n                 },\n                 _ => Ok(false),\n             },\n             \"pat\" => match *tok {\n                 TokenTree::Token(_, ref tok) => match *tok {\n                     FatArrow | Comma | Eq | BinOp(token::Or) => Ok(true),\n                     Ident(i, false) if i.name == \"if\" || i.name == \"in\" => Ok(true),\n-                    _ => Ok(false),\n+                    _ => Ok(false)\n                 },\n                 _ => Ok(false),\n             },\n             \"path\" | \"ty\" => match *tok {\n                 TokenTree::Token(_, ref tok) => match *tok {\n-                    OpenDelim(token::DelimToken::Brace)\n-                    | OpenDelim(token::DelimToken::Bracket)\n-                    | Comma\n-                    | FatArrow\n-                    | Colon\n-                    | Eq\n-                    | Gt\n-                    | Semi\n-                    | BinOp(token::Or) => Ok(true),\n+                    OpenDelim(token::DelimToken::Brace) | OpenDelim(token::DelimToken::Bracket) |\n+                    Comma | FatArrow | Colon | Eq | Gt | Semi | BinOp(token::Or) => Ok(true),\n                     Ident(i, false) if i.name == \"as\" || i.name == \"where\" => Ok(true),\n-                    _ => Ok(false),\n+                    _ => Ok(false)\n                 },\n                 TokenTree::MetaVarDecl(_, _, frag) if frag.name == \"block\" => Ok(true),\n                 _ => Ok(false),\n             },\n             \"ident\" | \"lifetime\" => {\n                 // being a single token, idents and lifetimes are harmless\n                 Ok(true)\n-            }\n+            },\n             \"literal\" => {\n                 // literals may be of a single token, or two tokens (negative numbers)\n                 Ok(true)\n-            }\n+            },\n             \"meta\" | \"tt\" => {\n                 // being either a single token or a delimited sequence, tt is\n                 // harmless\n                 Ok(true)\n-            }\n+            },\n             \"vis\" => {\n                 // Explicitly disallow `priv`, on the off chance it comes back.\n                 match *tok {\n                     TokenTree::Token(_, ref tok) => match *tok {\n                         Comma => Ok(true),\n                         Ident(i, is_raw) if is_raw || i.name != \"priv\" => Ok(true),\n-                        ref tok => Ok(tok.can_begin_type()),\n+                        ref tok => Ok(tok.can_begin_type())\n                     },\n-                    TokenTree::MetaVarDecl(_, _, frag)\n-                        if frag.name == \"ident\" || frag.name == \"ty\" || frag.name == \"path\" =>\n-                    {\n-                        Ok(true)\n-                    }\n-                    _ => Ok(false),\n+                    TokenTree::MetaVarDecl(_, _, frag) if frag.name == \"ident\"\n+                                                       || frag.name == \"ty\"\n+                                                       || frag.name == \"path\" => Ok(true),\n+                    _ => Ok(false)\n                 }\n-            }\n+            },\n             \"\" => Ok(true), // keywords::Invalid\n-            _ => Err((\n-                format!(\"invalid fragment specifier `{}`\", frag),\n-                \"valid fragment specifiers are `ident`, `block`, \\\n-                 `stmt`, `expr`, `pat`, `ty`, `path`, `meta`, `tt`, \\\n-                 `literal`, `item` and `vis`\",\n-            )),\n+            _ => Err((format!(\"invalid fragment specifier `{}`\", frag),\n+                     \"valid fragment specifiers are `ident`, `block`, \\\n+                      `stmt`, `expr`, `pat`, `ty`, `path`, `meta`, `tt`, \\\n+                      `literal`, `item` and `vis`\"))\n         }\n     }\n }\n \n-fn has_legal_fragment_specifier(\n-    sess: &ParseSess,\n-    features: &Features,\n-    attrs: &[ast::Attribute],\n-    tok: &quoted::TokenTree,\n-) -> Result<(), String> {\n+fn has_legal_fragment_specifier(sess: &ParseSess,\n+                                features: &Features,\n+                                attrs: &[ast::Attribute],\n+                                tok: &quoted::TokenTree) -> Result<(), String> {\n     debug!(\"has_legal_fragment_specifier({:?})\", tok);\n     if let quoted::TokenTree::MetaVarDecl(_, _, ref frag_spec) = *tok {\n         let frag_name = frag_spec.as_str();\n@@ -1005,45 +931,38 @@ fn has_legal_fragment_specifier(\n     Ok(())\n }\n \n-fn is_legal_fragment_specifier(\n-    sess: &ParseSess,\n-    features: &Features,\n-    attrs: &[ast::Attribute],\n-    frag_name: &str,\n-    frag_span: Span,\n-) -> bool {\n+fn is_legal_fragment_specifier(sess: &ParseSess,\n+                               features: &Features,\n+                               attrs: &[ast::Attribute],\n+                               frag_name: &str,\n+                               frag_span: Span) -> bool {\n     match frag_name {\n-        \"item\" | \"block\" | \"stmt\" | \"expr\" | \"pat\" | \"lifetime\" | \"path\" | \"ty\" | \"ident\"\n-        | \"meta\" | \"tt\" | \"\" => true,\n+        \"item\" | \"block\" | \"stmt\" | \"expr\" | \"pat\" | \"lifetime\" |\n+        \"path\" | \"ty\" | \"ident\" | \"meta\" | \"tt\" | \"\" => true,\n         \"literal\" => {\n-            if !features.macro_literal_matcher\n-                && !attr::contains_name(attrs, \"allow_internal_unstable\")\n-            {\n+            if !features.macro_literal_matcher &&\n+               !attr::contains_name(attrs, \"allow_internal_unstable\") {\n                 let explain = feature_gate::EXPLAIN_LITERAL_MATCHER;\n-                emit_feature_err(\n-                    sess,\n-                    \"macro_literal_matcher\",\n-                    frag_span,\n-                    GateIssue::Language,\n-                    explain,\n-                );\n+                emit_feature_err(sess,\n+                                 \"macro_literal_matcher\",\n+                                 frag_span,\n+                                 GateIssue::Language,\n+                                 explain);\n             }\n             true\n-        }\n+        },\n         \"vis\" => {\n-            if !features.macro_vis_matcher && !attr::contains_name(attrs, \"allow_internal_unstable\")\n-            {\n+            if !features.macro_vis_matcher &&\n+               !attr::contains_name(attrs, \"allow_internal_unstable\") {\n                 let explain = feature_gate::EXPLAIN_VIS_MATCHER;\n-                emit_feature_err(\n-                    sess,\n-                    \"macro_vis_matcher\",\n-                    frag_span,\n-                    GateIssue::Language,\n-                    explain,\n-                );\n+                emit_feature_err(sess,\n+                                 \"macro_vis_matcher\",\n+                                 frag_span,\n+                                 GateIssue::Language,\n+                                 explain);\n             }\n             true\n-        }\n+        },\n         _ => false,\n     }\n }\n@@ -1053,9 +972,7 @@ fn quoted_tt_to_string(tt: &quoted::TokenTree) -> String {\n         quoted::TokenTree::Token(_, ref tok) => ::print::pprust::token_to_string(tok),\n         quoted::TokenTree::MetaVar(_, name) => format!(\"${}\", name),\n         quoted::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n-        _ => panic!(\n-            \"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n-             in follow set checker\"\n-        ),\n+        _ => panic!(\"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n+                     in follow set checker\"),\n     }\n }"}, {"sha": "e209e077bf4db999c675d31ba03926a4b941d3b8", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5d872727e02d9cc67813fa7f00763e355d39ae06/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5d872727e02d9cc67813fa7f00763e355d39ae06/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=5d872727e02d9cc67813fa7f00763e355d39ae06", "patch": "@@ -13,7 +13,7 @@ use feature_gate::{self, emit_feature_err, Features, GateIssue};\n use parse::{token, ParseSess};\n use print::pprust;\n use symbol::keywords;\n-use syntax_pos::{edition::Edition, BytePos, Span, DUMMY_SP};\n+use syntax_pos::{edition::Edition, BytePos, Span};\n use tokenstream;\n use {ast, attr};\n "}]}