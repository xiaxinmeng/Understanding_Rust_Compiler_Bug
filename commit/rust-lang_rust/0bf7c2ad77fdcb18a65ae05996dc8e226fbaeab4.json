{"sha": "0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBiZjdjMmFkNzdmZGNiMThhNjVhZTA1OTk2ZGM4ZTIyNmZiYWVhYjQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-03-27T21:36:51Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-03-27T21:36:51Z"}, "message": "Auto merge of #70162 - cjgillot:split_query, r=Zoxc\n\nMove the query system to a dedicated crate\n\nThe query system `rustc::ty::query` is split out into the `rustc_query_system` crate.\n\nSome commits are unformatted, to ease rebasing.\n\nBased on #67761 and #69910.\n\nr? @Zoxc", "tree": {"sha": "a16379a79bc3e283c99f2aa2aabe007754c36684", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a16379a79bc3e283c99f2aa2aabe007754c36684"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "html_url": "https://github.com/rust-lang/rust/commit/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "75208942f6144daac669e8e382029fc33bdce841", "url": "https://api.github.com/repos/rust-lang/rust/commits/75208942f6144daac669e8e382029fc33bdce841", "html_url": "https://github.com/rust-lang/rust/commit/75208942f6144daac669e8e382029fc33bdce841"}, {"sha": "2d7bbda966744f5eff12135bb523ac9c1d561cf0", "url": "https://api.github.com/repos/rust-lang/rust/commits/2d7bbda966744f5eff12135bb523ac9c1d561cf0", "html_url": "https://github.com/rust-lang/rust/commit/2d7bbda966744f5eff12135bb523ac9c1d561cf0"}], "stats": {"total": 3085, "additions": 1556, "deletions": 1529}, "files": [{"sha": "a592c82225e6de0e9bf2692eb41a297bb72fa410", "filename": "Cargo.lock", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -4081,12 +4081,12 @@ version = \"0.0.0\"\n dependencies = [\n  \"log\",\n  \"parking_lot 0.9.0\",\n- \"rustc_ast\",\n+ \"rustc-rayon-core\",\n  \"rustc_data_structures\",\n  \"rustc_errors\",\n- \"rustc_hir\",\n  \"rustc_index\",\n  \"rustc_macros\",\n+ \"rustc_span\",\n  \"serialize\",\n  \"smallvec 1.0.0\",\n ]"}, {"sha": "f56df19bfb0617e1ac89f2799015c02dda05c3c3", "filename": "src/librustc/dep_graph/mod.rs", "status": "modified", "additions": 18, "deletions": 23, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fmod.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -8,7 +8,6 @@ use rustc_errors::Diagnostic;\n use rustc_hir::def_id::DefId;\n \n mod dep_node;\n-mod safe;\n \n pub(crate) use rustc_query_system::dep_graph::DepNodeParams;\n pub use rustc_query_system::dep_graph::{\n@@ -17,8 +16,6 @@ pub use rustc_query_system::dep_graph::{\n };\n \n pub use dep_node::{label_strs, DepConstructor, DepKind, DepNode, DepNodeExt};\n-pub use safe::AssertDepGraphSafe;\n-pub use safe::DepGraphSafe;\n \n pub type DepGraph = rustc_query_system::dep_graph::DepGraph<DepKind>;\n pub type TaskDeps = rustc_query_system::dep_graph::TaskDeps<DepKind>;\n@@ -27,6 +24,8 @@ pub type PreviousDepGraph = rustc_query_system::dep_graph::PreviousDepGraph<DepK\n pub type SerializedDepGraph = rustc_query_system::dep_graph::SerializedDepGraph<DepKind>;\n \n impl rustc_query_system::dep_graph::DepKind for DepKind {\n+    const NULL: Self = DepKind::Null;\n+\n     fn is_eval_always(&self) -> bool {\n         DepKind::is_eval_always(self)\n     }\n@@ -82,6 +81,10 @@ impl rustc_query_system::dep_graph::DepKind for DepKind {\n             op(icx.task_deps)\n         })\n     }\n+\n+    fn can_reconstruct_query_key(&self) -> bool {\n+        DepKind::can_reconstruct_query_key(self)\n+    }\n }\n \n impl<'tcx> DepContext for TyCtxt<'tcx> {\n@@ -92,6 +95,10 @@ impl<'tcx> DepContext for TyCtxt<'tcx> {\n         TyCtxt::create_stable_hashing_context(*self)\n     }\n \n+    fn debug_dep_tasks(&self) -> bool {\n+        self.sess.opts.debugging_opts.dep_tasks\n+    }\n+\n     fn try_force_from_dep_node(&self, dep_node: &DepNode) -> bool {\n         // FIXME: This match is just a workaround for incremental bugs and should\n         // be removed. https://github.com/rust-lang/rust/issues/62649 is one such\n@@ -160,6 +167,14 @@ impl<'tcx> DepContext for TyCtxt<'tcx> {\n         self.queries.on_disk_cache.store_diagnostics(dep_node_index, diagnostics)\n     }\n \n+    fn store_diagnostics_for_anon_node(\n+        &self,\n+        dep_node_index: DepNodeIndex,\n+        diagnostics: ThinVec<Diagnostic>,\n+    ) {\n+        self.queries.on_disk_cache.store_diagnostics_for_anon_node(dep_node_index, diagnostics)\n+    }\n+\n     fn profiler(&self) -> &SelfProfilerRef {\n         &self.prof\n     }\n@@ -169,23 +184,3 @@ fn def_id_corresponds_to_hir_dep_node(tcx: TyCtxt<'_>, def_id: DefId) -> bool {\n     let hir_id = tcx.hir().as_local_hir_id(def_id).unwrap();\n     def_id.index == hir_id.owner.local_def_index\n }\n-\n-impl rustc_query_system::HashStableContext for StableHashingContext<'_> {\n-    fn debug_dep_tasks(&self) -> bool {\n-        self.sess().opts.debugging_opts.dep_tasks\n-    }\n-}\n-\n-impl rustc_query_system::HashStableContextProvider<StableHashingContext<'tcx>> for TyCtxt<'tcx> {\n-    fn get_stable_hashing_context(&self) -> StableHashingContext<'tcx> {\n-        self.create_stable_hashing_context()\n-    }\n-}\n-\n-impl rustc_query_system::HashStableContextProvider<StableHashingContext<'a>>\n-    for StableHashingContext<'a>\n-{\n-    fn get_stable_hashing_context(&self) -> Self {\n-        self.clone()\n-    }\n-}"}, {"sha": "47a1c09672ff60aad8fa8c5f84b788d0e34b1b02", "filename": "src/librustc/dep_graph/safe.rs", "status": "removed", "additions": 0, "deletions": 9, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/75208942f6144daac669e8e382029fc33bdce841/src%2Flibrustc%2Fdep_graph%2Fsafe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75208942f6144daac669e8e382029fc33bdce841/src%2Flibrustc%2Fdep_graph%2Fsafe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fsafe.rs?ref=75208942f6144daac669e8e382029fc33bdce841", "patch": "@@ -1,9 +0,0 @@\n-//! The `DepGraphSafe` trait\n-\n-use crate::ty::TyCtxt;\n-\n-pub use rustc_query_system::dep_graph::{AssertDepGraphSafe, DepGraphSafe};\n-\n-/// The type context itself can be used to access all kinds of tracked\n-/// state, but those accesses should always generate read events.\n-impl<'tcx> DepGraphSafe for TyCtxt<'tcx> {}"}, {"sha": "ac3faae072b68c6a535c478d8cbf6c9ae2690950", "filename": "src/librustc/ich/hcx.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fich%2Fhcx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fich%2Fhcx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fhcx.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -194,8 +194,6 @@ impl<'a> StableHashingContextProvider<'a> for StableHashingContext<'a> {\n     }\n }\n \n-impl<'a> crate::dep_graph::DepGraphSafe for StableHashingContext<'a> {}\n-\n impl<'a> HashStable<StableHashingContext<'a>> for ast::NodeId {\n     fn hash_stable(&self, _: &mut StableHashingContext<'a>, _: &mut StableHasher) {\n         panic!(\"Node IDs should not appear in incremental state\");"}, {"sha": "3d4806f53be7992a2abe460b69af336c11e3b371", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -1603,7 +1603,7 @@ nop_list_lift! {substs; GenericArg<'a> => GenericArg<'tcx>}\n pub mod tls {\n     use super::{ptr_eq, GlobalCtxt, TyCtxt};\n \n-    use crate::dep_graph::TaskDeps;\n+    use crate::dep_graph::{DepKind, TaskDeps};\n     use crate::ty::query;\n     use rustc_data_structures::sync::{self, Lock};\n     use rustc_data_structures::thin_vec::ThinVec;\n@@ -1630,7 +1630,7 @@ pub mod tls {\n \n         /// The current query job, if any. This is updated by `JobOwner::start` in\n         /// `ty::query::plumbing` when executing a query.\n-        pub query: Option<query::QueryJobId>,\n+        pub query: Option<query::QueryJobId<DepKind>>,\n \n         /// Where to store diagnostics for the current query job, if any.\n         /// This is updated by `JobOwner::start` in `ty::query::plumbing` when executing a query."}, {"sha": "72a0fdf1567268f03338dbd0db6afc97ad70fb85", "filename": "src/librustc/ty/query/config.rs", "status": "removed", "additions": 0, "deletions": 82, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/75208942f6144daac669e8e382029fc33bdce841/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75208942f6144daac669e8e382029fc33bdce841/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs?ref=75208942f6144daac669e8e382029fc33bdce841", "patch": "@@ -1,82 +0,0 @@\n-use crate::dep_graph::SerializedDepNodeIndex;\n-use crate::dep_graph::{DepKind, DepNode};\n-use crate::ty::query::caches::QueryCache;\n-use crate::ty::query::plumbing::CycleError;\n-use crate::ty::query::QueryState;\n-use crate::ty::TyCtxt;\n-use rustc_data_structures::profiling::ProfileCategory;\n-use rustc_hir::def_id::DefId;\n-\n-use crate::ich::StableHashingContext;\n-use rustc_data_structures::fingerprint::Fingerprint;\n-use std::borrow::Cow;\n-use std::fmt::Debug;\n-use std::hash::Hash;\n-\n-// Query configuration and description traits.\n-\n-// FIXME(eddyb) false positive, the lifetime parameter is used for `Key`/`Value`.\n-#[allow(unused_lifetimes)]\n-pub trait QueryConfig<'tcx> {\n-    const NAME: &'static str;\n-    const CATEGORY: ProfileCategory;\n-\n-    type Key: Eq + Hash + Clone + Debug;\n-    type Value: Clone;\n-}\n-\n-pub(crate) trait QueryAccessors<'tcx>: QueryConfig<'tcx> {\n-    const ANON: bool;\n-    const EVAL_ALWAYS: bool;\n-    const DEP_KIND: DepKind;\n-\n-    type Cache: QueryCache<Key = Self::Key, Value = Self::Value>;\n-\n-    // Don't use this method to access query results, instead use the methods on TyCtxt\n-    fn query_state<'a>(tcx: TyCtxt<'tcx>) -> &'a QueryState<'tcx, Self::Cache>;\n-\n-    fn to_dep_node(tcx: TyCtxt<'tcx>, key: &Self::Key) -> DepNode;\n-\n-    // Don't use this method to compute query results, instead use the methods on TyCtxt\n-    fn compute(tcx: TyCtxt<'tcx>, key: Self::Key) -> Self::Value;\n-\n-    fn hash_result(hcx: &mut StableHashingContext<'_>, result: &Self::Value)\n-    -> Option<Fingerprint>;\n-\n-    fn handle_cycle_error(tcx: TyCtxt<'tcx>, error: CycleError<'tcx>) -> Self::Value;\n-}\n-\n-pub(crate) trait QueryDescription<'tcx>: QueryAccessors<'tcx> {\n-    fn describe(tcx: TyCtxt<'_>, key: Self::Key) -> Cow<'static, str>;\n-\n-    #[inline]\n-    fn cache_on_disk(_: TyCtxt<'tcx>, _: Self::Key, _: Option<&Self::Value>) -> bool {\n-        false\n-    }\n-\n-    fn try_load_from_disk(_: TyCtxt<'tcx>, _: SerializedDepNodeIndex) -> Option<Self::Value> {\n-        bug!(\"QueryDescription::load_from_disk() called for an unsupported query.\")\n-    }\n-}\n-\n-impl<'tcx, M: QueryAccessors<'tcx, Key = DefId>> QueryDescription<'tcx> for M {\n-    default fn describe(tcx: TyCtxt<'_>, def_id: DefId) -> Cow<'static, str> {\n-        if !tcx.sess.verbose() {\n-            format!(\"processing `{}`\", tcx.def_path_str(def_id)).into()\n-        } else {\n-            let name = ::std::any::type_name::<M>();\n-            format!(\"processing {:?} with query `{}`\", def_id, name).into()\n-        }\n-    }\n-\n-    default fn cache_on_disk(_: TyCtxt<'tcx>, _: Self::Key, _: Option<&Self::Value>) -> bool {\n-        false\n-    }\n-\n-    default fn try_load_from_disk(\n-        _: TyCtxt<'tcx>,\n-        _: SerializedDepNodeIndex,\n-    ) -> Option<Self::Value> {\n-        bug!(\"QueryDescription::load_from_disk() called for an unsupported query.\")\n-    }\n-}"}, {"sha": "5f7a9e81158e0580809d4133bbde8f60a7471565", "filename": "src/librustc/ty/query/job.rs", "status": "modified", "additions": 3, "deletions": 563, "changes": 566, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fjob.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -1,531 +1,12 @@\n-use crate::dep_graph::DepKind;\n-use crate::ty::context::TyCtxt;\n-use crate::ty::query::plumbing::CycleError;\n-use crate::ty::query::Query;\n use crate::ty::tls;\n \n-use rustc_data_structures::fx::FxHashMap;\n-use rustc_span::Span;\n-\n-use std::convert::TryFrom;\n-use std::marker::PhantomData;\n-use std::num::NonZeroU32;\n-\n-#[cfg(parallel_compiler)]\n-use {\n-    parking_lot::{Condvar, Mutex},\n-    rustc_data_structures::fx::FxHashSet,\n-    rustc_data_structures::stable_hasher::{HashStable, StableHasher},\n-    rustc_data_structures::sync::Lock,\n-    rustc_data_structures::sync::Lrc,\n-    rustc_data_structures::{jobserver, OnDrop},\n-    rustc_rayon_core as rayon_core,\n-    rustc_span::DUMMY_SP,\n-    std::iter::FromIterator,\n-    std::{mem, process, thread},\n-};\n-\n-/// Represents a span and a query key.\n-#[derive(Clone, Debug)]\n-pub struct QueryInfo<'tcx> {\n-    /// The span corresponding to the reason for which this query was required.\n-    pub span: Span,\n-    pub query: Query<'tcx>,\n-}\n-\n-type QueryMap<'tcx> = FxHashMap<QueryJobId, QueryJobInfo<'tcx>>;\n-\n-/// A value uniquely identifiying an active query job within a shard in the query cache.\n-#[derive(Copy, Clone, Eq, PartialEq, Hash)]\n-pub struct QueryShardJobId(pub NonZeroU32);\n-\n-/// A value uniquely identifiying an active query job.\n-#[derive(Copy, Clone, Eq, PartialEq, Hash)]\n-pub struct QueryJobId {\n-    /// Which job within a shard is this\n-    pub job: QueryShardJobId,\n-\n-    /// In which shard is this job\n-    pub shard: u16,\n-\n-    /// What kind of query this job is\n-    pub kind: DepKind,\n-}\n-\n-impl QueryJobId {\n-    pub fn new(job: QueryShardJobId, shard: usize, kind: DepKind) -> Self {\n-        QueryJobId { job, shard: u16::try_from(shard).unwrap(), kind }\n-    }\n-\n-    fn query<'tcx>(self, map: &QueryMap<'tcx>) -> Query<'tcx> {\n-        map.get(&self).unwrap().info.query.clone()\n-    }\n-\n-    #[cfg(parallel_compiler)]\n-    fn span(self, map: &QueryMap<'_>) -> Span {\n-        map.get(&self).unwrap().job.span\n-    }\n-\n-    #[cfg(parallel_compiler)]\n-    fn parent(self, map: &QueryMap<'_>) -> Option<QueryJobId> {\n-        map.get(&self).unwrap().job.parent\n-    }\n-\n-    #[cfg(parallel_compiler)]\n-    fn latch<'a, 'tcx>(self, map: &'a QueryMap<'tcx>) -> Option<&'a QueryLatch<'tcx>> {\n-        map.get(&self).unwrap().job.latch.as_ref()\n-    }\n-}\n-\n-pub struct QueryJobInfo<'tcx> {\n-    pub info: QueryInfo<'tcx>,\n-    pub job: QueryJob<'tcx>,\n-}\n-\n-/// Represents an active query job.\n-#[derive(Clone)]\n-pub struct QueryJob<'tcx> {\n-    pub id: QueryShardJobId,\n-\n-    /// The span corresponding to the reason for which this query was required.\n-    pub span: Span,\n-\n-    /// The parent query job which created this job and is implicitly waiting on it.\n-    pub parent: Option<QueryJobId>,\n-\n-    /// The latch that is used to wait on this job.\n-    #[cfg(parallel_compiler)]\n-    latch: Option<QueryLatch<'tcx>>,\n-\n-    dummy: PhantomData<QueryLatch<'tcx>>,\n-}\n-\n-impl<'tcx> QueryJob<'tcx> {\n-    /// Creates a new query job.\n-    pub fn new(id: QueryShardJobId, span: Span, parent: Option<QueryJobId>) -> Self {\n-        QueryJob {\n-            id,\n-            span,\n-            parent,\n-            #[cfg(parallel_compiler)]\n-            latch: None,\n-            dummy: PhantomData,\n-        }\n-    }\n-\n-    #[cfg(parallel_compiler)]\n-    pub(super) fn latch(&mut self, _id: QueryJobId) -> QueryLatch<'tcx> {\n-        if self.latch.is_none() {\n-            self.latch = Some(QueryLatch::new());\n-        }\n-        self.latch.as_ref().unwrap().clone()\n-    }\n-\n-    #[cfg(not(parallel_compiler))]\n-    pub(super) fn latch(&mut self, id: QueryJobId) -> QueryLatch<'tcx> {\n-        QueryLatch { id, dummy: PhantomData }\n-    }\n-\n-    /// Signals to waiters that the query is complete.\n-    ///\n-    /// This does nothing for single threaded rustc,\n-    /// as there are no concurrent jobs which could be waiting on us\n-    pub fn signal_complete(self) {\n-        #[cfg(parallel_compiler)]\n-        self.latch.map(|latch| latch.set());\n-    }\n-}\n-\n-#[cfg(not(parallel_compiler))]\n-#[derive(Clone)]\n-pub(super) struct QueryLatch<'tcx> {\n-    id: QueryJobId,\n-    dummy: PhantomData<&'tcx ()>,\n-}\n-\n-#[cfg(not(parallel_compiler))]\n-impl<'tcx> QueryLatch<'tcx> {\n-    pub(super) fn find_cycle_in_stack(&self, tcx: TyCtxt<'tcx>, span: Span) -> CycleError<'tcx> {\n-        let query_map = tcx.queries.try_collect_active_jobs().unwrap();\n-\n-        // Get the current executing query (waiter) and find the waitee amongst its parents\n-        let mut current_job = tls::with_related_context(tcx, |icx| icx.query);\n-        let mut cycle = Vec::new();\n-\n-        while let Some(job) = current_job {\n-            let info = query_map.get(&job).unwrap();\n-            cycle.push(info.info.clone());\n-\n-            if job == self.id {\n-                cycle.reverse();\n-\n-                // This is the end of the cycle\n-                // The span entry we included was for the usage\n-                // of the cycle itself, and not part of the cycle\n-                // Replace it with the span which caused the cycle to form\n-                cycle[0].span = span;\n-                // Find out why the cycle itself was used\n-                let usage = info\n-                    .job\n-                    .parent\n-                    .as_ref()\n-                    .map(|parent| (info.info.span, parent.query(&query_map)));\n-                return CycleError { usage, cycle };\n-            }\n-\n-            current_job = info.job.parent;\n-        }\n-\n-        panic!(\"did not find a cycle\")\n-    }\n-}\n-\n-#[cfg(parallel_compiler)]\n-struct QueryWaiter<'tcx> {\n-    query: Option<QueryJobId>,\n-    condvar: Condvar,\n-    span: Span,\n-    cycle: Lock<Option<CycleError<'tcx>>>,\n-}\n-\n-#[cfg(parallel_compiler)]\n-impl<'tcx> QueryWaiter<'tcx> {\n-    fn notify(&self, registry: &rayon_core::Registry) {\n-        rayon_core::mark_unblocked(registry);\n-        self.condvar.notify_one();\n-    }\n-}\n-\n-#[cfg(parallel_compiler)]\n-struct QueryLatchInfo<'tcx> {\n-    complete: bool,\n-    waiters: Vec<Lrc<QueryWaiter<'tcx>>>,\n-}\n-\n-#[cfg(parallel_compiler)]\n-#[derive(Clone)]\n-pub(super) struct QueryLatch<'tcx> {\n-    info: Lrc<Mutex<QueryLatchInfo<'tcx>>>,\n-}\n-\n-#[cfg(parallel_compiler)]\n-impl<'tcx> QueryLatch<'tcx> {\n-    fn new() -> Self {\n-        QueryLatch {\n-            info: Lrc::new(Mutex::new(QueryLatchInfo { complete: false, waiters: Vec::new() })),\n-        }\n-    }\n-\n-    /// Awaits for the query job to complete.\n-    #[cfg(parallel_compiler)]\n-    pub(super) fn wait_on(&self, tcx: TyCtxt<'tcx>, span: Span) -> Result<(), CycleError<'tcx>> {\n-        tls::with_related_context(tcx, move |icx| {\n-            let waiter = Lrc::new(QueryWaiter {\n-                query: icx.query,\n-                span,\n-                cycle: Lock::new(None),\n-                condvar: Condvar::new(),\n-            });\n-            self.wait_on_inner(&waiter);\n-            // FIXME: Get rid of this lock. We have ownership of the QueryWaiter\n-            // although another thread may still have a Lrc reference so we cannot\n-            // use Lrc::get_mut\n-            let mut cycle = waiter.cycle.lock();\n-            match cycle.take() {\n-                None => Ok(()),\n-                Some(cycle) => Err(cycle),\n-            }\n-        })\n-    }\n-\n-    /// Awaits the caller on this latch by blocking the current thread.\n-    fn wait_on_inner(&self, waiter: &Lrc<QueryWaiter<'tcx>>) {\n-        let mut info = self.info.lock();\n-        if !info.complete {\n-            // We push the waiter on to the `waiters` list. It can be accessed inside\n-            // the `wait` call below, by 1) the `set` method or 2) by deadlock detection.\n-            // Both of these will remove it from the `waiters` list before resuming\n-            // this thread.\n-            info.waiters.push(waiter.clone());\n-\n-            // If this detects a deadlock and the deadlock handler wants to resume this thread\n-            // we have to be in the `wait` call. This is ensured by the deadlock handler\n-            // getting the self.info lock.\n-            rayon_core::mark_blocked();\n-            jobserver::release_thread();\n-            waiter.condvar.wait(&mut info);\n-            // Release the lock before we potentially block in `acquire_thread`\n-            mem::drop(info);\n-            jobserver::acquire_thread();\n-        }\n-    }\n-\n-    /// Sets the latch and resumes all waiters on it\n-    fn set(&self) {\n-        let mut info = self.info.lock();\n-        debug_assert!(!info.complete);\n-        info.complete = true;\n-        let registry = rayon_core::Registry::current();\n-        for waiter in info.waiters.drain(..) {\n-            waiter.notify(&registry);\n-        }\n-    }\n-\n-    /// Removes a single waiter from the list of waiters.\n-    /// This is used to break query cycles.\n-    fn extract_waiter(&self, waiter: usize) -> Lrc<QueryWaiter<'tcx>> {\n-        let mut info = self.info.lock();\n-        debug_assert!(!info.complete);\n-        // Remove the waiter from the list of waiters\n-        info.waiters.remove(waiter)\n-    }\n-}\n-\n-/// A resumable waiter of a query. The usize is the index into waiters in the query's latch\n-#[cfg(parallel_compiler)]\n-type Waiter = (QueryJobId, usize);\n-\n-/// Visits all the non-resumable and resumable waiters of a query.\n-/// Only waiters in a query are visited.\n-/// `visit` is called for every waiter and is passed a query waiting on `query_ref`\n-/// and a span indicating the reason the query waited on `query_ref`.\n-/// If `visit` returns Some, this function returns.\n-/// For visits of non-resumable waiters it returns the return value of `visit`.\n-/// For visits of resumable waiters it returns Some(Some(Waiter)) which has the\n-/// required information to resume the waiter.\n-/// If all `visit` calls returns None, this function also returns None.\n-#[cfg(parallel_compiler)]\n-fn visit_waiters<'tcx, F>(\n-    query_map: &QueryMap<'tcx>,\n-    query: QueryJobId,\n-    mut visit: F,\n-) -> Option<Option<Waiter>>\n-where\n-    F: FnMut(Span, QueryJobId) -> Option<Option<Waiter>>,\n-{\n-    // Visit the parent query which is a non-resumable waiter since it's on the same stack\n-    if let Some(parent) = query.parent(query_map) {\n-        if let Some(cycle) = visit(query.span(query_map), parent) {\n-            return Some(cycle);\n-        }\n-    }\n-\n-    // Visit the explicit waiters which use condvars and are resumable\n-    if let Some(latch) = query.latch(query_map) {\n-        for (i, waiter) in latch.info.lock().waiters.iter().enumerate() {\n-            if let Some(waiter_query) = waiter.query {\n-                if visit(waiter.span, waiter_query).is_some() {\n-                    // Return a value which indicates that this waiter can be resumed\n-                    return Some(Some((query, i)));\n-                }\n-            }\n-        }\n-    }\n-\n-    None\n-}\n-\n-/// Look for query cycles by doing a depth first search starting at `query`.\n-/// `span` is the reason for the `query` to execute. This is initially DUMMY_SP.\n-/// If a cycle is detected, this initial value is replaced with the span causing\n-/// the cycle.\n-#[cfg(parallel_compiler)]\n-fn cycle_check<'tcx>(\n-    query_map: &QueryMap<'tcx>,\n-    query: QueryJobId,\n-    span: Span,\n-    stack: &mut Vec<(Span, QueryJobId)>,\n-    visited: &mut FxHashSet<QueryJobId>,\n-) -> Option<Option<Waiter>> {\n-    if !visited.insert(query) {\n-        return if let Some(p) = stack.iter().position(|q| q.1 == query) {\n-            // We detected a query cycle, fix up the initial span and return Some\n-\n-            // Remove previous stack entries\n-            stack.drain(0..p);\n-            // Replace the span for the first query with the cycle cause\n-            stack[0].0 = span;\n-            Some(None)\n-        } else {\n-            None\n-        };\n-    }\n-\n-    // Query marked as visited is added it to the stack\n-    stack.push((span, query));\n-\n-    // Visit all the waiters\n-    let r = visit_waiters(query_map, query, |span, successor| {\n-        cycle_check(query_map, successor, span, stack, visited)\n-    });\n-\n-    // Remove the entry in our stack if we didn't find a cycle\n-    if r.is_none() {\n-        stack.pop();\n-    }\n-\n-    r\n-}\n-\n-/// Finds out if there's a path to the compiler root (aka. code which isn't in a query)\n-/// from `query` without going through any of the queries in `visited`.\n-/// This is achieved with a depth first search.\n-#[cfg(parallel_compiler)]\n-fn connected_to_root<'tcx>(\n-    query_map: &QueryMap<'tcx>,\n-    query: QueryJobId,\n-    visited: &mut FxHashSet<QueryJobId>,\n-) -> bool {\n-    // We already visited this or we're deliberately ignoring it\n-    if !visited.insert(query) {\n-        return false;\n-    }\n-\n-    // This query is connected to the root (it has no query parent), return true\n-    if query.parent(query_map).is_none() {\n-        return true;\n-    }\n-\n-    visit_waiters(query_map, query, |_, successor| {\n-        connected_to_root(query_map, successor, visited).then_some(None)\n-    })\n-    .is_some()\n-}\n-\n-// Deterministically pick an query from a list\n-#[cfg(parallel_compiler)]\n-fn pick_query<'a, 'tcx, T, F: Fn(&T) -> (Span, QueryJobId)>(\n-    query_map: &QueryMap<'tcx>,\n-    tcx: TyCtxt<'tcx>,\n-    queries: &'a [T],\n-    f: F,\n-) -> &'a T {\n-    // Deterministically pick an entry point\n-    // FIXME: Sort this instead\n-    let mut hcx = tcx.create_stable_hashing_context();\n-    queries\n-        .iter()\n-        .min_by_key(|v| {\n-            let (span, query) = f(v);\n-            let mut stable_hasher = StableHasher::new();\n-            query.query(query_map).hash_stable(&mut hcx, &mut stable_hasher);\n-            // Prefer entry points which have valid spans for nicer error messages\n-            // We add an integer to the tuple ensuring that entry points\n-            // with valid spans are picked first\n-            let span_cmp = if span == DUMMY_SP { 1 } else { 0 };\n-            (span_cmp, stable_hasher.finish::<u64>())\n-        })\n-        .unwrap()\n-}\n-\n-/// Looks for query cycles starting from the last query in `jobs`.\n-/// If a cycle is found, all queries in the cycle is removed from `jobs` and\n-/// the function return true.\n-/// If a cycle was not found, the starting query is removed from `jobs` and\n-/// the function returns false.\n-#[cfg(parallel_compiler)]\n-fn remove_cycle<'tcx>(\n-    query_map: &QueryMap<'tcx>,\n-    jobs: &mut Vec<QueryJobId>,\n-    wakelist: &mut Vec<Lrc<QueryWaiter<'tcx>>>,\n-    tcx: TyCtxt<'tcx>,\n-) -> bool {\n-    let mut visited = FxHashSet::default();\n-    let mut stack = Vec::new();\n-    // Look for a cycle starting with the last query in `jobs`\n-    if let Some(waiter) =\n-        cycle_check(query_map, jobs.pop().unwrap(), DUMMY_SP, &mut stack, &mut visited)\n-    {\n-        // The stack is a vector of pairs of spans and queries; reverse it so that\n-        // the earlier entries require later entries\n-        let (mut spans, queries): (Vec<_>, Vec<_>) = stack.into_iter().rev().unzip();\n-\n-        // Shift the spans so that queries are matched with the span for their waitee\n-        spans.rotate_right(1);\n-\n-        // Zip them back together\n-        let mut stack: Vec<_> = spans.into_iter().zip(queries).collect();\n-\n-        // Remove the queries in our cycle from the list of jobs to look at\n-        for r in &stack {\n-            jobs.remove_item(&r.1);\n-        }\n-\n-        // Find the queries in the cycle which are\n-        // connected to queries outside the cycle\n-        let entry_points = stack\n-            .iter()\n-            .filter_map(|&(span, query)| {\n-                if query.parent(query_map).is_none() {\n-                    // This query is connected to the root (it has no query parent)\n-                    Some((span, query, None))\n-                } else {\n-                    let mut waiters = Vec::new();\n-                    // Find all the direct waiters who lead to the root\n-                    visit_waiters(query_map, query, |span, waiter| {\n-                        // Mark all the other queries in the cycle as already visited\n-                        let mut visited = FxHashSet::from_iter(stack.iter().map(|q| q.1));\n-\n-                        if connected_to_root(query_map, waiter, &mut visited) {\n-                            waiters.push((span, waiter));\n-                        }\n-\n-                        None\n-                    });\n-                    if waiters.is_empty() {\n-                        None\n-                    } else {\n-                        // Deterministically pick one of the waiters to show to the user\n-                        let waiter = *pick_query(query_map, tcx, &waiters, |s| *s);\n-                        Some((span, query, Some(waiter)))\n-                    }\n-                }\n-            })\n-            .collect::<Vec<(Span, QueryJobId, Option<(Span, QueryJobId)>)>>();\n-\n-        // Deterministically pick an entry point\n-        let (_, entry_point, usage) = pick_query(query_map, tcx, &entry_points, |e| (e.0, e.1));\n-\n-        // Shift the stack so that our entry point is first\n-        let entry_point_pos = stack.iter().position(|(_, query)| query == entry_point);\n-        if let Some(pos) = entry_point_pos {\n-            stack.rotate_left(pos);\n-        }\n-\n-        let usage = usage.as_ref().map(|(span, query)| (*span, query.query(query_map)));\n-\n-        // Create the cycle error\n-        let error = CycleError {\n-            usage,\n-            cycle: stack\n-                .iter()\n-                .map(|&(s, ref q)| QueryInfo { span: s, query: q.query(query_map) })\n-                .collect(),\n-        };\n-\n-        // We unwrap `waiter` here since there must always be one\n-        // edge which is resumeable / waited using a query latch\n-        let (waitee_query, waiter_idx) = waiter.unwrap();\n-\n-        // Extract the waiter we want to resume\n-        let waiter = waitee_query.latch(query_map).unwrap().extract_waiter(waiter_idx);\n-\n-        // Set the cycle error so it will be picked up when resumed\n-        *waiter.cycle.lock() = Some(error);\n-\n-        // Put the waiter on the list of things to resume\n-        wakelist.push(waiter);\n-\n-        true\n-    } else {\n-        false\n-    }\n-}\n+use rustc_query_system::query::deadlock;\n+use rustc_rayon_core as rayon_core;\n+use std::thread;\n \n /// Creates a new thread and forwards information in thread locals to it.\n /// The new thread runs the deadlock handler.\n /// Must only be called when a deadlock is about to happen.\n-#[cfg(parallel_compiler)]\n pub unsafe fn handle_deadlock() {\n     let registry = rayon_core::Registry::current();\n \n@@ -546,44 +27,3 @@ pub unsafe fn handle_deadlock() {\n         })\n     });\n }\n-\n-/// Detects query cycles by using depth first search over all active query jobs.\n-/// If a query cycle is found it will break the cycle by finding an edge which\n-/// uses a query latch and then resuming that waiter.\n-/// There may be multiple cycles involved in a deadlock, so this searches\n-/// all active queries for cycles before finally resuming all the waiters at once.\n-#[cfg(parallel_compiler)]\n-fn deadlock(tcx: TyCtxt<'_>, registry: &rayon_core::Registry) {\n-    let on_panic = OnDrop(|| {\n-        eprintln!(\"deadlock handler panicked, aborting process\");\n-        process::abort();\n-    });\n-\n-    let mut wakelist = Vec::new();\n-    let query_map = tcx.queries.try_collect_active_jobs().unwrap();\n-    let mut jobs: Vec<QueryJobId> = query_map.keys().cloned().collect();\n-\n-    let mut found_cycle = false;\n-\n-    while jobs.len() > 0 {\n-        if remove_cycle(&query_map, &mut jobs, &mut wakelist, tcx) {\n-            found_cycle = true;\n-        }\n-    }\n-\n-    // Check that a cycle was found. It is possible for a deadlock to occur without\n-    // a query cycle if a query which can be waited on uses Rayon to do multithreading\n-    // internally. Such a query (X) may be executing on 2 threads (A and B) and A may\n-    // wait using Rayon on B. Rayon may then switch to executing another query (Y)\n-    // which in turn will wait on X causing a deadlock. We have a false dependency from\n-    // X to Y due to Rayon waiting and a true dependency from Y to X. The algorithm here\n-    // only considers the true dependency and won't detect a cycle.\n-    assert!(found_cycle);\n-\n-    // FIXME: Ensure this won't cause a deadlock before we return\n-    for waiter in wakelist.into_iter() {\n-        waiter.notify(registry);\n-    }\n-\n-    on_panic.disable();\n-}"}, {"sha": "a261e484a85faada4d493a0fc16df0a29f74f62e", "filename": "src/librustc/ty/query/keys.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fkeys.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fkeys.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fkeys.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -4,10 +4,10 @@ use crate::infer::canonical::Canonical;\n use crate::mir;\n use crate::traits;\n use crate::ty::fast_reject::SimplifiedType;\n-use crate::ty::query::caches::DefaultCacheSelector;\n use crate::ty::subst::{GenericArg, SubstsRef};\n use crate::ty::{self, Ty, TyCtxt};\n use rustc_hir::def_id::{CrateNum, DefId, LocalDefId, LOCAL_CRATE};\n+use rustc_query_system::query::DefaultCacheSelector;\n use rustc_span::symbol::Symbol;\n use rustc_span::{Span, DUMMY_SP};\n "}, {"sha": "744237520fbfd07eaec63cd9d517b1a4eae5a8db", "filename": "src/librustc/ty/query/mod.rs", "status": "modified", "additions": 7, "deletions": 11, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -61,31 +61,27 @@ use std::sync::Arc;\n \n #[macro_use]\n mod plumbing;\n-pub(crate) use self::plumbing::CycleError;\n-use self::plumbing::*;\n+pub(crate) use rustc_query_system::query::CycleError;\n+use rustc_query_system::query::*;\n \n mod stats;\n pub use self::stats::print_stats;\n \n+#[cfg(parallel_compiler)]\n mod job;\n #[cfg(parallel_compiler)]\n pub use self::job::handle_deadlock;\n-use self::job::QueryJobInfo;\n-pub use self::job::{QueryInfo, QueryJob, QueryJobId};\n+pub use rustc_query_system::query::{QueryInfo, QueryJob, QueryJobId};\n \n mod keys;\n use self::keys::Key;\n \n mod values;\n use self::values::Value;\n \n-mod caches;\n-use self::caches::CacheSelector;\n-\n-mod config;\n-use self::config::QueryAccessors;\n-pub use self::config::QueryConfig;\n-pub(crate) use self::config::QueryDescription;\n+use rustc_query_system::query::QueryAccessors;\n+pub use rustc_query_system::query::QueryConfig;\n+pub(crate) use rustc_query_system::query::QueryDescription;\n \n mod on_disk_cache;\n pub use self::on_disk_cache::OnDiskCache;"}, {"sha": "8aecc0e698a8efe4d161b5549de3eb4d5c1b871b", "filename": "src/librustc/ty/query/on_disk_cache.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -994,7 +994,8 @@ fn encode_query_results<'a, 'tcx, Q, E>(\n     query_result_index: &mut EncodedQueryResultIndex,\n ) -> Result<(), E::Error>\n where\n-    Q: super::config::QueryDescription<'tcx, Value: Encodable>,\n+    Q: super::QueryDescription<TyCtxt<'tcx>>,\n+    Q::Value: Encodable,\n     E: 'a + TyEncoder,\n {\n     let _timer = tcx"}, {"sha": "1bb392f436fc6bbe601fa77731ba00543e71317e", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 48, "deletions": 684, "changes": 732, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -2,388 +2,83 @@\n //! generate the actual methods on tcx which find and execute the provider,\n //! manage the caches, and so forth.\n \n-use crate::dep_graph::{DepKind, DepNode, DepNodeIndex, SerializedDepNodeIndex};\n-use crate::ty::query::caches::QueryCache;\n-use crate::ty::query::config::QueryDescription;\n-use crate::ty::query::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo, QueryShardJobId};\n+use crate::dep_graph::DepGraph;\n use crate::ty::query::Query;\n-use crate::ty::tls;\n+use crate::ty::tls::{self, ImplicitCtxt};\n use crate::ty::{self, TyCtxt};\n+use rustc_query_system::query::QueryContext;\n+use rustc_query_system::query::{CycleError, QueryJobId, QueryJobInfo};\n \n-#[cfg(not(parallel_compiler))]\n-use rustc_data_structures::cold_path;\n-use rustc_data_structures::fx::{FxHashMap, FxHasher};\n-use rustc_data_structures::sharded::Sharded;\n-use rustc_data_structures::sync::{Lock, LockGuard};\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::sync::Lock;\n use rustc_data_structures::thin_vec::ThinVec;\n-use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, FatalError, Handler, Level};\n-use rustc_span::source_map::DUMMY_SP;\n+use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, Handler, Level};\n+use rustc_span::def_id::DefId;\n use rustc_span::Span;\n-use std::collections::hash_map::Entry;\n-use std::convert::TryFrom;\n-use std::fmt::Debug;\n-use std::hash::{Hash, Hasher};\n-use std::mem;\n-use std::num::NonZeroU32;\n-use std::ptr;\n-#[cfg(debug_assertions)]\n-use std::sync::atomic::{AtomicUsize, Ordering};\n-\n-pub(crate) struct QueryStateShard<'tcx, K, C> {\n-    cache: C,\n-    active: FxHashMap<K, QueryResult<'tcx>>,\n-\n-    /// Used to generate unique ids for active jobs.\n-    jobs: u32,\n-}\n \n-impl<'tcx, K, C> QueryStateShard<'tcx, K, C> {\n-    fn get_cache(&mut self) -> &mut C {\n-        &mut self.cache\n-    }\n-}\n+impl QueryContext for TyCtxt<'tcx> {\n+    type Query = Query<'tcx>;\n \n-impl<'tcx, K, C: Default> Default for QueryStateShard<'tcx, K, C> {\n-    fn default() -> QueryStateShard<'tcx, K, C> {\n-        QueryStateShard { cache: Default::default(), active: Default::default(), jobs: 0 }\n+    fn incremental_verify_ich(&self) -> bool {\n+        self.sess.opts.debugging_opts.incremental_verify_ich\n     }\n-}\n-\n-pub(crate) struct QueryState<'tcx, C: QueryCache> {\n-    cache: C,\n-    shards: Sharded<QueryStateShard<'tcx, C::Key, C::Sharded>>,\n-    #[cfg(debug_assertions)]\n-    pub(super) cache_hits: AtomicUsize,\n-}\n-\n-impl<'tcx, C: QueryCache> QueryState<'tcx, C> {\n-    pub(super) fn get_lookup<K2: Hash>(\n-        &'tcx self,\n-        key: &K2,\n-    ) -> QueryLookup<'tcx, C::Key, C::Sharded> {\n-        // We compute the key's hash once and then use it for both the\n-        // shard lookup and the hashmap lookup. This relies on the fact\n-        // that both of them use `FxHasher`.\n-        let mut hasher = FxHasher::default();\n-        key.hash(&mut hasher);\n-        let key_hash = hasher.finish();\n-\n-        let shard = self.shards.get_shard_index_by_hash(key_hash);\n-        let lock = self.shards.get_shard_by_index(shard).lock();\n-        QueryLookup { key_hash, shard, lock }\n+    fn verbose(&self) -> bool {\n+        self.sess.verbose()\n     }\n-}\n-\n-/// Indicates the state of a query for a given key in a query map.\n-enum QueryResult<'tcx> {\n-    /// An already executing query. The query job can be used to await for its completion.\n-    Started(QueryJob<'tcx>),\n-\n-    /// The query panicked. Queries trying to wait on this will raise a fatal error which will\n-    /// silently panic.\n-    Poisoned,\n-}\n \n-impl<'tcx, C: QueryCache> QueryState<'tcx, C> {\n-    pub(super) fn iter_results<R>(\n-        &self,\n-        f: impl for<'a> FnOnce(\n-            Box<dyn Iterator<Item = (&'a C::Key, &'a C::Value, DepNodeIndex)> + 'a>,\n-        ) -> R,\n-    ) -> R {\n-        self.cache.iter(&self.shards, |shard| &mut shard.cache, f)\n+    fn def_path_str(&self, def_id: DefId) -> String {\n+        TyCtxt::def_path_str(*self, def_id)\n     }\n-    pub(super) fn all_inactive(&self) -> bool {\n-        let shards = self.shards.lock_shards();\n-        shards.iter().all(|shard| shard.active.is_empty())\n-    }\n-\n-    pub(super) fn try_collect_active_jobs(\n-        &self,\n-        kind: DepKind,\n-        make_query: fn(C::Key) -> Query<'tcx>,\n-        jobs: &mut FxHashMap<QueryJobId, QueryJobInfo<'tcx>>,\n-    ) -> Option<()>\n-    where\n-        C::Key: Clone,\n-    {\n-        // We use try_lock_shards here since we are called from the\n-        // deadlock handler, and this shouldn't be locked.\n-        let shards = self.shards.try_lock_shards()?;\n-        let shards = shards.iter().enumerate();\n-        jobs.extend(shards.flat_map(|(shard_id, shard)| {\n-            shard.active.iter().filter_map(move |(k, v)| {\n-                if let QueryResult::Started(ref job) = *v {\n-                    let id =\n-                        QueryJobId { job: job.id, shard: u16::try_from(shard_id).unwrap(), kind };\n-                    let info = QueryInfo { span: job.span, query: make_query(k.clone()) };\n-                    Some((id, QueryJobInfo { info, job: job.clone() }))\n-                } else {\n-                    None\n-                }\n-            })\n-        }));\n \n-        Some(())\n+    fn dep_graph(&self) -> &DepGraph {\n+        &self.dep_graph\n     }\n-}\n \n-impl<'tcx, C: QueryCache> Default for QueryState<'tcx, C> {\n-    fn default() -> QueryState<'tcx, C> {\n-        QueryState {\n-            cache: C::default(),\n-            shards: Default::default(),\n-            #[cfg(debug_assertions)]\n-            cache_hits: AtomicUsize::new(0),\n-        }\n+    fn current_query_job(&self) -> Option<QueryJobId<Self::DepKind>> {\n+        tls::with_related_context(*self, |icx| icx.query)\n     }\n-}\n-\n-/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n-pub(crate) struct QueryLookup<'tcx, K, C> {\n-    pub(super) key_hash: u64,\n-    shard: usize,\n-    pub(super) lock: LockGuard<'tcx, QueryStateShard<'tcx, K, C>>,\n-}\n-\n-/// A type representing the responsibility to execute the job in the `job` field.\n-/// This will poison the relevant query if dropped.\n-struct JobOwner<'tcx, C>\n-where\n-    C: QueryCache,\n-    C::Key: Eq + Hash + Clone + Debug,\n-    C::Value: Clone,\n-{\n-    state: &'tcx QueryState<'tcx, C>,\n-    key: C::Key,\n-    id: QueryJobId,\n-}\n-\n-impl<'tcx, C: QueryCache> JobOwner<'tcx, C>\n-where\n-    C: QueryCache,\n-    C::Key: Eq + Hash + Clone + Debug,\n-    C::Value: Clone,\n-{\n-    /// Either gets a `JobOwner` corresponding the query, allowing us to\n-    /// start executing the query, or returns with the result of the query.\n-    /// This function assumes that `try_get_cached` is already called and returned `lookup`.\n-    /// If the query is executing elsewhere, this will wait for it and return the result.\n-    /// If the query panicked, this will silently panic.\n-    ///\n-    /// This function is inlined because that results in a noticeable speed-up\n-    /// for some compile-time benchmarks.\n-    #[inline(always)]\n-    fn try_start<Q>(\n-        tcx: TyCtxt<'tcx>,\n-        span: Span,\n-        key: &C::Key,\n-        mut lookup: QueryLookup<'tcx, C::Key, C::Sharded>,\n-    ) -> TryGetJob<'tcx, C>\n-    where\n-        Q: QueryDescription<'tcx, Key = C::Key, Value = C::Value, Cache = C>,\n-    {\n-        let lock = &mut *lookup.lock;\n-\n-        let (latch, mut _query_blocked_prof_timer) = match lock.active.entry((*key).clone()) {\n-            Entry::Occupied(mut entry) => {\n-                match entry.get_mut() {\n-                    QueryResult::Started(job) => {\n-                        // For parallel queries, we'll block and wait until the query running\n-                        // in another thread has completed. Record how long we wait in the\n-                        // self-profiler.\n-                        let _query_blocked_prof_timer = if cfg!(parallel_compiler) {\n-                            Some(tcx.prof.query_blocked())\n-                        } else {\n-                            None\n-                        };\n-\n-                        // Create the id of the job we're waiting for\n-                        let id = QueryJobId::new(job.id, lookup.shard, Q::DEP_KIND);\n \n-                        (job.latch(id), _query_blocked_prof_timer)\n-                    }\n-                    QueryResult::Poisoned => FatalError.raise(),\n-                }\n-            }\n-            Entry::Vacant(entry) => {\n-                // No job entry for this query. Return a new one to be started later.\n-\n-                // Generate an id unique within this shard.\n-                let id = lock.jobs.checked_add(1).unwrap();\n-                lock.jobs = id;\n-                let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n-\n-                let global_id = QueryJobId::new(id, lookup.shard, Q::DEP_KIND);\n-\n-                let job = tls::with_related_context(tcx, |icx| QueryJob::new(id, span, icx.query));\n-\n-                entry.insert(QueryResult::Started(job));\n-\n-                let owner =\n-                    JobOwner { state: Q::query_state(tcx), id: global_id, key: (*key).clone() };\n-                return TryGetJob::NotYetStarted(owner);\n-            }\n-        };\n-        mem::drop(lookup.lock);\n-\n-        // If we are single-threaded we know that we have cycle error,\n-        // so we just return the error.\n-        #[cfg(not(parallel_compiler))]\n-        return TryGetJob::Cycle(cold_path(|| {\n-            Q::handle_cycle_error(tcx, latch.find_cycle_in_stack(tcx, span))\n-        }));\n-\n-        // With parallel queries we might just have to wait on some other\n-        // thread.\n-        #[cfg(parallel_compiler)]\n-        {\n-            let result = latch.wait_on(tcx, span);\n-\n-            if let Err(cycle) = result {\n-                return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n-            }\n-\n-            let cached = tcx.try_get_cached(\n-                Q::query_state(tcx),\n-                (*key).clone(),\n-                |value, index| (value.clone(), index),\n-                |_, _| panic!(\"value must be in cache after waiting\"),\n-            );\n-\n-            if let Some(prof_timer) = _query_blocked_prof_timer.take() {\n-                prof_timer.finish_with_query_invocation_id(cached.1.into());\n-            }\n-\n-            return TryGetJob::JobCompleted(cached);\n-        }\n-    }\n-\n-    /// Completes the query by updating the query cache with the `result`,\n-    /// signals the waiter and forgets the JobOwner, so it won't poison the query\n-    #[inline(always)]\n-    fn complete(self, tcx: TyCtxt<'tcx>, result: &C::Value, dep_node_index: DepNodeIndex) {\n-        // We can move out of `self` here because we `mem::forget` it below\n-        let key = unsafe { ptr::read(&self.key) };\n-        let state = self.state;\n-\n-        // Forget ourself so our destructor won't poison the query\n-        mem::forget(self);\n-\n-        let job = {\n-            let result = result.clone();\n-            let mut lock = state.shards.get_shard_by_value(&key).lock();\n-            let job = match lock.active.remove(&key).unwrap() {\n-                QueryResult::Started(job) => job,\n-                QueryResult::Poisoned => panic!(),\n-            };\n-            state.cache.complete(tcx, &mut lock.cache, key, result, dep_node_index);\n-            job\n-        };\n-\n-        job.signal_complete();\n-    }\n-}\n-\n-#[inline(always)]\n-fn with_diagnostics<F, R>(f: F) -> (R, ThinVec<Diagnostic>)\n-where\n-    F: FnOnce(Option<&Lock<ThinVec<Diagnostic>>>) -> R,\n-{\n-    let diagnostics = Lock::new(ThinVec::new());\n-    let result = f(Some(&diagnostics));\n-    (result, diagnostics.into_inner())\n-}\n-\n-impl<'tcx, C: QueryCache> Drop for JobOwner<'tcx, C>\n-where\n-    C::Key: Eq + Hash + Clone + Debug,\n-    C::Value: Clone,\n-{\n-    #[inline(never)]\n-    #[cold]\n-    fn drop(&mut self) {\n-        // Poison the query so jobs waiting on it panic.\n-        let state = self.state;\n-        let shard = state.shards.get_shard_by_value(&self.key);\n-        let job = {\n-            let mut shard = shard.lock();\n-            let job = match shard.active.remove(&self.key).unwrap() {\n-                QueryResult::Started(job) => job,\n-                QueryResult::Poisoned => panic!(),\n-            };\n-            shard.active.insert(self.key.clone(), QueryResult::Poisoned);\n-            job\n-        };\n-        // Also signal the completion of the job, so waiters\n-        // will continue execution.\n-        job.signal_complete();\n+    fn try_collect_active_jobs(\n+        &self,\n+    ) -> Option<FxHashMap<QueryJobId<Self::DepKind>, QueryJobInfo<Self>>> {\n+        self.queries.try_collect_active_jobs()\n     }\n-}\n \n-#[derive(Clone)]\n-pub(crate) struct CycleError<'tcx> {\n-    /// The query and related span that uses the cycle.\n-    pub(super) usage: Option<(Span, Query<'tcx>)>,\n-    pub(super) cycle: Vec<QueryInfo<'tcx>>,\n-}\n-\n-/// The result of `try_start`.\n-enum TryGetJob<'tcx, C: QueryCache>\n-where\n-    C::Key: Eq + Hash + Clone + Debug,\n-    C::Value: Clone,\n-{\n-    /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'tcx, C>),\n-\n-    /// The query was already completed.\n-    /// Returns the result of the query and its dep-node index\n-    /// if it succeeded or a cycle error if it failed.\n-    #[cfg(parallel_compiler)]\n-    JobCompleted((C::Value, DepNodeIndex)),\n-\n-    /// Trying to execute the query resulted in a cycle.\n-    Cycle(C::Value),\n-}\n-\n-impl<'tcx> TyCtxt<'tcx> {\n     /// Executes a job by changing the `ImplicitCtxt` to point to the\n     /// new query job while it executes. It returns the diagnostics\n     /// captured during execution and the actual result.\n     #[inline(always)]\n-    fn start_query<F, R>(\n-        self,\n-        token: QueryJobId,\n+    fn start_query<R>(\n+        &self,\n+        token: QueryJobId<Self::DepKind>,\n         diagnostics: Option<&Lock<ThinVec<Diagnostic>>>,\n-        compute: F,\n-    ) -> R\n-    where\n-        F: FnOnce(TyCtxt<'tcx>) -> R,\n-    {\n+        compute: impl FnOnce(Self) -> R,\n+    ) -> R {\n         // The `TyCtxt` stored in TLS has the same global interner lifetime\n         // as `self`, so we use `with_related_context` to relate the 'tcx lifetimes\n         // when accessing the `ImplicitCtxt`.\n-        tls::with_related_context(self, move |current_icx| {\n+        tls::with_related_context(*self, move |current_icx| {\n             // Update the `ImplicitCtxt` to point to our new query job.\n-            let new_icx = tls::ImplicitCtxt {\n-                tcx: self,\n+            let new_icx = ImplicitCtxt {\n+                tcx: *self,\n                 query: Some(token),\n                 diagnostics,\n                 layout_depth: current_icx.layout_depth,\n                 task_deps: current_icx.task_deps,\n             };\n \n             // Use the `ImplicitCtxt` while we execute the query.\n-            tls::enter_context(&new_icx, |_| compute(self))\n+            tls::enter_context(&new_icx, |_| compute(*self))\n         })\n     }\n+}\n \n+impl<'tcx> TyCtxt<'tcx> {\n     #[inline(never)]\n     #[cold]\n     pub(super) fn report_cycle(\n         self,\n-        CycleError { usage, cycle: stack }: CycleError<'tcx>,\n+        CycleError { usage, cycle: stack }: CycleError<Query<'tcx>>,\n     ) -> DiagnosticBuilder<'tcx> {\n         assert!(!stack.is_empty());\n \n@@ -433,7 +128,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         // Be careful reyling on global state here: this code is called from\n         // a panic hook, which means that the global `Handler` may be in a weird\n         // state if it was responsible for triggering the panic.\n-        tls::with_context_opt(|icx| {\n+        ty::tls::with_context_opt(|icx| {\n             if let Some(icx) = icx {\n                 let query_map = icx.tcx.queries.try_collect_active_jobs();\n \n@@ -468,337 +163,6 @@ impl<'tcx> TyCtxt<'tcx> {\n \n         eprintln!(\"end of query stack\");\n     }\n-\n-    /// Checks if the query is already computed and in the cache.\n-    /// It returns the shard index and a lock guard to the shard,\n-    /// which will be used if the query is not in the cache and we need\n-    /// to compute it.\n-    #[inline(always)]\n-    fn try_get_cached<C, R, OnHit, OnMiss>(\n-        self,\n-        state: &'tcx QueryState<'tcx, C>,\n-        key: C::Key,\n-        // `on_hit` can be called while holding a lock to the query cache\n-        on_hit: OnHit,\n-        on_miss: OnMiss,\n-    ) -> R\n-    where\n-        C: QueryCache,\n-        OnHit: FnOnce(&C::Value, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(C::Key, QueryLookup<'tcx, C::Key, C::Sharded>) -> R,\n-    {\n-        state.cache.lookup(\n-            state,\n-            QueryStateShard::<C::Key, C::Sharded>::get_cache,\n-            key,\n-            |value, index| {\n-                if unlikely!(self.prof.enabled()) {\n-                    self.prof.query_cache_hit(index.into());\n-                }\n-                #[cfg(debug_assertions)]\n-                {\n-                    state.cache_hits.fetch_add(1, Ordering::Relaxed);\n-                }\n-                on_hit(value, index)\n-            },\n-            on_miss,\n-        )\n-    }\n-\n-    #[inline(never)]\n-    pub(super) fn get_query<Q: QueryDescription<'tcx> + 'tcx>(\n-        self,\n-        span: Span,\n-        key: Q::Key,\n-    ) -> Q::Value {\n-        debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n-\n-        self.try_get_cached(\n-            Q::query_state(self),\n-            key,\n-            |value, index| {\n-                self.dep_graph.read_index(index);\n-                value.clone()\n-            },\n-            |key, lookup| self.try_execute_query::<Q>(span, key, lookup),\n-        )\n-    }\n-\n-    #[inline(always)]\n-    fn try_execute_query<Q: QueryDescription<'tcx> + 'tcx>(\n-        self,\n-        span: Span,\n-        key: Q::Key,\n-        lookup: QueryLookup<'tcx, Q::Key, <Q::Cache as QueryCache>::Sharded>,\n-    ) -> Q::Value {\n-        let job = match JobOwner::try_start::<Q>(self, span, &key, lookup) {\n-            TryGetJob::NotYetStarted(job) => job,\n-            TryGetJob::Cycle(result) => return result,\n-            #[cfg(parallel_compiler)]\n-            TryGetJob::JobCompleted((v, index)) => {\n-                self.dep_graph.read_index(index);\n-                return v;\n-            }\n-        };\n-\n-        // Fast path for when incr. comp. is off. `to_dep_node` is\n-        // expensive for some `DepKind`s.\n-        if !self.dep_graph.is_fully_enabled() {\n-            let null_dep_node = DepNode::new_no_params(crate::dep_graph::DepKind::Null);\n-            return self.force_query_with_job::<Q>(key, job, null_dep_node).0;\n-        }\n-\n-        if Q::ANON {\n-            let prof_timer = self.prof.query_provider();\n-\n-            let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-                self.start_query(job.id, diagnostics, |tcx| {\n-                    tcx.dep_graph.with_anon_task(Q::DEP_KIND, || Q::compute(tcx, key))\n-                })\n-            });\n-\n-            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-            self.dep_graph.read_index(dep_node_index);\n-\n-            if unlikely!(!diagnostics.is_empty()) {\n-                self.queries\n-                    .on_disk_cache\n-                    .store_diagnostics_for_anon_node(dep_node_index, diagnostics);\n-            }\n-\n-            job.complete(self, &result, dep_node_index);\n-\n-            return result;\n-        }\n-\n-        let dep_node = Q::to_dep_node(self, &key);\n-\n-        if !Q::EVAL_ALWAYS {\n-            // The diagnostics for this query will be\n-            // promoted to the current session during\n-            // `try_mark_green()`, so we can ignore them here.\n-            let loaded = self.start_query(job.id, None, |tcx| {\n-                let marked = tcx.dep_graph.try_mark_green_and_read(tcx, &dep_node);\n-                marked.map(|(prev_dep_node_index, dep_node_index)| {\n-                    (\n-                        tcx.load_from_disk_and_cache_in_memory::<Q>(\n-                            key.clone(),\n-                            prev_dep_node_index,\n-                            dep_node_index,\n-                            &dep_node,\n-                        ),\n-                        dep_node_index,\n-                    )\n-                })\n-            });\n-            if let Some((result, dep_node_index)) = loaded {\n-                job.complete(self, &result, dep_node_index);\n-                return result;\n-            }\n-        }\n-\n-        let (result, dep_node_index) = self.force_query_with_job::<Q>(key, job, dep_node);\n-        self.dep_graph.read_index(dep_node_index);\n-        result\n-    }\n-\n-    fn load_from_disk_and_cache_in_memory<Q: QueryDescription<'tcx>>(\n-        self,\n-        key: Q::Key,\n-        prev_dep_node_index: SerializedDepNodeIndex,\n-        dep_node_index: DepNodeIndex,\n-        dep_node: &DepNode,\n-    ) -> Q::Value {\n-        // Note this function can be called concurrently from the same query\n-        // We must ensure that this is handled correctly.\n-\n-        debug_assert!(self.dep_graph.is_green(dep_node));\n-\n-        // First we try to load the result from the on-disk cache.\n-        let result = if Q::cache_on_disk(self, key.clone(), None) {\n-            let prof_timer = self.prof.incr_cache_loading();\n-            let result = Q::try_load_from_disk(self, prev_dep_node_index);\n-            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-            // We always expect to find a cached result for things that\n-            // can be forced from `DepNode`.\n-            debug_assert!(\n-                !dep_node.kind.can_reconstruct_query_key() || result.is_some(),\n-                \"missing on-disk cache entry for {:?}\",\n-                dep_node\n-            );\n-            result\n-        } else {\n-            // Some things are never cached on disk.\n-            None\n-        };\n-\n-        let result = if let Some(result) = result {\n-            result\n-        } else {\n-            // We could not load a result from the on-disk cache, so\n-            // recompute.\n-            let prof_timer = self.prof.query_provider();\n-\n-            // The dep-graph for this computation is already in-place.\n-            let result = self.dep_graph.with_ignore(|| Q::compute(self, key));\n-\n-            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-            result\n-        };\n-\n-        // If `-Zincremental-verify-ich` is specified, re-hash results from\n-        // the cache and make sure that they have the expected fingerprint.\n-        if unlikely!(self.sess.opts.debugging_opts.incremental_verify_ich) {\n-            self.incremental_verify_ich::<Q>(&result, dep_node, dep_node_index);\n-        }\n-\n-        result\n-    }\n-\n-    #[inline(never)]\n-    #[cold]\n-    fn incremental_verify_ich<Q: QueryDescription<'tcx>>(\n-        self,\n-        result: &Q::Value,\n-        dep_node: &DepNode,\n-        dep_node_index: DepNodeIndex,\n-    ) {\n-        use rustc_data_structures::fingerprint::Fingerprint;\n-\n-        assert!(\n-            Some(self.dep_graph.fingerprint_of(dep_node_index))\n-                == self.dep_graph.prev_fingerprint_of(dep_node),\n-            \"fingerprint for green query instance not loaded from cache: {:?}\",\n-            dep_node,\n-        );\n-\n-        debug!(\"BEGIN verify_ich({:?})\", dep_node);\n-        let mut hcx = self.create_stable_hashing_context();\n-\n-        let new_hash = Q::hash_result(&mut hcx, result).unwrap_or(Fingerprint::ZERO);\n-        debug!(\"END verify_ich({:?})\", dep_node);\n-\n-        let old_hash = self.dep_graph.fingerprint_of(dep_node_index);\n-\n-        assert!(new_hash == old_hash, \"found unstable fingerprints for {:?}\", dep_node,);\n-    }\n-\n-    #[inline(always)]\n-    fn force_query_with_job<Q: QueryDescription<'tcx> + 'tcx>(\n-        self,\n-        key: Q::Key,\n-        job: JobOwner<'tcx, Q::Cache>,\n-        dep_node: DepNode,\n-    ) -> (Q::Value, DepNodeIndex) {\n-        // If the following assertion triggers, it can have two reasons:\n-        // 1. Something is wrong with DepNode creation, either here or\n-        //    in `DepGraph::try_mark_green()`.\n-        // 2. Two distinct query keys get mapped to the same `DepNode`\n-        //    (see for example #48923).\n-        assert!(\n-            !self.dep_graph.dep_node_exists(&dep_node),\n-            \"forcing query with already existing `DepNode`\\n\\\n-                 - query-key: {:?}\\n\\\n-                 - dep-node: {:?}\",\n-            key,\n-            dep_node\n-        );\n-\n-        let prof_timer = self.prof.query_provider();\n-\n-        let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-            self.start_query(job.id, diagnostics, |tcx| {\n-                if Q::EVAL_ALWAYS {\n-                    tcx.dep_graph.with_eval_always_task(\n-                        dep_node,\n-                        tcx,\n-                        key,\n-                        Q::compute,\n-                        Q::hash_result,\n-                    )\n-                } else {\n-                    tcx.dep_graph.with_task(dep_node, tcx, key, Q::compute, Q::hash_result)\n-                }\n-            })\n-        });\n-\n-        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-        if unlikely!(!diagnostics.is_empty()) {\n-            if dep_node.kind != crate::dep_graph::DepKind::Null {\n-                self.queries.on_disk_cache.store_diagnostics(dep_node_index, diagnostics);\n-            }\n-        }\n-\n-        job.complete(self, &result, dep_node_index);\n-\n-        (result, dep_node_index)\n-    }\n-\n-    /// Ensure that either this query has all green inputs or been executed.\n-    /// Executing `query::ensure(D)` is considered a read of the dep-node `D`.\n-    ///\n-    /// This function is particularly useful when executing passes for their\n-    /// side-effects -- e.g., in order to report errors for erroneous programs.\n-    ///\n-    /// Note: The optimization is only available during incr. comp.\n-    pub(super) fn ensure_query<Q: QueryDescription<'tcx> + 'tcx>(self, key: Q::Key) {\n-        if Q::EVAL_ALWAYS {\n-            let _ = self.get_query::<Q>(DUMMY_SP, key);\n-            return;\n-        }\n-\n-        // Ensuring an anonymous query makes no sense\n-        assert!(!Q::ANON);\n-\n-        let dep_node = Q::to_dep_node(self, &key);\n-\n-        match self.dep_graph.try_mark_green_and_read(self, &dep_node) {\n-            None => {\n-                // A None return from `try_mark_green_and_read` means that this is either\n-                // a new dep node or that the dep node has already been marked red.\n-                // Either way, we can't call `dep_graph.read()` as we don't have the\n-                // DepNodeIndex. We must invoke the query itself. The performance cost\n-                // this introduces should be negligible as we'll immediately hit the\n-                // in-memory cache, or another query down the line will.\n-                let _ = self.get_query::<Q>(DUMMY_SP, key);\n-            }\n-            Some((_, dep_node_index)) => {\n-                self.prof.query_cache_hit(dep_node_index.into());\n-            }\n-        }\n-    }\n-\n-    #[allow(dead_code)]\n-    pub(super) fn force_query<Q: QueryDescription<'tcx> + 'tcx>(\n-        self,\n-        key: Q::Key,\n-        span: Span,\n-        dep_node: DepNode,\n-    ) {\n-        // We may be concurrently trying both execute and force a query.\n-        // Ensure that only one of them runs the query.\n-\n-        self.try_get_cached(\n-            Q::query_state(self),\n-            key,\n-            |_, _| {\n-                // Cache hit, do nothing\n-            },\n-            |key, lookup| {\n-                let job = match JobOwner::try_start::<Q>(self, span, &key, lookup) {\n-                    TryGetJob::NotYetStarted(job) => job,\n-                    TryGetJob::Cycle(_) => return,\n-                    #[cfg(parallel_compiler)]\n-                    TryGetJob::JobCompleted(_) => return,\n-                };\n-                self.force_query_with_job::<Q>(key, job, dep_node);\n-            },\n-        );\n-    }\n }\n \n macro_rules! handle_cycle_error {\n@@ -909,7 +273,7 @@ macro_rules! define_queries_inner {\n                 }\n             }\n \n-            pub fn describe(&self, tcx: TyCtxt<'_>) -> Cow<'static, str> {\n+            pub fn describe(&self, tcx: TyCtxt<$tcx>) -> Cow<'static, str> {\n                 let (r, name) = match *self {\n                     $(Query::$name(key) => {\n                         (queries::$name::describe(tcx, key), stringify!($name))\n@@ -956,22 +320,22 @@ macro_rules! define_queries_inner {\n             })*\n         }\n \n-        $(impl<$tcx> QueryConfig<$tcx> for queries::$name<$tcx> {\n+        $(impl<$tcx> QueryConfig<TyCtxt<$tcx>> for queries::$name<$tcx> {\n             type Key = $K;\n             type Value = $V;\n             const NAME: &'static str = stringify!($name);\n             const CATEGORY: ProfileCategory = $category;\n         }\n \n-        impl<$tcx> QueryAccessors<$tcx> for queries::$name<$tcx> {\n+        impl<$tcx> QueryAccessors<TyCtxt<$tcx>> for queries::$name<$tcx> {\n             const ANON: bool = is_anon!([$($modifiers)*]);\n             const EVAL_ALWAYS: bool = is_eval_always!([$($modifiers)*]);\n             const DEP_KIND: dep_graph::DepKind = dep_graph::DepKind::$node;\n \n             type Cache = query_storage!([$($modifiers)*][$K, $V]);\n \n             #[inline(always)]\n-            fn query_state<'a>(tcx: TyCtxt<$tcx>) -> &'a QueryState<$tcx, Self::Cache> {\n+            fn query_state<'a>(tcx: TyCtxt<$tcx>) -> &'a QueryState<TyCtxt<$tcx>, Self::Cache> {\n                 &tcx.queries.$name\n             }\n \n@@ -1002,7 +366,7 @@ macro_rules! define_queries_inner {\n \n             fn handle_cycle_error(\n                 tcx: TyCtxt<'tcx>,\n-                error: CycleError<'tcx>\n+                error: CycleError<Query<'tcx>>\n             ) -> Self::Value {\n                 handle_cycle_error!([$($modifiers)*][tcx, error])\n             }\n@@ -1017,7 +381,7 @@ macro_rules! define_queries_inner {\n             $($(#[$attr])*\n             #[inline(always)]\n             pub fn $name(self, key: $K) {\n-                self.tcx.ensure_query::<queries::$name<'_>>(key)\n+                ensure_query::<queries::$name<'_>, _>(self.tcx, key)\n             })*\n         }\n \n@@ -1095,7 +459,7 @@ macro_rules! define_queries_inner {\n             $($(#[$attr])*\n             #[inline(always)]\n             pub fn $name(self, key: $K) -> $V {\n-                self.tcx.get_query::<queries::$name<'_>>(self.span, key)\n+                get_query::<queries::$name<'_>, _>(self.tcx, self.span, key)\n             })*\n         }\n \n@@ -1124,8 +488,8 @@ macro_rules! define_queries_struct {\n             fallback_extern_providers: Box<Providers<$tcx>>,\n \n             $($(#[$attr])*  $name: QueryState<\n-                $tcx,\n-                <queries::$name<$tcx> as QueryAccessors<'tcx>>::Cache,\n+                TyCtxt<$tcx>,\n+                <queries::$name<$tcx> as QueryAccessors<TyCtxt<'tcx>>>::Cache,\n             >,)*\n         }\n \n@@ -1145,12 +509,12 @@ macro_rules! define_queries_struct {\n \n             pub(crate) fn try_collect_active_jobs(\n                 &self\n-            ) -> Option<FxHashMap<QueryJobId, QueryJobInfo<'tcx>>> {\n+            ) -> Option<FxHashMap<QueryJobId<crate::dep_graph::DepKind>, QueryJobInfo<TyCtxt<'tcx>>>> {\n                 let mut jobs = FxHashMap::default();\n \n                 $(\n                     self.$name.try_collect_active_jobs(\n-                        <queries::$name<'tcx> as QueryAccessors<'tcx>>::DEP_KIND,\n+                        <queries::$name<'tcx> as QueryAccessors<TyCtxt<'tcx>>>::DEP_KIND,\n                         Query::$name,\n                         &mut jobs,\n                     )?;"}, {"sha": "e0d3e764dad8396c99ee39760b2624af43b1ce07", "filename": "src/librustc/ty/query/profiling_support.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -1,11 +1,11 @@\n use crate::ty::context::TyCtxt;\n-use crate::ty::query::caches::QueryCache;\n-use crate::ty::query::plumbing::QueryState;\n use measureme::{StringComponent, StringId};\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::profiling::SelfProfiler;\n use rustc_hir::def_id::{CrateNum, DefId, DefIndex, CRATE_DEF_INDEX, LOCAL_CRATE};\n use rustc_hir::definitions::DefPathData;\n+use rustc_query_system::query::QueryCache;\n+use rustc_query_system::query::QueryState;\n use std::fmt::Debug;\n use std::io::Write;\n \n@@ -160,7 +160,7 @@ where\n pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n     tcx: TyCtxt<'tcx>,\n     query_name: &'static str,\n-    query_state: &QueryState<'tcx, C>,\n+    query_state: &QueryState<TyCtxt<'tcx>, C>,\n     string_cache: &mut QueryKeyStringCache,\n ) where\n     C: QueryCache,"}, {"sha": "b496bf839ab9e70bcab14cba64c86b2d89e76da2", "filename": "src/librustc/ty/query/stats.rs", "status": "modified", "additions": 9, "deletions": 5, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fstats.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc%2Fty%2Fquery%2Fstats.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fstats.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -1,9 +1,9 @@\n-use crate::ty::query::caches::QueryCache;\n-use crate::ty::query::config::QueryAccessors;\n-use crate::ty::query::plumbing::QueryState;\n use crate::ty::query::queries;\n use crate::ty::TyCtxt;\n use rustc_hir::def_id::{DefId, LOCAL_CRATE};\n+use rustc_query_system::query::QueryCache;\n+use rustc_query_system::query::QueryState;\n+use rustc_query_system::query::{QueryAccessors, QueryContext};\n \n use std::any::type_name;\n use std::mem;\n@@ -38,7 +38,10 @@ struct QueryStats {\n     local_def_id_keys: Option<usize>,\n }\n \n-fn stats<'tcx, C: QueryCache>(name: &'static str, map: &QueryState<'tcx, C>) -> QueryStats {\n+fn stats<CTX: QueryContext, C: QueryCache>(\n+    name: &'static str,\n+    map: &QueryState<CTX, C>,\n+) -> QueryStats {\n     let mut stats = QueryStats {\n         name,\n         #[cfg(debug_assertions)]\n@@ -124,7 +127,8 @@ macro_rules! print_stats {\n \n             $($(\n                 queries.push(stats::<\n-                    <queries::$name<'_> as QueryAccessors<'_>>::Cache,\n+                    TyCtxt<'_>,\n+                    <queries::$name<'_> as QueryAccessors<TyCtxt<'_>>>::Cache,\n                 >(\n                     stringify!($name),\n                     &tcx.queries.$name,"}, {"sha": "7e87f45ba4bb1b48ab548b0aac4563b51f3f72fc", "filename": "src/librustc_codegen_llvm/context.rs", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_codegen_llvm%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_codegen_llvm%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fcontext.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -7,7 +7,6 @@ use crate::type_::Type;\n use crate::value::Value;\n \n use rustc::bug;\n-use rustc::dep_graph::DepGraphSafe;\n use rustc::mir::mono::CodegenUnit;\n use rustc::ty::layout::{\n     HasParamEnv, LayoutError, LayoutOf, PointeeInfo, Size, TyLayout, VariantIdx,\n@@ -90,8 +89,6 @@ pub struct CodegenCx<'ll, 'tcx> {\n     local_gen_sym_counter: Cell<usize>,\n }\n \n-impl<'ll, 'tcx> DepGraphSafe for CodegenCx<'ll, 'tcx> {}\n-\n pub fn get_reloc_model(sess: &Session) -> llvm::RelocMode {\n     let reloc_model_arg = match sess.opts.cg.relocation_model {\n         Some(ref s) => &s[..],"}, {"sha": "26c3bce4a9a02afec3d88a235c3e55991e795593", "filename": "src/librustc_macros/src/query.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_macros%2Fsrc%2Fquery.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_macros%2Fsrc%2Fquery.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_macros%2Fsrc%2Fquery.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -380,7 +380,7 @@ fn add_query_description_impl(\n         quote! {\n             #[allow(unused_variables)]\n             fn describe(\n-                #tcx: TyCtxt<'_>,\n+                #tcx: TyCtxt<'tcx>,\n                 #key: #arg,\n             ) -> Cow<'static, str> {\n                 format!(#desc).into()\n@@ -393,7 +393,7 @@ fn add_query_description_impl(\n         let desc = desc.unwrap_or(quote! {});\n \n         impls.extend(quote! {\n-            impl<'tcx> QueryDescription<'tcx> for queries::#name<'tcx> {\n+            impl<'tcx> QueryDescription<TyCtxt<'tcx>> for queries::#name<'tcx> {\n                 #desc\n                 #cache\n             }\n@@ -489,7 +489,8 @@ pub fn rustc_queries(input: TokenStream) -> TokenStream {\n                 ::rustc::dep_graph::DepKind::#name => {\n                     if <#arg as DepNodeParams<TyCtxt<'_>>>::CAN_RECONSTRUCT_QUERY_KEY {\n                         if let Some(key) = <#arg as DepNodeParams<TyCtxt<'_>>>::recover($tcx, $dep_node) {\n-                            $tcx.force_query::<crate::ty::query::queries::#name<'_>>(\n+                            force_query::<crate::ty::query::queries::#name<'_>, _>(\n+                                $tcx,\n                                 key,\n                                 DUMMY_SP,\n                                 *$dep_node"}, {"sha": "7a1ac9e0a60ec9fddac3e92d52636ab9e838382d", "filename": "src/librustc_metadata/rmeta/decoder/cstore_impl.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -37,7 +37,7 @@ macro_rules! provide {\n             $(fn $name<$lt: $lt, T: IntoArgs>(\n                 $tcx: TyCtxt<$lt>,\n                 def_id_arg: T,\n-            ) -> <ty::queries::$name<$lt> as QueryConfig<$lt>>::Value {\n+            ) -> <ty::queries::$name<$lt> as QueryConfig<TyCtxt<$lt>>>::Value {\n                 let _prof_timer =\n                     $tcx.prof.generic_activity(\"metadata_decode_entry\");\n "}, {"sha": "e1657a8f3c607e68e7d9574dd8a3fa814c46973f", "filename": "src/librustc_query_system/Cargo.toml", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2FCargo.toml?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -11,12 +11,12 @@ doctest = false\n \n [dependencies]\n log = { version = \"0.4\", features = [\"release_max_level_info\", \"std\"] }\n-rustc_ast = { path = \"../librustc_ast\" }\n+rustc-rayon-core = \"0.3.0\"\n rustc_data_structures = { path = \"../librustc_data_structures\" }\n rustc_errors = { path = \"../librustc_errors\" }\n-rustc_hir = { path = \"../librustc_hir\" }\n rustc_index = { path = \"../librustc_index\" }\n rustc_macros = { path = \"../librustc_macros\" }\n rustc_serialize = { path = \"../libserialize\", package = \"serialize\" }\n+rustc_span = { path = \"../librustc_span\" }\n parking_lot = \"0.9\"\n smallvec = { version = \"1.0\", features = [\"union\", \"may_dangle\"] }"}, {"sha": "b1d332da1159295307f8df38392668fb537553b7", "filename": "src/librustc_query_system/dep_graph/dep_node.rs", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fdep_graph%2Fdep_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fdep_graph%2Fdep_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fdep_graph%2Fdep_node.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -46,7 +46,6 @@ use super::{DepContext, DepKind};\n \n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n-use rustc_macros::HashStable_Generic;\n \n use std::fmt;\n use std::hash::Hash;\n@@ -127,7 +126,6 @@ where\n /// the need to be mapped or unmapped. (This ensures we can serialize\n /// them even in the absence of a tcx.)\n #[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n-#[derive(HashStable_Generic)]\n pub struct WorkProductId {\n     hash: Fingerprint,\n }\n@@ -144,3 +142,10 @@ impl WorkProductId {\n         WorkProductId { hash: fingerprint }\n     }\n }\n+\n+impl<HCX> HashStable<HCX> for WorkProductId {\n+    #[inline]\n+    fn hash_stable(&self, hcx: &mut HCX, hasher: &mut StableHasher) {\n+        self.hash.hash_stable(hcx, hasher)\n+    }\n+}"}, {"sha": "73983e1644cb01bb30e03898e3e36a98dd1da9cb", "filename": "src/librustc_query_system/dep_graph/graph.rs", "status": "modified", "additions": 17, "deletions": 31, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fdep_graph%2Fgraph.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -20,10 +20,8 @@ use std::sync::atomic::Ordering::Relaxed;\n use super::debug::EdgeFilter;\n use super::prev::PreviousDepGraph;\n use super::query::DepGraphQuery;\n-use super::safe::DepGraphSafe;\n use super::serialized::{SerializedDepGraph, SerializedDepNodeIndex};\n use super::{DepContext, DepKind, DepNode, WorkProductId};\n-use crate::{HashStableContext, HashStableContextProvider};\n \n #[derive(Clone)]\n pub struct DepGraph<K: DepKind> {\n@@ -191,18 +189,14 @@ impl<K: DepKind> DepGraph<K> {\n     ///   `arg` parameter.\n     ///\n     /// [rustc dev guide]: https://rustc-dev-guide.rust-lang.org/incremental-compilation.html\n-    pub fn with_task<H, C, A, R>(\n+    pub fn with_task<Ctxt: DepContext<DepKind = K>, A, R>(\n         &self,\n         key: DepNode<K>,\n-        cx: C,\n+        cx: Ctxt,\n         arg: A,\n-        task: fn(C, A) -> R,\n-        hash_result: impl FnOnce(&mut H, &R) -> Option<Fingerprint>,\n-    ) -> (R, DepNodeIndex)\n-    where\n-        C: DepGraphSafe + HashStableContextProvider<H>,\n-        H: HashStableContext,\n-    {\n+        task: fn(Ctxt, A) -> R,\n+        hash_result: impl FnOnce(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n+    ) -> (R, DepNodeIndex) {\n         self.with_task_impl(\n             key,\n             cx,\n@@ -223,26 +217,22 @@ impl<K: DepKind> DepGraph<K> {\n         )\n     }\n \n-    fn with_task_impl<H, C, A, R>(\n+    fn with_task_impl<Ctxt: DepContext<DepKind = K>, A, R>(\n         &self,\n         key: DepNode<K>,\n-        cx: C,\n+        cx: Ctxt,\n         arg: A,\n         no_tcx: bool,\n-        task: fn(C, A) -> R,\n+        task: fn(Ctxt, A) -> R,\n         create_task: fn(DepNode<K>) -> Option<TaskDeps<K>>,\n         finish_task_and_alloc_depnode: fn(\n             &CurrentDepGraph<K>,\n             DepNode<K>,\n             Fingerprint,\n             Option<TaskDeps<K>>,\n         ) -> DepNodeIndex,\n-        hash_result: impl FnOnce(&mut H, &R) -> Option<Fingerprint>,\n-    ) -> (R, DepNodeIndex)\n-    where\n-        C: DepGraphSafe + HashStableContextProvider<H>,\n-        H: HashStableContext,\n-    {\n+        hash_result: impl FnOnce(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n+    ) -> (R, DepNodeIndex) {\n         if let Some(ref data) = self.data {\n             let task_deps = create_task(key).map(Lock::new);\n \n@@ -251,7 +241,7 @@ impl<K: DepKind> DepGraph<K> {\n             // anyway so that\n             //  - we make sure that the infrastructure works and\n             //  - we can get an idea of the runtime cost.\n-            let mut hcx = cx.get_stable_hashing_context();\n+            let mut hcx = cx.create_stable_hashing_context();\n \n             let result = if no_tcx {\n                 task(cx, arg)\n@@ -268,7 +258,7 @@ impl<K: DepKind> DepGraph<K> {\n                 task_deps.map(|lock| lock.into_inner()),\n             );\n \n-            let print_status = cfg!(debug_assertions) && hcx.debug_dep_tasks();\n+            let print_status = cfg!(debug_assertions) && cx.debug_dep_tasks();\n \n             // Determine the color of the new DepNode.\n             if let Some(prev_index) = data.previous.node_to_index_opt(&key) {\n@@ -335,18 +325,14 @@ impl<K: DepKind> DepGraph<K> {\n \n     /// Executes something within an \"eval-always\" task which is a task\n     /// that runs whenever anything changes.\n-    pub fn with_eval_always_task<H, C, A, R>(\n+    pub fn with_eval_always_task<Ctxt: DepContext<DepKind = K>, A, R>(\n         &self,\n         key: DepNode<K>,\n-        cx: C,\n+        cx: Ctxt,\n         arg: A,\n-        task: fn(C, A) -> R,\n-        hash_result: impl FnOnce(&mut H, &R) -> Option<Fingerprint>,\n-    ) -> (R, DepNodeIndex)\n-    where\n-        C: DepGraphSafe + HashStableContextProvider<H>,\n-        H: HashStableContext,\n-    {\n+        task: fn(Ctxt, A) -> R,\n+        hash_result: impl FnOnce(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n+    ) -> (R, DepNodeIndex) {\n         self.with_task_impl(\n             key,\n             cx,"}, {"sha": "fbc91575ede4198f46653fbecbc9a1d5221011a6", "filename": "src/librustc_query_system/dep_graph/mod.rs", "status": "modified", "additions": 14, "deletions": 4, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fdep_graph%2Fmod.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -3,16 +3,13 @@ mod dep_node;\n mod graph;\n mod prev;\n mod query;\n-mod safe;\n mod serialized;\n \n pub use dep_node::{DepNode, DepNodeParams, WorkProductId};\n pub use graph::WorkProductFileKind;\n pub use graph::{hash_result, DepGraph, DepNodeColor, DepNodeIndex, TaskDeps, WorkProduct};\n pub use prev::PreviousDepGraph;\n pub use query::DepGraphQuery;\n-pub use safe::AssertDepGraphSafe;\n-pub use safe::DepGraphSafe;\n pub use serialized::{SerializedDepGraph, SerializedDepNodeIndex};\n \n use rustc_data_structures::profiling::SelfProfilerRef;\n@@ -25,11 +22,13 @@ use std::hash::Hash;\n \n pub trait DepContext: Copy {\n     type DepKind: self::DepKind;\n-    type StableHashingContext: crate::HashStableContext;\n+    type StableHashingContext;\n \n     /// Create a hashing context for hashing new results.\n     fn create_stable_hashing_context(&self) -> Self::StableHashingContext;\n \n+    fn debug_dep_tasks(&self) -> bool;\n+\n     /// Try to force a dep node to execute and see if it's green.\n     fn try_force_from_dep_node(&self, dep_node: &DepNode<Self::DepKind>) -> bool;\n \n@@ -48,12 +47,21 @@ pub trait DepContext: Copy {\n     /// Register diagnostics for the given node, for use in next session.\n     fn store_diagnostics(&self, dep_node_index: DepNodeIndex, diagnostics: ThinVec<Diagnostic>);\n \n+    /// Register diagnostics for the given node, for use in next session.\n+    fn store_diagnostics_for_anon_node(\n+        &self,\n+        dep_node_index: DepNodeIndex,\n+        diagnostics: ThinVec<Diagnostic>,\n+    );\n+\n     /// Access the profiler.\n     fn profiler(&self) -> &SelfProfilerRef;\n }\n \n /// Describe the different families of dependency nodes.\n pub trait DepKind: Copy + fmt::Debug + Eq + Ord + Hash {\n+    const NULL: Self;\n+\n     /// Return whether this kind always require evaluation.\n     fn is_eval_always(&self) -> bool;\n \n@@ -72,4 +80,6 @@ pub trait DepKind: Copy + fmt::Debug + Eq + Ord + Hash {\n     fn read_deps<OP>(op: OP) -> ()\n     where\n         OP: for<'a> FnOnce(Option<&'a Lock<TaskDeps<Self>>>) -> ();\n+\n+    fn can_reconstruct_query_key(&self) -> bool;\n }"}, {"sha": "7bba348f8841f70c46019f9aa8ba64612f9c3190", "filename": "src/librustc_query_system/dep_graph/safe.rs", "status": "removed", "additions": 0, "deletions": 51, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/75208942f6144daac669e8e382029fc33bdce841/src%2Flibrustc_query_system%2Fdep_graph%2Fsafe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75208942f6144daac669e8e382029fc33bdce841/src%2Flibrustc_query_system%2Fdep_graph%2Fsafe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fdep_graph%2Fsafe.rs?ref=75208942f6144daac669e8e382029fc33bdce841", "patch": "@@ -1,51 +0,0 @@\n-//! The `DepGraphSafe` trait\n-\n-use rustc_ast::ast::NodeId;\n-use rustc_hir::def_id::DefId;\n-use rustc_hir::BodyId;\n-\n-/// The `DepGraphSafe` trait is used to specify what kinds of values\n-/// are safe to \"leak\" into a task. The idea is that this should be\n-/// only be implemented for things like the tcx as well as various id\n-/// types, which will create reads in the dep-graph whenever the trait\n-/// loads anything that might depend on the input program.\n-pub trait DepGraphSafe {}\n-\n-/// A `BodyId` on its own doesn't give access to any particular state.\n-/// You must fetch the state from the various maps or generate\n-/// on-demand queries, all of which create reads.\n-impl DepGraphSafe for BodyId {}\n-\n-/// A `NodeId` on its own doesn't give access to any particular state.\n-/// You must fetch the state from the various maps or generate\n-/// on-demand queries, all of which create reads.\n-impl DepGraphSafe for NodeId {}\n-\n-/// A `DefId` on its own doesn't give access to any particular state.\n-/// You must fetch the state from the various maps or generate\n-/// on-demand queries, all of which create reads.\n-impl DepGraphSafe for DefId {}\n-\n-/// Tuples make it easy to build up state.\n-impl<A, B> DepGraphSafe for (A, B)\n-where\n-    A: DepGraphSafe,\n-    B: DepGraphSafe,\n-{\n-}\n-\n-/// Shared ref to dep-graph-safe stuff should still be dep-graph-safe.\n-impl<'a, A> DepGraphSafe for &'a A where A: DepGraphSafe {}\n-\n-/// Mut ref to dep-graph-safe stuff should still be dep-graph-safe.\n-impl<'a, A> DepGraphSafe for &'a mut A where A: DepGraphSafe {}\n-\n-/// No data here! :)\n-impl DepGraphSafe for () {}\n-\n-/// A convenient override that lets you pass arbitrary state into a\n-/// task. Every use should be accompanied by a comment explaining why\n-/// it makes sense (or how it could be refactored away in the future).\n-pub struct AssertDepGraphSafe<T>(pub T);\n-\n-impl<T> DepGraphSafe for AssertDepGraphSafe<T> {}"}, {"sha": "0e6a07e06d0f202ad7148cf92dbf79cb814836ed", "filename": "src/librustc_query_system/lib.rs", "status": "modified", "additions": 6, "deletions": 21, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Flib.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -1,32 +1,17 @@\n+#![feature(bool_to_option)]\n #![feature(const_fn)]\n #![feature(const_if_match)]\n #![feature(const_panic)]\n #![feature(core_intrinsics)]\n+#![feature(hash_raw_entry)]\n #![feature(specialization)]\n #![feature(stmt_expr_attributes)]\n+#![feature(vec_remove_item)]\n \n #[macro_use]\n extern crate log;\n+#[macro_use]\n+extern crate rustc_data_structures;\n \n pub mod dep_graph;\n-\n-pub trait HashStableContext {\n-    fn debug_dep_tasks(&self) -> bool;\n-}\n-\n-/// Something that can provide a stable hashing context.\n-pub trait HashStableContextProvider<Ctxt> {\n-    fn get_stable_hashing_context(&self) -> Ctxt;\n-}\n-\n-impl<Ctxt, T: HashStableContextProvider<Ctxt>> HashStableContextProvider<Ctxt> for &T {\n-    fn get_stable_hashing_context(&self) -> Ctxt {\n-        (**self).get_stable_hashing_context()\n-    }\n-}\n-\n-impl<Ctxt, T: HashStableContextProvider<Ctxt>> HashStableContextProvider<Ctxt> for &mut T {\n-    fn get_stable_hashing_context(&self) -> Ctxt {\n-        (**self).get_stable_hashing_context()\n-    }\n-}\n+pub mod query;"}, {"sha": "8ec07b9fdeb7844820f565350d72f2b102ea6496", "filename": "src/librustc_query_system/query/README.md", "status": "added", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2FREADME.md?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -0,0 +1,3 @@\n+For more information about how the query system works, see the [rustc dev guide].\n+\n+[rustc dev guide]: https://rustc-dev-guide.rust-lang.org/query.html"}, {"sha": "0c0335ba04f9a17934a8b96fc3d476a1294d7b05", "filename": "src/librustc_query_system/query/caches.rs", "status": "renamed", "additions": 16, "deletions": 23, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fcaches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fcaches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fcaches.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -1,45 +1,41 @@\n use crate::dep_graph::DepNodeIndex;\n-use crate::ty::query::plumbing::{QueryLookup, QueryState, QueryStateShard};\n-use crate::ty::TyCtxt;\n+use crate::query::plumbing::{QueryLookup, QueryState};\n+use crate::query::QueryContext;\n \n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sharded::Sharded;\n use std::default::Default;\n use std::hash::Hash;\n use std::marker::PhantomData;\n \n-pub(crate) trait CacheSelector<K, V> {\n+pub trait CacheSelector<K: Hash, V> {\n     type Cache: QueryCache<Key = K, Value = V>;\n }\n \n-pub(crate) trait QueryCache: Default {\n-    type Key;\n+pub trait QueryCache: Default {\n+    type Key: Hash;\n     type Value;\n     type Sharded: Default;\n \n     /// Checks if the query is already computed and in the cache.\n     /// It returns the shard index and a lock guard to the shard,\n     /// which will be used if the query is not in the cache and we need\n     /// to compute it.\n-    fn lookup<'tcx, R, GetCache, OnHit, OnMiss>(\n+    fn lookup<CTX: QueryContext, R, OnHit, OnMiss>(\n         &self,\n-        state: &'tcx QueryState<'tcx, Self>,\n-        get_cache: GetCache,\n+        state: &QueryState<CTX, Self>,\n         key: Self::Key,\n         // `on_hit` can be called while holding a lock to the query state shard.\n         on_hit: OnHit,\n         on_miss: OnMiss,\n     ) -> R\n     where\n-        GetCache: for<'a> Fn(\n-            &'a mut QueryStateShard<'tcx, Self::Key, Self::Sharded>,\n-        ) -> &'a mut Self::Sharded,\n         OnHit: FnOnce(&Self::Value, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(Self::Key, QueryLookup<'tcx, Self::Key, Self::Sharded>) -> R;\n+        OnMiss: FnOnce(Self::Key, QueryLookup<'_, CTX, Self::Key, Self::Sharded>) -> R;\n \n-    fn complete(\n+    fn complete<CTX: QueryContext>(\n         &self,\n-        tcx: TyCtxt<'tcx>,\n+        tcx: CTX,\n         lock_sharded_storage: &mut Self::Sharded,\n         key: Self::Key,\n         value: Self::Value,\n@@ -76,32 +72,29 @@ impl<K: Eq + Hash, V: Clone> QueryCache for DefaultCache<K, V> {\n     type Sharded = FxHashMap<K, (V, DepNodeIndex)>;\n \n     #[inline(always)]\n-    fn lookup<'tcx, R, GetCache, OnHit, OnMiss>(\n+    fn lookup<CTX: QueryContext, R, OnHit, OnMiss>(\n         &self,\n-        state: &'tcx QueryState<'tcx, Self>,\n-        get_cache: GetCache,\n+        state: &QueryState<CTX, Self>,\n         key: K,\n         on_hit: OnHit,\n         on_miss: OnMiss,\n     ) -> R\n     where\n-        GetCache:\n-            for<'a> Fn(&'a mut QueryStateShard<'tcx, K, Self::Sharded>) -> &'a mut Self::Sharded,\n         OnHit: FnOnce(&V, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(K, QueryLookup<'tcx, K, Self::Sharded>) -> R,\n+        OnMiss: FnOnce(K, QueryLookup<'_, CTX, K, Self::Sharded>) -> R,\n     {\n         let mut lookup = state.get_lookup(&key);\n         let lock = &mut *lookup.lock;\n \n-        let result = get_cache(lock).raw_entry().from_key_hashed_nocheck(lookup.key_hash, &key);\n+        let result = lock.cache.raw_entry().from_key_hashed_nocheck(lookup.key_hash, &key);\n \n         if let Some((_, value)) = result { on_hit(&value.0, value.1) } else { on_miss(key, lookup) }\n     }\n \n     #[inline]\n-    fn complete(\n+    fn complete<CTX: QueryContext>(\n         &self,\n-        _: TyCtxt<'tcx>,\n+        _: CTX,\n         lock_sharded_storage: &mut Self::Sharded,\n         key: K,\n         value: V,", "previous_filename": "src/librustc/ty/query/caches.rs"}, {"sha": "20dad0bd47ebcfb1de39e458e0d35a5b7f31268d", "filename": "src/librustc_query_system/query/config.rs", "status": "added", "additions": 82, "deletions": 0, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fconfig.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -0,0 +1,82 @@\n+//! Query configuration and description traits.\n+\n+use crate::dep_graph::DepNode;\n+use crate::dep_graph::SerializedDepNodeIndex;\n+use crate::query::caches::QueryCache;\n+use crate::query::plumbing::CycleError;\n+use crate::query::{QueryContext, QueryState};\n+use rustc_data_structures::profiling::ProfileCategory;\n+use rustc_span::def_id::DefId;\n+\n+use rustc_data_structures::fingerprint::Fingerprint;\n+use std::borrow::Cow;\n+use std::fmt::Debug;\n+use std::hash::Hash;\n+\n+// The parameter `CTX` is required in librustc: implementations may need to access the `'tcx`\n+// lifetime in `CTX = TyCtxt<'tcx>`.\n+pub trait QueryConfig<CTX> {\n+    const NAME: &'static str;\n+    const CATEGORY: ProfileCategory;\n+\n+    type Key: Eq + Hash + Clone + Debug;\n+    type Value: Clone;\n+}\n+\n+pub trait QueryAccessors<CTX: QueryContext>: QueryConfig<CTX> {\n+    const ANON: bool;\n+    const EVAL_ALWAYS: bool;\n+    const DEP_KIND: CTX::DepKind;\n+\n+    type Cache: QueryCache<Key = Self::Key, Value = Self::Value>;\n+\n+    // Don't use this method to access query results, instead use the methods on TyCtxt\n+    fn query_state<'a>(tcx: CTX) -> &'a QueryState<CTX, Self::Cache>;\n+\n+    fn to_dep_node(tcx: CTX, key: &Self::Key) -> DepNode<CTX::DepKind>;\n+\n+    // Don't use this method to compute query results, instead use the methods on TyCtxt\n+    fn compute(tcx: CTX, key: Self::Key) -> Self::Value;\n+\n+    fn hash_result(\n+        hcx: &mut CTX::StableHashingContext,\n+        result: &Self::Value,\n+    ) -> Option<Fingerprint>;\n+\n+    fn handle_cycle_error(tcx: CTX, error: CycleError<CTX::Query>) -> Self::Value;\n+}\n+\n+pub trait QueryDescription<CTX: QueryContext>: QueryAccessors<CTX> {\n+    fn describe(tcx: CTX, key: Self::Key) -> Cow<'static, str>;\n+\n+    #[inline]\n+    fn cache_on_disk(_: CTX, _: Self::Key, _: Option<&Self::Value>) -> bool {\n+        false\n+    }\n+\n+    fn try_load_from_disk(_: CTX, _: SerializedDepNodeIndex) -> Option<Self::Value> {\n+        panic!(\"QueryDescription::load_from_disk() called for an unsupported query.\")\n+    }\n+}\n+\n+impl<CTX: QueryContext, M> QueryDescription<CTX> for M\n+where\n+    M: QueryAccessors<CTX, Key = DefId>,\n+{\n+    default fn describe(tcx: CTX, def_id: DefId) -> Cow<'static, str> {\n+        if !tcx.verbose() {\n+            format!(\"processing `{}`\", tcx.def_path_str(def_id)).into()\n+        } else {\n+            let name = ::std::any::type_name::<M>();\n+            format!(\"processing {:?} with query `{}`\", def_id, name).into()\n+        }\n+    }\n+\n+    default fn cache_on_disk(_: CTX, _: Self::Key, _: Option<&Self::Value>) -> bool {\n+        false\n+    }\n+\n+    default fn try_load_from_disk(_: CTX, _: SerializedDepNodeIndex) -> Option<Self::Value> {\n+        panic!(\"QueryDescription::load_from_disk() called for an unsupported query.\")\n+    }\n+}"}, {"sha": "de6dc81d8687a18be8d9e7ad7ccc7cc3257258e3", "filename": "src/librustc_query_system/query/job.rs", "status": "added", "additions": 564, "deletions": 0, "changes": 564, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fjob.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -0,0 +1,564 @@\n+use crate::dep_graph::{DepContext, DepKind};\n+use crate::query::plumbing::CycleError;\n+use crate::query::QueryContext;\n+\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_span::Span;\n+\n+use std::convert::TryFrom;\n+use std::marker::PhantomData;\n+use std::num::NonZeroU32;\n+\n+#[cfg(parallel_compiler)]\n+use {\n+    parking_lot::{Condvar, Mutex},\n+    rustc_data_structures::fx::FxHashSet,\n+    rustc_data_structures::stable_hasher::{HashStable, StableHasher},\n+    rustc_data_structures::sync::Lock,\n+    rustc_data_structures::sync::Lrc,\n+    rustc_data_structures::{jobserver, OnDrop},\n+    rustc_rayon_core as rayon_core,\n+    rustc_span::DUMMY_SP,\n+    std::iter::FromIterator,\n+    std::{mem, process},\n+};\n+\n+/// Represents a span and a query key.\n+#[derive(Clone, Debug)]\n+pub struct QueryInfo<Q> {\n+    /// The span corresponding to the reason for which this query was required.\n+    pub span: Span,\n+    pub query: Q,\n+}\n+\n+type QueryMap<CTX> = FxHashMap<QueryJobId<<CTX as DepContext>::DepKind>, QueryJobInfo<CTX>>;\n+\n+/// A value uniquely identifiying an active query job within a shard in the query cache.\n+#[derive(Copy, Clone, Eq, PartialEq, Hash)]\n+pub struct QueryShardJobId(pub NonZeroU32);\n+\n+/// A value uniquely identifiying an active query job.\n+#[derive(Copy, Clone, Eq, PartialEq, Hash)]\n+pub struct QueryJobId<K> {\n+    /// Which job within a shard is this\n+    pub job: QueryShardJobId,\n+\n+    /// In which shard is this job\n+    pub shard: u16,\n+\n+    /// What kind of query this job is\n+    pub kind: K,\n+}\n+\n+impl<K: DepKind> QueryJobId<K> {\n+    pub fn new(job: QueryShardJobId, shard: usize, kind: K) -> Self {\n+        QueryJobId { job, shard: u16::try_from(shard).unwrap(), kind }\n+    }\n+\n+    fn query<CTX: QueryContext<DepKind = K>>(self, map: &QueryMap<CTX>) -> CTX::Query {\n+        map.get(&self).unwrap().info.query.clone()\n+    }\n+\n+    #[cfg(parallel_compiler)]\n+    fn span<CTX: QueryContext<DepKind = K>>(self, map: &QueryMap<CTX>) -> Span {\n+        map.get(&self).unwrap().job.span\n+    }\n+\n+    #[cfg(parallel_compiler)]\n+    fn parent<CTX: QueryContext<DepKind = K>>(self, map: &QueryMap<CTX>) -> Option<QueryJobId<K>> {\n+        map.get(&self).unwrap().job.parent\n+    }\n+\n+    #[cfg(parallel_compiler)]\n+    fn latch<'a, CTX: QueryContext<DepKind = K>>(\n+        self,\n+        map: &'a QueryMap<CTX>,\n+    ) -> Option<&'a QueryLatch<CTX>> {\n+        map.get(&self).unwrap().job.latch.as_ref()\n+    }\n+}\n+\n+pub struct QueryJobInfo<CTX: QueryContext> {\n+    pub info: QueryInfo<CTX::Query>,\n+    pub job: QueryJob<CTX>,\n+}\n+\n+/// Represents an active query job.\n+#[derive(Clone)]\n+pub struct QueryJob<CTX: QueryContext> {\n+    pub id: QueryShardJobId,\n+\n+    /// The span corresponding to the reason for which this query was required.\n+    pub span: Span,\n+\n+    /// The parent query job which created this job and is implicitly waiting on it.\n+    pub parent: Option<QueryJobId<CTX::DepKind>>,\n+\n+    /// The latch that is used to wait on this job.\n+    #[cfg(parallel_compiler)]\n+    latch: Option<QueryLatch<CTX>>,\n+\n+    dummy: PhantomData<QueryLatch<CTX>>,\n+}\n+\n+impl<CTX: QueryContext> QueryJob<CTX> {\n+    /// Creates a new query job.\n+    pub fn new(id: QueryShardJobId, span: Span, parent: Option<QueryJobId<CTX::DepKind>>) -> Self {\n+        QueryJob {\n+            id,\n+            span,\n+            parent,\n+            #[cfg(parallel_compiler)]\n+            latch: None,\n+            dummy: PhantomData,\n+        }\n+    }\n+\n+    #[cfg(parallel_compiler)]\n+    pub(super) fn latch(&mut self, _id: QueryJobId<CTX::DepKind>) -> QueryLatch<CTX> {\n+        if self.latch.is_none() {\n+            self.latch = Some(QueryLatch::new());\n+        }\n+        self.latch.as_ref().unwrap().clone()\n+    }\n+\n+    #[cfg(not(parallel_compiler))]\n+    pub(super) fn latch(&mut self, id: QueryJobId<CTX::DepKind>) -> QueryLatch<CTX> {\n+        QueryLatch { id, dummy: PhantomData }\n+    }\n+\n+    /// Signals to waiters that the query is complete.\n+    ///\n+    /// This does nothing for single threaded rustc,\n+    /// as there are no concurrent jobs which could be waiting on us\n+    pub fn signal_complete(self) {\n+        #[cfg(parallel_compiler)]\n+        self.latch.map(|latch| latch.set());\n+    }\n+}\n+\n+#[cfg(not(parallel_compiler))]\n+#[derive(Clone)]\n+pub(super) struct QueryLatch<CTX: QueryContext> {\n+    id: QueryJobId<CTX::DepKind>,\n+    dummy: PhantomData<CTX>,\n+}\n+\n+#[cfg(not(parallel_compiler))]\n+impl<CTX: QueryContext> QueryLatch<CTX> {\n+    pub(super) fn find_cycle_in_stack(&self, tcx: CTX, span: Span) -> CycleError<CTX::Query> {\n+        let query_map = tcx.try_collect_active_jobs().unwrap();\n+\n+        // Get the current executing query (waiter) and find the waitee amongst its parents\n+        let mut current_job = tcx.current_query_job();\n+        let mut cycle = Vec::new();\n+\n+        while let Some(job) = current_job {\n+            let info = query_map.get(&job).unwrap();\n+            cycle.push(info.info.clone());\n+\n+            if job == self.id {\n+                cycle.reverse();\n+\n+                // This is the end of the cycle\n+                // The span entry we included was for the usage\n+                // of the cycle itself, and not part of the cycle\n+                // Replace it with the span which caused the cycle to form\n+                cycle[0].span = span;\n+                // Find out why the cycle itself was used\n+                let usage = info\n+                    .job\n+                    .parent\n+                    .as_ref()\n+                    .map(|parent| (info.info.span, parent.query(&query_map)));\n+                return CycleError { usage, cycle };\n+            }\n+\n+            current_job = info.job.parent;\n+        }\n+\n+        panic!(\"did not find a cycle\")\n+    }\n+}\n+\n+#[cfg(parallel_compiler)]\n+struct QueryWaiter<CTX: QueryContext> {\n+    query: Option<QueryJobId<CTX::DepKind>>,\n+    condvar: Condvar,\n+    span: Span,\n+    cycle: Lock<Option<CycleError<CTX::Query>>>,\n+}\n+\n+#[cfg(parallel_compiler)]\n+impl<CTX: QueryContext> QueryWaiter<CTX> {\n+    fn notify(&self, registry: &rayon_core::Registry) {\n+        rayon_core::mark_unblocked(registry);\n+        self.condvar.notify_one();\n+    }\n+}\n+\n+#[cfg(parallel_compiler)]\n+struct QueryLatchInfo<CTX: QueryContext> {\n+    complete: bool,\n+    waiters: Vec<Lrc<QueryWaiter<CTX>>>,\n+}\n+\n+#[cfg(parallel_compiler)]\n+#[derive(Clone)]\n+pub(super) struct QueryLatch<CTX: QueryContext> {\n+    info: Lrc<Mutex<QueryLatchInfo<CTX>>>,\n+}\n+\n+#[cfg(parallel_compiler)]\n+impl<CTX: QueryContext> QueryLatch<CTX> {\n+    fn new() -> Self {\n+        QueryLatch {\n+            info: Lrc::new(Mutex::new(QueryLatchInfo { complete: false, waiters: Vec::new() })),\n+        }\n+    }\n+}\n+\n+#[cfg(parallel_compiler)]\n+impl<CTX: QueryContext> QueryLatch<CTX> {\n+    /// Awaits for the query job to complete.\n+    pub(super) fn wait_on(&self, tcx: CTX, span: Span) -> Result<(), CycleError<CTX::Query>> {\n+        let query = tcx.current_query_job();\n+        let waiter =\n+            Lrc::new(QueryWaiter { query, span, cycle: Lock::new(None), condvar: Condvar::new() });\n+        self.wait_on_inner(&waiter);\n+        // FIXME: Get rid of this lock. We have ownership of the QueryWaiter\n+        // although another thread may still have a Lrc reference so we cannot\n+        // use Lrc::get_mut\n+        let mut cycle = waiter.cycle.lock();\n+        match cycle.take() {\n+            None => Ok(()),\n+            Some(cycle) => Err(cycle),\n+        }\n+    }\n+}\n+\n+#[cfg(parallel_compiler)]\n+impl<CTX: QueryContext> QueryLatch<CTX> {\n+    /// Awaits the caller on this latch by blocking the current thread.\n+    fn wait_on_inner(&self, waiter: &Lrc<QueryWaiter<CTX>>) {\n+        let mut info = self.info.lock();\n+        if !info.complete {\n+            // We push the waiter on to the `waiters` list. It can be accessed inside\n+            // the `wait` call below, by 1) the `set` method or 2) by deadlock detection.\n+            // Both of these will remove it from the `waiters` list before resuming\n+            // this thread.\n+            info.waiters.push(waiter.clone());\n+\n+            // If this detects a deadlock and the deadlock handler wants to resume this thread\n+            // we have to be in the `wait` call. This is ensured by the deadlock handler\n+            // getting the self.info lock.\n+            rayon_core::mark_blocked();\n+            jobserver::release_thread();\n+            waiter.condvar.wait(&mut info);\n+            // Release the lock before we potentially block in `acquire_thread`\n+            mem::drop(info);\n+            jobserver::acquire_thread();\n+        }\n+    }\n+\n+    /// Sets the latch and resumes all waiters on it\n+    fn set(&self) {\n+        let mut info = self.info.lock();\n+        debug_assert!(!info.complete);\n+        info.complete = true;\n+        let registry = rayon_core::Registry::current();\n+        for waiter in info.waiters.drain(..) {\n+            waiter.notify(&registry);\n+        }\n+    }\n+\n+    /// Removes a single waiter from the list of waiters.\n+    /// This is used to break query cycles.\n+    fn extract_waiter(&self, waiter: usize) -> Lrc<QueryWaiter<CTX>> {\n+        let mut info = self.info.lock();\n+        debug_assert!(!info.complete);\n+        // Remove the waiter from the list of waiters\n+        info.waiters.remove(waiter)\n+    }\n+}\n+\n+/// A resumable waiter of a query. The usize is the index into waiters in the query's latch\n+#[cfg(parallel_compiler)]\n+type Waiter<K> = (QueryJobId<K>, usize);\n+\n+/// Visits all the non-resumable and resumable waiters of a query.\n+/// Only waiters in a query are visited.\n+/// `visit` is called for every waiter and is passed a query waiting on `query_ref`\n+/// and a span indicating the reason the query waited on `query_ref`.\n+/// If `visit` returns Some, this function returns.\n+/// For visits of non-resumable waiters it returns the return value of `visit`.\n+/// For visits of resumable waiters it returns Some(Some(Waiter)) which has the\n+/// required information to resume the waiter.\n+/// If all `visit` calls returns None, this function also returns None.\n+#[cfg(parallel_compiler)]\n+fn visit_waiters<CTX: QueryContext, F>(\n+    query_map: &QueryMap<CTX>,\n+    query: QueryJobId<CTX::DepKind>,\n+    mut visit: F,\n+) -> Option<Option<Waiter<CTX::DepKind>>>\n+where\n+    F: FnMut(Span, QueryJobId<CTX::DepKind>) -> Option<Option<Waiter<CTX::DepKind>>>,\n+{\n+    // Visit the parent query which is a non-resumable waiter since it's on the same stack\n+    if let Some(parent) = query.parent(query_map) {\n+        if let Some(cycle) = visit(query.span(query_map), parent) {\n+            return Some(cycle);\n+        }\n+    }\n+\n+    // Visit the explicit waiters which use condvars and are resumable\n+    if let Some(latch) = query.latch(query_map) {\n+        for (i, waiter) in latch.info.lock().waiters.iter().enumerate() {\n+            if let Some(waiter_query) = waiter.query {\n+                if visit(waiter.span, waiter_query).is_some() {\n+                    // Return a value which indicates that this waiter can be resumed\n+                    return Some(Some((query, i)));\n+                }\n+            }\n+        }\n+    }\n+\n+    None\n+}\n+\n+/// Look for query cycles by doing a depth first search starting at `query`.\n+/// `span` is the reason for the `query` to execute. This is initially DUMMY_SP.\n+/// If a cycle is detected, this initial value is replaced with the span causing\n+/// the cycle.\n+#[cfg(parallel_compiler)]\n+fn cycle_check<CTX: QueryContext>(\n+    query_map: &QueryMap<CTX>,\n+    query: QueryJobId<CTX::DepKind>,\n+    span: Span,\n+    stack: &mut Vec<(Span, QueryJobId<CTX::DepKind>)>,\n+    visited: &mut FxHashSet<QueryJobId<CTX::DepKind>>,\n+) -> Option<Option<Waiter<CTX::DepKind>>> {\n+    if !visited.insert(query) {\n+        return if let Some(p) = stack.iter().position(|q| q.1 == query) {\n+            // We detected a query cycle, fix up the initial span and return Some\n+\n+            // Remove previous stack entries\n+            stack.drain(0..p);\n+            // Replace the span for the first query with the cycle cause\n+            stack[0].0 = span;\n+            Some(None)\n+        } else {\n+            None\n+        };\n+    }\n+\n+    // Query marked as visited is added it to the stack\n+    stack.push((span, query));\n+\n+    // Visit all the waiters\n+    let r = visit_waiters(query_map, query, |span, successor| {\n+        cycle_check(query_map, successor, span, stack, visited)\n+    });\n+\n+    // Remove the entry in our stack if we didn't find a cycle\n+    if r.is_none() {\n+        stack.pop();\n+    }\n+\n+    r\n+}\n+\n+/// Finds out if there's a path to the compiler root (aka. code which isn't in a query)\n+/// from `query` without going through any of the queries in `visited`.\n+/// This is achieved with a depth first search.\n+#[cfg(parallel_compiler)]\n+fn connected_to_root<CTX: QueryContext>(\n+    query_map: &QueryMap<CTX>,\n+    query: QueryJobId<CTX::DepKind>,\n+    visited: &mut FxHashSet<QueryJobId<CTX::DepKind>>,\n+) -> bool {\n+    // We already visited this or we're deliberately ignoring it\n+    if !visited.insert(query) {\n+        return false;\n+    }\n+\n+    // This query is connected to the root (it has no query parent), return true\n+    if query.parent(query_map).is_none() {\n+        return true;\n+    }\n+\n+    visit_waiters(query_map, query, |_, successor| {\n+        connected_to_root(query_map, successor, visited).then_some(None)\n+    })\n+    .is_some()\n+}\n+\n+// Deterministically pick an query from a list\n+#[cfg(parallel_compiler)]\n+fn pick_query<'a, CTX, T, F>(query_map: &QueryMap<CTX>, tcx: CTX, queries: &'a [T], f: F) -> &'a T\n+where\n+    CTX: QueryContext,\n+    F: Fn(&T) -> (Span, QueryJobId<CTX::DepKind>),\n+{\n+    // Deterministically pick an entry point\n+    // FIXME: Sort this instead\n+    let mut hcx = tcx.create_stable_hashing_context();\n+    queries\n+        .iter()\n+        .min_by_key(|v| {\n+            let (span, query) = f(v);\n+            let mut stable_hasher = StableHasher::new();\n+            query.query(query_map).hash_stable(&mut hcx, &mut stable_hasher);\n+            // Prefer entry points which have valid spans for nicer error messages\n+            // We add an integer to the tuple ensuring that entry points\n+            // with valid spans are picked first\n+            let span_cmp = if span == DUMMY_SP { 1 } else { 0 };\n+            (span_cmp, stable_hasher.finish::<u64>())\n+        })\n+        .unwrap()\n+}\n+\n+/// Looks for query cycles starting from the last query in `jobs`.\n+/// If a cycle is found, all queries in the cycle is removed from `jobs` and\n+/// the function return true.\n+/// If a cycle was not found, the starting query is removed from `jobs` and\n+/// the function returns false.\n+#[cfg(parallel_compiler)]\n+fn remove_cycle<CTX: QueryContext>(\n+    query_map: &QueryMap<CTX>,\n+    jobs: &mut Vec<QueryJobId<CTX::DepKind>>,\n+    wakelist: &mut Vec<Lrc<QueryWaiter<CTX>>>,\n+    tcx: CTX,\n+) -> bool {\n+    let mut visited = FxHashSet::default();\n+    let mut stack = Vec::new();\n+    // Look for a cycle starting with the last query in `jobs`\n+    if let Some(waiter) =\n+        cycle_check(query_map, jobs.pop().unwrap(), DUMMY_SP, &mut stack, &mut visited)\n+    {\n+        // The stack is a vector of pairs of spans and queries; reverse it so that\n+        // the earlier entries require later entries\n+        let (mut spans, queries): (Vec<_>, Vec<_>) = stack.into_iter().rev().unzip();\n+\n+        // Shift the spans so that queries are matched with the span for their waitee\n+        spans.rotate_right(1);\n+\n+        // Zip them back together\n+        let mut stack: Vec<_> = spans.into_iter().zip(queries).collect();\n+\n+        // Remove the queries in our cycle from the list of jobs to look at\n+        for r in &stack {\n+            jobs.remove_item(&r.1);\n+        }\n+\n+        // Find the queries in the cycle which are\n+        // connected to queries outside the cycle\n+        let entry_points = stack\n+            .iter()\n+            .filter_map(|&(span, query)| {\n+                if query.parent(query_map).is_none() {\n+                    // This query is connected to the root (it has no query parent)\n+                    Some((span, query, None))\n+                } else {\n+                    let mut waiters = Vec::new();\n+                    // Find all the direct waiters who lead to the root\n+                    visit_waiters(query_map, query, |span, waiter| {\n+                        // Mark all the other queries in the cycle as already visited\n+                        let mut visited = FxHashSet::from_iter(stack.iter().map(|q| q.1));\n+\n+                        if connected_to_root(query_map, waiter, &mut visited) {\n+                            waiters.push((span, waiter));\n+                        }\n+\n+                        None\n+                    });\n+                    if waiters.is_empty() {\n+                        None\n+                    } else {\n+                        // Deterministically pick one of the waiters to show to the user\n+                        let waiter = *pick_query(query_map, tcx, &waiters, |s| *s);\n+                        Some((span, query, Some(waiter)))\n+                    }\n+                }\n+            })\n+            .collect::<Vec<(Span, QueryJobId<CTX::DepKind>, Option<(Span, QueryJobId<CTX::DepKind>)>)>>();\n+\n+        // Deterministically pick an entry point\n+        let (_, entry_point, usage) = pick_query(query_map, tcx, &entry_points, |e| (e.0, e.1));\n+\n+        // Shift the stack so that our entry point is first\n+        let entry_point_pos = stack.iter().position(|(_, query)| query == entry_point);\n+        if let Some(pos) = entry_point_pos {\n+            stack.rotate_left(pos);\n+        }\n+\n+        let usage = usage.as_ref().map(|(span, query)| (*span, query.query(query_map)));\n+\n+        // Create the cycle error\n+        let error = CycleError {\n+            usage,\n+            cycle: stack\n+                .iter()\n+                .map(|&(s, ref q)| QueryInfo { span: s, query: q.query(query_map) })\n+                .collect(),\n+        };\n+\n+        // We unwrap `waiter` here since there must always be one\n+        // edge which is resumeable / waited using a query latch\n+        let (waitee_query, waiter_idx) = waiter.unwrap();\n+\n+        // Extract the waiter we want to resume\n+        let waiter = waitee_query.latch(query_map).unwrap().extract_waiter(waiter_idx);\n+\n+        // Set the cycle error so it will be picked up when resumed\n+        *waiter.cycle.lock() = Some(error);\n+\n+        // Put the waiter on the list of things to resume\n+        wakelist.push(waiter);\n+\n+        true\n+    } else {\n+        false\n+    }\n+}\n+\n+/// Detects query cycles by using depth first search over all active query jobs.\n+/// If a query cycle is found it will break the cycle by finding an edge which\n+/// uses a query latch and then resuming that waiter.\n+/// There may be multiple cycles involved in a deadlock, so this searches\n+/// all active queries for cycles before finally resuming all the waiters at once.\n+#[cfg(parallel_compiler)]\n+pub fn deadlock<CTX: QueryContext>(tcx: CTX, registry: &rayon_core::Registry) {\n+    let on_panic = OnDrop(|| {\n+        eprintln!(\"deadlock handler panicked, aborting process\");\n+        process::abort();\n+    });\n+\n+    let mut wakelist = Vec::new();\n+    let query_map = tcx.try_collect_active_jobs().unwrap();\n+    let mut jobs: Vec<QueryJobId<CTX::DepKind>> = query_map.keys().cloned().collect();\n+\n+    let mut found_cycle = false;\n+\n+    while jobs.len() > 0 {\n+        if remove_cycle(&query_map, &mut jobs, &mut wakelist, tcx) {\n+            found_cycle = true;\n+        }\n+    }\n+\n+    // Check that a cycle was found. It is possible for a deadlock to occur without\n+    // a query cycle if a query which can be waited on uses Rayon to do multithreading\n+    // internally. Such a query (X) may be executing on 2 threads (A and B) and A may\n+    // wait using Rayon on B. Rayon may then switch to executing another query (Y)\n+    // which in turn will wait on X causing a deadlock. We have a false dependency from\n+    // X to Y due to Rayon waiting and a true dependency from Y to X. The algorithm here\n+    // only considers the true dependency and won't detect a cycle.\n+    assert!(found_cycle);\n+\n+    // FIXME: Ensure this won't cause a deadlock before we return\n+    for waiter in wakelist.into_iter() {\n+        waiter.notify(registry);\n+    }\n+\n+    on_panic.disable();\n+}"}, {"sha": "b1677c5c93da9e9a4a8fa978e7b255135339e103", "filename": "src/librustc_query_system/query/mod.rs", "status": "added", "additions": 52, "deletions": 0, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fmod.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -0,0 +1,52 @@\n+mod plumbing;\n+pub use self::plumbing::*;\n+\n+mod job;\n+#[cfg(parallel_compiler)]\n+pub use self::job::deadlock;\n+pub use self::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n+\n+mod caches;\n+pub use self::caches::{CacheSelector, DefaultCacheSelector, QueryCache};\n+\n+mod config;\n+pub use self::config::{QueryAccessors, QueryConfig, QueryDescription};\n+\n+use crate::dep_graph::{DepContext, DepGraph};\n+\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::stable_hasher::HashStable;\n+use rustc_data_structures::sync::Lock;\n+use rustc_data_structures::thin_vec::ThinVec;\n+use rustc_errors::Diagnostic;\n+use rustc_span::def_id::DefId;\n+\n+pub trait QueryContext: DepContext {\n+    type Query: Clone + HashStable<Self::StableHashingContext>;\n+\n+    fn incremental_verify_ich(&self) -> bool;\n+    fn verbose(&self) -> bool;\n+\n+    /// Get string representation from DefPath.\n+    fn def_path_str(&self, def_id: DefId) -> String;\n+\n+    /// Access the DepGraph.\n+    fn dep_graph(&self) -> &DepGraph<Self::DepKind>;\n+\n+    /// Get the query information from the TLS context.\n+    fn current_query_job(&self) -> Option<QueryJobId<Self::DepKind>>;\n+\n+    fn try_collect_active_jobs(\n+        &self,\n+    ) -> Option<FxHashMap<QueryJobId<Self::DepKind>, QueryJobInfo<Self>>>;\n+\n+    /// Executes a job by changing the `ImplicitCtxt` to point to the\n+    /// new query job while it executes. It returns the diagnostics\n+    /// captured during execution and the actual result.\n+    fn start_query<R>(\n+        &self,\n+        token: QueryJobId<Self::DepKind>,\n+        diagnostics: Option<&Lock<ThinVec<Diagnostic>>>,\n+        compute: impl FnOnce(Self) -> R,\n+    ) -> R;\n+}"}, {"sha": "b371a914c6fce02304d26bd16c237862b4a91e7c", "filename": "src/librustc_query_system/query/plumbing.rs", "status": "added", "additions": 693, "deletions": 0, "changes": 693, "blob_url": "https://github.com/rust-lang/rust/blob/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4/src%2Flibrustc_query_system%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fplumbing.rs?ref=0bf7c2ad77fdcb18a65ae05996dc8e226fbaeab4", "patch": "@@ -0,0 +1,693 @@\n+//! The implementation of the query system itself. This defines the macros that\n+//! generate the actual methods on tcx which find and execute the provider,\n+//! manage the caches, and so forth.\n+\n+use crate::dep_graph::{DepKind, DepNode};\n+use crate::dep_graph::{DepNodeIndex, SerializedDepNodeIndex};\n+use crate::query::caches::QueryCache;\n+use crate::query::config::QueryDescription;\n+use crate::query::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo, QueryShardJobId};\n+use crate::query::QueryContext;\n+\n+#[cfg(not(parallel_compiler))]\n+use rustc_data_structures::cold_path;\n+use rustc_data_structures::fingerprint::Fingerprint;\n+use rustc_data_structures::fx::{FxHashMap, FxHasher};\n+use rustc_data_structures::sharded::Sharded;\n+use rustc_data_structures::sync::{Lock, LockGuard};\n+use rustc_data_structures::thin_vec::ThinVec;\n+use rustc_errors::{Diagnostic, FatalError};\n+use rustc_span::source_map::DUMMY_SP;\n+use rustc_span::Span;\n+use std::collections::hash_map::Entry;\n+use std::convert::TryFrom;\n+use std::fmt::Debug;\n+use std::hash::{Hash, Hasher};\n+use std::mem;\n+use std::num::NonZeroU32;\n+use std::ptr;\n+#[cfg(debug_assertions)]\n+use std::sync::atomic::{AtomicUsize, Ordering};\n+\n+pub struct QueryStateShard<CTX: QueryContext, K, C> {\n+    pub(super) cache: C,\n+    active: FxHashMap<K, QueryResult<CTX>>,\n+\n+    /// Used to generate unique ids for active jobs.\n+    jobs: u32,\n+}\n+\n+impl<CTX: QueryContext, K, C: Default> Default for QueryStateShard<CTX, K, C> {\n+    fn default() -> QueryStateShard<CTX, K, C> {\n+        QueryStateShard { cache: Default::default(), active: Default::default(), jobs: 0 }\n+    }\n+}\n+\n+pub struct QueryState<CTX: QueryContext, C: QueryCache> {\n+    cache: C,\n+    shards: Sharded<QueryStateShard<CTX, C::Key, C::Sharded>>,\n+    #[cfg(debug_assertions)]\n+    pub cache_hits: AtomicUsize,\n+}\n+\n+impl<CTX: QueryContext, C: QueryCache> QueryState<CTX, C> {\n+    pub(super) fn get_lookup<'tcx>(\n+        &'tcx self,\n+        key: &C::Key,\n+    ) -> QueryLookup<'tcx, CTX, C::Key, C::Sharded> {\n+        // We compute the key's hash once and then use it for both the\n+        // shard lookup and the hashmap lookup. This relies on the fact\n+        // that both of them use `FxHasher`.\n+        let mut hasher = FxHasher::default();\n+        key.hash(&mut hasher);\n+        let key_hash = hasher.finish();\n+\n+        let shard = self.shards.get_shard_index_by_hash(key_hash);\n+        let lock = self.shards.get_shard_by_index(shard).lock();\n+        QueryLookup { key_hash, shard, lock }\n+    }\n+}\n+\n+/// Indicates the state of a query for a given key in a query map.\n+enum QueryResult<CTX: QueryContext> {\n+    /// An already executing query. The query job can be used to await for its completion.\n+    Started(QueryJob<CTX>),\n+\n+    /// The query panicked. Queries trying to wait on this will raise a fatal error which will\n+    /// silently panic.\n+    Poisoned,\n+}\n+\n+impl<CTX: QueryContext, C: QueryCache> QueryState<CTX, C> {\n+    pub fn iter_results<R>(\n+        &self,\n+        f: impl for<'a> FnOnce(\n+            Box<dyn Iterator<Item = (&'a C::Key, &'a C::Value, DepNodeIndex)> + 'a>,\n+        ) -> R,\n+    ) -> R {\n+        self.cache.iter(&self.shards, |shard| &mut shard.cache, f)\n+    }\n+\n+    pub fn all_inactive(&self) -> bool {\n+        let shards = self.shards.lock_shards();\n+        shards.iter().all(|shard| shard.active.is_empty())\n+    }\n+\n+    pub fn try_collect_active_jobs(\n+        &self,\n+        kind: CTX::DepKind,\n+        make_query: fn(C::Key) -> CTX::Query,\n+        jobs: &mut FxHashMap<QueryJobId<CTX::DepKind>, QueryJobInfo<CTX>>,\n+    ) -> Option<()>\n+    where\n+        C::Key: Clone,\n+    {\n+        // We use try_lock_shards here since we are called from the\n+        // deadlock handler, and this shouldn't be locked.\n+        let shards = self.shards.try_lock_shards()?;\n+        let shards = shards.iter().enumerate();\n+        jobs.extend(shards.flat_map(|(shard_id, shard)| {\n+            shard.active.iter().filter_map(move |(k, v)| {\n+                if let QueryResult::Started(ref job) = *v {\n+                    let id =\n+                        QueryJobId { job: job.id, shard: u16::try_from(shard_id).unwrap(), kind };\n+                    let info = QueryInfo { span: job.span, query: make_query(k.clone()) };\n+                    Some((id, QueryJobInfo { info, job: job.clone() }))\n+                } else {\n+                    None\n+                }\n+            })\n+        }));\n+\n+        Some(())\n+    }\n+}\n+\n+impl<CTX: QueryContext, C: QueryCache> Default for QueryState<CTX, C> {\n+    fn default() -> QueryState<CTX, C> {\n+        QueryState {\n+            cache: C::default(),\n+            shards: Default::default(),\n+            #[cfg(debug_assertions)]\n+            cache_hits: AtomicUsize::new(0),\n+        }\n+    }\n+}\n+\n+/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n+pub struct QueryLookup<'tcx, CTX: QueryContext, K, C> {\n+    pub(super) key_hash: u64,\n+    shard: usize,\n+    pub(super) lock: LockGuard<'tcx, QueryStateShard<CTX, K, C>>,\n+}\n+\n+/// A type representing the responsibility to execute the job in the `job` field.\n+/// This will poison the relevant query if dropped.\n+struct JobOwner<'tcx, CTX: QueryContext, C>\n+where\n+    C: QueryCache,\n+    C::Key: Eq + Hash + Clone + Debug,\n+    C::Value: Clone,\n+{\n+    state: &'tcx QueryState<CTX, C>,\n+    key: C::Key,\n+    id: QueryJobId<CTX::DepKind>,\n+}\n+\n+impl<'tcx, CTX: QueryContext, C> JobOwner<'tcx, CTX, C>\n+where\n+    C: QueryCache,\n+    C::Key: Eq + Hash + Clone + Debug,\n+    C::Value: Clone,\n+{\n+    /// Either gets a `JobOwner` corresponding the query, allowing us to\n+    /// start executing the query, or returns with the result of the query.\n+    /// This function assumes that `try_get_cached` is already called and returned `lookup`.\n+    /// If the query is executing elsewhere, this will wait for it and return the result.\n+    /// If the query panicked, this will silently panic.\n+    ///\n+    /// This function is inlined because that results in a noticeable speed-up\n+    /// for some compile-time benchmarks.\n+    #[inline(always)]\n+    fn try_start<'a, 'b, Q>(\n+        tcx: CTX,\n+        span: Span,\n+        key: &C::Key,\n+        mut lookup: QueryLookup<'a, CTX, C::Key, C::Sharded>,\n+    ) -> TryGetJob<'b, CTX, C>\n+    where\n+        Q: QueryDescription<CTX, Key = C::Key, Value = C::Value, Cache = C>,\n+        CTX: QueryContext,\n+    {\n+        let lock = &mut *lookup.lock;\n+\n+        let (latch, mut _query_blocked_prof_timer) = match lock.active.entry((*key).clone()) {\n+            Entry::Occupied(mut entry) => {\n+                match entry.get_mut() {\n+                    QueryResult::Started(job) => {\n+                        // For parallel queries, we'll block and wait until the query running\n+                        // in another thread has completed. Record how long we wait in the\n+                        // self-profiler.\n+                        let _query_blocked_prof_timer = if cfg!(parallel_compiler) {\n+                            Some(tcx.profiler().query_blocked())\n+                        } else {\n+                            None\n+                        };\n+\n+                        // Create the id of the job we're waiting for\n+                        let id = QueryJobId::new(job.id, lookup.shard, Q::DEP_KIND);\n+\n+                        (job.latch(id), _query_blocked_prof_timer)\n+                    }\n+                    QueryResult::Poisoned => FatalError.raise(),\n+                }\n+            }\n+            Entry::Vacant(entry) => {\n+                // No job entry for this query. Return a new one to be started later.\n+\n+                // Generate an id unique within this shard.\n+                let id = lock.jobs.checked_add(1).unwrap();\n+                lock.jobs = id;\n+                let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n+\n+                let global_id = QueryJobId::new(id, lookup.shard, Q::DEP_KIND);\n+\n+                let job = tcx.current_query_job();\n+                let job = QueryJob::new(id, span, job);\n+\n+                entry.insert(QueryResult::Started(job));\n+\n+                let owner =\n+                    JobOwner { state: Q::query_state(tcx), id: global_id, key: (*key).clone() };\n+                return TryGetJob::NotYetStarted(owner);\n+            }\n+        };\n+        mem::drop(lookup.lock);\n+\n+        // If we are single-threaded we know that we have cycle error,\n+        // so we just return the error.\n+        #[cfg(not(parallel_compiler))]\n+        return TryGetJob::Cycle(cold_path(|| {\n+            Q::handle_cycle_error(tcx, latch.find_cycle_in_stack(tcx, span))\n+        }));\n+\n+        // With parallel queries we might just have to wait on some other\n+        // thread.\n+        #[cfg(parallel_compiler)]\n+        {\n+            let result = latch.wait_on(tcx, span);\n+\n+            if let Err(cycle) = result {\n+                return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n+            }\n+\n+            let cached = try_get_cached(\n+                tcx,\n+                Q::query_state(tcx),\n+                (*key).clone(),\n+                |value, index| (value.clone(), index),\n+                |_, _| panic!(\"value must be in cache after waiting\"),\n+            );\n+\n+            if let Some(prof_timer) = _query_blocked_prof_timer.take() {\n+                prof_timer.finish_with_query_invocation_id(cached.1.into());\n+            }\n+\n+            return TryGetJob::JobCompleted(cached);\n+        }\n+    }\n+\n+    /// Completes the query by updating the query cache with the `result`,\n+    /// signals the waiter and forgets the JobOwner, so it won't poison the query\n+    #[inline(always)]\n+    fn complete(self, tcx: CTX, result: &C::Value, dep_node_index: DepNodeIndex) {\n+        // We can move out of `self` here because we `mem::forget` it below\n+        let key = unsafe { ptr::read(&self.key) };\n+        let state = self.state;\n+\n+        // Forget ourself so our destructor won't poison the query\n+        mem::forget(self);\n+\n+        let job = {\n+            let result = result.clone();\n+            let mut lock = state.shards.get_shard_by_value(&key).lock();\n+            let job = match lock.active.remove(&key).unwrap() {\n+                QueryResult::Started(job) => job,\n+                QueryResult::Poisoned => panic!(),\n+            };\n+            state.cache.complete(tcx, &mut lock.cache, key, result, dep_node_index);\n+            job\n+        };\n+\n+        job.signal_complete();\n+    }\n+}\n+\n+#[inline(always)]\n+fn with_diagnostics<F, R>(f: F) -> (R, ThinVec<Diagnostic>)\n+where\n+    F: FnOnce(Option<&Lock<ThinVec<Diagnostic>>>) -> R,\n+{\n+    let diagnostics = Lock::new(ThinVec::new());\n+    let result = f(Some(&diagnostics));\n+    (result, diagnostics.into_inner())\n+}\n+\n+impl<'tcx, CTX: QueryContext, C: QueryCache> Drop for JobOwner<'tcx, CTX, C>\n+where\n+    C::Key: Eq + Hash + Clone + Debug,\n+    C::Value: Clone,\n+{\n+    #[inline(never)]\n+    #[cold]\n+    fn drop(&mut self) {\n+        // Poison the query so jobs waiting on it panic.\n+        let state = self.state;\n+        let shard = state.shards.get_shard_by_value(&self.key);\n+        let job = {\n+            let mut shard = shard.lock();\n+            let job = match shard.active.remove(&self.key).unwrap() {\n+                QueryResult::Started(job) => job,\n+                QueryResult::Poisoned => panic!(),\n+            };\n+            shard.active.insert(self.key.clone(), QueryResult::Poisoned);\n+            job\n+        };\n+        // Also signal the completion of the job, so waiters\n+        // will continue execution.\n+        job.signal_complete();\n+    }\n+}\n+\n+#[derive(Clone)]\n+pub struct CycleError<Q> {\n+    /// The query and related span that uses the cycle.\n+    pub usage: Option<(Span, Q)>,\n+    pub cycle: Vec<QueryInfo<Q>>,\n+}\n+\n+/// The result of `try_start`.\n+enum TryGetJob<'tcx, CTX: QueryContext, C: QueryCache>\n+where\n+    C::Key: Eq + Hash + Clone + Debug,\n+    C::Value: Clone,\n+{\n+    /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n+    NotYetStarted(JobOwner<'tcx, CTX, C>),\n+\n+    /// The query was already completed.\n+    /// Returns the result of the query and its dep-node index\n+    /// if it succeeded or a cycle error if it failed.\n+    #[cfg(parallel_compiler)]\n+    JobCompleted((C::Value, DepNodeIndex)),\n+\n+    /// Trying to execute the query resulted in a cycle.\n+    Cycle(C::Value),\n+}\n+\n+/// Checks if the query is already computed and in the cache.\n+/// It returns the shard index and a lock guard to the shard,\n+/// which will be used if the query is not in the cache and we need\n+/// to compute it.\n+#[inline(always)]\n+fn try_get_cached<CTX, C, R, OnHit, OnMiss>(\n+    tcx: CTX,\n+    state: &QueryState<CTX, C>,\n+    key: C::Key,\n+    // `on_hit` can be called while holding a lock to the query cache\n+    on_hit: OnHit,\n+    on_miss: OnMiss,\n+) -> R\n+where\n+    C: QueryCache,\n+    CTX: QueryContext,\n+    OnHit: FnOnce(&C::Value, DepNodeIndex) -> R,\n+    OnMiss: FnOnce(C::Key, QueryLookup<'_, CTX, C::Key, C::Sharded>) -> R,\n+{\n+    state.cache.lookup(\n+        state,\n+        key,\n+        |value, index| {\n+            if unlikely!(tcx.profiler().enabled()) {\n+                tcx.profiler().query_cache_hit(index.into());\n+            }\n+            #[cfg(debug_assertions)]\n+            {\n+                state.cache_hits.fetch_add(1, Ordering::Relaxed);\n+            }\n+            on_hit(value, index)\n+        },\n+        on_miss,\n+    )\n+}\n+\n+#[inline(always)]\n+fn try_execute_query<Q, CTX>(\n+    tcx: CTX,\n+    span: Span,\n+    key: Q::Key,\n+    lookup: QueryLookup<'_, CTX, Q::Key, <Q::Cache as QueryCache>::Sharded>,\n+) -> Q::Value\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext,\n+{\n+    let job = match JobOwner::try_start::<Q>(tcx, span, &key, lookup) {\n+        TryGetJob::NotYetStarted(job) => job,\n+        TryGetJob::Cycle(result) => return result,\n+        #[cfg(parallel_compiler)]\n+        TryGetJob::JobCompleted((v, index)) => {\n+            tcx.dep_graph().read_index(index);\n+            return v;\n+        }\n+    };\n+\n+    // Fast path for when incr. comp. is off. `to_dep_node` is\n+    // expensive for some `DepKind`s.\n+    if !tcx.dep_graph().is_fully_enabled() {\n+        let null_dep_node = DepNode::new_no_params(DepKind::NULL);\n+        return force_query_with_job::<Q, _>(tcx, key, job, null_dep_node).0;\n+    }\n+\n+    if Q::ANON {\n+        let prof_timer = tcx.profiler().query_provider();\n+\n+        let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n+            tcx.start_query(job.id, diagnostics, |tcx| {\n+                tcx.dep_graph().with_anon_task(Q::DEP_KIND, || Q::compute(tcx, key))\n+            })\n+        });\n+\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+\n+        tcx.dep_graph().read_index(dep_node_index);\n+\n+        if unlikely!(!diagnostics.is_empty()) {\n+            tcx.store_diagnostics_for_anon_node(dep_node_index, diagnostics);\n+        }\n+\n+        job.complete(tcx, &result, dep_node_index);\n+\n+        return result;\n+    }\n+\n+    let dep_node = Q::to_dep_node(tcx, &key);\n+\n+    if !Q::EVAL_ALWAYS {\n+        // The diagnostics for this query will be\n+        // promoted to the current session during\n+        // `try_mark_green()`, so we can ignore them here.\n+        let loaded = tcx.start_query(job.id, None, |tcx| {\n+            let marked = tcx.dep_graph().try_mark_green_and_read(tcx, &dep_node);\n+            marked.map(|(prev_dep_node_index, dep_node_index)| {\n+                (\n+                    load_from_disk_and_cache_in_memory::<Q, _>(\n+                        tcx,\n+                        key.clone(),\n+                        prev_dep_node_index,\n+                        dep_node_index,\n+                        &dep_node,\n+                    ),\n+                    dep_node_index,\n+                )\n+            })\n+        });\n+        if let Some((result, dep_node_index)) = loaded {\n+            job.complete(tcx, &result, dep_node_index);\n+            return result;\n+        }\n+    }\n+\n+    let (result, dep_node_index) = force_query_with_job::<Q, _>(tcx, key, job, dep_node);\n+    tcx.dep_graph().read_index(dep_node_index);\n+    result\n+}\n+\n+fn load_from_disk_and_cache_in_memory<Q, CTX>(\n+    tcx: CTX,\n+    key: Q::Key,\n+    prev_dep_node_index: SerializedDepNodeIndex,\n+    dep_node_index: DepNodeIndex,\n+    dep_node: &DepNode<CTX::DepKind>,\n+) -> Q::Value\n+where\n+    CTX: QueryContext,\n+    Q: QueryDescription<CTX>,\n+{\n+    // Note this function can be called concurrently from the same query\n+    // We must ensure that this is handled correctly.\n+\n+    debug_assert!(tcx.dep_graph().is_green(dep_node));\n+\n+    // First we try to load the result from the on-disk cache.\n+    let result = if Q::cache_on_disk(tcx, key.clone(), None) {\n+        let prof_timer = tcx.profiler().incr_cache_loading();\n+        let result = Q::try_load_from_disk(tcx, prev_dep_node_index);\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+\n+        // We always expect to find a cached result for things that\n+        // can be forced from `DepNode`.\n+        debug_assert!(\n+            !dep_node.kind.can_reconstruct_query_key() || result.is_some(),\n+            \"missing on-disk cache entry for {:?}\",\n+            dep_node\n+        );\n+        result\n+    } else {\n+        // Some things are never cached on disk.\n+        None\n+    };\n+\n+    let result = if let Some(result) = result {\n+        result\n+    } else {\n+        // We could not load a result from the on-disk cache, so\n+        // recompute.\n+        let prof_timer = tcx.profiler().query_provider();\n+\n+        // The dep-graph for this computation is already in-place.\n+        let result = tcx.dep_graph().with_ignore(|| Q::compute(tcx, key));\n+\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+\n+        result\n+    };\n+\n+    // If `-Zincremental-verify-ich` is specified, re-hash results from\n+    // the cache and make sure that they have the expected fingerprint.\n+    if unlikely!(tcx.incremental_verify_ich()) {\n+        incremental_verify_ich::<Q, _>(tcx, &result, dep_node, dep_node_index);\n+    }\n+\n+    result\n+}\n+\n+#[inline(never)]\n+#[cold]\n+fn incremental_verify_ich<Q, CTX>(\n+    tcx: CTX,\n+    result: &Q::Value,\n+    dep_node: &DepNode<CTX::DepKind>,\n+    dep_node_index: DepNodeIndex,\n+) where\n+    CTX: QueryContext,\n+    Q: QueryDescription<CTX>,\n+{\n+    assert!(\n+        Some(tcx.dep_graph().fingerprint_of(dep_node_index))\n+            == tcx.dep_graph().prev_fingerprint_of(dep_node),\n+        \"fingerprint for green query instance not loaded from cache: {:?}\",\n+        dep_node,\n+    );\n+\n+    debug!(\"BEGIN verify_ich({:?})\", dep_node);\n+    let mut hcx = tcx.create_stable_hashing_context();\n+\n+    let new_hash = Q::hash_result(&mut hcx, result).unwrap_or(Fingerprint::ZERO);\n+    debug!(\"END verify_ich({:?})\", dep_node);\n+\n+    let old_hash = tcx.dep_graph().fingerprint_of(dep_node_index);\n+\n+    assert!(new_hash == old_hash, \"found unstable fingerprints for {:?}\", dep_node,);\n+}\n+\n+#[inline(always)]\n+fn force_query_with_job<Q, CTX>(\n+    tcx: CTX,\n+    key: Q::Key,\n+    job: JobOwner<'_, CTX, Q::Cache>,\n+    dep_node: DepNode<CTX::DepKind>,\n+) -> (Q::Value, DepNodeIndex)\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext,\n+{\n+    // If the following assertion triggers, it can have two reasons:\n+    // 1. Something is wrong with DepNode creation, either here or\n+    //    in `DepGraph::try_mark_green()`.\n+    // 2. Two distinct query keys get mapped to the same `DepNode`\n+    //    (see for example #48923).\n+    assert!(\n+        !tcx.dep_graph().dep_node_exists(&dep_node),\n+        \"forcing query with already existing `DepNode`\\n\\\n+                 - query-key: {:?}\\n\\\n+                 - dep-node: {:?}\",\n+        key,\n+        dep_node\n+    );\n+\n+    let prof_timer = tcx.profiler().query_provider();\n+\n+    let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n+        tcx.start_query(job.id, diagnostics, |tcx| {\n+            if Q::EVAL_ALWAYS {\n+                tcx.dep_graph().with_eval_always_task(\n+                    dep_node,\n+                    tcx,\n+                    key,\n+                    Q::compute,\n+                    Q::hash_result,\n+                )\n+            } else {\n+                tcx.dep_graph().with_task(dep_node, tcx, key, Q::compute, Q::hash_result)\n+            }\n+        })\n+    });\n+\n+    prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+\n+    if unlikely!(!diagnostics.is_empty()) {\n+        if dep_node.kind != DepKind::NULL {\n+            tcx.store_diagnostics(dep_node_index, diagnostics);\n+        }\n+    }\n+\n+    job.complete(tcx, &result, dep_node_index);\n+\n+    (result, dep_node_index)\n+}\n+\n+#[inline(never)]\n+pub fn get_query<Q, CTX>(tcx: CTX, span: Span, key: Q::Key) -> Q::Value\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext,\n+{\n+    debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n+\n+    try_get_cached(\n+        tcx,\n+        Q::query_state(tcx),\n+        key,\n+        |value, index| {\n+            tcx.dep_graph().read_index(index);\n+            value.clone()\n+        },\n+        |key, lookup| try_execute_query::<Q, _>(tcx, span, key, lookup),\n+    )\n+}\n+\n+/// Ensure that either this query has all green inputs or been executed.\n+/// Executing `query::ensure(D)` is considered a read of the dep-node `D`.\n+///\n+/// This function is particularly useful when executing passes for their\n+/// side-effects -- e.g., in order to report errors for erroneous programs.\n+///\n+/// Note: The optimization is only available during incr. comp.\n+pub fn ensure_query<Q, CTX>(tcx: CTX, key: Q::Key)\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext,\n+{\n+    if Q::EVAL_ALWAYS {\n+        let _ = get_query::<Q, _>(tcx, DUMMY_SP, key);\n+        return;\n+    }\n+\n+    // Ensuring an anonymous query makes no sense\n+    assert!(!Q::ANON);\n+\n+    let dep_node = Q::to_dep_node(tcx, &key);\n+\n+    match tcx.dep_graph().try_mark_green_and_read(tcx, &dep_node) {\n+        None => {\n+            // A None return from `try_mark_green_and_read` means that this is either\n+            // a new dep node or that the dep node has already been marked red.\n+            // Either way, we can't call `dep_graph.read()` as we don't have the\n+            // DepNodeIndex. We must invoke the query itself. The performance cost\n+            // this introduces should be negligible as we'll immediately hit the\n+            // in-memory cache, or another query down the line will.\n+            let _ = get_query::<Q, _>(tcx, DUMMY_SP, key);\n+        }\n+        Some((_, dep_node_index)) => {\n+            tcx.profiler().query_cache_hit(dep_node_index.into());\n+        }\n+    }\n+}\n+\n+pub fn force_query<Q, CTX>(tcx: CTX, key: Q::Key, span: Span, dep_node: DepNode<CTX::DepKind>)\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext,\n+{\n+    // We may be concurrently trying both execute and force a query.\n+    // Ensure that only one of them runs the query.\n+\n+    try_get_cached(\n+        tcx,\n+        Q::query_state(tcx),\n+        key,\n+        |_, _| {\n+            // Cache hit, do nothing\n+        },\n+        |key, lookup| {\n+            let job = match JobOwner::try_start::<Q>(tcx, span, &key, lookup) {\n+                TryGetJob::NotYetStarted(job) => job,\n+                TryGetJob::Cycle(_) => return,\n+                #[cfg(parallel_compiler)]\n+                TryGetJob::JobCompleted(_) => return,\n+            };\n+            force_query_with_job::<Q, _>(tcx, key, job, dep_node);\n+        },\n+    );\n+}"}]}