{"sha": "668864d9edd4f28d48005b57e5b177228cb974c5", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY2ODg2NGQ5ZWRkNGYyOGQ0ODAwNWI1N2U1YjE3NzIyOGNiOTc0YzU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-02-16T20:32:45Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-02-16T20:32:45Z"}, "message": "Auto merge of #38368 - arthurprs:hm-adapt, r=alexcrichton\n\nAdaptive hashmap implementation\n\nAll credits to @pczarn who wrote https://github.com/rust-lang/rfcs/pull/1796 and https://github.com/contain-rs/hashmap2/pull/5\n\n **Background**\n\nRust std lib hashmap puts a strong emphasis on security, we did some improvements in https://github.com/rust-lang/rust/pull/37470 but in some very specific cases and for non-default hashers it's still vulnerable (see #36481).\n\nThis is a simplified version of https://github.com/rust-lang/rfcs/pull/1796 proposal sans switching hashers on the fly and other things that require an RFC process and further decisions. I think this part has great potential by itself.\n\n**Proposal**\nThis PR adds code checking for extra long probe and shifts lengths (see code comments and https://github.com/rust-lang/rfcs/pull/1796 for details), when those are encountered the hashmap will grow (even if the capacity limit is not reached yet) _greatly_ attenuating the degenerate performance case.\n\nWe need a lower bound on the minimum occupancy that may trigger the early resize, otherwise in extreme cases it's possible to turn the CPU attack into a memory attack. The PR code puts that lower bound at half of the max occupancy (defined by ResizePolicy). This reduces the protection (it could potentially be exploited between 0-50% occupancy) but makes it completely safe.\n\n**Drawbacks**\n\n* May interact badly with poor hashers.  Maps using those may not use the desired capacity.\n* It adds 2-3 branches to the common insert path, luckily those are highly predictable and there's room to shave some in future patches.\n* May complicate exposure of ResizePolicy in the future as the constants are a function of the fill factor.\n\n**Example**\n\nExample code that exploit the exposure of iteration order and weak hasher.\n\n```\nconst MERGE: usize = 10_000usize;\n#[bench]\nfn merge_dos(b: &mut Bencher) {\n    let first_map: $hashmap<usize, usize, FnvBuilder> = (0..MERGE).map(|i| (i, i)).collect();\n    let second_map: $hashmap<usize, usize, FnvBuilder> = (MERGE..MERGE * 2).map(|i| (i, i)).collect();\n    b.iter(|| {\n        let mut merged = first_map.clone();\n        for (&k, &v) in &second_map {\n            merged.insert(k, v);\n        }\n        ::test::black_box(merged);\n    });\n}\n```\n\n_91 is stdlib and _ad is patched (the end capacity in both cases is the same)\n\n```\nrunning 2 tests\ntest _91::merge_dos              ... bench:  47,311,843 ns/iter (+/- 2,040,302)\ntest _ad::merge_dos              ... bench:     599,099 ns/iter (+/- 83,270)\n```", "tree": {"sha": "b8bae15b445bd6d969cbc6a74566e6de572f7fe4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b8bae15b445bd6d969cbc6a74566e6de572f7fe4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/668864d9edd4f28d48005b57e5b177228cb974c5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/668864d9edd4f28d48005b57e5b177228cb974c5", "html_url": "https://github.com/rust-lang/rust/commit/668864d9edd4f28d48005b57e5b177228cb974c5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/668864d9edd4f28d48005b57e5b177228cb974c5/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ccd96c945fb5d3a0841e0f9469d27f1fc8142edd", "url": "https://api.github.com/repos/rust-lang/rust/commits/ccd96c945fb5d3a0841e0f9469d27f1fc8142edd", "html_url": "https://github.com/rust-lang/rust/commit/ccd96c945fb5d3a0841e0f9469d27f1fc8142edd"}, {"sha": "57940d063c26ccabc7038f2fe9cf23faf9ee1ab6", "url": "https://api.github.com/repos/rust-lang/rust/commits/57940d063c26ccabc7038f2fe9cf23faf9ee1ab6", "html_url": "https://github.com/rust-lang/rust/commit/57940d063c26ccabc7038f2fe9cf23faf9ee1ab6"}], "stats": {"total": 117, "additions": 105, "deletions": 12}, "files": [{"sha": "079dbd667d65b583f06f3a1fc42c556cdc77528c", "filename": "src/libstd/collections/hash/map.rs", "status": "modified", "additions": 105, "deletions": 12, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/668864d9edd4f28d48005b57e5b177228cb974c5/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/668864d9edd4f28d48005b57e5b177228cb974c5/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs?ref=668864d9edd4f28d48005b57e5b177228cb974c5", "patch": "@@ -177,6 +177,51 @@ impl DefaultResizePolicy {\n // element.\n //\n // FIXME(Gankro, pczarn): review the proof and put it all in a separate README.md\n+//\n+// Adaptive early resizing\n+// ----------------------\n+// To protect against degenerate performance scenarios (including DOS attacks),\n+// the implementation includes an adaptive behavior that can resize the map\n+// early (before it's capacity is exceeded) when suspiciously long probe or\n+// foward shifts sequences are encounted.\n+//\n+// With this algorithm in place it would be possible to turn a CPU attack into\n+// a memory attack due to the agressive resizing. To prevent that the\n+// adaptive behavior only triggers when the map occupancy is half the maximum occupancy.\n+// This reduces the effectivenes of the algorithm but also makes it completelly safe.\n+//\n+// The previous safety measure that also prevents degenerate iteractions with\n+// really bad quality hash algorithms that can make normal inputs look like a\n+// DOS attack.\n+//\n+const DISPLACEMENT_THRESHOLD: usize = 128;\n+const FORWARD_SHIFT_THRESHOLD: usize = 512;\n+//\n+// The thresholds of 128 and 512 are chosen to minimize the chance of exceeding them.\n+// In particular, we want that chance to be less than 10^-8 with a load of 90%.\n+// For displacement, the smallest constant that fits our needs is 90,\n+// so we round that up to 128. For the number of forward-shifted buckets,\n+// we choose k=512. Keep in mind that the run length is a sum of the displacement and\n+// the number of forward-shifted buckets, so its threshold is 128+512=640.\n+// Even though the probability of having a run length of more than 640 buckets may be\n+// higher than the probability we want, it should be low enough.\n+//\n+// At a load factor of \u03b1, the odds of finding the target bucket after exactly n\n+// unsuccesful probes[1] are\n+//\n+// Pr_\u03b1{displacement = n} =\n+// (1 - \u03b1) / \u03b1 * \u2211_{k\u22651} e^(-k\u03b1) * (k\u03b1)^(k+n) / (k + n)! * (1 - k\u03b1 / (k + n + 1))\n+//\n+// We use this formula to find the probability of loading half of triggering the adaptive behavior\n+//\n+// Pr_0.909{displacement > 128} = 1.601 * 10^-11\n+//\n+// FIXME: Extend with math for shift threshold in [2]\n+//\n+// 1. Alfredo Viola (2005). Distributional analysis of Robin Hood linear probing\n+//    hashing with buckets.\n+// 2. http://www.cs.tau.ac.il/~zwick/Adv-Alg-2015/Linear-Probing.pdf\n+\n \n /// A hash map implementation which uses linear probing with Robin Hood bucket\n /// stealing.\n@@ -360,6 +405,8 @@ pub struct HashMap<K, V, S = RandomState> {\n     table: RawTable<K, V>,\n \n     resize_policy: DefaultResizePolicy,\n+\n+    long_probes: bool,\n }\n \n /// Search for a pre-hashed key.\n@@ -385,7 +432,7 @@ fn search_hashed<K, V, M, F>(table: M, hash: SafeHash, mut is_match: F) -> Inter\n                 // Found a hole!\n                 return InternalEntry::Vacant {\n                     hash: hash,\n-                    elem: NoElem(bucket),\n+                    elem: NoElem(bucket, displacement),\n                 };\n             }\n             Full(bucket) => bucket,\n@@ -447,15 +494,15 @@ fn robin_hood<'a, K: 'a, V: 'a>(bucket: FullBucketMut<'a, K, V>,\n                                 mut hash: SafeHash,\n                                 mut key: K,\n                                 mut val: V)\n-                                -> &'a mut V {\n-    let starting_index = bucket.index();\n+                                -> (usize, &'a mut V) {\n+    let start_index = bucket.index();\n     let size = bucket.table().size();\n     // Save the *starting point*.\n     let mut bucket = bucket.stash();\n     // There can be at most `size - dib` buckets to displace, because\n     // in the worst case, there are `size` elements and we already are\n     // `displacement` buckets away from the initial one.\n-    let idx_end = starting_index + size - bucket.displacement();\n+    let idx_end = start_index + size - bucket.displacement();\n \n     loop {\n         let (old_hash, old_key, old_val) = bucket.replace(hash, key, val);\n@@ -472,14 +519,15 @@ fn robin_hood<'a, K: 'a, V: 'a>(bucket: FullBucketMut<'a, K, V>,\n                 Empty(bucket) => {\n                     // Found a hole!\n                     let bucket = bucket.put(hash, key, val);\n+                    let end_index = bucket.index();\n                     // Now that it's stolen, just read the value's pointer\n                     // right out of the table! Go back to the *starting point*.\n                     //\n                     // This use of `into_table` is misleading. It turns the\n                     // bucket, which is a FullBucket on top of a\n                     // FullBucketMut, into just one FullBucketMut. The \"table\"\n                     // refers to the inner FullBucketMut in this context.\n-                    return bucket.into_table().into_mut_refs().1;\n+                    return (end_index - start_index, bucket.into_table().into_mut_refs().1);\n                 }\n                 Full(bucket) => bucket,\n             };\n@@ -617,6 +665,7 @@ impl<K, V, S> HashMap<K, V, S>\n             hash_builder: hash_builder,\n             resize_policy: DefaultResizePolicy::new(),\n             table: RawTable::new(0),\n+            long_probes: false,\n         }\n     }\n \n@@ -649,6 +698,7 @@ impl<K, V, S> HashMap<K, V, S>\n             hash_builder: hash_builder,\n             resize_policy: resize_policy,\n             table: RawTable::new(raw_cap),\n+            long_probes: false,\n         }\n     }\n \n@@ -706,6 +756,11 @@ impl<K, V, S> HashMap<K, V, S>\n             let min_cap = self.len().checked_add(additional).expect(\"reserve overflow\");\n             let raw_cap = self.resize_policy.raw_capacity(min_cap);\n             self.resize(raw_cap);\n+        } else if self.long_probes && remaining <= self.len() {\n+            // Probe sequence is too long and table is half full,\n+            // resize early to reduce probing length.\n+            let new_capacity = self.table.capacity() * 2;\n+            self.resize(new_capacity);\n         }\n     }\n \n@@ -718,10 +773,11 @@ impl<K, V, S> HashMap<K, V, S>\n         assert!(self.table.size() <= new_raw_cap);\n         assert!(new_raw_cap.is_power_of_two() || new_raw_cap == 0);\n \n+        self.long_probes = false;\n         let mut old_table = replace(&mut self.table, RawTable::new(new_raw_cap));\n         let old_size = old_table.size();\n \n-        if old_table.capacity() == 0 || old_table.size() == 0 {\n+        if old_table.size() == 0 {\n             return;\n         }\n \n@@ -798,7 +854,8 @@ impl<K, V, S> HashMap<K, V, S>\n     /// If the key already exists, the hashtable will be returned untouched\n     /// and a reference to the existing element will be returned.\n     fn insert_hashed_nocheck(&mut self, hash: SafeHash, k: K, v: V) -> Option<V> {\n-        let entry = search_hashed(&mut self.table, hash, |key| *key == k).into_entry(k);\n+        let entry = search_hashed(&mut self.table, hash, |key| *key == k)\n+            .into_entry(k, &mut self.long_probes);\n         match entry {\n             Some(Occupied(mut elem)) => Some(elem.insert(v)),\n             Some(Vacant(elem)) => {\n@@ -953,7 +1010,9 @@ impl<K, V, S> HashMap<K, V, S>\n     pub fn entry(&mut self, key: K) -> Entry<K, V> {\n         // Gotta resize now.\n         self.reserve(1);\n-        self.search_mut(&key).into_entry(key).expect(\"unreachable\")\n+        let hash = self.make_hash(&key);\n+        search_hashed(&mut self.table, hash, |q| q.eq(&key))\n+            .into_entry(key, &mut self.long_probes).expect(\"unreachable\")\n     }\n \n     /// Returns the number of elements in the map.\n@@ -1407,7 +1466,7 @@ impl<K, V, M> InternalEntry<K, V, M> {\n \n impl<'a, K, V> InternalEntry<K, V, &'a mut RawTable<K, V>> {\n     #[inline]\n-    fn into_entry(self, key: K) -> Option<Entry<'a, K, V>> {\n+    fn into_entry(self, key: K, long_probes: &'a mut bool) -> Option<Entry<'a, K, V>> {\n         match self {\n             InternalEntry::Occupied { elem } => {\n                 Some(Occupied(OccupiedEntry {\n@@ -1420,6 +1479,7 @@ impl<'a, K, V> InternalEntry<K, V, &'a mut RawTable<K, V>> {\n                     hash: hash,\n                     key: key,\n                     elem: elem,\n+                    long_probes: long_probes,\n                 }))\n             }\n             InternalEntry::TableIsEmpty => None,\n@@ -1492,6 +1552,7 @@ pub struct VacantEntry<'a, K: 'a, V: 'a> {\n     hash: SafeHash,\n     key: K,\n     elem: VacantEntryState<K, V, &'a mut RawTable<K, V>>,\n+    long_probes: &'a mut bool,\n }\n \n #[stable(feature= \"debug_hash_map\", since = \"1.12.0\")]\n@@ -1509,7 +1570,7 @@ enum VacantEntryState<K, V, M> {\n     /// and will kick the current one out on insertion.\n     NeqElem(FullBucket<K, V, M>, usize),\n     /// The index is genuinely vacant.\n-    NoElem(EmptyBucket<K, V, M>),\n+    NoElem(EmptyBucket<K, V, M>, usize),\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n@@ -2066,8 +2127,20 @@ impl<'a, K: 'a, V: 'a> VacantEntry<'a, K, V> {\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn insert(self, value: V) -> &'a mut V {\n         match self.elem {\n-            NeqElem(bucket, disp) => robin_hood(bucket, disp, self.hash, self.key, value),\n-            NoElem(bucket) => bucket.put(self.hash, self.key, value).into_mut_refs().1,\n+            NeqElem(bucket, disp) => {\n+                let (shift, v_ref) = robin_hood(bucket, disp, self.hash, self.key, value);\n+                if disp >= DISPLACEMENT_THRESHOLD || shift >= FORWARD_SHIFT_THRESHOLD {\n+                    *self.long_probes = true;\n+                }\n+                v_ref\n+            },\n+            NoElem(bucket, disp) => {\n+                if disp >= DISPLACEMENT_THRESHOLD {\n+                    *self.long_probes = true;\n+                }\n+                let bucket = bucket.put(self.hash, self.key, value);\n+                bucket.into_mut_refs().1\n+            },\n         }\n     }\n }\n@@ -3192,4 +3265,24 @@ mod test_map {\n         assert_eq!(map[&4], 40);\n         assert_eq!(map[&6], 60);\n     }\n+\n+    #[test]\n+    fn test_adaptive() {\n+        const TEST_LEN: usize = 5000;\n+        // by cloning we get maps with the same hasher seed\n+        let mut first = HashMap::new();\n+        let mut second = first.clone();\n+        first.extend((0..TEST_LEN).map(|i| (i, i)));\n+        second.extend((TEST_LEN..TEST_LEN * 2).map(|i| (i, i)));\n+\n+        for (&k, &v) in &second {\n+            let prev_cap = first.capacity();\n+            let expect_grow = first.len() == prev_cap;\n+            first.insert(k, v);\n+            if !expect_grow && first.capacity() != prev_cap {\n+                return;\n+            }\n+        }\n+        panic!(\"Adaptive early resize failed\");\n+    }\n }"}]}