{"sha": "f3ae5e56fbf35e7b47a071b28432f72b669f444a", "node_id": "C_kwDOAAsO6NoAKGYzYWU1ZTU2ZmJmMzVlN2I0N2EwNzFiMjg0MzJmNzJiNjY5ZjQ0NGE", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2022-10-10T13:45:24Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2022-10-10T13:45:24Z"}, "message": "Refactor completions expansion", "tree": {"sha": "330ca86279900bc76a29b0bdd27564b4f254ac8a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/330ca86279900bc76a29b0bdd27564b4f254ac8a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f3ae5e56fbf35e7b47a071b28432f72b669f444a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f3ae5e56fbf35e7b47a071b28432f72b669f444a", "html_url": "https://github.com/rust-lang/rust/commit/f3ae5e56fbf35e7b47a071b28432f72b669f444a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f3ae5e56fbf35e7b47a071b28432f72b669f444a/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "476d0438749e3a5b2669811f9429da79a6628e8a", "url": "https://api.github.com/repos/rust-lang/rust/commits/476d0438749e3a5b2669811f9429da79a6628e8a", "html_url": "https://github.com/rust-lang/rust/commit/476d0438749e3a5b2669811f9429da79a6628e8a"}], "stats": {"total": 1982, "additions": 1011, "deletions": 971}, "files": [{"sha": "5ac460fc6eb961f5f503a9ff59d1c73d83945347", "filename": "crates/ide-completion/src/context.rs", "status": "modified", "additions": 26, "deletions": 17, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/f3ae5e56fbf35e7b47a071b28432f72b669f444a/crates%2Fide-completion%2Fsrc%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f3ae5e56fbf35e7b47a071b28432f72b669f444a/crates%2Fide-completion%2Fsrc%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide-completion%2Fsrc%2Fcontext.rs?ref=f3ae5e56fbf35e7b47a071b28432f72b669f444a", "patch": "@@ -23,7 +23,10 @@ use syntax::{\n };\n use text_edit::Indel;\n \n-use crate::CompletionConfig;\n+use crate::{\n+    context::analysis::{expand_and_analyze, AnalysisResult},\n+    CompletionConfig,\n+};\n \n const COMPLETION_MARKER: &str = \"intellijRulezz\";\n \n@@ -561,15 +564,27 @@ impl<'a> CompletionContext<'a> {\n             let edit = Indel::insert(offset, COMPLETION_MARKER.to_string());\n             parse.reparse(&edit).tree()\n         };\n-        let fake_ident_token =\n-            file_with_fake_ident.syntax().token_at_offset(offset).right_biased()?;\n \n+        // always pick the token to the immediate left of the cursor, as that is what we are actually\n+        // completing on\n         let original_token = original_file.syntax().token_at_offset(offset).left_biased()?;\n-        let token = sema.descend_into_macros_single(original_token.clone());\n+\n+        let AnalysisResult {\n+            analysis,\n+            expected: (expected_type, expected_name),\n+            qualifier_ctx,\n+            token,\n+            offset,\n+        } = expand_and_analyze(\n+            &sema,\n+            original_file.syntax().clone(),\n+            file_with_fake_ident.syntax().clone(),\n+            offset,\n+            &original_token,\n+        )?;\n \n         // adjust for macro input, this still fails if there is no token written yet\n-        let scope_offset = if original_token == token { offset } else { token.text_range().end() };\n-        let scope = sema.scope_at_offset(&token.parent()?, scope_offset)?;\n+        let scope = sema.scope_at_offset(&token.parent()?, offset)?;\n \n         let krate = scope.krate();\n         let module = scope.module();\n@@ -583,7 +598,7 @@ impl<'a> CompletionContext<'a> {\n \n         let depth_from_crate_root = iter::successors(module.parent(db), |m| m.parent(db)).count();\n \n-        let mut ctx = CompletionContext {\n+        let ctx = CompletionContext {\n             sema,\n             scope,\n             db,\n@@ -593,19 +608,13 @@ impl<'a> CompletionContext<'a> {\n             token,\n             krate,\n             module,\n-            expected_name: None,\n-            expected_type: None,\n-            qualifier_ctx: Default::default(),\n+            expected_name,\n+            expected_type,\n+            qualifier_ctx,\n             locals,\n             depth_from_crate_root,\n         };\n-        let ident_ctx = ctx.expand_and_analyze(\n-            original_file.syntax().clone(),\n-            file_with_fake_ident.syntax().clone(),\n-            offset,\n-            fake_ident_token,\n-        )?;\n-        Some((ctx, ident_ctx))\n+        Some((ctx, analysis))\n     }\n }\n "}, {"sha": "04111ec7efaa68e4dad225e25a8a220861d6b490", "filename": "crates/ide-completion/src/context/analysis.rs", "status": "modified", "additions": 985, "deletions": 954, "changes": 1939, "blob_url": "https://github.com/rust-lang/rust/blob/f3ae5e56fbf35e7b47a071b28432f72b669f444a/crates%2Fide-completion%2Fsrc%2Fcontext%2Fanalysis.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f3ae5e56fbf35e7b47a071b28432f72b669f444a/crates%2Fide-completion%2Fsrc%2Fcontext%2Fanalysis.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide-completion%2Fsrc%2Fcontext%2Fanalysis.rs?ref=f3ae5e56fbf35e7b47a071b28432f72b669f444a", "patch": "@@ -11,1063 +11,1094 @@ use syntax::{\n };\n \n use crate::context::{\n-    AttrCtx, CompletionAnalysis, CompletionContext, DotAccess, DotAccessKind, ExprCtx,\n-    ItemListKind, LifetimeContext, LifetimeKind, NameContext, NameKind, NameRefContext,\n-    NameRefKind, ParamContext, ParamKind, PathCompletionCtx, PathKind, PatternContext,\n-    PatternRefutability, Qualified, QualifierCtx, TypeAscriptionTarget, TypeLocation,\n-    COMPLETION_MARKER,\n+    AttrCtx, CompletionAnalysis, DotAccess, DotAccessKind, ExprCtx, ItemListKind, LifetimeContext,\n+    LifetimeKind, NameContext, NameKind, NameRefContext, NameRefKind, ParamContext, ParamKind,\n+    PathCompletionCtx, PathKind, PatternContext, PatternRefutability, Qualified, QualifierCtx,\n+    TypeAscriptionTarget, TypeLocation, COMPLETION_MARKER,\n };\n \n-impl<'a> CompletionContext<'a> {\n-    /// Expand attributes and macro calls at the current cursor position for both the original file\n-    /// and fake file repeatedly. As soon as one of the two expansions fail we stop so the original\n-    /// and speculative states stay in sync.\n-    pub(super) fn expand_and_analyze(\n-        &mut self,\n-        mut original_file: SyntaxNode,\n-        mut speculative_file: SyntaxNode,\n-        mut offset: TextSize,\n-        mut fake_ident_token: SyntaxToken,\n-    ) -> Option<CompletionAnalysis> {\n-        let _p = profile::span(\"CompletionContext::expand_and_fill\");\n-        let mut derive_ctx = None;\n-\n-        'expansion: loop {\n-            let parent_item =\n-                |item: &ast::Item| item.syntax().ancestors().skip(1).find_map(ast::Item::cast);\n-            let ancestor_items = iter::successors(\n-                Option::zip(\n-                    find_node_at_offset::<ast::Item>(&original_file, offset),\n-                    find_node_at_offset::<ast::Item>(&speculative_file, offset),\n+struct ExpansionResult {\n+    original_file: SyntaxNode,\n+    speculative_file: SyntaxNode,\n+    offset: TextSize,\n+    fake_ident_token: SyntaxToken,\n+    derive_ctx: Option<(SyntaxNode, SyntaxNode, TextSize, ast::Attr)>,\n+}\n+\n+pub(super) struct AnalysisResult {\n+    pub(super) analysis: CompletionAnalysis,\n+    pub(super) expected: (Option<Type>, Option<ast::NameOrNameRef>),\n+    pub(super) qualifier_ctx: QualifierCtx,\n+    pub(super) token: SyntaxToken,\n+    pub(super) offset: TextSize,\n+}\n+\n+pub(super) fn expand_and_analyze(\n+    sema: &Semantics<'_, RootDatabase>,\n+    original_file: SyntaxNode,\n+    speculative_file: SyntaxNode,\n+    offset: TextSize,\n+    original_token: &SyntaxToken,\n+) -> Option<AnalysisResult> {\n+    // as we insert after the offset, right biased will *always* pick the identifier no matter\n+    // if there is an ident already typed or not\n+    let fake_ident_token = speculative_file.token_at_offset(offset).right_biased()?;\n+    // the relative offset between the cursor and the *identifier* token we are completing on\n+    let relative_offset = offset - fake_ident_token.text_range().start();\n+    // make the offset point to the start of the original token, as that is what the\n+    // intermediate offsets calculated in expansion always points to\n+    let offset = offset - relative_offset;\n+    let expansion = expand(sema, original_file, speculative_file, offset, fake_ident_token);\n+    // add the relative offset back, so that left_biased finds the proper token\n+    let offset = expansion.offset + relative_offset;\n+    let token = expansion.original_file.token_at_offset(offset).left_biased()?;\n+\n+    analyze(sema, expansion, original_token, &token).map(|(analysis, expected, qualifier_ctx)| {\n+        AnalysisResult { analysis, expected, qualifier_ctx, token, offset }\n+    })\n+}\n+\n+/// Expand attributes and macro calls at the current cursor position for both the original file\n+/// and fake file repeatedly. As soon as one of the two expansions fail we stop so the original\n+/// and speculative states stay in sync.\n+fn expand(\n+    sema: &Semantics<'_, RootDatabase>,\n+    mut original_file: SyntaxNode,\n+    mut speculative_file: SyntaxNode,\n+    mut offset: TextSize,\n+    mut fake_ident_token: SyntaxToken,\n+) -> ExpansionResult {\n+    let _p = profile::span(\"CompletionContext::expand\");\n+    let mut derive_ctx = None;\n+\n+    'expansion: loop {\n+        let parent_item =\n+            |item: &ast::Item| item.syntax().ancestors().skip(1).find_map(ast::Item::cast);\n+        let ancestor_items = iter::successors(\n+            Option::zip(\n+                find_node_at_offset::<ast::Item>(&original_file, offset),\n+                find_node_at_offset::<ast::Item>(&speculative_file, offset),\n+            ),\n+            |(a, b)| parent_item(a).zip(parent_item(b)),\n+        );\n+\n+        // first try to expand attributes as these are always the outermost macro calls\n+        'ancestors: for (actual_item, item_with_fake_ident) in ancestor_items {\n+            match (\n+                sema.expand_attr_macro(&actual_item),\n+                sema.speculative_expand_attr_macro(\n+                    &actual_item,\n+                    &item_with_fake_ident,\n+                    fake_ident_token.clone(),\n                 ),\n-                |(a, b)| parent_item(a).zip(parent_item(b)),\n-            );\n-\n-            // first try to expand attributes as these are always the outermost macro calls\n-            'ancestors: for (actual_item, item_with_fake_ident) in ancestor_items {\n-                match (\n-                    self.sema.expand_attr_macro(&actual_item),\n-                    self.sema.speculative_expand_attr_macro(\n-                        &actual_item,\n-                        &item_with_fake_ident,\n-                        fake_ident_token.clone(),\n-                    ),\n-                ) {\n-                    // maybe parent items have attributes, so continue walking the ancestors\n-                    (None, None) => continue 'ancestors,\n-                    // successful expansions\n-                    (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n-                        let new_offset = fake_mapped_token.text_range().start();\n-                        if new_offset > actual_expansion.text_range().end() {\n-                            // offset outside of bounds from the original expansion,\n-                            // stop here to prevent problems from happening\n-                            break 'expansion;\n-                        }\n-                        original_file = actual_expansion;\n-                        speculative_file = fake_expansion;\n-                        fake_ident_token = fake_mapped_token;\n-                        offset = new_offset;\n-                        continue 'expansion;\n+            ) {\n+                // maybe parent items have attributes, so continue walking the ancestors\n+                (None, None) => continue 'ancestors,\n+                // successful expansions\n+                (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n+                    let new_offset = fake_mapped_token.text_range().start();\n+                    if new_offset > actual_expansion.text_range().end() {\n+                        // offset outside of bounds from the original expansion,\n+                        // stop here to prevent problems from happening\n+                        break 'expansion;\n                     }\n-                    // exactly one expansion failed, inconsistent state so stop expanding completely\n-                    _ => break 'expansion,\n+                    original_file = actual_expansion;\n+                    speculative_file = fake_expansion;\n+                    fake_ident_token = fake_mapped_token;\n+                    offset = new_offset;\n+                    continue 'expansion;\n                 }\n+                // exactly one expansion failed, inconsistent state so stop expanding completely\n+                _ => break 'expansion,\n             }\n+        }\n \n-            // No attributes have been expanded, so look for macro_call! token trees or derive token trees\n-            let orig_tt = match find_node_at_offset::<ast::TokenTree>(&original_file, offset) {\n-                Some(it) => it,\n-                None => break 'expansion,\n-            };\n-            let spec_tt = match find_node_at_offset::<ast::TokenTree>(&speculative_file, offset) {\n-                Some(it) => it,\n-                None => break 'expansion,\n-            };\n+        // No attributes have been expanded, so look for macro_call! token trees or derive token trees\n+        let orig_tt = match find_node_at_offset::<ast::TokenTree>(&original_file, offset) {\n+            Some(it) => it,\n+            None => break 'expansion,\n+        };\n+        let spec_tt = match find_node_at_offset::<ast::TokenTree>(&speculative_file, offset) {\n+            Some(it) => it,\n+            None => break 'expansion,\n+        };\n \n-            // Expand pseudo-derive expansion\n-            if let (Some(orig_attr), Some(spec_attr)) = (\n-                orig_tt.syntax().parent().and_then(ast::Meta::cast).and_then(|it| it.parent_attr()),\n-                spec_tt.syntax().parent().and_then(ast::Meta::cast).and_then(|it| it.parent_attr()),\n+        // Expand pseudo-derive expansion\n+        if let (Some(orig_attr), Some(spec_attr)) = (\n+            orig_tt.syntax().parent().and_then(ast::Meta::cast).and_then(|it| it.parent_attr()),\n+            spec_tt.syntax().parent().and_then(ast::Meta::cast).and_then(|it| it.parent_attr()),\n+        ) {\n+            if let (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) = (\n+                sema.expand_derive_as_pseudo_attr_macro(&orig_attr),\n+                sema.speculative_expand_derive_as_pseudo_attr_macro(\n+                    &orig_attr,\n+                    &spec_attr,\n+                    fake_ident_token.clone(),\n+                ),\n             ) {\n-                if let (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) = (\n-                    self.sema.expand_derive_as_pseudo_attr_macro(&orig_attr),\n-                    self.sema.speculative_expand_derive_as_pseudo_attr_macro(\n-                        &orig_attr,\n-                        &spec_attr,\n-                        fake_ident_token.clone(),\n-                    ),\n-                ) {\n-                    derive_ctx = Some((\n-                        actual_expansion,\n-                        fake_expansion,\n-                        fake_mapped_token.text_range().start(),\n-                        orig_attr,\n-                    ));\n-                }\n-                // at this point we won't have any more successful expansions, so stop\n+                derive_ctx = Some((\n+                    actual_expansion,\n+                    fake_expansion,\n+                    fake_mapped_token.text_range().start(),\n+                    orig_attr,\n+                ));\n+            }\n+            // at this point we won't have any more successful expansions, so stop\n+            break 'expansion;\n+        }\n+\n+        // Expand fn-like macro calls\n+        if let (Some(actual_macro_call), Some(macro_call_with_fake_ident)) = (\n+            orig_tt.syntax().ancestors().find_map(ast::MacroCall::cast),\n+            spec_tt.syntax().ancestors().find_map(ast::MacroCall::cast),\n+        ) {\n+            let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n+            let mac_call_path1 =\n+                macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n+\n+            // inconsistent state, stop expanding\n+            if mac_call_path0 != mac_call_path1 {\n                 break 'expansion;\n             }\n+            let speculative_args = match macro_call_with_fake_ident.token_tree() {\n+                Some(tt) => tt,\n+                None => break 'expansion,\n+            };\n \n-            // Expand fn-like macro calls\n-            if let (Some(actual_macro_call), Some(macro_call_with_fake_ident)) = (\n-                orig_tt.syntax().ancestors().find_map(ast::MacroCall::cast),\n-                spec_tt.syntax().ancestors().find_map(ast::MacroCall::cast),\n+            match (\n+                sema.expand(&actual_macro_call),\n+                sema.speculative_expand(\n+                    &actual_macro_call,\n+                    &speculative_args,\n+                    fake_ident_token.clone(),\n+                ),\n             ) {\n-                let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n-                let mac_call_path1 =\n-                    macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n-\n-                // inconsistent state, stop expanding\n-                if mac_call_path0 != mac_call_path1 {\n-                    break 'expansion;\n-                }\n-                let speculative_args = match macro_call_with_fake_ident.token_tree() {\n-                    Some(tt) => tt,\n-                    None => break 'expansion,\n-                };\n-\n-                match (\n-                    self.sema.expand(&actual_macro_call),\n-                    self.sema.speculative_expand(\n-                        &actual_macro_call,\n-                        &speculative_args,\n-                        fake_ident_token.clone(),\n-                    ),\n-                ) {\n-                    // successful expansions\n-                    (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n-                        let new_offset = fake_mapped_token.text_range().start();\n-                        if new_offset > actual_expansion.text_range().end() {\n-                            // offset outside of bounds from the original expansion,\n-                            // stop here to prevent problems from happening\n-                            break 'expansion;\n-                        }\n-                        original_file = actual_expansion;\n-                        speculative_file = fake_expansion;\n-                        fake_ident_token = fake_mapped_token;\n-                        offset = new_offset;\n-                        continue 'expansion;\n+                // successful expansions\n+                (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n+                    let new_offset = fake_mapped_token.text_range().start();\n+                    if new_offset > actual_expansion.text_range().end() {\n+                        // offset outside of bounds from the original expansion,\n+                        // stop here to prevent problems from happening\n+                        break 'expansion;\n                     }\n-                    // at least on expansion failed, we won't have anything to expand from this point\n-                    // onwards so break out\n-                    _ => break 'expansion,\n+                    original_file = actual_expansion;\n+                    speculative_file = fake_expansion;\n+                    fake_ident_token = fake_mapped_token;\n+                    offset = new_offset;\n+                    continue 'expansion;\n                 }\n+                // at least on expansion failed, we won't have anything to expand from this point\n+                // onwards so break out\n+                _ => break 'expansion,\n             }\n-\n-            // none of our states have changed so stop the loop\n-            break 'expansion;\n         }\n \n-        self.analyze(&original_file, speculative_file, offset, derive_ctx)\n+        // none of our states have changed so stop the loop\n+        break 'expansion;\n     }\n+    ExpansionResult { original_file, speculative_file, offset, fake_ident_token, derive_ctx }\n+}\n \n-    /// Calculate the expected type and name of the cursor position.\n-    fn expected_type_and_name(\n-        &self,\n-        name_like: &ast::NameLike,\n-    ) -> (Option<Type>, Option<NameOrNameRef>) {\n-        let mut node = match self.token.parent() {\n-            Some(it) => it,\n-            None => return (None, None),\n-        };\n+/// Fill the completion context, this is what does semantic reasoning about the surrounding context\n+/// of the completion location.\n+fn analyze(\n+    sema: &Semantics<'_, RootDatabase>,\n+    expansion_result: ExpansionResult,\n+    original_token: &SyntaxToken,\n+    self_token: &SyntaxToken,\n+) -> Option<(CompletionAnalysis, (Option<Type>, Option<ast::NameOrNameRef>), QualifierCtx)> {\n+    let _p = profile::span(\"CompletionContext::analyze\");\n+    let ExpansionResult { original_file, speculative_file, offset, fake_ident_token, derive_ctx } =\n+        expansion_result;\n+    let syntax_element = NodeOrToken::Token(fake_ident_token);\n+    if is_in_token_of_for_loop(syntax_element.clone()) {\n+        // for pat $0\n+        // there is nothing to complete here except `in` keyword\n+        // don't bother populating the context\n+        // FIXME: the completion calculations should end up good enough\n+        // such that this special case becomes unnecessary\n+        return None;\n+    }\n \n-        let strip_refs = |mut ty: Type| match name_like {\n-            ast::NameLike::NameRef(n) => {\n-                let p = match n.syntax().parent() {\n-                    Some(it) => it,\n-                    None => return ty,\n-                };\n-                let top_syn = match_ast! {\n-                    match p {\n-                        ast::FieldExpr(e) => e\n-                            .syntax()\n-                            .ancestors()\n-                            .map_while(ast::FieldExpr::cast)\n-                            .last()\n-                            .map(|it| it.syntax().clone()),\n-                        ast::PathSegment(e) => e\n-                            .syntax()\n-                            .ancestors()\n-                            .skip(1)\n-                            .take_while(|it| ast::Path::can_cast(it.kind()) || ast::PathExpr::can_cast(it.kind()))\n-                            .find_map(ast::PathExpr::cast)\n-                            .map(|it| it.syntax().clone()),\n-                        _ => None\n-                    }\n+    // Overwrite the path kind for derives\n+    if let Some((original_file, file_with_fake_ident, offset, origin_attr)) = derive_ctx {\n+        if let Some(ast::NameLike::NameRef(name_ref)) =\n+            find_node_at_offset(&file_with_fake_ident, offset)\n+        {\n+            let parent = name_ref.syntax().parent()?;\n+            let (mut nameref_ctx, _) = classify_name_ref(&sema, &original_file, name_ref, parent)?;\n+            if let NameRefKind::Path(path_ctx) = &mut nameref_ctx.kind {\n+                path_ctx.kind = PathKind::Derive {\n+                    existing_derives: sema\n+                        .resolve_derive_macro(&origin_attr)\n+                        .into_iter()\n+                        .flatten()\n+                        .flatten()\n+                        .collect(),\n                 };\n-                let top_syn = match top_syn {\n-                    Some(it) => it,\n-                    None => return ty,\n-                };\n-                for _ in top_syn.ancestors().skip(1).map_while(ast::RefExpr::cast) {\n-                    cov_mark::hit!(expected_type_fn_param_ref);\n-                    ty = ty.strip_reference();\n-                }\n-                ty\n             }\n-            _ => ty,\n-        };\n+            return Some((\n+                CompletionAnalysis::NameRef(nameref_ctx),\n+                (None, None),\n+                QualifierCtx::default(),\n+            ));\n+        }\n+        return None;\n+    }\n \n-        loop {\n-            break match_ast! {\n-                match node {\n-                    ast::LetStmt(it) => {\n-                        cov_mark::hit!(expected_type_let_with_leading_char);\n-                        cov_mark::hit!(expected_type_let_without_leading_char);\n-                        let ty = it.pat()\n-                            .and_then(|pat| self.sema.type_of_pat(&pat))\n-                            .or_else(|| it.initializer().and_then(|it| self.sema.type_of_expr(&it)))\n-                            .map(TypeInfo::original);\n-                        let name = match it.pat() {\n-                            Some(ast::Pat::IdentPat(ident)) => ident.name().map(NameOrNameRef::Name),\n-                            Some(_) | None => None,\n-                        };\n-\n-                        (ty, name)\n-                    },\n-                    ast::LetExpr(it) => {\n-                        cov_mark::hit!(expected_type_if_let_without_leading_char);\n-                        let ty = it.pat()\n-                            .and_then(|pat| self.sema.type_of_pat(&pat))\n-                            .or_else(|| it.expr().and_then(|it| self.sema.type_of_expr(&it)))\n-                            .map(TypeInfo::original);\n-                        (ty, None)\n-                    },\n-                    ast::ArgList(_) => {\n-                        cov_mark::hit!(expected_type_fn_param);\n-                        ActiveParameter::at_token(\n-                            &self.sema,\n-                            self.token.clone(),\n-                        ).map(|ap| {\n-                            let name = ap.ident().map(NameOrNameRef::Name);\n-\n-                            let ty = strip_refs(ap.ty);\n-                            (Some(ty), name)\n-                        })\n-                        .unwrap_or((None, None))\n-                    },\n-                    ast::RecordExprFieldList(it) => {\n-                        // wouldn't try {} be nice...\n-                        (|| {\n-                            if self.token.kind() == T![..]\n-                                || self.token.prev_token().map(|t| t.kind()) == Some(T![..])\n-                            {\n-                                cov_mark::hit!(expected_type_struct_func_update);\n-                                let record_expr = it.syntax().parent().and_then(ast::RecordExpr::cast)?;\n-                                let ty = self.sema.type_of_expr(&record_expr.into())?;\n-                                Some((\n-                                    Some(ty.original),\n-                                    None\n-                                ))\n-                            } else {\n-                                cov_mark::hit!(expected_type_struct_field_without_leading_char);\n-                                let expr_field = self.token.prev_sibling_or_token()?\n-                                    .into_node()\n-                                    .and_then(ast::RecordExprField::cast)?;\n-                                let (_, _, ty) = self.sema.resolve_record_field(&expr_field)?;\n-                                Some((\n-                                    Some(ty),\n-                                    expr_field.field_name().map(NameOrNameRef::NameRef),\n-                                ))\n-                            }\n-                        })().unwrap_or((None, None))\n-                    },\n-                    ast::RecordExprField(it) => {\n-                        if let Some(expr) = it.expr() {\n-                            cov_mark::hit!(expected_type_struct_field_with_leading_char);\n-                            (\n-                                self.sema.type_of_expr(&expr).map(TypeInfo::original),\n-                                it.field_name().map(NameOrNameRef::NameRef),\n-                            )\n-                        } else {\n-                            cov_mark::hit!(expected_type_struct_field_followed_by_comma);\n-                            let ty = self.sema.resolve_record_field(&it)\n-                                .map(|(_, _, ty)| ty);\n-                            (\n-                                ty,\n-                                it.field_name().map(NameOrNameRef::NameRef),\n-                            )\n-                        }\n-                    },\n-                    // match foo { $0 }\n-                    // match foo { ..., pat => $0 }\n-                    ast::MatchExpr(it) => {\n-                        let on_arrow = previous_non_trivia_token(self.token.clone()).map_or(false, |it| T![=>] == it.kind());\n-\n-                        let ty = if on_arrow {\n-                            // match foo { ..., pat => $0 }\n-                            cov_mark::hit!(expected_type_match_arm_body_without_leading_char);\n-                            cov_mark::hit!(expected_type_match_arm_body_with_leading_char);\n-                            self.sema.type_of_expr(&it.into())\n-                        } else {\n-                            // match foo { $0 }\n-                            cov_mark::hit!(expected_type_match_arm_without_leading_char);\n-                            it.expr().and_then(|e| self.sema.type_of_expr(&e))\n-                        }.map(TypeInfo::original);\n-                        (ty, None)\n-                    },\n-                    ast::IfExpr(it) => {\n-                        let ty = it.condition()\n-                            .and_then(|e| self.sema.type_of_expr(&e))\n-                            .map(TypeInfo::original);\n-                        (ty, None)\n-                    },\n-                    ast::IdentPat(it) => {\n-                        cov_mark::hit!(expected_type_if_let_with_leading_char);\n-                        cov_mark::hit!(expected_type_match_arm_with_leading_char);\n-                        let ty = self.sema.type_of_pat(&ast::Pat::from(it)).map(TypeInfo::original);\n-                        (ty, None)\n-                    },\n-                    ast::Fn(it) => {\n-                        cov_mark::hit!(expected_type_fn_ret_with_leading_char);\n-                        cov_mark::hit!(expected_type_fn_ret_without_leading_char);\n-                        let def = self.sema.to_def(&it);\n-                        (def.map(|def| def.ret_type(self.db)), None)\n-                    },\n-                    ast::ClosureExpr(it) => {\n-                        let ty = self.sema.type_of_expr(&it.into());\n-                        ty.and_then(|ty| ty.original.as_callable(self.db))\n-                            .map(|c| (Some(c.return_type()), None))\n-                            .unwrap_or((None, None))\n-                    },\n-                    ast::ParamList(_) => (None, None),\n-                    ast::Stmt(_) => (None, None),\n-                    ast::Item(_) => (None, None),\n-                    _ => {\n-                        match node.parent() {\n-                            Some(n) => {\n-                                node = n;\n-                                continue;\n-                            },\n-                            None => (None, None),\n-                        }\n-                    },\n+    let name_like = match find_node_at_offset(&speculative_file, offset) {\n+        Some(it) => it,\n+        None => {\n+            let analysis = if let Some(original) = ast::String::cast(original_token.clone()) {\n+                CompletionAnalysis::String {\n+                    original,\n+                    expanded: ast::String::cast(self_token.clone()),\n+                }\n+            } else {\n+                // Fix up trailing whitespace problem\n+                // #[attr(foo = $0\n+                let token = syntax::algo::skip_trivia_token(self_token.clone(), Direction::Prev)?;\n+                let p = token.parent()?;\n+                if p.kind() == SyntaxKind::TOKEN_TREE\n+                    && p.ancestors().any(|it| it.kind() == SyntaxKind::META)\n+                {\n+                    let colon_prefix = previous_non_trivia_token(self_token.clone())\n+                        .map_or(false, |it| T![:] == it.kind());\n+                    CompletionAnalysis::UnexpandedAttrTT {\n+                        fake_attribute_under_caret: syntax_element\n+                            .ancestors()\n+                            .find_map(ast::Attr::cast),\n+                        colon_prefix,\n+                    }\n+                } else {\n+                    return None;\n                 }\n             };\n+            return Some((analysis, (None, None), QualifierCtx::default()));\n         }\n-    }\n-\n-    /// Fill the completion context, this is what does semantic reasoning about the surrounding context\n-    /// of the completion location.\n-    fn analyze(\n-        &mut self,\n-        original_file: &SyntaxNode,\n-        file_with_fake_ident: SyntaxNode,\n-        offset: TextSize,\n-        derive_ctx: Option<(SyntaxNode, SyntaxNode, TextSize, ast::Attr)>,\n-    ) -> Option<CompletionAnalysis> {\n-        let fake_ident_token = file_with_fake_ident.token_at_offset(offset).right_biased()?;\n-        let syntax_element = NodeOrToken::Token(fake_ident_token);\n-        if is_in_token_of_for_loop(syntax_element.clone()) {\n-            // for pat $0\n-            // there is nothing to complete here except `in` keyword\n-            // don't bother populating the context\n-            // FIXME: the completion calculations should end up good enough\n-            // such that this special case becomes unnecessary\n-            return None;\n+    };\n+    let expected = expected_type_and_name(sema, &self_token, &name_like);\n+    let mut qual_ctx = QualifierCtx::default();\n+    let analysis = match name_like {\n+        ast::NameLike::Lifetime(lifetime) => {\n+            CompletionAnalysis::Lifetime(classify_lifetime(sema, &original_file, lifetime)?)\n+        }\n+        ast::NameLike::NameRef(name_ref) => {\n+            let parent = name_ref.syntax().parent()?;\n+            let (nameref_ctx, qualifier_ctx) =\n+                classify_name_ref(sema, &original_file, name_ref, parent.clone())?;\n+            qual_ctx = qualifier_ctx;\n+            CompletionAnalysis::NameRef(nameref_ctx)\n+        }\n+        ast::NameLike::Name(name) => {\n+            let name_ctx = classify_name(sema, &original_file, name)?;\n+            CompletionAnalysis::Name(name_ctx)\n         }\n+    };\n+    Some((analysis, expected, qual_ctx))\n+}\n \n-        // Overwrite the path kind for derives\n-        if let Some((original_file, file_with_fake_ident, offset, origin_attr)) = derive_ctx {\n-            if let Some(ast::NameLike::NameRef(name_ref)) =\n-                find_node_at_offset(&file_with_fake_ident, offset)\n-            {\n-                let parent = name_ref.syntax().parent()?;\n-                let (mut nameref_ctx, _) =\n-                    Self::classify_name_ref(&self.sema, &original_file, name_ref, parent)?;\n-                if let NameRefKind::Path(path_ctx) = &mut nameref_ctx.kind {\n-                    path_ctx.kind = PathKind::Derive {\n-                        existing_derives: self\n-                            .sema\n-                            .resolve_derive_macro(&origin_attr)\n-                            .into_iter()\n-                            .flatten()\n-                            .flatten()\n-                            .collect(),\n-                    };\n+/// Calculate the expected type and name of the cursor position.\n+fn expected_type_and_name(\n+    sema: &Semantics<'_, RootDatabase>,\n+    token: &SyntaxToken,\n+    name_like: &ast::NameLike,\n+) -> (Option<Type>, Option<NameOrNameRef>) {\n+    let mut node = match token.parent() {\n+        Some(it) => it,\n+        None => return (None, None),\n+    };\n+\n+    let strip_refs = |mut ty: Type| match name_like {\n+        ast::NameLike::NameRef(n) => {\n+            let p = match n.syntax().parent() {\n+                Some(it) => it,\n+                None => return ty,\n+            };\n+            let top_syn = match_ast! {\n+                match p {\n+                    ast::FieldExpr(e) => e\n+                        .syntax()\n+                        .ancestors()\n+                        .map_while(ast::FieldExpr::cast)\n+                        .last()\n+                        .map(|it| it.syntax().clone()),\n+                    ast::PathSegment(e) => e\n+                        .syntax()\n+                        .ancestors()\n+                        .skip(1)\n+                        .take_while(|it| ast::Path::can_cast(it.kind()) || ast::PathExpr::can_cast(it.kind()))\n+                        .find_map(ast::PathExpr::cast)\n+                        .map(|it| it.syntax().clone()),\n+                    _ => None\n                 }\n-                return Some(CompletionAnalysis::NameRef(nameref_ctx));\n+            };\n+            let top_syn = match top_syn {\n+                Some(it) => it,\n+                None => return ty,\n+            };\n+            for _ in top_syn.ancestors().skip(1).map_while(ast::RefExpr::cast) {\n+                cov_mark::hit!(expected_type_fn_param_ref);\n+                ty = ty.strip_reference();\n             }\n-            return None;\n+            ty\n         }\n+        _ => ty,\n+    };\n \n-        let name_like = match find_node_at_offset(&file_with_fake_ident, offset) {\n-            Some(it) => it,\n-            None => {\n-                let analysis =\n-                    if let Some(original) = ast::String::cast(self.original_token.clone()) {\n-                        CompletionAnalysis::String {\n-                            original,\n-                            expanded: ast::String::cast(self.token.clone()),\n-                        }\n-                    } else {\n-                        // Fix up trailing whitespace problem\n-                        // #[attr(foo = $0\n-                        let token =\n-                            syntax::algo::skip_trivia_token(self.token.clone(), Direction::Prev)?;\n-                        let p = token.parent()?;\n-                        if p.kind() == SyntaxKind::TOKEN_TREE\n-                            && p.ancestors().any(|it| it.kind() == SyntaxKind::META)\n+    loop {\n+        break match_ast! {\n+            match node {\n+                ast::LetStmt(it) => {\n+                    cov_mark::hit!(expected_type_let_with_leading_char);\n+                    cov_mark::hit!(expected_type_let_without_leading_char);\n+                    let ty = it.pat()\n+                        .and_then(|pat| sema.type_of_pat(&pat))\n+                        .or_else(|| it.initializer().and_then(|it| sema.type_of_expr(&it)))\n+                        .map(TypeInfo::original);\n+                    let name = match it.pat() {\n+                        Some(ast::Pat::IdentPat(ident)) => ident.name().map(NameOrNameRef::Name),\n+                        Some(_) | None => None,\n+                    };\n+\n+                    (ty, name)\n+                },\n+                ast::LetExpr(it) => {\n+                    cov_mark::hit!(expected_type_if_let_without_leading_char);\n+                    let ty = it.pat()\n+                        .and_then(|pat| sema.type_of_pat(&pat))\n+                        .or_else(|| it.expr().and_then(|it| sema.type_of_expr(&it)))\n+                        .map(TypeInfo::original);\n+                    (ty, None)\n+                },\n+                ast::ArgList(_) => {\n+                    cov_mark::hit!(expected_type_fn_param);\n+                    ActiveParameter::at_token(\n+                        &sema,\n+                       token.clone(),\n+                    ).map(|ap| {\n+                        let name = ap.ident().map(NameOrNameRef::Name);\n+\n+                        let ty = strip_refs(ap.ty);\n+                        (Some(ty), name)\n+                    })\n+                    .unwrap_or((None, None))\n+                },\n+                ast::RecordExprFieldList(it) => {\n+                    // wouldn't try {} be nice...\n+                    (|| {\n+                        if token.kind() == T![..]\n+                            ||token.prev_token().map(|t| t.kind()) == Some(T![..])\n                         {\n-                            let colon_prefix = previous_non_trivia_token(self.token.clone())\n-                                .map_or(false, |it| T![:] == it.kind());\n-                            CompletionAnalysis::UnexpandedAttrTT {\n-                                fake_attribute_under_caret: syntax_element\n-                                    .ancestors()\n-                                    .find_map(ast::Attr::cast),\n-                                colon_prefix,\n-                            }\n+                            cov_mark::hit!(expected_type_struct_func_update);\n+                            let record_expr = it.syntax().parent().and_then(ast::RecordExpr::cast)?;\n+                            let ty = sema.type_of_expr(&record_expr.into())?;\n+                            Some((\n+                                Some(ty.original),\n+                                None\n+                            ))\n                         } else {\n-                            return None;\n+                            cov_mark::hit!(expected_type_struct_field_without_leading_char);\n+                            let expr_field = token.prev_sibling_or_token()?\n+                                .into_node()\n+                                .and_then(ast::RecordExprField::cast)?;\n+                            let (_, _, ty) = sema.resolve_record_field(&expr_field)?;\n+                            Some((\n+                                Some(ty),\n+                                expr_field.field_name().map(NameOrNameRef::NameRef),\n+                            ))\n                         }\n-                    };\n-                return Some(analysis);\n+                    })().unwrap_or((None, None))\n+                },\n+                ast::RecordExprField(it) => {\n+                    if let Some(expr) = it.expr() {\n+                        cov_mark::hit!(expected_type_struct_field_with_leading_char);\n+                        (\n+                            sema.type_of_expr(&expr).map(TypeInfo::original),\n+                            it.field_name().map(NameOrNameRef::NameRef),\n+                        )\n+                    } else {\n+                        cov_mark::hit!(expected_type_struct_field_followed_by_comma);\n+                        let ty = sema.resolve_record_field(&it)\n+                            .map(|(_, _, ty)| ty);\n+                        (\n+                            ty,\n+                            it.field_name().map(NameOrNameRef::NameRef),\n+                        )\n+                    }\n+                },\n+                // match foo { $0 }\n+                // match foo { ..., pat => $0 }\n+                ast::MatchExpr(it) => {\n+                    let on_arrow = previous_non_trivia_token(token.clone()).map_or(false, |it| T![=>] == it.kind());\n+\n+                    let ty = if on_arrow {\n+                        // match foo { ..., pat => $0 }\n+                        cov_mark::hit!(expected_type_match_arm_body_without_leading_char);\n+                        cov_mark::hit!(expected_type_match_arm_body_with_leading_char);\n+                        sema.type_of_expr(&it.into())\n+                    } else {\n+                        // match foo { $0 }\n+                        cov_mark::hit!(expected_type_match_arm_without_leading_char);\n+                        it.expr().and_then(|e| sema.type_of_expr(&e))\n+                    }.map(TypeInfo::original);\n+                    (ty, None)\n+                },\n+                ast::IfExpr(it) => {\n+                    let ty = it.condition()\n+                        .and_then(|e| sema.type_of_expr(&e))\n+                        .map(TypeInfo::original);\n+                    (ty, None)\n+                },\n+                ast::IdentPat(it) => {\n+                    cov_mark::hit!(expected_type_if_let_with_leading_char);\n+                    cov_mark::hit!(expected_type_match_arm_with_leading_char);\n+                    let ty = sema.type_of_pat(&ast::Pat::from(it)).map(TypeInfo::original);\n+                    (ty, None)\n+                },\n+                ast::Fn(it) => {\n+                    cov_mark::hit!(expected_type_fn_ret_with_leading_char);\n+                    cov_mark::hit!(expected_type_fn_ret_without_leading_char);\n+                    let def = sema.to_def(&it);\n+                    (def.map(|def| def.ret_type(sema.db)), None)\n+                },\n+                ast::ClosureExpr(it) => {\n+                    let ty = sema.type_of_expr(&it.into());\n+                    ty.and_then(|ty| ty.original.as_callable(sema.db))\n+                        .map(|c| (Some(c.return_type()), None))\n+                        .unwrap_or((None, None))\n+                },\n+                ast::ParamList(_) => (None, None),\n+                ast::Stmt(_) => (None, None),\n+                ast::Item(_) => (None, None),\n+                _ => {\n+                    match node.parent() {\n+                        Some(n) => {\n+                            node = n;\n+                            continue;\n+                        },\n+                        None => (None, None),\n+                    }\n+                },\n             }\n         };\n-        (self.expected_type, self.expected_name) = self.expected_type_and_name(&name_like);\n-        let analysis = match name_like {\n-            ast::NameLike::Lifetime(lifetime) => CompletionAnalysis::Lifetime(\n-                Self::classify_lifetime(&self.sema, original_file, lifetime)?,\n-            ),\n-            ast::NameLike::NameRef(name_ref) => {\n-                let parent = name_ref.syntax().parent()?;\n-                let (nameref_ctx, qualifier_ctx) =\n-                    Self::classify_name_ref(&self.sema, &original_file, name_ref, parent.clone())?;\n+    }\n+}\n \n-                self.qualifier_ctx = qualifier_ctx;\n-                CompletionAnalysis::NameRef(nameref_ctx)\n-            }\n-            ast::NameLike::Name(name) => {\n-                let name_ctx = Self::classify_name(&self.sema, original_file, name)?;\n-                CompletionAnalysis::Name(name_ctx)\n-            }\n-        };\n-        Some(analysis)\n+fn classify_lifetime(\n+    _sema: &Semantics<'_, RootDatabase>,\n+    original_file: &SyntaxNode,\n+    lifetime: ast::Lifetime,\n+) -> Option<LifetimeContext> {\n+    let parent = lifetime.syntax().parent()?;\n+    if parent.kind() == SyntaxKind::ERROR {\n+        return None;\n     }\n \n-    fn classify_lifetime(\n-        _sema: &Semantics<'_, RootDatabase>,\n-        original_file: &SyntaxNode,\n-        lifetime: ast::Lifetime,\n-    ) -> Option<LifetimeContext> {\n-        let parent = lifetime.syntax().parent()?;\n-        if parent.kind() == SyntaxKind::ERROR {\n-            return None;\n+    let kind = match_ast! {\n+        match parent {\n+            ast::LifetimeParam(param) => LifetimeKind::LifetimeParam {\n+                is_decl: param.lifetime().as_ref() == Some(&lifetime),\n+                param\n+            },\n+            ast::BreakExpr(_) => LifetimeKind::LabelRef,\n+            ast::ContinueExpr(_) => LifetimeKind::LabelRef,\n+            ast::Label(_) => LifetimeKind::LabelDef,\n+            _ => LifetimeKind::Lifetime,\n         }\n+    };\n+    let lifetime = find_node_at_offset(&original_file, lifetime.syntax().text_range().start());\n \n-        let kind = match_ast! {\n-            match parent {\n-                ast::LifetimeParam(param) => LifetimeKind::LifetimeParam {\n-                    is_decl: param.lifetime().as_ref() == Some(&lifetime),\n-                    param\n-                },\n-                ast::BreakExpr(_) => LifetimeKind::LabelRef,\n-                ast::ContinueExpr(_) => LifetimeKind::LabelRef,\n-                ast::Label(_) => LifetimeKind::LabelDef,\n-                _ => LifetimeKind::Lifetime,\n-            }\n-        };\n-        let lifetime = find_node_at_offset(&original_file, lifetime.syntax().text_range().start());\n+    Some(LifetimeContext { lifetime, kind })\n+}\n \n-        Some(LifetimeContext { lifetime, kind })\n-    }\n+fn classify_name(\n+    sema: &Semantics<'_, RootDatabase>,\n+    original_file: &SyntaxNode,\n+    name: ast::Name,\n+) -> Option<NameContext> {\n+    let parent = name.syntax().parent()?;\n+    let kind = match_ast! {\n+        match parent {\n+            ast::Const(_) => NameKind::Const,\n+            ast::ConstParam(_) => NameKind::ConstParam,\n+            ast::Enum(_) => NameKind::Enum,\n+            ast::Fn(_) => NameKind::Function,\n+            ast::IdentPat(bind_pat) => {\n+                let mut pat_ctx = pattern_context_for(sema, original_file, bind_pat.into());\n+                if let Some(record_field) = ast::RecordPatField::for_field_name(&name) {\n+                    pat_ctx.record_pat = find_node_in_file_compensated(sema, original_file, &record_field.parent_record_pat());\n+                }\n \n-    fn classify_name(\n-        sema: &Semantics<'_, RootDatabase>,\n-        original_file: &SyntaxNode,\n-        name: ast::Name,\n-    ) -> Option<NameContext> {\n-        let parent = name.syntax().parent()?;\n-        let kind = match_ast! {\n-            match parent {\n-                ast::Const(_) => NameKind::Const,\n-                ast::ConstParam(_) => NameKind::ConstParam,\n-                ast::Enum(_) => NameKind::Enum,\n-                ast::Fn(_) => NameKind::Function,\n-                ast::IdentPat(bind_pat) => {\n-                    let mut pat_ctx = pattern_context_for(sema, original_file, bind_pat.into());\n-                    if let Some(record_field) = ast::RecordPatField::for_field_name(&name) {\n-                        pat_ctx.record_pat = find_node_in_file_compensated(sema, original_file, &record_field.parent_record_pat());\n-                    }\n+                NameKind::IdentPat(pat_ctx)\n+            },\n+            ast::MacroDef(_) => NameKind::MacroDef,\n+            ast::MacroRules(_) => NameKind::MacroRules,\n+            ast::Module(module) => NameKind::Module(module),\n+            ast::RecordField(_) => NameKind::RecordField,\n+            ast::Rename(_) => NameKind::Rename,\n+            ast::SelfParam(_) => NameKind::SelfParam,\n+            ast::Static(_) => NameKind::Static,\n+            ast::Struct(_) => NameKind::Struct,\n+            ast::Trait(_) => NameKind::Trait,\n+            ast::TypeAlias(_) => NameKind::TypeAlias,\n+            ast::TypeParam(_) => NameKind::TypeParam,\n+            ast::Union(_) => NameKind::Union,\n+            ast::Variant(_) => NameKind::Variant,\n+            _ => return None,\n+        }\n+    };\n+    let name = find_node_at_offset(&original_file, name.syntax().text_range().start());\n+    Some(NameContext { name, kind })\n+}\n \n-                    NameKind::IdentPat(pat_ctx)\n-                },\n-                ast::MacroDef(_) => NameKind::MacroDef,\n-                ast::MacroRules(_) => NameKind::MacroRules,\n-                ast::Module(module) => NameKind::Module(module),\n-                ast::RecordField(_) => NameKind::RecordField,\n-                ast::Rename(_) => NameKind::Rename,\n-                ast::SelfParam(_) => NameKind::SelfParam,\n-                ast::Static(_) => NameKind::Static,\n-                ast::Struct(_) => NameKind::Struct,\n-                ast::Trait(_) => NameKind::Trait,\n-                ast::TypeAlias(_) => NameKind::TypeAlias,\n-                ast::TypeParam(_) => NameKind::TypeParam,\n-                ast::Union(_) => NameKind::Union,\n-                ast::Variant(_) => NameKind::Variant,\n-                _ => return None,\n-            }\n-        };\n-        let name = find_node_at_offset(&original_file, name.syntax().text_range().start());\n-        Some(NameContext { name, kind })\n+fn classify_name_ref(\n+    sema: &Semantics<'_, RootDatabase>,\n+    original_file: &SyntaxNode,\n+    name_ref: ast::NameRef,\n+    parent: SyntaxNode,\n+) -> Option<(NameRefContext, QualifierCtx)> {\n+    let nameref = find_node_at_offset(&original_file, name_ref.syntax().text_range().start());\n+\n+    let make_res = |kind| (NameRefContext { nameref: nameref.clone(), kind }, Default::default());\n+\n+    if let Some(record_field) = ast::RecordExprField::for_field_name(&name_ref) {\n+        let dot_prefix = previous_non_trivia_token(name_ref.syntax().clone())\n+            .map_or(false, |it| T![.] == it.kind());\n+\n+        return find_node_in_file_compensated(\n+            sema,\n+            original_file,\n+            &record_field.parent_record_lit(),\n+        )\n+        .map(|expr| NameRefKind::RecordExpr { expr, dot_prefix })\n+        .map(make_res);\n     }\n-\n-    fn classify_name_ref(\n-        sema: &Semantics<'_, RootDatabase>,\n-        original_file: &SyntaxNode,\n-        name_ref: ast::NameRef,\n-        parent: SyntaxNode,\n-    ) -> Option<(NameRefContext, QualifierCtx)> {\n-        let nameref = find_node_at_offset(&original_file, name_ref.syntax().text_range().start());\n-\n-        let make_res =\n-            |kind| (NameRefContext { nameref: nameref.clone(), kind }, Default::default());\n-\n-        if let Some(record_field) = ast::RecordExprField::for_field_name(&name_ref) {\n-            let dot_prefix = previous_non_trivia_token(name_ref.syntax().clone())\n-                .map_or(false, |it| T![.] == it.kind());\n-\n-            return find_node_in_file_compensated(\n+    if let Some(record_field) = ast::RecordPatField::for_field_name_ref(&name_ref) {\n+        let kind = NameRefKind::Pattern(PatternContext {\n+            param_ctx: None,\n+            has_type_ascription: false,\n+            ref_token: None,\n+            mut_token: None,\n+            record_pat: find_node_in_file_compensated(\n                 sema,\n                 original_file,\n-                &record_field.parent_record_lit(),\n+                &record_field.parent_record_pat(),\n+            ),\n+            ..pattern_context_for(\n+                sema,\n+                original_file,\n+                record_field.parent_record_pat().clone().into(),\n             )\n-            .map(|expr| NameRefKind::RecordExpr { expr, dot_prefix })\n-            .map(make_res);\n+        });\n+        return Some(make_res(kind));\n+    }\n+\n+    let segment = match_ast! {\n+        match parent {\n+            ast::PathSegment(segment) => segment,\n+            ast::FieldExpr(field) => {\n+                let receiver = find_opt_node_in_file(original_file, field.expr());\n+                let receiver_is_ambiguous_float_literal = match &receiver {\n+                    Some(ast::Expr::Literal(l)) => matches! {\n+                        l.kind(),\n+                        ast::LiteralKind::FloatNumber { .. } if l.syntax().last_token().map_or(false, |it| it.text().ends_with('.'))\n+                    },\n+                    _ => false,\n+                };\n+                let kind = NameRefKind::DotAccess(DotAccess {\n+                    receiver_ty: receiver.as_ref().and_then(|it| sema.type_of_expr(it)),\n+                    kind: DotAccessKind::Field { receiver_is_ambiguous_float_literal },\n+                    receiver\n+                });\n+                return Some(make_res(kind));\n+            },\n+            ast::MethodCallExpr(method) => {\n+                let receiver = find_opt_node_in_file(original_file, method.receiver());\n+                let kind = NameRefKind::DotAccess(DotAccess {\n+                    receiver_ty: receiver.as_ref().and_then(|it| sema.type_of_expr(it)),\n+                    kind: DotAccessKind::Method { has_parens: method.arg_list().map_or(false, |it| it.l_paren_token().is_some()) },\n+                    receiver\n+                });\n+                return Some(make_res(kind));\n+            },\n+            _ => return None,\n         }\n-        if let Some(record_field) = ast::RecordPatField::for_field_name_ref(&name_ref) {\n-            let kind = NameRefKind::Pattern(PatternContext {\n-                param_ctx: None,\n-                has_type_ascription: false,\n-                ref_token: None,\n-                mut_token: None,\n-                record_pat: find_node_in_file_compensated(\n-                    sema,\n-                    original_file,\n-                    &record_field.parent_record_pat(),\n-                ),\n-                ..pattern_context_for(\n-                    sema,\n-                    original_file,\n-                    record_field.parent_record_pat().clone().into(),\n-                )\n-            });\n-            return Some(make_res(kind));\n+    };\n+\n+    let path = segment.parent_path();\n+    let original_path = find_node_in_file_compensated(sema, original_file, &path);\n+\n+    let mut path_ctx = PathCompletionCtx {\n+        has_call_parens: false,\n+        has_macro_bang: false,\n+        qualified: Qualified::No,\n+        parent: None,\n+        path: path.clone(),\n+        original_path,\n+        kind: PathKind::Item { kind: ItemListKind::SourceFile },\n+        has_type_args: false,\n+        use_tree_parent: false,\n+    };\n+\n+    let is_in_block = |it: &SyntaxNode| {\n+        it.parent()\n+            .map(|node| {\n+                ast::ExprStmt::can_cast(node.kind()) || ast::StmtList::can_cast(node.kind())\n+            })\n+            .unwrap_or(false)\n+    };\n+    let func_update_record = |syn: &SyntaxNode| {\n+        if let Some(record_expr) = syn.ancestors().nth(2).and_then(ast::RecordExpr::cast) {\n+            find_node_in_file_compensated(sema, original_file, &record_expr)\n+        } else {\n+            None\n+        }\n+    };\n+    let after_if_expr = |node: SyntaxNode| {\n+        let prev_expr = (|| {\n+            let prev_sibling = non_trivia_sibling(node.into(), Direction::Prev)?.into_node()?;\n+            ast::ExprStmt::cast(prev_sibling)?.expr()\n+        })();\n+        matches!(prev_expr, Some(ast::Expr::IfExpr(_)))\n+    };\n+\n+    // We do not want to generate path completions when we are sandwiched between an item decl signature and its body.\n+    // ex. trait Foo $0 {}\n+    // in these cases parser recovery usually kicks in for our inserted identifier, causing it\n+    // to either be parsed as an ExprStmt or a MacroCall, depending on whether it is in a block\n+    // expression or an item list.\n+    // The following code checks if the body is missing, if it is we either cut off the body\n+    // from the item or it was missing in the first place\n+    let inbetween_body_and_decl_check = |node: SyntaxNode| {\n+        if let Some(NodeOrToken::Node(n)) =\n+            syntax::algo::non_trivia_sibling(node.into(), syntax::Direction::Prev)\n+        {\n+            if let Some(item) = ast::Item::cast(n) {\n+                let is_inbetween = match &item {\n+                    ast::Item::Const(it) => it.body().is_none(),\n+                    ast::Item::Enum(it) => it.variant_list().is_none(),\n+                    ast::Item::ExternBlock(it) => it.extern_item_list().is_none(),\n+                    ast::Item::Fn(it) => it.body().is_none(),\n+                    ast::Item::Impl(it) => it.assoc_item_list().is_none(),\n+                    ast::Item::Module(it) => it.item_list().is_none(),\n+                    ast::Item::Static(it) => it.body().is_none(),\n+                    ast::Item::Struct(it) => it.field_list().is_none(),\n+                    ast::Item::Trait(it) => it.assoc_item_list().is_none(),\n+                    ast::Item::TypeAlias(it) => it.ty().is_none(),\n+                    ast::Item::Union(it) => it.record_field_list().is_none(),\n+                    _ => false,\n+                };\n+                if is_inbetween {\n+                    return Some(item);\n+                }\n+            }\n         }\n+        None\n+    };\n \n-        let segment = match_ast! {\n+    let type_location = |node: &SyntaxNode| {\n+        let parent = node.parent()?;\n+        let res = match_ast! {\n             match parent {\n-                ast::PathSegment(segment) => segment,\n-                ast::FieldExpr(field) => {\n-                    let receiver = find_opt_node_in_file(original_file, field.expr());\n-                    let receiver_is_ambiguous_float_literal = match &receiver {\n-                        Some(ast::Expr::Literal(l)) => matches! {\n-                            l.kind(),\n-                            ast::LiteralKind::FloatNumber { .. } if l.syntax().last_token().map_or(false, |it| it.text().ends_with('.'))\n-                        },\n-                        _ => false,\n+                ast::Const(it) => {\n+                    let name = find_opt_node_in_file(original_file, it.name())?;\n+                    let original = ast::Const::cast(name.syntax().parent()?)?;\n+                    TypeLocation::TypeAscription(TypeAscriptionTarget::Const(original.body()))\n+                },\n+                ast::RetType(it) => {\n+                    if it.thin_arrow_token().is_none() {\n+                        return None;\n+                    }\n+                    let parent = match ast::Fn::cast(parent.parent()?) {\n+                        Some(x) => x.param_list(),\n+                        None => ast::ClosureExpr::cast(parent.parent()?)?.param_list(),\n                     };\n-                    let kind = NameRefKind::DotAccess(DotAccess {\n-                        receiver_ty: receiver.as_ref().and_then(|it| sema.type_of_expr(it)),\n-                        kind: DotAccessKind::Field { receiver_is_ambiguous_float_literal },\n-                        receiver\n-                    });\n-                    return Some(make_res(kind));\n+\n+                    let parent = find_opt_node_in_file(original_file, parent)?.syntax().parent()?;\n+                    TypeLocation::TypeAscription(TypeAscriptionTarget::RetType(match_ast! {\n+                        match parent {\n+                            ast::ClosureExpr(it) => {\n+                                it.body()\n+                            },\n+                            ast::Fn(it) => {\n+                                it.body().map(ast::Expr::BlockExpr)\n+                            },\n+                            _ => return None,\n+                        }\n+                    }))\n                 },\n-                ast::MethodCallExpr(method) => {\n-                    let receiver = find_opt_node_in_file(original_file, method.receiver());\n-                    let kind = NameRefKind::DotAccess(DotAccess {\n-                        receiver_ty: receiver.as_ref().and_then(|it| sema.type_of_expr(it)),\n-                        kind: DotAccessKind::Method { has_parens: method.arg_list().map_or(false, |it| it.l_paren_token().is_some()) },\n-                        receiver\n-                    });\n-                    return Some(make_res(kind));\n+                ast::Param(it) => {\n+                    if it.colon_token().is_none() {\n+                        return None;\n+                    }\n+                    TypeLocation::TypeAscription(TypeAscriptionTarget::FnParam(find_opt_node_in_file(original_file, it.pat())))\n                 },\n+                ast::LetStmt(it) => {\n+                    if it.colon_token().is_none() {\n+                        return None;\n+                    }\n+                    TypeLocation::TypeAscription(TypeAscriptionTarget::Let(find_opt_node_in_file(original_file, it.pat())))\n+                },\n+                ast::Impl(it) => {\n+                    match it.trait_() {\n+                        Some(t) if t.syntax() == node => TypeLocation::ImplTrait,\n+                        _ => match it.self_ty() {\n+                            Some(t) if t.syntax() == node => TypeLocation::ImplTarget,\n+                            _ => return None,\n+                        },\n+                    }\n+                },\n+                ast::TypeBound(_) => TypeLocation::TypeBound,\n+                // is this case needed?\n+                ast::TypeBoundList(_) => TypeLocation::TypeBound,\n+                ast::GenericArg(it) => TypeLocation::GenericArgList(find_opt_node_in_file_compensated(sema, original_file, it.syntax().parent().and_then(ast::GenericArgList::cast))),\n+                // is this case needed?\n+                ast::GenericArgList(it) => TypeLocation::GenericArgList(find_opt_node_in_file_compensated(sema, original_file, Some(it))),\n+                ast::TupleField(_) => TypeLocation::TupleField,\n                 _ => return None,\n             }\n         };\n+        Some(res)\n+    };\n \n-        let path = segment.parent_path();\n-        let original_path = find_node_in_file_compensated(sema, original_file, &path);\n-\n-        let mut path_ctx = PathCompletionCtx {\n-            has_call_parens: false,\n-            has_macro_bang: false,\n-            qualified: Qualified::No,\n-            parent: None,\n-            path: path.clone(),\n-            original_path,\n-            kind: PathKind::Item { kind: ItemListKind::SourceFile },\n-            has_type_args: false,\n-            use_tree_parent: false,\n-        };\n-\n-        let is_in_block = |it: &SyntaxNode| {\n-            it.parent()\n-                .map(|node| {\n-                    ast::ExprStmt::can_cast(node.kind()) || ast::StmtList::can_cast(node.kind())\n-                })\n-                .unwrap_or(false)\n-        };\n-        let func_update_record = |syn: &SyntaxNode| {\n-            if let Some(record_expr) = syn.ancestors().nth(2).and_then(ast::RecordExpr::cast) {\n-                find_node_in_file_compensated(sema, original_file, &record_expr)\n+    let is_in_condition = |it: &ast::Expr| {\n+        (|| {\n+            let parent = it.syntax().parent()?;\n+            if let Some(expr) = ast::WhileExpr::cast(parent.clone()) {\n+                Some(expr.condition()? == *it)\n+            } else if let Some(expr) = ast::IfExpr::cast(parent) {\n+                Some(expr.condition()? == *it)\n             } else {\n                 None\n             }\n-        };\n-        let after_if_expr = |node: SyntaxNode| {\n-            let prev_expr = (|| {\n-                let prev_sibling = non_trivia_sibling(node.into(), Direction::Prev)?.into_node()?;\n-                ast::ExprStmt::cast(prev_sibling)?.expr()\n-            })();\n-            matches!(prev_expr, Some(ast::Expr::IfExpr(_)))\n-        };\n+        })()\n+        .unwrap_or(false)\n+    };\n \n-        // We do not want to generate path completions when we are sandwiched between an item decl signature and its body.\n-        // ex. trait Foo $0 {}\n-        // in these cases parser recovery usually kicks in for our inserted identifier, causing it\n-        // to either be parsed as an ExprStmt or a MacroCall, depending on whether it is in a block\n-        // expression or an item list.\n-        // The following code checks if the body is missing, if it is we either cut off the body\n-        // from the item or it was missing in the first place\n-        let inbetween_body_and_decl_check = |node: SyntaxNode| {\n-            if let Some(NodeOrToken::Node(n)) =\n-                syntax::algo::non_trivia_sibling(node.into(), syntax::Direction::Prev)\n-            {\n-                if let Some(item) = ast::Item::cast(n) {\n-                    let is_inbetween = match &item {\n-                        ast::Item::Const(it) => it.body().is_none(),\n-                        ast::Item::Enum(it) => it.variant_list().is_none(),\n-                        ast::Item::ExternBlock(it) => it.extern_item_list().is_none(),\n-                        ast::Item::Fn(it) => it.body().is_none(),\n-                        ast::Item::Impl(it) => it.assoc_item_list().is_none(),\n-                        ast::Item::Module(it) => it.item_list().is_none(),\n-                        ast::Item::Static(it) => it.body().is_none(),\n-                        ast::Item::Struct(it) => it.field_list().is_none(),\n-                        ast::Item::Trait(it) => it.assoc_item_list().is_none(),\n-                        ast::Item::TypeAlias(it) => it.ty().is_none(),\n-                        ast::Item::Union(it) => it.record_field_list().is_none(),\n-                        _ => false,\n-                    };\n-                    if is_inbetween {\n-                        return Some(item);\n+    let make_path_kind_expr = |expr: ast::Expr| {\n+        let it = expr.syntax();\n+        let in_block_expr = is_in_block(it);\n+        let in_loop_body = is_in_loop_body(it);\n+        let after_if_expr = after_if_expr(it.clone());\n+        let ref_expr_parent =\n+            path.as_single_name_ref().and_then(|_| it.parent()).and_then(ast::RefExpr::cast);\n+        let (innermost_ret_ty, self_param) = {\n+            let find_ret_ty = |it: SyntaxNode| {\n+                if let Some(item) = ast::Item::cast(it.clone()) {\n+                    match item {\n+                        ast::Item::Fn(f) => Some(sema.to_def(&f).map(|it| it.ret_type(sema.db))),\n+                        ast::Item::MacroCall(_) => None,\n+                        _ => Some(None),\n                     }\n-                }\n-            }\n-            None\n-        };\n-\n-        let type_location = |node: &SyntaxNode| {\n-            let parent = node.parent()?;\n-            let res = match_ast! {\n-                match parent {\n-                    ast::Const(it) => {\n-                        let name = find_opt_node_in_file(original_file, it.name())?;\n-                        let original = ast::Const::cast(name.syntax().parent()?)?;\n-                        TypeLocation::TypeAscription(TypeAscriptionTarget::Const(original.body()))\n-                    },\n-                    ast::RetType(it) => {\n-                        if it.thin_arrow_token().is_none() {\n-                            return None;\n-                        }\n-                        let parent = match ast::Fn::cast(parent.parent()?) {\n-                            Some(x) => x.param_list(),\n-                            None => ast::ClosureExpr::cast(parent.parent()?)?.param_list(),\n-                        };\n-\n-                        let parent = find_opt_node_in_file(original_file, parent)?.syntax().parent()?;\n-                        TypeLocation::TypeAscription(TypeAscriptionTarget::RetType(match_ast! {\n-                            match parent {\n-                                ast::ClosureExpr(it) => {\n-                                    it.body()\n-                                },\n-                                ast::Fn(it) => {\n-                                    it.body().map(ast::Expr::BlockExpr)\n-                                },\n-                                _ => return None,\n-                            }\n-                        }))\n-                    },\n-                    ast::Param(it) => {\n-                        if it.colon_token().is_none() {\n-                            return None;\n-                        }\n-                        TypeLocation::TypeAscription(TypeAscriptionTarget::FnParam(find_opt_node_in_file(original_file, it.pat())))\n-                    },\n-                    ast::LetStmt(it) => {\n-                        if it.colon_token().is_none() {\n-                            return None;\n-                        }\n-                        TypeLocation::TypeAscription(TypeAscriptionTarget::Let(find_opt_node_in_file(original_file, it.pat())))\n-                    },\n-                    ast::Impl(it) => {\n-                        match it.trait_() {\n-                            Some(t) if t.syntax() == node => TypeLocation::ImplTrait,\n-                            _ => match it.self_ty() {\n-                                Some(t) if t.syntax() == node => TypeLocation::ImplTarget,\n-                                _ => return None,\n-                            },\n-                        }\n-                    },\n-                    ast::TypeBound(_) => TypeLocation::TypeBound,\n-                    // is this case needed?\n-                    ast::TypeBoundList(_) => TypeLocation::TypeBound,\n-                    ast::GenericArg(it) => TypeLocation::GenericArgList(find_opt_node_in_file_compensated(sema, original_file, it.syntax().parent().and_then(ast::GenericArgList::cast))),\n-                    // is this case needed?\n-                    ast::GenericArgList(it) => TypeLocation::GenericArgList(find_opt_node_in_file_compensated(sema, original_file, Some(it))),\n-                    ast::TupleField(_) => TypeLocation::TupleField,\n-                    _ => return None,\n-                }\n-            };\n-            Some(res)\n-        };\n-\n-        let is_in_condition = |it: &ast::Expr| {\n-            (|| {\n-                let parent = it.syntax().parent()?;\n-                if let Some(expr) = ast::WhileExpr::cast(parent.clone()) {\n-                    Some(expr.condition()? == *it)\n-                } else if let Some(expr) = ast::IfExpr::cast(parent) {\n-                    Some(expr.condition()? == *it)\n                 } else {\n-                    None\n-                }\n-            })()\n-            .unwrap_or(false)\n-        };\n-\n-        let make_path_kind_expr = |expr: ast::Expr| {\n-            let it = expr.syntax();\n-            let in_block_expr = is_in_block(it);\n-            let in_loop_body = is_in_loop_body(it);\n-            let after_if_expr = after_if_expr(it.clone());\n-            let ref_expr_parent =\n-                path.as_single_name_ref().and_then(|_| it.parent()).and_then(ast::RefExpr::cast);\n-            let (innermost_ret_ty, self_param) = {\n-                let find_ret_ty = |it: SyntaxNode| {\n-                    if let Some(item) = ast::Item::cast(it.clone()) {\n-                        match item {\n-                            ast::Item::Fn(f) => {\n-                                Some(sema.to_def(&f).map(|it| it.ret_type(sema.db)))\n-                            }\n-                            ast::Item::MacroCall(_) => None,\n-                            _ => Some(None),\n-                        }\n-                    } else {\n-                        let expr = ast::Expr::cast(it)?;\n-                        let callable = match expr {\n-                            // FIXME\n-                            // ast::Expr::BlockExpr(b) if b.async_token().is_some() || b.try_token().is_some() => sema.type_of_expr(b),\n-                            ast::Expr::ClosureExpr(_) => sema.type_of_expr(&expr),\n-                            _ => return None,\n-                        };\n-                        Some(\n-                            callable\n-                                .and_then(|c| c.adjusted().as_callable(sema.db))\n-                                .map(|it| it.return_type()),\n-                        )\n-                    }\n-                };\n-                let find_fn_self_param = |it| match it {\n-                    ast::Item::Fn(fn_) => {\n-                        Some(sema.to_def(&fn_).and_then(|it| it.self_param(sema.db)))\n-                    }\n-                    ast::Item::MacroCall(_) => None,\n-                    _ => Some(None),\n-                };\n-\n-                match find_node_in_file_compensated(sema, original_file, &expr) {\n-                    Some(it) => {\n-                        let innermost_ret_ty = sema\n-                            .ancestors_with_macros(it.syntax().clone())\n-                            .find_map(find_ret_ty)\n-                            .flatten();\n-\n-                        let self_param = sema\n-                            .ancestors_with_macros(it.syntax().clone())\n-                            .filter_map(ast::Item::cast)\n-                            .find_map(find_fn_self_param)\n-                            .flatten();\n-                        (innermost_ret_ty, self_param)\n-                    }\n-                    None => (None, None),\n+                    let expr = ast::Expr::cast(it)?;\n+                    let callable = match expr {\n+                        // FIXME\n+                        // ast::Expr::BlockExpr(b) if b.async_token().is_some() || b.try_token().is_some() => sema.type_of_expr(b),\n+                        ast::Expr::ClosureExpr(_) => sema.type_of_expr(&expr),\n+                        _ => return None,\n+                    };\n+                    Some(\n+                        callable\n+                            .and_then(|c| c.adjusted().as_callable(sema.db))\n+                            .map(|it| it.return_type()),\n+                    )\n                 }\n             };\n-            let is_func_update = func_update_record(it);\n-            let in_condition = is_in_condition(&expr);\n-            let incomplete_let = it\n-                .parent()\n-                .and_then(ast::LetStmt::cast)\n-                .map_or(false, |it| it.semicolon_token().is_none());\n-            let impl_ = fetch_immediate_impl(sema, original_file, expr.syntax());\n-\n-            let in_match_guard = match it.parent().and_then(ast::MatchArm::cast) {\n-                Some(arm) => arm\n-                    .fat_arrow_token()\n-                    .map_or(true, |arrow| it.text_range().start() < arrow.text_range().start()),\n-                None => false,\n+            let find_fn_self_param = |it| match it {\n+                ast::Item::Fn(fn_) => Some(sema.to_def(&fn_).and_then(|it| it.self_param(sema.db))),\n+                ast::Item::MacroCall(_) => None,\n+                _ => Some(None),\n             };\n \n-            PathKind::Expr {\n-                expr_ctx: ExprCtx {\n-                    in_block_expr,\n-                    in_loop_body,\n-                    after_if_expr,\n-                    in_condition,\n-                    ref_expr_parent,\n-                    is_func_update,\n-                    innermost_ret_ty,\n-                    self_param,\n-                    incomplete_let,\n-                    impl_,\n-                    in_match_guard,\n-                },\n+            match find_node_in_file_compensated(sema, original_file, &expr) {\n+                Some(it) => {\n+                    let innermost_ret_ty = sema\n+                        .ancestors_with_macros(it.syntax().clone())\n+                        .find_map(find_ret_ty)\n+                        .flatten();\n+\n+                    let self_param = sema\n+                        .ancestors_with_macros(it.syntax().clone())\n+                        .filter_map(ast::Item::cast)\n+                        .find_map(find_fn_self_param)\n+                        .flatten();\n+                    (innermost_ret_ty, self_param)\n+                }\n+                None => (None, None),\n             }\n         };\n-        let make_path_kind_type = |ty: ast::Type| {\n-            let location = type_location(ty.syntax());\n-            PathKind::Type { location: location.unwrap_or(TypeLocation::Other) }\n+        let is_func_update = func_update_record(it);\n+        let in_condition = is_in_condition(&expr);\n+        let incomplete_let = it\n+            .parent()\n+            .and_then(ast::LetStmt::cast)\n+            .map_or(false, |it| it.semicolon_token().is_none());\n+        let impl_ = fetch_immediate_impl(sema, original_file, expr.syntax());\n+\n+        let in_match_guard = match it.parent().and_then(ast::MatchArm::cast) {\n+            Some(arm) => arm\n+                .fat_arrow_token()\n+                .map_or(true, |arrow| it.text_range().start() < arrow.text_range().start()),\n+            None => false,\n         };\n \n-        let mut kind_macro_call = |it: ast::MacroCall| {\n-            path_ctx.has_macro_bang = it.excl_token().is_some();\n-            let parent = it.syntax().parent()?;\n-            // Any path in an item list will be treated as a macro call by the parser\n-            let kind = match_ast! {\n-                match parent {\n-                    ast::MacroExpr(expr) => make_path_kind_expr(expr.into()),\n-                    ast::MacroPat(it) => PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into())},\n-                    ast::MacroType(ty) => make_path_kind_type(ty.into()),\n-                    ast::ItemList(_) => PathKind::Item { kind: ItemListKind::Module },\n-                    ast::AssocItemList(_) => PathKind::Item { kind: match parent.parent() {\n-                        Some(it) => match_ast! {\n-                            match it {\n-                                ast::Trait(_) => ItemListKind::Trait,\n-                                ast::Impl(it) => if it.trait_().is_some() {\n-                                    ItemListKind::TraitImpl(find_node_in_file_compensated(sema, original_file, &it))\n-                                } else {\n-                                    ItemListKind::Impl\n-                                },\n-                                _ => return None\n-                            }\n-                        },\n-                        None => return None,\n-                    } },\n-                    ast::ExternItemList(_) => PathKind::Item { kind: ItemListKind::ExternBlock },\n-                    ast::SourceFile(_) => PathKind::Item { kind: ItemListKind::SourceFile },\n-                    _ => return None,\n-                }\n-            };\n-            Some(kind)\n-        };\n-        let make_path_kind_attr = |meta: ast::Meta| {\n-            let attr = meta.parent_attr()?;\n-            let kind = attr.kind();\n-            let attached = attr.syntax().parent()?;\n-            let is_trailing_outer_attr = kind != AttrKind::Inner\n-                && non_trivia_sibling(attr.syntax().clone().into(), syntax::Direction::Next)\n-                    .is_none();\n-            let annotated_item_kind =\n-                if is_trailing_outer_attr { None } else { Some(attached.kind()) };\n-            Some(PathKind::Attr { attr_ctx: AttrCtx { kind, annotated_item_kind } })\n-        };\n+        PathKind::Expr {\n+            expr_ctx: ExprCtx {\n+                in_block_expr,\n+                in_loop_body,\n+                after_if_expr,\n+                in_condition,\n+                ref_expr_parent,\n+                is_func_update,\n+                innermost_ret_ty,\n+                self_param,\n+                incomplete_let,\n+                impl_,\n+                in_match_guard,\n+            },\n+        }\n+    };\n+    let make_path_kind_type = |ty: ast::Type| {\n+        let location = type_location(ty.syntax());\n+        PathKind::Type { location: location.unwrap_or(TypeLocation::Other) }\n+    };\n \n-        // Infer the path kind\n-        let parent = path.syntax().parent()?;\n+    let mut kind_macro_call = |it: ast::MacroCall| {\n+        path_ctx.has_macro_bang = it.excl_token().is_some();\n+        let parent = it.syntax().parent()?;\n+        // Any path in an item list will be treated as a macro call by the parser\n         let kind = match_ast! {\n             match parent {\n-                ast::PathType(it) => make_path_kind_type(it.into()),\n-                ast::PathExpr(it) => {\n-                    if let Some(p) = it.syntax().parent() {\n-                        if ast::ExprStmt::can_cast(p.kind()) {\n-                            if let Some(kind) = inbetween_body_and_decl_check(p) {\n-                                return Some(make_res(NameRefKind::Keyword(kind)));\n-                            }\n-                        }\n-                    }\n-\n-                    path_ctx.has_call_parens = it.syntax().parent().map_or(false, |it| ast::CallExpr::can_cast(it.kind()));\n-\n-                    make_path_kind_expr(it.into())\n-                },\n-                ast::TupleStructPat(it) => {\n-                    path_ctx.has_call_parens = true;\n-                    PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n-                },\n-                ast::RecordPat(it) => {\n-                    path_ctx.has_call_parens = true;\n-                    PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n-                },\n-                ast::PathPat(it) => {\n-                    PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into())}\n-                },\n-                ast::MacroCall(it) => {\n-                    // A macro call in this position is usually a result of parsing recovery, so check that\n-                    if let Some(kind) = inbetween_body_and_decl_check(it.syntax().clone()) {\n-                        return Some(make_res(NameRefKind::Keyword(kind)));\n-                    }\n-\n-                    kind_macro_call(it)?\n-                },\n-                ast::Meta(meta) => make_path_kind_attr(meta)?,\n-                ast::Visibility(it) => PathKind::Vis { has_in_token: it.in_token().is_some() },\n-                ast::UseTree(_) => PathKind::Use,\n-                // completing inside a qualifier\n-                ast::Path(parent) => {\n-                    path_ctx.parent = Some(parent.clone());\n-                    let parent = iter::successors(Some(parent), |it| it.parent_path()).last()?.syntax().parent()?;\n-                    match_ast! {\n-                        match parent {\n-                            ast::PathType(it) => make_path_kind_type(it.into()),\n-                            ast::PathExpr(it) => {\n-                                path_ctx.has_call_parens = it.syntax().parent().map_or(false, |it| ast::CallExpr::can_cast(it.kind()));\n-\n-                                make_path_kind_expr(it.into())\n-                            },\n-                            ast::TupleStructPat(it) => {\n-                                path_ctx.has_call_parens = true;\n-                                PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n-                            },\n-                            ast::RecordPat(it) => {\n-                                path_ctx.has_call_parens = true;\n-                                PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n-                            },\n-                            ast::PathPat(it) => {\n-                                PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into())}\n-                            },\n-                            ast::MacroCall(it) => {\n-                                kind_macro_call(it)?\n+                ast::MacroExpr(expr) => make_path_kind_expr(expr.into()),\n+                ast::MacroPat(it) => PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into())},\n+                ast::MacroType(ty) => make_path_kind_type(ty.into()),\n+                ast::ItemList(_) => PathKind::Item { kind: ItemListKind::Module },\n+                ast::AssocItemList(_) => PathKind::Item { kind: match parent.parent() {\n+                    Some(it) => match_ast! {\n+                        match it {\n+                            ast::Trait(_) => ItemListKind::Trait,\n+                            ast::Impl(it) => if it.trait_().is_some() {\n+                                ItemListKind::TraitImpl(find_node_in_file_compensated(sema, original_file, &it))\n+                            } else {\n+                                ItemListKind::Impl\n                             },\n-                            ast::Meta(meta) => make_path_kind_attr(meta)?,\n-                            ast::Visibility(it) => PathKind::Vis { has_in_token: it.in_token().is_some() },\n-                            ast::UseTree(_) => PathKind::Use,\n-                            ast::RecordExpr(it) => make_path_kind_expr(it.into()),\n-                            _ => return None,\n+                            _ => return None\n                         }\n-                    }\n-                },\n-                ast::RecordExpr(it) => make_path_kind_expr(it.into()),\n+                    },\n+                    None => return None,\n+                } },\n+                ast::ExternItemList(_) => PathKind::Item { kind: ItemListKind::ExternBlock },\n+                ast::SourceFile(_) => PathKind::Item { kind: ItemListKind::SourceFile },\n                 _ => return None,\n             }\n         };\n+        Some(kind)\n+    };\n+    let make_path_kind_attr = |meta: ast::Meta| {\n+        let attr = meta.parent_attr()?;\n+        let kind = attr.kind();\n+        let attached = attr.syntax().parent()?;\n+        let is_trailing_outer_attr = kind != AttrKind::Inner\n+            && non_trivia_sibling(attr.syntax().clone().into(), syntax::Direction::Next).is_none();\n+        let annotated_item_kind = if is_trailing_outer_attr { None } else { Some(attached.kind()) };\n+        Some(PathKind::Attr { attr_ctx: AttrCtx { kind, annotated_item_kind } })\n+    };\n \n-        path_ctx.kind = kind;\n-        path_ctx.has_type_args = segment.generic_arg_list().is_some();\n+    // Infer the path kind\n+    let parent = path.syntax().parent()?;\n+    let kind = match_ast! {\n+        match parent {\n+            ast::PathType(it) => make_path_kind_type(it.into()),\n+            ast::PathExpr(it) => {\n+                if let Some(p) = it.syntax().parent() {\n+                    if ast::ExprStmt::can_cast(p.kind()) {\n+                        if let Some(kind) = inbetween_body_and_decl_check(p) {\n+                            return Some(make_res(NameRefKind::Keyword(kind)));\n+                        }\n+                    }\n+                }\n \n-        // calculate the qualifier context\n-        if let Some((qualifier, use_tree_parent)) = path_or_use_tree_qualifier(&path) {\n-            path_ctx.use_tree_parent = use_tree_parent;\n-            if !use_tree_parent && segment.coloncolon_token().is_some() {\n-                path_ctx.qualified = Qualified::Absolute;\n-            } else {\n-                let qualifier = qualifier\n-                    .segment()\n-                    .and_then(|it| find_node_in_file(original_file, &it))\n-                    .map(|it| it.parent_path());\n-                if let Some(qualifier) = qualifier {\n-                    let type_anchor = match qualifier.segment().and_then(|it| it.kind()) {\n-                        Some(ast::PathSegmentKind::Type {\n-                            type_ref: Some(type_ref),\n-                            trait_ref,\n-                        }) if qualifier.qualifier().is_none() => Some((type_ref, trait_ref)),\n-                        _ => None,\n-                    };\n+                path_ctx.has_call_parens = it.syntax().parent().map_or(false, |it| ast::CallExpr::can_cast(it.kind()));\n+\n+                make_path_kind_expr(it.into())\n+            },\n+            ast::TupleStructPat(it) => {\n+                path_ctx.has_call_parens = true;\n+                PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n+            },\n+            ast::RecordPat(it) => {\n+                path_ctx.has_call_parens = true;\n+                PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n+            },\n+            ast::PathPat(it) => {\n+                PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into())}\n+            },\n+            ast::MacroCall(it) => {\n+                // A macro call in this position is usually a result of parsing recovery, so check that\n+                if let Some(kind) = inbetween_body_and_decl_check(it.syntax().clone()) {\n+                    return Some(make_res(NameRefKind::Keyword(kind)));\n+                }\n \n-                    path_ctx.qualified = if let Some((ty, trait_ref)) = type_anchor {\n-                        let ty = match ty {\n-                            ast::Type::InferType(_) => None,\n-                            ty => sema.resolve_type(&ty),\n-                        };\n-                        let trait_ = trait_ref.and_then(|it| sema.resolve_trait(&it.path()?));\n-                        Qualified::TypeAnchor { ty, trait_ }\n-                    } else {\n-                        let res = sema.resolve_path(&qualifier);\n-\n-                        // For understanding how and why super_chain_len is calculated the way it\n-                        // is check the documentation at it's definition\n-                        let mut segment_count = 0;\n-                        let super_count =\n-                            iter::successors(Some(qualifier.clone()), |p| p.qualifier())\n-                                .take_while(|p| {\n-                                    p.segment()\n-                                        .and_then(|s| {\n-                                            segment_count += 1;\n-                                            s.super_token()\n-                                        })\n-                                        .is_some()\n-                                })\n-                                .count();\n+                kind_macro_call(it)?\n+            },\n+            ast::Meta(meta) => make_path_kind_attr(meta)?,\n+            ast::Visibility(it) => PathKind::Vis { has_in_token: it.in_token().is_some() },\n+            ast::UseTree(_) => PathKind::Use,\n+            // completing inside a qualifier\n+            ast::Path(parent) => {\n+                path_ctx.parent = Some(parent.clone());\n+                let parent = iter::successors(Some(parent), |it| it.parent_path()).last()?.syntax().parent()?;\n+                match_ast! {\n+                    match parent {\n+                        ast::PathType(it) => make_path_kind_type(it.into()),\n+                        ast::PathExpr(it) => {\n+                            path_ctx.has_call_parens = it.syntax().parent().map_or(false, |it| ast::CallExpr::can_cast(it.kind()));\n+\n+                            make_path_kind_expr(it.into())\n+                        },\n+                        ast::TupleStructPat(it) => {\n+                            path_ctx.has_call_parens = true;\n+                            PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n+                        },\n+                        ast::RecordPat(it) => {\n+                            path_ctx.has_call_parens = true;\n+                            PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into()) }\n+                        },\n+                        ast::PathPat(it) => {\n+                            PathKind::Pat { pat_ctx: pattern_context_for(sema, original_file, it.into())}\n+                        },\n+                        ast::MacroCall(it) => {\n+                            kind_macro_call(it)?\n+                        },\n+                        ast::Meta(meta) => make_path_kind_attr(meta)?,\n+                        ast::Visibility(it) => PathKind::Vis { has_in_token: it.in_token().is_some() },\n+                        ast::UseTree(_) => PathKind::Use,\n+                        ast::RecordExpr(it) => make_path_kind_expr(it.into()),\n+                        _ => return None,\n+                    }\n+                }\n+            },\n+            ast::RecordExpr(it) => make_path_kind_expr(it.into()),\n+            _ => return None,\n+        }\n+    };\n \n-                        let super_chain_len =\n-                            if segment_count > super_count { None } else { Some(super_count) };\n+    path_ctx.kind = kind;\n+    path_ctx.has_type_args = segment.generic_arg_list().is_some();\n \n-                        Qualified::With { path: qualifier, resolution: res, super_chain_len }\n+    // calculate the qualifier context\n+    if let Some((qualifier, use_tree_parent)) = path_or_use_tree_qualifier(&path) {\n+        path_ctx.use_tree_parent = use_tree_parent;\n+        if !use_tree_parent && segment.coloncolon_token().is_some() {\n+            path_ctx.qualified = Qualified::Absolute;\n+        } else {\n+            let qualifier = qualifier\n+                .segment()\n+                .and_then(|it| find_node_in_file(original_file, &it))\n+                .map(|it| it.parent_path());\n+            if let Some(qualifier) = qualifier {\n+                let type_anchor = match qualifier.segment().and_then(|it| it.kind()) {\n+                    Some(ast::PathSegmentKind::Type { type_ref: Some(type_ref), trait_ref })\n+                        if qualifier.qualifier().is_none() =>\n+                    {\n+                        Some((type_ref, trait_ref))\n                     }\n+                    _ => None,\n                 };\n-            }\n-        } else if let Some(segment) = path.segment() {\n-            if segment.coloncolon_token().is_some() {\n-                path_ctx.qualified = Qualified::Absolute;\n-            }\n-        }\n \n-        let mut qualifier_ctx = QualifierCtx::default();\n-        if path_ctx.is_trivial_path() {\n-            // fetch the full expression that may have qualifiers attached to it\n-            let top_node = match path_ctx.kind {\n-                PathKind::Expr { expr_ctx: ExprCtx { in_block_expr: true, .. } } => {\n-                    parent.ancestors().find(|it| ast::PathExpr::can_cast(it.kind())).and_then(|p| {\n-                        let parent = p.parent()?;\n-                        if ast::StmtList::can_cast(parent.kind()) {\n-                            Some(p)\n-                        } else if ast::ExprStmt::can_cast(parent.kind()) {\n-                            Some(parent)\n-                        } else {\n-                            None\n-                        }\n-                    })\n-                }\n-                PathKind::Item { .. } => {\n-                    parent.ancestors().find(|it| ast::MacroCall::can_cast(it.kind()))\n+                path_ctx.qualified = if let Some((ty, trait_ref)) = type_anchor {\n+                    let ty = match ty {\n+                        ast::Type::InferType(_) => None,\n+                        ty => sema.resolve_type(&ty),\n+                    };\n+                    let trait_ = trait_ref.and_then(|it| sema.resolve_trait(&it.path()?));\n+                    Qualified::TypeAnchor { ty, trait_ }\n+                } else {\n+                    let res = sema.resolve_path(&qualifier);\n+\n+                    // For understanding how and why super_chain_len is calculated the way it\n+                    // is check the documentation at it's definition\n+                    let mut segment_count = 0;\n+                    let super_count = iter::successors(Some(qualifier.clone()), |p| p.qualifier())\n+                        .take_while(|p| {\n+                            p.segment()\n+                                .and_then(|s| {\n+                                    segment_count += 1;\n+                                    s.super_token()\n+                                })\n+                                .is_some()\n+                        })\n+                        .count();\n+\n+                    let super_chain_len =\n+                        if segment_count > super_count { None } else { Some(super_count) };\n+\n+                    Qualified::With { path: qualifier, resolution: res, super_chain_len }\n                 }\n-                _ => None,\n             };\n-            if let Some(top) = top_node {\n-                if let Some(NodeOrToken::Node(error_node)) =\n-                    syntax::algo::non_trivia_sibling(top.clone().into(), syntax::Direction::Prev)\n-                {\n-                    if error_node.kind() == SyntaxKind::ERROR {\n-                        qualifier_ctx.unsafe_tok = error_node\n-                            .children_with_tokens()\n-                            .filter_map(NodeOrToken::into_token)\n-                            .find(|it| it.kind() == T![unsafe]);\n-                        qualifier_ctx.vis_node =\n-                            error_node.children().find_map(ast::Visibility::cast);\n+        }\n+    } else if let Some(segment) = path.segment() {\n+        if segment.coloncolon_token().is_some() {\n+            path_ctx.qualified = Qualified::Absolute;\n+        }\n+    }\n+\n+    let mut qualifier_ctx = QualifierCtx::default();\n+    if path_ctx.is_trivial_path() {\n+        // fetch the full expression that may have qualifiers attached to it\n+        let top_node = match path_ctx.kind {\n+            PathKind::Expr { expr_ctx: ExprCtx { in_block_expr: true, .. } } => {\n+                parent.ancestors().find(|it| ast::PathExpr::can_cast(it.kind())).and_then(|p| {\n+                    let parent = p.parent()?;\n+                    if ast::StmtList::can_cast(parent.kind()) {\n+                        Some(p)\n+                    } else if ast::ExprStmt::can_cast(parent.kind()) {\n+                        Some(parent)\n+                    } else {\n+                        None\n                     }\n+                })\n+            }\n+            PathKind::Item { .. } => {\n+                parent.ancestors().find(|it| ast::MacroCall::can_cast(it.kind()))\n+            }\n+            _ => None,\n+        };\n+        if let Some(top) = top_node {\n+            if let Some(NodeOrToken::Node(error_node)) =\n+                syntax::algo::non_trivia_sibling(top.clone().into(), syntax::Direction::Prev)\n+            {\n+                if error_node.kind() == SyntaxKind::ERROR {\n+                    qualifier_ctx.unsafe_tok = error_node\n+                        .children_with_tokens()\n+                        .filter_map(NodeOrToken::into_token)\n+                        .find(|it| it.kind() == T![unsafe]);\n+                    qualifier_ctx.vis_node = error_node.children().find_map(ast::Visibility::cast);\n                 }\n+            }\n \n-                if let PathKind::Item { .. } = path_ctx.kind {\n-                    if qualifier_ctx.none() {\n-                        if let Some(t) = top.first_token() {\n-                            if let Some(prev) = t\n-                                .prev_token()\n-                                .and_then(|t| syntax::algo::skip_trivia_token(t, Direction::Prev))\n-                            {\n-                                if ![T![;], T!['}'], T!['{']].contains(&prev.kind()) {\n-                                    // This was inferred to be an item position path, but it seems\n-                                    // to be part of some other broken node which leaked into an item\n-                                    // list\n-                                    return None;\n-                                }\n+            if let PathKind::Item { .. } = path_ctx.kind {\n+                if qualifier_ctx.none() {\n+                    if let Some(t) = top.first_token() {\n+                        if let Some(prev) = t\n+                            .prev_token()\n+                            .and_then(|t| syntax::algo::skip_trivia_token(t, Direction::Prev))\n+                        {\n+                            if ![T![;], T!['}'], T!['{']].contains(&prev.kind()) {\n+                                // This was inferred to be an item position path, but it seems\n+                                // to be part of some other broken node which leaked into an item\n+                                // list\n+                                return None;\n                             }\n                         }\n                     }\n                 }\n             }\n         }\n-        Some((NameRefContext { nameref, kind: NameRefKind::Path(path_ctx) }, qualifier_ctx))\n     }\n+    Some((NameRefContext { nameref, kind: NameRefKind::Path(path_ctx) }, qualifier_ctx))\n }\n \n fn pattern_context_for("}]}