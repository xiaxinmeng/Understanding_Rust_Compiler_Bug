{"sha": "81d20156cd44358e47e5081635f28ea31c01a757", "node_id": "MDY6Q29tbWl0NzI0NzEyOjgxZDIwMTU2Y2Q0NDM1OGU0N2U1MDgxNjM1ZjI4ZWEzMWMwMWE3NTc=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-11-16T03:37:29Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-11-16T20:06:44Z"}, "message": "Change spans to use byte offsets instead of char offsets", "tree": {"sha": "000e99c48bf31156f8574e9ea2d6830722503328", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/000e99c48bf31156f8574e9ea2d6830722503328"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/81d20156cd44358e47e5081635f28ea31c01a757", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/81d20156cd44358e47e5081635f28ea31c01a757", "html_url": "https://github.com/rust-lang/rust/commit/81d20156cd44358e47e5081635f28ea31c01a757", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/81d20156cd44358e47e5081635f28ea31c01a757/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8cba337cce19c71c4030f26fba2b00842172b99e", "url": "https://api.github.com/repos/rust-lang/rust/commits/8cba337cce19c71c4030f26fba2b00842172b99e", "html_url": "https://github.com/rust-lang/rust/commit/8cba337cce19c71c4030f26fba2b00842172b99e"}], "stats": {"total": 250, "additions": 161, "deletions": 89}, "files": [{"sha": "d4d1c8d3b2ecd6dae546d91ae766ac134aea2dfc", "filename": "src/librustc/middle/trans/debuginfo.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -112,7 +112,7 @@ type compile_unit_md = {name: ~str};\n type subprogram_md = {id: ast::node_id};\n type local_var_md = {id: ast::node_id};\n type tydesc_md = {hash: uint};\n-type block_md = {start: codemap::Loc<CharPos>, end: codemap::Loc<CharPos>};\n+type block_md = {start: codemap::Loc, end: codemap::Loc};\n type argument_md = {id: ast::node_id};\n type retval_md = {id: ast::node_id};\n "}, {"sha": "73a1c4b7530a028e696ec0594c9273970b4616f0", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -1,7 +1,7 @@\n-use codemap::{span, CharPos};\n+use codemap::{span, BytePos};\n use ast::*;\n \n-pure fn spanned<T>(+lo: CharPos, +hi: CharPos, +t: T) -> spanned<T> {\n+pure fn spanned<T>(+lo: BytePos, +hi: BytePos, +t: T) -> spanned<T> {\n     respan(mk_sp(lo, hi), move t)\n }\n \n@@ -14,12 +14,12 @@ pure fn dummy_spanned<T>(+t: T) -> spanned<T> {\n }\n \n /* assuming that we're not in macro expansion */\n-pure fn mk_sp(+lo: CharPos, +hi: CharPos) -> span {\n+pure fn mk_sp(+lo: BytePos, +hi: BytePos) -> span {\n     span {lo: lo, hi: hi, expn_info: None}\n }\n \n // make this a const, once the compiler supports it\n-pure fn dummy_sp() -> span { return mk_sp(CharPos(0), CharPos(0)); }\n+pure fn dummy_sp() -> span { return mk_sp(BytePos(0), BytePos(0)); }\n \n \n "}, {"sha": "da80e26b1afe95d9f1f7258dec3095b18a66449a", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -6,7 +6,7 @@ use either::Either;\n use diagnostic::span_handler;\n use ast_util::{spanned, dummy_spanned};\n use parse::comments::{doc_comment_style, strip_doc_comment_decoration};\n-use codemap::CharPos;\n+use codemap::BytePos;\n \n // Constructors\n export mk_name_value_item_str;\n@@ -76,7 +76,7 @@ fn mk_attr(item: @ast::meta_item) -> ast::attribute {\n }\n \n fn mk_sugared_doc_attr(text: ~str,\n-                       +lo: CharPos, +hi: CharPos) -> ast::attribute {\n+                       +lo: BytePos, +hi: BytePos) -> ast::attribute {\n     let lit = spanned(lo, hi, ast::lit_str(@text));\n     let attr = {\n         style: doc_comment_style(text),"}, {"sha": "13f2ea4e210a6b9ed79ade77af9c60e5c9149b37", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 106, "deletions": 39, "changes": 145, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -118,8 +118,8 @@ impl CharPos: to_bytes::IterBytes {\n }\n \n pub struct span {\n-    lo: CharPos,\n-    hi: CharPos,\n+    lo: BytePos,\n+    hi: BytePos,\n     expn_info: Option<@ExpnInfo>\n }\n \n@@ -141,8 +141,10 @@ impl<D: Deserializer> span: Deserializable<D> {\n     }\n }\n \n-pub struct Loc<A: Pos> {\n-    file: @FileMap, line: uint, col: A\n+// XXX col shouldn't be CharPos because col is not an absolute location in the\n+// codemap, and BytePos and CharPos always represent absolute positions\n+pub struct Loc {\n+    file: @FileMap, line: uint, col: CharPos\n }\n \n /// An absolute offset within the CodeMap (not a relative offset within a\n@@ -178,12 +180,24 @@ pub enum FileSubstr {\n     pub FssExternal({filename: ~str, line: uint, col: CharPos})\n }\n \n+/// Identifies an offset of a multi-byte character in a FileMap\n+pub struct MultiByteChar {\n+    /// The absolute offset of the character in the CodeMap\n+    pos: BytePos,\n+    /// The number of bytes, >=2\n+    bytes: uint,\n+    /// The complete number of 'extra' bytes through this character in the\n+    /// FileMap\n+    sum: uint\n+}\n+\n pub struct FileMap {\n     name: FileName,\n     substr: FileSubstr,\n     src: @~str,\n     start_pos: FilePos,\n-    mut lines: ~[FilePos]\n+    mut lines: ~[FilePos],\n+    multibyte_chars: DVec<MultiByteChar>\n }\n \n pub impl FileMap {\n@@ -194,7 +208,8 @@ pub impl FileMap {\n         return FileMap {\n             name: filename, substr: substr, src: src,\n             start_pos: start_pos,\n-            mut lines: ~[]\n+            mut lines: ~[],\n+            multibyte_chars: DVec()\n         };\n     }\n \n@@ -219,6 +234,21 @@ pub impl FileMap {\n         str::slice(*self.src, begin, end)\n     }\n \n+    pub fn record_multibyte_char(&self, pos: BytePos, bytes: uint) {\n+        assert bytes >=2 && bytes <= 4;\n+        let sum = if self.multibyte_chars.len() > 0 {\n+            self.multibyte_chars.last().sum\n+        } else {\n+            0\n+        };\n+        let sum = sum + bytes;\n+        let mbc = MultiByteChar {\n+            pos: pos,\n+            bytes: bytes,\n+            sum: sum\n+        };\n+        self.multibyte_chars.push(mbc);\n+    }\n }\n \n pub struct CodeMap {\n@@ -254,12 +284,11 @@ pub impl CodeMap {\n                     pos.line, pos.col.to_uint());\n     }\n \n-    pub fn lookup_char_pos(&self, +pos: CharPos) -> Loc<CharPos> {\n-        pure fn lookup(pos: FilePos) -> uint { return pos.ch.to_uint(); }\n-        return self.lookup_pos(pos, lookup);\n+    pub fn lookup_char_pos(&self, +pos: BytePos) -> Loc {\n+        return self.lookup_pos(pos);\n     }\n \n-    pub fn lookup_char_pos_adj(&self, +pos: CharPos)\n+    pub fn lookup_char_pos_adj(&self, +pos: BytePos)\n         -> {filename: ~str, line: uint, col: CharPos, file: Option<@FileMap>}\n     {\n         let loc = self.lookup_char_pos(pos);\n@@ -272,7 +301,7 @@ pub impl CodeMap {\n             }\n             FssInternal(sp) => {\n                 self.lookup_char_pos_adj(\n-                    sp.lo + (pos - loc.file.start_pos.ch))\n+                    sp.lo + (pos - loc.file.start_pos.byte))\n             }\n             FssExternal(eloc) => {\n                 {filename: /* FIXME (#2543) */ copy eloc.filename,\n@@ -284,14 +313,13 @@ pub impl CodeMap {\n     }\n \n     pub fn adjust_span(&self, sp: span) -> span {\n-        pure fn lookup(pos: FilePos) -> uint { return pos.ch.to_uint(); }\n-        let line = self.lookup_line(sp.lo, lookup);\n+        let line = self.lookup_line(sp.lo);\n         match (line.fm.substr) {\n             FssNone => sp,\n             FssInternal(s) => {\n                 self.adjust_span(span {\n-                    lo: s.lo + (sp.lo - line.fm.start_pos.ch),\n-                    hi: s.lo + (sp.hi - line.fm.start_pos.ch),\n+                    lo: s.lo + (sp.lo - line.fm.start_pos.byte),\n+                    hi: s.lo + (sp.hi - line.fm.start_pos.byte),\n                     expn_info: sp.expn_info\n                 })\n             }\n@@ -321,18 +349,6 @@ pub impl CodeMap {\n         return @FileLines {file: lo.file, lines: lines};\n     }\n \n-    fn lookup_byte_offset(&self, +chpos: CharPos)\n-        -> {fm: @FileMap, pos: BytePos} {\n-        pure fn lookup(pos: FilePos) -> uint { return pos.ch.to_uint(); }\n-        let {fm, line} = self.lookup_line(chpos, lookup);\n-        let line_offset = fm.lines[line].byte - fm.start_pos.byte;\n-        let col = chpos - fm.lines[line].ch;\n-        let col_offset = str::count_bytes(*fm.src,\n-                                          line_offset.to_uint(),\n-                                          col.to_uint());\n-        {fm: fm, pos: line_offset + BytePos(col_offset)}\n-    }\n-\n     pub fn span_to_snippet(&self, sp: span) -> ~str {\n         let begin = self.lookup_byte_offset(sp.lo);\n         let end = self.lookup_byte_offset(sp.hi);\n@@ -351,15 +367,14 @@ pub impl CodeMap {\n }\n \n priv impl CodeMap {\n-    fn lookup_line<A: Pos>(&self, pos: A, lookup: LookupFn)\n-        -> {fm: @FileMap, line: uint}\n-    {\n+\n+    fn lookup_filemap_idx(&self, +pos: BytePos) -> uint {\n         let len = self.files.len();\n         let mut a = 0u;\n         let mut b = len;\n         while b - a > 1u {\n             let m = (a + b) / 2u;\n-            if lookup(self.files[m].start_pos) > pos.to_uint() {\n+            if self.files[m].start_pos.byte > pos {\n                 b = m;\n             } else {\n                 a = m;\n@@ -369,22 +384,40 @@ priv impl CodeMap {\n             fail fmt!(\"position %u does not resolve to a source location\",\n                       pos.to_uint())\n         }\n-        let f = self.files[a];\n-        a = 0u;\n-        b = vec::len(f.lines);\n+\n+        return a;\n+    }\n+\n+    fn lookup_line(&self, +pos: BytePos)\n+        -> {fm: @FileMap, line: uint}\n+    {\n+        let idx = self.lookup_filemap_idx(pos);\n+        let f = self.files[idx];\n+        let mut a = 0u;\n+        let mut b = vec::len(f.lines);\n         while b - a > 1u {\n             let m = (a + b) / 2u;\n-            if lookup(f.lines[m]) > pos.to_uint() { b = m; } else { a = m; }\n+            if f.lines[m].byte > pos { b = m; } else { a = m; }\n         }\n         return {fm: f, line: a};\n     }\n \n-    fn lookup_pos<A: Pos Num>(&self, pos: A, lookup: LookupFn) -> Loc<A> {\n-        let {fm: f, line: a} = self.lookup_line(pos, lookup);\n+    fn lookup_pos(&self, +pos: BytePos) -> Loc {\n+        let {fm: f, line: a} = self.lookup_line(pos);\n+        let line = a + 1u; // Line numbers start at 1\n+        let chpos = self.bytepos_to_local_charpos(pos);\n+        let linebpos = f.lines[a].byte;\n+        let linechpos = self.bytepos_to_local_charpos(linebpos);\n+        debug!(\"codemap: byte pos %? is on the line at byte pos %?\",\n+               pos, linebpos);\n+        debug!(\"codemap: char pos %? is on the line at char pos %?\",\n+               chpos, linechpos);\n+        debug!(\"codemap: byte is on line: %?\", line);\n+        assert chpos >= linechpos;\n         return Loc {\n             file: f,\n-            line: a + 1u,\n-            col: pos - from_uint(lookup(f.lines[a]))\n+            line: line,\n+            col: chpos - linechpos\n         };\n     }\n \n@@ -394,6 +427,40 @@ priv impl CodeMap {\n         return fmt!(\"%s:%u:%u: %u:%u\", lo.file.name,\n                     lo.line, lo.col.to_uint(), hi.line, hi.col.to_uint())\n     }\n+\n+    fn lookup_byte_offset(&self, +bpos: BytePos)\n+        -> {fm: @FileMap, pos: BytePos} {\n+        let idx = self.lookup_filemap_idx(bpos);\n+        let fm = self.files[idx];\n+        let offset = bpos - fm.start_pos.byte;\n+        return {fm: fm, pos: offset};\n+    }\n+\n+    // Converts an absolute BytePos to a CharPos relative to the file it is\n+    // located in\n+    fn bytepos_to_local_charpos(&self, +bpos: BytePos) -> CharPos {\n+        debug!(\"codemap: converting %? to char pos\", bpos);\n+        let idx = self.lookup_filemap_idx(bpos);\n+        let map = self.files[idx];\n+\n+        // The number of extra bytes due to multibyte chars in the FileMap\n+        let mut total_extra_bytes = 0;\n+\n+        for map.multibyte_chars.each |mbc| {\n+            debug!(\"codemap: %?-byte char at %?\", mbc.bytes, mbc.pos);\n+            if mbc.pos < bpos {\n+                total_extra_bytes += mbc.bytes;\n+                // We should never see a byte position in the middle of a\n+                // character\n+                assert bpos == mbc.pos\n+                    || bpos.to_uint() >= mbc.pos.to_uint() + mbc.bytes;\n+            } else {\n+                break;\n+            }\n+        }\n+\n+        CharPos(bpos.to_uint() - total_extra_bytes)\n+    }\n }\n \n //"}, {"sha": "888932e58e7138b76e59e69b229a6ad347beea45", "filename": "src/libsyntax/ext/qquote.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fext%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fext%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fqquote.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -4,7 +4,7 @@ use parse::parser;\n use parse::parser::{Parser, parse_from_source_str};\n use dvec::DVec;\n use parse::token::ident_interner;\n-use codemap::CharPos;\n+use codemap::{CharPos, BytePos};\n \n use fold::*;\n use visit::*;\n@@ -16,13 +16,13 @@ use io::*;\n use codemap::span;\n \n struct gather_item {\n-    lo: CharPos,\n-    hi: CharPos,\n+    lo: BytePos,\n+    hi: BytePos,\n     e: @ast::expr,\n     constr: ~str\n }\n \n-type aq_ctxt = @{lo: CharPos, gather: DVec<gather_item>};\n+type aq_ctxt = @{lo: BytePos, gather: DVec<gather_item>};\n enum fragment {\n     from_expr(@ast::expr),\n     from_ty(@ast::Ty)\n@@ -115,7 +115,7 @@ impl @ast::pat: qq_helper {\n     fn get_fold_fn() -> ~str {~\"fold_pat\"}\n }\n \n-fn gather_anti_quotes<N: qq_helper>(lo: CharPos, node: N) -> aq_ctxt\n+fn gather_anti_quotes<N: qq_helper>(lo: BytePos, node: N) -> aq_ctxt\n {\n     let v = @{visit_expr: |node, &&cx, v| visit_aq(node, ~\"from_expr\", cx, v),\n               visit_ty: |node, &&cx, v| visit_aq(node, ~\"from_ty\", cx, v),\n@@ -227,7 +227,7 @@ fn finish<T: qq_helper>\n     let mut str2 = ~\"\";\n     enum state {active, skip(uint), blank};\n     let mut state = active;\n-    let mut i = CharPos(0u);\n+    let mut i = BytePos(0u);\n     let mut j = 0u;\n     let g_len = cx.gather.len();\n     for str::chars_each(*str) |ch| {\n@@ -244,7 +244,7 @@ fn finish<T: qq_helper>\n           blank if is_space(ch) => str::push_char(&mut str2, ch),\n           blank => str::push_char(&mut str2, ' ')\n         }\n-        i += CharPos(1u);\n+        i += BytePos(1u);\n         if (j < g_len && i == cx.gather[j].hi) {\n             assert ch == ')';\n             state = active;"}, {"sha": "6779ed263d5a8a574f37b9d028edefcbc8630d41", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -11,7 +11,7 @@ use dvec::DVec;\n use ast::{matcher, match_tok, match_seq, match_nonterminal, ident};\n use ast_util::mk_sp;\n use std::map::HashMap;\n-use codemap::CharPos;\n+use codemap::BytePos;\n \n /* This is an Earley-like parser, without support for in-grammar nonterminals,\n only by calling out to the main rust parser for named nonterminals (which it\n@@ -103,7 +103,7 @@ type matcher_pos = ~{\n     mut up: matcher_pos_up, // mutable for swapping only\n     matches: ~[DVec<@named_match>],\n     match_lo: uint, match_hi: uint,\n-    sp_lo: CharPos,\n+    sp_lo: BytePos,\n };\n \n fn copy_up(&& mpu: matcher_pos_up) -> matcher_pos {\n@@ -123,7 +123,7 @@ fn count_names(ms: &[matcher]) -> uint {\n }\n \n #[allow(non_implicitly_copyable_typarams)]\n-fn initial_matcher_pos(ms: ~[matcher], sep: Option<Token>, lo: CharPos)\n+fn initial_matcher_pos(ms: ~[matcher], sep: Option<Token>, lo: BytePos)\n     -> matcher_pos {\n     let mut match_idx_hi = 0u;\n     for ms.each() |elt| {"}, {"sha": "f0cb1d4ba3e1c6e58948c8d9a43bcaecbcd38342", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -14,7 +14,7 @@ trait parser_attr {\n         -> attr_or_ext;\n     fn parse_outer_attributes() -> ~[ast::attribute];\n     fn parse_attribute(style: ast::attr_style) -> ast::attribute;\n-    fn parse_attribute_naked(style: ast::attr_style, lo: CharPos) ->\n+    fn parse_attribute_naked(style: ast::attr_style, lo: BytePos) ->\n         ast::attribute;\n     fn parse_inner_attrs_and_next() ->\n         {inner: ~[ast::attribute], next: ~[ast::attribute]};\n@@ -85,7 +85,7 @@ impl Parser: parser_attr {\n         return self.parse_attribute_naked(style, lo);\n     }\n \n-    fn parse_attribute_naked(style: ast::attr_style, lo: CharPos) ->\n+    fn parse_attribute_naked(style: ast::attr_style, lo: BytePos) ->\n         ast::attribute {\n         self.expect(token::LBRACKET);\n         let meta_item = self.parse_meta_item();"}, {"sha": "589a5f25ecfaace962a9ea325e4a1f9c5be5b6e6", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -28,7 +28,7 @@ impl cmnt_style : cmp::Eq {\n     }\n }\n \n-type cmnt = {style: cmnt_style, lines: ~[~str], pos: CharPos};\n+type cmnt = {style: cmnt_style, lines: ~[~str], pos: BytePos};\n \n fn is_doc_comment(s: ~str) -> bool {\n     s.starts_with(~\"///\") ||\n@@ -131,7 +131,7 @@ fn consume_non_eol_whitespace(rdr: string_reader) {\n fn push_blank_line_comment(rdr: string_reader, comments: &mut ~[cmnt]) {\n     debug!(\">>> blank-line comment\");\n     let v: ~[~str] = ~[];\n-    comments.push({style: blank_line, lines: v, pos: rdr.last_pos.ch});\n+    comments.push({style: blank_line, lines: v, pos: rdr.last_pos.byte});\n }\n \n fn consume_whitespace_counting_blank_lines(rdr: string_reader,\n@@ -148,7 +148,7 @@ fn consume_whitespace_counting_blank_lines(rdr: string_reader,\n fn read_shebang_comment(rdr: string_reader, code_to_the_left: bool,\n                                             comments: &mut ~[cmnt]) {\n     debug!(\">>> shebang comment\");\n-    let p = rdr.last_pos.ch;\n+    let p = rdr.last_pos.byte;\n     debug!(\"<<< shebang comment\");\n     comments.push({\n         style: if code_to_the_left { trailing } else { isolated },\n@@ -160,7 +160,7 @@ fn read_shebang_comment(rdr: string_reader, code_to_the_left: bool,\n fn read_line_comments(rdr: string_reader, code_to_the_left: bool,\n                                           comments: &mut ~[cmnt]) {\n     debug!(\">>> line comments\");\n-    let p = rdr.last_pos.ch;\n+    let p = rdr.last_pos.byte;\n     let mut lines: ~[~str] = ~[];\n     while rdr.curr == '/' && nextch(rdr) == '/' {\n         let line = read_one_line_comment(rdr);\n@@ -209,7 +209,7 @@ fn trim_whitespace_prefix_and_push_line(lines: &mut ~[~str],\n fn read_block_comment(rdr: string_reader, code_to_the_left: bool,\n                                           comments: &mut ~[cmnt]) {\n     debug!(\">>> block comment\");\n-    let p = rdr.last_pos.ch;\n+    let p = rdr.last_pos.byte;\n     let mut lines: ~[~str] = ~[];\n     let mut col: CharPos = rdr.col;\n     bump(rdr);\n@@ -284,7 +284,7 @@ fn consume_comment(rdr: string_reader, code_to_the_left: bool,\n     debug!(\"<<< consume comment\");\n }\n \n-type lit = {lit: ~str, pos: CharPos};\n+type lit = {lit: ~str, pos: BytePos};\n \n fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n                                 path: ~str,"}, {"sha": "1811951fc0e9a8496497a4f3a1386e11be4cd636", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -205,7 +205,7 @@ impl Parser: parser_common {\n         if self.token == token::GT {\n             self.bump();\n         } else if self.token == token::BINOP(token::SHR) {\n-            self.swap(token::GT, self.span.lo + CharPos(1u), self.span.hi);\n+            self.swap(token::GT, self.span.lo + BytePos(1u), self.span.hi);\n         } else {\n             let mut s: ~str = ~\"expected `\";\n             s += token_to_str(self.reader, token::GT);"}, {"sha": "00a0b40ab65f8f1962fc89f88443b228ca98c74a", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 13, "deletions": 8, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -23,7 +23,7 @@ type string_reader = @{\n     src: @~str,\n     // The absolute offset within the codemap of the next character to read\n     mut pos: FilePos,\n-    // The absolute offset within the codemap of the last character to be read (curr)\n+    // The absolute offset within the codemap of the last character read(curr)\n     mut last_pos: FilePos,\n     // The column of the next character to read\n     mut col: CharPos,\n@@ -123,9 +123,9 @@ fn string_advance_token(&&r: string_reader) {\n     if is_eof(r) {\n         r.peek_tok = token::EOF;\n     } else {\n-        let start_chpos = r.last_pos.ch;\n+        let start_bytepos = r.last_pos.byte;\n         r.peek_tok = next_token_inner(r);\n-        r.peek_span = ast_util::mk_sp(start_chpos, r.last_pos.ch);\n+        r.peek_span = ast_util::mk_sp(start_bytepos, r.last_pos.byte);\n     };\n \n }\n@@ -158,6 +158,11 @@ fn bump(rdr: string_reader) {\n             rdr.filemap.next_line(rdr.last_pos);\n             rdr.col = CharPos(0u);\n         }\n+\n+        if byte_offset_diff > 1 {\n+            rdr.filemap.record_multibyte_char(\n+                BytePos(current_byte_offset), byte_offset_diff);\n+        }\n     } else {\n         // XXX: What does this accomplish?\n         if (rdr.curr != -1 as char) {\n@@ -233,15 +238,15 @@ fn consume_any_line_comment(rdr: string_reader)\n             bump(rdr);\n             // line comments starting with \"///\" or \"//!\" are doc-comments\n             if rdr.curr == '/' || rdr.curr == '!' {\n-                let start_chpos = rdr.pos.ch - CharPos(2u);\n+                let start_bpos = rdr.pos.byte - BytePos(2u);\n                 let mut acc = ~\"//\";\n                 while rdr.curr != '\\n' && !is_eof(rdr) {\n                     str::push_char(&mut acc, rdr.curr);\n                     bump(rdr);\n                 }\n                 return Some({\n                     tok: token::DOC_COMMENT(rdr.interner.intern(@acc)),\n-                    sp: ast_util::mk_sp(start_chpos, rdr.pos.ch)\n+                    sp: ast_util::mk_sp(start_bpos, rdr.pos.byte)\n                 });\n             } else {\n                 while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n@@ -256,7 +261,7 @@ fn consume_any_line_comment(rdr: string_reader)\n         if nextch(rdr) == '!' {\n             let cmap = @CodeMap::new();\n             (*cmap).files.push(rdr.filemap);\n-            let loc = cmap.lookup_char_pos_adj(rdr.last_pos.ch);\n+            let loc = cmap.lookup_char_pos_adj(rdr.last_pos.byte);\n             if loc.line == 1u && loc.col == CharPos(0u) {\n                 while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n                 return consume_whitespace_and_comments(rdr);\n@@ -272,7 +277,7 @@ fn consume_block_comment(rdr: string_reader)\n \n     // block comments starting with \"/**\" or \"/*!\" are doc-comments\n     if rdr.curr == '*' || rdr.curr == '!' {\n-        let start_chpos = rdr.pos.ch - CharPos(2u);\n+        let start_bpos = rdr.pos.byte - BytePos(2u);\n         let mut acc = ~\"/*\";\n         while !(rdr.curr == '*' && nextch(rdr) == '/') && !is_eof(rdr) {\n             str::push_char(&mut acc, rdr.curr);\n@@ -286,7 +291,7 @@ fn consume_block_comment(rdr: string_reader)\n             bump(rdr);\n             return Some({\n                 tok: token::DOC_COMMENT(rdr.interner.intern(@acc)),\n-                sp: ast_util::mk_sp(start_chpos, rdr.pos.ch)\n+                sp: ast_util::mk_sp(start_bpos, rdr.pos.byte)\n             });\n         }\n     } else {"}, {"sha": "74d06789ad8995c34a3be35789b620791aa8badb", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -5,7 +5,7 @@ use either::{Either, Left, Right};\n use std::map::HashMap;\n use token::{can_begin_expr, is_ident, is_ident_or_path, is_plain_ident,\n             INTERPOLATED, special_idents};\n-use codemap::{span,FssNone, CharPos};\n+use codemap::{span,FssNone, BytePos};\n use util::interner::Interner;\n use ast_util::{spanned, respan, mk_sp, ident_to_path, operator_prec};\n use lexer::reader;\n@@ -244,7 +244,7 @@ impl Parser {\n         self.token = next.tok;\n         self.span = next.sp;\n     }\n-    fn swap(next: token::Token, +lo: CharPos, +hi: CharPos) {\n+    fn swap(next: token::Token, +lo: BytePos, +hi: BytePos) {\n         self.token = next;\n         self.span = mk_sp(lo, hi);\n     }\n@@ -904,12 +904,12 @@ impl Parser {\n         return spanned(lo, e.span.hi, {mutbl: m, ident: i, expr: e});\n     }\n \n-    fn mk_expr(+lo: CharPos, +hi: CharPos, +node: expr_) -> @expr {\n+    fn mk_expr(+lo: BytePos, +hi: BytePos, +node: expr_) -> @expr {\n         return @{id: self.get_id(), callee_id: self.get_id(),\n               node: node, span: mk_sp(lo, hi)};\n     }\n \n-    fn mk_mac_expr(+lo: CharPos, +hi: CharPos, m: mac_) -> @expr {\n+    fn mk_mac_expr(+lo: BytePos, +hi: BytePos, m: mac_) -> @expr {\n         return @{id: self.get_id(),\n               callee_id: self.get_id(),\n               node: expr_mac({node: m, span: mk_sp(lo, hi)}),\n@@ -1134,7 +1134,7 @@ impl Parser {\n         return self.mk_expr(lo, hi, ex);\n     }\n \n-    fn parse_block_expr(lo: CharPos, blk_mode: blk_check_mode) -> @expr {\n+    fn parse_block_expr(lo: BytePos, blk_mode: blk_check_mode) -> @expr {\n         self.expect(token::LBRACE);\n         let blk = self.parse_block_tail(lo, blk_mode);\n         return self.mk_expr(blk.span.lo, blk.span.hi, expr_block(blk));\n@@ -1146,7 +1146,7 @@ impl Parser {\n         return self.parse_syntax_ext_naked(lo);\n     }\n \n-    fn parse_syntax_ext_naked(lo: CharPos) -> @expr {\n+    fn parse_syntax_ext_naked(lo: BytePos) -> @expr {\n         match self.token {\n           token::IDENT(_, _) => (),\n           _ => self.fatal(~\"expected a syntax expander name\")\n@@ -2279,11 +2279,11 @@ impl Parser {\n     // I guess that also means \"already parsed the 'impure'\" if\n     // necessary, and this should take a qualifier.\n     // some blocks start with \"#{\"...\n-    fn parse_block_tail(lo: CharPos, s: blk_check_mode) -> blk {\n+    fn parse_block_tail(lo: BytePos, s: blk_check_mode) -> blk {\n         self.parse_block_tail_(lo, s, ~[])\n     }\n \n-    fn parse_block_tail_(lo: CharPos, s: blk_check_mode,\n+    fn parse_block_tail_(lo: BytePos, s: blk_check_mode,\n                          +first_item_attrs: ~[attribute]) -> blk {\n         let mut stmts = ~[];\n         let mut expr = None;\n@@ -2581,7 +2581,7 @@ impl Parser {\n         return {ident: id, tps: ty_params};\n     }\n \n-    fn mk_item(+lo: CharPos, +hi: CharPos, +ident: ident,\n+    fn mk_item(+lo: BytePos, +hi: BytePos, +ident: ident,\n                +node: item_, vis: visibility,\n                +attrs: ~[attribute]) -> @item {\n         return @{ident: ident,\n@@ -3037,7 +3037,7 @@ impl Parser {\n             items: items};\n     }\n \n-    fn parse_item_foreign_mod(lo: CharPos,\n+    fn parse_item_foreign_mod(lo: BytePos,\n                               visibility: visibility,\n                               attrs: ~[attribute],\n                               items_allowed: bool)\n@@ -3092,7 +3092,7 @@ impl Parser {\n         });\n     }\n \n-    fn parse_type_decl() -> {lo: CharPos, ident: ident} {\n+    fn parse_type_decl() -> {lo: BytePos, ident: ident} {\n         let lo = self.last_span.lo;\n         let id = self.parse_ident();\n         return {lo: lo, ident: id};"}, {"sha": "949d2defa9a2aa315ecb858d9a5ba25c26860565", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81d20156cd44358e47e5081635f28ea31c01a757/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=81d20156cd44358e47e5081635f28ea31c01a757", "patch": "@@ -1,5 +1,5 @@\n use parse::{comments, lexer, token};\n-use codemap::{CodeMap, CharPos};\n+use codemap::{CodeMap, BytePos};\n use pp::{break_offset, word, printer, space, zerobreak, hardbreak, breaks};\n use pp::{consistent, inconsistent, eof};\n use ast::{required, provided};\n@@ -1898,15 +1898,15 @@ fn print_ty_fn(s: ps,\n }\n \n fn maybe_print_trailing_comment(s: ps, span: codemap::span,\n-                                next_pos: Option<CharPos>) {\n+                                next_pos: Option<BytePos>) {\n     let mut cm;\n     match s.cm { Some(ccm) => cm = ccm, _ => return }\n     match next_comment(s) {\n       Some(cmnt) => {\n         if cmnt.style != comments::trailing { return; }\n         let span_line = cm.lookup_char_pos(span.hi);\n         let comment_line = cm.lookup_char_pos(cmnt.pos);\n-        let mut next = cmnt.pos + CharPos(1u);\n+        let mut next = cmnt.pos + BytePos(1u);\n         match next_pos { None => (), Some(p) => next = p }\n         if span.hi < cmnt.pos && cmnt.pos < next &&\n                span_line.line == comment_line.line {\n@@ -1981,7 +1981,7 @@ fn lit_to_str(l: @ast::lit) -> ~str {\n     return to_str(l, print_literal, parse::token::mk_fake_ident_interner());\n }\n \n-fn next_lit(s: ps, pos: CharPos) -> Option<comments::lit> {\n+fn next_lit(s: ps, pos: BytePos) -> Option<comments::lit> {\n     match s.literals {\n       Some(lits) => {\n         while s.cur_lit < vec::len(lits) {\n@@ -1996,7 +1996,7 @@ fn next_lit(s: ps, pos: CharPos) -> Option<comments::lit> {\n     }\n }\n \n-fn maybe_print_comment(s: ps, pos: CharPos) {\n+fn maybe_print_comment(s: ps, pos: BytePos) {\n     loop {\n         match next_comment(s) {\n           Some(cmnt) => {"}]}