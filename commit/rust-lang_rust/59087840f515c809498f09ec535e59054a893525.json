{"sha": "59087840f515c809498f09ec535e59054a893525", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU5MDg3ODQwZjUxNWM4MDk0OThmMDllYzUzNWU1OTA1NGE4OTM1MjU=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2018-02-11T14:58:22Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2018-02-11T14:58:22Z"}, "message": "Document how the parsing works", "tree": {"sha": "282e1f9606dbeeba6c19a2dcd6ff94da420d155a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/282e1f9606dbeeba6c19a2dcd6ff94da420d155a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/59087840f515c809498f09ec535e59054a893525", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/59087840f515c809498f09ec535e59054a893525", "html_url": "https://github.com/rust-lang/rust/commit/59087840f515c809498f09ec535e59054a893525", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/59087840f515c809498f09ec535e59054a893525/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9e2c0564783aa91f6440e7cadcc1a4dfda785de0", "url": "https://api.github.com/repos/rust-lang/rust/commits/9e2c0564783aa91f6440e7cadcc1a4dfda785de0", "html_url": "https://github.com/rust-lang/rust/commit/9e2c0564783aa91f6440e7cadcc1a4dfda785de0"}], "stats": {"total": 116, "additions": 91, "deletions": 25}, "files": [{"sha": "6b4434396aaa4a976b30e0f14d1708ca2233e589", "filename": "docs/ARCHITECTURE.md", "status": "modified", "additions": 9, "deletions": 12, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/59087840f515c809498f09ec535e59054a893525/docs%2FARCHITECTURE.md", "raw_url": "https://github.com/rust-lang/rust/raw/59087840f515c809498f09ec535e59054a893525/docs%2FARCHITECTURE.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2FARCHITECTURE.md?ref=59087840f515c809498f09ec535e59054a893525", "patch": "@@ -33,19 +33,22 @@ The centerpiece of this whole endeavor is the syntax tree, in the\n \n The syntax tree is produced using a three-staged process. \n \n-First, a raw text is split into tokens with a lexer. Lexer has a\n-peculiar signature: it is an `Fn(&str) -> Token`, where token is a\n-pair of `SyntaxKind` (you should have read the `tree` module and RFC\n+First, a raw text is split into tokens with a lexer (the `lexer` module).\n+Lexer has a peculiar signature: it is an `Fn(&str) -> Token`, where token \n+is a pair of `SyntaxKind` (you should have read the `tree` module and RFC\n by this time! :)) and a len. That is, lexer chomps only the first\n token of the input. This forces the lexer to be stateless, and makes\n it possible to implement incremental relexing easily.\n \n Then, the bulk of work, the parser turns a stream of tokens into\n-stream of events. Not that parser **does not** construct a tree right\n-away. This is done for several reasons:\n+stream of events (the `parser` module; of particular interest are \n+the `parser/event` and `parser/parser` modules, which contain parsing \n+API, and the `parser/grammar` module, which contains actual parsing code\n+for various Rust syntactic constructs). Not that parser **does not** \n+construct a tree right away. This is done for several reasons:\n \n * to decouple the actual tree data structure from the parser: you can\n-  build any datastructre you want from the stream of events\n+  build any data structure you want from the stream of events\n   \n * to make parsing fast: you can produce a list of events without\n   allocations\n@@ -77,12 +80,6 @@ And at last, the TreeBuilder converts a flat stream of events into a\n tree structure. It also *should* be responsible for attaching comments\n and rebalancing the tree, but it does not do this yet :) \n \n-\n-## Error reporing\n-\n-TODO: describe how stuff like `skip_to_first` works\n-\n-\n ## Validator\n \n Parser and lexer accept a lot of *invalid* code intentionally. The"}, {"sha": "4af16d783b6ee0f4e3db197762b67f781061015f", "filename": "src/parser/event.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fevent.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fevent.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fparser%2Fevent.rs?ref=59087840f515c809498f09ec535e59054a893525", "patch": "@@ -42,7 +42,7 @@ pub(crate) enum Event {\n     ///    |\n     ///   'foo'\n     ///\n-    /// See also `CompleteMarker::precede`.\n+    /// See also `CompletedMarker::precede`.\n     Start {\n         kind: SyntaxKind,\n         forward_parent: Option<u32>,"}, {"sha": "ee0263203e7b78e4a79628f6480fde52d6a50284", "filename": "src/parser/grammar/mod.rs", "status": "modified", "additions": 24, "deletions": 1, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fgrammar%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fgrammar%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fparser%2Fgrammar%2Fmod.rs?ref=59087840f515c809498f09ec535e59054a893525", "patch": "@@ -1,4 +1,27 @@\n-use parser::parser::{Parser};\n+//! This is the actual \"grammar\" of the Rust language.\n+//!\n+//! Each function in this module and its children corresponds\n+//! to a production of the format grammar. Submodules roughly\n+//! correspond to different *areas* of the grammar. By convention,\n+//! each submodule starts with `use super::*` import and exports\n+//! \"public\" productions via `pub(super)`.\n+//!\n+//! See docs for `Parser` to learn about API, available to the grammar,\n+//! and see docs for `Event` to learn how this actually manages to\n+//! produce parse trees.\n+//!\n+//! Code in this module also contains inline tests, which start with\n+//! `// test name-of-the-test` comment and look like this:\n+//!\n+//! ```\n+//! // test fn_item_with_zero_parameters\n+//! // fn foo() {}\n+//! ```\n+//!\n+//! After adding a new inline-test, run `cargo collect-tests` to extract\n+//! it as a standalone text-fixture into `tests/data/parser/inline`, and\n+//! run `cargo test` once to create the \"gold\" value.\n+use parser::parser::Parser;\n use parser::token_set::TokenSet;\n use SyntaxKind;\n use syntax_kinds::*;"}, {"sha": "03c0440913dd0cae449010afd2234ee51e0de9ec", "filename": "src/parser/parser/imp.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fparser%2Fimp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fparser%2Fimp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fparser%2Fparser%2Fimp.rs?ref=59087840f515c809498f09ec535e59054a893525", "patch": "@@ -4,6 +4,9 @@ use parser::event::Event;\n use SyntaxKind;\n use syntax_kinds::{TOMBSTONE, EOF};\n \n+/// Implementation details of `Parser`, extracted\n+/// to a separate struct in order not to pollute\n+/// the public API of the `Parser`.\n pub(crate) struct ParserImpl<'t> {\n     inp: &'t ParserInput<'t>,\n "}, {"sha": "618b439be506719f29b96fbc3be44e94f49067e1", "filename": "src/parser/parser/mod.rs", "status": "modified", "additions": 54, "deletions": 11, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59087840f515c809498f09ec535e59054a893525/src%2Fparser%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fparser%2Fparser%2Fmod.rs?ref=59087840f515c809498f09ec535e59054a893525", "patch": "@@ -4,51 +4,72 @@ use syntax_kinds::ERROR;\n pub(super) mod imp;\n use self::imp::ParserImpl;\n \n+/// `Parser` struct provides the low-level API for\n+/// navigating through the stream of tokens and\n+/// constructing the parse tree. The actual parsing\n+/// happens in the `grammar` module.\n+///\n+/// However, the result of this `Parser` is not a real\n+/// tree, but rather a flat stream of events of the form\n+/// \"start expression, consume number literal,\n+/// finish expression\". See `Event` docs for more.\n pub(crate) struct Parser<'t>(pub(super) ParserImpl<'t>);\n \n-\n impl<'t> Parser<'t> {\n+    /// Returns the kind of the current token.\n+    /// If parser has already reached the end of input,\n+    /// the special `EOF` kind is returned.\n     pub(crate) fn current(&self) -> SyntaxKind {\n         self.nth(0)\n     }\n \n+    /// Lookahead operation: returns the kind of the next nth\n+    /// token.\n     pub(crate) fn nth(&self, n: u32) -> SyntaxKind {\n         self.0.nth(n)\n     }\n \n+    /// Checks if the current token is `kind`.\n     pub(crate) fn at(&self, kind: SyntaxKind) -> bool {\n         self.current() == kind\n     }\n \n-    pub(crate) fn at_kw(&self, t: &str) -> bool {\n+    /// Checks if the current token is contextual keyword with text `t`.\n+    pub(crate) fn at_contextual_kw(&self, t: &str) -> bool {\n         self.0.at_kw(t)\n     }\n \n+    /// Starts a new node in the syntax tree. All nodes and tokens\n+    /// consumed between the `start` and the corresponding `Marker::complete`\n+    /// belong to the same node.\n     pub(crate) fn start(&mut self) -> Marker {\n         Marker(self.0.start())\n     }\n \n+    /// Advances the parser by one token.\n     pub(crate) fn bump(&mut self) {\n         self.0.bump();\n     }\n \n+    /// Advances the parser by one token, remapping its kind.\n+    /// This is useful to create contextual keywords from\n+    /// identifiers. For example, the lexer creates an `union`\n+    /// *identifier* token, but the parser remaps it to the\n+    /// `union` keyword, and keyword is what ends up in the\n+    /// final tree.\n     pub(crate) fn bump_remap(&mut self, kind: SyntaxKind) {\n         self.0.bump_remap(kind);\n     }\n \n+    /// Emit error with the `message`\n+    /// TODO: this should be much more fancy and support\n+    /// structured errors with spans and notes, like rustc\n+    /// does.\n     pub(crate) fn error<T: Into<String>>(&mut self, message: T) {\n         self.0.error(message.into())\n     }\n \n-    pub(crate) fn expect(&mut self, kind: SyntaxKind) -> bool {\n-        if self.at(kind) {\n-            self.bump();\n-            return true;\n-        }\n-        self.error(format!(\"expected {:?}\", kind));\n-        false\n-    }\n-\n+    /// Consume the next token if it is `kind`.\n     pub(crate) fn eat(&mut self, kind: SyntaxKind) -> bool {\n         if !self.at(kind) {\n             return false;\n@@ -57,6 +78,17 @@ impl<'t> Parser<'t> {\n         true\n     }\n \n+    /// Consume the next token if it is `kind` or emit an error\n+    /// otherwise.\n+    pub(crate) fn expect(&mut self, kind: SyntaxKind) -> bool {\n+        if self.eat(kind) {\n+            return true;\n+        }\n+        self.error(format!(\"expected {:?}\", kind));\n+        false\n+    }\n+\n+    /// Create an error node and consume the next token.\n     pub(crate) fn err_and_bump(&mut self, message: &str) {\n         let m = self.start();\n         self.error(message);\n@@ -65,16 +97,20 @@ impl<'t> Parser<'t> {\n     }\n }\n \n+/// See `Parser::start`.\n pub(crate) struct Marker(u32);\n \n impl Marker {\n+    /// Finishes the syntax tree node and assigns `kind` to it.\n     pub(crate) fn complete(self, p: &mut Parser, kind: SyntaxKind) -> CompletedMarker {\n         let pos = self.0;\n         ::std::mem::forget(self);\n         p.0.complete(pos, kind);\n         CompletedMarker(pos)\n     }\n \n+    /// Abandons the syntax tree node. All its children\n+    /// are attached to its parent instead.\n     pub(crate) fn abandon(self, p: &mut Parser) {\n         let pos = self.0;\n         ::std::mem::forget(self);\n@@ -94,6 +130,13 @@ impl Drop for Marker {\n pub(crate) struct CompletedMarker(u32);\n \n impl CompletedMarker {\n+    /// This one is tricky :-)\n+    /// This method allows to create a new node which starts\n+    /// *before* the current one. That is, parser could start\n+    /// node `A`, then complete it, and then after parsing the\n+    /// whole `A`, decide that it should have started some node\n+    /// `B` before starting `A`. `precede` allows to do exactly\n+    /// that. See also docs about `forward_parent` in `Event::Start`.\n     pub(crate) fn precede(self, p: &mut Parser) -> Marker {\n         Marker(p.0.precede(self.0))\n     }"}]}