{"sha": "0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjYmI4YjU4ZThhNTU3MzE5MGM5M2M5Yzk0ZTBiMDAzYjFjZmM2ZWY=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2017-05-31T14:42:52Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2017-05-31T14:42:52Z"}, "message": "incr.comp.: Use DefPathHash-based DepNodes in the serialized DepGraph and remove obsolete DefIdDirectory.", "tree": {"sha": "7e915a67a07e0b9d12e4a18218b6f7dcdef41c80", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7e915a67a07e0b9d12e4a18218b6f7dcdef41c80"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "html_url": "https://github.com/rust-lang/rust/commit/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9da83a8daf159ef1e85da1a018b5204e47e77e6d", "url": "https://api.github.com/repos/rust-lang/rust/commits/9da83a8daf159ef1e85da1a018b5204e47e77e6d", "html_url": "https://github.com/rust-lang/rust/commit/9da83a8daf159ef1e85da1a018b5204e47e77e6d"}], "stats": {"total": 342, "additions": 74, "deletions": 268}, "files": [{"sha": "336197d7d6d7d9d0ed0c641b5cb887d2fc43640d", "filename": "src/librustc_incremental/persist/data.rs", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs?ref=0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "patch": "@@ -12,13 +12,12 @@\n \n use rustc::dep_graph::{DepNode, WorkProduct, WorkProductId};\n use rustc::hir::def_id::DefIndex;\n+use rustc::hir::map::DefPathHash;\n use rustc::ich::Fingerprint;\n use rustc::middle::cstore::EncodedMetadataHash;\n use std::sync::Arc;\n use rustc_data_structures::fx::FxHashMap;\n \n-use super::directory::DefPathIndex;\n-\n /// Data for use when recompiling the **current crate**.\n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedDepGraph {\n@@ -27,7 +26,7 @@ pub struct SerializedDepGraph {\n     /// These are output nodes that have no incoming edges. We track\n     /// these separately so that when we reload all edges, we don't\n     /// lose track of these nodes.\n-    pub bootstrap_outputs: Vec<DepNode<DefPathIndex>>,\n+    pub bootstrap_outputs: Vec<DepNode<DefPathHash>>,\n \n     /// These are hashes of two things:\n     /// - the HIR nodes in this crate\n@@ -55,14 +54,14 @@ pub struct SerializedDepGraph {\n /// outgoing edges from a single source together.\n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedEdgeSet {\n-    pub source: DepNode<DefPathIndex>,\n-    pub targets: Vec<DepNode<DefPathIndex>>\n+    pub source: DepNode<DefPathHash>,\n+    pub targets: Vec<DepNode<DefPathHash>>\n }\n \n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedHash {\n     /// def-id of thing being hashed\n-    pub dep_node: DepNode<DefPathIndex>,\n+    pub dep_node: DepNode<DefPathHash>,\n \n     /// the hash as of previous compilation, computed by code in\n     /// `hash` module\n@@ -115,5 +114,5 @@ pub struct SerializedMetadataHashes {\n     /// is only populated if -Z query-dep-graph is specified. It will be\n     /// empty otherwise. Importing crates are perfectly happy with just having\n     /// the DefIndex.\n-    pub index_map: FxHashMap<DefIndex, DefPathIndex>\n+    pub index_map: FxHashMap<DefIndex, DefPathHash>\n }"}, {"sha": "b9b860222968b7b232050ca1cd5d46b36b0afa25", "filename": "src/librustc_incremental/persist/directory.rs", "status": "removed", "additions": 0, "deletions": 204, "changes": 204, "blob_url": "https://github.com/rust-lang/rust/blob/9da83a8daf159ef1e85da1a018b5204e47e77e6d/src%2Flibrustc_incremental%2Fpersist%2Fdirectory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9da83a8daf159ef1e85da1a018b5204e47e77e6d/src%2Flibrustc_incremental%2Fpersist%2Fdirectory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdirectory.rs?ref=9da83a8daf159ef1e85da1a018b5204e47e77e6d", "patch": "@@ -1,204 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Code to convert a DefId into a DefPath (when serializing) and then\n-//! back again (when deserializing). Note that the new DefId\n-//! necessarily will not be the same as the old (and of course the\n-//! item might even be removed in the meantime).\n-\n-use rustc::dep_graph::DepNode;\n-use rustc::hir::map::DefPath;\n-use rustc::hir::def_id::{CrateNum, DefId, LOCAL_CRATE};\n-use rustc::ty::TyCtxt;\n-use rustc::util::nodemap::DefIdMap;\n-use std::fmt::{self, Debug};\n-use std::iter::once;\n-use std::collections::HashMap;\n-\n-/// Index into the DefIdDirectory\n-#[derive(Copy, Clone, Debug, PartialOrd, Ord, Hash, PartialEq, Eq,\n-         RustcEncodable, RustcDecodable)]\n-pub struct DefPathIndex {\n-    index: u32\n-}\n-\n-#[derive(RustcEncodable, RustcDecodable)]\n-pub struct DefIdDirectory {\n-    // N.B. don't use Removable here because these def-ids are loaded\n-    // directly without remapping, so loading them should not fail.\n-    paths: Vec<DefPath>,\n-\n-    // For each crate, saves the crate-name/disambiguator so that\n-    // later we can match crate-numbers up again.\n-    krates: Vec<CrateInfo>,\n-}\n-\n-#[derive(Debug, RustcEncodable, RustcDecodable)]\n-pub struct CrateInfo {\n-    krate: CrateNum,\n-    name: String,\n-    disambiguator: String,\n-}\n-\n-impl DefIdDirectory {\n-    pub fn new(krates: Vec<CrateInfo>) -> DefIdDirectory {\n-        DefIdDirectory { paths: vec![], krates: krates }\n-    }\n-\n-    fn max_current_crate(&self, tcx: TyCtxt) -> CrateNum {\n-        tcx.sess.cstore.crates()\n-                       .into_iter()\n-                       .max()\n-                       .unwrap_or(LOCAL_CRATE)\n-    }\n-\n-    /// Returns a string form for `index`; useful for debugging\n-    pub fn def_path_string(&self, tcx: TyCtxt, index: DefPathIndex) -> String {\n-        let path = &self.paths[index.index as usize];\n-        if self.krate_still_valid(tcx, self.max_current_crate(tcx), path.krate) {\n-            path.to_string(tcx)\n-        } else {\n-            format!(\"<crate {} changed>\", path.krate)\n-        }\n-    }\n-\n-    pub fn krate_still_valid(&self,\n-                             tcx: TyCtxt,\n-                             max_current_crate: CrateNum,\n-                             krate: CrateNum) -> bool {\n-        // Check that the crate-number still matches. For now, if it\n-        // doesn't, just return None. We could do better, such as\n-        // finding the new number.\n-\n-        if krate > max_current_crate {\n-            false\n-        } else {\n-            let old_info = &self.krates[krate.as_usize()];\n-            assert_eq!(old_info.krate, krate);\n-            let old_name: &str = &old_info.name;\n-            let old_disambiguator: &str = &old_info.disambiguator;\n-            let new_name: &str = &tcx.crate_name(krate).as_str();\n-            let new_disambiguator: &str = &tcx.crate_disambiguator(krate).as_str();\n-            old_name == new_name && old_disambiguator == new_disambiguator\n-        }\n-    }\n-\n-    pub fn retrace(&self, tcx: TyCtxt) -> RetracedDefIdDirectory {\n-\n-        fn make_key(name: &str, disambiguator: &str) -> String {\n-            format!(\"{}/{}\", name, disambiguator)\n-        }\n-\n-        let new_krates: HashMap<_, _> =\n-            once(LOCAL_CRATE)\n-            .chain(tcx.sess.cstore.crates())\n-            .map(|krate| (make_key(&tcx.crate_name(krate).as_str(),\n-                                   &tcx.crate_disambiguator(krate).as_str()), krate))\n-            .collect();\n-\n-        let ids = self.paths.iter()\n-                            .map(|path| {\n-                                let old_krate_id = path.krate.as_usize();\n-                                assert!(old_krate_id < self.krates.len());\n-                                let old_crate_info = &self.krates[old_krate_id];\n-                                let old_crate_key = make_key(&old_crate_info.name,\n-                                                         &old_crate_info.disambiguator);\n-                                if let Some(&new_crate_key) = new_krates.get(&old_crate_key) {\n-                                    tcx.retrace_path(new_crate_key, &path.data)\n-                                } else {\n-                                    debug!(\"crate {:?} no longer exists\", old_crate_key);\n-                                    None\n-                                }\n-                            })\n-                            .collect();\n-        RetracedDefIdDirectory { ids: ids }\n-    }\n-}\n-\n-#[derive(Debug, RustcEncodable, RustcDecodable)]\n-pub struct RetracedDefIdDirectory {\n-    ids: Vec<Option<DefId>>\n-}\n-\n-impl RetracedDefIdDirectory {\n-    pub fn def_id(&self, index: DefPathIndex) -> Option<DefId> {\n-        self.ids[index.index as usize]\n-    }\n-\n-    pub fn map(&self, node: &DepNode<DefPathIndex>) -> Option<DepNode<DefId>> {\n-        node.map_def(|&index| self.def_id(index))\n-    }\n-}\n-\n-pub struct DefIdDirectoryBuilder<'a,'tcx:'a> {\n-    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    hash: DefIdMap<DefPathIndex>,\n-    directory: DefIdDirectory,\n-}\n-\n-impl<'a,'tcx> DefIdDirectoryBuilder<'a,'tcx> {\n-    pub fn new(tcx: TyCtxt<'a, 'tcx, 'tcx>) -> DefIdDirectoryBuilder<'a, 'tcx> {\n-        let mut krates: Vec<_> =\n-            once(LOCAL_CRATE)\n-            .chain(tcx.sess.cstore.crates())\n-            .map(|krate| {\n-                CrateInfo {\n-                    krate: krate,\n-                    name: tcx.crate_name(krate).to_string(),\n-                    disambiguator: tcx.crate_disambiguator(krate).to_string()\n-                }\n-            })\n-            .collect();\n-\n-        // the result of crates() is not in order, so sort list of\n-        // crates so that we can just index it later\n-        krates.sort_by_key(|k| k.krate);\n-\n-        DefIdDirectoryBuilder {\n-            tcx: tcx,\n-            hash: DefIdMap(),\n-            directory: DefIdDirectory::new(krates),\n-        }\n-    }\n-\n-    pub fn tcx(&self) -> TyCtxt<'a, 'tcx, 'tcx> {\n-        self.tcx\n-    }\n-\n-    pub fn add(&mut self, def_id: DefId) -> DefPathIndex {\n-        debug!(\"DefIdDirectoryBuilder: def_id={:?}\", def_id);\n-        let tcx = self.tcx;\n-        let paths = &mut self.directory.paths;\n-        self.hash.entry(def_id)\n-                 .or_insert_with(|| {\n-                     let def_path = tcx.def_path(def_id);\n-                     let index = paths.len() as u32;\n-                     paths.push(def_path);\n-                     DefPathIndex { index: index }\n-                 })\n-                 .clone()\n-    }\n-\n-    pub fn map(&mut self, node: &DepNode<DefId>) -> DepNode<DefPathIndex> {\n-        node.map_def(|&def_id| Some(self.add(def_id))).unwrap()\n-    }\n-\n-    pub fn directory(&self) -> &DefIdDirectory {\n-        &self.directory\n-    }\n-}\n-\n-impl Debug for DefIdDirectory {\n-    fn fmt(&self, fmt: &mut fmt::Formatter) -> Result<(), fmt::Error> {\n-        fmt.debug_list()\n-           .entries(self.paths.iter().enumerate())\n-           .finish()\n-    }\n-}"}, {"sha": "3a428bd7b8f7d273819fb2c8e3481d01a3798337", "filename": "src/librustc_incremental/persist/dirty_clean.rs", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fdirty_clean.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fdirty_clean.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdirty_clean.rs?ref=0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "patch": "@@ -40,7 +40,6 @@\n //! previous revision to compare things to.\n //!\n \n-use super::directory::RetracedDefIdDirectory;\n use super::load::DirtyNodes;\n use rustc::dep_graph::{DepGraphQuery, DepNode};\n use rustc::hir;\n@@ -58,18 +57,23 @@ const LABEL: &'static str = \"label\";\n const CFG: &'static str = \"cfg\";\n \n pub fn check_dirty_clean_annotations<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                               dirty_inputs: &DirtyNodes,\n-                                               retraced: &RetracedDefIdDirectory) {\n+                                               dirty_inputs: &DirtyNodes) {\n     // can't add `#[rustc_dirty]` etc without opting in to this feature\n     if !tcx.sess.features.borrow().rustc_attrs {\n         return;\n     }\n \n     let _ignore = tcx.dep_graph.in_ignore();\n+    let def_path_hash_to_def_id = tcx.def_path_hash_to_def_id.as_ref().unwrap();\n     let dirty_inputs: FxHashSet<DepNode<DefId>> =\n         dirty_inputs.keys()\n-                    .filter_map(|d| retraced.map(d))\n+                    .filter_map(|dep_node| {\n+                        dep_node.map_def(|def_path_hash| {\n+                            def_path_hash_to_def_id.get(def_path_hash).cloned()\n+                        })\n+                    })\n                     .collect();\n+\n     let query = tcx.dep_graph.query();\n     debug!(\"query-nodes: {:?}\", query.nodes());\n     let krate = tcx.hir.krate();"}, {"sha": "d383f80d5c2da9fffb7f913aa3de642ff6f93906", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 43, "deletions": 34, "changes": 77, "blob_url": "https://github.com/rust-lang/rust/blob/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "patch": "@@ -12,6 +12,7 @@\n \n use rustc::dep_graph::{DepNode, WorkProductId};\n use rustc::hir::def_id::DefId;\n+use rustc::hir::map::DefPathHash;\n use rustc::hir::svh::Svh;\n use rustc::ich::Fingerprint;\n use rustc::session::Session;\n@@ -24,7 +25,6 @@ use std::sync::Arc;\n \n use IncrementalHashesMap;\n use super::data::*;\n-use super::directory::*;\n use super::dirty_clean;\n use super::hash::*;\n use super::fs::*;\n@@ -33,7 +33,7 @@ use super::work_product;\n \n // The key is a dirty node. The value is **some** base-input that we\n // can blame it on.\n-pub type DirtyNodes = FxHashMap<DepNode<DefPathIndex>, DepNode<DefPathIndex>>;\n+pub type DirtyNodes = FxHashMap<DepNode<DefPathHash>, DepNode<DefPathHash>>;\n \n /// If we are in incremental mode, and a previous dep-graph exists,\n /// then load up those nodes/edges that are still valid into the\n@@ -118,6 +118,16 @@ fn load_data(sess: &Session, path: &Path) -> Option<Vec<u8>> {\n     None\n }\n \n+/// Try to convert a DepNode from the old dep-graph into a DepNode in the\n+/// current graph by mapping the DefPathHash to a valid DefId. This will fail\n+/// if the DefPathHash refers to something that has been removed (because\n+/// there is no DefId for that thing anymore).\n+fn retrace(tcx: TyCtxt, dep_node: &DepNode<DefPathHash>) -> Option<DepNode<DefId>> {\n+    dep_node.map_def(|def_path_hash| {\n+        tcx.def_path_hash_to_def_id.as_ref().unwrap().get(def_path_hash).cloned()\n+    })\n+}\n+\n /// Decode the dep graph and load the edges/nodes that are still clean\n /// into `tcx.dep_graph`.\n pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n@@ -149,17 +159,13 @@ pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         return Ok(());\n     }\n \n-    let directory = DefIdDirectory::decode(&mut dep_graph_decoder)?;\n     let serialized_dep_graph = SerializedDepGraph::decode(&mut dep_graph_decoder)?;\n \n     let edge_map: FxHashMap<_, _> = serialized_dep_graph.edges\n                                                         .into_iter()\n                                                         .map(|s| (s.source, s.targets))\n                                                         .collect();\n \n-    // Retrace the paths in the directory to find their current location (if any).\n-    let retraced = directory.retrace(tcx);\n-\n     // Compute the set of nodes from the old graph where some input\n     // has changed or been removed. These are \"raw\" source nodes,\n     // which means that they still use the original `DefPathIndex`\n@@ -169,8 +175,7 @@ pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     // the current compilation).\n     let dirty_raw_nodes = initial_dirty_nodes(tcx,\n                                               incremental_hashes_map,\n-                                              &serialized_dep_graph.hashes,\n-                                              &retraced);\n+                                              &serialized_dep_graph.hashes);\n     let dirty_raw_nodes = transitive_dirty_nodes(&edge_map, dirty_raw_nodes);\n \n     // Recreate the edges in the graph that are still clean.\n@@ -179,15 +184,15 @@ pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let mut extra_edges = vec![];\n     for (source, targets) in &edge_map {\n         for target in targets {\n-            process_edges(tcx, source, target, &edge_map, &directory, &retraced, &dirty_raw_nodes,\n+            process_edges(tcx, source, target, &edge_map, &dirty_raw_nodes,\n                           &mut clean_work_products, &mut dirty_work_products, &mut extra_edges);\n         }\n     }\n \n     // Recreate bootstrap outputs, which are outputs that have no incoming edges (and hence cannot\n     // be dirty).\n     for bootstrap_output in &serialized_dep_graph.bootstrap_outputs {\n-        if let Some(n) = retraced.map(bootstrap_output) {\n+        if let Some(n) = retrace(tcx, bootstrap_output) {\n             if let DepNode::WorkProduct(ref wp) = n {\n                 clean_work_products.insert(wp.clone());\n             }\n@@ -214,18 +219,17 @@ pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     // the edge from `Hir(X)` to `Bar` (or, if `Bar` itself cannot be\n     // recreated, to the targets of `Bar`).\n     while let Some((source, target)) = extra_edges.pop() {\n-        process_edges(tcx, source, target, &edge_map, &directory, &retraced, &dirty_raw_nodes,\n+        process_edges(tcx, source, target, &edge_map, &dirty_raw_nodes,\n                       &mut clean_work_products, &mut dirty_work_products, &mut extra_edges);\n     }\n \n     // Add in work-products that are still clean, and delete those that are\n     // dirty.\n     reconcile_work_products(tcx, work_products, &clean_work_products);\n \n-    dirty_clean::check_dirty_clean_annotations(tcx, &dirty_raw_nodes, &retraced);\n+    dirty_clean::check_dirty_clean_annotations(tcx, &dirty_raw_nodes);\n \n     load_prev_metadata_hashes(tcx,\n-                              &retraced,\n                               &mut *incremental_hashes_map.prev_metadata_hashes.borrow_mut());\n     Ok(())\n }\n@@ -234,8 +238,7 @@ pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n /// a bit vector where the index is the DefPathIndex.\n fn initial_dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                  incremental_hashes_map: &IncrementalHashesMap,\n-                                 serialized_hashes: &[SerializedHash],\n-                                 retraced: &RetracedDefIdDirectory)\n+                                 serialized_hashes: &[SerializedHash])\n                                  -> DirtyNodes {\n     let mut hcx = HashContext::new(tcx, incremental_hashes_map);\n     let mut dirty_nodes = FxHashMap();\n@@ -249,7 +252,7 @@ fn initial_dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     };\n \n     for hash in serialized_hashes {\n-        if let Some(dep_node) = retraced.map(&hash.dep_node) {\n+        if let Some(dep_node) = retrace(tcx, &hash.dep_node) {\n             if let Some(current_hash) = hcx.hash(&dep_node) {\n                 if current_hash == hash.hash {\n                     debug!(\"initial_dirty_nodes: {:?} is clean (hash={:?})\",\n@@ -282,11 +285,11 @@ fn initial_dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     dirty_nodes\n }\n \n-fn transitive_dirty_nodes(edge_map: &FxHashMap<DepNode<DefPathIndex>, Vec<DepNode<DefPathIndex>>>,\n+fn transitive_dirty_nodes(edge_map: &FxHashMap<DepNode<DefPathHash>, Vec<DepNode<DefPathHash>>>,\n                           mut dirty_nodes: DirtyNodes)\n                           -> DirtyNodes\n {\n-    let mut stack: Vec<(DepNode<DefPathIndex>, DepNode<DefPathIndex>)> = vec![];\n+    let mut stack: Vec<(DepNode<DefPathHash>, DepNode<DefPathHash>)> = vec![];\n     stack.extend(dirty_nodes.iter().map(|(s, b)| (s.clone(), b.clone())));\n     while let Some((source, blame)) = stack.pop() {\n         // we know the source is dirty (because of the node `blame`)...\n@@ -348,7 +351,6 @@ fn delete_dirty_work_product(tcx: TyCtxt,\n }\n \n fn load_prev_metadata_hashes(tcx: TyCtxt,\n-                             retraced: &RetracedDefIdDirectory,\n                              output: &mut FxHashMap<DefId, Fingerprint>) {\n     if !tcx.sess.opts.debugging_opts.query_dep_graph {\n         return\n@@ -388,9 +390,11 @@ fn load_prev_metadata_hashes(tcx: TyCtxt,\n     debug!(\"load_prev_metadata_hashes() - Mapping DefIds\");\n \n     assert_eq!(serialized_hashes.index_map.len(), serialized_hashes.entry_hashes.len());\n+    let def_path_hash_to_def_id = tcx.def_path_hash_to_def_id.as_ref().unwrap();\n+\n     for serialized_hash in serialized_hashes.entry_hashes {\n-        let def_path_index = serialized_hashes.index_map[&serialized_hash.def_index];\n-        if let Some(def_id) = retraced.def_id(def_path_index) {\n+        let def_path_hash = serialized_hashes.index_map[&serialized_hash.def_index];\n+        if let Some(&def_id) = def_path_hash_to_def_id.get(&def_path_hash) {\n             let old = output.insert(def_id, serialized_hash.hash);\n             assert!(old.is_none(), \"already have hash for {:?}\", def_id);\n         }\n@@ -402,15 +406,13 @@ fn load_prev_metadata_hashes(tcx: TyCtxt,\n \n fn process_edges<'a, 'tcx, 'edges>(\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    source: &'edges DepNode<DefPathIndex>,\n-    target: &'edges DepNode<DefPathIndex>,\n-    edges: &'edges FxHashMap<DepNode<DefPathIndex>, Vec<DepNode<DefPathIndex>>>,\n-    directory: &DefIdDirectory,\n-    retraced: &RetracedDefIdDirectory,\n+    source: &'edges DepNode<DefPathHash>,\n+    target: &'edges DepNode<DefPathHash>,\n+    edges: &'edges FxHashMap<DepNode<DefPathHash>, Vec<DepNode<DefPathHash>>>,\n     dirty_raw_nodes: &DirtyNodes,\n     clean_work_products: &mut FxHashSet<Arc<WorkProductId>>,\n     dirty_work_products: &mut FxHashSet<Arc<WorkProductId>>,\n-    extra_edges: &mut Vec<(&'edges DepNode<DefPathIndex>, &'edges DepNode<DefPathIndex>)>)\n+    extra_edges: &mut Vec<(&'edges DepNode<DefPathHash>, &'edges DepNode<DefPathHash>)>)\n {\n     // If the target is dirty, skip the edge. If this is an edge\n     // that targets a work-product, we can print the blame\n@@ -419,14 +421,21 @@ fn process_edges<'a, 'tcx, 'edges>(\n         if let DepNode::WorkProduct(ref wp) = *target {\n             if tcx.sess.opts.debugging_opts.incremental_info {\n                 if dirty_work_products.insert(wp.clone()) {\n-                    // It'd be nice to pretty-print these paths better than just\n-                    // using the `Debug` impls, but wev.\n+                    // Try to reconstruct the human-readable version of the\n+                    // DepNode. This cannot be done for things that where\n+                    // removed.\n+                    let readable_blame = if let Some(dep_node) = retrace(tcx, blame) {\n+                        dep_node.map_def(|&def_id| Some(tcx.def_path(def_id).to_string(tcx)))\n+                                .unwrap()\n+                    } else {\n+                        blame.map_def(|def_path_hash| Some(format!(\"{:?}\", def_path_hash)))\n+                             .unwrap()\n+                    };\n+\n                     println!(\"incremental: module {:?} is dirty because {:?} \\\n                               changed or was removed\",\n                              wp,\n-                             blame.map_def(|&index| {\n-                                 Some(directory.def_path_string(tcx, index))\n-                             }).unwrap());\n+                             readable_blame);\n                 }\n             }\n         }\n@@ -439,8 +448,8 @@ fn process_edges<'a, 'tcx, 'edges>(\n     // Retrace the source -> target edges to def-ids and then create\n     // an edge in the graph. Retracing may yield none if some of the\n     // data happens to have been removed.\n-    if let Some(source_node) = retraced.map(source) {\n-        if let Some(target_node) = retraced.map(target) {\n+    if let Some(source_node) = retrace(tcx, source) {\n+        if let Some(target_node) = retrace(tcx, target) {\n             let _task = tcx.dep_graph.in_task(target_node);\n             tcx.dep_graph.read(source_node);\n             if let DepNode::WorkProduct(ref wp) = *target {"}, {"sha": "c03a0ab4ba2c181d0c19267b2f9b65948bc0d48c", "filename": "src/librustc_incremental/persist/mod.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs?ref=0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "patch": "@@ -13,7 +13,6 @@\n //! various HIR nodes.\n \n mod data;\n-mod directory;\n mod dirty_clean;\n mod fs;\n mod hash;"}, {"sha": "28ac5a0fdf5622b14e6c14a4895484297d4ce27c", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 17, "deletions": 18, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=0cbb8b58e8a5573190c93c9c94e0b003b1cfc6ef", "patch": "@@ -24,7 +24,6 @@ use std::path::PathBuf;\n \n use IncrementalHashesMap;\n use super::data::*;\n-use super::directory::*;\n use super::hash::*;\n use super::preds::*;\n use super::fs::*;\n@@ -43,7 +42,6 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         return;\n     }\n \n-    let mut builder = DefIdDirectoryBuilder::new(tcx);\n     let query = tcx.dep_graph.query();\n \n     if tcx.sess.opts.debugging_opts.incremental_info {\n@@ -65,14 +63,13 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                 |e| encode_metadata_hashes(tcx,\n                                            svh,\n                                            metadata_hashes,\n-                                           &mut builder,\n                                            &mut current_metadata_hashes,\n                                            e));\n     }\n \n     save_in(sess,\n             dep_graph_path(sess),\n-            |e| encode_dep_graph(&preds, &mut builder, e));\n+            |e| encode_dep_graph(tcx, &preds, e));\n \n     let prev_metadata_hashes = incremental_hashes_map.prev_metadata_hashes.borrow();\n     dirty_clean::check_dirty_clean_metadata(tcx,\n@@ -167,14 +164,17 @@ fn save_in<F>(sess: &Session, path_buf: PathBuf, encode: F)\n     }\n }\n \n-pub fn encode_dep_graph(preds: &Predecessors,\n-                        builder: &mut DefIdDirectoryBuilder,\n+pub fn encode_dep_graph(tcx: TyCtxt,\n+                        preds: &Predecessors,\n                         encoder: &mut Encoder)\n                         -> io::Result<()> {\n     // First encode the commandline arguments hash\n-    let tcx = builder.tcx();\n     tcx.sess.opts.dep_tracking_hash().encode(encoder)?;\n \n+    let to_hash_based_node = |dep_node: &DepNode<DefId>| {\n+        dep_node.map_def(|&def_id| Some(tcx.def_path_hash(def_id))).unwrap()\n+    };\n+\n     // Create a flat list of (Input, WorkProduct) edges for\n     // serialization.\n     let mut edges = FxHashMap();\n@@ -191,8 +191,8 @@ pub fn encode_dep_graph(preds: &Predecessors,\n             _ => (),\n         }\n         debug!(\"serialize edge: {:?} -> {:?}\", source, target);\n-        let source = builder.map(source);\n-        let target = builder.map(target);\n+        let source = to_hash_based_node(source);\n+        let target = to_hash_based_node(target);\n         edges.entry(source).or_insert(vec![]).push(target);\n     }\n \n@@ -203,9 +203,10 @@ pub fn encode_dep_graph(preds: &Predecessors,\n     }\n \n     // Create the serialized dep-graph.\n-    let bootstrap_outputs = preds.bootstrap_outputs.iter()\n-                                                   .map(|n| builder.map(n))\n-                                                   .collect();\n+    let bootstrap_outputs = preds.bootstrap_outputs\n+                                 .iter()\n+                                 .map(|n| to_hash_based_node(n))\n+                                 .collect();\n     let edges = edges.into_iter()\n                      .map(|(k, v)| SerializedEdgeSet { source: k, targets: v })\n                      .collect();\n@@ -216,7 +217,7 @@ pub fn encode_dep_graph(preds: &Predecessors,\n             .iter()\n             .map(|(&dep_node, &hash)| {\n                 SerializedHash {\n-                    dep_node: builder.map(dep_node),\n+                    dep_node: to_hash_based_node(dep_node),\n                     hash: hash,\n                 }\n             })\n@@ -231,8 +232,7 @@ pub fn encode_dep_graph(preds: &Predecessors,\n \n     debug!(\"graph = {:#?}\", graph);\n \n-    // Encode the directory and then the graph data.\n-    builder.directory().encode(encoder)?;\n+    // Encode the graph data.\n     graph.encode(encoder)?;\n \n     Ok(())\n@@ -241,7 +241,6 @@ pub fn encode_dep_graph(preds: &Predecessors,\n pub fn encode_metadata_hashes(tcx: TyCtxt,\n                               svh: Svh,\n                               metadata_hashes: &EncodedMetadataHashes,\n-                              builder: &mut DefIdDirectoryBuilder,\n                               current_metadata_hashes: &mut FxHashMap<DefId, Fingerprint>,\n                               encoder: &mut Encoder)\n                               -> io::Result<()> {\n@@ -256,8 +255,8 @@ pub fn encode_metadata_hashes(tcx: TyCtxt,\n             let def_id = DefId::local(serialized_hash.def_index);\n \n             // Store entry in the index_map\n-            let def_path_index = builder.add(def_id);\n-            serialized_hashes.index_map.insert(def_id.index, def_path_index);\n+            let def_path_hash = tcx.def_path_hash(def_id);\n+            serialized_hashes.index_map.insert(def_id.index, def_path_hash);\n \n             // Record hash in current_metadata_hashes\n             current_metadata_hashes.insert(def_id, serialized_hash.hash);"}]}