{"sha": "331e74014a0a2bf18aae7f02495f97958bf9767d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMzMWU3NDAxNGEwYTJiZjE4YWFlN2YwMjQ5NWY5Nzk1OGJmOTc2N2Q=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-12-14T07:03:52Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-12-14T07:03:52Z"}, "message": "Auto merge of #79944 - sivadeilra:syms_proc_macro_testing, r=petrochenkov\n\nImprove error handling in `symbols` proc-macro\n\nThis improves how the `symbols` proc-macro handles errors.\nIf it finds an error in its input, the macro does not panic.\nInstead, it still produces an output token stream. That token\nstream will contain `compile_error!(...)` macro invocations.\nThis will still cause compilation to fail (which is what we want),\nbut it will prevent meaningless errors caused by the output not\ncontaining symbols that the macro normally generates.\n\nThis solves a small (but annoying) problem. When you're editing\nrustc_span/src/symbol.rs, and you get something wrong (dup\nsymbol name, misordered symbol), you want to get only the errors\nthat are relevant, not a burst of errors that are irrelevant.\nThis change also uses the correct Span when reporting errors,\nso you get errors that point to the correct place in\nrustc_span/src/symbol.rs where something is wrong.\n\nThis also adds several unit tests which test the `symbols` proc-macro.\n\nThis commit also makes it easy to run the `symbols` proc-macro\nas an ordinary Cargo test. Just run `cargo test`. This makes it\neasier to do development on the macro itself, such as running it\nunder a debugger.\n\nThis commit also uses the `Punctuated` type in `syn` for parsing\ncomma-separated lists, rather than doing it manually.\n\nThe output of the macro is not changed at all by this commit,\nso rustc should be completely unchanged. This just improves\nquality of life during development.", "tree": {"sha": "b7b13bee3eacfa00125ecd515e9ff63c58406a5e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b7b13bee3eacfa00125ecd515e9ff63c58406a5e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/331e74014a0a2bf18aae7f02495f97958bf9767d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/331e74014a0a2bf18aae7f02495f97958bf9767d", "html_url": "https://github.com/rust-lang/rust/commit/331e74014a0a2bf18aae7f02495f97958bf9767d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/331e74014a0a2bf18aae7f02495f97958bf9767d/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7feab000b283139b5b7ba131a2495515bc80c627", "url": "https://api.github.com/repos/rust-lang/rust/commits/7feab000b283139b5b7ba131a2495515bc80c627", "html_url": "https://github.com/rust-lang/rust/commit/7feab000b283139b5b7ba131a2495515bc80c627"}, {"sha": "1a5b9b037e0fb8cf204e44e604ff4ad09612b8b6", "url": "https://api.github.com/repos/rust-lang/rust/commits/1a5b9b037e0fb8cf204e44e604ff4ad09612b8b6", "html_url": "https://github.com/rust-lang/rust/commit/1a5b9b037e0fb8cf204e44e604ff4ad09612b8b6"}], "stats": {"total": 258, "additions": 204, "deletions": 54}, "files": [{"sha": "152ae159aed446556ad243c1d58cf10f6a9df691", "filename": "compiler/rustc_macros/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/331e74014a0a2bf18aae7f02495f97958bf9767d/compiler%2Frustc_macros%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/331e74014a0a2bf18aae7f02495f97958bf9767d/compiler%2Frustc_macros%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_macros%2Fsrc%2Flib.rs?ref=331e74014a0a2bf18aae7f02495f97958bf9767d", "patch": "@@ -21,7 +21,7 @@ pub fn rustc_queries(input: TokenStream) -> TokenStream {\n \n #[proc_macro]\n pub fn symbols(input: TokenStream) -> TokenStream {\n-    symbols::symbols(input)\n+    symbols::symbols(input.into()).into()\n }\n \n decl_derive!([HashStable, attributes(stable_hasher)] => hash_stable::hash_stable_derive);"}, {"sha": "f449900d5c245c6409a7c042efd13b7074a9a7e3", "filename": "compiler/rustc_macros/src/symbols.rs", "status": "modified", "additions": 101, "deletions": 53, "changes": 154, "blob_url": "https://github.com/rust-lang/rust/blob/331e74014a0a2bf18aae7f02495f97958bf9767d/compiler%2Frustc_macros%2Fsrc%2Fsymbols.rs", "raw_url": "https://github.com/rust-lang/rust/raw/331e74014a0a2bf18aae7f02495f97958bf9767d/compiler%2Frustc_macros%2Fsrc%2Fsymbols.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_macros%2Fsrc%2Fsymbols.rs?ref=331e74014a0a2bf18aae7f02495f97958bf9767d", "patch": "@@ -1,8 +1,35 @@\n-use proc_macro::TokenStream;\n+//! Proc macro which builds the Symbol table\n+//!\n+//! # Debugging\n+//!\n+//! Since this proc-macro does some non-trivial work, debugging it is important.\n+//! This proc-macro can be invoked as an ordinary unit test, like so:\n+//!\n+//! ```bash\n+//! cd compiler/rustc_macros\n+//! cargo test symbols::test_symbols -- --nocapture\n+//! ```\n+//!\n+//! This unit test finds the `symbols!` invocation in `compiler/rustc_span/src/symbol.rs`\n+//! and runs it. It verifies that the output token stream can be parsed as valid module\n+//! items and that no errors were produced.\n+//!\n+//! You can also view the generated code by using `cargo expand`:\n+//!\n+//! ```bash\n+//! cargo install cargo-expand          # this is necessary only once\n+//! cd compiler/rustc_span\n+//! cargo expand > /tmp/rustc_span.rs   # it's a big file\n+//! ```\n+\n+use proc_macro2::{Span, TokenStream};\n use quote::quote;\n-use std::collections::HashSet;\n+use std::collections::HashMap;\n use syn::parse::{Parse, ParseStream, Result};\n-use syn::{braced, parse_macro_input, Ident, LitStr, Token};\n+use syn::{braced, punctuated::Punctuated, Ident, LitStr, Token};\n+\n+#[cfg(test)]\n+mod tests;\n \n mod kw {\n     syn::custom_keyword!(Keywords);\n@@ -19,7 +46,6 @@ impl Parse for Keyword {\n         let name = input.parse()?;\n         input.parse::<Token![:]>()?;\n         let value = input.parse()?;\n-        input.parse::<Token![,]>()?;\n \n         Ok(Keyword { name, value })\n     }\n@@ -37,78 +63,101 @@ impl Parse for Symbol {\n             Ok(_) => Some(input.parse()?),\n             Err(_) => None,\n         };\n-        input.parse::<Token![,]>()?;\n \n         Ok(Symbol { name, value })\n     }\n }\n \n-/// A type used to greedily parse another type until the input is empty.\n-struct List<T>(Vec<T>);\n-\n-impl<T: Parse> Parse for List<T> {\n-    fn parse(input: ParseStream<'_>) -> Result<Self> {\n-        let mut list = Vec::new();\n-        while !input.is_empty() {\n-            list.push(input.parse()?);\n-        }\n-        Ok(List(list))\n-    }\n-}\n-\n struct Input {\n-    keywords: List<Keyword>,\n-    symbols: List<Symbol>,\n+    keywords: Punctuated<Keyword, Token![,]>,\n+    symbols: Punctuated<Symbol, Token![,]>,\n }\n \n impl Parse for Input {\n     fn parse(input: ParseStream<'_>) -> Result<Self> {\n         input.parse::<kw::Keywords>()?;\n         let content;\n         braced!(content in input);\n-        let keywords = content.parse()?;\n+        let keywords = Punctuated::parse_terminated(&content)?;\n \n         input.parse::<kw::Symbols>()?;\n         let content;\n         braced!(content in input);\n-        let symbols = content.parse()?;\n+        let symbols = Punctuated::parse_terminated(&content)?;\n \n         Ok(Input { keywords, symbols })\n     }\n }\n \n+#[derive(Default)]\n+struct Errors {\n+    list: Vec<syn::Error>,\n+}\n+\n+impl Errors {\n+    fn error(&mut self, span: Span, message: String) {\n+        self.list.push(syn::Error::new(span, message));\n+    }\n+}\n+\n pub fn symbols(input: TokenStream) -> TokenStream {\n-    let input = parse_macro_input!(input as Input);\n+    let (mut output, errors) = symbols_with_errors(input);\n+\n+    // If we generated any errors, then report them as compiler_error!() macro calls.\n+    // This lets the errors point back to the most relevant span. It also allows us\n+    // to report as many errors as we can during a single run.\n+    output.extend(errors.into_iter().map(|e| e.to_compile_error()));\n+\n+    output\n+}\n+\n+fn symbols_with_errors(input: TokenStream) -> (TokenStream, Vec<syn::Error>) {\n+    let mut errors = Errors::default();\n+\n+    let input: Input = match syn::parse2(input) {\n+        Ok(input) => input,\n+        Err(e) => {\n+            // This allows us to display errors at the proper span, while minimizing\n+            // unrelated errors caused by bailing out (and not generating code).\n+            errors.list.push(e);\n+            Input { keywords: Default::default(), symbols: Default::default() }\n+        }\n+    };\n \n     let mut keyword_stream = quote! {};\n     let mut symbols_stream = quote! {};\n     let mut digits_stream = quote! {};\n     let mut prefill_stream = quote! {};\n     let mut counter = 0u32;\n-    let mut keys = HashSet::<String>::new();\n-    let mut prev_key: Option<String> = None;\n-    let mut errors = Vec::<String>::new();\n-\n-    let mut check_dup = |str: &str, errors: &mut Vec<String>| {\n-        if !keys.insert(str.to_string()) {\n-            errors.push(format!(\"Symbol `{}` is duplicated\", str));\n+    let mut keys =\n+        HashMap::<String, Span>::with_capacity(input.keywords.len() + input.symbols.len() + 10);\n+    let mut prev_key: Option<(Span, String)> = None;\n+\n+    let mut check_dup = |span: Span, str: &str, errors: &mut Errors| {\n+        if let Some(prev_span) = keys.get(str) {\n+            errors.error(span, format!(\"Symbol `{}` is duplicated\", str));\n+            errors.error(*prev_span, format!(\"location of previous definition\"));\n+        } else {\n+            keys.insert(str.to_string(), span);\n         }\n     };\n \n-    let mut check_order = |str: &str, errors: &mut Vec<String>| {\n-        if let Some(ref prev_str) = prev_key {\n+    let mut check_order = |span: Span, str: &str, errors: &mut Errors| {\n+        if let Some((prev_span, ref prev_str)) = prev_key {\n             if str < prev_str {\n-                errors.push(format!(\"Symbol `{}` must precede `{}`\", str, prev_str));\n+                errors.error(span, format!(\"Symbol `{}` must precede `{}`\", str, prev_str));\n+                errors.error(prev_span, format!(\"location of previous symbol `{}`\", prev_str));\n             }\n         }\n-        prev_key = Some(str.to_string());\n+        prev_key = Some((span, str.to_string()));\n     };\n \n     // Generate the listed keywords.\n-    for keyword in &input.keywords.0 {\n+    for keyword in input.keywords.iter() {\n         let name = &keyword.name;\n         let value = &keyword.value;\n-        check_dup(&value.value(), &mut errors);\n+        let value_string = value.value();\n+        check_dup(keyword.name.span(), &value_string, &mut errors);\n         prefill_stream.extend(quote! {\n             #value,\n         });\n@@ -120,14 +169,15 @@ pub fn symbols(input: TokenStream) -> TokenStream {\n     }\n \n     // Generate the listed symbols.\n-    for symbol in &input.symbols.0 {\n+    for symbol in input.symbols.iter() {\n         let name = &symbol.name;\n         let value = match &symbol.value {\n             Some(value) => value.value(),\n             None => name.to_string(),\n         };\n-        check_dup(&value, &mut errors);\n-        check_order(&name.to_string(), &mut errors);\n+        check_dup(symbol.name.span(), &value, &mut errors);\n+        check_order(symbol.name.span(), &name.to_string(), &mut errors);\n+\n         prefill_stream.extend(quote! {\n             #value,\n         });\n@@ -142,7 +192,7 @@ pub fn symbols(input: TokenStream) -> TokenStream {\n     // Generate symbols for the strings \"0\", \"1\", ..., \"9\".\n     for n in 0..10 {\n         let n = n.to_string();\n-        check_dup(&n, &mut errors);\n+        check_dup(Span::call_site(), &n, &mut errors);\n         prefill_stream.extend(quote! {\n             #n,\n         });\n@@ -152,14 +202,7 @@ pub fn symbols(input: TokenStream) -> TokenStream {\n         counter += 1;\n     }\n \n-    if !errors.is_empty() {\n-        for error in errors.into_iter() {\n-            eprintln!(\"error: {}\", error)\n-        }\n-        panic!(\"errors in `Keywords` and/or `Symbols`\");\n-    }\n-\n-    let tt = TokenStream::from(quote! {\n+    let output = quote! {\n         macro_rules! keywords {\n             () => {\n                 #keyword_stream\n@@ -184,11 +227,16 @@ pub fn symbols(input: TokenStream) -> TokenStream {\n                 ])\n             }\n         }\n-    });\n+    };\n \n-    // To see the generated code generated, uncomment this line, recompile, and\n-    // run the resulting output through `rustfmt`.\n-    //eprintln!(\"{}\", tt);\n+    (output, errors.list)\n \n-    tt\n+    // To see the generated code, use the \"cargo expand\" command.\n+    // Do this once to install:\n+    //      cargo install cargo-expand\n+    //\n+    // Then, cd to rustc_span and run:\n+    //      cargo expand > /tmp/rustc_span_expanded.rs\n+    //\n+    // and read that file.\n }"}, {"sha": "82b4b876978f248abe50058bef19e491ed9061c9", "filename": "compiler/rustc_macros/src/symbols/tests.rs", "status": "added", "additions": 102, "deletions": 0, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/331e74014a0a2bf18aae7f02495f97958bf9767d/compiler%2Frustc_macros%2Fsrc%2Fsymbols%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/331e74014a0a2bf18aae7f02495f97958bf9767d/compiler%2Frustc_macros%2Fsrc%2Fsymbols%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_macros%2Fsrc%2Fsymbols%2Ftests.rs?ref=331e74014a0a2bf18aae7f02495f97958bf9767d", "patch": "@@ -0,0 +1,102 @@\n+use super::*;\n+\n+// This test is mainly here for interactive development. Use this test while\n+// you're working on the proc-macro defined in this file.\n+#[test]\n+fn test_symbols() {\n+    // We textually include the symbol.rs file, which contains the list of all\n+    // symbols, keywords, and common words. Then we search for the\n+    // `symbols! { ... }` call.\n+\n+    static SYMBOL_RS_FILE: &str = include_str!(\"../../../rustc_span/src/symbol.rs\");\n+\n+    let file = syn::parse_file(SYMBOL_RS_FILE).unwrap();\n+    let symbols_path: syn::Path = syn::parse_quote!(symbols);\n+\n+    let m: &syn::ItemMacro = file\n+        .items\n+        .iter()\n+        .filter_map(|i| {\n+            if let syn::Item::Macro(m) = i {\n+                if m.mac.path == symbols_path { Some(m) } else { None }\n+            } else {\n+                None\n+            }\n+        })\n+        .next()\n+        .expect(\"did not find `symbols!` macro invocation.\");\n+\n+    let body_tokens = m.mac.tokens.clone();\n+\n+    test_symbols_macro(body_tokens, &[]);\n+}\n+\n+fn test_symbols_macro(input: TokenStream, expected_errors: &[&str]) {\n+    let (output, found_errors) = symbols_with_errors(input);\n+\n+    // It should always parse.\n+    let _parsed_file = syn::parse2::<syn::File>(output).unwrap();\n+\n+    assert_eq!(\n+        found_errors.len(),\n+        expected_errors.len(),\n+        \"Macro generated a different number of errors than expected\"\n+    );\n+\n+    for (found_error, &expected_error) in found_errors.iter().zip(expected_errors.iter()) {\n+        let found_error_str = format!(\"{}\", found_error);\n+        assert_eq!(found_error_str, expected_error);\n+    }\n+}\n+\n+#[test]\n+fn check_dup_keywords() {\n+    let input = quote! {\n+        Keywords {\n+            Crate: \"crate\",\n+            Crate: \"crate\",\n+        }\n+        Symbols {}\n+    };\n+    test_symbols_macro(input, &[\"Symbol `crate` is duplicated\", \"location of previous definition\"]);\n+}\n+\n+#[test]\n+fn check_dup_symbol() {\n+    let input = quote! {\n+        Keywords {}\n+        Symbols {\n+            splat,\n+            splat,\n+        }\n+    };\n+    test_symbols_macro(input, &[\"Symbol `splat` is duplicated\", \"location of previous definition\"]);\n+}\n+\n+#[test]\n+fn check_dup_symbol_and_keyword() {\n+    let input = quote! {\n+        Keywords {\n+            Splat: \"splat\",\n+        }\n+        Symbols {\n+            splat,\n+        }\n+    };\n+    test_symbols_macro(input, &[\"Symbol `splat` is duplicated\", \"location of previous definition\"]);\n+}\n+\n+#[test]\n+fn check_symbol_order() {\n+    let input = quote! {\n+        Keywords {}\n+        Symbols {\n+            zebra,\n+            aardvark,\n+        }\n+    };\n+    test_symbols_macro(\n+        input,\n+        &[\"Symbol `aardvark` must precede `zebra`\", \"location of previous symbol `zebra`\"],\n+    );\n+}"}]}