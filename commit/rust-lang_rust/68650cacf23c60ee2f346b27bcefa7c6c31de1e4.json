{"sha": "68650cacf23c60ee2f346b27bcefa7c6c31de1e4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY4NjUwY2FjZjIzYzYwZWUyZjM0NmIyN2JjZWZhN2M2YzMxZGUxZTQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-02-10T11:18:50Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-02-10T11:18:50Z"}, "message": "Auto merge of #58085 - wesleywiser:profiler_2, r=wesleywiser\n\nImplement more detailed self profiling\n\nTiming data and cache hits/misses are now recorded at the query level.\nThis allows us to show detailed per query information such as total time\nfor each query.\n\nTo see detailed query information in the summary pass the `-Z verbose`\nflag. For example:\n\n```\nrustc -Z self-profile -Z verbose hello_world.rs\n```\n\nresults in something like:\n\n```md\nSelf profiling results:\n\n| Phase                                     | Time (ms)      | Time (%) | Queries        | Hits (%)\n| ----------------------------------------- | -------------- | -------- | -------------- | --------\n| Other                                     |            177 |    54.97 |           8094 |    45.47\n| - {time spent not running queries}        |            113 |    35.09 |              0 |     0.00\n| - const_eval                              |             16 |     4.97 |             26 |    11.54\n| - type_of                                 |              9 |     2.80 |            627 |    27.75\n| - const_eval_raw                          |              8 |     2.48 |             22 |     0.00\n| - adt_def                                 |              7 |     2.17 |            381 |    11.55\n| - visible_parent_map                      |              7 |     2.17 |             99 |    98.99\n| - item_attrs                              |              6 |     1.86 |            698 |    50.14\n| - item_children                           |              5 |     1.55 |           2815 |     0.00\n| - adt_dtorck_constraint                   |              4 |     1.24 |              2 |     0.00\n| - adt_destructor                          |              2 |     0.62 |             15 |    86.67\n| TypeChecking                              |             53 |    16.46 |           2834 |    79.89\n| - trait_impls_of                          |              9 |     2.80 |             65 |    86.15\n| - evaluate_obligation                     |              7 |     2.17 |             80 |     2.50\n| - const_is_rvalue_promotable_to_static    |              6 |     1.86 |              1 |     0.00\n| - is_copy_raw                             |              6 |     1.86 |             29 |    58.62\n| - rvalue_promotable_map                   |              6 |     1.86 |              2 |    50.00\n| - {time spent not running queries}        |              6 |     1.86 |              0 |     0.00\n| - typeck_item_bodies                      |              5 |     1.55 |              1 |     0.00\n| - typeck_tables_of                        |              5 |     1.55 |             19 |    94.74\n| - dropck_outlives                         |              2 |     0.62 |              1 |     0.00\n| - layout_raw                              |              1 |     0.31 |            668 |    87.87\n| Linking                                   |             48 |    14.91 |             43 |    46.51\n| - {time spent not running queries}        |             48 |    14.91 |              0 |     0.00\n| Codegen                                   |             29 |     9.01 |            420 |    61.90\n| - {time spent not running queries}        |             16 |     4.97 |              0 |     0.00\n| - collect_and_partition_mono_items        |             11 |     3.42 |             13 |    92.31\n| - mir_const                               |              1 |     0.31 |              1 |     0.00\n| - mir_validated                           |              1 |     0.31 |              3 |    66.67\n| Expansion                                 |             14 |     4.35 |              0 |     0.00\n| - {time spent not running queries}        |             14 |     4.35 |              0 |     0.00\n| BorrowChecking                            |              1 |     0.31 |             12 |    41.67\n| - borrowck                                |              1 |     0.31 |              2 |    50.00\n| Parsing                                   |              0 |     0.00 |              0 |     0.00\n\nOptimization level: No\nIncremental: off\n```\n\n<details>\n<summary>Rendered</summary>\n\nSelf profiling results:\n\n| Phase                                     | Time (ms)      | Time (%) | Queries        | Hits (%)\n| ----------------------------------------- | -------------- | -------- | -------------- | --------\n| **Other**                                     |           **177** |   **54.97** |   **8094** |  **45.47**\n| - {time spent not running queries}        |            113 |    35.09 |              0 |     0.00\n| - const_eval                              |             16 |     4.97 |             26 |    11.54\n| - type_of                                 |              9 |     2.80 |            627 |    27.75\n| - const_eval_raw                          |              8 |     2.48 |             22 |     0.00\n| - adt_def                                 |              7 |     2.17 |            381 |    11.55\n| - visible_parent_map                      |              7 |     2.17 |             99 |    98.99\n| - item_attrs                              |              6 |     1.86 |            698 |    50.14\n| - item_children                           |              5 |     1.55 |           2815 |     0.00\n| - adt_dtorck_constraint                   |              4 |     1.24 |              2 |     0.00\n| - adt_destructor                          |              2 |     0.62 |             15 |    86.67\n| TypeChecking                              |             53 |    16.46 |           2834 |    79.89\n| - trait_impls_of                          |              9 |     2.80 |             65 |    86.15\n| - evaluate_obligation                     |              7 |     2.17 |             80 |     2.50\n| - const_is_rvalue_promotable_to_static    |              6 |     1.86 |              1 |     0.00\n| - is_copy_raw                             |              6 |     1.86 |             29 |    58.62\n| - rvalue_promotable_map                   |              6 |     1.86 |              2 |    50.00\n| - {time spent not running queries}        |              6 |     1.86 |              0 |     0.00\n| - typeck_item_bodies                      |              5 |     1.55 |              1 |     0.00\n| - typeck_tables_of                        |              5 |     1.55 |             19 |    94.74\n| - dropck_outlives                         |              2 |     0.62 |              1 |     0.00\n| - layout_raw                              |              1 |     0.31 |            668 |    87.87\n| Linking                                   |             48 |    14.91 |             43 |    46.51\n| - {time spent not running queries}        |             48 |    14.91 |              0 |     0.00\n| Codegen                                   |             29 |     9.01 |            420 |    61.90\n| - {time spent not running queries}        |             16 |     4.97 |              0 |     0.00\n| - collect_and_partition_mono_items        |             11 |     3.42 |             13 |    92.31\n| - mir_const                               |              1 |     0.31 |              1 |     0.00\n| - mir_validated                           |              1 |     0.31 |              3 |    66.67\n| Expansion                                 |             14 |     4.35 |              0 |     0.00\n| - {time spent not running queries}        |             14 |     4.35 |              0 |     0.00\n| BorrowChecking                            |              1 |     0.31 |             12 |    41.67\n| - borrowck                                |              1 |     0.31 |              2 |    50.00\n| Parsing                                   |              0 |     0.00 |              0 |     0.00\n\nOptimization level: No\nIncremental: off\n\n</details>\ncc @nikomatsakis @michaelwoerister @Zoxc\n\nFixes #54141", "tree": {"sha": "2790801be091ea556e4afc1068aa066961bf4163", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2790801be091ea556e4afc1068aa066961bf4163"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/68650cacf23c60ee2f346b27bcefa7c6c31de1e4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/68650cacf23c60ee2f346b27bcefa7c6c31de1e4", "html_url": "https://github.com/rust-lang/rust/commit/68650cacf23c60ee2f346b27bcefa7c6c31de1e4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/68650cacf23c60ee2f346b27bcefa7c6c31de1e4/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "de111e6367b065fd5f8cee59b64eefefd8272f44", "url": "https://api.github.com/repos/rust-lang/rust/commits/de111e6367b065fd5f8cee59b64eefefd8272f44", "html_url": "https://github.com/rust-lang/rust/commit/de111e6367b065fd5f8cee59b64eefefd8272f44"}, {"sha": "584081af4a386e9ef2e03684f1f3f1466b3996d1", "url": "https://api.github.com/repos/rust-lang/rust/commits/584081af4a386e9ef2e03684f1f3f1466b3996d1", "html_url": "https://github.com/rust-lang/rust/commit/584081af4a386e9ef2e03684f1f3f1466b3996d1"}], "stats": {"total": 545, "additions": 363, "deletions": 182}, "files": [{"sha": "f63fbd79825db482be357e12695cd0591bd57e91", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/68650cacf23c60ee2f346b27bcefa7c6c31de1e4/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/68650cacf23c60ee2f346b27bcefa7c6c31de1e4/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=68650cacf23c60ee2f346b27bcefa7c6c31de1e4", "patch": "@@ -113,7 +113,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             let mut lock = cache.borrow_mut();\n             if let Some(value) = lock.results.get(key) {\n                 profq_msg!(tcx, ProfileQueriesMsg::CacheHit);\n-                tcx.sess.profiler(|p| p.record_query_hit(Q::CATEGORY));\n+                tcx.sess.profiler(|p| p.record_query_hit(Q::NAME, Q::CATEGORY));\n                 let result = Ok((value.value.clone(), value.index));\n                 #[cfg(debug_assertions)]\n                 {\n@@ -375,7 +375,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n \n         if dep_node.kind.is_anon() {\n             profq_msg!(self, ProfileQueriesMsg::ProviderBegin);\n-            self.sess.profiler(|p| p.start_activity(Q::CATEGORY));\n+            self.sess.profiler(|p| p.start_query(Q::NAME, Q::CATEGORY));\n \n             let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n                 job.start(self, diagnostics, |tcx| {\n@@ -385,7 +385,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                 })\n             });\n \n-            self.sess.profiler(|p| p.end_activity(Q::CATEGORY));\n+            self.sess.profiler(|p| p.end_query(Q::NAME, Q::CATEGORY));\n             profq_msg!(self, ProfileQueriesMsg::ProviderEnd);\n \n             self.dep_graph.read_index(dep_node_index);\n@@ -452,14 +452,14 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n \n         let result = if let Some(result) = result {\n             profq_msg!(self, ProfileQueriesMsg::CacheHit);\n-            self.sess.profiler(|p| p.record_query_hit(Q::CATEGORY));\n+            self.sess.profiler(|p| p.record_query_hit(Q::NAME, Q::CATEGORY));\n \n             result\n         } else {\n             // We could not load a result from the on-disk cache, so\n             // recompute.\n \n-            self.sess.profiler(|p| p.start_activity(Q::CATEGORY));\n+            self.sess.profiler(|p| p.start_query(Q::NAME, Q::CATEGORY));\n \n             // The diagnostics for this query have already been\n             // promoted to the current session during\n@@ -472,7 +472,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                 })\n             });\n \n-            self.sess.profiler(|p| p.end_activity(Q::CATEGORY));\n+            self.sess.profiler(|p| p.end_query(Q::NAME, Q::CATEGORY));\n             result\n         };\n \n@@ -537,7 +537,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                 key, dep_node);\n \n         profq_msg!(self, ProfileQueriesMsg::ProviderBegin);\n-        self.sess.profiler(|p| p.start_activity(Q::CATEGORY));\n+        self.sess.profiler(|p| p.start_query(Q::NAME, Q::CATEGORY));\n \n         let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n             job.start(self, diagnostics, |tcx| {\n@@ -557,7 +557,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n             })\n         });\n \n-        self.sess.profiler(|p| p.end_activity(Q::CATEGORY));\n+        self.sess.profiler(|p| p.end_query(Q::NAME, Q::CATEGORY));\n         profq_msg!(self, ProfileQueriesMsg::ProviderEnd);\n \n         if unlikely!(self.sess.opts.debugging_opts.query_dep_graph) {\n@@ -600,7 +600,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n             let _ = self.get_query::<Q>(DUMMY_SP, key);\n         } else {\n             profq_msg!(self, ProfileQueriesMsg::CacheHit);\n-            self.sess.profiler(|p| p.record_query_hit(Q::CATEGORY));\n+            self.sess.profiler(|p| p.record_query_hit(Q::NAME, Q::CATEGORY));\n         }\n     }\n \n@@ -739,6 +739,7 @@ macro_rules! define_queries_inner {\n                 sess.profiler(|p| {\n                     $(\n                         p.record_computed_queries(\n+                            <queries::$name<'_> as QueryConfig<'_>>::NAME,\n                             <queries::$name<'_> as QueryConfig<'_>>::CATEGORY,\n                             self.$name.lock().results.len()\n                         );"}, {"sha": "f8fa01b6395008beb0abc4748f7ba6e7e8fa1d47", "filename": "src/librustc/util/profiling.rs", "status": "modified", "additions": 353, "deletions": 173, "changes": 526, "blob_url": "https://github.com/rust-lang/rust/blob/68650cacf23c60ee2f346b27bcefa7c6c31de1e4/src%2Flibrustc%2Futil%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/68650cacf23c60ee2f346b27bcefa7c6c31de1e4/src%2Flibrustc%2Futil%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fprofiling.rs?ref=68650cacf23c60ee2f346b27bcefa7c6c31de1e4", "patch": "@@ -1,251 +1,431 @@\n-use crate::session::config::Options;\n-\n+use std::collections::{BTreeMap, HashMap};\n use std::fs;\n-use std::io::{self, StderrLock, Write};\n+use std::io::{self, Write};\n+use std::thread::ThreadId;\n use std::time::Instant;\n \n-macro_rules! define_categories {\n-    ($($name:ident,)*) => {\n-        #[derive(Clone, Copy, Debug, PartialEq, Eq)]\n-        pub enum ProfileCategory {\n-            $($name),*\n+use crate::session::config::{Options, OptLevel};\n+\n+#[derive(Clone, Copy, Debug, PartialEq, Eq, Ord, PartialOrd)]\n+pub enum ProfileCategory {\n+    Parsing,\n+    Expansion,\n+    TypeChecking,\n+    BorrowChecking,\n+    Codegen,\n+    Linking,\n+    Other,\n+}\n+\n+#[derive(Clone, Copy, Debug, Eq, PartialEq)]\n+pub enum ProfilerEvent {\n+    QueryStart { query_name: &'static str, category: ProfileCategory, time: Instant },\n+    QueryEnd { query_name: &'static str, category: ProfileCategory, time: Instant },\n+    GenericActivityStart { category: ProfileCategory, time: Instant },\n+    GenericActivityEnd { category: ProfileCategory, time: Instant },\n+    QueryCacheHit { query_name: &'static str, category: ProfileCategory },\n+    QueryCount { query_name: &'static str, category: ProfileCategory, count: usize },\n+}\n+\n+impl ProfilerEvent {\n+    fn is_start_event(&self) -> bool {\n+        use self::ProfilerEvent::*;\n+\n+        match self {\n+            QueryStart { .. } | GenericActivityStart { .. } => true,\n+            QueryEnd { .. } | GenericActivityEnd { .. } |\n+            QueryCacheHit { .. } | QueryCount { .. } => false,\n         }\n+    }\n+}\n \n-        #[allow(nonstandard_style)]\n-        struct Categories<T> {\n-            $($name: T),*\n+pub struct SelfProfiler {\n+    events: HashMap<ThreadId, Vec<ProfilerEvent>>,\n+}\n+\n+struct CategoryResultData {\n+    query_times: BTreeMap<&'static str, u64>,\n+    query_cache_stats: BTreeMap<&'static str, (u64, u64)>, //(hits, total)\n+}\n+\n+impl CategoryResultData {\n+    fn new() -> CategoryResultData {\n+        CategoryResultData {\n+            query_times: BTreeMap::new(),\n+            query_cache_stats: BTreeMap::new(),\n         }\n+    }\n \n-        impl<T: Default> Categories<T> {\n-            fn new() -> Categories<T> {\n-                Categories {\n-                    $($name: T::default()),*\n-                }\n-            }\n+    fn total_time(&self) -> u64 {\n+        let mut total = 0;\n+        for (_, time) in &self.query_times {\n+            total += time;\n         }\n \n-        impl<T> Categories<T> {\n-            fn get(&self, category: ProfileCategory) -> &T {\n-                match category {\n-                    $(ProfileCategory::$name => &self.$name),*\n-                }\n-            }\n+        total\n+    }\n \n-            fn set(&mut self, category: ProfileCategory, value: T) {\n-                match category {\n-                    $(ProfileCategory::$name => self.$name = value),*\n-                }\n-            }\n-        }\n+    fn total_cache_data(&self) -> (u64, u64) {\n+        let (mut hits, mut total) = (0, 0);\n \n-        struct CategoryData {\n-            times: Categories<u64>,\n-            query_counts: Categories<(u64, u64)>,\n+        for (_, (h, t)) in &self.query_cache_stats {\n+            hits += h;\n+            total += t;\n         }\n \n-        impl CategoryData {\n-            fn new() -> CategoryData {\n-                CategoryData {\n-                    times: Categories::new(),\n-                    query_counts: Categories::new(),\n-                }\n-            }\n+        (hits, total)\n+    }\n+}\n \n-            fn print(&self, lock: &mut StderrLock<'_>) {\n-                writeln!(lock, \"| Phase            | Time (ms)      \\\n-                                | Time (%) | Queries        | Hits (%)\")\n-                    .unwrap();\n-                writeln!(lock, \"| ---------------- | -------------- \\\n-                                | -------- | -------------- | --------\")\n-                    .unwrap();\n-\n-                let total_time = ($(self.times.$name + )* 0) as f32;\n-\n-                $(\n-                    let (hits, computed) = self.query_counts.$name;\n-                    let total = hits + computed;\n-                    let (hits, total) = if total > 0 {\n-                        (format!(\"{:.2}\",\n-                        (((hits as f32) / (total as f32)) * 100.0)), total.to_string())\n-                    } else {\n-                        (String::new(), String::new())\n-                    };\n+impl Default for CategoryResultData {\n+    fn default() -> CategoryResultData {\n+        CategoryResultData::new()\n+    }\n+}\n \n-                    writeln!(\n-                        lock,\n-                        \"| {0: <16} | {1: <14} | {2: <8.2} | {3: <14} | {4: <8}\",\n-                        stringify!($name),\n-                        self.times.$name / 1_000_000,\n-                        ((self.times.$name as f32) / total_time) * 100.0,\n-                        total,\n-                        hits,\n-                    ).unwrap();\n-                )*\n-            }\n+struct CalculatedResults {\n+    categories: BTreeMap<ProfileCategory, CategoryResultData>,\n+    crate_name: Option<String>,\n+    optimization_level: OptLevel,\n+    incremental: bool,\n+    verbose: bool,\n+}\n \n-            fn json(&self) -> String {\n-                let mut json = String::from(\"[\");\n-\n-                $(\n-                    let (hits, computed) = self.query_counts.$name;\n-                    let total = hits + computed;\n-\n-                    //normalize hits to 0%\n-                    let hit_percent =\n-                        if total > 0 {\n-                            ((hits as f32) / (total as f32)) * 100.0\n-                        } else {\n-                            0.0\n-                        };\n-\n-                    json.push_str(&format!(\n-                        \"{{ \\\"category\\\": \\\"{}\\\", \\\"time_ms\\\": {},\\\n-                            \\\"query_count\\\": {}, \\\"query_hits\\\": {} }},\",\n-                        stringify!($name),\n-                        self.times.$name / 1_000_000,\n-                        total,\n-                        format!(\"{:.2}\", hit_percent)\n-                    ));\n-                )*\n+impl CalculatedResults {\n+    fn new() -> CalculatedResults {\n+        CalculatedResults {\n+            categories: BTreeMap::new(),\n+            crate_name: None,\n+            optimization_level: OptLevel::No,\n+            incremental: false,\n+            verbose: false,\n+        }\n+    }\n \n-                //remove the trailing ',' character\n-                json.pop();\n+    fn consolidate(mut cr1: CalculatedResults, cr2: CalculatedResults) -> CalculatedResults {\n+        for (category, data) in cr2.categories {\n+            let cr1_data = cr1.categories.entry(category).or_default();\n \n-                json.push(']');\n+            for (query, time) in data.query_times {\n+                *cr1_data.query_times.entry(query).or_default() += time;\n+            }\n \n-                json\n+            for (query, (hits, total)) in data.query_cache_stats {\n+                let (h, t) = cr1_data.query_cache_stats.entry(query).or_insert((0, 0));\n+                *h += hits;\n+                *t += total;\n             }\n         }\n+\n+        cr1\n+    }\n+\n+    fn total_time(&self) -> u64 {\n+        let mut total = 0;\n+\n+        for (_, data) in &self.categories {\n+            total += data.total_time();\n+        }\n+\n+        total\n+    }\n+\n+    fn with_options(mut self, opts: &Options) -> CalculatedResults {\n+        self.crate_name = opts.crate_name.clone();\n+        self.optimization_level = opts.optimize;\n+        self.incremental = opts.incremental.is_some();\n+        self.verbose = opts.debugging_opts.verbose;\n+\n+        self\n     }\n }\n \n-define_categories! {\n-    Parsing,\n-    Expansion,\n-    TypeChecking,\n-    BorrowChecking,\n-    Codegen,\n-    Linking,\n-    Other,\n+fn time_between_ns(start: Instant, end: Instant) -> u64 {\n+    if start < end {\n+        let time = end - start;\n+        (time.as_secs() * 1_000_000_000) + (time.subsec_nanos() as u64)\n+    } else {\n+        debug!(\"time_between_ns: ignorning instance of end < start\");\n+        0\n+    }\n }\n \n-pub struct SelfProfiler {\n-    timer_stack: Vec<ProfileCategory>,\n-    data: CategoryData,\n-    current_timer: Instant,\n+fn calculate_percent(numerator: u64, denominator: u64) -> f32 {\n+    if denominator > 0 {\n+        ((numerator as f32) / (denominator as f32)) * 100.0\n+    } else {\n+        0.0\n+    }\n }\n \n impl SelfProfiler {\n     pub fn new() -> SelfProfiler {\n         let mut profiler = SelfProfiler {\n-            timer_stack: Vec::new(),\n-            data: CategoryData::new(),\n-            current_timer: Instant::now(),\n+            events: HashMap::new(),\n         };\n \n         profiler.start_activity(ProfileCategory::Other);\n \n         profiler\n     }\n \n+    #[inline]\n     pub fn start_activity(&mut self, category: ProfileCategory) {\n-        match self.timer_stack.last().cloned() {\n-            None => {\n-                self.current_timer = Instant::now();\n-            },\n-            Some(current_category) if current_category == category => {\n-                //since the current category is the same as the new activity's category,\n-                //we don't need to do anything with the timer, we just need to push it on the stack\n-            }\n-            Some(current_category) => {\n-                let elapsed = self.stop_timer();\n+        self.record(ProfilerEvent::GenericActivityStart {\n+            category,\n+            time: Instant::now(),\n+        })\n+    }\n \n-                //record the current category's time\n-                let new_time = self.data.times.get(current_category) + elapsed;\n-                self.data.times.set(current_category, new_time);\n-            }\n-        }\n+    #[inline]\n+    pub fn end_activity(&mut self, category: ProfileCategory) {\n+        self.record(ProfilerEvent::GenericActivityEnd {\n+            category,\n+            time: Instant::now(),\n+        })\n+    }\n \n-        //push the new category\n-        self.timer_stack.push(category);\n+    #[inline]\n+    pub fn record_computed_queries(\n+        &mut self,\n+        query_name: &'static str,\n+        category: ProfileCategory,\n+        count: usize)\n+        {\n+        self.record(ProfilerEvent::QueryCount {\n+            query_name,\n+            category,\n+            count,\n+        })\n     }\n \n-    pub fn record_computed_queries(&mut self, category: ProfileCategory, count: usize) {\n-        let (hits, computed) = *self.data.query_counts.get(category);\n-        self.data.query_counts.set(category, (hits, computed + count as u64));\n+    #[inline]\n+    pub fn record_query_hit(&mut self, query_name: &'static str, category: ProfileCategory) {\n+        self.record(ProfilerEvent::QueryCacheHit {\n+            query_name,\n+            category,\n+        })\n     }\n \n-    pub fn record_query_hit(&mut self, category: ProfileCategory) {\n-        let (hits, computed) = *self.data.query_counts.get(category);\n-        self.data.query_counts.set(category, (hits + 1, computed));\n+    #[inline]\n+    pub fn start_query(&mut self, query_name: &'static str, category: ProfileCategory) {\n+        self.record(ProfilerEvent::QueryStart {\n+            query_name,\n+            category,\n+            time: Instant::now(),\n+        });\n     }\n \n-    pub fn end_activity(&mut self, category: ProfileCategory) {\n-        match self.timer_stack.pop() {\n-            None => bug!(\"end_activity() was called but there was no running activity\"),\n-            Some(c) =>\n-                assert!(\n-                    c == category,\n-                    \"end_activity() was called but a different activity was running\"),\n+    #[inline]\n+    pub fn end_query(&mut self, query_name: &'static str, category: ProfileCategory) {\n+        self.record(ProfilerEvent::QueryEnd {\n+            query_name,\n+            category,\n+            time: Instant::now(),\n+        })\n+    }\n+\n+    #[inline]\n+    fn record(&mut self, event: ProfilerEvent) {\n+        let thread_id = std::thread::current().id();\n+        let events = self.events.entry(thread_id).or_default();\n+\n+        events.push(event);\n+    }\n+\n+    fn calculate_thread_results(events: &Vec<ProfilerEvent>) -> CalculatedResults {\n+        use self::ProfilerEvent::*;\n+\n+        assert!(\n+            events.last().map(|e| !e.is_start_event()).unwrap_or(true),\n+            \"there was an event running when calculate_reslts() was called\"\n+        );\n+\n+        let mut results = CalculatedResults::new();\n+\n+        //(event, child time to subtract)\n+        let mut query_stack = Vec::new();\n+\n+        for event in events {\n+            match event {\n+                QueryStart { .. } | GenericActivityStart { .. } => {\n+                    query_stack.push((event, 0));\n+                },\n+                QueryEnd { query_name, category, time: end_time } => {\n+                    let previous_query = query_stack.pop();\n+                    if let Some((QueryStart {\n+                                    query_name: p_query_name,\n+                                    time: start_time,\n+                                    category: _ }, child_time_to_subtract)) = previous_query {\n+                        assert_eq!(\n+                            p_query_name,\n+                            query_name,\n+                            \"Saw a query end but the previous query wasn't the corresponding start\"\n+                        );\n+\n+                        let time_ns = time_between_ns(*start_time, *end_time);\n+                        let self_time_ns = time_ns - child_time_to_subtract;\n+                        let result_data = results.categories.entry(*category).or_default();\n+\n+                        *result_data.query_times.entry(query_name).or_default() += self_time_ns;\n+\n+                        if let Some((_, child_time_to_subtract)) = query_stack.last_mut() {\n+                            *child_time_to_subtract += time_ns;\n+                        }\n+                    } else {\n+                        bug!(\"Saw a query end but the previous event wasn't a query start\");\n+                    }\n+                }\n+                GenericActivityEnd { category, time: end_time } => {\n+                    let previous_event = query_stack.pop();\n+                    if let Some((GenericActivityStart {\n+                                    category: previous_category,\n+                                    time: start_time }, child_time_to_subtract)) = previous_event {\n+                        assert_eq!(\n+                            previous_category,\n+                            category,\n+                            \"Saw an end but the previous event wasn't the corresponding start\"\n+                        );\n+\n+                        let time_ns = time_between_ns(*start_time, *end_time);\n+                        let self_time_ns = time_ns - child_time_to_subtract;\n+                        let result_data = results.categories.entry(*category).or_default();\n+\n+                        *result_data.query_times\n+                            .entry(\"{time spent not running queries}\")\n+                            .or_default() += self_time_ns;\n+\n+                        if let Some((_, child_time_to_subtract)) = query_stack.last_mut() {\n+                            *child_time_to_subtract += time_ns;\n+                        }\n+                    } else {\n+                        bug!(\"Saw an activity end but the previous event wasn't an activity start\");\n+                    }\n+                },\n+                QueryCacheHit { category, query_name } => {\n+                    let result_data = results.categories.entry(*category).or_default();\n+\n+                    let (hits, total) =\n+                        result_data.query_cache_stats.entry(query_name).or_insert((0, 0));\n+                    *hits += 1;\n+                    *total += 1;\n+                },\n+                QueryCount { category, query_name, count } => {\n+                    let result_data = results.categories.entry(*category).or_default();\n+\n+                    let (_, totals) =\n+                        result_data.query_cache_stats.entry(query_name).or_insert((0, 0));\n+                    *totals += *count as u64;\n+                },\n+            }\n         }\n \n-        //check if the new running timer is in the same category as this one\n-        //if it is, we don't need to do anything\n-        if let Some(c) = self.timer_stack.last() {\n-            if *c == category {\n-                return;\n+        //normalize the times to ms\n+        for (_, data) in &mut results.categories {\n+            for (_, time) in &mut data.query_times {\n+                *time = *time / 1_000_000;\n             }\n         }\n \n-        //the new timer is different than the previous,\n-        //so record the elapsed time and start a new timer\n-        let elapsed = self.stop_timer();\n-        let new_time = self.data.times.get(category) + elapsed;\n-        self.data.times.set(category, new_time);\n+        results\n     }\n \n-    fn stop_timer(&mut self) -> u64 {\n-        let elapsed = self.current_timer.elapsed();\n-\n-        self.current_timer = Instant::now();\n-\n-        (elapsed.as_secs() * 1_000_000_000) + (elapsed.subsec_nanos() as u64)\n+    fn get_results(&self, opts: &Options) -> CalculatedResults {\n+        self.events\n+            .iter()\n+            .map(|(_, r)| SelfProfiler::calculate_thread_results(r))\n+            .fold(CalculatedResults::new(), CalculatedResults::consolidate)\n+            .with_options(opts)\n     }\n \n     pub fn print_results(&mut self, opts: &Options) {\n         self.end_activity(ProfileCategory::Other);\n \n-        assert!(\n-            self.timer_stack.is_empty(),\n-            \"there were timers running when print_results() was called\");\n+        let results = self.get_results(opts);\n+\n+        let total_time = results.total_time() as f32;\n \n         let out = io::stderr();\n         let mut lock = out.lock();\n \n-        let crate_name =\n-            opts.crate_name\n-            .as_ref()\n-            .map(|n| format!(\" for {}\", n))\n-            .unwrap_or_default();\n+        let crate_name = results.crate_name.map(|n| format!(\" for {}\", n)).unwrap_or_default();\n \n         writeln!(lock, \"Self profiling results{}:\", crate_name).unwrap();\n         writeln!(lock).unwrap();\n \n-        self.data.print(&mut lock);\n+        writeln!(lock, \"| Phase                                     | Time (ms)      \\\n+                        | Time (%) | Queries        | Hits (%)\")\n+            .unwrap();\n+        writeln!(lock, \"| ----------------------------------------- | -------------- \\\n+                        | -------- | -------------- | --------\")\n+            .unwrap();\n+\n+        let mut categories: Vec<_> = results.categories.iter().collect();\n+        categories.sort_by(|(_, data1), (_, data2)| data2.total_time().cmp(&data1.total_time()));\n+\n+        for (category, data) in categories {\n+            let (category_hits, category_total) = data.total_cache_data();\n+            let category_hit_percent = calculate_percent(category_hits, category_total);\n+\n+            writeln!(\n+                lock,\n+                \"| {0: <41} | {1: >14} | {2: >8.2} | {3: >14} | {4: >8}\",\n+                format!(\"{:?}\", category),\n+                data.total_time(),\n+                ((data.total_time() as f32) / total_time) * 100.0,\n+                category_total,\n+                format!(\"{:.2}\", category_hit_percent),\n+            ).unwrap();\n+\n+            //in verbose mode, show individual query data\n+            if results.verbose {\n+                //don't show queries that took less than 1ms\n+                let mut times: Vec<_> = data.query_times.iter().filter(|(_, t)| **t > 0).collect();\n+                times.sort_by(|(_, time1), (_, time2)| time2.cmp(time1));\n+\n+                for (query, time) in times {\n+                    let (hits, total) = data.query_cache_stats.get(query).unwrap_or(&(0, 0));\n+                    let hit_percent = calculate_percent(*hits, *total);\n+\n+                    writeln!(\n+                        lock,\n+                        \"| - {0: <39} | {1: >14} | {2: >8.2} | {3: >14} | {4: >8}\",\n+                        query,\n+                        time,\n+                        ((*time as f32) / total_time) * 100.0,\n+                        total,\n+                        format!(\"{:.2}\", hit_percent),\n+                    ).unwrap();\n+                }\n+            }\n+        }\n \n         writeln!(lock).unwrap();\n         writeln!(lock, \"Optimization level: {:?}\", opts.optimize).unwrap();\n-\n-        let incremental = if opts.incremental.is_some() { \"on\" } else { \"off\" };\n-        writeln!(lock, \"Incremental: {}\", incremental).unwrap();\n+        writeln!(lock, \"Incremental: {}\", if results.incremental { \"on\" } else { \"off\" }).unwrap();\n     }\n \n     pub fn save_results(&self, opts: &Options) {\n-        let category_data = self.data.json();\n+        let results = self.get_results(opts);\n+\n         let compilation_options =\n             format!(\"{{ \\\"optimization_level\\\": \\\"{:?}\\\", \\\"incremental\\\": {} }}\",\n-                    opts.optimize,\n-                    if opts.incremental.is_some() { \"true\" } else { \"false\" });\n+                    results.optimization_level,\n+                    if results.incremental { \"true\" } else { \"false\" });\n+\n+        let mut category_data = String::new();\n+\n+        for (category, data) in &results.categories {\n+            let (hits, total) = data.total_cache_data();\n+            let hit_percent = calculate_percent(hits, total);\n+\n+            category_data.push_str(&format!(\"{{ \\\"category\\\": \\\"{:?}\\\", \\\"time_ms\\\": {}, \\\n+                                                \\\"query_count\\\": {}, \\\"query_hits\\\": {} }}\",\n+                                            category,\n+                                            data.total_time(),\n+                                            total,\n+                                            format!(\"{:.2}\", hit_percent)));\n+        }\n \n         let json = format!(\"{{ \\\"category_data\\\": {}, \\\"compilation_options\\\": {} }}\",\n                         category_data,"}]}