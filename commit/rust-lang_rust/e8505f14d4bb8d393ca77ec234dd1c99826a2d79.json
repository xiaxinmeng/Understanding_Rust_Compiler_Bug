{"sha": "e8505f14d4bb8d393ca77ec234dd1c99826a2d79", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU4NTA1ZjE0ZDRiYjhkMzkzY2E3N2VjMjM0ZGQxYzk5ODI2YTJkNzk=", "commit": {"author": {"name": "Lauren\u021biu Nicola", "email": "lnicola@dend.ro", "date": "2020-07-01T09:43:36Z"}, "committer": {"name": "Lauren\u021biu Nicola", "email": "lnicola@dend.ro", "date": "2020-07-01T11:38:42Z"}, "message": "Try to reduce Semantics monomorphisations", "tree": {"sha": "21a8035b8e27cc1c66e66a69a3228e06160057bb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/21a8035b8e27cc1c66e66a69a3228e06160057bb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e8505f14d4bb8d393ca77ec234dd1c99826a2d79", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e8505f14d4bb8d393ca77ec234dd1c99826a2d79", "html_url": "https://github.com/rust-lang/rust/commit/e8505f14d4bb8d393ca77ec234dd1c99826a2d79", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e8505f14d4bb8d393ca77ec234dd1c99826a2d79/comments", "author": {"login": "lnicola", "id": 308347, "node_id": "MDQ6VXNlcjMwODM0Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/308347?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lnicola", "html_url": "https://github.com/lnicola", "followers_url": "https://api.github.com/users/lnicola/followers", "following_url": "https://api.github.com/users/lnicola/following{/other_user}", "gists_url": "https://api.github.com/users/lnicola/gists{/gist_id}", "starred_url": "https://api.github.com/users/lnicola/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lnicola/subscriptions", "organizations_url": "https://api.github.com/users/lnicola/orgs", "repos_url": "https://api.github.com/users/lnicola/repos", "events_url": "https://api.github.com/users/lnicola/events{/privacy}", "received_events_url": "https://api.github.com/users/lnicola/received_events", "type": "User", "site_admin": false}, "committer": {"login": "lnicola", "id": 308347, "node_id": "MDQ6VXNlcjMwODM0Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/308347?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lnicola", "html_url": "https://github.com/lnicola", "followers_url": "https://api.github.com/users/lnicola/followers", "following_url": "https://api.github.com/users/lnicola/following{/other_user}", "gists_url": "https://api.github.com/users/lnicola/gists{/gist_id}", "starred_url": "https://api.github.com/users/lnicola/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lnicola/subscriptions", "organizations_url": "https://api.github.com/users/lnicola/orgs", "repos_url": "https://api.github.com/users/lnicola/repos", "events_url": "https://api.github.com/users/lnicola/events{/privacy}", "received_events_url": "https://api.github.com/users/lnicola/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "99d6ef29a136069f6c99ec9f628108f151dec999", "url": "https://api.github.com/repos/rust-lang/rust/commits/99d6ef29a136069f6c99ec9f628108f151dec999", "html_url": "https://github.com/rust-lang/rust/commit/99d6ef29a136069f6c99ec9f628108f151dec999"}], "stats": {"total": 217, "additions": 193, "deletions": 24}, "files": [{"sha": "fbea9ad5711725854bb469bcb811e6bbb7e11bec", "filename": "crates/ra_hir/src/semantics.rs", "status": "modified", "additions": 186, "deletions": 23, "changes": 209, "blob_url": "https://github.com/rust-lang/rust/blob/e8505f14d4bb8d393ca77ec234dd1c99826a2d79/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e8505f14d4bb8d393ca77ec234dd1c99826a2d79/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsemantics.rs?ref=e8505f14d4bb8d393ca77ec234dd1c99826a2d79", "patch": "@@ -83,6 +83,11 @@ impl PathResolution {\n /// Primary API to get semantic information, like types, from syntax trees.\n pub struct Semantics<'db, DB> {\n     pub db: &'db DB,\n+    impl_: SemanticsImpl<'db>,\n+}\n+\n+pub struct SemanticsImpl<'db> {\n+    pub db: &'db dyn HirDatabase,\n     s2d_cache: RefCell<SourceToDefCache>,\n     cache: RefCell<FxHashMap<SyntaxNode, HirFileId>>,\n }\n@@ -95,7 +100,166 @@ impl<DB> fmt::Debug for Semantics<'_, DB> {\n \n impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n     pub fn new(db: &DB) -> Semantics<DB> {\n-        Semantics { db, s2d_cache: Default::default(), cache: Default::default() }\n+        let impl_ = SemanticsImpl::new(db);\n+        Semantics { db, impl_ }\n+    }\n+\n+    pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n+        self.impl_.parse(file_id)\n+    }\n+\n+    pub fn ast<T: AstDiagnostic + Diagnostic>(&self, d: &T) -> <T as AstDiagnostic>::AST {\n+        self.impl_.ast(d)\n+    }\n+\n+    pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n+        self.impl_.expand(macro_call)\n+    }\n+\n+    pub fn expand_hypothetical(\n+        &self,\n+        actual_macro_call: &ast::MacroCall,\n+        hypothetical_args: &ast::TokenTree,\n+        token_to_map: SyntaxToken,\n+    ) -> Option<(SyntaxNode, SyntaxToken)> {\n+        self.impl_.expand_hypothetical(actual_macro_call, hypothetical_args, token_to_map)\n+    }\n+\n+    pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n+        self.impl_.descend_into_macros(token)\n+    }\n+\n+    pub fn descend_node_at_offset<N: ast::AstNode>(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> Option<N> {\n+        self.impl_.descend_node_at_offset(node, offset)\n+    }\n+\n+    pub fn original_range(&self, node: &SyntaxNode) -> FileRange {\n+        self.impl_.original_range(node)\n+    }\n+\n+    pub fn diagnostics_range(&self, diagnostics: &dyn Diagnostic) -> FileRange {\n+        self.impl_.diagnostics_range(diagnostics)\n+    }\n+\n+    pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n+        self.impl_.ancestors_with_macros(node)\n+    }\n+\n+    pub fn ancestors_at_offset_with_macros(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> impl Iterator<Item = SyntaxNode> + '_ {\n+        self.impl_.ancestors_at_offset_with_macros(node, offset)\n+    }\n+\n+    /// Find a AstNode by offset inside SyntaxNode, if it is inside *Macrofile*,\n+    /// search up until it is of the target AstNode type\n+    pub fn find_node_at_offset_with_macros<N: AstNode>(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> Option<N> {\n+        self.impl_.find_node_at_offset_with_macros(node, offset)\n+    }\n+\n+    /// Find a AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,\n+    /// descend it and find again\n+    pub fn find_node_at_offset_with_descend<N: AstNode>(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> Option<N> {\n+        self.impl_.find_node_at_offset_with_descend(node, offset)\n+    }\n+\n+    pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n+        self.impl_.type_of_expr(expr)\n+    }\n+\n+    pub fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n+        self.impl_.type_of_pat(pat)\n+    }\n+\n+    pub fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n+        self.impl_.resolve_method_call(call)\n+    }\n+\n+    pub fn resolve_field(&self, field: &ast::FieldExpr) -> Option<Field> {\n+        self.impl_.resolve_field(field)\n+    }\n+\n+    pub fn resolve_record_field(&self, field: &ast::RecordField) -> Option<(Field, Option<Local>)> {\n+        self.impl_.resolve_record_field(field)\n+    }\n+\n+    pub fn resolve_record_field_pat(&self, field: &ast::RecordFieldPat) -> Option<Field> {\n+        self.impl_.resolve_record_field_pat(field)\n+    }\n+\n+    pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n+        self.impl_.resolve_macro_call(macro_call)\n+    }\n+\n+    pub fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n+        self.impl_.resolve_path(path)\n+    }\n+\n+    pub fn resolve_variant(&self, record_lit: ast::RecordLit) -> Option<VariantId> {\n+        self.impl_.resolve_variant(record_lit)\n+    }\n+\n+    pub fn lower_path(&self, path: &ast::Path) -> Option<Path> {\n+        self.impl_.lower_path(path)\n+    }\n+\n+    pub fn resolve_bind_pat_to_const(&self, pat: &ast::BindPat) -> Option<ModuleDef> {\n+        self.impl_.resolve_bind_pat_to_const(pat)\n+    }\n+\n+    // FIXME: use this instead?\n+    // pub fn resolve_name_ref(&self, name_ref: &ast::NameRef) -> Option<???>;\n+\n+    pub fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n+        self.impl_.record_literal_missing_fields(literal)\n+    }\n+\n+    pub fn record_pattern_missing_fields(&self, pattern: &ast::RecordPat) -> Vec<(Field, Type)> {\n+        self.impl_.record_pattern_missing_fields(pattern)\n+    }\n+\n+    pub fn to_def<T: ToDef>(&self, src: &T) -> Option<T::Def> {\n+        self.impl_.to_def(src)\n+    }\n+\n+    pub fn to_module_def(&self, file: FileId) -> Option<Module> {\n+        self.impl_.to_module_def(file)\n+    }\n+\n+    pub fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db> {\n+        self.impl_.scope(node)\n+    }\n+\n+    pub fn scope_at_offset(&self, node: &SyntaxNode, offset: TextSize) -> SemanticsScope<'db> {\n+        self.impl_.scope_at_offset(node, offset)\n+    }\n+\n+    pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n+        self.impl_.scope_for_def(def)\n+    }\n+\n+    pub fn assert_contains_node(&self, node: &SyntaxNode) {\n+        self.impl_.assert_contains_node(node)\n+    }\n+}\n+\n+impl<'db> SemanticsImpl<'db> {\n+    pub fn new(db: &'db dyn HirDatabase) -> Self {\n+        Self { db, s2d_cache: Default::default(), cache: Default::default() }\n     }\n \n     pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n@@ -108,7 +272,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n         let file_id = d.source().file_id;\n         let root = self.db.parse_or_expand(file_id).unwrap();\n         self.cache(root, file_id);\n-        d.ast(self.db)\n+        d.ast(self.db.upcast())\n     }\n \n     pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n@@ -130,9 +294,15 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             self.find_file(actual_macro_call.syntax().clone()).with_value(actual_macro_call);\n         let sa = self.analyze2(macro_call.map(|it| it.syntax()), None);\n         let krate = sa.resolver.krate()?;\n-        let macro_call_id = macro_call\n-            .as_call_id(self.db, krate, |path| sa.resolver.resolve_path_as_macro(self.db, &path))?;\n-        hir_expand::db::expand_hypothetical(self.db, macro_call_id, hypothetical_args, token_to_map)\n+        let macro_call_id = macro_call.as_call_id(self.db.upcast(), krate, |path| {\n+            sa.resolver.resolve_path_as_macro(self.db.upcast(), &path)\n+        })?;\n+        hir_expand::db::expand_hypothetical(\n+            self.db.upcast(),\n+            macro_call_id,\n+            hypothetical_args,\n+            token_to_map,\n+        )\n     }\n \n     pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n@@ -147,7 +317,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n                 return None;\n             }\n             let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n-            let token = file_id.expansion_info(self.db)?.map_token_down(token.as_ref())?;\n+            let token = file_id.expansion_info(self.db.upcast())?.map_token_down(token.as_ref())?;\n \n             self.cache(find_root(&token.value.parent()), token.file_id);\n \n@@ -184,7 +354,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n \n     pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n         let node = self.find_file(node);\n-        node.ancestors_with_macros(self.db).map(|it| it.value)\n+        node.ancestors_with_macros(self.db.upcast()).map(|it| it.value)\n     }\n \n     pub fn ancestors_at_offset_with_macros(\n@@ -197,8 +367,6 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             .kmerge_by(|node1, node2| node1.text_range().len() < node2.text_range().len())\n     }\n \n-    /// Find a AstNode by offset inside SyntaxNode, if it is inside *Macrofile*,\n-    /// search up until it is of the target AstNode type\n     pub fn find_node_at_offset_with_macros<N: AstNode>(\n         &self,\n         node: &SyntaxNode,\n@@ -207,8 +375,6 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n         self.ancestors_at_offset_with_macros(node, offset).find_map(N::cast)\n     }\n \n-    /// Find a AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,\n-    /// descend it and find again\n     pub fn find_node_at_offset_with_descend<N: AstNode>(\n         &self,\n         node: &SyntaxNode,\n@@ -267,9 +433,6 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n         self.analyze(pat.syntax()).resolve_bind_pat_to_const(self.db, pat)\n     }\n \n-    // FIXME: use this instead?\n-    // pub fn resolve_name_ref(&self, name_ref: &ast::NameRef) -> Option<???>;\n-\n     pub fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n         self.analyze(literal.syntax())\n             .record_literal_missing_fields(self.db, literal)\n@@ -310,7 +473,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n     }\n \n     pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n-        let resolver = def.id.resolver(self.db);\n+        let resolver = def.id.resolver(self.db.upcast());\n         SemanticsScope { db: self.db, resolver }\n     }\n \n@@ -331,12 +494,12 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             ChildContainer::DefWithBodyId(def) => {\n                 return SourceAnalyzer::new_for_body(self.db, def, src, offset)\n             }\n-            ChildContainer::TraitId(it) => it.resolver(self.db),\n-            ChildContainer::ImplId(it) => it.resolver(self.db),\n-            ChildContainer::ModuleId(it) => it.resolver(self.db),\n-            ChildContainer::EnumId(it) => it.resolver(self.db),\n-            ChildContainer::VariantId(it) => it.resolver(self.db),\n-            ChildContainer::GenericDefId(it) => it.resolver(self.db),\n+            ChildContainer::TraitId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::ImplId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::ModuleId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::EnumId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::VariantId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::GenericDefId(it) => it.resolver(self.db.upcast()),\n         };\n         SourceAnalyzer::new_for_resolver(resolver, src)\n     }\n@@ -382,14 +545,14 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n pub trait ToDef: AstNode + Clone {\n     type Def;\n \n-    fn to_def<DB: HirDatabase>(sema: &Semantics<DB>, src: InFile<Self>) -> Option<Self::Def>;\n+    fn to_def(sema: &SemanticsImpl, src: InFile<Self>) -> Option<Self::Def>;\n }\n \n macro_rules! to_def_impls {\n     ($(($def:path, $ast:path, $meth:ident)),* ,) => {$(\n         impl ToDef for $ast {\n             type Def = $def;\n-            fn to_def<DB: HirDatabase>(sema: &Semantics<DB>, src: InFile<Self>) -> Option<Self::Def> {\n+            fn to_def(sema: &SemanticsImpl, src: InFile<Self>) -> Option<Self::Def> {\n                 sema.with_ctx(|ctx| ctx.$meth(src)).map(<$def>::from)\n             }\n         }"}, {"sha": "c78071ad6ecddbbc69bc6f4cdfa5d7cf831c2ffd", "filename": "crates/ra_ide_db/src/lib.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e8505f14d4bb8d393ca77ec234dd1c99826a2d79/crates%2Fra_ide_db%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e8505f14d4bb8d393ca77ec234dd1c99826a2d79/crates%2Fra_ide_db%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_db%2Fsrc%2Flib.rs?ref=e8505f14d4bb8d393ca77ec234dd1c99826a2d79", "patch": "@@ -13,7 +13,7 @@ mod wasm_shims;\n \n use std::sync::Arc;\n \n-use hir::db::{AstDatabase, DefDatabase};\n+use hir::db::{AstDatabase, DefDatabase, HirDatabase};\n use ra_db::{\n     salsa::{self, Database, Durability},\n     Canceled, CheckCanceled, CrateId, FileId, FileLoader, FileLoaderDelegate, SourceDatabase,\n@@ -52,6 +52,12 @@ impl Upcast<dyn DefDatabase> for RootDatabase {\n     }\n }\n \n+impl Upcast<dyn HirDatabase> for RootDatabase {\n+    fn upcast(&self) -> &(dyn HirDatabase + 'static) {\n+        &*self\n+    }\n+}\n+\n impl FileLoader for RootDatabase {\n     fn file_text(&self, file_id: FileId) -> Arc<String> {\n         FileLoaderDelegate(self).file_text(file_id)"}]}