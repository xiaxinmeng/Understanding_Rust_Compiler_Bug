{"sha": "336194c09b404a1b2e4a360058337372446ee88c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMzNjE5NGMwOWI0MDRhMWIyZTRhMzYwMDU4MzM3MzcyNDQ2ZWU4OGM=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-07-03T19:26:04Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-07-03T19:26:04Z"}, "message": "Merge #9476\n\n9476: internal: overhaul codegen r=matklad a=matklad\n\nbors r+\n\ud83e\udd16\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "cedc48fc70029f8ce3b7e415210501a9b6f2a340", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cedc48fc70029f8ce3b7e415210501a9b6f2a340"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/336194c09b404a1b2e4a360058337372446ee88c", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJg4LnMCRBK7hj4Ov3rIwAAMcYIAEeXud0+/b+3SL21VGGZrxyb\nP+FtwkE+5UrqcbDyBHWgNVR9QmRGOWHgRP6/t45o8CHj0O1+KvKKUsvGMHWsoltG\nzJmefuZdw5wi9PbyMNsFK6XywmaN26fpdDYrQX7UC9F2ox1+O0lXdBRqEsLkOMdd\nOm5w06ygwBUaSpPEpX59onpHMUjEHvmMP81MzpZm3pHm4TmT6K1H1fbZzJ+g2OKb\nKxvYcINtfv9MrVOkkrWLDE9O6IELEDeYHaSws06gR/byJlF3FBPteAt2jAuiXUP/\nbjLOvGULcxbNIgVTPFjViF40BtBrVyPeYYZCtmHh4oMEjWdfdnR2d9NJBWyNMVU=\n=XZny\n-----END PGP SIGNATURE-----\n", "payload": "tree cedc48fc70029f8ce3b7e415210501a9b6f2a340\nparent 888bb6c452f89a1b587fb4cf88a6cedd9c0652bb\nparent 660930623eb002cfc56cd2a4e392ad40e8c53696\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1625340364 +0000\ncommitter GitHub <noreply@github.com> 1625340364 +0000\n\nMerge #9476\n\n9476: internal: overhaul codegen r=matklad a=matklad\n\nbors r+\n\ud83e\udd16\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/336194c09b404a1b2e4a360058337372446ee88c", "html_url": "https://github.com/rust-lang/rust/commit/336194c09b404a1b2e4a360058337372446ee88c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/336194c09b404a1b2e4a360058337372446ee88c/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "888bb6c452f89a1b587fb4cf88a6cedd9c0652bb", "url": "https://api.github.com/repos/rust-lang/rust/commits/888bb6c452f89a1b587fb4cf88a6cedd9c0652bb", "html_url": "https://github.com/rust-lang/rust/commit/888bb6c452f89a1b587fb4cf88a6cedd9c0652bb"}, {"sha": "660930623eb002cfc56cd2a4e392ad40e8c53696", "url": "https://api.github.com/repos/rust-lang/rust/commits/660930623eb002cfc56cd2a4e392ad40e8c53696", "html_url": "https://github.com/rust-lang/rust/commit/660930623eb002cfc56cd2a4e392ad40e8c53696"}], "stats": {"total": 1496, "additions": 769, "deletions": 727}, "files": [{"sha": "339a2262d79643b97f2e1b1cb7b2037376681879", "filename": "Cargo.lock", "status": "modified", "additions": 16, "deletions": 4, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -600,6 +600,7 @@ dependencies = [\n  \"itertools\",\n  \"profile\",\n  \"rustc-hash\",\n+ \"sourcegen\",\n  \"stdx\",\n  \"syntax\",\n  \"test_utils\",\n@@ -621,10 +622,12 @@ dependencies = [\n  \"once_cell\",\n  \"profile\",\n  \"rustc-hash\",\n+ \"sourcegen\",\n  \"stdx\",\n  \"syntax\",\n  \"test_utils\",\n  \"text_edit\",\n+ \"xshell\",\n ]\n \n [[package]]\n@@ -662,6 +665,7 @@ dependencies = [\n  \"itertools\",\n  \"profile\",\n  \"rustc-hash\",\n+ \"sourcegen\",\n  \"stdx\",\n  \"syntax\",\n  \"test_utils\",\n@@ -1323,6 +1327,7 @@ dependencies = [\n  \"serde\",\n  \"serde_json\",\n  \"serde_path_to_error\",\n+ \"sourcegen\",\n  \"stdx\",\n  \"syntax\",\n  \"test_utils\",\n@@ -1518,6 +1523,13 @@ version = \"1.0.5\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"45456094d1983e2ee2a18fdfebce3189fa451699d0502cb8e3b49dba5ba41451\"\n \n+[[package]]\n+name = \"sourcegen\"\n+version = \"0.0.0\"\n+dependencies = [\n+ \"xshell\",\n+]\n+\n [[package]]\n name = \"stdx\"\n version = \"0.0.0\"\n@@ -1563,17 +1575,20 @@ dependencies = [\n  \"itertools\",\n  \"once_cell\",\n  \"parser\",\n+ \"proc-macro2\",\n  \"profile\",\n+ \"quote\",\n  \"rayon\",\n  \"rowan\",\n  \"rustc-ap-rustc_lexer\",\n  \"rustc-hash\",\n  \"serde\",\n  \"smol_str\",\n+ \"sourcegen\",\n  \"stdx\",\n  \"test_utils\",\n  \"text_edit\",\n- \"walkdir\",\n+ \"ungrammar\",\n ]\n \n [[package]]\n@@ -1942,9 +1957,6 @@ version = \"0.1.0\"\n dependencies = [\n  \"anyhow\",\n  \"flate2\",\n- \"proc-macro2\",\n- \"quote\",\n- \"ungrammar\",\n  \"walkdir\",\n  \"write-json\",\n  \"xflags\","}, {"sha": "984e20441648009d9158fe809d02b758926626e5", "filename": "crates/ide_assists/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_assists%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -24,4 +24,5 @@ hir = { path = \"../hir\", version = \"0.0.0\" }\n \n [dev-dependencies]\n test_utils = { path = \"../test_utils\" }\n+sourcegen = { path = \"../sourcegen\" }\n expect-test = \"1.1\""}, {"sha": "9a2aa698728a0dabd1f187e5ef9dfe02da2c20d6", "filename": "crates/ide_assists/src/tests.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_assists%2Fsrc%2Ftests.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,3 +1,4 @@\n+mod sourcegen;\n mod generated;\n \n use expect_test::expect;"}, {"sha": "1bc23df7dc62c59e777f8ead8914f95fe954d222", "filename": "crates/ide_assists/src/tests/generated.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2Fsrc%2Ftests%2Fgenerated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2Fsrc%2Ftests%2Fgenerated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_assists%2Fsrc%2Ftests%2Fgenerated.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,4 +1,4 @@\n-//! Generated file, do not edit by hand, see `xtask/src/codegen`\n+//! Generated by `sourcegen_assists_docs`, do not edit by hand.\n \n use super::check_doc_test;\n "}, {"sha": "bf29c5e536f2c3d44bd1bc33e9db0eda2d5ead6a", "filename": "crates/ide_assists/src/tests/sourcegen.rs", "status": "renamed", "additions": 69, "deletions": 65, "changes": 134, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2Fsrc%2Ftests%2Fsourcegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_assists%2Fsrc%2Ftests%2Fsourcegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_assists%2Fsrc%2Ftests%2Fsourcegen.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,49 +1,84 @@\n //! Generates `assists.md` documentation.\n \n-use std::{fmt, path::Path};\n+use std::{fmt, fs, path::Path};\n \n-use xshell::write_file;\n+use test_utils::project_root;\n \n-use crate::{\n-    codegen::{self, extract_comment_blocks_with_empty_lines, reformat, Location, PREAMBLE},\n-    project_root, rust_files_in, Result,\n-};\n+#[test]\n+fn sourcegen_assists_docs() {\n+    let assists = Assist::collect();\n+\n+    {\n+        // Generate doctests.\n+\n+        let mut buf = \"\n+use super::check_doc_test;\n+\"\n+        .to_string();\n+        for assist in assists.iter() {\n+            let test = format!(\n+                r######\"\n+#[test]\n+fn doctest_{}() {{\n+    check_doc_test(\n+        \"{}\",\n+r#####\"\n+{}\"#####, r#####\"\n+{}\"#####)\n+}}\n+\"######,\n+                assist.id,\n+                assist.id,\n+                reveal_hash_comments(&assist.before),\n+                reveal_hash_comments(&assist.after)\n+            );\n \n-pub(crate) fn generate_assists_tests() -> Result<()> {\n-    let assists = Assist::collect()?;\n-    generate_tests(&assists)\n-}\n+            buf.push_str(&test)\n+        }\n+        let buf = sourcegen::add_preamble(\"sourcegen_assists_docs\", sourcegen::reformat(buf));\n+        sourcegen::ensure_file_contents(\n+            &project_root().join(\"crates/ide_assists/src/tests/generated.rs\"),\n+            &buf,\n+        );\n+    }\n+\n+    {\n+        // Generate assists manual. Note that we do _not_ commit manual to the\n+        // git repo. Instead, `cargo xtask release` runs this test before making\n+        // a release.\n \n-pub(crate) fn generate_assists_docs() -> Result<()> {\n-    let assists = Assist::collect()?;\n-    let contents = assists.into_iter().map(|it| it.to_string()).collect::<Vec<_>>().join(\"\\n\\n\");\n-    let contents = format!(\"//{}\\n{}\\n\", PREAMBLE, contents.trim());\n-    let dst = project_root().join(\"docs/user/generated_assists.adoc\");\n-    write_file(dst, &contents)?;\n-    Ok(())\n+        let contents = sourcegen::add_preamble(\n+            \"sourcegen_assists_docs\",\n+            assists.into_iter().map(|it| it.to_string()).collect::<Vec<_>>().join(\"\\n\\n\"),\n+        );\n+        let dst = project_root().join(\"docs/user/generated_assists.adoc\");\n+        fs::write(dst, contents).unwrap();\n+    }\n }\n \n #[derive(Debug)]\n struct Assist {\n     id: String,\n-    location: Location,\n+    location: sourcegen::Location,\n     doc: String,\n     before: String,\n     after: String,\n }\n \n impl Assist {\n-    fn collect() -> Result<Vec<Assist>> {\n+    fn collect() -> Vec<Assist> {\n+        let handlers_dir = project_root().join(\"crates/ide_assists/src/handlers\");\n+\n         let mut res = Vec::new();\n-        for path in rust_files_in(&project_root().join(\"crates/ide_assists/src/handlers\")) {\n-            collect_file(&mut res, path.as_path())?;\n+        for path in sourcegen::list_rust_files(&handlers_dir) {\n+            collect_file(&mut res, path.as_path());\n         }\n         res.sort_by(|lhs, rhs| lhs.id.cmp(&rhs.id));\n-        return Ok(res);\n+        return res;\n \n-        fn collect_file(acc: &mut Vec<Assist>, path: &Path) -> Result<()> {\n-            let text = xshell::read_file(path)?;\n-            let comment_blocks = extract_comment_blocks_with_empty_lines(\"Assist\", &text);\n+        fn collect_file(acc: &mut Vec<Assist>, path: &Path) {\n+            let text = fs::read_to_string(path).unwrap();\n+            let comment_blocks = sourcegen::CommentBlock::extract(\"Assist\", &text);\n \n             for block in comment_blocks {\n                 // FIXME: doesn't support blank lines yet, need to tweak\n@@ -68,21 +103,20 @@ impl Assist {\n                 assert_eq!(lines.next().unwrap().as_str(), \"->\");\n                 assert_eq!(lines.next().unwrap().as_str(), \"```\");\n                 let after = take_until(lines.by_ref(), \"```\");\n-                let location = Location::new(path.to_path_buf(), block.line);\n+                let location = sourcegen::Location { file: path.to_path_buf(), line: block.line };\n                 acc.push(Assist { id, location, doc, before, after })\n             }\n+        }\n \n-            fn take_until<'a>(lines: impl Iterator<Item = &'a String>, marker: &str) -> String {\n-                let mut buf = Vec::new();\n-                for line in lines {\n-                    if line == marker {\n-                        break;\n-                    }\n-                    buf.push(line.clone());\n+        fn take_until<'a>(lines: impl Iterator<Item = &'a String>, marker: &str) -> String {\n+            let mut buf = Vec::new();\n+            for line in lines {\n+                if line == marker {\n+                    break;\n                 }\n-                buf.join(\"\\n\")\n+                buf.push(line.clone());\n             }\n-            Ok(())\n+            buf.join(\"\\n\")\n         }\n     }\n }\n@@ -114,36 +148,6 @@ impl fmt::Display for Assist {\n     }\n }\n \n-fn generate_tests(assists: &[Assist]) -> Result<()> {\n-    let mut buf = String::from(\"use super::check_doc_test;\\n\");\n-\n-    for assist in assists.iter() {\n-        let test = format!(\n-            r######\"\n-#[test]\n-fn doctest_{}() {{\n-    check_doc_test(\n-        \"{}\",\n-r#####\"\n-{}\"#####, r#####\"\n-{}\"#####)\n-}}\n-\"######,\n-            assist.id,\n-            assist.id,\n-            reveal_hash_comments(&assist.before),\n-            reveal_hash_comments(&assist.after)\n-        );\n-\n-        buf.push_str(&test)\n-    }\n-    let buf = reformat(&buf)?;\n-    codegen::ensure_file_contents(\n-        &project_root().join(\"crates/ide_assists/src/tests/generated.rs\"),\n-        &buf,\n-    )\n-}\n-\n fn hide_hash_comments(text: &str) -> String {\n     text.split('\\n') // want final newline\n         .filter(|&it| !(it.starts_with(\"# \") || it == \"#\"))", "previous_filename": "xtask/src/codegen/gen_assists_docs.rs"}, {"sha": "ce5ba72efe1015dafe4f5017ef6b2df91c07a1a6", "filename": "crates/ide_completion/Cargo.toml", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_completion%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_completion%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -29,5 +29,8 @@ profile = { path = \"../profile\", version = \"0.0.0\" }\n hir = { path = \"../hir\", version = \"0.0.0\" }\n \n [dev-dependencies]\n-test_utils = { path = \"../test_utils\" }\n expect-test = \"1.1\"\n+xshell = \"0.1\"\n+\n+test_utils = { path = \"../test_utils\" }\n+sourcegen = { path = \"../sourcegen\" }"}, {"sha": "6bc25add4f74a74f8109216e97c0b0435f372870", "filename": "crates/ide_completion/src/tests.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_completion%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_completion%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Ftests.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -10,6 +10,7 @@ mod items;\n mod pattern;\n mod type_pos;\n mod predicate;\n+mod sourcegen;\n \n use std::mem;\n "}, {"sha": "face0c27fcc1997bdd240183c326d99e89b66a55", "filename": "crates/ide_completion/src/tests/sourcegen.rs", "status": "renamed", "additions": 60, "deletions": 62, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_completion%2Fsrc%2Ftests%2Fsourcegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_completion%2Fsrc%2Ftests%2Fsourcegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Ftests%2Fsourcegen.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,53 +1,55 @@\n //! Generates descriptors structure for unstable feature from Unstable Book\n-use std::borrow::Cow;\n-use std::fmt::Write;\n-use std::path::{Path, PathBuf};\n-\n-use walkdir::WalkDir;\n-use xshell::{cmd, read_file};\n-\n-use crate::codegen::{ensure_file_contents, project_root, reformat, Result};\n-\n-pub(crate) fn generate_lint_completions() -> Result<()> {\n-    if !project_root().join(\"./target/rust\").exists() {\n-        cmd!(\"git clone --depth=1 https://github.com/rust-lang/rust ./target/rust\").run()?;\n+use std::{\n+    borrow::Cow,\n+    fs,\n+    path::{Path, PathBuf},\n+};\n+\n+use stdx::format_to;\n+use test_utils::project_root;\n+use xshell::cmd;\n+\n+/// This clones rustc repo, and so is not worth to keep up-to-date. We update\n+/// manually by un-ignoring the test from time to time.\n+#[test]\n+#[ignore]\n+fn sourcegen_lint_completions() {\n+    let rust_repo = project_root().join(\"./target/rust\");\n+    if !rust_repo.exists() {\n+        cmd!(\"git clone --depth=1 https://github.com/rust-lang/rust {rust_repo}\").run().unwrap();\n     }\n \n-    let mut contents = String::from(\n-        r#\"pub struct Lint {\n+    let mut contents = r\"\n+pub struct Lint {\n     pub label: &'static str,\n     pub description: &'static str,\n }\n-\n-\"#,\n-    );\n-    generate_lint_descriptor(&mut contents)?;\n+\"\n+    .to_string();\n+    generate_lint_descriptor(&mut contents);\n     contents.push('\\n');\n \n-    generate_feature_descriptor(&mut contents, \"./target/rust/src/doc/unstable-book/src\".into())?;\n+    generate_feature_descriptor(&mut contents, \"./target/rust/src/doc/unstable-book/src\".into());\n     contents.push('\\n');\n \n-    cmd!(\"curl https://rust-lang.github.io/rust-clippy/master/lints.json --output ./target/clippy_lints.json\").run()?;\n-    generate_descriptor_clippy(&mut contents, Path::new(\"./target/clippy_lints.json\"))?;\n-    let contents = reformat(&contents)?;\n+    cmd!(\"curl https://rust-lang.github.io/rust-clippy/master/lints.json --output ./target/clippy_lints.json\").run().unwrap();\n+    generate_descriptor_clippy(&mut contents, Path::new(\"./target/clippy_lints.json\"));\n \n-    let destination = project_root().join(\"crates/ide_db/src/helpers/generated_lints.rs\");\n-    ensure_file_contents(destination.as_path(), &contents)?;\n+    let contents =\n+        sourcegen::add_preamble(\"sourcegen_lint_completions\", sourcegen::reformat(contents));\n \n-    Ok(())\n+    let destination = project_root().join(\"crates/ide_db/src/helpers/generated_lints.rs\");\n+    sourcegen::ensure_file_contents(destination.as_path(), &contents);\n }\n \n-fn generate_lint_descriptor(buf: &mut String) -> Result<()> {\n-    let stdout = cmd!(\"rustc -W help\").read()?;\n-    let start_lints =\n-        stdout.find(\"----  -------  -------\").ok_or_else(|| anyhow::format_err!(\"\"))?;\n-    let start_lint_groups =\n-        stdout.find(\"----  ---------\").ok_or_else(|| anyhow::format_err!(\"\"))?;\n-    let end_lints =\n-        stdout.find(\"Lint groups provided by rustc:\").ok_or_else(|| anyhow::format_err!(\"\"))?;\n+fn generate_lint_descriptor(buf: &mut String) {\n+    let stdout = cmd!(\"rustc -W help\").read().unwrap();\n+    let start_lints = stdout.find(\"----  -------  -------\").unwrap();\n+    let start_lint_groups = stdout.find(\"----  ---------\").unwrap();\n+    let end_lints = stdout.find(\"Lint groups provided by rustc:\").unwrap();\n     let end_lint_groups = stdout\n         .find(\"Lint tools like Clippy can provide additional lints and lint groups.\")\n-        .ok_or_else(|| anyhow::format_err!(\"\"))?;\n+        .unwrap();\n     buf.push_str(r#\"pub const DEFAULT_LINTS: &[Lint] = &[\"#);\n     buf.push('\\n');\n     let mut lints = stdout[start_lints..end_lints]\n@@ -75,32 +77,30 @@ fn generate_lint_descriptor(buf: &mut String) -> Result<()> {\n         push_lint_completion(buf, &name.replace(\"-\", \"_\"), &description)\n     });\n     buf.push_str(\"];\\n\");\n-    Ok(())\n }\n \n-fn generate_feature_descriptor(buf: &mut String, src_dir: PathBuf) -> Result<()> {\n-    buf.push_str(r#\"pub const FEATURES: &[Lint] = &[\"#);\n-    buf.push('\\n');\n-    let mut vec = [\"language-features\", \"library-features\"]\n+fn generate_feature_descriptor(buf: &mut String, src_dir: PathBuf) {\n+    let mut features = [\"language-features\", \"library-features\"]\n         .iter()\n-        .flat_map(|it| WalkDir::new(src_dir.join(it)))\n-        .filter_map(|e| e.ok())\n-        .filter(|entry| {\n+        .flat_map(|it| sourcegen::list_files(&src_dir.join(it)))\n+        .filter(|path| {\n             // Get all `.md ` files\n-            entry.file_type().is_file() && entry.path().extension().unwrap_or_default() == \"md\"\n+            path.extension().unwrap_or_default().to_str().unwrap_or_default() == \"md\"\n         })\n-        .map(|entry| {\n-            let path = entry.path();\n+        .map(|path| {\n             let feature_ident = path.file_stem().unwrap().to_str().unwrap().replace(\"-\", \"_\");\n-            let doc = read_file(path).unwrap();\n+            let doc = fs::read_to_string(path).unwrap();\n             (feature_ident, doc)\n         })\n         .collect::<Vec<_>>();\n-    vec.sort_by(|(feature_ident, _), (feature_ident2, _)| feature_ident.cmp(feature_ident2));\n-    vec.into_iter()\n-        .for_each(|(feature_ident, doc)| push_lint_completion(buf, &feature_ident, &doc));\n+    features.sort_by(|(feature_ident, _), (feature_ident2, _)| feature_ident.cmp(feature_ident2));\n+\n+    buf.push_str(r#\"pub const FEATURES: &[Lint] = &[\"#);\n+    for (feature_ident, doc) in features.into_iter() {\n+        push_lint_completion(buf, &feature_ident, &doc)\n+    }\n+    buf.push('\\n');\n     buf.push_str(\"];\\n\");\n-    Ok(())\n }\n \n #[derive(Default)]\n@@ -113,9 +113,9 @@ fn unescape(s: &str) -> String {\n     s.replace(r#\"\\\"\"#, \"\").replace(r#\"\\n\"#, \"\\n\").replace(r#\"\\r\"#, \"\")\n }\n \n-fn generate_descriptor_clippy(buf: &mut String, path: &Path) -> Result<()> {\n-    let file_content = read_file(path)?;\n-    let mut clippy_lints: Vec<ClippyLint> = vec![];\n+fn generate_descriptor_clippy(buf: &mut String, path: &Path) {\n+    let file_content = std::fs::read_to_string(path).unwrap();\n+    let mut clippy_lints: Vec<ClippyLint> = Vec::new();\n \n     for line in file_content.lines().map(|line| line.trim()) {\n         if line.starts_with(r#\"\"id\":\"#) {\n@@ -144,27 +144,25 @@ fn generate_descriptor_clippy(buf: &mut String, path: &Path) -> Result<()> {\n         }\n     }\n     clippy_lints.sort_by(|lint, lint2| lint.id.cmp(&lint2.id));\n+\n     buf.push_str(r#\"pub const CLIPPY_LINTS: &[Lint] = &[\"#);\n     buf.push('\\n');\n-    clippy_lints.into_iter().for_each(|clippy_lint| {\n+    for clippy_lint in clippy_lints.into_iter() {\n         let lint_ident = format!(\"clippy::{}\", clippy_lint.id);\n         let doc = clippy_lint.help;\n         push_lint_completion(buf, &lint_ident, &doc);\n-    });\n-\n+    }\n     buf.push_str(\"];\\n\");\n-\n-    Ok(())\n }\n \n fn push_lint_completion(buf: &mut String, label: &str, description: &str) {\n-    writeln!(\n+    format_to!(\n         buf,\n         r###\"    Lint {{\n         label: \"{}\",\n         description: r##\"{}\"##\n     }},\"###,\n-        label, description\n-    )\n-    .unwrap();\n+        label,\n+        description\n+    );\n }", "previous_filename": "xtask/src/codegen/gen_lint_completions.rs"}, {"sha": "4ec63a234b07e64846d87e67c9be7e25fe9ad87b", "filename": "crates/ide_db/src/helpers/generated_lints.rs", "status": "modified", "additions": 79, "deletions": 65, "changes": 144, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_db%2Fsrc%2Fhelpers%2Fgenerated_lints.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_db%2Fsrc%2Fhelpers%2Fgenerated_lints.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_db%2Fsrc%2Fhelpers%2Fgenerated_lints.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,10 +1,9 @@\n-//! Generated file, do not edit by hand, see `xtask/src/codegen`\n+//! Generated by `sourcegen_lint_completions`, do not edit by hand.\n \n pub struct Lint {\n     pub label: &'static str,\n     pub description: &'static str,\n }\n-\n pub const DEFAULT_LINTS: &[Lint] = &[\n     Lint {\n         label: \"absolute_paths_not_starting_with_crate\",\n@@ -71,8 +70,8 @@ pub const DEFAULT_LINTS: &[Lint] = &[\n         description: r##\"detects when an null pointer is dereferenced\"##,\n     },\n     Lint {\n-        label: \"disjoint_capture_migration\",\n-        description: r##\"Drop reorder and auto traits error because of `capture_disjoint_fields`\"##,\n+        label: \"disjoint_capture_drop_reorder\",\n+        description: r##\"Drop reorder because of `capture_disjoint_fields`\"##,\n     },\n     Lint { label: \"drop_bounds\", description: r##\"bounds of the form `T: Drop` are useless\"## },\n     Lint {\n@@ -98,7 +97,7 @@ pub const DEFAULT_LINTS: &[Lint] = &[\n     },\n     Lint {\n         label: \"future_incompatible\",\n-        description: r##\"lint group for: keyword-idents, anonymous-parameters, ellipsis-inclusive-range-patterns, forbidden-lint-groups, illegal-floating-point-literal-pattern, private-in-public, pub-use-of-private-extern-crate, invalid-type-param-default, const-err, unaligned-references, patterns-in-fns-without-body, missing-fragment-specifier, late-bound-lifetime-arguments, order-dependent-trait-objects, coherence-leak-check, tyvar-behind-raw-pointer, bare-trait-objects, absolute-paths-not-starting-with-crate, unstable-name-collisions, where-clauses-object-safety, proc-macro-derive-resolution-fallback, macro-expanded-macro-exports-accessed-by-absolute-paths, ill-formed-attribute-input, conflicting-repr-hints, ambiguous-associated-items, mutable-borrow-reservation-conflict, indirect-structural-match, pointer-structural-match, nontrivial-structural-match, soft-unstable, cenum-impl-drop-cast, const-evaluatable-unchecked, uninhabited-static, unsupported-naked-functions, semicolon-in-expressions-from-macros, legacy-derive-helpers, proc-macro-back-compat, array-into-iter\"##,\n+        description: r##\"lint group for: keyword-idents, anonymous-parameters, forbidden-lint-groups, illegal-floating-point-literal-pattern, private-in-public, pub-use-of-private-extern-crate, invalid-type-param-default, const-err, unaligned-references, patterns-in-fns-without-body, missing-fragment-specifier, late-bound-lifetime-arguments, order-dependent-trait-objects, coherence-leak-check, tyvar-behind-raw-pointer, absolute-paths-not-starting-with-crate, unstable-name-collisions, where-clauses-object-safety, proc-macro-derive-resolution-fallback, macro-expanded-macro-exports-accessed-by-absolute-paths, ill-formed-attribute-input, conflicting-repr-hints, ambiguous-associated-items, mutable-borrow-reservation-conflict, indirect-structural-match, pointer-structural-match, nontrivial-structural-match, soft-unstable, cenum-impl-drop-cast, const-evaluatable-unchecked, uninhabited-static, unsupported-naked-functions, semicolon-in-expressions-from-macros, legacy-derive-helpers, proc-macro-back-compat, array-into-iter\"##,\n     },\n     Lint {\n         label: \"ill_formed_attribute_input\",\n@@ -139,7 +138,7 @@ pub const DEFAULT_LINTS: &[Lint] = &[\n     },\n     Lint {\n         label: \"invalid_value\",\n-        description: r##\"an invalid value is being created (such as a null reference)\"##,\n+        description: r##\"an invalid value is being created (such as a NULL reference)\"##,\n     },\n     Lint {\n         label: \"irrefutable_let_patterns\",\n@@ -291,10 +290,6 @@ pub const DEFAULT_LINTS: &[Lint] = &[\n         label: \"rust_2018_idioms\",\n         description: r##\"lint group for: bare-trait-objects, unused-extern-crates, ellipsis-inclusive-range-patterns, elided-lifetimes-in-paths, explicit-outlives-requirements\"##,\n     },\n-    Lint {\n-        label: \"rust_2021_compatibility\",\n-        description: r##\"lint group for: ellipsis-inclusive-range-patterns, bare-trait-objects\"##,\n-    },\n     Lint {\n         label: \"semicolon_in_expressions_from_macros\",\n         description: r##\"trailing semicolon in macro body used as expression\"##,\n@@ -804,6 +799,7 @@ Inline assembly is currently supported on the following architectures:\n - Hexagon\n - MIPS32r2 and MIPS64r2\n - wasm32\n+- BPF\n \n ## Basic usage\n \n@@ -1229,7 +1225,7 @@ reg_spec := <register class> / \"<explicit register>\"\n operand_expr := expr / \"_\" / expr \"=>\" expr / expr \"=>\" \"_\"\n reg_operand := dir_spec \"(\" reg_spec \")\" operand_expr\n operand := reg_operand / \"const\" const_expr / \"sym\" path\n-option := \"pure\" / \"nomem\" / \"readonly\" / \"preserves_flags\" / \"noreturn\" / \"nostack\" / \"att_syntax\"\n+option := \"pure\" / \"nomem\" / \"readonly\" / \"preserves_flags\" / \"noreturn\" / \"nostack\" / \"att_syntax\" / \"raw\"\n options := \"options(\" option *[\",\" option] [\",\"] \")\"\n asm := \"asm!(\" format_string *(\",\" format_string) *(\",\" [ident \"=\"] operand) [\",\" options] [\",\"] \")\"\n ```\n@@ -1344,6 +1340,8 @@ Here is the list of currently supported register classes:\n | PowerPC | `reg_nonzero` | | `r[1-31]` | `b` |\n | PowerPC | `freg` | `f[0-31]` | `f` |\n | wasm32 | `local` | None\\* | `r` |\n+| BPF | `reg` |\u00a0`r[0-10]` | `r` |\n+| BPF | `wreg` |\u00a0`w[0-10]` | `w` |\n \n > **Note**: On x86 we treat `reg_byte` differently from `reg` because the compiler can allocate `al` and `ah` separately whereas `reg` reserves the whole register.\n >\n@@ -1389,6 +1387,8 @@ Each register class has constraints on which value types they can be used with.\n | PowerPC | `reg_nonzero` | None | `i8`, `i16`, `i32` |\n | PowerPC | `freg` | None | `f32`, `f64` |\n | wasm32 | `local` | None | `i8` `i16` `i32` `i64` `f32` `f64` |\n+| BPF |\u00a0`reg` |\u00a0None | `i8` `i16` `i32` `i64` |\n+| BPF |\u00a0`wreg` |\u00a0`alu32` | `i8` `i16` `i32` |\n \n > **Note**: For the purposes of the above table pointers, function pointers and `isize`/`usize` are treated as the equivalent integer type (`i16`/`i32`/`i64` depending on the target).\n \n@@ -1448,6 +1448,7 @@ Some registers have multiple names. These are all treated by the compiler as ide\n | Hexagon | `r29` | `sp` |\n | Hexagon | `r30` | `fr` |\n | Hexagon | `r31` | `lr` |\n+| BPF | `r[0-10]` | `w[0-10]` |\n \n Some registers cannot be used for input or output operands:\n \n@@ -1549,6 +1550,7 @@ Currently the following options are defined:\n - `noreturn`: The `asm` block never returns, and its return type is defined as `!` (never). Behavior is undefined if execution falls through past the end of the asm code. A `noreturn` asm block behaves just like a function which doesn't return; notably, local variables in scope are not dropped before it is invoked.\n - `nostack`: The `asm` block does not push data to the stack, or write to the stack red-zone (if supported by the target). If this option is *not* used then the stack pointer is guaranteed to be suitably aligned (according to the target ABI) for a function call.\n - `att_syntax`: This option is only valid on x86, and causes the assembler to use the `.att_syntax prefix` mode of the GNU assembler. Register operands are substituted in with a leading `%`.\n+- `raw`: This causes the template string to be parsed as a raw assembly string, with no special handling for `{` and `}`. This is primarily useful when including raw assembly code from an external file using `include_str!`.\n \n The compiler performs some additional checks on options:\n - The `nomem` and `readonly` options are mutually exclusive: it is a compile-time error to specify both.\n@@ -3801,6 +3803,39 @@ fn cheap_clone<T: CheapToClone>(t: T) -> T {\n \n This is expected to replace the unstable `overlapping_marker_traits`\n feature, which applied to all empty traits (without needing an opt-in).\n+\"##,\n+    },\n+    Lint {\n+        label: \"more_qualified_paths\",\n+        description: r##\"# `more_qualified_paths`\n+\n+The `more_qualified_paths` feature can be used in order to enable the\n+use of qualified paths in patterns.\n+\n+## Example\n+\n+```rust\n+#![feature(more_qualified_paths)]\n+\n+fn main() {\n+    // destructure through a qualified path\n+    let <Foo as A>::Assoc { br } = StructStruct { br: 2 };\n+}\n+\n+struct StructStruct {\n+    br: i8,\n+}\n+\n+struct Foo;\n+\n+trait A {\n+    type Assoc;\n+}\n+\n+impl A for Foo {\n+    type Assoc = StructStruct;\n+}\n+```\n \"##,\n     },\n     Lint {\n@@ -4681,60 +4716,6 @@ let result: Result<i32, ParseIntError> = try {\n };\n assert!(result.is_err());\n ```\n-\"##,\n-    },\n-    Lint {\n-        label: \"try_trait\",\n-        description: r##\"# `try_trait`\n-\n-The tracking issue for this feature is: [#42327]\n-\n-[#42327]: https://github.com/rust-lang/rust/issues/42327\n-\n-------------------------\n-\n-This introduces a new trait `Try` for extending the `?` operator to types\n-other than `Result` (a part of [RFC 1859]).  The trait provides the canonical\n-way to _view_ a type in terms of a success/failure dichotomy.  This will\n-allow `?` to supplant the `try_opt!` macro on `Option` and the `try_ready!`\n-macro on `Poll`, among other things.\n-\n-[RFC 1859]: https://github.com/rust-lang/rfcs/pull/1859\n-\n-Here's an example implementation of the trait:\n-\n-```rust,ignore (cannot-reimpl-Try)\n-/// A distinct type to represent the `None` value of an `Option`.\n-///\n-/// This enables using the `?` operator on `Option`; it's rarely useful alone.\n-#[derive(Debug)]\n-#[unstable(feature = \"try_trait\", issue = \"42327\")]\n-pub struct None { _priv: () }\n-\n-#[unstable(feature = \"try_trait\", issue = \"42327\")]\n-impl<T> ops::Try for Option<T>  {\n-    type Ok = T;\n-    type Error = None;\n-\n-    fn into_result(self) -> Result<T, None> {\n-        self.ok_or(None { _priv: () })\n-    }\n-\n-    fn from_ok(v: T) -> Self {\n-        Some(v)\n-    }\n-\n-    fn from_error(_: None) -> Self {\n-        None\n-    }\n-}\n-```\n-\n-Note the `Error` associated type here is a new marker.  The `?` operator\n-allows interconversion between different `Try` implementers only when\n-the error type can be converted `Into` the error type of the enclosing\n-function (or catch block).  Having a distinct error type (as opposed to\n-just `()`, or similar) restricts this to where it's semantically meaningful.\n \"##,\n     },\n     Lint {\n@@ -5035,6 +5016,10 @@ checked.\"##,\n         label: \"clippy::almost_swapped\",\n         description: r##\"Checks for `foo = bar; bar = foo` sequences.\"##,\n     },\n+    Lint {\n+        label: \"clippy::append_instead_of_extend\",\n+        description: r##\"Checks for occurrences where one vector gets extended instead of append\"##,\n+    },\n     Lint {\n         label: \"clippy::approx_constant\",\n         description: r##\"Checks for floating point literals that approximate\n@@ -5371,6 +5356,25 @@ explicitly or vice versa.\"##,\n         label: \"clippy::disallowed_method\",\n         description: r##\"Denies the configured methods and functions in clippy.toml\"##,\n     },\n+    Lint {\n+        label: \"clippy::disallowed_script_idents\",\n+        description: r##\"Checks for usage of unicode scripts other than those explicitly allowed\n+by the lint config.\n+\n+This lint doesn't take into account non-text scripts such as `Unknown` and `Linear_A`.\n+It also ignores the `Common` script type.\n+While configuring, be sure to use official script name [aliases] from\n+[the list of supported scripts][supported_scripts].\n+\n+See also: [`non_ascii_idents`].\n+\n+[aliases]: http://www.unicode.org/reports/tr24/tr24-31.html#Script_Value_Aliases\n+[supported_scripts]: https://www.unicode.org/iso15924/iso15924-codes.html\"##,\n+    },\n+    Lint {\n+        label: \"clippy::disallowed_type\",\n+        description: r##\"Denies the configured types in clippy.toml.\"##,\n+    },\n     Lint {\n         label: \"clippy::diverging_sub_expression\",\n         description: r##\"Checks for diverging calls that are not match arms or\n@@ -6147,6 +6151,11 @@ used to clamp values, but switched so that the result is constant.\"##,\n         label: \"clippy::missing_docs_in_private_items\",\n         description: r##\"Warns if there is missing doc for any documentable item\n (public or private).\"##,\n+    },\n+    Lint {\n+        label: \"clippy::missing_enforced_import_renames\",\n+        description: r##\"Checks for imports that do not rename the item as specified\n+in the `enforce-import-renames` config option.\"##,\n     },\n     Lint {\n         label: \"clippy::missing_errors_doc\",\n@@ -6372,6 +6381,10 @@ concisely.\"##,\n         description: r##\"Checks for duplicate open options as well as combinations\n that make no sense.\"##,\n     },\n+    Lint {\n+        label: \"clippy::nonstandard_macro_braces\",\n+        description: r##\"Checks that common macros are used with consistent bracing.\"##,\n+    },\n     Lint {\n         label: \"clippy::not_unsafe_ptr_arg_deref\",\n         description: r##\"Checks for public functions that dereference raw pointer\n@@ -6560,6 +6573,7 @@ upper bound, e.g., `x..(y+1)`.\"##,\n         label: \"clippy::rc_buffer\",\n         description: r##\"Checks for `Rc<T>` and `Arc<T>` when `T` is a mutable buffer type such as `String` or `Vec`.\"##,\n     },\n+    Lint { label: \"clippy::rc_mutex\", description: r##\"Checks for `Rc<Mutex<T>>`.\"## },\n     Lint {\n         label: \"clippy::redundant_allocation\",\n         description: r##\"Checks for use of redundant allocations anywhere in the code.\"##,"}, {"sha": "53514d54b720e86660d25f5eca73c3f910b7b066", "filename": "crates/ide_diagnostics/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_diagnostics%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -27,3 +27,4 @@ ide_db = { path = \"../ide_db\", version = \"0.0.0\" }\n expect-test = \"1.1\"\n \n test_utils = { path = \"../test_utils\" }\n+sourcegen = { path = \"../sourcegen\" }"}, {"sha": "dd87738aac46e24e2ccd2f394b7d5fe09710d21a", "filename": "crates/ide_diagnostics/src/lib.rs", "status": "modified", "additions": 3, "deletions": 149, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_diagnostics%2Fsrc%2Flib.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -49,6 +49,9 @@ mod handlers {\n     pub(crate) mod unlinked_file;\n }\n \n+#[cfg(test)]\n+mod tests;\n+\n use hir::{diagnostics::AnyDiagnostic, Semantics};\n use ide_db::{\n     assists::{Assist, AssistId, AssistKind, AssistResolveStrategy},\n@@ -223,152 +226,3 @@ fn unresolved_fix(id: &'static str, label: &str, target: TextRange) -> Assist {\n         source_change: None,\n     }\n }\n-\n-#[cfg(test)]\n-mod tests {\n-    use expect_test::Expect;\n-    use ide_db::{\n-        assists::AssistResolveStrategy,\n-        base_db::{fixture::WithFixture, SourceDatabaseExt},\n-        RootDatabase,\n-    };\n-    use stdx::trim_indent;\n-    use test_utils::{assert_eq_text, extract_annotations};\n-\n-    use crate::{DiagnosticsConfig, Severity};\n-\n-    /// Takes a multi-file input fixture with annotated cursor positions,\n-    /// and checks that:\n-    ///  * a diagnostic is produced\n-    ///  * the first diagnostic fix trigger range touches the input cursor position\n-    ///  * that the contents of the file containing the cursor match `after` after the diagnostic fix is applied\n-    #[track_caller]\n-    pub(crate) fn check_fix(ra_fixture_before: &str, ra_fixture_after: &str) {\n-        check_nth_fix(0, ra_fixture_before, ra_fixture_after);\n-    }\n-    /// Takes a multi-file input fixture with annotated cursor positions,\n-    /// and checks that:\n-    ///  * a diagnostic is produced\n-    ///  * every diagnostic fixes trigger range touches the input cursor position\n-    ///  * that the contents of the file containing the cursor match `after` after each diagnostic fix is applied\n-    pub(crate) fn check_fixes(ra_fixture_before: &str, ra_fixtures_after: Vec<&str>) {\n-        for (i, ra_fixture_after) in ra_fixtures_after.iter().enumerate() {\n-            check_nth_fix(i, ra_fixture_before, ra_fixture_after)\n-        }\n-    }\n-\n-    #[track_caller]\n-    fn check_nth_fix(nth: usize, ra_fixture_before: &str, ra_fixture_after: &str) {\n-        let after = trim_indent(ra_fixture_after);\n-\n-        let (db, file_position) = RootDatabase::with_position(ra_fixture_before);\n-        let diagnostic = super::diagnostics(\n-            &db,\n-            &DiagnosticsConfig::default(),\n-            &AssistResolveStrategy::All,\n-            file_position.file_id,\n-        )\n-        .pop()\n-        .expect(\"no diagnostics\");\n-        let fix = &diagnostic.fixes.expect(\"diagnostic misses fixes\")[nth];\n-        let actual = {\n-            let source_change = fix.source_change.as_ref().unwrap();\n-            let file_id = *source_change.source_file_edits.keys().next().unwrap();\n-            let mut actual = db.file_text(file_id).to_string();\n-\n-            for edit in source_change.source_file_edits.values() {\n-                edit.apply(&mut actual);\n-            }\n-            actual\n-        };\n-\n-        assert_eq_text!(&after, &actual);\n-        assert!(\n-            fix.target.contains_inclusive(file_position.offset),\n-            \"diagnostic fix range {:?} does not touch cursor position {:?}\",\n-            fix.target,\n-            file_position.offset\n-        );\n-    }\n-\n-    /// Checks that there's a diagnostic *without* fix at `$0`.\n-    pub(crate) fn check_no_fix(ra_fixture: &str) {\n-        let (db, file_position) = RootDatabase::with_position(ra_fixture);\n-        let diagnostic = super::diagnostics(\n-            &db,\n-            &DiagnosticsConfig::default(),\n-            &AssistResolveStrategy::All,\n-            file_position.file_id,\n-        )\n-        .pop()\n-        .unwrap();\n-        assert!(diagnostic.fixes.is_none(), \"got a fix when none was expected: {:?}\", diagnostic);\n-    }\n-\n-    pub(crate) fn check_expect(ra_fixture: &str, expect: Expect) {\n-        let (db, file_id) = RootDatabase::with_single_file(ra_fixture);\n-        let diagnostics = super::diagnostics(\n-            &db,\n-            &DiagnosticsConfig::default(),\n-            &AssistResolveStrategy::All,\n-            file_id,\n-        );\n-        expect.assert_debug_eq(&diagnostics)\n-    }\n-\n-    #[track_caller]\n-    pub(crate) fn check_diagnostics(ra_fixture: &str) {\n-        let mut config = DiagnosticsConfig::default();\n-        config.disabled.insert(\"inactive-code\".to_string());\n-        check_diagnostics_with_config(config, ra_fixture)\n-    }\n-\n-    #[track_caller]\n-    pub(crate) fn check_diagnostics_with_config(config: DiagnosticsConfig, ra_fixture: &str) {\n-        let (db, files) = RootDatabase::with_many_files(ra_fixture);\n-        for file_id in files {\n-            let diagnostics =\n-                super::diagnostics(&db, &config, &AssistResolveStrategy::All, file_id);\n-\n-            let expected = extract_annotations(&*db.file_text(file_id));\n-            let mut actual = diagnostics\n-                .into_iter()\n-                .map(|d| {\n-                    let mut annotation = String::new();\n-                    if let Some(fixes) = &d.fixes {\n-                        assert!(!fixes.is_empty());\n-                        annotation.push_str(\"\ud83d\udca1 \")\n-                    }\n-                    annotation.push_str(match d.severity {\n-                        Severity::Error => \"error\",\n-                        Severity::WeakWarning => \"weak\",\n-                    });\n-                    annotation.push_str(\": \");\n-                    annotation.push_str(&d.message);\n-                    (d.range, annotation)\n-                })\n-                .collect::<Vec<_>>();\n-            actual.sort_by_key(|(range, _)| range.start());\n-            assert_eq!(expected, actual);\n-        }\n-    }\n-\n-    #[test]\n-    fn test_disabled_diagnostics() {\n-        let mut config = DiagnosticsConfig::default();\n-        config.disabled.insert(\"unresolved-module\".into());\n-\n-        let (db, file_id) = RootDatabase::with_single_file(r#\"mod foo;\"#);\n-\n-        let diagnostics = super::diagnostics(&db, &config, &AssistResolveStrategy::All, file_id);\n-        assert!(diagnostics.is_empty());\n-\n-        let diagnostics = super::diagnostics(\n-            &db,\n-            &DiagnosticsConfig::default(),\n-            &AssistResolveStrategy::All,\n-            file_id,\n-        );\n-        assert!(!diagnostics.is_empty());\n-    }\n-}"}, {"sha": "a2b92c4ff91ebbb0fd32d9301465d6ba9126f83f", "filename": "crates/ide_diagnostics/src/tests.rs", "status": "added", "additions": 146, "deletions": 0, "changes": 146, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_diagnostics%2Fsrc%2Ftests.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -0,0 +1,146 @@\n+mod sourcegen;\n+\n+use expect_test::Expect;\n+use ide_db::{\n+    assists::AssistResolveStrategy,\n+    base_db::{fixture::WithFixture, SourceDatabaseExt},\n+    RootDatabase,\n+};\n+use stdx::trim_indent;\n+use test_utils::{assert_eq_text, extract_annotations};\n+\n+use crate::{DiagnosticsConfig, Severity};\n+\n+/// Takes a multi-file input fixture with annotated cursor positions,\n+/// and checks that:\n+///  * a diagnostic is produced\n+///  * the first diagnostic fix trigger range touches the input cursor position\n+///  * that the contents of the file containing the cursor match `after` after the diagnostic fix is applied\n+#[track_caller]\n+pub(crate) fn check_fix(ra_fixture_before: &str, ra_fixture_after: &str) {\n+    check_nth_fix(0, ra_fixture_before, ra_fixture_after);\n+}\n+/// Takes a multi-file input fixture with annotated cursor positions,\n+/// and checks that:\n+///  * a diagnostic is produced\n+///  * every diagnostic fixes trigger range touches the input cursor position\n+///  * that the contents of the file containing the cursor match `after` after each diagnostic fix is applied\n+pub(crate) fn check_fixes(ra_fixture_before: &str, ra_fixtures_after: Vec<&str>) {\n+    for (i, ra_fixture_after) in ra_fixtures_after.iter().enumerate() {\n+        check_nth_fix(i, ra_fixture_before, ra_fixture_after)\n+    }\n+}\n+\n+#[track_caller]\n+fn check_nth_fix(nth: usize, ra_fixture_before: &str, ra_fixture_after: &str) {\n+    let after = trim_indent(ra_fixture_after);\n+\n+    let (db, file_position) = RootDatabase::with_position(ra_fixture_before);\n+    let diagnostic = super::diagnostics(\n+        &db,\n+        &DiagnosticsConfig::default(),\n+        &AssistResolveStrategy::All,\n+        file_position.file_id,\n+    )\n+    .pop()\n+    .expect(\"no diagnostics\");\n+    let fix = &diagnostic.fixes.expect(\"diagnostic misses fixes\")[nth];\n+    let actual = {\n+        let source_change = fix.source_change.as_ref().unwrap();\n+        let file_id = *source_change.source_file_edits.keys().next().unwrap();\n+        let mut actual = db.file_text(file_id).to_string();\n+\n+        for edit in source_change.source_file_edits.values() {\n+            edit.apply(&mut actual);\n+        }\n+        actual\n+    };\n+\n+    assert_eq_text!(&after, &actual);\n+    assert!(\n+        fix.target.contains_inclusive(file_position.offset),\n+        \"diagnostic fix range {:?} does not touch cursor position {:?}\",\n+        fix.target,\n+        file_position.offset\n+    );\n+}\n+\n+/// Checks that there's a diagnostic *without* fix at `$0`.\n+pub(crate) fn check_no_fix(ra_fixture: &str) {\n+    let (db, file_position) = RootDatabase::with_position(ra_fixture);\n+    let diagnostic = super::diagnostics(\n+        &db,\n+        &DiagnosticsConfig::default(),\n+        &AssistResolveStrategy::All,\n+        file_position.file_id,\n+    )\n+    .pop()\n+    .unwrap();\n+    assert!(diagnostic.fixes.is_none(), \"got a fix when none was expected: {:?}\", diagnostic);\n+}\n+\n+pub(crate) fn check_expect(ra_fixture: &str, expect: Expect) {\n+    let (db, file_id) = RootDatabase::with_single_file(ra_fixture);\n+    let diagnostics = super::diagnostics(\n+        &db,\n+        &DiagnosticsConfig::default(),\n+        &AssistResolveStrategy::All,\n+        file_id,\n+    );\n+    expect.assert_debug_eq(&diagnostics)\n+}\n+\n+#[track_caller]\n+pub(crate) fn check_diagnostics(ra_fixture: &str) {\n+    let mut config = DiagnosticsConfig::default();\n+    config.disabled.insert(\"inactive-code\".to_string());\n+    check_diagnostics_with_config(config, ra_fixture)\n+}\n+\n+#[track_caller]\n+pub(crate) fn check_diagnostics_with_config(config: DiagnosticsConfig, ra_fixture: &str) {\n+    let (db, files) = RootDatabase::with_many_files(ra_fixture);\n+    for file_id in files {\n+        let diagnostics = super::diagnostics(&db, &config, &AssistResolveStrategy::All, file_id);\n+\n+        let expected = extract_annotations(&*db.file_text(file_id));\n+        let mut actual = diagnostics\n+            .into_iter()\n+            .map(|d| {\n+                let mut annotation = String::new();\n+                if let Some(fixes) = &d.fixes {\n+                    assert!(!fixes.is_empty());\n+                    annotation.push_str(\"\ud83d\udca1 \")\n+                }\n+                annotation.push_str(match d.severity {\n+                    Severity::Error => \"error\",\n+                    Severity::WeakWarning => \"weak\",\n+                });\n+                annotation.push_str(\": \");\n+                annotation.push_str(&d.message);\n+                (d.range, annotation)\n+            })\n+            .collect::<Vec<_>>();\n+        actual.sort_by_key(|(range, _)| range.start());\n+        assert_eq!(expected, actual);\n+    }\n+}\n+\n+#[test]\n+fn test_disabled_diagnostics() {\n+    let mut config = DiagnosticsConfig::default();\n+    config.disabled.insert(\"unresolved-module\".into());\n+\n+    let (db, file_id) = RootDatabase::with_single_file(r#\"mod foo;\"#);\n+\n+    let diagnostics = super::diagnostics(&db, &config, &AssistResolveStrategy::All, file_id);\n+    assert!(diagnostics.is_empty());\n+\n+    let diagnostics = super::diagnostics(\n+        &db,\n+        &DiagnosticsConfig::default(),\n+        &AssistResolveStrategy::All,\n+        file_id,\n+    );\n+    assert!(!diagnostics.is_empty());\n+}"}, {"sha": "f36959fb5c3c47ba9cd14e6de0c3ea80911140f3", "filename": "crates/ide_diagnostics/src/tests/sourcegen.rs", "status": "renamed", "additions": 16, "deletions": 19, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2Fsrc%2Ftests%2Fsourcegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fide_diagnostics%2Fsrc%2Ftests%2Fsourcegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_diagnostics%2Fsrc%2Ftests%2Fsourcegen.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,51 +1,48 @@\n //! Generates `assists.md` documentation.\n \n-use std::{fmt, path::PathBuf};\n+use std::{fmt, fs, io, path::PathBuf};\n \n-use xshell::write_file;\n+use sourcegen::project_root;\n \n-use crate::{\n-    codegen::{extract_comment_blocks_with_empty_lines, Location, PREAMBLE},\n-    project_root, rust_files, Result,\n-};\n-\n-pub(crate) fn generate_diagnostic_docs() -> Result<()> {\n-    let diagnostics = Diagnostic::collect()?;\n+#[test]\n+fn sourcegen_diagnostic_docs() {\n+    let diagnostics = Diagnostic::collect().unwrap();\n     let contents =\n         diagnostics.into_iter().map(|it| it.to_string()).collect::<Vec<_>>().join(\"\\n\\n\");\n-    let contents = format!(\"//{}\\n{}\\n\", PREAMBLE, contents.trim());\n+    let contents = sourcegen::add_preamble(\"sourcegen_diagnostic_docs\", contents);\n     let dst = project_root().join(\"docs/user/generated_diagnostic.adoc\");\n-    write_file(&dst, &contents)?;\n-    Ok(())\n+    fs::write(&dst, &contents).unwrap();\n }\n \n #[derive(Debug)]\n struct Diagnostic {\n     id: String,\n-    location: Location,\n+    location: sourcegen::Location,\n     doc: String,\n }\n \n impl Diagnostic {\n-    fn collect() -> Result<Vec<Diagnostic>> {\n+    fn collect() -> io::Result<Vec<Diagnostic>> {\n+        let handlers_dir = project_root().join(\"crates/ide_diagnostics/src/handlers\");\n+\n         let mut res = Vec::new();\n-        for path in rust_files() {\n+        for path in sourcegen::list_rust_files(&handlers_dir) {\n             collect_file(&mut res, path)?;\n         }\n         res.sort_by(|lhs, rhs| lhs.id.cmp(&rhs.id));\n         return Ok(res);\n \n-        fn collect_file(acc: &mut Vec<Diagnostic>, path: PathBuf) -> Result<()> {\n-            let text = xshell::read_file(&path)?;\n-            let comment_blocks = extract_comment_blocks_with_empty_lines(\"Diagnostic\", &text);\n+        fn collect_file(acc: &mut Vec<Diagnostic>, path: PathBuf) -> io::Result<()> {\n+            let text = fs::read_to_string(&path)?;\n+            let comment_blocks = sourcegen::CommentBlock::extract(\"Diagnostic\", &text);\n \n             for block in comment_blocks {\n                 let id = block.id;\n                 if let Err(msg) = is_valid_diagnostic_name(&id) {\n                     panic!(\"invalid diagnostic name: {:?}:\\n  {}\", id, msg)\n                 }\n                 let doc = block.contents.join(\"\\n\");\n-                let location = Location::new(path.clone(), block.line);\n+                let location = sourcegen::Location { file: path.clone(), line: block.line };\n                 acc.push(Diagnostic { id, location, doc })\n             }\n ", "previous_filename": "xtask/src/codegen/gen_diagnostic_docs.rs"}, {"sha": "082e813519ba28ca97247de8ea4778c41d0e373e", "filename": "crates/parser/src/syntax_kind/generated.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,4 +1,4 @@\n-//! Generated file, do not edit by hand, see `xtask/src/codegen`\n+//! Generated by `sourcegen_ast`, do not edit by hand.\n \n #![allow(bad_style, missing_docs, unreachable_pub)]\n #[doc = r\" The kind of syntax node, e.g. `IDENT`, `USE_KW`, or `STRUCT`.\"]"}, {"sha": "d152646f14981717f0a605d04c127b653072cf78", "filename": "crates/rust-analyzer/Cargo.toml", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Frust-analyzer%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Frust-analyzer%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -66,7 +66,9 @@ jemallocator = { version = \"0.4.1\", package = \"tikv-jemallocator\", optional = tr\n \n [dev-dependencies]\n expect-test = \"1.1\"\n+\n test_utils = { path = \"../test_utils\" }\n+sourcegen = { path = \"../sourcegen\" }\n mbe = { path = \"../mbe\" }\n tt = { path = \"../tt\" }\n "}, {"sha": "6c739c3bcecd2bf1f5fd2ef0e33bdc6304655ee0", "filename": "crates/rust-analyzer/tests/slow-tests/main.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Fmain.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -8,6 +8,7 @@\n //! specific JSON shapes here -- there's little value in such tests, as we can't\n //! be sure without a real client anyway.\n \n+mod sourcegen;\n mod testdir;\n mod support;\n "}, {"sha": "06139b59f207dd8a824b675059783b6102281f86", "filename": "crates/rust-analyzer/tests/slow-tests/sourcegen.rs", "status": "renamed", "additions": 22, "deletions": 21, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Fsourcegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Fsourcegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Fsourcegen.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,50 +1,51 @@\n //! Generates `assists.md` documentation.\n \n-use std::{fmt, path::PathBuf};\n+use std::{fmt, fs, io, path::PathBuf};\n \n-use xshell::write_file;\n-\n-use crate::{\n-    codegen::{extract_comment_blocks_with_empty_lines, Location, PREAMBLE},\n-    project_root, rust_files, Result,\n-};\n-\n-pub(crate) fn generate_feature_docs() -> Result<()> {\n-    let features = Feature::collect()?;\n+#[test]\n+fn sourcegen_feature_docs() {\n+    let features = Feature::collect().unwrap();\n     let contents = features.into_iter().map(|it| it.to_string()).collect::<Vec<_>>().join(\"\\n\\n\");\n-    let contents = format!(\"//{}\\n{}\\n\", PREAMBLE, contents.trim());\n-    let dst = project_root().join(\"docs/user/generated_features.adoc\");\n-    write_file(&dst, &contents)?;\n-    Ok(())\n+    let contents = format!(\n+        \"\n+// Generated file, do not edit by hand, see `sourcegen_feature_docs`.\n+{}\n+\",\n+        contents.trim()\n+    );\n+    let dst = sourcegen::project_root().join(\"docs/user/generated_features.adoc\");\n+    fs::write(&dst, &contents).unwrap();\n }\n \n #[derive(Debug)]\n struct Feature {\n     id: String,\n-    location: Location,\n+    location: sourcegen::Location,\n     doc: String,\n }\n \n impl Feature {\n-    fn collect() -> Result<Vec<Feature>> {\n+    fn collect() -> io::Result<Vec<Feature>> {\n+        let crates_dir = sourcegen::project_root().join(\"crates\");\n+\n         let mut res = Vec::new();\n-        for path in rust_files() {\n+        for path in sourcegen::list_rust_files(&crates_dir) {\n             collect_file(&mut res, path)?;\n         }\n         res.sort_by(|lhs, rhs| lhs.id.cmp(&rhs.id));\n         return Ok(res);\n \n-        fn collect_file(acc: &mut Vec<Feature>, path: PathBuf) -> Result<()> {\n-            let text = xshell::read_file(&path)?;\n-            let comment_blocks = extract_comment_blocks_with_empty_lines(\"Feature\", &text);\n+        fn collect_file(acc: &mut Vec<Feature>, path: PathBuf) -> io::Result<()> {\n+            let text = std::fs::read_to_string(&path)?;\n+            let comment_blocks = sourcegen::CommentBlock::extract(\"Feature\", &text);\n \n             for block in comment_blocks {\n                 let id = block.id;\n                 if let Err(msg) = is_valid_feature_name(&id) {\n                     panic!(\"invalid feature name: {:?}:\\n  {}\", id, msg)\n                 }\n                 let doc = block.contents.join(\"\\n\");\n-                let location = Location::new(path.clone(), block.line);\n+                let location = sourcegen::Location { file: path.clone(), line: block.line };\n                 acc.push(Feature { id, location, doc })\n             }\n ", "previous_filename": "xtask/src/codegen/gen_feature_docs.rs"}, {"sha": "4456a435aa52e937e7668fb9a6b5e970c76bb219", "filename": "crates/sourcegen/Cargo.toml", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsourcegen%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsourcegen%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsourcegen%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -0,0 +1,13 @@\n+[package]\n+name = \"sourcegen\"\n+version = \"0.0.0\"\n+description = \"TBD\"\n+license = \"MIT OR Apache-2.0\"\n+authors = [\"rust-analyzer developers\"]\n+edition = \"2018\"\n+\n+[lib]\n+doctest = false\n+\n+[dependencies]\n+xshell = \"0.1\""}, {"sha": "9197dbed8f6a3f4fcc473089f96df0dd054b5b81", "filename": "crates/sourcegen/src/lib.rs", "status": "added", "additions": 195, "deletions": 0, "changes": 195, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsourcegen%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsourcegen%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsourcegen%2Fsrc%2Flib.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -0,0 +1,195 @@\n+//! rust-analyzer relies heavily on source code generation.\n+//!\n+//! Things like feature documentation or assist tests are implemented by\n+//! processing rust-analyzer's own source code and generating the appropriate\n+//! output. See `sourcegen_` tests in various crates.\n+//!\n+//! This crate contains utilities to make this kind of source-gen easy.\n+\n+use std::{\n+    fmt, fs, mem,\n+    path::{Path, PathBuf},\n+};\n+\n+use xshell::{cmd, pushenv};\n+\n+pub fn list_rust_files(dir: &Path) -> Vec<PathBuf> {\n+    let mut res = list_files(dir);\n+    res.retain(|it| {\n+        it.file_name().unwrap_or_default().to_str().unwrap_or_default().ends_with(\".rs\")\n+    });\n+    res\n+}\n+\n+pub fn list_files(dir: &Path) -> Vec<PathBuf> {\n+    let mut res = Vec::new();\n+    let mut work = vec![dir.to_path_buf()];\n+    while let Some(dir) = work.pop() {\n+        for entry in dir.read_dir().unwrap() {\n+            let entry = entry.unwrap();\n+            let file_type = entry.file_type().unwrap();\n+            let path = entry.path();\n+            let is_hidden =\n+                path.file_name().unwrap_or_default().to_str().unwrap_or_default().starts_with('.');\n+            if !is_hidden {\n+                if file_type.is_dir() {\n+                    work.push(path)\n+                } else if file_type.is_file() {\n+                    res.push(path)\n+                }\n+            }\n+        }\n+    }\n+    res\n+}\n+\n+pub struct CommentBlock {\n+    pub id: String,\n+    pub line: usize,\n+    pub contents: Vec<String>,\n+}\n+\n+impl CommentBlock {\n+    pub fn extract(tag: &str, text: &str) -> Vec<CommentBlock> {\n+        assert!(tag.starts_with(char::is_uppercase));\n+\n+        let tag = format!(\"{}:\", tag);\n+        let mut res = Vec::new();\n+        for (line, mut block) in do_extract_comment_blocks(text, true) {\n+            let first = block.remove(0);\n+            if let Some(id) = first.strip_prefix(&tag) {\n+                let id = id.trim().to_string();\n+                let block = CommentBlock { id, line, contents: block };\n+                res.push(block);\n+            }\n+        }\n+        res\n+    }\n+\n+    pub fn extract_untagged(text: &str) -> Vec<CommentBlock> {\n+        let mut res = Vec::new();\n+        for (line, block) in do_extract_comment_blocks(text, false) {\n+            let id = String::new();\n+            let block = CommentBlock { id, line, contents: block };\n+            res.push(block);\n+        }\n+        res\n+    }\n+}\n+\n+fn do_extract_comment_blocks(\n+    text: &str,\n+    allow_blocks_with_empty_lines: bool,\n+) -> Vec<(usize, Vec<String>)> {\n+    let mut res = Vec::new();\n+\n+    let prefix = \"// \";\n+    let lines = text.lines().map(str::trim_start);\n+\n+    let mut block = (0, vec![]);\n+    for (line_num, line) in lines.enumerate() {\n+        if line == \"//\" && allow_blocks_with_empty_lines {\n+            block.1.push(String::new());\n+            continue;\n+        }\n+\n+        let is_comment = line.starts_with(prefix);\n+        if is_comment {\n+            block.1.push(line[prefix.len()..].to_string());\n+        } else {\n+            if !block.1.is_empty() {\n+                res.push(mem::take(&mut block));\n+            }\n+            block.0 = line_num + 2;\n+        }\n+    }\n+    if !block.1.is_empty() {\n+        res.push(block)\n+    }\n+    res\n+}\n+\n+#[derive(Debug)]\n+pub struct Location {\n+    pub file: PathBuf,\n+    pub line: usize,\n+}\n+\n+impl fmt::Display for Location {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        let path = self.file.strip_prefix(&project_root()).unwrap().display().to_string();\n+        let path = path.replace('\\\\', \"/\");\n+        let name = self.file.file_name().unwrap();\n+        write!(\n+            f,\n+            \"https://github.com/rust-analyzer/rust-analyzer/blob/master/{}#L{}[{}]\",\n+            path,\n+            self.line,\n+            name.to_str().unwrap()\n+        )\n+    }\n+}\n+\n+fn ensure_rustfmt() {\n+    let version = cmd!(\"rustfmt --version\").read().unwrap_or_default();\n+    if !version.contains(\"stable\") {\n+        panic!(\n+            \"Failed to run rustfmt from toolchain 'stable'. \\\n+                 Please run `rustup component add rustfmt --toolchain stable` to install it.\",\n+        )\n+    }\n+}\n+\n+pub fn reformat(text: String) -> String {\n+    let _e = pushenv(\"RUSTUP_TOOLCHAIN\", \"stable\");\n+    ensure_rustfmt();\n+    let rustfmt_toml = project_root().join(\"rustfmt.toml\");\n+    let mut stdout = cmd!(\"rustfmt --config-path {rustfmt_toml} --config fn_single_line=true\")\n+        .stdin(text)\n+        .read()\n+        .unwrap();\n+    if !stdout.ends_with('\\n') {\n+        stdout.push('\\n');\n+    }\n+    stdout\n+}\n+\n+pub fn add_preamble(generator: &'static str, mut text: String) -> String {\n+    let preamble = format!(\"//! Generated by `{}`, do not edit by hand.\\n\\n\", generator);\n+    text.insert_str(0, &preamble);\n+    text\n+}\n+\n+/// Checks that the `file` has the specified `contents`. If that is not the\n+/// case, updates the file and then fails the test.\n+pub fn ensure_file_contents(file: &Path, contents: &str) {\n+    if let Ok(old_contents) = fs::read_to_string(file) {\n+        if normalize_newlines(&old_contents) == normalize_newlines(contents) {\n+            // File is already up to date.\n+            return;\n+        }\n+    }\n+\n+    let display_path = file.strip_prefix(&project_root()).unwrap_or(file);\n+    eprintln!(\n+        \"\\n\\x1b[31;1merror\\x1b[0m: {} was not up-to-date, updating\\n\",\n+        display_path.display()\n+    );\n+    if std::env::var(\"CI\").is_ok() {\n+        eprintln!(\"    NOTE: run `cargo test` locally and commit the updated files\\n\");\n+    }\n+    if let Some(parent) = file.parent() {\n+        let _ = fs::create_dir_all(parent);\n+    }\n+    fs::write(file, contents).unwrap();\n+    panic!(\"some file was not up to date and has been updated, simply re-run the tests\")\n+}\n+\n+fn normalize_newlines(s: &str) -> String {\n+    s.replace(\"\\r\\n\", \"\\n\")\n+}\n+\n+pub fn project_root() -> PathBuf {\n+    let dir = env!(\"CARGO_MANIFEST_DIR\");\n+    PathBuf::from(dir).parent().unwrap().parent().unwrap().to_owned()\n+}"}, {"sha": "1a0d7522ef363ba981c8b8dc850e15e5d8d4546e", "filename": "crates/syntax/Cargo.toml", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -28,7 +28,11 @@ parser = { path = \"../parser\", version = \"0.0.0\" }\n profile = { path = \"../profile\", version = \"0.0.0\" }\n \n [dev-dependencies]\n-test_utils = { path = \"../test_utils\" }\n-walkdir = \"2.3.1\"\n rayon = \"1\"\n expect-test = \"1.1\"\n+proc-macro2 = \"1.0.8\"\n+quote = \"1.0.2\"\n+ungrammar = \"=1.14\"\n+\n+test_utils = { path = \"../test_utils\" }\n+sourcegen = { path = \"../sourcegen\" }"}, {"sha": "b040bf61f4837b00f45065ce480a473e9b1a1702", "filename": "crates/syntax/src/ast/generated/nodes.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Fast%2Fgenerated%2Fnodes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Fast%2Fgenerated%2Fnodes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Fast%2Fgenerated%2Fnodes.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,4 +1,4 @@\n-//! Generated file, do not edit by hand, see `xtask/src/codegen`\n+//! Generated by `sourcegen_ast`, do not edit by hand.\n \n use crate::{\n     ast::{self, support, AstChildren, AstNode},"}, {"sha": "83fd5ce899b95bcf48b868b43d02d2b447021cf3", "filename": "crates/syntax/src/ast/generated/tokens.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Fast%2Fgenerated%2Ftokens.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Fast%2Fgenerated%2Ftokens.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Fast%2Fgenerated%2Ftokens.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,4 +1,4 @@\n-//! Generated file, do not edit by hand, see `xtask/src/codegen`\n+//! Generated by `sourcegen_ast`, do not edit by hand.\n \n use crate::{\n     ast::AstToken,"}, {"sha": "b4bc6beeadee282a71d919985051e455c6b64e12", "filename": "crates/syntax/src/tests.rs", "status": "modified", "additions": 12, "deletions": 14, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Ftests.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,3 +1,7 @@\n+mod sourcegen_tests;\n+mod sourcegen_ast;\n+mod ast_src;\n+\n use std::{\n     fmt::Write,\n     fs,\n@@ -152,20 +156,14 @@ fn reparse_fuzz_tests() {\n /// Test that Rust-analyzer can parse and validate the rust-analyzer\n #[test]\n fn self_hosting_parsing() {\n-    let dir = project_root().join(\"crates\");\n-    let files = walkdir::WalkDir::new(dir)\n-        .into_iter()\n-        .filter_entry(|entry| {\n-            // Get all files which are not in the crates/syntax/test_data folder\n-            !entry.path().components().any(|component| component.as_os_str() == \"test_data\")\n-        })\n-        .map(|e| e.unwrap())\n-        .filter(|entry| {\n-            // Get all `.rs ` files\n-            !entry.path().is_dir() && (entry.path().extension().unwrap_or_default() == \"rs\")\n-        })\n-        .map(|entry| entry.into_path())\n-        .collect::<Vec<_>>();\n+    let crates_dir = project_root().join(\"crates\");\n+\n+    let mut files = ::sourcegen::list_rust_files(&crates_dir);\n+    files.retain(|path| {\n+        // Get all files which are not in the crates/syntax/test_data folder\n+        !path.components().any(|component| component.as_os_str() == \"test_data\")\n+    });\n+\n     assert!(\n         files.len() > 100,\n         \"self_hosting_parsing found too few files - is it running in the right directory?\""}, {"sha": "fe37d0245186c3d725598022ff8d03e75400e811", "filename": "crates/syntax/src/tests/ast_src.rs", "status": "renamed", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests%2Fast_src.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests%2Fast_src.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Ftests%2Fast_src.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "previous_filename": "xtask/src/ast_src.rs"}, {"sha": "d2bafb3a7b86fe9c4e1b749ffff0fa7266d8184c", "filename": "crates/syntax/src/tests/sourcegen_ast.rs", "status": "renamed", "additions": 33, "deletions": 33, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_ast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_ast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_ast.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -12,32 +12,31 @@ use proc_macro2::{Punct, Spacing};\n use quote::{format_ident, quote};\n use ungrammar::{rust_grammar, Grammar, Rule};\n \n-use crate::{\n-    ast_src::{AstEnumSrc, AstNodeSrc, AstSrc, Cardinality, Field, KindsSrc, KINDS_SRC},\n-    codegen::{ensure_file_contents, reformat},\n-    project_root, Result,\n+use crate::tests::ast_src::{\n+    AstEnumSrc, AstNodeSrc, AstSrc, Cardinality, Field, KindsSrc, KINDS_SRC,\n };\n \n-pub(crate) fn generate_syntax() -> Result<()> {\n+#[test]\n+fn sourcegen_ast() {\n     let grammar = rust_grammar();\n     let ast = lower(&grammar);\n \n-    let syntax_kinds_file = project_root().join(\"crates/parser/src/syntax_kind/generated.rs\");\n-    let syntax_kinds = generate_syntax_kinds(KINDS_SRC)?;\n-    ensure_file_contents(syntax_kinds_file.as_path(), &syntax_kinds)?;\n+    let syntax_kinds_file =\n+        sourcegen::project_root().join(\"crates/parser/src/syntax_kind/generated.rs\");\n+    let syntax_kinds = generate_syntax_kinds(KINDS_SRC);\n+    sourcegen::ensure_file_contents(syntax_kinds_file.as_path(), &syntax_kinds);\n \n-    let ast_tokens_file = project_root().join(\"crates/syntax/src/ast/generated/tokens.rs\");\n-    let contents = generate_tokens(&ast)?;\n-    ensure_file_contents(ast_tokens_file.as_path(), &contents)?;\n+    let ast_tokens_file =\n+        sourcegen::project_root().join(\"crates/syntax/src/ast/generated/tokens.rs\");\n+    let contents = generate_tokens(&ast);\n+    sourcegen::ensure_file_contents(ast_tokens_file.as_path(), &contents);\n \n-    let ast_nodes_file = project_root().join(\"crates/syntax/src/ast/generated/nodes.rs\");\n-    let contents = generate_nodes(KINDS_SRC, &ast)?;\n-    ensure_file_contents(ast_nodes_file.as_path(), &contents)?;\n-\n-    Ok(())\n+    let ast_nodes_file = sourcegen::project_root().join(\"crates/syntax/src/ast/generated/nodes.rs\");\n+    let contents = generate_nodes(KINDS_SRC, &ast);\n+    sourcegen::ensure_file_contents(ast_nodes_file.as_path(), &contents);\n }\n \n-fn generate_tokens(grammar: &AstSrc) -> Result<String> {\n+fn generate_tokens(grammar: &AstSrc) -> String {\n     let tokens = grammar.tokens.iter().map(|token| {\n         let name = format_ident!(\"{}\", token);\n         let kind = format_ident!(\"{}\", to_upper_snake_case(token));\n@@ -61,18 +60,20 @@ fn generate_tokens(grammar: &AstSrc) -> Result<String> {\n         }\n     });\n \n-    let pretty = reformat(\n-        &quote! {\n-            use crate::{SyntaxKind::{self, *}, SyntaxToken, ast::AstToken};\n-            #(#tokens)*\n-        }\n-        .to_string(),\n-    )?\n-    .replace(\"#[derive\", \"\\n#[derive\");\n-    Ok(pretty)\n+    sourcegen::add_preamble(\n+        \"sourcegen_ast\",\n+        sourcegen::reformat(\n+            quote! {\n+                use crate::{SyntaxKind::{self, *}, SyntaxToken, ast::AstToken};\n+                #(#tokens)*\n+            }\n+            .to_string(),\n+        ),\n+    )\n+    .replace(\"#[derive\", \"\\n#[derive\")\n }\n \n-fn generate_nodes(kinds: KindsSrc<'_>, grammar: &AstSrc) -> Result<String> {\n+fn generate_nodes(kinds: KindsSrc<'_>, grammar: &AstSrc) -> String {\n     let (node_defs, node_boilerplate_impls): (Vec<_>, Vec<_>) = grammar\n         .nodes\n         .iter()\n@@ -230,7 +231,7 @@ fn generate_nodes(kinds: KindsSrc<'_>, grammar: &AstSrc) -> Result<String> {\n         .filter(|name| !defined_nodes.iter().any(|&it| it == name))\n     {\n         drop(node)\n-        // TODO: restore this\n+        // FIXME: restore this\n         // eprintln!(\"Warning: node {} not defined in ast source\", node);\n     }\n \n@@ -262,8 +263,7 @@ fn generate_nodes(kinds: KindsSrc<'_>, grammar: &AstSrc) -> Result<String> {\n         }\n     }\n \n-    let pretty = reformat(&res)?;\n-    Ok(pretty)\n+    sourcegen::add_preamble(\"sourcegen_ast\", sourcegen::reformat(res))\n }\n \n fn write_doc_comment(contents: &[String], dest: &mut String) {\n@@ -272,7 +272,7 @@ fn write_doc_comment(contents: &[String], dest: &mut String) {\n     }\n }\n \n-fn generate_syntax_kinds(grammar: KindsSrc<'_>) -> Result<String> {\n+fn generate_syntax_kinds(grammar: KindsSrc<'_>) -> String {\n     let (single_byte_tokens_values, single_byte_tokens): (Vec<_>, Vec<_>) = grammar\n         .punct\n         .iter()\n@@ -384,7 +384,7 @@ fn generate_syntax_kinds(grammar: KindsSrc<'_>) -> Result<String> {\n         }\n     };\n \n-    reformat(&ast.to_string())\n+    sourcegen::add_preamble(\"sourcegen_ast\", sourcegen::reformat(ast.to_string()))\n }\n \n fn to_upper_snake_case(s: &str) -> String {\n@@ -580,7 +580,7 @@ fn lower_rule(acc: &mut Vec<Field>, grammar: &Grammar, label: Option<&String>, r\n                 acc.push(field);\n                 return;\n             }\n-            todo!(\"{:?}\", rule)\n+            panic!(\"unhandled rule: {:?}\", rule)\n         }\n         Rule::Labeled { label: l, rule } => {\n             assert!(label.is_none());", "previous_filename": "xtask/src/codegen/gen_syntax.rs"}, {"sha": "7f56807947f2482e377a85b9ca6d57ce8b9b7f60", "filename": "crates/syntax/src/tests/sourcegen_tests.rs", "status": "renamed", "additions": 36, "deletions": 44, "changes": 80, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_tests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_tests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_tests.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -1,26 +1,28 @@\n-//! This module greps parser's code for specially formatted comments and turnes\n+//! This module greps parser's code for specially formatted comments and turns\n //! them into tests.\n \n use std::{\n-    collections::HashMap,\n     fs, iter,\n     path::{Path, PathBuf},\n };\n \n-use crate::{\n-    codegen::{ensure_file_contents, extract_comment_blocks},\n-    project_root, Result,\n-};\n+use rustc_hash::FxHashMap;\n+\n+#[test]\n+fn sourcegen_parser_tests() {\n+    let grammar_dir = sourcegen::project_root().join(Path::new(\"crates/parser/src/grammar\"));\n+    let tests = tests_from_dir(&grammar_dir);\n+\n+    install_tests(&tests.ok, \"crates/syntax/test_data/parser/inline/ok\");\n+    install_tests(&tests.err, \"crates/syntax/test_data/parser/inline/err\");\n \n-pub(crate) fn generate_parser_tests() -> Result<()> {\n-    let tests = tests_from_dir(&project_root().join(Path::new(\"crates/parser/src/grammar\")))?;\n-    fn install_tests(tests: &HashMap<String, Test>, into: &str) -> Result<()> {\n-        let tests_dir = project_root().join(into);\n+    fn install_tests(tests: &FxHashMap<String, Test>, into: &str) {\n+        let tests_dir = sourcegen::project_root().join(into);\n         if !tests_dir.is_dir() {\n-            fs::create_dir_all(&tests_dir)?;\n+            fs::create_dir_all(&tests_dir).unwrap();\n         }\n         // ok is never actually read, but it needs to be specified to create a Test in existing_tests\n-        let existing = existing_tests(&tests_dir, true)?;\n+        let existing = existing_tests(&tests_dir, true);\n         for t in existing.keys().filter(|&t| !tests.contains_key(t)) {\n             panic!(\"Test is deleted: {}\", t);\n         }\n@@ -35,12 +37,9 @@ pub(crate) fn generate_parser_tests() -> Result<()> {\n                     tests_dir.join(file_name)\n                 }\n             };\n-            ensure_file_contents(&path, &test.text)?;\n+            sourcegen::ensure_file_contents(&path, &test.text);\n         }\n-        Ok(())\n     }\n-    install_tests(&tests.ok, \"crates/syntax/test_data/parser/inline/ok\")?;\n-    install_tests(&tests.err, \"crates/syntax/test_data/parser/inline/err\")\n }\n \n #[derive(Debug)]\n@@ -52,22 +51,22 @@ struct Test {\n \n #[derive(Default, Debug)]\n struct Tests {\n-    ok: HashMap<String, Test>,\n-    err: HashMap<String, Test>,\n+    ok: FxHashMap<String, Test>,\n+    err: FxHashMap<String, Test>,\n }\n \n fn collect_tests(s: &str) -> Vec<Test> {\n     let mut res = Vec::new();\n-    for comment_block in extract_comment_blocks(s) {\n-        let first_line = &comment_block[0];\n+    for comment_block in sourcegen::CommentBlock::extract_untagged(s) {\n+        let first_line = &comment_block.contents[0];\n         let (name, ok) = if let Some(name) = first_line.strip_prefix(\"test \") {\n             (name.to_string(), true)\n         } else if let Some(name) = first_line.strip_prefix(\"test_err \") {\n             (name.to_string(), false)\n         } else {\n             continue;\n         };\n-        let text: String = comment_block[1..]\n+        let text: String = comment_block.contents[1..]\n             .iter()\n             .cloned()\n             .chain(iter::once(String::new()))\n@@ -79,41 +78,34 @@ fn collect_tests(s: &str) -> Vec<Test> {\n     res\n }\n \n-fn tests_from_dir(dir: &Path) -> Result<Tests> {\n+fn tests_from_dir(dir: &Path) -> Tests {\n     let mut res = Tests::default();\n-    for entry in ::walkdir::WalkDir::new(dir) {\n-        let entry = entry.unwrap();\n-        if !entry.file_type().is_file() {\n-            continue;\n-        }\n-        if entry.path().extension().unwrap_or_default() != \"rs\" {\n-            continue;\n-        }\n-        process_file(&mut res, entry.path())?;\n+    for entry in sourcegen::list_rust_files(dir) {\n+        process_file(&mut res, entry.as_path());\n     }\n     let grammar_rs = dir.parent().unwrap().join(\"grammar.rs\");\n-    process_file(&mut res, &grammar_rs)?;\n-    return Ok(res);\n-    fn process_file(res: &mut Tests, path: &Path) -> Result<()> {\n-        let text = fs::read_to_string(path)?;\n+    process_file(&mut res, &grammar_rs);\n+    return res;\n+\n+    fn process_file(res: &mut Tests, path: &Path) {\n+        let text = fs::read_to_string(path).unwrap();\n \n         for test in collect_tests(&text) {\n             if test.ok {\n                 if let Some(old_test) = res.ok.insert(test.name.clone(), test) {\n-                    anyhow::bail!(\"Duplicate test: {}\", old_test.name);\n+                    panic!(\"Duplicate test: {}\", old_test.name);\n                 }\n             } else if let Some(old_test) = res.err.insert(test.name.clone(), test) {\n-                anyhow::bail!(\"Duplicate test: {}\", old_test.name);\n+                panic!(\"Duplicate test: {}\", old_test.name);\n             }\n         }\n-        Ok(())\n     }\n }\n \n-fn existing_tests(dir: &Path, ok: bool) -> Result<HashMap<String, (PathBuf, Test)>> {\n-    let mut res = HashMap::new();\n-    for file in fs::read_dir(dir)? {\n-        let file = file?;\n+fn existing_tests(dir: &Path, ok: bool) -> FxHashMap<String, (PathBuf, Test)> {\n+    let mut res = FxHashMap::default();\n+    for file in fs::read_dir(dir).unwrap() {\n+        let file = file.unwrap();\n         let path = file.path();\n         if path.extension().unwrap_or_default() != \"rs\" {\n             continue;\n@@ -122,11 +114,11 @@ fn existing_tests(dir: &Path, ok: bool) -> Result<HashMap<String, (PathBuf, Test\n             let file_name = path.file_name().unwrap().to_str().unwrap();\n             file_name[5..file_name.len() - 3].to_string()\n         };\n-        let text = xshell::read_file(&path)?;\n+        let text = fs::read_to_string(&path).unwrap();\n         let test = Test { name: name.clone(), text, ok };\n         if let Some(old) = res.insert(name, (path, test)) {\n             println!(\"Duplicate test: {:?}\", old);\n         }\n     }\n-    Ok(res)\n+    res\n }", "previous_filename": "xtask/src/codegen/gen_parser_tests.rs"}, {"sha": "663d63922749989fcd15fcaaba37643c2beaf125", "filename": "docs/dev/architecture.md", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/docs%2Fdev%2Farchitecture.md", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/docs%2Fdev%2Farchitecture.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2Fdev%2Farchitecture.md?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -325,6 +325,8 @@ In particular, we generate:\n \n * Documentation tests for assists\n \n+See the `sourcegen` crate for details.\n+\n **Architecture Invariant:** we avoid bootstrapping.\n For codegen we need to parse Rust code.\n Using rust-analyzer for that would work and would be fun, but it would also complicate the build process a lot."}, {"sha": "3628f92ef3cc02b7c429a0db602863ffc30af067", "filename": "xtask/Cargo.toml", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/xtask%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/xtask%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2FCargo.toml?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -9,9 +9,6 @@ license = \"MIT OR Apache-2.0\"\n [dependencies]\n anyhow = \"1.0.26\"\n flate2 = \"1.0\"\n-proc-macro2 = \"1.0.8\"\n-quote = \"1.0.2\"\n-ungrammar = \"=1.14\"\n walkdir = \"2.3.1\"\n write-json = \"0.1.0\"\n xshell = \"0.1\""}, {"sha": "518e17e3897cace71c0a30c96afa1d59ff250239", "filename": "xtask/src/codegen.rs", "status": "removed", "additions": 0, "deletions": 166, "changes": 166, "blob_url": "https://github.com/rust-lang/rust/blob/888bb6c452f89a1b587fb4cf88a6cedd9c0652bb/xtask%2Fsrc%2Fcodegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/888bb6c452f89a1b587fb4cf88a6cedd9c0652bb/xtask%2Fsrc%2Fcodegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fcodegen.rs?ref=888bb6c452f89a1b587fb4cf88a6cedd9c0652bb", "patch": "@@ -1,166 +0,0 @@\n-//! We use code generation heavily in rust-analyzer.\n-//!\n-//! Rather then doing it via proc-macros, we use old-school way of just dumping\n-//! the source code.\n-//!\n-//! This module's submodules define specific bits that we generate.\n-\n-mod gen_syntax;\n-mod gen_parser_tests;\n-mod gen_lint_completions;\n-mod gen_assists_docs;\n-mod gen_feature_docs;\n-mod gen_diagnostic_docs;\n-\n-use std::{\n-    fmt, mem,\n-    path::{Path, PathBuf},\n-};\n-use xshell::{cmd, pushenv};\n-\n-use crate::{ensure_rustfmt, project_root, Result};\n-\n-pub(crate) use self::{\n-    gen_assists_docs::generate_assists_tests, gen_lint_completions::generate_lint_completions,\n-    gen_parser_tests::generate_parser_tests, gen_syntax::generate_syntax,\n-};\n-\n-pub(crate) fn docs() -> Result<()> {\n-    // We don't commit docs to the repo, so we can just overwrite them.\n-    gen_assists_docs::generate_assists_docs()?;\n-    gen_feature_docs::generate_feature_docs()?;\n-    gen_diagnostic_docs::generate_diagnostic_docs()?;\n-    Ok(())\n-}\n-\n-#[allow(unused)]\n-fn used() {\n-    generate_parser_tests();\n-    generate_assists_tests();\n-    generate_syntax();\n-    generate_lint_completions();\n-}\n-\n-/// Checks that the `file` has the specified `contents`. If that is not the\n-/// case, updates the file and then fails the test.\n-pub(crate) fn ensure_file_contents(file: &Path, contents: &str) -> Result<()> {\n-    match std::fs::read_to_string(file) {\n-        Ok(old_contents) if normalize_newlines(&old_contents) == normalize_newlines(contents) => {\n-            return Ok(())\n-        }\n-        _ => (),\n-    }\n-    let display_path = file.strip_prefix(&project_root()).unwrap_or(file);\n-    eprintln!(\n-        \"\\n\\x1b[31;1merror\\x1b[0m: {} was not up-to-date, updating\\n\",\n-        display_path.display()\n-    );\n-    if std::env::var(\"CI\").is_ok() {\n-        eprintln!(\"    NOTE: run `cargo test` locally and commit the updated files\\n\");\n-    }\n-    if let Some(parent) = file.parent() {\n-        let _ = std::fs::create_dir_all(parent);\n-    }\n-    std::fs::write(file, contents).unwrap();\n-    anyhow::bail!(\"some file was not up to date and has been updated, simply re-run the tests\")\n-}\n-\n-fn normalize_newlines(s: &str) -> String {\n-    s.replace(\"\\r\\n\", \"\\n\")\n-}\n-\n-const PREAMBLE: &str = \"Generated file, do not edit by hand, see `xtask/src/codegen`\";\n-\n-fn reformat(text: &str) -> Result<String> {\n-    let _e = pushenv(\"RUSTUP_TOOLCHAIN\", \"stable\");\n-    ensure_rustfmt()?;\n-    let rustfmt_toml = project_root().join(\"rustfmt.toml\");\n-    let stdout = cmd!(\"rustfmt --config-path {rustfmt_toml} --config fn_single_line=true\")\n-        .stdin(text)\n-        .read()?;\n-    Ok(format!(\"//! {}\\n\\n{}\\n\", PREAMBLE, stdout))\n-}\n-\n-fn extract_comment_blocks(text: &str) -> Vec<Vec<String>> {\n-    do_extract_comment_blocks(text, false).into_iter().map(|(_line, block)| block).collect()\n-}\n-\n-fn extract_comment_blocks_with_empty_lines(tag: &str, text: &str) -> Vec<CommentBlock> {\n-    assert!(tag.starts_with(char::is_uppercase));\n-    let tag = format!(\"{}:\", tag);\n-    let mut res = Vec::new();\n-    for (line, mut block) in do_extract_comment_blocks(text, true) {\n-        let first = block.remove(0);\n-        if first.starts_with(&tag) {\n-            let id = first[tag.len()..].trim().to_string();\n-            let block = CommentBlock { id, line, contents: block };\n-            res.push(block);\n-        }\n-    }\n-    res\n-}\n-\n-struct CommentBlock {\n-    id: String,\n-    line: usize,\n-    contents: Vec<String>,\n-}\n-\n-fn do_extract_comment_blocks(\n-    text: &str,\n-    allow_blocks_with_empty_lines: bool,\n-) -> Vec<(usize, Vec<String>)> {\n-    let mut res = Vec::new();\n-\n-    let prefix = \"// \";\n-    let lines = text.lines().map(str::trim_start);\n-\n-    let mut block = (0, vec![]);\n-    for (line_num, line) in lines.enumerate() {\n-        if line == \"//\" && allow_blocks_with_empty_lines {\n-            block.1.push(String::new());\n-            continue;\n-        }\n-\n-        let is_comment = line.starts_with(prefix);\n-        if is_comment {\n-            block.1.push(line[prefix.len()..].to_string());\n-        } else {\n-            if !block.1.is_empty() {\n-                res.push(mem::take(&mut block));\n-            }\n-            block.0 = line_num + 2;\n-        }\n-    }\n-    if !block.1.is_empty() {\n-        res.push(block)\n-    }\n-    res\n-}\n-\n-#[derive(Debug)]\n-struct Location {\n-    file: PathBuf,\n-    line: usize,\n-}\n-\n-impl Location {\n-    fn new(file: PathBuf, line: usize) -> Self {\n-        Self { file, line }\n-    }\n-}\n-\n-impl fmt::Display for Location {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        let path = self.file.strip_prefix(&project_root()).unwrap().display().to_string();\n-        let path = path.replace('\\\\', \"/\");\n-        let name = self.file.file_name().unwrap();\n-        write!(\n-            f,\n-            \"https://github.com/rust-analyzer/rust-analyzer/blob/master/{}#L{}[{}]\",\n-            path,\n-            self.line,\n-            name.to_str().unwrap()\n-        )\n-    }\n-}"}, {"sha": "42e91749a97d611c8c4007a4057c5cd71747c05a", "filename": "xtask/src/main.rs", "status": "modified", "additions": 0, "deletions": 43, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/xtask%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/xtask%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fmain.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -9,8 +9,6 @@\n //! `.cargo/config`.\n mod flags;\n \n-mod codegen;\n-mod ast_src;\n #[cfg(test)]\n mod tidy;\n \n@@ -24,7 +22,6 @@ use std::{\n     env,\n     path::{Path, PathBuf},\n };\n-use walkdir::{DirEntry, WalkDir};\n use xshell::{cmd, cp, pushd, pushenv};\n \n fn main() -> Result<()> {\n@@ -63,31 +60,6 @@ fn project_root() -> PathBuf {\n     .to_path_buf()\n }\n \n-fn rust_files() -> impl Iterator<Item = PathBuf> {\n-    rust_files_in(&project_root().join(\"crates\"))\n-}\n-\n-#[cfg(test)]\n-fn cargo_files() -> impl Iterator<Item = PathBuf> {\n-    files_in(&project_root(), \"toml\")\n-        .filter(|path| path.file_name().map(|it| it == \"Cargo.toml\").unwrap_or(false))\n-}\n-\n-fn rust_files_in(path: &Path) -> impl Iterator<Item = PathBuf> {\n-    files_in(path, \"rs\")\n-}\n-\n-fn ensure_rustfmt() -> Result<()> {\n-    let out = cmd!(\"rustfmt --version\").read()?;\n-    if !out.contains(\"stable\") {\n-        bail!(\n-            \"Failed to run rustfmt from toolchain 'stable'. \\\n-             Please run `rustup component add rustfmt --toolchain stable` to install it.\",\n-        )\n-    }\n-    Ok(())\n-}\n-\n fn run_fuzzer() -> Result<()> {\n     let _d = pushd(\"./crates/syntax\")?;\n     let _e = pushenv(\"RUSTUP_TOOLCHAIN\", \"nightly\");\n@@ -113,18 +85,3 @@ fn date_iso() -> Result<String> {\n fn is_release_tag(tag: &str) -> bool {\n     tag.len() == \"2020-02-24\".len() && tag.starts_with(|c: char| c.is_ascii_digit())\n }\n-\n-fn files_in(path: &Path, ext: &'static str) -> impl Iterator<Item = PathBuf> {\n-    let iter = WalkDir::new(path);\n-    return iter\n-        .into_iter()\n-        .filter_entry(|e| !is_hidden(e))\n-        .map(|e| e.unwrap())\n-        .filter(|e| !e.file_type().is_dir())\n-        .map(|e| e.into_path())\n-        .filter(move |path| path.extension().map(|it| it == ext).unwrap_or(false));\n-\n-    fn is_hidden(entry: &DirEntry) -> bool {\n-        entry.file_name().to_str().map(|s| s.starts_with('.')).unwrap_or(false)\n-    }\n-}"}, {"sha": "37de5b36f18bd677bcddcd8408b23da845977463", "filename": "xtask/src/release.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/xtask%2Fsrc%2Frelease.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/xtask%2Fsrc%2Frelease.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Frelease.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -2,7 +2,7 @@ mod changelog;\n \n use xshell::{cmd, pushd, read_dir, read_file, write_file};\n \n-use crate::{codegen, date_iso, flags, is_release_tag, project_root, Result};\n+use crate::{date_iso, flags, is_release_tag, project_root, Result};\n \n impl flags::Release {\n     pub(crate) fn run(self) -> Result<()> {\n@@ -21,7 +21,10 @@ impl flags::Release {\n             // to delete old tags.\n             cmd!(\"git push --force\").run()?;\n         }\n-        codegen::docs()?;\n+\n+        // Generates bits of manual.adoc.\n+        cmd!(\"cargo test -p ide_assists -p ide_diagnostics -p rust-analyzer -- sourcegen_\")\n+            .run()?;\n \n         let website_root = project_root().join(\"../rust-analyzer.github.io\");\n         let changelog_dir = website_root.join(\"./thisweek/_posts\");"}, {"sha": "fc5bf17a28fc5f5cbd7d690111b3dfb86fbde80b", "filename": "xtask/src/tidy.rs", "status": "modified", "additions": 41, "deletions": 30, "changes": 71, "blob_url": "https://github.com/rust-lang/rust/blob/336194c09b404a1b2e4a360058337372446ee88c/xtask%2Fsrc%2Ftidy.rs", "raw_url": "https://github.com/rust-lang/rust/raw/336194c09b404a1b2e4a360058337372446ee88c/xtask%2Fsrc%2Ftidy.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Ftidy.rs?ref=336194c09b404a1b2e4a360058337372446ee88c", "patch": "@@ -3,50 +3,31 @@ use std::{\n     path::{Path, PathBuf},\n };\n \n+use walkdir::{DirEntry, WalkDir};\n use xshell::{cmd, pushd, pushenv, read_file};\n \n-use crate::{cargo_files, codegen, project_root, rust_files};\n-\n-#[test]\n-fn generate_grammar() {\n-    codegen::generate_syntax().unwrap()\n-}\n-\n-#[test]\n-fn generate_parser_tests() {\n-    codegen::generate_parser_tests().unwrap()\n-}\n-\n-#[test]\n-fn generate_assists_tests() {\n-    codegen::generate_assists_tests().unwrap();\n-}\n-\n-/// This clones rustc repo, and so is not worth to keep up-to-date. We update\n-/// manually by un-ignoring the test from time to time.\n-#[test]\n-#[ignore]\n-fn generate_lint_completions() {\n-    codegen::generate_lint_completions().unwrap()\n-}\n+use crate::project_root;\n \n #[test]\n fn check_code_formatting() {\n     let _dir = pushd(project_root()).unwrap();\n     let _e = pushenv(\"RUSTUP_TOOLCHAIN\", \"stable\");\n-    crate::ensure_rustfmt().unwrap();\n+\n+    let out = cmd!(\"rustfmt --version\").read().unwrap();\n+    if !out.contains(\"stable\") {\n+        panic!(\n+            \"Failed to run rustfmt from toolchain 'stable'. \\\n+                 Please run `rustup component add rustfmt --toolchain stable` to install it.\",\n+        )\n+    }\n+\n     let res = cmd!(\"cargo fmt -- --check\").run();\n     if res.is_err() {\n         let _ = cmd!(\"cargo fmt\").run();\n     }\n     res.unwrap()\n }\n \n-#[test]\n-fn smoke_test_generate_documentation() {\n-    codegen::docs().unwrap()\n-}\n-\n #[test]\n fn check_lsp_extensions_docs() {\n     let expected_hash = {\n@@ -344,6 +325,8 @@ fn check_test_attrs(path: &Path, text: &str) {\n         // A legit test which needs to be ignored, as it takes too long to run\n         // :(\n         \"hir_def/src/nameres/collector.rs\",\n+        // Long sourcegen test to generate lint completions.\n+        \"ide_completion/src/tests/sourcegen.rs\",\n         // Obviously needs ignore.\n         \"ide_assists/src/handlers/toggle_ignore.rs\",\n         // See above.\n@@ -498,3 +481,31 @@ fn find_mark<'a>(text: &'a str, mark: &'static str) -> Option<&'a str> {\n     let text = &text[..idx];\n     Some(text)\n }\n+\n+fn rust_files() -> impl Iterator<Item = PathBuf> {\n+    rust_files_in(&project_root().join(\"crates\"))\n+}\n+\n+fn cargo_files() -> impl Iterator<Item = PathBuf> {\n+    files_in(&project_root(), \"toml\")\n+        .filter(|path| path.file_name().map(|it| it == \"Cargo.toml\").unwrap_or(false))\n+}\n+\n+fn rust_files_in(path: &Path) -> impl Iterator<Item = PathBuf> {\n+    files_in(path, \"rs\")\n+}\n+\n+fn files_in(path: &Path, ext: &'static str) -> impl Iterator<Item = PathBuf> {\n+    let iter = WalkDir::new(path);\n+    return iter\n+        .into_iter()\n+        .filter_entry(|e| !is_hidden(e))\n+        .map(|e| e.unwrap())\n+        .filter(|e| !e.file_type().is_dir())\n+        .map(|e| e.into_path())\n+        .filter(move |path| path.extension().map(|it| it == ext).unwrap_or(false));\n+\n+    fn is_hidden(entry: &DirEntry) -> bool {\n+        entry.file_name().to_str().map(|s| s.starts_with('.')).unwrap_or(false)\n+    }\n+}"}]}