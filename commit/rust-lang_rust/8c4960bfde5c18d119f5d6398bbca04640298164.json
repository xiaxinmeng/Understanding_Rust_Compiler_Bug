{"sha": "8c4960bfde5c18d119f5d6398bbca04640298164", "node_id": "MDY6Q29tbWl0NzI0NzEyOjhjNDk2MGJmZGU1YzE4ZDExOWY1ZDYzOThiYmNhMDQ2NDAyOTgxNjQ=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-27T13:21:20Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-02-28T22:13:38Z"}, "message": "Remove `ext::tt::transcribe::tt_next_token`.", "tree": {"sha": "90f9dc5440e05630df0041fe7adbb2b3ddc16ed8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/90f9dc5440e05630df0041fe7adbb2b3ddc16ed8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8c4960bfde5c18d119f5d6398bbca04640298164", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8c4960bfde5c18d119f5d6398bbca04640298164", "html_url": "https://github.com/rust-lang/rust/commit/8c4960bfde5c18d119f5d6398bbca04640298164", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8c4960bfde5c18d119f5d6398bbca04640298164/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "abdc68973ea5961c3e942c7176c2894d00c547d7", "url": "https://api.github.com/repos/rust-lang/rust/commits/abdc68973ea5961c3e942c7176c2894d00c547d7", "html_url": "https://github.com/rust-lang/rust/commit/abdc68973ea5961c3e942c7176c2894d00c547d7"}], "stats": {"total": 273, "additions": 124, "deletions": 149}, "files": [{"sha": "fce89d06216ebc1eba8832e381069bc28195f050", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 124, "deletions": 149, "changes": 273, "blob_url": "https://github.com/rust-lang/rust/blob/8c4960bfde5c18d119f5d6398bbca04640298164/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8c4960bfde5c18d119f5d6398bbca04640298164/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=8c4960bfde5c18d119f5d6398bbca04640298164", "patch": "@@ -7,7 +7,6 @@\n // <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n-use self::LockstepIterSize::*;\n \n use ast::Ident;\n use errors::Handler;\n@@ -41,6 +40,13 @@ enum Frame {\n     },\n }\n \n+impl Frame {\n+    fn new(tts: Vec<TokenTree>) -> Frame {\n+        let forest = Rc::new(tokenstream::Delimited { delim: token::NoDelim, tts: tts });\n+        Frame::Delimited { forest: forest, idx: 0, span: DUMMY_SP }\n+    }\n+}\n+\n impl Iterator for Frame {\n     type Item = TokenTree;\n \n@@ -75,143 +81,42 @@ impl Iterator for Frame {\n     }\n }\n \n-struct TtReader<'a> {\n-    sp_diag: &'a Handler,\n-    /// the unzipped tree:\n-    stack: SmallVector<Frame>,\n-    /* for MBE-style macro transcription */\n-    interpolations: HashMap<Ident, Rc<NamedMatch>>,\n-\n-    repeat_idx: Vec<usize>,\n-    repeat_len: Vec<usize>,\n-}\n-\n /// This can do Macro-By-Example transcription. On the other hand, if\n /// `src` contains no `TokenTree::Sequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n /// (and should) be None.\n pub fn transcribe(sp_diag: &Handler,\n                   interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n                   src: Vec<tokenstream::TokenTree>)\n                   -> Vec<TokenTree> {\n-    let mut r = TtReader {\n-        sp_diag: sp_diag,\n-        stack: SmallVector::one(Frame::Delimited {\n-            forest: Rc::new(tokenstream::Delimited { delim: token::NoDelim, tts: src }),\n-            idx: 0,\n-            span: DUMMY_SP,\n-        }),\n-        interpolations: match interp { /* just a convenience */\n-            None => HashMap::new(),\n-            Some(x) => x,\n-        },\n-        repeat_idx: Vec::new(),\n-        repeat_len: Vec::new(),\n-    };\n-\n-    let mut tts = Vec::new();\n-    let mut prev_span = DUMMY_SP;\n-    while let Some(tt) = tt_next_token(&mut r, prev_span) {\n-        prev_span = tt.span();\n-        tts.push(tt);\n-    }\n-    tts\n-}\n-\n-fn lookup_cur_matched_by_matched(r: &TtReader, start: Rc<NamedMatch>) -> Rc<NamedMatch> {\n-    r.repeat_idx.iter().fold(start, |ad, idx| {\n-        match *ad {\n-            MatchedNonterminal(_) => {\n-                // end of the line; duplicate henceforth\n-                ad.clone()\n-            }\n-            MatchedSeq(ref ads, _) => ads[*idx].clone()\n-        }\n-    })\n-}\n-\n-fn lookup_cur_matched(r: &TtReader, name: Ident) -> Option<Rc<NamedMatch>> {\n-    let matched_opt = r.interpolations.get(&name).cloned();\n-    matched_opt.map(|s| lookup_cur_matched_by_matched(r, s))\n-}\n-\n-#[derive(Clone)]\n-enum LockstepIterSize {\n-    LisUnconstrained,\n-    LisConstraint(usize, Ident),\n-    LisContradiction(String),\n-}\n+    let mut stack = SmallVector::one(Frame::new(src));\n+    let interpolations = interp.unwrap_or_else(HashMap::new); /* just a convenience */\n+    let mut repeat_idx = Vec::new();\n+    let mut repeat_len = Vec::new();\n+    let mut result = Vec::new();\n \n-impl Add for LockstepIterSize {\n-    type Output = LockstepIterSize;\n-\n-    fn add(self, other: LockstepIterSize) -> LockstepIterSize {\n-        match self {\n-            LisUnconstrained => other,\n-            LisContradiction(_) => self,\n-            LisConstraint(l_len, ref l_id) => match other {\n-                LisUnconstrained => self.clone(),\n-                LisContradiction(_) => other,\n-                LisConstraint(r_len, _) if l_len == r_len => self.clone(),\n-                LisConstraint(r_len, r_id) => {\n-                    LisContradiction(format!(\"inconsistent lockstep iteration: \\\n-                                              '{}' has {} items, but '{}' has {}\",\n-                                              l_id, l_len, r_id, r_len))\n-                }\n-            },\n-        }\n-    }\n-}\n-\n-fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n-    match *t {\n-        TokenTree::Delimited(_, ref delimed) => {\n-            delimed.tts.iter().fold(LisUnconstrained, |size, tt| {\n-                size + lockstep_iter_size(tt, r)\n-            })\n-        },\n-        TokenTree::Sequence(_, ref seq) => {\n-            seq.tts.iter().fold(LisUnconstrained, |size, tt| {\n-                size + lockstep_iter_size(tt, r)\n-            })\n-        },\n-        TokenTree::Token(_, SubstNt(name)) | TokenTree::Token(_, MatchNt(name, _)) =>\n-            match lookup_cur_matched(r, name) {\n-                Some(matched) => match *matched {\n-                    MatchedNonterminal(_) => LisUnconstrained,\n-                    MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name),\n-                },\n-                _ => LisUnconstrained\n-            },\n-        TokenTree::Token(..) => LisUnconstrained,\n-    }\n-}\n-\n-/// Return the next token from the TtReader.\n-/// EFFECT: advances the reader's token field\n-fn tt_next_token(r: &mut TtReader, prev_span: Span) -> Option<TokenTree> {\n     loop {\n-        let tree = match r.stack.last_mut() {\n-            Some(frame) => frame.next(),\n-            None => return None,\n-        };\n-\n-        let tree = if let Some(tree) = tree {\n+        let tree = if let Some(tree) = stack.last_mut().unwrap().next() {\n             tree\n         } else {\n-            if let Frame::Sequence { ref mut idx, ref sep, .. } = *r.stack.last_mut().unwrap() {\n-                if *r.repeat_idx.last().unwrap() < *r.repeat_len.last().unwrap() - 1 {\n-                    *r.repeat_idx.last_mut().unwrap() += 1;\n+            if let Frame::Sequence { ref mut idx, ref sep, .. } = *stack.last_mut().unwrap() {\n+                if *repeat_idx.last().unwrap() < *repeat_len.last().unwrap() - 1 {\n+                    *repeat_idx.last_mut().unwrap() += 1;\n                     *idx = 0;\n                     if let Some(sep) = sep.clone() {\n-                        return Some(TokenTree::Token(prev_span, sep)); // repeat same span, I guess\n+                        // repeat same span, I guess\n+                        let prev_span = result.last().map(TokenTree::span).unwrap_or(DUMMY_SP);\n+                        result.push(TokenTree::Token(prev_span, sep));\n                     }\n                     continue\n                 }\n             }\n \n-            if let Frame::Sequence { .. } = r.stack.pop().unwrap() {\n-                r.repeat_idx.pop();\n-                r.repeat_len.pop();\n+            if let Frame::Sequence { .. } = stack.pop().unwrap() {\n+                repeat_idx.pop();\n+                repeat_len.pop();\n+            }\n+            if stack.is_empty() {\n+                return result;\n             }\n             continue\n         };\n@@ -220,73 +125,143 @@ fn tt_next_token(r: &mut TtReader, prev_span: Span) -> Option<TokenTree> {\n             TokenTree::Sequence(sp, seq) => {\n                 // FIXME(pcwalton): Bad copy.\n                 match lockstep_iter_size(&TokenTree::Sequence(sp, seq.clone()),\n-                                         r) {\n-                    LisUnconstrained => {\n-                        panic!(r.sp_diag.span_fatal(\n+                                         &interpolations,\n+                                         &repeat_idx) {\n+                    LockstepIterSize::Unconstrained => {\n+                        panic!(sp_diag.span_fatal(\n                             sp.clone(), /* blame macro writer */\n                             \"attempted to repeat an expression \\\n                              containing no syntax \\\n                              variables matched as repeating at this depth\"));\n                     }\n-                    LisContradiction(ref msg) => {\n+                    LockstepIterSize::Contradiction(ref msg) => {\n                         // FIXME #2887 blame macro invoker instead\n-                        panic!(r.sp_diag.span_fatal(sp.clone(), &msg[..]));\n+                        panic!(sp_diag.span_fatal(sp.clone(), &msg[..]));\n                     }\n-                    LisConstraint(len, _) => {\n+                    LockstepIterSize::Constraint(len, _) => {\n                         if len == 0 {\n                             if seq.op == tokenstream::KleeneOp::OneOrMore {\n                                 // FIXME #2887 blame invoker\n-                                panic!(r.sp_diag.span_fatal(sp.clone(),\n-                                                     \"this must repeat at least once\"));\n+                                panic!(sp_diag.span_fatal(sp.clone(),\n+                                                          \"this must repeat at least once\"));\n                             }\n-\n-                            return tt_next_token(r, prev_span);\n+                        } else {\n+                            repeat_len.push(len);\n+                            repeat_idx.push(0);\n+                            stack.push(Frame::Sequence {\n+                                idx: 0,\n+                                sep: seq.separator.clone(),\n+                                forest: seq,\n+                            });\n                         }\n-                        r.repeat_len.push(len);\n-                        r.repeat_idx.push(0);\n-                        r.stack.push(Frame::Sequence {\n-                            idx: 0,\n-                            sep: seq.separator.clone(),\n-                            forest: seq,\n-                        });\n                     }\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n             TokenTree::Token(sp, SubstNt(ident)) => {\n-                match lookup_cur_matched(r, ident) {\n-                    None => {\n-                        return Some(TokenTree::Token(sp, SubstNt(ident)));\n-                        // this can't be 0 length, just like TokenTree::Delimited\n-                    }\n+                match lookup_cur_matched(ident, &interpolations, &repeat_idx) {\n+                    None => result.push(TokenTree::Token(sp, SubstNt(ident))),\n                     Some(cur_matched) => if let MatchedNonterminal(ref nt) = *cur_matched {\n                         match **nt {\n                             // sidestep the interpolation tricks for ident because\n                             // (a) idents can be in lots of places, so it'd be a pain\n                             // (b) we actually can, since it's a token.\n                             NtIdent(ref sn) => {\n-                                return Some(TokenTree::Token(sn.span, token::Ident(sn.node)));\n+                                result.push(TokenTree::Token(sn.span, token::Ident(sn.node)));\n                             }\n-                            NtTT(ref tt) => return Some(tt.clone()),\n+                            NtTT(ref tt) => result.push(tt.clone()),\n                             _ => {\n                                 // FIXME(pcwalton): Bad copy\n-                                return Some(TokenTree::Token(sp, token::Interpolated(nt.clone())));\n+                                result.push(TokenTree::Token(sp, token::Interpolated(nt.clone())));\n                             }\n                         }\n                     } else {\n-                        panic!(r.sp_diag.span_fatal(\n+                        panic!(sp_diag.span_fatal(\n                             sp, /* blame the macro writer */\n                             &format!(\"variable '{}' is still repeating at this depth\", ident)));\n                     }\n                 }\n             }\n             TokenTree::Delimited(span, delimited) => {\n-                r.stack.push(Frame::Delimited { forest: delimited, idx: 0, span: span });\n+                stack.push(Frame::Delimited { forest: delimited, idx: 0, span: span });\n             }\n             TokenTree::Token(span, MatchNt(name, kind)) => {\n-                r.stack.push(Frame::MatchNt { name: name, kind: kind, idx: 0, span: span });\n+                stack.push(Frame::MatchNt { name: name, kind: kind, idx: 0, span: span });\n             }\n-            tt @ TokenTree::Token(..) => return Some(tt),\n+            tt @ TokenTree::Token(..) => result.push(tt),\n         }\n     }\n }\n+\n+fn lookup_cur_matched(ident: Ident,\n+                      interpolations: &HashMap<Ident, Rc<NamedMatch>>,\n+                      repeat_idx: &[usize])\n+                      -> Option<Rc<NamedMatch>> {\n+    interpolations.get(&ident).map(|matched| {\n+        repeat_idx.iter().fold(matched.clone(), |ad, idx| {\n+            match *ad {\n+                MatchedNonterminal(_) => {\n+                    // end of the line; duplicate henceforth\n+                    ad.clone()\n+                }\n+                MatchedSeq(ref ads, _) => ads[*idx].clone()\n+            }\n+        })\n+    })\n+}\n+\n+#[derive(Clone)]\n+enum LockstepIterSize {\n+    Unconstrained,\n+    Constraint(usize, Ident),\n+    Contradiction(String),\n+}\n+\n+impl Add for LockstepIterSize {\n+    type Output = LockstepIterSize;\n+\n+    fn add(self, other: LockstepIterSize) -> LockstepIterSize {\n+        match self {\n+            LockstepIterSize::Unconstrained => other,\n+            LockstepIterSize::Contradiction(_) => self,\n+            LockstepIterSize::Constraint(l_len, ref l_id) => match other {\n+                LockstepIterSize::Unconstrained => self.clone(),\n+                LockstepIterSize::Contradiction(_) => other,\n+                LockstepIterSize::Constraint(r_len, _) if l_len == r_len => self.clone(),\n+                LockstepIterSize::Constraint(r_len, r_id) => {\n+                    let msg = format!(\"inconsistent lockstep iteration: \\\n+                                       '{}' has {} items, but '{}' has {}\",\n+                                      l_id, l_len, r_id, r_len);\n+                    LockstepIterSize::Contradiction(msg)\n+                }\n+            },\n+        }\n+    }\n+}\n+\n+fn lockstep_iter_size(tree: &TokenTree,\n+                      interpolations: &HashMap<Ident, Rc<NamedMatch>>,\n+                      repeat_idx: &[usize])\n+                      -> LockstepIterSize {\n+    match *tree {\n+        TokenTree::Delimited(_, ref delimed) => {\n+            delimed.tts.iter().fold(LockstepIterSize::Unconstrained, |size, tt| {\n+                size + lockstep_iter_size(tt, interpolations, repeat_idx)\n+            })\n+        },\n+        TokenTree::Sequence(_, ref seq) => {\n+            seq.tts.iter().fold(LockstepIterSize::Unconstrained, |size, tt| {\n+                size + lockstep_iter_size(tt, interpolations, repeat_idx)\n+            })\n+        },\n+        TokenTree::Token(_, SubstNt(name)) | TokenTree::Token(_, MatchNt(name, _)) =>\n+            match lookup_cur_matched(name, interpolations, repeat_idx) {\n+                Some(matched) => match *matched {\n+                    MatchedNonterminal(_) => LockstepIterSize::Unconstrained,\n+                    MatchedSeq(ref ads, _) => LockstepIterSize::Constraint(ads.len(), name),\n+                },\n+                _ => LockstepIterSize::Unconstrained\n+            },\n+        TokenTree::Token(..) => LockstepIterSize::Unconstrained,\n+    }\n+}"}]}