{"sha": "8aef340b8b0658e34b54fdea59e5ffc5ec581106", "node_id": "C_kwDOAAsO6NoAKDhhZWYzNDBiOGIwNjU4ZTM0YjU0ZmRlYTU5ZTVmZmM1ZWM1ODExMDY", "commit": {"author": {"name": "Jubilee Young", "email": "workingjubilee@gmail.com", "date": "2021-12-09T01:23:54Z"}, "committer": {"name": "Jubilee Young", "email": "workingjubilee@gmail.com", "date": "2021-12-09T02:09:32Z"}, "message": "Refactor bitops with `#[must_use]`", "tree": {"sha": "94efa61f1ca6074cc24153a96564a1517435ed47", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/94efa61f1ca6074cc24153a96564a1517435ed47"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8aef340b8b0658e34b54fdea59e5ffc5ec581106", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8aef340b8b0658e34b54fdea59e5ffc5ec581106", "html_url": "https://github.com/rust-lang/rust/commit/8aef340b8b0658e34b54fdea59e5ffc5ec581106", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8aef340b8b0658e34b54fdea59e5ffc5ec581106/comments", "author": {"login": "workingjubilee", "id": 46493976, "node_id": "MDQ6VXNlcjQ2NDkzOTc2", "avatar_url": "https://avatars.githubusercontent.com/u/46493976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/workingjubilee", "html_url": "https://github.com/workingjubilee", "followers_url": "https://api.github.com/users/workingjubilee/followers", "following_url": "https://api.github.com/users/workingjubilee/following{/other_user}", "gists_url": "https://api.github.com/users/workingjubilee/gists{/gist_id}", "starred_url": "https://api.github.com/users/workingjubilee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/workingjubilee/subscriptions", "organizations_url": "https://api.github.com/users/workingjubilee/orgs", "repos_url": "https://api.github.com/users/workingjubilee/repos", "events_url": "https://api.github.com/users/workingjubilee/events{/privacy}", "received_events_url": "https://api.github.com/users/workingjubilee/received_events", "type": "User", "site_admin": false}, "committer": {"login": "workingjubilee", "id": 46493976, "node_id": "MDQ6VXNlcjQ2NDkzOTc2", "avatar_url": "https://avatars.githubusercontent.com/u/46493976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/workingjubilee", "html_url": "https://github.com/workingjubilee", "followers_url": "https://api.github.com/users/workingjubilee/followers", "following_url": "https://api.github.com/users/workingjubilee/following{/other_user}", "gists_url": "https://api.github.com/users/workingjubilee/gists{/gist_id}", "starred_url": "https://api.github.com/users/workingjubilee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/workingjubilee/subscriptions", "organizations_url": "https://api.github.com/users/workingjubilee/orgs", "repos_url": "https://api.github.com/users/workingjubilee/repos", "events_url": "https://api.github.com/users/workingjubilee/events{/privacy}", "received_events_url": "https://api.github.com/users/workingjubilee/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b6d0eec3de0ac75ce81784251b4648a1cef7f628", "url": "https://api.github.com/repos/rust-lang/rust/commits/b6d0eec3de0ac75ce81784251b4648a1cef7f628", "html_url": "https://github.com/rust-lang/rust/commit/b6d0eec3de0ac75ce81784251b4648a1cef7f628"}], "stats": {"total": 131, "additions": 98, "deletions": 33}, "files": [{"sha": "5e775d6ca138b6634fc761593cf25d02ef82048a", "filename": "crates/core_simd/src/ops.rs", "status": "modified", "additions": 98, "deletions": 33, "changes": 131, "blob_url": "https://github.com/rust-lang/rust/blob/8aef340b8b0658e34b54fdea59e5ffc5ec581106/crates%2Fcore_simd%2Fsrc%2Fops.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8aef340b8b0658e34b54fdea59e5ffc5ec581106/crates%2Fcore_simd%2Fsrc%2Fops.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Fops.rs?ref=8aef340b8b0658e34b54fdea59e5ffc5ec581106", "patch": "@@ -32,6 +32,29 @@ where\n     }\n }\n \n+macro_rules! unsafe_base_op {\n+    ($(impl<const LANES: usize> $op:ident for Simd<$scalar:ty, LANES> {\n+        fn $call:ident(self, rhs: Self) -> Self::Output {\n+            unsafe{ $simd_call:ident }\n+        }\n+    })*) => {\n+        $(impl<const LANES: usize> $op for Simd<$scalar, LANES>\n+            where\n+                $scalar: SimdElement,\n+                LaneCount<LANES>: SupportedLaneCount,\n+            {\n+                type Output = Self;\n+\n+                #[inline]\n+                #[must_use = \"operator returns a new vector without mutating the inputs\"]\n+                fn $call(self, rhs: Self) -> Self::Output {\n+                    unsafe { $crate::intrinsics::$simd_call(self, rhs) }\n+                }\n+            }\n+        )*\n+    }\n+}\n+\n /// SAFETY: This macro should not be used for anything except Shl or Shr, and passed the appropriate shift intrinsic.\n /// It handles performing a bitand in addition to calling the shift operator, so that the result\n /// is well-defined: LLVM can return a poison value if you shl, lshr, or ashr if rhs >= <Int>::BITS\n@@ -41,13 +64,13 @@ where\n ///\n // FIXME: Consider implementing this in cg_llvm instead?\n // cg_clif defaults to this, and scalar MIR shifts also default to wrapping\n-macro_rules! wrap_bitshift_inner {\n-    (impl<const LANES: usize> $op:ident for Simd<$int:ty, LANES> {\n+macro_rules! wrap_bitshift {\n+    ($(impl<const LANES: usize> $op:ident for Simd<$int:ty, LANES> {\n         fn $call:ident(self, rhs: Self) -> Self::Output {\n             unsafe { $simd_call:ident }\n         }\n-    }) => {\n-        impl<const LANES: usize> $op for Simd<$int, LANES>\n+    })*) => {\n+        $(impl<const LANES: usize> $op for Simd<$int, LANES>\n         where\n             $int: SimdElement,\n             LaneCount<LANES>: SupportedLaneCount,\n@@ -61,24 +84,45 @@ macro_rules! wrap_bitshift_inner {\n                     $crate::intrinsics::$simd_call(self, rhs.bitand(Simd::splat(<$int>::BITS as $int - 1)))\n                 }\n             }\n-        }\n+        })*\n     };\n }\n \n-macro_rules! wrap_bitshifts {\n-    ($(impl<const LANES: usize> ShiftOps for Simd<$int:ty, LANES> {\n+macro_rules! bitops {\n+    ($(impl<const LANES: usize> BitOps for Simd<$int:ty, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n      })*) => {\n         $(\n-            wrap_bitshift_inner! {\n+            unsafe_base_op!{\n+                impl<const LANES: usize> BitAnd for Simd<$int, LANES> {\n+                    fn bitand(self, rhs: Self) -> Self::Output {\n+                        unsafe { simd_and }\n+                    }\n+                }\n+\n+                impl<const LANES: usize> BitOr for Simd<$int, LANES> {\n+                    fn bitor(self, rhs: Self) -> Self::Output {\n+                        unsafe { simd_or }\n+                    }\n+                }\n+\n+                impl<const LANES: usize> BitXor for Simd<$int, LANES> {\n+                    fn bitxor(self, rhs: Self) -> Self::Output {\n+                        unsafe { simd_xor }\n+                    }\n+                }\n+            }\n+            wrap_bitshift! {\n                 impl<const LANES: usize> Shl for Simd<$int, LANES> {\n                     fn shl(self, rhs: Self) -> Self::Output {\n                         unsafe { simd_shl }\n                     }\n                 }\n-            }\n-            wrap_bitshift_inner! {\n+\n                 impl<const LANES: usize> Shr for Simd<$int, LANES> {\n                     fn shr(self, rhs: Self) -> Self::Output {\n                         // This automatically monomorphizes to lshr or ashr, depending,\n@@ -91,53 +135,86 @@ macro_rules! wrap_bitshifts {\n     };\n }\n \n-wrap_bitshifts! {\n-    impl<const LANES: usize> ShiftOps for Simd<i8, LANES> {\n+// Integers can always accept bitand, bitor, and bitxor.\n+// The only question is how to handle shifts >= <Int>::BITS?\n+// Our current solution uses wrapping logic.\n+bitops! {\n+    impl<const LANES: usize> BitOps for Simd<i8, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<i16, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<i16, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<i32, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<i32, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<i64, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<i64, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<isize, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<isize, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<u8, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<u8, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<u16, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<u16, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<u32, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<u32, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<u64, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<u64, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n \n-    impl<const LANES: usize> ShiftOps for Simd<usize, LANES> {\n+    impl<const LANES: usize> BitOps for Simd<usize, LANES> {\n+        fn bitand(self, rhs: Self) -> Self::Output;\n+        fn bitor(self, rhs: Self) -> Self::Output;\n+        fn bitxor(self, rhs: Self) -> Self::Output;\n         fn shl(self, rhs: Self) -> Self::Output;\n         fn shr(self, rhs: Self) -> Self::Output;\n     }\n@@ -186,15 +263,6 @@ macro_rules! impl_op {\n     { impl Rem for $scalar:ty } => {\n         impl_op! { @binary $scalar, Rem::rem, simd_rem }\n     };\n-    { impl BitAnd for $scalar:ty } => {\n-        impl_op! { @binary $scalar, BitAnd::bitand, simd_and }\n-    };\n-    { impl BitOr for $scalar:ty } => {\n-        impl_op! { @binary $scalar, BitOr::bitor, simd_or }\n-    };\n-    { impl BitXor for $scalar:ty } => {\n-        impl_op! { @binary $scalar, BitXor::bitxor, simd_xor }\n-    };\n \n     // generic binary op with assignment when output is `Self`\n     { @binary $scalar:ty, $trait:ident :: $trait_fn:ident, $intrinsic:ident } => {\n@@ -236,9 +304,6 @@ macro_rules! impl_unsigned_int_ops {\n             impl_op! { impl Add for $scalar }\n             impl_op! { impl Sub for $scalar }\n             impl_op! { impl Mul for $scalar }\n-            impl_op! { impl BitAnd for $scalar }\n-            impl_op! { impl BitOr  for $scalar }\n-            impl_op! { impl BitXor for $scalar }\n \n             // Integers panic on divide by 0\n             impl_ref_ops! {"}]}