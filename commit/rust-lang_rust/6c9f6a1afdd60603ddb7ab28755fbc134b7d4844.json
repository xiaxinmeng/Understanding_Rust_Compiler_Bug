{"sha": "6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZjOWY2YTFhZmRkNjA2MDNkZGI3YWIyODc1NWZiYzEzNGI3ZDQ4NDQ=", "commit": {"author": {"name": "David Lavati", "email": "david.lavati@gmail.com", "date": "2018-10-29T20:26:13Z"}, "committer": {"name": "David Lavati", "email": "david.lavati@gmail.com", "date": "2018-10-29T20:26:13Z"}, "message": "Rename other occs of (Code/File)Map to Source(Map/File) #51574", "tree": {"sha": "0214e66ce78d708630935fe8e00dfa01d2cdaa8a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0214e66ce78d708630935fe8e00dfa01d2cdaa8a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "html_url": "https://github.com/rust-lang/rust/commit/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/comments", "author": {"login": "dlavati", "id": 9315596, "node_id": "MDQ6VXNlcjkzMTU1OTY=", "avatar_url": "https://avatars.githubusercontent.com/u/9315596?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dlavati", "html_url": "https://github.com/dlavati", "followers_url": "https://api.github.com/users/dlavati/followers", "following_url": "https://api.github.com/users/dlavati/following{/other_user}", "gists_url": "https://api.github.com/users/dlavati/gists{/gist_id}", "starred_url": "https://api.github.com/users/dlavati/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dlavati/subscriptions", "organizations_url": "https://api.github.com/users/dlavati/orgs", "repos_url": "https://api.github.com/users/dlavati/repos", "events_url": "https://api.github.com/users/dlavati/events{/privacy}", "received_events_url": "https://api.github.com/users/dlavati/received_events", "type": "User", "site_admin": false}, "committer": {"login": "dlavati", "id": 9315596, "node_id": "MDQ6VXNlcjkzMTU1OTY=", "avatar_url": "https://avatars.githubusercontent.com/u/9315596?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dlavati", "html_url": "https://github.com/dlavati", "followers_url": "https://api.github.com/users/dlavati/followers", "following_url": "https://api.github.com/users/dlavati/following{/other_user}", "gists_url": "https://api.github.com/users/dlavati/gists{/gist_id}", "starred_url": "https://api.github.com/users/dlavati/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dlavati/subscriptions", "organizations_url": "https://api.github.com/users/dlavati/orgs", "repos_url": "https://api.github.com/users/dlavati/repos", "events_url": "https://api.github.com/users/dlavati/events{/privacy}", "received_events_url": "https://api.github.com/users/dlavati/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d586d5d2f51489821b471f20959333558c24b129", "url": "https://api.github.com/repos/rust-lang/rust/commits/d586d5d2f51489821b471f20959333558c24b129", "html_url": "https://github.com/rust-lang/rust/commit/d586d5d2f51489821b471f20959333558c24b129"}], "stats": {"total": 419, "additions": 210, "deletions": 209}, "files": [{"sha": "fbf4297222f9bd9109374f432b1cd5f25a744b34", "filename": "src/librustc/ich/caching_source_map_view.rs", "status": "renamed", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc%2Fich%2Fcaching_source_map_view.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc%2Fich%2Fcaching_source_map_view.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fcaching_source_map_view.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "previous_filename": "src/librustc/ich/caching_codemap_view.rs"}, {"sha": "9751c560acd1e0535a4aa057b945bfc27188a974", "filename": "src/librustc/ich/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc%2Fich%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc%2Fich%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fmod.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -11,10 +11,10 @@\n //! ICH - Incremental Compilation Hash\n \n crate use rustc_data_structures::fingerprint::Fingerprint;\n-pub use self::caching_codemap_view::CachingSourceMapView;\n+pub use self::caching_source_map_view::CachingSourceMapView;\n pub use self::hcx::{StableHashingContextProvider, StableHashingContext, NodeIdHashingMode,\n                     hash_stable_trait_impls};\n-mod caching_codemap_view;\n+mod caching_source_map_view;\n mod hcx;\n \n mod impls_cstore;"}, {"sha": "d6f75318551226ad871004a972e831bfa4b88db2", "filename": "src/librustc/ty/query/on_disk_cache.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -25,7 +25,7 @@ use rustc_serialize::{Decodable, Decoder, Encodable, Encoder, opaque,\n use session::{CrateDisambiguator, Session};\n use std::mem;\n use syntax::ast::NodeId;\n-use syntax::source_map::{SourceMap, StableFilemapId};\n+use syntax::source_map::{SourceMap, StableSourceFileId};\n use syntax_pos::{BytePos, Span, DUMMY_SP, SourceFile};\n use syntax_pos::hygiene::{Mark, SyntaxContext, ExpnInfo};\n use ty;\n@@ -62,7 +62,7 @@ pub struct OnDiskCache<'sess> {\n     cnum_map: Once<IndexVec<CrateNum, Option<CrateNum>>>,\n \n     source_map: &'sess SourceMap,\n-    file_index_to_stable_id: FxHashMap<SourceFileIndex, StableFilemapId>,\n+    file_index_to_stable_id: FxHashMap<SourceFileIndex, StableSourceFileId>,\n \n     // These two fields caches that are populated lazily during decoding.\n     file_index_to_file: Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n@@ -82,7 +82,7 @@ pub struct OnDiskCache<'sess> {\n // This type is used only for (de-)serialization.\n #[derive(RustcEncodable, RustcDecodable)]\n struct Footer {\n-    file_index_to_stable_id: FxHashMap<SourceFileIndex, StableFilemapId>,\n+    file_index_to_stable_id: FxHashMap<SourceFileIndex, StableSourceFileId>,\n     prev_cnums: Vec<(u32, String, CrateDisambiguator)>,\n     query_result_index: EncodedQueryResultIndex,\n     diagnostics_index: EncodedQueryResultIndex,\n@@ -181,7 +181,7 @@ impl<'sess> OnDiskCache<'sess> {\n                     let index = SourceFileIndex(index as u32);\n                     let file_ptr: *const SourceFile = &**file as *const _;\n                     file_to_file_index.insert(file_ptr, index);\n-                    file_index_to_stable_id.insert(index, StableFilemapId::new(&file));\n+                    file_index_to_stable_id.insert(index, StableSourceFileId::new(&file));\n                 }\n \n                 (file_to_file_index, file_index_to_stable_id)\n@@ -473,7 +473,7 @@ struct CacheDecoder<'a, 'tcx: 'a, 'x> {\n     cnum_map: &'x IndexVec<CrateNum, Option<CrateNum>>,\n     synthetic_expansion_infos: &'x Lock<FxHashMap<AbsoluteBytePos, SyntaxContext>>,\n     file_index_to_file: &'x Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n-    file_index_to_stable_id: &'x FxHashMap<SourceFileIndex, StableFilemapId>,\n+    file_index_to_stable_id: &'x FxHashMap<SourceFileIndex, StableSourceFileId>,\n     alloc_decoding_session: AllocDecodingSession<'x>,\n }\n "}, {"sha": "720e8def5ab1c2a7d30abec1e97e67649736e39e", "filename": "src/librustc_errors/emitter.rs", "status": "modified", "additions": 28, "deletions": 28, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc_errors%2Femitter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc_errors%2Femitter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_errors%2Femitter.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -120,7 +120,7 @@ impl ColorConfig {\n \n pub struct EmitterWriter {\n     dst: Destination,\n-    cm: Option<Lrc<SourceMapperDyn>>,\n+    sm: Option<Lrc<SourceMapperDyn>>,\n     short_message: bool,\n     teach: bool,\n     ui_testing: bool,\n@@ -134,28 +134,28 @@ struct FileWithAnnotatedLines {\n \n impl EmitterWriter {\n     pub fn stderr(color_config: ColorConfig,\n-                  code_map: Option<Lrc<SourceMapperDyn>>,\n+                  source_map: Option<Lrc<SourceMapperDyn>>,\n                   short_message: bool,\n                   teach: bool)\n                   -> EmitterWriter {\n         let dst = Destination::from_stderr(color_config);\n         EmitterWriter {\n             dst,\n-            cm: code_map,\n+            sm: source_map,\n             short_message,\n             teach,\n             ui_testing: false,\n         }\n     }\n \n     pub fn new(dst: Box<dyn Write + Send>,\n-               code_map: Option<Lrc<SourceMapperDyn>>,\n+               source_map: Option<Lrc<SourceMapperDyn>>,\n                short_message: bool,\n                teach: bool)\n                -> EmitterWriter {\n         EmitterWriter {\n             dst: Raw(dst),\n-            cm: code_map,\n+            sm: source_map,\n             short_message,\n             teach,\n             ui_testing: false,\n@@ -214,14 +214,14 @@ impl EmitterWriter {\n         let mut output = vec![];\n         let mut multiline_annotations = vec![];\n \n-        if let Some(ref cm) = self.cm {\n+        if let Some(ref sm) = self.sm {\n             for span_label in msp.span_labels() {\n                 if span_label.span.is_dummy() {\n                     continue;\n                 }\n \n-                let lo = cm.lookup_char_pos(span_label.span.lo());\n-                let mut hi = cm.lookup_char_pos(span_label.span.hi());\n+                let lo = sm.lookup_char_pos(span_label.span.lo());\n+                let mut hi = sm.lookup_char_pos(span_label.span.hi());\n \n                 // Watch out for \"empty spans\". If we get a span like 6..6, we\n                 // want to just display a `^` at 6, so convert that to\n@@ -724,10 +724,10 @@ impl EmitterWriter {\n \n     fn get_multispan_max_line_num(&mut self, msp: &MultiSpan) -> usize {\n         let mut max = 0;\n-        if let Some(ref cm) = self.cm {\n+        if let Some(ref sm) = self.sm {\n             for primary_span in msp.primary_spans() {\n                 if !primary_span.is_dummy() {\n-                    let hi = cm.lookup_char_pos(primary_span.hi());\n+                    let hi = sm.lookup_char_pos(primary_span.hi());\n                     if hi.line > max {\n                         max = hi.line;\n                     }\n@@ -736,7 +736,7 @@ impl EmitterWriter {\n             if !self.short_message {\n                 for span_label in msp.span_labels() {\n                     if !span_label.span.is_dummy() {\n-                        let hi = cm.lookup_char_pos(span_label.span.hi());\n+                        let hi = sm.lookup_char_pos(span_label.span.hi());\n                         if hi.line > max {\n                             max = hi.line;\n                         }\n@@ -768,7 +768,7 @@ impl EmitterWriter {\n                                    always_backtrace: bool) -> bool {\n         let mut spans_updated = false;\n \n-        if let Some(ref cm) = self.cm {\n+        if let Some(ref sm) = self.sm {\n             let mut before_after: Vec<(Span, Span)> = vec![];\n             let mut new_labels: Vec<(Span, String)> = vec![];\n \n@@ -777,7 +777,7 @@ impl EmitterWriter {\n                 if sp.is_dummy() {\n                     continue;\n                 }\n-                let call_sp = cm.call_span_if_macro(*sp);\n+                let call_sp = sm.call_span_if_macro(*sp);\n                 if call_sp != *sp && !always_backtrace {\n                     before_after.push((*sp, call_sp));\n                 }\n@@ -802,7 +802,7 @@ impl EmitterWriter {\n                                                      })));\n                         }\n                         // Check to make sure we're not in any <*macros>\n-                        if !cm.span_to_filename(def_site).is_macros() &&\n+                        if !sm.span_to_filename(def_site).is_macros() &&\n                            !trace.macro_decl_name.starts_with(\"desugaring of \") &&\n                            !trace.macro_decl_name.starts_with(\"#[\") ||\n                            always_backtrace {\n@@ -829,7 +829,7 @@ impl EmitterWriter {\n                 if sp_label.span.is_dummy() {\n                     continue;\n                 }\n-                if cm.span_to_filename(sp_label.span.clone()).is_macros() &&\n+                if sm.span_to_filename(sp_label.span.clone()).is_macros() &&\n                     !always_backtrace\n                 {\n                     let v = sp_label.span.macro_backtrace();\n@@ -1000,10 +1000,10 @@ impl EmitterWriter {\n         let mut annotated_files = self.preprocess_annotations(msp);\n \n         // Make sure our primary file comes first\n-        let (primary_lo, cm) = if let (Some(cm), Some(ref primary_span)) =\n-            (self.cm.as_ref(), msp.primary_span().as_ref()) {\n+        let (primary_lo, sm) = if let (Some(sm), Some(ref primary_span)) =\n+            (self.sm.as_ref(), msp.primary_span().as_ref()) {\n             if !primary_span.is_dummy() {\n-                (cm.lookup_char_pos(primary_span.lo()), cm)\n+                (sm.lookup_char_pos(primary_span.lo()), sm)\n             } else {\n                 emit_to_destination(&buffer.render(), level, &mut self.dst, self.short_message)?;\n                 return Ok(());\n@@ -1021,7 +1021,7 @@ impl EmitterWriter {\n         // Print out the annotate source lines that correspond with the error\n         for annotated_file in annotated_files {\n             // we can't annotate anything if the source is unavailable.\n-            if !cm.ensure_source_file_source_present(annotated_file.file.clone()) {\n+            if !sm.ensure_source_file_source_present(annotated_file.file.clone()) {\n                 continue;\n             }\n \n@@ -1038,7 +1038,7 @@ impl EmitterWriter {\n                     buffer.append(buffer_msg_line_offset,\n                                   &format!(\"{}:{}:{}\",\n                                            loc.file.name,\n-                                           cm.doctest_offset_line(loc.line),\n+                                           sm.doctest_offset_line(loc.line),\n                                            loc.col.0 + 1),\n                                   Style::LineAndColumn);\n                     for _ in 0..max_line_num_len {\n@@ -1048,7 +1048,7 @@ impl EmitterWriter {\n                     buffer.prepend(0,\n                                    &format!(\"{}:{}:{}: \",\n                                             loc.file.name,\n-                                            cm.doctest_offset_line(loc.line),\n+                                            sm.doctest_offset_line(loc.line),\n                                             loc.col.0 + 1),\n                                    Style::LineAndColumn);\n                 }\n@@ -1069,7 +1069,7 @@ impl EmitterWriter {\n                     };\n                     format!(\"{}:{}{}\",\n                             annotated_file.file.name,\n-                            cm.doctest_offset_line(first_line.line_index),\n+                            sm.doctest_offset_line(first_line.line_index),\n                             col)\n                 } else {\n                     annotated_file.file.name.to_string()\n@@ -1194,7 +1194,7 @@ impl EmitterWriter {\n                                level: &Level,\n                                max_line_num_len: usize)\n                                -> io::Result<()> {\n-        if let Some(ref cm) = self.cm {\n+        if let Some(ref sm) = self.sm {\n             let mut buffer = StyledBuffer::new();\n \n             // Render the suggestion message\n@@ -1210,7 +1210,7 @@ impl EmitterWriter {\n                                Some(Style::HeaderMsg));\n \n             // Render the replacements for each suggestion\n-            let suggestions = suggestion.splice_lines(&**cm);\n+            let suggestions = suggestion.splice_lines(&**sm);\n \n             let mut row_num = 2;\n             for &(ref complete, ref parts) in suggestions.iter().take(MAX_SUGGESTIONS) {\n@@ -1221,11 +1221,11 @@ impl EmitterWriter {\n                     && parts[0].snippet.trim() == complete.trim())\n                     && complete.lines().count() == 1;\n \n-                let lines = cm.span_to_lines(parts[0].span).unwrap();\n+                let lines = sm.span_to_lines(parts[0].span).unwrap();\n \n                 assert!(!lines.lines.is_empty());\n \n-                let line_start = cm.lookup_char_pos(parts[0].span.lo()).line;\n+                let line_start = sm.lookup_char_pos(parts[0].span.lo()).line;\n                 draw_col_separator_no_space(&mut buffer, 1, max_line_num_len + 1);\n                 let mut line_pos = 0;\n                 let mut lines = complete.lines();\n@@ -1250,8 +1250,8 @@ impl EmitterWriter {\n                 if show_underline {\n                     draw_col_separator(&mut buffer, row_num, max_line_num_len + 1);\n                     for part in parts {\n-                        let span_start_pos = cm.lookup_char_pos(part.span.lo()).col_display;\n-                        let span_end_pos = cm.lookup_char_pos(part.span.hi()).col_display;\n+                        let span_start_pos = sm.lookup_char_pos(part.span.lo()).col_display;\n+                        let span_end_pos = sm.lookup_char_pos(part.span.hi()).col_display;\n \n                         // Do not underline the leading...\n                         let start = part.snippet.len()"}, {"sha": "0fb77a7a3ab526a59a5708fd78b51b05b353f40d", "filename": "src/librustc_errors/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc_errors%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibrustc_errors%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_errors%2Flib.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -129,7 +129,7 @@ pub trait SourceMapper {\n     fn span_to_filename(&self, sp: Span) -> FileName;\n     fn merge_spans(&self, sp_lhs: Span, sp_rhs: Span) -> Option<Span>;\n     fn call_span_if_macro(&self, sp: Span) -> Span;\n-    fn ensure_source_file_source_present(&self, file_map: Lrc<SourceFile>) -> bool;\n+    fn ensure_source_file_source_present(&self, source_file: Lrc<SourceFile>) -> bool;\n     fn doctest_offset_line(&self, line: usize) -> usize;\n }\n "}, {"sha": "a32682967c7409de4d28874a3dd1d9aabff8796e", "filename": "src/libsyntax/json.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fjson.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fjson.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fjson.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -36,19 +36,19 @@ use rustc_serialize::json::{as_json, as_pretty_json};\n pub struct JsonEmitter {\n     dst: Box<dyn Write + Send>,\n     registry: Option<Registry>,\n-    cm: Lrc<dyn SourceMapper + sync::Send + sync::Sync>,\n+    sm: Lrc<dyn SourceMapper + sync::Send + sync::Sync>,\n     pretty: bool,\n     ui_testing: bool,\n }\n \n impl JsonEmitter {\n     pub fn stderr(registry: Option<Registry>,\n-                  code_map: Lrc<SourceMap>,\n+                  source_map: Lrc<SourceMap>,\n                   pretty: bool) -> JsonEmitter {\n         JsonEmitter {\n             dst: Box::new(io::stderr()),\n             registry,\n-            cm: code_map,\n+            sm: source_map,\n             pretty,\n             ui_testing: false,\n         }\n@@ -62,12 +62,12 @@ impl JsonEmitter {\n \n     pub fn new(dst: Box<dyn Write + Send>,\n                registry: Option<Registry>,\n-               code_map: Lrc<SourceMap>,\n+               source_map: Lrc<SourceMap>,\n                pretty: bool) -> JsonEmitter {\n         JsonEmitter {\n             dst,\n             registry,\n-            cm: code_map,\n+            sm: source_map,\n             pretty,\n             ui_testing: false,\n         }\n@@ -199,7 +199,7 @@ impl Diagnostic {\n         }\n         let buf = BufWriter::default();\n         let output = buf.clone();\n-        EmitterWriter::new(Box::new(buf), Some(je.cm.clone()), false, false)\n+        EmitterWriter::new(Box::new(buf), Some(je.sm.clone()), false, false)\n             .ui_testing(je.ui_testing).emit(db);\n         let output = Arc::try_unwrap(output.0).unwrap().into_inner().unwrap();\n         let output = String::from_utf8(output).unwrap();\n@@ -269,8 +269,8 @@ impl DiagnosticSpan {\n                       mut backtrace: vec::IntoIter<MacroBacktrace>,\n                       je: &JsonEmitter)\n                       -> DiagnosticSpan {\n-        let start = je.cm.lookup_char_pos(span.lo());\n-        let end = je.cm.lookup_char_pos(span.hi());\n+        let start = je.sm.lookup_char_pos(span.lo());\n+        let end = je.sm.lookup_char_pos(span.hi());\n         let backtrace_step = backtrace.next().map(|bt| {\n             let call_site =\n                 Self::from_span_full(bt.call_site,\n@@ -356,7 +356,7 @@ impl DiagnosticSpanLine {\n     /// of `span` gets a DiagnosticSpanLine, with the highlight indicating the\n     /// `span` within the line.\n     fn from_span(span: Span, je: &JsonEmitter) -> Vec<DiagnosticSpanLine> {\n-        je.cm.span_to_lines(span)\n+        je.sm.span_to_lines(span)\n              .map(|lines| {\n                  let fm = &*lines.file;\n                  lines.lines"}, {"sha": "465ce73e01de20d6dc0097eab8c6db41f8bfc342", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 54, "deletions": 54, "changes": 108, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -256,11 +256,11 @@ impl<'a> StringReader<'a> {\n         let end = sess.source_map().lookup_byte_offset(span.hi());\n \n         // Make the range zero-length if the span is invalid.\n-        if span.lo() > span.hi() || begin.fm.start_pos != end.fm.start_pos {\n+        if span.lo() > span.hi() || begin.sf.start_pos != end.sf.start_pos {\n             span = span.shrink_to_lo();\n         }\n \n-        let mut sr = StringReader::new_raw_internal(sess, begin.fm, None);\n+        let mut sr = StringReader::new_raw_internal(sess, begin.sf, None);\n \n         // Seek the lexer to the right byte range.\n         sr.next_pos = span.lo();\n@@ -640,9 +640,9 @@ impl<'a> StringReader<'a> {\n \n                 // I guess this is the only way to figure out if\n                 // we're at the beginning of the file...\n-                let cmap = SourceMap::new(FilePathMapping::empty());\n-                cmap.files.borrow_mut().file_maps.push(self.source_file.clone());\n-                let loc = cmap.lookup_char_pos_adj(self.pos);\n+                let smap = SourceMap::new(FilePathMapping::empty());\n+                smap.files.borrow_mut().source_files.push(self.source_file.clone());\n+                let loc = smap.lookup_char_pos_adj(self.pos);\n                 debug!(\"Skipping a shebang\");\n                 if loc.line == 1 && loc.col == CharPos(0) {\n                     // FIXME: Add shebang \"token\", return it\n@@ -1855,17 +1855,17 @@ mod tests {\n     use rustc_data_structures::fx::FxHashSet;\n     use rustc_data_structures::sync::Lock;\n     use with_globals;\n-    fn mk_sess(cm: Lrc<SourceMap>) -> ParseSess {\n+    fn mk_sess(sm: Lrc<SourceMap>) -> ParseSess {\n         let emitter = errors::emitter::EmitterWriter::new(Box::new(io::sink()),\n-                                                          Some(cm.clone()),\n+                                                          Some(sm.clone()),\n                                                           false,\n                                                           false);\n         ParseSess {\n             span_diagnostic: errors::Handler::with_emitter(true, false, Box::new(emitter)),\n             unstable_features: UnstableFeatures::from_environment(),\n             config: CrateConfig::default(),\n             included_mod_stack: Lock::new(Vec::new()),\n-            code_map: cm,\n+            source_map: sm,\n             missing_fragment_specifiers: Lock::new(FxHashSet::default()),\n             raw_identifier_spans: Lock::new(Vec::new()),\n             registered_diagnostics: Lock::new(ErrorMap::new()),\n@@ -1875,20 +1875,20 @@ mod tests {\n     }\n \n     // open a string reader for the given string\n-    fn setup<'a>(cm: &SourceMap,\n+    fn setup<'a>(sm: &SourceMap,\n                  sess: &'a ParseSess,\n                  teststr: String)\n                  -> StringReader<'a> {\n-        let fm = cm.new_source_file(PathBuf::from(\"zebra.rs\").into(), teststr);\n-        StringReader::new(sess, fm, None)\n+        let sf = sm.new_source_file(PathBuf::from(\"zebra.rs\").into(), teststr);\n+        StringReader::new(sess, sf, None)\n     }\n \n     #[test]\n     fn t1() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            let mut string_reader = setup(&cm,\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            let mut string_reader = setup(&sm,\n                                         &sh,\n                                         \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\"\n                                             .to_string());\n@@ -1934,89 +1934,89 @@ mod tests {\n     #[test]\n     fn doublecolonparsing() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            check_tokenization(setup(&cm, &sh, \"a b\".to_string()),\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            check_tokenization(setup(&sm, &sh, \"a b\".to_string()),\n                             vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")]);\n         })\n     }\n \n     #[test]\n     fn dcparsing_2() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            check_tokenization(setup(&cm, &sh, \"a::b\".to_string()),\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            check_tokenization(setup(&sm, &sh, \"a::b\".to_string()),\n                             vec![mk_ident(\"a\"), token::ModSep, mk_ident(\"b\")]);\n         })\n     }\n \n     #[test]\n     fn dcparsing_3() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            check_tokenization(setup(&cm, &sh, \"a ::b\".to_string()),\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            check_tokenization(setup(&sm, &sh, \"a ::b\".to_string()),\n                             vec![mk_ident(\"a\"), token::Whitespace, token::ModSep, mk_ident(\"b\")]);\n         })\n     }\n \n     #[test]\n     fn dcparsing_4() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            check_tokenization(setup(&cm, &sh, \"a:: b\".to_string()),\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            check_tokenization(setup(&sm, &sh, \"a:: b\".to_string()),\n                             vec![mk_ident(\"a\"), token::ModSep, token::Whitespace, mk_ident(\"b\")]);\n         })\n     }\n \n     #[test]\n     fn character_a() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            assert_eq!(setup(&cm, &sh, \"'a'\".to_string()).next_token().tok,\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            assert_eq!(setup(&sm, &sh, \"'a'\".to_string()).next_token().tok,\n                     token::Literal(token::Char(Symbol::intern(\"a\")), None));\n         })\n     }\n \n     #[test]\n     fn character_space() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            assert_eq!(setup(&cm, &sh, \"' '\".to_string()).next_token().tok,\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            assert_eq!(setup(&sm, &sh, \"' '\".to_string()).next_token().tok,\n                     token::Literal(token::Char(Symbol::intern(\" \")), None));\n         })\n     }\n \n     #[test]\n     fn character_escaped() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            assert_eq!(setup(&cm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            assert_eq!(setup(&sm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n                     token::Literal(token::Char(Symbol::intern(\"\\\\n\")), None));\n         })\n     }\n \n     #[test]\n     fn lifetime_name() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            assert_eq!(setup(&cm, &sh, \"'abc\".to_string()).next_token().tok,\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            assert_eq!(setup(&sm, &sh, \"'abc\".to_string()).next_token().tok,\n                     token::Lifetime(Ident::from_str(\"'abc\")));\n         })\n     }\n \n     #[test]\n     fn raw_string() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            assert_eq!(setup(&cm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            assert_eq!(setup(&sm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n                         .next_token()\n                         .tok,\n                     token::Literal(token::StrRaw(Symbol::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n@@ -2026,15 +2026,15 @@ mod tests {\n     #[test]\n     fn literal_suffixes() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n             macro_rules! test {\n                 ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n-                    assert_eq!(setup(&cm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n+                    assert_eq!(setup(&sm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n                             token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n                                             Some(Symbol::intern(\"suffix\"))));\n                     // with a whitespace separator:\n-                    assert_eq!(setup(&cm, &sh, format!(\"{} suffix\", $input)).next_token().tok,\n+                    assert_eq!(setup(&sm, &sh, format!(\"{} suffix\", $input)).next_token().tok,\n                             token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n                                             None));\n                 }}\n@@ -2050,13 +2050,13 @@ mod tests {\n             test!(\"1.0\", Float, \"1.0\");\n             test!(\"1.0e10\", Float, \"1.0e10\");\n \n-            assert_eq!(setup(&cm, &sh, \"2us\".to_string()).next_token().tok,\n+            assert_eq!(setup(&sm, &sh, \"2us\".to_string()).next_token().tok,\n                     token::Literal(token::Integer(Symbol::intern(\"2\")),\n                                     Some(Symbol::intern(\"us\"))));\n-            assert_eq!(setup(&cm, &sh, \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n+            assert_eq!(setup(&sm, &sh, \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n                     token::Literal(token::StrRaw(Symbol::intern(\"raw\"), 3),\n                                     Some(Symbol::intern(\"suffix\"))));\n-            assert_eq!(setup(&cm, &sh, \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n+            assert_eq!(setup(&sm, &sh, \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n                     token::Literal(token::ByteStrRaw(Symbol::intern(\"raw\"), 3),\n                                     Some(Symbol::intern(\"suffix\"))));\n         })\n@@ -2072,9 +2072,9 @@ mod tests {\n     #[test]\n     fn nested_block_comments() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            let mut lexer = setup(&cm, &sh, \"/* /* */ */'a'\".to_string());\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            let mut lexer = setup(&sm, &sh, \"/* /* */ */'a'\".to_string());\n             match lexer.next_token().tok {\n                 token::Comment => {}\n                 _ => panic!(\"expected a comment!\"),\n@@ -2087,9 +2087,9 @@ mod tests {\n     #[test]\n     fn crlf_comments() {\n         with_globals(|| {\n-            let cm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-            let sh = mk_sess(cm.clone());\n-            let mut lexer = setup(&cm, &sh, \"// test\\r\\n/// test\\r\\n\".to_string());\n+            let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(sm.clone());\n+            let mut lexer = setup(&sm, &sh, \"// test\\r\\n/// test\\r\\n\".to_string());\n             let comment = lexer.next_token();\n             assert_eq!(comment.tok, token::Comment);\n             assert_eq!((comment.sp.lo(), comment.sp.hi()), (BytePos(0), BytePos(7)));"}, {"sha": "ce32520b8e74603e3f58a25cbe4fb34e4ba1b5f7", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -57,7 +57,7 @@ pub struct ParseSess {\n     pub non_modrs_mods: Lock<Vec<(ast::Ident, Span)>>,\n     /// Used to determine and report recursive mod inclusions\n     included_mod_stack: Lock<Vec<PathBuf>>,\n-    code_map: Lrc<SourceMap>,\n+    source_map: Lrc<SourceMap>,\n     pub buffered_lints: Lock<Vec<BufferedEarlyLint>>,\n }\n \n@@ -71,7 +71,7 @@ impl ParseSess {\n         ParseSess::with_span_handler(handler, cm)\n     }\n \n-    pub fn with_span_handler(handler: Handler, code_map: Lrc<SourceMap>) -> ParseSess {\n+    pub fn with_span_handler(handler: Handler, source_map: Lrc<SourceMap>) -> ParseSess {\n         ParseSess {\n             span_diagnostic: handler,\n             unstable_features: UnstableFeatures::from_environment(),\n@@ -80,14 +80,14 @@ impl ParseSess {\n             raw_identifier_spans: Lock::new(Vec::new()),\n             registered_diagnostics: Lock::new(ErrorMap::new()),\n             included_mod_stack: Lock::new(vec![]),\n-            code_map,\n+            source_map,\n             non_modrs_mods: Lock::new(vec![]),\n             buffered_lints: Lock::new(vec![]),\n         }\n     }\n \n     pub fn source_map(&self) -> &SourceMap {\n-        &self.code_map\n+        &self.source_map\n     }\n \n     pub fn buffer_lint<S: Into<MultiSpan>>(&self,"}, {"sha": "e8cacc3b5aff31e4d4560491c3574ae68cffdc9e", "filename": "src/libsyntax/source_map.rs", "status": "modified", "additions": 92, "deletions": 91, "changes": 183, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fsource_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Fsource_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsource_map.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -106,17 +106,17 @@ impl FileLoader for RealFileLoader {\n // subsequent compilation sessions (which is something we need to do during\n // incremental compilation).\n #[derive(Copy, Clone, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable, Debug)]\n-pub struct StableFilemapId(u128);\n+pub struct StableSourceFileId(u128);\n \n-impl StableFilemapId {\n-    pub fn new(source_file: &SourceFile) -> StableFilemapId {\n+impl StableSourceFileId {\n+    pub fn new(source_file: &SourceFile) -> StableSourceFileId {\n         let mut hasher = StableHasher::new();\n \n         source_file.name.hash(&mut hasher);\n         source_file.name_was_remapped.hash(&mut hasher);\n         source_file.unmapped_path.hash(&mut hasher);\n \n-        StableFilemapId(hasher.finish())\n+        StableSourceFileId(hasher.finish())\n     }\n }\n \n@@ -126,8 +126,8 @@ impl StableFilemapId {\n \n #[derive(Default)]\n pub(super) struct SourceMapFiles {\n-    pub(super) file_maps: Vec<Lrc<SourceFile>>,\n-    stable_id_to_source_file: FxHashMap<StableFilemapId, Lrc<SourceFile>>\n+    pub(super) source_files: Vec<Lrc<SourceFile>>,\n+    stable_id_to_source_file: FxHashMap<StableSourceFileId, Lrc<SourceFile>>\n }\n \n pub struct SourceMap {\n@@ -190,15 +190,16 @@ impl SourceMap {\n     }\n \n     pub fn files(&self) -> MappedLockGuard<Vec<Lrc<SourceFile>>> {\n-        LockGuard::map(self.files.borrow(), |files| &mut files.file_maps)\n+        LockGuard::map(self.files.borrow(), |files| &mut files.source_files)\n     }\n \n-    pub fn source_file_by_stable_id(&self, stable_id: StableFilemapId) -> Option<Lrc<SourceFile>> {\n-        self.files.borrow().stable_id_to_source_file.get(&stable_id).map(|fm| fm.clone())\n+    pub fn source_file_by_stable_id(&self, stable_id: StableSourceFileId) ->\n+    Option<Lrc<SourceFile>> {\n+        self.files.borrow().stable_id_to_source_file.get(&stable_id).map(|sf| sf.clone())\n     }\n \n     fn next_start_pos(&self) -> usize {\n-        match self.files.borrow().file_maps.last() {\n+        match self.files.borrow().source_files.last() {\n             None => 0,\n             // Add one so there is some space between files. This lets us distinguish\n             // positions in the source_map, even in the presence of zero-length files.\n@@ -235,8 +236,8 @@ impl SourceMap {\n \n         let mut files = self.files.borrow_mut();\n \n-        files.file_maps.push(source_file.clone());\n-        files.stable_id_to_source_file.insert(StableFilemapId::new(&source_file),\n+        files.source_files.push(source_file.clone());\n+        files.stable_id_to_source_file.insert(StableSourceFileId::new(&source_file),\n                                               source_file.clone());\n \n         source_file\n@@ -293,8 +294,8 @@ impl SourceMap {\n \n         let mut files = self.files.borrow_mut();\n \n-        files.file_maps.push(source_file.clone());\n-        files.stable_id_to_source_file.insert(StableFilemapId::new(&source_file),\n+        files.source_files.push(source_file.clone());\n+        files.stable_id_to_source_file.insert(StableSourceFileId::new(&source_file),\n                                               source_file.clone());\n \n         source_file\n@@ -324,7 +325,7 @@ impl SourceMap {\n     pub fn lookup_char_pos(&self, pos: BytePos) -> Loc {\n         let chpos = self.bytepos_to_file_charpos(pos);\n         match self.lookup_line(pos) {\n-            Ok(SourceFileAndLine { fm: f, line: a }) => {\n+            Ok(SourceFileAndLine { sf: f, line: a }) => {\n                 let line = a + 1; // Line numbers start at 1\n                 let linebpos = f.lines[a];\n                 let linechpos = self.bytepos_to_file_charpos(linebpos);\n@@ -387,10 +388,10 @@ impl SourceMap {\n     pub fn lookup_line(&self, pos: BytePos) -> Result<SourceFileAndLine, Lrc<SourceFile>> {\n         let idx = self.lookup_source_file_idx(pos);\n \n-        let f = (*self.files.borrow().file_maps)[idx].clone();\n+        let f = (*self.files.borrow().source_files)[idx].clone();\n \n         match f.lookup_line(pos) {\n-            Some(line) => Ok(SourceFileAndLine { fm: f, line: line }),\n+            Some(line) => Ok(SourceFileAndLine { sf: f, line: line }),\n             None => Err(f)\n         }\n     }\n@@ -441,7 +442,7 @@ impl SourceMap {\n     }\n \n     pub fn span_to_string(&self, sp: Span) -> String {\n-        if self.files.borrow().file_maps.is_empty() && sp.is_dummy() {\n+        if self.files.borrow().source_files.is_empty() && sp.is_dummy() {\n             return \"no-location\".to_string();\n         }\n \n@@ -531,38 +532,38 @@ impl SourceMap {\n         let local_begin = self.lookup_byte_offset(sp.lo());\n         let local_end = self.lookup_byte_offset(sp.hi());\n \n-        if local_begin.fm.start_pos != local_end.fm.start_pos {\n+        if local_begin.sf.start_pos != local_end.sf.start_pos {\n             return Err(SpanSnippetError::DistinctSources(DistinctSources {\n-                begin: (local_begin.fm.name.clone(),\n-                        local_begin.fm.start_pos),\n-                end: (local_end.fm.name.clone(),\n-                      local_end.fm.start_pos)\n+                begin: (local_begin.sf.name.clone(),\n+                        local_begin.sf.start_pos),\n+                end: (local_end.sf.name.clone(),\n+                      local_end.sf.start_pos)\n             }));\n         } else {\n-            self.ensure_source_file_source_present(local_begin.fm.clone());\n+            self.ensure_source_file_source_present(local_begin.sf.clone());\n \n             let start_index = local_begin.pos.to_usize();\n             let end_index = local_end.pos.to_usize();\n-            let source_len = (local_begin.fm.end_pos -\n-                              local_begin.fm.start_pos).to_usize();\n+            let source_len = (local_begin.sf.end_pos -\n+                              local_begin.sf.start_pos).to_usize();\n \n             if start_index > end_index || end_index > source_len {\n-                return Err(SpanSnippetError::MalformedForCodemap(\n-                    MalformedCodemapPositions {\n-                        name: local_begin.fm.name.clone(),\n+                return Err(SpanSnippetError::MalformedForSourcemap(\n+                    MalformedSourceMapPositions {\n+                        name: local_begin.sf.name.clone(),\n                         source_len,\n                         begin_pos: local_begin.pos,\n                         end_pos: local_end.pos,\n                     }));\n             }\n \n-            if let Some(ref src) = local_begin.fm.src {\n+            if let Some(ref src) = local_begin.sf.src {\n                 return Ok(extract_source(src, start_index, end_index));\n-            } else if let Some(src) = local_begin.fm.external_src.borrow().get_source() {\n+            } else if let Some(src) = local_begin.sf.external_src.borrow().get_source() {\n                 return Ok(extract_source(src, start_index, end_index));\n             } else {\n                 return Err(SpanSnippetError::SourceNotAvailable {\n-                    filename: local_begin.fm.name.clone()\n+                    filename: local_begin.sf.name.clone()\n                 });\n             }\n         }\n@@ -757,19 +758,19 @@ impl SourceMap {\n             return 1;\n         }\n \n-        let source_len = (local_begin.fm.end_pos - local_begin.fm.start_pos).to_usize();\n+        let source_len = (local_begin.sf.end_pos - local_begin.sf.start_pos).to_usize();\n         debug!(\"find_width_of_character_at_span: source_len=`{:?}`\", source_len);\n         // Ensure indexes are also not malformed.\n         if start_index > end_index || end_index > source_len {\n             debug!(\"find_width_of_character_at_span: source indexes are malformed\");\n             return 1;\n         }\n \n-        let src = local_begin.fm.external_src.borrow();\n+        let src = local_begin.sf.external_src.borrow();\n \n         // We need to extend the snippet to the end of the src rather than to end_index so when\n         // searching forwards for boundaries we've got somewhere to search.\n-        let snippet = if let Some(ref src) = local_begin.fm.src {\n+        let snippet = if let Some(ref src) = local_begin.sf.src {\n             let len = src.len();\n             (&src[start_index..len])\n         } else if let Some(src) = src.get_source() {\n@@ -806,9 +807,9 @@ impl SourceMap {\n     }\n \n     pub fn get_source_file(&self, filename: &FileName) -> Option<Lrc<SourceFile>> {\n-        for fm in self.files.borrow().file_maps.iter() {\n-            if *filename == fm.name {\n-                return Some(fm.clone());\n+        for sf in self.files.borrow().source_files.iter() {\n+            if *filename == sf.name {\n+                return Some(sf.clone());\n             }\n         }\n         None\n@@ -817,15 +818,15 @@ impl SourceMap {\n     /// For a global BytePos compute the local offset within the containing SourceFile\n     pub fn lookup_byte_offset(&self, bpos: BytePos) -> SourceFileAndBytePos {\n         let idx = self.lookup_source_file_idx(bpos);\n-        let fm = (*self.files.borrow().file_maps)[idx].clone();\n-        let offset = bpos - fm.start_pos;\n-        SourceFileAndBytePos {fm: fm, pos: offset}\n+        let sf = (*self.files.borrow().source_files)[idx].clone();\n+        let offset = bpos - sf.start_pos;\n+        SourceFileAndBytePos {sf: sf, pos: offset}\n     }\n \n     /// Converts an absolute BytePos to a CharPos relative to the source_file.\n     pub fn bytepos_to_file_charpos(&self, bpos: BytePos) -> CharPos {\n         let idx = self.lookup_source_file_idx(bpos);\n-        let map = &(*self.files.borrow().file_maps)[idx];\n+        let map = &(*self.files.borrow().source_files)[idx];\n \n         // The number of extra bytes due to multibyte chars in the SourceFile\n         let mut total_extra_bytes = 0;\n@@ -851,7 +852,7 @@ impl SourceMap {\n     // Return the index of the source_file (in self.files) which contains pos.\n     pub fn lookup_source_file_idx(&self, pos: BytePos) -> usize {\n         let files = self.files.borrow();\n-        let files = &files.file_maps;\n+        let files = &files.source_files;\n         let count = files.len();\n \n         // Binary search for the source_file.\n@@ -974,9 +975,9 @@ impl SourceMapper for SourceMap {\n         }\n         sp\n     }\n-    fn ensure_source_file_source_present(&self, file_map: Lrc<SourceFile>) -> bool {\n-        file_map.add_external_src(\n-            || match file_map.name {\n+    fn ensure_source_file_source_present(&self, source_file: Lrc<SourceFile>) -> bool {\n+        source_file.add_external_src(\n+            || match source_file.name {\n                 FileName::Real(ref name) => self.file_loader.read_file(name).ok(),\n                 _ => None,\n             }\n@@ -1031,97 +1032,97 @@ mod tests {\n     use super::*;\n     use rustc_data_structures::sync::Lrc;\n \n-    fn init_code_map() -> SourceMap {\n-        let cm = SourceMap::new(FilePathMapping::empty());\n-        cm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n+    fn init_source_map() -> SourceMap {\n+        let sm = SourceMap::new(FilePathMapping::empty());\n+        sm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n                        \"first line.\\nsecond line\".to_string());\n-        cm.new_source_file(PathBuf::from(\"empty.rs\").into(),\n+        sm.new_source_file(PathBuf::from(\"empty.rs\").into(),\n                        String::new());\n-        cm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n+        sm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n                        \"first line.\\nsecond line\".to_string());\n-        cm\n+        sm\n     }\n \n     #[test]\n     fn t3() {\n         // Test lookup_byte_offset\n-        let cm = init_code_map();\n+        let sm = init_source_map();\n \n-        let fmabp1 = cm.lookup_byte_offset(BytePos(23));\n-        assert_eq!(fmabp1.fm.name, PathBuf::from(\"blork.rs\").into());\n-        assert_eq!(fmabp1.pos, BytePos(23));\n+        let srcfbp1 = sm.lookup_byte_offset(BytePos(23));\n+        assert_eq!(srcfbp1.sf.name, PathBuf::from(\"blork.rs\").into());\n+        assert_eq!(srcfbp1.pos, BytePos(23));\n \n-        let fmabp1 = cm.lookup_byte_offset(BytePos(24));\n-        assert_eq!(fmabp1.fm.name, PathBuf::from(\"empty.rs\").into());\n-        assert_eq!(fmabp1.pos, BytePos(0));\n+        let srcfbp1 = sm.lookup_byte_offset(BytePos(24));\n+        assert_eq!(srcfbp1.sf.name, PathBuf::from(\"empty.rs\").into());\n+        assert_eq!(srcfbp1.pos, BytePos(0));\n \n-        let fmabp2 = cm.lookup_byte_offset(BytePos(25));\n-        assert_eq!(fmabp2.fm.name, PathBuf::from(\"blork2.rs\").into());\n-        assert_eq!(fmabp2.pos, BytePos(0));\n+        let srcfbp2 = sm.lookup_byte_offset(BytePos(25));\n+        assert_eq!(srcfbp2.sf.name, PathBuf::from(\"blork2.rs\").into());\n+        assert_eq!(srcfbp2.pos, BytePos(0));\n     }\n \n     #[test]\n     fn t4() {\n         // Test bytepos_to_file_charpos\n-        let cm = init_code_map();\n+        let sm = init_source_map();\n \n-        let cp1 = cm.bytepos_to_file_charpos(BytePos(22));\n+        let cp1 = sm.bytepos_to_file_charpos(BytePos(22));\n         assert_eq!(cp1, CharPos(22));\n \n-        let cp2 = cm.bytepos_to_file_charpos(BytePos(25));\n+        let cp2 = sm.bytepos_to_file_charpos(BytePos(25));\n         assert_eq!(cp2, CharPos(0));\n     }\n \n     #[test]\n     fn t5() {\n         // Test zero-length source_files.\n-        let cm = init_code_map();\n+        let sm = init_source_map();\n \n-        let loc1 = cm.lookup_char_pos(BytePos(22));\n+        let loc1 = sm.lookup_char_pos(BytePos(22));\n         assert_eq!(loc1.file.name, PathBuf::from(\"blork.rs\").into());\n         assert_eq!(loc1.line, 2);\n         assert_eq!(loc1.col, CharPos(10));\n \n-        let loc2 = cm.lookup_char_pos(BytePos(25));\n+        let loc2 = sm.lookup_char_pos(BytePos(25));\n         assert_eq!(loc2.file.name, PathBuf::from(\"blork2.rs\").into());\n         assert_eq!(loc2.line, 1);\n         assert_eq!(loc2.col, CharPos(0));\n     }\n \n-    fn init_code_map_mbc() -> SourceMap {\n-        let cm = SourceMap::new(FilePathMapping::empty());\n+    fn init_source_map_mbc() -> SourceMap {\n+        let sm = SourceMap::new(FilePathMapping::empty());\n         // \u20ac is a three byte utf8 char.\n-        cm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n+        sm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n                        \"fir\u20acst \u20ac\u20ac\u20ac\u20ac line.\\nsecond line\".to_string());\n-        cm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n+        sm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n                        \"first line\u20ac\u20ac.\\n\u20ac second line\".to_string());\n-        cm\n+        sm\n     }\n \n     #[test]\n     fn t6() {\n         // Test bytepos_to_file_charpos in the presence of multi-byte chars\n-        let cm = init_code_map_mbc();\n+        let sm = init_source_map_mbc();\n \n-        let cp1 = cm.bytepos_to_file_charpos(BytePos(3));\n+        let cp1 = sm.bytepos_to_file_charpos(BytePos(3));\n         assert_eq!(cp1, CharPos(3));\n \n-        let cp2 = cm.bytepos_to_file_charpos(BytePos(6));\n+        let cp2 = sm.bytepos_to_file_charpos(BytePos(6));\n         assert_eq!(cp2, CharPos(4));\n \n-        let cp3 = cm.bytepos_to_file_charpos(BytePos(56));\n+        let cp3 = sm.bytepos_to_file_charpos(BytePos(56));\n         assert_eq!(cp3, CharPos(12));\n \n-        let cp4 = cm.bytepos_to_file_charpos(BytePos(61));\n+        let cp4 = sm.bytepos_to_file_charpos(BytePos(61));\n         assert_eq!(cp4, CharPos(15));\n     }\n \n     #[test]\n     fn t7() {\n         // Test span_to_lines for a span ending at the end of source_file\n-        let cm = init_code_map();\n+        let sm = init_source_map();\n         let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n-        let file_lines = cm.span_to_lines(span).unwrap();\n+        let file_lines = sm.span_to_lines(span).unwrap();\n \n         assert_eq!(file_lines.file.name, PathBuf::from(\"blork.rs\").into());\n         assert_eq!(file_lines.lines.len(), 1);\n@@ -1143,17 +1144,17 @@ mod tests {\n     /// lines in the middle of a file.\n     #[test]\n     fn span_to_snippet_and_lines_spanning_multiple_lines() {\n-        let cm = SourceMap::new(FilePathMapping::empty());\n+        let sm = SourceMap::new(FilePathMapping::empty());\n         let inputtext = \"aaaaa\\nbbbbBB\\nCCC\\nDDDDDddddd\\neee\\n\";\n         let selection = \"     \\n    ~~\\n~~~\\n~~~~~     \\n   \\n\";\n-        cm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_string());\n+        sm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_string());\n         let span = span_from_selection(inputtext, selection);\n \n         // check that we are extracting the text we thought we were extracting\n-        assert_eq!(&cm.span_to_snippet(span).unwrap(), \"BB\\nCCC\\nDDDDD\");\n+        assert_eq!(&sm.span_to_snippet(span).unwrap(), \"BB\\nCCC\\nDDDDD\");\n \n         // check that span_to_lines gives us the complete result with the lines/cols we expected\n-        let lines = cm.span_to_lines(span).unwrap();\n+        let lines = sm.span_to_lines(span).unwrap();\n         let expected = vec![\n             LineInfo { line_index: 1, start_col: CharPos(4), end_col: CharPos(6) },\n             LineInfo { line_index: 2, start_col: CharPos(0), end_col: CharPos(3) },\n@@ -1165,35 +1166,35 @@ mod tests {\n     #[test]\n     fn t8() {\n         // Test span_to_snippet for a span ending at the end of source_file\n-        let cm = init_code_map();\n+        let sm = init_source_map();\n         let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n-        let snippet = cm.span_to_snippet(span);\n+        let snippet = sm.span_to_snippet(span);\n \n         assert_eq!(snippet, Ok(\"second line\".to_string()));\n     }\n \n     #[test]\n     fn t9() {\n         // Test span_to_str for a span ending at the end of source_file\n-        let cm = init_code_map();\n+        let sm = init_source_map();\n         let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n-        let sstr =  cm.span_to_string(span);\n+        let sstr =  sm.span_to_string(span);\n \n         assert_eq!(sstr, \"blork.rs:2:1: 2:12\");\n     }\n \n     /// Test failing to merge two spans on different lines\n     #[test]\n     fn span_merging_fail() {\n-        let cm = SourceMap::new(FilePathMapping::empty());\n+        let sm = SourceMap::new(FilePathMapping::empty());\n         let inputtext  = \"bbbb BB\\ncc CCC\\n\";\n         let selection1 = \"     ~~\\n      \\n\";\n         let selection2 = \"       \\n   ~~~\\n\";\n-        cm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_owned());\n+        sm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_owned());\n         let span1 = span_from_selection(inputtext, selection1);\n         let span2 = span_from_selection(inputtext, selection2);\n \n-        assert!(cm.merge_spans(span1, span2).is_none());\n+        assert!(sm.merge_spans(span1, span2).is_none());\n     }\n \n     /// Returns the span corresponding to the `n`th occurrence of"}, {"sha": "799489ba42cc31b528c0ed6336594b4f2ca08277", "filename": "src/libsyntax/test_snippet.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Ftest_snippet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax%2Ftest_snippet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftest_snippet.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -50,20 +50,20 @@ fn test_harness(file_text: &str, span_labels: Vec<SpanLabel>, expected_output: &\n     with_globals(|| {\n         let output = Arc::new(Mutex::new(Vec::new()));\n \n-        let code_map = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-        code_map.new_source_file(Path::new(\"test.rs\").to_owned().into(), file_text.to_owned());\n+        let source_map = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n+        source_map.new_source_file(Path::new(\"test.rs\").to_owned().into(), file_text.to_owned());\n \n         let primary_span = make_span(&file_text, &span_labels[0].start, &span_labels[0].end);\n         let mut msp = MultiSpan::from_span(primary_span);\n         for span_label in span_labels {\n             let span = make_span(&file_text, &span_label.start, &span_label.end);\n             msp.push_span_label(span, span_label.label.to_string());\n             println!(\"span: {:?} label: {:?}\", span, span_label.label);\n-            println!(\"text: {:?}\", code_map.span_to_snippet(span));\n+            println!(\"text: {:?}\", source_map.span_to_snippet(span));\n         }\n \n         let emitter = EmitterWriter::new(Box::new(Shared { data: output.clone() }),\n-                                        Some(code_map.clone()),\n+                                        Some(source_map.clone()),\n                                         false,\n                                         false);\n         let handler = Handler::with_emitter(true, false, Box::new(emitter));"}, {"sha": "7bc9a1af62c19b1e45710ce549c51480c1c4690f", "filename": "src/libsyntax_pos/analyze_source_file.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax_pos%2Fanalyze_source_file.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax_pos%2Fanalyze_source_file.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fanalyze_source_file.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -36,9 +36,9 @@ pub fn analyze_source_file(\n     // it encounters. If that point is already outside the source_file, remove\n     // it again.\n     if let Some(&last_line_start) = lines.last() {\n-        let file_map_end = source_file_start_pos + BytePos::from_usize(src.len());\n-        assert!(file_map_end >= last_line_start);\n-        if last_line_start == file_map_end {\n+        let source_file_end = source_file_start_pos + BytePos::from_usize(src.len());\n+        assert!(source_file_end >= last_line_start);\n+        if last_line_start == source_file_end {\n             lines.pop();\n         }\n     }"}, {"sha": "a780a38ff96f53fb1b8ea73fa1036c7e17771154", "filename": "src/libsyntax_pos/lib.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax_pos%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Flibsyntax_pos%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Flib.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -1266,9 +1266,9 @@ pub struct LocWithOpt {\n \n // used to be structural records. Better names, anyone?\n #[derive(Debug)]\n-pub struct SourceFileAndLine { pub fm: Lrc<SourceFile>, pub line: usize }\n+pub struct SourceFileAndLine { pub sf: Lrc<SourceFile>, pub line: usize }\n #[derive(Debug)]\n-pub struct SourceFileAndBytePos { pub fm: Lrc<SourceFile>, pub pos: BytePos }\n+pub struct SourceFileAndBytePos { pub sf: Lrc<SourceFile>, pub pos: BytePos }\n \n #[derive(Copy, Clone, Debug, PartialEq, Eq)]\n pub struct LineInfo {\n@@ -1303,7 +1303,7 @@ pub struct MacroBacktrace {\n }\n \n // _____________________________________________________________________________\n-// SpanLinesError, SpanSnippetError, DistinctSources, MalformedCodemapPositions\n+// SpanLinesError, SpanSnippetError, DistinctSources, MalformedSourceMapPositions\n //\n \n pub type FileLinesResult = Result<FileLines, SpanLinesError>;\n@@ -1318,7 +1318,7 @@ pub enum SpanLinesError {\n pub enum SpanSnippetError {\n     IllFormedSpan(Span),\n     DistinctSources(DistinctSources),\n-    MalformedForCodemap(MalformedCodemapPositions),\n+    MalformedForSourcemap(MalformedSourceMapPositions),\n     SourceNotAvailable { filename: FileName }\n }\n \n@@ -1329,7 +1329,7 @@ pub struct DistinctSources {\n }\n \n #[derive(Clone, PartialEq, Eq, Debug)]\n-pub struct MalformedCodemapPositions {\n+pub struct MalformedSourceMapPositions {\n     pub name: FileName,\n     pub source_len: usize,\n     pub begin_pos: BytePos,"}, {"sha": "dd26cf78fdabeea6f1110b9e601132ee32f54d0b", "filename": "src/test/run-pass/imports/import-crate-with-invalid-spans/auxiliary/crate_with_invalid_spans.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Ftest%2Frun-pass%2Fimports%2Fimport-crate-with-invalid-spans%2Fauxiliary%2Fcrate_with_invalid_spans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6c9f6a1afdd60603ddb7ab28755fbc134b7d4844/src%2Ftest%2Frun-pass%2Fimports%2Fimport-crate-with-invalid-spans%2Fauxiliary%2Fcrate_with_invalid_spans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fimports%2Fimport-crate-with-invalid-spans%2Fauxiliary%2Fcrate_with_invalid_spans.rs?ref=6c9f6a1afdd60603ddb7ab28755fbc134b7d4844", "patch": "@@ -23,8 +23,8 @@ pub fn exported_generic<T>(x: T, y: u32) -> (T, u32) {\n     // The AST node for the (1 + y) expression generated by the macro will then\n     // take it's `lo` span bound from the `1` literal in the macro-defining file\n     // and it's `hi` bound from `y` in this file, which should be lower than the\n-    // `lo` and even lower than the lower bound of the FileMap it is supposedly\n-    // contained in because the FileMap for this file was allocated earlier than\n-    // the FileMap of the macro-defining file.\n+    // `lo` and even lower than the lower bound of the SourceFile it is supposedly\n+    // contained in because the SourceFile for this file was allocated earlier than\n+    // the SourceFile of the macro-defining file.\n     return (x, add1!(y));\n }"}]}