{"sha": "cae94e8ec0971d6762fb06aa05c3d733e670abe5", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNhZTk0ZThlYzA5NzFkNjc2MmZiMDZhYTA1YzNkNzMzZTY3MGFiZTU=", "commit": {"author": {"name": "Austin Hicks", "email": "camlorn@camlorn.net", "date": "2016-10-16T21:31:19Z"}, "committer": {"name": "Austin Hicks", "email": "camlorn@camlorn.net", "date": "2016-12-14T17:28:18Z"}, "message": "Optimize anything using a layout::Struct by introducing a mapping from source code field order to in-memory field order and sorting by alignment.", "tree": {"sha": "75fa0f6d092840b1dee314a73d57382fb4c86a46", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/75fa0f6d092840b1dee314a73d57382fb4c86a46"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/cae94e8ec0971d6762fb06aa05c3d733e670abe5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/cae94e8ec0971d6762fb06aa05c3d733e670abe5", "html_url": "https://github.com/rust-lang/rust/commit/cae94e8ec0971d6762fb06aa05c3d733e670abe5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/cae94e8ec0971d6762fb06aa05c3d733e670abe5/comments", "author": {"login": "ahicks92", "id": 6968705, "node_id": "MDQ6VXNlcjY5Njg3MDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6968705?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahicks92", "html_url": "https://github.com/ahicks92", "followers_url": "https://api.github.com/users/ahicks92/followers", "following_url": "https://api.github.com/users/ahicks92/following{/other_user}", "gists_url": "https://api.github.com/users/ahicks92/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahicks92/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahicks92/subscriptions", "organizations_url": "https://api.github.com/users/ahicks92/orgs", "repos_url": "https://api.github.com/users/ahicks92/repos", "events_url": "https://api.github.com/users/ahicks92/events{/privacy}", "received_events_url": "https://api.github.com/users/ahicks92/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ahicks92", "id": 6968705, "node_id": "MDQ6VXNlcjY5Njg3MDU=", "avatar_url": "https://avatars.githubusercontent.com/u/6968705?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahicks92", "html_url": "https://github.com/ahicks92", "followers_url": "https://api.github.com/users/ahicks92/followers", "following_url": "https://api.github.com/users/ahicks92/following{/other_user}", "gists_url": "https://api.github.com/users/ahicks92/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahicks92/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahicks92/subscriptions", "organizations_url": "https://api.github.com/users/ahicks92/orgs", "repos_url": "https://api.github.com/users/ahicks92/repos", "events_url": "https://api.github.com/users/ahicks92/events{/privacy}", "received_events_url": "https://api.github.com/users/ahicks92/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "01d53df82ef12625f947f5c0a6004e1aea2f9782", "url": "https://api.github.com/repos/rust-lang/rust/commits/01d53df82ef12625f947f5c0a6004e1aea2f9782", "html_url": "https://github.com/rust-lang/rust/commit/01d53df82ef12625f947f5c0a6004e1aea2f9782"}], "stats": {"total": 261, "additions": 180, "deletions": 81}, "files": [{"sha": "74b3bc609abfe323c2714302241838b5639616aa", "filename": "src/librustc/ty/layout.rs", "status": "modified", "additions": 153, "deletions": 62, "changes": 215, "blob_url": "https://github.com/rust-lang/rust/blob/cae94e8ec0971d6762fb06aa05c3d733e670abe5/src%2Flibrustc%2Fty%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cae94e8ec0971d6762fb06aa05c3d733e670abe5/src%2Flibrustc%2Fty%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Flayout.rs?ref=cae94e8ec0971d6762fb06aa05c3d733e670abe5", "patch": "@@ -24,6 +24,7 @@ use syntax_pos::DUMMY_SP;\n use std::cmp;\n use std::fmt;\n use std::i64;\n+use std::iter;\n \n /// Parsed [Data layout](http://llvm.org/docs/LangRef.html#data-layout)\n /// for a target, which contains everything needed to compute layouts.\n@@ -511,41 +512,76 @@ pub struct Struct {\n     /// If true, the size is exact, otherwise it's only a lower bound.\n     pub sized: bool,\n \n-    /// Offsets for the first byte of each field.\n+    /// Offsets for the first byte of each field, ordered to match the tys.\n+    /// This vector does not go in increasing order.\n     /// FIXME(eddyb) use small vector optimization for the common case.\n     pub offsets: Vec<Size>,\n \n+    /// Maps field indices to GEP indices, depending how fields were permuted.\n+    /// FIXME (camlorn) also consider small vector  optimization here.\n+    pub gep_index: Vec<u32>,\n+\n     pub min_size: Size,\n }\n \n impl<'a, 'gcx, 'tcx> Struct {\n-    pub fn new(dl: &TargetDataLayout, packed: bool) -> Struct {\n-        Struct {\n+    pub fn new<I>(dl: &TargetDataLayout, fields: I,\n+                  repr: attr::ReprAttr, is_enum_variant: bool,\n+                  scapegoat: Ty<'gcx>) -> Result<Struct, LayoutError<'gcx>>\n+        where I: Iterator<Item=Result<&'a Layout, LayoutError<'gcx>>>{\n+        let packed = repr == attr::ReprPacked;\n+        let mut ret = Struct {\n             align: if packed { dl.i8_align } else { dl.aggregate_align },\n             packed: packed,\n             sized: true,\n             offsets: vec![],\n+            gep_index: vec![],\n             min_size: Size::from_bytes(0),\n-        }\n+        };\n+        ret.fill_in_fields(dl, fields, scapegoat, repr, is_enum_variant)?;\n+        Ok(ret)\n     }\n \n-    /// Extend the Struct with more fields.\n-    pub fn extend<I>(&mut self, dl: &TargetDataLayout,\n+    fn fill_in_fields<I>(&mut self, dl: &TargetDataLayout,\n                      fields: I,\n-                     scapegoat: Ty<'gcx>)\n+                     scapegoat: Ty<'gcx>,\n+                     repr: attr::ReprAttr,\n+                     is_enum_variant: bool)\n                      -> Result<(), LayoutError<'gcx>>\n     where I: Iterator<Item=Result<&'a Layout, LayoutError<'gcx>>> {\n-        self.offsets.reserve(fields.size_hint().0);\n+        let fields = fields.collect::<Result<Vec<_>, LayoutError<'gcx>>>()?;\n+        if fields.len() == 0 {return Ok(())};\n+\n+        self.offsets = vec![Size::from_bytes(0); fields.len()];\n+        let mut inverse_gep_index: Vec<u32> = Vec::with_capacity(fields.len());\n+        inverse_gep_index.extend(0..fields.len() as u32);\n+\n+        if repr == attr::ReprAny {\n+            let start: usize = if is_enum_variant {1} else {0};\n+            // FIXME(camlorn): we can't reorder the last field because it is possible for structs to be coerced to unsized.\n+            // Example: struct Foo<T: ?Sized> { x: i32, y: T }\n+            // We can coerce &Foo<u8> to &Foo<Trait>.\n+            let end = inverse_gep_index.len()-1;\n+            if end > start {\n+                let optimizing  = &mut inverse_gep_index[start..end];\n+                optimizing.sort_by_key(|&x| fields[x as usize].align(dl).abi());\n+            }\n+        }\n+        \n+        // At this point, inverse_gep_index holds field indices by increasing offset.\n+        // That is, if field 5 has offset 0, the first element of inverse_gep_index is 5.\n+        // We now write field offsets to the corresponding offset slot; field 5 with offset 0 puts 0 in offsets[5].\n+        // At the bottom of this function, we use inverse_gep_index to produce gep_index.\n \n-        let mut offset = self.min_size;\n+        let mut offset = Size::from_bytes(0);\n \n-        for field in fields {\n+        for i in inverse_gep_index.iter() {\n+            let field = fields[*i as usize];\n             if !self.sized {\n                 bug!(\"Struct::extend: field #{} of `{}` comes after unsized field\",\n                      self.offsets.len(), scapegoat);\n             }\n \n-            let field = field?;\n             if field.is_unsized() {\n                 self.sized = false;\n             }\n@@ -557,9 +593,10 @@ impl<'a, 'gcx, 'tcx> Struct {\n                 offset = offset.abi_align(align);\n             }\n \n-            self.offsets.push(offset);\n \n             debug!(\"Struct::extend offset: {:?} field: {:?} {:?}\", offset, field, field.size(dl));\n+            self.offsets[*i as usize] = offset;\n+\n \n             offset = offset.checked_add(field.size(dl), dl)\n                            .map_or(Err(LayoutError::SizeOverflow(scapegoat)), Ok)?;\n@@ -569,12 +606,21 @@ impl<'a, 'gcx, 'tcx> Struct {\n \n         self.min_size = offset;\n \n+        // As stated above, inverse_gep_index holds field indices by increasing offset.\n+        // This makes it an already-sorted view of the offsets vec.\n+        // To invert it, consider:\n+        // If field 5 has offset 0, offsets[0] is 5, and gep_index[5] should be 0.\n+        // Field 5 would be the first element, so gep_index is i:\n+        self.gep_index = vec![0; inverse_gep_index.len()];\n+\n+        for i in 0..inverse_gep_index.len() {\n+            self.gep_index[inverse_gep_index[i] as usize]  = i as u32;\n+        }\n+\n         Ok(())\n     }\n \n-    /// Get the size without trailing alignment padding.\n-\n-    /// Get the size with trailing aligment padding.\n+    /// Get the size with trailing alignment padding.\n     pub fn stride(&self) -> Size {\n         self.min_size.abi_align(self.align)\n     }\n@@ -592,10 +638,35 @@ impl<'a, 'gcx, 'tcx> Struct {\n         Ok(true)\n     }\n \n+    /// Get indices of the tys that made this struct by increasing offset.\n+    #[inline]\n+    pub fn field_index_by_increasing_offset<'b>(&'b self) -> impl iter::Iterator<Item=usize>+'b {\n+        let mut inverse_small = [0u8; 64];\n+        let mut inverse_big = vec![];\n+        let use_small = self.gep_index.len() <= inverse_small.len();\n+\n+        // We have to write this logic twice in order to keep the array small.\n+        if use_small {\n+            for i in 0..self.gep_index.len() {\n+                inverse_small[self.gep_index[i] as usize] = i as u8;\n+            }\n+        } else {\n+            inverse_big = vec![0; self.gep_index.len()];\n+            for i in 0..self.gep_index.len() {\n+                inverse_big[self.gep_index[i] as usize] = i as u32;\n+            }\n+        }\n+\n+        (0..self.gep_index.len()).map(move |i| {\n+            if use_small { inverse_small[i] as usize }\n+            else { inverse_big[i] as usize }\n+        })\n+    }\n+\n     /// Find the path leading to a non-zero leaf field, starting from\n     /// the given type and recursing through aggregates.\n     // FIXME(eddyb) track value ranges and traverse already optimized enums.\n-    pub fn non_zero_field_in_type(infcx: &InferCtxt<'a, 'gcx, 'tcx>,\n+    fn non_zero_field_in_type(infcx: &InferCtxt<'a, 'gcx, 'tcx>,\n                                   ty: Ty<'gcx>)\n                                   -> Result<Option<FieldPath>, LayoutError<'gcx>> {\n         let tcx = infcx.tcx.global_tcx();\n@@ -625,27 +696,30 @@ impl<'a, 'gcx, 'tcx> Struct {\n \n             // Perhaps one of the fields of this struct is non-zero\n             // let's recurse and find out\n-            (_, &ty::TyAdt(def, substs)) if def.is_struct() => {\n+            (&Univariant { ref variant, .. }, &ty::TyAdt(def, substs)) if def.is_struct() => {\n                 Struct::non_zero_field_path(infcx, def.struct_variant().fields\n                                                       .iter().map(|field| {\n                     field.ty(tcx, substs)\n-                }))\n+                }),\n+                Some(&variant.gep_index[..]))\n             }\n \n             // Perhaps one of the upvars of this closure is non-zero\n-            // Let's recurse and find out!\n-            (_, &ty::TyClosure(def_id, ref substs)) => {\n-                Struct::non_zero_field_path(infcx, substs.upvar_tys(def_id, tcx))\n+            (&Univariant { ref variant, .. }, &ty::TyClosure(def, substs)) => {\n+                let upvar_tys = substs.upvar_tys(def, tcx);\n+                Struct::non_zero_field_path(infcx, upvar_tys,\n+                    Some(&variant.gep_index[..]))\n             }\n             // Can we use one of the fields in this tuple?\n-            (_, &ty::TyTuple(tys)) => {\n-                Struct::non_zero_field_path(infcx, tys.iter().cloned())\n+            (&Univariant { ref variant, .. }, &ty::TyTuple(tys)) => {\n+                Struct::non_zero_field_path(infcx, tys.iter().cloned(),\n+                    Some(&variant.gep_index[..]))\n             }\n \n             // Is this a fixed-size array of something non-zero\n             // with at least one element?\n             (_, &ty::TyArray(ety, d)) if d > 0 => {\n-                Struct::non_zero_field_path(infcx, Some(ety).into_iter())\n+                Struct::non_zero_field_path(infcx, Some(ety).into_iter(), None)\n             }\n \n             (_, &ty::TyProjection(_)) | (_, &ty::TyAnon(..)) => {\n@@ -663,13 +737,19 @@ impl<'a, 'gcx, 'tcx> Struct {\n \n     /// Find the path leading to a non-zero leaf field, starting from\n     /// the given set of fields and recursing through aggregates.\n-    pub fn non_zero_field_path<I>(infcx: &InferCtxt<'a, 'gcx, 'tcx>,\n-                                  fields: I)\n+    fn non_zero_field_path<I>(infcx: &InferCtxt<'a, 'gcx, 'tcx>,\n+                                  fields: I,\n+                                  permutation: Option<&[u32]>)\n                                   -> Result<Option<FieldPath>, LayoutError<'gcx>>\n     where I: Iterator<Item=Ty<'gcx>> {\n         for (i, ty) in fields.enumerate() {\n             if let Some(mut path) = Struct::non_zero_field_in_type(infcx, ty)? {\n-                path.push(i as u32);\n+                let index = if let Some(p) = permutation {\n+                    p[i] as usize\n+                } else {\n+                    i\n+                };\n+                path.push(index as u32);\n                 return Ok(Some(path));\n             }\n         }\n@@ -723,7 +803,7 @@ impl<'a, 'gcx, 'tcx> Union {\n         Ok(())\n     }\n \n-    /// Get the size with trailing aligment padding.\n+    /// Get the size with trailing alignment padding.\n     pub fn stride(&self) -> Size {\n         self.min_size.abi_align(self.align)\n     }\n@@ -887,6 +967,7 @@ impl<'a, 'gcx, 'tcx> Layout {\n         let dl = &tcx.data_layout;\n         assert!(!ty.has_infer_types());\n \n+\n         let layout = match ty.sty {\n             // Basic scalars.\n             ty::TyBool => Scalar { value: Int(I1), non_zero: false },\n@@ -908,7 +989,7 @@ impl<'a, 'gcx, 'tcx> Layout {\n             ty::TyFnPtr(_) => Scalar { value: Pointer, non_zero: true },\n \n             // The never type.\n-            ty::TyNever => Univariant { variant: Struct::new(dl, false), non_zero: false },\n+            ty::TyNever => Univariant { variant: Struct::new(dl, iter::empty(), attr::ReprAny, false, ty)?, non_zero: false },\n \n             // Potentially-fat pointers.\n             ty::TyBox(pointee) |\n@@ -959,27 +1040,30 @@ impl<'a, 'gcx, 'tcx> Layout {\n             // Odd unit types.\n             ty::TyFnDef(..) => {\n                 Univariant {\n-                    variant: Struct::new(dl, false),\n+                    variant: Struct::new(dl, iter::empty(), attr::ReprAny, false, ty)?,\n                     non_zero: false\n                 }\n             }\n-            ty::TyDynamic(..) => {\n-                let mut unit = Struct::new(dl, false);\n+            ty::TyDynamic(_) => {\n+                let mut unit = Struct::new(dl, iter::empty(), attr::ReprAny, false, ty)?;\n                 unit.sized = false;\n                 Univariant { variant: unit, non_zero: false }\n             }\n \n             // Tuples and closures.\n             ty::TyClosure(def_id, ref substs) => {\n-                let mut st = Struct::new(dl, false);\n                 let tys = substs.upvar_tys(def_id, tcx);\n-                st.extend(dl, tys.map(|ty| ty.layout(infcx)), ty)?;\n+                let mut st = Struct::new(dl,\n+                    tys.map(|ty| ty.layout(infcx)),\n+                    attr::ReprAny,\n+                    false, ty)?;\n                 Univariant { variant: st, non_zero: false }\n             }\n \n             ty::TyTuple(tys) => {\n-                let mut st = Struct::new(dl, false);\n-                st.extend(dl, tys.iter().map(|ty| ty.layout(infcx)), ty)?;\n+                let st = Struct::new(dl,\n+                    tys.iter().map(|ty| ty.layout(infcx)),\n+                    attr::ReprAny, false, ty)?;\n                 Univariant { variant: st, non_zero: false }\n             }\n \n@@ -1012,7 +1096,7 @@ impl<'a, 'gcx, 'tcx> Layout {\n                     assert_eq!(hint, attr::ReprAny);\n \n                     return success(Univariant {\n-                        variant: Struct::new(dl, false),\n+                        variant: Struct::new(dl, iter::empty(), hint, false, ty)?,\n                         non_zero: false\n                     });\n                 }\n@@ -1050,8 +1134,7 @@ impl<'a, 'gcx, 'tcx> Layout {\n                         un.extend(dl, fields, ty)?;\n                         UntaggedUnion { variants: un }\n                     } else {\n-                        let mut st = Struct::new(dl, packed);\n-                        st.extend(dl, fields, ty)?;\n+                        let st = Struct::new(dl, fields, hint, false, ty)?;\n                         let non_zero = Some(def.did) == tcx.lang_items.non_zero();\n                         Univariant { variant: st, non_zero: non_zero }\n                     };\n@@ -1083,7 +1166,8 @@ impl<'a, 'gcx, 'tcx> Layout {\n                             continue;\n                         }\n                         let path = Struct::non_zero_field_path(infcx,\n-                            variants[discr].iter().cloned())?;\n+                            variants[discr].iter().cloned(),\n+                            None)?;\n                         let mut path = if let Some(p) = path { p } else { continue };\n \n                         // FIXME(eddyb) should take advantage of a newtype.\n@@ -1101,10 +1185,17 @@ impl<'a, 'gcx, 'tcx> Layout {\n                             });\n                         }\n \n+                        let st = Struct::new(dl,\n+                            variants[discr].iter().map(|ty| ty.layout(infcx)),\n+                            hint, false, ty)?;\n+\n+                        // We have to fix the last element of path here as only we know the right value.\n+                        let mut i = *path.last().unwrap();\n+                        i = st.gep_index[i as usize];\n+                        *path.last_mut().unwrap() = i;\n                         path.push(0); // For GEP through a pointer.\n                         path.reverse();\n-                        let mut st = Struct::new(dl, false);\n-                        st.extend(dl, variants[discr].iter().map(|ty| ty.layout(infcx)), ty)?;\n+\n                         return success(StructWrappedNullablePointer {\n                             nndiscr: discr as u64,\n                             nonnull: st,\n@@ -1126,24 +1217,25 @@ impl<'a, 'gcx, 'tcx> Layout {\n \n                 // Create the set of structs that represent each variant\n                 // Use the minimum integer type we figured out above\n-                let discr = Some(Scalar { value: Int(min_ity), non_zero: false });\n+                let discr = Scalar { value: Int(min_ity), non_zero: false };\n                 let mut variants = variants.into_iter().map(|fields| {\n-                    let mut found_start = false;\n-                    let fields = fields.into_iter().map(|field| {\n-                        let field = field.layout(infcx)?;\n-                        if !found_start {\n-                            // Find the first field we can't move later\n-                            // to make room for a larger discriminant.\n-                            let field_align = field.align(dl);\n-                            if field.size(dl).bytes() != 0 || field_align.abi() != 1 {\n-                                start_align = start_align.min(field_align);\n-                                found_start = true;\n-                            }\n+                    let mut fields = fields.into_iter().map(|field| {\n+                        field.layout(infcx)\n+                    }).collect::<Vec<_>>();\n+                    fields.insert(0, Ok(&discr));\n+                    let st = Struct::new(dl,\n+                        fields.iter().cloned(),\n+                        hint, false, ty)?;\n+                    // Find the first field we can't move later\n+                    // to make room for a larger discriminant.\n+                    for i in st.field_index_by_increasing_offset() {\n+                        let field = fields[i].unwrap();\n+                        let field_align = field.align(dl);\n+                        if field.size(dl).bytes() != 0 || field_align.abi() != 1 {\n+                            start_align = start_align.min(field_align);\n+                            break;\n                         }\n-                        Ok(field)\n-                    });\n-                    let mut st = Struct::new(dl, false);\n-                    st.extend(dl, discr.iter().map(Ok).chain(fields), ty)?;\n+                    }\n                     size = cmp::max(size, st.min_size);\n                     align = align.max(st.align);\n                     Ok(st)\n@@ -1177,11 +1269,10 @@ impl<'a, 'gcx, 'tcx> Layout {\n                     let old_ity_size = Int(min_ity).size(dl);\n                     let new_ity_size = Int(ity).size(dl);\n                     for variant in &mut variants {\n-                        for offset in &mut variant.offsets[1..] {\n-                            if *offset > old_ity_size {\n-                                break;\n+                        for i in variant.offsets.iter_mut() {\n+                            if *i <= old_ity_size {\n+                                *i = new_ity_size;\n                             }\n-                            *offset = new_ity_size;\n                         }\n                         // We might be making the struct larger.\n                         if variant.min_size <= old_ity_size {"}, {"sha": "0690bea6c2f851af663f3e2f638f05157b1e2b8c", "filename": "src/librustc_trans/adt.rs", "status": "modified", "additions": 24, "deletions": 18, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/cae94e8ec0971d6762fb06aa05c3d733e670abe5/src%2Flibrustc_trans%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cae94e8ec0971d6762fb06aa05c3d733e670abe5/src%2Flibrustc_trans%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fadt.rs?ref=cae94e8ec0971d6762fb06aa05c3d733e670abe5", "patch": "@@ -151,14 +151,14 @@ pub fn finish_type_of<'a, 'tcx>(cx: &CrateContext<'a, 'tcx>,\n         | layout::UntaggedUnion { .. } | layout::RawNullablePointer { .. } => { }\n         layout::Univariant { ..}\n         | layout::StructWrappedNullablePointer { .. } => {\n-            let (nonnull_variant, packed) = match *l {\n-                layout::Univariant { ref variant, .. } => (0, variant.packed),\n+            let (nonnull_variant_index, nonnull_variant, packed) = match *l {\n+                layout::Univariant { ref variant, .. } => (0, variant, variant.packed),\n                 layout::StructWrappedNullablePointer { nndiscr, ref nonnull, .. } =>\n-                    (nndiscr, nonnull.packed),\n+                    (nndiscr, nonnull, nonnull.packed),\n                 _ => unreachable!()\n             };\n-            let fields = compute_fields(cx, t, nonnull_variant as usize, true);\n-            llty.set_struct_body(&struct_llfields(cx, &fields, false, false),\n+            let fields = compute_fields(cx, t, nonnull_variant_index as usize, true);\n+            llty.set_struct_body(&struct_llfields(cx, &fields, nonnull_variant, false, false),\n                                  packed)\n         },\n         _ => bug!(\"This function cannot handle {} with layout {:#?}\", t, l)\n@@ -188,7 +188,7 @@ fn generic_type_of<'a, 'tcx>(cx: &CrateContext<'a, 'tcx>,\n             let fields = compute_fields(cx, t, nndiscr as usize, false);\n             match name {\n                 None => {\n-                    Type::struct_(cx, &struct_llfields(cx, &fields, sizing, dst),\n+                    Type::struct_(cx, &struct_llfields(cx, &fields, nonnull, sizing, dst),\n                                   nonnull.packed)\n                 }\n                 Some(name) => {\n@@ -203,7 +203,7 @@ fn generic_type_of<'a, 'tcx>(cx: &CrateContext<'a, 'tcx>,\n             let fields = compute_fields(cx, t, 0, true);\n             match name {\n                 None => {\n-                    let fields = struct_llfields(cx, &fields, sizing, dst);\n+                    let fields = struct_llfields(cx, &fields, &variant, sizing, dst);\n                     Type::struct_(cx, &fields, variant.packed)\n                 }\n                 Some(name) => {\n@@ -291,12 +291,14 @@ fn union_fill(cx: &CrateContext, size: u64, align: u64) -> Type {\n \n \n fn struct_llfields<'a, 'tcx>(cx: &CrateContext<'a, 'tcx>, fields: &Vec<Ty<'tcx>>,\n+                             variant: &layout::Struct,\n                              sizing: bool, dst: bool) -> Vec<Type> {\n+    let fields = variant.field_index_by_increasing_offset().map(|i| fields[i as usize]);\n     if sizing {\n-        fields.iter().filter(|&ty| !dst || type_is_sized(cx.tcx(), *ty))\n-            .map(|&ty| type_of::sizing_type_of(cx, ty)).collect()\n+        fields.filter(|ty| !dst || type_is_sized(cx.tcx(), *ty))\n+            .map(|ty| type_of::sizing_type_of(cx, ty)).collect()\n     } else {\n-        fields.iter().map(|&ty| type_of::in_memory_type_of(cx, ty)).collect()\n+        fields.map(|ty| type_of::in_memory_type_of(cx, ty)).collect()\n     }\n }\n \n@@ -564,16 +566,16 @@ pub fn trans_field_ptr_builder<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n fn struct_field_ptr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                 st: &layout::Struct, fields: &Vec<Ty<'tcx>>, val: MaybeSizedValue,\n                                 ix: usize, needs_cast: bool) -> ValueRef {\n-    let ccx = bcx.ccx();\n     let fty = fields[ix];\n+    let ccx = bcx.ccx();\n     let ll_fty = type_of::in_memory_type_of(bcx.ccx(), fty);\n     if bcx.is_unreachable() {\n         return C_undef(ll_fty.ptr_to());\n     }\n \n     let ptr_val = if needs_cast {\n-        let fields = fields.iter().map(|&ty| {\n-            type_of::in_memory_type_of(ccx, ty)\n+        let fields = st.field_index_by_increasing_offset().map(|i| {\n+            type_of::in_memory_type_of(ccx, fields[i])\n         }).collect::<Vec<_>>();\n         let real_ty = Type::struct_(ccx, &fields[..], st.packed);\n         bcx.pointercast(val.value, real_ty.ptr_to())\n@@ -585,15 +587,15 @@ fn struct_field_ptr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n     //   * First field - Always aligned properly\n     //   * Packed struct - There is no alignment padding\n     //   * Field is sized - pointer is properly aligned already\n-    if ix == 0 || st.packed || type_is_sized(bcx.tcx(), fty) {\n-        return bcx.struct_gep(ptr_val, ix);\n+    if st.offsets[ix] == layout::Size::from_bytes(0) || st.packed || type_is_sized(bcx.tcx(), fty) {\n+        return bcx.struct_gep(ptr_val, st.gep_index[ix] as usize);\n     }\n \n     // If the type of the last field is [T] or str, then we don't need to do\n     // any adjusments\n     match fty.sty {\n         ty::TySlice(..) | ty::TyStr => {\n-            return bcx.struct_gep(ptr_val, ix);\n+            return bcx.struct_gep(ptr_val, st.gep_index[ix] as usize);\n         }\n         _ => ()\n     }\n@@ -755,8 +757,12 @@ fn build_const_struct<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n     // offset of current value\n     let mut offset = 0;\n     let mut cfields = Vec::new();\n-    let offsets = st.offsets.iter().map(|i| i.bytes());\n-    for (&val, target_offset) in vals.iter().zip(offsets) {\n+    cfields.reserve(st.offsets.len()*2);\n+\n+    let parts = st.field_index_by_increasing_offset().map(|i| {\n+        (&vals[i], st.offsets[i].bytes())\n+    });\n+    for (&val, target_offset) in parts {\n         if offset < target_offset {\n             cfields.push(padding(ccx, target_offset - offset));\n             offset = target_offset;"}, {"sha": "c379ec7da90e104248bfaaf7ef80b783c5193ea3", "filename": "src/librustc_trans/base.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/cae94e8ec0971d6762fb06aa05c3d733e670abe5/src%2Flibrustc_trans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cae94e8ec0971d6762fb06aa05c3d733e670abe5/src%2Flibrustc_trans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbase.rs?ref=cae94e8ec0971d6762fb06aa05c3d733e670abe5", "patch": "@@ -827,7 +827,9 @@ pub fn alloca(cx: Block, ty: Type, name: &str) -> ValueRef {\n         }\n     }\n     DebugLoc::None.apply(cx.fcx);\n-    Alloca(cx, ty, name)\n+    let result = Alloca(cx, ty, name);\n+    debug!(\"alloca({:?}) = {:?}\", name, result);\n+    result\n }\n \n impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {"}]}