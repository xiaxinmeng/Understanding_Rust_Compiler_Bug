{"sha": "cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNkN2E0MjhiNWU1NTA4ZDQzZGVhYmRkMWExZDNhNmU3NzZmNTQ5Mjk=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2020-02-09T14:54:38Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2020-02-09T21:08:53Z"}, "message": "parser: Keep current and previous tokens precisely\n\nincluding their unnormalized forms.\nAdd more documentation for them.", "tree": {"sha": "4bdacacb2ec89e500b11e547c6b101bc6dcdd742", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4bdacacb2ec89e500b11e547c6b101bc6dcdd742"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "html_url": "https://github.com/rust-lang/rust/commit/cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1ad6b5e1e69ad3d3509abd8c041bb9fb2dd86c41", "url": "https://api.github.com/repos/rust-lang/rust/commits/1ad6b5e1e69ad3d3509abd8c041bb9fb2dd86c41", "html_url": "https://github.com/rust-lang/rust/commit/1ad6b5e1e69ad3d3509abd8c041bb9fb2dd86c41"}], "stats": {"total": 80, "additions": 54, "deletions": 26}, "files": [{"sha": "7131eb1144e0669cae5f53c43b8b4f3d6746d7f7", "filename": "src/librustc_parse/parser/mod.rs", "status": "modified", "additions": 51, "deletions": 23, "changes": 74, "blob_url": "https://github.com/rust-lang/rust/blob/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fmod.rs?ref=cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "patch": "@@ -95,23 +95,32 @@ enum PrevTokenKind {\n     Other,\n }\n \n-// NOTE: `Ident`s are handled by `common.rs`.\n-\n #[derive(Clone)]\n pub struct Parser<'a> {\n     pub sess: &'a ParseSess,\n     /// The current normalized token.\n     /// \"Normalized\" means that some interpolated tokens\n     /// (`$i: ident` and `$l: lifetime` meta-variables) are replaced\n     /// with non-interpolated identifier and lifetime tokens they refer to.\n-    /// Perhaps the normalized / non-normalized setup can be simplified somehow.\n+    /// Use span from this token if you need an isolated span.\n     pub token: Token,\n-    /// The span of the current non-normalized token.\n-    meta_var_span: Option<Span>,\n-    /// The span of the previous non-normalized token.\n-    pub prev_span: Span,\n-    /// The kind of the previous normalized token (in simplified form).\n+    /// The current non-normalized token if it's different from `token`.\n+    /// Preferable use is through the `unnormalized_token()` getter.\n+    /// Use span from this token if you need to concatenate it with some neighbouring spans.\n+    unnormalized_token: Option<Token>,\n+    /// The previous normalized token.\n+    /// Use span from this token if you need an isolated span.\n+    prev_token: Token,\n+    /// The previous non-normalized token if it's different from `prev_token`.\n+    /// Preferable use is through the `unnormalized_prev_token()` getter.\n+    /// Use span from this token if you need to concatenate it with some neighbouring spans.\n+    unnormalized_prev_token: Option<Token>,\n+    /// Equivalent to `prev_token.kind` in simplified form.\n+    /// FIXME: Remove in favor of `(unnormalized_)prev_token().kind`.\n     prev_token_kind: PrevTokenKind,\n+    /// Equivalent to `unnormalized_prev_token().span`.\n+    /// FIXME: Remove in favor of `(unnormalized_)prev_token().span`.\n+    pub prev_span: Span,\n     restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files.\n     pub(super) directory: Directory<'a>,\n@@ -384,9 +393,11 @@ impl<'a> Parser<'a> {\n         let mut parser = Parser {\n             sess,\n             token: Token::dummy(),\n-            prev_span: DUMMY_SP,\n-            meta_var_span: None,\n+            unnormalized_token: None,\n+            prev_token: Token::dummy(),\n+            unnormalized_prev_token: None,\n             prev_token_kind: PrevTokenKind::Other,\n+            prev_span: DUMMY_SP,\n             restrictions: Restrictions::empty(),\n             recurse_into_file_modules,\n             directory: Directory {\n@@ -427,6 +438,14 @@ impl<'a> Parser<'a> {\n         parser\n     }\n \n+    fn unnormalized_token(&self) -> &Token {\n+        self.unnormalized_token.as_ref().unwrap_or(&self.token)\n+    }\n+\n+    fn unnormalized_prev_token(&self) -> &Token {\n+        self.unnormalized_prev_token.as_ref().unwrap_or(&self.prev_token)\n+    }\n+\n     fn next_tok(&mut self) -> Token {\n         let mut next = if self.desugar_doc_comments {\n             self.token_cursor.next_desugared()\n@@ -435,7 +454,7 @@ impl<'a> Parser<'a> {\n         };\n         if next.span.is_dummy() {\n             // Tweak the location for better diagnostics, but keep syntactic context intact.\n-            next.span = self.prev_span.with_ctxt(next.span.ctxt());\n+            next.span = self.unnormalized_token().span.with_ctxt(next.span.ctxt());\n         }\n         next\n     }\n@@ -895,10 +914,13 @@ impl<'a> Parser<'a> {\n             self.span_bug(self.token.span, msg);\n         }\n \n-        self.prev_span = self.meta_var_span.take().unwrap_or(self.token.span);\n+        // Update the current and previous tokens.\n+        let next_token = self.next_tok();\n+        self.prev_token = mem::replace(&mut self.token, next_token);\n+        self.unnormalized_prev_token = self.unnormalized_token.take();\n \n-        // Record last token kind for possible error recovery.\n-        self.prev_token_kind = match self.token.kind {\n+        // Update fields derived from the previous token.\n+        self.prev_token_kind = match self.prev_token.kind {\n             token::DocComment(..) => PrevTokenKind::DocComment,\n             token::Comma => PrevTokenKind::Comma,\n             token::BinOp(token::Plus) => PrevTokenKind::Plus,\n@@ -908,22 +930,28 @@ impl<'a> Parser<'a> {\n             token::Ident(..) => PrevTokenKind::Ident,\n             _ => PrevTokenKind::Other,\n         };\n+        self.prev_span = self.unnormalized_prev_token().span;\n \n-        self.token = self.next_tok();\n         self.expected_tokens.clear();\n         // Check after each token.\n         self.process_potential_macro_variable();\n     }\n \n     /// Advances the parser using provided token as a next one. Use this when\n     /// consuming a part of a token. For example a single `<` from `<<`.\n+    /// FIXME: this function sets the previous token data to some semi-nonsensical values\n+    /// which kind of work because they are currently used in very limited ways in practice.\n+    /// Correct token kinds and spans need to be calculated instead.\n     fn bump_with(&mut self, next: TokenKind, span: Span) {\n-        self.prev_span = self.token.span.with_hi(span.lo());\n-        // It would be incorrect to record the kind of the current token, but\n-        // fortunately for tokens currently using `bump_with`, the\n-        // `prev_token_kind` will be of no use anyway.\n+        // Update the current and previous tokens.\n+        let next_token = Token::new(next, span);\n+        self.prev_token = mem::replace(&mut self.token, next_token);\n+        self.unnormalized_prev_token = self.unnormalized_token.take();\n+\n+        // Update fields derived from the previous token.\n         self.prev_token_kind = PrevTokenKind::Other;\n-        self.token = Token::new(next, span);\n+        self.prev_span = self.unnormalized_prev_token().span.with_hi(span.lo());\n+\n         self.expected_tokens.clear();\n     }\n \n@@ -1054,7 +1082,7 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn process_potential_macro_variable(&mut self) {\n-        self.token = match self.token.kind {\n+        let normalized_token = match self.token.kind {\n             token::Dollar\n                 if self.token.span.from_expansion() && self.look_ahead(1, |t| t.is_ident()) =>\n             {\n@@ -1071,7 +1099,6 @@ impl<'a> Parser<'a> {\n                 return;\n             }\n             token::Interpolated(ref nt) => {\n-                self.meta_var_span = Some(self.token.span);\n                 // Interpolated identifier and lifetime tokens are replaced with usual identifier\n                 // and lifetime tokens, so the former are never encountered during normal parsing.\n                 match **nt {\n@@ -1084,6 +1111,7 @@ impl<'a> Parser<'a> {\n             }\n             _ => return,\n         };\n+        self.unnormalized_token = Some(mem::replace(&mut self.token, normalized_token));\n     }\n \n     /// Parses a single token tree from the input.\n@@ -1100,7 +1128,7 @@ impl<'a> Parser<'a> {\n             }\n             token::CloseDelim(_) | token::Eof => unreachable!(),\n             _ => {\n-                let token = self.token.take();\n+                let token = self.token.clone();\n                 self.bump();\n                 TokenTree::Token(token)\n             }"}, {"sha": "761c06b70ee8bdb212d9a25a51500a8d4d831c45", "filename": "src/librustc_parse/parser/path.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/src%2Flibrustc_parse%2Fparser%2Fpath.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/src%2Flibrustc_parse%2Fparser%2Fpath.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fpath.rs?ref=cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "patch": "@@ -134,7 +134,7 @@ impl<'a> Parser<'a> {\n             path\n         });\n \n-        let lo = self.meta_var_span.unwrap_or(self.token.span);\n+        let lo = self.unnormalized_token().span;\n         let mut segments = Vec::new();\n         let mod_sep_ctxt = self.token.span.ctxt();\n         if self.eat(&token::ModSep) {"}, {"sha": "ec04b937b9ace73aba14a438058791a7c8a89bd1", "filename": "src/test/ui/parser/mbe_missing_right_paren.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/src%2Ftest%2Fui%2Fparser%2Fmbe_missing_right_paren.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/cd7a428b5e5508d43deabdd1a1d3a6e776f54929/src%2Ftest%2Fui%2Fparser%2Fmbe_missing_right_paren.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fmbe_missing_right_paren.stderr?ref=cd7a428b5e5508d43deabdd1a1d3a6e776f54929", "patch": "@@ -22,10 +22,10 @@ LL | macro_rules! abc(\u063c;\n    |                   ^\n \n error: unexpected end of macro invocation\n-  --> $DIR/mbe_missing_right_paren.rs:3:1\n+  --> $DIR/mbe_missing_right_paren.rs:3:19\n    |\n LL | macro_rules! abc(\u063c\n-   | ^^^^^^^^^^^^^^^^^^ missing tokens in macro arguments\n+   |                   ^ missing tokens in macro arguments\n \n error: aborting due to 3 previous errors\n "}]}