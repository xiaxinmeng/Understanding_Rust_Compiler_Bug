{"sha": "0d7f193dd358cdc13506cac2e0b84fc473b628be", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBkN2YxOTNkZDM1OGNkYzEzNTA2Y2FjMmUwYjg0ZmM0NzNiNjI4YmU=", "commit": {"author": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-20T02:47:39Z"}, "committer": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-26T20:47:24Z"}, "message": "Added a bunch of comments to macro_parser.rs", "tree": {"sha": "f72b48ce78b61af38c7eea720014ed971b609440", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f72b48ce78b61af38c7eea720014ed971b609440"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0d7f193dd358cdc13506cac2e0b84fc473b628be", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0d7f193dd358cdc13506cac2e0b84fc473b628be", "html_url": "https://github.com/rust-lang/rust/commit/0d7f193dd358cdc13506cac2e0b84fc473b628be", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0d7f193dd358cdc13506cac2e0b84fc473b628be/comments", "author": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ac0c16d3b5cc5644b3311811e127411b87f3abf0", "url": "https://api.github.com/repos/rust-lang/rust/commits/ac0c16d3b5cc5644b3311811e127411b87f3abf0", "html_url": "https://github.com/rust-lang/rust/commit/ac0c16d3b5cc5644b3311811e127411b87f3abf0"}], "stats": {"total": 72, "additions": 62, "deletions": 10}, "files": [{"sha": "cb671d75a002fdd6a363642a038173177f72b1d5", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 62, "deletions": 10, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/0d7f193dd358cdc13506cac2e0b84fc473b628be/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d7f193dd358cdc13506cac2e0b84fc473b628be/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=0d7f193dd358cdc13506cac2e0b84fc473b628be", "patch": "@@ -429,22 +429,46 @@ fn inner_parse_loop(\n     Success(())\n }\n \n+/// Parse the given set of token trees (`ms`), possibly consuming additional token trees from the\n+/// tokenstream (`tts`).\n+///\n+/// # Parameters\n+///\n+/// - `sess`: The session into which errors are emitted\n+/// - `tts`: The tokenstream from which additional token trees may be consumed if needed\n+/// - `ms`: The token trees we want to parse as macros\n+/// - `directory`: Information about the file locations (needed for the black-box parser)\n+/// - `recurse_into_modules`: Whether or not to recurse into modules (needed for the black-box\n+///   parser)\n pub fn parse(\n     sess: &ParseSess,\n     tts: TokenStream,\n     ms: &[TokenTree],\n     directory: Option<Directory>,\n     recurse_into_modules: bool,\n ) -> NamedParseResult {\n+    // Create a parser that can be used for the \"black box\" parts.\n     let mut parser = Parser::new(sess, tts, directory, recurse_into_modules, true);\n+\n+    // A queue of possible matcher positions. We initialize it with the matcher position in which\n+    // the \"dot\" is before the first token of the first token tree. `inner_parse_loop` then\n+    // processes all of these possible matcher positions and produces posible next positions into\n+    // `next_items`. After some post-processing, the contents of `next_items` replenish\n+    // `cur_items` and we start over again.\n     let mut cur_items = SmallVector::one(initial_matcher_pos(ms.to_owned(), parser.span.lo()));\n-    let mut next_items = Vec::new(); // or proceed normally\n+    let mut next_items = Vec::new();\n \n     loop {\n-        let mut bb_items = SmallVector::new(); // black-box parsed by parser.rs\n+        // Matcher positions black-box parsed by parser.rs (`parser`)\n+        let mut bb_items = SmallVector::new();\n+\n+        // Matcher positions that would be valid if the macro invocation was over now\n         let mut eof_items = SmallVector::new();\n         assert!(next_items.is_empty());\n \n+        // Process `cur_items` until either we have finished the input or we need to get some\n+        // parsing from the black-box parser done. The result is that `next_items` will contain a\n+        // bunch of possible next matcher positions in `next_items`.\n         match inner_parse_loop(\n             sess,\n             &mut cur_items,\n@@ -462,7 +486,12 @@ pub fn parse(\n         // inner parse loop handled all cur_items, so it's empty\n         assert!(cur_items.is_empty());\n \n-        /* error messages here could be improved with links to orig. rules */\n+        // We need to do some post processing after the `inner_parser_loop`.\n+        //\n+        // Error messages here could be improved with links to original rules.\n+\n+        // If we reached the EOF, check that there is EXACTLY ONE possible matcher. Otherwise,\n+        // either the parse is ambiguous (which should never happen) or their is a syntax error.\n         if token_name_eq(&parser.token, &token::Eof) {\n             if eof_items.len() == 1 {\n                 let matches = eof_items[0]\n@@ -478,7 +507,10 @@ pub fn parse(\n             } else {\n                 return Failure(parser.span, token::Eof);\n             }\n-        } else if (!bb_items.is_empty() && !next_items.is_empty()) || bb_items.len() > 1 {\n+        }\n+        // Another possibility is that we need to call out to parse some rust nonterminal\n+        // (black-box) parser. However, if there is not EXACTLY ONE of these, something is wrong.\n+        else if (!bb_items.is_empty() && !next_items.is_empty()) || bb_items.len() > 1 {\n             let nts = bb_items\n                 .iter()\n                 .map(|item| match item.top_elts.get_tt(item.idx) {\n@@ -499,15 +531,23 @@ pub fn parse(\n                     }\n                 ),\n             );\n-        } else if bb_items.is_empty() && next_items.is_empty() {\n+        }\n+        // If there are no posible next positions AND we aren't waiting for the black-box parser,\n+        // then their is a syntax error.\n+        else if bb_items.is_empty() && next_items.is_empty() {\n             return Failure(parser.span, parser.token);\n-        } else if !next_items.is_empty() {\n-            /* Now process the next token */\n+        }\n+        // Dump all possible `next_items` into `cur_items` for the next iteration.\n+        else if !next_items.is_empty() {\n+            // Now process the next token\n             cur_items.extend(next_items.drain(..));\n             parser.bump();\n-        } else\n-        /* bb_items.len() == 1 */\n-        {\n+        }\n+        // Finally, we have the case where we need to call the black-box parser to get some\n+        // nonterminal.\n+        else {\n+            assert_eq!(bb_items.len(), 1);\n+\n             let mut item = bb_items.pop().unwrap();\n             if let TokenTree::MetaVarDecl(span, _, ident) = item.top_elts.get_tt(item.idx) {\n                 let match_cur = item.match_cur;\n@@ -595,6 +635,18 @@ fn may_begin_with(name: &str, token: &Token) -> bool {\n     }\n }\n \n+/// A call to the \"black-box\" parser to parse some rust nonterminal.\n+///\n+/// # Parameters\n+///\n+/// - `p`: the \"black-box\" parser to use\n+/// - `sp`: the `Span` we want to parse\n+/// - `name`: the name of the metavar _matcher_ we want to match (e.g. `tt`, `ident`, `block`,\n+///   etc...)\n+///\n+/// # Returns\n+///\n+/// The parsed nonterminal.\n fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n     if name == \"tt\" {\n         return token::NtTT(p.parse_token_tree());"}]}