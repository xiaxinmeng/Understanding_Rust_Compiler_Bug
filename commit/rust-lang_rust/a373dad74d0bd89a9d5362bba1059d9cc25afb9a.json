{"sha": "a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "node_id": "MDY6Q29tbWl0NzI0NzEyOmEzNzNkYWQ3NGQwYmQ4OWE5ZDUzNjJiYmExMDU5ZDljYzI1YWZiOWE=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2013-05-29T22:55:23Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2013-05-30T00:00:05Z"}, "message": "core::rt: Outline the full multithreaded scheduling algo. Implement sleeping", "tree": {"sha": "d1a2f67e2d0a9249ca007c823ef758587e11fdeb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d1a2f67e2d0a9249ca007c823ef758587e11fdeb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "html_url": "https://github.com/rust-lang/rust/commit/a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5043ea269da73e96fbadc7c443aec01f087dabe9", "url": "https://api.github.com/repos/rust-lang/rust/commits/5043ea269da73e96fbadc7c443aec01f087dabe9", "html_url": "https://github.com/rust-lang/rust/commit/5043ea269da73e96fbadc7c443aec01f087dabe9"}], "stats": {"total": 243, "additions": 162, "deletions": 81}, "files": [{"sha": "21711bbe84c7095acb0e99a620aba116112d1e6c", "filename": "src/libcore/rt/message_queue.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Fmessage_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Fmessage_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Frt%2Fmessage_queue.rs?ref=a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "patch": "@@ -8,6 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+//! A concurrent queue that supports multiple producers and a\n+//! single consumer.\n+\n use container::Container;\n use kinds::Owned;\n use vec::OwnedVector;"}, {"sha": "e23ad76a8c610ec2b54fd3639e9a551252509778", "filename": "src/libcore/rt/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Frt%2Fmod.rs?ref=a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "patch": "@@ -158,6 +158,7 @@ pub fn start(_argc: int, _argv: **u8, crate_map: *u8, main: ~fn()) -> int {\n     let work_queue = WorkQueue::new();\n     let sleepers = SleeperList::new();\n     let mut sched = ~Scheduler::new(loop_, work_queue, sleepers);\n+    sched.no_sleep = true;\n     let main_task = ~Coroutine::new(&mut sched.stack_pool, main);\n \n     sched.enqueue_task(main_task);"}, {"sha": "c6d6bb9f39e50c56a375bc14ecc27a2a426d8395", "filename": "src/libcore/rt/sched.rs", "status": "modified", "additions": 145, "deletions": 77, "changes": 222, "blob_url": "https://github.com/rust-lang/rust/blob/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Frt%2Fsched.rs?ref=a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "patch": "@@ -12,16 +12,18 @@ use option::*;\n use sys;\n use cast::transmute;\n use cell::Cell;\n+use clone::Clone;\n \n use super::sleeper_list::SleeperList;\n use super::work_queue::WorkQueue;\n use super::stack::{StackPool, StackSegment};\n use super::rtio::{EventLoop, EventLoopObject, RemoteCallbackObject};\n use super::context::Context;\n use super::task::Task;\n+use super::message_queue::MessageQueue;\n use rt::local_ptr;\n use rt::local::Local;\n-use rt::rtio::IoFactoryObject;\n+use rt::rtio::{IoFactoryObject, RemoteCallback};\n \n /// The Scheduler is responsible for coordinating execution of Coroutines\n /// on a single thread. When the scheduler is running it is owned by\n@@ -31,9 +33,23 @@ pub struct Scheduler {\n     /// A queue of available work. Under a work-stealing policy there\n     /// is one per Scheduler.\n     priv work_queue: WorkQueue<~Coroutine>,\n+    /// The queue of incoming messages from other schedulers.\n+    /// These are enqueued by SchedHandles after which a remote callback\n+    /// is triggered to handle the message.\n+    priv message_queue: MessageQueue<SchedMessage>,\n     /// A shared list of sleeping schedulers. We'll use this to wake\n     /// up schedulers when pushing work onto the work queue.\n     priv sleeper_list: SleeperList,\n+    /// Indicates that we have previously pushed a handle onto the\n+    /// SleeperList but have not yet received the Wake message.\n+    /// Being `true` does not necessarily mean that the scheduler is\n+    /// not active since there are multiple event sources that may\n+    /// wake the scheduler. It just prevents the scheduler from pushing\n+    /// multiple handles onto the sleeper list.\n+    priv sleepy: bool,\n+    /// A flag to indicate we've received the shutdown message and should\n+    /// no longer try to go to sleep, but exit instead.\n+    no_sleep: bool,\n     stack_pool: StackPool,\n     /// The event loop used to drive the scheduler and perform I/O\n     event_loop: ~EventLoopObject,\n@@ -47,6 +63,11 @@ pub struct Scheduler {\n     priv cleanup_job: Option<CleanupJob>\n }\n \n+pub struct SchedHandle {\n+    priv remote: ~RemoteCallbackObject,\n+    priv queue: MessageQueue<SchedMessage>\n+}\n+\n pub struct Coroutine {\n     /// The segment of stack on which the task is currently running or,\n     /// if the task is blocked, on which the task will resume execution\n@@ -58,8 +79,9 @@ pub struct Coroutine {\n     task: ~Task\n }\n \n-pub struct SchedHandle {\n-    priv remote: ~RemoteCallbackObject\n+pub enum SchedMessage {\n+    Wake,\n+    Shutdown\n }\n \n enum CleanupJob {\n@@ -81,12 +103,15 @@ pub impl Scheduler {\n \n         Scheduler {\n             sleeper_list: sleeper_list,\n+            message_queue: MessageQueue::new(),\n+            sleepy: false,\n+            no_sleep: false,\n             event_loop: event_loop,\n             work_queue: work_queue,\n             stack_pool: StackPool::new(),\n             saved_context: Context::empty(),\n             current_task: None,\n-            cleanup_job: None\n+            cleanup_job: None,\n         }\n     }\n \n@@ -116,17 +141,51 @@ pub impl Scheduler {\n         return sched;\n     }\n \n+    fn run_sched_once() {\n+\n+        let sched = Local::take::<Scheduler>();\n+        if sched.interpret_message_queue() {\n+            // We performed a scheduling action. There may be other work\n+            // to do yet, so let's try again later.\n+            let mut sched = Local::take::<Scheduler>();\n+            sched.event_loop.callback(Scheduler::run_sched_once);\n+            Local::put(sched);\n+            return;\n+        }\n+\n+        let sched = Local::take::<Scheduler>();\n+        if sched.resume_task_from_queue() {\n+            // We performed a scheduling action. There may be other work\n+            // to do yet, so let's try again later.\n+            let mut sched = Local::take::<Scheduler>();\n+            sched.event_loop.callback(Scheduler::run_sched_once);\n+            Local::put(sched);\n+            return;\n+        }\n+\n+        // If we got here then there was no work to do.\n+        // Generate a SchedHandle and push it to the sleeper list so\n+        // somebody can wake us up later.\n+        rtdebug!(\"no work to do\");\n+        let mut sched = Local::take::<Scheduler>();\n+        if !sched.sleepy && !sched.no_sleep {\n+            rtdebug!(\"sleeping\");\n+            sched.sleepy = true;\n+            let handle = sched.make_handle();\n+            sched.sleeper_list.push(handle);\n+        } else {\n+            rtdebug!(\"not sleeping\");\n+        }\n+        Local::put(sched);\n+    }\n+\n     fn make_handle(&mut self) -> SchedHandle {\n-        let remote = self.event_loop.remote_callback(wake_up);\n+        let remote = self.event_loop.remote_callback(Scheduler::run_sched_once);\n \n         return SchedHandle {\n-            remote: remote\n+            remote: remote,\n+            queue: self.message_queue.clone()\n         };\n-\n-        fn wake_up() {\n-            let sched = Local::take::<Scheduler>();\n-            sched.resume_task_from_queue();\n-        }\n     }\n \n     /// Schedule a task to be executed later.\n@@ -136,17 +195,63 @@ pub impl Scheduler {\n     /// directly.\n     fn enqueue_task(&mut self, task: ~Coroutine) {\n         self.work_queue.push(task);\n-        self.event_loop.callback(resume_task_from_queue);\n+        self.event_loop.callback(Scheduler::run_sched_once);\n \n-        fn resume_task_from_queue() {\n-            let sched = Local::take::<Scheduler>();\n-            sched.resume_task_from_queue();\n+        // We've made work available. Notify a sleeping scheduler.\n+        match self.sleeper_list.pop() {\n+            Some(handle) => {\n+                let mut handle = handle;\n+                handle.send(Wake)\n+            }\n+            None => (/* pass */)\n         }\n     }\n \n     // * Scheduler-context operations\n \n-    fn resume_task_from_queue(~self) {\n+    fn interpret_message_queue(~self) -> bool {\n+        assert!(!self.in_task_context());\n+\n+        rtdebug!(\"looking for scheduler messages\");\n+\n+        let mut this = self;\n+        match this.message_queue.pop() {\n+            Some(Wake) => {\n+                rtdebug!(\"recv Wake message\");\n+                this.sleepy = false;\n+                Local::put(this);\n+                return true;\n+            }\n+            Some(Shutdown) => {\n+                rtdebug!(\"recv Shutdown message\");\n+                if this.sleepy {\n+                    // There may be an outstanding handle on the sleeper list.\n+                    // Pop them all to make sure that's not the case.\n+                    loop {\n+                        match this.sleeper_list.pop() {\n+                            Some(handle) => {\n+                                let mut handle = handle;\n+                                handle.send(Wake);\n+                            }\n+                            None => (/* pass */)\n+                        }\n+                    }\n+                }\n+                // No more sleeping. After there are no outstanding event loop\n+                // references we will shut down.\n+                this.no_sleep = true;\n+                this.sleepy = false;\n+                Local::put(this);\n+                return true;\n+            }\n+            None => {\n+                Local::put(this);\n+                return false;\n+            }\n+        }\n+    }\n+\n+    fn resume_task_from_queue(~self) -> bool {\n         assert!(!self.in_task_context());\n \n         rtdebug!(\"looking in work queue for task to schedule\");\n@@ -156,10 +261,12 @@ pub impl Scheduler {\n             Some(task) => {\n                 rtdebug!(\"resuming task from work queue\");\n                 this.resume_task_immediately(task);\n+                return true;\n             }\n             None => {\n                 rtdebug!(\"no tasks in queue\");\n                 Local::put(this);\n+                return false;\n             }\n         }\n     }\n@@ -363,6 +470,13 @@ pub impl Scheduler {\n     }\n }\n \n+impl SchedHandle {\n+    pub fn send(&mut self, msg: SchedMessage) {\n+        self.queue.push(msg);\n+        self.remote.fire();\n+    }\n+}\n+\n pub impl Coroutine {\n     fn new(stack_pool: &mut StackPool, start: ~fn()) -> Coroutine {\n         Coroutine::with_task(stack_pool, ~Task::new(), start)\n@@ -621,71 +735,25 @@ mod test {\n \n     #[test]\n     fn multithreading() {\n-        use clone::Clone;\n-        use iter::Times;\n-        use rt::work_queue::WorkQueue;\n         use rt::comm::*;\n-        use container::Container;\n+        use iter::Times;\n         use vec::OwnedVector;\n-        use rt::rtio::RemoteCallback;\n-        use rt::sleeper_list::SleeperList;\n-\n-        do run_in_bare_thread {\n-            let sleepers1 = SleeperList::new();\n-            let work_queue1 = WorkQueue::new();\n-\n-            let sleepers2 = sleepers1.clone();\n-            let work_queue2 = work_queue1.clone();\n-\n-            let loop1 = ~UvEventLoop::new();\n-            let mut sched1 = ~Scheduler::new(loop1, work_queue1.clone(), sleepers1);\n-            let handle1 = sched1.make_handle();\n-            let sched1_cell = Cell(sched1);\n-            let handle1_cell = Cell(handle1);\n-\n-            let loop2 = ~UvEventLoop::new();\n-            let mut sched2 = ~Scheduler::new(loop2, work_queue2.clone(), sleepers2);\n-            let handle2 = sched2.make_handle();\n-            let sched2_cell = Cell(sched2);\n-            let handle2_cell = Cell(handle2);\n-\n-            let _thread1 = do Thread::start {\n-                let mut sched1 = sched1_cell.take();\n-                sched1.run();\n-            };\n-\n-            let _thread2 = do Thread::start {\n-                let mut sched2 = sched2_cell.take();\n-                let handle1_cell = Cell(handle1_cell.take());\n-                let handle2_cell = Cell(handle2_cell.take());\n-\n-                let task = ~do Coroutine::new(&mut sched2.stack_pool) {\n-                    // Hold handles to keep the schedulers alive\n-                    let mut handle1 = handle1_cell.take();\n-                    let mut handle2 = handle2_cell.take();\n-\n-                    let mut ports = ~[];\n-                    for 10.times {\n-                        let (port, chan) = oneshot();\n-                        let chan_cell = Cell(chan);\n-                        do spawntask_later {\n-                            chan_cell.take().send(());\n-                        }\n-                        ports.push(port);\n-\n-                        // Make sure the other scheduler is awake\n-                        handle1.remote.fire();\n-                        handle2.remote.fire();\n-                    }\n+        use container::Container;\n \n-                    while !ports.is_empty() {\n-                        ports.pop().recv();\n-                    }\n-                };\n+        do run_in_mt_newsched_task {\n+            let mut ports = ~[];\n+            for 10.times {\n+                let (port, chan) = oneshot();\n+                let chan_cell = Cell(chan);\n+                do spawntask_later {\n+                    chan_cell.take().send(());\n+                }\n+                ports.push(port);\n+            }\n \n-                sched2.enqueue_task(task);\n-                sched2.run();\n-            };\n+            while !ports.is_empty() {\n+                ports.pop().recv();\n+            }\n         }\n     }\n }"}, {"sha": "1bbfe8d473db32d495d96b7455f99e8c0ef65ff5", "filename": "src/libcore/rt/test.rs", "status": "modified", "additions": 13, "deletions": 4, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a373dad74d0bd89a9d5362bba1059d9cc25afb9a/src%2Flibcore%2Frt%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Frt%2Ftest.rs?ref=a373dad74d0bd89a9d5362bba1059d9cc25afb9a", "patch": "@@ -13,6 +13,7 @@ use option::{Option, Some, None};\n use cell::Cell;\n use clone::Clone;\n use container::Container;\n+use old_iter::MutableIter;\n use vec::OwnedVector;\n use result::{Result, Ok, Err};\n use unstable::run_in_bare_thread;\n@@ -29,7 +30,10 @@ pub fn new_test_uv_sched() -> Scheduler {\n     use rt::work_queue::WorkQueue;\n     use rt::sleeper_list::SleeperList;\n \n-    Scheduler::new(~UvEventLoop::new(), WorkQueue::new(), SleeperList::new())\n+    let mut sched = Scheduler::new(~UvEventLoop::new(), WorkQueue::new(), SleeperList::new());\n+    // Don't wait for the Shutdown message\n+    sched.no_sleep = true;\n+    return sched;\n }\n \n /// Creates a new scheduler in a new thread and runs a task in it,\n@@ -57,6 +61,7 @@ pub fn run_in_newsched_task(f: ~fn()) {\n /// until the function `f` returns.\n pub fn run_in_mt_newsched_task(f: ~fn()) {\n     use rt::uv::uvio::UvEventLoop;\n+    use rt::sched::Shutdown;\n \n     let f_cell = Cell(f);\n \n@@ -78,11 +83,15 @@ pub fn run_in_mt_newsched_task(f: ~fn()) {\n         }\n \n         let f_cell = Cell(f_cell.take());\n-        let handles = handles; // Freeze\n+        let handles = Cell(handles);\n         let main_task = ~do Coroutine::new(&mut scheds[0].stack_pool) {\n             f_cell.take()();\n-            // Hold on to handles until the function exits. This keeps the schedulers alive.\n-            let _captured_handles = &handles;\n+\n+            let mut handles = handles.take();\n+            // Tell schedulers to exit\n+            for handles.each_mut |handle| {\n+                handle.send(Shutdown);\n+            }\n         };\n \n         scheds[0].enqueue_task(main_task);"}]}