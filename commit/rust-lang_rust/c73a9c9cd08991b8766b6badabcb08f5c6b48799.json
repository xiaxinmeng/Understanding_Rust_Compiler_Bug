{"sha": "c73a9c9cd08991b8766b6badabcb08f5c6b48799", "node_id": "MDY6Q29tbWl0NzI0NzEyOmM3M2E5YzljZDA4OTkxYjg3NjZiNmJhZGFiY2IwOGY1YzZiNDg3OTk=", "commit": {"author": {"name": "John Clements", "email": "clements@racket-lang.org", "date": "2013-04-23T17:57:41Z"}, "committer": {"name": "John Clements", "email": "clements@racket-lang.org", "date": "2013-04-28T16:49:20Z"}, "message": "refactoring mod.rs", "tree": {"sha": "ef8d0e45759b9b72b1b263a209da79268a5047db", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ef8d0e45759b9b72b1b263a209da79268a5047db"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c73a9c9cd08991b8766b6badabcb08f5c6b48799", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c73a9c9cd08991b8766b6badabcb08f5c6b48799", "html_url": "https://github.com/rust-lang/rust/commit/c73a9c9cd08991b8766b6badabcb08f5c6b48799", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c73a9c9cd08991b8766b6badabcb08f5c6b48799/comments", "author": {"login": "jbclements", "id": 226617, "node_id": "MDQ6VXNlcjIyNjYxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/226617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbclements", "html_url": "https://github.com/jbclements", "followers_url": "https://api.github.com/users/jbclements/followers", "following_url": "https://api.github.com/users/jbclements/following{/other_user}", "gists_url": "https://api.github.com/users/jbclements/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbclements/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbclements/subscriptions", "organizations_url": "https://api.github.com/users/jbclements/orgs", "repos_url": "https://api.github.com/users/jbclements/repos", "events_url": "https://api.github.com/users/jbclements/events{/privacy}", "received_events_url": "https://api.github.com/users/jbclements/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jbclements", "id": 226617, "node_id": "MDQ6VXNlcjIyNjYxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/226617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbclements", "html_url": "https://github.com/jbclements", "followers_url": "https://api.github.com/users/jbclements/followers", "following_url": "https://api.github.com/users/jbclements/following{/other_user}", "gists_url": "https://api.github.com/users/jbclements/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbclements/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbclements/subscriptions", "organizations_url": "https://api.github.com/users/jbclements/orgs", "repos_url": "https://api.github.com/users/jbclements/repos", "events_url": "https://api.github.com/users/jbclements/events{/privacy}", "received_events_url": "https://api.github.com/users/jbclements/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a2493ad04811c1133127be8740bf30c2d24504ab", "url": "https://api.github.com/repos/rust-lang/rust/commits/a2493ad04811c1133127be8740bf30c2d24504ab", "html_url": "https://github.com/rust-lang/rust/commit/a2493ad04811c1133127be8740bf30c2d24504ab"}], "stats": {"total": 600, "additions": 437, "deletions": 163}, "files": [{"sha": "2e64c0c45bffeb18099b6070eaeb9fcd4a44cce6", "filename": "src/librustc/driver/driver.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibrustc%2Fdriver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibrustc%2Fdriver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdriver%2Fdriver.rs?ref=c73a9c9cd08991b8766b6badabcb08f5c6b48799", "patch": "@@ -149,7 +149,7 @@ pub fn parse_input(sess: Session, cfg: ast::crate_cfg, input: &input)\n     -> @ast::crate {\n     match *input {\n       file_input(ref file) => {\n-        parse::parse_crate_from_file_using_tts(&(*file), cfg, sess.parse_sess)\n+        parse::parse_crate_from_file(&(*file), cfg, sess.parse_sess)\n       }\n       str_input(ref src) => {\n         // FIXME (#2319): Don't really want to box the source string"}, {"sha": "433809b9db291377d7b80be692a4a7c5a793f22a", "filename": "src/librustdoc/attr_parser.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibrustdoc%2Fattr_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibrustdoc%2Fattr_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fattr_parser.rs?ref=c73a9c9cd08991b8766b6badabcb08f5c6b48799", "patch": "@@ -79,7 +79,7 @@ mod test {\n \n         let parse_sess = syntax::parse::new_parse_sess(None);\n         let parser = parse::new_parser_from_source_str(\n-            parse_sess, ~[], ~\"-\", codemap::FssNone, @source);\n+            parse_sess, ~[], ~\"-\", @source);\n \n         parser.parse_outer_attributes()\n     }"}, {"sha": "0063c7ea8763f9c73d4ecc4a0a2994e042ce34c5", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 377, "deletions": 111, "changes": 488, "blob_url": "https://github.com/rust-lang/rust/blob/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=c73a9c9cd08991b8766b6badabcb08f5c6b48799", "patch": "@@ -13,7 +13,7 @@\n \n use ast::node_id;\n use ast;\n-use codemap::{span, CodeMap};\n+use codemap::{span, CodeMap, FileMap, FileSubstr};\n use codemap;\n use diagnostic::{span_handler, mk_span_handler, mk_handler, Emitter};\n use parse::attr::parser_attr;\n@@ -22,7 +22,7 @@ use parse::parser::Parser;\n use parse::token::{ident_interner, mk_ident_interner};\n \n use core::io;\n-use core::option::{None, Option};\n+use core::option::{None, Option, Some};\n use core::path::Path;\n use core::result::{Err, Ok, Result};\n \n@@ -82,31 +82,15 @@ pub fn new_parse_sess_special_handler(sh: @span_handler,\n // uses a HOF to parse anything, and <source> includes file and\n // source_str.\n \n-// this appears to be the main entry point for rust parsing by\n-// rustc and crate:\n pub fn parse_crate_from_file(\n     input: &Path,\n     cfg: ast::crate_cfg,\n     sess: @mut ParseSess\n ) -> @ast::crate {\n-    let p = new_parser_from_file(sess, /*bad*/ copy cfg, input);\n-    p.parse_crate_mod(/*bad*/ copy cfg)\n+    new_parser_from_file(sess, /*bad*/ copy cfg, input).parse_crate_mod()\n     // why is there no p.abort_if_errors here?\n }\n \n-pub fn parse_crate_from_file_using_tts(\n-    input: &Path,\n-    cfg: ast::crate_cfg,\n-    sess: @mut ParseSess\n-) -> @ast::crate {\n-    let p = new_parser_from_file(sess, /*bad*/ copy cfg, input);\n-    let tts = p.parse_all_token_trees();\n-    new_parser_from_tts(sess,cfg,tts).parse_crate_mod(/*bad*/ copy cfg)\n-    // why is there no p.abort_if_errors here?\n-}\n-\n-\n-\n pub fn parse_crate_from_source_str(\n     name: ~str,\n     source: @~str,\n@@ -117,10 +101,9 @@ pub fn parse_crate_from_source_str(\n         sess,\n         /*bad*/ copy cfg,\n         /*bad*/ copy name,\n-        codemap::FssNone,\n         source\n     );\n-    maybe_aborted(p.parse_crate_mod(/*bad*/ copy cfg),p)\n+    maybe_aborted(p.parse_crate_mod(),p)\n }\n \n pub fn parse_expr_from_source_str(\n@@ -133,7 +116,6 @@ pub fn parse_expr_from_source_str(\n         sess,\n         cfg,\n         /*bad*/ copy name,\n-        codemap::FssNone,\n         source\n     );\n     maybe_aborted(p.parse_expr(), p)\n@@ -150,7 +132,6 @@ pub fn parse_item_from_source_str(\n         sess,\n         cfg,\n         /*bad*/ copy name,\n-        codemap::FssNone,\n         source\n     );\n     maybe_aborted(p.parse_item(attrs),p)\n@@ -166,7 +147,6 @@ pub fn parse_meta_from_source_str(\n         sess,\n         cfg,\n         /*bad*/ copy name,\n-        codemap::FssNone,\n         source\n     );\n     maybe_aborted(p.parse_meta_item(),p)\n@@ -183,7 +163,6 @@ pub fn parse_stmt_from_source_str(\n         sess,\n         cfg,\n         /*bad*/ copy name,\n-        codemap::FssNone,\n         source\n     );\n     maybe_aborted(p.parse_stmt(attrs),p)\n@@ -199,21 +178,26 @@ pub fn parse_tts_from_source_str(\n         sess,\n         cfg,\n         /*bad*/ copy name,\n-        codemap::FssNone,\n         source\n     );\n     *p.quote_depth += 1u;\n+    // right now this is re-creating the token trees from ... token trees.\n     maybe_aborted(p.parse_all_token_trees(),p)\n }\n \n+// given a function and parsing information (source str,\n+// filename, crate cfg, and sess), create a parser,\n+// apply the function, and check that the parser\n+// consumed all of the input before returning the function's\n+// result.\n pub fn parse_from_source_str<T>(\n     f: &fn(&Parser) -> T,\n     name: ~str, ss: codemap::FileSubstr,\n     source: @~str,\n     cfg: ast::crate_cfg,\n     sess: @mut ParseSess\n ) -> T {\n-    let p = new_parser_from_source_str(\n+    let p = new_parser_from_source_substr(\n         sess,\n         cfg,\n         name,\n@@ -227,6 +211,7 @@ pub fn parse_from_source_str<T>(\n     maybe_aborted(r,p)\n }\n \n+// return the next unused node id.\n pub fn next_node_id(sess: @mut ParseSess) -> node_id {\n     let rv = sess.next_id;\n     sess.next_id += 1;\n@@ -235,39 +220,24 @@ pub fn next_node_id(sess: @mut ParseSess) -> node_id {\n     return rv;\n }\n \n+// Create a new parser from a source string\n pub fn new_parser_from_source_str(sess: @mut ParseSess,\n                                   cfg: ast::crate_cfg,\n                                   name: ~str,\n-                                  ss: codemap::FileSubstr,\n                                   source: @~str)\n                                -> Parser {\n-    let filemap = sess.cm.new_filemap_w_substr(name, ss, source);\n-    let srdr = lexer::new_string_reader(\n-        copy sess.span_diagnostic,\n-        filemap,\n-        sess.interner\n-    );\n-    Parser(sess, cfg, srdr as @reader)\n+    filemap_to_parser(sess,string_to_filemap(sess,source,name),cfg)\n }\n \n-/// Read the entire source file, return a parser\n-/// that draws from that string\n-pub fn new_parser_result_from_file(\n-    sess: @mut ParseSess,\n-    cfg: ast::crate_cfg,\n-    path: &Path\n-) -> Result<Parser, ~str> {\n-    match io::read_whole_file_str(path) {\n-        Ok(src) => {\n-            let filemap = sess.cm.new_filemap(path.to_str(), @src);\n-            let srdr = lexer::new_string_reader(copy sess.span_diagnostic,\n-                                                filemap,\n-                                                sess.interner);\n-            Ok(Parser(sess, cfg, srdr as @reader))\n-\n-        }\n-        Err(e) => Err(e)\n-    }\n+// Create a new parser from a source string where the origin\n+// is specified as a substring of another file.\n+pub fn new_parser_from_source_substr(sess: @mut ParseSess,\n+                                  cfg: ast::crate_cfg,\n+                                  name: ~str,\n+                                  ss: codemap::FileSubstr,\n+                                  source: @~str)\n+                               -> Parser {\n+    filemap_to_parser(sess,substring_to_filemap(sess,source,name,ss),cfg)\n }\n \n /// Create a new parser, handling errors as appropriate\n@@ -277,35 +247,85 @@ pub fn new_parser_from_file(\n     cfg: ast::crate_cfg,\n     path: &Path\n ) -> Parser {\n-    match new_parser_result_from_file(sess, cfg, path) {\n-        Ok(parser) => parser,\n-        Err(e) => {\n-            sess.span_diagnostic.handler().fatal(e)\n-        }\n-    }\n+    filemap_to_parser(sess,file_to_filemap(sess,path,None),cfg)\n }\n \n-/// Create a new parser based on a span from an existing parser. Handles\n-/// error messages correctly when the file does not exist.\n+/// Given a session, a crate config, a path, and a span, add\n+/// the file at the given path to the codemap, and return a parser.\n+/// On an error, use the given span as the source of the problem.\n pub fn new_sub_parser_from_file(\n     sess: @mut ParseSess,\n     cfg: ast::crate_cfg,\n     path: &Path,\n     sp: span\n ) -> Parser {\n-    match new_parser_result_from_file(sess, cfg, path) {\n-        Ok(parser) => parser,\n+    filemap_to_parser(sess,file_to_filemap(sess,path,Some(sp)),cfg)\n+}\n+\n+/// Given a filemap and config, return a parser\n+pub fn filemap_to_parser(sess: @mut ParseSess,\n+                         filemap: @FileMap,\n+                         cfg: ast::crate_cfg) -> Parser {\n+    tts_to_parser(sess,filemap_to_tts(sess,filemap),cfg)\n+}\n+\n+// must preserve old name for now, because quote! from the *existing*\n+// compiler expands into it\n+pub fn new_parser_from_tts(sess: @mut ParseSess,\n+                     cfg: ast::crate_cfg,\n+                     tts: ~[ast::token_tree]) -> Parser {\n+    tts_to_parser(sess,tts,cfg)\n+}\n+\n+\n+// base abstractions\n+\n+/// Given a session and a path and an optional span (for error reporting),\n+/// add the path to the session's codemap and return the new filemap.\n+pub fn file_to_filemap(sess: @mut ParseSess, path: &Path, spanopt: Option<span>)\n+    -> @FileMap {\n+    match io::read_whole_file_str(path) {\n+        Ok(src) => string_to_filemap(sess, @src, path.to_str()),\n         Err(e) => {\n-            sess.span_diagnostic.span_fatal(sp, e)\n+            match spanopt {\n+                Some(span) => sess.span_diagnostic.span_fatal(span, e),\n+                None => sess.span_diagnostic.handler().fatal(e)\n+            }\n         }\n     }\n }\n \n-pub fn new_parser_from_tts(\n-    sess: @mut ParseSess,\n-    cfg: ast::crate_cfg,\n-    tts: ~[ast::token_tree]\n-) -> Parser {\n+// given a session and a string, add the string to\n+// the session's codemap and return the new filemap\n+pub fn string_to_filemap(sess: @mut ParseSess, source: @~str, path: ~str)\n+    -> @FileMap {\n+    sess.cm.new_filemap(path, source)\n+}\n+\n+// given a session and a string and a path and a FileSubStr, add\n+// the string to the CodeMap and return the new FileMap\n+pub fn substring_to_filemap(sess: @mut ParseSess, source: @~str, path: ~str,\n+                           filesubstr: FileSubstr) -> @FileMap {\n+    sess.cm.new_filemap_w_substr(path,filesubstr,source)\n+}\n+\n+// given a filemap, produce a sequence of token-trees\n+pub fn filemap_to_tts(sess: @mut ParseSess, filemap: @FileMap)\n+    -> ~[ast::token_tree] {\n+    // it appears to me that the cfg doesn't matter here... indeed,\n+    // parsing tt's probably shouldn't require a parser at all.\n+    let cfg = ~[];\n+    let srdr = lexer::new_string_reader(copy sess.span_diagnostic,\n+                                        filemap,\n+                                        sess.interner);\n+    let p1 = Parser(sess, cfg, srdr as @reader);\n+    p1.parse_all_token_trees()\n+}\n+\n+// given tts and cfg, produce a parser\n+pub fn tts_to_parser(sess: @mut ParseSess,\n+                     tts: ~[ast::token_tree],\n+                     cfg: ast::crate_cfg) -> Parser {\n     let trdr = lexer::new_tt_reader(\n         copy sess.span_diagnostic,\n         sess.interner,\n@@ -329,8 +349,76 @@ mod test {\n     use std::serialize::Encodable;\n     use std;\n     use core::io;\n+    use core::option::Option;\n+    use core::option::Some;\n     use core::option::None;\n+    use core::int;\n+    use core::num::NumCast;\n+    use codemap::{dummy_sp, CodeMap, span, BytePos, spanned};\n+    use opt_vec;\n     use ast;\n+    use abi;\n+    use ast_util::mk_ident;\n+    use parse::parser::Parser;\n+    use parse::token::{ident_interner, mk_ident_interner, mk_fresh_ident_interner};\n+    use diagnostic::{span_handler, mk_span_handler, mk_handler, Emitter};\n+\n+    // add known names to interner for testing\n+    fn mk_testing_interner() -> @ident_interner {\n+        let i = mk_fresh_ident_interner();\n+        // baby hack; in order to put the identifiers\n+        // 'a' and 'b' at known locations, we're going\n+        // to fill up the interner to length 100. If\n+        // the # of preloaded items on the interner\n+        // ever gets larger than 100, we'll have to\n+        // adjust this number (say, to 200) and\n+        // change the numbers in the identifier\n+        // test cases below.\n+\n+        assert!(i.len() < 100);\n+        for int::range(0,100-((i.len()).to_int())) |_dc| {\n+            i.gensym(@~\"dontcare\");\n+        }\n+        i.intern(@~\"a\");\n+        i.intern(@~\"b\");\n+        i.intern(@~\"c\");\n+        i.intern(@~\"d\");\n+        i.intern(@~\"return\");\n+        assert!(i.get(ast::ident{repr:101,ctxt:0}) == @~\"b\");\n+        i\n+    }\n+\n+    // make a parse_sess that's closed over a\n+    // testing interner (where a -> 100, b -> 101)\n+    fn mk_testing_parse_sess() -> @mut ParseSess {\n+        let interner = mk_testing_interner();\n+        let cm = @CodeMap::new();\n+        @mut ParseSess {\n+            cm: cm,\n+            next_id: 1,\n+            span_diagnostic: mk_span_handler(mk_handler(None), cm),\n+            interner: interner,\n+        }\n+    }\n+\n+    // map a string to tts, using a made-up filename: return both the token_trees\n+    // and the ParseSess\n+    fn string_to_tts_t (source_str : @~str) -> (~[ast::token_tree],@mut ParseSess) {\n+        let ps = mk_testing_parse_sess();\n+        (filemap_to_tts(ps,string_to_filemap(ps,source_str,~\"bogofile\")),ps)\n+    }\n+\n+    // map a string to tts, return the tt without its parsesess\n+    fn string_to_tts_only(source_str : @~str) -> ~[ast::token_tree] {\n+        let (tts,ps) = string_to_tts_t(source_str);\n+        tts\n+    }\n+\n+    // map string to parser (via tts)\n+    fn string_to_parser(source_str: @~str) -> Parser {\n+        let ps = mk_testing_parse_sess();\n+        new_parser_from_source_str(ps,~[],~\"bogofile\",source_str)\n+    }\n \n     #[test] fn to_json_str<E : Encodable<std::json::Encoder>>(val: @E) -> ~str {\n         do io::with_str_writer |writer| {\n@@ -339,49 +427,71 @@ mod test {\n     }\n \n     fn string_to_crate (source_str : @~str) -> @ast::crate {\n-        parse_crate_from_source_str(\n-            ~\"bogofile\",\n-            source_str,\n-            ~[],\n-            new_parse_sess(None))\n+        string_to_parser(source_str).parse_crate_mod()\n     }\n \n-    fn string_to_tt_to_crate (source_str : @~str) -> @ast::crate {\n-        let tts = parse_tts_from_source_str(\n-            ~\"bogofile\",\n-           source_str,\n-           ~[],\n-           new_parse_sess(None));\n-        new_parser_from_tts(new_parse_sess(None),~[],tts)\n-            .parse_crate_mod(~[])\n+    fn string_to_expr (source_str : @~str) -> @ast::expr {\n+        string_to_parser(source_str).parse_expr()\n     }\n \n-    // make sure that parsing from TTs produces the same result\n-    // as parsing from strings\n-    #[test] fn tts_produce_the_same_result () {\n-        let source_str = @~\"fn foo (x : int) { x; }\";\n-        assert_eq!(string_to_tt_to_crate(source_str),\n-                     string_to_crate(source_str));\n+    fn string_to_item (source_str : @~str) -> Option<@ast::item> {\n+        string_to_parser(source_str).parse_item(~[])\n     }\n \n-    // check the contents of the tt manually:\n-    #[test] fn alltts () {\n-        let source_str = @~\"fn foo (x : int) { x; }\";\n-        let tts = parse_tts_from_source_str(\n-            ~\"bogofile\",\n-            source_str,\n-            ~[],\n-            new_parse_sess(None));\n-        assert_eq!(\n-            to_json_str(@tts),\n-            ~\"[\\\n+    fn string_to_stmt (source_str : @~str) -> @ast::stmt {\n+        string_to_parser(source_str).parse_stmt(~[])\n+    }\n+\n+    // produce a codemap::span\n+    fn sp (a: uint, b: uint) -> span {\n+        span{lo:BytePos(a),hi:BytePos(b),expn_info:None}\n+    }\n+\n+    // convert a vector of uints to a vector of ast::idents\n+    fn ints_to_idents(ids: ~[uint]) -> ~[ast::ident] {\n+        ids.map(|u| mk_ident(*u))\n+    }\n+\n+    #[test] fn path_exprs_1 () {\n+        assert_eq!(string_to_expr(@~\"a\"),\n+                   @ast::expr{id:1,\n+                              callee_id:2,\n+                              node:ast::expr_path(@ast::Path {span:sp(0,1),\n+                                                              global:false,\n+                                                              idents:~[mk_ident(100)],\n+                                                              rp:None,\n+                                                              types:~[]}),\n+                              span:sp(0,1)})\n+    }\n+\n+    #[test] fn path_exprs_2 () {\n+        assert_eq!(string_to_expr(@~\"::a::b\"),\n+                   @ast::expr{id:1,\n+                               callee_id:2,\n+                               node:ast::expr_path(@ast::Path {span:sp(0,6),\n+                                                               global:true,\n+                                                               idents:ints_to_idents(~[100,101]),\n+                                                               rp:None,\n+                                                               types:~[]}),\n+                              span:sp(0,6)})\n+    }\n+\n+    #[should_fail]\n+    #[test] fn bad_path_expr_1() {\n+        string_to_expr(@~\"::abc::def::return\");\n+    }\n+\n+    #[test] fn string_to_tts_1 () {\n+        let (tts,ps) = string_to_tts_t(@~\"fn a (b : int) { b; }\");\n+        assert_eq!(to_json_str(@tts),\n+                   ~\"[\\\n                 [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"fn\\\",false]],\\\n-                [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"foo\\\",false]],\\\n+                [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"a\\\",false]],\\\n                 [\\\n                     \\\"tt_delim\\\",\\\n                     [\\\n                         [\\\"tt_tok\\\",null,\\\"LPAREN\\\"],\\\n-                        [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"x\\\",false]],\\\n+                        [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"b\\\",false]],\\\n                         [\\\"tt_tok\\\",null,\\\"COLON\\\"],\\\n                         [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"int\\\",false]],\\\n                         [\\\"tt_tok\\\",null,\\\"RPAREN\\\"]\\\n@@ -391,21 +501,177 @@ mod test {\n                     \\\"tt_delim\\\",\\\n                     [\\\n                         [\\\"tt_tok\\\",null,\\\"LBRACE\\\"],\\\n-                        [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"x\\\",false]],\\\n+                        [\\\"tt_tok\\\",null,[\\\"IDENT\\\",\\\"b\\\",false]],\\\n                         [\\\"tt_tok\\\",null,\\\"SEMI\\\"],\\\n                         [\\\"tt_tok\\\",null,\\\"RBRACE\\\"]\\\n                     ]\\\n                 ]\\\n             ]\"\n-        );\n-        let ast1 = new_parser_from_tts(new_parse_sess(None),~[],tts)\n-            .parse_item(~[]);\n-        let ast2 = parse_item_from_source_str(\n-            ~\"bogofile\",\n-            @~\"fn foo (x : int) { x; }\",\n-            ~[],~[],\n-            new_parse_sess(None));\n-        assert_eq!(ast1,ast2);\n+                  );\n+    }\n+\n+    #[test] fn ret_expr() {\n+        assert_eq!(string_to_expr(@~\"return d\"),\n+                   @ast::expr{id:3,\n+                              callee_id:4,\n+                              node:ast::expr_ret(\n+                                  Some(@ast::expr{id:1,callee_id:2,\n+                                                  node:ast::expr_path(\n+                                                      @ast::Path{span:sp(7,8),\n+                                                                 global:false,\n+                                                                 idents:~[mk_ident(103)],\n+                                                                 rp:None,\n+                                                                 types:~[]\n+                                                                }),\n+                                                  span:sp(7,8)})),\n+                              span:sp(0,8)})\n+    }\n+\n+    #[test] fn parse_stmt_1 () {\n+        assert_eq!(string_to_stmt(@~\"b;\"),\n+                   @spanned{\n+                       node: ast::stmt_expr(@ast::expr{\n+                           id: 1,\n+                           callee_id: 2,\n+                           node: ast::expr_path(\n+                               @ast::Path{\n+                                   span:sp(0,1),\n+                                   global:false,\n+                                   idents:~[mk_ident(101)],\n+                                   rp:None,\n+                                   types: ~[]}),\n+                           span: sp(0,1)},\n+                                            3), // fixme\n+                       span: sp(0,1)})\n+\n+    }\n+\n+    #[test] fn parse_ident_pat () {\n+        let parser = string_to_parser(@~\"b\");\n+        assert_eq!(parser.parse_pat(false),\n+                   @ast::pat{id:1, // fixme\n+                             node: ast::pat_ident(ast::bind_by_copy,\n+                                                  @ast::Path{\n+                                                      span:sp(0,1),\n+                                                      global:false,\n+                                                      idents:~[mk_ident(101)],\n+                                                      rp: None,\n+                                                      types: ~[]},\n+                                                  None // no idea\n+                                                 ),\n+                             span: sp(0,1)});\n+        assert_eq!(*parser.token,token::EOF);\n+    }\n+\n+    #[test] fn parse_arg () {\n+        let parser = string_to_parser(@~\"b : int\");\n+        assert_eq!(parser.parse_arg_general(true),\n+                   ast::arg{\n+                       mode: ast::infer(1),\n+                       is_mutbl: false,\n+                       ty: @ast::Ty{id:4, // fixme\n+                                    node: ast::ty_path(@ast::Path{\n+                                        span:sp(4,4), // this is bizarre...\n+                                        // check this in the original parser?\n+                                        global:false,\n+                                        idents:~[mk_ident(105)],\n+                                        rp: None,\n+                                        types: ~[]},\n+                                                       3),\n+                                    span:sp(4,7)},\n+                       pat: @ast::pat{id:2,\n+                                      node: ast::pat_ident(ast::bind_by_copy,\n+                                                           @ast::Path{\n+                                                               span:sp(0,1),\n+                                                               global:false,\n+                                                               idents:~[mk_ident(101)],\n+                                                               rp: None,\n+                                                               types: ~[]},\n+                                                           None // no idea\n+                                                          ),\n+                                      span: sp(0,3)}, // really?\n+                       id: 5 // fixme\n+                   })\n+    }\n+\n+    // check the contents of the tt manually:\n+    #[test] fn parse_fundecl () {\n+        // this test depends on the intern order of \"fn\" and \"int\", and on the\n+        // assignment order of the node_ids.\n+        assert_eq!(string_to_item(@~\"fn a (b : int) { b; }\"),\n+                  Some(\n+                      @ast::item{ident:mk_ident(100),\n+                            attrs:~[],\n+                            id: 11, // fixme\n+                            node: ast::item_fn(ast::fn_decl{\n+                                inputs: ~[ast::arg{\n+                                    mode: ast::infer(1),\n+                                    is_mutbl: false,\n+                                    ty: @ast::Ty{id:4, // fixme\n+                                                node: ast::ty_path(@ast::Path{\n+                                        span:sp(10,13),\n+                                        global:false,\n+                                        idents:~[mk_ident(106)],\n+                                        rp: None,\n+                                        types: ~[]},\n+                                                       3),\n+                                                span:sp(10,13)},\n+                                    pat: @ast::pat{id:2, // fixme\n+                                                   node: ast::pat_ident(\n+                                                       ast::bind_by_copy,\n+                                                       @ast::Path{\n+                                                           span:sp(6,7),\n+                                                           global:false,\n+                                                           idents:~[mk_ident(101)],\n+                                                           rp: None,\n+                                                           types: ~[]},\n+                                                       None // no idea\n+                                                   ),\n+                                                  span: sp(6,9)}, // bleah.\n+                                    id: 5 // fixme\n+                                }],\n+                                output: @ast::Ty{id:6, // fixme\n+                                                 node: ast::ty_nil,\n+                                                 span:sp(15,15)}, // not sure\n+                                cf: ast::return_val\n+                            },\n+                                    ast::impure_fn,\n+                                    abi::AbiSet::Rust(),\n+                                    ast::Generics{ // no idea on either of these:\n+                                        lifetimes: opt_vec::Empty,\n+                                        ty_params: opt_vec::Empty,\n+                                    },\n+                                    spanned{\n+                                        span: sp(15,21),\n+                                        node: ast::blk_{\n+                                            view_items: ~[],\n+                                            stmts: ~[@spanned{\n+                                                node: ast::stmt_semi(@ast::expr{\n+                                                    id: 7,\n+                                                    callee_id: 8,\n+                                                    node: ast::expr_path(\n+                                                        @ast::Path{\n+                                                            span:sp(17,18),\n+                                                            global:false,\n+                                                            idents:~[mk_ident(101)],\n+                                                            rp:None,\n+                                                            types: ~[]}),\n+                                                    span: sp(17,18)},\n+                                                                     9), // fixme\n+                                                span: sp(17,18)}],\n+                                            expr: None,\n+                                            id: 10, // fixme\n+                                            rules: ast::default_blk // no idea\n+                                        }}),\n+                            vis: ast::inherited,\n+                            span: sp(0,21)}));\n+    }\n+\n+\n+    #[test] fn parse_exprs () {\n+        // just make sure that they parse....\n+        string_to_expr(@~\"3 + 4\");\n+        string_to_expr(@~\"a::z.froob(b,@(987+3))\");\n     }\n }\n "}, {"sha": "cc20e996dba915fda7d907f1869cadb1847143a6", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=c73a9c9cd08991b8766b6badabcb08f5c6b48799", "patch": "@@ -4463,7 +4463,7 @@ pub impl Parser {\n     }\n \n     // Parses a source module as a crate\n-    fn parse_crate_mod(&self, _cfg: crate_cfg) -> @crate {\n+    fn parse_crate_mod(&self) -> @crate {\n         let lo = self.span.lo;\n         // parse the crate's inner attrs, maybe (oops) one\n         // of the attrs of an item:"}, {"sha": "2f8acbcece7499f9e07907ac3f78d8f2a0b20c8d", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 57, "deletions": 49, "changes": 106, "blob_url": "https://github.com/rust-lang/rust/blob/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c73a9c9cd08991b8766b6badabcb08f5c6b48799/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=c73a9c9cd08991b8766b6badabcb08f5c6b48799", "patch": "@@ -390,60 +390,68 @@ pub impl ident_interner {\n     }\n }\n \n+// return a fresh interner, preloaded with special identifiers.\n+// EFFECT: stores this interner in TLS\n+pub fn mk_fresh_ident_interner() -> @ident_interner {\n+    // the indices here must correspond to the numbers in\n+    // special_idents.\n+    let init_vec = ~[\n+        @~\"_\",                  // 0\n+        @~\"anon\",               // 1\n+        @~\"drop\",               // 2\n+        @~\"\",                   // 3\n+        @~\"unary\",              // 4\n+        @~\"!\",                  // 5\n+        @~\"[]\",                 // 6\n+        @~\"unary-\",             // 7\n+        @~\"__extensions__\",     // 8\n+        @~\"self\",               // 9\n+        @~\"item\",               // 10\n+        @~\"block\",              // 11\n+        @~\"stmt\",               // 12\n+        @~\"pat\",                // 13\n+        @~\"expr\",               // 14\n+        @~\"ty\",                 // 15\n+        @~\"ident\",              // 16\n+        @~\"path\",               // 17\n+        @~\"tt\",                 // 18\n+        @~\"matchers\",           // 19\n+        @~\"str\",                // 20\n+        @~\"TyVisitor\",          // 21\n+        @~\"arg\",                // 22\n+        @~\"descrim\",            // 23\n+        @~\"__rust_abi\",         // 24\n+        @~\"__rust_stack_shim\",  // 25\n+        @~\"TyDesc\",             // 26\n+        @~\"dtor\",               // 27\n+        @~\"main\",               // 28\n+        @~\"<opaque>\",           // 29\n+        @~\"blk\",                // 30\n+        @~\"static\",             // 31\n+        @~\"intrinsic\",          // 32\n+        @~\"__foreign_mod__\",    // 33\n+        @~\"__field__\",          // 34\n+        @~\"C\",                  // 35\n+        @~\"Self\",               // 36\n+    ];\n+\n+    let rv = @ident_interner {\n+        interner: interner::Interner::prefill(init_vec)\n+    };\n+    unsafe {\n+        task::local_data::local_data_set(interner_key!(), @rv);\n+    }\n+    rv\n+}\n+\n+// if an interner exists in TLS, return it. Otherwise, prepare a\n+// fresh one.\n pub fn mk_ident_interner() -> @ident_interner {\n     unsafe {\n         match task::local_data::local_data_get(interner_key!()) {\n             Some(interner) => *interner,\n             None => {\n-                // the indices here must correspond to the numbers in\n-                // special_idents.\n-                let init_vec = ~[\n-                    @~\"_\",                  // 0\n-                    @~\"anon\",               // 1\n-                    @~\"drop\",               // 2\n-                    @~\"\",                   // 3\n-                    @~\"unary\",              // 4\n-                    @~\"!\",                  // 5\n-                    @~\"[]\",                 // 6\n-                    @~\"unary-\",             // 7\n-                    @~\"__extensions__\",     // 8\n-                    @~\"self\",               // 9\n-                    @~\"item\",               // 10\n-                    @~\"block\",              // 11\n-                    @~\"stmt\",               // 12\n-                    @~\"pat\",                // 13\n-                    @~\"expr\",               // 14\n-                    @~\"ty\",                 // 15\n-                    @~\"ident\",              // 16\n-                    @~\"path\",               // 17\n-                    @~\"tt\",                 // 18\n-                    @~\"matchers\",           // 19\n-                    @~\"str\",                // 20\n-                    @~\"TyVisitor\",          // 21\n-                    @~\"arg\",                // 22\n-                    @~\"descrim\",            // 23\n-                    @~\"__rust_abi\",         // 24\n-                    @~\"__rust_stack_shim\",  // 25\n-                    @~\"TyDesc\",             // 26\n-                    @~\"dtor\",               // 27\n-                    @~\"main\",               // 28\n-                    @~\"<opaque>\",           // 29\n-                    @~\"blk\",                // 30\n-                    @~\"static\",             // 31\n-                    @~\"intrinsic\",          // 32\n-                    @~\"__foreign_mod__\",    // 33\n-                    @~\"__field__\",          // 34\n-                    @~\"C\",                  // 35\n-                    @~\"Self\",               // 36\n-                ];\n-\n-                let rv = @ident_interner {\n-                    interner: interner::Interner::prefill(init_vec)\n-                };\n-\n-                task::local_data::local_data_set(interner_key!(), @rv);\n-\n-                rv\n+                mk_fresh_ident_interner()\n             }\n         }\n     }"}]}