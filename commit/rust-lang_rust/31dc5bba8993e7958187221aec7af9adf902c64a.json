{"sha": "31dc5bba8993e7958187221aec7af9adf902c64a", "node_id": "C_kwDOAAsO6NoAKDMxZGM1YmJhODk5M2U3OTU4MTg3MjIxYWVjN2FmOWFkZjkwMmM2NGE", "commit": {"author": {"name": "Ibraheem Ahmed", "email": "ibraheem@ibraheem.ca", "date": "2022-10-17T23:11:56Z"}, "committer": {"name": "Ibraheem Ahmed", "email": "ibraheem@ibraheem.ca", "date": "2022-11-10T04:20:00Z"}, "message": "implement `sync::mpsc` as a wrapper around `sync::mpmc`", "tree": {"sha": "8345834b1bba2556b0fd62bf150096362dc2e29e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8345834b1bba2556b0fd62bf150096362dc2e29e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/31dc5bba8993e7958187221aec7af9adf902c64a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/31dc5bba8993e7958187221aec7af9adf902c64a", "html_url": "https://github.com/rust-lang/rust/commit/31dc5bba8993e7958187221aec7af9adf902c64a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/31dc5bba8993e7958187221aec7af9adf902c64a/comments", "author": {"login": "ibraheemdev", "id": 34988408, "node_id": "MDQ6VXNlcjM0OTg4NDA4", "avatar_url": "https://avatars.githubusercontent.com/u/34988408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibraheemdev", "html_url": "https://github.com/ibraheemdev", "followers_url": "https://api.github.com/users/ibraheemdev/followers", "following_url": "https://api.github.com/users/ibraheemdev/following{/other_user}", "gists_url": "https://api.github.com/users/ibraheemdev/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibraheemdev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibraheemdev/subscriptions", "organizations_url": "https://api.github.com/users/ibraheemdev/orgs", "repos_url": "https://api.github.com/users/ibraheemdev/repos", "events_url": "https://api.github.com/users/ibraheemdev/events{/privacy}", "received_events_url": "https://api.github.com/users/ibraheemdev/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ibraheemdev", "id": 34988408, "node_id": "MDQ6VXNlcjM0OTg4NDA4", "avatar_url": "https://avatars.githubusercontent.com/u/34988408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibraheemdev", "html_url": "https://github.com/ibraheemdev", "followers_url": "https://api.github.com/users/ibraheemdev/followers", "following_url": "https://api.github.com/users/ibraheemdev/following{/other_user}", "gists_url": "https://api.github.com/users/ibraheemdev/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibraheemdev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibraheemdev/subscriptions", "organizations_url": "https://api.github.com/users/ibraheemdev/orgs", "repos_url": "https://api.github.com/users/ibraheemdev/repos", "events_url": "https://api.github.com/users/ibraheemdev/events{/privacy}", "received_events_url": "https://api.github.com/users/ibraheemdev/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a43da5a09701469e013c623c7cfc1e2f7ec83e47", "url": "https://api.github.com/repos/rust-lang/rust/commits/a43da5a09701469e013c623c7cfc1e2f7ec83e47", "html_url": "https://github.com/rust-lang/rust/commit/a43da5a09701469e013c623c7cfc1e2f7ec83e47"}], "stats": {"total": 2822, "additions": 24, "deletions": 2798}, "files": [{"sha": "021df7b096cbc0670155fa63fcc65d8798544147", "filename": "library/std/src/sync/mpsc/blocking.rs", "status": "removed", "additions": 0, "deletions": 82, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fblocking.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fblocking.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fblocking.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,82 +0,0 @@\n-//! Generic support for building blocking abstractions.\n-\n-use crate::sync::atomic::{AtomicBool, Ordering};\n-use crate::sync::Arc;\n-use crate::thread::{self, Thread};\n-use crate::time::Instant;\n-\n-struct Inner {\n-    thread: Thread,\n-    woken: AtomicBool,\n-}\n-\n-unsafe impl Send for Inner {}\n-unsafe impl Sync for Inner {}\n-\n-#[derive(Clone)]\n-pub struct SignalToken {\n-    inner: Arc<Inner>,\n-}\n-\n-pub struct WaitToken {\n-    inner: Arc<Inner>,\n-}\n-\n-impl !Send for WaitToken {}\n-\n-impl !Sync for WaitToken {}\n-\n-pub fn tokens() -> (WaitToken, SignalToken) {\n-    let inner = Arc::new(Inner { thread: thread::current(), woken: AtomicBool::new(false) });\n-    let wait_token = WaitToken { inner: inner.clone() };\n-    let signal_token = SignalToken { inner };\n-    (wait_token, signal_token)\n-}\n-\n-impl SignalToken {\n-    pub fn signal(&self) -> bool {\n-        let wake = self\n-            .inner\n-            .woken\n-            .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)\n-            .is_ok();\n-        if wake {\n-            self.inner.thread.unpark();\n-        }\n-        wake\n-    }\n-\n-    /// Converts to an unsafe raw pointer. Useful for storing in a pipe's state\n-    /// flag.\n-    #[inline]\n-    pub unsafe fn to_raw(self) -> *mut u8 {\n-        Arc::into_raw(self.inner) as *mut u8\n-    }\n-\n-    /// Converts from an unsafe raw pointer. Useful for retrieving a pipe's state\n-    /// flag.\n-    #[inline]\n-    pub unsafe fn from_raw(signal_ptr: *mut u8) -> SignalToken {\n-        SignalToken { inner: Arc::from_raw(signal_ptr as *mut Inner) }\n-    }\n-}\n-\n-impl WaitToken {\n-    pub fn wait(self) {\n-        while !self.inner.woken.load(Ordering::SeqCst) {\n-            thread::park()\n-        }\n-    }\n-\n-    /// Returns `true` if we wake up normally.\n-    pub fn wait_max_until(self, end: Instant) -> bool {\n-        while !self.inner.woken.load(Ordering::SeqCst) {\n-            let now = Instant::now();\n-            if now >= end {\n-                return false;\n-            }\n-            thread::park_timeout(end - now)\n-        }\n-        true\n-    }\n-}"}, {"sha": "9197f0d6e6c8c3a2f737096cc9f7fff29ef625fb", "filename": "library/std/src/sync/mpsc/cache_aligned.rs", "status": "removed", "additions": 0, "deletions": 25, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fcache_aligned.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fcache_aligned.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fcache_aligned.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,25 +0,0 @@\n-use crate::ops::{Deref, DerefMut};\n-\n-#[derive(Copy, Clone, Default, PartialEq, Eq, PartialOrd, Ord, Hash)]\n-#[cfg_attr(target_arch = \"aarch64\", repr(align(128)))]\n-#[cfg_attr(not(target_arch = \"aarch64\"), repr(align(64)))]\n-pub(super) struct CacheAligned<T>(pub T);\n-\n-impl<T> Deref for CacheAligned<T> {\n-    type Target = T;\n-    fn deref(&self) -> &Self::Target {\n-        &self.0\n-    }\n-}\n-\n-impl<T> DerefMut for CacheAligned<T> {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        &mut self.0\n-    }\n-}\n-\n-impl<T> CacheAligned<T> {\n-    pub(super) fn new(t: T) -> Self {\n-        CacheAligned(t)\n-    }\n-}"}, {"sha": "d15289623fe3afbcf98bb64a9a5e117c54127b3d", "filename": "library/std/src/sync/mpsc/mod.rs", "status": "modified", "additions": 24, "deletions": 406, "changes": 430, "blob_url": "https://github.com/rust-lang/rust/blob/31dc5bba8993e7958187221aec7af9adf902c64a/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/31dc5bba8993e7958187221aec7af9adf902c64a/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmod.rs?ref=31dc5bba8993e7958187221aec7af9adf902c64a", "patch": "@@ -143,175 +143,16 @@ mod tests;\n #[cfg(all(test, not(target_os = \"emscripten\")))]\n mod sync_tests;\n \n-// A description of how Rust's channel implementation works\n-//\n-// Channels are supposed to be the basic building block for all other\n-// concurrent primitives that are used in Rust. As a result, the channel type\n-// needs to be highly optimized, flexible, and broad enough for use everywhere.\n-//\n-// The choice of implementation of all channels is to be built on lock-free data\n-// structures. The channels themselves are then consequently also lock-free data\n-// structures. As always with lock-free code, this is a very \"here be dragons\"\n-// territory, especially because I'm unaware of any academic papers that have\n-// gone into great length about channels of these flavors.\n-//\n-// ## Flavors of channels\n-//\n-// From the perspective of a consumer of this library, there is only one flavor\n-// of channel. This channel can be used as a stream and cloned to allow multiple\n-// senders. Under the hood, however, there are actually three flavors of\n-// channels in play.\n-//\n-// * Flavor::Oneshots - these channels are highly optimized for the one-send use\n-//                      case. They contain as few atomics as possible and\n-//                      involve one and exactly one allocation.\n-// * Streams - these channels are optimized for the non-shared use case. They\n-//             use a different concurrent queue that is more tailored for this\n-//             use case. The initial allocation of this flavor of channel is not\n-//             optimized.\n-// * Shared - this is the most general form of channel that this module offers,\n-//            a channel with multiple senders. This type is as optimized as it\n-//            can be, but the previous two types mentioned are much faster for\n-//            their use-cases.\n-//\n-// ## Concurrent queues\n-//\n-// The basic idea of Rust's Sender/Receiver types is that send() never blocks,\n-// but recv() obviously blocks. This means that under the hood there must be\n-// some shared and concurrent queue holding all of the actual data.\n-//\n-// With two flavors of channels, two flavors of queues are also used. We have\n-// chosen to use queues from a well-known author that are abbreviated as SPSC\n-// and MPSC (single producer, single consumer and multiple producer, single\n-// consumer). SPSC queues are used for streams while MPSC queues are used for\n-// shared channels.\n-//\n-// ### SPSC optimizations\n-//\n-// The SPSC queue found online is essentially a linked list of nodes where one\n-// half of the nodes are the \"queue of data\" and the other half of nodes are a\n-// cache of unused nodes. The unused nodes are used such that an allocation is\n-// not required on every push() and a free doesn't need to happen on every\n-// pop().\n-//\n-// As found online, however, the cache of nodes is of an infinite size. This\n-// means that if a channel at one point in its life had 50k items in the queue,\n-// then the queue will always have the capacity for 50k items. I believed that\n-// this was an unnecessary limitation of the implementation, so I have altered\n-// the queue to optionally have a bound on the cache size.\n-//\n-// By default, streams will have an unbounded SPSC queue with a small-ish cache\n-// size. The hope is that the cache is still large enough to have very fast\n-// send() operations while not too large such that millions of channels can\n-// coexist at once.\n-//\n-// ### MPSC optimizations\n-//\n-// Right now the MPSC queue has not been optimized. Like the SPSC queue, it uses\n-// a linked list under the hood to earn its unboundedness, but I have not put\n-// forth much effort into having a cache of nodes similar to the SPSC queue.\n-//\n-// For now, I believe that this is \"ok\" because shared channels are not the most\n-// common type, but soon we may wish to revisit this queue choice and determine\n-// another candidate for backend storage of shared channels.\n-//\n-// ## Overview of the Implementation\n-//\n-// Now that there's a little background on the concurrent queues used, it's\n-// worth going into much more detail about the channels themselves. The basic\n-// pseudocode for a send/recv are:\n-//\n-//\n-//      send(t)                             recv()\n-//        queue.push(t)                       return if queue.pop()\n-//        if increment() == -1                deschedule {\n-//          wakeup()                            if decrement() > 0\n-//                                                cancel_deschedule()\n-//                                            }\n-//                                            queue.pop()\n-//\n-// As mentioned before, there are no locks in this implementation, only atomic\n-// instructions are used.\n-//\n-// ### The internal atomic counter\n-//\n-// Every channel has a shared counter with each half to keep track of the size\n-// of the queue. This counter is used to abort descheduling by the receiver and\n-// to know when to wake up on the sending side.\n-//\n-// As seen in the pseudocode, senders will increment this count and receivers\n-// will decrement the count. The theory behind this is that if a sender sees a\n-// -1 count, it will wake up the receiver, and if the receiver sees a 1+ count,\n-// then it doesn't need to block.\n-//\n-// The recv() method has a beginning call to pop(), and if successful, it needs\n-// to decrement the count. It is a crucial implementation detail that this\n-// decrement does *not* happen to the shared counter. If this were the case,\n-// then it would be possible for the counter to be very negative when there were\n-// no receivers waiting, in which case the senders would have to determine when\n-// it was actually appropriate to wake up a receiver.\n-//\n-// Instead, the \"steal count\" is kept track of separately (not atomically\n-// because it's only used by receivers), and then the decrement() call when\n-// descheduling will lump in all of the recent steals into one large decrement.\n-//\n-// The implication of this is that if a sender sees a -1 count, then there's\n-// guaranteed to be a waiter waiting!\n-//\n-// ## Native Implementation\n-//\n-// A major goal of these channels is to work seamlessly on and off the runtime.\n-// All of the previous race conditions have been worded in terms of\n-// scheduler-isms (which is obviously not available without the runtime).\n-//\n-// For now, native usage of channels (off the runtime) will fall back onto\n-// mutexes/cond vars for descheduling/atomic decisions. The no-contention path\n-// is still entirely lock-free, the \"deschedule\" blocks above are surrounded by\n-// a mutex and the \"wakeup\" blocks involve grabbing a mutex and signaling on a\n-// condition variable.\n-//\n-// ## Select\n-//\n-// Being able to support selection over channels has greatly influenced this\n-// design, and not only does selection need to work inside the runtime, but also\n-// outside the runtime.\n-//\n-// The implementation is fairly straightforward. The goal of select() is not to\n-// return some data, but only to return which channel can receive data without\n-// blocking. The implementation is essentially the entire blocking procedure\n-// followed by an increment as soon as its woken up. The cancellation procedure\n-// involves an increment and swapping out of to_wake to acquire ownership of the\n-// thread to unblock.\n-//\n-// Sadly this current implementation requires multiple allocations, so I have\n-// seen the throughput of select() be much worse than it should be. I do not\n-// believe that there is anything fundamental that needs to change about these\n-// channels, however, in order to support a more efficient select().\n-//\n-// FIXME: Select is now removed, so these factors are ready to be cleaned up!\n-//\n-// # Conclusion\n-//\n-// And now that you've seen all the races that I found and attempted to fix,\n-// here's the code for you to find some more!\n-\n-use crate::cell::UnsafeCell;\n+// MPSC channels are built as a wrapper around MPMC channels, which\n+// were ported from the `crossbeam-channel` crate. MPMC channels are\n+// not exposed publicly, but if you are curious about the implementation,\n+// that's where everything is.\n+\n use crate::error;\n use crate::fmt;\n-use crate::mem;\n-use crate::sync::Arc;\n+use crate::sync::mpmc;\n use crate::time::{Duration, Instant};\n \n-mod blocking;\n-mod mpsc_queue;\n-mod oneshot;\n-mod shared;\n-mod spsc_queue;\n-mod stream;\n-mod sync;\n-\n-mod cache_aligned;\n-\n /// The receiving half of Rust's [`channel`] (or [`sync_channel`]) type.\n /// This half can only be owned by one thread.\n ///\n@@ -341,7 +182,7 @@ mod cache_aligned;\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n #[cfg_attr(not(test), rustc_diagnostic_item = \"Receiver\")]\n pub struct Receiver<T> {\n-    inner: UnsafeCell<Flavor<T>>,\n+    inner: mpmc::Receiver<T>,\n }\n \n // The receiver port can be sent from place to place, so long as it\n@@ -498,7 +339,7 @@ pub struct IntoIter<T> {\n /// ```\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub struct Sender<T> {\n-    inner: UnsafeCell<Flavor<T>>,\n+    inner: mpmc::Sender<T>,\n }\n \n // The send port can be sent from place to place, so long as it\n@@ -557,7 +398,7 @@ impl<T> !Sync for Sender<T> {}\n /// ```\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub struct SyncSender<T> {\n-    inner: Arc<sync::Packet<T>>,\n+    inner: mpmc::Sender<T>,\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n@@ -643,34 +484,6 @@ pub enum TrySendError<T> {\n     Disconnected(#[stable(feature = \"rust1\", since = \"1.0.0\")] T),\n }\n \n-enum Flavor<T> {\n-    Oneshot(Arc<oneshot::Packet<T>>),\n-    Stream(Arc<stream::Packet<T>>),\n-    Shared(Arc<shared::Packet<T>>),\n-    Sync(Arc<sync::Packet<T>>),\n-}\n-\n-#[doc(hidden)]\n-trait UnsafeFlavor<T> {\n-    fn inner_unsafe(&self) -> &UnsafeCell<Flavor<T>>;\n-    unsafe fn inner_mut(&self) -> &mut Flavor<T> {\n-        &mut *self.inner_unsafe().get()\n-    }\n-    unsafe fn inner(&self) -> &Flavor<T> {\n-        &*self.inner_unsafe().get()\n-    }\n-}\n-impl<T> UnsafeFlavor<T> for Sender<T> {\n-    fn inner_unsafe(&self) -> &UnsafeCell<Flavor<T>> {\n-        &self.inner\n-    }\n-}\n-impl<T> UnsafeFlavor<T> for Receiver<T> {\n-    fn inner_unsafe(&self) -> &UnsafeCell<Flavor<T>> {\n-        &self.inner\n-    }\n-}\n-\n /// Creates a new asynchronous channel, returning the sender/receiver halves.\n /// All data sent on the [`Sender`] will become available on the [`Receiver`] in\n /// the same order as it was sent, and no [`send`] will block the calling thread\n@@ -711,8 +524,8 @@ impl<T> UnsafeFlavor<T> for Receiver<T> {\n #[must_use]\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub fn channel<T>() -> (Sender<T>, Receiver<T>) {\n-    let a = Arc::new(oneshot::Packet::new());\n-    (Sender::new(Flavor::Oneshot(a.clone())), Receiver::new(Flavor::Oneshot(a)))\n+    let (tx, rx) = mpmc::channel();\n+    (Sender { inner: tx }, Receiver { inner: rx })\n }\n \n /// Creates a new synchronous, bounded channel.\n@@ -760,19 +573,15 @@ pub fn channel<T>() -> (Sender<T>, Receiver<T>) {\n #[must_use]\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub fn sync_channel<T>(bound: usize) -> (SyncSender<T>, Receiver<T>) {\n-    let a = Arc::new(sync::Packet::new(bound));\n-    (SyncSender::new(a.clone()), Receiver::new(Flavor::Sync(a)))\n+    let (tx, rx) = mpmc::sync_channel(bound);\n+    (SyncSender { inner: tx }, Receiver { inner: rx })\n }\n \n ////////////////////////////////////////////////////////////////////////////////\n // Sender\n ////////////////////////////////////////////////////////////////////////////////\n \n impl<T> Sender<T> {\n-    fn new(inner: Flavor<T>) -> Sender<T> {\n-        Sender { inner: UnsafeCell::new(inner) }\n-    }\n-\n     /// Attempts to send a value on this channel, returning it back if it could\n     /// not be sent.\n     ///\n@@ -802,40 +611,7 @@ impl<T> Sender<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn send(&self, t: T) -> Result<(), SendError<T>> {\n-        let (new_inner, ret) = match *unsafe { self.inner() } {\n-            Flavor::Oneshot(ref p) => {\n-                if !p.sent() {\n-                    return p.send(t).map_err(SendError);\n-                } else {\n-                    let a = Arc::new(stream::Packet::new());\n-                    let rx = Receiver::new(Flavor::Stream(a.clone()));\n-                    match p.upgrade(rx) {\n-                        oneshot::UpSuccess => {\n-                            let ret = a.send(t);\n-                            (a, ret)\n-                        }\n-                        oneshot::UpDisconnected => (a, Err(t)),\n-                        oneshot::UpWoke(token) => {\n-                            // This send cannot panic because the thread is\n-                            // asleep (we're looking at it), so the receiver\n-                            // can't go away.\n-                            a.send(t).ok().unwrap();\n-                            token.signal();\n-                            (a, Ok(()))\n-                        }\n-                    }\n-                }\n-            }\n-            Flavor::Stream(ref p) => return p.send(t).map_err(SendError),\n-            Flavor::Shared(ref p) => return p.send(t).map_err(SendError),\n-            Flavor::Sync(..) => unreachable!(),\n-        };\n-\n-        unsafe {\n-            let tmp = Sender::new(Flavor::Stream(new_inner));\n-            mem::swap(self.inner_mut(), tmp.inner_mut());\n-        }\n-        ret.map_err(SendError)\n+        self.inner.send(t)\n     }\n }\n \n@@ -847,57 +623,14 @@ impl<T> Clone for Sender<T> {\n     /// (including the original) need to be dropped in order for\n     /// [`Receiver::recv`] to stop blocking.\n     fn clone(&self) -> Sender<T> {\n-        let packet = match *unsafe { self.inner() } {\n-            Flavor::Oneshot(ref p) => {\n-                let a = Arc::new(shared::Packet::new());\n-                {\n-                    let guard = a.postinit_lock();\n-                    let rx = Receiver::new(Flavor::Shared(a.clone()));\n-                    let sleeper = match p.upgrade(rx) {\n-                        oneshot::UpSuccess | oneshot::UpDisconnected => None,\n-                        oneshot::UpWoke(task) => Some(task),\n-                    };\n-                    a.inherit_blocker(sleeper, guard);\n-                }\n-                a\n-            }\n-            Flavor::Stream(ref p) => {\n-                let a = Arc::new(shared::Packet::new());\n-                {\n-                    let guard = a.postinit_lock();\n-                    let rx = Receiver::new(Flavor::Shared(a.clone()));\n-                    let sleeper = match p.upgrade(rx) {\n-                        stream::UpSuccess | stream::UpDisconnected => None,\n-                        stream::UpWoke(task) => Some(task),\n-                    };\n-                    a.inherit_blocker(sleeper, guard);\n-                }\n-                a\n-            }\n-            Flavor::Shared(ref p) => {\n-                p.clone_chan();\n-                return Sender::new(Flavor::Shared(p.clone()));\n-            }\n-            Flavor::Sync(..) => unreachable!(),\n-        };\n-\n-        unsafe {\n-            let tmp = Sender::new(Flavor::Shared(packet.clone()));\n-            mem::swap(self.inner_mut(), tmp.inner_mut());\n-        }\n-        Sender::new(Flavor::Shared(packet))\n+        Sender { inner: self.inner.clone() }\n     }\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T> Drop for Sender<T> {\n     fn drop(&mut self) {\n-        match *unsafe { self.inner() } {\n-            Flavor::Oneshot(ref p) => p.drop_chan(),\n-            Flavor::Stream(ref p) => p.drop_chan(),\n-            Flavor::Shared(ref p) => p.drop_chan(),\n-            Flavor::Sync(..) => unreachable!(),\n-        }\n+        let _ = self.inner;\n     }\n }\n \n@@ -913,10 +646,6 @@ impl<T> fmt::Debug for Sender<T> {\n ////////////////////////////////////////////////////////////////////////////////\n \n impl<T> SyncSender<T> {\n-    fn new(inner: Arc<sync::Packet<T>>) -> SyncSender<T> {\n-        SyncSender { inner }\n-    }\n-\n     /// Sends a value on this synchronous channel.\n     ///\n     /// This function will *block* until space in the internal buffer becomes\n@@ -955,7 +684,7 @@ impl<T> SyncSender<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn send(&self, t: T) -> Result<(), SendError<T>> {\n-        self.inner.send(t).map_err(SendError)\n+        self.inner.send(t)\n     }\n \n     /// Attempts to send a value on this channel without blocking.\n@@ -1016,15 +745,14 @@ impl<T> SyncSender<T> {\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T> Clone for SyncSender<T> {\n     fn clone(&self) -> SyncSender<T> {\n-        self.inner.clone_chan();\n-        SyncSender::new(self.inner.clone())\n+        SyncSender { inner: self.inner.clone() }\n     }\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T> Drop for SyncSender<T> {\n     fn drop(&mut self) {\n-        self.inner.drop_chan();\n+        let _ = self.inner;\n     }\n }\n \n@@ -1040,10 +768,6 @@ impl<T> fmt::Debug for SyncSender<T> {\n ////////////////////////////////////////////////////////////////////////////////\n \n impl<T> Receiver<T> {\n-    fn new(inner: Flavor<T>) -> Receiver<T> {\n-        Receiver { inner: UnsafeCell::new(inner) }\n-    }\n-\n     /// Attempts to return a pending value on this receiver without blocking.\n     ///\n     /// This method will never block the caller in order to wait for data to\n@@ -1069,35 +793,7 @@ impl<T> Receiver<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn try_recv(&self) -> Result<T, TryRecvError> {\n-        loop {\n-            let new_port = match *unsafe { self.inner() } {\n-                Flavor::Oneshot(ref p) => match p.try_recv() {\n-                    Ok(t) => return Ok(t),\n-                    Err(oneshot::Empty) => return Err(TryRecvError::Empty),\n-                    Err(oneshot::Disconnected) => return Err(TryRecvError::Disconnected),\n-                    Err(oneshot::Upgraded(rx)) => rx,\n-                },\n-                Flavor::Stream(ref p) => match p.try_recv() {\n-                    Ok(t) => return Ok(t),\n-                    Err(stream::Empty) => return Err(TryRecvError::Empty),\n-                    Err(stream::Disconnected) => return Err(TryRecvError::Disconnected),\n-                    Err(stream::Upgraded(rx)) => rx,\n-                },\n-                Flavor::Shared(ref p) => match p.try_recv() {\n-                    Ok(t) => return Ok(t),\n-                    Err(shared::Empty) => return Err(TryRecvError::Empty),\n-                    Err(shared::Disconnected) => return Err(TryRecvError::Disconnected),\n-                },\n-                Flavor::Sync(ref p) => match p.try_recv() {\n-                    Ok(t) => return Ok(t),\n-                    Err(sync::Empty) => return Err(TryRecvError::Empty),\n-                    Err(sync::Disconnected) => return Err(TryRecvError::Disconnected),\n-                },\n-            };\n-            unsafe {\n-                mem::swap(self.inner_mut(), new_port.inner_mut());\n-            }\n-        }\n+        self.inner.try_recv()\n     }\n \n     /// Attempts to wait for a value on this receiver, returning an error if the\n@@ -1156,31 +852,7 @@ impl<T> Receiver<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn recv(&self) -> Result<T, RecvError> {\n-        loop {\n-            let new_port = match *unsafe { self.inner() } {\n-                Flavor::Oneshot(ref p) => match p.recv(None) {\n-                    Ok(t) => return Ok(t),\n-                    Err(oneshot::Disconnected) => return Err(RecvError),\n-                    Err(oneshot::Upgraded(rx)) => rx,\n-                    Err(oneshot::Empty) => unreachable!(),\n-                },\n-                Flavor::Stream(ref p) => match p.recv(None) {\n-                    Ok(t) => return Ok(t),\n-                    Err(stream::Disconnected) => return Err(RecvError),\n-                    Err(stream::Upgraded(rx)) => rx,\n-                    Err(stream::Empty) => unreachable!(),\n-                },\n-                Flavor::Shared(ref p) => match p.recv(None) {\n-                    Ok(t) => return Ok(t),\n-                    Err(shared::Disconnected) => return Err(RecvError),\n-                    Err(shared::Empty) => unreachable!(),\n-                },\n-                Flavor::Sync(ref p) => return p.recv(None).map_err(|_| RecvError),\n-            };\n-            unsafe {\n-                mem::swap(self.inner_mut(), new_port.inner_mut());\n-            }\n-        }\n+        self.inner.recv()\n     }\n \n     /// Attempts to wait for a value on this receiver, returning an error if the\n@@ -1268,17 +940,7 @@ impl<T> Receiver<T> {\n     /// ```\n     #[stable(feature = \"mpsc_recv_timeout\", since = \"1.12.0\")]\n     pub fn recv_timeout(&self, timeout: Duration) -> Result<T, RecvTimeoutError> {\n-        // Do an optimistic try_recv to avoid the performance impact of\n-        // Instant::now() in the full-channel case.\n-        match self.try_recv() {\n-            Ok(result) => Ok(result),\n-            Err(TryRecvError::Disconnected) => Err(RecvTimeoutError::Disconnected),\n-            Err(TryRecvError::Empty) => match Instant::now().checked_add(timeout) {\n-                Some(deadline) => self.recv_deadline(deadline),\n-                // So far in the future that it's practically the same as waiting indefinitely.\n-                None => self.recv().map_err(RecvTimeoutError::from),\n-            },\n-        }\n+        self.inner.recv_timeout(timeout)\n     }\n \n     /// Attempts to wait for a value on this receiver, returning an error if the\n@@ -1339,46 +1001,7 @@ impl<T> Receiver<T> {\n     /// ```\n     #[unstable(feature = \"deadline_api\", issue = \"46316\")]\n     pub fn recv_deadline(&self, deadline: Instant) -> Result<T, RecvTimeoutError> {\n-        use self::RecvTimeoutError::*;\n-\n-        loop {\n-            let port_or_empty = match *unsafe { self.inner() } {\n-                Flavor::Oneshot(ref p) => match p.recv(Some(deadline)) {\n-                    Ok(t) => return Ok(t),\n-                    Err(oneshot::Disconnected) => return Err(Disconnected),\n-                    Err(oneshot::Upgraded(rx)) => Some(rx),\n-                    Err(oneshot::Empty) => None,\n-                },\n-                Flavor::Stream(ref p) => match p.recv(Some(deadline)) {\n-                    Ok(t) => return Ok(t),\n-                    Err(stream::Disconnected) => return Err(Disconnected),\n-                    Err(stream::Upgraded(rx)) => Some(rx),\n-                    Err(stream::Empty) => None,\n-                },\n-                Flavor::Shared(ref p) => match p.recv(Some(deadline)) {\n-                    Ok(t) => return Ok(t),\n-                    Err(shared::Disconnected) => return Err(Disconnected),\n-                    Err(shared::Empty) => None,\n-                },\n-                Flavor::Sync(ref p) => match p.recv(Some(deadline)) {\n-                    Ok(t) => return Ok(t),\n-                    Err(sync::Disconnected) => return Err(Disconnected),\n-                    Err(sync::Empty) => None,\n-                },\n-            };\n-\n-            if let Some(new_port) = port_or_empty {\n-                unsafe {\n-                    mem::swap(self.inner_mut(), new_port.inner_mut());\n-                }\n-            }\n-\n-            // If we're already passed the deadline, and we're here without\n-            // data, return a timeout, else try again.\n-            if Instant::now() >= deadline {\n-                return Err(Timeout);\n-            }\n-        }\n+        self.inner.recv_deadline(deadline)\n     }\n \n     /// Returns an iterator that will block waiting for messages, but never\n@@ -1500,12 +1123,7 @@ impl<T> IntoIterator for Receiver<T> {\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T> Drop for Receiver<T> {\n     fn drop(&mut self) {\n-        match *unsafe { self.inner() } {\n-            Flavor::Oneshot(ref p) => p.drop_port(),\n-            Flavor::Stream(ref p) => p.drop_port(),\n-            Flavor::Shared(ref p) => p.drop_port(),\n-            Flavor::Sync(ref p) => p.drop_port(),\n-        }\n+        let _ = self.inner;\n     }\n }\n "}, {"sha": "7322512e3b4585346b96d8b31bf29a94f673eb7c", "filename": "library/std/src/sync/mpsc/mpsc_queue.rs", "status": "removed", "additions": 0, "deletions": 124, "changes": 124, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmpsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmpsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmpsc_queue.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,124 +0,0 @@\n-//! A mostly lock-free multi-producer, single consumer queue.\n-//!\n-//! This module contains an implementation of a concurrent MPSC queue. This\n-//! queue can be used to share data between threads, and is also used as the\n-//! building block of channels in rust.\n-//!\n-//! Note that the current implementation of this queue has a caveat of the `pop`\n-//! method, and see the method for more information about it. Due to this\n-//! caveat, this queue might not be appropriate for all use-cases.\n-\n-// The original implementation is based off:\n-// https://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\n-//\n-// Note that back when the code was imported, it was licensed under the BSD-2-Clause license:\n-// http://web.archive.org/web/20110411011612/https://www.1024cores.net/home/lock-free-algorithms/queues/unbounded-spsc-queue\n-//\n-// The original author of the code agreed to relicense it under `MIT OR Apache-2.0` in 2017, so as\n-// of today the license of this file is the same as the rest of the codebase:\n-// https://github.com/rust-lang/rust/pull/42149\n-\n-#[cfg(all(test, not(target_os = \"emscripten\")))]\n-mod tests;\n-\n-pub use self::PopResult::*;\n-\n-use core::cell::UnsafeCell;\n-use core::ptr;\n-\n-use crate::boxed::Box;\n-use crate::sync::atomic::{AtomicPtr, Ordering};\n-\n-/// A result of the `pop` function.\n-pub enum PopResult<T> {\n-    /// Some data has been popped\n-    Data(T),\n-    /// The queue is empty\n-    Empty,\n-    /// The queue is in an inconsistent state. Popping data should succeed, but\n-    /// some pushers have yet to make enough progress in order allow a pop to\n-    /// succeed. It is recommended that a pop() occur \"in the near future\" in\n-    /// order to see if the sender has made progress or not\n-    Inconsistent,\n-}\n-\n-struct Node<T> {\n-    next: AtomicPtr<Node<T>>,\n-    value: Option<T>,\n-}\n-\n-/// The multi-producer single-consumer structure. This is not cloneable, but it\n-/// may be safely shared so long as it is guaranteed that there is only one\n-/// popper at a time (many pushers are allowed).\n-pub struct Queue<T> {\n-    head: AtomicPtr<Node<T>>,\n-    tail: UnsafeCell<*mut Node<T>>,\n-}\n-\n-unsafe impl<T: Send> Send for Queue<T> {}\n-unsafe impl<T: Send> Sync for Queue<T> {}\n-\n-impl<T> Node<T> {\n-    unsafe fn new(v: Option<T>) -> *mut Node<T> {\n-        Box::into_raw(box Node { next: AtomicPtr::new(ptr::null_mut()), value: v })\n-    }\n-}\n-\n-impl<T> Queue<T> {\n-    /// Creates a new queue that is safe to share among multiple producers and\n-    /// one consumer.\n-    pub fn new() -> Queue<T> {\n-        let stub = unsafe { Node::new(None) };\n-        Queue { head: AtomicPtr::new(stub), tail: UnsafeCell::new(stub) }\n-    }\n-\n-    /// Pushes a new value onto this queue.\n-    pub fn push(&self, t: T) {\n-        unsafe {\n-            let n = Node::new(Some(t));\n-            let prev = self.head.swap(n, Ordering::AcqRel);\n-            (*prev).next.store(n, Ordering::Release);\n-        }\n-    }\n-\n-    /// Pops some data from this queue.\n-    ///\n-    /// Note that the current implementation means that this function cannot\n-    /// return `Option<T>`. It is possible for this queue to be in an\n-    /// inconsistent state where many pushes have succeeded and completely\n-    /// finished, but pops cannot return `Some(t)`. This inconsistent state\n-    /// happens when a pusher is pre-empted at an inopportune moment.\n-    ///\n-    /// This inconsistent state means that this queue does indeed have data, but\n-    /// it does not currently have access to it at this time.\n-    pub fn pop(&self) -> PopResult<T> {\n-        unsafe {\n-            let tail = *self.tail.get();\n-            let next = (*tail).next.load(Ordering::Acquire);\n-\n-            if !next.is_null() {\n-                *self.tail.get() = next;\n-                assert!((*tail).value.is_none());\n-                assert!((*next).value.is_some());\n-                let ret = (*next).value.take().unwrap();\n-                let _: Box<Node<T>> = Box::from_raw(tail);\n-                return Data(ret);\n-            }\n-\n-            if self.head.load(Ordering::Acquire) == tail { Empty } else { Inconsistent }\n-        }\n-    }\n-}\n-\n-impl<T> Drop for Queue<T> {\n-    fn drop(&mut self) {\n-        unsafe {\n-            let mut cur = *self.tail.get();\n-            while !cur.is_null() {\n-                let next = (*cur).next.load(Ordering::Relaxed);\n-                let _: Box<Node<T>> = Box::from_raw(cur);\n-                cur = next;\n-            }\n-        }\n-    }\n-}"}, {"sha": "34b2a9a98ac36fa523fc4435fc12db5a8fe99f23", "filename": "library/std/src/sync/mpsc/mpsc_queue/tests.rs", "status": "removed", "additions": 0, "deletions": 47, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmpsc_queue%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmpsc_queue%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fmpsc_queue%2Ftests.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,47 +0,0 @@\n-use super::{Data, Empty, Inconsistent, Queue};\n-use crate::sync::mpsc::channel;\n-use crate::sync::Arc;\n-use crate::thread;\n-\n-#[test]\n-fn test_full() {\n-    let q: Queue<Box<_>> = Queue::new();\n-    q.push(Box::new(1));\n-    q.push(Box::new(2));\n-}\n-\n-#[test]\n-fn test() {\n-    let nthreads = 8;\n-    let nmsgs = if cfg!(miri) { 100 } else { 1000 };\n-    let q = Queue::new();\n-    match q.pop() {\n-        Empty => {}\n-        Inconsistent | Data(..) => panic!(),\n-    }\n-    let (tx, rx) = channel();\n-    let q = Arc::new(q);\n-\n-    for _ in 0..nthreads {\n-        let tx = tx.clone();\n-        let q = q.clone();\n-        thread::spawn(move || {\n-            for i in 0..nmsgs {\n-                q.push(i);\n-            }\n-            tx.send(()).unwrap();\n-        });\n-    }\n-\n-    let mut i = 0;\n-    while i < nthreads * nmsgs {\n-        match q.pop() {\n-            Empty | Inconsistent => {}\n-            Data(_) => i += 1,\n-        }\n-    }\n-    drop(tx);\n-    for _ in 0..nthreads {\n-        rx.recv().unwrap();\n-    }\n-}"}, {"sha": "0e259b8aecb9a35744ae9225ab33a41d4c7ac83d", "filename": "library/std/src/sync/mpsc/oneshot.rs", "status": "removed", "additions": 0, "deletions": 315, "changes": 315, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Foneshot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Foneshot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Foneshot.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,315 +0,0 @@\n-/// Oneshot channels/ports\n-///\n-/// This is the initial flavor of channels/ports used for comm module. This is\n-/// an optimization for the one-use case of a channel. The major optimization of\n-/// this type is to have one and exactly one allocation when the chan/port pair\n-/// is created.\n-///\n-/// Another possible optimization would be to not use an Arc box because\n-/// in theory we know when the shared packet can be deallocated (no real need\n-/// for the atomic reference counting), but I was having trouble how to destroy\n-/// the data early in a drop of a Port.\n-///\n-/// # Implementation\n-///\n-/// Oneshots are implemented around one atomic usize variable. This variable\n-/// indicates both the state of the port/chan but also contains any threads\n-/// blocked on the port. All atomic operations happen on this one word.\n-///\n-/// In order to upgrade a oneshot channel, an upgrade is considered a disconnect\n-/// on behalf of the channel side of things (it can be mentally thought of as\n-/// consuming the port). This upgrade is then also stored in the shared packet.\n-/// The one caveat to consider is that when a port sees a disconnected channel\n-/// it must check for data because there is no \"data plus upgrade\" state.\n-pub use self::Failure::*;\n-use self::MyUpgrade::*;\n-pub use self::UpgradeResult::*;\n-\n-use crate::cell::UnsafeCell;\n-use crate::ptr;\n-use crate::sync::atomic::{AtomicPtr, Ordering};\n-use crate::sync::mpsc::blocking::{self, SignalToken};\n-use crate::sync::mpsc::Receiver;\n-use crate::time::Instant;\n-\n-// Various states you can find a port in.\n-const EMPTY: *mut u8 = ptr::invalid_mut::<u8>(0); // initial state: no data, no blocked receiver\n-const DATA: *mut u8 = ptr::invalid_mut::<u8>(1); // data ready for receiver to take\n-const DISCONNECTED: *mut u8 = ptr::invalid_mut::<u8>(2); // channel is disconnected OR upgraded\n-// Any other value represents a pointer to a SignalToken value. The\n-// protocol ensures that when the state moves *to* a pointer,\n-// ownership of the token is given to the packet, and when the state\n-// moves *from* a pointer, ownership of the token is transferred to\n-// whoever changed the state.\n-\n-pub struct Packet<T> {\n-    // Internal state of the chan/port pair (stores the blocked thread as well)\n-    state: AtomicPtr<u8>,\n-    // One-shot data slot location\n-    data: UnsafeCell<Option<T>>,\n-    // when used for the second time, a oneshot channel must be upgraded, and\n-    // this contains the slot for the upgrade\n-    upgrade: UnsafeCell<MyUpgrade<T>>,\n-}\n-\n-pub enum Failure<T> {\n-    Empty,\n-    Disconnected,\n-    Upgraded(Receiver<T>),\n-}\n-\n-pub enum UpgradeResult {\n-    UpSuccess,\n-    UpDisconnected,\n-    UpWoke(SignalToken),\n-}\n-\n-enum MyUpgrade<T> {\n-    NothingSent,\n-    SendUsed,\n-    GoUp(Receiver<T>),\n-}\n-\n-impl<T> Packet<T> {\n-    pub fn new() -> Packet<T> {\n-        Packet {\n-            data: UnsafeCell::new(None),\n-            upgrade: UnsafeCell::new(NothingSent),\n-            state: AtomicPtr::new(EMPTY),\n-        }\n-    }\n-\n-    pub fn send(&self, t: T) -> Result<(), T> {\n-        unsafe {\n-            // Sanity check\n-            match *self.upgrade.get() {\n-                NothingSent => {}\n-                _ => panic!(\"sending on a oneshot that's already sent on \"),\n-            }\n-            assert!((*self.data.get()).is_none());\n-            ptr::write(self.data.get(), Some(t));\n-            ptr::write(self.upgrade.get(), SendUsed);\n-\n-            match self.state.swap(DATA, Ordering::SeqCst) {\n-                // Sent the data, no one was waiting\n-                EMPTY => Ok(()),\n-\n-                // Couldn't send the data, the port hung up first. Return the data\n-                // back up the stack.\n-                DISCONNECTED => {\n-                    self.state.swap(DISCONNECTED, Ordering::SeqCst);\n-                    ptr::write(self.upgrade.get(), NothingSent);\n-                    Err((&mut *self.data.get()).take().unwrap())\n-                }\n-\n-                // Not possible, these are one-use channels\n-                DATA => unreachable!(),\n-\n-                // There is a thread waiting on the other end. We leave the 'DATA'\n-                // state inside so it'll pick it up on the other end.\n-                ptr => {\n-                    SignalToken::from_raw(ptr).signal();\n-                    Ok(())\n-                }\n-            }\n-        }\n-    }\n-\n-    // Just tests whether this channel has been sent on or not, this is only\n-    // safe to use from the sender.\n-    pub fn sent(&self) -> bool {\n-        unsafe { !matches!(*self.upgrade.get(), NothingSent) }\n-    }\n-\n-    pub fn recv(&self, deadline: Option<Instant>) -> Result<T, Failure<T>> {\n-        // Attempt to not block the thread (it's a little expensive). If it looks\n-        // like we're not empty, then immediately go through to `try_recv`.\n-        if self.state.load(Ordering::SeqCst) == EMPTY {\n-            let (wait_token, signal_token) = blocking::tokens();\n-            let ptr = unsafe { signal_token.to_raw() };\n-\n-            // race with senders to enter the blocking state\n-            if self.state.compare_exchange(EMPTY, ptr, Ordering::SeqCst, Ordering::SeqCst).is_ok() {\n-                if let Some(deadline) = deadline {\n-                    let timed_out = !wait_token.wait_max_until(deadline);\n-                    // Try to reset the state\n-                    if timed_out {\n-                        self.abort_selection().map_err(Upgraded)?;\n-                    }\n-                } else {\n-                    wait_token.wait();\n-                    debug_assert!(self.state.load(Ordering::SeqCst) != EMPTY);\n-                }\n-            } else {\n-                // drop the signal token, since we never blocked\n-                drop(unsafe { SignalToken::from_raw(ptr) });\n-            }\n-        }\n-\n-        self.try_recv()\n-    }\n-\n-    pub fn try_recv(&self) -> Result<T, Failure<T>> {\n-        unsafe {\n-            match self.state.load(Ordering::SeqCst) {\n-                EMPTY => Err(Empty),\n-\n-                // We saw some data on the channel, but the channel can be used\n-                // again to send us an upgrade. As a result, we need to re-insert\n-                // into the channel that there's no data available (otherwise we'll\n-                // just see DATA next time). This is done as a cmpxchg because if\n-                // the state changes under our feet we'd rather just see that state\n-                // change.\n-                DATA => {\n-                    let _ = self.state.compare_exchange(\n-                        DATA,\n-                        EMPTY,\n-                        Ordering::SeqCst,\n-                        Ordering::SeqCst,\n-                    );\n-                    match (&mut *self.data.get()).take() {\n-                        Some(data) => Ok(data),\n-                        None => unreachable!(),\n-                    }\n-                }\n-\n-                // There's no guarantee that we receive before an upgrade happens,\n-                // and an upgrade flags the channel as disconnected, so when we see\n-                // this we first need to check if there's data available and *then*\n-                // we go through and process the upgrade.\n-                DISCONNECTED => match (&mut *self.data.get()).take() {\n-                    Some(data) => Ok(data),\n-                    None => match ptr::replace(self.upgrade.get(), SendUsed) {\n-                        SendUsed | NothingSent => Err(Disconnected),\n-                        GoUp(upgrade) => Err(Upgraded(upgrade)),\n-                    },\n-                },\n-\n-                // We are the sole receiver; there cannot be a blocking\n-                // receiver already.\n-                _ => unreachable!(),\n-            }\n-        }\n-    }\n-\n-    // Returns whether the upgrade was completed. If the upgrade wasn't\n-    // completed, then the port couldn't get sent to the other half (it will\n-    // never receive it).\n-    pub fn upgrade(&self, up: Receiver<T>) -> UpgradeResult {\n-        unsafe {\n-            let prev = match *self.upgrade.get() {\n-                NothingSent => NothingSent,\n-                SendUsed => SendUsed,\n-                _ => panic!(\"upgrading again\"),\n-            };\n-            ptr::write(self.upgrade.get(), GoUp(up));\n-\n-            match self.state.swap(DISCONNECTED, Ordering::SeqCst) {\n-                // If the channel is empty or has data on it, then we're good to go.\n-                // Senders will check the data before the upgrade (in case we\n-                // plastered over the DATA state).\n-                DATA | EMPTY => UpSuccess,\n-\n-                // If the other end is already disconnected, then we failed the\n-                // upgrade. Be sure to trash the port we were given.\n-                DISCONNECTED => {\n-                    ptr::replace(self.upgrade.get(), prev);\n-                    UpDisconnected\n-                }\n-\n-                // If someone's waiting, we gotta wake them up\n-                ptr => UpWoke(SignalToken::from_raw(ptr)),\n-            }\n-        }\n-    }\n-\n-    pub fn drop_chan(&self) {\n-        match self.state.swap(DISCONNECTED, Ordering::SeqCst) {\n-            DATA | DISCONNECTED | EMPTY => {}\n-\n-            // If someone's waiting, we gotta wake them up\n-            ptr => unsafe {\n-                SignalToken::from_raw(ptr).signal();\n-            },\n-        }\n-    }\n-\n-    pub fn drop_port(&self) {\n-        match self.state.swap(DISCONNECTED, Ordering::SeqCst) {\n-            // An empty channel has nothing to do, and a remotely disconnected\n-            // channel also has nothing to do b/c we're about to run the drop\n-            // glue\n-            DISCONNECTED | EMPTY => {}\n-\n-            // There's data on the channel, so make sure we destroy it promptly.\n-            // This is why not using an arc is a little difficult (need the box\n-            // to stay valid while we take the data).\n-            DATA => unsafe {\n-                (&mut *self.data.get()).take().unwrap();\n-            },\n-\n-            // We're the only ones that can block on this port\n-            _ => unreachable!(),\n-        }\n-    }\n-\n-    ////////////////////////////////////////////////////////////////////////////\n-    // select implementation\n-    ////////////////////////////////////////////////////////////////////////////\n-\n-    // Remove a previous selecting thread from this port. This ensures that the\n-    // blocked thread will no longer be visible to any other threads.\n-    //\n-    // The return value indicates whether there's data on this port.\n-    pub fn abort_selection(&self) -> Result<bool, Receiver<T>> {\n-        let state = match self.state.load(Ordering::SeqCst) {\n-            // Each of these states means that no further activity will happen\n-            // with regard to abortion selection\n-            s @ (EMPTY | DATA | DISCONNECTED) => s,\n-\n-            // If we've got a blocked thread, then use an atomic to gain ownership\n-            // of it (may fail)\n-            ptr => self\n-                .state\n-                .compare_exchange(ptr, EMPTY, Ordering::SeqCst, Ordering::SeqCst)\n-                .unwrap_or_else(|x| x),\n-        };\n-\n-        // Now that we've got ownership of our state, figure out what to do\n-        // about it.\n-        match state {\n-            EMPTY => unreachable!(),\n-            // our thread used for select was stolen\n-            DATA => Ok(true),\n-\n-            // If the other end has hung up, then we have complete ownership\n-            // of the port. First, check if there was data waiting for us. This\n-            // is possible if the other end sent something and then hung up.\n-            //\n-            // We then need to check to see if there was an upgrade requested,\n-            // and if so, the upgraded port needs to have its selection aborted.\n-            DISCONNECTED => unsafe {\n-                if (*self.data.get()).is_some() {\n-                    Ok(true)\n-                } else {\n-                    match ptr::replace(self.upgrade.get(), SendUsed) {\n-                        GoUp(port) => Err(port),\n-                        _ => Ok(true),\n-                    }\n-                }\n-            },\n-\n-            // We woke ourselves up from select.\n-            ptr => unsafe {\n-                drop(SignalToken::from_raw(ptr));\n-                Ok(false)\n-            },\n-        }\n-    }\n-}\n-\n-impl<T> Drop for Packet<T> {\n-    fn drop(&mut self) {\n-        assert_eq!(self.state.load(Ordering::SeqCst), DISCONNECTED);\n-    }\n-}"}, {"sha": "51917bd96bd60a46bd7f1b96df4a0e0bbc0d9a34", "filename": "library/std/src/sync/mpsc/shared.rs", "status": "removed", "additions": 0, "deletions": 501, "changes": 501, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fshared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fshared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fshared.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,501 +0,0 @@\n-/// Shared channels.\n-///\n-/// This is the flavor of channels which are not necessarily optimized for any\n-/// particular use case, but are the most general in how they are used. Shared\n-/// channels are cloneable allowing for multiple senders.\n-///\n-/// High level implementation details can be found in the comment of the parent\n-/// module. You'll also note that the implementation of the shared and stream\n-/// channels are quite similar, and this is no coincidence!\n-pub use self::Failure::*;\n-use self::StartResult::*;\n-\n-use core::cmp;\n-use core::intrinsics::abort;\n-\n-use crate::cell::UnsafeCell;\n-use crate::ptr;\n-use crate::sync::atomic::{AtomicBool, AtomicIsize, AtomicPtr, AtomicUsize, Ordering};\n-use crate::sync::mpsc::blocking::{self, SignalToken};\n-use crate::sync::mpsc::mpsc_queue as mpsc;\n-use crate::sync::{Mutex, MutexGuard};\n-use crate::thread;\n-use crate::time::Instant;\n-\n-const DISCONNECTED: isize = isize::MIN;\n-const FUDGE: isize = 1024;\n-const MAX_REFCOUNT: usize = (isize::MAX) as usize;\n-#[cfg(test)]\n-const MAX_STEALS: isize = 5;\n-#[cfg(not(test))]\n-const MAX_STEALS: isize = 1 << 20;\n-const EMPTY: *mut u8 = ptr::null_mut(); // initial state: no data, no blocked receiver\n-\n-pub struct Packet<T> {\n-    queue: mpsc::Queue<T>,\n-    cnt: AtomicIsize,          // How many items are on this channel\n-    steals: UnsafeCell<isize>, // How many times has a port received without blocking?\n-    to_wake: AtomicPtr<u8>,    // SignalToken for wake up\n-\n-    // The number of channels which are currently using this packet.\n-    channels: AtomicUsize,\n-\n-    // See the discussion in Port::drop and the channel send methods for what\n-    // these are used for\n-    port_dropped: AtomicBool,\n-    sender_drain: AtomicIsize,\n-\n-    // this lock protects various portions of this implementation during\n-    // select()\n-    select_lock: Mutex<()>,\n-}\n-\n-pub enum Failure {\n-    Empty,\n-    Disconnected,\n-}\n-\n-#[derive(PartialEq, Eq)]\n-enum StartResult {\n-    Installed,\n-    Abort,\n-}\n-\n-impl<T> Packet<T> {\n-    // Creation of a packet *must* be followed by a call to postinit_lock\n-    // and later by inherit_blocker\n-    pub fn new() -> Packet<T> {\n-        Packet {\n-            queue: mpsc::Queue::new(),\n-            cnt: AtomicIsize::new(0),\n-            steals: UnsafeCell::new(0),\n-            to_wake: AtomicPtr::new(EMPTY),\n-            channels: AtomicUsize::new(2),\n-            port_dropped: AtomicBool::new(false),\n-            sender_drain: AtomicIsize::new(0),\n-            select_lock: Mutex::new(()),\n-        }\n-    }\n-\n-    // This function should be used after newly created Packet\n-    // was wrapped with an Arc\n-    // In other case mutex data will be duplicated while cloning\n-    // and that could cause problems on platforms where it is\n-    // represented by opaque data structure\n-    pub fn postinit_lock(&self) -> MutexGuard<'_, ()> {\n-        self.select_lock.lock().unwrap()\n-    }\n-\n-    // This function is used at the creation of a shared packet to inherit a\n-    // previously blocked thread. This is done to prevent spurious wakeups of\n-    // threads in select().\n-    //\n-    // This can only be called at channel-creation time\n-    pub fn inherit_blocker(&self, token: Option<SignalToken>, guard: MutexGuard<'_, ()>) {\n-        if let Some(token) = token {\n-            assert_eq!(self.cnt.load(Ordering::SeqCst), 0);\n-            assert_eq!(self.to_wake.load(Ordering::SeqCst), EMPTY);\n-            self.to_wake.store(unsafe { token.to_raw() }, Ordering::SeqCst);\n-            self.cnt.store(-1, Ordering::SeqCst);\n-\n-            // This store is a little sketchy. What's happening here is that\n-            // we're transferring a blocker from a oneshot or stream channel to\n-            // this shared channel. In doing so, we never spuriously wake them\n-            // up and rather only wake them up at the appropriate time. This\n-            // implementation of shared channels assumes that any blocking\n-            // recv() will undo the increment of steals performed in try_recv()\n-            // once the recv is complete.  This thread that we're inheriting,\n-            // however, is not in the middle of recv. Hence, the first time we\n-            // wake them up, they're going to wake up from their old port, move\n-            // on to the upgraded port, and then call the block recv() function.\n-            //\n-            // When calling this function, they'll find there's data immediately\n-            // available, counting it as a steal. This in fact wasn't a steal\n-            // because we appropriately blocked them waiting for data.\n-            //\n-            // To offset this bad increment, we initially set the steal count to\n-            // -1. You'll find some special code in abort_selection() as well to\n-            // ensure that this -1 steal count doesn't escape too far.\n-            unsafe {\n-                *self.steals.get() = -1;\n-            }\n-        }\n-\n-        // When the shared packet is constructed, we grabbed this lock. The\n-        // purpose of this lock is to ensure that abort_selection() doesn't\n-        // interfere with this method. After we unlock this lock, we're\n-        // signifying that we're done modifying self.cnt and self.to_wake and\n-        // the port is ready for the world to continue using it.\n-        drop(guard);\n-    }\n-\n-    pub fn send(&self, t: T) -> Result<(), T> {\n-        // See Port::drop for what's going on\n-        if self.port_dropped.load(Ordering::SeqCst) {\n-            return Err(t);\n-        }\n-\n-        // Note that the multiple sender case is a little trickier\n-        // semantically than the single sender case. The logic for\n-        // incrementing is \"add and if disconnected store disconnected\".\n-        // This could end up leading some senders to believe that there\n-        // wasn't a disconnect if in fact there was a disconnect. This means\n-        // that while one thread is attempting to re-store the disconnected\n-        // states, other threads could walk through merrily incrementing\n-        // this very-negative disconnected count. To prevent senders from\n-        // spuriously attempting to send when the channels is actually\n-        // disconnected, the count has a ranged check here.\n-        //\n-        // This is also done for another reason. Remember that the return\n-        // value of this function is:\n-        //\n-        //  `true` == the data *may* be received, this essentially has no\n-        //            meaning\n-        //  `false` == the data will *never* be received, this has a lot of\n-        //             meaning\n-        //\n-        // In the SPSC case, we have a check of 'queue.is_empty()' to see\n-        // whether the data was actually received, but this same condition\n-        // means nothing in a multi-producer context. As a result, this\n-        // preflight check serves as the definitive \"this will never be\n-        // received\". Once we get beyond this check, we have permanently\n-        // entered the realm of \"this may be received\"\n-        if self.cnt.load(Ordering::SeqCst) < DISCONNECTED + FUDGE {\n-            return Err(t);\n-        }\n-\n-        self.queue.push(t);\n-        match self.cnt.fetch_add(1, Ordering::SeqCst) {\n-            -1 => {\n-                self.take_to_wake().signal();\n-            }\n-\n-            // In this case, we have possibly failed to send our data, and\n-            // we need to consider re-popping the data in order to fully\n-            // destroy it. We must arbitrate among the multiple senders,\n-            // however, because the queues that we're using are\n-            // single-consumer queues. In order to do this, all exiting\n-            // pushers will use an atomic count in order to count those\n-            // flowing through. Pushers who see 0 are required to drain as\n-            // much as possible, and then can only exit when they are the\n-            // only pusher (otherwise they must try again).\n-            n if n < DISCONNECTED + FUDGE => {\n-                // see the comment in 'try' for a shared channel for why this\n-                // window of \"not disconnected\" is ok.\n-                self.cnt.store(DISCONNECTED, Ordering::SeqCst);\n-\n-                if self.sender_drain.fetch_add(1, Ordering::SeqCst) == 0 {\n-                    loop {\n-                        // drain the queue, for info on the thread yield see the\n-                        // discussion in try_recv\n-                        loop {\n-                            match self.queue.pop() {\n-                                mpsc::Data(..) => {}\n-                                mpsc::Empty => break,\n-                                mpsc::Inconsistent => thread::yield_now(),\n-                            }\n-                        }\n-                        // maybe we're done, if we're not the last ones\n-                        // here, then we need to go try again.\n-                        if self.sender_drain.fetch_sub(1, Ordering::SeqCst) == 1 {\n-                            break;\n-                        }\n-                    }\n-\n-                    // At this point, there may still be data on the queue,\n-                    // but only if the count hasn't been incremented and\n-                    // some other sender hasn't finished pushing data just\n-                    // yet. That sender in question will drain its own data.\n-                }\n-            }\n-\n-            // Can't make any assumptions about this case like in the SPSC case.\n-            _ => {}\n-        }\n-\n-        Ok(())\n-    }\n-\n-    pub fn recv(&self, deadline: Option<Instant>) -> Result<T, Failure> {\n-        // This code is essentially the exact same as that found in the stream\n-        // case (see stream.rs)\n-        match self.try_recv() {\n-            Err(Empty) => {}\n-            data => return data,\n-        }\n-\n-        let (wait_token, signal_token) = blocking::tokens();\n-        if self.decrement(signal_token) == Installed {\n-            if let Some(deadline) = deadline {\n-                let timed_out = !wait_token.wait_max_until(deadline);\n-                if timed_out {\n-                    self.abort_selection(false);\n-                }\n-            } else {\n-                wait_token.wait();\n-            }\n-        }\n-\n-        match self.try_recv() {\n-            data @ Ok(..) => unsafe {\n-                *self.steals.get() -= 1;\n-                data\n-            },\n-            data => data,\n-        }\n-    }\n-\n-    // Essentially the exact same thing as the stream decrement function.\n-    // Returns true if blocking should proceed.\n-    fn decrement(&self, token: SignalToken) -> StartResult {\n-        unsafe {\n-            assert_eq!(\n-                self.to_wake.load(Ordering::SeqCst),\n-                EMPTY,\n-                \"This is a known bug in the Rust standard library. See https://github.com/rust-lang/rust/issues/39364\"\n-            );\n-            let ptr = token.to_raw();\n-            self.to_wake.store(ptr, Ordering::SeqCst);\n-\n-            let steals = ptr::replace(self.steals.get(), 0);\n-\n-            match self.cnt.fetch_sub(1 + steals, Ordering::SeqCst) {\n-                DISCONNECTED => {\n-                    self.cnt.store(DISCONNECTED, Ordering::SeqCst);\n-                }\n-                // If we factor in our steals and notice that the channel has no\n-                // data, we successfully sleep\n-                n => {\n-                    assert!(n >= 0);\n-                    if n - steals <= 0 {\n-                        return Installed;\n-                    }\n-                }\n-            }\n-\n-            self.to_wake.store(EMPTY, Ordering::SeqCst);\n-            drop(SignalToken::from_raw(ptr));\n-            Abort\n-        }\n-    }\n-\n-    pub fn try_recv(&self) -> Result<T, Failure> {\n-        let ret = match self.queue.pop() {\n-            mpsc::Data(t) => Some(t),\n-            mpsc::Empty => None,\n-\n-            // This is a bit of an interesting case. The channel is reported as\n-            // having data available, but our pop() has failed due to the queue\n-            // being in an inconsistent state.  This means that there is some\n-            // pusher somewhere which has yet to complete, but we are guaranteed\n-            // that a pop will eventually succeed. In this case, we spin in a\n-            // yield loop because the remote sender should finish their enqueue\n-            // operation \"very quickly\".\n-            //\n-            // Avoiding this yield loop would require a different queue\n-            // abstraction which provides the guarantee that after M pushes have\n-            // succeeded, at least M pops will succeed. The current queues\n-            // guarantee that if there are N active pushes, you can pop N times\n-            // once all N have finished.\n-            mpsc::Inconsistent => {\n-                let data;\n-                loop {\n-                    thread::yield_now();\n-                    match self.queue.pop() {\n-                        mpsc::Data(t) => {\n-                            data = t;\n-                            break;\n-                        }\n-                        mpsc::Empty => panic!(\"inconsistent => empty\"),\n-                        mpsc::Inconsistent => {}\n-                    }\n-                }\n-                Some(data)\n-            }\n-        };\n-        match ret {\n-            // See the discussion in the stream implementation for why we\n-            // might decrement steals.\n-            Some(data) => unsafe {\n-                if *self.steals.get() > MAX_STEALS {\n-                    match self.cnt.swap(0, Ordering::SeqCst) {\n-                        DISCONNECTED => {\n-                            self.cnt.store(DISCONNECTED, Ordering::SeqCst);\n-                        }\n-                        n => {\n-                            let m = cmp::min(n, *self.steals.get());\n-                            *self.steals.get() -= m;\n-                            self.bump(n - m);\n-                        }\n-                    }\n-                    assert!(*self.steals.get() >= 0);\n-                }\n-                *self.steals.get() += 1;\n-                Ok(data)\n-            },\n-\n-            // See the discussion in the stream implementation for why we try\n-            // again.\n-            None => {\n-                match self.cnt.load(Ordering::SeqCst) {\n-                    n if n != DISCONNECTED => Err(Empty),\n-                    _ => {\n-                        match self.queue.pop() {\n-                            mpsc::Data(t) => Ok(t),\n-                            mpsc::Empty => Err(Disconnected),\n-                            // with no senders, an inconsistency is impossible.\n-                            mpsc::Inconsistent => unreachable!(),\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-    }\n-\n-    // Prepares this shared packet for a channel clone, essentially just bumping\n-    // a refcount.\n-    pub fn clone_chan(&self) {\n-        let old_count = self.channels.fetch_add(1, Ordering::SeqCst);\n-\n-        // See comments on Arc::clone() on why we do this (for `mem::forget`).\n-        if old_count > MAX_REFCOUNT {\n-            abort();\n-        }\n-    }\n-\n-    // Decrement the reference count on a channel. This is called whenever a\n-    // Chan is dropped and may end up waking up a receiver. It's the receiver's\n-    // responsibility on the other end to figure out that we've disconnected.\n-    pub fn drop_chan(&self) {\n-        match self.channels.fetch_sub(1, Ordering::SeqCst) {\n-            1 => {}\n-            n if n > 1 => return,\n-            n => panic!(\"bad number of channels left {n}\"),\n-        }\n-\n-        match self.cnt.swap(DISCONNECTED, Ordering::SeqCst) {\n-            -1 => {\n-                self.take_to_wake().signal();\n-            }\n-            DISCONNECTED => {}\n-            n => {\n-                assert!(n >= 0);\n-            }\n-        }\n-    }\n-\n-    // See the long discussion inside of stream.rs for why the queue is drained,\n-    // and why it is done in this fashion.\n-    pub fn drop_port(&self) {\n-        self.port_dropped.store(true, Ordering::SeqCst);\n-        let mut steals = unsafe { *self.steals.get() };\n-        while {\n-            match self.cnt.compare_exchange(\n-                steals,\n-                DISCONNECTED,\n-                Ordering::SeqCst,\n-                Ordering::SeqCst,\n-            ) {\n-                Ok(_) => false,\n-                Err(old) => old != DISCONNECTED,\n-            }\n-        } {\n-            // See the discussion in 'try_recv' for why we yield\n-            // control of this thread.\n-            loop {\n-                match self.queue.pop() {\n-                    mpsc::Data(..) => {\n-                        steals += 1;\n-                    }\n-                    mpsc::Empty | mpsc::Inconsistent => break,\n-                }\n-            }\n-        }\n-    }\n-\n-    // Consumes ownership of the 'to_wake' field.\n-    fn take_to_wake(&self) -> SignalToken {\n-        let ptr = self.to_wake.load(Ordering::SeqCst);\n-        self.to_wake.store(EMPTY, Ordering::SeqCst);\n-        assert!(ptr != EMPTY);\n-        unsafe { SignalToken::from_raw(ptr) }\n-    }\n-\n-    ////////////////////////////////////////////////////////////////////////////\n-    // select implementation\n-    ////////////////////////////////////////////////////////////////////////////\n-\n-    // increment the count on the channel (used for selection)\n-    fn bump(&self, amt: isize) -> isize {\n-        match self.cnt.fetch_add(amt, Ordering::SeqCst) {\n-            DISCONNECTED => {\n-                self.cnt.store(DISCONNECTED, Ordering::SeqCst);\n-                DISCONNECTED\n-            }\n-            n => n,\n-        }\n-    }\n-\n-    // Cancels a previous thread waiting on this port, returning whether there's\n-    // data on the port.\n-    //\n-    // This is similar to the stream implementation (hence fewer comments), but\n-    // uses a different value for the \"steals\" variable.\n-    pub fn abort_selection(&self, _was_upgrade: bool) -> bool {\n-        // Before we do anything else, we bounce on this lock. The reason for\n-        // doing this is to ensure that any upgrade-in-progress is gone and\n-        // done with. Without this bounce, we can race with inherit_blocker\n-        // about looking at and dealing with to_wake. Once we have acquired the\n-        // lock, we are guaranteed that inherit_blocker is done.\n-        {\n-            let _guard = self.select_lock.lock().unwrap();\n-        }\n-\n-        // Like the stream implementation, we want to make sure that the count\n-        // on the channel goes non-negative. We don't know how negative the\n-        // stream currently is, so instead of using a steal value of 1, we load\n-        // the channel count and figure out what we should do to make it\n-        // positive.\n-        let steals = {\n-            let cnt = self.cnt.load(Ordering::SeqCst);\n-            if cnt < 0 && cnt != DISCONNECTED { -cnt } else { 0 }\n-        };\n-        let prev = self.bump(steals + 1);\n-\n-        if prev == DISCONNECTED {\n-            assert_eq!(self.to_wake.load(Ordering::SeqCst), EMPTY);\n-            true\n-        } else {\n-            let cur = prev + steals + 1;\n-            assert!(cur >= 0);\n-            if prev < 0 {\n-                drop(self.take_to_wake());\n-            } else {\n-                while self.to_wake.load(Ordering::SeqCst) != EMPTY {\n-                    thread::yield_now();\n-                }\n-            }\n-            unsafe {\n-                // if the number of steals is -1, it was the pre-emptive -1 steal\n-                // count from when we inherited a blocker. This is fine because\n-                // we're just going to overwrite it with a real value.\n-                let old = self.steals.get();\n-                assert!(*old == 0 || *old == -1);\n-                *old = steals;\n-                prev >= 0\n-            }\n-        }\n-    }\n-}\n-\n-impl<T> Drop for Packet<T> {\n-    fn drop(&mut self) {\n-        // Note that this load is not only an assert for correctness about\n-        // disconnection, but also a proper fence before the read of\n-        // `to_wake`, so this assert cannot be removed with also removing\n-        // the `to_wake` assert.\n-        assert_eq!(self.cnt.load(Ordering::SeqCst), DISCONNECTED);\n-        assert_eq!(self.to_wake.load(Ordering::SeqCst), EMPTY);\n-        assert_eq!(self.channels.load(Ordering::SeqCst), 0);\n-    }\n-}"}, {"sha": "61f91313ea96d79f645c4cfee272826ee5947de3", "filename": "library/std/src/sync/mpsc/spsc_queue.rs", "status": "removed", "additions": 0, "deletions": 244, "changes": 244, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fspsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fspsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fspsc_queue.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,244 +0,0 @@\n-//! A single-producer single-consumer concurrent queue\n-//!\n-//! This module contains the implementation of an SPSC queue which can be used\n-//! concurrently between two threads. This data structure is safe to use and\n-//! enforces the semantics that there is one pusher and one popper.\n-\n-// The original implementation is based off:\n-// https://www.1024cores.net/home/lock-free-algorithms/queues/unbounded-spsc-queue\n-//\n-// Note that back when the code was imported, it was licensed under the BSD-2-Clause license:\n-// http://web.archive.org/web/20110411011612/https://www.1024cores.net/home/lock-free-algorithms/queues/unbounded-spsc-queue\n-//\n-// The original author of the code agreed to relicense it under `MIT OR Apache-2.0` in 2017, so as\n-// of today the license of this file is the same as the rest of the codebase:\n-// https://github.com/rust-lang/rust/pull/42149\n-\n-#[cfg(all(test, not(target_os = \"emscripten\")))]\n-mod tests;\n-\n-use core::cell::UnsafeCell;\n-use core::ptr;\n-\n-use crate::boxed::Box;\n-use crate::sync::atomic::{AtomicPtr, AtomicUsize, Ordering};\n-\n-use super::cache_aligned::CacheAligned;\n-\n-// Node within the linked list queue of messages to send\n-struct Node<T> {\n-    // FIXME: this could be an uninitialized T if we're careful enough, and\n-    //      that would reduce memory usage (and be a bit faster).\n-    //      is it worth it?\n-    value: Option<T>,         // nullable for re-use of nodes\n-    cached: bool,             // This node goes into the node cache\n-    next: AtomicPtr<Node<T>>, // next node in the queue\n-}\n-\n-/// The single-producer single-consumer queue. This structure is not cloneable,\n-/// but it can be safely shared in an Arc if it is guaranteed that there\n-/// is only one popper and one pusher touching the queue at any one point in\n-/// time.\n-pub struct Queue<T, ProducerAddition = (), ConsumerAddition = ()> {\n-    // consumer fields\n-    consumer: CacheAligned<Consumer<T, ConsumerAddition>>,\n-\n-    // producer fields\n-    producer: CacheAligned<Producer<T, ProducerAddition>>,\n-}\n-\n-struct Consumer<T, Addition> {\n-    tail: UnsafeCell<*mut Node<T>>, // where to pop from\n-    tail_prev: AtomicPtr<Node<T>>,  // where to pop from\n-    cache_bound: usize,             // maximum cache size\n-    cached_nodes: AtomicUsize,      // number of nodes marked as cacheable\n-    addition: Addition,\n-}\n-\n-struct Producer<T, Addition> {\n-    head: UnsafeCell<*mut Node<T>>,      // where to push to\n-    first: UnsafeCell<*mut Node<T>>,     // where to get new nodes from\n-    tail_copy: UnsafeCell<*mut Node<T>>, // between first/tail\n-    addition: Addition,\n-}\n-\n-unsafe impl<T: Send, P: Send + Sync, C: Send + Sync> Send for Queue<T, P, C> {}\n-\n-unsafe impl<T: Send, P: Send + Sync, C: Send + Sync> Sync for Queue<T, P, C> {}\n-\n-impl<T> Node<T> {\n-    fn new() -> *mut Node<T> {\n-        Box::into_raw(box Node {\n-            value: None,\n-            cached: false,\n-            next: AtomicPtr::new(ptr::null_mut::<Node<T>>()),\n-        })\n-    }\n-}\n-\n-impl<T, ProducerAddition, ConsumerAddition> Queue<T, ProducerAddition, ConsumerAddition> {\n-    /// Creates a new queue. With given additional elements in the producer and\n-    /// consumer portions of the queue.\n-    ///\n-    /// Due to the performance implications of cache-contention,\n-    /// we wish to keep fields used mainly by the producer on a separate cache\n-    /// line than those used by the consumer.\n-    /// Since cache lines are usually 64 bytes, it is unreasonably expensive to\n-    /// allocate one for small fields, so we allow users to insert additional\n-    /// fields into the cache lines already allocated by this for the producer\n-    /// and consumer.\n-    ///\n-    /// This is unsafe as the type system doesn't enforce a single\n-    /// consumer-producer relationship. It also allows the consumer to `pop`\n-    /// items while there is a `peek` active due to all methods having a\n-    /// non-mutable receiver.\n-    ///\n-    /// # Arguments\n-    ///\n-    ///   * `bound` - This queue implementation is implemented with a linked\n-    ///               list, and this means that a push is always a malloc. In\n-    ///               order to amortize this cost, an internal cache of nodes is\n-    ///               maintained to prevent a malloc from always being\n-    ///               necessary. This bound is the limit on the size of the\n-    ///               cache (if desired). If the value is 0, then the cache has\n-    ///               no bound. Otherwise, the cache will never grow larger than\n-    ///               `bound` (although the queue itself could be much larger.\n-    pub unsafe fn with_additions(\n-        bound: usize,\n-        producer_addition: ProducerAddition,\n-        consumer_addition: ConsumerAddition,\n-    ) -> Self {\n-        let n1 = Node::new();\n-        let n2 = Node::new();\n-        (*n1).next.store(n2, Ordering::Relaxed);\n-        Queue {\n-            consumer: CacheAligned::new(Consumer {\n-                tail: UnsafeCell::new(n2),\n-                tail_prev: AtomicPtr::new(n1),\n-                cache_bound: bound,\n-                cached_nodes: AtomicUsize::new(0),\n-                addition: consumer_addition,\n-            }),\n-            producer: CacheAligned::new(Producer {\n-                head: UnsafeCell::new(n2),\n-                first: UnsafeCell::new(n1),\n-                tail_copy: UnsafeCell::new(n1),\n-                addition: producer_addition,\n-            }),\n-        }\n-    }\n-\n-    /// Pushes a new value onto this queue. Note that to use this function\n-    /// safely, it must be externally guaranteed that there is only one pusher.\n-    pub fn push(&self, t: T) {\n-        unsafe {\n-            // Acquire a node (which either uses a cached one or allocates a new\n-            // one), and then append this to the 'head' node.\n-            let n = self.alloc();\n-            assert!((*n).value.is_none());\n-            (*n).value = Some(t);\n-            (*n).next.store(ptr::null_mut(), Ordering::Relaxed);\n-            (**self.producer.head.get()).next.store(n, Ordering::Release);\n-            *(&self.producer.head).get() = n;\n-        }\n-    }\n-\n-    unsafe fn alloc(&self) -> *mut Node<T> {\n-        // First try to see if we can consume the 'first' node for our uses.\n-        if *self.producer.first.get() != *self.producer.tail_copy.get() {\n-            let ret = *self.producer.first.get();\n-            *self.producer.0.first.get() = (*ret).next.load(Ordering::Relaxed);\n-            return ret;\n-        }\n-        // If the above fails, then update our copy of the tail and try\n-        // again.\n-        *self.producer.0.tail_copy.get() = self.consumer.tail_prev.load(Ordering::Acquire);\n-        if *self.producer.first.get() != *self.producer.tail_copy.get() {\n-            let ret = *self.producer.first.get();\n-            *self.producer.0.first.get() = (*ret).next.load(Ordering::Relaxed);\n-            return ret;\n-        }\n-        // If all of that fails, then we have to allocate a new node\n-        // (there's nothing in the node cache).\n-        Node::new()\n-    }\n-\n-    /// Attempts to pop a value from this queue. Remember that to use this type\n-    /// safely you must ensure that there is only one popper at a time.\n-    pub fn pop(&self) -> Option<T> {\n-        unsafe {\n-            // The `tail` node is not actually a used node, but rather a\n-            // sentinel from where we should start popping from. Hence, look at\n-            // tail's next field and see if we can use it. If we do a pop, then\n-            // the current tail node is a candidate for going into the cache.\n-            let tail = *self.consumer.tail.get();\n-            let next = (*tail).next.load(Ordering::Acquire);\n-            if next.is_null() {\n-                return None;\n-            }\n-            assert!((*next).value.is_some());\n-            let ret = (*next).value.take();\n-\n-            *self.consumer.0.tail.get() = next;\n-            if self.consumer.cache_bound == 0 {\n-                self.consumer.tail_prev.store(tail, Ordering::Release);\n-            } else {\n-                let cached_nodes = self.consumer.cached_nodes.load(Ordering::Relaxed);\n-                if cached_nodes < self.consumer.cache_bound && !(*tail).cached {\n-                    self.consumer.cached_nodes.store(cached_nodes, Ordering::Relaxed);\n-                    (*tail).cached = true;\n-                }\n-\n-                if (*tail).cached {\n-                    self.consumer.tail_prev.store(tail, Ordering::Release);\n-                } else {\n-                    (*self.consumer.tail_prev.load(Ordering::Relaxed))\n-                        .next\n-                        .store(next, Ordering::Relaxed);\n-                    // We have successfully erased all references to 'tail', so\n-                    // now we can safely drop it.\n-                    let _: Box<Node<T>> = Box::from_raw(tail);\n-                }\n-            }\n-            ret\n-        }\n-    }\n-\n-    /// Attempts to peek at the head of the queue, returning `None` if the queue\n-    /// has no data currently\n-    ///\n-    /// # Warning\n-    /// The reference returned is invalid if it is not used before the consumer\n-    /// pops the value off the queue. If the producer then pushes another value\n-    /// onto the queue, it will overwrite the value pointed to by the reference.\n-    pub fn peek(&self) -> Option<&mut T> {\n-        // This is essentially the same as above with all the popping bits\n-        // stripped out.\n-        unsafe {\n-            let tail = *self.consumer.tail.get();\n-            let next = (*tail).next.load(Ordering::Acquire);\n-            if next.is_null() { None } else { (*next).value.as_mut() }\n-        }\n-    }\n-\n-    pub fn producer_addition(&self) -> &ProducerAddition {\n-        &self.producer.addition\n-    }\n-\n-    pub fn consumer_addition(&self) -> &ConsumerAddition {\n-        &self.consumer.addition\n-    }\n-}\n-\n-impl<T, ProducerAddition, ConsumerAddition> Drop for Queue<T, ProducerAddition, ConsumerAddition> {\n-    fn drop(&mut self) {\n-        unsafe {\n-            let mut cur = *self.producer.first.get();\n-            while !cur.is_null() {\n-                let next = (*cur).next.load(Ordering::Relaxed);\n-                let _n: Box<Node<T>> = Box::from_raw(cur);\n-                cur = next;\n-            }\n-        }\n-    }\n-}"}, {"sha": "eb6d5c2cf66d8fc71a850d05646c1706916dfbbc", "filename": "library/std/src/sync/mpsc/spsc_queue/tests.rs", "status": "removed", "additions": 0, "deletions": 102, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fspsc_queue%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fspsc_queue%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fspsc_queue%2Ftests.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,102 +0,0 @@\n-use super::Queue;\n-use crate::sync::mpsc::channel;\n-use crate::sync::Arc;\n-use crate::thread;\n-\n-#[test]\n-fn smoke() {\n-    unsafe {\n-        let queue = Queue::with_additions(0, (), ());\n-        queue.push(1);\n-        queue.push(2);\n-        assert_eq!(queue.pop(), Some(1));\n-        assert_eq!(queue.pop(), Some(2));\n-        assert_eq!(queue.pop(), None);\n-        queue.push(3);\n-        queue.push(4);\n-        assert_eq!(queue.pop(), Some(3));\n-        assert_eq!(queue.pop(), Some(4));\n-        assert_eq!(queue.pop(), None);\n-    }\n-}\n-\n-#[test]\n-fn peek() {\n-    unsafe {\n-        let queue = Queue::with_additions(0, (), ());\n-        queue.push(vec![1]);\n-\n-        // Ensure the borrowchecker works\n-        match queue.peek() {\n-            Some(vec) => {\n-                assert_eq!(&*vec, &[1]);\n-            }\n-            None => unreachable!(),\n-        }\n-\n-        match queue.pop() {\n-            Some(vec) => {\n-                assert_eq!(&*vec, &[1]);\n-            }\n-            None => unreachable!(),\n-        }\n-    }\n-}\n-\n-#[test]\n-fn drop_full() {\n-    unsafe {\n-        let q: Queue<Box<_>> = Queue::with_additions(0, (), ());\n-        q.push(Box::new(1));\n-        q.push(Box::new(2));\n-    }\n-}\n-\n-#[test]\n-fn smoke_bound() {\n-    unsafe {\n-        let q = Queue::with_additions(0, (), ());\n-        q.push(1);\n-        q.push(2);\n-        assert_eq!(q.pop(), Some(1));\n-        assert_eq!(q.pop(), Some(2));\n-        assert_eq!(q.pop(), None);\n-        q.push(3);\n-        q.push(4);\n-        assert_eq!(q.pop(), Some(3));\n-        assert_eq!(q.pop(), Some(4));\n-        assert_eq!(q.pop(), None);\n-    }\n-}\n-\n-#[test]\n-fn stress() {\n-    unsafe {\n-        stress_bound(0);\n-        stress_bound(1);\n-    }\n-\n-    unsafe fn stress_bound(bound: usize) {\n-        let count = if cfg!(miri) { 1000 } else { 100000 };\n-        let q = Arc::new(Queue::with_additions(bound, (), ()));\n-\n-        let (tx, rx) = channel();\n-        let q2 = q.clone();\n-        let _t = thread::spawn(move || {\n-            for _ in 0..count {\n-                loop {\n-                    match q2.pop() {\n-                        Some(1) => break,\n-                        Some(_) => panic!(),\n-                        None => {}\n-                    }\n-                }\n-            }\n-            tx.send(()).unwrap();\n-        });\n-        for _ in 0..count {\n-            q.push(1);\n-        }\n-        rx.recv().unwrap();\n-    }\n-}"}, {"sha": "4592e9141600e600d876a07aabe2cb6d10e70114", "filename": "library/std/src/sync/mpsc/stream.rs", "status": "removed", "additions": 0, "deletions": 457, "changes": 457, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fstream.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,457 +0,0 @@\n-/// Stream channels\n-///\n-/// This is the flavor of channels which are optimized for one sender and one\n-/// receiver. The sender will be upgraded to a shared channel if the channel is\n-/// cloned.\n-///\n-/// High level implementation details can be found in the comment of the parent\n-/// module.\n-pub use self::Failure::*;\n-use self::Message::*;\n-pub use self::UpgradeResult::*;\n-\n-use core::cmp;\n-\n-use crate::cell::UnsafeCell;\n-use crate::ptr;\n-use crate::thread;\n-use crate::time::Instant;\n-\n-use crate::sync::atomic::{AtomicBool, AtomicIsize, AtomicPtr, Ordering};\n-use crate::sync::mpsc::blocking::{self, SignalToken};\n-use crate::sync::mpsc::spsc_queue as spsc;\n-use crate::sync::mpsc::Receiver;\n-\n-const DISCONNECTED: isize = isize::MIN;\n-#[cfg(test)]\n-const MAX_STEALS: isize = 5;\n-#[cfg(not(test))]\n-const MAX_STEALS: isize = 1 << 20;\n-const EMPTY: *mut u8 = ptr::null_mut(); // initial state: no data, no blocked receiver\n-\n-pub struct Packet<T> {\n-    // internal queue for all messages\n-    queue: spsc::Queue<Message<T>, ProducerAddition, ConsumerAddition>,\n-}\n-\n-struct ProducerAddition {\n-    cnt: AtomicIsize,       // How many items are on this channel\n-    to_wake: AtomicPtr<u8>, // SignalToken for the blocked thread to wake up\n-\n-    port_dropped: AtomicBool, // flag if the channel has been destroyed.\n-}\n-\n-struct ConsumerAddition {\n-    steals: UnsafeCell<isize>, // How many times has a port received without blocking?\n-}\n-\n-pub enum Failure<T> {\n-    Empty,\n-    Disconnected,\n-    Upgraded(Receiver<T>),\n-}\n-\n-pub enum UpgradeResult {\n-    UpSuccess,\n-    UpDisconnected,\n-    UpWoke(SignalToken),\n-}\n-\n-// Any message could contain an \"upgrade request\" to a new shared port, so the\n-// internal queue it's a queue of T, but rather Message<T>\n-enum Message<T> {\n-    Data(T),\n-    GoUp(Receiver<T>),\n-}\n-\n-impl<T> Packet<T> {\n-    pub fn new() -> Packet<T> {\n-        Packet {\n-            queue: unsafe {\n-                spsc::Queue::with_additions(\n-                    128,\n-                    ProducerAddition {\n-                        cnt: AtomicIsize::new(0),\n-                        to_wake: AtomicPtr::new(EMPTY),\n-\n-                        port_dropped: AtomicBool::new(false),\n-                    },\n-                    ConsumerAddition { steals: UnsafeCell::new(0) },\n-                )\n-            },\n-        }\n-    }\n-\n-    pub fn send(&self, t: T) -> Result<(), T> {\n-        // If the other port has deterministically gone away, then definitely\n-        // must return the data back up the stack. Otherwise, the data is\n-        // considered as being sent.\n-        if self.queue.producer_addition().port_dropped.load(Ordering::SeqCst) {\n-            return Err(t);\n-        }\n-\n-        match self.do_send(Data(t)) {\n-            UpSuccess | UpDisconnected => {}\n-            UpWoke(token) => {\n-                token.signal();\n-            }\n-        }\n-        Ok(())\n-    }\n-\n-    pub fn upgrade(&self, up: Receiver<T>) -> UpgradeResult {\n-        // If the port has gone away, then there's no need to proceed any\n-        // further.\n-        if self.queue.producer_addition().port_dropped.load(Ordering::SeqCst) {\n-            return UpDisconnected;\n-        }\n-\n-        self.do_send(GoUp(up))\n-    }\n-\n-    fn do_send(&self, t: Message<T>) -> UpgradeResult {\n-        self.queue.push(t);\n-        match self.queue.producer_addition().cnt.fetch_add(1, Ordering::SeqCst) {\n-            // As described in the mod's doc comment, -1 == wakeup\n-            -1 => UpWoke(self.take_to_wake()),\n-            // As described before, SPSC queues must be >= -2\n-            -2 => UpSuccess,\n-\n-            // Be sure to preserve the disconnected state, and the return value\n-            // in this case is going to be whether our data was received or not.\n-            // This manifests itself on whether we have an empty queue or not.\n-            //\n-            // Primarily, are required to drain the queue here because the port\n-            // will never remove this data. We can only have at most one item to\n-            // drain (the port drains the rest).\n-            DISCONNECTED => {\n-                self.queue.producer_addition().cnt.store(DISCONNECTED, Ordering::SeqCst);\n-                let first = self.queue.pop();\n-                let second = self.queue.pop();\n-                assert!(second.is_none());\n-\n-                match first {\n-                    Some(..) => UpSuccess,  // we failed to send the data\n-                    None => UpDisconnected, // we successfully sent data\n-                }\n-            }\n-\n-            // Otherwise we just sent some data on a non-waiting queue, so just\n-            // make sure the world is sane and carry on!\n-            n => {\n-                assert!(n >= 0);\n-                UpSuccess\n-            }\n-        }\n-    }\n-\n-    // Consumes ownership of the 'to_wake' field.\n-    fn take_to_wake(&self) -> SignalToken {\n-        let ptr = self.queue.producer_addition().to_wake.load(Ordering::SeqCst);\n-        self.queue.producer_addition().to_wake.store(EMPTY, Ordering::SeqCst);\n-        assert!(ptr != EMPTY);\n-        unsafe { SignalToken::from_raw(ptr) }\n-    }\n-\n-    // Decrements the count on the channel for a sleeper, returning the sleeper\n-    // back if it shouldn't sleep. Note that this is the location where we take\n-    // steals into account.\n-    fn decrement(&self, token: SignalToken) -> Result<(), SignalToken> {\n-        assert_eq!(self.queue.producer_addition().to_wake.load(Ordering::SeqCst), EMPTY);\n-        let ptr = unsafe { token.to_raw() };\n-        self.queue.producer_addition().to_wake.store(ptr, Ordering::SeqCst);\n-\n-        let steals = unsafe { ptr::replace(self.queue.consumer_addition().steals.get(), 0) };\n-\n-        match self.queue.producer_addition().cnt.fetch_sub(1 + steals, Ordering::SeqCst) {\n-            DISCONNECTED => {\n-                self.queue.producer_addition().cnt.store(DISCONNECTED, Ordering::SeqCst);\n-            }\n-            // If we factor in our steals and notice that the channel has no\n-            // data, we successfully sleep\n-            n => {\n-                assert!(n >= 0);\n-                if n - steals <= 0 {\n-                    return Ok(());\n-                }\n-            }\n-        }\n-\n-        self.queue.producer_addition().to_wake.store(EMPTY, Ordering::SeqCst);\n-        Err(unsafe { SignalToken::from_raw(ptr) })\n-    }\n-\n-    pub fn recv(&self, deadline: Option<Instant>) -> Result<T, Failure<T>> {\n-        // Optimistic preflight check (scheduling is expensive).\n-        match self.try_recv() {\n-            Err(Empty) => {}\n-            data => return data,\n-        }\n-\n-        // Welp, our channel has no data. Deschedule the current thread and\n-        // initiate the blocking protocol.\n-        let (wait_token, signal_token) = blocking::tokens();\n-        if self.decrement(signal_token).is_ok() {\n-            if let Some(deadline) = deadline {\n-                let timed_out = !wait_token.wait_max_until(deadline);\n-                if timed_out {\n-                    self.abort_selection(/* was_upgrade = */ false).map_err(Upgraded)?;\n-                }\n-            } else {\n-                wait_token.wait();\n-            }\n-        }\n-\n-        match self.try_recv() {\n-            // Messages which actually popped from the queue shouldn't count as\n-            // a steal, so offset the decrement here (we already have our\n-            // \"steal\" factored into the channel count above).\n-            data @ (Ok(..) | Err(Upgraded(..))) => unsafe {\n-                *self.queue.consumer_addition().steals.get() -= 1;\n-                data\n-            },\n-\n-            data => data,\n-        }\n-    }\n-\n-    pub fn try_recv(&self) -> Result<T, Failure<T>> {\n-        match self.queue.pop() {\n-            // If we stole some data, record to that effect (this will be\n-            // factored into cnt later on).\n-            //\n-            // Note that we don't allow steals to grow without bound in order to\n-            // prevent eventual overflow of either steals or cnt as an overflow\n-            // would have catastrophic results. Sometimes, steals > cnt, but\n-            // other times cnt > steals, so we don't know the relation between\n-            // steals and cnt. This code path is executed only rarely, so we do\n-            // a pretty slow operation, of swapping 0 into cnt, taking steals\n-            // down as much as possible (without going negative), and then\n-            // adding back in whatever we couldn't factor into steals.\n-            Some(data) => unsafe {\n-                if *self.queue.consumer_addition().steals.get() > MAX_STEALS {\n-                    match self.queue.producer_addition().cnt.swap(0, Ordering::SeqCst) {\n-                        DISCONNECTED => {\n-                            self.queue\n-                                .producer_addition()\n-                                .cnt\n-                                .store(DISCONNECTED, Ordering::SeqCst);\n-                        }\n-                        n => {\n-                            let m = cmp::min(n, *self.queue.consumer_addition().steals.get());\n-                            *self.queue.consumer_addition().steals.get() -= m;\n-                            self.bump(n - m);\n-                        }\n-                    }\n-                    assert!(*self.queue.consumer_addition().steals.get() >= 0);\n-                }\n-                *self.queue.consumer_addition().steals.get() += 1;\n-                match data {\n-                    Data(t) => Ok(t),\n-                    GoUp(up) => Err(Upgraded(up)),\n-                }\n-            },\n-\n-            None => {\n-                match self.queue.producer_addition().cnt.load(Ordering::SeqCst) {\n-                    n if n != DISCONNECTED => Err(Empty),\n-\n-                    // This is a little bit of a tricky case. We failed to pop\n-                    // data above, and then we have viewed that the channel is\n-                    // disconnected. In this window more data could have been\n-                    // sent on the channel. It doesn't really make sense to\n-                    // return that the channel is disconnected when there's\n-                    // actually data on it, so be extra sure there's no data by\n-                    // popping one more time.\n-                    //\n-                    // We can ignore steals because the other end is\n-                    // disconnected and we'll never need to really factor in our\n-                    // steals again.\n-                    _ => match self.queue.pop() {\n-                        Some(Data(t)) => Ok(t),\n-                        Some(GoUp(up)) => Err(Upgraded(up)),\n-                        None => Err(Disconnected),\n-                    },\n-                }\n-            }\n-        }\n-    }\n-\n-    pub fn drop_chan(&self) {\n-        // Dropping a channel is pretty simple, we just flag it as disconnected\n-        // and then wakeup a blocker if there is one.\n-        match self.queue.producer_addition().cnt.swap(DISCONNECTED, Ordering::SeqCst) {\n-            -1 => {\n-                self.take_to_wake().signal();\n-            }\n-            DISCONNECTED => {}\n-            n => {\n-                assert!(n >= 0);\n-            }\n-        }\n-    }\n-\n-    pub fn drop_port(&self) {\n-        // Dropping a port seems like a fairly trivial thing. In theory all we\n-        // need to do is flag that we're disconnected and then everything else\n-        // can take over (we don't have anyone to wake up).\n-        //\n-        // The catch for Ports is that we want to drop the entire contents of\n-        // the queue. There are multiple reasons for having this property, the\n-        // largest of which is that if another chan is waiting in this channel\n-        // (but not received yet), then waiting on that port will cause a\n-        // deadlock.\n-        //\n-        // So if we accept that we must now destroy the entire contents of the\n-        // queue, this code may make a bit more sense. The tricky part is that\n-        // we can't let any in-flight sends go un-dropped, we have to make sure\n-        // *everything* is dropped and nothing new will come onto the channel.\n-\n-        // The first thing we do is set a flag saying that we're done for. All\n-        // sends are gated on this flag, so we're immediately guaranteed that\n-        // there are a bounded number of active sends that we'll have to deal\n-        // with.\n-        self.queue.producer_addition().port_dropped.store(true, Ordering::SeqCst);\n-\n-        // Now that we're guaranteed to deal with a bounded number of senders,\n-        // we need to drain the queue. This draining process happens atomically\n-        // with respect to the \"count\" of the channel. If the count is nonzero\n-        // (with steals taken into account), then there must be data on the\n-        // channel. In this case we drain everything and then try again. We will\n-        // continue to fail while active senders send data while we're dropping\n-        // data, but eventually we're guaranteed to break out of this loop\n-        // (because there is a bounded number of senders).\n-        let mut steals = unsafe { *self.queue.consumer_addition().steals.get() };\n-        while {\n-            match self.queue.producer_addition().cnt.compare_exchange(\n-                steals,\n-                DISCONNECTED,\n-                Ordering::SeqCst,\n-                Ordering::SeqCst,\n-            ) {\n-                Ok(_) => false,\n-                Err(old) => old != DISCONNECTED,\n-            }\n-        } {\n-            while self.queue.pop().is_some() {\n-                steals += 1;\n-            }\n-        }\n-\n-        // At this point in time, we have gated all future senders from sending,\n-        // and we have flagged the channel as being disconnected. The senders\n-        // still have some responsibility, however, because some sends might not\n-        // complete until after we flag the disconnection. There are more\n-        // details in the sending methods that see DISCONNECTED\n-    }\n-\n-    ////////////////////////////////////////////////////////////////////////////\n-    // select implementation\n-    ////////////////////////////////////////////////////////////////////////////\n-\n-    // increment the count on the channel (used for selection)\n-    fn bump(&self, amt: isize) -> isize {\n-        match self.queue.producer_addition().cnt.fetch_add(amt, Ordering::SeqCst) {\n-            DISCONNECTED => {\n-                self.queue.producer_addition().cnt.store(DISCONNECTED, Ordering::SeqCst);\n-                DISCONNECTED\n-            }\n-            n => n,\n-        }\n-    }\n-\n-    // Removes a previous thread from being blocked in this port\n-    pub fn abort_selection(&self, was_upgrade: bool) -> Result<bool, Receiver<T>> {\n-        // If we're aborting selection after upgrading from a oneshot, then\n-        // we're guarantee that no one is waiting. The only way that we could\n-        // have seen the upgrade is if data was actually sent on the channel\n-        // half again. For us, this means that there is guaranteed to be data on\n-        // this channel. Furthermore, we're guaranteed that there was no\n-        // start_selection previously, so there's no need to modify `self.cnt`\n-        // at all.\n-        //\n-        // Hence, because of these invariants, we immediately return `Ok(true)`.\n-        // Note that the data might not actually be sent on the channel just yet.\n-        // The other end could have flagged the upgrade but not sent data to\n-        // this end. This is fine because we know it's a small bounded windows\n-        // of time until the data is actually sent.\n-        if was_upgrade {\n-            assert_eq!(unsafe { *self.queue.consumer_addition().steals.get() }, 0);\n-            assert_eq!(self.queue.producer_addition().to_wake.load(Ordering::SeqCst), EMPTY);\n-            return Ok(true);\n-        }\n-\n-        // We want to make sure that the count on the channel goes non-negative,\n-        // and in the stream case we can have at most one steal, so just assume\n-        // that we had one steal.\n-        let steals = 1;\n-        let prev = self.bump(steals + 1);\n-\n-        // If we were previously disconnected, then we know for sure that there\n-        // is no thread in to_wake, so just keep going\n-        let has_data = if prev == DISCONNECTED {\n-            assert_eq!(self.queue.producer_addition().to_wake.load(Ordering::SeqCst), EMPTY);\n-            true // there is data, that data is that we're disconnected\n-        } else {\n-            let cur = prev + steals + 1;\n-            assert!(cur >= 0);\n-\n-            // If the previous count was negative, then we just made things go\n-            // positive, hence we passed the -1 boundary and we're responsible\n-            // for removing the to_wake() field and trashing it.\n-            //\n-            // If the previous count was positive then we're in a tougher\n-            // situation. A possible race is that a sender just incremented\n-            // through -1 (meaning it's going to try to wake a thread up), but it\n-            // hasn't yet read the to_wake. In order to prevent a future recv()\n-            // from waking up too early (this sender picking up the plastered\n-            // over to_wake), we spin loop here waiting for to_wake to be 0.\n-            // Note that this entire select() implementation needs an overhaul,\n-            // and this is *not* the worst part of it, so this is not done as a\n-            // final solution but rather out of necessity for now to get\n-            // something working.\n-            if prev < 0 {\n-                drop(self.take_to_wake());\n-            } else {\n-                while self.queue.producer_addition().to_wake.load(Ordering::SeqCst) != EMPTY {\n-                    thread::yield_now();\n-                }\n-            }\n-            unsafe {\n-                assert_eq!(*self.queue.consumer_addition().steals.get(), 0);\n-                *self.queue.consumer_addition().steals.get() = steals;\n-            }\n-\n-            // if we were previously positive, then there's surely data to\n-            // receive\n-            prev >= 0\n-        };\n-\n-        // Now that we've determined that this queue \"has data\", we peek at the\n-        // queue to see if the data is an upgrade or not. If it's an upgrade,\n-        // then we need to destroy this port and abort selection on the\n-        // upgraded port.\n-        if has_data {\n-            match self.queue.peek() {\n-                Some(&mut GoUp(..)) => match self.queue.pop() {\n-                    Some(GoUp(port)) => Err(port),\n-                    _ => unreachable!(),\n-                },\n-                _ => Ok(true),\n-            }\n-        } else {\n-            Ok(false)\n-        }\n-    }\n-}\n-\n-impl<T> Drop for Packet<T> {\n-    fn drop(&mut self) {\n-        // Note that this load is not only an assert for correctness about\n-        // disconnection, but also a proper fence before the read of\n-        // `to_wake`, so this assert cannot be removed with also removing\n-        // the `to_wake` assert.\n-        assert_eq!(self.queue.producer_addition().cnt.load(Ordering::SeqCst), DISCONNECTED);\n-        assert_eq!(self.queue.producer_addition().to_wake.load(Ordering::SeqCst), EMPTY);\n-    }\n-}"}, {"sha": "733761671a041e75bffa361e8cc906a26559b4fb", "filename": "library/std/src/sync/mpsc/sync.rs", "status": "removed", "additions": 0, "deletions": 495, "changes": 495, "blob_url": "https://github.com/rust-lang/rust/blob/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a43da5a09701469e013c623c7cfc1e2f7ec83e47/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fstd%2Fsrc%2Fsync%2Fmpsc%2Fsync.rs?ref=a43da5a09701469e013c623c7cfc1e2f7ec83e47", "patch": "@@ -1,495 +0,0 @@\n-use self::Blocker::*;\n-/// Synchronous channels/ports\n-///\n-/// This channel implementation differs significantly from the asynchronous\n-/// implementations found next to it (oneshot/stream/share). This is an\n-/// implementation of a synchronous, bounded buffer channel.\n-///\n-/// Each channel is created with some amount of backing buffer, and sends will\n-/// *block* until buffer space becomes available. A buffer size of 0 is valid,\n-/// which means that every successful send is paired with a successful recv.\n-///\n-/// This flavor of channels defines a new `send_opt` method for channels which\n-/// is the method by which a message is sent but the thread does not panic if it\n-/// cannot be delivered.\n-///\n-/// Another major difference is that send() will *always* return back the data\n-/// if it couldn't be sent. This is because it is deterministically known when\n-/// the data is received and when it is not received.\n-///\n-/// Implementation-wise, it can all be summed up with \"use a mutex plus some\n-/// logic\". The mutex used here is an OS native mutex, meaning that no user code\n-/// is run inside of the mutex (to prevent context switching). This\n-/// implementation shares almost all code for the buffered and unbuffered cases\n-/// of a synchronous channel. There are a few branches for the unbuffered case,\n-/// but they're mostly just relevant to blocking senders.\n-pub use self::Failure::*;\n-\n-use core::intrinsics::abort;\n-use core::mem;\n-use core::ptr;\n-\n-use crate::sync::atomic::{AtomicUsize, Ordering};\n-use crate::sync::mpsc::blocking::{self, SignalToken, WaitToken};\n-use crate::sync::{Mutex, MutexGuard};\n-use crate::time::Instant;\n-\n-const MAX_REFCOUNT: usize = (isize::MAX) as usize;\n-\n-pub struct Packet<T> {\n-    /// Only field outside of the mutex. Just done for kicks, but mainly because\n-    /// the other shared channel already had the code implemented\n-    channels: AtomicUsize,\n-\n-    lock: Mutex<State<T>>,\n-}\n-\n-unsafe impl<T: Send> Send for Packet<T> {}\n-\n-unsafe impl<T: Send> Sync for Packet<T> {}\n-\n-struct State<T> {\n-    disconnected: bool, // Is the channel disconnected yet?\n-    queue: Queue,       // queue of senders waiting to send data\n-    blocker: Blocker,   // currently blocked thread on this channel\n-    buf: Buffer<T>,     // storage for buffered messages\n-    cap: usize,         // capacity of this channel\n-\n-    /// A curious flag used to indicate whether a sender failed or succeeded in\n-    /// blocking. This is used to transmit information back to the thread that it\n-    /// must dequeue its message from the buffer because it was not received.\n-    /// This is only relevant in the 0-buffer case. This obviously cannot be\n-    /// safely constructed, but it's guaranteed to always have a valid pointer\n-    /// value.\n-    canceled: Option<&'static mut bool>,\n-}\n-\n-unsafe impl<T: Send> Send for State<T> {}\n-\n-/// Possible flavors of threads who can be blocked on this channel.\n-enum Blocker {\n-    BlockedSender(SignalToken),\n-    BlockedReceiver(SignalToken),\n-    NoneBlocked,\n-}\n-\n-/// Simple queue for threading threads together. Nodes are stack-allocated, so\n-/// this structure is not safe at all\n-struct Queue {\n-    head: *mut Node,\n-    tail: *mut Node,\n-}\n-\n-struct Node {\n-    token: Option<SignalToken>,\n-    next: *mut Node,\n-}\n-\n-unsafe impl Send for Node {}\n-\n-/// A simple ring-buffer\n-struct Buffer<T> {\n-    buf: Vec<Option<T>>,\n-    start: usize,\n-    size: usize,\n-}\n-\n-#[derive(Debug)]\n-pub enum Failure {\n-    Empty,\n-    Disconnected,\n-}\n-\n-/// Atomically blocks the current thread, placing it into `slot`, unlocking `lock`\n-/// in the meantime. This re-locks the mutex upon returning.\n-fn wait<'a, 'b, T>(\n-    lock: &'a Mutex<State<T>>,\n-    mut guard: MutexGuard<'b, State<T>>,\n-    f: fn(SignalToken) -> Blocker,\n-) -> MutexGuard<'a, State<T>> {\n-    let (wait_token, signal_token) = blocking::tokens();\n-    match mem::replace(&mut guard.blocker, f(signal_token)) {\n-        NoneBlocked => {}\n-        _ => unreachable!(),\n-    }\n-    drop(guard); // unlock\n-    wait_token.wait(); // block\n-    lock.lock().unwrap() // relock\n-}\n-\n-/// Same as wait, but waiting at most until `deadline`.\n-fn wait_timeout_receiver<'a, 'b, T>(\n-    lock: &'a Mutex<State<T>>,\n-    deadline: Instant,\n-    mut guard: MutexGuard<'b, State<T>>,\n-    success: &mut bool,\n-) -> MutexGuard<'a, State<T>> {\n-    let (wait_token, signal_token) = blocking::tokens();\n-    match mem::replace(&mut guard.blocker, BlockedReceiver(signal_token)) {\n-        NoneBlocked => {}\n-        _ => unreachable!(),\n-    }\n-    drop(guard); // unlock\n-    *success = wait_token.wait_max_until(deadline); // block\n-    let mut new_guard = lock.lock().unwrap(); // relock\n-    if !*success {\n-        abort_selection(&mut new_guard);\n-    }\n-    new_guard\n-}\n-\n-fn abort_selection<T>(guard: &mut MutexGuard<'_, State<T>>) -> bool {\n-    match mem::replace(&mut guard.blocker, NoneBlocked) {\n-        NoneBlocked => true,\n-        BlockedSender(token) => {\n-            guard.blocker = BlockedSender(token);\n-            true\n-        }\n-        BlockedReceiver(token) => {\n-            drop(token);\n-            false\n-        }\n-    }\n-}\n-\n-/// Wakes up a thread, dropping the lock at the correct time\n-fn wakeup<T>(token: SignalToken, guard: MutexGuard<'_, State<T>>) {\n-    // We need to be careful to wake up the waiting thread *outside* of the mutex\n-    // in case it incurs a context switch.\n-    drop(guard);\n-    token.signal();\n-}\n-\n-impl<T> Packet<T> {\n-    pub fn new(capacity: usize) -> Packet<T> {\n-        Packet {\n-            channels: AtomicUsize::new(1),\n-            lock: Mutex::new(State {\n-                disconnected: false,\n-                blocker: NoneBlocked,\n-                cap: capacity,\n-                canceled: None,\n-                queue: Queue { head: ptr::null_mut(), tail: ptr::null_mut() },\n-                buf: Buffer {\n-                    buf: (0..capacity + if capacity == 0 { 1 } else { 0 }).map(|_| None).collect(),\n-                    start: 0,\n-                    size: 0,\n-                },\n-            }),\n-        }\n-    }\n-\n-    // wait until a send slot is available, returning locked access to\n-    // the channel state.\n-    fn acquire_send_slot(&self) -> MutexGuard<'_, State<T>> {\n-        let mut node = Node { token: None, next: ptr::null_mut() };\n-        loop {\n-            let mut guard = self.lock.lock().unwrap();\n-            // are we ready to go?\n-            if guard.disconnected || guard.buf.size() < guard.buf.capacity() {\n-                return guard;\n-            }\n-            // no room; actually block\n-            let wait_token = guard.queue.enqueue(&mut node);\n-            drop(guard);\n-            wait_token.wait();\n-        }\n-    }\n-\n-    pub fn send(&self, t: T) -> Result<(), T> {\n-        let mut guard = self.acquire_send_slot();\n-        if guard.disconnected {\n-            return Err(t);\n-        }\n-        guard.buf.enqueue(t);\n-\n-        match mem::replace(&mut guard.blocker, NoneBlocked) {\n-            // if our capacity is 0, then we need to wait for a receiver to be\n-            // available to take our data. After waiting, we check again to make\n-            // sure the port didn't go away in the meantime. If it did, we need\n-            // to hand back our data.\n-            NoneBlocked if guard.cap == 0 => {\n-                let mut canceled = false;\n-                assert!(guard.canceled.is_none());\n-                guard.canceled = Some(unsafe { mem::transmute(&mut canceled) });\n-                let mut guard = wait(&self.lock, guard, BlockedSender);\n-                if canceled { Err(guard.buf.dequeue()) } else { Ok(()) }\n-            }\n-\n-            // success, we buffered some data\n-            NoneBlocked => Ok(()),\n-\n-            // success, someone's about to receive our buffered data.\n-            BlockedReceiver(token) => {\n-                wakeup(token, guard);\n-                Ok(())\n-            }\n-\n-            BlockedSender(..) => panic!(\"lolwut\"),\n-        }\n-    }\n-\n-    pub fn try_send(&self, t: T) -> Result<(), super::TrySendError<T>> {\n-        let mut guard = self.lock.lock().unwrap();\n-        if guard.disconnected {\n-            Err(super::TrySendError::Disconnected(t))\n-        } else if guard.buf.size() == guard.buf.capacity() {\n-            Err(super::TrySendError::Full(t))\n-        } else if guard.cap == 0 {\n-            // With capacity 0, even though we have buffer space we can't\n-            // transfer the data unless there's a receiver waiting.\n-            match mem::replace(&mut guard.blocker, NoneBlocked) {\n-                NoneBlocked => Err(super::TrySendError::Full(t)),\n-                BlockedSender(..) => unreachable!(),\n-                BlockedReceiver(token) => {\n-                    guard.buf.enqueue(t);\n-                    wakeup(token, guard);\n-                    Ok(())\n-                }\n-            }\n-        } else {\n-            // If the buffer has some space and the capacity isn't 0, then we\n-            // just enqueue the data for later retrieval, ensuring to wake up\n-            // any blocked receiver if there is one.\n-            assert!(guard.buf.size() < guard.buf.capacity());\n-            guard.buf.enqueue(t);\n-            match mem::replace(&mut guard.blocker, NoneBlocked) {\n-                BlockedReceiver(token) => wakeup(token, guard),\n-                NoneBlocked => {}\n-                BlockedSender(..) => unreachable!(),\n-            }\n-            Ok(())\n-        }\n-    }\n-\n-    // Receives a message from this channel\n-    //\n-    // When reading this, remember that there can only ever be one receiver at\n-    // time.\n-    pub fn recv(&self, deadline: Option<Instant>) -> Result<T, Failure> {\n-        let mut guard = self.lock.lock().unwrap();\n-\n-        let mut woke_up_after_waiting = false;\n-        // Wait for the buffer to have something in it. No need for a\n-        // while loop because we're the only receiver.\n-        if !guard.disconnected && guard.buf.size() == 0 {\n-            if let Some(deadline) = deadline {\n-                guard =\n-                    wait_timeout_receiver(&self.lock, deadline, guard, &mut woke_up_after_waiting);\n-            } else {\n-                guard = wait(&self.lock, guard, BlockedReceiver);\n-                woke_up_after_waiting = true;\n-            }\n-        }\n-\n-        // N.B., channel could be disconnected while waiting, so the order of\n-        // these conditionals is important.\n-        if guard.disconnected && guard.buf.size() == 0 {\n-            return Err(Disconnected);\n-        }\n-\n-        // Pick up the data, wake up our neighbors, and carry on\n-        assert!(guard.buf.size() > 0 || (deadline.is_some() && !woke_up_after_waiting));\n-\n-        if guard.buf.size() == 0 {\n-            return Err(Empty);\n-        }\n-\n-        let ret = guard.buf.dequeue();\n-        self.wakeup_senders(woke_up_after_waiting, guard);\n-        Ok(ret)\n-    }\n-\n-    pub fn try_recv(&self) -> Result<T, Failure> {\n-        let mut guard = self.lock.lock().unwrap();\n-\n-        // Easy cases first\n-        if guard.disconnected && guard.buf.size() == 0 {\n-            return Err(Disconnected);\n-        }\n-        if guard.buf.size() == 0 {\n-            return Err(Empty);\n-        }\n-\n-        // Be sure to wake up neighbors\n-        let ret = Ok(guard.buf.dequeue());\n-        self.wakeup_senders(false, guard);\n-        ret\n-    }\n-\n-    // Wake up pending senders after some data has been received\n-    //\n-    // * `waited` - flag if the receiver blocked to receive some data, or if it\n-    //              just picked up some data on the way out\n-    // * `guard` - the lock guard that is held over this channel's lock\n-    fn wakeup_senders(&self, waited: bool, mut guard: MutexGuard<'_, State<T>>) {\n-        let pending_sender1: Option<SignalToken> = guard.queue.dequeue();\n-\n-        // If this is a no-buffer channel (cap == 0), then if we didn't wait we\n-        // need to ACK the sender. If we waited, then the sender waking us up\n-        // was already the ACK.\n-        let pending_sender2 = if guard.cap == 0 && !waited {\n-            match mem::replace(&mut guard.blocker, NoneBlocked) {\n-                NoneBlocked => None,\n-                BlockedReceiver(..) => unreachable!(),\n-                BlockedSender(token) => {\n-                    guard.canceled.take();\n-                    Some(token)\n-                }\n-            }\n-        } else {\n-            None\n-        };\n-        mem::drop(guard);\n-\n-        // only outside of the lock do we wake up the pending threads\n-        if let Some(token) = pending_sender1 {\n-            token.signal();\n-        }\n-        if let Some(token) = pending_sender2 {\n-            token.signal();\n-        }\n-    }\n-\n-    // Prepares this shared packet for a channel clone, essentially just bumping\n-    // a refcount.\n-    pub fn clone_chan(&self) {\n-        let old_count = self.channels.fetch_add(1, Ordering::SeqCst);\n-\n-        // See comments on Arc::clone() on why we do this (for `mem::forget`).\n-        if old_count > MAX_REFCOUNT {\n-            abort();\n-        }\n-    }\n-\n-    pub fn drop_chan(&self) {\n-        // Only flag the channel as disconnected if we're the last channel\n-        match self.channels.fetch_sub(1, Ordering::SeqCst) {\n-            1 => {}\n-            _ => return,\n-        }\n-\n-        // Not much to do other than wake up a receiver if one's there\n-        let mut guard = self.lock.lock().unwrap();\n-        if guard.disconnected {\n-            return;\n-        }\n-        guard.disconnected = true;\n-        match mem::replace(&mut guard.blocker, NoneBlocked) {\n-            NoneBlocked => {}\n-            BlockedSender(..) => unreachable!(),\n-            BlockedReceiver(token) => wakeup(token, guard),\n-        }\n-    }\n-\n-    pub fn drop_port(&self) {\n-        let mut guard = self.lock.lock().unwrap();\n-\n-        if guard.disconnected {\n-            return;\n-        }\n-        guard.disconnected = true;\n-\n-        // If the capacity is 0, then the sender may want its data back after\n-        // we're disconnected. Otherwise it's now our responsibility to destroy\n-        // the buffered data. As with many other portions of this code, this\n-        // needs to be careful to destroy the data *outside* of the lock to\n-        // prevent deadlock.\n-        let _data = if guard.cap != 0 { mem::take(&mut guard.buf.buf) } else { Vec::new() };\n-        let mut queue =\n-            mem::replace(&mut guard.queue, Queue { head: ptr::null_mut(), tail: ptr::null_mut() });\n-\n-        let waiter = match mem::replace(&mut guard.blocker, NoneBlocked) {\n-            NoneBlocked => None,\n-            BlockedSender(token) => {\n-                *guard.canceled.take().unwrap() = true;\n-                Some(token)\n-            }\n-            BlockedReceiver(..) => unreachable!(),\n-        };\n-        mem::drop(guard);\n-\n-        while let Some(token) = queue.dequeue() {\n-            token.signal();\n-        }\n-        if let Some(token) = waiter {\n-            token.signal();\n-        }\n-    }\n-}\n-\n-impl<T> Drop for Packet<T> {\n-    fn drop(&mut self) {\n-        assert_eq!(self.channels.load(Ordering::SeqCst), 0);\n-        let mut guard = self.lock.lock().unwrap();\n-        assert!(guard.queue.dequeue().is_none());\n-        assert!(guard.canceled.is_none());\n-    }\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Buffer, a simple ring buffer backed by Vec<T>\n-////////////////////////////////////////////////////////////////////////////////\n-\n-impl<T> Buffer<T> {\n-    fn enqueue(&mut self, t: T) {\n-        let pos = (self.start + self.size) % self.buf.len();\n-        self.size += 1;\n-        let prev = mem::replace(&mut self.buf[pos], Some(t));\n-        assert!(prev.is_none());\n-    }\n-\n-    fn dequeue(&mut self) -> T {\n-        let start = self.start;\n-        self.size -= 1;\n-        self.start = (self.start + 1) % self.buf.len();\n-        let result = &mut self.buf[start];\n-        result.take().unwrap()\n-    }\n-\n-    fn size(&self) -> usize {\n-        self.size\n-    }\n-    fn capacity(&self) -> usize {\n-        self.buf.len()\n-    }\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Queue, a simple queue to enqueue threads with (stack-allocated nodes)\n-////////////////////////////////////////////////////////////////////////////////\n-\n-impl Queue {\n-    fn enqueue(&mut self, node: &mut Node) -> WaitToken {\n-        let (wait_token, signal_token) = blocking::tokens();\n-        node.token = Some(signal_token);\n-        node.next = ptr::null_mut();\n-\n-        if self.tail.is_null() {\n-            self.head = node as *mut Node;\n-            self.tail = node as *mut Node;\n-        } else {\n-            unsafe {\n-                (*self.tail).next = node as *mut Node;\n-                self.tail = node as *mut Node;\n-            }\n-        }\n-\n-        wait_token\n-    }\n-\n-    fn dequeue(&mut self) -> Option<SignalToken> {\n-        if self.head.is_null() {\n-            return None;\n-        }\n-        let node = self.head;\n-        self.head = unsafe { (*node).next };\n-        if self.head.is_null() {\n-            self.tail = ptr::null_mut();\n-        }\n-        unsafe {\n-            (*node).next = ptr::null_mut();\n-            Some((*node).token.take().unwrap())\n-        }\n-    }\n-}"}]}