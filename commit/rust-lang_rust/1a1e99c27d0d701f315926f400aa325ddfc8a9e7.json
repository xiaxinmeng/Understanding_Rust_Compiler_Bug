{"sha": "1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFhMWU5OWMyN2QwZDcwMWYzMTU5MjZmNDAwYWEzMjVkZGZjOGE5ZTc=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-11-17T02:54:48Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-11-18T02:38:39Z"}, "message": "Merge remote-tracking branch 'brson/codemap'\n\nConflicts:\n\tsrc/libsyntax/ext/source_util.rs", "tree": {"sha": "27286028e54cd6af98f1a3294c43984306b2215e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/27286028e54cd6af98f1a3294c43984306b2215e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "html_url": "https://github.com/rust-lang/rust/commit/1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "428c58b9f983d31f9c7df2d48d45f6a22996692e", "url": "https://api.github.com/repos/rust-lang/rust/commits/428c58b9f983d31f9c7df2d48d45f6a22996692e", "html_url": "https://github.com/rust-lang/rust/commit/428c58b9f983d31f9c7df2d48d45f6a22996692e"}, {"sha": "e621e68c60d02bb33a2d808071f3f07674db871c", "url": "https://api.github.com/repos/rust-lang/rust/commits/e621e68c60d02bb33a2d808071f3f07674db871c", "html_url": "https://github.com/rust-lang/rust/commit/e621e68c60d02bb33a2d808071f3f07674db871c"}], "stats": {"total": 1228, "additions": 710, "deletions": 518}, "files": [{"sha": "86e45179cb033441782d7f097ef1f4df7360e738", "filename": "src/libfuzzer/fuzzer.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibfuzzer%2Ffuzzer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibfuzzer%2Ffuzzer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibfuzzer%2Ffuzzer.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -225,7 +225,7 @@ fn as_str(f: fn@(+x: io::Writer)) -> ~str {\n     io::with_str_writer(f)\n }\n \n-fn check_variants_of_ast(crate: ast::crate, codemap: codemap::CodeMap,\n+fn check_variants_of_ast(crate: ast::crate, codemap: @codemap::CodeMap,\n                          filename: &Path, cx: context) {\n     let stolen = steal(crate, cx.mode);\n     let extra_exprs = vec::filter(common_exprs(),\n@@ -239,7 +239,7 @@ fn check_variants_of_ast(crate: ast::crate, codemap: codemap::CodeMap,\n \n fn check_variants_T<T: Copy>(\n   crate: ast::crate,\n-  codemap: codemap::CodeMap,\n+  codemap: @codemap::CodeMap,\n   filename: &Path,\n   thing_label: ~str,\n   things: ~[T],"}, {"sha": "6476b1bb6d4f41d76b5554e6f57056d88ded9bd0", "filename": "src/librustc/driver/driver.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fdriver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fdriver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdriver%2Fdriver.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -366,7 +366,7 @@ fn pretty_print_input(sess: Session, cfg: ast::crate_cfg, input: input,\n       ppm_expanded | ppm_normal => pprust::no_ann()\n     };\n     let is_expanded = upto != cu_parse;\n-    let src = codemap::get_filemap(sess.codemap, source_name(input)).src;\n+    let src = sess.codemap.get_filemap(source_name(input)).src;\n     do io::with_str_reader(*src) |rdr| {\n         pprust::print_crate(sess.codemap, sess.parse_sess.interner,\n                             sess.span_diagnostic, crate,\n@@ -586,7 +586,7 @@ fn build_session_options(binary: ~str,\n \n fn build_session(sopts: @session::options,\n                  demitter: diagnostic::emitter) -> Session {\n-    let codemap = codemap::new_codemap();\n+    let codemap = @codemap::CodeMap::new();\n     let diagnostic_handler =\n         diagnostic::mk_handler(Some(demitter));\n     let span_diagnostic_handler =\n@@ -595,7 +595,7 @@ fn build_session(sopts: @session::options,\n }\n \n fn build_session_(sopts: @session::options,\n-                  cm: codemap::CodeMap,\n+                  cm: @codemap::CodeMap,\n                   demitter: diagnostic::emitter,\n                   span_diagnostic_handler: diagnostic::span_handler)\n                -> Session {"}, {"sha": "d2a277e82fbd522f6b9c92df2cc32648c666dc81", "filename": "src/librustc/driver/session.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fdriver%2Fsession.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fdriver%2Fsession.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdriver%2Fsession.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -131,7 +131,7 @@ type Session_ = {targ_cfg: @config,\n                  opts: @options,\n                  cstore: metadata::cstore::CStore,\n                  parse_sess: parse_sess,\n-                 codemap: codemap::CodeMap,\n+                 codemap: @codemap::CodeMap,\n                  // For a library crate, this is always none\n                  mut main_fn: Option<(node_id, codemap::span)>,\n                  span_diagnostic: diagnostic::span_handler,"}, {"sha": "6c5a3d0470c7833a735a4fa49c0e82b4c3e9e227", "filename": "src/librustc/metadata/encoder.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmetadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmetadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Fencoder.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -557,7 +557,7 @@ fn encode_info_for_item(ecx: @encode_ctxt, ebml_w: ebml::Serializer,\n     let add_to_index = |copy ebml_w| add_to_index_(item, ebml_w, index);\n \n     debug!(\"encoding info for item at %s\",\n-           syntax::codemap::span_to_str(item.span, ecx.tcx.sess.codemap));\n+           ecx.tcx.sess.codemap.span_to_str(item.span));\n \n     match item.node {\n       item_const(_, _) => {"}, {"sha": "2465017f545cee1998075f7ad96729bd8f637ef1", "filename": "src/librustc/middle/liveness.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Fliveness.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Fliveness.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fliveness.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -97,7 +97,7 @@ use std::map::HashMap;\n use syntax::{visit, ast_util};\n use syntax::print::pprust::{expr_to_str, block_to_str};\n use visit::vt;\n-use syntax::codemap::{span, span_to_str};\n+use syntax::codemap::span;\n use syntax::ast::*;\n use io::WriterUtil;\n use capture::{cap_move, cap_drop, cap_copy, cap_ref};\n@@ -170,9 +170,9 @@ impl LiveNodeKind : cmp::Eq {\n fn live_node_kind_to_str(lnk: LiveNodeKind, cx: ty::ctxt) -> ~str {\n     let cm = cx.sess.codemap;\n     match lnk {\n-        FreeVarNode(s) => fmt!(\"Free var node [%s]\", span_to_str(s, cm)),\n-        ExprNode(s)    => fmt!(\"Expr node [%s]\", span_to_str(s, cm)),\n-        VarDefNode(s)  => fmt!(\"Var def node [%s]\", span_to_str(s, cm)),\n+        FreeVarNode(s) => fmt!(\"Free var node [%s]\", cm.span_to_str(s)),\n+        ExprNode(s)    => fmt!(\"Expr node [%s]\", cm.span_to_str(s)),\n+        VarDefNode(s)  => fmt!(\"Var def node [%s]\", cm.span_to_str(s)),\n         ExitNode       => ~\"Exit node\"\n     }\n }"}, {"sha": "548018438ca3d817bd2ebb09b92622362a843c37", "filename": "src/librustc/middle/trans/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbase.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -919,7 +919,7 @@ fn trans_trace(bcx: block, sp_opt: Option<span>, trace_str: ~str) {\n     let {V_filename, V_line} = match sp_opt {\n       Some(sp) => {\n         let sess = bcx.sess();\n-        let loc = codemap::lookup_char_pos(sess.parse_sess.cm, sp.lo);\n+        let loc = sess.parse_sess.cm.lookup_char_pos(sp.lo);\n         {V_filename: C_cstr(bcx.ccx(), loc.file.name),\n          V_line: loc.line as int}\n       }"}, {"sha": "f980990517495ff27aa707c029b2976fa6100f10", "filename": "src/librustc/middle/trans/build.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbuild.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -645,7 +645,7 @@ fn _UndefReturn(cx: block, Fn: ValueRef) -> ValueRef {\n fn add_span_comment(bcx: block, sp: span, text: ~str) {\n     let ccx = bcx.ccx();\n     if !ccx.sess.no_asm_comments() {\n-        let s = text + ~\" (\" + codemap::span_to_str(sp, ccx.sess.codemap)\n+        let s = text + ~\" (\" + ccx.sess.codemap.span_to_str(sp)\n             + ~\")\";\n         log(debug, s);\n         add_comment(bcx, s);"}, {"sha": "0c09b02bb07b108da688bff7ae929d6a62c38bec", "filename": "src/librustc/middle/trans/controlflow.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcontrolflow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcontrolflow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcontrolflow.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -339,7 +339,7 @@ fn trans_fail_value(bcx: block, sp_opt: Option<span>, V_fail_str: ValueRef)\n     let {V_filename, V_line} = match sp_opt {\n       Some(sp) => {\n         let sess = bcx.sess();\n-        let loc = codemap::lookup_char_pos(sess.parse_sess.cm, sp.lo);\n+        let loc = sess.parse_sess.cm.lookup_char_pos(sp.lo);\n         {V_filename: C_cstr(bcx.ccx(), loc.file.name),\n          V_line: loc.line as int}\n       }\n@@ -361,7 +361,7 @@ fn trans_fail_bounds_check(bcx: block, sp: span,\n     let _icx = bcx.insn_ctxt(\"trans_fail_bounds_check\");\n     let ccx = bcx.ccx();\n \n-    let loc = codemap::lookup_char_pos(bcx.sess().parse_sess.cm, sp.lo);\n+    let loc = bcx.sess().parse_sess.cm.lookup_char_pos(sp.lo);\n     let line = C_int(ccx, loc.line as int);\n     let filename_cstr = C_cstr(bcx.ccx(), loc.file.name);\n     let filename = PointerCast(bcx, filename_cstr, T_ptr(T_i8()));"}, {"sha": "d4d1c8d3b2ecd6dae546d91ae766ac134aea2dfc", "filename": "src/librustc/middle/trans/debuginfo.rs", "status": "modified", "additions": 16, "deletions": 19, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -8,7 +8,7 @@ use trans::build::B;\n use middle::ty;\n use syntax::{ast, codemap, ast_util, ast_map};\n use syntax::parse::token::ident_interner;\n-use codemap::span;\n+use codemap::{span, CharPos};\n use ast::Ty;\n use pat_util::*;\n use util::ppaux::ty_to_str;\n@@ -112,7 +112,7 @@ type compile_unit_md = {name: ~str};\n type subprogram_md = {id: ast::node_id};\n type local_var_md = {id: ast::node_id};\n type tydesc_md = {hash: uint};\n-type block_md = {start: codemap::loc, end: codemap::loc};\n+type block_md = {start: codemap::Loc, end: codemap::Loc};\n type argument_md = {id: ast::node_id};\n type retval_md = {id: ast::node_id};\n \n@@ -229,8 +229,8 @@ fn create_file(cx: @crate_ctxt, full_path: ~str) -> @metadata<file_md> {\n     return mdval;\n }\n \n-fn line_from_span(cm: codemap::CodeMap, sp: span) -> uint {\n-    codemap::lookup_char_pos(cm, sp.lo).line\n+fn line_from_span(cm: @codemap::CodeMap, sp: span) -> uint {\n+    cm.lookup_char_pos(sp.lo).line\n }\n \n fn create_block(cx: block) -> @metadata<block_md> {\n@@ -244,9 +244,9 @@ fn create_block(cx: block) -> @metadata<block_md> {\n     }\n     let sp = cx.node_info.get().span;\n \n-    let start = codemap::lookup_char_pos(cx.sess().codemap, sp.lo);\n+    let start = cx.sess().codemap.lookup_char_pos(sp.lo);\n     let fname = start.file.name;\n-    let end = codemap::lookup_char_pos(cx.sess().codemap, sp.hi);\n+    let end = cx.sess().codemap.lookup_char_pos(sp.hi);\n     let tg = LexicalBlockTag;\n     /*alt cached_metadata::<@metadata<block_md>>(\n         cache, tg,\n@@ -266,8 +266,8 @@ fn create_block(cx: block) -> @metadata<block_md> {\n     };\n     let lldata = ~[lltag(tg),\n                   parent,\n-                  lli32(start.line as int),\n-                  lli32(start.col as int),\n+                  lli32(start.line.to_int()),\n+                  lli32(start.col.to_int()),\n                   file_node.node,\n                   lli32(unique_id)\n                  ];\n@@ -597,7 +597,7 @@ fn create_ty(_cx: @crate_ctxt, _t: ty::t, _ty: @ast::Ty)\n }\n \n fn filename_from_span(cx: @crate_ctxt, sp: codemap::span) -> ~str {\n-    codemap::lookup_char_pos(cx.sess.codemap, sp.lo).file.name\n+    cx.sess.codemap.lookup_char_pos(sp.lo).file.name\n }\n \n fn create_var(type_tag: int, context: ValueRef, name: ~str, file: ValueRef,\n@@ -629,8 +629,7 @@ fn create_local_var(bcx: block, local: @ast::local)\n       // FIXME this should be handled (#2533)\n       _ => fail ~\"no single variable name for local\"\n     };\n-    let loc = codemap::lookup_char_pos(cx.sess.codemap,\n-                                       local.span.lo);\n+    let loc = cx.sess.codemap.lookup_char_pos(local.span.lo);\n     let ty = node_id_type(bcx, local.node.id);\n     let tymd = create_ty(cx, ty, local.node.ty);\n     let filemd = create_file(cx, loc.file.name);\n@@ -674,8 +673,7 @@ fn create_arg(bcx: block, arg: ast::arg, sp: span)\n       option::None => ()\n     }\n \n-    let loc = codemap::lookup_char_pos(cx.sess.codemap,\n-                                       sp.lo);\n+    let loc = cx.sess.codemap.lookup_char_pos(sp.lo);\n     let ty = node_id_type(bcx, arg.id);\n     let tymd = create_ty(cx, ty, arg.ty);\n     let filemd = create_file(cx, loc.file.name);\n@@ -714,9 +712,9 @@ fn update_source_pos(cx: block, s: span) {\n     }\n     let cm = cx.sess().codemap;\n     let blockmd = create_block(cx);\n-    let loc = codemap::lookup_char_pos(cm, s.lo);\n-    let scopedata = ~[lli32(loc.line as int),\n-                     lli32(loc.col as int),\n+    let loc = cm.lookup_char_pos(s.lo);\n+    let scopedata = ~[lli32(loc.line.to_int()),\n+                     lli32(loc.col.to_int()),\n                      blockmd.node,\n                      llnull()];\n     let dbgscope = llmdnode(scopedata);\n@@ -731,7 +729,7 @@ fn create_function(fcx: fn_ctxt) -> @metadata<subprogram_md> {\n     log(debug, fcx.id);\n \n     let sp = fcx.span.get();\n-    log(debug, codemap::span_to_str(sp, cx.sess.codemap));\n+    log(debug, cx.sess.codemap.span_to_str(sp));\n \n     let (ident, ret_ty, id) = match cx.tcx.items.get(fcx.id) {\n       ast_map::node_item(item, _) => {\n@@ -773,8 +771,7 @@ fn create_function(fcx: fn_ctxt) -> @metadata<subprogram_md> {\n       option::None => ()\n     }\n \n-    let loc = codemap::lookup_char_pos(cx.sess.codemap,\n-                                       sp.lo);\n+    let loc = cx.sess.codemap.lookup_char_pos(sp.lo);\n     let file_node = create_file(cx, loc.file.name).node;\n     let ty_node = if cx.sess.opts.extra_debuginfo {\n         match ret_ty.node {"}, {"sha": "652d99779d3120672ca5c38da45383ae075784e8", "filename": "src/librustc/middle/typeck/infer/region_inference.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -507,7 +507,7 @@ impl RegionVarBindings {\n             self.undo_log.push(AddVar(vid));\n         }\n         debug!(\"created new region variable %? with span %?\",\n-               vid, codemap::span_to_str(span, self.tcx.sess.codemap));\n+               vid, self.tcx.sess.codemap.span_to_str(span));\n         return vid;\n     }\n "}, {"sha": "c959f12863d60c12cead655afebfb3242f5f07fa", "filename": "src/librustc/rustc.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Frustc.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -193,7 +193,7 @@ fn monitor(+f: fn~(diagnostic::emitter)) {\n \n         // The 'diagnostics emitter'. Every error, warning, etc. should\n         // go through this function.\n-        let demitter = fn@(cmsp: Option<(codemap::CodeMap, codemap::span)>,\n+        let demitter = fn@(cmsp: Option<(@codemap::CodeMap, codemap::span)>,\n                            msg: &str, lvl: diagnostic::level) {\n             if lvl == diagnostic::fatal {\n                 comm::send(ch, fatal);"}, {"sha": "198b26c4ecc691057887c072e6d539f615353dc5", "filename": "src/librustc/util/ppaux.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Futil%2Fppaux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustc%2Futil%2Fppaux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fppaux.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -105,8 +105,9 @@ fn explain_region_and_span(cx: ctxt, region: ty::Region)\n     fn explain_span(cx: ctxt, heading: ~str, span: span)\n         -> (~str, Option<span>)\n     {\n-        let lo = codemap::lookup_char_pos_adj(cx.sess.codemap, span.lo);\n-        (fmt!(\"the %s at %u:%u\", heading, lo.line, lo.col), Some(span))\n+        let lo = cx.sess.codemap.lookup_char_pos_adj(span.lo);\n+        (fmt!(\"the %s at %u:%u\", heading,\n+              lo.line, lo.col.to_uint()), Some(span))\n     }\n }\n \n@@ -131,29 +132,29 @@ fn re_scope_id_to_str(cx: ctxt, node_id: ast::node_id) -> ~str {\n     match cx.items.find(node_id) {\n       Some(ast_map::node_block(blk)) => {\n         fmt!(\"<block at %s>\",\n-             codemap::span_to_str(blk.span, cx.sess.codemap))\n+             cx.sess.codemap.span_to_str(blk.span))\n       }\n       Some(ast_map::node_expr(expr)) => {\n         match expr.node {\n           ast::expr_call(*) => {\n             fmt!(\"<call at %s>\",\n-                 codemap::span_to_str(expr.span, cx.sess.codemap))\n+                 cx.sess.codemap.span_to_str(expr.span))\n           }\n           ast::expr_match(*) => {\n             fmt!(\"<alt at %s>\",\n-                 codemap::span_to_str(expr.span, cx.sess.codemap))\n+                 cx.sess.codemap.span_to_str(expr.span))\n           }\n           ast::expr_assign_op(*) |\n           ast::expr_field(*) |\n           ast::expr_unary(*) |\n           ast::expr_binary(*) |\n           ast::expr_index(*) => {\n             fmt!(\"<method at %s>\",\n-                 codemap::span_to_str(expr.span, cx.sess.codemap))\n+                 cx.sess.codemap.span_to_str(expr.span))\n           }\n           _ => {\n             fmt!(\"<expression at %s>\",\n-                 codemap::span_to_str(expr.span, cx.sess.codemap))\n+                 cx.sess.codemap.span_to_str(expr.span))\n           }\n         }\n       }"}, {"sha": "cb97d38b208542d908672b0065b56356a3dd209a", "filename": "src/librustdoc/astsrv.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustdoc%2Fastsrv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustdoc%2Fastsrv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fastsrv.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -120,7 +120,7 @@ fn build_ctxt(sess: Session,\n \n fn build_session() -> Session {\n     let sopts: @options = basic_options();\n-    let codemap = codemap::new_codemap();\n+    let codemap = @codemap::CodeMap::new();\n     let error_handlers = build_error_handlers(codemap);\n     let {emitter, span_handler} = error_handlers;\n \n@@ -137,7 +137,7 @@ type ErrorHandlers = {\n // Build a custom error handler that will allow us to ignore non-fatal\n // errors\n fn build_error_handlers(\n-    codemap: codemap::CodeMap\n+    codemap: @codemap::CodeMap\n ) -> ErrorHandlers {\n \n     type DiagnosticHandler = {\n@@ -156,13 +156,13 @@ fn build_error_handlers(\n         fn note(msg: &str) { self.inner.note(msg) }\n         fn bug(msg: &str) -> ! { self.inner.bug(msg) }\n         fn unimpl(msg: &str) -> ! { self.inner.unimpl(msg) }\n-        fn emit(cmsp: Option<(codemap::CodeMap, codemap::span)>,\n+        fn emit(cmsp: Option<(@codemap::CodeMap, codemap::span)>,\n                 msg: &str, lvl: diagnostic::level) {\n             self.inner.emit(cmsp, msg, lvl)\n         }\n     }\n \n-    let emitter = fn@(cmsp: Option<(codemap::CodeMap, codemap::span)>,\n+    let emitter = fn@(cmsp: Option<(@codemap::CodeMap, codemap::span)>,\n                        msg: &str, lvl: diagnostic::level) {\n         diagnostic::emit(cmsp, msg, lvl);\n     };"}, {"sha": "4e8b11d2ca6fa3fdeca47c0532fcd07be8f48924", "filename": "src/librustdoc/attr_parser.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustdoc%2Fattr_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibrustdoc%2Fattr_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fattr_parser.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -30,7 +30,7 @@ mod test {\n \n         let parse_sess = syntax::parse::new_parse_sess(None);\n         let parser = parse::new_parser_from_source_str(\n-            parse_sess, ~[], ~\"-\", codemap::fss_none, @source);\n+            parse_sess, ~[], ~\"-\", codemap::FssNone, @source);\n \n         parser.parse_outer_attributes()\n     }"}, {"sha": "fa4998ef7b5355be7baf85c1f241e91dcc51cd1d", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -4,7 +4,7 @@ use std::serialization::{Serializable,\n                          Deserializable,\n                          Serializer,\n                          Deserializer};\n-use codemap::{span, filename};\n+use codemap::{span, FileName};\n use parse::token;\n \n #[auto_serialize]"}, {"sha": "73a1c4b7530a028e696ec0594c9273970b4616f0", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,7 +1,7 @@\n-use codemap::span;\n+use codemap::{span, BytePos};\n use ast::*;\n \n-pure fn spanned<T>(lo: uint, hi: uint, +t: T) -> spanned<T> {\n+pure fn spanned<T>(+lo: BytePos, +hi: BytePos, +t: T) -> spanned<T> {\n     respan(mk_sp(lo, hi), move t)\n }\n \n@@ -14,12 +14,12 @@ pure fn dummy_spanned<T>(+t: T) -> spanned<T> {\n }\n \n /* assuming that we're not in macro expansion */\n-pure fn mk_sp(lo: uint, hi: uint) -> span {\n-    {lo: lo, hi: hi, expn_info: None}\n+pure fn mk_sp(+lo: BytePos, +hi: BytePos) -> span {\n+    span {lo: lo, hi: hi, expn_info: None}\n }\n \n // make this a const, once the compiler supports it\n-pure fn dummy_sp() -> span { return mk_sp(0u, 0u); }\n+pure fn dummy_sp() -> span { return mk_sp(BytePos(0), BytePos(0)); }\n \n \n "}, {"sha": "da80e26b1afe95d9f1f7258dec3095b18a66449a", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -6,6 +6,7 @@ use either::Either;\n use diagnostic::span_handler;\n use ast_util::{spanned, dummy_spanned};\n use parse::comments::{doc_comment_style, strip_doc_comment_decoration};\n+use codemap::BytePos;\n \n // Constructors\n export mk_name_value_item_str;\n@@ -74,7 +75,8 @@ fn mk_attr(item: @ast::meta_item) -> ast::attribute {\n                        is_sugared_doc: false});\n }\n \n-fn mk_sugared_doc_attr(text: ~str, lo: uint, hi: uint) -> ast::attribute {\n+fn mk_sugared_doc_attr(text: ~str,\n+                       +lo: BytePos, +hi: BytePos) -> ast::attribute {\n     let lit = spanned(lo, hi, ast::lit_str(@text));\n     let attr = {\n         style: doc_comment_style(text),"}, {"sha": "d291d9545eb6a7b9db14eaf7db258d0043f756e9", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 393, "deletions": 194, "changes": 587, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,179 +1,144 @@\n+/*!\n+\n+The CodeMap tracks all the source code used within a single crate, mapping\n+from integer byte positions to the original source code location. Each bit of\n+source parsed during crate parsing (typically files, in-memory strings, or\n+various bits of macro expansion) cover a continuous range of bytes in the\n+CodeMap and are represented by FileMaps. Byte positions are stored in `spans`\n+and used pervasively in the compiler. They are absolute positions within the\n+CodeMap, which upon request can be converted to line and column information,\n+source code snippets, etc.\n+\n+*/\n+\n use dvec::DVec;\n use std::serialization::{Serializable,\n                          Deserializable,\n                          Serializer,\n                          Deserializer};\n \n-export filename;\n-export filemap;\n-export span;\n-export file_substr;\n-export fss_none;\n-export fss_internal;\n-export fss_external;\n-export CodeMap;\n-export expn_info;\n-export expn_info_;\n-export expanded_from;\n-export new_filemap;\n-export new_filemap_w_substr;\n-export mk_substr_filename;\n-export lookup_char_pos;\n-export lookup_char_pos_adj;\n-export adjust_span;\n-export span_to_str;\n-export span_to_filename;\n-export span_to_lines;\n-export file_lines;\n-export get_line;\n-export next_line;\n-export span_to_snippet;\n-export loc;\n-export get_filemap;\n-export new_codemap;\n-\n-type filename = ~str;\n-\n-type file_pos = {ch: uint, byte: uint};\n-\n-impl file_pos : cmp::Eq {\n-    pure fn eq(other: &file_pos) -> bool {\n-        self.ch == (*other).ch && self.byte == (*other).byte\n-    }\n-    pure fn ne(other: &file_pos) -> bool { !self.eq(other) }\n+trait Pos {\n+    static pure fn from_uint(n: uint) -> self;\n+    pure fn to_uint(&self) -> uint;\n }\n \n-/* A codemap is a thing that maps uints to file/line/column positions\n- * in a crate. This to make it possible to represent the positions\n- * with single-word things, rather than passing records all over the\n- * compiler.\n- */\n-\n-enum file_substr {\n-    fss_none,\n-    fss_internal(span),\n-    fss_external({filename: ~str, line: uint, col: uint})\n-}\n+/// A byte offset\n+pub enum BytePos = uint;\n+/// A character offset. Because of multibyte utf8 characters, a byte offset\n+/// is not equivalent to a character offset. The CodeMap will convert BytePos\n+/// values to CharPos values as necessary.\n+pub enum CharPos = uint;\n \n-type filemap =\n-    @{name: filename, substr: file_substr, src: @~str,\n-      start_pos: file_pos, mut lines: ~[file_pos]};\n+// XXX: Lots of boilerplate in these impls, but so far my attempts to fix\n+// have been unsuccessful\n \n-type CodeMap = @{files: DVec<filemap>};\n-\n-type loc = {file: filemap, line: uint, col: uint};\n-\n-fn new_codemap() -> CodeMap { @{files: DVec()} }\n-\n-fn new_filemap_w_substr(+filename: filename, +substr: file_substr,\n-                        src: @~str,\n-                        start_pos_ch: uint, start_pos_byte: uint)\n-   -> filemap {\n-    return @{name: filename, substr: substr, src: src,\n-          start_pos: {ch: start_pos_ch, byte: start_pos_byte},\n-          mut lines: ~[{ch: start_pos_ch, byte: start_pos_byte}]};\n+impl BytePos: Pos {\n+    static pure fn from_uint(n: uint) -> BytePos { BytePos(n) }\n+    pure fn to_uint(&self) -> uint { **self }\n }\n \n-fn new_filemap(+filename: filename, src: @~str,\n-               start_pos_ch: uint, start_pos_byte: uint)\n-    -> filemap {\n-    return new_filemap_w_substr(filename, fss_none, src,\n-                             start_pos_ch, start_pos_byte);\n+impl BytePos: cmp::Eq {\n+    pure fn eq(other: &BytePos) -> bool {\n+        *self == **other\n+    }\n+    pure fn ne(other: &BytePos) -> bool { !self.eq(other) }\n }\n \n-fn mk_substr_filename(cm: CodeMap, sp: span) -> ~str\n-{\n-    let pos = lookup_char_pos(cm, sp.lo);\n-    return fmt!(\"<%s:%u:%u>\", pos.file.name, pos.line, pos.col);\n+impl BytePos: cmp::Ord {\n+    pure fn lt(other: &BytePos) -> bool { *self < **other }\n+    pure fn le(other: &BytePos) -> bool { *self <= **other }\n+    pure fn ge(other: &BytePos) -> bool { *self >= **other }\n+    pure fn gt(other: &BytePos) -> bool { *self > **other }\n }\n \n-fn next_line(file: filemap, chpos: uint, byte_pos: uint) {\n-    file.lines.push({ch: chpos, byte: byte_pos + file.start_pos.byte});\n+impl BytePos: Num {\n+    pure fn add(other: &BytePos) -> BytePos {\n+        BytePos(*self + **other)\n+    }\n+    pure fn sub(other: &BytePos) -> BytePos {\n+        BytePos(*self - **other)\n+    }\n+    pure fn mul(other: &BytePos) -> BytePos {\n+        BytePos(*self * (**other))\n+    }\n+    pure fn div(other: &BytePos) -> BytePos {\n+        BytePos(*self / **other)\n+    }\n+    pure fn modulo(other: &BytePos) -> BytePos {\n+        BytePos(*self % **other)\n+    }\n+    pure fn neg() -> BytePos {\n+        BytePos(-*self)\n+    }\n+    pure fn to_int() -> int { *self as int }\n+    static pure fn from_int(+n: int) -> BytePos { BytePos(n as uint) }\n }\n \n-type lookup_fn = pure fn(file_pos) -> uint;\n-\n-fn lookup_line(map: CodeMap, pos: uint, lookup: lookup_fn)\n-    -> {fm: filemap, line: uint}\n-{\n-    let len = map.files.len();\n-    let mut a = 0u;\n-    let mut b = len;\n-    while b - a > 1u {\n-        let m = (a + b) / 2u;\n-        if lookup(map.files[m].start_pos) > pos { b = m; } else { a = m; }\n-    }\n-    if (a >= len) {\n-        fail fmt!(\"position %u does not resolve to a source location\", pos)\n-    }\n-    let f = map.files[a];\n-    a = 0u;\n-    b = vec::len(f.lines);\n-    while b - a > 1u {\n-        let m = (a + b) / 2u;\n-        if lookup(f.lines[m]) > pos { b = m; } else { a = m; }\n-    }\n-    return {fm: f, line: a};\n+impl BytePos: to_bytes::IterBytes {\n+    pure fn iter_bytes(+lsb0: bool, f: to_bytes::Cb) {\n+        (*self).iter_bytes(lsb0, f)\n+    }\n }\n \n-fn lookup_pos(map: CodeMap, pos: uint, lookup: lookup_fn) -> loc {\n-    let {fm: f, line: a} = lookup_line(map, pos, lookup);\n-    return {file: f, line: a + 1u, col: pos - lookup(f.lines[a])};\n+impl CharPos: Pos {\n+    static pure fn from_uint(n: uint) -> CharPos { CharPos(n) }\n+    pure fn to_uint(&self) -> uint { **self }\n }\n \n-fn lookup_char_pos(map: CodeMap, pos: uint) -> loc {\n-    pure fn lookup(pos: file_pos) -> uint { return pos.ch; }\n-    return lookup_pos(map, pos, lookup);\n+impl CharPos: cmp::Eq {\n+    pure fn eq(other: &CharPos) -> bool {\n+        *self == **other\n+    }\n+    pure fn ne(other: &CharPos) -> bool { !self.eq(other) }\n }\n \n-fn lookup_byte_pos(map: CodeMap, pos: uint) -> loc {\n-    pure fn lookup(pos: file_pos) -> uint { return pos.byte; }\n-    return lookup_pos(map, pos, lookup);\n+impl CharPos: cmp::Ord {\n+    pure fn lt(other: &CharPos) -> bool { *self < **other }\n+    pure fn le(other: &CharPos) -> bool { *self <= **other }\n+    pure fn ge(other: &CharPos) -> bool { *self >= **other }\n+    pure fn gt(other: &CharPos) -> bool { *self > **other }\n }\n \n-fn lookup_char_pos_adj(map: CodeMap, pos: uint)\n-    -> {filename: ~str, line: uint, col: uint, file: Option<filemap>}\n-{\n-    let loc = lookup_char_pos(map, pos);\n-    match (loc.file.substr) {\n-      fss_none => {\n-        {filename: /* FIXME (#2543) */ copy loc.file.name,\n-         line: loc.line,\n-         col: loc.col,\n-         file: Some(loc.file)}\n-      }\n-      fss_internal(sp) => {\n-        lookup_char_pos_adj(map, sp.lo + (pos - loc.file.start_pos.ch))\n-      }\n-      fss_external(eloc) => {\n-        {filename: /* FIXME (#2543) */ copy eloc.filename,\n-         line: eloc.line + loc.line - 1u,\n-         col: if loc.line == 1u {eloc.col + loc.col} else {loc.col},\n-         file: None}\n-      }\n+impl CharPos: Num {\n+    pure fn add(other: &CharPos) -> CharPos {\n+        CharPos(*self + **other)\n     }\n+    pure fn sub(other: &CharPos) -> CharPos {\n+        CharPos(*self - **other)\n+    }\n+    pure fn mul(other: &CharPos) -> CharPos {\n+        CharPos(*self * (**other))\n+    }\n+    pure fn div(other: &CharPos) -> CharPos {\n+        CharPos(*self / **other)\n+    }\n+    pure fn modulo(other: &CharPos) -> CharPos {\n+        CharPos(*self % **other)\n+    }\n+    pure fn neg() -> CharPos {\n+        CharPos(-*self)\n+    }\n+    pure fn to_int() -> int { *self as int }\n+    static pure fn from_int(+n: int) -> CharPos { CharPos(n as uint) }\n }\n \n-fn adjust_span(map: CodeMap, sp: span) -> span {\n-    pure fn lookup(pos: file_pos) -> uint { return pos.ch; }\n-    let line = lookup_line(map, sp.lo, lookup);\n-    match (line.fm.substr) {\n-      fss_none => sp,\n-      fss_internal(s) => {\n-        adjust_span(map, {lo: s.lo + (sp.lo - line.fm.start_pos.ch),\n-                          hi: s.lo + (sp.hi - line.fm.start_pos.ch),\n-                          expn_info: sp.expn_info})}\n-      fss_external(_) => sp\n+impl CharPos: to_bytes::IterBytes {\n+    pure fn iter_bytes(+lsb0: bool, f: to_bytes::Cb) {\n+        (*self).iter_bytes(lsb0, f)\n     }\n }\n \n-enum expn_info_ {\n-    expanded_from({call_site: span,\n-                   callie: {name: ~str, span: Option<span>}})\n+/**\n+Spans represent a region of code, used for error reporting. Positions in spans\n+are *absolute* positions from the beginning of the codemap, not positions\n+relative to FileMaps. Methods on the CodeMap can be used to relate spans back\n+to the original source.\n+*/\n+pub struct span {\n+    lo: BytePos,\n+    hi: BytePos,\n+    expn_info: Option<@ExpnInfo>\n }\n-type expn_info = Option<@expn_info_>;\n-\n-type span = {lo: uint, hi: uint, expn_info: expn_info};\n \n impl span : cmp::Eq {\n     pure fn eq(other: &span) -> bool {\n@@ -193,74 +158,308 @@ impl<D: Deserializer> span: Deserializable<D> {\n     }\n }\n \n-fn span_to_str_no_adj(sp: span, cm: CodeMap) -> ~str {\n-    let lo = lookup_char_pos(cm, sp.lo);\n-    let hi = lookup_char_pos(cm, sp.hi);\n-    return fmt!(\"%s:%u:%u: %u:%u\", lo.file.name,\n-             lo.line, lo.col, hi.line, hi.col)\n+/// A source code location used for error reporting\n+pub struct Loc {\n+    /// Information about the original source\n+    file: @FileMap,\n+    /// The (1-based) line number\n+    line: uint,\n+    /// The (0-based) column offset\n+    col: CharPos\n }\n \n-fn span_to_str(sp: span, cm: CodeMap) -> ~str {\n-    let lo = lookup_char_pos_adj(cm, sp.lo);\n-    let hi = lookup_char_pos_adj(cm, sp.hi);\n-    return fmt!(\"%s:%u:%u: %u:%u\", lo.filename,\n-             lo.line, lo.col, hi.line, hi.col)\n+/// Extra information for tracking macro expansion of spans\n+pub enum ExpnInfo {\n+    ExpandedFrom({call_site: span,\n+                  callie: {name: ~str, span: Option<span>}})\n }\n \n-type file_lines = {file: filemap, lines: ~[uint]};\n+pub type FileName = ~str;\n \n-fn span_to_filename(sp: span, cm: codemap::CodeMap) -> filename {\n-    let lo = lookup_char_pos(cm, sp.lo);\n-    return /* FIXME (#2543) */ copy lo.file.name;\n+pub struct FileLines {\n+    file: @FileMap,\n+    lines: ~[uint]\n }\n \n-fn span_to_lines(sp: span, cm: codemap::CodeMap) -> @file_lines {\n-    let lo = lookup_char_pos(cm, sp.lo);\n-    let hi = lookup_char_pos(cm, sp.hi);\n-    let mut lines = ~[];\n-    for uint::range(lo.line - 1u, hi.line as uint) |i| {\n-        lines.push(i);\n-    };\n-    return @{file: lo.file, lines: lines};\n+pub enum FileSubstr {\n+    pub FssNone,\n+    pub FssInternal(span),\n+    pub FssExternal({filename: ~str, line: uint, col: CharPos})\n }\n \n-fn get_line(fm: filemap, line: int) -> ~str unsafe {\n-    let begin: uint = fm.lines[line].byte - fm.start_pos.byte;\n-    let end = match str::find_char_from(*fm.src, '\\n', begin) {\n-      Some(e) => e,\n-      None => str::len(*fm.src)\n-    };\n-    str::slice(*fm.src, begin, end)\n+/// Identifies an offset of a multi-byte character in a FileMap\n+pub struct MultiByteChar {\n+    /// The absolute offset of the character in the CodeMap\n+    pos: BytePos,\n+    /// The number of bytes, >=2\n+    bytes: uint,\n }\n \n-fn lookup_byte_offset(cm: codemap::CodeMap, chpos: uint)\n-    -> {fm: filemap, pos: uint} {\n-    pure fn lookup(pos: file_pos) -> uint { return pos.ch; }\n-    let {fm, line} = lookup_line(cm, chpos, lookup);\n-    let line_offset = fm.lines[line].byte - fm.start_pos.byte;\n-    let col = chpos - fm.lines[line].ch;\n-    let col_offset = str::count_bytes(*fm.src, line_offset, col);\n-    {fm: fm, pos: line_offset + col_offset}\n+/// A single source in the CodeMap\n+pub struct FileMap {\n+    /// The name of the file that the source came from, source that doesn't\n+    /// originate from files has names between angle brackets by convention,\n+    /// e.g. `<anon>`\n+    name: FileName,\n+    /// Extra information used by qquote\n+    substr: FileSubstr,\n+    /// The complete source code\n+    src: @~str,\n+    /// The start position of this source in the CodeMap\n+    start_pos: BytePos,\n+    /// Locations of lines beginnings in the source code\n+    mut lines: ~[BytePos],\n+    /// Locations of multi-byte characters in the source code\n+    multibyte_chars: DVec<MultiByteChar>\n }\n \n-fn span_to_snippet(sp: span, cm: codemap::CodeMap) -> ~str {\n-    let begin = lookup_byte_offset(cm, sp.lo);\n-    let end = lookup_byte_offset(cm, sp.hi);\n-    assert begin.fm.start_pos == end.fm.start_pos;\n-    return str::slice(*begin.fm.src, begin.pos, end.pos);\n+pub impl FileMap {\n+    fn next_line(&self, +pos: BytePos) {\n+        self.lines.push(pos);\n+    }\n+\n+    pub fn get_line(&self, line: int) -> ~str unsafe {\n+        let begin: BytePos = self.lines[line] - self.start_pos;\n+        let begin = begin.to_uint();\n+        let end = match str::find_char_from(*self.src, '\\n', begin) {\n+            Some(e) => e,\n+            None => str::len(*self.src)\n+        };\n+        str::slice(*self.src, begin, end)\n+    }\n+\n+    pub fn record_multibyte_char(&self, pos: BytePos, bytes: uint) {\n+        assert bytes >=2 && bytes <= 4;\n+        let mbc = MultiByteChar {\n+            pos: pos,\n+            bytes: bytes,\n+        };\n+        self.multibyte_chars.push(mbc);\n+    }\n }\n \n-fn get_snippet(cm: codemap::CodeMap, fidx: uint, lo: uint, hi: uint) -> ~str\n-{\n-    let fm = cm.files[fidx];\n-    return str::slice(*fm.src, lo, hi)\n+pub struct CodeMap {\n+    files: DVec<@FileMap>\n }\n \n-fn get_filemap(cm: CodeMap, filename: ~str) -> filemap {\n-    for cm.files.each |fm| { if fm.name == filename { return *fm; } }\n-    //XXjdm the following triggers a mismatched type bug\n-    //      (or expected function, found _|_)\n-    fail; // (\"asking for \" + filename + \" which we don't know about\");\n+pub impl CodeMap {\n+    static pub fn new() -> CodeMap {\n+        CodeMap {\n+            files: DVec()\n+        }\n+    }\n+\n+    /// Add a new FileMap to the CodeMap and return it\n+    fn new_filemap(+filename: FileName, src: @~str) -> @FileMap {\n+        return self.new_filemap_w_substr(filename, FssNone, src);\n+    }\n+\n+    fn new_filemap_w_substr(+filename: FileName, +substr: FileSubstr,\n+                            src: @~str) -> @FileMap {\n+        let start_pos = if self.files.len() == 0 {\n+            0\n+        } else {\n+            let last_start = self.files.last().start_pos.to_uint();\n+            let last_len = self.files.last().src.len();\n+            last_start + last_len\n+        };\n+\n+        let filemap = @FileMap {\n+            name: filename, substr: substr, src: src,\n+            start_pos: BytePos(start_pos),\n+            mut lines: ~[],\n+            multibyte_chars: DVec()\n+        };\n+\n+        self.files.push(filemap);\n+\n+        return filemap;\n+    }\n+\n+    pub fn mk_substr_filename(&self, sp: span) -> ~str {\n+        let pos = self.lookup_char_pos(sp.lo);\n+        return fmt!(\"<%s:%u:%u>\", pos.file.name,\n+                    pos.line, pos.col.to_uint());\n+    }\n+\n+    /// Lookup source information about a BytePos\n+    pub fn lookup_char_pos(&self, +pos: BytePos) -> Loc {\n+        return self.lookup_pos(pos);\n+    }\n+\n+    pub fn lookup_char_pos_adj(&self, +pos: BytePos)\n+        -> {filename: ~str, line: uint, col: CharPos, file: Option<@FileMap>}\n+    {\n+        let loc = self.lookup_char_pos(pos);\n+        match (loc.file.substr) {\n+            FssNone => {\n+                {filename: /* FIXME (#2543) */ copy loc.file.name,\n+                 line: loc.line,\n+                 col: loc.col,\n+                 file: Some(loc.file)}\n+            }\n+            FssInternal(sp) => {\n+                self.lookup_char_pos_adj(\n+                    sp.lo + (pos - loc.file.start_pos))\n+            }\n+            FssExternal(eloc) => {\n+                {filename: /* FIXME (#2543) */ copy eloc.filename,\n+                 line: eloc.line + loc.line - 1u,\n+                 col: if loc.line == 1u {eloc.col + loc.col} else {loc.col},\n+                 file: None}\n+            }\n+        }\n+    }\n+\n+    pub fn adjust_span(&self, sp: span) -> span {\n+        let line = self.lookup_line(sp.lo);\n+        match (line.fm.substr) {\n+            FssNone => sp,\n+            FssInternal(s) => {\n+                self.adjust_span(span {\n+                    lo: s.lo + (sp.lo - line.fm.start_pos),\n+                    hi: s.lo + (sp.hi - line.fm.start_pos),\n+                    expn_info: sp.expn_info\n+                })\n+            }\n+            FssExternal(_) => sp\n+        }\n+    }\n+\n+    pub fn span_to_str(&self, sp: span) -> ~str {\n+        let lo = self.lookup_char_pos_adj(sp.lo);\n+        let hi = self.lookup_char_pos_adj(sp.hi);\n+        return fmt!(\"%s:%u:%u: %u:%u\", lo.filename,\n+                    lo.line, lo.col.to_uint(), hi.line, hi.col.to_uint())\n+    }\n+\n+    pub fn span_to_filename(&self, sp: span) -> FileName {\n+        let lo = self.lookup_char_pos(sp.lo);\n+        return /* FIXME (#2543) */ copy lo.file.name;\n+    }\n+\n+    pub fn span_to_lines(&self, sp: span) -> @FileLines {\n+        let lo = self.lookup_char_pos(sp.lo);\n+        let hi = self.lookup_char_pos(sp.hi);\n+        let mut lines = ~[];\n+        for uint::range(lo.line - 1u, hi.line as uint) |i| {\n+            lines.push(i);\n+        };\n+        return @FileLines {file: lo.file, lines: lines};\n+    }\n+\n+    pub fn span_to_snippet(&self, sp: span) -> ~str {\n+        let begin = self.lookup_byte_offset(sp.lo);\n+        let end = self.lookup_byte_offset(sp.hi);\n+        assert begin.fm.start_pos == end.fm.start_pos;\n+        return str::slice(*begin.fm.src,\n+                          begin.pos.to_uint(), end.pos.to_uint());\n+    }\n+\n+    pub fn get_filemap(&self, filename: ~str) -> @FileMap {\n+        for self.files.each |fm| { if fm.name == filename { return *fm; } }\n+        //XXjdm the following triggers a mismatched type bug\n+        //      (or expected function, found _|_)\n+        fail; // (\"asking for \" + filename + \" which we don't know about\");\n+    }\n+\n+}\n+\n+priv impl CodeMap {\n+\n+    fn lookup_filemap_idx(&self, +pos: BytePos) -> uint {\n+        let len = self.files.len();\n+        let mut a = 0u;\n+        let mut b = len;\n+        while b - a > 1u {\n+            let m = (a + b) / 2u;\n+            if self.files[m].start_pos > pos {\n+                b = m;\n+            } else {\n+                a = m;\n+            }\n+        }\n+        if (a >= len) {\n+            fail fmt!(\"position %u does not resolve to a source location\",\n+                      pos.to_uint())\n+        }\n+\n+        return a;\n+    }\n+\n+    fn lookup_line(&self, +pos: BytePos)\n+        -> {fm: @FileMap, line: uint}\n+    {\n+        let idx = self.lookup_filemap_idx(pos);\n+        let f = self.files[idx];\n+        let mut a = 0u;\n+        let mut b = vec::len(f.lines);\n+        while b - a > 1u {\n+            let m = (a + b) / 2u;\n+            if f.lines[m] > pos { b = m; } else { a = m; }\n+        }\n+        return {fm: f, line: a};\n+    }\n+\n+    fn lookup_pos(&self, +pos: BytePos) -> Loc {\n+        let {fm: f, line: a} = self.lookup_line(pos);\n+        let line = a + 1u; // Line numbers start at 1\n+        let chpos = self.bytepos_to_local_charpos(pos);\n+        let linebpos = f.lines[a];\n+        let linechpos = self.bytepos_to_local_charpos(linebpos);\n+        debug!(\"codemap: byte pos %? is on the line at byte pos %?\",\n+               pos, linebpos);\n+        debug!(\"codemap: char pos %? is on the line at char pos %?\",\n+               chpos, linechpos);\n+        debug!(\"codemap: byte is on line: %?\", line);\n+        assert chpos >= linechpos;\n+        return Loc {\n+            file: f,\n+            line: line,\n+            col: chpos - linechpos\n+        };\n+    }\n+\n+    fn span_to_str_no_adj(&self, sp: span) -> ~str {\n+        let lo = self.lookup_char_pos(sp.lo);\n+        let hi = self.lookup_char_pos(sp.hi);\n+        return fmt!(\"%s:%u:%u: %u:%u\", lo.file.name,\n+                    lo.line, lo.col.to_uint(), hi.line, hi.col.to_uint())\n+    }\n+\n+    fn lookup_byte_offset(&self, +bpos: BytePos)\n+        -> {fm: @FileMap, pos: BytePos} {\n+        let idx = self.lookup_filemap_idx(bpos);\n+        let fm = self.files[idx];\n+        let offset = bpos - fm.start_pos;\n+        return {fm: fm, pos: offset};\n+    }\n+\n+    // Converts an absolute BytePos to a CharPos relative to the file it is\n+    // located in\n+    fn bytepos_to_local_charpos(&self, +bpos: BytePos) -> CharPos {\n+        debug!(\"codemap: converting %? to char pos\", bpos);\n+        let idx = self.lookup_filemap_idx(bpos);\n+        let map = self.files[idx];\n+\n+        // The number of extra bytes due to multibyte chars in the FileMap\n+        let mut total_extra_bytes = 0;\n+\n+        for map.multibyte_chars.each |mbc| {\n+            debug!(\"codemap: %?-byte char at %?\", mbc.bytes, mbc.pos);\n+            if mbc.pos < bpos {\n+                total_extra_bytes += mbc.bytes;\n+                // We should never see a byte position in the middle of a\n+                // character\n+                assert bpos == mbc.pos\n+                    || bpos.to_uint() >= mbc.pos.to_uint() + mbc.bytes;\n+            } else {\n+                break;\n+            }\n+        }\n+\n+        CharPos(bpos.to_uint() - total_extra_bytes)\n+    }\n }\n \n //"}, {"sha": "007100856ebc416366b037e2c898856093c03d4c", "filename": "src/libsyntax/diagnostic.rs", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fdiagnostic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fdiagnostic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostic.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -9,7 +9,7 @@ export codemap_span_handler, codemap_handler;\n export ice_msg;\n export expect;\n \n-type emitter = fn@(cmsp: Option<(codemap::CodeMap, span)>,\n+type emitter = fn@(cmsp: Option<(@codemap::CodeMap, span)>,\n                    msg: &str, lvl: level);\n \n \n@@ -33,7 +33,7 @@ trait handler {\n     fn note(msg: &str);\n     fn bug(msg: &str) -> !;\n     fn unimpl(msg: &str) -> !;\n-    fn emit(cmsp: Option<(codemap::CodeMap, span)>, msg: &str, lvl: level);\n+    fn emit(cmsp: Option<(@codemap::CodeMap, span)>, msg: &str, lvl: level);\n }\n \n type handler_t = @{\n@@ -43,7 +43,7 @@ type handler_t = @{\n \n type codemap_t = @{\n     handler: handler,\n-    cm: codemap::CodeMap\n+    cm: @codemap::CodeMap\n };\n \n impl codemap_t: span_handler {\n@@ -107,7 +107,7 @@ impl handler_t: handler {\n         self.fatal(ice_msg(msg));\n     }\n     fn unimpl(msg: &str) -> ! { self.bug(~\"unimplemented \" + msg); }\n-    fn emit(cmsp: Option<(codemap::CodeMap, span)>, msg: &str, lvl: level) {\n+    fn emit(cmsp: Option<(@codemap::CodeMap, span)>, msg: &str, lvl: level) {\n         self.emit(cmsp, msg, lvl);\n     }\n }\n@@ -116,7 +116,7 @@ fn ice_msg(msg: &str) -> ~str {\n     fmt!(\"internal compiler error: %s\", msg)\n }\n \n-fn mk_span_handler(handler: handler, cm: codemap::CodeMap) -> span_handler {\n+fn mk_span_handler(handler: handler, cm: @codemap::CodeMap) -> span_handler {\n     @{ handler: handler, cm: cm } as span_handler\n }\n \n@@ -125,7 +125,7 @@ fn mk_handler(emitter: Option<emitter>) -> handler {\n     let emit = match emitter {\n       Some(e) => e,\n       None => {\n-        let f = fn@(cmsp: Option<(codemap::CodeMap, span)>,\n+        let f = fn@(cmsp: Option<(@codemap::CodeMap, span)>,\n             msg: &str, t: level) {\n             emit(cmsp, msg, t);\n         };\n@@ -189,12 +189,12 @@ fn print_diagnostic(topic: ~str, lvl: level, msg: &str) {\n     io::stderr().write_str(fmt!(\" %s\\n\", msg));\n }\n \n-fn emit(cmsp: Option<(codemap::CodeMap, span)>, msg: &str, lvl: level) {\n+fn emit(cmsp: Option<(@codemap::CodeMap, span)>, msg: &str, lvl: level) {\n     match cmsp {\n       Some((cm, sp)) => {\n-        let sp = codemap::adjust_span(cm,sp);\n-        let ss = codemap::span_to_str(sp, cm);\n-        let lines = codemap::span_to_lines(sp, cm);\n+        let sp = cm.adjust_span(sp);\n+        let ss = cm.span_to_str(sp);\n+        let lines = cm.span_to_lines(sp);\n         print_diagnostic(ss, lvl, msg);\n         highlight_lines(cm, sp, lines);\n         print_macro_backtrace(cm, sp);\n@@ -205,8 +205,8 @@ fn emit(cmsp: Option<(codemap::CodeMap, span)>, msg: &str, lvl: level) {\n     }\n }\n \n-fn highlight_lines(cm: codemap::CodeMap, sp: span,\n-                   lines: @codemap::file_lines) {\n+fn highlight_lines(cm: @codemap::CodeMap, sp: span,\n+                   lines: @codemap::FileLines) {\n \n     let fm = lines.file;\n \n@@ -221,7 +221,7 @@ fn highlight_lines(cm: codemap::CodeMap, sp: span,\n     // Print the offending lines\n     for display_lines.each |line| {\n         io::stderr().write_str(fmt!(\"%s:%u \", fm.name, *line + 1u));\n-        let s = codemap::get_line(fm, *line as int) + ~\"\\n\";\n+        let s = fm.get_line(*line as int) + ~\"\\n\";\n         io::stderr().write_str(s);\n     }\n     if elided {\n@@ -237,36 +237,36 @@ fn highlight_lines(cm: codemap::CodeMap, sp: span,\n \n     // If there's one line at fault we can easily point to the problem\n     if vec::len(lines.lines) == 1u {\n-        let lo = codemap::lookup_char_pos(cm, sp.lo);\n+        let lo = cm.lookup_char_pos(sp.lo);\n         let mut digits = 0u;\n         let mut num = (lines.lines[0] + 1u) / 10u;\n \n         // how many digits must be indent past?\n         while num > 0u { num /= 10u; digits += 1u; }\n \n         // indent past |name:## | and the 0-offset column location\n-        let mut left = str::len(fm.name) + digits + lo.col + 3u;\n+        let mut left = str::len(fm.name) + digits + lo.col.to_uint() + 3u;\n         let mut s = ~\"\";\n         while left > 0u { str::push_char(&mut s, ' '); left -= 1u; }\n \n         s += ~\"^\";\n-        let hi = codemap::lookup_char_pos(cm, sp.hi);\n+        let hi = cm.lookup_char_pos(sp.hi);\n         if hi.col != lo.col {\n             // the ^ already takes up one space\n-            let mut width = hi.col - lo.col - 1u;\n+            let mut width = hi.col.to_uint() - lo.col.to_uint() - 1u;\n             while width > 0u { str::push_char(&mut s, '~'); width -= 1u; }\n         }\n         io::stderr().write_str(s + ~\"\\n\");\n     }\n }\n \n-fn print_macro_backtrace(cm: codemap::CodeMap, sp: span) {\n+fn print_macro_backtrace(cm: @codemap::CodeMap, sp: span) {\n     do option::iter(&sp.expn_info) |ei| {\n         let ss = option::map_default(&ei.callie.span, @~\"\",\n-                                     |span| @codemap::span_to_str(*span, cm));\n+                                     |span| @cm.span_to_str(*span));\n         print_diagnostic(*ss, note,\n                          fmt!(\"in expansion of %s!\", ei.callie.name));\n-        let ss = codemap::span_to_str(ei.call_site, cm);\n+        let ss = cm.span_to_str(ei.call_site);\n         print_diagnostic(ss, note, ~\"expansion site\");\n         print_macro_backtrace(cm, ei.call_site);\n     }"}, {"sha": "c4611074b14feca85922c993d89f0da24e9444c1", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 17, "deletions": 14, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,7 +1,8 @@\n use std::map::HashMap;\n use parse::parser;\n use diagnostic::span_handler;\n-use codemap::{CodeMap, span, expn_info, expanded_from};\n+use codemap::{CodeMap, span, ExpnInfo, ExpandedFrom};\n+use ast_util::dummy_sp;\n \n // obsolete old-style #macro code:\n //\n@@ -139,15 +140,15 @@ fn syntax_expander_table() -> HashMap<~str, syntax_extension> {\n // when a macro expansion occurs, the resulting nodes have the backtrace()\n // -> expn_info of their expansion context stored into their span.\n trait ext_ctxt {\n-    fn codemap() -> CodeMap;\n+    fn codemap() -> @CodeMap;\n     fn parse_sess() -> parse::parse_sess;\n     fn cfg() -> ast::crate_cfg;\n     fn print_backtrace();\n-    fn backtrace() -> expn_info;\n+    fn backtrace() -> Option<@ExpnInfo>;\n     fn mod_push(mod_name: ast::ident);\n     fn mod_pop();\n     fn mod_path() -> ~[ast::ident];\n-    fn bt_push(ei: codemap::expn_info_);\n+    fn bt_push(ei: codemap::ExpnInfo);\n     fn bt_pop();\n     fn span_fatal(sp: span, msg: &str) -> !;\n     fn span_err(sp: span, msg: &str);\n@@ -167,32 +168,34 @@ fn mk_ctxt(parse_sess: parse::parse_sess,\n            cfg: ast::crate_cfg) -> ext_ctxt {\n     type ctxt_repr = {parse_sess: parse::parse_sess,\n                       cfg: ast::crate_cfg,\n-                      mut backtrace: expn_info,\n+                      mut backtrace: Option<@ExpnInfo>,\n                       mut mod_path: ~[ast::ident],\n                       mut trace_mac: bool};\n     impl ctxt_repr: ext_ctxt {\n-        fn codemap() -> CodeMap { self.parse_sess.cm }\n+        fn codemap() -> @CodeMap { self.parse_sess.cm }\n         fn parse_sess() -> parse::parse_sess { self.parse_sess }\n         fn cfg() -> ast::crate_cfg { self.cfg }\n         fn print_backtrace() { }\n-        fn backtrace() -> expn_info { self.backtrace }\n+        fn backtrace() -> Option<@ExpnInfo> { self.backtrace }\n         fn mod_push(i: ast::ident) { self.mod_path.push(i); }\n         fn mod_pop() { self.mod_path.pop(); }\n         fn mod_path() -> ~[ast::ident] { return self.mod_path; }\n-        fn bt_push(ei: codemap::expn_info_) {\n+        fn bt_push(ei: codemap::ExpnInfo) {\n             match ei {\n-              expanded_from({call_site: cs, callie: callie}) => {\n+              ExpandedFrom({call_site: cs, callie: callie}) => {\n                 self.backtrace =\n-                    Some(@expanded_from({\n-                        call_site: {lo: cs.lo, hi: cs.hi,\n-                                    expn_info: self.backtrace},\n+                    Some(@ExpandedFrom({\n+                        call_site: span {lo: cs.lo, hi: cs.hi,\n+                                         expn_info: self.backtrace},\n                         callie: callie}));\n               }\n             }\n         }\n         fn bt_pop() {\n             match self.backtrace {\n-              Some(@expanded_from({call_site: {expn_info: prev, _}, _})) => {\n+              Some(@ExpandedFrom({\n+                  call_site: span {expn_info: prev, _}, _\n+              })) => {\n                 self.backtrace = prev\n               }\n               _ => self.bug(~\"tried to pop without a push\")\n@@ -326,7 +329,7 @@ fn tt_args_to_original_flavor(cx: ext_ctxt, sp: span, arg: ~[ast::token_tree])\n \n     // these spans won't matter, anyways\n     fn ms(m: matcher_) -> matcher {\n-        {node: m, span: {lo: 0u, hi: 0u, expn_info: None}}\n+        {node: m, span: dummy_sp()}\n     }\n     let arg_nm = cx.parse_sess().interner.gensym(@~\"arg\");\n "}, {"sha": "69d067f1ddb0a0549e1c6b149e4f40568a0a7c42", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -8,7 +8,7 @@ use ext::qquote::{qq_helper};\n use parse::{parser, parse_expr_from_source_str, new_parser_from_tt};\n \n \n-use codemap::{span, expanded_from};\n+use codemap::{span, ExpandedFrom};\n \n fn expand_expr(exts: HashMap<~str, syntax_extension>, cx: ext_ctxt,\n                e: expr_, s: span, fld: ast_fold,\n@@ -41,7 +41,7 @@ fn expand_expr(exts: HashMap<~str, syntax_extension>, cx: ext_ctxt,\n                   Some(normal({expander: exp, span: exp_sp})) => {\n                     let expanded = exp(cx, mac.span, args, body);\n \n-                    cx.bt_push(expanded_from({call_site: s,\n+                    cx.bt_push(ExpandedFrom({call_site: s,\n                                 callie: {name: *extname, span: exp_sp}}));\n                     //keep going, outside-in\n                     let fully_expanded = fld.fold_expr(expanded).node;\n@@ -86,7 +86,7 @@ fn expand_expr(exts: HashMap<~str, syntax_extension>, cx: ext_ctxt,\n                                          *extname))\n                     };\n \n-                    cx.bt_push(expanded_from({call_site: s,\n+                    cx.bt_push(ExpandedFrom({call_site: s,\n                                 callie: {name: *extname, span: exp_sp}}));\n                     //keep going, outside-in\n                     let fully_expanded = fld.fold_expr(expanded).node;\n@@ -100,7 +100,7 @@ fn expand_expr(exts: HashMap<~str, syntax_extension>, cx: ext_ctxt,\n                                                                tts);\n                     let expanded = exp(cx, mac.span, arg, None);\n \n-                    cx.bt_push(expanded_from({call_site: s,\n+                    cx.bt_push(ExpandedFrom({call_site: s,\n                                 callie: {name: *extname, span: exp_sp}}));\n                     //keep going, outside-in\n                     let fully_expanded = fld.fold_expr(expanded).node;\n@@ -206,7 +206,7 @@ fn expand_item_mac(exts: HashMap<~str, syntax_extension>,\n           }\n           Some(item_tt(expand)) => {\n             let expanded = expand.expander(cx, it.span, it.ident, tts);\n-            cx.bt_push(expanded_from({call_site: it.span,\n+            cx.bt_push(ExpandedFrom({call_site: it.span,\n                                       callie: {name: *extname,\n                                                span: expand.span}}));\n             let maybe_it = match expanded {\n@@ -232,7 +232,7 @@ fn expand_item_mac(exts: HashMap<~str, syntax_extension>,\n \n fn new_span(cx: ext_ctxt, sp: span) -> span {\n     /* this discards information in the case of macro-defining macros */\n-    return {lo: sp.lo, hi: sp.hi, expn_info: cx.backtrace()};\n+    return span {lo: sp.lo, hi: sp.hi, expn_info: cx.backtrace()};\n }\n \n // FIXME (#2247): this is a terrible kludge to inject some macros into"}, {"sha": "652ad5533c4c793373144c0c26538e37573aed75", "filename": "src/libsyntax/ext/pipes/ast_builder.rs", "status": "modified", "additions": 23, "deletions": 32, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fast_builder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fast_builder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fast_builder.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -4,7 +4,7 @@\n // something smarter.\n \n use ast::{ident, node_id};\n-use ast_util::{ident_to_path, respan};\n+use ast_util::{ident_to_path, respan, dummy_sp};\n use codemap::span;\n use ext::base::mk_ctxt;\n \n@@ -23,10 +23,6 @@ fn path(ids: ~[ident], span: span) -> @ast::path {\n       types: ~[]}\n }\n \n-fn empty_span() -> span {\n-    {lo: 0, hi: 0, expn_info: None}\n-}\n-\n trait append_types {\n     fn add_ty(ty: @ast::Ty) -> @ast::path;\n     fn add_tys(+tys: ~[@ast::Ty]) -> @ast::path;\n@@ -83,26 +79,21 @@ trait ext_ctxt_ast_builder {\n     fn stmt_let(ident: ident, e: @ast::expr) -> @ast::stmt;\n     fn stmt_expr(e: @ast::expr) -> @ast::stmt;\n     fn block_expr(b: ast::blk) -> @ast::expr;\n-    fn empty_span() -> span;\n     fn ty_option(ty: @ast::Ty) -> @ast::Ty;\n }\n \n impl ext_ctxt: ext_ctxt_ast_builder {\n     fn ty_option(ty: @ast::Ty) -> @ast::Ty {\n         self.ty_path_ast_builder(path(~[self.ident_of(~\"Option\")],\n-                                      self.empty_span())\n+                                      dummy_sp())\n                                  .add_ty(ty))\n     }\n \n-    fn empty_span() -> span {\n-        {lo: 0, hi: 0, expn_info: self.backtrace()}\n-    }\n-\n     fn block_expr(b: ast::blk) -> @ast::expr {\n         @{id: self.next_id(),\n           callee_id: self.next_id(),\n           node: ast::expr_block(b),\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn move_expr(e: @ast::expr) -> @ast::expr {\n@@ -114,7 +105,7 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n \n     fn stmt_expr(e: @ast::expr) -> @ast::stmt {\n         @{node: ast::stmt_expr(e, self.next_id()),\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn stmt_let(ident: ident, e: @ast::expr) -> @ast::stmt {\n@@ -130,43 +121,43 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n                      pat: @{id: self.next_id(),\n                             node: ast::pat_ident(ast::bind_by_implicit_ref,\n                                                  path(~[ident],\n-                                                      self.empty_span()),\n+                                                      dummy_sp()),\n                                                  None),\n-                            span: self.empty_span()},\n+                            span: dummy_sp()},\n                      init: Some(self.move_expr(e)),\n                      id: self.next_id()},\n-              span: self.empty_span()}]),\n-                               span: self.empty_span()}, self.next_id()),\n-         span: self.empty_span()}\n+              span: dummy_sp()}]),\n+                               span: dummy_sp()}, self.next_id()),\n+         span: dummy_sp()}\n     }\n \n     fn field_imm(name: ident, e: @ast::expr) -> ast::field {\n         {node: {mutbl: ast::m_imm, ident: name, expr: e},\n-         span: self.empty_span()}\n+         span: dummy_sp()}\n     }\n \n     fn rec(+fields: ~[ast::field]) -> @ast::expr {\n         @{id: self.next_id(),\n           callee_id: self.next_id(),\n           node: ast::expr_rec(fields, None),\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn ty_field_imm(name: ident, ty: @ast::Ty) -> ast::ty_field {\n         {node: {ident: name, mt: { ty: ty, mutbl: ast::m_imm } },\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn ty_rec(+fields: ~[ast::ty_field]) -> @ast::Ty {\n         @{id: self.next_id(),\n           node: ast::ty_rec(fields),\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn ty_infer() -> @ast::Ty {\n         @{id: self.next_id(),\n           node: ast::ty_infer,\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn ty_param(id: ast::ident, +bounds: ~[ast::ty_param_bound])\n@@ -181,9 +172,9 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n          pat: @{id: self.next_id(),\n                 node: ast::pat_ident(\n                     ast::bind_by_value,\n-                    ast_util::ident_to_path(self.empty_span(), name),\n+                    ast_util::ident_to_path(dummy_sp(), name),\n                     None),\n-                span: self.empty_span()},\n+                span: dummy_sp()},\n          id: self.next_id()}\n     }\n \n@@ -195,7 +186,7 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n                    rules: ast::default_blk};\n \n         {node: blk,\n-         span: self.empty_span()}\n+         span: dummy_sp()}\n     }\n \n     fn expr_block(e: @ast::expr) -> ast::blk {\n@@ -215,11 +206,11 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n \n         // XXX: Would be nice if our generated code didn't violate\n         // Rust coding conventions\n-        let non_camel_case_attribute = respan(self.empty_span(), {\n+        let non_camel_case_attribute = respan(dummy_sp(), {\n             style: ast::attr_outer,\n-            value: respan(self.empty_span(),\n+            value: respan(dummy_sp(),\n                           ast::meta_list(~\"allow\", ~[\n-                              @respan(self.empty_span(),\n+                              @respan(dummy_sp(),\n                                       ast::meta_word(~\"non_camel_case_types\"))\n                           ])),\n             is_sugared_doc: false\n@@ -239,7 +230,7 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n                     +ty_params: ~[ast::ty_param],\n                     +body: ast::blk) -> @ast::item {\n         self.item(name,\n-                  self.empty_span(),\n+                  dummy_sp(),\n                   ast::item_fn(self.fn_decl(inputs, output),\n                                ast::impure_fn,\n                                ty_params,\n@@ -298,7 +289,7 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n     fn ty_nil_ast_builder() -> @ast::Ty {\n         @{id: self.next_id(),\n           node: ast::ty_nil,\n-          span: self.empty_span()}\n+          span: dummy_sp()}\n     }\n \n     fn item_ty_poly(name: ident,\n@@ -314,6 +305,6 @@ impl ext_ctxt: ext_ctxt_ast_builder {\n \n     fn ty_vars(+ty_params: ~[ast::ty_param]) -> ~[@ast::Ty] {\n         ty_params.map(|p| self.ty_path_ast_builder(\n-            path(~[p.ident], self.empty_span())))\n+            path(~[p.ident], dummy_sp())))\n     }\n }"}, {"sha": "a90b679f6974c9530963e1dbb8cc2ad351c06fff", "filename": "src/libsyntax/ext/pipes/check.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fcheck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fcheck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fcheck.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -22,7 +22,6 @@ that.\n use ext::base::ext_ctxt;\n \n use proto::{state, protocol, next_state};\n-use ast_builder::empty_span;\n \n impl ext_ctxt: proto::visitor<(), (), ()>  {\n     fn visit_proto(_proto: protocol,"}, {"sha": "e86b3f0ea59e49cb5b708a22cd876e9c90f9b06b", "filename": "src/libsyntax/ext/pipes/liveness.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fliveness.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fliveness.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fliveness.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -29,8 +29,6 @@ updating the states using rule (2) until there are no changes.\n \n use std::bitv::{Bitv};\n \n-use ast_builder::empty_span;\n-\n fn analyze(proto: protocol, _cx: ext_ctxt) {\n     debug!(\"initializing colive analysis\");\n     let num_states = proto.num_states();"}, {"sha": "d03a0fde66c97f61d9ebb7091fd16a23c7e694ff", "filename": "src/libsyntax/ext/pipes/pipec.rs", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fpipec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fpipes%2Fpipec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fpipec.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -5,14 +5,15 @@ use to_str::ToStr;\n use dvec::DVec;\n \n use ast::ident;\n+use ast_util::dummy_sp;\n use util::interner;\n use print::pprust;\n use pprust::{item_to_str, ty_to_str};\n use ext::base::{mk_ctxt, ext_ctxt};\n use parse::*;\n use proto::*;\n \n-use ast_builder::{append_types, path, empty_span};\n+use ast_builder::{append_types, path};\n \n // Transitional reexports so qquote can find the paths it is looking for\n mod syntax {\n@@ -256,11 +257,11 @@ impl state: to_type_decls {\n                     cx.ty_path_ast_builder(\n                         path(~[cx.ident_of(~\"pipes\"),\n                                cx.ident_of(dir.to_str() + ~\"Packet\")],\n-                             empty_span())\n+                             dummy_sp())\n                         .add_ty(cx.ty_path_ast_builder(\n                             path(~[cx.ident_of(self.proto.name),\n                                    self.data_name()],\n-                                 empty_span())\n+                                 dummy_sp())\n                             .add_tys(cx.ty_vars(self.ty_params))))),\n                     self.ty_params));\n         }\n@@ -273,11 +274,11 @@ impl state: to_type_decls {\n                         path(~[cx.ident_of(~\"pipes\"),\n                                cx.ident_of(dir.to_str()\n                                            + ~\"PacketBuffered\")],\n-                             empty_span())\n+                             dummy_sp())\n                         .add_tys(~[cx.ty_path_ast_builder(\n                             path(~[cx.ident_of(self.proto.name),\n                                    self.data_name()],\n-                                 empty_span())\n+                                 dummy_sp())\n                             .add_tys(cx.ty_vars(self.ty_params))),\n                                    self.proto.buffer_ty_path(cx)])),\n                     self.ty_params));\n@@ -394,7 +395,7 @@ impl protocol: gen_init {\n \n         cx.item_ty_poly(\n             cx.ident_of(~\"__Buffer\"),\n-            cx.empty_span(),\n+            dummy_sp(),\n             cx.ty_rec(fields),\n             params)\n     }"}, {"sha": "888932e58e7138b76e59e69b229a6ad347beea45", "filename": "src/libsyntax/ext/qquote.rs", "status": "modified", "additions": 15, "deletions": 13, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fqquote.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -4,6 +4,7 @@ use parse::parser;\n use parse::parser::{Parser, parse_from_source_str};\n use dvec::DVec;\n use parse::token::ident_interner;\n+use codemap::{CharPos, BytePos};\n \n use fold::*;\n use visit::*;\n@@ -15,13 +16,13 @@ use io::*;\n use codemap::span;\n \n struct gather_item {\n-    lo: uint,\n-    hi: uint,\n+    lo: BytePos,\n+    hi: BytePos,\n     e: @ast::expr,\n     constr: ~str\n }\n \n-type aq_ctxt = @{lo: uint, gather: DVec<gather_item>};\n+type aq_ctxt = @{lo: BytePos, gather: DVec<gather_item>};\n enum fragment {\n     from_expr(@ast::expr),\n     from_ty(@ast::Ty)\n@@ -114,7 +115,7 @@ impl @ast::pat: qq_helper {\n     fn get_fold_fn() -> ~str {~\"fold_pat\"}\n }\n \n-fn gather_anti_quotes<N: qq_helper>(lo: uint, node: N) -> aq_ctxt\n+fn gather_anti_quotes<N: qq_helper>(lo: BytePos, node: N) -> aq_ctxt\n {\n     let v = @{visit_expr: |node, &&cx, v| visit_aq(node, ~\"from_expr\", cx, v),\n               visit_ty: |node, &&cx, v| visit_aq(node, ~\"from_ty\", cx, v),\n@@ -204,13 +205,13 @@ fn finish<T: qq_helper>\n     -> @ast::expr\n {\n     let cm = ecx.codemap();\n-    let str = @codemap::span_to_snippet(body.span, cm);\n+    let str = @cm.span_to_snippet(body.span);\n     debug!(\"qquote--str==%?\", str);\n-    let fname = codemap::mk_substr_filename(cm, body.span);\n+    let fname = cm.mk_substr_filename(body.span);\n     let node = parse_from_source_str\n-        (f, fname, codemap::fss_internal(body.span), str,\n+        (f, fname, codemap::FssInternal(body.span), str,\n          ecx.cfg(), ecx.parse_sess());\n-    let loc = codemap::lookup_char_pos(cm, body.span.lo);\n+    let loc = cm.lookup_char_pos(body.span.lo);\n \n     let sp = node.span();\n     let qcx = gather_anti_quotes(sp.lo, node);\n@@ -226,7 +227,8 @@ fn finish<T: qq_helper>\n     let mut str2 = ~\"\";\n     enum state {active, skip(uint), blank};\n     let mut state = active;\n-    let mut i = 0u, j = 0u;\n+    let mut i = BytePos(0u);\n+    let mut j = 0u;\n     let g_len = cx.gather.len();\n     for str::chars_each(*str) |ch| {\n         if (j < g_len && i == cx.gather[j].lo) {\n@@ -242,7 +244,7 @@ fn finish<T: qq_helper>\n           blank if is_space(ch) => str::push_char(&mut str2, ch),\n           blank => str::push_char(&mut str2, ' ')\n         }\n-        i += 1u;\n+        i += BytePos(1u);\n         if (j < g_len && i == cx.gather[j].hi) {\n             assert ch == ')';\n             state = active;\n@@ -270,7 +272,7 @@ fn finish<T: qq_helper>\n                                  ~\"qquote\", ~\"mk_file_substr\"]),\n                                 ~[mk_uniq_str(cx,sp, loc.file.name),\n                                  mk_uint(cx,sp, loc.line),\n-                                 mk_uint(cx,sp, loc.col)]),\n+                                 mk_uint(cx,sp, loc.col.to_uint())]),\n                         mk_unary(cx,sp, ast::box(ast::m_imm),\n                                  mk_uniq_str(cx,sp, str2)),\n                         cfg_call(),\n@@ -345,8 +347,8 @@ fn replace_ty(repls: ~[fragment],\n }\n \n fn mk_file_substr(fname: ~str, line: uint, col: uint) ->\n-    codemap::file_substr {\n-    codemap::fss_external({filename: fname, line: line, col: col})\n+    codemap::FileSubstr {\n+    codemap::FssExternal({filename: fname, line: line, col: CharPos(col)})\n }\n \n // Local Variables:"}, {"sha": "3cca48c7508911d5443807d75dc22a86237e8178", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 16, "deletions": 5, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,7 +1,7 @@\n use mod ast;\n use mod parse::token;\n \n-use codemap::span;\n+use codemap::{span, BytePos};\n use ext::base::ext_ctxt;\n use token::*;\n \n@@ -20,6 +20,8 @@ pub mod rt {\n     pub use ast::*;\n     pub use parse::token::*;\n     pub use parse::new_parser_from_tt;\n+    pub use codemap::BytePos;\n+    pub use codemap::span;\n }\n \n pub fn expand_quote_tokens(cx: ext_ctxt,\n@@ -92,7 +94,7 @@ fn mk_span(cx: ext_ctxt, qsp: span, sp: span) -> @ast::expr {\n \n     let e_expn_info = match sp.expn_info {\n         None => build::mk_path(cx, qsp, ids_ext(cx, ~[~\"None\"])),\n-        Some(@codemap::expanded_from(cr)) => {\n+        Some(@codemap::ExpandedFrom(cr)) => {\n             let e_callee =\n                 build::mk_rec_e(\n                     cx, qsp,\n@@ -119,12 +121,16 @@ fn mk_span(cx: ext_ctxt, qsp: span, sp: span) -> @ast::expr {\n         }\n     };\n \n-    build::mk_rec_e(cx, qsp,\n+    let span_path = ids_ext(\n+        cx, ~[~\"syntax\", ~\"ext\", ~\"quote\", ~\"rt\", ~\"span\"]);\n+\n+    build::mk_struct_e(cx, qsp,\n+                       span_path,\n                     ~[{ident: id_ext(cx, ~\"lo\"),\n-                       ex: build::mk_uint(cx, qsp, sp.lo) },\n+                       ex: mk_bytepos(cx, qsp, sp.lo) },\n \n                       {ident: id_ext(cx, ~\"hi\"),\n-                       ex: build::mk_uint(cx, qsp, sp.hi) },\n+                       ex: mk_bytepos(cx, qsp, sp.hi) },\n \n                       {ident: id_ext(cx, ~\"expn_info\"),\n                        ex: e_expn_info}])\n@@ -143,6 +149,11 @@ fn mk_ident(cx: ext_ctxt, sp: span, ident: ast::ident) -> @ast::expr {\n                           ex: build::mk_uint(cx, sp, ident.repr) }])\n }\n \n+fn mk_bytepos(cx: ext_ctxt, sp: span, bpos: BytePos) -> @ast::expr {\n+    let path = ids_ext(cx, ~[~\"syntax\", ~\"ext\", ~\"quote\", ~\"rt\", ~\"BytePos\"]);\n+    let arg = build::mk_uint(cx, sp, bpos.to_uint());\n+    build::mk_call(cx, sp, path, ~[arg])\n+}\n \n fn mk_binop(cx: ext_ctxt, sp: span, bop: token::binop) -> @ast::expr {\n     let name = match bop {"}, {"sha": "df7674264ca110d5b24da5682b1011ffae2a08b0", "filename": "src/libsyntax/ext/simplext.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fsimplext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fsimplext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsimplext.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -177,7 +177,7 @@ fn transcribe(cx: ext_ctxt, b: bindings, body: @expr) -> @expr {\n     fn new_id(_old: node_id, cx: ext_ctxt) -> node_id { return cx.next_id(); }\n     fn new_span(cx: ext_ctxt, sp: span) -> span {\n         /* this discards information in the case of macro-defining macros */\n-        return {lo: sp.lo, hi: sp.hi, expn_info: cx.backtrace()};\n+        return span {lo: sp.lo, hi: sp.hi, expn_info: cx.backtrace()};\n     }\n     let afp = default_ast_fold();\n     let f_pre ="}, {"sha": "baf92175e7d6b5be4b7aa603217dd02d9ca2c092", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,5 +1,5 @@\n use base::*;\n-use codemap::span;\n+use codemap::{span, Loc, FileMap};\n use print::pprust;\n use build::{mk_base_vec_e,mk_uint,mk_u8,mk_uniq_str};\n \n@@ -16,16 +16,16 @@ export expand_include_bin;\n fn expand_line(cx: ext_ctxt, sp: span, arg: ast::mac_arg,\n                _body: ast::mac_body) -> @ast::expr {\n     get_mac_args(cx, sp, arg, 0u, option::Some(0u), ~\"line\");\n-    let loc = codemap::lookup_char_pos(cx.codemap(), sp.lo);\n+    let loc = cx.codemap().lookup_char_pos(sp.lo);\n     return mk_uint(cx, sp, loc.line);\n }\n \n /* col!(): expands to the current column number */\n fn expand_col(cx: ext_ctxt, sp: span, arg: ast::mac_arg,\n               _body: ast::mac_body) -> @ast::expr {\n     get_mac_args(cx, sp, arg, 0u, option::Some(0u), ~\"col\");\n-    let loc = codemap::lookup_char_pos(cx.codemap(), sp.lo);\n-    return mk_uint(cx, sp, loc.col);\n+    let loc = cx.codemap().lookup_char_pos(sp.lo);\n+    return mk_uint(cx, sp, loc.col.to_uint());\n }\n \n /* file!(): expands to the current filename */\n@@ -34,8 +34,8 @@ fn expand_col(cx: ext_ctxt, sp: span, arg: ast::mac_arg,\n fn expand_file(cx: ext_ctxt, sp: span, arg: ast::mac_arg,\n                _body: ast::mac_body) -> @ast::expr {\n     get_mac_args(cx, sp, arg, 0u, option::Some(0u), ~\"file\");\n-    let { file: @{ name: filename, _ }, _ } =\n-        codemap::lookup_char_pos(cx.codemap(), sp.lo);\n+    let Loc { file: @FileMap { name: filename, _ }, _ } =\n+        cx.codemap().lookup_char_pos(sp.lo);\n     return mk_uniq_str(cx, sp, filename);\n }\n \n@@ -103,7 +103,7 @@ fn expand_include_bin(cx: ext_ctxt, sp: codemap::span, arg: ast::mac_arg,\n fn res_rel_file(cx: ext_ctxt, sp: codemap::span, arg: &Path) -> Path {\n     // NB: relative paths are resolved relative to the compilation unit\n     if !arg.is_absolute {\n-        let cu = Path(codemap::span_to_filename(sp, cx.codemap()));\n+        let cu = Path(cx.codemap().span_to_filename(sp));\n         cu.dir_path().push_many(arg.components)\n     } else {\n         copy *arg"}, {"sha": "6779ed263d5a8a574f37b9d028edefcbc8630d41", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -11,6 +11,7 @@ use dvec::DVec;\n use ast::{matcher, match_tok, match_seq, match_nonterminal, ident};\n use ast_util::mk_sp;\n use std::map::HashMap;\n+use codemap::BytePos;\n \n /* This is an Earley-like parser, without support for in-grammar nonterminals,\n only by calling out to the main rust parser for named nonterminals (which it\n@@ -102,7 +103,7 @@ type matcher_pos = ~{\n     mut up: matcher_pos_up, // mutable for swapping only\n     matches: ~[DVec<@named_match>],\n     match_lo: uint, match_hi: uint,\n-    sp_lo: uint,\n+    sp_lo: BytePos,\n };\n \n fn copy_up(&& mpu: matcher_pos_up) -> matcher_pos {\n@@ -122,7 +123,7 @@ fn count_names(ms: &[matcher]) -> uint {\n }\n \n #[allow(non_implicitly_copyable_typarams)]\n-fn initial_matcher_pos(ms: ~[matcher], sep: Option<Token>, lo: uint)\n+fn initial_matcher_pos(ms: ~[matcher], sep: Option<Token>, lo: BytePos)\n     -> matcher_pos {\n     let mut match_idx_hi = 0u;\n     for ms.each() |elt| {"}, {"sha": "8bfd1c0a18d39176660f64c7b11cae1eb37a70b3", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -9,12 +9,13 @@ use macro_parser::{parse, parse_or_else, success, failure, named_match,\n                       matched_seq, matched_nonterminal, error};\n use std::map::HashMap;\n use parse::token::special_idents;\n+use ast_util::dummy_sp;\n \n fn add_new_extension(cx: ext_ctxt, sp: span, name: ident,\n                      arg: ~[ast::token_tree]) -> base::mac_result {\n     // these spans won't matter, anyways\n     fn ms(m: matcher_) -> matcher {\n-        {node: m, span: {lo: 0u, hi: 0u, expn_info: None}}\n+        {node: m, span: dummy_sp()}\n     }\n \n     let lhs_nm =  cx.parse_sess().interner.gensym(@~\"lhs\");\n@@ -65,7 +66,7 @@ fn add_new_extension(cx: ext_ctxt, sp: span, name: ident,\n         }\n \n         // Which arm's failure should we report? (the one furthest along)\n-        let mut best_fail_spot = {lo: 0u, hi: 0u, expn_info: None};\n+        let mut best_fail_spot = dummy_sp();\n         let mut best_fail_msg = ~\"internal error: ran no matchers\";\n \n         let s_d = cx.parse_sess().span_diagnostic;"}, {"sha": "78f0e4fc8f8bf763cfd90d67e8acc2c2d7671952", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -53,7 +53,7 @@ fn new_tt_reader(sp_diag: span_handler, itr: @ident_interner,\n               mut repeat_len: ~[],\n               /* dummy values, never read: */\n               mut cur_tok: EOF,\n-              mut cur_span: ast_util::mk_sp(0u,0u)\n+              mut cur_span: ast_util::dummy_sp()\n              };\n     tt_next_token(r); /* get cur_tok and cur_span set up */\n     return r;"}, {"sha": "593ff6d034ee007e9b70ac444e4e6f64e1daeedc", "filename": "src/libsyntax/parse.rs", "status": "modified", "additions": 30, "deletions": 65, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -20,33 +20,31 @@ use util::interner;\n use diagnostic::{span_handler, mk_span_handler, mk_handler, emitter};\n use lexer::{reader, string_reader};\n use parse::token::{ident_interner, mk_ident_interner};\n+use codemap::{CodeMap, FileMap, CharPos, BytePos};\n \n type parse_sess = @{\n-    cm: codemap::CodeMap,\n+    cm: @codemap::CodeMap,\n     mut next_id: node_id,\n     span_diagnostic: span_handler,\n     interner: @ident_interner,\n-    // these two must be kept up to date\n-    mut chpos: uint,\n-    mut byte_pos: uint\n };\n \n fn new_parse_sess(demitter: Option<emitter>) -> parse_sess {\n-    let cm = codemap::new_codemap();\n+    let cm = @CodeMap::new();\n     return @{cm: cm,\n              mut next_id: 1,\n              span_diagnostic: mk_span_handler(mk_handler(demitter), cm),\n              interner: mk_ident_interner(),\n-             mut chpos: 0u, mut byte_pos: 0u};\n+            };\n }\n \n-fn new_parse_sess_special_handler(sh: span_handler, cm: codemap::CodeMap)\n+fn new_parse_sess_special_handler(sh: span_handler, cm: @codemap::CodeMap)\n     -> parse_sess {\n     return @{cm: cm,\n              mut next_id: 1,\n              span_diagnostic: sh,\n              interner: mk_ident_interner(),\n-             mut chpos: 0u, mut byte_pos: 0u};\n+             };\n }\n \n fn parse_crate_from_file(input: &Path, cfg: ast::crate_cfg,\n@@ -63,15 +61,13 @@ fn parse_crate_from_file(input: &Path, cfg: ast::crate_cfg,\n \n fn parse_crate_from_crate_file(input: &Path, cfg: ast::crate_cfg,\n                                sess: parse_sess) -> @ast::crate {\n-    let (p, rdr) = new_parser_etc_from_file(sess, cfg, input,\n-                                            parser::CRATE_FILE);\n+    let p = new_parser_from_file(sess, cfg, input,\n+                                 parser::CRATE_FILE);\n     let lo = p.span.lo;\n     let prefix = input.dir_path();\n     let leading_attrs = p.parse_inner_attrs_and_next();\n     let { inner: crate_attrs, next: first_cdir_attr } = leading_attrs;\n     let cdirs = p.parse_crate_directives(token::EOF, first_cdir_attr);\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     let cx = @{sess: sess, cfg: /* FIXME (#2543) */ copy p.cfg};\n     let companionmod = input.filestem().map(|s| Path(*s));\n     let (m, attrs) = eval::eval_crate_directives_to_mod(\n@@ -88,75 +84,63 @@ fn parse_crate_from_crate_file(input: &Path, cfg: ast::crate_cfg,\n \n fn parse_crate_from_source_file(input: &Path, cfg: ast::crate_cfg,\n                                 sess: parse_sess) -> @ast::crate {\n-    let (p, rdr) = new_parser_etc_from_file(sess, cfg, input,\n-                                            parser::SOURCE_FILE);\n+    let p = new_parser_from_file(sess, cfg, input,\n+                                 parser::SOURCE_FILE);\n     let r = p.parse_crate_mod(cfg);\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     return r;\n }\n \n fn parse_crate_from_source_str(name: ~str, source: @~str, cfg: ast::crate_cfg,\n                                sess: parse_sess) -> @ast::crate {\n-    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n-                                                  codemap::fss_none, source);\n+    let p = new_parser_from_source_str(sess, cfg, name,\n+                                       codemap::FssNone, source);\n     let r = p.parse_crate_mod(cfg);\n     p.abort_if_errors();\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     return r;\n }\n \n fn parse_expr_from_source_str(name: ~str, source: @~str, cfg: ast::crate_cfg,\n                               sess: parse_sess) -> @ast::expr {\n-    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n-                                                  codemap::fss_none, source);\n+    let p = new_parser_from_source_str(sess, cfg, name,\n+                                       codemap::FssNone, source);\n     let r = p.parse_expr();\n     p.abort_if_errors();\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     return r;\n }\n \n fn parse_item_from_source_str(name: ~str, source: @~str, cfg: ast::crate_cfg,\n                               +attrs: ~[ast::attribute],\n                               sess: parse_sess) -> Option<@ast::item> {\n-    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n-                                                  codemap::fss_none, source);\n+    let p = new_parser_from_source_str(sess, cfg, name,\n+                                       codemap::FssNone, source);\n     let r = p.parse_item(attrs);\n     p.abort_if_errors();\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     return r;\n }\n \n fn parse_stmt_from_source_str(name: ~str, source: @~str, cfg: ast::crate_cfg,\n                               +attrs: ~[ast::attribute],\n                               sess: parse_sess) -> @ast::stmt {\n-    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n-                                                  codemap::fss_none, source);\n+    let p = new_parser_from_source_str(sess, cfg, name,\n+                                       codemap::FssNone, source);\n     let r = p.parse_stmt(attrs);\n     p.abort_if_errors();\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     return r;\n }\n \n fn parse_from_source_str<T>(f: fn (p: Parser) -> T,\n-                            name: ~str, ss: codemap::file_substr,\n+                            name: ~str, ss: codemap::FileSubstr,\n                             source: @~str, cfg: ast::crate_cfg,\n                             sess: parse_sess)\n     -> T\n {\n-    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name, ss,\n-                                                  source);\n+    let p = new_parser_from_source_str(sess, cfg, name, ss,\n+                                       source);\n     let r = f(p);\n     if !p.reader.is_eof() {\n         p.reader.fatal(~\"expected end-of-string\");\n     }\n     p.abort_if_errors();\n-    sess.chpos = rdr.chpos;\n-    sess.byte_pos = sess.byte_pos + rdr.pos;\n     move r\n }\n \n@@ -168,47 +152,28 @@ fn next_node_id(sess: parse_sess) -> node_id {\n     return rv;\n }\n \n-fn new_parser_etc_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n-                                  +name: ~str, +ss: codemap::file_substr,\n-                                  source: @~str) -> (Parser, string_reader) {\n+fn new_parser_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n+                              +name: ~str, +ss: codemap::FileSubstr,\n+                              source: @~str) -> Parser {\n     let ftype = parser::SOURCE_FILE;\n-    let filemap = codemap::new_filemap_w_substr\n-        (name, ss, source, sess.chpos, sess.byte_pos);\n-    sess.cm.files.push(filemap);\n+    let filemap = sess.cm.new_filemap_w_substr(name, ss, source);\n     let srdr = lexer::new_string_reader(sess.span_diagnostic, filemap,\n                                         sess.interner);\n-    return (Parser(sess, cfg, srdr as reader, ftype), srdr);\n+    return Parser(sess, cfg, srdr as reader, ftype);\n }\n \n-fn new_parser_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n-                              +name: ~str, +ss: codemap::file_substr,\n-                              source: @~str) -> Parser {\n-    let (p, _) = new_parser_etc_from_source_str(sess, cfg, name, ss, source);\n-    move p\n-}\n-\n-\n-fn new_parser_etc_from_file(sess: parse_sess, cfg: ast::crate_cfg,\n-                            path: &Path, ftype: parser::file_type) ->\n-   (Parser, string_reader) {\n+fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg,\n+                        path: &Path, ftype: parser::file_type) -> Parser {\n     let res = io::read_whole_file_str(path);\n     match res {\n       result::Ok(_) => { /* Continue. */ }\n       result::Err(e) => sess.span_diagnostic.handler().fatal(e)\n     }\n     let src = @result::unwrap(res);\n-    let filemap = codemap::new_filemap(path.to_str(), src,\n-                                       sess.chpos, sess.byte_pos);\n-    sess.cm.files.push(filemap);\n+    let filemap = sess.cm.new_filemap(path.to_str(), src);\n     let srdr = lexer::new_string_reader(sess.span_diagnostic, filemap,\n                                         sess.interner);\n-    return (Parser(sess, cfg, srdr as reader, ftype), srdr);\n-}\n-\n-fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, path: &Path,\n-                        ftype: parser::file_type) -> Parser {\n-    let (p, _) = new_parser_etc_from_file(sess, cfg, path, ftype);\n-    move p\n+    return Parser(sess, cfg, srdr as reader, ftype);\n }\n \n fn new_parser_from_tt(sess: parse_sess, cfg: ast::crate_cfg,"}, {"sha": "f0cb1d4ba3e1c6e58948c8d9a43bcaecbcd38342", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -14,7 +14,7 @@ trait parser_attr {\n         -> attr_or_ext;\n     fn parse_outer_attributes() -> ~[ast::attribute];\n     fn parse_attribute(style: ast::attr_style) -> ast::attribute;\n-    fn parse_attribute_naked(style: ast::attr_style, lo: uint) ->\n+    fn parse_attribute_naked(style: ast::attr_style, lo: BytePos) ->\n         ast::attribute;\n     fn parse_inner_attrs_and_next() ->\n         {inner: ~[ast::attribute], next: ~[ast::attribute]};\n@@ -85,7 +85,7 @@ impl Parser: parser_attr {\n         return self.parse_attribute_naked(style, lo);\n     }\n \n-    fn parse_attribute_naked(style: ast::attr_style, lo: uint) ->\n+    fn parse_attribute_naked(style: ast::attr_style, lo: BytePos) ->\n         ast::attribute {\n         self.expect(token::LBRACKET);\n         let meta_item = self.parse_meta_item();"}, {"sha": "2a8bbe3b6d86263fd56ddbc8ffefefc43f7c7f3b", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 18, "deletions": 11, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -3,6 +3,7 @@ use io::ReaderUtil;\n use util::interner;\n use lexer::{string_reader, bump, is_eof, nextch,\n                is_whitespace, get_str_from, reader};\n+use codemap::{FileMap, CharPos};\n \n export cmnt;\n export lit;\n@@ -27,7 +28,7 @@ impl cmnt_style : cmp::Eq {\n     }\n }\n \n-type cmnt = {style: cmnt_style, lines: ~[~str], pos: uint};\n+type cmnt = {style: cmnt_style, lines: ~[~str], pos: BytePos};\n \n fn is_doc_comment(s: ~str) -> bool {\n     s.starts_with(~\"///\") ||\n@@ -130,13 +131,13 @@ fn consume_non_eol_whitespace(rdr: string_reader) {\n fn push_blank_line_comment(rdr: string_reader, comments: &mut ~[cmnt]) {\n     debug!(\">>> blank-line comment\");\n     let v: ~[~str] = ~[];\n-    comments.push({style: blank_line, lines: v, pos: rdr.chpos});\n+    comments.push({style: blank_line, lines: v, pos: rdr.last_pos});\n }\n \n fn consume_whitespace_counting_blank_lines(rdr: string_reader,\n                                            comments: &mut ~[cmnt]) {\n     while is_whitespace(rdr.curr) && !is_eof(rdr) {\n-        if rdr.col == 0u && rdr.curr == '\\n' {\n+        if rdr.col == CharPos(0u) && rdr.curr == '\\n' {\n             push_blank_line_comment(rdr, comments);\n         }\n         bump(rdr);\n@@ -147,7 +148,7 @@ fn consume_whitespace_counting_blank_lines(rdr: string_reader,\n fn read_shebang_comment(rdr: string_reader, code_to_the_left: bool,\n                                             comments: &mut ~[cmnt]) {\n     debug!(\">>> shebang comment\");\n-    let p = rdr.chpos;\n+    let p = rdr.last_pos;\n     debug!(\"<<< shebang comment\");\n     comments.push({\n         style: if code_to_the_left { trailing } else { isolated },\n@@ -159,7 +160,7 @@ fn read_shebang_comment(rdr: string_reader, code_to_the_left: bool,\n fn read_line_comments(rdr: string_reader, code_to_the_left: bool,\n                                           comments: &mut ~[cmnt]) {\n     debug!(\">>> line comments\");\n-    let p = rdr.chpos;\n+    let p = rdr.last_pos;\n     let mut lines: ~[~str] = ~[];\n     while rdr.curr == '/' && nextch(rdr) == '/' {\n         let line = read_one_line_comment(rdr);\n@@ -180,6 +181,8 @@ fn read_line_comments(rdr: string_reader, code_to_the_left: bool,\n     }\n }\n \n+// FIXME #3961: This is not the right way to convert string byte\n+// offsets to characters.\n fn all_whitespace(s: ~str, begin: uint, end: uint) -> bool {\n     let mut i: uint = begin;\n     while i != end {\n@@ -189,9 +192,11 @@ fn all_whitespace(s: ~str, begin: uint, end: uint) -> bool {\n }\n \n fn trim_whitespace_prefix_and_push_line(lines: &mut ~[~str],\n-                                        s: ~str, col: uint) {\n+                                        s: ~str, col: CharPos) {\n     let mut s1;\n     let len = str::len(s);\n+    // FIXME #3961: Doing bytewise comparison and slicing with CharPos\n+    let col = col.to_uint();\n     if all_whitespace(s, 0u, uint::min(len, col)) {\n         if col < len {\n             s1 = str::slice(s, col, len);\n@@ -204,9 +209,9 @@ fn trim_whitespace_prefix_and_push_line(lines: &mut ~[~str],\n fn read_block_comment(rdr: string_reader, code_to_the_left: bool,\n                                           comments: &mut ~[cmnt]) {\n     debug!(\">>> block comment\");\n-    let p = rdr.chpos;\n+    let p = rdr.last_pos;\n     let mut lines: ~[~str] = ~[];\n-    let mut col: uint = rdr.col;\n+    let mut col: CharPos = rdr.col;\n     bump(rdr);\n     bump(rdr);\n \n@@ -279,16 +284,18 @@ fn consume_comment(rdr: string_reader, code_to_the_left: bool,\n     debug!(\"<<< consume comment\");\n }\n \n-type lit = {lit: ~str, pos: uint};\n+type lit = {lit: ~str, pos: BytePos};\n \n fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n                                 path: ~str,\n                                 srdr: io::Reader) ->\n    {cmnts: ~[cmnt], lits: ~[lit]} {\n     let src = @str::from_bytes(srdr.read_whole_stream());\n     let itr = parse::token::mk_fake_ident_interner();\n-    let rdr = lexer::new_low_level_string_reader\n-        (span_diagnostic, codemap::new_filemap(path, src, 0u, 0u), itr);\n+    let cm = CodeMap::new();\n+    let filemap = cm.new_filemap(path, src);\n+    let rdr = lexer::new_low_level_string_reader(\n+        span_diagnostic, filemap, itr);\n \n     let mut comments: ~[cmnt] = ~[];\n     let mut literals: ~[lit] = ~[];"}, {"sha": "1811951fc0e9a8496497a4f3a1386e11be4cd636", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -205,7 +205,7 @@ impl Parser: parser_common {\n         if self.token == token::GT {\n             self.bump();\n         } else if self.token == token::BINOP(token::SHR) {\n-            self.swap(token::GT, self.span.lo + 1u, self.span.hi);\n+            self.swap(token::GT, self.span.lo + BytePos(1u), self.span.hi);\n         } else {\n             let mut s: ~str = ~\"expected `\";\n             s += token_to_str(self.reader, token::GT);"}, {"sha": "f08f195446442e417e5602391d5422afff9eb2f9", "filename": "src/libsyntax/parse/eval.rs", "status": "modified", "additions": 5, "deletions": 10, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Feval.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -62,12 +62,10 @@ fn parse_companion_mod(cx: ctx, prefix: &Path, suffix: &Option<Path>)\n     let modpath = &companion_file(prefix, suffix);\n     if file_exists(modpath) {\n         debug!(\"found companion mod\");\n-        let (p0, r0) = new_parser_etc_from_file(cx.sess, cx.cfg,\n-                                                modpath, SOURCE_FILE);\n+        let p0 = new_parser_from_file(cx.sess, cx.cfg,\n+                                      modpath, SOURCE_FILE);\n         let inner_attrs = p0.parse_inner_attrs_and_next();\n         let m0 = p0.parse_mod_items(token::EOF, inner_attrs.next);\n-        cx.sess.chpos = r0.chpos;\n-        cx.sess.byte_pos = cx.sess.byte_pos + r0.pos;\n         return (m0.view_items, m0.items, inner_attrs.inner);\n     } else {\n         return (~[], ~[], ~[]);\n@@ -93,9 +91,9 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: &Path,\n         } else {\n             prefix.push_many(file_path.components)\n         };\n-        let (p0, r0) =\n-            new_parser_etc_from_file(cx.sess, cx.cfg,\n-                                     &full_path, SOURCE_FILE);\n+        let p0 =\n+            new_parser_from_file(cx.sess, cx.cfg,\n+                                 &full_path, SOURCE_FILE);\n         let inner_attrs = p0.parse_inner_attrs_and_next();\n         let mod_attrs = vec::append(attrs, inner_attrs.inner);\n         let first_item_outer_attrs = inner_attrs.next;\n@@ -104,9 +102,6 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: &Path,\n         let i = p0.mk_item(cdir.span.lo, cdir.span.hi,\n                            /* FIXME (#2543) */ copy id,\n                            ast::item_mod(m0), vis, mod_attrs);\n-        // Thread defids, chpos and byte_pos through the parsers\n-        cx.sess.chpos = r0.chpos;\n-        cx.sess.byte_pos = cx.sess.byte_pos + r0.pos;\n         items.push(i);\n       }\n       ast::cdir_dir_mod(vis, id, cdirs, attrs) => {"}, {"sha": "d65be043f86a5c6eae3a69146122df2dd7ae9a24", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 62, "deletions": 41, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,5 +1,5 @@\n use diagnostic::span_handler;\n-use codemap::span;\n+use codemap::{span, CodeMap, CharPos, BytePos};\n use ext::tt::transcribe::{tt_reader,  new_tt_reader, dup_tt_reader,\n                              tt_next_token};\n \n@@ -21,19 +21,23 @@ trait reader {\n type string_reader = @{\n     span_diagnostic: span_handler,\n     src: @~str,\n-    mut col: uint,\n-    mut pos: uint,\n+    // The absolute offset within the codemap of the next character to read\n+    mut pos: BytePos,\n+    // The absolute offset within the codemap of the last character read(curr)\n+    mut last_pos: BytePos,\n+    // The column of the next character to read\n+    mut col: CharPos,\n+    // The last character to be read\n     mut curr: char,\n-    mut chpos: uint,\n-    filemap: codemap::filemap,\n+    filemap: @codemap::FileMap,\n     interner: @token::ident_interner,\n     /* cached: */\n     mut peek_tok: token::Token,\n     mut peek_span: span\n };\n \n fn new_string_reader(span_diagnostic: span_handler,\n-                     filemap: codemap::filemap,\n+                     filemap: @codemap::FileMap,\n                      itr: @token::ident_interner) -> string_reader {\n     let r = new_low_level_string_reader(span_diagnostic, filemap, itr);\n     string_advance_token(r); /* fill in peek_* */\n@@ -42,27 +46,29 @@ fn new_string_reader(span_diagnostic: span_handler,\n \n /* For comments.rs, which hackily pokes into 'pos' and 'curr' */\n fn new_low_level_string_reader(span_diagnostic: span_handler,\n-                               filemap: codemap::filemap,\n+                               filemap: @codemap::FileMap,\n                                itr: @token::ident_interner)\n     -> string_reader {\n+    // Force the initial reader bump to start on a fresh line\n+    let initial_char = '\\n';\n     let r = @{span_diagnostic: span_diagnostic, src: filemap.src,\n-              mut col: 0u, mut pos: 0u, mut curr: -1 as char,\n-              mut chpos: filemap.start_pos.ch,\n+              mut pos: filemap.start_pos,\n+              mut last_pos: filemap.start_pos,\n+              mut col: CharPos(0),\n+              mut curr: initial_char,\n               filemap: filemap, interner: itr,\n               /* dummy values; not read */\n               mut peek_tok: token::EOF,\n-              mut peek_span: ast_util::mk_sp(0u,0u)};\n-    if r.pos < (*filemap.src).len() {\n-        let next = str::char_range_at(*r.src, r.pos);\n-        r.pos = next.next;\n-        r.curr = next.ch;\n-    }\n+              mut peek_span: ast_util::dummy_sp()};\n+    bump(r);\n     return r;\n }\n \n fn dup_string_reader(&&r: string_reader) -> string_reader {\n     @{span_diagnostic: r.span_diagnostic, src: r.src,\n-      mut col: r.col, mut pos: r.pos, mut curr: r.curr, mut chpos: r.chpos,\n+      mut pos: r.pos,\n+      mut last_pos: r.last_pos,\n+      mut col: r.col, mut curr: r.curr,\n       filemap: r.filemap, interner: r.interner,\n       mut peek_tok: r.peek_tok, mut peek_span: r.peek_span}\n }\n@@ -117,34 +123,48 @@ fn string_advance_token(&&r: string_reader) {\n     if is_eof(r) {\n         r.peek_tok = token::EOF;\n     } else {\n-        let start_chpos = r.chpos;\n+        let start_bytepos = r.last_pos;\n         r.peek_tok = next_token_inner(r);\n-        r.peek_span = ast_util::mk_sp(start_chpos, r.chpos);\n+        r.peek_span = ast_util::mk_sp(start_bytepos, r.last_pos);\n     };\n \n }\n \n-fn get_str_from(rdr: string_reader, start: uint) -> ~str unsafe {\n+fn byte_offset(rdr: string_reader) -> BytePos {\n+    (rdr.pos - rdr.filemap.start_pos)\n+}\n+\n+fn get_str_from(rdr: string_reader, start: BytePos) -> ~str unsafe {\n     // I'm pretty skeptical about this subtraction. What if there's a\n     // multi-byte character before the mark?\n-    return str::slice(*rdr.src, start - 1u, rdr.pos - 1u);\n+    return str::slice(*rdr.src, start.to_uint() - 1u,\n+                      byte_offset(rdr).to_uint() - 1u);\n }\n \n fn bump(rdr: string_reader) {\n-    if rdr.pos < (*rdr.src).len() {\n-        rdr.col += 1u;\n-        rdr.chpos += 1u;\n-        if rdr.curr == '\\n' {\n-            codemap::next_line(rdr.filemap, rdr.chpos, rdr.pos);\n-            rdr.col = 0u;\n-        }\n-        let next = str::char_range_at(*rdr.src, rdr.pos);\n-        rdr.pos = next.next;\n+    rdr.last_pos = rdr.pos;\n+    let current_byte_offset = byte_offset(rdr).to_uint();;\n+    if current_byte_offset < (*rdr.src).len() {\n+        let last_char = rdr.curr;\n+        let next = str::char_range_at(*rdr.src, current_byte_offset);\n+        let byte_offset_diff = next.next - current_byte_offset;\n+        rdr.pos = rdr.pos + BytePos(byte_offset_diff);\n         rdr.curr = next.ch;\n+        rdr.col += CharPos(1u);\n+        if last_char == '\\n' {\n+            rdr.filemap.next_line(rdr.last_pos);\n+            rdr.col = CharPos(0u);\n+        }\n+\n+        if byte_offset_diff > 1 {\n+            rdr.filemap.record_multibyte_char(\n+                BytePos(current_byte_offset), byte_offset_diff);\n+        }\n     } else {\n+        // XXX: What does this accomplish?\n         if (rdr.curr != -1 as char) {\n-            rdr.col += 1u;\n-            rdr.chpos += 1u;\n+            rdr.pos = rdr.pos + BytePos(1u);\n+            rdr.col += CharPos(1u);\n             rdr.curr = -1 as char;\n         }\n     }\n@@ -153,8 +173,9 @@ fn is_eof(rdr: string_reader) -> bool {\n     rdr.curr == -1 as char\n }\n fn nextch(rdr: string_reader) -> char {\n-    if rdr.pos < (*rdr.src).len() {\n-        return str::char_at(*rdr.src, rdr.pos);\n+    let offset = byte_offset(rdr).to_uint();\n+    if offset < (*rdr.src).len() {\n+        return str::char_at(*rdr.src, offset);\n     } else { return -1 as char; }\n }\n \n@@ -211,15 +232,15 @@ fn consume_any_line_comment(rdr: string_reader)\n             bump(rdr);\n             // line comments starting with \"///\" or \"//!\" are doc-comments\n             if rdr.curr == '/' || rdr.curr == '!' {\n-                let start_chpos = rdr.chpos - 2u;\n+                let start_bpos = rdr.pos - BytePos(2u);\n                 let mut acc = ~\"//\";\n                 while rdr.curr != '\\n' && !is_eof(rdr) {\n                     str::push_char(&mut acc, rdr.curr);\n                     bump(rdr);\n                 }\n                 return Some({\n                     tok: token::DOC_COMMENT(rdr.interner.intern(@acc)),\n-                    sp: ast_util::mk_sp(start_chpos, rdr.chpos)\n+                    sp: ast_util::mk_sp(start_bpos, rdr.pos)\n                 });\n             } else {\n                 while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n@@ -232,10 +253,10 @@ fn consume_any_line_comment(rdr: string_reader)\n         }\n     } else if rdr.curr == '#' {\n         if nextch(rdr) == '!' {\n-            let cmap = codemap::new_codemap();\n+            let cmap = @CodeMap::new();\n             (*cmap).files.push(rdr.filemap);\n-            let loc = codemap::lookup_char_pos_adj(cmap, rdr.chpos);\n-            if loc.line == 1u && loc.col == 0u {\n+            let loc = cmap.lookup_char_pos_adj(rdr.last_pos);\n+            if loc.line == 1u && loc.col == CharPos(0u) {\n                 while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n                 return consume_whitespace_and_comments(rdr);\n             }\n@@ -250,7 +271,7 @@ fn consume_block_comment(rdr: string_reader)\n \n     // block comments starting with \"/**\" or \"/*!\" are doc-comments\n     if rdr.curr == '*' || rdr.curr == '!' {\n-        let start_chpos = rdr.chpos - 2u;\n+        let start_bpos = rdr.pos - BytePos(2u);\n         let mut acc = ~\"/*\";\n         while !(rdr.curr == '*' && nextch(rdr) == '/') && !is_eof(rdr) {\n             str::push_char(&mut acc, rdr.curr);\n@@ -264,7 +285,7 @@ fn consume_block_comment(rdr: string_reader)\n             bump(rdr);\n             return Some({\n                 tok: token::DOC_COMMENT(rdr.interner.intern(@acc)),\n-                sp: ast_util::mk_sp(start_chpos, rdr.chpos)\n+                sp: ast_util::mk_sp(start_bpos, rdr.pos)\n             });\n         }\n     } else {\n@@ -590,7 +611,7 @@ fn next_token_inner(rdr: string_reader) -> token::Token {\n         return token::LIT_INT(c2 as i64, ast::ty_char);\n       }\n       '\"' => {\n-        let n = rdr.chpos;\n+        let n = byte_offset(rdr);\n         bump(rdr);\n         while rdr.curr != '\"' {\n             if is_eof(rdr) {"}, {"sha": "2f96f6ba0a098f05585f6dfc06797f5bc634d0c3", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 13, "deletions": 14, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -5,7 +5,7 @@ use either::{Either, Left, Right};\n use std::map::HashMap;\n use token::{can_begin_expr, is_ident, is_ident_or_path, is_plain_ident,\n             INTERPOLATED, special_idents};\n-use codemap::{span,fss_none};\n+use codemap::{span,FssNone, BytePos};\n use util::interner::Interner;\n use ast_util::{spanned, respan, mk_sp, ident_to_path, operator_prec};\n use lexer::reader;\n@@ -244,7 +244,7 @@ impl Parser {\n         self.token = next.tok;\n         self.span = next.sp;\n     }\n-    fn swap(next: token::Token, lo: uint, hi: uint) {\n+    fn swap(next: token::Token, +lo: BytePos, +hi: BytePos) {\n         self.token = next;\n         self.span = mk_sp(lo, hi);\n     }\n@@ -906,12 +906,12 @@ impl Parser {\n         return spanned(lo, e.span.hi, {mutbl: m, ident: i, expr: e});\n     }\n \n-    fn mk_expr(lo: uint, hi: uint, +node: expr_) -> @expr {\n+    fn mk_expr(+lo: BytePos, +hi: BytePos, +node: expr_) -> @expr {\n         return @{id: self.get_id(), callee_id: self.get_id(),\n               node: node, span: mk_sp(lo, hi)};\n     }\n \n-    fn mk_mac_expr(lo: uint, hi: uint, m: mac_) -> @expr {\n+    fn mk_mac_expr(+lo: BytePos, +hi: BytePos, m: mac_) -> @expr {\n         return @{id: self.get_id(),\n               callee_id: self.get_id(),\n               node: expr_mac({node: m, span: mk_sp(lo, hi)}),\n@@ -1141,7 +1141,7 @@ impl Parser {\n         return self.mk_expr(lo, hi, ex);\n     }\n \n-    fn parse_block_expr(lo: uint, blk_mode: blk_check_mode) -> @expr {\n+    fn parse_block_expr(lo: BytePos, blk_mode: blk_check_mode) -> @expr {\n         self.expect(token::LBRACE);\n         let blk = self.parse_block_tail(lo, blk_mode);\n         return self.mk_expr(blk.span.lo, blk.span.hi, expr_block(blk));\n@@ -1153,7 +1153,7 @@ impl Parser {\n         return self.parse_syntax_ext_naked(lo);\n     }\n \n-    fn parse_syntax_ext_naked(lo: uint) -> @expr {\n+    fn parse_syntax_ext_naked(lo: BytePos) -> @expr {\n         match self.token {\n           token::IDENT(_, _) => (),\n           _ => self.fatal(~\"expected a syntax expander name\")\n@@ -2287,11 +2287,11 @@ impl Parser {\n     // I guess that also means \"already parsed the 'impure'\" if\n     // necessary, and this should take a qualifier.\n     // some blocks start with \"#{\"...\n-    fn parse_block_tail(lo: uint, s: blk_check_mode) -> blk {\n+    fn parse_block_tail(lo: BytePos, s: blk_check_mode) -> blk {\n         self.parse_block_tail_(lo, s, ~[])\n     }\n \n-    fn parse_block_tail_(lo: uint, s: blk_check_mode,\n+    fn parse_block_tail_(lo: BytePos, s: blk_check_mode,\n                          +first_item_attrs: ~[attribute]) -> blk {\n         let mut stmts = ~[];\n         let mut expr = None;\n@@ -2589,7 +2589,7 @@ impl Parser {\n         return {ident: id, tps: ty_params};\n     }\n \n-    fn mk_item(lo: uint, hi: uint, +ident: ident,\n+    fn mk_item(+lo: BytePos, +hi: BytePos, +ident: ident,\n                +node: item_, vis: visibility,\n                +attrs: ~[attribute]) -> @item {\n         return @{ident: ident,\n@@ -3041,7 +3041,7 @@ impl Parser {\n             items: items};\n     }\n \n-    fn parse_item_foreign_mod(lo: uint,\n+    fn parse_item_foreign_mod(lo: BytePos,\n                               visibility: visibility,\n                               attrs: ~[attribute],\n                               items_allowed: bool)\n@@ -3096,7 +3096,7 @@ impl Parser {\n         });\n     }\n \n-    fn parse_type_decl() -> {lo: uint, ident: ident} {\n+    fn parse_type_decl() -> {lo: BytePos, ident: ident} {\n         let lo = self.last_span.lo;\n         let id = self.parse_ident();\n         return {lo: lo, ident: id};\n@@ -3425,9 +3425,8 @@ impl Parser {\n             };\n             let m = ast::mac_invoc_tt(pth, tts);\n             let m: ast::mac = {node: m,\n-                               span: {lo: self.span.lo,\n-                                      hi: self.span.hi,\n-                                      expn_info: None}};\n+                               span: mk_sp(self.span.lo,\n+                                           self.span.hi)};\n             let item_ = item_mac(m);\n             return iovi_item(self.mk_item(lo, self.last_span.hi, id, item_,\n                                           visibility, attrs));"}, {"sha": "b4a5407c00249a79c7771ce15d2682d0811122a1", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -1,5 +1,5 @@\n use parse::{comments, lexer, token};\n-use codemap::CodeMap;\n+use codemap::{CodeMap, BytePos};\n use pp::{break_offset, word, printer, space, zerobreak, hardbreak, breaks};\n use pp::{consistent, inconsistent, eof};\n use ast::{required, provided};\n@@ -25,7 +25,7 @@ fn no_ann() -> pp_ann {\n \n type ps =\n     @{s: pp::printer,\n-      cm: Option<CodeMap>,\n+      cm: Option<@CodeMap>,\n       intr: @token::ident_interner,\n       comments: Option<~[comments::cmnt]>,\n       literals: Option<~[comments::lit]>,\n@@ -46,7 +46,7 @@ fn end(s: ps) {\n \n fn rust_printer(writer: io::Writer, intr: @ident_interner) -> ps {\n     return @{s: pp::mk_printer(writer, default_columns),\n-             cm: None::<CodeMap>,\n+             cm: None::<@CodeMap>,\n              intr: intr,\n              comments: None::<~[comments::cmnt]>,\n              literals: None::<~[comments::lit]>,\n@@ -64,7 +64,7 @@ const default_columns: uint = 78u;\n // Requires you to pass an input filename and reader so that\n // it can scan the input text for comments and literals to\n // copy forward.\n-fn print_crate(cm: CodeMap, intr: @ident_interner,\n+fn print_crate(cm: @CodeMap, intr: @ident_interner,\n                span_diagnostic: diagnostic::span_handler,\n                crate: @ast::crate, filename: ~str, in: io::Reader,\n                out: io::Writer, ann: pp_ann, is_expanded: bool) {\n@@ -628,7 +628,7 @@ fn print_variants(s: ps, variants: ~[ast::variant], span: ast::span) {\n         print_variant(s, *v);\n         word(s.s, ~\",\");\n         end(s);\n-        maybe_print_trailing_comment(s, v.span, None::<uint>);\n+        maybe_print_trailing_comment(s, v.span, None);\n     }\n     bclose(s, span);\n }\n@@ -883,7 +883,7 @@ fn print_stmt(s: ps, st: ast::stmt) {\n       }\n     }\n     if parse::classify::stmt_ends_with_semi(st) { word(s.s, ~\";\"); }\n-    maybe_print_trailing_comment(s, st.span, None::<uint>);\n+    maybe_print_trailing_comment(s, st.span, None);\n }\n \n fn print_block(s: ps, blk: ast::blk) {\n@@ -1895,15 +1895,15 @@ fn print_ty_fn(s: ps,\n }\n \n fn maybe_print_trailing_comment(s: ps, span: codemap::span,\n-                                next_pos: Option<uint>) {\n+                                next_pos: Option<BytePos>) {\n     let mut cm;\n     match s.cm { Some(ccm) => cm = ccm, _ => return }\n     match next_comment(s) {\n       Some(cmnt) => {\n         if cmnt.style != comments::trailing { return; }\n-        let span_line = codemap::lookup_char_pos(cm, span.hi);\n-        let comment_line = codemap::lookup_char_pos(cm, cmnt.pos);\n-        let mut next = cmnt.pos + 1u;\n+        let span_line = cm.lookup_char_pos(span.hi);\n+        let comment_line = cm.lookup_char_pos(cmnt.pos);\n+        let mut next = cmnt.pos + BytePos(1u);\n         match next_pos { None => (), Some(p) => next = p }\n         if span.hi < cmnt.pos && cmnt.pos < next &&\n                span_line.line == comment_line.line {\n@@ -1979,7 +1979,7 @@ fn lit_to_str(l: @ast::lit) -> ~str {\n     return to_str(l, print_literal, parse::token::mk_fake_ident_interner());\n }\n \n-fn next_lit(s: ps, pos: uint) -> Option<comments::lit> {\n+fn next_lit(s: ps, pos: BytePos) -> Option<comments::lit> {\n     match s.literals {\n       Some(lits) => {\n         while s.cur_lit < vec::len(lits) {\n@@ -1994,7 +1994,7 @@ fn next_lit(s: ps, pos: uint) -> Option<comments::lit> {\n     }\n }\n \n-fn maybe_print_comment(s: ps, pos: uint) {\n+fn maybe_print_comment(s: ps, pos: BytePos) {\n     loop {\n         match next_comment(s) {\n           Some(cmnt) => {"}, {"sha": "718c916df46c4a2eb1400f150bbf30f5a2260b40", "filename": "src/libsyntax/syntax.rc", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fsyntax.rc", "raw_url": "https://github.com/rust-lang/rust/raw/1a1e99c27d0d701f315926f400aa325ddfc8a9e7/src%2Flibsyntax%2Fsyntax.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsyntax.rc?ref=1a1e99c27d0d701f315926f400aa325ddfc8a9e7", "patch": "@@ -25,7 +25,6 @@ use core::*;\n mod attr;\n #[legacy_exports]\n mod diagnostic;\n-#[legacy_exports]\n mod codemap;\n #[legacy_exports]\n mod ast;"}]}