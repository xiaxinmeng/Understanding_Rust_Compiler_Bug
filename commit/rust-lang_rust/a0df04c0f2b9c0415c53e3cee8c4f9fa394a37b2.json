{"sha": "a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "node_id": "C_kwDOAAsO6NoAKGEwZGYwNGMwZjJiOWMwNDE1YzUzZTNjZWU4YzRmOWZhMzk0YTM3YjI", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2023-06-08T07:30:03Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2023-06-08T07:30:03Z"}, "message": "Auto merge of #110040 - ndrewxie:issue-84447-partial-1, r=lcnr,michaelwoerister\n\nRemoved use of iteration through a HashMap/HashSet in rustc_incremental and replaced with IndexMap/IndexSet\n\nThis allows for the `#[allow(rustc::potential_query_instability)]` in rustc_incremental to be removed, moving towards fixing #84447 (although a LOT more modules have to be changed to fully resolve it). Only HashMaps/HashSets that are being iterated through have been modified (although many structs and traits outside of rustc_incremental had to be modified as well, as they had fields/methods that involved a HashMap/HashSet that would be iterated through)\n\nI'm making a PR for just 1 module changed to test for performance regressions and such, for future changes I'll either edit this PR to reflect additional modules being converted, or batch multiple modules of changes together and make a PR for each group of modules.", "tree": {"sha": "0be6a55d83be0af20c6a73a5b7981cad8483d5f1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0be6a55d83be0af20c6a73a5b7981cad8483d5f1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "html_url": "https://github.com/rust-lang/rust/commit/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "80917360d350fb55aebf383e7ff99efea41f63fd", "url": "https://api.github.com/repos/rust-lang/rust/commits/80917360d350fb55aebf383e7ff99efea41f63fd", "html_url": "https://github.com/rust-lang/rust/commit/80917360d350fb55aebf383e7ff99efea41f63fd"}, {"sha": "3f324a8b7d62f44f97ba76eeb76b67d6ff0bf744", "url": "https://api.github.com/repos/rust-lang/rust/commits/3f324a8b7d62f44f97ba76eeb76b67d6ff0bf744", "html_url": "https://github.com/rust-lang/rust/commit/3f324a8b7d62f44f97ba76eeb76b67d6ff0bf744"}], "stats": {"total": 453, "additions": 261, "deletions": 192}, "files": [{"sha": "e1b9987f5781619a813c31e172b9f51238e58845", "filename": "compiler/rustc_abi/src/lib.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_abi%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_abi%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_abi%2Fsrc%2Flib.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -414,7 +414,9 @@ pub struct Size {\n // Safety: Ord is implement as just comparing numerical values and numerical values\n // are not changed by (de-)serialization.\n #[cfg(feature = \"nightly\")]\n-unsafe impl StableOrd for Size {}\n+unsafe impl StableOrd for Size {\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}\n \n // This is debug-printed a lot in larger structs, don't waste too much space there\n impl fmt::Debug for Size {"}, {"sha": "d143bcc96ef937f9ccad87daf131cb1d7a0ccce4", "filename": "compiler/rustc_codegen_cranelift/src/driver/aot.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_cranelift%2Fsrc%2Fdriver%2Faot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_cranelift%2Fsrc%2Fdriver%2Faot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_cranelift%2Fsrc%2Fdriver%2Faot.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -54,8 +54,8 @@ impl OngoingCodegen {\n         self,\n         sess: &Session,\n         backend_config: &BackendConfig,\n-    ) -> (CodegenResults, FxHashMap<WorkProductId, WorkProduct>) {\n-        let mut work_products = FxHashMap::default();\n+    ) -> (CodegenResults, FxIndexMap<WorkProductId, WorkProduct>) {\n+        let mut work_products = FxIndexMap::default();\n         let mut modules = vec![];\n \n         for module_codegen in self.modules {"}, {"sha": "095fbe62c1902b1e2a3ca041963a103033b3380c", "filename": "compiler/rustc_codegen_cranelift/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_cranelift%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_cranelift%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_cranelift%2Fsrc%2Flib.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -88,7 +88,7 @@ mod prelude {\n     };\n     pub(crate) use rustc_target::abi::{Abi, FieldIdx, Scalar, Size, VariantIdx, FIRST_VARIANT};\n \n-    pub(crate) use rustc_data_structures::fx::FxHashMap;\n+    pub(crate) use rustc_data_structures::fx::{FxHashMap, FxIndexMap};\n \n     pub(crate) use rustc_index::Idx;\n \n@@ -223,7 +223,7 @@ impl CodegenBackend for CraneliftCodegenBackend {\n         ongoing_codegen: Box<dyn Any>,\n         sess: &Session,\n         _outputs: &OutputFilenames,\n-    ) -> Result<(CodegenResults, FxHashMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n+    ) -> Result<(CodegenResults, FxIndexMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n         Ok(ongoing_codegen\n             .downcast::<driver::aot::OngoingCodegen>()\n             .unwrap()"}, {"sha": "ea013c4428cce63c1e6fa3631b44ef3d1e9d233e", "filename": "compiler/rustc_codegen_gcc/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_gcc%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_gcc%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_gcc%2Fsrc%2Flib.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -75,7 +75,7 @@ use rustc_codegen_ssa::back::write::{CodegenContext, FatLTOInput, ModuleConfig,\n use rustc_codegen_ssa::back::lto::{LtoModuleCodegen, SerializedModule, ThinModule};\n use rustc_codegen_ssa::target_features::supported_target_features;\n use rustc_codegen_ssa::traits::{CodegenBackend, ExtraBackendMethods, ModuleBufferMethods, ThinBufferMethods, WriteBackendMethods};\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::FxIndexMap;\n use rustc_errors::{DiagnosticMessage, ErrorGuaranteed, Handler, SubdiagnosticMessage};\n use rustc_fluent_macro::fluent_messages;\n use rustc_metadata::EncodedMetadata;\n@@ -137,7 +137,7 @@ impl CodegenBackend for GccCodegenBackend {\n         Box::new(res)\n     }\n \n-    fn join_codegen(&self, ongoing_codegen: Box<dyn Any>, sess: &Session, _outputs: &OutputFilenames) -> Result<(CodegenResults, FxHashMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n+    fn join_codegen(&self, ongoing_codegen: Box<dyn Any>, sess: &Session, _outputs: &OutputFilenames) -> Result<(CodegenResults, FxIndexMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n         let (codegen_results, work_products) = ongoing_codegen\n             .downcast::<rustc_codegen_ssa::back::write::OngoingCodegen<GccCodegenBackend>>()\n             .expect(\"Expected GccCodegenBackend's OngoingCodegen, found Box<Any>\")"}, {"sha": "24968e00cc8e5051a8e466d5296bac5bbcd5a4ea", "filename": "compiler/rustc_codegen_llvm/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_llvm%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_llvm%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_llvm%2Fsrc%2Flib.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -34,7 +34,7 @@ use rustc_codegen_ssa::back::write::{\n use rustc_codegen_ssa::traits::*;\n use rustc_codegen_ssa::ModuleCodegen;\n use rustc_codegen_ssa::{CodegenResults, CompiledModule};\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::FxIndexMap;\n use rustc_errors::{DiagnosticMessage, ErrorGuaranteed, FatalError, Handler, SubdiagnosticMessage};\n use rustc_fluent_macro::fluent_messages;\n use rustc_metadata::EncodedMetadata;\n@@ -356,7 +356,7 @@ impl CodegenBackend for LlvmCodegenBackend {\n         ongoing_codegen: Box<dyn Any>,\n         sess: &Session,\n         outputs: &OutputFilenames,\n-    ) -> Result<(CodegenResults, FxHashMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n+    ) -> Result<(CodegenResults, FxIndexMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n         let (codegen_results, work_products) = ongoing_codegen\n             .downcast::<rustc_codegen_ssa::back::write::OngoingCodegen<LlvmCodegenBackend>>()\n             .expect(\"Expected LlvmCodegenBackend's OngoingCodegen, found Box<Any>\")"}, {"sha": "701d0d73ad38c60f2288b05f3a5ccec4710a2c04", "filename": "compiler/rustc_codegen_ssa/src/back/write.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_ssa%2Fsrc%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_ssa%2Fsrc%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Fback%2Fwrite.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -9,7 +9,7 @@ use crate::{\n };\n use jobserver::{Acquired, Client};\n use rustc_ast::attr;\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::{FxHashMap, FxIndexMap};\n use rustc_data_structures::memmap::Mmap;\n use rustc_data_structures::profiling::SelfProfilerRef;\n use rustc_data_structures::profiling::TimingGuard;\n@@ -498,8 +498,8 @@ pub fn start_async_codegen<B: ExtraBackendMethods>(\n fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n     sess: &Session,\n     compiled_modules: &CompiledModules,\n-) -> FxHashMap<WorkProductId, WorkProduct> {\n-    let mut work_products = FxHashMap::default();\n+) -> FxIndexMap<WorkProductId, WorkProduct> {\n+    let mut work_products = FxIndexMap::default();\n \n     if sess.opts.incremental.is_none() {\n         return work_products;\n@@ -1885,7 +1885,7 @@ pub struct OngoingCodegen<B: ExtraBackendMethods> {\n }\n \n impl<B: ExtraBackendMethods> OngoingCodegen<B> {\n-    pub fn join(self, sess: &Session) -> (CodegenResults, FxHashMap<WorkProductId, WorkProduct>) {\n+    pub fn join(self, sess: &Session) -> (CodegenResults, FxIndexMap<WorkProductId, WorkProduct>) {\n         let _timer = sess.timer(\"finish_ongoing_codegen\");\n \n         self.shared_emitter_main.check(sess, true);"}, {"sha": "b3c9ecf8b938b71e19c6b573cf368a59ac6dd811", "filename": "compiler/rustc_codegen_ssa/src/traits/backend.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_ssa%2Fsrc%2Ftraits%2Fbackend.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_codegen_ssa%2Fsrc%2Ftraits%2Fbackend.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Ftraits%2Fbackend.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -6,7 +6,7 @@ use crate::back::write::TargetMachineFactoryFn;\n use crate::{CodegenResults, ModuleCodegen};\n \n use rustc_ast::expand::allocator::AllocatorKind;\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::FxIndexMap;\n use rustc_data_structures::sync::{DynSend, DynSync};\n use rustc_errors::ErrorGuaranteed;\n use rustc_metadata::EncodedMetadata;\n@@ -101,7 +101,7 @@ pub trait CodegenBackend {\n         ongoing_codegen: Box<dyn Any>,\n         sess: &Session,\n         outputs: &OutputFilenames,\n-    ) -> Result<(CodegenResults, FxHashMap<WorkProductId, WorkProduct>), ErrorGuaranteed>;\n+    ) -> Result<(CodegenResults, FxIndexMap<WorkProductId, WorkProduct>), ErrorGuaranteed>;\n \n     /// This is called on the returned `Box<dyn Any>` from `join_codegen`\n     ///"}, {"sha": "0c1fb7518fa3bb477bbd95dbc8dd22b7937986c9", "filename": "compiler/rustc_data_structures/src/stable_hasher.rs", "status": "modified", "additions": 45, "deletions": 5, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_data_structures%2Fsrc%2Fstable_hasher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_data_structures%2Fsrc%2Fstable_hasher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fstable_hasher.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -233,7 +233,17 @@ pub trait ToStableHashKey<HCX> {\n ///  - `DefIndex`, `CrateNum`, `LocalDefId`, because their concrete\n ///    values depend on state that might be different between\n ///    compilation sessions.\n-pub unsafe trait StableOrd: Ord {}\n+///\n+/// The associated constant `CAN_USE_UNSTABLE_SORT` denotes whether\n+/// unstable sorting can be used for this type. Set to true if and\n+/// only if `a == b` implies `a` and `b` are fully indistinguishable.\n+pub unsafe trait StableOrd: Ord {\n+    const CAN_USE_UNSTABLE_SORT: bool;\n+}\n+\n+unsafe impl<T: StableOrd> StableOrd for &T {\n+    const CAN_USE_UNSTABLE_SORT: bool = T::CAN_USE_UNSTABLE_SORT;\n+}\n \n /// Implement HashStable by just calling `Hash::hash()`. Also implement `StableOrd` for the type since\n /// that has the same requirements.\n@@ -253,7 +263,9 @@ macro_rules! impl_stable_traits_for_trivial_type {\n             }\n         }\n \n-        unsafe impl $crate::stable_hasher::StableOrd for $t {}\n+        unsafe impl $crate::stable_hasher::StableOrd for $t {\n+            const CAN_USE_UNSTABLE_SORT: bool = true;\n+        }\n     };\n }\n \n@@ -339,6 +351,10 @@ impl<T1: HashStable<CTX>, T2: HashStable<CTX>, CTX> HashStable<CTX> for (T1, T2)\n     }\n }\n \n+unsafe impl<T1: StableOrd, T2: StableOrd> StableOrd for (T1, T2) {\n+    const CAN_USE_UNSTABLE_SORT: bool = T1::CAN_USE_UNSTABLE_SORT && T2::CAN_USE_UNSTABLE_SORT;\n+}\n+\n impl<T1, T2, T3, CTX> HashStable<CTX> for (T1, T2, T3)\n where\n     T1: HashStable<CTX>,\n@@ -353,6 +369,11 @@ where\n     }\n }\n \n+unsafe impl<T1: StableOrd, T2: StableOrd, T3: StableOrd> StableOrd for (T1, T2, T3) {\n+    const CAN_USE_UNSTABLE_SORT: bool =\n+        T1::CAN_USE_UNSTABLE_SORT && T2::CAN_USE_UNSTABLE_SORT && T3::CAN_USE_UNSTABLE_SORT;\n+}\n+\n impl<T1, T2, T3, T4, CTX> HashStable<CTX> for (T1, T2, T3, T4)\n where\n     T1: HashStable<CTX>,\n@@ -369,6 +390,15 @@ where\n     }\n }\n \n+unsafe impl<T1: StableOrd, T2: StableOrd, T3: StableOrd, T4: StableOrd> StableOrd\n+    for (T1, T2, T3, T4)\n+{\n+    const CAN_USE_UNSTABLE_SORT: bool = T1::CAN_USE_UNSTABLE_SORT\n+        && T2::CAN_USE_UNSTABLE_SORT\n+        && T3::CAN_USE_UNSTABLE_SORT\n+        && T4::CAN_USE_UNSTABLE_SORT;\n+}\n+\n impl<T: HashStable<CTX>, CTX> HashStable<CTX> for [T] {\n     default fn hash_stable(&self, ctx: &mut CTX, hasher: &mut StableHasher) {\n         self.len().hash_stable(ctx, hasher);\n@@ -459,6 +489,10 @@ impl<CTX> HashStable<CTX> for str {\n     }\n }\n \n+unsafe impl StableOrd for &str {\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}\n+\n impl<CTX> HashStable<CTX> for String {\n     #[inline]\n     fn hash_stable(&self, hcx: &mut CTX, hasher: &mut StableHasher) {\n@@ -468,7 +502,9 @@ impl<CTX> HashStable<CTX> for String {\n \n // Safety: String comparison only depends on their contents and the\n // contents are not changed by (de-)serialization.\n-unsafe impl StableOrd for String {}\n+unsafe impl StableOrd for String {\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}\n \n impl<HCX> ToStableHashKey<HCX> for String {\n     type KeyType = String;\n@@ -494,7 +530,9 @@ impl<CTX> HashStable<CTX> for bool {\n }\n \n // Safety: sort order of bools is not changed by (de-)serialization.\n-unsafe impl StableOrd for bool {}\n+unsafe impl StableOrd for bool {\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}\n \n impl<T, CTX> HashStable<CTX> for Option<T>\n where\n@@ -512,7 +550,9 @@ where\n }\n \n // Safety: the Option wrapper does not add instability to comparison.\n-unsafe impl<T: StableOrd> StableOrd for Option<T> {}\n+unsafe impl<T: StableOrd> StableOrd for Option<T> {\n+    const CAN_USE_UNSTABLE_SORT: bool = T::CAN_USE_UNSTABLE_SORT;\n+}\n \n impl<T1, T2, CTX> HashStable<CTX> for Result<T1, T2>\n where"}, {"sha": "e18c7b415f6cf32be5ba35f71668a0e17859a4fd", "filename": "compiler/rustc_data_structures/src/unord.rs", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_data_structures%2Fsrc%2Funord.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_data_structures%2Fsrc%2Funord.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Funord.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -140,12 +140,12 @@ impl<T: Ord, I: Iterator<Item = T>> UnordItems<T, I> {\n     }\n \n     #[inline]\n-    pub fn into_sorted_stable_ord(self, use_stable_sort: bool) -> Vec<T>\n+    pub fn into_sorted_stable_ord(self) -> Vec<T>\n     where\n         T: Ord + StableOrd,\n     {\n         let mut items: Vec<T> = self.0.collect();\n-        if use_stable_sort {\n+        if !T::CAN_USE_UNSTABLE_SORT {\n             items.sort();\n         } else {\n             items.sort_unstable()\n@@ -161,6 +161,10 @@ impl<T: Ord, I: Iterator<Item = T>> UnordItems<T, I> {\n         items.sort_by_cached_key(|x| x.to_stable_hash_key(hcx));\n         items\n     }\n+\n+    pub fn collect<C: From<UnordItems<T, I>>>(self) -> C {\n+        self.into()\n+    }\n }\n \n /// This is a set collection type that tries very hard to not expose"}, {"sha": "34c615779366329bf09a81fe3830c4d2f5a5ebd5", "filename": "compiler/rustc_hir/src/hir_id.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_hir%2Fsrc%2Fhir_id.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_hir%2Fsrc%2Fhir_id.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_hir%2Fsrc%2Fhir_id.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -166,7 +166,9 @@ impl ItemLocalId {\n \n // Safety: Ord is implement as just comparing the ItemLocalId's numerical\n // values and these are not changed by (de-)serialization.\n-unsafe impl StableOrd for ItemLocalId {}\n+unsafe impl StableOrd for ItemLocalId {\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}\n \n /// The `HirId` corresponding to `CRATE_NODE_ID` and `CRATE_DEF_ID`.\n pub const CRATE_HIR_ID: HirId ="}, {"sha": "52a84b204d00bf6f6a0e3a3727da35673d3809a1", "filename": "compiler/rustc_incremental/src/assert_dep_graph.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fassert_dep_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fassert_dep_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fassert_dep_graph.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -35,7 +35,7 @@\n \n use crate::errors;\n use rustc_ast as ast;\n-use rustc_data_structures::fx::FxHashSet;\n+use rustc_data_structures::fx::FxIndexSet;\n use rustc_data_structures::graph::implementation::{Direction, NodeIndex, INCOMING, OUTGOING};\n use rustc_graphviz as dot;\n use rustc_hir as hir;\n@@ -258,7 +258,7 @@ fn dump_graph(query: &DepGraphQuery) {\n }\n \n #[allow(missing_docs)]\n-pub struct GraphvizDepGraph(FxHashSet<DepKind>, Vec<(DepKind, DepKind)>);\n+pub struct GraphvizDepGraph(FxIndexSet<DepKind>, Vec<(DepKind, DepKind)>);\n \n impl<'a> dot::GraphWalk<'a> for GraphvizDepGraph {\n     type Node = DepKind;\n@@ -303,7 +303,7 @@ impl<'a> dot::Labeller<'a> for GraphvizDepGraph {\n fn node_set<'q>(\n     query: &'q DepGraphQuery,\n     filter: &DepNodeFilter,\n-) -> Option<FxHashSet<&'q DepNode>> {\n+) -> Option<FxIndexSet<&'q DepNode>> {\n     debug!(\"node_set(filter={:?})\", filter);\n \n     if filter.accepts_all() {\n@@ -315,9 +315,9 @@ fn node_set<'q>(\n \n fn filter_nodes<'q>(\n     query: &'q DepGraphQuery,\n-    sources: &Option<FxHashSet<&'q DepNode>>,\n-    targets: &Option<FxHashSet<&'q DepNode>>,\n-) -> FxHashSet<DepKind> {\n+    sources: &Option<FxIndexSet<&'q DepNode>>,\n+    targets: &Option<FxIndexSet<&'q DepNode>>,\n+) -> FxIndexSet<DepKind> {\n     if let Some(sources) = sources {\n         if let Some(targets) = targets {\n             walk_between(query, sources, targets)\n@@ -333,10 +333,10 @@ fn filter_nodes<'q>(\n \n fn walk_nodes<'q>(\n     query: &'q DepGraphQuery,\n-    starts: &FxHashSet<&'q DepNode>,\n+    starts: &FxIndexSet<&'q DepNode>,\n     direction: Direction,\n-) -> FxHashSet<DepKind> {\n-    let mut set = FxHashSet::default();\n+) -> FxIndexSet<DepKind> {\n+    let mut set = FxIndexSet::default();\n     for &start in starts {\n         debug!(\"walk_nodes: start={:?} outgoing?={:?}\", start, direction == OUTGOING);\n         if set.insert(start.kind) {\n@@ -357,9 +357,9 @@ fn walk_nodes<'q>(\n \n fn walk_between<'q>(\n     query: &'q DepGraphQuery,\n-    sources: &FxHashSet<&'q DepNode>,\n-    targets: &FxHashSet<&'q DepNode>,\n-) -> FxHashSet<DepKind> {\n+    sources: &FxIndexSet<&'q DepNode>,\n+    targets: &FxIndexSet<&'q DepNode>,\n+) -> FxIndexSet<DepKind> {\n     // This is a bit tricky. We want to include a node only if it is:\n     // (a) reachable from a source and (b) will reach a target. And we\n     // have to be careful about cycles etc. Luckily efficiency is not\n@@ -426,8 +426,8 @@ fn walk_between<'q>(\n     }\n }\n \n-fn filter_edges(query: &DepGraphQuery, nodes: &FxHashSet<DepKind>) -> Vec<(DepKind, DepKind)> {\n-    let uniq: FxHashSet<_> = query\n+fn filter_edges(query: &DepGraphQuery, nodes: &FxIndexSet<DepKind>) -> Vec<(DepKind, DepKind)> {\n+    let uniq: FxIndexSet<_> = query\n         .edges()\n         .into_iter()\n         .map(|(s, t)| (s.kind, t.kind))"}, {"sha": "0111a6d302d4a679b803aba7addeff2de812ba1c", "filename": "compiler/rustc_incremental/src/assert_module_sources.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fassert_module_sources.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fassert_module_sources.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fassert_module_sources.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -24,7 +24,7 @@\n \n use crate::errors;\n use rustc_ast as ast;\n-use rustc_data_structures::fx::FxHashSet;\n+use rustc_data_structures::unord::UnordSet;\n use rustc_hir::def_id::LOCAL_CRATE;\n use rustc_middle::mir::mono::CodegenUnitNameBuilder;\n use rustc_middle::ty::TyCtxt;\n@@ -52,7 +52,7 @@ pub fn assert_module_sources(tcx: TyCtxt<'_>) {\n \n struct AssertModuleSource<'tcx> {\n     tcx: TyCtxt<'tcx>,\n-    available_cgus: FxHashSet<Symbol>,\n+    available_cgus: UnordSet<Symbol>,\n }\n \n impl<'tcx> AssertModuleSource<'tcx> {\n@@ -118,9 +118,8 @@ impl<'tcx> AssertModuleSource<'tcx> {\n         debug!(\"mapping '{}' to cgu name '{}'\", self.field(attr, sym::module), cgu_name);\n \n         if !self.available_cgus.contains(&cgu_name) {\n-            let mut cgu_names: Vec<&str> =\n-                self.available_cgus.iter().map(|cgu| cgu.as_str()).collect();\n-            cgu_names.sort();\n+            let cgu_names: Vec<&str> =\n+                self.available_cgus.items().map(|cgu| cgu.as_str()).into_sorted_stable_ord();\n             self.tcx.sess.emit_err(errors::NoModuleNamed {\n                 span: attr.span,\n                 user_path,"}, {"sha": "b9171fad55ba335aca180d9be2c62a1f5faa9753", "filename": "compiler/rustc_incremental/src/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Flib.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -4,7 +4,6 @@\n #![doc(html_root_url = \"https://doc.rust-lang.org/nightly/nightly-rustc/\")]\n #![feature(never_type)]\n #![recursion_limit = \"256\"]\n-#![allow(rustc::potential_query_instability)]\n #![deny(rustc::untranslatable_diagnostic)]\n #![deny(rustc::diagnostic_outside_of_impl)]\n "}, {"sha": "cbe77e7b16de8dfcfcfbb964b75a0690230fa23b", "filename": "compiler/rustc_incremental/src/persist/dirty_clean.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fdirty_clean.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fdirty_clean.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fdirty_clean.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -22,6 +22,7 @@\n use crate::errors;\n use rustc_ast::{self as ast, Attribute, NestedMetaItem};\n use rustc_data_structures::fx::FxHashSet;\n+use rustc_data_structures::unord::UnordSet;\n use rustc_hir::def_id::LocalDefId;\n use rustc_hir::intravisit;\n use rustc_hir::Node as HirNode;\n@@ -125,7 +126,7 @@ const LABELS_ADT: &[&[&str]] = &[BASE_HIR, BASE_STRUCT];\n //\n //     type_of for these.\n \n-type Labels = FxHashSet<String>;\n+type Labels = UnordSet<String>;\n \n /// Represents the requested configuration by rustc_clean/dirty\n struct Assertion {\n@@ -197,7 +198,7 @@ impl<'tcx> DirtyCleanVisitor<'tcx> {\n         let (name, mut auto) = self.auto_labels(item_id, attr);\n         let except = self.except(attr);\n         let loaded_from_disk = self.loaded_from_disk(attr);\n-        for e in except.iter() {\n+        for e in except.items().map(|x| x.as_str()).into_sorted_stable_ord() {\n             if !auto.remove(e) {\n                 self.tcx.sess.emit_fatal(errors::AssertionAuto { span: attr.span, name, e });\n             }\n@@ -376,15 +377,17 @@ impl<'tcx> DirtyCleanVisitor<'tcx> {\n                 continue;\n             };\n             self.checked_attrs.insert(attr.id);\n-            for label in assertion.clean {\n+            for label in assertion.clean.items().map(|x| x.as_str()).into_sorted_stable_ord() {\n                 let dep_node = DepNode::from_label_string(self.tcx, &label, def_path_hash).unwrap();\n                 self.assert_clean(item_span, dep_node);\n             }\n-            for label in assertion.dirty {\n+            for label in assertion.dirty.items().map(|x| x.as_str()).into_sorted_stable_ord() {\n                 let dep_node = DepNode::from_label_string(self.tcx, &label, def_path_hash).unwrap();\n                 self.assert_dirty(item_span, dep_node);\n             }\n-            for label in assertion.loaded_from_disk {\n+            for label in\n+                assertion.loaded_from_disk.items().map(|x| x.as_str()).into_sorted_stable_ord()\n+            {\n                 let dep_node = DepNode::from_label_string(self.tcx, &label, def_path_hash).unwrap();\n                 self.assert_loaded_from_disk(item_span, dep_node);\n             }"}, {"sha": "243057b99bca206627e4d0c85ce64a5ab230b173", "filename": "compiler/rustc_incremental/src/persist/fs.rs", "status": "modified", "additions": 107, "deletions": 101, "changes": 208, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffs.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -104,8 +104,9 @@\n //! implemented.\n \n use crate::errors;\n-use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+use rustc_data_structures::fx::{FxHashSet, FxIndexSet};\n use rustc_data_structures::svh::Svh;\n+use rustc_data_structures::unord::{UnordMap, UnordSet};\n use rustc_data_structures::{base_n, flock};\n use rustc_errors::ErrorGuaranteed;\n use rustc_fs_util::{link_or_copy, try_canonicalize, LinkOrCopy};\n@@ -635,8 +636,8 @@ pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n \n     // First do a pass over the crate directory, collecting lock files and\n     // session directories\n-    let mut session_directories = FxHashSet::default();\n-    let mut lock_files = FxHashSet::default();\n+    let mut session_directories = FxIndexSet::default();\n+    let mut lock_files = UnordSet::default();\n \n     for dir_entry in crate_directory.read_dir()? {\n         let Ok(dir_entry) = dir_entry else {\n@@ -657,10 +658,11 @@ pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n             // This is something we don't know, leave it alone\n         }\n     }\n+    session_directories.sort();\n \n     // Now map from lock files to session directories\n-    let lock_file_to_session_dir: FxHashMap<String, Option<String>> = lock_files\n-        .into_iter()\n+    let lock_file_to_session_dir: UnordMap<String, Option<String>> = lock_files\n+        .into_items()\n         .map(|lock_file_name| {\n             assert!(lock_file_name.ends_with(LOCK_FILE_EXT));\n             let dir_prefix_end = lock_file_name.len() - LOCK_FILE_EXT.len();\n@@ -670,11 +672,13 @@ pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n             };\n             (lock_file_name, session_dir.map(String::clone))\n         })\n-        .collect();\n+        .into();\n \n     // Delete all lock files, that don't have an associated directory. They must\n     // be some kind of leftover\n-    for (lock_file_name, directory_name) in &lock_file_to_session_dir {\n+    for (lock_file_name, directory_name) in\n+        lock_file_to_session_dir.items().into_sorted_stable_ord()\n+    {\n         if directory_name.is_none() {\n             let Ok(timestamp) = extract_timestamp_from_session_dir(lock_file_name) else {\n                 debug!(\n@@ -685,34 +689,34 @@ pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n                 continue;\n             };\n \n-            let lock_file_path = crate_directory.join(&**lock_file_name);\n+            let lock_file_path = crate_directory.join(&*lock_file_name);\n \n             if is_old_enough_to_be_collected(timestamp) {\n                 debug!(\n                     \"garbage_collect_session_directories() - deleting \\\n-                        garbage lock file: {}\",\n+                    garbage lock file: {}\",\n                     lock_file_path.display()\n                 );\n                 delete_session_dir_lock_file(sess, &lock_file_path);\n             } else {\n                 debug!(\n                     \"garbage_collect_session_directories() - lock file with \\\n-                        no session dir not old enough to be collected: {}\",\n+                    no session dir not old enough to be collected: {}\",\n                     lock_file_path.display()\n                 );\n             }\n         }\n     }\n \n     // Filter out `None` directories\n-    let lock_file_to_session_dir: FxHashMap<String, String> = lock_file_to_session_dir\n-        .into_iter()\n+    let lock_file_to_session_dir: UnordMap<String, String> = lock_file_to_session_dir\n+        .into_items()\n         .filter_map(|(lock_file_name, directory_name)| directory_name.map(|n| (lock_file_name, n)))\n-        .collect();\n+        .into();\n \n     // Delete all session directories that don't have a lock file.\n     for directory_name in session_directories {\n-        if !lock_file_to_session_dir.values().any(|dir| *dir == directory_name) {\n+        if !lock_file_to_session_dir.items().any(|(_, dir)| *dir == directory_name) {\n             let path = crate_directory.join(directory_name);\n             if let Err(err) = safe_remove_dir_all(&path) {\n                 sess.emit_warning(errors::InvalidGcFailed { path: &path, err });\n@@ -721,103 +725,103 @@ pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n     }\n \n     // Now garbage collect the valid session directories.\n-    let mut deletion_candidates = vec![];\n+    let deletion_candidates =\n+        lock_file_to_session_dir.items().filter_map(|(lock_file_name, directory_name)| {\n+            debug!(\"garbage_collect_session_directories() - inspecting: {}\", directory_name);\n \n-    for (lock_file_name, directory_name) in &lock_file_to_session_dir {\n-        debug!(\"garbage_collect_session_directories() - inspecting: {}\", directory_name);\n-\n-        let Ok(timestamp) = extract_timestamp_from_session_dir(directory_name) else {\n+            let Ok(timestamp) = extract_timestamp_from_session_dir(directory_name) else {\n             debug!(\n                 \"found session-dir with malformed timestamp: {}\",\n                 crate_directory.join(directory_name).display()\n             );\n             // Ignore it\n-            continue;\n+            return None;\n         };\n \n-        if is_finalized(directory_name) {\n-            let lock_file_path = crate_directory.join(lock_file_name);\n-            match flock::Lock::new(\n-                &lock_file_path,\n-                false, // don't wait\n-                false, // don't create the lock-file\n-                true,\n-            ) {\n-                // get an exclusive lock\n-                Ok(lock) => {\n-                    debug!(\n-                        \"garbage_collect_session_directories() - \\\n+            if is_finalized(directory_name) {\n+                let lock_file_path = crate_directory.join(lock_file_name);\n+                match flock::Lock::new(\n+                    &lock_file_path,\n+                    false, // don't wait\n+                    false, // don't create the lock-file\n+                    true,\n+                ) {\n+                    // get an exclusive lock\n+                    Ok(lock) => {\n+                        debug!(\n+                            \"garbage_collect_session_directories() - \\\n                             successfully acquired lock\"\n-                    );\n-                    debug!(\n-                        \"garbage_collect_session_directories() - adding \\\n+                        );\n+                        debug!(\n+                            \"garbage_collect_session_directories() - adding \\\n                             deletion candidate: {}\",\n-                        directory_name\n-                    );\n-\n-                    // Note that we are holding on to the lock\n-                    deletion_candidates.push((\n-                        timestamp,\n-                        crate_directory.join(directory_name),\n-                        Some(lock),\n-                    ));\n-                }\n-                Err(_) => {\n-                    debug!(\n-                        \"garbage_collect_session_directories() - \\\n+                            directory_name\n+                        );\n+\n+                        // Note that we are holding on to the lock\n+                        return Some((\n+                            (timestamp, crate_directory.join(directory_name)),\n+                            Some(lock),\n+                        ));\n+                    }\n+                    Err(_) => {\n+                        debug!(\n+                            \"garbage_collect_session_directories() - \\\n                             not collecting, still in use\"\n-                    );\n+                        );\n+                    }\n                 }\n-            }\n-        } else if is_old_enough_to_be_collected(timestamp) {\n-            // When cleaning out \"-working\" session directories, i.e.\n-            // session directories that might still be in use by another\n-            // compiler instance, we only look a directories that are\n-            // at least ten seconds old. This is supposed to reduce the\n-            // chance of deleting a directory in the time window where\n-            // the process has allocated the directory but has not yet\n-            // acquired the file-lock on it.\n-\n-            // Try to acquire the directory lock. If we can't, it\n-            // means that the owning process is still alive and we\n-            // leave this directory alone.\n-            let lock_file_path = crate_directory.join(lock_file_name);\n-            match flock::Lock::new(\n-                &lock_file_path,\n-                false, // don't wait\n-                false, // don't create the lock-file\n-                true,\n-            ) {\n-                // get an exclusive lock\n-                Ok(lock) => {\n-                    debug!(\n-                        \"garbage_collect_session_directories() - \\\n+            } else if is_old_enough_to_be_collected(timestamp) {\n+                // When cleaning out \"-working\" session directories, i.e.\n+                // session directories that might still be in use by another\n+                // compiler instance, we only look a directories that are\n+                // at least ten seconds old. This is supposed to reduce the\n+                // chance of deleting a directory in the time window where\n+                // the process has allocated the directory but has not yet\n+                // acquired the file-lock on it.\n+\n+                // Try to acquire the directory lock. If we can't, it\n+                // means that the owning process is still alive and we\n+                // leave this directory alone.\n+                let lock_file_path = crate_directory.join(lock_file_name);\n+                match flock::Lock::new(\n+                    &lock_file_path,\n+                    false, // don't wait\n+                    false, // don't create the lock-file\n+                    true,\n+                ) {\n+                    // get an exclusive lock\n+                    Ok(lock) => {\n+                        debug!(\n+                            \"garbage_collect_session_directories() - \\\n                             successfully acquired lock\"\n-                    );\n+                        );\n \n-                    delete_old(sess, &crate_directory.join(directory_name));\n+                        delete_old(sess, &crate_directory.join(directory_name));\n \n-                    // Let's make it explicit that the file lock is released at this point,\n-                    // or rather, that we held on to it until here\n-                    drop(lock);\n-                }\n-                Err(_) => {\n-                    debug!(\n-                        \"garbage_collect_session_directories() - \\\n+                        // Let's make it explicit that the file lock is released at this point,\n+                        // or rather, that we held on to it until here\n+                        drop(lock);\n+                    }\n+                    Err(_) => {\n+                        debug!(\n+                            \"garbage_collect_session_directories() - \\\n                             not collecting, still in use\"\n-                    );\n+                        );\n+                    }\n                 }\n-            }\n-        } else {\n-            debug!(\n-                \"garbage_collect_session_directories() - not finalized, not \\\n+            } else {\n+                debug!(\n+                    \"garbage_collect_session_directories() - not finalized, not \\\n                     old enough\"\n-            );\n-        }\n-    }\n+                );\n+            }\n+            None\n+        });\n+    let deletion_candidates = deletion_candidates.into();\n \n     // Delete all but the most recent of the candidates\n-    for (path, lock) in all_except_most_recent(deletion_candidates) {\n+    all_except_most_recent(deletion_candidates).into_items().all(|(path, lock)| {\n         debug!(\"garbage_collect_session_directories() - deleting `{}`\", path.display());\n \n         if let Err(err) = safe_remove_dir_all(&path) {\n@@ -829,7 +833,8 @@ pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n         // Let's make it explicit that the file lock is released at this point,\n         // or rather, that we held on to it until here\n         drop(lock);\n-    }\n+        true\n+    });\n \n     Ok(())\n }\n@@ -845,18 +850,19 @@ fn delete_old(sess: &Session, path: &Path) {\n }\n \n fn all_except_most_recent(\n-    deletion_candidates: Vec<(SystemTime, PathBuf, Option<flock::Lock>)>,\n-) -> FxHashMap<PathBuf, Option<flock::Lock>> {\n-    let most_recent = deletion_candidates.iter().map(|&(timestamp, ..)| timestamp).max();\n+    deletion_candidates: UnordMap<(SystemTime, PathBuf), Option<flock::Lock>>,\n+) -> UnordMap<PathBuf, Option<flock::Lock>> {\n+    let most_recent = deletion_candidates.items().map(|(&(timestamp, _), _)| timestamp).max();\n \n     if let Some(most_recent) = most_recent {\n-        deletion_candidates\n-            .into_iter()\n-            .filter(|&(timestamp, ..)| timestamp != most_recent)\n-            .map(|(_, path, lock)| (path, lock))\n-            .collect()\n+        UnordMap::from(\n+            deletion_candidates\n+                .into_items()\n+                .filter(|&((timestamp, _), _)| timestamp != most_recent)\n+                .map(|((_, path), lock)| (path, lock)),\n+        )\n     } else {\n-        FxHashMap::default()\n+        UnordMap::default()\n     }\n }\n "}, {"sha": "644b8187621c979afa9a4c21c69c3347a4ff95b2", "filename": "compiler/rustc_incremental/src/persist/fs/tests.rs", "status": "modified", "additions": 10, "deletions": 17, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffs%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffs%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Ffs%2Ftests.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -2,26 +2,19 @@ use super::*;\n \n #[test]\n fn test_all_except_most_recent() {\n+    let input: UnordMap<_, Option<flock::Lock>> = UnordMap::from_iter([\n+        ((UNIX_EPOCH + Duration::new(4, 0), PathBuf::from(\"4\")), None),\n+        ((UNIX_EPOCH + Duration::new(1, 0), PathBuf::from(\"1\")), None),\n+        ((UNIX_EPOCH + Duration::new(5, 0), PathBuf::from(\"5\")), None),\n+        ((UNIX_EPOCH + Duration::new(3, 0), PathBuf::from(\"3\")), None),\n+        ((UNIX_EPOCH + Duration::new(2, 0), PathBuf::from(\"2\")), None),\n+    ]);\n     assert_eq!(\n-        all_except_most_recent(vec![\n-            (UNIX_EPOCH + Duration::new(4, 0), PathBuf::from(\"4\"), None),\n-            (UNIX_EPOCH + Duration::new(1, 0), PathBuf::from(\"1\"), None),\n-            (UNIX_EPOCH + Duration::new(5, 0), PathBuf::from(\"5\"), None),\n-            (UNIX_EPOCH + Duration::new(3, 0), PathBuf::from(\"3\"), None),\n-            (UNIX_EPOCH + Duration::new(2, 0), PathBuf::from(\"2\"), None),\n-        ])\n-        .keys()\n-        .cloned()\n-        .collect::<FxHashSet<PathBuf>>(),\n-        [PathBuf::from(\"1\"), PathBuf::from(\"2\"), PathBuf::from(\"3\"), PathBuf::from(\"4\"),]\n-            .into_iter()\n-            .collect::<FxHashSet<PathBuf>>()\n+        all_except_most_recent(input).into_items().map(|(path, _)| path).into_sorted_stable_ord(),\n+        vec![PathBuf::from(\"1\"), PathBuf::from(\"2\"), PathBuf::from(\"3\"), PathBuf::from(\"4\")]\n     );\n \n-    assert_eq!(\n-        all_except_most_recent(vec![]).keys().cloned().collect::<FxHashSet<PathBuf>>(),\n-        FxHashSet::default()\n-    );\n+    assert!(all_except_most_recent(UnordMap::default()).is_empty());\n }\n \n #[test]"}, {"sha": "bb479b5bdccda51a91d145c1ca873b4613d8ff8b", "filename": "compiler/rustc_incremental/src/persist/load.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fload.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -1,8 +1,8 @@\n //! Code to save/load the dep-graph from files.\n \n use crate::errors;\n-use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::memmap::Mmap;\n+use rustc_data_structures::unord::UnordMap;\n use rustc_middle::dep_graph::{SerializedDepGraph, WorkProduct, WorkProductId};\n use rustc_middle::query::on_disk_cache::OnDiskCache;\n use rustc_serialize::opaque::MemDecoder;\n@@ -16,7 +16,7 @@ use super::file_format;\n use super::fs::*;\n use super::work_product;\n \n-type WorkProductMap = FxHashMap<WorkProductId, WorkProduct>;\n+type WorkProductMap = UnordMap<WorkProductId, WorkProduct>;\n \n #[derive(Debug)]\n /// Represents the result of an attempt to load incremental compilation data.\n@@ -147,7 +147,7 @@ pub fn load_dep_graph(sess: &Session) -> DepGraphFuture {\n     let report_incremental_info = sess.opts.unstable_opts.incremental_info;\n     let expected_hash = sess.opts.dep_tracking_hash(false);\n \n-    let mut prev_work_products = FxHashMap::default();\n+    let mut prev_work_products = UnordMap::default();\n \n     // If we are only building with -Zquery-dep-graph but without an actual\n     // incr. comp. session directory, we skip this. Otherwise we'd fail\n@@ -163,7 +163,7 @@ pub fn load_dep_graph(sess: &Session) -> DepGraphFuture {\n                 Decodable::decode(&mut work_product_decoder);\n \n             for swp in work_products {\n-                let all_files_exist = swp.work_product.saved_files.iter().all(|(_, path)| {\n+                let all_files_exist = swp.work_product.saved_files.items().all(|(_, path)| {\n                     let exists = in_incr_comp_dir_sess(sess, path).exists();\n                     if !exists && sess.opts.unstable_opts.incremental_info {\n                         eprintln!(\"incremental: could not find file for work product: {path}\",);"}, {"sha": "bfaa52f9c813416ad50a970a505a1ad6ea602863", "filename": "compiler/rustc_incremental/src/persist/save.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fsave.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -1,5 +1,5 @@\n use crate::errors;\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::FxIndexMap;\n use rustc_data_structures::sync::join;\n use rustc_middle::dep_graph::{DepGraph, SerializedDepGraph, WorkProduct, WorkProductId};\n use rustc_middle::ty::TyCtxt;\n@@ -79,7 +79,7 @@ pub fn save_dep_graph(tcx: TyCtxt<'_>) {\n pub fn save_work_product_index(\n     sess: &Session,\n     dep_graph: &DepGraph,\n-    new_work_products: FxHashMap<WorkProductId, WorkProduct>,\n+    new_work_products: FxIndexMap<WorkProductId, WorkProduct>,\n ) {\n     if sess.opts.incremental.is_none() {\n         return;\n@@ -105,21 +105,21 @@ pub fn save_work_product_index(\n         if !new_work_products.contains_key(id) {\n             work_product::delete_workproduct_files(sess, wp);\n             debug_assert!(\n-                !wp.saved_files.iter().all(|(_, path)| in_incr_comp_dir_sess(sess, path).exists())\n+                !wp.saved_files.items().all(|(_, path)| in_incr_comp_dir_sess(sess, path).exists())\n             );\n         }\n     }\n \n     // Check that we did not delete one of the current work-products:\n     debug_assert!({\n         new_work_products.iter().all(|(_, wp)| {\n-            wp.saved_files.iter().all(|(_, path)| in_incr_comp_dir_sess(sess, path).exists())\n+            wp.saved_files.items().all(|(_, path)| in_incr_comp_dir_sess(sess, path).exists())\n         })\n     });\n }\n \n fn encode_work_product_index(\n-    work_products: &FxHashMap<WorkProductId, WorkProduct>,\n+    work_products: &FxIndexMap<WorkProductId, WorkProduct>,\n     encoder: &mut FileEncoder,\n ) {\n     let serialized_products: Vec<_> = work_products\n@@ -146,7 +146,7 @@ fn encode_query_cache(tcx: TyCtxt<'_>, encoder: FileEncoder) -> FileEncodeResult\n pub fn build_dep_graph(\n     sess: &Session,\n     prev_graph: SerializedDepGraph,\n-    prev_work_products: FxHashMap<WorkProductId, WorkProduct>,\n+    prev_work_products: FxIndexMap<WorkProductId, WorkProduct>,\n ) -> Option<DepGraph> {\n     if sess.opts.incremental.is_none() {\n         // No incremental compilation."}, {"sha": "bce5ca1e16bd15491715586181a8a00c0bd35e62", "filename": "compiler/rustc_incremental/src/persist/work_product.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fwork_product.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fwork_product.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_incremental%2Fsrc%2Fpersist%2Fwork_product.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -4,7 +4,7 @@\n \n use crate::errors;\n use crate::persist::fs::*;\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::unord::UnordMap;\n use rustc_fs_util::link_or_copy;\n use rustc_middle::dep_graph::{WorkProduct, WorkProductId};\n use rustc_session::Session;\n@@ -20,7 +20,7 @@ pub fn copy_cgu_workproduct_to_incr_comp_cache_dir(\n     debug!(?cgu_name, ?files);\n     sess.opts.incremental.as_ref()?;\n \n-    let mut saved_files = FxHashMap::default();\n+    let mut saved_files = UnordMap::default();\n     for (ext, path) in files {\n         let file_name = format!(\"{cgu_name}.{ext}\");\n         let path_in_incr_dir = in_incr_comp_dir_sess(sess, &file_name);\n@@ -46,7 +46,7 @@ pub fn copy_cgu_workproduct_to_incr_comp_cache_dir(\n \n /// Removes files for a given work product.\n pub fn delete_workproduct_files(sess: &Session, work_product: &WorkProduct) {\n-    for (_, path) in &work_product.saved_files {\n+    for (_, path) in work_product.saved_files.items().into_sorted_stable_ord() {\n         let path = in_incr_comp_dir_sess(sess, path);\n         if let Err(err) = std_fs::remove_file(&path) {\n             sess.emit_warning(errors::DeleteWorkProduct { path: &path, err });"}, {"sha": "455a8129656d4a915d5da528997c2ace43d49bfb", "filename": "compiler/rustc_interface/src/queries.rs", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_interface%2Fsrc%2Fqueries.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_interface%2Fsrc%2Fqueries.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_interface%2Fsrc%2Fqueries.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -5,6 +5,7 @@ use crate::passes;\n use rustc_ast as ast;\n use rustc_codegen_ssa::traits::CodegenBackend;\n use rustc_codegen_ssa::CodegenResults;\n+use rustc_data_structures::fx::FxIndexMap;\n use rustc_data_structures::steal::Steal;\n use rustc_data_structures::svh::Svh;\n use rustc_data_structures::sync::{AppendOnlyIndexVec, Lrc, OnceCell, RwLock, WorkerLocal};\n@@ -193,9 +194,15 @@ impl<'tcx> Queries<'tcx> {\n             let future_opt = self.dep_graph_future()?.steal();\n             let dep_graph = future_opt\n                 .and_then(|future| {\n-                    let (prev_graph, prev_work_products) =\n+                    let (prev_graph, mut prev_work_products) =\n                         sess.time(\"blocked_on_dep_graph_loading\", || future.open().open(sess));\n-\n+                    // Convert from UnordMap to FxIndexMap by sorting\n+                    let prev_work_product_ids =\n+                        prev_work_products.items().map(|x| *x.0).into_sorted_stable_ord();\n+                    let prev_work_products = prev_work_product_ids\n+                        .into_iter()\n+                        .map(|x| (x, prev_work_products.remove(&x).unwrap()))\n+                        .collect::<FxIndexMap<_, _>>();\n                     rustc_incremental::build_dep_graph(sess, prev_graph, prev_work_products)\n                 })\n                 .unwrap_or_else(DepGraph::new_disabled);"}, {"sha": "39a4cb1b179b4a265fee2ab3eb72d1e2e37ac998", "filename": "compiler/rustc_query_system/src/dep_graph/dep_node.rs", "status": "modified", "additions": 12, "deletions": 1, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fdep_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fdep_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fdep_node.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -46,7 +46,7 @@ use super::{DepContext, DepKind, FingerprintStyle};\n use crate::ich::StableHashingContext;\n \n use rustc_data_structures::fingerprint::{Fingerprint, PackedFingerprint};\n-use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n+use rustc_data_structures::stable_hasher::{HashStable, StableHasher, StableOrd, ToStableHashKey};\n use rustc_hir::definitions::DefPathHash;\n use std::fmt;\n use std::hash::Hash;\n@@ -247,3 +247,14 @@ impl<HCX> HashStable<HCX> for WorkProductId {\n         self.hash.hash_stable(hcx, hasher)\n     }\n }\n+impl<HCX> ToStableHashKey<HCX> for WorkProductId {\n+    type KeyType = Fingerprint;\n+    #[inline]\n+    fn to_stable_hash_key(&self, _: &HCX) -> Self::KeyType {\n+        self.hash\n+    }\n+}\n+unsafe impl StableOrd for WorkProductId {\n+    // Fingerprint can use unstable (just a tuple of `u64`s), so WorkProductId can as well\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}"}, {"sha": "c9e80a6d9bc13d38a8ce0776c230d624bd5501f8", "filename": "compiler/rustc_query_system/src/dep_graph/graph.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -1,11 +1,12 @@\n use parking_lot::Mutex;\n use rustc_data_structures::fingerprint::Fingerprint;\n-use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+use rustc_data_structures::fx::{FxHashMap, FxHashSet, FxIndexMap};\n use rustc_data_structures::profiling::{EventId, QueryInvocationId, SelfProfilerRef};\n use rustc_data_structures::sharded::{self, Sharded};\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::steal::Steal;\n use rustc_data_structures::sync::{AtomicU32, AtomicU64, Lock, Lrc, Ordering};\n+use rustc_data_structures::unord::UnordMap;\n use rustc_index::IndexVec;\n use rustc_serialize::opaque::{FileEncodeResult, FileEncoder};\n use smallvec::{smallvec, SmallVec};\n@@ -93,7 +94,7 @@ pub struct DepGraphData<K: DepKind> {\n     /// things available to us. If we find that they are not dirty, we\n     /// load the path to the file storing those work-products here into\n     /// this map. We can later look for and extract that data.\n-    previous_work_products: FxHashMap<WorkProductId, WorkProduct>,\n+    previous_work_products: FxIndexMap<WorkProductId, WorkProduct>,\n \n     dep_node_debug: Lock<FxHashMap<DepNode<K>, String>>,\n \n@@ -116,7 +117,7 @@ impl<K: DepKind> DepGraph<K> {\n     pub fn new(\n         profiler: &SelfProfilerRef,\n         prev_graph: SerializedDepGraph<K>,\n-        prev_work_products: FxHashMap<WorkProductId, WorkProduct>,\n+        prev_work_products: FxIndexMap<WorkProductId, WorkProduct>,\n         encoder: FileEncoder,\n         record_graph: bool,\n         record_stats: bool,\n@@ -688,7 +689,7 @@ impl<K: DepKind> DepGraph<K> {\n \n     /// Access the map of work-products created during the cached run. Only\n     /// used during saving of the dep-graph.\n-    pub fn previous_work_products(&self) -> &FxHashMap<WorkProductId, WorkProduct> {\n+    pub fn previous_work_products(&self) -> &FxIndexMap<WorkProductId, WorkProduct> {\n         &self.data.as_ref().unwrap().previous_work_products\n     }\n \n@@ -1048,7 +1049,7 @@ pub struct WorkProduct {\n     ///\n     /// By convention, file extensions are currently used as identifiers, i.e. the key \"o\" maps to\n     /// the object file's path, and \"dwo\" to the dwarf object file's path.\n-    pub saved_files: FxHashMap<String, String>,\n+    pub saved_files: UnordMap<String, String>,\n }\n \n // Index type for `DepNodeData`'s edges."}, {"sha": "21491afa9423553c6ab876032302833c8427a0b3", "filename": "compiler/rustc_session/src/config.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_session%2Fsrc%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/compiler%2Frustc_session%2Fsrc%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_session%2Fsrc%2Fconfig.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -311,7 +311,9 @@ pub enum OutputType {\n }\n \n // Safety: Trivial C-Style enums have a stable sort order across compilation sessions.\n-unsafe impl StableOrd for OutputType {}\n+unsafe impl StableOrd for OutputType {\n+    const CAN_USE_UNSTABLE_SORT: bool = true;\n+}\n \n impl<HCX: HashStableContext> ToStableHashKey<HCX> for OutputType {\n     type KeyType = Self;"}, {"sha": "2a3d86988bb04ef5130df6b8312bb60b7a03bad6", "filename": "src/tools/clippy/clippy_lints/src/wildcard_imports.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/src%2Ftools%2Fclippy%2Fclippy_lints%2Fsrc%2Fwildcard_imports.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/src%2Ftools%2Fclippy%2Fclippy_lints%2Fsrc%2Fwildcard_imports.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fclippy%2Fclippy_lints%2Fsrc%2Fwildcard_imports.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -160,7 +160,7 @@ impl LateLintPass<'_> for WildcardImports {\n                     )\n                 };\n \n-                let mut imports = used_imports.items().map(ToString::to_string).into_sorted_stable_ord(false);\n+                let mut imports = used_imports.items().map(ToString::to_string).into_sorted_stable_ord();\n                 let imports_string = if imports.len() == 1 {\n                     imports.pop().unwrap()\n                 } else if braced_glob {"}, {"sha": "8a275751e38dee0f7dab88016d864d6ce2cb1237", "filename": "tests/run-make-fulldeps/hotplug_codegen_backend/the_backend.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/tests%2Frun-make-fulldeps%2Fhotplug_codegen_backend%2Fthe_backend.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2/tests%2Frun-make-fulldeps%2Fhotplug_codegen_backend%2Fthe_backend.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-make-fulldeps%2Fhotplug_codegen_backend%2Fthe_backend.rs?ref=a0df04c0f2b9c0415c53e3cee8c4f9fa394a37b2", "patch": "@@ -15,7 +15,7 @@ extern crate rustc_target;\n \n use rustc_codegen_ssa::traits::CodegenBackend;\n use rustc_codegen_ssa::{CodegenResults, CrateInfo};\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::FxIndexMap;\n use rustc_errors::ErrorGuaranteed;\n use rustc_metadata::EncodedMetadata;\n use rustc_middle::dep_graph::{WorkProduct, WorkProductId};\n@@ -49,11 +49,11 @@ impl CodegenBackend for TheBackend {\n         ongoing_codegen: Box<dyn Any>,\n         _sess: &Session,\n         _outputs: &OutputFilenames,\n-    ) -> Result<(CodegenResults, FxHashMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n+    ) -> Result<(CodegenResults, FxIndexMap<WorkProductId, WorkProduct>), ErrorGuaranteed> {\n         let codegen_results = ongoing_codegen\n             .downcast::<CodegenResults>()\n             .expect(\"in join_codegen: ongoing_codegen is not a CodegenResults\");\n-        Ok((*codegen_results, FxHashMap::default()))\n+        Ok((*codegen_results, FxIndexMap::default()))\n     }\n \n     fn link("}]}