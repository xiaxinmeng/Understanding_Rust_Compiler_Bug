{"sha": "4a95e9704de0eeaecba55df102c1129e79a3a929", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRhOTVlOTcwNGRlMGVlYWVjYmE1NWRmMTAyYzExMjllNzlhM2E5Mjk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-07-13T06:49:02Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-07-13T06:49:02Z"}, "message": "Auto merge of #61953 - Centril:shared-from-iter, r=RalfJung\n\nAdd `impl<T> FromIterator<T> for Arc/Rc<[T]>`\n\nAdd implementations of `FromIterator<T> for Arc/Rc<[T]>` with symmetrical logic.\n\nThis also takes advantage of specialization in the case of iterators with known length (`TrustedLen`) to elide the final allocation/copying from a `Vec<T>` into `Rc<[T]>` because we can allocate the space for the `Rc<[T]>` directly when the size is known. This is the primary motivation and why this is to be preferred over `iter.collect::<Vec<_>>().into(): Rc<[T]>`.\n\nMoreover, this PR does some refactoring in some places.\n\nr? @RalfJung for the code\ncc @alexcrichton from T-libs", "tree": {"sha": "363bc1700a2826f38735027195160fa84ecefc2c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/363bc1700a2826f38735027195160fa84ecefc2c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4a95e9704de0eeaecba55df102c1129e79a3a929", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4a95e9704de0eeaecba55df102c1129e79a3a929", "html_url": "https://github.com/rust-lang/rust/commit/4a95e9704de0eeaecba55df102c1129e79a3a929", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4a95e9704de0eeaecba55df102c1129e79a3a929/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a9c7febb879689a3d24e3ba34531026930313c4c", "url": "https://api.github.com/repos/rust-lang/rust/commits/a9c7febb879689a3d24e3ba34531026930313c4c", "html_url": "https://github.com/rust-lang/rust/commit/a9c7febb879689a3d24e3ba34531026930313c4c"}, {"sha": "85def307fc83f8c0d164b1506bb855dfaed5f8b5", "url": "https://api.github.com/repos/rust-lang/rust/commits/85def307fc83f8c0d164b1506bb855dfaed5f8b5", "html_url": "https://github.com/rust-lang/rust/commit/85def307fc83f8c0d164b1506bb855dfaed5f8b5"}], "stats": {"total": 792, "additions": 652, "deletions": 140}, "files": [{"sha": "2e48825e81c291ccbecb09fec21c0bdfc44033b8", "filename": "src/liballoc/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Flib.rs?ref=4a95e9704de0eeaecba55df102c1129e79a3a929", "patch": "@@ -93,6 +93,7 @@\n #![feature(ptr_offset_from)]\n #![feature(rustc_attrs)]\n #![feature(receiver_trait)]\n+#![feature(slice_from_raw_parts)]\n #![feature(specialization)]\n #![feature(staged_api)]\n #![feature(std_internals)]"}, {"sha": "36d5465679581bff307c70718d681a3d62c2ad86", "filename": "src/liballoc/rc.rs", "status": "modified", "additions": 213, "deletions": 74, "changes": 287, "blob_url": "https://github.com/rust-lang/rust/blob/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Frc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Frc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Frc.rs?ref=4a95e9704de0eeaecba55df102c1129e79a3a929", "patch": "@@ -238,12 +238,13 @@ use core::cmp::Ordering;\n use core::fmt;\n use core::hash::{Hash, Hasher};\n use core::intrinsics::abort;\n+use core::iter;\n use core::marker::{self, Unpin, Unsize, PhantomData};\n use core::mem::{self, align_of, align_of_val, forget, size_of_val};\n use core::ops::{Deref, Receiver, CoerceUnsized, DispatchFromDyn};\n use core::pin::Pin;\n use core::ptr::{self, NonNull};\n-use core::slice::from_raw_parts_mut;\n+use core::slice::{self, from_raw_parts_mut};\n use core::convert::From;\n use core::usize;\n \n@@ -286,6 +287,19 @@ impl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<Rc<U>> for Rc<T> {}\n #[unstable(feature = \"dispatch_from_dyn\", issue = \"0\")]\n impl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Rc<U>> for Rc<T> {}\n \n+impl<T: ?Sized> Rc<T> {\n+    fn from_inner(ptr: NonNull<RcBox<T>>) -> Self {\n+        Self {\n+            ptr,\n+            phantom: PhantomData,\n+        }\n+    }\n+\n+    unsafe fn from_ptr(ptr: *mut RcBox<T>) -> Self {\n+        Self::from_inner(NonNull::new_unchecked(ptr))\n+    }\n+}\n+\n impl<T> Rc<T> {\n     /// Constructs a new `Rc<T>`.\n     ///\n@@ -298,18 +312,15 @@ impl<T> Rc<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn new(value: T) -> Rc<T> {\n-        Rc {\n-            // there is an implicit weak pointer owned by all the strong\n-            // pointers, which ensures that the weak destructor never frees\n-            // the allocation while the strong destructor is running, even\n-            // if the weak pointer is stored inside the strong one.\n-            ptr: Box::into_raw_non_null(box RcBox {\n-                strong: Cell::new(1),\n-                weak: Cell::new(1),\n-                value,\n-            }),\n-            phantom: PhantomData,\n-        }\n+        // There is an implicit weak pointer owned by all the strong\n+        // pointers, which ensures that the weak destructor never frees\n+        // the allocation while the strong destructor is running, even\n+        // if the weak pointer is stored inside the strong one.\n+        Self::from_inner(Box::into_raw_non_null(box RcBox {\n+            strong: Cell::new(1),\n+            weak: Cell::new(1),\n+            value,\n+        }))\n     }\n \n     /// Constructs a new `Pin<Rc<T>>`. If `T` does not implement `Unpin`, then\n@@ -422,10 +433,7 @@ impl<T: ?Sized> Rc<T> {\n         let fake_ptr = ptr as *mut RcBox<T>;\n         let rc_ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n \n-        Rc {\n-            ptr: NonNull::new_unchecked(rc_ptr),\n-            phantom: PhantomData,\n-        }\n+        Self::from_ptr(rc_ptr)\n     }\n \n     /// Consumes the `Rc`, returning the wrapped pointer as `NonNull<T>`.\n@@ -683,29 +691,37 @@ impl Rc<dyn Any> {\n         if (*self).is::<T>() {\n             let ptr = self.ptr.cast::<RcBox<T>>();\n             forget(self);\n-            Ok(Rc { ptr, phantom: PhantomData })\n+            Ok(Rc::from_inner(ptr))\n         } else {\n             Err(self)\n         }\n     }\n }\n \n impl<T: ?Sized> Rc<T> {\n-    // Allocates an `RcBox<T>` with sufficient space for an unsized value\n-    unsafe fn allocate_for_ptr(ptr: *const T) -> *mut RcBox<T> {\n-        // Calculate layout using the given value.\n+    /// Allocates an `RcBox<T>` with sufficient space for\n+    /// an unsized value where the value has the layout provided.\n+    ///\n+    /// The function `mem_to_rcbox` is called with the data pointer\n+    /// and must return back a (potentially fat)-pointer for the `RcBox<T>`.\n+    unsafe fn allocate_for_unsized(\n+        value_layout: Layout,\n+        mem_to_rcbox: impl FnOnce(*mut u8) -> *mut RcBox<T>\n+    ) -> *mut RcBox<T> {\n+        // Calculate layout using the given value layout.\n         // Previously, layout was calculated on the expression\n         // `&*(ptr as *const RcBox<T>)`, but this created a misaligned\n         // reference (see #54908).\n         let layout = Layout::new::<RcBox<()>>()\n-            .extend(Layout::for_value(&*ptr)).unwrap().0\n+            .extend(value_layout).unwrap().0\n             .pad_to_align().unwrap();\n \n+        // Allocate for the layout.\n         let mem = Global.alloc(layout)\n             .unwrap_or_else(|_| handle_alloc_error(layout));\n \n         // Initialize the RcBox\n-        let inner = set_data_ptr(ptr as *mut T, mem.as_ptr() as *mut u8) as *mut RcBox<T>;\n+        let inner = mem_to_rcbox(mem.as_ptr());\n         debug_assert_eq!(Layout::for_value(&*inner), layout);\n \n         ptr::write(&mut (*inner).strong, Cell::new(1));\n@@ -714,6 +730,15 @@ impl<T: ?Sized> Rc<T> {\n         inner\n     }\n \n+    /// Allocates an `RcBox<T>` with sufficient space for an unsized value\n+    unsafe fn allocate_for_ptr(ptr: *const T) -> *mut RcBox<T> {\n+        // Allocate for the `RcBox<T>` using the given value.\n+        Self::allocate_for_unsized(\n+            Layout::for_value(&*ptr),\n+            |mem| set_data_ptr(ptr as *mut T, mem) as *mut RcBox<T>,\n+        )\n+    }\n+\n     fn from_box(v: Box<T>) -> Rc<T> {\n         unsafe {\n             let box_unique = Box::into_unique(v);\n@@ -731,44 +756,49 @@ impl<T: ?Sized> Rc<T> {\n             // Free the allocation without dropping its contents\n             box_free(box_unique);\n \n-            Rc { ptr: NonNull::new_unchecked(ptr), phantom: PhantomData }\n+            Self::from_ptr(ptr)\n         }\n     }\n }\n \n-// Sets the data pointer of a `?Sized` raw pointer.\n-//\n-// For a slice/trait object, this sets the `data` field and leaves the rest\n-// unchanged. For a sized raw pointer, this simply sets the pointer.\n+impl<T> Rc<[T]> {\n+    /// Allocates an `RcBox<[T]>` with the given length.\n+    unsafe fn allocate_for_slice(len: usize) -> *mut RcBox<[T]> {\n+        Self::allocate_for_unsized(\n+            Layout::array::<T>(len).unwrap(),\n+            |mem| ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut RcBox<[T]>,\n+        )\n+    }\n+}\n+\n+/// Sets the data pointer of a `?Sized` raw pointer.\n+///\n+/// For a slice/trait object, this sets the `data` field and leaves the rest\n+/// unchanged. For a sized raw pointer, this simply sets the pointer.\n unsafe fn set_data_ptr<T: ?Sized, U>(mut ptr: *mut T, data: *mut U) -> *mut T {\n     ptr::write(&mut ptr as *mut _ as *mut *mut u8, data as *mut u8);\n     ptr\n }\n \n impl<T> Rc<[T]> {\n-    // Copy elements from slice into newly allocated Rc<[T]>\n-    //\n-    // Unsafe because the caller must either take ownership or bind `T: Copy`\n+    /// Copy elements from slice into newly allocated Rc<[T]>\n+    ///\n+    /// Unsafe because the caller must either take ownership or bind `T: Copy`\n     unsafe fn copy_from_slice(v: &[T]) -> Rc<[T]> {\n-        let v_ptr = v as *const [T];\n-        let ptr = Self::allocate_for_ptr(v_ptr);\n+        let ptr = Self::allocate_for_slice(v.len());\n \n         ptr::copy_nonoverlapping(\n             v.as_ptr(),\n             &mut (*ptr).value as *mut [T] as *mut T,\n             v.len());\n \n-        Rc { ptr: NonNull::new_unchecked(ptr), phantom: PhantomData }\n+        Self::from_ptr(ptr)\n     }\n-}\n \n-trait RcFromSlice<T> {\n-    fn from_slice(slice: &[T]) -> Self;\n-}\n-\n-impl<T: Clone> RcFromSlice<T> for Rc<[T]> {\n-    #[inline]\n-    default fn from_slice(v: &[T]) -> Self {\n+    /// Constructs an `Rc<[T]>` from an iterator known to be of a certain size.\n+    ///\n+    /// Behavior is undefined should the size be wrong.\n+    unsafe fn from_iter_exact(iter: impl iter::Iterator<Item = T>, len: usize) -> Rc<[T]> {\n         // Panic guard while cloning T elements.\n         // In the event of a panic, elements that have been written\n         // into the new RcBox will be dropped, then the memory freed.\n@@ -790,32 +820,43 @@ impl<T: Clone> RcFromSlice<T> for Rc<[T]> {\n             }\n         }\n \n-        unsafe {\n-            let v_ptr = v as *const [T];\n-            let ptr = Self::allocate_for_ptr(v_ptr);\n+        let ptr = Self::allocate_for_slice(len);\n \n-            let mem = ptr as *mut _ as *mut u8;\n-            let layout = Layout::for_value(&*ptr);\n+        let mem = ptr as *mut _ as *mut u8;\n+        let layout = Layout::for_value(&*ptr);\n \n-            // Pointer to first element\n-            let elems = &mut (*ptr).value as *mut [T] as *mut T;\n+        // Pointer to first element\n+        let elems = &mut (*ptr).value as *mut [T] as *mut T;\n \n-            let mut guard = Guard{\n-                mem: NonNull::new_unchecked(mem),\n-                elems: elems,\n-                layout: layout,\n-                n_elems: 0,\n-            };\n+        let mut guard = Guard {\n+            mem: NonNull::new_unchecked(mem),\n+            elems,\n+            layout,\n+            n_elems: 0,\n+        };\n \n-            for (i, item) in v.iter().enumerate() {\n-                ptr::write(elems.add(i), item.clone());\n-                guard.n_elems += 1;\n-            }\n+        for (i, item) in iter.enumerate() {\n+            ptr::write(elems.add(i), item);\n+            guard.n_elems += 1;\n+        }\n+\n+        // All clear. Forget the guard so it doesn't free the new RcBox.\n+        forget(guard);\n+\n+        Self::from_ptr(ptr)\n+    }\n+}\n \n-            // All clear. Forget the guard so it doesn't free the new RcBox.\n-            forget(guard);\n+/// Specialization trait used for `From<&[T]>`.\n+trait RcFromSlice<T> {\n+    fn from_slice(slice: &[T]) -> Self;\n+}\n \n-            Rc { ptr: NonNull::new_unchecked(ptr), phantom: PhantomData }\n+impl<T: Clone> RcFromSlice<T> for Rc<[T]> {\n+    #[inline]\n+    default fn from_slice(v: &[T]) -> Self {\n+        unsafe {\n+            Self::from_iter_exact(v.iter().cloned(), v.len())\n         }\n     }\n }\n@@ -907,7 +948,7 @@ impl<T: ?Sized> Clone for Rc<T> {\n     #[inline]\n     fn clone(&self) -> Rc<T> {\n         self.inc_strong();\n-        Rc { ptr: self.ptr, phantom: PhantomData }\n+        Self::from_inner(self.ptr)\n     }\n }\n \n@@ -1213,6 +1254,98 @@ impl<T> From<Vec<T>> for Rc<[T]> {\n     }\n }\n \n+#[stable(feature = \"shared_from_iter\", since = \"1.37.0\")]\n+impl<T> iter::FromIterator<T> for Rc<[T]> {\n+    /// Takes each element in the `Iterator` and collects it into an `Rc<[T]>`.\n+    ///\n+    /// # Performance characteristics\n+    ///\n+    /// ## The general case\n+    ///\n+    /// In the general case, collecting into `Rc<[T]>` is done by first\n+    /// collecting into a `Vec<T>`. That is, when writing the following:\n+    ///\n+    /// ```rust\n+    /// # use std::rc::Rc;\n+    /// let evens: Rc<[u8]> = (0..10).filter(|&x| x % 2 == 0).collect();\n+    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n+    /// ```\n+    ///\n+    /// this behaves as if we wrote:\n+    ///\n+    /// ```rust\n+    /// # use std::rc::Rc;\n+    /// let evens: Rc<[u8]> = (0..10).filter(|&x| x % 2 == 0)\n+    ///     .collect::<Vec<_>>() // The first set of allocations happens here.\n+    ///     .into(); // A second allocation for `Rc<[T]>` happens here.\n+    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n+    /// ```\n+    ///\n+    /// This will allocate as many times as needed for constructing the `Vec<T>`\n+    /// and then it will allocate once for turning the `Vec<T>` into the `Rc<[T]>`.\n+    ///\n+    /// ## Iterators of known length\n+    ///\n+    /// When your `Iterator` implements `TrustedLen` and is of an exact size,\n+    /// a single allocation will be made for the `Rc<[T]>`. For example:\n+    ///\n+    /// ```rust\n+    /// # use std::rc::Rc;\n+    /// let evens: Rc<[u8]> = (0..10).collect(); // Just a single allocation happens here.\n+    /// # assert_eq!(&*evens, &*(0..10).collect::<Vec<_>>());\n+    /// ```\n+    fn from_iter<I: iter::IntoIterator<Item = T>>(iter: I) -> Self {\n+        RcFromIter::from_iter(iter.into_iter())\n+    }\n+}\n+\n+/// Specialization trait used for collecting into `Rc<[T]>`.\n+trait RcFromIter<T, I> {\n+    fn from_iter(iter: I) -> Self;\n+}\n+\n+impl<T, I: Iterator<Item = T>> RcFromIter<T, I> for Rc<[T]> {\n+    default fn from_iter(iter: I) -> Self {\n+        iter.collect::<Vec<T>>().into()\n+    }\n+}\n+\n+impl<T, I: iter::TrustedLen<Item = T>> RcFromIter<T, I> for Rc<[T]>  {\n+    default fn from_iter(iter: I) -> Self {\n+        // This is the case for a `TrustedLen` iterator.\n+        let (low, high) = iter.size_hint();\n+        if let Some(high) = high {\n+            debug_assert_eq!(\n+                low, high,\n+                \"TrustedLen iterator's size hint is not exact: {:?}\",\n+                (low, high)\n+            );\n+\n+            unsafe {\n+                // SAFETY: We need to ensure that the iterator has an exact length and we have.\n+                Rc::from_iter_exact(iter, low)\n+            }\n+        } else {\n+            // Fall back to normal implementation.\n+            iter.collect::<Vec<T>>().into()\n+        }\n+    }\n+}\n+\n+impl<'a, T: 'a + Clone> RcFromIter<&'a T, slice::Iter<'a, T>> for Rc<[T]> {\n+    fn from_iter(iter: slice::Iter<'a, T>) -> Self {\n+        // Delegate to `impl<T: Clone> From<&[T]> for Rc<[T]>`.\n+        //\n+        // In the case that `T: Copy`, we get to use `ptr::copy_nonoverlapping`\n+        // which is even more performant.\n+        //\n+        // In the fall-back case we have `T: Clone`. This is still better\n+        // than the `TrustedLen` implementation as slices have a known length\n+        // and so we get to avoid calling `size_hint` and avoid the branching.\n+        iter.as_slice().into()\n+    }\n+}\n+\n /// `Weak` is a version of [`Rc`] that holds a non-owning reference to the\n /// managed value. The value is accessed by calling [`upgrade`] on the `Weak`\n /// pointer, which returns an [`Option`]`<`[`Rc`]`<T>>`.\n@@ -1456,7 +1589,7 @@ impl<T: ?Sized> Weak<T> {\n             None\n         } else {\n             inner.inc_strong();\n-            Some(Rc { ptr: self.ptr, phantom: PhantomData })\n+            Some(Rc::from_inner(self.ptr))\n         }\n     }\n \n@@ -1660,14 +1793,16 @@ trait RcBoxPtr<T: ?Sized> {\n \n     #[inline]\n     fn inc_strong(&self) {\n+        let strong = self.strong();\n+\n         // We want to abort on overflow instead of dropping the value.\n         // The reference count will never be zero when this is called;\n         // nevertheless, we insert an abort here to hint LLVM at\n         // an otherwise missed optimization.\n-        if self.strong() == 0 || self.strong() == usize::max_value() {\n+        if strong == 0 || strong == usize::max_value() {\n             unsafe { abort(); }\n         }\n-        self.inner().strong.set(self.strong() + 1);\n+        self.inner().strong.set(strong + 1);\n     }\n \n     #[inline]\n@@ -1682,14 +1817,16 @@ trait RcBoxPtr<T: ?Sized> {\n \n     #[inline]\n     fn inc_weak(&self) {\n+        let weak = self.weak();\n+\n         // We want to abort on overflow instead of dropping the value.\n         // The reference count will never be zero when this is called;\n         // nevertheless, we insert an abort here to hint LLVM at\n         // an otherwise missed optimization.\n-        if self.weak() == 0 || self.weak() == usize::max_value() {\n+        if weak == 0 || weak == usize::max_value() {\n             unsafe { abort(); }\n         }\n-        self.inner().weak.set(self.weak() + 1);\n+        self.inner().weak.set(weak + 1);\n     }\n \n     #[inline]\n@@ -2162,18 +2299,20 @@ impl<T: ?Sized> AsRef<T> for Rc<T> {\n impl<T: ?Sized> Unpin for Rc<T> { }\n \n unsafe fn data_offset<T: ?Sized>(ptr: *const T) -> isize {\n-    // Align the unsized value to the end of the RcBox.\n+    // Align the unsized value to the end of the `RcBox`.\n     // Because it is ?Sized, it will always be the last field in memory.\n-    let align = align_of_val(&*ptr);\n-    let layout = Layout::new::<RcBox<()>>();\n-    (layout.size() + layout.padding_needed_for(align)) as isize\n+    data_offset_align(align_of_val(&*ptr))\n }\n \n-/// Computes the offset of the data field within ArcInner.\n+/// Computes the offset of the data field within `RcBox`.\n ///\n /// Unlike [`data_offset`], this doesn't need the pointer, but it works only on `T: Sized`.\n fn data_offset_sized<T>() -> isize {\n-    let align = align_of::<T>();\n+    data_offset_align(align_of::<T>())\n+}\n+\n+#[inline]\n+fn data_offset_align(align: usize) -> isize {\n     let layout = Layout::new::<RcBox<()>>();\n     (layout.size() + layout.padding_needed_for(align)) as isize\n }"}, {"sha": "7cb826ee0242ff6b78126861720bfb5a88456c69", "filename": "src/liballoc/sync.rs", "status": "modified", "additions": 198, "deletions": 66, "changes": 264, "blob_url": "https://github.com/rust-lang/rust/blob/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fsync.rs?ref=4a95e9704de0eeaecba55df102c1129e79a3a929", "patch": "@@ -12,6 +12,7 @@ use core::sync::atomic::Ordering::{Acquire, Relaxed, Release, SeqCst};\n use core::borrow;\n use core::fmt;\n use core::cmp::{self, Ordering};\n+use core::iter;\n use core::intrinsics::abort;\n use core::mem::{self, align_of, align_of_val, size_of_val};\n use core::ops::{Deref, Receiver, CoerceUnsized, DispatchFromDyn};\n@@ -21,7 +22,7 @@ use core::marker::{Unpin, Unsize, PhantomData};\n use core::hash::{Hash, Hasher};\n use core::{isize, usize};\n use core::convert::From;\n-use core::slice::from_raw_parts_mut;\n+use core::slice::{self, from_raw_parts_mut};\n \n use crate::alloc::{Global, Alloc, Layout, box_free, handle_alloc_error};\n use crate::boxed::Box;\n@@ -206,6 +207,19 @@ impl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<Arc<U>> for Arc<T> {}\n #[unstable(feature = \"dispatch_from_dyn\", issue = \"0\")]\n impl<T: ?Sized + Unsize<U>, U: ?Sized> DispatchFromDyn<Arc<U>> for Arc<T> {}\n \n+impl<T: ?Sized> Arc<T> {\n+    fn from_inner(ptr: NonNull<ArcInner<T>>) -> Self {\n+        Self {\n+            ptr,\n+            phantom: PhantomData,\n+        }\n+    }\n+\n+    unsafe fn from_ptr(ptr: *mut ArcInner<T>) -> Self {\n+        Self::from_inner(NonNull::new_unchecked(ptr))\n+    }\n+}\n+\n /// `Weak` is a version of [`Arc`] that holds a non-owning reference to the\n /// managed value. The value is accessed by calling [`upgrade`] on the `Weak`\n /// pointer, which returns an [`Option`]`<`[`Arc`]`<T>>`.\n@@ -290,7 +304,7 @@ impl<T> Arc<T> {\n             weak: atomic::AtomicUsize::new(1),\n             data,\n         };\n-        Arc { ptr: Box::into_raw_non_null(x), phantom: PhantomData }\n+        Self::from_inner(Box::into_raw_non_null(x))\n     }\n \n     /// Constructs a new `Pin<Arc<T>>`. If `T` does not implement `Unpin`, then\n@@ -403,10 +417,7 @@ impl<T: ?Sized> Arc<T> {\n         let fake_ptr = ptr as *mut ArcInner<T>;\n         let arc_ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n \n-        Arc {\n-            ptr: NonNull::new_unchecked(arc_ptr),\n-            phantom: PhantomData,\n-        }\n+        Self::from_ptr(arc_ptr)\n     }\n \n     /// Consumes the `Arc`, returning the wrapped pointer as `NonNull<T>`.\n@@ -577,21 +588,28 @@ impl<T: ?Sized> Arc<T> {\n }\n \n impl<T: ?Sized> Arc<T> {\n-    // Allocates an `ArcInner<T>` with sufficient space for an unsized value\n-    unsafe fn allocate_for_ptr(ptr: *const T) -> *mut ArcInner<T> {\n-        // Calculate layout using the given value.\n+    /// Allocates an `ArcInner<T>` with sufficient space for\n+    /// an unsized value where the value has the layout provided.\n+    ///\n+    /// The function `mem_to_arcinner` is called with the data pointer\n+    /// and must return back a (potentially fat)-pointer for the `ArcInner<T>`.\n+    unsafe fn allocate_for_unsized(\n+        value_layout: Layout,\n+        mem_to_arcinner: impl FnOnce(*mut u8) -> *mut ArcInner<T>\n+    ) -> *mut ArcInner<T> {\n+        // Calculate layout using the given value layout.\n         // Previously, layout was calculated on the expression\n         // `&*(ptr as *const ArcInner<T>)`, but this created a misaligned\n         // reference (see #54908).\n         let layout = Layout::new::<ArcInner<()>>()\n-            .extend(Layout::for_value(&*ptr)).unwrap().0\n+            .extend(value_layout).unwrap().0\n             .pad_to_align().unwrap();\n \n         let mem = Global.alloc(layout)\n             .unwrap_or_else(|_| handle_alloc_error(layout));\n \n         // Initialize the ArcInner\n-        let inner = set_data_ptr(ptr as *mut T, mem.as_ptr() as *mut u8) as *mut ArcInner<T>;\n+        let inner = mem_to_arcinner(mem.as_ptr());\n         debug_assert_eq!(Layout::for_value(&*inner), layout);\n \n         ptr::write(&mut (*inner).strong, atomic::AtomicUsize::new(1));\n@@ -600,6 +618,15 @@ impl<T: ?Sized> Arc<T> {\n         inner\n     }\n \n+    /// Allocates an `ArcInner<T>` with sufficient space for an unsized value.\n+    unsafe fn allocate_for_ptr(ptr: *const T) -> *mut ArcInner<T> {\n+        // Allocate for the `ArcInner<T>` using the given value.\n+        Self::allocate_for_unsized(\n+            Layout::for_value(&*ptr),\n+            |mem| set_data_ptr(ptr as *mut T, mem) as *mut ArcInner<T>,\n+        )\n+    }\n+\n     fn from_box(v: Box<T>) -> Arc<T> {\n         unsafe {\n             let box_unique = Box::into_unique(v);\n@@ -617,45 +644,49 @@ impl<T: ?Sized> Arc<T> {\n             // Free the allocation without dropping its contents\n             box_free(box_unique);\n \n-            Arc { ptr: NonNull::new_unchecked(ptr), phantom: PhantomData }\n+            Self::from_ptr(ptr)\n         }\n     }\n }\n \n-// Sets the data pointer of a `?Sized` raw pointer.\n-//\n-// For a slice/trait object, this sets the `data` field and leaves the rest\n-// unchanged. For a sized raw pointer, this simply sets the pointer.\n+impl<T> Arc<[T]> {\n+    /// Allocates an `ArcInner<[T]>` with the given length.\n+    unsafe fn allocate_for_slice(len: usize) -> *mut ArcInner<[T]> {\n+        Self::allocate_for_unsized(\n+            Layout::array::<T>(len).unwrap(),\n+            |mem| ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut ArcInner<[T]>,\n+        )\n+    }\n+}\n+\n+/// Sets the data pointer of a `?Sized` raw pointer.\n+///\n+/// For a slice/trait object, this sets the `data` field and leaves the rest\n+/// unchanged. For a sized raw pointer, this simply sets the pointer.\n unsafe fn set_data_ptr<T: ?Sized, U>(mut ptr: *mut T, data: *mut U) -> *mut T {\n     ptr::write(&mut ptr as *mut _ as *mut *mut u8, data as *mut u8);\n     ptr\n }\n \n impl<T> Arc<[T]> {\n-    // Copy elements from slice into newly allocated Arc<[T]>\n-    //\n-    // Unsafe because the caller must either take ownership or bind `T: Copy`\n+    /// Copy elements from slice into newly allocated Arc<[T]>\n+    ///\n+    /// Unsafe because the caller must either take ownership or bind `T: Copy`.\n     unsafe fn copy_from_slice(v: &[T]) -> Arc<[T]> {\n-        let v_ptr = v as *const [T];\n-        let ptr = Self::allocate_for_ptr(v_ptr);\n+        let ptr = Self::allocate_for_slice(v.len());\n \n         ptr::copy_nonoverlapping(\n             v.as_ptr(),\n             &mut (*ptr).data as *mut [T] as *mut T,\n             v.len());\n \n-        Arc { ptr: NonNull::new_unchecked(ptr), phantom: PhantomData }\n+        Self::from_ptr(ptr)\n     }\n-}\n \n-// Specialization trait used for From<&[T]>\n-trait ArcFromSlice<T> {\n-    fn from_slice(slice: &[T]) -> Self;\n-}\n-\n-impl<T: Clone> ArcFromSlice<T> for Arc<[T]> {\n-    #[inline]\n-    default fn from_slice(v: &[T]) -> Self {\n+    /// Constructs an `Arc<[T]>` from an iterator known to be of a certain size.\n+    ///\n+    /// Behavior is undefined should the size be wrong.\n+    unsafe fn from_iter_exact(iter: impl iter::Iterator<Item = T>, len: usize) -> Arc<[T]> {\n         // Panic guard while cloning T elements.\n         // In the event of a panic, elements that have been written\n         // into the new ArcInner will be dropped, then the memory freed.\n@@ -677,32 +708,43 @@ impl<T: Clone> ArcFromSlice<T> for Arc<[T]> {\n             }\n         }\n \n-        unsafe {\n-            let v_ptr = v as *const [T];\n-            let ptr = Self::allocate_for_ptr(v_ptr);\n+        let ptr = Self::allocate_for_slice(len);\n+\n+        let mem = ptr as *mut _ as *mut u8;\n+        let layout = Layout::for_value(&*ptr);\n \n-            let mem = ptr as *mut _ as *mut u8;\n-            let layout = Layout::for_value(&*ptr);\n+        // Pointer to first element\n+        let elems = &mut (*ptr).data as *mut [T] as *mut T;\n \n-            // Pointer to first element\n-            let elems = &mut (*ptr).data as *mut [T] as *mut T;\n+        let mut guard = Guard {\n+            mem: NonNull::new_unchecked(mem),\n+            elems,\n+            layout,\n+            n_elems: 0,\n+        };\n \n-            let mut guard = Guard{\n-                mem: NonNull::new_unchecked(mem),\n-                elems: elems,\n-                layout: layout,\n-                n_elems: 0,\n-            };\n+        for (i, item) in iter.enumerate() {\n+            ptr::write(elems.add(i), item);\n+            guard.n_elems += 1;\n+        }\n \n-            for (i, item) in v.iter().enumerate() {\n-                ptr::write(elems.add(i), item.clone());\n-                guard.n_elems += 1;\n-            }\n+        // All clear. Forget the guard so it doesn't free the new ArcInner.\n+        mem::forget(guard);\n+\n+        Self::from_ptr(ptr)\n+    }\n+}\n \n-            // All clear. Forget the guard so it doesn't free the new ArcInner.\n-            mem::forget(guard);\n+/// Specialization trait used for `From<&[T]>`.\n+trait ArcFromSlice<T> {\n+    fn from_slice(slice: &[T]) -> Self;\n+}\n \n-            Arc { ptr: NonNull::new_unchecked(ptr), phantom: PhantomData }\n+impl<T: Clone> ArcFromSlice<T> for Arc<[T]> {\n+    #[inline]\n+    default fn from_slice(v: &[T]) -> Self {\n+        unsafe {\n+            Self::from_iter_exact(v.iter().cloned(), v.len())\n         }\n     }\n }\n@@ -760,7 +802,7 @@ impl<T: ?Sized> Clone for Arc<T> {\n             }\n         }\n \n-        Arc { ptr: self.ptr, phantom: PhantomData }\n+        Self::from_inner(self.ptr)\n     }\n }\n \n@@ -1039,7 +1081,7 @@ impl Arc<dyn Any + Send + Sync> {\n         if (*self).is::<T>() {\n             let ptr = self.ptr.cast::<ArcInner<T>>();\n             mem::forget(self);\n-            Ok(Arc { ptr, phantom: PhantomData })\n+            Ok(Arc::from_inner(ptr))\n         } else {\n             Err(self)\n         }\n@@ -1260,11 +1302,7 @@ impl<T: ?Sized> Weak<T> {\n \n             // Relaxed is valid for the same reason it is on Arc's Clone impl\n             match inner.strong.compare_exchange_weak(n, n + 1, Relaxed, Relaxed) {\n-                Ok(_) => return Some(Arc {\n-                    // null checked above\n-                    ptr: self.ptr,\n-                    phantom: PhantomData,\n-                }),\n+                Ok(_) => return Some(Arc::from_inner(self.ptr)), // null checked above\n                 Err(old) => n = old,\n             }\n         }\n@@ -1785,6 +1823,98 @@ impl<T> From<Vec<T>> for Arc<[T]> {\n     }\n }\n \n+#[stable(feature = \"shared_from_iter\", since = \"1.37.0\")]\n+impl<T> iter::FromIterator<T> for Arc<[T]> {\n+    /// Takes each element in the `Iterator` and collects it into an `Arc<[T]>`.\n+    ///\n+    /// # Performance characteristics\n+    ///\n+    /// ## The general case\n+    ///\n+    /// In the general case, collecting into `Arc<[T]>` is done by first\n+    /// collecting into a `Vec<T>`. That is, when writing the following:\n+    ///\n+    /// ```rust\n+    /// # use std::sync::Arc;\n+    /// let evens: Arc<[u8]> = (0..10).filter(|&x| x % 2 == 0).collect();\n+    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n+    /// ```\n+    ///\n+    /// this behaves as if we wrote:\n+    ///\n+    /// ```rust\n+    /// # use std::sync::Arc;\n+    /// let evens: Arc<[u8]> = (0..10).filter(|&x| x % 2 == 0)\n+    ///     .collect::<Vec<_>>() // The first set of allocations happens here.\n+    ///     .into(); // A second allocation for `Arc<[T]>` happens here.\n+    /// # assert_eq!(&*evens, &[0, 2, 4, 6, 8]);\n+    /// ```\n+    ///\n+    /// This will allocate as many times as needed for constructing the `Vec<T>`\n+    /// and then it will allocate once for turning the `Vec<T>` into the `Arc<[T]>`.\n+    ///\n+    /// ## Iterators of known length\n+    ///\n+    /// When your `Iterator` implements `TrustedLen` and is of an exact size,\n+    /// a single allocation will be made for the `Arc<[T]>`. For example:\n+    ///\n+    /// ```rust\n+    /// # use std::sync::Arc;\n+    /// let evens: Arc<[u8]> = (0..10).collect(); // Just a single allocation happens here.\n+    /// # assert_eq!(&*evens, &*(0..10).collect::<Vec<_>>());\n+    /// ```\n+    fn from_iter<I: iter::IntoIterator<Item = T>>(iter: I) -> Self {\n+        ArcFromIter::from_iter(iter.into_iter())\n+    }\n+}\n+\n+/// Specialization trait used for collecting into `Arc<[T]>`.\n+trait ArcFromIter<T, I> {\n+    fn from_iter(iter: I) -> Self;\n+}\n+\n+impl<T, I: Iterator<Item = T>> ArcFromIter<T, I> for Arc<[T]> {\n+    default fn from_iter(iter: I) -> Self {\n+        iter.collect::<Vec<T>>().into()\n+    }\n+}\n+\n+impl<T, I: iter::TrustedLen<Item = T>> ArcFromIter<T, I> for Arc<[T]> {\n+    default fn from_iter(iter: I) -> Self {\n+        // This is the case for a `TrustedLen` iterator.\n+        let (low, high) = iter.size_hint();\n+        if let Some(high) = high {\n+            debug_assert_eq!(\n+                low, high,\n+                \"TrustedLen iterator's size hint is not exact: {:?}\",\n+                (low, high)\n+            );\n+\n+            unsafe {\n+                // SAFETY: We need to ensure that the iterator has an exact length and we have.\n+                Arc::from_iter_exact(iter, low)\n+            }\n+        } else {\n+            // Fall back to normal implementation.\n+            iter.collect::<Vec<T>>().into()\n+        }\n+    }\n+}\n+\n+impl<'a, T: 'a + Clone> ArcFromIter<&'a T, slice::Iter<'a, T>> for Arc<[T]> {\n+    fn from_iter(iter: slice::Iter<'a, T>) -> Self {\n+        // Delegate to `impl<T: Clone> From<&[T]> for Arc<[T]>`.\n+        //\n+        // In the case that `T: Copy`, we get to use `ptr::copy_nonoverlapping`\n+        // which is even more performant.\n+        //\n+        // In the fall-back case we have `T: Clone`. This is still better\n+        // than the `TrustedLen` implementation as slices have a known length\n+        // and so we get to avoid calling `size_hint` and avoid the branching.\n+        iter.as_slice().into()\n+    }\n+}\n+\n #[cfg(test)]\n mod tests {\n     use std::boxed::Box;\n@@ -2285,20 +2415,22 @@ impl<T: ?Sized> AsRef<T> for Arc<T> {\n #[stable(feature = \"pin\", since = \"1.33.0\")]\n impl<T: ?Sized> Unpin for Arc<T> { }\n \n-/// Computes the offset of the data field within ArcInner.\n+/// Computes the offset of the data field within `ArcInner`.\n unsafe fn data_offset<T: ?Sized>(ptr: *const T) -> isize {\n-    // Align the unsized value to the end of the ArcInner.\n-    // Because it is ?Sized, it will always be the last field in memory.\n-    let align = align_of_val(&*ptr);\n-    let layout = Layout::new::<ArcInner<()>>();\n-    (layout.size() + layout.padding_needed_for(align)) as isize\n+    // Align the unsized value to the end of the `ArcInner`.\n+    // Because it is `?Sized`, it will always be the last field in memory.\n+    data_offset_align(align_of_val(&*ptr))\n }\n \n-/// Computes the offset of the data field within ArcInner.\n+/// Computes the offset of the data field within `ArcInner`.\n ///\n /// Unlike [`data_offset`], this doesn't need the pointer, but it works only on `T: Sized`.\n fn data_offset_sized<T>() -> isize {\n-    let align = align_of::<T>();\n+    data_offset_align(align_of::<T>())\n+}\n+\n+#[inline]\n+fn data_offset_align(align: usize) -> isize {\n     let layout = Layout::new::<ArcInner<()>>();\n     (layout.size() + layout.padding_needed_for(align)) as isize\n }"}, {"sha": "cf2ad2a8e60338620de2fb9f931006f14d13f594", "filename": "src/liballoc/tests/arc.rs", "status": "modified", "additions": 121, "deletions": 0, "changes": 121, "blob_url": "https://github.com/rust-lang/rust/blob/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Ftests%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Ftests%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Ftests%2Farc.rs?ref=4a95e9704de0eeaecba55df102c1129e79a3a929", "patch": "@@ -2,6 +2,8 @@ use std::any::Any;\n use std::sync::{Arc, Weak};\n use std::cell::RefCell;\n use std::cmp::PartialEq;\n+use std::iter::TrustedLen;\n+use std::mem;\n \n #[test]\n fn uninhabited() {\n@@ -85,3 +87,122 @@ fn eq() {\n     assert!(!(x != x));\n     assert_eq!(*x.0.borrow(), 0);\n }\n+\n+// The test code below is identical to that in `rc.rs`.\n+// For better maintainability we therefore define this type alias.\n+type Rc<T> = Arc<T>;\n+\n+const SHARED_ITER_MAX: u16 = 100;\n+\n+fn assert_trusted_len<I: TrustedLen>(_: &I) {}\n+\n+#[test]\n+fn shared_from_iter_normal() {\n+    // Exercise the base implementation for non-`TrustedLen` iterators.\n+    {\n+        // `Filter` is never `TrustedLen` since we don't\n+        // know statically how many elements will be kept:\n+        let iter = (0..SHARED_ITER_MAX).filter(|x| x % 2 == 0).map(Box::new);\n+\n+        // Collecting into a `Vec<T>` or `Rc<[T]>` should make no difference:\n+        let vec = iter.clone().collect::<Vec<_>>();\n+        let rc = iter.collect::<Rc<[_]>>();\n+        assert_eq!(&*vec, &*rc);\n+\n+        // Clone a bit and let these get dropped.\n+        {\n+            let _rc_2 = rc.clone();\n+            let _rc_3 = rc.clone();\n+            let _rc_4 = Rc::downgrade(&_rc_3);\n+        }\n+    } // Drop what hasn't been here.\n+}\n+\n+#[test]\n+fn shared_from_iter_trustedlen_normal() {\n+    // Exercise the `TrustedLen` implementation under normal circumstances\n+    // where `size_hint()` matches `(_, Some(exact_len))`.\n+    {\n+        let iter = (0..SHARED_ITER_MAX).map(Box::new);\n+        assert_trusted_len(&iter);\n+\n+        // Collecting into a `Vec<T>` or `Rc<[T]>` should make no difference:\n+        let vec = iter.clone().collect::<Vec<_>>();\n+        let rc = iter.collect::<Rc<[_]>>();\n+        assert_eq!(&*vec, &*rc);\n+        assert_eq!(mem::size_of::<Box<u16>>() * SHARED_ITER_MAX as usize, mem::size_of_val(&*rc));\n+\n+        // Clone a bit and let these get dropped.\n+        {\n+            let _rc_2 = rc.clone();\n+            let _rc_3 = rc.clone();\n+            let _rc_4 = Rc::downgrade(&_rc_3);\n+        }\n+    } // Drop what hasn't been here.\n+\n+    // Try a ZST to make sure it is handled well.\n+    {\n+        let iter = (0..SHARED_ITER_MAX).map(|_| ());\n+        let vec = iter.clone().collect::<Vec<_>>();\n+        let rc = iter.collect::<Rc<[_]>>();\n+        assert_eq!(&*vec, &*rc);\n+        assert_eq!(0, mem::size_of_val(&*rc));\n+        {\n+            let _rc_2 = rc.clone();\n+            let _rc_3 = rc.clone();\n+            let _rc_4 = Rc::downgrade(&_rc_3);\n+        }\n+    }\n+}\n+\n+#[test]\n+#[should_panic = \"I've almost got 99 problems.\"]\n+fn shared_from_iter_trustedlen_panic() {\n+    // Exercise the `TrustedLen` implementation when `size_hint()` matches\n+    // `(_, Some(exact_len))` but where `.next()` drops before the last iteration.\n+    let iter = (0..SHARED_ITER_MAX)\n+        .map(|val| {\n+            match val {\n+                98 => panic!(\"I've almost got 99 problems.\"),\n+                _ => Box::new(val),\n+            }\n+        });\n+    assert_trusted_len(&iter);\n+    let _ = iter.collect::<Rc<[_]>>();\n+\n+    panic!(\"I am unreachable.\");\n+}\n+\n+#[test]\n+fn shared_from_iter_trustedlen_no_fuse() {\n+    // Exercise the `TrustedLen` implementation when `size_hint()` matches\n+    // `(_, Some(exact_len))` but where the iterator does not behave in a fused manner.\n+    struct Iter(std::vec::IntoIter<Option<Box<u8>>>);\n+\n+    unsafe impl TrustedLen for Iter {}\n+\n+    impl Iterator for Iter {\n+        fn size_hint(&self) -> (usize, Option<usize>) {\n+            (2, Some(2))\n+        }\n+\n+        type Item = Box<u8>;\n+\n+        fn next(&mut self) -> Option<Self::Item> {\n+            self.0.next().flatten()\n+        }\n+    }\n+\n+    let vec = vec![\n+        Some(Box::new(42)),\n+        Some(Box::new(24)),\n+        None,\n+        Some(Box::new(12)),\n+    ];\n+    let iter = Iter(vec.into_iter());\n+    assert_trusted_len(&iter);\n+    assert_eq!(\n+        &[Box::new(42), Box::new(24)],\n+        &*iter.collect::<Rc<[_]>>()\n+    );\n+}"}, {"sha": "5a43c8e09a2a8a5b4b82b655e1adeb1842c974e0", "filename": "src/liballoc/tests/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Ftests%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Ftests%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Ftests%2Flib.rs?ref=4a95e9704de0eeaecba55df102c1129e79a3a929", "patch": "@@ -2,8 +2,10 @@\n #![feature(box_syntax)]\n #![feature(drain_filter)]\n #![feature(exact_size_is_empty)]\n+#![feature(option_flattening)]\n #![feature(pattern)]\n #![feature(repeat_generic_slice)]\n+#![feature(trusted_len)]\n #![feature(try_reserve)]\n #![feature(unboxed_closures)]\n #![deny(rust_2018_idioms)]"}, {"sha": "7854ca0fc16b26936111d78926fff1252df1e960", "filename": "src/liballoc/tests/rc.rs", "status": "modified", "additions": 117, "deletions": 0, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Ftests%2Frc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4a95e9704de0eeaecba55df102c1129e79a3a929/src%2Fliballoc%2Ftests%2Frc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Ftests%2Frc.rs?ref=4a95e9704de0eeaecba55df102c1129e79a3a929", "patch": "@@ -2,6 +2,8 @@ use std::any::Any;\n use std::rc::{Rc, Weak};\n use std::cell::RefCell;\n use std::cmp::PartialEq;\n+use std::mem;\n+use std::iter::TrustedLen;\n \n #[test]\n fn uninhabited() {\n@@ -85,3 +87,118 @@ fn eq() {\n     assert!(!(x != x));\n     assert_eq!(*x.0.borrow(), 0);\n }\n+\n+const SHARED_ITER_MAX: u16 = 100;\n+\n+fn assert_trusted_len<I: TrustedLen>(_: &I) {}\n+\n+#[test]\n+fn shared_from_iter_normal() {\n+    // Exercise the base implementation for non-`TrustedLen` iterators.\n+    {\n+        // `Filter` is never `TrustedLen` since we don't\n+        // know statically how many elements will be kept:\n+        let iter = (0..SHARED_ITER_MAX).filter(|x| x % 2 == 0).map(Box::new);\n+\n+        // Collecting into a `Vec<T>` or `Rc<[T]>` should make no difference:\n+        let vec = iter.clone().collect::<Vec<_>>();\n+        let rc = iter.collect::<Rc<[_]>>();\n+        assert_eq!(&*vec, &*rc);\n+\n+        // Clone a bit and let these get dropped.\n+        {\n+            let _rc_2 = rc.clone();\n+            let _rc_3 = rc.clone();\n+            let _rc_4 = Rc::downgrade(&_rc_3);\n+        }\n+    } // Drop what hasn't been here.\n+}\n+\n+#[test]\n+fn shared_from_iter_trustedlen_normal() {\n+    // Exercise the `TrustedLen` implementation under normal circumstances\n+    // where `size_hint()` matches `(_, Some(exact_len))`.\n+    {\n+        let iter = (0..SHARED_ITER_MAX).map(Box::new);\n+        assert_trusted_len(&iter);\n+\n+        // Collecting into a `Vec<T>` or `Rc<[T]>` should make no difference:\n+        let vec = iter.clone().collect::<Vec<_>>();\n+        let rc = iter.collect::<Rc<[_]>>();\n+        assert_eq!(&*vec, &*rc);\n+        assert_eq!(mem::size_of::<Box<u16>>() * SHARED_ITER_MAX as usize, mem::size_of_val(&*rc));\n+\n+        // Clone a bit and let these get dropped.\n+        {\n+            let _rc_2 = rc.clone();\n+            let _rc_3 = rc.clone();\n+            let _rc_4 = Rc::downgrade(&_rc_3);\n+        }\n+    } // Drop what hasn't been here.\n+\n+    // Try a ZST to make sure it is handled well.\n+    {\n+        let iter = (0..SHARED_ITER_MAX).map(|_| ());\n+        let vec = iter.clone().collect::<Vec<_>>();\n+        let rc = iter.collect::<Rc<[_]>>();\n+        assert_eq!(&*vec, &*rc);\n+        assert_eq!(0, mem::size_of_val(&*rc));\n+        {\n+            let _rc_2 = rc.clone();\n+            let _rc_3 = rc.clone();\n+            let _rc_4 = Rc::downgrade(&_rc_3);\n+        }\n+    }\n+}\n+\n+#[test]\n+#[should_panic = \"I've almost got 99 problems.\"]\n+fn shared_from_iter_trustedlen_panic() {\n+    // Exercise the `TrustedLen` implementation when `size_hint()` matches\n+    // `(_, Some(exact_len))` but where `.next()` drops before the last iteration.\n+    let iter = (0..SHARED_ITER_MAX)\n+        .map(|val| {\n+            match val {\n+                98 => panic!(\"I've almost got 99 problems.\"),\n+                _ => Box::new(val),\n+            }\n+        });\n+    assert_trusted_len(&iter);\n+    let _ = iter.collect::<Rc<[_]>>();\n+\n+    panic!(\"I am unreachable.\");\n+}\n+\n+#[test]\n+fn shared_from_iter_trustedlen_no_fuse() {\n+    // Exercise the `TrustedLen` implementation when `size_hint()` matches\n+    // `(_, Some(exact_len))` but where the iterator does not behave in a fused manner.\n+    struct Iter(std::vec::IntoIter<Option<Box<u8>>>);\n+\n+    unsafe impl TrustedLen for Iter {}\n+\n+    impl Iterator for Iter {\n+        fn size_hint(&self) -> (usize, Option<usize>) {\n+            (2, Some(2))\n+        }\n+\n+        type Item = Box<u8>;\n+\n+        fn next(&mut self) -> Option<Self::Item> {\n+            self.0.next().flatten()\n+        }\n+    }\n+\n+    let vec = vec![\n+        Some(Box::new(42)),\n+        Some(Box::new(24)),\n+        None,\n+        Some(Box::new(12)),\n+    ];\n+    let iter = Iter(vec.into_iter());\n+    assert_trusted_len(&iter);\n+    assert_eq!(\n+        &[Box::new(42), Box::new(24)],\n+        &*iter.collect::<Rc<[_]>>()\n+    );\n+}"}]}