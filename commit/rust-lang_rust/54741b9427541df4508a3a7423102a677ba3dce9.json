{"sha": "54741b9427541df4508a3a7423102a677ba3dce9", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU0NzQxYjk0Mjc1NDFkZjQ1MDhhM2E3NDIzMTAyYTY3N2JhM2RjZTk=", "commit": {"author": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-07-07T01:04:28Z"}, "committer": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-07-10T00:44:46Z"}, "message": "Allow defining token tree macros. They should work now!", "tree": {"sha": "59e443febfea46a250d7b1672fa3505f2d3eedfd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/59e443febfea46a250d7b1672fa3505f2d3eedfd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/54741b9427541df4508a3a7423102a677ba3dce9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/54741b9427541df4508a3a7423102a677ba3dce9", "html_url": "https://github.com/rust-lang/rust/commit/54741b9427541df4508a3a7423102a677ba3dce9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/54741b9427541df4508a3a7423102a677ba3dce9/comments", "author": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "committer": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "caa83b41bba2b63c8b55193d176d40f5eb0fa9a8", "url": "https://api.github.com/repos/rust-lang/rust/commits/caa83b41bba2b63c8b55193d176d40f5eb0fa9a8", "html_url": "https://github.com/rust-lang/rust/commit/caa83b41bba2b63c8b55193d176d40f5eb0fa9a8"}], "stats": {"total": 259, "additions": 185, "deletions": 74}, "files": [{"sha": "3df4a2aefa5679b9f6778f4ce0325b0c625cf927", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -413,7 +413,7 @@ type mac_body = option<mac_body_>;\n #[auto_serialize]\n enum mac_ {\n     mac_invoc(@path, mac_arg, mac_body),\n-    mac_invoc_tt(@path, token_tree), //will kill mac_invoc and steal its name\n+    mac_invoc_tt(@path,~[token_tree]),//will kill mac_invoc and steal its name\n     mac_embed_type(@ty),\n     mac_embed_block(blk),\n     mac_ellipsis,"}, {"sha": "7b08b18596e7dac3495e75a89aa3157f0bd42f87", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 12, "deletions": 5, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -4,8 +4,10 @@ import diagnostic::span_handler;\n import codemap::{codemap, span, expn_info, expanded_from};\n import std::map::str_hash;\n \n+// second argument is the span to blame for general argument problems\n type syntax_expander_ =\n     fn@(ext_ctxt, span, ast::mac_arg, ast::mac_body) -> @ast::expr;\n+// second argument is the origin of the macro, if user-defined\n type syntax_expander = {expander: syntax_expander_, span: option<span>};\n \n type macro_def = {ident: ast::ident, ext: syntax_extension};\n@@ -15,14 +17,16 @@ type item_decorator =\n     fn@(ext_ctxt, span, ast::meta_item, ~[@ast::item]) -> ~[@ast::item];\n \n type syntax_expander_tt = {expander: syntax_expander_tt_, span: option<span>};\n-type syntax_expander_tt_ = fn@(ext_ctxt, span, ast::token_tree) -> @ast::expr;\n+type syntax_expander_tt_ = fn@(ext_ctxt, span, ~[ast::token_tree])\n+    -> mac_result;\n \n type syntax_expander_tt_item\n     = {expander: syntax_expander_tt_item_, span: option<span>};\n type syntax_expander_tt_item_\n-    = fn@(ext_ctxt, span, ast::ident, ast::token_tree) -> mac_result;\n+    = fn@(ext_ctxt, span, ast::ident, ~[ast::token_tree]) -> mac_result;\n \n enum mac_result {\n+    mr_expr(@ast::expr),\n     mr_item(@ast::item),\n     mr_def(macro_def)\n }\n@@ -32,7 +36,7 @@ enum syntax_extension {\n     macro_defining(macro_definer),\n     item_decorator(item_decorator),\n \n-    normal_tt(syntax_expander_tt),\n+    expr_tt(syntax_expander_tt),\n     item_tt(syntax_expander_tt_item),\n }\n \n@@ -45,12 +49,15 @@ fn syntax_expander_table() -> hashmap<str, syntax_extension> {\n         item_tt({expander: f, span: none})\n     }\n     let syntax_expanders = str_hash::<syntax_extension>();\n+    syntax_expanders.insert(\"macro\",\n+                            macro_defining(ext::simplext::add_new_extension));\n+    syntax_expanders.insert(\"macro_rules\",\n+                            builtin_item_tt(\n+                                ext::tt::macro_rules::add_new_extension));\n     syntax_expanders.insert(\"fmt\", builtin(ext::fmt::expand_syntax_ext));\n     syntax_expanders.insert(\"auto_serialize\",\n                             item_decorator(ext::auto_serialize::expand));\n     syntax_expanders.insert(\"env\", builtin(ext::env::expand_syntax_ext));\n-    syntax_expanders.insert(\"macro\",\n-                            macro_defining(ext::simplext::add_new_extension));\n     syntax_expanders.insert(\"concat_idents\",\n                             builtin(ext::concat_idents::expand_syntax_ext));\n     syntax_expanders.insert(\"ident_to_str\","}, {"sha": "05c7e6f1c5af6e589b5f06328565ca0d1d0f2144", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 25, "deletions": 17, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -32,7 +32,7 @@ fn expand_expr(exts: hashmap<str, syntax_extension>, cx: ext_ctxt,\n                         #fmt[\"%s can only be used as a decorator\", *extname]);\n                   }\n                   some(normal({expander: exp, span: exp_sp})) {\n-                    let expanded = exp(cx, pth.span, args, body);\n+                    let expanded = exp(cx, mac.span, args, body);\n \n                     cx.bt_push(expanded_from({call_site: s,\n                                 callie: {name: *extname, span: exp_sp}}));\n@@ -43,11 +43,11 @@ fn expand_expr(exts: hashmap<str, syntax_extension>, cx: ext_ctxt,\n                     (fully_expanded, s)\n                   }\n                   some(macro_defining(ext)) {\n-                    let named_extension = ext(cx, pth.span, args, body);\n+                    let named_extension = ext(cx, mac.span, args, body);\n                     exts.insert(*named_extension.ident, named_extension.ext);\n                     (ast::expr_rec(~[], none), s)\n                   }\n-                  some(normal_tt(_)) {\n+                  some(expr_tt(_)) {\n                     cx.span_fatal(pth.span,\n                                   #fmt[\"this tt-style macro should be \\\n                                         invoked '%s!{...}'\", *extname])\n@@ -58,16 +58,21 @@ fn expand_expr(exts: hashmap<str, syntax_extension>, cx: ext_ctxt,\n                   }\n                 }\n               }\n-              mac_invoc_tt(pth, tt) {\n-                assert (vec::len(pth.idents) > 0u);\n+              mac_invoc_tt(pth, tts) {\n+                assert (vec::len(pth.idents) == 1u);\n                 let extname = pth.idents[0];\n                 alt exts.find(*extname) {\n                   none {\n                     cx.span_fatal(pth.span,\n                                   #fmt[\"macro undefined: '%s'\", *extname])\n                   }\n-                  some(normal_tt({expander: exp, span: exp_sp})) {\n-                    let expanded = exp(cx, pth.span, tt);\n+                  some(expr_tt({expander: exp, span: exp_sp})) {\n+                    let expanded = alt exp(cx, mac.span, tts) {\n+                      mr_expr(e) { e }\n+                      _ { cx.span_fatal(\n+                          pth.span, #fmt[\"non-expr macro in expr pos: %s\",\n+                                         *extname]) }\n+                    };\n \n                     cx.bt_push(expanded_from({call_site: s,\n                                 callie: {name: *extname, span: exp_sp}}));\n@@ -113,7 +118,7 @@ fn expand_mod_items(exts: hashmap<str, syntax_extension>, cx: ext_ctxt,\n             };\n             alt exts.find(*mname) {\n               none | some(normal(_)) | some(macro_defining(_))\n-              | some(normal_tt(_)) | some(item_tt(*)) {\n+              | some(expr_tt(_)) | some(item_tt(*)) {\n                 items\n               }\n \n@@ -159,25 +164,28 @@ fn expand_item_mac(exts: hashmap<str, syntax_extension>,\n                    cx: ext_ctxt, &&it: @ast::item,\n                    fld: ast_fold) -> option<@ast::item> {\n     alt it.node {\n-      item_mac({node: mac_invoc_tt(pth, tt), span}) {\n+      item_mac({node: mac_invoc_tt(pth, tts), span}) {\n         let extname = pth.idents[0];\n         alt exts.find(*extname) {\n           none {\n             cx.span_fatal(pth.span,\n                           #fmt(\"macro undefined: '%s'\", *extname))\n           }\n           some(item_tt(expand)) {\n+            let expanded = expand.expander(cx, it.span, it.ident, tts);\n             cx.bt_push(expanded_from({call_site: it.span,\n                                       callie: {name: *extname,\n                                                span: expand.span}}));\n-            let maybe_it =\n-                alt expand.expander(cx, it.span, it.ident, tt) {\n-                  mr_item(it) { fld.fold_item(it) }\n-                  mr_def(mdef) {\n-                    exts.insert(*mdef.ident, mdef.ext);\n-                    none\n-                  }\n-                };\n+            let maybe_it = alt expanded {\n+              mr_item(it) { fld.fold_item(it) }\n+              mr_expr(e) { cx.span_fatal(pth.span,\n+                                         \"expr macro in item position: \" +\n+                                         *extname) }\n+              mr_def(mdef) {\n+                exts.insert(*mdef.ident, mdef.ext);\n+                none\n+              }\n+            };\n             cx.bt_pop();\n             ret maybe_it\n           }"}, {"sha": "3a6a2ff7a5239ba9bfcf00db72b792feb342d172", "filename": "src/libsyntax/ext/pipes.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fpipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fpipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -10,16 +10,13 @@ import pipes::parse_proto::proto_parser;\n \n import pipes::pipec::methods;\n \n-fn expand_proto(cx: ext_ctxt, _sp: span, id: ast::ident, tt: ast::token_tree)\n-    -> base::mac_result\n+fn expand_proto(cx: ext_ctxt, _sp: span, id: ast::ident,\n+                tt: ~[ast::token_tree]) -> base::mac_result\n {\n     let sess = cx.parse_sess();\n     let cfg = cx.cfg();\n-    let body_core = alt tt { tt_delim(tts) { tts } _ {fail}};\n     let tt_rdr = new_tt_reader(cx.parse_sess().span_diagnostic,\n-                               cx.parse_sess().interner,\n-                               none,\n-                               body_core);\n+                               cx.parse_sess().interner, none, tt);\n     let rdr = tt_rdr as reader;\n     let rust_parser = parser(sess, cfg, rdr.dup(), SOURCE_FILE);\n "}, {"sha": "420de449a5cbac9ab7a01808af848ebea29da3b8", "filename": "src/libsyntax/ext/pipes/parse_proto.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fpipes%2Fparse_proto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Fpipes%2Fparse_proto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fpipes%2Fparse_proto.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -10,10 +10,9 @@ impl proto_parser for parser {\n     fn parse_proto(id: ident) -> protocol {\n         let proto = protocol(id);\n \n-        self.parse_unspanned_seq(token::LBRACE,\n-                                 token::RBRACE,\n-                                 {sep: none, trailing_sep_allowed: false},\n-                                 |self| self.parse_state(proto));\n+        self.parse_seq_to_before_end(token::EOF,\n+                                     {sep: none, trailing_sep_allowed: false},\n+                                     |self| self.parse_state(proto));\n \n         ret proto;\n     }"}, {"sha": "d26f5dc0e3c4108c6235c051d9d33a5607a9545c", "filename": "src/libsyntax/ext/tt/earley_parser.rs", "status": "modified", "additions": 13, "deletions": 8, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Ftt%2Fearley_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Ftt%2Fearley_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fearley_parser.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -72,11 +72,10 @@ enum arb_depth { leaf(whole_nt), seq(~[@arb_depth], codemap::span) }\n \n type earley_item = matcher_pos;\n \n-\n-fn nameize(&&p_s: parse_sess, ms: ~[matcher], &&res: ~[@arb_depth])\n+fn nameize(p_s: parse_sess, ms: ~[matcher], res: ~[@arb_depth])\n     -> hashmap<ident,@arb_depth> {\n-    fn n_rec(&&p_s: parse_sess, &&m: matcher, &&res: ~[@arb_depth],\n-             &&ret_val: hashmap<ident, @arb_depth>) {\n+    fn n_rec(p_s: parse_sess, m: matcher, res: ~[@arb_depth],\n+             ret_val: hashmap<ident, @arb_depth>) {\n         alt m {\n           {node: mtc_tok(_), span: _} { }\n           {node: mtc_rep(more_ms, _, _), span: _} {\n@@ -142,8 +141,11 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n                         // doing a lot of array work that will get thrown away\n                         // most of the time.\n                         for ei.matches.eachi() |idx, elt| {\n+                            let sub = elt.get();\n+                            // Some subtrees don't contain the name at all\n+                            if sub.len() == 0u { cont; }\n                             new_pos.matches[idx]\n-                                .push(@seq(elt.get(), mk_sp(ei.sp_lo,sp.hi)));\n+                                .push(@seq(sub, mk_sp(ei.sp_lo,sp.hi)));\n                         }\n \n                         new_pos.idx += 1u;\n@@ -221,8 +223,8 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n                      built-in NTs %s or %u other options.\",\n                     nts, next_eis.len()]);\n             } else if (bb_eis.len() == 0u && next_eis.len() == 0u) {\n-                failure(sp, \"No rules expected the token \"\n-                        + to_str(*rdr.interner(), tok));\n+                ret failure(sp, \"No rules expected the token \"\n+                            + to_str(*rdr.interner(), tok));\n             } else if (next_eis.len() > 0u) {\n                 /* Now process the next token */\n                 while(next_eis.len() > 0u) {\n@@ -246,6 +248,9 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n                 /* this would fail if zero-length tokens existed */\n                 while rdr.peek().sp.lo < rust_parser.span.lo {\n                     rdr.next_token();\n+                } /* except for EOF... */\n+                while rust_parser.token == EOF && rdr.peek().tok != EOF {\n+                    rdr.next_token();\n                 }\n             }\n         }\n@@ -273,7 +278,7 @@ fn parse_nt(p: parser, name: str) -> whole_nt {\n       } }\n       \"path\" { token::w_path(p.parse_path_with_tps(false)) }\n       \"tt\" {\n-        p.quote_depth += 1u;\n+        p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n         let res = token::w_tt(@p.parse_token_tree());\n         p.quote_depth -= 1u;\n         res"}, {"sha": "822e8e0d6973b541189b357ea7be9a945eddc5b0", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -0,0 +1,83 @@\n+import base::{ext_ctxt, mac_result, mr_expr, mr_def, expr_tt};\n+import codemap::span;\n+import ast::{ident, matcher_, matcher, mtc_tok, mtc_bb, mtc_rep, tt_delim};\n+import parse::lexer::{new_tt_reader, tt_reader_as_reader, reader};\n+import parse::token::{FAT_ARROW, SEMI, LBRACE, RBRACE, w_mtcs, w_tt};\n+import parse::parser::{parser, SOURCE_FILE};\n+import earley_parser::{parse, success, failure, arb_depth, seq, leaf};\n+import std::map::hashmap;\n+\n+\n+\n+fn add_new_extension(cx: ext_ctxt, sp: span, name: ident,\n+                     arg: ~[ast::token_tree]) -> base::mac_result {\n+    // these spans won't matter, anyways\n+    fn ms(m: matcher_) -> matcher {\n+        {node: m, span: {lo: 0u, hi: 0u, expn_info: none}}\n+    }\n+\n+    let argument_gram = ~[\n+        ms(mtc_rep(~[\n+            ms(mtc_bb(@\"lhs\",@\"mtcs\", 0u)),\n+            ms(mtc_tok(FAT_ARROW)),\n+            ms(mtc_bb(@\"rhs\",@\"tt\", 1u)),\n+        ], some(SEMI), false))];\n+\n+    let arg_reader = new_tt_reader(cx.parse_sess().span_diagnostic,\n+                                   cx.parse_sess().interner, none, arg);\n+    let arguments = alt parse(cx.parse_sess(), cx.cfg(),\n+                              arg_reader as reader, argument_gram) {\n+      success(m) { m }\n+      failure(sp, msg) { cx.span_fatal(sp, msg); }\n+    };\n+\n+    let lhses = alt arguments.get(@\"lhs\") {\n+      @seq(s, sp) { s }\n+      _ { cx.span_bug(sp, \"wrong-structured lhs\") }\n+    };\n+    let rhses = alt arguments.get(@\"rhs\") {\n+      @seq(s, sp) { s }\n+      _ { cx.span_bug(sp, \"wrong-structured rhs\") }\n+    };\n+\n+    fn generic_extension(cx: ext_ctxt, sp: span, arg: ~[ast::token_tree],\n+                         lhses: ~[@arb_depth], rhses: ~[@arb_depth])\n+    -> mac_result {\n+        let mut best_fail_spot = {lo: 0u, hi: 0u, expn_info: none};\n+        let mut best_fail_msg = \"internal error: ran no matchers\";\n+\n+        let s_d = cx.parse_sess().span_diagnostic;\n+        let itr = cx.parse_sess().interner;\n+\n+        for lhses.eachi() |i, lhs| {\n+            alt lhs {\n+              @leaf(w_mtcs(mtcs)) {\n+                let arg_rdr = new_tt_reader(s_d, itr, none, arg) as reader;\n+                alt parse(cx.parse_sess(), cx.cfg(), arg_rdr, mtcs) {\n+                  success(m) {\n+                    let rhs = alt rhses[i] {\n+                      @leaf(w_tt(@tt)) { tt }\n+                      _ { cx.span_bug(sp, \"bad thing in rhs\") }\n+                    };\n+                    let trncbr = new_tt_reader(s_d, itr, some(m), ~[rhs]);\n+                    let p = parser(cx.parse_sess(), cx.cfg(),\n+                                   trncbr as reader, SOURCE_FILE);\n+                    ret mr_expr(p.parse_expr());\n+                  }\n+                  failure(sp, msg) {\n+                    if sp.lo >= best_fail_spot.lo {\n+                        best_fail_spot = sp; best_fail_msg = msg;\n+                    }\n+                  }\n+                }\n+              }\n+              _ { cx.bug(\"non-matcher found in parsed lhses\"); }\n+            }\n+        }\n+        cx.span_fatal(best_fail_spot, best_fail_msg);\n+    }\n+\n+    let exp = |cx, sp, arg| generic_extension(cx, sp, arg, lhses, rhses);\n+\n+    ret mr_def({ident: name, ext: expr_tt({expander: exp, span: some(sp)})});\n+}\n\\ No newline at end of file"}, {"sha": "8924c5820a946c35824cf1b3062d61368e95b503", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 28, "deletions": 24, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -23,7 +23,7 @@ type tt_frame = @{\n };\n \n type tt_reader = @{\n-    span_diagnostic: span_handler,\n+    sp_diag: span_handler,\n     interner: @interner<@str>,\n     mut cur: tt_frame,\n     /* for MBE-style macro transcription */\n@@ -36,13 +36,13 @@ type tt_reader = @{\n };\n \n /** This can do Macro-By-Example transcription. On the other hand, if\n- *  `doc` contains no `tt_dotdotdot`s and `tt_interpolate`s, `interp` can (and\n+ *  `src` contains no `tt_dotdotdot`s and `tt_interpolate`s, `interp` can (and\n  *  should) be none. */\n-fn new_tt_reader(span_diagnostic: span_handler, itr: @interner<@str>,\n+fn new_tt_reader(sp_diag: span_handler, itr: @interner<@str>,\n                  interp: option<std::map::hashmap<ident,@arb_depth>>,\n                  src: ~[ast::token_tree])\n     -> tt_reader {\n-    let r = @{span_diagnostic: span_diagnostic, interner: itr,\n+    let r = @{sp_diag: sp_diag, interner: itr,\n               mut cur: @{readme: src, mut idx: 0u, dotdotdoted: false,\n                          sep: none, up: tt_frame_up(option::none)},\n               interpolations: alt interp { /* just a convienience */\n@@ -70,7 +70,7 @@ pure fn dup_tt_frame(&&f: tt_frame) -> tt_frame {\n }\n \n pure fn dup_tt_reader(&&r: tt_reader) -> tt_reader {\n-    @{span_diagnostic: r.span_diagnostic, interner: r.interner,\n+    @{sp_diag: r.sp_diag, interner: r.interner,\n       mut cur: dup_tt_frame(r.cur),\n       interpolations: r.interpolations,\n       mut repeat_idx: copy r.repeat_idx, mut repeat_len: copy r.repeat_len,\n@@ -132,28 +132,27 @@ fn lockstep_iter_size(&&t: token_tree, &&r: tt_reader) -> lis {\n \n fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n     let ret_val = { tok: r.cur_tok, sp: r.cur_span };\n-    if r.cur.idx >= vec::len(r.cur.readme) {\n+    while r.cur.idx >= vec::len(r.cur.readme) {\n         /* done with this set; pop or repeat? */\n         if ! r.cur.dotdotdoted\n             || r.repeat_idx.last() == r.repeat_len.last() - 1 {\n-            if r.cur.dotdotdoted {\n-                vec::pop(r.repeat_idx); vec::pop(r.repeat_len);\n-            }\n+\n             alt r.cur.up {\n               tt_frame_up(none) {\n                 r.cur_tok = EOF;\n                 ret ret_val;\n               }\n               tt_frame_up(some(tt_f)) {\n+                if r.cur.dotdotdoted {\n+                    vec::pop(r.repeat_idx); vec::pop(r.repeat_len);\n+                }\n+\n                 r.cur = tt_f;\n-                /* the outermost `if` would need to be a `while` if we\n-                didn't know that the last thing in a `tt_delim` is always\n-                a `tt_flat`, and that a `tt_dotdotdot` is never empty */\n                 r.cur.idx += 1u;\n               }\n             }\n \n-        } else {\n+        } else { /* repeat */\n             r.cur.idx = 0u;\n             r.repeat_idx[r.repeat_idx.len() - 1u] += 1u;\n             alt r.cur.sep {\n@@ -165,14 +164,13 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n             }\n         }\n     }\n-    /* if `tt_delim`s could be 0-length, we'd need to be able to switch\n-    between popping and pushing until we got to an actual `tt_flat` */\n     loop { /* because it's easiest, this handles `tt_delim` not starting\n     with a `tt_flat`, even though it won't happen */\n         alt r.cur.readme[r.cur.idx] {\n           tt_delim(tts) {\n             r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: false,\n                       sep: none, up: tt_frame_up(option::some(r.cur)) };\n+            // if this could be 0-length, we'd need to potentially recur here\n           }\n           tt_flat(sp, tok) {\n             r.cur_span = sp; r.cur_tok = tok;\n@@ -182,23 +180,29 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n           tt_dotdotdot(sp, tts, sep, zerok) {\n             alt lockstep_iter_size(tt_dotdotdot(sp, tts, sep, zerok), r) {\n               lis_unconstrained {\n-                r.span_diagnostic.span_fatal(\n-                    copy r.cur_span, /* blame macro writer */\n+                r.sp_diag.span_fatal(\n+                    sp, /* blame macro writer */\n                     \"attempted to repeat an expression containing no syntax \\\n                      variables matched as repeating at this depth\");\n               }\n-              lis_contradiction(msg) { /* blame macro invoker */\n-                r.span_diagnostic.span_fatal(sp, msg);\n+              lis_contradiction(msg) { /* TODO blame macro invoker instead*/\n+                r.sp_diag.span_fatal(sp, msg);\n               }\n               lis_constraint(len, _) {\n-                if len == 0 && !zerok {\n-                    r.span_diagnostic.span_fatal(sp, \"this must repeat \\\n-                                                      at least once\");\n-                }\n                 vec::push(r.repeat_len, len);\n                 vec::push(r.repeat_idx, 0u);\n                 r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: true,\n                           sep: sep, up: tt_frame_up(option::some(r.cur)) };\n+\n+                if len == 0 {\n+                    if !zerok {\n+                        r.sp_diag.span_fatal(sp, /* TODO blame invoker */\n+                                             \"this must repeat at least \\\n+                                              once\");\n+                    }\n+                    /* we need to pop before we proceed, so recur */\n+                    ret tt_next_token(r);\n+                }\n               }\n             }\n           }\n@@ -219,7 +223,7 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n                 ret ret_val;\n               }\n               seq(*) {\n-                r.span_diagnostic.span_fatal(\n+                r.sp_diag.span_fatal(\n                     copy r.cur_span, /* blame the macro writer */\n                     #fmt[\"variable '%s' is still repeating at this depth\",\n                          *ident]);"}, {"sha": "b3ba35dea2ef797e92aad87bcc498e1792512f6f", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -98,9 +98,9 @@ impl tt_reader_as_reader of reader for tt_reader {\n         tt_next_token(self)\n     }\n     fn fatal(m: str) -> ! {\n-        self.span_diagnostic.span_fatal(copy self.cur_span, m);\n+        self.sp_diag.span_fatal(copy self.cur_span, m);\n     }\n-    fn span_diag() -> span_handler { self.span_diagnostic }\n+    fn span_diag() -> span_handler { self.sp_diag }\n     fn interner() -> @interner<@str> { self.interner }\n     fn peek() -> {tok: token::token, sp: span} {\n         { tok: self.cur_tok, sp: self.cur_span }"}, {"sha": "b800dc7fda3adaba0348be26c7c38884cc7a5ccd", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 10, "deletions": 4, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -1022,9 +1022,12 @@ class parser {\n             /* `!`, as an operator, is prefix, so we know this isn't that */\n             if self.token == token::NOT {\n                 self.bump();\n-                let m_body = self.parse_token_tree();\n+                let tts = self.parse_unspanned_seq(\n+                    token::LBRACE, token::RBRACE, seq_sep_none(),\n+                    |p| p.parse_token_tree());\n                 let hi = self.span.hi;\n-                ret pexpr(self.mk_mac_expr(lo, hi, mac_invoc_tt(pth,m_body)));\n+\n+                ret pexpr(self.mk_mac_expr(lo, hi, mac_invoc_tt(pth, tts)));\n             } else {\n                 hi = pth.span.hi;\n                 ex = expr_path(pth);\n@@ -2642,14 +2645,17 @@ class parser {\n             self.parse_item_class()\n         } else if !self.is_any_keyword(copy self.token)\n             && self.look_ahead(1) == token::NOT\n+            && is_plain_ident(self.look_ahead(2))\n         {\n             // item macro.\n             let pth = self.parse_path_without_tps();\n             #error(\"parsing invocation of %s\", *pth.idents[0]);\n             self.expect(token::NOT);\n             let id = self.parse_ident();\n-            let tt = self.parse_token_tree();\n-            let m = ast::mac_invoc_tt(pth, tt);\n+            let tts = self.parse_unspanned_seq(token::LBRACE, token::RBRACE,\n+                                               seq_sep_none(),\n+                                               |p| p.parse_token_tree());\n+            let m = ast::mac_invoc_tt(pth, tts);\n             let m: ast::mac = {node: m,\n                                span: {lo: self.span.lo,\n                                       hi: self.span.hi,"}, {"sha": "b1a1677dfed7a821035433ef74596a2c37e045b2", "filename": "src/libsyntax/syntax.rc", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fsyntax.rc", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Flibsyntax%2Fsyntax.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsyntax.rc?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -68,11 +68,13 @@ mod ext {\n     mod tt {\n         mod transcribe;\n         mod earley_parser;\n+        mod macro_rules;\n     }\n \n+\n+    mod simplext;\n     mod fmt;\n     mod env;\n-    mod simplext;\n     mod concat_idents;\n     mod ident_to_str;\n     mod log_syntax;"}, {"sha": "29bd6e65f4f03f14aee8afb640c900c841be6b09", "filename": "src/test/run-pass/syntax-extension-source-utils.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/54741b9427541df4508a3a7423102a677ba3dce9/src%2Ftest%2Frun-pass%2Fsyntax-extension-source-utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/54741b9427541df4508a3a7423102a677ba3dce9/src%2Ftest%2Frun-pass%2Fsyntax-extension-source-utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fsyntax-extension-source-utils.rs?ref=54741b9427541df4508a3a7423102a677ba3dce9", "patch": "@@ -1,4 +1,4 @@\n-// This test is brittle! \n+// This test is brittle!\n // xfail-pretty - the pretty tests lose path information, breaking #include\n \n mod m1 {\n@@ -9,7 +9,7 @@ mod m1 {\n \n fn main() {\n     assert(#line[] == 11u);\n-    assert(#col[] == 12u);\n+    assert(#col[] == 11u);\n     assert(#file[].ends_with(\"syntax-extension-source-utils.rs\"));\n     assert(#stringify[(2*3) + 5] == \"2 * 3 + 5\");\n     assert(#include[\"syntax-extension-source-utils-files/includeme.fragment\"]"}]}