{"sha": "99582f88847b6c1feba61c4cbce7e95308d5103b", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk5NTgyZjg4ODQ3YjZjMWZlYmE2MWM0Y2JjZTdlOTUzMDhkNTEwM2I=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-01-17T03:54:24Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-02-03T20:04:30Z"}, "message": "std: Hardcode pthread constants and structures\n\nThis allows for easier static initialization of a pthread mutex, although the\nwindows mutexes still sadly suffer.\n\nNote that this commit removes the clone() method from a mutex because it no\nlonger makes sense for pthreads mutexes. This also removes the Once type for\nnow, but it'll get added back shortly.", "tree": {"sha": "bfb01ba7aa26a8a17cdd7d87b2bf470b122b1b22", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bfb01ba7aa26a8a17cdd7d87b2bf470b122b1b22"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/99582f88847b6c1feba61c4cbce7e95308d5103b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/99582f88847b6c1feba61c4cbce7e95308d5103b", "html_url": "https://github.com/rust-lang/rust/commit/99582f88847b6c1feba61c4cbce7e95308d5103b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/99582f88847b6c1feba61c4cbce7e95308d5103b/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "24631c8bcd294c07f9c9779628ac2da761d52d6f", "url": "https://api.github.com/repos/rust-lang/rust/commits/24631c8bcd294c07f9c9779628ac2da761d52d6f", "html_url": "https://github.com/rust-lang/rust/commit/24631c8bcd294c07f9c9779628ac2da761d52d6f"}], "stats": {"total": 563, "additions": 228, "deletions": 335}, "files": [{"sha": "da4f0a3b68a92cbb55f2d9236474d39b2fb8016d", "filename": "src/libgreen/sched.rs", "status": "modified", "additions": 11, "deletions": 15, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/99582f88847b6c1feba61c4cbce7e95308d5103b/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99582f88847b6c1feba61c4cbce7e95308d5103b/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=99582f88847b6c1feba61c4cbce7e95308d5103b", "patch": "@@ -1416,7 +1416,8 @@ mod test {\n \n     #[test]\n     fn test_spawn_sched_blocking() {\n-        use std::unstable::mutex::Mutex;\n+        use std::unstable::mutex::{Mutex, MUTEX_INIT};\n+        static mut LOCK: Mutex = MUTEX_INIT;\n \n         // Testing that a task in one scheduler can block in foreign code\n         // without affecting other schedulers\n@@ -1425,19 +1426,15 @@ mod test {\n             let (start_po, start_ch) = Chan::new();\n             let (fin_po, fin_ch) = Chan::new();\n \n-            let lock = unsafe { Mutex::new() };\n-            let lock2 = unsafe { lock.clone() };\n-\n             let mut handle = pool.spawn_sched();\n             handle.send(PinnedTask(pool.task(TaskOpts::new(), proc() {\n-                let mut lock = lock2;\n                 unsafe {\n-                    lock.lock();\n+                    LOCK.lock();\n \n                     start_ch.send(());\n-                    lock.wait();   // block the scheduler thread\n-                    lock.signal(); // let them know we have the lock\n-                    lock.unlock();\n+                    LOCK.wait();   // block the scheduler thread\n+                    LOCK.signal(); // let them know we have the lock\n+                    LOCK.unlock();\n                 }\n \n                 fin_ch.send(());\n@@ -1469,12 +1466,11 @@ mod test {\n                 child_ch.send(20);\n                 pingpong(&parent_po, &child_ch);\n                 unsafe {\n-                    let mut lock = lock;\n-                    lock.lock();\n-                    lock.signal();   // wakeup waiting scheduler\n-                    lock.wait();     // wait for them to grab the lock\n-                    lock.unlock();\n-                    lock.destroy();  // now we're guaranteed they have no locks\n+                    LOCK.lock();\n+                    LOCK.signal();   // wakeup waiting scheduler\n+                    LOCK.wait();     // wait for them to grab the lock\n+                    LOCK.unlock();\n+                    LOCK.destroy();  // now we're guaranteed they have no locks\n                 }\n             })));\n             drop(handle);"}, {"sha": "4804de756876f5e042ae2c010355149b5b2d2b08", "filename": "src/libstd/unstable/mutex.rs", "status": "modified", "additions": 217, "deletions": 300, "changes": 517, "blob_url": "https://github.com/rust-lang/rust/blob/99582f88847b6c1feba61c4cbce7e95308d5103b/src%2Flibstd%2Funstable%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/99582f88847b6c1feba61c4cbce7e95308d5103b/src%2Flibstd%2Funstable%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fmutex.rs?ref=99582f88847b6c1feba61c4cbce7e95308d5103b", "patch": "@@ -47,180 +47,186 @@\n \n #[allow(non_camel_case_types)];\n \n-use int;\n-use sync::atomics;\n-\n pub struct Mutex {\n-    // pointers for the lock/cond handles, atomically updated\n-    priv lock: atomics::AtomicUint,\n-    priv cond: atomics::AtomicUint,\n+    priv inner: imp::Mutex,\n }\n \n pub static MUTEX_INIT: Mutex = Mutex {\n-    lock: atomics::INIT_ATOMIC_UINT,\n-    cond: atomics::INIT_ATOMIC_UINT,\n+    inner: imp::MUTEX_INIT,\n };\n \n impl Mutex {\n-    /// Creates a new mutex, with the lock/condition variable pre-initialized\n+    /// Creates a new mutex\n     pub unsafe fn new() -> Mutex {\n-        Mutex {\n-            lock: atomics::AtomicUint::new(imp::init_lock()),\n-            cond: atomics::AtomicUint::new(imp::init_cond()),\n-        }\n-    }\n-\n-    /// Creates a new mutex, with the lock/condition variable not initialized.\n-    /// This is the same as initializing from the MUTEX_INIT static.\n-    pub unsafe fn empty() -> Mutex {\n-        Mutex {\n-            lock: atomics::AtomicUint::new(0),\n-            cond: atomics::AtomicUint::new(0),\n-        }\n-    }\n-\n-    /// Creates a new copy of this mutex. This is an unsafe operation because\n-    /// there is no reference counting performed on this type.\n-    ///\n-    /// This function may only be called on mutexes which have had both the\n-    /// internal condition variable and lock initialized. This means that the\n-    /// mutex must have been created via `new`, or usage of it has already\n-    /// initialized the internal handles.\n-    ///\n-    /// This is a dangerous function to call as both this mutex and the returned\n-    /// mutex will share the same handles to the underlying mutex/condition\n-    /// variable. Care must be taken to ensure that deallocation happens\n-    /// accordingly.\n-    pub unsafe fn clone(&self) -> Mutex {\n-        let lock = self.lock.load(atomics::Relaxed);\n-        let cond = self.cond.load(atomics::Relaxed);\n-        assert!(lock != 0);\n-        assert!(cond != 0);\n-        Mutex {\n-            lock: atomics::AtomicUint::new(lock),\n-            cond: atomics::AtomicUint::new(cond),\n-        }\n+        Mutex { inner: imp::Mutex::new() }\n     }\n \n     /// Acquires this lock. This assumes that the current thread does not\n     /// already hold the lock.\n-    pub unsafe fn lock(&mut self) { imp::lock(self.getlock()) }\n+    pub unsafe fn lock(&mut self) { self.inner.lock() }\n \n     /// Attempts to acquire the lock. The value returned is whether the lock was\n     /// acquired or not\n-    pub unsafe fn trylock(&mut self) -> bool { imp::trylock(self.getlock()) }\n+    pub unsafe fn trylock(&mut self) -> bool { self.inner.trylock() }\n \n     /// Unlocks the lock. This assumes that the current thread already holds the\n     /// lock.\n-    pub unsafe fn unlock(&mut self) { imp::unlock(self.getlock()) }\n+    pub unsafe fn unlock(&mut self) { self.inner.unlock() }\n \n     /// Block on the internal condition variable.\n     ///\n     /// This function assumes that the lock is already held\n-    pub unsafe fn wait(&mut self) { imp::wait(self.getcond(), self.getlock()) }\n+    pub unsafe fn wait(&mut self) { self.inner.wait() }\n \n     /// Signals a thread in `wait` to wake up\n-    pub unsafe fn signal(&mut self) { imp::signal(self.getcond()) }\n+    pub unsafe fn signal(&mut self) { self.inner.signal() }\n \n     /// This function is especially unsafe because there are no guarantees made\n     /// that no other thread is currently holding the lock or waiting on the\n     /// condition variable contained inside.\n-    pub unsafe fn destroy(&mut self) {\n-        let lock = self.lock.swap(0, atomics::Relaxed);\n-        let cond = self.cond.swap(0, atomics::Relaxed);\n-        if lock != 0 { imp::free_lock(lock) }\n-        if cond != 0 { imp::free_cond(cond) }\n-    }\n-\n-    unsafe fn getlock(&mut self) -> uint{\n-        match self.lock.load(atomics::Relaxed) {\n-            0 => {}\n-            n => return n\n-        }\n-        let lock = imp::init_lock();\n-        match self.lock.compare_and_swap(0, lock, atomics::SeqCst) {\n-            0 => return lock,\n-            _ => {}\n-        }\n-        imp::free_lock(lock);\n-        self.lock.load(atomics::Relaxed)\n-    }\n-\n-    unsafe fn getcond(&mut self) -> uint {\n-        match self.cond.load(atomics::Relaxed) {\n-            0 => {}\n-            n => return n\n-        }\n-        let cond = imp::init_cond();\n-        match self.cond.compare_and_swap(0, cond, atomics::SeqCst) {\n-            0 => return cond,\n-            _ => {}\n-        }\n-        imp::free_cond(cond);\n-        self.cond.load(atomics::Relaxed)\n-    }\n+    pub unsafe fn destroy(&mut self) { self.inner.destroy() }\n }\n \n #[cfg(unix)]\n mod imp {\n     use libc;\n-    use ptr;\n-    use rt::global_heap::malloc_raw;\n+    use self::os::{PTHREAD_MUTEX_INITIALIZER, PTHREAD_COND_INITIALIZER,\n+                   pthread_mutex_t, pthread_cond_t};\n+    use unstable::intrinsics;\n \n-    type pthread_mutex_t = libc::c_void;\n     type pthread_mutexattr_t = libc::c_void;\n-    type pthread_cond_t = libc::c_void;\n     type pthread_condattr_t = libc::c_void;\n \n-    pub unsafe fn init_lock() -> uint {\n-        let block = malloc_raw(rust_pthread_mutex_t_size() as uint) as *mut pthread_mutex_t;\n-        let n = pthread_mutex_init(block, ptr::null());\n-        assert_eq!(n, 0);\n-        return block as uint;\n-    }\n+    #[cfg(target_os = \"freebsd\")]\n+    mod os {\n+        use libc;\n+\n+        pub type pthread_mutex_t = *libc::c_void;\n+        pub type pthread_cond_t = *libc::c_void;\n+\n+        pub static PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t =\n+            0 as pthread_mutex_t;\n+        pub static PTHREAD_COND_INITIALIZER: pthread_cond_t =\n+            0 as pthread_cond_t;\n+    }\n+\n+    #[cfg(target_os = \"macos\")]\n+    mod os {\n+        use libc;\n+\n+        #[cfg(target_arch = \"x86_64\")]\n+        static __PTHREAD_MUTEX_SIZE__: uint = 56;\n+        #[cfg(target_arch = \"x86_64\")]\n+        static __PTHREAD_COND_SIZE__: uint = 40;\n+        #[cfg(target_arch = \"x86\")]\n+        static __PTHREAD_MUTEX_SIZE__: uint = 40;\n+        #[cfg(target_arch = \"x86\")]\n+        static __PTHREAD_COND_SIZE__: uint = 24;\n+        static _PTHREAD_MUTEX_SIG_init: libc::c_long = 0x32AAABA7;\n+        static _PTHREAD_COND_SIG_init: libc::c_long = 0x3CB0B1BB;\n+\n+        pub struct pthread_mutex_t {\n+            __sig: libc::c_long,\n+            __opaque: [u8, ..__PTHREAD_MUTEX_SIZE__],\n+        }\n+        pub struct pthread_cond_t {\n+            __sig: libc::c_long,\n+            __opaque: [u8, ..__PTHREAD_COND_SIZE__],\n+        }\n \n-    pub unsafe fn init_cond() -> uint {\n-        let block = malloc_raw(rust_pthread_cond_t_size() as uint) as *mut pthread_cond_t;\n-        let n = pthread_cond_init(block, ptr::null());\n-        assert_eq!(n, 0);\n-        return block as uint;\n-    }\n+        pub static PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = pthread_mutex_t {\n+            __sig: _PTHREAD_MUTEX_SIG_init,\n+            __opaque: [0, ..__PTHREAD_MUTEX_SIZE__],\n+        };\n+        pub static PTHREAD_COND_INITIALIZER: pthread_cond_t = pthread_cond_t {\n+            __sig: _PTHREAD_COND_SIG_init,\n+            __opaque: [0, ..__PTHREAD_COND_SIZE__],\n+        };\n+    }\n+\n+    #[cfg(target_os = \"linux\")]\n+    mod os {\n+        use libc;\n+\n+        // minus 8 because we have an 'align' field\n+        #[cfg(target_arch = \"x86_64\")]\n+        static __SIZEOF_PTHREAD_MUTEX_T: uint = 40 - 8;\n+        #[cfg(target_arch = \"x86\")]\n+        static __SIZEOF_PTHREAD_MUTEX_T: uint = 24 - 8;\n+        #[cfg(target_arch = \"x86_64\")]\n+        static __SIZEOF_PTHREAD_COND_T: uint = 48 - 8;\n+        #[cfg(target_arch = \"x86\")]\n+        static __SIZEOF_PTHREAD_COND_T: uint = 48 - 8;\n+\n+        pub struct pthread_mutex_t {\n+            __align: libc::c_long,\n+            size: [u8, ..__SIZEOF_PTHREAD_MUTEX_T],\n+        }\n+        pub struct pthread_cond_t {\n+            __align: libc::c_longlong,\n+            size: [u8, ..__SIZEOF_PTHREAD_COND_T],\n+        }\n \n-    pub unsafe fn free_lock(h: uint) {\n-        let block = h as *mut libc::c_void;\n-        assert_eq!(pthread_mutex_destroy(block), 0);\n-        libc::free(block);\n+        pub static PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = pthread_mutex_t {\n+            __align: 0,\n+            size: [0, ..__SIZEOF_PTHREAD_MUTEX_T],\n+        };\n+        pub static PTHREAD_COND_INITIALIZER: pthread_cond_t = pthread_cond_t {\n+            __align: 0,\n+            size: [0, ..__SIZEOF_PTHREAD_COND_T],\n+        };\n     }\n+    #[cfg(target_os = \"android\")]\n+    mod os {\n+        use libc;\n \n-    pub unsafe fn free_cond(h: uint) {\n-        let block = h as *mut pthread_cond_t;\n-        assert_eq!(pthread_cond_destroy(block), 0);\n-        libc::free(block);\n-    }\n+        pub struct pthread_mutex_t { value: libc::c_int }\n+        pub struct pthread_cond_t { value: libc::c_int }\n \n-    pub unsafe fn lock(l: uint) {\n-        assert_eq!(pthread_mutex_lock(l as *mut pthread_mutex_t), 0);\n+        pub static PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = pthread_mutex_t {\n+            value: 0,\n+        };\n+        pub static PTHREAD_COND_INITIALIZER: pthread_cond_t = pthread_cond_t {\n+            value: 0,\n+        };\n     }\n \n-    pub unsafe fn trylock(l: uint) -> bool {\n-        pthread_mutex_trylock(l as *mut pthread_mutex_t) == 0\n+    pub struct Mutex {\n+        priv lock: pthread_mutex_t,\n+        priv cond: pthread_cond_t,\n     }\n \n-    pub unsafe fn unlock(l: uint) {\n-        assert_eq!(pthread_mutex_unlock(l as *mut pthread_mutex_t), 0);\n-    }\n+    pub static MUTEX_INIT: Mutex = Mutex {\n+        lock: PTHREAD_MUTEX_INITIALIZER,\n+        cond: PTHREAD_COND_INITIALIZER,\n+    };\n \n-    pub unsafe fn wait(cond: uint, m: uint) {\n-        assert_eq!(pthread_cond_wait(cond as *mut pthread_cond_t, m as *mut pthread_mutex_t), 0);\n-    }\n+    impl Mutex {\n+        pub unsafe fn new() -> Mutex {\n+            let mut m = Mutex {\n+                lock: intrinsics::init(),\n+                cond: intrinsics::init(),\n+            };\n \n-    pub unsafe fn signal(cond: uint) {\n-        assert_eq!(pthread_cond_signal(cond as *mut pthread_cond_t), 0);\n-    }\n+            pthread_mutex_init(&mut m.lock, 0 as *libc::c_void);\n+            pthread_cond_init(&mut m.cond, 0 as *libc::c_void);\n \n-    extern {\n-        fn rust_pthread_mutex_t_size() -> libc::c_int;\n-        fn rust_pthread_cond_t_size() -> libc::c_int;\n+            return m;\n+        }\n+\n+        pub unsafe fn lock(&mut self) { pthread_mutex_lock(&mut self.lock); }\n+        pub unsafe fn unlock(&mut self) { pthread_mutex_unlock(&mut self.lock); }\n+        pub unsafe fn signal(&mut self) { pthread_cond_signal(&mut self.cond); }\n+        pub unsafe fn wait(&mut self) {\n+            pthread_cond_wait(&mut self.cond, &mut self.lock);\n+        }\n+        pub unsafe fn trylock(&mut self) -> bool {\n+            pthread_mutex_trylock(&mut self.lock) == 0\n+        }\n+        pub unsafe fn destroy(&mut self) {\n+            pthread_mutex_destroy(&mut self.lock);\n+            pthread_cond_destroy(&mut self.cond);\n+        }\n     }\n \n     extern {\n@@ -242,16 +248,96 @@ mod imp {\n \n #[cfg(windows)]\n mod imp {\n-    use libc;\n+    use rt::global_heap::malloc_raw;\n     use libc::{HANDLE, BOOL, LPSECURITY_ATTRIBUTES, c_void, DWORD, LPCSTR};\n+    use libc;\n     use ptr;\n-    use rt::global_heap::malloc_raw;\n+    use sync::atomics;\n \n-    type LPCRITICAL_SECTION = *c_void;\n+    type LPCRITICAL_SECTION = *mut c_void;\n     static SPIN_COUNT: DWORD = 4000;\n+    #[cfg(target_arch = \"x86\")]\n+    static CRIT_SECTION_SIZE: uint = 24;\n+\n+    pub struct Mutex {\n+        // pointers for the lock/cond handles, atomically updated\n+        priv lock: atomics::AtomicUint,\n+        priv cond: atomics::AtomicUint,\n+    }\n+\n+    pub static MUTEX_INIT: Mutex = Mutex {\n+        lock: atomics::INIT_ATOMIC_UINT,\n+        cond: atomics::INIT_ATOMIC_UINT,\n+    };\n+\n+    impl Mutex {\n+        pub unsafe fn new() -> Mutex {\n+            Mutex {\n+                lock: atomics::AtomicUint::new(init_lock()),\n+                cond: atomics::AtomicUint::new(init_cond()),\n+            }\n+        }\n+        pub unsafe fn lock(&mut self) {\n+            EnterCriticalSection(self.getlock() as LPCRITICAL_SECTION)\n+        }\n+        pub unsafe fn trylock(&mut self) -> bool {\n+            TryEnterCriticalSection(self.getlock() as LPCRITICAL_SECTION) != 0\n+        }\n+        pub unsafe fn unlock(&mut self) {\n+            LeaveCriticalSection(self.getlock() as LPCRITICAL_SECTION)\n+        }\n+\n+        pub unsafe fn wait(&mut self) {\n+            self.unlock();\n+            WaitForSingleObject(self.getcond() as HANDLE, libc::INFINITE);\n+            self.lock();\n+        }\n+\n+        pub unsafe fn signal(&mut self) {\n+            assert!(SetEvent(self.getcond() as HANDLE) != 0);\n+        }\n+\n+        /// This function is especially unsafe because there are no guarantees made\n+        /// that no other thread is currently holding the lock or waiting on the\n+        /// condition variable contained inside.\n+        pub unsafe fn destroy(&mut self) {\n+            let lock = self.lock.swap(0, atomics::SeqCst);\n+            let cond = self.cond.swap(0, atomics::SeqCst);\n+            if lock != 0 { free_lock(lock) }\n+            if cond != 0 { free_cond(cond) }\n+        }\n+\n+        unsafe fn getlock(&mut self) -> *mut c_void {\n+            match self.lock.load(atomics::SeqCst) {\n+                0 => {}\n+                n => return n as *mut c_void\n+            }\n+            let lock = init_lock();\n+            match self.lock.compare_and_swap(0, lock, atomics::SeqCst) {\n+                0 => return lock as *mut c_void,\n+                _ => {}\n+            }\n+            free_lock(lock);\n+            return self.lock.load(atomics::SeqCst) as *mut c_void;\n+        }\n+\n+        unsafe fn getcond(&mut self) -> *mut c_void {\n+            match self.cond.load(atomics::SeqCst) {\n+                0 => {}\n+                n => return n as *mut c_void\n+            }\n+            let cond = init_cond();\n+            match self.cond.compare_and_swap(0, cond, atomics::SeqCst) {\n+                0 => return cond as *mut c_void,\n+                _ => {}\n+            }\n+            free_cond(cond);\n+            return self.cond.load(atomics::SeqCst) as *mut c_void;\n+        }\n+    }\n \n     pub unsafe fn init_lock() -> uint {\n-        let block = malloc_raw(rust_crit_section_size() as uint) as *c_void;\n+        let block = malloc_raw(CRIT_SECTION_SIZE as uint) as *mut c_void;\n         InitializeCriticalSectionAndSpinCount(block, SPIN_COUNT);\n         return block as uint;\n     }\n@@ -271,32 +357,6 @@ mod imp {\n         libc::CloseHandle(block);\n     }\n \n-    pub unsafe fn lock(l: uint) {\n-        EnterCriticalSection(l as LPCRITICAL_SECTION)\n-    }\n-\n-    pub unsafe fn trylock(l: uint) -> bool {\n-        TryEnterCriticalSection(l as LPCRITICAL_SECTION) != 0\n-    }\n-\n-    pub unsafe fn unlock(l: uint) {\n-        LeaveCriticalSection(l as LPCRITICAL_SECTION)\n-    }\n-\n-    pub unsafe fn wait(cond: uint, m: uint) {\n-        unlock(m);\n-        WaitForSingleObject(cond as HANDLE, libc::INFINITE);\n-        lock(m);\n-    }\n-\n-    pub unsafe fn signal(cond: uint) {\n-        assert!(SetEvent(cond as HANDLE) != 0);\n-    }\n-\n-    extern {\n-        fn rust_crit_section_size() -> libc::c_int;\n-    }\n-\n     extern \"system\" {\n         fn CreateEventA(lpSecurityAttributes: LPSECURITY_ATTRIBUTES,\n                         bManualReset: BOOL,\n@@ -314,157 +374,14 @@ mod imp {\n     }\n }\n \n-/// A type which can be used to run a one-time global initialization. This type\n-/// is *unsafe* to use because it is built on top of the `Mutex` in this module.\n-/// It does not know whether the currently running task is in a green or native\n-/// context, and a blocking mutex should *not* be used under normal\n-/// circumstances on a green task.\n-///\n-/// Despite its unsafety, it is often useful to have a one-time initialization\n-/// routine run for FFI bindings or related external functionality. This type\n-/// can only be statically constructed with the `ONCE_INIT` value.\n-///\n-/// # Example\n-///\n-/// ```rust\n-/// use std::unstable::mutex::{Once, ONCE_INIT};\n-///\n-/// static mut START: Once = ONCE_INIT;\n-/// unsafe {\n-///     START.doit(|| {\n-///         // run initialization here\n-///     });\n-/// }\n-/// ```\n-pub struct Once {\n-    priv mutex: Mutex,\n-    priv cnt: atomics::AtomicInt,\n-    priv lock_cnt: atomics::AtomicInt,\n-}\n-\n-/// Initialization value for static `Once` values.\n-pub static ONCE_INIT: Once = Once {\n-    mutex: MUTEX_INIT,\n-    cnt: atomics::INIT_ATOMIC_INT,\n-    lock_cnt: atomics::INIT_ATOMIC_INT,\n-};\n-\n-impl Once {\n-    /// Perform an initialization routine once and only once. The given closure\n-    /// will be executed if this is the first time `doit` has been called, and\n-    /// otherwise the routine will *not* be invoked.\n-    ///\n-    /// This method will block the calling *os thread* if another initialization\n-    /// routine is currently running.\n-    ///\n-    /// When this function returns, it is guaranteed that some initialization\n-    /// has run and completed (it may not be the closure specified).\n-    pub fn doit(&mut self, f: ||) {\n-        // Implementation-wise, this would seem like a fairly trivial primitive.\n-        // The stickler part is where our mutexes currently require an\n-        // allocation, and usage of a `Once` should't leak this allocation.\n-        //\n-        // This means that there must be a deterministic destroyer of the mutex\n-        // contained within (because it's not needed after the initialization\n-        // has run).\n-        //\n-        // The general scheme here is to gate all future threads once\n-        // initialization has completed with a \"very negative\" count, and to\n-        // allow through threads to lock the mutex if they see a non negative\n-        // count. For all threads grabbing the mutex, exactly one of them should\n-        // be responsible for unlocking the mutex, and this should only be done\n-        // once everyone else is done with the mutex.\n-        //\n-        // This atomicity is achieved by swapping a very negative value into the\n-        // shared count when the initialization routine has completed. This will\n-        // read the number of threads which will at some point attempt to\n-        // acquire the mutex. This count is then squirreled away in a separate\n-        // variable, and the last person on the way out of the mutex is then\n-        // responsible for destroying the mutex.\n-        //\n-        // It is crucial that the negative value is swapped in *after* the\n-        // initialization routine has completed because otherwise new threads\n-        // calling `doit` will return immediately before the initialization has\n-        // completed.\n-\n-        let prev = self.cnt.fetch_add(1, atomics::SeqCst);\n-        if prev < 0 {\n-            // Make sure we never overflow, we'll never have int::MIN\n-            // simultaneous calls to `doit` to make this value go back to 0\n-            self.cnt.store(int::MIN, atomics::SeqCst);\n-            return\n-        }\n-\n-        // If the count is negative, then someone else finished the job,\n-        // otherwise we run the job and record how many people will try to grab\n-        // this lock\n-        unsafe { self.mutex.lock() }\n-        if self.cnt.load(atomics::SeqCst) > 0 {\n-            f();\n-            let prev = self.cnt.swap(int::MIN, atomics::SeqCst);\n-            self.lock_cnt.store(prev, atomics::SeqCst);\n-        }\n-        unsafe { self.mutex.unlock() }\n-\n-        // Last one out cleans up after everyone else, no leaks!\n-        if self.lock_cnt.fetch_add(-1, atomics::SeqCst) == 1 {\n-            unsafe { self.mutex.destroy() }\n-        }\n-    }\n-}\n-\n #[cfg(test)]\n mod test {\n     use prelude::*;\n \n+    use super::{Mutex, MUTEX_INIT};\n     use rt::thread::Thread;\n-    use super::{ONCE_INIT, Once, Mutex, MUTEX_INIT};\n     use task;\n \n-    #[test]\n-    fn smoke_once() {\n-        static mut o: Once = ONCE_INIT;\n-        let mut a = 0;\n-        unsafe { o.doit(|| a += 1); }\n-        assert_eq!(a, 1);\n-        unsafe { o.doit(|| a += 1); }\n-        assert_eq!(a, 1);\n-    }\n-\n-    #[test]\n-    fn stampede_once() {\n-        static mut o: Once = ONCE_INIT;\n-        static mut run: bool = false;\n-\n-        let (p, c) = SharedChan::new();\n-        for _ in range(0, 10) {\n-            let c = c.clone();\n-            spawn(proc() {\n-                for _ in range(0, 4) { task::deschedule() }\n-                unsafe {\n-                    o.doit(|| {\n-                        assert!(!run);\n-                        run = true;\n-                    });\n-                    assert!(run);\n-                }\n-                c.send(());\n-            });\n-        }\n-\n-        unsafe {\n-            o.doit(|| {\n-                assert!(!run);\n-                run = true;\n-            });\n-            assert!(run);\n-        }\n-\n-        for _ in range(0, 10) {\n-            p.recv();\n-        }\n-    }\n-\n     #[test]\n     fn somke_lock() {\n         static mut lock: Mutex = MUTEX_INIT;\n@@ -493,7 +410,7 @@ mod test {\n     #[test]\n     fn destroy_immediately() {\n         unsafe {\n-            let mut m = Mutex::empty();\n+            let mut m = Mutex::new();\n             m.destroy();\n         }\n     }"}, {"sha": "81eba2984dad0aa8e6f79b1f8f8bb902ece7dbf2", "filename": "src/rt/rust_builtin.c", "status": "modified", "additions": 0, "deletions": 20, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/99582f88847b6c1feba61c4cbce7e95308d5103b/src%2Frt%2Frust_builtin.c", "raw_url": "https://github.com/rust-lang/rust/raw/99582f88847b6c1feba61c4cbce7e95308d5103b/src%2Frt%2Frust_builtin.c", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_builtin.c?ref=99582f88847b6c1feba61c4cbce7e95308d5103b", "patch": "@@ -437,26 +437,6 @@ rust_win32_rand_release() {\n \n #endif\n \n-#if defined(__WIN32__)\n-\n-int\n-rust_crit_section_size() { return sizeof(CRITICAL_SECTION); }\n-int\n-rust_pthread_mutex_t_size() { return 0; }\n-int\n-rust_pthread_cond_t_size() { return 0; }\n-\n-#else\n-\n-int\n-rust_crit_section_size() { return 0; }\n-int\n-rust_pthread_mutex_t_size() { return sizeof(pthread_mutex_t); }\n-int\n-rust_pthread_cond_t_size() { return sizeof(pthread_cond_t); }\n-\n-#endif\n-\n //\n // Local Variables:\n // mode: C++"}]}