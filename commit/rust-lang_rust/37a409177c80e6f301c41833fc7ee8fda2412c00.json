{"sha": "37a409177c80e6f301c41833fc7ee8fda2412c00", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM3YTQwOTE3N2M4MGU2ZjMwMWM0MTgzM2ZjN2VlOGZkYTI0MTJjMDA=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-05-18T21:49:38Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-05-18T21:49:38Z"}, "message": "Auto merge of #50319 - nagisa:align_to, r=alexcrichton\n\nImplement [T]::align_to\n\nNote that this PR deviates from what is accepted by RFC slightly by making `align_offset` to return an offset in elements, rather than bytes. This is necessary to sanely support `[T]::align_to` and also simply makes more sense\u2122. The caveat is that trying to align a pointer of ZST is now an equivalent to `is_aligned` check, rather than anything else (as no number of ZST elements will align a misaligned ZST pointer).\n\nIt also implements the `align_to` slightly differently than proposed in the RFC to properly handle cases where size of T and U aren\u2019t co-prime.\n\nFurthermore, a promise is made that the slice containing `U`s will be as large as possible (contrary to the RFC) \u2013 otherwise the function is quite useless.\n\nThe implementation uses quite a few underhanded tricks and takes advantage of the fact that alignment is a power-of-two quite heavily to optimise the machine code down to something that results in as few known-expensive instructions as possible. Currently calling `ptr.align_offset` with an unknown-at-compile-time `align` results in code that has just a single \"expensive\" modulo operation; the rest is \"cheap\" arithmetic and bitwise ops.\n\ncc https://github.com/rust-lang/rust/issues/44488 @oli-obk\n\nAs mentioned in the commit message for align_offset, many thanks go to Chris McDonald.", "tree": {"sha": "e5f1161550985792701d06edfb9584d1a6b6fe5d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e5f1161550985792701d06edfb9584d1a6b6fe5d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/37a409177c80e6f301c41833fc7ee8fda2412c00", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/37a409177c80e6f301c41833fc7ee8fda2412c00", "html_url": "https://github.com/rust-lang/rust/commit/37a409177c80e6f301c41833fc7ee8fda2412c00", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/37a409177c80e6f301c41833fc7ee8fda2412c00/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "952f344cdc0bca58d9f6c54dcfbae0890246e886", "url": "https://api.github.com/repos/rust-lang/rust/commits/952f344cdc0bca58d9f6c54dcfbae0890246e886", "html_url": "https://github.com/rust-lang/rust/commit/952f344cdc0bca58d9f6c54dcfbae0890246e886"}, {"sha": "59bb0fe66ea6d80c5e1466b9609887e4cf7cde47", "url": "https://api.github.com/repos/rust-lang/rust/commits/59bb0fe66ea6d80c5e1466b9609887e4cf7cde47", "html_url": "https://github.com/rust-lang/rust/commit/59bb0fe66ea6d80c5e1466b9609887e4cf7cde47"}], "stats": {"total": 632, "additions": 521, "deletions": 111}, "files": [{"sha": "2e3f5cb65c9263f3c37285209dcc1693b6f79b4e", "filename": "src/libcore/intrinsics.rs", "status": "modified", "additions": 2, "deletions": 32, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fintrinsics.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -1364,38 +1364,8 @@ extern \"rust-intrinsic\" {\n     /// source as well as std's catch implementation.\n     pub fn try(f: fn(*mut u8), data: *mut u8, local_ptr: *mut u8) -> i32;\n \n-    /// Computes the byte offset that needs to be applied to `ptr` in order to\n-    /// make it aligned to `align`.\n-    /// If it is not possible to align `ptr`, the implementation returns\n-    /// `usize::max_value()`.\n-    ///\n-    /// There are no guarantees whatsover that offsetting the pointer will not\n-    /// overflow or go beyond the allocation that `ptr` points into.\n-    /// It is up to the caller to ensure that the returned offset is correct\n-    /// in all terms other than alignment.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Accessing adjacent `u8` as `u16`\n-    ///\n-    /// ```\n-    /// # #![feature(core_intrinsics)]\n-    /// # fn foo(n: usize) {\n-    /// # use std::intrinsics::align_offset;\n-    /// # use std::mem::align_of;\n-    /// # unsafe {\n-    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n-    /// let ptr = &x[n] as *const u8;\n-    /// let offset = align_offset(ptr as *const (), align_of::<u16>());\n-    /// if offset < x.len() - n - 1 {\n-    ///     let u16_ptr = ptr.offset(offset as isize) as *const u16;\n-    ///     assert_ne!(*u16_ptr, 500);\n-    /// } else {\n-    ///     // while the pointer can be aligned via `offset`, it would point\n-    ///     // outside the allocation\n-    /// }\n-    /// # } }\n-    /// ```\n+    #[cfg(stage0)]\n+    /// docs my friends, its friday!\n     pub fn align_offset(ptr: *const (), align: usize) -> usize;\n \n     /// Emits a `!nontemporal` store according to LLVM (see their docs)."}, {"sha": "6c0709caa084b045eda0ac1f7d8cc63e02f3651e", "filename": "src/libcore/ptr.rs", "status": "modified", "additions": 224, "deletions": 46, "changes": 270, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Fptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Fptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fptr.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -1203,15 +1203,22 @@ impl<T: ?Sized> *const T {\n         copy_nonoverlapping(self, dest, count)\n     }\n \n-    /// Computes the byte offset that needs to be applied in order to\n-    /// make the pointer aligned to `align`.\n+    /// Computes the offset that needs to be applied to the pointer in order to make it aligned to\n+    /// `align`.\n+    ///\n     /// If it is not possible to align the pointer, the implementation returns\n     /// `usize::max_value()`.\n     ///\n-    /// There are no guarantees whatsover that offsetting the pointer will not\n-    /// overflow or go beyond the allocation that the pointer points into.\n-    /// It is up to the caller to ensure that the returned offset is correct\n-    /// in all terms other than alignment.\n+    /// The offset is expressed in number of `T` elements, and not bytes. The value returned can be\n+    /// used with the `offset` or `offset_to` methods.\n+    ///\n+    /// There are no guarantees whatsover that offsetting the pointer will not overflow or go\n+    /// beyond the allocation that the pointer points into. It is up to the caller to ensure that\n+    /// the returned offset is correct in all terms other than alignment.\n+    ///\n+    /// # Panics\n+    ///\n+    /// The function panics if `align` is not a power-of-two.\n     ///\n     /// # Examples\n     ///\n@@ -1235,13 +1242,30 @@ impl<T: ?Sized> *const T {\n     /// # } }\n     /// ```\n     #[unstable(feature = \"align_offset\", issue = \"44488\")]\n-    pub fn align_offset(self, align: usize) -> usize {\n+    #[cfg(not(stage0))]\n+    pub fn align_offset(self, align: usize) -> usize where T: Sized {\n+        if !align.is_power_of_two() {\n+            panic!(\"align_offset: align is not a power-of-two\");\n+        }\n+        unsafe {\n+            align_offset(self, align)\n+        }\n+    }\n+\n+    /// definitely docs.\n+    #[unstable(feature = \"align_offset\", issue = \"44488\")]\n+    #[cfg(stage0)]\n+    pub fn align_offset(self, align: usize) -> usize where T: Sized {\n+        if !align.is_power_of_two() {\n+            panic!(\"align_offset: align is not a power-of-two\");\n+        }\n         unsafe {\n-            intrinsics::align_offset(self as *const _, align)\n+            intrinsics::align_offset(self as *const (), align)\n         }\n     }\n }\n \n+\n #[lang = \"mut_ptr\"]\n impl<T: ?Sized> *mut T {\n     /// Returns `true` if the pointer is null.\n@@ -1574,44 +1598,6 @@ impl<T: ?Sized> *mut T {\n         (self as *const T).wrapping_offset_from(origin)\n     }\n \n-    /// Computes the byte offset that needs to be applied in order to\n-    /// make the pointer aligned to `align`.\n-    /// If it is not possible to align the pointer, the implementation returns\n-    /// `usize::max_value()`.\n-    ///\n-    /// There are no guarantees whatsover that offsetting the pointer will not\n-    /// overflow or go beyond the allocation that the pointer points into.\n-    /// It is up to the caller to ensure that the returned offset is correct\n-    /// in all terms other than alignment.\n-    ///\n-    /// # Examples\n-    ///\n-    /// Accessing adjacent `u8` as `u16`\n-    ///\n-    /// ```\n-    /// # #![feature(align_offset)]\n-    /// # fn foo(n: usize) {\n-    /// # use std::mem::align_of;\n-    /// # unsafe {\n-    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n-    /// let ptr = &x[n] as *const u8;\n-    /// let offset = ptr.align_offset(align_of::<u16>());\n-    /// if offset < x.len() - n - 1 {\n-    ///     let u16_ptr = ptr.offset(offset as isize) as *const u16;\n-    ///     assert_ne!(*u16_ptr, 500);\n-    /// } else {\n-    ///     // while the pointer can be aligned via `offset`, it would point\n-    ///     // outside the allocation\n-    /// }\n-    /// # } }\n-    /// ```\n-    #[unstable(feature = \"align_offset\", issue = \"44488\")]\n-    pub fn align_offset(self, align: usize) -> usize {\n-        unsafe {\n-            intrinsics::align_offset(self as *const _, align)\n-        }\n-    }\n-\n     /// Calculates the offset from a pointer (convenience for `.offset(count as isize)`).\n     ///\n     /// `count` is in units of T; e.g. a `count` of 3 represents a pointer\n@@ -2281,8 +2267,200 @@ impl<T: ?Sized> *mut T {\n     {\n         swap(self, with)\n     }\n+\n+    /// Computes the offset that needs to be applied to the pointer in order to make it aligned to\n+    /// `align`.\n+    ///\n+    /// If it is not possible to align the pointer, the implementation returns\n+    /// `usize::max_value()`.\n+    ///\n+    /// The offset is expressed in number of `T` elements, and not bytes. The value returned can be\n+    /// used with the `offset` or `offset_to` methods.\n+    ///\n+    /// There are no guarantees whatsover that offsetting the pointer will not overflow or go\n+    /// beyond the allocation that the pointer points into. It is up to the caller to ensure that\n+    /// the returned offset is correct in all terms other than alignment.\n+    ///\n+    /// # Panics\n+    ///\n+    /// The function panics if `align` is not a power-of-two.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Accessing adjacent `u8` as `u16`\n+    ///\n+    /// ```\n+    /// # #![feature(align_offset)]\n+    /// # fn foo(n: usize) {\n+    /// # use std::mem::align_of;\n+    /// # unsafe {\n+    /// let x = [5u8, 6u8, 7u8, 8u8, 9u8];\n+    /// let ptr = &x[n] as *const u8;\n+    /// let offset = ptr.align_offset(align_of::<u16>());\n+    /// if offset < x.len() - n - 1 {\n+    ///     let u16_ptr = ptr.offset(offset as isize) as *const u16;\n+    ///     assert_ne!(*u16_ptr, 500);\n+    /// } else {\n+    ///     // while the pointer can be aligned via `offset`, it would point\n+    ///     // outside the allocation\n+    /// }\n+    /// # } }\n+    /// ```\n+    #[unstable(feature = \"align_offset\", issue = \"44488\")]\n+    #[cfg(not(stage0))]\n+    pub fn align_offset(self, align: usize) -> usize where T: Sized {\n+        if !align.is_power_of_two() {\n+            panic!(\"align_offset: align is not a power-of-two\");\n+        }\n+        unsafe {\n+            align_offset(self, align)\n+        }\n+    }\n+\n+    /// definitely docs.\n+    #[unstable(feature = \"align_offset\", issue = \"44488\")]\n+    #[cfg(stage0)]\n+    pub fn align_offset(self, align: usize) -> usize where T: Sized {\n+        if !align.is_power_of_two() {\n+            panic!(\"align_offset: align is not a power-of-two\");\n+        }\n+        unsafe {\n+            intrinsics::align_offset(self as *const (), align)\n+        }\n+    }\n+}\n+\n+/// Align pointer `p`.\n+///\n+/// Calculate offset (in terms of elements of `stride` stride) that has to be applied\n+/// to pointer `p` so that pointer `p` would get aligned to `a`.\n+///\n+/// Note: This implementation has been carefully tailored to not panic. It is UB for this to panic.\n+/// The only real change that can be made here is change of `INV_TABLE_MOD_16` and associated\n+/// constants.\n+///\n+/// If we ever decide to make it possible to call the intrinsic with `a` that is not a\n+/// power-of-two, it will probably be more prudent to just change to a naive implementation rather\n+/// than trying to adapt this to accomodate that change.\n+///\n+/// Any questions go to @nagisa.\n+#[lang=\"align_offset\"]\n+#[cfg(not(stage0))]\n+pub(crate) unsafe fn align_offset<T: Sized>(p: *const T, a: usize) -> usize {\n+    /// Calculate multiplicative modular inverse of `x` modulo `m`.\n+    ///\n+    /// This implementation is tailored for align_offset and has following preconditions:\n+    ///\n+    /// * `m` is a power-of-two;\n+    /// * `x < m`; (if `x \u2265 m`, pass in `x % m` instead)\n+    ///\n+    /// Implementation of this function shall not panic. Ever.\n+    #[inline]\n+    fn mod_inv(x: usize, m: usize) -> usize {\n+        /// Multiplicative modular inverse table modulo 2\u2074 = 16.\n+        ///\n+        /// Note, that this table does not contain values where inverse does not exist (i.e. for\n+        /// `0\u207b\u00b9 mod 16`, `2\u207b\u00b9 mod 16`, etc.)\n+        const INV_TABLE_MOD_16: [usize; 8] = [1, 11, 13, 7, 9, 3, 5, 15];\n+        /// Modulo for which the `INV_TABLE_MOD_16` is intended.\n+        const INV_TABLE_MOD: usize = 16;\n+        /// INV_TABLE_MOD\u00b2\n+        const INV_TABLE_MOD_SQUARED: usize = INV_TABLE_MOD * INV_TABLE_MOD;\n+\n+        let table_inverse = INV_TABLE_MOD_16[(x & (INV_TABLE_MOD - 1)) >> 1];\n+        if m <= INV_TABLE_MOD {\n+            return table_inverse & (m - 1);\n+        } else {\n+            // We iterate \"up\" using the following formula:\n+            //\n+            // $$ xy \u2261 1 (mod 2\u207f) \u2192 xy (2 - xy) \u2261 1 (mod 2\u00b2\u207f) $$\n+            //\n+            // until 2\u00b2\u207f \u2265 m. Then we can reduce to our desired `m` by taking the result `mod m`.\n+            let mut inverse = table_inverse;\n+            let mut going_mod = INV_TABLE_MOD_SQUARED;\n+            loop {\n+                // y = y * (2 - xy) mod n\n+                //\n+                // Note, that we use wrapping operations here intentionally \u2013 the original formula\n+                // uses e.g. subtraction `mod n`. It is entirely fine to do them `mod\n+                // usize::max_value()` instead, because we take the result `mod n` at the end\n+                // anyway.\n+                inverse = inverse.wrapping_mul(\n+                    2usize.wrapping_sub(x.wrapping_mul(inverse))\n+                ) & (going_mod - 1);\n+                if going_mod > m {\n+                    return inverse & (m - 1);\n+                }\n+                going_mod = going_mod.wrapping_mul(going_mod);\n+            }\n+        }\n+    }\n+\n+    let stride = ::mem::size_of::<T>();\n+    let a_minus_one = a.wrapping_sub(1);\n+    let pmoda = p as usize & a_minus_one;\n+\n+    if pmoda == 0 {\n+        // Already aligned. Yay!\n+        return 0;\n+    }\n+\n+    if stride <= 1 {\n+        return if stride == 0 {\n+            // If the pointer is not aligned, and the element is zero-sized, then no amount of\n+            // elements will ever align the pointer.\n+            !0\n+        } else {\n+            a.wrapping_sub(pmoda)\n+        };\n+    }\n+\n+    let smoda = stride & a_minus_one;\n+    // a is power-of-two so cannot be 0. stride = 0 is handled above.\n+    let gcdpow = intrinsics::cttz_nonzero(stride).min(intrinsics::cttz_nonzero(a));\n+    let gcd = 1usize << gcdpow;\n+\n+    if gcd == 1 {\n+        // This branch solves for the variable $o$ in following linear congruence equation:\n+        //\n+        // \u23b0 p + o \u2261 0 (mod a)   # $p + o$ must be aligned to specified alignment $a$\n+        // \u23b1     o \u2261 0 (mod s)   # offset $o$ must be a multiple of stride $s$\n+        //\n+        // where\n+        //\n+        // * a, s are co-prime\n+        //\n+        // This gives us the formula below:\n+        //\n+        // o = (a - (p mod a)) * (s\u207b\u00b9 mod a) * s\n+        //\n+        // The first term is \u201cthe relative alignment of p to a\u201d, the second term is \u201chow does\n+        // incrementing p by one s change the relative alignment of p\u201d, the third term is\n+        // translating change in units of s to a byte count.\n+        //\n+        // Furthermore, the result produced by this solution is not \u201cminimal\u201d, so it is necessary\n+        // to take the result $o mod lcm(s, a)$. Since $s$ and $a$ are co-prime (i.e. $gcd(s, a) =\n+        // 1$) and $lcm(s, a) = s * a / gcd(s, a)$, we can replace $lcm(s, a)$ with just a $s * a$.\n+        //\n+        // (Author note: we decided later on to express the offset in \"elements\" rather than bytes,\n+        // which drops the multiplication by `s` on both sides of the modulo.)\n+        return intrinsics::unchecked_rem(a.wrapping_sub(pmoda).wrapping_mul(mod_inv(smoda, a)), a);\n+    }\n+\n+    if p as usize & (gcd - 1) == 0 {\n+        // This can be aligned, but `a` and `stride` are not co-prime, so a somewhat adapted\n+        // formula is used.\n+        let j = a.wrapping_sub(pmoda) >> gcdpow;\n+        let k = smoda >> gcdpow;\n+        return intrinsics::unchecked_rem(j.wrapping_mul(mod_inv(k, a)), a >> gcdpow);\n+    }\n+\n+    // Cannot be aligned at all.\n+    return usize::max_value();\n }\n \n+\n+\n // Equality for pointers\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T: ?Sized> PartialEq for *const T {"}, {"sha": "fdc9aa473e8b8ed2247225eecf8495ea96af1eba", "filename": "src/libcore/slice/mod.rs", "status": "modified", "additions": 167, "deletions": 0, "changes": 167, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Fslice%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Fslice%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fslice%2Fmod.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -1696,6 +1696,173 @@ impl<T> [T] {\n                 self.as_mut_ptr(), other.as_mut_ptr(), self.len());\n         }\n     }\n+\n+    /// Function to calculate lenghts of the middle and trailing slice for `align_to{,_mut}`.\n+    fn align_to_offsets<U>(&self) -> (usize, usize) {\n+        // What we gonna do about `rest` is figure out what multiple of `U`s we can put in a\n+        // lowest number of `T`s. And how many `T`s we need for each such \"multiple\".\n+        //\n+        // Consider for example T=u8 U=u16. Then we can put 1 U in 2 Ts. Simple. Now, consider\n+        // for example a case where size_of::<T> = 16, size_of::<U> = 24. We can put 2 Us in\n+        // place of every 3 Ts in the `rest` slice. A bit more complicated.\n+        //\n+        // Formula to calculate this is:\n+        //\n+        // Us = lcm(size_of::<T>, size_of::<U>) / size_of::<U>\n+        // Ts = lcm(size_of::<T>, size_of::<U>) / size_of::<T>\n+        //\n+        // Expanded and simplified:\n+        //\n+        // Us = size_of::<T> / gcd(size_of::<T>, size_of::<U>)\n+        // Ts = size_of::<U> / gcd(size_of::<T>, size_of::<U>)\n+        //\n+        // Luckily since all this is constant-evaluated... performance here matters not!\n+        #[inline]\n+        fn gcd(a: usize, b: usize) -> usize {\n+            // iterative stein\u2019s algorithm\n+            // We should still make this `const fn` (and revert to recursive algorithm if we do)\n+            // because relying on llvm to consteval all this is\u2026 well, it makes me\n+            let (ctz_a, mut ctz_b) = unsafe {\n+                if a == 0 { return b; }\n+                if b == 0 { return a; }\n+                (::intrinsics::cttz_nonzero(a), ::intrinsics::cttz_nonzero(b))\n+            };\n+            let k = ctz_a.min(ctz_b);\n+            let mut a = a >> ctz_a;\n+            let mut b = b;\n+            loop {\n+                // remove all factors of 2 from b\n+                b >>= ctz_b;\n+                if a > b {\n+                    ::mem::swap(&mut a, &mut b);\n+                }\n+                b = b - a;\n+                unsafe {\n+                    if b == 0 {\n+                        break;\n+                    }\n+                    ctz_b = ::intrinsics::cttz_nonzero(b);\n+                }\n+            }\n+            return a << k;\n+        }\n+        let gcd: usize = gcd(::mem::size_of::<T>(), ::mem::size_of::<U>());\n+        let ts: usize = ::mem::size_of::<U>() / gcd;\n+        let us: usize = ::mem::size_of::<T>() / gcd;\n+\n+        // Armed with this knowledge, we can find how many `U`s we can fit!\n+        let us_len = self.len() / ts * us;\n+        // And how many `T`s will be in the trailing slice!\n+        let ts_len = self.len() % ts;\n+        return (us_len, ts_len);\n+    }\n+\n+    /// Transmute the slice to a slice of another type, ensuring aligment of the types is\n+    /// maintained.\n+    ///\n+    /// This method splits the slice into three distinct slices: prefix, correctly aligned middle\n+    /// slice of a new type, and the suffix slice. The middle slice will have the greatest length\n+    /// possible for a given type and input slice.\n+    ///\n+    /// This method has no purpose when either input element `T` or output element `U` are\n+    /// zero-sized and will return the original slice without splitting anything.\n+    ///\n+    /// # Unsafety\n+    ///\n+    /// This method is essentially a `transmute` with respect to the elements in the returned\n+    /// middle slice, so all the usual caveats pertaining to `transmute::<T, U>` also apply here.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// # #![feature(slice_align_to)]\n+    /// unsafe {\n+    ///     let bytes: [u8; 7] = [1, 2, 3, 4, 5, 6, 7];\n+    ///     let (prefix, shorts, suffix) = bytes.align_to::<u16>();\n+    ///     // less_efficient_algorithm_for_bytes(prefix);\n+    ///     // more_efficient_algorithm_for_aligned_shorts(shorts);\n+    ///     // less_efficient_algorithm_for_bytes(suffix);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"slice_align_to\", issue = \"44488\")]\n+    #[cfg(not(stage0))]\n+    pub unsafe fn align_to<U>(&self) -> (&[T], &[U], &[T]) {\n+        // Note that most of this function will be constant-evaluated,\n+        if ::mem::size_of::<U>() == 0 || ::mem::size_of::<T>() == 0 {\n+            // handle ZSTs specially, which is \u2013 don't handle them at all.\n+            return (self, &[], &[]);\n+        }\n+\n+        // First, find at what point do we split between the first and 2nd slice. Easy with\n+        // ptr.align_offset.\n+        let ptr = self.as_ptr();\n+        let offset = ::ptr::align_offset(ptr, ::mem::align_of::<U>());\n+        if offset > self.len() {\n+            return (self, &[], &[]);\n+        } else {\n+            let (left, rest) = self.split_at(offset);\n+            let (us_len, ts_len) = rest.align_to_offsets::<U>();\n+            return (left,\n+                    from_raw_parts(rest.as_ptr() as *const U, us_len),\n+                    from_raw_parts(rest.as_ptr().offset((rest.len() - ts_len) as isize), ts_len))\n+        }\n+    }\n+\n+    /// Transmute the slice to a slice of another type, ensuring aligment of the types is\n+    /// maintained.\n+    ///\n+    /// This method splits the slice into three distinct slices: prefix, correctly aligned middle\n+    /// slice of a new type, and the suffix slice. The middle slice will have the greatest length\n+    /// possible for a given type and input slice.\n+    ///\n+    /// This method has no purpose when either input element `T` or output element `U` are\n+    /// zero-sized and will return the original slice without splitting anything.\n+    ///\n+    /// # Unsafety\n+    ///\n+    /// This method is essentially a `transmute` with respect to the elements in the returned\n+    /// middle slice, so all the usual caveats pertaining to `transmute::<T, U>` also apply here.\n+    ///\n+    /// # Examples\n+    ///\n+    /// Basic usage:\n+    ///\n+    /// ```\n+    /// # #![feature(slice_align_to)]\n+    /// unsafe {\n+    ///     let mut bytes: [u8; 7] = [1, 2, 3, 4, 5, 6, 7];\n+    ///     let (prefix, shorts, suffix) = bytes.align_to_mut::<u16>();\n+    ///     // less_efficient_algorithm_for_bytes(prefix);\n+    ///     // more_efficient_algorithm_for_aligned_shorts(shorts);\n+    ///     // less_efficient_algorithm_for_bytes(suffix);\n+    /// }\n+    /// ```\n+    #[unstable(feature = \"slice_align_to\", issue = \"44488\")]\n+    #[cfg(not(stage0))]\n+    pub unsafe fn align_to_mut<U>(&mut self) -> (&mut [T], &mut [U], &mut [T]) {\n+        // Note that most of this function will be constant-evaluated,\n+        if ::mem::size_of::<U>() == 0 || ::mem::size_of::<T>() == 0 {\n+            // handle ZSTs specially, which is \u2013 don't handle them at all.\n+            return (self, &mut [], &mut []);\n+        }\n+\n+        // First, find at what point do we split between the first and 2nd slice. Easy with\n+        // ptr.align_offset.\n+        let ptr = self.as_ptr();\n+        let offset = ::ptr::align_offset(ptr, ::mem::align_of::<U>());\n+        if offset > self.len() {\n+            return (self, &mut [], &mut []);\n+        } else {\n+            let (left, rest) = self.split_at_mut(offset);\n+            let (us_len, ts_len) = rest.align_to_offsets::<U>();\n+            let mut_ptr = rest.as_mut_ptr();\n+            return (left,\n+                    from_raw_parts_mut(mut_ptr as *mut U, us_len),\n+                    from_raw_parts_mut(mut_ptr.offset((rest.len() - ts_len) as isize), ts_len))\n+        }\n+    }\n }\n \n #[lang = \"slice_u8\"]"}, {"sha": "13189d532aba1c92708cca8a32fb92f86e25b090", "filename": "src/libcore/tests/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Ftests%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Ftests%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftests%2Flib.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -41,6 +41,8 @@\n #![feature(try_from)]\n #![feature(try_trait)]\n #![feature(exact_chunks)]\n+#![feature(slice_align_to)]\n+#![feature(align_offset)]\n #![feature(reverse_bits)]\n #![feature(iterator_find_map)]\n #![feature(slice_internals)]"}, {"sha": "31bc1d677686a59c8ee11ffc92882dc0cb80d9e5", "filename": "src/libcore/tests/ptr.rs", "status": "modified", "additions": 89, "deletions": 0, "changes": 89, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Ftests%2Fptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Ftests%2Fptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftests%2Fptr.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -296,3 +296,92 @@ fn write_unaligned_drop() {\n     }\n     DROPS.with(|d| assert_eq!(*d.borrow(), [0]));\n }\n+\n+#[test]\n+fn align_offset_zst() {\n+    // For pointers of stride = 0, the pointer is already aligned or it cannot be aligned at\n+    // all, because no amount of elements will align the pointer.\n+    let mut p = 1;\n+    while p < 1024 {\n+        assert_eq!((p as *const ()).align_offset(p), 0);\n+        if p != 1 {\n+            assert_eq!(((p + 1) as *const ()).align_offset(p), !0);\n+        }\n+        p = (p + 1).next_power_of_two();\n+    }\n+}\n+\n+#[test]\n+fn align_offset_stride1() {\n+    // For pointers of stride = 1, the pointer can always be aligned. The offset is equal to\n+    // number of bytes.\n+    let mut align = 1;\n+    while align < 1024 {\n+        for ptr in 1..2*align {\n+            let expected = ptr % align;\n+            let offset = if expected == 0 { 0 } else { align - expected };\n+            assert_eq!((ptr as *const u8).align_offset(align), offset,\n+            \"ptr = {}, align = {}, size = 1\", ptr, align);\n+        }\n+        align = (align + 1).next_power_of_two();\n+    }\n+}\n+\n+#[test]\n+fn align_offset_weird_strides() {\n+    #[repr(packed)]\n+    struct A3(u16, u8);\n+    struct A4(u32);\n+    #[repr(packed)]\n+    struct A5(u32, u8);\n+    #[repr(packed)]\n+    struct A6(u32, u16);\n+    #[repr(packed)]\n+    struct A7(u32, u16, u8);\n+    #[repr(packed)]\n+    struct A8(u32, u32);\n+    #[repr(packed)]\n+    struct A9(u32, u32, u8);\n+    #[repr(packed)]\n+    struct A10(u32, u32, u16);\n+\n+    unsafe fn test_weird_stride<T>(ptr: *const T, align: usize) -> bool {\n+        let numptr = ptr as usize;\n+        let mut expected = usize::max_value();\n+        // Naive but definitely correct way to find the *first* aligned element of stride::<T>.\n+        for el in 0..align {\n+            if (numptr + el * ::std::mem::size_of::<T>()) % align == 0 {\n+                expected = el;\n+                break;\n+            }\n+        }\n+        let got = ptr.align_offset(align);\n+        if got != expected {\n+            eprintln!(\"aligning {:p} (with stride of {}) to {}, expected {}, got {}\", ptr,\n+                      ::std::mem::size_of::<T>(), align, expected, got);\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    // For pointers of stride != 1, we verify the algorithm against the naivest possible\n+    // implementation\n+    let mut align = 1;\n+    let mut x = false;\n+    while align < 1024 {\n+        for ptr in 1usize..4*align {\n+            unsafe {\n+                x |= test_weird_stride::<A3>(ptr as *const A3, align);\n+                x |= test_weird_stride::<A4>(ptr as *const A4, align);\n+                x |= test_weird_stride::<A5>(ptr as *const A5, align);\n+                x |= test_weird_stride::<A6>(ptr as *const A6, align);\n+                x |= test_weird_stride::<A7>(ptr as *const A7, align);\n+                x |= test_weird_stride::<A8>(ptr as *const A8, align);\n+                x |= test_weird_stride::<A9>(ptr as *const A9, align);\n+                x |= test_weird_stride::<A10>(ptr as *const A10, align);\n+            }\n+        }\n+        align = (align + 1).next_power_of_two();\n+    }\n+    assert!(!x);\n+}"}, {"sha": "fcd79222e1699882aee57f3f54528967dbbb646e", "filename": "src/libcore/tests/slice.rs", "status": "modified", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Ftests%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibcore%2Ftests%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftests%2Fslice.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -812,3 +812,37 @@ pub mod memchr {\n         }\n     }\n }\n+\n+#[test]\n+fn test_align_to_simple() {\n+    let bytes = [1u8, 2, 3, 4, 5, 6, 7];\n+    let (prefix, aligned, suffix) = unsafe { bytes.align_to::<u16>() };\n+    assert_eq!(aligned.len(), 3);\n+    assert!(prefix == [1] || suffix == [7]);\n+    let expect1 = [1 << 8 | 2, 3 << 8 | 4, 5 << 8 | 6];\n+    let expect2 = [1 | 2 << 8, 3 | 4 << 8, 5 | 6 << 8];\n+    let expect3 = [2 << 8 | 3, 4 << 8 | 5, 6 << 8 | 7];\n+    let expect4 = [2 | 3 << 8, 4 | 5 << 8, 6 | 7 << 8];\n+    assert!(aligned == expect1 || aligned == expect2 || aligned == expect3 || aligned == expect4,\n+            \"aligned={:?} expected={:?} || {:?} || {:?} || {:?}\",\n+            aligned, expect1, expect2, expect3, expect4);\n+}\n+\n+#[test]\n+fn test_align_to_zst() {\n+    let bytes = [1, 2, 3, 4, 5, 6, 7];\n+    let (prefix, aligned, suffix) = unsafe { bytes.align_to::<()>() };\n+    assert_eq!(aligned.len(), 0);\n+    assert!(prefix == [1, 2, 3, 4, 5, 6, 7] || suffix == [1, 2, 3, 4, 5, 6, 7]);\n+}\n+\n+#[test]\n+fn test_align_to_non_trivial() {\n+    #[repr(align(8))] struct U64(u64, u64);\n+    #[repr(align(8))] struct U64U64U32(u64, u64, u32);\n+    let data = [U64(1, 2), U64(3, 4), U64(5, 6), U64(7, 8), U64(9, 10), U64(11, 12), U64(13, 14),\n+                U64(15, 16)];\n+    let (prefix, aligned, suffix) = unsafe { data.align_to::<U64U64U32>() };\n+    assert_eq!(aligned.len(), 4);\n+    assert_eq!(prefix.len() + suffix.len(), 2);\n+}"}, {"sha": "d70f994e87ba7f878cf3cc208ee4117759b7fa09", "filename": "src/librustc/middle/lang_items.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibrustc%2Fmiddle%2Flang_items.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibrustc%2Fmiddle%2Flang_items.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Flang_items.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -348,6 +348,9 @@ language_item_table! {\n     I128ShroFnLangItem,              \"i128_shro\",               i128_shro_fn;\n     U128ShroFnLangItem,              \"u128_shro\",               u128_shro_fn;\n \n+    // Align offset for stride != 1, must not panic.\n+    AlignOffsetLangItem,             \"align_offset\",            align_offset_fn;\n+\n     TerminationTraitLangItem,        \"termination\",             termination;\n }\n "}, {"sha": "cffe7f79e970c91e44eb93817b8bd19050f88172", "filename": "src/librustc_codegen_llvm/intrinsic.rs", "status": "modified", "additions": 0, "deletions": 12, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibrustc_codegen_llvm%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibrustc_codegen_llvm%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fintrinsic.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -389,18 +389,6 @@ pub fn codegen_intrinsic_call<'a, 'tcx>(bx: &Builder<'a, 'tcx>,\n             args[0].deref(bx.cx).codegen_get_discr(bx, ret_ty)\n         }\n \n-        \"align_offset\" => {\n-            // `ptr as usize`\n-            let ptr_val = bx.ptrtoint(args[0].immediate(), bx.cx.isize_ty);\n-            // `ptr_val % align`\n-            let align = args[1].immediate();\n-            let offset = bx.urem(ptr_val, align);\n-            let zero = C_null(bx.cx.isize_ty);\n-            // `offset == 0`\n-            let is_zero = bx.icmp(llvm::IntPredicate::IntEQ, offset, zero);\n-            // `if offset == 0 { 0 } else { align - offset }`\n-            bx.select(is_zero, zero, bx.sub(align, offset))\n-        }\n         name if name.starts_with(\"simd_\") => {\n             match generic_simd_intrinsic(bx, name,\n                                          callee_ty,"}, {"sha": "af1f1044edf2f79c5586f8110067c7e3c7a141ef", "filename": "src/librustc_typeck/check/intrinsic.rs", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/37a409177c80e6f301c41833fc7ee8fda2412c00/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs?ref=37a409177c80e6f301c41833fc7ee8fda2412c00", "patch": "@@ -314,11 +314,6 @@ pub fn check_intrinsic_type<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                 (0, vec![tcx.mk_fn_ptr(fn_ty), mut_u8, mut_u8], tcx.types.i32)\n             }\n \n-            \"align_offset\" => {\n-                let ptr_ty = tcx.mk_imm_ptr(tcx.mk_nil());\n-                (0, vec![ptr_ty, tcx.types.usize], tcx.types.usize)\n-            },\n-\n             \"nontemporal_store\" => {\n                 (1, vec![ tcx.mk_mut_ptr(param(0)), param(0) ], tcx.mk_nil())\n             }"}, {"sha": "aaa0419d061cb8797611f29e171fb55b23630201", "filename": "src/test/run-pass/align-offset-sign.rs", "status": "removed", "additions": 0, "deletions": 16, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/952f344cdc0bca58d9f6c54dcfbae0890246e886/src%2Ftest%2Frun-pass%2Falign-offset-sign.rs", "raw_url": "https://github.com/rust-lang/rust/raw/952f344cdc0bca58d9f6c54dcfbae0890246e886/src%2Ftest%2Frun-pass%2Falign-offset-sign.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Falign-offset-sign.rs?ref=952f344cdc0bca58d9f6c54dcfbae0890246e886", "patch": "@@ -1,16 +0,0 @@\n-// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-#![feature(align_offset)]\n-\n-fn main() {\n-    let x = 1 as *const u8;\n-    assert_eq!(x.align_offset(8), 7);\n-}"}]}