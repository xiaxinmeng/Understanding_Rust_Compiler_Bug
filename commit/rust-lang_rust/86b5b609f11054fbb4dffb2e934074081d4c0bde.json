{"sha": "86b5b609f11054fbb4dffb2e934074081d4c0bde", "node_id": "C_kwDOAAsO6NoAKDg2YjViNjA5ZjExMDU0ZmJiNGRmZmIyZTkzNDA3NDA4MWQ0YzBiZGU", "commit": {"author": {"name": "hkalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2022-10-23T08:12:05Z"}, "committer": {"name": "hkalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2022-12-03T20:59:34Z"}, "message": "Compute data layout of types", "tree": {"sha": "acf0afa2a6191e321cfeb5a72d5f75732a196006", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/acf0afa2a6191e321cfeb5a72d5f75732a196006"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/86b5b609f11054fbb4dffb2e934074081d4c0bde", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/86b5b609f11054fbb4dffb2e934074081d4c0bde", "html_url": "https://github.com/rust-lang/rust/commit/86b5b609f11054fbb4dffb2e934074081d4c0bde", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/86b5b609f11054fbb4dffb2e934074081d4c0bde/comments", "author": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "committer": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "957b4bb2164e57a58d7e6cb5b4915b298dab9391", "url": "https://api.github.com/repos/rust-lang/rust/commits/957b4bb2164e57a58d7e6cb5b4915b298dab9391", "html_url": "https://github.com/rust-lang/rust/commit/957b4bb2164e57a58d7e6cb5b4915b298dab9391"}], "stats": {"total": 2979, "additions": 2822, "deletions": 157}, "files": [{"sha": "62efc409868457f176200bcb3e26ca87e4287291", "filename": "crates/hir-def/src/adt.rs", "status": "modified", "additions": 34, "deletions": 39, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-def%2Fsrc%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-def%2Fsrc%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Fadt.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -1,6 +1,6 @@\n //! Defines hir-level representation of structs, enums and unions\n \n-use std::{num::NonZeroU32, sync::Arc};\n+use std::sync::Arc;\n \n use base_db::CrateId;\n use either::Either;\n@@ -18,6 +18,7 @@ use crate::{\n     db::DefDatabase,\n     intern::Interned,\n     item_tree::{AttrOwner, Field, FieldAstId, Fields, ItemTree, ModItem, RawVisibilityId},\n+    layout::{Align, ReprFlags, ReprOptions},\n     nameres::diagnostics::DefDiagnostic,\n     src::HasChildSource,\n     src::HasSource,\n@@ -34,15 +35,15 @@ use cfg::CfgOptions;\n pub struct StructData {\n     pub name: Name,\n     pub variant_data: Arc<VariantData>,\n-    pub repr: Option<ReprData>,\n+    pub repr: Option<ReprOptions>,\n     pub visibility: RawVisibility,\n }\n \n #[derive(Debug, Clone, PartialEq, Eq)]\n pub struct EnumData {\n     pub name: Name,\n     pub variants: Arena<EnumVariantData>,\n-    pub repr: Option<ReprData>,\n+    pub repr: Option<ReprOptions>,\n     pub visibility: RawVisibility,\n }\n \n@@ -67,80 +68,74 @@ pub struct FieldData {\n     pub visibility: RawVisibility,\n }\n \n-#[derive(Copy, Debug, Clone, PartialEq, Eq)]\n-pub enum ReprKind {\n-    C,\n-    BuiltinInt { builtin: Either<BuiltinInt, BuiltinUint>, is_c: bool },\n-    Transparent,\n-    Default,\n-}\n-\n-#[derive(Copy, Debug, Clone, PartialEq, Eq)]\n-pub struct ReprData {\n-    pub kind: ReprKind,\n-    pub packed: bool,\n-    pub align: Option<NonZeroU32>,\n-}\n-\n fn repr_from_value(\n     db: &dyn DefDatabase,\n     krate: CrateId,\n     item_tree: &ItemTree,\n     of: AttrOwner,\n-) -> Option<ReprData> {\n+) -> Option<ReprOptions> {\n     item_tree.attrs(db, krate, of).by_key(\"repr\").tt_values().find_map(parse_repr_tt)\n }\n \n-fn parse_repr_tt(tt: &Subtree) -> Option<ReprData> {\n+fn parse_repr_tt(tt: &Subtree) -> Option<ReprOptions> {\n     match tt.delimiter {\n         Some(Delimiter { kind: DelimiterKind::Parenthesis, .. }) => {}\n         _ => return None,\n     }\n \n-    let mut data = ReprData { kind: ReprKind::Default, packed: false, align: None };\n+    let mut flags = ReprFlags::empty();\n+    let mut int = None;\n+    let mut max_align: Option<Align> = None;\n+    let mut min_pack: Option<Align> = None;\n \n     let mut tts = tt.token_trees.iter().peekable();\n     while let Some(tt) = tts.next() {\n         if let TokenTree::Leaf(Leaf::Ident(ident)) = tt {\n-            match &*ident.text {\n+            flags.insert(match &*ident.text {\n                 \"packed\" => {\n-                    data.packed = true;\n-                    if let Some(TokenTree::Subtree(_)) = tts.peek() {\n+                    let pack = if let Some(TokenTree::Subtree(tt)) = tts.peek() {\n                         tts.next();\n-                    }\n+                        if let Some(TokenTree::Leaf(Leaf::Literal(lit))) = tt.token_trees.first() {\n+                            lit.text.parse().unwrap_or_default()\n+                        } else {\n+                            0\n+                        }\n+                    } else {\n+                        0\n+                    };\n+                    let pack = Align::from_bytes(pack).unwrap();\n+                    min_pack =\n+                        Some(if let Some(min_pack) = min_pack { min_pack.min(pack) } else { pack });\n+                    ReprFlags::empty()\n                 }\n                 \"align\" => {\n                     if let Some(TokenTree::Subtree(tt)) = tts.peek() {\n                         tts.next();\n                         if let Some(TokenTree::Leaf(Leaf::Literal(lit))) = tt.token_trees.first() {\n                             if let Ok(align) = lit.text.parse() {\n-                                data.align = Some(align);\n+                                let align = Align::from_bytes(align).ok();\n+                                max_align = max_align.max(align);\n                             }\n                         }\n                     }\n+                    ReprFlags::empty()\n                 }\n-                \"C\" => {\n-                    if let ReprKind::BuiltinInt { is_c, .. } = &mut data.kind {\n-                        *is_c = true;\n-                    } else {\n-                        data.kind = ReprKind::C;\n-                    }\n-                }\n-                \"transparent\" => data.kind = ReprKind::Transparent,\n+                \"C\" => ReprFlags::IS_C,\n+                \"transparent\" => ReprFlags::IS_TRANSPARENT,\n                 repr => {\n-                    let is_c = matches!(data.kind, ReprKind::C);\n                     if let Some(builtin) = BuiltinInt::from_suffix(repr)\n                         .map(Either::Left)\n                         .or_else(|| BuiltinUint::from_suffix(repr).map(Either::Right))\n                     {\n-                        data.kind = ReprKind::BuiltinInt { builtin, is_c };\n+                        int = Some(builtin);\n                     }\n+                    ReprFlags::empty()\n                 }\n-            }\n+            })\n         }\n     }\n \n-    Some(data)\n+    Some(ReprOptions { int, align: max_align, pack: min_pack, flags })\n }\n \n impl StructData {\n@@ -283,7 +278,7 @@ impl EnumData {\n \n     pub fn variant_body_type(&self) -> Either<BuiltinInt, BuiltinUint> {\n         match self.repr {\n-            Some(ReprData { kind: ReprKind::BuiltinInt { builtin, .. }, .. }) => builtin,\n+            Some(ReprOptions { int: Some(builtin), .. }) => builtin,\n             _ => Either::Left(BuiltinInt::Isize),\n         }\n     }"}, {"sha": "cc8177376f7ef6aa8c606fdb279eadbc07523c1c", "filename": "crates/hir-def/src/layout.rs", "status": "added", "additions": 1173, "deletions": 0, "changes": 1173, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-def%2Fsrc%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-def%2Fsrc%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Flayout.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -0,0 +1,1173 @@\n+//! Definitions related to binary representations of types\n+\n+use bitflags::bitflags;\n+use either::Either;\n+use std::{\n+    cmp, fmt,\n+    num::NonZeroUsize,\n+    ops::{Add, AddAssign, Mul, Sub},\n+};\n+\n+use crate::{\n+    builtin_type::{BuiltinInt, BuiltinUint},\n+    LocalEnumVariantId,\n+};\n+use la_arena::ArenaMap;\n+\n+/// Size of a type in bytes.\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct Size {\n+    raw: u64,\n+}\n+\n+// This is debug-printed a lot in larger structs, don't waste too much space there\n+impl fmt::Debug for Size {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        write!(f, \"Size({} bytes)\", self.raw)\n+    }\n+}\n+\n+// Panicking addition, subtraction and multiplication for convenience.\n+// Avoid during layout computation, return `LayoutError` instead.\n+\n+impl Add for Size {\n+    type Output = Size;\n+    #[inline]\n+    fn add(self, other: Size) -> Size {\n+        Size::from_bytes(self.bytes().checked_add(other.bytes()).unwrap_or_else(|| {\n+            panic!(\"Size::add: {} + {} doesn't fit in u64\", self.bytes(), other.bytes())\n+        }))\n+    }\n+}\n+\n+impl Sub for Size {\n+    type Output = Size;\n+    #[inline]\n+    fn sub(self, other: Size) -> Size {\n+        Size::from_bytes(self.bytes().checked_sub(other.bytes()).unwrap_or_else(|| {\n+            panic!(\"Size::sub: {} - {} would result in negative size\", self.bytes(), other.bytes())\n+        }))\n+    }\n+}\n+\n+impl Mul<Size> for u64 {\n+    type Output = Size;\n+    #[inline]\n+    fn mul(self, size: Size) -> Size {\n+        size * self\n+    }\n+}\n+\n+impl Mul<u64> for Size {\n+    type Output = Size;\n+    #[inline]\n+    fn mul(self, count: u64) -> Size {\n+        match self.bytes().checked_mul(count) {\n+            Some(bytes) => Size::from_bytes(bytes),\n+            None => panic!(\"Size::mul: {} * {} doesn't fit in u64\", self.bytes(), count),\n+        }\n+    }\n+}\n+\n+impl AddAssign for Size {\n+    #[inline]\n+    fn add_assign(&mut self, other: Size) {\n+        *self = *self + other;\n+    }\n+}\n+\n+impl Size {\n+    pub const ZERO: Size = Size { raw: 0 };\n+\n+    /// Rounds `bits` up to the next-higher byte boundary, if `bits` is\n+    /// not a multiple of 8.\n+    pub fn from_bits(bits: impl TryInto<u64>) -> Size {\n+        let bits = bits.try_into().ok().unwrap();\n+        // Avoid potential overflow from `bits + 7`.\n+        Size { raw: bits / 8 + ((bits % 8) + 7) / 8 }\n+    }\n+\n+    #[inline]\n+    pub fn from_bytes(bytes: impl TryInto<u64>) -> Size {\n+        let bytes: u64 = bytes.try_into().ok().unwrap();\n+        Size { raw: bytes }\n+    }\n+\n+    #[inline]\n+    pub fn bytes(self) -> u64 {\n+        self.raw\n+    }\n+\n+    #[inline]\n+    pub fn bytes_usize(self) -> usize {\n+        self.bytes().try_into().unwrap()\n+    }\n+\n+    #[inline]\n+    pub fn bits(self) -> u64 {\n+        #[cold]\n+        fn overflow(bytes: u64) -> ! {\n+            panic!(\"Size::bits: {} bytes in bits doesn't fit in u64\", bytes)\n+        }\n+\n+        self.bytes().checked_mul(8).unwrap_or_else(|| overflow(self.bytes()))\n+    }\n+\n+    #[inline]\n+    pub fn bits_usize(self) -> usize {\n+        self.bits().try_into().unwrap()\n+    }\n+\n+    #[inline]\n+    pub fn checked_add(self, offset: Size, dl: &TargetDataLayout) -> Option<Size> {\n+        let bytes = self.bytes().checked_add(offset.bytes())?;\n+\n+        if bytes < dl.obj_size_bound() {\n+            Some(Size::from_bytes(bytes))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn checked_mul(self, count: u64, dl: &TargetDataLayout) -> Option<Size> {\n+        let bytes = self.bytes().checked_mul(count)?;\n+        if bytes < dl.obj_size_bound() {\n+            Some(Size::from_bytes(bytes))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn align_to(self, align: Align) -> Size {\n+        let mask = align.bytes() - 1;\n+        Size::from_bytes((self.bytes() + mask) & !mask)\n+    }\n+\n+    #[inline]\n+    pub fn is_aligned(self, align: Align) -> bool {\n+        let mask = align.bytes() - 1;\n+        self.bytes() & mask == 0\n+    }\n+\n+    /// Truncates `value` to `self` bits and then sign-extends it to 128 bits\n+    /// (i.e., if it is negative, fill with 1's on the left).\n+    #[inline]\n+    pub fn sign_extend(self, value: u128) -> u128 {\n+        let size = self.bits();\n+        if size == 0 {\n+            // Truncated until nothing is left.\n+            return 0;\n+        }\n+        // Sign-extend it.\n+        let shift = 128 - size;\n+        // Shift the unsigned value to the left, then shift back to the right as signed\n+        // (essentially fills with sign bit on the left).\n+        (((value << shift) as i128) >> shift) as u128\n+    }\n+\n+    /// Truncates `value` to `self` bits.\n+    #[inline]\n+    pub fn truncate(self, value: u128) -> u128 {\n+        let size = self.bits();\n+        if size == 0 {\n+            // Truncated until nothing is left.\n+            return 0;\n+        }\n+        let shift = 128 - size;\n+        // Truncate (shift left to drop out leftover values, shift right to fill with zeroes).\n+        (value << shift) >> shift\n+    }\n+\n+    #[inline]\n+    pub fn signed_int_min(&self) -> i128 {\n+        self.sign_extend(1_u128 << (self.bits() - 1)) as i128\n+    }\n+\n+    #[inline]\n+    pub fn signed_int_max(&self) -> i128 {\n+        i128::MAX >> (128 - self.bits())\n+    }\n+\n+    #[inline]\n+    pub fn unsigned_int_max(&self) -> u128 {\n+        u128::MAX >> (128 - self.bits())\n+    }\n+}\n+\n+#[derive(Copy, Clone, Debug)]\n+pub enum StructKind {\n+    /// A tuple, closure, or univariant which cannot be coerced to unsized.\n+    AlwaysSized,\n+    /// A univariant, the last field of which may be coerced to unsized.\n+    MaybeUnsized,\n+    /// A univariant, but with a prefix of an arbitrary size & alignment (e.g., enum tag).\n+    Prefixed(Size, Align),\n+}\n+\n+/// Describes how the fields of a type are located in memory.\n+#[derive(PartialEq, Eq, Hash, Debug, Clone)]\n+pub enum FieldsShape {\n+    /// Scalar primitives and `!`, which never have fields.\n+    Primitive,\n+\n+    /// All fields start at no offset. The `usize` is the field count.\n+    Union(NonZeroUsize),\n+\n+    /// Array/vector-like placement, with all fields of identical types.\n+    Array { stride: Size, count: u64 },\n+\n+    /// Struct-like placement, with precomputed offsets.\n+    ///\n+    /// Fields are guaranteed to not overlap, but note that gaps\n+    /// before, between and after all the fields are NOT always\n+    /// padding, and as such their contents may not be discarded.\n+    /// For example, enum variants leave a gap at the start,\n+    /// where the discriminant field in the enum layout goes.\n+    Arbitrary {\n+        /// Offsets for the first byte of each field,\n+        /// ordered to match the source definition order.\n+        /// This vector does not go in increasing order.\n+        // FIXME(eddyb) use small vector optimization for the common case.\n+        offsets: Vec<Size>,\n+\n+        /// Maps source order field indices to memory order indices,\n+        /// depending on how the fields were reordered (if at all).\n+        /// This is a permutation, with both the source order and the\n+        /// memory order using the same (0..n) index ranges.\n+        ///\n+        /// Note that during computation of `memory_index`, sometimes\n+        /// it is easier to operate on the inverse mapping (that is,\n+        /// from memory order to source order), and that is usually\n+        /// named `inverse_memory_index`.\n+        ///\n+        // FIXME(eddyb) build a better abstraction for permutations, if possible.\n+        // FIXME(camlorn) also consider small vector  optimization here.\n+        memory_index: Vec<u32>,\n+    },\n+}\n+\n+impl FieldsShape {\n+    #[inline]\n+    pub fn count(&self) -> usize {\n+        match *self {\n+            FieldsShape::Primitive => 0,\n+            FieldsShape::Union(count) => count.get(),\n+            FieldsShape::Array { count, .. } => count.try_into().unwrap(),\n+            FieldsShape::Arbitrary { ref offsets, .. } => offsets.len(),\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn offset(&self, i: usize, dl: &TargetDataLayout) -> Size {\n+        match *self {\n+            FieldsShape::Primitive => {\n+                unreachable!(\"FieldsShape::offset: `Primitive`s have no fields\")\n+            }\n+            FieldsShape::Union(count) => {\n+                assert!(\n+                    i < count.get(),\n+                    \"tried to access field {} of union with {} fields\",\n+                    i,\n+                    count\n+                );\n+                Size::ZERO\n+            }\n+            FieldsShape::Array { stride, count } => {\n+                let i = u64::try_from(i).unwrap();\n+                assert!(i < count);\n+                stride.checked_mul(i, dl).unwrap()\n+            }\n+            FieldsShape::Arbitrary { ref offsets, .. } => offsets[i],\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn memory_index(&self, i: usize) -> usize {\n+        match *self {\n+            FieldsShape::Primitive => {\n+                unreachable!(\"FieldsShape::memory_index: `Primitive`s have no fields\")\n+            }\n+            FieldsShape::Union(_) | FieldsShape::Array { .. } => i,\n+            FieldsShape::Arbitrary { ref memory_index, .. } => memory_index[i].try_into().unwrap(),\n+        }\n+    }\n+\n+    /// Gets source indices of the fields by increasing offsets.\n+    #[inline]\n+    pub fn index_by_increasing_offset<'a>(&'a self) -> impl Iterator<Item = usize> + 'a {\n+        let mut inverse_small = [0u8; 64];\n+        let mut inverse_big = vec![];\n+        let use_small = self.count() <= inverse_small.len();\n+\n+        // We have to write this logic twice in order to keep the array small.\n+        if let FieldsShape::Arbitrary { ref memory_index, .. } = *self {\n+            if use_small {\n+                for i in 0..self.count() {\n+                    inverse_small[memory_index[i] as usize] = i as u8;\n+                }\n+            } else {\n+                inverse_big = vec![0; self.count()];\n+                for i in 0..self.count() {\n+                    inverse_big[memory_index[i] as usize] = i as u32;\n+                }\n+            }\n+        }\n+\n+        (0..self.count()).map(move |i| match *self {\n+            FieldsShape::Primitive | FieldsShape::Union(_) | FieldsShape::Array { .. } => i,\n+            FieldsShape::Arbitrary { .. } => {\n+                if use_small {\n+                    inverse_small[i] as usize\n+                } else {\n+                    inverse_big[i] as usize\n+                }\n+            }\n+        })\n+    }\n+}\n+\n+/// Integers, also used for enum discriminants.\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n+pub enum Integer {\n+    I8,\n+    I16,\n+    I32,\n+    I64,\n+    I128,\n+}\n+\n+impl Integer {\n+    #[inline]\n+    pub fn size(self) -> Size {\n+        match self {\n+            Integer::I8 => Size::from_bytes(1),\n+            Integer::I16 => Size::from_bytes(2),\n+            Integer::I32 => Size::from_bytes(4),\n+            Integer::I64 => Size::from_bytes(8),\n+            Integer::I128 => Size::from_bytes(16),\n+        }\n+    }\n+\n+    pub fn align(self, dl: &TargetDataLayout) -> AbiAndPrefAlign {\n+        match self {\n+            Integer::I8 => dl.i8_align,\n+            Integer::I16 => dl.i16_align,\n+            Integer::I32 => dl.i32_align,\n+            Integer::I64 => dl.i64_align,\n+            Integer::I128 => dl.i128_align,\n+        }\n+    }\n+\n+    /// Finds the smallest integer with the given alignment.\n+    pub fn for_align(dl: &TargetDataLayout, wanted: Align) -> Option<Integer> {\n+        use Integer::*;\n+        for candidate in [I8, I16, I32, I64, I128] {\n+            if wanted == candidate.align(dl).abi && wanted.bytes() == candidate.size().bytes() {\n+                return Some(candidate);\n+            }\n+        }\n+        None\n+    }\n+\n+    /// Finds the smallest Integer type which can represent the signed value.\n+    #[inline]\n+    pub fn fit_signed(x: i128) -> Integer {\n+        match x {\n+            -0x0000_0000_0000_0080..=0x0000_0000_0000_007f => Integer::I8,\n+            -0x0000_0000_0000_8000..=0x0000_0000_0000_7fff => Integer::I16,\n+            -0x0000_0000_8000_0000..=0x0000_0000_7fff_ffff => Integer::I32,\n+            -0x8000_0000_0000_0000..=0x7fff_ffff_ffff_ffff => Integer::I64,\n+            _ => Integer::I128,\n+        }\n+    }\n+\n+    /// Finds the smallest Integer type which can represent the unsigned value.\n+    #[inline]\n+    pub fn fit_unsigned(x: u128) -> Integer {\n+        match x {\n+            0..=0x0000_0000_0000_00ff => Integer::I8,\n+            0..=0x0000_0000_0000_ffff => Integer::I16,\n+            0..=0x0000_0000_ffff_ffff => Integer::I32,\n+            0..=0xffff_ffff_ffff_ffff => Integer::I64,\n+            _ => Integer::I128,\n+        }\n+    }\n+\n+    /// Gets the Integer type from an attr::IntType.\n+    pub fn from_attr(dl: &TargetDataLayout, ity: Either<BuiltinInt, BuiltinUint>) -> Integer {\n+        match ity {\n+            Either::Left(BuiltinInt::I8) | Either::Right(BuiltinUint::U8) => Integer::I8,\n+            Either::Left(BuiltinInt::I16) | Either::Right(BuiltinUint::U16) => Integer::I16,\n+            Either::Left(BuiltinInt::I32) | Either::Right(BuiltinUint::U32) => Integer::I32,\n+            Either::Left(BuiltinInt::I64) | Either::Right(BuiltinUint::U64) => Integer::I64,\n+            Either::Left(BuiltinInt::I128) | Either::Right(BuiltinUint::U128) => Integer::I128,\n+            Either::Left(BuiltinInt::Isize) | Either::Right(BuiltinUint::Usize) => {\n+                dl.ptr_sized_integer()\n+            }\n+        }\n+    }\n+\n+    /// Finds the appropriate Integer type and signedness for the given\n+    /// signed discriminant range and `#[repr]` attribute.\n+    /// N.B.: `u128` values above `i128::MAX` will be treated as signed, but\n+    /// that shouldn't affect anything, other than maybe debuginfo.\n+    pub fn repr_discr(\n+        dl: &TargetDataLayout,\n+        repr: &ReprOptions,\n+        min: i128,\n+        max: i128,\n+    ) -> Result<(Integer, bool), LayoutError> {\n+        // Theoretically, negative values could be larger in unsigned representation\n+        // than the unsigned representation of the signed minimum. However, if there\n+        // are any negative values, the only valid unsigned representation is u128\n+        // which can fit all i128 values, so the result remains unaffected.\n+        let unsigned_fit = Integer::fit_unsigned(cmp::max(min as u128, max as u128));\n+        let signed_fit = cmp::max(Integer::fit_signed(min), Integer::fit_signed(max));\n+\n+        if let Some(ity) = repr.int {\n+            let discr = Integer::from_attr(dl, ity);\n+            let fit = if ity.is_left() { signed_fit } else { unsigned_fit };\n+            if discr < fit {\n+                return Err(LayoutError::UserError(\n+                    \"Integer::repr_discr: `#[repr]` hint too small for \\\n+                      discriminant range of enum \"\n+                        .to_string(),\n+                ));\n+            }\n+            return Ok((discr, ity.is_left()));\n+        }\n+\n+        let at_least = if repr.c() {\n+            // This is usually I32, however it can be different on some platforms,\n+            // notably hexagon and arm-none/thumb-none\n+            dl.c_enum_min_size\n+        } else {\n+            // repr(Rust) enums try to be as small as possible\n+            Integer::I8\n+        };\n+\n+        // If there are no negative values, we can use the unsigned fit.\n+        Ok(if min >= 0 {\n+            (cmp::max(unsigned_fit, at_least), false)\n+        } else {\n+            (cmp::max(signed_fit, at_least), true)\n+        })\n+    }\n+}\n+\n+/// Endianness of the target, which must match cfg(target-endian).\n+#[derive(Copy, Clone, PartialEq, Eq)]\n+pub enum Endian {\n+    Little,\n+    Big,\n+}\n+\n+impl Endian {\n+    pub fn as_str(&self) -> &'static str {\n+        match self {\n+            Self::Little => \"little\",\n+            Self::Big => \"big\",\n+        }\n+    }\n+}\n+\n+impl fmt::Debug for Endian {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        f.write_str(self.as_str())\n+    }\n+}\n+\n+/// An identifier that specifies the address space that some operation\n+/// should operate on. Special address spaces have an effect on code generation,\n+/// depending on the target and the address spaces it implements.\n+#[derive(Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]\n+pub struct AddressSpace(pub u32);\n+\n+/// Parsed [Data layout](https://llvm.org/docs/LangRef.html#data-layout)\n+/// for a target, which contains everything needed to compute layouts.\n+#[derive(Debug, PartialEq, Eq)]\n+pub struct TargetDataLayout {\n+    pub endian: Endian,\n+    pub i1_align: AbiAndPrefAlign,\n+    pub i8_align: AbiAndPrefAlign,\n+    pub i16_align: AbiAndPrefAlign,\n+    pub i32_align: AbiAndPrefAlign,\n+    pub i64_align: AbiAndPrefAlign,\n+    pub i128_align: AbiAndPrefAlign,\n+    pub f32_align: AbiAndPrefAlign,\n+    pub f64_align: AbiAndPrefAlign,\n+    pub pointer_size: Size,\n+    pub pointer_align: AbiAndPrefAlign,\n+    pub aggregate_align: AbiAndPrefAlign,\n+\n+    /// Alignments for vector types.\n+    pub vector_align: Vec<(Size, AbiAndPrefAlign)>,\n+\n+    pub instruction_address_space: AddressSpace,\n+\n+    /// Minimum size of #[repr(C)] enums (default I32 bits)\n+    pub c_enum_min_size: Integer,\n+}\n+\n+impl TargetDataLayout {\n+    /// Returns exclusive upper bound on object size.\n+    ///\n+    /// The theoretical maximum object size is defined as the maximum positive `isize` value.\n+    /// This ensures that the `offset` semantics remain well-defined by allowing it to correctly\n+    /// index every address within an object along with one byte past the end, along with allowing\n+    /// `isize` to store the difference between any two pointers into an object.\n+    ///\n+    /// The upper bound on 64-bit currently needs to be lower because LLVM uses a 64-bit integer\n+    /// to represent object size in bits. It would need to be 1 << 61 to account for this, but is\n+    /// currently conservatively bounded to 1 << 47 as that is enough to cover the current usable\n+    /// address space on 64-bit ARMv8 and x86_64.\n+    #[inline]\n+    pub fn obj_size_bound(&self) -> u64 {\n+        match self.pointer_size.bits() {\n+            16 => 1 << 15,\n+            32 => 1 << 31,\n+            64 => 1 << 47,\n+            bits => panic!(\"obj_size_bound: unknown pointer bit size {}\", bits),\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn ptr_sized_integer(&self) -> Integer {\n+        match self.pointer_size.bits() {\n+            16 => Integer::I16,\n+            32 => Integer::I32,\n+            64 => Integer::I64,\n+            bits => panic!(\"ptr_sized_integer: unknown pointer bit size {}\", bits),\n+        }\n+    }\n+}\n+\n+/// Fundamental unit of memory access and layout.\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n+pub enum Primitive {\n+    /// The `bool` is the signedness of the `Integer` type.\n+    ///\n+    /// One would think we would not care about such details this low down,\n+    /// but some ABIs are described in terms of C types and ISAs where the\n+    /// integer arithmetic is done on {sign,zero}-extended registers, e.g.\n+    /// a negative integer passed by zero-extension will appear positive in\n+    /// the callee, and most operations on it will produce the wrong values.\n+    Int(Integer, bool),\n+    F32,\n+    F64,\n+    Pointer,\n+}\n+\n+impl Primitive {\n+    pub fn size(self, dl: &TargetDataLayout) -> Size {\n+        match self {\n+            Primitive::Int(i, _) => i.size(),\n+            Primitive::F32 => Size::from_bits(32),\n+            Primitive::F64 => Size::from_bits(64),\n+            Primitive::Pointer => dl.pointer_size,\n+        }\n+    }\n+\n+    pub fn align(self, dl: &TargetDataLayout) -> AbiAndPrefAlign {\n+        match self {\n+            Primitive::Int(i, _) => i.align(dl),\n+            Primitive::F32 => dl.f32_align,\n+            Primitive::F64 => dl.f64_align,\n+            Primitive::Pointer => dl.pointer_align,\n+        }\n+    }\n+}\n+\n+/// Inclusive wrap-around range of valid values, that is, if\n+/// start > end, it represents `start..=MAX`,\n+/// followed by `0..=end`.\n+///\n+/// That is, for an i8 primitive, a range of `254..=2` means following\n+/// sequence:\n+///\n+///    254 (-2), 255 (-1), 0, 1, 2\n+///\n+/// This is intended specifically to mirror LLVM\u2019s `!range` metadata semantics.\n+#[derive(Clone, Copy, PartialEq, Eq, Hash)]\n+pub struct WrappingRange {\n+    pub start: u128,\n+    pub end: u128,\n+}\n+\n+impl WrappingRange {\n+    pub fn full(size: Size) -> Self {\n+        Self { start: 0, end: size.unsigned_int_max() }\n+    }\n+\n+    /// Returns `true` if `v` is contained in the range.\n+    #[inline(always)]\n+    pub fn contains(&self, v: u128) -> bool {\n+        if self.start <= self.end {\n+            self.start <= v && v <= self.end\n+        } else {\n+            self.start <= v || v <= self.end\n+        }\n+    }\n+\n+    /// Returns `self` with replaced `start`\n+    #[inline(always)]\n+    pub fn with_start(mut self, start: u128) -> Self {\n+        self.start = start;\n+        self\n+    }\n+\n+    /// Returns `self` with replaced `end`\n+    #[inline(always)]\n+    pub fn with_end(mut self, end: u128) -> Self {\n+        self.end = end;\n+        self\n+    }\n+\n+    /// Returns `true` if `size` completely fills the range.\n+    #[inline]\n+    pub fn is_full_for(&self, size: Size) -> bool {\n+        let max_value = size.unsigned_int_max();\n+        debug_assert!(self.start <= max_value && self.end <= max_value);\n+        self.start == (self.end.wrapping_add(1) & max_value)\n+    }\n+}\n+\n+impl fmt::Debug for WrappingRange {\n+    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        if self.start > self.end {\n+            write!(fmt, \"(..={}) | ({}..)\", self.end, self.start)?;\n+        } else {\n+            write!(fmt, \"{}..={}\", self.start, self.end)?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+/// Information about one scalar component of a Rust type.\n+#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n+pub enum Scalar {\n+    Initialized {\n+        value: Primitive,\n+\n+        // FIXME(eddyb) always use the shortest range, e.g., by finding\n+        // the largest space between two consecutive valid values and\n+        // taking everything else as the (shortest) valid range.\n+        valid_range: WrappingRange,\n+    },\n+    Union {\n+        /// Even for unions, we need to use the correct registers for the kind of\n+        /// values inside the union, so we keep the `Primitive` type around. We\n+        /// also use it to compute the size of the scalar.\n+        /// However, unions never have niches and even allow undef,\n+        /// so there is no `valid_range`.\n+        value: Primitive,\n+    },\n+}\n+\n+impl Scalar {\n+    #[inline]\n+    pub fn is_bool(&self) -> bool {\n+        matches!(\n+            self,\n+            Scalar::Initialized {\n+                value: Primitive::Int(Integer::I8, false),\n+                valid_range: WrappingRange { start: 0, end: 1 }\n+            }\n+        )\n+    }\n+\n+    /// Get the primitive representation of this type, ignoring the valid range and whether the\n+    /// value is allowed to be undefined (due to being a union).\n+    pub fn primitive(&self) -> Primitive {\n+        match *self {\n+            Scalar::Initialized { value, .. } | Scalar::Union { value } => value,\n+        }\n+    }\n+\n+    pub fn align(self, cx: &TargetDataLayout) -> AbiAndPrefAlign {\n+        self.primitive().align(cx)\n+    }\n+\n+    pub fn size(self, cx: &TargetDataLayout) -> Size {\n+        self.primitive().size(cx)\n+    }\n+\n+    #[inline]\n+    pub fn to_union(&self) -> Self {\n+        Self::Union { value: self.primitive() }\n+    }\n+\n+    #[inline]\n+    pub fn valid_range(&self, cx: &TargetDataLayout) -> WrappingRange {\n+        match *self {\n+            Scalar::Initialized { valid_range, .. } => valid_range,\n+            Scalar::Union { value } => WrappingRange::full(value.size(cx)),\n+        }\n+    }\n+\n+    #[inline]\n+    /// Allows the caller to mutate the valid range. This operation will panic if attempted on a union.\n+    pub fn valid_range_mut(&mut self) -> &mut WrappingRange {\n+        match self {\n+            Scalar::Initialized { valid_range, .. } => valid_range,\n+            Scalar::Union { .. } => panic!(\"cannot change the valid range of a union\"),\n+        }\n+    }\n+\n+    /// Returns `true` if all possible numbers are valid, i.e `valid_range` covers the whole layout\n+    #[inline]\n+    pub fn is_always_valid(&self, cx: &TargetDataLayout) -> bool {\n+        match *self {\n+            Scalar::Initialized { valid_range, .. } => valid_range.is_full_for(self.size(cx)),\n+            Scalar::Union { .. } => true,\n+        }\n+    }\n+\n+    /// Returns `true` if this type can be left uninit.\n+    #[inline]\n+    pub fn is_uninit_valid(&self) -> bool {\n+        match *self {\n+            Scalar::Initialized { .. } => false,\n+            Scalar::Union { .. } => true,\n+        }\n+    }\n+}\n+\n+/// Describes how values of the type are passed by target ABIs,\n+/// in terms of categories of C types there are ABI rules for.\n+#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n+pub enum Abi {\n+    Uninhabited,\n+    Scalar(Scalar),\n+    ScalarPair(Scalar, Scalar),\n+    Vector {\n+        element: Scalar,\n+        count: u64,\n+    },\n+    Aggregate {\n+        /// If true, the size is exact, otherwise it's only a lower bound.\n+        sized: bool,\n+    },\n+}\n+\n+impl Abi {\n+    /// Returns `true` if the layout corresponds to an unsized type.\n+    #[inline]\n+    pub fn is_unsized(&self) -> bool {\n+        match *self {\n+            Abi::Uninhabited | Abi::Scalar(_) | Abi::ScalarPair(..) | Abi::Vector { .. } => false,\n+            Abi::Aggregate { sized } => !sized,\n+        }\n+    }\n+\n+    /// Returns `true` if this is an uninhabited type\n+    #[inline]\n+    pub fn is_uninhabited(&self) -> bool {\n+        matches!(*self, Abi::Uninhabited)\n+    }\n+\n+    /// Returns `true` is this is a scalar type\n+    #[inline]\n+    pub fn is_scalar(&self) -> bool {\n+        matches!(*self, Abi::Scalar(_))\n+    }\n+}\n+\n+/// Alignment of a type in bytes (always a power of two).\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct Align {\n+    pow2: u8,\n+}\n+\n+// This is debug-printed a lot in larger structs, don't waste too much space there\n+impl fmt::Debug for Align {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        write!(f, \"Align({} bytes)\", self.bytes())\n+    }\n+}\n+\n+impl Align {\n+    pub const ONE: Align = Align { pow2: 0 };\n+    pub const MAX: Align = Align { pow2: 29 };\n+\n+    #[inline]\n+    pub fn from_bytes(align: u64) -> Result<Align, String> {\n+        // Treat an alignment of 0 bytes like 1-byte alignment.\n+        if align == 0 {\n+            return Ok(Align::ONE);\n+        }\n+\n+        #[cold]\n+        fn not_power_of_2(align: u64) -> String {\n+            format!(\"`{}` is not a power of 2\", align)\n+        }\n+\n+        #[cold]\n+        fn too_large(align: u64) -> String {\n+            format!(\"`{}` is too large\", align)\n+        }\n+\n+        let mut bytes = align;\n+        let mut pow2: u8 = 0;\n+        while (bytes & 1) == 0 {\n+            pow2 += 1;\n+            bytes >>= 1;\n+        }\n+        if bytes != 1 {\n+            return Err(not_power_of_2(align));\n+        }\n+        if pow2 > Self::MAX.pow2 {\n+            return Err(too_large(align));\n+        }\n+\n+        Ok(Align { pow2 })\n+    }\n+\n+    #[inline]\n+    pub fn bytes(self) -> u64 {\n+        1 << self.pow2\n+    }\n+\n+    #[inline]\n+    pub fn bits(self) -> u64 {\n+        self.bytes() * 8\n+    }\n+\n+    /// Computes the best alignment possible for the given offset\n+    /// (the largest power of two that the offset is a multiple of).\n+    ///\n+    /// N.B., for an offset of `0`, this happens to return `2^64`.\n+    #[inline]\n+    pub fn max_for_offset(offset: Size) -> Align {\n+        Align { pow2: offset.bytes().trailing_zeros() as u8 }\n+    }\n+\n+    /// Lower the alignment, if necessary, such that the given offset\n+    /// is aligned to it (the offset is a multiple of the alignment).\n+    #[inline]\n+    pub fn restrict_for_offset(self, offset: Size) -> Align {\n+        self.min(Align::max_for_offset(offset))\n+    }\n+}\n+\n+/// A pair of alignments, ABI-mandated and preferred.\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n+pub struct AbiAndPrefAlign {\n+    pub abi: Align,\n+    pub pref: Align,\n+}\n+\n+impl AbiAndPrefAlign {\n+    #[inline]\n+    pub fn new(align: Align) -> AbiAndPrefAlign {\n+        AbiAndPrefAlign { abi: align, pref: align }\n+    }\n+\n+    #[inline]\n+    pub fn min(self, other: AbiAndPrefAlign) -> AbiAndPrefAlign {\n+        AbiAndPrefAlign { abi: self.abi.min(other.abi), pref: self.pref.min(other.pref) }\n+    }\n+\n+    #[inline]\n+    pub fn max(self, other: AbiAndPrefAlign) -> AbiAndPrefAlign {\n+        AbiAndPrefAlign { abi: self.abi.max(other.abi), pref: self.pref.max(other.pref) }\n+    }\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n+pub struct Niche {\n+    pub offset: Size,\n+    pub value: Primitive,\n+    pub valid_range: WrappingRange,\n+}\n+\n+impl Niche {\n+    pub fn from_scalar(cx: &TargetDataLayout, offset: Size, scalar: Scalar) -> Option<Self> {\n+        let (value, valid_range) = match scalar {\n+            Scalar::Initialized { value, valid_range } => (value, valid_range),\n+            _ => return None,\n+        };\n+        let niche = Niche { offset, value, valid_range };\n+        if niche.available(cx) > 0 {\n+            Some(niche)\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn available(&self, cx: &TargetDataLayout) -> u128 {\n+        let Self { value, valid_range: v, .. } = *self;\n+        let size = value.size(cx);\n+        assert!(size.bits() <= 128);\n+        let max_value = size.unsigned_int_max();\n+\n+        // Find out how many values are outside the valid range.\n+        let niche = v.end.wrapping_add(1)..v.start;\n+        niche.end.wrapping_sub(niche.start) & max_value\n+    }\n+\n+    pub fn reserve(&self, cx: &TargetDataLayout, count: u128) -> Option<(u128, Scalar)> {\n+        assert!(count > 0);\n+\n+        let Self { value, valid_range: v, .. } = *self;\n+        let size = value.size(cx);\n+        assert!(size.bits() <= 128);\n+        let max_value = size.unsigned_int_max();\n+\n+        let niche = v.end.wrapping_add(1)..v.start;\n+        let available = niche.end.wrapping_sub(niche.start) & max_value;\n+        if count > available {\n+            return None;\n+        }\n+\n+        // Extend the range of valid values being reserved by moving either `v.start` or `v.end` bound.\n+        // Given an eventual `Option<T>`, we try to maximize the chance for `None` to occupy the niche of zero.\n+        // This is accomplished by preferring enums with 2 variants(`count==1`) and always taking the shortest path to niche zero.\n+        // Having `None` in niche zero can enable some special optimizations.\n+        //\n+        // Bound selection criteria:\n+        // 1. Select closest to zero given wrapping semantics.\n+        // 2. Avoid moving past zero if possible.\n+        //\n+        // In practice this means that enums with `count > 1` are unlikely to claim niche zero, since they have to fit perfectly.\n+        // If niche zero is already reserved, the selection of bounds are of little interest.\n+        let move_start = |v: WrappingRange| {\n+            let start = v.start.wrapping_sub(count) & max_value;\n+            Some((start, Scalar::Initialized { value, valid_range: v.with_start(start) }))\n+        };\n+        let move_end = |v: WrappingRange| {\n+            let start = v.end.wrapping_add(1) & max_value;\n+            let end = v.end.wrapping_add(count) & max_value;\n+            Some((start, Scalar::Initialized { value, valid_range: v.with_end(end) }))\n+        };\n+        let distance_end_zero = max_value - v.end;\n+        if v.start > v.end {\n+            // zero is unavailable because wrapping occurs\n+            move_end(v)\n+        } else if v.start <= distance_end_zero {\n+            if count <= v.start {\n+                move_start(v)\n+            } else {\n+                // moved past zero, use other bound\n+                move_end(v)\n+            }\n+        } else {\n+            let end = v.end.wrapping_add(count) & max_value;\n+            let overshot_zero = (1..=v.end).contains(&end);\n+            if overshot_zero {\n+                // moved past zero, use other bound\n+                move_start(v)\n+            } else {\n+                move_end(v)\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(PartialEq, Eq, Hash, Debug, Clone)]\n+pub enum TagEncoding {\n+    /// The tag directly stores the discriminant, but possibly with a smaller layout\n+    /// (so converting the tag to the discriminant can require sign extension).\n+    Direct,\n+\n+    /// Niche (values invalid for a type) encoding the discriminant:\n+    /// Discriminant and variant index coincide.\n+    /// The variant `untagged_variant` contains a niche at an arbitrary\n+    /// offset (field `tag_field` of the enum), which for a variant with\n+    /// discriminant `d` is set to\n+    /// `(d - niche_variants.start).wrapping_add(niche_start)`.\n+    ///\n+    /// For example, `Option<(usize, &T)>`  is represented such that\n+    /// `None` has a null pointer for the second tuple field, and\n+    /// `Some` is the identity function (with a non-null reference).\n+    Niche { untagged_variant: LocalEnumVariantId, niche_start: u128 },\n+}\n+\n+#[derive(PartialEq, Eq, Hash, Debug, Clone)]\n+pub enum Variants {\n+    /// Single enum variants, structs/tuples, unions, and all non-ADTs.\n+    Single,\n+\n+    /// Enum-likes with more than one inhabited variant: each variant comes with\n+    /// a *discriminant* (usually the same as the variant index but the user can\n+    /// assign explicit discriminant values).  That discriminant is encoded\n+    /// as a *tag* on the machine.  The layout of each variant is\n+    /// a struct, and they all have space reserved for the tag.\n+    /// For enums, the tag is the sole field of the layout.\n+    Multiple {\n+        tag: Scalar,\n+        tag_encoding: TagEncoding,\n+        tag_field: usize,\n+        variants: ArenaMap<LocalEnumVariantId, Layout>,\n+    },\n+}\n+\n+bitflags! {\n+    #[derive(Default)]\n+    pub struct ReprFlags: u8 {\n+        const IS_C               = 1 << 0;\n+        const IS_SIMD            = 1 << 1;\n+        const IS_TRANSPARENT     = 1 << 2;\n+        // Internal only for now. If true, don't reorder fields.\n+        const IS_LINEAR          = 1 << 3;\n+        // Any of these flags being set prevent field reordering optimisation.\n+        const IS_UNOPTIMISABLE   = ReprFlags::IS_C.bits\n+                                 | ReprFlags::IS_SIMD.bits\n+                                 | ReprFlags::IS_LINEAR.bits;\n+    }\n+}\n+\n+/// Represents the repr options provided by the user,\n+#[derive(Copy, Clone, Debug, Eq, PartialEq, Default)]\n+pub struct ReprOptions {\n+    pub int: Option<Either<BuiltinInt, BuiltinUint>>,\n+    pub align: Option<Align>,\n+    pub pack: Option<Align>,\n+    pub flags: ReprFlags,\n+}\n+\n+impl ReprOptions {\n+    #[inline]\n+    pub fn simd(&self) -> bool {\n+        self.flags.contains(ReprFlags::IS_SIMD)\n+    }\n+\n+    #[inline]\n+    pub fn c(&self) -> bool {\n+        self.flags.contains(ReprFlags::IS_C)\n+    }\n+\n+    #[inline]\n+    pub fn packed(&self) -> bool {\n+        self.pack.is_some()\n+    }\n+\n+    #[inline]\n+    pub fn transparent(&self) -> bool {\n+        self.flags.contains(ReprFlags::IS_TRANSPARENT)\n+    }\n+\n+    #[inline]\n+    pub fn linear(&self) -> bool {\n+        self.flags.contains(ReprFlags::IS_LINEAR)\n+    }\n+\n+    /// Returns the discriminant type, given these `repr` options.\n+    /// This must only be called on enums!\n+    pub fn discr_type(&self) -> Either<BuiltinInt, BuiltinUint> {\n+        self.int.unwrap_or(Either::Left(BuiltinInt::Isize))\n+    }\n+\n+    /// Returns `true` if this `#[repr()]` should inhabit \"smart enum\n+    /// layout\" optimizations, such as representing `Foo<&T>` as a\n+    /// single pointer.\n+    pub fn inhibit_enum_layout_opt(&self) -> bool {\n+        self.c() || self.int.is_some()\n+    }\n+\n+    /// Returns `true` if this `#[repr()]` should inhibit struct field reordering\n+    /// optimizations, such as with `repr(C)`, `repr(packed(1))`, or `repr(<int>)`.\n+    pub fn inhibit_struct_field_reordering_opt(&self) -> bool {\n+        if let Some(pack) = self.pack {\n+            if pack.bytes() == 1 {\n+                return true;\n+            }\n+        }\n+\n+        self.flags.intersects(ReprFlags::IS_UNOPTIMISABLE) || self.int.is_some()\n+    }\n+\n+    /// Returns `true` if this `#[repr()]` should inhibit union ABI optimisations.\n+    pub fn inhibit_union_abi_opt(&self) -> bool {\n+        self.c()\n+    }\n+}\n+\n+#[derive(PartialEq, Eq, Hash, Clone)]\n+pub struct Layout {\n+    /// Says where the fields are located within the layout.\n+    pub fields: FieldsShape,\n+\n+    /// Encodes information about multi-variant layouts.\n+    /// Even with `Multiple` variants, a layout still has its own fields! Those are then\n+    /// shared between all variants. One of them will be the discriminant,\n+    /// but e.g. generators can have more.\n+    ///\n+    /// To access all fields of this layout, both `fields` and the fields of the active variant\n+    /// must be taken into account.\n+    pub variants: Variants,\n+\n+    /// The `abi` defines how this data is passed between functions, and it defines\n+    /// value restrictions via `valid_range`.\n+    ///\n+    /// Note that this is entirely orthogonal to the recursive structure defined by\n+    /// `variants` and `fields`; for example, `ManuallyDrop<Result<isize, isize>>` has\n+    /// `Abi::ScalarPair`! So, even with non-`Aggregate` `abi`, `fields` and `variants`\n+    /// have to be taken into account to find all fields of this layout.\n+    pub abi: Abi,\n+\n+    /// The leaf scalar with the largest number of invalid values\n+    /// (i.e. outside of its `valid_range`), if it exists.\n+    pub largest_niche: Option<Niche>,\n+\n+    pub align: AbiAndPrefAlign,\n+    pub size: Size,\n+}\n+\n+impl Layout {\n+    pub fn scalar(dl: &TargetDataLayout, scalar: Scalar) -> Self {\n+        let largest_niche = Niche::from_scalar(dl, Size::ZERO, scalar);\n+        let size = scalar.size(dl);\n+        let align = scalar.align(dl);\n+        Layout {\n+            variants: Variants::Single,\n+            fields: FieldsShape::Primitive,\n+            abi: Abi::Scalar(scalar),\n+            largest_niche,\n+            size,\n+            align,\n+        }\n+    }\n+}\n+\n+impl fmt::Debug for Layout {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        // This is how `Layout` used to print before it become\n+        // `Interned<LayoutS>`. We print it like this to avoid having to update\n+        // expected output in a lot of tests.\n+        let Layout { size, align, abi, fields, largest_niche, variants } = self;\n+        f.debug_struct(\"Layout\")\n+            .field(\"size\", size)\n+            .field(\"align\", align)\n+            .field(\"abi\", abi)\n+            .field(\"fields\", fields)\n+            .field(\"largest_niche\", largest_niche)\n+            .field(\"variants\", variants)\n+            .finish()\n+    }\n+}\n+\n+impl Layout {\n+    pub fn is_unsized(&self) -> bool {\n+        self.abi.is_unsized()\n+    }\n+\n+    /// Returns `true` if the type is a ZST and not unsized.\n+    pub fn is_zst(&self) -> bool {\n+        match self.abi {\n+            Abi::Scalar(_) | Abi::ScalarPair(..) | Abi::Vector { .. } => false,\n+            Abi::Uninhabited => self.size.bytes() == 0,\n+            Abi::Aggregate { sized } => sized && self.size.bytes() == 0,\n+        }\n+    }\n+}\n+\n+#[derive(Debug, PartialEq, Eq, Clone)]\n+pub enum LayoutError {\n+    UserError(String),\n+    SizeOverflow,\n+    HasPlaceholder,\n+    NotImplemented,\n+}"}, {"sha": "8267ef09cb0a2e81b39d91def9927dfa541c94a6", "filename": "crates/hir-def/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-def%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-def%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Flib.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -34,6 +34,7 @@ pub mod adt;\n pub mod data;\n pub mod generics;\n pub mod lang_item;\n+pub mod layout;\n \n pub mod expr;\n pub mod body;"}, {"sha": "beff3f6ad9624ebdf55846253de9d356cd52e15c", "filename": "crates/hir-expand/src/name.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-expand%2Fsrc%2Fname.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-expand%2Fsrc%2Fname.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-expand%2Fsrc%2Fname.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -419,6 +419,7 @@ pub mod known {\n         shr,\n         sub_assign,\n         sub,\n+        unsafe_cell,\n         va_list\n     );\n "}, {"sha": "e80f18811f29b407cc06096318f5bae6bdbefc19", "filename": "crates/hir-ty/src/db.rs", "status": "modified", "additions": 13, "deletions": 3, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Fdb.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -6,8 +6,11 @@ use std::sync::Arc;\n use arrayvec::ArrayVec;\n use base_db::{impl_intern_key, salsa, CrateId, Upcast};\n use hir_def::{\n-    db::DefDatabase, expr::ExprId, BlockId, ConstId, ConstParamId, DefWithBodyId, EnumVariantId,\n-    FunctionId, GenericDefId, ImplId, LifetimeParamId, LocalFieldId, TypeOrConstParamId, VariantId,\n+    db::DefDatabase,\n+    expr::ExprId,\n+    layout::{Layout, LayoutError, TargetDataLayout},\n+    AdtId, BlockId, ConstId, ConstParamId, DefWithBodyId, EnumVariantId, FunctionId, GenericDefId,\n+    ImplId, LifetimeParamId, LocalFieldId, TypeOrConstParamId, VariantId,\n };\n use la_arena::ArenaMap;\n \n@@ -16,7 +19,7 @@ use crate::{\n     consteval::{ComputedExpr, ConstEvalError},\n     method_resolution::{InherentImpls, TraitImpls, TyFingerprint},\n     Binders, CallableDefId, FnDefId, GenericArg, ImplTraitId, InferenceResult, Interner, PolyFnSig,\n-    QuantifiedWhereClause, ReturnTypeImplTraits, TraitRef, Ty, TyDefId, ValueTyDefId,\n+    QuantifiedWhereClause, ReturnTypeImplTraits, Substitution, TraitRef, Ty, TyDefId, ValueTyDefId,\n };\n use hir_expand::name::Name;\n \n@@ -57,6 +60,13 @@ pub trait HirDatabase: DefDatabase + Upcast<dyn DefDatabase> {\n     #[salsa::invoke(crate::lower::field_types_query)]\n     fn field_types(&self, var: VariantId) -> Arc<ArenaMap<LocalFieldId, Binders<Ty>>>;\n \n+    #[salsa::invoke(crate::layout::layout_of_adt_query)]\n+    #[salsa::cycle(crate::layout::layout_of_adt_recover)]\n+    fn layout_of_adt(&self, def: AdtId, subst: Substitution) -> Result<Layout, LayoutError>;\n+\n+    #[salsa::invoke(crate::layout::current_target_data_layout_query)]\n+    fn current_target_data_layout(&self) -> Arc<TargetDataLayout>;\n+\n     #[salsa::invoke(crate::lower::callable_item_sig)]\n     fn callable_item_signature(&self, def: CallableDefId) -> PolyFnSig;\n "}, {"sha": "e0905e01b6a1a49cd92fad87bb519b838230e424", "filename": "crates/hir-ty/src/diagnostics/match_check.rs", "status": "modified", "additions": 3, "deletions": 10, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Fdiagnostics%2Fmatch_check.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Fdiagnostics%2Fmatch_check.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Fdiagnostics%2Fmatch_check.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -12,16 +12,16 @@ pub(crate) mod usefulness;\n \n use chalk_ir::Mutability;\n use hir_def::{\n-    adt::VariantData, body::Body, expr::PatId, AdtId, EnumVariantId, HasModule, LocalFieldId,\n-    VariantId,\n+    adt::VariantData, body::Body, expr::PatId, AdtId, EnumVariantId, LocalFieldId, VariantId,\n };\n-use hir_expand::name::{name, Name};\n+use hir_expand::name::Name;\n use stdx::{always, never};\n \n use crate::{\n     db::HirDatabase,\n     display::{HirDisplay, HirDisplayError, HirFormatter},\n     infer::BindingMode,\n+    lang_items::is_box,\n     InferenceResult, Interner, Substitution, Ty, TyExt, TyKind,\n };\n \n@@ -405,13 +405,6 @@ where\n     }\n }\n \n-fn is_box(adt: AdtId, db: &dyn HirDatabase) -> bool {\n-    let owned_box = name![owned_box].to_smol_str();\n-    let krate = adt.module(db.upcast()).krate();\n-    let box_adt = db.lang_item(krate, owned_box).and_then(|it| it.as_struct()).map(AdtId::from);\n-    Some(adt) == box_adt\n-}\n-\n pub(crate) trait PatternFoldable: Sized {\n     fn fold_with<F: PatternFolder>(&self, folder: &mut F) -> Self {\n         self.super_fold_with(folder)"}, {"sha": "afc54e729f9c3972e2134692eafa748a2ec223dd", "filename": "crates/hir-ty/src/lang_items.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flang_items.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flang_items.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flang_items.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -0,0 +1,20 @@\n+//! Functions to detect special lang items\n+\n+use hir_def::{AdtId, HasModule};\n+use hir_expand::name;\n+\n+use crate::db::HirDatabase;\n+\n+pub fn is_box(adt: AdtId, db: &dyn HirDatabase) -> bool {\n+    let owned_box = name![owned_box].to_smol_str();\n+    let krate = adt.module(db.upcast()).krate();\n+    let box_adt = db.lang_item(krate, owned_box).and_then(|it| it.as_struct()).map(AdtId::from);\n+    Some(adt) == box_adt\n+}\n+\n+pub fn is_unsafe_cell(adt: AdtId, db: &dyn HirDatabase) -> bool {\n+    let owned_box = name![unsafe_cell].to_smol_str();\n+    let krate = adt.module(db.upcast()).krate();\n+    let box_adt = db.lang_item(krate, owned_box).and_then(|it| it.as_struct()).map(AdtId::from);\n+    Some(adt) == box_adt\n+}"}, {"sha": "ca39fde11898b5d2c66683cf994b2af923dbb9ca", "filename": "crates/hir-ty/src/layout.rs", "status": "added", "additions": 271, "deletions": 0, "changes": 271, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -0,0 +1,271 @@\n+//! Compute the binary representation of a type\n+\n+use chalk_ir::{AdtId, TyKind};\n+pub(self) use hir_def::layout::*;\n+use hir_def::LocalFieldId;\n+\n+use crate::{db::HirDatabase, Interner, Substitution, Ty};\n+\n+use self::adt::univariant;\n+pub use self::{\n+    adt::{layout_of_adt_query, layout_of_adt_recover},\n+    target::current_target_data_layout_query,\n+};\n+\n+macro_rules! user_error {\n+    ($x: expr) => {\n+        return Err(LayoutError::UserError(format!($x)))\n+    };\n+}\n+\n+mod adt;\n+mod target;\n+\n+fn scalar_unit(dl: &TargetDataLayout, value: Primitive) -> Scalar {\n+    Scalar::Initialized { value, valid_range: WrappingRange::full(value.size(dl)) }\n+}\n+\n+fn scalar(dl: &TargetDataLayout, value: Primitive) -> Layout {\n+    Layout::scalar(dl, scalar_unit(dl, value))\n+}\n+\n+fn scalar_pair(dl: &TargetDataLayout, a: Scalar, b: Scalar) -> Layout {\n+    let b_align = b.align(dl);\n+    let align = a.align(dl).max(b_align).max(dl.aggregate_align);\n+    let b_offset = a.size(dl).align_to(b_align.abi);\n+    let size = b_offset.checked_add(b.size(dl), dl).unwrap().align_to(align.abi);\n+\n+    // HACK(nox): We iter on `b` and then `a` because `max_by_key`\n+    // returns the last maximum.\n+    let largest_niche = Niche::from_scalar(dl, b_offset, b)\n+        .into_iter()\n+        .chain(Niche::from_scalar(dl, Size::ZERO, a))\n+        .max_by_key(|niche| niche.available(dl));\n+\n+    Layout {\n+        variants: Variants::Single,\n+        fields: FieldsShape::Arbitrary {\n+            offsets: vec![Size::ZERO, b_offset],\n+            memory_index: vec![0, 1],\n+        },\n+        abi: Abi::ScalarPair(a, b),\n+        largest_niche,\n+        align,\n+        size,\n+    }\n+}\n+\n+pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError> {\n+    let dl = &*db.current_target_data_layout();\n+    Ok(match ty.kind(Interner) {\n+        TyKind::Adt(AdtId(def), subst) => db.layout_of_adt(*def, subst.clone())?,\n+        TyKind::Scalar(s) => match s {\n+            chalk_ir::Scalar::Bool => Layout::scalar(\n+                dl,\n+                Scalar::Initialized {\n+                    value: Primitive::Int(Integer::I8, false),\n+                    valid_range: WrappingRange { start: 0, end: 1 },\n+                },\n+            ),\n+            chalk_ir::Scalar::Char => Layout::scalar(\n+                dl,\n+                Scalar::Initialized {\n+                    value: Primitive::Int(Integer::I32, false),\n+                    valid_range: WrappingRange { start: 0, end: 0x10FFFF },\n+                },\n+            ),\n+            chalk_ir::Scalar::Int(i) => scalar(\n+                dl,\n+                Primitive::Int(\n+                    match i {\n+                        chalk_ir::IntTy::Isize => dl.ptr_sized_integer(),\n+                        chalk_ir::IntTy::I8 => Integer::I8,\n+                        chalk_ir::IntTy::I16 => Integer::I16,\n+                        chalk_ir::IntTy::I32 => Integer::I32,\n+                        chalk_ir::IntTy::I64 => Integer::I64,\n+                        chalk_ir::IntTy::I128 => Integer::I128,\n+                    },\n+                    false,\n+                ),\n+            ),\n+            chalk_ir::Scalar::Uint(i) => scalar(\n+                dl,\n+                Primitive::Int(\n+                    match i {\n+                        chalk_ir::UintTy::Usize => dl.ptr_sized_integer(),\n+                        chalk_ir::UintTy::U8 => Integer::I8,\n+                        chalk_ir::UintTy::U16 => Integer::I16,\n+                        chalk_ir::UintTy::U32 => Integer::I32,\n+                        chalk_ir::UintTy::U64 => Integer::I64,\n+                        chalk_ir::UintTy::U128 => Integer::I128,\n+                    },\n+                    true,\n+                ),\n+            ),\n+            chalk_ir::Scalar::Float(f) => scalar(\n+                dl,\n+                match f {\n+                    chalk_ir::FloatTy::F32 => Primitive::F32,\n+                    chalk_ir::FloatTy::F64 => Primitive::F64,\n+                },\n+            ),\n+        },\n+        TyKind::Tuple(len, tys) => {\n+            let kind = if *len == 0 { StructKind::AlwaysSized } else { StructKind::MaybeUnsized };\n+\n+            univariant(\n+                dl,\n+                &tys.iter(Interner)\n+                    .map(|k| layout_of_ty(db, k.assert_ty_ref(Interner)))\n+                    .collect::<Result<Vec<_>, _>>()?,\n+                &ReprOptions::default(),\n+                kind,\n+            )?\n+        }\n+        TyKind::Array(element, count) => {\n+            let count = match count.data(Interner).value {\n+                chalk_ir::ConstValue::Concrete(c) => match c.interned {\n+                    hir_def::type_ref::ConstScalar::Int(x) => x as u64,\n+                    hir_def::type_ref::ConstScalar::UInt(x) => x as u64,\n+                    hir_def::type_ref::ConstScalar::Unknown => {\n+                        user_error!(\"unknown const generic parameter\")\n+                    }\n+                    _ => user_error!(\"mismatched type of const generic parameter\"),\n+                },\n+                _ => return Err(LayoutError::HasPlaceholder),\n+            };\n+            let element = layout_of_ty(db, element)?;\n+            let size = element.size.checked_mul(count, dl).ok_or(LayoutError::SizeOverflow)?;\n+\n+            let abi = if count != 0 && matches!(element.abi, Abi::Uninhabited) {\n+                Abi::Uninhabited\n+            } else {\n+                Abi::Aggregate { sized: true }\n+            };\n+\n+            let largest_niche = if count != 0 { element.largest_niche } else { None };\n+\n+            Layout {\n+                variants: Variants::Single,\n+                fields: FieldsShape::Array { stride: element.size, count },\n+                abi,\n+                largest_niche,\n+                align: element.align,\n+                size,\n+            }\n+        }\n+        TyKind::Slice(element) => {\n+            let element = layout_of_ty(db, element)?;\n+            Layout {\n+                variants: Variants::Single,\n+                fields: FieldsShape::Array { stride: element.size, count: 0 },\n+                abi: Abi::Aggregate { sized: false },\n+                largest_niche: None,\n+                align: element.align,\n+                size: Size::ZERO,\n+            }\n+        }\n+        // Potentially-wide pointers.\n+        TyKind::Ref(_, _, pointee) | TyKind::Raw(_, pointee) => {\n+            let mut data_ptr = scalar_unit(dl, Primitive::Pointer);\n+            if matches!(ty.kind(Interner), TyKind::Ref(..)) {\n+                data_ptr.valid_range_mut().start = 1;\n+            }\n+\n+            // let pointee = tcx.normalize_erasing_regions(param_env, pointee);\n+            // if pointee.is_sized(tcx.at(DUMMY_SP), param_env) {\n+            //     return Ok(tcx.intern_layout(LayoutS::scalar(cx, data_ptr)));\n+            // }\n+\n+            let unsized_part = struct_tail_erasing_lifetimes(db, pointee.clone());\n+            let metadata = match unsized_part.kind(Interner) {\n+                TyKind::Slice(_) | TyKind::Str => {\n+                    scalar_unit(dl, Primitive::Int(dl.ptr_sized_integer(), false))\n+                }\n+                TyKind::Dyn(..) => {\n+                    let mut vtable = scalar_unit(dl, Primitive::Pointer);\n+                    vtable.valid_range_mut().start = 1;\n+                    vtable\n+                }\n+                _ => {\n+                    // pointee is sized\n+                    return Ok(Layout::scalar(dl, data_ptr));\n+                }\n+            };\n+\n+            // Effectively a (ptr, meta) tuple.\n+            scalar_pair(dl, data_ptr, metadata)\n+        }\n+        TyKind::FnDef(_, _) => {\n+            univariant(dl, &[], &ReprOptions::default(), StructKind::AlwaysSized)?\n+        }\n+        TyKind::Str => Layout {\n+            variants: Variants::Single,\n+            fields: FieldsShape::Array { stride: Size::from_bytes(1), count: 0 },\n+            abi: Abi::Aggregate { sized: false },\n+            largest_niche: None,\n+            align: dl.i8_align,\n+            size: Size::ZERO,\n+        },\n+        TyKind::Never => Layout {\n+            variants: Variants::Single,\n+            fields: FieldsShape::Primitive,\n+            abi: Abi::Uninhabited,\n+            largest_niche: None,\n+            align: dl.i8_align,\n+            size: Size::ZERO,\n+        },\n+        TyKind::Dyn(_) | TyKind::Foreign(_) => {\n+            let mut unit = univariant(dl, &[], &ReprOptions::default(), StructKind::AlwaysSized)?;\n+            match unit.abi {\n+                Abi::Aggregate { ref mut sized } => *sized = false,\n+                _ => user_error!(\"bug\"),\n+            }\n+            unit\n+        }\n+        TyKind::Function(_) => {\n+            let mut ptr = scalar_unit(dl, Primitive::Pointer);\n+            ptr.valid_range_mut().start = 1;\n+            Layout::scalar(dl, ptr)\n+        }\n+        TyKind::Closure(_, _)\n+        | TyKind::OpaqueType(_, _)\n+        | TyKind::Generator(_, _)\n+        | TyKind::GeneratorWitness(_, _) => return Err(LayoutError::NotImplemented),\n+        TyKind::AssociatedType(_, _)\n+        | TyKind::Error\n+        | TyKind::Alias(_)\n+        | TyKind::Placeholder(_)\n+        | TyKind::BoundVar(_)\n+        | TyKind::InferenceVar(_, _) => return Err(LayoutError::HasPlaceholder),\n+    })\n+}\n+\n+fn struct_tail_erasing_lifetimes(db: &dyn HirDatabase, pointee: Ty) -> Ty {\n+    match pointee.kind(Interner) {\n+        TyKind::Adt(AdtId(adt), subst) => match adt {\n+            &hir_def::AdtId::StructId(i) => {\n+                let data = db.struct_data(i);\n+                let mut it = data.variant_data.fields().iter().rev();\n+                match it.next() {\n+                    Some((f, _)) => field_ty(db, i.into(), f, subst),\n+                    None => pointee,\n+                }\n+            }\n+            _ => pointee,\n+        },\n+        _ => pointee,\n+    }\n+}\n+\n+fn field_ty(\n+    db: &dyn HirDatabase,\n+    def: hir_def::VariantId,\n+    fd: LocalFieldId,\n+    subst: &Substitution,\n+) -> Ty {\n+    db.field_types(def)[fd].clone().substitute(Interner, subst)\n+}\n+\n+#[cfg(test)]\n+mod tests;"}, {"sha": "e353034eb99f0042ad89a60a6693500a5ea42c1b", "filename": "crates/hir-ty/src/layout/adt.rs", "status": "added", "additions": 900, "deletions": 0, "changes": 900, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout%2Fadt.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -0,0 +1,900 @@\n+//! Compute the binary representation of structs, unions and enums\n+\n+use std::{\n+    cmp::{self, Ordering},\n+    iter,\n+    num::NonZeroUsize,\n+};\n+\n+use chalk_ir::TyKind;\n+use hir_def::{\n+    adt::VariantData,\n+    layout::{\n+        Abi, AbiAndPrefAlign, Align, FieldsShape, Integer, Layout, LayoutError, Niche, Primitive,\n+        ReprOptions, Scalar, Size, StructKind, TagEncoding, TargetDataLayout, Variants,\n+        WrappingRange,\n+    },\n+    AdtId, EnumVariantId, LocalEnumVariantId, UnionId, VariantId,\n+};\n+use la_arena::{ArenaMap, RawIdx};\n+\n+use crate::{\n+    db::HirDatabase,\n+    lang_items::is_unsafe_cell,\n+    layout::{field_ty, scalar_unit},\n+    Interner, Substitution,\n+};\n+\n+use super::layout_of_ty;\n+\n+pub fn layout_of_adt_query(\n+    db: &dyn HirDatabase,\n+    def: AdtId,\n+    subst: Substitution,\n+) -> Result<Layout, LayoutError> {\n+    let handle_variant = |def: VariantId, var: &VariantData| {\n+        var.fields()\n+            .iter()\n+            .map(|(fd, _)| layout_of_ty(db, &field_ty(db, def, fd, &subst)))\n+            .collect::<Result<Vec<_>, _>>()\n+    };\n+    fn struct_variant_idx() -> LocalEnumVariantId {\n+        LocalEnumVariantId::from_raw(RawIdx::from(0))\n+    }\n+    let (variants, is_enum, repr) = match def {\n+        AdtId::StructId(s) => {\n+            let data = db.struct_data(s);\n+            let mut r = ArenaMap::new();\n+            r.insert(struct_variant_idx(), handle_variant(s.into(), &data.variant_data)?);\n+            (r, false, data.repr.unwrap_or_default())\n+        }\n+        AdtId::UnionId(id) => return layout_of_union(db, id, &subst),\n+        AdtId::EnumId(e) => {\n+            let data = db.enum_data(e);\n+            let r = data\n+                .variants\n+                .iter()\n+                .map(|(idx, v)| {\n+                    Ok((\n+                        idx,\n+                        handle_variant(\n+                            EnumVariantId { parent: e, local_id: idx }.into(),\n+                            &v.variant_data,\n+                        )?,\n+                    ))\n+                })\n+                .collect::<Result<_, _>>()?;\n+            (r, true, data.repr.unwrap_or_default())\n+        }\n+    };\n+\n+    // A variant is absent if it's uninhabited and only has ZST fields.\n+    // Present uninhabited variants only require space for their fields,\n+    // but *not* an encoding of the discriminant (e.g., a tag value).\n+    // See issue #49298 for more details on the need to leave space\n+    // for non-ZST uninhabited data (mostly partial initialization).\n+    let absent = |fields: &[Layout]| {\n+        let uninhabited = fields.iter().any(|f| f.abi.is_uninhabited());\n+        let is_zst = fields.iter().all(|f| f.is_zst());\n+        uninhabited && is_zst\n+    };\n+    let (present_first, present_second) = {\n+        let mut present_variants =\n+            variants.iter().filter_map(|(i, v)| if absent(v) { None } else { Some(i) });\n+        (present_variants.next(), present_variants.next())\n+    };\n+    let present_first = match present_first {\n+        Some(present_first) => present_first,\n+        // Uninhabited because it has no variants, or only absent ones.\n+        None if is_enum => return layout_of_ty(db, &TyKind::Never.intern(Interner)),\n+        // If it's a struct, still compute a layout so that we can still compute the\n+        // field offsets.\n+        None => struct_variant_idx(),\n+    };\n+\n+    let is_univariant = !is_enum ||\n+                    // Only one variant is present.\n+                    (present_second.is_none() &&\n+                        // Representation optimizations are allowed.\n+                        !repr.inhibit_enum_layout_opt());\n+    let dl = &*db.current_target_data_layout();\n+\n+    if is_univariant {\n+        // Struct, or univariant enum equivalent to a struct.\n+        // (Typechecking will reject discriminant-sizing attrs.)\n+\n+        let v = present_first;\n+        let kind = if is_enum || variants[v].is_empty() {\n+            StructKind::AlwaysSized\n+        } else {\n+            let always_sized = !variants[v].last().unwrap().is_unsized();\n+            if !always_sized {\n+                StructKind::MaybeUnsized\n+            } else {\n+                StructKind::AlwaysSized\n+            }\n+        };\n+\n+        let mut st = univariant(dl, &variants[v], &repr, kind)?;\n+        st.variants = Variants::Single;\n+\n+        if is_unsafe_cell(def, db) {\n+            let hide_niches = |scalar: &mut _| match scalar {\n+                Scalar::Initialized { value, valid_range } => {\n+                    *valid_range = WrappingRange::full(value.size(dl))\n+                }\n+                // Already doesn't have any niches\n+                Scalar::Union { .. } => {}\n+            };\n+            match &mut st.abi {\n+                Abi::Uninhabited => {}\n+                Abi::Scalar(scalar) => hide_niches(scalar),\n+                Abi::ScalarPair(a, b) => {\n+                    hide_niches(a);\n+                    hide_niches(b);\n+                }\n+                Abi::Vector { element, count: _ } => hide_niches(element),\n+                Abi::Aggregate { sized: _ } => {}\n+            }\n+            st.largest_niche = None;\n+        }\n+        return Ok(st);\n+    }\n+\n+    // Until we've decided whether to use the tagged or\n+    // niche filling LayoutS, we don't want to intern the\n+    // variant layouts, so we can't store them in the\n+    // overall LayoutS. Store the overall LayoutS\n+    // and the variant LayoutSs here until then.\n+    struct TmpLayout {\n+        layout: Layout,\n+        variants: ArenaMap<LocalEnumVariantId, Layout>,\n+    }\n+\n+    let calculate_niche_filling_layout = || -> Result<Option<TmpLayout>, LayoutError> {\n+        // The current code for niche-filling relies on variant indices\n+        // instead of actual discriminants, so enums with\n+        // explicit discriminants (RFC #2363) would misbehave.\n+        if repr.inhibit_enum_layout_opt()\n+        // FIXME: bring these codes back\n+        // || def\n+        //     .variants()\n+        //     .iter_enumerated()\n+        //     .any(|(i, v)| v.discr != ty::VariantDiscr::Relative(i.as_u32()))\n+        {\n+            return Ok(None);\n+        }\n+\n+        if variants.iter().count() < 2 {\n+            return Ok(None);\n+        }\n+\n+        let mut align = dl.aggregate_align;\n+        let mut variant_layouts = variants\n+            .iter()\n+            .map(|(j, v)| {\n+                let mut st = univariant(dl, v, &repr, StructKind::AlwaysSized)?;\n+                st.variants = Variants::Single;\n+\n+                align = align.max(st.align);\n+\n+                Ok((j, st))\n+            })\n+            .collect::<Result<ArenaMap<_, _>, _>>()?;\n+\n+        let largest_variant_index = match variant_layouts\n+            .iter()\n+            .max_by_key(|(_i, layout)| layout.size.bytes())\n+            .map(|(i, _layout)| i)\n+        {\n+            None => return Ok(None),\n+            Some(i) => i,\n+        };\n+\n+        let count = variants\n+            .iter()\n+            .map(|(i, _)| i)\n+            .filter(|x| *x != largest_variant_index && !absent(&variants[*x]))\n+            .count() as u128;\n+\n+        // Find the field with the largest niche\n+        let (field_index, niche, (niche_start, niche_scalar)) = match variants\n+            [largest_variant_index]\n+            .iter()\n+            .enumerate()\n+            .filter_map(|(j, field)| Some((j, field.largest_niche?)))\n+            .max_by_key(|(_, niche)| niche.available(dl))\n+            .and_then(|(j, niche)| Some((j, niche, niche.reserve(dl, count)?)))\n+        {\n+            None => return Ok(None),\n+            Some(x) => x,\n+        };\n+\n+        let niche_offset =\n+            niche.offset + variant_layouts[largest_variant_index].fields.offset(field_index, dl);\n+        let niche_size = niche.value.size(dl);\n+        let size = variant_layouts[largest_variant_index].size.align_to(align.abi);\n+\n+        let all_variants_fit = variant_layouts.iter_mut().all(|(i, layout)| {\n+            if i == largest_variant_index {\n+                return true;\n+            }\n+\n+            layout.largest_niche = None;\n+\n+            if layout.size <= niche_offset {\n+                // This variant will fit before the niche.\n+                return true;\n+            }\n+\n+            // Determine if it'll fit after the niche.\n+            let this_align = layout.align.abi;\n+            let this_offset = (niche_offset + niche_size).align_to(this_align);\n+\n+            if this_offset + layout.size > size {\n+                return false;\n+            }\n+\n+            // It'll fit, but we need to make some adjustments.\n+            match layout.fields {\n+                FieldsShape::Arbitrary { ref mut offsets, .. } => {\n+                    for (j, offset) in offsets.iter_mut().enumerate() {\n+                        if !variants[i][j].is_zst() {\n+                            *offset += this_offset;\n+                        }\n+                    }\n+                }\n+                _ => {\n+                    panic!(\"Layout of fields should be Arbitrary for variants\")\n+                }\n+            }\n+\n+            // It can't be a Scalar or ScalarPair because the offset isn't 0.\n+            if !layout.abi.is_uninhabited() {\n+                layout.abi = Abi::Aggregate { sized: true };\n+            }\n+            layout.size += this_offset;\n+\n+            true\n+        });\n+\n+        if !all_variants_fit {\n+            return Ok(None);\n+        }\n+\n+        let largest_niche = Niche::from_scalar(dl, niche_offset, niche_scalar);\n+\n+        let others_zst = variant_layouts\n+            .iter()\n+            .all(|(i, layout)| i == largest_variant_index || layout.size == Size::ZERO);\n+        let same_size = size == variant_layouts[largest_variant_index].size;\n+        let same_align = align == variant_layouts[largest_variant_index].align;\n+\n+        let abi = if variant_layouts.iter().all(|(_, v)| v.abi.is_uninhabited()) {\n+            Abi::Uninhabited\n+        } else if same_size && same_align && others_zst {\n+            match variant_layouts[largest_variant_index].abi {\n+                // When the total alignment and size match, we can use the\n+                // same ABI as the scalar variant with the reserved niche.\n+                Abi::Scalar(_) => Abi::Scalar(niche_scalar),\n+                Abi::ScalarPair(first, second) => {\n+                    // Only the niche is guaranteed to be initialised,\n+                    // so use union layouts for the other primitive.\n+                    if niche_offset == Size::ZERO {\n+                        Abi::ScalarPair(niche_scalar, second.to_union())\n+                    } else {\n+                        Abi::ScalarPair(first.to_union(), niche_scalar)\n+                    }\n+                }\n+                _ => Abi::Aggregate { sized: true },\n+            }\n+        } else {\n+            Abi::Aggregate { sized: true }\n+        };\n+\n+        let layout = Layout {\n+            variants: Variants::Multiple {\n+                tag: niche_scalar,\n+                tag_encoding: TagEncoding::Niche {\n+                    untagged_variant: largest_variant_index,\n+                    niche_start,\n+                },\n+                tag_field: 0,\n+                variants: ArenaMap::new(),\n+            },\n+            fields: FieldsShape::Arbitrary { offsets: vec![niche_offset], memory_index: vec![0] },\n+            abi,\n+            largest_niche,\n+            size,\n+            align,\n+        };\n+\n+        Ok(Some(TmpLayout { layout, variants: variant_layouts }))\n+    };\n+\n+    let niche_filling_layout = calculate_niche_filling_layout()?;\n+\n+    let (mut min, mut max) = (i128::MAX, i128::MIN);\n+    // FIXME: bring these back\n+    // let discr_type = repr.discr_type();\n+    // let bits = Integer::from_attr(dl, discr_type).size().bits();\n+    // for (i, discr) in def.discriminants(tcx) {\n+    //     if variants[i].iter().any(|f| f.abi.is_uninhabited()) {\n+    //         continue;\n+    //     }\n+    //     let mut x = discr.val as i128;\n+    //     if discr_type.is_signed() {\n+    //         // sign extend the raw representation to be an i128\n+    //         x = (x << (128 - bits)) >> (128 - bits);\n+    //     }\n+    //     if x < min {\n+    //         min = x;\n+    //     }\n+    //     if x > max {\n+    //         max = x;\n+    //     }\n+    // }\n+    // We might have no inhabited variants, so pretend there's at least one.\n+    if (min, max) == (i128::MAX, i128::MIN) {\n+        min = 0;\n+        max = 0;\n+    }\n+    assert!(min <= max, \"discriminant range is {}...{}\", min, max);\n+    let (min_ity, signed) = Integer::repr_discr(dl, &repr, min, max)?;\n+\n+    let mut align = dl.aggregate_align;\n+    let mut size = Size::ZERO;\n+\n+    // We're interested in the smallest alignment, so start large.\n+    let mut start_align = Align::from_bytes(256).unwrap();\n+    assert_eq!(Integer::for_align(dl, start_align), None);\n+\n+    // repr(C) on an enum tells us to make a (tag, union) layout,\n+    // so we need to grow the prefix alignment to be at least\n+    // the alignment of the union. (This value is used both for\n+    // determining the alignment of the overall enum, and the\n+    // determining the alignment of the payload after the tag.)\n+    let mut prefix_align = min_ity.align(dl).abi;\n+    if repr.c() {\n+        for (_, fields) in variants.iter() {\n+            for field in fields {\n+                prefix_align = prefix_align.max(field.align.abi);\n+            }\n+        }\n+    }\n+\n+    // Create the set of structs that represent each variant.\n+    let mut layout_variants = variants\n+        .iter()\n+        .map(|(i, field_layouts)| {\n+            let mut st = univariant(\n+                dl,\n+                &field_layouts,\n+                &repr,\n+                StructKind::Prefixed(min_ity.size(), prefix_align),\n+            )?;\n+            st.variants = Variants::Single;\n+            // Find the first field we can't move later\n+            // to make room for a larger discriminant.\n+            for field in st.fields.index_by_increasing_offset().map(|j| &field_layouts[j]) {\n+                if !field.is_zst() || field.align.abi.bytes() != 1 {\n+                    start_align = start_align.min(field.align.abi);\n+                    break;\n+                }\n+            }\n+            size = cmp::max(size, st.size);\n+            align = align.max(st.align);\n+            Ok((i, st))\n+        })\n+        .collect::<Result<ArenaMap<_, _>, _>>()?;\n+\n+    // Align the maximum variant size to the largest alignment.\n+    size = size.align_to(align.abi);\n+\n+    if size.bytes() >= dl.obj_size_bound() {\n+        return Err(LayoutError::SizeOverflow);\n+    }\n+\n+    // Check to see if we should use a different type for the\n+    // discriminant. We can safely use a type with the same size\n+    // as the alignment of the first field of each variant.\n+    // We increase the size of the discriminant to avoid LLVM copying\n+    // padding when it doesn't need to. This normally causes unaligned\n+    // load/stores and excessive memcpy/memset operations. By using a\n+    // bigger integer size, LLVM can be sure about its contents and\n+    // won't be so conservative.\n+\n+    // Use the initial field alignment\n+    let mut ity = if repr.c() || repr.int.is_some() {\n+        min_ity\n+    } else {\n+        Integer::for_align(dl, start_align).unwrap_or(min_ity)\n+    };\n+\n+    // If the alignment is not larger than the chosen discriminant size,\n+    // don't use the alignment as the final size.\n+    if ity <= min_ity {\n+        ity = min_ity;\n+    } else {\n+        // Patch up the variants' first few fields.\n+        // Patch up the variants' first few fields.\n+        let old_ity_size = min_ity.size();\n+        let new_ity_size = ity.size();\n+        for (_, variant) in layout_variants.iter_mut() {\n+            match variant.fields {\n+                FieldsShape::Arbitrary { ref mut offsets, .. } => {\n+                    for i in offsets {\n+                        if *i <= old_ity_size {\n+                            assert_eq!(*i, old_ity_size);\n+                            *i = new_ity_size;\n+                        }\n+                    }\n+                    // We might be making the struct larger.\n+                    if variant.size <= old_ity_size {\n+                        variant.size = new_ity_size;\n+                    }\n+                }\n+                _ => user_error!(\"bug\"),\n+            }\n+        }\n+    }\n+\n+    let tag_mask = ity.size().unsigned_int_max();\n+    let tag = Scalar::Initialized {\n+        value: Primitive::Int(ity, signed),\n+        valid_range: WrappingRange {\n+            start: (min as u128 & tag_mask),\n+            end: (max as u128 & tag_mask),\n+        },\n+    };\n+    let mut abi = Abi::Aggregate { sized: true };\n+\n+    if layout_variants.iter().all(|(_, v)| v.abi.is_uninhabited()) {\n+        abi = Abi::Uninhabited;\n+    } else if tag.size(dl) == size {\n+        // Make sure we only use scalar layout when the enum is entirely its\n+        // own tag (i.e. it has no padding nor any non-ZST variant fields).\n+        abi = Abi::Scalar(tag);\n+    } else {\n+        // Try to use a ScalarPair for all tagged enums.\n+        let mut common_prim = None;\n+        let mut common_prim_initialized_in_all_variants = true;\n+        for ((_, field_layouts), (_, layout_variant)) in\n+            iter::zip(variants.iter(), layout_variants.iter())\n+        {\n+            let offsets = match layout_variant.fields {\n+                FieldsShape::Arbitrary { ref offsets, .. } => offsets,\n+                _ => user_error!(\"bug\"),\n+            };\n+            let mut fields = iter::zip(field_layouts, offsets).filter(|p| !p.0.is_zst());\n+            let (field, offset) = match (fields.next(), fields.next()) {\n+                (None, None) => {\n+                    common_prim_initialized_in_all_variants = false;\n+                    continue;\n+                }\n+                (Some(pair), None) => pair,\n+                _ => {\n+                    common_prim = None;\n+                    break;\n+                }\n+            };\n+            let prim = match field.abi {\n+                Abi::Scalar(scalar) => {\n+                    common_prim_initialized_in_all_variants &=\n+                        matches!(scalar, Scalar::Initialized { .. });\n+                    scalar.primitive()\n+                }\n+                _ => {\n+                    common_prim = None;\n+                    break;\n+                }\n+            };\n+            if let Some(pair) = common_prim {\n+                // This is pretty conservative. We could go fancier\n+                // by conflating things like i32 and u32, or even\n+                // realising that (u8, u8) could just cohabit with\n+                // u16 or even u32.\n+                if pair != (prim, offset) {\n+                    common_prim = None;\n+                    break;\n+                }\n+            } else {\n+                common_prim = Some((prim, offset));\n+            }\n+        }\n+        if let Some((prim, offset)) = common_prim {\n+            let prim_scalar = if common_prim_initialized_in_all_variants {\n+                scalar_unit(dl, prim)\n+            } else {\n+                // Common prim might be uninit.\n+                Scalar::Union { value: prim }\n+            };\n+            let pair = scalar_pair(dl, tag, prim_scalar);\n+            let pair_offsets = match pair.fields {\n+                FieldsShape::Arbitrary { ref offsets, ref memory_index } => {\n+                    assert_eq!(memory_index, &[0, 1]);\n+                    offsets\n+                }\n+                _ => user_error!(\"bug\"),\n+            };\n+            if pair_offsets[0] == Size::ZERO\n+                && pair_offsets[1] == *offset\n+                && align == pair.align\n+                && size == pair.size\n+            {\n+                // We can use `ScalarPair` only when it matches our\n+                // already computed layout (including `#[repr(C)]`).\n+                abi = pair.abi;\n+            }\n+        }\n+    }\n+\n+    // If we pick a \"clever\" (by-value) ABI, we might have to adjust the ABI of the\n+    // variants to ensure they are consistent. This is because a downcast is\n+    // semantically a NOP, and thus should not affect layout.\n+    if matches!(abi, Abi::Scalar(..) | Abi::ScalarPair(..)) {\n+        for (_, variant) in layout_variants.iter_mut() {\n+            // We only do this for variants with fields; the others are not accessed anyway.\n+            // Also do not overwrite any already existing \"clever\" ABIs.\n+            if variant.fields.count() > 0 && matches!(variant.abi, Abi::Aggregate { .. }) {\n+                variant.abi = abi;\n+                // Also need to bump up the size and alignment, so that the entire value fits in here.\n+                variant.size = cmp::max(variant.size, size);\n+                variant.align.abi = cmp::max(variant.align.abi, align.abi);\n+            }\n+        }\n+    }\n+\n+    let largest_niche = Niche::from_scalar(dl, Size::ZERO, tag);\n+\n+    let tagged_layout = Layout {\n+        variants: Variants::Multiple {\n+            tag,\n+            tag_encoding: TagEncoding::Direct,\n+            tag_field: 0,\n+            variants: ArenaMap::new(),\n+        },\n+        fields: FieldsShape::Arbitrary { offsets: vec![Size::ZERO], memory_index: vec![0] },\n+        largest_niche,\n+        abi,\n+        align,\n+        size,\n+    };\n+\n+    let tagged_layout = TmpLayout { layout: tagged_layout, variants: layout_variants };\n+\n+    let mut best_layout = match (tagged_layout, niche_filling_layout) {\n+        (tl, Some(nl)) => {\n+            // Pick the smaller layout; otherwise,\n+            // pick the layout with the larger niche; otherwise,\n+            // pick tagged as it has simpler codegen.\n+            use Ordering::*;\n+            let niche_size =\n+                |tmp_l: &TmpLayout| tmp_l.layout.largest_niche.map_or(0, |n| n.available(dl));\n+            match (tl.layout.size.cmp(&nl.layout.size), niche_size(&tl).cmp(&niche_size(&nl))) {\n+                (Greater, _) => nl,\n+                (Equal, Less) => nl,\n+                _ => tl,\n+            }\n+        }\n+        (tl, None) => tl,\n+    };\n+\n+    // Now we can intern the variant layouts and store them in the enum layout.\n+    best_layout.layout.variants = match best_layout.layout.variants {\n+        Variants::Multiple { tag, tag_encoding, tag_field, .. } => {\n+            Variants::Multiple { tag, tag_encoding, tag_field, variants: best_layout.variants }\n+        }\n+        _ => user_error!(\"bug\"),\n+    };\n+\n+    Ok(best_layout.layout)\n+}\n+\n+pub fn layout_of_adt_recover(\n+    _: &dyn HirDatabase,\n+    _: &[String],\n+    _: &AdtId,\n+    _: &Substitution,\n+) -> Result<Layout, LayoutError> {\n+    user_error!(\"infinite sized recursive type\");\n+}\n+\n+pub(crate) fn univariant(\n+    dl: &TargetDataLayout,\n+    fields: &[Layout],\n+    repr: &ReprOptions,\n+    kind: StructKind,\n+) -> Result<Layout, LayoutError> {\n+    let pack = repr.pack;\n+    if pack.is_some() && repr.align.is_some() {\n+        user_error!(\"Struct can not be packed and aligned\");\n+    }\n+\n+    let mut align = if pack.is_some() { dl.i8_align } else { dl.aggregate_align };\n+\n+    let mut inverse_memory_index: Vec<u32> = (0..fields.len() as u32).collect();\n+\n+    let optimize = !repr.inhibit_struct_field_reordering_opt();\n+    if optimize {\n+        let end = if let StructKind::MaybeUnsized = kind { fields.len() - 1 } else { fields.len() };\n+        let optimizing = &mut inverse_memory_index[..end];\n+        let field_align = |f: &Layout| {\n+            if let Some(pack) = pack {\n+                f.align.abi.min(pack)\n+            } else {\n+                f.align.abi\n+            }\n+        };\n+\n+        match kind {\n+            StructKind::AlwaysSized | StructKind::MaybeUnsized => {\n+                optimizing.sort_by_key(|&x| {\n+                    // Place ZSTs first to avoid \"interesting offsets\",\n+                    // especially with only one or two non-ZST fields.\n+                    let f = &fields[x as usize];\n+                    (!f.is_zst(), cmp::Reverse(field_align(f)))\n+                });\n+            }\n+\n+            StructKind::Prefixed(..) => {\n+                // Sort in ascending alignment so that the layout stays optimal\n+                // regardless of the prefix\n+                optimizing.sort_by_key(|&x| field_align(&fields[x as usize]));\n+            }\n+        }\n+    }\n+\n+    // inverse_memory_index holds field indices by increasing memory offset.\n+    // That is, if field 5 has offset 0, the first element of inverse_memory_index is 5.\n+    // We now write field offsets to the corresponding offset slot;\n+    // field 5 with offset 0 puts 0 in offsets[5].\n+    // At the bottom of this function, we invert `inverse_memory_index` to\n+    // produce `memory_index` (see `invert_mapping`).\n+\n+    let mut sized = true;\n+    let mut offsets = vec![Size::ZERO; fields.len()];\n+    let mut offset = Size::ZERO;\n+    let mut largest_niche = None;\n+    let mut largest_niche_available = 0;\n+\n+    if let StructKind::Prefixed(prefix_size, prefix_align) = kind {\n+        let prefix_align =\n+            if let Some(pack) = pack { prefix_align.min(pack) } else { prefix_align };\n+        align = align.max(AbiAndPrefAlign::new(prefix_align));\n+        offset = prefix_size.align_to(prefix_align);\n+    }\n+\n+    for &i in &inverse_memory_index {\n+        let field = &fields[i as usize];\n+        if !sized {\n+            user_error!(\"Unsized field is not last field\");\n+        }\n+\n+        if field.is_unsized() {\n+            sized = false;\n+        }\n+\n+        // Invariant: offset < dl.obj_size_bound() <= 1<<61\n+        let field_align = if let Some(pack) = pack {\n+            field.align.min(AbiAndPrefAlign::new(pack))\n+        } else {\n+            field.align\n+        };\n+        offset = offset.align_to(field_align.abi);\n+        align = align.max(field_align);\n+\n+        offsets[i as usize] = offset;\n+\n+        if let Some(mut niche) = field.largest_niche {\n+            let available = niche.available(dl);\n+            if available > largest_niche_available {\n+                largest_niche_available = available;\n+                niche.offset =\n+                    niche.offset.checked_add(offset, dl).ok_or(LayoutError::SizeOverflow)?;\n+                largest_niche = Some(niche);\n+            }\n+        }\n+\n+        offset = offset.checked_add(field.size, dl).ok_or(LayoutError::SizeOverflow)?;\n+    }\n+\n+    if let Some(repr_align) = repr.align {\n+        align = align.max(AbiAndPrefAlign::new(repr_align));\n+    }\n+\n+    let min_size = offset;\n+\n+    // As stated above, inverse_memory_index holds field indices by increasing offset.\n+    // This makes it an already-sorted view of the offsets vec.\n+    // To invert it, consider:\n+    // If field 5 has offset 0, offsets[0] is 5, and memory_index[5] should be 0.\n+    // Field 5 would be the first element, so memory_index is i:\n+    // Note: if we didn't optimize, it's already right.\n+\n+    let memory_index =\n+        if optimize { invert_mapping(&inverse_memory_index) } else { inverse_memory_index };\n+\n+    let size = min_size.align_to(align.abi);\n+    let mut abi = Abi::Aggregate { sized };\n+\n+    // Unpack newtype ABIs and find scalar pairs.\n+    if sized && size.bytes() > 0 {\n+        // All other fields must be ZSTs.\n+        let mut non_zst_fields = fields.iter().enumerate().filter(|&(_, f)| !f.is_zst());\n+\n+        match (non_zst_fields.next(), non_zst_fields.next(), non_zst_fields.next()) {\n+            // We have exactly one non-ZST field.\n+            (Some((i, field)), None, None) => {\n+                // Field fills the struct and it has a scalar or scalar pair ABI.\n+                if offsets[i].bytes() == 0 && align.abi == field.align.abi && size == field.size {\n+                    match field.abi {\n+                        // For plain scalars, or vectors of them, we can't unpack\n+                        // newtypes for `#[repr(C)]`, as that affects C ABIs.\n+                        Abi::Scalar(_) | Abi::Vector { .. } if optimize => {\n+                            abi = field.abi;\n+                        }\n+                        // But scalar pairs are Rust-specific and get\n+                        // treated as aggregates by C ABIs anyway.\n+                        Abi::ScalarPair(..) => {\n+                            abi = field.abi;\n+                        }\n+                        _ => {}\n+                    }\n+                }\n+            }\n+\n+            // Two non-ZST fields, and they're both scalars.\n+            (Some((i, a)), Some((j, b)), None) => {\n+                match (a.abi, b.abi) {\n+                    (Abi::Scalar(a), Abi::Scalar(b)) => {\n+                        // Order by the memory placement, not source order.\n+                        let ((i, a), (j, b)) = if offsets[i] < offsets[j] {\n+                            ((i, a), (j, b))\n+                        } else {\n+                            ((j, b), (i, a))\n+                        };\n+                        let pair = scalar_pair(dl, a, b);\n+                        let pair_offsets = match pair.fields {\n+                            FieldsShape::Arbitrary { ref offsets, .. } => offsets,\n+                            _ => unreachable!(),\n+                        };\n+                        if offsets[i] == pair_offsets[0]\n+                            && offsets[j] == pair_offsets[1]\n+                            && align == pair.align\n+                            && size == pair.size\n+                        {\n+                            // We can use `ScalarPair` only when it matches our\n+                            // already computed layout (including `#[repr(C)]`).\n+                            abi = pair.abi;\n+                        }\n+                    }\n+                    _ => {}\n+                }\n+            }\n+\n+            _ => {}\n+        }\n+    }\n+\n+    if fields.iter().any(|f| f.abi.is_uninhabited()) {\n+        abi = Abi::Uninhabited;\n+    }\n+\n+    Ok(Layout {\n+        variants: Variants::Single,\n+        fields: FieldsShape::Arbitrary { offsets, memory_index },\n+        abi,\n+        largest_niche,\n+        align,\n+        size,\n+    })\n+}\n+\n+fn layout_of_union(\n+    db: &dyn HirDatabase,\n+    id: UnionId,\n+    subst: &Substitution,\n+) -> Result<Layout, LayoutError> {\n+    let dl = &*db.current_target_data_layout();\n+\n+    let union_data = db.union_data(id);\n+\n+    let repr = union_data.repr.unwrap_or_default();\n+    let fields = union_data.variant_data.fields();\n+\n+    if repr.pack.is_some() && repr.align.is_some() {\n+        user_error!(\"union cannot be packed and aligned\");\n+    }\n+\n+    let mut align = if repr.pack.is_some() { dl.i8_align } else { dl.aggregate_align };\n+    if let Some(repr_align) = repr.align {\n+        align = align.max(AbiAndPrefAlign::new(repr_align));\n+    }\n+\n+    let optimize = !repr.inhibit_union_abi_opt();\n+    let mut size = Size::ZERO;\n+    let mut abi = Abi::Aggregate { sized: true };\n+    for (fd, _) in fields.iter() {\n+        let field_ty = field_ty(db, id.into(), fd, subst);\n+        let field = layout_of_ty(db, &field_ty)?;\n+        if field.is_unsized() {\n+            user_error!(\"unsized union field\");\n+        }\n+        // If all non-ZST fields have the same ABI, forward this ABI\n+        if optimize && !field.is_zst() {\n+            // Discard valid range information and allow undef\n+            let field_abi = match field.abi {\n+                Abi::Scalar(x) => Abi::Scalar(x.to_union()),\n+                Abi::ScalarPair(x, y) => Abi::ScalarPair(x.to_union(), y.to_union()),\n+                Abi::Vector { element: x, count } => Abi::Vector { element: x.to_union(), count },\n+                Abi::Uninhabited | Abi::Aggregate { .. } => Abi::Aggregate { sized: true },\n+            };\n+\n+            if size == Size::ZERO {\n+                // first non ZST: initialize 'abi'\n+                abi = field_abi;\n+            } else if abi != field_abi {\n+                // different fields have different ABI: reset to Aggregate\n+                abi = Abi::Aggregate { sized: true };\n+            }\n+        }\n+\n+        size = cmp::max(size, field.size);\n+    }\n+\n+    if let Some(pack) = repr.pack {\n+        align = align.min(AbiAndPrefAlign::new(pack));\n+    }\n+\n+    Ok(Layout {\n+        variants: Variants::Single,\n+        fields: FieldsShape::Union(\n+            NonZeroUsize::new(fields.len())\n+                .ok_or(LayoutError::UserError(\"union with zero fields\".to_string()))?,\n+        ),\n+        abi,\n+        largest_niche: None,\n+        align,\n+        size: size.align_to(align.abi),\n+    })\n+}\n+\n+// Invert a bijective mapping, i.e. `invert(map)[y] = x` if `map[x] = y`.\n+// This is used to go between `memory_index` (source field order to memory order)\n+// and `inverse_memory_index` (memory order to source field order).\n+// See also `FieldsShape::Arbitrary::memory_index` for more details.\n+// FIXME(eddyb) build a better abstraction for permutations, if possible.\n+fn invert_mapping(map: &[u32]) -> Vec<u32> {\n+    let mut inverse = vec![0; map.len()];\n+    for i in 0..map.len() {\n+        inverse[map[i] as usize] = i as u32;\n+    }\n+    inverse\n+}\n+\n+fn scalar_pair(dl: &TargetDataLayout, a: Scalar, b: Scalar) -> Layout {\n+    let b_align = b.align(dl);\n+    let align = a.align(dl).max(b_align).max(dl.aggregate_align);\n+    let b_offset = a.size(dl).align_to(b_align.abi);\n+    let size = b_offset.checked_add(b.size(dl), dl).unwrap().align_to(align.abi);\n+\n+    // HACK(nox): We iter on `b` and then `a` because `max_by_key`\n+    // returns the last maximum.\n+    let largest_niche = Niche::from_scalar(dl, b_offset, b)\n+        .into_iter()\n+        .chain(Niche::from_scalar(dl, Size::ZERO, a))\n+        .max_by_key(|niche| niche.available(dl));\n+\n+    Layout {\n+        variants: Variants::Single,\n+        fields: FieldsShape::Arbitrary {\n+            offsets: vec![Size::ZERO, b_offset],\n+            memory_index: vec![0, 1],\n+        },\n+        abi: Abi::ScalarPair(a, b),\n+        largest_niche,\n+        align,\n+        size,\n+    }\n+}"}, {"sha": "ba810b12b1fb8e03a1deae082c0cc527fd2b03fd", "filename": "crates/hir-ty/src/layout/target.rs", "status": "added", "additions": 44, "deletions": 0, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftarget.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftarget.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftarget.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -0,0 +1,44 @@\n+//! Target dependent parameters needed for layouts\n+\n+use std::sync::Arc;\n+\n+use hir_def::layout::TargetDataLayout;\n+\n+use crate::db::HirDatabase;\n+\n+use super::{AbiAndPrefAlign, AddressSpace, Align, Endian, Integer, Size};\n+\n+pub fn current_target_data_layout_query(db: &dyn HirDatabase) -> Arc<TargetDataLayout> {\n+    let crate_graph = db.crate_graph();\n+    let cfg_options = &crate_graph[crate_graph.iter().next().unwrap()].cfg_options;\n+    let endian = match cfg_options.get_cfg_values(\"target_endian\").next() {\n+        Some(x) if x.as_str() == \"big\" => Endian::Big,\n+        _ => Endian::Little,\n+    };\n+    let pointer_size =\n+        Size::from_bytes(match cfg_options.get_cfg_values(\"target_pointer_width\").next() {\n+            Some(x) => match x.as_str() {\n+                \"16\" => 2,\n+                \"32\" => 4,\n+                _ => 8,\n+            },\n+            _ => 8,\n+        });\n+    Arc::new(TargetDataLayout {\n+        endian,\n+        i1_align: AbiAndPrefAlign::new(Align::from_bytes(1).unwrap()),\n+        i8_align: AbiAndPrefAlign::new(Align::from_bytes(1).unwrap()),\n+        i16_align: AbiAndPrefAlign::new(Align::from_bytes(2).unwrap()),\n+        i32_align: AbiAndPrefAlign::new(Align::from_bytes(4).unwrap()),\n+        i64_align: AbiAndPrefAlign::new(Align::from_bytes(8).unwrap()),\n+        i128_align: AbiAndPrefAlign::new(Align::from_bytes(8).unwrap()),\n+        f32_align: AbiAndPrefAlign::new(Align::from_bytes(4).unwrap()),\n+        f64_align: AbiAndPrefAlign::new(Align::from_bytes(8).unwrap()),\n+        pointer_size,\n+        pointer_align: AbiAndPrefAlign::new(Align::from_bytes(8).unwrap()),\n+        aggregate_align: AbiAndPrefAlign::new(Align::from_bytes(1).unwrap()),\n+        vector_align: vec![],\n+        instruction_address_space: AddressSpace(0),\n+        c_enum_min_size: Integer::I32,\n+    })\n+}"}, {"sha": "9543b4dcbc6b641d152cbaef7e1f63e3a6d4c90c", "filename": "crates/hir-ty/src/layout/tests.rs", "status": "added", "additions": 167, "deletions": 0, "changes": 167, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftests.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -0,0 +1,167 @@\n+use base_db::fixture::WithFixture;\n+use chalk_ir::{AdtId, TyKind};\n+use hir_def::{\n+    db::DefDatabase,\n+    layout::{Layout, LayoutError},\n+};\n+\n+use crate::{test_db::TestDB, Interner, Substitution};\n+\n+use super::layout_of_ty;\n+\n+fn eval_goal(ra_fixture: &str) -> Result<Layout, LayoutError> {\n+    let (db, file_id) = TestDB::with_single_file(ra_fixture);\n+    let module_id = db.module_for_file(file_id);\n+    let def_map = module_id.def_map(&db);\n+    let scope = &def_map[module_id.local_id].scope;\n+    let adt_id = scope\n+        .declarations()\n+        .into_iter()\n+        .find_map(|x| match x {\n+            hir_def::ModuleDefId::AdtId(x) => {\n+                let name = match x {\n+                    hir_def::AdtId::StructId(x) => db.struct_data(x).name.to_string(),\n+                    hir_def::AdtId::UnionId(x) => db.union_data(x).name.to_string(),\n+                    hir_def::AdtId::EnumId(x) => db.enum_data(x).name.to_string(),\n+                };\n+                if name == \"Goal\" {\n+                    Some(x)\n+                } else {\n+                    None\n+                }\n+            }\n+            _ => None,\n+        })\n+        .unwrap();\n+    let goal_ty = TyKind::Adt(AdtId(adt_id), Substitution::empty(Interner)).intern(Interner);\n+    layout_of_ty(&db, &goal_ty)\n+}\n+\n+fn check_size_and_align(ra_fixture: &str, size: u64, align: u64) {\n+    let l = eval_goal(ra_fixture).unwrap();\n+    assert_eq!(l.size.bytes(), size);\n+    assert_eq!(l.align.abi.bytes(), align);\n+}\n+\n+fn check_fail(ra_fixture: &str, e: LayoutError) {\n+    let r = eval_goal(ra_fixture);\n+    assert_eq!(r, Err(e));\n+}\n+\n+macro_rules! size_and_align {\n+    ($($t:tt)*) => {\n+        {\n+            #[allow(dead_code)]\n+            $($t)*\n+            check_size_and_align(\n+                stringify!($($t)*),\n+                ::std::mem::size_of::<Goal>() as u64,\n+                ::std::mem::align_of::<Goal>() as u64,\n+            );\n+        }\n+    };\n+}\n+\n+#[test]\n+fn hello_world() {\n+    size_and_align! {\n+        struct Goal(i32);\n+    }\n+    //check_size_and_align(r#\"struct Goal(i32)\"#, 4, 4);\n+}\n+\n+#[test]\n+fn field_order_optimization() {\n+    size_and_align! {\n+        struct Goal(u8, i32, u8);\n+    }\n+    size_and_align! {\n+        #[repr(C)]\n+        struct Goal(u8, i32, u8);\n+    }\n+}\n+\n+#[test]\n+fn recursive() {\n+    size_and_align! {\n+        struct Goal {\n+            left: &'static Goal,\n+            right: &'static Goal,\n+        }\n+    }\n+    size_and_align! {\n+        struct BoxLike<T: ?Sized>(*mut T);\n+        struct Goal(BoxLike<Goal>);\n+    }\n+    check_fail(\n+        r#\"struct Goal(Goal);\"#,\n+        LayoutError::UserError(\"infinite sized recursive type\".to_string()),\n+    );\n+    check_fail(\n+        r#\"\n+        struct Foo<T>(Foo<T>);\n+        struct Goal(Foo<i32>);\n+        \"#,\n+        LayoutError::UserError(\"infinite sized recursive type\".to_string()),\n+    );\n+}\n+\n+#[test]\n+fn generic() {\n+    size_and_align! {\n+        struct Pair<A, B>(A, B);\n+        struct Goal(Pair<Pair<i32, u8>, i64>);\n+    }\n+    size_and_align! {\n+        struct X<const N: usize> {\n+            field1: [i32; N],\n+            field2: [u8; N],\n+        }\n+        struct Goal(X<1000>);\n+    }\n+}\n+\n+#[test]\n+fn enums() {\n+    size_and_align! {\n+        enum Goal {\n+            Quit,\n+            Move { x: i32, y: i32 },\n+            ChangeColor(i32, i32, i32),\n+        }\n+    }\n+}\n+\n+#[test]\n+fn primitives() {\n+    size_and_align! {\n+        struct Goal(i32, i128, isize, usize, f32, f64, bool, char);\n+    }\n+}\n+\n+#[test]\n+fn tuple() {\n+    size_and_align! {\n+        struct Goal((), (i32, u64, bool));\n+    }\n+}\n+\n+#[test]\n+fn niche_optimization() {\n+    check_size_and_align(\n+        r#\"\n+    //- minicore: option\n+    struct Goal(Option<&i32>);\n+    \"#,\n+        8,\n+        8,\n+    );\n+    check_size_and_align(\n+        r#\"\n+    //- minicore: option\n+    struct Goal(Option<Option<bool>>);\n+    \"#,\n+        1,\n+        1,\n+    );\n+}"}, {"sha": "2a41cafba98a5471c7ee4cc6903f3b0a05864bab", "filename": "crates/hir-ty/src/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir-ty%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flib.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -27,6 +27,8 @@ pub mod display;\n pub mod method_resolution;\n pub mod primitive;\n pub mod traits;\n+pub mod layout;\n+pub mod lang_items;\n \n #[cfg(test)]\n mod tests;"}, {"sha": "42b7c0781bf4a6a5639b13393f99f909159cd76b", "filename": "crates/hir/src/lib.rs", "status": "modified", "additions": 20, "deletions": 3, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fhir%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Flib.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -39,12 +39,13 @@ use arrayvec::ArrayVec;\n use base_db::{CrateDisplayName, CrateId, CrateOrigin, Edition, FileId, ProcMacroKind};\n use either::Either;\n use hir_def::{\n-    adt::{ReprData, VariantData},\n+    adt::VariantData,\n     body::{BodyDiagnostic, SyntheticSyntax},\n     expr::{BindingAnnotation, LabelId, Pat, PatId},\n     generics::{TypeOrConstParamData, TypeParamProvenance},\n     item_tree::ItemTreeNode,\n     lang_item::LangItemTarget,\n+    layout::{Layout, LayoutError, ReprOptions},\n     nameres::{self, diagnostics::DefDiagnostic},\n     per_ns::PerNs,\n     resolver::{HasResolver, Resolver},\n@@ -59,6 +60,7 @@ use hir_ty::{\n     all_super_traits, autoderef,\n     consteval::{unknown_const_as_generic, ComputedExpr, ConstEvalError, ConstExt},\n     diagnostics::BodyValidationDiagnostic,\n+    layout::layout_of_ty,\n     method_resolution::{self, TyFingerprint},\n     primitive::UintTy,\n     traits::FnTrait,\n@@ -844,6 +846,10 @@ impl Field {\n         self.parent.variant_data(db).fields()[self.id].name.clone()\n     }\n \n+    pub fn index(&self) -> usize {\n+        u32::from(self.id.into_raw()) as usize\n+    }\n+\n     /// Returns the type as in the signature of the struct (i.e., with\n     /// placeholder types for type parameters). Only use this in the context of\n     /// the field definition.\n@@ -859,6 +865,10 @@ impl Field {\n         Type::new(db, var_id, ty)\n     }\n \n+    pub fn layout(&self, db: &dyn HirDatabase) -> Result<Layout, LayoutError> {\n+        layout_of_ty(db, &self.ty(db).ty)\n+    }\n+\n     pub fn parent_def(&self, _db: &dyn HirDatabase) -> VariantDef {\n         self.parent\n     }\n@@ -900,7 +910,7 @@ impl Struct {\n         Type::from_def(db, self.id)\n     }\n \n-    pub fn repr(self, db: &dyn HirDatabase) -> Option<ReprData> {\n+    pub fn repr(self, db: &dyn HirDatabase) -> Option<ReprOptions> {\n         db.struct_data(self.id).repr.clone()\n     }\n \n@@ -1076,6 +1086,13 @@ impl Adt {\n         })\n     }\n \n+    pub fn layout(self, db: &dyn HirDatabase) -> Result<Layout, LayoutError> {\n+        if db.generic_params(self.into()).iter().count() != 0 {\n+            return Err(LayoutError::HasPlaceholder);\n+        }\n+        db.layout_of_adt(self.into(), Substitution::empty(Interner))\n+    }\n+\n     /// Turns this ADT into a type. Any type parameters of the ADT will be\n     /// turned into unknown types, which is good for e.g. finding the most\n     /// general set of completions, but will not look very nice when printed.\n@@ -3031,7 +3048,7 @@ impl Type {\n \n         let adt = adt_id.into();\n         match adt {\n-            Adt::Struct(s) => matches!(s.repr(db), Some(ReprData { packed: true, .. })),\n+            Adt::Struct(s) => s.repr(db).unwrap_or_default().pack.is_some(),\n             _ => false,\n         }\n     }"}, {"sha": "470c6626f9d90853b67815efd1ec99a2d64a4dcd", "filename": "crates/ide/src/hover/render.rs", "status": "modified", "additions": 45, "deletions": 3, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fide%2Fsrc%2Fhover%2Frender.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fide%2Fsrc%2Fhover%2Frender.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fhover%2Frender.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -2,7 +2,10 @@\n use std::fmt::Display;\n \n use either::Either;\n-use hir::{AsAssocItem, AttributeTemplate, HasAttrs, HasSource, HirDisplay, Semantics, TypeInfo};\n+use hir::{\n+    db::HirDatabase, Adt, AsAssocItem, AttributeTemplate, HasAttrs, HasSource, HirDisplay,\n+    Semantics, TypeInfo,\n+};\n use ide_db::{\n     base_db::SourceDatabase,\n     defs::Definition,\n@@ -388,10 +391,30 @@ pub(super) fn definition(\n     let mod_path = definition_mod_path(db, &def);\n     let (label, docs) = match def {\n         Definition::Macro(it) => label_and_docs(db, it),\n-        Definition::Field(it) => label_and_docs(db, it),\n+        Definition::Field(it) => label_and_layout_info_and_docs(db, it, |&it| {\n+            let var_def = it.parent_def(db);\n+            let id = it.index();\n+            let layout = it.layout(db).ok()?;\n+            let offset = match var_def {\n+                hir::VariantDef::Struct(s) => {\n+                    let layout = Adt::from(s).layout(db).ok()?;\n+                    layout.fields.offset(id, &db.current_target_data_layout())\n+                }\n+                _ => return None,\n+            };\n+            Some(format!(\n+                \"size = {}, align = {}, offset = {}\",\n+                layout.size.bytes(),\n+                layout.align.abi.bytes(),\n+                offset.bytes()\n+            ))\n+        }),\n         Definition::Module(it) => label_and_docs(db, it),\n         Definition::Function(it) => label_and_docs(db, it),\n-        Definition::Adt(it) => label_and_docs(db, it),\n+        Definition::Adt(it) => label_and_layout_info_and_docs(db, it, |&it| {\n+            let layout = it.layout(db).ok()?;\n+            Some(format!(\"size = {}, align = {}\", layout.size.bytes(), layout.align.abi.bytes()))\n+        }),\n         Definition::Variant(it) => label_value_and_docs(db, it, |&it| {\n             if !it.parent_enum(db).is_data_carrying(db) {\n                 match it.eval(db) {\n@@ -489,6 +512,25 @@ where\n     (label, docs)\n }\n \n+fn label_and_layout_info_and_docs<D, E, V>(\n+    db: &RootDatabase,\n+    def: D,\n+    value_extractor: E,\n+) -> (String, Option<hir::Documentation>)\n+where\n+    D: HasAttrs + HirDisplay,\n+    E: Fn(&D) -> Option<V>,\n+    V: Display,\n+{\n+    let label = if let Some(value) = value_extractor(&def) {\n+        format!(\"{} // {}\", def.display(db), value)\n+    } else {\n+        def.display(db).to_string()\n+    };\n+    let docs = def.attrs(db).docs();\n+    (label, docs)\n+}\n+\n fn label_value_and_docs<D, E, V>(\n     db: &RootDatabase,\n     def: D,"}, {"sha": "f630c3b36dc6f029b3ae4da8018e0f7a43a92096", "filename": "crates/ide/src/hover/tests.rs", "status": "modified", "additions": 120, "deletions": 99, "changes": 219, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fide%2Fsrc%2Fhover%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/crates%2Fide%2Fsrc%2Fhover%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fhover%2Ftests.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -522,6 +522,27 @@ fn main() { }\n     );\n }\n \n+#[test]\n+fn hover_field_offset() {\n+    // Hovering over the field when instantiating\n+    check(\n+        r#\"\n+struct Foo { fiel$0d_a: u8, field_b: i32, field_c: i16 }\n+\"#,\n+        expect![[r#\"\n+            *field_a*\n+\n+            ```rust\n+            test::Foo\n+            ```\n+\n+            ```rust\n+            field_a: u8 // size = 1, align = 1, offset = 6\n+            ```\n+        \"#]],\n+    );\n+}\n+\n #[test]\n fn hover_shows_struct_field_info() {\n     // Hovering over the field when instantiating\n@@ -534,16 +555,16 @@ fn main() {\n }\n \"#,\n         expect![[r#\"\n-                *field_a*\n+            *field_a*\n \n-                ```rust\n-                test::Foo\n-                ```\n+            ```rust\n+            test::Foo\n+            ```\n \n-                ```rust\n-                field_a: u32\n-                ```\n-            \"#]],\n+            ```rust\n+            field_a: u32 // size = 4, align = 4, offset = 0\n+            ```\n+        \"#]],\n     );\n \n     // Hovering over the field in the definition\n@@ -556,16 +577,16 @@ fn main() {\n }\n \"#,\n         expect![[r#\"\n-                *field_a*\n+            *field_a*\n \n-                ```rust\n-                test::Foo\n-                ```\n+            ```rust\n+            test::Foo\n+            ```\n \n-                ```rust\n-                field_a: u32\n-                ```\n-            \"#]],\n+            ```rust\n+            field_a: u32 // size = 4, align = 4, offset = 0\n+            ```\n+        \"#]],\n     );\n }\n \n@@ -1508,30 +1529,30 @@ struct Bar;\n \n fn foo() { let bar = Ba$0r; }\n \"#,\n-        expect![[r##\"\n-                *Bar*\n+        expect![[r#\"\n+            *Bar*\n \n-                ```rust\n-                test\n-                ```\n+            ```rust\n+            test\n+            ```\n \n-                ```rust\n-                struct Bar\n-                ```\n+            ```rust\n+            struct Bar // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                This is an example\n-                multiline doc\n+            This is an example\n+            multiline doc\n \n-                # Example\n+            # Example\n \n-                ```\n-                let five = 5;\n+            ```\n+            let five = 5;\n \n-                assert_eq!(6, my_crate::add_one(5));\n-                ```\n-            \"##]],\n+            assert_eq!(6, my_crate::add_one(5));\n+            ```\n+        \"#]],\n     );\n }\n \n@@ -1545,20 +1566,20 @@ struct Bar;\n fn foo() { let bar = Ba$0r; }\n \"#,\n         expect![[r#\"\n-                *Bar*\n+            *Bar*\n \n-                ```rust\n-                test\n-                ```\n+            ```rust\n+            test\n+            ```\n \n-                ```rust\n-                struct Bar\n-                ```\n+            ```rust\n+            struct Bar // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                bar docs\n-            \"#]],\n+            bar docs\n+        \"#]],\n     );\n }\n \n@@ -1574,22 +1595,22 @@ struct Bar;\n fn foo() { let bar = Ba$0r; }\n \"#,\n         expect![[r#\"\n-                *Bar*\n+            *Bar*\n \n-                ```rust\n-                test\n-                ```\n+            ```rust\n+            test\n+            ```\n \n-                ```rust\n-                struct Bar\n-                ```\n+            ```rust\n+            struct Bar // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                bar docs 0\n-                bar docs 1\n-                bar docs 2\n-            \"#]],\n+            bar docs 0\n+            bar docs 1\n+            bar docs 2\n+        \"#]],\n     );\n }\n \n@@ -1602,20 +1623,20 @@ pub struct Foo;\n pub struct B$0ar\n \"#,\n         expect![[r#\"\n-                *Bar*\n+            *Bar*\n \n-                ```rust\n-                test\n-                ```\n+            ```rust\n+            test\n+            ```\n \n-                ```rust\n-                pub struct Bar\n-                ```\n+            ```rust\n+            pub struct Bar // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                [external](https://www.google.com)\n-            \"#]],\n+            [external](https://www.google.com)\n+        \"#]],\n     );\n }\n \n@@ -1629,20 +1650,20 @@ pub struct Foo;\n pub struct B$0ar\n \"#,\n         expect![[r#\"\n-                *Bar*\n+            *Bar*\n \n-                ```rust\n-                test\n-                ```\n+            ```rust\n+            test\n+            ```\n \n-                ```rust\n-                pub struct Bar\n-                ```\n+            ```rust\n+            pub struct Bar // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                [baz](Baz)\n-            \"#]],\n+            [baz](Baz)\n+        \"#]],\n     );\n }\n \n@@ -2960,7 +2981,7 @@ fn main() {\n             ```\n \n             ```rust\n-            f: i32\n+            f: i32 // size = 4, align = 4, offset = 0\n             ```\n         \"#]],\n     );\n@@ -4203,20 +4224,20 @@ pub fn gimme() -> theitem::TheItem {\n }\n \"#,\n         expect![[r#\"\n-                *[`TheItem`]*\n+            *[`TheItem`]*\n \n-                ```rust\n-                test::theitem\n-                ```\n+            ```rust\n+            test::theitem\n+            ```\n \n-                ```rust\n-                pub struct TheItem\n-                ```\n+            ```rust\n+            pub struct TheItem // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                This is the item. Cool!\n-            \"#]],\n+            This is the item. Cool!\n+        \"#]],\n     );\n }\n \n@@ -4351,20 +4372,20 @@ mod string {\n }\n \"#,\n         expect![[r#\"\n-                *String*\n+            *String*\n \n-                ```rust\n-                main\n-                ```\n+            ```rust\n+            main\n+            ```\n \n-                ```rust\n-                struct String\n-                ```\n+            ```rust\n+            struct String // size = 0, align = 1\n+            ```\n \n-                ---\n+            ---\n \n-                Custom `String` type.\n-            \"#]],\n+            Custom `String` type.\n+        \"#]],\n     )\n }\n \n@@ -5025,7 +5046,7 @@ foo_macro!(\n             ```\n \n             ```rust\n-            pub struct Foo\n+            pub struct Foo // size = 0, align = 1\n             ```\n \n             ---\n@@ -5040,7 +5061,7 @@ fn hover_intra_in_attr() {\n     check(\n         r#\"\n #[doc = \"Doc comment for [`Foo$0`]\"]\n-pub struct Foo;\n+pub struct Foo(i32);\n \"#,\n         expect![[r#\"\n             *[`Foo`]*\n@@ -5050,7 +5071,7 @@ pub struct Foo;\n             ```\n \n             ```rust\n-            pub struct Foo\n+            pub struct Foo // size = 4, align = 4\n             ```\n \n             ---"}, {"sha": "b9d491da3c0cffe317eb5de2c598fac1692e0aca", "filename": "lib/la-arena/src/map.rs", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/86b5b609f11054fbb4dffb2e934074081d4c0bde/lib%2Fla-arena%2Fsrc%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86b5b609f11054fbb4dffb2e934074081d4c0bde/lib%2Fla-arena%2Fsrc%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/lib%2Fla-arena%2Fsrc%2Fmap.rs?ref=86b5b609f11054fbb4dffb2e934074081d4c0bde", "patch": "@@ -86,6 +86,14 @@ impl<T, V> ArenaMap<Idx<T>, V> {\n         self.v.iter().enumerate().filter_map(|(idx, o)| Some((Self::from_idx(idx), o.as_ref()?)))\n     }\n \n+    /// Returns an iterator over the arena indexes and values in the map.\n+    pub fn iter_mut(&mut self) -> impl Iterator<Item = (Idx<T>, &mut V)> {\n+        self.v\n+            .iter_mut()\n+            .enumerate()\n+            .filter_map(|(idx, o)| Some((Self::from_idx(idx), o.as_mut()?)))\n+    }\n+\n     /// Gets the given key's corresponding entry in the map for in-place manipulation.\n     pub fn entry(&mut self, idx: Idx<T>) -> Entry<'_, Idx<T>, V> {\n         let idx = Self::to_idx(idx);"}]}