{"sha": "82a15a6a0af724e71004c735f8a99ec5f2a03920", "node_id": "MDY6Q29tbWl0NzI0NzEyOjgyYTE1YTZhMGFmNzI0ZTcxMDA0YzczNWY4YTk5ZWM1ZjJhMDM5MjA=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-06-25T22:35:30Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-06-26T02:11:59Z"}, "message": "Rollup merge of #34385 - cgswords:tstream, r=nrc\n\nsyntax-[breaking-change] cc #31645\n(Only breaking because ast::TokenTree is now tokenstream::TokenTree.)\n\nThis pull request refactors TokenTrees into their own file as src/libsyntax/tokenstream.rs, moving them out of src/libsyntax/ast.rs, in order to prepare for an accompanying TokenStream implementation (per RFC 1566).", "tree": {"sha": "1894cea4f94545ddeed63febd5ad7b20519e3270", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1894cea4f94545ddeed63febd5ad7b20519e3270"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/82a15a6a0af724e71004c735f8a99ec5f2a03920", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/82a15a6a0af724e71004c735f8a99ec5f2a03920", "html_url": "https://github.com/rust-lang/rust/commit/82a15a6a0af724e71004c735f8a99ec5f2a03920", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/82a15a6a0af724e71004c735f8a99ec5f2a03920/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d3ae56d755f912471e4c36982a069317842fa495", "url": "https://api.github.com/repos/rust-lang/rust/commits/d3ae56d755f912471e4c36982a069317842fa495", "html_url": "https://github.com/rust-lang/rust/commit/d3ae56d755f912471e4c36982a069317842fa495"}, {"sha": "d59accfb065843d12db9180a4f504664e3d23ef1", "url": "https://api.github.com/repos/rust-lang/rust/commits/d59accfb065843d12db9180a4f504664e3d23ef1", "html_url": "https://github.com/rust-lang/rust/commit/d59accfb065843d12db9180a4f504664e3d23ef1"}], "stats": {"total": 629, "additions": 342, "deletions": 287}, "files": [{"sha": "c6338568c0e05536702585b9867ad9607a21b583", "filename": "src/librustc/hir/mod.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibrustc%2Fhir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibrustc%2Fhir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmod.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -39,11 +39,12 @@ use util::nodemap::{NodeMap, FnvHashSet};\n use syntax_pos::{mk_sp, Span, ExpnId};\n use syntax::codemap::{self, respan, Spanned};\n use syntax::abi::Abi;\n-use syntax::ast::{Name, NodeId, DUMMY_NODE_ID, TokenTree, AsmDialect};\n+use syntax::ast::{Name, NodeId, DUMMY_NODE_ID, AsmDialect};\n use syntax::ast::{Attribute, Lit, StrStyle, FloatTy, IntTy, UintTy, MetaItem};\n use syntax::attr::{ThinAttributes, ThinAttributesExt};\n use syntax::parse::token::{keywords, InternedString};\n use syntax::ptr::P;\n+use syntax::tokenstream::TokenTree;\n \n use std::collections::BTreeMap;\n use std::fmt;"}, {"sha": "f8fd6eea211a022eb8cdb9b068dbd59382e98690", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 191, "changes": 192, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -20,13 +20,10 @@ use syntax_pos::{mk_sp, Span, DUMMY_SP, ExpnId};\n use codemap::{respan, Spanned};\n use abi::Abi;\n use errors;\n-use ext::base;\n-use ext::tt::macro_parser;\n use parse::token::{self, keywords, InternedString};\n-use parse::lexer;\n-use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use print::pprust;\n use ptr::P;\n+use tokenstream::{TokenTree};\n \n use std::fmt;\n use std::rc::Rc;\n@@ -1134,193 +1131,6 @@ pub enum CaptureBy {\n     Ref,\n }\n \n-/// A delimited sequence of token trees\n-#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n-pub struct Delimited {\n-    /// The type of delimiter\n-    pub delim: token::DelimToken,\n-    /// The span covering the opening delimiter\n-    pub open_span: Span,\n-    /// The delimited sequence of token trees\n-    pub tts: Vec<TokenTree>,\n-    /// The span covering the closing delimiter\n-    pub close_span: Span,\n-}\n-\n-impl Delimited {\n-    /// Returns the opening delimiter as a token.\n-    pub fn open_token(&self) -> token::Token {\n-        token::OpenDelim(self.delim)\n-    }\n-\n-    /// Returns the closing delimiter as a token.\n-    pub fn close_token(&self) -> token::Token {\n-        token::CloseDelim(self.delim)\n-    }\n-\n-    /// Returns the opening delimiter as a token tree.\n-    pub fn open_tt(&self) -> TokenTree {\n-        TokenTree::Token(self.open_span, self.open_token())\n-    }\n-\n-    /// Returns the closing delimiter as a token tree.\n-    pub fn close_tt(&self) -> TokenTree {\n-        TokenTree::Token(self.close_span, self.close_token())\n-    }\n-}\n-\n-/// A sequence of token trees\n-#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n-pub struct SequenceRepetition {\n-    /// The sequence of token trees\n-    pub tts: Vec<TokenTree>,\n-    /// The optional separator\n-    pub separator: Option<token::Token>,\n-    /// Whether the sequence can be repeated zero (*), or one or more times (+)\n-    pub op: KleeneOp,\n-    /// The number of `MatchNt`s that appear in the sequence (and subsequences)\n-    pub num_captures: usize,\n-}\n-\n-/// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n-/// for token sequences.\n-#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n-pub enum KleeneOp {\n-    ZeroOrMore,\n-    OneOrMore,\n-}\n-\n-/// When the main rust parser encounters a syntax-extension invocation, it\n-/// parses the arguments to the invocation as a token-tree. This is a very\n-/// loose structure, such that all sorts of different AST-fragments can\n-/// be passed to syntax extensions using a uniform type.\n-///\n-/// If the syntax extension is an MBE macro, it will attempt to match its\n-/// LHS token tree against the provided token tree, and if it finds a\n-/// match, will transcribe the RHS token tree, splicing in any captured\n-/// macro_parser::matched_nonterminals into the `SubstNt`s it finds.\n-///\n-/// The RHS of an MBE macro is the only place `SubstNt`s are substituted.\n-/// Nothing special happens to misnamed or misplaced `SubstNt`s.\n-#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n-pub enum TokenTree {\n-    /// A single token\n-    Token(Span, token::Token),\n-    /// A delimited sequence of token trees\n-    Delimited(Span, Rc<Delimited>),\n-\n-    // This only makes sense in MBE macros.\n-\n-    /// A kleene-style repetition sequence with a span\n-    // FIXME(eddyb) #12938 Use DST.\n-    Sequence(Span, Rc<SequenceRepetition>),\n-}\n-\n-impl TokenTree {\n-    pub fn len(&self) -> usize {\n-        match *self {\n-            TokenTree::Token(_, token::DocComment(name)) => {\n-                match doc_comment_style(&name.as_str()) {\n-                    AttrStyle::Outer => 2,\n-                    AttrStyle::Inner => 3\n-                }\n-            }\n-            TokenTree::Token(_, token::SpecialVarNt(..)) => 2,\n-            TokenTree::Token(_, token::MatchNt(..)) => 3,\n-            TokenTree::Delimited(_, ref delimed) => {\n-                delimed.tts.len() + 2\n-            }\n-            TokenTree::Sequence(_, ref seq) => {\n-                seq.tts.len()\n-            }\n-            TokenTree::Token(..) => 0\n-        }\n-    }\n-\n-    pub fn get_tt(&self, index: usize) -> TokenTree {\n-        match (self, index) {\n-            (&TokenTree::Token(sp, token::DocComment(_)), 0) => {\n-                TokenTree::Token(sp, token::Pound)\n-            }\n-            (&TokenTree::Token(sp, token::DocComment(name)), 1)\n-            if doc_comment_style(&name.as_str()) == AttrStyle::Inner => {\n-                TokenTree::Token(sp, token::Not)\n-            }\n-            (&TokenTree::Token(sp, token::DocComment(name)), _) => {\n-                let stripped = strip_doc_comment_decoration(&name.as_str());\n-\n-                // Searches for the occurrences of `\"#*` and returns the minimum number of `#`s\n-                // required to wrap the text.\n-                let num_of_hashes = stripped.chars().scan(0, |cnt, x| {\n-                    *cnt = if x == '\"' {\n-                        1\n-                    } else if *cnt != 0 && x == '#' {\n-                        *cnt + 1\n-                    } else {\n-                        0\n-                    };\n-                    Some(*cnt)\n-                }).max().unwrap_or(0);\n-\n-                TokenTree::Delimited(sp, Rc::new(Delimited {\n-                    delim: token::Bracket,\n-                    open_span: sp,\n-                    tts: vec![TokenTree::Token(sp, token::Ident(token::str_to_ident(\"doc\"))),\n-                              TokenTree::Token(sp, token::Eq),\n-                              TokenTree::Token(sp, token::Literal(\n-                                  token::StrRaw(token::intern(&stripped), num_of_hashes), None))],\n-                    close_span: sp,\n-                }))\n-            }\n-            (&TokenTree::Delimited(_, ref delimed), _) => {\n-                if index == 0 {\n-                    return delimed.open_tt();\n-                }\n-                if index == delimed.tts.len() + 1 {\n-                    return delimed.close_tt();\n-                }\n-                delimed.tts[index - 1].clone()\n-            }\n-            (&TokenTree::Token(sp, token::SpecialVarNt(var)), _) => {\n-                let v = [TokenTree::Token(sp, token::Dollar),\n-                         TokenTree::Token(sp, token::Ident(token::str_to_ident(var.as_str())))];\n-                v[index].clone()\n-            }\n-            (&TokenTree::Token(sp, token::MatchNt(name, kind)), _) => {\n-                let v = [TokenTree::Token(sp, token::SubstNt(name)),\n-                         TokenTree::Token(sp, token::Colon),\n-                         TokenTree::Token(sp, token::Ident(kind))];\n-                v[index].clone()\n-            }\n-            (&TokenTree::Sequence(_, ref seq), _) => {\n-                seq.tts[index].clone()\n-            }\n-            _ => panic!(\"Cannot expand a token tree\")\n-        }\n-    }\n-\n-    /// Returns the `Span` corresponding to this token tree.\n-    pub fn get_span(&self) -> Span {\n-        match *self {\n-            TokenTree::Token(span, _)     => span,\n-            TokenTree::Delimited(span, _) => span,\n-            TokenTree::Sequence(span, _)  => span,\n-        }\n-    }\n-\n-    /// Use this token tree as a matcher to parse given tts.\n-    pub fn parse(cx: &base::ExtCtxt, mtch: &[TokenTree], tts: &[TokenTree])\n-                 -> macro_parser::NamedParseResult {\n-        // `None` is because we're not interpolating\n-        let arg_rdr = lexer::new_tt_reader_with_doc_flag(&cx.parse_sess().span_diagnostic,\n-                                                         None,\n-                                                         None,\n-                                                         tts.iter().cloned().collect(),\n-                                                         true);\n-        macro_parser::parse(cx.parse_sess(), cx.cfg(), arg_rdr, mtch)\n-    }\n-}\n-\n pub type Mac = Spanned<Mac_>;\n \n /// Represents a macro invocation. The Path indicates which macro"}, {"sha": "4e50299e836b3b71ef58be94ef9175bb342dc868", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -13,12 +13,13 @@ use std::collections::BTreeMap;\n use std::env;\n \n use ast;\n-use ast::{Ident, Name, TokenTree};\n+use ast::{Ident, Name};\n use syntax_pos::Span;\n use ext::base::{ExtCtxt, MacEager, MacResult};\n use ext::build::AstBuilder;\n use parse::token;\n use ptr::P;\n+use tokenstream::{TokenTree};\n use util::small_vector::SmallVector;\n \n use diagnostics::metadata::output_metadata;"}, {"sha": "d1b7546752d3b90508dcb2eb1adcc65d329b8f3b", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 16, "deletions": 12, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -32,6 +32,7 @@ use fold::Folder;\n use std::collections::{HashMap, HashSet};\n use std::rc::Rc;\n use std::default::Default;\n+use tokenstream;\n \n \n #[derive(Debug,Clone)]\n@@ -168,20 +169,22 @@ pub trait TTMacroExpander {\n     fn expand<'cx>(&self,\n                    ecx: &'cx mut ExtCtxt,\n                    span: Span,\n-                   token_tree: &[ast::TokenTree])\n+                   token_tree: &[tokenstream::TokenTree])\n                    -> Box<MacResult+'cx>;\n }\n \n pub type MacroExpanderFn =\n-    for<'cx> fn(&'cx mut ExtCtxt, Span, &[ast::TokenTree]) -> Box<MacResult+'cx>;\n+    for<'cx> fn(&'cx mut ExtCtxt, Span, &[tokenstream::TokenTree])\n+                -> Box<MacResult+'cx>;\n \n impl<F> TTMacroExpander for F\n-    where F : for<'cx> Fn(&'cx mut ExtCtxt, Span, &[ast::TokenTree]) -> Box<MacResult+'cx>\n+    where F : for<'cx> Fn(&'cx mut ExtCtxt, Span, &[tokenstream::TokenTree])\n+                          -> Box<MacResult+'cx>\n {\n     fn expand<'cx>(&self,\n                    ecx: &'cx mut ExtCtxt,\n                    span: Span,\n-                   token_tree: &[ast::TokenTree])\n+                   token_tree: &[tokenstream::TokenTree])\n                    -> Box<MacResult+'cx> {\n         (*self)(ecx, span, token_tree)\n     }\n@@ -192,22 +195,23 @@ pub trait IdentMacroExpander {\n                    cx: &'cx mut ExtCtxt,\n                    sp: Span,\n                    ident: ast::Ident,\n-                   token_tree: Vec<ast::TokenTree> )\n+                   token_tree: Vec<tokenstream::TokenTree> )\n                    -> Box<MacResult+'cx>;\n }\n \n pub type IdentMacroExpanderFn =\n-    for<'cx> fn(&'cx mut ExtCtxt, Span, ast::Ident, Vec<ast::TokenTree>) -> Box<MacResult+'cx>;\n+    for<'cx> fn(&'cx mut ExtCtxt, Span, ast::Ident, Vec<tokenstream::TokenTree>)\n+                -> Box<MacResult+'cx>;\n \n impl<F> IdentMacroExpander for F\n     where F : for<'cx> Fn(&'cx mut ExtCtxt, Span, ast::Ident,\n-                          Vec<ast::TokenTree>) -> Box<MacResult+'cx>\n+                          Vec<tokenstream::TokenTree>) -> Box<MacResult+'cx>\n {\n     fn expand<'cx>(&self,\n                    cx: &'cx mut ExtCtxt,\n                    sp: Span,\n                    ident: ast::Ident,\n-                   token_tree: Vec<ast::TokenTree> )\n+                   token_tree: Vec<tokenstream::TokenTree> )\n                    -> Box<MacResult+'cx>\n     {\n         (*self)(cx, sp, ident, token_tree)\n@@ -630,7 +634,7 @@ impl<'a> ExtCtxt<'a> {\n         expand::MacroExpander::new(self)\n     }\n \n-    pub fn new_parser_from_tts(&self, tts: &[ast::TokenTree])\n+    pub fn new_parser_from_tts(&self, tts: &[tokenstream::TokenTree])\n         -> parser::Parser<'a> {\n         parse::tts_to_parser(self.parse_sess, tts.to_vec(), self.cfg())\n     }\n@@ -829,7 +833,7 @@ pub fn expr_to_string(cx: &mut ExtCtxt, expr: P<ast::Expr>, err_msg: &str)\n /// done as rarely as possible).\n pub fn check_zero_tts(cx: &ExtCtxt,\n                       sp: Span,\n-                      tts: &[ast::TokenTree],\n+                      tts: &[tokenstream::TokenTree],\n                       name: &str) {\n     if !tts.is_empty() {\n         cx.span_err(sp, &format!(\"{} takes no arguments\", name));\n@@ -840,7 +844,7 @@ pub fn check_zero_tts(cx: &ExtCtxt,\n /// is not a string literal, emit an error and return None.\n pub fn get_single_str_from_tts(cx: &mut ExtCtxt,\n                                sp: Span,\n-                               tts: &[ast::TokenTree],\n+                               tts: &[tokenstream::TokenTree],\n                                name: &str)\n                                -> Option<String> {\n     let mut p = cx.new_parser_from_tts(tts);\n@@ -861,7 +865,7 @@ pub fn get_single_str_from_tts(cx: &mut ExtCtxt,\n /// parsing error, emit a non-fatal error and return None.\n pub fn get_exprs_from_tts(cx: &mut ExtCtxt,\n                           sp: Span,\n-                          tts: &[ast::TokenTree]) -> Option<Vec<P<ast::Expr>>> {\n+                          tts: &[tokenstream::TokenTree]) -> Option<Vec<P<ast::Expr>>> {\n     let mut p = cx.new_parser_from_tts(tts);\n     let mut es = Vec::new();\n     while p.token != token::Eof {"}, {"sha": "3a3863ae65316c353187d205152af010b8d7ed24", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -11,7 +11,6 @@\n use ast::{Block, Crate, DeclKind, PatKind};\n use ast::{Local, Ident, Mac_, Name, SpannedIdent};\n use ast::{MacStmtStyle, Mrk, Stmt, StmtKind, ItemKind};\n-use ast::TokenTree;\n use ast;\n use attr::HasAttrs;\n use ext::mtwt;\n@@ -28,6 +27,7 @@ use fold::*;\n use util::move_map::MoveMap;\n use parse::token::{fresh_mark, fresh_name, intern, keywords};\n use ptr::P;\n+use tokenstream::TokenTree;\n use util::small_vector::SmallVector;\n use visit;\n use visit::Visitor;"}, {"sha": "89a260a02357b436d3428f7b6d53426612712d76", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 12, "deletions": 9, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{self, Arg, Arm, Block, Expr, Item, Pat, Stmt, TokenTree, Ty};\n+use ast::{self, Arg, Arm, Block, Expr, Item, Pat, Stmt, Ty};\n use syntax_pos::Span;\n use ext::base::ExtCtxt;\n use ext::base;\n@@ -17,6 +17,7 @@ use parse::parser::{Parser, PathStyle};\n use parse::token::*;\n use parse::token;\n use ptr::P;\n+use tokenstream::{self, TokenTree};\n \n /// Quasiquoting works via token trees.\n ///\n@@ -33,7 +34,7 @@ pub mod rt {\n     use ptr::P;\n     use std::rc::Rc;\n \n-    use ast::TokenTree;\n+    use tokenstream::{self, TokenTree};\n \n     pub use parse::new_parser_from_tts;\n     pub use syntax_pos::{BytePos, Span, DUMMY_SP};\n@@ -215,7 +216,7 @@ pub mod rt {\n             if self.node.style == ast::AttrStyle::Inner {\n                 r.push(TokenTree::Token(self.span, token::Not));\n             }\n-            r.push(TokenTree::Delimited(self.span, Rc::new(ast::Delimited {\n+            r.push(TokenTree::Delimited(self.span, Rc::new(tokenstream::Delimited {\n                 delim: token::Bracket,\n                 open_span: self.span,\n                 tts: self.node.value.to_tokens(cx),\n@@ -235,7 +236,7 @@ pub mod rt {\n \n     impl ToTokens for () {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Delimited(DUMMY_SP, Rc::new(ast::Delimited {\n+            vec![TokenTree::Delimited(DUMMY_SP, Rc::new(tokenstream::Delimited {\n                 delim: token::Paren,\n                 open_span: DUMMY_SP,\n                 tts: vec![],\n@@ -549,7 +550,7 @@ fn mk_name(cx: &ExtCtxt, sp: Span, ident: ast::Ident) -> P<ast::Expr> {\n }\n \n fn mk_tt_path(cx: &ExtCtxt, sp: Span, name: &str) -> P<ast::Expr> {\n-    let idents = vec!(id_ext(\"syntax\"), id_ext(\"ast\"), id_ext(\"TokenTree\"), id_ext(name));\n+    let idents = vec!(id_ext(\"syntax\"), id_ext(\"tokenstream\"), id_ext(\"TokenTree\"), id_ext(name));\n     cx.expr_path(cx.path_global(sp, idents))\n }\n \n@@ -773,12 +774,12 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, matcher: bool) -> Vec<ast::Stm\n                 None => cx.expr_none(sp),\n             };\n             let e_op = match seq.op {\n-                ast::KleeneOp::ZeroOrMore => \"ZeroOrMore\",\n-                ast::KleeneOp::OneOrMore => \"OneOrMore\",\n+                tokenstream::KleeneOp::ZeroOrMore => \"ZeroOrMore\",\n+                tokenstream::KleeneOp::OneOrMore => \"OneOrMore\",\n             };\n             let e_op_idents = vec![\n                 id_ext(\"syntax\"),\n-                id_ext(\"ast\"),\n+                id_ext(\"tokenstream\"),\n                 id_ext(\"KleeneOp\"),\n                 id_ext(e_op),\n             ];\n@@ -788,7 +789,9 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, matcher: bool) -> Vec<ast::Stm\n                               cx.field_imm(sp, id_ext(\"op\"), e_op),\n                               cx.field_imm(sp, id_ext(\"num_captures\"),\n                                                cx.expr_usize(sp, seq.num_captures))];\n-            let seq_path = vec![id_ext(\"syntax\"), id_ext(\"ast\"), id_ext(\"SequenceRepetition\")];\n+            let seq_path = vec![id_ext(\"syntax\"),\n+                                id_ext(\"tokenstream\"),\n+                                id_ext(\"SequenceRepetition\")];\n             let e_seq_struct = cx.expr_struct(sp, cx.path_global(sp, seq_path), fields);\n             let e_rc_new = cx.expr_call_global(sp, vec![id_ext(\"std\"),\n                                                         id_ext(\"rc\"),"}, {"sha": "b4ee6fa418aaea45ebb4eae93415dcd0a2723b32", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -17,6 +17,7 @@ use parse::token;\n use parse;\n use print::pprust;\n use ptr::P;\n+use tokenstream;\n use util::small_vector::SmallVector;\n \n use std::fs::File;\n@@ -29,7 +30,7 @@ use std::rc::Rc;\n // a given file into the current one.\n \n /// line!(): expands to the current line number\n-pub fn expand_line(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_line(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                    -> Box<base::MacResult+'static> {\n     base::check_zero_tts(cx, sp, tts, \"line!\");\n \n@@ -40,7 +41,7 @@ pub fn expand_line(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n }\n \n /* column!(): expands to the current column number */\n-pub fn expand_column(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_column(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                   -> Box<base::MacResult+'static> {\n     base::check_zero_tts(cx, sp, tts, \"column!\");\n \n@@ -53,7 +54,7 @@ pub fn expand_column(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n /// file!(): expands to the current filename */\n /// The filemap (`loc.file`) contains a bunch more information we could spit\n /// out if we wanted.\n-pub fn expand_file(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_file(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                    -> Box<base::MacResult+'static> {\n     base::check_zero_tts(cx, sp, tts, \"file!\");\n \n@@ -63,14 +64,14 @@ pub fn expand_file(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     base::MacEager::expr(cx.expr_str(topmost, filename))\n }\n \n-pub fn expand_stringify(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_stringify(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                         -> Box<base::MacResult+'static> {\n     let s = pprust::tts_to_string(tts);\n     base::MacEager::expr(cx.expr_str(sp,\n                                    token::intern_and_get_ident(&s[..])))\n }\n \n-pub fn expand_mod(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_mod(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                   -> Box<base::MacResult+'static> {\n     base::check_zero_tts(cx, sp, tts, \"module_path!\");\n     let string = cx.mod_path()\n@@ -86,7 +87,7 @@ pub fn expand_mod(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n /// include! : parse the given file as an expr\n /// This is generally a bad idea because it's going to behave\n /// unhygienically.\n-pub fn expand_include<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_include<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                            -> Box<base::MacResult+'cx> {\n     let file = match get_single_str_from_tts(cx, sp, tts, \"include!\") {\n         Some(f) => f,\n@@ -129,7 +130,7 @@ pub fn expand_include<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree\n }\n \n // include_str! : read the given file, insert it as a literal string expr\n-pub fn expand_include_str(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_include_str(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                           -> Box<base::MacResult+'static> {\n     let file = match get_single_str_from_tts(cx, sp, tts, \"include_str!\") {\n         Some(f) => f,\n@@ -166,7 +167,7 @@ pub fn expand_include_str(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     }\n }\n \n-pub fn expand_include_bytes(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_include_bytes(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                             -> Box<base::MacResult+'static> {\n     let file = match get_single_str_from_tts(cx, sp, tts, \"include_bytes!\") {\n         Some(f) => f,"}, {"sha": "813afb935762e9e7d9a40ac40e8ee6d6fb29882f", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -79,7 +79,7 @@ pub use self::ParseResult::*;\n use self::TokenTreeOrTokenTreeVec::*;\n \n use ast;\n-use ast::{TokenTree, Name, Ident};\n+use ast::{Name, Ident};\n use syntax_pos::{self, BytePos, mk_sp, Span};\n use codemap::Spanned;\n use errors::FatalError;\n@@ -91,6 +91,7 @@ use parse::token::{Token, Nonterminal};\n use parse::token;\n use print::pprust;\n use ptr::P;\n+use tokenstream::{self, TokenTree};\n \n use std::mem;\n use std::rc::Rc;\n@@ -102,8 +103,8 @@ use std::collections::hash_map::Entry::{Vacant, Occupied};\n \n #[derive(Clone)]\n enum TokenTreeOrTokenTreeVec {\n-    Tt(ast::TokenTree),\n-    TtSeq(Rc<Vec<ast::TokenTree>>),\n+    Tt(tokenstream::TokenTree),\n+    TtSeq(Rc<Vec<tokenstream::TokenTree>>),\n }\n \n impl TokenTreeOrTokenTreeVec {\n@@ -374,7 +375,7 @@ pub fn parse(sess: &ParseSess,\n                 match ei.top_elts.get_tt(idx) {\n                     /* need to descend into sequence */\n                     TokenTree::Sequence(sp, seq) => {\n-                        if seq.op == ast::KleeneOp::ZeroOrMore {\n+                        if seq.op == tokenstream::KleeneOp::ZeroOrMore {\n                             let mut new_ei = ei.clone();\n                             new_ei.match_cur += seq.num_captures;\n                             new_ei.idx += 1;"}, {"sha": "5015a741378b87d39fa62d46e0125784612b7c49", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 9, "deletions": 7, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{self, TokenTree};\n+use ast;\n use syntax_pos::{Span, DUMMY_SP};\n use ext::base::{DummyResult, ExtCtxt, MacResult, SyntaxExtension};\n use ext::base::{NormalTT, TTMacroExpander};\n@@ -21,6 +21,7 @@ use parse::token::{self, gensym_ident, NtTT, Token};\n use parse::token::Token::*;\n use print;\n use ptr::P;\n+use tokenstream::{self, TokenTree};\n \n use util::small_vector::SmallVector;\n \n@@ -263,22 +264,22 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n     let match_rhs_tok = MatchNt(rhs_nm, token::str_to_ident(\"tt\"));\n     let argument_gram = vec!(\n         TokenTree::Sequence(DUMMY_SP,\n-                   Rc::new(ast::SequenceRepetition {\n+                   Rc::new(tokenstream::SequenceRepetition {\n                        tts: vec![\n                            TokenTree::Token(DUMMY_SP, match_lhs_tok),\n                            TokenTree::Token(DUMMY_SP, token::FatArrow),\n                            TokenTree::Token(DUMMY_SP, match_rhs_tok)],\n                        separator: Some(token::Semi),\n-                       op: ast::KleeneOp::OneOrMore,\n+                       op: tokenstream::KleeneOp::OneOrMore,\n                        num_captures: 2\n                    })),\n         //to phase into semicolon-termination instead of\n         //semicolon-separation\n         TokenTree::Sequence(DUMMY_SP,\n-                   Rc::new(ast::SequenceRepetition {\n+                   Rc::new(tokenstream::SequenceRepetition {\n                        tts: vec![TokenTree::Token(DUMMY_SP, token::Semi)],\n                        separator: None,\n-                       op: ast::KleeneOp::ZeroOrMore,\n+                       op: tokenstream::KleeneOp::ZeroOrMore,\n                        num_captures: 0\n                    })));\n \n@@ -442,7 +443,7 @@ impl FirstSets {\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n-                        if subfirst.maybe_empty || seq_rep.op == ast::KleeneOp::ZeroOrMore {\n+                        if subfirst.maybe_empty || seq_rep.op == tokenstream::KleeneOp::ZeroOrMore {\n                             // If sequence is potentially empty, then\n                             // union them (preserving first emptiness).\n                             first.add_all(&TokenSet { maybe_empty: true, ..subfirst });\n@@ -489,7 +490,8 @@ impl FirstSets {\n \n                             assert!(first.maybe_empty);\n                             first.add_all(subfirst);\n-                            if subfirst.maybe_empty || seq_rep.op == ast::KleeneOp::ZeroOrMore {\n+                            if subfirst.maybe_empty ||\n+                               seq_rep.op == tokenstream::KleeneOp::ZeroOrMore {\n                                 // continue scanning for more first\n                                 // tokens, but also make sure we\n                                 // restore empty-tracking state"}, {"sha": "9c493948d604ca02cd3ef48f9e66d094e99ea8eb", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -9,15 +9,15 @@\n // except according to those terms.\n use self::LockstepIterSize::*;\n \n-use ast;\n-use ast::{TokenTree, Ident, Name};\n+use ast::{Ident, Name};\n use syntax_pos::{Span, DUMMY_SP};\n use errors::{Handler, DiagnosticBuilder};\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use parse::token::{DocComment, MatchNt, SubstNt};\n use parse::token::{Token, NtIdent, SpecialMacroVar};\n use parse::token;\n use parse::lexer::TokenAndSpan;\n+use tokenstream::{self, TokenTree};\n \n use std::rc::Rc;\n use std::ops::Add;\n@@ -59,7 +59,7 @@ pub struct TtReader<'a> {\n pub fn new_tt_reader(sp_diag: &Handler,\n                      interp: Option<HashMap<Name, Rc<NamedMatch>>>,\n                      imported_from: Option<Ident>,\n-                     src: Vec<ast::TokenTree>)\n+                     src: Vec<tokenstream::TokenTree>)\n                      -> TtReader {\n     new_tt_reader_with_doc_flag(sp_diag, interp, imported_from, src, false)\n }\n@@ -73,16 +73,16 @@ pub fn new_tt_reader(sp_diag: &Handler,\n pub fn new_tt_reader_with_doc_flag(sp_diag: &Handler,\n                                    interp: Option<HashMap<Name, Rc<NamedMatch>>>,\n                                    imported_from: Option<Ident>,\n-                                   src: Vec<ast::TokenTree>,\n+                                   src: Vec<tokenstream::TokenTree>,\n                                    desugar_doc_comments: bool)\n                                    -> TtReader {\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n         stack: vec!(TtFrame {\n-            forest: TokenTree::Sequence(DUMMY_SP, Rc::new(ast::SequenceRepetition {\n+            forest: TokenTree::Sequence(DUMMY_SP, Rc::new(tokenstream::SequenceRepetition {\n                 tts: src,\n                 // doesn't matter. This merely holds the root unzipping.\n-                separator: None, op: ast::KleeneOp::ZeroOrMore, num_captures: 0\n+                separator: None, op: tokenstream::KleeneOp::ZeroOrMore, num_captures: 0\n             })),\n             idx: 0,\n             dotdotdoted: false,\n@@ -259,7 +259,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                     }\n                     LisConstraint(len, _) => {\n                         if len == 0 {\n-                            if seq.op == ast::KleeneOp::OneOrMore {\n+                            if seq.op == tokenstream::KleeneOp::OneOrMore {\n                                 // FIXME #2887 blame invoker\n                                 panic!(r.sp_diag.span_fatal(sp.clone(),\n                                                      \"this must repeat at least once\"));"}, {"sha": "54f6584101070dddaa1a259fdc8daad020335c78", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -25,6 +25,7 @@ use syntax_pos::Span;\n use codemap::{Spanned, respan};\n use parse::token::{self, keywords};\n use ptr::P;\n+use tokenstream::*;\n use util::small_vector::SmallVector;\n use util::move_map::MoveMap;\n "}, {"sha": "9c1b8175a3e7e93cb80ba5b993ffff7529bec30a", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -105,6 +105,7 @@ pub mod show_span;\n pub mod std_inject;\n pub mod str;\n pub mod test;\n+pub mod tokenstream;\n pub mod visit;\n \n pub mod print {"}, {"sha": "d594e0f5558d5e7180f4fdce77a2a022ae0fa419", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -18,6 +18,7 @@ use parse::parser::Parser;\n use parse::token::InternedString;\n use ptr::P;\n use str::char_at;\n+use tokenstream;\n \n use std::cell::RefCell;\n use std::iter;\n@@ -161,7 +162,7 @@ pub fn parse_tts_from_source_str<'a>(name: String,\n                                      source: String,\n                                      cfg: ast::CrateConfig,\n                                      sess: &'a ParseSess)\n-                                     -> PResult<'a, Vec<ast::TokenTree>> {\n+                                     -> PResult<'a, Vec<tokenstream::TokenTree>> {\n     let mut p = new_parser_from_source_str(\n         sess,\n         cfg,\n@@ -223,7 +224,7 @@ pub fn filemap_to_parser<'a>(sess: &'a ParseSess,\n // compiler expands into it\n pub fn new_parser_from_tts<'a>(sess: &'a ParseSess,\n                                cfg: ast::CrateConfig,\n-                               tts: Vec<ast::TokenTree>) -> Parser<'a> {\n+                               tts: Vec<tokenstream::TokenTree>) -> Parser<'a> {\n     tts_to_parser(sess, tts, cfg)\n }\n \n@@ -248,7 +249,7 @@ fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n \n /// Given a filemap, produce a sequence of token-trees\n pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n-    -> Vec<ast::TokenTree> {\n+    -> Vec<tokenstream::TokenTree> {\n     // it appears to me that the cfg doesn't matter here... indeed,\n     // parsing tt's probably shouldn't require a parser at all.\n     let cfg = Vec::new();\n@@ -259,7 +260,7 @@ pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n \n /// Given tts and cfg, produce a parser\n pub fn tts_to_parser<'a>(sess: &'a ParseSess,\n-                         tts: Vec<ast::TokenTree>,\n+                         tts: Vec<tokenstream::TokenTree>,\n                          cfg: ast::CrateConfig) -> Parser<'a> {\n     let trdr = lexer::new_tt_reader(&sess.span_diagnostic, None, None, tts);\n     let mut p = Parser::new(sess, cfg, Box::new(trdr));\n@@ -664,14 +665,15 @@ mod tests {\n     use std::rc::Rc;\n     use syntax_pos::{Span, BytePos, Pos, NO_EXPANSION};\n     use codemap::Spanned;\n-    use ast::{self, TokenTree, PatKind};\n+    use ast::{self, PatKind};\n     use abi::Abi;\n     use attr::{first_attr_value_str_by_name, AttrMetaMethods};\n     use parse;\n     use parse::parser::Parser;\n     use parse::token::{str_to_ident};\n     use print::pprust::item_to_string;\n     use ptr::P;\n+    use tokenstream::{self, TokenTree};\n     use util::parser_testing::{string_to_tts, string_to_parser};\n     use util::parser_testing::{string_to_expr, string_to_item, string_to_stmt};\n \n@@ -731,7 +733,7 @@ mod tests {\n     #[test]\n     fn string_to_tts_macro () {\n         let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n-        let tts: &[ast::TokenTree] = &tts[..];\n+        let tts: &[tokenstream::TokenTree] = &tts[..];\n \n         match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n             (\n@@ -791,7 +793,7 @@ mod tests {\n             TokenTree::Token(sp(3, 4), token::Ident(str_to_ident(\"a\"))),\n             TokenTree::Delimited(\n                 sp(5, 14),\n-                Rc::new(ast::Delimited {\n+                Rc::new(tokenstream::Delimited {\n                     delim: token::DelimToken::Paren,\n                     open_span: sp(5, 6),\n                     tts: vec![\n@@ -803,7 +805,7 @@ mod tests {\n                 })),\n             TokenTree::Delimited(\n                 sp(15, 21),\n-                Rc::new(ast::Delimited {\n+                Rc::new(tokenstream::Delimited {\n                     delim: token::DelimToken::Brace,\n                     open_span: sp(15, 16),\n                     tts: vec!["}, {"sha": "e643de66691706f290abc210f4675d0100b81fe6", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -33,7 +33,7 @@ use ast::{Stmt, StmtKind};\n use ast::{VariantData, StructField};\n use ast::StrStyle;\n use ast::SelfKind;\n-use ast::{Delimited, SequenceRepetition, TokenTree, TraitItem, TraitRef};\n+use ast::{TraitItem, TraitRef};\n use ast::{Ty, TyKind, TypeBinding, TyParam, TyParamBounds};\n use ast::{ViewPath, ViewPathGlob, ViewPathList, ViewPathSimple};\n use ast::{Visibility, WhereClause};\n@@ -56,6 +56,7 @@ use util::parser::{AssocOp, Fixity};\n use print::pprust;\n use ptr::P;\n use parse::PResult;\n+use tokenstream::{self, Delimited, SequenceRepetition, TokenTree};\n \n use std::collections::HashSet;\n use std::mem;\n@@ -2746,16 +2747,17 @@ impl<'a> Parser<'a> {\n     /// Parse an optional separator followed by a Kleene-style\n     /// repetition token (+ or *).\n     pub fn parse_sep_and_kleene_op(&mut self)\n-                                   -> PResult<'a, (Option<token::Token>, ast::KleeneOp)> {\n-        fn parse_kleene_op<'a>(parser: &mut Parser<'a>) -> PResult<'a,  Option<ast::KleeneOp>> {\n+                                   -> PResult<'a, (Option<token::Token>, tokenstream::KleeneOp)> {\n+        fn parse_kleene_op<'a>(parser: &mut Parser<'a>) ->\n+          PResult<'a,  Option<tokenstream::KleeneOp>> {\n             match parser.token {\n                 token::BinOp(token::Star) => {\n                     parser.bump();\n-                    Ok(Some(ast::KleeneOp::ZeroOrMore))\n+                    Ok(Some(tokenstream::KleeneOp::ZeroOrMore))\n                 },\n                 token::BinOp(token::Plus) => {\n                     parser.bump();\n-                    Ok(Some(ast::KleeneOp::OneOrMore))\n+                    Ok(Some(tokenstream::KleeneOp::OneOrMore))\n                 },\n                 _ => Ok(None)\n             }"}, {"sha": "8376d28164dee58ad0b0f81354ec30a5e63a729b", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -19,6 +19,7 @@ use ext::mtwt;\n use ptr::P;\n use util::interner::{RcStr, StrInterner};\n use util::interner;\n+use tokenstream;\n \n use serialize::{Decodable, Decoder, Encodable, Encoder};\n use std::fmt;\n@@ -338,7 +339,7 @@ pub enum Nonterminal {\n     /// Stuff inside brackets for attributes\n     NtMeta(P<ast::MetaItem>),\n     NtPath(Box<ast::Path>),\n-    NtTT(P<ast::TokenTree>), // needs P'ed to break a circularity\n+    NtTT(P<tokenstream::TokenTree>), // needs P'ed to break a circularity\n     // These are not exposed to macros, but are used by quasiquote.\n     NtArm(ast::Arm),\n     NtImplItem(P<ast::ImplItem>),"}, {"sha": "3f466f9e6426e61ad4f45d577ea42712d0f48973", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -11,7 +11,7 @@\n pub use self::AnnNode::*;\n \n use abi::{self, Abi};\n-use ast::{self, TokenTree, BlockCheckMode, PatKind};\n+use ast::{self, BlockCheckMode, PatKind};\n use ast::{SelfKind, RegionTyParamBound, TraitTyParamBound, TraitBoundModifier};\n use ast::Attribute;\n use attr::ThinAttributesExt;\n@@ -29,6 +29,7 @@ use print::pp::{Breaks, eof};\n use print::pp::Breaks::{Consistent, Inconsistent};\n use ptr::P;\n use std_inject;\n+use tokenstream::{self, TokenTree};\n \n use std::ascii;\n use std::io::{self, Write, Read};\n@@ -331,11 +332,11 @@ pub fn lifetime_to_string(e: &ast::Lifetime) -> String {\n     to_string(|s| s.print_lifetime(e))\n }\n \n-pub fn tt_to_string(tt: &ast::TokenTree) -> String {\n+pub fn tt_to_string(tt: &tokenstream::TokenTree) -> String {\n     to_string(|s| s.print_tt(tt))\n }\n \n-pub fn tts_to_string(tts: &[ast::TokenTree]) -> String {\n+pub fn tts_to_string(tts: &[tokenstream::TokenTree]) -> String {\n     to_string(|s| s.print_tts(tts))\n }\n \n@@ -1446,7 +1447,7 @@ impl<'a> State<'a> {\n     /// appropriate macro, transcribe back into the grammar we just parsed from,\n     /// and then pretty-print the resulting AST nodes (so, e.g., we print\n     /// expression arguments as expressions). It can be done! I think.\n-    pub fn print_tt(&mut self, tt: &ast::TokenTree) -> io::Result<()> {\n+    pub fn print_tt(&mut self, tt: &tokenstream::TokenTree) -> io::Result<()> {\n         match *tt {\n             TokenTree::Token(_, ref tk) => {\n                 try!(word(&mut self.s, &token_to_string(tk)));\n@@ -1477,14 +1478,14 @@ impl<'a> State<'a> {\n                     None => {},\n                 }\n                 match seq.op {\n-                    ast::KleeneOp::ZeroOrMore => word(&mut self.s, \"*\"),\n-                    ast::KleeneOp::OneOrMore => word(&mut self.s, \"+\"),\n+                    tokenstream::KleeneOp::ZeroOrMore => word(&mut self.s, \"*\"),\n+                    tokenstream::KleeneOp::OneOrMore => word(&mut self.s, \"+\"),\n                 }\n             }\n         }\n     }\n \n-    pub fn print_tts(&mut self, tts: &[ast::TokenTree]) -> io::Result<()> {\n+    pub fn print_tts(&mut self, tts: &[tokenstream::TokenTree]) -> io::Result<()> {\n         try!(self.ibox(0));\n         for (i, tt) in tts.iter().enumerate() {\n             if i != 0 {"}, {"sha": "b903537a7b7582b39a36c3f5816a1f09b631f155", "filename": "src/libsyntax/tokenstream.rs", "status": "added", "additions": 211, "deletions": 0, "changes": 211, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -0,0 +1,211 @@\n+// Copyright 2012-2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! # Token Trees\n+//! TokenTrees are syntactic forms for dealing with tokens. The description below is\n+//! more complete; in short a TokenTree is a single token, a delimited sequence of token\n+//! trees, or a sequence with repetition for list splicing as part of macro expansion.\n+\n+use ast::{AttrStyle};\n+use codemap::{Span};\n+use ext::base;\n+use ext::tt::macro_parser;\n+use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n+use parse::lexer;\n+use parse::token;\n+use std::rc::Rc;\n+\n+/// A delimited sequence of token trees\n+#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n+pub struct Delimited {\n+    /// The type of delimiter\n+    pub delim: token::DelimToken,\n+    /// The span covering the opening delimiter\n+    pub open_span: Span,\n+    /// The delimited sequence of token trees\n+    pub tts: Vec<TokenTree>,\n+    /// The span covering the closing delimiter\n+    pub close_span: Span,\n+}\n+\n+impl Delimited {\n+    /// Returns the opening delimiter as a token.\n+    pub fn open_token(&self) -> token::Token {\n+        token::OpenDelim(self.delim)\n+    }\n+\n+    /// Returns the closing delimiter as a token.\n+    pub fn close_token(&self) -> token::Token {\n+        token::CloseDelim(self.delim)\n+    }\n+\n+    /// Returns the opening delimiter as a token tree.\n+    pub fn open_tt(&self) -> TokenTree {\n+        TokenTree::Token(self.open_span, self.open_token())\n+    }\n+\n+    /// Returns the closing delimiter as a token tree.\n+    pub fn close_tt(&self) -> TokenTree {\n+        TokenTree::Token(self.close_span, self.close_token())\n+    }\n+}\n+\n+/// A sequence of token trees\n+#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n+pub struct SequenceRepetition {\n+    /// The sequence of token trees\n+    pub tts: Vec<TokenTree>,\n+    /// The optional separator\n+    pub separator: Option<token::Token>,\n+    /// Whether the sequence can be repeated zero (*), or one or more times (+)\n+    pub op: KleeneOp,\n+    /// The number of `MatchNt`s that appear in the sequence (and subsequences)\n+    pub num_captures: usize,\n+}\n+\n+/// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n+/// for token sequences.\n+#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n+pub enum KleeneOp {\n+    ZeroOrMore,\n+    OneOrMore,\n+}\n+\n+/// When the main rust parser encounters a syntax-extension invocation, it\n+/// parses the arguments to the invocation as a token-tree. This is a very\n+/// loose structure, such that all sorts of different AST-fragments can\n+/// be passed to syntax extensions using a uniform type.\n+///\n+/// If the syntax extension is an MBE macro, it will attempt to match its\n+/// LHS token tree against the provided token tree, and if it finds a\n+/// match, will transcribe the RHS token tree, splicing in any captured\n+/// macro_parser::matched_nonterminals into the `SubstNt`s it finds.\n+///\n+/// The RHS of an MBE macro is the only place `SubstNt`s are substituted.\n+/// Nothing special happens to misnamed or misplaced `SubstNt`s.\n+#[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug)]\n+pub enum TokenTree {\n+    /// A single token\n+    Token(Span, token::Token),\n+    /// A delimited sequence of token trees\n+    Delimited(Span, Rc<Delimited>),\n+\n+    // This only makes sense in MBE macros.\n+\n+    /// A kleene-style repetition sequence with a span\n+    // FIXME(eddyb) #12938 Use DST.\n+    Sequence(Span, Rc<SequenceRepetition>),\n+}\n+\n+impl TokenTree {\n+    pub fn len(&self) -> usize {\n+        match *self {\n+            TokenTree::Token(_, token::DocComment(name)) => {\n+                match doc_comment_style(&name.as_str()) {\n+                    AttrStyle::Outer => 2,\n+                    AttrStyle::Inner => 3\n+                }\n+            }\n+            TokenTree::Token(_, token::SpecialVarNt(..)) => 2,\n+            TokenTree::Token(_, token::MatchNt(..)) => 3,\n+            TokenTree::Delimited(_, ref delimed) => {\n+                delimed.tts.len() + 2\n+            }\n+            TokenTree::Sequence(_, ref seq) => {\n+                seq.tts.len()\n+            }\n+            TokenTree::Token(..) => 0\n+        }\n+    }\n+\n+    pub fn get_tt(&self, index: usize) -> TokenTree {\n+        match (self, index) {\n+            (&TokenTree::Token(sp, token::DocComment(_)), 0) => {\n+                TokenTree::Token(sp, token::Pound)\n+            }\n+            (&TokenTree::Token(sp, token::DocComment(name)), 1)\n+            if doc_comment_style(&name.as_str()) == AttrStyle::Inner => {\n+                TokenTree::Token(sp, token::Not)\n+            }\n+            (&TokenTree::Token(sp, token::DocComment(name)), _) => {\n+                let stripped = strip_doc_comment_decoration(&name.as_str());\n+\n+                // Searches for the occurrences of `\"#*` and returns the minimum number of `#`s\n+                // required to wrap the text.\n+                let num_of_hashes = stripped.chars().scan(0, |cnt, x| {\n+                    *cnt = if x == '\"' {\n+                        1\n+                    } else if *cnt != 0 && x == '#' {\n+                        *cnt + 1\n+                    } else {\n+                        0\n+                    };\n+                    Some(*cnt)\n+                }).max().unwrap_or(0);\n+\n+                TokenTree::Delimited(sp, Rc::new(Delimited {\n+                    delim: token::Bracket,\n+                    open_span: sp,\n+                    tts: vec![TokenTree::Token(sp, token::Ident(token::str_to_ident(\"doc\"))),\n+                              TokenTree::Token(sp, token::Eq),\n+                              TokenTree::Token(sp, token::Literal(\n+                                  token::StrRaw(token::intern(&stripped), num_of_hashes), None))],\n+                    close_span: sp,\n+                }))\n+            }\n+            (&TokenTree::Delimited(_, ref delimed), _) => {\n+                if index == 0 {\n+                    return delimed.open_tt();\n+                }\n+                if index == delimed.tts.len() + 1 {\n+                    return delimed.close_tt();\n+                }\n+                delimed.tts[index - 1].clone()\n+            }\n+            (&TokenTree::Token(sp, token::SpecialVarNt(var)), _) => {\n+                let v = [TokenTree::Token(sp, token::Dollar),\n+                         TokenTree::Token(sp, token::Ident(token::str_to_ident(var.as_str())))];\n+                v[index].clone()\n+            }\n+            (&TokenTree::Token(sp, token::MatchNt(name, kind)), _) => {\n+                let v = [TokenTree::Token(sp, token::SubstNt(name)),\n+                         TokenTree::Token(sp, token::Colon),\n+                         TokenTree::Token(sp, token::Ident(kind))];\n+                v[index].clone()\n+            }\n+            (&TokenTree::Sequence(_, ref seq), _) => {\n+                seq.tts[index].clone()\n+            }\n+            _ => panic!(\"Cannot expand a token tree\")\n+        }\n+    }\n+\n+    /// Returns the `Span` corresponding to this token tree.\n+    pub fn get_span(&self) -> Span {\n+        match *self {\n+            TokenTree::Token(span, _)     => span,\n+            TokenTree::Delimited(span, _) => span,\n+            TokenTree::Sequence(span, _)  => span,\n+        }\n+    }\n+\n+    /// Use this token tree as a matcher to parse given tts.\n+    pub fn parse(cx: &base::ExtCtxt, mtch: &[TokenTree], tts: &[TokenTree])\n+                 -> macro_parser::NamedParseResult {\n+        // `None` is because we're not interpolating\n+        let arg_rdr = lexer::new_tt_reader_with_doc_flag(&cx.parse_sess().span_diagnostic,\n+                                                         None,\n+                                                         None,\n+                                                         tts.iter().cloned().collect(),\n+                                                         true);\n+        macro_parser::parse(cx.parse_sess(), cx.cfg(), arg_rdr, mtch)\n+    }\n+}\n+"}, {"sha": "f59428bf536cfdd73e7e0196a9ddd5ef025c3493", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -14,10 +14,11 @@ use parse::{lexer, new_parser_from_source_str};\n use parse::parser::Parser;\n use parse::token;\n use ptr::P;\n+use tokenstream;\n use std::iter::Peekable;\n \n /// Map a string to tts, using a made-up filename:\n-pub fn string_to_tts(source_str: String) -> Vec<ast::TokenTree> {\n+pub fn string_to_tts(source_str: String) -> Vec<tokenstream::TokenTree> {\n     let ps = ParseSess::new();\n     filemap_to_tts(&ps, ps.codemap().new_filemap(\"bogofile\".to_string(), None, source_str))\n }"}, {"sha": "e9e72c040fe36c29c2f39e4a7dcd299235435036", "filename": "src/libsyntax_ext/asm.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fasm.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -23,6 +23,7 @@ use syntax::parse::{self, token};\n use syntax::ptr::P;\n use syntax::ast::AsmDialect;\n use syntax_pos::Span;\n+use syntax::tokenstream;\n \n enum State {\n     Asm,\n@@ -48,7 +49,7 @@ impl State {\n \n const OPTIONS: &'static [&'static str] = &[\"volatile\", \"alignstack\", \"intel\"];\n \n-pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                        -> Box<base::MacResult+'cx> {\n     if !cx.ecfg.enable_asm() {\n         feature_gate::emit_feature_err(\n@@ -62,8 +63,8 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     // parsed as `asm!(z)` with `z = \"x\": y` which is type ascription.\n     let first_colon = tts.iter().position(|tt| {\n         match *tt {\n-            ast::TokenTree::Token(_, token::Colon) |\n-            ast::TokenTree::Token(_, token::ModSep) => true,\n+            tokenstream::TokenTree::Token(_, token::Colon) |\n+            tokenstream::TokenTree::Token(_, token::ModSep) => true,\n             _ => false\n         }\n     }).unwrap_or(tts.len());"}, {"sha": "dbf23328f41fe3394a95359f95ab35283f57ecc0", "filename": "src/libsyntax_ext/cfg.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fcfg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fcfg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fcfg.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -12,17 +12,17 @@\n /// a literal `true` or `false` based on whether the given cfg matches the\n /// current compilation environment.\n \n-use syntax::ast;\n use syntax::ext::base::*;\n use syntax::ext::base;\n use syntax::ext::build::AstBuilder;\n use syntax::attr;\n+use syntax::tokenstream;\n use syntax::parse::token;\n use syntax_pos::Span;\n \n pub fn expand_cfg<'cx>(cx: &mut ExtCtxt,\n                        sp: Span,\n-                       tts: &[ast::TokenTree])\n+                       tts: &[tokenstream::TokenTree])\n                        -> Box<base::MacResult+'static> {\n     let mut p = cx.new_parser_from_tts(tts);\n     let cfg = panictry!(p.parse_meta_item());"}, {"sha": "22c4aeefbd169c03fa2fea10cd7144999faec45a", "filename": "src/libsyntax_ext/concat.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fconcat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fconcat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fconcat.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -13,12 +13,13 @@ use syntax::ext::base;\n use syntax::ext::build::AstBuilder;\n use syntax::parse::token;\n use syntax_pos;\n+use syntax::tokenstream;\n \n use std::string::String;\n \n pub fn expand_syntax_ext(cx: &mut base::ExtCtxt,\n                          sp: syntax_pos::Span,\n-                         tts: &[ast::TokenTree])\n+                         tts: &[tokenstream::TokenTree])\n                          -> Box<base::MacResult+'static> {\n     let es = match base::get_exprs_from_tts(cx, sp, tts) {\n         Some(e) => e,"}, {"sha": "2be32d33345a17cfd58015f50eceb76ac09807b4", "filename": "src/libsyntax_ext/concat_idents.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fconcat_idents.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -8,14 +8,15 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use syntax::ast::{self, TokenTree};\n+use syntax::ast;\n use syntax::ext::base::*;\n use syntax::ext::base;\n use syntax::feature_gate;\n use syntax::parse::token;\n use syntax::parse::token::str_to_ident;\n use syntax::ptr::P;\n use syntax_pos::Span;\n+use syntax::tokenstream::TokenTree;\n \n pub fn expand_syntax_ext<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[TokenTree])\n                               -> Box<base::MacResult+'cx> {"}, {"sha": "546f8eaa692863d8280f9cba0c8a1a35aff2e965", "filename": "src/libsyntax_ext/env.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fenv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fenv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fenv.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -20,10 +20,11 @@ use syntax::ext::base;\n use syntax::ext::build::AstBuilder;\n use syntax::parse::token;\n use syntax_pos::Span;\n+use syntax::tokenstream;\n \n use std::env;\n \n-pub fn expand_option_env<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_option_env<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                               -> Box<base::MacResult+'cx> {\n     let var = match get_single_str_from_tts(cx, sp, tts, \"option_env!\") {\n         None => return DummyResult::expr(sp),\n@@ -56,7 +57,7 @@ pub fn expand_option_env<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenT\n     MacEager::expr(e)\n }\n \n-pub fn expand_env<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+pub fn expand_env<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                        -> Box<base::MacResult+'cx> {\n     let mut exprs = match get_exprs_from_tts(cx, sp, tts) {\n         Some(ref exprs) if exprs.is_empty() => {"}, {"sha": "a14544521606adb392450ac8d2153ead9357027a", "filename": "src/libsyntax_ext/format.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fformat.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -22,6 +22,7 @@ use syntax::fold::Folder;\n use syntax::parse::token::{self, keywords};\n use syntax::ptr::P;\n use syntax_pos::{Span, DUMMY_SP};\n+use syntax::tokenstream;\n \n use std::collections::HashMap;\n \n@@ -81,7 +82,7 @@ struct Context<'a, 'b:'a> {\n /// Some((fmtstr, unnamed arguments, ordering of named arguments,\n ///       named arguments))\n /// ```\n-fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n+fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n               -> Option<(P<ast::Expr>, Vec<P<ast::Expr>>, Vec<String>,\n                          HashMap<String, P<ast::Expr>>)> {\n     let mut args = Vec::new();\n@@ -607,7 +608,7 @@ impl<'a, 'b> Context<'a, 'b> {\n }\n \n pub fn expand_format_args<'cx>(ecx: &'cx mut ExtCtxt, sp: Span,\n-                               tts: &[ast::TokenTree])\n+                               tts: &[tokenstream::TokenTree])\n                                -> Box<base::MacResult+'cx> {\n \n     match parse_args(ecx, sp, tts) {"}, {"sha": "9645c5bb42723dbdc43831a5fec0ef321ee3e83c", "filename": "src/libsyntax_ext/log_syntax.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Flog_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Flog_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Flog_syntax.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -8,15 +8,15 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use syntax::ast;\n use syntax::ext::base;\n use syntax::feature_gate;\n use syntax::print;\n+use syntax::tokenstream;\n use syntax_pos;\n \n pub fn expand_syntax_ext<'cx>(cx: &'cx mut base::ExtCtxt,\n                               sp: syntax_pos::Span,\n-                              tts: &[ast::TokenTree])\n+                              tts: &[tokenstream::TokenTree])\n                               -> Box<base::MacResult+'cx> {\n     if !cx.ecfg.enable_log_syntax() {\n         feature_gate::emit_feature_err(&cx.parse_sess.span_diagnostic,"}, {"sha": "ad396d38de9f56b7a2470a9bd6be91c760919187", "filename": "src/libsyntax_ext/trace_macros.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Flibsyntax_ext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Ftrace_macros.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -8,12 +8,12 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use syntax::ast::TokenTree;\n use syntax::ext::base::ExtCtxt;\n use syntax::ext::base;\n use syntax::feature_gate;\n use syntax::parse::token::keywords;\n use syntax_pos::Span;\n+use syntax::tokenstream::TokenTree;\n \n pub fn expand_trace_macros(cx: &mut ExtCtxt,\n                            sp: Span,"}, {"sha": "a6bc9db199c8be156ec2c2f49ce470b93a720e15", "filename": "src/test/compile-fail-fulldeps/auxiliary/macro_crate_test.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Fcompile-fail-fulldeps%2Fauxiliary%2Fmacro_crate_test.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Fcompile-fail-fulldeps%2Fauxiliary%2Fmacro_crate_test.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail-fulldeps%2Fauxiliary%2Fmacro_crate_test.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -17,10 +17,11 @@ extern crate syntax_pos;\n extern crate rustc;\n extern crate rustc_plugin;\n \n-use syntax::ast::{self, TokenTree, Item, MetaItem, ImplItem, TraitItem, ItemKind};\n+use syntax::ast::{self, Item, MetaItem, ImplItem, TraitItem, ItemKind};\n use syntax::ext::base::*;\n use syntax::parse::{self, token};\n use syntax::ptr::P;\n+use syntax::tokenstream::TokenTree;\n use syntax_pos::Span;\n use rustc_plugin::Registry;\n "}, {"sha": "7f8a741465b30598b32e32b73592c94a8720ab1c", "filename": "src/test/run-pass-fulldeps/auxiliary/issue_16723_multiple_items_syntax_ext.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fissue_16723_multiple_items_syntax_ext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fissue_16723_multiple_items_syntax_ext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fissue_16723_multiple_items_syntax_ext.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -21,14 +21,16 @@ extern crate syntax_pos;\n use syntax::ast;\n use syntax::ext::base::{ExtCtxt, MacResult, MacEager};\n use syntax::util::small_vector::SmallVector;\n+use syntax::tokenstream;\n use rustc_plugin::Registry;\n \n #[plugin_registrar]\n pub fn plugin_registrar(reg: &mut Registry) {\n     reg.register_macro(\"multiple_items\", expand)\n }\n \n-fn expand(cx: &mut ExtCtxt, _: syntax_pos::Span, _: &[ast::TokenTree]) -> Box<MacResult+'static> {\n+fn expand(cx: &mut ExtCtxt, _: syntax_pos::Span, _: &[tokenstream::TokenTree])\n+          -> Box<MacResult+'static> {\n     MacEager::items(SmallVector::many(vec![\n         quote_item!(cx, struct Struct1;).unwrap(),\n         quote_item!(cx, struct Struct2;).unwrap()"}, {"sha": "11d81eda55625960ae69fcca3483de8072e7de35", "filename": "src/test/run-pass-fulldeps/auxiliary/macro_crate_test.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fmacro_crate_test.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fmacro_crate_test.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fmacro_crate_test.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -17,10 +17,11 @@ extern crate rustc;\n extern crate rustc_plugin;\n extern crate syntax_pos;\n \n-use syntax::ast::{self, TokenTree, Item, MetaItem, ImplItem, TraitItem, ItemKind};\n+use syntax::ast::{self, Item, MetaItem, ImplItem, TraitItem, ItemKind};\n use syntax::ext::base::*;\n use syntax::parse::{self, token};\n use syntax::ptr::P;\n+use syntax::tokenstream::TokenTree;\n use syntax_pos::Span;\n use rustc_plugin::Registry;\n "}, {"sha": "f0edc0f2b120f887dde338ce2b9ae1774a1c4f9a", "filename": "src/test/run-pass-fulldeps/auxiliary/plugin_args.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fplugin_args.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fplugin_args.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fplugin_args.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -26,6 +26,7 @@ use syntax::parse::token;\n use syntax::print::pprust;\n use syntax::ptr::P;\n use syntax_pos::Span;\n+use syntax::tokenstream;\n use rustc_plugin::Registry;\n \n struct Expander {\n@@ -36,7 +37,7 @@ impl TTMacroExpander for Expander {\n     fn expand<'cx>(&self,\n                    ecx: &'cx mut ExtCtxt,\n                    sp: Span,\n-                   _: &[ast::TokenTree]) -> Box<MacResult+'cx> {\n+                   _: &[tokenstream::TokenTree]) -> Box<MacResult+'cx> {\n         let args = self.args.iter().map(|i| pprust::meta_item_to_string(&*i))\n             .collect::<Vec<_>>().join(\", \");\n         let interned = token::intern_and_get_ident(&args[..]);"}, {"sha": "5b1e210b0b2586b9449b341868910557cc1dbdb7", "filename": "src/test/run-pass-fulldeps/auxiliary/procedural_mbe_matching.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -19,7 +19,8 @@ extern crate rustc;\n extern crate rustc_plugin;\n \n use syntax::parse::token::{self, str_to_ident, NtExpr, NtPat};\n-use syntax::ast::{TokenTree, Pat};\n+use syntax::ast::{Pat};\n+use syntax::tokenstream::{TokenTree};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n use syntax::ext::build::AstBuilder;\n use syntax::ext::tt::macro_parser::{MatchedSeq, MatchedNonterminal};"}, {"sha": "0c8af013fd12d2ed69c467285ff233fa7f492415", "filename": "src/test/run-pass-fulldeps/auxiliary/roman_numerals.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Froman_numerals.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -19,8 +19,8 @@ extern crate syntax_pos;\n extern crate rustc;\n extern crate rustc_plugin;\n \n-use syntax::ast::TokenTree;\n use syntax::parse::token;\n+use syntax::tokenstream::TokenTree;\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n use syntax::ext::build::AstBuilder;  // trait for expr_usize\n use syntax_pos::Span;"}, {"sha": "72d262853555698199c17c2a9ce4d16bfd0b24c4", "filename": "src/test/run-pass-fulldeps/auxiliary/syntax_extension_with_dll_deps_2.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fsyntax_extension_with_dll_deps_2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fsyntax_extension_with_dll_deps_2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fsyntax_extension_with_dll_deps_2.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -19,8 +19,9 @@ extern crate syntax_pos;\n extern crate rustc;\n extern crate rustc_plugin;\n \n-use syntax::ast::{TokenTree, Item, MetaItem};\n+use syntax::ast::{Item, MetaItem};\n use syntax::ext::base::*;\n+use syntax::tokenstream::TokenTree;\n use syntax_pos::Span;\n use rustc_plugin::Registry;\n "}, {"sha": "710e2fd1d07a38ab3b7c36c0f03064ec514de4e9", "filename": "src/test/run-pass-fulldeps/quote-tokens.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fquote-tokens.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82a15a6a0af724e71004c735f8a99ec5f2a03920/src%2Ftest%2Frun-pass-fulldeps%2Fquote-tokens.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fquote-tokens.rs?ref=82a15a6a0af724e71004c735f8a99ec5f2a03920", "patch": "@@ -20,8 +20,8 @@ use syntax::ptr::P;\n use syntax::parse::PResult;\n \n fn syntax_extension(cx: &ExtCtxt) {\n-    let e_toks : Vec<syntax::ast::TokenTree> = quote_tokens!(cx, 1 + 2);\n-    let p_toks : Vec<syntax::ast::TokenTree> = quote_tokens!(cx, (x, 1 .. 4, *));\n+    let e_toks : Vec<syntax::tokenstream::TokenTree> = quote_tokens!(cx, 1 + 2);\n+    let p_toks : Vec<syntax::tokenstream::TokenTree> = quote_tokens!(cx, (x, 1 .. 4, *));\n \n     let a: P<syntax::ast::Expr> = quote_expr!(cx, 1 + 2);\n     let _b: Option<P<syntax::ast::Item>> = quote_item!(cx, static foo : isize = $e_toks; );\n@@ -39,7 +39,7 @@ fn syntax_extension(cx: &ExtCtxt) {\n \n     let _l: P<syntax::ast::Ty> = quote_ty!(cx, &isize);\n \n-    let _m: Vec<syntax::ast::TokenTree> = quote_matcher!(cx, $($foo:tt,)* bar);\n+    let _m: Vec<syntax::tokenstream::TokenTree> = quote_matcher!(cx, $($foo:tt,)* bar);\n     let _n: syntax::ast::Attribute = quote_attr!(cx, #![cfg(foo, bar = \"baz\")]);\n \n     let _o: Option<P<syntax::ast::Item>> = quote_item!(cx, fn foo<T: ?Sized>() {});"}]}