{"sha": "891ca5f63c3b3cfe3939710a728671243e881ed6", "node_id": "C_kwDOAAsO6NoAKDg5MWNhNWY2M2MzYjNjZmUzOTM5NzEwYTcyODY3MTI0M2U4ODFlZDY", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-11-15T20:19:23Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-11-15T20:19:23Z"}, "message": "Auto merge of #90821 - scottmcm:new-slice-reverse, r=Mark-Simulacrum\n\nMIRI says `reverse` is UB, so replace it with something LLVM can vectorize\n\nFor small types with padding, the current implementation is UB because it does integer operations on uninit values.\n```\nerror: Undefined Behavior: using uninitialized data, but this operation requires initialized memory\n   --> /playground/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/num/mod.rs:836:5\n    |\n836 | /     uint_impl! { u32, u32, i32, 32, 4294967295, 8, \"0x10000b3\", \"0xb301\", \"0x12345678\",\n837 | |     \"0x78563412\", \"0x1e6a2c48\", \"[0x78, 0x56, 0x34, 0x12]\", \"[0x12, 0x34, 0x56, 0x78]\", \"\", \"\" }\n    | |________________________________________________________________________________________________^ using uninitialized data, but this operation requires initialized memory\n    |\n    = help: this indicates a bug in the program: it performed an invalid operation, and caused Undefined Behavior\n    = help: see https://doc.rust-lang.org/nightly/reference/behavior-considered-undefined.html for further information\n\n    = note: inside `core::num::<impl u32>::rotate_left` at /playground/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/num/uint_macros.rs:211:13\n    = note: inside `core::slice::<impl [Foo]>::reverse` at /playground/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/mod.rs:701:58\n```\n<https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=340739f22ca5b457e1da6f361768edc6>\n\nBut LLVM has gotten smarter since I wrote the previous implementation in 2017, so this PR removes all the manual magic and just writes it in such a way that LLVM will vectorize.  This code is much simpler and has very little `unsafe`, and is actually faster to boot!\n\nIf you're curious to see the codegen: <https://rust.godbolt.org/z/Pcn13Y9E3>\n\nBefore:\n```\nrunning 7 tests\ntest slice::reverse_simd_f64x4                           ... bench:      17,940 ns/iter (+/- 481) = 58448 MB/s\ntest slice::reverse_u128                                 ... bench:      17,758 ns/iter (+/- 205) = 59048 MB/s\ntest slice::reverse_u16                                  ... bench:     158,234 ns/iter (+/- 6,876) = 6626 MB/s\ntest slice::reverse_u32                                  ... bench:      62,047 ns/iter (+/- 1,117) = 16899 MB/s\ntest slice::reverse_u64                                  ... bench:      31,582 ns/iter (+/- 552) = 33201 MB/s\ntest slice::reverse_u8                                   ... bench:      81,253 ns/iter (+/- 1,510) = 12905 MB/s\ntest slice::reverse_u8x3                                 ... bench:     270,615 ns/iter (+/- 11,463) = 3874 MB/s\n```\n\nAfter:\n```\nrunning 7 tests\ntest slice::reverse_simd_f64x4                           ... bench:      17,731 ns/iter (+/- 306) = 59137 MB/s\ntest slice::reverse_u128                                 ... bench:      17,919 ns/iter (+/- 239) = 58517 MB/s\ntest slice::reverse_u16                                  ... bench:      43,160 ns/iter (+/- 607) = 24295 MB/s\ntest slice::reverse_u32                                  ... bench:      21,065 ns/iter (+/- 371) = 49778 MB/s\ntest slice::reverse_u64                                  ... bench:      21,118 ns/iter (+/- 482) = 49653 MB/s\ntest slice::reverse_u8                                   ... bench:      76,878 ns/iter (+/- 1,688) = 13639 MB/s\ntest slice::reverse_u8x3                                 ... bench:     264,723 ns/iter (+/- 5,544) = 3961 MB/s\n```\n\nThose are the existing benches, <https://github.com/rust-lang/rust/blob/14a2fd640e0df9ee8cc1e04280b0c3aff93c42da/library/alloc/benches/slice.rs#L322-L346>", "tree": {"sha": "a8b746f2f3a0b5b9c9d37939d372dead47432c3e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a8b746f2f3a0b5b9c9d37939d372dead47432c3e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/891ca5f63c3b3cfe3939710a728671243e881ed6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/891ca5f63c3b3cfe3939710a728671243e881ed6", "html_url": "https://github.com/rust-lang/rust/commit/891ca5f63c3b3cfe3939710a728671243e881ed6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/891ca5f63c3b3cfe3939710a728671243e881ed6/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c26746af5a925bad66b7ed4f9e7c3018f00d4010", "url": "https://api.github.com/repos/rust-lang/rust/commits/c26746af5a925bad66b7ed4f9e7c3018f00d4010", "html_url": "https://github.com/rust-lang/rust/commit/c26746af5a925bad66b7ed4f9e7c3018f00d4010"}, {"sha": "f541dd13f17fd41800c65019e7d133a0a8e63370", "url": "https://api.github.com/repos/rust-lang/rust/commits/f541dd13f17fd41800c65019e7d133a0a8e63370", "html_url": "https://github.com/rust-lang/rust/commit/f541dd13f17fd41800c65019e7d133a0a8e63370"}], "stats": {"total": 150, "additions": 59, "deletions": 91}, "files": [{"sha": "34754cffae12a4cd94be76d771f3de48d6071295", "filename": "library/core/src/slice/mod.rs", "status": "modified", "additions": 32, "deletions": 91, "changes": 123, "blob_url": "https://github.com/rust-lang/rust/blob/891ca5f63c3b3cfe3939710a728671243e881ed6/library%2Fcore%2Fsrc%2Fslice%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/891ca5f63c3b3cfe3939710a728671243e881ed6/library%2Fcore%2Fsrc%2Fslice%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fcore%2Fsrc%2Fslice%2Fmod.rs?ref=891ca5f63c3b3cfe3939710a728671243e881ed6", "patch": "@@ -623,100 +623,41 @@ impl<T> [T] {\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     #[inline]\n     pub fn reverse(&mut self) {\n-        let mut i: usize = 0;\n-        let ln = self.len();\n-\n-        // For very small types, all the individual reads in the normal\n-        // path perform poorly.  We can do better, given efficient unaligned\n-        // load/store, by loading a larger chunk and reversing a register.\n-\n-        // Ideally LLVM would do this for us, as it knows better than we do\n-        // whether unaligned reads are efficient (since that changes between\n-        // different ARM versions, for example) and what the best chunk size\n-        // would be.  Unfortunately, as of LLVM 4.0 (2017-05) it only unrolls\n-        // the loop, so we need to do this ourselves.  (Hypothesis: reverse\n-        // is troublesome because the sides can be aligned differently --\n-        // will be, when the length is odd -- so there's no way of emitting\n-        // pre- and postludes to use fully-aligned SIMD in the middle.)\n-\n-        let fast_unaligned = cfg!(any(target_arch = \"x86\", target_arch = \"x86_64\"));\n-\n-        if fast_unaligned && mem::size_of::<T>() == 1 {\n-            // Use the llvm.bswap intrinsic to reverse u8s in a usize\n-            let chunk = mem::size_of::<usize>();\n-            while i + chunk - 1 < ln / 2 {\n-                // SAFETY: There are several things to check here:\n-                //\n-                // - Note that `chunk` is either 4 or 8 due to the cfg check\n-                //   above. So `chunk - 1` is positive.\n-                // - Indexing with index `i` is fine as the loop check guarantees\n-                //   `i + chunk - 1 < ln / 2`\n-                //   <=> `i < ln / 2 - (chunk - 1) < ln / 2 < ln`.\n-                // - Indexing with index `ln - i - chunk = ln - (i + chunk)` is fine:\n-                //   - `i + chunk > 0` is trivially true.\n-                //   - The loop check guarantees:\n-                //     `i + chunk - 1 < ln / 2`\n-                //     <=> `i + chunk \u2264 ln / 2 \u2264 ln`, thus subtraction does not underflow.\n-                // - The `read_unaligned` and `write_unaligned` calls are fine:\n-                //   - `pa` points to index `i` where `i < ln / 2 - (chunk - 1)`\n-                //     (see above) and `pb` points to index `ln - i - chunk`, so\n-                //     both are at least `chunk`\n-                //     many bytes away from the end of `self`.\n-                //   - Any initialized memory is valid `usize`.\n-                unsafe {\n-                    let ptr = self.as_mut_ptr();\n-                    let pa = ptr.add(i);\n-                    let pb = ptr.add(ln - i - chunk);\n-                    let va = ptr::read_unaligned(pa as *mut usize);\n-                    let vb = ptr::read_unaligned(pb as *mut usize);\n-                    ptr::write_unaligned(pa as *mut usize, vb.swap_bytes());\n-                    ptr::write_unaligned(pb as *mut usize, va.swap_bytes());\n-                }\n-                i += chunk;\n-            }\n-        }\n+        let half_len = self.len() / 2;\n+        let Range { start, end } = self.as_mut_ptr_range();\n+\n+        // These slices will skip the middle item for an odd length,\n+        // since that one doesn't need to move.\n+        let (front_half, back_half) =\n+            // SAFETY: Both are subparts of the original slice, so the memory\n+            // range is valid, and they don't overlap because they're each only\n+            // half (or less) of the original slice.\n+            unsafe {\n+                (\n+                    slice::from_raw_parts_mut(start, half_len),\n+                    slice::from_raw_parts_mut(end.sub(half_len), half_len),\n+                )\n+            };\n \n-        if fast_unaligned && mem::size_of::<T>() == 2 {\n-            // Use rotate-by-16 to reverse u16s in a u32\n-            let chunk = mem::size_of::<u32>() / 2;\n-            while i + chunk - 1 < ln / 2 {\n-                // SAFETY: An unaligned u32 can be read from `i` if `i + 1 < ln`\n-                // (and obviously `i < ln`), because each element is 2 bytes and\n-                // we're reading 4.\n-                //\n-                // `i + chunk - 1 < ln / 2` # while condition\n-                // `i + 2 - 1 < ln / 2`\n-                // `i + 1 < ln / 2`\n-                //\n-                // Since it's less than the length divided by 2, then it must be\n-                // in bounds.\n-                //\n-                // This also means that the condition `0 < i + chunk <= ln` is\n-                // always respected, ensuring the `pb` pointer can be used\n-                // safely.\n-                unsafe {\n-                    let ptr = self.as_mut_ptr();\n-                    let pa = ptr.add(i);\n-                    let pb = ptr.add(ln - i - chunk);\n-                    let va = ptr::read_unaligned(pa as *mut u32);\n-                    let vb = ptr::read_unaligned(pb as *mut u32);\n-                    ptr::write_unaligned(pa as *mut u32, vb.rotate_left(16));\n-                    ptr::write_unaligned(pb as *mut u32, va.rotate_left(16));\n-                }\n-                i += chunk;\n-            }\n-        }\n+        // Introducing a function boundary here means that the two halves\n+        // get `noalias` markers, allowing better optimization as LLVM\n+        // knows that they're disjoint, unlike in the original slice.\n+        revswap(front_half, back_half, half_len);\n \n-        while i < ln / 2 {\n-            // SAFETY: `i` is inferior to half the length of the slice so\n-            // accessing `i` and `ln - i - 1` is safe (`i` starts at 0 and\n-            // will not go further than `ln / 2 - 1`).\n-            // The resulting pointers `pa` and `pb` are therefore valid and\n-            // aligned, and can be read from and written to.\n-            unsafe {\n-                self.swap_unchecked(i, ln - i - 1);\n+        #[inline]\n+        fn revswap<T>(a: &mut [T], b: &mut [T], n: usize) {\n+            debug_assert_eq!(a.len(), n);\n+            debug_assert_eq!(b.len(), n);\n+\n+            // Because this function is first compiled in isolation,\n+            // this check tells LLVM that the indexing below is\n+            // in-bounds.  Then after inlining -- once the actual\n+            // lengths of the slices are known -- it's removed.\n+            let (a, b) = (&mut a[..n], &mut b[..n]);\n+\n+            for i in 0..n {\n+                mem::swap(&mut a[i], &mut b[n - 1 - i]);\n             }\n-            i += 1;\n         }\n     }\n "}, {"sha": "e50b22f3ac400234859ee2cc461f723c5ba8eab1", "filename": "src/test/codegen/slice-reverse.rs", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/891ca5f63c3b3cfe3939710a728671243e881ed6/src%2Ftest%2Fcodegen%2Fslice-reverse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/891ca5f63c3b3cfe3939710a728671243e881ed6/src%2Ftest%2Fcodegen%2Fslice-reverse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcodegen%2Fslice-reverse.rs?ref=891ca5f63c3b3cfe3939710a728671243e881ed6", "patch": "@@ -0,0 +1,27 @@\n+// compile-flags: -O\n+// only-x86_64\n+// ignore-debug: the debug assertions in from_raw_parts get in the way\n+\n+#![crate_type = \"lib\"]\n+\n+// CHECK-LABEL: @slice_reverse_u8\n+#[no_mangle]\n+pub fn slice_reverse_u8(slice: &mut [u8]) {\n+    // CHECK-NOT: panic_bounds_check\n+    // CHECK-NOT: slice_end_index_len_fail\n+    // CHECK: shufflevector <{{[0-9]+}} x i8>\n+    // CHECK-NOT: panic_bounds_check\n+    // CHECK-NOT: slice_end_index_len_fail\n+    slice.reverse();\n+}\n+\n+// CHECK-LABEL: @slice_reverse_i32\n+#[no_mangle]\n+pub fn slice_reverse_i32(slice: &mut [i32]) {\n+    // CHECK-NOT: panic_bounds_check\n+    // CHECK-NOT: slice_end_index_len_fail\n+    // CHECK: shufflevector <{{[0-9]+}} x i32>\n+    // CHECK-NOT: panic_bounds_check\n+    // CHECK-NOT: slice_end_index_len_fail\n+    slice.reverse();\n+}"}]}