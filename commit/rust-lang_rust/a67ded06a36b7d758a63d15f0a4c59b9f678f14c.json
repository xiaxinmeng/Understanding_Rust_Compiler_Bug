{"sha": "a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE2N2RlZDA2YTM2YjdkNzU4YTYzZDE1ZjBhNGM1OWI5ZjY3OGYxNGM=", "commit": {"author": {"name": "Oliver Schneider", "email": "git-no-reply-9879165716479413131@oli-obk.de", "date": "2018-04-10T07:58:46Z"}, "committer": {"name": "Oliver Schneider", "email": "git-no-reply-9879165716479413131@oli-obk.de", "date": "2018-04-14T10:21:46Z"}, "message": "Don't recurse into allocations, use a global table instead", "tree": {"sha": "e01497bc3332aeda852eb564e8fefb2fd1e77bf3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e01497bc3332aeda852eb564e8fefb2fd1e77bf3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQJgBAABCgBKFiEEvpMjxK4/cnPNfesJHVy0/Fl8MAQFAlrR1josHGdpdC1uby1y\nZXBseS05ODc5MTY1NzE2NDc5NDEzMTMxQG9saS1vYmsuZGUACgkQHVy0/Fl8MAQL\n5g/+NPvdG6qofmwFKkVYTiqk1gjhzBR7yzfyy45nPT9Ey2Ww5FDA8y3Lcku6iiwm\nPeghWB7sxwLVLFpWpvIqmVm1rwStU42PI97okl7icF9+GxIr3uZ1o4zqFvpx1AnA\nPUR5dMQpTSKUJ0p0aCLa1WIj7B2KiCQYqkqjPCoBwqlxlGl/DzWvV2q+PGUWtOj9\nglbz3o3juQnG7immlkvjwnrkdDH45Q2xNIa9fVhgS8xriUk8tt8MexdaKhfx9G/R\npqb1snWCg7YT1WV4eALp3hF+72je693EVZaj9PnmyO/QOKYY9uA0U1M0WyKbGiWU\nkAQKKgLX9sdRGgToFWN2Geo4LVCobuGPa0U6z2sIvYciz3/b9wjYy6g8GP0LN8ze\nhJd3g8QUvIqBnYAdskhrLNuO+/rq618OMaQ176mdtELdSdco3AMi7NqkfGHou7ov\nMkv2AtS3L8krpO7qAyAb83iwnWERDOeJx8rXvBJ7IWlDrHRPzT0Vd6FZIAGFsHBd\nU39uYjtEhjWjtrY1hnKv+JzuJskS/JpDgejg7PDuhgN8qWnUvxpO/L1MdGEkEFSl\nhxsOggdg8kE/fYws3LWjgyq75+NanOXi7INFDDgBfDgqNQIwG2cODVCxc8L2nXgq\nu12NR4I9xIJL/V554VM4amZXV56idd+7/nO2swTs5nOfWPI=\n=lR9b\n-----END PGP SIGNATURE-----", "payload": "tree e01497bc3332aeda852eb564e8fefb2fd1e77bf3\nparent fb730d75d4c1c05c90419841758300b6fbf01250\nauthor Oliver Schneider <git-no-reply-9879165716479413131@oli-obk.de> 1523347126 +0200\ncommitter Oliver Schneider <git-no-reply-9879165716479413131@oli-obk.de> 1523701306 +0200\n\nDon't recurse into allocations, use a global table instead\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "html_url": "https://github.com/rust-lang/rust/commit/a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/comments", "author": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "committer": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fb730d75d4c1c05c90419841758300b6fbf01250", "url": "https://api.github.com/repos/rust-lang/rust/commits/fb730d75d4c1c05c90419841758300b6fbf01250", "html_url": "https://github.com/rust-lang/rust/commit/fb730d75d4c1c05c90419841758300b6fbf01250"}], "stats": {"total": 344, "additions": 192, "deletions": 152}, "files": [{"sha": "2425fef7e7f534972b809343e4fafb64ffa4427f", "filename": "src/librustc/ich/impls_ty.rs", "status": "modified", "additions": 13, "deletions": 11, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc%2Fich%2Fimpls_ty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc%2Fich%2Fimpls_ty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_ty.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -398,12 +398,12 @@ impl_stable_hash_for!(struct mir::interpret::MemoryPointer {\n \n enum AllocDiscriminant {\n     Alloc,\n-    ExternStatic,\n+    Static,\n     Function,\n }\n impl_stable_hash_for!(enum self::AllocDiscriminant {\n     Alloc,\n-    ExternStatic,\n+    Static,\n     Function\n });\n \n@@ -414,24 +414,26 @@ impl<'a> HashStable<StableHashingContext<'a>> for mir::interpret::AllocId {\n         hasher: &mut StableHasher<W>,\n     ) {\n         ty::tls::with_opt(|tcx| {\n+            trace!(\"hashing {:?}\", *self);\n             let tcx = tcx.expect(\"can't hash AllocIds during hir lowering\");\n-            if let Some(alloc) = tcx.interpret_interner.get_alloc(*self) {\n+            if let Some(def_id) = tcx.interpret_interner\n+                                     .get_corresponding_static_def_id(*self) {\n+                AllocDiscriminant::Static.hash_stable(hcx, hasher);\n+                trace!(\"hashing {:?} as static {:?}\", *self, def_id);\n+                def_id.hash_stable(hcx, hasher);\n+            } else if let Some(alloc) = tcx.interpret_interner.get_alloc(*self) {\n                 AllocDiscriminant::Alloc.hash_stable(hcx, hasher);\n                 if hcx.alloc_id_recursion_tracker.insert(*self) {\n-                    tcx\n-                        .interpret_interner\n-                        .get_corresponding_static_def_id(*self)\n-                        .hash_stable(hcx, hasher);\n+                    trace!(\"hashing {:?} as alloc {:#?}\", *self, alloc);\n                     alloc.hash_stable(hcx, hasher);\n                     assert!(hcx.alloc_id_recursion_tracker.remove(self));\n+                } else {\n+                    trace!(\"skipping hashing of {:?} due to recursion\", *self);\n                 }\n             } else if let Some(inst) = tcx.interpret_interner.get_fn(*self) {\n+                trace!(\"hashing {:?} as fn {:#?}\", *self, inst);\n                 AllocDiscriminant::Function.hash_stable(hcx, hasher);\n                 inst.hash_stable(hcx, hasher);\n-            } else if let Some(def_id) = tcx.interpret_interner\n-                                            .get_corresponding_static_def_id(*self) {\n-                AllocDiscriminant::ExternStatic.hash_stable(hcx, hasher);\n-                def_id.hash_stable(hcx, hasher);\n             } else {\n                 bug!(\"no allocation for {}\", self);\n             }"}, {"sha": "9003cca815ee3d45538ee591f66a0f8495b50660", "filename": "src/librustc/mir/interpret/mod.rs", "status": "modified", "additions": 20, "deletions": 28, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -154,10 +154,12 @@ pub struct AllocId(pub u64);\n impl ::rustc_serialize::UseSpecializedEncodable for AllocId {}\n impl ::rustc_serialize::UseSpecializedDecodable for AllocId {}\n \n-pub const ALLOC_DISCRIMINANT: usize = 0;\n-pub const FN_DISCRIMINANT: usize = 1;\n-pub const EXTERN_STATIC_DISCRIMINANT: usize = 2;\n-pub const SHORTHAND_START: usize = 3;\n+#[derive(RustcDecodable, RustcEncodable)]\n+enum AllocKind {\n+    Alloc,\n+    Fn,\n+    ExternStatic,\n+}\n \n pub fn specialized_encode_alloc_id<\n     'a, 'tcx,\n@@ -166,26 +168,22 @@ pub fn specialized_encode_alloc_id<\n     encoder: &mut E,\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     alloc_id: AllocId,\n-    shorthand: Option<usize>,\n ) -> Result<(), E::Error> {\n-    if let Some(shorthand) = shorthand {\n-        return shorthand.encode(encoder);\n-    }\n     if let Some(alloc) = tcx.interpret_interner.get_alloc(alloc_id) {\n         trace!(\"encoding {:?} with {:#?}\", alloc_id, alloc);\n-        ALLOC_DISCRIMINANT.encode(encoder)?;\n+        AllocKind::Alloc.encode(encoder)?;\n         alloc.encode(encoder)?;\n         // encode whether this allocation is the root allocation of a static\n         tcx.interpret_interner\n             .get_corresponding_static_def_id(alloc_id)\n             .encode(encoder)?;\n     } else if let Some(fn_instance) = tcx.interpret_interner.get_fn(alloc_id) {\n         trace!(\"encoding {:?} with {:#?}\", alloc_id, fn_instance);\n-        FN_DISCRIMINANT.encode(encoder)?;\n+        AllocKind::Fn.encode(encoder)?;\n         fn_instance.encode(encoder)?;\n     } else if let Some(did) = tcx.interpret_interner.get_corresponding_static_def_id(alloc_id) {\n         // extern \"C\" statics don't have allocations, just encode its def_id\n-        EXTERN_STATIC_DISCRIMINANT.encode(encoder)?;\n+        AllocKind::ExternStatic.encode(encoder)?;\n         did.encode(encoder)?;\n     } else {\n         bug!(\"alloc id without corresponding allocation: {}\", alloc_id);\n@@ -196,21 +194,18 @@ pub fn specialized_encode_alloc_id<\n pub fn specialized_decode_alloc_id<\n     'a, 'tcx,\n     D: Decoder,\n-    CACHE: FnOnce(&mut D, usize, AllocId),\n-    SHORT: FnOnce(&mut D, usize) -> Result<AllocId, D::Error>\n+    CACHE: FnOnce(&mut D, AllocId),\n >(\n     decoder: &mut D,\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    pos: usize,\n     cache: CACHE,\n-    short: SHORT,\n ) -> Result<AllocId, D::Error> {\n-    match usize::decode(decoder)? {\n-        ALLOC_DISCRIMINANT => {\n+    match AllocKind::decode(decoder)? {\n+        AllocKind::Alloc => {\n             let alloc_id = tcx.interpret_interner.reserve();\n-            trace!(\"creating alloc id {:?} at {}\", alloc_id, pos);\n+            trace!(\"creating alloc id {:?}\", alloc_id);\n             // insert early to allow recursive allocs\n-            cache(decoder, pos, alloc_id);\n+            cache(decoder, alloc_id);\n \n             let allocation = Allocation::decode(decoder)?;\n             trace!(\"decoded alloc {:?} {:#?}\", alloc_id, allocation);\n@@ -223,26 +218,23 @@ pub fn specialized_decode_alloc_id<\n \n             Ok(alloc_id)\n         },\n-        FN_DISCRIMINANT => {\n-            trace!(\"creating fn alloc id at {}\", pos);\n+        AllocKind::Fn => {\n+            trace!(\"creating fn alloc id\");\n             let instance = ty::Instance::decode(decoder)?;\n             trace!(\"decoded fn alloc instance: {:?}\", instance);\n             let id = tcx.interpret_interner.create_fn_alloc(instance);\n             trace!(\"created fn alloc id: {:?}\", id);\n-            cache(decoder, pos, id);\n+            cache(decoder, id);\n             Ok(id)\n         },\n-        EXTERN_STATIC_DISCRIMINANT => {\n-            trace!(\"creating extern static alloc id at {}\", pos);\n+        AllocKind::ExternStatic => {\n+            trace!(\"creating extern static alloc id at\");\n             let did = DefId::decode(decoder)?;\n             let alloc_id = tcx.interpret_interner.reserve();\n+            cache(decoder, alloc_id);\n             tcx.interpret_interner.cache(did, alloc_id);\n             Ok(alloc_id)\n         },\n-        shorthand => {\n-            trace!(\"loading shorthand {}\", shorthand);\n-            short(decoder, shorthand)\n-        },\n     }\n }\n "}, {"sha": "62f2cd88935d367b75f3ff89c06d693607ad1801", "filename": "src/librustc/ty/maps/on_disk_cache.rs", "status": "modified", "additions": 75, "deletions": 60, "changes": 135, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -77,12 +77,11 @@ pub struct OnDiskCache<'sess> {\n     // `serialized_data`.\n     prev_diagnostics_index: FxHashMap<SerializedDepNodeIndex, AbsoluteBytePos>,\n \n-    // A cache to ensure we don't read allocations twice\n-    interpret_alloc_cache: RefCell<FxHashMap<usize, interpret::AllocId>>,\n+    // Alloc indices to memory location map\n+    prev_interpret_alloc_index: Vec<AbsoluteBytePos>,\n \n-    // A map from positions to size of the serialized allocation\n-    // so we can skip over already processed allocations\n-    interpret_alloc_size: RefCell<FxHashMap<usize, usize>>,\n+    /// Deserialization: A cache to ensure we don't read allocations twice\n+    interpret_alloc_cache: RefCell<FxHashMap<usize, interpret::AllocId>>,\n }\n \n // This type is used only for (de-)serialization.\n@@ -92,6 +91,8 @@ struct Footer {\n     prev_cnums: Vec<(u32, String, CrateDisambiguator)>,\n     query_result_index: EncodedQueryResultIndex,\n     diagnostics_index: EncodedQueryResultIndex,\n+    // the location of all allocations\n+    interpret_alloc_index: Vec<AbsoluteBytePos>,\n }\n \n type EncodedQueryResultIndex = Vec<(SerializedDepNodeIndex, AbsoluteBytePos)>;\n@@ -148,8 +149,8 @@ impl<'sess> OnDiskCache<'sess> {\n             query_result_index: footer.query_result_index.into_iter().collect(),\n             prev_diagnostics_index: footer.diagnostics_index.into_iter().collect(),\n             synthetic_expansion_infos: Lock::new(FxHashMap()),\n+            prev_interpret_alloc_index: footer.interpret_alloc_index,\n             interpret_alloc_cache: RefCell::new(FxHashMap::default()),\n-            interpret_alloc_size: RefCell::new(FxHashMap::default()),\n         }\n     }\n \n@@ -165,8 +166,8 @@ impl<'sess> OnDiskCache<'sess> {\n             query_result_index: FxHashMap(),\n             prev_diagnostics_index: FxHashMap(),\n             synthetic_expansion_infos: Lock::new(FxHashMap()),\n+            prev_interpret_alloc_index: Vec::new(),\n             interpret_alloc_cache: RefCell::new(FxHashMap::default()),\n-            interpret_alloc_size: RefCell::new(FxHashMap::default()),\n         }\n     }\n \n@@ -199,7 +200,9 @@ impl<'sess> OnDiskCache<'sess> {\n                 type_shorthands: FxHashMap(),\n                 predicate_shorthands: FxHashMap(),\n                 expn_info_shorthands: FxHashMap(),\n-                interpret_alloc_shorthands: FxHashMap(),\n+                interpret_allocs: FxHashMap(),\n+                interpret_alloc_ids: FxHashSet(),\n+                interpret_allocs_inverse: Vec::new(),\n                 codemap: CachingCodemapView::new(tcx.sess.codemap()),\n                 file_to_file_index,\n             };\n@@ -277,6 +280,31 @@ impl<'sess> OnDiskCache<'sess> {\n                 diagnostics_index\n             };\n \n+            let interpret_alloc_index = {\n+                let mut interpret_alloc_index = Vec::new();\n+                let mut n = 0;\n+                loop {\n+                    let new_n = encoder.interpret_alloc_ids.len();\n+                    for idx in n..new_n {\n+                        let id = encoder.interpret_allocs_inverse[idx];\n+                        let pos = AbsoluteBytePos::new(encoder.position());\n+                        interpret_alloc_index.push(pos);\n+                        interpret::specialized_encode_alloc_id(\n+                            &mut encoder,\n+                            tcx,\n+                            id,\n+                        )?;\n+                    }\n+                    // if we have found new ids, serialize those, too\n+                    if n == new_n {\n+                        // otherwise, abort\n+                        break;\n+                    }\n+                    n = new_n;\n+                }\n+                interpret_alloc_index\n+            };\n+\n             let sorted_cnums = sorted_cnums_including_local_crate(tcx);\n             let prev_cnums: Vec<_> = sorted_cnums.iter().map(|&cnum| {\n                 let crate_name = tcx.original_crate_name(cnum).as_str().to_string();\n@@ -291,6 +319,7 @@ impl<'sess> OnDiskCache<'sess> {\n                 prev_cnums,\n                 query_result_index,\n                 diagnostics_index,\n+                interpret_alloc_index,\n             })?;\n \n             // Encode the position of the footer as the last 8 bytes of the\n@@ -396,8 +425,8 @@ impl<'sess> OnDiskCache<'sess> {\n             file_index_to_file: &self.file_index_to_file,\n             file_index_to_stable_id: &self.file_index_to_stable_id,\n             synthetic_expansion_infos: &self.synthetic_expansion_infos,\n+            prev_interpret_alloc_index: &self.prev_interpret_alloc_index,\n             interpret_alloc_cache: &self.interpret_alloc_cache,\n-            interpret_alloc_size: &self.interpret_alloc_size,\n         };\n \n         match decode_tagged(&mut decoder, dep_node_index) {\n@@ -460,7 +489,8 @@ struct CacheDecoder<'a, 'tcx: 'a, 'x> {\n     file_index_to_file: &'x Lock<FxHashMap<FileMapIndex, Lrc<FileMap>>>,\n     file_index_to_stable_id: &'x FxHashMap<FileMapIndex, StableFilemapId>,\n     interpret_alloc_cache: &'x RefCell<FxHashMap<usize, interpret::AllocId>>,\n-    interpret_alloc_size: &'x RefCell<FxHashMap<usize, usize>>,\n+    /// maps from index in the cache file to location in the cache file\n+    prev_interpret_alloc_index: &'x [AbsoluteBytePos],\n }\n \n impl<'a, 'tcx, 'x> CacheDecoder<'a, 'tcx, 'x> {\n@@ -584,36 +614,29 @@ implement_ty_decoder!( CacheDecoder<'a, 'tcx, 'x> );\n impl<'a, 'tcx, 'x> SpecializedDecoder<interpret::AllocId> for CacheDecoder<'a, 'tcx, 'x> {\n     fn specialized_decode(&mut self) -> Result<interpret::AllocId, Self::Error> {\n         let tcx = self.tcx;\n-        let pos = TyDecoder::position(self);\n-        trace!(\"specialized_decode_alloc_id: {:?}\", pos);\n-        if let Some(cached) = self.interpret_alloc_cache.borrow().get(&pos).cloned() {\n-            // if there's no end position we are currently deserializing a recursive\n-            // allocation\n-            if let Some(end) = self.interpret_alloc_size.borrow().get(&pos).cloned() {\n-                trace!(\"{} already cached as {:?}\", pos, cached);\n-                // skip ahead\n-                self.opaque.set_position(end);\n-                return Ok(cached)\n-            }\n+        let idx = usize::decode(self)?;\n+        trace!(\"loading index {}\", idx);\n+\n+        if let Some(cached) = self.interpret_alloc_cache.borrow().get(&idx).cloned() {\n+            trace!(\"loading alloc id {:?} from alloc_cache\", cached);\n+            return Ok(cached);\n         }\n-        let id = interpret::specialized_decode_alloc_id(\n-            self,\n-            tcx,\n-            pos,\n-            |this, pos, alloc_id| {\n-                assert!(this.interpret_alloc_cache.borrow_mut().insert(pos, alloc_id).is_none());\n-            },\n-            |this, shorthand| {\n-                // need to load allocation\n-                this.with_position(shorthand, |this| interpret::AllocId::decode(this))\n-            }\n-        )?;\n-        assert!(self\n-            .interpret_alloc_size\n-            .borrow_mut()\n-            .insert(pos, TyDecoder::position(self))\n-            .is_none());\n-        Ok(id)\n+        let pos = self.prev_interpret_alloc_index[idx].to_usize();\n+        trace!(\"loading position {}\", pos);\n+        self.with_position(pos, |this| {\n+            interpret::specialized_decode_alloc_id(\n+                this,\n+                tcx,\n+                |this, alloc_id| {\n+                    trace!(\"caching idx {} for alloc id {} at position {}\", idx, alloc_id, pos);\n+                    assert!(this\n+                        .interpret_alloc_cache\n+                        .borrow_mut()\n+                        .insert(idx, alloc_id)\n+                        .is_none());\n+                },\n+            )\n+        })\n     }\n }\n impl<'a, 'tcx, 'x> SpecializedDecoder<Span> for CacheDecoder<'a, 'tcx, 'x> {\n@@ -777,7 +800,9 @@ struct CacheEncoder<'enc, 'a, 'tcx, E>\n     type_shorthands: FxHashMap<ty::Ty<'tcx>, usize>,\n     predicate_shorthands: FxHashMap<ty::Predicate<'tcx>, usize>,\n     expn_info_shorthands: FxHashMap<Mark, AbsoluteBytePos>,\n-    interpret_alloc_shorthands: FxHashMap<interpret::AllocId, usize>,\n+    interpret_allocs: FxHashMap<interpret::AllocId, usize>,\n+    interpret_allocs_inverse: Vec<interpret::AllocId>,\n+    interpret_alloc_ids: FxHashSet<interpret::AllocId>,\n     codemap: CachingCodemapView<'tcx>,\n     file_to_file_index: FxHashMap<*const FileMap, FileMapIndex>,\n }\n@@ -814,27 +839,17 @@ impl<'enc, 'a, 'tcx, E> SpecializedEncoder<interpret::AllocId> for CacheEncoder<\n     where E: 'enc + ty_codec::TyEncoder\n {\n     fn specialized_encode(&mut self, alloc_id: &interpret::AllocId) -> Result<(), Self::Error> {\n-        use std::collections::hash_map::Entry;\n-        let tcx = self.tcx;\n-        let pos = self.position();\n-        let shorthand = match self.interpret_alloc_shorthands.entry(*alloc_id) {\n-            Entry::Occupied(entry) => Some(entry.get().clone()),\n-            Entry::Vacant(entry) => {\n-                // ensure that we don't place any AllocIds at the very beginning\n-                // of the metadata file, because that would end up making our indices\n-                // not special. It is essentially impossible for that to happen,\n-                // but let's make sure\n-                assert!(pos >= interpret::SHORTHAND_START);\n-                entry.insert(pos);\n-                None\n-            },\n+        let index = if self.interpret_alloc_ids.insert(*alloc_id) {\n+            let idx = self.interpret_alloc_ids.len() - 1;\n+            assert_eq!(idx, self.interpret_allocs_inverse.len());\n+            self.interpret_allocs_inverse.push(*alloc_id);\n+            assert!(self.interpret_allocs.insert(*alloc_id, idx).is_none());\n+            idx\n+        } else {\n+            self.interpret_allocs[alloc_id]\n         };\n-        interpret::specialized_encode_alloc_id(\n-            self,\n-            tcx,\n-            *alloc_id,\n-            shorthand,\n-        )\n+\n+        index.encode(self)\n     }\n }\n "}, {"sha": "9173d12827446d3216c5e284b8e4bccde308bbc9", "filename": "src/librustc_metadata/decoder.rs", "status": "modified", "additions": 18, "deletions": 31, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc_metadata%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc_metadata%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fdecoder.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -59,9 +59,6 @@ pub struct DecodeContext<'a, 'tcx: 'a> {\n \n     // interpreter allocation cache\n     interpret_alloc_cache: FxHashMap<usize, interpret::AllocId>,\n-    // a cache for sizes of interpreter allocations\n-    // needed to skip already deserialized allocations\n-    interpret_alloc_size: FxHashMap<usize, usize>,\n }\n \n /// Abstract over the various ways one can create metadata decoders.\n@@ -81,7 +78,6 @@ pub trait Metadata<'a, 'tcx>: Copy {\n             last_filemap_index: 0,\n             lazy_state: LazyState::NoNode,\n             interpret_alloc_cache: FxHashMap::default(),\n-            interpret_alloc_size: FxHashMap::default(),\n         }\n     }\n }\n@@ -290,34 +286,25 @@ impl<'a, 'tcx> SpecializedDecoder<LocalDefId> for DecodeContext<'a, 'tcx> {\n \n impl<'a, 'tcx> SpecializedDecoder<interpret::AllocId> for DecodeContext<'a, 'tcx> {\n     fn specialized_decode(&mut self) -> Result<interpret::AllocId, Self::Error> {\n-        let tcx = self.tcx.expect(\"need tcx for AllocId decoding\");\n-        let pos = self.position();\n-        if let Some(cached) = self.interpret_alloc_cache.get(&pos).cloned() {\n-            // if there's no end position we are currently deserializing a recursive\n-            // allocation\n-            if let Some(end) = self.interpret_alloc_size.get(&pos).cloned() {\n-                trace!(\"{} already cached as {:?}\", pos, cached);\n-                // skip ahead\n-                self.opaque.set_position(end);\n-                return Ok(cached)\n-            }\n+        let tcx = self.tcx.unwrap();\n+        let idx = usize::decode(self)?;\n+\n+        if let Some(cached) = self.interpret_alloc_cache.get(&idx).cloned() {\n+            return Ok(cached);\n         }\n-        let id = interpret::specialized_decode_alloc_id(\n-            self,\n-            tcx,\n-            pos,\n-            |this, pos, alloc_id| { this.interpret_alloc_cache.insert(pos, alloc_id); },\n-            |this, shorthand| {\n-                // need to load allocation\n-                this.with_position(shorthand, |this| interpret::AllocId::decode(this))\n-            }\n-        )?;\n-        let end_pos = self.position();\n-        assert!(self\n-            .interpret_alloc_size\n-            .insert(pos, end_pos)\n-            .is_none());\n-        Ok(id)\n+        let pos = self\n+            .cdata()\n+            .root\n+            .interpret_alloc_index[idx];\n+        self.with_position(pos as usize, |this| {\n+            interpret::specialized_decode_alloc_id(\n+                this,\n+                tcx,\n+                |this, alloc_id| {\n+                    assert!(this.interpret_alloc_cache.insert(idx, alloc_id).is_none());\n+                },\n+            )\n+        })\n     }\n }\n "}, {"sha": "cc2d0eab2331ecc034bebd42173abe0c9fccf4c9", "filename": "src/librustc_metadata/encoder.rs", "status": "modified", "additions": 46, "deletions": 22, "changes": 68, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc_metadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc_metadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fencoder.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -29,7 +29,7 @@ use rustc::ty::{self, Ty, TyCtxt, ReprOptions, SymbolName};\n use rustc::ty::codec::{self as ty_codec, TyEncoder};\n \n use rustc::session::config::{self, CrateTypeProcMacro};\n-use rustc::util::nodemap::FxHashMap;\n+use rustc::util::nodemap::{FxHashMap, FxHashSet};\n \n use rustc_data_structures::stable_hasher::StableHasher;\n use rustc_serialize::{Encodable, Encoder, SpecializedEncoder, opaque};\n@@ -59,7 +59,10 @@ pub struct EncodeContext<'a, 'tcx: 'a> {\n     lazy_state: LazyState,\n     type_shorthands: FxHashMap<Ty<'tcx>, usize>,\n     predicate_shorthands: FxHashMap<ty::Predicate<'tcx>, usize>,\n-    interpret_alloc_shorthands: FxHashMap<interpret::AllocId, usize>,\n+\n+    interpret_allocs: FxHashMap<interpret::AllocId, usize>,\n+    interpret_allocs_inverse: Vec<interpret::AllocId>,\n+    interpret_alloc_ids: FxHashSet<interpret::AllocId>,\n \n     // This is used to speed up Span encoding.\n     filemap_cache: Lrc<FileMap>,\n@@ -196,26 +199,17 @@ impl<'a, 'tcx> SpecializedEncoder<Ty<'tcx>> for EncodeContext<'a, 'tcx> {\n \n impl<'a, 'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, alloc_id: &interpret::AllocId) -> Result<(), Self::Error> {\n-        use std::collections::hash_map::Entry;\n-        let tcx = self.tcx;\n-        let pos = self.position();\n-        let shorthand = match self.interpret_alloc_shorthands.entry(*alloc_id) {\n-            Entry::Occupied(entry) => Some(entry.get().clone()),\n-            Entry::Vacant(entry) => {\n-                // ensure that we don't place any AllocIds at the very beginning\n-                // of the metadata file, because that would end up making our indices\n-                // not special. This is essentially impossible, but let's make sure\n-                assert!(pos >= interpret::SHORTHAND_START);\n-                entry.insert(pos);\n-                None\n-            },\n+        let index = if self.interpret_alloc_ids.insert(*alloc_id) {\n+            let idx = self.interpret_alloc_ids.len() - 1;\n+            assert_eq!(idx, self.interpret_allocs_inverse.len());\n+            self.interpret_allocs_inverse.push(*alloc_id);\n+            assert!(self.interpret_allocs.insert(*alloc_id, idx).is_none());\n+            idx\n+        } else {\n+            self.interpret_allocs[alloc_id]\n         };\n-        interpret::specialized_encode_alloc_id(\n-            self,\n-            tcx,\n-            *alloc_id,\n-            shorthand,\n-        )\n+\n+        index.encode(self)\n     }\n }\n \n@@ -460,6 +454,33 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n         let has_default_lib_allocator =\n             attr::contains_name(tcx.hir.krate_attrs(), \"default_lib_allocator\");\n         let has_global_allocator = *tcx.sess.has_global_allocator.get();\n+\n+        // Encode the allocation index\n+        let interpret_alloc_index = {\n+            let mut interpret_alloc_index = Vec::new();\n+            let mut n = 0;\n+            loop {\n+                let new_n = self.interpret_alloc_ids.len();\n+                for idx in n..new_n {\n+                    let id = self.interpret_allocs_inverse[idx];\n+                    let pos = self.position() as u32;\n+                    interpret_alloc_index.push(pos);\n+                    interpret::specialized_encode_alloc_id(\n+                        self,\n+                        tcx,\n+                        id,\n+                    ).unwrap();\n+                }\n+                // if we have found new ids, serialize those, too\n+                if n == new_n {\n+                    // otherwise, abort\n+                    break;\n+                }\n+                n = new_n;\n+            }\n+            interpret_alloc_index\n+        };\n+\n         let root = self.lazy(&CrateRoot {\n             name: tcx.crate_name(LOCAL_CRATE),\n             extra_filename: tcx.sess.opts.cg.extra_filename.clone(),\n@@ -492,6 +513,7 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n             exported_symbols,\n             wasm_custom_sections,\n             index,\n+            interpret_alloc_index,\n         });\n \n         let total_bytes = self.position();\n@@ -1760,7 +1782,9 @@ pub fn encode_metadata<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n             type_shorthands: Default::default(),\n             predicate_shorthands: Default::default(),\n             filemap_cache: tcx.sess.codemap().files()[0].clone(),\n-            interpret_alloc_shorthands: Default::default(),\n+            interpret_allocs: Default::default(),\n+            interpret_allocs_inverse: Default::default(),\n+            interpret_alloc_ids: Default::default(),\n         };\n \n         // Encode the rustc version string in a predictable location."}, {"sha": "4eaf08742ecaeaeb1e5e75c48f144a95dad04f9e", "filename": "src/librustc_metadata/schema.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc_metadata%2Fschema.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Flibrustc_metadata%2Fschema.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fschema.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -207,6 +207,7 @@ pub struct CrateRoot {\n     pub impls: LazySeq<TraitImpls>,\n     pub exported_symbols: EncodedExportedSymbols,\n     pub wasm_custom_sections: LazySeq<DefIndex>,\n+    pub interpret_alloc_index: Vec<u32>,\n \n     pub index: LazySeq<index::Index>,\n }"}, {"sha": "b659703bef004781dc7a25f98bcc0fc20da493c0", "filename": "src/test/incremental/static_cycle/b.rs", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Ftest%2Fincremental%2Fstatic_cycle%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a67ded06a36b7d758a63d15f0a4c59b9f678f14c/src%2Ftest%2Fincremental%2Fstatic_cycle%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstatic_cycle%2Fb.rs?ref=a67ded06a36b7d758a63d15f0a4c59b9f678f14c", "patch": "@@ -0,0 +1,19 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// revisions:rpass1 rpass2\n+\n+#![cfg_attr(rpass2, warn(dead_code))]\n+\n+pub static mut BAA: *const i8 = unsafe { &BOO as *const _ as *const i8 };\n+\n+pub static mut BOO: *const i8 = unsafe { &BAA as *const _ as *const i8 };\n+\n+fn main() {}"}]}