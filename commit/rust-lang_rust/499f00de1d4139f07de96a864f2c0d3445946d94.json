{"sha": "499f00de1d4139f07de96a864f2c0d3445946d94", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ5OWYwMGRlMWQ0MTM5ZjA3ZGU5NmE4NjRmMmMwZDM0NDU5NDZkOTQ=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2013-01-07T21:08:43Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2013-01-23T01:55:36Z"}, "message": "std: various hacking on workcache.", "tree": {"sha": "a6c3a86f7ee55c1360d25c9c8e1465734e23c9fe", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a6c3a86f7ee55c1360d25c9c8e1465734e23c9fe"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/499f00de1d4139f07de96a864f2c0d3445946d94", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/499f00de1d4139f07de96a864f2c0d3445946d94", "html_url": "https://github.com/rust-lang/rust/commit/499f00de1d4139f07de96a864f2c0d3445946d94", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/499f00de1d4139f07de96a864f2c0d3445946d94/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bcaeb2080069b83bc50a537ce7bd14d7521ce65e", "url": "https://api.github.com/repos/rust-lang/rust/commits/bcaeb2080069b83bc50a537ce7bd14d7521ce65e", "html_url": "https://github.com/rust-lang/rust/commit/bcaeb2080069b83bc50a537ce7bd14d7521ce65e"}], "stats": {"total": 292, "additions": 185, "deletions": 107}, "files": [{"sha": "c0d762370c633152c76dbd6b0231bcd8803eff44", "filename": "src/libstd/workcache.rs", "status": "modified", "additions": 185, "deletions": 107, "changes": 292, "blob_url": "https://github.com/rust-lang/rust/blob/499f00de1d4139f07de96a864f2c0d3445946d94/src%2Flibstd%2Fworkcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/499f00de1d4139f07de96a864f2c0d3445946d94/src%2Flibstd%2Fworkcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fworkcache.rs?ref=499f00de1d4139f07de96a864f2c0d3445946d94", "patch": "@@ -11,7 +11,10 @@\n use json;\n use sha1;\n use serialize::{Encoder, Encodable, Decoder, Decodable};\n+use sort;\n \n+use core::cmp;\n+use core::dvec;\n use core::either::{Either, Left, Right};\n use core::io;\n use core::option;\n@@ -22,6 +25,7 @@ use core::run;\n use core::send_map::linear::LinearMap;\n use core::task;\n use core::to_bytes;\n+use core::mutable::Mut;\n \n /**\n *\n@@ -50,13 +54,13 @@ use core::to_bytes;\n * in maps of the form (type,name) => value. These are WorkMaps.\n *\n * A cached function divides the works it's interested up into inputs and\n-* outputs, and subdivides those into declared (input and output) works and\n+* outputs, and subdivides those into declared (input) works and\n * discovered (input and output) works.\n *\n-* A _declared_ input or output is one that is given to the workcache before\n+* A _declared_ input or is one that is given to the workcache before\n * any work actually happens, in the \"prep\" phase. Even when a function's\n * work-doing part (the \"exec\" phase) never gets called, it has declared\n-* inputs and outputs, which can be checked for freshness (and potentially\n+* inputs, which can be checked for freshness (and potentially\n * used to determine that the function can be skipped).\n *\n * The workcache checks _all_ works for freshness, but uses the set of\n@@ -78,12 +82,21 @@ use core::to_bytes;\n *\n * A database (the central store of a workcache) stores a mappings:\n *\n-* (fn_name,{declared_input}) => ({declared_output},{discovered_input},\n+* (fn_name,{declared_input}) => ({discovered_input},\n *                                {discovered_output},result)\n *\n+* (Note: fbuild, which workcache is based on, has the concept of a declared\n+* output as separate from a discovered output. This distinction exists only\n+* as an artifact of how fbuild works: via annotations on function types\n+* and metaprogramming, with explicit dependency declaration as a fallback.\n+* Workcache is more explicit about dependencies, and as such treats all\n+* outputs the same, as discovered-during-the-last-run.)\n+*\n */\n \n #[deriving_eq]\n+#[auto_encode]\n+#[auto_decode]\n struct WorkKey {\n     kind: ~str,\n     name: ~str\n@@ -99,6 +112,23 @@ impl WorkKey: to_bytes::IterBytes {\n     }\n }\n \n+impl WorkKey: cmp::Ord {\n+    pure fn lt(&self, other: &WorkKey) -> bool {\n+        self.kind < other.kind ||\n+            (self.kind == other.kind &&\n+             self.name < other.name)\n+    }\n+    pure fn le(&self, other: &WorkKey) -> bool {\n+        self.lt(other) || self.eq(other)\n+    }\n+    pure fn ge(&self, other: &WorkKey) -> bool {\n+        self.gt(other) || self.eq(other)\n+    }\n+    pure fn gt(&self, other: &WorkKey) -> bool {\n+        ! self.le(other)\n+    }\n+}\n+\n impl WorkKey {\n     static fn new(kind: &str, name: &str) -> WorkKey {\n     WorkKey { kind: kind.to_owned(), name: name.to_owned() }\n@@ -107,26 +137,60 @@ impl WorkKey {\n \n type WorkMap = LinearMap<WorkKey, ~str>;\n \n+pub impl<S: Encoder> WorkMap: Encodable<S> {\n+    fn encode(&self, s: &S) {\n+        let d = dvec::DVec();\n+        for self.each |k, v| {\n+            d.push((copy *k, copy *v))\n+        }\n+        let mut v = d.get();\n+        sort::tim_sort(v);\n+        v.encode(s)\n+    }\n+}\n+\n+pub impl<D: Decoder> WorkMap: Decodable<D> {\n+    static fn decode(&self, d: &D) -> WorkMap {\n+        let v : ~[(WorkKey,~str)] = Decodable::decode(d);\n+        let mut w = LinearMap();\n+        for v.each |&(k,v)| {\n+            w.insert(copy k, copy v);\n+        }\n+        w\n+    }\n+}\n+\n struct Database {\n-    // FIXME #4432: Fill in.\n-    a: ()\n+    db_filename: Path,\n+    db_cache: LinearMap<~str, ~str>,\n+    mut db_dirty: bool\n }\n \n impl Database {\n-    pure fn prepare(_fn_name: &str,\n-                    _declared_inputs: &const WorkMap,\n-                    _declared_outputs: &const WorkMap) ->\n+\n+    fn prepare(&mut self,\n+               fn_name: &str,\n+               declared_inputs: &WorkMap) ->\n         Option<(WorkMap, WorkMap, ~str)> {\n-        // FIXME #4432: load\n-        None\n+        let k = json_encode(&(fn_name, declared_inputs));\n+        match self.db_cache.find(&k) {\n+            None => None,\n+            Some(v) => Some(json_decode(v))\n+        }\n     }\n-    pure fn cache(_fn_name: &str,\n-                  _declared_inputs: &WorkMap,\n-                  _declared_outputs: &WorkMap,\n-                  _discovered_inputs: &WorkMap,\n-                  _discovered_outputs: &WorkMap,\n-                  _result: &str) {\n-        // FIXME #4432: store\n+\n+    fn cache(&mut self,\n+             fn_name: &str,\n+             declared_inputs: &WorkMap,\n+             discovered_inputs: &WorkMap,\n+             discovered_outputs: &WorkMap,\n+             result: &str) {\n+        let k = json_encode(&(fn_name, declared_inputs));\n+        let v = json_encode(&(discovered_inputs,\n+                              discovered_outputs,\n+                              result));\n+        self.db_cache.insert(k,v);\n+        self.db_dirty = true\n     }\n }\n \n@@ -136,25 +200,22 @@ struct Logger {\n }\n \n impl Logger {\n-    pure fn info(i: &str) {\n-        unsafe {\n-            io::println(~\"workcache: \" + i.to_owned());\n-        }\n+    fn info(i: &str) {\n+        io::println(~\"workcache: \" + i.to_owned());\n     }\n }\n \n struct Context {\n-    db: @Database,\n-    logger: @Logger,\n+    db: @Mut<Database>,\n+    logger: @Mut<Logger>,\n     cfg: @json::Object,\n-    freshness: LinearMap<~str,@pure fn(&str,&str)->bool>\n+    freshness: LinearMap<~str,@fn(&str,&str)->bool>\n }\n \n struct Prep {\n     ctxt: @Context,\n     fn_name: ~str,\n     declared_inputs: WorkMap,\n-    declared_outputs: WorkMap\n }\n \n struct Exec {\n@@ -163,19 +224,26 @@ struct Exec {\n }\n \n struct Work<T:Owned> {\n-    prep: @mut Prep,\n+    prep: @Mut<Prep>,\n     res: Option<Either<T,PortOne<(Exec,T)>>>\n }\n \n-fn digest<T:Encodable<json::Encoder>\n-            Decodable<json::Decoder>>(t: &T) -> ~str {\n-    let sha = sha1::sha1();\n-    let s = do io::with_str_writer |wr| {\n-        // FIXME #4432: sha1 should be a writer itself, shouldn't\n-        // go via strings.\n+fn json_encode<T:Encodable<json::Encoder>>(t: &T) -> ~str {\n+    do io::with_str_writer |wr| {\n         t.encode(&json::Encoder(wr));\n-    };\n-    sha.input_str(s);\n+    }\n+}\n+\n+fn json_decode<T:Decodable<json::Decoder>>(s: &str) -> T {\n+    do io::with_str_reader(s) |rdr| {\n+        let j = result::unwrap(json::from_reader(rdr));\n+        Decodable::decode(&json::Decoder(move j))\n+    }\n+}\n+\n+fn digest<T:Encodable<json::Encoder>>(t: &T) -> ~str {\n+    let sha = sha1::sha1();\n+    sha.input_str(json_encode(t));\n     sha.result_str()\n }\n \n@@ -188,7 +256,8 @@ fn digest_file(path: &Path) -> ~str {\n \n impl Context {\n \n-    static fn new(db: @Database, lg: @Logger,\n+    static fn new(db: @Mut<Database>,\n+                  lg: @Mut<Logger>,\n                   cfg: @json::Object) -> Context {\n         Context {db: db, logger: lg, cfg: cfg, freshness: LinearMap()}\n     }\n@@ -198,41 +267,51 @@ impl Context {\n               Decodable<json::Decoder>>(\n                   @self,\n                   fn_name:&str,\n-                  blk: fn((@mut Prep))->Work<T>) -> Work<T> {\n-        let p = @mut Prep {ctxt: self,\n+                  blk: fn(@Mut<Prep>)->Work<T>) -> Work<T> {\n+        let p = @Mut(Prep {ctxt: self,\n                            fn_name: fn_name.to_owned(),\n-                           declared_inputs: LinearMap(),\n-                           declared_outputs: LinearMap()};\n+                           declared_inputs: LinearMap()});\n         blk(p)\n     }\n }\n \n-impl Prep {\n-    fn declare_input(&mut self, kind:&str, name:&str, val:&str) {\n-        self.declared_inputs.insert(WorkKey::new(kind, name),\n-                                    val.to_owned());\n-    }\n \n-    fn declare_output(&mut self, kind:&str, name:&str, val:&str) {\n-        self.declared_outputs.insert(WorkKey::new(kind, name),\n+trait TPrep {\n+    fn declare_input(&self, kind:&str, name:&str, val:&str);\n+    fn is_fresh(&self, cat:&str, kind:&str, name:&str, val:&str) -> bool;\n+    fn all_fresh(&self, cat:&str, map:&WorkMap) -> bool;\n+    fn exec<T:Owned\n+        Encodable<json::Encoder>\n+        Decodable<json::Decoder>>(&self, blk: ~fn(&Exec) -> T) -> Work<T>;\n+}\n+\n+impl @Mut<Prep> : TPrep {\n+    fn declare_input(&self, kind:&str, name:&str, val:&str) {\n+        do self.borrow_mut |p| {\n+            p.declared_inputs.insert(WorkKey::new(kind, name),\n                                      val.to_owned());\n+        }\n     }\n \n-    pure fn is_fresh(cat: &str, kind: &str,\n-                     name: &str, val: &str) -> bool {\n-        let k = kind.to_owned();\n-        let f = (self.ctxt.freshness.get(&k))(name, val);\n-        if f {\n-            self.ctxt.logger.info(fmt!(\"%s %s:%s is fresh\",\n-                                       cat, kind, name));\n-        } else {\n-            self.ctxt.logger.info(fmt!(\"%s %s:%s is not fresh\",\n-                                       cat, kind, name))\n+    fn is_fresh(&self, cat: &str, kind: &str,\n+                name: &str, val: &str) -> bool {\n+        do self.borrow_imm |p| {\n+            let k = kind.to_owned();\n+            let f = (p.ctxt.freshness.get(&k))(name, val);\n+            do p.ctxt.logger.borrow_imm |lg| {\n+                if f {\n+                    lg.info(fmt!(\"%s %s:%s is fresh\",\n+                                 cat, kind, name));\n+                } else {\n+                    lg.info(fmt!(\"%s %s:%s is not fresh\",\n+                                 cat, kind, name))\n+                }\n+            }\n+            f\n         }\n-        return f;\n     }\n \n-    pure fn all_fresh(cat: &str, map: WorkMap) -> bool {\n+    fn all_fresh(&self, cat: &str, map: &WorkMap) -> bool {\n         for map.each |k,v| {\n             if ! self.is_fresh(cat, k.kind, k.name, *v) {\n                 return false;\n@@ -242,56 +321,52 @@ impl Prep {\n     }\n \n     fn exec<T:Owned\n-              Encodable<json::Encoder>\n-              Decodable<json::Decoder>>(\n-                  @mut self, blk: ~fn(&Exec) -> T) -> Work<T> {\n+        Encodable<json::Encoder>\n+        Decodable<json::Decoder>>(&self,\n+                                  blk: ~fn(&Exec) -> T) -> Work<T> {\n \n-        let cached = self.ctxt.db.prepare(self.fn_name,\n-                                          &self.declared_inputs,\n-                                          &self.declared_outputs);\n+        let mut bo = Some(move blk);\n \n-        match move cached {\n-            None => (),\n-            Some((move disc_in,\n-                  move disc_out,\n-                  move res)) => {\n+        do self.borrow_imm |p| {\n+            let cached = do p.ctxt.db.borrow_mut |db| {\n+                db.prepare(p.fn_name, &p.declared_inputs)\n+            };\n \n+            match move cached {\n+                Some((ref disc_in, ref disc_out, ref res))\n                 if self.all_fresh(\"declared input\",\n-                                  self.declared_inputs) &&\n-                    self.all_fresh(\"declared output\",\n-                                   self.declared_outputs) &&\n-                    self.all_fresh(\"discovered input\", disc_in) &&\n-                    self.all_fresh(\"discovered output\", disc_out) {\n-\n-                    let v : T = do io::with_str_reader(res) |rdr| {\n-                        let j = result::unwrap(json::from_reader(rdr));\n-                        Decodable::decode(&json::Decoder(move j))\n-                    };\n-                    return Work::new(self, move Left(move v));\n+                                  &p.declared_inputs) &&\n+                self.all_fresh(\"discovered input\", disc_in) &&\n+                self.all_fresh(\"discovered output\", disc_out) => {\n+                    Work::new(*self, move Left(json_decode(*res)))\n                 }\n-            }\n-        }\n-\n-        let (chan, port) = oneshot::init();\n \n-        let chan = ~mut Some(move chan);\n-        do task::spawn |move blk, move chan| {\n-            let exe = Exec { discovered_inputs: LinearMap(),\n-                             discovered_outputs: LinearMap() };\n-            let chan = option::swap_unwrap(&mut *chan);\n-            let v = blk(&exe);\n-            send_one(move chan, (move exe, move v));\n+                _ => {\n+                    let (chan, port) = oneshot::init();\n+                    let mut blk = None;\n+                    blk <-> bo;\n+                    let blk = blk.unwrap();\n+                    let chan = ~mut Some(move chan);\n+                    do task::spawn |move blk, move chan| {\n+                        let exe = Exec { discovered_inputs: LinearMap(),\n+                                         discovered_outputs: LinearMap() };\n+                        let chan = option::swap_unwrap(&mut *chan);\n+                        let v = blk(&exe);\n+                        send_one(move chan, (move exe, move v));\n+                    }\n+\n+                    Work::new(*self, move Right(move port))\n+                }\n+            }\n         }\n-\n-        Work::new(self, move Right(move port))\n     }\n }\n \n impl<T:Owned\n        Encodable<json::Encoder>\n        Decodable<json::Decoder>>\n     Work<T> {\n-    static fn new(p: @mut Prep, e: Either<T,PortOne<(Exec,T)>>) -> Work<T> {\n+    static fn new(p: @Mut<Prep>, e: Either<T,PortOne<(Exec,T)>>) -> Work<T> {\n         move Work { prep: p, res: Some(move e) }\n     }\n }\n@@ -315,27 +390,30 @@ fn unwrap<T:Owned\n                 oneshot::send(move data) => move data\n             };\n \n-            let s = do io::with_str_writer |wr| {\n-                v.encode(&json::Encoder(wr));\n-            };\n+            let s = json_encode(&v);\n \n-            ww.prep.ctxt.db.cache(ww.prep.fn_name,\n-                                  &ww.prep.declared_inputs,\n-                                  &ww.prep.declared_outputs,\n-                                  &exe.discovered_inputs,\n-                                  &exe.discovered_outputs,\n-                                  s);\n+            do ww.prep.borrow_imm |p| {\n+                do p.ctxt.db.borrow_mut |db| {\n+                    db.cache(p.fn_name,\n+                             &p.declared_inputs,\n+                             &exe.discovered_inputs,\n+                             &exe.discovered_outputs,\n+                             s);\n+                }\n+            }\n             move v\n         }\n     }\n }\n \n-#[test]\n+//#[test]\n fn test() {\n     use io::WriterUtil;\n \n-    let db = @Database { a: () };\n-    let lg = @Logger { a: () };\n+    let db = @Mut(Database { db_filename: Path(\"db.json\"),\n+                             db_cache: LinearMap(),\n+                             db_dirty: false });\n+    let lg = @Mut(Logger { a: () });\n     let cfg = @LinearMap();\n     let cx = @Context::new(db, lg, cfg);\n     let w:Work<~str> = do cx.prep(\"test1\") |prep| {"}]}