{"sha": "927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "node_id": "C_kwDOAAsO6NoAKDkyN2FiMTljZmM2N2Y5NmY3NTQzYWE5MjliZDFhMDFjOGYyMjZkYzI", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-08-05T21:53:18Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-08-09T17:59:34Z"}, "message": "make some operations private to the data race detector / atomic intrinsic file", "tree": {"sha": "3e1353e2c8858325266cdabde875d481d4c60319", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3e1353e2c8858325266cdabde875d481d4c60319"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "html_url": "https://github.com/rust-lang/rust/commit/927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "cd2edbfd098b6c9351f8c168c8f36c190ce5e675", "url": "https://api.github.com/repos/rust-lang/rust/commits/cd2edbfd098b6c9351f8c168c8f36c190ce5e675", "html_url": "https://github.com/rust-lang/rust/commit/cd2edbfd098b6c9351f8c168c8f36c190ce5e675"}], "stats": {"total": 217, "additions": 110, "deletions": 107}, "files": [{"sha": "bcbdb616514f10516a235dd541f04fe8a288baa0", "filename": "src/concurrency/data_race.rs", "status": "modified", "additions": 100, "deletions": 100, "changes": 200, "blob_url": "https://github.com/rust-lang/rust/blob/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/src%2Fconcurrency%2Fdata_race.rs", "raw_url": "https://github.com/rust-lang/rust/raw/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/src%2Fconcurrency%2Fdata_race.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fconcurrency%2Fdata_race.rs?ref=927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "patch": "@@ -464,33 +464,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         this.write_scalar_atomic(value.into(), &value_place, atomic)\n     }\n \n-    /// Checks that an atomic access is legal at the given place.\n-    fn atomic_access_check(&self, place: &MPlaceTy<'tcx, Provenance>) -> InterpResult<'tcx> {\n-        let this = self.eval_context_ref();\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-        // Ensure the allocation is mutable. Even failing (read-only) compare_exchange need mutable\n-        // memory on many targets (i.e., they segfault if taht memory is mapped read-only), and\n-        // atomic loads can be implemented via compare_exchange on some targets. See\n-        // <https://github.com/rust-lang/miri/issues/2463>.\n-        // We avoid `get_ptr_alloc` since we do *not* want to run the access hooks -- the actual\n-        // access will happen later.\n-        let (alloc_id, _offset, _prov) =\n-            this.ptr_try_get_alloc_id(place.ptr).expect(\"there are no zero-sized atomic accesses\");\n-        if this.get_alloc_mutability(alloc_id)? == Mutability::Not {\n-            throw_ub_format!(\"atomic operations cannot be performed on read-only memory\");\n-        }\n-        Ok(())\n-    }\n-\n     /// Perform an atomic read operation at the memory location.\n     fn read_scalar_atomic(\n         &self,\n@@ -682,80 +655,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         Ok(res)\n     }\n \n-    /// Update the data-race detector for an atomic read occurring at the\n-    /// associated memory-place and on the current thread.\n-    fn validate_atomic_load(\n-        &self,\n-        place: &MPlaceTy<'tcx, Provenance>,\n-        atomic: AtomicReadOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_ref();\n-        this.validate_overlapping_atomic(place)?;\n-        this.validate_atomic_op(\n-            place,\n-            atomic,\n-            \"Atomic Load\",\n-            move |memory, clocks, index, atomic| {\n-                if atomic == AtomicReadOrd::Relaxed {\n-                    memory.load_relaxed(&mut *clocks, index)\n-                } else {\n-                    memory.load_acquire(&mut *clocks, index)\n-                }\n-            },\n-        )\n-    }\n-\n-    /// Update the data-race detector for an atomic write occurring at the\n-    /// associated memory-place and on the current thread.\n-    fn validate_atomic_store(\n-        &mut self,\n-        place: &MPlaceTy<'tcx, Provenance>,\n-        atomic: AtomicWriteOrd,\n-    ) -> InterpResult<'tcx> {\n-        let this = self.eval_context_mut();\n-        this.validate_overlapping_atomic(place)?;\n-        this.validate_atomic_op(\n-            place,\n-            atomic,\n-            \"Atomic Store\",\n-            move |memory, clocks, index, atomic| {\n-                if atomic == AtomicWriteOrd::Relaxed {\n-                    memory.store_relaxed(clocks, index)\n-                } else {\n-                    memory.store_release(clocks, index)\n-                }\n-            },\n-        )\n-    }\n-\n-    /// Update the data-race detector for an atomic read-modify-write occurring\n-    /// at the associated memory place and on the current thread.\n-    fn validate_atomic_rmw(\n-        &mut self,\n-        place: &MPlaceTy<'tcx, Provenance>,\n-        atomic: AtomicRwOrd,\n-    ) -> InterpResult<'tcx> {\n-        use AtomicRwOrd::*;\n-        let acquire = matches!(atomic, Acquire | AcqRel | SeqCst);\n-        let release = matches!(atomic, Release | AcqRel | SeqCst);\n-        let this = self.eval_context_mut();\n-        this.validate_overlapping_atomic(place)?;\n-        this.validate_atomic_op(place, atomic, \"Atomic RMW\", move |memory, clocks, index, _| {\n-            if acquire {\n-                memory.load_acquire(clocks, index)?;\n-            } else {\n-                memory.load_relaxed(clocks, index)?;\n-            }\n-            if release {\n-                memory.rmw_release(clocks, index)\n-            } else {\n-                memory.rmw_relaxed(clocks, index)\n-            }\n-        })\n-    }\n-\n     /// Update the data-race detector for an atomic fence on the current thread.\n-    fn validate_atomic_fence(&mut self, atomic: AtomicFenceOrd) -> InterpResult<'tcx> {\n+    fn atomic_fence(&mut self, atomic: AtomicFenceOrd) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         if let Some(data_race) = &mut this.machine.data_race {\n             data_race.maybe_perform_sync_operation(&this.machine.threads, |index, mut clocks| {\n@@ -1081,6 +982,105 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         result\n     }\n \n+    /// Checks that an atomic access is legal at the given place.\n+    fn atomic_access_check(&self, place: &MPlaceTy<'tcx, Provenance>) -> InterpResult<'tcx> {\n+        let this = self.eval_context_ref();\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+        // Ensure the allocation is mutable. Even failing (read-only) compare_exchange need mutable\n+        // memory on many targets (i.e., they segfault if taht memory is mapped read-only), and\n+        // atomic loads can be implemented via compare_exchange on some targets. See\n+        // <https://github.com/rust-lang/miri/issues/2463>.\n+        // We avoid `get_ptr_alloc` since we do *not* want to run the access hooks -- the actual\n+        // access will happen later.\n+        let (alloc_id, _offset, _prov) =\n+            this.ptr_try_get_alloc_id(place.ptr).expect(\"there are no zero-sized atomic accesses\");\n+        if this.get_alloc_mutability(alloc_id)? == Mutability::Not {\n+            throw_ub_format!(\"atomic operations cannot be performed on read-only memory\");\n+        }\n+        Ok(())\n+    }\n+\n+    /// Update the data-race detector for an atomic read occurring at the\n+    /// associated memory-place and on the current thread.\n+    fn validate_atomic_load(\n+        &self,\n+        place: &MPlaceTy<'tcx, Provenance>,\n+        atomic: AtomicReadOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_ref();\n+        this.validate_overlapping_atomic(place)?;\n+        this.validate_atomic_op(\n+            place,\n+            atomic,\n+            \"Atomic Load\",\n+            move |memory, clocks, index, atomic| {\n+                if atomic == AtomicReadOrd::Relaxed {\n+                    memory.load_relaxed(&mut *clocks, index)\n+                } else {\n+                    memory.load_acquire(&mut *clocks, index)\n+                }\n+            },\n+        )\n+    }\n+\n+    /// Update the data-race detector for an atomic write occurring at the\n+    /// associated memory-place and on the current thread.\n+    fn validate_atomic_store(\n+        &mut self,\n+        place: &MPlaceTy<'tcx, Provenance>,\n+        atomic: AtomicWriteOrd,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        this.validate_overlapping_atomic(place)?;\n+        this.validate_atomic_op(\n+            place,\n+            atomic,\n+            \"Atomic Store\",\n+            move |memory, clocks, index, atomic| {\n+                if atomic == AtomicWriteOrd::Relaxed {\n+                    memory.store_relaxed(clocks, index)\n+                } else {\n+                    memory.store_release(clocks, index)\n+                }\n+            },\n+        )\n+    }\n+\n+    /// Update the data-race detector for an atomic read-modify-write occurring\n+    /// at the associated memory place and on the current thread.\n+    fn validate_atomic_rmw(\n+        &mut self,\n+        place: &MPlaceTy<'tcx, Provenance>,\n+        atomic: AtomicRwOrd,\n+    ) -> InterpResult<'tcx> {\n+        use AtomicRwOrd::*;\n+        let acquire = matches!(atomic, Acquire | AcqRel | SeqCst);\n+        let release = matches!(atomic, Release | AcqRel | SeqCst);\n+        let this = self.eval_context_mut();\n+        this.validate_overlapping_atomic(place)?;\n+        this.validate_atomic_op(place, atomic, \"Atomic RMW\", move |memory, clocks, index, _| {\n+            if acquire {\n+                memory.load_acquire(clocks, index)?;\n+            } else {\n+                memory.load_relaxed(clocks, index)?;\n+            }\n+            if release {\n+                memory.rmw_release(clocks, index)\n+            } else {\n+                memory.rmw_relaxed(clocks, index)\n+            }\n+        })\n+    }\n+\n     /// Generic atomic operation implementation\n     fn validate_atomic_op<A: Debug + Copy>(\n         &self,"}, {"sha": "86f132f73fc80d4ed1634e4fba3bf46d46ad436a", "filename": "src/shims/intrinsics/atomic.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/src%2Fshims%2Fintrinsics%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/src%2Fshims%2Fintrinsics%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fintrinsics%2Fatomic.rs?ref=927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "patch": "@@ -67,8 +67,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             [\"load\", ord] => this.atomic_load(args, dest, read_ord(ord)?)?,\n             [\"store\", ord] => this.atomic_store(args, write_ord(ord)?)?,\n \n-            [\"fence\", ord] => this.atomic_fence(args, fence_ord(ord)?)?,\n-            [\"singlethreadfence\", ord] => this.compiler_fence(args, fence_ord(ord)?)?,\n+            [\"fence\", ord] => this.atomic_fence_intrinsic(args, fence_ord(ord)?)?,\n+            [\"singlethreadfence\", ord] => this.compiler_fence_intrinsic(args, fence_ord(ord)?)?,\n \n             [\"xchg\", ord] => this.atomic_exchange(args, dest, rw_ord(ord)?)?,\n             [\"cxchg\", ord1, ord2] =>\n@@ -117,7 +117,10 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         }\n         Ok(())\n     }\n+}\n \n+impl<'mir, 'tcx: 'mir> EvalContextPrivExt<'mir, 'tcx> for MiriEvalContext<'mir, 'tcx> {}\n+trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     fn atomic_load(\n         &mut self,\n         args: &[OpTy<'tcx, Provenance>],\n@@ -153,7 +156,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(())\n     }\n \n-    fn compiler_fence(\n+    fn compiler_fence_intrinsic(\n         &mut self,\n         args: &[OpTy<'tcx, Provenance>],\n         atomic: AtomicFenceOrd,\n@@ -164,14 +167,14 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(())\n     }\n \n-    fn atomic_fence(\n+    fn atomic_fence_intrinsic(\n         &mut self,\n         args: &[OpTy<'tcx, Provenance>],\n         atomic: AtomicFenceOrd,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         let [] = check_arg_count(args)?;\n-        this.validate_atomic_fence(atomic)?;\n+        this.atomic_fence(atomic)?;\n         Ok(())\n     }\n "}, {"sha": "b33553f4663b901604e0730bd9d8a5f6a1ff9245", "filename": "src/shims/unix/linux/sync.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/src%2Fshims%2Funix%2Flinux%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/927ab19cfc67f96f7543aa929bd1a01c8f226dc2/src%2Fshims%2Funix%2Flinux%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Funix%2Flinux%2Fsync.rs?ref=927ab19cfc67f96f7543aa929bd1a01c8f226dc2", "patch": "@@ -169,7 +169,7 @@ pub fn futex<'tcx>(\n             //\n             // Thankfully, preemptions cannot happen inside a Miri shim, so we do not need to\n             // do anything special to guarantee fence-load-comparison atomicity.\n-            this.validate_atomic_fence(AtomicFenceOrd::SeqCst)?;\n+            this.atomic_fence(AtomicFenceOrd::SeqCst)?;\n             // Read an `i32` through the pointer, regardless of any wrapper types.\n             // It's not uncommon for `addr` to be passed as another type than `*mut i32`, such as `*const AtomicI32`.\n             let futex_val = this\n@@ -240,7 +240,7 @@ pub fn futex<'tcx>(\n             // Together with the SeqCst fence in futex_wait, this makes sure that futex_wait\n             // will see the latest value on addr which could be changed by our caller\n             // before doing the syscall.\n-            this.validate_atomic_fence(AtomicFenceOrd::SeqCst)?;\n+            this.atomic_fence(AtomicFenceOrd::SeqCst)?;\n             let mut n = 0;\n             for _ in 0..val {\n                 if let Some(thread) = this.futex_wake(addr_usize, bitset) {"}]}