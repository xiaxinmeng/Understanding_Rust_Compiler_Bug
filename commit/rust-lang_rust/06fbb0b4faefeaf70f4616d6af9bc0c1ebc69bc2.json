{"sha": "06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA2ZmJiMGI0ZmFlZmVhZjcwZjQ2MTZkNmFmOWJjMGMxZWJjNjliYzI=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2020-02-16T20:19:51Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2020-02-17T19:12:39Z"}, "message": "parser: Remove `Option`s from unnormalized tokens\n\nThey are always set synchronously with normalized tokens now", "tree": {"sha": "fd73ac992e03a157f6557dccd11f3f436ffb2331", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fd73ac992e03a157f6557dccd11f3f436ffb2331"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "html_url": "https://github.com/rust-lang/rust/commit/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ed2fd28d385c1cc9b2ab3e91513b4d2ffc612671", "url": "https://api.github.com/repos/rust-lang/rust/commits/ed2fd28d385c1cc9b2ab3e91513b4d2ffc612671", "html_url": "https://github.com/rust-lang/rust/commit/ed2fd28d385c1cc9b2ab3e91513b4d2ffc612671"}], "stats": {"total": 69, "additions": 26, "deletions": 43}, "files": [{"sha": "a0b8415b3e17e5f9e66767ca87ae7886ff554ac2", "filename": "src/librustc_parse/lib.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Flib.rs?ref=06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "patch": "@@ -9,7 +9,7 @@ use rustc_errors::{Diagnostic, FatalError, Level, PResult};\n use rustc_session::parse::ParseSess;\n use rustc_span::{FileName, SourceFile, Span};\n use syntax::ast;\n-use syntax::token::{self, Nonterminal};\n+use syntax::token::{self, Nonterminal, Token};\n use syntax::tokenstream::{self, TokenStream, TokenTree};\n \n use std::path::{Path, PathBuf};\n@@ -170,9 +170,9 @@ fn maybe_source_file_to_parser(\n     let (stream, unclosed_delims) = maybe_file_to_stream(sess, source_file, None)?;\n     let mut parser = stream_to_parser(sess, stream, None);\n     parser.unclosed_delims = unclosed_delims;\n-    if parser.token == token::Eof && parser.token.span.is_dummy() {\n-        parser.token.span = Span::new(end_pos, end_pos, parser.token.span.ctxt());\n-        assert!(parser.unnormalized_token.is_none());\n+    if parser.token == token::Eof {\n+        let span = Span::new(end_pos, end_pos, parser.token.span.ctxt());\n+        parser.set_token(Token::new(token::Eof, span));\n     }\n \n     Ok(parser)"}, {"sha": "97daa91eed196ee08c351b18f3a632908b3ae473", "filename": "src/librustc_parse/parser/expr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fexpr.rs?ref=06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "patch": "@@ -166,7 +166,7 @@ impl<'a> Parser<'a> {\n         while let Some(op) = self.check_assoc_op() {\n             // Adjust the span for interpolated LHS to point to the `$lhs` token\n             // and not to what it refers to.\n-            let lhs_span = match self.unnormalized_prev_token().kind {\n+            let lhs_span = match self.unnormalized_prev_token.kind {\n                 TokenKind::Interpolated(..) => self.prev_span,\n                 _ => lhs.span,\n             };\n@@ -527,7 +527,7 @@ impl<'a> Parser<'a> {\n     ) -> PResult<'a, (Span, P<Expr>)> {\n         expr.map(|e| {\n             (\n-                match self.unnormalized_prev_token().kind {\n+                match self.unnormalized_prev_token.kind {\n                     TokenKind::Interpolated(..) => self.prev_span,\n                     _ => e.span,\n                 },"}, {"sha": "937e5e3cd695b24670c1454ae8d9e97bfb34c9ea", "filename": "src/librustc_parse/parser/mod.rs", "status": "modified", "additions": 19, "deletions": 36, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fmod.rs?ref=06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "patch": "@@ -93,18 +93,16 @@ pub struct Parser<'a> {\n     /// Use span from this token if you need an isolated span.\n     pub token: Token,\n     /// The current non-normalized token if it's different from `token`.\n-    /// Preferable use is through the `unnormalized_token()` getter.\n     /// Use span from this token if you need to concatenate it with some neighbouring spans.\n-    pub unnormalized_token: Option<Token>,\n+    unnormalized_token: Token,\n     /// The previous normalized token.\n     /// Use span from this token if you need an isolated span.\n     prev_token: Token,\n     /// The previous non-normalized token if it's different from `prev_token`.\n-    /// Preferable use is through the `unnormalized_prev_token()` getter.\n     /// Use span from this token if you need to concatenate it with some neighbouring spans.\n-    unnormalized_prev_token: Option<Token>,\n-    /// Equivalent to `unnormalized_prev_token().span`.\n-    /// FIXME: Remove in favor of `(unnormalized_)prev_token().span`.\n+    unnormalized_prev_token: Token,\n+    /// Equivalent to `unnormalized_prev_token.span`.\n+    /// FIXME: Remove in favor of `(unnormalized_)prev_token.span`.\n     pub prev_span: Span,\n     restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files.\n@@ -378,9 +376,9 @@ impl<'a> Parser<'a> {\n         let mut parser = Parser {\n             sess,\n             token: Token::dummy(),\n-            unnormalized_token: None,\n+            unnormalized_token: Token::dummy(),\n             prev_token: Token::dummy(),\n-            unnormalized_prev_token: None,\n+            unnormalized_prev_token: Token::dummy(),\n             prev_span: DUMMY_SP,\n             restrictions: Restrictions::empty(),\n             recurse_into_file_modules,\n@@ -422,14 +420,6 @@ impl<'a> Parser<'a> {\n         parser\n     }\n \n-    fn unnormalized_token(&self) -> &Token {\n-        self.unnormalized_token.as_ref().unwrap_or(&self.token)\n-    }\n-\n-    fn unnormalized_prev_token(&self) -> &Token {\n-        self.unnormalized_prev_token.as_ref().unwrap_or(&self.prev_token)\n-    }\n-\n     fn next_tok(&mut self, fallback_span: Span) -> Token {\n         let mut next = if self.desugar_doc_comments {\n             self.token_cursor.next_desugared()\n@@ -899,18 +889,17 @@ impl<'a> Parser<'a> {\n     // Interpolated identifier (`$i: ident`) and lifetime (`$l: lifetime`)\n     // tokens are replaced with usual identifier and lifetime tokens,\n     // so the former are never encountered during normal parsing.\n-    fn normalize_token(token: &Token) -> Option<Token> {\n-        match &token.kind {\n+    crate fn set_token(&mut self, token: Token) {\n+        self.unnormalized_token = token;\n+        self.token = match &self.unnormalized_token.kind {\n             token::Interpolated(nt) => match **nt {\n                 token::NtIdent(ident, is_raw) => {\n-                    Some(Token::new(token::Ident(ident.name, is_raw), ident.span))\n+                    Token::new(token::Ident(ident.name, is_raw), ident.span)\n                 }\n-                token::NtLifetime(ident) => {\n-                    Some(Token::new(token::Lifetime(ident.name), ident.span))\n-                }\n-                _ => None,\n+                token::NtLifetime(ident) => Token::new(token::Lifetime(ident.name), ident.span),\n+                _ => self.unnormalized_token.clone(),\n             },\n-            _ => None,\n+            _ => self.unnormalized_token.clone(),\n         }\n     }\n \n@@ -925,13 +914,11 @@ impl<'a> Parser<'a> {\n         // Update the current and previous tokens.\n         self.prev_token = self.token.take();\n         self.unnormalized_prev_token = self.unnormalized_token.take();\n-        self.token = self.next_tok(self.unnormalized_prev_token().span);\n-        if let Some(normalized_token) = Self::normalize_token(&self.token) {\n-            self.unnormalized_token = Some(mem::replace(&mut self.token, normalized_token));\n-        }\n+        let next_token = self.next_tok(self.unnormalized_prev_token.span);\n+        self.set_token(next_token);\n \n         // Update fields derived from the previous token.\n-        self.prev_span = self.unnormalized_prev_token().span;\n+        self.prev_span = self.unnormalized_prev_token.span;\n \n         self.expected_tokens.clear();\n     }\n@@ -945,13 +932,10 @@ impl<'a> Parser<'a> {\n         // Update the current and previous tokens.\n         self.prev_token = self.token.take();\n         self.unnormalized_prev_token = self.unnormalized_token.take();\n-        self.token = Token::new(next, span);\n-        if let Some(normalized_token) = Self::normalize_token(&self.token) {\n-            self.unnormalized_token = Some(mem::replace(&mut self.token, normalized_token));\n-        }\n+        self.set_token(Token::new(next, span));\n \n         // Update fields derived from the previous token.\n-        self.prev_span = self.unnormalized_prev_token().span.with_hi(span.lo());\n+        self.prev_span = self.unnormalized_prev_token.span.with_hi(span.lo());\n \n         self.expected_tokens.clear();\n     }\n@@ -1096,8 +1080,7 @@ impl<'a> Parser<'a> {\n                     &mut self.token_cursor.frame,\n                     self.token_cursor.stack.pop().unwrap(),\n                 );\n-                self.token = Token::new(TokenKind::CloseDelim(frame.delim), frame.span.close);\n-                self.unnormalized_token = None;\n+                self.set_token(Token::new(TokenKind::CloseDelim(frame.delim), frame.span.close));\n                 self.bump();\n                 TokenTree::Delimited(frame.span, frame.delim, frame.tree_cursor.stream.into())\n             }"}, {"sha": "18e57c6a5d49fd7039e96fcce8b4089cd537b911", "filename": "src/librustc_parse/parser/path.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Fparser%2Fpath.rs", "raw_url": "https://github.com/rust-lang/rust/raw/06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2/src%2Flibrustc_parse%2Fparser%2Fpath.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fpath.rs?ref=06fbb0b4faefeaf70f4616d6af9bc0c1ebc69bc2", "patch": "@@ -134,7 +134,7 @@ impl<'a> Parser<'a> {\n             path\n         });\n \n-        let lo = self.unnormalized_token().span;\n+        let lo = self.unnormalized_token.span;\n         let mut segments = Vec::new();\n         let mod_sep_ctxt = self.token.span.ctxt();\n         if self.eat(&token::ModSep) {"}]}