{"sha": "371bf0eda20eed78d5ed366426acd167b0d15b2e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM3MWJmMGVkYTIwZWVkNzhkNWVkMzY2NDI2YWNkMTY3YjBkMTViMmU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-06-08T00:56:35Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-06-08T00:56:35Z"}, "message": "Auto merge of #33982 - LeoTestard:remove-check-matcher-old, r=pnkfelix\n\nRemove the old FOLLOW checking (aka `check_matcher_old`).\n\nIt was supposed to be removed at the next release cycle but is still in the tree since like 6 months.\nPotential breaking change, since some cases (such as #25658) will change from a warning to an error. But the warning stating that it will be a hard error in the next release has been there for 6 months now.\nI think it's safe to break this code. ^_^", "tree": {"sha": "136c7956fb043cf40cc525a7f7d66d31ae50d493", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/136c7956fb043cf40cc525a7f7d66d31ae50d493"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/371bf0eda20eed78d5ed366426acd167b0d15b2e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/371bf0eda20eed78d5ed366426acd167b0d15b2e", "html_url": "https://github.com/rust-lang/rust/commit/371bf0eda20eed78d5ed366426acd167b0d15b2e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/371bf0eda20eed78d5ed366426acd167b0d15b2e/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ec872dc8a3f008299ca1508105ee064d1f0f0367", "url": "https://api.github.com/repos/rust-lang/rust/commits/ec872dc8a3f008299ca1508105ee064d1f0f0367", "html_url": "https://github.com/rust-lang/rust/commit/ec872dc8a3f008299ca1508105ee064d1f0f0367"}, {"sha": "4dab8ae64e816fc098fee2d75fb053df3f585ad2", "url": "https://api.github.com/repos/rust-lang/rust/commits/4dab8ae64e816fc098fee2d75fb053df3f585ad2", "html_url": "https://github.com/rust-lang/rust/commit/4dab8ae64e816fc098fee2d75fb053df3f585ad2"}], "stats": {"total": 306, "additions": 29, "deletions": 277}, "files": [{"sha": "bbe989b0f40abb7e1b565675b22332983849bd46", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 18, "deletions": 233, "changes": 251, "blob_url": "https://github.com/rust-lang/rust/blob/371bf0eda20eed78d5ed366426acd167b0d15b2e/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/371bf0eda20eed78d5ed366426acd167b0d15b2e/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=371bf0eda20eed78d5ed366426acd167b0d15b2e", "patch": "@@ -349,203 +349,12 @@ fn check_rhs(cx: &mut ExtCtxt, rhs: &TokenTree) -> bool {\n     false\n }\n \n-// Issue 30450: when we are through a warning cycle, we can just error\n-// on all failure conditions and remove this struct and enum.\n-\n-#[derive(Debug)]\n-struct OnFail {\n-    saw_failure: bool,\n-    action: OnFailAction,\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq)]\n-enum OnFailAction { Warn, Error, DoNothing }\n-\n-impl OnFail {\n-    fn warn() -> OnFail { OnFail { saw_failure: false, action: OnFailAction::Warn } }\n-    fn error() -> OnFail { OnFail { saw_failure: false, action: OnFailAction::Error } }\n-    fn do_nothing() -> OnFail { OnFail { saw_failure: false, action: OnFailAction::DoNothing } }\n-    fn react(&mut self, cx: &mut ExtCtxt, sp: Span, msg: &str, help: Option<&str>) {\n-        match self.action {\n-            OnFailAction::DoNothing => {}\n-            OnFailAction::Error => {\n-                let mut err = cx.struct_span_err(sp, msg);\n-                if let Some(msg) = help { err.span_help(sp, msg); }\n-                err.emit();\n-            }\n-            OnFailAction::Warn => {\n-                let mut warn = cx.struct_span_warn(sp, msg);\n-                if let Some(msg) = help { warn.span_help(sp, msg); }\n-                warn.span_note(sp, \"The above warning will be a hard error in the next release.\")\n-                    .emit();\n-            }\n-        };\n-        self.saw_failure = true;\n-    }\n-}\n-\n fn check_matcher(cx: &mut ExtCtxt, matcher: &[TokenTree]) -> bool {\n-    // Issue 30450: when we are through a warning cycle, we can just\n-    // error on all failure conditions (and remove check_matcher_old).\n-\n-    // First run the old-pass, but *only* to find out if it would have failed.\n-    let mut on_fail = OnFail::do_nothing();\n-    check_matcher_old(cx, matcher.iter(), &Eof, &mut on_fail);\n-    // Then run the new pass, but merely warn if the old pass accepts and new pass rejects.\n-    // (Note this silently accepts code if new pass accepts.)\n-    let mut on_fail = if on_fail.saw_failure {\n-        OnFail::error()\n-    } else {\n-        OnFail::warn()\n-    };\n-    check_matcher_new(cx, matcher, &mut on_fail);\n-    // matcher is valid if the new pass didn't see any error,\n-    // or if errors were considered warnings\n-    on_fail.action != OnFailAction::Error || !on_fail.saw_failure\n-}\n-\n-// returns the last token that was checked, for TokenTree::Sequence.\n-// return value is used by recursive calls.\n-fn check_matcher_old<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token, on_fail: &mut OnFail)\n--> Option<(Span, Token)> where I: Iterator<Item=&'a TokenTree> {\n-    use print::pprust::token_to_string;\n-    use std::iter::once;\n-\n-    let mut last = None;\n-\n-    // 2. For each token T in M:\n-    let mut tokens = matcher.peekable();\n-    while let Some(token) = tokens.next() {\n-        last = match *token {\n-            TokenTree::Token(sp, MatchNt(ref name, ref frag_spec)) => {\n-                // ii. If T is a simple NT, look ahead to the next token T' in\n-                // M. If T' is in the set FOLLOW(NT), continue. Else; reject.\n-                if can_be_followed_by_any(&frag_spec.name.as_str()) {\n-                    continue\n-                } else {\n-                    let next_token = match tokens.peek() {\n-                        // If T' closes a complex NT, replace T' with F\n-                        Some(&&TokenTree::Token(_, CloseDelim(_))) => follow.clone(),\n-                        Some(&&TokenTree::Token(_, ref tok)) => tok.clone(),\n-                        Some(&&TokenTree::Sequence(sp, _)) => {\n-                            // Be conservative around sequences: to be\n-                            // more specific, we would need to\n-                            // consider FIRST sets, but also the\n-                            // possibility that the sequence occurred\n-                            // zero times (in which case we need to\n-                            // look at the token that follows the\n-                            // sequence, which may itself be a sequence,\n-                            // and so on).\n-                            on_fail.react(cx, sp,\n-                                          &format!(\"`${0}:{1}` is followed by a \\\n-                                                    sequence repetition, which is not \\\n-                                                    allowed for `{1}` fragments\",\n-                                                   name, frag_spec),\n-                                          None);\n-                            Eof\n-                        },\n-                        // die next iteration\n-                        Some(&&TokenTree::Delimited(_, ref delim)) => delim.close_token(),\n-                        // else, we're at the end of the macro or sequence\n-                        None => follow.clone()\n-                    };\n-\n-                    let tok = if let TokenTree::Token(_, ref tok) = *token {\n-                        tok\n-                    } else {\n-                        unreachable!()\n-                    };\n-\n-                    // If T' is in the set FOLLOW(NT), continue. Else, reject.\n-                    match (&next_token, is_in_follow(cx, &next_token, &frag_spec.name.as_str())) {\n-                        (_, Err((msg, _))) => {\n-                            // no need for help message, those messages\n-                            // are never emitted anyway...\n-                            on_fail.react(cx, sp, &msg, None);\n-                            continue\n-                        }\n-                        (&Eof, _) => return Some((sp, tok.clone())),\n-                        (_, Ok(true)) => continue,\n-                        (next, Ok(false)) => {\n-                            on_fail.react(cx, sp, &format!(\"`${0}:{1}` is followed by `{2}`, which \\\n-                                                      is not allowed for `{1}` fragments\",\n-                                                     name, frag_spec,\n-                                                     token_to_string(next)), None);\n-                            continue\n-                        },\n-                    }\n-                }\n-            },\n-            TokenTree::Sequence(sp, ref seq) => {\n-                // iii. Else, T is a complex NT.\n-                match seq.separator {\n-                    // If T has the form $(...)U+ or $(...)U* for some token U,\n-                    // run the algorithm on the contents with F set to U. If it\n-                    // accepts, continue, else, reject.\n-                    Some(ref u) => {\n-                        let last = check_matcher_old(cx, seq.tts.iter(), u, on_fail);\n-                        match last {\n-                            // Since the delimiter isn't required after the last\n-                            // repetition, make sure that the *next* token is\n-                            // sane. This doesn't actually compute the FIRST of\n-                            // the rest of the matcher yet, it only considers\n-                            // single tokens and simple NTs. This is imprecise,\n-                            // but conservatively correct.\n-                            Some((span, tok)) => {\n-                                let fol = match tokens.peek() {\n-                                    Some(&&TokenTree::Token(_, ref tok)) => tok.clone(),\n-                                    Some(&&TokenTree::Delimited(_, ref delim)) =>\n-                                        delim.close_token(),\n-                                    Some(_) => {\n-                                        on_fail.react(cx, sp, \"sequence repetition followed by \\\n-                                                another sequence repetition, which is not allowed\",\n-                                                      None);\n-                                        Eof\n-                                    },\n-                                    None => Eof\n-                                };\n-                                check_matcher_old(cx, once(&TokenTree::Token(span, tok.clone())),\n-                                                  &fol, on_fail)\n-                            },\n-                            None => last,\n-                        }\n-                    },\n-                    // If T has the form $(...)+ or $(...)*, run the algorithm\n-                    // on the contents with F set to the token following the\n-                    // sequence. If it accepts, continue, else, reject.\n-                    None => {\n-                        let fol = match tokens.peek() {\n-                            Some(&&TokenTree::Token(_, ref tok)) => tok.clone(),\n-                            Some(&&TokenTree::Delimited(_, ref delim)) => delim.close_token(),\n-                            Some(_) => {\n-                                on_fail.react(cx, sp, \"sequence repetition followed by another \\\n-                                             sequence repetition, which is not allowed\", None);\n-                                Eof\n-                            },\n-                            None => Eof\n-                        };\n-                        check_matcher_old(cx, seq.tts.iter(), &fol, on_fail)\n-                    }\n-                }\n-            },\n-            TokenTree::Token(..) => {\n-                // i. If T is not an NT, continue.\n-                continue\n-            },\n-            TokenTree::Delimited(_, ref tts) => {\n-                // if we don't pass in that close delimiter, we'll incorrectly consider the matcher\n-                // `{ $foo:ty }` as having a follow that isn't `RBrace`\n-                check_matcher_old(cx, tts.tts.iter(), &tts.close_token(), on_fail)\n-            }\n-        }\n-    }\n-    last\n-}\n-\n-fn check_matcher_new(cx: &mut ExtCtxt, matcher: &[TokenTree], on_fail: &mut OnFail) {\n     let first_sets = FirstSets::new(matcher);\n     let empty_suffix = TokenSet::empty();\n-    check_matcher_core(cx, &first_sets, matcher, &empty_suffix, on_fail);\n+    let err = cx.parse_sess.span_diagnostic.err_count();\n+    check_matcher_core(cx, &first_sets, matcher, &empty_suffix);\n+    err == cx.parse_sess.span_diagnostic.err_count()\n }\n \n // The FirstSets for a matcher is a mapping from subsequences in the\n@@ -785,8 +594,7 @@ impl TokenSet {\n fn check_matcher_core(cx: &mut ExtCtxt,\n                       first_sets: &FirstSets,\n                       matcher: &[TokenTree],\n-                      follow: &TokenSet,\n-                      on_fail: &mut OnFail) -> TokenSet {\n+                      follow: &TokenSet) -> TokenSet {\n     use print::pprust::token_to_string;\n \n     let mut last = TokenSet::empty();\n@@ -815,11 +623,11 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n             TokenTree::Token(sp, ref tok) => {\n                 let can_be_followed_by_any;\n                 if let Err(bad_frag) = has_legal_fragment_specifier(tok) {\n-                    on_fail.react(cx, sp,\n-                                  &format!(\"invalid fragment specifier `{}`\", bad_frag),\n-                                  Some(\"valid fragment specifiers are `ident`, `block`, \\\n-                                        `stmt`, `expr`, `pat`, `ty`, `path`, `meta`, `tt` \\\n-                                        and `item`\"));\n+                    cx.struct_span_err(sp, &format!(\"invalid fragment specifier `{}`\", bad_frag))\n+                        .help(\"valid fragment specifiers are `ident`, `block`, \\\n+                               `stmt`, `expr`, `pat`, `ty`, `path`, `meta`, `tt` \\\n+                               and `item`\")\n+                        .emit();\n                     // (This eliminates false positives and duplicates\n                     // from error messages.)\n                     can_be_followed_by_any = true;\n@@ -840,7 +648,7 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n             }\n             TokenTree::Delimited(_, ref d) => {\n                 let my_suffix = TokenSet::singleton((d.close_span, Token::CloseDelim(d.delim)));\n-                check_matcher_core(cx, first_sets, &d.tts, &my_suffix, on_fail);\n+                check_matcher_core(cx, first_sets, &d.tts, &my_suffix);\n                 // don't track non NT tokens\n                 last.replace_with_irrelevant();\n \n@@ -872,7 +680,7 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n                 // At this point, `suffix_first` is built, and\n                 // `my_suffix` is some TokenSet that we can use\n                 // for checking the interior of `seq_rep`.\n-                let next = check_matcher_core(cx, first_sets, &seq_rep.tts, my_suffix, on_fail);\n+                let next = check_matcher_core(cx, first_sets, &seq_rep.tts, my_suffix);\n                 if next.maybe_empty {\n                     last.add_all(&next);\n                 } else {\n@@ -894,7 +702,7 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n                 for &(sp, ref next_token) in &suffix_first.tokens {\n                     match is_in_follow(cx, next_token, &frag_spec.name.as_str()) {\n                         Err((msg, help)) => {\n-                            on_fail.react(cx, sp, &msg, Some(help));\n+                            cx.struct_span_err(sp, &msg).help(help).emit();\n                             // don't bother reporting every source of\n                             // conflict for a particular element of `last`.\n                             continue 'each_last;\n@@ -909,15 +717,14 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n                                 \"may be\"\n                             };\n \n-                            on_fail.react(\n-                                cx, sp,\n+                            cx.span_err(\n+                                sp,\n                                 &format!(\"`${name}:{frag}` {may_be} followed by `{next}`, which \\\n                                           is not allowed for `{frag}` fragments\",\n                                          name=name,\n                                          frag=frag_spec,\n                                          next=token_to_string(next_token),\n-                                         may_be=may_be),\n-                                None\n+                                         may_be=may_be)\n                             );\n                         }\n                     }\n@@ -947,33 +754,11 @@ fn token_can_be_followed_by_any(tok: &Token) -> bool {\n /// ANYTHING without fear of future compatibility hazards).\n fn frag_can_be_followed_by_any(frag: &str) -> bool {\n     match frag {\n-        \"item\" |  // always terminated by `}` or `;`\n-        \"block\" | // exactly one token tree\n-        \"ident\" | // exactly one token tree\n-        \"meta\" |  // exactly one token tree\n-        \"tt\" =>    // exactly one token tree\n-            true,\n-\n-        _ =>\n-            false,\n-    }\n-}\n-\n-/// True if a fragment of type `frag` can be followed by any sort of\n-/// token.  We use this (among other things) as a useful approximation\n-/// for when `frag` can be followed by a repetition like `$(...)*` or\n-/// `$(...)+`. In general, these can be a bit tricky to reason about,\n-/// so we adopt a conservative position that says that any fragment\n-/// specifier which consumes at most one token tree can be followed by\n-/// a fragment specifier (indeed, these fragments can be followed by\n-/// ANYTHING without fear of future compatibility hazards).\n-fn can_be_followed_by_any(frag: &str) -> bool {\n-    match frag {\n-        \"item\" |  // always terminated by `}` or `;`\n+        \"item\"  | // always terminated by `}` or `;`\n         \"block\" | // exactly one token tree\n         \"ident\" | // exactly one token tree\n-        \"meta\" |  // exactly one token tree\n-        \"tt\" =>    // exactly one token tree\n+        \"meta\"  | // exactly one token tree\n+        \"tt\" =>   // exactly one token tree\n             true,\n \n         _ =>"}, {"sha": "5cacf8f53c62edbd946eefa1f02d0514a24b54b7", "filename": "src/test/compile-fail/issue-30715.rs", "status": "removed", "additions": 0, "deletions": 33, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/ec872dc8a3f008299ca1508105ee064d1f0f0367/src%2Ftest%2Fcompile-fail%2Fissue-30715.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec872dc8a3f008299ca1508105ee064d1f0f0367/src%2Ftest%2Fcompile-fail%2Fissue-30715.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-30715.rs?ref=ec872dc8a3f008299ca1508105ee064d1f0f0367", "patch": "@@ -1,33 +0,0 @@\n-// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// compile-flags: -Z continue-parse-after-error\n-\n-macro_rules! parallel {\n-    (\n-        // If future has `pred`/`moelarry` fragments (where \"pred\" is\n-        // \"like expr, but with `{` in its FOLLOW set\"), then could\n-        // use `pred` instead of future-proof erroring here. See also:\n-        //\n-        // https://github.com/rust-lang/rfcs/pull/1384#issuecomment-160165525\n-        for $id:ident in $iter:expr { //~ WARN `$iter:expr` is followed by `{`\n-            $( $inner:expr; )*\n-        }\n-    ) => {};\n-}\n-\n-\n-fn main() {\n-    parallel! {\n-        for i in 0..n {\n-            x += i; //~ ERROR expected `:`, found `+=`\n-        } //~ ERROR unexpected end of macro invocation\n-    }\n-}"}, {"sha": "001bc42274b4daea014bfc5a56f584e27f9dff19", "filename": "src/test/compile-fail/macro-follow.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/371bf0eda20eed78d5ed366426acd167b0d15b2e/src%2Ftest%2Fcompile-fail%2Fmacro-follow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/371bf0eda20eed78d5ed366426acd167b0d15b2e/src%2Ftest%2Fcompile-fail%2Fmacro-follow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fmacro-follow.rs?ref=371bf0eda20eed78d5ed366426acd167b0d15b2e", "patch": "@@ -12,9 +12,9 @@\n \n // FOLLOW(pat) = {FatArrow, Comma, Eq, Or, Ident(if), Ident(in)}\n macro_rules! follow_pat {\n-    ($p:pat ()) => {};       //~WARN  `$p:pat` is followed by `(`\n-    ($p:pat []) => {};       //~WARN  `$p:pat` is followed by `[`\n-    ($p:pat {}) => {};       //~WARN  `$p:pat` is followed by `{`\n+    ($p:pat ()) => {};       //~ERROR  `$p:pat` is followed by `(`\n+    ($p:pat []) => {};       //~ERROR  `$p:pat` is followed by `[`\n+    ($p:pat {}) => {};       //~ERROR  `$p:pat` is followed by `{`\n     ($p:pat :) => {};        //~ERROR `$p:pat` is followed by `:`\n     ($p:pat >) => {};        //~ERROR `$p:pat` is followed by `>`\n     ($p:pat +) => {};        //~ERROR `$p:pat` is followed by `+`\n@@ -32,9 +32,9 @@ macro_rules! follow_pat {\n }\n // FOLLOW(expr) = {FatArrow, Comma, Semicolon}\n macro_rules! follow_expr {\n-    ($e:expr ()) => {};       //~WARN  `$e:expr` is followed by `(`\n-    ($e:expr []) => {};       //~WARN  `$e:expr` is followed by `[`\n-    ($e:expr {}) => {};       //~WARN  `$e:expr` is followed by `{`\n+    ($e:expr ()) => {};       //~ERROR  `$e:expr` is followed by `(`\n+    ($e:expr []) => {};       //~ERROR  `$e:expr` is followed by `[`\n+    ($e:expr {}) => {};       //~ERROR  `$e:expr` is followed by `{`\n     ($e:expr =) => {};        //~ERROR `$e:expr` is followed by `=`\n     ($e:expr |) => {};        //~ERROR `$e:expr` is followed by `|`\n     ($e:expr :) => {};        //~ERROR `$e:expr` is followed by `:`\n@@ -57,7 +57,7 @@ macro_rules! follow_expr {\n // FOLLOW(ty) = {OpenDelim(Brace), Comma, FatArrow, Colon, Eq, Gt, Semi, Or,\n //               Ident(as), Ident(where), OpenDelim(Bracket), Nonterminal(Block)}\n macro_rules! follow_ty {\n-    ($t:ty ()) => {};       //~WARN  `$t:ty` is followed by `(`\n+    ($t:ty ()) => {};       //~ERROR  `$t:ty` is followed by `(`\n     ($t:ty []) => {};       // ok (RFC 1462)\n     ($t:ty +) => {};        //~ERROR `$t:ty` is followed by `+`\n     ($t:ty ident) => {};    //~ERROR `$t:ty` is followed by `ident`\n@@ -75,9 +75,9 @@ macro_rules! follow_ty {\n }\n // FOLLOW(stmt) = FOLLOW(expr)\n macro_rules! follow_stmt {\n-    ($s:stmt ()) => {};       //~WARN  `$s:stmt` is followed by `(`\n-    ($s:stmt []) => {};       //~WARN  `$s:stmt` is followed by `[`\n-    ($s:stmt {}) => {};       //~WARN  `$s:stmt` is followed by `{`\n+    ($s:stmt ()) => {};       //~ERROR  `$s:stmt` is followed by `(`\n+    ($s:stmt []) => {};       //~ERROR  `$s:stmt` is followed by `[`\n+    ($s:stmt {}) => {};       //~ERROR  `$s:stmt` is followed by `{`\n     ($s:stmt =) => {};        //~ERROR `$s:stmt` is followed by `=`\n     ($s:stmt |) => {};        //~ERROR `$s:stmt` is followed by `|`\n     ($s:stmt :) => {};        //~ERROR `$s:stmt` is followed by `:`\n@@ -99,7 +99,7 @@ macro_rules! follow_stmt {\n }\n // FOLLOW(path) = FOLLOW(ty)\n macro_rules! follow_path {\n-    ($p:path ()) => {};       //~WARN  `$p:path` is followed by `(`\n+    ($p:path ()) => {};       //~ERROR  `$p:path` is followed by `(`\n     ($p:path []) => {};       // ok (RFC 1462)\n     ($p:path +) => {};        //~ERROR `$p:path` is followed by `+`\n     ($p:path ident) => {};    //~ERROR `$p:path` is followed by `ident`"}]}