{"sha": "ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZmNDBlMzdiOThmYjQ0MzY2YTMyOWQxYjBkOTY0MmQ0NjJjYzZhYjY=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-05T11:17:56Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-06T11:04:02Z"}, "message": "Some code cleanup and tidy/test fixes", "tree": {"sha": "19ba8638a9ad0939e7f918765872f3c4e7c6bec1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/19ba8638a9ad0939e7f918765872f3c4e7c6bec1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "html_url": "https://github.com/rust-lang/rust/commit/ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "738e14565deb48800c06abc22f8e35e412f10010", "url": "https://api.github.com/repos/rust-lang/rust/commits/738e14565deb48800c06abc22f8e35e412f10010", "html_url": "https://github.com/rust-lang/rust/commit/738e14565deb48800c06abc22f8e35e412f10010"}], "stats": {"total": 210, "additions": 109, "deletions": 101}, "files": [{"sha": "1994cf491889bddd82e384f8a8aaa25504a6662e", "filename": "src/doc/unstable-book/src/language-features/plugin.md", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Fdoc%2Funstable-book%2Fsrc%2Flanguage-features%2Fplugin.md", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Fdoc%2Funstable-book%2Fsrc%2Flanguage-features%2Fplugin.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Funstable-book%2Fsrc%2Flanguage-features%2Fplugin.md?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -56,15 +56,15 @@ extern crate syntax_pos;\n extern crate rustc;\n extern crate rustc_plugin;\n \n-use syntax::parse::token;\n+use syntax::parse::token::{self, Token};\n use syntax::tokenstream::TokenTree;\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n use syntax::ext::build::AstBuilder;  // A trait for expr_usize.\n use syntax_pos::Span;\n use rustc_plugin::Registry;\n \n fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n-        -> Box<MacResult + 'static> {\n+        -> Box<dyn MacResult + 'static> {\n \n     static NUMERALS: &'static [(&'static str, usize)] = &[\n         (\"M\", 1000), (\"CM\", 900), (\"D\", 500), (\"CD\", 400),\n@@ -80,7 +80,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n     }\n \n     let text = match args[0] {\n-        TokenTree::Token(_, token::Ident(s)) => s.to_string(),\n+        TokenTree::Token(Token { kind: token::Ident(s, _), .. }) => s.to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}, {"sha": "6e4d0e881f76bffad08b2763c21f5db35b6b04fe", "filename": "src/librustc_lint/builtin.rs", "status": "modified", "additions": 3, "deletions": 9, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibrustc_lint%2Fbuiltin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibrustc_lint%2Fbuiltin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lint%2Fbuiltin.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -1414,15 +1414,9 @@ impl KeywordIdents {\n     fn check_tokens(&mut self, cx: &EarlyContext<'_>, tokens: TokenStream) {\n         for tt in tokens.into_trees() {\n             match tt {\n-                TokenTree::Token(token) => match token.ident() {\n-                    // only report non-raw idents\n-                    Some((ident, false)) => {\n-                        self.check_ident_token(cx, UnderMacro(true), ast::Ident {\n-                            span: token.span.substitute_dummy(ident.span),\n-                            ..ident\n-                        });\n-                    }\n-                    _ => {},\n+                // Only report non-raw idents.\n+                TokenTree::Token(token) => if let Some((ident, false)) = token.ident() {\n+                    self.check_ident_token(cx, UnderMacro(true), ident);\n                 }\n                 TokenTree::Delimited(_, _, tts) => {\n                     self.check_tokens(cx, tts)"}, {"sha": "edfe097c72f615c6a3340488b9db514d59a38848", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -483,7 +483,8 @@ impl MetaItem {\n             Some(TokenTree::Token(Token { kind: kind @ token::Ident(..), span })) |\n             Some(TokenTree::Token(Token { kind: kind @ token::ModSep, span })) => 'arm: {\n                 let mut segments = if let token::Ident(name, _) = kind {\n-                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. })) = tokens.peek() {\n+                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. }))\n+                            = tokens.peek() {\n                         tokens.next();\n                         vec![PathSegment::from_ident(Ident::new(name, span))]\n                     } else {\n@@ -493,12 +494,14 @@ impl MetaItem {\n                     vec![PathSegment::path_root(span)]\n                 };\n                 loop {\n-                    if let Some(TokenTree::Token(Token { kind: token::Ident(name, _), span })) = tokens.next() {\n+                    if let Some(TokenTree::Token(Token { kind: token::Ident(name, _), span }))\n+                            = tokens.next() {\n                         segments.push(PathSegment::from_ident(Ident::new(name, span)));\n                     } else {\n                         return None;\n                     }\n-                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. })) = tokens.peek() {\n+                    if let Some(TokenTree::Token(Token { kind: token::ModSep, .. }))\n+                            = tokens.peek() {\n                         tokens.next();\n                     } else {\n                         break;"}, {"sha": "9f01b9b9f9b58e98971935465136beaeef935434", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -77,7 +77,9 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt<'_>,\n         },\n         (3, Some(&TokenTree::Token(Token { kind: token::Ident(code, _), .. })),\n             Some(&TokenTree::Token(Token { kind: token::Comma, .. })),\n-            Some(&TokenTree::Token(Token { kind: token::Literal(token::Lit { symbol, .. }), .. }))) => {\n+            Some(&TokenTree::Token(Token {\n+                kind: token::Literal(token::Lit { symbol, .. }), ..\n+            }))) => {\n             (code, Some(symbol))\n         }\n         _ => unreachable!()"}, {"sha": "598c8459d159053ce822ef235e088fcff96707ba", "filename": "src/libsyntax/early_buffered_lints.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fearly_buffered_lints.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fearly_buffered_lints.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fearly_buffered_lints.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -3,7 +3,7 @@\n //! Since we cannot have a dependency on `librustc`, we implement some types here that are somewhat\n //! redundant. Later, these types can be converted to types for use by the rest of the compiler.\n \n-use crate::syntax::ast::NodeId;\n+use crate::ast::NodeId;\n use syntax_pos::MultiSpan;\n \n /// Since we cannot import `LintId`s from `rustc::lint`, we define some Ids here which can later be"}, {"sha": "ec7d7f705d8937ed5bcdba65c4274e8c1d5f9802", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 21, "deletions": 20, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -24,12 +24,12 @@ pub struct Delimited {\n \n impl Delimited {\n     /// Returns the opening delimiter (possibly `NoDelim`).\n-    pub fn open_token(&self) -> token::TokenKind {\n+    pub fn open_token(&self) -> TokenKind {\n         token::OpenDelim(self.delim)\n     }\n \n     /// Returns the closing delimiter (possibly `NoDelim`).\n-    pub fn close_token(&self) -> token::TokenKind {\n+    pub fn close_token(&self) -> TokenKind {\n         token::CloseDelim(self.delim)\n     }\n \n@@ -59,7 +59,7 @@ pub struct SequenceRepetition {\n     /// The sequence of token trees\n     pub tts: Vec<TokenTree>,\n     /// The optional separator\n-    pub separator: Option<token::TokenKind>,\n+    pub separator: Option<TokenKind>,\n     /// Whether the sequence can be repeated zero (*), or one or more times (+)\n     pub op: KleeneOp,\n     /// The number of `Match`s that appear in the sequence (and subsequences)\n@@ -210,20 +210,21 @@ pub fn parse(\n         match tree {\n             TokenTree::MetaVar(start_sp, ident) if expect_matchers => {\n                 let span = match trees.next() {\n-                    Some(tokenstream::TokenTree::Token(Token { kind: token::Colon, span })) => match trees.next() {\n-                        Some(tokenstream::TokenTree::Token(token)) => match token.ident() {\n-                            Some((kind, _)) => {\n-                                let span = token.span.with_lo(start_sp.lo());\n-                                result.push(TokenTree::MetaVarDecl(span, ident, kind));\n-                                continue;\n-                            }\n-                            _ => token.span,\n+                    Some(tokenstream::TokenTree::Token(Token { kind: token::Colon, span })) =>\n+                        match trees.next() {\n+                            Some(tokenstream::TokenTree::Token(token)) => match token.ident() {\n+                                Some((kind, _)) => {\n+                                    let span = token.span.with_lo(start_sp.lo());\n+                                    result.push(TokenTree::MetaVarDecl(span, ident, kind));\n+                                    continue;\n+                                }\n+                                _ => token.span,\n+                            },\n+                            tree => tree\n+                                .as_ref()\n+                                .map(tokenstream::TokenTree::span)\n+                                .unwrap_or(span),\n                         },\n-                        tree => tree\n-                            .as_ref()\n-                            .map(tokenstream::TokenTree::span)\n-                            .unwrap_or(span),\n-                    },\n                     tree => tree\n                         .as_ref()\n                         .map(tokenstream::TokenTree::span)\n@@ -370,7 +371,7 @@ where\n \n /// Takes a token and returns `Some(KleeneOp)` if the token is `+` `*` or `?`. Otherwise, return\n /// `None`.\n-fn kleene_op(token: &token::TokenKind) -> Option<KleeneOp> {\n+fn kleene_op(token: &TokenKind) -> Option<KleeneOp> {\n     match *token {\n         token::BinOp(token::Star) => Some(KleeneOp::ZeroOrMore),\n         token::BinOp(token::Plus) => Some(KleeneOp::OneOrMore),\n@@ -423,7 +424,7 @@ fn parse_sep_and_kleene_op<I>(\n     attrs: &[ast::Attribute],\n     edition: Edition,\n     macro_node_id: NodeId,\n-) -> (Option<token::TokenKind>, KleeneOp)\n+) -> (Option<TokenKind>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -448,7 +449,7 @@ fn parse_sep_and_kleene_op_2015<I>(\n     _features: &Features,\n     _attrs: &[ast::Attribute],\n     macro_node_id: NodeId,\n-) -> (Option<token::TokenKind>, KleeneOp)\n+) -> (Option<TokenKind>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -566,7 +567,7 @@ fn parse_sep_and_kleene_op_2018<I>(\n     sess: &ParseSess,\n     _features: &Features,\n     _attrs: &[ast::Attribute],\n-) -> (Option<token::TokenKind>, KleeneOp)\n+) -> (Option<TokenKind>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {"}, {"sha": "90a9cc8f34d2d51f506c120db5e598ec2d45c14b", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -242,7 +242,7 @@ pub fn transcribe(\n                         Ident::new(ident.name, ident.span.apply_mark(cx.current_expansion.mark));\n                     sp = sp.apply_mark(cx.current_expansion.mark);\n                     result.push(TokenTree::token(token::Dollar, sp).into());\n-                    result.push(TokenTree::token(token::TokenKind::from_ast_ident(ident), sp).into());\n+                    result.push(TokenTree::token(TokenKind::from_ast_ident(ident), sp).into());\n                 }\n             }\n "}, {"sha": "c69364d4e19bbb7eb790abadb71849aeb297b2dd", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -137,12 +137,6 @@ pub mod util {\n \n pub mod json;\n \n-pub mod syntax {\n-    pub use crate::ext;\n-    pub use crate::parse;\n-    pub use crate::ast;\n-}\n-\n pub mod ast;\n pub mod attr;\n pub mod source_map;"}, {"sha": "7f0bf4a90508bcab564e28b04d40b4a4fe0afdeb", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -2,8 +2,9 @@ use crate::ast::{\n     self, Arg, BinOpKind, BindingMode, BlockCheckMode, Expr, ExprKind, Ident, Item, ItemKind,\n     Mutability, Pat, PatKind, PathSegment, QSelf, Ty, TyKind, VariantData,\n };\n-use crate::parse::{SeqSep, token, PResult, Parser};\n+use crate::parse::{SeqSep, PResult, Parser};\n use crate::parse::parser::{BlockMode, PathStyle, SemiColonMode, TokenType, TokenExpectType};\n+use crate::parse::token::{self, TokenKind};\n use crate::print::pprust;\n use crate::ptr::P;\n use crate::source_map::Spanned;\n@@ -229,8 +230,8 @@ impl<'a> Parser<'a> {\n \n     pub fn expected_one_of_not_found(\n         &mut self,\n-        edible: &[token::TokenKind],\n-        inedible: &[token::TokenKind],\n+        edible: &[TokenKind],\n+        inedible: &[TokenKind],\n     ) -> PResult<'a, bool /* recovered */> {\n         fn tokens_to_string(tokens: &[TokenType]) -> String {\n             let mut i = tokens.iter();\n@@ -368,7 +369,7 @@ impl<'a> Parser<'a> {\n \n     /// Eats and discards tokens until one of `kets` is encountered. Respects token trees,\n     /// passes through any errors encountered. Used for error recovery.\n-    crate fn eat_to_tokens(&mut self, kets: &[&token::TokenKind]) {\n+    crate fn eat_to_tokens(&mut self, kets: &[&TokenKind]) {\n         let handler = self.diagnostic();\n \n         if let Err(ref mut err) = self.parse_seq_to_before_tokens(\n@@ -388,7 +389,7 @@ impl<'a> Parser<'a> {\n     /// let _ = vec![1, 2, 3].into_iter().collect::<Vec<usize>>>>();\n     ///                                                        ^^ help: remove extra angle brackets\n     /// ```\n-    crate fn check_trailing_angle_brackets(&mut self, segment: &PathSegment, end: token::TokenKind) {\n+    crate fn check_trailing_angle_brackets(&mut self, segment: &PathSegment, end: TokenKind) {\n         // This function is intended to be invoked after parsing a path segment where there are two\n         // cases:\n         //\n@@ -726,7 +727,7 @@ impl<'a> Parser<'a> {\n     /// closing delimiter.\n     pub fn unexpected_try_recover(\n         &mut self,\n-        t: &token::TokenKind,\n+        t: &TokenKind,\n     ) -> PResult<'a, bool /* recovered */> {\n         let token_str = pprust::token_to_string(t);\n         let this_token_str = self.this_token_descr();\n@@ -903,7 +904,7 @@ impl<'a> Parser<'a> {\n \n     crate fn recover_closing_delimiter(\n         &mut self,\n-        tokens: &[token::TokenKind],\n+        tokens: &[TokenKind],\n         mut err: DiagnosticBuilder<'a>,\n     ) -> PResult<'a, bool> {\n         let mut pos = None;"}, {"sha": "7d5356ffe4d8dc08835e7f4de3fdb94caaeb7291", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -272,7 +272,8 @@ impl<'a> Parser<'a> {\n         if self.token == token::Dot {\n             // Attempt to recover `.4` as `0.4`.\n             recovered = self.look_ahead(1, |t| {\n-                if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = t.kind {\n+                if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix })\n+                        = t.kind {\n                     let next_span = self.look_ahead_span(1);\n                     if self.span.hi() == next_span.lo() {\n                         let s = String::from(\"0.\") + &symbol.as_str();"}, {"sha": "063823bbf4d11a26282cb7f7b4980b61ac1fe902", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 13, "deletions": 6, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -5,7 +5,8 @@ use crate::early_buffered_lints::{BufferedEarlyLint, BufferedEarlyLintId};\n use crate::source_map::{SourceMap, FilePathMapping};\n use crate::feature_gate::UnstableFeatures;\n use crate::parse::parser::Parser;\n-use crate::syntax::parse::parser::emit_unclosed_delims;\n+use crate::parse::parser::emit_unclosed_delims;\n+use crate::parse::token::TokenKind;\n use crate::tokenstream::{TokenStream, TokenTree};\n use crate::diagnostics::plugin::ErrorMap;\n use crate::print::pprust::token_to_string;\n@@ -358,13 +359,13 @@ pub fn stream_to_parser_with_base_dir<'a>(\n /// A sequence separator.\n pub struct SeqSep {\n     /// The seperator token.\n-    pub sep: Option<token::TokenKind>,\n+    pub sep: Option<TokenKind>,\n     /// `true` if a trailing separator is allowed.\n     pub trailing_sep_allowed: bool,\n }\n \n impl SeqSep {\n-    pub fn trailing_allowed(t: token::TokenKind) -> SeqSep {\n+    pub fn trailing_allowed(t: TokenKind) -> SeqSep {\n         SeqSep {\n             sep: Some(t),\n             trailing_sep_allowed: true,\n@@ -426,7 +427,9 @@ mod tests {\n             match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n                 (\n                     4,\n-                    Some(&TokenTree::Token(Token { kind: token::Ident(name_macro_rules, false), .. })),\n+                    Some(&TokenTree::Token(Token {\n+                        kind: token::Ident(name_macro_rules, false), ..\n+                    })),\n                     Some(&TokenTree::Token(Token { kind: token::Not, .. })),\n                     Some(&TokenTree::Token(Token { kind: token::Ident(name_zip, false), .. })),\n                     Some(&TokenTree::Delimited(_, macro_delim, ref macro_tts)),\n@@ -446,7 +449,9 @@ mod tests {\n                                 (\n                                     2,\n                                     Some(&TokenTree::Token(Token { kind: token::Dollar, .. })),\n-                                    Some(&TokenTree::Token(Token { kind: token::Ident(name, false), .. })),\n+                                    Some(&TokenTree::Token(Token {\n+                                        kind: token::Ident(name, false), ..\n+                                    })),\n                                 )\n                                 if first_delim == token::Paren && name.as_str() == \"a\" => {},\n                                 _ => panic!(\"value 3: {:?} {:?}\", first_delim, first_tts),\n@@ -456,7 +461,9 @@ mod tests {\n                                 (\n                                     2,\n                                     Some(&TokenTree::Token(Token { kind: token::Dollar, .. })),\n-                                    Some(&TokenTree::Token(Token { kind: token::Ident(name, false), .. })),\n+                                    Some(&TokenTree::Token(Token {\n+                                        kind: token::Ident(name, false), ..\n+                                    })),\n                                 )\n                                 if second_delim == token::Paren && name.as_str() == \"a\" => {},\n                                 _ => panic!(\"value 4: {:?} {:?}\", second_delim, second_tts),"}, {"sha": "51bfe3527cf4dfa099e875aba1c75a69dc8170d4", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 30, "deletions": 25, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -38,7 +38,7 @@ use crate::source_map::{self, SourceMap, Spanned, respan};\n use crate::parse::{SeqSep, classify, literal, token};\n use crate::parse::lexer::UnmatchedBrace;\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n-use crate::parse::token::{Token, DelimToken};\n+use crate::parse::token::{Token, TokenKind, DelimToken};\n use crate::parse::{new_sub_parser_from_file, ParseSess, Directory, DirectoryOwnership};\n use crate::util::parser::{AssocOp, Fixity};\n use crate::print::pprust;\n@@ -337,8 +337,8 @@ impl TokenCursor {\n     }\n \n     fn next_desugared(&mut self) -> Token {\n-        let (sp, name) = match self.next() {\n-            Token { span, kind: token::DocComment(name) } => (span, name),\n+        let (name, sp) = match self.next() {\n+            Token { kind: token::DocComment(name), span } => (name, span),\n             tok => return tok,\n         };\n \n@@ -364,7 +364,7 @@ impl TokenCursor {\n             [\n                 TokenTree::token(token::Ident(sym::doc, false), sp),\n                 TokenTree::token(token::Eq, sp),\n-                TokenTree::token(token::TokenKind::lit(\n+                TokenTree::token(TokenKind::lit(\n                     token::StrRaw(num_of_hashes), Symbol::intern(&stripped), None\n                 ), sp),\n             ]\n@@ -389,7 +389,7 @@ impl TokenCursor {\n \n #[derive(Clone, PartialEq)]\n crate enum TokenType {\n-    Token(token::TokenKind),\n+    Token(TokenKind),\n     Keyword(Symbol),\n     Operator,\n     Lifetime,\n@@ -419,7 +419,7 @@ impl TokenType {\n ///\n /// Types can also be of the form `IDENT(u8, u8) -> u8`, however this assumes\n /// that `IDENT` is not the ident of a fn trait.\n-fn can_continue_type_after_non_fn_ident(t: &token::TokenKind) -> bool {\n+fn can_continue_type_after_non_fn_ident(t: &TokenKind) -> bool {\n     t == &token::ModSep || t == &token::Lt ||\n     t == &token::BinOp(token::Shl)\n }\n@@ -565,7 +565,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Expects and consumes the token `t`. Signals an error if the next token is not `t`.\n-    pub fn expect(&mut self, t: &token::TokenKind) -> PResult<'a, bool /* recovered */> {\n+    pub fn expect(&mut self, t: &TokenKind) -> PResult<'a, bool /* recovered */> {\n         if self.expected_tokens.is_empty() {\n             if self.token == *t {\n                 self.bump();\n@@ -583,8 +583,8 @@ impl<'a> Parser<'a> {\n     /// anything.  Signal a fatal error if next token is unexpected.\n     pub fn expect_one_of(\n         &mut self,\n-        edible: &[token::TokenKind],\n-        inedible: &[token::TokenKind],\n+        edible: &[TokenKind],\n+        inedible: &[TokenKind],\n     ) -> PResult<'a, bool /* recovered */> {\n         if edible.contains(&self.token) {\n             self.bump();\n@@ -646,14 +646,14 @@ impl<'a> Parser<'a> {\n     ///\n     /// This method will automatically add `tok` to `expected_tokens` if `tok` is not\n     /// encountered.\n-    crate fn check(&mut self, tok: &token::TokenKind) -> bool {\n+    crate fn check(&mut self, tok: &TokenKind) -> bool {\n         let is_present = self.token == *tok;\n         if !is_present { self.expected_tokens.push(TokenType::Token(tok.clone())); }\n         is_present\n     }\n \n     /// Consumes a token 'tok' if it exists. Returns whether the given token was present.\n-    pub fn eat(&mut self, tok: &token::TokenKind) -> bool {\n+    pub fn eat(&mut self, tok: &TokenKind) -> bool {\n         let is_present = self.check(tok);\n         if is_present { self.bump() }\n         is_present\n@@ -889,7 +889,7 @@ impl<'a> Parser<'a> {\n     /// `f` must consume tokens until reaching the next separator or\n     /// closing bracket.\n     pub fn parse_seq_to_end<T, F>(&mut self,\n-                                  ket: &token::TokenKind,\n+                                  ket: &TokenKind,\n                                   sep: SeqSep,\n                                   f: F)\n                                   -> PResult<'a, Vec<T>> where\n@@ -907,7 +907,7 @@ impl<'a> Parser<'a> {\n     /// closing bracket.\n     pub fn parse_seq_to_before_end<T, F>(\n         &mut self,\n-        ket: &token::TokenKind,\n+        ket: &TokenKind,\n         sep: SeqSep,\n         f: F,\n     ) -> PResult<'a, (Vec<T>, bool)>\n@@ -918,7 +918,7 @@ impl<'a> Parser<'a> {\n \n     crate fn parse_seq_to_before_tokens<T, F>(\n         &mut self,\n-        kets: &[&token::TokenKind],\n+        kets: &[&TokenKind],\n         sep: SeqSep,\n         expect: TokenExpectType,\n         mut f: F,\n@@ -992,8 +992,8 @@ impl<'a> Parser<'a> {\n     /// closing bracket.\n     fn parse_unspanned_seq<T, F>(\n         &mut self,\n-        bra: &token::TokenKind,\n-        ket: &token::TokenKind,\n+        bra: &TokenKind,\n+        ket: &TokenKind,\n         sep: SeqSep,\n         f: F,\n     ) -> PResult<'a, Vec<T>> where\n@@ -1036,7 +1036,7 @@ impl<'a> Parser<'a> {\n \n     /// Advance the parser using provided token as a next one. Use this when\n     /// consuming a part of a token. For example a single `<` from `<<`.\n-    fn bump_with(&mut self, next: token::TokenKind, span: Span) {\n+    fn bump_with(&mut self, next: TokenKind, span: Span) {\n         self.prev_span = self.span.with_hi(span.lo());\n         // It would be incorrect to record the kind of the current token, but\n         // fortunately for tokens currently using `bump_with`, the\n@@ -1050,15 +1050,15 @@ impl<'a> Parser<'a> {\n         F: FnOnce(&Token) -> R,\n     {\n         if dist == 0 {\n-            // FIXME: Avoid cloning here.\n             return f(&self.token);\n         }\n \n         let frame = &self.token_cursor.frame;\n         f(&match frame.tree_cursor.look_ahead(dist - 1) {\n             Some(tree) => match tree {\n                 TokenTree::Token(token) => token,\n-                TokenTree::Delimited(dspan, delim, _) => Token::new(token::OpenDelim(delim), dspan.open),\n+                TokenTree::Delimited(dspan, delim, _) =>\n+                    Token::new(token::OpenDelim(delim), dspan.open),\n             }\n             None => Token::new(token::CloseDelim(frame.delim), frame.span.close)\n         })\n@@ -1768,7 +1768,7 @@ impl<'a> Parser<'a> {\n     fn parse_path_segment(&mut self, style: PathStyle) -> PResult<'a, PathSegment> {\n         let ident = self.parse_path_segment_ident()?;\n \n-        let is_args_start = |token: &token::TokenKind| match *token {\n+        let is_args_start = |token: &TokenKind| match *token {\n             token::Lt | token::BinOp(token::Shl) | token::OpenDelim(token::Paren)\n             | token::LArrow => true,\n             _ => false,\n@@ -1864,7 +1864,8 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_field_name(&mut self) -> PResult<'a, Ident> {\n-        if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = self.token.kind {\n+        if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) =\n+                self.token.kind {\n             self.expect_no_suffix(self.span, \"a tuple index\", suffix);\n             self.bump();\n             Ok(Ident::new(symbol, self.prev_span))\n@@ -2649,8 +2650,10 @@ impl<'a> Parser<'a> {\n                 // Interpolated identifier and lifetime tokens are replaced with usual identifier\n                 // and lifetime tokens, so the former are never encountered during normal parsing.\n                 match **nt {\n-                    token::NtIdent(ident, is_raw) => Token::new(token::Ident(ident.name, is_raw), ident.span),\n-                    token::NtLifetime(ident) => Token::new(token::Lifetime(ident.name), ident.span),\n+                    token::NtIdent(ident, is_raw) =>\n+                        Token::new(token::Ident(ident.name, is_raw), ident.span),\n+                    token::NtLifetime(ident) =>\n+                        Token::new(token::Lifetime(ident.name), ident.span),\n                     _ => return,\n                 }\n             }\n@@ -4481,7 +4484,9 @@ impl<'a> Parser<'a> {\n                 // We used to incorrectly stop parsing macro-expanded statements here.\n                 // If the next token will be an error anyway but could have parsed with the\n                 // earlier behavior, stop parsing here and emit a warning to avoid breakage.\n-                else if macro_legacy_warnings && self.token.can_begin_expr() && match self.token.kind {\n+                else if macro_legacy_warnings &&\n+                        self.token.can_begin_expr() &&\n+                        match self.token.kind {\n                     // These can continue an expression, so we can't stop parsing and warn.\n                     token::OpenDelim(token::Paren) | token::OpenDelim(token::Bracket) |\n                     token::BinOp(token::Minus) | token::BinOp(token::Star) |\n@@ -6409,7 +6414,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Given a termination token, parses all of the items in a module.\n-    fn parse_mod_items(&mut self, term: &token::TokenKind, inner_lo: Span) -> PResult<'a, Mod> {\n+    fn parse_mod_items(&mut self, term: &TokenKind, inner_lo: Span) -> PResult<'a, Mod> {\n         let mut items = vec![];\n         while let Some(item) = self.parse_item()? {\n             items.push(item);"}, {"sha": "28a733728bf7b6a5769688f2b4ffcae45943b5b1", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -5,11 +5,10 @@ pub use LitKind::*;\n pub use TokenKind::*;\n \n use crate::ast::{self};\n-use crate::parse::ParseSess;\n+use crate::parse::{parse_stream_from_source_str, ParseSess};\n use crate::print::pprust;\n use crate::ptr::P;\n use crate::symbol::kw;\n-use crate::syntax::parse::parse_stream_from_source_str;\n use crate::tokenstream::{self, DelimSpan, TokenStream, TokenTree};\n \n use syntax_pos::symbol::Symbol;"}, {"sha": "9dea3a4dcc144ed1981b073ab38bb6805d62d4c5", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -203,7 +203,8 @@ impl TokenStream {\n                 if let Some((_, next)) = iter.peek() {\n                     let sp = match (&ts, &next) {\n                         (_, (TokenTree::Token(Token { kind: token::Comma, .. }), _)) => continue,\n-                        ((TokenTree::Token(token_left), NonJoint), (TokenTree::Token(token_right), _))\n+                        ((TokenTree::Token(token_left), NonJoint),\n+                         (TokenTree::Token(token_right), _))\n                         if ((token_left.is_ident() && !token_left.is_reserved_ident())\n                             || token_left.is_lit()) &&\n                             ((token_right.is_ident() && !token_right.is_reserved_ident())\n@@ -575,7 +576,7 @@ impl DelimSpan {\n #[cfg(test)]\n mod tests {\n     use super::*;\n-    use crate::syntax::ast::Name;\n+    use crate::ast::Name;\n     use crate::with_default_globals;\n     use crate::util::parser_testing::string_to_stream;\n     use syntax_pos::{Span, BytePos, NO_EXPANSION};"}, {"sha": "3886528c74c2f6703b0d401e3f3ada021ee486f2", "filename": "src/libsyntax_ext/assert.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax_ext%2Fassert.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax_ext%2Fassert.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fassert.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -103,7 +103,8 @@ fn parse_assert<'a>(\n     //\n     // Parse this as an actual message, and suggest inserting a comma. Eventually, this should be\n     // turned into an error.\n-    let custom_message = if let token::Literal(token::Lit { kind: token::Str, .. }) = parser.token.kind {\n+    let custom_message = if let token::Literal(token::Lit { kind: token::Str, .. })\n+                                = parser.token.kind {\n         let mut err = cx.struct_span_warn(parser.span, \"unexpected string literal\");\n         let comma_span = cx.source_map().next_point(parser.prev_span);\n         err.span_suggestion_short("}, {"sha": "5dd4d6566ed1c3bfa2568218f09937dce57b9974", "filename": "src/libsyntax_pos/symbol.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax_pos%2Fsymbol.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Flibsyntax_pos%2Fsymbol.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fsymbol.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -921,10 +921,9 @@ pub struct Interner {\n \n impl Interner {\n     fn prefill(init: &[&'static str]) -> Self {\n-        let symbols = (0 .. init.len() as u32).map(Symbol::new);\n         Interner {\n-            strings: init.to_vec(),\n-            names: init.iter().copied().zip(symbols).collect(),\n+            strings: init.into(),\n+            names: init.iter().copied().zip((0..).map(Symbol::new)).collect(),\n             ..Default::default()\n         }\n     }"}, {"sha": "4d9e0129e54db2d4d3a6b4e49113742271298a87", "filename": "src/test/run-pass-fulldeps/auxiliary/roman-numerals.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Froman-numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff40e37b98fb44366a329d1b0d9642d462cc6ab6/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Froman-numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Froman-numerals.rs?ref=ff40e37b98fb44366a329d1b0d9642d462cc6ab6", "patch": "@@ -1,3 +1,9 @@\n+// WARNING WARNING WARNING WARNING WARNING\n+// =======================================\n+//\n+// This code also appears in src/doc/unstable-book/src/language-features/plugin.md.\n+// Please keep the two copies in sync!  FIXME: have rustdoc read this file\n+\n // force-host\n \n #![crate_type=\"dylib\"]\n@@ -8,21 +14,15 @@ extern crate syntax_pos;\n extern crate rustc;\n extern crate rustc_plugin;\n \n-use syntax::parse::token;\n+use syntax::parse::token::{self, Token};\n use syntax::tokenstream::TokenTree;\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacEager};\n-use syntax::ext::build::AstBuilder;  // trait for expr_usize\n+use syntax::ext::build::AstBuilder;  // A trait for expr_usize.\n use syntax_pos::Span;\n use rustc_plugin::Registry;\n \n-// WARNING WARNING WARNING WARNING WARNING\n-// =======================================\n-//\n-// This code also appears in src/doc/unstable-book/src/language-features/plugin.md.\n-// Please keep the two copies in sync!  FIXME: have rustdoc read this file\n-\n fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n-        -> Box<MacResult + 'static> {\n+        -> Box<dyn MacResult + 'static> {\n \n     static NUMERALS: &'static [(&'static str, usize)] = &[\n         (\"M\", 1000), (\"CM\", 900), (\"D\", 500), (\"CD\", 400),\n@@ -38,7 +38,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n     }\n \n     let text = match args[0] {\n-        TokenTree::Token(_, token::Ident(s, _)) => s.to_string(),\n+        TokenTree::Token(Token { kind: token::Ident(s, _), .. }) => s.to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}]}