{"sha": "3291ae33907f2a866ea6cea89113200555038d06", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMyOTFhZTMzOTA3ZjJhODY2ZWE2Y2VhODkxMTMyMDA1NTUwMzhkMDY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-01-15T19:40:45Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-01-15T19:40:45Z"}, "message": "Auto merge of #68254 - Dylan-DPC:rollup-9vhc59u, r=Dylan-DPC\n\nRollup of 6 pull requests\n\nSuccessful merges:\n\n - #68123 (Implement Cursor for linked lists. (RFC 2570).)\n - #68212 (Suggest to shorten temporary lifetime during method call inside generator)\n - #68232 (Optimize size/speed of Unicode datasets)\n - #68236 (Add some regression tests)\n - #68237 (Account for `Path`s in `is_suggestable_infer_ty`)\n - #68252 (remove redundant clones, found by clippy)\n\nFailed merges:\n\nr? @ghost", "tree": {"sha": "631b0f552543741c78dc50dd94d184db5d20e41b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/631b0f552543741c78dc50dd94d184db5d20e41b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3291ae33907f2a866ea6cea89113200555038d06", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3291ae33907f2a866ea6cea89113200555038d06", "html_url": "https://github.com/rust-lang/rust/commit/3291ae33907f2a866ea6cea89113200555038d06", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3291ae33907f2a866ea6cea89113200555038d06/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "faf45c5dadc04e2ee2f2b772402321e621899641", "url": "https://api.github.com/repos/rust-lang/rust/commits/faf45c5dadc04e2ee2f2b772402321e621899641", "html_url": "https://github.com/rust-lang/rust/commit/faf45c5dadc04e2ee2f2b772402321e621899641"}, {"sha": "4ff6195929b6649f776312f177ba601b2542872a", "url": "https://api.github.com/repos/rust-lang/rust/commits/4ff6195929b6649f776312f177ba601b2542872a", "html_url": "https://github.com/rust-lang/rust/commit/4ff6195929b6649f776312f177ba601b2542872a"}], "stats": {"total": 7197, "additions": 3903, "deletions": 3294}, "files": [{"sha": "d9761ce40927ce92d29daa23b4496e04b9e97e4f", "filename": ".gitignore", "status": "modified", "additions": 1, "deletions": 8, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/.gitignore", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/.gitignore", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.gitignore?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -34,14 +34,7 @@ __pycache__/\n # Created by default with `src/ci/docker/run.sh`:\n /obj/\n /rustllvm/\n-/src/libcore/unicode/DerivedCoreProperties.txt\n-/src/libcore/unicode/DerivedNormalizationProps.txt\n-/src/libcore/unicode/PropList.txt\n-/src/libcore/unicode/ReadMe.txt\n-/src/libcore/unicode/Scripts.txt\n-/src/libcore/unicode/SpecialCasing.txt\n-/src/libcore/unicode/UnicodeData.txt\n-/src/libcore/unicode/downloaded\n+/unicode-downloads\n /target/\n # Generated by compiletest for incremental:\n /tmp/"}, {"sha": "3359fe488f16b2cbdacd514c9dd489acad56ccdd", "filename": "Cargo.lock", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -4953,6 +4953,16 @@ version = \"1.10.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"612d636f949607bdf9b123b4a6f6d966dedf3ff669f7f045890d3a4a73948169\"\n \n+[[package]]\n+name = \"ucd-parse\"\n+version = \"0.1.4\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"ca6b52bf4da6512f0f07785a04769222e50d29639e7ecd016b7806fd2de306b4\"\n+dependencies = [\n+ \"lazy_static 1.3.0\",\n+ \"regex\",\n+]\n+\n [[package]]\n name = \"ucd-trie\"\n version = \"0.1.1\"\n@@ -4974,6 +4984,13 @@ dependencies = [\n  \"version_check 0.1.5\",\n ]\n \n+[[package]]\n+name = \"unicode-bdd\"\n+version = \"0.1.0\"\n+dependencies = [\n+ \"ucd-parse\",\n+]\n+\n [[package]]\n name = \"unicode-bidi\"\n version = \"0.3.4\""}, {"sha": "9d5c27b96df5d435daaded1ece44d1c8b6b613c1", "filename": "Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/Cargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/Cargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.toml?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -23,6 +23,7 @@ members = [\n   \"src/tools/rustfmt\",\n   \"src/tools/miri\",\n   \"src/tools/rustdoc-themes\",\n+  \"src/tools/unicode-table-generator\",\n ]\n exclude = [\n   \"build\","}, {"sha": "b88ca8a0fb0d10870be027d9863fe7224ad61aba", "filename": "src/liballoc/collections/linked_list.rs", "status": "modified", "additions": 555, "deletions": 24, "changes": 579, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Fliballoc%2Fcollections%2Flinked_list.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Fliballoc%2Fcollections%2Flinked_list.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Flinked_list.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -242,6 +242,121 @@ impl<T> LinkedList<T> {\n \n         self.len -= 1;\n     }\n+\n+    /// Splices a series of nodes between two existing nodes.\n+    ///\n+    /// Warning: this will not check that the provided node belongs to the two existing lists.\n+    #[inline]\n+    unsafe fn splice_nodes(\n+        &mut self,\n+        existing_prev: Option<NonNull<Node<T>>>,\n+        existing_next: Option<NonNull<Node<T>>>,\n+        mut splice_start: NonNull<Node<T>>,\n+        mut splice_end: NonNull<Node<T>>,\n+        splice_length: usize,\n+    ) {\n+        // This method takes care not to create multiple mutable references to whole nodes at the same time,\n+        // to maintain validity of aliasing pointers into `element`.\n+        if let Some(mut existing_prev) = existing_prev {\n+            existing_prev.as_mut().next = Some(splice_start);\n+        } else {\n+            self.head = Some(splice_start);\n+        }\n+        if let Some(mut existing_next) = existing_next {\n+            existing_next.as_mut().prev = Some(splice_end);\n+        } else {\n+            self.tail = Some(splice_end);\n+        }\n+        splice_start.as_mut().prev = existing_prev;\n+        splice_end.as_mut().next = existing_next;\n+\n+        self.len += splice_length;\n+    }\n+\n+    /// Detaches all nodes from a linked list as a series of nodes.\n+    #[inline]\n+    fn detach_all_nodes(mut self) -> Option<(NonNull<Node<T>>, NonNull<Node<T>>, usize)> {\n+        let head = self.head.take();\n+        let tail = self.tail.take();\n+        let len = mem::replace(&mut self.len, 0);\n+        if let Some(head) = head {\n+            let tail = tail.unwrap_or_else(|| unsafe { core::hint::unreachable_unchecked() });\n+            Some((head, tail, len))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    #[inline]\n+    unsafe fn split_off_before_node(\n+        &mut self,\n+        split_node: Option<NonNull<Node<T>>>,\n+        at: usize,\n+    ) -> Self {\n+        // The split node is the new head node of the second part\n+        if let Some(mut split_node) = split_node {\n+            let first_part_head;\n+            let first_part_tail;\n+            first_part_tail = split_node.as_mut().prev.take();\n+            if let Some(mut tail) = first_part_tail {\n+                tail.as_mut().next = None;\n+                first_part_head = self.head;\n+            } else {\n+                first_part_head = None;\n+            }\n+\n+            let first_part = LinkedList {\n+                head: first_part_head,\n+                tail: first_part_tail,\n+                len: at,\n+                marker: PhantomData,\n+            };\n+\n+            // Fix the head ptr of the second part\n+            self.head = Some(split_node);\n+            self.len = self.len - at;\n+\n+            first_part\n+        } else {\n+            mem::replace(self, LinkedList::new())\n+        }\n+    }\n+\n+    #[inline]\n+    unsafe fn split_off_after_node(\n+        &mut self,\n+        split_node: Option<NonNull<Node<T>>>,\n+        at: usize,\n+    ) -> Self {\n+        // The split node is the new tail node of the first part and owns\n+        // the head of the second part.\n+        if let Some(mut split_node) = split_node {\n+            let second_part_head;\n+            let second_part_tail;\n+            second_part_head = split_node.as_mut().next.take();\n+            if let Some(mut head) = second_part_head {\n+                head.as_mut().prev = None;\n+                second_part_tail = self.tail;\n+            } else {\n+                second_part_tail = None;\n+            }\n+\n+            let second_part = LinkedList {\n+                head: second_part_head,\n+                tail: second_part_tail,\n+                len: self.len - at,\n+                marker: PhantomData,\n+            };\n+\n+            // Fix the tail ptr of the first part\n+            self.tail = Some(split_node);\n+            self.len = at;\n+\n+            second_part\n+        } else {\n+            mem::replace(self, LinkedList::new())\n+        }\n+    }\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n@@ -319,6 +434,27 @@ impl<T> LinkedList<T> {\n         }\n     }\n \n+    /// Moves all elements from `other` to the begin of the list.\n+    #[unstable(feature = \"linked_list_prepend\", issue = \"none\")]\n+    pub fn prepend(&mut self, other: &mut Self) {\n+        match self.head {\n+            None => mem::swap(self, other),\n+            Some(mut head) => {\n+                // `as_mut` is okay here because we have exclusive access to the entirety\n+                // of both lists.\n+                if let Some(mut other_tail) = other.tail.take() {\n+                    unsafe {\n+                        head.as_mut().prev = Some(other_tail);\n+                        other_tail.as_mut().next = Some(head);\n+                    }\n+\n+                    self.head = other.head.take();\n+                    self.len += mem::replace(&mut other.len, 0);\n+                }\n+            }\n+        }\n+    }\n+\n     /// Provides a forward iterator.\n     ///\n     /// # Examples\n@@ -373,6 +509,42 @@ impl<T> LinkedList<T> {\n         IterMut { head: self.head, tail: self.tail, len: self.len, list: self }\n     }\n \n+    /// Provides a cursor at the front element.\n+    ///\n+    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n+    #[inline]\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn cursor_front(&self) -> Cursor<'_, T> {\n+        Cursor { index: 0, current: self.head, list: self }\n+    }\n+\n+    /// Provides a cursor with editing operations at the front element.\n+    ///\n+    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n+    #[inline]\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn cursor_front_mut(&mut self) -> CursorMut<'_, T> {\n+        CursorMut { index: 0, current: self.head, list: self }\n+    }\n+\n+    /// Provides a cursor at the back element.\n+    ///\n+    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n+    #[inline]\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn cursor_back(&self) -> Cursor<'_, T> {\n+        Cursor { index: self.len.checked_sub(1).unwrap_or(0), current: self.tail, list: self }\n+    }\n+\n+    /// Provides a cursor with editing operations at the back element.\n+    ///\n+    /// The cursor is pointing to the \"ghost\" non-element if the list is empty.\n+    #[inline]\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn cursor_back_mut(&mut self) -> CursorMut<'_, T> {\n+        CursorMut { index: self.len.checked_sub(1).unwrap_or(0), current: self.tail, list: self }\n+    }\n+\n     /// Returns `true` if the `LinkedList` is empty.\n     ///\n     /// This operation should compute in O(1) time.\n@@ -703,30 +875,7 @@ impl<T> LinkedList<T> {\n             }\n             iter.tail\n         };\n-\n-        // The split node is the new tail node of the first part and owns\n-        // the head of the second part.\n-        let second_part_head;\n-\n-        unsafe {\n-            second_part_head = split_node.unwrap().as_mut().next.take();\n-            if let Some(mut head) = second_part_head {\n-                head.as_mut().prev = None;\n-            }\n-        }\n-\n-        let second_part = LinkedList {\n-            head: second_part_head,\n-            tail: self.tail,\n-            len: len - at,\n-            marker: PhantomData,\n-        };\n-\n-        // Fix the tail ptr of the first part\n-        self.tail = split_node;\n-        self.len = at;\n-\n-        second_part\n+        unsafe { self.split_off_after_node(split_node, at) }\n     }\n \n     /// Creates an iterator which uses a closure to determine if an element should be removed.\n@@ -986,6 +1135,388 @@ impl<T> IterMut<'_, T> {\n     }\n }\n \n+/// A cursor over a `LinkedList`.\n+///\n+/// A `Cursor` is like an iterator, except that it can freely seek back-and-forth.\n+///\n+/// Cursors always rest between two elements in the list, and index in a logically circular way.\n+/// To accommodate this, there is a \"ghost\" non-element that yields `None` between the head and\n+/// tail of the list.\n+///\n+/// When created, cursors start at the front of the list, or the \"ghost\" non-element if the list is empty.\n+#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+pub struct Cursor<'a, T: 'a> {\n+    index: usize,\n+    current: Option<NonNull<Node<T>>>,\n+    list: &'a LinkedList<T>,\n+}\n+\n+#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+impl<T: fmt::Debug> fmt::Debug for Cursor<'_, T> {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        f.debug_tuple(\"Cursor\").field(&self.list).field(&self.index()).finish()\n+    }\n+}\n+\n+/// A cursor over a `LinkedList` with editing operations.\n+///\n+/// A `Cursor` is like an iterator, except that it can freely seek back-and-forth, and can\n+/// safely mutate the list during iteration. This is because the lifetime of its yielded\n+/// references is tied to its own lifetime, instead of just the underlying list. This means\n+/// cursors cannot yield multiple elements at once.\n+///\n+/// Cursors always rest between two elements in the list, and index in a logically circular way.\n+/// To accommodate this, there is a \"ghost\" non-element that yields `None` between the head and\n+/// tail of the list.\n+#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+pub struct CursorMut<'a, T: 'a> {\n+    index: usize,\n+    current: Option<NonNull<Node<T>>>,\n+    list: &'a mut LinkedList<T>,\n+}\n+\n+#[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+impl<T: fmt::Debug> fmt::Debug for CursorMut<'_, T> {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        f.debug_tuple(\"CursorMut\").field(&self.list).field(&self.index()).finish()\n+    }\n+}\n+\n+impl<'a, T> Cursor<'a, T> {\n+    /// Returns the cursor position index within the `LinkedList`.\n+    ///\n+    /// This returns `None` if the cursor is currently pointing to the\n+    /// \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn index(&self) -> Option<usize> {\n+        let _ = self.current?;\n+        Some(self.index)\n+    }\n+\n+    /// Moves the cursor to the next element of the `LinkedList`.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n+    /// the first element of the `LinkedList`. If it is pointing to the last\n+    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn move_next(&mut self) {\n+        match self.current.take() {\n+            // We had no current element; the cursor was sitting at the start position\n+            // Next element should be the head of the list\n+            None => {\n+                self.current = self.list.head;\n+                self.index = 0;\n+            }\n+            // We had a previous element, so let's go to its next\n+            Some(current) => unsafe {\n+                self.current = current.as_ref().next;\n+                self.index += 1;\n+            },\n+        }\n+    }\n+\n+    /// Moves the cursor to the previous element of the `LinkedList`.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n+    /// the last element of the `LinkedList`. If it is pointing to the first\n+    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn move_prev(&mut self) {\n+        match self.current.take() {\n+            // No current. We're at the start of the list. Yield None and jump to the end.\n+            None => {\n+                self.current = self.list.tail;\n+                self.index = self.list.len().checked_sub(1).unwrap_or(0);\n+            }\n+            // Have a prev. Yield it and go to the previous element.\n+            Some(current) => unsafe {\n+                self.current = current.as_ref().prev;\n+                self.index = self.index.checked_sub(1).unwrap_or_else(|| self.list.len());\n+            },\n+        }\n+    }\n+\n+    /// Returns a reference to the element that the cursor is currently\n+    /// pointing to.\n+    ///\n+    /// This returns `None` if the cursor is currently pointing to the\n+    /// \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn current(&self) -> Option<&'a T> {\n+        unsafe { self.current.map(|current| &(*current.as_ptr()).element) }\n+    }\n+\n+    /// Returns a reference to the next element.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n+    /// the first element of the `LinkedList`. If it is pointing to the last\n+    /// element of the `LinkedList` then this returns `None`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn peek_next(&self) -> Option<&'a T> {\n+        unsafe {\n+            let next = match self.current {\n+                None => self.list.head,\n+                Some(current) => current.as_ref().next,\n+            };\n+            next.map(|next| &(*next.as_ptr()).element)\n+        }\n+    }\n+\n+    /// Returns a reference to the previous element.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n+    /// the last element of the `LinkedList`. If it is pointing to the first\n+    /// element of the `LinkedList` then this returns `None`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn peek_prev(&self) -> Option<&'a T> {\n+        unsafe {\n+            let prev = match self.current {\n+                None => self.list.tail,\n+                Some(current) => current.as_ref().prev,\n+            };\n+            prev.map(|prev| &(*prev.as_ptr()).element)\n+        }\n+    }\n+}\n+\n+impl<'a, T> CursorMut<'a, T> {\n+    /// Returns the cursor position index within the `LinkedList`.\n+    ///\n+    /// This returns `None` if the cursor is currently pointing to the\n+    /// \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn index(&self) -> Option<usize> {\n+        let _ = self.current?;\n+        Some(self.index)\n+    }\n+\n+    /// Moves the cursor to the next element of the `LinkedList`.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n+    /// the first element of the `LinkedList`. If it is pointing to the last\n+    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn move_next(&mut self) {\n+        match self.current.take() {\n+            // We had no current element; the cursor was sitting at the start position\n+            // Next element should be the head of the list\n+            None => {\n+                self.current = self.list.head;\n+                self.index = 0;\n+            }\n+            // We had a previous element, so let's go to its next\n+            Some(current) => unsafe {\n+                self.current = current.as_ref().next;\n+                self.index += 1;\n+            },\n+        }\n+    }\n+\n+    /// Moves the cursor to the previous element of the `LinkedList`.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this will move it to\n+    /// the last element of the `LinkedList`. If it is pointing to the first\n+    /// element of the `LinkedList` then this will move it to the \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn move_prev(&mut self) {\n+        match self.current.take() {\n+            // No current. We're at the start of the list. Yield None and jump to the end.\n+            None => {\n+                self.current = self.list.tail;\n+                self.index = self.list.len().checked_sub(1).unwrap_or(0);\n+            }\n+            // Have a prev. Yield it and go to the previous element.\n+            Some(current) => unsafe {\n+                self.current = current.as_ref().prev;\n+                self.index = self.index.checked_sub(1).unwrap_or_else(|| self.list.len());\n+            },\n+        }\n+    }\n+\n+    /// Returns a reference to the element that the cursor is currently\n+    /// pointing to.\n+    ///\n+    /// This returns `None` if the cursor is currently pointing to the\n+    /// \"ghost\" non-element.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn current(&mut self) -> Option<&mut T> {\n+        unsafe { self.current.map(|current| &mut (*current.as_ptr()).element) }\n+    }\n+\n+    /// Returns a reference to the next element.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n+    /// the first element of the `LinkedList`. If it is pointing to the last\n+    /// element of the `LinkedList` then this returns `None`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn peek_next(&mut self) -> Option<&mut T> {\n+        unsafe {\n+            let next = match self.current {\n+                None => self.list.head,\n+                Some(current) => current.as_ref().next,\n+            };\n+            next.map(|next| &mut (*next.as_ptr()).element)\n+        }\n+    }\n+\n+    /// Returns a reference to the previous element.\n+    ///\n+    /// If the cursor is pointing to the \"ghost\" non-element then this returns\n+    /// the last element of the `LinkedList`. If it is pointing to the first\n+    /// element of the `LinkedList` then this returns `None`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn peek_prev(&mut self) -> Option<&mut T> {\n+        unsafe {\n+            let prev = match self.current {\n+                None => self.list.tail,\n+                Some(current) => current.as_ref().prev,\n+            };\n+            prev.map(|prev| &mut (*prev.as_ptr()).element)\n+        }\n+    }\n+\n+    /// Returns a read-only cursor pointing to the current element.\n+    ///\n+    /// The lifetime of the returned `Cursor` is bound to that of the\n+    /// `CursorMut`, which means it cannot outlive the `CursorMut` and that the\n+    /// `CursorMut` is frozen for the lifetime of the `Cursor`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn as_cursor<'cm>(&'cm self) -> Cursor<'cm, T> {\n+        Cursor { list: self.list, current: self.current, index: self.index }\n+    }\n+}\n+\n+// Now the list editing operations\n+\n+impl<'a, T> CursorMut<'a, T> {\n+    /// Inserts a new element into the `LinkedList` after the current one.\n+    ///\n+    /// If the cursor is pointing at the \"ghost\" non-element then the new element is\n+    /// inserted at the front of the `LinkedList`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn insert_after(&mut self, item: T) {\n+        unsafe {\n+            let spliced_node = Box::into_raw_non_null(Box::new(Node::new(item)));\n+            let node_next = match self.current {\n+                None => self.list.head,\n+                Some(node) => node.as_ref().next,\n+            };\n+            self.list.splice_nodes(self.current, node_next, spliced_node, spliced_node, 1);\n+            if self.current.is_none() {\n+                // The \"ghost\" non-element's index has changed.\n+                self.index = self.list.len;\n+            }\n+        }\n+    }\n+\n+    /// Inserts a new element into the `LinkedList` before the current one.\n+    ///\n+    /// If the cursor is pointing at the \"ghost\" non-element then the new element is\n+    /// inserted at the end of the `LinkedList`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn insert_before(&mut self, item: T) {\n+        unsafe {\n+            let spliced_node = Box::into_raw_non_null(Box::new(Node::new(item)));\n+            let node_prev = match self.current {\n+                None => self.list.tail,\n+                Some(node) => node.as_ref().prev,\n+            };\n+            self.list.splice_nodes(node_prev, self.current, spliced_node, spliced_node, 1);\n+            self.index += 1;\n+        }\n+    }\n+\n+    /// Removes the current element from the `LinkedList`.\n+    ///\n+    /// The element that was removed is returned, and the cursor is\n+    /// moved to point to the next element in the `LinkedList`.\n+    ///\n+    /// If the cursor is currently pointing to the \"ghost\" non-element then no element\n+    /// is removed and `None` is returned.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn remove_current(&mut self) -> Option<T> {\n+        let unlinked_node = self.current?;\n+        unsafe {\n+            self.current = unlinked_node.as_ref().next;\n+            self.list.unlink_node(unlinked_node);\n+            let unlinked_node = Box::from_raw(unlinked_node.as_ptr());\n+            Some(unlinked_node.element)\n+        }\n+    }\n+\n+    /// Inserts the elements from the given `LinkedList` after the current one.\n+    ///\n+    /// If the cursor is pointing at the \"ghost\" non-element then the new elements are\n+    /// inserted at the start of the `LinkedList`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn splice_after(&mut self, list: LinkedList<T>) {\n+        unsafe {\n+            let (splice_head, splice_tail, splice_len) = match list.detach_all_nodes() {\n+                Some(parts) => parts,\n+                _ => return,\n+            };\n+            let node_next = match self.current {\n+                None => self.list.head,\n+                Some(node) => node.as_ref().next,\n+            };\n+            self.list.splice_nodes(self.current, node_next, splice_head, splice_tail, splice_len);\n+            if self.current.is_none() {\n+                // The \"ghost\" non-element's index has changed.\n+                self.index = self.list.len;\n+            }\n+        }\n+    }\n+\n+    /// Inserts the elements from the given `LinkedList` before the current one.\n+    ///\n+    /// If the cursor is pointing at the \"ghost\" non-element then the new elements are\n+    /// inserted at the end of the `LinkedList`.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn splice_before(&mut self, list: LinkedList<T>) {\n+        unsafe {\n+            let (splice_head, splice_tail, splice_len) = match list.detach_all_nodes() {\n+                Some(parts) => parts,\n+                _ => return,\n+            };\n+            let node_prev = match self.current {\n+                None => self.list.tail,\n+                Some(node) => node.as_ref().prev,\n+            };\n+            self.list.splice_nodes(node_prev, self.current, splice_head, splice_tail, splice_len);\n+            self.index += splice_len;\n+        }\n+    }\n+\n+    /// Splits the list into two after the current element. This will return a\n+    /// new list consisting of everything after the cursor, with the original\n+    /// list retaining everything before.\n+    ///\n+    /// If the cursor is pointing at the \"ghost\" non-element then the entire contents\n+    /// of the `LinkedList` are moved.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn split_after(&mut self) -> LinkedList<T> {\n+        let split_off_idx = if self.index == self.list.len { 0 } else { self.index + 1 };\n+        if self.index == self.list.len {\n+            // The \"ghost\" non-element's index has changed to 0.\n+            self.index = 0;\n+        }\n+        unsafe { self.list.split_off_after_node(self.current, split_off_idx) }\n+    }\n+\n+    /// Splits the list into two before the current element. This will return a\n+    /// new list consisting of everything before the cursor, with the original\n+    /// list retaining everything after.\n+    ///\n+    /// If the cursor is pointing at the \"ghost\" non-element then the entire contents\n+    /// of the `LinkedList` are moved.\n+    #[unstable(feature = \"linked_list_cursors\", issue = \"58533\")]\n+    pub fn split_before(&mut self) -> LinkedList<T> {\n+        let split_off_idx = self.index;\n+        self.index = 0;\n+        unsafe { self.list.split_off_before_node(self.current, split_off_idx) }\n+    }\n+}\n+\n /// An iterator produced by calling `drain_filter` on LinkedList.\n #[unstable(feature = \"drain_filter\", reason = \"recently added\", issue = \"43244\")]\n pub struct DrainFilter<'a, T: 'a, F: 'a>"}, {"sha": "085f734ed916a0ca43cc92ad4e257268d48e5ff7", "filename": "src/liballoc/collections/linked_list/tests.rs", "status": "modified", "additions": 152, "deletions": 0, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Fliballoc%2Fcollections%2Flinked_list%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Fliballoc%2Fcollections%2Flinked_list%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Flinked_list%2Ftests.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -304,3 +304,155 @@ fn drain_to_empty_test() {\n     assert_eq!(deleted, &[1, 2, 3, 4, 5, 6]);\n     assert_eq!(m.into_iter().collect::<Vec<_>>(), &[]);\n }\n+\n+#[test]\n+fn test_cursor_move_peek() {\n+    let mut m: LinkedList<u32> = LinkedList::new();\n+    m.extend(&[1, 2, 3, 4, 5, 6]);\n+    let mut cursor = m.cursor_front();\n+    assert_eq!(cursor.current(), Some(&1));\n+    assert_eq!(cursor.peek_next(), Some(&2));\n+    assert_eq!(cursor.peek_prev(), None);\n+    assert_eq!(cursor.index(), Some(0));\n+    cursor.move_prev();\n+    assert_eq!(cursor.current(), None);\n+    assert_eq!(cursor.peek_next(), Some(&1));\n+    assert_eq!(cursor.peek_prev(), Some(&6));\n+    assert_eq!(cursor.index(), None);\n+    cursor.move_next();\n+    cursor.move_next();\n+    assert_eq!(cursor.current(), Some(&2));\n+    assert_eq!(cursor.peek_next(), Some(&3));\n+    assert_eq!(cursor.peek_prev(), Some(&1));\n+    assert_eq!(cursor.index(), Some(1));\n+\n+    let mut cursor = m.cursor_back();\n+    assert_eq!(cursor.current(), Some(&6));\n+    assert_eq!(cursor.peek_next(), None);\n+    assert_eq!(cursor.peek_prev(), Some(&5));\n+    assert_eq!(cursor.index(), Some(5));\n+    cursor.move_next();\n+    assert_eq!(cursor.current(), None);\n+    assert_eq!(cursor.peek_next(), Some(&1));\n+    assert_eq!(cursor.peek_prev(), Some(&6));\n+    assert_eq!(cursor.index(), None);\n+    cursor.move_prev();\n+    cursor.move_prev();\n+    assert_eq!(cursor.current(), Some(&5));\n+    assert_eq!(cursor.peek_next(), Some(&6));\n+    assert_eq!(cursor.peek_prev(), Some(&4));\n+    assert_eq!(cursor.index(), Some(4));\n+\n+    let mut m: LinkedList<u32> = LinkedList::new();\n+    m.extend(&[1, 2, 3, 4, 5, 6]);\n+    let mut cursor = m.cursor_front_mut();\n+    assert_eq!(cursor.current(), Some(&mut 1));\n+    assert_eq!(cursor.peek_next(), Some(&mut 2));\n+    assert_eq!(cursor.peek_prev(), None);\n+    assert_eq!(cursor.index(), Some(0));\n+    cursor.move_prev();\n+    assert_eq!(cursor.current(), None);\n+    assert_eq!(cursor.peek_next(), Some(&mut 1));\n+    assert_eq!(cursor.peek_prev(), Some(&mut 6));\n+    assert_eq!(cursor.index(), None);\n+    cursor.move_next();\n+    cursor.move_next();\n+    assert_eq!(cursor.current(), Some(&mut 2));\n+    assert_eq!(cursor.peek_next(), Some(&mut 3));\n+    assert_eq!(cursor.peek_prev(), Some(&mut 1));\n+    assert_eq!(cursor.index(), Some(1));\n+    let mut cursor2 = cursor.as_cursor();\n+    assert_eq!(cursor2.current(), Some(&2));\n+    assert_eq!(cursor2.index(), Some(1));\n+    cursor2.move_next();\n+    assert_eq!(cursor2.current(), Some(&3));\n+    assert_eq!(cursor2.index(), Some(2));\n+    assert_eq!(cursor.current(), Some(&mut 2));\n+    assert_eq!(cursor.index(), Some(1));\n+\n+    let mut m: LinkedList<u32> = LinkedList::new();\n+    m.extend(&[1, 2, 3, 4, 5, 6]);\n+    let mut cursor = m.cursor_back_mut();\n+    assert_eq!(cursor.current(), Some(&mut 6));\n+    assert_eq!(cursor.peek_next(), None);\n+    assert_eq!(cursor.peek_prev(), Some(&mut 5));\n+    assert_eq!(cursor.index(), Some(5));\n+    cursor.move_next();\n+    assert_eq!(cursor.current(), None);\n+    assert_eq!(cursor.peek_next(), Some(&mut 1));\n+    assert_eq!(cursor.peek_prev(), Some(&mut 6));\n+    assert_eq!(cursor.index(), None);\n+    cursor.move_prev();\n+    cursor.move_prev();\n+    assert_eq!(cursor.current(), Some(&mut 5));\n+    assert_eq!(cursor.peek_next(), Some(&mut 6));\n+    assert_eq!(cursor.peek_prev(), Some(&mut 4));\n+    assert_eq!(cursor.index(), Some(4));\n+    let mut cursor2 = cursor.as_cursor();\n+    assert_eq!(cursor2.current(), Some(&5));\n+    assert_eq!(cursor2.index(), Some(4));\n+    cursor2.move_prev();\n+    assert_eq!(cursor2.current(), Some(&4));\n+    assert_eq!(cursor2.index(), Some(3));\n+    assert_eq!(cursor.current(), Some(&mut 5));\n+    assert_eq!(cursor.index(), Some(4));\n+}\n+\n+#[test]\n+fn test_cursor_mut_insert() {\n+    let mut m: LinkedList<u32> = LinkedList::new();\n+    m.extend(&[1, 2, 3, 4, 5, 6]);\n+    let mut cursor = m.cursor_front_mut();\n+    cursor.insert_before(7);\n+    cursor.insert_after(8);\n+    check_links(&m);\n+    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[7, 1, 8, 2, 3, 4, 5, 6]);\n+    let mut cursor = m.cursor_front_mut();\n+    cursor.move_prev();\n+    cursor.insert_before(9);\n+    cursor.insert_after(10);\n+    check_links(&m);\n+    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[10, 7, 1, 8, 2, 3, 4, 5, 6, 9]);\n+    let mut cursor = m.cursor_front_mut();\n+    cursor.move_prev();\n+    assert_eq!(cursor.remove_current(), None);\n+    cursor.move_next();\n+    cursor.move_next();\n+    assert_eq!(cursor.remove_current(), Some(7));\n+    cursor.move_prev();\n+    cursor.move_prev();\n+    cursor.move_prev();\n+    assert_eq!(cursor.remove_current(), Some(9));\n+    cursor.move_next();\n+    assert_eq!(cursor.remove_current(), Some(10));\n+    check_links(&m);\n+    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[1, 8, 2, 3, 4, 5, 6]);\n+    let mut cursor = m.cursor_front_mut();\n+    let mut p: LinkedList<u32> = LinkedList::new();\n+    p.extend(&[100, 101, 102, 103]);\n+    let mut q: LinkedList<u32> = LinkedList::new();\n+    q.extend(&[200, 201, 202, 203]);\n+    cursor.splice_after(p);\n+    cursor.splice_before(q);\n+    check_links(&m);\n+    assert_eq!(\n+        m.iter().cloned().collect::<Vec<_>>(),\n+        &[200, 201, 202, 203, 1, 100, 101, 102, 103, 8, 2, 3, 4, 5, 6]\n+    );\n+    let mut cursor = m.cursor_front_mut();\n+    cursor.move_prev();\n+    let tmp = cursor.split_before();\n+    assert_eq!(m.into_iter().collect::<Vec<_>>(), &[]);\n+    m = tmp;\n+    let mut cursor = m.cursor_front_mut();\n+    cursor.move_next();\n+    cursor.move_next();\n+    cursor.move_next();\n+    cursor.move_next();\n+    cursor.move_next();\n+    cursor.move_next();\n+    let tmp = cursor.split_after();\n+    assert_eq!(tmp.into_iter().collect::<Vec<_>>(), &[102, 103, 8, 2, 3, 4, 5, 6]);\n+    check_links(&m);\n+    assert_eq!(m.iter().cloned().collect::<Vec<_>>(), &[200, 201, 202, 203, 1, 100, 101]);\n+}"}, {"sha": "c341bb552a1eaf4c4dc89b4a1246abfaad2bed66", "filename": "src/libcore/char/methods.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Fchar%2Fmethods.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Fchar%2Fmethods.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fchar%2Fmethods.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -3,7 +3,7 @@\n use crate::slice;\n use crate::str::from_utf8_unchecked_mut;\n use crate::unicode::printable::is_printable;\n-use crate::unicode::tables::{conversions, derived_property, general_category, property};\n+use crate::unicode::{self, conversions};\n \n use super::*;\n \n@@ -552,7 +552,7 @@ impl char {\n     pub fn is_alphabetic(self) -> bool {\n         match self {\n             'a'..='z' | 'A'..='Z' => true,\n-            c => c > '\\x7f' && derived_property::Alphabetic(c),\n+            c => c > '\\x7f' && unicode::Alphabetic(c),\n         }\n     }\n \n@@ -583,7 +583,7 @@ impl char {\n     pub fn is_lowercase(self) -> bool {\n         match self {\n             'a'..='z' => true,\n-            c => c > '\\x7f' && derived_property::Lowercase(c),\n+            c => c > '\\x7f' && unicode::Lowercase(c),\n         }\n     }\n \n@@ -614,7 +614,7 @@ impl char {\n     pub fn is_uppercase(self) -> bool {\n         match self {\n             'A'..='Z' => true,\n-            c => c > '\\x7f' && derived_property::Uppercase(c),\n+            c => c > '\\x7f' && unicode::Uppercase(c),\n         }\n     }\n \n@@ -642,7 +642,7 @@ impl char {\n     pub fn is_whitespace(self) -> bool {\n         match self {\n             ' ' | '\\x09'..='\\x0d' => true,\n-            c => c > '\\x7f' && property::White_Space(c),\n+            c => c > '\\x7f' && unicode::White_Space(c),\n         }\n     }\n \n@@ -693,7 +693,7 @@ impl char {\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     #[inline]\n     pub fn is_control(self) -> bool {\n-        general_category::Cc(self)\n+        unicode::Cc(self)\n     }\n \n     /// Returns `true` if this `char` has the `Grapheme_Extend` property.\n@@ -707,7 +707,7 @@ impl char {\n     /// [`DerivedCoreProperties.txt`]: https://www.unicode.org/Public/UCD/latest/ucd/DerivedCoreProperties.txt\n     #[inline]\n     pub(crate) fn is_grapheme_extended(self) -> bool {\n-        derived_property::Grapheme_Extend(self)\n+        unicode::Grapheme_Extend(self)\n     }\n \n     /// Returns `true` if this `char` has one of the general categories for numbers.\n@@ -739,7 +739,7 @@ impl char {\n     pub fn is_numeric(self) -> bool {\n         match self {\n             '0'..='9' => true,\n-            c => c > '\\x7f' && general_category::N(c),\n+            c => c > '\\x7f' && unicode::N(c),\n         }\n     }\n "}, {"sha": "cf5576e549cdfa043ad0b9ea24b238178f19272d", "filename": "src/libcore/char/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Fchar%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Fchar%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fchar%2Fmod.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -37,9 +37,9 @@ pub use self::decode::{decode_utf16, DecodeUtf16, DecodeUtf16Error};\n \n // unstable re-exports\n #[unstable(feature = \"unicode_version\", issue = \"49726\")]\n-pub use crate::unicode::tables::UNICODE_VERSION;\n-#[unstable(feature = \"unicode_version\", issue = \"49726\")]\n pub use crate::unicode::version::UnicodeVersion;\n+#[unstable(feature = \"unicode_version\", issue = \"49726\")]\n+pub use crate::unicode::UNICODE_VERSION;\n \n use crate::fmt::{self, Write};\n use crate::iter::FusedIterator;"}, {"sha": "b7fba88a540f9012dbc01efd9b5758d86e30709d", "filename": "src/libcore/unicode/bool_trie.rs", "status": "removed", "additions": 0, "deletions": 66, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/faf45c5dadc04e2ee2f2b772402321e621899641/src%2Flibcore%2Funicode%2Fbool_trie.rs", "raw_url": "https://github.com/rust-lang/rust/raw/faf45c5dadc04e2ee2f2b772402321e621899641/src%2Flibcore%2Funicode%2Fbool_trie.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funicode%2Fbool_trie.rs?ref=faf45c5dadc04e2ee2f2b772402321e621899641", "patch": "@@ -1,66 +0,0 @@\n-/// BoolTrie is a trie for representing a set of Unicode codepoints. It is\n-/// implemented with postfix compression (sharing of identical child nodes),\n-/// which gives both compact size and fast lookup.\n-///\n-/// The space of Unicode codepoints is divided into 3 subareas, each\n-/// represented by a trie with different depth. In the first (0..0x800), there\n-/// is no trie structure at all; each u64 entry corresponds to a bitvector\n-/// effectively holding 64 bool values.\n-///\n-/// In the second (0x800..0x10000), each child of the root node represents a\n-/// 64-wide subrange, but instead of storing the full 64-bit value of the leaf,\n-/// the trie stores an 8-bit index into a shared table of leaf values. This\n-/// exploits the fact that in reasonable sets, many such leaves can be shared.\n-///\n-/// In the third (0x10000..0x110000), each child of the root node represents a\n-/// 4096-wide subrange, and the trie stores an 8-bit index into a 64-byte slice\n-/// of a child tree. Each of these 64 bytes represents an index into the table\n-/// of shared 64-bit leaf values. This exploits the sparse structure in the\n-/// non-BMP range of most Unicode sets.\n-pub struct BoolTrie {\n-    // 0..0x800 (corresponding to 1 and 2 byte utf-8 sequences)\n-    pub r1: [u64; 32], // leaves\n-\n-    // 0x800..0x10000 (corresponding to 3 byte utf-8 sequences)\n-    pub r2: [u8; 992],      // first level\n-    pub r3: &'static [u64], // leaves\n-\n-    // 0x10000..0x110000 (corresponding to 4 byte utf-8 sequences)\n-    pub r4: [u8; 256],      // first level\n-    pub r5: &'static [u8],  // second level\n-    pub r6: &'static [u64], // leaves\n-}\n-impl BoolTrie {\n-    pub fn lookup(&self, c: char) -> bool {\n-        let c = c as u32;\n-        if c < 0x800 {\n-            trie_range_leaf(c, self.r1[(c >> 6) as usize])\n-        } else if c < 0x10000 {\n-            let child = self.r2[(c >> 6) as usize - 0x20];\n-            trie_range_leaf(c, self.r3[child as usize])\n-        } else {\n-            let child = self.r4[(c >> 12) as usize - 0x10];\n-            let leaf = self.r5[((child as usize) << 6) + ((c >> 6) as usize & 0x3f)];\n-            trie_range_leaf(c, self.r6[leaf as usize])\n-        }\n-    }\n-}\n-\n-pub struct SmallBoolTrie {\n-    pub(crate) r1: &'static [u8],  // first level\n-    pub(crate) r2: &'static [u64], // leaves\n-}\n-\n-impl SmallBoolTrie {\n-    pub fn lookup(&self, c: char) -> bool {\n-        let c = c as u32;\n-        match self.r1.get((c >> 6) as usize) {\n-            Some(&child) => trie_range_leaf(c, self.r2[child as usize]),\n-            None => false,\n-        }\n-    }\n-}\n-\n-fn trie_range_leaf(c: u32, bitmap_chunk: u64) -> bool {\n-    ((bitmap_chunk >> (c & 63)) & 1) != 0\n-}"}, {"sha": "b6eaf06aa7f63be316f86ef76f26ffa0ba935def", "filename": "src/libcore/unicode/mod.rs", "status": "modified", "additions": 49, "deletions": 5, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Funicode%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Funicode%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funicode%2Fmod.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -1,15 +1,59 @@\n #![unstable(feature = \"unicode_internals\", issue = \"none\")]\n #![allow(missing_docs)]\n \n-mod bool_trie;\n pub(crate) mod printable;\n-pub(crate) mod tables;\n+mod unicode_data;\n pub(crate) mod version;\n \n+use version::UnicodeVersion;\n+\n+/// The version of [Unicode](http://www.unicode.org/) that the Unicode parts of\n+/// `char` and `str` methods are based on.\n+#[unstable(feature = \"unicode_version\", issue = \"49726\")]\n+pub const UNICODE_VERSION: UnicodeVersion = UnicodeVersion {\n+    major: unicode_data::UNICODE_VERSION.0,\n+    minor: unicode_data::UNICODE_VERSION.1,\n+    micro: unicode_data::UNICODE_VERSION.2,\n+    _priv: (),\n+};\n+\n // For use in liballoc, not re-exported in libstd.\n pub mod derived_property {\n-    pub use crate::unicode::tables::derived_property::{Case_Ignorable, Cased};\n+    pub use super::{Case_Ignorable, Cased};\n }\n-pub mod conversions {\n-    pub use crate::unicode::tables::conversions::{to_lower, to_upper};\n+\n+pub use unicode_data::alphabetic::lookup as Alphabetic;\n+pub use unicode_data::case_ignorable::lookup as Case_Ignorable;\n+pub use unicode_data::cased::lookup as Cased;\n+pub use unicode_data::cc::lookup as Cc;\n+pub use unicode_data::conversions;\n+pub use unicode_data::grapheme_extend::lookup as Grapheme_Extend;\n+pub use unicode_data::lowercase::lookup as Lowercase;\n+pub use unicode_data::n::lookup as N;\n+pub use unicode_data::uppercase::lookup as Uppercase;\n+pub use unicode_data::white_space::lookup as White_Space;\n+\n+#[inline(always)]\n+fn range_search<const N: usize, const N1: usize, const N2: usize>(\n+    needle: u32,\n+    chunk_idx_map: &[u8; N],\n+    (last_chunk_idx, last_chunk_mapping): (u16, u8),\n+    bitset_chunk_idx: &[[u8; 16]; N1],\n+    bitset: &[u64; N2],\n+) -> bool {\n+    let bucket_idx = (needle / 64) as usize;\n+    let chunk_map_idx = bucket_idx / 16;\n+    let chunk_piece = bucket_idx % 16;\n+    let chunk_idx = if chunk_map_idx >= N {\n+        if chunk_map_idx == last_chunk_idx as usize {\n+            last_chunk_mapping\n+        } else {\n+            return false;\n+        }\n+    } else {\n+        chunk_idx_map[chunk_map_idx]\n+    };\n+    let idx = bitset_chunk_idx[(chunk_idx as usize)][chunk_piece];\n+    let word = bitset[(idx as usize)];\n+    (word & (1 << (needle % 64) as u64)) != 0\n }"}, {"sha": "3fa125e8fea15fc9921ce35af4660c76554f619c", "filename": "src/libcore/unicode/tables.rs", "status": "removed", "additions": 0, "deletions": 2235, "changes": 2235, "blob_url": "https://github.com/rust-lang/rust/blob/faf45c5dadc04e2ee2f2b772402321e621899641/src%2Flibcore%2Funicode%2Ftables.rs", "raw_url": "https://github.com/rust-lang/rust/raw/faf45c5dadc04e2ee2f2b772402321e621899641/src%2Flibcore%2Funicode%2Ftables.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funicode%2Ftables.rs?ref=faf45c5dadc04e2ee2f2b772402321e621899641"}, {"sha": "97df92a56da66ea2b0527a35d4a5eb28f6457390", "filename": "src/libcore/unicode/unicode.py", "status": "removed", "additions": 0, "deletions": 878, "changes": 878, "blob_url": "https://github.com/rust-lang/rust/blob/faf45c5dadc04e2ee2f2b772402321e621899641/src%2Flibcore%2Funicode%2Funicode.py", "raw_url": "https://github.com/rust-lang/rust/raw/faf45c5dadc04e2ee2f2b772402321e621899641/src%2Flibcore%2Funicode%2Funicode.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funicode%2Funicode.py?ref=faf45c5dadc04e2ee2f2b772402321e621899641", "patch": "@@ -1,878 +0,0 @@\n-#!/usr/bin/env python\n-\n-\"\"\"\n-Regenerate Unicode tables (tables.rs).\n-\"\"\"\n-\n-# This script uses the Unicode tables as defined\n-# in the UnicodeFiles class.\n-\n-# Since this should not require frequent updates, we just store this\n-# out-of-line and check the tables.rs file into git.\n-\n-# Note that the \"curl\" program is required for operation.\n-# This script is compatible with Python 2.7 and 3.x.\n-\n-import argparse\n-import datetime\n-import fileinput\n-import itertools\n-import os\n-import re\n-import textwrap\n-import subprocess\n-\n-from collections import defaultdict, namedtuple\n-\n-try:\n-    # Python 3\n-    from itertools import zip_longest\n-    from io import StringIO\n-except ImportError:\n-    # Python 2 compatibility\n-    zip_longest = itertools.izip_longest\n-    from StringIO import StringIO\n-\n-try:\n-    # Completely optional type hinting\n-    # (Python 2 compatible using comments,\n-    # see: https://mypy.readthedocs.io/en/latest/python2.html)\n-    # This is very helpful in typing-aware IDE like PyCharm.\n-    from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Set, Tuple\n-except ImportError:\n-    pass\n-\n-\n-# We don't use enum.Enum because of Python 2.7 compatibility.\n-class UnicodeFiles(object):\n-    # ReadMe does not contain any Unicode data, we\n-    # only use it to extract versions.\n-    README = \"ReadMe.txt\"\n-\n-    DERIVED_CORE_PROPERTIES = \"DerivedCoreProperties.txt\"\n-    DERIVED_NORMALIZATION_PROPS = \"DerivedNormalizationProps.txt\"\n-    PROPS = \"PropList.txt\"\n-    SCRIPTS = \"Scripts.txt\"\n-    SPECIAL_CASING = \"SpecialCasing.txt\"\n-    UNICODE_DATA = \"UnicodeData.txt\"\n-\n-\n-# The order doesn't really matter (Python < 3.6 won't preserve it),\n-# we only want to aggregate all the file names.\n-ALL_UNICODE_FILES = tuple(\n-    value for name, value in UnicodeFiles.__dict__.items()\n-    if not name.startswith(\"_\")\n-)\n-\n-assert len(ALL_UNICODE_FILES) == 7, \"Unexpected number of unicode files\"\n-\n-# The directory this file is located in.\n-THIS_DIR = os.path.dirname(os.path.realpath(__file__))\n-\n-# Where to download the Unicode data.  The downloaded files\n-# will be placed in sub-directories named after Unicode version.\n-FETCH_DIR = os.path.join(THIS_DIR, \"downloaded\")\n-\n-FETCH_URL_LATEST = \"ftp://ftp.unicode.org/Public/UNIDATA/{filename}\"\n-FETCH_URL_VERSION = \"ftp://ftp.unicode.org/Public/{version}/ucd/{filename}\"\n-\n-PREAMBLE = \"\"\"\\\n-// NOTE: The following code was generated by \"./unicode.py\", do not edit directly\n-\n-#![allow(missing_docs, non_upper_case_globals, non_snake_case, clippy::unreadable_literal)]\n-\n-use crate::unicode::bool_trie::{{BoolTrie, SmallBoolTrie}};\n-use crate::unicode::version::UnicodeVersion;\n-\"\"\".format(year=datetime.datetime.now().year)\n-\n-# Mapping taken from Table 12 from:\n-# http://www.unicode.org/reports/tr44/#General_Category_Values\n-EXPANDED_CATEGORIES = {\n-    \"Lu\": [\"LC\", \"L\"], \"Ll\": [\"LC\", \"L\"], \"Lt\": [\"LC\", \"L\"],\n-    \"Lm\": [\"L\"], \"Lo\": [\"L\"],\n-    \"Mn\": [\"M\"], \"Mc\": [\"M\"], \"Me\": [\"M\"],\n-    \"Nd\": [\"N\"], \"Nl\": [\"N\"], \"No\": [\"N\"],\n-    \"Pc\": [\"P\"], \"Pd\": [\"P\"], \"Ps\": [\"P\"], \"Pe\": [\"P\"],\n-    \"Pi\": [\"P\"], \"Pf\": [\"P\"], \"Po\": [\"P\"],\n-    \"Sm\": [\"S\"], \"Sc\": [\"S\"], \"Sk\": [\"S\"], \"So\": [\"S\"],\n-    \"Zs\": [\"Z\"], \"Zl\": [\"Z\"], \"Zp\": [\"Z\"],\n-    \"Cc\": [\"C\"], \"Cf\": [\"C\"], \"Cs\": [\"C\"], \"Co\": [\"C\"], \"Cn\": [\"C\"],\n-}\n-\n-# This is the (inclusive) range of surrogate codepoints.\n-# These are not valid Rust characters.\n-SURROGATE_CODEPOINTS_RANGE = (0xd800, 0xdfff)\n-\n-UnicodeData = namedtuple(\n-    \"UnicodeData\", (\n-        # Conversions:\n-        \"to_upper\", \"to_lower\", \"to_title\",\n-\n-        # Decompositions: canonical decompositions, compatibility decomp\n-        \"canon_decomp\", \"compat_decomp\",\n-\n-        # Grouped: general categories and combining characters\n-        \"general_categories\", \"combines\",\n-    )\n-)\n-\n-UnicodeVersion = namedtuple(\n-    \"UnicodeVersion\", (\"major\", \"minor\", \"micro\", \"as_str\")\n-)\n-\n-\n-def fetch_files(version=None):\n-    # type: (str) -> UnicodeVersion\n-    \"\"\"\n-    Fetch all the Unicode files from unicode.org.\n-\n-    This will use cached files (stored in `FETCH_DIR`) if they exist,\n-    creating them if they don't.  In any case, the Unicode version\n-    is always returned.\n-\n-    :param version: The desired Unicode version, as string.\n-        (If None, defaults to latest final release available,\n-         querying the unicode.org service).\n-    \"\"\"\n-    have_version = check_stored_version(version)\n-    if have_version:\n-        return have_version\n-\n-    if version:\n-        # Check if the desired version exists on the server.\n-        get_fetch_url = lambda name: FETCH_URL_VERSION.format(version=version, filename=name)\n-    else:\n-        # Extract the latest version.\n-        get_fetch_url = lambda name: FETCH_URL_LATEST.format(filename=name)\n-\n-    readme_url = get_fetch_url(UnicodeFiles.README)\n-\n-    print(\"Fetching: {}\".format(readme_url))\n-    readme_content = subprocess.check_output((\"curl\", readme_url))\n-\n-    unicode_version = parse_readme_unicode_version(\n-        readme_content.decode(\"utf8\")\n-    )\n-\n-    download_dir = get_unicode_dir(unicode_version)\n-    if not os.path.exists(download_dir):\n-        # For 2.7 compat, we don't use `exist_ok=True`.\n-        os.makedirs(download_dir)\n-\n-    for filename in ALL_UNICODE_FILES:\n-        file_path = get_unicode_file_path(unicode_version, filename)\n-\n-        if os.path.exists(file_path):\n-            # Assume file on the server didn't change if it's been saved before.\n-            continue\n-\n-        if filename == UnicodeFiles.README:\n-            with open(file_path, \"wb\") as fd:\n-                fd.write(readme_content)\n-        else:\n-            url = get_fetch_url(filename)\n-            print(\"Fetching: {}\".format(url))\n-            subprocess.check_call((\"curl\", \"-o\", file_path, url))\n-\n-    return unicode_version\n-\n-\n-def check_stored_version(version):\n-    # type: (Optional[str]) -> Optional[UnicodeVersion]\n-    \"\"\"\n-    Given desired Unicode version, return the version\n-    if stored files are all present, and `None` otherwise.\n-    \"\"\"\n-    if not version:\n-        # If no desired version specified, we should check what's the latest\n-        # version, skipping stored version checks.\n-        return None\n-\n-    fetch_dir = os.path.join(FETCH_DIR, version)\n-\n-    for filename in ALL_UNICODE_FILES:\n-        file_path = os.path.join(fetch_dir, filename)\n-\n-        if not os.path.exists(file_path):\n-            return None\n-\n-    with open(os.path.join(fetch_dir, UnicodeFiles.README)) as fd:\n-        return parse_readme_unicode_version(fd.read())\n-\n-\n-def parse_readme_unicode_version(readme_content):\n-    # type: (str) -> UnicodeVersion\n-    \"\"\"\n-    Parse the Unicode version contained in their `ReadMe.txt` file.\n-    \"\"\"\n-    # \"Raw string\" is necessary for \\d not being treated as escape char\n-    # (for the sake of compat with future Python versions).\n-    # See: https://docs.python.org/3.6/whatsnew/3.6.html#deprecated-python-behavior\n-    pattern = r\"for Version (\\d+)\\.(\\d+)\\.(\\d+) of the Unicode\"\n-    groups = re.search(pattern, readme_content).groups()\n-\n-    return UnicodeVersion(*map(int, groups), as_str=\".\".join(groups))\n-\n-\n-def get_unicode_dir(unicode_version):\n-    # type: (UnicodeVersion) -> str\n-    \"\"\"\n-    Indicate in which parent dir the Unicode data files should be stored.\n-\n-    This returns a full, absolute path.\n-    \"\"\"\n-    return os.path.join(FETCH_DIR, unicode_version.as_str)\n-\n-\n-def get_unicode_file_path(unicode_version, filename):\n-    # type: (UnicodeVersion, str) -> str\n-    \"\"\"\n-    Indicate where the Unicode data file should be stored.\n-    \"\"\"\n-    return os.path.join(get_unicode_dir(unicode_version), filename)\n-\n-\n-def is_surrogate(n):\n-    # type: (int) -> bool\n-    \"\"\"\n-    Tell if given codepoint is a surrogate (not a valid Rust character).\n-    \"\"\"\n-    return SURROGATE_CODEPOINTS_RANGE[0] <= n <= SURROGATE_CODEPOINTS_RANGE[1]\n-\n-\n-def load_unicode_data(file_path):\n-    # type: (str) -> UnicodeData\n-    \"\"\"\n-    Load main Unicode data.\n-    \"\"\"\n-    # Conversions\n-    to_lower = {}   # type: Dict[int, Tuple[int, int, int]]\n-    to_upper = {}   # type: Dict[int, Tuple[int, int, int]]\n-    to_title = {}   # type: Dict[int, Tuple[int, int, int]]\n-\n-    # Decompositions\n-    compat_decomp = {}   # type: Dict[int, List[int]]\n-    canon_decomp = {}    # type: Dict[int, List[int]]\n-\n-    # Combining characters\n-    # FIXME: combines are not used\n-    combines = defaultdict(set)   # type: Dict[str, Set[int]]\n-\n-    # Categories\n-    general_categories = defaultdict(set)   # type: Dict[str, Set[int]]\n-    category_assigned_codepoints = set()    # type: Set[int]\n-\n-    all_codepoints = {}\n-\n-    range_start = -1\n-\n-    for line in fileinput.input(file_path):\n-        data = line.split(\";\")\n-        if len(data) != 15:\n-            continue\n-        codepoint = int(data[0], 16)\n-        if is_surrogate(codepoint):\n-            continue\n-        if range_start >= 0:\n-            for i in range(range_start, codepoint):\n-                all_codepoints[i] = data\n-            range_start = -1\n-        if data[1].endswith(\", First>\"):\n-            range_start = codepoint\n-            continue\n-        all_codepoints[codepoint] = data\n-\n-    for code, data in all_codepoints.items():\n-        (code_org, name, gencat, combine, bidi,\n-         decomp, deci, digit, num, mirror,\n-         old, iso, upcase, lowcase, titlecase) = data\n-\n-        # Generate char to char direct common and simple conversions:\n-\n-        # Uppercase to lowercase\n-        if lowcase != \"\" and code_org != lowcase:\n-            to_lower[code] = (int(lowcase, 16), 0, 0)\n-\n-        # Lowercase to uppercase\n-        if upcase != \"\" and code_org != upcase:\n-            to_upper[code] = (int(upcase, 16), 0, 0)\n-\n-        # Title case\n-        if titlecase.strip() != \"\" and code_org != titlecase:\n-            to_title[code] = (int(titlecase, 16), 0, 0)\n-\n-        # Store decomposition, if given\n-        if decomp:\n-            decompositions = decomp.split()[1:]\n-            decomp_code_points = [int(i, 16) for i in decompositions]\n-\n-            if decomp.startswith(\"<\"):\n-                # Compatibility decomposition\n-                compat_decomp[code] = decomp_code_points\n-            else:\n-                # Canonical decomposition\n-                canon_decomp[code] = decomp_code_points\n-\n-        # Place letter in categories as appropriate.\n-        for cat in itertools.chain((gencat, ), EXPANDED_CATEGORIES.get(gencat, [])):\n-            general_categories[cat].add(code)\n-            category_assigned_codepoints.add(code)\n-\n-        # Record combining class, if any.\n-        if combine != \"0\":\n-            combines[combine].add(code)\n-\n-    # Generate Not_Assigned from Assigned.\n-    general_categories[\"Cn\"] = get_unassigned_codepoints(category_assigned_codepoints)\n-\n-    # Other contains Not_Assigned\n-    general_categories[\"C\"].update(general_categories[\"Cn\"])\n-\n-    grouped_categories = group_categories(general_categories)\n-\n-    # FIXME: combines are not used\n-    return UnicodeData(\n-        to_lower=to_lower, to_upper=to_upper, to_title=to_title,\n-        compat_decomp=compat_decomp, canon_decomp=canon_decomp,\n-        general_categories=grouped_categories, combines=combines,\n-    )\n-\n-\n-def load_special_casing(file_path, unicode_data):\n-    # type: (str, UnicodeData) -> None\n-    \"\"\"\n-    Load special casing data and enrich given Unicode data.\n-    \"\"\"\n-    for line in fileinput.input(file_path):\n-        data = line.split(\"#\")[0].split(\";\")\n-        if len(data) == 5:\n-            code, lower, title, upper, _comment = data\n-        elif len(data) == 6:\n-            code, lower, title, upper, condition, _comment = data\n-            if condition.strip():  # Only keep unconditional mappins\n-                continue\n-        else:\n-            continue\n-        code = code.strip()\n-        lower = lower.strip()\n-        title = title.strip()\n-        upper = upper.strip()\n-        key = int(code, 16)\n-        for (map_, values) in ((unicode_data.to_lower, lower),\n-                               (unicode_data.to_upper, upper),\n-                               (unicode_data.to_title, title)):\n-            if values != code:\n-                split = values.split()\n-\n-                codepoints = list(itertools.chain(\n-                    (int(i, 16) for i in split),\n-                    (0 for _ in range(len(split), 3))\n-                ))\n-\n-                assert len(codepoints) == 3\n-                map_[key] = codepoints\n-\n-\n-def group_categories(mapping):\n-    # type: (Dict[Any, Iterable[int]]) -> Dict[str, List[Tuple[int, int]]]\n-    \"\"\"\n-    Group codepoints mapped in \"categories\".\n-    \"\"\"\n-    return {category: group_codepoints(codepoints)\n-            for category, codepoints in mapping.items()}\n-\n-\n-def group_codepoints(codepoints):\n-    # type: (Iterable[int]) -> List[Tuple[int, int]]\n-    \"\"\"\n-    Group integral values into continuous, disjoint value ranges.\n-\n-    Performs value deduplication.\n-\n-    :return: sorted list of pairs denoting start and end of codepoint\n-        group values, both ends inclusive.\n-\n-    >>> group_codepoints([1, 2, 10, 11, 12, 3, 4])\n-    [(1, 4), (10, 12)]\n-    >>> group_codepoints([1])\n-    [(1, 1)]\n-    >>> group_codepoints([1, 5, 6])\n-    [(1, 1), (5, 6)]\n-    >>> group_codepoints([])\n-    []\n-    \"\"\"\n-    sorted_codes = sorted(set(codepoints))\n-    result = []     # type: List[Tuple[int, int]]\n-\n-    if not sorted_codes:\n-        return result\n-\n-    next_codes = sorted_codes[1:]\n-    start_code = sorted_codes[0]\n-\n-    for code, next_code in zip_longest(sorted_codes, next_codes, fillvalue=None):\n-        if next_code is None or next_code - code != 1:\n-            result.append((start_code, code))\n-            start_code = next_code\n-\n-    return result\n-\n-\n-def ungroup_codepoints(codepoint_pairs):\n-    # type: (Iterable[Tuple[int, int]]) -> List[int]\n-    \"\"\"\n-    The inverse of group_codepoints -- produce a flat list of values\n-    from value range pairs.\n-\n-    >>> ungroup_codepoints([(1, 4), (10, 12)])\n-    [1, 2, 3, 4, 10, 11, 12]\n-    >>> ungroup_codepoints([(1, 1), (5, 6)])\n-    [1, 5, 6]\n-    >>> ungroup_codepoints(group_codepoints([1, 2, 7, 8]))\n-    [1, 2, 7, 8]\n-    >>> ungroup_codepoints([])\n-    []\n-    \"\"\"\n-    return list(itertools.chain.from_iterable(\n-        range(lo, hi + 1) for lo, hi in codepoint_pairs\n-    ))\n-\n-\n-def get_unassigned_codepoints(assigned_codepoints):\n-    # type: (Set[int]) -> Set[int]\n-    \"\"\"\n-    Given a set of \"assigned\" codepoints, return a set\n-    of these that are not in assigned and not surrogate.\n-    \"\"\"\n-    return {i for i in range(0, 0x110000)\n-            if i not in assigned_codepoints and not is_surrogate(i)}\n-\n-\n-def generate_table_lines(items, indent, wrap=98):\n-    # type: (Iterable[str], int, int) -> Iterator[str]\n-    \"\"\"\n-    Given table items, generate wrapped lines of text with comma-separated items.\n-\n-    This is a generator function.\n-\n-    :param wrap: soft wrap limit (characters per line), integer.\n-    \"\"\"\n-    line = \" \" * indent\n-    first = True\n-    for item in items:\n-        if len(line) + len(item) < wrap:\n-            if first:\n-                line += item\n-            else:\n-                line += \", \" + item\n-            first = False\n-        else:\n-            yield line + \",\\n\"\n-            line = \" \" * indent + item\n-\n-    yield line\n-\n-\n-def load_properties(file_path, interesting_props):\n-    # type: (str, Iterable[str]) -> Dict[str, List[Tuple[int, int]]]\n-    \"\"\"\n-    Load properties data and return in grouped form.\n-    \"\"\"\n-    props = defaultdict(list)   # type: Dict[str, List[Tuple[int, int]]]\n-    # \"Raw string\" is necessary for `\\.` and `\\w` not to be treated as escape chars\n-    # (for the sake of compat with future Python versions).\n-    # See: https://docs.python.org/3.6/whatsnew/3.6.html#deprecated-python-behavior\n-    re1 = re.compile(r\"^ *([0-9A-F]+) *; *(\\w+)\")\n-    re2 = re.compile(r\"^ *([0-9A-F]+)\\.\\.([0-9A-F]+) *; *(\\w+)\")\n-\n-    for line in fileinput.input(file_path):\n-        match = re1.match(line) or re2.match(line)\n-        if match:\n-            groups = match.groups()\n-\n-            if len(groups) == 2:\n-                # `re1` matched (2 groups).\n-                d_lo, prop = groups\n-                d_hi = d_lo\n-            else:\n-                d_lo, d_hi, prop = groups\n-        else:\n-            continue\n-\n-        if interesting_props and prop not in interesting_props:\n-            continue\n-\n-        lo_value = int(d_lo, 16)\n-        hi_value = int(d_hi, 16)\n-\n-        props[prop].append((lo_value, hi_value))\n-\n-    # Optimize if possible.\n-    for prop in props:\n-        props[prop] = group_codepoints(ungroup_codepoints(props[prop]))\n-\n-    return props\n-\n-\n-def escape_char(c):\n-    # type: (int) -> str\n-    r\"\"\"\n-    Escape a codepoint for use as Rust char literal.\n-\n-    Outputs are OK to use as Rust source code as char literals\n-    and they also include necessary quotes.\n-\n-    >>> escape_char(97)\n-    \"'\\\\u{61}'\"\n-    >>> escape_char(0)\n-    \"'\\\\0'\"\n-    \"\"\"\n-    return r\"'\\u{%x}'\" % c if c != 0 else r\"'\\0'\"\n-\n-\n-def format_char_pair(pair):\n-    # type: (Tuple[int, int]) -> str\n-    \"\"\"\n-    Format a pair of two Rust chars.\n-    \"\"\"\n-    return \"(%s,%s)\" % (escape_char(pair[0]), escape_char(pair[1]))\n-\n-\n-def generate_table(\n-    name,   # type: str\n-    items,  # type: List[Tuple[int, int]]\n-    decl_type=\"&[(char, char)]\",    # type: str\n-    is_pub=True,                    # type: bool\n-    format_item=format_char_pair,   # type: Callable[[Tuple[int, int]], str]\n-):\n-    # type: (...) -> Iterator[str]\n-    \"\"\"\n-    Generate a nicely formatted Rust constant \"table\" array.\n-\n-    This generates actual Rust code.\n-    \"\"\"\n-    pub_string = \"\"\n-    if is_pub:\n-        pub_string = \"pub \"\n-\n-    yield \"\\n\"\n-    yield \"    #[rustfmt::skip]\\n\"\n-    yield \"    %sconst %s: %s = &[\\n\" % (pub_string, name, decl_type)\n-\n-    data = []\n-    first = True\n-    for item in items:\n-        if not first:\n-            data.append(\",\")\n-        first = False\n-        data.extend(format_item(item))\n-\n-    for table_line in generate_table_lines(\"\".join(data).split(\",\"), 8):\n-        yield table_line\n-\n-    yield \"\\n    ];\\n\"\n-\n-\n-def compute_trie(raw_data, chunk_size):\n-    # type: (List[int], int) -> Tuple[List[int], List[int]]\n-    \"\"\"\n-    Compute postfix-compressed trie.\n-\n-    See: bool_trie.rs for more details.\n-\n-    >>> compute_trie([1, 2, 3, 1, 2, 3, 4, 5, 6], 3)\n-    ([0, 0, 1], [1, 2, 3, 4, 5, 6])\n-    >>> compute_trie([1, 2, 3, 1, 2, 4, 4, 5, 6], 3)\n-    ([0, 1, 2], [1, 2, 3, 1, 2, 4, 4, 5, 6])\n-    \"\"\"\n-    root = []\n-    childmap = {}       # type: Dict[Tuple[int, ...], int]\n-    child_data = []\n-\n-    assert len(raw_data) % chunk_size == 0, \"Chunks must be equally sized\"\n-\n-    for i in range(len(raw_data) // chunk_size):\n-        data = raw_data[i * chunk_size : (i + 1) * chunk_size]\n-\n-        # Postfix compression of child nodes (data chunks)\n-        # (identical child nodes are shared).\n-\n-        # Make a tuple out of the list so it's hashable.\n-        child = tuple(data)\n-        if child not in childmap:\n-            childmap[child] = len(childmap)\n-            child_data.extend(data)\n-\n-        root.append(childmap[child])\n-\n-    return root, child_data\n-\n-\n-def generate_bool_trie(name, codepoint_ranges, is_pub=False):\n-    # type: (str, List[Tuple[int, int]], bool) -> Iterator[str]\n-    \"\"\"\n-    Generate Rust code for BoolTrie struct.\n-\n-    This yields string fragments that should be joined to produce\n-    the final string.\n-\n-    See: `bool_trie.rs`.\n-    \"\"\"\n-    chunk_size = 64\n-    rawdata = [False] * 0x110000\n-    for (lo, hi) in codepoint_ranges:\n-        for cp in range(lo, hi + 1):\n-            rawdata[cp] = True\n-\n-    # Convert to bitmap chunks of `chunk_size` bits each.\n-    chunks = []\n-    for i in range(0x110000 // chunk_size):\n-        chunk = 0\n-        for j in range(chunk_size):\n-            if rawdata[i * chunk_size + j]:\n-                chunk |= 1 << j\n-        chunks.append(chunk)\n-\n-    pub_string = \"\"\n-    if is_pub:\n-        pub_string = \"pub \"\n-\n-    yield \"\\n\"\n-    yield \"    #[rustfmt::skip]\\n\"\n-    yield \"    %sconst %s: &super::BoolTrie = &super::BoolTrie {\\n\" % (pub_string, name)\n-    yield \"        r1: [\\n\"\n-    data = (\"0x%016x\" % chunk for chunk in chunks[:0x800 // chunk_size])\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    # 0x800..0x10000 trie\n-    (r2, r3) = compute_trie(chunks[0x800 // chunk_size : 0x10000 // chunk_size], 64 // chunk_size)\n-    yield \"        r2: [\\n\"\n-    data = map(str, r2)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    yield \"        r3: &[\\n\"\n-    data = (\"0x%016x\" % node for node in r3)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    # 0x10000..0x110000 trie\n-    (mid, r6) = compute_trie(chunks[0x10000 // chunk_size : 0x110000 // chunk_size],\n-                             64 // chunk_size)\n-    (r4, r5) = compute_trie(mid, 64)\n-\n-    yield \"        r4: [\\n\"\n-    data = map(str, r4)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    yield \"        r5: &[\\n\"\n-    data = map(str, r5)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    yield \"        r6: &[\\n\"\n-    data = (\"0x%016x\" % node for node in r6)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    yield \"    };\\n\"\n-\n-\n-def generate_small_bool_trie(name, codepoint_ranges, is_pub=False):\n-    # type: (str, List[Tuple[int, int]], bool) -> Iterator[str]\n-    \"\"\"\n-    Generate Rust code for `SmallBoolTrie` struct.\n-\n-    See: `bool_trie.rs`.\n-    \"\"\"\n-    last_chunk = max(hi // 64 for (lo, hi) in codepoint_ranges)\n-    n_chunks = last_chunk + 1\n-    chunks = [0] * n_chunks\n-    for (lo, hi) in codepoint_ranges:\n-        for cp in range(lo, hi + 1):\n-            assert cp // 64 < len(chunks)\n-            chunks[cp // 64] |= 1 << (cp & 63)\n-\n-    pub_string = \"\"\n-    if is_pub:\n-        pub_string = \"pub \"\n-\n-    yield \"\\n\"\n-    yield \"    #[rustfmt::skip]\\n\"\n-    yield (\"    %sconst %s: &super::SmallBoolTrie = &super::SmallBoolTrie {\\n\"\n-           % (pub_string, name))\n-\n-    (r1, r2) = compute_trie(chunks, 1)\n-\n-    yield \"        r1: &[\\n\"\n-    data = (str(node) for node in r1)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    yield \"        r2: &[\\n\"\n-    data = (\"0x%016x\" % node for node in r2)\n-    for fragment in generate_table_lines(data, 12):\n-        yield fragment\n-    yield \"\\n        ],\\n\"\n-\n-    yield \"    };\\n\"\n-\n-\n-def generate_property_module(mod, grouped_categories, category_subset):\n-    # type: (str, Dict[str, List[Tuple[int, int]]], Iterable[str]) -> Iterator[str]\n-    \"\"\"\n-    Generate Rust code for module defining properties.\n-    \"\"\"\n-\n-    yield \"pub(crate) mod %s {\" % mod\n-    for cat in sorted(category_subset):\n-        if cat in (\"Cc\", \"White_Space\"):\n-            generator = generate_small_bool_trie(\"%s_table\" % cat, grouped_categories[cat])\n-        else:\n-            generator = generate_bool_trie(\"%s_table\" % cat, grouped_categories[cat])\n-\n-        for fragment in generator:\n-            yield fragment\n-\n-        yield \"\\n\"\n-        yield \"    pub fn %s(c: char) -> bool {\\n\" % cat\n-        yield \"        %s_table.lookup(c)\\n\" % cat\n-        yield \"    }\\n\"\n-\n-    yield \"}\\n\\n\"\n-\n-\n-def generate_conversions_module(unicode_data):\n-    # type: (UnicodeData) -> Iterator[str]\n-    \"\"\"\n-    Generate Rust code for module defining conversions.\n-    \"\"\"\n-\n-    yield \"pub(crate) mod conversions {\"\n-    yield \"\"\"\n-    pub fn to_lower(c: char) -> [char; 3] {\n-        match bsearch_case_table(c, to_lowercase_table) {\n-            None => [c, '\\\\0', '\\\\0'],\n-            Some(index) => to_lowercase_table[index].1,\n-        }\n-    }\n-\n-    pub fn to_upper(c: char) -> [char; 3] {\n-        match bsearch_case_table(c, to_uppercase_table) {\n-            None => [c, '\\\\0', '\\\\0'],\n-            Some(index) => to_uppercase_table[index].1,\n-        }\n-    }\n-\n-    fn bsearch_case_table(c: char, table: &[(char, [char; 3])]) -> Option<usize> {\n-        table.binary_search_by(|&(key, _)| key.cmp(&c)).ok()\n-    }\\n\"\"\"\n-\n-    decl_type = \"&[(char, [char; 3])]\"\n-    format_conversion = lambda x: \"({},[{},{},{}])\".format(*(\n-        escape_char(c) for c in (x[0], x[1][0], x[1][1], x[1][2])\n-    ))\n-\n-    for fragment in generate_table(\n-        name=\"to_lowercase_table\",\n-        items=sorted(unicode_data.to_lower.items(), key=lambda x: x[0]),\n-        decl_type=decl_type,\n-        is_pub=False,\n-        format_item=format_conversion\n-    ):\n-        yield fragment\n-\n-    for fragment in generate_table(\n-        name=\"to_uppercase_table\",\n-        items=sorted(unicode_data.to_upper.items(), key=lambda x: x[0]),\n-        decl_type=decl_type,\n-        is_pub=False,\n-        format_item=format_conversion\n-    ):\n-        yield fragment\n-\n-    yield \"}\\n\"\n-\n-\n-def parse_args():\n-    # type: () -> argparse.Namespace\n-    \"\"\"\n-    Parse command line arguments.\n-    \"\"\"\n-    parser = argparse.ArgumentParser(description=__doc__)\n-    parser.add_argument(\"-v\", \"--version\", default=None, type=str,\n-                        help=\"Unicode version to use (if not specified,\"\n-                             \" defaults to latest release).\")\n-\n-    return parser.parse_args()\n-\n-\n-def main():\n-    # type: () -> None\n-    \"\"\"\n-    Script entry point.\n-    \"\"\"\n-    args = parse_args()\n-\n-    unicode_version = fetch_files(args.version)\n-    print(\"Using Unicode version: {}\".format(unicode_version.as_str))\n-\n-    # All the writing happens entirely in memory, we only write to file\n-    # once we have generated the file content (it's not very large, <1 MB).\n-    buf = StringIO()\n-    buf.write(PREAMBLE)\n-\n-    unicode_version_notice = textwrap.dedent(\"\"\"\n-    /// The version of [Unicode](http://www.unicode.org/) that the Unicode parts of\n-    /// `char` and `str` methods are based on.\n-    #[unstable(feature = \"unicode_version\", issue = \"49726\")]\n-    pub const UNICODE_VERSION: UnicodeVersion =\n-        UnicodeVersion {{ major: {v.major}, minor: {v.minor}, micro: {v.micro}, _priv: () }};\n-    \"\"\").format(v=unicode_version)\n-    buf.write(unicode_version_notice)\n-\n-    get_path = lambda f: get_unicode_file_path(unicode_version, f)\n-\n-    unicode_data = load_unicode_data(get_path(UnicodeFiles.UNICODE_DATA))\n-    load_special_casing(get_path(UnicodeFiles.SPECIAL_CASING), unicode_data)\n-\n-    want_derived = {\"Alphabetic\", \"Lowercase\", \"Uppercase\",\n-                    \"Cased\", \"Case_Ignorable\", \"Grapheme_Extend\"}\n-    derived = load_properties(get_path(UnicodeFiles.DERIVED_CORE_PROPERTIES), want_derived)\n-\n-    props = load_properties(get_path(UnicodeFiles.PROPS),\n-                            {\"White_Space\", \"Join_Control\", \"Noncharacter_Code_Point\"})\n-\n-    # Category tables\n-    for (name, categories, category_subset) in (\n-            (\"general_category\", unicode_data.general_categories, [\"N\", \"Cc\"]),\n-            (\"derived_property\", derived, want_derived),\n-            (\"property\", props, [\"White_Space\"])\n-    ):\n-        for fragment in generate_property_module(name, categories, category_subset):\n-            buf.write(fragment)\n-\n-    for fragment in generate_conversions_module(unicode_data):\n-        buf.write(fragment)\n-\n-    tables_rs_path = os.path.join(THIS_DIR, \"tables.rs\")\n-\n-    # Actually write out the file content.\n-    # Will overwrite the file if it exists.\n-    with open(tables_rs_path, \"w\") as fd:\n-        fd.write(buf.getvalue())\n-\n-    print(\"Regenerated tables.rs.\")\n-\n-\n-if __name__ == \"__main__\":\n-    main()"}, {"sha": "da4cd4e9b1da1900e5703b5a2cc7f3ad65a77d90", "filename": "src/libcore/unicode/unicode_data.rs", "status": "added", "additions": 2343, "deletions": 0, "changes": 2343, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Funicode%2Funicode_data.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibcore%2Funicode%2Funicode_data.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funicode%2Funicode_data.rs?ref=3291ae33907f2a866ea6cea89113200555038d06"}, {"sha": "c1df1149bbdfc234b9fda7db231d2e51b655b2d3", "filename": "src/librustc/traits/error_reporting.rs", "status": "modified", "additions": 26, "deletions": 6, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc%2Ftraits%2Ferror_reporting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc%2Ftraits%2Ferror_reporting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Ferror_reporting.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -2479,19 +2479,21 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n                 );\n                 eq\n             })\n-            .map(|ty::GeneratorInteriorTypeCause { span, scope_span, .. }| {\n-                (span, source_map.span_to_snippet(*span), scope_span)\n+            .map(|ty::GeneratorInteriorTypeCause { span, scope_span, expr, .. }| {\n+                (span, source_map.span_to_snippet(*span), scope_span, expr)\n             });\n+\n         debug!(\n             \"maybe_note_obligation_cause_for_async_await: target_ty={:?} \\\n                 generator_interior_types={:?} target_span={:?}\",\n             target_ty, tables.generator_interior_types, target_span\n         );\n-        if let Some((target_span, Ok(snippet), scope_span)) = target_span {\n+        if let Some((target_span, Ok(snippet), scope_span, expr)) = target_span {\n             self.note_obligation_cause_for_async_await(\n                 err,\n                 *target_span,\n                 scope_span,\n+                *expr,\n                 snippet,\n                 generator_did,\n                 last_generator,\n@@ -2514,6 +2516,7 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n         err: &mut DiagnosticBuilder<'_>,\n         target_span: Span,\n         scope_span: &Option<Span>,\n+        expr: Option<hir::HirId>,\n         snippet: String,\n         first_generator: DefId,\n         last_generator: Option<DefId>,\n@@ -2549,6 +2552,7 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n         // not implemented.\n         let is_send = self.tcx.is_diagnostic_item(sym::send_trait, trait_ref.def_id);\n         let is_sync = self.tcx.is_diagnostic_item(sym::sync_trait, trait_ref.def_id);\n+        let hir = self.tcx.hir();\n         let trait_explanation = if is_send || is_sync {\n             let (trait_name, trait_verb) =\n                 if is_send { (\"`Send`\", \"sent\") } else { (\"`Sync`\", \"shared\") };\n@@ -2564,8 +2568,8 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n \n             let message = if let Some(name) = last_generator\n                 .and_then(|generator_did| self.tcx.parent(generator_did))\n-                .and_then(|parent_did| self.tcx.hir().as_local_hir_id(parent_did))\n-                .and_then(|parent_hir_id| self.tcx.hir().opt_name(parent_hir_id))\n+                .and_then(|parent_did| hir.as_local_hir_id(parent_did))\n+                .and_then(|parent_hir_id| hir.opt_name(parent_hir_id))\n             {\n                 format!(\"future returned by `{}` is not {}\", name, trait_name)\n             } else {\n@@ -2581,7 +2585,7 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n         };\n \n         // Look at the last interior type to get a span for the `.await`.\n-        let await_span = tables.generator_interior_types.iter().map(|i| i.span).last().unwrap();\n+        let await_span = tables.generator_interior_types.iter().map(|t| t.span).last().unwrap();\n         let mut span = MultiSpan::from_span(await_span);\n         span.push_span_label(\n             await_span,\n@@ -2606,6 +2610,22 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n             ),\n         );\n \n+        if let Some(expr_id) = expr {\n+            let expr = hir.expect_expr(expr_id);\n+            let is_ref = tables.expr_adjustments(expr).iter().any(|adj| adj.is_region_borrow());\n+            let parent = hir.get_parent_node(expr_id);\n+            if let Some(hir::Node::Expr(e)) = hir.find(parent) {\n+                let method_span = hir.span(parent);\n+                if tables.is_method_call(e) && is_ref {\n+                    err.span_help(\n+                        method_span,\n+                        \"consider moving this method call into a `let` \\\n+                        binding to create a shorter lived borrow\",\n+                    );\n+                }\n+            }\n+        }\n+\n         // Add a note for the item obligation that remains - normally a note pointing to the\n         // bound that introduced the obligation (e.g. `T: Send`).\n         debug!(\"note_obligation_cause_for_async_await: next_code={:?}\", next_code);"}, {"sha": "db034d1618cea6cb35659e1792760e3418c47e5a", "filename": "src/librustc/ty/adjustment.rs", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc%2Fty%2Fadjustment.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc%2Fty%2Fadjustment.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fadjustment.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -81,6 +81,15 @@ pub struct Adjustment<'tcx> {\n     pub target: Ty<'tcx>,\n }\n \n+impl Adjustment<'tcx> {\n+    pub fn is_region_borrow(&self) -> bool {\n+        match self.kind {\n+            Adjust::Borrow(AutoBorrow::Ref(..)) => true,\n+            _ => false,\n+        }\n+    }\n+}\n+\n #[derive(Clone, Debug, RustcEncodable, RustcDecodable, HashStable, TypeFoldable)]\n pub enum Adjust<'tcx> {\n     /// Go from ! to any type."}, {"sha": "ef776c88a8f7cd85859c809c59c46a90cb56a37d", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -315,15 +315,16 @@ pub struct ResolvedOpaqueTy<'tcx> {\n ///\n /// Here, we would store the type `T`, the span of the value `x`, and the \"scope-span\" for\n /// the scope that contains `x`.\n-#[derive(RustcEncodable, RustcDecodable, Clone, Debug, Eq, Hash, PartialEq)]\n-#[derive(HashStable, TypeFoldable)]\n+#[derive(RustcEncodable, RustcDecodable, Clone, Debug, Eq, Hash, PartialEq, HashStable)]\n pub struct GeneratorInteriorTypeCause<'tcx> {\n     /// Type of the captured binding.\n     pub ty: Ty<'tcx>,\n     /// Span of the binding that was captured.\n     pub span: Span,\n     /// Span of the scope of the captured binding.\n     pub scope_span: Option<Span>,\n+    /// Expr which the type evaluated from.\n+    pub expr: Option<hir::HirId>,\n }\n \n #[derive(RustcEncodable, RustcDecodable, Debug)]\n@@ -436,7 +437,7 @@ pub struct TypeckTables<'tcx> {\n     /// entire variable.\n     pub upvar_list: ty::UpvarListMap,\n \n-    /// Stores the type, span and optional scope span of all types\n+    /// Stores the type, expression, span and optional scope span of all types\n     /// that are live across the yield of this generator (if a generator).\n     pub generator_interior_types: Vec<GeneratorInteriorTypeCause<'tcx>>,\n }"}, {"sha": "6ef6dcf87eddb6b552f0d2cc64ca32158f128458", "filename": "src/librustc_driver/pretty.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_driver%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_driver%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fpretty.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -429,7 +429,6 @@ pub fn print_after_hir_lowering<'tcx>(\n         PpmSource(s) => {\n             // Silently ignores an identified node.\n             let out = &mut out;\n-            let src = src.clone();\n             call_with_pp_support(&s, tcx.sess, Some(tcx), move |annotation| {\n                 debug!(\"pretty printing source code {:?}\", s);\n                 let sess = annotation.sess();\n@@ -447,7 +446,6 @@ pub fn print_after_hir_lowering<'tcx>(\n \n         PpmHir(s) => {\n             let out = &mut out;\n-            let src = src.clone();\n             call_with_pp_support_hir(&s, tcx, move |annotation, krate| {\n                 debug!(\"pretty printing source code {:?}\", s);\n                 let sess = annotation.sess();"}, {"sha": "065a3b14428c700f4691f6ba6721bf4f911cdd73", "filename": "src/librustc_parse/parser/ty.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_parse%2Fparser%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_parse%2Fparser%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fty.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -500,7 +500,7 @@ impl<'a> Parser<'a> {\n             err.span_suggestion_short(\n                 lo.to(self.prev_span),\n                 \"remove the parentheses\",\n-                snippet.to_owned(),\n+                snippet,\n                 Applicability::MachineApplicable,\n             );\n         }"}, {"sha": "5bd10303162b295711ce9e076d04b7f22a632d84", "filename": "src/librustc_resolve/imports.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_resolve%2Fimports.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_resolve%2Fimports.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fimports.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -718,7 +718,7 @@ impl<'a, 'b> ImportResolver<'a, 'b> {\n         }\n \n         if !errors.is_empty() {\n-            self.throw_unresolved_import_error(errors.clone(), None);\n+            self.throw_unresolved_import_error(errors, None);\n         }\n     }\n "}, {"sha": "fc02d17a50f373d9752e07d95014bfa6fcb7e954", "filename": "src/librustc_typeck/check/generator_interior.rs", "status": "modified", "additions": 13, "deletions": 4, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_typeck%2Fcheck%2Fgenerator_interior.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_typeck%2Fcheck%2Fgenerator_interior.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fgenerator_interior.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -97,6 +97,7 @@ impl<'a, 'tcx> InteriorVisitor<'a, 'tcx> {\n                         span: source_span,\n                         ty: &ty,\n                         scope_span,\n+                        expr: expr.map(|e| e.hir_id),\n                     })\n                     .or_insert(entries);\n             }\n@@ -164,17 +165,25 @@ pub fn resolve_interior<'a, 'tcx>(\n     // which means that none of the regions inside relate to any other, even if\n     // typeck had previously found constraints that would cause them to be related.\n     let mut counter = 0;\n-    let types = fcx.tcx.fold_regions(&types, &mut false, |_, current_depth| {\n+    let fold_types: Vec<_> = types.iter().map(|(t, _)| t.ty).collect();\n+    let folded_types = fcx.tcx.fold_regions(&fold_types, &mut false, |_, current_depth| {\n         counter += 1;\n         fcx.tcx.mk_region(ty::ReLateBound(current_depth, ty::BrAnon(counter)))\n     });\n \n     // Store the generator types and spans into the tables for this generator.\n-    let interior_types = types.iter().map(|t| t.0.clone()).collect::<Vec<_>>();\n-    visitor.fcx.inh.tables.borrow_mut().generator_interior_types = interior_types;\n+    let types = types\n+        .into_iter()\n+        .zip(&folded_types)\n+        .map(|((mut interior_cause, _), ty)| {\n+            interior_cause.ty = ty;\n+            interior_cause\n+        })\n+        .collect();\n+    visitor.fcx.inh.tables.borrow_mut().generator_interior_types = types;\n \n     // Extract type components\n-    let type_list = fcx.tcx.mk_type_list(types.into_iter().map(|t| (t.0).ty));\n+    let type_list = fcx.tcx.mk_type_list(folded_types.iter());\n \n     let witness = fcx.tcx.mk_generator_witness(ty::Binder::bind(type_list));\n "}, {"sha": "dca3289747e4ce92c52ac07bc20a5e84eb01549f", "filename": "src/librustc_typeck/collect.rs", "status": "modified", "additions": 20, "deletions": 7, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_typeck%2Fcollect.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustc_typeck%2Fcollect.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcollect.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -1806,6 +1806,16 @@ fn find_opaque_ty_constraints(tcx: TyCtxt<'_>, def_id: DefId) -> Ty<'_> {\n     }\n }\n \n+fn are_suggestable_generic_args(generic_args: &[hir::GenericArg<'_>]) -> bool {\n+    generic_args\n+        .iter()\n+        .filter_map(|arg| match arg {\n+            hir::GenericArg::Type(ty) => Some(ty),\n+            _ => None,\n+        })\n+        .any(is_suggestable_infer_ty)\n+}\n+\n /// Whether `ty` is a type with `_` placeholders that can be infered. Used in diagnostics only to\n /// use inference to provide suggestions for the appropriate type if possible.\n fn is_suggestable_infer_ty(ty: &hir::Ty<'_>) -> bool {\n@@ -1815,13 +1825,16 @@ fn is_suggestable_infer_ty(ty: &hir::Ty<'_>) -> bool {\n         Slice(ty) | Array(ty, _) => is_suggestable_infer_ty(ty),\n         Tup(tys) => tys.iter().any(is_suggestable_infer_ty),\n         Ptr(mut_ty) | Rptr(_, mut_ty) => is_suggestable_infer_ty(mut_ty.ty),\n-        Def(_, generic_args) => generic_args\n-            .iter()\n-            .filter_map(|arg| match arg {\n-                hir::GenericArg::Type(ty) => Some(ty),\n-                _ => None,\n-            })\n-            .any(is_suggestable_infer_ty),\n+        Def(_, generic_args) => are_suggestable_generic_args(generic_args),\n+        Path(hir::QPath::TypeRelative(ty, segment)) => {\n+            is_suggestable_infer_ty(ty) || are_suggestable_generic_args(segment.generic_args().args)\n+        }\n+        Path(hir::QPath::Resolved(ty_opt, hir::Path { segments, .. })) => {\n+            ty_opt.map_or(false, is_suggestable_infer_ty)\n+                || segments\n+                    .iter()\n+                    .any(|segment| are_suggestable_generic_args(segment.generic_args().args))\n+        }\n         _ => false,\n     }\n }"}, {"sha": "f899e722a561573085add3ad490a14c6b2e33ed3", "filename": "src/librustdoc/test.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustdoc%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibrustdoc%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Ftest.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -704,7 +704,7 @@ impl Tester for Collector {\n         debug!(\"creating test {}: {}\", name, test);\n         self.tests.push(testing::TestDescAndFn {\n             desc: testing::TestDesc {\n-                name: testing::DynTestName(name.clone()),\n+                name: testing::DynTestName(name),\n                 ignore: match config.ignore {\n                     Ignore::All => true,\n                     Ignore::None => false,"}, {"sha": "45669d120c7c276cc8391f5c30857b3e011b399e", "filename": "src/libtest/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibtest%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Flibtest%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibtest%2Flib.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -553,7 +553,7 @@ fn run_test_in_process(\n         Err(e) => calc_result(&desc, Err(e.as_ref()), &time_opts, &exec_time),\n     };\n     let stdout = data.lock().unwrap().to_vec();\n-    let message = CompletedTest::new(desc.clone(), test_result, exec_time, stdout);\n+    let message = CompletedTest::new(desc, test_result, exec_time, stdout);\n     monitor_ch.send(message).unwrap();\n }\n \n@@ -602,7 +602,7 @@ fn spawn_test_subprocess(\n         (result, test_output, exec_time)\n     })();\n \n-    let message = CompletedTest::new(desc.clone(), result, exec_time, test_output);\n+    let message = CompletedTest::new(desc, result, exec_time, test_output);\n     monitor_ch.send(message).unwrap();\n }\n "}, {"sha": "f368bdef6f8e2d85d0fb28b6e1db639a4de3b834", "filename": "src/test/mir-opt/inline/inline-into-box-place.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fmir-opt%2Finline%2Finline-into-box-place.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fmir-opt%2Finline%2Finline-into-box-place.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fmir-opt%2Finline%2Finline-into-box-place.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -1,5 +1,6 @@\n // ignore-tidy-linelength\n // ignore-wasm32-bare compiled with panic=abort by default\n+// compile-flags: -Z mir-opt-level=3\n #![feature(box_syntax)]\n \n fn main() {"}, {"sha": "77712168a0fd912125877ee64d983167817bf908", "filename": "src/test/ui/associated-types/issue-64848.rs", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fassociated-types%2Fissue-64848.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fassociated-types%2Fissue-64848.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fassociated-types%2Fissue-64848.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,29 @@\n+// build-pass\n+\n+trait AssociatedConstant {\n+    const DATA: ();\n+}\n+\n+impl<F, T> AssociatedConstant for F\n+where\n+    F: FnOnce() -> T,\n+    T: AssociatedConstant,\n+{\n+    const DATA: () = T::DATA;\n+}\n+\n+impl AssociatedConstant for () {\n+    const DATA: () = ();\n+}\n+\n+fn foo() -> impl AssociatedConstant {\n+    ()\n+}\n+\n+fn get_data<T: AssociatedConstant>(_: T) -> &'static () {\n+    &T::DATA\n+}\n+\n+fn main() {\n+    get_data(foo);\n+}"}, {"sha": "77d0885c38d58a75c4624102d11dd7d638573a35", "filename": "src/test/ui/async-await/issue-64130-4-async-move.stderr", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fasync-await%2Fissue-64130-4-async-move.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fasync-await%2Fissue-64130-4-async-move.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fasync-await%2Fissue-64130-4-async-move.stderr?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -16,6 +16,11 @@ LL |                 let _x = get().await;\n ...\n LL |     }\n    |     - `client` is later dropped here\n+help: consider moving this method call into a `let` binding to create a shorter lived borrow\n+  --> $DIR/issue-64130-4-async-move.rs:19:15\n+   |\n+LL |         match client.status() {\n+   |               ^^^^^^^^^^^^^^^\n    = note: the return type of a function must have a statically known size\n \n error: aborting due to previous error"}, {"sha": "18d9012b3acf69410ce744320a54424a2c066471", "filename": "src/test/ui/generator/not-send-sync.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fgenerator%2Fnot-send-sync.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fgenerator%2Fnot-send-sync.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fgenerator%2Fnot-send-sync.stderr?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -20,7 +20,7 @@ LL |     fn assert_sync<T: Sync>(_: T) {}\n LL |     assert_sync(|| {\n    |     ^^^^^^^^^^^ future returned by `main` is not `Sync`\n    |\n-   = help: within `[generator@$DIR/not-send-sync.rs:9:17: 13:6 {std::cell::Cell<i32>, ()}]`, the trait `std::marker::Sync` is not implemented for `std::cell::Cell<i32>`\n+   = help: within `[generator@$DIR/not-send-sync.rs:9:17: 13:6 {std::cell::Cell<i32>, (), ()}]`, the trait `std::marker::Sync` is not implemented for `std::cell::Cell<i32>`\n note: future is not `Sync` as this value is used across an yield\n   --> $DIR/not-send-sync.rs:12:9\n    |"}, {"sha": "15a028f60ae1154208e9c9e7ded2a4d65be10130", "filename": "src/test/ui/impl-trait/recursive-impl-trait-type-indirect.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fimpl-trait%2Frecursive-impl-trait-type-indirect.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fimpl-trait%2Frecursive-impl-trait-type-indirect.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fimpl-trait%2Frecursive-impl-trait-type-indirect.stderr?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -76,7 +76,7 @@ error[E0720]: opaque type expands to a recursive type\n LL | fn generator_capture() -> impl Sized {\n    |                           ^^^^^^^^^^ expands to a recursive type\n    |\n-   = note: expanded type is `[generator@$DIR/recursive-impl-trait-type-indirect.rs:50:5: 50:26 x:impl Sized {()}]`\n+   = note: expanded type is `[generator@$DIR/recursive-impl-trait-type-indirect.rs:50:5: 50:26 x:impl Sized {(), ()}]`\n \n error[E0720]: opaque type expands to a recursive type\n   --> $DIR/recursive-impl-trait-type-indirect.rs:53:26\n@@ -92,7 +92,7 @@ error[E0720]: opaque type expands to a recursive type\n LL | fn generator_hold() -> impl Sized {\n    |                        ^^^^^^^^^^ expands to a recursive type\n    |\n-   = note: expanded type is `[generator@$DIR/recursive-impl-trait-type-indirect.rs:58:5: 62:6 {impl Sized, ()}]`\n+   = note: expanded type is `[generator@$DIR/recursive-impl-trait-type-indirect.rs:58:5: 62:6 {impl Sized, (), ()}]`\n \n error[E0720]: opaque type expands to a recursive type\n   --> $DIR/recursive-impl-trait-type-indirect.rs:69:26"}, {"sha": "cc298a28b97e5bc6e683fe5faee36d95d64720bf", "filename": "src/test/ui/issues/issue-66473.rs", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fissues%2Fissue-66473.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fissues%2Fissue-66473.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fissues%2Fissue-66473.rs?ref=3291ae33907f2a866ea6cea89113200555038d06"}, {"sha": "dbeef44bad0ec68b68ce3c3c06768df43587855c", "filename": "src/test/ui/issues/issue-66473.stderr", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fissues%2Fissue-66473.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Fissues%2Fissue-66473.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fissues%2Fissue-66473.stderr?ref=3291ae33907f2a866ea6cea89113200555038d06"}, {"sha": "97efb85ef64c7bdf02bffc441546eecdf4f91d4f", "filename": "src/test/ui/type-alias-impl-trait/issue-65918.rs", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Ftype-alias-impl-trait%2Fissue-65918.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Ftype-alias-impl-trait%2Fissue-65918.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ftype-alias-impl-trait%2Fissue-65918.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,49 @@\n+// build-pass\n+\n+#![feature(type_alias_impl_trait)]\n+\n+use std::marker::PhantomData;\n+\n+/* copied Index and TryFrom for convinience (and simplicity) */\n+trait MyIndex<T> {\n+    type O;\n+    fn my_index(self) -> Self::O;\n+}\n+trait MyFrom<T>: Sized {\n+    type Error;\n+    fn my_from(value: T) -> Result<Self, Self::Error>;\n+}\n+\n+/* MCVE starts here */\n+trait F {}\n+impl F for () {}\n+type DummyT<T> = impl F;\n+fn _dummy_t<T>() -> DummyT<T> {}\n+\n+struct Phantom1<T>(PhantomData<T>);\n+struct Phantom2<T>(PhantomData<T>);\n+struct Scope<T>(Phantom2<DummyT<T>>);\n+\n+impl<T> Scope<T> {\n+    fn new() -> Self {\n+        unimplemented!()\n+    }\n+}\n+\n+impl<T> MyFrom<Phantom2<T>> for Phantom1<T> {\n+    type Error = ();\n+    fn my_from(_: Phantom2<T>) -> Result<Self, Self::Error> {\n+        unimplemented!()\n+    }\n+}\n+\n+impl<T: MyFrom<Phantom2<DummyT<U>>>, U> MyIndex<Phantom1<T>> for Scope<U> {\n+    type O = T;\n+    fn my_index(self) -> Self::O {\n+        MyFrom::my_from(self.0).ok().unwrap()\n+    }\n+}\n+\n+fn main() {\n+    let _pos: Phantom1<DummyT<()>> = Scope::new().my_index();\n+}"}, {"sha": "86c7c52b27166ed608d80c9353c31e5db16e8eef", "filename": "src/test/ui/typeck/typeck_type_placeholder_item.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Ftypeck%2Ftypeck_type_placeholder_item.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Ftypeck%2Ftypeck_type_placeholder_item.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ftypeck%2Ftypeck_type_placeholder_item.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -68,6 +68,13 @@ struct Test10 {\n }\n \n pub fn main() {\n+    static A = 42;\n+    //~^ ERROR missing type for `static` item\n+    static B: _ = 42;\n+    //~^ ERROR the type placeholder `_` is not allowed within types on item signatures\n+    static C: Option<_> = Some(42);\n+    //~^ ERROR the type placeholder `_` is not allowed within types on item signatures\n+\n     fn fn_test() -> _ { 5 }\n     //~^ ERROR the type placeholder `_` is not allowed within types on item signatures\n "}, {"sha": "f740a9f7f34b115536a4071d67230a0d8c7cc1ac", "filename": "src/test/ui/typeck/typeck_type_placeholder_item.stderr", "status": "modified", "additions": 59, "deletions": 38, "changes": 97, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Ftypeck%2Ftypeck_type_placeholder_item.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftest%2Fui%2Ftypeck%2Ftypeck_type_placeholder_item.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ftypeck%2Ftypeck_type_placeholder_item.stderr?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -1,35 +1,35 @@\n error: expected identifier, found reserved identifier `_`\n-  --> $DIR/typeck_type_placeholder_item.rs:146:18\n+  --> $DIR/typeck_type_placeholder_item.rs:153:18\n    |\n LL | struct BadStruct<_>(_);\n    |                  ^ expected identifier, found reserved identifier\n \n error: expected identifier, found reserved identifier `_`\n-  --> $DIR/typeck_type_placeholder_item.rs:149:16\n+  --> $DIR/typeck_type_placeholder_item.rs:156:16\n    |\n LL | trait BadTrait<_> {}\n    |                ^ expected identifier, found reserved identifier\n \n error: expected identifier, found reserved identifier `_`\n-  --> $DIR/typeck_type_placeholder_item.rs:159:19\n+  --> $DIR/typeck_type_placeholder_item.rs:166:19\n    |\n LL | struct BadStruct1<_, _>(_);\n    |                   ^ expected identifier, found reserved identifier\n \n error: expected identifier, found reserved identifier `_`\n-  --> $DIR/typeck_type_placeholder_item.rs:159:22\n+  --> $DIR/typeck_type_placeholder_item.rs:166:22\n    |\n LL | struct BadStruct1<_, _>(_);\n    |                      ^ expected identifier, found reserved identifier\n \n error: expected identifier, found reserved identifier `_`\n-  --> $DIR/typeck_type_placeholder_item.rs:164:19\n+  --> $DIR/typeck_type_placeholder_item.rs:171:19\n    |\n LL | struct BadStruct2<_, T>(_, T);\n    |                   ^ expected identifier, found reserved identifier\n \n error[E0403]: the name `_` is already used for a generic parameter in this item's generic parameters\n-  --> $DIR/typeck_type_placeholder_item.rs:159:22\n+  --> $DIR/typeck_type_placeholder_item.rs:166:22\n    |\n LL | struct BadStruct1<_, _>(_);\n    |                   -  ^ already used\n@@ -177,8 +177,29 @@ LL |\n LL |     b: (T, T),\n    |\n \n+error: missing type for `static` item\n+  --> $DIR/typeck_type_placeholder_item.rs:71:12\n+   |\n+LL |     static A = 42;\n+   |            ^ help: provide a type for the item: `A: i32`\n+\n+error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n+  --> $DIR/typeck_type_placeholder_item.rs:73:15\n+   |\n+LL |     static B: _ = 42;\n+   |               ^\n+   |               |\n+   |               not allowed in type signatures\n+   |               help: replace `_` with the correct type: `i32`\n+\n+error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n+  --> $DIR/typeck_type_placeholder_item.rs:75:15\n+   |\n+LL |     static C: Option<_> = Some(42);\n+   |               ^^^^^^^^^ not allowed in type signatures\n+\n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:71:21\n+  --> $DIR/typeck_type_placeholder_item.rs:78:21\n    |\n LL |     fn fn_test() -> _ { 5 }\n    |                     ^\n@@ -187,7 +208,7 @@ LL |     fn fn_test() -> _ { 5 }\n    |                     help: replace with the correct return type: `i32`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:74:23\n+  --> $DIR/typeck_type_placeholder_item.rs:81:23\n    |\n LL |     fn fn_test2() -> (_, _) { (5, 5) }\n    |                      -^--^-\n@@ -197,7 +218,7 @@ LL |     fn fn_test2() -> (_, _) { (5, 5) }\n    |                      help: replace with the correct return type: `(i32, i32)`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:77:22\n+  --> $DIR/typeck_type_placeholder_item.rs:84:22\n    |\n LL |     static FN_TEST3: _ = \"test\";\n    |                      ^\n@@ -206,7 +227,7 @@ LL |     static FN_TEST3: _ = \"test\";\n    |                      help: replace `_` with the correct type: `&'static str`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:80:22\n+  --> $DIR/typeck_type_placeholder_item.rs:87:22\n    |\n LL |     static FN_TEST4: _ = 145;\n    |                      ^\n@@ -215,13 +236,13 @@ LL |     static FN_TEST4: _ = 145;\n    |                      help: replace `_` with the correct type: `i32`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:83:22\n+  --> $DIR/typeck_type_placeholder_item.rs:90:22\n    |\n LL |     static FN_TEST5: (_, _) = (1, 2);\n    |                      ^^^^^^ not allowed in type signatures\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:86:20\n+  --> $DIR/typeck_type_placeholder_item.rs:93:20\n    |\n LL |     fn fn_test6(_: _) { }\n    |                    ^ not allowed in type signatures\n@@ -232,7 +253,7 @@ LL |     fn fn_test6<T>(_: T) { }\n    |                ^^^    ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:89:20\n+  --> $DIR/typeck_type_placeholder_item.rs:96:20\n    |\n LL |     fn fn_test7(x: _) { let _x: usize = x; }\n    |                    ^ not allowed in type signatures\n@@ -243,13 +264,13 @@ LL |     fn fn_test7<T>(x: T) { let _x: usize = x; }\n    |                ^^^    ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:92:29\n+  --> $DIR/typeck_type_placeholder_item.rs:99:29\n    |\n LL |     fn fn_test8(_f: fn() -> _) { }\n    |                             ^ not allowed in type signatures\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:92:29\n+  --> $DIR/typeck_type_placeholder_item.rs:99:29\n    |\n LL |     fn fn_test8(_f: fn() -> _) { }\n    |                             ^ not allowed in type signatures\n@@ -260,7 +281,7 @@ LL |     fn fn_test8<T>(_f: fn() -> T) { }\n    |                ^^^             ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:115:12\n+  --> $DIR/typeck_type_placeholder_item.rs:122:12\n    |\n LL |         a: _,\n    |            ^ not allowed in type signatures\n@@ -279,21 +300,21 @@ LL |         b: (T, T),\n    |\n \n error[E0282]: type annotations needed\n-  --> $DIR/typeck_type_placeholder_item.rs:120:27\n+  --> $DIR/typeck_type_placeholder_item.rs:127:27\n    |\n LL |     fn fn_test11(_: _) -> (_, _) { panic!() }\n    |                           ^^^^^^ cannot infer type\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:120:28\n+  --> $DIR/typeck_type_placeholder_item.rs:127:28\n    |\n LL |     fn fn_test11(_: _) -> (_, _) { panic!() }\n    |                            ^  ^ not allowed in type signatures\n    |                            |\n    |                            not allowed in type signatures\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:124:30\n+  --> $DIR/typeck_type_placeholder_item.rs:131:30\n    |\n LL |     fn fn_test12(x: i32) -> (_, _) { (x, x) }\n    |                             -^--^-\n@@ -303,7 +324,7 @@ LL |     fn fn_test12(x: i32) -> (_, _) { (x, x) }\n    |                             help: replace with the correct return type: `(i32, i32)`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:127:33\n+  --> $DIR/typeck_type_placeholder_item.rs:134:33\n    |\n LL |     fn fn_test13(x: _) -> (i32, _) { (x, x) }\n    |                           ------^-\n@@ -312,7 +333,7 @@ LL |     fn fn_test13(x: _) -> (i32, _) { (x, x) }\n    |                           help: replace with the correct return type: `(i32, i32)`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:146:21\n+  --> $DIR/typeck_type_placeholder_item.rs:153:21\n    |\n LL | struct BadStruct<_>(_);\n    |                     ^ not allowed in type signatures\n@@ -323,7 +344,7 @@ LL | struct BadStruct<T>(T);\n    |                  ^  ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:151:15\n+  --> $DIR/typeck_type_placeholder_item.rs:158:15\n    |\n LL | impl BadTrait<_> for BadStruct<_> {}\n    |               ^                ^ not allowed in type signatures\n@@ -336,13 +357,13 @@ LL | impl<T> BadTrait<T> for BadStruct<T> {}\n    |     ^^^          ^                ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:154:34\n+  --> $DIR/typeck_type_placeholder_item.rs:161:34\n    |\n LL | fn impl_trait() -> impl BadTrait<_> {\n    |                                  ^ not allowed in type signatures\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:159:25\n+  --> $DIR/typeck_type_placeholder_item.rs:166:25\n    |\n LL | struct BadStruct1<_, _>(_);\n    |                         ^ not allowed in type signatures\n@@ -353,7 +374,7 @@ LL | struct BadStruct1<T, _>(T);\n    |                   ^     ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:164:25\n+  --> $DIR/typeck_type_placeholder_item.rs:171:25\n    |\n LL | struct BadStruct2<_, T>(_, T);\n    |                         ^ not allowed in type signatures\n@@ -364,7 +385,7 @@ LL | struct BadStruct2<K, T>(K, T);\n    |                   ^     ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:168:14\n+  --> $DIR/typeck_type_placeholder_item.rs:175:14\n    |\n LL | type X = Box<_>;\n    |              ^ not allowed in type signatures\n@@ -381,7 +402,7 @@ LL |     fn test10<T>(&self, _x : T) { }\n    |              ^^^             ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:132:31\n+  --> $DIR/typeck_type_placeholder_item.rs:139:31\n    |\n LL |     fn method_test1(&self, x: _);\n    |                               ^ not allowed in type signatures\n@@ -392,7 +413,7 @@ LL |     fn method_test1<T>(&self, x: T);\n    |                    ^^^           ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:134:31\n+  --> $DIR/typeck_type_placeholder_item.rs:141:31\n    |\n LL |     fn method_test2(&self, x: _) -> _;\n    |                               ^     ^ not allowed in type signatures\n@@ -405,7 +426,7 @@ LL |     fn method_test2<T>(&self, x: T) -> T;\n    |                    ^^^           ^     ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:136:31\n+  --> $DIR/typeck_type_placeholder_item.rs:143:31\n    |\n LL |     fn method_test3(&self) -> _;\n    |                               ^ not allowed in type signatures\n@@ -416,7 +437,7 @@ LL |     fn method_test3<T>(&self) -> T;\n    |                    ^^^           ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:138:26\n+  --> $DIR/typeck_type_placeholder_item.rs:145:26\n    |\n LL |     fn assoc_fn_test1(x: _);\n    |                          ^ not allowed in type signatures\n@@ -427,7 +448,7 @@ LL |     fn assoc_fn_test1<T>(x: T);\n    |                      ^^^    ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:140:26\n+  --> $DIR/typeck_type_placeholder_item.rs:147:26\n    |\n LL |     fn assoc_fn_test2(x: _) -> _;\n    |                          ^     ^ not allowed in type signatures\n@@ -440,7 +461,7 @@ LL |     fn assoc_fn_test2<T>(x: T) -> T;\n    |                      ^^^    ^     ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:142:28\n+  --> $DIR/typeck_type_placeholder_item.rs:149:28\n    |\n LL |     fn assoc_fn_test3() -> _;\n    |                            ^ not allowed in type signatures\n@@ -462,7 +483,7 @@ LL |     fn clone_from<T>(&mut self, other: T) { *self = Test9; }\n    |                  ^^^                   ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:102:34\n+  --> $DIR/typeck_type_placeholder_item.rs:109:34\n    |\n LL |         fn fn_test10(&self, _x : _) { }\n    |                                  ^ not allowed in type signatures\n@@ -473,7 +494,7 @@ LL |         fn fn_test10<T>(&self, _x : T) { }\n    |                     ^^^             ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:110:41\n+  --> $DIR/typeck_type_placeholder_item.rs:117:41\n    |\n LL |         fn clone_from(&mut self, other: _) { *self = FnTest9; }\n    |                                         ^ not allowed in type signatures\n@@ -484,7 +505,7 @@ LL |         fn clone_from<T>(&mut self, other: T) { *self = FnTest9; }\n    |                      ^^^                   ^\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:174:21\n+  --> $DIR/typeck_type_placeholder_item.rs:181:21\n    |\n LL | type Y = impl Trait<_>;\n    |                     ^ not allowed in type signatures\n@@ -508,7 +529,7 @@ LL |     fn clone(&self) -> _ { Test9 }\n    |                        help: replace with the correct return type: `Test9`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:99:31\n+  --> $DIR/typeck_type_placeholder_item.rs:106:31\n    |\n LL |         fn fn_test9(&self) -> _ { () }\n    |                               ^\n@@ -517,15 +538,15 @@ LL |         fn fn_test9(&self) -> _ { () }\n    |                               help: replace with the correct return type: `()`\n \n error[E0121]: the type placeholder `_` is not allowed within types on item signatures\n-  --> $DIR/typeck_type_placeholder_item.rs:107:28\n+  --> $DIR/typeck_type_placeholder_item.rs:114:28\n    |\n LL |         fn clone(&self) -> _ { FnTest9 }\n    |                            ^\n    |                            |\n    |                            not allowed in type signatures\n    |                            help: replace with the correct return type: `main::FnTest9`\n \n-error: aborting due to 55 previous errors\n+error: aborting due to 58 previous errors\n \n Some errors have detailed explanations: E0121, E0282, E0403.\n For more information about an error, try `rustc --explain E0121`."}, {"sha": "92344cdfc89eed1a9c889f6402ce3f508e70fc02", "filename": "src/tools/unicode-table-generator/Cargo.toml", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2FCargo.toml?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,10 @@\n+[package]\n+name = \"unicode-bdd\"\n+version = \"0.1.0\"\n+authors = [\"Mark Rousskov <mark.simulacrum@gmail.com>\"]\n+edition = \"2018\"\n+\n+# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n+\n+[dependencies]\n+ucd-parse = \"0.1.3\""}, {"sha": "01f199c213e02441bf3d15393b80dacbafff1a2e", "filename": "src/tools/unicode-table-generator/src/case_mapping.rs", "status": "added", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fcase_mapping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fcase_mapping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fcase_mapping.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,62 @@\n+use crate::{fmt_list, UnicodeData};\n+use std::fmt;\n+\n+pub(crate) fn generate_case_mapping(data: &UnicodeData) -> String {\n+    let mut file = String::new();\n+\n+    file.push_str(HEADER.trim_start());\n+\n+    let decl_type = \"&[(char, [char; 3])]\";\n+\n+    file.push_str(&format!(\n+        \"static LOWERCASE_TABLE: {} = &[{}];\",\n+        decl_type,\n+        fmt_list(data.to_lower.iter().map(to_mapping))\n+    ));\n+    file.push_str(\"\\n\\n\");\n+    file.push_str(&format!(\n+        \"static UPPERCASE_TABLE: {} = &[{}];\",\n+        decl_type,\n+        fmt_list(data.to_upper.iter().map(to_mapping))\n+    ));\n+    file\n+}\n+\n+fn to_mapping((key, (a, b, c)): (&u32, &(u32, u32, u32))) -> (CharEscape, [CharEscape; 3]) {\n+    (\n+        CharEscape(std::char::from_u32(*key).unwrap()),\n+        [\n+            CharEscape(std::char::from_u32(*a).unwrap()),\n+            CharEscape(std::char::from_u32(*b).unwrap()),\n+            CharEscape(std::char::from_u32(*c).unwrap()),\n+        ],\n+    )\n+}\n+\n+struct CharEscape(char);\n+\n+impl fmt::Debug for CharEscape {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        write!(f, \"'{}'\", self.0.escape_default())\n+    }\n+}\n+\n+static HEADER: &str = \"\n+pub fn to_lower(c: char) -> [char; 3] {\n+    match bsearch_case_table(c, LOWERCASE_TABLE) {\n+        None => [c, '\\\\0', '\\\\0'],\n+        Some(index) => LOWERCASE_TABLE[index].1,\n+    }\n+}\n+\n+pub fn to_upper(c: char) -> [char; 3] {\n+    match bsearch_case_table(c, UPPERCASE_TABLE) {\n+        None => [c, '\\\\0', '\\\\0'],\n+        Some(index) => UPPERCASE_TABLE[index].1,\n+    }\n+}\n+\n+fn bsearch_case_table(c: char, table: &[(char, [char; 3])]) -> Option<usize> {\n+    table.binary_search_by(|&(key, _)| key.cmp(&c)).ok()\n+}\n+\";"}, {"sha": "be8508e3973a2486bc6f1b43d58371a7f5bfa23d", "filename": "src/tools/unicode-table-generator/src/main.rs", "status": "added", "additions": 261, "deletions": 0, "changes": 261, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fmain.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,261 @@\n+use std::collections::{BTreeMap, HashMap};\n+use std::ops::Range;\n+use ucd_parse::Codepoints;\n+\n+mod case_mapping;\n+mod raw_emitter;\n+mod unicode_download;\n+\n+use raw_emitter::{emit_codepoints, RawEmitter};\n+\n+static PROPERTIES: &[&str] = &[\n+    \"Alphabetic\",\n+    \"Lowercase\",\n+    \"Uppercase\",\n+    \"Cased\",\n+    \"Case_Ignorable\",\n+    \"Grapheme_Extend\",\n+    \"White_Space\",\n+    \"Cc\",\n+    \"N\",\n+];\n+\n+struct UnicodeData {\n+    ranges: Vec<(&'static str, Vec<Range<u32>>)>,\n+    to_upper: BTreeMap<u32, (u32, u32, u32)>,\n+    to_lower: BTreeMap<u32, (u32, u32, u32)>,\n+}\n+\n+fn to_mapping(origin: u32, codepoints: Vec<ucd_parse::Codepoint>) -> Option<(u32, u32, u32)> {\n+    let mut a = None;\n+    let mut b = None;\n+    let mut c = None;\n+\n+    for codepoint in codepoints {\n+        if origin == codepoint.value() {\n+            return None;\n+        }\n+\n+        if a.is_none() {\n+            a = Some(codepoint.value());\n+        } else if b.is_none() {\n+            b = Some(codepoint.value());\n+        } else if c.is_none() {\n+            c = Some(codepoint.value());\n+        } else {\n+            panic!(\"more than 3 mapped codepoints\")\n+        }\n+    }\n+\n+    Some((a.unwrap(), b.unwrap_or(0), c.unwrap_or(0)))\n+}\n+\n+static UNICODE_DIRECTORY: &str = \"unicode-downloads\";\n+\n+fn load_data() -> UnicodeData {\n+    unicode_download::fetch_latest();\n+\n+    let mut properties = HashMap::new();\n+    for row in ucd_parse::parse::<_, ucd_parse::CoreProperty>(&UNICODE_DIRECTORY).unwrap() {\n+        if let Some(name) = PROPERTIES.iter().find(|prop| **prop == row.property.as_str()) {\n+            properties.entry(*name).or_insert_with(Vec::new).push(row.codepoints);\n+        }\n+    }\n+    for row in ucd_parse::parse::<_, ucd_parse::Property>(&UNICODE_DIRECTORY).unwrap() {\n+        if let Some(name) = PROPERTIES.iter().find(|prop| **prop == row.property.as_str()) {\n+            properties.entry(*name).or_insert_with(Vec::new).push(row.codepoints);\n+        }\n+    }\n+\n+    let mut to_lower = BTreeMap::new();\n+    let mut to_upper = BTreeMap::new();\n+    for row in ucd_parse::UnicodeDataExpander::new(\n+        ucd_parse::parse::<_, ucd_parse::UnicodeData>(&UNICODE_DIRECTORY).unwrap(),\n+    ) {\n+        let general_category = if [\"Nd\", \"Nl\", \"No\"].contains(&row.general_category.as_str()) {\n+            \"N\"\n+        } else {\n+            row.general_category.as_str()\n+        };\n+        if let Some(name) = PROPERTIES.iter().find(|prop| **prop == general_category) {\n+            properties\n+                .entry(*name)\n+                .or_insert_with(Vec::new)\n+                .push(Codepoints::Single(row.codepoint));\n+        }\n+\n+        if let Some(mapped) = row.simple_lowercase_mapping {\n+            if mapped != row.codepoint {\n+                to_lower.insert(row.codepoint.value(), (mapped.value(), 0, 0));\n+            }\n+        }\n+        if let Some(mapped) = row.simple_uppercase_mapping {\n+            if mapped != row.codepoint {\n+                to_upper.insert(row.codepoint.value(), (mapped.value(), 0, 0));\n+            }\n+        }\n+    }\n+\n+    for row in ucd_parse::parse::<_, ucd_parse::SpecialCaseMapping>(&UNICODE_DIRECTORY).unwrap() {\n+        if !row.conditions.is_empty() {\n+            // Skip conditional case mappings\n+            continue;\n+        }\n+\n+        let key = row.codepoint.value();\n+        if let Some(lower) = to_mapping(key, row.lowercase) {\n+            to_lower.insert(key, lower);\n+        }\n+        if let Some(upper) = to_mapping(key, row.uppercase) {\n+            to_upper.insert(key, upper);\n+        }\n+    }\n+\n+    let mut properties: HashMap<&'static str, Vec<Range<u32>>> = properties\n+        .into_iter()\n+        .map(|(k, v)| {\n+            (\n+                k,\n+                v.into_iter()\n+                    .flat_map(|codepoints| match codepoints {\n+                        Codepoints::Single(c) => c\n+                            .scalar()\n+                            .map(|ch| (ch as u32..ch as u32 + 1))\n+                            .into_iter()\n+                            .collect::<Vec<_>>(),\n+                        Codepoints::Range(c) => c\n+                            .into_iter()\n+                            .flat_map(|c| c.scalar().map(|ch| (ch as u32..ch as u32 + 1)))\n+                            .collect::<Vec<_>>(),\n+                    })\n+                    .collect::<Vec<Range<u32>>>(),\n+            )\n+        })\n+        .collect();\n+\n+    for ranges in properties.values_mut() {\n+        merge_ranges(ranges);\n+    }\n+\n+    let mut properties = properties.into_iter().collect::<Vec<_>>();\n+    properties.sort_by_key(|p| p.0);\n+    UnicodeData { ranges: properties, to_lower, to_upper }\n+}\n+\n+fn main() {\n+    let write_location = std::env::args().nth(1).unwrap_or_else(|| {\n+        eprintln!(\"Must provide path to write unicode tables to\");\n+        eprintln!(\n+            \"e.g. {} src/libcore/unicode/unicode_data.rs\",\n+            std::env::args().nth(0).unwrap_or_default()\n+        );\n+        std::process::exit(1);\n+    });\n+\n+    let unicode_data = load_data();\n+    let ranges_by_property = &unicode_data.ranges;\n+\n+    let mut total_bytes = 0;\n+    let mut modules = Vec::new();\n+    for (property, ranges) in ranges_by_property {\n+        let datapoints = ranges.iter().map(|r| r.end - r.start).sum::<u32>();\n+        let mut emitter = RawEmitter::new();\n+        emit_codepoints(&mut emitter, &ranges);\n+\n+        modules.push((property.to_lowercase().to_string(), emitter.file));\n+        println!(\"{:15}: {} bytes, {} codepoints\", property, emitter.bytes_used, datapoints,);\n+        total_bytes += emitter.bytes_used;\n+    }\n+\n+    let mut table_file = String::new();\n+\n+    table_file.push_str(\n+        \"///! This file is generated by src/tools/unicode-table-generator; do not edit manually!\\n\",\n+    );\n+\n+    table_file.push_str(\"use super::range_search;\\n\\n\");\n+\n+    table_file.push_str(&version());\n+\n+    table_file.push('\\n');\n+\n+    modules.push((String::from(\"conversions\"), case_mapping::generate_case_mapping(&unicode_data)));\n+\n+    for (name, contents) in modules {\n+        table_file.push_str(\"#[rustfmt::skip]\\n\");\n+        table_file.push_str(&format!(\"pub mod {} {{\\n\", name));\n+        for line in contents.lines() {\n+            if !line.trim().is_empty() {\n+                table_file.push_str(\"    \");\n+                table_file.push_str(&line);\n+            }\n+            table_file.push('\\n');\n+        }\n+        table_file.push_str(\"}\\n\\n\");\n+    }\n+\n+    std::fs::write(&write_location, format!(\"{}\\n\", table_file.trim_end())).unwrap();\n+\n+    println!(\"Total table sizes: {} bytes\", total_bytes);\n+}\n+\n+fn version() -> String {\n+    let mut out = String::new();\n+    out.push_str(\"pub const UNICODE_VERSION: (u32, u32, u32) = \");\n+\n+    let readme =\n+        std::fs::read_to_string(std::path::Path::new(UNICODE_DIRECTORY).join(\"ReadMe.txt\"))\n+            .unwrap();\n+\n+    let prefix = \"for Version \";\n+    let start = readme.find(prefix).unwrap() + prefix.len();\n+    let end = readme.find(\" of the Unicode Standard.\").unwrap();\n+    let version =\n+        readme[start..end].split('.').map(|v| v.parse::<u32>().expect(&v)).collect::<Vec<_>>();\n+    let [major, minor, micro] = [version[0], version[1], version[2]];\n+\n+    out.push_str(&format!(\"({}, {}, {});\\n\", major, minor, micro));\n+    out\n+}\n+\n+fn fmt_list<V: std::fmt::Debug>(values: impl IntoIterator<Item = V>) -> String {\n+    let pieces = values.into_iter().map(|b| format!(\"{:?}, \", b)).collect::<Vec<_>>();\n+    let mut out = String::new();\n+    let mut line = format!(\"\\n    \");\n+    for piece in pieces {\n+        if line.len() + piece.len() < 98 {\n+            line.push_str(&piece);\n+        } else {\n+            out.push_str(line.trim_end());\n+            out.push('\\n');\n+            line = format!(\"    {}\", piece);\n+        }\n+    }\n+    out.push_str(line.trim_end());\n+    out.push('\\n');\n+    out\n+}\n+\n+fn merge_ranges(ranges: &mut Vec<Range<u32>>) {\n+    loop {\n+        let mut new_ranges = Vec::new();\n+        let mut idx_iter = 0..(ranges.len() - 1);\n+        while let Some(idx) = idx_iter.next() {\n+            let cur = ranges[idx].clone();\n+            let next = ranges[idx + 1].clone();\n+            if cur.end == next.start {\n+                let _ = idx_iter.next(); // skip next as we're merging it in\n+                new_ranges.push(cur.start..next.end);\n+            } else {\n+                new_ranges.push(cur);\n+            }\n+        }\n+        new_ranges.push(ranges.last().unwrap().clone());\n+        if new_ranges.len() == ranges.len() {\n+            *ranges = new_ranges;\n+            break;\n+        } else {\n+            *ranges = new_ranges;\n+        }\n+    }\n+}"}, {"sha": "3e60ce13f9223fc24082eb167bfa5f6bb9e36f8a", "filename": "src/tools/unicode-table-generator/src/raw_emitter.rs", "status": "added", "additions": 170, "deletions": 0, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fraw_emitter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fraw_emitter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Fraw_emitter.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,170 @@\n+//! This implements the core logic of the compression scheme used to compactly\n+//! encode the Unicode character classes.\n+//!\n+//! The primary idea is that we 'flatten' the Unicode ranges into an enormous\n+//! bitset. To represent any arbitrary codepoint in a raw bitset, we would need\n+//! over 17 kilobytes of data per character set -- way too much for our\n+//! purposes.\n+//!\n+//! We have two primary goals with the encoding: we want to be compact, because\n+//! these tables often end up in ~every Rust program (especially the\n+//! grapheme_extend table, used for str debugging), including those for embedded\n+//! targets (where space is important). We also want to be relatively fast,\n+//! though this is more of a nice to have rather than a key design constraint.\n+//! In practice, due to modern processor design these two are closely related.\n+//!\n+//! The encoding scheme here compresses the bitset by first deduplicating the\n+//! \"words\" (64 bits on all platforms). In practice very few words are present\n+//! in most data sets.\n+//!\n+//! This gives us an array that maps `u8 -> word` (if we ever went beyond 256\n+//! words, we could go to u16 -> word or have some dual compression scheme\n+//! mapping into two separate sets; currently this is not dealt with).\n+//!\n+//! With that scheme, we now have a single byte for every 64 codepoints. We\n+//! further group these by 16 (arbitrarily chosen), and again deduplicate and\n+//! store in an array (u8 -> [u8; 16]).\n+//!\n+//! The indices into this array represent ranges of 64*16 = 1024 codepoints.\n+//!\n+//! This already reduces the top-level array to at most 1,086 bytes, but in\n+//! practice we usually can encode in far fewer (the first couple Unicode planes\n+//! are dense).\n+//!\n+//! The last byte of this top-level array is pulled out to a separate static\n+//! and trailing zeros are dropped; this is simply because grapheme_extend and\n+//! case_ignorable have a single entry in the 896th entry, so this shrinks them\n+//! down considerably.\n+\n+use crate::fmt_list;\n+use std::collections::{BTreeSet, HashMap};\n+use std::convert::TryFrom;\n+use std::fmt::Write;\n+use std::ops::Range;\n+\n+pub struct RawEmitter {\n+    pub file: String,\n+    pub bytes_used: usize,\n+}\n+\n+impl RawEmitter {\n+    pub fn new() -> RawEmitter {\n+        RawEmitter { file: String::new(), bytes_used: 0 }\n+    }\n+\n+    fn blank_line(&mut self) {\n+        if self.file.is_empty() || self.file.ends_with(\"\\n\\n\") {\n+            return;\n+        }\n+        writeln!(&mut self.file, \"\").unwrap();\n+    }\n+\n+    fn emit_bitset(&mut self, words: &[u64]) {\n+        let unique_words =\n+            words.iter().cloned().collect::<BTreeSet<_>>().into_iter().collect::<Vec<_>>();\n+        if unique_words.len() > u8::max_value() as usize {\n+            panic!(\"cannot pack {} into 8 bits\", unique_words.len());\n+        }\n+\n+        let word_indices = unique_words\n+            .iter()\n+            .cloned()\n+            .enumerate()\n+            .map(|(idx, word)| (word, u8::try_from(idx).unwrap()))\n+            .collect::<HashMap<_, _>>();\n+\n+        let mut idx = words.iter().map(|w| word_indices[w]).collect::<Vec<u8>>();\n+        let chunk_length = 16;\n+        for _ in 0..(chunk_length - (idx.len() % chunk_length)) {\n+            assert_eq!(unique_words[0], 0, \"first word is all zeros\");\n+            // pad out bitset index with zero words so we have all chunks of 16\n+            idx.push(0);\n+        }\n+\n+        let mut chunks = BTreeSet::new();\n+        for chunk in idx.chunks(chunk_length) {\n+            chunks.insert(chunk);\n+        }\n+        let chunk_map = chunks\n+            .clone()\n+            .into_iter()\n+            .enumerate()\n+            .map(|(idx, chunk)| (chunk, idx))\n+            .collect::<HashMap<_, _>>();\n+        let mut chunk_indices = Vec::new();\n+        for chunk in idx.chunks(chunk_length) {\n+            chunk_indices.push(chunk_map[chunk]);\n+        }\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET_LAST_CHUNK_MAP: (u16, u8) = ({}, {});\",\n+            chunk_indices.len() - 1,\n+            chunk_indices.pop().unwrap(),\n+        )\n+        .unwrap();\n+        self.bytes_used += 3;\n+        // Strip out the empty pieces, presuming our above pop() made us now\n+        // have some trailing zeros.\n+        assert_eq!(unique_words[0], 0, \"first word is all zeros\");\n+        while let Some(0) = chunk_indices.last() {\n+            chunk_indices.pop();\n+        }\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET_CHUNKS_MAP: [u8; {}] = [{}];\",\n+            chunk_indices.len(),\n+            fmt_list(&chunk_indices),\n+        )\n+        .unwrap();\n+        self.bytes_used += chunk_indices.len();\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET_INDEX_CHUNKS: [[u8; 16]; {}] = [{}];\",\n+            chunks.len(),\n+            fmt_list(chunks.iter()),\n+        )\n+        .unwrap();\n+        self.bytes_used += 16 * chunks.len();\n+        writeln!(\n+            &mut self.file,\n+            \"static BITSET: [u64; {}] = [{}];\",\n+            unique_words.len(),\n+            fmt_list(&unique_words),\n+        )\n+        .unwrap();\n+        self.bytes_used += 8 * unique_words.len();\n+    }\n+\n+    pub fn emit_lookup(&mut self) {\n+        writeln!(&mut self.file, \"pub fn lookup(c: char) -> bool {{\").unwrap();\n+        writeln!(&mut self.file, \"    super::range_search(\",).unwrap();\n+        writeln!(&mut self.file, \"        c as u32,\").unwrap();\n+        writeln!(&mut self.file, \"        &BITSET_CHUNKS_MAP,\").unwrap();\n+        writeln!(&mut self.file, \"        BITSET_LAST_CHUNK_MAP,\").unwrap();\n+        writeln!(&mut self.file, \"        &BITSET_INDEX_CHUNKS,\").unwrap();\n+        writeln!(&mut self.file, \"        &BITSET,\").unwrap();\n+        writeln!(&mut self.file, \"    )\").unwrap();\n+        writeln!(&mut self.file, \"}}\").unwrap();\n+    }\n+}\n+\n+pub fn emit_codepoints(emitter: &mut RawEmitter, ranges: &[Range<u32>]) {\n+    emitter.blank_line();\n+\n+    let last_code_point = ranges.last().unwrap().end;\n+    // bitset for every bit in the codepoint range\n+    //\n+    // + 2 to ensure an all zero word to use for padding\n+    let mut buckets = vec![0u64; (last_code_point as usize / 64) + 2];\n+    for range in ranges {\n+        for codepoint in range.clone() {\n+            let bucket = codepoint as usize / 64;\n+            let bit = codepoint as u64 % 64;\n+            buckets[bucket] |= 1 << bit;\n+        }\n+    }\n+\n+    emitter.emit_bitset(&buckets);\n+    emitter.blank_line();\n+    emitter.emit_lookup();\n+}"}, {"sha": "3f6de9ea3bbd78b05b7f807876312da38f936e4e", "filename": "src/tools/unicode-table-generator/src/unicode_download.rs", "status": "added", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Funicode_download.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3291ae33907f2a866ea6cea89113200555038d06/src%2Ftools%2Funicode-table-generator%2Fsrc%2Funicode_download.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Funicode-table-generator%2Fsrc%2Funicode_download.rs?ref=3291ae33907f2a866ea6cea89113200555038d06", "patch": "@@ -0,0 +1,42 @@\n+use crate::UNICODE_DIRECTORY;\n+use std::path::Path;\n+use std::process::Command;\n+\n+static URL_PREFIX: &str = \"https://www.unicode.org/Public/UCD/latest/ucd/\";\n+\n+static README: &str = \"ReadMe.txt\";\n+\n+static RESOURCES: &[&str] =\n+    &[\"DerivedCoreProperties.txt\", \"PropList.txt\", \"UnicodeData.txt\", \"SpecialCasing.txt\"];\n+\n+pub fn fetch_latest() {\n+    let directory = Path::new(UNICODE_DIRECTORY);\n+    if let Err(e) = std::fs::create_dir_all(directory) {\n+        if e.kind() != std::io::ErrorKind::AlreadyExists {\n+            panic!(\"Failed to create {:?}: {}\", UNICODE_DIRECTORY, e);\n+        }\n+    }\n+    let output = Command::new(\"curl\").arg(URL_PREFIX.to_owned() + README).output().unwrap();\n+    if !output.status.success() {\n+        panic!(\n+            \"Failed to run curl to fetch readme: stderr: {}\",\n+            String::from_utf8_lossy(&output.stderr)\n+        );\n+    }\n+    let current = std::fs::read_to_string(directory.join(README)).unwrap_or_default();\n+    if current.as_bytes() != &output.stdout[..] {\n+        std::fs::write(directory.join(README), output.stdout).unwrap();\n+    }\n+\n+    for resource in RESOURCES {\n+        let output = Command::new(\"curl\").arg(URL_PREFIX.to_owned() + resource).output().unwrap();\n+        if !output.status.success() {\n+            panic!(\n+                \"Failed to run curl to fetch {}: stderr: {}\",\n+                resource,\n+                String::from_utf8_lossy(&output.stderr)\n+            );\n+        }\n+        std::fs::write(directory.join(resource), output.stdout).unwrap();\n+    }\n+}"}]}