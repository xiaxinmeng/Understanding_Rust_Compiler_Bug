{"sha": "315b0a7254974f1a2ef9777944531cdbca15be7b", "node_id": "C_kwDOAAsO6NoAKDMxNWIwYTcyNTQ5NzRmMWEyZWY5Nzc3OTQ0NTMxY2RiY2ExNWJlN2I", "commit": {"author": {"name": "Amos Wenger", "email": "amoswenger@gmail.com", "date": "2022-07-20T16:27:58Z"}, "committer": {"name": "Amos Wenger", "email": "amoswenger@gmail.com", "date": "2022-07-20T17:18:39Z"}, "message": "Add sysroot-abi feature, copy 1.64 ABI fo rnow", "tree": {"sha": "9253a013661089b17c1f8f410263d49b4075d5b8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9253a013661089b17c1f8f410263d49b4075d5b8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/315b0a7254974f1a2ef9777944531cdbca15be7b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/315b0a7254974f1a2ef9777944531cdbca15be7b", "html_url": "https://github.com/rust-lang/rust/commit/315b0a7254974f1a2ef9777944531cdbca15be7b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/315b0a7254974f1a2ef9777944531cdbca15be7b/comments", "author": {"login": "fasterthanlime", "id": 7998310, "node_id": "MDQ6VXNlcjc5OTgzMTA=", "avatar_url": "https://avatars.githubusercontent.com/u/7998310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fasterthanlime", "html_url": "https://github.com/fasterthanlime", "followers_url": "https://api.github.com/users/fasterthanlime/followers", "following_url": "https://api.github.com/users/fasterthanlime/following{/other_user}", "gists_url": "https://api.github.com/users/fasterthanlime/gists{/gist_id}", "starred_url": "https://api.github.com/users/fasterthanlime/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fasterthanlime/subscriptions", "organizations_url": "https://api.github.com/users/fasterthanlime/orgs", "repos_url": "https://api.github.com/users/fasterthanlime/repos", "events_url": "https://api.github.com/users/fasterthanlime/events{/privacy}", "received_events_url": "https://api.github.com/users/fasterthanlime/received_events", "type": "User", "site_admin": false}, "committer": {"login": "fasterthanlime", "id": 7998310, "node_id": "MDQ6VXNlcjc5OTgzMTA=", "avatar_url": "https://avatars.githubusercontent.com/u/7998310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fasterthanlime", "html_url": "https://github.com/fasterthanlime", "followers_url": "https://api.github.com/users/fasterthanlime/followers", "following_url": "https://api.github.com/users/fasterthanlime/following{/other_user}", "gists_url": "https://api.github.com/users/fasterthanlime/gists{/gist_id}", "starred_url": "https://api.github.com/users/fasterthanlime/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fasterthanlime/subscriptions", "organizations_url": "https://api.github.com/users/fasterthanlime/orgs", "repos_url": "https://api.github.com/users/fasterthanlime/repos", "events_url": "https://api.github.com/users/fasterthanlime/events{/privacy}", "received_events_url": "https://api.github.com/users/fasterthanlime/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fa883cb64715fb89c0ce673ee8bf5a141893d5da", "url": "https://api.github.com/repos/rust-lang/rust/commits/fa883cb64715fb89c0ce673ee8bf5a141893d5da", "html_url": "https://github.com/rust-lang/rust/commit/fa883cb64715fb89c0ce673ee8bf5a141893d5da"}], "stats": {"total": 904, "additions": 904, "deletions": 0}, "files": [{"sha": "e39026ac70bfd52e4d78b7b6a08a85d6938306ac", "filename": "crates/proc-macro-srv/Cargo.toml", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fproc-macro-srv%2FCargo.toml?ref=315b0a7254974f1a2ef9777944531cdbca15be7b", "patch": "@@ -30,3 +30,6 @@ expect-test = \"1.4.0\"\n \n # used as proc macro test targets\n proc-macro-test = { path = \"../proc-macro-test\" }\n+\n+[features]\n+sysroot-abi = []"}, {"sha": "44712f419191b1af43d9ec32f409e046bb7d3024", "filename": "crates/proc-macro-srv/src/abis/abi_sysroot/mod.rs", "status": "added", "additions": 102, "deletions": 0, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fabi_sysroot%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fabi_sysroot%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fabi_sysroot%2Fmod.rs?ref=315b0a7254974f1a2ef9777944531cdbca15be7b", "patch": "@@ -0,0 +1,102 @@\n+//! Proc macro ABI\n+\n+extern crate proc_macro;\n+\n+#[allow(dead_code)]\n+#[doc(hidden)]\n+mod ra_server;\n+\n+use libloading::Library;\n+use proc_macro_api::ProcMacroKind;\n+\n+use super::PanicMessage;\n+\n+pub(crate) struct Abi {\n+    exported_macros: Vec<proc_macro::bridge::client::ProcMacro>,\n+}\n+\n+impl From<proc_macro::bridge::PanicMessage> for PanicMessage {\n+    fn from(p: proc_macro::bridge::PanicMessage) -> Self {\n+        Self { message: p.as_str().map(|s| s.to_string()) }\n+    }\n+}\n+\n+impl Abi {\n+    pub unsafe fn from_lib(lib: &Library, symbol_name: String) -> Result<Abi, libloading::Error> {\n+        let macros: libloading::Symbol<'_, &&[proc_macro::bridge::client::ProcMacro]> =\n+            lib.get(symbol_name.as_bytes())?;\n+        Ok(Self { exported_macros: macros.to_vec() })\n+    }\n+\n+    pub fn expand(\n+        &self,\n+        macro_name: &str,\n+        macro_body: &tt::Subtree,\n+        attributes: Option<&tt::Subtree>,\n+    ) -> Result<tt::Subtree, PanicMessage> {\n+        let parsed_body = ra_server::TokenStream::with_subtree(macro_body.clone());\n+\n+        let parsed_attributes = attributes.map_or(ra_server::TokenStream::new(), |attr| {\n+            ra_server::TokenStream::with_subtree(attr.clone())\n+        });\n+\n+        for proc_macro in &self.exported_macros {\n+            match proc_macro {\n+                proc_macro::bridge::client::ProcMacro::CustomDerive {\n+                    trait_name, client, ..\n+                } if *trait_name == macro_name => {\n+                    let res = client.run(\n+                        &proc_macro::bridge::server::SameThread,\n+                        ra_server::RustAnalyzer::default(),\n+                        parsed_body,\n+                        true,\n+                    );\n+                    return res.map(|it| it.into_subtree()).map_err(PanicMessage::from);\n+                }\n+                proc_macro::bridge::client::ProcMacro::Bang { name, client }\n+                    if *name == macro_name =>\n+                {\n+                    let res = client.run(\n+                        &proc_macro::bridge::server::SameThread,\n+                        ra_server::RustAnalyzer::default(),\n+                        parsed_body,\n+                        true,\n+                    );\n+                    return res.map(|it| it.into_subtree()).map_err(PanicMessage::from);\n+                }\n+                proc_macro::bridge::client::ProcMacro::Attr { name, client }\n+                    if *name == macro_name =>\n+                {\n+                    let res = client.run(\n+                        &proc_macro::bridge::server::SameThread,\n+                        ra_server::RustAnalyzer::default(),\n+                        parsed_attributes,\n+                        parsed_body,\n+                        true,\n+                    );\n+                    return res.map(|it| it.into_subtree()).map_err(PanicMessage::from);\n+                }\n+                _ => continue,\n+            }\n+        }\n+\n+        Err(proc_macro::bridge::PanicMessage::String(\"Nothing to expand\".to_string()).into())\n+    }\n+\n+    pub fn list_macros(&self) -> Vec<(String, ProcMacroKind)> {\n+        self.exported_macros\n+            .iter()\n+            .map(|proc_macro| match proc_macro {\n+                proc_macro::bridge::client::ProcMacro::CustomDerive { trait_name, .. } => {\n+                    (trait_name.to_string(), ProcMacroKind::CustomDerive)\n+                }\n+                proc_macro::bridge::client::ProcMacro::Bang { name, .. } => {\n+                    (name.to_string(), ProcMacroKind::FuncLike)\n+                }\n+                proc_macro::bridge::client::ProcMacro::Attr { name, .. } => {\n+                    (name.to_string(), ProcMacroKind::Attr)\n+                }\n+            })\n+            .collect()\n+    }\n+}"}, {"sha": "00b9d9bd3d3eaf0471a6191e21a9bc5d54553fc0", "filename": "crates/proc-macro-srv/src/abis/abi_sysroot/ra_server.rs", "status": "added", "additions": 792, "deletions": 0, "changes": 792, "blob_url": "https://github.com/rust-lang/rust/blob/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fabi_sysroot%2Fra_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fabi_sysroot%2Fra_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fabi_sysroot%2Fra_server.rs?ref=315b0a7254974f1a2ef9777944531cdbca15be7b", "patch": "@@ -0,0 +1,792 @@\n+//! proc-macro server implementation\n+//!\n+//! Based on idea from <https://github.com/fedochet/rust-proc-macro-expander>\n+//! The lib-proc-macro server backend is `TokenStream`-agnostic, such that\n+//! we could provide any TokenStream implementation.\n+//! The original idea from fedochet is using proc-macro2 as backend,\n+//! we use tt instead for better integration with RA.\n+//!\n+//! FIXME: No span and source file information is implemented yet\n+\n+use super::proc_macro::bridge::{self, server};\n+\n+use std::collections::HashMap;\n+use std::hash::Hash;\n+use std::iter::FromIterator;\n+use std::ops::Bound;\n+use std::{ascii, vec::IntoIter};\n+\n+type Group = tt::Subtree;\n+type TokenTree = tt::TokenTree;\n+type Punct = tt::Punct;\n+type Spacing = tt::Spacing;\n+type Literal = tt::Literal;\n+type Span = tt::TokenId;\n+\n+#[derive(Debug, Default, Clone)]\n+pub struct TokenStream {\n+    pub token_trees: Vec<TokenTree>,\n+}\n+\n+impl TokenStream {\n+    pub fn new() -> Self {\n+        TokenStream::default()\n+    }\n+\n+    pub fn with_subtree(subtree: tt::Subtree) -> Self {\n+        if subtree.delimiter.is_some() {\n+            TokenStream { token_trees: vec![TokenTree::Subtree(subtree)] }\n+        } else {\n+            TokenStream { token_trees: subtree.token_trees }\n+        }\n+    }\n+\n+    pub fn into_subtree(self) -> tt::Subtree {\n+        tt::Subtree { delimiter: None, token_trees: self.token_trees }\n+    }\n+\n+    pub fn is_empty(&self) -> bool {\n+        self.token_trees.is_empty()\n+    }\n+}\n+\n+/// Creates a token stream containing a single token tree.\n+impl From<TokenTree> for TokenStream {\n+    fn from(tree: TokenTree) -> TokenStream {\n+        TokenStream { token_trees: vec![tree] }\n+    }\n+}\n+\n+/// Collects a number of token trees into a single stream.\n+impl FromIterator<TokenTree> for TokenStream {\n+    fn from_iter<I: IntoIterator<Item = TokenTree>>(trees: I) -> Self {\n+        trees.into_iter().map(TokenStream::from).collect()\n+    }\n+}\n+\n+/// A \"flattening\" operation on token streams, collects token trees\n+/// from multiple token streams into a single stream.\n+impl FromIterator<TokenStream> for TokenStream {\n+    fn from_iter<I: IntoIterator<Item = TokenStream>>(streams: I) -> Self {\n+        let mut builder = TokenStreamBuilder::new();\n+        streams.into_iter().for_each(|stream| builder.push(stream));\n+        builder.build()\n+    }\n+}\n+\n+impl Extend<TokenTree> for TokenStream {\n+    fn extend<I: IntoIterator<Item = TokenTree>>(&mut self, trees: I) {\n+        self.extend(trees.into_iter().map(TokenStream::from));\n+    }\n+}\n+\n+impl Extend<TokenStream> for TokenStream {\n+    fn extend<I: IntoIterator<Item = TokenStream>>(&mut self, streams: I) {\n+        for item in streams {\n+            for tkn in item {\n+                match tkn {\n+                    tt::TokenTree::Subtree(subtree) if subtree.delimiter.is_none() => {\n+                        self.token_trees.extend(subtree.token_trees);\n+                    }\n+                    _ => {\n+                        self.token_trees.push(tkn);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Clone)]\n+pub struct SourceFile {\n+    // FIXME stub\n+}\n+\n+type Level = super::proc_macro::Level;\n+type LineColumn = super::proc_macro::LineColumn;\n+\n+/// A structure representing a diagnostic message and associated children\n+/// messages.\n+#[derive(Clone, Debug)]\n+pub struct Diagnostic {\n+    level: Level,\n+    message: String,\n+    spans: Vec<Span>,\n+    children: Vec<Diagnostic>,\n+}\n+\n+impl Diagnostic {\n+    /// Creates a new diagnostic with the given `level` and `message`.\n+    pub fn new<T: Into<String>>(level: Level, message: T) -> Diagnostic {\n+        Diagnostic { level, message: message.into(), spans: vec![], children: vec![] }\n+    }\n+}\n+\n+// Rustc Server Ident has to be `Copyable`\n+// We use a stub here for bypassing\n+#[derive(Hash, Eq, PartialEq, Copy, Clone)]\n+pub struct IdentId(u32);\n+\n+#[derive(Clone, Hash, Eq, PartialEq)]\n+struct IdentData(tt::Ident);\n+\n+#[derive(Default)]\n+struct IdentInterner {\n+    idents: HashMap<IdentData, u32>,\n+    ident_data: Vec<IdentData>,\n+}\n+\n+impl IdentInterner {\n+    fn intern(&mut self, data: &IdentData) -> u32 {\n+        if let Some(index) = self.idents.get(data) {\n+            return *index;\n+        }\n+\n+        let index = self.idents.len() as u32;\n+        self.ident_data.push(data.clone());\n+        self.idents.insert(data.clone(), index);\n+        index\n+    }\n+\n+    fn get(&self, index: u32) -> &IdentData {\n+        &self.ident_data[index as usize]\n+    }\n+\n+    #[allow(unused)]\n+    fn get_mut(&mut self, index: u32) -> &mut IdentData {\n+        self.ident_data.get_mut(index as usize).expect(\"Should be consistent\")\n+    }\n+}\n+\n+pub struct TokenStreamBuilder {\n+    acc: TokenStream,\n+}\n+\n+/// Public implementation details for the `TokenStream` type, such as iterators.\n+pub mod token_stream {\n+    use std::str::FromStr;\n+\n+    use super::{TokenStream, TokenTree};\n+\n+    /// An iterator over `TokenStream`'s `TokenTree`s.\n+    /// The iteration is \"shallow\", e.g., the iterator doesn't recurse into delimited groups,\n+    /// and returns whole groups as token trees.\n+    impl IntoIterator for TokenStream {\n+        type Item = TokenTree;\n+        type IntoIter = super::IntoIter<TokenTree>;\n+\n+        fn into_iter(self) -> Self::IntoIter {\n+            self.token_trees.into_iter()\n+        }\n+    }\n+\n+    type LexError = String;\n+\n+    /// Attempts to break the string into tokens and parse those tokens into a token stream.\n+    /// May fail for a number of reasons, for example, if the string contains unbalanced delimiters\n+    /// or characters not existing in the language.\n+    /// All tokens in the parsed stream get `Span::call_site()` spans.\n+    ///\n+    /// NOTE: some errors may cause panics instead of returning `LexError`. We reserve the right to\n+    /// change these errors into `LexError`s later.\n+    impl FromStr for TokenStream {\n+        type Err = LexError;\n+\n+        fn from_str(src: &str) -> Result<TokenStream, LexError> {\n+            let (subtree, _token_map) =\n+                mbe::parse_to_token_tree(src).ok_or(\"Failed to parse from mbe\")?;\n+\n+            let subtree = subtree_replace_token_ids_with_unspecified(subtree);\n+            Ok(TokenStream::with_subtree(subtree))\n+        }\n+    }\n+\n+    impl ToString for TokenStream {\n+        fn to_string(&self) -> String {\n+            tt::pretty(&self.token_trees)\n+        }\n+    }\n+\n+    fn subtree_replace_token_ids_with_unspecified(subtree: tt::Subtree) -> tt::Subtree {\n+        tt::Subtree {\n+            delimiter: subtree\n+                .delimiter\n+                .map(|d| tt::Delimiter { id: tt::TokenId::unspecified(), ..d }),\n+            token_trees: subtree\n+                .token_trees\n+                .into_iter()\n+                .map(token_tree_replace_token_ids_with_unspecified)\n+                .collect(),\n+        }\n+    }\n+\n+    fn token_tree_replace_token_ids_with_unspecified(tt: tt::TokenTree) -> tt::TokenTree {\n+        match tt {\n+            tt::TokenTree::Leaf(leaf) => {\n+                tt::TokenTree::Leaf(leaf_replace_token_ids_with_unspecified(leaf))\n+            }\n+            tt::TokenTree::Subtree(subtree) => {\n+                tt::TokenTree::Subtree(subtree_replace_token_ids_with_unspecified(subtree))\n+            }\n+        }\n+    }\n+\n+    fn leaf_replace_token_ids_with_unspecified(leaf: tt::Leaf) -> tt::Leaf {\n+        match leaf {\n+            tt::Leaf::Literal(lit) => {\n+                tt::Leaf::Literal(tt::Literal { id: tt::TokenId::unspecified(), ..lit })\n+            }\n+            tt::Leaf::Punct(punct) => {\n+                tt::Leaf::Punct(tt::Punct { id: tt::TokenId::unspecified(), ..punct })\n+            }\n+            tt::Leaf::Ident(ident) => {\n+                tt::Leaf::Ident(tt::Ident { id: tt::TokenId::unspecified(), ..ident })\n+            }\n+        }\n+    }\n+}\n+\n+impl TokenStreamBuilder {\n+    fn new() -> TokenStreamBuilder {\n+        TokenStreamBuilder { acc: TokenStream::new() }\n+    }\n+\n+    fn push(&mut self, stream: TokenStream) {\n+        self.acc.extend(stream.into_iter())\n+    }\n+\n+    fn build(self) -> TokenStream {\n+        self.acc\n+    }\n+}\n+\n+pub struct FreeFunctions;\n+\n+#[derive(Clone)]\n+pub struct TokenStreamIter {\n+    trees: IntoIter<TokenTree>,\n+}\n+\n+#[derive(Default)]\n+pub struct RustAnalyzer {\n+    ident_interner: IdentInterner,\n+    // FIXME: store span information here.\n+}\n+\n+impl server::Types for RustAnalyzer {\n+    type FreeFunctions = FreeFunctions;\n+    type TokenStream = TokenStream;\n+    type Ident = IdentId;\n+    type Literal = Literal;\n+    type SourceFile = SourceFile;\n+    type Diagnostic = Diagnostic;\n+    type Span = Span;\n+    type MultiSpan = Vec<Span>;\n+}\n+\n+impl server::FreeFunctions for RustAnalyzer {\n+    fn track_env_var(&mut self, _var: &str, _value: Option<&str>) {\n+        // FIXME: track env var accesses\n+        // https://github.com/rust-lang/rust/pull/71858\n+    }\n+    fn track_path(&mut self, _path: &str) {}\n+}\n+\n+impl server::TokenStream for RustAnalyzer {\n+    fn is_empty(&mut self, stream: &Self::TokenStream) -> bool {\n+        stream.is_empty()\n+    }\n+    fn from_str(&mut self, src: &str) -> Self::TokenStream {\n+        use std::str::FromStr;\n+\n+        Self::TokenStream::from_str(src).expect(\"cannot parse string\")\n+    }\n+    fn to_string(&mut self, stream: &Self::TokenStream) -> String {\n+        stream.to_string()\n+    }\n+    fn from_token_tree(\n+        &mut self,\n+        tree: bridge::TokenTree<Self::TokenStream, Self::Span, Self::Ident, Self::Literal>,\n+    ) -> Self::TokenStream {\n+        match tree {\n+            bridge::TokenTree::Group(group) => {\n+                let group = Group {\n+                    delimiter: delim_to_internal(group.delimiter),\n+                    token_trees: match group.stream {\n+                        Some(stream) => stream.into_iter().collect(),\n+                        None => Vec::new(),\n+                    },\n+                };\n+                let tree = TokenTree::from(group);\n+                Self::TokenStream::from_iter(vec![tree])\n+            }\n+\n+            bridge::TokenTree::Ident(IdentId(index)) => {\n+                let IdentData(ident) = self.ident_interner.get(index).clone();\n+                let ident: tt::Ident = ident;\n+                let leaf = tt::Leaf::from(ident);\n+                let tree = TokenTree::from(leaf);\n+                Self::TokenStream::from_iter(vec![tree])\n+            }\n+\n+            bridge::TokenTree::Literal(literal) => {\n+                let leaf = tt::Leaf::from(literal);\n+                let tree = TokenTree::from(leaf);\n+                Self::TokenStream::from_iter(vec![tree])\n+            }\n+\n+            bridge::TokenTree::Punct(p) => {\n+                let punct = tt::Punct {\n+                    char: p.ch as char,\n+                    spacing: if p.joint { Spacing::Joint } else { Spacing::Alone },\n+                    id: p.span,\n+                };\n+                let leaf = tt::Leaf::from(punct);\n+                let tree = TokenTree::from(leaf);\n+                Self::TokenStream::from_iter(vec![tree])\n+            }\n+        }\n+    }\n+\n+    fn expand_expr(&mut self, self_: &Self::TokenStream) -> Result<Self::TokenStream, ()> {\n+        Ok(self_.clone())\n+    }\n+\n+    fn concat_trees(\n+        &mut self,\n+        base: Option<Self::TokenStream>,\n+        trees: Vec<bridge::TokenTree<Self::TokenStream, Self::Span, Self::Ident, Self::Literal>>,\n+    ) -> Self::TokenStream {\n+        let mut builder = TokenStreamBuilder::new();\n+        if let Some(base) = base {\n+            builder.push(base);\n+        }\n+        for tree in trees {\n+            builder.push(self.from_token_tree(tree));\n+        }\n+        builder.build()\n+    }\n+\n+    fn concat_streams(\n+        &mut self,\n+        base: Option<Self::TokenStream>,\n+        streams: Vec<Self::TokenStream>,\n+    ) -> Self::TokenStream {\n+        let mut builder = TokenStreamBuilder::new();\n+        if let Some(base) = base {\n+            builder.push(base);\n+        }\n+        for stream in streams {\n+            builder.push(stream);\n+        }\n+        builder.build()\n+    }\n+\n+    fn into_trees(\n+        &mut self,\n+        stream: Self::TokenStream,\n+    ) -> Vec<bridge::TokenTree<Self::TokenStream, Self::Span, Self::Ident, Self::Literal>> {\n+        stream\n+            .into_iter()\n+            .map(|tree| match tree {\n+                tt::TokenTree::Leaf(tt::Leaf::Ident(ident)) => {\n+                    bridge::TokenTree::Ident(IdentId(self.ident_interner.intern(&IdentData(ident))))\n+                }\n+                tt::TokenTree::Leaf(tt::Leaf::Literal(lit)) => bridge::TokenTree::Literal(lit),\n+                tt::TokenTree::Leaf(tt::Leaf::Punct(punct)) => {\n+                    bridge::TokenTree::Punct(bridge::Punct {\n+                        ch: punct.char as u8,\n+                        joint: punct.spacing == Spacing::Joint,\n+                        span: punct.id,\n+                    })\n+                }\n+                tt::TokenTree::Subtree(subtree) => bridge::TokenTree::Group(bridge::Group {\n+                    delimiter: delim_to_external(subtree.delimiter),\n+                    stream: if subtree.token_trees.is_empty() {\n+                        None\n+                    } else {\n+                        Some(subtree.token_trees.into_iter().collect())\n+                    },\n+                    span: bridge::DelimSpan::from_single(\n+                        subtree.delimiter.map_or(Span::unspecified(), |del| del.id),\n+                    ),\n+                }),\n+            })\n+            .collect()\n+    }\n+}\n+\n+fn delim_to_internal(d: bridge::Delimiter) -> Option<tt::Delimiter> {\n+    let kind = match d {\n+        bridge::Delimiter::Parenthesis => tt::DelimiterKind::Parenthesis,\n+        bridge::Delimiter::Brace => tt::DelimiterKind::Brace,\n+        bridge::Delimiter::Bracket => tt::DelimiterKind::Bracket,\n+        bridge::Delimiter::None => return None,\n+    };\n+    Some(tt::Delimiter { id: tt::TokenId::unspecified(), kind })\n+}\n+\n+fn delim_to_external(d: Option<tt::Delimiter>) -> bridge::Delimiter {\n+    match d.map(|it| it.kind) {\n+        Some(tt::DelimiterKind::Parenthesis) => bridge::Delimiter::Parenthesis,\n+        Some(tt::DelimiterKind::Brace) => bridge::Delimiter::Brace,\n+        Some(tt::DelimiterKind::Bracket) => bridge::Delimiter::Bracket,\n+        None => bridge::Delimiter::None,\n+    }\n+}\n+\n+fn spacing_to_internal(spacing: bridge::Spacing) -> Spacing {\n+    match spacing {\n+        bridge::Spacing::Alone => Spacing::Alone,\n+        bridge::Spacing::Joint => Spacing::Joint,\n+    }\n+}\n+\n+fn spacing_to_external(spacing: Spacing) -> bridge::Spacing {\n+    match spacing {\n+        Spacing::Alone => bridge::Spacing::Alone,\n+        Spacing::Joint => bridge::Spacing::Joint,\n+    }\n+}\n+\n+impl server::Ident for RustAnalyzer {\n+    fn new(&mut self, string: &str, span: Self::Span, _is_raw: bool) -> Self::Ident {\n+        IdentId(self.ident_interner.intern(&IdentData(tt::Ident { text: string.into(), id: span })))\n+    }\n+\n+    fn span(&mut self, ident: Self::Ident) -> Self::Span {\n+        self.ident_interner.get(ident.0).0.id\n+    }\n+    fn with_span(&mut self, ident: Self::Ident, span: Self::Span) -> Self::Ident {\n+        let data = self.ident_interner.get(ident.0);\n+        let new = IdentData(tt::Ident { id: span, ..data.0.clone() });\n+        IdentId(self.ident_interner.intern(&new))\n+    }\n+}\n+\n+impl server::Literal for RustAnalyzer {\n+    fn debug_kind(&mut self, _literal: &Self::Literal) -> String {\n+        // r-a: debug_kind and suffix are unsupported; corresponding client code has been changed to not call these.\n+        // They must still be present to be ABI-compatible and work with upstream proc_macro.\n+        \"\".to_owned()\n+    }\n+    fn from_str(&mut self, s: &str) -> Result<Self::Literal, ()> {\n+        Ok(Literal { text: s.into(), id: tt::TokenId::unspecified() })\n+    }\n+    fn symbol(&mut self, literal: &Self::Literal) -> String {\n+        literal.text.to_string()\n+    }\n+    fn suffix(&mut self, _literal: &Self::Literal) -> Option<String> {\n+        None\n+    }\n+\n+    fn to_string(&mut self, literal: &Self::Literal) -> String {\n+        literal.to_string()\n+    }\n+\n+    fn integer(&mut self, n: &str) -> Self::Literal {\n+        let n = match n.parse::<i128>() {\n+            Ok(n) => n.to_string(),\n+            Err(_) => n.parse::<u128>().unwrap().to_string(),\n+        };\n+        Literal { text: n.into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn typed_integer(&mut self, n: &str, kind: &str) -> Self::Literal {\n+        macro_rules! def_suffixed_integer {\n+            ($kind:ident, $($ty:ty),*) => {\n+                match $kind {\n+                    $(\n+                        stringify!($ty) => {\n+                            let n: $ty = n.parse().unwrap();\n+                            format!(concat!(\"{}\", stringify!($ty)), n)\n+                        }\n+                    )*\n+                    _ => unimplemented!(\"unknown args for typed_integer: n {}, kind {}\", n, $kind),\n+                }\n+            }\n+        }\n+\n+        let text = def_suffixed_integer! {kind, u8, u16, u32, u64, u128, usize, i8, i16, i32, i64, i128, isize};\n+\n+        Literal { text: text.into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn float(&mut self, n: &str) -> Self::Literal {\n+        let n: f64 = n.parse().unwrap();\n+        let mut text = f64::to_string(&n);\n+        if !text.contains('.') {\n+            text += \".0\"\n+        }\n+        Literal { text: text.into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn f32(&mut self, n: &str) -> Self::Literal {\n+        let n: f32 = n.parse().unwrap();\n+        let text = format!(\"{}f32\", n);\n+        Literal { text: text.into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn f64(&mut self, n: &str) -> Self::Literal {\n+        let n: f64 = n.parse().unwrap();\n+        let text = format!(\"{}f64\", n);\n+        Literal { text: text.into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn string(&mut self, string: &str) -> Self::Literal {\n+        let mut escaped = String::new();\n+        for ch in string.chars() {\n+            escaped.extend(ch.escape_debug());\n+        }\n+        Literal { text: format!(\"\\\"{}\\\"\", escaped).into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn character(&mut self, ch: char) -> Self::Literal {\n+        Literal { text: format!(\"'{}'\", ch).into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn byte_string(&mut self, bytes: &[u8]) -> Self::Literal {\n+        let string = bytes\n+            .iter()\n+            .cloned()\n+            .flat_map(ascii::escape_default)\n+            .map(Into::<char>::into)\n+            .collect::<String>();\n+\n+        Literal { text: format!(\"b\\\"{}\\\"\", string).into(), id: tt::TokenId::unspecified() }\n+    }\n+\n+    fn span(&mut self, literal: &Self::Literal) -> Self::Span {\n+        literal.id\n+    }\n+\n+    fn set_span(&mut self, literal: &mut Self::Literal, span: Self::Span) {\n+        literal.id = span;\n+    }\n+\n+    fn subspan(\n+        &mut self,\n+        _literal: &Self::Literal,\n+        _start: Bound<usize>,\n+        _end: Bound<usize>,\n+    ) -> Option<Self::Span> {\n+        // FIXME handle span\n+        None\n+    }\n+}\n+\n+impl server::SourceFile for RustAnalyzer {\n+    // FIXME these are all stubs\n+    fn eq(&mut self, _file1: &Self::SourceFile, _file2: &Self::SourceFile) -> bool {\n+        true\n+    }\n+    fn path(&mut self, _file: &Self::SourceFile) -> String {\n+        String::new()\n+    }\n+    fn is_real(&mut self, _file: &Self::SourceFile) -> bool {\n+        true\n+    }\n+}\n+\n+impl server::Diagnostic for RustAnalyzer {\n+    fn new(&mut self, level: Level, msg: &str, spans: Self::MultiSpan) -> Self::Diagnostic {\n+        let mut diag = Diagnostic::new(level, msg);\n+        diag.spans = spans;\n+        diag\n+    }\n+\n+    fn sub(\n+        &mut self,\n+        _diag: &mut Self::Diagnostic,\n+        _level: Level,\n+        _msg: &str,\n+        _spans: Self::MultiSpan,\n+    ) {\n+        // FIXME handle diagnostic\n+        //\n+    }\n+\n+    fn emit(&mut self, _diag: Self::Diagnostic) {\n+        // FIXME handle diagnostic\n+        // diag.emit()\n+    }\n+}\n+\n+impl server::Span for RustAnalyzer {\n+    fn debug(&mut self, span: Self::Span) -> String {\n+        format!(\"{:?}\", span.0)\n+    }\n+    fn source_file(&mut self, _span: Self::Span) -> Self::SourceFile {\n+        SourceFile {}\n+    }\n+    fn save_span(&mut self, _span: Self::Span) -> usize {\n+        // FIXME stub\n+        0\n+    }\n+    fn recover_proc_macro_span(&mut self, _id: usize) -> Self::Span {\n+        // FIXME stub\n+        tt::TokenId::unspecified()\n+    }\n+    /// Recent feature, not yet in the proc_macro\n+    ///\n+    /// See PR:\n+    /// https://github.com/rust-lang/rust/pull/55780\n+    fn source_text(&mut self, _span: Self::Span) -> Option<String> {\n+        None\n+    }\n+\n+    fn parent(&mut self, _span: Self::Span) -> Option<Self::Span> {\n+        // FIXME handle span\n+        None\n+    }\n+    fn source(&mut self, span: Self::Span) -> Self::Span {\n+        // FIXME handle span\n+        span\n+    }\n+    fn start(&mut self, _span: Self::Span) -> LineColumn {\n+        // FIXME handle span\n+        LineColumn { line: 0, column: 0 }\n+    }\n+    fn end(&mut self, _span: Self::Span) -> LineColumn {\n+        // FIXME handle span\n+        LineColumn { line: 0, column: 0 }\n+    }\n+    fn join(&mut self, first: Self::Span, _second: Self::Span) -> Option<Self::Span> {\n+        // Just return the first span again, because some macros will unwrap the result.\n+        Some(first)\n+    }\n+    fn resolved_at(&mut self, _span: Self::Span, _at: Self::Span) -> Self::Span {\n+        // FIXME handle span\n+        tt::TokenId::unspecified()\n+    }\n+\n+    fn after(&mut self, _self_: Self::Span) -> Self::Span {\n+        tt::TokenId::unspecified()\n+    }\n+\n+    fn before(&mut self, _self_: Self::Span) -> Self::Span {\n+        tt::TokenId::unspecified()\n+    }\n+}\n+\n+impl server::MultiSpan for RustAnalyzer {\n+    fn new(&mut self) -> Self::MultiSpan {\n+        // FIXME handle span\n+        vec![]\n+    }\n+\n+    fn push(&mut self, other: &mut Self::MultiSpan, span: Self::Span) {\n+        //TODP\n+        other.push(span)\n+    }\n+}\n+\n+impl server::Server for RustAnalyzer {\n+    fn globals(&mut self) -> bridge::ExpnGlobals<Self::Span> {\n+        bridge::ExpnGlobals {\n+            def_site: Span::unspecified(),\n+            call_site: Span::unspecified(),\n+            mixed_site: Span::unspecified(),\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::super::proc_macro::bridge::server::Literal;\n+    use super::*;\n+\n+    #[test]\n+    fn test_ra_server_literals() {\n+        let mut srv = RustAnalyzer { ident_interner: IdentInterner::default() };\n+        assert_eq!(srv.integer(\"1234\").text, \"1234\");\n+\n+        assert_eq!(srv.typed_integer(\"12\", \"u8\").text, \"12u8\");\n+        assert_eq!(srv.typed_integer(\"255\", \"u16\").text, \"255u16\");\n+        assert_eq!(srv.typed_integer(\"1234\", \"u32\").text, \"1234u32\");\n+        assert_eq!(srv.typed_integer(\"15846685\", \"u64\").text, \"15846685u64\");\n+        assert_eq!(srv.typed_integer(\"15846685258\", \"u128\").text, \"15846685258u128\");\n+        assert_eq!(srv.typed_integer(\"156788984\", \"usize\").text, \"156788984usize\");\n+        assert_eq!(srv.typed_integer(\"127\", \"i8\").text, \"127i8\");\n+        assert_eq!(srv.typed_integer(\"255\", \"i16\").text, \"255i16\");\n+        assert_eq!(srv.typed_integer(\"1234\", \"i32\").text, \"1234i32\");\n+        assert_eq!(srv.typed_integer(\"15846685\", \"i64\").text, \"15846685i64\");\n+        assert_eq!(srv.typed_integer(\"15846685258\", \"i128\").text, \"15846685258i128\");\n+        assert_eq!(srv.float(\"0\").text, \"0.0\");\n+        assert_eq!(srv.float(\"15684.5867\").text, \"15684.5867\");\n+        assert_eq!(srv.f32(\"15684.58\").text, \"15684.58f32\");\n+        assert_eq!(srv.f64(\"15684.58\").text, \"15684.58f64\");\n+\n+        assert_eq!(srv.string(\"hello_world\").text, \"\\\"hello_world\\\"\");\n+        assert_eq!(srv.character('c').text, \"'c'\");\n+        assert_eq!(srv.byte_string(b\"1234586\\x88\").text, \"b\\\"1234586\\\\x88\\\"\");\n+\n+        // u128::max\n+        assert_eq!(\n+            srv.integer(\"340282366920938463463374607431768211455\").text,\n+            \"340282366920938463463374607431768211455\"\n+        );\n+        // i128::min\n+        assert_eq!(\n+            srv.integer(\"-170141183460469231731687303715884105728\").text,\n+            \"-170141183460469231731687303715884105728\"\n+        );\n+    }\n+\n+    #[test]\n+    fn test_ra_server_to_string() {\n+        let s = TokenStream {\n+            token_trees: vec![\n+                tt::TokenTree::Leaf(tt::Leaf::Ident(tt::Ident {\n+                    text: \"struct\".into(),\n+                    id: tt::TokenId::unspecified(),\n+                })),\n+                tt::TokenTree::Leaf(tt::Leaf::Ident(tt::Ident {\n+                    text: \"T\".into(),\n+                    id: tt::TokenId::unspecified(),\n+                })),\n+                tt::TokenTree::Subtree(tt::Subtree {\n+                    delimiter: Some(tt::Delimiter {\n+                        id: tt::TokenId::unspecified(),\n+                        kind: tt::DelimiterKind::Brace,\n+                    }),\n+                    token_trees: vec![],\n+                }),\n+            ],\n+        };\n+\n+        assert_eq!(s.to_string(), \"struct T {}\");\n+    }\n+\n+    #[test]\n+    fn test_ra_server_from_str() {\n+        use std::str::FromStr;\n+        let subtree_paren_a = tt::TokenTree::Subtree(tt::Subtree {\n+            delimiter: Some(tt::Delimiter {\n+                id: tt::TokenId::unspecified(),\n+                kind: tt::DelimiterKind::Parenthesis,\n+            }),\n+            token_trees: vec![tt::TokenTree::Leaf(tt::Leaf::Ident(tt::Ident {\n+                text: \"a\".into(),\n+                id: tt::TokenId::unspecified(),\n+            }))],\n+        });\n+\n+        let t1 = TokenStream::from_str(\"(a)\").unwrap();\n+        assert_eq!(t1.token_trees.len(), 1);\n+        assert_eq!(t1.token_trees[0], subtree_paren_a);\n+\n+        let t2 = TokenStream::from_str(\"(a);\").unwrap();\n+        assert_eq!(t2.token_trees.len(), 2);\n+        assert_eq!(t2.token_trees[0], subtree_paren_a);\n+\n+        let underscore = TokenStream::from_str(\"_\").unwrap();\n+        assert_eq!(\n+            underscore.token_trees[0],\n+            tt::TokenTree::Leaf(tt::Leaf::Ident(tt::Ident {\n+                text: \"_\".into(),\n+                id: tt::TokenId::unspecified(),\n+            }))\n+        );\n+    }\n+}"}, {"sha": "62479b7ccd6b246335f326abbf8011779a640b34", "filename": "crates/proc-macro-srv/src/abis/mod.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fproc-macro-srv%2Fsrc%2Fabis%2Fmod.rs?ref=315b0a7254974f1a2ef9777944531cdbca15be7b", "patch": "@@ -26,6 +26,8 @@\n mod abi_1_58;\n mod abi_1_63;\n mod abi_1_64;\n+#[cfg(feature = \"sysroot-abi\")]\n+mod abi_sysroot;\n \n // Used by `test/utils.rs`\n #[cfg(test)]"}, {"sha": "2ab6eba6f424febb5b1fc9a32999cd397ce35627", "filename": "crates/proc-macro-srv/src/lib.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Fproc-macro-srv%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fproc-macro-srv%2Fsrc%2Flib.rs?ref=315b0a7254974f1a2ef9777944531cdbca15be7b", "patch": "@@ -11,6 +11,10 @@\n //!   rustc rather than `unstable`. (Although in general ABI compatibility is still an issue)\u2026\n \n #![warn(rust_2018_idioms, unused_lifetimes, semicolon_in_expressions_from_macros)]\n+#![cfg_attr(\n+    feature = \"sysroot-abi\",\n+    feature(proc_macro_internals, proc_macro_diagnostic, proc_macro_span)\n+)]\n #![allow(unreachable_pub)]\n \n mod dylib;"}, {"sha": "41205f2584a970e71cd1ecc2facebc1970449ff7", "filename": "crates/rust-analyzer/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Frust-analyzer%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/315b0a7254974f1a2ef9777944531cdbca15be7b/crates%2Frust-analyzer%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2FCargo.toml?ref=315b0a7254974f1a2ef9777944531cdbca15be7b", "patch": "@@ -84,3 +84,4 @@ mbe = { path = \"../mbe\" }\n [features]\n jemalloc = [\"jemallocator\", \"profile/jemalloc\"]\n force-always-assert = [\"always-assert/force\"]\n+in-rust-tree = [\"proc-macro-srv/sysroot-abi\"]"}]}