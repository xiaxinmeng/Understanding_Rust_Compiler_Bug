{"sha": "575058f3d7ccba3c20080b55e0ca409a35607330", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU3NTA1OGYzZDdjY2JhM2MyMDA4MGI1NWUwY2E0MDlhMzU2MDczMzA=", "commit": {"author": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2019-10-28T03:53:09Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-10-28T03:53:09Z"}, "message": "Rollup merge of #65849 - popzxc:document-librustc_lexer, r=petrochenkov\n\nlibrustc_lexer: Enhance documentation\n\nThis PR enhances documentation state of the `librustc_lexer` (as initiative caused by [rustc-guide#474](https://github.com/rust-lang/rustc-guide/issues/474)), by adding:\n\n- Module documentation.\n- Doc-comments (and a bit of usual comments) in non-obvious (as for me) places.\n\nr? @petrochenkov\n\ncc @Centril", "tree": {"sha": "a94060fa3a851d6ec92439e317938be3b5c6329e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a94060fa3a851d6ec92439e317938be3b5c6329e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/575058f3d7ccba3c20080b55e0ca409a35607330", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJdtmYlCRBK7hj4Ov3rIwAAdHIIAGdKybZPeD9B5xMvixAPGXrP\n6Bfb6nupBfAjAzCUBCMe1Le7h3nITGyiWoSeVjsgUVSm5aH/yQ4PunpR0UzXBLhz\ngBTkVeMwzqj218MK9RmWsA5xRWKw7KKtCcgrr+M3QENPgyNkzeFCcR1oGtD93M/4\nljO0oN45MDwpX4G7CVMTH+5wltlz7QG/9oCFuCYJhRm+/9UgtLIYZixWYe+lxEcS\nznte7VYq1j4R3MWNSDXig4riCb4Nk4RTI927vBG0WL2bzmL1F0qG9nB7eDHci5CS\nt3BeUFxP5qLbCTiwLonN0/KcyjwZvjhcvs8XfqXXWESKNpDkBpXyhb1nChhUIHs=\n=xNJY\n-----END PGP SIGNATURE-----\n", "payload": "tree a94060fa3a851d6ec92439e317938be3b5c6329e\nparent 83260d5c4370679f145d5cebb471f91e81771ee2\nparent 993b920032b17def5c773ed78b09890abb95854e\nauthor Mazdak Farrokhzad <twingoow@gmail.com> 1572234789 +0100\ncommitter GitHub <noreply@github.com> 1572234789 +0100\n\nRollup merge of #65849 - popzxc:document-librustc_lexer, r=petrochenkov\n\nlibrustc_lexer: Enhance documentation\n\nThis PR enhances documentation state of the `librustc_lexer` (as initiative caused by [rustc-guide#474](https://github.com/rust-lang/rustc-guide/issues/474)), by adding:\n\n- Module documentation.\n- Doc-comments (and a bit of usual comments) in non-obvious (as for me) places.\n\nr? @petrochenkov\n\ncc @Centril\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/575058f3d7ccba3c20080b55e0ca409a35607330", "html_url": "https://github.com/rust-lang/rust/commit/575058f3d7ccba3c20080b55e0ca409a35607330", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/575058f3d7ccba3c20080b55e0ca409a35607330/comments", "author": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "83260d5c4370679f145d5cebb471f91e81771ee2", "url": "https://api.github.com/repos/rust-lang/rust/commits/83260d5c4370679f145d5cebb471f91e81771ee2", "html_url": "https://github.com/rust-lang/rust/commit/83260d5c4370679f145d5cebb471f91e81771ee2"}, {"sha": "993b920032b17def5c773ed78b09890abb95854e", "url": "https://api.github.com/repos/rust-lang/rust/commits/993b920032b17def5c773ed78b09890abb95854e", "html_url": "https://github.com/rust-lang/rust/commit/993b920032b17def5c773ed78b09890abb95854e"}], "stats": {"total": 249, "additions": 225, "deletions": 24}, "files": [{"sha": "73d305c6d4fe2c292e3d46863b28d69f92ccb81d", "filename": "src/librustc_lexer/src/cursor.rs", "status": "modified", "additions": 18, "deletions": 1, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/575058f3d7ccba3c20080b55e0ca409a35607330/src%2Flibrustc_lexer%2Fsrc%2Fcursor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/575058f3d7ccba3c20080b55e0ca409a35607330/src%2Flibrustc_lexer%2Fsrc%2Fcursor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Fcursor.rs?ref=575058f3d7ccba3c20080b55e0ca409a35607330", "patch": "@@ -1,5 +1,9 @@\n use std::str::Chars;\n \n+/// Peekable iterator over a char sequence.\n+///\n+/// Next characters can be peeked via `nth_char` method,\n+/// and position can be shifted forward via `bump` method.\n pub(crate) struct Cursor<'a> {\n     initial_len: usize,\n     chars: Chars<'a>,\n@@ -18,7 +22,9 @@ impl<'a> Cursor<'a> {\n             prev: EOF_CHAR,\n         }\n     }\n+\n     /// For debug assertions only\n+    /// Returns the last eaten symbol (or '\\0' in release builds).\n     pub(crate) fn prev(&self) -> char {\n         #[cfg(debug_assertions)]\n         {\n@@ -30,19 +36,30 @@ impl<'a> Cursor<'a> {\n             '\\0'\n         }\n     }\n+\n+    /// Returns nth character relative to the current cursor position.\n+    /// If requested position doesn't exist, `EOF_CHAR` is returned.\n+    /// However, getting `EOF_CHAR` doesn't always mean actual end of file,\n+    /// it should be checked with `is_eof` method.\n     pub(crate) fn nth_char(&self, n: usize) -> char {\n         self.chars().nth(n).unwrap_or(EOF_CHAR)\n     }\n+\n+    /// Checks if there is nothing more to consume.\n     pub(crate) fn is_eof(&self) -> bool {\n         self.chars.as_str().is_empty()\n     }\n+\n+    /// Returns amount of already consumed symbols.\n     pub(crate) fn len_consumed(&self) -> usize {\n         self.initial_len - self.chars.as_str().len()\n     }\n-    /// Returns an iterator over the remaining characters.\n+\n+    /// Returns a `Chars` iterator over the remaining characters.\n     fn chars(&self) -> Chars<'a> {\n         self.chars.clone()\n     }\n+\n     /// Moves to the next character.\n     pub(crate) fn bump(&mut self) -> Option<char> {\n         let c = self.chars.next()?;"}, {"sha": "d55ef46d7506e6b3eddf5dea3bf56baa2150a67e", "filename": "src/librustc_lexer/src/lib.rs", "status": "modified", "additions": 145, "deletions": 11, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/575058f3d7ccba3c20080b55e0ca409a35607330/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/575058f3d7ccba3c20080b55e0ca409a35607330/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Flib.rs?ref=575058f3d7ccba3c20080b55e0ca409a35607330", "patch": "@@ -1,3 +1,16 @@\n+//! Low-level Rust lexer.\n+//!\n+//! Tokens produced by this lexer are not yet ready for parsing the Rust syntax,\n+//! for that see `libsyntax::parse::lexer`, which converts this basic token stream\n+//! into wide tokens used by actual parser.\n+//!\n+//! The purpose of this crate is to convert raw sources into a labeled sequence\n+//! of well-known token types, so building an actual Rust token stream will\n+//! be easier.\n+//!\n+//! Main entity of this crate is [`TokenKind`] enum which represents common\n+//! lexeme types.\n+\n // We want to be able to build this crate with a stable compiler, so no\n // `#![feature]` attributes should be added.\n \n@@ -6,78 +19,144 @@ pub mod unescape;\n \n use crate::cursor::{Cursor, EOF_CHAR};\n \n+/// Parsed token.\n+/// It doesn't contain information about data that has been parsed,\n+/// only the type of the token and its size.\n pub struct Token {\n     pub kind: TokenKind,\n     pub len: usize,\n }\n \n+impl Token {\n+    fn new(kind: TokenKind, len: usize) -> Token {\n+        Token { kind, len }\n+    }\n+}\n+\n+/// Enum represening common lexeme types.\n #[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n pub enum TokenKind {\n+    // Multi-char tokens:\n+\n+    /// \"// comment\"\n     LineComment,\n+    /// \"/* block comment */\"\n+    /// Block comments can be recursive, so the sequence like \"/* /* */\"\n+    /// will not be considered terminated and will result in a parsing error.\n     BlockComment { terminated: bool },\n+    /// Any whitespace characters sequence.\n     Whitespace,\n+    /// \"ident\" or \"continue\"\n+    /// At this step keywords are also considered identifiers.\n     Ident,\n+    /// \"r#ident\"\n     RawIdent,\n+    /// \"12_u8\", \"1.0e-40\", \"b\"123\"\". See `LiteralKind` for more details.\n     Literal { kind: LiteralKind, suffix_start: usize },\n+    /// \"'a\"\n     Lifetime { starts_with_number: bool },\n+\n+    // One-char tokens:\n+\n+    /// \";\"\n     Semi,\n+    /// \",\"\n     Comma,\n+    /// \".\"\n     Dot,\n+    /// \"(\"\n     OpenParen,\n+    /// \")\"\n     CloseParen,\n+    /// \"{\"\n     OpenBrace,\n+    /// \"}\"\n     CloseBrace,\n+    /// \"[\"\n     OpenBracket,\n+    /// \"]\"\n     CloseBracket,\n+    /// \"@\"\n     At,\n+    /// \"#\"\n     Pound,\n+    /// \"~\"\n     Tilde,\n+    /// \"?\"\n     Question,\n+    /// \":\"\n     Colon,\n+    /// \"$\"\n     Dollar,\n+    /// \"=\"\n     Eq,\n+    /// \"!\"\n     Not,\n+    /// \"<\"\n     Lt,\n+    /// \">\"\n     Gt,\n+    /// \"-\"\n     Minus,\n+    /// \"&\"\n     And,\n+    /// \"|\"\n     Or,\n+    /// \"+\"\n     Plus,\n+    /// \"*\"\n     Star,\n+    /// \"/\"\n     Slash,\n+    /// \"^\"\n     Caret,\n+    /// \"%\"\n     Percent,\n+\n+    /// Unknown token, not expected by the lexer, e.g. \"\u2116\"\n     Unknown,\n }\n use self::TokenKind::*;\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n pub enum LiteralKind {\n+    /// \"12_u8\", \"0o100\", \"0b120i99\"\n     Int { base: Base, empty_int: bool },\n+    /// \"12.34f32\", \"0b100.100\"\n     Float { base: Base, empty_exponent: bool },\n+    /// \"'a'\", \"'\\\\'\", \"'''\", \"';\"\n     Char { terminated: bool },\n+    /// \"b'a'\", \"b'\\\\'\", \"b'''\", \"b';\"\n     Byte { terminated: bool },\n+    /// \"\"abc\"\", \"\"abc\"\n     Str { terminated: bool },\n+    /// \"b\"abc\"\", \"b\"abc\"\n     ByteStr { terminated: bool },\n+    /// \"r\"abc\"\", \"r#\"abc\"#\", \"r####\"ab\"###\"c\"####\", \"r#\"a\"\n     RawStr { n_hashes: usize, started: bool, terminated: bool },\n+    /// \"br\"abc\"\", \"br#\"abc\"#\", \"br####\"ab\"###\"c\"####\", \"br#\"a\"\n     RawByteStr { n_hashes: usize, started: bool, terminated: bool },\n }\n use self::LiteralKind::*;\n \n+/// Base of numeric literal encoding according to its prefix.\n #[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n pub enum Base {\n+    /// Literal starts with \"0b\".\n     Binary,\n+    /// Literal starts with \"0o\".\n     Octal,\n+    /// Literal starts with \"0x\".\n     Hexadecimal,\n+    /// Literal doesn't contain a prefix.\n     Decimal,\n }\n \n-impl Token {\n-    fn new(kind: TokenKind, len: usize) -> Token {\n-        Token { kind, len }\n-    }\n-}\n-\n+/// `rustc` allows files to have a shebang, e.g. \"#!/usr/bin/rustrun\",\n+/// but shebang isn't a part of rust syntax, so this function\n+/// skips the line if it starts with a shebang (\"#!\").\n+/// Line won't be skipped if it represents a valid Rust syntax\n+/// (e.g. \"#![deny(missing_docs)]\").\n pub fn strip_shebang(input: &str) -> Option<usize> {\n     debug_assert!(!input.is_empty());\n     if !input.starts_with(\"#!\") || input.starts_with(\"#![\") {\n@@ -86,11 +165,13 @@ pub fn strip_shebang(input: &str) -> Option<usize> {\n     Some(input.find('\\n').unwrap_or(input.len()))\n }\n \n+/// Parses the first token from the provided input string.\n pub fn first_token(input: &str) -> Token {\n     debug_assert!(!input.is_empty());\n     Cursor::new(input).advance_token()\n }\n \n+/// Creates an iterator that produces tokens from the input string.\n pub fn tokenize(mut input: &str) -> impl Iterator<Item = Token> + '_ {\n     std::iter::from_fn(move || {\n         if input.is_empty() {\n@@ -102,10 +183,9 @@ pub fn tokenize(mut input: &str) -> impl Iterator<Item = Token> + '_ {\n     })\n }\n \n-// See [UAX #31](http://unicode.org/reports/tr31) for definitions of these\n-// classes.\n-\n /// True if `c` is considered a whitespace according to Rust language definition.\n+/// See [Rust language reference](https://doc.rust-lang.org/reference/whitespace.html)\n+/// for definitions of these classes.\n pub fn is_whitespace(c: char) -> bool {\n     // This is Pattern_White_Space.\n     //\n@@ -137,6 +217,8 @@ pub fn is_whitespace(c: char) -> bool {\n }\n \n /// True if `c` is valid as a first character of an identifier.\n+/// See [Rust language reference](https://doc.rust-lang.org/reference/identifiers.html) for\n+/// a formal definition of valid identifier name.\n pub fn is_id_start(c: char) -> bool {\n     // This is XID_Start OR '_' (which formally is not a XID_Start).\n     // We also add fast-path for ascii idents\n@@ -147,6 +229,8 @@ pub fn is_id_start(c: char) -> bool {\n }\n \n /// True if `c` is valid as a non-first character of an identifier.\n+/// See [Rust language reference](https://doc.rust-lang.org/reference/identifiers.html) for\n+/// a formal definition of valid identifier name.\n pub fn is_id_continue(c: char) -> bool {\n     // This is exactly XID_Continue.\n     // We also add fast-path for ascii idents\n@@ -159,15 +243,21 @@ pub fn is_id_continue(c: char) -> bool {\n \n \n impl Cursor<'_> {\n+    /// Parses a token from the input string.\n     fn advance_token(&mut self) -> Token {\n         let first_char = self.bump().unwrap();\n         let token_kind = match first_char {\n+            // Slash, comment or block comment.\n             '/' => match self.nth_char(0) {\n                 '/' => self.line_comment(),\n                 '*' => self.block_comment(),\n                 _ => Slash,\n             },\n+\n+            // Whitespace sequence.\n             c if is_whitespace(c) => self.whitespace(),\n+\n+            // Raw string literal or identifier.\n             'r' => match (self.nth_char(0), self.nth_char(1)) {\n                 ('#', c1) if is_id_start(c1) => self.raw_ident(),\n                 ('#', _) | ('\"', _) => {\n@@ -181,6 +271,8 @@ impl Cursor<'_> {\n                 }\n                 _ => self.ident(),\n             },\n+\n+            // Byte literal, byte string literal, raw byte string literal or identifier.\n             'b' => match (self.nth_char(0), self.nth_char(1)) {\n                 ('\\'', _) => {\n                     self.bump();\n@@ -214,13 +306,20 @@ impl Cursor<'_> {\n                 }\n                 _ => self.ident(),\n             },\n+\n+            // Identifier (this should be checked after other variant that can\n+            // start as identifier).\n             c if is_id_start(c) => self.ident(),\n+\n+            // Numeric literal.\n             c @ '0'..='9' => {\n                 let literal_kind = self.number(c);\n                 let suffix_start = self.len_consumed();\n                 self.eat_literal_suffix();\n                 TokenKind::Literal { kind: literal_kind, suffix_start }\n             }\n+\n+            // One-symbol tokens.\n             ';' => Semi,\n             ',' => Comma,\n             '.' => Dot,\n@@ -247,7 +346,11 @@ impl Cursor<'_> {\n             '*' => Star,\n             '^' => Caret,\n             '%' => Percent,\n+\n+            // Lifetime or character literal.\n             '\\'' => self.lifetime_or_char(),\n+\n+            // String literal.\n             '\"' => {\n                 let terminated = self.double_quoted_string();\n                 let suffix_start = self.len_consumed();\n@@ -291,6 +394,9 @@ impl Cursor<'_> {\n                     self.bump();\n                     depth -= 1;\n                     if depth == 0 {\n+                        // This block comment is closed, so for a construction like \"/* */ */\"\n+                        // there will be a successfully parsed block comment \"/* */\"\n+                        // and \" */\" will be processed separately.\n                         break;\n                     }\n                 }\n@@ -335,6 +441,7 @@ impl Cursor<'_> {\n         debug_assert!('0' <= self.prev() && self.prev() <= '9');\n         let mut base = Base::Decimal;\n         if first_digit == '0' {\n+            // Attempt to parse encoding base.\n             let has_digits = match self.nth_char(0) {\n                 'b' => {\n                     base = Base::Binary;\n@@ -351,17 +458,21 @@ impl Cursor<'_> {\n                     self.bump();\n                     self.eat_hexadecimal_digits()\n                 }\n+                // Not a base prefix.\n                 '0'..='9' | '_' | '.' | 'e' | 'E' => {\n                     self.eat_decimal_digits();\n                     true\n                 }\n-                // just a 0\n+                // Just a 0.\n                 _ => return Int { base, empty_int: false },\n             };\n+            // Base prefix was provided, but there were no digits\n+            // after it, e.g. \"0x\".\n             if !has_digits {\n                 return Int { base, empty_int: true };\n             }\n         } else {\n+            // No base prefix, parse number in the usual way.\n             self.eat_decimal_digits();\n         };\n \n@@ -400,6 +511,9 @@ impl Cursor<'_> {\n     fn lifetime_or_char(&mut self) -> TokenKind {\n         debug_assert!(self.prev() == '\\'');\n         let mut starts_with_number = false;\n+\n+        // Check if the first symbol after '\\'' is a valid identifier\n+        // character or a number (not a digit followed by '\\'').\n         if (is_id_start(self.nth_char(0))\n             || self.nth_char(0).is_digit(10) && {\n                 starts_with_number = true;\n@@ -408,6 +522,8 @@ impl Cursor<'_> {\n             && self.nth_char(1) != '\\''\n         {\n             self.bump();\n+\n+            // Skip the identifier.\n             while is_id_continue(self.nth_char(0)) {\n                 self.bump();\n             }\n@@ -420,6 +536,8 @@ impl Cursor<'_> {\n                 Lifetime { starts_with_number }\n             };\n         }\n+\n+        // This is not a lifetime (checked above), parse a char literal.\n         let terminated = self.single_quoted_string();\n         let suffix_start = self.len_consumed();\n         if terminated {\n@@ -431,24 +549,32 @@ impl Cursor<'_> {\n \n     fn single_quoted_string(&mut self) -> bool {\n         debug_assert!(self.prev() == '\\'');\n-        // parse `'''` as a single char literal\n+        // Parse `'''` as a single char literal.\n         if self.nth_char(0) == '\\'' && self.nth_char(1) == '\\'' {\n             self.bump();\n         }\n+        // Parse until either quotes are terminated or error is detected.\n         let mut first = true;\n         loop {\n             match self.nth_char(0) {\n+                // Probably beginning of the comment, which we don't want to include\n+                // to the error report.\n                 '/' if !first => break,\n+                // Newline without following '\\'' means unclosed quote, stop parsing.\n                 '\\n' if self.nth_char(1) != '\\'' => break,\n+                // End of file, stop parsing.\n                 EOF_CHAR if self.is_eof() => break,\n+                // Quotes are terminated, finish parsing.\n                 '\\'' => {\n                     self.bump();\n                     return true;\n                 }\n+                // Escaped slash is considered one character, so bump twice.\n                 '\\\\' => {\n                     self.bump();\n                     self.bump();\n                 }\n+                // Skip the character.\n                 _ => {\n                     self.bump();\n                 }\n@@ -458,6 +584,8 @@ impl Cursor<'_> {\n         false\n     }\n \n+    /// Eats double-quoted string and returns true\n+    /// if string is terminated.\n     fn double_quoted_string(&mut self) -> bool {\n         debug_assert!(self.prev() == '\"');\n         loop {\n@@ -476,8 +604,11 @@ impl Cursor<'_> {\n         }\n     }\n \n+    /// Eats the double-quoted string and returns a tuple of\n+    /// (amount of the '#' symbols, raw string started, raw string terminated)\n     fn raw_double_quoted_string(&mut self) -> (usize, bool, bool) {\n         debug_assert!(self.prev() == 'r');\n+        // Count opening '#' symbols.\n         let n_hashes = {\n             let mut acc: usize = 0;\n             loop {\n@@ -489,6 +620,8 @@ impl Cursor<'_> {\n             }\n         };\n \n+        // Skip the string itself and check that amount of closing '#'\n+        // symbols is equal to the amount of opening ones.\n         loop {\n             match self.bump() {\n                 Some('\"') => {\n@@ -549,6 +682,7 @@ impl Cursor<'_> {\n         if self.eat_decimal_digits() { Ok(()) } else { Err(()) }\n     }\n \n+    // Eats the suffix if it's an identifier.\n     fn eat_literal_suffix(&mut self) {\n         if !is_id_start(self.nth_char(0)) {\n             return;"}, {"sha": "dee7bc2260bf0556a735b34229e880f9240042a9", "filename": "src/librustc_lexer/src/unescape.rs", "status": "modified", "additions": 62, "deletions": 12, "changes": 74, "blob_url": "https://github.com/rust-lang/rust/blob/575058f3d7ccba3c20080b55e0ca409a35607330/src%2Flibrustc_lexer%2Fsrc%2Funescape.rs", "raw_url": "https://github.com/rust-lang/rust/raw/575058f3d7ccba3c20080b55e0ca409a35607330/src%2Flibrustc_lexer%2Fsrc%2Funescape.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Funescape.rs?ref=575058f3d7ccba3c20080b55e0ca409a35607330", "patch": "@@ -7,32 +7,54 @@ use std::ops::Range;\n #[cfg(test)]\n mod tests;\n \n+/// Errors that can occur during string unescaping.\n #[derive(Debug, PartialEq, Eq)]\n pub enum EscapeError {\n+    /// Expected 1 char, but 0 were found.\n     ZeroChars,\n+    /// Expected 1 char, but more than 1 were found.\n     MoreThanOneChar,\n \n+    /// Escaped '\\' character without continuation.\n     LoneSlash,\n+    /// Invalid escape characted (e.g. '\\z').\n     InvalidEscape,\n+    /// Raw '\\r' encountered.\n     BareCarriageReturn,\n+    /// Raw '\\r' encountered in raw string.\n     BareCarriageReturnInRawString,\n+    /// Unescaped character that was expected to be escaped (e.g. raw '\\t').\n     EscapeOnlyChar,\n \n+    /// Numeric character escape is too short (e.g. '\\x1').\n     TooShortHexEscape,\n+    /// Invalid character in numeric escape (e.g. '\\xz')\n     InvalidCharInHexEscape,\n+    /// Character code in numeric escape is non-ascii (e.g. '\\xFF').\n     OutOfRangeHexEscape,\n \n+    /// '\\u' not followed by '{'.\n     NoBraceInUnicodeEscape,\n+    /// Non-hexadecimal value in '\\u{..}'.\n     InvalidCharInUnicodeEscape,\n+    /// '\\u{}'\n     EmptyUnicodeEscape,\n+    /// No closing brace in '\\u{..}', e.g. '\\u{12'.\n     UnclosedUnicodeEscape,\n+    /// '\\u{_12}'\n     LeadingUnderscoreUnicodeEscape,\n+    /// More than 6 charactes in '\\u{..}', e.g. '\\u{10FFFF_FF}'\n     OverlongUnicodeEscape,\n+    /// Invalid in-bound unicode character code, e.g. '\\u{DFFF}'.\n     LoneSurrogateUnicodeEscape,\n+    /// Out of bounds unicode character code, e.g. '\\u{FFFFFF}'.\n     OutOfRangeUnicodeEscape,\n \n+    /// Unicode escape code in byte literal.\n     UnicodeEscapeInByte,\n+    /// Non-ascii character in byte literal.\n     NonAsciiCharInByte,\n+    /// Non-ascii character in byte string literal.\n     NonAsciiCharInByteString,\n }\n \n@@ -44,15 +66,8 @@ pub fn unescape_char(literal_text: &str) -> Result<char, (usize, EscapeError)> {\n         .map_err(|err| (literal_text.len() - chars.as_str().len(), err))\n }\n \n-/// Takes a contents of a string literal (without quotes) and produces a\n-/// sequence of escaped characters or errors.\n-pub fn unescape_str<F>(literal_text: &str, callback: &mut F)\n-where\n-    F: FnMut(Range<usize>, Result<char, EscapeError>),\n-{\n-    unescape_str_or_byte_str(literal_text, Mode::Str, callback)\n-}\n-\n+/// Takes a contents of a byte literal (without quotes), and returns an\n+/// unescaped byte or an error.\n pub fn unescape_byte(literal_text: &str) -> Result<u8, (usize, EscapeError)> {\n     let mut chars = literal_text.chars();\n     unescape_char_or_byte(&mut chars, Mode::Byte)\n@@ -62,6 +77,17 @@ pub fn unescape_byte(literal_text: &str) -> Result<u8, (usize, EscapeError)> {\n \n /// Takes a contents of a string literal (without quotes) and produces a\n /// sequence of escaped characters or errors.\n+/// Values are returned through invoking of the provided callback.\n+pub fn unescape_str<F>(literal_text: &str, callback: &mut F)\n+where\n+    F: FnMut(Range<usize>, Result<char, EscapeError>),\n+{\n+    unescape_str_or_byte_str(literal_text, Mode::Str, callback)\n+}\n+\n+/// Takes a contents of a byte string literal (without quotes) and produces a\n+/// sequence of bytes or errors.\n+/// Values are returned through invoking of the provided callback.\n pub fn unescape_byte_str<F>(literal_text: &str, callback: &mut F)\n where\n     F: FnMut(Range<usize>, Result<u8, EscapeError>),\n@@ -71,8 +97,9 @@ where\n     })\n }\n \n-/// Takes a contents of a string literal (without quotes) and produces a\n+/// Takes a contents of a raw string literal (without quotes) and produces a\n /// sequence of characters or errors.\n+/// Values are returned through invoking of the provided callback.\n /// NOTE: Raw strings do not perform any explicit character escaping, here we\n /// only translate CRLF to LF and produce errors on bare CR.\n pub fn unescape_raw_str<F>(literal_text: &str, callback: &mut F)\n@@ -82,8 +109,9 @@ where\n     unescape_raw_str_or_byte_str(literal_text, Mode::Str, callback)\n }\n \n-/// Takes a contents of a string literal (without quotes) and produces a\n-/// sequence of characters or errors.\n+/// Takes a contents of a raw byte string literal (without quotes) and produces a\n+/// sequence of bytes or errors.\n+/// Values are returned through invoking of the provided callback.\n /// NOTE: Raw strings do not perform any explicit character escaping, here we\n /// only translate CRLF to LF and produce errors on bare CR.\n pub fn unescape_raw_byte_str<F>(literal_text: &str, callback: &mut F)\n@@ -95,6 +123,7 @@ where\n     })\n }\n \n+/// What kind of literal do we parse.\n #[derive(Debug, Clone, Copy)]\n pub enum Mode {\n     Char,\n@@ -126,20 +155,25 @@ impl Mode {\n \n fn scan_escape(first_char: char, chars: &mut Chars<'_>, mode: Mode) -> Result<char, EscapeError> {\n     if first_char != '\\\\' {\n+        // Previous character was not a slash, and we don't expect it to be\n+        // an escape-only character.\n         return match first_char {\n             '\\t' | '\\n' => Err(EscapeError::EscapeOnlyChar),\n             '\\r' => Err(EscapeError::BareCarriageReturn),\n             '\\'' if mode.in_single_quotes() => Err(EscapeError::EscapeOnlyChar),\n             '\"' if mode.in_double_quotes() => Err(EscapeError::EscapeOnlyChar),\n             _ => {\n                 if mode.is_bytes() && !first_char.is_ascii() {\n+                    // Byte literal can't be a non-ascii character.\n                     return Err(EscapeError::NonAsciiCharInByte);\n                 }\n                 Ok(first_char)\n             }\n         };\n     }\n \n+    // Previous character is '\\\\', try to unescape it.\n+\n     let second_char = chars.next().ok_or(EscapeError::LoneSlash)?;\n \n     let res = match second_char {\n@@ -152,6 +186,8 @@ fn scan_escape(first_char: char, chars: &mut Chars<'_>, mode: Mode) -> Result<ch\n         '0' => '\\0',\n \n         'x' => {\n+            // Parse hexadecimal character code.\n+\n             let hi = chars.next().ok_or(EscapeError::TooShortHexEscape)?;\n             let hi = hi.to_digit(16).ok_or(EscapeError::InvalidCharInHexEscape)?;\n \n@@ -160,6 +196,7 @@ fn scan_escape(first_char: char, chars: &mut Chars<'_>, mode: Mode) -> Result<ch\n \n             let value = hi * 16 + lo;\n \n+            // For a byte literal verify that it is within ASCII range.\n             if !mode.is_bytes() && !is_ascii(value) {\n                 return Err(EscapeError::OutOfRangeHexEscape);\n             }\n@@ -169,17 +206,22 @@ fn scan_escape(first_char: char, chars: &mut Chars<'_>, mode: Mode) -> Result<ch\n         }\n \n         'u' => {\n+            // We've parsed '\\u', now we have to parse '{..}'.\n+\n             if chars.next() != Some('{') {\n                 return Err(EscapeError::NoBraceInUnicodeEscape);\n             }\n \n+            // First characrer must be a hexadecimal digit.\n             let mut n_digits = 1;\n             let mut value: u32 = match chars.next().ok_or(EscapeError::UnclosedUnicodeEscape)? {\n                 '_' => return Err(EscapeError::LeadingUnderscoreUnicodeEscape),\n                 '}' => return Err(EscapeError::EmptyUnicodeEscape),\n                 c => c.to_digit(16).ok_or(EscapeError::InvalidCharInUnicodeEscape)?,\n             };\n \n+            // First character is valid, now parse the rest of the number\n+            // and closing brace.\n             loop {\n                 match chars.next() {\n                     None => return Err(EscapeError::UnclosedUnicodeEscape),\n@@ -188,6 +230,9 @@ fn scan_escape(first_char: char, chars: &mut Chars<'_>, mode: Mode) -> Result<ch\n                         if n_digits > 6 {\n                             return Err(EscapeError::OverlongUnicodeEscape);\n                         }\n+\n+                        // Incorrect syntax has higher priority for error reporting\n+                        // than unallowed value for a literal.\n                         if mode.is_bytes() {\n                             return Err(EscapeError::UnicodeEscapeInByte);\n                         }\n@@ -204,6 +249,7 @@ fn scan_escape(first_char: char, chars: &mut Chars<'_>, mode: Mode) -> Result<ch\n                         let digit = c.to_digit(16).ok_or(EscapeError::InvalidCharInUnicodeEscape)?;\n                         n_digits += 1;\n                         if n_digits > 6 {\n+                            // Stop updating value since we're sure that it's is incorrect already.\n                             continue;\n                         }\n                         let digit = digit as u32;\n@@ -243,6 +289,10 @@ where\n                 let second_char = chars.clone().next();\n                 match second_char {\n                     Some('\\n') => {\n+                        // Rust language specification requires us to skip whitespaces\n+                        // if unescaped '\\' character is followed by '\\n'.\n+                        // For details see [Rust language reference]\n+                        // (https://doc.rust-lang.org/reference/tokens.html#string-literals).\n                         skip_ascii_whitespace(&mut chars);\n                         continue;\n                     }"}]}