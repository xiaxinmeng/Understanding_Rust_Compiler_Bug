{"sha": "878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg3OGE5YjkyZWJlMWQ1NWMxMTlkOWM2YWU0NjM2YzMxY2E2ZDZjZDY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-06-08T20:37:10Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-06-08T20:37:10Z"}, "message": "auto merge of #7004 : dotdash/rust/allocs, r=thestinger\n\nThis removes some unnecessary allocations in the lexer, the typechecker and the metadata decoder. Reduces the time spent in the parsing and typechecking passes by about 10% for me.", "tree": {"sha": "6106d3a76c472a65eae65bda392ac08955fa29f1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6106d3a76c472a65eae65bda392ac08955fa29f1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "html_url": "https://github.com/rust-lang/rust/commit/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4aa77198cba0cc49fac2d47f1832b6b33ac57ada", "url": "https://api.github.com/repos/rust-lang/rust/commits/4aa77198cba0cc49fac2d47f1832b6b33ac57ada", "html_url": "https://github.com/rust-lang/rust/commit/4aa77198cba0cc49fac2d47f1832b6b33ac57ada"}, {"sha": "2096d79626029bfbfd7d42668be4705390a2c4ec", "url": "https://api.github.com/repos/rust-lang/rust/commits/2096d79626029bfbfd7d42668be4705390a2c4ec", "html_url": "https://github.com/rust-lang/rust/commit/2096d79626029bfbfd7d42668be4705390a2c4ec"}], "stats": {"total": 391, "additions": 199, "deletions": 192}, "files": [{"sha": "09e6a849f98b5e05ad4f7c1f61327d8ea5438a56", "filename": "src/libextra/ebml.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibextra%2Febml.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibextra%2Febml.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Febml.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -93,6 +93,14 @@ pub mod reader {\n         pub fn get(&self, tag: uint) -> Doc {\n             get_doc(*self, tag)\n         }\n+\n+        pub fn as_str_slice<'a>(&'a self) -> &'a str {\n+            str::from_bytes_slice(self.data.slice(self.start, self.end))\n+        }\n+\n+        pub fn as_str(&self) -> ~str {\n+            self.as_str_slice().to_owned()\n+        }\n     }\n \n     struct Res {\n@@ -239,15 +247,10 @@ pub mod reader {\n         return true;\n     }\n \n-    pub fn doc_data(d: Doc) -> ~[u8] {\n-        vec::slice::<u8>(*d.data, d.start, d.end).to_vec()\n-    }\n-\n     pub fn with_doc_data<T>(d: Doc, f: &fn(x: &[u8]) -> T) -> T {\n         f(vec::slice(*d.data, d.start, d.end))\n     }\n \n-    pub fn doc_as_str(d: Doc) -> ~str { str::from_bytes(doc_data(d)) }\n \n     pub fn doc_as_u8(d: Doc) -> u8 {\n         assert_eq!(d.end, d.start + 1u);\n@@ -294,7 +297,7 @@ pub mod reader {\n \n                 if r_tag == (EsLabel as uint) {\n                     self.pos = r_doc.end;\n-                    let str = doc_as_str(r_doc);\n+                    let str = r_doc.as_str_slice();\n                     if lbl != str {\n                         fail!(\"Expected label %s but found %s\", lbl, str);\n                     }\n@@ -415,7 +418,9 @@ pub mod reader {\n         fn read_char(&mut self) -> char {\n             doc_as_u32(self.next_doc(EsChar)) as char\n         }\n-        fn read_str(&mut self) -> ~str { doc_as_str(self.next_doc(EsStr)) }\n+        fn read_str(&mut self) -> ~str {\n+            self.next_doc(EsStr).as_str()\n+        }\n \n         // Compound types:\n         fn read_enum<T>(&mut self,"}, {"sha": "81c1560f18bd49a05823bc4c7c3d84eb0f89fd79", "filename": "src/librustc/metadata/decoder.rs", "status": "modified", "additions": 42, "deletions": 53, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmetadata%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmetadata%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Fdecoder.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -162,19 +162,18 @@ fn item_visibility(item: ebml::Doc) -> ast::visibility {\n \n fn item_method_sort(item: ebml::Doc) -> char {\n     for reader::tagged_docs(item, tag_item_trait_method_sort) |doc| {\n-        return str::from_bytes(reader::doc_data(doc))[0] as char;\n+        return doc.as_str_slice()[0] as char;\n     }\n     return 'r';\n }\n \n fn item_symbol(item: ebml::Doc) -> ~str {\n-    let sym = reader::get_doc(item, tag_items_data_item_symbol);\n-    return str::from_bytes(reader::doc_data(sym));\n+    reader::get_doc(item, tag_items_data_item_symbol).as_str()\n }\n \n fn item_parent_item(d: ebml::Doc) -> Option<ast::def_id> {\n     for reader::tagged_docs(d, tag_items_data_parent_item) |did| {\n-        return Some(reader::with_doc_data(did, |d| parse_def_id(d)));\n+        return Some(reader::with_doc_data(did, parse_def_id));\n     }\n     None\n }\n@@ -195,8 +194,7 @@ fn item_reqd_and_translated_parent_item(cnum: ast::crate_num,\n \n fn item_def_id(d: ebml::Doc, cdata: cmd) -> ast::def_id {\n     let tagdoc = reader::get_doc(d, tag_def_id);\n-    return translate_def_id(cdata, reader::with_doc_data(tagdoc,\n-                                                    |d| parse_def_id(d)));\n+    return translate_def_id(cdata, reader::with_doc_data(tagdoc, parse_def_id));\n }\n \n fn each_reexport(d: ebml::Doc, f: &fn(ebml::Doc) -> bool) -> bool {\n@@ -210,19 +208,19 @@ fn each_reexport(d: ebml::Doc, f: &fn(ebml::Doc) -> bool) -> bool {\n \n fn variant_disr_val(d: ebml::Doc) -> Option<int> {\n     do reader::maybe_get_doc(d, tag_disr_val).chain |val_doc| {\n-        int::parse_bytes(reader::doc_data(val_doc), 10u)\n+        do reader::with_doc_data(val_doc) |data| { int::parse_bytes(data, 10u) }\n     }\n }\n \n fn doc_type(doc: ebml::Doc, tcx: ty::ctxt, cdata: cmd) -> ty::t {\n     let tp = reader::get_doc(doc, tag_items_data_item_type);\n-    parse_ty_data(tp.data, cdata.cnum, tp.start, tcx,\n+    parse_ty_data(*tp.data, cdata.cnum, tp.start, tcx,\n                   |_, did| translate_def_id(cdata, did))\n }\n \n fn doc_method_fty(doc: ebml::Doc, tcx: ty::ctxt, cdata: cmd) -> ty::BareFnTy {\n     let tp = reader::get_doc(doc, tag_item_method_fty);\n-    parse_bare_fn_ty_data(tp.data, cdata.cnum, tp.start, tcx,\n+    parse_bare_fn_ty_data(*tp.data, cdata.cnum, tp.start, tcx,\n                           |_, did| translate_def_id(cdata, did))\n }\n \n@@ -231,7 +229,7 @@ fn doc_transformed_self_ty(doc: ebml::Doc,\n                            cdata: cmd) -> Option<ty::t>\n {\n     do reader::maybe_get_doc(doc, tag_item_method_transformed_self_ty).map |tp| {\n-        parse_ty_data(tp.data, cdata.cnum, tp.start, tcx,\n+        parse_ty_data(*tp.data, cdata.cnum, tp.start, tcx,\n                       |_, did| translate_def_id(cdata, did))\n     }\n }\n@@ -242,7 +240,7 @@ pub fn item_type(_item_id: ast::def_id, item: ebml::Doc,\n }\n \n fn doc_trait_ref(doc: ebml::Doc, tcx: ty::ctxt, cdata: cmd) -> ty::TraitRef {\n-    parse_trait_ref_data(doc.data, cdata.cnum, doc.start, tcx,\n+    parse_trait_ref_data(*doc.data, cdata.cnum, doc.start, tcx,\n                          |_, did| translate_def_id(cdata, did))\n }\n \n@@ -257,7 +255,7 @@ fn item_ty_param_defs(item: ebml::Doc, tcx: ty::ctxt, cdata: cmd,\n     let mut bounds = ~[];\n     for reader::tagged_docs(item, tag) |p| {\n         let bd = parse_type_param_def_data(\n-            p.data, p.start, cdata.cnum, tcx,\n+            *p.data, p.start, cdata.cnum, tcx,\n             |_, did| translate_def_id(cdata, did));\n         bounds.push(bd);\n     }\n@@ -282,7 +280,7 @@ fn enum_variant_ids(item: ebml::Doc, cdata: cmd) -> ~[ast::def_id] {\n     let mut ids: ~[ast::def_id] = ~[];\n     let v = tag_items_data_item_variant;\n     for reader::tagged_docs(item, v) |p| {\n-        let ext = reader::with_doc_data(p, |d| parse_def_id(d));\n+        let ext = reader::with_doc_data(p, parse_def_id);\n         ids.push(ast::def_id { crate: cdata.cnum, node: ext.node });\n     };\n     return ids;\n@@ -297,10 +295,10 @@ fn item_path(item_doc: ebml::Doc) -> ast_map::path {\n     let mut result = vec::with_capacity(len);\n     for reader::docs(path_doc) |tag, elt_doc| {\n         if tag == tag_path_elt_mod {\n-            let str = reader::doc_as_str(elt_doc);\n+            let str = elt_doc.as_str_slice();\n             result.push(ast_map::path_mod(token::str_to_ident(str)));\n         } else if tag == tag_path_elt_name {\n-            let str = reader::doc_as_str(elt_doc);\n+            let str = elt_doc.as_str_slice();\n             result.push(ast_map::path_name(token::str_to_ident(str)));\n         } else {\n             // ignore tag_path_len element\n@@ -312,12 +310,10 @@ fn item_path(item_doc: ebml::Doc) -> ast_map::path {\n \n fn item_name(intr: @ident_interner, item: ebml::Doc) -> ast::ident {\n     let name = reader::get_doc(item, tag_paths_data_name);\n-    do reader::with_doc_data(name) |data| {\n-        let string = str::from_bytes_slice(data);\n-        match intr.find_equiv(&StringRef(string)) {\n-            None => token::str_to_ident(string),\n-            Some(val) => ast::new_ident(val),\n-        }\n+    let string = name.as_str_slice();\n+    match intr.find_equiv(&StringRef(string)) {\n+        None => token::str_to_ident(string),\n+        Some(val) => ast::new_ident(val),\n     }\n }\n \n@@ -413,15 +409,9 @@ pub fn get_impl_trait(cdata: cmd,\n                        tcx: ty::ctxt) -> Option<@ty::TraitRef>\n {\n     let item_doc = lookup_item(id, cdata.data);\n-    let mut result = None;\n-    for reader::tagged_docs(item_doc, tag_item_trait_ref) |tp| {\n-        let trait_ref =\n-            @parse_trait_ref_data(tp.data, cdata.cnum, tp.start, tcx,\n-                                  |_, did| translate_def_id(cdata, did));\n-        result = Some(trait_ref);\n-        break;\n-    };\n-    result\n+    do reader::maybe_get_doc(item_doc, tag_item_trait_ref).map |&tp| {\n+        @doc_trait_ref(tp, tcx, cdata)\n+    }\n }\n \n pub fn get_impl_method(intr: @ident_interner, cdata: cmd, id: ast::node_id,\n@@ -430,7 +420,7 @@ pub fn get_impl_method(intr: @ident_interner, cdata: cmd, id: ast::node_id,\n     let mut found = None;\n     for reader::tagged_docs(find_item(id, items), tag_item_impl_method)\n         |mid| {\n-            let m_did = reader::with_doc_data(mid, |d| parse_def_id(d));\n+            let m_did = reader::with_doc_data(mid, parse_def_id);\n             if item_name(intr, find_item(m_did.node, items)) == name {\n                 found = Some(translate_def_id(cdata, m_did));\n             }\n@@ -513,19 +503,17 @@ pub fn each_path(intr: @ident_interner,\n             let def_id_doc =\n                 reader::get_doc(reexport_doc,\n                                 tag_items_data_item_reexport_def_id);\n-            let def_id =\n-                reader::with_doc_data(def_id_doc,\n-                                      |d| parse_def_id(d));\n+            let def_id = reader::with_doc_data(def_id_doc, parse_def_id);\n             let def_id = translate_def_id(cdata, def_id);\n \n             let reexport_name_doc =\n                 reader::get_doc(reexport_doc,\n                                 tag_items_data_item_reexport_name);\n-            let reexport_name = reader::doc_as_str(reexport_name_doc);\n+            let reexport_name = reexport_name_doc.as_str_slice();\n \n             let reexport_path;\n             if path_is_empty {\n-                reexport_path = reexport_name;\n+                reexport_path = reexport_name.to_owned();\n             } else {\n                 reexport_path = path + \"::\" + reexport_name;\n             }\n@@ -646,7 +634,7 @@ fn get_explicit_self(item: ebml::Doc) -> ast::explicit_self_ {\n     }\n \n     let explicit_self_doc = reader::get_doc(item, tag_item_trait_method_explicit_self);\n-    let string = reader::doc_as_str(explicit_self_doc);\n+    let string = explicit_self_doc.as_str_slice();\n \n     let explicit_self_kind = string[0];\n     match explicit_self_kind as char {\n@@ -668,7 +656,7 @@ fn item_impl_methods(intr: @ident_interner, cdata: cmd, item: ebml::Doc,\n                      base_tps: uint) -> ~[@resolve::MethodInfo] {\n     let mut rslt = ~[];\n     for reader::tagged_docs(item, tag_item_impl_method) |doc| {\n-        let m_did = reader::with_doc_data(doc, |d| parse_def_id(d));\n+        let m_did = reader::with_doc_data(doc, parse_def_id);\n         let mth_item = lookup_item(m_did.node, cdata.data);\n         let explicit_self = get_explicit_self(mth_item);\n         rslt.push(@resolve::MethodInfo {\n@@ -690,7 +678,7 @@ pub fn get_impls_for_mod(intr: @ident_interner,\n     let mod_item = lookup_item(m_id, data);\n     let mut result = ~[];\n     for reader::tagged_docs(mod_item, tag_mod_impl) |doc| {\n-        let did = reader::with_doc_data(doc, |d| parse_def_id(d));\n+        let did = reader::with_doc_data(doc, parse_def_id);\n         let local_did = translate_def_id(cdata, did);\n         debug!(\"(get impls for mod) getting did %? for '%?'\",\n                local_did, name);\n@@ -831,7 +819,7 @@ pub fn get_type_name_if_impl(cdata: cmd,\n     }\n \n     for reader::tagged_docs(item, tag_item_impl_type_basename) |doc| {\n-        return Some(token::str_to_ident(str::from_bytes(reader::doc_data(doc))));\n+        return Some(token::str_to_ident(doc.as_str_slice()));\n     }\n \n     return None;\n@@ -853,7 +841,7 @@ pub fn get_static_methods_if_impl(intr: @ident_interner,\n \n     let mut impl_method_ids = ~[];\n     for reader::tagged_docs(item, tag_item_impl_method) |impl_method_doc| {\n-        impl_method_ids.push(parse_def_id(reader::doc_data(impl_method_doc)));\n+        impl_method_ids.push(reader::with_doc_data(impl_method_doc, parse_def_id));\n     }\n \n     let mut static_impl_methods = ~[];\n@@ -950,12 +938,13 @@ fn family_names_type(fam: Family) -> bool {\n }\n \n fn read_path(d: ebml::Doc) -> (~str, uint) {\n-    let desc = reader::doc_data(d);\n-    let pos = io::u64_from_be_bytes(desc, 0u, 4u) as uint;\n-    let pathbytes = vec::slice::<u8>(desc, 4u, vec::len::<u8>(desc));\n-    let path = str::from_bytes(pathbytes);\n+    do reader::with_doc_data(d) |desc| {\n+        let pos = io::u64_from_be_bytes(desc, 0u, 4u) as uint;\n+        let pathbytes = desc.slice(4u, desc.len());\n+        let path = str::from_bytes(pathbytes);\n \n-    (path, pos)\n+        (path, pos)\n+    }\n }\n \n fn describe_def(items: ebml::Doc, id: ast::def_id) -> ~str {\n@@ -996,21 +985,21 @@ fn get_meta_items(md: ebml::Doc) -> ~[@ast::meta_item] {\n     let mut items: ~[@ast::meta_item] = ~[];\n     for reader::tagged_docs(md, tag_meta_item_word) |meta_item_doc| {\n         let nd = reader::get_doc(meta_item_doc, tag_meta_item_name);\n-        let n = str::from_bytes(reader::doc_data(nd));\n+        let n = nd.as_str();\n         items.push(attr::mk_word_item(@n));\n     };\n     for reader::tagged_docs(md, tag_meta_item_name_value) |meta_item_doc| {\n         let nd = reader::get_doc(meta_item_doc, tag_meta_item_name);\n         let vd = reader::get_doc(meta_item_doc, tag_meta_item_value);\n-        let n = str::from_bytes(reader::doc_data(nd));\n-        let v = str::from_bytes(reader::doc_data(vd));\n+        let n = nd.as_str();\n+        let v = vd.as_str();\n         // FIXME (#623): Should be able to decode meta_name_value variants,\n         // but currently the encoder just drops them\n         items.push(attr::mk_name_value_item_str(@n, @v));\n     };\n     for reader::tagged_docs(md, tag_meta_item_list) |meta_item_doc| {\n         let nd = reader::get_doc(meta_item_doc, tag_meta_item_name);\n-        let n = str::from_bytes(reader::doc_data(nd));\n+        let n = nd.as_str();\n         let subitems = get_meta_items(meta_item_doc);\n         items.push(attr::mk_list_item(@n, subitems));\n     };\n@@ -1079,7 +1068,7 @@ pub fn get_crate_deps(data: @~[u8]) -> ~[crate_dep] {\n     let depsdoc = reader::get_doc(cratedoc, tag_crate_deps);\n     let mut crate_num = 1;\n     fn docstr(doc: ebml::Doc, tag_: uint) -> ~str {\n-        str::from_bytes(reader::doc_data(reader::get_doc(doc, tag_)))\n+        reader::get_doc(doc, tag_).as_str()\n     }\n     for reader::tagged_docs(depsdoc, tag_crate_dep) |depdoc| {\n         deps.push(crate_dep {cnum: crate_num,\n@@ -1106,7 +1095,7 @@ fn list_crate_deps(data: @~[u8], out: @io::Writer) {\n pub fn get_crate_hash(data: @~[u8]) -> @~str {\n     let cratedoc = reader::Doc(data);\n     let hashdoc = reader::get_doc(cratedoc, tag_crate_hash);\n-    @str::from_bytes(reader::doc_data(hashdoc))\n+    @hashdoc.as_str()\n }\n \n pub fn get_crate_vers(data: @~[u8]) -> @~str {\n@@ -1161,7 +1150,7 @@ pub fn get_link_args_for_crate(cdata: cmd) -> ~[~str] {\n     let link_args = reader::get_doc(reader::Doc(cdata.data), tag_link_args);\n     let mut result = ~[];\n     for reader::tagged_docs(link_args, tag_link_args_arg) |arg_doc| {\n-        result.push(reader::doc_as_str(arg_doc));\n+        result.push(arg_doc.as_str());\n     }\n     result\n }"}, {"sha": "cf2a92b291f2883641dfc92e92f3a063f0a5715e", "filename": "src/librustc/metadata/tydecode.rs", "status": "modified", "additions": 50, "deletions": 53, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmetadata%2Ftydecode.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmetadata%2Ftydecode.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Ftydecode.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -55,24 +55,24 @@ pub enum DefIdSource {\n type conv_did<'self> =\n     &'self fn(source: DefIdSource, ast::def_id) -> ast::def_id;\n \n-pub struct PState {\n-    data: @~[u8],\n+pub struct PState<'self> {\n+    data: &'self [u8],\n     crate: int,\n     pos: uint,\n     tcx: ty::ctxt\n }\n \n-fn peek(st: @mut PState) -> char {\n+fn peek(st: &PState) -> char {\n     st.data[st.pos] as char\n }\n \n-fn next(st: @mut PState) -> char {\n+fn next(st: &mut PState) -> char {\n     let ch = st.data[st.pos] as char;\n     st.pos = st.pos + 1u;\n     return ch;\n }\n \n-fn next_byte(st: @mut PState) -> u8 {\n+fn next_byte(st: &mut PState) -> u8 {\n     let b = st.data[st.pos];\n     st.pos = st.pos + 1u;\n     return b;\n@@ -92,46 +92,46 @@ fn scan<R>(st: &mut PState, is_last: &fn(char) -> bool,\n     return op(st.data.slice(start_pos, end_pos));\n }\n \n-pub fn parse_ident(st: @mut PState, last: char) -> ast::ident {\n+pub fn parse_ident(st: &mut PState, last: char) -> ast::ident {\n     fn is_last(b: char, c: char) -> bool { return c == b; }\n     return parse_ident_(st, |a| is_last(last, a) );\n }\n \n-fn parse_ident_(st: @mut PState, is_last: @fn(char) -> bool) ->\n+fn parse_ident_(st: &mut PState, is_last: @fn(char) -> bool) ->\n    ast::ident {\n     let rslt = scan(st, is_last, str::from_bytes);\n     return st.tcx.sess.ident_of(rslt);\n }\n \n-pub fn parse_state_from_data(data: @~[u8], crate_num: int,\n-                             pos: uint, tcx: ty::ctxt) -> @mut PState {\n-    @mut PState {\n+pub fn parse_state_from_data<'a>(data: &'a [u8], crate_num: int,\n+                             pos: uint, tcx: ty::ctxt) -> PState<'a> {\n+    PState {\n         data: data,\n         crate: crate_num,\n         pos: pos,\n         tcx: tcx\n     }\n }\n \n-pub fn parse_ty_data(data: @~[u8], crate_num: int, pos: uint, tcx: ty::ctxt,\n+pub fn parse_ty_data(data: &[u8], crate_num: int, pos: uint, tcx: ty::ctxt,\n                      conv: conv_did) -> ty::t {\n-    let st = parse_state_from_data(data, crate_num, pos, tcx);\n-    parse_ty(st, conv)\n+    let mut st = parse_state_from_data(data, crate_num, pos, tcx);\n+    parse_ty(&mut st, conv)\n }\n \n-pub fn parse_bare_fn_ty_data(data: @~[u8], crate_num: int, pos: uint, tcx: ty::ctxt,\n+pub fn parse_bare_fn_ty_data(data: &[u8], crate_num: int, pos: uint, tcx: ty::ctxt,\n                              conv: conv_did) -> ty::BareFnTy {\n-    let st = parse_state_from_data(data, crate_num, pos, tcx);\n-    parse_bare_fn_ty(st, conv)\n+    let mut st = parse_state_from_data(data, crate_num, pos, tcx);\n+    parse_bare_fn_ty(&mut st, conv)\n }\n \n-pub fn parse_trait_ref_data(data: @~[u8], crate_num: int, pos: uint, tcx: ty::ctxt,\n+pub fn parse_trait_ref_data(data: &[u8], crate_num: int, pos: uint, tcx: ty::ctxt,\n                             conv: conv_did) -> ty::TraitRef {\n-    let st = parse_state_from_data(data, crate_num, pos, tcx);\n-    parse_trait_ref(st, conv)\n+    let mut st = parse_state_from_data(data, crate_num, pos, tcx);\n+    parse_trait_ref(&mut st, conv)\n }\n \n-fn parse_path(st: @mut PState) -> @ast::Path {\n+fn parse_path(st: &mut PState) -> @ast::Path {\n     let mut idents: ~[ast::ident] = ~[];\n     fn is_last(c: char) -> bool { return c == '(' || c == ':'; }\n     idents.push(parse_ident_(st, is_last));\n@@ -151,7 +151,7 @@ fn parse_path(st: @mut PState) -> @ast::Path {\n     };\n }\n \n-fn parse_sigil(st: @mut PState) -> ast::Sigil {\n+fn parse_sigil(st: &mut PState) -> ast::Sigil {\n     match next(st) {\n         '@' => ast::ManagedSigil,\n         '~' => ast::OwnedSigil,\n@@ -160,7 +160,7 @@ fn parse_sigil(st: @mut PState) -> ast::Sigil {\n     }\n }\n \n-fn parse_vstore(st: @mut PState) -> ty::vstore {\n+fn parse_vstore(st: &mut PState) -> ty::vstore {\n     assert_eq!(next(st), '/');\n \n     let c = peek(st);\n@@ -178,7 +178,7 @@ fn parse_vstore(st: @mut PState) -> ty::vstore {\n     }\n }\n \n-fn parse_trait_store(st: @mut PState) -> ty::TraitStore {\n+fn parse_trait_store(st: &mut PState) -> ty::TraitStore {\n     match next(st) {\n         '~' => ty::UniqTraitStore,\n         '@' => ty::BoxTraitStore,\n@@ -187,10 +187,10 @@ fn parse_trait_store(st: @mut PState) -> ty::TraitStore {\n     }\n }\n \n-fn parse_substs(st: @mut PState, conv: conv_did) -> ty::substs {\n-    let self_r = parse_opt(st, || parse_region(st) );\n+fn parse_substs(st: &mut PState, conv: conv_did) -> ty::substs {\n+    let self_r = parse_opt(st, |st| parse_region(st) );\n \n-    let self_ty = parse_opt(st, || parse_ty(st, conv) );\n+    let self_ty = parse_opt(st, |st| parse_ty(st, conv) );\n \n     assert_eq!(next(st), '[');\n     let mut params: ~[ty::t] = ~[];\n@@ -204,7 +204,7 @@ fn parse_substs(st: @mut PState, conv: conv_did) -> ty::substs {\n     };\n }\n \n-fn parse_bound_region(st: @mut PState) -> ty::bound_region {\n+fn parse_bound_region(st: &mut PState) -> ty::bound_region {\n     match next(st) {\n       's' => ty::br_self,\n       'a' => {\n@@ -222,7 +222,7 @@ fn parse_bound_region(st: @mut PState) -> ty::bound_region {\n     }\n }\n \n-fn parse_region(st: @mut PState) -> ty::Region {\n+fn parse_region(st: &mut PState) -> ty::Region {\n     match next(st) {\n       'b' => {\n         ty::re_bound(parse_bound_region(st))\n@@ -251,15 +251,15 @@ fn parse_region(st: @mut PState) -> ty::Region {\n     }\n }\n \n-fn parse_opt<T>(st: @mut PState, f: &fn() -> T) -> Option<T> {\n+fn parse_opt<T>(st: &mut PState, f: &fn(&mut PState) -> T) -> Option<T> {\n     match next(st) {\n       'n' => None,\n-      's' => Some(f()),\n+      's' => Some(f(st)),\n       _ => fail!(\"parse_opt: bad input\")\n     }\n }\n \n-fn parse_str(st: @mut PState, term: char) -> ~str {\n+fn parse_str(st: &mut PState, term: char) -> ~str {\n     let mut result = ~\"\";\n     while peek(st) != term {\n         result += str::from_byte(next_byte(st));\n@@ -268,13 +268,13 @@ fn parse_str(st: @mut PState, term: char) -> ~str {\n     return result;\n }\n \n-fn parse_trait_ref(st: @mut PState, conv: conv_did) -> ty::TraitRef {\n+fn parse_trait_ref(st: &mut PState, conv: conv_did) -> ty::TraitRef {\n     let def = parse_def(st, NominalType, conv);\n     let substs = parse_substs(st, conv);\n     ty::TraitRef {def_id: def, substs: substs}\n }\n \n-fn parse_ty(st: @mut PState, conv: conv_did) -> ty::t {\n+fn parse_ty(st: &mut PState, conv: conv_did) -> ty::t {\n     match next(st) {\n       'n' => return ty::mk_nil(),\n       'z' => return ty::mk_bot(),\n@@ -370,8 +370,8 @@ fn parse_ty(st: @mut PState, conv: conv_did) -> ty::t {\n         match st.tcx.rcache.find(&key) {\n           Some(&tt) => return tt,\n           None => {\n-            let ps = @mut PState {pos: pos ,.. copy *st};\n-            let tt = parse_ty(ps, conv);\n+            let mut ps = PState {pos: pos ,.. copy *st};\n+            let tt = parse_ty(&mut ps, conv);\n             st.tcx.rcache.insert(key, tt);\n             return tt;\n           }\n@@ -394,28 +394,25 @@ fn parse_ty(st: @mut PState, conv: conv_did) -> ty::t {\n     }\n }\n \n-fn parse_mutability(st: @mut PState) -> ast::mutability {\n+fn parse_mutability(st: &mut PState) -> ast::mutability {\n     match peek(st) {\n       'm' => { next(st); ast::m_mutbl }\n       '?' => { next(st); ast::m_const }\n       _ => { ast::m_imm }\n     }\n }\n \n-fn parse_mt(st: @mut PState, conv: conv_did) -> ty::mt {\n+fn parse_mt(st: &mut PState, conv: conv_did) -> ty::mt {\n     let m = parse_mutability(st);\n     ty::mt { ty: parse_ty(st, conv), mutbl: m }\n }\n \n-fn parse_def(st: @mut PState, source: DefIdSource,\n+fn parse_def(st: &mut PState, source: DefIdSource,\n              conv: conv_did) -> ast::def_id {\n-    let mut def = ~[];\n-    while peek(st) != '|' { def.push(next_byte(st)); }\n-    st.pos = st.pos + 1u;\n-    return conv(source, parse_def_id(def));\n+    return conv(source, scan(st, |c| { c == '|' }, parse_def_id));\n }\n \n-fn parse_uint(st: @mut PState) -> uint {\n+fn parse_uint(st: &mut PState) -> uint {\n     let mut n = 0;\n     loop {\n         let cur = peek(st);\n@@ -426,7 +423,7 @@ fn parse_uint(st: @mut PState) -> uint {\n     };\n }\n \n-fn parse_hex(st: @mut PState) -> uint {\n+fn parse_hex(st: &mut PState) -> uint {\n     let mut n = 0u;\n     loop {\n         let cur = peek(st);\n@@ -449,7 +446,7 @@ fn parse_purity(c: char) -> purity {\n     }\n }\n \n-fn parse_abi_set(st: @mut PState) -> AbiSet {\n+fn parse_abi_set(st: &mut PState) -> AbiSet {\n     assert_eq!(next(st), '[');\n     let mut abis = AbiSet::empty();\n     while peek(st) != ']' {\n@@ -470,7 +467,7 @@ fn parse_onceness(c: char) -> ast::Onceness {\n     }\n }\n \n-fn parse_closure_ty(st: @mut PState, conv: conv_did) -> ty::ClosureTy {\n+fn parse_closure_ty(st: &mut PState, conv: conv_did) -> ty::ClosureTy {\n     let sigil = parse_sigil(st);\n     let purity = parse_purity(next(st));\n     let onceness = parse_onceness(next(st));\n@@ -487,7 +484,7 @@ fn parse_closure_ty(st: @mut PState, conv: conv_did) -> ty::ClosureTy {\n     }\n }\n \n-fn parse_bare_fn_ty(st: @mut PState, conv: conv_did) -> ty::BareFnTy {\n+fn parse_bare_fn_ty(st: &mut PState, conv: conv_did) -> ty::BareFnTy {\n     let purity = parse_purity(next(st));\n     let abi = parse_abi_set(st);\n     let sig = parse_sig(st, conv);\n@@ -498,7 +495,7 @@ fn parse_bare_fn_ty(st: @mut PState, conv: conv_did) -> ty::BareFnTy {\n     }\n }\n \n-fn parse_sig(st: @mut PState, conv: conv_did) -> ty::FnSig {\n+fn parse_sig(st: &mut PState, conv: conv_did) -> ty::FnSig {\n     assert_eq!(next(st), '[');\n     let mut inputs = ~[];\n     while peek(st) != ']' {\n@@ -537,20 +534,20 @@ pub fn parse_def_id(buf: &[u8]) -> ast::def_id {\n     ast::def_id { crate: crate_num, node: def_num }\n }\n \n-pub fn parse_type_param_def_data(data: @~[u8], start: uint,\n+pub fn parse_type_param_def_data(data: &[u8], start: uint,\n                                  crate_num: int, tcx: ty::ctxt,\n                                  conv: conv_did) -> ty::TypeParameterDef\n {\n-    let st = parse_state_from_data(data, crate_num, start, tcx);\n-    parse_type_param_def(st, conv)\n+    let mut st = parse_state_from_data(data, crate_num, start, tcx);\n+    parse_type_param_def(&mut st, conv)\n }\n \n-fn parse_type_param_def(st: @mut PState, conv: conv_did) -> ty::TypeParameterDef {\n+fn parse_type_param_def(st: &mut PState, conv: conv_did) -> ty::TypeParameterDef {\n     ty::TypeParameterDef {def_id: parse_def(st, NominalType, conv),\n                           bounds: @parse_bounds(st, conv)}\n }\n \n-fn parse_bounds(st: @mut PState, conv: conv_did) -> ty::ParamBounds {\n+fn parse_bounds(st: &mut PState, conv: conv_did) -> ty::ParamBounds {\n     let mut param_bounds = ty::ParamBounds {\n         builtin_bounds: ty::EmptyBuiltinBounds(),\n         trait_bounds: ~[]"}, {"sha": "32a2bf22f27057daf4c7c7bc8cd6f4279ee8fd11", "filename": "src/librustc/middle/astencode.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmiddle%2Fastencode.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmiddle%2Fastencode.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fastencode.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -964,7 +964,7 @@ impl ebml_decoder_decoder_helpers for reader::Decoder {\n \n         return do self.read_opaque |this, doc| {\n             let ty = tydecode::parse_ty_data(\n-                doc.data,\n+                *doc.data,\n                 xcx.dcx.cdata.cnum,\n                 doc.start,\n                 xcx.dcx.tcx,\n@@ -994,7 +994,7 @@ impl ebml_decoder_decoder_helpers for reader::Decoder {\n                            -> ty::TypeParameterDef {\n         do self.read_opaque |this, doc| {\n             tydecode::parse_type_param_def_data(\n-                doc.data,\n+                *doc.data,\n                 doc.start,\n                 xcx.dcx.cdata.cnum,\n                 xcx.dcx.tcx,"}, {"sha": "76681674892096761b70102939a07c0a8e5b2fa0", "filename": "src/librustc/middle/typeck/infer/combine.rs", "status": "modified", "additions": 33, "deletions": 33, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcombine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcombine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcombine.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -434,12 +434,12 @@ pub fn super_fn_sigs<C:Combine>(\n pub fn super_tys<C:Combine>(\n     this: &C, a: ty::t, b: ty::t) -> cres<ty::t> {\n     let tcx = this.infcx().tcx;\n-    return match (/*bad*/copy ty::get(a).sty, /*bad*/copy ty::get(b).sty) {\n+    return match (&ty::get(a).sty, &ty::get(b).sty) {\n       // The \"subtype\" ought to be handling cases involving bot or var:\n-      (ty::ty_bot, _) |\n-      (_, ty::ty_bot) |\n-      (ty::ty_infer(TyVar(_)), _) |\n-      (_, ty::ty_infer(TyVar(_))) => {\n+      (&ty::ty_bot, _) |\n+      (_, &ty::ty_bot) |\n+      (&ty::ty_infer(TyVar(_)), _) |\n+      (_, &ty::ty_infer(TyVar(_))) => {\n         tcx.sess.bug(\n             fmt!(\"%s: bot and var types should have been handled (%s,%s)\",\n                  this.tag(),\n@@ -448,68 +448,68 @@ pub fn super_tys<C:Combine>(\n       }\n \n         // Relate integral variables to other types\n-        (ty::ty_infer(IntVar(a_id)), ty::ty_infer(IntVar(b_id))) => {\n+        (&ty::ty_infer(IntVar(a_id)), &ty::ty_infer(IntVar(b_id))) => {\n             if_ok!(this.infcx().simple_vars(this.a_is_expected(),\n                                             a_id, b_id));\n             Ok(a)\n         }\n-        (ty::ty_infer(IntVar(v_id)), ty::ty_int(v)) => {\n+        (&ty::ty_infer(IntVar(v_id)), &ty::ty_int(v)) => {\n             unify_integral_variable(this, this.a_is_expected(),\n                                     v_id, IntType(v))\n         }\n-        (ty::ty_int(v), ty::ty_infer(IntVar(v_id))) => {\n+        (&ty::ty_int(v), &ty::ty_infer(IntVar(v_id))) => {\n             unify_integral_variable(this, !this.a_is_expected(),\n                                     v_id, IntType(v))\n         }\n-        (ty::ty_infer(IntVar(v_id)), ty::ty_uint(v)) => {\n+        (&ty::ty_infer(IntVar(v_id)), &ty::ty_uint(v)) => {\n             unify_integral_variable(this, this.a_is_expected(),\n                                     v_id, UintType(v))\n         }\n-        (ty::ty_uint(v), ty::ty_infer(IntVar(v_id))) => {\n+        (&ty::ty_uint(v), &ty::ty_infer(IntVar(v_id))) => {\n             unify_integral_variable(this, !this.a_is_expected(),\n                                     v_id, UintType(v))\n         }\n \n         // Relate floating-point variables to other types\n-        (ty::ty_infer(FloatVar(a_id)), ty::ty_infer(FloatVar(b_id))) => {\n+        (&ty::ty_infer(FloatVar(a_id)), &ty::ty_infer(FloatVar(b_id))) => {\n             if_ok!(this.infcx().simple_vars(this.a_is_expected(),\n                                             a_id, b_id));\n             Ok(a)\n         }\n-        (ty::ty_infer(FloatVar(v_id)), ty::ty_float(v)) => {\n+        (&ty::ty_infer(FloatVar(v_id)), &ty::ty_float(v)) => {\n             unify_float_variable(this, this.a_is_expected(), v_id, v)\n         }\n-        (ty::ty_float(v), ty::ty_infer(FloatVar(v_id))) => {\n+        (&ty::ty_float(v), &ty::ty_infer(FloatVar(v_id))) => {\n             unify_float_variable(this, !this.a_is_expected(), v_id, v)\n         }\n \n-      (ty::ty_nil, _) |\n-      (ty::ty_bool, _) |\n-      (ty::ty_int(_), _) |\n-      (ty::ty_uint(_), _) |\n-      (ty::ty_float(_), _) => {\n+      (&ty::ty_nil, _) |\n+      (&ty::ty_bool, _) |\n+      (&ty::ty_int(_), _) |\n+      (&ty::ty_uint(_), _) |\n+      (&ty::ty_float(_), _) => {\n         if ty::get(a).sty == ty::get(b).sty {\n             Ok(a)\n         } else {\n             Err(ty::terr_sorts(expected_found(this, a, b)))\n         }\n       }\n \n-      (ty::ty_param(ref a_p), ty::ty_param(ref b_p)) if a_p.idx == b_p.idx => {\n+      (&ty::ty_param(ref a_p), &ty::ty_param(ref b_p)) if a_p.idx == b_p.idx => {\n         Ok(a)\n       }\n \n-      (ty::ty_enum(a_id, ref a_substs),\n-       ty::ty_enum(b_id, ref b_substs))\n+      (&ty::ty_enum(a_id, ref a_substs),\n+       &ty::ty_enum(b_id, ref b_substs))\n       if a_id == b_id => {\n           let type_def = ty::lookup_item_type(tcx, a_id);\n           do this.substs(&type_def.generics, a_substs, b_substs).chain |substs| {\n               Ok(ty::mk_enum(tcx, a_id, substs))\n           }\n       }\n \n-      (ty::ty_trait(a_id, ref a_substs, a_store, a_mutbl),\n-       ty::ty_trait(b_id, ref b_substs, b_store, b_mutbl))\n+      (&ty::ty_trait(a_id, ref a_substs, a_store, a_mutbl),\n+       &ty::ty_trait(b_id, ref b_substs, b_store, b_mutbl))\n       if a_id == b_id && a_mutbl == b_mutbl => {\n           let trait_def = ty::lookup_trait_def(tcx, a_id);\n           do this.substs(&trait_def.generics, a_substs, b_substs).chain |substs| {\n@@ -519,53 +519,53 @@ pub fn super_tys<C:Combine>(\n           }\n       }\n \n-      (ty::ty_struct(a_id, ref a_substs), ty::ty_struct(b_id, ref b_substs))\n+      (&ty::ty_struct(a_id, ref a_substs), &ty::ty_struct(b_id, ref b_substs))\n       if a_id == b_id => {\n           let type_def = ty::lookup_item_type(tcx, a_id);\n           do this.substs(&type_def.generics, a_substs, b_substs).chain |substs| {\n               Ok(ty::mk_struct(tcx, a_id, substs))\n           }\n       }\n \n-      (ty::ty_box(ref a_mt), ty::ty_box(ref b_mt)) => {\n+      (&ty::ty_box(ref a_mt), &ty::ty_box(ref b_mt)) => {\n         do this.mts(a_mt, b_mt).chain |mt| {\n             Ok(ty::mk_box(tcx, mt))\n         }\n       }\n \n-      (ty::ty_uniq(ref a_mt), ty::ty_uniq(ref b_mt)) => {\n+      (&ty::ty_uniq(ref a_mt), &ty::ty_uniq(ref b_mt)) => {\n         do this.mts(a_mt, b_mt).chain |mt| {\n             Ok(ty::mk_uniq(tcx, mt))\n         }\n       }\n \n-      (ty::ty_ptr(ref a_mt), ty::ty_ptr(ref b_mt)) => {\n+      (&ty::ty_ptr(ref a_mt), &ty::ty_ptr(ref b_mt)) => {\n         do this.mts(a_mt, b_mt).chain |mt| {\n             Ok(ty::mk_ptr(tcx, mt))\n         }\n       }\n \n-      (ty::ty_rptr(a_r, ref a_mt), ty::ty_rptr(b_r, ref b_mt)) => {\n+      (&ty::ty_rptr(a_r, ref a_mt), &ty::ty_rptr(b_r, ref b_mt)) => {\n           let r = if_ok!(this.contraregions(a_r, b_r));\n           let mt = if_ok!(this.mts(a_mt, b_mt));\n           Ok(ty::mk_rptr(tcx, r, mt))\n       }\n \n-      (ty::ty_evec(ref a_mt, vs_a), ty::ty_evec(ref b_mt, vs_b)) => {\n+      (&ty::ty_evec(ref a_mt, vs_a), &ty::ty_evec(ref b_mt, vs_b)) => {\n         do this.mts(a_mt, b_mt).chain |mt| {\n             do this.vstores(ty::terr_vec, vs_a, vs_b).chain |vs| {\n                 Ok(ty::mk_evec(tcx, mt, vs))\n             }\n         }\n       }\n \n-      (ty::ty_estr(vs_a), ty::ty_estr(vs_b)) => {\n+      (&ty::ty_estr(vs_a), &ty::ty_estr(vs_b)) => {\n         do this.vstores(ty::terr_str, vs_a, vs_b).chain |vs| {\n             Ok(ty::mk_estr(tcx,vs))\n         }\n       }\n \n-      (ty::ty_tup(ref as_), ty::ty_tup(ref bs)) => {\n+      (&ty::ty_tup(ref as_), &ty::ty_tup(ref bs)) => {\n         if as_.len() == bs.len() {\n             map_vec2(*as_, *bs, |a, b| this.tys(*a, *b) )\n                 .chain(|ts| Ok(ty::mk_tup(tcx, ts)) )\n@@ -575,13 +575,13 @@ pub fn super_tys<C:Combine>(\n         }\n       }\n \n-      (ty::ty_bare_fn(ref a_fty), ty::ty_bare_fn(ref b_fty)) => {\n+      (&ty::ty_bare_fn(ref a_fty), &ty::ty_bare_fn(ref b_fty)) => {\n         do this.bare_fn_tys(a_fty, b_fty).chain |fty| {\n             Ok(ty::mk_bare_fn(tcx, fty))\n         }\n       }\n \n-      (ty::ty_closure(ref a_fty), ty::ty_closure(ref b_fty)) => {\n+      (&ty::ty_closure(ref a_fty), &ty::ty_closure(ref b_fty)) => {\n         do this.closure_tys(a_fty, b_fty).chain |fty| {\n             Ok(ty::mk_closure(tcx, fty))\n         }"}, {"sha": "57df0fe6f86323b3b5d8574e15f5caa9733b00cd", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -13,7 +13,7 @@ use core::prelude::*;\n use ast;\n use codemap::{BytePos, CharPos, CodeMap, Pos};\n use diagnostic;\n-use parse::lexer::{is_whitespace, get_str_from, reader};\n+use parse::lexer::{is_whitespace, with_str_from, reader};\n use parse::lexer::{StringReader, bump, is_eof, nextch, TokenAndSpan};\n use parse::lexer::{is_line_non_doc_comment, is_block_non_doc_comment};\n use parse::lexer;\n@@ -352,9 +352,10 @@ pub fn gather_comments_and_literals(span_diagnostic:\n         //discard, and look ahead; we're working with internal state\n         let TokenAndSpan {tok: tok, sp: sp} = rdr.peek();\n         if token::is_lit(&tok) {\n-            let s = get_str_from(rdr, bstart);\n-            debug!(\"tok lit: %s\", s);\n-            literals.push(lit {lit: s, pos: sp.lo});\n+            do with_str_from(rdr, bstart) |s| {\n+                debug!(\"tok lit: %s\", s);\n+                literals.push(lit {lit: s.to_owned(), pos: sp.lo});\n+            }\n         } else {\n             debug!(\"tok: %s\", token::to_str(get_ident_interner(), &tok));\n         }"}, {"sha": "8ee0a976c8b9c5d29c89c78bf05714d01873b3e9", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 55, "deletions": 40, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=878a9b92ebe1d55c119d9c6ae4636c31ca6d6cd6", "patch": "@@ -165,9 +165,10 @@ fn byte_offset(rdr: &StringReader, pos: BytePos) -> BytePos {\n     (pos - rdr.filemap.start_pos)\n }\n \n-pub fn get_str_from(rdr: @mut StringReader, start: BytePos) -> ~str {\n-    return str::slice(*rdr.src, start.to_uint(),\n-                      byte_offset(rdr, rdr.last_pos).to_uint()).to_owned();\n+pub fn with_str_from<T>(rdr: @mut StringReader, start: BytePos, f: &fn(s: &str) -> T) -> T {\n+    f(rdr.src.slice(\n+            byte_offset(rdr, start).to_uint(),\n+            byte_offset(rdr, rdr.last_pos).to_uint()))\n }\n \n // EFFECT: advance the StringReader by one character. If a newline is\n@@ -259,18 +260,24 @@ fn consume_any_line_comment(rdr: @mut StringReader)\n             bump(rdr);\n             // line comments starting with \"///\" or \"//!\" are doc-comments\n             if rdr.curr == '/' || rdr.curr == '!' {\n-                let start_bpos = rdr.pos - BytePos(2u);\n-                let mut acc = ~\"//\";\n+                let start_bpos = rdr.pos - BytePos(3u);\n                 while rdr.curr != '\\n' && !is_eof(rdr) {\n-                    str::push_char(&mut acc, rdr.curr);\n                     bump(rdr);\n                 }\n-                // but comments with only more \"/\"s are not\n-                if !is_line_non_doc_comment(acc) {\n-                    return Some(TokenAndSpan{\n-                        tok: token::DOC_COMMENT(str_to_ident(acc)),\n-                        sp: codemap::mk_sp(start_bpos, rdr.pos)\n-                    });\n+                let ret = do with_str_from(rdr, start_bpos) |string| {\n+                    // but comments with only more \"/\"s are not\n+                    if !is_line_non_doc_comment(string) {\n+                        Some(TokenAndSpan{\n+                            tok: token::DOC_COMMENT(str_to_ident(string)),\n+                            sp: codemap::mk_sp(start_bpos, rdr.pos)\n+                        })\n+                    } else {\n+                        None\n+                    }\n+                };\n+\n+                if ret.is_some() {\n+                    return ret;\n                 }\n             } else {\n                 while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n@@ -306,25 +313,26 @@ pub fn is_block_non_doc_comment(s: &str) -> bool {\n fn consume_block_comment(rdr: @mut StringReader)\n                       -> Option<TokenAndSpan> {\n     // block comments starting with \"/**\" or \"/*!\" are doc-comments\n-    if rdr.curr == '*' || rdr.curr == '!' {\n-        let start_bpos = rdr.pos - BytePos(2u);\n-        let mut acc = ~\"/*\";\n+    let res = if rdr.curr == '*' || rdr.curr == '!' {\n+        let start_bpos = rdr.pos - BytePos(3u);\n         while !(rdr.curr == '*' && nextch(rdr) == '/') && !is_eof(rdr) {\n-            str::push_char(&mut acc, rdr.curr);\n             bump(rdr);\n         }\n         if is_eof(rdr) {\n             rdr.fatal(~\"unterminated block doc-comment\");\n         } else {\n-            acc += \"*/\";\n             bump(rdr);\n             bump(rdr);\n-            // but comments with only \"*\"s between two \"/\"s are not\n-            if !is_block_non_doc_comment(acc) {\n-                return Some(TokenAndSpan{\n-                    tok: token::DOC_COMMENT(str_to_ident(acc)),\n-                    sp: codemap::mk_sp(start_bpos, rdr.pos)\n-                });\n+            do with_str_from(rdr, start_bpos) |string| {\n+                // but comments with only \"*\"s between two \"/\"s are not\n+                if !is_block_non_doc_comment(string) {\n+                    Some(TokenAndSpan{\n+                         tok: token::DOC_COMMENT(str_to_ident(string)),\n+                         sp: codemap::mk_sp(start_bpos, rdr.pos)\n+                         })\n+                } else {\n+                    None\n+                }\n             }\n         }\n     } else {\n@@ -338,10 +346,11 @@ fn consume_block_comment(rdr: @mut StringReader)\n                 bump(rdr);\n             }\n         }\n-    }\n+        None\n+    };\n     // restart whitespace munch.\n \n-    return consume_whitespace_and_comments(rdr);\n+   if res.is_some() { res } else { consume_whitespace_and_comments(rdr) }\n }\n \n fn scan_exponent(rdr: @mut StringReader) -> Option<~str> {\n@@ -538,19 +547,23 @@ fn ident_continue(c: char) -> bool {\n // EFFECT: advances the input past that token\n // EFFECT: updates the interner\n fn next_token_inner(rdr: @mut StringReader) -> token::Token {\n-    let mut accum_str = ~\"\";\n     let mut c = rdr.curr;\n     if ident_start(c) {\n-        while ident_continue(c) {\n-            str::push_char(&mut accum_str, c);\n+        let start = rdr.last_pos;\n+        while ident_continue(rdr.curr) {\n             bump(rdr);\n-            c = rdr.curr;\n         }\n-        if accum_str == ~\"_\" { return token::UNDERSCORE; }\n-        let is_mod_name = c == ':' && nextch(rdr) == ':';\n \n-        // FIXME: perform NFKC normalization here. (Issue #2253)\n-        return token::IDENT(str_to_ident(accum_str), is_mod_name);\n+        return do with_str_from(rdr, start) |string| {\n+            if string == \"_\" {\n+                token::UNDERSCORE\n+            } else {\n+                let is_mod_name = rdr.curr == ':' && nextch(rdr) == ':';\n+\n+                // FIXME: perform NFKC normalization here. (Issue #2253)\n+                token::IDENT(str_to_ident(string), is_mod_name)\n+            }\n+        }\n     }\n     if is_dec_digit(c) {\n         return scan_number(c, rdr);\n@@ -648,19 +661,19 @@ fn next_token_inner(rdr: @mut StringReader) -> token::Token {\n       '\\'' => {\n         // Either a character constant 'a' OR a lifetime name 'abc\n         bump(rdr);\n+        let start = rdr.last_pos;\n         let mut c2 = rdr.curr;\n         bump(rdr);\n \n         // If the character is an ident start not followed by another single\n         // quote, then this is a lifetime name:\n         if ident_start(c2) && rdr.curr != '\\'' {\n-            let mut lifetime_name = ~\"\";\n-            lifetime_name.push_char(c2);\n             while ident_continue(rdr.curr) {\n-                lifetime_name.push_char(rdr.curr);\n                 bump(rdr);\n             }\n-            return token::LIFETIME(str_to_ident(lifetime_name));\n+            return do with_str_from(rdr, start) |lifetime_name| {\n+                token::LIFETIME(str_to_ident(lifetime_name))\n+            }\n         }\n \n         // Otherwise it is a character constant:\n@@ -690,12 +703,14 @@ fn next_token_inner(rdr: @mut StringReader) -> token::Token {\n         return token::LIT_INT(c2 as i64, ast::ty_char);\n       }\n       '\"' => {\n-        let n = byte_offset(rdr, rdr.last_pos);\n+        let mut accum_str = ~\"\";\n+        let n = rdr.last_pos;\n         bump(rdr);\n         while rdr.curr != '\"' {\n             if is_eof(rdr) {\n-                rdr.fatal(fmt!(\"unterminated double quote string: %s\",\n-                               get_str_from(rdr, n)));\n+                do with_str_from(rdr, n) |s| {\n+                    rdr.fatal(fmt!(\"unterminated double quote string: %s\", s));\n+                }\n             }\n \n             let ch = rdr.curr;"}]}