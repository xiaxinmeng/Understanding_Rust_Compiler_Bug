{"sha": "c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90", "node_id": "MDY6Q29tbWl0NzI0NzEyOmMxNThkMWNhMGM5Y2Y4YzdjYWFiN2I1ZDFkNTJmYmY5NzBjZTljOTA=", "commit": {"author": {"name": "Tyler Mandry", "email": "tmandry@gmail.com", "date": "2019-06-01T04:30:08Z"}, "committer": {"name": "Tyler Mandry", "email": "tmandry@gmail.com", "date": "2019-06-10T21:48:58Z"}, "message": "Extract univariant_uninterned as method", "tree": {"sha": "bc48805de3a1d895b9504eff5c093f2e8da476c6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bc48805de3a1d895b9504eff5c093f2e8da476c6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90", "html_url": "https://github.com/rust-lang/rust/commit/c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90/comments", "author": {"login": "tmandry", "id": 2280544, "node_id": "MDQ6VXNlcjIyODA1NDQ=", "avatar_url": "https://avatars.githubusercontent.com/u/2280544?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmandry", "html_url": "https://github.com/tmandry", "followers_url": "https://api.github.com/users/tmandry/followers", "following_url": "https://api.github.com/users/tmandry/following{/other_user}", "gists_url": "https://api.github.com/users/tmandry/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmandry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmandry/subscriptions", "organizations_url": "https://api.github.com/users/tmandry/orgs", "repos_url": "https://api.github.com/users/tmandry/repos", "events_url": "https://api.github.com/users/tmandry/events{/privacy}", "received_events_url": "https://api.github.com/users/tmandry/received_events", "type": "User", "site_admin": false}, "committer": {"login": "tmandry", "id": 2280544, "node_id": "MDQ6VXNlcjIyODA1NDQ=", "avatar_url": "https://avatars.githubusercontent.com/u/2280544?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmandry", "html_url": "https://github.com/tmandry", "followers_url": "https://api.github.com/users/tmandry/followers", "following_url": "https://api.github.com/users/tmandry/following{/other_user}", "gists_url": "https://api.github.com/users/tmandry/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmandry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmandry/subscriptions", "organizations_url": "https://api.github.com/users/tmandry/orgs", "repos_url": "https://api.github.com/users/tmandry/repos", "events_url": "https://api.github.com/users/tmandry/events{/privacy}", "received_events_url": "https://api.github.com/users/tmandry/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fbdff56f4ba2383c9d4bea58531dea66f5b2afa6", "url": "https://api.github.com/repos/rust-lang/rust/commits/fbdff56f4ba2383c9d4bea58531dea66f5b2afa6", "html_url": "https://github.com/rust-lang/rust/commit/fbdff56f4ba2383c9d4bea58531dea66f5b2afa6"}], "stats": {"total": 458, "additions": 234, "deletions": 224}, "files": [{"sha": "d3caedb50ae2cfb06353a6c1bef22b9144412053", "filename": "src/librustc/ty/layout.rs", "status": "modified", "additions": 234, "deletions": 224, "changes": 458, "blob_url": "https://github.com/rust-lang/rust/blob/c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90/src%2Flibrustc%2Fty%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90/src%2Flibrustc%2Fty%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Flayout.rs?ref=c158d1ca0c9cf8c7caab7b5d1d52fbf970ce9c90", "patch": "@@ -215,260 +215,268 @@ pub struct LayoutCx<'tcx, C> {\n     pub param_env: ty::ParamEnv<'tcx>,\n }\n \n+#[derive(Copy, Clone, Debug)]\n+enum StructKind {\n+    /// A tuple, closure, or univariant which cannot be coerced to unsized.\n+    AlwaysSized,\n+    /// A univariant, the last field of which may be coerced to unsized.\n+    MaybeUnsized,\n+    /// A univariant, but with a prefix of an arbitrary size & alignment (e.g., enum tag).\n+    Prefixed(Size, Align),\n+}\n+\n impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n-    fn layout_raw_uncached(&self, ty: Ty<'tcx>) -> Result<&'tcx LayoutDetails, LayoutError<'tcx>> {\n-        let tcx = self.tcx;\n-        let param_env = self.param_env;\n+    fn scalar_pair(&self, a: Scalar, b: Scalar) -> LayoutDetails {\n         let dl = self.data_layout();\n-        let scalar_unit = |value: Primitive| {\n-            let bits = value.size(dl).bits();\n-            assert!(bits <= 128);\n-            Scalar {\n-                value,\n-                valid_range: 0..=(!0 >> (128 - bits))\n-            }\n-        };\n-        let scalar = |value: Primitive| {\n-            tcx.intern_layout(LayoutDetails::scalar(self, scalar_unit(value)))\n-        };\n-        let scalar_pair = |a: Scalar, b: Scalar| {\n-            let b_align = b.value.align(dl);\n-            let align = a.value.align(dl).max(b_align).max(dl.aggregate_align);\n-            let b_offset = a.value.size(dl).align_to(b_align.abi);\n-            let size = (b_offset + b.value.size(dl)).align_to(align.abi);\n-            LayoutDetails {\n-                variants: Variants::Single { index: VariantIdx::new(0) },\n-                fields: FieldPlacement::Arbitrary {\n-                    offsets: vec![Size::ZERO, b_offset],\n-                    memory_index: vec![0, 1]\n-                },\n-                abi: Abi::ScalarPair(a, b),\n-                align,\n-                size\n-            }\n-        };\n-\n-        #[derive(Copy, Clone, Debug)]\n-        enum StructKind {\n-            /// A tuple, closure, or univariant which cannot be coerced to unsized.\n-            AlwaysSized,\n-            /// A univariant, the last field of which may be coerced to unsized.\n-            MaybeUnsized,\n-            /// A univariant, but with a prefix of an arbitrary size & alignment (e.g., enum tag).\n-            Prefixed(Size, Align),\n+        let b_align = b.value.align(dl);\n+        let align = a.value.align(dl).max(b_align).max(dl.aggregate_align);\n+        let b_offset = a.value.size(dl).align_to(b_align.abi);\n+        let size = (b_offset + b.value.size(dl)).align_to(align.abi);\n+        LayoutDetails {\n+            variants: Variants::Single { index: VariantIdx::new(0) },\n+            fields: FieldPlacement::Arbitrary {\n+                offsets: vec![Size::ZERO, b_offset],\n+                memory_index: vec![0, 1]\n+            },\n+            abi: Abi::ScalarPair(a, b),\n+            align,\n+            size\n         }\n+    }\n \n-        let univariant_uninterned = |fields: &[TyLayout<'_>], repr: &ReprOptions, kind| {\n-            let packed = repr.packed();\n-            if packed && repr.align > 0 {\n-                bug!(\"struct cannot be packed and aligned\");\n-            }\n+    fn univariant_uninterned(&self,\n+                             ty: Ty<'tcx>,\n+                             fields: &[TyLayout<'_>],\n+                             repr: &ReprOptions,\n+                             kind: StructKind) -> Result<LayoutDetails, LayoutError<'tcx>> {\n+        let dl = self.data_layout();\n+        let packed = repr.packed();\n+        if packed && repr.align > 0 {\n+            bug!(\"struct cannot be packed and aligned\");\n+        }\n \n-            let pack = Align::from_bytes(repr.pack as u64).unwrap();\n+        let pack = Align::from_bytes(repr.pack as u64).unwrap();\n \n-            let mut align = if packed {\n-                dl.i8_align\n-            } else {\n-                dl.aggregate_align\n-            };\n+        let mut align = if packed {\n+            dl.i8_align\n+        } else {\n+            dl.aggregate_align\n+        };\n \n-            let mut sized = true;\n-            let mut offsets = vec![Size::ZERO; fields.len()];\n-            let mut inverse_memory_index: Vec<u32> = (0..fields.len() as u32).collect();\n+        let mut sized = true;\n+        let mut offsets = vec![Size::ZERO; fields.len()];\n+        let mut inverse_memory_index: Vec<u32> = (0..fields.len() as u32).collect();\n \n-            let mut optimize = !repr.inhibit_struct_field_reordering_opt();\n-            if let StructKind::Prefixed(_, align) = kind {\n-                optimize &= align.bytes() == 1;\n-            }\n+        let mut optimize = !repr.inhibit_struct_field_reordering_opt();\n+        if let StructKind::Prefixed(_, align) = kind {\n+            optimize &= align.bytes() == 1;\n+        }\n \n-            if optimize {\n-                let end = if let StructKind::MaybeUnsized = kind {\n-                    fields.len() - 1\n-                } else {\n-                    fields.len()\n-                };\n-                let optimizing = &mut inverse_memory_index[..end];\n-                let field_align = |f: &TyLayout<'_>| {\n-                    if packed { f.align.abi.min(pack) } else { f.align.abi }\n-                };\n-                match kind {\n-                    StructKind::AlwaysSized |\n-                    StructKind::MaybeUnsized => {\n-                        optimizing.sort_by_key(|&x| {\n-                            // Place ZSTs first to avoid \"interesting offsets\",\n-                            // especially with only one or two non-ZST fields.\n-                            let f = &fields[x as usize];\n-                            (!f.is_zst(), cmp::Reverse(field_align(f)))\n-                        });\n-                    }\n-                    StructKind::Prefixed(..) => {\n-                        optimizing.sort_by_key(|&x| field_align(&fields[x as usize]));\n-                    }\n+        if optimize {\n+            let end = if let StructKind::MaybeUnsized = kind {\n+                fields.len() - 1\n+            } else {\n+                fields.len()\n+            };\n+            let optimizing = &mut inverse_memory_index[..end];\n+            let field_align = |f: &TyLayout<'_>| {\n+                if packed { f.align.abi.min(pack) } else { f.align.abi }\n+            };\n+            match kind {\n+                StructKind::AlwaysSized |\n+                StructKind::MaybeUnsized => {\n+                    optimizing.sort_by_key(|&x| {\n+                        // Place ZSTs first to avoid \"interesting offsets\",\n+                        // especially with only one or two non-ZST fields.\n+                        let f = &fields[x as usize];\n+                        (!f.is_zst(), cmp::Reverse(field_align(f)))\n+                    });\n+                }\n+                StructKind::Prefixed(..) => {\n+                    optimizing.sort_by_key(|&x| field_align(&fields[x as usize]));\n                 }\n             }\n+        }\n \n-            // inverse_memory_index holds field indices by increasing memory offset.\n-            // That is, if field 5 has offset 0, the first element of inverse_memory_index is 5.\n-            // We now write field offsets to the corresponding offset slot;\n-            // field 5 with offset 0 puts 0 in offsets[5].\n-            // At the bottom of this function, we use inverse_memory_index to produce memory_index.\n+        // inverse_memory_index holds field indices by increasing memory offset.\n+        // That is, if field 5 has offset 0, the first element of inverse_memory_index is 5.\n+        // We now write field offsets to the corresponding offset slot;\n+        // field 5 with offset 0 puts 0 in offsets[5].\n+        // At the bottom of this function, we use inverse_memory_index to produce memory_index.\n \n-            let mut offset = Size::ZERO;\n+        let mut offset = Size::ZERO;\n \n-            if let StructKind::Prefixed(prefix_size, prefix_align) = kind {\n-                let prefix_align = if packed {\n-                    prefix_align.min(pack)\n-                } else {\n-                    prefix_align\n-                };\n-                align = align.max(AbiAndPrefAlign::new(prefix_align));\n-                offset = prefix_size.align_to(prefix_align);\n+        if let StructKind::Prefixed(prefix_size, prefix_align) = kind {\n+            let prefix_align = if packed {\n+                prefix_align.min(pack)\n+            } else {\n+                prefix_align\n+            };\n+            align = align.max(AbiAndPrefAlign::new(prefix_align));\n+            offset = prefix_size.align_to(prefix_align);\n+        }\n+\n+        for &i in &inverse_memory_index {\n+            let field = fields[i as usize];\n+            if !sized {\n+                bug!(\"univariant: field #{} of `{}` comes after unsized field\",\n+                     offsets.len(), ty);\n             }\n \n-            for &i in &inverse_memory_index {\n-                let field = fields[i as usize];\n-                if !sized {\n-                    bug!(\"univariant: field #{} of `{}` comes after unsized field\",\n-                         offsets.len(), ty);\n-                }\n+            if field.is_unsized() {\n+                sized = false;\n+            }\n \n-                if field.is_unsized() {\n-                    sized = false;\n-                }\n+            // Invariant: offset < dl.obj_size_bound() <= 1<<61\n+            let field_align = if packed {\n+                field.align.min(AbiAndPrefAlign::new(pack))\n+            } else {\n+                field.align\n+            };\n+            offset = offset.align_to(field_align.abi);\n+            align = align.max(field_align);\n \n-                // Invariant: offset < dl.obj_size_bound() <= 1<<61\n-                let field_align = if packed {\n-                    field.align.min(AbiAndPrefAlign::new(pack))\n-                } else {\n-                    field.align\n-                };\n-                offset = offset.align_to(field_align.abi);\n-                align = align.max(field_align);\n+            debug!(\"univariant offset: {:?} field: {:#?}\", offset, field);\n+            offsets[i as usize] = offset;\n \n-                debug!(\"univariant offset: {:?} field: {:#?}\", offset, field);\n-                offsets[i as usize] = offset;\n+            offset = offset.checked_add(field.size, dl)\n+                .ok_or(LayoutError::SizeOverflow(ty))?;\n+        }\n \n-                offset = offset.checked_add(field.size, dl)\n-                    .ok_or(LayoutError::SizeOverflow(ty))?;\n-            }\n+        if repr.align > 0 {\n+            let repr_align = repr.align as u64;\n+            align = align.max(AbiAndPrefAlign::new(Align::from_bytes(repr_align).unwrap()));\n+            debug!(\"univariant repr_align: {:?}\", repr_align);\n+        }\n \n-            if repr.align > 0 {\n-                let repr_align = repr.align as u64;\n-                align = align.max(AbiAndPrefAlign::new(Align::from_bytes(repr_align).unwrap()));\n-                debug!(\"univariant repr_align: {:?}\", repr_align);\n-            }\n+        debug!(\"univariant min_size: {:?}\", offset);\n+        let min_size = offset;\n \n-            debug!(\"univariant min_size: {:?}\", offset);\n-            let min_size = offset;\n+        // As stated above, inverse_memory_index holds field indices by increasing offset.\n+        // This makes it an already-sorted view of the offsets vec.\n+        // To invert it, consider:\n+        // If field 5 has offset 0, offsets[0] is 5, and memory_index[5] should be 0.\n+        // Field 5 would be the first element, so memory_index is i:\n+        // Note: if we didn't optimize, it's already right.\n \n-            // As stated above, inverse_memory_index holds field indices by increasing offset.\n-            // This makes it an already-sorted view of the offsets vec.\n-            // To invert it, consider:\n-            // If field 5 has offset 0, offsets[0] is 5, and memory_index[5] should be 0.\n-            // Field 5 would be the first element, so memory_index is i:\n-            // Note: if we didn't optimize, it's already right.\n+        let mut memory_index;\n+        if optimize {\n+            memory_index = vec![0; inverse_memory_index.len()];\n \n-            let mut memory_index;\n-            if optimize {\n-                memory_index = vec![0; inverse_memory_index.len()];\n+            for i in 0..inverse_memory_index.len() {\n+                memory_index[inverse_memory_index[i] as usize]  = i as u32;\n+            }\n+        } else {\n+            memory_index = inverse_memory_index;\n+        }\n \n-                for i in 0..inverse_memory_index.len() {\n-                    memory_index[inverse_memory_index[i] as usize]  = i as u32;\n-                }\n-            } else {\n-                memory_index = inverse_memory_index;\n-            }\n-\n-            let size = min_size.align_to(align.abi);\n-            let mut abi = Abi::Aggregate { sized };\n-\n-            // Unpack newtype ABIs and find scalar pairs.\n-            if sized && size.bytes() > 0 {\n-                // All other fields must be ZSTs, and we need them to all start at 0.\n-                let mut zst_offsets =\n-                    offsets.iter().enumerate().filter(|&(i, _)| fields[i].is_zst());\n-                if zst_offsets.all(|(_, o)| o.bytes() == 0) {\n-                    let mut non_zst_fields =\n-                        fields.iter().enumerate().filter(|&(_, f)| !f.is_zst());\n-\n-                    match (non_zst_fields.next(), non_zst_fields.next(), non_zst_fields.next()) {\n-                        // We have exactly one non-ZST field.\n-                        (Some((i, field)), None, None) => {\n-                            // Field fills the struct and it has a scalar or scalar pair ABI.\n-                            if offsets[i].bytes() == 0 &&\n-                               align.abi == field.align.abi &&\n-                               size == field.size {\n-                                match field.abi {\n-                                    // For plain scalars, or vectors of them, we can't unpack\n-                                    // newtypes for `#[repr(C)]`, as that affects C ABIs.\n-                                    Abi::Scalar(_) | Abi::Vector { .. } if optimize => {\n-                                        abi = field.abi.clone();\n-                                    }\n-                                    // But scalar pairs are Rust-specific and get\n-                                    // treated as aggregates by C ABIs anyway.\n-                                    Abi::ScalarPair(..) => {\n-                                        abi = field.abi.clone();\n-                                    }\n-                                    _ => {}\n+        let size = min_size.align_to(align.abi);\n+        let mut abi = Abi::Aggregate { sized };\n+\n+        // Unpack newtype ABIs and find scalar pairs.\n+        if sized && size.bytes() > 0 {\n+            // All other fields must be ZSTs, and we need them to all start at 0.\n+            let mut zst_offsets =\n+                offsets.iter().enumerate().filter(|&(i, _)| fields[i].is_zst());\n+            if zst_offsets.all(|(_, o)| o.bytes() == 0) {\n+                let mut non_zst_fields =\n+                    fields.iter().enumerate().filter(|&(_, f)| !f.is_zst());\n+\n+                match (non_zst_fields.next(), non_zst_fields.next(), non_zst_fields.next()) {\n+                    // We have exactly one non-ZST field.\n+                    (Some((i, field)), None, None) => {\n+                        // Field fills the struct and it has a scalar or scalar pair ABI.\n+                        if offsets[i].bytes() == 0 &&\n+                           align.abi == field.align.abi &&\n+                           size == field.size {\n+                            match field.abi {\n+                                // For plain scalars, or vectors of them, we can't unpack\n+                                // newtypes for `#[repr(C)]`, as that affects C ABIs.\n+                                Abi::Scalar(_) | Abi::Vector { .. } if optimize => {\n+                                    abi = field.abi.clone();\n+                                }\n+                                // But scalar pairs are Rust-specific and get\n+                                // treated as aggregates by C ABIs anyway.\n+                                Abi::ScalarPair(..) => {\n+                                    abi = field.abi.clone();\n                                 }\n+                                _ => {}\n                             }\n                         }\n+                    }\n \n-                        // Two non-ZST fields, and they're both scalars.\n-                        (Some((i, &TyLayout {\n-                            details: &LayoutDetails { abi: Abi::Scalar(ref a), .. }, ..\n-                        })), Some((j, &TyLayout {\n-                            details: &LayoutDetails { abi: Abi::Scalar(ref b), .. }, ..\n-                        })), None) => {\n-                            // Order by the memory placement, not source order.\n-                            let ((i, a), (j, b)) = if offsets[i] < offsets[j] {\n-                                ((i, a), (j, b))\n-                            } else {\n-                                ((j, b), (i, a))\n-                            };\n-                            let pair = scalar_pair(a.clone(), b.clone());\n-                            let pair_offsets = match pair.fields {\n-                                FieldPlacement::Arbitrary {\n-                                    ref offsets,\n-                                    ref memory_index\n-                                } => {\n-                                    assert_eq!(memory_index, &[0, 1]);\n-                                    offsets\n-                                }\n-                                _ => bug!()\n-                            };\n-                            if offsets[i] == pair_offsets[0] &&\n-                               offsets[j] == pair_offsets[1] &&\n-                               align == pair.align &&\n-                               size == pair.size {\n-                                // We can use `ScalarPair` only when it matches our\n-                                // already computed layout (including `#[repr(C)]`).\n-                                abi = pair.abi;\n+                    // Two non-ZST fields, and they're both scalars.\n+                    (Some((i, &TyLayout {\n+                        details: &LayoutDetails { abi: Abi::Scalar(ref a), .. }, ..\n+                    })), Some((j, &TyLayout {\n+                        details: &LayoutDetails { abi: Abi::Scalar(ref b), .. }, ..\n+                    })), None) => {\n+                        // Order by the memory placement, not source order.\n+                        let ((i, a), (j, b)) = if offsets[i] < offsets[j] {\n+                            ((i, a), (j, b))\n+                        } else {\n+                            ((j, b), (i, a))\n+                        };\n+                        let pair = self.scalar_pair(a.clone(), b.clone());\n+                        let pair_offsets = match pair.fields {\n+                            FieldPlacement::Arbitrary {\n+                                ref offsets,\n+                                ref memory_index\n+                            } => {\n+                                assert_eq!(memory_index, &[0, 1]);\n+                                offsets\n                             }\n+                            _ => bug!()\n+                        };\n+                        if offsets[i] == pair_offsets[0] &&\n+                           offsets[j] == pair_offsets[1] &&\n+                           align == pair.align &&\n+                           size == pair.size {\n+                            // We can use `ScalarPair` only when it matches our\n+                            // already computed layout (including `#[repr(C)]`).\n+                            abi = pair.abi;\n                         }\n-\n-                        _ => {}\n                     }\n+\n+                    _ => {}\n                 }\n             }\n+        }\n \n-            if sized && fields.iter().any(|f| f.abi.is_uninhabited()) {\n-                abi = Abi::Uninhabited;\n-            }\n+        if sized && fields.iter().any(|f| f.abi.is_uninhabited()) {\n+            abi = Abi::Uninhabited;\n+        }\n \n-            Ok(LayoutDetails {\n-                variants: Variants::Single { index: VariantIdx::new(0) },\n-                fields: FieldPlacement::Arbitrary {\n-                    offsets,\n-                    memory_index\n-                },\n-                abi,\n-                align,\n-                size\n-            })\n+        Ok(LayoutDetails {\n+            variants: Variants::Single { index: VariantIdx::new(0) },\n+            fields: FieldPlacement::Arbitrary {\n+                offsets,\n+                memory_index\n+            },\n+            abi,\n+            align,\n+            size\n+        })\n+    }\n+\n+    fn layout_raw_uncached(&self, ty: Ty<'tcx>) -> Result<&'tcx LayoutDetails, LayoutError<'tcx>> {\n+        let tcx = self.tcx;\n+        let param_env = self.param_env;\n+        let dl = self.data_layout();\n+        let scalar_unit = |value: Primitive| {\n+            let bits = value.size(dl).bits();\n+            assert!(bits <= 128);\n+            Scalar {\n+                value,\n+                valid_range: 0..=(!0 >> (128 - bits))\n+            }\n         };\n+        let scalar = |value: Primitive| {\n+            tcx.intern_layout(LayoutDetails::scalar(self, scalar_unit(value)))\n+        };\n+\n         let univariant = |fields: &[TyLayout<'_>], repr: &ReprOptions, kind| {\n-            Ok(tcx.intern_layout(univariant_uninterned(fields, repr, kind)?))\n+            Ok(tcx.intern_layout(self.univariant_uninterned(ty, fields, repr, kind)?))\n         };\n         debug_assert!(!ty.has_infer_types());\n \n@@ -540,7 +548,7 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n                 };\n \n                 // Effectively a (ptr, meta) tuple.\n-                tcx.intern_layout(scalar_pair(data_ptr, metadata))\n+                tcx.intern_layout(self.scalar_pair(data_ptr, metadata))\n             }\n \n             // Arrays and slices.\n@@ -605,7 +613,7 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n                 univariant(&[], &ReprOptions::default(), StructKind::AlwaysSized)?\n             }\n             ty::Dynamic(..) | ty::Foreign(..) => {\n-                let mut unit = univariant_uninterned(&[], &ReprOptions::default(),\n+                let mut unit = self.univariant_uninterned(ty, &[], &ReprOptions::default(),\n                   StructKind::AlwaysSized)?;\n                 match unit.abi {\n                     Abi::Aggregate { ref mut sized } => *sized = false,\n@@ -730,7 +738,8 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n                 let prefix_tys = substs.prefix_tys(def_id, tcx)\n                     .chain(iter::once(substs.discr_ty(tcx)))\n                     .chain(promoted_tys);\n-                let prefix = univariant_uninterned(\n+                let prefix = self.univariant_uninterned(\n+                    ty,\n                     &prefix_tys.map(|ty| self.layout_of(ty)).collect::<Result<Vec<_>, _>>()?,\n                     &ReprOptions::default(),\n                     StructKind::AlwaysSized)?;\n@@ -787,7 +796,8 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n                         })\n                         .map(|local| subst_field(info.field_tys[*local]));\n \n-                    let mut variant = univariant_uninterned(\n+                    let mut variant = self.univariant_uninterned(\n+                        ty,\n                         &variant_only_tys\n                             .map(|ty| self.layout_of(ty))\n                             .collect::<Result<Vec<_>, _>>()?,\n@@ -1049,7 +1059,7 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n                         else { StructKind::AlwaysSized }\n                     };\n \n-                    let mut st = univariant_uninterned(&variants[v], &def.repr, kind)?;\n+                    let mut st = self.univariant_uninterned(ty, &variants[v], &def.repr, kind)?;\n                     st.variants = Variants::Single { index: v };\n                     let (start, end) = self.tcx.layout_scalar_valid_range(def.did);\n                     match st.abi {\n@@ -1128,7 +1138,7 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n \n                             let mut align = dl.aggregate_align;\n                             let st = variants.iter_enumerated().map(|(j, v)| {\n-                                let mut st = univariant_uninterned(v,\n+                                let mut st = self.univariant_uninterned(ty, v,\n                                     &def.repr, StructKind::AlwaysSized)?;\n                                 st.variants = Variants::Single { index: j };\n \n@@ -1236,7 +1246,7 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n \n                 // Create the set of structs that represent each variant.\n                 let mut layout_variants = variants.iter_enumerated().map(|(i, field_layouts)| {\n-                    let mut st = univariant_uninterned(&field_layouts,\n+                    let mut st = self.univariant_uninterned(ty, &field_layouts,\n                         &def.repr, StructKind::Prefixed(min_ity.size(), prefix_align))?;\n                     st.variants = Variants::Single { index: i };\n                     // Find the first field we can't move later\n@@ -1368,7 +1378,7 @@ impl<'a, 'tcx> LayoutCx<'tcx, TyCtxt<'a, 'tcx, 'tcx>> {\n                         }\n                     }\n                     if let Some((prim, offset)) = common_prim {\n-                        let pair = scalar_pair(tag.clone(), scalar_unit(prim));\n+                        let pair = self.scalar_pair(tag.clone(), scalar_unit(prim));\n                         let pair_offsets = match pair.fields {\n                             FieldPlacement::Arbitrary {\n                                 ref offsets,"}]}