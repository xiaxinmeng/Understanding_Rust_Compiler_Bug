{"sha": "d833ded3b4a12280f3e63e182ca7268a17cff90d", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ4MzNkZWQzYjRhMTIyODBmM2U2M2UxODJjYTcyNjhhMTdjZmY5MGQ=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-05-27T14:56:21Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-05-27T15:20:43Z"}, "message": "Remove Queier and SubtreeWalk", "tree": {"sha": "2e9fb66389163fa1924f0e5e8819fda968eee032", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2e9fb66389163fa1924f0e5e8819fda968eee032"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d833ded3b4a12280f3e63e182ca7268a17cff90d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d833ded3b4a12280f3e63e182ca7268a17cff90d", "html_url": "https://github.com/rust-lang/rust/commit/d833ded3b4a12280f3e63e182ca7268a17cff90d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d833ded3b4a12280f3e63e182ca7268a17cff90d/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0d1c6076073c73f57340e256dc25da9d37311ef0", "url": "https://api.github.com/repos/rust-lang/rust/commits/0d1c6076073c73f57340e256dc25da9d37311ef0", "html_url": "https://github.com/rust-lang/rust/commit/0d1c6076073c73f57340e256dc25da9d37311ef0"}], "stats": {"total": 196, "additions": 104, "deletions": 92}, "files": [{"sha": "2ba0b16019a1ff372ac8e06e5cf8b624f0fee8a8", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "modified", "additions": 34, "deletions": 52, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/d833ded3b4a12280f3e63e182ca7268a17cff90d/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d833ded3b4a12280f3e63e182ca7268a17cff90d/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=d833ded3b4a12280f3e63e182ca7268a17cff90d", "patch": "@@ -1,34 +1,56 @@\n use ra_parser::{TokenSource, Token};\n use ra_syntax::{classify_literal, SmolStr, SyntaxKind, SyntaxKind::*, T};\n use std::cell::{RefCell, Cell};\n-use std::sync::Arc;\n use tt::buffer::{TokenBuffer, Cursor};\n \n-pub(crate) trait Querier {\n-    fn token(&self, uidx: usize) -> (SyntaxKind, SmolStr, bool);\n-}\n-\n #[derive(Debug, Clone, Eq, PartialEq)]\n struct TtToken {\n     pub kind: SyntaxKind,\n     pub is_joint_to_next: bool,\n     pub text: SmolStr,\n }\n \n-// A wrapper class for ref cell\n-#[derive(Debug)]\n-pub(crate) struct SubtreeWalk<'a> {\n+pub(crate) struct SubtreeTokenSource<'a> {\n     start: Cursor<'a>,\n     cursor: Cell<Cursor<'a>>,\n     cached: RefCell<Vec<Option<TtToken>>>,\n+    curr: (Token, usize),\n+}\n+\n+impl<'a> SubtreeTokenSource<'a> {\n+    // Helper function used in test\n+    #[allow(unused)]\n+    pub fn text(&self) -> SmolStr {\n+        match self.get(self.curr.1) {\n+            Some(tt) => tt.text,\n+            _ => SmolStr::new(\"\"),\n+        }\n+    }\n }\n \n-impl<'a> SubtreeWalk<'a> {\n-    fn new(cursor: Cursor<'a>) -> Self {\n-        SubtreeWalk {\n+impl<'a> SubtreeTokenSource<'a> {\n+    pub fn new(buffer: &'a TokenBuffer) -> SubtreeTokenSource<'a> {\n+        let cursor = buffer.begin();\n+\n+        let mut res = SubtreeTokenSource {\n+            curr: (Token { kind: EOF, is_jointed_to_next: false }, 0),\n             start: cursor,\n             cursor: Cell::new(cursor),\n             cached: RefCell::new(Vec::with_capacity(10)),\n+        };\n+        res.curr = (res.mk_token(0), 0);\n+        res\n+    }\n+\n+    pub(crate) fn bump_n(&mut self, parsed_tokens: usize) -> Vec<tt::TokenTree> {\n+        let res = self.collect_token_trees(parsed_tokens);\n+        res\n+    }\n+\n+    fn mk_token(&self, pos: usize) -> Token {\n+        match self.get(pos) {\n+            Some(tt) => Token { kind: tt.kind, is_jointed_to_next: tt.is_joint_to_next },\n+            None => Token { kind: EOF, is_jointed_to_next: false },\n         }\n     }\n \n@@ -109,46 +131,6 @@ impl<'a> SubtreeWalk<'a> {\n     }\n }\n \n-impl<'a> Querier for SubtreeWalk<'a> {\n-    fn token(&self, uidx: usize) -> (SyntaxKind, SmolStr, bool) {\n-        self.get(uidx)\n-            .map(|tkn| (tkn.kind, tkn.text, tkn.is_joint_to_next))\n-            .unwrap_or_else(|| (SyntaxKind::EOF, \"\".into(), false))\n-    }\n-}\n-\n-pub(crate) struct SubtreeTokenSource<'a> {\n-    walker: Arc<SubtreeWalk<'a>>,\n-    curr: (Token, usize),\n-}\n-\n-impl<'a> SubtreeTokenSource<'a> {\n-    pub fn new(buffer: &'a TokenBuffer) -> SubtreeTokenSource<'a> {\n-        let mut res = SubtreeTokenSource {\n-            walker: Arc::new(SubtreeWalk::new(buffer.begin())),\n-            curr: (Token { kind: EOF, is_jointed_to_next: false }, 0),\n-        };\n-        res.curr = (res.mk_token(0), 0);\n-        res\n-    }\n-\n-    pub fn querier(&self) -> Arc<SubtreeWalk<'a>> {\n-        self.walker.clone()\n-    }\n-\n-    pub(crate) fn bump_n(&mut self, parsed_tokens: usize) -> Vec<tt::TokenTree> {\n-        let res = self.walker.collect_token_trees(parsed_tokens);\n-        res\n-    }\n-\n-    fn mk_token(&self, pos: usize) -> Token {\n-        match self.walker.get(pos) {\n-            Some(tt) => Token { kind: tt.kind, is_jointed_to_next: tt.is_joint_to_next },\n-            None => Token { kind: EOF, is_jointed_to_next: false },\n-        }\n-    }\n-}\n-\n impl<'a> TokenSource for SubtreeTokenSource<'a> {\n     fn current(&self) -> Token {\n         self.curr.0\n@@ -170,7 +152,7 @@ impl<'a> TokenSource for SubtreeTokenSource<'a> {\n \n     /// Is the current token a specified keyword?\n     fn is_keyword(&self, kw: &str) -> bool {\n-        match self.walker.get(self.curr.1) {\n+        match self.get(self.curr.1) {\n             Some(t) => t.text == *kw,\n             _ => false,\n         }"}, {"sha": "058f65ffdfc2447f863761ec74c4bdf4a74295cd", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 70, "deletions": 40, "changes": 110, "blob_url": "https://github.com/rust-lang/rust/blob/d833ded3b4a12280f3e63e182ca7268a17cff90d/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d833ded3b4a12280f3e63e182ca7268a17cff90d/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=d833ded3b4a12280f3e63e182ca7268a17cff90d", "patch": "@@ -3,8 +3,9 @@ use ra_syntax::{\n     AstNode, SyntaxNode, TextRange, SyntaxKind, SmolStr, SyntaxTreeBuilder, TreeArc, SyntaxElement,\n     ast, SyntaxKind::*, TextUnit, T\n };\n+use tt::buffer::Cursor;\n \n-use crate::subtree_source::{SubtreeTokenSource, Querier};\n+use crate::subtree_source::{SubtreeTokenSource};\n use crate::ExpandError;\n \n /// Maps `tt::TokenId` to the relative range of the original token.\n@@ -51,8 +52,7 @@ where\n {\n     let buffer = tt::buffer::TokenBuffer::new(&[tt.clone().into()]);\n     let mut token_source = SubtreeTokenSource::new(&buffer);\n-    let querier = token_source.querier();\n-    let mut tree_sink = TtTreeSink::new(querier.as_ref());\n+    let mut tree_sink = TtTreeSink::new(buffer.begin());\n     f(&mut token_source, &mut tree_sink);\n     if tree_sink.roots.len() != 1 {\n         return Err(ExpandError::ConversionError);\n@@ -259,64 +259,90 @@ fn convert_tt(\n     Some(res)\n }\n \n-struct TtTreeSink<'a, Q: Querier> {\n+struct TtTreeSink<'a> {\n     buf: String,\n-    src_querier: &'a Q,\n+    cursor: Cursor<'a>,\n     text_pos: TextUnit,\n-    token_pos: usize,\n     inner: SyntaxTreeBuilder,\n \n     // Number of roots\n     // Use for detect ill-form tree which is not single root\n     roots: smallvec::SmallVec<[usize; 1]>,\n }\n \n-impl<'a, Q: Querier> TtTreeSink<'a, Q> {\n-    fn new(src_querier: &'a Q) -> Self {\n+impl<'a> TtTreeSink<'a> {\n+    fn new(cursor: Cursor<'a>) -> Self {\n         TtTreeSink {\n             buf: String::new(),\n-            src_querier,\n+            cursor,\n             text_pos: 0.into(),\n-            token_pos: 0,\n             inner: SyntaxTreeBuilder::default(),\n             roots: smallvec::SmallVec::new(),\n         }\n     }\n }\n \n-fn is_delimiter(kind: SyntaxKind) -> bool {\n-    match kind {\n-        T!['('] | T!['['] | T!['{'] | T![')'] | T![']'] | T!['}'] => true,\n-        _ => false,\n-    }\n+fn delim_to_str(d: tt::Delimiter, closing: bool) -> SmolStr {\n+    let texts = match d {\n+        tt::Delimiter::Parenthesis => \"()\",\n+        tt::Delimiter::Brace => \"{}\",\n+        tt::Delimiter::Bracket => \"[]\",\n+        tt::Delimiter::None => \"\",\n+    };\n+\n+    let idx = closing as usize;\n+    let text = if texts.len() > 0 { &texts[idx..texts.len() - (1 - idx)] } else { \"\" };\n+    text.into()\n }\n \n-impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n+impl<'a> TreeSink for TtTreeSink<'a> {\n     fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         if kind == L_DOLLAR || kind == R_DOLLAR {\n-            self.token_pos += n_tokens as usize;\n+            if let Some(_) = self.cursor.end() {\n+                self.cursor = self.cursor.bump();\n+            } else {\n+                self.cursor = self.cursor.subtree().unwrap();\n+            }\n             return;\n         }\n \n         for _ in 0..n_tokens {\n-            self.buf += &self.src_querier.token(self.token_pos).1;\n-            self.token_pos += 1;\n+            if self.cursor.eof() {\n+                break;\n+            }\n+\n+            match self.cursor.token_tree() {\n+                Some(tt::TokenTree::Leaf(leaf)) => {\n+                    self.cursor = self.cursor.bump();\n+                    self.buf += &format!(\"{}\", leaf);\n+                }\n+                Some(tt::TokenTree::Subtree(subtree)) => {\n+                    self.cursor = self.cursor.subtree().unwrap();\n+                    self.buf += &delim_to_str(subtree.delimiter, false);\n+                }\n+                None => {\n+                    if let Some(parent) = self.cursor.end() {\n+                        self.cursor = self.cursor.bump();\n+                        self.buf += &delim_to_str(parent.delimiter, true);\n+                    }\n+                }\n+            };\n         }\n+\n         self.text_pos += TextUnit::of_str(&self.buf);\n         let text = SmolStr::new(self.buf.as_str());\n         self.buf.clear();\n         self.inner.token(kind, text);\n \n-        // Add a white space between tokens, only if both are not delimiters\n-        if !is_delimiter(kind) {\n-            let (last_kind, _, last_joint_to_next) = self.src_querier.token(self.token_pos - 1);\n-            if !last_joint_to_next && last_kind.is_punct() {\n-                let (cur_kind, _, _) = self.src_querier.token(self.token_pos);\n-                if !is_delimiter(cur_kind) {\n-                    if cur_kind.is_punct() {\n-                        self.inner.token(WHITESPACE, \" \".into());\n-                    }\n-                }\n+        // Add whitespace between adjoint puncts\n+        let next = self.cursor.bump();\n+        if let (\n+            Some(tt::TokenTree::Leaf(tt::Leaf::Punct(curr))),\n+            Some(tt::TokenTree::Leaf(tt::Leaf::Punct(_))),\n+        ) = (self.cursor.token_tree(), next.token_tree())\n+        {\n+            if curr.spacing == tt::Spacing::Alone {\n+                self.inner.token(WHITESPACE, \" \".into());\n             }\n         }\n     }\n@@ -344,6 +370,7 @@ impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n mod tests {\n     use super::*;\n     use crate::tests::{expand, create_rules};\n+    use ra_parser::TokenSource;\n \n     #[test]\n     fn convert_tt_token_source() {\n@@ -363,24 +390,27 @@ mod tests {\n         );\n         let expansion = expand(&rules, \"literals!(foo)\");\n         let buffer = tt::buffer::TokenBuffer::new(&[expansion.clone().into()]);\n-        let tt_src = SubtreeTokenSource::new(&buffer);\n-\n-        let query = tt_src.querier();\n+        let mut tt_src = SubtreeTokenSource::new(&buffer);\n+        let mut tokens = vec![];\n+        while tt_src.current().kind != EOF {\n+            tokens.push((tt_src.current().kind, tt_src.text()));\n+            tt_src.bump();\n+        }\n \n         // [${]\n         // [let] [a] [=] ['c'] [;]\n-        assert_eq!(query.token(2 + 3).1, \"'c'\");\n-        assert_eq!(query.token(2 + 3).0, CHAR);\n+        assert_eq!(tokens[2 + 3].1, \"'c'\");\n+        assert_eq!(tokens[2 + 3].0, CHAR);\n         // [let] [c] [=] [1000] [;]\n-        assert_eq!(query.token(2 + 5 + 3).1, \"1000\");\n-        assert_eq!(query.token(2 + 5 + 3).0, INT_NUMBER);\n+        assert_eq!(tokens[2 + 5 + 3].1, \"1000\");\n+        assert_eq!(tokens[2 + 5 + 3].0, INT_NUMBER);\n         // [let] [f] [=] [12E+99_f64] [;]\n-        assert_eq!(query.token(2 + 10 + 3).1, \"12E+99_f64\");\n-        assert_eq!(query.token(2 + 10 + 3).0, FLOAT_NUMBER);\n+        assert_eq!(tokens[2 + 10 + 3].1, \"12E+99_f64\");\n+        assert_eq!(tokens[2 + 10 + 3].0, FLOAT_NUMBER);\n \n         // [let] [s] [=] [\"rust1\"] [;]\n-        assert_eq!(query.token(2 + 15 + 3).1, \"\\\"rust1\\\"\");\n-        assert_eq!(query.token(2 + 15 + 3).0, STRING);\n+        assert_eq!(tokens[2 + 15 + 3].1, \"\\\"rust1\\\"\");\n+        assert_eq!(tokens[2 + 15 + 3].0, STRING);\n     }\n \n     #[test]"}]}