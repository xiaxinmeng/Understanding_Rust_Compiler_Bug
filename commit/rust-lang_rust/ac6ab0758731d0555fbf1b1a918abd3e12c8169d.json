{"sha": "ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFjNmFiMDc1ODczMWQwNTU1ZmJmMWIxYTkxOGFiZDNlMTJjODE2OWQ=", "commit": {"author": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-04-08T14:18:57Z"}, "committer": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-04-08T14:18:57Z"}, "message": "Merge #1105\n\n1105: [WIP] Implement ra_mbe meta variables support  r=matklad a=edwin0cheng\n\nThis PR implements the following meta variable support in `ra_mba` crate (issue  #720):\r\n\r\n- [x] `path`\r\n- [ ] `expr`\r\n- [ ] `ty`\r\n- [ ]  `pat`\r\n- [ ] `stmt`\r\n- [ ]  `block`\r\n- [ ]  `meta`\r\n- [ ] `item`\r\n\r\n*Implementation Details*\r\n\r\nIn the macro expanding lhs phase, if we see a meta variable type, we try to create a `tt:TokenTree` from the remaining input. And then we use a special set of `ra_parser` to parse it to `SyntaxNode`. \r\n\n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>", "tree": {"sha": "05f568cbd925dbbd578f9414fd9e4ea3634b68e4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/05f568cbd925dbbd578f9414fd9e4ea3634b68e4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "html_url": "https://github.com/rust-lang/rust/commit/ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "parents": [{"sha": "1ca7a744eb512e6b900988cba871dcd3d90d447f", "url": "https://api.github.com/repos/rust-lang/rust/commits/1ca7a744eb512e6b900988cba871dcd3d90d447f", "html_url": "https://github.com/rust-lang/rust/commit/1ca7a744eb512e6b900988cba871dcd3d90d447f"}, {"sha": "8ed710457875e6f580a0ddf6ab29c6b10d389a41", "url": "https://api.github.com/repos/rust-lang/rust/commits/8ed710457875e6f580a0ddf6ab29c6b10d389a41", "html_url": "https://github.com/rust-lang/rust/commit/8ed710457875e6f580a0ddf6ab29c6b10d389a41"}], "stats": {"total": 914, "additions": 683, "deletions": 231}, "files": [{"sha": "a21ea4dbcbda4a94ea007841536f30bfba5f3d88", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 54, "deletions": 1, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -15,10 +15,13 @@ macro_rules! impl_froms {\n     }\n }\n \n-mod tt_cursor;\n+// mod tt_cursor;\n mod mbe_parser;\n mod mbe_expander;\n mod syntax_bridge;\n+mod tt_cursor;\n+mod subtree_source;\n+mod subtree_parser;\n \n use ra_syntax::SmolStr;\n \n@@ -379,4 +382,54 @@ SOURCE_FILE@[0; 40)\n         // [let] [s] [=] [\"rust1\"] [;]\n         assert_eq!(to_literal(&stm_tokens[15 + 3]).text, \"\\\"rust1\\\"\");\n     }\n+\n+    #[test]\n+    fn test_two_idents() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ i:ident, $ j:ident) => {\n+                fn foo() { let a = $ i; let b = $j; }\n+            }\n+        }\n+\"#,\n+        );\n+        assert_expansion(&rules, \"foo! { foo, bar }\", \"fn foo () {let a = foo ; let b = bar ;}\");\n+    }\n+\n+    // The following tests are port from intellij-rust directly\n+    // https://github.com/intellij-rust/intellij-rust/blob/c4e9feee4ad46e7953b1948c112533360b6087bb/src/test/kotlin/org/rust/lang/core/macros/RsMacroExpansionTest.kt\n+\n+    #[test]\n+    fn test_path() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ i:path) => {\n+                fn foo() { let a = $ i; }\n+            }\n+        }\n+\"#,\n+        );\n+        assert_expansion(&rules, \"foo! { foo }\", \"fn foo () {let a = foo ;}\");\n+        assert_expansion(\n+            &rules,\n+            \"foo! { bar::<u8>::baz::<u8> }\",\n+            \"fn foo () {let a = bar ::< u8 > ::baz ::< u8 > ;}\",\n+        );\n+    }\n+\n+    #[test]\n+    fn test_two_paths() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ i:path, $ j:path) => {\n+                fn foo() { let a = $ i; let b = $j; }\n+            }\n+        }\n+\"#,\n+        );\n+        assert_expansion(&rules, \"foo! { foo, bar }\", \"fn foo () {let a = foo ; let b = bar ;}\");\n+    }\n }"}, {"sha": "ce41d722562d7e0f8ed30f0ea1fc083e3b076ee8", "filename": "crates/ra_mbe/src/mbe_expander.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fmbe_expander.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fmbe_expander.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fmbe_expander.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -139,6 +139,11 @@ fn match_lhs(pattern: &crate::Subtree, input: &mut TtCursor) -> Result<Bindings,\n                                 Binding::Simple(tt::Leaf::from(ident).into()),\n                             );\n                         }\n+                        \"path\" => {\n+                            let path =\n+                                input.eat_path().ok_or(ExpandError::UnexpectedToken)?.clone();\n+                            res.inner.insert(text.clone(), Binding::Simple(path.into()));\n+                        }\n                         _ => return Err(ExpandError::UnexpectedToken),\n                     }\n                 }"}, {"sha": "ce39a40bb545d6dd55121d413e4430c4765a1f93", "filename": "crates/ra_mbe/src/subtree_parser.rs", "status": "added", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -0,0 +1,61 @@\n+use crate::subtree_source::SubtreeTokenSource;\n+\n+use ra_parser::{TokenSource, TreeSink};\n+use ra_syntax::{SyntaxKind};\n+\n+struct OffsetTokenSink {\n+    token_pos: usize,\n+}\n+\n+impl TreeSink for OffsetTokenSink {\n+    fn token(&mut self, _kind: SyntaxKind, n_tokens: u8) {\n+        self.token_pos += n_tokens as usize;\n+    }\n+    fn start_node(&mut self, _kind: SyntaxKind) {}\n+    fn finish_node(&mut self) {}\n+    fn error(&mut self, _error: ra_parser::ParseError) {}\n+}\n+\n+pub(crate) struct Parser<'a> {\n+    subtree: &'a tt::Subtree,\n+    cur_pos: &'a mut usize,\n+}\n+\n+impl<'a> Parser<'a> {\n+    pub fn new(cur_pos: &'a mut usize, subtree: &'a tt::Subtree) -> Parser<'a> {\n+        Parser { cur_pos, subtree }\n+    }\n+\n+    pub fn parse_path(self) -> Option<tt::TokenTree> {\n+        self.parse(ra_parser::parse_path)\n+    }\n+\n+    fn parse<F>(self, f: F) -> Option<tt::TokenTree>\n+    where\n+        F: FnOnce(&dyn TokenSource, &mut dyn TreeSink),\n+    {\n+        let mut src = SubtreeTokenSource::new(self.subtree);\n+        src.start_from_nth(*self.cur_pos);\n+        let mut sink = OffsetTokenSink { token_pos: 0 };\n+\n+        f(&src, &mut sink);\n+\n+        self.finish(sink.token_pos, &mut src)\n+    }\n+\n+    fn finish(self, parsed_token: usize, src: &mut SubtreeTokenSource) -> Option<tt::TokenTree> {\n+        let res = src.bump_n(parsed_token);\n+        *self.cur_pos += res.len();\n+\n+        let res: Vec<_> = res.into_iter().cloned().collect();\n+\n+        match res.len() {\n+            0 => None,\n+            1 => Some(res[0].clone()),\n+            _ => Some(tt::TokenTree::Subtree(tt::Subtree {\n+                delimiter: tt::Delimiter::None,\n+                token_trees: res,\n+            })),\n+        }\n+    }\n+}"}, {"sha": "4b37c2bdadd522eaac23af7bca4515e00d29b47d", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "added", "additions": 521, "deletions": 0, "changes": 521, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -0,0 +1,521 @@\n+use ra_parser::{TokenSource};\n+use ra_syntax::{classify_literal, SmolStr, SyntaxKind, SyntaxKind::*};\n+use std::cell::{RefCell};\n+\n+#[derive(Debug, Clone, Eq, PartialEq)]\n+struct TtToken {\n+    pub kind: SyntaxKind,\n+    pub is_joint_to_next: bool,\n+    pub text: SmolStr,\n+    pub n_tokens: usize,\n+}\n+\n+#[derive(Debug, Clone, Eq, PartialEq)]\n+enum WalkCursor {\n+    DelimiterBegin(Option<TtToken>),\n+    Token(usize, Option<TtToken>),\n+    DelimiterEnd(Option<TtToken>),\n+    Eof,\n+}\n+\n+#[derive(Debug)]\n+struct SubTreeWalker<'a> {\n+    pos: usize,\n+    stack: Vec<(&'a tt::Subtree, Option<usize>)>,\n+    cursor: WalkCursor,\n+    last_steps: Vec<usize>,\n+    subtree: &'a tt::Subtree,\n+}\n+\n+impl<'a> SubTreeWalker<'a> {\n+    fn new(subtree: &tt::Subtree) -> SubTreeWalker {\n+        let mut res = SubTreeWalker {\n+            pos: 0,\n+            stack: vec![],\n+            cursor: WalkCursor::Eof,\n+            last_steps: vec![],\n+            subtree,\n+        };\n+\n+        res.reset();\n+        res\n+    }\n+\n+    fn is_eof(&self) -> bool {\n+        self.cursor == WalkCursor::Eof\n+    }\n+\n+    fn reset(&mut self) {\n+        self.pos = 0;\n+        self.stack = vec![(self.subtree, None)];\n+        self.cursor = WalkCursor::DelimiterBegin(convert_delim(self.subtree.delimiter, false));\n+        self.last_steps = vec![];\n+\n+        while self.is_empty_delimiter() {\n+            self.forward_unchecked();\n+        }\n+    }\n+\n+    // This funciton will fast forward the cursor,\n+    // Such that backward will stop at `start_pos` point\n+    fn start_from_nth(&mut self, start_pos: usize) {\n+        self.reset();\n+        self.pos = start_pos;\n+        self.cursor = self.walk_token(start_pos, 0, false);\n+\n+        while self.is_empty_delimiter() {\n+            self.forward_unchecked();\n+        }\n+    }\n+\n+    fn current(&self) -> Option<&TtToken> {\n+        match &self.cursor {\n+            WalkCursor::DelimiterBegin(t) => t.as_ref(),\n+            WalkCursor::Token(_, t) => t.as_ref(),\n+            WalkCursor::DelimiterEnd(t) => t.as_ref(),\n+            WalkCursor::Eof => None,\n+        }\n+    }\n+\n+    fn is_empty_delimiter(&self) -> bool {\n+        match &self.cursor {\n+            WalkCursor::DelimiterBegin(None) => true,\n+            WalkCursor::DelimiterEnd(None) => true,\n+            _ => false,\n+        }\n+    }\n+\n+    /// Move cursor backward by 1 step with empty checking\n+    fn backward(&mut self) {\n+        if self.last_steps.is_empty() {\n+            return;\n+        }\n+        self.pos -= 1;\n+        loop {\n+            self.backward_unchecked();\n+            // Skip Empty delimiter\n+            if self.last_steps.is_empty() || !self.is_empty_delimiter() {\n+                break;\n+            }\n+        }\n+\n+        // Move forward if it is empty delimiter\n+        if self.last_steps.is_empty() {\n+            while self.is_empty_delimiter() {\n+                self.forward_unchecked();\n+            }\n+        }\n+    }\n+\n+    /// Move cursor backward by 1 step without empty check\n+    ///\n+    /// Depends on the current state of cursor:\n+    ///\n+    /// * Delimiter Begin => Pop the stack, goto last walking token  (`walk_token`)\n+    /// * Token => Goto prev token  (`walk_token`)\n+    /// * Delimiter End => Goto the last child token (`walk_token`)\n+    /// * Eof => push the root subtree, and set it as Delimiter End\n+    fn backward_unchecked(&mut self) {\n+        if self.last_steps.is_empty() {\n+            return;\n+        }\n+\n+        let last_step = self.last_steps.pop().unwrap();\n+        let do_walk_token = match self.cursor {\n+            WalkCursor::DelimiterBegin(_) => None,\n+            WalkCursor::Token(u, _) => Some(u),\n+            WalkCursor::DelimiterEnd(_) => {\n+                let (top, _) = self.stack.last().unwrap();\n+                Some(top.token_trees.len())\n+            }\n+            WalkCursor::Eof => None,\n+        };\n+\n+        self.cursor = match do_walk_token {\n+            Some(u) => self.walk_token(u, last_step, true),\n+            None => match self.cursor {\n+                WalkCursor::Eof => {\n+                    self.stack.push((self.subtree, None));\n+                    WalkCursor::DelimiterEnd(convert_delim(\n+                        self.stack.last().unwrap().0.delimiter,\n+                        true,\n+                    ))\n+                }\n+                _ => {\n+                    let (_, last_top_cursor) = self.stack.pop().unwrap();\n+                    assert!(!self.stack.is_empty());\n+\n+                    self.walk_token(last_top_cursor.unwrap(), last_step, true)\n+                }\n+            },\n+        };\n+    }\n+\n+    /// Move cursor forward by 1 step with empty checking\n+    fn forward(&mut self) {\n+        if self.is_eof() {\n+            return;\n+        }\n+\n+        self.pos += 1;\n+        loop {\n+            self.forward_unchecked();\n+            if !self.is_empty_delimiter() {\n+                break;\n+            }\n+        }\n+    }\n+\n+    /// Move cursor forward by 1 step without empty checking\n+    ///\n+    /// Depends on the current state of cursor:\n+    ///\n+    /// * Delimiter Begin => Goto the first child token (`walk_token`)\n+    /// * Token => Goto next token  (`walk_token`)\n+    /// * Delimiter End => Pop the stack, goto last walking token  (`walk_token`)\n+    ///   \n+    fn forward_unchecked(&mut self) {\n+        if self.is_eof() {\n+            return;\n+        }\n+\n+        let step = self.current().map(|x| x.n_tokens).unwrap_or(1);\n+        self.last_steps.push(step);\n+\n+        let do_walk_token = match self.cursor {\n+            WalkCursor::DelimiterBegin(_) => Some((0, 0)),\n+            WalkCursor::Token(u, _) => Some((u, step)),\n+            WalkCursor::DelimiterEnd(_) => None,\n+            _ => unreachable!(),\n+        };\n+\n+        self.cursor = match do_walk_token {\n+            Some((u, step)) => self.walk_token(u, step, false),\n+            None => {\n+                let (_, last_top_idx) = self.stack.pop().unwrap();\n+                match self.stack.last() {\n+                    Some(_) => self.walk_token(last_top_idx.unwrap(), 1, false),\n+                    None => WalkCursor::Eof,\n+                }\n+            }\n+        };\n+    }\n+\n+    /// Traversal child token\n+    /// Depends on the new position, it returns:\n+    ///\n+    /// * new position < 0 => DelimiterBegin\n+    /// * new position > token_tree.len() => DelimiterEnd\n+    /// * if new position is a subtree, depends on traversal direction:\n+    /// ** backward => DelimiterEnd\n+    /// ** forward => DelimiterBegin\n+    /// * if new psoition is a leaf, return walk_leaf()\n+    fn walk_token(&mut self, pos: usize, offset: usize, backward: bool) -> WalkCursor {\n+        let (top, _) = self.stack.last().unwrap();\n+\n+        if backward && pos < offset {\n+            return WalkCursor::DelimiterBegin(convert_delim(\n+                self.stack.last().unwrap().0.delimiter,\n+                false,\n+            ));\n+        }\n+\n+        if !backward && pos + offset >= top.token_trees.len() {\n+            return WalkCursor::DelimiterEnd(convert_delim(\n+                self.stack.last().unwrap().0.delimiter,\n+                true,\n+            ));\n+        }\n+\n+        let pos = if backward { pos - offset } else { pos + offset };\n+\n+        match &top.token_trees[pos] {\n+            tt::TokenTree::Subtree(subtree) => {\n+                self.stack.push((subtree, Some(pos)));\n+                let delim = convert_delim(self.stack.last().unwrap().0.delimiter, backward);\n+                if backward {\n+                    WalkCursor::DelimiterEnd(delim)\n+                } else {\n+                    WalkCursor::DelimiterBegin(delim)\n+                }\n+            }\n+            tt::TokenTree::Leaf(leaf) => WalkCursor::Token(pos, Some(self.walk_leaf(leaf, pos))),\n+        }\n+    }\n+\n+    fn walk_leaf(&mut self, leaf: &tt::Leaf, pos: usize) -> TtToken {\n+        match leaf {\n+            tt::Leaf::Literal(l) => convert_literal(l),\n+            tt::Leaf::Ident(ident) => convert_ident(ident),\n+            tt::Leaf::Punct(punct) => {\n+                let (top, _) = self.stack.last().unwrap();\n+                convert_punct(punct, top, pos)\n+            }\n+        }\n+    }\n+}\n+\n+pub(crate) trait Querier {\n+    fn token(&self, uidx: usize) -> (SyntaxKind, SmolStr);\n+}\n+\n+// A wrapper class for ref cell\n+#[derive(Debug)]\n+pub(crate) struct WalkerOwner<'a> {\n+    walker: RefCell<SubTreeWalker<'a>>,\n+    offset: usize,\n+}\n+\n+impl<'a> WalkerOwner<'a> {\n+    fn new(subtree: &'a tt::Subtree) -> Self {\n+        WalkerOwner { walker: RefCell::new(SubTreeWalker::new(subtree)), offset: 0 }\n+    }\n+\n+    fn get<'b>(&self, pos: usize) -> Option<TtToken> {\n+        self.set_walker_pos(pos);\n+        let walker = self.walker.borrow();\n+        walker.current().cloned()\n+    }\n+\n+    fn start_from_nth(&mut self, pos: usize) {\n+        self.offset = pos;\n+        self.walker.borrow_mut().start_from_nth(pos);\n+    }\n+\n+    fn set_walker_pos(&self, mut pos: usize) {\n+        pos += self.offset;\n+        let mut walker = self.walker.borrow_mut();\n+        while pos > walker.pos && !walker.is_eof() {\n+            walker.forward();\n+        }\n+        while pos < walker.pos {\n+            walker.backward();\n+        }\n+    }\n+\n+    fn collect_token_trees(&mut self, n: usize) -> Vec<&tt::TokenTree> {\n+        self.start_from_nth(self.offset);\n+\n+        let mut res = vec![];\n+        let mut walker = self.walker.borrow_mut();\n+\n+        while walker.pos - self.offset < n {\n+            if let WalkCursor::Token(u, tt) = &walker.cursor {\n+                if walker.stack.len() == 1 {\n+                    // We only collect the topmost child\n+                    res.push(&walker.stack[0].0.token_trees[*u]);\n+                    if let Some(tt) = tt {\n+                        for i in 0..tt.n_tokens - 1 {\n+                            res.push(&walker.stack[0].0.token_trees[u + i]);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            walker.forward();\n+        }\n+\n+        res\n+    }\n+}\n+\n+impl<'a> Querier for WalkerOwner<'a> {\n+    fn token(&self, uidx: usize) -> (SyntaxKind, SmolStr) {\n+        let tkn = self.get(uidx).unwrap();\n+        (tkn.kind, tkn.text)\n+    }\n+}\n+\n+pub(crate) struct SubtreeTokenSource<'a> {\n+    walker: WalkerOwner<'a>,\n+}\n+\n+impl<'a> SubtreeTokenSource<'a> {\n+    pub fn new(subtree: &tt::Subtree) -> SubtreeTokenSource {\n+        SubtreeTokenSource { walker: WalkerOwner::new(subtree) }\n+    }\n+\n+    pub fn start_from_nth(&mut self, n: usize) {\n+        self.walker.start_from_nth(n);\n+    }\n+\n+    pub fn querier<'b>(&'a self) -> &'b WalkerOwner<'a>\n+    where\n+        'a: 'b,\n+    {\n+        &self.walker\n+    }\n+\n+    pub(crate) fn bump_n(&mut self, parsed_tokens: usize) -> Vec<&tt::TokenTree> {\n+        let res = self.walker.collect_token_trees(parsed_tokens);\n+        res\n+    }\n+}\n+\n+impl<'a> TokenSource for SubtreeTokenSource<'a> {\n+    fn token_kind(&self, pos: usize) -> SyntaxKind {\n+        if let Some(tok) = self.walker.get(pos) {\n+            tok.kind\n+        } else {\n+            SyntaxKind::EOF\n+        }\n+    }\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n+        self.walker.get(pos).unwrap().is_joint_to_next\n+    }\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n+        self.walker.get(pos).unwrap().text == *kw\n+    }\n+}\n+\n+struct TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    iter: itertools::MultiPeek<I>,\n+}\n+\n+// helper function\n+fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n+    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n+        return Some(pp);\n+    }\n+    None\n+}\n+\n+impl<'a, I> TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    pub fn new(iter: I) -> Self {\n+        TokenPeek { iter: itertools::multipeek(iter) }\n+    }\n+\n+    fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n+        if p.spacing != tt::Spacing::Joint {\n+            return None;\n+        }\n+\n+        self.iter.reset_peek();\n+        let p1 = to_punct(self.iter.peek()?)?;\n+        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n+    }\n+\n+    fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n+        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n+            if !last_joint {\n+                None\n+            } else {\n+                let p2 = to_punct(*self.iter.peek()?)?;\n+                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n+            }\n+        })\n+    }\n+}\n+\n+fn convert_multi_char_punct<'b, I>(\n+    p: &tt::Punct,\n+    iter: &mut TokenPeek<'b, I>,\n+) -> Option<(SyntaxKind, bool, &'static str, usize)>\n+where\n+    I: Iterator<Item = &'b tt::TokenTree>,\n+{\n+    if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n+        if let Some((kind, text)) = match m {\n+            ('<', '<', '=') => Some((SHLEQ, \"<<=\")),\n+            ('>', '>', '=') => Some((SHREQ, \">>=\")),\n+            ('.', '.', '.') => Some((DOTDOTDOT, \"...\")),\n+            ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n+            _ => None,\n+        } {\n+            return Some((kind, is_joint_to_next, text, 3));\n+        }\n+    }\n+\n+    if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n+        if let Some((kind, text)) = match m {\n+            ('<', '<') => Some((SHL, \"<<\")),\n+            ('>', '>') => Some((SHR, \">>\")),\n+\n+            ('|', '|') => Some((PIPEPIPE, \"||\")),\n+            ('&', '&') => Some((AMPAMP, \"&&\")),\n+            ('%', '=') => Some((PERCENTEQ, \"%=\")),\n+            ('*', '=') => Some((STAREQ, \"*=\")),\n+            ('/', '=') => Some((SLASHEQ, \"/=\")),\n+            ('^', '=') => Some((CARETEQ, \"^=\")),\n+\n+            ('&', '=') => Some((AMPEQ, \"&=\")),\n+            ('|', '=') => Some((PIPEEQ, \"|=\")),\n+            ('-', '=') => Some((MINUSEQ, \"-=\")),\n+            ('+', '=') => Some((PLUSEQ, \"+=\")),\n+            ('>', '=') => Some((GTEQ, \">=\")),\n+            ('<', '=') => Some((LTEQ, \"<=\")),\n+\n+            ('-', '>') => Some((THIN_ARROW, \"->\")),\n+            ('!', '=') => Some((NEQ, \"!=\")),\n+            ('=', '>') => Some((FAT_ARROW, \"=>\")),\n+            ('=', '=') => Some((EQEQ, \"==\")),\n+            ('.', '.') => Some((DOTDOT, \"..\")),\n+            (':', ':') => Some((COLONCOLON, \"::\")),\n+\n+            _ => None,\n+        } {\n+            return Some((kind, is_joint_to_next, text, 2));\n+        }\n+    }\n+\n+    None\n+}\n+\n+fn convert_delim(d: tt::Delimiter, closing: bool) -> Option<TtToken> {\n+    let (kinds, texts) = match d {\n+        tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n+        tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n+        tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n+        tt::Delimiter::None => return None,\n+    };\n+\n+    let idx = closing as usize;\n+    let kind = kinds[idx];\n+    let text = &texts[idx..texts.len() - (1 - idx)];\n+    Some(TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 })\n+}\n+\n+fn convert_literal(l: &tt::Literal) -> TtToken {\n+    TtToken {\n+        kind: classify_literal(&l.text).unwrap().kind,\n+        is_joint_to_next: false,\n+        text: l.text.clone(),\n+        n_tokens: 1,\n+    }\n+}\n+\n+fn convert_ident(ident: &tt::Ident) -> TtToken {\n+    let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n+    TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n+}\n+\n+fn convert_punct(p: &tt::Punct, parent: &tt::Subtree, next: usize) -> TtToken {\n+    let iter = parent.token_trees[next + 1..].iter();\n+    let mut peek = TokenPeek::new(iter);\n+\n+    if let Some((kind, is_joint_to_next, text, size)) = convert_multi_char_punct(p, &mut peek) {\n+        TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n+    } else {\n+        let kind = match p.char {\n+            // lexer may produce combpund tokens for these ones\n+            '.' => DOT,\n+            ':' => COLON,\n+            '=' => EQ,\n+            '!' => EXCL,\n+            '-' => MINUS,\n+            c => SyntaxKind::from_char(c).unwrap(),\n+        };\n+        let text = {\n+            let mut buf = [0u8; 4];\n+            let s: &str = p.char.encode_utf8(&mut buf);\n+            SmolStr::new(s)\n+        };\n+        TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text, n_tokens: 1 }\n+    }\n+}"}, {"sha": "19c17bd550b953db767a1e7ff4d5c753f4d3bb85", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 24, "deletions": 230, "changes": 254, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -1,9 +1,11 @@\n-use ra_parser::{TokenSource, TreeSink, ParseError};\n+use ra_parser::{TreeSink, ParseError};\n use ra_syntax::{\n     AstNode, SyntaxNode, TextRange, SyntaxKind, SmolStr, SyntaxTreeBuilder, TreeArc, SyntaxElement,\n-    ast, SyntaxKind::*, TextUnit, classify_literal\n+    ast, SyntaxKind::*, TextUnit\n };\n \n+use crate::subtree_source::{SubtreeTokenSource, Querier};\n+\n /// Maps `tt::TokenId` to the relative range of the original token.\n #[derive(Default)]\n pub struct TokenMap {\n@@ -22,8 +24,8 @@ pub fn ast_to_token_tree(ast: &ast::TokenTree) -> Option<(tt::Subtree, TokenMap)\n \n /// Parses the token tree (result of macro expansion) as a sequence of items\n pub fn token_tree_to_ast_item_list(tt: &tt::Subtree) -> TreeArc<ast::SourceFile> {\n-    let token_source = TtTokenSource::new(tt);\n-    let mut tree_sink = TtTreeSink::new(&token_source.tokens);\n+    let token_source = SubtreeTokenSource::new(tt);\n+    let mut tree_sink = TtTreeSink::new(token_source.querier());\n     ra_parser::parse(&token_source, &mut tree_sink);\n     let syntax = tree_sink.inner.finish();\n     ast::SourceFile::cast(&syntax).unwrap().to_owned()\n@@ -103,240 +105,30 @@ fn convert_tt(\n     Some(res)\n }\n \n-#[derive(Debug)]\n-struct TtTokenSource {\n-    tokens: Vec<TtToken>,\n-}\n-\n-#[derive(Debug)]\n-struct TtToken {\n-    kind: SyntaxKind,\n-    is_joint_to_next: bool,\n-    text: SmolStr,\n-}\n-\n-// Some helper functions\n-fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n-    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n-        return Some(pp);\n-    }\n-    None\n-}\n-\n-struct TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    iter: itertools::MultiPeek<I>,\n-}\n-\n-impl<'a, I> TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    fn next(&mut self) -> Option<&tt::TokenTree> {\n-        self.iter.next()\n-    }\n-\n-    fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n-        if p.spacing != tt::Spacing::Joint {\n-            return None;\n-        }\n-\n-        self.iter.reset_peek();\n-        let p1 = to_punct(self.iter.peek()?)?;\n-        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n-    }\n-\n-    fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n-        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n-            if !last_joint {\n-                None\n-            } else {\n-                let p2 = to_punct(*self.iter.peek()?)?;\n-                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n-            }\n-        })\n-    }\n-}\n-\n-impl TtTokenSource {\n-    fn new(tt: &tt::Subtree) -> TtTokenSource {\n-        let mut res = TtTokenSource { tokens: Vec::new() };\n-        res.convert_subtree(tt);\n-        res\n-    }\n-    fn convert_subtree(&mut self, sub: &tt::Subtree) {\n-        self.push_delim(sub.delimiter, false);\n-        let mut peek = TokenPeek { iter: itertools::multipeek(sub.token_trees.iter()) };\n-        while let Some(tt) = peek.iter.next() {\n-            self.convert_tt(tt, &mut peek);\n-        }\n-        self.push_delim(sub.delimiter, true)\n-    }\n-\n-    fn convert_tt<'a, I>(&mut self, tt: &tt::TokenTree, iter: &mut TokenPeek<'a, I>)\n-    where\n-        I: Iterator<Item = &'a tt::TokenTree>,\n-    {\n-        match tt {\n-            tt::TokenTree::Leaf(token) => self.convert_token(token, iter),\n-            tt::TokenTree::Subtree(sub) => self.convert_subtree(sub),\n-        }\n-    }\n-\n-    fn convert_token<'a, I>(&mut self, token: &tt::Leaf, iter: &mut TokenPeek<'a, I>)\n-    where\n-        I: Iterator<Item = &'a tt::TokenTree>,\n-    {\n-        let tok = match token {\n-            tt::Leaf::Literal(l) => TtToken {\n-                kind: classify_literal(&l.text).unwrap().kind,\n-                is_joint_to_next: false,\n-                text: l.text.clone(),\n-            },\n-            tt::Leaf::Punct(p) => {\n-                if let Some(tt) = Self::convert_multi_char_punct(p, iter) {\n-                    tt\n-                } else {\n-                    let kind = match p.char {\n-                        // lexer may produce combpund tokens for these ones\n-                        '.' => DOT,\n-                        ':' => COLON,\n-                        '=' => EQ,\n-                        '!' => EXCL,\n-                        '-' => MINUS,\n-                        c => SyntaxKind::from_char(c).unwrap(),\n-                    };\n-                    let text = {\n-                        let mut buf = [0u8; 4];\n-                        let s: &str = p.char.encode_utf8(&mut buf);\n-                        SmolStr::new(s)\n-                    };\n-                    TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n-                }\n-            }\n-            tt::Leaf::Ident(ident) => {\n-                let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n-                TtToken { kind, is_joint_to_next: false, text: ident.text.clone() }\n-            }\n-        };\n-        self.tokens.push(tok)\n-    }\n-\n-    fn convert_multi_char_punct<'a, I>(\n-        p: &tt::Punct,\n-        iter: &mut TokenPeek<'a, I>,\n-    ) -> Option<TtToken>\n-    where\n-        I: Iterator<Item = &'a tt::TokenTree>,\n-    {\n-        if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n-            if let Some((kind, text)) = match m {\n-                ('<', '<', '=') => Some((SHLEQ, \"<<=\")),\n-                ('>', '>', '=') => Some((SHREQ, \">>=\")),\n-                ('.', '.', '.') => Some((DOTDOTDOT, \"...\")),\n-                ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n-                _ => None,\n-            } {\n-                iter.next();\n-                iter.next();\n-                return Some(TtToken { kind, is_joint_to_next, text: text.into() });\n-            }\n-        }\n-\n-        if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n-            if let Some((kind, text)) = match m {\n-                ('<', '<') => Some((SHL, \"<<\")),\n-                ('>', '>') => Some((SHR, \">>\")),\n-\n-                ('|', '|') => Some((PIPEPIPE, \"||\")),\n-                ('&', '&') => Some((AMPAMP, \"&&\")),\n-                ('%', '=') => Some((PERCENTEQ, \"%=\")),\n-                ('*', '=') => Some((STAREQ, \"*=\")),\n-                ('/', '=') => Some((SLASHEQ, \"/=\")),\n-                ('^', '=') => Some((CARETEQ, \"^=\")),\n-\n-                ('&', '=') => Some((AMPEQ, \"&=\")),\n-                ('|', '=') => Some((PIPEEQ, \"|=\")),\n-                ('-', '=') => Some((MINUSEQ, \"-=\")),\n-                ('+', '=') => Some((PLUSEQ, \"+=\")),\n-                ('>', '=') => Some((GTEQ, \">=\")),\n-                ('<', '=') => Some((LTEQ, \"<=\")),\n-\n-                ('-', '>') => Some((THIN_ARROW, \"->\")),\n-                ('!', '=') => Some((NEQ, \"!=\")),\n-                ('=', '>') => Some((FAT_ARROW, \"=>\")),\n-                ('=', '=') => Some((EQEQ, \"==\")),\n-                ('.', '.') => Some((DOTDOT, \"..\")),\n-                (':', ':') => Some((COLONCOLON, \"::\")),\n-\n-                _ => None,\n-            } {\n-                iter.next();\n-                return Some(TtToken { kind, is_joint_to_next, text: text.into() });\n-            }\n-        }\n-\n-        None\n-    }\n-\n-    fn push_delim(&mut self, d: tt::Delimiter, closing: bool) {\n-        let (kinds, texts) = match d {\n-            tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n-            tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n-            tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n-            tt::Delimiter::None => return,\n-        };\n-        let idx = closing as usize;\n-        let kind = kinds[idx];\n-        let text = &texts[idx..texts.len() - (1 - idx)];\n-        let tok = TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text) };\n-        self.tokens.push(tok)\n-    }\n-}\n-\n-impl TokenSource for TtTokenSource {\n-    fn token_kind(&self, pos: usize) -> SyntaxKind {\n-        if let Some(tok) = self.tokens.get(pos) {\n-            tok.kind\n-        } else {\n-            SyntaxKind::EOF\n-        }\n-    }\n-    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n-        self.tokens[pos].is_joint_to_next\n-    }\n-    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n-        self.tokens[pos].text == *kw\n-    }\n-}\n-\n-#[derive(Default)]\n-struct TtTreeSink<'a> {\n+struct TtTreeSink<'a, Q: Querier> {\n     buf: String,\n-    tokens: &'a [TtToken],\n+    src_querier: &'a Q,\n     text_pos: TextUnit,\n     token_pos: usize,\n     inner: SyntaxTreeBuilder,\n }\n \n-impl<'a> TtTreeSink<'a> {\n-    fn new(tokens: &'a [TtToken]) -> TtTreeSink {\n+impl<'a, Q: Querier> TtTreeSink<'a, Q> {\n+    fn new(src_querier: &'a Q) -> Self {\n         TtTreeSink {\n             buf: String::new(),\n-            tokens,\n+            src_querier,\n             text_pos: 0.into(),\n             token_pos: 0,\n             inner: SyntaxTreeBuilder::default(),\n         }\n     }\n }\n \n-impl<'a> TreeSink for TtTreeSink<'a> {\n+impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n     fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         for _ in 0..n_tokens {\n-            self.buf += self.tokens[self.token_pos].text.as_str();\n+            self.buf += &self.src_querier.token(self.token_pos).1;\n             self.token_pos += 1;\n         }\n         self.text_pos += TextUnit::of_str(&self.buf);\n@@ -380,21 +172,23 @@ mod tests {\n             \"#,\n         );\n         let expansion = expand(&rules, \"literals!(foo)\");\n-        let tt_src = TtTokenSource::new(&expansion);\n+        let tt_src = SubtreeTokenSource::new(&expansion);\n+\n+        let query = tt_src.querier();\n \n         // [{]\n         // [let] [a] [=] ['c'] [;]\n-        assert_eq!(tt_src.tokens[1 + 3].text, \"'c'\");\n-        assert_eq!(tt_src.tokens[1 + 3].kind, CHAR);\n+        assert_eq!(query.token(1 + 3).1, \"'c'\");\n+        assert_eq!(query.token(1 + 3).0, CHAR);\n         // [let] [c] [=] [1000] [;]\n-        assert_eq!(tt_src.tokens[1 + 5 + 3].text, \"1000\");\n-        assert_eq!(tt_src.tokens[1 + 5 + 3].kind, INT_NUMBER);\n+        assert_eq!(query.token(1 + 5 + 3).1, \"1000\");\n+        assert_eq!(query.token(1 + 5 + 3).0, INT_NUMBER);\n         // [let] [f] [=] [12E+99_f64] [;]\n-        assert_eq!(tt_src.tokens[1 + 10 + 3].text, \"12E+99_f64\");\n-        assert_eq!(tt_src.tokens[1 + 10 + 3].kind, FLOAT_NUMBER);\n+        assert_eq!(query.token(1 + 10 + 3).1, \"12E+99_f64\");\n+        assert_eq!(query.token(1 + 10 + 3).0, FLOAT_NUMBER);\n \n         // [let] [s] [=] [\"rust1\"] [;]\n-        assert_eq!(tt_src.tokens[1 + 15 + 3].text, \"\\\"rust1\\\"\");\n-        assert_eq!(tt_src.tokens[1 + 15 + 3].kind, STRING);\n+        assert_eq!(query.token(1 + 15 + 3).1, \"\\\"rust1\\\"\");\n+        assert_eq!(query.token(1 + 15 + 3).0, STRING);\n     }\n }"}, {"sha": "d29faa77ce8dbc26cf9f47f0775c8a32389c87e5", "filename": "crates/ra_mbe/src/tt_cursor.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -1,4 +1,5 @@\n use crate::ParseError;\n+use crate::subtree_parser::Parser;\n \n #[derive(Clone)]\n pub(crate) struct TtCursor<'a> {\n@@ -78,6 +79,11 @@ impl<'a> TtCursor<'a> {\n         })\n     }\n \n+    pub(crate) fn eat_path(&mut self) -> Option<tt::TokenTree> {\n+        let parser = Parser::new(&mut self.pos, self.subtree);\n+        parser.parse_path()\n+    }\n+\n     pub(crate) fn expect_char(&mut self, char: char) -> Result<(), ParseError> {\n         if self.at_char(char) {\n             self.bump();"}, {"sha": "c5f510e6b7779705d3995a8e453cdc4d271884bb", "filename": "crates/ra_parser/src/grammar.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_parser%2Fsrc%2Fgrammar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_parser%2Fsrc%2Fgrammar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Fgrammar.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -49,6 +49,10 @@ pub(crate) fn root(p: &mut Parser) {\n     m.complete(p, SOURCE_FILE);\n }\n \n+pub(crate) fn path(p: &mut Parser) {\n+    paths::type_path(p);\n+}\n+\n pub(crate) fn reparser(\n     node: SyntaxKind,\n     first_child: Option<SyntaxKind>,"}, {"sha": "3ceeeebd75150aba0f22ceaa3b5e9b6cae0b70e1", "filename": "crates/ra_parser/src/lib.rs", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_parser%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac6ab0758731d0555fbf1b1a918abd3e12c8169d/crates%2Fra_parser%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Flib.rs?ref=ac6ab0758731d0555fbf1b1a918abd3e12c8169d", "patch": "@@ -61,6 +61,14 @@ pub fn parse(token_source: &dyn TokenSource, tree_sink: &mut dyn TreeSink) {\n     event::process(tree_sink, events);\n }\n \n+/// Parse given tokens into the given sink as a path\n+pub fn parse_path(token_source: &dyn TokenSource, tree_sink: &mut dyn TreeSink) {\n+    let mut p = parser::Parser::new(token_source);\n+    grammar::path(&mut p);\n+    let events = p.finish();\n+    event::process(tree_sink, events);\n+}\n+\n /// A parsing function for a specific braced-block.\n pub struct Reparser(fn(&mut parser::Parser));\n "}]}